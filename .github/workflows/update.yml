name: Daily arXiv Update

on:
  schedule:
    # Run at 00:20 UTC every day
    - cron: '20 0 * * *'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to process (YYYY-MM-DD format)'
        required: false
        type: string
      start-date:
        description: 'Start date for date range (YYYY-MM-DD format)'
        required: false
        type: string
      end-date:
        description: 'End date for date range (YYYY-MM-DD format, inclusive)'
        required: false
        type: string
      category:
        description: 'arXiv category to process'
        required: false
        default: 'cs.AI'
        type: string
      max-results:
        description: 'Maximum number of papers to fetch'
        required: false
        default: '1000' # Default value from script
        type: string
      force:
        description: 'Force refresh existing data'
        required: false
        default: false
        type: boolean
      log-level:
        description: 'Set logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)'
        required: false
        default: 'INFO' # Default value from script
        type: string

jobs:
  update:
    runs-on: ubuntu-latest
    env:
      # Core settings (match .env.sample; values can come from secrets or vars)
      DDARXIV_DATA_DIR: ${{ secrets.DDARXIV_DATA_DIR || vars.DDARXIV_DATA_DIR }}
      DDARXIV_LOG_DIR: ${{ secrets.DDARXIV_LOG_DIR || vars.DDARXIV_LOG_DIR }}
      DDARXIV_LOG_LEVEL: ${{ secrets.DDARXIV_LOG_LEVEL || vars.DDARXIV_LOG_LEVEL }}
      DDARXIV_CATEGORY: ${{ secrets.DDARXIV_CATEGORY || vars.DDARXIV_CATEGORY }}
      DDARXIV_MAX_RESULTS: ${{ secrets.DDARXIV_MAX_RESULTS || vars.DDARXIV_MAX_RESULTS }}
      DDARXIV_CONCURRENCY: ${{ secrets.DDARXIV_CONCURRENCY || vars.DDARXIV_CONCURRENCY }}
      DDARXIV_BATCH_SIZE: ${{ secrets.DDARXIV_BATCH_SIZE || vars.DDARXIV_BATCH_SIZE }}
      DDARXIV_FORCE: ${{ secrets.DDARXIV_FORCE || vars.DDARXIV_FORCE }}
      DDARXIV_PAPER_MAX_ATTEMPTS: ${{ secrets.DDARXIV_PAPER_MAX_ATTEMPTS || vars.DDARXIV_PAPER_MAX_ATTEMPTS }}
      DDARXIV_FAIL_ON_ERROR: ${{ secrets.DDARXIV_FAIL_ON_ERROR || vars.DDARXIV_FAIL_ON_ERROR }}
      DDARXIV_STATE_SAVE_INTERVAL_S: ${{ secrets.DDARXIV_STATE_SAVE_INTERVAL_S || vars.DDARXIV_STATE_SAVE_INTERVAL_S }}
      DDARXIV_FAILURE_PATTERNS: ${{ secrets.DDARXIV_FAILURE_PATTERNS || vars.DDARXIV_FAILURE_PATTERNS }}

      # LLM providers (match .env.sample)
      DDARXIV_LLM_WEAK_BASE_URL: ${{ secrets.DDARXIV_LLM_WEAK_BASE_URL || vars.DDARXIV_LLM_WEAK_BASE_URL }}
      DDARXIV_LLM_WEAK_API_KEY: ${{ secrets.DDARXIV_LLM_WEAK_API_KEY || vars.DDARXIV_LLM_WEAK_API_KEY }}
      DDARXIV_LLM_WEAK_MODEL: ${{ secrets.DDARXIV_LLM_WEAK_MODEL || vars.DDARXIV_LLM_WEAK_MODEL }}
      DDARXIV_LLM_WEAK_RPM: ${{ secrets.DDARXIV_LLM_WEAK_RPM || vars.DDARXIV_LLM_WEAK_RPM }}
      DDARXIV_LLM_WEAK_TIMEOUT_S: ${{ secrets.DDARXIV_LLM_WEAK_TIMEOUT_S || vars.DDARXIV_LLM_WEAK_TIMEOUT_S }}
      DDARXIV_LLM_WEAK_MAX_RETRIES: ${{ secrets.DDARXIV_LLM_WEAK_MAX_RETRIES || vars.DDARXIV_LLM_WEAK_MAX_RETRIES }}

      DDARXIV_LLM_STRONG_BASE_URL: ${{ secrets.DDARXIV_LLM_STRONG_BASE_URL || vars.DDARXIV_LLM_STRONG_BASE_URL }}
      DDARXIV_LLM_STRONG_API_KEY: ${{ secrets.DDARXIV_LLM_STRONG_API_KEY || vars.DDARXIV_LLM_STRONG_API_KEY }}
      DDARXIV_LLM_STRONG_MODEL: ${{ secrets.DDARXIV_LLM_STRONG_MODEL || vars.DDARXIV_LLM_STRONG_MODEL }}
      DDARXIV_LLM_STRONG_RPM: ${{ secrets.DDARXIV_LLM_STRONG_RPM || vars.DDARXIV_LLM_STRONG_RPM }}
      DDARXIV_LLM_STRONG_TIMEOUT_S: ${{ secrets.DDARXIV_LLM_STRONG_TIMEOUT_S || vars.DDARXIV_LLM_STRONG_TIMEOUT_S }}
      DDARXIV_LLM_STRONG_MAX_RETRIES: ${{ secrets.DDARXIV_LLM_STRONG_MAX_RETRIES || vars.DDARXIV_LLM_STRONG_MAX_RETRIES }}

      DDARXIV_LLM_BACKUP_BASE_URL: ${{ secrets.DDARXIV_LLM_BACKUP_BASE_URL || vars.DDARXIV_LLM_BACKUP_BASE_URL }}
      DDARXIV_LLM_BACKUP_API_KEY: ${{ secrets.DDARXIV_LLM_BACKUP_API_KEY || vars.DDARXIV_LLM_BACKUP_API_KEY }}
      DDARXIV_LLM_BACKUP_MODEL: ${{ secrets.DDARXIV_LLM_BACKUP_MODEL || vars.DDARXIV_LLM_BACKUP_MODEL }}
      DDARXIV_LLM_BACKUP_RPM: ${{ secrets.DDARXIV_LLM_BACKUP_RPM || vars.DDARXIV_LLM_BACKUP_RPM }}
      DDARXIV_LLM_BACKUP_TIMEOUT_S: ${{ secrets.DDARXIV_LLM_BACKUP_TIMEOUT_S || vars.DDARXIV_LLM_BACKUP_TIMEOUT_S }}
      DDARXIV_LLM_BACKUP_MAX_RETRIES: ${{ secrets.DDARXIV_LLM_BACKUP_MAX_RETRIES || vars.DDARXIV_LLM_BACKUP_MAX_RETRIES }}

      # Langfuse (match .env.sample; keep backward compatibility with LANGFUSE_* secrets)
      DDARXIV_LANGFUSE_ENABLED: ${{ secrets.DDARXIV_LANGFUSE_ENABLED || vars.DDARXIV_LANGFUSE_ENABLED }}
      DDARXIV_LANGFUSE_HOST: ${{ secrets.DDARXIV_LANGFUSE_HOST || secrets.LANGFUSE_HOST || vars.DDARXIV_LANGFUSE_HOST || vars.LANGFUSE_HOST }}
      DDARXIV_LANGFUSE_PUBLIC_KEY: ${{ secrets.DDARXIV_LANGFUSE_PUBLIC_KEY || secrets.LANGFUSE_PUBLIC_KEY || vars.DDARXIV_LANGFUSE_PUBLIC_KEY || vars.LANGFUSE_PUBLIC_KEY }}
      DDARXIV_LANGFUSE_SECRET_KEY: ${{ secrets.DDARXIV_LANGFUSE_SECRET_KEY || secrets.LANGFUSE_SECRET_KEY || vars.DDARXIV_LANGFUSE_SECRET_KEY || vars.LANGFUSE_SECRET_KEY }}
      DDARXIV_LANGFUSE_SESSION_NOTE: ${{ secrets.DDARXIV_LANGFUSE_SESSION_NOTE || secrets.LANGFUSE_SESSION_NOTE || vars.DDARXIV_LANGFUSE_SESSION_NOTE || vars.LANGFUSE_SESSION_NOTE }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for proper commits

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"

      - name: Install dependencies
        run: uv sync
      
      - name: Set timezone to UTC
        run: |
          echo "TZ=UTC" >> $GITHUB_ENV
          date  # Print current date/time for logging
      
      - name: Set current date
        id: date
        run: |
          echo "current_date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
          echo "start_date_7_days=$(date -d '6 days ago' +'%Y-%m-%d')" >> $GITHUB_OUTPUT
      
      - name: Run fetch_arxiv script (with specified date or date range)
        if: ${{ inputs.date != '' || (inputs.start-date != '' && inputs.end-date != '') }}
        run: uv run fetch_arxiv.py
        env:
          # Pass all inputs as environment variables for cleaner YAML
          DDARXIV_DATE: ${{ inputs.date }}
          DDARXIV_START_DATE: ${{ inputs.start-date }}
          DDARXIV_END_DATE: ${{ inputs.end-date }}
          DDARXIV_CATEGORY: ${{ inputs.category }}
          DDARXIV_MAX_RESULTS: ${{ inputs.max-results }}
          DDARXIV_FORCE: ${{ inputs.force }}
          DDARXIV_LOG_LEVEL: ${{ inputs.log-level }}
      
      - name: Run fetch_arxiv script (for scheduled runs or manual runs without specified dates)
        if: ${{ inputs.date == '' && inputs.start-date == '' }}
        run: uv run fetch_arxiv.py
        env:
          # For scheduled runs or manual runs without date inputs, process the last 7 days (today UTC + past 6 days)
          DDARXIV_START_DATE: ${{ steps.date.outputs.start_date_7_days }}
          DDARXIV_END_DATE: ${{ steps.date.outputs.current_date }}
          DDARXIV_CATEGORY: ${{ inputs.category || 'cs.AI' }}
          DDARXIV_MAX_RESULTS: ${{ inputs.max-results || '1000' }}
          DDARXIV_FORCE: ${{ inputs.force }}
          DDARXIV_LOG_LEVEL: ${{ inputs.log-level || 'INFO' }}

      - name: Check for changes
        id: check_changes
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          if [[ $(git status --porcelain) ]]; then
            echo "changes=true" >> $GITHUB_OUTPUT
          else
            echo "changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          DATE=$(date -u +'%Y-%m-%d %H:%M:%S UTC')
          git add -A
          git commit -m "Update data: $DATE"
          git remote set-url origin https://x-access-token:${{ secrets.PAT_GITHUB }}@github.com/${{ github.repository }}
          git push

      - name: Trigger build-frontend workflow
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.PAT_GITHUB }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/build-frontend.yml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'
