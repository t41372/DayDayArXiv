name: Daily arXiv Update

on:
  schedule:
    # Run at 00:20 UTC every day
    - cron: '20 0 * * *'
  workflow_dispatch:
    inputs:
      date:
        description: 'Date to process (YYYY-MM-DD format)'
        required: false
        type: string
      start-date:
        description: 'Start date for date range (YYYY-MM-DD format)'
        required: false
        type: string
      end-date:
        description: 'End date for date range (YYYY-MM-DD format, inclusive)'
        required: false
        type: string
      category:
        description: 'arXiv category to process'
        required: false
        default: 'cs.AI'
        type: string
      max-results:
        description: 'Maximum number of papers to fetch'
        required: false
        default: '1000' # Default value from script
        type: string
      force:
        description: 'Force refresh existing data'
        required: false
        default: false
        type: boolean
      log-level:
        description: 'Set logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)'
        required: false
        default: 'INFO' # Default value from script
        type: string

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for proper commits

      - name: Install uv
        uses: astral-sh/setup-uv@v5
        with:
          enable-cache: true
          cache-dependency-glob: "pyproject.toml"
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: "pyproject.toml"

      - name: Install dependencies
        run: uv sync
      
      - name: Set timezone to UTC
        run: |
          echo "TZ=UTC" >> $GITHUB_ENV
          date  # Print current date/time for logging
      
      - name: Set current date
        id: date
        run: |
          echo "current_date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT
          echo "start_date_7_days=$(date -d '6 days ago' +'%Y-%m-%d')" >> $GITHUB_OUTPUT
      
      - name: Run fetch_arxiv script (with specified date or date range)
        if: ${{ inputs.date != '' || (inputs.start-date != '' && inputs.end-date != '') }}
        run: uv run fetch_arxiv.py
        env:
          # Pass all inputs as environment variables for cleaner YAML
          DAYDAYARXIV_DATE: ${{ inputs.date }}
          DAYDAYARXIV_START_DATE: ${{ inputs.start-date }}
          DAYDAYARXIV_END_DATE: ${{ inputs.end-date }}
          DAYDAYARXIV_CATEGORY: ${{ inputs.category }}
          DAYDAYARXIV_MAX_RESULTS: ${{ inputs.max-results }}
          DAYDAYARXIV_FORCE: ${{ inputs.force }}
          DAYDAYARXIV_LOG_LEVEL: ${{ inputs.log-level }}
          # LLM configuration (OpenAI-compatible providers)
          DAYDAYARXIV_LLM__WEAK__API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DAYDAYARXIV_LLM__WEAK__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL }}
          DAYDAYARXIV_LLM__WEAK__MODEL: ${{ secrets.LLM_MODEL }}
          DAYDAYARXIV_LLM__WEAK__RPM: ${{ secrets.LLM_RPM || secrets.RPM || '20' }}
          DAYDAYARXIV_LLM__STRONG__API_KEY: ${{ secrets.OPENAI_API_KEY_STRONG }}
          DAYDAYARXIV_LLM__STRONG__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL_STRONG }}
          DAYDAYARXIV_LLM__STRONG__MODEL: ${{ secrets.LLM_MODEL_STRONG }}
          DAYDAYARXIV_LLM__STRONG__RPM: ${{ secrets.LLM_RPM_STRONG || '10' }}
          DAYDAYARXIV_LLM__BACKUP__API_KEY: ${{ secrets.OPENAI_API_KEY_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__MODEL: ${{ secrets.LLM_MODEL_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__RPM: ${{ secrets.LLM_RPM_BACKUP || '10' }}
          LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}
          LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}
          LANGFUSE_HOST: ${{ secrets.LANGFUSE_HOST }}
          LANGFUSE_SESSION_NOTE: ${{ secrets.LANGFUSE_SESSION_NOTE }}
          DAYDAYARXIV_LANGFUSE__ENABLED: "true"
      
      - name: Run fetch_arxiv script (for scheduled runs or manual runs without specified dates)
        if: ${{ inputs.date == '' && inputs.start-date == '' }}
        run: uv run fetch_arxiv.py
        env:
          # For scheduled runs or manual runs without date inputs, process the last 7 days (today UTC + past 6 days)
          DAYDAYARXIV_START_DATE: ${{ steps.date.outputs.start_date_7_days }}
          DAYDAYARXIV_END_DATE: ${{ steps.date.outputs.current_date }}
          DAYDAYARXIV_CATEGORY: ${{ inputs.category || 'cs.AI' }}
          DAYDAYARXIV_MAX_RESULTS: ${{ inputs.max-results || '1000' }}
          DAYDAYARXIV_FORCE: ${{ inputs.force }}
          DAYDAYARXIV_LOG_LEVEL: ${{ inputs.log-level || 'INFO' }}
          # LLM configuration (OpenAI-compatible providers)
          DAYDAYARXIV_LLM__WEAK__API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DAYDAYARXIV_LLM__WEAK__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL }}
          DAYDAYARXIV_LLM__WEAK__MODEL: ${{ secrets.LLM_MODEL }}
          DAYDAYARXIV_LLM__WEAK__RPM: ${{ secrets.LLM_RPM || secrets.RPM || '20' }}
          DAYDAYARXIV_LLM__STRONG__API_KEY: ${{ secrets.OPENAI_API_KEY_STRONG }}
          DAYDAYARXIV_LLM__STRONG__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL_STRONG }}
          DAYDAYARXIV_LLM__STRONG__MODEL: ${{ secrets.LLM_MODEL_STRONG }}
          DAYDAYARXIV_LLM__STRONG__RPM: ${{ secrets.LLM_RPM_STRONG || '10' }}
          DAYDAYARXIV_LLM__BACKUP__API_KEY: ${{ secrets.OPENAI_API_KEY_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__BASE_URL: ${{ secrets.OPENAI_API_BASE_URL_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__MODEL: ${{ secrets.LLM_MODEL_BACKUP }}
          DAYDAYARXIV_LLM__BACKUP__RPM: ${{ secrets.LLM_RPM_BACKUP || '10' }}
          LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}
          LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}
          LANGFUSE_HOST: ${{ secrets.LANGFUSE_HOST }}
          LANGFUSE_SESSION_NOTE: ${{ secrets.LANGFUSE_SESSION_NOTE }}
          DAYDAYARXIV_LANGFUSE__ENABLED: "true"

      - name: Check for changes
        id: check_changes
        run: |
          git config user.name "GitHub Actions Bot"
          git config user.email "actions@github.com"
          if [[ $(git status --porcelain) ]]; then
            echo "changes=true" >> $GITHUB_OUTPUT
          else
            echo "changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          DATE=$(date -u +'%Y-%m-%d %H:%M:%S UTC')
          git add -A
          git commit -m "Update data: $DATE"
          git remote set-url origin https://x-access-token:${{ secrets.PAT_GITHUB }}@github.com/${{ github.repository }}
          git push

      - name: Trigger build-frontend workflow
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          curl -X POST \
            -H "Authorization: token ${{ secrets.PAT_GITHUB }}" \
            -H "Accept: application/vnd.github.v3+json" \
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/build-frontend.yml/dispatches \
            -d '{"ref":"${{ github.ref }}"}'
