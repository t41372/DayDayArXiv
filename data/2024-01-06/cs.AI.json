{
  "date": "2024-01-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 安全、机器人学习、LLM 应用以及医疗信号处理等领域，重点包括恶意 LLM 服务的分析（USENIX Security '24 接受）和知名学者如 Chelsea Finn 的机器人学习工作，以及 CogGPT 等创新性 LLM 框架，这些文章展示了 AI 在实际应用中的潜力与挑战。\n\n以下是今日值得关注的论文，先优先讨论高话题度、突破性贡献或知名作者的作品，再简要掠过其他相关内容。每个条目列出论文标题（中文 + 英文），并概述核心贡献和发现。\n\n**1. 恶意 LLM 服务的系统研究（Malla: Demystifying Real-world Large Language Model Integrated Malicious Services）**  \n这篇论文由 Zilong Lin 等作者完成，揭示了地下恶意 LLM 服务的生态，包括 212 个真实案例的分析，发现了绕过公共 LLM API 的 182 个提示，并提出应对策略。该工作在 AI 安全领域有重要影响，已被 USENIX Security '24 接受。\n\n**2. 机器人学习框架的离线预训练和在线微调（MOTO: Offline Pre-training to Online Fine-tuning for Model-based Robot Learning）**  \n知名学者 Chelsea Finn 参与的这篇论文提出 MOTO 框架，使用模型-based 值扩展和策略正则化，从图像中解决机器人任务，首次在 MetaWorld 和 Franka Kitchen 环境中实现完全图像驱动的离线到在线学习，显著提升样本效率和任务适应性。\n\n**3. LLM 的自对齐方法（Human-Instruction-Free LLM Self-Alignment with Limited Samples）**  \n论文引入无人类指令的自对齐算法，通过迭代生成和微调 LLM，实现少样本域适应，在安全和指令遵循任务中表现出色，展示了 LLM 在资源受限场景下的自提升潜力。\n\n**4. 时间图的时序推理（TimeGraphs: Graph-based Temporal Reasoning）**  \nJure Leskovec 等作者的工作提出 TimeGraphs 框架，使用分层图表示动态交互数据，实现高效的自监督时序推理，在足球模拟和人类活动数据集上超越基线，证明了其在复杂动态系统中的鲁棒性。\n\n**5. LLM 的认知动态框架（CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models）**  \n论文提出 CogGPT，通过迭代认知机制模拟 LLM 的动态认知过程，结合基准 CogBench 评估其在持续信息流下的表现，提升了 LLM 在角色特定任务中的适应性。\n\n其他论文中，以 AI 应用为主题的几篇值得快速一提：\n- **脑肿瘤检测（Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT）**：使用 YOLOv8 和 DeiT 模型实现异常感知的脑肿瘤检测，F1 分数达 84%，在真实医疗场景中提升诊断准确性。\n- **医疗信号处理框架（TRLS: A Time Series Representation Learning Framework via Spectrogram for Medical Signal Processing）**：提出 TRLS 框架，通过谱图和 RNN 捕获医疗信号特征，提升分类性能，在多个数据集上表现优异。\n- **短文本分类的 CoT 框架（CoT-Driven Framework for Short Text Classification: Enhancing and Transferring Capabilities from Large to Smaller Model）**：使用链式思维增强短文本分类，并转移能力到小模型，在多个基准上实现 SOTA 性能。\n\n剩余论文如事件序列分类或交通预测等，虽然有技术贡献，但相对常规，故从简略过，不做深入讨论。今天 arXiv 更新多元而富有洞见，欢迎读者根据兴趣深入探索！",
  "papers": [
    {
      "arxiv_id": "2402.00031v1",
      "title": "An Integrated Framework for Team Formation and Winner Prediction in the FIRST Robotics Competition: Model, Algorithm, and Analysis",
      "title_zh": "一个集成框架，用于 FIRST Robotics Competition 中的团队组建和获胜者预测：模型、算法和分析",
      "authors": [
        "Federico Galbiati",
        "Ranier X. Gran",
        "Brendan D. Jacques",
        "Sullivan J. Mulhern",
        "Chun-Kit Ngan"
      ],
      "abstract": "This research work aims to develop an analytical approach for optimizing team\nformation and predicting team performance in a competitive environment based on\ndata on the competitors' skills prior to the team formation. There are several\napproaches in scientific literature to optimize and predict a team's\nperformance. However, most studies employ fine-grained skill statistics of the\nindividual members or constraints such as teams with a set group of members.\nCurrently, no research tackles the highly constrained domain of the FIRST\nRobotics Competition. This research effort aims to fill this gap by providing\nan analytical method for optimizing and predicting team performance in a\ncompetitive environment while allowing these constraints and only using metrics\non previous team performance, not on each individual member's performance. We\napply our method to the drafting process of the FIRST Robotics competition, a\ndomain in which the skills change year-over-year, team members change\nthroughout the season, each match only has a superficial set of statistics, and\nalliance formation is key to competitive success. First, we develop a method\nthat could extrapolate individual members' performance based on overall team\nperformance. An alliance optimization algorithm is developed to optimize team\nformation and a deep neural network model is trained to predict the winning\nteam, both using highly post-processed real-world data. Our method is able to\nsuccessfully extract individual members' metrics from overall team statistics,\nform competitive teams, and predict the winning team with 84.08% accuracy.",
      "tldr_zh": "本研究提出一个整合框架，用于优化团队组建和预测获胜团队，针对FIRST Robotics Competition的约束环境，仅基于先前团队表现指标而非个体技能统计。框架包括从整体团队统计中推断个体成员表现的方法、一个联盟优化算法来形成竞争团队，以及一个深度神经网络模型来预测获胜团队。实验结果显示，该方法能成功提取个体指标、优化团队结构，并在真实数据上实现84.08%的预测准确率，为类似竞争领域的团队策略提供分析工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00031v1",
      "published_date": "2024-01-06 23:11:50 UTC",
      "updated_date": "2024-01-06 23:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:04:49.578914"
    },
    {
      "arxiv_id": "2401.03322v1",
      "title": "Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection",
      "title_zh": "注意力与自编码器混合模型用于无监督在线异常检测",
      "authors": [
        "Seyed Amirhossein Najafi",
        "Mohammad Hassan Asemani",
        "Peyman Setoodeh"
      ],
      "abstract": "This paper introduces a hybrid attention and autoencoder (AE) model for\nunsupervised online anomaly detection in time series. The autoencoder captures\nlocal structural patterns in short embeddings, while the attention model learns\nlong-term features, facilitating parallel computing with positional encoding.\nUnique in its approach, our proposed hybrid model combines attention and\nautoencoder for the first time in time series anomaly detection. It employs an\nattention-based mechanism, akin to the deep transformer model, with key\narchitectural modifications for predicting the next time step window in the\nautoencoder's latent space. The model utilizes a threshold from the validation\ndataset for anomaly detection and introduces an alternative method based on\nanalyzing the first statistical moment of error, improving accuracy without\ndependence on a validation dataset. Evaluation on diverse real-world benchmark\ndatasets and comparing with other well-established models, confirms the\neffectiveness of our proposed model in anomaly detection.",
      "tldr_zh": "本论文提出了一种混合注意力(attention)和自编码器(autoencoder)模型，用于时间序列的无监督在线异常检测，其中自编码器捕捉短嵌入中的局部结构模式，而注意力模型学习长期特征，支持并行计算和位置编码。该模型首次将注意力机制与自编码器结合，并通过类似于深度Transformer的架构修改，在自编码器的潜在空间中预测下一个时间步窗口，以实现异常检测。它引入了基于验证数据集阈值或错误的第一统计矩分析的替代方法，提高准确性并减少对验证数据集的依赖。在真实世界基准数据集上的评估显示，该模型在异常检测性能上优于现有基准模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03322v1",
      "published_date": "2024-01-06 22:55:02 UTC",
      "updated_date": "2024-01-06 22:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:05:02.696627"
    },
    {
      "arxiv_id": "2401.03315v3",
      "title": "Malla: Demystifying Real-world Large Language Model Integrated Malicious Services",
      "title_zh": "翻译失败",
      "authors": [
        "Zilong Lin",
        "Jian Cui",
        "Xiaojing Liao",
        "XiaoFeng Wang"
      ],
      "abstract": "The underground exploitation of large language models (LLMs) for malicious\nservices (i.e., Malla) is witnessing an uptick, amplifying the cyber threat\nlandscape and posing questions about the trustworthiness of LLM technologies.\nHowever, there has been little effort to understand this new cybercrime, in\nterms of its magnitude, impact, and techniques. In this paper, we conduct the\nfirst systematic study on 212 real-world Mallas, uncovering their proliferation\nin underground marketplaces and exposing their operational modalities. Our\nstudy discloses the Malla ecosystem, revealing its significant growth and\nimpact on today's public LLM services. Through examining 212 Mallas, we\nuncovered eight backend LLMs used by Mallas, along with 182 prompts that\ncircumvent the protective measures of public LLM APIs. We further demystify the\ntactics employed by Mallas, including the abuse of uncensored LLMs and the\nexploitation of public LLM APIs through jailbreak prompts. Our findings enable\na better understanding of the real-world exploitation of LLMs by\ncybercriminals, offering insights into strategies to counteract this\ncybercrime.",
      "tldr_zh": "本研究首次系统分析了212个真实世界的Malla，即利用大型语言模型(LLMs)进行恶意服务的地下活动，揭示了其在地下市场的快速增长、对公共LLM服务的重大影响以及相关技术。研究者识别了八个后端LLMs和182个绕过API保护的越狱提示，并暴露了Malla的策略，包括滥用无审查LLMs和通过越狱提示利用公共LLM API。结果显示，这种网络犯罪生态系统正不断壮大，为理解和对抗LLMs的恶意利用提供了关键洞见。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at the 33rd USENIX Security Symposium (USENIX Security '24).\n  The data and code are available at\n  https://github.com/idllresearch/malicious-gpt",
      "pdf_url": "http://arxiv.org/pdf/2401.03315v3",
      "published_date": "2024-01-06 22:25:42 UTC",
      "updated_date": "2024-08-19 20:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:05:16.241807"
    },
    {
      "arxiv_id": "2401.03314v1",
      "title": "Enhancing Context Through Contrast",
      "title_zh": "通过对比增强上下文",
      "authors": [
        "Kshitij Ambilduke",
        "Aneesh Shetye",
        "Diksha Bagade",
        "Rishika Bhagwatkar",
        "Khurshed Fitter",
        "Prasad Vagdargi",
        "Shital Chiddarwar"
      ],
      "abstract": "Neural machine translation benefits from semantically rich representations.\nConsiderable progress in learning such representations has been achieved by\nlanguage modelling and mutual information maximization objectives using\ncontrastive learning. The language-dependent nature of language modelling\nintroduces a trade-off between the universality of the learned representations\nand the model's performance on the language modelling tasks. Although\ncontrastive learning improves performance, its success cannot be attributed to\nmutual information alone. We propose a novel Context Enhancement step to\nimprove performance on neural machine translation by maximizing mutual\ninformation using the Barlow Twins loss. Unlike other approaches, we do not\nexplicitly augment the data but view languages as implicit augmentations,\neradicating the risk of disrupting semantic information. Further, our method\ndoes not learn embeddings from scratch and can be generalised to any set of\npre-trained embeddings. Finally, we evaluate the language-agnosticism of our\nembeddings through language classification and use them for neural machine\ntranslation to compare with state-of-the-art approaches.",
      "tldr_zh": "该论文探讨了神经机器翻译（Neural Machine Translation）如何通过语义丰富的表示提升性能，并分析了现有方法如语言建模和对比学习（Contrastive Learning）的局限性，例如语言依赖性和并非完全依赖互信息（Mutual Information）。作者提出了一种新颖的 Context Enhancement 步骤，使用 Barlow Twins loss 来最大化互信息，将语言视为隐式增强（Implicit Augmentations），从而避免破坏语义信息，同时基于预训练嵌入（Pre-trained Embeddings）进行改进，而非从零开始训练。实验通过语言分类（Language Classification）评估了该方法的语言无关性，并在神经机器翻译任务上与最先进方法进行了比较，展示了其通用性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03314v1",
      "published_date": "2024-01-06 22:13:51 UTC",
      "updated_date": "2024-01-06 22:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:05:27.610605"
    },
    {
      "arxiv_id": "2401.03312v1",
      "title": "Exploiting Data Hierarchy as a New Modality for Contrastive Learning",
      "title_zh": "利用数据层次作为对比学习的新模态",
      "authors": [
        "Arjun Bhalla",
        "Daniel Levenson",
        "Jan Bernhard",
        "Anton Abilov"
      ],
      "abstract": "This work investigates how hierarchically structured data can help neural\nnetworks learn conceptual representations of cathedrals. The underlying\nWikiScenes dataset provides a spatially organized hierarchical structure of\ncathedral components. We propose a novel hierarchical contrastive training\napproach that leverages a triplet margin loss to represent the data's spatial\nhierarchy in the encoder's latent space. As such, the proposed approach\ninvestigates if the dataset structure provides valuable information for\nself-supervised learning. We apply t-SNE to visualize the resultant latent\nspace and evaluate the proposed approach by comparing it with other\ndataset-specific contrastive learning methods using a common downstream\nclassification task. The proposed method outperforms the comparable\nweakly-supervised and baseline methods. Our findings suggest that dataset\nstructure is a valuable modality for weakly-supervised learning.",
      "tldr_zh": "本研究探讨了利用数据层次结构作为对比学习（contrastive learning）的新模态，帮助神经网络学习大教堂的概念表示。作者基于WikiScenes数据集提出了一种新型层次对比训练方法，使用triplet margin loss在编码器的潜在空间中表示数据的空间层次，从而探索数据集结构在自监督学习（self-supervised learning）中的价值。实验通过t-SNE可视化潜在空间，并与其它弱监督和基线方法在下游分类任务上进行比较，结果显示该方法表现出色。总体而言，该工作证明了数据集结构作为一种有价值的模态，可提升弱监督学习的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03312v1",
      "published_date": "2024-01-06 21:47:49 UTC",
      "updated_date": "2024-01-06 21:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:05:37.089163"
    },
    {
      "arxiv_id": "2401.03310v1",
      "title": "CAVIAR: Co-simulation of 6G Communications, 3D Scenarios and AI for Digital Twins",
      "title_zh": "CAVIAR：用于数字孪生的 6G 通信、3D 场景和 AI ",
      "authors": [
        "João Borges",
        "Felipe Bastos",
        "Ilan Correa",
        "Pedro Batista",
        "Aldebaro Klautau"
      ],
      "abstract": "Digital twins are an important technology for advancing mobile\ncommunications, specially in use cases that require simultaneously simulating\nthe wireless channel, 3D scenes and machine learning. Aiming at providing a\nsolution to this demand, this work describes a modular co-simulation\nmethodology called CAVIAR. Here, CAVIAR is upgraded to support a message\npassing library and enable the virtual counterpart of a digital twin system\nusing different 6G-related simulators. The main contributions of this work are\nthe detailed description of different CAVIAR architectures, the implementation\nof this methodology to assess a 6G use case of UAV-based search and rescue\nmission (SAR), and the generation of benchmarking data about the computational\nresource usage. For executing the SAR co-simulation we adopt five open-source\nsolutions: the physical and link level network simulator Sionna, the simulator\nfor autonomous vehicles AirSim, scikit-learn for training a decision tree for\nMIMO beam selection, Yolov8 for the detection of rescue targets and NATS for\nmessage passing. Results for the implemented SAR use case suggest that the\nmethodology can run in a single machine, with the main demanded resources being\nthe CPU processing and the GPU memory.",
      "tldr_zh": "本研究提出 CAVIAR，一种模块化联合模拟方法，用于 6G 通信、3D 场景和 AI 的数字孪生系统，旨在同时模拟无线通道、3D 环境和机器学习组件。CAVIAR 通过升级支持消息传递库，并结合开源工具如 Sionna（网络模拟器）、AirSim（自主车辆模拟器）、scikit-learn（训练决策树用于 MIMO 波束选择）、Yolov8（目标检测）和 NATS（消息传递），评估了一个基于 UAV 的搜索和救援（SAR）用例。主要贡献包括详细描述不同 CAVIAR 架构、用例实施以及生成计算资源使用基准数据，结果表明该方法可在单机运行，主要需求是 CPU 处理和 GPU 内存。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03310v1",
      "published_date": "2024-01-06 21:22:18 UTC",
      "updated_date": "2024-01-06 21:22:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:05:51.782021"
    },
    {
      "arxiv_id": "2402.00030v1",
      "title": "Evolution-Bootstrapped Simulation: Artificial or Human Intelligence: Which Came First?",
      "title_zh": "翻译失败",
      "authors": [
        "Paul Alexander Bilokon"
      ],
      "abstract": "Humans have created artificial intelligence (AI), not the other way around.\nThis statement is deceptively obvious. In this note, we decided to challenge\nthis statement as a small, lighthearted Gedankenexperiment. We ask a simple\nquestion: in a world driven by evolution by natural selection, would neural\nnetworks or humans be likely to evolve first? We compare the\nSolomonoff--Kolmogorov--Chaitin complexity of the two and find neural networks\n(even LLMs) to be significantly simpler than humans. Further, we claim that it\nis unnecessary for any complex human-made equipment to exist for there to be\nneural networks. Neural networks may have evolved as naturally occurring\nobjects before humans did as a form of chemical reaction-based or enzyme-based\ncomputation. Now that we know that neural networks can pass the Turing test and\nsuspect that they may be capable of superintelligence, we ask whether the\nnatural evolution of neural networks could lead from pure evolution by natural\nselection to what we call evolution-bootstrapped simulation. The evolution of\nneural networks does not involve irreducible complexity; would easily allow\nirreducible complexity to exist in the evolution-bootstrapped simulation; is a\nfalsifiable scientific hypothesis; and is independent of / orthogonal to the\nissue of intelligent design.",
      "tldr_zh": "本论文通过一个轻松的思想实验（Gedankenexperiment）质疑人类是否先于人工智能（AI）进化，比较了Solomonoff-Kolmogorov-Chaitin complexity，发现神经网络（包括LLMs）比人类更简单，可能作为化学反应或酶基计算在自然选择中先于人类进化。论文提出，神经网络的自然进化可能导致“evolution-bootstrapped simulation”，即从纯自然选择过渡到更高级模拟形式，而这不需要复杂的人类设备。最终，该假设被视为一个可证伪的科学假设，与intelligent design无关。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "q-bio.PE"
      ],
      "primary_category": "cs.NE",
      "comment": "6 pages, no figures",
      "pdf_url": "http://arxiv.org/pdf/2402.00030v1",
      "published_date": "2024-01-06 21:06:58 UTC",
      "updated_date": "2024-01-06 21:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:06:01.138246"
    },
    {
      "arxiv_id": "2401.03306v1",
      "title": "MOTO: Offline Pre-training to Online Fine-tuning for Model-based Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rafael Rafailov",
        "Kyle Hatch",
        "Victor Kolev",
        "John D. Martin",
        "Mariano Phielipp",
        "Chelsea Finn"
      ],
      "abstract": "We study the problem of offline pre-training and online fine-tuning for\nreinforcement learning from high-dimensional observations in the context of\nrealistic robot tasks. Recent offline model-free approaches successfully use\nonline fine-tuning to either improve the performance of the agent over the data\ncollection policy or adapt to novel tasks. At the same time, model-based RL\nalgorithms have achieved significant progress in sample efficiency and the\ncomplexity of the tasks they can solve, yet remain under-utilized in the\nfine-tuning setting. In this work, we argue that existing model-based offline\nRL methods are not suitable for offline-to-online fine-tuning in\nhigh-dimensional domains due to issues with distribution shifts, off-dynamics\ndata, and non-stationary rewards. We propose an on-policy model-based method\nthat can efficiently reuse prior data through model-based value expansion and\npolicy regularization, while preventing model exploitation by controlling\nepistemic uncertainty. We find that our approach successfully solves tasks from\nthe MetaWorld benchmark, as well as the Franka Kitchen robot manipulation\nenvironment completely from images. To the best of our knowledge, MOTO is the\nfirst method to solve this environment from pixels.",
      "tldr_zh": "本文研究了在高维观察下的强化学习问题，专注于从离线 pre-training 到在线 fine-tuning 的模型-based RL 方法，以应对现实机器人任务中的挑战。提出 MOTO 框架，该框架采用 on-policy 策略，通过模型-based value expansion 和 policy regularization 高效重用先验数据，同时通过控制 epistemic uncertainty 避免模型利用问题。实验结果显示，MOTO 在 MetaWorld 基准和 Franka Kitchen 机器人操作环境中完全基于图像成功解决问题，这是首个从 pixels 实现此环境的模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "This is an updated version of a manuscript that originally appeared\n  at CoRL 2023. The project website is here https://sites.google.com/view/mo2o",
      "pdf_url": "http://arxiv.org/pdf/2401.03306v1",
      "published_date": "2024-01-06 21:04:31 UTC",
      "updated_date": "2024-01-06 21:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:06:14.726529"
    },
    {
      "arxiv_id": "2402.00029v1",
      "title": "Exploring Public Opinion on Responsible AI Through The Lens of Cultural Consensus Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Necdet Gurkan",
        "Jordan W. Suchow"
      ],
      "abstract": "As the societal implications of Artificial Intelligence (AI) continue to\ngrow, the pursuit of responsible AI necessitates public engagement in its\ndevelopment and governance processes. This involvement is crucial for capturing\ndiverse perspectives and promoting equitable practices and outcomes. We applied\nCultural Consensus Theory (CCT) to a nationally representative survey dataset\non various aspects of AI to discern beliefs and attitudes about responsible AI\nin the United States. Our results offer valuable insights by identifying shared\nand contrasting views on responsible AI. Furthermore, these findings serve as\ncritical reference points for developers and policymakers, enabling them to\nmore effectively consider individual variances and group-level cultural\nperspectives when making significant decisions and addressing the public's\nconcerns.",
      "tldr_zh": "本研究探讨了公众对负责任 AI 的看法，通过 Cultural Consensus Theory (CCT) 分析美国全国代表性调查数据，旨在捕捉多样化视角并促进公平实践。研究发现，公众在负责任 AI 方面存在共享观点和对比意见，例如在 AI 开发和治理上的不同态度。这些结果为 AI 开发者和社会政策制定者提供了关键参考，帮助他们在决策中考虑个体差异和群体文化视角，从而更好地应对公众关切。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00029v1",
      "published_date": "2024-01-06 20:57:35 UTC",
      "updated_date": "2024-01-06 20:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:06:23.213482"
    },
    {
      "arxiv_id": "2401.03302v3",
      "title": "Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Hossein Hashemi",
        "Leila Safari",
        "Amirhossein Dadashzadeh Taromi"
      ],
      "abstract": "In the field of medical sciences, reliable detection and classification of\nbrain tumors from images remains a formidable challenge due to the rarity of\ntumors within the population of patients. Therefore, the ability to detect\ntumors in anomaly scenarios is paramount for ensuring timely interventions and\nimproved patient outcomes. This study addresses the issue by leveraging deep\nlearning (DL) techniques to detect and classify brain tumors in challenging\nsituations. The curated data set from the National Brain Mapping Lab (NBML)\ncomprises 81 patients, including 30 Tumor cases and 51 Normal cases. The\ndetection and classification pipelines are separated into two consecutive\ntasks. The detection phase involved comprehensive data analysis and\npre-processing to modify the number of image samples and the number of patients\nof each class to anomaly distribution (9 Normal per 1 Tumor) to comply with\nreal world scenarios. Next, in addition to common evaluation metrics for the\ntesting, we employed a novel performance evaluation method called Patient to\nPatient (PTP), focusing on the realistic evaluation of the model. In the\ndetection phase, we fine-tuned a YOLOv8n detection model to detect the tumor\nregion. Subsequent testing and evaluation yielded competitive performance both\nin Common Evaluation Metrics and PTP metrics. Furthermore, using the Data\nEfficient Image Transformer (DeiT) module, we distilled a Vision Transformer\n(ViT) model from a fine-tuned ResNet152 as a teacher in the classification\nphase. This approach demonstrates promising strides in reliable tumor detection\nand classification, offering potential advancements in tumor diagnosis for\nreal-world medical imaging scenarios.",
      "tldr_zh": "本研究针对脑肿瘤在患者中的稀有性，提出了一种异常感知诊断方法，使用 YOLOv8 和 DeiT 模型从医疗图像中检测和分类肿瘤。研究使用来自 National Brain Mapping Lab (NBML) 的数据集（81 名患者，包括 30 例肿瘤和 51 例正常），通过调整数据分布模拟真实世界场景（9 Normal per 1 Tumor），并将任务分为 YOLOv8n 检测肿瘤区域和 DeiT 蒸馏 Vision Transformer (ViT) 模型进行分类。实验结果显示，该方法在常见评估指标和新型 Patient to Patient (PTP) 指标上表现出色，准确率和可靠性显著提升，为真实医疗场景的肿瘤诊断提供了潜在进展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.IV",
      "comment": "This work has been submitted to the Elsevier for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2401.03302v3",
      "published_date": "2024-01-06 20:53:02 UTC",
      "updated_date": "2024-09-25 10:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:06:37.891787"
    },
    {
      "arxiv_id": "2401.03301v2",
      "title": "On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond",
      "title_zh": "关于样本高效离线强化学习：数据多样性、后验采样与更多",
      "authors": [
        "Thanh Nguyen-Tang",
        "Raman Arora"
      ],
      "abstract": "We seek to understand what facilitates sample-efficient learning from\nhistorical datasets for sequential decision-making, a problem that is popularly\nknown as offline reinforcement learning (RL). Further, we are interested in\nalgorithms that enjoy sample efficiency while leveraging (value) function\napproximation. In this paper, we address these fundamental questions by (i)\nproposing a notion of data diversity that subsumes the previous notions of\ncoverage measures in offline RL and (ii) using this notion to {unify} three\ndistinct classes of offline RL algorithms based on version spaces (VS),\nregularized optimization (RO), and posterior sampling (PS). We establish that\nVS-based, RO-based, and PS-based algorithms, under standard assumptions,\nachieve \\emph{comparable} sample efficiency, which recovers the\nstate-of-the-art sub-optimality bounds for finite and linear model classes with\nthe standard assumptions. This result is surprising, given that the prior work\nsuggested an unfavorable sample complexity of the RO-based algorithm compared\nto the VS-based algorithm, whereas posterior sampling is rarely considered in\noffline RL due to its explorative nature. Notably, our proposed model-free\nPS-based algorithm for offline RL is {novel}, with sub-optimality bounds that\nare {frequentist} (i.e., worst-case) in nature.",
      "tldr_zh": "本论文探讨了离线强化学习（offline RL）中样本效率的关键因素，提出了一种新的数据多样性（data diversity）概念，以统一基于版本空间（VS）、正则化优化（RO）和后验采样（PS）的三种算法。研究发现，在标准假设下，这些算法在样本效率上表现出可比性（comparable），从而恢复了现有最先进的状态，包括针对有限和线性模型类的子最优性界（sub-optimality bounds）。此外，论文引入了一个新颖的模型无关的 PS-based 算法，其性能界限具有频度主义（frequentist）性质，并挑战了先前对 RO-based 算法的不利评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS'23; Arxiv is the authors' preferred version; v2: add a\n  missing related work",
      "pdf_url": "http://arxiv.org/pdf/2401.03301v2",
      "published_date": "2024-01-06 20:52:04 UTC",
      "updated_date": "2024-02-06 18:08:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:06:55.696752"
    },
    {
      "arxiv_id": "2401.03275v1",
      "title": "Real Time Human Detection by Unmanned Aerial Vehicles",
      "title_zh": "实时人体检测由无人驾驶航空器实现",
      "authors": [
        "Walid Guettala",
        "Ali Sayah",
        "Laid Kahloul",
        "Ahmed Tibermacine"
      ],
      "abstract": "One of the most important problems in computer vision and remote sensing is\nobject detection, which identifies particular categories of diverse things in\npictures. Two crucial data sources for public security are the thermal infrared\n(TIR) remote sensing multi-scenario photos and videos produced by unmanned\naerial vehicles (UAVs). Due to the small scale of the target, complex scene\ninformation, low resolution relative to the viewable videos, and dearth of\npublicly available labeled datasets and training models, their object detection\nprocedure is still difficult. A UAV TIR object detection framework for pictures\nand videos is suggested in this study. The Forward-looking Infrared (FLIR)\ncameras used to gather ground-based TIR photos and videos are used to create\nthe ``You Only Look Once'' (YOLO) model, which is based on CNN architecture.\nResults indicated that in the validating task, detecting human object had an\naverage precision at IOU (Intersection over Union) = 0.5, which was 72.5\\%,\nusing YOLOv7 (YOLO version 7) state of the art model \\cite{1}, while the\ndetection speed around 161 frames per second (FPS/second). The usefulness of\nthe YOLO architecture is demonstrated in the application, which evaluates the\ncross-detection performance of people in UAV TIR videos under a YOLOv7 model in\nterms of the various UAVs' observation angles. The qualitative and quantitative\nevaluation of object detection from TIR pictures and videos using deep-learning\nmodels is supported favorably by this work.",
      "tldr_zh": "本研究针对无人机（UAVs）热红外（TIR）图像和视频中人体检测的挑战，如目标规模小、场景复杂和数据缺乏，提出了一种基于卷积神经网络（CNN）的YOLO框架。使用Forward-looking Infrared (FLIR)相机采集数据，并基于YOLOv7模型进行训练，结果显示在IOU=0.5时，人体检测的平均精度达72.5%，检测速度为161 FPS。该框架还评估了不同UAV观察角度下的跨检测性能，证明了其在实时物体检测中的有效性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T45, 68U10, 68U99",
        "I.2.10; I.4.8"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.03275v1",
      "published_date": "2024-01-06 18:28:01 UTC",
      "updated_date": "2024-01-06 18:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:07:06.899919"
    },
    {
      "arxiv_id": "2401.03267v1",
      "title": "Autonomous Navigation in Complex Environments",
      "title_zh": "复杂环境中的自主导航",
      "authors": [
        "Andrew Gerstenslager",
        "Jomol Lewis",
        "Liam McKenna",
        "Poorva Patel"
      ],
      "abstract": "This paper explores the application of CNN-DNN network fusion to construct a\nrobot navigation controller within a simulated environment. The simulated\nenvironment is constructed to model a subterranean rescue situation, such that\nan autonomous agent is tasked with finding a goal within an unknown cavernous\nsystem. Imitation learning is used to train the control algorithm to use LiDAR\nand camera data to navigate the space and find the goal. The trained model is\nthen tested for robustness using Monte-Carlo.",
      "tldr_zh": "这篇论文探讨了在复杂环境中实现自主导航的方法，通过 CNN-DNN 网络融合构建一个机器人导航控制器，并模拟地下救援场景，让自主代理在未知洞穴系统中寻找目标。研究采用 Imitation Learning 模仿学习来训练算法，利用 LiDAR 和相机数据进行空间导航和目标定位。最终，通过 Monte-Carlo 方法测试模型的鲁棒性，证明了该方法的有效性，为机器人自主导航提供了新的框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures, independent paper",
      "pdf_url": "http://arxiv.org/pdf/2401.03267v1",
      "published_date": "2024-01-06 18:05:06 UTC",
      "updated_date": "2024-01-06 18:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:07:15.324812"
    },
    {
      "arxiv_id": "2401.03246v1",
      "title": "SeqNAS: Neural Architecture Search for Event Sequence Classification",
      "title_zh": "SeqNAS：用于事件序列分类的神经架构搜索",
      "authors": [
        "Igor Udovichenko",
        "Egor Shvetsov",
        "Denis Divitsky",
        "Dmitry Osin",
        "Ilya Trofimov",
        "Anatoly Glushenko",
        "Ivan Sukharev",
        "Dmitry Berestenev",
        "Evgeny Burnaev"
      ],
      "abstract": "Neural Architecture Search (NAS) methods are widely used in various\nindustries to obtain high quality taskspecific solutions with minimal human\nintervention. Event Sequences find widespread use in various industrial\napplications including churn prediction customer segmentation fraud detection\nand fault diagnosis among others. Such data consist of categorical and\nreal-valued components with irregular timestamps. Despite the usefulness of NAS\nmethods previous approaches only have been applied to other domains images\ntexts or time series. Our work addresses this limitation by introducing a novel\nNAS algorithm SeqNAS specifically designed for event sequence classification.\nWe develop a simple yet expressive search space that leverages commonly used\nbuilding blocks for event sequence classification including multihead self\nattention convolutions and recurrent cells. To perform the search we adopt\nsequential Bayesian Optimization and utilize previously trained models as an\nensemble of teachers to augment knowledge distillation. As a result of our work\nwe demonstrate that our method surpasses state of the art NAS methods and\npopular architectures suitable for sequence classification and holds great\npotential for various industrial applications.",
      "tldr_zh": "本研究提出 SeqNAS，一种专门针对事件序列分类的 Neural Architecture Search (NAS) 算法，以解决现有方法未应用于此领域的局限性。SeqNAS 构建了一个简单且富有表现力的搜索空间，利用多头自注意力(multihead self-attention)、卷积(convolutions)和循环单元(recurrent cells)等常见构建块，并通过顺序 Bayesian Optimization 和知识蒸馏(knowledge distillation)来优化架构搜索。实验结果显示，SeqNAS 超过了现有 NAS 方法和适合序列分类的流行架构，在工业应用如客户流失预测和欺诈检测中展现出巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "in IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2401.03246v1",
      "published_date": "2024-01-06 16:00:26 UTC",
      "updated_date": "2024-01-06 16:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:07:28.636949"
    },
    {
      "arxiv_id": "2401.03244v2",
      "title": "Artificial Intelligence for Operations Research: Revolutionizing the Operations Research Process",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenan Fan",
        "Bissan Ghaddar",
        "Xinglu Wang",
        "Linzi Xing",
        "Yong Zhang",
        "Zirui Zhou"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) techniques has opened\nup new opportunities to revolutionize various fields, including operations\nresearch (OR). This survey paper explores the integration of AI within the OR\nprocess (AI4OR) to enhance its effectiveness and efficiency across multiple\nstages, such as parameter generation, model formulation, and model\noptimization. By providing a comprehensive overview of the state-of-the-art and\nexamining the potential of AI to transform OR, this paper aims to inspire\nfurther research and innovation in the development of AI-enhanced OR methods\nand tools. The synergy between AI and OR is poised to drive significant\nadvancements and novel solutions in a multitude of domains, ultimately leading\nto more effective and efficient decision-making.",
      "tldr_zh": "这篇调查论文探讨了人工智能 (AI) 如何整合到运筹学 (Operations Research, OR) 过程中，从而革命性地提升其有效性和效率。论文概述了 AI 在参数生成、模型制定和模型优化等关键阶段的应用现状，并强调 AI 与 OR 的协同作用。最终，该研究旨在激发更多创新，推动 AI 增强 OR 方法的应用，实现更高效的决策支持。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03244v2",
      "published_date": "2024-01-06 15:55:14 UTC",
      "updated_date": "2024-03-26 20:35:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:07:40.426786"
    },
    {
      "arxiv_id": "2401.03238v1",
      "title": "Using Large Language Models to Assess Tutors' Performance in Reacting to Students Making Math Errors",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjit Kakarla",
        "Danielle Thomas",
        "Jionghao Lin",
        "Shivang Gupta",
        "Kenneth R. Koedinger"
      ],
      "abstract": "Research suggests that tutors should adopt a strategic approach when\naddressing math errors made by low-efficacy students. Rather than drawing\ndirect attention to the error, tutors should guide the students to identify and\ncorrect their mistakes on their own. While tutor lessons have introduced this\npedagogical skill, human evaluation of tutors applying this strategy is arduous\nand time-consuming. Large language models (LLMs) show promise in providing\nreal-time assessment to tutors during their actual tutoring sessions, yet\nlittle is known regarding their accuracy in this context. In this study, we\ninvestigate the capacity of generative AI to evaluate real-life tutors'\nperformance in responding to students making math errors. By analyzing 50\nreal-life tutoring dialogues, we find both GPT-3.5-Turbo and GPT-4 demonstrate\nproficiency in assessing the criteria related to reacting to students making\nerrors. However, both models exhibit limitations in recognizing instances where\nthe student made an error. Notably, GPT-4 tends to overidentify instances of\nstudents making errors, often attributing student uncertainty or inferring\npotential errors where human evaluators did not. Future work will focus on\nenhancing generalizability by assessing a larger dataset of dialogues and\nevaluating learning transfer. Specifically, we will analyze the performance of\ntutors in real-life scenarios when responding to students' math errors before\nand after lesson completion on this crucial tutoring skill.",
      "tldr_zh": "本研究使用Large Language Models (LLMs) 如GPT-3.5-Turbo和GPT-4 来评估导师在应对低效能学生数学错误时的表现，旨在通过分析50个真实辅导对话，检查导师是否采用引导学生自我发现错误的策略。结果显示，这些模型在评估反应标准方面表现出色，但GPT-4 易于过度识别错误，往往将学生的不确定性误判为错误。未来工作将扩展数据集并评估导师在完成相关培训前后表现的改进，以提升评估的泛化性和学习转移效果。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "13 page Workshop paper, AAAI2024 Workshop on AI for Education -\n  Bridging Innovation and Responsibility, Tutoring, Tutor evaluation, Real-time\n  feedback, Math learning, LLMs, GPT-4",
      "pdf_url": "http://arxiv.org/pdf/2401.03238v1",
      "published_date": "2024-01-06 15:34:27 UTC",
      "updated_date": "2024-01-06 15:34:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:07:54.145764"
    },
    {
      "arxiv_id": "2401.03233v3",
      "title": "Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Matea Marinova",
        "Daniel Denkovski",
        "Hristijan Gjoreski",
        "Zoran Hadzi-Velkov",
        "Valentin Rakovic"
      ],
      "abstract": "Split Learning (SL) is a promising Distributed Learning approach in\nelectromyography (EMG) based prosthetic control, due to its applicability\nwithin resource-constrained environments. Other learning approaches, such as\nDeep Learning and Federated Learning (FL), provide suboptimal solutions, since\nprosthetic devices are extremely limited in terms of processing power and\nbattery life. The viability of implementing SL in such scenarios is caused by\nits inherent model partitioning, with clients executing the smaller model\nsegment. However, selecting an inadequate cut layer hinders the training\nprocess in SL systems. This paper presents an algorithm for optimal cut layer\nselection in terms of maximizing the convergence rate of the model. The\nperformance evaluation demonstrates that the proposed algorithm substantially\naccelerates the convergence in an EMG pattern recognition task for improving\nprosthetic device control.",
      "tldr_zh": "该研究探讨了 Split Learning (SL) 在 electromyography (EMG) 基于假肢控制中的应用，强调其适合资源受限环境的优势，与 Deep Learning 和 Federated Learning (FL) 相比更高效。论文提出了一种算法，通过优化切分层（cut layer）的选择来最大化模型的收敛率，从而加速训练过程。实验结果显示，该算法显著提升了 EMG 模式识别任务的收敛速度，最终改善了假肢设备的控制性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 20th International Conference on Intelligent\n  Environments (IE), 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03233v3",
      "published_date": "2024-01-06 15:05:49 UTC",
      "updated_date": "2024-05-12 21:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:08:04.846769"
    },
    {
      "arxiv_id": "2401.03221v1",
      "title": "MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Yupei Lin",
        "Xiaoyu Xian",
        "Yukai Shi",
        "Liang Lin"
      ],
      "abstract": "Recently, text-to-image diffusion models become a new paradigm in image\nprocessing fields, including content generation, image restoration and\nimage-to-image translation. Given a target prompt, Denoising Diffusion\nProbabilistic Models (DDPM) are able to generate realistic yet eligible images.\nWith this appealing property, the image translation task has the potential to\nbe free from target image samples for supervision. By using a target text\nprompt for domain adaption, the diffusion model is able to implement zero-shot\nimage-to-image translation advantageously. However, the sampling and inversion\nprocesses of DDPM are stochastic, and thus the inversion process often fail to\nreconstruct the input content. Specifically, the displacement effect will\ngradually accumulated during the diffusion and inversion processes, which led\nto the reconstructed results deviating from the source domain. To make\nreconstruction explicit, we propose a prompt redescription strategy to realize\na mirror effect between the source and reconstructed image in the diffusion\nmodel (MirrorDiffusion). More specifically, a prompt redescription mechanism is\ninvestigated to align the text prompts with latent code at each time step of\nthe Denoising Diffusion Implicit Models (DDIM) inversion to pursue a\nstructure-preserving reconstruction. With the revised DDIM inversion,\nMirrorDiffusion is able to realize accurate zero-shot image translation by\nediting optimized text prompts and latent code. Extensive experiments\ndemonstrate that MirrorDiffusion achieves superior performance over the\nstate-of-the-art methods on zero-shot image translation benchmarks by clear\nmargins and practical model stability.",
      "tldr_zh": "本论文提出MirrorDiffusion框架，通过提示重描述(prompt redescription)策略来稳定扩散过程，实现零-shot图像翻译，从而避免了传统Denoising Diffusion Probabilistic Models (DDPM)中因随机性导致的重建失败和位移效应。具体方法包括在Denoising Diffusion Implicit Models (DDIM)反演的每个时间步调整文本提示与潜在代码的alignment，以确保结构保持。实验结果表明，MirrorDiffusion在零-shot图像翻译基准上显著优于现有方法，提高了准确性和模型稳定性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "A prompt re-description strategy is proposed for stabilizing the\n  diffusion model in image-to-image translation. Code and dataset page:\n  https://mirrordiffusion.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2401.03221v1",
      "published_date": "2024-01-06 14:12:16 UTC",
      "updated_date": "2024-01-06 14:12:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:08:17.494957"
    },
    {
      "arxiv_id": "2401.06785v1",
      "title": "Human-Instruction-Free LLM Self-Alignment with Limited Samples",
      "title_zh": "翻译失败",
      "authors": [
        "Hongyi Guo",
        "Yuanshun Yao",
        "Wei Shen",
        "Jiaheng Wei",
        "Xiaoying Zhang",
        "Zhaoran Wang",
        "Yang Liu"
      ],
      "abstract": "Aligning large language models (LLMs) with human values is a vital task for\nLLM practitioners. Current alignment techniques have several limitations: (1)\nrequiring a large amount of annotated data; (2) demanding heavy human\ninvolvement; (3) lacking a systematic mechanism to continuously improve. In\nthis work, we study aligning LLMs to a new domain with limited samples (e.g. <\n100). We propose an algorithm that can self-align LLMs iteratively without\nactive human involvement. Unlike existing works, our algorithm relies on\nneither human-crafted instructions nor labeled rewards, significantly reducing\nhuman involvement. In addition, our algorithm can self-improve the alignment\ncontinuously. The key idea is to first retrieve high-quality samples related to\nthe target domain and use them as In-context Learning examples to generate more\nsamples. Then we use the self-generated samples to finetune the LLM\niteratively. We show that our method can unlock the LLMs' self-generalization\nability to perform alignment with near-zero human supervision. We test our\nalgorithm on three benchmarks in safety, truthfulness, and\ninstruction-following, and show good performance in alignment, domain\nadaptability, and scalability.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的对齐问题，提出了一种Human-Instruction-Free LLM Self-Alignment算法，仅需有限样本（如少于100个）即可实现迭代自我对齐，而无需人类指令或标注奖励。算法的关键步骤包括检索高质量样本作为In-context Learning示例来生成更多数据，然后使用这些自我生成的样本对LLMs进行迭代微调，从而解锁模型的自我泛化能力。实验结果显示，该方法在安全、真实性和指令遵循三个基准上表现出色的对齐性能、领域适应性和可扩展性，几乎无需人类监督。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06785v1",
      "published_date": "2024-01-06 14:00:12 UTC",
      "updated_date": "2024-01-06 14:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:08:32.285692"
    },
    {
      "arxiv_id": "2401.03214v1",
      "title": "Understanding Representation Learnability of Nonlinear Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruofeng Yang",
        "Xiangyuan Li",
        "Bo Jiang",
        "Shuai Li"
      ],
      "abstract": "Self-supervised learning (SSL) has empirically shown its data representation\nlearnability in many downstream tasks. There are only a few theoretical works\non data representation learnability, and many of those focus on final data\nrepresentation, treating the nonlinear neural network as a ``black box\".\nHowever, the accurate learning results of neural networks are crucial for\ndescribing the data distribution features learned by SSL models. Our paper is\nthe first to analyze the learning results of the nonlinear SSL model\naccurately. We consider a toy data distribution that contains two features: the\nlabel-related feature and the hidden feature. Unlike previous linear setting\nwork that depends on closed-form solutions, we use the gradient descent\nalgorithm to train a 1-layer nonlinear SSL model with a certain initialization\nregion and prove that the model converges to a local minimum. Furthermore,\ndifferent from the complex iterative analysis, we propose a new analysis\nprocess which uses the exact version of Inverse Function Theorem to accurately\ndescribe the features learned by the local minimum. With this local minimum, we\nprove that the nonlinear SSL model can capture the label-related feature and\nhidden feature at the same time. In contrast, the nonlinear supervised learning\n(SL) model can only learn the label-related feature. We also present the\nlearning processes and results of the nonlinear SSL and SL model via simulation\nexperiments.",
      "tldr_zh": "本文首次准确分析非线性自监督学习 (SSL) 模型的学习结果，聚焦于其数据表示可学习性，并与非线性监督学习 (SL) 模型进行比较。研究者考虑一个包含标签相关特征和隐藏特征的玩具数据分布，使用梯度下降算法训练一个1层非线性SSL模型，并在特定初始化区域证明模型收敛到局部最小值。接着，通过Inverse Function Theorem精确描述局部最小值学到的特征，发现非线性SSL模型能同时捕获标签相关特征和隐藏特征，而非线性SL模型仅能学习标签相关特征。模拟实验进一步验证了这些学习过程和结果，强调了SSL在特征学习方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03214v1",
      "published_date": "2024-01-06 13:23:26 UTC",
      "updated_date": "2024-01-06 13:23:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:08:44.057845"
    },
    {
      "arxiv_id": "2401.03197v2",
      "title": "Decision Making in Non-Stationary Environments with Policy-Augmented Search",
      "title_zh": "在非平稳环境中利用策略增强搜索进行决策",
      "authors": [
        "Ava Pettet",
        "Yunuo Zhang",
        "Baiting Luo",
        "Kyle Wray",
        "Hendrik Baier",
        "Aron Laszka",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "abstract": "Sequential decision-making under uncertainty is present in many important\nproblems. Two popular approaches for tackling such problems are reinforcement\nlearning and online search (e.g., Monte Carlo tree search). While the former\nlearns a policy by interacting with the environment (typically done before\nexecution), the latter uses a generative model of the environment to sample\npromising action trajectories at decision time. Decision-making is particularly\nchallenging in non-stationary environments, where the environment in which an\nagent operates can change over time. Both approaches have shortcomings in such\nsettings -- on the one hand, policies learned before execution become stale\nwhen the environment changes and relearning takes both time and computational\neffort. Online search, on the other hand, can return sub-optimal actions when\nthere are limitations on allowed runtime. In this paper, we introduce\n\\textit{Policy-Augmented Monte Carlo tree search} (PA-MCTS), which combines\naction-value estimates from an out-of-date policy with an online search using\nan up-to-date model of the environment. We prove theoretical results showing\nconditions under which PA-MCTS selects the one-step optimal action and also\nbound the error accrued while following PA-MCTS as a policy. We compare and\ncontrast our approach with AlphaZero, another hybrid planning approach, and\nDeep Q Learning on several OpenAI Gym environments. Through extensive\nexperiments, we show that under non-stationary settings with limited time\nconstraints, PA-MCTS outperforms these baselines.",
      "tldr_zh": "该论文探讨了在非平稳环境中进行顺序决策的挑战，强化学习和在线搜索（如 Monte Carlo tree search）各自存在局限：前者策略易过时，后者受运行时间限制可能次优。作者提出 Policy-Augmented Monte Carlo tree search (PA-MCTS)，通过结合过时策略的行动价值估计与最新环境模型的在线搜索，实现了更有效的决策。理论证明显示 PA-MCTS 在特定条件下选择一步最优行动，并限制错误积累；实验在 OpenAI Gym 环境中表明，该方法在非平稳设置和时间约束下，优于 AlphaZero 和 Deep Q Learning 的基线。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended Abstract accepted for presentation at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03197v2",
      "published_date": "2024-01-06 11:51:50 UTC",
      "updated_date": "2024-01-20 18:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:01.060965"
    },
    {
      "arxiv_id": "2401.03196v3",
      "title": "SecureReg: Combining NLP and MLP for Enhanced Detection of Malicious Domain Name Registrations",
      "title_zh": "SecureReg：结合 NLP 和 MLP 用于增强恶意域名注册检测",
      "authors": [
        "Furkan Çolhak",
        "Mert İlhan Ecevit",
        "Hasan Dağ",
        "Reiner Creutzburg"
      ],
      "abstract": "The escalating landscape of cyber threats, characterized by the registration\nof thousands of new domains daily for large-scale Internet attacks such as\nspam, phishing, and drive-by downloads, underscores the imperative for\ninnovative detection methodologies. This paper introduces a cutting-edge\napproach for identifying suspicious domains at the onset of the registration\nprocess. The accompanying data pipeline generates crucial features by comparing\nnew domains to registered domains, emphasizing the crucial similarity score.\nThe proposed system analyzes semantic and numerical attributes by leveraging a\nnovel combination of Natural Language Processing (NLP) techniques, including a\npretrained CANINE model and Multilayer Perceptron (MLP) models, providing a\nrobust solution for early threat detection. This integrated Pretrained NLP\n(CANINE) + MLP model showcases the outstanding performance, surpassing both\nindividual pretrained NLP models and standalone MLP models. With an F1 score of\n84.86\\% and an accuracy of 84.95\\% on the SecureReg dataset, it effectively\ndetects malicious domain registrations. The findings demonstrate the\neffectiveness of the integrated approach and contribute to the ongoing efforts\nto develop proactive strategies to mitigate the risks associated with illicit\nonline activities through the early identification of suspicious domain\nregistrations.",
      "tldr_zh": "这篇论文提出SecureReg系统，通过结合Natural Language Processing (NLP)技术和Multilayer Perceptron (MLP)模型，增强对恶意域名注册的早期检测。系统利用数据管道生成特征，基于新域名与已注册域名的相似性分数，并采用预训练CANINE模型分析语义属性，以实现更准确的威胁识别。在SecureReg数据集上，该集成模型的F1分数达到84.86%、准确率达84.95%，显著优于单独使用NLP或MLP模型。该方法证明了混合方法的有效性，有助于开发主动策略，降低网络攻击风险如钓鱼和垃圾邮件。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03196v3",
      "published_date": "2024-01-06 11:43:57 UTC",
      "updated_date": "2024-07-10 11:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:14.054095"
    },
    {
      "arxiv_id": "2401.03194v1",
      "title": "Learning Persistent Community Structures in Dynamic Networks via Topological Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Dexu Kong",
        "Anping Zhang",
        "Yang Li"
      ],
      "abstract": "Dynamic community detection methods often lack effective mechanisms to ensure\ntemporal consistency, hindering the analysis of network evolution. In this\npaper, we propose a novel deep graph clustering framework with temporal\nconsistency regularization on inter-community structures, inspired by the\nconcept of minimal network topological changes within short intervals.\nSpecifically, to address the representation collapse problem, we first\nintroduce MFC, a matrix factorization-based deep graph clustering algorithm\nthat preserves node embedding. Based on static clustering results, we construct\nprobabilistic community networks and compute their persistence homology, a\nrobust topological measure, to assess structural similarity between them.\nMoreover, a novel neural network regularization TopoReg is introduced to ensure\nthe preservation of topological similarity between inter-community structures\nover time intervals. Our approach enhances temporal consistency and clustering\naccuracy on real-world datasets with both fixed and varying numbers of\ncommunities. It is also a pioneer application of TDA in temporally persistent\ncommunity detection, offering an insightful contribution to field of network\nanalysis. Code and data are available at the public git repository:\nhttps://github.com/kundtx/MFC_TopoReg",
      "tldr_zh": "本论文提出了一种新型深度图聚类框架，用于在动态网络中学习持久社区结构，通过 Topological Data Analysis (TDA) 实现时间一致性正则化，以解决现有方法在网络演化分析中的时间一致性问题。具体地，该框架引入 MFC（基于矩阵分解的深度图聚类算法）来保留节点嵌入，并基于静态聚类结果构建概率社区网络，使用 persistence homology 计算拓扑相似性，同时通过新型神经网络正则化 TopoReg 确保社区间结构在时间间隔上的相似性。实验结果显示，该方法在真实数据集上显著提高了聚类准确性和时间一致性，支持固定和变化的社区数量，并首次将 TDA 应用于时间持久社区检测领域，为网络分析提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.03194v1",
      "published_date": "2024-01-06 11:29:19 UTC",
      "updated_date": "2024-01-06 11:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:24.266209"
    },
    {
      "arxiv_id": "2401.03190v1",
      "title": "MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing",
      "title_zh": "MPN：利用多语言补丁神经元进行跨语言模型编辑",
      "authors": [
        "Nianwen Si",
        "Hao Zhang",
        "Weiqiang Zhang"
      ],
      "abstract": "Large language models are known for encoding a vast amount of factual\nknowledge, but they often becomes outdated due to the ever-changing nature of\nexternal information. A promising solution to this challenge is the utilization\nof model editing methods to update the knowledge in an efficient manner.\nHowever, the majority of existing model editing techniques are limited to\nmonolingual frameworks, thus failing to address the crucial issue of\ncross-lingual knowledge synchronization for multilingual models. To tackle this\nproblem, we propose a simple yet effective method that trains multilingual\npatch neuron to store cross-lingual knowledge. It can be easily adapted to\nexisting approaches to enhance their cross-lingual editing capabilities. To\nevaluate our method, we conduct experiments using both the XNLI dataset and a\nself-constructed XFEVER dataset. Experimental results demonstrate that our\nproposed method achieves improved performance in cross-lingual editing tasks\nwithout requiring excessive modifications to the original methodology, thereby\nshowcasing its user-friendly characteristics. Codes will be released soon.",
      "tldr_zh": "大语言模型常因外部信息变化而过时，现有的模型编辑方法主要局限于单语框架，无法实现跨语言知识同步。论文提出 MPN 方法，通过训练 Multilingual Patch Neuron 来存储跨语言知识，并轻松适应现有方法以提升其跨语言编辑能力。实验在 XNLI 数据集和自构建的 XFEVER 数据集上显示，该方法显著提高了编辑性能，且无需过多修改原方法，展示了其用户友好性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.03190v1",
      "published_date": "2024-01-06 10:40:24 UTC",
      "updated_date": "2024-01-06 10:40:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:36.120352"
    },
    {
      "arxiv_id": "2401.03188v2",
      "title": "A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Justus Renkhoff",
        "Ke Feng",
        "Marc Meier-Doernberg",
        "Alvaro Velasquez",
        "Houbing Herbert Song"
      ],
      "abstract": "Neurosymbolic artificial intelligence (AI) is an emerging branch of AI that\ncombines the strengths of symbolic AI and sub-symbolic AI. A major drawback of\nsub-symbolic AI is that it acts as a \"black box\", meaning that predictions are\ndifficult to explain, making the testing & evaluation (T&E) and validation &\nverification (V&V) processes of a system that uses sub-symbolic AI a challenge.\nSince neurosymbolic AI combines the advantages of both symbolic and\nsub-symbolic AI, this survey explores how neurosymbolic applications can ease\nthe V&V process. This survey considers two taxonomies of neurosymbolic AI,\nevaluates them, and analyzes which algorithms are commonly used as the symbolic\nand sub-symbolic components in current applications. Additionally, an overview\nof current techniques for the T&E and V&V processes of these components is\nprovided. Furthermore, it is investigated how the symbolic part is used for T&E\nand V&V purposes in current neurosymbolic applications. Our research shows that\nneurosymbolic AI as great potential to ease the T&E and V&V processes of\nsub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,\nthe applicability of current T&E and V&V methods to neurosymbolic AI is\nassessed, and how different neurosymbolic architectures can impact these\nmethods is explored. It is found that current T&E and V&V techniques are partly\nsufficient to test, evaluate, verify, or validate the symbolic and sub-symbolic\npart of neurosymbolic applications independently, while some of them use\napproaches where current T&E and V&V methods are not applicable by default, and\nadjustments or even new approaches are needed. Our research shows that there is\ngreat potential in using symbolic AI to test, evaluate, verify, or validate the\npredictions of a sub-symbolic model, making neurosymbolic AI an interesting\nresearch direction for safe, secure, and trustworthy AI.",
      "tldr_zh": "这篇调查论文探讨了神经符号AI（Neurosymbolic AI）的验证与验证（V&V）和测试与评估（T&E）方法，强调其结合符号AI和子符号AI（sub-symbolic AI）的优势，以缓解子符号AI的“黑箱”问题带来的挑战。论文分析了两种神经符号AI分类，评估了常用符号和子符号组件的算法，并概述了当前T&E和V&V技术。研究发现，神经符号AI通过符号部分增强了子符号模型的解释性和可靠性，但现有方法仅部分适用于其架构，需要调整或开发新方法，以推动安全、可信赖AI的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03188v2",
      "published_date": "2024-01-06 10:28:52 UTC",
      "updated_date": "2024-01-10 16:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:47.299582"
    },
    {
      "arxiv_id": "2401.03175v1",
      "title": "Part-of-Speech Tagger for Bodo Language using Deep Learning approach",
      "title_zh": "翻译失败",
      "authors": [
        "Dhrubajyoti Pathak",
        "Sanjib Narzary",
        "Sukumar Nandi",
        "Bidisha Som"
      ],
      "abstract": "Language Processing systems such as Part-of-speech tagging, Named entity\nrecognition, Machine translation, Speech recognition, and Language modeling\n(LM) are well-studied in high-resource languages. Nevertheless, research on\nthese systems for several low-resource languages, including Bodo, Mizo,\nNagamese, and others, is either yet to commence or is in its nascent stages.\nLanguage model plays a vital role in the downstream tasks of modern NLP.\nExtensive studies are carried out on LMs for high-resource languages.\nNevertheless, languages such as Bodo, Rabha, and Mising continue to lack\ncoverage. In this study, we first present BodoBERT, a language model for the\nBodo language. To the best of our knowledge, this work is the first such effort\nto develop a language model for Bodo. Secondly, we present an ensemble DL-based\nPOS tagging model for Bodo. The POS tagging model is based on combinations of\nBiLSTM with CRF and stacked embedding of BodoBERT with BytePairEmbeddings. We\ncover several language models in the experiment to see how well they work in\nPOS tagging tasks. The best-performing model achieves an F1 score of 0.8041. A\ncomparative experiment was also conducted on Assamese POS taggers, considering\nthat the language is spoken in the same region as Bodo.",
      "tldr_zh": "该论文针对低资源语言Bodo，首次开发了BodoBERT语言模型，以填补其在NLP下游任务中的空白。研究提出了一种集成深度学习模型，用于Bodo的Part-of-Speech tagging，结合BiLSTM with CRF和BodoBERT的BytePairEmbeddings。实验结果显示，该模型的最佳版本F1 score达到0.8041，并在与Assamese语言的比较中展示了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Natural Language Engineering",
      "pdf_url": "http://arxiv.org/pdf/2401.03175v1",
      "published_date": "2024-01-06 09:37:56 UTC",
      "updated_date": "2024-01-06 09:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:09:59.129311"
    },
    {
      "arxiv_id": "2401.03171v1",
      "title": "Exploration of Adolescent Depression Risk Prediction Based on Census Surveys and General Life Issues",
      "title_zh": "基于人口普查调查",
      "authors": [
        "Qiang Li",
        "Yufeng Wu",
        "Zhan Xu",
        "Hefeng Zhou"
      ],
      "abstract": "In contemporary society, the escalating pressures of life and work have\npropelled psychological disorders to the forefront of modern health concerns,\nan issue that has been further accentuated by the COVID-19 pandemic. The\nprevalence of depression among adolescents is steadily increasing, and\ntraditional diagnostic methods, which rely on scales or interviews, prove\nparticularly inadequate for detecting depression in young people. Addressing\nthese challenges, numerous AI-based methods for assisting in the diagnosis of\nmental health issues have emerged. However, most of these methods center around\nfundamental issues with scales or use multimodal approaches like facial\nexpression recognition. Diagnosis of depression risk based on everyday habits\nand behaviors has been limited to small-scale qualitative studies. Our research\nleverages adolescent census data to predict depression risk, focusing on\nchildren's experiences with depression and their daily life situations. We\nintroduced a method for managing severely imbalanced high-dimensional data and\nan adaptive predictive approach tailored to data structure characteristics.\nFurthermore, we proposed a cloud-based architecture for automatic online\nlearning and data updates. This study utilized publicly available NSCH youth\ncensus data from 2020 to 2022, encompassing nearly 150,000 data entries. We\nconducted basic data analyses and predictive experiments, demonstrating\nsignificant performance improvements over standard machine learning and deep\nlearning algorithms. This affirmed our data processing method's broad\napplicability in handling imbalanced medical data. Diverging from typical\npredictive method research, our study presents a comprehensive architectural\nsolution, considering a wider array of user needs.",
      "tldr_zh": "本研究探讨了基于普查调查和日常生活问题的青少年抑郁风险预测，以应对传统诊断方法的不足和现有AI方法的局限。研究团队引入了管理严重不平衡高维数据的方法、适应性预测方法，以及一个基于云的架构，支持自动在线学习和数据更新，并利用2020-2022年NSCH数据进行分析。实验结果显示，该方法在预测性能上显著优于标准machine learning和deep learning算法，证明了其在处理不平衡医疗数据中的广泛适用性，并提供了一个全面的架构解决方案以满足用户多样需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03171v1",
      "published_date": "2024-01-06 09:14:25 UTC",
      "updated_date": "2024-01-06 09:14:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:10:11.712009"
    },
    {
      "arxiv_id": "2401.06783v1",
      "title": "MultiSiam: A Multiple Input Siamese Network For Social Media Text Classification And Duplicate Text Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sudhanshu Bhoi",
        "Swapnil Markhedkar",
        "Shruti Phadke",
        "Prashant Agrawal"
      ],
      "abstract": "Social media accounts post increasingly similar content, creating a chaotic\nexperience across platforms, which makes accessing desired information\ndifficult. These posts can be organized by categorizing and grouping duplicates\nacross social handles and accounts. There can be more than one duplicate of a\npost, however, a conventional Siamese neural network only considers a pair of\ninputs for duplicate text detection. In this paper, we first propose a\nmultiple-input Siamese network, MultiSiam. This condensed network is then used\nto propose another model, SMCD (Social Media Classification and Duplication\nModel) to perform both duplicate text grouping and categorization. The\nMultiSiam network, just like the Siamese, can be used in multiple applications\nby changing the sub-network appropriately.",
      "tldr_zh": "本论文针对社交媒体上内容重复导致的信息混乱问题，提出了一种多输入 Siamese 网络 MultiSiam，以处理传统 Siamese 神经网络仅限于一对输入的局限性。MultiSiam 被用于构建 SMCD（Social Media Classification and Duplication Model）模型，实现重复文本检测和分组以及文本分类的功能。通过这种设计，MultiSiam 可以根据需要改变子网络，适用于多种应用场景。实验结果表明，该方法有效地组织了社交媒体内容，提高了信息访问效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06783v1",
      "published_date": "2024-01-06 09:13:34 UTC",
      "updated_date": "2024-01-06 09:13:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:10:23.088790"
    },
    {
      "arxiv_id": "2401.03167v1",
      "title": "PosDiffNet: Positional Neural Diffusion for Point Cloud Registration in a Large Field of View with Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Rui She",
        "Sijie Wang",
        "Qiyu Kang",
        "Kai Zhao",
        "Yang Song",
        "Wee Peng Tay",
        "Tianyu Geng",
        "Xingchao Jian"
      ],
      "abstract": "Point cloud registration is a crucial technique in 3D computer vision with a\nwide range of applications. However, this task can be challenging, particularly\nin large fields of view with dynamic objects, environmental noise, or other\nperturbations. To address this challenge, we propose a model called PosDiffNet.\nOur approach performs hierarchical registration based on window-level,\npatch-level, and point-level correspondence. We leverage a graph neural partial\ndifferential equation (PDE) based on Beltrami flow to obtain high-dimensional\nfeatures and position embeddings for point clouds. We incorporate position\nembeddings into a Transformer module based on a neural ordinary differential\nequation (ODE) to efficiently represent patches within points. We employ the\nmulti-level correspondence derived from the high feature similarity scores to\nfacilitate alignment between point clouds. Subsequently, we use registration\nmethods such as SVD-based algorithms to predict the transformation using\ncorresponding point pairs. We evaluate PosDiffNet on several 3D point cloud\ndatasets, verifying that it achieves state-of-the-art (SOTA) performance for\npoint cloud registration in large fields of view with perturbations. The\nimplementation code of experiments is available at\nhttps://github.com/AI-IT-AVs/PosDiffNet.",
      "tldr_zh": "本文提出PosDiffNet模型，用于解决点云注册在大型视野下面对动态物体、环境噪声或其他perturbations的挑战。该模型采用分层注册策略，包括窗口级、补丁级和点级对应，并利用基于Beltrami流的图神经PDE获取高维特征和位置嵌入，再结合基于神经ODE的Transformer模块高效表示补丁。实验结果显示，PosDiffNet在多个3D点云数据集上实现了SOTA性能，证明了其鲁棒性和准确性提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03167v1",
      "published_date": "2024-01-06 08:58:15 UTC",
      "updated_date": "2024-01-06 08:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:10:35.827066"
    },
    {
      "arxiv_id": "2401.03160v5",
      "title": "HAIM-DRL: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zilin Huang",
        "Zihao Sheng",
        "Chengyuan Ma",
        "Sikai Chen"
      ],
      "abstract": "Despite significant progress in autonomous vehicles (AVs), the development of\ndriving policies that ensure both the safety of AVs and traffic flow efficiency\nhas not yet been fully explored. In this paper, we propose an enhanced\nhuman-in-the-loop reinforcement learning method, termed the Human as AI\nmentor-based deep reinforcement learning (HAIM-DRL) framework, which\nfacilitates safe and efficient autonomous driving in mixed traffic platoon.\nDrawing inspiration from the human learning process, we first introduce an\ninnovative learning paradigm that effectively injects human intelligence into\nAI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves\nas a mentor to the AI agent. While allowing the agent to sufficiently explore\nuncertain environments, the human expert can take control in dangerous\nsituations and demonstrate correct actions to avoid potential accidents. On the\nother hand, the agent could be guided to minimize traffic flow disturbance,\nthereby optimizing traffic flow efficiency. In detail, HAIM-DRL leverages data\ncollected from free exploration and partial human demonstrations as its two\ntraining sources. Remarkably, we circumvent the intricate process of manually\ndesigning reward functions; instead, we directly derive proxy state-action\nvalues from partial human demonstrations to guide the agents' policy learning.\nAdditionally, we employ a minimal intervention technique to reduce the human\nmentor's cognitive load. Comparative results show that HAIM-DRL outperforms\ntraditional methods in driving safety, sampling efficiency, mitigation of\ntraffic flow disturbance, and generalizability to unseen traffic scenarios. The\ncode and demo videos for this paper can be accessed at:\nhttps://zilin-huang.github.io/HAIM-DRL-website/",
      "tldr_zh": "本研究提出 HAIM-DRL 框架，一种增强的人-in-the-loop 强化学习方法，旨在实现自动驾驶的安全性和交通流量效率。该框架引入 Human as AI mentor (HAIM) 范式，让人类专家在危险场景中接管并示范正确动作，同时利用自由探索和部分人类示范数据训练代理，避免手动设计奖励函数并采用最小干预技术减少导师负担。实验结果表明，HAIM-DRL 在驾驶安全、采样效率、交通流量干扰缓解以及对未知场景的泛化能力方面均优于传统方法，为混合交通环境下的自主驾驶提供了可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Communications in Transportation Research",
      "pdf_url": "http://arxiv.org/pdf/2401.03160v5",
      "published_date": "2024-01-06 08:30:14 UTC",
      "updated_date": "2024-06-14 23:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:10:48.821588"
    },
    {
      "arxiv_id": "2401.03158v2",
      "title": "CoT-Driven Framework for Short Text Classification: Enhancing and Transferring Capabilities from Large to Smaller Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Wu",
        "Yuanben Zhang",
        "Zhonghe Han",
        "Yingyan Hou",
        "Lei Wang",
        "Siye Liu",
        "Qihang Gong",
        "Yunping Ge"
      ],
      "abstract": "Short Text Classification (STC) is crucial for processing and understanding\nthe brief but substantial content prevalent on contemporary digital platforms.\nThe STC encounters difficulties in grasping the semantic and syntactic\nintricacies, an issue that is apparent in traditional pre-trained language\nmodels. Although Graph Convolutional Networks enhance performance by\nintegrating external knowledge bases, these methods are limited by the quality\nand extent of the knowledge applied. Recently, the emergence of Large Language\nModels (LLMs) and Chain-of-Thought (CoT) has significantly improved the\nperformance of complex reasoning tasks. However, some studies have highlighted\nthe limitations of their application in fundamental NLP tasks. Consequently,\nthis study first employs CoT to investigate and enhance the capabilities of\nLLMs in STC tasks. We propose the Syntactic and Semantic Enrichment CoT\n(SSE-CoT) method, effectively decomposing the STC tasks into four distinct\nsteps: (i) essential concept identification, (ii) common-sense knowledge\nretrieval, (iii) text rewriting, and (iv) classification. Furthermore,\nrecognizing resource constraints in sectors like finance and healthcare, we\nthen introduce the CoT-Driven Multi-Task Learning (CDMT) framework to extend\nthese capabilities to smaller models. This framework begins by extracting\nrationales from LLMs and subsequently fine-tunes smaller models to optimize\ntheir performance. Extensive experimentation across six short-text benchmarks\nvalidated the efficacy of the proposed methods. In particular, SSE-CoT achieved\nstate-of-the-art performance with substantial improvements on all datasets,\nparticularly on the Ohsumed and TagMyNews datasets.",
      "tldr_zh": "本研究针对短文本分类（Short Text Classification, STC）的语义和句法挑战，提出了一种基于Chain-of-Thought (CoT)的框架，以提升Large Language Models (LLMs)的能力。研究引入Syntactic and Semantic Enrichment CoT (SSE-CoT)方法，将STC任务分解为四个步骤：基本概念识别（essential concept identification）、常识知识检索（common-sense knowledge retrieval）、文本重写（text rewriting）和分类（classification），从而显著改善分类性能。进一步，作者开发了CoT-Driven Multi-Task Learning (CDMT)框架，通过从LLMs提取推理路径并微调较小模型，实现能力的转移，以适应资源受限的场景。在六个基准数据集上的实验中，SSE-CoT取得了state-of-the-art性能，尤其在Ohsumed和TagMyNews数据集上实现了显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Knowledge-Based Systems",
      "pdf_url": "http://arxiv.org/pdf/2401.03158v2",
      "published_date": "2024-01-06 08:28:20 UTC",
      "updated_date": "2025-01-19 12:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:11:05.731760"
    },
    {
      "arxiv_id": "2401.03154v2",
      "title": "Decentralized Multi-Agent Active Search and Tracking when Targets Outnumber Agents",
      "title_zh": "当目标",
      "authors": [
        "Arundhati Banerjee",
        "Jeff Schneider"
      ],
      "abstract": "Multi-agent multi-target tracking has a wide range of applications, including\nwildlife patrolling, security surveillance or environment monitoring. Such\nalgorithms often make restrictive assumptions: the number of targets and/or\ntheir initial locations may be assumed known, or agents may be pre-assigned to\nmonitor disjoint partitions of the environment, reducing the burden of\nexploration. This also limits applicability when there are fewer agents than\ntargets, since agents are unable to continuously follow the targets in their\nfields of view. Multi-agent tracking algorithms additionally assume inter-agent\nsynchronization of observations, or the presence of a central controller to\ncoordinate joint actions. Instead, we focus on the setting of decentralized\nmulti-agent, multi-target, simultaneous active search-and-tracking with\nasynchronous inter-agent communication. Our proposed algorithm DecSTER uses a\nsequential monte carlo implementation of the probability hypothesis density\nfilter for posterior inference combined with Thompson sampling for\ndecentralized multi-agent decision making. We compare different action\nselection policies, focusing on scenarios where targets outnumber agents. In\nsimulation, we demonstrate that DecSTER is robust to unreliable inter-agent\ncommunication and outperforms information-greedy baselines in terms of the\nOptimal Sub-Pattern Assignment (OSPA) metric for different numbers of targets\nand varying teamsizes.",
      "tldr_zh": "本研究针对多智能体多目标跟踪场景（如野生动物巡逻或安全监控），提出了一种去中心化算法 DecSTER，以应对目标数量多于代理的情况，以及代理间异步通信和无中央控制器的挑战。该算法结合了顺序蒙特卡洛（Sequential Monte Carlo）实现的概率假设密度过滤器（PHD filter）进行后验推理，以及 Thompson sampling 用于去中心化决策，从而实现同时主动搜索和跟踪。实验结果显示，DecSTER 在模拟环境中对不可靠的代理间通信表现出鲁棒性，并在 Optimal Sub-Pattern Assignment (OSPA) 指标上优于信息贪婪基线模型，尤其适用于不同目标数量和代理团队规模的场景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.9; I.2.11"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2401.03154v2",
      "published_date": "2024-01-06 08:10:58 UTC",
      "updated_date": "2024-01-09 23:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:11:16.812747"
    },
    {
      "arxiv_id": "2402.01647v1",
      "title": "Build Your Own Robot Friend: An Open-Source Learning Module for Accessible and Engaging AI Education",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghao Shi",
        "Allison O'Connell",
        "Zongjian Li",
        "Siqi Liu",
        "Jennifer Ayissi",
        "Guy Hoffman",
        "Mohammad Soleymani",
        "Maja J. Matarić"
      ],
      "abstract": "As artificial intelligence (AI) is playing an increasingly important role in\nour society and global economy, AI education and literacy have become necessary\ncomponents in college and K-12 education to prepare students for an AI-powered\nsociety. However, current AI curricula have not yet been made accessible and\nengaging enough for students and schools from all socio-economic backgrounds\nwith different educational goals. In this work, we developed an open-source\nlearning module for college and high school students, which allows students to\nbuild their own robot companion from the ground up. This open platform can be\nused to provide hands-on experience and introductory knowledge about various\naspects of AI, including robotics, machine learning (ML), software engineering,\nand mechanical engineering. Because of the social and personal nature of a\nsocially assistive robot companion, this module also puts a special emphasis on\nhuman-centered AI, enabling students to develop a better understanding of\nhuman-AI interaction and AI ethics through hands-on learning activities. With\nopen-source documentation, assembling manuals and affordable materials,\nstudents from different socio-economic backgrounds can personalize their\nlearning experience based on their individual educational goals. To evaluate\nthe student-perceived quality of our module, we conducted a usability testing\nworkshop with 15 college students recruited from a minority-serving\ninstitution. Our results indicate that our AI module is effective,\neasy-to-follow, and engaging, and it increases student interest in studying\nAI/ML and robotics in the future. We hope that this work will contribute toward\naccessible and engaging AI education in human-AI interaction for college and\nhigh school students.",
      "tldr_zh": "这篇论文提出了一种开源学习模块“Build Your Own Robot Friend”，旨在为大学和高中生提供可访问且引人入胜的 AI 教育，帮助他们从零构建自己的机器人伴侣。模块通过动手实践介绍 AI 的各个方面，包括 robotics、machine learning (ML)、software engineering 和 mechanical engineering，同时强调 human-centered AI，以加深学生对 human-AI interaction 和 AI ethics 的理解。该模块使用开源文档、组装手册和负担得起的材料，使不同社会经济背景的学生能够个性化学习。在一项涉及15名来自少数民族服务机构的大学生可用性测试中，结果显示模块易于遵循、有效且吸引人，提升了学生对 AI/ML 和 robotics 的未来兴趣。该工作旨在推动更具包容性的 AI 教育。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to the Proceedings of the AAAI Conference on Artificial\n  Intelligence (2024)",
      "pdf_url": "http://arxiv.org/pdf/2402.01647v1",
      "published_date": "2024-01-06 08:03:08 UTC",
      "updated_date": "2024-01-06 08:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:11:28.561334"
    },
    {
      "arxiv_id": "2401.03138v1",
      "title": "TelTrans: Applying Multi-Type Telecom Data to Transportation Evaluation and Prediction via Multifaceted Graph Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "ChungYi Lin",
        "Shen-Lung Tung",
        "Hung-Ting Su",
        "Winston H. Hsu"
      ],
      "abstract": "To address the limitations of traffic prediction from location-bound\ndetectors, we present Geographical Cellular Traffic (GCT) flow, a novel data\nsource that leverages the extensive coverage of cellular traffic to capture\nmobility patterns. Our extensive analysis validates its potential for\ntransportation. Focusing on vehicle-related GCT flow prediction, we propose a\ngraph neural network that integrates multivariate, temporal, and spatial facets\nfor improved accuracy. Experiments reveal our model's superiority over\nbaselines, especially in long-term predictions. We also highlight the potential\nfor GCT flow integration into transportation systems.",
      "tldr_zh": "本研究针对传统交通预测依赖位置绑定检测器的局限性，提出了一种新型数据源Geographical Cellular Traffic (GCT)流，利用蜂窝流量捕获更广泛的移动模式，并通过分析验证其在交通领域的潜力。作者开发了TelTrans框架，该框架基于图神经网络(graph neural network)，整合多变量、时间和空间方面(multi-faceted graph modeling)，以提升车辆相关GCT流预测的准确性。实验结果显示，TelTrans模型在长期预测方面显著优于基线模型，并强调了GCT流整合到交通系统中的实际应用前景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 7 figures, 4 tables. Accepted by AAAI-24-IAAI, to appear",
      "pdf_url": "http://arxiv.org/pdf/2401.03138v1",
      "published_date": "2024-01-06 06:44:06 UTC",
      "updated_date": "2024-01-06 06:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:11:39.816811"
    },
    {
      "arxiv_id": "2401.03137v1",
      "title": "SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dohyeok Lee",
        "Seungyub Han",
        "Taehyun Cho",
        "Jungwoo Lee"
      ],
      "abstract": "Alleviating overestimation bias is a critical challenge for deep\nreinforcement learning to achieve successful performance on more complex tasks\nor offline datasets containing out-of-distribution data. In order to overcome\noverestimation bias, ensemble methods for Q-learning have been investigated to\nexploit the diversity of multiple Q-functions. Since network initialization has\nbeen the predominant approach to promote diversity in Q-functions,\nheuristically designed diversity injection methods have been studied in the\nliterature. However, previous studies have not attempted to approach guaranteed\nindependence over an ensemble from a theoretical perspective. By introducing a\nnovel regularization loss for Q-ensemble independence based on random matrix\ntheory, we propose spiked Wishart Q-ensemble independence regularization (SPQR)\nfor reinforcement learning. Specifically, we modify the intractable hypothesis\ntesting criterion for the Q-ensemble independence into a tractable KL\ndivergence between the spectral distribution of the Q-ensemble and the target\nWigner's semicircle distribution. We implement SPQR in several online and\noffline ensemble Q-learning algorithms. In the experiments, SPQR outperforms\nthe baseline algorithms in both online and offline RL benchmarks.",
      "tldr_zh": "这篇论文针对深度强化学习中的过估计偏差（overestimation bias），提出了一种基于随机矩阵理论的正则化方法 SPQR，用于控制 Q-ensemble 的独立性。具体而言，SPQR 通过引入 spiked Wishart 正则化损失，将 Q-ensemble 的谱分布与 Wigner's semicircle distribution 的 KL divergence 最小化，从而从理论角度保证 Q 函数的多样性。实验结果显示，在在线和离线 RL 基准测试中，应用 SPQR 的算法性能优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at NeurIPS 23",
      "pdf_url": "http://arxiv.org/pdf/2401.03137v1",
      "published_date": "2024-01-06 06:39:06 UTC",
      "updated_date": "2024-01-06 06:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:11:52.347815"
    },
    {
      "arxiv_id": "2401.03134v1",
      "title": "TimeGraphs: Graph-based Temporal Reasoning",
      "title_zh": "TimeGraphs：基于图的时间推理",
      "authors": [
        "Paridhi Maheshwari",
        "Hongyu Ren",
        "Yanan Wang",
        "Rok Sosic",
        "Jure Leskovec"
      ],
      "abstract": "Many real-world systems exhibit temporal, dynamic behaviors, which are\ncaptured as time series of complex agent interactions. To perform temporal\nreasoning, current methods primarily encode temporal dynamics through simple\nsequence-based models. However, in general these models fail to efficiently\ncapture the full spectrum of rich dynamics in the input, since the dynamics is\nnot uniformly distributed. In particular, relevant information might be harder\nto extract and computing power is wasted for processing all individual\ntimesteps, even if they contain no significant changes or no new information.\nHere we propose TimeGraphs, a novel approach that characterizes dynamic\ninteractions as a hierarchical temporal graph, diverging from traditional\nsequential representations. Our approach models the interactions using a\ncompact graph-based representation, enabling adaptive reasoning across diverse\ntime scales. Adopting a self-supervised method, TimeGraphs constructs a\nmulti-level event hierarchy from a temporal input, which is then used to\nefficiently reason about the unevenly distributed dynamics. This construction\nprocess is scalable and incremental to accommodate streaming data. We evaluate\nTimeGraphs on multiple datasets with complex, dynamic agent interactions,\nincluding a football simulator, the Resistance game, and the MOMA human\nactivity dataset. The results demonstrate both robustness and efficiency of\nTimeGraphs on a range of temporal reasoning tasks. Our approach obtains\nstate-of-the-art performance and leads to a performance increase of up to 12.2%\non event prediction and recognition tasks over current approaches. Our\nexperiments further demonstrate a wide array of capabilities including\nzero-shot generalization, robustness in case of data sparsity, and adaptability\nto streaming data flow.",
      "tldr_zh": "该论文提出 TimeGraphs，一种基于图的 temporal reasoning 方法，将动态交互建模为分层时间图，以克服传统序列模型在处理不均匀分布时间动态时的低效问题。该方法采用自监督方式构建多级事件层次，支持自适应推理、可扩展的增量处理和流式数据。该框架在足球模拟器、Resistance 游戏和 MOMA 数据集等测试中取得最先进性能，提升事件预测和识别任务准确率高达 12.2%，并展示零样本泛化、数据稀疏鲁棒性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03134v1",
      "published_date": "2024-01-06 06:26:49 UTC",
      "updated_date": "2024-01-06 06:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:12:04.231025"
    },
    {
      "arxiv_id": "2401.05434v1",
      "title": "ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification",
      "title_zh": "ECGformer: 利用 Transformer 进行 ECG 心跳",
      "authors": [
        "Taymaz Akan",
        "Sait Alp",
        "Mohammad Alfrad Nobel Bhuiyan"
      ],
      "abstract": "An arrhythmia, also known as a dysrhythmia, refers to an irregular heartbeat.\nThere are various types of arrhythmias that can originate from different areas\nof the heart, resulting in either a rapid, slow, or irregular heartbeat. An\nelectrocardiogram (ECG) is a vital diagnostic tool used to detect heart\nirregularities and abnormalities, allowing experts to analyze the heart's\nelectrical signals to identify intricate patterns and deviations from the norm.\nOver the past few decades, numerous studies have been conducted to develop\nautomated methods for classifying heartbeats based on ECG data. In recent\nyears, deep learning has demonstrated exceptional capabilities in tackling\nvarious medical challenges, particularly with transformers as a model\narchitecture for sequence processing. By leveraging the transformers, we\ndeveloped the ECGformer model for the classification of various arrhythmias\npresent in electrocardiogram data. We assessed the suggested approach using the\nMIT-BIH and PTB datasets. ECG heartbeat arrhythmia classification results show\nthat the proposed method is highly effective.",
      "tldr_zh": "本研究针对心律失常(arrhythmias)分类问题，开发了ECGformer模型，该模型利用Transformer架构处理心电图(ECG)数据序列，以实现对各种心律失常的自动化识别。相比传统方法，ECGformer通过深度学习技术提升了序列处理能力，并在MIT-BIH和PTB数据集上进行了评估。实验结果显示，该模型在心律失常分类任务中表现出色，证明了其高度有效性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.05434v1",
      "published_date": "2024-01-06 06:14:48 UTC",
      "updated_date": "2024-01-06 06:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:12:12.711917"
    },
    {
      "arxiv_id": "2401.03131v1",
      "title": "A Physics-guided Generative AI Toolkit for Geophysical Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Junhuan Yang",
        "Hanchen Wang",
        "Yi Sheng",
        "Youzuo Lin",
        "Lei Yang"
      ],
      "abstract": "Full-waveform inversion (FWI) plays a vital role in geoscience to explore the\nsubsurface. It utilizes the seismic wave to image the subsurface velocity map.\nAs the machine learning (ML) technique evolves, the data-driven approaches\nusing ML for FWI tasks have emerged, offering enhanced accuracy and reduced\ncomputational cost compared to traditional physics-based methods. However, a\ncommon challenge in geoscience, the unprivileged data, severely limits ML\neffectiveness. The issue becomes even worse during model pruning, a step\nessential in geoscience due to environmental complexities. To tackle this, we\nintroduce the EdGeo toolkit, which employs a diffusion-based model guided by\nphysics principles to generate high-fidelity velocity maps. The toolkit uses\nthe acoustic wave equation to generate corresponding seismic waveform data,\nfacilitating the fine-tuning of pruned ML models. Our results demonstrate\nsignificant improvements in SSIM scores and reduction in both MAE and MSE\nacross various pruning ratios. Notably, the ML model fine-tuned using data\ngenerated by EdGeo yields superior quality of velocity maps, especially in\nrepresenting unprivileged features, outperforming other existing methods.",
      "tldr_zh": "本论文针对地科学中全波形反演 (FWI) 的数据不足问题，引入了 EdGeo 工具包，这是一个受物理原理指导的生成 AI 工具包，利用基于扩散的模型生成高保真度的地下速度图和对应的地震波形数据，以辅助机器学习 (ML) 模型的微调。EdGeo 结合声波方程处理模型修剪后的 ML 模型，确保在环境复杂性下提升性能。实验结果显示，该工具包显著提高了 SSIM 分数，并降低了 MAE 和 MSE，在各种修剪比例下表现优异，尤其在表示未充分数据化的特征时超越现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.03131v1",
      "published_date": "2024-01-06 06:09:05 UTC",
      "updated_date": "2024-01-06 06:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:12:28.545170"
    },
    {
      "arxiv_id": "2401.05433v1",
      "title": "Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling",
      "title_zh": "利用对抗权重扰动和指标特定注意力池化增强作文评分",
      "authors": [
        "Jiaxin Huang",
        "Xinyu Zhao",
        "Chang Che",
        "Qunwei Lin",
        "Bo Liu"
      ],
      "abstract": "The objective of this study is to improve automated feedback tools designed\nfor English Language Learners (ELLs) through the utilization of data science\ntechniques encompassing machine learning, natural language processing, and\neducational data analytics. Automated essay scoring (AES) research has made\nstrides in evaluating written essays, but it often overlooks the specific needs\nof English Language Learners (ELLs) in language development. This study\nexplores the application of BERT-related techniques to enhance the assessment\nof ELLs' writing proficiency within AES.\n  To address the specific needs of ELLs, we propose the use of DeBERTa, a\nstate-of-the-art neural language model, for improving automated feedback tools.\nDeBERTa, pretrained on large text corpora using self-supervised learning,\nlearns universal language representations adaptable to various natural language\nunderstanding tasks. The model incorporates several innovative techniques,\nincluding adversarial training through Adversarial Weights Perturbation (AWP)\nand Metric-specific AttentionPooling (6 kinds of AP) for each label in the\ncompetition.\n  The primary focus of this research is to investigate the impact of\nhyperparameters, particularly the adversarial learning rate, on the performance\nof the model. By fine-tuning the hyperparameter tuning process, including the\ninfluence of 6AP and AWP, the resulting models can provide more accurate\nevaluations of language proficiency and support tailored learning tasks for\nELLs. This work has the potential to significantly benefit ELLs by improving\ntheir English language proficiency and facilitating their educational journey.",
      "tldr_zh": "本研究旨在通过数据科学技术提升自动作文评分（AES）系统，以更好地支持英语学习者（ELLs）的语言发展。研究提出使用 DeBERTa 模型结合 Adversarial Weights Perturbation (AWP) 和 Metric-specific AttentionPooling (6 kinds of AP)，通过对抗训练和度量特定注意力机制来优化模型性能，并细化超参数如对抗学习率。实验结果显示，该方法能提供更准确的语言熟练度评估，并为 ELLs 提供个性化反馈，促进他们的教育进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This article was accepted by 2023 International Conference on\n  Information Network and Computer Communications(INCC)",
      "pdf_url": "http://arxiv.org/pdf/2401.05433v1",
      "published_date": "2024-01-06 06:05:12 UTC",
      "updated_date": "2024-01-06 06:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:12:37.152699"
    },
    {
      "arxiv_id": "2401.03128v1",
      "title": "Manifold-based Shapley for SAR Recognization Network Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuran Hu",
        "Mingzhe Zhu",
        "Yuanjing Liu",
        "Zhenpeng Feng",
        "LJubisa Stankovic"
      ],
      "abstract": "Explainable artificial intelligence (XAI) holds immense significance in\nenhancing the deep neural network's transparency and credibility, particularly\nin some risky and high-cost scenarios, like synthetic aperture radar (SAR).\nShapley is a game-based explanation technique with robust mathematical\nfoundations. However, Shapley assumes that model's features are independent,\nrendering Shapley explanation invalid for high dimensional models. This study\nintroduces a manifold-based Shapley method by projecting high-dimensional\nfeatures into low-dimensional manifold features and subsequently obtaining\nFusion-Shap, which aims at (1) addressing the issue of erroneous explanations\nencountered by traditional Shap; (2) resolving the challenge of\ninterpretability that traditional Shap faces in complex scenarios.",
      "tldr_zh": "该研究针对合成孔径雷达(SAR)识别网络的解释性问题，指出传统Shapley值方法假设特征独立，导致在高维模型中出现错误解释。论文提出一种manifold-based Shapley方法，通过将高维特征投影到低维流形特征并计算Fusion-Shap，来解决这一局限性。最终，该方法提升了模型在复杂场景下的可解释性，为可信赖的XAI应用奠定基础。",
      "categories": [
        "cs.AI",
        "H.1.m"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.03128v1",
      "published_date": "2024-01-06 05:26:20 UTC",
      "updated_date": "2024-01-06 05:26:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:12:50.245957"
    },
    {
      "arxiv_id": "2401.08438v2",
      "title": "CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yaojia Lv",
        "Haojie Pan",
        "Zekun Wang",
        "Jiafeng Liang",
        "Yuanxing Liu",
        "Ruiji Fu",
        "Ming Liu",
        "Zhongyuan Wang",
        "Bing Qin"
      ],
      "abstract": "Cognitive dynamics are pivotal to advance human understanding of the world.\nRecent advancements in large language models (LLMs) reveal their potential for\ncognitive simulation. However, these LLM-based cognitive studies primarily\nfocus on static modeling, overlooking the dynamic nature of cognition. To\nbridge this gap, we propose the concept of the cognitive dynamics of LLMs and\npresent a corresponding task with the inspiration of longitudinal studies.\nTowards the task, we develop CogBench, a novel benchmark to assess the\ncognitive dynamics of LLMs and validate it through participant surveys. We also\ndesign two evaluation metrics for CogBench, including Authenticity and\nRationality. Recognizing the inherent static nature of LLMs, we introduce\nCogGPT for the task, which features an innovative iterative cognitive mechanism\naimed at enhancing lifelong cognitive dynamics. Empirical results demonstrate\nthe superiority of CogGPT over existing methods, particularly in its ability to\nfacilitate role-specific cognitive dynamics under continuous information flows.",
      "tldr_zh": "该论文指出，现有的LLMs（Large Language Models）在认知模拟中主要关注静态建模，而忽略了认知 dynamics 的动态性质，因此提出LLMs的认知 dynamics 概念，并基于纵向研究设计相应的任务。研究团队开发了CogBench基准，用于评估LLMs的认知 dynamics，并通过参与者调查验证其有效性，同时设计了Authenticity（真实性）和Rationality（合理性）两个评估指标。为解决LLMs的静态局限，论文引入CogGPT模型，该模型采用创新的迭代认知机制来增强终身认知 dynamics。实验结果显示，CogGPT在处理连续信息流下的角色特定认知 dynamics 方面，显著优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 (Findings)",
      "pdf_url": "http://arxiv.org/pdf/2401.08438v2",
      "published_date": "2024-01-06 03:59:59 UTC",
      "updated_date": "2024-09-24 07:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:13:04.802287"
    },
    {
      "arxiv_id": "2401.05432v1",
      "title": "TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Khondoker Murad Hossain",
        "Tim Oates"
      ],
      "abstract": "As deep neural networks and the datasets used to train them get larger, the\ndefault approach to integrating them into research and commercial projects is\nto download a pre-trained model and fine tune it. But these models can have\nuncertain provenance, opening up the possibility that they embed hidden\nmalicious behavior such as trojans or backdoors, where small changes to an\ninput (triggers) can cause the model to produce incorrect outputs (e.g., to\nmisclassify). This paper introduces a novel approach to backdoor detection that\nuses two tensor decomposition methods applied to network activations. This has\na number of advantages relative to existing detection methods, including the\nability to analyze multiple models at the same time, working across a wide\nvariety of network architectures, making no assumptions about the nature of\ntriggers used to alter network behavior, and being computationally efficient.\nWe provide a detailed description of the detection pipeline along with results\non models trained on the MNIST digit dataset, CIFAR-10 dataset, and two\ndifficult datasets from NIST's TrojAI competition. These results show that our\nmethod detects backdoored networks more accurately and efficiently than current\nstate-of-the-art methods.",
      "tldr_zh": "本论文提出TEN-GUARD，一种利用张量分解(Tensor Decomposition)方法分析网络激活(Network Activations)来检测深度神经网络(Deep Neural Networks)中的后门攻击(Backdoor Attacks)的创新框架。该方法能同时处理多个模型，适用于各种网络架构，且不依赖于触发器(Triggers)的特定形式，同时保持计算高效。实验结果显示，在MNIST、CIFAR-10和NIST的TrojAI数据集上，TEN-GUARD比现有最先进方法更准确和高效地识别后门网络。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.05432v1",
      "published_date": "2024-01-06 03:08:28 UTC",
      "updated_date": "2024-01-06 03:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:13:15.208840"
    },
    {
      "arxiv_id": "2401.06782v1",
      "title": "Semantic Similarity Matching for Patent Documents Using Ensemble BERT-related Model and Novel Text Processing Method",
      "title_zh": "翻译失败",
      "authors": [
        "Liqiang Yu",
        "Bo Liu",
        "Qunwei Lin",
        "Xinyu Zhao",
        "Chang Che"
      ],
      "abstract": "In the realm of patent document analysis, assessing semantic similarity\nbetween phrases presents a significant challenge, notably amplifying the\ninherent complexities of Cooperative Patent Classification (CPC) research.\nFirstly, this study addresses these challenges, recognizing early CPC work\nwhile acknowledging past struggles with language barriers and document\nintricacy. Secondly, it underscores the persisting difficulties of CPC\nresearch.\n  To overcome these challenges and bolster the CPC system, This paper presents\ntwo key innovations. Firstly, it introduces an ensemble approach that\nincorporates four BERT-related models, enhancing semantic similarity accuracy\nthrough weighted averaging. Secondly, a novel text preprocessing method\ntailored for patent documents is introduced, featuring a distinctive input\nstructure with token scoring that aids in capturing semantic relationships\nduring CPC context training, utilizing BCELoss. Our experimental findings\nconclusively establish the effectiveness of both our Ensemble Model and novel\ntext processing strategies when deployed on the U.S. Patent Phrase to Phrase\nMatching dataset.",
      "tldr_zh": "本研究针对专利文档中短语语义相似性的评估挑战，特别是Cooperative Patent Classification (CPC) 研究的语言障碍和文档复杂性问题，回顾了早期相关工作并强调了持续难题。论文提出两个创新：一个Ensemble模型结合四个BERT-related模型，通过加权平均提升语义相似性准确性；以及一个新型文本预处理方法，采用独特输入结构和token scoring，在CPC上下文训练中使用BCELoss来捕捉语义关系。在U.S. Patent Phrase to Phrase Matching数据集上的实验证明，这些策略有效，提高了整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "It accepted by The 6th International Conference on Machine Learning\n  and Machine Intelligence (MLMI 2023)",
      "pdf_url": "http://arxiv.org/pdf/2401.06782v1",
      "published_date": "2024-01-06 02:35:49 UTC",
      "updated_date": "2024-01-06 02:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:13:27.703863"
    },
    {
      "arxiv_id": "2401.05431v1",
      "title": "TRLS: A Time Series Representation Learning Framework via Spectrogram for Medical Signal Processing",
      "title_zh": "TRLS：一种通过频谱图的时间序列表示学习框架，用于医疗信号处理",
      "authors": [
        "Luyuan Xie",
        "Cong Li",
        "Xin Zhang",
        "Shengfang Zhai",
        "Yuejian Fang",
        "Qingni Shen",
        "Zhonghai Wu"
      ],
      "abstract": "Representation learning frameworks in unlabeled time series have been\nproposed for medical signal processing. Despite the numerous excellent\nprogresses have been made in previous works, we observe the representation\nextracted for the time series still does not generalize well. In this paper, we\npresent a Time series (medical signal) Representation Learning framework via\nSpectrogram (TRLS) to get more informative representations. We transform the\ninput time-domain medical signals into spectrograms and design a time-frequency\nencoder named Time Frequency RNN (TFRNN) to capture more robust multi-scale\nrepresentations from the augmented spectrograms. Our TRLS takes spectrogram as\ninput with two types of different data augmentations and maximizes the\nsimilarity between positive ones, which effectively circumvents the problem of\ndesigning negative samples. Our evaluation of four real-world medical signal\ndatasets focusing on medical signal classification shows that TRLS is superior\nto the existing frameworks.",
      "tldr_zh": "这篇论文提出了TRLS框架，用于无标签时间序列的表示学习，旨在解决现有方法在医疗信号处理中提取表示不泛化的问题。TRLS通过将时间域医疗信号转换为spectrogram，并设计Time Frequency RNN (TFRNN)编码器来捕获更鲁棒的多尺度表示，同时采用两种数据增强方法最大化正样本之间的相似性，从而避免了设计负样本的难题。在四个真实世界医疗信号数据集上的分类任务评估中，TRLS表现出色，优于现有框架。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper is accept by ICASSP 2024. This is a more detailed version",
      "pdf_url": "http://arxiv.org/pdf/2401.05431v1",
      "published_date": "2024-01-06 02:26:02 UTC",
      "updated_date": "2024-01-06 02:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:13:40.491825"
    },
    {
      "arxiv_id": "2401.04130v3",
      "title": "Plug-and-Play Transformer Modules for Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Chang",
        "Sk Miraj Ahmed",
        "Srikanth V. Krishnamurthy",
        "Basak Guler",
        "Ananthram Swami",
        "Samet Oymak",
        "Amit K. Roy-Chowdhury"
      ],
      "abstract": "Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual\nPrompt Tuning (VPT) have found success in enabling adaptation to new domains by\ntuning small modules within a transformer model. However, the number of domains\nencountered during test time can be very large, and the data is usually\nunlabeled. Thus, adaptation to new domains is challenging; it is also\nimpractical to generate customized tuned modules for each such domain. Toward\naddressing these challenges, this work introduces PLUTO: a Plug-and-pLay\nmodUlar Test-time domain adaptatiOn strategy. We pre-train a large set of\nmodules, each specialized for different source domains, effectively creating a\n``module store''. Given a target domain with few-shot unlabeled data, we\nintroduce an unsupervised test-time adaptation (TTA) method to (1) select a\nsparse subset of relevant modules from this store and (2) create a weighted\ncombination of selected modules without tuning their weights. This\nplug-and-play nature enables us to harness multiple most-relevant source\ndomains in a single inference call. Comprehensive evaluations demonstrate that\nPLUTO uniformly outperforms alternative TTA methods and that selecting $\\leq$5\nmodules suffice to extract most of the benefit. At a high level, our method\nequips pre-trained transformers with the capability to dynamically adapt to new\ndomains, motivating a new paradigm for efficient and scalable domain\nadaptation.",
      "tldr_zh": "本研究提出PLUTO，一种Plug-and-Play的模块化策略，用于Transformer模型的Test-Time Adaptation（TTA），以解决参数高效调整（PET）方法如LoRA、Adapter和VPT在面对大量无标签新领域时的适应挑战。PLUTO通过预训练一系列针对不同源领域的模块，形成一个“模块存储”，然后在目标领域使用无监督TTA方法选择少量相关模块（如≤5个）并创建它们的加权组合，而无需调整权重，从而在单次推理中利用多个源领域知识。实验结果显示，PLUTO在全面评估中显著优于其他TTA方法，并为预训练Transformer提供高效、可扩展的动态域适应范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04130v3",
      "published_date": "2024-01-06 00:24:50 UTC",
      "updated_date": "2024-02-08 22:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:13:52.840494"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 45,
  "processed_papers_count": 45,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T20:14:15.863426"
}