[
  {
    "arxiv_id": "2402.00031v1",
    "title": "An Integrated Framework for Team Formation and Winner Prediction in the FIRST Robotics Competition: Model, Algorithm, and Analysis",
    "authors": [
      "Federico Galbiati",
      "Ranier X. Gran",
      "Brendan D. Jacques",
      "Sullivan J. Mulhern",
      "Chun-Kit Ngan"
    ],
    "abstract": "This research work aims to develop an analytical approach for optimizing team\nformation and predicting team performance in a competitive environment based on\ndata on the competitors' skills prior to the team formation. There are several\napproaches in scientific literature to optimize and predict a team's\nperformance. However, most studies employ fine-grained skill statistics of the\nindividual members or constraints such as teams with a set group of members.\nCurrently, no research tackles the highly constrained domain of the FIRST\nRobotics Competition. This research effort aims to fill this gap by providing\nan analytical method for optimizing and predicting team performance in a\ncompetitive environment while allowing these constraints and only using metrics\non previous team performance, not on each individual member's performance. We\napply our method to the drafting process of the FIRST Robotics competition, a\ndomain in which the skills change year-over-year, team members change\nthroughout the season, each match only has a superficial set of statistics, and\nalliance formation is key to competitive success. First, we develop a method\nthat could extrapolate individual members' performance based on overall team\nperformance. An alliance optimization algorithm is developed to optimize team\nformation and a deep neural network model is trained to predict the winning\nteam, both using highly post-processed real-world data. Our method is able to\nsuccessfully extract individual members' metrics from overall team statistics,\nform competitive teams, and predict the winning team with 84.08% accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00031v1",
    "published_date": "2024-01-06 23:11:50 UTC",
    "updated_date": "2024-01-06 23:11:50 UTC"
  },
  {
    "arxiv_id": "2401.03322v1",
    "title": "Attention and Autoencoder Hybrid Model for Unsupervised Online Anomaly Detection",
    "authors": [
      "Seyed Amirhossein Najafi",
      "Mohammad Hassan Asemani",
      "Peyman Setoodeh"
    ],
    "abstract": "This paper introduces a hybrid attention and autoencoder (AE) model for\nunsupervised online anomaly detection in time series. The autoencoder captures\nlocal structural patterns in short embeddings, while the attention model learns\nlong-term features, facilitating parallel computing with positional encoding.\nUnique in its approach, our proposed hybrid model combines attention and\nautoencoder for the first time in time series anomaly detection. It employs an\nattention-based mechanism, akin to the deep transformer model, with key\narchitectural modifications for predicting the next time step window in the\nautoencoder's latent space. The model utilizes a threshold from the validation\ndataset for anomaly detection and introduces an alternative method based on\nanalyzing the first statistical moment of error, improving accuracy without\ndependence on a validation dataset. Evaluation on diverse real-world benchmark\ndatasets and comparing with other well-established models, confirms the\neffectiveness of our proposed model in anomaly detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03322v1",
    "published_date": "2024-01-06 22:55:02 UTC",
    "updated_date": "2024-01-06 22:55:02 UTC"
  },
  {
    "arxiv_id": "2401.03315v3",
    "title": "Malla: Demystifying Real-world Large Language Model Integrated Malicious Services",
    "authors": [
      "Zilong Lin",
      "Jian Cui",
      "Xiaojing Liao",
      "XiaoFeng Wang"
    ],
    "abstract": "The underground exploitation of large language models (LLMs) for malicious\nservices (i.e., Malla) is witnessing an uptick, amplifying the cyber threat\nlandscape and posing questions about the trustworthiness of LLM technologies.\nHowever, there has been little effort to understand this new cybercrime, in\nterms of its magnitude, impact, and techniques. In this paper, we conduct the\nfirst systematic study on 212 real-world Mallas, uncovering their proliferation\nin underground marketplaces and exposing their operational modalities. Our\nstudy discloses the Malla ecosystem, revealing its significant growth and\nimpact on today's public LLM services. Through examining 212 Mallas, we\nuncovered eight backend LLMs used by Mallas, along with 182 prompts that\ncircumvent the protective measures of public LLM APIs. We further demystify the\ntactics employed by Mallas, including the abuse of uncensored LLMs and the\nexploitation of public LLM APIs through jailbreak prompts. Our findings enable\na better understanding of the real-world exploitation of LLMs by\ncybercriminals, offering insights into strategies to counteract this\ncybercrime.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at the 33rd USENIX Security Symposium (USENIX Security '24).\n  The data and code are available at\n  https://github.com/idllresearch/malicious-gpt",
    "pdf_url": "http://arxiv.org/pdf/2401.03315v3",
    "published_date": "2024-01-06 22:25:42 UTC",
    "updated_date": "2024-08-19 20:08:29 UTC"
  },
  {
    "arxiv_id": "2401.03314v1",
    "title": "Enhancing Context Through Contrast",
    "authors": [
      "Kshitij Ambilduke",
      "Aneesh Shetye",
      "Diksha Bagade",
      "Rishika Bhagwatkar",
      "Khurshed Fitter",
      "Prasad Vagdargi",
      "Shital Chiddarwar"
    ],
    "abstract": "Neural machine translation benefits from semantically rich representations.\nConsiderable progress in learning such representations has been achieved by\nlanguage modelling and mutual information maximization objectives using\ncontrastive learning. The language-dependent nature of language modelling\nintroduces a trade-off between the universality of the learned representations\nand the model's performance on the language modelling tasks. Although\ncontrastive learning improves performance, its success cannot be attributed to\nmutual information alone. We propose a novel Context Enhancement step to\nimprove performance on neural machine translation by maximizing mutual\ninformation using the Barlow Twins loss. Unlike other approaches, we do not\nexplicitly augment the data but view languages as implicit augmentations,\neradicating the risk of disrupting semantic information. Further, our method\ndoes not learn embeddings from scratch and can be generalised to any set of\npre-trained embeddings. Finally, we evaluate the language-agnosticism of our\nembeddings through language classification and use them for neural machine\ntranslation to compare with state-of-the-art approaches.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03314v1",
    "published_date": "2024-01-06 22:13:51 UTC",
    "updated_date": "2024-01-06 22:13:51 UTC"
  },
  {
    "arxiv_id": "2401.03312v1",
    "title": "Exploiting Data Hierarchy as a New Modality for Contrastive Learning",
    "authors": [
      "Arjun Bhalla",
      "Daniel Levenson",
      "Jan Bernhard",
      "Anton Abilov"
    ],
    "abstract": "This work investigates how hierarchically structured data can help neural\nnetworks learn conceptual representations of cathedrals. The underlying\nWikiScenes dataset provides a spatially organized hierarchical structure of\ncathedral components. We propose a novel hierarchical contrastive training\napproach that leverages a triplet margin loss to represent the data's spatial\nhierarchy in the encoder's latent space. As such, the proposed approach\ninvestigates if the dataset structure provides valuable information for\nself-supervised learning. We apply t-SNE to visualize the resultant latent\nspace and evaluate the proposed approach by comparing it with other\ndataset-specific contrastive learning methods using a common downstream\nclassification task. The proposed method outperforms the comparable\nweakly-supervised and baseline methods. Our findings suggest that dataset\nstructure is a valuable modality for weakly-supervised learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03312v1",
    "published_date": "2024-01-06 21:47:49 UTC",
    "updated_date": "2024-01-06 21:47:49 UTC"
  },
  {
    "arxiv_id": "2401.03310v1",
    "title": "CAVIAR: Co-simulation of 6G Communications, 3D Scenarios and AI for Digital Twins",
    "authors": [
      "João Borges",
      "Felipe Bastos",
      "Ilan Correa",
      "Pedro Batista",
      "Aldebaro Klautau"
    ],
    "abstract": "Digital twins are an important technology for advancing mobile\ncommunications, specially in use cases that require simultaneously simulating\nthe wireless channel, 3D scenes and machine learning. Aiming at providing a\nsolution to this demand, this work describes a modular co-simulation\nmethodology called CAVIAR. Here, CAVIAR is upgraded to support a message\npassing library and enable the virtual counterpart of a digital twin system\nusing different 6G-related simulators. The main contributions of this work are\nthe detailed description of different CAVIAR architectures, the implementation\nof this methodology to assess a 6G use case of UAV-based search and rescue\nmission (SAR), and the generation of benchmarking data about the computational\nresource usage. For executing the SAR co-simulation we adopt five open-source\nsolutions: the physical and link level network simulator Sionna, the simulator\nfor autonomous vehicles AirSim, scikit-learn for training a decision tree for\nMIMO beam selection, Yolov8 for the detection of rescue targets and NATS for\nmessage passing. Results for the implemented SAR use case suggest that the\nmethodology can run in a single machine, with the main demanded resources being\nthe CPU processing and the GPU memory.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03310v1",
    "published_date": "2024-01-06 21:22:18 UTC",
    "updated_date": "2024-01-06 21:22:18 UTC"
  },
  {
    "arxiv_id": "2402.00030v1",
    "title": "Evolution-Bootstrapped Simulation: Artificial or Human Intelligence: Which Came First?",
    "authors": [
      "Paul Alexander Bilokon"
    ],
    "abstract": "Humans have created artificial intelligence (AI), not the other way around.\nThis statement is deceptively obvious. In this note, we decided to challenge\nthis statement as a small, lighthearted Gedankenexperiment. We ask a simple\nquestion: in a world driven by evolution by natural selection, would neural\nnetworks or humans be likely to evolve first? We compare the\nSolomonoff--Kolmogorov--Chaitin complexity of the two and find neural networks\n(even LLMs) to be significantly simpler than humans. Further, we claim that it\nis unnecessary for any complex human-made equipment to exist for there to be\nneural networks. Neural networks may have evolved as naturally occurring\nobjects before humans did as a form of chemical reaction-based or enzyme-based\ncomputation. Now that we know that neural networks can pass the Turing test and\nsuspect that they may be capable of superintelligence, we ask whether the\nnatural evolution of neural networks could lead from pure evolution by natural\nselection to what we call evolution-bootstrapped simulation. The evolution of\nneural networks does not involve irreducible complexity; would easily allow\nirreducible complexity to exist in the evolution-bootstrapped simulation; is a\nfalsifiable scientific hypothesis; and is independent of / orthogonal to the\nissue of intelligent design.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "q-bio.PE"
    ],
    "primary_category": "cs.NE",
    "comment": "6 pages, no figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00030v1",
    "published_date": "2024-01-06 21:06:58 UTC",
    "updated_date": "2024-01-06 21:06:58 UTC"
  },
  {
    "arxiv_id": "2401.03306v1",
    "title": "MOTO: Offline Pre-training to Online Fine-tuning for Model-based Robot Learning",
    "authors": [
      "Rafael Rafailov",
      "Kyle Hatch",
      "Victor Kolev",
      "John D. Martin",
      "Mariano Phielipp",
      "Chelsea Finn"
    ],
    "abstract": "We study the problem of offline pre-training and online fine-tuning for\nreinforcement learning from high-dimensional observations in the context of\nrealistic robot tasks. Recent offline model-free approaches successfully use\nonline fine-tuning to either improve the performance of the agent over the data\ncollection policy or adapt to novel tasks. At the same time, model-based RL\nalgorithms have achieved significant progress in sample efficiency and the\ncomplexity of the tasks they can solve, yet remain under-utilized in the\nfine-tuning setting. In this work, we argue that existing model-based offline\nRL methods are not suitable for offline-to-online fine-tuning in\nhigh-dimensional domains due to issues with distribution shifts, off-dynamics\ndata, and non-stationary rewards. We propose an on-policy model-based method\nthat can efficiently reuse prior data through model-based value expansion and\npolicy regularization, while preventing model exploitation by controlling\nepistemic uncertainty. We find that our approach successfully solves tasks from\nthe MetaWorld benchmark, as well as the Franka Kitchen robot manipulation\nenvironment completely from images. To the best of our knowledge, MOTO is the\nfirst method to solve this environment from pixels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an updated version of a manuscript that originally appeared\n  at CoRL 2023. The project website is here https://sites.google.com/view/mo2o",
    "pdf_url": "http://arxiv.org/pdf/2401.03306v1",
    "published_date": "2024-01-06 21:04:31 UTC",
    "updated_date": "2024-01-06 21:04:31 UTC"
  },
  {
    "arxiv_id": "2402.00029v1",
    "title": "Exploring Public Opinion on Responsible AI Through The Lens of Cultural Consensus Theory",
    "authors": [
      "Necdet Gurkan",
      "Jordan W. Suchow"
    ],
    "abstract": "As the societal implications of Artificial Intelligence (AI) continue to\ngrow, the pursuit of responsible AI necessitates public engagement in its\ndevelopment and governance processes. This involvement is crucial for capturing\ndiverse perspectives and promoting equitable practices and outcomes. We applied\nCultural Consensus Theory (CCT) to a nationally representative survey dataset\non various aspects of AI to discern beliefs and attitudes about responsible AI\nin the United States. Our results offer valuable insights by identifying shared\nand contrasting views on responsible AI. Furthermore, these findings serve as\ncritical reference points for developers and policymakers, enabling them to\nmore effectively consider individual variances and group-level cultural\nperspectives when making significant decisions and addressing the public's\nconcerns.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00029v1",
    "published_date": "2024-01-06 20:57:35 UTC",
    "updated_date": "2024-01-06 20:57:35 UTC"
  },
  {
    "arxiv_id": "2401.03302v3",
    "title": "Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT",
    "authors": [
      "Seyed Mohammad Hossein Hashemi",
      "Leila Safari",
      "Amirhossein Dadashzadeh Taromi"
    ],
    "abstract": "In the field of medical sciences, reliable detection and classification of\nbrain tumors from images remains a formidable challenge due to the rarity of\ntumors within the population of patients. Therefore, the ability to detect\ntumors in anomaly scenarios is paramount for ensuring timely interventions and\nimproved patient outcomes. This study addresses the issue by leveraging deep\nlearning (DL) techniques to detect and classify brain tumors in challenging\nsituations. The curated data set from the National Brain Mapping Lab (NBML)\ncomprises 81 patients, including 30 Tumor cases and 51 Normal cases. The\ndetection and classification pipelines are separated into two consecutive\ntasks. The detection phase involved comprehensive data analysis and\npre-processing to modify the number of image samples and the number of patients\nof each class to anomaly distribution (9 Normal per 1 Tumor) to comply with\nreal world scenarios. Next, in addition to common evaluation metrics for the\ntesting, we employed a novel performance evaluation method called Patient to\nPatient (PTP), focusing on the realistic evaluation of the model. In the\ndetection phase, we fine-tuned a YOLOv8n detection model to detect the tumor\nregion. Subsequent testing and evaluation yielded competitive performance both\nin Common Evaluation Metrics and PTP metrics. Furthermore, using the Data\nEfficient Image Transformer (DeiT) module, we distilled a Vision Transformer\n(ViT) model from a fine-tuned ResNet152 as a teacher in the classification\nphase. This approach demonstrates promising strides in reliable tumor detection\nand classification, offering potential advancements in tumor diagnosis for\nreal-world medical imaging scenarios.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "eess.IV",
    "comment": "This work has been submitted to the Elsevier for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2401.03302v3",
    "published_date": "2024-01-06 20:53:02 UTC",
    "updated_date": "2024-09-25 10:45:52 UTC"
  },
  {
    "arxiv_id": "2401.03301v2",
    "title": "On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond",
    "authors": [
      "Thanh Nguyen-Tang",
      "Raman Arora"
    ],
    "abstract": "We seek to understand what facilitates sample-efficient learning from\nhistorical datasets for sequential decision-making, a problem that is popularly\nknown as offline reinforcement learning (RL). Further, we are interested in\nalgorithms that enjoy sample efficiency while leveraging (value) function\napproximation. In this paper, we address these fundamental questions by (i)\nproposing a notion of data diversity that subsumes the previous notions of\ncoverage measures in offline RL and (ii) using this notion to {unify} three\ndistinct classes of offline RL algorithms based on version spaces (VS),\nregularized optimization (RO), and posterior sampling (PS). We establish that\nVS-based, RO-based, and PS-based algorithms, under standard assumptions,\nachieve \\emph{comparable} sample efficiency, which recovers the\nstate-of-the-art sub-optimality bounds for finite and linear model classes with\nthe standard assumptions. This result is surprising, given that the prior work\nsuggested an unfavorable sample complexity of the RO-based algorithm compared\nto the VS-based algorithm, whereas posterior sampling is rarely considered in\noffline RL due to its explorative nature. Notably, our proposed model-free\nPS-based algorithm for offline RL is {novel}, with sub-optimality bounds that\nare {frequentist} (i.e., worst-case) in nature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS'23; Arxiv is the authors' preferred version; v2: add a\n  missing related work",
    "pdf_url": "http://arxiv.org/pdf/2401.03301v2",
    "published_date": "2024-01-06 20:52:04 UTC",
    "updated_date": "2024-02-06 18:08:40 UTC"
  },
  {
    "arxiv_id": "2401.03275v1",
    "title": "Real Time Human Detection by Unmanned Aerial Vehicles",
    "authors": [
      "Walid Guettala",
      "Ali Sayah",
      "Laid Kahloul",
      "Ahmed Tibermacine"
    ],
    "abstract": "One of the most important problems in computer vision and remote sensing is\nobject detection, which identifies particular categories of diverse things in\npictures. Two crucial data sources for public security are the thermal infrared\n(TIR) remote sensing multi-scenario photos and videos produced by unmanned\naerial vehicles (UAVs). Due to the small scale of the target, complex scene\ninformation, low resolution relative to the viewable videos, and dearth of\npublicly available labeled datasets and training models, their object detection\nprocedure is still difficult. A UAV TIR object detection framework for pictures\nand videos is suggested in this study. The Forward-looking Infrared (FLIR)\ncameras used to gather ground-based TIR photos and videos are used to create\nthe ``You Only Look Once'' (YOLO) model, which is based on CNN architecture.\nResults indicated that in the validating task, detecting human object had an\naverage precision at IOU (Intersection over Union) = 0.5, which was 72.5\\%,\nusing YOLOv7 (YOLO version 7) state of the art model \\cite{1}, while the\ndetection speed around 161 frames per second (FPS/second). The usefulness of\nthe YOLO architecture is demonstrated in the application, which evaluates the\ncross-detection performance of people in UAV TIR videos under a YOLOv7 model in\nterms of the various UAVs' observation angles. The qualitative and quantitative\nevaluation of object detection from TIR pictures and videos using deep-learning\nmodels is supported favorably by this work.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T45, 68U10, 68U99",
      "I.2.10; I.4.8"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.03275v1",
    "published_date": "2024-01-06 18:28:01 UTC",
    "updated_date": "2024-01-06 18:28:01 UTC"
  },
  {
    "arxiv_id": "2401.03267v1",
    "title": "Autonomous Navigation in Complex Environments",
    "authors": [
      "Andrew Gerstenslager",
      "Jomol Lewis",
      "Liam McKenna",
      "Poorva Patel"
    ],
    "abstract": "This paper explores the application of CNN-DNN network fusion to construct a\nrobot navigation controller within a simulated environment. The simulated\nenvironment is constructed to model a subterranean rescue situation, such that\nan autonomous agent is tasked with finding a goal within an unknown cavernous\nsystem. Imitation learning is used to train the control algorithm to use LiDAR\nand camera data to navigate the space and find the goal. The trained model is\nthen tested for robustness using Monte-Carlo.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 3 figures, independent paper",
    "pdf_url": "http://arxiv.org/pdf/2401.03267v1",
    "published_date": "2024-01-06 18:05:06 UTC",
    "updated_date": "2024-01-06 18:05:06 UTC"
  },
  {
    "arxiv_id": "2401.03246v1",
    "title": "SeqNAS: Neural Architecture Search for Event Sequence Classification",
    "authors": [
      "Igor Udovichenko",
      "Egor Shvetsov",
      "Denis Divitsky",
      "Dmitry Osin",
      "Ilya Trofimov",
      "Anatoly Glushenko",
      "Ivan Sukharev",
      "Dmitry Berestenev",
      "Evgeny Burnaev"
    ],
    "abstract": "Neural Architecture Search (NAS) methods are widely used in various\nindustries to obtain high quality taskspecific solutions with minimal human\nintervention. Event Sequences find widespread use in various industrial\napplications including churn prediction customer segmentation fraud detection\nand fault diagnosis among others. Such data consist of categorical and\nreal-valued components with irregular timestamps. Despite the usefulness of NAS\nmethods previous approaches only have been applied to other domains images\ntexts or time series. Our work addresses this limitation by introducing a novel\nNAS algorithm SeqNAS specifically designed for event sequence classification.\nWe develop a simple yet expressive search space that leverages commonly used\nbuilding blocks for event sequence classification including multihead self\nattention convolutions and recurrent cells. To perform the search we adopt\nsequential Bayesian Optimization and utilize previously trained models as an\nensemble of teachers to augment knowledge distillation. As a result of our work\nwe demonstrate that our method surpasses state of the art NAS methods and\npopular architectures suitable for sequence classification and holds great\npotential for various industrial applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "in IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2401.03246v1",
    "published_date": "2024-01-06 16:00:26 UTC",
    "updated_date": "2024-01-06 16:00:26 UTC"
  },
  {
    "arxiv_id": "2401.03244v2",
    "title": "Artificial Intelligence for Operations Research: Revolutionizing the Operations Research Process",
    "authors": [
      "Zhenan Fan",
      "Bissan Ghaddar",
      "Xinglu Wang",
      "Linzi Xing",
      "Yong Zhang",
      "Zirui Zhou"
    ],
    "abstract": "The rapid advancement of artificial intelligence (AI) techniques has opened\nup new opportunities to revolutionize various fields, including operations\nresearch (OR). This survey paper explores the integration of AI within the OR\nprocess (AI4OR) to enhance its effectiveness and efficiency across multiple\nstages, such as parameter generation, model formulation, and model\noptimization. By providing a comprehensive overview of the state-of-the-art and\nexamining the potential of AI to transform OR, this paper aims to inspire\nfurther research and innovation in the development of AI-enhanced OR methods\nand tools. The synergy between AI and OR is poised to drive significant\nadvancements and novel solutions in a multitude of domains, ultimately leading\nto more effective and efficient decision-making.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03244v2",
    "published_date": "2024-01-06 15:55:14 UTC",
    "updated_date": "2024-03-26 20:35:45 UTC"
  },
  {
    "arxiv_id": "2401.03238v1",
    "title": "Using Large Language Models to Assess Tutors' Performance in Reacting to Students Making Math Errors",
    "authors": [
      "Sanjit Kakarla",
      "Danielle Thomas",
      "Jionghao Lin",
      "Shivang Gupta",
      "Kenneth R. Koedinger"
    ],
    "abstract": "Research suggests that tutors should adopt a strategic approach when\naddressing math errors made by low-efficacy students. Rather than drawing\ndirect attention to the error, tutors should guide the students to identify and\ncorrect their mistakes on their own. While tutor lessons have introduced this\npedagogical skill, human evaluation of tutors applying this strategy is arduous\nand time-consuming. Large language models (LLMs) show promise in providing\nreal-time assessment to tutors during their actual tutoring sessions, yet\nlittle is known regarding their accuracy in this context. In this study, we\ninvestigate the capacity of generative AI to evaluate real-life tutors'\nperformance in responding to students making math errors. By analyzing 50\nreal-life tutoring dialogues, we find both GPT-3.5-Turbo and GPT-4 demonstrate\nproficiency in assessing the criteria related to reacting to students making\nerrors. However, both models exhibit limitations in recognizing instances where\nthe student made an error. Notably, GPT-4 tends to overidentify instances of\nstudents making errors, often attributing student uncertainty or inferring\npotential errors where human evaluators did not. Future work will focus on\nenhancing generalizability by assessing a larger dataset of dialogues and\nevaluating learning transfer. Specifically, we will analyze the performance of\ntutors in real-life scenarios when responding to students' math errors before\nand after lesson completion on this crucial tutoring skill.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "13 page Workshop paper, AAAI2024 Workshop on AI for Education -\n  Bridging Innovation and Responsibility, Tutoring, Tutor evaluation, Real-time\n  feedback, Math learning, LLMs, GPT-4",
    "pdf_url": "http://arxiv.org/pdf/2401.03238v1",
    "published_date": "2024-01-06 15:34:27 UTC",
    "updated_date": "2024-01-06 15:34:27 UTC"
  },
  {
    "arxiv_id": "2401.03233v3",
    "title": "Convergence Rate Maximization for Split Learning-based Control of EMG Prosthetic Devices",
    "authors": [
      "Matea Marinova",
      "Daniel Denkovski",
      "Hristijan Gjoreski",
      "Zoran Hadzi-Velkov",
      "Valentin Rakovic"
    ],
    "abstract": "Split Learning (SL) is a promising Distributed Learning approach in\nelectromyography (EMG) based prosthetic control, due to its applicability\nwithin resource-constrained environments. Other learning approaches, such as\nDeep Learning and Federated Learning (FL), provide suboptimal solutions, since\nprosthetic devices are extremely limited in terms of processing power and\nbattery life. The viability of implementing SL in such scenarios is caused by\nits inherent model partitioning, with clients executing the smaller model\nsegment. However, selecting an inadequate cut layer hinders the training\nprocess in SL systems. This paper presents an algorithm for optimal cut layer\nselection in terms of maximizing the convergence rate of the model. The\nperformance evaluation demonstrates that the proposed algorithm substantially\naccelerates the convergence in an EMG pattern recognition task for improving\nprosthetic device control.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the 20th International Conference on Intelligent\n  Environments (IE), 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.03233v3",
    "published_date": "2024-01-06 15:05:49 UTC",
    "updated_date": "2024-05-12 21:39:54 UTC"
  },
  {
    "arxiv_id": "2401.03221v1",
    "title": "MirrorDiffusion: Stabilizing Diffusion Process in Zero-shot Image Translation by Prompts Redescription and Beyond",
    "authors": [
      "Yupei Lin",
      "Xiaoyu Xian",
      "Yukai Shi",
      "Liang Lin"
    ],
    "abstract": "Recently, text-to-image diffusion models become a new paradigm in image\nprocessing fields, including content generation, image restoration and\nimage-to-image translation. Given a target prompt, Denoising Diffusion\nProbabilistic Models (DDPM) are able to generate realistic yet eligible images.\nWith this appealing property, the image translation task has the potential to\nbe free from target image samples for supervision. By using a target text\nprompt for domain adaption, the diffusion model is able to implement zero-shot\nimage-to-image translation advantageously. However, the sampling and inversion\nprocesses of DDPM are stochastic, and thus the inversion process often fail to\nreconstruct the input content. Specifically, the displacement effect will\ngradually accumulated during the diffusion and inversion processes, which led\nto the reconstructed results deviating from the source domain. To make\nreconstruction explicit, we propose a prompt redescription strategy to realize\na mirror effect between the source and reconstructed image in the diffusion\nmodel (MirrorDiffusion). More specifically, a prompt redescription mechanism is\ninvestigated to align the text prompts with latent code at each time step of\nthe Denoising Diffusion Implicit Models (DDIM) inversion to pursue a\nstructure-preserving reconstruction. With the revised DDIM inversion,\nMirrorDiffusion is able to realize accurate zero-shot image translation by\nediting optimized text prompts and latent code. Extensive experiments\ndemonstrate that MirrorDiffusion achieves superior performance over the\nstate-of-the-art methods on zero-shot image translation benchmarks by clear\nmargins and practical model stability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A prompt re-description strategy is proposed for stabilizing the\n  diffusion model in image-to-image translation. Code and dataset page:\n  https://mirrordiffusion.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2401.03221v1",
    "published_date": "2024-01-06 14:12:16 UTC",
    "updated_date": "2024-01-06 14:12:16 UTC"
  },
  {
    "arxiv_id": "2401.06785v1",
    "title": "Human-Instruction-Free LLM Self-Alignment with Limited Samples",
    "authors": [
      "Hongyi Guo",
      "Yuanshun Yao",
      "Wei Shen",
      "Jiaheng Wei",
      "Xiaoying Zhang",
      "Zhaoran Wang",
      "Yang Liu"
    ],
    "abstract": "Aligning large language models (LLMs) with human values is a vital task for\nLLM practitioners. Current alignment techniques have several limitations: (1)\nrequiring a large amount of annotated data; (2) demanding heavy human\ninvolvement; (3) lacking a systematic mechanism to continuously improve. In\nthis work, we study aligning LLMs to a new domain with limited samples (e.g. <\n100). We propose an algorithm that can self-align LLMs iteratively without\nactive human involvement. Unlike existing works, our algorithm relies on\nneither human-crafted instructions nor labeled rewards, significantly reducing\nhuman involvement. In addition, our algorithm can self-improve the alignment\ncontinuously. The key idea is to first retrieve high-quality samples related to\nthe target domain and use them as In-context Learning examples to generate more\nsamples. Then we use the self-generated samples to finetune the LLM\niteratively. We show that our method can unlock the LLMs' self-generalization\nability to perform alignment with near-zero human supervision. We test our\nalgorithm on three benchmarks in safety, truthfulness, and\ninstruction-following, and show good performance in alignment, domain\nadaptability, and scalability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06785v1",
    "published_date": "2024-01-06 14:00:12 UTC",
    "updated_date": "2024-01-06 14:00:12 UTC"
  },
  {
    "arxiv_id": "2401.03214v1",
    "title": "Understanding Representation Learnability of Nonlinear Self-Supervised Learning",
    "authors": [
      "Ruofeng Yang",
      "Xiangyuan Li",
      "Bo Jiang",
      "Shuai Li"
    ],
    "abstract": "Self-supervised learning (SSL) has empirically shown its data representation\nlearnability in many downstream tasks. There are only a few theoretical works\non data representation learnability, and many of those focus on final data\nrepresentation, treating the nonlinear neural network as a ``black box\".\nHowever, the accurate learning results of neural networks are crucial for\ndescribing the data distribution features learned by SSL models. Our paper is\nthe first to analyze the learning results of the nonlinear SSL model\naccurately. We consider a toy data distribution that contains two features: the\nlabel-related feature and the hidden feature. Unlike previous linear setting\nwork that depends on closed-form solutions, we use the gradient descent\nalgorithm to train a 1-layer nonlinear SSL model with a certain initialization\nregion and prove that the model converges to a local minimum. Furthermore,\ndifferent from the complex iterative analysis, we propose a new analysis\nprocess which uses the exact version of Inverse Function Theorem to accurately\ndescribe the features learned by the local minimum. With this local minimum, we\nprove that the nonlinear SSL model can capture the label-related feature and\nhidden feature at the same time. In contrast, the nonlinear supervised learning\n(SL) model can only learn the label-related feature. We also present the\nlearning processes and results of the nonlinear SSL and SL model via simulation\nexperiments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03214v1",
    "published_date": "2024-01-06 13:23:26 UTC",
    "updated_date": "2024-01-06 13:23:26 UTC"
  },
  {
    "arxiv_id": "2401.03197v2",
    "title": "Decision Making in Non-Stationary Environments with Policy-Augmented Search",
    "authors": [
      "Ava Pettet",
      "Yunuo Zhang",
      "Baiting Luo",
      "Kyle Wray",
      "Hendrik Baier",
      "Aron Laszka",
      "Abhishek Dubey",
      "Ayan Mukhopadhyay"
    ],
    "abstract": "Sequential decision-making under uncertainty is present in many important\nproblems. Two popular approaches for tackling such problems are reinforcement\nlearning and online search (e.g., Monte Carlo tree search). While the former\nlearns a policy by interacting with the environment (typically done before\nexecution), the latter uses a generative model of the environment to sample\npromising action trajectories at decision time. Decision-making is particularly\nchallenging in non-stationary environments, where the environment in which an\nagent operates can change over time. Both approaches have shortcomings in such\nsettings -- on the one hand, policies learned before execution become stale\nwhen the environment changes and relearning takes both time and computational\neffort. Online search, on the other hand, can return sub-optimal actions when\nthere are limitations on allowed runtime. In this paper, we introduce\n\\textit{Policy-Augmented Monte Carlo tree search} (PA-MCTS), which combines\naction-value estimates from an out-of-date policy with an online search using\nan up-to-date model of the environment. We prove theoretical results showing\nconditions under which PA-MCTS selects the one-step optimal action and also\nbound the error accrued while following PA-MCTS as a policy. We compare and\ncontrast our approach with AlphaZero, another hybrid planning approach, and\nDeep Q Learning on several OpenAI Gym environments. Through extensive\nexperiments, we show that under non-stationary settings with limited time\nconstraints, PA-MCTS outperforms these baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended Abstract accepted for presentation at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.03197v2",
    "published_date": "2024-01-06 11:51:50 UTC",
    "updated_date": "2024-01-20 18:34:03 UTC"
  },
  {
    "arxiv_id": "2401.03196v3",
    "title": "SecureReg: Combining NLP and MLP for Enhanced Detection of Malicious Domain Name Registrations",
    "authors": [
      "Furkan Çolhak",
      "Mert İlhan Ecevit",
      "Hasan Dağ",
      "Reiner Creutzburg"
    ],
    "abstract": "The escalating landscape of cyber threats, characterized by the registration\nof thousands of new domains daily for large-scale Internet attacks such as\nspam, phishing, and drive-by downloads, underscores the imperative for\ninnovative detection methodologies. This paper introduces a cutting-edge\napproach for identifying suspicious domains at the onset of the registration\nprocess. The accompanying data pipeline generates crucial features by comparing\nnew domains to registered domains, emphasizing the crucial similarity score.\nThe proposed system analyzes semantic and numerical attributes by leveraging a\nnovel combination of Natural Language Processing (NLP) techniques, including a\npretrained CANINE model and Multilayer Perceptron (MLP) models, providing a\nrobust solution for early threat detection. This integrated Pretrained NLP\n(CANINE) + MLP model showcases the outstanding performance, surpassing both\nindividual pretrained NLP models and standalone MLP models. With an F1 score of\n84.86\\% and an accuracy of 84.95\\% on the SecureReg dataset, it effectively\ndetects malicious domain registrations. The findings demonstrate the\neffectiveness of the integrated approach and contribute to the ongoing efforts\nto develop proactive strategies to mitigate the risks associated with illicit\nonline activities through the early identification of suspicious domain\nregistrations.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03196v3",
    "published_date": "2024-01-06 11:43:57 UTC",
    "updated_date": "2024-07-10 11:17:50 UTC"
  },
  {
    "arxiv_id": "2401.03194v1",
    "title": "Learning Persistent Community Structures in Dynamic Networks via Topological Data Analysis",
    "authors": [
      "Dexu Kong",
      "Anping Zhang",
      "Yang Li"
    ],
    "abstract": "Dynamic community detection methods often lack effective mechanisms to ensure\ntemporal consistency, hindering the analysis of network evolution. In this\npaper, we propose a novel deep graph clustering framework with temporal\nconsistency regularization on inter-community structures, inspired by the\nconcept of minimal network topological changes within short intervals.\nSpecifically, to address the representation collapse problem, we first\nintroduce MFC, a matrix factorization-based deep graph clustering algorithm\nthat preserves node embedding. Based on static clustering results, we construct\nprobabilistic community networks and compute their persistence homology, a\nrobust topological measure, to assess structural similarity between them.\nMoreover, a novel neural network regularization TopoReg is introduced to ensure\nthe preservation of topological similarity between inter-community structures\nover time intervals. Our approach enhances temporal consistency and clustering\naccuracy on real-world datasets with both fixed and varying numbers of\ncommunities. It is also a pioneer application of TDA in temporally persistent\ncommunity detection, offering an insightful contribution to field of network\nanalysis. Code and data are available at the public git repository:\nhttps://github.com/kundtx/MFC_TopoReg",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.03194v1",
    "published_date": "2024-01-06 11:29:19 UTC",
    "updated_date": "2024-01-06 11:29:19 UTC"
  },
  {
    "arxiv_id": "2401.03190v1",
    "title": "MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing",
    "authors": [
      "Nianwen Si",
      "Hao Zhang",
      "Weiqiang Zhang"
    ],
    "abstract": "Large language models are known for encoding a vast amount of factual\nknowledge, but they often becomes outdated due to the ever-changing nature of\nexternal information. A promising solution to this challenge is the utilization\nof model editing methods to update the knowledge in an efficient manner.\nHowever, the majority of existing model editing techniques are limited to\nmonolingual frameworks, thus failing to address the crucial issue of\ncross-lingual knowledge synchronization for multilingual models. To tackle this\nproblem, we propose a simple yet effective method that trains multilingual\npatch neuron to store cross-lingual knowledge. It can be easily adapted to\nexisting approaches to enhance their cross-lingual editing capabilities. To\nevaluate our method, we conduct experiments using both the XNLI dataset and a\nself-constructed XFEVER dataset. Experimental results demonstrate that our\nproposed method achieves improved performance in cross-lingual editing tasks\nwithout requiring excessive modifications to the original methodology, thereby\nshowcasing its user-friendly characteristics. Codes will be released soon.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.03190v1",
    "published_date": "2024-01-06 10:40:24 UTC",
    "updated_date": "2024-01-06 10:40:24 UTC"
  },
  {
    "arxiv_id": "2401.03188v2",
    "title": "A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic Artificial Intelligence",
    "authors": [
      "Justus Renkhoff",
      "Ke Feng",
      "Marc Meier-Doernberg",
      "Alvaro Velasquez",
      "Houbing Herbert Song"
    ],
    "abstract": "Neurosymbolic artificial intelligence (AI) is an emerging branch of AI that\ncombines the strengths of symbolic AI and sub-symbolic AI. A major drawback of\nsub-symbolic AI is that it acts as a \"black box\", meaning that predictions are\ndifficult to explain, making the testing & evaluation (T&E) and validation &\nverification (V&V) processes of a system that uses sub-symbolic AI a challenge.\nSince neurosymbolic AI combines the advantages of both symbolic and\nsub-symbolic AI, this survey explores how neurosymbolic applications can ease\nthe V&V process. This survey considers two taxonomies of neurosymbolic AI,\nevaluates them, and analyzes which algorithms are commonly used as the symbolic\nand sub-symbolic components in current applications. Additionally, an overview\nof current techniques for the T&E and V&V processes of these components is\nprovided. Furthermore, it is investigated how the symbolic part is used for T&E\nand V&V purposes in current neurosymbolic applications. Our research shows that\nneurosymbolic AI as great potential to ease the T&E and V&V processes of\nsub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,\nthe applicability of current T&E and V&V methods to neurosymbolic AI is\nassessed, and how different neurosymbolic architectures can impact these\nmethods is explored. It is found that current T&E and V&V techniques are partly\nsufficient to test, evaluate, verify, or validate the symbolic and sub-symbolic\npart of neurosymbolic applications independently, while some of them use\napproaches where current T&E and V&V methods are not applicable by default, and\nadjustments or even new approaches are needed. Our research shows that there is\ngreat potential in using symbolic AI to test, evaluate, verify, or validate the\npredictions of a sub-symbolic model, making neurosymbolic AI an interesting\nresearch direction for safe, secure, and trustworthy AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.03188v2",
    "published_date": "2024-01-06 10:28:52 UTC",
    "updated_date": "2024-01-10 16:54:11 UTC"
  },
  {
    "arxiv_id": "2401.03175v1",
    "title": "Part-of-Speech Tagger for Bodo Language using Deep Learning approach",
    "authors": [
      "Dhrubajyoti Pathak",
      "Sanjib Narzary",
      "Sukumar Nandi",
      "Bidisha Som"
    ],
    "abstract": "Language Processing systems such as Part-of-speech tagging, Named entity\nrecognition, Machine translation, Speech recognition, and Language modeling\n(LM) are well-studied in high-resource languages. Nevertheless, research on\nthese systems for several low-resource languages, including Bodo, Mizo,\nNagamese, and others, is either yet to commence or is in its nascent stages.\nLanguage model plays a vital role in the downstream tasks of modern NLP.\nExtensive studies are carried out on LMs for high-resource languages.\nNevertheless, languages such as Bodo, Rabha, and Mising continue to lack\ncoverage. In this study, we first present BodoBERT, a language model for the\nBodo language. To the best of our knowledge, this work is the first such effort\nto develop a language model for Bodo. Secondly, we present an ensemble DL-based\nPOS tagging model for Bodo. The POS tagging model is based on combinations of\nBiLSTM with CRF and stacked embedding of BodoBERT with BytePairEmbeddings. We\ncover several language models in the experiment to see how well they work in\nPOS tagging tasks. The best-performing model achieves an F1 score of 0.8041. A\ncomparative experiment was also conducted on Assamese POS taggers, considering\nthat the language is spoken in the same region as Bodo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Natural Language Engineering",
    "pdf_url": "http://arxiv.org/pdf/2401.03175v1",
    "published_date": "2024-01-06 09:37:56 UTC",
    "updated_date": "2024-01-06 09:37:56 UTC"
  },
  {
    "arxiv_id": "2401.03171v1",
    "title": "Exploration of Adolescent Depression Risk Prediction Based on Census Surveys and General Life Issues",
    "authors": [
      "Qiang Li",
      "Yufeng Wu",
      "Zhan Xu",
      "Hefeng Zhou"
    ],
    "abstract": "In contemporary society, the escalating pressures of life and work have\npropelled psychological disorders to the forefront of modern health concerns,\nan issue that has been further accentuated by the COVID-19 pandemic. The\nprevalence of depression among adolescents is steadily increasing, and\ntraditional diagnostic methods, which rely on scales or interviews, prove\nparticularly inadequate for detecting depression in young people. Addressing\nthese challenges, numerous AI-based methods for assisting in the diagnosis of\nmental health issues have emerged. However, most of these methods center around\nfundamental issues with scales or use multimodal approaches like facial\nexpression recognition. Diagnosis of depression risk based on everyday habits\nand behaviors has been limited to small-scale qualitative studies. Our research\nleverages adolescent census data to predict depression risk, focusing on\nchildren's experiences with depression and their daily life situations. We\nintroduced a method for managing severely imbalanced high-dimensional data and\nan adaptive predictive approach tailored to data structure characteristics.\nFurthermore, we proposed a cloud-based architecture for automatic online\nlearning and data updates. This study utilized publicly available NSCH youth\ncensus data from 2020 to 2022, encompassing nearly 150,000 data entries. We\nconducted basic data analyses and predictive experiments, demonstrating\nsignificant performance improvements over standard machine learning and deep\nlearning algorithms. This affirmed our data processing method's broad\napplicability in handling imbalanced medical data. Diverging from typical\npredictive method research, our study presents a comprehensive architectural\nsolution, considering a wider array of user needs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03171v1",
    "published_date": "2024-01-06 09:14:25 UTC",
    "updated_date": "2024-01-06 09:14:25 UTC"
  },
  {
    "arxiv_id": "2401.06783v1",
    "title": "MultiSiam: A Multiple Input Siamese Network For Social Media Text Classification And Duplicate Text Detection",
    "authors": [
      "Sudhanshu Bhoi",
      "Swapnil Markhedkar",
      "Shruti Phadke",
      "Prashant Agrawal"
    ],
    "abstract": "Social media accounts post increasingly similar content, creating a chaotic\nexperience across platforms, which makes accessing desired information\ndifficult. These posts can be organized by categorizing and grouping duplicates\nacross social handles and accounts. There can be more than one duplicate of a\npost, however, a conventional Siamese neural network only considers a pair of\ninputs for duplicate text detection. In this paper, we first propose a\nmultiple-input Siamese network, MultiSiam. This condensed network is then used\nto propose another model, SMCD (Social Media Classification and Duplication\nModel) to perform both duplicate text grouping and categorization. The\nMultiSiam network, just like the Siamese, can be used in multiple applications\nby changing the sub-network appropriately.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06783v1",
    "published_date": "2024-01-06 09:13:34 UTC",
    "updated_date": "2024-01-06 09:13:34 UTC"
  },
  {
    "arxiv_id": "2401.03167v1",
    "title": "PosDiffNet: Positional Neural Diffusion for Point Cloud Registration in a Large Field of View with Perturbations",
    "authors": [
      "Rui She",
      "Sijie Wang",
      "Qiyu Kang",
      "Kai Zhao",
      "Yang Song",
      "Wee Peng Tay",
      "Tianyu Geng",
      "Xingchao Jian"
    ],
    "abstract": "Point cloud registration is a crucial technique in 3D computer vision with a\nwide range of applications. However, this task can be challenging, particularly\nin large fields of view with dynamic objects, environmental noise, or other\nperturbations. To address this challenge, we propose a model called PosDiffNet.\nOur approach performs hierarchical registration based on window-level,\npatch-level, and point-level correspondence. We leverage a graph neural partial\ndifferential equation (PDE) based on Beltrami flow to obtain high-dimensional\nfeatures and position embeddings for point clouds. We incorporate position\nembeddings into a Transformer module based on a neural ordinary differential\nequation (ODE) to efficiently represent patches within points. We employ the\nmulti-level correspondence derived from the high feature similarity scores to\nfacilitate alignment between point clouds. Subsequently, we use registration\nmethods such as SVD-based algorithms to predict the transformation using\ncorresponding point pairs. We evaluate PosDiffNet on several 3D point cloud\ndatasets, verifying that it achieves state-of-the-art (SOTA) performance for\npoint cloud registration in large fields of view with perturbations. The\nimplementation code of experiments is available at\nhttps://github.com/AI-IT-AVs/PosDiffNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03167v1",
    "published_date": "2024-01-06 08:58:15 UTC",
    "updated_date": "2024-01-06 08:58:15 UTC"
  },
  {
    "arxiv_id": "2401.03160v5",
    "title": "HAIM-DRL: Enhanced Human-in-the-loop Reinforcement Learning for Safe and Efficient Autonomous Driving",
    "authors": [
      "Zilin Huang",
      "Zihao Sheng",
      "Chengyuan Ma",
      "Sikai Chen"
    ],
    "abstract": "Despite significant progress in autonomous vehicles (AVs), the development of\ndriving policies that ensure both the safety of AVs and traffic flow efficiency\nhas not yet been fully explored. In this paper, we propose an enhanced\nhuman-in-the-loop reinforcement learning method, termed the Human as AI\nmentor-based deep reinforcement learning (HAIM-DRL) framework, which\nfacilitates safe and efficient autonomous driving in mixed traffic platoon.\nDrawing inspiration from the human learning process, we first introduce an\ninnovative learning paradigm that effectively injects human intelligence into\nAI, termed Human as AI mentor (HAIM). In this paradigm, the human expert serves\nas a mentor to the AI agent. While allowing the agent to sufficiently explore\nuncertain environments, the human expert can take control in dangerous\nsituations and demonstrate correct actions to avoid potential accidents. On the\nother hand, the agent could be guided to minimize traffic flow disturbance,\nthereby optimizing traffic flow efficiency. In detail, HAIM-DRL leverages data\ncollected from free exploration and partial human demonstrations as its two\ntraining sources. Remarkably, we circumvent the intricate process of manually\ndesigning reward functions; instead, we directly derive proxy state-action\nvalues from partial human demonstrations to guide the agents' policy learning.\nAdditionally, we employ a minimal intervention technique to reduce the human\nmentor's cognitive load. Comparative results show that HAIM-DRL outperforms\ntraditional methods in driving safety, sampling efficiency, mitigation of\ntraffic flow disturbance, and generalizability to unseen traffic scenarios. The\ncode and demo videos for this paper can be accessed at:\nhttps://zilin-huang.github.io/HAIM-DRL-website/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Communications in Transportation Research",
    "pdf_url": "http://arxiv.org/pdf/2401.03160v5",
    "published_date": "2024-01-06 08:30:14 UTC",
    "updated_date": "2024-06-14 23:00:31 UTC"
  },
  {
    "arxiv_id": "2401.03158v2",
    "title": "CoT-Driven Framework for Short Text Classification: Enhancing and Transferring Capabilities from Large to Smaller Model",
    "authors": [
      "Hui Wu",
      "Yuanben Zhang",
      "Zhonghe Han",
      "Yingyan Hou",
      "Lei Wang",
      "Siye Liu",
      "Qihang Gong",
      "Yunping Ge"
    ],
    "abstract": "Short Text Classification (STC) is crucial for processing and understanding\nthe brief but substantial content prevalent on contemporary digital platforms.\nThe STC encounters difficulties in grasping the semantic and syntactic\nintricacies, an issue that is apparent in traditional pre-trained language\nmodels. Although Graph Convolutional Networks enhance performance by\nintegrating external knowledge bases, these methods are limited by the quality\nand extent of the knowledge applied. Recently, the emergence of Large Language\nModels (LLMs) and Chain-of-Thought (CoT) has significantly improved the\nperformance of complex reasoning tasks. However, some studies have highlighted\nthe limitations of their application in fundamental NLP tasks. Consequently,\nthis study first employs CoT to investigate and enhance the capabilities of\nLLMs in STC tasks. We propose the Syntactic and Semantic Enrichment CoT\n(SSE-CoT) method, effectively decomposing the STC tasks into four distinct\nsteps: (i) essential concept identification, (ii) common-sense knowledge\nretrieval, (iii) text rewriting, and (iv) classification. Furthermore,\nrecognizing resource constraints in sectors like finance and healthcare, we\nthen introduce the CoT-Driven Multi-Task Learning (CDMT) framework to extend\nthese capabilities to smaller models. This framework begins by extracting\nrationales from LLMs and subsequently fine-tunes smaller models to optimize\ntheir performance. Extensive experimentation across six short-text benchmarks\nvalidated the efficacy of the proposed methods. In particular, SSE-CoT achieved\nstate-of-the-art performance with substantial improvements on all datasets,\nparticularly on the Ohsumed and TagMyNews datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Knowledge-Based Systems",
    "pdf_url": "http://arxiv.org/pdf/2401.03158v2",
    "published_date": "2024-01-06 08:28:20 UTC",
    "updated_date": "2025-01-19 12:56:59 UTC"
  },
  {
    "arxiv_id": "2401.03154v2",
    "title": "Decentralized Multi-Agent Active Search and Tracking when Targets Outnumber Agents",
    "authors": [
      "Arundhati Banerjee",
      "Jeff Schneider"
    ],
    "abstract": "Multi-agent multi-target tracking has a wide range of applications, including\nwildlife patrolling, security surveillance or environment monitoring. Such\nalgorithms often make restrictive assumptions: the number of targets and/or\ntheir initial locations may be assumed known, or agents may be pre-assigned to\nmonitor disjoint partitions of the environment, reducing the burden of\nexploration. This also limits applicability when there are fewer agents than\ntargets, since agents are unable to continuously follow the targets in their\nfields of view. Multi-agent tracking algorithms additionally assume inter-agent\nsynchronization of observations, or the presence of a central controller to\ncoordinate joint actions. Instead, we focus on the setting of decentralized\nmulti-agent, multi-target, simultaneous active search-and-tracking with\nasynchronous inter-agent communication. Our proposed algorithm DecSTER uses a\nsequential monte carlo implementation of the probability hypothesis density\nfilter for posterior inference combined with Thompson sampling for\ndecentralized multi-agent decision making. We compare different action\nselection policies, focusing on scenarios where targets outnumber agents. In\nsimulation, we demonstrate that DecSTER is robust to unreliable inter-agent\ncommunication and outperforms information-greedy baselines in terms of the\nOptimal Sub-Pattern Assignment (OSPA) metric for different numbers of targets\nand varying teamsizes.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "I.2.9; I.2.11"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2401.03154v2",
    "published_date": "2024-01-06 08:10:58 UTC",
    "updated_date": "2024-01-09 23:25:39 UTC"
  },
  {
    "arxiv_id": "2402.01647v1",
    "title": "Build Your Own Robot Friend: An Open-Source Learning Module for Accessible and Engaging AI Education",
    "authors": [
      "Zhonghao Shi",
      "Allison O'Connell",
      "Zongjian Li",
      "Siqi Liu",
      "Jennifer Ayissi",
      "Guy Hoffman",
      "Mohammad Soleymani",
      "Maja J. Matarić"
    ],
    "abstract": "As artificial intelligence (AI) is playing an increasingly important role in\nour society and global economy, AI education and literacy have become necessary\ncomponents in college and K-12 education to prepare students for an AI-powered\nsociety. However, current AI curricula have not yet been made accessible and\nengaging enough for students and schools from all socio-economic backgrounds\nwith different educational goals. In this work, we developed an open-source\nlearning module for college and high school students, which allows students to\nbuild their own robot companion from the ground up. This open platform can be\nused to provide hands-on experience and introductory knowledge about various\naspects of AI, including robotics, machine learning (ML), software engineering,\nand mechanical engineering. Because of the social and personal nature of a\nsocially assistive robot companion, this module also puts a special emphasis on\nhuman-centered AI, enabling students to develop a better understanding of\nhuman-AI interaction and AI ethics through hands-on learning activities. With\nopen-source documentation, assembling manuals and affordable materials,\nstudents from different socio-economic backgrounds can personalize their\nlearning experience based on their individual educational goals. To evaluate\nthe student-perceived quality of our module, we conducted a usability testing\nworkshop with 15 college students recruited from a minority-serving\ninstitution. Our results indicate that our AI module is effective,\neasy-to-follow, and engaging, and it increases student interest in studying\nAI/ML and robotics in the future. We hope that this work will contribute toward\naccessible and engaging AI education in human-AI interaction for college and\nhigh school students.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted to the Proceedings of the AAAI Conference on Artificial\n  Intelligence (2024)",
    "pdf_url": "http://arxiv.org/pdf/2402.01647v1",
    "published_date": "2024-01-06 08:03:08 UTC",
    "updated_date": "2024-01-06 08:03:08 UTC"
  },
  {
    "arxiv_id": "2401.03138v1",
    "title": "TelTrans: Applying Multi-Type Telecom Data to Transportation Evaluation and Prediction via Multifaceted Graph Modeling",
    "authors": [
      "ChungYi Lin",
      "Shen-Lung Tung",
      "Hung-Ting Su",
      "Winston H. Hsu"
    ],
    "abstract": "To address the limitations of traffic prediction from location-bound\ndetectors, we present Geographical Cellular Traffic (GCT) flow, a novel data\nsource that leverages the extensive coverage of cellular traffic to capture\nmobility patterns. Our extensive analysis validates its potential for\ntransportation. Focusing on vehicle-related GCT flow prediction, we propose a\ngraph neural network that integrates multivariate, temporal, and spatial facets\nfor improved accuracy. Experiments reveal our model's superiority over\nbaselines, especially in long-term predictions. We also highlight the potential\nfor GCT flow integration into transportation systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 7 figures, 4 tables. Accepted by AAAI-24-IAAI, to appear",
    "pdf_url": "http://arxiv.org/pdf/2401.03138v1",
    "published_date": "2024-01-06 06:44:06 UTC",
    "updated_date": "2024-01-06 06:44:06 UTC"
  },
  {
    "arxiv_id": "2401.03137v1",
    "title": "SPQR: Controlling Q-ensemble Independence with Spiked Random Model for Reinforcement Learning",
    "authors": [
      "Dohyeok Lee",
      "Seungyub Han",
      "Taehyun Cho",
      "Jungwoo Lee"
    ],
    "abstract": "Alleviating overestimation bias is a critical challenge for deep\nreinforcement learning to achieve successful performance on more complex tasks\nor offline datasets containing out-of-distribution data. In order to overcome\noverestimation bias, ensemble methods for Q-learning have been investigated to\nexploit the diversity of multiple Q-functions. Since network initialization has\nbeen the predominant approach to promote diversity in Q-functions,\nheuristically designed diversity injection methods have been studied in the\nliterature. However, previous studies have not attempted to approach guaranteed\nindependence over an ensemble from a theoretical perspective. By introducing a\nnovel regularization loss for Q-ensemble independence based on random matrix\ntheory, we propose spiked Wishart Q-ensemble independence regularization (SPQR)\nfor reinforcement learning. Specifically, we modify the intractable hypothesis\ntesting criterion for the Q-ensemble independence into a tractable KL\ndivergence between the spectral distribution of the Q-ensemble and the target\nWigner's semicircle distribution. We implement SPQR in several online and\noffline ensemble Q-learning algorithms. In the experiments, SPQR outperforms\nthe baseline algorithms in both online and offline RL benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at NeurIPS 23",
    "pdf_url": "http://arxiv.org/pdf/2401.03137v1",
    "published_date": "2024-01-06 06:39:06 UTC",
    "updated_date": "2024-01-06 06:39:06 UTC"
  },
  {
    "arxiv_id": "2401.03134v1",
    "title": "TimeGraphs: Graph-based Temporal Reasoning",
    "authors": [
      "Paridhi Maheshwari",
      "Hongyu Ren",
      "Yanan Wang",
      "Rok Sosic",
      "Jure Leskovec"
    ],
    "abstract": "Many real-world systems exhibit temporal, dynamic behaviors, which are\ncaptured as time series of complex agent interactions. To perform temporal\nreasoning, current methods primarily encode temporal dynamics through simple\nsequence-based models. However, in general these models fail to efficiently\ncapture the full spectrum of rich dynamics in the input, since the dynamics is\nnot uniformly distributed. In particular, relevant information might be harder\nto extract and computing power is wasted for processing all individual\ntimesteps, even if they contain no significant changes or no new information.\nHere we propose TimeGraphs, a novel approach that characterizes dynamic\ninteractions as a hierarchical temporal graph, diverging from traditional\nsequential representations. Our approach models the interactions using a\ncompact graph-based representation, enabling adaptive reasoning across diverse\ntime scales. Adopting a self-supervised method, TimeGraphs constructs a\nmulti-level event hierarchy from a temporal input, which is then used to\nefficiently reason about the unevenly distributed dynamics. This construction\nprocess is scalable and incremental to accommodate streaming data. We evaluate\nTimeGraphs on multiple datasets with complex, dynamic agent interactions,\nincluding a football simulator, the Resistance game, and the MOMA human\nactivity dataset. The results demonstrate both robustness and efficiency of\nTimeGraphs on a range of temporal reasoning tasks. Our approach obtains\nstate-of-the-art performance and leads to a performance increase of up to 12.2%\non event prediction and recognition tasks over current approaches. Our\nexperiments further demonstrate a wide array of capabilities including\nzero-shot generalization, robustness in case of data sparsity, and adaptability\nto streaming data flow.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03134v1",
    "published_date": "2024-01-06 06:26:49 UTC",
    "updated_date": "2024-01-06 06:26:49 UTC"
  },
  {
    "arxiv_id": "2401.05434v1",
    "title": "ECGformer: Leveraging transformer for ECG heartbeat arrhythmia classification",
    "authors": [
      "Taymaz Akan",
      "Sait Alp",
      "Mohammad Alfrad Nobel Bhuiyan"
    ],
    "abstract": "An arrhythmia, also known as a dysrhythmia, refers to an irregular heartbeat.\nThere are various types of arrhythmias that can originate from different areas\nof the heart, resulting in either a rapid, slow, or irregular heartbeat. An\nelectrocardiogram (ECG) is a vital diagnostic tool used to detect heart\nirregularities and abnormalities, allowing experts to analyze the heart's\nelectrical signals to identify intricate patterns and deviations from the norm.\nOver the past few decades, numerous studies have been conducted to develop\nautomated methods for classifying heartbeats based on ECG data. In recent\nyears, deep learning has demonstrated exceptional capabilities in tackling\nvarious medical challenges, particularly with transformers as a model\narchitecture for sequence processing. By leveraging the transformers, we\ndeveloped the ECGformer model for the classification of various arrhythmias\npresent in electrocardiogram data. We assessed the suggested approach using the\nMIT-BIH and PTB datasets. ECG heartbeat arrhythmia classification results show\nthat the proposed method is highly effective.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05434v1",
    "published_date": "2024-01-06 06:14:48 UTC",
    "updated_date": "2024-01-06 06:14:48 UTC"
  },
  {
    "arxiv_id": "2401.03131v1",
    "title": "A Physics-guided Generative AI Toolkit for Geophysical Monitoring",
    "authors": [
      "Junhuan Yang",
      "Hanchen Wang",
      "Yi Sheng",
      "Youzuo Lin",
      "Lei Yang"
    ],
    "abstract": "Full-waveform inversion (FWI) plays a vital role in geoscience to explore the\nsubsurface. It utilizes the seismic wave to image the subsurface velocity map.\nAs the machine learning (ML) technique evolves, the data-driven approaches\nusing ML for FWI tasks have emerged, offering enhanced accuracy and reduced\ncomputational cost compared to traditional physics-based methods. However, a\ncommon challenge in geoscience, the unprivileged data, severely limits ML\neffectiveness. The issue becomes even worse during model pruning, a step\nessential in geoscience due to environmental complexities. To tackle this, we\nintroduce the EdGeo toolkit, which employs a diffusion-based model guided by\nphysics principles to generate high-fidelity velocity maps. The toolkit uses\nthe acoustic wave equation to generate corresponding seismic waveform data,\nfacilitating the fine-tuning of pruned ML models. Our results demonstrate\nsignificant improvements in SSIM scores and reduction in both MAE and MSE\nacross various pruning ratios. Notably, the ML model fine-tuned using data\ngenerated by EdGeo yields superior quality of velocity maps, especially in\nrepresenting unprivileged features, outperforming other existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.03131v1",
    "published_date": "2024-01-06 06:09:05 UTC",
    "updated_date": "2024-01-06 06:09:05 UTC"
  },
  {
    "arxiv_id": "2401.05433v1",
    "title": "Enhancing Essay Scoring with Adversarial Weights Perturbation and Metric-specific AttentionPooling",
    "authors": [
      "Jiaxin Huang",
      "Xinyu Zhao",
      "Chang Che",
      "Qunwei Lin",
      "Bo Liu"
    ],
    "abstract": "The objective of this study is to improve automated feedback tools designed\nfor English Language Learners (ELLs) through the utilization of data science\ntechniques encompassing machine learning, natural language processing, and\neducational data analytics. Automated essay scoring (AES) research has made\nstrides in evaluating written essays, but it often overlooks the specific needs\nof English Language Learners (ELLs) in language development. This study\nexplores the application of BERT-related techniques to enhance the assessment\nof ELLs' writing proficiency within AES.\n  To address the specific needs of ELLs, we propose the use of DeBERTa, a\nstate-of-the-art neural language model, for improving automated feedback tools.\nDeBERTa, pretrained on large text corpora using self-supervised learning,\nlearns universal language representations adaptable to various natural language\nunderstanding tasks. The model incorporates several innovative techniques,\nincluding adversarial training through Adversarial Weights Perturbation (AWP)\nand Metric-specific AttentionPooling (6 kinds of AP) for each label in the\ncompetition.\n  The primary focus of this research is to investigate the impact of\nhyperparameters, particularly the adversarial learning rate, on the performance\nof the model. By fine-tuning the hyperparameter tuning process, including the\ninfluence of 6AP and AWP, the resulting models can provide more accurate\nevaluations of language proficiency and support tailored learning tasks for\nELLs. This work has the potential to significantly benefit ELLs by improving\ntheir English language proficiency and facilitating their educational journey.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This article was accepted by 2023 International Conference on\n  Information Network and Computer Communications(INCC)",
    "pdf_url": "http://arxiv.org/pdf/2401.05433v1",
    "published_date": "2024-01-06 06:05:12 UTC",
    "updated_date": "2024-01-06 06:05:12 UTC"
  },
  {
    "arxiv_id": "2401.03128v1",
    "title": "Manifold-based Shapley for SAR Recognization Network Explanation",
    "authors": [
      "Xuran Hu",
      "Mingzhe Zhu",
      "Yuanjing Liu",
      "Zhenpeng Feng",
      "LJubisa Stankovic"
    ],
    "abstract": "Explainable artificial intelligence (XAI) holds immense significance in\nenhancing the deep neural network's transparency and credibility, particularly\nin some risky and high-cost scenarios, like synthetic aperture radar (SAR).\nShapley is a game-based explanation technique with robust mathematical\nfoundations. However, Shapley assumes that model's features are independent,\nrendering Shapley explanation invalid for high dimensional models. This study\nintroduces a manifold-based Shapley method by projecting high-dimensional\nfeatures into low-dimensional manifold features and subsequently obtaining\nFusion-Shap, which aims at (1) addressing the issue of erroneous explanations\nencountered by traditional Shap; (2) resolving the challenge of\ninterpretability that traditional Shap faces in complex scenarios.",
    "categories": [
      "cs.AI",
      "H.1.m"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.03128v1",
    "published_date": "2024-01-06 05:26:20 UTC",
    "updated_date": "2024-01-06 05:26:20 UTC"
  },
  {
    "arxiv_id": "2401.08438v2",
    "title": "CogGPT: Unleashing the Power of Cognitive Dynamics on Large Language Models",
    "authors": [
      "Yaojia Lv",
      "Haojie Pan",
      "Zekun Wang",
      "Jiafeng Liang",
      "Yuanxing Liu",
      "Ruiji Fu",
      "Ming Liu",
      "Zhongyuan Wang",
      "Bing Qin"
    ],
    "abstract": "Cognitive dynamics are pivotal to advance human understanding of the world.\nRecent advancements in large language models (LLMs) reveal their potential for\ncognitive simulation. However, these LLM-based cognitive studies primarily\nfocus on static modeling, overlooking the dynamic nature of cognition. To\nbridge this gap, we propose the concept of the cognitive dynamics of LLMs and\npresent a corresponding task with the inspiration of longitudinal studies.\nTowards the task, we develop CogBench, a novel benchmark to assess the\ncognitive dynamics of LLMs and validate it through participant surveys. We also\ndesign two evaluation metrics for CogBench, including Authenticity and\nRationality. Recognizing the inherent static nature of LLMs, we introduce\nCogGPT for the task, which features an innovative iterative cognitive mechanism\naimed at enhancing lifelong cognitive dynamics. Empirical results demonstrate\nthe superiority of CogGPT over existing methods, particularly in its ability to\nfacilitate role-specific cognitive dynamics under continuous information flows.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2401.08438v2",
    "published_date": "2024-01-06 03:59:59 UTC",
    "updated_date": "2024-09-24 07:41:19 UTC"
  },
  {
    "arxiv_id": "2401.05432v1",
    "title": "TEN-GUARD: Tensor Decomposition for Backdoor Attack Detection in Deep Neural Networks",
    "authors": [
      "Khondoker Murad Hossain",
      "Tim Oates"
    ],
    "abstract": "As deep neural networks and the datasets used to train them get larger, the\ndefault approach to integrating them into research and commercial projects is\nto download a pre-trained model and fine tune it. But these models can have\nuncertain provenance, opening up the possibility that they embed hidden\nmalicious behavior such as trojans or backdoors, where small changes to an\ninput (triggers) can cause the model to produce incorrect outputs (e.g., to\nmisclassify). This paper introduces a novel approach to backdoor detection that\nuses two tensor decomposition methods applied to network activations. This has\na number of advantages relative to existing detection methods, including the\nability to analyze multiple models at the same time, working across a wide\nvariety of network architectures, making no assumptions about the nature of\ntriggers used to alter network behavior, and being computationally efficient.\nWe provide a detailed description of the detection pipeline along with results\non models trained on the MNIST digit dataset, CIFAR-10 dataset, and two\ndifficult datasets from NIST's TrojAI competition. These results show that our\nmethod detects backdoored networks more accurately and efficiently than current\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05432v1",
    "published_date": "2024-01-06 03:08:28 UTC",
    "updated_date": "2024-01-06 03:08:28 UTC"
  },
  {
    "arxiv_id": "2401.06782v1",
    "title": "Semantic Similarity Matching for Patent Documents Using Ensemble BERT-related Model and Novel Text Processing Method",
    "authors": [
      "Liqiang Yu",
      "Bo Liu",
      "Qunwei Lin",
      "Xinyu Zhao",
      "Chang Che"
    ],
    "abstract": "In the realm of patent document analysis, assessing semantic similarity\nbetween phrases presents a significant challenge, notably amplifying the\ninherent complexities of Cooperative Patent Classification (CPC) research.\nFirstly, this study addresses these challenges, recognizing early CPC work\nwhile acknowledging past struggles with language barriers and document\nintricacy. Secondly, it underscores the persisting difficulties of CPC\nresearch.\n  To overcome these challenges and bolster the CPC system, This paper presents\ntwo key innovations. Firstly, it introduces an ensemble approach that\nincorporates four BERT-related models, enhancing semantic similarity accuracy\nthrough weighted averaging. Secondly, a novel text preprocessing method\ntailored for patent documents is introduced, featuring a distinctive input\nstructure with token scoring that aids in capturing semantic relationships\nduring CPC context training, utilizing BCELoss. Our experimental findings\nconclusively establish the effectiveness of both our Ensemble Model and novel\ntext processing strategies when deployed on the U.S. Patent Phrase to Phrase\nMatching dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "It accepted by The 6th International Conference on Machine Learning\n  and Machine Intelligence (MLMI 2023)",
    "pdf_url": "http://arxiv.org/pdf/2401.06782v1",
    "published_date": "2024-01-06 02:35:49 UTC",
    "updated_date": "2024-01-06 02:35:49 UTC"
  },
  {
    "arxiv_id": "2401.05431v1",
    "title": "TRLS: A Time Series Representation Learning Framework via Spectrogram for Medical Signal Processing",
    "authors": [
      "Luyuan Xie",
      "Cong Li",
      "Xin Zhang",
      "Shengfang Zhai",
      "Yuejian Fang",
      "Qingni Shen",
      "Zhonghai Wu"
    ],
    "abstract": "Representation learning frameworks in unlabeled time series have been\nproposed for medical signal processing. Despite the numerous excellent\nprogresses have been made in previous works, we observe the representation\nextracted for the time series still does not generalize well. In this paper, we\npresent a Time series (medical signal) Representation Learning framework via\nSpectrogram (TRLS) to get more informative representations. We transform the\ninput time-domain medical signals into spectrograms and design a time-frequency\nencoder named Time Frequency RNN (TFRNN) to capture more robust multi-scale\nrepresentations from the augmented spectrograms. Our TRLS takes spectrogram as\ninput with two types of different data augmentations and maximizes the\nsimilarity between positive ones, which effectively circumvents the problem of\ndesigning negative samples. Our evaluation of four real-world medical signal\ndatasets focusing on medical signal classification shows that TRLS is superior\nto the existing frameworks.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "This paper is accept by ICASSP 2024. This is a more detailed version",
    "pdf_url": "http://arxiv.org/pdf/2401.05431v1",
    "published_date": "2024-01-06 02:26:02 UTC",
    "updated_date": "2024-01-06 02:26:02 UTC"
  },
  {
    "arxiv_id": "2401.04130v3",
    "title": "Plug-and-Play Transformer Modules for Test-Time Adaptation",
    "authors": [
      "Xiangyu Chang",
      "Sk Miraj Ahmed",
      "Srikanth V. Krishnamurthy",
      "Basak Guler",
      "Ananthram Swami",
      "Samet Oymak",
      "Amit K. Roy-Chowdhury"
    ],
    "abstract": "Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual\nPrompt Tuning (VPT) have found success in enabling adaptation to new domains by\ntuning small modules within a transformer model. However, the number of domains\nencountered during test time can be very large, and the data is usually\nunlabeled. Thus, adaptation to new domains is challenging; it is also\nimpractical to generate customized tuned modules for each such domain. Toward\naddressing these challenges, this work introduces PLUTO: a Plug-and-pLay\nmodUlar Test-time domain adaptatiOn strategy. We pre-train a large set of\nmodules, each specialized for different source domains, effectively creating a\n``module store''. Given a target domain with few-shot unlabeled data, we\nintroduce an unsupervised test-time adaptation (TTA) method to (1) select a\nsparse subset of relevant modules from this store and (2) create a weighted\ncombination of selected modules without tuning their weights. This\nplug-and-play nature enables us to harness multiple most-relevant source\ndomains in a single inference call. Comprehensive evaluations demonstrate that\nPLUTO uniformly outperforms alternative TTA methods and that selecting $\\leq$5\nmodules suffice to extract most of the benefit. At a high level, our method\nequips pre-trained transformers with the capability to dynamically adapt to new\ndomains, motivating a new paradigm for efficient and scalable domain\nadaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.04130v3",
    "published_date": "2024-01-06 00:24:50 UTC",
    "updated_date": "2024-02-08 22:13:45 UTC"
  }
]