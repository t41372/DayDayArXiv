{
  "date": "2024-05-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-12 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，特别是大型语言模型 (LLMs) 在教育、机器人和药物开发中的应用，突出如 GPT-4V 在视觉任务的创新，以及知名学者如 OpenAI 相关工作的影响力，同时涉及天气预报优化和公平性研究的突破性贡献。\n\n### 重点论文讨论\n我们先聚焦于 AI 和 LLMs 相关的论文，这些领域有高话题度和实际影响，然后依次聊及机器人、医疗和其他主题。以下挑选并简要概述最具代表性的论文，优先突出核心贡献和发现。\n\n**1. CaFA: Global Weather Forecasting with Factorized Attention on Sphere（CaFA: 基于球面因子化注意力机制的全球天气预报）**  \n这篇论文提出了一种基于 Transformer 的天气预报模型，使用因子化注意力机制来降低计算复杂度，实现与现有数据驱动模型相当的准确性（1.5°分辨率下0-7天预测），显著提高了效率和准确性-效率 Pareto 前沿的优化。\n\n**2. Intrinsic Fairness-Accuracy Tradeoffs under Equalized Odds（在等化机会下固有公平性-准确性权衡）**  \n作者 Meiyu Zhong 和 Ravi Tandon 探讨了机器学习公平性，提出新的准确性上界函数，依赖数据统计，实验验证在 COMPAS、Adult 和 Law School 数据集上，揭示了低偏差条件下准确性的根本限制，帮助理解公平性在实际应用中的权衡。\n\n**3. AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch（AnyRotate: 基于模拟到真实触觉的引力不变手持物体旋转）**  \n这篇论文开发了 AnyRotate 系统，通过密集触觉策略训练，实现机器人手部多轴物体旋转，实验显示其能检测不稳定抓取并提升鲁棒性，项目网站提供更多细节，展示了触觉感知在机器人灵巧操作中的潜力。\n\n**4. PHUDGE: Phi-3 as Scalable Judge（PHUDGE: Phi-3 作为可扩展评估器）**  \n作者微调了 Phi-3 模型，在反馈测试和偏好任务中超越现有模型，展示了小语言模型在高效评估中的优势，并引入 Wasserstein 距离作为损失函数，改进训练稳定性，强调 AI 在生产级系统的成本效益。\n\n**5. HGTDR: Advancing Drug Repurposing with Heterogeneous Graph Transformers（HGTDR: 使用异构图 Transformer 推进药物再利用）**  \n这篇论文提出 HGTDR 框架，通过异构知识图和图 Transformer 网络进行药物再利用，实验显示其与现有方法相当，并验证了前10个建议的实际效果，解决了传统方法的数据处理局限，提升了端到端功能。\n\n**6. Understanding Sarcoidosis Using Large Language Models and Social Media Data（使用大型语言模型和社会媒体数据理解结节病）**  \n作者使用 LLM 分析 Reddit 上结节病讨论，识别症状（如疲劳）、药物效果（Infliximab 最有效）和患者亚群，揭示年龄和性别对预后的影响，这是 LLM 在医疗社交数据分析的首次应用，提供数据驱动的个性化治疗见解。\n\n**7. MathDivide: Improved mathematical reasoning by large language models（MathDivide: 通过大型语言模型改进数学推理）**  \n这篇论文引入 MathDivide 提示技术，将数学问题分解为子问题并用 Python 代码求解，实验在 GSM8K 数据集上超越 Math-prompter，提升了 LLM 的数学推理准确性。\n\n**8. From Probability to Counterfactuals: the Increasing Complexity of Satisfiability in Pearl's Causal Hierarchy（从概率到反事实：Pearl 因果层次中可满足性的递增复杂性）**  \n作者证明了 Pearl 因果层次中概率、干预和反事实推理的可满足性问题复杂度从 NP^PP 到 NEXP 递增，这是首次展示严格递增复杂性，提供理论基础支持因果推理的计算分析。\n\n**9. DuetRAG: Collaborative Retrieval-Augmented Generation（DuetRAG: 协作检索增强生成）**  \n这篇论文提出 DuetRAG 框架，结合领域微调和 RAG 模型改善知识检索，提升多文档摘要生成质量，在 HotPot QA 上与人类专家相当，展示了协作 AI 在复杂查询中的潜力。\n\n其他论文较多，我们快速掠过一些次要或领域特定的：  \n- **DiffGen（机器人演示生成 via 可微物理模拟）**：使用 LLM 和可微模拟生成机器人演示，高效无需人工标注。  \n- **WeedScout（实时杂草检测）**：基于 YOLO 模型的农业应用，实现黑麦草检测和映射。  \n- **TKAN（Temporal Kolmogorov-Arnold Networks）**：提出时间序列预测新架构，结合 KAN 和 LSTM，提升多步预测准确性。  \n- **OXYGENERATOR（海洋脱氧重建）**：使用深度学习重建百年海洋数据，超越数值模拟，提供环境变化洞见。  \n- 其余如 LLMs 在教育中的应用（第37篇）和药物再利用相关（第5篇）等，虽然有贡献，但较聚焦特定子领域，故简要提及。\n\n总之，今天的 arXiv 强调 AI 模型的创新应用，LLMs 在跨领域（如教育和医疗）的潜力值得关注，读者可优先探索这些论文以捕捉前沿动态。保持关注，未来可能有更多突破！",
  "papers": [
    {
      "arxiv_id": "2405.07395v1",
      "title": "CaFA: Global Weather Forecasting with Factorized Attention on Sphere",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Li",
        "Anthony Zhou",
        "Saurabh Patil",
        "Amir Barati Farimani"
      ],
      "abstract": "Accurate weather forecasting is crucial in various sectors, impacting\ndecision-making processes and societal events. Data-driven approaches based on\nmachine learning models have recently emerged as a promising alternative to\nnumerical weather prediction models given their potential to capture physics of\ndifferent scales from historical data and the significantly lower computational\ncost during the prediction stage. Renowned for its state-of-the-art performance\nacross diverse domains, the Transformer model has also gained popularity in\nmachine learning weather prediction. Yet applying Transformer architectures to\nweather forecasting, particularly on a global scale is computationally\nchallenging due to the quadratic complexity of attention and the quadratic\nincrease in spatial points as resolution increases. In this work, we propose a\nfactorized-attention-based model tailored for spherical geometries to mitigate\nthis issue. More specifically, it utilizes multi-dimensional factorized kernels\nthat convolve over different axes where the computational complexity of the\nkernel is only quadratic to the axial resolution instead of overall resolution.\nThe deterministic forecasting accuracy of the proposed model on $1.5^\\circ$ and\n0-7 days' lead time is on par with state-of-the-art purely data-driven machine\nlearning weather prediction models. We also showcase the proposed model holds\ngreat potential to push forward the Pareto front of accuracy-efficiency for\nTransformer weather models, where it can achieve better accuracy with less\ncomputational cost compared to Transformer based models with standard\nattention.",
      "tldr_zh": "本文提出 CaFA 模型，用于全球天气预报，旨在解决 Transformer 模型在球面几何上的计算挑战，该模型采用 factorized attention 机制，通过多维因子化内核仅与轴向分辨率二次方相关，从而降低整体计算复杂度。CaFA 在 1.5° 分辨率和 0-7 天预测时，其确定性预报准确性与最先进的数据驱动机器学习模型相当。相比标准 Transformer 模型，CaFA 实现了更好的准确性与效率平衡，推动了准确性-效率的 Pareto front 前沿。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.07395v1",
      "published_date": "2024-05-12 23:18:14 UTC",
      "updated_date": "2024-05-12 23:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:49:27.698741"
    },
    {
      "arxiv_id": "2405.07393v1",
      "title": "Intrinsic Fairness-Accuracy Tradeoffs under Equalized Odds",
      "title_zh": "翻译失败",
      "authors": [
        "Meiyu Zhong",
        "Ravi Tandon"
      ],
      "abstract": "With the growing adoption of machine learning (ML) systems in areas like law\nenforcement, criminal justice, finance, hiring, and admissions, it is\nincreasingly critical to guarantee the fairness of decisions assisted by ML. In\nthis paper, we study the tradeoff between fairness and accuracy under the\nstatistical notion of equalized odds. We present a new upper bound on the\naccuracy (that holds for any classifier), as a function of the fairness budget.\nIn addition, our bounds also exhibit dependence on the underlying statistics of\nthe data, labels and the sensitive group attributes. We validate our\ntheoretical upper bounds through empirical analysis on three real-world\ndatasets: COMPAS, Adult, and Law School. Specifically, we compare our upper\nbound to the tradeoffs that are achieved by various existing fair classifiers\nin the literature. Our results show that achieving high accuracy subject to a\nlow-bias could be fundamentally limited based on the statistical disparity\nacross the groups.",
      "tldr_zh": "这篇论文探讨了机器学习模型在 equalized odds 公平性标准下的内在公平性-准确性权衡，强调了在法律、金融等领域决策中的公平保障。研究者提出一个新的准确性上界，作为公平 budget 的函数，并揭示了这一上界如何依赖于数据、标签和敏感群体属性的统计特性。通过对 COMPAS、Adult 和 Law School 等真实数据集的实证分析，论文证明了在群体间统计差异较大的情况下，实现高准确性同时满足低偏差可能存在根本限制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07393v1",
      "published_date": "2024-05-12 23:15:21 UTC",
      "updated_date": "2024-05-12 23:15:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:49:38.131110"
    },
    {
      "arxiv_id": "2405.07391v3",
      "title": "AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch",
      "title_zh": "翻译失败",
      "authors": [
        "Max Yang",
        "Chenghua Lu",
        "Alex Church",
        "Yijiong Lin",
        "Chris Ford",
        "Haoran Li",
        "Efi Psomopoulou",
        "David A. W. Barton",
        "Nathan F. Lepora"
      ],
      "abstract": "Human hands are capable of in-hand manipulation in the presence of different\nhand motions. For a robot hand, harnessing rich tactile information to achieve\nthis level of dexterity still remains a significant challenge. In this paper,\nwe present AnyRotate, a system for gravity-invariant multi-axis in-hand object\nrotation using dense featured sim-to-real touch. We tackle this problem by\ntraining a dense tactile policy in simulation and present a sim-to-real method\nfor rich tactile sensing to achieve zero-shot policy transfer. Our formulation\nallows the training of a unified policy to rotate unseen objects about\narbitrary rotation axes in any hand direction. In our experiments, we highlight\nthe benefit of capturing detailed contact information when handling objects of\nvarying properties. Interestingly, we found rich multi-fingered tactile sensing\ncan detect unstable grasps and provide a reactive behavior that improves the\nrobustness of the policy. The project website can be found at\nhttps://maxyang27896.github.io/anyrotate/.",
      "tldr_zh": "本文提出 AnyRotate 系统，实现 gravity-invariant 的多轴 in-hand object rotation，利用 sim-to-real 触觉方法，使机器人手具备类似人类的灵活性。该系统通过在模拟环境中训练密集触觉策略，并采用零样本转移技术，训练一个统一的策略来旋转未知物体关于任意旋转轴，无论手部方向如何。实验结果显示，捕获详细接触信息有助于处理不同物体的特性，且丰富的多指触觉感知能检测不稳定抓取并提供反应行为，从而显著提升策略的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website can be found at\n  https://maxyang27896.github.io/anyrotate/",
      "pdf_url": "http://arxiv.org/pdf/2405.07391v3",
      "published_date": "2024-05-12 22:51:35 UTC",
      "updated_date": "2024-11-03 16:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:49:50.843307"
    },
    {
      "arxiv_id": "2405.08032v1",
      "title": "Exploring the Potential of Conversational AI Support for Agent-Based Social Simulation Model Design",
      "title_zh": "探索对话式 AI 支持在基于代理的社会模拟模型设计中的潜力",
      "authors": [
        "Peer-Olaf Siebers"
      ],
      "abstract": "ChatGPT, the AI-powered chatbot with a massive user base of hundreds of\nmillions, has become a global phenomenon. However, the use of Conversational AI\nSystems (CAISs) like ChatGPT for research in the field of Social Simulation is\nstill limited. Specifically, there is no evidence of its usage in Agent-Based\nSocial Simulation (ABSS) model design. While scepticism towards anything new is\ninherent to human nature, we firmly believe it is imperative to initiate the\nuse of this innovative technology to support ABSS model design. This paper\npresents a proof-of-concept that demonstrates how CAISs can facilitate the\ndevelopment of innovative conceptual ABSS models in a concise timeframe and\nwith minimal required upfront case-based knowledge. By employing advanced\nprompt engineering techniques and adhering to the Engineering ABSS framework,\nwe have constructed a comprehensive prompt script that enables the design of\nABSS models with or by the CAIS. The effectiveness of the script is\ndemonstrated through an illustrative case study concerning the use of adaptive\narchitecture in museums. Despite occasional inaccuracies and divergences in\nconversation, the CAIS proved to be a valuable companion for ABSS modellers.",
      "tldr_zh": "这篇论文探讨了 Conversational AI Systems (CAISs) 如 ChatGPT 在 Agent-Based Social Simulation (ABSS) 模型设计中的潜力，目前该领域的应用仍很有限。作者通过高级 prompt engineering 技术和 Engineering ABSS 框架，构建了一个全面的提示脚本，实现快速开发创新的 ABSS 模型，而无需大量前期案例知识。在一个关于博物馆自适应建筑的案例研究中，脚本证明了 CAISs 的有效性，尽管存在 occasional inaccuracies and divergences，但它被视为 ABSS 建模者的宝贵辅助工具。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "29 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.08032v1",
      "published_date": "2024-05-12 22:11:54 UTC",
      "updated_date": "2024-05-12 22:11:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:50:02.959245"
    },
    {
      "arxiv_id": "2405.08031v2",
      "title": "HGTDR: Advancing Drug Repurposing with Heterogeneous Graph Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Gharizadeh",
        "Karim Abbasi",
        "Amin Ghareyazi",
        "Mohammad R. K. Mofrad",
        "Hamid R. Rabiee"
      ],
      "abstract": "Motivation: Drug repurposing is a viable solution for reducing the time and\ncost associated with drug development. However, thus far, the proposed drug\nrepurposing approaches still need to meet expectations. Therefore, it is\ncrucial to offer a systematic approach for drug repurposing to achieve cost\nsavings and enhance human lives. In recent years, using biological\nnetwork-based methods for drug repurposing has generated promising results.\nNevertheless, these methods have limitations. Primarily, the scope of these\nmethods is generally limited concerning the size and variety of data they can\neffectively handle. Another issue arises from the treatment of heterogeneous\ndata, which needs to be addressed or converted into homogeneous data, leading\nto a loss of information. A significant drawback is that most of these\napproaches lack end-to-end functionality, necessitating manual implementation\nand expert knowledge in certain stages. Results: We propose a new solution,\nHGTDR (Heterogeneous Graph Transformer for Drug Repurposing), to address the\nchallenges associated with drug repurposing. HGTDR is a three-step approach for\nknowledge graph-based drug re-purposing: 1) constructing a heterogeneous\nknowledge graph, 2) utilizing a heterogeneous graph transformer network, and 3)\ncomputing relationship scores using a fully connected network. By leveraging\nHGTDR, users gain the ability to manipulate input graphs, extract information\nfrom diverse entities, and obtain their desired output. In the evaluation step,\nwe demonstrate that HGTDR performs comparably to previous methods. Furthermore,\nwe review medical studies to validate our method's top ten drug repurposing\nsuggestions, which have exhibited promising results. We also demon-strated\nHGTDR's capability to predict other types of relations through numerical and\nexperimental validation, such as drug-protein and disease-protein\ninter-relations.",
      "tldr_zh": "该研究针对药物再利用（Drug Repurposing）的挑战，提出HGTDR框架，以解决现有生物网络方法在数据规模、异构数据处理和端到端功能方面的局限性。HGTDR采用三步方法：构建异构知识图谱（Heterogeneous Knowledge Graph）、利用异构图变换器网络（Heterogeneous Graph Transformer Network）进行信息提取，以及通过全连接网络计算关系分数。实验结果显示，HGTDR的性能与现有方法相当，并通过医疗研究验证了其前十药物再利用建议的有效性，同时证明了其在预测药物-蛋白质和疾病-蛋白质等关系的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been archived without having permission from all\n  authors. Please withdraw",
      "pdf_url": "http://arxiv.org/pdf/2405.08031v2",
      "published_date": "2024-05-12 21:34:03 UTC",
      "updated_date": "2024-05-18 08:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:50:14.483643"
    },
    {
      "arxiv_id": "2405.13005v2",
      "title": "Understanding Sarcoidosis Using Large Language Models and Social Media Data",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Miles Xi",
        "Hong-Long Ji",
        "Lin Wang"
      ],
      "abstract": "Sarcoidosis is a rare inflammatory disease characterized by the formation of\ngranulomas in various organs. The disease presents diagnostic and treatment\nchallenges due to its diverse manifestations and unpredictable nature. In this\nstudy, we employed a Large Language Model (LLM) to analyze sarcoidosis-related\ndiscussions on the social media platform Reddit. Our findings underscore the\nefficacy of LLMs in accurately identifying sarcoidosis-related content. We\ndiscovered a wide array of symptoms reported by patients, with fatigue, swollen\nlymph nodes, and shortness of breath as the most prevalent. Prednisone was the\nmost prescribed medication, while infliximab showed the highest effectiveness\nin improving prognoses. Notably, our analysis revealed disparities in prognosis\nbased on age and gender, with women and younger patients experiencing good and\npolarized outcomes, respectively. Furthermore, unsupervised clustering\nidentified three distinct patient subgroups (phenotypes) with unique symptom\nprofiles, prognostic outcomes, and demographic distributions. Finally,\nsentiment analysis revealed a moderate negative impact on patients' mental\nhealth post-diagnosis, particularly among women and younger individuals. Our\nstudy represents the first application of LLMs to understand sarcoidosis\nthrough social media data. It contributes to understanding the disease by\nproviding data-driven insights into its manifestations, treatments, prognoses,\nand impact on patients' lives. Our findings have direct implications for\nimproving personalized treatment strategies and enhancing the quality of care\nfor individuals living with sarcoidosis.",
      "tldr_zh": "本研究使用 Large Language Model (LLM) 分析 Reddit 上的 Sarcoidosis 相关讨论，以探索这种罕见炎症性疾病的症状、治疗和预后。研究发现，常见症状包括疲劳、肿胀的淋巴结和呼吸短促，Prednisone 是最常用药物，而 Infliximab 显示最高疗效；同时，年龄和性别影响预后，女性和年轻人分别表现出较好和两极分化的结果。无监督聚类识别了三种患者亚群（phenotypes），并通过情感分析揭示诊断后对心理健康的负面影响，尤其是女性和年轻人。该工作首次应用 LLM 于社交媒体数据，提供数据驱动见解，有助于优化个性化治疗策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13005v2",
      "published_date": "2024-05-12 20:54:23 UTC",
      "updated_date": "2024-10-27 21:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:50:27.110143"
    },
    {
      "arxiv_id": "2405.07374v2",
      "title": "Conformalized Survival Distributions: A Generic Post-Process to Increase Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Shi-ang Qi",
        "Yakun Yu",
        "Russell Greiner"
      ],
      "abstract": "Discrimination and calibration represent two important properties of survival\nanalysis, with the former assessing the model's ability to accurately rank\nsubjects and the latter evaluating the alignment of predicted outcomes with\nactual events. With their distinct nature, it is hard for survival models to\nsimultaneously optimize both of them especially as many previous results found\nimproving calibration tends to diminish discrimination performance. This paper\nintroduces a novel approach utilizing conformal regression that can improve a\nmodel's calibration without degrading discrimination. We provide theoretical\nguarantees for the above claim, and rigorously validate the efficiency of our\napproach across 11 real-world datasets, showcasing its practical applicability\nand robustness in diverse scenarios.",
      "tldr_zh": "本研究针对生存分析（survival analysis）中的判别力（discrimination）和校准性（calibration）问题，提出了一种通用后处理方法，即基于共形回归（conformal regression）的生存分布校准化技术，以改善模型的校准性能，同时避免降低判别力。不同于以往优化这些属性的权衡，该方法提供了理论保证，确保校准提升不会牺牲模型对主体排名的准确性。在11个真实数据集上的实验验证了该方法的效率、实用性和鲁棒性，展示了其在多样场景中的广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024; 37 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07374v2",
      "published_date": "2024-05-12 20:27:34 UTC",
      "updated_date": "2024-06-03 03:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:50:39.235299"
    },
    {
      "arxiv_id": "2405.07373v3",
      "title": "From Probability to Counterfactuals: the Increasing Complexity of Satisfiability in Pearl's Causal Hierarchy",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Dörfler",
        "Benito van der Zander",
        "Markus Bläser",
        "Maciej Liskiewicz"
      ],
      "abstract": "The framework of Pearl's Causal Hierarchy (PCH) formalizes three types of\nreasoning: probabilistic (i.e. purely observational), interventional, and\ncounterfactual, that reflect the progressive sophistication of human thought\nregarding causation. We investigate the computational complexity aspects of\nreasoning in this framework focusing mainly on satisfiability problems\nexpressed in probabilistic and causal languages across the PCH. That is, given\na system of formulas in the standard probabilistic and causal languages, does\nthere exist a model satisfying the formulas?\n  Our main contribution is to prove the exact computational complexities\nshowing that languages allowing addition and marginalization (via the summation\noperator) yield NP^PP, PSPACE-, and NEXP-complete satisfiability problems,\ndepending on the level of the PCH. These are the first results to demonstrate a\nstrictly increasing complexity across the PCH: from probabilistic to causal and\ncounterfactual reasoning. On the other hand, in the case of full languages,\ni.e. allowing addition, marginalization, and multiplication, we show that the\nsatisfiability for the counterfactual level remains the same as for the\nprobabilistic and causal levels, solving an open problem in the field.",
      "tldr_zh": "本论文探讨了 Pearl's Causal Hierarchy (PCH) 中的满足性问题，分析从概率推理到干预性和反事实推理的计算复杂性。研究的主要贡献是证明，在允许加法和边缘化（via summation operator）的语言下，满足性问题的复杂度从概率层级的 NP^PP-complete，到因果层级的 PSPACE-complete，再到反事实层级的 NEXP-complete，展示了严格递增的复杂度趋势。对于完整语言（包括加法、边缘化和乘法），论文证明反事实层级的满足性与概率和因果层级相同，从而解决了该领域的开放问题。这些结果突显了因果推理复杂性的本质差异，为未来计算因果模型提供了重要洞见。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted at ICLR 25",
      "pdf_url": "http://arxiv.org/pdf/2405.07373v3",
      "published_date": "2024-05-12 20:25:36 UTC",
      "updated_date": "2025-02-06 18:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:50:51.218405"
    },
    {
      "arxiv_id": "2405.13004v1",
      "title": "MathDivide: Improved mathematical reasoning by large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Saksham Sahai Srivastava",
        "Ashutosh Gandhi"
      ],
      "abstract": "Large language models have been proven to be capable of handling complex\nlinguistic and cognitive tasks. Therefore their usage has been extended to\ntasks requiring logical reasoning ability such as Mathematics. In this paper,\nwe propose a prompting technique called MathDivide that breaks down the\nmathematical problem into simpler subproblems. Each of the subproblems is\nformulated as an algebraic expression whose value is evaluated by the Python\ncode generated by the LLM for the corresponding algebraic expression. The\nvalues fed to the Python code are the numerical values provided in the problem\nstatement. The solutions for the subproblems are composed together to obtain\nthe final answer for the problem statement. Finally, the final answer is\ncompared to the correct answer. If the final answer matches the correct answer,\nit is produced as output else a refinement prompt is fed to the LLM. We\nexperiment with this prompting technique on both closed-source LLM models and\nopen-source LLM models using GSM8K dataset. The results obtained demonstrate\nthat MathDivide was able to significantly outperform the leading prompting\ntechnique called Math-prompter.",
      "tldr_zh": "本研究提出了一种名为 MathDivide 的提示技术，以提升大型语言模型（LLMs）在数学推理方面的性能。该技术将复杂数学问题分解为更简单的子问题，每个子问题表述为代数表达式，并由LLMs生成的Python代码求值，然后将子问题的解决方案组合以得出最终答案。如果答案不正确，会通过精炼提示反馈给LLMs进行优化。在GSM8K数据集上的实验显示，MathDivide显著优于领先的提示技术Math-prompter，证明了其在提升数学推理准确率方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13004v1",
      "published_date": "2024-05-12 20:21:15 UTC",
      "updated_date": "2024-05-12 20:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:51:02.226258"
    },
    {
      "arxiv_id": "2405.08029v2",
      "title": "PHUDGE: Phi-3 as Scalable Judge",
      "title_zh": "PHUDGE：Phi-3 作为可扩展判断器",
      "authors": [
        "Mahesh Deshwal",
        "Apoorva Chawla"
      ],
      "abstract": "In this paper cum technical report, we present PHUDGE A fine tuned Phi3 model\nthat achieved SOTA results in 4 tasks as Feedback Test, Feedback OOD, MT Human,\nPreference Test surpassing each and every existing model in latency and\nthroughput. It shows very strong correlation not only with GPT4 but with Human\nannotators too in unseen data as well as in both absolute and relative grading\ntasks. We have not only addressed the usage of small LMs for cost effective\nproduction grade systems but have also shown that Causal modelling is not only\nslow in nature but sometimes it can hinder models learning capabilities and\nshould be replaced by simpler tasks whenever we can to make the overall system\nfaster and better. We show that by following systematic ML experimentation,\nthoughtful data augmentation and re purposing the problem itself, we can even\nbeat 10x bigger models even with lesser training data. To the best of our\nknowledge, we are re the first one to experiment and showcase the usage of\ngeneralised version of Earth Movers Distance AKA Wasserstein distance by using\nMinkowski Distance with a penalty to control loss smoothing and can be used as\na loss function instead of Cross Entropy to get stable training and better\nresults for grading tasks.",
      "tldr_zh": "本研究介绍了 PHUDGE，一种微调后的 Phi-3 模型，作为可扩展的评估器（Scalable Judge），在 Feedback Test、Feedback OOD、MT Human 和 Preference Test 等 4 个任务中达到了 SOTA（State-of-the-Art）结果，并在延迟和吞吐量方面超越现有模型。PHUDGE 显示出与 GPT-4 以及人类标注者的高度相关性，尤其在未见数据、绝对和相对评分任务中，通过系统化的 ML 实验、数据增强和问题重构，即使使用较少训练数据，也能击败 10 倍大的模型。论文还指出，Causal modelling 可能减缓模型学习，并建议用更简单任务替换，同时首次使用 Minkowski Distance 作为 Wasserstein distance 的泛化版本来替代 Cross Entropy 损失函数，实现更稳定的训练和更好性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08029v2",
      "published_date": "2024-05-12 18:22:16 UTC",
      "updated_date": "2024-05-15 05:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:51:15.712745"
    },
    {
      "arxiv_id": "2405.07349v1",
      "title": "WeedScout: Real-Time Autonomous blackgrass Classification and Mapping using dedicated hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Gazzard",
        "Helen Hicks",
        "Isibor Kennedy Ihianle",
        "Jordan J. Bird",
        "Md Mahmudul Hasan",
        "Pedro Machado"
      ],
      "abstract": "Blackgrass (Alopecurus myosuroides) is a competitive weed that has\nwide-ranging impacts on food security by reducing crop yields and increasing\ncultivation costs. In addition to the financial burden on agriculture, the\napplication of herbicides as a preventive to blackgrass can negatively affect\naccess to clean water and sanitation. The WeedScout project introduces a\nReal-Rime Autonomous Black-Grass Classification and Mapping (RT-ABGCM), a\ncutting-edge solution tailored for real-time detection of blackgrass, for\nprecision weed management practices. Leveraging Artificial Intelligence (AI)\nalgorithms, the system processes live image feeds, infers blackgrass density,\nand covers two stages of maturation. The research investigates the deployment\nof You Only Look Once (YOLO) models, specifically the streamlined YOLOv8 and\nYOLO-NAS, accelerated at the edge with the NVIDIA Jetson Nano (NJN). By\noptimising inference speed and model performance, the project advances the\nintegration of AI into agricultural practices, offering potential solutions to\nchallenges such as herbicide resistance and environmental impact. Additionally,\ntwo datasets and model weights are made available to the research community,\nfacilitating further advancements in weed detection and precision farming\ntechnologies.",
      "tldr_zh": "该研究介绍了WeedScout系统，用于实时自主黑麦草(Blackgrass)分类和映射(RT-ABGCM)，旨在解决黑麦草对作物产量和环境的影响，如化肥使用导致的水资源问题。系统利用AI算法处理实时图像数据，采用优化的You Only Look Once(YOLO)模型，包括YOLOv8和YOLO-NAS，在NVIDIA Jetson Nano硬件上加速推理，以提升检测速度和准确性。实验结果显示，该系统在精准杂草管理中表现出色，并公开了两个数据集和模型权重，促进AI在农业领域的进一步应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07349v1",
      "published_date": "2024-05-12 18:04:41 UTC",
      "updated_date": "2024-05-12 18:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:51:27.299072"
    },
    {
      "arxiv_id": "2405.07344v3",
      "title": "TKAN: Temporal Kolmogorov-Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Remi Genet",
        "Hugo Inzirillo"
      ],
      "abstract": "Recurrent Neural Networks (RNNs) have revolutionized many areas of machine\nlearning, particularly in natural language and data sequence processing. Long\nShort-Term Memory (LSTM) has demonstrated its ability to capture long-term\ndependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks\n(KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposed\na new neural networks architecture inspired by KAN and the LSTM, the Temporal\nKolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both\nnetworks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers\nembedding memory management. This innovation enables us to perform multi-step\ntime series forecasting with enhanced accuracy and efficiency. By addressing\nthe limitations of traditional models in handling complex sequential patterns,\nthe TKAN architecture offers significant potential for advancements in fields\nrequiring more than one step ahead forecasting.",
      "tldr_zh": "本论文提出了一种新颖的神经网络架构 Temporal Kolmogorov-Arnold Networks (TKANs)，受 Kolmogorov-Arnold Networks (KANs) 和 Long Short-Term Memory (LSTM) 的启发，用于处理序列数据中的长期依赖。TKANs 由 Recurring Kolmogorov-Arnold Networks (RKANs) 层组成，嵌入记忆管理机制，从而提升多步时间序列预测的准确性和效率。相比传统模型，该架构有效解决了处理复杂序列模式时的局限性，在需要多步预测的领域展现出显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07344v3",
      "published_date": "2024-05-12 17:40:48 UTC",
      "updated_date": "2024-12-17 17:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:51:40.693165"
    },
    {
      "arxiv_id": "2405.07327v1",
      "title": "Liquid Ensemble Selection for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Carter Blair",
        "Ben Armstrong",
        "Kate Larson"
      ],
      "abstract": "Continual learning aims to enable machine learning models to continually\nlearn from a shifting data distribution without forgetting what has already\nbeen learned. Such shifting distributions can be broken into disjoint subsets\nof related examples; by training each member of an ensemble on a different\nsubset it is possible for the ensemble as a whole to achieve much higher\naccuracy with less forgetting than a naive model. We address the problem of\nselecting which models within an ensemble should learn on any given data, and\nwhich should predict. By drawing on work from delegative voting we develop an\nalgorithm for using delegation to dynamically select which models in an\nensemble are active. We explore a variety of delegation methods and performance\nmetrics, ultimately finding that delegation is able to provide a significant\nperformance boost over naive learning in the face of distribution shifts.",
      "tldr_zh": "该论文针对 Continual Learning（持续学习）提出了一种 Liquid Ensemble Selection 方法，通过将不断变化的数据分布分解为不相交子集，并分别训练集成模型（ensemble）的成员，以实现更高的准确率和更少遗忘。作者借鉴 Delegative Voting 的概念，开发了一个算法，使用委托机制动态选择集成模型中哪些模型负责学习和预测。实验结果表明，这种方法在面对数据分布偏移时，比传统 naive learning 显著提升了性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Canadian AI Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07327v1",
      "published_date": "2024-05-12 16:33:48 UTC",
      "updated_date": "2024-05-12 16:33:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:51:52.463943"
    },
    {
      "arxiv_id": "2405.07317v1",
      "title": "Machine Unlearning in Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zixin Wang",
        "Kongyang Chen"
      ],
      "abstract": "Machine unlearning is a complex process that necessitates the model to\ndiminish the influence of the training data while keeping the loss of accuracy\nto a minimum. Despite the numerous studies on machine unlearning in recent\nyears, the majority of them have primarily focused on supervised learning\nmodels, leaving research on contrastive learning models relatively\nunderexplored. With the conviction that self-supervised learning harbors a\npromising potential, surpassing or rivaling that of supervised learning, we set\nout to investigate methods for machine unlearning centered around contrastive\nlearning models. In this study, we introduce a novel gradient constraint-based\napproach for training the model to effectively achieve machine unlearning. Our\nmethod only necessitates a minimal number of training epochs and the\nidentification of the data slated for unlearning. Remarkably, our approach\ndemonstrates proficient performance not only on contrastive learning models but\nalso on supervised learning models, showcasing its versatility and adaptability\nin various learning paradigms.",
      "tldr_zh": "本研究探讨了 machine unlearning 在 contrastive learning 中的应用，旨在减少特定训练数据的影响，同时最小化模型准确性损失。现有的研究多聚焦于 supervised learning，而本工作引入了一种新型 gradient constraint-based 方法，仅需少量训练周期和标识要 unlearning 的数据，即可有效实现 unlearning。该方法不仅在 contrastive learning 模型上表现出色，还适用于 supervised learning 模型，展示了其通用性和适应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07317v1",
      "published_date": "2024-05-12 16:09:01 UTC",
      "updated_date": "2024-05-12 16:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:52:03.692893"
    },
    {
      "arxiv_id": "2405.07309v1",
      "title": "DiffGen: Robot Demonstration Generation via Differentiable Physics Simulation, Differentiable Rendering, and Vision-Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Jin",
        "Jun Lv",
        "Shuqiang Jiang",
        "Cewu Lu"
      ],
      "abstract": "Generating robot demonstrations through simulation is widely recognized as an\neffective way to scale up robot data. Previous work often trained reinforcement\nlearning agents to generate expert policies, but this approach lacks sample\nefficiency. Recently, a line of work has attempted to generate robot\ndemonstrations via differentiable simulation, which is promising but heavily\nrelies on reward design, a labor-intensive process. In this paper, we propose\nDiffGen, a novel framework that integrates differentiable physics simulation,\ndifferentiable rendering, and a vision-language model to enable automatic and\nefficient generation of robot demonstrations. Given a simulated robot\nmanipulation scenario and a natural language instruction, DiffGen can generate\nrealistic robot demonstrations by minimizing the distance between the embedding\nof the language instruction and the embedding of the simulated observation\nafter manipulation. The embeddings are obtained from the vision-language model,\nand the optimization is achieved by calculating and descending gradients\nthrough the differentiable simulation, differentiable rendering, and\nvision-language model components, thereby accomplishing the specified task.\nExperiments demonstrate that with DiffGen, we could efficiently and effectively\ngenerate robot data with minimal human effort or training time.",
      "tldr_zh": "该论文提出 DiffGen 框架，通过整合 Differentiable Physics Simulation、Differentiable Rendering 和 Vision-Language Model，实现机器人演示的自动高效生成，以解决传统方法在样本效率和奖励设计上的问题。\nDiffGen 的工作原理是给定模拟机器人操作场景和自然语言指令，通过最小化指令嵌入与操作后模拟观察嵌入的距离，并利用梯度下降优化来生成逼真的演示。\n实验证明，该框架能以最少人力和训练时间有效生成机器人数据，显著提升了数据规模扩展的效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07309v1",
      "published_date": "2024-05-12 15:38:17 UTC",
      "updated_date": "2024-05-12 15:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:52:16.271114"
    },
    {
      "arxiv_id": "2405.07295v3",
      "title": "Bridging Neuroscience and AI: Environmental Enrichment as a Model for Forward Knowledge Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Rajat Saxena",
        "Bruce L. McNaughton"
      ],
      "abstract": "Continual learning (CL) refers to an agent's capability to learn from a\ncontinuous stream of data and transfer knowledge without forgetting old\ninformation. One crucial aspect of CL is forward transfer, i.e., improved and\nfaster learning on a new task by leveraging information from prior knowledge.\nWhile this ability comes naturally to biological brains, it poses a significant\nchallenge for artificial intelligence (AI). Here, we suggest that environmental\nenrichment (EE) can be used as a biological model for studying forward\ntransfer, inspiring human-like AI development. EE refers to animal studies that\nenhance cognitive, social, motor, and sensory stimulation and is a model for\nwhat, in humans, is referred to as 'cognitive reserve'. Enriched animals show\nsignificant improvement in learning speed and performance on new tasks,\ntypically exhibiting forward transfer. We explore anatomical, molecular, and\nneuronal changes post-EE and discuss how artificial neural networks (ANNs) can\nbe used to predict neural computation changes after enriched experiences.\nFinally, we provide a synergistic way of combining neuroscience and AI research\nthat paves the path toward developing AI capable of rapid and efficient new\ntask learning.",
      "tldr_zh": "该论文探讨了持续学习（Continual Learning）中的前向转移（Forward Transfer），即利用先前知识来加速和改善新任务的学习，尽管生物大脑自然具备此能力，但人工智能（AI）仍面临挑战。作者提出环境丰富化（Environmental Enrichment, EE）作为一种生物模型，EE 通过增强认知、社会、运动和感官刺激，类似于人类的“认知储备”，能显著提升动物的学习速度和性能。论文分析了 EE 后的解剖、分子和神经元变化，并探讨如何使用人工神经网络（ANNs）预测这些神经计算变化，以启发 AI 的发展。最后，该研究提供了一种协同神经科学和 AI 的方法，推动创建快速高效学习新任务的 AI 系统。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07295v3",
      "published_date": "2024-05-12 14:33:50 UTC",
      "updated_date": "2025-01-23 03:11:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:52:29.538075"
    },
    {
      "arxiv_id": "2405.07293v1",
      "title": "Sparse Sampling is All You Need for Fast Wrong-way Cycling Detection in CCTV Videos",
      "title_zh": "稀疏采样就是你所需要的",
      "authors": [
        "Jing Xu",
        "Wentao Shi",
        "Sheng Ren",
        "Pan Gao",
        "Peng Zhou",
        "Jie Qin"
      ],
      "abstract": "In the field of transportation, it is of paramount importance to address and\nmitigate illegal actions committed by both motor and non-motor vehicles. Among\nthose actions, wrong-way cycling (i.e., riding a bicycle or e-bike in the\nopposite direction of the designated traffic flow) poses significant risks to\nboth cyclists and other road users. To this end, this paper formulates a\nproblem of detecting wrong-way cycling ratios in CCTV videos. Specifically, we\npropose a sparse sampling method called WWC-Predictor to efficiently solve this\nproblem, addressing the inefficiencies of direct tracking methods. Our approach\nleverages both detection-based information, which utilizes the information from\nbounding boxes, and orientation-based information, which provides insights into\nthe image itself, to enhance instantaneous information capture capability. On\nour proposed benchmark dataset consisting of 35 minutes of video sequences and\nminute-level annotation, our method achieves an average error rate of a mere\n1.475% while taking only 19.12% GPU time of straightforward tracking methods\nunder the same detection model. This remarkable performance demonstrates the\neffectiveness of our approach in identifying and predicting instances of\nwrong-way cycling.",
      "tldr_zh": "本研究针对交通领域的逆行骑行（wrong-way cycling）问题，提出了一种高效的稀疏采样方法WWC-Predictor，用于检测CCTV视频中的逆行比例。该方法结合基于检测的信息（bounding boxes）和基于方向的信息，提升了即时信息捕获能力，从而避免了直接跟踪方法的低效。实验在包含35分钟视频序列的基准数据集上显示，该方法实现了仅1.475%的平均错误率，同时只需直接跟踪方法的19.12% GPU时间，证明了其在快速准确检测方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07293v1",
      "published_date": "2024-05-12 14:16:05 UTC",
      "updated_date": "2024-05-12 14:16:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:52:39.635834"
    },
    {
      "arxiv_id": "2405.07284v1",
      "title": "Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP)",
      "title_zh": "翻译失败",
      "authors": [
        "Saaketh Koundinya Gundavarapu",
        "Arushi Arora",
        "Shreya Agarwal"
      ],
      "abstract": "We present SLIP (SAM+CLIP), an enhanced architecture for zero-shot object\nsegmentation. SLIP combines the Segment Anything Model (SAM)\n\\cite{kirillov2023segment} with the Contrastive Language-Image Pretraining\n(CLIP) \\cite{radford2021learning}. By incorporating text prompts into SAM using\nCLIP, SLIP enables object segmentation without prior training on specific\nclasses or categories. We fine-tune CLIP on a Pokemon dataset, allowing it to\nlearn meaningful image-text representations. SLIP demonstrates the ability to\nrecognize and segment objects in images based on contextual information from\ntext prompts, expanding the capabilities of SAM for versatile object\nsegmentation. Our experiments demonstrate the effectiveness of the SLIP\narchitecture in segmenting objects in images based on textual cues. The\nintegration of CLIP's text-image understanding capabilities into SAM expands\nthe capabilities of the original architecture and enables more versatile and\ncontext-aware object segmentation.",
      "tldr_zh": "本研究提出 SLIP（SAM+CLIP），一种用于零样本对象分割（zero-shot object segmentation）的增强架构，将 Segment Anything Model (SAM) 与 Contrastive Language-Image Pretraining (CLIP) 相结合。通过在 Pokemon 数据集上微调 CLIP 并融入文本提示，SLIP 实现了无需针对特定类别预训练即可基于上下文信息识别和分割图像中的对象。实验结果表明，该架构有效扩展了 SAM 的能力，提升了对象分割的通用性和上下文感知性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.07284v1",
      "published_date": "2024-05-12 13:51:11 UTC",
      "updated_date": "2024-05-12 13:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:52:52.544573"
    },
    {
      "arxiv_id": "2405.08027v4",
      "title": "Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Xie",
        "Xueru Zhang"
      ],
      "abstract": "As machine learning (ML) models are increasingly used in social domains to\nmake consequential decisions about humans, they often have the power to reshape\ndata distributions. Humans, as strategic agents, continuously adapt their\nbehaviors in response to the learning system. As populations change\ndynamically, ML systems may need frequent updates to ensure high performance.\nHowever, acquiring high-quality human-annotated samples can be highly\nchallenging and even infeasible in social domains. A common practice to address\nthis issue is using the model itself to annotate unlabeled data samples. This\npaper investigates the long-term impacts when ML models are retrained with\nmodel-annotated samples when they incorporate human strategic responses. We\nfirst formalize the interactions between strategic agents and the model and\nthen analyze how they evolve under such dynamic interactions. We find that\nagents are increasingly likely to receive positive decisions as the model gets\nretrained, whereas the proportion of agents with positive labels may decrease\nover time. We thus propose a refined retraining process to stabilize the\ndynamics. Last, we examine how algorithmic fairness can be affected by these\nretraining processes and find that enforcing common fairness constraints at\nevery round may not benefit the disadvantaged group in the long run.\nExperiments on (semi-)synthetic and real data validate the theoretical\nfindings.",
      "tldr_zh": "本研究探讨了机器学习 (ML) 模型在社会领域决策时，面对战略人类代理 (strategic human agents) 的适应行为，导致数据分布变化和模型更新挑战的问题。论文形式化了代理与模型的动态互动，分析了使用模型自身标注数据 (model-annotated samples) 进行再训练的长期影响，发现代理获得正面决策的概率增加，但正面标签比例可能下降。作者提出了一种改进的再训练过程来稳定这些动态，并通过实验验证了理论发现，同时指出强制执行常见算法公平性 (algorithmic fairness) 约束可能在长期内不利于弱势群体。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08027v4",
      "published_date": "2024-05-12 13:36:58 UTC",
      "updated_date": "2024-10-11 00:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:53:04.955966"
    },
    {
      "arxiv_id": "2405.07280v1",
      "title": "Humor Mechanics: Advancing Humor Generation with Multistep Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Alexey Tikhonov",
        "Pavel Shtykovskiy"
      ],
      "abstract": "In this paper, we explore the generation of one-liner jokes through\nmulti-step reasoning. Our work involved reconstructing the process behind\ncreating humorous one-liners and developing a working prototype for humor\ngeneration. We conducted comprehensive experiments with human participants to\nevaluate our approach, comparing it with human-created jokes, zero-shot GPT-4\ngenerated humor, and other baselines. The evaluation focused on the quality of\nhumor produced, using human labeling as a benchmark. Our findings demonstrate\nthat the multi-step reasoning approach consistently improves the quality of\ngenerated humor. We present the results and share the datasets used in our\nexperiments, offering insights into enhancing humor generation with artificial\nintelligence.",
      "tldr_zh": "本文通过多步推理（multistep reasoning）探索生成单句笑话（one-liner jokes），重建了幽默创建过程并开发了一个幽默生成原型。研究者进行全面实验，使用人类参与者评估生成的幽默质量，与人类笑话、零样本 GPT-4 生成内容和其他基线模型进行比较。结果表明，多步推理方法显著提升了幽默质量，并分享了实验数据集，为人工智能增强幽默生成提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "68T05, 68T30, 68T50, 91-08",
        "I.2.7; I.2.1; I.2.6; H.5.2"
      ],
      "primary_category": "cs.CL",
      "comment": "ICCC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07280v1",
      "published_date": "2024-05-12 13:00:14 UTC",
      "updated_date": "2024-05-12 13:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:53:16.233022"
    },
    {
      "arxiv_id": "2405.07272v3",
      "title": "MAML MOT: Multiple Object Tracking based on Meta-Learning",
      "title_zh": "MAML MOT：基于元学习的多个对象跟踪",
      "authors": [
        "Jiayi Chen",
        "Chunhua Deng"
      ],
      "abstract": "With the advancement of video analysis technology, the multi-object tracking\n(MOT) problem in complex scenes involving pedestrians is gaining increasing\nimportance. This challenge primarily involves two key tasks: pedestrian\ndetection and re-identification. While significant progress has been achieved\nin pedestrian detection tasks in recent years, enhancing the effectiveness of\nre-identification tasks remains a persistent challenge. This difficulty arises\nfrom the large total number of pedestrian samples in multi-object tracking\ndatasets and the scarcity of individual instance samples. Motivated by recent\nrapid advancements in meta-learning techniques, we introduce MAML MOT, a\nmeta-learning-based training approach for multi-object tracking. This approach\nleverages the rapid learning capability of meta-learning to tackle the issue of\nsample scarcity in pedestrian re-identification tasks, aiming to improve the\nmodel's generalization performance and robustness. Experimental results\ndemonstrate that the proposed method achieves high accuracy on mainstream\ndatasets in the MOT Challenge. This offers new perspectives and solutions for\nresearch in the field of pedestrian multi-object tracking.",
      "tldr_zh": "本研究针对多对象跟踪（MOT）中的行人再识别挑战，提出了一种基于元学习（Meta-Learning）的训练方法，名为MAML MOT。该方法利用元学习的快速学习能力，解决行人样本稀缺问题，从而提升模型的泛化性能和鲁棒性。实验结果显示，在MOT Challenge的主流数据集上，该方法实现了高准确率，为复杂场景下的行人多对象跟踪提供了新颖的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07272v3",
      "published_date": "2024-05-12 12:38:40 UTC",
      "updated_date": "2024-08-23 12:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:53:28.979627"
    },
    {
      "arxiv_id": "2405.07260v1",
      "title": "A Supervised Information Enhanced Multi-Granularity Contrastive Learning Framework for EEG Based Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Li",
        "Jian Song",
        "Zhigang Zhao",
        "Chunxiao Wang",
        "Dawei Song",
        "Bin Hu"
      ],
      "abstract": "This study introduces a novel Supervised Info-enhanced Contrastive Learning\nframework for EEG based Emotion Recognition (SICLEER). SI-CLEER employs\nmulti-granularity contrastive learning to create robust EEG contextual\nrepresentations, potentiallyn improving emotion recognition effectiveness.\nUnlike existing methods solely guided by classification loss, we propose a\njoint learning model combining self-supervised contrastive learning loss and\nsupervised classification loss. This model optimizes both loss functions,\ncapturing subtle EEG signal differences specific to emotion detection.\nExtensive experiments demonstrate SI-CLEER's robustness and superior accuracy\non the SEED dataset compared to state-of-the-art methods. Furthermore, we\nanalyze electrode performance, highlighting the significance of central frontal\nand temporal brain region EEGs in emotion detection. This study offers an\nuniversally applicable approach with potential benefits for diverse EEG\nclassification tasks.",
      "tldr_zh": "本研究提出了一种名为 SI-CLEER 的 Supervised Info-enhanced Contrastive Learning 框架，用于基于 EEG 的情感识别。该框架采用 multi-granularity contrastive learning，通过结合自监督对比学习损失和监督分类损失，优化 EEG 信号的上下文表示，以捕捉情感检测中的细微差异。在 SEED 数据集上的广泛实验显示，SI-CLEER 比现有最先进方法具有更高的准确性和鲁棒性，并突出了中央额叶和颞叶脑区 EEG 信号的重要性。该方法提供了一个通用的 EEG 分类策略，具有广泛的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures, 2024 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)",
      "pdf_url": "http://arxiv.org/pdf/2405.07260v1",
      "published_date": "2024-05-12 11:51:00 UTC",
      "updated_date": "2024-05-12 11:51:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:53:40.334510"
    },
    {
      "arxiv_id": "2405.10974v2",
      "title": "Bottleneck-Minimal Indexing for Generative Document Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Du",
        "Lixin Xiu",
        "Kumiko Tanaka-Ishii"
      ],
      "abstract": "We apply an information-theoretic perspective to reconsider generative\ndocument retrieval (GDR), in which a document $x \\in X$ is indexed by $t \\in\nT$, and a neural autoregressive model is trained to map queries $Q$ to $T$. GDR\ncan be considered to involve information transmission from documents $X$ to\nqueries $Q$, with the requirement to transmit more bits via the indexes $T$. By\napplying Shannon's rate-distortion theory, the optimality of indexing can be\nanalyzed in terms of the mutual information, and the design of the indexes $T$\ncan then be regarded as a {\\em bottleneck} in GDR. After reformulating GDR from\nthis perspective, we empirically quantify the bottleneck underlying GDR.\nFinally, using the NQ320K and MARCO datasets, we evaluate our proposed\nbottleneck-minimal indexing method in comparison with various previous indexing\nmethods, and we show that it outperforms those methods.",
      "tldr_zh": "这篇论文从信息理论视角重新审视生成式文档检索 (Generative Document Retrieval, GDR)，将文档索引视为信息传输中的瓶颈问题，并应用 Shannon 的 rate-distortion theory 来分析索引的优化设计。研究者通过量化 GDR 中的 mutual information 瓶颈，提出了一种 bottleneck-minimal indexing 方法，以提高查询到文档的映射效率。在 NQ320K 和 MARCO 数据集的实验中，该方法表现出色，优于现有索引方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted for ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.10974v2",
      "published_date": "2024-05-12 11:41:26 UTC",
      "updated_date": "2024-05-21 01:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:53:53.536794"
    },
    {
      "arxiv_id": "2405.07248v1",
      "title": "Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis",
      "title_zh": "LLMs 模拟人类心理行为的能力有限：一项心理测量分析",
      "authors": [
        "Nikolay B Petrov",
        "Gregory Serapio-García",
        "Jason Rentfrow"
      ],
      "abstract": "The humanlike responses of large language models (LLMs) have prompted social\nscientists to investigate whether LLMs can be used to simulate human\nparticipants in experiments, opinion polls and surveys. Of central interest in\nthis line of research has been mapping out the psychological profiles of LLMs\nby prompting them to respond to standardized questionnaires. The conflicting\nfindings of this research are unsurprising given that mapping out underlying,\nor latent, traits from LLMs' text responses to questionnaires is no easy task.\nTo address this, we use psychometrics, the science of psychological\nmeasurement. In this study, we prompt OpenAI's flagship models, GPT-3.5 and\nGPT-4, to assume different personas and respond to a range of standardized\nmeasures of personality constructs. We used two kinds of persona descriptions:\neither generic (four or five random person descriptions) or specific (mostly\ndemographics of actual humans from a large-scale human dataset). We found that\nthe responses from GPT-4, but not GPT-3.5, using generic persona descriptions\nshow promising, albeit not perfect, psychometric properties, similar to human\nnorms, but the data from both LLMs when using specific demographic profiles,\nshow poor psychometrics properties. We conclude that, currently, when LLMs are\nasked to simulate silicon personas, their responses are poor signals of\npotentially underlying latent traits. Thus, our work casts doubt on LLMs'\nability to simulate individual-level human behaviour across multiple-choice\nquestion answering tasks.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 模拟人类心理行为的局限性，通过心理测量学 (psychometrics) 方法，让 OpenAI 的 GPT-3.5 和 GPT-4 模型采用泛化 (generic) 或具体 (specific) 人设响应标准化人格问卷。结果显示，GPT-4 在泛化人设下表现出较为可靠的心理测量属性，与人类标准相似，但 GPT-3.5 则表现不佳；当使用具体人口统计数据时，两者均显示出较差的心理测量性质。研究结论质疑了 LLMs 在多选题任务中模拟个体人类行为的可靠性，强调其响应无法有效反映潜在的潜在特质 (latent traits)。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07248v1",
      "published_date": "2024-05-12 10:52:15 UTC",
      "updated_date": "2024-05-12 10:52:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:54:04.480913"
    },
    {
      "arxiv_id": "2405.13003v1",
      "title": "A Survey on Recent Advances in Conversational Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Heydar Soudani",
        "Roxana Petcu",
        "Evangelos Kanoulas",
        "Faegheh Hasibi"
      ],
      "abstract": "Recent advancements in conversational systems have significantly enhanced\nhuman-machine interactions across various domains. However, training these\nsystems is challenging due to the scarcity of specialized dialogue data.\nTraditionally, conversational datasets were created through crowdsourcing, but\nthis method has proven costly, limited in scale, and labor-intensive. As a\nsolution, the development of synthetic dialogue data has emerged, utilizing\ntechniques to augment existing datasets or convert textual resources into\nconversational formats, providing a more efficient and scalable approach to\ndataset creation. In this survey, we offer a systematic and comprehensive\nreview of multi-turn conversational data generation, focusing on three types of\ndialogue systems: open domain, task-oriented, and information-seeking. We\ncategorize the existing research based on key components like seed data\ncreation, utterance generation, and quality filtering methods, and introduce a\ngeneral framework that outlines the main principles of conversation data\ngeneration systems. Additionally, we examine the evaluation metrics and methods\nfor assessing synthetic conversational data, address current challenges in the\nfield, and explore potential directions for future research. Our goal is to\naccelerate progress for researchers and practitioners by presenting an overview\nof state-of-the-art methods and highlighting opportunities to further research\nin this area.",
      "tldr_zh": "这篇调查论文回顾了对话数据生成(conversational data generation)的最新进展，旨在解决训练对话系统时专业数据集稀缺的挑战。论文系统分类了现有研究，包括种子数据创建(seed data creation)、话语生成(utterance generation)和质量过滤方法，并引入了一个通用框架，聚焦于开放域(open domain)、任务导向(task-oriented)和信息寻求(information-seeking)对话系统。最终，它评估了合成对话数据的指标、当前问题，并探讨了未来研究方向，以加速该领域的创新和发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13003v1",
      "published_date": "2024-05-12 10:11:12 UTC",
      "updated_date": "2024-05-12 10:11:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:54:17.230949"
    },
    {
      "arxiv_id": "2405.13002v1",
      "title": "DuetRAG: Collaborative Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dian Jiao",
        "Li Cai",
        "Jingsheng Huang",
        "Wenqiao Zhang",
        "Siliang Tang",
        "Yueting Zhuang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) methods augment the input of Large\nLanguage Models (LLMs) with relevant retrieved passages, reducing factual\nerrors in knowledge-intensive tasks. However, contemporary RAG approaches\nsuffer from irrelevant knowledge retrieval issues in complex domain questions\n(e.g., HotPot QA) due to the lack of corresponding domain knowledge, leading to\nlow-quality generations. To address this issue, we propose a novel\nCollaborative Retrieval-Augmented Generation framework, DuetRAG. Our\nbootstrapping philosophy is to simultaneously integrate the domain fintuning\nand RAG models to improve the knowledge retrieval quality, thereby enhancing\ngeneration quality. Finally, we demonstrate DuetRAG' s matches with expert\nhuman researchers on HotPot QA.",
      "tldr_zh": "该研究针对 Retrieval-Augmented Generation (RAG) 方法在复杂领域问题（如 HotPot QA）中存在的无关知识检索问题，提出了一种新型协作框架 DuetRAG。该框架通过同时整合领域微调和 RAG 模型，提升知识检索质量，从而改善生成结果的准确性和相关性。实验结果显示，DuetRAG 在 HotPot QA 任务上达到了与人类专家相当的性能，为知识密集型任务提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.13002v1",
      "published_date": "2024-05-12 09:48:28 UTC",
      "updated_date": "2024-05-12 09:48:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:54:28.248743"
    },
    {
      "arxiv_id": "2405.07233v1",
      "title": "OXYGENERATOR: Reconstructing Global Ocean Deoxygenation Over a Century with Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Lu",
        "Ze Zhao",
        "Luyu Han",
        "Xiaoying Gan",
        "Yuntao Zhou",
        "Lei Zhou",
        "Luoyi Fu",
        "Xinbing Wang",
        "Chenghu Zhou",
        "Jing Zhang"
      ],
      "abstract": "Accurately reconstructing the global ocean deoxygenation over a century is\ncrucial for assessing and protecting marine ecosystem. Existing\nexpert-dominated numerical simulations fail to catch up with the dynamic\nvariation caused by global warming and human activities. Besides, due to the\nhigh-cost data collection, the historical observations are severely sparse,\nleading to big challenge for precise reconstruction. In this work, we propose\nOxyGenerator, the first deep learning based model, to reconstruct the global\nocean deoxygenation from 1920 to 2023. Specifically, to address the\nheterogeneity across large temporal and spatial scales, we propose\nzoning-varying graph message-passing to capture the complex oceanographic\ncorrelations between missing values and sparse observations. Additionally, to\nfurther calibrate the uncertainty, we incorporate inductive bias from dissolved\noxygen (DO) variations and chemical effects. Compared with in-situ DO\nobservations, OxyGenerator significantly outperforms CMIP6 numerical\nsimulations, reducing MAPE by 38.77%, demonstrating a promising potential to\nunderstand the \"breathless ocean\" in data-driven manner.",
      "tldr_zh": "这篇论文提出 OXYGENERATOR，一种基于 deep learning 的模型，用于重建 1920 至 2023 年的全球海洋 deoxygenation，以解决现有数值模拟无法捕捉动态变化和历史观测数据稀疏的挑战。模型创新性地采用 zoning-varying graph message-passing 来捕捉大规模时间和空间异质性的海洋相关性，并融入 dissolved oxygen (DO) 变异和化学效应的归纳偏差，以校准不确定性。与 CMIP6 数值模拟相比，OXYGENERATOR 显著降低了 MAPE 38.77%，展示了数据驱动方法在理解“无呼吸海洋”方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07233v1",
      "published_date": "2024-05-12 09:32:40 UTC",
      "updated_date": "2024-05-12 09:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:54:41.990742"
    },
    {
      "arxiv_id": "2405.07226v1",
      "title": "Separable Power of Classical and Quantum Learning Protocols Through the Lens of No-Free-Lunch Theorem",
      "title_zh": "从无免费午餐定理的视角审视经典和量子学习协议的可分离能力",
      "authors": [
        "Xinbiao Wang",
        "Yuxuan Du",
        "Kecheng Liu",
        "Yong Luo",
        "Bo Du",
        "Dacheng Tao"
      ],
      "abstract": "The No-Free-Lunch (NFL) theorem, which quantifies problem- and\ndata-independent generalization errors regardless of the optimization process,\nprovides a foundational framework for comprehending diverse learning protocols'\npotential. Despite its significance, the establishment of the NFL theorem for\nquantum machine learning models remains largely unexplored, thereby overlooking\nbroader insights into the fundamental relationship between quantum and\nclassical learning protocols. To address this gap, we categorize a diverse\narray of quantum learning algorithms into three learning protocols designed for\nlearning quantum dynamics under a specified observable and establish their NFL\ntheorem. The exploited protocols, namely Classical Learning Protocols\n(CLC-LPs), Restricted Quantum Learning Protocols (ReQu-LPs), and Quantum\nLearning Protocols (Qu-LPs), offer varying levels of access to quantum\nresources. Our derived NFL theorems demonstrate quadratic reductions in sample\ncomplexity across CLC-LPs, ReQu-LPs, and Qu-LPs, contingent upon the\northogonality of quantum states and the diagonality of observables. We\nattribute this performance discrepancy to the unique capacity of\nquantum-related learning protocols to indirectly utilize information concerning\nthe global phases of non-orthogonal quantum states, a distinctive physical\nfeature inherent in quantum mechanics. Our findings not only deepen our\nunderstanding of quantum learning protocols' capabilities but also provide\npractical insights for the development of advanced quantum learning algorithms.",
      "tldr_zh": "这篇论文通过 No-Free-Lunch (NFL) 定理的视角，探讨了经典和量子学习协议在泛化错误方面的性能差异，并首次为量子机器学习模型建立了 NFL 定理。作者将量子学习算法分类为 Classical Learning Protocols (CLC-LPs)、Restricted Quantum Learning Protocols (ReQu-LPs) 和 Quantum Learning Protocols (Qu-LPs)，这些协议针对学习量子动力学下的指定可观测量，提供不同级别的量子资源访问。研究发现，量子协议在样本复杂度上实现了二次减少，取决于量子态的正交性和可观测量的对角性，这归因于量子机制中对非正交量子态全局相位的间接利用。该工作加深了对量子学习协议能力的理解，并为开发高级量子学习算法提供了实用指导。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07226v1",
      "published_date": "2024-05-12 09:05:13 UTC",
      "updated_date": "2024-05-12 09:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:54:53.981172"
    },
    {
      "arxiv_id": "2405.10973v1",
      "title": "Adaptation of XAI to Auto-tuning for Numerical Libraries",
      "title_zh": "翻译失败",
      "authors": [
        "Shota Aoki",
        "Takahiro Katagiri",
        "Satoshi Ohshima",
        "Masatoshi Kawai",
        "Toru Nagai",
        "Tetsuya Hoshino"
      ],
      "abstract": "Concerns have arisen regarding the unregulated utilization of artificial\nintelligence (AI) outputs, potentially leading to various societal issues.\nWhile humans routinely validate information, manually inspecting the vast\nvolumes of AI-generated results is impractical. Therefore, automation and\nvisualization are imperative. In this context, Explainable AI (XAI) technology\nis gaining prominence, aiming to streamline AI model development and alleviate\nthe burden of explaining AI outputs to users. Simultaneously, software\nauto-tuning (AT) technology has emerged, aiming to reduce the man-hours\nrequired for performance tuning in numerical calculations. AT is a potent tool\nfor cost reduction during parameter optimization and high-performance\nprogramming for numerical computing. The synergy between AT mechanisms and AI\ntechnology is noteworthy, with AI finding extensive applications in AT.\nHowever, applying AI to AT mechanisms introduces challenges in AI model\nexplainability. This research focuses on XAI for AI models when integrated into\ntwo different processes for practical numerical computations: performance\nparameter tuning of accuracy-guaranteed numerical calculations and sparse\niterative algorithm.",
      "tldr_zh": "该研究探讨了将 Explainable AI (XAI) 技术适应于软件 auto-tuning (AT) 的应用，以解决 AI 在数值计算库中的模型可解释性挑战。背景在于 AI 输出可能引发社会问题，而手动验证不切实际，因此需要自动化和可视化手段。研究重点关注 XAI 在两个实际数值计算过程中的整合：精度保证的性能参数调优和稀疏迭代算法，从而提升 AT 的效率和 AI 的可信度。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.MS"
      ],
      "primary_category": "cs.SE",
      "comment": "This article has been submitted to Special Session: Performance\n  Optimization and Auto-Tuning of Software on Multicore/Manycore Systems\n  (POAT), In conjunction with IEEE MCSoC-2024 (Dec 16-19, 2024, Days Hotel &\n  Suites by Wyndham Fraser Business Park, Kuala Lumpur)",
      "pdf_url": "http://arxiv.org/pdf/2405.10973v1",
      "published_date": "2024-05-12 09:00:56 UTC",
      "updated_date": "2024-05-12 09:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:55:05.180729"
    },
    {
      "arxiv_id": "2405.07223v1",
      "title": "Ensemble Successor Representations for Task Generalization in Offline-to-Online Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Changhong Wang",
        "Xudong Yu",
        "Chenjia Bai",
        "Qiaosheng Zhang",
        "Zhen Wang"
      ],
      "abstract": "In Reinforcement Learning (RL), training a policy from scratch with online\nexperiences can be inefficient because of the difficulties in exploration.\nRecently, offline RL provides a promising solution by giving an initialized\noffline policy, which can be refined through online interactions. However,\nexisting approaches primarily perform offline and online learning in the same\ntask, without considering the task generalization problem in offline-to-online\nadaptation. In real-world applications, it is common that we only have an\noffline dataset from a specific task while aiming for fast online-adaptation\nfor several tasks. To address this problem, our work builds upon the\ninvestigation of successor representations for task generalization in online RL\nand extends the framework to incorporate offline-to-online learning. We\ndemonstrate that the conventional paradigm using successor features cannot\neffectively utilize offline data and improve the performance for the new task\nby online fine-tuning. To mitigate this, we introduce a novel methodology that\nleverages offline data to acquire an ensemble of successor representations and\nsubsequently constructs ensemble Q functions. This approach enables robust\nrepresentation learning from datasets with different coverage and facilitates\nfast adaption of Q functions towards new tasks during the online fine-tuning\nphase. Extensive empirical evaluations provide compelling evidence showcasing\nthe superior performance of our method in generalizing to diverse or even\nunseen tasks.",
      "tldr_zh": "本文探讨了强化学习（RL）中离线到在线学习的任务泛化问题，指出现有方法难以有效利用离线数据来适应新任务。作者提出一种新方法，利用离线数据训练后继表示的集合（ensemble of successor representations），并构建 ensemble Q functions，以实现鲁棒表示学习和快速在线微调。实验结果显示，该方法在泛化到多样或未见任务时，比传统方法表现出显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by Science China Information Sciences",
      "pdf_url": "http://arxiv.org/pdf/2405.07223v1",
      "published_date": "2024-05-12 08:52:52 UTC",
      "updated_date": "2024-05-12 08:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:55:17.782229"
    },
    {
      "arxiv_id": "2405.07220v1",
      "title": "On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Inwoo Hwang",
        "Yunhyeok Kwak",
        "Yeon-Ji Song",
        "Byoung-Tak Zhang",
        "Sanghack Lee"
      ],
      "abstract": "Conditional independence provides a way to understand causal relationships\namong the variables of interest. An underlying system may exhibit more\nfine-grained causal relationships especially between a variable and its\nparents, which will be called the local independence relationships. One of the\nmost widely studied local relationships is Context-Specific Independence (CSI),\nwhich holds in a specific assignment of conditioned variables. However, its\napplicability is often limited since it does not allow continuous variables:\ndata conditioned to the specific value of a continuous variable contains few\ninstances, if not none, making it infeasible to test independence. In this\nwork, we define and characterize the local independence relationship that holds\nin a specific set of joint assignments of parental variables, which we call\ncontext-set specific independence (CSSI). We then provide a canonical\nrepresentation of CSSI and prove its fundamental properties. Based on our\ntheoretical findings, we cast the problem of discovering multiple CSSI\nrelationships in a system as finding a partition of the joint outcome space.\nFinally, we propose a novel method, coined neural contextual decomposition\n(NCD), which learns such partition by imposing each set to induce CSSI via\nmodeling a conditional distribution. We empirically demonstrate that the\nproposed method successfully discovers the ground truth local independence\nrelationships in both synthetic dataset and complex system reflecting the\nreal-world physical dynamics.",
      "tldr_zh": "这篇论文探讨了变量间局部独立关系（Local Independence），特别是针对连续变量的挑战，提出了 context-set specific independence (CSSI) 概念，以克服传统 Context-Specific Independence (CSI) 在连续变量数据稀少问题上的局限性。作者提供了 CSSI 的规范表示，证明了其基本属性，并将发现多个 CSSI 关系的问题转化为联合结果空间的划分。最终，他们提出 neural contextual decomposition (NCD) 方法，通过学习条件分布来实现这种划分，并在合成数据集和真实世界物理动态系统中实验验证了其准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Conference on Causal Learning and Reasoning (CLeaR), 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.07220v1",
      "published_date": "2024-05-12 08:48:37 UTC",
      "updated_date": "2024-05-12 08:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:55:31.099030"
    },
    {
      "arxiv_id": "2405.07212v1",
      "title": "Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective",
      "title_zh": "通过LLM辅助推理增强优化中的决策：一个神经网络视角",
      "authors": [
        "Gaurav Singh",
        "Kavitesh Kumar Bali"
      ],
      "abstract": "This paper explores the seamless integration of Generative AI (GenAI) and\nEvolutionary Algorithms (EAs) within the domain of large-scale multi-objective\noptimization. Focusing on the transformative role of Large Language Models\n(LLMs), our study investigates the potential of LLM-Assisted Inference to\nautomate and enhance decision-making processes. Specifically, we highlight its\neffectiveness in illuminating key decision variables in evolutionarily\noptimized solutions while articulating contextual trade-offs. Tailored to\naddress the challenges inherent in inferring complex multi-objective\noptimization solutions at scale, our approach emphasizes the adaptive nature of\nLLMs, allowing them to provide nuanced explanations and align their language\nwith diverse stakeholder expertise levels and domain preferences. Empirical\nstudies underscore the practical applicability and impact of LLM-Assisted\nInference in real-world decision-making scenarios.",
      "tldr_zh": "这篇论文探讨了在大型多目标优化领域中整合Generative AI (GenAI) 和Evolutionary Algorithms (EAs)，特别强调Large Language Models (LLMs) 的辅助推理（LLM-Assisted Inference）来自动化和提升决策过程。研究方法聚焦于使用LLMs 突出进化优化解决方案中的关键决策变量、解释上下文权衡，并根据不同利益相关者的专业水平和领域偏好提供适应性解释。实证研究证明了这一方法在真实决策场景中的实用性和显著影响。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted IJCNN",
      "pdf_url": "http://arxiv.org/pdf/2405.07212v1",
      "published_date": "2024-05-12 08:22:53 UTC",
      "updated_date": "2024-05-12 08:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:55:42.188799"
    },
    {
      "arxiv_id": "2405.07202v1",
      "title": "Unified Video-Language Pre-training with Synchronized Audio",
      "title_zh": "统一视频-语言预训练，结合",
      "authors": [
        "Shentong Mo",
        "Haofan Wang",
        "Huaxia Li",
        "Xu Tang"
      ],
      "abstract": "Video-language pre-training is a typical and challenging problem that aims at\nlearning visual and textual representations from large-scale data in a\nself-supervised way. Existing pre-training approaches either captured the\ncorrespondence of image-text pairs or utilized temporal ordering of frames.\nHowever, they do not explicitly explore the natural synchronization between\naudio and the other two modalities. In this work, we propose an enhanced\nframework for Video-Language pre-training with Synchronized Audio, termed as\nVLSA, that can learn tri-modal representations in a unified self-supervised\ntransformer. Specifically, our VLSA jointly aggregates embeddings of local\npatches and global tokens for video, text, and audio. Furthermore, we utilize\nlocal-patch masked modeling to learn modality-aware features, and leverage\nglobal audio matching to capture audio-guided features for video and text. We\nconduct extensive experiments on retrieval across text, video, and audio. Our\nsimple model pre-trained on only 0.9M data achieves improving results against\nstate-of-the-art baselines. In addition, qualitative visualizations vividly\nshowcase the superiority of our VLSA in learning discriminative visual-textual\nrepresentations.",
      "tldr_zh": "本研究针对视频-语言预训练问题，提出了一种名为 VLSA 的框架，该框架首次明确整合同步音频，以自监督方式学习视频、文本和音频的三模态表示。VLSA 采用统一的 self-supervised transformer 模型，联合聚合局部补丁和全局标记的嵌入，并通过局部补丁掩码建模学习模态感知特征，以及全局音频匹配捕获音频引导的视频和文本特征。实验结果显示，该模型仅在 0.9M 数据上预训练，就在文本、视频和音频检索任务上超过了最先进基线，且定性可视化证明了 VLSA 在学习判别性视觉-文本表示方面的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07202v1",
      "published_date": "2024-05-12 07:59:46 UTC",
      "updated_date": "2024-05-12 07:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:55:54.859292"
    },
    {
      "arxiv_id": "2405.07200v3",
      "title": "Chebyshev Polynomial-Based Kolmogorov-Arnold Networks: An Efficient Architecture for Nonlinear Function Approximation",
      "title_zh": "基于切比雪夫多项式的 Kolmogorov-Arnold 网络：一种用于非线性函数逼近的高效架构",
      "authors": [
        "Sidharth SS",
        "Keerthana AR",
        "Gokul R",
        "Anas KP"
      ],
      "abstract": "Accurate approximation of complex nonlinear functions is a fundamental\nchallenge across many scientific and engineering domains. Traditional neural\nnetwork architectures, such as Multi-Layer Perceptrons (MLPs), often struggle\nto efficiently capture intricate patterns and irregularities present in\nhigh-dimensional functions. This paper presents the Chebyshev Kolmogorov-Arnold\nNetwork (Chebyshev KAN), a new neural network architecture inspired by the\nKolmogorov-Arnold representation theorem, incorporating the powerful\napproximation capabilities of Chebyshev polynomials. By utilizing learnable\nfunctions parametrized by Chebyshev polynomials on the network's edges,\nChebyshev KANs enhance flexibility, efficiency, and interpretability in\nfunction approximation tasks. We demonstrate the efficacy of Chebyshev KANs\nthrough experiments on digit classification, synthetic function approximation,\nand fractal function generation, highlighting their superiority over\ntraditional MLPs in terms of parameter efficiency and interpretability. Our\ncomprehensive evaluation, including ablation studies, confirms the potential of\nChebyshev KANs to address longstanding challenges in nonlinear function\napproximation, paving the way for further advancements in various scientific\nand engineering applications.",
      "tldr_zh": "本论文提出 Chebyshev Kolmogorov-Arnold Network (Chebyshev KAN)，一种基于 Kolmogorov-Arnold 表示定理并整合 Chebyshev 多项式的神经网络架构，用于高效逼近复杂非线性函数。\n该架构通过在网络边上使用 Chebyshev 多项式参数化的可学习函数，提升了模型的灵活性、效率和可解释性，解决了传统 Multi-Layer Perceptrons (MLPs) 在处理高维函数模式时的局限性。\n实验结果显示，Chebyshev KAN 在数字分类、合成函数逼近和分形函数生成任务中，参数效率和性能均优于 MLPs。\n这项创新为非线性函数逼近领域的长期挑战提供了新路径，并有望应用于各种科学和工程领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07200v3",
      "published_date": "2024-05-12 07:55:43 UTC",
      "updated_date": "2024-06-14 15:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:56:07.358745"
    },
    {
      "arxiv_id": "2405.07195v1",
      "title": "InsightNet: Structured Insight Mining from Customer Feedback",
      "title_zh": "InsightNet：从客户反馈中进行结构化洞察挖掘",
      "authors": [
        "Sandeep Sricharan Mukku",
        "Manan Soni",
        "Jitenkumar Rana",
        "Chetan Aggarwal",
        "Promod Yenigalla",
        "Rashmi Patange",
        "Shyam Mohan"
      ],
      "abstract": "We propose InsightNet, a novel approach for the automated extraction of\nstructured insights from customer reviews. Our end-to-end machine learning\nframework is designed to overcome the limitations of current solutions,\nincluding the absence of structure for identified topics, non-standard aspect\nnames, and lack of abundant training data. The proposed solution builds a\nsemi-supervised multi-level taxonomy from raw reviews, a semantic similarity\nheuristic approach to generate labelled data and employs a multi-task insight\nextraction architecture by fine-tuning an LLM. InsightNet identifies granular\nactionable topics with customer sentiments and verbatim for each topic.\nEvaluations on real-world customer review data show that InsightNet performs\nbetter than existing solutions in terms of structure, hierarchy and\ncompleteness. We empirically demonstrate that InsightNet outperforms the\ncurrent state-of-the-art methods in multi-label topic classification, achieving\nan F1 score of 0.85, which is an improvement of 11% F1-score over the previous\nbest results. Additionally, InsightNet generalises well for unseen aspects and\nsuggests new topics to be added to the taxonomy.",
      "tldr_zh": "我们提出 InsightNet，一种从客户评论中自动提取结构化洞察的端到端机器学习框架，旨在解决现有方法在结构缺失、非标准方面名称和训练数据不足等方面的局限性。该框架通过构建半监督的多级分类法、语义相似性启发式生成标记数据，并微调 LLM 的多任务洞察提取架构，来识别细粒度的可操作主题、客户情感和相关原话。在真实世界数据上的评估显示，InsightNet 在多标签主题分类中实现 F1 score 0.85，比现有最佳方法提高 11%，并在结构、层次和完整性上表现出色，同时具备对未见方面的泛化能力和添加新主题的建议功能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.07195v1",
      "published_date": "2024-05-12 07:40:12 UTC",
      "updated_date": "2024-05-12 07:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:56:18.447761"
    },
    {
      "arxiv_id": "2405.07194v1",
      "title": "Differentiable Model Scaling using Differentiable Topk",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Liu",
        "Ruohui Wang",
        "Jianfei Gao",
        "Kai Chen"
      ],
      "abstract": "Over the past few years, as large language models have ushered in an era of\nintelligence emergence, there has been an intensified focus on scaling\nnetworks. Currently, many network architectures are designed manually, often\nresulting in sub-optimal configurations. Although Neural Architecture Search\n(NAS) methods have been proposed to automate this process, they suffer from low\nsearch efficiency. This study introduces Differentiable Model Scaling (DMS),\nincreasing the efficiency for searching optimal width and depth in networks.\nDMS can model both width and depth in a direct and fully differentiable way,\nmaking it easy to optimize. We have evaluated our DMS across diverse tasks,\nranging from vision tasks to NLP tasks and various network architectures,\nincluding CNNs and Transformers. Results consistently indicate that our DMS can\nfind improved structures and outperforms state-of-the-art NAS methods.\nSpecifically, for image classification on ImageNet, our DMS improves the top-1\naccuracy of EfficientNet-B0 and Deit-Tiny by 1.4% and 0.6%, respectively, and\noutperforms the state-of-the-art zero-shot NAS method, ZiCo, by 1.3% while\nrequiring only 0.4 GPU days for searching. For object detection on COCO, DMS\nimproves the mAP of Yolo-v8-n by 2.0%. For language modeling, our pruned\nLlama-7B outperforms the prior method with lower perplexity and higher\nzero-shot classification accuracy. We will release our code in the future.",
      "tldr_zh": "本文提出 Differentiable Model Scaling (DMS) 方法，使用 Differentiable Topk 技术来高效搜索网络的最佳宽度和深度，解决传统 Neural Architecture Search (NAS) 方法效率低的问题。DMS 通过直接且完全可微的方式优化模型架构，适用于视觉任务（如 ImageNet 图像分类）和 NLP 任务，涵盖 CNN 和 Transformer 架构。实验结果显示，DMS 显著提升性能，例如在 ImageNet 上提高 EfficientNet-B0 的 top-1 accuracy 1.4% 和 Deit-Tiny 的 0.6%，在 COCO 对象检测上提升 Yolo-v8-n 的 mAP 2.0%，并在语言建模中使修剪后的 Llama-7B 模型获得更低的 perplexity 和更高的零样本分类准确率。作者计划未来发布代码，以进一步推动相关研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07194v1",
      "published_date": "2024-05-12 07:34:33 UTC",
      "updated_date": "2024-05-12 07:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:56:34.619417"
    },
    {
      "arxiv_id": "2405.07163v1",
      "title": "Realizing Visual Question Answering for Education: GPT-4V as a Multimodal AI",
      "title_zh": "翻译失败",
      "authors": [
        "Gyeong-Geon Lee",
        "Xiaoming Zhai"
      ],
      "abstract": "Educational scholars have analyzed various image data acquired from teaching\nand learning situations, such as photos that shows classroom dynamics,\nstudents' drawings with regard to the learning content, textbook illustrations,\netc. Unquestioningly, most qualitative analysis of and explanation on image\ndata have been conducted by human researchers, without machine-based\nautomation. It was partially because most image processing artificial\nintelligence models were not accessible to general educational scholars or\nexplainable due to their complex deep neural network architecture. However, the\nrecent development of Visual Question Answering (VQA) techniques is\naccomplishing usable visual language models, which receive from the user a\nquestion about the given image and returns an answer, both in natural language.\nParticularly, GPT-4V released by OpenAI, has wide opened the state-of-the-art\nvisual langauge model service so that VQA could be used for a variety of\npurposes. However, VQA and GPT-4V have not yet been applied to educational\nstudies much. In this position paper, we suggest that GPT-4V contributes to\nrealizing VQA for education. By 'realizing' VQA, we denote two meanings: (1)\nGPT-4V realizes the utilization of VQA techniques by any educational scholars\nwithout technical/accessibility barrier, and (2) GPT-4V makes educational\nscholars realize the usefulness of VQA to educational research. Given these,\nthis paper aims to introduce VQA for educational studies so that it provides a\nmilestone for educational research methodology. In this paper, chapter II\nreviews the development of VQA techniques, which primes with the release of\nGPT-4V. Chapter III reviews the use of image analysis in educational studies.\nChapter IV demonstrates how GPT-4V can be used for each research usage reviewed\nin Chapter III, with operating prompts provided. Finally, chapter V discusses\nthe future implications.",
      "tldr_zh": "这篇论文探讨了在教育领域实现 Visual Question Answering (VQA) 的潜力，将 GPT-4V 作为多模态 AI 工具，用于分析教学图像数据，如课堂照片和学生绘图。论文指出，传统图像分析依赖人类操作，但 GPT-4V 消除了技术障碍，使教育学者无需专业知识即可使用 VQA 技术。作者通过回顾 VQA 发展、图像在教育中的应用，并提供具体提示示例，展示了 GPT-4V 如何提升教育研究效率，并讨论了其未来影响。",
      "categories": [
        "physics.ed-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ed-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07163v1",
      "published_date": "2024-05-12 05:05:31 UTC",
      "updated_date": "2024-05-12 05:05:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:56:42.796816"
    },
    {
      "arxiv_id": "2405.07162v3",
      "title": "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yuwei Zeng",
        "Yao Mu",
        "Lin Shao"
      ],
      "abstract": "Learning reward functions remains the bottleneck to equip a robot with a\nbroad repertoire of skills. Large Language Models (LLM) contain valuable\ntask-related knowledge that can potentially aid in the learning of reward\nfunctions. However, the proposed reward function can be imprecise, thus\nineffective which requires to be further grounded with environment information.\nWe proposed a method to learn rewards more efficiently in the absence of\nhumans. Our approach consists of two components: We first use the LLM to\npropose features and parameterization of the reward, then update the parameters\nthrough an iterative self-alignment process. In particular, the process\nminimizes the ranking inconsistency between the LLM and the learnt reward\nfunctions based on the execution feedback. The method was validated on 9 tasks\nacross 2 simulation environments. It demonstrates a consistent improvement over\ntraining efficacy and efficiency, meanwhile consuming significantly fewer GPT\ntokens compared to the alternative mutation-based method.",
      "tldr_zh": "本论文提出了一种使用 Large Language Models (LLM) 通过自对齐(self-alignment)过程来学习机器人技能奖励函数的方法，以解决奖励函数学习效率低下的瓶颈问题。方法包括先利用 LLM 提出奖励的特征和参数化，然后通过迭代过程基于执行反馈最小化 LLM 与学习奖励函数之间的排名不一致性，从而提高奖励函数的精确性。在 9 个任务和 2 个模拟环境中进行验证，结果显示该方法显著提升了训练效率和效果，同时比突变-based 方法消耗更少的 GPT tokens。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.07162v3",
      "published_date": "2024-05-12 04:57:43 UTC",
      "updated_date": "2024-05-16 02:37:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:56:54.688233"
    },
    {
      "arxiv_id": "2406.00005v1",
      "title": "Disentangling Specificity for Abstractive Multi-document Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Congbo Ma",
        "Wei Emma Zhang",
        "Hu Wang",
        "Haojie Zhuang",
        "Mingyu Guo"
      ],
      "abstract": "Multi-document summarization (MDS) generates a summary from a document set.\nEach document in a set describes topic-relevant concepts, while per document\nalso has its unique contents. However, the document specificity receives little\nattention from existing MDS approaches. Neglecting specific information for\neach document limits the comprehensiveness of the generated summaries. To solve\nthis problem, in this paper, we propose to disentangle the specific content\nfrom documents in one document set. The document-specific representations,\nwhich are encouraged to be distant from each other via a proposed orthogonal\nconstraint, are learned by the specific representation learner. We provide\nextensive analysis and have interesting findings that specific information and\ndocument set representations contribute distinctive strengths and their\ncombination yields a more comprehensive solution for the MDS. Also, we find\nthat the common (i.e. shared) information could not contribute much to the\noverall performance under the MDS settings. Implemetation codes are available\nat https://github.com/congboma/DisentangleSum.",
      "tldr_zh": "该论文针对抽象式多文档摘要(MDS)的问题，提出了一种分离(disentangling)文档特定性的方法，以提升摘要的全面性。研究通过特定表示学习器(specific representation learner)和正交约束(orthogonal constraint)来学习文档间相互远离的特定表示，从而更好地捕捉每个文档的独特内容。实验分析发现，特定信息与文档集表示的结合能提供更全面的MDS解决方案，而共享信息对性能贡献有限；相关代码已在GitHub上公开。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "The IEEE World Congress on Computational Intelligence (WCCI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.00005v1",
      "published_date": "2024-05-12 04:36:19 UTC",
      "updated_date": "2024-05-12 04:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:57:06.916684"
    },
    {
      "arxiv_id": "2405.07157v1",
      "title": "Semi-Self-Supervised Domain Adaptation: Developing Deep Learning Models with Limited Annotated Data for Wheat Head Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Ghanbari",
        "Gholamhassan Shirdel",
        "Farhad Maleki"
      ],
      "abstract": "Precision agriculture involves the application of advanced technologies to\nimprove agricultural productivity, efficiency, and profitability while\nminimizing waste and environmental impact. Deep learning approaches enable\nautomated decision-making for many visual tasks. However, in the agricultural\ndomain, variability in growth stages and environmental conditions, such as\nweather and lighting, presents significant challenges to developing deep\nlearning-based techniques that generalize across different conditions. The\nresource-intensive nature of creating extensive annotated datasets that capture\nthese variabilities further hinders the widespread adoption of these\napproaches. To tackle these issues, we introduce a semi-self-supervised domain\nadaptation technique based on deep convolutional neural networks with a\nprobabilistic diffusion process, requiring minimal manual data annotation.\nUsing only three manually annotated images and a selection of video clips from\nwheat fields, we generated a large-scale computationally annotated dataset of\nimage-mask pairs and a large dataset of unannotated images extracted from video\nframes. We developed a two-branch convolutional encoder-decoder model\narchitecture that uses both synthesized image-mask pairs and unannotated\nimages, enabling effective adaptation to real images. The proposed model\nachieved a Dice score of 80.7\\% on an internal test dataset and a Dice score of\n64.8\\% on an external test set, composed of images from five countries and\nspanning 18 domains, indicating its potential to develop generalizable\nsolutions that could encourage the wider adoption of advanced technologies in\nagriculture.",
      "tldr_zh": "本研究提出了一种半-self-supervised domain adaptation技术，旨在解决农业领域深度学习模型在环境变异（如生长阶段和天气条件）下泛化性差的问题，仅需少量标注数据（如3张手动标注图像和视频剪辑）。该方法利用深度卷积神经网络结合概率扩散过程，生成大规模计算标注数据集（图像-掩码对）和未标注图像数据集，并开发了一个双分支卷积编码器-解码器模型来处理合成数据和真实图像，实现高效域适应。实验结果显示，该模型在内部测试集上达到80.7%的Dice score，在跨5个国家和18个领域的外部测试集上达到64.8%的Dice score，证明了其潜力在促进精确农业中深度学习的广泛应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12",
      "pdf_url": "http://arxiv.org/pdf/2405.07157v1",
      "published_date": "2024-05-12 04:35:49 UTC",
      "updated_date": "2024-05-12 04:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:57:19.875125"
    },
    {
      "arxiv_id": "2406.00004v4",
      "title": "Navigating the Future of Federated Recommendation Systems with Foundation Models",
      "title_zh": "通过基础模型导航联邦推荐系统的未来",
      "authors": [
        "Zhiwei Li",
        "Guodong Long",
        "Chunxu Zhang",
        "Honglei Zhang",
        "Jing Jiang",
        "Chengqi Zhang"
      ],
      "abstract": "Federated Recommendation Systems (FRSs) offer a privacy-preserving\nalternative to traditional centralized approaches by decentralizing data\nstorage. However, they face persistent challenges such as data sparsity and\nheterogeneity, largely due to isolated client environments. Recent advances in\nFoundation Models (FMs), particularly large language models like ChatGPT,\npresent an opportunity to surmount these issues through powerful, cross-task\nknowledge transfer. In this position paper, we systematically examine the\nconvergence of FRSs and FMs, illustrating how FM-enhanced frameworks can\nsubstantially improve client-side personalization, communication efficiency,\nand server-side aggregation. We also delve into pivotal challenges introduced\nby this integration, including privacy-security trade-offs, non-IID data, and\nresource constraints in federated setups, and propose prospective research\ndirections in areas such as multimodal recommendation, real-time FM adaptation,\nand explainable federated reasoning. By unifying FRSs with FMs, our position\npaper provides a forward-looking roadmap for advancing privacy-preserving,\nhigh-performance recommendation systems that fully leverage large-scale\npre-trained knowledge to enhance local performance.",
      "tldr_zh": "本论文探讨了Federated Recommendation Systems (FRSs) 的未来发展，通过整合Foundation Models (FMs) 如ChatGPT来解决数据稀疏性和异质性等挑战。作者提出FM增强框架可显著提升客户端个性化、通信效率和服务器端聚合，从而实现隐私保护下的高性能推荐系统。论文还分析了整合带来的关键问题，如隐私安全权衡、非IID数据和资源约束，并建议未来研究方向，包括多模态推荐、实时FM适应和可解释的联邦推理，提供了一个前瞻性路线图。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "11 pages, position paper, survey",
      "pdf_url": "http://arxiv.org/pdf/2406.00004v4",
      "published_date": "2024-05-12 04:15:05 UTC",
      "updated_date": "2025-04-11 08:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:57:32.680582"
    },
    {
      "arxiv_id": "2405.07142v1",
      "title": "Cross-Domain Continual Learning via CLAMP",
      "title_zh": "翻译失败",
      "authors": [
        "Weiwei Weng",
        "Mahardhika Pratama",
        "Jie Zhang",
        "Chen Chen",
        "Edward Yapp Kien Yee",
        "Ramasamy Savitha"
      ],
      "abstract": "Artificial neural networks, celebrated for their human-like cognitive\nlearning abilities, often encounter the well-known catastrophic forgetting (CF)\nproblem, where the neural networks lose the proficiency in previously acquired\nknowledge. Despite numerous efforts to mitigate CF, it remains the significant\nchallenge particularly in complex changing environments. This challenge is even\nmore pronounced in cross-domain adaptation following the continual learning\n(CL) setting, which is a more challenging and realistic scenario that is\nunder-explored. To this end, this article proposes a cross-domain CL approach\nmaking possible to deploy a single model in such environments without\nadditional labelling costs. Our approach, namely continual learning approach\nfor many processes (CLAMP), integrates a class-aware adversarial domain\nadaptation strategy to align a source domain and a target domain. An\nassessor-guided learning process is put forward to navigate the learning\nprocess of a base model assigning a set of weights to every sample controlling\nthe influence of every sample and the interactions of each loss function in\nsuch a way to balance the stability and plasticity dilemma thus preventing the\nCF problem. The first assessor focuses on the negative transfer problem\nrejecting irrelevant samples of the source domain while the second assessor\nprevents noisy pseudo labels of the target domain. Both assessors are trained\nin the meta-learning approach using random transformation techniques and\nsimilar samples of the source domain. Theoretical analysis and extensive\nnumerical validations demonstrate that CLAMP significantly outperforms\nestablished baseline algorithms across all experiments by at least $10\\%$\nmargin.",
      "tldr_zh": "这篇论文针对神经网络的灾难性遗忘（catastrophic forgetting, CF）问题，特别是在跨域持续学习（cross-domain continual learning, CL）场景中，提出了一种名为 CLAMP 的方法，以实现单个模型在复杂环境中的部署，而无需额外标注。CLAMP 整合了类感知对抗域适应策略（class-aware adversarial domain adaptation strategy）来对齐源域和目标域，并引入评估器引导的学习过程，通过为每个样本分配权重来平衡稳定性（stability）和可塑性（plasticity），从而防止 CF。两个评估器分别处理负转移问题（negative transfer）和目标域的噪声伪标签（noisy pseudo labels），并采用元学习（meta-learning）和随机变换技术进行训练。实验结果表明，CLAMP 在所有测试中比基线算法至少提高了 10%，证明了其显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review in Elsevier Journal",
      "pdf_url": "http://arxiv.org/pdf/2405.07142v1",
      "published_date": "2024-05-12 02:41:31 UTC",
      "updated_date": "2024-05-12 02:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:57:46.725697"
    },
    {
      "arxiv_id": "2405.07140v1",
      "title": "Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyuan Zhang",
        "Jiang Liu",
        "Zehui Xiong",
        "Yudong Huang",
        "Gaochang Xie",
        "Ran Zhang"
      ],
      "abstract": "Generative Artificial Intelligence (GAI) is taking the world by storm with\nits unparalleled content creation ability. Large Language Models (LLMs) are at\nthe forefront of this movement. However, the significant resource demands of\nLLMs often require cloud hosting, which raises issues regarding privacy,\nlatency, and usage limitations. Although edge intelligence has long been\nutilized to solve these challenges by enabling real-time AI computation on\nubiquitous edge resources close to data sources, most research has focused on\ntraditional AI models and has left a gap in addressing the unique\ncharacteristics of LLM inference, such as considerable model size,\nauto-regressive processes, and self-attention mechanisms. In this paper, we\npresent an edge intelligence optimization problem tailored for LLM inference.\nSpecifically, with the deployment of the batching technique and model\nquantization on resource-limited edge devices, we formulate an inference model\nfor transformer decoder-based LLMs. Furthermore, our approach aims to maximize\nthe inference throughput via batch scheduling and joint allocation of\ncommunication and computation resources, while also considering edge resource\nconstraints and varying user requirements of latency and accuracy. To address\nthis NP-hard problem, we develop an optimal Depth-First Tree-Searching\nalgorithm with online tree-Pruning (DFTSP) that operates within a feasible time\ncomplexity. Simulation results indicate that DFTSP surpasses other batching\nbenchmarks in throughput across diverse user settings and quantization\ntechniques, and it reduces time complexity by over 45% compared to the\nbrute-force searching method.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)推理的资源需求问题，提出一种边智能优化方案，以解决隐私、延迟和使用限制的挑战。研究通过引入batching技术和模型quantization，在资源有限的边设备上部署transformer解码器-based LLMs，并联合分配通信和计算资源来最大化推理吞吐量，同时考虑用户对延迟和准确性的需求。为解决这一NP-hard问题，作者开发了Depth-First Tree-Searching with online tree-Pruning (DFTSP)算法，该算法在可接受的时间复杂度内运行。模拟结果显示，DFTSP在各种用户设置和quantization技术下，显著提升了吞吐量，并将时间复杂度比暴力搜索方法降低了45%以上。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07140v1",
      "published_date": "2024-05-12 02:38:58 UTC",
      "updated_date": "2024-05-12 02:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:57:56.492972"
    },
    {
      "arxiv_id": "2405.07135v3",
      "title": "Post Training Quantization of Large Language Models with Microscaling Formats",
      "title_zh": "翻译失败",
      "authors": [
        "Sayeh Sharify",
        "Utkarsh Saxena",
        "Zifei Xu",
        "Wanzin Yazar",
        "Ilya Soloveychik",
        "Xin Wang"
      ],
      "abstract": "Large Language Models (LLMs) have distinguished themselves with outstanding\nperformance in complex language modeling tasks, yet they come with significant\ncomputational and storage challenges. This paper explores the potential of\nquantization to mitigate these challenges. We systematically study the combined\napplication of three well-known post-training techniques, SmoothQuant, AWQ, and\nGPTQ, and provide a comprehensive analysis of their interactions and\nimplications for advancing LLM quantization. We enhance the versatility of\nthese methods by enabling quantization to microscaling (MX) formats, extending\nthe applicability of these PTQ algorithms beyond their original fixed-point\nformat targets. We show that combining different PTQ methods enables us to\nquantize models to 4-bit weights and 8-bit activations using the MXINT format\nwith negligible accuracy loss compared to the uncompressed baseline.",
      "tldr_zh": "这篇论文探讨了后训练量化（Post Training Quantization）技术，以缓解大型语言模型（LLMs）的计算和存储挑战。作者系统研究了 SmoothQuant、AWQ 和 GPTQ 三种方法的结合，并将其扩展到微缩放（Microscaling）格式，从而超越了原有固定点格式的限制。实验结果表明，通过 MXINT 格式将模型量化到 4-bit 权重和 8-bit 激活时，与未压缩基线相比，准确率损失几乎可以忽略，为高效的 LLM 部署提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07135v3",
      "published_date": "2024-05-12 02:15:26 UTC",
      "updated_date": "2024-10-15 18:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:58:08.479047"
    },
    {
      "arxiv_id": "2405.13001v1",
      "title": "Large Language Models for Education: A Survey",
      "title_zh": "大型语言模型在教育中的",
      "authors": [
        "Hanyi Xu",
        "Wensheng Gan",
        "Zhenlian Qi",
        "Jiayang Wu",
        "Philip S. Yu"
      ],
      "abstract": "Artificial intelligence (AI) has a profound impact on traditional education.\nIn recent years, large language models (LLMs) have been increasingly used in\nvarious applications such as natural language processing, computer vision,\nspeech recognition, and autonomous driving. LLMs have also been applied in many\nfields, including recommendation, finance, government, education, legal\naffairs, and finance. As powerful auxiliary tools, LLMs incorporate various\ntechnologies such as deep learning, pre-training, fine-tuning, and\nreinforcement learning. The use of LLMs for smart education (LLMEdu) has been a\nsignificant strategic direction for countries worldwide. While LLMs have shown\ngreat promise in improving teaching quality, changing education models, and\nmodifying teacher roles, the technologies are still facing several challenges.\nIn this paper, we conduct a systematic review of LLMEdu, focusing on current\ntechnologies, challenges, and future developments. We first summarize the\ncurrent state of LLMEdu and then introduce the characteristics of LLMs and\neducation, as well as the benefits of integrating LLMs into education. We also\nreview the process of integrating LLMs into the education industry, as well as\nthe introduction of related technologies. Finally, we discuss the challenges\nand problems faced by LLMEdu, as well as prospects for future optimization of\nLLMEdu.",
      "tldr_zh": "这篇论文对大语言模型 (LLMs) 在教育领域的应用进行了系统调查，探讨了 LLMs 如何通过深度学习、预训练、微调和强化学习等技术提升教学质量、变革教育模式并调整教师角色。调查总结了 LLMs 在智能教育 (LLMEdu) 中的当前状态、整合过程及其益处，同时分析了面临的挑战，如技术局限性和知识缺口。最终，论文展望了 LLMEdu 的未来优化方向，以推动全球教育战略的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Journal of Machine Learning and Cybernetics. 4 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13001v1",
      "published_date": "2024-05-12 01:50:01 UTC",
      "updated_date": "2024-05-12 01:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:58:20.252847"
    },
    {
      "arxiv_id": "2405.07117v1",
      "title": "Context Neural Networks: A Scalable Multivariate Model for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Abishek Sriramulu",
        "Christoph Bergmeir",
        "Slawek Smyl"
      ],
      "abstract": "Real-world time series often exhibit complex interdependencies that cannot be\ncaptured in isolation. Global models that model past data from multiple related\ntime series globally while producing series-specific forecasts locally are now\ncommon. However, their forecasts for each individual series remain isolated,\nfailing to account for the current state of its neighbouring series.\nMultivariate models like multivariate attention and graph neural networks can\nexplicitly incorporate inter-series information, thus addressing the\nshortcomings of global models. However, these techniques exhibit quadratic\ncomplexity per timestep, limiting scalability. This paper introduces the\nContext Neural Network, an efficient linear complexity approach for augmenting\ntime series models with relevant contextual insights from neighbouring time\nseries without significant computational overhead. The proposed method enriches\npredictive models by providing the target series with real-time information\nfrom its neighbours, addressing the limitations of global models, yet remaining\ncomputationally tractable for large datasets.",
      "tldr_zh": "该论文提出了 Context Neural Network，一种可扩展的多变量模型，用于时间序列预测，以解决传统全局 models 在处理复杂序列间依赖关系时的局限性。不同于 multivariate attention 和 graph neural networks 等二次复杂度的方法，该模型采用线性复杂度设计，通过从相邻时间序列获取相关上下文信息，实时增强目标序列的预测能力。实验结果表明，这种方法能在大型数据集上显著提高效率，同时保持预测的准确性和计算可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.07117v1",
      "published_date": "2024-05-12 00:21:57 UTC",
      "updated_date": "2024-05-12 00:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:58:31.861788"
    },
    {
      "arxiv_id": "2405.08717v1",
      "title": "How Much You Ate? Food Portion Estimation on Spoons",
      "title_zh": "翻译失败",
      "authors": [
        "Aaryam Sharma",
        "Chris Czarnecki",
        "Yuhao Chen",
        "Pengcheng Xi",
        "Linlin Xu",
        "Alexander Wong"
      ],
      "abstract": "Monitoring dietary intake is a crucial aspect of promoting healthy living. In\nrecent years, advances in computer vision technology have facilitated dietary\nintake monitoring through the use of images and depth cameras. However, the\ncurrent state-of-the-art image-based food portion estimation algorithms assume\nthat users take images of their meals one or two times, which can be\ninconvenient and fail to capture food items that are not visible from a\ntop-down perspective, such as ingredients submerged in a stew. To address these\nlimitations, we introduce an innovative solution that utilizes stationary\nuser-facing cameras to track food items on utensils, not requiring any change\nof camera perspective after installation. The shallow depth of utensils\nprovides a more favorable angle for capturing food items, and tracking them on\nthe utensil's surface offers a significantly more accurate estimation of\ndietary intake without the need for post-meal image capture. The system is\nreliable for estimation of nutritional content of liquid-solid heterogeneous\nmixtures such as soups and stews. Through a series of experiments, we\ndemonstrate the exceptional potential of our method as a non-invasive,\nuser-friendly, and highly accurate dietary intake monitoring tool.",
      "tldr_zh": "本文提出一种创新的食物部分估计方法（food portion estimation），利用固定用户面对相机跟踪餐具上的食物，避免了传统图像-based 算法需要多次拍摄的麻烦，并能捕捉不易从顶部视角观察的食物，如浸没在炖菜中的成分。该方法利用餐具的浅深度提供更佳的捕捉角度，实现对液体-固体混合物（如汤和炖菜）的准确营养估算，而无需餐后拍照。通过实验验证，该系统展示了非侵入性、高准确性和用户友好的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.08717v1",
      "published_date": "2024-05-12 00:16:02 UTC",
      "updated_date": "2024-05-12 00:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T07:58:44.390693"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 47,
  "processed_papers_count": 47,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T07:59:04.344908"
}