[
  {
    "arxiv_id": "2405.07395v1",
    "title": "CaFA: Global Weather Forecasting with Factorized Attention on Sphere",
    "authors": [
      "Zijie Li",
      "Anthony Zhou",
      "Saurabh Patil",
      "Amir Barati Farimani"
    ],
    "abstract": "Accurate weather forecasting is crucial in various sectors, impacting\ndecision-making processes and societal events. Data-driven approaches based on\nmachine learning models have recently emerged as a promising alternative to\nnumerical weather prediction models given their potential to capture physics of\ndifferent scales from historical data and the significantly lower computational\ncost during the prediction stage. Renowned for its state-of-the-art performance\nacross diverse domains, the Transformer model has also gained popularity in\nmachine learning weather prediction. Yet applying Transformer architectures to\nweather forecasting, particularly on a global scale is computationally\nchallenging due to the quadratic complexity of attention and the quadratic\nincrease in spatial points as resolution increases. In this work, we propose a\nfactorized-attention-based model tailored for spherical geometries to mitigate\nthis issue. More specifically, it utilizes multi-dimensional factorized kernels\nthat convolve over different axes where the computational complexity of the\nkernel is only quadratic to the axial resolution instead of overall resolution.\nThe deterministic forecasting accuracy of the proposed model on $1.5^\\circ$ and\n0-7 days' lead time is on par with state-of-the-art purely data-driven machine\nlearning weather prediction models. We also showcase the proposed model holds\ngreat potential to push forward the Pareto front of accuracy-efficiency for\nTransformer weather models, where it can achieve better accuracy with less\ncomputational cost compared to Transformer based models with standard\nattention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.07395v1",
    "published_date": "2024-05-12 23:18:14 UTC",
    "updated_date": "2024-05-12 23:18:14 UTC"
  },
  {
    "arxiv_id": "2405.07393v1",
    "title": "Intrinsic Fairness-Accuracy Tradeoffs under Equalized Odds",
    "authors": [
      "Meiyu Zhong",
      "Ravi Tandon"
    ],
    "abstract": "With the growing adoption of machine learning (ML) systems in areas like law\nenforcement, criminal justice, finance, hiring, and admissions, it is\nincreasingly critical to guarantee the fairness of decisions assisted by ML. In\nthis paper, we study the tradeoff between fairness and accuracy under the\nstatistical notion of equalized odds. We present a new upper bound on the\naccuracy (that holds for any classifier), as a function of the fairness budget.\nIn addition, our bounds also exhibit dependence on the underlying statistics of\nthe data, labels and the sensitive group attributes. We validate our\ntheoretical upper bounds through empirical analysis on three real-world\ndatasets: COMPAS, Adult, and Law School. Specifically, we compare our upper\nbound to the tradeoffs that are achieved by various existing fair classifiers\nin the literature. Our results show that achieving high accuracy subject to a\nlow-bias could be fundamentally limited based on the statistical disparity\nacross the groups.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07393v1",
    "published_date": "2024-05-12 23:15:21 UTC",
    "updated_date": "2024-05-12 23:15:21 UTC"
  },
  {
    "arxiv_id": "2405.07391v3",
    "title": "AnyRotate: Gravity-Invariant In-Hand Object Rotation with Sim-to-Real Touch",
    "authors": [
      "Max Yang",
      "Chenghua Lu",
      "Alex Church",
      "Yijiong Lin",
      "Chris Ford",
      "Haoran Li",
      "Efi Psomopoulou",
      "David A. W. Barton",
      "Nathan F. Lepora"
    ],
    "abstract": "Human hands are capable of in-hand manipulation in the presence of different\nhand motions. For a robot hand, harnessing rich tactile information to achieve\nthis level of dexterity still remains a significant challenge. In this paper,\nwe present AnyRotate, a system for gravity-invariant multi-axis in-hand object\nrotation using dense featured sim-to-real touch. We tackle this problem by\ntraining a dense tactile policy in simulation and present a sim-to-real method\nfor rich tactile sensing to achieve zero-shot policy transfer. Our formulation\nallows the training of a unified policy to rotate unseen objects about\narbitrary rotation axes in any hand direction. In our experiments, we highlight\nthe benefit of capturing detailed contact information when handling objects of\nvarying properties. Interestingly, we found rich multi-fingered tactile sensing\ncan detect unstable grasps and provide a reactive behavior that improves the\nrobustness of the policy. The project website can be found at\nhttps://maxyang27896.github.io/anyrotate/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website can be found at\n  https://maxyang27896.github.io/anyrotate/",
    "pdf_url": "http://arxiv.org/pdf/2405.07391v3",
    "published_date": "2024-05-12 22:51:35 UTC",
    "updated_date": "2024-11-03 16:22:30 UTC"
  },
  {
    "arxiv_id": "2405.08032v1",
    "title": "Exploring the Potential of Conversational AI Support for Agent-Based Social Simulation Model Design",
    "authors": [
      "Peer-Olaf Siebers"
    ],
    "abstract": "ChatGPT, the AI-powered chatbot with a massive user base of hundreds of\nmillions, has become a global phenomenon. However, the use of Conversational AI\nSystems (CAISs) like ChatGPT for research in the field of Social Simulation is\nstill limited. Specifically, there is no evidence of its usage in Agent-Based\nSocial Simulation (ABSS) model design. While scepticism towards anything new is\ninherent to human nature, we firmly believe it is imperative to initiate the\nuse of this innovative technology to support ABSS model design. This paper\npresents a proof-of-concept that demonstrates how CAISs can facilitate the\ndevelopment of innovative conceptual ABSS models in a concise timeframe and\nwith minimal required upfront case-based knowledge. By employing advanced\nprompt engineering techniques and adhering to the Engineering ABSS framework,\nwe have constructed a comprehensive prompt script that enables the design of\nABSS models with or by the CAIS. The effectiveness of the script is\ndemonstrated through an illustrative case study concerning the use of adaptive\narchitecture in museums. Despite occasional inaccuracies and divergences in\nconversation, the CAIS proved to be a valuable companion for ABSS modellers.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "29 pages, 3 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2405.08032v1",
    "published_date": "2024-05-12 22:11:54 UTC",
    "updated_date": "2024-05-12 22:11:54 UTC"
  },
  {
    "arxiv_id": "2405.08031v2",
    "title": "HGTDR: Advancing Drug Repurposing with Heterogeneous Graph Transformers",
    "authors": [
      "Ali Gharizadeh",
      "Karim Abbasi",
      "Amin Ghareyazi",
      "Mohammad R. K. Mofrad",
      "Hamid R. Rabiee"
    ],
    "abstract": "Motivation: Drug repurposing is a viable solution for reducing the time and\ncost associated with drug development. However, thus far, the proposed drug\nrepurposing approaches still need to meet expectations. Therefore, it is\ncrucial to offer a systematic approach for drug repurposing to achieve cost\nsavings and enhance human lives. In recent years, using biological\nnetwork-based methods for drug repurposing has generated promising results.\nNevertheless, these methods have limitations. Primarily, the scope of these\nmethods is generally limited concerning the size and variety of data they can\neffectively handle. Another issue arises from the treatment of heterogeneous\ndata, which needs to be addressed or converted into homogeneous data, leading\nto a loss of information. A significant drawback is that most of these\napproaches lack end-to-end functionality, necessitating manual implementation\nand expert knowledge in certain stages. Results: We propose a new solution,\nHGTDR (Heterogeneous Graph Transformer for Drug Repurposing), to address the\nchallenges associated with drug repurposing. HGTDR is a three-step approach for\nknowledge graph-based drug re-purposing: 1) constructing a heterogeneous\nknowledge graph, 2) utilizing a heterogeneous graph transformer network, and 3)\ncomputing relationship scores using a fully connected network. By leveraging\nHGTDR, users gain the ability to manipulate input graphs, extract information\nfrom diverse entities, and obtain their desired output. In the evaluation step,\nwe demonstrate that HGTDR performs comparably to previous methods. Furthermore,\nwe review medical studies to validate our method's top ten drug repurposing\nsuggestions, which have exhibited promising results. We also demon-strated\nHGTDR's capability to predict other types of relations through numerical and\nexperimental validation, such as drug-protein and disease-protein\ninter-relations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been archived without having permission from all\n  authors. Please withdraw",
    "pdf_url": "http://arxiv.org/pdf/2405.08031v2",
    "published_date": "2024-05-12 21:34:03 UTC",
    "updated_date": "2024-05-18 08:53:37 UTC"
  },
  {
    "arxiv_id": "2405.13005v2",
    "title": "Understanding Sarcoidosis Using Large Language Models and Social Media Data",
    "authors": [
      "Nan Miles Xi",
      "Hong-Long Ji",
      "Lin Wang"
    ],
    "abstract": "Sarcoidosis is a rare inflammatory disease characterized by the formation of\ngranulomas in various organs. The disease presents diagnostic and treatment\nchallenges due to its diverse manifestations and unpredictable nature. In this\nstudy, we employed a Large Language Model (LLM) to analyze sarcoidosis-related\ndiscussions on the social media platform Reddit. Our findings underscore the\nefficacy of LLMs in accurately identifying sarcoidosis-related content. We\ndiscovered a wide array of symptoms reported by patients, with fatigue, swollen\nlymph nodes, and shortness of breath as the most prevalent. Prednisone was the\nmost prescribed medication, while infliximab showed the highest effectiveness\nin improving prognoses. Notably, our analysis revealed disparities in prognosis\nbased on age and gender, with women and younger patients experiencing good and\npolarized outcomes, respectively. Furthermore, unsupervised clustering\nidentified three distinct patient subgroups (phenotypes) with unique symptom\nprofiles, prognostic outcomes, and demographic distributions. Finally,\nsentiment analysis revealed a moderate negative impact on patients' mental\nhealth post-diagnosis, particularly among women and younger individuals. Our\nstudy represents the first application of LLMs to understand sarcoidosis\nthrough social media data. It contributes to understanding the disease by\nproviding data-driven insights into its manifestations, treatments, prognoses,\nand impact on patients' lives. Our findings have direct implications for\nimproving personalized treatment strategies and enhancing the quality of care\nfor individuals living with sarcoidosis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13005v2",
    "published_date": "2024-05-12 20:54:23 UTC",
    "updated_date": "2024-10-27 21:48:23 UTC"
  },
  {
    "arxiv_id": "2405.07374v2",
    "title": "Conformalized Survival Distributions: A Generic Post-Process to Increase Calibration",
    "authors": [
      "Shi-ang Qi",
      "Yakun Yu",
      "Russell Greiner"
    ],
    "abstract": "Discrimination and calibration represent two important properties of survival\nanalysis, with the former assessing the model's ability to accurately rank\nsubjects and the latter evaluating the alignment of predicted outcomes with\nactual events. With their distinct nature, it is hard for survival models to\nsimultaneously optimize both of them especially as many previous results found\nimproving calibration tends to diminish discrimination performance. This paper\nintroduces a novel approach utilizing conformal regression that can improve a\nmodel's calibration without degrading discrimination. We provide theoretical\nguarantees for the above claim, and rigorously validate the efficiency of our\napproach across 11 real-world datasets, showcasing its practical applicability\nand robustness in diverse scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024; 37 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.07374v2",
    "published_date": "2024-05-12 20:27:34 UTC",
    "updated_date": "2024-06-03 03:32:56 UTC"
  },
  {
    "arxiv_id": "2405.07373v3",
    "title": "From Probability to Counterfactuals: the Increasing Complexity of Satisfiability in Pearl's Causal Hierarchy",
    "authors": [
      "Julian Dörfler",
      "Benito van der Zander",
      "Markus Bläser",
      "Maciej Liskiewicz"
    ],
    "abstract": "The framework of Pearl's Causal Hierarchy (PCH) formalizes three types of\nreasoning: probabilistic (i.e. purely observational), interventional, and\ncounterfactual, that reflect the progressive sophistication of human thought\nregarding causation. We investigate the computational complexity aspects of\nreasoning in this framework focusing mainly on satisfiability problems\nexpressed in probabilistic and causal languages across the PCH. That is, given\na system of formulas in the standard probabilistic and causal languages, does\nthere exist a model satisfying the formulas?\n  Our main contribution is to prove the exact computational complexities\nshowing that languages allowing addition and marginalization (via the summation\noperator) yield NP^PP, PSPACE-, and NEXP-complete satisfiability problems,\ndepending on the level of the PCH. These are the first results to demonstrate a\nstrictly increasing complexity across the PCH: from probabilistic to causal and\ncounterfactual reasoning. On the other hand, in the case of full languages,\ni.e. allowing addition, marginalization, and multiplication, we show that the\nsatisfiability for the counterfactual level remains the same as for the\nprobabilistic and causal levels, solving an open problem in the field.",
    "categories": [
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted at ICLR 25",
    "pdf_url": "http://arxiv.org/pdf/2405.07373v3",
    "published_date": "2024-05-12 20:25:36 UTC",
    "updated_date": "2025-02-06 18:53:16 UTC"
  },
  {
    "arxiv_id": "2405.13004v1",
    "title": "MathDivide: Improved mathematical reasoning by large language models",
    "authors": [
      "Saksham Sahai Srivastava",
      "Ashutosh Gandhi"
    ],
    "abstract": "Large language models have been proven to be capable of handling complex\nlinguistic and cognitive tasks. Therefore their usage has been extended to\ntasks requiring logical reasoning ability such as Mathematics. In this paper,\nwe propose a prompting technique called MathDivide that breaks down the\nmathematical problem into simpler subproblems. Each of the subproblems is\nformulated as an algebraic expression whose value is evaluated by the Python\ncode generated by the LLM for the corresponding algebraic expression. The\nvalues fed to the Python code are the numerical values provided in the problem\nstatement. The solutions for the subproblems are composed together to obtain\nthe final answer for the problem statement. Finally, the final answer is\ncompared to the correct answer. If the final answer matches the correct answer,\nit is produced as output else a refinement prompt is fed to the LLM. We\nexperiment with this prompting technique on both closed-source LLM models and\nopen-source LLM models using GSM8K dataset. The results obtained demonstrate\nthat MathDivide was able to significantly outperform the leading prompting\ntechnique called Math-prompter.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13004v1",
    "published_date": "2024-05-12 20:21:15 UTC",
    "updated_date": "2024-05-12 20:21:15 UTC"
  },
  {
    "arxiv_id": "2405.08029v2",
    "title": "PHUDGE: Phi-3 as Scalable Judge",
    "authors": [
      "Mahesh Deshwal",
      "Apoorva Chawla"
    ],
    "abstract": "In this paper cum technical report, we present PHUDGE A fine tuned Phi3 model\nthat achieved SOTA results in 4 tasks as Feedback Test, Feedback OOD, MT Human,\nPreference Test surpassing each and every existing model in latency and\nthroughput. It shows very strong correlation not only with GPT4 but with Human\nannotators too in unseen data as well as in both absolute and relative grading\ntasks. We have not only addressed the usage of small LMs for cost effective\nproduction grade systems but have also shown that Causal modelling is not only\nslow in nature but sometimes it can hinder models learning capabilities and\nshould be replaced by simpler tasks whenever we can to make the overall system\nfaster and better. We show that by following systematic ML experimentation,\nthoughtful data augmentation and re purposing the problem itself, we can even\nbeat 10x bigger models even with lesser training data. To the best of our\nknowledge, we are re the first one to experiment and showcase the usage of\ngeneralised version of Earth Movers Distance AKA Wasserstein distance by using\nMinkowski Distance with a penalty to control loss smoothing and can be used as\na loss function instead of Cross Entropy to get stable training and better\nresults for grading tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08029v2",
    "published_date": "2024-05-12 18:22:16 UTC",
    "updated_date": "2024-05-15 05:46:01 UTC"
  },
  {
    "arxiv_id": "2405.07349v1",
    "title": "WeedScout: Real-Time Autonomous blackgrass Classification and Mapping using dedicated hardware",
    "authors": [
      "Matthew Gazzard",
      "Helen Hicks",
      "Isibor Kennedy Ihianle",
      "Jordan J. Bird",
      "Md Mahmudul Hasan",
      "Pedro Machado"
    ],
    "abstract": "Blackgrass (Alopecurus myosuroides) is a competitive weed that has\nwide-ranging impacts on food security by reducing crop yields and increasing\ncultivation costs. In addition to the financial burden on agriculture, the\napplication of herbicides as a preventive to blackgrass can negatively affect\naccess to clean water and sanitation. The WeedScout project introduces a\nReal-Rime Autonomous Black-Grass Classification and Mapping (RT-ABGCM), a\ncutting-edge solution tailored for real-time detection of blackgrass, for\nprecision weed management practices. Leveraging Artificial Intelligence (AI)\nalgorithms, the system processes live image feeds, infers blackgrass density,\nand covers two stages of maturation. The research investigates the deployment\nof You Only Look Once (YOLO) models, specifically the streamlined YOLOv8 and\nYOLO-NAS, accelerated at the edge with the NVIDIA Jetson Nano (NJN). By\noptimising inference speed and model performance, the project advances the\nintegration of AI into agricultural practices, offering potential solutions to\nchallenges such as herbicide resistance and environmental impact. Additionally,\ntwo datasets and model weights are made available to the research community,\nfacilitating further advancements in weed detection and precision farming\ntechnologies.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07349v1",
    "published_date": "2024-05-12 18:04:41 UTC",
    "updated_date": "2024-05-12 18:04:41 UTC"
  },
  {
    "arxiv_id": "2405.07344v3",
    "title": "TKAN: Temporal Kolmogorov-Arnold Networks",
    "authors": [
      "Remi Genet",
      "Hugo Inzirillo"
    ],
    "abstract": "Recurrent Neural Networks (RNNs) have revolutionized many areas of machine\nlearning, particularly in natural language and data sequence processing. Long\nShort-Term Memory (LSTM) has demonstrated its ability to capture long-term\ndependencies in sequential data. Inspired by the Kolmogorov-Arnold Networks\n(KANs) a promising alternatives to Multi-Layer Perceptrons (MLPs), we proposed\na new neural networks architecture inspired by KAN and the LSTM, the Temporal\nKolomogorov-Arnold Networks (TKANs). TKANs combined the strenght of both\nnetworks, it is composed of Recurring Kolmogorov-Arnold Networks (RKANs) Layers\nembedding memory management. This innovation enables us to perform multi-step\ntime series forecasting with enhanced accuracy and efficiency. By addressing\nthe limitations of traditional models in handling complex sequential patterns,\nthe TKAN architecture offers significant potential for advancements in fields\nrequiring more than one step ahead forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07344v3",
    "published_date": "2024-05-12 17:40:48 UTC",
    "updated_date": "2024-12-17 17:13:03 UTC"
  },
  {
    "arxiv_id": "2405.07327v1",
    "title": "Liquid Ensemble Selection for Continual Learning",
    "authors": [
      "Carter Blair",
      "Ben Armstrong",
      "Kate Larson"
    ],
    "abstract": "Continual learning aims to enable machine learning models to continually\nlearn from a shifting data distribution without forgetting what has already\nbeen learned. Such shifting distributions can be broken into disjoint subsets\nof related examples; by training each member of an ensemble on a different\nsubset it is possible for the ensemble as a whole to achieve much higher\naccuracy with less forgetting than a naive model. We address the problem of\nselecting which models within an ensemble should learn on any given data, and\nwhich should predict. By drawing on work from delegative voting we develop an\nalgorithm for using delegation to dynamically select which models in an\nensemble are active. We explore a variety of delegation methods and performance\nmetrics, ultimately finding that delegation is able to provide a significant\nperformance boost over naive learning in the face of distribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Canadian AI Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.07327v1",
    "published_date": "2024-05-12 16:33:48 UTC",
    "updated_date": "2024-05-12 16:33:48 UTC"
  },
  {
    "arxiv_id": "2405.07317v1",
    "title": "Machine Unlearning in Contrastive Learning",
    "authors": [
      "Zixin Wang",
      "Kongyang Chen"
    ],
    "abstract": "Machine unlearning is a complex process that necessitates the model to\ndiminish the influence of the training data while keeping the loss of accuracy\nto a minimum. Despite the numerous studies on machine unlearning in recent\nyears, the majority of them have primarily focused on supervised learning\nmodels, leaving research on contrastive learning models relatively\nunderexplored. With the conviction that self-supervised learning harbors a\npromising potential, surpassing or rivaling that of supervised learning, we set\nout to investigate methods for machine unlearning centered around contrastive\nlearning models. In this study, we introduce a novel gradient constraint-based\napproach for training the model to effectively achieve machine unlearning. Our\nmethod only necessitates a minimal number of training epochs and the\nidentification of the data slated for unlearning. Remarkably, our approach\ndemonstrates proficient performance not only on contrastive learning models but\nalso on supervised learning models, showcasing its versatility and adaptability\nin various learning paradigms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07317v1",
    "published_date": "2024-05-12 16:09:01 UTC",
    "updated_date": "2024-05-12 16:09:01 UTC"
  },
  {
    "arxiv_id": "2405.07309v1",
    "title": "DiffGen: Robot Demonstration Generation via Differentiable Physics Simulation, Differentiable Rendering, and Vision-Language Model",
    "authors": [
      "Yang Jin",
      "Jun Lv",
      "Shuqiang Jiang",
      "Cewu Lu"
    ],
    "abstract": "Generating robot demonstrations through simulation is widely recognized as an\neffective way to scale up robot data. Previous work often trained reinforcement\nlearning agents to generate expert policies, but this approach lacks sample\nefficiency. Recently, a line of work has attempted to generate robot\ndemonstrations via differentiable simulation, which is promising but heavily\nrelies on reward design, a labor-intensive process. In this paper, we propose\nDiffGen, a novel framework that integrates differentiable physics simulation,\ndifferentiable rendering, and a vision-language model to enable automatic and\nefficient generation of robot demonstrations. Given a simulated robot\nmanipulation scenario and a natural language instruction, DiffGen can generate\nrealistic robot demonstrations by minimizing the distance between the embedding\nof the language instruction and the embedding of the simulated observation\nafter manipulation. The embeddings are obtained from the vision-language model,\nand the optimization is achieved by calculating and descending gradients\nthrough the differentiable simulation, differentiable rendering, and\nvision-language model components, thereby accomplishing the specified task.\nExperiments demonstrate that with DiffGen, we could efficiently and effectively\ngenerate robot data with minimal human effort or training time.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07309v1",
    "published_date": "2024-05-12 15:38:17 UTC",
    "updated_date": "2024-05-12 15:38:17 UTC"
  },
  {
    "arxiv_id": "2405.07295v3",
    "title": "Bridging Neuroscience and AI: Environmental Enrichment as a Model for Forward Knowledge Transfer",
    "authors": [
      "Rajat Saxena",
      "Bruce L. McNaughton"
    ],
    "abstract": "Continual learning (CL) refers to an agent's capability to learn from a\ncontinuous stream of data and transfer knowledge without forgetting old\ninformation. One crucial aspect of CL is forward transfer, i.e., improved and\nfaster learning on a new task by leveraging information from prior knowledge.\nWhile this ability comes naturally to biological brains, it poses a significant\nchallenge for artificial intelligence (AI). Here, we suggest that environmental\nenrichment (EE) can be used as a biological model for studying forward\ntransfer, inspiring human-like AI development. EE refers to animal studies that\nenhance cognitive, social, motor, and sensory stimulation and is a model for\nwhat, in humans, is referred to as 'cognitive reserve'. Enriched animals show\nsignificant improvement in learning speed and performance on new tasks,\ntypically exhibiting forward transfer. We explore anatomical, molecular, and\nneuronal changes post-EE and discuss how artificial neural networks (ANNs) can\nbe used to predict neural computation changes after enriched experiences.\nFinally, we provide a synergistic way of combining neuroscience and AI research\nthat paves the path toward developing AI capable of rapid and efficient new\ntask learning.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.07295v3",
    "published_date": "2024-05-12 14:33:50 UTC",
    "updated_date": "2025-01-23 03:11:36 UTC"
  },
  {
    "arxiv_id": "2405.07293v1",
    "title": "Sparse Sampling is All You Need for Fast Wrong-way Cycling Detection in CCTV Videos",
    "authors": [
      "Jing Xu",
      "Wentao Shi",
      "Sheng Ren",
      "Pan Gao",
      "Peng Zhou",
      "Jie Qin"
    ],
    "abstract": "In the field of transportation, it is of paramount importance to address and\nmitigate illegal actions committed by both motor and non-motor vehicles. Among\nthose actions, wrong-way cycling (i.e., riding a bicycle or e-bike in the\nopposite direction of the designated traffic flow) poses significant risks to\nboth cyclists and other road users. To this end, this paper formulates a\nproblem of detecting wrong-way cycling ratios in CCTV videos. Specifically, we\npropose a sparse sampling method called WWC-Predictor to efficiently solve this\nproblem, addressing the inefficiencies of direct tracking methods. Our approach\nleverages both detection-based information, which utilizes the information from\nbounding boxes, and orientation-based information, which provides insights into\nthe image itself, to enhance instantaneous information capture capability. On\nour proposed benchmark dataset consisting of 35 minutes of video sequences and\nminute-level annotation, our method achieves an average error rate of a mere\n1.475% while taking only 19.12% GPU time of straightforward tracking methods\nunder the same detection model. This remarkable performance demonstrates the\neffectiveness of our approach in identifying and predicting instances of\nwrong-way cycling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07293v1",
    "published_date": "2024-05-12 14:16:05 UTC",
    "updated_date": "2024-05-12 14:16:05 UTC"
  },
  {
    "arxiv_id": "2405.07284v1",
    "title": "Zero Shot Context-Based Object Segmentation using SLIP (SAM+CLIP)",
    "authors": [
      "Saaketh Koundinya Gundavarapu",
      "Arushi Arora",
      "Shreya Agarwal"
    ],
    "abstract": "We present SLIP (SAM+CLIP), an enhanced architecture for zero-shot object\nsegmentation. SLIP combines the Segment Anything Model (SAM)\n\\cite{kirillov2023segment} with the Contrastive Language-Image Pretraining\n(CLIP) \\cite{radford2021learning}. By incorporating text prompts into SAM using\nCLIP, SLIP enables object segmentation without prior training on specific\nclasses or categories. We fine-tune CLIP on a Pokemon dataset, allowing it to\nlearn meaningful image-text representations. SLIP demonstrates the ability to\nrecognize and segment objects in images based on contextual information from\ntext prompts, expanding the capabilities of SAM for versatile object\nsegmentation. Our experiments demonstrate the effectiveness of the SLIP\narchitecture in segmenting objects in images based on textual cues. The\nintegration of CLIP's text-image understanding capabilities into SAM expands\nthe capabilities of the original architecture and enables more versatile and\ncontext-aware object segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.07284v1",
    "published_date": "2024-05-12 13:51:11 UTC",
    "updated_date": "2024-05-12 13:51:11 UTC"
  },
  {
    "arxiv_id": "2405.08027v4",
    "title": "Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions",
    "authors": [
      "Tian Xie",
      "Xueru Zhang"
    ],
    "abstract": "As machine learning (ML) models are increasingly used in social domains to\nmake consequential decisions about humans, they often have the power to reshape\ndata distributions. Humans, as strategic agents, continuously adapt their\nbehaviors in response to the learning system. As populations change\ndynamically, ML systems may need frequent updates to ensure high performance.\nHowever, acquiring high-quality human-annotated samples can be highly\nchallenging and even infeasible in social domains. A common practice to address\nthis issue is using the model itself to annotate unlabeled data samples. This\npaper investigates the long-term impacts when ML models are retrained with\nmodel-annotated samples when they incorporate human strategic responses. We\nfirst formalize the interactions between strategic agents and the model and\nthen analyze how they evolve under such dynamic interactions. We find that\nagents are increasingly likely to receive positive decisions as the model gets\nretrained, whereas the proportion of agents with positive labels may decrease\nover time. We thus propose a refined retraining process to stabilize the\ndynamics. Last, we examine how algorithmic fairness can be affected by these\nretraining processes and find that enforcing common fairness constraints at\nevery round may not benefit the disadvantaged group in the long run.\nExperiments on (semi-)synthetic and real data validate the theoretical\nfindings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08027v4",
    "published_date": "2024-05-12 13:36:58 UTC",
    "updated_date": "2024-10-11 00:37:14 UTC"
  },
  {
    "arxiv_id": "2405.07280v1",
    "title": "Humor Mechanics: Advancing Humor Generation with Multistep Reasoning",
    "authors": [
      "Alexey Tikhonov",
      "Pavel Shtykovskiy"
    ],
    "abstract": "In this paper, we explore the generation of one-liner jokes through\nmulti-step reasoning. Our work involved reconstructing the process behind\ncreating humorous one-liners and developing a working prototype for humor\ngeneration. We conducted comprehensive experiments with human participants to\nevaluate our approach, comparing it with human-created jokes, zero-shot GPT-4\ngenerated humor, and other baselines. The evaluation focused on the quality of\nhumor produced, using human labeling as a benchmark. Our findings demonstrate\nthat the multi-step reasoning approach consistently improves the quality of\ngenerated humor. We present the results and share the datasets used in our\nexperiments, offering insights into enhancing humor generation with artificial\nintelligence.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "68T05, 68T30, 68T50, 91-08",
      "I.2.7; I.2.1; I.2.6; H.5.2"
    ],
    "primary_category": "cs.CL",
    "comment": "ICCC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.07280v1",
    "published_date": "2024-05-12 13:00:14 UTC",
    "updated_date": "2024-05-12 13:00:14 UTC"
  },
  {
    "arxiv_id": "2405.07272v3",
    "title": "MAML MOT: Multiple Object Tracking based on Meta-Learning",
    "authors": [
      "Jiayi Chen",
      "Chunhua Deng"
    ],
    "abstract": "With the advancement of video analysis technology, the multi-object tracking\n(MOT) problem in complex scenes involving pedestrians is gaining increasing\nimportance. This challenge primarily involves two key tasks: pedestrian\ndetection and re-identification. While significant progress has been achieved\nin pedestrian detection tasks in recent years, enhancing the effectiveness of\nre-identification tasks remains a persistent challenge. This difficulty arises\nfrom the large total number of pedestrian samples in multi-object tracking\ndatasets and the scarcity of individual instance samples. Motivated by recent\nrapid advancements in meta-learning techniques, we introduce MAML MOT, a\nmeta-learning-based training approach for multi-object tracking. This approach\nleverages the rapid learning capability of meta-learning to tackle the issue of\nsample scarcity in pedestrian re-identification tasks, aiming to improve the\nmodel's generalization performance and robustness. Experimental results\ndemonstrate that the proposed method achieves high accuracy on mainstream\ndatasets in the MOT Challenge. This offers new perspectives and solutions for\nresearch in the field of pedestrian multi-object tracking.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07272v3",
    "published_date": "2024-05-12 12:38:40 UTC",
    "updated_date": "2024-08-23 12:23:56 UTC"
  },
  {
    "arxiv_id": "2405.07260v1",
    "title": "A Supervised Information Enhanced Multi-Granularity Contrastive Learning Framework for EEG Based Emotion Recognition",
    "authors": [
      "Xiang Li",
      "Jian Song",
      "Zhigang Zhao",
      "Chunxiao Wang",
      "Dawei Song",
      "Bin Hu"
    ],
    "abstract": "This study introduces a novel Supervised Info-enhanced Contrastive Learning\nframework for EEG based Emotion Recognition (SICLEER). SI-CLEER employs\nmulti-granularity contrastive learning to create robust EEG contextual\nrepresentations, potentiallyn improving emotion recognition effectiveness.\nUnlike existing methods solely guided by classification loss, we propose a\njoint learning model combining self-supervised contrastive learning loss and\nsupervised classification loss. This model optimizes both loss functions,\ncapturing subtle EEG signal differences specific to emotion detection.\nExtensive experiments demonstrate SI-CLEER's robustness and superior accuracy\non the SEED dataset compared to state-of-the-art methods. Furthermore, we\nanalyze electrode performance, highlighting the significance of central frontal\nand temporal brain region EEGs in emotion detection. This study offers an\nuniversally applicable approach with potential benefits for diverse EEG\nclassification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 3 figures, 2024 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP)",
    "pdf_url": "http://arxiv.org/pdf/2405.07260v1",
    "published_date": "2024-05-12 11:51:00 UTC",
    "updated_date": "2024-05-12 11:51:00 UTC"
  },
  {
    "arxiv_id": "2405.10974v2",
    "title": "Bottleneck-Minimal Indexing for Generative Document Retrieval",
    "authors": [
      "Xin Du",
      "Lixin Xiu",
      "Kumiko Tanaka-Ishii"
    ],
    "abstract": "We apply an information-theoretic perspective to reconsider generative\ndocument retrieval (GDR), in which a document $x \\in X$ is indexed by $t \\in\nT$, and a neural autoregressive model is trained to map queries $Q$ to $T$. GDR\ncan be considered to involve information transmission from documents $X$ to\nqueries $Q$, with the requirement to transmit more bits via the indexes $T$. By\napplying Shannon's rate-distortion theory, the optimality of indexing can be\nanalyzed in terms of the mutual information, and the design of the indexes $T$\ncan then be regarded as a {\\em bottleneck} in GDR. After reformulating GDR from\nthis perspective, we empirically quantify the bottleneck underlying GDR.\nFinally, using the NQ320K and MARCO datasets, we evaluate our proposed\nbottleneck-minimal indexing method in comparison with various previous indexing\nmethods, and we show that it outperforms those methods.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted for ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10974v2",
    "published_date": "2024-05-12 11:41:26 UTC",
    "updated_date": "2024-05-21 01:29:13 UTC"
  },
  {
    "arxiv_id": "2405.07248v1",
    "title": "Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis",
    "authors": [
      "Nikolay B Petrov",
      "Gregory Serapio-García",
      "Jason Rentfrow"
    ],
    "abstract": "The humanlike responses of large language models (LLMs) have prompted social\nscientists to investigate whether LLMs can be used to simulate human\nparticipants in experiments, opinion polls and surveys. Of central interest in\nthis line of research has been mapping out the psychological profiles of LLMs\nby prompting them to respond to standardized questionnaires. The conflicting\nfindings of this research are unsurprising given that mapping out underlying,\nor latent, traits from LLMs' text responses to questionnaires is no easy task.\nTo address this, we use psychometrics, the science of psychological\nmeasurement. In this study, we prompt OpenAI's flagship models, GPT-3.5 and\nGPT-4, to assume different personas and respond to a range of standardized\nmeasures of personality constructs. We used two kinds of persona descriptions:\neither generic (four or five random person descriptions) or specific (mostly\ndemographics of actual humans from a large-scale human dataset). We found that\nthe responses from GPT-4, but not GPT-3.5, using generic persona descriptions\nshow promising, albeit not perfect, psychometric properties, similar to human\nnorms, but the data from both LLMs when using specific demographic profiles,\nshow poor psychometrics properties. We conclude that, currently, when LLMs are\nasked to simulate silicon personas, their responses are poor signals of\npotentially underlying latent traits. Thus, our work casts doubt on LLMs'\nability to simulate individual-level human behaviour across multiple-choice\nquestion answering tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07248v1",
    "published_date": "2024-05-12 10:52:15 UTC",
    "updated_date": "2024-05-12 10:52:15 UTC"
  },
  {
    "arxiv_id": "2405.13003v1",
    "title": "A Survey on Recent Advances in Conversational Data Generation",
    "authors": [
      "Heydar Soudani",
      "Roxana Petcu",
      "Evangelos Kanoulas",
      "Faegheh Hasibi"
    ],
    "abstract": "Recent advancements in conversational systems have significantly enhanced\nhuman-machine interactions across various domains. However, training these\nsystems is challenging due to the scarcity of specialized dialogue data.\nTraditionally, conversational datasets were created through crowdsourcing, but\nthis method has proven costly, limited in scale, and labor-intensive. As a\nsolution, the development of synthetic dialogue data has emerged, utilizing\ntechniques to augment existing datasets or convert textual resources into\nconversational formats, providing a more efficient and scalable approach to\ndataset creation. In this survey, we offer a systematic and comprehensive\nreview of multi-turn conversational data generation, focusing on three types of\ndialogue systems: open domain, task-oriented, and information-seeking. We\ncategorize the existing research based on key components like seed data\ncreation, utterance generation, and quality filtering methods, and introduce a\ngeneral framework that outlines the main principles of conversation data\ngeneration systems. Additionally, we examine the evaluation metrics and methods\nfor assessing synthetic conversational data, address current challenges in the\nfield, and explore potential directions for future research. Our goal is to\naccelerate progress for researchers and practitioners by presenting an overview\nof state-of-the-art methods and highlighting opportunities to further research\nin this area.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13003v1",
    "published_date": "2024-05-12 10:11:12 UTC",
    "updated_date": "2024-05-12 10:11:12 UTC"
  },
  {
    "arxiv_id": "2405.13002v1",
    "title": "DuetRAG: Collaborative Retrieval-Augmented Generation",
    "authors": [
      "Dian Jiao",
      "Li Cai",
      "Jingsheng Huang",
      "Wenqiao Zhang",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) methods augment the input of Large\nLanguage Models (LLMs) with relevant retrieved passages, reducing factual\nerrors in knowledge-intensive tasks. However, contemporary RAG approaches\nsuffer from irrelevant knowledge retrieval issues in complex domain questions\n(e.g., HotPot QA) due to the lack of corresponding domain knowledge, leading to\nlow-quality generations. To address this issue, we propose a novel\nCollaborative Retrieval-Augmented Generation framework, DuetRAG. Our\nbootstrapping philosophy is to simultaneously integrate the domain fintuning\nand RAG models to improve the knowledge retrieval quality, thereby enhancing\ngeneration quality. Finally, we demonstrate DuetRAG' s matches with expert\nhuman researchers on HotPot QA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.13002v1",
    "published_date": "2024-05-12 09:48:28 UTC",
    "updated_date": "2024-05-12 09:48:28 UTC"
  },
  {
    "arxiv_id": "2405.07233v1",
    "title": "OXYGENERATOR: Reconstructing Global Ocean Deoxygenation Over a Century with Deep Learning",
    "authors": [
      "Bin Lu",
      "Ze Zhao",
      "Luyu Han",
      "Xiaoying Gan",
      "Yuntao Zhou",
      "Lei Zhou",
      "Luoyi Fu",
      "Xinbing Wang",
      "Chenghu Zhou",
      "Jing Zhang"
    ],
    "abstract": "Accurately reconstructing the global ocean deoxygenation over a century is\ncrucial for assessing and protecting marine ecosystem. Existing\nexpert-dominated numerical simulations fail to catch up with the dynamic\nvariation caused by global warming and human activities. Besides, due to the\nhigh-cost data collection, the historical observations are severely sparse,\nleading to big challenge for precise reconstruction. In this work, we propose\nOxyGenerator, the first deep learning based model, to reconstruct the global\nocean deoxygenation from 1920 to 2023. Specifically, to address the\nheterogeneity across large temporal and spatial scales, we propose\nzoning-varying graph message-passing to capture the complex oceanographic\ncorrelations between missing values and sparse observations. Additionally, to\nfurther calibrate the uncertainty, we incorporate inductive bias from dissolved\noxygen (DO) variations and chemical effects. Compared with in-situ DO\nobservations, OxyGenerator significantly outperforms CMIP6 numerical\nsimulations, reducing MAPE by 38.77%, demonstrating a promising potential to\nunderstand the \"breathless ocean\" in data-driven manner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.07233v1",
    "published_date": "2024-05-12 09:32:40 UTC",
    "updated_date": "2024-05-12 09:32:40 UTC"
  },
  {
    "arxiv_id": "2405.07226v1",
    "title": "Separable Power of Classical and Quantum Learning Protocols Through the Lens of No-Free-Lunch Theorem",
    "authors": [
      "Xinbiao Wang",
      "Yuxuan Du",
      "Kecheng Liu",
      "Yong Luo",
      "Bo Du",
      "Dacheng Tao"
    ],
    "abstract": "The No-Free-Lunch (NFL) theorem, which quantifies problem- and\ndata-independent generalization errors regardless of the optimization process,\nprovides a foundational framework for comprehending diverse learning protocols'\npotential. Despite its significance, the establishment of the NFL theorem for\nquantum machine learning models remains largely unexplored, thereby overlooking\nbroader insights into the fundamental relationship between quantum and\nclassical learning protocols. To address this gap, we categorize a diverse\narray of quantum learning algorithms into three learning protocols designed for\nlearning quantum dynamics under a specified observable and establish their NFL\ntheorem. The exploited protocols, namely Classical Learning Protocols\n(CLC-LPs), Restricted Quantum Learning Protocols (ReQu-LPs), and Quantum\nLearning Protocols (Qu-LPs), offer varying levels of access to quantum\nresources. Our derived NFL theorems demonstrate quadratic reductions in sample\ncomplexity across CLC-LPs, ReQu-LPs, and Qu-LPs, contingent upon the\northogonality of quantum states and the diagonality of observables. We\nattribute this performance discrepancy to the unique capacity of\nquantum-related learning protocols to indirectly utilize information concerning\nthe global phases of non-orthogonal quantum states, a distinctive physical\nfeature inherent in quantum mechanics. Our findings not only deepen our\nunderstanding of quantum learning protocols' capabilities but also provide\npractical insights for the development of advanced quantum learning algorithms.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07226v1",
    "published_date": "2024-05-12 09:05:13 UTC",
    "updated_date": "2024-05-12 09:05:13 UTC"
  },
  {
    "arxiv_id": "2405.10973v1",
    "title": "Adaptation of XAI to Auto-tuning for Numerical Libraries",
    "authors": [
      "Shota Aoki",
      "Takahiro Katagiri",
      "Satoshi Ohshima",
      "Masatoshi Kawai",
      "Toru Nagai",
      "Tetsuya Hoshino"
    ],
    "abstract": "Concerns have arisen regarding the unregulated utilization of artificial\nintelligence (AI) outputs, potentially leading to various societal issues.\nWhile humans routinely validate information, manually inspecting the vast\nvolumes of AI-generated results is impractical. Therefore, automation and\nvisualization are imperative. In this context, Explainable AI (XAI) technology\nis gaining prominence, aiming to streamline AI model development and alleviate\nthe burden of explaining AI outputs to users. Simultaneously, software\nauto-tuning (AT) technology has emerged, aiming to reduce the man-hours\nrequired for performance tuning in numerical calculations. AT is a potent tool\nfor cost reduction during parameter optimization and high-performance\nprogramming for numerical computing. The synergy between AT mechanisms and AI\ntechnology is noteworthy, with AI finding extensive applications in AT.\nHowever, applying AI to AT mechanisms introduces challenges in AI model\nexplainability. This research focuses on XAI for AI models when integrated into\ntwo different processes for practical numerical computations: performance\nparameter tuning of accuracy-guaranteed numerical calculations and sparse\niterative algorithm.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.MS"
    ],
    "primary_category": "cs.SE",
    "comment": "This article has been submitted to Special Session: Performance\n  Optimization and Auto-Tuning of Software on Multicore/Manycore Systems\n  (POAT), In conjunction with IEEE MCSoC-2024 (Dec 16-19, 2024, Days Hotel &\n  Suites by Wyndham Fraser Business Park, Kuala Lumpur)",
    "pdf_url": "http://arxiv.org/pdf/2405.10973v1",
    "published_date": "2024-05-12 09:00:56 UTC",
    "updated_date": "2024-05-12 09:00:56 UTC"
  },
  {
    "arxiv_id": "2405.07223v1",
    "title": "Ensemble Successor Representations for Task Generalization in Offline-to-Online Reinforcement Learning",
    "authors": [
      "Changhong Wang",
      "Xudong Yu",
      "Chenjia Bai",
      "Qiaosheng Zhang",
      "Zhen Wang"
    ],
    "abstract": "In Reinforcement Learning (RL), training a policy from scratch with online\nexperiences can be inefficient because of the difficulties in exploration.\nRecently, offline RL provides a promising solution by giving an initialized\noffline policy, which can be refined through online interactions. However,\nexisting approaches primarily perform offline and online learning in the same\ntask, without considering the task generalization problem in offline-to-online\nadaptation. In real-world applications, it is common that we only have an\noffline dataset from a specific task while aiming for fast online-adaptation\nfor several tasks. To address this problem, our work builds upon the\ninvestigation of successor representations for task generalization in online RL\nand extends the framework to incorporate offline-to-online learning. We\ndemonstrate that the conventional paradigm using successor features cannot\neffectively utilize offline data and improve the performance for the new task\nby online fine-tuning. To mitigate this, we introduce a novel methodology that\nleverages offline data to acquire an ensemble of successor representations and\nsubsequently constructs ensemble Q functions. This approach enables robust\nrepresentation learning from datasets with different coverage and facilitates\nfast adaption of Q functions towards new tasks during the online fine-tuning\nphase. Extensive empirical evaluations provide compelling evidence showcasing\nthe superior performance of our method in generalizing to diverse or even\nunseen tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Science China Information Sciences",
    "pdf_url": "http://arxiv.org/pdf/2405.07223v1",
    "published_date": "2024-05-12 08:52:52 UTC",
    "updated_date": "2024-05-12 08:52:52 UTC"
  },
  {
    "arxiv_id": "2405.07220v1",
    "title": "On Discovery of Local Independence over Continuous Variables via Neural Contextual Decomposition",
    "authors": [
      "Inwoo Hwang",
      "Yunhyeok Kwak",
      "Yeon-Ji Song",
      "Byoung-Tak Zhang",
      "Sanghack Lee"
    ],
    "abstract": "Conditional independence provides a way to understand causal relationships\namong the variables of interest. An underlying system may exhibit more\nfine-grained causal relationships especially between a variable and its\nparents, which will be called the local independence relationships. One of the\nmost widely studied local relationships is Context-Specific Independence (CSI),\nwhich holds in a specific assignment of conditioned variables. However, its\napplicability is often limited since it does not allow continuous variables:\ndata conditioned to the specific value of a continuous variable contains few\ninstances, if not none, making it infeasible to test independence. In this\nwork, we define and characterize the local independence relationship that holds\nin a specific set of joint assignments of parental variables, which we call\ncontext-set specific independence (CSSI). We then provide a canonical\nrepresentation of CSSI and prove its fundamental properties. Based on our\ntheoretical findings, we cast the problem of discovering multiple CSSI\nrelationships in a system as finding a partition of the joint outcome space.\nFinally, we propose a novel method, coined neural contextual decomposition\n(NCD), which learns such partition by imposing each set to induce CSSI via\nmodeling a conditional distribution. We empirically demonstrate that the\nproposed method successfully discovers the ground truth local independence\nrelationships in both synthetic dataset and complex system reflecting the\nreal-world physical dynamics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Conference on Causal Learning and Reasoning (CLeaR), 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.07220v1",
    "published_date": "2024-05-12 08:48:37 UTC",
    "updated_date": "2024-05-12 08:48:37 UTC"
  },
  {
    "arxiv_id": "2405.07212v1",
    "title": "Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective",
    "authors": [
      "Gaurav Singh",
      "Kavitesh Kumar Bali"
    ],
    "abstract": "This paper explores the seamless integration of Generative AI (GenAI) and\nEvolutionary Algorithms (EAs) within the domain of large-scale multi-objective\noptimization. Focusing on the transformative role of Large Language Models\n(LLMs), our study investigates the potential of LLM-Assisted Inference to\nautomate and enhance decision-making processes. Specifically, we highlight its\neffectiveness in illuminating key decision variables in evolutionarily\noptimized solutions while articulating contextual trade-offs. Tailored to\naddress the challenges inherent in inferring complex multi-objective\noptimization solutions at scale, our approach emphasizes the adaptive nature of\nLLMs, allowing them to provide nuanced explanations and align their language\nwith diverse stakeholder expertise levels and domain preferences. Empirical\nstudies underscore the practical applicability and impact of LLM-Assisted\nInference in real-world decision-making scenarios.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted IJCNN",
    "pdf_url": "http://arxiv.org/pdf/2405.07212v1",
    "published_date": "2024-05-12 08:22:53 UTC",
    "updated_date": "2024-05-12 08:22:53 UTC"
  },
  {
    "arxiv_id": "2405.07202v1",
    "title": "Unified Video-Language Pre-training with Synchronized Audio",
    "authors": [
      "Shentong Mo",
      "Haofan Wang",
      "Huaxia Li",
      "Xu Tang"
    ],
    "abstract": "Video-language pre-training is a typical and challenging problem that aims at\nlearning visual and textual representations from large-scale data in a\nself-supervised way. Existing pre-training approaches either captured the\ncorrespondence of image-text pairs or utilized temporal ordering of frames.\nHowever, they do not explicitly explore the natural synchronization between\naudio and the other two modalities. In this work, we propose an enhanced\nframework for Video-Language pre-training with Synchronized Audio, termed as\nVLSA, that can learn tri-modal representations in a unified self-supervised\ntransformer. Specifically, our VLSA jointly aggregates embeddings of local\npatches and global tokens for video, text, and audio. Furthermore, we utilize\nlocal-patch masked modeling to learn modality-aware features, and leverage\nglobal audio matching to capture audio-guided features for video and text. We\nconduct extensive experiments on retrieval across text, video, and audio. Our\nsimple model pre-trained on only 0.9M data achieves improving results against\nstate-of-the-art baselines. In addition, qualitative visualizations vividly\nshowcase the superiority of our VLSA in learning discriminative visual-textual\nrepresentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07202v1",
    "published_date": "2024-05-12 07:59:46 UTC",
    "updated_date": "2024-05-12 07:59:46 UTC"
  },
  {
    "arxiv_id": "2405.07200v3",
    "title": "Chebyshev Polynomial-Based Kolmogorov-Arnold Networks: An Efficient Architecture for Nonlinear Function Approximation",
    "authors": [
      "Sidharth SS",
      "Keerthana AR",
      "Gokul R",
      "Anas KP"
    ],
    "abstract": "Accurate approximation of complex nonlinear functions is a fundamental\nchallenge across many scientific and engineering domains. Traditional neural\nnetwork architectures, such as Multi-Layer Perceptrons (MLPs), often struggle\nto efficiently capture intricate patterns and irregularities present in\nhigh-dimensional functions. This paper presents the Chebyshev Kolmogorov-Arnold\nNetwork (Chebyshev KAN), a new neural network architecture inspired by the\nKolmogorov-Arnold representation theorem, incorporating the powerful\napproximation capabilities of Chebyshev polynomials. By utilizing learnable\nfunctions parametrized by Chebyshev polynomials on the network's edges,\nChebyshev KANs enhance flexibility, efficiency, and interpretability in\nfunction approximation tasks. We demonstrate the efficacy of Chebyshev KANs\nthrough experiments on digit classification, synthetic function approximation,\nand fractal function generation, highlighting their superiority over\ntraditional MLPs in terms of parameter efficiency and interpretability. Our\ncomprehensive evaluation, including ablation studies, confirms the potential of\nChebyshev KANs to address longstanding challenges in nonlinear function\napproximation, paving the way for further advancements in various scientific\nand engineering applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07200v3",
    "published_date": "2024-05-12 07:55:43 UTC",
    "updated_date": "2024-06-14 15:46:11 UTC"
  },
  {
    "arxiv_id": "2405.07195v1",
    "title": "InsightNet: Structured Insight Mining from Customer Feedback",
    "authors": [
      "Sandeep Sricharan Mukku",
      "Manan Soni",
      "Jitenkumar Rana",
      "Chetan Aggarwal",
      "Promod Yenigalla",
      "Rashmi Patange",
      "Shyam Mohan"
    ],
    "abstract": "We propose InsightNet, a novel approach for the automated extraction of\nstructured insights from customer reviews. Our end-to-end machine learning\nframework is designed to overcome the limitations of current solutions,\nincluding the absence of structure for identified topics, non-standard aspect\nnames, and lack of abundant training data. The proposed solution builds a\nsemi-supervised multi-level taxonomy from raw reviews, a semantic similarity\nheuristic approach to generate labelled data and employs a multi-task insight\nextraction architecture by fine-tuning an LLM. InsightNet identifies granular\nactionable topics with customer sentiments and verbatim for each topic.\nEvaluations on real-world customer review data show that InsightNet performs\nbetter than existing solutions in terms of structure, hierarchy and\ncompleteness. We empirically demonstrate that InsightNet outperforms the\ncurrent state-of-the-art methods in multi-label topic classification, achieving\nan F1 score of 0.85, which is an improvement of 11% F1-score over the previous\nbest results. Additionally, InsightNet generalises well for unseen aspects and\nsuggests new topics to be added to the taxonomy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.07195v1",
    "published_date": "2024-05-12 07:40:12 UTC",
    "updated_date": "2024-05-12 07:40:12 UTC"
  },
  {
    "arxiv_id": "2405.07194v1",
    "title": "Differentiable Model Scaling using Differentiable Topk",
    "authors": [
      "Kai Liu",
      "Ruohui Wang",
      "Jianfei Gao",
      "Kai Chen"
    ],
    "abstract": "Over the past few years, as large language models have ushered in an era of\nintelligence emergence, there has been an intensified focus on scaling\nnetworks. Currently, many network architectures are designed manually, often\nresulting in sub-optimal configurations. Although Neural Architecture Search\n(NAS) methods have been proposed to automate this process, they suffer from low\nsearch efficiency. This study introduces Differentiable Model Scaling (DMS),\nincreasing the efficiency for searching optimal width and depth in networks.\nDMS can model both width and depth in a direct and fully differentiable way,\nmaking it easy to optimize. We have evaluated our DMS across diverse tasks,\nranging from vision tasks to NLP tasks and various network architectures,\nincluding CNNs and Transformers. Results consistently indicate that our DMS can\nfind improved structures and outperforms state-of-the-art NAS methods.\nSpecifically, for image classification on ImageNet, our DMS improves the top-1\naccuracy of EfficientNet-B0 and Deit-Tiny by 1.4% and 0.6%, respectively, and\noutperforms the state-of-the-art zero-shot NAS method, ZiCo, by 1.3% while\nrequiring only 0.4 GPU days for searching. For object detection on COCO, DMS\nimproves the mAP of Yolo-v8-n by 2.0%. For language modeling, our pruned\nLlama-7B outperforms the prior method with lower perplexity and higher\nzero-shot classification accuracy. We will release our code in the future.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.07194v1",
    "published_date": "2024-05-12 07:34:33 UTC",
    "updated_date": "2024-05-12 07:34:33 UTC"
  },
  {
    "arxiv_id": "2405.07163v1",
    "title": "Realizing Visual Question Answering for Education: GPT-4V as a Multimodal AI",
    "authors": [
      "Gyeong-Geon Lee",
      "Xiaoming Zhai"
    ],
    "abstract": "Educational scholars have analyzed various image data acquired from teaching\nand learning situations, such as photos that shows classroom dynamics,\nstudents' drawings with regard to the learning content, textbook illustrations,\netc. Unquestioningly, most qualitative analysis of and explanation on image\ndata have been conducted by human researchers, without machine-based\nautomation. It was partially because most image processing artificial\nintelligence models were not accessible to general educational scholars or\nexplainable due to their complex deep neural network architecture. However, the\nrecent development of Visual Question Answering (VQA) techniques is\naccomplishing usable visual language models, which receive from the user a\nquestion about the given image and returns an answer, both in natural language.\nParticularly, GPT-4V released by OpenAI, has wide opened the state-of-the-art\nvisual langauge model service so that VQA could be used for a variety of\npurposes. However, VQA and GPT-4V have not yet been applied to educational\nstudies much. In this position paper, we suggest that GPT-4V contributes to\nrealizing VQA for education. By 'realizing' VQA, we denote two meanings: (1)\nGPT-4V realizes the utilization of VQA techniques by any educational scholars\nwithout technical/accessibility barrier, and (2) GPT-4V makes educational\nscholars realize the usefulness of VQA to educational research. Given these,\nthis paper aims to introduce VQA for educational studies so that it provides a\nmilestone for educational research methodology. In this paper, chapter II\nreviews the development of VQA techniques, which primes with the release of\nGPT-4V. Chapter III reviews the use of image analysis in educational studies.\nChapter IV demonstrates how GPT-4V can be used for each research usage reviewed\nin Chapter III, with operating prompts provided. Finally, chapter V discusses\nthe future implications.",
    "categories": [
      "physics.ed-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ed-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07163v1",
    "published_date": "2024-05-12 05:05:31 UTC",
    "updated_date": "2024-05-12 05:05:31 UTC"
  },
  {
    "arxiv_id": "2405.07162v3",
    "title": "Learning Reward for Robot Skills Using Large Language Models via Self-Alignment",
    "authors": [
      "Yuwei Zeng",
      "Yao Mu",
      "Lin Shao"
    ],
    "abstract": "Learning reward functions remains the bottleneck to equip a robot with a\nbroad repertoire of skills. Large Language Models (LLM) contain valuable\ntask-related knowledge that can potentially aid in the learning of reward\nfunctions. However, the proposed reward function can be imprecise, thus\nineffective which requires to be further grounded with environment information.\nWe proposed a method to learn rewards more efficiently in the absence of\nhumans. Our approach consists of two components: We first use the LLM to\npropose features and parameterization of the reward, then update the parameters\nthrough an iterative self-alignment process. In particular, the process\nminimizes the ranking inconsistency between the LLM and the learnt reward\nfunctions based on the execution feedback. The method was validated on 9 tasks\nacross 2 simulation environments. It demonstrates a consistent improvement over\ntraining efficacy and efficiency, meanwhile consuming significantly fewer GPT\ntokens compared to the alternative mutation-based method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.07162v3",
    "published_date": "2024-05-12 04:57:43 UTC",
    "updated_date": "2024-05-16 02:37:29 UTC"
  },
  {
    "arxiv_id": "2406.00005v1",
    "title": "Disentangling Specificity for Abstractive Multi-document Summarization",
    "authors": [
      "Congbo Ma",
      "Wei Emma Zhang",
      "Hu Wang",
      "Haojie Zhuang",
      "Mingyu Guo"
    ],
    "abstract": "Multi-document summarization (MDS) generates a summary from a document set.\nEach document in a set describes topic-relevant concepts, while per document\nalso has its unique contents. However, the document specificity receives little\nattention from existing MDS approaches. Neglecting specific information for\neach document limits the comprehensiveness of the generated summaries. To solve\nthis problem, in this paper, we propose to disentangle the specific content\nfrom documents in one document set. The document-specific representations,\nwhich are encouraged to be distant from each other via a proposed orthogonal\nconstraint, are learned by the specific representation learner. We provide\nextensive analysis and have interesting findings that specific information and\ndocument set representations contribute distinctive strengths and their\ncombination yields a more comprehensive solution for the MDS. Also, we find\nthat the common (i.e. shared) information could not contribute much to the\noverall performance under the MDS settings. Implemetation codes are available\nat https://github.com/congboma/DisentangleSum.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "The IEEE World Congress on Computational Intelligence (WCCI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.00005v1",
    "published_date": "2024-05-12 04:36:19 UTC",
    "updated_date": "2024-05-12 04:36:19 UTC"
  },
  {
    "arxiv_id": "2405.07157v1",
    "title": "Semi-Self-Supervised Domain Adaptation: Developing Deep Learning Models with Limited Annotated Data for Wheat Head Segmentation",
    "authors": [
      "Alireza Ghanbari",
      "Gholamhassan Shirdel",
      "Farhad Maleki"
    ],
    "abstract": "Precision agriculture involves the application of advanced technologies to\nimprove agricultural productivity, efficiency, and profitability while\nminimizing waste and environmental impact. Deep learning approaches enable\nautomated decision-making for many visual tasks. However, in the agricultural\ndomain, variability in growth stages and environmental conditions, such as\nweather and lighting, presents significant challenges to developing deep\nlearning-based techniques that generalize across different conditions. The\nresource-intensive nature of creating extensive annotated datasets that capture\nthese variabilities further hinders the widespread adoption of these\napproaches. To tackle these issues, we introduce a semi-self-supervised domain\nadaptation technique based on deep convolutional neural networks with a\nprobabilistic diffusion process, requiring minimal manual data annotation.\nUsing only three manually annotated images and a selection of video clips from\nwheat fields, we generated a large-scale computationally annotated dataset of\nimage-mask pairs and a large dataset of unannotated images extracted from video\nframes. We developed a two-branch convolutional encoder-decoder model\narchitecture that uses both synthesized image-mask pairs and unannotated\nimages, enabling effective adaptation to real images. The proposed model\nachieved a Dice score of 80.7\\% on an internal test dataset and a Dice score of\n64.8\\% on an external test set, composed of images from five countries and\nspanning 18 domains, indicating its potential to develop generalizable\nsolutions that could encourage the wider adoption of advanced technologies in\nagriculture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12",
    "pdf_url": "http://arxiv.org/pdf/2405.07157v1",
    "published_date": "2024-05-12 04:35:49 UTC",
    "updated_date": "2024-05-12 04:35:49 UTC"
  },
  {
    "arxiv_id": "2406.00004v4",
    "title": "Navigating the Future of Federated Recommendation Systems with Foundation Models",
    "authors": [
      "Zhiwei Li",
      "Guodong Long",
      "Chunxu Zhang",
      "Honglei Zhang",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Federated Recommendation Systems (FRSs) offer a privacy-preserving\nalternative to traditional centralized approaches by decentralizing data\nstorage. However, they face persistent challenges such as data sparsity and\nheterogeneity, largely due to isolated client environments. Recent advances in\nFoundation Models (FMs), particularly large language models like ChatGPT,\npresent an opportunity to surmount these issues through powerful, cross-task\nknowledge transfer. In this position paper, we systematically examine the\nconvergence of FRSs and FMs, illustrating how FM-enhanced frameworks can\nsubstantially improve client-side personalization, communication efficiency,\nand server-side aggregation. We also delve into pivotal challenges introduced\nby this integration, including privacy-security trade-offs, non-IID data, and\nresource constraints in federated setups, and propose prospective research\ndirections in areas such as multimodal recommendation, real-time FM adaptation,\nand explainable federated reasoning. By unifying FRSs with FMs, our position\npaper provides a forward-looking roadmap for advancing privacy-preserving,\nhigh-performance recommendation systems that fully leverage large-scale\npre-trained knowledge to enhance local performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "11 pages, position paper, survey",
    "pdf_url": "http://arxiv.org/pdf/2406.00004v4",
    "published_date": "2024-05-12 04:15:05 UTC",
    "updated_date": "2025-04-11 08:41:07 UTC"
  },
  {
    "arxiv_id": "2405.07142v1",
    "title": "Cross-Domain Continual Learning via CLAMP",
    "authors": [
      "Weiwei Weng",
      "Mahardhika Pratama",
      "Jie Zhang",
      "Chen Chen",
      "Edward Yapp Kien Yee",
      "Ramasamy Savitha"
    ],
    "abstract": "Artificial neural networks, celebrated for their human-like cognitive\nlearning abilities, often encounter the well-known catastrophic forgetting (CF)\nproblem, where the neural networks lose the proficiency in previously acquired\nknowledge. Despite numerous efforts to mitigate CF, it remains the significant\nchallenge particularly in complex changing environments. This challenge is even\nmore pronounced in cross-domain adaptation following the continual learning\n(CL) setting, which is a more challenging and realistic scenario that is\nunder-explored. To this end, this article proposes a cross-domain CL approach\nmaking possible to deploy a single model in such environments without\nadditional labelling costs. Our approach, namely continual learning approach\nfor many processes (CLAMP), integrates a class-aware adversarial domain\nadaptation strategy to align a source domain and a target domain. An\nassessor-guided learning process is put forward to navigate the learning\nprocess of a base model assigning a set of weights to every sample controlling\nthe influence of every sample and the interactions of each loss function in\nsuch a way to balance the stability and plasticity dilemma thus preventing the\nCF problem. The first assessor focuses on the negative transfer problem\nrejecting irrelevant samples of the source domain while the second assessor\nprevents noisy pseudo labels of the target domain. Both assessors are trained\nin the meta-learning approach using random transformation techniques and\nsimilar samples of the source domain. Theoretical analysis and extensive\nnumerical validations demonstrate that CLAMP significantly outperforms\nestablished baseline algorithms across all experiments by at least $10\\%$\nmargin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review in Elsevier Journal",
    "pdf_url": "http://arxiv.org/pdf/2405.07142v1",
    "published_date": "2024-05-12 02:41:31 UTC",
    "updated_date": "2024-05-12 02:41:31 UTC"
  },
  {
    "arxiv_id": "2405.07140v1",
    "title": "Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization",
    "authors": [
      "Xinyuan Zhang",
      "Jiang Liu",
      "Zehui Xiong",
      "Yudong Huang",
      "Gaochang Xie",
      "Ran Zhang"
    ],
    "abstract": "Generative Artificial Intelligence (GAI) is taking the world by storm with\nits unparalleled content creation ability. Large Language Models (LLMs) are at\nthe forefront of this movement. However, the significant resource demands of\nLLMs often require cloud hosting, which raises issues regarding privacy,\nlatency, and usage limitations. Although edge intelligence has long been\nutilized to solve these challenges by enabling real-time AI computation on\nubiquitous edge resources close to data sources, most research has focused on\ntraditional AI models and has left a gap in addressing the unique\ncharacteristics of LLM inference, such as considerable model size,\nauto-regressive processes, and self-attention mechanisms. In this paper, we\npresent an edge intelligence optimization problem tailored for LLM inference.\nSpecifically, with the deployment of the batching technique and model\nquantization on resource-limited edge devices, we formulate an inference model\nfor transformer decoder-based LLMs. Furthermore, our approach aims to maximize\nthe inference throughput via batch scheduling and joint allocation of\ncommunication and computation resources, while also considering edge resource\nconstraints and varying user requirements of latency and accuracy. To address\nthis NP-hard problem, we develop an optimal Depth-First Tree-Searching\nalgorithm with online tree-Pruning (DFTSP) that operates within a feasible time\ncomplexity. Simulation results indicate that DFTSP surpasses other batching\nbenchmarks in throughput across diverse user settings and quantization\ntechniques, and it reduces time complexity by over 45% compared to the\nbrute-force searching method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07140v1",
    "published_date": "2024-05-12 02:38:58 UTC",
    "updated_date": "2024-05-12 02:38:58 UTC"
  },
  {
    "arxiv_id": "2405.07135v3",
    "title": "Post Training Quantization of Large Language Models with Microscaling Formats",
    "authors": [
      "Sayeh Sharify",
      "Utkarsh Saxena",
      "Zifei Xu",
      "Wanzin Yazar",
      "Ilya Soloveychik",
      "Xin Wang"
    ],
    "abstract": "Large Language Models (LLMs) have distinguished themselves with outstanding\nperformance in complex language modeling tasks, yet they come with significant\ncomputational and storage challenges. This paper explores the potential of\nquantization to mitigate these challenges. We systematically study the combined\napplication of three well-known post-training techniques, SmoothQuant, AWQ, and\nGPTQ, and provide a comprehensive analysis of their interactions and\nimplications for advancing LLM quantization. We enhance the versatility of\nthese methods by enabling quantization to microscaling (MX) formats, extending\nthe applicability of these PTQ algorithms beyond their original fixed-point\nformat targets. We show that combining different PTQ methods enables us to\nquantize models to 4-bit weights and 8-bit activations using the MXINT format\nwith negligible accuracy loss compared to the uncompressed baseline.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07135v3",
    "published_date": "2024-05-12 02:15:26 UTC",
    "updated_date": "2024-10-15 18:09:23 UTC"
  },
  {
    "arxiv_id": "2405.13001v1",
    "title": "Large Language Models for Education: A Survey",
    "authors": [
      "Hanyi Xu",
      "Wensheng Gan",
      "Zhenlian Qi",
      "Jiayang Wu",
      "Philip S. Yu"
    ],
    "abstract": "Artificial intelligence (AI) has a profound impact on traditional education.\nIn recent years, large language models (LLMs) have been increasingly used in\nvarious applications such as natural language processing, computer vision,\nspeech recognition, and autonomous driving. LLMs have also been applied in many\nfields, including recommendation, finance, government, education, legal\naffairs, and finance. As powerful auxiliary tools, LLMs incorporate various\ntechnologies such as deep learning, pre-training, fine-tuning, and\nreinforcement learning. The use of LLMs for smart education (LLMEdu) has been a\nsignificant strategic direction for countries worldwide. While LLMs have shown\ngreat promise in improving teaching quality, changing education models, and\nmodifying teacher roles, the technologies are still facing several challenges.\nIn this paper, we conduct a systematic review of LLMEdu, focusing on current\ntechnologies, challenges, and future developments. We first summarize the\ncurrent state of LLMEdu and then introduce the characteristics of LLMs and\neducation, as well as the benefits of integrating LLMs into education. We also\nreview the process of integrating LLMs into the education industry, as well as\nthe introduction of related technologies. Finally, we discuss the challenges\nand problems faced by LLMEdu, as well as prospects for future optimization of\nLLMEdu.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Journal of Machine Learning and Cybernetics. 4 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13001v1",
    "published_date": "2024-05-12 01:50:01 UTC",
    "updated_date": "2024-05-12 01:50:01 UTC"
  },
  {
    "arxiv_id": "2405.07117v1",
    "title": "Context Neural Networks: A Scalable Multivariate Model for Time Series Forecasting",
    "authors": [
      "Abishek Sriramulu",
      "Christoph Bergmeir",
      "Slawek Smyl"
    ],
    "abstract": "Real-world time series often exhibit complex interdependencies that cannot be\ncaptured in isolation. Global models that model past data from multiple related\ntime series globally while producing series-specific forecasts locally are now\ncommon. However, their forecasts for each individual series remain isolated,\nfailing to account for the current state of its neighbouring series.\nMultivariate models like multivariate attention and graph neural networks can\nexplicitly incorporate inter-series information, thus addressing the\nshortcomings of global models. However, these techniques exhibit quadratic\ncomplexity per timestep, limiting scalability. This paper introduces the\nContext Neural Network, an efficient linear complexity approach for augmenting\ntime series models with relevant contextual insights from neighbouring time\nseries without significant computational overhead. The proposed method enriches\npredictive models by providing the target series with real-time information\nfrom its neighbours, addressing the limitations of global models, yet remaining\ncomputationally tractable for large datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.07117v1",
    "published_date": "2024-05-12 00:21:57 UTC",
    "updated_date": "2024-05-12 00:21:57 UTC"
  },
  {
    "arxiv_id": "2405.08717v1",
    "title": "How Much You Ate? Food Portion Estimation on Spoons",
    "authors": [
      "Aaryam Sharma",
      "Chris Czarnecki",
      "Yuhao Chen",
      "Pengcheng Xi",
      "Linlin Xu",
      "Alexander Wong"
    ],
    "abstract": "Monitoring dietary intake is a crucial aspect of promoting healthy living. In\nrecent years, advances in computer vision technology have facilitated dietary\nintake monitoring through the use of images and depth cameras. However, the\ncurrent state-of-the-art image-based food portion estimation algorithms assume\nthat users take images of their meals one or two times, which can be\ninconvenient and fail to capture food items that are not visible from a\ntop-down perspective, such as ingredients submerged in a stew. To address these\nlimitations, we introduce an innovative solution that utilizes stationary\nuser-facing cameras to track food items on utensils, not requiring any change\nof camera perspective after installation. The shallow depth of utensils\nprovides a more favorable angle for capturing food items, and tracking them on\nthe utensil's surface offers a significantly more accurate estimation of\ndietary intake without the need for post-meal image capture. The system is\nreliable for estimation of nutritional content of liquid-solid heterogeneous\nmixtures such as soups and stews. Through a series of experiments, we\ndemonstrate the exceptional potential of our method as a non-invasive,\nuser-friendly, and highly accurate dietary intake monitoring tool.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08717v1",
    "published_date": "2024-05-12 00:16:02 UTC",
    "updated_date": "2024-05-12 00:16:02 UTC"
  }
]