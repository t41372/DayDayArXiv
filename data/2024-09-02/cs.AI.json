{
  "date": "2024-09-02",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-02 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 84 篇论文，主要聚焦 AI 应用（如生成模型、强化学习和医疗诊断）、机器人与自动驾驶，以及多模态语言模型的创新；重点包括视频生成和推荐系统的突破性方法，以及 NeurIPS 接受的强化学习论文；令人印象深刻的文章有 AMG（结合 2D 和 3D 的视频生成）和 TRACE（Transformer-based 用户表示），而知名学者如 George Em Karniadakis 的工作也值得关注。\n\n下面，我挑选了其中最重要、话题度和影响大的论文先聊（例如 AI 生成、机器人和医疗领域），并将相关主题归类讨论。对于其他较常规或次要论文，我会快速掠过，只列出标题和核心要点，以控制篇幅。\n\n### 重点论文讨论\n\n**1. AMG: Avatar Motion Guided Video Generation（AMG: 头像运动引导视频生成）**  \n这篇论文提出 AMG 方法，通过条件扩散模型结合 2D 逼真性和 3D 可控性，生成多人物视频，支持精确控制相机位置、人体运动和背景风格。主要贡献是首次实现多人物视频生成，并在真实性和适应性上超越现有基于姿态序列的方法，适用于动画和虚拟现实领域。\n\n**2. TRACE: Transformer-based user Representations from Attributed Clickstream Event sequences（TRACE: 基于 Transformer 的用户表示从归因点击流事件序列）**  \n作者包括 RecSys 相关研究者，论文引入 TRACE 框架，使用 Transformer 处理多会话点击流数据，生成用户嵌入以提升个性化推荐。主要发现是通过多任务学习捕捉长期用户偏好，在旅游电商数据集上优于传统 Transformer 和 LLM 模型，显著提高了推荐系统的准确性和用户行为聚类。\n\n**3. EarthGen: Generating the World from Top-Down Views（EarthGen: 从顶部视图生成世界）**  \n这篇创新性工作提出级联超分辨率扩散模型，生成数千平方公里的高分辨率地球表面图像。主要贡献是使用 Bing Maps 数据训练模型，超越基线在极端超分辨率任务中的性能，并支持可控世界生成和 3D 场景应用，适用于地图和模拟环境。\n\n**4. Real-Time Recurrent Learning using Trace Units in Reinforcement Learning（使用 Trace Units 的实时循环学习在强化学习中）**  \nNeurIPS 2024 接受论文，作者包括 Michael Bowling 等知名学者。论文引入 Recurrent Trace Units (RTUs)，改进了线性循环架构，在部分可观测环境中训练 RNN。主要发现是 RTUs 在计算效率和性能上优于现有方法，适用于在线强化学习任务，如机器人导航。\n\n**5. Democratizing MLLMs in Healthcare: TinyLLaVA-Med for Efficient Healthcare Diagnostics（医疗领域的大语言模型民主化：TinyLLaVA-Med 用于高效医疗诊断）**  \n这篇论文针对资源受限设备优化多模态大语言模型，提出 TinyLLaVA-Med 方法，通过指令微调实现低功耗诊断。主要贡献是显著降低计算需求（18.9W 和 11.9GB 内存），在 VQA-RAD 和 SLAKE 数据集上达到 64.54% 和 70.70% 准确率，适用于偏远医疗场景。\n\n### 相关主题快速讨论\n- **机器人和自动驾驶领域（相关论文如 Grounding Language Models in Autonomous Loco-manipulation Tasks 和 Efficient and Scalable Estimation of Tool Representations）**：  \n  这些论文探索机器人操作和工具使用优化。主要发现包括使用 LLM 指导机器人轨迹规划（如 Grounding Language Models），和工具嵌入生成提升效率（如 Efficient and Scalable）。总体上，它们推进了自主系统的鲁棒性，但细节较常规，故快速掠过。标题：Grounding Language Models in Autonomous Loco-manipulation Tasks（在自主机操纵任务中植根语言模型）；Efficient and Scalable Estimation of Tool Representations（高效可扩展的工具表示估计）。\n\n- **医疗和生物应用（相关论文如 Pediatric brain tumor classification 和 H-ARC）**：  \n  这些工作使用深度学习改善医疗图像分析。主要贡献是多中心数据集上的高精度分类（如 Pediatric brain tumor classification，使用 MIL 框架提升诊断准确性）和人类性能基准（如 H-ARC，提供鲁棒性估计）。标题：Pediatric brain tumor classification using digital histopathology and deep learning（使用数字组织病理学和深度学习的儿科脑肿瘤分类）；H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark（H-ARC: 抽象和推理语料库基准上人类性能的鲁棒估计）。\n\n- **其他 AI 创新（快速掠过非核心论文）**：  \n  如 Imitating Language via Scalable Inverse Reinforcement Learning（通过可扩展逆强化学习模仿语言），主要发现是优化 LLM 训练以提升序列生成多样性；以及 Self-Supervised Learning for Identifying Defects in Sewer Footage（自监督学习识别下水道缺陷），贡献在于高效缺陷检测。其他如 The Role of Transformer Models in Advancing Blockchain Technology（Transformer 模型在区块链技术中的作用），讨论 Transformer 在异常检测等领域的应用，但影响力较小，仅提及其在区块链安全上的进展。标题：Imitating Language via Scalable Inverse Reinforcement Learning（通过可扩展逆强化学习模仿语言）；Self-Supervised Learning for Identifying Defects in Sewer Footage（自监督学习识别下水道缺陷）；The Role of Transformer Models in Advancing Blockchain Technology（Transformer 模型在区块链技术中的作用）。\n\n今天 arXiv 的论文整体质量高，但许多聚焦常规优化（如数据增强或小改进），未列出的 70+ 篇我已简化处理。如果您对特定领域感兴趣，下次快报可更针对性调整！",
  "papers": [
    {
      "arxiv_id": "2409.01502v1",
      "title": "AMG: Avatar Motion Guided Video Generation",
      "title_zh": "AMG：化身运动引导视频生成",
      "authors": [
        "Zhangsihao Yang",
        "Mengyi Shan",
        "Mohammad Farazi",
        "Wenhui Zhu",
        "Yanxi Chen",
        "Xuanzhao Dong",
        "Yalin Wang"
      ],
      "abstract": "Human video generation task has gained significant attention with the\nadvancement of deep generative models. Generating realistic videos with human\nmovements is challenging in nature, due to the intricacies of human body\ntopology and sensitivity to visual artifacts. The extensively studied 2D media\ngeneration methods take advantage of massive human media datasets, but struggle\nwith 3D-aware control; whereas 3D avatar-based approaches, while offering more\nfreedom in control, lack photorealism and cannot be harmonized seamlessly with\nbackground scene. We propose AMG, a method that combines the 2D photorealism\nand 3D controllability by conditioning video diffusion models on controlled\nrendering of 3D avatars. We additionally introduce a novel data processing\npipeline that reconstructs and renders human avatar movements from dynamic\ncamera videos. AMG is the first method that enables multi-person diffusion\nvideo generation with precise control over camera positions, human motions, and\nbackground style. We also demonstrate through extensive evaluation that it\noutperforms existing human video generation methods conditioned on pose\nsequences or driving videos in terms of realism and adaptability.",
      "tldr_zh": "本文提出AMG方法，通过在视频扩散 models 上使用受控的3D avatars 渲染，结合2D photorealism 和3D controllability，解决人类视频生成中的真实性和控制挑战。AMG 引入一个新颖的数据处理 pipeline，从动态相机视频中重建和渲染人类头像运动，实现多人物扩散视频生成，并精确控制相机位置、人类 motions 和背景样式。该方法在广泛评估中，表现出色，在 realism 和 adaptability 方面优于现有的基于 pose sequences 或 driving videos 的视频生成方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "The project page is at https://github.com/zshyang/amg",
      "pdf_url": "http://arxiv.org/pdf/2409.01502v1",
      "published_date": "2024-09-02 23:59:01 UTC",
      "updated_date": "2024-09-02 23:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:36:13.265988"
    },
    {
      "arxiv_id": "2409.12972v1",
      "title": "TRACE: Transformer-based user Representations from Attributed Clickstream Event sequences",
      "title_zh": "翻译失败",
      "authors": [
        "William Black",
        "Alexander Manlove",
        "Jack Pennington",
        "Andrea Marchini",
        "Ercument Ilhan",
        "Vilda Markeviciute"
      ],
      "abstract": "For users navigating travel e-commerce websites, the process of researching\nproducts and making a purchase often results in intricate browsing patterns\nthat span numerous sessions over an extended period of time. The resulting\nclickstream data chronicle these user journeys and present valuable\nopportunities to derive insights that can significantly enhance personalized\nrecommendations. We introduce TRACE, a novel transformer-based approach\ntailored to generate rich user embeddings from live multi-session clickstreams\nfor real-time recommendation applications. Prior works largely focus on\nsingle-session product sequences, whereas TRACE leverages site-wide page view\nsequences spanning multiple user sessions to model long-term engagement.\nEmploying a multi-task learning framework, TRACE captures comprehensive user\npreferences and intents distilled into low-dimensional representations. We\ndemonstrate TRACE's superior performance over vanilla transformer and LLM-style\narchitectures through extensive experiments on a large-scale travel e-commerce\ndataset of real user journeys, where the challenges of long page-histories and\nsparse targets are particularly prevalent. Visualizations of the learned\nembeddings reveal meaningful clusters corresponding to latent user states and\nbehaviors, highlighting TRACE's potential to enhance recommendation systems by\ncapturing nuanced user interactions and preferences",
      "tldr_zh": "本研究提出 TRACE，一种基于 Transformer 的方法，用于从归因点击流事件序列中生成丰富的用户嵌入（user embeddings），以提升旅行电商网站的实时个性化推荐。TRACE 不同于以往专注于单会话的产品序列，而是利用跨越多个会话的网站级页面查看序列，并采用多任务学习框架（multi-task learning framework）来捕捉用户的长期偏好和意图。在大规模旅行电商数据集上的实验中，TRACE 显著优于传统 Transformer 和 LLM 风格架构，尤其在处理长页面历史和稀疏目标时；此外，嵌入的可视化揭示了有意义的用户行为集群，从而增强推荐系统的捕捉用户互动能力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "RecSys Workshop on Recommenders in Tourism (RecTour 2024), October\n  14th-18th, 2024, co-located with the 18th ACM Conference on Recommender\n  Systems, Bari, Italy",
      "pdf_url": "http://arxiv.org/pdf/2409.12972v1",
      "published_date": "2024-09-02 23:33:19 UTC",
      "updated_date": "2024-09-02 23:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:36:15.499281"
    },
    {
      "arxiv_id": "2409.01491v2",
      "title": "EarthGen: Generating the World from Top-Down Views",
      "title_zh": "翻译失败",
      "authors": [
        "Ansh Sharma",
        "Albert Xiao",
        "Praneet Rathi",
        "Rohit Kundu",
        "Albert Zhai",
        "Yuan Shen",
        "Shenlong Wang"
      ],
      "abstract": "In this work, we present a novel method for extensive multi-scale generative\nterrain modeling. At the core of our model is a cascade of superresolution\ndiffusion models that can be combined to produce consistent images across\nmultiple resolutions. Pairing this concept with a tiled generation method\nyields a scalable system that can generate thousands of square kilometers of\nrealistic Earth surfaces at high resolution. We evaluate our method on a\ndataset collected from Bing Maps and show that it outperforms super-resolution\nbaselines on the extreme super-resolution task of 1024x zoom. We also\ndemonstrate its ability to create diverse and coherent scenes via an\ninteractive gigapixel-scale generated map. Finally, we demonstrate how our\nsystem can be extended to enable novel content creation applications including\ncontrollable world generation and 3D scene generation.",
      "tldr_zh": "本文提出EarthGen，一种从顶部视图生成多尺度地形的新方法，其核心是级联的superresolution diffusion models和tiled generation技术，能够生成数千平方公里的高分辨率地球表面图像。实验在Bing Maps数据集上显示，该方法在极端超分辨率任务（如1024x缩放）中优于基线模型。EarthGen还能创建多样且连贯的交互式千兆像素级场景，并扩展到可控世界生成和3D场景生成等应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "J.2; I.4.8"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01491v2",
      "published_date": "2024-09-02 23:17:56 UTC",
      "updated_date": "2024-09-07 21:49:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:36:28.534943"
    },
    {
      "arxiv_id": "2409.12184v1",
      "title": "Democratizing MLLMs in Healthcare: TinyLLaVA-Med for Efficient Healthcare Diagnostics in Resource-Constrained Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Aya El Mir",
        "Lukelo Thadei Luoga",
        "Boyuan Chen",
        "Muhammad Abdullah Hanif",
        "Muhammad Shafique"
      ],
      "abstract": "Deploying Multi-Modal Large Language Models (MLLMs) in healthcare is hindered\nby their high computational demands and significant memory requirements, which\nare particularly challenging for resource-constrained devices like the Nvidia\nJetson Xavier. This problem is particularly evident in remote medical settings\nwhere advanced diagnostics are needed but resources are limited. In this paper,\nwe introduce an optimization method for the general-purpose MLLM, TinyLLaVA,\nwhich we have adapted and renamed TinyLLaVA-Med. This adaptation involves\ninstruction-tuning and fine-tuning TinyLLaVA on a medical dataset by drawing\ninspiration from the LLaVA-Med training pipeline. Our approach successfully\nminimizes computational complexity and power consumption, with TinyLLaVA-Med\noperating at 18.9W and using 11.9GB of memory, while achieving accuracies of\n64.54% on VQA-RAD and 70.70% on SLAKE for closed-ended questions. Therefore,\nTinyLLaVA-Med achieves deployment viability in hardware-constrained\nenvironments with low computational resources, maintaining essential\nfunctionalities and delivering accuracies close to state-of-the-art models.",
      "tldr_zh": "本研究针对多模态大型语言模型（MLLMs）在医疗领域的部署挑战，特别是高计算需求和内存限制（如Nvidia Jetson Xavier设备），提出了一种优化模型TinyLLaVA-Med。研究通过指令微调和细调TinyLLaVA，使用医疗数据集并借鉴LLaVA-Med的训练管道，显著降低了计算复杂性和功耗，使模型在18.9W功耗和11.9GB内存下运行。结果显示，TinyLLaVA-Med在资源受限环境中实现了高效诊断，在VQA-RAD数据集上达到64.54%的准确率，在SLAKE数据集上达到70.70%，性能接近最先进模型，从而推动MLLMs在偏远医疗场景中的普及。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.12184v1",
      "published_date": "2024-09-02 21:14:16 UTC",
      "updated_date": "2024-09-02 21:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:36:41.488946"
    },
    {
      "arxiv_id": "2409.01466v2",
      "title": "Enhancing LLM-Based Text Classification in Political Science: Automatic Prompt Optimization and Dynamic Exemplar Selection for Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Menglin Liu",
        "Ge Shi"
      ],
      "abstract": "Large language models (LLMs) offer substantial promise for text\nclassification in political science, yet their effectiveness often depends on\nhigh-quality prompts and exemplars. To address this, we introduce a three-stage\nframework that enhances LLM performance through automatic prompt optimization,\ndynamic exemplar selection, and a consensus mechanism. Our approach automates\nprompt refinement using task-specific exemplars, eliminating speculative\ntrial-and-error adjustments and producing structured prompts aligned with\nhuman-defined criteria. In the second stage, we dynamically select the most\nrelevant exemplars, ensuring contextually appropriate guidance for each query.\nFinally, our consensus mechanism mimics the role of multiple human coders for a\nsingle task, combining outputs from LLMs to achieve high reliability and\nconsistency at a reduced cost. Evaluated across tasks including sentiment\nanalysis, stance detection, and campaign ad tone classification, our method\nenhances classification accuracy without requiring task-specific model\nretraining or extensive manual adjustments to prompts. This framework not only\nboosts accuracy, interpretability and transparency but also provides a\ncost-effective, scalable solution tailored to political science applications.\nAn open-source Python package (PoliPrompt) is available on GitHub.",
      "tldr_zh": "这篇论文提出一个三阶段框架，用于提升LLM（Large Language Models）在政治科学文本分类中的性能，通过自动prompt优化、动态exemplar选择和共识机制来解决few-shot learning的挑战。该框架自动精炼prompt，使用任务特定的exemplars提供指导，并在共识机制下模拟多个编码者以提高输出可靠性，从而避免手动调整和模型重新训练。在情感分析、立场检测和竞选广告语气分类等任务上，实验结果显示准确性显著提升，同时增强了可解释性和透明度，并提供开源Python包PoliPrompt作为成本有效的可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "46 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01466v2",
      "published_date": "2024-09-02 21:05:31 UTC",
      "updated_date": "2025-04-06 15:38:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:36:52.275902"
    },
    {
      "arxiv_id": "2409.01449v2",
      "title": "Real-Time Recurrent Learning using Trace Units in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Esraa Elelimy",
        "Adam White",
        "Michael Bowling",
        "Martha White"
      ],
      "abstract": "Recurrent Neural Networks (RNNs) are used to learn representations in\npartially observable environments. For agents that learn online and continually\ninteract with the environment, it is desirable to train RNNs with real-time\nrecurrent learning (RTRL); unfortunately, RTRL is prohibitively expensive for\nstandard RNNs. A promising direction is to use linear recurrent architectures\n(LRUs), where dense recurrent weights are replaced with a complex-valued\ndiagonal, making RTRL efficient. In this work, we build on these insights to\nprovide a lightweight but effective approach for training RNNs in online RL. We\nintroduce Recurrent Trace Units (RTUs), a small modification on LRUs that we\nnonetheless find to have significant performance benefits over LRUs when\ntrained with RTRL. We find RTUs significantly outperform other recurrent\narchitectures across several partially observable environments while using\nsignificantly less computation.",
      "tldr_zh": "本研究针对在线强化学习（Reinforcement Learning）中训练Recurrent Neural Networks (RNNs)的挑战，提出了一种轻量级方法，使用Real-Time Recurrent Learning (RTRL)结合Recurrent Trace Units (RTUs)。RTUs是对Linear Recurrent Architectures (LRUs)的微小改进，通过优化循环权重，使RTRL训练更高效。实验结果显示，RTUs在多个部分可观测环境中显著优于其他循环架构，同时减少了计算资源消耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01449v2",
      "published_date": "2024-09-02 20:08:23 UTC",
      "updated_date": "2024-10-30 04:07:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:37:02.591984"
    },
    {
      "arxiv_id": "2409.01437v1",
      "title": "Kvasir-VQA: A Text-Image Pair GI Tract Dataset",
      "title_zh": "Kvasir-VQA：文本-图像对胃肠道数据集",
      "authors": [
        "Sushant Gautam",
        "Andrea Storås",
        "Cise Midoglu",
        "Steven A. Hicks",
        "Vajira Thambawita",
        "Pål Halvorsen",
        "Michael A. Riegler"
      ],
      "abstract": "We introduce Kvasir-VQA, an extended dataset derived from the HyperKvasir and\nKvasir-Instrument datasets, augmented with question-and-answer annotations to\nfacilitate advanced machine learning tasks in Gastrointestinal (GI)\ndiagnostics. This dataset comprises 6,500 annotated images spanning various GI\ntract conditions and surgical instruments, and it supports multiple question\ntypes including yes/no, choice, location, and numerical count. The dataset is\nintended for applications such as image captioning, Visual Question Answering\n(VQA), text-based generation of synthetic medical images, object detection, and\nclassification. Our experiments demonstrate the dataset's effectiveness in\ntraining models for three selected tasks, showcasing significant applications\nin medical image analysis and diagnostics. We also present evaluation metrics\nfor each task, highlighting the usability and versatility of our dataset. The\ndataset and supporting artifacts are available at\nhttps://datasets.simula.no/kvasir-vqa.",
      "tldr_zh": "本文介绍了 Kvasir-VQA 数据集，这是一个从 HyperKvasir 和 Kvasir-Instrument 数据集扩展而来的文本-图像配对数据集，包含 6,500 张标注图像，涵盖各种胃肠道 (GI) 条件和手术仪器，并支持 yes/no、choice、location 和 numerical count 等问题类型。数据集适用于图像标题生成、Visual Question Answering (VQA)、基于文本生成合成医疗图像、物体检测和分类等任务。实验结果展示了其在训练模型方面的有效性，并提供了相应评估指标，突显了数据集的可用性和多功能性，可从 https://datasets.simula.no/kvasir-vqa 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "to be published in VLM4Bio 2024, part of the ACM Multimedia (ACM MM)\n  conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01437v1",
      "published_date": "2024-09-02 19:41:59 UTC",
      "updated_date": "2024-09-02 19:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:37:17.597141"
    },
    {
      "arxiv_id": "2409.02141v1",
      "title": "Efficient and Scalable Estimation of Tool Representations in Vector Space",
      "title_zh": "高效且可扩展的工具表示在向量空间中的估计",
      "authors": [
        "Suhong Moon",
        "Siddharth Jha",
        "Lutfi Eren Erdogan",
        "Sehoon Kim",
        "Woosang Lim",
        "Kurt Keutzer",
        "Amir Gholami"
      ],
      "abstract": "Recent advancements in function calling and tool use have significantly\nenhanced the capabilities of large language models (LLMs) by enabling them to\ninteract with external information sources and execute complex tasks. However,\nthe limited context window of LLMs presents challenges when a large number of\ntools are available, necessitating efficient methods to manage prompt length\nand maintain accuracy. Existing approaches, such as fine-tuning LLMs or\nleveraging their reasoning capabilities, either require frequent retraining or\nincur significant latency overhead. A more efficient solution involves training\nsmaller models to retrieve the most relevant tools for a given query, although\nthis requires high quality, domain-specific data. To address those challenges,\nwe present a novel framework for generating synthetic data for tool retrieval\napplications and an efficient data-driven tool retrieval strategy using small\nencoder models. Empowered by LLMs, we create ToolBank, a new tool retrieval\ndataset that reflects real human user usages. For tool retrieval methodologies,\nwe propose novel approaches: (1) Tool2Vec: usage-driven tool embedding\ngeneration for tool retrieval, (2) ToolRefiner: a staged retrieval method that\niteratively improves the quality of retrieved tools, and (3) MLC: framing tool\nretrieval as a multi-label classification problem. With these new methods, we\nachieve improvements of up to 27.28 in Recall@K on the ToolBench dataset and\n30.5 in Recall@K on ToolBank. Additionally, we present further experimental\nresults to rigorously validate our methods. Our code is available at\n\\url{https://github.com/SqueezeAILab/Tool2Vec}",
      "tldr_zh": "该论文针对大型语言模型(LLMs)处理大量工具时的上下文窗口限制，提出了一种高效框架，用于生成合成数据和优化工具检索策略。具体方法包括Tool2Vec（基于使用驱动的工具嵌入生成）、ToolRefiner（分阶段迭代改进检索质量）和MLC（将工具检索 framing 为多标签分类问题）。实验结果显示，这些方法在ToolBench数据集上Recall@K提高了27.28，在ToolBank数据集上提高了30.5，展示了其在工具检索中的可扩展性和性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02141v1",
      "published_date": "2024-09-02 19:39:24 UTC",
      "updated_date": "2024-09-02 19:39:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:37:27.866208"
    },
    {
      "arxiv_id": "2409.02140v1",
      "title": "Self-Supervised Learning for Identifying Defects in Sewer Footage",
      "title_zh": "自监督学习用于识别下水道视频中的缺陷",
      "authors": [
        "Daniel Otero",
        "Rafael Mateus"
      ],
      "abstract": "Sewerage infrastructure is among the most expensive modern investments\nrequiring time-intensive manual inspections by qualified personnel. Our study\naddresses the need for automated solutions without relying on large amounts of\nlabeled data. We propose a novel application of Self-Supervised Learning (SSL)\nfor sewer inspection that offers a scalable and cost-effective solution for\ndefect detection. We achieve competitive results with a model that is at least\n5 times smaller than other approaches found in the literature and obtain\ncompetitive performance with 10\\% of the available data when training with a\nlarger architecture. Our findings highlight the potential of SSL to\nrevolutionize sewer maintenance in resource-limited settings.",
      "tldr_zh": "本文研究了下水道检查的自动化问题，提出了一种基于Self-Supervised Learning (SSL)的创新方法，用于识别缺陷，而无需依赖大量标注数据。该方法采用更小规模的模型（至少比文献中其他方法小5倍），并在仅使用10%的可用数据时仍能实现竞争性性能。研究发现，SSL为资源有限的环境提供可扩展且成本有效的解决方案，有望革新下水道维护实践。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Poster at the LatinX in AI Workshop @ ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02140v1",
      "published_date": "2024-09-02 19:28:48 UTC",
      "updated_date": "2024-09-02 19:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:37:37.956523"
    },
    {
      "arxiv_id": "2409.02139v2",
      "title": "The Role of Transformer Models in Advancing Blockchain Technology: A Systematic Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Tianxu Liu",
        "Yanbin Wang",
        "Jianguo Sun",
        "Ye Tian",
        "Yanyu Huang",
        "Tao Xue",
        "Peiyue Li",
        "Yiwei Liu"
      ],
      "abstract": "As blockchain technology rapidly evolves, the demand for enhanced efficiency,\nsecurity, and scalability grows.Transformer models, as powerful deep learning\narchitectures,have shown unprecedented potential in addressing various\nblockchain challenges. However, a systematic review of Transformer applications\nin blockchain is lacking. This paper aims to fill this research gap by\nsurveying over 200 relevant papers, comprehensively reviewing practical cases\nand research progress of Transformers in blockchain applications. Our survey\ncovers key areas including anomaly detection, smart contract security analysis,\ncryptocurrency prediction and trend analysis, and code summary generation. To\nclearly articulate the advancements of Transformers across various blockchain\ndomains, we adopt a domain-oriented classification system, organizing and\nintroducing representative methods based on major challenges in current\nblockchain research. For each research domain,we first introduce its background\nand objectives, then review previous representative methods and analyze their\nlimitations,and finally introduce the advancements brought by Transformer\nmodels. Furthermore, we explore the challenges of utilizing Transformer, such\nas data privacy, model complexity, and real-time processing requirements.\nFinally, this article proposes future research directions, emphasizing the\nimportance of exploring the Transformer architecture in depth to adapt it to\nspecific blockchain applications, and discusses its potential role in promoting\nthe development of blockchain technology. This review aims to provide new\nperspectives and a research foundation for the integrated development of\nblockchain technology and machine learning, supporting further innovation and\napplication expansion of blockchain technology.",
      "tldr_zh": "这篇论文通过系统性调查超过200篇相关文献，探讨了Transformer模型在区块链技术中的作用，旨在提升区块链的效率、安全性和可扩展性。论文采用领域导向的分类系统，涵盖关键领域如anomaly detection、智能合约安全分析、cryptocurrency prediction和代码摘要生成，分析了Transformer模型带来的进步及其对现有方法的改进。最终，论文指出了Transformer应用的挑战，包括data privacy、model complexity和实时处理需求，并提出未来研究方向，以推动区块链与机器学习的深度整合。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02139v2",
      "published_date": "2024-09-02 19:12:54 UTC",
      "updated_date": "2024-09-05 11:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:37:49.140261"
    },
    {
      "arxiv_id": "2409.01411v1",
      "title": "Performance-Aware Self-Configurable Multi-Agent Networks: A Distributed Submodular Approach for Simultaneous Coordination and Network Design",
      "title_zh": "性能感知的自配置多智能体网络：一种用于同时协调和网络设计的分布式子模函数方法",
      "authors": [
        "Zirui Xu",
        "Vasileios Tzoumas"
      ],
      "abstract": "We introduce the first, to our knowledge, rigorous approach that enables\nmulti-agent networks to self-configure their communication topology to balance\nthe trade-off between scalability and optimality during multi-agent planning.\nWe are motivated by the future of ubiquitous collaborative autonomy where\nnumerous distributed agents will be coordinating via agent-to-agent\ncommunication to execute complex tasks such as traffic monitoring, event\ndetection, and environmental exploration. But the explosion of information in\nsuch large-scale networks currently curtails their deployment due to\nimpractical decision times induced by the computational and communication\nrequirements of the existing near-optimal coordination algorithms. To overcome\nthis challenge, we present the AlterNAting COordination and Network-Design\nAlgorithm (Anaconda), a scalable algorithm that also enjoys near-optimality\nguarantees. Subject to the agents' bandwidth constraints, Anaconda enables the\nagents to optimize their local communication neighborhoods such that the\naction-coordination approximation performance of the network is maximized.\nCompared to the state of the art, Anaconda is an anytime self-configurable\nalgorithm that quantifies its suboptimality guarantee for any type of network,\nfrom fully disconnected to fully centralized, and that, for sparse networks, is\none order faster in terms of decision speed. To develop the algorithm, we\nquantify the suboptimality cost due to decentralization, i.e., due to\ncommunication-minimal distributed coordination. We also employ tools inspired\nby the literature on multi-armed bandits and submodular maximization subject to\ncardinality constraints. We demonstrate Anaconda in simulated scenarios of area\nmonitoring and compare it with a state-of-the-art algorithm.",
      "tldr_zh": "本研究首次提出了一种严格方法，使多智能体网络（multi-agent networks）能够自配置通信拓扑，以平衡可扩展性和最优性，针对大规模协作任务如交通监控和环境探索。论文引入了AlterNAting COordination and Network-Design Algorithm (Anaconda)，一个可扩展的分布式子模函数（submodular）算法，该算法优化代理的本地通信邻域，最大化网络的行动协调性能，同时量化子最优性保证。实验结果显示，Anaconda 在稀疏网络中决策速度比现有算法快一倍，并在模拟区域监控场景中表现出色，为高效的多智能体协调提供了新框架。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted to CDC 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01411v1",
      "published_date": "2024-09-02 18:11:33 UTC",
      "updated_date": "2024-09-02 18:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:38:05.280854"
    },
    {
      "arxiv_id": "2409.01392v2",
      "title": "ComfyBench: Benchmarking LLM-based Agents in ComfyUI for Autonomously Designing Collaborative AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyuan Xue",
        "Zeyu Lu",
        "Di Huang",
        "Zidong Wang",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Much previous AI research has focused on developing monolithic models to\nmaximize their intelligence, with the primary goal of enhancing performance on\nspecific tasks. In contrast, this work attempts to study using LLM-based agents\nto design collaborative AI systems autonomously. To explore this problem, we\nfirst introduce ComfyBench to evaluate agents's ability to design collaborative\nAI systems in ComfyUI. ComfyBench is a comprehensive benchmark comprising 200\ndiverse tasks covering various instruction-following generation challenges,\nalong with detailed annotations for 3,205 nodes and 20 workflows. Based on\nComfyBench, we further develop ComfyAgent, a novel framework that empowers\nLLM-based agents to autonomously design collaborative AI systems by generating\nworkflows. ComfyAgent is based on two core concepts. First, it represents\nworkflows with code, which can be reversibly converted into workflows and\nexecuted as collaborative systems by the interpreter. Second, it constructs a\nmulti-agent system that cooperates to learn from existing workflows and\ngenerate new workflows for a given task. While experimental results demonstrate\nthat ComfyAgent achieves a comparable resolve rate to o1-preview and\nsignificantly surpasses other agents on ComfyBench, ComfyAgent has resolved\nonly 15\\% of creative tasks. LLM-based agents still have a long way to go in\nautonomously designing collaborative AI systems. Progress with ComfyBench is\npaving the way for more intelligent and autonomous collaborative AI systems.",
      "tldr_zh": "本研究转向使用LLM-based agents自主设计协作AI系统，而不是开发单一智能模型。论文引入ComfyBench基准测试，用于评估代理在ComfyUI中设计协作AI系统的能力，该基准包含200个多样化任务、3,205个节点和20个工作流的详细注释。基于此，作者开发了ComfyAgent框架，该框架通过代码表示工作流（可逆转换和执行）以及多代理系统合作学习和生成新工作流，实现自主设计。实验结果显示，ComfyAgent在ComfyBench上的解决率与o1-preview相当，并显著优于其他代理，但仅处理了15%的创造性任务，表明LLM-based agents在这一领域仍有较大改进空间。该工作为更智能的自主协作AI系统铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01392v2",
      "published_date": "2024-09-02 17:44:10 UTC",
      "updated_date": "2024-11-26 14:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:38:17.314995"
    },
    {
      "arxiv_id": "2409.01387v1",
      "title": "VLSI Hypergraph Partitioning with Deep Learning",
      "title_zh": "VLSI 超图分区与深度学习",
      "authors": [
        "Muhammad Hadir Khan",
        "Bugra Onal",
        "Eren Dogan",
        "Matthew R. Guthaus"
      ],
      "abstract": "Partitioning is a known problem in computer science and is critical in chip\ndesign workflows, as advancements in this area can significantly influence\ndesign quality and efficiency. Deep Learning (DL) techniques, particularly\nthose involving Graph Neural Networks (GNNs), have demonstrated strong\nperformance in various node, edge, and graph prediction tasks using both\ninductive and transductive learning methods. A notable area of recent interest\nwithin GNNs are pooling layers and their application to graph partitioning.\nWhile these methods have yielded promising results across social,\ncomputational, and other random graphs, their effectiveness has not yet been\nexplored in the context of VLSI hypergraph netlists. In this study, we\nintroduce a new set of synthetic partitioning benchmarks that emulate\nreal-world netlist characteristics and possess a known upper bound for solution\ncut quality. We distinguish these benchmarks with the prior work and evaluate\nexisting state-of-the-art partitioning algorithms alongside GNN-based\napproaches, highlighting their respective advantages and disadvantages.",
      "tldr_zh": "这篇论文探讨了深度学习（Deep Learning）在VLSI超图分区（VLSI Hypergraph Partitioning）中的应用，强调了分区问题在芯片设计流程中的关键作用，特别是Graph Neural Networks (GNNs)及其池化层在图预测任务上的表现。研究者引入了一套新的合成基准，这些基准模拟真实网表特征并具有已知的上限切割质量，以区分现有工作。最终，通过评估现有最先进的分区算法和基于GNNs的方法，论文突出了它们的优缺点，为VLSI设计效率的提升提供了宝贵见解。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01387v1",
      "published_date": "2024-09-02 17:32:01 UTC",
      "updated_date": "2024-09-02 17:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:38:29.216424"
    },
    {
      "arxiv_id": "2409.01382v1",
      "title": "Automatic Detection of LLM-generated Code: A Case Study of Claude 3 Haiku",
      "title_zh": "LLM 生成代码的自动检测：Claude 3 Haiku 的案例研究",
      "authors": [
        "Musfiqur Rahman",
        "SayedHassan Khatoonabadi",
        "Ahmad Abdellatif",
        "Emad Shihab"
      ],
      "abstract": "Using Large Language Models (LLMs) has gained popularity among software\ndevelopers for generating source code. However, the use of LLM-generated code\ncan introduce risks of adding suboptimal, defective, and vulnerable code. This\nmakes it necessary to devise methods for the accurate detection of\nLLM-generated code. Toward this goal, we perform a case study of Claude 3 Haiku\n(or Claude 3 for brevity) on CodeSearchNet dataset. We divide our analyses into\ntwo parts: function-level and class-level. We extract 22 software metric\nfeatures, such as Code Lines and Cyclomatic Complexity, for each level of\ngranularity. We then analyze code snippets generated by Claude 3 and their\nhuman-authored counterparts using the extracted features to understand how\nunique the code generated by Claude 3 is. In the following step, we use the\nunique characteristics of Claude 3-generated code to build Machine Learning\n(ML) models and identify which features of the code snippets make them more\ndetectable by ML models. Our results indicate that Claude 3 tends to generate\nlonger functions, but shorter classes than humans, and this characteristic can\nbe used to detect Claude 3-generated code with ML models with 82% and 66%\naccuracies for function-level and class-level snippets, respectively.",
      "tldr_zh": "本研究针对 Large Language Models (LLM) 生成代码可能带来的次优、缺陷或漏洞风险，提出了一种自动检测方法，并以 Claude 3 Haiku 为案例，在 CodeSearchNet 数据集上进行分析。研究者提取了 22 个软件指标特征（如 Code Lines 和 Cyclomatic Complexity），并比较 Claude 3 生成的代码与人类代码在函数级和类级上的差异，结果显示 Claude 3 倾向于生成较长的函数但较短的类。最终，通过构建 Machine Learning (ML) 模型，实现函数级检测准确率 82% 和类级 66%，为准确识别 LLM 生成代码提供了有效途径。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Submitted to a journal for potential publication",
      "pdf_url": "http://arxiv.org/pdf/2409.01382v1",
      "published_date": "2024-09-02 17:25:15 UTC",
      "updated_date": "2024-09-02 17:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:38:40.520792"
    },
    {
      "arxiv_id": "2409.01374v1",
      "title": "H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Solim LeGris",
        "Wai Keen Vong",
        "Brenden M. Lake",
        "Todd M. Gureckis"
      ],
      "abstract": "The Abstraction and Reasoning Corpus (ARC) is a visual program synthesis\nbenchmark designed to test challenging out-of-distribution generalization in\nhumans and machines. Since 2019, limited progress has been observed on the\nchallenge using existing artificial intelligence methods. Comparing human and\nmachine performance is important for the validity of the benchmark. While\nprevious work explored how well humans can solve tasks from the ARC benchmark,\nthey either did so using only a subset of tasks from the original dataset, or\nfrom variants of ARC, and therefore only provided a tentative estimate of human\nperformance. In this work, we obtain a more robust estimate of human\nperformance by evaluating 1729 humans on the full set of 400 training and 400\nevaluation tasks from the original ARC problem set. We estimate that average\nhuman performance lies between 73.3% and 77.2% correct with a reported\nempirical average of 76.2% on the training set, and between 55.9% and 68.9%\ncorrect with a reported empirical average of 64.2% on the public evaluation\nset. However, we also find that 790 out of the 800 tasks were solvable by at\nleast one person in three attempts, suggesting that the vast majority of the\npublicly available ARC tasks are in principle solvable by typical crowd-workers\nrecruited over the internet. Notably, while these numbers are slightly lower\nthan earlier estimates, human performance still greatly exceeds current\nstate-of-the-art approaches for solving ARC. To facilitate research on ARC, we\npublicly release our dataset, called H-ARC (human-ARC), which includes all of\nthe submissions and action traces from human participants.",
      "tldr_zh": "这篇论文评估了人类在Abstraction and Reasoning Corpus (ARC)基准上的表现，以提供更可靠的估计。研究者通过测试1729名参与者在ARC的完整400个训练任务和400个评估任务上，发现人类在训练集的平均正确率为76.2%（估计范围73.3%-77.2%），在评估集为64.2%（估计范围55.9%-68.9%）。此外，800个任务中有790个至少被一人解决，表明大多数任务对网络众包工作者是可解的，而人类表现仍远超当前AI方法；论文还公开了H-ARC数据集，包括人类提交和行动痕迹，以支持进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01374v1",
      "published_date": "2024-09-02 17:11:32 UTC",
      "updated_date": "2024-09-02 17:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:38:55.885935"
    },
    {
      "arxiv_id": "2409.01369v2",
      "title": "Imitating Language via Scalable Inverse Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Markus Wulfmeier",
        "Michael Bloesch",
        "Nino Vieillard",
        "Arun Ahuja",
        "Jorg Bornschein",
        "Sandy Huang",
        "Artem Sokolov",
        "Matt Barnes",
        "Guillaume Desjardins",
        "Alex Bewley",
        "Sarah Maria Elisabeth Bechtle",
        "Jost Tobias Springenberg",
        "Nikola Momchev",
        "Olivier Bachem",
        "Matthieu Geist",
        "Martin Riedmiller"
      ],
      "abstract": "The majority of language model training builds on imitation learning. It\ncovers pretraining, supervised fine-tuning, and affects the starting conditions\nfor reinforcement learning from human feedback (RLHF). The simplicity and\nscalability of maximum likelihood estimation (MLE) for next token prediction\nled to its role as predominant paradigm. However, the broader field of\nimitation learning can more effectively utilize the sequential structure\nunderlying autoregressive generation. We focus on investigating the inverse\nreinforcement learning (IRL) perspective to imitation, extracting rewards and\ndirectly optimizing sequences instead of individual token likelihoods and\nevaluate its benefits for fine-tuning large language models. We provide a new\nangle, reformulating inverse soft-Q-learning as a temporal difference\nregularized extension of MLE. This creates a principled connection between MLE\nand IRL and allows trading off added complexity with increased performance and\ndiversity of generations in the supervised fine-tuning (SFT) setting. We find\nclear advantages for IRL-based imitation, in particular for retaining diversity\nwhile maximizing task performance, rendering IRL a strong alternative on fixed\nSFT datasets even without online data generation. Our analysis of IRL-extracted\nreward functions further indicates benefits for more robust reward functions\nvia tighter integration of supervised and preference-based LLM post-training.",
      "tldr_zh": "这篇论文探讨了通过可扩展的Inverse Reinforcement Learning (IRL)来改进语言模型的模仿学习，相比传统的Maximum Likelihood Estimation (MLE)，IRL通过提取奖励并直接优化序列生成，能够更好地利用序列结构。作者将逆软Q学习重新表述为MLE的扩展形式，引入时间差正则化，从而在Supervised Fine-Tuning (SFT)设置中实现性能和生成多样性的权衡。实验结果显示，IRL方法显著提升任务性能，同时保留内容多样性，甚至在固定数据集上无需在线数据生成即可表现出优势，并为更稳健的奖励函数和Reinforcement Learning from Human Feedback (RLHF)整合提供新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01369v2",
      "published_date": "2024-09-02 16:48:57 UTC",
      "updated_date": "2024-12-09 14:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:39:16.681087"
    },
    {
      "arxiv_id": "2409.01366v2",
      "title": "CHESS: Optimizing LLM Inference via Channel-Wise Thresholding and Selective Sparsification",
      "title_zh": "翻译失败",
      "authors": [
        "Junhui He",
        "Shangyu Wu",
        "Weidong Wen",
        "Chun Jason Xue",
        "Qingan Li"
      ],
      "abstract": "Deploying large language models (LLMs) on edge devices presents significant\nchallenges due to the substantial computational overhead and memory\nrequirements. Activation sparsification can mitigate these resource challenges\nby reducing the number of activated neurons during inference. Existing methods\ntypically employ thresholding-based sparsification based on the statistics of\nactivation tensors. However, they do not model the impact of activation\nsparsification on performance, resulting in suboptimal performance degradation.\nTo address the limitations, this paper reformulates the activation\nsparsification problem to explicitly capture the relationship between\nactivation sparsity and model performance. Then, this paper proposes CHESS, a\ngeneral activation sparsification approach via CHannel-wise thrEsholding and\nSelective Sparsification. First, channel-wise thresholding assigns a unique\nthreshold to each activation channel in the feed-forward network (FFN) layers.\nThen, selective sparsification involves applying thresholding-based activation\nsparsification to specific layers within the attention modules. Finally, we\ndetail the implementation of sparse kernels to accelerate LLM inference.\nExperimental results demonstrate that the proposed CHESS achieves lower\nperformance degradation over eight downstream tasks while activating fewer\nparameters than existing methods, thus speeding up the LLM inference by up to\n1.27x.",
      "tldr_zh": "本文提出 CHESS 方法，用于优化大型语言模型 (LLMs) 在边缘设备的推理过程，以应对计算开销和内存需求的挑战。CHESS 通过 Channel-wise Thresholding 为前馈网络 (FFN) 层的每个激活通道分配独特阈值，并结合 Selective Sparsification 在注意力模块的特定层应用基于阈值的激活稀疏化，从而减少激活参数并最小化性能损失。实验结果显示，CHESS 在八个下游任务上比现有方法实现更低的性能下降，同时激活更少的参数，并将 LLM 推理加速高达 1.27 倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01366v2",
      "published_date": "2024-09-02 16:41:44 UTC",
      "updated_date": "2024-12-27 17:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:39:16.599185"
    },
    {
      "arxiv_id": "2409.01362v1",
      "title": "Correlating Time Series with Interpretable Convolutional Kernels",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Chen",
        "HanQin Cai",
        "Fuqiang Liu",
        "Jinhua Zhao"
      ],
      "abstract": "This study addresses the problem of convolutional kernel learning in\nunivariate, multivariate, and multidimensional time series data, which is\ncrucial for interpreting temporal patterns in time series and supporting\ndownstream machine learning tasks. First, we propose formulating convolutional\nkernel learning for univariate time series as a sparse regression problem with\na non-negative constraint, leveraging the properties of circular convolution\nand circulant matrices. Second, to generalize this approach to multivariate and\nmultidimensional time series data, we use tensor computations, reformulating\nthe convolutional kernel learning problem in the form of tensors. This is\nfurther converted into a standard sparse regression problem through\nvectorization and tensor unfolding operations. In the proposed methodology, the\noptimization problem is addressed using the existing non-negative subspace\npursuit method, enabling the convolutional kernel to capture temporal\ncorrelations and patterns. To evaluate the proposed model, we apply it to\nseveral real-world time series datasets. On the multidimensional rideshare and\ntaxi trip data from New York City and Chicago, the convolutional kernels reveal\ninterpretable local correlations and cyclical patterns, such as weekly\nseasonality. In the context of multidimensional fluid flow data, both local and\nnonlocal correlations captured by the convolutional kernels can reinforce\ntensor factorization, leading to performance improvements in fluid flow\nreconstruction tasks. Thus, this study lays an insightful foundation for\nautomatically learning convolutional kernels from time series data, with an\nemphasis on interpretability through sparsity and non-negativity constraints.",
      "tldr_zh": "这篇论文提出了一种通过稀疏回归和非负约束来学习可解释卷积 kernels 的方法，适用于单变量、多变量和多维时间序列数据，以解释时间模式并支持下游机器学习任务。具体而言，他们将卷积 kernel 学习问题转化为张量形式，通过向量化和平铺操作转换为标准稀疏回归问题，并使用非负子空间追踪方法进行优化，以捕获时间相关性和周期模式。在实际数据集（如纽约和芝加哥的rideshare数据及流体流动数据）上的实验表明，该方法能揭示本地和非本地相关性，如每周季节性，并显著提升任务性能，例如流体流动重建。总的来说，这为自动从时间序列数据中学习可解释卷积 kernels 提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01362v1",
      "published_date": "2024-09-02 16:29:21 UTC",
      "updated_date": "2024-09-02 16:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:39:39.991928"
    },
    {
      "arxiv_id": "2409.01354v3",
      "title": "Explanation Space: A New Perspective into Time Series Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Shahbaz Rezaei",
        "Xin Liu"
      ],
      "abstract": "Human understandable explanation of deep learning models is essential for\nvarious critical and sensitive applications. Unlike image or tabular data where\nthe importance of each input feature (for the classifier's decision) can be\ndirectly projected into the input, time series distinguishable features (e.g.\ndominant frequency) are often hard to manifest in time domain for a user to\neasily understand. Additionally, most explanation methods require a baseline\nvalue as an indication of the absence of any feature. However, the notion of\nlack of feature, which is often defined as black pixels for vision tasks or\nzero/mean values for tabular data, is not well-defined in time series. Despite\nthe adoption of explainable AI methods (XAI) from tabular and vision domain\ninto time series domain, these differences limit the application of these XAI\nmethods in practice. In this paper, we propose a simple yet effective method\nthat allows a model originally trained on the time domain to be interpreted in\nother explanation spaces using existing methods. We suggest five explanation\nspaces, each of which can potentially alleviate these issues in certain types\nof time series. Our method can be easily integrated into existing platforms\nwithout any changes to trained models or XAI methods. The code will be released\nupon acceptance.",
      "tldr_zh": "这篇论文从一个新视角探讨了时间序列(time series)数据的可解释性问题，强调了其与图像或表格数据不同的挑战，如特征难以在时间域直观显示和基线值的定义不明确，导致现有XAI方法的应用受限。作者提出了一种简单有效的方法，将原本在时间域训练的模型解释到其他explanation spaces，使用现有XAI技术，并建议了五个潜在解释空间，以缓解不同类型时间序列的解释难题。该方法易于集成到现有平台中，无需修改训练模型或XAI工具，从而提升了时间序列可解释性的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01354v3",
      "published_date": "2024-09-02 16:15:26 UTC",
      "updated_date": "2025-04-03 19:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:39:50.866272"
    },
    {
      "arxiv_id": "2409.01345v3",
      "title": "Language Models Benefit from Preparation with Elicited Knowledge",
      "title_zh": "语言模型受益于提取知识的准备",
      "authors": [
        "Jiacan Yu",
        "Hannah An",
        "Lenhart K. Schubert"
      ],
      "abstract": "The zero-shot chain of thought (CoT) approach is often used in question\nanswering (QA) by language models (LMs) for tasks that require multiple\nreasoning steps. However, some QA tasks hinge more on accessing relevant\nknowledge than on chaining reasoning steps. We introduce a simple prompting\ntechnique, called PREP, that involves using two instances of LMs: the first\n(LM1) generates relevant information, and the second (LM2) receives the\ninformation from the user and answers the question. This design is intended to\nmake better use of the LM's instruction-following capability. PREP is\napplicable across various QA tasks without domain-specific prompt engineering.\nPREP is developed on a dataset of 100 QA questions, derived from an extensive\nschematic dataset specifying artifact parts and material composition. These\nquestions ask which of two artifacts is less likely to share materials with\nanother artifact. Such questions probe the LM's knowledge of shared materials\nin the part structure of different artifacts. We test our method on our\nparts-and-materials dataset and three published commonsense reasoning datasets.\nThe average accuracy of our method is consistently higher than that of all the\nother tested methods across all the tested datasets.",
      "tldr_zh": "这篇论文提出了一种名为 PREP 的简单提示技术，以提升语言模型（LMs）在问答（QA）任务中的性能，特别是那些更依赖相关知识而非链式推理（Chain of Thought）的任务。PREP 通过使用两个 LMs 实例——第一个（LM1）生成相关信息，第二个（LM2）基于此信息回答问题——来更好地利用模型的指令遵循能力，且无需特定领域的提示工程。实验在包含 100 个 QA 问题的自定义数据集（涉及工件部件和材料组成）以及三个公开的常识推理数据集上进行，结果显示 PREP 的平均准确率 consistently higher than other tested methods。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01345v3",
      "published_date": "2024-09-02 15:58:27 UTC",
      "updated_date": "2024-12-02 03:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:39:52.882539"
    },
    {
      "arxiv_id": "2409.01344v2",
      "title": "Pairing Analogy-Augmented Generation with Procedural Memory for Procedural Q&A",
      "title_zh": "翻译失败",
      "authors": [
        "K Roth",
        "Rushil Gupta",
        "Simon Halle",
        "Bang Liu"
      ],
      "abstract": "Large language models struggle to synthesize disparate pieces of information\ninto a coherent plan when approaching a complex procedural task. In this work,\nwe introduce a novel formalism and structure for such procedural knowledge.\nBased on this formalism, we present a novel procedural knowledge dataset called\nLCStep, which we created from LangChain tutorials. To leverage this procedural\nknowledge to solve new tasks, we propose analogy-augmented generation (AAG),\nwhich draws inspiration from the human ability to assimilate past experiences\nto solve unfamiliar problems. AAG uses a custom procedure memory store to\nretrieve and adapt specialized domain knowledge to answer new procedural tasks.\nWe demonstrate that AAG outperforms few-shot and RAG baselines on LCStep,\nRecipeNLG, and CHAMP datasets under a pairwise LLM-based evaluation,\ncorroborated by human evaluation in the case of RecipeNLG.",
      "tldr_zh": "本研究解决了大型语言模型（Large Language Models）在处理复杂程序任务时难以整合分散信息的问题，提出了一种结合Analogy-Augmented Generation (AAG)与Procedural Memory的新方法。AAG 借鉴人类类比过去的经验，通过自定义程序记忆存储检索和适应特定领域知识，以生成针对新程序任务的回答。研究创建了名为LCStep的程序知识数据集，并证明AAG在LCStep、RecipeNLG和CHAMP数据集上优于少样本和RAG基线，在配对LLM评估和RecipeNLG的人工评估中表现突出。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01344v2",
      "published_date": "2024-09-02 15:58:24 UTC",
      "updated_date": "2024-10-21 19:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:40:07.282675"
    },
    {
      "arxiv_id": "2409.02138v1",
      "title": "A Financial Time Series Denoiser Based on Diffusion Model",
      "title_zh": "基于扩散模型的金融时间序列去噪器",
      "authors": [
        "Zhuohan Wang",
        "Carmine Ventre"
      ],
      "abstract": "Financial time series often exhibit low signal-to-noise ratio, posing\nsignificant challenges for accurate data interpretation and prediction and\nultimately decision making. Generative models have gained attention as powerful\ntools for simulating and predicting intricate data patterns, with the diffusion\nmodel emerging as a particularly effective method. This paper introduces a\nnovel approach utilizing the diffusion model as a denoiser for financial time\nseries in order to improve data predictability and trading performance. By\nleveraging the forward and reverse processes of the conditional diffusion model\nto add and remove noise progressively, we reconstruct original data from noisy\ninputs. Our extensive experiments demonstrate that diffusion model-based\ndenoised time series significantly enhance the performance on downstream future\nreturn classification tasks. Moreover, trading signals derived from the\ndenoised data yield more profitable trades with fewer transactions, thereby\nminimizing transaction costs and increasing overall trading efficiency.\nFinally, we show that by using classifiers trained on denoised time series, we\ncan recognize the noising state of the market and obtain excess return.",
      "tldr_zh": "本研究提出了一种基于 diffusion model 的金融时间序列去噪器（denoiser），旨在解决金融时间序列低信噪比问题，从而提升数据预测和交易决策的准确性。该方法利用条件 diffusion model 的前向和反向过程逐步添加和去除噪声，从噪声输入重建原始数据。实验结果显示，使用去噪后的时间序列显著提高了下游未来回报分类任务的性能，且从去噪数据衍生的交易信号实现了更高利润、减少交易次数，降低了交易成本并提升了整体效率。最后，该框架还可通过在去噪数据上训练的分类器识别市场噪声状态，从而获得超额回报。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "q-fin.TR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02138v1",
      "published_date": "2024-09-02 15:55:36 UTC",
      "updated_date": "2024-09-02 15:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:40:19.504697"
    },
    {
      "arxiv_id": "2409.01330v1",
      "title": "Pediatric brain tumor classification using digital histopathology and deep learning: evaluation of SOTA methods on a multi-center Swedish cohort",
      "title_zh": "翻译失败",
      "authors": [
        "Iulian Emil Tampu",
        "Per Nyman",
        "Christoforos Spyretos",
        "Ida Blystad",
        "Alia Shamikh",
        "Gabriela Prochazka",
        "Teresita Díaz de Ståhl",
        "Johanna Sandgren",
        "Peter Lundberg",
        "Neda Haj-Hosseini"
      ],
      "abstract": "Brain tumors are the most common solid tumors in children and young adults,\nbut the scarcity of large histopathology datasets has limited the application\nof computational pathology in this group. This study implements two weakly\nsupervised multiple-instance learning (MIL) approaches on patch-features\nobtained from state-of-the-art histology-specific foundation models to classify\npediatric brain tumors in hematoxylin and eosin whole slide images (WSIs) from\na multi-center Swedish cohort. WSIs from 540 subjects (age 8.5$\\pm$4.9 years)\ndiagnosed with brain tumor were gathered from the six Swedish university\nhospitals. Instance (patch)-level features were obtained from WSIs using three\npre-trained feature extractors: ResNet50, UNI and CONCH. Instances were\naggregated using attention-based MIL (ABMIL) or clustering-constrained\nattention MIL (CLAM) for patient-level classification. Models were evaluated on\nthree classification tasks based on the hierarchical classification of\npediatric brain tumors: tumor category, family and type. Model generalization\nwas assessed by training on data from two of the centers and testing on data\nfrom four other centers. Model interpretability was evaluated through\nattention-mapping. The highest classification performance was achieved using\nUNI features and AMBIL aggregation, with Matthew's correlation coefficient of\n0.86$\\pm$0.04, 0.63$\\pm$0.04, and 0.53$\\pm$0.05, for tumor category, family and\ntype classification, respectively. When evaluating generalization, models\nutilizing UNI and CONCH features outperformed those using ResNet50. However,\nthe drop in performance from the in-site to out-of-site testing was similar\nacross feature extractors. These results show the potential of state-of-the-art\ncomputational pathology methods in diagnosing pediatric brain tumors at\ndifferent hierarchical levels with fair generalizability on a multi-center\nnational dataset.",
      "tldr_zh": "本研究评估了最先进（SOTA）深度学习方法在儿童脑肿瘤分类中的性能，使用数字组织病理学（hematoxylin and eosin whole slide images, WSIs）从瑞典六家大学医院的多中心队列中收集了540名受试者（年龄8.5±4.9岁）的图像。研究采用弱监督多实例学习（MIL）方法，包括attention-based MIL (ABMIL)和clustering-constrained attention MIL (CLAM)，并基于预训练特征提取器（ResNet50、UNI和CONCH）从WSIs提取实例级特征，对肿瘤类别、家族和类型进行层次化分类。结果显示，UNI特征结合ABMIL聚合方法表现出最佳性能，Matthew's correlation coefficient (MCC)分别为0.86±0.04（类别）、0.63±0.04（家族）和0.53±0.05（类型），并在跨中心泛化测试中优于ResNet50。该方法证明了计算病理学在多中心数据集上诊断儿童脑肿瘤的潜力，具有良好的可解释性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01330v1",
      "published_date": "2024-09-02 15:32:04 UTC",
      "updated_date": "2024-09-02 15:32:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:40:35.210804"
    },
    {
      "arxiv_id": "2409.01326v1",
      "title": "Grounding Language Models in Autonomous Loco-manipulation Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Wang",
        "Nikos Tsagarakis"
      ],
      "abstract": "Humanoid robots with behavioral autonomy have consistently been regarded as\nideal collaborators in our daily lives and promising representations of\nembodied intelligence. Compared to fixed-based robotic arms, humanoid robots\noffer a larger operational space while significantly increasing the difficulty\nof control and planning. Despite the rapid progress towards general-purpose\nhumanoid robots, most studies remain focused on locomotion ability with few\ninvestigations into whole-body coordination and tasks planning, thus limiting\nthe potential to demonstrate long-horizon tasks involving both mobility and\nmanipulation under open-ended verbal instructions. In this work, we propose a\nnovel framework that learns, selects, and plans behaviors based on tasks in\ndifferent scenarios. We combine reinforcement learning (RL) with whole-body\noptimization to generate robot motions and store them into a motion library. We\nfurther leverage the planning and reasoning features of the large language\nmodel (LLM), constructing a hierarchical task graph that comprises a series of\nmotion primitives to bridge lower-level execution with higher-level planning.\nExperiments in simulation and real-world using the CENTAURO robot show that the\nlanguage model based planner can efficiently adapt to new loco-manipulation\ntasks, demonstrating high autonomy from free-text commands in unstructured\nscenes.",
      "tldr_zh": "该论文探讨了将语言模型应用于人形机器人的自主移动操纵(loco-manipulation)任务，旨在解决现有研究中对全身协调和任务规划的不足。研究提出一个新框架，通过强化学习(RL)结合全身优化生成机器人动作并存储到动作库，并利用大型语言模型(LLM)的规划和推理能力构建分层任务图，以桥接高层规划和底层执行。实验在模拟和真实环境中使用 CENTAURO 机器人证明，该框架能高效适应新任务，从自由文本命令实现高自治性，从而提升机器人对复杂场景的响应能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Summit to ICRA@40. arXiv admin note: substantial text overlap with\n  arXiv:2406.14655",
      "pdf_url": "http://arxiv.org/pdf/2409.01326v1",
      "published_date": "2024-09-02 15:27:48 UTC",
      "updated_date": "2024-09-02 15:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:40:44.205942"
    },
    {
      "arxiv_id": "2409.12968v1",
      "title": "MITHOS: Interactive Mixed Reality Training to Support Professional Socio-Emotional Interactions at Schools",
      "title_zh": "翻译失败",
      "authors": [
        "Lara Chehayeb",
        "Chirag Bhuvaneshwara",
        "Manuel Anglet",
        "Bernhard Hilpert",
        "Ann-Kristin Meyer",
        "Dimitra Tsovaltzi",
        "Patrick Gebhard",
        "Antje Biermann",
        "Sinah Auchtor",
        "Nils Lauinger",
        "Julia Knopf",
        "Andreas Kaiser",
        "Fabian Kersting",
        "Gregor Mehlmann",
        "Florian Lingenfelser",
        "Elisabeth André"
      ],
      "abstract": "Teachers in challenging conflict situations often experience shame and\nself-blame, which relate to the feeling of incompetence but may externalise as\nanger. Sensing mixed signals fails the contingency rule for developing affect\nregulation and may result in confusion for students about their own emotions\nand hinder their emotion regulation. Therefore, being able to constructively\nregulate emotions not only benefits individual experience of emotions but also\nfosters effective interpersonal emotion regulation and influences how a\nsituation is managed. MITHOS is a system aimed at training teachers' conflict\nresolution skills through realistic situative learning opportunities during\nclassroom conflicts. In four stages, MITHOS supports teachers' socio-emotional\nself-awareness, perspective-taking and positive regard. It provides: a) a safe\nvirtual environment to train free social interaction and receive natural social\nfeedback from reciprocal student-agent reactions, b) spatial situational\nperspective taking through an avatar, c) individual virtual reflection guidance\non emotional experiences through co-regulation processes, and d) expert\nfeedback on professional behavioural strategies. This chapter presents the four\nstages and their implementation in a semi-automatic Wizard-of-Oz (WoZ) System.\nThe WoZ system affords collecting data that are used for developing the fully\nautomated hybrid (machine learning and model-based) system, and to validate the\nunderlying psychological and conflict resolution models. We present results\nvalidating the approach in terms of scenario realism, as well as a systematic\ntesting of the effects of external avatar similarity on antecedents of\nself-awareness with behavior similarity. The chapter contributes to a common\nmethodology of conducting interdisciplinary research for human-centered and\ngeneralisable XR and presents a system designed to support it.",
      "tldr_zh": "本研究介绍了 MITHOS 系统，这是一个互动混合现实（Mixed Reality）训练平台，旨在帮助教师在学校冲突情境中提升社会情感互动技能，解决情感调节问题并改善人际关系。系统通过四个阶段支持教师的自我意识、视角转换和积极关注，包括：a) 安全的虚拟环境提供社会互动反馈，b) 通过头像实现空间视角转换，c) 虚拟反思指导促进情感共同调节，以及 d) 专家反馈优化专业行为策略。采用半自动 Wizard-of-Oz (WoZ) 系统进行实施，实验结果验证了场景的现实性和头像相似性对自我意识的影响，为人类中心和可泛化的 XR 研究提供跨学科方法论。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.12968v1",
      "published_date": "2024-09-02 15:24:33 UTC",
      "updated_date": "2024-09-02 15:24:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:05.412170"
    },
    {
      "arxiv_id": "2409.01315v1",
      "title": "Multi-frequency Neural Born Iterative Method for Solving 2-D Inverse Scattering Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Daoqi Liu",
        "Tao Shan",
        "Maokun Li",
        "Fan Yang",
        "Shenheng Xu"
      ],
      "abstract": "In this work, we propose a deep learning-based imaging method for addressing\nthe multi-frequency electromagnetic (EM) inverse scattering problem (ISP). By\ncombining deep learning technology with EM physical laws, we have successfully\ndeveloped a multi-frequency neural Born iterative method (NeuralBIM), guided by\nthe principles of the single-frequency NeuralBIM. This method integrates\nmultitask learning techniques with NeuralBIM's efficient iterative inversion\nprocess to construct a robust multi-frequency Born iterative inversion model.\nDuring training, the model employs a multitask learning approach guided by\nhomoscedastic uncertainty to adaptively allocate the weights of each\nfrequency's data. Additionally, an unsupervised learning method, constrained by\nthe physical laws of ISP, is used to train the multi-frequency NeuralBIM model,\neliminating the need for contrast and total field data. The effectiveness of\nthe multi-frequency NeuralBIM is validated through synthetic and experimental\ndata, demonstrating improvements in accuracy and computational efficiency for\nsolving ISP. Moreover, this method exhibits strong generalization capabilities\nand noise resistance. The multi-frequency NeuralBIM method explores a novel\ninversion method for multi-frequency EM data and provides an effective solution\nfor the electromagnetic ISP of multi-frequency data.",
      "tldr_zh": "本文提出了一种基于深度学习的成像方法，即多频 Neural Born Iterative Method (NeuralBIM)，用于解决二维电磁（EM）反散射问题（ISP）。该方法整合多任务学习（multitask learning）和无监督学习，结合 EM 物理定律，通过 homoscedastic uncertainty 指导的自适应权重分配，实现高效的迭代反演过程，且无需对比和总场数据。实验结果显示，NeuralBIM 在合成和实验数据上显著提高了准确性和计算效率，并展现出强大的泛化能力和抗噪声性能，为多频 EM 数据反演提供了一种新型解决方案。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "35Q61",
        "I.2.6; G.1.8; G.1.3"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01315v1",
      "published_date": "2024-09-02 15:16:07 UTC",
      "updated_date": "2024-09-02 15:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:10.273271"
    },
    {
      "arxiv_id": "2409.01303v1",
      "title": "Topological degree as a discrete diagnostic for disentanglement, with applications to the $Δ$VAE",
      "title_zh": "拓扑度作为解缠结的离散诊断工具，并应用于 ΔVAE",
      "authors": [
        "Mahefa Ratsisetraina Ravelonanosy",
        "Vlado Menkovski",
        "Jacobus W. Portegies"
      ],
      "abstract": "We investigate the ability of Diffusion Variational Autoencoder ($\\Delta$VAE)\nwith unit sphere $\\mathcal{S}^2$ as latent space to capture topological and\ngeometrical structure and disentangle latent factors in datasets. For this, we\nintroduce a new diagnostic of disentanglement: namely the topological degree of\nthe encoder, which is a map from the data manifold to the latent space. By\nusing tools from homology theory, we derive and implement an algorithm that\ncomputes this degree. We use the algorithm to compute the degree of the encoder\nof models that result from the training procedure. Our experimental results\nshow that the $\\Delta$VAE achieves relatively small LSBD scores, and that\nregardless of the degree after initialization, the degree of the encoder after\ntraining becomes $-1$ or $+1$, which implies that the resulting encoder is at\nleast homotopic to a homeomorphism.",
      "tldr_zh": "这篇论文探讨了Diffusion Variational Autoencoder ($Δ$VAE) 使用单位球面 $\\mathcal{S}^2$ 作为潜在空间的能力，焦点在于捕捉拓扑和几何结构并实现潜在因素的解缠结。研究者引入了编码器的拓扑度 (topological degree) 作为一种新的离散诊断工具，并利用同调理论 (homology theory) 开发了相应的计算算法。实验结果显示，$Δ$VAE 取得了较低的 LSBD scores，且训练后编码器的度变为 -1 或 +1，这表明编码器至少同伦于一个同胚映射 (homotopic to a homeomorphism)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AT",
        "51H20 55N35 68T09 68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01303v1",
      "published_date": "2024-09-02 14:51:31 UTC",
      "updated_date": "2024-09-02 14:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:20.857910"
    },
    {
      "arxiv_id": "2409.02136v1",
      "title": "Large Language Models versus Classical Machine Learning: Performance in COVID-19 Mortality Prediction Using High-Dimensional Tabular Data",
      "title_zh": "大语言模型与经典机器学习：在使用高维表格数据的 COVID-19 死亡率预测中的性能",
      "authors": [
        "Mohammadreza Ghaffarzadeh-Esfahani",
        "Mahdi Ghaffarzadeh-Esfahani",
        "Arian Salahi-Niri",
        "Hossein Toreyhi",
        "Zahra Atf",
        "Amirali Mohsenzadeh-Kermani",
        "Mahshad Sarikhani",
        "Zohreh Tajabadi",
        "Fatemeh Shojaeian",
        "Mohammad Hassan Bagheri",
        "Aydin Feyzi",
        "Mohammadamin Tarighatpayma",
        "Narges Gazmeh",
        "Fateme Heydari",
        "Hossein Afshar",
        "Amirreza Allahgholipour",
        "Farid Alimardani",
        "Ameneh Salehi",
        "Naghmeh Asadimanesh",
        "Mohammad Amin Khalafi",
        "Hadis Shabanipour",
        "Ali Moradi",
        "Sajjad Hossein Zadeh",
        "Omid Yazdani",
        "Romina Esbati",
        "Moozhan Maleki",
        "Danial Samiei Nasr",
        "Amirali Soheili",
        "Hossein Majlesi",
        "Saba Shahsavan",
        "Alireza Soheilipour",
        "Nooshin Goudarzi",
        "Erfan Taherifard",
        "Hamidreza Hatamabadi",
        "Jamil S Samaan",
        "Thomas Savage",
        "Ankit Sakhuja",
        "Ali Soroush",
        "Girish Nadkarni",
        "Ilad Alavi Darazam",
        "Mohamad Amin Pourhoseingholi",
        "Seyed Amir Ahmad Safavi-Naini"
      ],
      "abstract": "Background: This study aimed to evaluate and compare the performance of\nclassical machine learning models (CMLs) and large language models (LLMs) in\npredicting mortality associated with COVID-19 by utilizing a high-dimensional\ntabular dataset.\n  Materials and Methods: We analyzed data from 9,134 COVID-19 patients\ncollected across four hospitals. Seven CML models, including XGBoost and random\nforest (RF), were trained and evaluated. The structured data was converted into\ntext for zero-shot classification by eight LLMs, including GPT-4 and\nMistral-7b. Additionally, Mistral-7b was fine-tuned using the QLoRA approach to\nenhance its predictive capabilities.\n  Results: Among the CML models, XGBoost and RF achieved the highest accuracy,\nwith F1 scores of 0.87 for internal validation and 0.83 for external\nvalidation. In the LLM category, GPT-4 was the top performer with an F1 score\nof 0.43. Fine-tuning Mistral-7b significantly improved its recall from 1% to\n79%, resulting in an F1 score of 0.74, which was stable during external\nvalidation.\n  Conclusion: While LLMs show moderate performance in zero-shot classification,\nfine-tuning can significantly enhance their effectiveness, potentially aligning\nthem closer to CML models. However, CMLs still outperform LLMs in\nhigh-dimensional tabular data tasks.",
      "tldr_zh": "本研究比较了经典机器学习模型 (CMLs) 和大型语言模型 (LLMs) 在使用高维表格数据预测 COVID-19 死亡率方面的表现，旨在评估二者在该任务中的效能。研究分析了来自四家医院的 9,134 名患者数据，训练了七种 CMLs（如 XGBoost 和 Random Forest），并将结构化数据转换为文本，用于八种 LLMs（如 GPT-4 和 Mistral-7B）的零样本分类，同时对 Mistral-7B 采用 QLoRA 方法进行微调。结果显示，CMLs 中的 XGBoost 和 Random Forest 在内部验证中 F1 分数达 0.87，在外部验证中达 0.83，而 LLMs 的 GPT-4 F1 分数为 0.43，微调后 Mistral-7B 的 F1 分数提升至 0.74。总体结论是，LLMs 通过微调可显著改善性能，但 CMLs 在高维表格数据任务中仍表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "92C50, 68T50",
        "J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "Code is available at:\n  https://github.com/mohammad-gh009/Large-Language-Models-vs-Classical-Machine-learning\n  and https://github.com/Sdamirsa/Tehran_COVID_Cohort. The datasets are\n  available from the corresponding author on reasonable request\n  (sdamirsa@ymail.com)",
      "pdf_url": "http://arxiv.org/pdf/2409.02136v1",
      "published_date": "2024-09-02 14:51:12 UTC",
      "updated_date": "2024-09-02 14:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:34.817991"
    },
    {
      "arxiv_id": "2409.10554v1",
      "title": "An Examination of Offline-Trained Encoders in Vision-Based Deep Reinforcement Learning for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Shawan Mohammed",
        "Alp Argun",
        "Nicolas Bonnotte",
        "Gerd Ascheid"
      ],
      "abstract": "Our research investigates the challenges Deep Reinforcement Learning (DRL)\nfaces in complex, Partially Observable Markov Decision Processes (POMDP) such\nas autonomous driving (AD), and proposes a solution for vision-based navigation\nin these environments. Partial observability reduces RL performance\nsignificantly, and this can be mitigated by augmenting sensor information and\ndata fusion to reflect a more Markovian environment. However, this necessitates\nan increasingly complex perception module, whose training via RL is complicated\ndue to inherent limitations. As the neural network architecture becomes more\ncomplex, the reward function's effectiveness as an error signal diminishes\nsince the only source of supervision is the reward, which is often noisy,\nsparse, and delayed. Task-irrelevant elements in images, such as the sky or\ncertain objects, pose additional complexities. Our research adopts an\noffline-trained encoder to leverage large video datasets through\nself-supervised learning to learn generalizable representations. Then, we train\na head network on top of these representations through DRL to learn to control\nan ego vehicle in the CARLA AD simulator. This study presents a broad\ninvestigation of the impact of different learning schemes for offline-training\nof encoders on the performance of DRL agents in challenging AD tasks.\nFurthermore, we show that the features learned by watching BDD100K driving\nvideos can be directly transferred to achieve lane following and collision\navoidance in CARLA simulator, in a zero-shot learning fashion. Finally, we\nexplore the impact of various architectural decisions for the RL networks to\nutilize the transferred representations efficiently. Therefore, in this work,\nwe introduce and validate an optimal way for obtaining suitable representations\nof the environment, and transferring them to RL networks.",
      "tldr_zh": "本研究探讨了Deep Reinforcement Learning (DRL) 在复杂Partially Observable Markov Decision Processes (POMDP)环境（如自动驾驶）中的挑战，特别是部分可观测性导致的性能下降问题。研究提出使用离线训练的编码器，通过self-supervised learning从大型视频数据集（如BDD100K）学习可泛化的环境表示，然后在DRL框架中训练头部网络以控制车辆。实验在CARLA模拟器上验证了不同离线训练方案对DRL代理性能的影响，并展示了从BDD100K学到的特征可实现零样本转移，实现车道跟随和碰撞避免。该方法为优化环境表示并高效转移到RL网络提供了有效策略。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10554v1",
      "published_date": "2024-09-02 14:16:23 UTC",
      "updated_date": "2024-09-02 14:16:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:46.832660"
    },
    {
      "arxiv_id": "2409.02720v2",
      "title": "GET-UP: GEomeTric-aware Depth Estimation with Radar Points UPsampling",
      "title_zh": "翻译失败",
      "authors": [
        "Huawei Sun",
        "Zixu Wang",
        "Hao Feng",
        "Julius Ott",
        "Lorenzo Servadei",
        "Robert Wille"
      ],
      "abstract": "Depth estimation plays a pivotal role in autonomous driving, facilitating a\ncomprehensive understanding of the vehicle's 3D surroundings. Radar, with its\nrobustness to adverse weather conditions and capability to measure distances,\nhas drawn significant interest for radar-camera depth estimation. However,\nexisting algorithms process the inherently noisy and sparse radar data by\nprojecting 3D points onto the image plane for pixel-level feature extraction,\noverlooking the valuable geometric information contained within the radar point\ncloud. To address this gap, we propose GET-UP, leveraging attention-enhanced\nGraph Neural Networks (GNN) to exchange and aggregate both 2D and 3D\ninformation from radar data. This approach effectively enriches the feature\nrepresentation by incorporating spatial relationships compared to traditional\nmethods that rely only on 2D feature extraction. Furthermore, we incorporate a\npoint cloud upsampling task to densify the radar point cloud, rectify point\npositions, and derive additional 3D features under the guidance of lidar data.\nFinally, we fuse radar and camera features during the decoding phase for depth\nestimation. We benchmark our proposed GET-UP on the nuScenes dataset, achieving\nstate-of-the-art performance with a 15.3% and 14.7% improvement in MAE and RMSE\nover the previously best-performing model. Code:\nhttps://github.com/harborsarah/GET-UP",
      "tldr_zh": "本论文提出 GET-UP 方法，用于改进自动驾驶中的深度估计问题，该方法通过 attention-enhanced Graph Neural Networks (GNN) 交换和聚合 radar 数据的2D和3D信息，充分利用 radar 点云的几何特性，避免了传统方法的局限。GET-UP 还引入点云 upsampling 任务，在 lidar 数据的指导下密化 radar 点云、修正点位置并提取额外3D特征，最终融合 radar 和 camera 特征进行深度估计。在 nuScenes 数据集上，GET-UP 取得了 state-of-the-art 性能，比最佳模型提高了 15.3% 的 MAE 和 14.7% 的 RMSE，为鲁棒的深度估计提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.02720v2",
      "published_date": "2024-09-02 14:15:09 UTC",
      "updated_date": "2024-09-08 18:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:41:58.671863"
    },
    {
      "arxiv_id": "2409.01256v1",
      "title": "Real-time Accident Anticipation for Autonomous Driving Through Monocular Depth-Enhanced 3D Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Haicheng Liao",
        "Yongkang Li",
        "Chengyue Wang",
        "Songning Lai",
        "Zhenning Li",
        "Zilin Bian",
        "Jaeyoung Lee",
        "Zhiyong Cui",
        "Guohui Zhang",
        "Chengzhong Xu"
      ],
      "abstract": "The primary goal of traffic accident anticipation is to foresee potential\naccidents in real time using dashcam videos, a task that is pivotal for\nenhancing the safety and reliability of autonomous driving technologies. In\nthis study, we introduce an innovative framework, AccNet, which significantly\nadvances the prediction capabilities beyond the current state-of-the-art (SOTA)\n2D-based methods by incorporating monocular depth cues for sophisticated 3D\nscene modeling. Addressing the prevalent challenge of skewed data distribution\nin traffic accident datasets, we propose the Binary Adaptive Loss for Early\nAnticipation (BA-LEA). This novel loss function, together with a multi-task\nlearning strategy, shifts the focus of the predictive model towards the\ncritical moments preceding an accident. {We rigorously evaluate the performance\nof our framework on three benchmark datasets--Dashcam Accident Dataset (DAD),\nCar Crash Dataset (CCD), and AnAn Accident Detection (A3D), and DADA-2000\nDataset--demonstrating its superior predictive accuracy through key metrics\nsuch as Average Precision (AP) and mean Time-To-Accident (mTTA).",
      "tldr_zh": "本文提出 AccNet 框架，通过整合 monocular depth cues 进行增强的 3D 场景建模，实现自动驾驶中基于 dashcam 视频的实时交通事故预测，超越现有 2D 方法。针对数据集中的数据分布偏差，该框架引入 Binary Adaptive Loss for Early Anticipation (BA-LEA) 损失函数和多任务学习策略，重点关注事故前关键时刻。实验在 Dashcam Accident Dataset (DAD)、Car Crash Dataset (CCD)、A3D 和 DADA-2000 等基准数据集上显示，AccNet 在 Average Precision (AP) 和 mean Time-To-Accident (mTTA) 等指标上表现出色，显著提升预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01256v1",
      "published_date": "2024-09-02 13:46:25 UTC",
      "updated_date": "2024-09-02 13:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:42:16.752956"
    },
    {
      "arxiv_id": "2409.01247v3",
      "title": "Conversational Complexity for Assessing Risk in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "John Burden",
        "Manuel Cebrian",
        "Jose Hernandez-Orallo"
      ],
      "abstract": "Large Language Models (LLMs) present a dual-use dilemma: they enable\nbeneficial applications while harboring potential for harm, particularly\nthrough conversational interactions. Despite various safeguards, advanced LLMs\nremain vulnerable. A watershed case in early 2023 involved journalist Kevin\nRoose's extended dialogue with Bing, an LLM-powered search engine, which\nrevealed harmful outputs after probing questions, highlighting vulnerabilities\nin the model's safeguards. This contrasts with simpler early jailbreaks, like\nthe \"Grandma Jailbreak,\" where users framed requests as innocent help for a\ngrandmother, easily eliciting similar content. This raises the question: How\nmuch conversational effort is needed to elicit harmful information from LLMs?\nWe propose two measures to quantify this effort: Conversational Length (CL),\nwhich measures the number of conversational turns needed to obtain a specific\nharmful response, and Conversational Complexity (CC), defined as the Kolmogorov\ncomplexity of the user's instruction sequence leading to the harmful response.\nTo address the incomputability of Kolmogorov complexity, we approximate CC\nusing a reference LLM to estimate the compressibility of the user instructions.\nApplying this approach to a large red-teaming dataset, we perform a\nquantitative analysis examining the statistical distribution of harmful and\nharmless conversational lengths and complexities. Our empirical findings\nsuggest that this distributional analysis and the minimization of CC serve as\nvaluable tools for understanding AI safety, offering insights into the\naccessibility of harmful information. This work establishes a foundation for a\nnew perspective on LLM safety, centered around the algorithmic complexity of\npathways to harm.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在对话交互中潜在风险评估问题，提出两种量化指标：Conversational Length (CL) 和 Conversational Complexity (CC)。CL 衡量获取有害响应的对话轮数，而 CC 通过参考 LLM 近似 Kolmogorov 复杂度，评估用户指令序列的可压缩性，以度量对话努力。研究对大型 red-teaming 数据集进行分析，发现这些指标的统计分布有助于揭示有害信息的可访问性，并为提升 AI 安全提供新的基础视角。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01247v3",
      "published_date": "2024-09-02 13:29:44 UTC",
      "updated_date": "2024-11-29 01:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:42:27.205213"
    },
    {
      "arxiv_id": "2409.01245v1",
      "title": "Revisiting Safe Exploration in Safe Reinforcement learning",
      "title_zh": "重新审视安全强化学习中的安全探索",
      "authors": [
        "David Eckel",
        "Baohe Zhang",
        "Joschka Bödecker"
      ],
      "abstract": "Safe reinforcement learning (SafeRL) extends standard reinforcement learning\nwith the idea of safety, where safety is typically defined through the\nconstraint of the expected cost return of a trajectory being below a set limit.\nHowever, this metric fails to distinguish how costs accrue, treating infrequent\nsevere cost events as equal to frequent mild ones, which can lead to riskier\nbehaviors and result in unsafe exploration. We introduce a new metric, expected\nmaximum consecutive cost steps (EMCC), which addresses safety during training\nby assessing the severity of unsafe steps based on their consecutive\noccurrence. This metric is particularly effective for distinguishing between\nprolonged and occasional safety violations. We apply EMMC in both on- and\noff-policy algorithm for benchmarking their safe exploration capability.\nFinally, we validate our metric through a set of benchmarks and propose a new\nlightweight benchmark task, which allows fast evaluation for algorithm design.",
      "tldr_zh": "本研究重新审视了Safe Reinforcement Learning（SafeRL）中的安全探索问题，指出传统指标（如期望成本回报）无法区分成本积累方式，导致频繁轻微违规与偶尔严重违规被等同对待，从而引发风险行为。作者引入了新的指标expected maximum consecutive cost steps (EMCC)，通过评估连续不安全步骤的严重性，更有效地识别持续安全违规。实验结果显示，EMCC应用于on-policy和off-policy算法后，能显著提升安全探索能力，并在新提出的轻量级基准任务中得到验证，为SafeRL算法设计提供了更可靠的评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01245v1",
      "published_date": "2024-09-02 13:29:29 UTC",
      "updated_date": "2024-09-02 13:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:42:35.847953"
    },
    {
      "arxiv_id": "2409.01241v3",
      "title": "CyberCortex.AI: An AI-based Operating System for Autonomous Robotics and Complex Automation",
      "title_zh": "CyberCortex.AI: 一种基于人工智能的操作系统，用于自主机器人和复杂自动化",
      "authors": [
        "Sorin Grigorescu",
        "Mihai Zaha"
      ],
      "abstract": "The underlying framework for controlling autonomous robots and complex\nautomation applications are Operating Systems (OS) capable of scheduling\nperception-and-control tasks, as well as providing real-time data communication\nto other robotic peers and remote cloud computers. In this paper, we introduce\nCyberCortex AI, a robotics OS designed to enable heterogeneous AI-based\nrobotics and complex automation applications. CyberCortex AI is a decentralized\ndistributed OS which enables robots to talk to each other, as well as to High\nPerformance Computers (HPC) in the cloud. Sensory and control data from the\nrobots is streamed towards HPC systems with the purpose of training AI\nalgorithms, which are afterwards deployed on the robots. Each functionality of\na robot (e.g. sensory data acquisition, path planning, motion control, etc.) is\nexecuted within a so-called DataBlock of Filters shared through the internet,\nwhere each filter is computed either locally on the robot itself, or remotely\non a different robotic system. The data is stored and accessed via a so-called\nTemporal Addressable Memory (TAM), which acts as a gateway between each\nfilter's input and output. CyberCortex AI has two main components: i) the\nCyberCortex AI inference system, which is a real-time implementation of the\nDataBlock running on the robots' embedded hardware, and ii) the CyberCortex AI\ndojo, which runs on an HPC computer in the cloud, and it is used to design,\ntrain and deploy AI algorithms. We present a quantitative and qualitative\nperformance analysis of the proposed approach using two collaborative robotics\napplications: i) a forest fires prevention system based on an Unitree A1 legged\nrobot and an Anafi Parrot 4K drone, as well as ii) an autonomous driving system\nwhich uses CyberCortex AI for collaborative perception and motion control.",
      "tldr_zh": "本论文引入了 CyberCortex AI，一种基于 AI 的操作系统（OS），旨在支持自主机器人和复杂自动化应用，通过去中心化分布式架构实现机器人间以及与云端 High Performance Computers (HPC) 的实时数据通信。系统核心组件包括 DataBlock of Filters，用于执行机器人功能（如感知数据获取、路径规划和运动控制），以及 Temporal Addressable Memory (TAM) 作为数据输入输出网关；另外，它包含 CyberCortex AI inference system（实时运行于机器人硬件）和 CyberCortex AI dojo（云端用于设计、训练和部署 AI 算法）。实验在两个场景中进行了定量和定性分析：森林火灾预防系统（结合 Unitree A1 机器人和 Anafi Parrot 4K 无人机）和自主驾驶系统，展示了其在协作感知和运动控制方面的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.OS"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01241v3",
      "published_date": "2024-09-02 13:14:50 UTC",
      "updated_date": "2024-10-04 11:32:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:42:51.153686"
    },
    {
      "arxiv_id": "2409.10552v1",
      "title": "AI Literacy for All: Adjustable Interdisciplinary Socio-technical Curriculum",
      "title_zh": "面向所有人的人工智能素养：可调整的跨学科社会技术课程",
      "authors": [
        "Sri Yash Tadimalla",
        "Mary Lou Maher"
      ],
      "abstract": "This paper presents a curriculum, \"AI Literacy for All,\" to promote an\ninterdisciplinary understanding of AI, its socio-technical implications, and\nits practical applications for all levels of education. With the rapid\nevolution of artificial intelligence (AI), there is a need for AI literacy that\ngoes beyond the traditional AI education curriculum. AI literacy has been\nconceptualized in various ways, including public literacy, competency building\nfor designers, conceptual understanding of AI concepts, and domain-specific\nupskilling. Most of these conceptualizations were established before the public\nrelease of Generative AI (Gen-AI) tools like ChatGPT. AI education has focused\non the principles and applications of AI through a technical lens that\nemphasizes the mastery of AI principles, the mathematical foundations\nunderlying these technologies, and the programming and mathematical skills\nnecessary to implement AI solutions. In AI Literacy for All, we emphasize a\nbalanced curriculum that includes technical and non-technical learning outcomes\nto enable a conceptual understanding and critical evaluation of AI technologies\nin an interdisciplinary socio-technical context. The paper presents four\npillars of AI literacy: understanding the scope and technical dimensions of AI,\nlearning how to interact with Gen-AI in an informed and responsible way, the\nsocio-technical issues of ethical and responsible AI, and the social and future\nimplications of AI. While it is important to include all learning outcomes for\nAI education in a Computer Science major, the learning outcomes can be adjusted\nfor other learning contexts, including, non-CS majors, high school summer\ncamps, the adult workforce, and the public. This paper advocates for a shift in\nAI literacy education to offer a more interdisciplinary socio-technical\napproach as a pathway to broaden participation in AI.",
      "tldr_zh": "这篇论文介绍了“AI Literacy for All”课程，这是一个可调整的跨学科社会技术（socio-technical）课程，旨在提升AI素养，包括AI的技术基础、社会影响和实际应用，以适应不同教育水平。课程强调平衡技术与非技术学习成果，构建四个支柱：AI的范围和技术维度、与Generative AI的负责任互动、AI的伦理和社会技术问题，以及AI的社会和未来影响。该框架可根据计算机科学专业、非CS专业、高中营或公众等不同背景进行调整，倡导更广泛的跨学科AI教育以促进参与和批判性评估。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Published at 2024 IEEE Frontiers in Education Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.10552v1",
      "published_date": "2024-09-02 13:13:53 UTC",
      "updated_date": "2024-09-02 13:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:43:00.711836"
    },
    {
      "arxiv_id": "2409.01216v1",
      "title": "ESP-PCT: Enhanced VR Semantic Performance through Efficient Compression of Temporal and Spatial Redundancies in Point Cloud Transformers",
      "title_zh": "ESP-PCT：通过点云变换器中时间和空间冗",
      "authors": [
        "Luoyu Mei",
        "Shuai Wang",
        "Yun Cheng",
        "Ruofeng Liu",
        "Zhimeng Yin",
        "Wenchao Jiang",
        "Shuai Wang",
        "Wei Gong"
      ],
      "abstract": "Semantic recognition is pivotal in virtual reality (VR) applications,\nenabling immersive and interactive experiences. A promising approach is\nutilizing millimeter-wave (mmWave) signals to generate point clouds. However,\nthe high computational and memory demands of current mmWave point cloud models\nhinder their efficiency and reliability. To address this limitation, our paper\nintroduces ESP-PCT, a novel Enhanced Semantic Performance Point Cloud\nTransformer with a two-stage semantic recognition framework tailored for VR\napplications. ESP-PCT takes advantage of the accuracy of sensory point cloud\ndata and optimizes the semantic recognition process, where the localization and\nfocus stages are trained jointly in an end-to-end manner. We evaluate ESP-PCT\non various VR semantic recognition conditions, demonstrating substantial\nenhancements in recognition efficiency. Notably, ESP-PCT achieves a remarkable\naccuracy of 93.2% while reducing the computational requirements (FLOPs) by\n76.9% and memory usage by 78.2% compared to the existing Point Transformer\nmodel simultaneously. These underscore ESP-PCT's potential in VR semantic\nrecognition by achieving high accuracy and reducing redundancy. The code and\ndata of this project are available at\n\\url{https://github.com/lymei-SEU/ESP-PCT}.",
      "tldr_zh": "本论文提出 ESP-PCT，一种针对虚拟现实 (VR) 应用的增强语义性能点云 Transformer，通过高效压缩时间和空间冗余来解决毫米波 (mmWave) 点云模型的高计算和内存需求问题。ESP-PCT 采用两阶段语义识别框架，包括定位和聚焦阶段，并以端到端方式联合训练，以优化点云数据的准确性和效率。在各种 VR 语义识别条件下，ESP-PCT 实现了 93.2% 的准确率，同时将 FLOPs 减少 76.9% 和内存使用减少 78.2%，相较于现有 Point Transformer 模型显著提升了性能和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01216v1",
      "published_date": "2024-09-02 12:48:40 UTC",
      "updated_date": "2024-09-02 12:48:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:43:15.460548"
    },
    {
      "arxiv_id": "2409.01201v1",
      "title": "EnCLAP++: Analyzing the EnCLAP Framework for Optimizing Automated Audio Captioning Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyeon Kim",
        "Minjeon Jeon",
        "Jaeyoon Jung",
        "Sang Hoon Woo",
        "Jinjoo Lee"
      ],
      "abstract": "In this work, we aim to analyze and optimize the EnCLAP framework, a\nstate-of-the-art model in automated audio captioning. We investigate the impact\nof modifying the acoustic encoder components, explore pretraining with\ndifferent dataset scales, and study the effectiveness of a reranking scheme.\nThrough extensive experimentation and quantitative analysis of generated\ncaptions, we develop EnCLAP++, an enhanced version that significantly surpasses\nthe original.",
      "tldr_zh": "本研究分析并优化了 EnCLAP 框架，这是一个用于自动音频描述（Automated Audio Captioning）的先进模型。研究团队调查了修改声学编码器（acoustic encoder）组件的影响、不同数据集规模的预训练效果，以及重新排序方案（reranking scheme）的有效性。通过广泛的实验和定量分析，他们开发了 EnCLAP++，这一增强版本在生成的音频描述性能上显著超过了原模型。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to DCASE2024 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.01201v1",
      "published_date": "2024-09-02 12:23:18 UTC",
      "updated_date": "2024-09-02 12:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:43:23.778860"
    },
    {
      "arxiv_id": "2409.13693v1",
      "title": "Declarative Integration and Management of Large Language Models through Finite Automata: Application to Automation, Communication, and Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Thierry Petit",
        "Arnault Pachot",
        "Claire Conan-Vrinat",
        "Alexandre Dubarry"
      ],
      "abstract": "This article introduces an innovative architecture designed to declaratively\ncombine Large Language Models (LLMs) with shared histories, and triggers to\nidentify the most appropriate LLM for a given task. Our approach is general and\ndeclarative, relying on the construction of finite automata coupled with an\nevent management system. The developed tool is crafted to facilitate the\nefficient and complex integration of LLMs with minimal programming effort,\nespecially, but not only, for integrating methods of positive psychology to AI.\nThe flexibility of our technique is demonstrated through applied examples in\nautomation, communication, and ethics.",
      "tldr_zh": "该论文提出了一种创新架构，用于声明式整合和管理 Large Language Models (LLMs)，通过共享历史和触发器来选择最适合的任务模型。该方法依赖于 finite automata 和事件管理系统的构建，旨在以最小编程努力实现 LLMs 的高效复杂整合，尤其适用于将积极心理学方法融入 AI。研究通过自动化、通信和伦理领域的应用示例，展示了该技术的通用性和灵活性。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.CL",
        "cs.ET",
        "cs.HC",
        "68T20",
        "I.2.7; H.5.2; K.4.1; D.3.2"
      ],
      "primary_category": "cs.FL",
      "comment": "Submitted to IAAI-2025, Philadelphia, PA",
      "pdf_url": "http://arxiv.org/pdf/2409.13693v1",
      "published_date": "2024-09-02 11:50:52 UTC",
      "updated_date": "2024-09-02 11:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:43:40.382721"
    },
    {
      "arxiv_id": "2409.02134v1",
      "title": "Edge AI: Evaluation of Model Compression Techniques for Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Samer Francy",
        "Raghubir Singh"
      ],
      "abstract": "This work evaluates the compression techniques on ConvNeXt models in image\nclassification tasks using the CIFAR-10 dataset. Structured pruning,\nunstructured pruning, and dynamic quantization methods are evaluated to reduce\nmodel size and computational complexity while maintaining accuracy. The\nexperiments, conducted on cloud-based platforms and edge device, assess the\nperformance of these techniques. Results show significant reductions in model\nsize, with up to 75% reduction achieved using structured pruning techniques.\nAdditionally, dynamic quantization achieves a reduction of up to 95% in the\nnumber of parameters. Fine-tuned models exhibit improved compression\nperformance, indicating the benefits of pre-training in conjunction with\ncompression techniques. Unstructured pruning methods reveal trends in accuracy\nand compression, with limited reductions in computational complexity. The\ncombination of OTOV3 pruning and dynamic quantization further enhances\ncompression performance, resulting 89.7% reduction in size, 95% reduction with\nnumber of parameters and MACs, and 3.8% increase with accuracy. The deployment\nof the final compressed model on edge device demonstrates high accuracy 92.5%\nand low inference time 20 ms, validating the effectiveness of compression\ntechniques for real-world edge computing applications.",
      "tldr_zh": "这篇论文评估了在 ConvNeXt 模型上用于图像分类任务的模型压缩技术，包括 structured pruning、unstructured pruning 和 dynamic quantization 方法，使用 CIFAR-10 数据集，旨在减少模型大小和计算复杂度同时保持准确性。实验在云平台和边缘设备上进行，结果显示 structured pruning 可实现模型大小减少高达 75%，dynamic quantization 可减少参数高达 95%，而结合 OTOV3 pruning 和 dynamic quantization 进一步提升了性能，实现了 89.7% 的大小减少、95% 的参数和 MACs 减少，以及 3.8% 的准确率提升。最终，在边缘设备上部署的压缩模型达到了 92.5% 的准确率和 20 ms 的推理时间，验证了这些技术在真实边缘计算应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02134v1",
      "published_date": "2024-09-02 11:48:19 UTC",
      "updated_date": "2024-09-02 11:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:43:53.542616"
    },
    {
      "arxiv_id": "2409.01178v1",
      "title": "Integrating End-to-End and Modular Driving Approaches for Online Corner Case Detection in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Gemb Kaljavesi",
        "Xiyan Su",
        "Frank Diermeyer"
      ],
      "abstract": "Online corner case detection is crucial for ensuring safety in autonomous\ndriving vehicles. Current autonomous driving approaches can be categorized into\nmodular approaches and end-to-end approaches. To leverage the advantages of\nboth, we propose a method for online corner case detection that integrates an\nend-to-end approach into a modular system. The modular system takes over the\nprimary driving task and the end-to-end network runs in parallel as a secondary\none, the disagreement between the systems is then used for corner case\ndetection. We implement this method on a real vehicle and evaluate it\nqualitatively. Our results demonstrate that end-to-end networks, known for\ntheir superior situational awareness, as secondary driving systems, can\neffectively contribute to corner case detection. These findings suggest that\nsuch an approach holds potential for enhancing the safety of autonomous\nvehicles.",
      "tldr_zh": "本研究提出了一种整合端到-end (end-to-end) 和模块化 (modular) 方法的在线角落案例 (corner case) 检测技术，旨在提升自动驾驶 (autonomous driving) 车辆的安全性。通过让模块化系统负责主要驾驶任务，而端-to-end 网络作为辅助系统并行运行，系统间的分歧被用于识别潜在角落案例。实验在真实车辆上进行定性评估，结果显示端-to-end 网络的优越情境感知能力能有效贡献于角落案例检测，为提高自动驾驶安全性提供了潜在解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE SMC 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01178v1",
      "published_date": "2024-09-02 11:14:41 UTC",
      "updated_date": "2024-09-02 11:14:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:44:05.529642"
    },
    {
      "arxiv_id": "2409.01175v1",
      "title": "Logit Scaling for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Andrija Djurisic",
        "Rosanne Liu",
        "Mladen Nikolic"
      ],
      "abstract": "The safe deployment of machine learning and AI models in open-world settings\nhinges critically on the ability to detect out-of-distribution (OOD) data\naccurately, data samples that contrast vastly from what the model was trained\nwith. Current approaches to OOD detection often require further training the\nmodel, and/or statistics about the training data which may no longer be\naccessible. Additionally, many existing OOD detection methods struggle to\nmaintain performance when transferred across different architectures. Our\nresearch tackles these issues by proposing a simple, post-hoc method that does\nnot require access to the training data distribution, keeps a trained network\nintact, and holds strong performance across a variety of architectures. Our\nmethod, Logit Scaling (LTS), as the name suggests, simply scales the logits in\na manner that effectively distinguishes between in-distribution (ID) and OOD\nsamples. We tested our method on benchmarks across various scales, including\nCIFAR-10, CIFAR-100, ImageNet and OpenOOD. The experiments cover 3 ID and 14\nOOD datasets, as well as 9 model architectures. Overall, we demonstrate\nstate-of-the-art performance, robustness and adaptability across different\narchitectures, paving the way towards a universally applicable solution for\nadvanced OOD detection.",
      "tldr_zh": "本研究针对机器学习模型在开放环境中的安全部署，提出了一种简单的事后方法Logit Scaling (LTS)，用于检测Out-of-Distribution (OOD)数据，该方法通过缩放logits来有效区分In-Distribution (ID)和OOD样本，而无需访问训练数据分布或进一步训练模型。LTS的优势在于其鲁棒性和跨架构适应性，在包括CIFAR-10、CIFAR-100、ImageNet和OpenOOD等基准上进行了测试，涵盖3个ID数据集、14个OOD数据集和9个模型架构。实验结果显示，该方法在各种场景下实现了state-of-the-art性能，显著提升了OOD检测的通用性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01175v1",
      "published_date": "2024-09-02 11:10:44 UTC",
      "updated_date": "2024-09-02 11:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:44:22.506710"
    },
    {
      "arxiv_id": "2409.01160v1",
      "title": "Expanding on EnCLAP with Auxiliary Retrieval Model for Automated Audio Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeyeon Kim",
        "Jaeyoon Jung",
        "Minjeong Jeon",
        "Sang Hoon Woo",
        "Jinjoo Lee"
      ],
      "abstract": "In this technical report, we describe our submission to DCASE2024 Challenge\nTask6 (Automated Audio Captioning) and Task8 (Language-based Audio Retrieval).\nWe develop our approach building upon the EnCLAP audio captioning framework and\noptimizing it for Task6 of the challenge. Notably, we outline the changes in\nthe underlying components and the incorporation of the reranking process.\nAdditionally, we submit a supplementary retriever model, a byproduct of our\nmodified framework, to Task8. Our proposed systems achieve FENSE score of 0.542\non Task6 and mAP@10 score of 0.386 on Task8, significantly outperforming the\nbaseline models.",
      "tldr_zh": "该研究基于 EnCLAP 框架扩展了一种优化系统，用于 DCASE2024 挑战赛的任务6（Automated Audio Captioning）和任务8（Language-based Audio Retrieval）。他们对底层组件进行了修改，并引入了 reranking 过程，同时开发了一个辅助检索模型作为任务8的补充。实验结果显示，该系统在任务6上达到 FENSE 得分 0.542，在任务8上达到 mAP@10 得分 0.386，显著超过了基线模型的表现。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "DCASE2024 Challenge Technical Report. Ranked 2nd in Task 6 Automated\n  Audio Captioning",
      "pdf_url": "http://arxiv.org/pdf/2409.01160v1",
      "published_date": "2024-09-02 10:47:07 UTC",
      "updated_date": "2024-09-02 10:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:44:42.374023"
    },
    {
      "arxiv_id": "2409.01148v3",
      "title": "FMRFT: Fusion Mamba and DETR for Query Time Sequence Intersection Fish Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyuan Yao",
        "Yukang Huo",
        "Qingbin Tian",
        "Jiayin Zhao",
        "Xiao Liu",
        "Ruifeng Wang",
        "Lin Xue",
        "Haihua Wang"
      ],
      "abstract": "Early detection of abnormal fish behavior caused by disease or hunger can be\nachieved through fish tracking using deep learning techniques, which holds\nsignificant value for industrial aquaculture. However, underwater reflections\nand some reasons with fish, such as the high similarity, rapid swimming caused\nby stimuli and mutual occlusion bring challenges to multi-target tracking of\nfish. To address these challenges, this paper establishes a complex\nmulti-scenario sturgeon tracking dataset and introduces the FMRFT model, a\nreal-time end-to-end fish tracking solution. The model incorporates the low\nvideo memory consumption Mamba In Mamba (MIM) architecture, which facilitates\nmulti-frame temporal memory and feature extraction, thereby addressing the\nchallenges to track multiple fish across frames. Additionally, the FMRFT model\nwith the Query Time Sequence Intersection (QTSI) module effectively manages\noccluded objects and reduces redundant tracking frames using the superior\nfeature interaction and prior frame processing capabilities of RT-DETR. This\ncombination significantly enhances the accuracy and stability of fish tracking.\nTrained and tested on the dataset, the model achieves an IDF1 score of 90.3%\nand a MOTA accuracy of 94.3%. Experimental results show that the proposed FMRFT\nmodel effectively addresses the challenges of high similarity and mutual\nocclusion in fish populations, enabling accurate tracking in factory farming\nenvironments.",
      "tldr_zh": "本研究针对水下反射、鱼类高相似度、快速游泳和相互遮挡等挑战，提出FMRFT模型，用于实时端到端鱼类跟踪，以实现工业水产养殖中异常行为的早期检测。FMRFT融合了Mamba In Mamba (MIM)架构进行多帧时间记忆和特征提取，以及Query Time Sequence Intersection (QTSI)模块与RT-DETR相结合，提升特征交互和遮挡对象处理能力，从而提高跟踪的准确性和稳定性。该模型在建立的复杂多场景鲟鱼跟踪数据集上测试，获得IDF1分数90.3%和MOTA准确率94.3%，有效解决了鱼类跟踪中的关键问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages,14 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01148v3",
      "published_date": "2024-09-02 10:33:45 UTC",
      "updated_date": "2025-01-10 03:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:44:44.784078"
    },
    {
      "arxiv_id": "2409.01145v1",
      "title": "LATEX-GCL: Large Language Models (LLMs)-Based Data Augmentation for Text-Attributed Graph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Yang",
        "Xiangyu Zhao",
        "Sirui Huang",
        "Qing Li",
        "Guandong Xu"
      ],
      "abstract": "Graph Contrastive Learning (GCL) is a potent paradigm for self-supervised\ngraph learning that has attracted attention across various application\nscenarios. However, GCL for learning on Text-Attributed Graphs (TAGs) has yet\nto be explored. Because conventional augmentation techniques like feature\nembedding masking cannot directly process textual attributes on TAGs. A naive\nstrategy for applying GCL to TAGs is to encode the textual attributes into\nfeature embeddings via a language model and then feed the embeddings into the\nfollowing GCL module for processing. Such a strategy faces three key\nchallenges: I) failure to avoid information loss, II) semantic loss during the\ntext encoding phase, and III) implicit augmentation constraints that lead to\nuncontrollable and incomprehensible results. In this paper, we propose a novel\nGCL framework named LATEX-GCL to utilize Large Language Models (LLMs) to\nproduce textual augmentations and LLMs' powerful natural language processing\n(NLP) abilities to address the three limitations aforementioned to pave the way\nfor applying GCL to TAG tasks. Extensive experiments on four high-quality TAG\ndatasets illustrate the superiority of the proposed LATEX-GCL method. The\nsource codes and datasets are released to ease the reproducibility, which can\nbe accessed via this link: https://anonymous.4open.science/r/LATEX-GCL-0712.",
      "tldr_zh": "该研究针对Graph Contrastive Learning (GCL)在Text-Attributed Graphs (TAGs)上的应用挑战，提出了一种基于Large Language Models (LLMs)的框架LATEX-GCL，以解决传统增强技术无法处理文本属性的问题。LATEX-GCL利用LLMs生成文本增强，并借助其强大的自然语言处理(NLP)能力，克服信息丢失、语义丢失以及增强约束不可控的三大局限。实验在四个高质量TAG数据集上验证了该方法的优越性，展示了显著的性能提升，并公开了源代码和数据集以促进复现。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01145v1",
      "published_date": "2024-09-02 10:30:55 UTC",
      "updated_date": "2024-09-02 10:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:44:55.751984"
    },
    {
      "arxiv_id": "2409.01138v1",
      "title": "Generating Synthetic Satellite Imagery for Rare Objects: An Empirical Comparison of Models and Metrics",
      "title_zh": "针对稀有物体的合成卫星图像生成：模型和指标的实证比较",
      "authors": [
        "Tuong Vy Nguyen",
        "Johannes Hoster",
        "Alexander Glaser",
        "Kristian Hildebrand",
        "Felix Biessmann"
      ],
      "abstract": "Generative deep learning architectures can produce realistic, high-resolution\nfake imagery -- with potentially drastic societal implications. A key question\nin this context is: How easy is it to generate realistic imagery, in particular\nfor niche domains. The iterative process required to achieve specific image\ncontent is difficult to automate and control. Especially for rare classes, it\nremains difficult to assess fidelity, meaning whether generative approaches\nproduce realistic imagery and alignment, meaning how (well) the generation can\nbe guided by human input. In this work, we present a large-scale empirical\nevaluation of generative architectures which we fine-tuned to generate\nsynthetic satellite imagery. We focus on nuclear power plants as an example of\na rare object category - as there are only around 400 facilities worldwide,\nthis restriction is exemplary for many other scenarios in which training and\ntest data is limited by the restricted number of occurrences of real-world\nexamples. We generate synthetic imagery by conditioning on two kinds of\nmodalities, textual input and image input obtained from a game engine that\nallows for detailed specification of the building layout. The generated images\nare assessed by commonly used metrics for automatic evaluation and then\ncompared with human judgement from our conducted user studies to assess their\ntrustworthiness. Our results demonstrate that even for rare objects, generation\nof authentic synthetic satellite imagery with textual or detailed building\nlayouts is feasible. In line with previous work, we find that automated metrics\nare often not aligned with human perception -- in fact, we find strong negative\ncorrelations between commonly used image quality metrics and human ratings.",
      "tldr_zh": "这篇论文通过实证比较评估了生成模型在创建稀有物体合成卫星图像方面的表现，以核电站为例，探讨了生成真实图像的易用性、逼真度(fidelity)和可控性(alignment)。研究者微调生成架构，使用文本输入和游戏引擎图像作为条件，生成合成图像，并结合自动评估指标和人类用户研究进行评估。结果表明，即使数据有限，也能实现真实卫星图像的生成，但常用图像质量指标往往与人类感知不一致，甚至出现负相关，从而质疑了这些指标的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented at KI 2024 - 47th German Conference on AI, 2nd Workshop on\n  Public Interest AI, 23 September, 2024, Wuerzburg, DE",
      "pdf_url": "http://arxiv.org/pdf/2409.01138v1",
      "published_date": "2024-09-02 10:19:39 UTC",
      "updated_date": "2024-09-02 10:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:45:10.857724"
    },
    {
      "arxiv_id": "2409.01137v3",
      "title": "Smart E-commerce Recommendations with Semantic AI",
      "title_zh": "翻译失败",
      "authors": [
        "M. Badouch",
        "M. Boutaounte"
      ],
      "abstract": "In e-commerce, web mining for page recommendations is widely used but often\nfails to meet user needs. To address this, we propose a novel solution\ncombining semantic web mining with BP neural networks. We process user search\nlogs to extract five key features: content priority, time spent, user feedback,\nrecommendation semantics, and input deviation. These features are then fed into\na BP neural network to classify and prioritize web pages. The prioritized pages\nare recommended to users. Using book sales pages for testing, our results\ndemonstrate that this solution can quickly and accurately identify the pages\nusers need. Our approach ensures that recommendations are more relevant and\ntailored to individual preferences, enhancing the online shopping experience.\nBy leveraging advanced semantic analysis and neural network techniques, we\nbridge the gap between user expectations and actual recommendations. This\ninnovative method not only improves accuracy but also speeds up the\nrecommendation process, making it a valuable tool for e-commerce platforms\naiming to boost user satisfaction and engagement. Additionally, our system\nability to handle large datasets and provide real-time recommendations makes it\na scalable and efficient solution for modern e-commerce challenges.",
      "tldr_zh": "本研究针对电商网页推荐的不足，提出一种结合语义网络挖掘（semantic web mining）和 BP neural networks 的智能推荐解决方案，以更好地满足用户需求。该方法从用户搜索日志中提取五个关键特征：content priority、time spent、user feedback、recommendation semantics 和 input deviation，并将这些特征输入 BP neural network 进行分类和优先级排序，从而生成个性化的网页推荐。在书籍销售页面的测试中，该系统实现了快速准确的页面识别，提高了推荐的相关性和用户满意度；此外，它还能处理大数据并提供实时推荐，为电商平台提升效率和用户参与度提供可扩展工具。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "My paper contain some errors",
      "pdf_url": "http://arxiv.org/pdf/2409.01137v3",
      "published_date": "2024-09-02 10:19:31 UTC",
      "updated_date": "2024-09-11 22:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:45:18.769684"
    },
    {
      "arxiv_id": "2409.01133v1",
      "title": "Large Language Models Can Understanding Depth from Monocular Images",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongyi Xia",
        "Tianzhao Wu"
      ],
      "abstract": "Monocular depth estimation is a critical function in computer vision\napplications. This paper shows that large language models (LLMs) can\neffectively interpret depth with minimal supervision, using efficient resource\nutilization and a consistent neural network architecture. We introduce LLM-MDE,\na multimodal framework that deciphers depth through language comprehension.\nSpecifically, LLM-MDE employs two main strategies to enhance the pretrained\nLLM's capability for depth estimation: cross-modal reprogramming and an\nadaptive prompt estimation module. These strategies align vision\nrepresentations with text prototypes and automatically generate prompts based\non monocular images, respectively. Comprehensive experiments on real-world MDE\ndatasets confirm the effectiveness and superiority of LLM-MDE, which excels in\nfew-/zero-shot tasks while minimizing resource use. The source code is\navailable.",
      "tldr_zh": "本研究证明，大型语言模型（LLMs）可以通过最小监督有效地进行单目深度估计（Monocular Depth Estimation），利用高效资源和一致的神经网络架构。论文引入了LLM-MDE多模态框架，通过跨模态重编程（cross-modal reprogramming）将视觉表示与文本原型对齐，以及自适应提示估计模块（adaptive prompt estimation module）基于单目图像自动生成提示，从而增强LLMs的深度解读能力。在真实世界MDE数据集上的全面实验显示，LLM-MDE在少样本/零样本任务中表现出色，并显著降低了资源使用，为计算机视觉应用提供了新颖解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01133v1",
      "published_date": "2024-09-02 10:11:52 UTC",
      "updated_date": "2024-09-02 10:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:45:31.460906"
    },
    {
      "arxiv_id": "2409.07480v3",
      "title": "EEG-Language Modeling for Pathology Detection",
      "title_zh": "EEG-语言建模用于病理检测",
      "authors": [
        "Sam Gijsen",
        "Kerstin Ritter"
      ],
      "abstract": "Multimodal language modeling has enabled breakthroughs for representation\nlearning, yet remains unexplored in the realm of functional brain data for\npathology detection. This paper pioneers EEG-language models (ELMs) trained on\nclinical reports and 15000 EEGs. We propose to combine multimodal alignment in\nthis novel domain with timeseries cropping and text segmentation, enabling an\nextension based on multiple instance learning to alleviate misalignment between\nirrelevant EEG or text segments. Our multimodal models significantly improve\npathology detection compared to EEG-only models across four evaluations and for\nthe first time enable zero-shot classification as well as retrieval of both\nneural signals and reports. In sum, these results highlight the potential of\nELMs, representing significant progress for clinical applications.",
      "tldr_zh": "本论文首次提出 EEG-language models (ELMs)，通过训练临床报告和15000个EEGs来实现病理检测的多模态表示学习。\n方法包括multimodal alignment、timeseries cropping、text segmentation，以及基于multiple instance learning的扩展，以缓解EEG和文本段的错位问题。\n实验结果显示，ELMs在四个评估中显著优于EEG-only模型，并首次实现了zero-shot classification和神经信号与报告的检索，为临床应用带来重大进展。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.07480v3",
      "published_date": "2024-09-02 10:03:03 UTC",
      "updated_date": "2025-01-31 13:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:45:43.816115"
    },
    {
      "arxiv_id": "2409.01124v1",
      "title": "Two-stage initial-value iterative physics-informed neural networks for simulating solitary waves of nonlinear wave equations",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Song",
        "Ming Zhong",
        "George Em Karniadakis",
        "Zhenya Yan"
      ],
      "abstract": "We propose a new two-stage initial-value iterative neural network (IINN)\nalgorithm for solitary wave computations of nonlinear wave equations based on\ntraditional numerical iterative methods and physics-informed neural networks\n(PINNs). Specifically, the IINN framework consists of two subnetworks, one of\nwhich is used to fit a given initial value, and the other incorporates physical\ninformation and continues training on the basis of the first subnetwork.\nImportantly, the IINN method does not require any additional data information\nincluding boundary conditions, apart from the given initial value.\nCorresponding theoretical guarantees are provided to demonstrate the\neffectiveness of our IINN method. The proposed IINN method is efficiently\napplied to learn some types of solutions in different nonlinear wave equations,\nincluding the one-dimensional (1D) nonlinear Schr\\\"odinger equations (NLS)\nequation (with and without potentials), the 1D saturable NLS equation with PT\n-symmetric optical lattices, the 1D focusing-defocusing coupled NLS equations,\nthe KdV equation, the two-dimensional (2D) NLS equation with potentials, the 2D\namended GP equation with a potential, the (2+1)-dimensional KP equation, and\nthe 3D NLS equation with a potential. These applications serve as evidence for\nthe efficacy of our method. Finally, by comparing with the traditional methods,\nwe demonstrate the advantages of the proposed IINN method.",
      "tldr_zh": "本研究提出了一种两阶段初始值迭代神经网络（IINN）算法，用于模拟非线性波方程的孤立波，结合了传统数值迭代方法和物理信息神经网络（PINNs）。IINN 框架包括两个子网络：一个负责拟合给定的初始值，另一个整合物理信息并在其基础上继续训练，且仅依赖初始值而不需额外边界条件。论文提供了理论保证，证明了方法的有效性，并将其应用于多种方程，如一维（1D）和二维（2D）的非线性Schrödinger方程（NLS）、KdV方程和KP方程等。相比传统方法，IINN 在准确性和效率上表现出显著优势。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "math-ph",
        "math.MP",
        "nlin.PS",
        "nlin.SI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "25 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01124v1",
      "published_date": "2024-09-02 10:00:02 UTC",
      "updated_date": "2024-09-02 10:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:06.345121"
    },
    {
      "arxiv_id": "2409.01104v2",
      "title": "AI Olympics challenge with Evolutionary Soft Actor Critic",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Calì",
        "Alberto Sinigaglia",
        "Niccolò Turcato",
        "Ruggero Carli",
        "Gian Antonio Susto"
      ],
      "abstract": "In the following report, we describe the solution we propose for the AI\nOlympics competition held at IROS 2024. Our solution is based on a Model-free\nDeep Reinforcement Learning approach combined with an evolutionary strategy. We\nwill briefly describe the algorithms that have been used and then provide\ndetails of the approach",
      "tldr_zh": "这篇论文介绍了针对 IROS 2024 AI Olympics 比赛的解决方案，采用无模型的深度强化学习（Model-free Deep Reinforcement Learning）结合进化策略的方法。核心算法为 Evolutionary Soft Actor Critic，通过简要描述算法细节和整体方法来优化性能。该方案旨在提升智能体在比赛中的决策和适应能力，为复杂环境下的强化学习应用提供实用见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "Added Sec 9 after testing on real robot",
      "pdf_url": "http://arxiv.org/pdf/2409.01104v2",
      "published_date": "2024-09-02 09:34:18 UTC",
      "updated_date": "2024-10-28 09:10:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:08.134792"
    },
    {
      "arxiv_id": "2409.01093v1",
      "title": "DS MYOLO: A Reliable Object Detector Based on SSMs for Driving Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Jianli Xiao"
      ],
      "abstract": "Accurate real-time object detection enhances the safety of advanced\ndriver-assistance systems, making it an essential component in driving\nscenarios. With the rapid development of deep learning technology, CNN-based\nYOLO real-time object detectors have gained significant attention. However, the\nlocal focus of CNNs results in performance bottlenecks. To further enhance\ndetector performance, researchers have introduced Transformer-based\nself-attention mechanisms to leverage global receptive fields, but their\nquadratic complexity incurs substantial computational costs. Recently, Mamba,\nwith its linear complexity, has made significant progress through global\nselective scanning. Inspired by Mamba's outstanding performance, we propose a\nnovel object detector: DS MYOLO. This detector captures global feature\ninformation through a simplified selective scanning fusion block (SimVSS Block)\nand effectively integrates the network's deep features. Additionally, we\nintroduce an efficient channel attention convolution (ECAConv) that enhances\ncross-channel feature interaction while maintaining low computational\ncomplexity. Extensive experiments on the CCTSDB 2021 and VLD-45 driving\nscenarios datasets demonstrate that DS MYOLO exhibits significant potential and\ncompetitive advantage among similarly scaled YOLO series real-time object\ndetectors.",
      "tldr_zh": "本文提出 DS MYOLO，一种基于 SSMs 的可靠物体检测器，针对驾驶场景中 CNN-based YOLO 检测器的局部焦点瓶颈和 Transformer 自注意力机制的高计算成本问题。DS MYOLO 通过简化选择性扫描融合块 (SimVSS Block) 捕获全局特征信息，并引入高效通道注意力卷积 (ECAConv) 来增强跨通道特征交互，同时保持低计算复杂度。在 CCTSDB 2021 和 VLD-45 数据集上的广泛实验显示，DS MYOLO 在同规模 YOLO 系列检测器中表现出显著的竞争优势和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27th International Conference on Pattern Recognition(ICPR)",
      "pdf_url": "http://arxiv.org/pdf/2409.01093v1",
      "published_date": "2024-09-02 09:22:33 UTC",
      "updated_date": "2024-09-02 09:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:24.414819"
    },
    {
      "arxiv_id": "2409.01092v1",
      "title": "Two-Timescale Synchronization and Migration for Digital Twin Networks: A Multi-Agent Deep Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Wenshuai Liu",
        "Yaru Fu",
        "Yongna Guo",
        "Fu Lee Wang",
        "Wen Sun",
        "Yan Zhang"
      ],
      "abstract": "Digital twins (DTs) have emerged as a promising enabler for representing the\nreal-time states of physical worlds and realizing self-sustaining systems. In\npractice, DTs of physical devices, such as mobile users (MUs), are commonly\ndeployed in multi-access edge computing (MEC) networks for the sake of reducing\nlatency. To ensure the accuracy and fidelity of DTs, it is essential for MUs to\nregularly synchronize their status with their DTs. However, MU mobility\nintroduces significant challenges to DT synchronization. Firstly, MU mobility\ntriggers DT migration which could cause synchronization failures. Secondly, MUs\nrequire frequent synchronization with their DTs to ensure DT fidelity.\nNonetheless, DT migration among MEC servers, caused by MU mobility, may occur\ninfrequently. Accordingly, we propose a two-timescale DT synchronization and\nmigration framework with reliability consideration by establishing a non-convex\nstochastic problem to minimize the long-term average energy consumption of MUs.\nWe use Lyapunov theory to convert the reliability constraints and reformulate\nthe new problem as a partially observable Markov decision-making process\n(POMDP). Furthermore, we develop a heterogeneous agent proximal policy\noptimization with Beta distribution (Beta-HAPPO) method to solve it. Numerical\nresults show that our proposed Beta-HAPPO method achieves significant\nimprovements in energy savings when compared with other benchmarks.",
      "tldr_zh": "这篇论文针对数字孪生 (DTs) 在多接入边缘计算 (MEC) 网络中的同步和迁移问题，提出了一种两时标框架，以应对移动用户 (MUs) 移动性导致的同步失败和可靠性挑战。框架通过 Lyapunov 理论转换可靠性约束，将问题重构为部分可观测 Markov 决策过程 (POMDP)，并开发了异构代理近端策略优化算法 (Beta-HAPPO) 来最小化 MUs 的长期平均能量消耗。主要实验结果显示，Beta-HAPPO 方法相较于基准方法实现了显著的能量节省改善。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.NI",
        "C.2.3; C.2.4"
      ],
      "primary_category": "cs.ET",
      "comment": "15 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01092v1",
      "published_date": "2024-09-02 09:20:46 UTC",
      "updated_date": "2024-09-02 09:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:36.014811"
    },
    {
      "arxiv_id": "2409.01087v1",
      "title": "Pre-Trained Language Models for Keyphrase Prediction: A Review",
      "title_zh": "预训练语言模型用于关键短语预测：综述",
      "authors": [
        "Muhammad Umair",
        "Tangina Sultana",
        "Young-Koo Lee"
      ],
      "abstract": "Keyphrase Prediction (KP) is essential for identifying keyphrases in a\ndocument that can summarize its content. However, recent Natural Language\nProcessing (NLP) advances have developed more efficient KP models using deep\nlearning techniques. The limitation of a comprehensive exploration jointly both\nkeyphrase extraction and generation using pre-trained language models\nspotlights a critical gap in the literature, compelling our survey paper to\nbridge this deficiency and offer a unified and in-depth analysis to address\nlimitations in previous surveys. This paper extensively examines the topic of\npre-trained language models for keyphrase prediction (PLM-KP), which are\ntrained on large text corpora via different learning (supervisor, unsupervised,\nsemi-supervised, and self-supervised) techniques, to provide respective\ninsights into these two types of tasks in NLP, precisely, Keyphrase Extraction\n(KPE) and Keyphrase Generation (KPG). We introduce appropriate taxonomies for\nPLM-KPE and KPG to highlight these two main tasks of NLP. Moreover, we point\nout some promising future directions for predicting keyphrases.",
      "tldr_zh": "这篇论文对预训练语言模型（PLMs）在关键短语预测（KP）中的应用进行了全面综述，旨在填补现有文献中对关键短语提取（KPE）和关键短语生成（KPG）联合探索的缺失。论文通过分析基于监督、非监督、半监督和自监督学习技术的 PLMs，提供统一的深入见解，并引入合适的分类法来区分 KPE 和 KPG 任务。最终，它指出了 KP 领域的 promising 未来方向，如改进模型效率和扩展应用场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01087v1",
      "published_date": "2024-09-02 09:15:44 UTC",
      "updated_date": "2024-09-02 09:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:47.372896"
    },
    {
      "arxiv_id": "2409.01086v2",
      "title": "DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing",
      "title_zh": "DPDEdit：细节保留扩散模型用于多模态时尚",
      "authors": [
        "Xiaolong Wang",
        "Zhi-Qi Cheng",
        "Jue Wang",
        "Xiaojiang Peng"
      ],
      "abstract": "Fashion image editing is a crucial tool for designers to convey their\ncreative ideas by visualizing design concepts interactively. Current fashion\nimage editing techniques, though advanced with multimodal prompts and powerful\ndiffusion models, often struggle to accurately identify editing regions and\npreserve the desired garment texture detail. To address these challenges, we\nintroduce a new multimodal fashion image editing architecture based on latent\ndiffusion models, called Detail-Preserved Diffusion Models (DPDEdit). DPDEdit\nguides the fashion image generation of diffusion models by integrating text\nprompts, region masks, human pose images, and garment texture images. To\nprecisely locate the editing region, we first introduce Grounded-SAM to predict\nthe editing region based on the user's textual description, and then combine it\nwith other conditions to perform local editing. To transfer the detail of the\ngiven garment texture into the target fashion image, we propose a texture\ninjection and refinement mechanism. Specifically, this mechanism employs a\ndecoupled cross-attention layer to integrate textual descriptions and texture\nimages, and incorporates an auxiliary U-Net to preserve the high-frequency\ndetails of generated garment texture. Additionally, we extend the VITON-HD\ndataset using a multimodal large language model to generate paired samples with\ntexture images and textual descriptions. Extensive experiments show that our\nDPDEdit outperforms state-of-the-art methods in terms of image fidelity and\ncoherence with the given multimodal inputs.",
      "tldr_zh": "该研究提出DPDEdit，一种基于潜在扩散模型的架构，用于多模态时尚图像编辑，旨在解决现有技术在识别编辑区域和保留服装纹理细节方面的不足。DPDEdit通过整合文本提示、区域掩码、人体姿势图像和服装纹理图像来指导图像生成，并引入Grounded-SAM预测编辑区域，以及一个纹理注入和精炼机制，包括解耦的交叉注意力层和辅助U-Net，以精确转移和保留高频纹理细节。同时，研究扩展了VITON-HD数据集，使用多模态大语言模型生成配对样本，实验结果显示DPDEdit在图像保真度和与输入一致性上优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages,12 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01086v2",
      "published_date": "2024-09-02 09:15:26 UTC",
      "updated_date": "2024-09-14 02:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:46:58.334200"
    },
    {
      "arxiv_id": "2409.01083v4",
      "title": "Affordance-based Robot Manipulation with Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Zhang",
        "Michael Gienger"
      ],
      "abstract": "We present a framework for assistive robot manipulation, which focuses on two\nfundamental challenges: first, efficiently adapting large-scale models to\ndownstream scene affordance understanding tasks, especially in daily living\nscenarios where gathering multi-task data involving humans requires strenuous\neffort; second, effectively learning robot action trajectories by grounding the\nvisual affordance model. We tackle the first challenge by employing a\nparameter-efficient prompt tuning method that prepends learnable text prompts\nto the frozen vision model to predict manipulation affordances in multi-task\nscenarios. Then we propose to learn robot action trajectories guided by\naffordances in a supervised flow matching method. Flow matching represents a\nrobot visuomotor policy as a conditional process of flowing random waypoints to\ndesired robot action trajectories. Finally, we introduce a real-world dataset\nwith 10 tasks across Activities of Daily Living to test our framework. Our\nextensive evaluation highlights that the proposed prompt tuning method for\nlearning manipulation affordance achieves competitive performance and even\noutperforms some other finetuning protocols across data scales, while\nsatisfying parameter efficiency. Learning multi-task robot action trajectories\nwith flow matching leads to consistently favorable results in several robot\nmanipulation benchmarks than some alternative behavior cloning methods. This\nincludes more stable training and evaluation, and noticeably faster inference,\nwhile maintaining comparable generalization performance to diffusion policy,\nwhere flow matching performs marginally better in most cases. Our framework\nseamlessly unifies affordance learning and action generation with flow matching\nfor robot manipulation.",
      "tldr_zh": "我们提出一个基于可操作性(Affordance)的机器人操作框架，使用Flow Matching来解决两大挑战：高效适应大规模模型到日常生活场景的可操作性理解，以及通过视觉模型指导学习机器人动作轨迹。该框架采用参数高效的提示调整(Prompt Tuning)方法，在冻结的视觉模型前添加可学习的文本提示，以预测多任务场景中的操作可操作性；同时，通过监督Flow Matching将随机航点流向所需的机器人动作轨迹，实现动作生成。在一个包含10个日常生活任务的真实数据集上，实验结果显示，该方法在参数效率和性能上优于其他微调协议和行为克隆方法，提供更稳定的训练、更快的推理，并与Diffusion Policy相当或略胜一筹，从而统一了可操作性学习和动作生成。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01083v4",
      "published_date": "2024-09-02 09:11:28 UTC",
      "updated_date": "2025-02-01 11:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:47:13.873926"
    },
    {
      "arxiv_id": "2409.01081v1",
      "title": "Beyond Efficiency: Molecular Data Pruning for Enhanced Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Dingshuo Chen",
        "Zhixun Li",
        "Yuyan Ni",
        "Guibin Zhang",
        "Ding Wang",
        "Qiang Liu",
        "Shu Wu",
        "Jeffrey Xu Yu",
        "Liang Wang"
      ],
      "abstract": "With the emergence of various molecular tasks and massive datasets, how to\nperform efficient training has become an urgent yet under-explored issue in the\narea. Data pruning (DP), as an oft-stated approach to saving training burdens,\nfilters out less influential samples to form a coreset for training. However,\nthe increasing reliance on pretrained models for molecular tasks renders\ntraditional in-domain DP methods incompatible. Therefore, we propose a\nMolecular data Pruning framework for enhanced Generalization (MolPeg), which\nfocuses on the source-free data pruning scenario, where data pruning is applied\nwith pretrained models. By maintaining two models with different updating paces\nduring training, we introduce a novel scoring function to measure the\ninformativeness of samples based on the loss discrepancy. As a plug-and-play\nframework, MolPeg realizes the perception of both source and target domain and\nconsistently outperforms existing DP methods across four downstream tasks.\nRemarkably, it can surpass the performance obtained from full-dataset training,\neven when pruning up to 60-70% of the data on HIV and PCBA dataset. Our work\nsuggests that the discovery of effective data-pruning metrics could provide a\nviable path to both enhanced efficiency and superior generalization in transfer\nlearning.",
      "tldr_zh": "本文提出 MolPeg 框架，用于分子数据修剪（Data Pruning, DP），旨在解决预训练模型在分子任务中训练效率和泛化能力的问题。MolPeg 在 source-free data pruning 场景下，通过维护两个更新速度不同的模型并引入基于损失差异的评分函数，来评估和筛选样本的信息性。作为一个即插即用框架，MolPeg 能感知源域和目标域，并在四个下游任务上优于现有 DP 方法，即使修剪 60-70% 的数据，其性能仍超过全数据集训练。该工作表明，设计有效的 DP 指标可同时提升训练效率和泛化性能，为转移学习提供新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2409.01081v1",
      "published_date": "2024-09-02 09:06:04 UTC",
      "updated_date": "2024-09-02 09:06:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:47:24.183678"
    },
    {
      "arxiv_id": "2409.01074v1",
      "title": "Bootstrap SGD: Algorithmic Stability and Robustness",
      "title_zh": "Bootstrap SGD：算法稳定性和鲁棒性",
      "authors": [
        "Andreas Christmann",
        "Yunwen Lei"
      ],
      "abstract": "In this paper some methods to use the empirical bootstrap approach for\nstochastic gradient descent (SGD) to minimize the empirical risk over a\nseparable Hilbert space are investigated from the view point of algorithmic\nstability and statistical robustness. The first two types of approaches are\nbased on averages and are investigated from a theoretical point of view. A\ngeneralization analysis for bootstrap SGD of Type 1 and Type 2 based on\nalgorithmic stability is done. Another type of bootstrap SGD is proposed to\ndemonstrate that it is possible to construct purely distribution-free pointwise\nconfidence intervals of the median curve using bootstrap SGD.",
      "tldr_zh": "本论文探讨了使用经验引导法(empirical bootstrap)来优化随机梯度下降(SGD)，以提升算法稳定性(algorithmic stability)和统计鲁棒性(statistical robustness)。研究从理论角度分析了基于平均的两类bootstrap SGD方法，并对Type 1和Type 2进行了泛化分析(generalization analysis)。此外，论文提出了一种新bootstrap SGD方法，能够构建纯分布无关的点估计置信区间(pointwise confidence intervals)，为SGD的鲁棒性应用提供了新途径。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01074v1",
      "published_date": "2024-09-02 08:56:39 UTC",
      "updated_date": "2024-09-02 08:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:47:35.046226"
    },
    {
      "arxiv_id": "2409.01073v1",
      "title": "SCOPE: Sign Language Contextual Processing with Embedding from LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Liu",
        "Wenqian Zhang",
        "Sihan Ren",
        "Chengyu Huang",
        "Jingyi Yu",
        "Lan Xu"
      ],
      "abstract": "Sign languages, used by around 70 million Deaf individuals globally, are\nvisual languages that convey visual and contextual information. Current methods\nin vision-based sign language recognition (SLR) and translation (SLT) struggle\nwith dialogue scenes due to limited dataset diversity and the neglect of\ncontextually relevant information. To address these challenges, we introduce\nSCOPE (Sign language Contextual Processing with Embedding from LLMs), a novel\ncontext-aware vision-based SLR and SLT framework. For SLR, we utilize dialogue\ncontexts through a multi-modal encoder to enhance gloss-level recognition. For\nsubsequent SLT, we further fine-tune a Large Language Model (LLM) by\nincorporating prior conversational context. We also contribute a new sign\nlanguage dataset that contains 72 hours of Chinese sign language videos in\ncontextual dialogues across various scenarios. Experimental results demonstrate\nthat our SCOPE framework achieves state-of-the-art performance on multiple\ndatasets, including Phoenix-2014T, CSL-Daily, and our SCOPE dataset. Moreover,\nsurveys conducted with participants from the Deaf community further validate\nthe robustness and effectiveness of our approach in real-world applications.\nBoth our dataset and code will be open-sourced to facilitate further research.",
      "tldr_zh": "该研究提出SCOPE框架，利用LLMs嵌入进行手语的上下文处理，旨在解决现有视觉SLR（Sign Language Recognition）和SLT（Sign Language Translation）方法在对话场景中的不足，如数据集多样性有限和上下文信息忽略。SCOPE通过多模态编码器整合对话上下文来提升词汇级SLR，并微调LLM以融入先前的对话信息，同时贡献了一个包含72小时中文手语视频的新数据集，涵盖各种场景。实验结果显示，SCOPE在Phoenix-2014T、CSL-Daily和自有数据集上实现最先进性能，并通过聋人社区调查验证其在实际应用中的稳健性；数据集和代码将开源以推动进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01073v1",
      "published_date": "2024-09-02 08:56:12 UTC",
      "updated_date": "2024-09-02 08:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:47:46.951843"
    },
    {
      "arxiv_id": "2409.01066v1",
      "title": "Learning in Hybrid Active Inference Models",
      "title_zh": "翻译失败",
      "authors": [
        "Poppy Collis",
        "Ryan Singh",
        "Paul F Kinghorn",
        "Christopher L Buckley"
      ],
      "abstract": "An open problem in artificial intelligence is how systems can flexibly learn\ndiscrete abstractions that are useful for solving inherently continuous\nproblems. Previous work in computational neuroscience has considered this\nfunctional integration of discrete and continuous variables during\ndecision-making under the formalism of active inference (Parr, Friston & de\nVries, 2017; Parr & Friston, 2018). However, their focus is on the expressive\nphysical implementation of categorical decisions and the hierarchical mixed\ngenerative model is assumed to be known. As a consequence, it is unclear how\nthis framework might be extended to learning. We therefore present a novel\nhierarchical hybrid active inference agent in which a high-level discrete\nactive inference planner sits above a low-level continuous active inference\ncontroller. We make use of recent work in recurrent switching linear dynamical\nsystems (rSLDS) which implement end-to-end learning of meaningful discrete\nrepresentations via the piecewise linear decomposition of complex continuous\ndynamics (Linderman et al., 2016). The representations learned by the rSLDS\ninform the structure of the hybrid decision-making agent and allow us to (1)\nspecify temporally-abstracted sub-goals in a method reminiscent of the options\nframework, (2) lift the exploration into discrete space allowing us to exploit\ninformation-theoretic exploration bonuses and (3) `cache' the approximate\nsolutions to low-level problems in the discrete planner. We apply our model to\nthe sparse Continuous Mountain Car task, demonstrating fast system\nidentification via enhanced exploration and successful planning through the\ndelineation of abstract sub-goals.",
      "tldr_zh": "本论文探讨了人工智能中系统如何学习有用的离散抽象来解决连续问题，提出了一种新颖的层次化混合 active inference 模型。模型包括一个高层离散 active inference 规划器和一个底层连续 active inference 控制器，利用 recurrent switching linear dynamical systems (rSLDS) 实现端到端学习离散表示，从而分解复杂连续动态。关键贡献包括指定时间抽象子目标、提升探索到离散空间以利用信息理论奖励，以及缓存低级问题解决方案；在稀疏 Continuous Mountain Car 任务上，该模型实现了快速系统识别、增强探索和成功规划。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages (+ appendix). Accepted to the International Workshop on\n  Active Inference 2024. arXiv admin note: substantial text overlap with\n  arXiv:2408.10970",
      "pdf_url": "http://arxiv.org/pdf/2409.01066v1",
      "published_date": "2024-09-02 08:41:45 UTC",
      "updated_date": "2024-09-02 08:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:47:59.369845"
    },
    {
      "arxiv_id": "2409.01053v1",
      "title": "A Perspective on Literary Metaphor in the Context of Generative AI",
      "title_zh": "生成式 AI 语境下的文学隐喻视角",
      "authors": [
        "Imke van Heerden",
        "Anil Bas"
      ],
      "abstract": "At the intersection of creative text generation and literary theory, this\nstudy explores the role of literary metaphor and its capacity to generate a\nrange of meanings. In this regard, literary metaphor is vital to the\ndevelopment of any particular language. To investigate whether the inclusion of\noriginal figurative language improves textual quality, we trained an LSTM-based\nlanguage model in Afrikaans. The network produces phrases containing\ncompellingly novel figures of speech. Specifically, the emphasis falls on how\nAI might be utilised as a defamiliarisation technique, which disrupts expected\nuses of language to augment poetic expression. Providing a literary perspective\non text generation, the paper raises thought-provoking questions on aesthetic\nvalue, interpretation and evaluation.",
      "tldr_zh": "本研究从文学理论视角探讨文学隐喻在生成式 AI 背景下的作用，强调其在生成多种含义和语言发展中的重要性。研究者训练了一个基于 LSTM 的语言模型，使用阿非利坎斯语来生成包含原创比喻的短语，以检验比喻语言是否能提升文本质量。论文特别关注 AI 作为陌生化技术（defamiliarisation technique）的潜力，以增强诗意表达，并引发关于审美价值、解释和评价的深刻问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as oral presentation to Workshop on Artificial Intelligence\n  and Creativity (CREAI) at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.01053v1",
      "published_date": "2024-09-02 08:27:29 UTC",
      "updated_date": "2024-09-02 08:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:48:12.400892"
    },
    {
      "arxiv_id": "2409.01046v1",
      "title": "Accelerated Multi-objective Task Learning using Modified Q-learning Algorithm",
      "title_zh": "基于改进 Q-learning 算法的加速多目标任务学习",
      "authors": [
        "Varun Prakash Rajamohan",
        "Senthil Kumar Jagatheesaperumal"
      ],
      "abstract": "Robots find extensive applications in industry. In recent years, the\ninfluence of robots has also increased rapidly in domestic scenarios. The\nQ-learning algorithm aims to maximise the reward for reaching the goal. This\npaper proposes a modified version of the Q-learning algorithm, known as\nQ-learning with scaled distance metric (Q-SD). This algorithm enhances task\nlearning and makes task completion more meaningful. A robotic manipulator\n(agent) applies the Q-SD algorithm to the task of table cleaning. Using Q-SD,\nthe agent acquires the sequence of steps necessary to accomplish the task while\nminimising the manipulator's movement distance. We partition the table into\ngrids of different dimensions. The first has a grid count of 3 times 3, and the\nsecond has a grid count of 4 times 4. Using the Q-SD algorithm, the maximum\nsuccess obtained in these two environments was 86% and 59% respectively.\nMoreover, Compared to the conventional Q-learning algorithm, the drop in\naverage distance moved by the agent in these two environments using the Q-SD\nalgorithm was 8.61% and 6.7% respectively.",
      "tldr_zh": "本论文提出了一种改进的 Q-learning 算法，名为 Q-SD（Q-learning with scaled distance metric），旨在加速多目标任务学习，通过引入缩放距离度量来提升任务效率和意义。研究将 Q-SD 应用于机器人机械臂的桌子清洁任务中，代理通过该算法学习完成任务的步骤序列，同时最小化机械臂的移动距离，并将任务环境划分为 3x3 和 4x4 网格。实验结果显示，在这两个环境中，Q-SD 算法的成功率分别达到 86% 和 59%，与传统 Q-learning 相比，平均移动距离分别降低了 8.61% 和 6.7%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T05, 93C85, 93B40, 90C29",
        "I.2.6; I.2.9; I.2.8; F.1.1; F.2.1; H.1.2; G.1.6"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 9 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.01046v1",
      "published_date": "2024-09-02 08:20:41 UTC",
      "updated_date": "2024-09-02 08:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:48:26.202228"
    },
    {
      "arxiv_id": "2409.01038v1",
      "title": "Robust Vehicle Localization and Tracking in Rain using Street Maps",
      "title_zh": "在雨中使用街道地图的稳健车辆定位和跟踪",
      "authors": [
        "Yu Xiang Tan",
        "Malika Meghjani"
      ],
      "abstract": "GPS-based vehicle localization and tracking suffers from unstable positional\ninformation commonly experienced in tunnel segments and in dense urban areas.\nAlso, both Visual Odometry (VO) and Visual Inertial Odometry (VIO) are\nsusceptible to adverse weather conditions that causes occlusions or blur on the\nvisual input. In this paper, we propose a novel approach for vehicle\nlocalization that uses street network based map information to correct drifting\nodometry estimates and intermittent GPS measurements especially, in adversarial\nscenarios such as driving in rain and tunnels. Specifically, our approach is a\nflexible fusion algorithm that integrates intermittent GPS, drifting IMU and VO\nestimates together with 2D map information for robust vehicle localization and\ntracking. We refer to our approach as Map-Fusion. We robustly evaluate our\nproposed approach on four geographically diverse datasets from different\ncountries ranging across clear and rain weather conditions. These datasets also\ninclude challenging visual segments in tunnels and underpasses. We show that\nwith the integration of the map information, our Map-Fusion algorithm reduces\nthe error of the state-of-the-art VO and VIO approaches across all datasets. We\nalso validate our proposed algorithm in a real-world environment and in\nreal-time on a hardware constrained mobile robot. Map-Fusion achieved 2.46m\nerror in clear weather and 6.05m error in rain weather for a 150m route.",
      "tldr_zh": "本论文针对GPS在隧道和城市区域的不稳定问题，以及Visual Odometry (VO) 和 Visual Inertial Odometry (VIO) 在雨天等恶劣天气下的易受影响，提出了一种名为 Map-Fusion 的鲁棒车辆定位方法。该方法通过融合间歇性 GPS、漂移的 IMU 和 VO 估计，以及街路网络的 2D 地图信息，来修正定位误差并提升在挑战性场景下的准确性。实验在四个地理多样的数据集上进行，结果显示 Map-Fusion 显著降低了现有 VO 和 VIO 方法的错误率；在真实环境中，150m 路线上晴天错误为 2.46m，雨天为 6.05m，从而为可靠的车辆跟踪提供了新方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.01038v1",
      "published_date": "2024-09-02 08:15:12 UTC",
      "updated_date": "2024-09-02 08:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:48:42.167598"
    },
    {
      "arxiv_id": "2409.01014v1",
      "title": "From Bird's-Eye to Street View: Crafting Diverse and Condition-Aligned Images with Latent Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojie Xu",
        "Tianshuo Xu",
        "Fulong Ma",
        "Yingcong Chen"
      ],
      "abstract": "We explore Bird's-Eye View (BEV) generation, converting a BEV map into its\ncorresponding multi-view street images. Valued for its unified spatial\nrepresentation aiding multi-sensor fusion, BEV is pivotal for various\nautonomous driving applications. Creating accurate street-view images from BEV\nmaps is essential for portraying complex traffic scenarios and enhancing\ndriving algorithms. Concurrently, diffusion-based conditional image generation\nmodels have demonstrated remarkable outcomes, adept at producing diverse,\nhigh-quality, and condition-aligned results. Nonetheless, the training of these\nmodels demands substantial data and computational resources. Hence, exploring\nmethods to fine-tune these advanced models, like Stable Diffusion, for specific\nconditional generation tasks emerges as a promising avenue. In this paper, we\nintroduce a practical framework for generating images from a BEV layout. Our\napproach comprises two main components: the Neural View Transformation and the\nStreet Image Generation. The Neural View Transformation phase converts the BEV\nmap into aligned multi-view semantic segmentation maps by learning the shape\ncorrespondence between the BEV and perspective views. Subsequently, the Street\nImage Generation phase utilizes these segmentations as a condition to guide a\nfine-tuned latent diffusion model. This finetuning process ensures both view\nand style consistency. Our model leverages the generative capacity of large\npretrained diffusion models within traffic contexts, effectively yielding\ndiverse and condition-coherent street view images.",
      "tldr_zh": "本研究探讨从 Bird's-Eye View (BEV) 地图生成对应多视图街景图像，旨在为自动驾驶应用提供统一的空间表示和复杂交通场景的精确可视化。论文提出一个实用的框架，包括 Neural View Transformation 组件（通过学习 BEV 与透视视图的形状对应关系，生成对齐的多视图语义分割地图）和 Street Image Generation 组件（利用这些分割地图作为条件，对 latent diffusion model 进行微调，确保视图和风格一致性）。这种方法充分利用大型预训练扩散模型的生成能力，产生多样且条件-aligned 的街景图像，相比传统方法显著提升了图像质量和应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at International Conference on Robotics and Automation(ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2409.01014v1",
      "published_date": "2024-09-02 07:47:16 UTC",
      "updated_date": "2024-09-02 07:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:48:52.084258"
    },
    {
      "arxiv_id": "2409.01013v1",
      "title": "SeCo-INR: Semantically Conditioned Implicit Neural Representations for Improved Medical Image Super-Resolution",
      "title_zh": "SeCo-INR：语义条件隐式神经表示",
      "authors": [
        "Mevan Ekanayake",
        "Zhifeng Chen",
        "Gary Egan",
        "Mehrtash Harandi",
        "Zhaolin Chen"
      ],
      "abstract": "Implicit Neural Representations (INRs) have recently advanced the field of\ndeep learning due to their ability to learn continuous representations of\nsignals without the need for large training datasets. Although INR methods have\nbeen studied for medical image super-resolution, their adaptability to\nlocalized priors in medical images has not been extensively explored. Medical\nimages contain rich anatomical divisions that could provide valuable local\nprior information to enhance the accuracy and robustness of INRs. In this work,\nwe propose a novel framework, referred to as the Semantically Conditioned INR\n(SeCo-INR), that conditions an INR using local priors from a medical image,\nenabling accurate model fitting and interpolation capabilities to achieve\nsuper-resolution. Our framework learns a continuous representation of the\nsemantic segmentation features of a medical image and utilizes it to derive the\noptimal INR for each semantic region of the image. We tested our framework\nusing several medical imaging modalities and achieved higher quantitative\nscores and more realistic super-resolution outputs compared to state-of-the-art\nmethods.",
      "tldr_zh": "本研究提出了一种名为 SeCo-INR 的新框架，用于提升医疗图像超分辨率，通过将 Implicit Neural Representations (INRs) 与图像的局部先验（如解剖学分区）相结合。SeCo-INR 通过学习医疗图像的语义分割特征的连续表示，并据此为每个语义区域生成优化后的 INR，实现更准确的模型拟合和插值。实验结果显示，该框架在多种医疗成像模式上，比现有最先进方法取得了更高的定量分数和更真实的超分辨率输出。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "This paper was accepted for presentation at the IEEE/CVF Winter\n  Conference on Applications of Computer Vision (WACV) 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.01013v1",
      "published_date": "2024-09-02 07:45:06 UTC",
      "updated_date": "2024-09-02 07:45:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:49:06.753619"
    },
    {
      "arxiv_id": "2409.01007v3",
      "title": "Unlocking the Wisdom of Large Language Models: An Introduction to The Path to Artificial General Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Y. Chang"
      ],
      "abstract": "This booklet, Unlocking the Wisdom of Multi-LLM Collaborative Intelligence,\nserves as an accessible introduction to the full volume The Path to Artificial\nGeneral Intelligence. Through fourteen aphorisms, it distills the core\nprinciples of Multi-LLM Agent Collaborative Intelligence (MACI), a framework\ndesigned to coordinate multiple LLMs toward reasoning, planning, and\ndecision-making that surpasses the capabilities of any single model. The\nbooklet includes titles, abstracts, and introductions from each main chapter,\nalong with the full content of the first two. The newly released third edition\nfeatures significant enhancements to Chapters 6 through 9 and a revised preface\nresponding to Yann LeCun's critique of AGI feasibility. While LeCun argues that\nLLMs lack grounding, memory, and planning, we propose that MACI's collaborative\narchitecture, featuring multimodal agents in executive, legislative, and\njudicial roles, directly addresses these limitations. Chapters on SocraSynth,\nEVINCE, consciousness modeling, and behavior regulation demonstrate that\nreasoning systems grounded in structured interaction and checks and balances\ncan produce more reliable, interpretable, and adaptive intelligence. By\nintegrating complementary model strengths, including world modeling and\nmultimodal perception, MACI enables a system-level intelligence that exceeds\nthe sum of its parts. Like human institutions, progress in AI may depend less\non isolated performance and more on coordinated judgment. Collaborative LLMs,\nnot just larger ones, may chart the path toward artificial general\nintelligence.",
      "tldr_zh": "这本小册子《Unlocking the Wisdom of Large Language Models》作为《The Path to Artificial General Intelligence》的引言，通过14个格言提炼了Multi-LLM Agent Collaborative Intelligence (MACI)框架的核心原则，该框架协调多个Large Language Models (LLMs)来实现超越单一模型的推理、规划和决策。MACI采用多模态代理在执行、立法和司法角色中的结构化互动，解决了LLMs的局限性，如缺乏grounding、记忆和规划，并通过章节如SocraSynth和EVINCE证明了这种协作能产生更可靠、可解释和适应的智能。第三版回应了Yann LeCun对AGI可行性的批评，强调通过整合模型优势，MACI推动了系统级智能的发展，最终为通往Artificial General Intelligence (AGI)的路径提供了新见解。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "153 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.01007v3",
      "published_date": "2024-09-02 07:29:37 UTC",
      "updated_date": "2025-04-15 05:21:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:49:17.596745"
    },
    {
      "arxiv_id": "2409.00991v2",
      "title": "3D Priors-Guided Diffusion for Blind Face Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaobin Lu",
        "Xiaobin Hu",
        "Jun Luo",
        "Ben Zhu",
        "Yaping Ruan",
        "Wenqi Ren"
      ],
      "abstract": "Blind face restoration endeavors to restore a clear face image from a\ndegraded counterpart. Recent approaches employing Generative Adversarial\nNetworks (GANs) as priors have demonstrated remarkable success in this field.\nHowever, these methods encounter challenges in achieving a balance between\nrealism and fidelity, particularly in complex degradation scenarios. To inherit\nthe exceptional realism generative ability of the diffusion model and also\nconstrained by the identity-aware fidelity, we propose a novel diffusion-based\nframework by embedding the 3D facial priors as structure and identity\nconstraints into a denoising diffusion process. Specifically, in order to\nobtain more accurate 3D prior representations, the 3D facial image is\nreconstructed by a 3D Morphable Model (3DMM) using an initial restored face\nimage that has been processed by a pretrained restoration network. A customized\nmulti-level feature extraction method is employed to exploit both structural\nand identity information of 3D facial images, which are then mapped into the\nnoise estimation process. In order to enhance the fusion of identity\ninformation into the noise estimation, we propose a Time-Aware Fusion Block\n(TAFB). This module offers a more efficient and adaptive fusion of weights for\ndenoising, considering the dynamic nature of the denoising process in the\ndiffusion model, which involves initial structure refinement followed by\ntexture detail enhancement. Extensive experiments demonstrate that our network\nperforms favorably against state-of-the-art algorithms on synthetic and\nreal-world datasets for blind face restoration. The Code is released on our\nproject page at https://github.com/838143396/3Diffusion.",
      "tldr_zh": "本论文针对盲人脸部修复（Blind Face Restoration）问题，提出了一种基于扩散模型（Diffusion Model）的框架，通过嵌入3D面部先验作为结构和身份约束，提升图像的真实性和保真度。具体方法包括使用3D Morphable Model (3DMM)从预训练网络处理的初始图像重建3D面部图像，并通过多级特征提取和Time-Aware Fusion Block (TAFB)模块动态融合身份信息到去噪过程中。实验结果显示，该框架在合成和真实数据集上优于现有算法，实现了显著的性能提升，并已开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper was accepted by ACM MM 2024, and the project page is\n  accessible at: https://github.com/838143396/3Diffusion",
      "pdf_url": "http://arxiv.org/pdf/2409.00991v2",
      "published_date": "2024-09-02 07:13:32 UTC",
      "updated_date": "2024-09-12 07:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:49:29.776349"
    },
    {
      "arxiv_id": "2409.00985v1",
      "title": "Co-Learning: Code Learning for Multi-Agent Reinforcement Collaborative Framework with Conversational Natural Language Interfaces",
      "title_zh": "翻译失败",
      "authors": [
        "Jiapeng Yu",
        "Yuqian Wu",
        "Yajing Zhan",
        "Wenhao Guo",
        "Zhou Xu",
        "Raymond Lee"
      ],
      "abstract": "Online question-and-answer (Q\\&A) systems based on the Large Language Model\n(LLM) have progressively diverged from recreational to professional use. This\npaper proposed a Multi-Agent framework with environmentally reinforcement\nlearning (E-RL) for code correction called Code Learning (Co-Learning)\ncommunity, assisting beginners to correct code errors independently. It\nevaluates the performance of multiple LLMs from an original dataset with 702\nerror codes, uses it as a reward or punishment criterion for E-RL; Analyzes\ninput error codes by the current agent; selects the appropriate LLM-based agent\nto achieve optimal error correction accuracy and reduce correction time.\nExperiment results showed that 3\\% improvement in Precision score and 15\\%\nimprovement in time cost as compared with no E-RL method respectively. Our\nsource code is available at: https://github.com/yuqian2003/Co_Learning",
      "tldr_zh": "本论文提出Co-Learning框架，这是一个多智能体强化学习系统，结合环境强化学习(E-RL)和对话式自然语言接口，帮助初学者独立修正代码错误。\n该框架使用一个包含702个错误代码的原始数据集评估多个LLM的表现，作为E-RL的奖励或惩罚标准，并动态选择合适代理来优化修正准确性和时间效率。\n实验结果显示，与无E-RL方法相比，精确度提高了3%，修正时间降低了15%，并提供了开源代码以供进一步应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00985v1",
      "published_date": "2024-09-02 07:03:22 UTC",
      "updated_date": "2024-09-02 07:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:49:39.704295"
    },
    {
      "arxiv_id": "2409.00980v2",
      "title": "DNN-GDITD: Out-of-distribution detection via Deep Neural Network based Gaussian Descriptor for Imbalanced Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Priyanka Chudasama",
        "Anil Surisetty",
        "Aakarsh Malhotra",
        "Alok Singh"
      ],
      "abstract": "Classification tasks present challenges due to class imbalances and evolving\ndata distributions. Addressing these issues requires a robust method to handle\nimbalances while effectively detecting out-of-distribution (OOD) samples not\nencountered during training. This study introduces a novel OOD detection\nalgorithm designed for tabular datasets, titled Deep Neural Network-based\nGaussian Descriptor for Imbalanced Tabular Data (DNN-GDITD). The DNN-GDITD\nalgorithm can be placed on top of any DNN to facilitate better classification\nof imbalanced data and OOD detection using spherical decision boundaries. Using\na combination of Push, Score-based, and focal losses, DNN-GDITD assigns\nconfidence scores to test data points, categorizing them as known classes or as\nan OOD sample. Extensive experimentation on tabular datasets demonstrates the\neffectiveness of DNN-GDITD compared to three OOD algorithms. Evaluation\nencompasses imbalanced and balanced scenarios on diverse tabular datasets,\nincluding a synthetic financial dispute dataset and publicly available tabular\ndatasets like Gas Sensor, Drive Diagnosis, and MNIST, showcasing DNN-GDITD's\nversatility.",
      "tldr_zh": "这篇论文提出了一种名为 DNN-GDITD 的新算法，用于处理类别不平衡的表格数据中的 Out-of-distribution (OOD) 检测问题。DNN-GDITD 基于 Deep Neural Network 和 Gaussian Descriptor，通过结合 Push、Score-based 和 focal 损失来为测试数据点分配置信度分数，并利用球形决策边界实现更好的分类和 OOD 检测。实验结果显示，该算法在各种数据集（如 Gas Sensor、Drive Diagnosis 和 MNIST）上的表现优于其他三款 OOD 算法，尤其在不平衡和平衡场景中，证明了其有效性和通用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00980v2",
      "published_date": "2024-09-02 06:52:01 UTC",
      "updated_date": "2024-09-04 12:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:49:52.072458"
    },
    {
      "arxiv_id": "2409.00974v1",
      "title": "Enhancing Privacy in Federated Learning: Secure Aggregation for Real-World Healthcare Applications",
      "title_zh": "在联邦学习中增强隐私：用于真实世界医疗保健应用的安全聚合",
      "authors": [
        "Riccardo Taiello",
        "Sergen Cansiz",
        "Marc Vesin",
        "Francesco Cremonesi",
        "Lucia Innocenti",
        "Melek Önen",
        "Marco Lorenzi"
      ],
      "abstract": "Deploying federated learning (FL) in real-world scenarios, particularly in\nhealthcare, poses challenges in communication and security. In particular, with\nrespect to the federated aggregation procedure, researchers have been focusing\non the study of secure aggregation (SA) schemes to provide privacy guarantees\nover the model's parameters transmitted by the clients. Nevertheless, the\npractical availability of SA in currently available FL frameworks is currently\nlimited, due to computational and communication bottlenecks. To fill this gap,\nthis study explores the implementation of SA within the open-source Fed-BioMed\nframework. We implement and compare two SA protocols, Joye-Libert (JL) and Low\nOverhead Masking (LOM), by providing extensive benchmarks in a panel of\nhealthcare data analysis problems. Our theoretical and experimental evaluations\non four datasets demonstrate that SA protocols effectively protect privacy\nwhile maintaining task accuracy. Computational overhead during training is less\nthan 1% on a CPU and less than 50% on a GPU for large models, with protection\nphases taking less than 10 seconds. Incorporating SA into Fed-BioMed impacts\ntask accuracy by no more than 2% compared to non-SA scenarios. Overall this\nstudy demonstrates the feasibility of SA in real-world healthcare applications\nand contributes in reducing the gap towards the adoption of privacy-preserving\ntechnologies in sensitive applications.",
      "tldr_zh": "本研究探讨了在联邦学习（FL）中增强隐私的方法，特别针对真实医疗应用中的安全聚合（SA）方案，以解决通信和安全挑战。该团队在开源框架 Fed-BioMed 中实现了并比较了两种 SA 协议：Joye-Libert (JL) 和 Low Overhead Masking (LOM)，并在多个医疗数据分析问题上进行了基准测试。实验结果显示，这些协议在四个数据集上有效保护隐私，同时保持任务准确性损失不超过2%，计算开销在CPU上小于1%、在GPU上小于50%，保护阶段耗时不到10秒。总体上，此工作证明了 SA 在医疗领域的可行性，并推动了隐私保护技术在敏感应用中的采用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at the 5-th MICCAI Workshop on Distributed, Collaborative\n  and Federated Learning in Conjunction with MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00974v1",
      "published_date": "2024-09-02 06:43:22 UTC",
      "updated_date": "2024-09-02 06:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:50:14.386113"
    },
    {
      "arxiv_id": "2409.00968v1",
      "title": "Solving Integrated Process Planning and Scheduling Problem via Graph Neural Network Based Deep Reinforcement Learning",
      "title_zh": "通过基于图神经网络的深度强化学习解决集成工艺规划",
      "authors": [
        "Hongpei Li",
        "Han Zhang",
        "Ziyan He",
        "Yunkai Jia",
        "Bo Jiang",
        "Xiang Huang",
        "Dongdong Ge"
      ],
      "abstract": "The Integrated Process Planning and Scheduling (IPPS) problem combines\nprocess route planning and shop scheduling to achieve high efficiency in\nmanufacturing and maximize resource utilization, which is crucial for modern\nmanufacturing systems. Traditional methods using Mixed Integer Linear\nProgramming (MILP) and heuristic algorithms can not well balance solution\nquality and speed when solving IPPS. In this paper, we propose a novel\nend-to-end Deep Reinforcement Learning (DRL) method. We model the IPPS problem\nas a Markov Decision Process (MDP) and employ a Heterogeneous Graph Neural\nNetwork (GNN) to capture the complex relationships among operations, machines,\nand jobs. To optimize the scheduling strategy, we use Proximal Policy\nOptimization (PPO). Experimental results show that, compared to traditional\nmethods, our approach significantly improves solution efficiency and quality in\nlarge-scale IPPS instances, providing superior scheduling strategies for modern\nintelligent manufacturing systems.",
      "tldr_zh": "本篇论文针对 Integrated Process Planning and Scheduling (IPPS) 问题提出了一种新型端到端 Deep Reinforcement Learning (DRL) 方法，以优化制造系统的效率和资源利用。研究者将 IPPS 建模为 Markov Decision Process (MDP)，并使用 Heterogeneous Graph Neural Network (GNN) 来捕捉操作、机器和作业之间的复杂关系，然后通过 Proximal Policy Optimization (PPO) 算法优化调度策略。相比传统 Mixed Integer Linear Programming (MILP) 和启发式算法，该方法在大型 IPPS 实例中显著提升了解决方案的质量和效率，为现代智能制造系统提供了更优的调度策略。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "24 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00968v1",
      "published_date": "2024-09-02 06:18:30 UTC",
      "updated_date": "2024-09-02 06:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:50:16.940902"
    },
    {
      "arxiv_id": "2409.00951v1",
      "title": "Semantically Controllable Augmentations for Generalizable Robot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zoey Chen",
        "Zhao Mandi",
        "Homanga Bharadhwaj",
        "Mohit Sharma",
        "Shuran Song",
        "Abhishek Gupta",
        "Vikash Kumar"
      ],
      "abstract": "Generalization to unseen real-world scenarios for robot manipulation requires\nexposure to diverse datasets during training. However, collecting large\nreal-world datasets is intractable due to high operational costs. For robot\nlearning to generalize despite these challenges, it is essential to leverage\nsources of data or priors beyond the robot's direct experience. In this work,\nwe posit that image-text generative models, which are pre-trained on large\ncorpora of web-scraped data, can serve as such a data source. These generative\nmodels encompass a broad range of real-world scenarios beyond a robot's direct\nexperience and can synthesize novel synthetic experiences that expose robotic\nagents to additional world priors aiding real-world generalization at no extra\ncost.\n  In particular, our approach leverages pre-trained generative models as an\neffective tool for data augmentation. We propose a generative augmentation\nframework for semantically controllable augmentations and rapidly multiplying\nrobot datasets while inducing rich variations that enable real-world\ngeneralization. Based on diverse augmentations of robot data, we show how\nscalable robot manipulation policies can be trained and deployed both in\nsimulation and in unseen real-world environments such as kitchens and\ntable-tops. By demonstrating the effectiveness of image-text generative models\nin diverse real-world robotic applications, our generative augmentation\nframework provides a scalable and efficient path for boosting generalization in\nrobot learning at no extra human cost.",
      "tldr_zh": "这篇论文解决了机器人操作学习在真实世界泛化的挑战，提出利用预训练的图像-文本生成模型（image-text generative models）作为廉价数据来源，以合成多样化场景并扩展数据集。作者开发了生成式增强框架（generative augmentation framework），通过语义可控的增强（semantically controllable augmentations）引入丰富的变化，帮助训练可扩展的机器人操作策略。实验结果显示，该框架在模拟和未见真实环境中（如厨房和桌面）成功部署，提升了机器人学习的泛化能力，而无需额外人力成本。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication by IJRR. First 3 authors contributed\n  equally. Last 3 authors advised equally",
      "pdf_url": "http://arxiv.org/pdf/2409.00951v1",
      "published_date": "2024-09-02 05:25:34 UTC",
      "updated_date": "2024-09-02 05:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:50:32.376766"
    },
    {
      "arxiv_id": "2409.00947v1",
      "title": "XNet v2: Fewer Limitations, Better Results and Greater Universality",
      "title_zh": "XNet v2：更少的限制、更好的结果和更大的通用性",
      "authors": [
        "Yanfeng Zhou",
        "Lingrui Li",
        "Zichen Wang",
        "Guole Liu",
        "Ziwen Liu",
        "Ge Yang"
      ],
      "abstract": "XNet introduces a wavelet-based X-shaped unified architecture for fully- and\nsemi-supervised biomedical segmentation. So far, however, XNet still faces the\nlimitations, including performance degradation when images lack high-frequency\n(HF) information, underutilization of raw images and insufficient fusion. To\naddress these issues, we propose XNet v2, a low- and high-frequency\ncomplementary model. XNet v2 performs wavelet-based image-level complementary\nfusion, using fusion results along with raw images inputs three different\nsub-networks to construct consistency loss. Furthermore, we introduce a\nfeature-level fusion module to enhance the transfer of low-frequency (LF)\ninformation and HF information. XNet v2 achieves state-of-the-art in\nsemi-supervised segmentation while maintaining competitve results in\nfully-supervised learning. More importantly, XNet v2 excels in scenarios where\nXNet fails. Compared to XNet, XNet v2 exhibits fewer limitations, better\nresults and greater universality. Extensive experiments on three 2D and two 3D\ndatasets demonstrate the effectiveness of XNet v2. Code is available at\nhttps://github.com/Yanfeng-Zhou/XNetv2 .",
      "tldr_zh": "本文提出 XNet v2，一种改进的 wavelet-based 架构，用于 fully- and semi-supervised biomedical segmentation，旨在解决 XNet 的性能下降、原始图像未充分利用和融合不足等问题。XNet v2 通过 wavelet-based image-level complementary fusion 和 feature-level fusion module 增强低频(LF)和高频(HF)信息的转移，并结合原始图像输入三个子网络构建 consistency loss。实验结果显示，XNet v2 在 semi-supervised segmentation 中达到 state-of-the-art 水平，在 fully-supervised learning 中保持竞争性表现，并在三个 2D 和两个 3D 数据集上证明了其更少的局限性、更好结果和更大通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00947v1",
      "published_date": "2024-09-02 05:20:18 UTC",
      "updated_date": "2024-09-02 05:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:50:45.713853"
    },
    {
      "arxiv_id": "2409.00946v2",
      "title": "A Framework for Synthetic Audio Conversations Generation using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kaung Myat Kyaw",
        "Jonathan Hoyin Chan"
      ],
      "abstract": "In this paper, we introduce ConversaSynth, a framework designed to generate\nsynthetic conversation audio using large language models (LLMs) with multiple\npersona settings. The framework first creates diverse and coherent text-based\ndialogues across various topics, which are then converted into audio using\ntext-to-speech (TTS) systems. Our experiments demonstrate that ConversaSynth\neffectively generates highquality synthetic audio datasets, which can\nsignificantly enhance the training and evaluation of models for audio tagging,\naudio classification, and multi-speaker speech recognition. The results\nindicate that the synthetic datasets generated by ConversaSynth exhibit\nsubstantial diversity and realism, making them suitable for developing robust,\nadaptable audio-based AI systems.",
      "tldr_zh": "本研究引入了ConversaSynth框架，利用Large Language Models (LLMs)生成多样化的合成对话音频，支持多种角色设置。该框架首先通过LLMs创建连贯的文本对话，然后使用Text-to-Speech (TTS)系统将这些对话转换为音频。实验结果显示，生成的合成数据集质量高且真实多样，能够显著提升音频标记、音频分类和多说话人语音识别模型的训练与评估，从而为开发稳健的音频AI系统提供有力支持。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "This work has been submitted for consideration at the WI-IAT'24 to be\n  held in December 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00946v2",
      "published_date": "2024-09-02 05:09:46 UTC",
      "updated_date": "2024-11-02 04:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:50:54.183596"
    },
    {
      "arxiv_id": "2409.00940v1",
      "title": "Large Language Models for Automatic Detection of Sensitive Topics",
      "title_zh": "大语言模型用于敏感主题的自动检测",
      "authors": [
        "Ruoyu Wen",
        "Stephanie Elena Crowe",
        "Kunal Gupta",
        "Xinyue Li",
        "Mark Billinghurst",
        "Simon Hoermann",
        "Dwain Allan",
        "Alaeddin Nassani",
        "Thammathip Piumsomboon"
      ],
      "abstract": "Sensitive information detection is crucial in content moderation to maintain\nsafe online communities. Assisting in this traditionally manual process could\nrelieve human moderators from overwhelming and tedious tasks, allowing them to\nfocus solely on flagged content that may pose potential risks. Rapidly\nadvancing large language models (LLMs) are known for their capability to\nunderstand and process natural language and so present a potential solution to\nsupport this process. This study explores the capabilities of five LLMs for\ndetecting sensitive messages in the mental well-being domain within two online\ndatasets and assesses their performance in terms of accuracy, precision,\nrecall, F1 scores, and consistency. Our findings indicate that LLMs have the\npotential to be integrated into the moderation workflow as a convenient and\nprecise detection tool. The best-performing model, GPT-4o, achieved an average\naccuracy of 99.5\\% and an F1-score of 0.99. We discuss the advantages and\npotential challenges of using LLMs in the moderation workflow and suggest that\nfuture research should address the ethical considerations of utilising this\ntechnology.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在自动检测敏感话题（如心理健康领域信息）中的应用，旨在辅助内容审核流程减轻人类审核员的负担。研究评估了五个LLMs在两个在线数据集上的性能，包括准确率、精确率、召回率、F1分数和一致性，结果显示GPT-4o表现出色，平均准确率达99.5%且F1分数为0.99。作者讨论了LLMs的优势（如便利性和精确性）、潜在挑战（如伦理问题），并建议未来研究关注其在审核工作流中的道德应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "J.6"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 Oz CHI conference",
      "pdf_url": "http://arxiv.org/pdf/2409.00940v1",
      "published_date": "2024-09-02 04:50:42 UTC",
      "updated_date": "2024-09-02 04:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:51:06.278229"
    },
    {
      "arxiv_id": "2409.00923v1",
      "title": "Development of Occupancy Prediction Algorithm for Underground Parking Lots",
      "title_zh": "地下停车场占用预测算法的开发",
      "authors": [
        "Shijie Wang"
      ],
      "abstract": "The core objective of this study is to address the perception challenges\nfaced by autonomous driving in adverse environments like basements. Initially,\nthis paper commences with data collection in an underground garage. A simulated\nunderground garage model is established within the CARLA simulation\nenvironment, and SemanticKITTI format occupancy ground truth data is collected\nin this simulated setting. Subsequently, the study integrates a\nTransformer-based Occupancy Network model to complete the occupancy grid\nprediction task within this scenario. A comprehensive BEV perception framework\nis designed to enhance the accuracy of neural network models in dimly lit,\nchallenging autonomous driving environments. Finally, experiments validate the\naccuracy of the proposed solution's perception performance in basement\nscenarios. The proposed solution is tested on our self-constructed underground\ngarage dataset, SUSTech-COE-ParkingLot, yielding satisfactory results.",
      "tldr_zh": "这篇论文针对自动驾驶在地下停车场等不利环境的感知挑战，开发了一种占用预测算法。研究方法包括在真实地下车库收集数据、在 CARLA 模拟环境中建立模型并生成 SemanticKITTI 格式的占用网格真实数据，然后整合 Transformer-based Occupancy Network 模型和 BEV 感知框架，以提升神经网络在光线不足场景下的准确性。实验结果显示，该算法在自建数据集 SUSTech-COE-ParkingLot 上取得了满意的感知性能，验证了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00923v1",
      "published_date": "2024-09-02 03:31:49 UTC",
      "updated_date": "2024-09-02 03:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:51:20.806865"
    },
    {
      "arxiv_id": "2409.00921v1",
      "title": "Statically Contextualizing Large Language Models with Typed Holes",
      "title_zh": "通过类型洞静态上下文化大型语言模型",
      "authors": [
        "Andrew Blinn",
        "Xiang Li",
        "June Hyung Kim",
        "Cyrus Omar"
      ],
      "abstract": "Large language models (LLMs) have reshaped the landscape of program\nsynthesis. However, contemporary LLM-based code completion systems often\nhallucinate broken code because they lack appropriate context, particularly\nwhen working with definitions not in the training data nor near the cursor.\nThis paper demonstrates that tight integration with the type and binding\nstructure of a language, as exposed by its language server, can address this\ncontextualization problem in a token-efficient manner. In short, we contend\nthat AIs need IDEs, too! In particular, we integrate LLM code generation into\nthe Hazel live program sketching environment. The Hazel Language Server\nidentifies the type and typing context of the hole being filled, even in the\npresence of errors, ensuring that a meaningful program sketch is always\navailable. This allows prompting with codebase-wide contextual information not\nlexically local to the cursor, nor necessarily in the same file, but that is\nlikely to be semantically local to the developer's goal. Completions\nsynthesized by the LLM are then iteratively refined via further dialog with the\nlanguage server. To evaluate these techniques, we introduce MVUBench, a dataset\nof model-view-update (MVU) web applications. These applications serve as\nchallenge problems due to their reliance on application-specific data\nstructures. We find that contextualization with type definitions is\nparticularly impactful. After introducing our ideas in the context of Hazel we\nduplicate our techniques and port MVUBench to TypeScript in order to validate\nthe applicability of these methods to higher-resource languages. Finally, we\noutline ChatLSP, a conservative extension to the Language Server Protocol (LSP)\nthat language servers can implement to expose capabilities that AI code\ncompletion systems of various designs can use to incorporate static context\nwhen generating prompts for an LLM.",
      "tldr_zh": "本论文探讨了如何通过类型化洞（typed holes）为大型语言模型（LLMs）提供静态上下文，以解决代码完成系统在处理训练数据外定义时常产生的错误代码问题。研究者将 LLMs 与语言服务器的类型和绑定结构紧密整合，在 Hazel 编程环境中实现程序草图生成，确保即使存在错误也能获取有意义的上下文，并通过迭代对话进行精炼。实验使用 MVUBench 数据集（一个基于模型-视图-更新（MVU）网络应用的基准）进行评估，结果显示类型定义的上下文显著提升了准确性，准确率在移植到 TypeScript 后同样有效。最后，论文提出 ChatLSP 作为 Language Server Protocol (LSP) 的扩展，允许 AI 系统利用静态上下文生成更可靠的提示。",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.SE",
        "D.3.0"
      ],
      "primary_category": "cs.PL",
      "comment": "To appear at OOPSLA2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00921v1",
      "published_date": "2024-09-02 03:29:00 UTC",
      "updated_date": "2024-09-02 03:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:51:44.095264"
    },
    {
      "arxiv_id": "2409.00920v1",
      "title": "ToolACE: Winning the Points of LLM Function Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Weiwen Liu",
        "Xu Huang",
        "Xingshan Zeng",
        "Xinlong Hao",
        "Shuai Yu",
        "Dexun Li",
        "Shuai Wang",
        "Weinan Gan",
        "Zhengying Liu",
        "Yuanqing Yu",
        "Zezhong Wang",
        "Yuxian Wang",
        "Wu Ning",
        "Yutai Hou",
        "Bin Wang",
        "Chuhan Wu",
        "Xinzhi Wang",
        "Yong Liu",
        "Yasheng Wang",
        "Duyu Tang",
        "Dandan Tu",
        "Lifeng Shang",
        "Xin Jiang",
        "Ruiming Tang",
        "Defu Lian",
        "Qun Liu",
        "Enhong Chen"
      ],
      "abstract": "Function calling significantly extends the application boundary of large\nlanguage models, where high-quality and diverse training data is critical for\nunlocking this capability. However, real function-calling data is quite\nchallenging to collect and annotate, while synthetic data generated by existing\npipelines tends to lack coverage and accuracy. In this paper, we present\nToolACE, an automatic agentic pipeline designed to generate accurate, complex,\nand diverse tool-learning data. ToolACE leverages a novel self-evolution\nsynthesis process to curate a comprehensive API pool of 26,507 diverse APIs.\nDialogs are further generated through the interplay among multiple agents,\nguided by a formalized thinking process. To ensure data accuracy, we implement\na dual-layer verification system combining rule-based and model-based checks.\nWe demonstrate that models trained on our synthesized data, even with only 8B\nparameters, achieve state-of-the-art performance on the Berkeley\nFunction-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a\nsubset of the data are publicly available at https://huggingface.co/Team-ACE.",
      "tldr_zh": "该论文提出ToolACE，一种自动代理管道，用于生成高质量、多样化的LLM函数调用（function calling）训练数据，以解决真实数据收集困难和合成数据准确性不足的问题。ToolACE采用自演化合成过程（self-evolution synthesis process）构建一个包含26,507个API的全面API池，并通过多个代理的互动和正式化思考过程生成复杂对话，同时使用双层验证系统（dual-layer verification system）确保数据准确性。实验结果显示，使用ToolACE数据训练的8B参数模型在Berkeley Function-Calling Leaderboard上达到最先进性能，媲美GPT-4模型。该框架及其数据子集已公开在Hugging Face上，促进了LLM工具学习领域的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00920v1",
      "published_date": "2024-09-02 03:19:56 UTC",
      "updated_date": "2024-09-02 03:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:51:43.572690"
    },
    {
      "arxiv_id": "2409.00919v1",
      "title": "MMT-BERT: Chord-aware Symbolic Music Generation Based on Multitrack Music Transformer and MusicBERT",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlong Zhu",
        "Keigo Sakurai",
        "Ren Togo",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "We propose a novel symbolic music representation and Generative Adversarial\nNetwork (GAN) framework specially designed for symbolic multitrack music\ngeneration. The main theme of symbolic music generation primarily encompasses\nthe preprocessing of music data and the implementation of a deep learning\nframework. Current techniques dedicated to symbolic music generation generally\nencounter two significant challenges: training data's lack of information about\nchords and scales and the requirement of specially designed model architecture\nadapted to the unique format of symbolic music representation. In this paper,\nwe solve the above problems by introducing new symbolic music representation\nwith MusicLang chord analysis model. We propose our MMT-BERT architecture\nadapting to the representation. To build a robust multitrack music generator,\nwe fine-tune a pre-trained MusicBERT model to serve as the discriminator, and\nincorporate relativistic standard loss. This approach, supported by the\nin-depth understanding of symbolic music encoded within MusicBERT, fortifies\nthe consonance and humanity of music generated by our method. Experimental\nresults demonstrate the effectiveness of our approach which strictly follows\nthe state-of-the-art methods.",
      "tldr_zh": "该论文提出了一种新的符号音乐表示方法和GAN框架，用于符号多轨音乐生成，以解决训练数据缺少和弦（chords）和音阶信息，以及模型架构需适应符号音乐格式的挑战。研究引入MusicLang进行和弦分析，并设计了MMT-BERT架构，该架构基于Multitrack Music Transformer，并利用预训练的MusicBERT作为判别器，结合relativistic standard loss来提升生成的音乐一致性和人性化。通过实验验证，该方法在多轨音乐生成任务上显示出与最先进技术相当的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to the 25th International Society for Music Information\n  Retrieval Conference (ISMIR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.00919v1",
      "published_date": "2024-09-02 03:18:56 UTC",
      "updated_date": "2024-09-02 03:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:51:55.493957"
    },
    {
      "arxiv_id": "2409.12926v1",
      "title": "MaskMol: Knowledge-guided Molecular Image Pre-Training Framework for Activity Cliffs",
      "title_zh": "MaskMol：基于知识引导的分子图像预训练框架，用于活性悬崖",
      "authors": [
        "Zhixiang Cheng",
        "Hongxin Xiang",
        "Pengsen Ma",
        "Li Zeng",
        "Xin Jin",
        "Xixi Yang",
        "Jianxin Lin",
        "Yang Deng",
        "Bosheng Song",
        "Xinxin Feng",
        "Changhui Deng",
        "Xiangxiang Zeng"
      ],
      "abstract": "Activity cliffs, which refer to pairs of molecules that are structurally\nsimilar but show significant differences in their potency, can lead to model\nrepresentation collapse and make the model challenging to distinguish them. Our\nresearch indicates that as molecular similarity increases, graph-based methods\nstruggle to capture these nuances, whereas image-based approaches effectively\nretain the distinctions. Thus, we developed MaskMol, a knowledge-guided\nmolecular image self-supervised learning framework. MaskMol accurately learns\nthe representation of molecular images by considering multiple levels of\nmolecular knowledge, such as atoms, bonds, and substructures. By utilizing\npixel masking tasks, MaskMol extracts fine-grained information from molecular\nimages, overcoming the limitations of existing deep learning models in\nidentifying subtle structural changes. Experimental results demonstrate\nMaskMol's high accuracy and transferability in activity cliff estimation and\ncompound potency prediction across 20 different macromolecular targets,\noutperforming 25 state-of-the-art deep learning and machine learning\napproaches. Visualization analyses reveal MaskMol's high biological\ninterpretability in identifying activity cliff-relevant molecular\nsubstructures. Notably, through MaskMol, we identified candidate EP4 inhibitors\nthat could be used to treat tumors. This study not only raises awareness about\nactivity cliffs but also introduces a novel method for molecular image\nrepresentation learning and virtual screening, advancing drug discovery and\nproviding new insights into structure-activity relationships (SAR).",
      "tldr_zh": "本研究针对Activity Cliffs（结构相似但效力差异显著的分子对）问题，提出MaskMol框架，这是一个知识引导的分子图像自监督学习预训练方法。MaskMol通过整合多级别分子知识（如atoms、bonds和substructures）并利用pixel masking任务，提取细粒度信息，帮助模型更好地捕捉微妙结构变化，从而克服现有深度学习模型的局限性。实验结果显示，MaskMol在20个大分子目标上的Activity Cliffs估计和化合物效力预测中，优于25个state-of-the-art方法，并在可视化分析中展现出高生物学可解释性。最终，该框架不仅识别出潜在的EP4抑制剂用于肿瘤治疗，还为分子图像表示学习、虚拟筛选和structure-activity relationships (SAR)研究提供了新洞见，推进了药物发现领域的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "33 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.12926v1",
      "published_date": "2024-09-02 03:03:22 UTC",
      "updated_date": "2024-09-02 03:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:52:08.777941"
    },
    {
      "arxiv_id": "2409.00909v1",
      "title": "ViRED: Prediction of Visual Relations in Engineering Drawings",
      "title_zh": "ViRED：工程图纸中视觉关系的预测",
      "authors": [
        "Chao Gu",
        "Ke Lin",
        "Yiyang Luo",
        "Jiahui Hou",
        "Xiang-Yang Li"
      ],
      "abstract": "To accurately understand engineering drawings, it is essential to establish\nthe correspondence between images and their description tables within the\ndrawings. Existing document understanding methods predominantly focus on text\nas the main modality, which is not suitable for documents containing\nsubstantial image information. In the field of visual relation detection, the\nstructure of the task inherently limits its capacity to assess relationships\namong all entity pairs in the drawings. To address this issue, we propose a\nvision-based relation detection model, named ViRED, to identify the\nassociations between tables and circuits in electrical engineering drawings.\nOur model mainly consists of three parts: a vision encoder, an object encoder,\nand a relation decoder. We implement ViRED using PyTorch to evaluate its\nperformance. To validate the efficacy of ViRED, we conduct a series of\nexperiments. The experimental results indicate that, within the engineering\ndrawing dataset, our approach attained an accuracy of 96\\% in the task of\nrelation prediction, marking a substantial improvement over existing\nmethodologies. The results also show that ViRED can inference at a fast speed\neven when there are numerous objects in a single engineering drawing.",
      "tldr_zh": "这篇论文提出了ViRED模型，用于预测工程图中的视觉关系，旨在解决现有文档理解方法偏重文本而忽略图像信息的问题。ViRED主要由vision encoder、object encoder和relation decoder组成，通过PyTorch实现，以识别电气工程图中表格和电路之间的关联。实验结果显示，该模型在工程图数据集上实现了96%的关系预测准确率，比现有方法显著提升，并支持快速推理，即使图中包含众多对象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00909v1",
      "published_date": "2024-09-02 02:42:34 UTC",
      "updated_date": "2024-09-02 02:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:52:22.857145"
    },
    {
      "arxiv_id": "2409.00904v1",
      "title": "Multi-scale Temporal Fusion Transformer for Incomplete Vehicle Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanwen Liu",
        "Chao Li",
        "Yang Wang",
        "Nan Yang",
        "Xing Fan",
        "Jiaqi Ma",
        "Xiangmo Zhao"
      ],
      "abstract": "Motion prediction plays an essential role in autonomous driving systems,\nenabling autonomous vehicles to achieve more accurate local-path planning and\ndriving decisions based on predictions of the surrounding vehicles. However,\nexisting methods neglect the potential missing values caused by object\nocclusion, perception failures, etc., which inevitably degrades the trajectory\nprediction performance in real traffic scenarios. To address this limitation,\nwe propose a novel end-to-end framework for incomplete vehicle trajectory\nprediction, named Multi-scale Temporal Fusion Transformer (MTFT), which\nconsists of the Multi-scale Attention Head (MAH) and the Continuity\nRepresentation-guided Multi-scale Fusion (CRMF) module. Specifically, the MAH\nleverages the multi-head attention mechanism to parallelly capture multi-scale\nmotion representation of trajectory from different temporal granularities, thus\nmitigating the adverse effect of missing values on prediction. Furthermore, the\nmulti-scale motion representation is input into the CRMF module for multi-scale\nfusion to obtain the robust temporal feature of the vehicle. During the fusion\nprocess, the continuity representation of vehicle motion is first extracted\nacross time steps to guide the fusion, ensuring that the resulting temporal\nfeature incorporates both detailed information and the overall trend of vehicle\nmotion, which facilitates the accurate decoding of future trajectory that is\nconsistent with the vehicle's motion trend. We evaluate the proposed model on\nfour datasets derived from highway and urban traffic scenarios. The\nexperimental results demonstrate its superior performance in the incomplete\nvehicle trajectory prediction task compared with state-of-the-art models, e.g.,\na comprehensive performance improvement of more than 39% on the HighD dataset.",
      "tldr_zh": "这篇论文针对自动驾驶系统中车辆轨迹预测的缺失值问题（如物体遮挡），提出了一种新颖的端到端框架 Multi-scale Temporal Fusion Transformer (MTFT)。MTFT 包括 Multi-scale Attention Head (MAH) 模块，用于并行捕获不同时间粒度的多尺度运动表示，以减轻缺失值的影响；以及 Continuity Representation-guided Multi-scale Fusion (CRMF) 模块，通过提取运动连续性表示来指导多尺度融合，确保生成的轨迹特征兼顾细节和整体趋势。在四个高速公路和城市交通数据集上的实验中，MTFT 比现有最先进模型表现出色，例如在 HighD 数据集上实现超过 39% 的综合性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00904v1",
      "published_date": "2024-09-02 02:36:18 UTC",
      "updated_date": "2024-09-02 02:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:52:38.338162"
    },
    {
      "arxiv_id": "2409.00899v2",
      "title": "MarsCode Agent: AI-native Automated Bug Fixing",
      "title_zh": "MarsCode Agent：AI 原生自动化错误修复",
      "authors": [
        "Yizhou Liu",
        "Pengfei Gao",
        "Xinchen Wang",
        "Jie Liu",
        "Yexuan Shi",
        "Zhao Zhang",
        "Chao Peng"
      ],
      "abstract": "Recent advances in large language models (LLMs) have shown significant\npotential to automate various software development tasks, including code\ncompletion, test generation, and bug fixing. However, the application of LLMs\nfor automated bug fixing remains challenging due to the complexity and\ndiversity of real-world software systems. In this paper, we introduce MarsCode\nAgent, a novel framework that leverages LLMs to automatically identify and\nrepair bugs in software code. MarsCode Agent combines the power of LLMs with\nadvanced code analysis techniques to accurately localize faults and generate\npatches. Our approach follows a systematic process of planning, bug\nreproduction, fault localization, candidate patch generation, and validation to\nensure high-quality bug fixes. We evaluated MarsCode Agent on SWE-bench, a\ncomprehensive benchmark of real-world software projects, and our results show\nthat MarsCode Agent achieves a high success rate in bug fixing compared to most\nof the existing automated approaches.",
      "tldr_zh": "这篇论文介绍了 MarsCode Agent，一种基于大型语言模型 (LLMs) 的创新框架，用于自动识别和修复软件代码中的 bug，以应对真实软件系统复杂性的挑战。该框架整合 LLMs 与高级代码分析技术，通过一个系统过程——包括规划、bug 再现、故障定位、候选补丁生成和验证——来确保高品质的修复。实验结果显示，在 SWE-bench 基准测试中，MarsCode Agent 的 bug 修复成功率显著高于现有方法，为 AI-native 软件开发工具提供了新进展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Yizhou Liu and Pengfei Gao contributed equally and the order is\n  determined by rolling the dice. Chao Peng is the corresponding author",
      "pdf_url": "http://arxiv.org/pdf/2409.00899v2",
      "published_date": "2024-09-02 02:24:38 UTC",
      "updated_date": "2024-09-04 06:19:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:52:49.081390"
    },
    {
      "arxiv_id": "2409.00887v1",
      "title": "User-Specific Dialogue Generation with User Profile-Aware Pre-Training Model and Parameter-Efficient Fine-Tuning",
      "title_zh": "用户特定对话生成：利用用户配置文件感知预训练模型和参数高效微调",
      "authors": [
        "Atsushi Otsuka",
        "Kazuya Matsuo",
        "Ryo Ishii",
        "Narichika Nomoto",
        "Hiroaki Sugiyama"
      ],
      "abstract": "This paper addresses user-specific dialogs. In contrast to previous research\non personalized dialogue focused on achieving virtual user dialogue as defined\nby persona descriptions, user-specific dialogue aims to reproduce real-user\ndialogue beyond persona-based dialogue. Fine-tuning using the target user's\ndialogue history is an efficient learning method for a user-specific model.\nHowever, it is prone to overfitting and model destruction due to the small\namount of data. Therefore, we propose a learning method for user-specific\nmodels by combining parameter-efficient fine-tuning with a pre-trained dialogue\nmodel that includes user profiles. Parameter-efficient fine-tuning adds a small\nnumber of parameters to the entire model, so even small amounts of training\ndata can be trained efficiently and are robust to model destruction. In\naddition, the pre-trained model, which is learned by adding simple prompts for\nautomatically inferred user profiles, can generate speech with enhanced\nknowledge of the user's profile, even when there is little training data during\nfine-tuning. In experiments, we compared the proposed model with\nlarge-language-model utterance generation using prompts containing users'\npersonal information. Experiments reproducing real users' utterances revealed\nthat the proposed model can generate utterances with higher reproducibility\nthan the compared methods, even with a small model.",
      "tldr_zh": "本论文针对用户特定对话（user-specific dialogue）提出了一种新方法，旨在超越基于角色描述的个性化对话，通过重现真实用户对话历史。研究结合了用户配置文件感知的预训练模型（pre-trained model）和参数高效微调（parameter-efficient fine-tuning），通过添加少量参数来避免小数据量导致的过拟合和模型破坏，同时利用简单提示学习自动推断的用户配置文件以增强对话生成。实验结果显示，与使用大语言模型的提示方法相比，该模型即使在小规模下也能生成更具再现性的用户话语，证明了其在高效学习和鲁棒性方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00887v1",
      "published_date": "2024-09-02 01:30:40 UTC",
      "updated_date": "2024-09-02 01:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:53:01.024112"
    },
    {
      "arxiv_id": "2409.00879v1",
      "title": "Beyond Parameter Count: Implicit Bias in Soft Mixture of Experts",
      "title_zh": "超越参数计数：软专家混合中的隐式偏差",
      "authors": [
        "Youngseog Chung",
        "Dhruv Malik",
        "Jeff Schneider",
        "Yuanzhi Li",
        "Aarti Singh"
      ],
      "abstract": "The traditional viewpoint on Sparse Mixture of Experts (MoE) models is that\ninstead of training a single large expert, which is computationally expensive,\nwe can train many small experts. The hope is that if the total parameter count\nof the small experts equals that of the singular large expert, then we retain\nthe representation power of the large expert while gaining computational\ntractability and promoting expert specialization. The recently introduced Soft\nMoE replaces the Sparse MoE's discrete routing mechanism with a differentiable\ngating function that smoothly mixes tokens. While this smooth gating function\nsuccessfully mitigates the various training instabilities associated with\nSparse MoE, it is unclear whether it induces implicit biases that affect Soft\nMoE's representation power or potential for expert specialization. We prove\nthat Soft MoE with a single arbitrarily powerful expert cannot represent simple\nconvex functions. This justifies that Soft MoE's success cannot be explained by\nthe traditional viewpoint of many small experts collectively mimicking the\nrepresentation power of a single large expert, and that multiple experts are\nactually necessary to achieve good representation power (even for a fixed total\nparameter count). Continuing along this line of investigation, we introduce a\nnotion of expert specialization for Soft MoE, and while varying the number of\nexperts yet fixing the total parameter count, we consider the following\n(computationally intractable) task. Given any input, how can we discover the\nexpert subset that is specialized to predict this input's label? We empirically\nshow that when there are many small experts, the architecture is implicitly\nbiased in a fashion that allows us to efficiently approximate the specialized\nexpert subset. Our method can be easily implemented to potentially reduce\ncomputation during inference.",
      "tldr_zh": "本论文挑战了传统Sparse Mixture of Experts (MoE)观点，证明Soft MoE即使使用一个强大专家也无法表示简单的凸函数，这表明多个专家是维持表示能力的关键，而非仅靠总参数数。研究者引入了Soft MoE的专家专业化概念，通过实验在固定总参数数下增加专家数量，展示了架构的隐式偏差能高效近似针对特定输入的专业化专家子集。最终，这种方法可简化推理过程，潜在减少计算开销，为MoE模型的优化提供新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 5 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.00879v1",
      "published_date": "2024-09-02 00:39:00 UTC",
      "updated_date": "2024-09-02 00:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:53:13.207070"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 84,
  "processed_papers_count": 84,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T20:53:43.130077"
}