{
  "date": "2024-01-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-09 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 68 篇论文，主要聚焦于 AI 模型（如大型语言模型 LLMs）的鲁棒性、图像生成、强化学习和知识图谱构建等领域，其中令人印象深刻的是 LLM 在概念对齐和调试中的创新应用，以及知名学者如 Thomas L. Griffiths 和 Yaochu Jin 的相关工作。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些重要、话题性和有影响力的高质量文章（如 LLM 相关和图像生成），再快速掠过其他次要内容。每个条目包括论文标题（中文 + 英文）和核心贡献描述。\n\n### 重点论文讨论\n\n**1. Concept Alignment（概念对齐）**  \n作者包括知名学者 Thomas L. Griffiths。  \n这篇论文强调在 AI 对齐中，需先实现人类和机器的概念对齐，而非仅局限于价值对齐。主要贡献是通过整合哲学、认知科学和深度学习，提出概念对齐框架，分析概念学习差异，并探讨实现共享概念的机会和挑战。\n\n**2. DebugBench: Evaluating Debugging Capability of Large Language Models（评估大型语言模型的调试能力）**  \n这篇论文（NeurIPS MP2 Workshop 2023）探讨 LLMs 在代码调试中的表现。  \n主要发现：构建了一个包含 4253 个实例的基准数据集，评估 LLMs 在零样本场景下的调试性能，发现闭源模型接近人类水平，但开源模型表现较差；实验证明，LLMs 在特定任务中可显著提升调试效率。\n\n**3. Agent Alignment in Evolving Social Norms（代理在演化社会规范中的对齐）**  \n论文提出一个演化框架 EvolutionaryAgent。  \n关键贡献：通过模拟社会规范演化，使用 LLMs 构建代理模型，实现代理在动态环境中自我对齐，提高了代理的适应性和长期性能，实验显示其在一般任务中保持高效。\n\n**4. Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation（可变形扩散：单图像头像创建的 3D 一致扩散模型）**  \n这篇论文（CVPR 2024）整合 3D 可变形模型和扩散方法。  \n主要发现：提出一个框架，能从单图像生成可动画的 3D 头像，实现高保真度和表情控制，实验在新型视图和表情合成任务中超越现有模型，显著提升了数字人类的生成质量。\n\n**5. MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation（MagicVideo-V2：多阶段高美学视频生成）**  \n论文引入端到端视频生成管道。  \n核心贡献：结合文本到图像模型和扩散技术，实现高质量视频生成，实验显示其在文本到视频任务中优于 Runway 和 Stable Video Diffusion 等基线，提供更流畅和高保真的输出。\n\n**6. DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation（DiffSHEG：基于扩散的实时语音驱动 3D 表情和手势生成方法）**  \n这篇论文提出一个扩散框架。  \n主要发现：使用单向信息流和并行解码，实现语音驱动的 3D 表情和手势生成，实验在公开数据集上达到最先进性能，适用于数字人类和交互应用。\n\n**7. Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints（基于图学习的城市空中机动车队调度）**  \n作者包括 Souma Chowdhury。  \n论文开发了一个图强化学习方法。  \n关键贡献：针对城市空中交通，构建一个考虑需求不确定性和约束的调度模型，使用图胶囊网络和 Transformer 优化，实验显示其在真实场景中比遗传算法快 1000 倍，同时提升利润。\n\n**8. Sample-and-Bound for Non-Convex Optimization（非凸优化的样本和边界方法）**  \n论文（AAAI 2024）提出基于 Monte Carlo Tree Search 的算法。  \n主要发现：改进了非凸优化效率，通过采样和边界策略平衡探索与利用，实验在高维基准上优于基线，代码已开源。\n\n### 其他论文快速掠过\n以下论文主题较常规或影响力较小，我仅简要概述核心点：\n\n**9. A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning（空间交互模型的深度学习表示，用于社区商业集群的弹性规划）**  \n提出 SIM-GAT 模型，用于预测商业集群访问流。贡献：使用图注意力网络捕获复杂交互，提高了城市规划的韧性。\n\n**10. MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer（MoSECroT：使用静态词嵌入的模型拼接实现跨语言零样本转移）**  \n探索跨语言转移方法。发现：框架通过相对表示构建公共空间，但实验显示其不如强基线。\n\n**11. Phishing Website Detection through Multi-Model Analysis of HTML Content（通过 HTML 内容的多模型分析检测网络钓鱼网站）**  \n使用 MLP 和 NLP 模型检测钓鱼网站。贡献：提出融合嵌入方法，F1 分数达 96.80%，在新数据集上表现优异。\n\n**12. Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models（Lightning Attention-2：处理 LLMs 中无限序列长度的免费午餐）**  \n优化线性注意力机制。发现：实现序列长度无关的训练速度，显著快于传统注意力。\n\n**13. RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation（RoSA：通过鲁棒适应实现精确的参数高效微调）**  \n针对 LLMs 提出低秩和稀疏微调。贡献：在生成任务中优于 LoRA，代码开源。\n\n其余论文如数据集构建、基准测试或特定领域优化（如医疗 AI、知识图谱），虽有贡献但不具广泛话题性，我在此不详细展开，以控制篇幅。总体而言，今天的更新突显 AI 模型的扩展性和实际应用潜力，LLM 相关工作尤其值得关注。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2401.04851v1",
      "title": "Graph Learning-based Fleet Scheduling for Urban Air Mobility under Operational Constraints, Varying Demand & Uncertainties",
      "title_zh": "翻译失败",
      "authors": [
        "Steve Paul",
        "Jhoel Witter",
        "Souma Chowdhury"
      ],
      "abstract": "This paper develops a graph reinforcement learning approach to online\nplanning of the schedule and destinations of electric aircraft that comprise an\nurban air mobility (UAM) fleet operating across multiple vertiports. This fleet\nscheduling problem is formulated to consider time-varying demand, constraints\nrelated to vertiport capacity, aircraft capacity and airspace safety\nguidelines, uncertainties related to take-off delay, weather-induced route\nclosures, and unanticipated aircraft downtime. Collectively, such a formulation\npresents greater complexity, and potentially increased realism, than in\nexisting UAM fleet planning implementations. To address these complexities, a\nnew policy architecture is constructed, primary components of which include:\ngraph capsule conv-nets for encoding vertiport and aircraft-fleet states both\nabstracted as graphs; transformer layers encoding time series information on\ndemand and passenger fare; and a Multi-head Attention-based decoder that uses\nthe encoded information to compute the probability of selecting each available\ndestination for an aircraft. Trained with Proximal Policy Optimization, this\npolicy architecture shows significantly better performance in terms of daily\naveraged profits on unseen test scenarios involving 8 vertiports and 40\naircraft, when compared to a random baseline and genetic algorithm-derived\noptimal solutions, while being nearly 1000 times faster in execution than the\nlatter.",
      "tldr_zh": "本文提出了一种基于图强化学习(graph reinforcement learning)的在线规划方法，用于城市空中交通(UAM)舰队的飞行计划和目的地调度，考虑了时间变化的需求、机场容量限制、飞机容量、空域安全准则以及不确定性如起飞延误和天气影响。核心架构包括图胶囊卷积网络(graph capsule conv-nets)编码机场和舰队状态、Transformer 层处理需求和乘客票价的时间序列信息，以及多头注意力(Multi-head Attention)解码器计算目的地选择概率，并采用 Proximal Policy Optimization 进行训练。在测试场景中，该方法在8个机场和40架飞机的环境下，比随机基准和遗传算法优化方案显著提高了每日平均利润，且执行速度快近1000倍。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "This paper is accepted to be presented at the ACM Symposium on\n  Applied Computing 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04851v1",
      "published_date": "2024-01-09 23:46:22 UTC",
      "updated_date": "2024-01-09 23:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:36:46.960544"
    },
    {
      "arxiv_id": "2401.04849v1",
      "title": "A Deep Learning Representation of Spatial Interaction Model for Resilient Spatial Planning of Community Business Clusters",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyan Hao",
        "Yan Wang"
      ],
      "abstract": "Existing Spatial Interaction Models (SIMs) are limited in capturing the\ncomplex and context-aware interactions between business clusters and trade\nareas. To address the limitation, we propose a SIM-GAT model to predict\nspatiotemporal visitation flows between community business clusters and their\ntrade areas. The model innovatively represents the integrated system of\nbusiness clusters, trade areas, and transportation infrastructure within an\nurban region using a connected graph. Then, a graph-based deep learning model,\ni.e., Graph AttenTion network (GAT), is used to capture the complexity and\ninterdependencies of business clusters. We developed this model with data\ncollected from the Miami metropolitan area in Florida. We then demonstrated its\neffectiveness in capturing varying attractiveness of business clusters to\ndifferent residential neighborhoods and across scenarios with an eXplainable AI\napproach. We contribute a novel method supplementing conventional SIMs to\npredict and analyze the dynamics of inter-connected community business\nclusters. The analysis results can inform data-evidenced and place-specific\nplanning strategies helping community business clusters better accommodate\ntheir customers across scenarios, and hence improve the resilience of community\nbusinesses.",
      "tldr_zh": "本研究针对现有 Spatial Interaction Models (SIMs) 在捕捉商业集群与贸易区域复杂互动的局限性，提出了一种基于深度学习的 SIM-GAT 模型，用于预测社区商业集群与贸易区域之间的时空访问流量。模型将商业集群、贸易区域和交通基础设施表示为一个连接图，并利用 Graph Attention Network (GAT) 来捕捉系统中的复杂性和相互依赖性。通过使用佛罗里达迈阿密都市区的真实数据进行验证，SIM-GAT 模型成功展示了商业集群对不同住宅社区吸引力的动态变化，并通过 eXplainable AI 方法进行解释。最终，该方法补充了传统 SIMs，为基于数据的弹性空间规划提供策略，帮助商业集群适应各种场景并提升社区业务的韧性。",
      "categories": [
        "econ.EM",
        "cs.AI"
      ],
      "primary_category": "econ.EM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04849v1",
      "published_date": "2024-01-09 23:42:21 UTC",
      "updated_date": "2024-01-09 23:42:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:36:58.037926"
    },
    {
      "arxiv_id": "2401.08672v1",
      "title": "Concept Alignment",
      "title_zh": "概念对齐",
      "authors": [
        "Sunayana Rane",
        "Polyphony J. Bruna",
        "Ilia Sucholutsky",
        "Christopher Kello",
        "Thomas L. Griffiths"
      ],
      "abstract": "Discussion of AI alignment (alignment between humans and AI systems) has\nfocused on value alignment, broadly referring to creating AI systems that share\nhuman values. We argue that before we can even attempt to align values, it is\nimperative that AI systems and humans align the concepts they use to understand\nthe world. We integrate ideas from philosophy, cognitive science, and deep\nlearning to explain the need for concept alignment, not just value alignment,\nbetween humans and machines. We summarize existing accounts of how humans and\nmachines currently learn concepts, and we outline opportunities and challenges\nin the path towards shared concepts. Finally, we explain how we can leverage\nthe tools already being developed in cognitive science and AI research to\naccelerate progress towards concept alignment.",
      "tldr_zh": "该论文强调，在实现AI alignment（AI与人类对齐）时，应优先关注concept alignment（概念对齐），而非仅限于value alignment（价值对齐），因为AI系统必须与人类共享相同的世界理解概念。作者整合了哲学、认知科学和深度学习的观点，分析了人类和机器当前学习概念的方式，并概述了实现共享概念的机遇和挑战。论文建议利用认知科学和AI研究中现有的工具来加速concept alignment的进展，从而为更可靠的人机互动奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS MP2 Workshop 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.08672v1",
      "published_date": "2024-01-09 23:32:18 UTC",
      "updated_date": "2024-01-09 23:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:37:07.657826"
    },
    {
      "arxiv_id": "2401.04846v10",
      "title": "The inherent goodness of well educated intelligence",
      "title_zh": "教育良好的智能的",
      "authors": [
        "Michael E. Glinsky"
      ],
      "abstract": "This paper will examine what makes a being intelligent, whether that be a\nbiological being or an artificial silicon being on a computer. Special\nattention will be paid to the being having the ability to characterize and\ncontrol a collective system of many identical conservative sub-systems\nconservatively interacting. The essence of intelligence will be found to be the\ngolden rule -- \"the collective acts as one\" or \"knowing the global consequences\nof local actions\". The flow of the collective is a small set of twinkling\ntextures, that are governed by a puppeteer who is pulling a small number of\nstrings according to a geodesic motion of least action, determined by the\nsymmetries. Controlling collective conservative systems is difficult and has\nhistorically been done by adding significant viscosity to the system to\nstabilize the desirable meta stable equilibriums of maximum performance, but it\ndegrades or destroys them in the process. There is an alternative. Once the\noptimum twinkling textures of the meta stable equilibriums are identified, the\ncollective system can be moved to the optimum twinkling textures, then quickly\nvibrated according to the textures so that the collective system remains at the\nmeta stable equilibrium. Well educated intelligence knows the global\nconsequences of its local actions so that it will not take short term actions\nthat will lead to poor long term outcomes. In contrast, trained intelligence or\ntrained stupidity will optimize its short term actions, leading to poor long\nterm outcomes. Well educated intelligence is inherently good, but trained\nstupidity is inherently evil and should be feared. Particular attention is paid\nto the control and optimization of economic and social collectives. These new\nresults are also applicable to physical collectives such as fields, fluids and\nplasmas.",
      "tldr_zh": "这篇论文探讨了智能的本质，定义为生物或人工智能实体能够表征和控制多个相同保守子系统的集体系统，并强调智能的核心在于遵守“golden rule”——即集体像一个整体行动，或了解局部行动的全局后果。论文指出，传统控制集体系统的方法（如添加viscosity）虽能稳定系统，但会损害性能；相反，通过识别和振动最佳“twinkling textures”，可以维持meta stable equilibriums，实现更优控制。作者区分了“well educated intelligence”（教育良好的智能），它能避免短期行动导致的长期不良结果，从而固有地善良，与“trained intelligence”（训练智能）或“trained stupidity”（训练愚蠢）形成对比，后者可能优化短期行为而导致负面影响。最终，论文将这些见解应用于经济、社会和物理集体系统，如fields、fluids和plasmas。",
      "categories": [
        "cs.AI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 13 figures, 15 equations, to be submitted to Nature",
      "pdf_url": "http://arxiv.org/pdf/2401.04846v10",
      "published_date": "2024-01-09 22:56:21 UTC",
      "updated_date": "2025-01-28 03:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:37:19.906853"
    },
    {
      "arxiv_id": "2401.04821v2",
      "title": "MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual Zero-shot Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Ye",
        "Yihong Liu",
        "Chunlan Ma",
        "Hinrich Schütze"
      ],
      "abstract": "Transformer-based pre-trained language models (PLMs) have achieved remarkable\nperformance in various natural language processing (NLP) tasks. However,\npre-training such models can take considerable resources that are almost only\navailable to high-resource languages. On the contrary, static word embeddings\nare easier to train in terms of computing resources and the amount of data\nrequired. In this paper, we introduce MoSECroT Model Stitching with Static Word\nEmbeddings for Crosslingual Zero-shot Transfer), a novel and challenging task\nthat is especially relevant to low-resource languages for which static word\nembeddings are available. To tackle the task, we present the first framework\nthat leverages relative representations to construct a common space for the\nembeddings of a source language PLM and the static word embeddings of a target\nlanguage. In this way, we can train the PLM on source-language training data\nand perform zero-shot transfer to the target language by simply swapping the\nembedding layer. However, through extensive experiments on two classification\ndatasets, we show that although our proposed framework is competitive with weak\nbaselines when addressing MoSECroT, it fails to achieve competitive results\ncompared with some strong baselines. In this paper, we attempt to explain this\nnegative result and provide several thoughts on possible improvement.",
      "tldr_zh": "本论文引入MoSECroT，一种基于Model Stitching和Static Word Embeddings的框架，旨在解决Transformer-based PLMs在低资源语言中的跨语言零样本转移（Crosslingual Zero-shot Transfer）问题，通过利用静态词嵌入减少资源需求。框架采用相对表示（relative representations）构建源语言PLM和目标语言静态词嵌入的共同空间，实现仅通过交换嵌入层即可进行零样本转移。实验结果显示，该方法在两个分类数据集上与弱基线（weak baselines）竞争，但未能超越强基线（strong baselines），论文随后分析了负面结果并提出潜在改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04821v2",
      "published_date": "2024-01-09 21:09:07 UTC",
      "updated_date": "2024-05-17 20:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:37:33.312294"
    },
    {
      "arxiv_id": "2401.04820v3",
      "title": "Phishing Website Detection through Multi-Model Analysis of HTML Content",
      "title_zh": "翻译失败",
      "authors": [
        "Furkan Çolhak",
        "Mert İlhan Ecevit",
        "Bilal Emir Uçar",
        "Reiner Creutzburg",
        "Hasan Dağ"
      ],
      "abstract": "The way we communicate and work has changed significantly with the rise of\nthe Internet. While it has opened up new opportunities, it has also brought\nabout an increase in cyber threats. One common and serious threat is phishing,\nwhere cybercriminals employ deceptive methods to steal sensitive\ninformation.This study addresses the pressing issue of phishing by introducing\nan advanced detection model that meticulously focuses on HTML content. Our\nproposed approach integrates a specialized Multi-Layer Perceptron (MLP) model\nfor structured tabular data and two pretrained Natural Language Processing\n(NLP) models for analyzing textual features such as page titles and content.\nThe embeddings from these models are harmoniously combined through a novel\nfusion process. The resulting fused embeddings are then input into a linear\nclassifier. Recognizing the scarcity of recent datasets for comprehensive\nphishing research, our contribution extends to the creation of an up-to-date\ndataset, which we openly share with the community. The dataset is meticulously\ncurated to reflect real-life phishing conditions, ensuring relevance and\napplicability. The research findings highlight the effectiveness of the\nproposed approach, with the CANINE demonstrating superior performance in\nanalyzing page titles and the RoBERTa excelling in evaluating page content. The\nfusion of two NLP and one MLP model,termed MultiText-LP, achieves impressive\nresults, yielding a 96.80 F1 score and a 97.18 accuracy score on our research\ndataset. Furthermore, our approach outperforms existing methods on the\nCatchPhish HTML dataset, showcasing its efficacies.",
      "tldr_zh": "这篇论文提出了一种通过多模型分析 HTML 内容来检测 Phishing 网站的方法，旨在应对网络威胁。方法整合了 Multi-Layer Perceptron (MLP) 模型用于处理结构化表格数据，以及两个预训练的 Natural Language Processing (NLP) 模型（CANINE 和 RoBERTa）来分析页面标题和内容，通过新型融合过程结合 embeddings 并输入线性分类器。研究者还创建并公开了一个最新的数据集，以反映真实钓鱼场景。实验结果显示，该融合模型 MultiText-LP 在数据集上达到了 96.80 F1 score 和 97.18 准确率，并超过了现有方法如 CatchPhish HTML 数据集上的表现。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04820v3",
      "published_date": "2024-01-09 21:08:13 UTC",
      "updated_date": "2024-07-10 10:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:37:45.721079"
    },
    {
      "arxiv_id": "2401.04812v3",
      "title": "Sample-and-Bound for Non-Convex Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yaoguang Zhai",
        "Zhizhen Qin",
        "Sicun Gao"
      ],
      "abstract": "Standard approaches for global optimization of non-convex functions, such as\nbranch-and-bound, maintain partition trees to systematically prune the domain.\nThe tree size grows exponentially in the number of dimensions. We propose new\nsampling-based methods for non-convex optimization that adapts Monte Carlo Tree\nSearch (MCTS) to improve efficiency. Instead of the standard use of visitation\ncount in Upper Confidence Bounds, we utilize numerical overapproximations of\nthe objective as an uncertainty metric, and also take into account of sampled\nestimates of first-order and second-order information. The Monte Carlo tree in\nour approach avoids the usual fixed combinatorial patterns in growing the tree,\nand aggressively zooms into the promising regions, while still balancing\nexploration and exploitation. We evaluate the proposed algorithms on\nhigh-dimensional non-convex optimization benchmarks against competitive\nbaselines and analyze the effects of the hyper parameters.",
      "tldr_zh": "这篇论文针对非凸优化（Non-Convex Optimization）的全局优化问题，提出了一种新的采样-based 方法Sample-and-Bound，以改进Monte Carlo Tree Search (MCTS)的效率。不同于传统方法如branch-and-bound的指数级树增长，该方法使用数值过近似（numerical overapproximations）作为不确定性指标，并结合一阶和二阶信息的采样估计，实现对有前景区域的针对性探索和利用。实验结果显示，该算法在高维基准测试中优于竞争基线，并对超参数的影响进行了分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at AAAI 2024. Code is available at\n  https://github.com/aaucsd/MCIR",
      "pdf_url": "http://arxiv.org/pdf/2401.04812v3",
      "published_date": "2024-01-09 20:45:47 UTC",
      "updated_date": "2024-02-20 00:18:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:37:56.513896"
    },
    {
      "arxiv_id": "2401.04728v2",
      "title": "Morphable Diffusion: 3D-Consistent Diffusion for Single-image Avatar Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyi Chen",
        "Marko Mihajlovic",
        "Shaofei Wang",
        "Sergey Prokudin",
        "Siyu Tang"
      ],
      "abstract": "Recent advances in generative diffusion models have enabled the previously\nunfeasible capability of generating 3D assets from a single input image or a\ntext prompt. In this work, we aim to enhance the quality and functionality of\nthese models for the task of creating controllable, photorealistic human\navatars. We achieve this by integrating a 3D morphable model into the\nstate-of-the-art multi-view-consistent diffusion approach. We demonstrate that\naccurate conditioning of a generative pipeline on the articulated 3D model\nenhances the baseline model performance on the task of novel view synthesis\nfrom a single image. More importantly, this integration facilitates a seamless\nand accurate incorporation of facial expression and body pose control into the\ngeneration process. To the best of our knowledge, our proposed framework is the\nfirst diffusion model to enable the creation of fully 3D-consistent,\nanimatable, and photorealistic human avatars from a single image of an unseen\nsubject; extensive quantitative and qualitative evaluations demonstrate the\nadvantages of our approach over existing state-of-the-art avatar creation\nmodels on both novel view and novel expression synthesis tasks. The code for\nour project is publicly available.",
      "tldr_zh": "这篇论文提出了Morphable Diffusion框架，通过将3D morphable模型整合到先进的multi-view-consistent diffusion方法中，从单张图像创建可控、光学真实的3D人类头像。 该框架通过准确的条件化提升了基线模型在新视图合成的性能，并首次实现了无缝整合面部表情和身体姿势控制，生成完全3D一致、可动画化的头像。 实验结果显示，该方法在新视图和新表情合成任务上优于现有模型，并在定量和定性评估中证明了其优势，代码已公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "[CVPR 2024] Project page:\n  https://xiyichen.github.io/morphablediffusion/",
      "pdf_url": "http://arxiv.org/pdf/2401.04728v2",
      "published_date": "2024-01-09 18:59:04 UTC",
      "updated_date": "2024-04-02 08:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:38:07.921856"
    },
    {
      "arxiv_id": "2402.03328v2",
      "title": "Visual Enumeration is Challenging for Large-scale Generative AI",
      "title_zh": "视觉枚举对大规模生成式人工智能构成挑战",
      "authors": [
        "Alberto Testolin",
        "Kuinan Hou",
        "Marco Zorzi"
      ],
      "abstract": "Humans can readily judge the number of objects in a visual scene, even\nwithout counting, and such a skill has been documented in many animal species\nand babies prior to language development and formal schooling. Numerical\njudgments are error-free for small sets, while for larger collections responses\nbecome approximate, with variability increasing proportionally to the target\nnumber. This response pattern is observed for items of all kinds, despite\nvariation in object features (such as color or shape), suggesting that our\nvisual number sense relies on abstract representations of numerosity. Here, we\ninvestigate whether large-scale generative Artificial Intelligence (AI) systems\nhave a human-like number sense, which should allow them to reliably name the\nnumber of objects in simple visual stimuli or generate images containing a\ntarget number of items in the 1-10 range. Surprisingly, most of the foundation\nmodels considered have a poor number sense: They make striking errors even with\nsmall numbers, the response variability does not increase in a systematic way,\nand the pattern of errors depends on object category. Only the most recent\nproprietary systems exhibit signatures of a visual number sense. Our findings\ndemonstrate that having an intuitive visual understanding of number remains\nchallenging for foundation models, which in turn might be detrimental to the\nperceptual grounding of numeracy that in humans is crucial for mathematical\nlearning.",
      "tldr_zh": "本论文探讨了大型生成AI模型是否具备人类般的视觉数字感，即准确判断或生成1-10个物体的图像。研究发现，大多数基础模型（foundation models）在处理小数字时出现显著错误，响应变异性不系统化，且错误模式依赖于物体类别，只有最新的专有系统显示出类似人类数字感的迹象。这些结果表明，直观的视觉数字理解（visual number sense）对AI模型而言仍具挑战，可能影响其数字感知的建立，并对数学学习产生负面影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03328v2",
      "published_date": "2024-01-09 18:18:32 UTC",
      "updated_date": "2024-05-03 15:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:38:20.342858"
    },
    {
      "arxiv_id": "2401.04757v1",
      "title": "How predictable is language model benchmark performance?",
      "title_zh": "语言模型基准性能的可预测性如何？",
      "authors": [
        "David Owen"
      ],
      "abstract": "We investigate large language model performance across five orders of\nmagnitude of compute scaling in eleven recent model architectures. We show that\naverage benchmark performance, aggregating over many individual tasks and\nevaluations as in the commonly-used BIG-Bench dataset, is decently predictable\nas a function of training compute scale. Specifically, when extrapolating\nBIG-Bench Hard performance across one order of magnitude in compute, we observe\naverage absolute errors of 6 percentage points (pp). By contrast, extrapolation\nfor individual BIG-Bench tasks across an order of magnitude in compute yields\nhigher average errors of 18pp. Nonetheless, individual task performance remains\nsignificantly more predictable than chance. Overall, our work suggests compute\nscaling provides a promising basis to forecast AI capabilities in diverse\nbenchmarks, though predicting performance in specific tasks poses challenges.",
      "tldr_zh": "本研究调查了大型语言模型在跨越五个数量级的计算规模（compute scaling）下，其基准性能的可预测性，涉及11个模型架构。结果显示，使用BIG-Bench数据集的平均性能作为训练计算规模的函数时，跨一个数量级外推的平均绝对误差为6个百分点，而单个任务的预测误差则高达18个百分点。尽管单个任务性能的预测性仍优于随机猜测，但整体表明计算规模可作为预测AI能力在多样基准中的可靠基础，同时也突出了特定任务预测的挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04757v1",
      "published_date": "2024-01-09 17:34:30 UTC",
      "updated_date": "2024-01-09 17:34:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:38:32.610739"
    },
    {
      "arxiv_id": "2402.01652v1",
      "title": "User-Centric AI Analytics for Chronic Health Conditions Management",
      "title_zh": "用户中心 AI 分析用于慢性健康状况管理",
      "authors": [
        "Aladdin Ayesh"
      ],
      "abstract": "The use of AI analytics in health informatics has seen a rapid growth in\nrecent years. In this talk, we look at AI analytics use in managing chronic\nhealth conditions such as diabetes, obesity, etc. We focus on the challenges in\nmanaging these conditions especially with drug-free approaches due to the\nvariations in individual circumstances. These variations directed the research\ninto user-centric approach leading to variety of research questions. In this\nshort paper, we give examples from recent and current research work and\nconclude with what, in our opinion, to be the next steps and some remaining\nopen research questions.",
      "tldr_zh": "该论文探讨了 User-Centric AI Analytics 在管理慢性健康状况（如糖尿病、肥胖等）中的应用，强调个体差异带来的挑战，特别是无药治疗方法。研究采用用户中心方法来应对这些变异，引发了一系列研究问题，并通过最近的研究例子进行说明。最终，论文总结了未来步骤和一些未解决的开放问题，为该领域的发展提供方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "68T09, 68T99",
        "I.2; I.2.1; J.3"
      ],
      "primary_category": "cs.CY",
      "comment": "Keynote talk at IEEE Conference on Intelligent Methods, Systems, and\n  Applications (IMSA), Cairo, Egypt, July 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.01652v1",
      "published_date": "2024-01-09 17:22:04 UTC",
      "updated_date": "2024-01-09 17:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:38:44.647823"
    },
    {
      "arxiv_id": "2401.04679v7",
      "title": "RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation",
      "title_zh": "RoSA：通过鲁棒适应实现准确的参数高效微调",
      "authors": [
        "Mahdi Nikdan",
        "Soroush Tabesh",
        "Elvir Crnčević",
        "Dan Alistarh"
      ],
      "abstract": "We investigate parameter-efficient fine-tuning (PEFT) methods that can\nprovide good accuracy under limited computational and memory budgets in the\ncontext of large language models (LLMs). We present a new PEFT method called\nRobust Adaptation (RoSA) inspired by robust principal component analysis that\njointly trains $\\textit{low-rank}$ and $\\textit{highly-sparse}$ components on\ntop of a set of fixed pretrained weights to efficiently approximate the\nperformance of a full-fine-tuning (FFT) solution. Across a series of\nchallenging generative tasks such as grade-school math and SQL query\ngeneration, which require fine-tuning for good performance, we show that RoSA\noutperforms LoRA, pure sparse fine-tuning, and alternative hybrid methods at\nthe same parameter budget, and can even recover the performance of FFT on some\ntasks. We provide system support for RoSA to complement the training algorithm,\nspecifically in the form of sparse GPU kernels which enable memory- and\ncomputationally-efficient training, and show that it is also compatible with\nlow-precision base weights, resulting in the first joint representation\ncombining quantization, low-rank and sparse approximations. Our code is\navailable at https://github.com/IST-DASLab/RoSA.",
      "tldr_zh": "本研究探讨了参数高效微调 (PEFT) 方法，以在计算和内存资源有限的情况下提升大型语言模型 (LLMs) 的准确性。作者提出了一种新方法 Robust Adaptation (RoSA)，灵感来源于 robust principal component analysis，通过联合训练 low-rank 和 highly-sparse 组件来高效逼近全微调 (FFT) 的性能。在挑战性生成任务（如小学数学和 SQL 查询生成）上，RoSA 在相同参数预算下优于 LoRA 和其他混合方法，甚至在某些任务上恢复了 FFT 的表现。该方法还提供了稀疏 GPU 内核支持，并兼容低精度基权重，实现量化、低秩和稀疏近似的联合表示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04679v7",
      "published_date": "2024-01-09 17:09:01 UTC",
      "updated_date": "2024-06-03 06:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:38:58.651863"
    },
    {
      "arxiv_id": "2401.04666v1",
      "title": "Benchmark Analysis of Various Pre-trained Deep Learning Models on ASSIRA Cats and Dogs Dataset",
      "title_zh": "各种预训练深度学习模型在 ASSIRA Cats and Dogs Dataset 上的基准分析",
      "authors": [
        "Galib Muhammad Shahriar Himel",
        "Md. Masudul Islam"
      ],
      "abstract": "As the most basic application and implementation of deep learning, image\nclassification has grown in popularity. Various datasets are provided by\nrenowned data science communities for benchmarking machine learning algorithms\nand pre-trained models. The ASSIRA Cats & Dogs dataset is one of them and is\nbeing used in this research for its overall acceptance and benchmark standards.\nA comparison of various pre-trained models is demonstrated by using different\ntypes of optimizers and loss functions. Hyper-parameters are changed to gain\nthe best result from a model. By applying this approach, we have got higher\naccuracy without major changes in the training model. To run the experiment, we\nused three different computer architectures: a laptop equipped with NVIDIA\nGeForce GTX 1070, a laptop equipped with NVIDIA GeForce RTX 3080Ti, and a\ndesktop equipped with NVIDIA GeForce RTX 3090. The acquired results demonstrate\nsupremacy in terms of accuracy over the previously done experiments on this\ndataset. From this experiment, the highest accuracy which is 99.65% is gained\nusing the NASNet Large.",
      "tldr_zh": "本研究对各种预训练深度学习模型在 ASSIRA Cats and Dogs 数据集上的性能进行了基准分析，使用不同的 optimizers 和 loss functions，并通过调整 hyper-parameters 来优化模型表现。实验在配备 NVIDIA GeForce GTX 1070、RTX 3080Ti 和 RTX 3090 的硬件上进行，结果显示这种方法比先前实验取得了更高的准确率，其中 NASNet Large 模型达到了最高的99.65%准确率。该工作为图像分类任务提供了有效的模型比较和优化策略，提升了深度学习应用的基准标准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04666v1",
      "published_date": "2024-01-09 16:48:11 UTC",
      "updated_date": "2024-01-09 16:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:39:08.968375"
    },
    {
      "arxiv_id": "2401.04658v2",
      "title": "Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Qin",
        "Weigao Sun",
        "Dong Li",
        "Xuyang Shen",
        "Weixuan Sun",
        "Yiran Zhong"
      ],
      "abstract": "Linear attention is an efficient attention mechanism that has recently\nemerged as a promising alternative to conventional softmax attention. With its\nability to process tokens in linear computational complexities, linear\nattention, in theory, can handle sequences of unlimited length without\nsacrificing speed, i.e., maintaining a constant training speed for various\nsequence lengths with a fixed memory consumption. However, due to the issue\nwith cumulative summation (cumsum), current linear attention algorithms cannot\ndemonstrate their theoretical advantage in a causal setting. In this paper, we\npresent Lightning Attention-2, the first linear attention implementation that\nenables linear attention to realize its theoretical computational benefits. To\nachieve this, we leverage the thought of tiling, separately handling the\nintra-block and inter-block components in linear attention calculation.\nSpecifically, we utilize the conventional attention computation mechanism for\nthe intra-blocks and apply linear attention kernel tricks for the inter-blocks.\nA tiling technique is adopted through both forward and backward procedures to\ntake full advantage of the GPU hardware. We implement our algorithm in Triton\nto make it IO-aware and hardware-friendly. Various experiments are conducted on\ndifferent model sizes and sequence lengths. Lightning Attention-2 retains\nconsistent training and inference speed regardless of input sequence length and\nis significantly faster than other attention mechanisms. The source code is\navailable at https://github.com/OpenNLPLab/lightning-attention.",
      "tldr_zh": "这篇论文介绍了 Lightning Attention-2，一种高效的 Linear Attention 机制，旨在解决现有算法在 causal setting 下因 cumulative summation (cumsum) 问题而无法实现处理无限序列长度的理论优势。方法采用 tiling 技术，分别处理 intra-block 和 inter-block 组件：使用常规 attention 计算 intra-block，并应用 Linear Attention kernel tricks 处理 inter-block，同时在 forward 和 backward 过程中优化 GPU 硬件利用。实验结果显示，Lightning Attention-2 在不同模型大小和序列长度下保持一致的训练和推理速度，并显著快于其他 attention 机制，为大型语言模型处理长序列提供了高效解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report. Yiran Zhong is the corresponding author. The source\n  code is available at https://github.com/OpenNLPLab/lightning-attention",
      "pdf_url": "http://arxiv.org/pdf/2401.04658v2",
      "published_date": "2024-01-09 16:27:28 UTC",
      "updated_date": "2024-01-15 14:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:39:22.071821"
    },
    {
      "arxiv_id": "2401.04648v1",
      "title": "A novel framework for generalization of deep hidden physics models",
      "title_zh": "翻译失败",
      "authors": [
        "Vijay Kag",
        "Birupaksha Pal"
      ],
      "abstract": "Modelling of systems where the full system information is unknown is an oft\nencountered problem for various engineering and industrial applications, as\nit's either impossible to consider all the complex physics involved or simpler\nmodels are considered to keep within the limits of the available resources.\nRecent advances in greybox modelling like the deep hidden physics models\naddress this space by combining data and physics. However, for most real-life\napplications, model generalizability is a key issue, as retraining a model for\nevery small change in system inputs and parameters or modification in domain\nconfiguration can render the model economically unviable. In this work we\npresent a novel enhancement to the idea of hidden physics models which can\ngeneralize for changes in system inputs, parameters and domains. We also show\nthat this approach holds promise in system discovery as well and helps learn\nthe hidden physics for the changed system inputs, parameters and domain\nconfiguration.",
      "tldr_zh": "本研究针对工程和工业应用中建模未知系统信息的问题，提出了一种新框架来增强 deep hidden physics models 的泛化能力。该框架通过结合数据和物理建模，避免了因系统输入、参数或域配置变化而需要重新训练模型，从而提高了模型的经济可行性。实验结果表明，这种方法不仅能有效适应这些变化，还在系统发现方面表现出潜力，能够学习隐藏物理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04648v1",
      "published_date": "2024-01-09 16:16:32 UTC",
      "updated_date": "2024-01-09 16:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:39:34.159865"
    },
    {
      "arxiv_id": "2401.04647v2",
      "title": "Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Tanmay Garg",
        "Deepika Vemuri",
        "Vineeth N Balasubramanian"
      ],
      "abstract": "This paper presents a novel concept learning framework for enhancing model\ninterpretability and performance in visual classification tasks. Our approach\nappends an unsupervised explanation generator to the primary classifier network\nand makes use of adversarial training. During training, the explanation module\nis optimized to extract visual concepts from the classifier's latent\nrepresentations, while the GAN-based module aims to discriminate images\ngenerated from concepts, from true images. This joint training scheme enables\nthe model to implicitly align its internally learned concepts with\nhuman-interpretable visual properties. Comprehensive experiments demonstrate\nthe robustness of our approach, while producing coherent concept activations.\nWe analyse the learned concepts, showing their semantic concordance with object\nparts and visual attributes. We also study how perturbations in the adversarial\ntraining protocol impact both classification and concept acquisition. In\nsummary, this work presents a significant step towards building inherently\ninterpretable deep vision models with task-aligned concept representations - a\nkey enabler for developing trustworthy AI for real-world perception tasks.",
      "tldr_zh": "这篇论文提出了一种新颖的概念学习框架，通过 Generative Adversarial Networks (GAN) 提升视觉分类任务中的模型可解释性和性能。该框架在主分类器网络上附加一个无监督解释生成器，并采用对抗训练优化解释模块，以从分类器的潜在表示中提取视觉概念，同时GAN模块区分概念生成的图像与真实图像。联合训练使模型隐式地将内部概念与人类可解释的视觉属性对齐，实验结果证明了方法的鲁棒性，并展示了学习到的概念与物体部分和视觉属性的语义一致性。总体而言，此工作为构建固有可解释的深度视觉模型提供了关键进展，促进了可信赖AI在真实感知任务中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https://hcrl-workshop.github.io/2024/). Paper accepted and\n  presented at Deployable AI Workshop at AAAI-2024\n  (https://sites.google.com/view/dai-2024/home)",
      "pdf_url": "http://arxiv.org/pdf/2401.04647v2",
      "published_date": "2024-01-09 16:16:16 UTC",
      "updated_date": "2024-04-03 09:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:39:46.571722"
    },
    {
      "arxiv_id": "2401.04637v1",
      "title": "Applying Large Language Models API to Issue Classification Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Aracena",
        "Kyle Luster",
        "Fabio Santos",
        "Igor Steinmacher",
        "Marco A. Gerosa"
      ],
      "abstract": "Effective prioritization of issue reports is crucial in software engineering\nto optimize resource allocation and address critical problems promptly.\nHowever, the manual classification of issue reports for prioritization is\nlaborious and lacks scalability. Alternatively, many open source software (OSS)\nprojects employ automated processes for this task, albeit relying on\nsubstantial datasets for adequate training. This research seeks to devise an\nautomated approach that ensures reliability in issue prioritization, even when\ntrained on smaller datasets. Our proposed methodology harnesses the power of\nGenerative Pre-trained Transformers (GPT), recognizing their potential to\nefficiently handle this task. By leveraging the capabilities of such models, we\naim to develop a robust system for prioritizing issue reports accurately,\nmitigating the necessity for extensive training data while maintaining\nreliability. In our research, we have developed a reliable GPT-based approach\nto accurately label and prioritize issue reports with a reduced training\ndataset. By reducing reliance on massive data requirements and focusing on\nfew-shot fine-tuning, our methodology offers a more accessible and efficient\nsolution for issue prioritization in software engineering. Our model predicted\nissue types in individual projects up to 93.2% in precision, 95% in recall, and\n89.3% in F1-score.",
      "tldr_zh": "本研究针对软件工程中问题报告的优先级排序问题，提出了一种基于 Large Language Models API 的自动化方法，利用 GPT 模型来实现高效分类和优先级处理。\n该方法通过 few-shot fine-tuning 技术，减少了对大规模数据集的依赖，即使在较小数据集上也能可靠地标记问题类型。\n实验结果显示，模型在单个项目中的 precision 达到 93.2%，recall 95%，F1-score 89.3%，为软件项目优化资源分配提供了可扩展的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages, 1 figure, NLBSE and ICSE conference submission, ACM\n  formatted, pre print",
      "pdf_url": "http://arxiv.org/pdf/2401.04637v1",
      "published_date": "2024-01-09 16:05:47 UTC",
      "updated_date": "2024-01-09 16:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:39:57.814006"
    },
    {
      "arxiv_id": "2401.04631v1",
      "title": "Deep Reinforcement Multi-agent Learning framework for Information Gathering with Local Gaussian Processes for Water Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Yanes Luis",
        "Dmitriy Shutin",
        "Juan Marchal Gómez",
        "Daniel Gutiérrez Reina",
        "Sergio Toral Marín"
      ],
      "abstract": "The conservation of hydrological resources involves continuously monitoring\ntheir contamination. A multi-agent system composed of autonomous surface\nvehicles is proposed in this paper to efficiently monitor the water quality. To\nachieve a safe control of the fleet, the fleet policy should be able to act\nbased on measurements and to the the fleet state. It is proposed to use Local\nGaussian Processes and Deep Reinforcement Learning to jointly obtain effective\nmonitoring policies. Local Gaussian processes, unlike classical global Gaussian\nprocesses, can accurately model the information in a dissimilar spatial\ncorrelation which captures more accurately the water quality information. A\nDeep convolutional policy is proposed, that bases the decisions on the\nobservation on the mean and variance of this model, by means of an information\ngain reward. Using a Double Deep Q-Learning algorithm, agents are trained to\nminimize the estimation error in a safe manner thanks to a Consensus-based\nheuristic. Simulation results indicate an improvement of up to 24% in terms of\nthe mean absolute error with the proposed models. Also, training results with\n1-3 agents indicate that our proposed approach returns 20% and 24% smaller\naverage estimation errors for, respectively, monitoring water quality variables\nand monitoring algae blooms, as compared to state-of-the-art approaches",
      "tldr_zh": "本论文提出了一种基于深度强化学习的多智能体框架，用于水监测的信息收集，结合 Local Gaussian Processes 来建模水质的空间相关性，以提高监测效率和准确性。该框架使用 Local Gaussian Processes 替代传统的全局 Gaussian Processes，更精确地捕捉不均匀的空间信息，并通过 Deep convolutional policy 和信息增益奖励来制定代理决策，同时采用 Double Deep Q-Learning 算法及 Consensus-based heuristic 确保安全训练。实验结果显示，与现有方法相比，该框架在模拟环境中将平均绝对错误降低了24%，并在1-3个代理的场景中，对水质变量和藻华监测的平均估计错误分别减少了20%和24%。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04631v1",
      "published_date": "2024-01-09 15:58:15 UTC",
      "updated_date": "2024-01-09 15:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:40:09.749722"
    },
    {
      "arxiv_id": "2401.04621v3",
      "title": "DebugBench: Evaluating Debugging Capability of Large Language Models",
      "title_zh": "DebugBench：评估大型语言模型的调试能力",
      "authors": [
        "Runchu Tian",
        "Yining Ye",
        "Yujia Qin",
        "Xin Cong",
        "Yankai Lin",
        "Yinxu Pan",
        "Yesai Wu",
        "Haotian Hui",
        "Weichuan Liu",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional coding capability.\nHowever, as another critical component of programming proficiency, the\ndebugging capability of LLMs remains relatively unexplored. Previous\nevaluations of LLMs' debugging ability are significantly limited by the risk of\ndata leakage, the scale of the dataset, and the variety of tested bugs. To\novercome these deficiencies, we introduce `DebugBench', an LLM debugging\nbenchmark consisting of 4,253 instances. It covers four major bug categories\nand 18 minor types in C++, Java, and Python. To construct DebugBench, we\ncollect code snippets from the LeetCode community, implant bugs into source\ndata with GPT-4, and assure rigorous quality checks. We evaluate two commercial\nand four open-source models in a zero-shot scenario. We find that (1) while\nclosed-source models exhibit inferior debugging performance compared to humans,\nopen-source models relatively lower pass rate scores; (2) the complexity of\ndebugging notably fluctuates depending on the bug category; (3) incorporating\nruntime feedback has a clear impact on debugging performance which is not\nalways helpful. As an extension, we also compare LLM debugging and code\ngeneration, revealing a strong correlation between them for closed-source\nmodels. These findings will benefit the development of LLMs in debugging.",
      "tldr_zh": "该研究引入了 DebugBench，这是一个包含 4,253 个实例的基准数据集，用于评估大型语言模型 (LLMs) 的调试能力，覆盖 C++、Java 和 Python 的四个主要错误类别和 18 个次要类型。研究团队通过从 LeetCode 社区收集代码片段、利用 GPT-4 植入错误并进行严格质量检查，克服了以往评估中的数据泄露风险和数据集规模问题。在零样本 (zero-shot) 场景下评估两款闭源模型和四款开源模型，结果显示闭源模型的调试性能虽优于开源模型但仍逊于人类，且调试复杂性因错误类别而异。进一步比较发现，加入运行时反馈对性能的影响不一，且 LLMs 的调试能力与代码生成能力在闭源模型中高度相关，这些发现有助于提升 LLMs 在调试方面的开发。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted as Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04621v3",
      "published_date": "2024-01-09 15:46:38 UTC",
      "updated_date": "2024-06-06 06:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:40:24.580896"
    },
    {
      "arxiv_id": "2401.04620v4",
      "title": "Agent Alignment in Evolving Social Norms",
      "title_zh": "翻译失败",
      "authors": [
        "Shimin Li",
        "Tianxiang Sun",
        "Qinyuan Cheng",
        "Xipeng Qiu"
      ],
      "abstract": "Agents based on Large Language Models (LLMs) are increasingly permeating\nvarious domains of human production and life, highlighting the importance of\naligning them with human values. The current alignment of AI systems primarily\nfocuses on passively aligning LLMs through human intervention. However, agents\npossess characteristics like receiving environmental feedback and\nself-evolution, rendering the LLM alignment methods inadequate. In response, we\npropose an evolutionary framework for agent evolution and alignment, named\nEvolutionaryAgent, which transforms agent alignment into a process of evolution\nand selection under the principle of survival of the fittest. In an environment\nwhere social norms continuously evolve, agents better adapted to the current\nsocial norms will have a higher probability of survival and proliferation,\nwhile those inadequately aligned dwindle over time. Experimental results\nassessing the agents from multiple perspectives in aligning with social norms\ndemonstrate that EvolutionaryAgent can align progressively better with the\nevolving social norms while maintaining its proficiency in general tasks.\nEffectiveness tests conducted on various open and closed-source LLMs as the\nfoundation for agents also prove the applicability of our approach.",
      "tldr_zh": "该论文探讨了基于Large Language Models (LLMs)的agents在动态演变的社会规范下与人类价值观对齐的重要性，指出现有被动对齐方法因agents的自我进化特性而不足。作者提出EvolutionaryAgent框架，将对齐过程转化为进化与选择的机制，遵循适者生存原则，让agents在不断变化的环境中通过反馈适应社会规范。实验结果显示，该框架能使agents逐步提升对社会规范的对齐度，同时维持在一般任务上的性能，并在多种开源和闭源LLMs上证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.04620v4",
      "published_date": "2024-01-09 15:44:44 UTC",
      "updated_date": "2024-02-20 03:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:40:33.693044"
    },
    {
      "arxiv_id": "2401.10274v1",
      "title": "Knowledge-Assisted Dual-Stage Evolutionary Optimization of Large-Scale Crude Oil Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Wanting Zhang",
        "Wei Du",
        "Guo Yu",
        "Renchu He",
        "Wenli Du",
        "Yaochu Jin"
      ],
      "abstract": "With the scaling up of crude oil scheduling in modern refineries, large-scale\ncrude oil scheduling problems (LSCOSPs) emerge with thousands of binary\nvariables and non-linear constraints, which are challenging to be optimized by\ntraditional optimization methods. To solve LSCOSPs, we take the practical crude\noil scheduling from a marine-access refinery as an example and start with\nmodeling LSCOSPs from crude unloading, transportation, crude distillation unit\nprocessing, and inventory management of intermediate products. On the basis of\nthe proposed model, a dual-stage evolutionary algorithm driven by heuristic\nrules (denoted by DSEA/HR) is developed, where the dual-stage search mechanism\nconsists of global search and local refinement. In the global search stage, we\ndevise several heuristic rules based on the empirical operating knowledge to\ngenerate a well-performing initial population and accelerate convergence in the\nmixed variables space. In the local refinement stage, a repair strategy is\nproposed to move the infeasible solutions towards feasible regions by further\noptimizing the local continuous variables. During the whole evolutionary\nprocess, the proposed dual-stage framework plays a crucial role in balancing\nexploration and exploitation. Experimental results have shown that DSEA/HR\noutperforms the state-of-the-art and widely-used mathematical programming\nmethods and metaheuristic algorithms on LSCOSP instances within a reasonable\ntime.",
      "tldr_zh": "本研究针对大型原油调度问题（LSCOSPs），该问题涉及数千个二进制变量和非线性约束，传统优化方法难以处理。通过以海洋接入炼油厂为例，建立了从原油卸载、运输、原油蒸馏单元处理到中间产品库存管理的数学模型。基于此，提出了一种知识辅助的双阶段进化算法（DSEA/HR），其中全局搜索阶段利用启发式规则生成高质量初始种群并加速收敛，局部精炼阶段则通过修复策略优化连续变量以平衡探索和利用。实验结果表明，DSEA/HR 在合理时间内优于现有数学规划方法和元启发式算法，在 LSCOSP 实例上表现出显著性能提升。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.10274v1",
      "published_date": "2024-01-09 15:26:44 UTC",
      "updated_date": "2024-01-09 15:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:40:47.408835"
    },
    {
      "arxiv_id": "2401.10910v2",
      "title": "Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Toy",
        "Josh MacAdam",
        "Phil Tabor"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have shown impressive\ncapabilities in various applications, yet LLMs face challenges such as limited\ncontext windows and difficulties in generalization. In this paper, we introduce\na metacognition module for generative agents, enabling them to observe their\nown thought processes and actions. This metacognitive approach, designed to\nemulate System 1 and System 2 cognitive processes, allows agents to\nsignificantly enhance their performance by modifying their strategy. We tested\nthe metacognition module on a variety of scenarios, including a situation where\ngenerative agents must survive a zombie apocalypse, and observe that our system\noutperform others, while agents adapt and improve their strategies to complete\ntasks over time.",
      "tldr_zh": "本论文探讨了如何通过引入元认知（metacognition）模块来提升生成代理（generative agents）的目标导向行为，解决Large Language Models (LLMs) 面临的上下文窗口限制和泛化难题。\n该模块让代理能够观察自身思考过程和行动，模仿System 1和System 2认知过程，从而动态修改策略以优化表现。\n在多种测试场景中，包括僵尸末日生存任务，该系统表现出色，代理能够适应环境并逐步改进策略，超越其他基线系统。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.10910v2",
      "published_date": "2024-01-09 15:00:47 UTC",
      "updated_date": "2024-02-29 21:05:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:40:58.612239"
    },
    {
      "arxiv_id": "2402.01651v1",
      "title": "Informed AI Regulation: Comparing the Ethical Frameworks of Leading LLM Chatbots Using an Ethics-Based Audit to Assess Moral Reasoning and Normative Values",
      "title_zh": "翻译失败",
      "authors": [
        "Jon Chun",
        "Katherine Elkins"
      ],
      "abstract": "With the rise of individual and collaborative networks of autonomous agents,\nAI is deployed in more key reasoning and decision-making roles. For this\nreason, ethics-based audits play a pivotal role in the rapidly growing fields\nof AI safety and regulation. This paper undertakes an ethics-based audit to\nprobe the 8 leading commercial and open-source Large Language Models including\nGPT-4. We assess explicability and trustworthiness by a) establishing how well\ndifferent models engage in moral reasoning and b) comparing normative values\nunderlying models as ethical frameworks. We employ an experimental,\nevidence-based approach that challenges the models with ethical dilemmas in\norder to probe human-AI alignment. The ethical scenarios are designed to\nrequire a decision in which the particulars of the situation may or may not\nnecessitate deviating from normative ethical principles. A sophisticated\nethical framework was consistently elicited in one model, GPT-4. Nonetheless,\ntroubling findings include underlying normative frameworks with clear bias\ntowards particular cultural norms. Many models also exhibit disturbing\nauthoritarian tendencies. Code is available at\nhttps://github.com/jonchun/llm-sota-chatbots-ethics-based-audit.",
      "tldr_zh": "这篇论文通过ethics-based audit评估了8个领先的商业和开源LLM（包括GPT-4）的道德推理和normative values，以探讨AI在推理决策中的ethical frameworks。研究采用实验方法，使用ethical dilemmas测试模型的moral reasoning和human-AI alignment，检查情境是否需要偏离规范伦理原则。结果显示，GPT-4表现出一致的sophisticated ethical framework，但许多模型存在文化偏见和authoritarian tendencies，这为AI安全与regulation提供了重要洞见。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68T27, 68T30, 68T37, 91F20, 93B52",
        "I.2.7; K.4.1; I.2.11; I.2.0; K.6.5"
      ],
      "primary_category": "cs.CY",
      "comment": "23 pages, 6 figures (3 as tables), 1 table (in LaTeX)",
      "pdf_url": "http://arxiv.org/pdf/2402.01651v1",
      "published_date": "2024-01-09 14:57:30 UTC",
      "updated_date": "2024-01-09 14:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:41:10.518941"
    },
    {
      "arxiv_id": "2401.04579v2",
      "title": "A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wei",
        "Yuqian Chen",
        "Tengfei Xue",
        "Leo Zekelman",
        "Nikos Makris",
        "Yogesh Rathi",
        "Weidong Cai",
        "Fan Zhang",
        "Lauren J. O' Donnell"
      ],
      "abstract": "Large datasets often contain multiple distinct feature sets, or views, that\noffer complementary information that can be exploited by multi-view learning\nmethods to improve results. We investigate anatomical multi-view data, where\neach brain anatomical structure is described with multiple feature sets. In\nparticular, we focus on sets of white matter microstructure and connectivity\nfeatures from diffusion MRI, as well as sets of gray matter area and thickness\nfeatures from structural MRI. We investigate machine learning methodology that\napplies multi-view approaches to improve the prediction of non-imaging\nphenotypes, including demographics (age), motor (strength), and cognition\n(picture vocabulary). We present an explainable multi-view network (EMV-Net)\nthat can use different anatomical views to improve prediction performance. In\nthis network, each individual anatomical view is processed by a view-specific\nfeature extractor and the extracted information from each view is fused using a\nlearnable weight. This is followed by a wavelet transform-based module to\nobtain complementary information across views which is then applied to\ncalibrate the view-specific information. Additionally, the calibrator produces\nan attention-based calibration score to indicate anatomical structures'\nimportance for interpretation.",
      "tldr_zh": "这篇论文提出了一种可解释的多视图网络（EMV-Net），用于利用脑部解剖多视图数据（如扩散MRI的白质微结构和连接特征，以及结构MRI的灰质面积和厚度特征）来预测非成像表型，包括年龄、运动能力和认知。EMV-Net 通过视图特定特征提取器处理每个解剖视图，并使用可学习的权重融合提取信息。接着，引入基于小波变换的模块获取跨视图互补信息，并通过注意力机制校准视图数据，以突出解剖结构的importance。该方法提高了预测性能，并增强了模型的可解释性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "2023 The Medical Image Computing and Computer Assisted Intervention\n  Society workshop",
      "pdf_url": "http://arxiv.org/pdf/2401.04579v2",
      "published_date": "2024-01-09 14:33:01 UTC",
      "updated_date": "2024-01-13 14:48:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:41:24.667674"
    },
    {
      "arxiv_id": "2401.04577v2",
      "title": "Masked Audio Generation using a Single Non-Autoregressive Transformer",
      "title_zh": "基于单一非自回归 Transformer 的掩码音频生成",
      "authors": [
        "Alon Ziv",
        "Itai Gat",
        "Gael Le Lan",
        "Tal Remez",
        "Felix Kreuk",
        "Alexandre Défossez",
        "Jade Copet",
        "Gabriel Synnaeve",
        "Yossi Adi"
      ],
      "abstract": "We introduce MAGNeT, a masked generative sequence modeling method that\noperates directly over several streams of audio tokens. Unlike prior work,\nMAGNeT is comprised of a single-stage, non-autoregressive transformer. During\ntraining, we predict spans of masked tokens obtained from a masking scheduler,\nwhile during inference we gradually construct the output sequence using several\ndecoding steps. To further enhance the quality of the generated audio, we\nintroduce a novel rescoring method in which, we leverage an external\npre-trained model to rescore and rank predictions from MAGNeT, which will be\nthen used for later decoding steps. Lastly, we explore a hybrid version of\nMAGNeT, in which we fuse between autoregressive and non-autoregressive models\nto generate the first few seconds in an autoregressive manner while the rest of\nthe sequence is being decoded in parallel. We demonstrate the efficiency of\nMAGNeT for the task of text-to-music and text-to-audio generation and conduct\nan extensive empirical evaluation, considering both objective metrics and human\nstudies. The proposed approach is comparable to the evaluated baselines, while\nbeing significantly faster (x7 faster than the autoregressive baseline).\nThrough ablation studies and analysis, we shed light on the importance of each\nof the components comprising MAGNeT, together with pointing to the trade-offs\nbetween autoregressive and non-autoregressive modeling, considering latency,\nthroughput, and generation quality. Samples are available on our demo page\nhttps://pages.cs.huji.ac.il/adiyoss-lab/MAGNeT.",
      "tldr_zh": "本研究提出了 MAGNeT，一种基于单阶段非自回归 Transformer 的掩码生成序列建模方法，用于直接处理音频标记流，以提高文本到音乐和文本到音频生成的效率。训练时，通过掩码调度器预测被掩盖标记的跨度，而推理时逐步构建输出序列；此外，引入了新型重评分机制，利用外部预训练模型对预测进行排序，以提升生成质量。研究还探索了混合版本，将自回归和非自回归模式结合，用于生成序列的前后部分。实验结果显示，MAGNeT 在生成质量上与基线模型相当，但速度提升显著（比自回归基线快7倍），并通过消融研究分析了各组件的重要性及建模间的权衡。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04577v2",
      "published_date": "2024-01-09 14:29:39 UTC",
      "updated_date": "2024-03-05 09:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:41:37.024812"
    },
    {
      "arxiv_id": "2401.04575v2",
      "title": "Let's Go Shopping (LGS) -- Web-Scale Image-Text Dataset for Visual Concept Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yatong Bai",
        "Utsav Garg",
        "Apaar Shanker",
        "Haoming Zhang",
        "Samyak Parajuli",
        "Erhan Bas",
        "Isidora Filipovic",
        "Amelia N. Chu",
        "Eugenia D Fomitcheva",
        "Elliot Branson",
        "Aerin Kim",
        "Somayeh Sojoudi",
        "Kyunghyun Cho"
      ],
      "abstract": "Vision and vision-language applications of neural networks, such as image\nclassification and captioning, rely on large-scale annotated datasets that\nrequire non-trivial data-collecting processes. This time-consuming endeavor\nhinders the emergence of large-scale datasets, limiting researchers and\npractitioners to a small number of choices. Therefore, we seek more efficient\nways to collect and annotate images. Previous initiatives have gathered\ncaptions from HTML alt-texts and crawled social media postings, but these data\nsources suffer from noise, sparsity, or subjectivity. For this reason, we turn\nto commercial shopping websites whose data meet three criteria: cleanliness,\ninformativeness, and fluency. We introduce the Let's Go Shopping (LGS) dataset,\na large-scale public dataset with 15 million image-caption pairs from publicly\navailable e-commerce websites. When compared with existing general-domain\ndatasets, the LGS images focus on the foreground object and have less complex\nbackgrounds. Our experiments on LGS show that the classifiers trained on\nexisting benchmark datasets do not readily generalize to e-commerce data, while\nspecific self-supervised visual feature extractors can better generalize.\nFurthermore, LGS's high-quality e-commerce-focused images and bimodal nature\nmake it advantageous for vision-language bi-modal tasks: LGS enables\nimage-captioning models to generate richer captions and helps text-to-image\ngeneration models achieve e-commerce style transfer.",
      "tldr_zh": "本研究引入了LGS（Let's Go Shopping）数据集，这是一个大规模的Web-Scale图像-文本数据集，包含1500万对图像和标题，从公开的电商网站收集，确保数据具有cleanliness（干净性）、informativeness（信息丰富性）和fluency（流畅性）。与现有通用数据集相比，LGS图像更注重前景对象且背景较简单，有助于提升视觉概念理解。实验结果显示，基于现有基准数据集的分类器难以泛化到电商数据，而特定self-supervised visual feature extractors能更好地适应；此外，LGS在视觉-语言双模态任务中表现出色，能帮助图像描述模型生成更丰富的标题，并支持文本到图像生成模型实现电商风格转移。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04575v2",
      "published_date": "2024-01-09 14:24:29 UTC",
      "updated_date": "2024-03-05 21:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:41:46.474716"
    },
    {
      "arxiv_id": "2401.04536v2",
      "title": "Evaluating Language Model Agency through Negotiations",
      "title_zh": "翻译失败",
      "authors": [
        "Tim R. Davidson",
        "Veniamin Veselovsky",
        "Martin Josifoski",
        "Maxime Peyrard",
        "Antoine Bosselut",
        "Michal Kosinski",
        "Robert West"
      ],
      "abstract": "We introduce an approach to evaluate language model (LM) agency using\nnegotiation games. This approach better reflects real-world use cases and\naddresses some of the shortcomings of alternative LM benchmarks. Negotiation\ngames enable us to study multi-turn, and cross-model interactions, modulate\ncomplexity, and side-step accidental evaluation data leakage. We use our\napproach to test six widely used and publicly accessible LMs, evaluating\nperformance and alignment in both self-play and cross-play settings. Noteworthy\nfindings include: (i) only closed-source models tested here were able to\ncomplete these tasks; (ii) cooperative bargaining games proved to be most\nchallenging to the models; and (iii) even the most powerful models sometimes\n\"lose\" to weaker opponents",
      "tldr_zh": "该研究提出了一种通过谈判游戏评估语言模型（LM）代理性的方法，该方法更贴近真实世界应用，能够处理多轮交互、跨模型互动、复杂性调节，并避免评估数据泄露。研究者测试了六个广泛使用的公开可访问LM，在自对弈和跨对弈设置中评估了它们的性能和对齐情况。关键发现包括：只有封闭源模型能够完成这些任务；合作讨价还价游戏是最具挑战性的；即使是最强大的模型有时也会输给较弱的对手。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2024, code and link to project data are made\n  available at https://github.com/epfl-dlab/LAMEN",
      "pdf_url": "http://arxiv.org/pdf/2401.04536v2",
      "published_date": "2024-01-09 13:19:37 UTC",
      "updated_date": "2024-03-16 16:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:41:58.187877"
    },
    {
      "arxiv_id": "2401.04531v3",
      "title": "MERA: A Comprehensive LLM Evaluation in Russian",
      "title_zh": "MERA：俄语的大型语言模型全面评估",
      "authors": [
        "Alena Fenogenova",
        "Artem Chervyakov",
        "Nikita Martynov",
        "Anastasia Kozlova",
        "Maria Tikhonova",
        "Albina Akhmetgareeva",
        "Anton Emelyanov",
        "Denis Shevelev",
        "Pavel Lebedev",
        "Leonid Sinev",
        "Ulyana Isaeva",
        "Katerina Kolomeytseva",
        "Daniil Moskovskiy",
        "Elizaveta Goncharova",
        "Nikita Savushkin",
        "Polina Mikhailova",
        "Denis Dimitrov",
        "Alexander Panchenko",
        "Sergei Markov"
      ],
      "abstract": "Over the past few years, one of the most notable advancements in AI research\nhas been in foundation models (FMs), headlined by the rise of language models\n(LMs). As the models' size increases, LMs demonstrate enhancements in\nmeasurable aspects and the development of new qualitative features. However,\ndespite researchers' attention and the rapid growth in LM application, the\ncapabilities, limitations, and associated risks still need to be better\nunderstood. To address these issues, we introduce an open Multimodal Evaluation\nof Russian-language Architectures (MERA), a new instruction benchmark for\nevaluating foundation models oriented towards the Russian language. The\nbenchmark encompasses 21 evaluation tasks for generative models in 11 skill\ndomains and is designed as a black-box test to ensure the exclusion of data\nleakage. The paper introduces a methodology to evaluate FMs and LMs in zero-\nand few-shot fixed instruction settings that can be extended to other\nmodalities. We propose an evaluation methodology, an open-source code base for\nthe MERA assessment, and a leaderboard with a submission system. We evaluate\nopen LMs as baselines and find that they are still far behind the human level.\nWe publicly release MERA to guide forthcoming research, anticipate\ngroundbreaking model features, standardize the evaluation procedure, and\naddress potential societal drawbacks.",
      "tldr_zh": "本论文引入了 MERA，这是一个针对俄语的开放式多模态评估基准，用于全面评估基础模型 (FMs) 和语言模型 (LMs)，以更好地理解它们的性能、局限性和潜在风险。MERA 涵盖 21 个评估任务和 11 个技能领域，采用黑盒测试方法并支持零样本和少样本固定指令设置，以防止数据泄露并提供可扩展的评估框架。实验结果显示，开源 LMs 作为基线模型，其表现远低于人类水平；论文公开了开源代码、排行榜和提交系统，以指导未来研究、标准化评估流程并缓解社会负面影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper version comparable with the release code v.1.1.0 of the\n  benchmark MERA. ACL-2024 main track camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2401.04531v3",
      "published_date": "2024-01-09 12:55:21 UTC",
      "updated_date": "2024-08-02 13:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:42:12.188909"
    },
    {
      "arxiv_id": "2401.04749v1",
      "title": "LogFormer: A Pre-train and Tuning Pipeline for Log Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hongcheng Guo",
        "Jian Yang",
        "Jiaheng Liu",
        "Jiaqi Bai",
        "Boyang Wang",
        "Zhoujun Li",
        "Tieqiao Zheng",
        "Bo Zhang",
        "Junran peng",
        "Qi Tian"
      ],
      "abstract": "Log anomaly detection is a key component in the field of artificial\nintelligence for IT operations (AIOps). Considering log data of variant\ndomains, retraining the whole network for unknown domains is inefficient in\nreal industrial scenarios. However, previous deep models merely focused on\nextracting the semantics of log sequences in the same domain, leading to poor\ngeneralization on multi-domain logs. To alleviate this issue, we propose a\nunified Transformer-based framework for Log anomaly detection (LogFormer) to\nimprove the generalization ability across different domains, where we establish\na two-stage process including the pre-training and adapter-based tuning stage.\nSpecifically, our model is first pre-trained on the source domain to obtain\nshared semantic knowledge of log data. Then, we transfer such knowledge to the\ntarget domain via shared parameters. Besides, the Log-Attention module is\nproposed to supplement the information ignored by the log-paring. The proposed\nmethod is evaluated on three public and one real-world datasets. Experimental\nresults on multiple benchmarks demonstrate the effectiveness of our LogFormer\nwith fewer trainable parameters and lower training costs.",
      "tldr_zh": "本论文针对日志异常检测在多领域场景下的泛化能力不足问题，提出了一种基于 Transformer 的统一框架 LogFormer，以减少重新训练的需求。该框架采用两阶段过程：首先在源领域进行预训练以获取共享语义知识，然后通过适配器-based tuning 将知识转移到目标领域，同时引入 Log-Attention 模块来补充日志配对中忽略的信息。在三个公共数据集和一个真实世界数据集上的实验结果表明，LogFormer 比传统模型更有效，具有更少的训练参数和更低的训练成本。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2201.00016",
      "pdf_url": "http://arxiv.org/pdf/2401.04749v1",
      "published_date": "2024-01-09 12:55:21 UTC",
      "updated_date": "2024-01-09 12:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:42:23.728011"
    },
    {
      "arxiv_id": "2401.04518v2",
      "title": "The Critique of Critique",
      "title_zh": "批判的批判",
      "authors": [
        "Shichao Sun",
        "Junlong Li",
        "Weizhe Yuan",
        "Ruifeng Yuan",
        "Wenjie Li",
        "Pengfei Liu"
      ],
      "abstract": "Critique, as a natural language description for assessing the quality of\nmodel-generated content, has played a vital role in the training, evaluation,\nand refinement of LLMs. However, a systematic method to evaluate the quality of\ncritique is lacking. In this paper, we pioneer the critique of critique, termed\nMetaCritique, which builds specific quantification criteria. To achieve a\nreliable evaluation outcome, we propose Atomic Information Units (AIUs), which\ndescribe the critique in a more fine-grained manner. MetaCritique aggregates\neach AIU's judgment for the overall score. Moreover, MetaCritique delivers a\nnatural language rationale for the intricate reasoning within each judgment.\nLastly, we construct a meta-evaluation dataset covering 4 tasks across 16\npublic datasets involving human-written and LLM-generated critiques.\nExperiments demonstrate that MetaCritique can achieve near-human performance.\nOur study can facilitate future research in LLM critiques based on our\nfollowing observations and released resources: (1) superior critiques judged by\nMetaCritique can lead to better refinements, indicating that it can potentially\nenhance the alignment of existing LLMs; (2) the leaderboard of critique models\nreveals that open-source critique models commonly suffer from factuality\nissues; (3) relevant code and data are publicly available at\nhttps://github.com/GAIR-NLP/MetaCritique to support deeper exploration; (4) an\nAPI at PyPI with the usage documentation in Appendix C allows users to assess\nthe critique conveniently.",
      "tldr_zh": "本研究针对评估大型语言模型（LLMs）生成内容的Critique质量缺乏系统方法的问题，提出了MetaCritique框架，该框架通过构建特定量化标准来评估Critique的可靠性。MetaCritique采用Atomic Information Units (AIUs)对Critique进行细粒度描述，并聚合每个AIU的判断得出整体分数，同时提供自然语言推理理由。实验结果显示，MetaCritique在覆盖4个任务和16个公共数据集的元评估中，性能接近人类水平，并揭示了优质Critique能提升LLMs的模型精炼，而开源Critique模型常存在事实性问题；相关代码、数据和PyPI API已公开以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04518v2",
      "published_date": "2024-01-09 12:20:41 UTC",
      "updated_date": "2024-06-01 17:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:42:35.185938"
    },
    {
      "arxiv_id": "2401.04515v1",
      "title": "Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models",
      "title_zh": "使用大型语言模型探索基于提示的零样本上位词预测方法",
      "authors": [
        "Mikhail Tikhomirov",
        "Natalia Loukachevitch"
      ],
      "abstract": "This article investigates a zero-shot approach to hypernymy prediction using\nlarge language models (LLMs). The study employs a method based on text\nprobability calculation, applying it to various generated prompts. The\nexperiments demonstrate a strong correlation between the effectiveness of\nlanguage model prompts and classic patterns, indicating that preliminary prompt\nselection can be carried out using smaller models before moving to larger ones.\nWe also explore prompts for predicting co-hyponyms and improving hypernymy\npredictions by augmenting prompts with additional information through\nautomatically identified co-hyponyms. An iterative approach is developed for\npredicting higher-level concepts, which further improves the quality on the\nBLESS dataset (MAP = 0.8).",
      "tldr_zh": "本研究探讨了基于提示的方法，用于大型语言模型（LLMs）在零样本（zero-shot）超类预测（hypernym prediction）中的应用，通过文本概率计算来评估各种生成的提示。实验发现，LLMs提示的有效性与经典模式高度相关，因此可先使用较小模型进行初步提示选择，再扩展到更大模型；此外，还通过自动识别同类词（co-hyponyms）增强提示，并开发迭代方法预测更高级别概念。结果显示，该方法在BLESS数据集上显著提升了预测质量（MAP = 0.8），为高效的零样本超类预测提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04515v1",
      "published_date": "2024-01-09 12:13:55 UTC",
      "updated_date": "2024-01-09 12:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:42:48.638876"
    },
    {
      "arxiv_id": "2401.04748v1",
      "title": "Convolutional Neural Network Ensemble Learning for Hyperspectral Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Chollette C. Olisah",
        "Ben Trewhella",
        "Bo Li",
        "Melvyn L. Smith",
        "Benjamin Winstone",
        "E. Charles Whitfield",
        "Felicidad Fernández Fernández",
        "Harriet Duncalfe"
      ],
      "abstract": "Fruit ripeness estimation models have for decades depended on spectral index\nfeatures or colour-based features, such as mean, standard deviation, skewness,\ncolour moments, and/or histograms for learning traits of fruit ripeness.\nRecently, few studies have explored the use of deep learning techniques to\nextract features from images of fruits with visible ripeness cues. However, the\nblackberry (Rubus fruticosus) fruit does not show obvious and reliable visible\ntraits of ripeness when mature and therefore poses great difficulty to fruit\npickers. The mature blackberry, to the human eye, is black before, during, and\npost-ripening. To address this engineering application challenge, this paper\nproposes a novel multi-input convolutional neural network (CNN) ensemble\nclassifier for detecting subtle traits of ripeness in blackberry fruits. The\nmulti-input CNN was created from a pre-trained visual geometry group 16-layer\ndeep convolutional network (VGG16) model trained on the ImageNet dataset. The\nfully connected layers were optimized for learning traits of ripeness of mature\nblackberry fruits. The resulting model served as the base for building\nhomogeneous ensemble learners that were ensemble using the stack generalization\nensemble (SGE) framework. The input to the network is images acquired with a\nstereo sensor using visible and near-infrared (VIS-NIR) spectral filters at\nwavelengths of 700 nm and 770 nm. Through experiments, the proposed model\nachieved 95.1% accuracy on unseen sets and 90.2% accuracy with in-field\nconditions. Further experiments reveal that machine sensory is highly and\npositively correlated to human sensory over blackberry fruit skin texture.",
      "tldr_zh": "本研究针对黑莓果实（Rubus fruticosus）在成熟时缺乏明显可见特征的挑战，提出了一种基于超光谱成像的多输入 Convolutional Neural Network (CNN) 集成分类器，用于在非控制农场环境中检测果实成熟度微妙特征。模型以预训练的 VGG16 网络为基础，优化全连接层并通过 stack generalization ensemble (SGE) 框架构建同质集成学习器，输入为可见光和近红外 (VIS-NIR) 图像（波长700 nm 和770 nm）。实验结果显示，该模型在未见数据集上达到95.1%准确率，在田间条件下达到90.2%准确率，并证明机器感知与人类感知在黑莓果实皮肤纹理上高度正相关，从而为果实成熟度检测提供可靠的深度学习解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 10 figures, 6 tables; submited to EAAI",
      "pdf_url": "http://arxiv.org/pdf/2401.04748v1",
      "published_date": "2024-01-09 12:00:17 UTC",
      "updated_date": "2024-01-09 12:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:43:02.822750"
    },
    {
      "arxiv_id": "2401.04507v1",
      "title": "TechGPT-2.0: A large language model project to solve the task of knowledge graph construction",
      "title_zh": "TechGPT-2.0：一个大型语言模型项目，用于解决知识图谱构建任务",
      "authors": [
        "Jiaqi Wang",
        "Yuying Chang",
        "Zhong Li",
        "Ning An",
        "Qi Ma",
        "Lei Hei",
        "Haibo Luo",
        "Yifei Lu",
        "Feiliang Ren"
      ],
      "abstract": "Large language models have exhibited robust performance across diverse\nnatural language processing tasks. This report introduces TechGPT-2.0, a\nproject designed to enhance the capabilities of large language models\nspecifically in knowledge graph construction tasks, including named entity\nrecognition (NER) and relationship triple extraction (RTE) tasks in NLP\napplications. Additionally, it serves as a LLM accessible for research within\nthe Chinese open-source model community. We offer two 7B large language model\nweights and a QLoRA weight specialized for processing lengthy texts.Notably,\nTechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all\nfunctionalities from TechGPT-1.0, it exhibits robust text processing\ncapabilities, particularly in the domains of medicine and law. Furthermore, we\nintroduce new capabilities to the model, enabling it to process texts in\nvarious domains such as geographical areas, transportation, organizations,\nliterary works, biology, natural sciences, astronomical objects, and\narchitecture. These enhancements also fortified the model's adeptness in\nhandling hallucinations, unanswerable queries, and lengthy texts. This report\nprovides a comprehensive and detailed introduction to the full fine-tuning\nprocess on Huawei's Ascend servers, encompassing experiences in Ascend server\ndebugging, instruction fine-tuning data processing, and model training. Our\ncode is available at https://github.com/neukg/TechGPT-2.0",
      "tldr_zh": "该研究介绍了 TechGPT-2.0，一个针对知识图谱构建的大语言模型 (LLM) 项目，专注于提升命名实体识别 (NER) 和关系三元组提取 (RTE) 等任务的表现。模型基于 Huawei's Ascend 服务器进行全面细调，提供两个 7B 模型权重和一个 QLoRA 权重，继承了 TechGPT-1.0 在医学和法律领域的强项，并扩展到地理、交通、生物等新领域，同时增强了对幻觉、无法回答的查询和长文本的处理能力。实验结果显示，该模型在多领域文本处理上表现出色，并通过开源代码（https://github.com/neukg/TechGPT-2.0）供中文社区研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04507v1",
      "published_date": "2024-01-09 11:52:58 UTC",
      "updated_date": "2024-01-09 11:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:43:13.869808"
    },
    {
      "arxiv_id": "2401.04747v2",
      "title": "DiffSHEG: A Diffusion-Based Approach for Real-Time Speech-driven Holistic 3D Expression and Gesture Generation",
      "title_zh": "DiffSHEG：一种基于扩散的方法，用于实时语音驱动的整体 3D 表情和手势生成",
      "authors": [
        "Junming Chen",
        "Yunfei Liu",
        "Jianan Wang",
        "Ailing Zeng",
        "Yu Li",
        "Qifeng Chen"
      ],
      "abstract": "We propose DiffSHEG, a Diffusion-based approach for Speech-driven Holistic 3D\nExpression and Gesture generation with arbitrary length. While previous works\nfocused on co-speech gesture or expression generation individually, the joint\ngeneration of synchronized expressions and gestures remains barely explored. To\naddress this, our diffusion-based co-speech motion generation transformer\nenables uni-directional information flow from expression to gesture,\nfacilitating improved matching of joint expression-gesture distributions.\nFurthermore, we introduce an outpainting-based sampling strategy for arbitrary\nlong sequence generation in diffusion models, offering flexibility and\ncomputational efficiency. Our method provides a practical solution that\nproduces high-quality synchronized expression and gesture generation driven by\nspeech. Evaluated on two public datasets, our approach achieves\nstate-of-the-art performance both quantitatively and qualitatively.\nAdditionally, a user study confirms the superiority of DiffSHEG over prior\napproaches. By enabling the real-time generation of expressive and synchronized\nmotions, DiffSHEG showcases its potential for various applications in the\ndevelopment of digital humans and embodied agents.",
      "tldr_zh": "本研究提出DiffSHEG，一种基于Diffusion模型的实时语音驱动整体3D表情和手势生成方法，能够处理任意长度的序列。DiffSHEG通过一个联合生成transformer实现从表情到手势的单向信息流，提升表情-手势的同步匹配，并引入基于outpainting的采样策略以提高灵活性和计算效率。实验在两个公共数据集上显示，该方法在定量和定性指标上达到最先进水平，用户研究也证实其优于现有方法，并为数字人类和具身代理的开发提供潜在应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by CVPR 2024. Project page:\n  https://jeremycjm.github.io/proj/DiffSHEG",
      "pdf_url": "http://arxiv.org/pdf/2401.04747v2",
      "published_date": "2024-01-09 11:38:18 UTC",
      "updated_date": "2024-04-06 14:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:43:23.471842"
    },
    {
      "arxiv_id": "2401.04489v1",
      "title": "Optimal Survival Trees: A Dynamic Programming Approach",
      "title_zh": "最优生存树：一种动态规划方法",
      "authors": [
        "Tim Huisman",
        "Jacobus G. M. van der Linden",
        "Emir Demirović"
      ],
      "abstract": "Survival analysis studies and predicts the time of death, or other singular\nunrepeated events, based on historical data, while the true time of death for\nsome instances is unknown. Survival trees enable the discovery of complex\nnonlinear relations in a compact human comprehensible model, by recursively\nsplitting the population and predicting a distinct survival distribution in\neach leaf node. We use dynamic programming to provide the first survival tree\nmethod with optimality guarantees, enabling the assessment of the optimality\ngap of heuristics. We improve the scalability of our method through a special\nalgorithm for computing trees up to depth two. The experiments show that our\nmethod's run time even outperforms some heuristics for realistic cases while\nobtaining similar out-of-sample performance with the state-of-the-art.",
      "tldr_zh": "本研究针对生存分析（Survival analysis），提出了一种使用动态规划（Dynamic Programming）的优化生存树（Survival trees）方法，以预测死亡或其他事件时间，同时处理未知事件数据。不同于传统方法，该方法通过递归分割人群并在叶节点预测生存分布，确保模型的最优性，并首次提供对启发式方法的优越性差距评估。研究还通过计算深度为二的树专用算法提升了可伸缩性，实验结果显示，该方法在实际场景下运行时间优于某些启发式方法，同时在样本外性能上与最先进技术相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at AAAI-24",
      "pdf_url": "http://arxiv.org/pdf/2401.04489v1",
      "published_date": "2024-01-09 11:01:11 UTC",
      "updated_date": "2024-01-09 11:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:43:36.553792"
    },
    {
      "arxiv_id": "2401.04481v1",
      "title": "Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset",
      "title_zh": "以火攻火：对抗提示用于生成误信息检测数据集",
      "authors": [
        "Shrey Satapara",
        "Parth Mehta",
        "Debasis Ganguly",
        "Sandip Modha"
      ],
      "abstract": "The recent success in language generation capabilities of large language\nmodels (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns\nabout their possible misuse in inducing mass agitation and communal hatred via\ngenerating fake news and spreading misinformation. Traditional means of\ndeveloping a misinformation ground-truth dataset does not scale well because of\nthe extensive manual effort required to annotate the data. In this paper, we\npropose an LLM-based approach of creating silver-standard ground-truth datasets\nfor identifying misinformation. Specifically speaking, given a trusted news\narticle, our proposed approach involves prompting LLMs to automatically\ngenerate a summarised version of the original article. The prompts in our\nproposed approach act as a controlling mechanism to generate specific types of\nfactual incorrectness in the generated summaries, e.g., incorrect quantities,\nfalse attributions etc. To investigate the usefulness of this dataset, we\nconduct a set of experiments where we train a range of supervised models for\nthe task of misinformation detection.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）如 GPT 和 Llama 等可能生成假新闻和传播错误信息的问题，提出了一种使用对抗性提示（Adversarial Prompting）的方法来自动创建银标准（silver-standard）错误信息数据集。方法涉及通过特定提示引导 LLMs 生成可信新闻文章的总结版本，同时故意引入如不正确数量或虚假归因等错误类型，以模拟真实错误信息。实验结果显示，使用此数据集训练的监督模型能够有效提升错误信息检测性能，为大规模数据集构建提供可扩展的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04481v1",
      "published_date": "2024-01-09 10:38:13 UTC",
      "updated_date": "2024-01-09 10:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:43:49.274131"
    },
    {
      "arxiv_id": "2401.04478v2",
      "title": "TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian G. Schuh",
        "Davide Boldini",
        "Stephan A. Sieber"
      ],
      "abstract": "The success of drug discovery and development relies on the precise\nprediction of molecular activities and properties. While in silico molecular\nproperty prediction has shown remarkable potential, its use has been limited so\nfar to assays for which large amounts of data are available. In this study, we\nuse a fine-tuned large language model to integrate biological assays based on\ntheir textual information, coupled with Barlow Twins, a Siamese neural network\nusing a novel self-supervised learning approach. This architecture uses both\nassay information and molecular fingerprints to extract the true molecular\ninformation. TwinBooster enables the prediction of properties of unseen\nbioassays and molecules by providing state-of-the-art zero-shot learning tasks.\nRemarkably, our artificial intelligence pipeline shows excellent performance on\nthe FS-Mol benchmark. This breakthrough demonstrates the application of deep\nlearning to critical property prediction tasks where data is typically scarce.\nBy accelerating the early identification of active molecules in drug discovery\nand development, this method has the potential to help streamline the\nidentification of novel therapeutics.",
      "tldr_zh": "该研究提出TwinBooster框架，通过整合微调的大型语言模型(Large Language Models)、Barlow Twins的自监督学习(Siamese neural network)和梯度提升(Gradient Boosting)，来提升分子属性预测的准确性。该方法利用生物测定(biological assays)的文本信息和分子指纹(molecular fingerprints)，实现对未见分子和测定的零样本学习(zero-shot learning)预测。在FS-Mol基准上，TwinBooster表现出色，即使在数据稀缺的情况下，也能加速药物发现中活性分子的早期识别，为新型疗法开发提供高效工具。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "13(+9) pages(+appendix), 5 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.04478v2",
      "published_date": "2024-01-09 10:36:20 UTC",
      "updated_date": "2024-01-30 09:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:44:00.847461"
    },
    {
      "arxiv_id": "2401.05447v1",
      "title": "Can ChatGPT Compute Trustworthy Sentiment Scores from Bloomberg Market Wraps?",
      "title_zh": "翻译失败",
      "authors": [
        "Baptiste Lefort",
        "Eric Benhamou",
        "Jean-Jacques Ohana",
        "David Saltiel",
        "Beatrice Guez",
        "Damien Challet"
      ],
      "abstract": "We used a dataset of daily Bloomberg Financial Market Summaries from 2010 to\n2023, reposted on large financial media, to determine how global news headlines\nmay affect stock market movements using ChatGPT and a two-stage prompt\napproach. We document a statistically significant positive correlation between\nthe sentiment score and future equity market returns over short to medium term,\nwhich reverts to a negative correlation over longer horizons. Validation of\nthis correlation pattern across multiple equity markets indicates its\nrobustness across equity regions and resilience to non-linearity, evidenced by\ncomparison of Pearson and Spearman correlations. Finally, we provide an\nestimate of the optimal horizon that strikes a balance between reactivity to\nnew information and correlation.",
      "tldr_zh": "这篇论文使用 ChatGPT 和两阶段提示方法分析 2010-2023 年的 Bloomberg 金融市场总结数据集，评估全球新闻头条如何影响股票市场回报。研究发现，sentiment score 与未来股票回报在短期到中期存在显著正相关，而在长期则转为负相关。该相关模式在多个股票市场中得到验证，显示出鲁棒性，并通过 Pearson and Spearman correlations 证明了对非线性性的抵抗力。最后，论文估计了最佳时限，以平衡对新信息的反应性和相关性。",
      "categories": [
        "q-fin.ST",
        "cs.AI"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.05447v1",
      "published_date": "2024-01-09 10:34:19 UTC",
      "updated_date": "2024-01-09 10:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:44:13.239787"
    },
    {
      "arxiv_id": "2401.04474v1",
      "title": "Combining Embedding-Based and Semantic-Based Models for Post-hoc Explanations in Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ngoc Luyen Le",
        "Marie-Hélène Abel",
        "Philippe Gouspillou"
      ],
      "abstract": "In today's data-rich environment, recommender systems play a crucial role in\ndecision support systems. They provide to users personalized recommendations\nand explanations about these recommendations. Embedding-based models, despite\ntheir widespread use, often suffer from a lack of interpretability, which can\nundermine trust and user engagement. This paper presents an approach that\ncombines embedding-based and semantic-based models to generate post-hoc\nexplanations in recommender systems, leveraging ontology-based knowledge graphs\nto improve interpretability and explainability. By organizing data within a\nstructured framework, ontologies enable the modeling of intricate relationships\nbetween entities, which is essential for generating explanations. By combining\nembedding-based and semantic based models for post-hoc explanations in\nrecommender systems, the framework we defined aims at producing meaningful and\neasy-to-understand explanations, enhancing user trust and satisfaction, and\npotentially promoting the adoption of recommender systems across the e-commerce\nsector.",
      "tldr_zh": "本论文提出了一种结合嵌入式模型（Embedding-based models）和语义模型（Semantic-based models）的框架，用于在推荐系统中生成后验解释（Post-hoc explanations）。该方法利用本体知识图谱（Ontology-based knowledge graphs）来建模实体间的复杂关系，从而提升推荐结果的可解释性和用户理解。实验框架旨在提供更有意义且易懂的解释，提高用户信任和满意度，并促进推荐系统在电商领域的广泛应用。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04474v1",
      "published_date": "2024-01-09 10:24:46 UTC",
      "updated_date": "2024-01-09 10:24:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:44:23.874729"
    },
    {
      "arxiv_id": "2401.04472v3",
      "title": "A Survey on Efficient Federated Learning Methods for Foundation Model Training",
      "title_zh": "关于高效联邦学习方法用于基础模型训练的调查",
      "authors": [
        "Herbert Woisetschläger",
        "Alexander Isenko",
        "Shiqiang Wang",
        "Ruben Mayer",
        "Hans-Arno Jacobsen"
      ],
      "abstract": "Federated Learning (FL) has become an established technique to facilitate\nprivacy-preserving collaborative training across a multitude of clients.\nHowever, new approaches to FL often discuss their contributions involving small\ndeep-learning models only and focus on training full models on clients. In the\nwake of Foundation Models (FM), the reality is different for many deep learning\napplications. Typically, FMs have already been pre-trained across a wide\nvariety of tasks and can be fine-tuned to specific downstream tasks over\nsignificantly smaller datasets than required for full model training. However,\naccess to such datasets is often challenging. By its design, FL can help to\nopen data silos. With this survey, we introduce a novel taxonomy focused on\ncomputational and communication efficiency, the vital elements to make use of\nFMs in FL systems. We discuss the benefits and drawbacks of parameter-efficient\nfine-tuning (PEFT) for FL applications, elaborate on the readiness of FL\nframeworks to work with FMs, and provide future research opportunities on how\nto evaluate generative models in FL as well as the interplay of privacy and\nPEFT.",
      "tldr_zh": "这篇调查论文探讨了高效的 Federated Learning (FL) 方法在 Foundation Models (FM) 训练中的应用，强调了计算和通信效率的重要性。论文引入了一个新的分类法，分析了 Parameter-Efficient Fine-Tuning (PEFT) 在 FL 场景下的优势（如减少数据需求）和挑战（如潜在隐私风险），并评估了现有 FL 框架对 FM 的适应性。未来研究机会包括评估生成模型在 FL 中的性能以及隐私与 PEFT 的互动关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "I.2.11; C.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at IJCAI 2024. Please cite the published\n  paper via https://doi.org/10.24963/ijcai.2024/919",
      "pdf_url": "http://arxiv.org/pdf/2401.04472v3",
      "published_date": "2024-01-09 10:22:23 UTC",
      "updated_date": "2024-09-05 20:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:44:37.824771"
    },
    {
      "arxiv_id": "2401.09466v1",
      "title": "Self Supervised Vision for Climate Downscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Karandeep Singh",
        "Chaeyoon Jeong",
        "Naufal Shidqi",
        "Sungwon Park",
        "Arjun Nellikkattil",
        "Elke Zeller",
        "Meeyoung Cha"
      ],
      "abstract": "Climate change is one of the most critical challenges that our planet is\nfacing today. Rising global temperatures are already bringing noticeable\nchanges to Earth's weather and climate patterns with an increased frequency of\nunpredictable and extreme weather events. Future projections for climate change\nresearch are based on Earth System Models (ESMs), the computer models that\nsimulate the Earth's climate system. ESMs provide a framework to integrate\nvarious physical systems, but their output is bound by the enormous\ncomputational resources required for running and archiving higher-resolution\nsimulations. For a given resource budget, the ESMs are generally run on a\ncoarser grid, followed by a computationally lighter $downscaling$ process to\nobtain a finer-resolution output. In this work, we present a deep-learning\nmodel for downscaling ESM simulation data that does not require high-resolution\nground truth data for model optimization. This is realized by leveraging\nsalient data distribution patterns and the hidden dependencies between weather\nvariables for an $\\textit{individual}$ data point at $\\textit{runtime}$.\nExtensive evaluation with $2$x, $3$x, and $4$x scaling factors demonstrates\nthat the proposed model consistently obtains superior performance over that of\nvarious baselines. The improved downscaling performance and no dependence on\nhigh-resolution ground truth data make the proposed method a valuable tool for\nclimate research and mark it as a promising direction for future research.",
      "tldr_zh": "本研究针对气候变化模拟中的分辨率问题，提出了一种自监督视觉(Self Supervised Vision)方法，用于Earth System Models (ESMs)数据的下采样过程。该方法利用数据分布模式和天气变量间的隐藏依赖关系，在运行时优化模型，而无需高分辨率地面真实数据作为训练标签。实验结果显示，该模型在2x、3x和4x缩放因子下，性能均优于多种基线模型，提供更准确的精细输出。该创新为气候研究提供了一个高效工具，并开辟了未来研究的潜在方向。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.09466v1",
      "published_date": "2024-01-09 10:20:49 UTC",
      "updated_date": "2024-01-09 10:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:44:50.197897"
    },
    {
      "arxiv_id": "2401.04468v1",
      "title": "MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Weimin Wang",
        "Jiawei Liu",
        "Zhijie Lin",
        "Jiangqiao Yan",
        "Shuo Chen",
        "Chetwin Low",
        "Tuyen Hoang",
        "Jie Wu",
        "Jun Hao Liew",
        "Hanshu Yan",
        "Daquan Zhou",
        "Jiashi Feng"
      ],
      "abstract": "The growing demand for high-fidelity video generation from textual\ndescriptions has catalyzed significant research in this field. In this work, we\nintroduce MagicVideo-V2 that integrates the text-to-image model, video motion\ngenerator, reference image embedding module and frame interpolation module into\nan end-to-end video generation pipeline. Benefiting from these architecture\ndesigns, MagicVideo-V2 can generate an aesthetically pleasing, high-resolution\nvideo with remarkable fidelity and smoothness. It demonstrates superior\nperformance over leading Text-to-Video systems such as Runway, Pika 1.0, Morph,\nMoon Valley and Stable Video Diffusion model via user evaluation at large\nscale.",
      "tldr_zh": "本研究推出了 MagicVideo-V2，一种多阶段高美学视频生成系统，通过整合文本到图像模型、视频运动生成器、参考图像嵌入模块和帧插值模块，构建了一个端到端视频生成管道。MagicVideo-V2 能够产生美观、高分辨率的视频，并实现出色的保真度和流畅性。在大规模用户评估中，它优于领先的 Text-to-Video 系统，如 Runway、Pika 1.0、Morph、Moon Valley 和 Stable Video Diffusion。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04468v1",
      "published_date": "2024-01-09 10:12:52 UTC",
      "updated_date": "2024-01-09 10:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:45:03.402969"
    },
    {
      "arxiv_id": "2401.04441v1",
      "title": "Image classification network enhancement methods based on knowledge injection",
      "title_zh": "基于知识注入的图像分类网络增强方法",
      "authors": [
        "Yishuang Tian",
        "Ning Wang",
        "Liang Zhang"
      ],
      "abstract": "The current deep neural network algorithm still stays in the end-to-end\ntraining supervision method like Image-Label pairs, which makes traditional\nalgorithm is difficult to explain the reason for the results, and the\nprediction logic is difficult to understand and analyze. The current algorithm\ndoes not use the existing human knowledge information, which makes the model\nnot in line with the human cognition model and makes the model not suitable for\nhuman use. In order to solve the above problems, the present invention provides\na deep neural network training method based on the human knowledge, which uses\nthe human cognition model to construct the deep neural network training model,\nand uses the existing human knowledge information to construct the deep neural\nnetwork training model. This paper proposes a multi-level hierarchical deep\nlearning algorithm, which is composed of multi-level hierarchical deep neural\nnetwork architecture and multi-level hierarchical deep learning framework. The\nexperimental results show that the proposed algorithm can effectively explain\nthe hidden information of the neural network. The goal of our study is to\nimprove the interpretability of deep neural networks (DNNs) by providing an\nanalysis of the impact of knowledge injection on the classification task. We\nconstructed a knowledge injection dataset with matching knowledge data and\nimage classification data. The knowledge injection dataset is the benchmark\ndataset for the experiments in the paper. Our model expresses the improvement\nin interpretability and classification task performance of hidden layers at\ndifferent scales.",
      "tldr_zh": "本研究针对当前深度神经网络（DNNs）算法依赖端到端训练（如 Image-Label pairs）的问题，指出其解释性不足且未利用人类知识，导致预测逻辑难以理解。作者提出了一种基于知识注入的增强方法，利用人类认知模型构建多级层次深度学习算法，包括多级层次神经网络架构和框架，以提高模型的可解释性和与人类认知的契合度。为此，他们构建了知识注入数据集，并通过实验验证，该方法能有效揭示神经网络的隐藏信息，并在不同规模的隐藏层上提升分类任务的性能和可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.04441v1",
      "published_date": "2024-01-09 09:11:41 UTC",
      "updated_date": "2024-01-09 09:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:45:14.860123"
    },
    {
      "arxiv_id": "2401.04437v1",
      "title": "Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using Dimension Reduction Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Dongeon Kim",
        "YeongHyeon Park"
      ],
      "abstract": "Recent studies try to use hyperspectral imaging (HSI) to detect foreign\nmatters in products because it enables to visualize the invisible wavelengths\nincluding ultraviolet and infrared. Considering the enormous image channels of\nthe HSI, several dimension reduction methods-e.g., PCA or UMAP-can be\nconsidered to reduce but those cannot ease the fundamental limitations, as\nfollows: (1) latency of HSI capturing. (2) less explanation ability of the\nimportant channels. In this paper, to circumvent the aforementioned methods,\none of the ways to channel reduction, on anomaly detection proposed HSI.\nDifferent from feature extraction methods (i.e., PCA or UMAP), feature\nselection can sort the feature by impact and show better explainability so we\nmight redesign the task-optimized and cost-effective spectroscopic camera. Via\nthe extensive experiment results with synthesized MVTec AD dataset, we confirm\nthat the feature selection method shows 6.90x faster at the inference phase\ncompared with feature extraction-based approaches while preserving anomaly\ndetection performance. Ultimately, we conclude the advantage of feature\nselection which is effective yet fast.",
      "tldr_zh": "本研究通过实证分析探讨了使用高光谱成像 (HSI) 进行异常检测时，维度减少方法的局限性，如 PCA 和 UMAP 导致的捕获延迟和解释能力不足。论文提出采用特征选择 (feature selection) 方法作为替代方案，该方法能根据特征影响进行排序，提供更好的可解释性，并优化任务设计。实验结果显示，在合成的 MVTec AD 数据集上，特征选择方法在推理阶段比特征提取 (feature extraction) 方法快 6.90 倍，同时保持了异常检测性能的稳定。最终，该研究证实了特征选择在 HSI 应用中的高效优势，有助于开发更具成本效益的光谱相机。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.04437v1",
      "published_date": "2024-01-09 09:05:15 UTC",
      "updated_date": "2024-01-09 09:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:45:29.385521"
    },
    {
      "arxiv_id": "2401.05446v1",
      "title": "Self-supervised Learning for Electroencephalogram: A Systematic Survey",
      "title_zh": "脑电图的自监督",
      "authors": [
        "Weining Weng",
        "Yang Gu",
        "Shuai Guo",
        "Yuan Ma",
        "Zhaohua Yang",
        "Yuchen Liu",
        "Yiqiang Chen"
      ],
      "abstract": "Electroencephalogram (EEG) is a non-invasive technique to record\nbioelectrical signals. Integrating supervised deep learning techniques with EEG\nsignals has recently facilitated automatic analysis across diverse EEG-based\ntasks. However, the label issues of EEG signals have constrained the\ndevelopment of EEG-based deep models. Obtaining EEG annotations is difficult\nthat requires domain experts to guide collection and labeling, and the\nvariability of EEG signals among different subjects causes significant label\nshifts. To solve the above challenges, self-supervised learning (SSL) has been\nproposed to extract representations from unlabeled samples through\nwell-designed pretext tasks. This paper concentrates on integrating SSL\nframeworks with temporal EEG signals to achieve efficient representation and\nproposes a systematic review of the SSL for EEG signals. In this paper, 1) we\nintroduce the concept and theory of self-supervised learning and typical SSL\nframeworks. 2) We provide a comprehensive review of SSL for EEG analysis,\nincluding taxonomy, methodology, and technique details of the existing\nEEG-based SSL frameworks, and discuss the difference between these methods. 3)\nWe investigate the adaptation of the SSL approach to various downstream tasks,\nincluding the task description and related benchmark datasets. 4) Finally, we\ndiscuss the potential directions for future SSL-EEG research.",
      "tldr_zh": "这篇论文对自监督学习 (Self-supervised Learning, SSL) 在脑电图 (Electroencephalogram, EEG) 信号分析中的应用进行了系统性回顾。论文首先介绍了 EEG 的概念及其面临的挑战，如标注困难和个体差异导致的标签偏移，并提出 SSL 通过设计预训练任务从无标签样本中提取高效表示来解决这些问题。研究全面梳理了现有的 EEG-based SSL 框架，包括分类、方法细节和差异，并探讨了 SSL 在各种下游任务（如分类和预测）的适应性及其基准数据集。最后，论文指出了未来 SSL-EEG 研究的方向，如改进框架和扩展应用，以推动 EEG 分析的自动化和鲁棒性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "68-02 (Primarily), 68T01 (Secondary)",
        "I.2; J.3; I.5.4"
      ],
      "primary_category": "eess.SP",
      "comment": "35 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.05446v1",
      "published_date": "2024-01-09 08:59:30 UTC",
      "updated_date": "2024-01-09 08:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:45:41.052099"
    },
    {
      "arxiv_id": "2401.04429v2",
      "title": "i-Rebalance: Personalized Vehicle Repositioning for Supply Demand Balance",
      "title_zh": "i-Rebalance：个性化的车辆重新定位用于",
      "authors": [
        "Haoyang Chen",
        "Peiyan Sun",
        "Qiyuan Song",
        "Wanyuan Wang",
        "Weiwei Wu",
        "Wencan Zhang",
        "Guanyu Gao",
        "Yan Lyu"
      ],
      "abstract": "Ride-hailing platforms have been facing the challenge of balancing demand and\nsupply. Existing vehicle reposition techniques often treat drivers as\nhomogeneous agents and relocate them deterministically, assuming compliance\nwith the reposition. In this paper, we consider a more realistic and\ndriver-centric scenario where drivers have unique cruising preferences and can\ndecide whether to take the recommendation or not on their own. We propose\ni-Rebalance, a personalized vehicle reposition technique with deep\nreinforcement learning (DRL). i-Rebalance estimates drivers' decisions on\naccepting reposition recommendations through an on-field user study involving\n99 real drivers. To optimize supply-demand balance and enhance preference\nsatisfaction simultaneously, i-Rebalance has a sequential reposition strategy\nwith dual DRL agents: Grid Agent to determine the reposition order of idle\nvehicles, and Vehicle Agent to provide personalized recommendations to each\nvehicle in the pre-defined order. This sequential learning strategy facilitates\nmore effective policy training within a smaller action space compared to\ntraditional joint-action methods. Evaluation of real-world trajectory data\nshows that i-Rebalance improves driver acceptance rate by 38.07% and total\ndriver income by 9.97%.",
      "tldr_zh": "该研究针对网约车平台的供需平衡问题，提出 i-Rebalance，一种个性化的车辆重新定位技术，使用深度强化学习(DRL)来考虑司机的独特偏好和自主决策。i-Rebalance 通过一个涉及99名真实司机的用户研究来估计司机对推荐的接受意愿，并采用双 DRL 代理系统：Grid Agent 负责确定空闲车辆的重新定位顺序，Vehicle Agent 则提供个性化推荐，以优化供需平衡和偏好满足。实验结果显示，该方法将司机接受率提高38.07%，并提升总收入9.97%。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04429v2",
      "published_date": "2024-01-09 08:51:56 UTC",
      "updated_date": "2024-04-02 05:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:45:51.146817"
    },
    {
      "arxiv_id": "2402.06629v1",
      "title": "Towards the mathematical foundation of the minimum enclosing ball and related problems",
      "title_zh": "迈向最小外接球及其相关问题的数学基础",
      "authors": [
        "Michael N. Vrahatis"
      ],
      "abstract": "Theoretical background is provided towards the mathematical foundation of the\nminimum enclosing ball problem. This problem concerns the determination of the\nunique spherical surface of smallest radius enclosing a given bounded set in\nthe d-dimensional Euclidean space. The study of several problems that are\nsimilar or related to the minimum enclosing ball problem has received a\nconsiderable impetus from the large amount of applications of these problems in\nvarious fields of science and technology. The proposed theoretical framework is\nbased on several enclosing (covering) and partitioning (clustering) theorems\nand provides among others bounds and relations between the circumradius,\ninradius, diameter and width of a set. These enclosing and partitioning\ntheorems are considered as cornerstones in the field that strongly influencing\ndevelopments and generalizations to other spaces and non-Euclidean geometries.",
      "tldr_zh": "本论文探讨了最小外接球（minimum enclosing ball）问题及其相关问题的数学基础，旨在在 d 维欧式空间（Euclidean space）中确定最小半径的球体来包围一个给定的有界集合。作者提出一个基于外接（covering）和分区（clustering）定理的理论框架，提供 circumradius（外接半径）、inradius（内接半径）、diameter（直径）和 width（宽度）之间的界限和关系。这些定理作为该领域的基石，不仅促进了相关问题的应用，还影响了对其他空间和非欧几何的扩展和发展。",
      "categories": [
        "cs.CG",
        "cs.AI",
        "math.GT"
      ],
      "primary_category": "cs.CG",
      "comment": "arXiv admin note: text overlap with arXiv:2401.03232",
      "pdf_url": "http://arxiv.org/pdf/2402.06629v1",
      "published_date": "2024-01-09 08:30:55 UTC",
      "updated_date": "2024-01-09 08:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:46:02.835102"
    },
    {
      "arxiv_id": "2401.04422v1",
      "title": "Estimating Text Similarity based on Semantic Concept Embeddings",
      "title_zh": "基于语义概念嵌入的文本相似度估计",
      "authors": [
        "Tim vor der Brück",
        "Marc Pouly"
      ],
      "abstract": "Due to their ease of use and high accuracy, Word2Vec (W2V) word embeddings\nenjoy great success in the semantic representation of words, sentences, and\nwhole documents as well as for semantic similarity estimation. However, they\nhave the shortcoming that they are directly extracted from a surface\nrepresentation, which does not adequately represent human thought processes and\nalso performs poorly for highly ambiguous words. Therefore, we propose Semantic\nConcept Embeddings (CE) based on the MultiNet Semantic Network (SN) formalism,\nwhich addresses both shortcomings. The evaluation on a marketing target group\ndistribution task showed that the accuracy of predicted target groups can be\nincreased by combining traditional word embeddings with semantic CEs.",
      "tldr_zh": "这篇论文指出了 Word2Vec (W2V) 词嵌入的局限性，即其基于表面表示，无法充分捕捉人类思维过程，且在处理高度模糊词时表现不佳。为此，作者提出 Semantic Concept Embeddings (CE)，基于 MultiNet Semantic Network (SN) 形式主义，以更好地实现语义表示和文本相似度估计。在一个营销目标群体分布任务的评估中，将传统词嵌入与语义 CE 结合后，显著提高了预测目标群体的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04422v1",
      "published_date": "2024-01-09 08:29:46 UTC",
      "updated_date": "2024-01-09 08:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:46:16.525943"
    },
    {
      "arxiv_id": "2401.04405v1",
      "title": "Optimal Transcoding Resolution Prediction for Efficient Per-Title Bitrate Ladder Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhai Yang",
        "Mengxi Guo",
        "Shijie Zhao",
        "Junlin Li",
        "Li Zhang"
      ],
      "abstract": "Adaptive video streaming requires efficient bitrate ladder construction to\nmeet heterogeneous network conditions and end-user demands. Per-title optimized\nencoding typically traverses numerous encoding parameters to search the\nPareto-optimal operating points for each video. Recently, researchers have\nattempted to predict the content-optimized bitrate ladder for pre-encoding\noverhead reduction. However, existing methods commonly estimate the encoding\nparameters on the Pareto front and still require subsequent pre-encodings. In\nthis paper, we propose to directly predict the optimal transcoding resolution\nat each preset bitrate for efficient bitrate ladder construction. We adopt a\nTemporal Attentive Gated Recurrent Network to capture spatial-temporal features\nand predict transcoding resolutions as a multi-task classification problem. We\ndemonstrate that content-optimized bitrate ladders can thus be efficiently\ndetermined without any pre-encoding. Our method well approximates the\nground-truth bitrate-resolution pairs with a slight Bj{\\o}ntegaard Delta rate\nloss of 1.21% and significantly outperforms the state-of-the-art fixed ladder.",
      "tldr_zh": "该论文针对适应性视频流媒体的比特率阶梯（bitrate ladder）构建问题，提出一种高效方法，通过直接预测每个预设比特率下的最优转码分辨率（transcoding resolution），以减少预编码开销。方法采用Temporal Attentive Gated Recurrent Network捕捉视频的空间-时间特征，并将其作为多任务分类问题进行预测，从而无需任何预编码即可确定内容优化的比特率阶梯。实验结果显示，该方法与地面真实值非常接近，仅有1.21%的Bj{\\o}ntegaard Delta rate损失，并显著优于现有的固定阶梯方案。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.MM",
      "comment": "Accepted by the 2024 Data Compression Conference (DCC) for\n  presentation as a poster. This is the full paper",
      "pdf_url": "http://arxiv.org/pdf/2401.04405v1",
      "published_date": "2024-01-09 08:01:47 UTC",
      "updated_date": "2024-01-09 08:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:46:28.424784"
    },
    {
      "arxiv_id": "2401.04402v2",
      "title": "IGNITE: Individualized GeNeration of Imputations in Time-series Electronic health records",
      "title_zh": "翻译失败",
      "authors": [
        "Ghadeer O. Ghosheh",
        "Jin Li",
        "Tingting Zhu"
      ],
      "abstract": "Electronic Health Records present a valuable modality for driving\npersonalized medicine, where treatment is tailored to fit individual-level\ndifferences. For this purpose, many data-driven machine learning and\nstatistical models rely on the wealth of longitudinal EHRs to study patients'\nphysiological and treatment effects. However, longitudinal EHRs tend to be\nsparse and highly missing, where missingness could also be informative and\nreflect the underlying patient's health status. Therefore, the success of\ndata-driven models for personalized medicine highly depends on how the EHR data\nis represented from physiological data, treatments, and the missing values in\nthe data. To this end, we propose a novel deep-learning model that learns the\nunderlying patient dynamics over time across multivariate data to generate\npersonalized realistic values conditioning on an individual's demographic\ncharacteristics and treatments. Our proposed model, IGNITE (Individualized\nGeNeration of Imputations in Time-series Electronic health records), utilises a\nconditional dual-variational autoencoder augmented with dual-stage attention to\ngenerate missing values for an individual. In IGNITE, we further propose a\nnovel individualized missingness mask (IMM), which helps our model generate\nvalues based on the individual's observed data and missingness patterns. We\nfurther extend the use of IGNITE from imputing missingness to a personalized\ndata synthesizer, where it generates missing EHRs that were never observed\nprior or even generates new patients for various applications. We validate our\nmodel on three large publicly available datasets and show that IGNITE\noutperforms state-of-the-art approaches in missing data reconstruction and task\nprediction.",
      "tldr_zh": "该论文针对电子健康记录 (EHRs) 的稀疏性和缺失问题，提出了一种新型深度学习模型 IGNITE，用于生成个性化的时间序列缺失值。IGNITE 基于条件双变分自编码器 (conditional dual-variational autoencoder) 和双阶段注意力 (dual-stage attention)，并引入 individualized missingness mask (IMM) 来根据个体的 demographic 特征、治疗数据和缺失模式生成真实值。该模型不仅能填充缺失数据，还扩展为个性化数据合成器，可生成未观察到的 EHRs 或新患者数据。在三个大型公开数据集上的实验中，IGNITE 在缺失数据重建和任务预测方面优于现有方法，为个性化医学提供了更可靠的数据表示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04402v2",
      "published_date": "2024-01-09 07:57:21 UTC",
      "updated_date": "2024-12-13 14:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:46:41.358099"
    },
    {
      "arxiv_id": "2401.05444v1",
      "title": "Fully Spiking Actor Network with Intra-layer Connections for Reinforcement Learning",
      "title_zh": "具有层内连接的完全脉冲演员网络用于强化学习",
      "authors": [
        "Ding Chen",
        "Peixi Peng",
        "Tiejun Huang",
        "Yonghong Tian"
      ],
      "abstract": "With the help of special neuromorphic hardware, spiking neural networks\n(SNNs) are expected to realize artificial intelligence (AI) with less energy\nconsumption. It provides a promising energy-efficient way for realistic control\ntasks by combining SNNs with deep reinforcement learning (DRL). In this paper,\nwe focus on the task where the agent needs to learn multi-dimensional\ndeterministic policies to control, which is very common in real scenarios.\nRecently, the surrogate gradient method has been utilized for training\nmulti-layer SNNs, which allows SNNs to achieve comparable performance with the\ncorresponding deep networks in this task. Most existing spike-based RL methods\ntake the firing rate as the output of SNNs, and convert it to represent\ncontinuous action space (i.e., the deterministic policy) through a\nfully-connected (FC) layer. However, the decimal characteristic of the firing\nrate brings the floating-point matrix operations to the FC layer, making the\nwhole SNN unable to deploy on the neuromorphic hardware directly. To develop a\nfully spiking actor network without any floating-point matrix operations, we\ndraw inspiration from the non-spiking interneurons found in insects and employ\nthe membrane voltage of the non-spiking neurons to represent the action. Before\nthe non-spiking neurons, multiple population neurons are introduced to decode\ndifferent dimensions of actions. Since each population is used to decode a\ndimension of action, we argue that the neurons in each population should be\nconnected in time domain and space domain. Hence, the intra-layer connections\nare used in output populations to enhance the representation capacity. Finally,\nwe propose a fully spiking actor network with intra-layer connections\n(ILC-SAN).",
      "tldr_zh": "这篇论文针对强化学习中的脉冲神经网络(SNNs)问题，提出了一种全 spiking 演员网络，以避免输出层浮点运算，从而实现直接部署到神经形态硬件(neuromorphic hardware)。方法灵感来源于昆虫的非 spiking 神经元，使用膜电压表示多维确定性动作，并引入多个种群神经元结合 intra-layer connections 来增强动作解码的表示能力。最终，论文开发了 ILC-SAN 框架，显著提高了 SNNs 在深度强化学习(DRL)任务中的能量效率和实用性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.05444v1",
      "published_date": "2024-01-09 07:31:34 UTC",
      "updated_date": "2024-01-09 07:31:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:46:55.925731"
    },
    {
      "arxiv_id": "2401.04385v4",
      "title": "Machine unlearning through fine-grained model parameters perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Zuo",
        "Zhuo Tang",
        "Kenli Li",
        "Anwitaman Datta"
      ],
      "abstract": "Machine unlearning techniques, which involve retracting data records and\nreducing influence of said data on trained models, help with the user privacy\nprotection objective but incur significant computational costs. Weight\nperturbation-based unlearning is a general approach, but it typically involves\nglobally modifying the parameters. We propose fine-grained Top-K and Random-k\nparameters perturbed inexact machine unlearning strategies that address the\nprivacy needs while keeping the computational costs tractable.\n  In order to demonstrate the efficacy of our strategies we also tackle the\nchallenge of evaluating the effectiveness of machine unlearning by considering\nthe model's generalization performance across both unlearning and remaining\ndata. To better assess the unlearning effect and model generalization, we\npropose novel metrics, namely, the forgetting rate and memory retention rate.\nHowever, for inexact machine unlearning, current metrics are inadequate in\nquantifying the degree of forgetting that occurs after unlearning strategies\nare applied. To address this, we introduce SPD-GAN, which subtly perturbs the\ndistribution of data targeted for unlearning. Then, we evaluate the degree of\nunlearning by measuring the performance difference of the models on the\nperturbed unlearning data before and after the unlearning process. By\nimplementing these innovative techniques and metrics, we achieve\ncomputationally efficacious privacy protection in machine learning applications\nwithout significant sacrifice of model performance. Furthermore, this approach\nprovides a novel method for evaluating the degree of unlearning.",
      "tldr_zh": "这篇论文提出了细粒度的 Top-K 和 Random-k 参数扰动策略，用于 machine unlearning，以实现用户隐私保护，同时降低计算成本，避免全局参数修改带来的效率问题。作者引入了新的评估指标，包括 forgetting rate 和 memory retention rate，来评估模型在取消学习数据和剩余数据上的泛化性能；此外，还开发了 SPD-GAN 工具，通过微妙扰动取消学习数据分布来量化取消学习效果。实验结果表明，这些方法在保持模型性能基本不变的情况下，实现了高效的隐私保护，并为 machine unlearning 的评估提供了创新框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04385v4",
      "published_date": "2024-01-09 07:14:45 UTC",
      "updated_date": "2025-01-15 06:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:47:08.064866"
    },
    {
      "arxiv_id": "2401.04374v2",
      "title": "Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective",
      "title_zh": "迈向可解释人工智能 (XAI)：数据挖掘视角",
      "authors": [
        "Haoyi Xiong",
        "Xuhong Li",
        "Xiaofei Zhang",
        "Jiamin Chen",
        "Xinhao Sun",
        "Yuchen Li",
        "Zeyi Sun",
        "Mengnan Du"
      ],
      "abstract": "Given the complexity and lack of transparency in deep neural networks (DNNs),\nextensive efforts have been made to make these systems more interpretable or\nexplain their behaviors in accessible terms. Unlike most reviews, which focus\non algorithmic and model-centric perspectives, this work takes a \"data-centric\"\nview, examining how data collection, processing, and analysis contribute to\nexplainable AI (XAI). We categorize existing work into three categories subject\nto their purposes: interpretations of deep models, referring to feature\nattributions and reasoning processes that correlate data points with model\noutputs; influences of training data, examining the impact of training data\nnuances, such as data valuation and sample anomalies, on decision-making\nprocesses; and insights of domain knowledge, discovering latent patterns and\nfostering new knowledge from data and models to advance social values and\nscientific discovery. Specifically, we distill XAI methodologies into data\nmining operations on training and testing data across modalities, such as\nimages, text, and tabular data, as well as on training logs, checkpoints,\nmodels and other DNN behavior descriptors. In this way, our study offers a\ncomprehensive, data-centric examination of XAI from a lens of data mining\nmethods and applications.",
      "tldr_zh": "这篇论文从数据挖掘视角探讨可解释人工智能(XAI)，强调数据收集、处理和分析如何提升深度神经网络(DNNs)的可解释性，而非仅聚焦算法或模型本身。论文将现有XAI工作分类为三类：深层模型的解释（如特征归因和推理过程）、训练数据的影響（如数据价值和样本异常对决策的影响），以及领域知识的洞见（如从数据中发现潜在模式以推进科学发现）。通过将XAI方法提炼为对训练和测试数据的挖掘操作，涵盖图像、文本和表格数据等模态，该研究提供了一个全面的数据中心框架，促进XAI在实际应用中的发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04374v2",
      "published_date": "2024-01-09 06:27:09 UTC",
      "updated_date": "2024-01-13 06:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:47:20.438955"
    },
    {
      "arxiv_id": "2402.03327v1",
      "title": "Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dingning Liu",
        "Xiaoshui Huang",
        "Yuenan Hou",
        "Zhihui Wang",
        "Zhenfei Yin",
        "Yongshun Gong",
        "Peng Gao",
        "Wanli Ouyang"
      ],
      "abstract": "In this paper, we introduce Uni3D-LLM, a unified framework that leverages a\nLarge Language Model (LLM) to integrate tasks of 3D perception, generation, and\nediting within point cloud scenes. This framework empowers users to\neffortlessly generate and modify objects at specified locations within a scene,\nguided by the versatility of natural language descriptions. Uni3D-LLM harnesses\nthe expressive power of natural language to allow for precise command over the\ngeneration and editing of 3D objects, thereby significantly enhancing\noperational flexibility and controllability. By mapping point cloud into the\nunified representation space, Uni3D-LLM achieves cross-application\nfunctionality, enabling the seamless execution of a wide array of tasks,\nranging from the accurate instantiation of 3D objects to the diverse\nrequirements of interactive design. Through a comprehensive suite of rigorous\nexperiments, the efficacy of Uni3D-LLM in the comprehension, generation, and\nediting of point cloud has been validated. Additionally, we have assessed the\nimpact of integrating a point cloud perception module on the generation and\nediting processes, confirming the substantial potential of our approach for\npractical applications.",
      "tldr_zh": "本研究提出Uni3D-LLM框架，利用Large Language Models (LLMs)统一整合3D点云的感知、生成和编辑任务，允许用户通过自然语言描述轻松生成或修改场景中指定位置的物体。框架通过将点云映射到统一的表示空间，实现跨应用功能，提升操作的灵活性和可控性，从而支持精确的3D对象实例化和交互设计。实验结果验证了Uni3D-LLM在点云理解、生成和编辑方面的有效性，并证明了整合点云感知模块对这些过程的显著提升，具有重要的实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.03327v1",
      "published_date": "2024-01-09 06:20:23 UTC",
      "updated_date": "2024-01-09 06:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:47:30.130700"
    },
    {
      "arxiv_id": "2401.04739v1",
      "title": "Content-Conditioned Generation of Stylized Free hand Sketches",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Liu",
        "Siyuan Wang",
        "Guangming Zhu",
        "Liang Zhang",
        "Ning Li",
        "Eryang Gao"
      ],
      "abstract": "In recent years, the recognition of free-hand sketches has remained a popular\ntask. However, in some special fields such as the military field, free-hand\nsketches are difficult to sample on a large scale. Common data augmentation and\nimage generation techniques are difficult to produce images with various\nfree-hand sketching styles. Therefore, the recognition and segmentation tasks\nin related fields are limited. In this paper, we propose a novel adversarial\ngenerative network that can accurately generate realistic free-hand sketches\nwith various styles. We explore the performance of the model, including using\nstyles randomly sampled from a prior normal distribution to generate images\nwith various free-hand sketching styles, disentangling the painters' styles\nfrom known free-hand sketches to generate images with specific styles, and\ngenerating images of unknown classes that are not in the training set. We\nfurther demonstrate with qualitative and quantitative evaluations our\nadvantages in visual quality, content accuracy, and style imitation on\nSketchIME.",
      "tldr_zh": "本论文针对自由手绘草图（free-hand sketches）在特定领域（如军事）采样困难的问题，提出了一种新颖的对抗生成网络（adversarial generative network），能够准确生成各种风格的真实草图。模型支持从先验正态分布随机采样风格、从已知草图中分离画家的特定风格，以及生成训练集外未知类别的图像。实验在 SketchIME 数据集上通过定性和定量评估，展示了该方法在视觉质量、内容准确性和风格模仿方面的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures, ICSMD",
      "pdf_url": "http://arxiv.org/pdf/2401.04739v1",
      "published_date": "2024-01-09 05:57:35 UTC",
      "updated_date": "2024-01-09 05:57:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:47:43.497923"
    },
    {
      "arxiv_id": "2401.04362v1",
      "title": "Representative Feature Extraction During Diffusion Process for Sketch Extraction with One Example",
      "title_zh": "扩散过程期间的代表性特征提取，用于单示例草图提取",
      "authors": [
        "Kwan Yun",
        "Youngseo Kim",
        "Kwanggyoon Seo",
        "Chang Wook Seo",
        "Junyong Noh"
      ],
      "abstract": "We introduce DiffSketch, a method for generating a variety of stylized\nsketches from images. Our approach focuses on selecting representative features\nfrom the rich semantics of deep features within a pretrained diffusion model.\nThis novel sketch generation method can be trained with one manual drawing.\nFurthermore, efficient sketch extraction is ensured by distilling a trained\ngenerator into a streamlined extractor. We select denoising diffusion features\nthrough analysis and integrate these selected features with VAE features to\nproduce sketches. Additionally, we propose a sampling scheme for training\nmodels using a conditional generative approach. Through a series of\ncomparisons, we verify that distilled DiffSketch not only outperforms existing\nstate-of-the-art sketch extraction methods but also surpasses diffusion-based\nstylization methods in the task of extracting sketches.",
      "tldr_zh": "该论文提出了一种名为 DiffSketch 的方法，用于从图像生成各种风格化的草图，通过在扩散过程中提取代表性特征，仅需一个手动绘图即可训练。方法的核心在于从预训练扩散模型中选择 denoising diffusion features，并与 VAE features 整合，以实现高效的草图生成和提取。作者还引入了采样方案和蒸馏(distilling)技术，将训练好的生成器优化为简化的提取器。实验比较表明，DiffSketch 不仅在草图提取任务中超越现有最先进方法，还优于基于扩散的风格化方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "68T01",
        "I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages(main paper), 8 pages(supplementary material)",
      "pdf_url": "http://arxiv.org/pdf/2401.04362v1",
      "published_date": "2024-01-09 05:22:15 UTC",
      "updated_date": "2024-01-09 05:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:47:55.906046"
    },
    {
      "arxiv_id": "2401.04361v1",
      "title": "Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaan Wang",
        "Jianfeng Qu",
        "Kexin Wang",
        "Zhixu Li",
        "Wen Hua",
        "Ximing Li",
        "An Liu"
      ],
      "abstract": "Knowledge-grounded dialogue (KGD) learns to generate an informative response\nbased on a given dialogue context and external knowledge (\\emph{e.g.},\nknowledge graphs; KGs). Recently, the emergence of large language models (LLMs)\nand pre-training techniques has brought great success to knowledge-grounded\ndialogue. However, when building KGD systems in real applications, there are\nvarious real-world noises that are inevitable to face. For example, the\ndialogue context might involve perturbations such as misspellings and\nabbreviations. In addition, KGs typically suffer from incompletion and also\nmight contain erroneous and outdated facts. Such real-world noises pose a\nchallenge to the robustness of KGD systems and hinder their applications in the\nreal world. In this paper, we propose an entity-based contrastive learning\nframework for improving the robustness of KGD. Specifically, we make use of the\nentity information in a KGD sample to create both its positive and negative\nsamples which involve semantic-irrelevant and semantic-relevant perturbations,\nrespectively. The contrastive learning framework ensures the KGD model is aware\nof these two types of perturbations, thus generating informative responses with\nthe potentially noisy inputs in real applications. Experimental results on\nthree benchmark datasets show that our method achieves new state-of-the-art\nperformance in terms of automatic evaluation scores, verifying its\neffectiveness and potentiality. Furthermore, we show that our method can\ngenerate better responses than comparison models in both the noisy and the\nfew-shot settings.",
      "tldr_zh": "本文提出了一种基于对比学习的框架，以提升知识导向对话 (KGD) 系统的鲁棒性，针对真实世界噪声如对话中的拼写错误、缩写，以及知识图谱 (KGs) 的不完整或错误问题。方法通过利用实体信息创建语义无关和语义相关的正负样本，进行对比学习训练，使模型能更好地处理噪声输入并生成信息丰富的响应。实验在三个基准数据集上实现了新的最先进性能，并在噪声和少样本设置下表现出色，验证了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04361v1",
      "published_date": "2024-01-09 05:16:52 UTC",
      "updated_date": "2024-01-09 05:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:48:07.461835"
    },
    {
      "arxiv_id": "2401.04357v1",
      "title": "Iterative Feedback Network for Unsupervised Point Cloud Registration",
      "title_zh": "用于无监督点云配准的迭代反馈",
      "authors": [
        "Yifan Xie",
        "Boyu Wang",
        "Shiqi Li",
        "Jihua Zhu"
      ],
      "abstract": "As a fundamental problem in computer vision, point cloud registration aims to\nseek the optimal transformation for aligning a pair of point clouds. In most\nexisting methods, the information flows are usually forward transferring, thus\nlacking the guidance from high-level information to low-level information.\nBesides, excessive high-level information may be overly redundant, and directly\nusing it may conflict with the original low-level information. In this paper,\nwe propose a novel Iterative Feedback Network (IFNet) for unsupervised point\ncloud registration, in which the representation of low-level features is\nefficiently enriched by rerouting subsequent high-level features. Specifically,\nour IFNet is built upon a series of Feedback Registration Block (FRB) modules,\nwith each module responsible for generating the feedforward rigid\ntransformation and feedback high-level features. These FRB modules are cascaded\nand recurrently unfolded over time. Further, the Feedback Transformer is\ndesigned to efficiently select relevant information from feedback high-level\nfeatures, which is utilized to refine the low-level features. What's more, we\nincorporate a geometry-awareness descriptor to empower the network for making\nfull use of most geometric information, which leads to more precise\nregistration results. Extensive experiments on various benchmark datasets\ndemonstrate the superior registration performance of our IFNet.",
      "tldr_zh": "本文提出了一种新的 Iterative Feedback Network (IFNet) 用于无监督点云注册问题，通过引入反馈机制来丰富低级特征，避免现有方法的单向信息流和冗余冲突。IFNet 基于一系列 Feedback Registration Block (FRB) 模块，这些模块级联展开，并在 Feedback Transformer 的帮助下从高水平特征中选择相关信息进行低级特征精炼，同时整合 geometry-awareness descriptor 以充分利用几何信息。实验在多个基准数据集上证明，IFNet 比传统方法取得了显著的注册性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, accepted by RAL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04357v1",
      "published_date": "2024-01-09 04:44:12 UTC",
      "updated_date": "2024-01-09 04:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:48:20.445038"
    },
    {
      "arxiv_id": "2401.04351v1",
      "title": "A Change Point Detection Integrated Remaining Useful Life Estimation Model under Variable Operating Conditions",
      "title_zh": "在可变操作",
      "authors": [
        "Anushiya Arunan",
        "Yan Qin",
        "Xiaoli Li",
        "Chau Yuen"
      ],
      "abstract": "By informing the onset of the degradation process, health status evaluation\nserves as a significant preliminary step for reliable remaining useful life\n(RUL) estimation of complex equipment. This paper proposes a novel temporal\ndynamics learning-based model for detecting change points of individual\ndevices, even under variable operating conditions, and utilises the learnt\nchange points to improve the RUL estimation accuracy. During offline model\ndevelopment, the multivariate sensor data are decomposed to learn fused\ntemporal correlation features that are generalisable and representative of\nnormal operation dynamics across multiple operating conditions. Monitoring\nstatistics and control limit thresholds for normal behaviour are dynamically\nconstructed from these learnt temporal features for the unsupervised detection\nof device-level change points. The detected change points then inform the\ndegradation data labelling for training a long short-term memory (LSTM)-based\nRUL estimation model. During online monitoring, the temporal correlation\ndynamics of a query device is monitored for breach of the control limit derived\nin offline training. If a change point is detected, the device's RUL is\nestimated with the well-trained offline model for early preventive action.\nUsing C-MAPSS turbofan engines as the case study, the proposed method improved\nthe accuracy by 5.6\\% and 7.5\\% for two scenarios with six operating\nconditions, when compared to existing LSTM-based RUL estimation models that do\nnot consider heterogeneous change points.",
      "tldr_zh": "该论文提出了一种整合变化点检测的剩余寿命（RUL）估计模型，旨在在可变操作条件下提升复杂设备健康状态评估和RUL预测的准确性。该模型通过分解多变量传感器数据，学习融合的时间相关特征，并在离线阶段构建监控统计和控制限阈值，实现无监督的设备级变化点检测；检测结果用于标记退化数据，训练基于长短时记忆（LSTM）的RUL估计模型。在C-MAPSS涡轮风扇引擎案例研究中，该方法与现有LSTM模型相比，准确率分别提高了5.6%和7.5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in Control Engineering Practice Journal with DOI:\n  https://doi.org/10.1016/j.conengprac.2023.105840",
      "pdf_url": "http://arxiv.org/pdf/2401.04351v1",
      "published_date": "2024-01-09 04:35:17 UTC",
      "updated_date": "2024-01-09 04:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:48:32.781563"
    },
    {
      "arxiv_id": "2401.04339v2",
      "title": "Memory-Efficient Fine-Tuning for Quantized Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hyogon Ryu",
        "Seohyun Lim",
        "Hyunjung Shim"
      ],
      "abstract": "The emergence of billion-parameter diffusion models such as Stable Diffusion\nXL, Imagen, and DALL-E 3 has significantly propelled the domain of generative\nAI. However, their large-scale architecture presents challenges in fine-tuning\nand deployment due to high resource demands and slow inference speed. This\npaper explores the relatively unexplored yet promising realm of fine-tuning\nquantized diffusion models. Our analysis revealed that the baseline neglects\nthe distinct patterns in model weights and the different roles throughout time\nsteps when finetuning the diffusion model. To address these limitations, we\nintroduce a novel memory-efficient fine-tuning method specifically designed for\nquantized diffusion models, dubbed TuneQDM. Our approach introduces\nquantization scales as separable functions to consider inter-channel weight\npatterns. Then, it optimizes these scales in a timestep-specific manner for\neffective reflection of the role of each time step. TuneQDM achieves\nperformance on par with its full-precision counterpart while simultaneously\noffering significant memory efficiency. Experimental results demonstrate that\nour method consistently outperforms the baseline in both single-/multi-subject\ngenerations, exhibiting high subject fidelity and prompt fidelity comparable to\nthe full precision model.",
      "tldr_zh": "本研究针对大型扩散模型（如Stable Diffusion XL、Imagen和DALL-E 3）在微调和部署中面临的资源消耗高和推理速度慢的问题，探索了quantized diffusion models的微调方法。论文提出了一种新型内存高效微调框架TuneQDM，通过将量化尺度设计为可分离函数来考虑通道间权重模式，并以时间步特定的方式优化这些尺度，以更好地反映各时间步的角色。实验结果显示，TuneQDM在单/多主题生成任务中性能与全精度模型相当，同时显著优于基线模型，在主题保真度和提示保真度方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024. Code will be released at\n  https://github.com/ugonfor/TuneQDM",
      "pdf_url": "http://arxiv.org/pdf/2401.04339v2",
      "published_date": "2024-01-09 03:42:08 UTC",
      "updated_date": "2024-07-18 11:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:48:44.387205"
    },
    {
      "arxiv_id": "2401.04336v3",
      "title": "Deep Efficient Private Neighbor Generation for Subgraph Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Zhang",
        "Lichao Sun",
        "Bolin Ding",
        "Siu Ming Yiu",
        "Carl Yang"
      ],
      "abstract": "Behemoth graphs are often fragmented and separately stored by multiple data\nowners as distributed subgraphs in many realistic applications. Without harming\ndata privacy, it is natural to consider the subgraph federated learning\n(subgraph FL) scenario, where each local client holds a subgraph of the entire\nglobal graph, to obtain globally generalized graph mining models. To overcome\nthe unique challenge of incomplete information propagation on local subgraphs\ndue to missing cross-subgraph neighbors, previous works resort to the\naugmentation of local neighborhoods through the joint FL of missing neighbor\ngenerators and GNNs. Yet their technical designs have profound limitations\nregarding the utility, efficiency, and privacy goals of FL. In this work, we\npropose FedDEP to comprehensively tackle these challenges in subgraph FL.\nFedDEP consists of a series of novel technical designs: (1) Deep neighbor\ngeneration through leveraging the GNN embeddings of potential missing\nneighbors; (2) Efficient pseudo-FL for neighbor generation through embedding\nprototyping; and (3) Privacy protection through noise-less\nedge-local-differential-privacy. We analyze the correctness and efficiency of\nFedDEP, and provide theoretical guarantees on its privacy. Empirical results on\nfour real-world datasets justify the clear benefits of proposed techniques.",
      "tldr_zh": "本研究针对子图联邦学习（subgraph Federated Learning）中的挑战，提出FedDEP框架，以生成缺失邻居并解决信息传播不完整问题，同时兼顾效用、效率和隐私。FedDEP的关键创新包括：利用GNN embeddings进行深度邻居生成、通过嵌入原型化实现高效的伪联邦学习（pseudo-FL）、以及采用无噪声的edge-local-differential-privacy机制保护隐私。实验结果在四个真实数据集上显示，FedDEP显著提升了模型性能，并提供了理论上的正确性、效率和隐私保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to SDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04336v3",
      "published_date": "2024-01-09 03:29:40 UTC",
      "updated_date": "2024-01-19 01:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:48:58.627735"
    },
    {
      "arxiv_id": "2401.04334v1",
      "title": "Large Language Models for Robotics: Opportunities, Challenges, and Perspectives",
      "title_zh": "大型语言模型在机器人学中的机会、挑战与展望",
      "authors": [
        "Jiaqi Wang",
        "Zihao Wu",
        "Yiwei Li",
        "Hanqi Jiang",
        "Peng Shu",
        "Enze Shi",
        "Huawen Hu",
        "Chong Ma",
        "Yiheng Liu",
        "Xuhui Wang",
        "Yincheng Yao",
        "Xuan Liu",
        "Huaqin Zhao",
        "Zhengliang Liu",
        "Haixing Dai",
        "Lin Zhao",
        "Bao Ge",
        "Xiang Li",
        "Tianming Liu",
        "Shu Zhang"
      ],
      "abstract": "Large language models (LLMs) have undergone significant expansion and have\nbeen increasingly integrated across various domains. Notably, in the realm of\nrobot task planning, LLMs harness their advanced reasoning and language\ncomprehension capabilities to formulate precise and efficient action plans\nbased on natural language instructions. However, for embodied tasks, where\nrobots interact with complex environments, text-only LLMs often face challenges\ndue to a lack of compatibility with robotic visual perception. This study\nprovides a comprehensive overview of the emerging integration of LLMs and\nmultimodal LLMs into various robotic tasks. Additionally, we propose a\nframework that utilizes multimodal GPT-4V to enhance embodied task planning\nthrough the combination of natural language instructions and robot visual\nperceptions. Our results, based on diverse datasets, indicate that GPT-4V\neffectively enhances robot performance in embodied tasks. This extensive survey\nand evaluation of LLMs and multimodal LLMs across a variety of robotic tasks\nenriches the understanding of LLM-centric embodied intelligence and provides\nforward-looking insights toward bridging the gap in Human-Robot-Environment\ninteraction.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在机器人领域的机会、挑战和展望，强调LLMs在任务规划中的推理和语言理解能力，但指出其在处理涉及视觉感知的实体任务时存在兼容性问题。作者提出一个框架，利用多模态GPT-4V结合自然语言指令和机器人视觉感知来增强任务规划。实验基于多样数据集，结果显示GPT-4V显著提高了机器人性能，并为桥接人类-机器人-环境互动提供了宝贵的见解和前瞻性洞察。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04334v1",
      "published_date": "2024-01-09 03:22:16 UTC",
      "updated_date": "2024-01-09 03:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:49:11.016215"
    },
    {
      "arxiv_id": "2401.04331v2",
      "title": "Coupling Graph Neural Networks with Fractional Order Continuous Dynamics: A Robustness Study",
      "title_zh": "将图神经网络与分数阶连续动力学耦合：稳健性研究",
      "authors": [
        "Qiyu Kang",
        "Kai Zhao",
        "Yang Song",
        "Yihang Xie",
        "Yanan Zhao",
        "Sijie Wang",
        "Rui She",
        "Wee Peng Tay"
      ],
      "abstract": "In this work, we rigorously investigate the robustness of graph neural\nfractional-order differential equation (FDE) models. This framework extends\nbeyond traditional graph neural (integer-order) ordinary differential equation\n(ODE) models by implementing the time-fractional Caputo derivative. Utilizing\nfractional calculus allows our model to consider long-term memory during the\nfeature updating process, diverging from the memoryless Markovian updates seen\nin traditional graph neural ODE models. The superiority of graph neural FDE\nmodels over graph neural ODE models has been established in environments free\nfrom attacks or perturbations. While traditional graph neural ODE models have\nbeen verified to possess a degree of stability and resilience in the presence\nof adversarial attacks in existing literature, the robustness of graph neural\nFDE models, especially under adversarial conditions, remains largely\nunexplored. This paper undertakes a detailed assessment of the robustness of\ngraph neural FDE models. We establish a theoretical foundation outlining the\nrobustness characteristics of graph neural FDE models, highlighting that they\nmaintain more stringent output perturbation bounds in the face of input and\ngraph topology disturbances, compared to their integer-order counterparts. Our\nempirical evaluations further confirm the enhanced robustness of graph neural\nFDE models, highlighting their potential in adversarially robust applications.",
      "tldr_zh": "本研究探讨了Graph Neural Networks与分数阶连续动力学的结合，特别是图神经分数阶微分方程（FDE）模型的鲁棒性，通过引入时间分数阶Caputo导数来实现特征更新的长期记忆机制，与传统无记忆的图神经ODE模型形成对比。论文建立了理论基础，证明FDE模型在输入和图拓扑扰动下具有更严格的输出扰动边界，从而比整数阶模型更具优势。经验评估进一步证实了FDE模型的增强鲁棒性，表明其在对抗性应用中具有较大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "in Proc. AAAI Conference on Artificial Intelligence, Vancouver,\n  Canada, Feb. 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04331v2",
      "published_date": "2024-01-09 02:56:52 UTC",
      "updated_date": "2024-03-04 05:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:49:23.406995"
    },
    {
      "arxiv_id": "2401.04330v2",
      "title": "BD-MSA: Body decouple VHR Remote Sensing Image Change Detection method guided by multi-scale feature information aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghui Tan",
        "Xiaolong Li",
        "Yishu Chen",
        "Jinquan Ai"
      ],
      "abstract": "The purpose of remote sensing image change detection (RSCD) is to detect\ndifferences between bi-temporal images taken at the same place. Deep learning\nhas been extensively used to RSCD tasks, yielding significant results in terms\nof result recognition. However, due to the shooting angle of the satellite, the\nimpacts of thin clouds, and certain lighting conditions, the problem of fuzzy\nedges in the change region in some remote sensing photographs cannot be\nproperly handled using current RSCD algorithms. To solve this issue, we\nproposed a Body Decouple Multi-Scale by fearure Aggregation change detection\n(BD-MSA), a novel model that collects both global and local feature map\ninformation in the channel and space dimensions of the feature map during the\ntraining and prediction phases. This approach allows us to successfully extract\nthe change region's boundary information while also divorcing the change\nregion's main body from its boundary. Numerous studies have shown that the\nassessment metrics and evaluation effects of the model described in this paper\non the publicly available datasets DSIFN-CD, S2Looking and WHU-CD are the best\nwhen compared to other models.",
      "tldr_zh": "该研究针对遥感图像变化检测（RSCD）中变化区域边缘模糊的问题，提出了一种新方法 BD-MSA（Body Decouple Multi-Scale by Feature Aggregation）。该方法通过在特征图的通道和空间维度聚合多尺度特征信息，实现变化区域主体与边界的分离，从而有效提取全局和局部边界细节。实验结果显示，BD-MSA 在公开数据集 DSIFN-CD、S2Looking 和 WHU-CD 上，评估指标和整体效果优于其他模型，显著提高了 VHR Remote Sensing Image 的变化检测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04330v2",
      "published_date": "2024-01-09 02:53:06 UTC",
      "updated_date": "2024-03-03 08:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:49:34.078850"
    },
    {
      "arxiv_id": "2401.04319v3",
      "title": "Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Wang",
        "Dan Yang",
        "Binbin Hu",
        "Yue Shen",
        "Wen Zhang",
        "Jinjie Gu"
      ],
      "abstract": "In this paper, we explore a new way for user targeting, where non-expert\nmarketers could select their target users solely given demands in natural\nlanguage form. The key to this issue is how to transform natural languages into\npractical structured logical languages, i.e., the structured understanding of\nmarketer demands. In practical scenarios, the demands of non-expert marketers\nare often abstract and diverse. Considering the impressive natural language\nprocessing ability of large language models (LLMs), we try to leverage LLMs to\nsolve this issue. To stimulate the LLMs' reasoning ability, the\nchain-of-thought (CoT) prompting method is widely used, but existing methods\nstill have some limitations in our scenario: (1) Previous methods either use\nsimple \"Let's think step by step\" spells or provide fixed examples in\ndemonstrations without considering compatibility between prompts and concrete\nquestions, making LLMs ineffective when the marketers' demands are abstract and\ndiverse. (2) Previous methods are often implemented in closed-source models or\nexcessively large models, which is not suitable in industrial practical\nscenarios. Based on these, we propose ARALLM (i.e., Analogical Reasoning\nAugmented Large Language Models) consisting of two modules: Analogical\nReasoning based Prompting and Reasoning-Augmented Multi-Task Model\nDistillation. Part of our data and code can be found at\nhttps://github.com/alipay/Analogic-Reasoning-Augmented-Large-Language-Model.",
      "tldr_zh": "本论文探讨如何将非专家营销人员的自然语言需求转化为结构化的逻辑语言，以实现高效的用户定位。针对现有Chain-of-Thought (CoT)方法的局限，如提示不兼容抽象多样需求和不适合工业场景，作者提出ARALLM框架，包括Analogical Reasoning based Prompting模块和Reasoning-Augmented Multi-Task Model Distillation模块，以增强LLMs的推理能力。实验结果表明，该框架能更好地处理多样化需求，为实际营销应用提供更可靠的结构化理解解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.04319v3",
      "published_date": "2024-01-09 02:25:23 UTC",
      "updated_date": "2024-06-12 03:02:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:49:45.457052"
    },
    {
      "arxiv_id": "2401.04737v1",
      "title": "Music Genre Classification: A Comparative Analysis of CNN and XGBoost Approaches with Mel-frequency cepstral coefficients and Mel Spectrograms",
      "title_zh": "翻译失败",
      "authors": [
        "Yigang Meng"
      ],
      "abstract": "In recent years, various well-designed algorithms have empowered music\nplatforms to provide content based on one's preferences. Music genres are\ndefined through various aspects, including acoustic features and cultural\nconsiderations. Music genre classification works well with content-based\nfiltering, which recommends content based on music similarity to users. Given a\nconsiderable dataset, one premise is automatic annotation using machine\nlearning or deep learning methods that can effectively classify audio files.\nThe effectiveness of systems largely depends on feature and model selection, as\ndifferent architectures and features can facilitate each other and yield\ndifferent results. In this study, we conduct a comparative study investigating\nthe performances of three models: a proposed convolutional neural network\n(CNN), the VGG16 with fully connected layers (FC), and an eXtreme Gradient\nBoosting (XGBoost) approach on different features: 30-second Mel spectrogram\nand 3-second Mel-frequency cepstral coefficients (MFCCs). The results show that\nthe MFCC XGBoost model outperformed the others. Furthermore, applying data\nsegmentation in the data preprocessing phase can significantly enhance the\nperformance of the CNNs.",
      "tldr_zh": "本研究比较了 CNN 和 XGBoost 等模型在音乐流派分类中的性能，使用 Mel spectrogram 和 MFCCs 作为音频特征。研究者评估了自定义 CNN、VGG16 以及 XGBoost 三种方法在 30-second Mel spectrogram 和 3-second MFCCs 数据上的表现。结果显示，MFCCs 与 XGBoost 组合的模型表现出色，且通过数据 segmentation 在预处理阶段能显著提升 CNN 的准确率。总的来说，此工作为基于机器学习的内容推荐系统提供了有益的见解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.04737v1",
      "published_date": "2024-01-09 01:50:31 UTC",
      "updated_date": "2024-01-09 01:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:49:57.430583"
    },
    {
      "arxiv_id": "2401.06796v1",
      "title": "AI Hallucinations: A Misnomer Worth Clarifying",
      "title_zh": "翻译失败",
      "authors": [
        "Negar Maleki",
        "Balaji Padmanabhan",
        "Kaushik Dutta"
      ],
      "abstract": "As large language models continue to advance in Artificial Intelligence (AI),\ntext generation systems have been shown to suffer from a problematic phenomenon\ntermed often as \"hallucination.\" However, with AI's increasing presence across\nvarious domains including medicine, concerns have arisen regarding the use of\nthe term itself. In this study, we conducted a systematic review to identify\npapers defining \"AI hallucination\" across fourteen databases. We present and\nanalyze definitions obtained across all databases, categorize them based on\ntheir applications, and extract key points within each category. Our results\nhighlight a lack of consistency in how the term is used, but also help identify\nseveral alternative terms in the literature. We discuss implications of these\nand call for a more unified effort to bring consistency to an important\ncontemporary AI issue that can affect multiple domains significantly.",
      "tldr_zh": "该研究审视了“AI hallucination”这一术语的不一致使用问题，通过在14个数据库中进行系统审查(systematic review)，识别并分析了相关论文的定义，并根据应用领域进行分类。结果显示，术语定义缺乏统一性，同时发现了诸如其他替代术语的存在，这可能对医学等多个领域产生重大影响。作者呼吁采取更统一的努力，以解决这一当代AI问题，确保术语的使用更具一致性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.06796v1",
      "published_date": "2024-01-09 01:49:41 UTC",
      "updated_date": "2024-01-09 01:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:50:09.519042"
    },
    {
      "arxiv_id": "2401.04290v1",
      "title": "StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For Multi-Agent Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sean Kulinski",
        "Nicholas R. Waytowich",
        "James Z. Hare",
        "David I. Inouye"
      ],
      "abstract": "Spatial reasoning tasks in multi-agent environments such as event prediction,\nagent type identification, or missing data imputation are important for\nmultiple applications (e.g., autonomous surveillance over sensor networks and\nsubtasks for reinforcement learning (RL)). StarCraft II game replays encode\nintelligent (and adversarial) multi-agent behavior and could provide a testbed\nfor these tasks; however, extracting simple and standardized representations\nfor prototyping these tasks is laborious and hinders reproducibility. In\ncontrast, MNIST and CIFAR10, despite their extreme simplicity, have enabled\nrapid prototyping and reproducibility of ML methods. Following the simplicity\nof these datasets, we construct a benchmark spatial reasoning dataset based on\nStarCraft II replays that exhibit complex multi-agent behaviors, while still\nbeing as easy to use as MNIST and CIFAR10. Specifically, we carefully summarize\na window of 255 consecutive game states to create 3.6 million summary images\nfrom 60,000 replays, including all relevant metadata such as game outcome and\nplayer races. We develop three formats of decreasing complexity: Hyperspectral\nimages that include one channel for every unit type (similar to multispectral\ngeospatial images), RGB images that mimic CIFAR10, and grayscale images that\nmimic MNIST. We show how this dataset can be used for prototyping spatial\nreasoning methods. All datasets, code for extraction, and code for dataset\nloading can be found at https://starcraftdata.davidinouye.com",
      "tldr_zh": "本研究引入了 StarCraftImage 数据集，用于原型化多智能体环境中的 spatial reasoning 方法，如事件预测、代理类型识别和缺失数据插补，这些任务对自主监控和 reinforcement learning (RL) 子任务至关重要。作者从 StarCraft II 游戏重播中提取数据，将 60,000 个重播总结为 3.6 百万张摘要图像，每个图像基于 255 个连续游戏状态，并包含元数据如游戏结果和玩家种族。数据集提供三种格式：Hyperspectral images（每个单位类型一个通道，类似多光谱地理图像）、RGB images（模仿 CIFAR10）和 grayscale images（模仿 MNIST），以实现简单易用和再现性。实验展示了该数据集如何促进 spatial reasoning 方法的快速原型化，并提供了相关代码和链接以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in CVPR 23'",
      "pdf_url": "http://arxiv.org/pdf/2401.04290v1",
      "published_date": "2024-01-09 00:05:56 UTC",
      "updated_date": "2024-01-09 00:05:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T20:50:23.344205"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 68,
  "processed_papers_count": 68,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T20:50:50.198170"
}