{
  "date": "2025-01-09",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-09 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文聚焦于 AI 安全、多模态理解、LLM 优化和应用创新等领域，亮点包括 Yarin Gal 等知名学者对 AI 安全问题的探讨，以及 Jitendra Malik 在视频预训练和机器人领域的贡献，强调了模型鲁棒性、可解释性和高效计算的趋势。\n\n下面，我挑选并简要讨论了部分重要论文，先从 AI 安全和 LLM 相关主题入手，再聊多模态和计算机视觉领域的内容。对于其他论文，我会快速掠过，只突出核心点。\n\n1. **Watermarking Graph Neural Networks via Explanations for Ownership Protection（基于解释的水印技术保护图神经网络所有权）**  \n   作者包括 Binghui Wang，这篇论文提出了一种基于解释的水印方法，用于保护图神经网络（GNNs）的知识产权。它避免了传统后门方法的数据污染，通过在 GNN 解释中嵌入统计显著的水印，并证明水印定位是 NP-hard 问题。主要贡献是提升了 GNNs 的鲁棒性，对模型盗用攻击有较强抵抗力。\n\n2. **Advancing Personalized Learning Analysis via an Innovative Domain Knowledge Informed Attention-based Knowledge Tracing Method（通过创新的领域知识告知注意力机制推进个性化学习分析）**  \n   这篇论文引入注意力机制和领域知识（如知识概念路径），改进了知识追踪模型，使用 XES3G5M 数据集评估，显著提升了学生学习预测的准确性。主要发现是，考虑知识间依赖能更好地理解学习结果，适用于教育 AI。\n\n3. **Vision-Language Models for Autonomous Driving: CLIP-Based Dynamic Scene Understanding（基于 CLIP 的视觉-语言模型用于自动驾驶的动态场景理解）**  \n   作者团队包括 Andry Rakotonirainy，这篇工作使用 CLIP 模型优化自动驾驶场景理解，在 Honda Scenes 数据集上实现了 91.1% 的 F1 分数，超越 GPT-4o。主要贡献是提升了实时场景识别和安全性，为高级驾驶辅助系统提供了可扩展框架。\n\n4. **Soup to go: mitigating forgetting during continual learning with model averaging（通过模型平均缓解持续学习中的遗忘问题）**  \n   作者包括 Jonathan Frankle，这篇论文提出 Sequential Fine-tuning with Averaging (SFA) 方法，在不存储历史数据的情况下减少灾难性遗忘，适用于图像和语言领域。主要发现是，SFA 在多种基准上优于传统方法，如 Task Arithmetic。\n\n5. **Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence（通过整合视觉对应提升零样本物体级变化检测）**  \n   这篇论文解决变化检测中的假阳性问题，使用匈牙利算法和同源矩阵预测变化对应点，在零样本基准上达到最先进性能。主要贡献是提升了检测准确性和泛化能力，适用于视觉检查任务。\n\n6. **LLMQuoter: Enhancing RAG Capabilities Through Efficient Quote Extraction From Large Contexts（通过高效引用提取增强检索增强生成能力）**  \n   论文提出 LLMQuoter 模型，使用知识蒸馏从大上下文提取关键引用，提升 RAG 准确性 20 点以上。主要发现是，引用优先策略简化了复杂工作流，适用于资源受限的场景。\n\n7. **The dynamics of meaning through time: Assessment of Large Language Models（通过时间动态评估大型语言模型的语义演变）**  \n   作者包括 Mohamed Medhat Gaber，这篇工作评估 LLMs（如 GPT-4）对历史语义的理解，使用主观和客观指标分析语义演变。主要贡献是揭示 LLMs 在历史文本分析中的优势和局限。\n\n8. **Explore Activation Sparsity in Recurrent LLMs for Energy-Efficient Neuromorphic Computing（探索循环 LLMs 中的激活稀疏性以实现能量高效的神经形态计算）**  \n   这篇论文提出无训练算法稀疏化循环 LLMs 的激活，显著降低计算需求，同时保持准确性。主要发现是，在神经形态硬件上实现高效部署，适用于边缘计算。\n\n9. **OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?（OVO-Bench: 评估视频LLMs与真实在线视频理解的差距）**  \n   论文介绍 OVO-Bench 基准，测试视频 LLMs 的时间感知能力，包括追溯、实时和前向响应场景。主要贡献是暴露了当前模型在在线视频理解中的不足，推动视频 AI 研究。\n\n10. **An Empirical Study of Autoregressive Pre-training from Videos（基于视频的自回归预训练的实证研究）**  \n    作者包括 Jitendra Malik，这篇工作构建 Toto 模型，使用自回归方法预训练视频序列，适用于图像识别和机器人任务。主要发现是，自回归预训练在各种基准上表现出色，并展示了与语言模型相似的缩放规律。\n\n其他论文中，如 **Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces（渐进式增长视频标记器以实现高度压缩的潜在空间）** 和 **From Simple to Complex Skills: The Case of In-Hand Object Reorientation（从简单到复杂技能：手持物体重定向案例）**，它们在视频处理和机器人领域有创新，但相对次要，我这里快速提到：前者优化了视频压缩，后者使用分层策略提升机器人操作鲁棒性。\n\n剩余论文涉及生物医学（如 Atlas: A Novel Pathology Foundation Model）、强化学习（如 Strategy Masking）和其他领域，我仅简要掠过，因为它们主题较分散或影响力较小。例如，**Open Problems in Machine Unlearning for AI Safety（AI 安全中机器遗忘技术的开放问题）** 由 Yarin Gal 参与，讨论了遗忘在 AI 安全中的挑战，但未有新方法实现。\n\n总之，今天的论文展示了 AI 领域的多样性与深度，AI 安全和多模态技术是值得关注的热点，期待后续研究进一步推动这些领域的发展！",
  "papers": [
    {
      "arxiv_id": "2501.05614v1",
      "title": "Watermarking Graph Neural Networks via Explanations for Ownership Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Jane Downer",
        "Ren Wang",
        "Binghui Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) are the mainstream method to learn pervasive\ngraph data and are widely deployed in industry, making their intellectual\nproperty valuable. However, protecting GNNs from unauthorized use remains a\nchallenge. Watermarking, which embeds ownership information into a model, is a\npotential solution. However, existing watermarking methods have two key\nlimitations: First, almost all of them focus on non-graph data, with\nwatermarking GNNs for complex graph data largely unexplored. Second, the de\nfacto backdoor-based watermarking methods pollute training data and induce\nownership ambiguity through intentional misclassification. Our\nexplanation-based watermarking inherits the strengths of backdoor-based methods\n(e.g., robust to watermark removal attacks), but avoids data pollution and\neliminates intentional misclassification. In particular, our method learns to\nembed the watermark in GNN explanations such that this unique watermark is\nstatistically distinct from other potential solutions, and ownership claims\nmust show statistical significance to be verified. We theoretically prove that,\neven with full knowledge of our method, locating the watermark is an NP-hard\nproblem. Empirically, our method manifests robustness to removal attacks like\nfine-tuning and pruning. By addressing these challenges, our approach marks a\nsignificant advancement in protecting GNN intellectual property.",
      "tldr_zh": "本研究针对Graph Neural Networks (GNNs) 的知识产权保护问题，提出了一种基于解释(explanations)的水印方法，以解决现有backdoor-based watermarking 方法的局限，如数据污染和故意误分类。该方法将水印嵌入GNN解释中，使其在统计上与其它解决方案显著不同，并要求所有权验证显示统计显著性，从而避免了传统方法的缺点。理论上，该方法证明了即使完全了解技术，定位水印也是NP-hard问题；实验结果显示，它对移除攻击如fine-tuning和pruning表现出鲁棒性，为GNN知识产权保护提供了重大进展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05614v1",
      "published_date": "2025-01-09 23:25:06 UTC",
      "updated_date": "2025-01-09 23:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:44:41.582871"
    },
    {
      "arxiv_id": "2501.05605v1",
      "title": "Advancing Personalized Learning Analysis via an Innovative Domain Knowledge Informed Attention-based Knowledge Tracing Method",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Kose",
        "Jin Wei-Kocsis"
      ],
      "abstract": "Emerging Knowledge Tracing (KT) models, particularly deep learning and\nattention-based Knowledge Tracing, have shown great potential in realizing\npersonalized learning analysis via prediction of students' future performance\nbased on their past interactions. The existing methods mainly focus on\nimmediate past interactions or individual concepts without accounting for\ndependencies between knowledge concept, referred as knowledge concept routes,\nthat can be critical to advance the understanding the students' learning\noutcomes. To address this, in this paper, we propose an innovative\nattention-based method by effectively incorporating the domain knowledge of\nknowledge concept routes in the given curriculum. Additionally, we leverage\nXES3G5M dataset, a benchmark dataset with rich auxiliary information for\nknowledge concept routes, to evaluate and compare the performance of our\nproposed method to the seven State-of-the-art (SOTA) deep learning models.",
      "tldr_zh": "本研究指出，现有的 Knowledge Tracing (KT) 模型在预测学生未来表现时，主要关注过去互动或单个知识概念，而忽略了知识概念之间的依赖关系（knowledge concept routes）。为此，作者提出了一种创新的 attention-based KT 方法，通过整合课程中的 domain knowledge of knowledge concept routes 来提升个性化学习分析的准确性。实验使用 XES3G5M 数据集对该方法与七个 SOTA 深度学习模型进行比较，结果显示其在理解学生学习成果方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05605v1",
      "published_date": "2025-01-09 22:41:50 UTC",
      "updated_date": "2025-01-09 22:41:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:44:53.265199"
    },
    {
      "arxiv_id": "2501.05567v1",
      "title": "Approximate Supervised Object Distance Estimation on Unmanned Surface Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Kiefer",
        "Yitong Quan",
        "Andreas Zell"
      ],
      "abstract": "Unmanned surface vehicles (USVs) and boats are increasingly important in\nmaritime operations, yet their deployment is limited due to costly sensors and\ncomplexity. LiDAR, radar, and depth cameras are either costly, yield sparse\npoint clouds or are noisy, and require extensive calibration. Here, we\nintroduce a novel approach for approximate distance estimation in USVs using\nsupervised object detection. We collected a dataset comprising images with\nmanually annotated bounding boxes and corresponding distance measurements.\nLeveraging this data, we propose a specialized branch of an object detection\nmodel, not only to detect objects but also to predict their distances from the\nUSV. This method offers a cost-efficient and intuitive alternative to\nconventional distance measurement techniques, aligning more closely with human\nestimation capabilities. We demonstrate its application in a marine assistance\nsystem that alerts operators to nearby objects such as boats, buoys, or other\nwaterborne hazards.",
      "tldr_zh": "该研究针对无人水面车辆 (USVs) 的距离估算问题，提出了一种基于监督对象检测的近似方法，以取代昂贵的传感器如 LiDAR、雷达和深度相机。研究团队收集了包含图像、手动标注边界框和距离测量的数据集，并开发了对象检测模型的专用分支，不仅能检测物体，还能预测其与 USV 的距离，提供一种经济直观且类似人类估计能力的替代方案。在实际应用中，该方法集成到海洋辅助系统中，用于警报附近物体如船只、浮标或其他水上危险。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05567v1",
      "published_date": "2025-01-09 20:34:36 UTC",
      "updated_date": "2025-01-09 20:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:45:05.829914"
    },
    {
      "arxiv_id": "2501.05566v1",
      "title": "Vision-Language Models for Autonomous Driving: CLIP-Based Dynamic Scene Understanding",
      "title_zh": "视觉语言模型用于自动驾驶：基于 CLIP 的动态场景理解",
      "authors": [
        "Mohammed Elhenawy",
        "Huthaifa I. Ashqar",
        "Andry Rakotonirainy",
        "Taqwa I. Alhadidi",
        "Ahmed Jaber",
        "Mohammad Abu Tami"
      ],
      "abstract": "Scene understanding is essential for enhancing driver safety, generating\nhuman-centric explanations for Automated Vehicle (AV) decisions, and leveraging\nArtificial Intelligence (AI) for retrospective driving video analysis. This\nstudy developed a dynamic scene retrieval system using Contrastive\nLanguage-Image Pretraining (CLIP) models, which can be optimized for real-time\ndeployment on edge devices. The proposed system outperforms state-of-the-art\nin-context learning methods, including the zero-shot capabilities of GPT-4o,\nparticularly in complex scenarios. By conducting frame-level analysis on the\nHonda Scenes Dataset, which contains a collection of about 80 hours of\nannotated driving videos capturing diverse real-world road and weather\nconditions, our study highlights the robustness of CLIP models in learning\nvisual concepts from natural language supervision. Results also showed that\nfine-tuning the CLIP models, such as ViT-L/14 and ViT-B/32, significantly\nimproved scene classification, achieving a top F1 score of 91.1%. These results\ndemonstrate the ability of the system to deliver rapid and precise scene\nrecognition, which can be used to meet the critical requirements of Advanced\nDriver Assistance Systems (ADAS). This study shows the potential of CLIP models\nto provide scalable and efficient frameworks for dynamic scene understanding\nand classification. Furthermore, this work lays the groundwork for advanced\nautonomous vehicle technologies by fostering a deeper understanding of driver\nbehavior, road conditions, and safety-critical scenarios, marking a significant\nstep toward smarter, safer, and more context-aware autonomous driving systems.",
      "tldr_zh": "这篇论文开发了一个基于CLIP（Contrastive Language-Image Pretraining）模型的动态场景检索系统，用于提升自动驾驶的安全性、生成人类中心化的决策解释，并支持AI驱动的驾驶视频分析。该系统在Honda Scenes Dataset（约80小时的标注驾驶视频）上进行帧级分析，优于现有方法如GPT-4o，尤其在复杂场景中，并通过微调ViT-L/14和ViT-B/32模型实现了91.1%的F1分数。研究证明了CLIP模型的鲁棒性，为Advanced Driver Assistance Systems (ADAS)提供快速精确的场景识别，并为更智能、安全的自动驾驶技术奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05566v1",
      "published_date": "2025-01-09 20:29:31 UTC",
      "updated_date": "2025-01-09 20:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:45:18.406684"
    },
    {
      "arxiv_id": "2501.05559v1",
      "title": "Soup to go: mitigating forgetting during continual learning with model averaging",
      "title_zh": "翻译失败",
      "authors": [
        "Anat Kleiman",
        "Gintare Karolina Dziugaite",
        "Jonathan Frankle",
        "Sham Kakade",
        "Mansheej Paul"
      ],
      "abstract": "In continual learning, where task data arrives in a sequence, fine-tuning on\nlater tasks will often lead to performance degradation on earlier tasks. This\nis especially pronounced when these tasks come from diverse domains. In this\nsetting, how can we mitigate catastrophic forgetting of earlier tasks and\nretain what the model has learned with minimal computational expenses? Inspired\nby other merging methods, and L2-regression, we propose Sequential Fine-tuning\nwith Averaging (SFA), a method that merges currently training models with\nearlier checkpoints during the course of training. SOTA approaches typically\nmaintain a data buffer of past tasks or impose a penalty at each gradient step.\nIn contrast, our method achieves comparable results without the need to store\npast data, or multiple copies of parameters for each gradient step.\nFurthermore, our method outperforms common merging techniques such as Task\nArithmetic, TIES Merging, and WiSE-FT, as well as other penalty methods like L2\nand Elastic Weight Consolidation. In turn, our method offers insight into the\nbenefits of merging partially-trained models during training across both image\nand language domains.",
      "tldr_zh": "在持续学习（continual learning）中，模型在后续任务上微调往往会导致早期任务的灾难性遗忘（catastrophic forgetting），本文提出Sequential Fine-tuning with Averaging (SFA)方法，通过在训练过程中将当前模型与早期检查点合并，来缓解这一问题，同时最小化计算开销。SFA无需存储过去任务数据或维护多个参数副本，便优于Task Arithmetic、TIES Merging和WiSE-FT等合并技术，以及L2和Elastic Weight Consolidation等惩罚方法。实验结果显示，SFA在图像和语言领域表现出色，并为合并部分训练模型提供了新的见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05559v1",
      "published_date": "2025-01-09 20:11:08 UTC",
      "updated_date": "2025-01-09 20:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:45:30.577982"
    },
    {
      "arxiv_id": "2501.05555v2",
      "title": "Improving Zero-Shot Object-Level Change Detection by Incorporating Visual Correspondence",
      "title_zh": "翻译失败",
      "authors": [
        "Hung Huy Nguyen",
        "Pooyan Rahmanzadehgervi",
        "Long Mai",
        "Anh Totti Nguyen"
      ],
      "abstract": "Detecting object-level changes between two images across possibly different\nviews is a core task in many applications that involve visual inspection or\ncamera surveillance. Existing change-detection approaches suffer from three\nmajor limitations: (1) lack of evaluation on image pairs that contain no\nchanges, leading to unreported false positive rates; (2) lack of\ncorrespondences (i.e., localizing the regions before and after a change); and\n(3) poor zero-shot generalization across different domains. To address these\nissues, we introduce a novel method that leverages change correspondences (a)\nduring training to improve change detection accuracy, and (b) at test time, to\nminimize false positives. That is, we harness the supervision labels of where\nan object is added or removed to supervise change detectors, improving their\naccuracy over previous work by a large margin. Our work is also the first to\npredict correspondences between pairs of detected changes using estimated\nhomography and the Hungarian algorithm. Our model demonstrates superior\nperformance over existing methods, achieving state-of-the-art results in change\ndetection and change correspondence accuracy across both in-distribution and\nzero-shot benchmarks.",
      "tldr_zh": "该论文旨在改善零样本（zero-shot）物体级变化检测，通过整合视觉对应关系（visual correspondence）来解决现有方法在假阳性率高、对应关系缺失和跨域泛化差的问题。\n新方法在训练阶段利用变化对应关系的监督标签来提升检测准确性，并在测试阶段通过估计的homography和Hungarian algorithm预测检测变化之间的对应关系，从而减少假阳性。\n实验结果表明，该模型在变化检测和对应关系准确性上大幅优于现有方法，并在分布内和零样本基准上实现了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05555v2",
      "published_date": "2025-01-09 20:02:10 UTC",
      "updated_date": "2025-01-16 16:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:45:43.031771"
    },
    {
      "arxiv_id": "2501.05554v1",
      "title": "LLMQuoter: Enhancing RAG Capabilities Through Efficient Quote Extraction From Large Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Yuri Facanha Bezerra",
        "Li Weigang"
      ],
      "abstract": "We introduce LLMQuoter, a lightweight, distillation-based model designed to\nenhance Retrieval Augmented Generation (RAG) by extracting the most relevant\ntextual evidence for downstream reasoning tasks. Built on the LLaMA-3B\narchitecture and fine-tuned with Low-Rank Adaptation (LoRA) on a 15,000-sample\nsubset of HotpotQA, LLMQuoter adopts a \"quote-first-then-answer\" strategy,\nefficiently identifying key quotes before passing curated snippets to reasoning\nmodels. This workflow reduces cognitive overhead and outperforms full-context\napproaches like Retrieval-Augmented Fine-Tuning (RAFT), achieving over 20-point\naccuracy gains across both small and large language models. By leveraging\nknowledge distillation from a high-performing teacher model, LLMQuoter achieves\ncompetitive results in a resource-efficient fine-tuning setup. It democratizes\nadvanced RAG capabilities, delivering significant performance improvements\nwithout requiring extensive model retraining. Our results highlight the\npotential of distilled quote-based reasoning to streamline complex workflows,\noffering a scalable and practical solution for researchers and practitioners\nalike.",
      "tldr_zh": "本研究引入LLMQuoter，一种轻量级的基于蒸馏的模型，用于提升Retrieval Augmented Generation (RAG)能力，通过高效提取大型上下文中的关键引文。模型基于LLaMA-3B架构，使用Low-Rank Adaptation (LoRA)在HotpotQA的15,000样本子集上微调，采用\"quote-first-then-answer\"策略，先识别核心引文再传递给推理模型，从而减少认知开销。实验结果显示，LLMQuoter相较于Retrieval-Augmented Fine-Tuning (RAFT)等全上下文方法，在小和大语言模型上准确率提升超过20点，并通过知识蒸馏实现资源高效的微调，提供可扩展的RAG解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05554v1",
      "published_date": "2025-01-09 20:01:15 UTC",
      "updated_date": "2025-01-09 20:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:45:54.224535"
    },
    {
      "arxiv_id": "2501.05552v1",
      "title": "The dynamics of meaning through time: Assessment of Large Language Models",
      "title_zh": "意义的历时动态：大型语言模型的评估",
      "authors": [
        "Mohamed Taher Alrefaie",
        "Fatty Salem",
        "Nour Eldin Morsy",
        "Nada Samir",
        "Mohamed Medhat Gaber"
      ],
      "abstract": "Understanding how large language models (LLMs) grasp the historical context\nof concepts and their semantic evolution is essential in advancing artificial\nintelligence and linguistic studies. This study aims to evaluate the\ncapabilities of various LLMs in capturing temporal dynamics of meaning,\nspecifically how they interpret terms across different time periods. We analyze\na diverse set of terms from multiple domains, using tailored prompts and\nmeasuring responses through both objective metrics (e.g., perplexity and word\ncount) and subjective human expert evaluations. Our comparative analysis\nincludes prominent models like ChatGPT, GPT-4, Claude, Bard, Gemini, and Llama.\nFindings reveal marked differences in each model's handling of historical\ncontext and semantic shifts, highlighting both strengths and limitations in\ntemporal semantic understanding. These insights offer a foundation for refining\nLLMs to better address the evolving nature of language, with implications for\nhistorical text analysis, AI design, and applications in digital humanities.",
      "tldr_zh": "这篇论文评估了Large Language Models (LLMs) 在理解概念历史背景和语义演变的能力，重点分析这些模型如何处理不同时间段的术语变化。研究采用定制提示、客观指标（如perplexity和word count）以及主观人类专家评估，对ChatGPT、GPT-4、Claude、Bard、Gemini和Llama等模型进行比较分析。结果显示，各模型在捕捉历史语义动态方面存在显著差异，突显了它们的优势和局限性，为优化LLMs以适应语言演变提供基础，并应用于历史文本分析、AI设计和数字人文领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05552v1",
      "published_date": "2025-01-09 19:56:44 UTC",
      "updated_date": "2025-01-09 19:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:46:05.369942"
    },
    {
      "arxiv_id": "2501.16337v1",
      "title": "Explore Activation Sparsity in Recurrent LLMs for Energy-Efficient Neuromorphic Computing",
      "title_zh": "探索循环 LLMs 中的激活稀疏性以实现能量高效的神经形态计算",
      "authors": [
        "Ivan Knunyants",
        "Maryam Tavakol",
        "Manolis Sifalakis",
        "Yingfu Xu",
        "Amirreza Yousefzadeh",
        "Guangzhi Tang"
      ],
      "abstract": "The recent rise of Large Language Models (LLMs) has revolutionized the deep\nlearning field. However, the desire to deploy LLMs on edge devices introduces\nenergy efficiency and latency challenges. Recurrent LLM (R-LLM) architectures\nhave proven effective in mitigating the quadratic complexity of self-attention,\nmaking them a potential paradigm for computing on-edge neuromorphic processors.\nIn this work, we propose a low-cost, training-free algorithm to sparsify\nR-LLMs' activations to enhance energy efficiency on neuromorphic hardware. Our\napproach capitalizes on the inherent structure of these models, rendering them\nwell-suited for energy-constrained environments. Although primarily designed\nfor R-LLMs, this method can be generalized to other LLM architectures, such as\ntransformers, as demonstrated on the OPT model, achieving comparable sparsity\nand efficiency improvements. Empirical studies illustrate that our method\nsignificantly reduces computational demands while maintaining competitive\naccuracy across multiple zero-shot learning benchmarks. Additionally, hardware\nsimulations with the SENECA neuromorphic processor underscore notable energy\nsavings and latency improvements. These results pave the way for low-power,\nreal-time neuromorphic deployment of LLMs and demonstrate the feasibility of\ntraining-free on-chip adaptation using activation sparsity.",
      "tldr_zh": "这篇论文探讨了在循环大型语言模型 (R-LLMs) 中激活稀疏化 (activation sparsity) 的应用，以提升神经形态计算 (neuromorphic computing) 的能源效率。研究提出了一种低成本、无需训练的算法，利用 R-LLMs 的固有结构来稀疏化模型激活，从而减少计算需求，同时保持在多个零样本学习基准上的竞争性准确率。该方法不仅适用于 R-LLMs，还可推广到其他架构如 transformers（例如在 OPT 模型上验证），并通过 SENECA 神经形态处理器模拟，展示了显著的能源节约和延迟改善。这些结果为低功耗、实时边缘部署的 LLMs 铺平了道路。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by AICAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16337v1",
      "published_date": "2025-01-09 19:13:03 UTC",
      "updated_date": "2025-01-09 19:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:46:18.633900"
    },
    {
      "arxiv_id": "2501.05510v2",
      "title": "OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?",
      "title_zh": "OVO-Bench：你的视频LLMs 距离真实世界的在线视频理解还有多远？",
      "authors": [
        "Yifei Li",
        "Junbo Niu",
        "Ziyang Miao",
        "Chunjiang Ge",
        "Yuanhang Zhou",
        "Qihao He",
        "Xiaoyi Dong",
        "Haodong Duan",
        "Shuangrui Ding",
        "Rui Qian",
        "Pan Zhang",
        "Yuhang Zang",
        "Yuhang Cao",
        "Conghui He",
        "Jiaqi Wang"
      ],
      "abstract": "Temporal Awareness, the ability to reason dynamically based on the timestamp\nwhen a question is raised, is the key distinction between offline and online\nvideo LLMs. Unlike offline models, which rely on complete videos for static,\npost hoc analysis, online models process video streams incrementally and\ndynamically adapt their responses based on the timestamp at which the question\nis posed. Despite its significance, temporal awareness has not been adequately\nevaluated in existing benchmarks. To fill this gap, we present OVO-Bench\n(Online-VideO-Benchmark), a novel video benchmark that emphasizes the\nimportance of timestamps for advanced online video understanding capability\nbenchmarking. OVO-Bench evaluates the ability of video LLMs to reason and\nrespond to events occurring at specific timestamps under three distinct\nscenarios: (1) Backward tracing: trace back to past events to answer the\nquestion. (2) Real-time understanding: understand and respond to events as they\nunfold at the current timestamp. (3) Forward active responding: delay the\nresponse until sufficient future information becomes available to answer the\nquestion accurately. OVO-Bench comprises 12 tasks, featuring 644 unique videos\nand approximately human-curated 2,800 fine-grained meta-annotations with\nprecise timestamps. We combine automated generation pipelines with human\ncuration. With these high-quality samples, we further developed an evaluation\npipeline to systematically query video LLMs along the video timeline.\nEvaluations of nine Video-LLMs reveal that, despite advancements on traditional\nbenchmarks, current models struggle with online video understanding, showing a\nsignificant gap compared to human agents. We hope OVO-Bench will drive progress\nin video LLMs and inspire future research in online video reasoning. Our\nbenchmark and code can be accessed at https://github.com/JoeLeelyf/OVO-Bench.",
      "tldr_zh": "该论文提出 OVO-Bench，一个新型基准测试，用于评估 Video-LLMs 在真实世界在线视频理解中的性能，强调 Temporal Awareness（时间意识）作为在线模型与离线模型的关键区别。OVO-Bench 涵盖三个场景——Backward tracing（回溯过去事件）、Real-time understanding（实时理解事件）和 Forward active responding（向前主动响应）——包括 12 个任务、644 个视频以及约 2800 个手动标注的时间戳，并结合自动化生成和人工整理的方法。实验评估了 9 个 Video-LLMs，发现这些模型在在线视频理解上显著落后于人类，尽管在传统基准上已有进步，从而推动了视频 LLM 的未来研究和发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05510v2",
      "published_date": "2025-01-09 19:00:01 UTC",
      "updated_date": "2025-03-27 17:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:46:30.150161"
    },
    {
      "arxiv_id": "2501.05453v1",
      "title": "An Empirical Study of Autoregressive Pre-training from Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Jathushan Rajasegaran",
        "Ilija Radosavovic",
        "Rahul Ravishankar",
        "Yossi Gandelsman",
        "Christoph Feichtenhofer",
        "Jitendra Malik"
      ],
      "abstract": "We empirically study autoregressive pre-training from videos. To perform our\nstudy, we construct a series of autoregressive video models, called Toto. We\ntreat videos as sequences of visual tokens and train transformer models to\nautoregressively predict future tokens. Our models are pre-trained on a diverse\ndataset of videos and images comprising over 1 trillion visual tokens. We\nexplore different architectural, training, and inference design choices. We\nevaluate the learned visual representations on a range of downstream tasks\nincluding image recognition, video classification, object tracking, and\nrobotics. Our results demonstrate that, despite minimal inductive biases,\nautoregressive pre-training leads to competitive performance across all\nbenchmarks. Finally, we find that scaling our video models results in similar\nscaling curves to those seen in language models, albeit with a different rate.\nMore details at https://brjathu.github.io/toto/",
      "tldr_zh": "本研究对视频的自回归预训练进行了经验性研究，构建了名为 Toto 的自回归视频模型，将视频视为视觉 tokens 序列，使用 Transformer 模型预测未来的 tokens。模型在超过 1 万亿视觉 tokens 的多样化视频和图像数据集上进行预训练，并探索了各种架构、训练和推理设计选择。在图像识别、视频分类、对象跟踪和机器人等下游任务上评估结果显示，尽管诱导偏差最小，该方法仍实现了与基准相当的竞争性性能。最后，研究发现扩展视频模型时，其缩放曲线类似于语言模型，但速率不同。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05453v1",
      "published_date": "2025-01-09 18:59:58 UTC",
      "updated_date": "2025-01-09 18:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:46:41.603241"
    },
    {
      "arxiv_id": "2501.05445v1",
      "title": "Consistent Flow Distillation for Text-to-3D Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Runjie Yan",
        "Yinbo Chen",
        "Xiaolong Wang"
      ],
      "abstract": "Score Distillation Sampling (SDS) has made significant strides in distilling\nimage-generative models for 3D generation. However, its\nmaximum-likelihood-seeking behavior often leads to degraded visual quality and\ndiversity, limiting its effectiveness in 3D applications. In this work, we\npropose Consistent Flow Distillation (CFD), which addresses these limitations.\nWe begin by leveraging the gradient of the diffusion ODE or SDE sampling\nprocess to guide the 3D generation. From the gradient-based sampling\nperspective, we find that the consistency of 2D image flows across different\nviewpoints is important for high-quality 3D generation. To achieve this, we\nintroduce multi-view consistent Gaussian noise on the 3D object, which can be\nrendered from various viewpoints to compute the flow gradient. Our experiments\ndemonstrate that CFD, through consistent flows, significantly outperforms\nprevious methods in text-to-3D generation.",
      "tldr_zh": "该研究针对 Score Distillation Sampling (SDS) 在文本到 3D 生成中的问题，如视觉质量和多样性下降，提出了一种新方法 Consistent Flow Distillation (CFD)。CFD 通过利用扩散 ODE 或 SDE 采样的梯度来指导 3D 生成，并强调 2D 图像流在不同视角的一致性。方法引入多视角一致的高斯噪声，对 3D 对象进行渲染以计算流梯度。实验结果显示，CFD 在文本到 3D 生成任务上显著优于现有方法，提高了生成质量和效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://runjie-yan.github.io/cfd/",
      "pdf_url": "http://arxiv.org/pdf/2501.05445v1",
      "published_date": "2025-01-09 18:56:05 UTC",
      "updated_date": "2025-01-09 18:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:46:53.400931"
    },
    {
      "arxiv_id": "2501.05443v1",
      "title": "A survey of textual cyber abuse detection using cutting-edge language models and large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Jose A. Diaz-Garcia",
        "Joao Paulo Carvalho"
      ],
      "abstract": "The success of social media platforms has facilitated the emergence of\nvarious forms of online abuse within digital communities. This abuse manifests\nin multiple ways, including hate speech, cyberbullying, emotional abuse,\ngrooming, and sexting. In this paper, we present a comprehensive analysis of\nthe different forms of abuse prevalent in social media, with a particular focus\non how emerging technologies, such as Language Models (LMs) and Large Language\nModels (LLMs), are reshaping both the detection and generation of abusive\ncontent within these networks. We delve into the mechanisms through which\nsocial media abuse is perpetuated, exploring the psychological and social\nimpact. Additionally, we examine the dual role of advanced language\nmodels-highlighting their potential to enhance automated detection systems for\nabusive behavior while also acknowledging their capacity to generate harmful\ncontent. This paper aims to contribute to the ongoing discourse on online\nsafety and ethics, offering insights into the evolving landscape of cyberabuse\nand the technological innovations that both mitigate and exacerbate it.",
      "tldr_zh": "这篇调查论文探讨了社交媒体上各种文本形式的网络滥用（如hate speech、网络bullying、emotional abuse等）的检测问题，重点分析了Language Models (LMs)和Large Language Models (LLMs)等先进技术如何重塑滥用内容的生成和识别。论文考察了这些滥用的心理、社会影响以及机制，并强调LLMs的双重作用：一方面提升自动化检测系统的效能，另一方面可能用于生成有害内容。最终，该研究为在线安全和伦理讨论提供见解，揭示了技术创新在缓解和加剧cyber abuse方面的复杂动态。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages, under review in WIREs Data Mining and Knowledge Discovery",
      "pdf_url": "http://arxiv.org/pdf/2501.05443v1",
      "published_date": "2025-01-09 18:55:50 UTC",
      "updated_date": "2025-01-09 18:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:47:04.875923"
    },
    {
      "arxiv_id": "2501.05442v1",
      "title": "Progressive Growing of Video Tokenizers for Highly Compressed Latent Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Aniruddha Mahapatra",
        "Long Mai",
        "Yitian Zhang",
        "David Bourgin",
        "Feng Liu"
      ],
      "abstract": "Video tokenizers are essential for latent video diffusion models, converting\nraw video data into spatiotemporally compressed latent spaces for efficient\ntraining. However, extending state-of-the-art video tokenizers to achieve a\ntemporal compression ratio beyond 4x without increasing channel capacity poses\nsignificant challenges. In this work, we propose an alternative approach to\nenhance temporal compression. We find that the reconstruction quality of\ntemporally subsampled videos from a low-compression encoder surpasses that of\nhigh-compression encoders applied to original videos. This indicates that\nhigh-compression models can leverage representations from lower-compression\nmodels. Building on this insight, we develop a bootstrapped\nhigh-temporal-compression model that progressively trains high-compression\nblocks atop well-trained lower-compression models. Our method includes a\ncross-level feature-mixing module to retain information from the pretrained\nlow-compression model and guide higher-compression blocks to capture the\nremaining details from the full video sequence. Evaluation of video benchmarks\nshows that our method significantly improves reconstruction quality while\nincreasing temporal compression compared to direct extensions of existing video\ntokenizers. Furthermore, the resulting compact latent space effectively trains\na video diffusion model for high-quality video generation with a reduced token\nbudget.",
      "tldr_zh": "本文提出了一种渐进式训练方法，用于提升视频分词器(video tokenizers)的时空压缩能力，旨在实现超过4x的时间压缩比而不增加通道容量。方法通过在训练良好的低压缩模型基础上，逐步添加并训练高压缩块，并引入交叉级别特征混合模块(cross-level feature-mixing module)来保留低压缩信息并捕获剩余视频细节。实验结果显示，该方法显著提高了视频重建质量，同时增强了时间压缩效果，并成功应用于视频扩散模型(video diffusion model)，实现了高质视频生成并降低了令牌预算。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Project website:\n  https://progressive-video-tokenizer.github.io/Pro-MAG/",
      "pdf_url": "http://arxiv.org/pdf/2501.05442v1",
      "published_date": "2025-01-09 18:55:15 UTC",
      "updated_date": "2025-01-09 18:55:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:47:18.342073"
    },
    {
      "arxiv_id": "2501.05439v1",
      "title": "From Simple to Complex Skills: The Case of In-Hand Object Reorientation",
      "title_zh": "从简单到复杂技能：手持物体重新定向的案例",
      "authors": [
        "Haozhi Qi",
        "Brent Yi",
        "Mike Lambeta",
        "Yi Ma",
        "Roberto Calandra",
        "Jitendra Malik"
      ],
      "abstract": "Learning policies in simulation and transferring them to the real world has\nbecome a promising approach in dexterous manipulation. However, bridging the\nsim-to-real gap for each new task requires substantial human effort, such as\ncareful reward engineering, hyperparameter tuning, and system identification.\nIn this work, we present a system that leverages low-level skills to address\nthese challenges for more complex tasks. Specifically, we introduce a\nhierarchical policy for in-hand object reorientation based on previously\nacquired rotation skills. This hierarchical policy learns to select which\nlow-level skill to execute based on feedback from both the environment and the\nlow-level skill policies themselves. Compared to learning from scratch, the\nhierarchical policy is more robust to out-of-distribution changes and transfers\neasily from simulation to real-world environments. Additionally, we propose a\ngeneralizable object pose estimator that uses proprioceptive information,\nlow-level skill predictions, and control errors as inputs to estimate the\nobject pose over time. We demonstrate that our system can reorient objects,\nincluding symmetrical and textureless ones, to a desired pose.",
      "tldr_zh": "本文提出一种利用低级技能构建复杂任务系统的框架，针对 dexterous manipulation 中的 sim-to-real gap 问题，焦点在于 in-hand object reorientation。系统引入一个基于先前获取的旋转技能的 hierarchical policy，该政策根据环境反馈和低级技能预测来选择执行技能，从而提升鲁棒性和转移效率。与从零学习相比，该方法更能适应分布外变化，并成功应用于现实环境。作者还开发了一个 generalizable object pose estimator，利用 proprioceptive information、低级技能预测和控制错误来实时估计物体姿势，证明了系统能精确重新定位对称和无纹理物体。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "website: https://dexhier.github.io",
      "pdf_url": "http://arxiv.org/pdf/2501.05439v1",
      "published_date": "2025-01-09 18:49:39 UTC",
      "updated_date": "2025-01-09 18:49:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:47:30.347945"
    },
    {
      "arxiv_id": "2501.05435v2",
      "title": "Neuro-Symbolic AI in 2024: A Systematic Review",
      "title_zh": "2024 年的神经符号 AI：系统综述",
      "authors": [
        "Brandon C. Colelough",
        "William Regli"
      ],
      "abstract": "Background: The field of Artificial Intelligence has undergone cyclical\nperiods of growth and decline, known as AI summers and winters. Currently, we\nare in the third AI summer, characterized by significant advancements and\ncommercialization, particularly in the integration of Symbolic AI and\nSub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI.\n  Methods: The review followed the PRISMA methodology, utilizing databases such\nas IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusion\ncriteria targeted peer-reviewed papers published between 2020 and 2024. Papers\nwere screened for relevance to Neuro-Symbolic AI, with further inclusion based\non the availability of associated codebases to ensure reproducibility.\n  Results: From an initial pool of 1,428 papers, 167 met the inclusion criteria\nand were analyzed in detail. The majority of research efforts are concentrated\nin the areas of learning and inference (63%), logic and reasoning (35%), and\nknowledge representation (44%). Explainability and trustworthiness are less\nrepresented (28%), with Meta-Cognition being the least explored area (5%). The\nreview identifies significant interdisciplinary opportunities, particularly in\nintegrating explainability and trustworthiness with other research areas.\n  Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, with\nconcentrated efforts in learning and inference. Significant gaps remain in\nexplainability, trustworthiness, and Meta-Cognition. Addressing these gaps\nthrough interdisciplinary research will be crucial for advancing the field\ntowards more intelligent, reliable, and context-aware AI systems.",
      "tldr_zh": "这篇论文对 2020-2024 年的 Neuro-Symbolic AI 研究进行了系统回顾，使用 PRISMA 方法从 IEEE Explore、Google Scholar 等数据库筛选了 167 篇同行评议论文，并优先考虑代码可用性以确保可重复性。结果显示，研究重点集中在学习和推理 (63%)、逻辑和推理 (35%) 以及知识表示 (44%) 等领域，而解释性 (28%) 和可信度较低，Meta-Cognition 仅占 5%。论文强调 Neuro-Symbolic AI 自 2020 年以来快速发展，但存在显著差距，并建议通过跨学科整合来推动 AI 向更智能、可靠和上下文感知系统发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.05435v2",
      "published_date": "2025-01-09 18:48:35 UTC",
      "updated_date": "2025-04-05 23:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:47:42.978820"
    },
    {
      "arxiv_id": "2501.05501v2",
      "title": "Strategy Masking: A Method for Guardrails in Value-based Reinforcement Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Keane",
        "Sam Keyser",
        "Jeremy Kedziora"
      ],
      "abstract": "The use of reward functions to structure AI learning and decision making is\ncore to the current reinforcement learning paradigm; however, without careful\ndesign of reward functions, agents can learn to solve problems in ways that may\nbe considered \"undesirable\" or \"unethical.\" Without thorough understanding of\nthe incentives a reward function creates, it can be difficult to impose\nprincipled yet general control mechanisms over its behavior. In this paper, we\nstudy methods for constructing guardrails for AI agents that use reward\nfunctions to learn decision making. We introduce a novel approach, which we\ncall strategy masking, to explicitly learn and then suppress undesirable AI\nagent behavior. We apply our method to study lying in AI agents and show that\nit can be used to effectively modify agent behavior by suppressing lying\npost-training without compromising agent ability to perform effectively.",
      "tldr_zh": "该论文探讨了强化学习（reinforcement learning）中奖励函数可能导致代理产生不期望或不道德行为的问题，如说谎。作者引入了一种新方法strategy masking，用于显式学习代理的不期望行为并在训练后抑制这些行为，同时保持代理的整体性能。实验结果显示，该方法在抑制AI代理的说谎行为方面非常有效，为构建可控的强化学习代理提供了原则性的守卫机制。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05501v2",
      "published_date": "2025-01-09 18:43:05 UTC",
      "updated_date": "2025-01-20 22:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:47:53.255650"
    },
    {
      "arxiv_id": "2501.05409v2",
      "title": "Atlas: A Novel Pathology Foundation Model by Mayo Clinic, Charité, and Aignostics",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Alber",
        "Stephan Tietz",
        "Jonas Dippel",
        "Timo Milbich",
        "Timothée Lesort",
        "Panos Korfiatis",
        "Moritz Krügener",
        "Beatriz Perez Cancer",
        "Neelay Shah",
        "Alexander Möllers",
        "Philipp Seegerer",
        "Alexandra Carpen-Amarie",
        "Kai Standvoss",
        "Gabriel Dernbach",
        "Edwin de Jong",
        "Simon Schallenberg",
        "Andreas Kunft",
        "Helmut Hoffer von Ankershoffen",
        "Gavin Schaeferle",
        "Patrick Duffy",
        "Matt Redlon",
        "Philipp Jurmeister",
        "David Horst",
        "Lukas Ruff",
        "Klaus-Robert Müller",
        "Frederick Klauschen",
        "Andrew Norgan"
      ],
      "abstract": "Recent advances in digital pathology have demonstrated the effectiveness of\nfoundation models across diverse applications. In this report, we present\nAtlas, a novel vision foundation model based on the RudolfV approach. Our model\nwas trained on a dataset comprising 1.2 million histopathology whole slide\nimages, collected from two medical institutions: Mayo Clinic and Charit\\'e -\nUniverst\\\"atsmedizin Berlin. Comprehensive evaluations show that Atlas achieves\nstate-of-the-art performance across twenty-one public benchmark datasets, even\nthough it is neither the largest model by parameter count nor by training\ndataset size.",
      "tldr_zh": "本研究介绍了Atlas，一种新型的病理学基础模型（foundation model），由Mayo Clinic、Charité和Aignostics合作开发。Atlas基于RudolfV方法，训练于来自两个医疗机构的120万张病理学全滑玻图像（whole slide images）。尽管模型的参数数量和训练数据集规模并非最大，综合评估显示Atlas在21个公共基准数据集（benchmark datasets）上达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05409v2",
      "published_date": "2025-01-09 18:06:45 UTC",
      "updated_date": "2025-01-10 16:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:48:04.356913"
    },
    {
      "arxiv_id": "2501.05408v1",
      "title": "TimeRL: Efficient Deep Reinforcement Learning with Polyhedral Dependence Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro F. Silvestre",
        "Peter Pietzuch"
      ],
      "abstract": "Modern deep learning (DL) workloads increasingly use complex deep\nreinforcement learning (DRL) algorithms that generate training data within the\nlearning loop. This results in programs with several nested loops and dynamic\ndata dependencies between tensors. While DL systems with eager execution\nsupport such dynamism, they lack the optimizations and smart scheduling of\ngraph-based execution. Graph-based execution, however, cannot express dynamic\ntensor shapes, instead requiring the use of multiple static subgraphs. Either\nexecution model for DRL thus leads to redundant computation, reduced\nparallelism, and less efficient memory management.\n  We describe TimeRL, a system for executing dynamic DRL programs that combines\nthe dynamism of eager execution with the whole-program optimizations and\nscheduling of graph-based execution. TimeRL achieves this by introducing the\ndeclarative programming model of recurrent tensors, which allows users to\ndefine dynamic dependencies as intuitive recurrence equations. TimeRL\ntranslates recurrent tensors into a polyhedral dependence graph (PDG) with\ndynamic dependencies as symbolic expressions. Through simple PDG\ntransformations, TimeRL applies whole-program optimizations, such as automatic\nvectorization, incrementalization, and operator fusion. The PDG also allows for\nthe computation of an efficient program-wide execution schedule, which decides\non buffer deallocations, buffer donations, and GPU/CPU memory swapping. We show\nthat TimeRL executes current DRL algorithms up to 47$\\times$ faster than\nexisting DRL systems, while using 16$\\times$ less GPU peak memory.",
      "tldr_zh": "该论文提出 TimeRL，一种高效的深度强化学习 (DRL) 系统，通过引入 recurrent tensors 的声明式编程模型来处理程序中的动态数据依赖，并将其转化为 polyhedral dependence graphs (PDG)。TimeRL 利用 PDG 进行整体程序优化，如自动向量化、增量化和操作融合，同时计算高效的执行调度以管理内存和并行性。实验结果显示，TimeRL 比现有 DRL 系统执行速度快 47 倍，并将 GPU 峰值内存使用减少 16 倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "D.4.7, I.1.1, I.1.3, I.2.5",
        "D.4.7; I.1.1; I.1.3; I.2.5"
      ],
      "primary_category": "cs.DC",
      "comment": "17 pages, 11 figures, 5 bibliography pages",
      "pdf_url": "http://arxiv.org/pdf/2501.05408v1",
      "published_date": "2025-01-09 18:05:33 UTC",
      "updated_date": "2025-01-09 18:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:48:18.330234"
    },
    {
      "arxiv_id": "2501.05407v1",
      "title": "On-line Policy Improvement using Monte-Carlo Search",
      "title_zh": "翻译失败",
      "authors": [
        "Gerald Tesauro",
        "Gregory R. Galperin"
      ],
      "abstract": "We present a Monte-Carlo simulation algorithm for real-time policy\nimprovement of an adaptive controller. In the Monte-Carlo simulation, the\nlong-term expected reward of each possible action is statistically measured,\nusing the initial policy to make decisions in each step of the simulation. The\naction maximizing the measured expected reward is then taken, resulting in an\nimproved policy. Our algorithm is easily parallelizable and has been\nimplemented on the IBM SP1 and SP2 parallel-RISC supercomputers.\n  We have obtained promising initial results in applying this algorithm to the\ndomain of backgammon. Results are reported for a wide variety of initial\npolicies, ranging from a random policy to TD-Gammon, an extremely strong\nmulti-layer neural network. In each case, the Monte-Carlo algorithm gives a\nsubstantial reduction, by as much as a factor of 5 or more, in the error rate\nof the base players. The algorithm is also potentially useful in many other\nadaptive control applications in which it is possible to simulate the\nenvironment.",
      "tldr_zh": "本文提出了一种基于 Monte-Carlo Search 的在线策略改进算法，用于实时提升自适应控制器的性能。该算法通过 Monte-Carlo 模拟统计每个可能动作的长期预期奖励，并使用初始策略指导决策，从而选择最佳动作实现策略优化。实验结果显示，在 backgammon 领域应用时，该算法对各种初始策略（如随机策略或 TD-Gammon）错误率降低了多达 5 倍以上。算法易于并行化，已在 IBM SP1 和 SP2 超级计算机上实现，并适用于其他可模拟环境的自适应控制应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accompanied by oral presentation by Gregory Galperin at NeurIPS 1996\n  (then known as NIPS*96)",
      "pdf_url": "http://arxiv.org/pdf/2501.05407v1",
      "published_date": "2025-01-09 18:05:05 UTC",
      "updated_date": "2025-01-09 18:05:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:48:29.303491"
    },
    {
      "arxiv_id": "2501.05403v1",
      "title": "TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts",
      "title_zh": "TimeDP：利用域提示学习生成多域时间序列",
      "authors": [
        "Yu-Hao Huang",
        "Chang Xu",
        "Yueying Wu",
        "Wu-Jun Li",
        "Jiang Bian"
      ],
      "abstract": "Time series generation models are crucial for applications like data\naugmentation and privacy preservation. Most existing time series generation\nmodels are typically designed to generate data from one specified domain. While\nleveraging data from other domain for better generalization is proved to work\nin other application areas, this approach remains challenging for time series\nmodeling due to the large divergence in patterns among different real world\ntime series categories. In this paper, we propose a multi-domain time series\ndiffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time\nseries semantic prototype module which defines time series prototypes to\nrepresent time series basis, each prototype vector serving as \"word\"\nrepresenting some elementary time series feature. A prototype assignment module\nis applied to extract the extract domain specific prototype weights, for\nlearning domain prompts as generation condition. During sampling, we extract\n\"domain prompt\" with few-shot samples from the target domain and use the domain\nprompts as condition to generate time series samples. Experiments demonstrate\nthat our method outperforms baselines to provide the state-of-the-art in-domain\ngeneration quality and strong unseen domain generation capability.",
      "tldr_zh": "该论文提出了一种多领域时间序列生成模型 TimeDP，利用 domain prompts 来提升生成质量。TimeDP 包括时间序列语义原型模块（定义原型向量作为基本特征）和原型分配模块（提取域特定权重以学习 domain prompts），并在采样时使用少量样本生成 domain prompts 作为条件。实验结果显示，TimeDP 在领域内生成性能和未见领域生成能力上均优于基线模型，达到了最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05403v1",
      "published_date": "2025-01-09 17:57:56 UTC",
      "updated_date": "2025-01-09 17:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:48:40.648003"
    },
    {
      "arxiv_id": "2501.05401v1",
      "title": "BRATI: Bidirectional Recurrent Attention for Time-Series Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Armando Collado-Villaverde",
        "Pablo Muñoz",
        "Maria D. R-Moreno"
      ],
      "abstract": "Missing data in time-series analysis poses significant challenges, affecting\nthe reliability of downstream applications. Imputation, the process of\nestimating missing values, has emerged as a key solution. This paper introduces\nBRATI, a novel deep-learning model designed to address multivariate time-series\nimputation by combining Bidirectional Recurrent Networks and Attention\nmechanisms. BRATI processes temporal dependencies and feature correlations\nacross long and short time horizons, utilizing two imputation blocks that\noperate in opposite temporal directions. Each block integrates recurrent layers\nand attention mechanisms to effectively resolve long-term dependencies.\n  We evaluate BRATI on three real-world datasets under diverse missing-data\nscenarios: randomly missing values, fixed-length missing sequences, and\nvariable-length missing sequences. Our findings demonstrate that BRATI\nconsistently outperforms state-of-the-art models, delivering superior accuracy\nand robustness in imputing multivariate time-series data.",
      "tldr_zh": "这篇论文提出了 BRATI，一种新型深度学习模型，用于处理多变量时间序列数据的插值问题，通过结合 Bidirectional Recurrent Networks 和 Attention mechanisms 来捕捉时间依赖性和特征相关性。BRATI 采用两个反向操作的插值块，每个块整合循环层和注意力机制，以有效解决长期依赖。实验在三个真实世界数据集上评估了不同缺失场景（如随机缺失值、固定长度和可变长度序列），结果显示 BRATI 比 state-of-the-art 模型表现出色，实现了更高的准确性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05401v1",
      "published_date": "2025-01-09 17:50:56 UTC",
      "updated_date": "2025-01-09 17:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:48:53.744508"
    },
    {
      "arxiv_id": "2501.05398v1",
      "title": "Mechanistic understanding and validation of large AI models with SemanticLens",
      "title_zh": "利用 SemanticLens 进行大型 AI 模型的机制理解和验证",
      "authors": [
        "Maximilian Dreyer",
        "Jim Berend",
        "Tobias Labarta",
        "Johanna Vielhaben",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek"
      ],
      "abstract": "Unlike human-engineered systems such as aeroplanes, where each component's\nrole and dependencies are well understood, the inner workings of AI models\nremain largely opaque, hindering verifiability and undermining trust. This\npaper introduces SemanticLens, a universal explanation method for neural\nnetworks that maps hidden knowledge encoded by components (e.g., individual\nneurons) into the semantically structured, multimodal space of a foundation\nmodel such as CLIP. In this space, unique operations become possible, including\n(i) textual search to identify neurons encoding specific concepts, (ii)\nsystematic analysis and comparison of model representations, (iii) automated\nlabelling of neurons and explanation of their functional roles, and (iv) audits\nto validate decision-making against requirements. Fully scalable and operating\nwithout human input, SemanticLens is shown to be effective for debugging and\nvalidation, summarizing model knowledge, aligning reasoning with expectations\n(e.g., adherence to the ABCDE-rule in melanoma classification), and detecting\ncomponents tied to spurious correlations and their associated training data. By\nenabling component-level understanding and validation, the proposed approach\nhelps bridge the \"trust gap\" between AI models and traditional engineered\nsystems. We provide code for SemanticLens on\nhttps://github.com/jim-berend/semanticlens and a demo on\nhttps://semanticlens.hhi-research-insights.eu.",
      "tldr_zh": "本研究针对AI模型的内部不透明性问题，引入了SemanticLens，一种通用解释方法，将神经网络的隐藏知识映射到基础模型（如CLIP）的语义结构化、多模态空间中。该方法无需人工输入，支持文本搜索识别特定概念神经元、系统分析模型表示、自动标记神经元功能以及审计决策是否符合要求（如黑色素瘤分类中的ABCDE-rule）。实验证明，SemanticLens在调试、验证模型知识、检测虚假相关性和提升AI决策可信度方面表现出色，有助于弥合AI模型与传统工程系统之间的信任差距，并提供了开源代码和演示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "74 pages (18 pages manuscript, 7 pages references, 49 pages appendix)",
      "pdf_url": "http://arxiv.org/pdf/2501.05398v1",
      "published_date": "2025-01-09 17:47:34 UTC",
      "updated_date": "2025-01-09 17:47:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:49:05.788304"
    },
    {
      "arxiv_id": "2501.05391v1",
      "title": "The global consensus on the risk management of autonomous driving",
      "title_zh": "自动驾驶风险管理的全球共识",
      "authors": [
        "Sebastian Krügel",
        "Matthias Uhl"
      ],
      "abstract": "Every maneuver of a vehicle redistributes risks between road users. While\nhuman drivers do this intuitively, autonomous vehicles allow and require\ndeliberative algorithmic risk management. But how should traffic risks be\ndistributed among road users? In a global experimental study in eight countries\nwith different cultural backgrounds and almost 11,000 participants, we compared\nrisk distribution preferences. It turns out that risk preferences in road\ntraffic are strikingly similar between the cultural zones. The vast majority of\nparticipants in all countries deviates from a guiding principle of minimizing\naccident probabilities in favor of weighing up the probability and severity of\naccidents. At the national level, the consideration of accident probability and\nseverity hardly differs between countries. The social dilemma of autonomous\nvehicles detected in deterministic crash scenarios disappears in risk\nassessments of everyday traffic situations in all countries. In no country do\ncyclists receive a risk bonus that goes beyond their higher vulnerability. In\nsum, our results suggest that a global consensus on the risk ethics of\nautonomous driving is easier to establish than on the ethics of crashing.",
      "tldr_zh": "这篇论文通过一项全球实验，调查了8个国家近11,000参与者的自动驾驶风险分配偏好，发现不同文化背景下的风险偏好高度相似，大多数人更倾向于权衡事故的概率和严重性，而不是单纯最小化事故概率。研究结果显示，在国家层面，各国对事故概率和严重性的考虑几乎没有差异，且自动驾驶的社会困境在日常交通场景中消失。参与者未为cyclists提供超出其更高vulnerability的风险奖励。总体而言，论文得出结论：全球共识在autonomous driving的风险管理上比在崩溃伦理上更容易建立。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05391v1",
      "published_date": "2025-01-09 17:33:08 UTC",
      "updated_date": "2025-01-09 17:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:49:18.178922"
    },
    {
      "arxiv_id": "2501.05497v1",
      "title": "Spatial Information Integration in Small Language Models for Document Layout Generation and Classification",
      "title_zh": "小型语言模型中的空间信息整合，用于文档布局生成和分类",
      "authors": [
        "Pablo Melendez",
        "Clemens Havas"
      ],
      "abstract": "Document layout understanding is a field of study that analyzes the spatial\narrangement of information in a document hoping to understand its structure and\nlayout. Models such as LayoutLM (and its subsequent iterations) can understand\nsemi-structured documents with SotA results; however, the lack of open\nsemi-structured data is a limitation in itself. While semi-structured data is\ncommon in everyday life (balance sheets, purchase orders, receipts), there is a\nlack of public datasets for training machine learning models for this type of\ndocument. In this investigation we propose a method to generate new, synthetic,\nlayout information that can help overcoming this data shortage. According to\nour results, the proposed method performs better than LayoutTransformer,\nanother popular layout generation method. We also show that, in some scenarios,\ntext classification can improve when supported by bounding box information.",
      "tldr_zh": "这篇论文探讨了在小语言模型中整合空间信息，以解决文档布局生成和分类中的数据短缺问题，特别是针对半结构化文档如收据和账单的公开数据集不足。研究提出了一种生成合成布局信息的方法，并通过实验证明其性能优于 LayoutTransformer。结果表明，在某些场景下，结合 bounding box 信息可以显著提升文本分类的准确性，为文档布局理解提供新的数据增强策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages. Symposium on Applied Computing 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05497v1",
      "published_date": "2025-01-09 17:20:00 UTC",
      "updated_date": "2025-01-09 17:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:49:28.594781"
    },
    {
      "arxiv_id": "2501.05382v1",
      "title": "Large Physics Models: Towards a collaborative approach with Large Language Models and Foundation Models",
      "title_zh": "大型物理模型：朝着与大型语言模型和基础模型的协作方法迈进",
      "authors": [
        "Kristian G. Barman",
        "Sascha Caron",
        "Emily Sullivan",
        "Henk W. de Regt",
        "Roberto Ruiz de Austri",
        "Mieke Boon",
        "Michael Färber",
        "Stefan Fröse",
        "Faegheh Hasibi",
        "Andreas Ipp",
        "Rukshak Kapoor",
        "Gregor Kasieczka",
        "Daniel Kostić",
        "Michael Krämer",
        "Tobias Golling",
        "Luis G. Lopez",
        "Jesus Marco",
        "Sydney Otten",
        "Pawel Pawlowski",
        "Pietro Vischia",
        "Erik Weber",
        "Christoph Weniger"
      ],
      "abstract": "This paper explores ideas and provides a potential roadmap for the\ndevelopment and evaluation of physics-specific large-scale AI models, which we\ncall Large Physics Models (LPMs). These models, based on foundation models such\nas Large Language Models (LLMs) - trained on broad data - are tailored to\naddress the demands of physics research. LPMs can function independently or as\npart of an integrated framework. This framework can incorporate specialized\ntools, including symbolic reasoning modules for mathematical manipulations,\nframeworks to analyse specific experimental and simulated data, and mechanisms\nfor synthesizing theories and scientific literature. We begin by examining\nwhether the physics community should actively develop and refine dedicated\nmodels, rather than relying solely on commercial LLMs. We then outline how LPMs\ncan be realized through interdisciplinary collaboration among experts in\nphysics, computer science, and philosophy of science. To integrate these models\neffectively, we identify three key pillars: Development, Evaluation, and\nPhilosophical Reflection. Development focuses on constructing models capable of\nprocessing physics texts, mathematical formulations, and diverse physical data.\nEvaluation assesses accuracy and reliability by testing and benchmarking.\nFinally, Philosophical Reflection encompasses the analysis of broader\nimplications of LLMs in physics, including their potential to generate new\nscientific understanding and what novel collaboration dynamics might arise in\nresearch. Inspired by the organizational structure of experimental\ncollaborations in particle physics, we propose a similarly interdisciplinary\nand collaborative approach to building and refining Large Physics Models. This\nroadmap provides specific objectives, defines pathways to achieve them, and\nidentifies challenges that must be addressed to realise physics-specific large\nscale AI models.",
      "tldr_zh": "这篇论文提出Large Physics Models (LPMs)的概念，作为一种基于Large Language Models (LLMs)和Foundation Models的专用AI模型，旨在满足物理研究的特定需求，包括处理物理文本、数学公式和实验数据。LPMs可以独立运行或整合符号推理模块、数据分析工具以及理论合成机制，以促进跨学科合作。作者强调通过三个关键支柱——Development（模型构建）、Evaluation（准确性评估）和Philosophical Reflection（对LLMs在物理中的影响分析）——来实现LPMs的开发，并建议采用类似粒子物理实验的协作框架，以应对挑战并推动物理研究的创新。",
      "categories": [
        "physics.data-an",
        "cs.AI",
        "hep-ph",
        "physics.comp-ph",
        "physics.hist-ph"
      ],
      "primary_category": "physics.data-an",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05382v1",
      "published_date": "2025-01-09 17:11:22 UTC",
      "updated_date": "2025-01-09 17:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:49:42.187160"
    },
    {
      "arxiv_id": "2501.05368v2",
      "title": "Developing a Foundation of Vector Symbolic Architectures Using Category Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Nolan P Shaw",
        "P Michael Furlong",
        "Britt Anderson",
        "Jeff Orchard"
      ],
      "abstract": "Connectionist approaches to machine learning, \\emph{i.e.} neural networks,\nare enjoying a considerable vogue right now. However, these methods require\nlarge volumes of data and produce models that are uninterpretable to humans. An\nalternative framework that is compatible with neural networks and\ngradient-based learning, but explicitly models compositionality, is Vector\nSymbolic Architectures (VSAs). VSAs are a family of algebras on\nhigh-dimensional vector representations. They arose in cognitive science from\nthe need to unify neural processing and the kind of symbolic reasoning that\nhumans perform. While machine learning methods have benefited from\ncategory-theoretical analyses, VSAs have not yet received similar treatment. In\nthis paper, we present a first attempt at applying category theory to VSAs.\nSpecifically, We generalise from vectors to co-presheaves, and describe VSA\noperations as the right Kan extensions of the external tensor product. This\nformalisation involves a proof that the right Kan extension in such cases can\nbe expressed as simple, element-wise operations. We validate our formalisation\nwith worked examples that connect to current VSA implementations, while\nsuggesting new possible designs for VSAs.",
      "tldr_zh": "本论文探讨了使用范畴论（Category Theory）为 Vector Symbolic Architectures (VSAs) 建立基础，VSAs 是一种与神经网络兼容的框架，能够显式建模组合性，以弥补传统机器学习模型在数据需求和可解释性方面的不足。作者将向量泛化为 co-presheaves，并将 VSA 操作定义为外部张量积（external tensor product）的右 Kan 扩展，同时证明了这种扩展可通过简单的元素级操作实现。该方法通过具体例子验证了其与现有 VSA 实现的兼容性，并提出新的设计可能性，为统一神经处理和符号推理提供更坚实的理论支撑。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T30"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, no figures, 2 tables, two appendices",
      "pdf_url": "http://arxiv.org/pdf/2501.05368v2",
      "published_date": "2025-01-09 16:49:04 UTC",
      "updated_date": "2025-05-02 18:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:49:53.300211"
    },
    {
      "arxiv_id": "2501.05366v1",
      "title": "Search-o1: Agentic Search-Enhanced Large Reasoning Models",
      "title_zh": "Search-o1: 代理搜索增强的大型推理模型",
      "authors": [
        "Xiaoxi Li",
        "Guanting Dong",
        "Jiajie Jin",
        "Yuyao Zhang",
        "Yujia Zhou",
        "Yutao Zhu",
        "Peitian Zhang",
        "Zhicheng Dou"
      ],
      "abstract": "Large reasoning models (LRMs) like OpenAI-o1 have demonstrated impressive\nlong stepwise reasoning capabilities through large-scale reinforcement\nlearning. However, their extended reasoning processes often suffer from\nknowledge insufficiency, leading to frequent uncertainties and potential\nerrors. To address this limitation, we introduce \\textbf{Search-o1}, a\nframework that enhances LRMs with an agentic retrieval-augmented generation\n(RAG) mechanism and a Reason-in-Documents module for refining retrieved\ndocuments. Search-o1 integrates an agentic search workflow into the reasoning\nprocess, enabling dynamic retrieval of external knowledge when LRMs encounter\nuncertain knowledge points. Additionally, due to the verbose nature of\nretrieved documents, we design a separate Reason-in-Documents module to deeply\nanalyze the retrieved information before injecting it into the reasoning chain,\nminimizing noise and preserving coherent reasoning flow. Extensive experiments\non complex reasoning tasks in science, mathematics, and coding, as well as six\nopen-domain QA benchmarks, demonstrate the strong performance of Search-o1.\nThis approach enhances the trustworthiness and applicability of LRMs in complex\nreasoning tasks, paving the way for more reliable and versatile intelligent\nsystems. The code is available at\n\\url{https://github.com/sunnynexus/Search-o1}.",
      "tldr_zh": "本研究针对大型推理模型(LRMs)如 OpenAI-o1 的知识不足问题，提出 Search-o1 框架，通过 agentic retrieval-augmented generation (RAG) 机制和 Reason-in-Documents 模块增强模型的推理能力。Search-o1 将智能搜索工作流集成到推理过程中，实现动态检索外部知识，并在分析检索文档后注入推理链，以减少噪声并保持流畅性。实验在科学、数学、编码的复杂任务以及六个开放域 QA 基准上证明了框架的优越性能，提升了 LRMs 的可信度和适用性，为更可靠的智能系统发展铺平道路。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05366v1",
      "published_date": "2025-01-09 16:48:17 UTC",
      "updated_date": "2025-01-09 16:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:52:05.326095"
    },
    {
      "arxiv_id": "2501.05360v1",
      "title": "On Corrigibility and Alignment in Multi Agent Games",
      "title_zh": "翻译失败",
      "authors": [
        "Edmund Dable-Heath",
        "Boyko Vodenicharski",
        "James Bishop"
      ],
      "abstract": "Corrigibility of autonomous agents is an under explored part of system\ndesign, with previous work focusing on single agent systems. It has been\nsuggested that uncertainty over the human preferences acts to keep the agents\ncorrigible, even in the face of human irrationality. We present a general\nframework for modelling corrigibility in a multi-agent setting as a 2 player\ngame in which the agents always have a move in which they can ask the human for\nsupervision. This is formulated as a Bayesian game for the purpose of\nintroducing uncertainty over the human beliefs. We further analyse two specific\ncases. First, a two player corrigibility game, in which we want corrigibility\ndisplayed in both agents for both common payoff (monotone) games and harmonic\ngames. Then we investigate an adversary setting, in which one agent is\nconsidered to be a `defending' agent and the other an `adversary'. A general\nresult is provided for what belief over the games and human rationality the\ndefending agent is required to have to induce corrigibility.",
      "tldr_zh": "本文提出一个通用框架，将多代理游戏中的corrigibility（可修正性）和alignment（对齐）问题建模为一个2玩家游戏，其中代理总能选择寻求人类监督，以应对人类偏好不确定性和非理性。框架利用Bayesian game引入人类信念的不确定性，分析corrigibility在不同场景下的表现，包括共同收益（monotone games和harmonic games）的双代理设置，以及对手场景中“defending agent”对抗“adversary agent”。研究结果显示，防御代理需持有特定信念（关于游戏类型和人类理性），才能诱导corrigibility，从而提升代理系统的可靠性和可控性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05360v1",
      "published_date": "2025-01-09 16:44:38 UTC",
      "updated_date": "2025-01-09 16:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:50:17.633737"
    },
    {
      "arxiv_id": "2501.05496v2",
      "title": "FedSA: A Unified Representation Learning via Semantic Anchors for Prototype-based Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbing Zhou",
        "Xiangmou Qu",
        "Chenlong You",
        "Jiyang Zhou",
        "Jingyue Tang",
        "Xin Zheng",
        "Chunmao Cai",
        "Yingbo Wu"
      ],
      "abstract": "Prototype-based federated learning has emerged as a promising approach that\nshares lightweight prototypes to transfer knowledge among clients with data\nheterogeneity in a model-agnostic manner. However, existing methods often\ncollect prototypes directly from local models, which inevitably introduce\ninconsistencies into representation learning due to the biased data\ndistributions and differing model architectures among clients. In this paper,\nwe identify that both statistical and model heterogeneity create a vicious\ncycle of representation inconsistency, classifier divergence, and skewed\nprototype alignment, which negatively impacts the performance of clients. To\nbreak the vicious cycle, we propose a novel framework named Federated Learning\nvia Semantic Anchors (FedSA) to decouple the generation of prototypes from\nlocal representation learning. We introduce a novel perspective that uses\nsimple yet effective semantic anchors serving as prototypes to guide local\nmodels in learning consistent representations. By incorporating semantic\nanchors, we further propose anchor-based regularization with margin-enhanced\ncontrastive learning and anchor-based classifier calibration to correct feature\nextractors and calibrate classifiers across clients, achieving intra-class\ncompactness and inter-class separability of prototypes while ensuring\nconsistent decision boundaries. We then update the semantic anchors with these\nconsistent and discriminative prototypes, which iteratively encourage clients\nto collaboratively learn a unified data representation with robust\ngeneralization. Extensive experiments under both statistical and model\nheterogeneity settings show that FedSA significantly outperforms existing\nprototype-based FL methods on various classification tasks.",
      "tldr_zh": "该论文提出 FedSA 框架，用于原型-based federated learning，通过引入 semantic anchors 作为原型来解耦本地表示学习与原型生成，解决数据和模型异质性导致的表示不一致、分类器发散和原型对齐偏差问题。FedSA 采用 anchor-based regularization 结合 margin-enhanced contrastive learning 和 classifier calibration，实现类内紧凑性、类间可分性和一致决策边界，并通过迭代更新 semantic anchors 促进客户端协作学习统一的表示。实验结果表明，在统计和模型异质性设置下，FedSA 在各种分类任务上显著优于现有原型-based FL 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05496v2",
      "published_date": "2025-01-09 16:10:03 UTC",
      "updated_date": "2025-04-22 02:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:50:30.122848"
    },
    {
      "arxiv_id": "2501.05336v1",
      "title": "Stream Aligner: Efficient Sentence-Level Alignment via Distribution Induction",
      "title_zh": "Stream Aligner",
      "authors": [
        "Hantao Lou",
        "Jiaming Ji",
        "Kaile Wang",
        "Yaodong Yang"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has led to significant\nimprovements in their capabilities, but also to increased concerns about their\nalignment with human values and intentions. Current alignment strategies,\nincluding adaptive training and inference-time methods, have demonstrated\npotential in this area. However, these approaches still struggle to balance\ndeployment complexity and capability across various tasks and difficulties. In\nthis work, we introduce the Streaming Distribution Induce Aligner (Stream\nAligner), a novel alignment paradigm that combines efficiency with enhanced\nperformance in various tasks throughout the generation process. Stream Aligner\nachieves dynamic sentence-level correction by using a small model to learn the\npreferences of the suffix sentence, iteratively correcting the suffix sentence\noutput by the upstream model, and then using the corrected sentence to replace\nthe suffix sentence in subsequent generations. Compared to Aligner, our\nexperiments demonstrate that Stream Aligner reduces reliance on the\ncapabilities of additional models, enhances the reasoning abilities of LLMs,\nand decreases latency during user interaction. Specifically, Stream Aligner-2B\nmodel has achieved an improvement of 76.1% in helpfulness, 36.0% in\nharmlessness on the tested Llama2-70B-chat model, and Stream Aligner-8B has\nachieved an improvement of 3.5% on the math ability of the tested\nLlama3-70B-Instruct model.",
      "tldr_zh": "本研究引入了 Stream Aligner，一种基于分布诱导的创新对齐范式，旨在提升大型语言模型 (LLMs) 与人类价值观的对齐，同时平衡部署复杂性和任务性能。Stream Aligner 通过一个小模型动态学习后缀句子的偏好，进行迭代修正上游模型的输出，并替换后续生成，从而实现高效的句子级对齐。实验结果表明，该方法减少了对额外模型的依赖，显著增强了 LLMs 的推理能力并降低了延迟；具体而言，Stream Aligner-2B 在 Llama2-70B-chat 上提升了 helpfulness 76.1% 和 harmlessness 36.0%，而 Stream Aligner-8B 在 Llama3-70B-Instruct 上提升了数学能力 3.5%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI Alignment Track 2025 Poster",
      "pdf_url": "http://arxiv.org/pdf/2501.05336v1",
      "published_date": "2025-01-09 16:02:51 UTC",
      "updated_date": "2025-01-09 16:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:52:17.881840"
    },
    {
      "arxiv_id": "2501.05334v1",
      "title": "The Bakers and Millers Game with Restricted Locations",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Krogmann",
        "Pascal Lenzner",
        "Alexander Skopalik"
      ],
      "abstract": "We study strategic location choice by customers and sellers, termed the\nBakers and Millers Game in the literature. In our generalized setting, each\nmiller can freely choose any location for setting up a mill, while each baker\nis restricted in the choice of location for setting up a bakery. For optimal\nbargaining power, a baker would like to select a location with many millers to\nbuy flour from and with little competition from other bakers. Likewise, a\nmiller aims for a location with many bakers and few competing millers. Thus,\nboth types of agents choose locations to optimize the ratio of agents of\nopposite type divided by agents of the same type at their chosen location.\nOriginally raised in the context of Fractional Hedonic Games, the Bakers and\nMillers Game has applications that range from commerce to product design.\n  We study the impact of location restrictions on the properties of the game.\nWhile pure Nash equilibria trivially exist in the setting without location\nrestrictions, we show via a sophisticated, efficient algorithm that even the\nmore challenging restricted setting admits equilibria. Moreover, the computed\nequilibrium approximates the optimal social welfare by a factor of at most\n$2\\left(\\frac{e}{e-1}\\right)$. Furthermore, we give tight bounds on the price\nof anarchy/stability.\n  On the conceptual side, the location choice feature adds a new layer to the\nstandard setting of Hedonic Games, in the sense that agents that select the\nsame location form a coalition. This allows to naturally restrict the possible\ncoalitions that can be formed. With this, our model generalizes simple\nsymmetric Fractional Hedonic Games on complete bipartite valuation graphs and\nalso Hedonic Diversity Games with utilities single-peaked at 0. We believe that\nthis generalization is also a very interesting direction for other types of\nHedonic Games.",
      "tldr_zh": "这篇论文研究了 Bakers and Millers Game 的泛化版本，其中 millers 可以自由选择位置，而 bakers 位置受限，双方通过优化位置来最大化谈判权。论文证明了即使在位置限制下，纯 Nash equilibria 依然存在，并提出一个高效算法来计算这些均衡，同时显示计算结果能近似最佳社会福利，近似因子为 \\(2\\left(\\frac{e}{e-1}\\right)\\)。此外，论文给出了 price of anarchy/stability 的紧密界，并将该模型扩展到 Hedonic Games 的框架中，作为 Fractional Hedonic Games 和 Hedonic Diversity Games 的泛化。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "To appear at the 24th International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.05334v1",
      "published_date": "2025-01-09 15:59:32 UTC",
      "updated_date": "2025-01-09 15:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:52:30.255189"
    },
    {
      "arxiv_id": "2501.05332v1",
      "title": "AnCoGen: Analysis, Control and Generation of Speech with a Masked Autoencoder",
      "title_zh": "AnCoGen：利用掩码自编码器实现语音的分析、控制和生成",
      "authors": [
        "Samir Sadok",
        "Simon Leglaive",
        "Laurent Girin",
        "Gaël Richard",
        "Xavier Alameda-Pineda"
      ],
      "abstract": "This article introduces AnCoGen, a novel method that leverages a masked\nautoencoder to unify the analysis, control, and generation of speech signals\nwithin a single model. AnCoGen can analyze speech by estimating key attributes,\nsuch as speaker identity, pitch, content, loudness, signal-to-noise ratio, and\nclarity index. In addition, it can generate speech from these attributes and\nallow precise control of the synthesized speech by modifying them. Extensive\nexperiments demonstrated the effectiveness of AnCoGen across speech\nanalysis-resynthesis, pitch estimation, pitch modification, and speech\nenhancement.",
      "tldr_zh": "这篇论文介绍了 AnCoGen，一种基于 masked autoencoder 的新方法，将语音信号的分析、控制和生成统一到一个模型中。AnCoGen 可以估计语音的关键属性，如 speaker identity、pitch、content、loudness、signal-to-noise ratio 和 clarity index，并通过修改这些属性实现精确的语音生成和控制。实验证明，该方法在语音分析-重合成、pitch estimation、pitch modification 和 speech enhancement 等任务上表现出色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, https://samsad35.github.io/site-ancogen",
      "pdf_url": "http://arxiv.org/pdf/2501.05332v1",
      "published_date": "2025-01-09 15:58:37 UTC",
      "updated_date": "2025-01-09 15:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:52:40.268598"
    },
    {
      "arxiv_id": "2501.05495v1",
      "title": "LSEBMCL: A Latent Space Energy-Based Model for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodi Li",
        "Dingcheng Li",
        "Rujun Gao",
        "Mahmoud Zamani",
        "Latifur Khan"
      ],
      "abstract": "Continual learning has become essential in many practical applications such\nas online news summaries and product classification. The primary challenge is\nknown as catastrophic forgetting, a phenomenon where a model inadvertently\ndiscards previously learned knowledge when it is trained on new tasks. Existing\nsolutions involve storing exemplars from previous classes, regularizing\nparameters during the fine-tuning process, or assigning different model\nparameters to each task. The proposed solution LSEBMCL (Latent Space\nEnergy-Based Model for Continual Learning) in this work is to use energy-based\nmodels (EBMs) to prevent catastrophic forgetting by sampling data points from\nprevious tasks when training on new ones. The EBM is a machine learning model\nthat associates an energy value with each input data point. The proposed method\nuses an EBM layer as an outer-generator in the continual learning framework for\nNLP tasks. The study demonstrates the efficacy of EBM in NLP tasks, achieving\nstate-of-the-art results in all experiments.",
      "tldr_zh": "这篇论文提出了LSEBMCL，一种基于潜在空间的Energy-Based Models (EBMs)用于Continual Learning的框架，旨在解决灾难性遗忘（catastrophic forgetting）问题，通过在训练新任务时从先前任务采样数据点来保留之前学到的知识。方法将EBM层作为外部生成器整合到持续学习框架中，专注于NLP任务。实验结果表明，该方法在所有测试中实现了state-of-the-art性能，证明了EBMs在防止知识遗忘方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "In the 7th International Conference on Artificial Intelligence in\n  Information and Communication (ICAIIC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.05495v1",
      "published_date": "2025-01-09 15:47:30 UTC",
      "updated_date": "2025-01-09 15:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:52:52.672795"
    },
    {
      "arxiv_id": "2501.05278v1",
      "title": "Off-Policy Evaluation and Counterfactual Methods in Dynamic Auction Environments",
      "title_zh": "离策略评估和反事实方法在动态拍卖环境中的应用",
      "authors": [
        "Ritam Guha",
        "Nilavra Pathak"
      ],
      "abstract": "Counterfactual estimators are critical for learning and refining policies\nusing logged data, a process known as Off-Policy Evaluation (OPE). OPE allows\nresearchers to assess new policies without costly experiments, speeding up the\nevaluation process. Online experimental methods, such as A/B tests, are\neffective but often slow, thus delaying the policy selection and optimization\nprocess.\n  In this work, we explore the application of OPE methods in the context of\nresource allocation in dynamic auction environments. Given the competitive\nnature of environments where rapid decision-making is crucial for gaining a\ncompetitive edge, the ability to quickly and accurately assess algorithmic\nperformance is essential. By utilizing counterfactual estimators as a\npreliminary step before conducting A/B tests, we aim to streamline the\nevaluation process, reduce the time and resources required for experimentation,\nand enhance confidence in the chosen policies. Our investigation focuses on the\nfeasibility and effectiveness of using these estimators to predict the outcomes\nof potential resource allocation strategies, evaluate their performance, and\nfacilitate more informed decision-making in policy selection. Motivated by the\noutcomes of our initial study, we envision an advanced analytics system\ndesigned to seamlessly and dynamically assess new resource allocation\nstrategies and policies.",
      "tldr_zh": "本研究探讨了Off-Policy Evaluation (OPE) 和Counterfactual estimators在动态拍卖环境中的应用，这些方法利用日志数据评估新策略，避免昂贵的在线实验，从而加速决策过程。作者提出使用Counterfactual estimators作为A/B测试的前置步骤，以简化资源分配策略的评估，减少时间和资源消耗，并提升对策略性能的信心。实验结果表明，这种方法在预测资源分配策略效果方面可行且有效，最终旨在开发一个先进的分析系统，支持动态评估和优化策略。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 15 figures, IEEE format",
      "pdf_url": "http://arxiv.org/pdf/2501.05278v1",
      "published_date": "2025-01-09 14:39:40 UTC",
      "updated_date": "2025-01-09 14:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:53:04.454029"
    },
    {
      "arxiv_id": "2501.05264v3",
      "title": "Towards Balanced Continual Multi-Modal Learning in Human Pose Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxuan Peng",
        "Mengshi Qi",
        "Dong Zhao",
        "Huadong Ma"
      ],
      "abstract": "3D human pose estimation (3D HPE) has emerged as a prominent research topic,\nparticularly in the realm of RGB-based methods. However, RGB images are\nsusceptible to limitations such as sensitivity to lighting conditions and\npotential user discomfort. Consequently, multi-modal sensing, which leverages\nnon-intrusive sensors, is gaining increasing attention. Nevertheless,\nmulti-modal 3D HPE still faces challenges, including modality imbalance and the\nimperative for continual learning. In this work, we introduce a novel balanced\ncontinual multi-modal learning method for 3D HPE, which harnesses the power of\nRGB, LiDAR, mmWave, and WiFi. Specifically, we propose a Shapley value-based\ncontribution algorithm to quantify the contribution of each modality and\nidentify modality imbalance. To address this imbalance, we employ a re-learning\nstrategy. Furthermore, recognizing that raw data is prone to noise\ncontamination, we develop a novel denoising continual learning approach. This\napproach incorporates a noise identification and separation module to mitigate\nthe adverse effects of noise and collaborates with the balanced learning\nstrategy to enhance optimization. Additionally, an adaptive EWC mechanism is\nemployed to alleviate catastrophic forgetting. We conduct extensive experiments\non the widely-adopted multi-modal dataset, MM-Fi, which demonstrate the\nsuperiority of our approach in boosting 3D pose estimation and mitigating\ncatastrophic forgetting in complex scenarios. We will release our codes.",
      "tldr_zh": "本研究针对多模态 3D 人类姿势估计（3D HPE）的挑战，如模态不平衡和持续学习需求，提出了一种平衡持续多模态学习方法，利用 RGB、LiDAR、mmWave 和 WiFi 等传感器。方法包括 Shapley value-based 贡献算法来量化各模态贡献并识别不平衡，随后采用 re-learning 策略和 denoising continual learning 模块（包含噪声识别和分离）来缓解噪声影响，并结合 adaptive EWC 机制以减轻 catastrophic forgetting。实验在 MM-Fi 数据集上表明，该方法显著提升了 3D 姿势估计性能，并在复杂场景中有效缓解了遗忘问题。作者计划发布代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05264v3",
      "published_date": "2025-01-09 14:19:33 UTC",
      "updated_date": "2025-01-16 02:39:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:01.542753"
    },
    {
      "arxiv_id": "2501.05260v1",
      "title": "Enhancing Plagiarism Detection in Marathi with a Weighted Ensemble of TF-IDF and BERT Embeddings for Low-Resource Language Processing",
      "title_zh": "针对低资源语言处理的马拉",
      "authors": [
        "Atharva Mutsaddi",
        "Aditya Choudhary"
      ],
      "abstract": "Plagiarism involves using another person's work or concepts without proper\nattribution, presenting them as original creations. With the growing amount of\ndata communicated in regional languages such as Marathi -- one of India's\nregional languages -- it is crucial to design robust plagiarism detection\nsystems tailored for low-resource languages. Language models like Bidirectional\nEncoder Representations from Transformers (BERT) have demonstrated exceptional\ncapability in text representation and feature extraction, making them essential\ntools for semantic analysis and plagiarism detection. However, the application\nof BERT for low-resource languages remains under-explored, particularly in the\ncontext of plagiarism detection. This paper presents a method to enhance the\naccuracy of plagiarism detection for Marathi texts using BERT sentence\nembeddings in conjunction with Term Frequency-Inverse Document Frequency\n(TF-IDF) feature representation. This approach effectively captures\nstatistical, semantic, and syntactic aspects of text features through a\nweighted voting ensemble of machine learning models.",
      "tldr_zh": "这篇论文针对低资源语言如马拉地语的剽窃检测问题，提出了一种增强方法，通过结合BERT Embeddings和TF-IDF特征来捕捉文本的统计、语义和句法方面。方法采用加权投票集成（Weighted Ensemble）机器学习模型，对马拉地语文本进行更准确的分析和检测。实验结果表明，这种集成方法显著提升了剽窃检测的性能，为类似低资源语言的文本处理提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted into LoResLM: The First Workshop on Language Models for\n  Low-Resource Languages, colocated with COLING 2025 and set to be published\n  into ACL Anthology",
      "pdf_url": "http://arxiv.org/pdf/2501.05260v1",
      "published_date": "2025-01-09 14:14:18 UTC",
      "updated_date": "2025-01-09 14:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:53:28.067125"
    },
    {
      "arxiv_id": "2501.05258v1",
      "title": "Automating the Detection of Code Vulnerabilities by Analyzing GitHub Issues",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Cipollone",
        "Changjie Wang",
        "Mariano Scazzariello",
        "Simone Ferlin",
        "Maliheh Izadi",
        "Dejan Kostic",
        "Marco Chiesa"
      ],
      "abstract": "In today's digital landscape, the importance of timely and accurate\nvulnerability detection has significantly increased. This paper presents a\nnovel approach that leverages transformer-based models and machine learning\ntechniques to automate the identification of software vulnerabilities by\nanalyzing GitHub issues. We introduce a new dataset specifically designed for\nclassifying GitHub issues relevant to vulnerability detection. We then examine\nvarious classification techniques to determine their effectiveness. The results\ndemonstrate the potential of this approach for real-world application in early\nvulnerability detection, which could substantially reduce the window of\nexploitation for software vulnerabilities. This research makes a key\ncontribution to the field by providing a scalable and computationally efficient\nframework for automated detection, enabling the prevention of compromised\nsoftware usage before official notifications. This work has the potential to\nenhance the security of open-source software ecosystems.",
      "tldr_zh": "这篇论文提出了一种新方法，利用 transformer-based 模型和机器学习技术，通过分析 GitHub issues 来自动检测代码漏洞，以提高漏洞识别的及时性和准确性。研究团队引入了一个专门设计的数据集，用于分类与漏洞相关的 issues，并评估了多种分类技术的有效性。实验结果表明，该方法在实际应用中具有潜力，能显著缩短漏洞利用窗口，并提供一个可扩展、高效的框架，帮助提升开源软件生态的安全性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "D.2.5; K.6.3"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05258v1",
      "published_date": "2025-01-09 14:13:39 UTC",
      "updated_date": "2025-01-09 14:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:53:40.243704"
    },
    {
      "arxiv_id": "2501.05252v1",
      "title": "From Scientific Texts to Verifiable Code: Automating the Process with Transformers",
      "title_zh": "从科学文本到可验证代码：使用 Transformers 自动化该过程",
      "authors": [
        "Changjie Wang",
        "Mariano Scazzariello",
        "Marco Chiesa"
      ],
      "abstract": "Despite the vast body of research literature proposing algorithms with formal\nguarantees, the amount of verifiable code in today's systems remains minimal.\nThis discrepancy stems from the inherent difficulty of verifying code,\nparticularly due to the time-consuming nature and strict formalism of proof\ndetails that formal verification tools require. However, the emergence of\ntransformers in Large Language Models presents a promising solution to this\nchallenge. In this position paper, we believe that transformers have the\npotential to read research papers that propose algorithms with formal proofs\nand translate these proofs into verifiable code. We leverage transformers to\nfirst build a formal structure of the proof using the original text from the\npaper, and then to handle the tedious, low-level aspects of proofs that are\noften omitted by humans. We argue that this approach can significantly reduce\nthe barrier to formal verification. The above idea of reading papers to write\nverifiable code opens new avenues for automating the verification of complex\nsystems, enabling a future where formally verified algorithms from academic\nresearch can more seamlessly transition into real-world software systems,\nthereby improving code reliability and security.",
      "tldr_zh": "该论文讨论了从科学文本到可验证代码的自动化过程，强调了 Transformers 在解决算法正式证明与实际代码验证之间差距的问题。作者提出利用 Large Language Models 中的 Transformers 来读取研究论文，构建证明的正式结构，并处理证明中的繁琐细节，从而自动生成可验证代码。这种方法可以显著降低 formal verification 的门槛，促进学术算法向实际软件系统的无缝过渡，最终提升代码的可靠性和安全性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LO",
        "D.2.4; D.2.3; I.2.7; I.2.2; I.2.3; I.2.5; F.3.1"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05252v1",
      "published_date": "2025-01-09 14:03:35 UTC",
      "updated_date": "2025-01-09 14:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:53:51.645547"
    },
    {
      "arxiv_id": "2501.05249v1",
      "title": "RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Peizhuo Lv",
        "Mengjie Sun",
        "Hao Wang",
        "Xiaofeng Wang",
        "Shengzhi Zhang",
        "Yuxuan Chen",
        "Kai Chen",
        "Limin Sun"
      ],
      "abstract": "In recent years, tremendous success has been witnessed in Retrieval-Augmented\nGeneration (RAG), widely used to enhance Large Language Models (LLMs) in\ndomain-specific, knowledge-intensive, and privacy-sensitive tasks. However,\nattackers may steal those valuable RAGs and deploy or commercialize them,\nmaking it essential to detect Intellectual Property (IP) infringement. Most\nexisting ownership protection solutions, such as watermarks, are designed for\nrelational databases and texts. They cannot be directly applied to RAGs because\nrelational database watermarks require white-box access to detect IP\ninfringement, which is unrealistic for the knowledge base in RAGs. Meanwhile,\npost-processing by the adversary's deployed LLMs typically destructs text\nwatermark information. To address those problems, we propose a novel black-box\n\"knowledge watermark\" approach, named RAG-WM, to detect IP infringement of\nRAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark\nGenerator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark\ntexts based on watermark entity-relationship tuples and inject them into the\ntarget RAG. We evaluate RAG-WM across three domain-specific and two\nprivacy-sensitive tasks on four benchmark LLMs. Experimental results show that\nRAG-WM effectively detects the stolen RAGs in various deployed LLMs.\nFurthermore, RAG-WM is robust against paraphrasing, unrelated content removal,\nknowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also\nevade watermark detection approaches, highlighting its promising application in\ndetecting IP infringement of RAG systems.",
      "tldr_zh": "该论文提出RAG-WM，一种高效的黑盒水印方法，用于检测Retrieval-Augmented Generation (RAG)系统的知识产权侵权问题，以应对现有水印技术的局限性。\nRAG-WM采用多LLM交互框架，包括Watermark Generator、Shadow LLM & RAG以及Watermark Discriminator，基于水印实体-关系元组生成并注入水印文本。\n实验结果显示，在三个领域特定任务和两个隐私敏感任务上，RAG-WM在四种基准LLM中有效识别被盗用RAG系统，并对改写、内容删除、知识插入和扩展等攻击具有强鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05249v1",
      "published_date": "2025-01-09 14:01:15 UTC",
      "updated_date": "2025-01-09 14:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:05.589765"
    },
    {
      "arxiv_id": "2501.05248v1",
      "title": "Deriving Coding-Specific Sub-Models from LLMs using Resource-Efficient Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Puccioni",
        "Alireza Farshin",
        "Mariano Scazzariello",
        "Changjie Wang",
        "Marco Chiesa",
        "Dejan Kostic"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated their exceptional performance\nin various complex code generation tasks. However, their broader adoption is\nlimited by significant computational demands and high resource requirements,\nparticularly memory and processing power. To mitigate such requirements, model\npruning techniques are used to create more compact models with significantly\nfewer parameters. However, current approaches do not focus on the efficient\nextraction of programming-language-specific sub-models. In this work, we\nexplore the idea of efficiently deriving coding-specific sub-models through\nunstructured pruning (i.e., Wanda). We investigate the impact of different\ndomain-specific calibration datasets on pruning outcomes across three distinct\ndomains and extend our analysis to extracting four language-specific\nsub-models: Python, Java, C++, and JavaScript. We are the first to efficiently\nextract programming-language-specific sub-models using appropriate calibration\ndatasets while maintaining acceptable accuracy w.r.t. full models. We are also\nthe first to provide analytical evidence that domain-specific tasks activate\ndistinct regions within LLMs, supporting the creation of specialized sub-models\nthrough unstructured pruning. We believe that this work has significant\npotential to enhance LLM accessibility for coding by reducing computational\nrequirements to enable local execution on consumer-grade hardware, and\nsupporting faster inference times critical for real-time development feedback.",
      "tldr_zh": "这篇论文探讨了使用资源高效的无结构修剪(unstructured pruning，如Wanda)从大型语言模型(LLMs)中衍生出代码特定子模型，以解决LLMs在代码生成任务中高计算需求的问题。研究者调查了不同领域特定校准数据集对修剪结果的影响，并成功提取了Python、Java、C++和JavaScript的子模型，同时保持与完整模型相似的准确性。他们首次提供了分析证据，表明领域特定任务激活LLMs中的不同区域，从而支持通过修剪创建专业子模型，这有助于降低计算要求，实现本地执行和更快推理以提升代码开发效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE",
        "I.2.2; I.2.6; D.1.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05248v1",
      "published_date": "2025-01-09 14:00:01 UTC",
      "updated_date": "2025-01-09 14:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:17.576258"
    },
    {
      "arxiv_id": "2501.05247v2",
      "title": "Online Prompt Selection for Program Synthesis",
      "title_zh": "在线提示选择用于程序合成",
      "authors": [
        "Yixuan Li",
        "Lewis Frampton",
        "Federico Mora",
        "Elizabeth Polgreen"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities in the\ndomain of program synthesis. This level of performance is not, however,\nuniversal across all tasks, all LLMs and all prompting styles. There are many\nareas where one LLM dominates, one prompting style dominates, or where calling\na symbolic solver is a better choice than an LLM. A key challenge for the user\nthen, is to identify not only when an LLM is the right choice of solver, and\nthe appropriate LLM to call for a given synthesis task, but also the right way\nto call it. A non-expert user who makes the wrong choice, incurs a cost both in\nterms of results (number of tasks solved, and the time it takes to solve them)\nand financial cost, if using a closed-source language model via a commercial\nAPI. We frame this choice as an online learning problem. We use a multi-armed\nbandit algorithm to select which symbolic solver, or LLM and prompt combination\nto deploy in order to maximize a given reward function (which may prioritize\nsolving time, number of synthesis tasks solved, or financial cost of solving).\nWe implement an instance of this approach, called CYANEA, and evaluate it on\nsynthesis queries from the literature in ranking function synthesis, from the\nsyntax-guided synthesis competition, and fresh, unseen queries generated from\nSMT problems. CYANEA solves 37.2% more queries than the best single solver and\nachieves results within 4% of the virtual best solver.",
      "tldr_zh": "该研究针对程序合成中的 Large Language Models (LLMs) 性能不稳定问题，提出了一种在线提示选择框架，将求解器选择（如符号求解器、LLMs 和提示组合）建模为多臂赌博机(multi-armed bandit)算法，以最大化奖励函数（如解决时间、任务数量或财务成本）。通过这种方法，用户可以动态优化求解策略，避免非专家错误选择带来的时间和经济损失。研究实现了名为 CYANEA 的系统，并在排名函数合成、语法引导合成和新的 SMT 问题查询上进行评估，结果显示 CYANEA 比最佳单一求解器多解决了 37.2% 的查询，并接近虚拟最佳求解器的性能（仅差 4%）。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the 39th AAAI Conference on Artificial Intelligence\n  (AAAI-25) Main Track",
      "pdf_url": "http://arxiv.org/pdf/2501.05247v2",
      "published_date": "2025-01-09 13:57:09 UTC",
      "updated_date": "2025-01-29 16:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:28.793150"
    },
    {
      "arxiv_id": "2503.15492v1",
      "title": "World of ScoreCraft: Novel Multi Scorer Experiment on the Impact of a Decision Support System in Sleep Staging",
      "title_zh": "翻译失败",
      "authors": [
        "Benedikt Holm",
        "Arnar Óskarsson",
        "Björn Elvar Þorleifsson",
        "Hörður Þór Hafsteinsson",
        "Sigríður Sigurðardóttir",
        "Heiður Grétarsdóttir",
        "Kenan Hoelke",
        "Gabriel Marc Marie Jouan",
        "Thomas Penzel",
        "Erna Sif Arnardottir",
        "María Óskarsdóttir"
      ],
      "abstract": "Manual scoring of polysomnography (PSG) is a time intensive task, prone to\ninter scorer variability that can impact diagnostic reliability. This study\ninvestigates the integration of decision support systems (DSS) into PSG scoring\nworkflows, focusing on their effects on accuracy, scoring time, and potential\nbiases toward recommendations from artificial intelligence (AI) compared to\nhuman generated recommendations. Using a novel online scoring platform, we\nconducted a repeated measures study with sleep technologists,\n  who scored traditional and self applied PSGs. Participants were occasionally\npresented with recommendations labeled as either human or AI generated. We\nfound that traditional PSGs tended to be scored slightly more accurately than\nself applied PSGs, but this difference was not statistically significant.\nCorrect recommendations significantly improved scoring accuracy for both PSG\ntypes, while incorrect recommendations reduced accuracy. No significant bias\nwas observed toward or against AI generated recommendations compared to human\ngenerated recommendations. These findings highlight the potential of AI to\nenhance PSG scoring reliability. However, ensuring the accuracy of AI outputs\nis critical to maximizing its benefits. Future research should explore the long\nterm impacts of DSS on scoring workflows and strategies for integrating AI in\nclinical practice.",
      "tldr_zh": "本研究探讨了决策支持系统(DSS)在多导睡眠图(PSG)评分中的影响，评估其对准确性、评分时间和对AI或人类推荐的偏见。研究采用新型在线平台进行重复测量实验，让睡眠技术人员评分传统和自助PSG，并比较标记为AI或人类生成的推荐。结果显示，正确推荐显著提高了两种PSG的评分准确性，而错误推荐降低了准确性，且未发现对AI推荐的显著偏见；这突显了AI提升PSG评分可靠性的潜力，但需确保AI输出准确，并进一步探索其长期临床应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 13 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15492v1",
      "published_date": "2025-01-09 13:48:54 UTC",
      "updated_date": "2025-01-09 13:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:41.505026"
    },
    {
      "arxiv_id": "2501.05238v1",
      "title": "FOCUS: Towards Universal Foreground Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zuyao You",
        "Lingyu Kong",
        "Lingchen Meng",
        "Zuxuan Wu"
      ],
      "abstract": "Foreground segmentation is a fundamental task in computer vision,\nencompassing various subdivision tasks. Previous research has typically\ndesigned task-specific architectures for each task, leading to a lack of\nunification. Moreover, they primarily focus on recognizing foreground objects\nwithout effectively distinguishing them from the background. In this paper, we\nemphasize the importance of the background and its relationship with the\nforeground. We introduce FOCUS, the Foreground ObjeCts Universal Segmentation\nframework that can handle multiple foreground tasks. We develop a multi-scale\nsemantic network using the edge information of objects to enhance image\nfeatures. To achieve boundary-aware segmentation, we propose a novel\ndistillation method, integrating the contrastive learning strategy to refine\nthe prediction mask in multi-modal feature space. We conduct extensive\nexperiments on a total of 13 datasets across 5 tasks, and the results\ndemonstrate that FOCUS consistently outperforms the state-of-the-art\ntask-specific models on most metrics.",
      "tldr_zh": "本文提出FOCUS框架（Foreground ObjeCts Universal Segmentation），旨在实现前景分割任务的统一化，解决以往任务特定架构的局限性，并强调背景与前景的关系。该框架采用多尺度语义网络，利用对象边缘信息增强图像特征，并引入一种新颖的蒸馏方法结合对比学习策略，在多模态特征空间中细化预测掩码。在13个数据集上涵盖的5个任务中，FOCUS在大多数指标上超越了最先进的任务特定模型，展示了其通用性和优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05238v1",
      "published_date": "2025-01-09 13:44:15 UTC",
      "updated_date": "2025-01-09 13:44:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:54:52.250848"
    },
    {
      "arxiv_id": "2501.05234v1",
      "title": "Optimizing Estonian TV Subtitles with Semi-supervised Learning and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Artem Fedorchenko",
        "Tanel Alumäe"
      ],
      "abstract": "This paper presents an approach for generating high-quality, same-language\nsubtitles for Estonian TV content. We fine-tune the Whisper model on\nhuman-generated Estonian subtitles and enhance it with iterative\npseudo-labeling and large language model (LLM) based post-editing. Our\nexperiments demonstrate notable subtitle quality improvement through\npseudo-labeling with an unlabeled dataset. We find that applying LLM-based\nediting at test time enhances subtitle accuracy, while its use during training\ndoes not yield further gains. This approach holds promise for creating subtitle\nquality close to human standard and could be extended to real-time\napplications.",
      "tldr_zh": "本研究提出了一种优化爱沙尼亚语电视字幕的方法，通过微调 Whisper model 并结合半监督学习中的迭代 pseudo-labeling 和大型语言模型(LLMs)基于的后编辑，提升字幕质量。实验结果显示，使用未标记数据集进行 pseudo-labeling 显著改善了字幕表现，而在测试阶段应用 LLM-based 编辑能进一步提高准确性，但在训练阶段则无额外收益。该方法有望生成接近人类标准的字幕，并扩展到实时应用中。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05234v1",
      "published_date": "2025-01-09 13:41:37 UTC",
      "updated_date": "2025-01-09 13:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:55:04.164029"
    },
    {
      "arxiv_id": "2501.06262v1",
      "title": "Towards smart and adaptive agents for active sensing on edge devices",
      "title_zh": "翻译失败",
      "authors": [
        "Devendra Vyas",
        "Miguel de Prado",
        "Tim Verbelen"
      ],
      "abstract": "TinyML has made deploying deep learning models on low-power edge devices\nfeasible, creating new opportunities for real-time perception in constrained\nenvironments. However, the adaptability of such deep learning methods remains\nlimited to data drift adaptation, lacking broader capabilities that account for\nthe environment's underlying dynamics and inherent uncertainty. Deep learning's\nscaling laws, which counterbalance this limitation by massively up-scaling data\nand model size, cannot be applied when deploying on the Edge, where deep\nlearning limitations are further amplified as models are scaled down for\ndeployment on resource-constrained devices.\n  This paper presents a smart agentic system capable of performing on-device\nperception and planning, enabling active sensing on the edge. By incorporating\nactive inference into our solution, our approach extends beyond deep learning\ncapabilities, allowing the system to plan in dynamic environments while\noperating in real time with a modest total model size of 2.3 MB. We showcase\nour proposed system by creating and deploying a saccade agent connected to an\nIoT camera with pan and tilt capabilities on an NVIDIA Jetson embedded device.\nThe saccade agent controls the camera's field of view following optimal\npolicies derived from the active inference principles, simulating human-like\nsaccadic motion for surveillance and robotics applications.",
      "tldr_zh": "这篇论文针对 TinyML 在边缘设备上部署深度学习模型的适应性问题，指出现有方法仅限于数据漂移适应，无法有效应对环境动态和不确定性。论文提出了一种智能代理系统，整合 active inference 技术，实现主动感知和规划，使系统能够在资源受限的设备上实时运行，总模型大小仅 2.3 MB。实验通过部署 saccade agent 于 NVIDIA Jetson 设备，控制 IoT 相机进行人类-like 眼动模拟，用于监控和机器人应用。结果显示，该系统显著提升了边缘设备的智能性和适应性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06262v1",
      "published_date": "2025-01-09 13:27:02 UTC",
      "updated_date": "2025-01-09 13:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:55:17.429904"
    },
    {
      "arxiv_id": "2501.16336v2",
      "title": "Runtime Analysis of Evolutionary Algorithms for Multiparty Multiobjective Optimization",
      "title_zh": "多方多目标优化的进化算法运行时分析",
      "authors": [
        "Yuetong Sun",
        "Peilan Xu",
        "Wenjian Luo"
      ],
      "abstract": "In scenarios where multiple decision-makers operate within a common decision\nspace, each focusing on their own multi-objective optimization problem (e.g.,\nbargaining games), the problem can be modeled as a multi-party multi-objective\noptimization problem (MPMOP). While numerous evolutionary algorithms have been\nproposed to solve MPMOPs, most results remain empirical. This paper presents\nthe first theoretical analysis of the expected runtime of evolutionary\nalgorithms on bi-party multi-objective optimization problems (BPMOPs). Our\nfindings demonstrate that employing traditional multi-objective optimization\nalgorithms to solve MPMOPs is both time-consuming and inefficient, as the\nresulting population contains many solutions that fail to achieve consensus\namong decision-makers. An alternative approach involves decision-makers\nindividually solving their respective optimization problems and seeking\nconsensus only in the final stage. While feasible for pseudo-Boolean\noptimization problems, this method may fail to guarantee approximate\nperformance for one party in NP-hard problems. Finally, We propose\ncoevolutionary multi-party multi-objective optimizers (CoEMPMO) for\npseudo-Boolean optimization and shortest path problems within a multi-party\nmulti-objective context, which maintains a common solution set among all\nparties through coevolution. Theoretical and experimental results demonstrate\nthat the proposed \\( \\text{CoEMPMO}_{\\text{random}} \\) outperforms previous\nalgorithms in terms of the expected lower bound on runtime for pseudo-Boolean\noptimization problems. Additionally, \\(\n\\text{CoEMPMO}_{\\text{cons}}^{\\text{SP}} \\) achieves better efficiency and\nprecision in solving shortest path problems compared to existing algorithms.",
      "tldr_zh": "这篇论文首次对进化算法在多方多目标优化问题 (MPMOP) 上的预期运行时间进行理论分析，特别针对双边多目标优化问题 (BPMOP)，揭示了传统多目标优化算法效率低下，因为生成的解集往往无法达成决策者共识。论文提出一种替代方法，让决策者分别优化自身问题后再寻求共识，但这在 NP-hard 问题中可能无法保证近似性能。为解决这一问题，作者设计了 coevolutionary multi-party multi-objective optimizers (CoEMPMO) 算法，通过协同进化维护共同解集，并在伪布尔优化和最短路径问题上实现性能提升。理论和实验结果表明，CoEMPMO_random 在伪布尔优化问题上提供了更好的运行时间下界，而CoEMPMO_cons^SP 在最短路径问题上表现出更高的效率和精度。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.16336v2",
      "published_date": "2025-01-09 13:16:08 UTC",
      "updated_date": "2025-02-23 12:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:55:29.582872"
    },
    {
      "arxiv_id": "2501.05220v1",
      "title": "A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Li",
        "Mutlu Cukurova",
        "Sahan Bulathwela"
      ],
      "abstract": "The development of Automatic Question Generation (QG) models has the\npotential to significantly improve educational practices by reducing the\nteacher workload associated with creating educational content. This paper\nintroduces a novel approach to educational question generation that controls\nthe topical focus of questions. The proposed Topic-Controlled Question\nGeneration (T-CQG) method enhances the relevance and effectiveness of the\ngenerated content for educational purposes. Our approach uses fine-tuning on a\npre-trained T5-small model, employing specially created datasets tailored to\neducational needs. The research further explores the impacts of pre-training\nstrategies, quantisation, and data augmentation on the model's performance. We\nspecifically address the challenge of generating semantically aligned questions\nwith paragraph-level contexts, thereby improving the topic specificity of the\ngenerated questions. In addition, we introduce and explore novel evaluation\nmethods to assess the topical relatedness of the generated questions. Our\nresults, validated through rigorous offline and human-backed evaluations,\ndemonstrate that the proposed models effectively generate high-quality,\ntopic-focused questions. These models have the potential to reduce teacher\nworkload and support personalised tutoring systems by serving as bespoke\nquestion generators. With its relatively small number of parameters, the\nproposals not only advance the capabilities of question generation models for\nhandling specific educational topics but also offer a scalable solution that\nreduces infrastructure costs. This scalability makes them feasible for\nwidespread use in education without reliance on proprietary large language\nmodels like ChatGPT.",
      "tldr_zh": "本研究提出了一种新型的 Topic-Controlled Question Generation (T-CQG) 方法，用于自动生成教育领域的主题控制问题，从而提高问题的相关性和有效性。方法基于对预训练 T5-small 模型的微调，利用专门创建的教育数据集，并探索预训练策略、quantisation 和 data augmentation 对性能的影响，以确保生成的问题与段落级上下文语义对齐。论文引入了新的评估方法来衡量生成的问题的主题相关性，并通过严格的离线和人工评估证明，该模型能产生高质量、主题聚焦的问题。总体结果显示，T-CQG 模型可显著减少教师工作量，支持个性化辅导系统，并提供可扩展的解决方案，而无需依赖如 ChatGPT 的专有大语言模型。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "H.3.3; J.1; I.2.0"
      ],
      "primary_category": "cs.CY",
      "comment": "To be published at ACM Conf. on Learning Analytics and Knowledge\n  (LAK'25)",
      "pdf_url": "http://arxiv.org/pdf/2501.05220v1",
      "published_date": "2025-01-09 13:13:24 UTC",
      "updated_date": "2025-01-09 13:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:55:40.727336"
    },
    {
      "arxiv_id": "2501.05213v1",
      "title": "GLaM-Sign: Greek Language Multimodal Lip Reading with Integrated Sign Language Accessibility",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitris Kouremenos",
        "Klimis Ntalianis"
      ],
      "abstract": "The Greek Language Multimodal Lip Reading with Integrated Sign Language\nAccessibility (GLaM-Sign) [1] is a groundbreaking resource in accessibility and\nmultimodal AI, designed to support Deaf and Hard-of-Hearing (DHH) individuals.\nDeveloped from the FEELIT project [2], it integrates high-resolution audio,\nvideo, textual transcriptions, and Greek Sign Language translations for\napplications like real-time sign language translation and enhanced subtitle\nsynchronization. While its primary focus is on promoting inclusivity in the\nGreek tourism sector, its adaptability extends to education, healthcare, and\npublic services. Future advancements will enhance word-level precision and\nscalability to additional languages, supported by advanced AI methodologies and\ncollaborations with diverse stakeholders. This dataset underscores the\ntransformative potential of multimodal resources in bridging communication\ngaps, fostering innovation, and setting a benchmark for ethical AI and\ninclusive technologies.",
      "tldr_zh": "GLaM-Sign是一个创新的多模态资源，旨在提升聋哑和听力障碍者（DHH）个体的可访问性，通过整合高分辨率音频、视频、文本转录和希腊手语翻译，支持实时手语翻译和增强字幕同步。该资源源于FEELIT项目，主要针对希腊旅游行业的包容性应用，但可扩展至教育、医疗和公共服务领域。未来将优化词级精度并扩展至其他语言，推动多模态AI在桥接沟通差距方面的伦理创新和基准建立。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05213v1",
      "published_date": "2025-01-09 13:06:47 UTC",
      "updated_date": "2025-01-09 13:06:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:55:51.709617"
    },
    {
      "arxiv_id": "2501.05205v4",
      "title": "Discovering Hidden Visual Concepts Beyond Linguistic Input in Infant Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyi Ke",
        "Satoshi Tsutsui",
        "Yayun Zhang",
        "Bihan Wen"
      ],
      "abstract": "Infants develop complex visual understanding rapidly, even preceding the\nacquisition of linguistic skills. As computer vision seeks to replicate the\nhuman vision system, understanding infant visual development may offer valuable\ninsights. In this paper, we present an interdisciplinary study exploring this\nquestion: can a computational model that imitates the infant learning process\ndevelop broader visual concepts that extend beyond the vocabulary it has heard,\nsimilar to how infants naturally learn? To investigate this, we analyze a\nrecently published model in Science by Vong et al., which is trained on\nlongitudinal, egocentric images of a single child paired with transcribed\nparental speech. We perform neuron labeling to identify visual concept neurons\nhidden in the model's internal representations. We then demonstrate that these\nneurons can recognize objects beyond the model's original vocabulary.\nFurthermore, we compare the differences in representation between infant models\nand those in modern computer vision models, such as CLIP and ImageNet\npre-trained model. Ultimately, our work bridges cognitive science and computer\nvision by analyzing the internal representations of a computational model\ntrained on an infant visual and linguistic inputs. Our code is available at\nhttps://github.com/Kexueyi/discover_infant_vis.",
      "tldr_zh": "本文研究探讨了计算机模型是否能模仿婴儿学习过程，在语言输入（linguistic input）之外发展更广泛的视觉概念。研究者分析了Vong et al.在Science上发表的模型，该模型基于一个孩子的纵向第一人称图像和父母语音转录，通过neuron labeling识别模型内部的隐藏视觉概念神经元，并证明这些神经元能识别超出原始词汇的对象。进一步比较了该婴儿模型与现代计算机视觉模型（如CLIP和ImageNet预训练模型）的表示差异，最终桥接了认知科学和计算机视觉领域，为理解人类视觉发展提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05205v4",
      "published_date": "2025-01-09 12:55:55 UTC",
      "updated_date": "2025-03-25 07:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:56:04.450065"
    },
    {
      "arxiv_id": "2501.05197v1",
      "title": "An Algorithmic Approach for Causal Health Equity: A Look at Race Differentials in Intensive Care Unit (ICU) Outcomes",
      "title_zh": "一种用于因果健康公平",
      "authors": [
        "Drago Plecko",
        "Paul Secombe",
        "Andrea Clarke",
        "Amelia Fiske",
        "Samarra Toby",
        "Donisha Duff",
        "David Pilcher",
        "Leo Anthony Celi",
        "Rinaldo Bellomo",
        "Elias Bareinboim"
      ],
      "abstract": "The new era of large-scale data collection and analysis presents an\nopportunity for diagnosing and understanding the causes of health inequities.\nIn this study, we describe a framework for systematically analyzing health\ndisparities using causal inference. The framework is illustrated by\ninvestigating racial and ethnic disparities in intensive care unit (ICU)\noutcome between majority and minority groups in Australia (Indigenous vs.\nNon-Indigenous) and the United States (African-American vs. White). We\ndemonstrate that commonly used statistical measures for quantifying inequity\nare insufficient, and focus on attributing the observed disparity to the causal\nmechanisms that generate it. We find that minority patients are younger at\nadmission, have worse chronic health, are more likely to be admitted for urgent\nand non-elective reasons, and have higher illness severity. At the same time,\nhowever, we find a protective direct effect of belonging to a minority group,\nwith minority patients showing improved survival compared to their majority\ncounterparts, with all other variables kept equal. We demonstrate that this\nprotective effect is related to the increased probability of being admitted to\nICU, with minority patients having an increased risk of ICU admission. We also\nfind that minority patients, while showing improved survival, are more likely\nto be readmitted to ICU. Thus, due to worse access to primary health care,\nminority patients are more likely to end up in ICU for preventable conditions,\ncausing a reduction in the mortality rates and creating an effect that appears\nto be protective. Since the baseline risk of ICU admission may serve as proxy\nfor lack of access to primary care, we developed the Indigenous Intensive Care\nEquity (IICE) Radar, a monitoring system for tracking the over-utilization of\nICU resources by the Indigenous population of Australia across geographical\nareas.",
      "tldr_zh": "这篇论文提出了一种基于因果推理的算法框架，用于系统分析健康不平等，聚焦于澳大利亚（Indigenous vs. Non-Indigenous）和美国（African-American vs. White）的 ICU 结果中种族差异。研究发现，少数群体患者入院时年龄更小、慢性健康更差、更可能因紧急原因入院且疾病严重性更高，但显示出保护性直接效应，即在其他变量相同的情况下生存率更高。作者解释这一效应源于少数群体更易被入院 ICU，可能由于初级医疗保健访问不足导致的可预防条件，从而降低整体死亡率。论文还开发了 Indigenous Intensive Care Equity (IICE) Radar 系统，作为监控工具来追踪澳大利亚土著人口在不同地区的 ICU 资源过度利用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05197v1",
      "published_date": "2025-01-09 12:48:15 UTC",
      "updated_date": "2025-01-09 12:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:56:17.546003"
    },
    {
      "arxiv_id": "2501.05165v1",
      "title": "Bringing Order Amidst Chaos: On the Role of Artificial Intelligence in Secure Software Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Esposito"
      ],
      "abstract": "Context. Developing secure and reliable software remains a key challenge in\nsoftware engineering (SE). The ever-evolving technological landscape offers\nboth opportunities and threats, creating a dynamic space where chaos and order\ncompete. Secure software engineering (SSE) must continuously address\nvulnerabilities that endanger software systems and carry broader socio-economic\nrisks, such as compromising critical national infrastructure and causing\nsignificant financial losses. Researchers and practitioners have explored\nmethodologies like Static Application Security Testing Tools (SASTTs) and\nartificial intelligence (AI) approaches, including machine learning (ML) and\nlarge language models (LLMs), to detect and mitigate these vulnerabilities.\nEach method has unique strengths and limitations.\n  Aim. This thesis seeks to bring order to the chaos in SSE by addressing\ndomain-specific differences that impact AI accuracy.\n  Methodology. The research employs a mix of empirical strategies, such as\nevaluating effort-aware metrics, analyzing SASTTs, conducting method-level\nanalysis, and leveraging evidence-based techniques like systematic dataset\nreviews. These approaches help characterize vulnerability prediction datasets.\n  Results. Key findings include limitations in static analysis tools for\nidentifying vulnerabilities, gaps in SASTT coverage of vulnerability types,\nweak relationships among vulnerability severity scores, improved defect\nprediction accuracy using just-in-time modeling, and threats posed by untouched\nmethods.\n  Conclusions. This thesis highlights the complexity of SSE and the importance\nof contextual knowledge in improving AI-driven vulnerability and defect\nprediction. The comprehensive analysis advances effective prediction models,\nbenefiting both researchers and practitioners.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在安全软件工程（SSE）中的作用，旨在通过解决领域特定差异来缓解软件漏洞检测中的混乱。研究采用混合经验策略，包括评估 effort-aware metrics、分析 Static Application Security Testing Tools (SASTTs)、进行方法级分析，以及系统性数据集审查，以表征漏洞预测数据集。关键发现包括 SASTTs 在识别漏洞方面的局限性、漏洞类型覆盖的差距、漏洞严重性分数之间的弱关系，以及使用 just-in-time 建模提升缺陷预测准确性。最终，该研究强调上下文知识的重要性，推动了 AI 驱动的漏洞和缺陷预测模型的发展，为研究者和从业者提供有益的见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.ET"
      ],
      "primary_category": "cs.SE",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2501.05165v1",
      "published_date": "2025-01-09 11:38:58 UTC",
      "updated_date": "2025-01-09 11:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:56:30.162955"
    },
    {
      "arxiv_id": "2501.05163v1",
      "title": "Explainable AI based System for Supply Air Temperature Forecast",
      "title_zh": "翻译失败",
      "authors": [
        "Marika Eik",
        "Ahmet Kose",
        "Hossein Nourollahi Hokmabad",
        "Juri Belikov"
      ],
      "abstract": "This paper explores the application of Explainable AI (XAI) techniques to\nimprove the transparency and understanding of predictive models in control of\nautomated supply air temperature (ASAT) of Air Handling Unit (AHU). The study\nfocuses on forecasting of ASAT using a linear regression with Huber loss.\nHowever, having only a control curve without semantic and/or physical\nexplanation is often not enough. The present study employs one of the XAI\nmethods: Shapley values, which allows to reveal the reasoning and highlight the\ncontribution of each feature to the final ASAT forecast. In comparison to other\nXAI methods, Shapley values have solid mathematical background, resulting in\ninterpretation transparency. The study demonstrates the contrastive\nexplanations--slices, for each control value of ASAT, which makes it possible\nto give the client objective justifications for curve changes.",
      "tldr_zh": "这篇论文提出了一种基于 Explainable AI (XAI) 的系统，用于预测空气处理单元 (AHU) 的自动供应空气温度 (ASAT)，以提升模型的透明度和可解释性。研究采用线性回归结合 Huber 损失作为预测方法，同时引入 Shapley values 作为 XAI 技术，来揭示每个特征对 ASAT 预测的贡献，并提供数学上可靠的解释。最终，论文通过对比解释（contrastive explanations）展示了如何为 ASAT 控制曲线的变化提供客观理由，从而帮助用户更好地理解和信任预测结果。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "5 pages, 7 figures, 1 table, conference paper",
      "pdf_url": "http://arxiv.org/pdf/2501.05163v1",
      "published_date": "2025-01-09 11:36:29 UTC",
      "updated_date": "2025-01-09 11:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:56:40.831736"
    },
    {
      "arxiv_id": "2501.05155v1",
      "title": "Biomedical Relation Extraction via Adaptive Document-Relation Cross-Mapping and Concept Unique Identifier",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Shang",
        "Yanrong Guo",
        "Shijie Hao",
        "Richang Hong"
      ],
      "abstract": "Document-Level Biomedical Relation Extraction (Bio-RE) aims to identify\nrelations between biomedical entities within extensive texts, serving as a\ncrucial subfield of biomedical text mining. Existing Bio-RE methods struggle\nwith cross-sentence inference, which is essential for capturing relations\nspanning multiple sentences. Moreover, previous methods often overlook the\nincompleteness of documents and lack the integration of external knowledge,\nlimiting contextual richness. Besides, the scarcity of annotated data further\nhampers model training. Recent advancements in large language models (LLMs)\nhave inspired us to explore all the above issues for document-level Bio-RE.\nSpecifically, we propose a document-level Bio-RE framework via LLM Adaptive\nDocument-Relation Cross-Mapping (ADRCM) Fine-Tuning and Concept Unique\nIdentifier (CUI) Retrieval-Augmented Generation (RAG). First, we introduce the\nIteration-of-REsummary (IoRs) prompt for solving the data scarcity issue. In\nthis way, Bio-RE task-specific synthetic data can be generated by guiding\nChatGPT to focus on entity relations and iteratively refining synthetic data.\nNext, we propose ADRCM fine-tuning, a novel fine-tuning recipe that establishes\nmappings across different documents and relations, enhancing the model's\ncontextual understanding and cross-sentence inference capabilities. Finally,\nduring the inference, a biomedical-specific RAG approach, named CUI RAG, is\ndesigned to leverage CUIs as indexes for entities, narrowing the retrieval\nscope and enriching the relevant document contexts. Experiments conducted on\nthree Bio-RE datasets (GDA, CDR, and BioRED) demonstrate the state-of-the-art\nperformance of our proposed method by comparing it with other related works.",
      "tldr_zh": "本文提出了一种文档级生物医学关系提取（Bio-RE）框架，旨在解决现有方法在跨句推理、文档不完整性和数据稀缺等方面的局限，通过大型语言模型（LLM）结合 Adaptive Document-Relation Cross-Mapping (ADRCM) 微调和 Concept Unique Identifier (CUI) Retrieval-Augmented Generation (RAG) 来提升模型性能。具体而言，该框架引入 Iteration-of-REsummary (IoRs) 提示生成合成数据补充训练数据，并通过 ADRCM 建立文档与关系间的映射以加强上下文理解和跨句推理。实验在 GDA、CDR 和 BioRED 数据集上显示，该方法比相关工作取得了 state-of-the-art 性能，为生物医学文本挖掘提供了更有效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05155v1",
      "published_date": "2025-01-09 11:19:40 UTC",
      "updated_date": "2025-01-09 11:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:58:29.103139"
    },
    {
      "arxiv_id": "2501.05147v1",
      "title": "A Systematic Literature Review on Deep Learning-based Depth Estimation in Computer Vision",
      "title_zh": "基于深度学习的计算机视觉深度估计的系统文献综述",
      "authors": [
        "Ali Rohan",
        "Md Junayed Hasan",
        "Andrei Petrovski"
      ],
      "abstract": "Depth estimation (DE) provides spatial information about a scene and enables\ntasks such as 3D reconstruction, object detection, and scene understanding.\nRecently, there has been an increasing interest in using deep learning\n(DL)-based methods for DE. Traditional techniques rely on handcrafted features\nthat often struggle to generalise to diverse scenes and require extensive\nmanual tuning. However, DL models for DE can automatically extract relevant\nfeatures from input data, adapt to various scene conditions, and generalise\nwell to unseen environments. Numerous DL-based methods have been developed,\nmaking it necessary to survey and synthesize the state-of-the-art (SOTA).\nPrevious reviews on DE have mainly focused on either monocular or stereo-based\ntechniques, rather than comprehensively reviewing DE. Furthermore, to the best\nof our knowledge, there is no systematic literature review (SLR) that\ncomprehensively focuses on DE. Therefore, this SLR study is being conducted.\nInitially, electronic databases were searched for relevant publications,\nresulting in 1284 publications. Using defined exclusion and quality criteria,\n128 publications were shortlisted and further filtered to select 59\nhigh-quality primary studies. These studies were analysed to extract data and\nanswer defined research questions. Based on the results, DL methods were\ndeveloped for mainly three different types of DE: monocular, stereo, and\nmulti-view. 20 publicly available datasets were used to train, test, and\nevaluate DL models for DE, with KITTI, NYU Depth V2, and Make 3D being the most\nused datasets. 29 evaluation metrics were used to assess the performance of DE.\n35 base models were reported in the primary studies, and the top five most-used\nbase models were ResNet-50, ResNet-18, ResNet-101, U-Net, and VGG-16. Finally,\nthe lack of ground truth data was among the most significant challenges\nreported by primary studies.",
      "tldr_zh": "这篇论文对Deep Learning-based Depth Estimation in Computer Vision 进行了系统文献综述（Systematic Literature Review），旨在总结深度学习方法在深度估计（Depth Estimation, DE）中的应用和发展。研究者从1284篇出版物中筛选出59篇高质量研究，分析了DE的类型（包括monocular、stereo和multi-view）、常用数据集（如KITTI、NYU Depth V2和Make 3D）、评估指标（29种）和基模型（如ResNet-50、ResNet-18和U-Net）。最终发现，缺乏ground truth data是主要挑战，这为未来DE研究提供了关键见解和改进方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05147v1",
      "published_date": "2025-01-09 10:56:50 UTC",
      "updated_date": "2025-01-09 10:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:57:05.872936"
    },
    {
      "arxiv_id": "2501.05113v1",
      "title": "Constrained Optimization of Charged Particle Tracking with Multi-Agent Reinforcement Learning",
      "title_zh": "带电粒子跟踪",
      "authors": [
        "Tobias Kortus",
        "Ralf Keidel",
        "Nicolas R. Gauger",
        "Jan Kieseler"
      ],
      "abstract": "Reinforcement learning demonstrated immense success in modelling complex\nphysics-driven systems, providing end-to-end trainable solutions by interacting\nwith a simulated or real environment, maximizing a scalar reward signal. In\nthis work, we propose, building upon previous work, a multi-agent reinforcement\nlearning approach with assignment constraints for reconstructing particle\ntracks in pixelated particle detectors. Our approach optimizes collaboratively\na parametrized policy, functioning as a heuristic to a multidimensional\nassignment problem, by jointly minimizing the total amount of particle\nscattering over the reconstructed tracks in a readout frame. To satisfy\nconstraints, guaranteeing a unique assignment of particle hits, we propose a\nsafety layer solving a linear assignment problem for every joint action.\nFurther, to enforce cost margins, increasing the distance of the local policies\npredictions to the decision boundaries of the optimizer mappings, we recommend\nthe use of an additional component in the blackbox gradient estimation, forcing\nthe policy to solutions with lower total assignment costs. We empirically show\non simulated data, generated for a particle detector developed for proton\nimaging, the effectiveness of our approach, compared to multiple single- and\nmulti-agent baselines. We further demonstrate the effectiveness of constraints\nwith cost margins for both optimization and generalization, introduced by wider\nregions with high reconstruction performance as well as reduced predictive\ninstabilities. Our results form the basis for further developments in RL-based\ntracking, offering both enhanced performance with constrained policies and\ngreater flexibility in optimizing tracking algorithms through the option for\nindividual and team rewards.",
      "tldr_zh": "本文提出了一种基于多智能体强化学习（multi-agent reinforcement learning）的约束优化方法，用于像素化粒子探测器中的带电粒子跟踪，通过最小化重建轨迹上的粒子散射来优化参数化策略。方法引入了安全层（safety layer）来解决线性赋值问题（linear assignment problem），确保粒子命中点的唯一赋值，并通过额外组件强制策略选择更低的总赋值成本，从而提高决策边界距离和预测稳定性。在模拟数据实验中，该方法比单智能体和多智能体基线表现出色，提升了优化和泛化性能，为基于RL的跟踪算法提供了更灵活且高效的基础。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05113v1",
      "published_date": "2025-01-09 09:59:42 UTC",
      "updated_date": "2025-01-09 09:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:57:17.190558"
    },
    {
      "arxiv_id": "2501.06256v1",
      "title": "What Matters for In-Context Learning: A Balancing Act of Look-up and In-Weight Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jelena Bratulić",
        "Sudhanshu Mittal",
        "Christian Rupprecht",
        "Thomas Brox"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive performance in\nvarious tasks, including In-Context Learning (ICL), where the model performs\nnew tasks by conditioning solely on the examples provided in the context,\nwithout updating the model's weights. While prior research has explored the\nroles of pretraining data and model architecture, the key mechanism behind ICL\nremains unclear. In this work, we systematically uncover properties present in\nLLMs that support the emergence of ICL. To disambiguate these factors, we\nconduct a study with a controlled dataset and data sequences using a deep\nautoregressive model. We show that conceptual repetitions in the data sequences\nare crucial for ICL, more so than previously indicated training data properties\nlike burstiness or long-tail distribution. Conceptual repetitions could refer\nto $n$-gram repetitions in textual data or exact image copies in image sequence\ndata. Such repetitions also offer other previously overlooked benefits such as\nreduced transiency in ICL performance. Furthermore, we show that the emergence\nof ICL depends on balancing the in-weight learning objective with the\nin-context solving ability during training.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 在 In-Context Learning (ICL) 中的关键机制，通过使用受控数据集和数据序列的系统实验，揭示概念重复(conceptual repetitions)是 ICL 出现的核心因素，而非之前强调的训练数据属性如 burstiness 或 long-tail distribution。研究发现，概念重复（如文本中的 n-gram 重复或图像序列中的精确副本）不仅促进 ICL，还能减少其性能的暂时性(transiency)。最终，ICL 的有效性取决于在训练过程中平衡 in-weight learning 和 in-context solving 能力，以实现更稳定的模型表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06256v1",
      "published_date": "2025-01-09 09:45:05 UTC",
      "updated_date": "2025-01-09 09:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:57:29.355691"
    },
    {
      "arxiv_id": "2501.05095v1",
      "title": "Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Xiu",
        "Xin Liu",
        "Taehoon Kim",
        "Kyoung-Sook Kim"
      ],
      "abstract": "The pre-training and fine-tuning paradigm has revolutionized satellite remote\nsensing applications. However, this approach remains largely underexplored for\nairborne laser scanning (ALS), an important technology for applications such as\nforest management and urban planning. In this study, we address this gap by\nconstructing a large-scale ALS point cloud dataset and evaluating its impact on\ndownstream applications. Our dataset comprises ALS point clouds collected\nacross the contiguous United States, provided by the United States Geological\nSurvey's 3D Elevation Program. To ensure efficient data collection while\ncapturing diverse land cover and terrain types, we introduce a geospatial\nsampling method that selects point cloud tiles based on land cover maps and\ndigital elevation models. As a baseline self-supervised learning model, we\nadopt BEV-MAE, a state-of-the-art masked autoencoder for 3D outdoor point\nclouds, and pre-train it on the constructed dataset. The pre-trained models are\nsubsequently fine-tuned for downstream tasks, including tree species\nclassification, terrain scene recognition, and point cloud semantic\nsegmentation. Our results show that the pre-trained models significantly\noutperform their scratch counterparts across all downstream tasks,\ndemonstrating the transferability of the representations learned from the\nproposed dataset. Furthermore, we observe that scaling the dataset using our\ngeospatial sampling method consistently enhances performance, whereas\npre-training on datasets constructed with random sampling fails to achieve\nsimilar improvements. These findings highlight the utility of the constructed\ndataset and the effectiveness of our sampling strategy in the pre-training and\nfine-tuning paradigm. The source code and pre-trained models will be made\npublicly available at \\url{https://github.com/martianxiu/ALS_pretraining}.",
      "tldr_zh": "本研究针对 airborne laser scanning (ALS) 应用，构建了一个大规模点云数据集，以填补预训练和微调范式在该领域的空白。研究者引入了一种基于土地覆盖地图和数字高程模型的 geospatial sampling 方法，确保数据集覆盖多样化的地形类型，并使用 BEV-MAE 模型作为基准进行自监督预训练。预训练模型随后应用于下游任务，包括树种分类、地形场景识别和点云语义分割，结果显示其在所有任务中显著优于从零开始训练的模型，且通过该采样方法扩展数据集进一步提升了性能。这些发现突显了数据集和采样策略的有效性，相关代码和预训练模型已计划公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05095v1",
      "published_date": "2025-01-09 09:21:09 UTC",
      "updated_date": "2025-01-09 09:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:57:40.995865"
    },
    {
      "arxiv_id": "2501.05079v2",
      "title": "Multimodal-to-Text Prompt Engineering in Large Language Models Using Feature Embeddings for GNSS Interference Characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Harshith Manjunath",
        "Lucas Heublein",
        "Tobias Feigl",
        "Felix Ott"
      ],
      "abstract": "Large language models (LLMs) are advanced AI systems applied across various\ndomains, including NLP, information retrieval, and recommendation systems.\nDespite their adaptability and efficiency, LLMs have not been extensively\nexplored for signal processing tasks, particularly in the domain of global\nnavigation satellite system (GNSS) interference monitoring. GNSS interference\nmonitoring is essential to ensure the reliability of vehicle localization on\nroads, a critical requirement for numerous applications. However, GNSS-based\npositioning is vulnerable to interference from jamming devices, which can\ncompromise its accuracy. The primary objective is to identify, classify, and\nmitigate these interferences. Interpreting GNSS snapshots and the associated\ninterferences presents significant challenges due to the inherent complexity,\nincluding multipath effects, diverse interference types, varying sensor\ncharacteristics, and satellite constellations. In this paper, we extract\nfeatures from a large GNSS dataset and employ LLaVA to retrieve relevant\ninformation from an extensive knowledge base. We employ prompt engineering to\ninterpret the interferences and environmental factors, and utilize t-SNE to\nanalyze the feature embeddings. Our findings demonstrate that the proposed\nmethod is capable of visual and logical reasoning within the GNSS context.\nFurthermore, our pipeline outperforms state-of-the-art machine learning models\nin interference classification tasks.",
      "tldr_zh": "本研究探讨了将 Large Language Models (LLMs) 应用于全球导航卫星系统 (GNSS) 干扰监测，通过 Multimodal-to-Text Prompt Engineering 和 Feature Embeddings 来提取并分析干扰特征。方法包括从大型 GNSS 数据集提取特征，使用 LLaVA 检索相关知识，并结合 Prompt Engineering 和 t-SNE 进行干扰解释及环境因素分析。结果显示，该框架在 GNSS 上下文中的视觉和逻辑推理能力突出，并在干扰分类任务中超越了最先进机器学习模型，为 GNSS 可靠性提升提供了新途径。",
      "categories": [
        "cs.AI",
        "eess.SP",
        "68T30, 68T05",
        "H.1; H.5; I.4.9; I.4.10"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05079v2",
      "published_date": "2025-01-09 09:01:04 UTC",
      "updated_date": "2025-01-15 20:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:57:53.146890"
    },
    {
      "arxiv_id": "2501.05078v1",
      "title": "Analyzing Memorization in Large Language Models through the Lens of Model Attribution",
      "title_zh": "通过模型归因的视角分析大语言模型中的记忆化",
      "authors": [
        "Tarun Ram Menta",
        "Susmit Agrawal",
        "Chirag Agarwal"
      ],
      "abstract": "Large Language Models (LLMs) are prevalent in modern applications but often\nmemorize training data, leading to privacy breaches and copyright issues.\nExisting research has mainly focused on posthoc analyses, such as extracting\nmemorized content or developing memorization metrics, without exploring the\nunderlying architectural factors that contribute to memorization. In this work,\nwe investigate memorization from an architectural lens by analyzing how\nattention modules at different layers impact its memorization and\ngeneralization performance. Using attribution techniques, we systematically\nintervene in the LLM architecture by bypassing attention modules at specific\nblocks while keeping other components like layer normalization and MLP\ntransformations intact. We provide theorems analyzing our intervention\nmechanism from a mathematical view, bounding the difference in layer outputs\nwith and without our attributions. Our theoretical and empirical analyses\nreveal that attention modules in deeper transformer blocks are primarily\nresponsible for memorization, whereas earlier blocks are crucial for the models\ngeneralization and reasoning capabilities. We validate our findings through\ncomprehensive experiments on different LLM families (Pythia and GPTNeo) and\nfive benchmark datasets. Our insights offer a practical approach to mitigate\nmemorization in LLMs while preserving their performance, contributing to safer\nand more ethical deployment in real world applications.",
      "tldr_zh": "本研究从模型归因（model attribution）的角度分析大型语言模型（LLMs）的记忆化问题，揭示了注意力模块（attention modules）在不同层对记忆和泛化性能的影响。研究者使用归因技术系统干预LLMs架构，通过绕过特定transformer块中的注意力模块，同时保留层归一化和MLP变换等组件，并通过数学定理界定输出差异。结果显示，更深层transformer块的注意力模块主要负责记忆化，而早期块更关键于模型的泛化和推理能力。在Pythia和GPTNeo等LLMs家族以及五个基准数据集上的实验验证了这些发现，提供了一种实用方法来缓解记忆化问题，同时保持模型性能，从而促进LLMs在实际应用中的安全和合乎道德部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05078v1",
      "published_date": "2025-01-09 09:00:32 UTC",
      "updated_date": "2025-01-09 09:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:58:04.796239"
    },
    {
      "arxiv_id": "2501.05075v1",
      "title": "A Text-Based Knowledge-Embedded Soft Sensing Modeling Approach for General Industrial Process Tasks Based on Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Tong",
        "Han Liu",
        "Runyuan Guo",
        "Xueqiong Tian",
        "Wenqing Wang",
        "Ding Liu",
        "Youmin Zhang"
      ],
      "abstract": "Data-driven soft sensors (DDSS) have become mainstream methods for predicting\nkey performance indicators in process industries. However, DDSS development\nrequires complex and costly customized designs tailored to various tasks during\nthe modeling process. Moreover, DDSS are constrained to a single structured\ndata modality, limiting their ability to incorporate additional contextual\nknowledge. Furthermore, DDSSs' limited representation learning leads to weak\npredictive performance with scarce data. To address these challenges, we\npropose a general framework named LLM-TKESS (large language model for\ntext-based knowledge-embedded soft sensing), harnessing the powerful general\nproblem-solving capabilities, cross-modal knowledge transfer abilities, and\nfew-shot capabilities of LLM for enhanced soft sensing modeling. Specifically,\nan auxiliary variable series encoder (AVS Encoder) is proposed to unleash LLM's\npotential for capturing temporal relationships within series and spatial\nsemantic relationships among auxiliary variables. Then, we propose a two-stage\nfine-tuning alignment strategy: in the first stage, employing\nparameter-efficient fine-tuning through autoregressive training adjusts LLM to\nrapidly accommodate process variable data, resulting in a soft sensing\nfoundation model (SSFM). Subsequently, by training adapters, we adapt the SSFM\nto various downstream tasks without modifying its architecture. Then, we\npropose two text-based knowledge-embedded soft sensors, integrating new natural\nlanguage modalities to overcome the limitations of pure structured data models.\nFurthermore, benefiting from LLM's pre-existing world knowledge, our model\ndemonstrates outstanding predictive capabilities in small sample conditions.\nUsing the thermal deformation of air preheater rotor as a case study, we\nvalidate through extensive experiments that LLM-TKESS exhibits outstanding\nperformance.",
      "tldr_zh": "本文针对数据驱动软传感器(DDSS)的局限性（如复杂定制设计、单一数据模态和数据稀缺下的弱表现），提出了一种基于大语言模型(LLM)的通用框架LLM-TKESS，用于工业过程任务的软感知建模。框架包括辅助变量序列编码器(AVS Encoder)来捕捉时序和空间关系，以及两阶段微调对齐策略：先通过参数高效微调生成软传感器基础模型(SSFM)，再训练适配器以适应各种下游任务，同时整合文本-based知识嵌入软传感器。实验结果显示，该模型利用LLM的先验知识，在小样本条件下表现出色，并在空气预热器转子热变形案例中验证了其优越预测性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05075v1",
      "published_date": "2025-01-09 08:59:14 UTC",
      "updated_date": "2025-01-09 08:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:58:42.133559"
    },
    {
      "arxiv_id": "2501.05069v2",
      "title": "Commonsense Video Question Answering through Video-Grounded Entailment Tree Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Huabin Liu",
        "Filip Ilievski",
        "Cees G. M. Snoek"
      ],
      "abstract": "This paper proposes the first video-grounded entailment tree reasoning method\nfor commonsense video question answering (VQA). Despite the remarkable progress\nof large visual-language models (VLMs), there are growing concerns that they\nlearn spurious correlations between videos and likely answers, reinforced by\ntheir black-box nature and remaining benchmarking biases. Our method explicitly\ngrounds VQA tasks to video fragments in four steps: entailment tree\nconstruction, video-language entailment verification, tree reasoning, and\ndynamic tree expansion. A vital benefit of the method is its generalizability\nto current video and image-based VLMs across reasoning types. To support fair\nevaluation, we devise a de-biasing procedure based on large-language models\nthat rewrites VQA benchmark answer sets to enforce model reasoning. Systematic\nexperiments on existing and de-biased benchmarks highlight the impact of our\nmethod components across benchmarks, VLMs, and reasoning types.",
      "tldr_zh": "这篇论文提出了第一个视频-grounded entailment tree reasoning 方法，用于改进常识视频问答（VQA），以解决大型视觉语言模型（VLMs）学习虚假相关性的问题。该方法通过四个步骤——entailment tree construction、video-language entailment verification、tree reasoning 和 dynamic tree expansion——将VQA任务显式地锚定到视频片段上，并展示出对不同VLMs和推理类型的通用性。为了公平评估，论文引入了一个基于大型语言模型的去偏置程序来重写VQA基准答案集，实验结果显示该方法在现有和去偏置基准上显著提升了模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05069v2",
      "published_date": "2025-01-09 08:44:42 UTC",
      "updated_date": "2025-03-25 03:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:58:52.827777"
    },
    {
      "arxiv_id": "2501.05068v2",
      "title": "D3RM: A Discrete Denoising Diffusion Refinement Model for Piano Transcription",
      "title_zh": "翻译失败",
      "authors": [
        "Hounsu Kim",
        "Taegyun Kwon",
        "Juhan Nam"
      ],
      "abstract": "Diffusion models have been widely used in the generative domain due to their\nconvincing performance in modeling complex data distributions. Moreover, they\nhave shown competitive results on discriminative tasks, such as image\nsegmentation. While diffusion models have also been explored for automatic\nmusic transcription, their performance has yet to reach a competitive level. In\nthis paper, we focus on discrete diffusion model's refinement capabilities and\npresent a novel architecture for piano transcription. Our model utilizes\nNeighborhood Attention layers as the denoising module, gradually predicting the\ntarget high-resolution piano roll, conditioned on the finetuned features of a\npretrained acoustic model. To further enhance refinement, we devise a novel\nstrategy which applies distinct transition states during training and inference\nstage of discrete diffusion models. Experiments on the MAESTRO dataset show\nthat our approach outperforms previous diffusion-based piano transcription\nmodels and the baseline model in terms of F1 score. Our code is available in\nhttps://github.com/hanshounsu/d3rm.",
      "tldr_zh": "本文提出 D3RM，一种基于离散去噪扩散模型的框架，用于提升钢琴转录任务的性能。该模型采用 Neighborhood Attention layers 作为去噪模块，逐步预测高分辨率 piano roll，并结合预训练声学模型的微调特征，同时引入一种新策略，使用不同的过渡状态来优化训练和推理阶段。实验结果显示，在 MAESTRO dataset 上，D3RM 在 F1 score 上超过了现有扩散模型和基线模型。该方法为音乐转录领域提供了更有效的精炼机制，并已在 GitHub 上开源。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05068v2",
      "published_date": "2025-01-09 08:44:06 UTC",
      "updated_date": "2025-01-13 12:06:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:59:04.764719"
    },
    {
      "arxiv_id": "2501.05067v2",
      "title": "LLaVA-Octopus: Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxing Zhao",
        "Boyuan Sun",
        "Xiang Chen",
        "Xihan Wei",
        "Qibin Hou"
      ],
      "abstract": "In this paper, we introduce LLaVA-Octopus, a novel video multimodal large\nlanguage model. LLaVA-Octopus adaptively weights features from different visual\nprojectors based on user instructions, enabling us to leverage the\ncomplementary strengths of each projector. We observe that different visual\nprojectors exhibit distinct characteristics when handling specific tasks. For\ninstance, some projectors excel at capturing static details, while others are\nmore effective at processing temporal information, and some are better suited\nfor tasks requiring temporal coherence. By dynamically adjusting feature\nweights according to user instructions, LLaVA-Octopus dynamically selects and\ncombines the most suitable features, significantly enhancing the model's\nperformance in multimodal tasks. Experimental results demonstrate that\nLLaVA-Octopus achieves excellent performance across multiple benchmarks,\nespecially in tasks such as video question answering, long video understanding,\nand comprehensive multi-choices benchmarks, highlighting its broad application\npotential.",
      "tldr_zh": "本文提出 LLaVA-Octopus，一种新型视频多模态大型语言模型，通过指令驱动的自适应投影器融合技术，根据用户指令动态加权不同 visual projectors 的特征，从而利用各投影器的互补优势，如捕捉静态细节、处理时间信息或确保时间连贯性。相比传统方法，该模型显著提升了多模态任务的性能，尤其在 video question answering、长视频理解和综合多选基准上表现出色。实验结果验证了 LLaVA-Octopus 的广泛应用潜力，为视频理解领域提供了创新解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05067v2",
      "published_date": "2025-01-09 08:43:57 UTC",
      "updated_date": "2025-03-14 07:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:59:16.396247"
    },
    {
      "arxiv_id": "2501.05066v1",
      "title": "Improving Skeleton-based Action Recognition with Interactive Object Information",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wen",
        "Ziqian Lu",
        "Fengli Shen",
        "Zhe-Ming Lu",
        "Jialin Cui"
      ],
      "abstract": "Human skeleton information is important in skeleton-based action recognition,\nwhich provides a simple and efficient way to describe human pose. However,\nexisting skeleton-based methods focus more on the skeleton, ignoring the\nobjects interacting with humans, resulting in poor performance in recognizing\nactions that involve object interactions. We propose a new action recognition\nframework introducing object nodes to supplement absent interactive object\ninformation. We also propose Spatial Temporal Variable Graph Convolutional\nNetworks (ST-VGCN) to effectively model the Variable Graph (VG) containing\nobject nodes. Specifically, in order to validate the role of interactive object\ninformation, by leveraging a simple self-training approach, we establish a new\ndataset, JXGC 24, and an extended dataset, NTU RGB+D+Object 60, including more\nthan 2 million additional object nodes. At the same time, we designe the\nVariable Graph construction method to accommodate a variable number of nodes\nfor graph structure. Additionally, we are the first to explore the overfitting\nissue introduced by incorporating additional object information, and we propose\na VG-based data augmentation method to address this issue, called Random Node\nAttack. Finally, regarding the network structure, we introduce two fusion\nmodules, CAF and WNPool, along with a novel Node Balance Loss, to enhance the\ncomprehensive performance by effectively fusing and balancing skeleton and\nobject node information. Our method surpasses the previous state-of-the-art on\nmultiple skeleton-based action recognition benchmarks. The accuracy of our\nmethod on NTU RGB+D 60 cross-subject split is 96.7\\%, and on cross-view split,\nit is 99.2\\%.",
      "tldr_zh": "这篇论文针对骨骼-based动作识别中忽略互动对象信息的局限性，提出了一种新框架，通过引入对象节点和Spatial Temporal Variable Graph Convolutional Networks (ST-VGCN)来有效建模包含对象节点的Variable Graph (VG)，从而提升识别涉及对象互动的动作性能。作者创建了新数据集JXGC 24和NTU RGB+D+Object 60，添加超过2百万对象节点，并首次探讨了加入额外对象信息导致的过拟合问题，提出Random Node Attack数据增强方法，以及CAF、WNPool融合模块和Node Balance Loss来平衡骨骼与对象节点信息。该方法在多个基准上超越现有最先进水平，在NTU RGB+D 60数据集的cross-subject和cross-view分割上分别达到96.7%和99.2%的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05066v1",
      "published_date": "2025-01-09 08:43:09 UTC",
      "updated_date": "2025-01-09 08:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:59:29.502772"
    },
    {
      "arxiv_id": "2501.05058v1",
      "title": "Simultaneous emulation and downscaling with physically-consistent deep learning-based regional ocean emulators",
      "title_zh": "翻译失败",
      "authors": [
        "Leonard Lupin-Jimenez",
        "Moein Darman",
        "Subhashis Hazarika",
        "Tianning Wu",
        "Michael Gray",
        "Ruyoing He",
        "Anthony Wong",
        "Ashesh Chattopadhyay"
      ],
      "abstract": "Building on top of the success in AI-based atmospheric emulation, we propose\nan AI-based ocean emulation and downscaling framework focusing on the\nhigh-resolution regional ocean over Gulf of Mexico. Regional ocean emulation\npresents unique challenges owing to the complex bathymetry and lateral boundary\nconditions as well as from fundamental biases in deep learning-based\nframeworks, such as instability and hallucinations. In this paper, we develop a\ndeep learning-based framework to autoregressively integrate ocean-surface\nvariables over the Gulf of Mexico at $8$ Km spatial resolution without\nunphysical drifts over decadal time scales and simulataneously downscale and\nbias-correct it to $4$ Km resolution using a physics-constrained generative\nmodel. The framework shows both short-term skills as well as accurate long-term\nstatistics in terms of mean and variability.",
      "tldr_zh": "该论文提出了一种基于 deep learning 的区域海洋模拟器框架，用于同时模拟和下采样墨西哥湾的高分辨率海洋数据，以应对复杂的海底地形、边界条件以及 deep learning 框架的偏见问题（如不稳定性）。框架采用 autoregressively 整合海洋表面变量，在 8 Km 分辨率下实现无非物理漂移的长期模拟，并使用 physics-constrained generative model 将其下采样到 4 Km 分辨率并进行偏差修正。结果显示，该方法在短期预测技能和长期统计（如均值和变异性）方面表现出色，为 AI-based 海洋模拟提供了可靠的解决方案。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG",
        "nlin.CD",
        "physics.geo-ph"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05058v1",
      "published_date": "2025-01-09 08:28:31 UTC",
      "updated_date": "2025-01-09 08:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:59:40.788068"
    },
    {
      "arxiv_id": "2501.05057v1",
      "title": "LearningFlow: Automated Policy Learning Workflow for Urban Driving with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zengqi Peng",
        "Yubin Wang",
        "Xu Han",
        "Lei Zheng",
        "Jun Ma"
      ],
      "abstract": "Recent advancements in reinforcement learning (RL) demonstrate the\nsignificant potential in autonomous driving. Despite this promise, challenges\nsuch as the manual design of reward functions and low sample efficiency in\ncomplex environments continue to impede the development of safe and effective\ndriving policies. To tackle these issues, we introduce LearningFlow, an\ninnovative automated policy learning workflow tailored to urban driving. This\nframework leverages the collaboration of multiple large language model (LLM)\nagents throughout the RL training process. LearningFlow includes a curriculum\nsequence generation process and a reward generation process, which work in\ntandem to guide the RL policy by generating tailored training curricula and\nreward functions. Particularly, each process is supported by an analysis agent\nthat evaluates training progress and provides critical insights to the\ngeneration agent. Through the collaborative efforts of these LLM agents,\nLearningFlow automates policy learning across a series of complex driving\ntasks, and it significantly reduces the reliance on manual reward function\ndesign while enhancing sample efficiency. Comprehensive experiments are\nconducted in the high-fidelity CARLA simulator, along with comparisons with\nother existing methods, to demonstrate the efficacy of our proposed approach.\nThe results demonstrate that LearningFlow excels in generating rewards and\ncurricula. It also achieves superior performance and robust generalization\nacross various driving tasks, as well as commendable adaptation to different RL\nalgorithms.",
      "tldr_zh": "该论文提出 LearningFlow，一种针对城市驾驶的自动策略学习工作流，利用多个大型语言模型 (LLM) 代理来辅助强化学习 (RL) 训练，解决手动设计奖励函数和低样本效率的挑战。该框架包括课程序列生成和奖励生成过程，由分析代理评估训练进度并提供见解，从而自动化生成定制化的训练课程和奖励函数。在高保真 CARLA 模拟器中进行的实验表明，LearningFlow 比现有方法表现出色，实现了更高的性能、鲁棒的泛化能力和对不同 RL 算法的出色适应性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05057v1",
      "published_date": "2025-01-09 08:28:16 UTC",
      "updated_date": "2025-01-09 08:28:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T21:59:52.589012"
    },
    {
      "arxiv_id": "2501.05053v1",
      "title": "TAPFed: Threshold Secure Aggregation for Privacy-Preserving Federated Learning",
      "title_zh": "TAPFed：阈值安全聚合用于保护隐私的联邦学习",
      "authors": [
        "Runhua Xu",
        "Bo Li",
        "Chao Li",
        "James B. D. Joshi",
        "Shuai Ma",
        "Jianxin Li"
      ],
      "abstract": "Federated learning is a computing paradigm that enhances privacy by enabling\nmultiple parties to collaboratively train a machine learning model without\nrevealing personal data. However, current research indicates that traditional\nfederated learning platforms are unable to ensure privacy due to privacy leaks\ncaused by the interchange of gradients. To achieve privacy-preserving federated\nlearning, integrating secure aggregation mechanisms is essential.\nUnfortunately, existing solutions are vulnerable to recently demonstrated\ninference attacks such as the disaggregation attack. This paper proposes\nTAPFed, an approach for achieving privacy-preserving federated learning in the\ncontext of multiple decentralized aggregators with malicious actors. TAPFed\nuses a proposed threshold functional encryption scheme and allows for a certain\nnumber of malicious aggregators while maintaining security and privacy. We\nprovide formal security and privacy analyses of TAPFed and compare it to\nvarious baselines through experimental evaluation. Our results show that TAPFed\noffers equivalent performance in terms of model quality compared to\nstate-of-the-art approaches while reducing transmission overhead by 29%-45%\nacross different model training scenarios. Most importantly, TAPFed can defend\nagainst recently demonstrated inference attacks caused by curious aggregators,\nwhich the majority of existing approaches are susceptible to.",
      "tldr_zh": "本论文提出TAPFed，一种基于阈值功能加密（threshold functional encryption）的安全聚合机制，用于隐私保护联邦学习（Federated Learning），以应对现有方法在梯度交换中面临的隐私泄露和推理攻击问题。TAPFed在多个去中心化聚合器环境中允许一定数量的恶意参与者，同时通过正式的安全和隐私分析确保系统鲁棒性。实验结果显示，TAPFed在模型质量上与最先进方法相当，却将传输开销降低了29%-45%，并有效防御了最近的推理攻击。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "The paper has been published in IEEE TDSC",
      "pdf_url": "http://arxiv.org/pdf/2501.05053v1",
      "published_date": "2025-01-09 08:24:10 UTC",
      "updated_date": "2025-01-09 08:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:00:04.589030"
    },
    {
      "arxiv_id": "2501.05032v1",
      "title": "Enhancing Human-Like Responses in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ethem Yağız Çalık",
        "Talha Rüzgar Akkuş"
      ],
      "abstract": "This paper explores the advancements in making large language models (LLMs)\nmore human-like. We focus on techniques that enhance natural language\nunderstanding, conversational coherence, and emotional intelligence in AI\nsystems. The study evaluates various approaches, including fine-tuning with\ndiverse datasets, incorporating psychological principles, and designing models\nthat better mimic human reasoning patterns. Our findings demonstrate that these\nenhancements not only improve user interactions but also open new possibilities\nfor AI applications across different domains. Future work will address the\nethical implications and potential biases introduced by these human-like\nattributes.",
      "tldr_zh": "这篇论文探讨了如何增强大型语言模型 (LLMs) 的人类化响应，重点提升自然语言理解、对话连贯性和情感智能。研究方法包括使用多样数据集进行微调、整合心理学原理，以及设计模仿人类推理模式的模型。这些增强措施显著改善了用户互动体验，并为 AI 在不同领域的应用打开了新可能性。未来工作将关注这些人类化属性的伦理影响和潜在偏见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05032v1",
      "published_date": "2025-01-09 07:44:06 UTC",
      "updated_date": "2025-01-09 07:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:02:16.874267"
    },
    {
      "arxiv_id": "2501.05030v1",
      "title": "A General Retrieval-Augmented Generation Framework for Multimodal Case-Based Reasoning Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Ofir Marom"
      ],
      "abstract": "Case-based reasoning (CBR) is an experience-based approach to problem\nsolving, where a repository of solved cases is adapted to solve new cases.\nRecent research shows that Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG) can support the Retrieve and Reuse stages\nof the CBR pipeline by retrieving similar cases and using them as additional\ncontext to an LLM query. Most studies have focused on text-only applications,\nhowever, in many real-world problems the components of a case are multimodal.\nIn this paper we present MCBR-RAG, a general RAG framework for multimodal CBR\napplications. The MCBR-RAG framework converts non-text case components into\ntext-based representations, allowing it to: 1) learn application-specific\nlatent representations that can be indexed for retrieval, and 2) enrich the\nquery provided to the LLM by incorporating all case components for better\ncontext. We demonstrate MCBR-RAG's effectiveness through experiments conducted\non a simplified Math-24 application and a more complex Backgammon application.\nOur empirical results show that MCBR-RAG improves generation quality compared\nto a baseline LLM with no contextual information provided.",
      "tldr_zh": "本文提出一个通用的 Retrieval-Augmented Generation (RAG) 框架 MCBR-RAG，用于多模态 Case-based Reasoning (CBR) 应用，以处理现实问题中包含文本以外组件的案例。框架通过将非文本案例组件转换为文本表示，实现应用特定的潜在表示索引和检索，以及丰富 Large Language Models (LLMs) 查询的上下文，从而提升问题解决的准确性。在 Math-24 和 Backgammon 应用上的实验中，MCBR-RAG 比无上下文基线 LLM 显著提高了生成质量。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05030v1",
      "published_date": "2025-01-09 07:41:22 UTC",
      "updated_date": "2025-01-09 07:41:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:00:29.240077"
    },
    {
      "arxiv_id": "2501.05490v1",
      "title": "Interpretable deep learning illuminates multiple structures fluorescence imaging: a path toward trustworthy artificial intelligence in microscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyang Chen",
        "Luhong Jin",
        "Xuwei Xuan",
        "Defu Yang",
        "Yun Cheng",
        "Ju Zhang"
      ],
      "abstract": "Live-cell imaging of multiple subcellular structures is essential for\nunderstanding subcellular dynamics. However, the conventional multi-color\nsequential fluorescence microscopy suffers from significant imaging delays and\nlimited number of subcellular structure separate labeling, resulting in\nsubstantial limitations for real-time live-cell research applications. Here, we\npresent the Adaptive Explainable Multi-Structure Network (AEMS-Net), a\ndeep-learning framework that enables simultaneous prediction of two subcellular\nstructures from a single image. The model normalizes staining intensity and\nprioritizes critical image features by integrating attention mechanisms and\nbrightness adaptation layers. Leveraging the Kolmogorov-Arnold representation\ntheorem, our model decomposes learned features into interpretable univariate\nfunctions, enhancing the explainability of complex subcellular morphologies. We\ndemonstrate that AEMS-Net allows real-time recording of interactions between\nmitochondria and microtubules, requiring only half the conventional\nsequential-channel imaging procedures. Notably, this approach achieves over 30%\nimprovement in imaging quality compared to traditional deep learning methods,\nestablishing a new paradigm for long-term, interpretable live-cell imaging that\nadvances the ability to explore subcellular dynamics.",
      "tldr_zh": "该研究针对传统多色荧光显微镜在活细胞成像中的成像延迟和标签限制问题，提出了一种深度学习框架——Adaptive Explainable Multi-Structure Network (AEMS-Net)，能够从单张图像中同时预测两个亚细胞结构。AEMS-Net 通过整合注意力机制和亮度适应层来标准化染色强度并优先关键特征，并利用 Kolmogorov-Arnold representation theorem 将学习特征分解为可解释的单变量函数，从而提升模型的可解释性和可信度。实验结果显示，该方法在记录线粒体和微管相互作用时，仅需传统顺序成像程序的一半时间，并将成像质量提高超过30%，为可信任的 AI 在显微镜领域的应用开辟新范式。",
      "categories": [
        "q-bio.SC",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.SC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05490v1",
      "published_date": "2025-01-09 07:36:28 UTC",
      "updated_date": "2025-01-09 07:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:02:29.076139"
    },
    {
      "arxiv_id": "2501.05018v1",
      "title": "Finding Needles in Emb(a)dding Haystacks: Legal Document Retrieval via Bagging and SVR Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Bönisch",
        "Alexander Mehler"
      ],
      "abstract": "We introduce a retrieval approach leveraging Support Vector Regression (SVR)\nensembles, bootstrap aggregation (bagging), and embedding spaces on the German\nDataset for Legal Information Retrieval (GerDaLIR). By conceptualizing the\nretrieval task in terms of multiple binary needle-in-a-haystack subtasks, we\nshow improved recall over the baselines (0.849 > 0.803 | 0.829) using our\nvoting ensemble, suggesting promising initial results, without training or\nfine-tuning any deep learning models. Our approach holds potential for further\nenhancement, particularly through refining the encoding models and optimizing\nhyperparameters.",
      "tldr_zh": "本文提出了一种法律文档检索方法，利用 Support Vector Regression (SVR) 集成、bootstrap aggregation (bagging) 和 embedding spaces，在 German Dataset for Legal Information Retrieval (GerDaLIR) 数据集上进行测试。通过将检索任务分解为多个二元 needle-in-a-haystack 子任务，并采用投票集成，该方法在不需训练或微调深度学习模型的情况下，实现了比基线更高的召回率（0.849 > 0.803 | 0.829）。实验结果显示，该方法具有良好的初步效果，并有潜力通过优化编码模型和超参数进一步提升性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05018v1",
      "published_date": "2025-01-09 07:21:44 UTC",
      "updated_date": "2025-01-09 07:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:02:40.403877"
    },
    {
      "arxiv_id": "2501.05015v1",
      "title": "On Measuring Unnoticeability of Graph Adversarial Attacks: Observations, New Measure, and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonsoo Jo",
        "Hyunjin Hwang",
        "Fanchen Bu",
        "Soo Yong Lee",
        "Chanyoung Park",
        "Kijung Shin"
      ],
      "abstract": "Adversarial attacks are allegedly unnoticeable. Prior studies have designed\nattack noticeability measures on graphs, primarily using statistical tests to\ncompare the topology of original and (possibly) attacked graphs. However, we\nobserve two critical limitations in the existing measures. First, because the\nmeasures rely on simple rules, attackers can readily enhance their attacks to\nbypass them, reducing their attack \"noticeability\" and, yet, maintaining their\nattack performance. Second, because the measures naively leverage global\nstatistics, such as degree distributions, they may entirely overlook attacks\nuntil severe perturbations occur, letting the attacks be almost \"totally\nunnoticeable.\" To address the limitations, we introduce HideNSeek, a learnable\nmeasure for graph attack noticeability. First, to mitigate the bypass problem,\nHideNSeek learns to distinguish the original and (potential) attack edges using\na learnable edge scorer (LEO), which scores each edge on its likelihood of\nbeing an attack. Second, to mitigate the overlooking problem, HideNSeek\nconducts imbalance-aware aggregation of all the edge scores to obtain the final\nnoticeability score. Using six real-world graphs, we empirically demonstrate\nthat HideNSeek effectively alleviates the observed limitations, and LEO (i.e.,\nour learnable edge scorer) outperforms eleven competitors in distinguishing\nattack edges under five different attack methods. For an additional\napplication, we show that LEO boost the performance of robust GNNs by removing\nattack-like edges.",
      "tldr_zh": "本研究分析了图对抗攻击（Graph Adversarial Attacks）的不可察觉性测量问题，指出现有方法依赖简单规则易被绕过，且基于全局统计（如度分布）可能忽略轻微攻击。论文提出了一种可学习测量方法HideNSeek，使用可学习的边评分器（LEO）来评估每个边的攻击可能性，并通过不平衡感知聚合计算最终不可察觉性分数。实验在六个真实世界图上表明，HideNSeek有效缓解了这些局限，LEO在五种攻击方法下优于11个竞争对手。此外，LEO可用于提升鲁棒GNNs（Robust GNNs）的性能，通过移除类似攻击的边。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05015v1",
      "published_date": "2025-01-09 07:16:21 UTC",
      "updated_date": "2025-01-09 07:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:23.207098"
    },
    {
      "arxiv_id": "2501.05014v2",
      "title": "UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Oleg Sautenkov",
        "Yasheerah Yaqoot",
        "Artem Lykov",
        "Muhammad Ahsan Mustafa",
        "Grik Tadevosyan",
        "Aibek Akhmetkazy",
        "Miguel Altamirano Cabrera",
        "Mikhail Martynov",
        "Sausar Karaf",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "The UAV-VLA (Visual-Language-Action) system is a tool designed to facilitate\ncommunication with aerial robots. By integrating satellite imagery processing\nwith the Visual Language Model (VLM) and the powerful capabilities of GPT,\nUAV-VLA enables users to generate general flight paths-and-action plans through\nsimple text requests. This system leverages the rich contextual information\nprovided by satellite images, allowing for enhanced decision-making and mission\nplanning. The combination of visual analysis by VLM and natural language\nprocessing by GPT can provide the user with the path-and-action set, making\naerial operations more efficient and accessible. The newly developed method\nshowed the difference in the length of the created trajectory in 22% and the\nmean error in finding the objects of interest on a map in 34.22 m by Euclidean\ndistance in the K-Nearest Neighbors (KNN) approach.",
      "tldr_zh": "该研究提出UAV-VLA系统，这是一个整合卫星图像处理、Visual Language Model (VLM) 和 GPT 的工具，允许用户通过简单文本请求生成大规模空中任务的飞行路径和行动计划。系统利用卫星图像的丰富上下文信息，结合VLM的视觉分析和GPT的自然语言处理，提升决策和任务规划的效率与可访问性。新方法在实验中显示，轨迹长度差异为22%，并在K-Nearest Neighbors (KNN)方法下，查找兴趣对象的均误差为34.22米。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "HRI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.05014v2",
      "published_date": "2025-01-09 07:15:59 UTC",
      "updated_date": "2025-05-13 06:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:03:04.599952"
    },
    {
      "arxiv_id": "2501.05007v1",
      "title": "Quantum-enhanced causal discovery for a small number of samples",
      "title_zh": "针对少量样本的量子增强因果发现",
      "authors": [
        "Yota Maeda",
        "Ken Arai",
        "Yu Tanaka",
        "Yu Terada",
        "Hiroshi Ueno",
        "Hiroyuki Tezuka"
      ],
      "abstract": "The discovery of causal relationships from observed data has attracted\nsignificant interest from disciplines such as economics, social sciences,\nepidemiology, and biology. In practical applications, considerable knowledge of\nthe underlying systems is often unavailable, and real data are often associated\nwith nonlinear causal structures, which make the direct use of most\nconventional causality analysis methods difficult. This study proposes a novel\nquantum Peter-Clark (qPC) algorithm for causal discovery that does not assume\nany underlying model structures. Based on the independence conditional tests in\na class of reproducing kernel Hilbert spaces characterized by quantum circuits,\nthe proposed qPC algorithm can explore causal relationships from the observed\ndata drawn from arbitrary distributions. We conducted systematic experiments on\nfundamental graph parts of causal structures, demonstrating that the qPC\nalgorithm exhibits a significantly better performance, particularly with\nsmaller sample sizes compared to its classical counterpart. Furthermore, we\nproposed a novel optimization approach based on Kernel Target Alignment (KTA)\nfor determining hyperparameters of quantum kernels. This method effectively\nreduced the risk of false positives in causal discovery, enabling more reliable\ninference. Our theoretical and experimental results demonstrate that the\nproposed quantum algorithm can empower classical algorithms for robust and\naccurate inference in causal discovery, supporting them in regimes where\nclassical algorithms typically fail. Additionally, the effectiveness of this\nmethod was validated using the Boston Housing dataset as a real-world\napplication. These findings demonstrate the new potential of quantum\ncircuit-based causal discovery methods in addressing practical challenges,\nparticularly in small-sample scenarios where traditional approaches have shown\nlimitations.",
      "tldr_zh": "本文提出了一种量子增强的 Peter-Clark (qPC) 算法，用于从少量样本中发现因果关系，该算法基于量子电路的独立条件测试，在再现核希尔伯特空间中处理任意分布的数据，而不假设任何底层模型结构。实验结果显示，qPC 算法在小样本场景下比经典对应算法性能显著提升，尤其在基础图结构测试中表现出色，并通过 Kernel Target Alignment (KTA) 优化方法有效降低了假阳性风险。总体而言，该方法在 Boston Housing 数据集的实际应用中验证了其鲁棒性和准确性，展示了量子电路在因果发现中的新潜力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "quant-ph",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05007v1",
      "published_date": "2025-01-09 07:05:22 UTC",
      "updated_date": "2025-01-09 07:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:22.852608"
    },
    {
      "arxiv_id": "2501.04997v1",
      "title": "GiNet: Integrating Sequential and Context-Aware Learning for Battery Capacity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Sameer",
        "Wei Zhang",
        "Xin Lou",
        "Qingyu Yan",
        "Terence Goh",
        "Yulin Gao"
      ],
      "abstract": "The surging demand for batteries requires advanced battery management\nsystems, where battery capacity modelling is a key functionality. In this\npaper, we aim to achieve accurate battery capacity prediction by learning from\nhistorical measurements of battery dynamics. We propose GiNet, a gated\nrecurrent units enhanced Informer network, for predicting battery's capacity.\nThe novelty and competitiveness of GiNet lies in its capability of capturing\nsequential and contextual information from raw battery data and reflecting the\nbattery's complex behaviors with both temporal dynamics and long-term\ndependencies. We conducted an experimental study based on a publicly available\ndataset to showcase GiNet's strength of gaining a holistic understanding of\nbattery behavior and predicting battery capacity accurately. GiNet achieves\n0.11 mean absolute error for predicting the battery capacity in a sequence of\nfuture time slots without knowing the historical battery capacity. It also\noutperforms the latest algorithms significantly with 27% error reduction on\naverage compared to Informer. The promising results highlight the importance of\ncustomized and optimized integration of algorithm and battery knowledge and\nshed light on other industry applications as well.",
      "tldr_zh": "本文提出 GiNet，一种基于 gated recurrent units 增强的 Informer 网络，用于从历史电池动态测量数据中实现准确的电池容量预测。GiNet 的创新在于整合顺序学习和上下文感知能力，以捕获电池行为的时序动态和长期依赖。实验在公开数据集上显示，GiNet 在预测未来时间槽的电池容量时，mean absolute error 仅为 0.11，并比 Informer 算法平均减少 27% 的错误。这些结果强调了算法与电池知识定制整合的重要性，并为其他工业应用提供潜在启发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.04997v1",
      "published_date": "2025-01-09 06:26:28 UTC",
      "updated_date": "2025-01-09 06:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:03:28.929436"
    },
    {
      "arxiv_id": "2501.04995v1",
      "title": "IPDN: Image-enhanced Prompt Decoding Network for 3D Referring Expression Segmentation",
      "title_zh": "IPDN",
      "authors": [
        "Qi Chen",
        "Changli Wu",
        "Jiayi Ji",
        "Yiwei Ma",
        "Danni Yang",
        "Xiaoshuai Sun"
      ],
      "abstract": "3D Referring Expression Segmentation (3D-RES) aims to segment point cloud\nscenes based on a given expression. However, existing 3D-RES approaches face\ntwo major challenges: feature ambiguity and intent ambiguity. Feature ambiguity\narises from information loss or distortion during point cloud acquisition due\nto limitations such as lighting and viewpoint. Intent ambiguity refers to the\nmodel's equal treatment of all queries during the decoding process, lacking\ntop-down task-specific guidance. In this paper, we introduce an Image enhanced\nPrompt Decoding Network (IPDN), which leverages multi-view images and\ntask-driven information to enhance the model's reasoning capabilities. To\naddress feature ambiguity, we propose the Multi-view Semantic Embedding (MSE)\nmodule, which injects multi-view 2D image information into the 3D scene and\ncompensates for potential spatial information loss. To tackle intent ambiguity,\nwe designed a Prompt-Aware Decoder (PAD) that guides the decoding process by\nderiving task-driven signals from the interaction between the expression and\nvisual features. Comprehensive experiments demonstrate that IPDN outperforms\nthe state-ofthe-art by 1.9 and 4.2 points in mIoU metrics on the 3D-RES and\n3D-GRES tasks, respectively.",
      "tldr_zh": "该论文针对3D Referring Expression Segmentation (3D-RES)任务，提出了一种Image-enhanced Prompt Decoding Network (IPDN)，以解决特征模糊和意图模糊两大挑战。IPDN通过Multi-view Semantic Embedding (MSE)模块注入多视图2D图像信息，补偿点云获取中的空间信息丢失；同时，设计Prompt-Aware Decoder (PAD)模块，利用表达式与视觉特征的交互提供任务驱动信号，指导解码过程。实验结果显示，IPDN在3D-RES和3D-GRES任务上分别比现有最先进方法提升1.9和4.2点的mIoU指标，显著提高了分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.04995v1",
      "published_date": "2025-01-09 06:20:00 UTC",
      "updated_date": "2025-01-09 06:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:03:40.538995"
    },
    {
      "arxiv_id": "2501.04982v1",
      "title": "CuRLA: Curriculum Learning Based Deep Reinforcement Learning for Autonomous Driving",
      "title_zh": "CuRLA：基于课程学习的深度强化学习用于自动驾驶",
      "authors": [
        "Bhargava Uppuluri",
        "Anjel Patel",
        "Neil Mehta",
        "Sridhar Kamath",
        "Pratyush Chakraborty"
      ],
      "abstract": "In autonomous driving, traditional Computer Vision (CV) agents often struggle\nin unfamiliar situations due to biases in the training data. Deep Reinforcement\nLearning (DRL) agents address this by learning from experience and maximizing\nrewards, which helps them adapt to dynamic environments. However, ensuring\ntheir generalization remains challenging, especially with static training\nenvironments. Additionally, DRL models lack transparency, making it difficult\nto guarantee safety in all scenarios, particularly those not seen during\ntraining. To tackle these issues, we propose a method that combines DRL with\nCurriculum Learning for autonomous driving. Our approach uses a Proximal Policy\nOptimization (PPO) agent and a Variational Autoencoder (VAE) to learn safe\ndriving in the CARLA simulator. The agent is trained using two-fold curriculum\nlearning, progressively increasing environment difficulty and incorporating a\ncollision penalty in the reward function to promote safety. This method\nimproves the agent's adaptability and reliability in complex environments, and\nunderstand the nuances of balancing multiple reward components from different\nfeedback signals in a single scalar reward function. Keywords: Computer Vision,\nDeep Reinforcement Learning, Variational Autoencoder, Proximal Policy\nOptimization, Curriculum Learning, Autonomous Driving.",
      "tldr_zh": "该论文提出 CuRLA 方法，将 Curriculum Learning 与 Deep Reinforcement Learning (DRL) 结合，用于解决自动驾驶中代理的泛化性和安全性问题。方法采用 Proximal Policy Optimization (PPO) 代理和 Variational Autoencoder (VAE) 在 CARLA 模拟器中训练，通过两折课程学习逐步增加环境难度，并在奖励函数中加入碰撞惩罚，以提升代理的适应性和可靠性。实验结果显示，该方法显著改善了代理在动态场景下的表现，并有助于理解从多个反馈信号中平衡单一标量奖励函数的细微差别。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "To be published in the 17th International Conference on Agents and\n  Artificial Intelligence (ICAART), Feb 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.04982v1",
      "published_date": "2025-01-09 05:45:03 UTC",
      "updated_date": "2025-01-09 05:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:03:52.774024"
    },
    {
      "arxiv_id": "2501.04974v3",
      "title": "SensorQA: A Question Answering Benchmark for Daily-Life Monitoring",
      "title_zh": "SensorQA：用于日常生活监测的问答基准",
      "authors": [
        "Benjamin Reichman",
        "Xiaofan Yu",
        "Lanxiang Hu",
        "Jack Truxal",
        "Atishay Jain",
        "Rushil Chandrupatla",
        "Tajana Šimunić Rosing",
        "Larry Heck"
      ],
      "abstract": "With the rapid growth in sensor data, effectively interpreting and\ninterfacing with these data in a human-understandable way has become crucial.\nWhile existing research primarily focuses on learning classification models,\nfewer studies have explored how end users can actively extract useful insights\nfrom sensor data, often hindered by the lack of a proper dataset. To address\nthis gap, we introduce SensorQA, the first human-created question-answering\n(QA) dataset for long-term time-series sensor data for daily life monitoring.\nSensorQA is created by human workers and includes 5.6K diverse and practical\nqueries that reflect genuine human interests, paired with accurate answers\nderived from sensor data. We further establish benchmarks for state-of-the-art\nAI models on this dataset and evaluate their performance on typical edge\ndevices. Our results reveal a gap between current models and optimal QA\nperformance and efficiency, highlighting the need for new contributions. The\ndataset and code are available at:\nhttps://github.com/benjamin-reichman/SensorQA.",
      "tldr_zh": "该论文引入了SensorQA，这是一个针对日常监测的长期时间序列传感器数据的Question Answering (QA)基准数据集，由人类工作者创建，包括5.6K个多样且实用的查询及其基于传感器数据的准确答案。SensorQA旨在填补现有研究中用户从传感器数据中提取洞察的空白，并通过评估最先进AI模型的性能来建立基准。实验结果显示，这些模型在QA任务上存在性能和效率差距，突显了需要进一步改进的需求；数据集和代码已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04974v3",
      "published_date": "2025-01-09 05:06:44 UTC",
      "updated_date": "2025-03-03 17:03:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:04.921260"
    },
    {
      "arxiv_id": "2501.04970v1",
      "title": "Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "HyunGi Kim",
        "Siwon Kim",
        "Jisoo Mok",
        "Sungroh Yoon"
      ],
      "abstract": "Deep Neural Networks have spearheaded remarkable advancements in time series\nforecasting (TSF), one of the major tasks in time series modeling. Nonetheless,\nthe non-stationarity of time series undermines the reliability of pre-trained\nsource time series forecasters in mission-critical deployment settings. In this\nstudy, we introduce a pioneering test-time adaptation framework tailored for\nTSF (TSF-TTA). TAFAS, the proposed approach to TSF-TTA, flexibly adapts source\nforecasters to continuously shifting test distributions while preserving the\ncore semantic information learned during pre-training. The novel utilization of\npartially-observed ground truth and gated calibration module enables proactive,\nrobust, and model-agnostic adaptation of source forecasters. Experiments on\ndiverse benchmark datasets and cutting-edge architectures demonstrate the\nefficacy and generality of TAFAS, especially in long-term forecasting scenarios\nthat suffer from significant distribution shifts. The code is available at\nhttps://github.com/kimanki/TAFAS.",
      "tldr_zh": "这篇论文针对时间序列预测（Time Series Forecasting, TSF）中的非平稳性（Non-stationarity）问题，提出了一种创新的测试时适应框架（Test-time Adaptation for TSF, TSF-TTA）。TAFAS 方法通过利用部分观察到的真实值（Partially-observed ground truth）和门控校准模块（Gated calibration module），实现源预测模型的主动、稳健且模型无关的适应，同时保留预训练的核心语义信息。实验在多种基准数据集和前沿架构上验证了 TAFAS 的有效性和通用性，尤其在长期预测场景中显著缓解分布偏移问题。代码已开源，可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.04970v1",
      "published_date": "2025-01-09 04:59:15 UTC",
      "updated_date": "2025-01-09 04:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:17.542189"
    },
    {
      "arxiv_id": "2501.14790v1",
      "title": "Towards Dynamic Neural Communication and Speech Neuroprosthesis Based on Viseme Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Ji-Ha Park",
        "Seo-Hyun Lee",
        "Soowon Kim",
        "Seong-Whan Lee"
      ],
      "abstract": "Decoding text, speech, or images from human neural signals holds promising\npotential both as neuroprosthesis for patients and as innovative communication\ntools for general users. Although neural signals contain various information on\nspeech intentions, movements, and phonetic details, generating informative\noutputs from them remains challenging, with mostly focusing on decoding short\nintentions or producing fragmented outputs. In this study, we developed a\ndiffusion model-based framework to decode visual speech intentions from\nspeech-related non-invasive brain signals, to facilitate face-to-face neural\ncommunication. We designed an experiment to consolidate various phonemes to\ntrain visemes of each phoneme, aiming to learn the representation of\ncorresponding lip formations from neural signals. By decoding visemes from both\nisolated trials and continuous sentences, we successfully reconstructed\ncoherent lip movements, effectively bridging the gap between brain signals and\ndynamic visual interfaces. The results highlight the potential of viseme\ndecoding and talking face reconstruction from human neural signals, marking a\nsignificant step toward dynamic neural communication systems and speech\nneuroprosthesis for patients.",
      "tldr_zh": "本研究开发了一个基于diffusion model的框架，从非侵入性脑信号中解码viseme（视觉语音意图），旨在实现动态神经通信和语音神经假肢，支持面对面交流和患者辅助。\n方法包括设计实验整合各种音素来训练每个viseme的表示，从而从神经信号中学习并重构对应的唇部运动。\n实验结果显示，该框架成功从孤立试验和连续句子中解码viseme，重构出连贯的唇部运动，标志着从脑信号到动态视觉接口的关键进展。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "q-bio.NC",
      "comment": "5 pages, 5 figures, 1 table, Name of Conference: 2025 IEEE\n  International Conference on Acoustics, Speech, and Signal Processing",
      "pdf_url": "http://arxiv.org/pdf/2501.14790v1",
      "published_date": "2025-01-09 04:47:27 UTC",
      "updated_date": "2025-01-09 04:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:35.599693"
    },
    {
      "arxiv_id": "2501.04961v2",
      "title": "Demystifying Domain-adaptive Post-training for Financial LLMs",
      "title_zh": "解密针对金融LLMs的领域自适应后训练",
      "authors": [
        "Zixuan Ke",
        "Yifei Ming",
        "Xuan-Phi Nguyen",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "Domain-adaptive post-training of large language models (LLMs) has emerged as\na promising approach for specialized domains such as medicine and finance.\nHowever, significant challenges remain in identifying optimal adaptation\ncriteria and training strategies across varying data and model configurations.\nTo address these challenges, we introduce FINDAP, a systematic and fine-grained\ninvestigation into domain adaptive post-training of LLMs for the finance\ndomain. Our approach consists of four key components: FinCap, which defines the\ncore capabilities required for the target domain; FinRec, an effective training\nrecipe that jointly optimizes continual pre-training and instruction-following,\nalong with a novel preference data distillation method leveraging process\nsignals from a generative reward model; FinTrain, a curated set of training\ndatasets supporting FinRec; and FinEval, a comprehensive evaluation suite\naligned with FinCap. The resulting model, Llama-Fin, achieves state-of-the-art\nperformance across a wide range of financial tasks. Our analysis also\nhighlights how each post-training stage contributes to distinct capabilities,\nuncovering specific challenges and effective solutions, providing valuable\ninsights for domain adaptation of LLMs.",
      "tldr_zh": "这篇论文介绍了FINDAP框架，用于系统调查金融领域LLMs的领域自适应后训练，旨在解决数据和模型配置的优化挑战。FINDAP包括四个关键组件：FinCap定义金融核心能力、FinRec联合优化持续预训练和指令遵循并引入偏好数据蒸馏方法、FinTrain提供精选训练数据集，以及FinEval进行全面评估。最终，开发的Llama-Fin模型在各种金融任务上实现了最先进性能，并通过分析揭示了每个后训练阶段对能力的贡献以及相应的挑战和解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04961v2",
      "published_date": "2025-01-09 04:26:15 UTC",
      "updated_date": "2025-02-12 04:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:46.456931"
    },
    {
      "arxiv_id": "2501.04958v1",
      "title": "Addressing Domain Shift via Imbalance-Aware Domain Adaptation in Embryo Development Assessment",
      "title_zh": "通过不平衡感知领域适应处理胚胎发育评估中的领域偏移",
      "authors": [
        "Lei Li",
        "Xinglin Zhang",
        "Jun Liang",
        "Tao Chen"
      ],
      "abstract": "Deep learning models in medical imaging face dual challenges: domain shift,\nwhere models perform poorly when deployed in settings different from their\ntraining environment, and class imbalance, where certain disease conditions are\nnaturally underrepresented. We present Imbalance-Aware Domain Adaptation\n(IADA), a novel framework that simultaneously tackles both challenges through\nthree key components: (1) adaptive feature learning with class-specific\nattention mechanisms, (2) balanced domain alignment with dynamic weighting, and\n(3) adaptive threshold optimization. Our theoretical analysis establishes\nconvergence guarantees and complexity bounds. Through extensive experiments on\nembryo development assessment across four imaging modalities, IADA demonstrates\nsignificant improvements over existing methods, achieving up to 25.19\\% higher\naccuracy while maintaining balanced performance across classes. In challenging\nscenarios with low-quality imaging systems, IADA shows robust generalization\nwith AUC improvements of up to 12.56\\%. These results demonstrate IADA's\npotential for developing reliable and equitable medical imaging systems for\ndiverse clinical settings. The code is made public available at\n\\url{https://github.com/yinghemedical/imbalance-aware_domain_adaptation}",
      "tldr_zh": "该研究针对医疗成像中的 domain shift 和 class imbalance 问题，提出了一种新型框架 Imbalance-Aware Domain Adaptation (IADA)，旨在同时处理领域偏移和类别不平衡。该框架包括三个关键组件：自适应特征学习（使用 class-specific attention mechanisms）、平衡领域对齐（通过 dynamic weighting）和自适应阈值优化，并通过理论分析建立了收敛保证和复杂度边界。在胚胎发育评估的四个成像模式实验中，IADA 比现有方法准确率提高了高达 25.19%，并在低质量成像系统中 AUC 提升了 12.56%，展示了其在构建可靠且公平的医疗成像系统方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.04958v1",
      "published_date": "2025-01-09 04:20:12 UTC",
      "updated_date": "2025-01-09 04:20:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:04:59.641052"
    },
    {
      "arxiv_id": "2501.04952v1",
      "title": "Open Problems in Machine Unlearning for AI Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Fazl Barez",
        "Tingchen Fu",
        "Ameya Prabhu",
        "Stephen Casper",
        "Amartya Sanyal",
        "Adel Bibi",
        "Aidan O'Gara",
        "Robert Kirk",
        "Ben Bucknall",
        "Tim Fist",
        "Luke Ong",
        "Philip Torr",
        "Kwok-Yan Lam",
        "Robert Trager",
        "David Krueger",
        "Sören Mindermann",
        "José Hernandez-Orallo",
        "Mor Geva",
        "Yarin Gal"
      ],
      "abstract": "As AI systems become more capable, widely deployed, and increasingly\nautonomous in critical areas such as cybersecurity, biological research, and\nhealthcare, ensuring their safety and alignment with human values is paramount.\nMachine unlearning -- the ability to selectively forget or suppress specific\ntypes of knowledge -- has shown promise for privacy and data removal tasks,\nwhich has been the primary focus of existing research. More recently, its\npotential application to AI safety has gained attention. In this paper, we\nidentify key limitations that prevent unlearning from serving as a\ncomprehensive solution for AI safety, particularly in managing dual-use\nknowledge in sensitive domains like cybersecurity and chemical, biological,\nradiological, and nuclear (CBRN) safety. In these contexts, information can be\nboth beneficial and harmful, and models may combine seemingly harmless\ninformation for harmful purposes -- unlearning this information could strongly\naffect beneficial uses. We provide an overview of inherent constraints and open\nproblems, including the broader side effects of unlearning dangerous knowledge,\nas well as previously unexplored tensions between unlearning and existing\nsafety mechanisms. Finally, we investigate challenges related to evaluation,\nrobustness, and the preservation of safety features during unlearning. By\nmapping these limitations and open challenges, we aim to guide future research\ntoward realistic applications of unlearning within a broader AI safety\nframework, acknowledging its limitations and highlighting areas where\nalternative approaches may be required.",
      "tldr_zh": "这篇论文探讨了机器 unlearning（机器学习）在 AI safety（AI 安全）中的开放问题，特别是处理双重用途知识（如网络安全和 CBRN 安全）的挑战。论文识别了关键限制，包括 unlearning 可能带来的副作用、与现有安全机制的张力，以及在评估、鲁棒性和安全特征保留方面的难题。最终，通过概述这些问题，该研究旨在指导未来工作，将 unlearning 整合到更广泛的 AI 安全框架中，并强调可能需要补充的替代方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04952v1",
      "published_date": "2025-01-09 03:59:10 UTC",
      "updated_date": "2025-01-09 03:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:05:10.402102"
    },
    {
      "arxiv_id": "2501.06255v1",
      "title": "Progressive Supervision via Label Decomposition: An Long-Term and Large-Scale Wireless Traffic Forecasting Method",
      "title_zh": "翻译失败",
      "authors": [
        "Daojun Liang",
        "Haixia Zhang",
        "Dongfeng Yuan"
      ],
      "abstract": "Long-term and Large-scale Wireless Traffic Forecasting (LL-WTF) is pivotal\nfor strategic network management and comprehensive planning on a macro scale.\nHowever, LL-WTF poses greater challenges than short-term ones due to the\npronounced non-stationarity of extended wireless traffic and the vast number of\nnodes distributed at the city scale. To cope with this, we propose a\nProgressive Supervision method based on Label Decomposition (PSLD).\nSpecifically, we first introduce a Random Subgraph Sampling (RSS) algorithm\ndesigned to sample a tractable subset from large-scale traffic data, thereby\nenabling efficient network training. Then, PSLD employs label decomposition to\nobtain multiple easy-to-learn components, which are learned progressively at\nshallow layers and combined at deep layers to effectively cope with the\nnon-stationary problem raised by LL-WTF tasks. Finally, we compare the proposed\nmethod with various state-of-the-art (SOTA) methods on three large-scale WT\ndatasets. Extensive experimental results demonstrate that the proposed PSLD\nsignificantly outperforms existing methods, with an average 2%, 4%, and 11%\nperformance improvement on three WT datasets, respectively. In addition, we\nbuilt an open source library for WT forecasting (WTFlib) to facilitate related\nresearch, which contains numerous SOTA methods and provides a strong\nbenchmark.Experiments can be reproduced through\nhttps://github.com/Anoise/WTFlib.",
      "tldr_zh": "该论文提出了一种针对长期和大规模无线流量预测（LL-WTF）的 Progressive Supervision via Label Decomposition (PSLD) 方法，以应对数据非平稳性和节点规模带来的挑战。PSLD 首先使用 Random Subgraph Sampling (RSS) 算法从大规模数据中采样子集，实现高效网络训练；随后，通过标签分解将预测任务分解为多个易学组件，在浅层逐步学习并在深层结合，以有效处理非平稳性问题。实验结果显示，PSLD 在三个大型无线流量数据集上比现有最先进方法平均提高了 2%、4% 和 11% 的性能；此外，论文还开源了 WTFlib 库，提供 SOTA 方法基准和可复现实验（https://github.com/Anoise/WTFlib）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Knowledge-Based Systems. arXiv admin note: substantial\n  text overlap with arXiv:2412.00108",
      "pdf_url": "http://arxiv.org/pdf/2501.06255v1",
      "published_date": "2025-01-09 03:35:00 UTC",
      "updated_date": "2025-01-09 03:35:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:05:22.003814"
    },
    {
      "arxiv_id": "2501.04945v3",
      "title": "Step-by-Step Mastery: Enhancing Soft Constraint Following Ability of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyu Ren",
        "Jie Zeng",
        "Qianyu He",
        "Jiaqing Liang",
        "Yanghua Xiao",
        "Weikang Zhou",
        "Zeye Sun",
        "Fei Yu"
      ],
      "abstract": "It is crucial for large language models (LLMs) to follow instructions that\ninvolve multiple constraints. However, it is an unexplored area to enhance\nLLMs' ability to follow soft constraints. To bridge the gap, we initially\ndesign a pipeline to construct datasets with high-quality outputs\nautomatically. Additionally, to fully utilize the positive and negative samples\ngenerated during the data construction process, we choose Direct Preference\nOptimization (DPO) as the training method. Furthermore, taking into account the\ndifficulty of soft constraints indicated by the number of constraints, we\ndesign a curriculum learning training paradigm based on the constraint\nquantity. We experimentally evaluate the effectiveness of our methods in\nimproving LLMs' soft constraint following ability and analyze the factors\ndriving the improvements.The datasets and code are publicly available at\nhttps://github.com/Rainier-rq/FollowSoftConstraint.",
      "tldr_zh": "本论文探讨了增强大型语言模型 (LLMs) 遵循软约束的能力，这是一个尚未充分探索的领域。研究者设计了一个自动管道来构建高质量数据集，并采用 Direct Preference Optimization (DPO) 作为训练方法，利用正负样本进行优化。同时，他们引入了基于约束数量的课程学习 (curriculum learning) 范式，以逐步提升模型处理复杂约束的难度。实验结果证明了这些方法的有效性，并分析了改进的关键因素；相关数据集和代码已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04945v3",
      "published_date": "2025-01-09 03:34:07 UTC",
      "updated_date": "2025-02-16 23:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:05:33.728952"
    },
    {
      "arxiv_id": "2501.06254v2",
      "title": "Rethinking Evaluation of Sparse Autoencoders through the Representation of Polysemous Words",
      "title_zh": "重新审视稀疏自动编码器的评估：通过多义词的表示",
      "authors": [
        "Gouki Minegishi",
        "Hiroki Furuta",
        "Yusuke Iwasawa",
        "Yutaka Matsuo"
      ],
      "abstract": "Sparse autoencoders (SAEs) have gained a lot of attention as a promising tool\nto improve the interpretability of large language models (LLMs) by mapping the\ncomplex superposition of polysemantic neurons into monosemantic features and\ncomposing a sparse dictionary of words. However, traditional performance\nmetrics like Mean Squared Error and L0 sparsity ignore the evaluation of the\nsemantic representational power of SAEs -- whether they can acquire\ninterpretable monosemantic features while preserving the semantic relationship\nof words. For instance, it is not obvious whether a learned sparse feature\ncould distinguish different meanings in one word. In this paper, we propose a\nsuite of evaluations for SAEs to analyze the quality of monosemantic features\nby focusing on polysemous words. Our findings reveal that SAEs developed to\nimprove the MSE-L0 Pareto frontier may confuse interpretability, which does not\nnecessarily enhance the extraction of monosemantic features. The analysis of\nSAEs with polysemous words can also figure out the internal mechanism of LLMs;\ndeeper layers and the Attention module contribute to distinguishing polysemy in\na word. Our semantics focused evaluation offers new insights into the polysemy\nand the existing SAE objective and contributes to the development of more\npractical SAEs.",
      "tldr_zh": "本论文重新审视了稀疏自编码器 (SAEs) 的评估方法，通过多义词 (polysemous words) 的表示来评估其性能。作者指出，传统指标如 Mean Squared Error (MSE) 和 L0 sparsity 忽略了语义表示能力，因此提出一套新评估套件，专注于分析 SAEs 是否能提取可解释的单义特征 (monosemantic features) 同时保留词语的语义关系。研究发现，虽然优化 MSE-L0 Pareto 前沿可能不会真正提升可解释性，但 LLMs 的更深层和 Attention 模块有助于区分多义词，这为理解 LLMs 的内部机制和开发更实用的 SAEs 提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published at ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06254v2",
      "published_date": "2025-01-09 02:54:19 UTC",
      "updated_date": "2025-02-18 17:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:05:45.835074"
    },
    {
      "arxiv_id": "2501.04931v1",
      "title": "Jailbreaking Multimodal Large Language Models via Shuffle Inconsistency",
      "title_zh": "通过混洗不一致性对多模态大型语言模型进行越狱攻击",
      "authors": [
        "Shiji Zhao",
        "Ranjie Duan",
        "Fengxiang Wang",
        "Chi Chen",
        "Caixin Kang",
        "Jialing Tao",
        "YueFeng Chen",
        "Hui Xue",
        "Xingxing Wei"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have achieved impressive performance\nand have been put into practical use in commercial applications, but they still\nhave potential safety mechanism vulnerabilities. Jailbreak attacks are red\nteaming methods that aim to bypass safety mechanisms and discover MLLMs'\npotential risks. Existing MLLMs' jailbreak methods often bypass the model's\nsafety mechanism through complex optimization methods or carefully designed\nimage and text prompts. Despite achieving some progress, they have a low attack\nsuccess rate on commercial closed-source MLLMs. Unlike previous research, we\nempirically find that there exists a Shuffle Inconsistency between MLLMs'\ncomprehension ability and safety ability for the shuffled harmful instruction.\nThat is, from the perspective of comprehension ability, MLLMs can understand\nthe shuffled harmful text-image instructions well. However, they can be easily\nbypassed by the shuffled harmful instructions from the perspective of safety\nability, leading to harmful responses. Then we innovatively propose a\ntext-image jailbreak attack named SI-Attack. Specifically, to fully utilize the\nShuffle Inconsistency and overcome the shuffle randomness, we apply a\nquery-based black-box optimization method to select the most harmful shuffled\ninputs based on the feedback of the toxic judge model. A series of experiments\nshow that SI-Attack can improve the attack's performance on three benchmarks.\nIn particular, SI-Attack can obviously improve the attack success rate for\ncommercial MLLMs such as GPT-4o or Claude-3.5-Sonnet.",
      "tldr_zh": "该研究揭示了多模态大语言模型 (MLLMs) 的安全机制漏洞，通过发现 Shuffle Inconsistency——即 MLLMs 能理解乱序的有害指令，但安全能力易被绕过。研究者提出了一种创新的文本-图像越狱攻击方法 SI-Attack，利用查询-based 黑盒优化和 toxic judge 模型来选择最有效的有害乱序输入，从而提升攻击性能。实验结果显示，SI-Attack 在多个基准上显著提高了攻击成功率，尤其是在商业模型如 GPT-4o 和 Claude-3.5-Sonnet 上。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04931v1",
      "published_date": "2025-01-09 02:47:01 UTC",
      "updated_date": "2025-01-09 02:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:05:57.779173"
    },
    {
      "arxiv_id": "2501.04928v1",
      "title": "Image2CADSeq: Computer-Aided Design Sequence and Knowledge Inference from Product Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xingang Li",
        "Zhenghui Sha"
      ],
      "abstract": "Computer-aided design (CAD) tools empower designers to design and modify 3D\nmodels through a series of CAD operations, commonly referred to as a CAD\nsequence. In scenarios where digital CAD files are not accessible, reverse\nengineering (RE) has been used to reconstruct 3D CAD models. Recent advances\nhave seen the rise of data-driven approaches for RE, with a primary focus on\nconverting 3D data, such as point clouds, into 3D models in boundary\nrepresentation (B-rep) format. However, obtaining 3D data poses significant\nchallenges, and B-rep models do not reveal knowledge about the 3D modeling\nprocess of designs. To this end, our research introduces a novel data-driven\napproach with an Image2CADSeq neural network model. This model aims to reverse\nengineer CAD models by processing images as input and generating CAD sequences.\nThese sequences can then be translated into B-rep models using a solid modeling\nkernel. Unlike B-rep models, CAD sequences offer enhanced flexibility to modify\nindividual steps of model creation, providing a deeper understanding of the\nconstruction process of CAD models. To quantitatively and rigorously evaluate\nthe predictive performance of the Image2CADSeq model, we have developed a\nmulti-level evaluation framework for model assessment. The model was trained on\na specially synthesized dataset, and various network architectures were\nexplored to optimize the performance. The experimental and validation results\nshow great potential for the model in generating CAD sequences from 2D image\ndata.",
      "tldr_zh": "本研究提出了一种名为Image2CADSeq的神经网络模型，用于从产品图像中推断Computer-Aided Design (CAD)序列和相关知识。该模型通过数据驱动的方法处理2D图像输入，生成CAD序列，这些序列可转换为boundary representation (B-rep)模型，并提供比传统B-rep更灵活的修改选项，以揭示3D建模过程的细节。为评估模型性能，研究团队开发了多级评估框架，并在合成数据集上训练并测试了多种网络架构。实验结果表明，Image2CADSeq在从图像逆向工程CAD模型方面表现出色，具有广阔的应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 10 figures, and 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.04928v1",
      "published_date": "2025-01-09 02:36:21 UTC",
      "updated_date": "2025-01-09 02:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:06:09.684536"
    },
    {
      "arxiv_id": "2501.04926v1",
      "title": "FLowHigh: Towards Efficient and High-Quality Audio Super-Resolution with Single-Step Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Jun-Hak Yun",
        "Seung-Bin Kim",
        "Seong-Whan Lee"
      ],
      "abstract": "Audio super-resolution is challenging owing to its ill-posed nature.\nRecently, the application of diffusion models in audio super-resolution has\nshown promising results in alleviating this challenge. However, diffusion-based\nmodels have limitations, primarily the necessity for numerous sampling steps,\nwhich causes significantly increased latency when synthesizing high-quality\naudio samples. In this paper, we propose FLowHigh, a novel approach that\nintegrates flow matching, a highly efficient generative model, into audio\nsuper-resolution. We also explore probability paths specially tailored for\naudio super-resolution, which effectively capture high-resolution audio\ndistributions, thereby enhancing reconstruction quality. The proposed method\ngenerates high-fidelity, high-resolution audio through a single-step sampling\nprocess across various input sampling rates. The experimental results on the\nVCTK benchmark dataset demonstrate that FLowHigh achieves state-of-the-art\nperformance in audio super-resolution, as evaluated by log-spectral distance\nand ViSQOL while maintaining computational efficiency with only a single-step\nsampling process.",
      "tldr_zh": "本论文针对音频超分辨率（Audio Super-Resolution）的病态问题和扩散模型（Diffusion Models）的多步采样延迟，提出了一种高效方法 FLowHigh，该方法整合了单步流匹配（Flow Matching）生成模型。FLowHigh 探索了专为音频超分辨率设计的概率路径，以更好地捕捉高分辨率音频分布，从而提升重建质量。实验结果显示，在 VCTK 数据集上，该方法在 log-spectral distance 和 ViSQOL 指标上实现了最先进性能，同时通过单步采样过程显著提高了计算效率。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.04926v1",
      "published_date": "2025-01-09 02:30:26 UTC",
      "updated_date": "2025-01-09 02:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:06:23.002025"
    },
    {
      "arxiv_id": "2502.15702v1",
      "title": "Large language models streamline automated systematic review: A preliminary study",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Xue Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in natural language\nprocessing tasks, with the potential to automate systematic reviews. This study\nevaluates the performance of three state-of-the-art LLMs in conducting\nsystematic review tasks. We assessed GPT-4, Claude-3, and Mistral 8x7B across\nfour systematic review tasks: study design formulation, search strategy\ndevelopment, literature screening, and data extraction. Sourced from a\npreviously published systematic review, we provided reference standard\nincluding standard PICO (Population, Intervention, Comparison, Outcome) design,\nstandard eligibility criteria, and data from 20 reference literature. Three\ninvestigators evaluated the quality of study design and eligibility criteria\nusing 5-point Liker Scale in terms of accuracy, integrity, relevance,\nconsistency and overall performance. For other tasks, the output is defined as\naccurate if it is the same as the reference standard. Search strategy\nperformance was evaluated through accuracy and retrieval efficacy. Screening\naccuracy was assessed for both abstracts screening and full texts screening.\nData extraction accuracy was evaluated across 1,120 data points comprising\n3,360 individual fields. Claude-3 demonstrated superior overall performance in\nPICO design. In search strategy formulation, GPT-4 and Claude-3 achieved\ncomparable accuracy, outperforming Mistral. For abstract screening, GPT-4\nachieved the highest accuracy, followed by Mistral and Claude-3. In data\nextraction, GPT-4 significantly outperformed other models. LLMs demonstrate\npotential for automating systematic review tasks, with GPT-4 showing superior\nperformance in search strategy formulation, literature screening and data\nextraction. These capabilities make them promising assistive tools for\nresearchers and warrant further development and validation in this field.",
      "tldr_zh": "这篇论文初步评估了 Large Language Models (LLMs) 在自动化系统综述中的性能，测试了 GPT-4、Claude-3 和 Mistral 8x7B 在研究设计制定、搜索策略开发、文献筛选和数据提取等四个任务上的表现。研究使用标准 PICO (Population, Intervention, Comparison, Outcome) 设计、资格标准和20篇参考文献作为基准，通过5点 Likert 量表评估研究设计质量，并通过准确性匹配评估其他任务。结果显示，Claude-3 在 PICO 设计上表现最佳，而 GPT-4 在搜索策略、文献筛选和数据提取上显著优于其他模型，准确率最高。总体而言，LLMs 展示了在简化系统综述流程方面的潜力，可作为研究人员的辅助工具，但需进一步开发和验证。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "25 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.15702v1",
      "published_date": "2025-01-09 01:59:35 UTC",
      "updated_date": "2025-01-09 01:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:06:36.171961"
    },
    {
      "arxiv_id": "2501.06253v1",
      "title": "The State of Post-Hoc Local XAI Techniques for Image Processing: Challenges and Motivations",
      "title_zh": "翻译失败",
      "authors": [
        "Rech Leong Tian Poh",
        "Sye Loong Keoh",
        "Liying Li"
      ],
      "abstract": "As complex AI systems further prove to be an integral part of our lives, a\npersistent and critical problem is the underlying black-box nature of such\nproducts and systems. In pursuit of productivity enhancements, one must not\nforget the need for various technology to boost the overall trustworthiness of\nsuch AI systems. One example, which is studied extensively in this work, is the\ndomain of Explainable Artificial Intelligence (XAI). Research works in this\nscope are centred around the objective of making AI systems more transparent\nand interpretable, to further boost reliability and trust in using them. In\nthis work, we discuss the various motivation for XAI and its approaches, the\nunderlying challenges that XAI faces, and some open problems that we believe\ndeserve further efforts to look into. We also provide a brief discussion of\nvarious XAI approaches for image processing, and finally discuss some future\ndirections, to hopefully express and motivate the positive development of the\nXAI research space.",
      "tldr_zh": "该论文探讨了后验局部 XAI（Post-Hoc Local XAI）技术在图像处理领域的现状，强调了可解释人工智能（XAI）在提升 AI 系统透明度和可信度方面的必要性。作者分析了 XAI 的动机和方法，包括面临的挑战如黑箱问题，以及一些值得进一步研究的开放问题。最终，论文总结了针对图像处理的各种 XAI 策略，并提出未来方向，以推动 XAI 研究领域的积极发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06253v1",
      "published_date": "2025-01-09 01:45:34 UTC",
      "updated_date": "2025-01-09 01:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:06:46.009639"
    },
    {
      "arxiv_id": "2501.04899v1",
      "title": "SUGAR: Leveraging Contextual Confidence for Smarter Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Hanna Zubkova",
        "Ji-Hoon Park",
        "Seong-Whan Lee"
      ],
      "abstract": "Bearing in mind the limited parametric knowledge of Large Language Models\n(LLMs), retrieval-augmented generation (RAG) which supplies them with the\nrelevant external knowledge has served as an approach to mitigate the issue of\nhallucinations to a certain extent. However, uniformly retrieving supporting\ncontext makes response generation source-inefficient, as triggering the\nretriever is not always necessary, or even inaccurate, when a model gets\ndistracted by noisy retrieved content and produces an unhelpful answer.\nMotivated by these issues, we introduce Semantic Uncertainty Guided Adaptive\nRetrieval (SUGAR), where we leverage context-based entropy to actively decide\nwhether to retrieve and to further determine between single-step and multi-step\nretrieval. Our empirical results show that selective retrieval guided by\nsemantic uncertainty estimation improves the performance across diverse\nquestion answering tasks, as well as achieves a more efficient inference.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的知识限制，提出SUGAR（Semantic Uncertainty Guided Adaptive Retrieval）方法，通过基于上下文的语义不确定性（如熵）来动态决定是否进行检索，以及选择单步或多步检索策略，以减少不必要的检索和噪音干扰。相比传统检索增强生成(RAG)方法，SUGAR显著提高了问答任务的性能，避免了模型因无关内容而产生的幻觉问题。实验结果显示，该方法在多样问答任务上提升了整体表现，同时实现了更高效的推理过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP2025",
      "pdf_url": "http://arxiv.org/pdf/2501.04899v1",
      "published_date": "2025-01-09 01:24:59 UTC",
      "updated_date": "2025-01-09 01:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:06:57.721801"
    },
    {
      "arxiv_id": "2501.06252v3",
      "title": "Transformer-Squared: Self-adaptive LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Sun",
        "Edoardo Cetin",
        "Yujin Tang"
      ],
      "abstract": "Self-adaptive large language models (LLMs) aim to solve the challenges posed\nby traditional fine-tuning methods, which are often computationally intensive\nand static in their ability to handle diverse tasks. We introduce\nTransformer-Squared, a novel self-adaptation framework that adapts LLMs for\nunseen tasks in real-time by selectively adjusting only the singular components\nof their weight matrices. During inference, Transformer-Squared employs a\ntwo-pass mechanism: first, a dispatch system identifies the task properties,\nand then task-specific 'expert' vectors, trained using reinforcement learning,\nare dynamically mixed to obtain targeted behavior for the incoming prompt. Our\nmethod consistently outperforms ubiquitous approaches such as LoRA, with fewer\nparameters and greater efficiency. Furthermore, Transformer-Squared\ndemonstrates versatility across different LLM architectures and modalities,\nincluding vision-language tasks. Transformer-Squared represents a significant\nleap forward, offering a scalable, efficient solution for enhancing the\nadaptability and task-specific performance of LLMs, paving the way for truly\ndynamic, self-organizing AI systems.",
      "tldr_zh": "本研究提出Transformer-Squared，一种自适应大型语言模型(LLMs)的创新框架，旨在克服传统微调方法的计算密集和静态问题，通过选择性地调整权重矩阵的单一组件，实现对未见任务的实时适应。框架采用两步机制：首先，调度系统识别任务属性；其次，使用强化学习训练的“专家”向量动态混合，以针对提示生成特定行为。该方法在参数更少的情况下，性能优于LoRA等主流方法，并在不同LLMs架构和模态（如视觉语言任务）中表现出色，为动态自组织AI系统的开发提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear at the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.06252v3",
      "published_date": "2025-01-09 01:19:21 UTC",
      "updated_date": "2025-01-24 01:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:07:10.099026"
    },
    {
      "arxiv_id": "2501.04896v1",
      "title": "Quantifying Itch and its Impact on Sleep Using Machine Learning and Radio Signals",
      "title_zh": "使用机器学习和无线电信号量化瘙痒及其对睡眠的影响",
      "authors": [
        "Michail Ouroutzoglou",
        "Mingmin Zhao",
        "Joshua Hellerstein",
        "Hariharan Rahul",
        "Asima Badic",
        "Brian S. Kim",
        "Dina Katabi"
      ],
      "abstract": "Chronic itch affects 13% of the US population, is highly debilitating, and\nunderlies many medical conditions. A major challenge in clinical care and new\ntherapeutics development is the lack of an objective measure for quantifying\nitch, leading to reliance on subjective measures like patients' self-assessment\nof itch severity. In this paper, we show that a home radio device paired with\nartificial intelligence (AI) can concurrently capture scratching and evaluate\nits impact on sleep quality by analyzing radio signals bouncing in the\nenvironment. The device eliminates the need for wearable sensors or skin\ncontact, enabling monitoring of chronic itch over extended periods at home\nwithout burdening patients or interfering with their skin condition. To\nvalidate the technology, we conducted an observational clinical study of\nchronic pruritus patients, monitored at home for one month using both the radio\ndevice and an infrared camera. Comparing the output of the device to ground\ntruth data from the camera demonstrates its feasibility and accuracy (ROC AUC =\n0.997, sensitivity = 0.825, specificity = 0.997). The results reveal a\nsignificant correlation between scratching and low sleep quality, manifested as\na reduction in sleep efficiency (R = 0.6, p < 0.001) and an increase in sleep\nlatency (R = 0.68, p < 0.001). Our study underscores the potential of passive,\nlong-term, at-home monitoring of chronic scratching and its sleep implications,\noffering a valuable tool for both clinical care of chronic itch patients and\npharmaceutical clinical trials.",
      "tldr_zh": "这篇论文提出了一种使用机器学习(Machine Learning)和无线电信号的方法，来客观量化慢性瘙痒及其对睡眠的影响，解决了传统依赖患者主观评估的局限性。该系统通过家庭无线电设备分析环境反弹信号，捕获抓挠行为并评估睡眠质量，而无需可穿戴传感器或皮肤接触。在为期一个月的临床研究中，设备显示出高准确性（ROC AUC = 0.997，sensitivity = 0.825，specificity = 0.997），并发现抓挠与睡眠效率降低（R = 0.6, p < 0.001）和睡眠潜时增加（R = 0.68, p < 0.001）显著相关。该技术为慢性瘙痒患者的临床护理和药物试验提供了一种被动、长期的家庭监测工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.04896v1",
      "published_date": "2025-01-09 00:50:44 UTC",
      "updated_date": "2025-01-09 00:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:07:23.228236"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 95,
  "processed_papers_count": 95,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T22:07:42.274972"
}