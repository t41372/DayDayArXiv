{
  "date": "2025-10-15",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-10-15 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š** ä»Šå¤© arXiv çš„é‡å¤´æˆé›†ä¸­åœ¨ **LLM çš„è®¤çŸ¥å¥åº·ï¼ˆ\"è„‘è…\"ç°è±¡ï¼‰**ã€**RL è®­ç»ƒçš„ Scaling Law** ä»¥åŠ **æç®€ä¸»ä¹‰çš„å…·èº«æ™ºèƒ½**ã€‚Google å¸¦æ¥äº†å·®åˆ†éšç§æ¨¡å‹ï¼Œè€Œå…³äº AI æ¨¡ä»¿ä½œå®¶é£æ ¼æ¯”äººç±»æ›´å¼ºçš„ç ”ç©¶å¯èƒ½ä¼šå¼•å‘æ–°çš„ç‰ˆæƒè®¨è®ºã€‚\n\n---\n\n### ğŸš€ å¿…è¯»ç²¾é€‰ï¼šå¤§æ¨¡å‹åŸºç¡€ã€Scalingä¸æ•°æ®è´¨é‡\n\n**1. LLMs Can Get \"Brain Rot\"! (LLM ä¹Ÿä¼šå¾—â€œè„‘è…ç—…â€ï¼)**\n> **# title:** LLMs Can Get \"Brain Rot\"!\n> **Authors:** Shuo Xing, et al. (UT Austin & Google DeepMind)\n**æ ¸å¿ƒå‘ç°ï¼š** è¿™æ˜¯ä¸€ç¯‡éå¸¸æœ‰æ„æ€ä¸”è­¦ç¤ºæ€§çš„æ–‡ç« ã€‚ä½œè€…æå‡ºäº†â€œLLM è„‘è…å‡è¯´â€ï¼šæŒç»­æ¥è§¦ä½è´¨é‡ï¼ˆjunkï¼‰ç½‘ç»œæ–‡æœ¬ä¼šå¯¼è‡´æ¨¡å‹è®¤çŸ¥èƒ½åŠ›çš„æŒä¹…ä¸‹é™ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š**\n*   å®éªŒè¡¨æ˜ï¼Œåœ¨â€œåƒåœ¾â€æ•°æ®ä¸ŠæŒç»­é¢„è®­ç»ƒä¼šå¯¼è‡´æ¨ç†ã€é•¿æ–‡æœ¬ç†è§£å’Œå®‰å…¨æ€§çš„æ˜¾è‘—ä¸‹é™ï¼ˆHedges' g > 0.3ï¼‰ï¼Œç”šè‡³å¢åŠ â€œé»‘æš—äººæ ¼â€ç‰¹è´¨ã€‚\n*   **ç—…ç†åˆ†æï¼š** è¿™ç§èƒ½åŠ›ä¸‹é™çš„ä¸»è¦åŸå› æ˜¯â€œæ€ç»´è·³è·ƒâ€ï¼ˆthought-skippingï¼‰ï¼Œå³æ¨¡å‹å¼€å§‹æˆªæ–­æ¨ç†é“¾æ¡ã€‚\n*   **ä¸å¯é€†æ€§ï¼š** è™½ç„¶é«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒèƒ½éƒ¨åˆ†ä¿®å¤ï¼Œä½†æ— æ³•å®Œå…¨æ¢å¤åŸºçº¿èƒ½åŠ›ï¼Œè¿™è¡¨æ˜æ•°æ®è´¨é‡å·®ä¼šå¯¼è‡´æ¨¡å‹è¡¨å¾å‘ç”ŸæŒä¹…æ€§æ¼‚ç§»ã€‚\n\n**2. The Art of Scaling Reinforcement Learning Compute (å¼ºåŒ–å­¦ä¹ è®¡ç®—æ‰©å±•çš„è‰ºæœ¯)**\n> **# title:** The Art of Scaling Reinforcement Learning Compute for LLMs\n> **Authors:** Devvrit Khatri, et al. (Google DeepMind)\n**æ ¸å¿ƒå‘ç°ï¼š** å°±åƒé¢„è®­ç»ƒæœ‰ Scaling Lawï¼ŒRL è®­ç»ƒï¼ˆPost-trainingï¼‰ä¹Ÿæœ‰ã€‚è¿™æ˜¯ä¸€é¡¹è€—æ—¶ 40 ä¸‡ GPU å°æ—¶çš„ç³»ç»Ÿæ€§ç ”ç©¶ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š**\n*   æå‡ºäº†åˆ†æå’Œé¢„æµ‹ LLM ä¸­ RL æ‰©å±•æ€§çš„æ¡†æ¶ã€‚\n*   **å…³é”®è§‚å¯Ÿï¼š** å¹¶ä¸æ˜¯æ‰€æœ‰çš„é…æ–¹éƒ½èƒ½è¾¾åˆ°åŒæ ·çš„æ¸è¿‘æ€§èƒ½ï¼›ç®—æ³•ç»†èŠ‚ï¼ˆå¦‚ loss aggregation, normalizationï¼‰ä¸»è¦å½±å“è®¡ç®—æ•ˆç‡è€Œéä¸Šé™ã€‚\n*   æå‡ºäº† **ScaleRL** é…æ–¹ï¼ŒæˆåŠŸé¢„æµ‹äº†æ‰©å¤§è®¡ç®—è§„æ¨¡åçš„éªŒè¯é›†æ€§èƒ½ï¼Œæ ‡å¿—ç€ RL è®­ç»ƒæ­£èµ°å‘å¯é¢„æµ‹çš„å·¥ç¨‹åŒ–é˜¶æ®µã€‚\n\n**3. Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs (Beeï¼šè§£é”å…¨å¼€æ”¾å¤šæ¨¡æ€å¤§æ¨¡å‹çš„é«˜è´¨é‡è¯­æ–™åº“)**\n> **# title:** Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs\n> **Authors:** Yi Zhang, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** å¼€æºå¤šæ¨¡æ€æ¨¡å‹ï¼ˆMLLMï¼‰é€šå¸¸å—é™äºæ•°æ®è´¨é‡ã€‚Bee é¡¹ç›®å‘å¸ƒäº† 15M çš„é«˜è´¨é‡ SFT æ•°æ®é›†ï¼ˆHoney-Data-15Mï¼‰ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š**\n*   å¼ºè°ƒæ•°æ®æ¸…æ´—å’ŒåŒå±‚ï¼ˆé•¿/çŸ­ï¼‰æ€ç»´é“¾ï¼ˆCoTï¼‰å¢å¼ºç­–ç•¥ã€‚\n*   å‘å¸ƒçš„ **Bee-8B** æ¨¡å‹åœ¨å…¨å¼€æ”¾æ¨¡å‹ä¸­è¾¾åˆ°äº† SOTAï¼Œç”šè‡³åœ¨æŸäº›æŒ‡æ ‡ä¸Šè¶…è¿‡äº†åŠå¼€æ”¾çš„ InternVL3.5-8Bã€‚è¿™å†æ¬¡è¯æ˜äº†æ•°æ®è´¨é‡ > æ•°æ®æ•°é‡ã€‚\n\n**4. VaultGemma: A Differentially Private Gemma Model (VaultGemmaï¼šå·®åˆ†éšç§ Gemma æ¨¡å‹)**\n> **# title:** VaultGemma: A Differentially Private Gemma Model\n> **Authors:** Amer Sinha, et al. (Google DeepMind)\n**æ ¸å¿ƒå‘ç°ï¼š** Google å‘å¸ƒäº† **VaultGemma 1B**ï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œå…¨ä½¿ç”¨å·®åˆ†éšç§ï¼ˆDPï¼‰è®­ç»ƒçš„ 1B å‚æ•°æ¨¡å‹ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** ä½¿ç”¨äº†ä¸ Gemma 2 ç³»åˆ—ç›¸åŒçš„æ•°æ®æ··åˆï¼Œä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸¥æ ¼ä¿è¯éšç§ã€‚è¿™æ˜¯éšç§ä¿æŠ¤å¤§è¯­è¨€æ¨¡å‹è¿ˆå‡ºçš„é‡è¦ä¸€æ­¥ï¼Œé€‚åˆå¯¹æ•°æ®æ³„éœ²æ•æ„Ÿçš„åº”ç”¨åœºæ™¯ã€‚\n\n---\n\n### ğŸ¤– å…·èº«æ™ºèƒ½ä¸å¤šæ¨¡æ€ (VLA & VLM)\n\n**5. VLA-0: Building State-of-the-Art VLAs with Zero Modification (VLA-0ï¼šé›¶ä¿®æ”¹æ„å»º SOTA è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹)**\n> **# title:** VLA-0: Building State-of-the-Art VLAs with Zero Modification\n> **Authors:** Ankit Goyal, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** æç®€ä¸»ä¹‰çš„èƒœåˆ©ã€‚ä½œè€…å‘ç°ï¼Œä¸éœ€è¦å¤æ‚çš„åŠ¨ä½œ Token æˆ–ç‰¹æ®Šçš„ Headï¼Œç›´æ¥æŠŠåŠ¨ä½œè¡¨ç¤ºä¸º**çº¯æ–‡æœ¬**ï¼Œå°±èƒ½è®­ç»ƒå‡ºæœ€å¼ºçš„ VLAã€‚\n**ä¸»è¦è´¡çŒ®ï¼š**\n*   **VLA-0** åœ¨ LIBERO åŸºå‡†ä¸Šå‡»è´¥äº† OpenVLA å’Œ SmolVLA ç­‰å¤æ‚è®¾è®¡ã€‚\n*   è¯æ˜äº†ç°æœ‰çš„ VLM è¯è¡¨æœ¬èº«å°±è¶³ä»¥å¤„ç†æœºå™¨äººæ§åˆ¶ä»»åŠ¡ï¼Œæ— éœ€è¿‡åº¦è®¾è®¡æ¶æ„ã€‚\n\n**6. InternVLA-M1: A Spatially Guided Vision-Language-Action Framework (InternVLA-M1ï¼šç©ºé—´å¼•å¯¼çš„é€šç”¨æœºå™¨äººç­–ç•¥)**\n> **# title:** InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy\n> **Authors:** Xinyi Chen, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** ä¸ VLA-0 çš„æç®€è·¯çº¿ä¸åŒï¼ŒInternVLA-M1 å¼ºè°ƒâ€œç©ºé—´è½åœ°â€ï¼ˆSpatial Groundingï¼‰æ˜¯è¿æ¥æŒ‡ä»¤å’ŒåŠ¨ä½œçš„å…³é”®ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒï¼šå…ˆé€šè¿‡ 2.3M æ•°æ®é¢„è®­ç»ƒç©ºé—´æ¨ç†ï¼ˆå†³å®šâ€œåœ¨å“ªé‡Œè¡ŒåŠ¨â€ï¼‰ï¼Œå†é€šè¿‡ç©ºé—´å¼•å¯¼çš„åŠ¨ä½œåè®­ç»ƒï¼ˆå†³å®šâ€œå¦‚ä½•è¡ŒåŠ¨â€ï¼‰ã€‚åœ¨é•¿ç¨‹æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ã€‚\n\n**7. What \"Not\" to Detect: Negation-Aware VLMs (VLMs çš„å¦å®šæ„ŸçŸ¥)**\n> **# title:** What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging\n> **Authors:** Inha Kang, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** ç°åœ¨çš„ VLM æœ‰ä¸¥é‡çš„â€œè‚¯å®šåå·®â€ï¼Œç»å¸¸å¿½ç•¥â€œNotâ€ï¼ˆä¾‹å¦‚æŠŠâ€œéå¥³å­©â€è¯†åˆ«ä¸ºâ€œå¥³å­©â€ï¼‰ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº† **NegToMe** æ¨¡å—ï¼Œé€šè¿‡ Token Merging å°†å¦å®šè¯ä¸å±æ€§ç»‘å®šï¼Œä»æ¶æ„ä¸Šè§£å†³äº†å¦å®šè¯ä¸¢å¤±çš„é—®é¢˜ï¼Œåœ¨ OVDEval ä¸Šå¤§å¹…æå‡äº†æ£€æµ‹å‡†ç¡®ç‡ã€‚\n\n---\n\n### ğŸ§  æ¨ç†ã€Agent ä¸ ç®—æ³•ä¼˜åŒ–\n\n**8. Towards Reversible Model Merging For Low-rank Weights (é¢å‘ä½ç§©æƒé‡çš„å¯é€†æ¨¡å‹åˆå¹¶)**\n> **# title:** Towards Reversible Model Merging For Low-rank Weights\n> **Authors:** Mohammadsajad Alipour, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** ç›´æ¥åˆå¹¶å¤šä¸ª LoRA æˆ–ä½ç§©æ¨¡å‹ä¼šå¯¼è‡´ä¸¥é‡çš„æ€§èƒ½ä¸‹é™ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº† **RMM (Reversible Model Merging)**ã€‚ä¸å…¶æŠŠæ‰€æœ‰ adapter å‹ç¼©æˆä¸€ç»„æƒé‡ï¼Œä¸å¦‚æ„å»ºä¸€ä¸ªç´§å‡‘çš„åŸºï¼ˆBasisï¼‰ï¼Œå¯ä»¥é€šè¿‡çº¿æ€§ç»„åˆæ¢å¤åŸå§‹çš„ç‰¹å®šä»»åŠ¡æ¨¡å‹ã€‚è¿™åœ¨ä¿ç•™å•ä¸ªæ¨¡å‹æ€§èƒ½çš„åŒæ—¶å®ç°äº†åˆå¹¶ã€‚\n\n**9. Minimal Test-Time Intervention (æç®€æµ‹è¯•æ—¶å¹²é¢„)**\n> **# title:** Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention\n> **Authors:** Zhen Yang, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** æ¨ç†çš„ä¸ç¡®å®šæ€§å¾€å¾€åªå±€é™åœ¨æå°‘æ•°çš„é«˜ç†µ Token ä¸Šã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº† **MTI**ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„æ–¹æ³•ã€‚åªåœ¨ä¸ç¡®å®šçš„ä½ç½®åº”ç”¨åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰ï¼Œå¹¶åˆ©ç”¨ KV cache è¿›è¡Œè½»é‡çº§è´Ÿå‘æç¤ºå¼•å¯¼ã€‚åœ¨ DeepSeek-R1-7B ä¸Šå¹³å‡æå‡äº† 9.28% çš„æ€§èƒ½ã€‚\n\n**10. Hard2Verify: A Step-Level Verification Benchmark (Hard2Verifyï¼šå‰æ²¿æ•°å­¦çš„æ­¥éª¤çº§éªŒè¯åŸºå‡†)**\n> **# title:** Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math\n> **Authors:** Shrey Pandit, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** é’ˆå¯¹ IMO çº§åˆ«çš„æ•°å­¦é¢˜ï¼Œæˆ‘ä»¬éœ€è¦èƒ½éªŒè¯æ¯ä¸€ä¸ªæ­¥éª¤ï¼ˆStep-levelï¼‰æ­£ç¡®æ€§çš„éªŒè¯å™¨ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æ„å»ºäº†ä¸€ä¸ªé«˜è´¨é‡çš„äººå·¥æ ‡æ³¨åŸºå‡†ã€‚è¯„ä¼°å‘ç°ï¼Œé™¤äº†å°‘æ•°é—­æºæ¨¡å‹ï¼Œå¤§å¤šæ•°å¼€æº Verifier åœ¨è¿™ç§é«˜éš¾åº¦ã€å¼€æ”¾å¼æ•°å­¦é¢˜çš„æ­¥éª¤çº§æŸ¥é”™ä¸Šè¡¨ç°è½åã€‚\n\n**11. Confidence as a Reward (ç½®ä¿¡åº¦å³å¥–åŠ±)**\n> **# title:** Confidence as a Reward: Transforming LLMs into Reward Models\n> **Authors:** He Du, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** å¯¹äºå°é—­å¼é—®é¢˜ï¼Œæ¨¡å‹å¯¹æœ€ç»ˆç­”æ¡ˆçš„ Token çº§ç½®ä¿¡åº¦å¯ä»¥ä½œä¸ºéå¸¸æœ‰æ•ˆçš„ Reward ä¿¡å·ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº† **CRew** æ–¹æ³•ï¼Œæ— éœ€è®­ç»ƒ Reward Modelï¼Œç›´æ¥åˆ©ç”¨ç½®ä¿¡åº¦è¿›è¡Œæ‰“åˆ†ã€‚å®éªŒè¡¨æ˜è¿™ç§ç®€å•çš„æ–¹æ³•åœ¨æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šç”šè‡³è¶…è¿‡äº†è®¸å¤šä¸“é—¨è®­ç»ƒçš„ RMã€‚\n\n---\n\n### âš–ï¸ ç¤¾ä¼šå½±å“ã€å®‰å…¨ä¸ç‰ˆæƒ\n\n**12. Readers Prefer Outputs of AI Trained on Copyrighted Books (è¯»è€…æ›´å–œæ¬¢ç»ç”±ç‰ˆæƒä¹¦ç±è®­ç»ƒçš„ AI ä½œå“)**\n> **# title:** Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers\n> **Authors:** Tuhin Chakrabarty, et al. (Columbia Law School)\n**æ ¸å¿ƒå‘ç°ï¼š** è¿™æ˜¯ä¸€ä¸ªå¯èƒ½åœ¨æ³•å¾‹ç•Œå¼•èµ·éœ‡åŠ¨çš„å‘ç°ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** ç ”ç©¶å¯¹æ¯”äº†æ¨¡ä»¿ 50 ä½è‘—åä½œå®¶çš„æ–‡æœ¬ã€‚å¦‚æœæ˜¯ç®€å•çš„ Promptingï¼Œäººç±»ä¸“å®¶å†™å¾—æ›´å¥½ï¼›ä½†å¦‚æœæ˜¯å¯¹è¯¥ä½œå®¶å…¨é›†è¿›è¡Œ **Fine-tuning** åçš„ ChatGPTï¼Œè¯»è€…ï¼ˆåŒ…æ‹¬ä¸“å®¶å’Œæ™®é€šäººï¼‰åœ¨é£æ ¼è¿˜åŸåº¦å’Œå†™ä½œè´¨é‡ä¸Šéƒ½æ›´åå‘ AIã€‚\n**Implicationï¼š** ä½œè€…æŒ‡å‡ºï¼Œè¿™ç§â€œéé€å­—æŠ„è¢­â€ä½†é£æ ¼å®Œç¾çš„æ¨¡ä»¿ï¼Œå¯èƒ½å¯¹ç‰ˆæƒæ³•ä¸­çš„â€œå¸‚åœºå½±å“â€è¦ç´ æ„æˆæŒ‘æˆ˜ã€‚\n\n**13. Formalizing Agentic AI Systems (å½¢å¼åŒ– Agentic AI ç³»ç»Ÿ)**\n> **# title:** Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems\n> **Authors:** Edoardo Allegrini, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** ç›®å‰ Agent ä¹‹é—´çš„é€šä¿¡ï¼ˆå¦‚ MCP åè®®ï¼‰ç¼ºä¹ç»Ÿä¸€çš„è¯­ä¹‰æ¡†æ¶æ¥è¿›è¡Œå®‰å…¨åˆ†æã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** æå‡ºäº†å®¿ä¸»ä»£ç†æ¨¡å‹ï¼ˆHost Agent Modelï¼‰å’Œä»»åŠ¡ç”Ÿå‘½å‘¨æœŸæ¨¡å‹ï¼Œå¹¶å®šä¹‰äº† 17 æ¡å®‰å…¨å±æ€§ï¼ˆå¦‚æ´»æ€§ã€å…¬å¹³æ€§ï¼‰ï¼Œåˆ©ç”¨æ—¶åºé€»è¾‘å¯¹å¤š Agent ç³»ç»Ÿè¿›è¡Œå½¢å¼åŒ–éªŒè¯ã€‚\n\n**14. Paper Copilot: Tracking the Evolution of Peer Review (è¿½è¸ª AI ä¼šè®®åŒè¡Œè¯„å®¡çš„æ¼”å˜)**\n> **# title:** Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences\n> **Authors:** Jing Yang, et al.\n**æ ¸å¿ƒå‘ç°ï¼š** AI ä¼šè®®çš„åŒè¡Œè¯„å®¡ç³»ç»Ÿæ­£é¢ä¸´å´©æºƒï¼ˆå·¥ä½œé‡å¤§ã€æ ‡å‡†ä¸ä¸€ï¼‰ã€‚\n**ä¸»è¦è´¡çŒ®ï¼š** å‘å¸ƒäº†ä¸€ä¸ªå¤§è§„æ¨¡çš„åŒè¡Œè¯„å®¡æ•°æ®é›†å’Œåˆ†æå·¥å…·ï¼Œæ¶µç›– ICLR å¤šå¹´çš„è¯„å®¡è®°å½•ï¼Œå¸®åŠ©ç¤¾åŒºé‡åŒ–åˆ†æè¯„å®¡è´¨é‡çš„å˜åŒ–ã€‚\n\n---\n\n### ğŸ”¬ ç§‘å­¦ AI (AI for Science)\n\n*   **#43 Scaling Vision Transformers for Functional MRI:** å°† fMRI æ•°æ®è½¬åŒ–ä¸º 2D å¹³é¢å›¾è§†é¢‘ï¼Œåº”ç”¨ ViT è¿›è¡Œ Scalingï¼Œå‘ç° fMRI å»ºæ¨¡ä¹Ÿéµå¾ª Scaling Lawã€‚\n*   **#57 Axial Neural Networks:** é’ˆå¯¹ PDEï¼ˆåå¾®åˆ†æ–¹ç¨‹ï¼‰æ±‚è§£ï¼Œæå‡ºäº†ä¸€ç§ç»´åº¦æ— å…³çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œè§£å†³äº†ä¸åŒç‰©ç†ç³»ç»Ÿç»´åº¦ä¸ä¸€è‡´çš„ç—›ç‚¹ã€‚\n*   **#77 MedREK:** é’ˆå¯¹åŒ»ç–—å¤§æ¨¡å‹çš„ç¼–è¾‘é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ£€ç´¢çš„ç¼–è¾‘æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯è§£å†³äº†åŒ»ç–—çŸ¥è¯†é‡å å¯¼è‡´çš„æ£€ç´¢ä¸å‡†é—®é¢˜ã€‚\n\n---\n\nğŸ‰ **ç»“è¯­ï¼š** ä»Šå¤©çš„è®ºæ–‡è´¨é‡æé«˜ã€‚ä»å¾®è§‚çš„ Token ç½®ä¿¡åº¦åˆ©ç”¨ï¼Œåˆ°å®è§‚çš„ RL è®­ç»ƒ Scaling Lawï¼Œå†åˆ°å¯¹ AI è®­ç»ƒæ•°æ®è´¨é‡ï¼ˆ\"Brain Rot\"ï¼‰çš„åæ€ï¼Œæˆ‘ä»¬çœ‹åˆ°ç¤¾åŒºæ­£åœ¨ä»å•çº¯çš„â€œåˆ·æ¦œâ€è½¬å‘å¯¹æ¨¡å‹åŸç†æ›´æ·±å±‚çš„æ¢ç´¢ã€‚åŒæ—¶ï¼ŒVLA-0 å’Œ Bee çš„å‡ºç°ä¹Ÿæé†’æˆ‘ä»¬ï¼Œæœ‰æ—¶â€œç®€å•â€å’Œâ€œé«˜è´¨é‡æ•°æ®â€æ‰æ˜¯ç»ˆææ­¦å™¨ã€‚\n\nå¸Œæœ›è¿™ä»½æ—¥æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰å¯å‘ï¼æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2510.14163v1",
      "title": "Towards Reversible Model Merging For Low-rank Weights",
      "title_zh": "é¢å‘ä½ç§©æƒé‡çš„å¯é€†æ¨¡å‹åˆå¹¶",
      "authors": [
        "Mohammadsajad Alipour",
        "Mohammad Mohammadi Amiri"
      ],
      "abstract": "Model merging aims to combine multiple fine-tuned models into a single set of weights that performs well across all source tasks. While prior work has shown that merging can approximate the performance of individual fine-tuned models for each task, it largely overlooks scenarios where models are compressed into low-rank representations, either through low-rank adaptation (LoRA) or post-training singular value decomposition (SVD). We first demonstrate that applying conventional merging methods to low-rank weights leads to severe performance degradation in the merged model. Motivated by this phenomenon, we propose a fundamentally different approach: instead of collapsing all adapters into one set of weights, we construct a compact basis (e.g., an equivalent of holding two or more models) from which original task-specific models can be recovered via linear combination. This reframes merging as generating a reconstruction-capable model space rather than producing a single merged model. Crucially, this allows us to ``revert'' to each individual model when needed, recognizing that no merged model can consistently outperform one specialized for its task. Building on this insight, we introduce our method, Reversible Model Merging (RMM), an efficient, data-free, and flexible method that provides a closed-form solution for selecting the optimal basis of model weights and task-specific coefficients for linear combination. Extensive experiments across diverse datasets and model scales demonstrate that RMM consistently outperforms existing merging approaches, preserving the performance of low-rank compressed models by a significant margin.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹åˆå¹¶(Model merging)åœ¨ä½ç§©æƒé‡(Low-rank weights)è¡¨ç¤ºä¸‹çš„æ€§èƒ½é€€åŒ–é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ä½ç§©è‡ªé€‚åº”(LoRA)æˆ–è®­ç»ƒåå¥‡å¼‚å€¼åˆ†è§£(SVD)å‹ç¼©çš„æ¨¡å‹ã€‚ä½œè€…å‘ç°ä¼ ç»Ÿçš„åˆå¹¶æ–¹æ³•åœ¨å¤„ç†è¿™äº›ä½ç§©æƒé‡æ—¶ä¼šå¯¼è‡´ä¸¥é‡çš„æ€§èƒ½æŸå¤±ï¼Œå› æ­¤æå‡ºäº†å¯é€†æ¨¡å‹åˆå¹¶(Reversible Model Merging, RMM)ã€‚è¯¥æ–¹æ³•å°†æ¨¡å‹åˆå¹¶é‡æ–°å®šä¹‰ä¸ºç”Ÿæˆä¸€ä¸ªå…·æœ‰é‡å»ºèƒ½åŠ›çš„æ¨¡å‹ç©ºé—´ï¼Œé€šè¿‡æ„å»ºç´§å‡‘åŸº(compact basis)å¹¶åˆ©ç”¨çº¿æ€§ç»„åˆ(linear combination)å®ç°åŸå§‹ä»»åŠ¡ç‰¹å®šæ¨¡å‹çš„ç²¾å‡†æ¢å¤ã€‚RMM æ˜¯ä¸€ç§é«˜æ•ˆã€æ— æ•°æ®(data-free)ä¸”çµæ´»çš„æ–¹æ³•ï¼Œå¹¶ä¸ºå¯»æ‰¾æœ€ä¼˜åŸºå’Œç³»æ•°æä¾›äº†é—­å¼è§£(closed-form solution)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒRMM åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹è§„æ¨¡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰åˆå¹¶æŠ€æœ¯ï¼Œåœ¨ç»´æŒä½ç§©å‹ç¼©æ¨¡å‹æ€§èƒ½çš„åŒæ—¶å®ç°äº†æ›´ä¼˜çš„è·¨ä»»åŠ¡è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14163v1",
      "published_date": "2025-10-15 23:22:38 UTC",
      "updated_date": "2025-10-15 23:22:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:31:55.951058+00:00"
    },
    {
      "arxiv_id": "2510.14162v2",
      "title": "FinAI Data Assistant: LLM-based Financial Database Query Processing with the OpenAI Function Calling API",
      "title_zh": "FinAI Data Assistantï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹ä¸ OpenAI å‡½æ•°è°ƒç”¨ API çš„é‡‘èæ•°æ®åº“æŸ¥è¯¢å¤„ç†",
      "authors": [
        "Juhyeong Kim",
        "Yejin Kim",
        "Youngbin Lee",
        "Hyunwoo Byun"
      ],
      "abstract": "We present FinAI Data Assistant, a practical approach for natural-language querying over financial databases that combines large language models (LLMs) with the OpenAI Function Calling API. Rather than synthesizing complete SQL via text-to-SQL, our system routes user requests to a small library of vetted, parameterized queries, trading generative flexibility for reliability, low latency, and cost efficiency. We empirically study three questions: (RQ1) whether LLMs alone can reliably recall or extrapolate time-dependent financial data without external retrieval; (RQ2) how well LLMs map company names to stock ticker symbols; and (RQ3) whether function calling outperforms text-to-SQL for end-to-end database query processing. Across controlled experiments on prices and fundamentals, LLM-only predictions exhibit non-negligible error and show look-ahead bias primarily for stock prices relative to model knowledge cutoffs. Ticker-mapping accuracy is near-perfect for NASDAQ-100 constituents and high for S\\&P~500 firms. Finally, FinAI Data Assistant achieves lower latency and cost and higher reliability than a text-to-SQL baseline on our task suite. We discuss design trade-offs, limitations, and avenues for deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FinAI Data Assistantï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç»“åˆ OpenAI Function Calling API å®ç°é‡‘èæ•°æ®åº“è‡ªç„¶è¯­è¨€æŸ¥è¯¢çš„å®ç”¨ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä¸ä¾èµ– text-to-SQL æŠ€æœ¯ç”Ÿæˆå®Œæ•´æŸ¥è¯¢ï¼Œè€Œæ˜¯å°†ç”¨æˆ·éœ€æ±‚æ˜ å°„åˆ°é¢„è®¾çš„å‚æ•°åŒ–æŸ¥è¯¢åº“ä¸­ï¼Œä»è€Œç¡®ä¿äº†é‡‘èæ•°æ®æ£€ç´¢çš„é«˜å¯é æ€§ã€ä½å»¶è¿Ÿå’Œä½æˆæœ¬ã€‚é€šè¿‡å¯¹ä¸‰ä¸ªæ ¸å¿ƒç ”ç©¶é—®é¢˜çš„æ¢è®¨ï¼Œä½œè€…å‘ç°ä»…é  LLM é¢„æµ‹é‡‘èæ•°æ®ä¼šäº§ç”Ÿä¸å¯å¿½è§†çš„è¯¯å·®å’Œå…ˆéªŒåå·®ï¼ˆlook-ahead biasï¼‰ï¼Œè€Œå…¶åœ¨è‚¡ç¥¨ä»£ç æ˜ å°„æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚å®éªŒç»“æœè¯æ˜ï¼Œä¸ text-to-SQL åŸºçº¿ç›¸æ¯”ï¼ŒFinAI Data Assistant åœ¨ç«¯åˆ°ç«¯æ•°æ®åº“æŸ¥è¯¢å¤„ç†ä»»åŠ¡ä¸­å…·æœ‰æ›´å¼ºçš„ç¨³å®šæ€§å’Œç»æµæ€§ã€‚è¯¥ç ”ç©¶ä¸ºé‡‘èé¢†åŸŸå¤§å‹è¯­è¨€æ¨¡å‹çš„éƒ¨ç½²æä¾›äº†é‡è¦çš„è®¾è®¡æƒè¡¡å‚è€ƒå’Œå®è·µè·¯å¾„ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "6 pages, 2 figures, accepted at CIKM 2025 FinAI Workshop",
      "pdf_url": "https://arxiv.org/pdf/2510.14162v2",
      "published_date": "2025-10-15 23:19:27 UTC",
      "updated_date": "2025-10-21 04:48:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:31:59.260230+00:00"
    },
    {
      "arxiv_id": "2510.14154v1",
      "title": "Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola",
      "title_zh": "åŸºäº AMD Schola ç»“åˆå¼ºåŒ–å­¦ä¹ ä¸è¡Œä¸ºæ ‘çš„è§†é¢‘æ¸¸æˆ NPC å¼€å‘",
      "authors": [
        "Tian Liu",
        "Alex Cann",
        "Ian Colbert",
        "Mehdi Saeedi"
      ],
      "abstract": "While the rapid advancements in the reinforcement learning (RL) research community have been remarkable, the adoption in commercial video games remains slow. In this paper, we outline common challenges the Game AI community faces when using RL-driven NPCs in practice, and highlight the intersection of RL with traditional behavior trees (BTs) as a crucial juncture to be explored further. Although the BT+RL intersection has been suggested in several research papers, its adoption is rare. We demonstrate the viability of this approach using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by creating multi-task NPCs in a complex 3D environment inspired by the commercial video game ``The Last of Us\". We provide detailed methodologies for jointly training RL models with BTs while showcasing various skills.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)åœ¨å•†ä¸šç”µå­æ¸¸æˆé¢†åŸŸåº”ç”¨æ»åçš„ç°çŠ¶ï¼Œæå‡ºå°†RLä¸ä¼ ç»Ÿè¡Œä¸ºæ ‘(Behavior Trees, BTs)ç›¸ç»“åˆæ˜¯å½“å‰å€¼å¾—æ·±å…¥æ¢ç´¢çš„å…³é”®è·¯å¾„ã€‚ä½œè€…é€šè¿‡ä¸“ä¸ºUnreal Engineè®¾è®¡çš„è®­ç»ƒæ’ä»¶AMD Scholaï¼Œåœ¨å—å•†ä¸šå¤§ä½œã€Šæœ€åç”Ÿè¿˜è€…ã€‹(The Last of Us)å¯å‘çš„å¤æ‚3Dåœºæ™¯ä¸­ï¼ŒæˆåŠŸæ„å»ºäº†å…·å¤‡å¤šä»»åŠ¡æ‰§è¡Œèƒ½åŠ›çš„NPCsã€‚æ–‡ä¸­è¯¦ç»†é˜è¿°äº†å°†RLæ¨¡å‹ä¸BTsè¿›è¡Œè”åˆè®­ç»ƒçš„ç³»ç»Ÿæ€§æ–¹æ³•ï¼Œå¹¶å…·ä½“å±•ç¤ºäº†æ™ºèƒ½ä½“åœ¨ä¸åŒæŠ€èƒ½ä»»åŠ¡ä¸­çš„å­¦ä¹ æˆæœã€‚è¯¥å®è·µä¸ä»…è¯æ˜äº†BT+RLæ··åˆæ¶æ„åœ¨å¤æ‚æ¸¸æˆç¯å¢ƒä¸­çš„å¯è¡Œæ€§ï¼Œè¿˜ä¸ºè§£å†³RLé©±åŠ¨è§’è‰²åœ¨å®é™…å¼€å‘ä¸­éš¾ä»¥è½åœ°çš„ç—›ç‚¹æä¾›äº†æœ‰åŠ›ä¾æ®ã€‚è¿™é¡¹å·¥ä½œä¸ºæ¸¸æˆAIç¤¾åŒºåˆ©ç”¨å…ˆè¿›ç®—æ³•æå‡è§’è‰²æ™ºèƒ½æä¾›äº†è¯¦å°½çš„æŠ€æœ¯æŒ‡å—ä¸å®æˆ˜å‚è€ƒã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.14154v1",
      "published_date": "2025-10-15 23:00:48 UTC",
      "updated_date": "2025-10-15 23:00:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:07.055373+00:00"
    },
    {
      "arxiv_id": "2510.14150v3",
      "title": "CodeEvolve: an open source evolutionary coding agent for algorithm discovery and optimization",
      "title_zh": "CodeEvolveï¼šç”¨äºç®—æ³•å‘ç°ä¸ä¼˜åŒ–çš„å¼€æºæ¼”åŒ–ç¼–ç¨‹æ™ºèƒ½ä½“",
      "authors": [
        "Henrique AssumpÃ§Ã£o",
        "Diego Ferreira",
        "Leandro Campos",
        "Fabricio Murai"
      ],
      "abstract": "We introduce CodeEvolve, an open-source framework that combines large language models (LLMs) with evolutionary search to synthesize high-performing algorithmic solutions. CodeEvolve couples an islands-based genetic algorithm with modular LLM orchestration, using execution feedback and task-specific metrics to guide selection and variation. Exploration and exploitation are balanced through context-aware recombination, adaptive meta-prompting, and targeted refinement of promising solutions. We evaluate CodeEvolve on benchmarks previously used to assess Google DeepMind's AlphaEvolve, showing superior performance on several tasks and competitive results overall. Notably, open-weight models often match or exceed closed-source baselines at a fraction of the compute cost. We provide extensive ablations analyzing the contribution of each component and release our framework and experimental results at https://github.com/inter-co/science-codeevolve.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† CodeEvolveï¼Œä¸€ä¸ªç»“åˆå¤§è¯­è¨€æ¨¡å‹ (LLMs) ä¸è¿›åŒ–æœç´¢ (evolutionary search) çš„å¼€æºæ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨åˆæˆé«˜æ€§èƒ½ç®—æ³•ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å²›å±¿é—ä¼ ç®—æ³• (islands-based genetic algorithm) ä¸æ¨¡å—åŒ– LLM ç¼–æ’ï¼Œåˆ©ç”¨æ‰§è¡Œåé¦ˆå’Œä»»åŠ¡ç‰¹å®šæŒ‡æ ‡æŒ‡å¯¼ç§ç¾¤çš„é€‰æ‹©ä¸å˜å¼‚ã€‚é€šè¿‡å¼•å…¥ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡ç»„ (context-aware recombination) å’Œè‡ªé€‚åº”å…ƒæç¤º (adaptive meta-prompting)ï¼ŒCodeEvolve å®ç°äº†æ¢ç´¢ä¸åˆ©ç”¨çš„åŠ¨æ€å¹³è¡¡ã€‚åœ¨ä¸ AlphaEvolve ç›¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶åœ¨å¤šé¡¹ä»»åŠ¡ä¸Šå±•ç°å‡ºæ›´ä¼˜æ€§èƒ½ï¼Œä¸”æ•´ä½“è¡¨ç°æå…·ç«äº‰åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¼€æºæ¨¡å‹ (open-weight models) åœ¨æä½è®¡ç®—æˆæœ¬ä¸‹å³å¯è¾¾åˆ°æˆ–è¶…è¿‡é—­æºæ¨¡å‹çš„æ•ˆæœã€‚è¯¥é¡¹ç›®å·²é€šè¿‡ GitHub å¼€æºäº†å®Œæ•´çš„æ¡†æ¶ä»£ç åŠå®éªŒåˆ†æç»“æœã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 10 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.14150v3",
      "published_date": "2025-10-15 22:58:06 UTC",
      "updated_date": "2026-01-06 13:58:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:05.550992+00:00"
    },
    {
      "arxiv_id": "2510.24744v1",
      "title": "PulseFi: A Low Cost Robust Machine Learning System for Accurate Cardiopulmonary and Apnea Monitoring Using Channel State Information",
      "title_zh": "PulseFiï¼šåŸºäºä¿¡é“çŠ¶æ€ä¿¡æ¯å®ç°ç²¾å‡†å¿ƒè‚ºä¸å‘¼å¸æš‚åœç›‘æµ‹çš„ä½æˆæœ¬é²æ£’æœºå™¨å­¦ä¹ ç³»ç»Ÿ",
      "authors": [
        "Pranay Kocheta",
        "Nayan Sanjay Bhatia",
        "Katia Obraczka"
      ],
      "abstract": "Non-intrusive monitoring of vital signs has become increasingly important in a variety of healthcare settings. In this paper, we present PulseFi, a novel low-cost non-intrusive system that uses Wi-Fi sensing and artificial intelligence to accurately and continuously monitor heart rate and breathing rate, as well as detect apnea events. PulseFi operates using low-cost commodity devices, making it more accessible and cost-effective. It uses a signal processing pipeline to process Wi-Fi telemetry data, specifically Channel State Information (CSI), that is fed into a custom low-compute Long Short-Term Memory (LSTM) neural network model. We evaluate PulseFi using two datasets: one that we collected locally using ESP32 devices and another that contains recordings of 118 participants collected using the Raspberry Pi 4B, making the latter the most comprehensive data set of its kind. Our results show that PulseFi can effectively estimate heart rate and breathing rate in a seemless non-intrusive way with comparable or better accuracy than multiple antenna systems that can be expensive and less accessible.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PulseFiï¼Œä¸€ç§ä½æˆæœ¬ä¸”é²æ£’æ€§å¼ºçš„æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œæ—¨åœ¨åˆ©ç”¨ Wi-Fi æ„ŸçŸ¥æŠ€æœ¯å®ç°éä¾µå…¥å¼çš„å‘¼å¸ç‡ã€å¿ƒç‡ç›‘æµ‹åŠå‘¼å¸æš‚åœ (Apnea) è‡ªåŠ¨æ£€æµ‹ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•è·æ™®é€šå•†ç”¨è®¾å¤‡çš„ä¿¡é“çŠ¶æ€ä¿¡æ¯ (Channel State Information, CSI) é¥æµ‹æ•°æ®ï¼Œå¹¶å°†å…¶è¾“å…¥åˆ°ä¸“é—¨å®šåˆ¶çš„ä½è®¡ç®—é‡é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ (LSTM) æ¨¡å‹ä¸­è¿›è¡Œå¤„ç†ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŸºäº ESP32 æ”¶é›†çš„æœ¬åœ°æ•°æ®ä»¥åŠåŒ…å« 118 åå‚ä¸è€…è®°å½•çš„ Raspberry Pi 4B å¤§å‹æ•°æ®é›†å¯¹ PulseFi è¿›è¡Œäº†å¹¿æ³›éªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨ä¼°ç®—ç”Ÿå‘½ä½“å¾æ–¹é¢çš„å‡†ç¡®åº¦ä¸æ˜‚è´µçš„å¤šå¤©çº¿ç³»ç»Ÿç›¸å½“ç”šè‡³æ›´é«˜ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½äº†ç¡¬ä»¶éƒ¨ç½²æˆæœ¬ã€‚PulseFi çš„æˆåŠŸç ”å‘ä¸ºåœ¨å„ç§åŒ»ç–—åœºæ™¯ä¸‹è¿›è¡Œè¿ç»­ã€æ— æ„Ÿä¸”ç»æµçš„ç”Ÿå‘½ä½“å¾ç›‘æµ‹æä¾›äº†é«˜æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "12 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.24744v1",
      "published_date": "2025-10-15 22:53:31 UTC",
      "updated_date": "2025-10-15 22:53:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:07.252130+00:00"
    },
    {
      "arxiv_id": "2510.17866v1",
      "title": "MUSE: Model-based Uncertainty-aware Similarity Estimation for zero-shot 2D Object Detection and Segmentation",
      "title_zh": "MUSEï¼šé¢å‘é›¶æ ·æœ¬äºŒç»´ç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²çš„åŸºäºæ¨¡å‹çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥ç›¸ä¼¼æ€§ä¼°è®¡",
      "authors": [
        "Sungmin Cho",
        "Sungbum Park",
        "Insoo Oh"
      ],
      "abstract": "In this work, we introduce MUSE (Model-based Uncertainty-aware Similarity Estimation), a training-free framework designed for model-based zero-shot 2D object detection and segmentation. MUSE leverages 2D multi-view templates rendered from 3D unseen objects and 2D object proposals extracted from input query images. In the embedding stage, it integrates class and patch embeddings, where the patch embeddings are normalized using generalized mean pooling (GeM) to capture both global and local representations efficiently. During the matching stage, MUSE employs a joint similarity metric that combines absolute and relative similarity scores, enhancing the robustness of matching under challenging scenarios. Finally, the similarity score is refined through an uncertainty-aware object prior that adjusts for proposal reliability. Without any additional training or fine-tuning, MUSE achieves state-of-the-art performance on the BOP Challenge 2025, ranking first across the Classic Core, H3, and Industrial tracks. These results demonstrate that MUSE offers a powerful and generalizable framework for zero-shot 2D object detection and segmentation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MUSE (Model-based Uncertainty-aware Similarity Estimation)ï¼Œä¸€ç§ç”¨äºé›¶æ ·æœ¬(zero-shot) 2Dç›®æ ‡æ£€æµ‹ä¸åˆ†å‰²çš„æ— éœ€è®­ç»ƒ(training-free)æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ä»3Dç‰©ä½“æ¸²æŸ“çš„2Då¤šè§†å›¾æ¨¡æ¿ä¸ä»æŸ¥è¯¢å›¾åƒæå–çš„2Då¯¹è±¡ææ¡ˆ(proposals)ï¼Œå¹¶åœ¨åµŒå…¥é˜¶æ®µåˆ©ç”¨å¹¿ä¹‰å¹³å‡æ± åŒ–(GeM)æ•´åˆç±»ä¸è¡¥ä¸åµŒå…¥ä»¥æœ‰æ•ˆæ•æ‰å…¨å±€å’Œå±€éƒ¨ç‰¹å¾ã€‚åœ¨åŒ¹é…è¿‡ç¨‹ä¸­ï¼ŒMUSE é‡‡ç”¨è”åˆç›¸ä¼¼åº¦æŒ‡æ ‡ç»“åˆç»å¯¹ä¸ç›¸å¯¹å¾—åˆ†ï¼Œå¹¶å¼•å…¥ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¯¹è±¡å…ˆéªŒ(uncertainty-aware object prior)æ¥æ ¹æ®ææ¡ˆå¯é æ€§ä¼˜åŒ–æœ€ç»ˆå¾—åˆ†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMUSE åœ¨æ— éœ€ä»»ä½•é¢å¤–è®­ç»ƒæˆ–å¾®è°ƒçš„æƒ…å†µä¸‹å¤ºå¾—BOP Challenge 2025ä¸‰ä¸ªèµ›é“çš„å† å†›ï¼Œå……åˆ†è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤„ç†æœªçŸ¥ç‰©ä½“æ£€æµ‹ä¸åˆ†å‰²ä»»åŠ¡æ—¶å…·æœ‰å¼ºå¤§çš„é²æ£’æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages with 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.17866v1",
      "published_date": "2025-10-15 22:16:09 UTC",
      "updated_date": "2025-10-15 22:16:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:11.464242+00:00"
    },
    {
      "arxiv_id": "2510.14139v1",
      "title": "Inferred global dense residue transition graphs from primary structure sequences enable protein interaction prediction via directed graph convolutional neural networks",
      "title_zh": "åŸºäºä¸€çº§ç»“æ„åºåˆ—æ¨æ–­çš„å…¨å±€ç¨ å¯†æ®‹åŸºè½¬ç§»å›¾ï¼šåˆ©ç”¨æœ‰å‘å›¾å·ç§¯ç¥ç»ç½‘ç»œå®ç°è›‹ç™½è´¨ç›¸äº’ä½œç”¨é¢„æµ‹",
      "authors": [
        "Islam Akef Ebeid",
        "Haoteng Tang",
        "Pengfei Gu"
      ],
      "abstract": "Introduction Accurate prediction of protein-protein interactions (PPIs) is crucial for understanding cellular functions and advancing drug development. Existing in-silico methods use direct sequence embeddings from Protein Language Models (PLMs). Others use Graph Neural Networks (GNNs) for 3D protein structures. This study explores less computationally intensive alternatives. We introduce a novel framework for downstream PPI prediction through link prediction. Methods We introduce a two-stage graph representation learning framework, ProtGram-DirectGCN. First, we developed ProtGram. This approach models a protein's primary structure as a hierarchy of globally inferred n-gram graphs. In these graphs, residue transition probabilities define edge weights. Each edge connects a pair of residues in a directed graph. The probabilities are aggregated from a large corpus of sequences. Second, we propose DirectGCN, a custom directed graph convolutional neural network. This model features a unique convolutional layer. It processes information through separate path-specific transformations: incoming, outgoing, and undirected. A shared transformation is also applied. These paths are combined via a learnable gating mechanism. We apply DirectGCN to ProtGram graphs to learn residue-level embeddings. These embeddings are pooled via attention to generate protein-level embeddings for prediction. Results We first established the efficacy of DirectGCN on standard node classification benchmarks. Its performance matches established methods on general datasets. The model excels at complex, directed graphs with dense, heterophilic structures. When applied to PPI prediction, the full ProtGram-DirectGCN framework delivers robust predictive power. This strong performance holds even with limited training data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ProtGram-DirectGCNï¼Œä¸€ç§ç”¨äºè›‹ç™½è´¨-è›‹ç™½è´¨ç›¸äº’ä½œç”¨(PPI)é¢„æµ‹çš„ä¸¤é˜¶æ®µå›¾è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨æä¾›æ¯”ç°æœ‰æ¨¡å‹è®¡ç®—æˆæœ¬æ›´ä½çš„æ›¿ä»£æ–¹æ¡ˆã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ProtGramæ–¹æ³•å°†è›‹ç™½è´¨ä¸€çº§ç»“æ„å»ºæ¨¡ä¸ºå…¨å±€æ¨æ–­çš„n-gramå›¾ï¼Œåˆ©ç”¨å¤§è§„æ¨¡è¯­æ–™åº“ä¸­çš„æ®‹åŸºè½¬ç§»æ¦‚ç‡(residue transition probabilities)å®šä¹‰æœ‰å‘è¾¹æƒé‡ã€‚éšåï¼Œç ”ç©¶è€…è®¾è®¡äº†å®šåˆ¶çš„æœ‰å‘å›¾å·ç§¯ç¥ç»ç½‘ç»œDirectGCNï¼Œé€šè¿‡ç‹¬ç‰¹çš„å·ç§¯å±‚å’Œå¯å­¦ä¹ çš„é—¨æ§æœºåˆ¶å¤„ç†å…¥è¾¹ã€å‡ºè¾¹åŠæ— å‘è·¯å¾„ä¿¡æ¯ã€‚è¯¥æ¨¡å‹é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶(attention)æ± åŒ–æ®‹åŸºçº§åµŒå…¥ä»¥ç”Ÿæˆè›‹ç™½è´¨è¡¨ç¤ºï¼Œåœ¨å¤„ç†å…·æœ‰å¯†é›†å¼‚è´¨ç»“æ„çš„æœ‰å‘å›¾æ—¶å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¯å®ï¼ŒProtGram-DirectGCNåœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ç¨³å¥ï¼Œå³ä½¿åœ¨è®­ç»ƒæ•°æ®æœ‰é™çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°é«˜ç²¾åº¦çš„PPIé¢„æµ‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "under review in Frontiers in Bioinformatics",
      "pdf_url": "https://arxiv.org/pdf/2510.14139v1",
      "published_date": "2025-10-15 22:15:31 UTC",
      "updated_date": "2025-10-15 22:15:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:14.011169+00:00"
    },
    {
      "arxiv_id": "2510.14136v1",
      "title": "A Multimodal Approach to Heritage Preservation in the Context of Climate Change",
      "title_zh": "æ°”å€™å˜åŒ–èƒŒæ™¯ä¸‹çš„æ–‡åŒ–é—äº§ä¿æŠ¤å¤šæ¨¡æ€æ–¹æ³•",
      "authors": [
        "David Roqui",
        "AdÃ¨le Cormier",
        "nistor Grozavu",
        "Ann Bourges"
      ],
      "abstract": "Cultural heritage sites face accelerating degradation due to climate change, yet tradi- tional monitoring relies on unimodal analysis (visual inspection or environmental sen- sors alone) that fails to capture the complex interplay between environmental stres- sors and material deterioration. We propose a lightweight multimodal architecture that fuses sensor data (temperature, humidity) with visual imagery to predict degradation severity at heritage sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified encoders (64D latent space) that prevent overfitting on small datasets (n=37 training samples), and (2) Adaptive Barlow Twins loss that encourages modality complementarity rather than redundancy. On data from Strasbourg Cathedral, our model achieves 76.9% accu- racy, a 43% improvement over standard multimodal architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO. Ablation studies reveal that sensor-only achieves 61.5% while image-only reaches 46.2%, confirming successful multimodal synergy. A systematic hyperparameter study identifies an optimal moderate correlation target (Ï„ =0.3) that balances align- ment and complementarity, achieving 69.2% accuracy compared to other Ï„ values (Ï„ =0.1/0.5/0.7: 53.8%, Ï„ =0.9: 61.5%). This work demonstrates that architectural sim- plicity combined with contrastive regularization enables effective multimodal learning in data-scarce heritage monitoring contexts, providing a foundation for AI-driven con- servation decision support systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ°”å€™å˜åŒ–èƒŒæ™¯ä¸‹æ–‡åŒ–é—äº§ä¿æŠ¤é¢ä¸´çš„ä¼ ç»Ÿå•æ¨¡æ€ç›‘æµ‹å±€é™ï¼Œæå‡ºäº†ä¸€ç§èåˆä¼ æ„Ÿå™¨æ•°æ®ï¼ˆæ¸©åº¦ã€æ¹¿åº¦ï¼‰ä¸è§†è§‰å›¾åƒçš„è½»é‡çº§å¤šæ¨¡æ€æ¶æ„ï¼Œæ—¨åœ¨é¢„æµ‹é—äº§åœ°ç‚¹çš„é€€åŒ–ä¸¥é‡ç¨‹åº¦ã€‚è¯¥æ–¹æ³•åŸºäº PerceiverIO è¿›è¡Œäº†ä¸¤é¡¹æ ¸å¿ƒåˆ›æ–°ï¼ŒåŒ…æ‹¬é‡‡ç”¨ 64 ç»´æ½œç©ºé—´çš„ç®€åŒ–ç¼–ç å™¨ï¼ˆsimplified encodersï¼‰ä»¥é˜²æ­¢åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆï¼Œä»¥åŠå¼•å…¥è‡ªé€‚åº” Barlow Twins æŸå¤±ï¼ˆAdaptive Barlow Twins lossï¼‰æ¥å¢å¼ºæ¨¡æ€é—´çš„äº’è¡¥æ€§ã€‚åœ¨æ–¯ç‰¹æ‹‰æ–¯å ¡å¤§æ•™å ‚ï¼ˆStrasbourg Cathedralï¼‰çš„æ•°æ®æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº† 76.9% çš„å‡†ç¡®ç‡ï¼Œç›¸æ¯” VisualBERT å’Œ Transformer ç­‰æ ‡å‡†å¤šæ¨¡æ€æ¶æ„æå‡äº† 43%ï¼Œæ¯”åŸå§‹ PerceiverIO æå‡äº† 25%ã€‚å®éªŒåˆ†æè¿›ä¸€æ­¥è¯å®äº†å¤šæ¨¡æ€ååŒæ•ˆåº”ï¼Œå¹¶ç¡®å®šäº†æœ€ä½³ç›¸å…³æ€§ç›®æ ‡ï¼ˆÏ„ = 0.3ï¼‰ä»¥å¹³è¡¡æ¨¡æ€é—´çš„å¯¹é½ä¸äº’è¡¥ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†åœ¨æ•°æ®ç¨€ç¼ºçš„é—äº§ç›‘æµ‹åœºæ™¯ä¸‹ï¼Œæ¶æ„ç®€åŒ–ç»“åˆå¯¹æ¯”æ­£åˆ™åŒ–ï¼ˆcontrastive regularizationï¼‰èƒ½æœ‰æ•ˆæå‡å­¦ä¹ æ€§èƒ½ï¼Œä¸ºäººå·¥æ™ºèƒ½é©±åŠ¨çš„ä¿æŠ¤å†³ç­–æ”¯æŒç³»ç»Ÿå¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14136v1",
      "published_date": "2025-10-15 22:07:57 UTC",
      "updated_date": "2025-10-15 22:07:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:19.293952+00:00"
    },
    {
      "arxiv_id": "2510.14133v1",
      "title": "Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems",
      "title_zh": "æ™ºèƒ½ä½“äººå·¥æ™ºèƒ½ç³»ç»Ÿå®‰å…¨æ€§ã€ä¿éšœæ€§ä¸åŠŸèƒ½å±æ€§çš„å½¢å¼åŒ–",
      "authors": [
        "Edoardo Allegrini",
        "Ananth Shreekumar",
        "Z. Berkay Celik"
      ],
      "abstract": "Agentic AI systems, which leverage multiple autonomous agents and Large Language Models (LLMs), are increasingly used to address complex, multi-step tasks. The safety, security, and functionality of these systems are critical, especially in high-stakes applications. However, the current ecosystem of inter-agent communication is fragmented, with protocols such as the Model Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol for coordination being analyzed in isolation. This fragmentation creates a semantic gap that prevents the rigorous analysis of system properties and introduces risks such as architectural misalignment and exploitable coordination issues. To address these challenges, we introduce a modeling framework for agentic AI systems composed of two foundational models. The first, the host agent model, formalizes the top-level entity that interacts with the user, decomposes tasks, and orchestrates their execution by leveraging external agents and tools. The second, the task lifecycle model, details the states and transitions of individual sub-tasks from creation to completion, providing a fine-grained view of task management and error handling. Together, these models provide a unified semantic framework for reasoning about the behavior of multi-AI agent systems. Grounded in this framework, we define 17 properties for the host agent and 14 for the task lifecycle, categorized into liveness, safety, completeness, and fairness. Expressed in temporal logic, these properties enable formal verification of system behavior, detection of coordination edge cases, and prevention of deadlocks and security vulnerabilities. Through this effort, we introduce the first rigorously grounded, domain-agnostic framework for the systematic analysis, design, and deployment of correct, reliable, and robust agentic AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Agentic AI ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ï¼Œå› é€šä¿¡åè®®ï¼ˆå¦‚ MCP å’Œ A2Aï¼‰ç¢ç‰‡åŒ–è€Œå¯¼è‡´çš„ Safetyã€Security å’ŒåŠŸèƒ½å±æ€§åˆ†æéš¾é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±è´Ÿè´£é¡¶å±‚ä»»åŠ¡åˆ†è§£ä¸åè°ƒçš„ Host Agent æ¨¡å‹ï¼Œä»¥åŠç»†åŒ–å­ä»»åŠ¡çŠ¶æ€è¿ç§»ä¸é”™è¯¯å¤„ç†çš„ Task Lifecycle æ¨¡å‹ç»„æˆã€‚åŸºäºè¯¥æ¡†æ¶ï¼Œç ”ç©¶è€…å®šä¹‰äº†æ¶µç›– Livenessã€Safetyã€Completeness å’Œ Fairness ç»´åº¦çš„ 31 é¡¹æ ¸å¿ƒå±æ€§ï¼Œå¹¶åˆ©ç”¨ Temporal Logic å®ç°äº†å¯¹ç³»ç»Ÿè¡Œä¸ºçš„ Formal Verificationã€‚è¿™ä¸€æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ£€æµ‹å¤šæ™ºèƒ½ä½“åä½œä¸­çš„è¾¹ç¼˜æ¡ˆä¾‹ï¼Œå¹¶é¢„é˜² Deadlocks ä¸å®‰å…¨æ¼æ´ã€‚è¯¥å·¥ä½œå»ºç«‹äº†é¦–ä¸ªä¸¥è°¨ä¸”é¢†åŸŸæ— å…³çš„ç†è®ºæ¡†æ¶ï¼Œä¸ºæ„å»ºã€è®¾è®¡å’Œéƒ¨ç½²å¯é ä¸”ç¨³å¥çš„ Agentic AI ç³»ç»Ÿå¥ å®šäº†ç³»ç»ŸåŒ–åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14133v1",
      "published_date": "2025-10-15 22:02:30 UTC",
      "updated_date": "2025-10-15 22:02:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:23.593292+00:00"
    },
    {
      "arxiv_id": "2510.15001v2",
      "title": "VaultGemma: A Differentially Private Gemma Model",
      "title_zh": "VaultGemmaï¼šå·®åˆ†éšç§ Gemma æ¨¡å‹",
      "authors": [
        "Amer Sinha",
        "Thomas Mesnard",
        "Ryan McKenna",
        "Daogao Liu",
        "Christopher A. Choquette-Choo",
        "Yangsibo Huang",
        "Da Yu",
        "George Kaissis",
        "Zachary Charles",
        "Ruibo Liu",
        "Lynn Chua",
        "Pritish Kamath",
        "Pasin Manurangsi",
        "Steve He",
        "Chiyuan Zhang",
        "Badih Ghazi",
        "Borja De Balle Pigem",
        "Prem Eruvbetine",
        "Tris Warkentin",
        "Armand Joulin",
        "Ravi Kumar"
      ],
      "abstract": "We introduce VaultGemma 1B, a 1 billion parameter model within the Gemma family, fully trained with differential privacy. Pretrained on the identical data mixture used for the Gemma 2 series, VaultGemma 1B represents a significant step forward in privacy-preserving large language models. We openly release this model to the community",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† VaultGemma 1Bï¼Œè¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰ 10 äº¿å‚æ•°çš„æ¨¡å‹ï¼Œå±äº Gemma ç³»åˆ—ï¼Œä¸”æ˜¯å®Œå…¨é‡‡ç”¨å·®åˆ†éšç§ (Differential Privacy) æŠ€æœ¯è®­ç»ƒè€Œæˆçš„ã€‚è¯¥æ¨¡å‹ä½¿ç”¨äº†ä¸ Gemma 2 ç³»åˆ—å®Œå…¨ç›¸åŒçš„é¢„è®­ç»ƒæ•°æ®æ··åˆç‰©ï¼Œåœ¨ç¡®ä¿éšç§å¼ºåº¦çš„åŒæ—¶ä¿æŒäº†æ¨¡å‹çš„èƒ½åŠ›ã€‚VaultGemma 1B çš„å‘å¸ƒä»£è¡¨äº†éšç§ä¿æŠ¤å¤§å‹è¯­è¨€æ¨¡å‹ (Large Language Models) é¢†åŸŸçš„é‡è¦è¿›å±•ï¼Œä¸ºå¤„ç†æ•æ„Ÿæ•°æ®æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚ç›®å‰ï¼Œç ”ç©¶å›¢é˜Ÿå·²å°†è¯¥æ¨¡å‹å‘ç¤¾åŒºå¼€æºï¼Œæ—¨åœ¨ä¿ƒè¿›å®‰å…¨ã€åˆè§„çš„ AI æŠ€æœ¯å‘å±•ä¸åº”ç”¨ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.15001v2",
      "published_date": "2025-10-15 21:59:53 UTC",
      "updated_date": "2025-10-22 23:11:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:22.774129+00:00"
    },
    {
      "arxiv_id": "2510.14113v1",
      "title": "Toward Cybersecurity-Expert Small Language Models",
      "title_zh": "è¿ˆå‘ç½‘ç»œå®‰å…¨ä¸“å®¶çº§å°è¯­è¨€æ¨¡å‹",
      "authors": [
        "Matan Levi",
        "Daniel Ohayon",
        "Ariel Blobstein",
        "Ravid Sagi",
        "Ian Molloy",
        "Yair Allouche"
      ],
      "abstract": "Large language models (LLMs) are transforming everyday applications, yet deployment in cybersecurity lags due to a lack of high-quality, domain-specific models and training datasets. To address this gap, we present CyberPal 2.0, a family of cybersecurity-expert small language models (SLMs) ranging from 4B-20B parameters. To train CyberPal 2.0, we generate an enriched chain-of-thought cybersecurity instruction dataset built with our data enrichment and formatting pipeline, SecKnowledge 2.0, which integrates expert-in-the-loop steering of reasoning formats alongside LLM-driven multi-step grounding, yielding higher-fidelity, task-grounded reasoning traces for security tasks. Across diverse cybersecurity benchmarks, CyberPal 2.0 consistently outperforms its baselines and matches or surpasses various open and closed-source frontier models, while remaining a fraction of their size. On core cyber threat intelligence knowledge tasks, our models outperform almost all tested frontier models, ranking second only to Sec-Gemini v1. On core threat-investigation tasks, such as correlating vulnerabilities and bug tickets with weaknesses, our best 20B-parameter model outperforms GPT-4o, o1, o3-mini, and Sec-Gemini v1, ranking first, while our smallest 4B-parameter model ranks second.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† CyberPal 2.0ï¼Œè¿™æ˜¯ä¸€ä¸ªå‚æ•°è§„æ¨¡åœ¨ 4B åˆ° 20B ä¹‹é—´çš„ç½‘ç»œå®‰å…¨ä¸“å®¶çº§å°è¯­è¨€æ¨¡å‹ï¼ˆSmall Language Modelsï¼‰ç³»åˆ—ï¼Œæ—¨åœ¨å¡«è¡¥è¯¥é¢†åŸŸé«˜è´¨é‡ä¸“ä¸šæ¨¡å‹ä¸æ•°æ®é›†çš„ç©ºç™½ã€‚é€šè¿‡å…¶å¼€å‘çš„æ•°æ®å¢å¼ºä¸æ ¼å¼åŒ–æµæ°´çº¿ SecKnowledge 2.0ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªå¯Œå«é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰çš„æŒ‡ä»¤æ•°æ®é›†ï¼Œè¯¥æµæ°´çº¿ç»“åˆäº†ä¸“å®¶åœ¨ç¯ï¼ˆexpert-in-the-loopï¼‰å¼•å¯¼å’Œå¤šæ­¥æ¥åœ°ï¼ˆmulti-step groundingï¼‰æŠ€æœ¯ï¼Œç¡®ä¿äº†æ¨ç†è½¨è¿¹çš„é«˜ä¿çœŸåº¦ã€‚åœ¨å¤šé¡¹ç½‘ç»œå®‰å…¨åŸºå‡†æµ‹è¯•ä¸­ï¼ŒCyberPal 2.0 å±•ç°å‡ºå“è¶Šæ€§èƒ½ï¼Œä¸ä»…åœ¨æ ¸å¿ƒç½‘ç»œå¨èƒæƒ…æŠ¥ï¼ˆCyber Threat Intelligenceï¼‰ä»»åŠ¡ä¸­æ’åå‰åˆ—ï¼Œæ›´åœ¨å¨èƒè°ƒæŸ¥ä»»åŠ¡ä¸Šè¡¨ç°æƒŠäººã€‚å…¶å®éªŒç»“æœè¡¨æ˜ï¼ŒCyberPal 2.0 çš„ 20B å‚æ•°ç‰ˆæœ¬åœ¨å…³è”æ¼æ´ä¸å¼±ç‚¹ç­‰ä»»åŠ¡ä¸­è¶…è¶Šäº† GPT-4oã€o1 å’Œ Sec-Gemini v1 ç­‰é¡¶çº§æ¨¡å‹ï¼Œç”šè‡³å…¶ 4B è§„æ¨¡çš„æœ€å°æ¨¡å‹ä¹Ÿå±•ç°äº†æå¼ºçš„ç«äº‰åŠ›ï¼Œä¸ºé«˜æ•ˆã€ä½æˆæœ¬çš„å®‰å…¨ä¸“ç”¨æ¨¡å‹éƒ¨ç½²æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14113v1",
      "published_date": "2025-10-15 21:34:58 UTC",
      "updated_date": "2025-10-15 21:34:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:36.727391+00:00"
    },
    {
      "arxiv_id": "2510.14112v2",
      "title": "STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management",
      "title_zh": "STEMSï¼šé¢å‘å»ºç­‘èƒ½æºç®¡ç†çš„æ—¶ç©ºå¢å¼ºå‹å®‰å…¨å¤šæ™ºèƒ½ä½“ååŒ",
      "authors": [
        "Huiliang Zhang",
        "Di Wu",
        "Arnaud Zinflou",
        "Benoit Boulet"
      ],
      "abstract": "Building energy management is essential for achieving carbon reduction goals, improving occupant comfort, and reducing energy costs. Coordinated building energy management faces critical challenges in exploiting spatial-temporal dependencies while ensuring operational safety across multi-building systems. Current multi-building energy systems face three key challenges: insufficient spatial-temporal information exploitation, lack of rigorous safety guarantees, and system complexity. This paper proposes Spatial-Temporal Enhanced Safe Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent reinforcement learning framework for coordinated building energy management. STEMS integrates two core components: (1) a spatial-temporal graph representation learning framework using a GCN-Transformer fusion architecture to capture inter-building relationships and temporal patterns, and (2) a safety-constrained multi-agent RL algorithm incorporating Control Barrier Functions to provide mathematical safety guarantees. Extensive experiments on real-world building datasets demonstrate STEMS's superior performance over existing methods, showing that STEMS achieves 21% cost reduction, 18% emission reduction, and dramatically reduces safety violations from 35.1% to 5.6% while maintaining optimal comfort with only 0.13 discomfort proportion. The framework also demonstrates strong robustness during extreme weather conditions and maintains effectiveness across different building types.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†STEMSï¼Œä¸€ç§æ—¨åœ¨è§£å†³å¤šå»ºç­‘èƒ½æºç®¡ç†(Building Energy Management)ä¸­æ—¶ç©ºä¾èµ–æ€§æŒ–æ˜ã€è¿è¡Œå®‰å…¨ä¿éšœä»¥åŠç³»ç»Ÿå¤æ‚æ€§æŒ‘æˆ˜çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚STEMSé›†æˆäº†åŸºäºGCN-Transformerèåˆæ¶æ„çš„æ—¶ç©ºå›¾è¡¨å¾å­¦ä¹ æ¡†æ¶ï¼Œç”¨ä»¥ç²¾å‡†æ•æ‰å»ºç­‘é—´çš„ç©ºé—´å…³è”ä¸æ—¶åºæ¨¡å¼ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ç»“åˆæ§åˆ¶å±éšœå‡½æ•°(Control Barrier Functions)çš„å®‰å…¨çº¦æŸå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)ç®—æ³•ï¼Œä¸ºèƒ½æºè°ƒåº¦æä¾›ä¸¥è°¨çš„æ•°å­¦å®‰å…¨ä¿è¯ã€‚åœ¨çœŸå®å»ºç­‘æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒSTEMSç›¸è¾ƒäºç°æœ‰æ–¹æ³•å®ç°äº†21%çš„æˆæœ¬é™ä½å’Œ18%çš„æ’æ”¾å‡å°‘ï¼Œå¹¶å°†å®‰å…¨è¿è§„ç‡ä»35.1%å¤§å¹…é™è‡³5.6%ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨æä½çš„ä¸é€‚æ¯”ä¾‹ä¸‹ç»´æŒäº†æœ€ä¼˜çš„å±…ä½èˆ’é€‚åº¦ï¼Œå¹¶åœ¨æç«¯å¤©æ°”æ¡ä»¶ä¸‹å±•ç°å‡ºæå¼ºçš„é²æ£’æ€§ä¸è·¨åœºæ™¯é€‚ç”¨æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14112v2",
      "published_date": "2025-10-15 21:33:58 UTC",
      "updated_date": "2025-12-16 03:53:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:37.870691+00:00"
    },
    {
      "arxiv_id": "2510.14106v1",
      "title": "Generating Fair Consensus Statements with Social Choice on Token-Level MDPs",
      "title_zh": "åŸºäºè¯å…ƒçº§é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ä¸ç¤¾ä¼šé€‰æ‹©çš„å…¬å¹³å…±è¯†å£°æ˜ç”Ÿæˆ",
      "authors": [
        "Carter Blair",
        "Kate Larson"
      ],
      "abstract": "Current frameworks for consensus statement generation with large language models lack the inherent structure needed to provide provable fairness guarantees when aggregating diverse free-form opinions. We model the task as a multi-objective, token-level Markov Decision Process (MDP), where each objective corresponds to an agent's preference. Token-level rewards for each agent are derived from their policy (e.g., a personalized language model). This approach utilizes the finding that such policies implicitly define optimal Q-functions, providing a principled way to quantify rewards at each generation step without a value function (Rafailov et al., 2024). This MDP formulation creates a formal structure amenable to analysis using principles from social choice theory. We propose two approaches grounded in social choice theory. First, we propose a stochastic generation policy guaranteed to be in the ex-ante core, extending core stability concepts from voting theory to text generation. This policy is derived from an underlying distribution over complete statements that maximizes proportional fairness (Nash Welfare). Second, for generating a single statement, we target the maximization of egalitarian welfare using search algorithms within the MDP framework. Empirically, experiments using language models to instantiate agent policies show that search guided by the egalitarian objective generates consensus statements with improved worst-case agent alignment compared to baseline methods, including the Habermas Machine (Tessler et al., 2024).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¤§è¯­è¨€æ¨¡å‹åœ¨ç”Ÿæˆå…±è¯†é™ˆè¿°æ—¶ç¼ºä¹å½¢å¼åŒ–ç»“æ„å’Œå¯è¯æ˜å…¬å¹³æ€§ä¿éšœçš„é—®é¢˜ï¼Œæå‡ºå°†å…±è¯†ç”Ÿæˆå»ºæ¨¡ä¸ºå¤šç›®æ ‡ã€Token-Level MDPï¼ˆé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼‰ã€‚è¯¥æ–¹æ³•å°†æ¯ä¸ªæ™ºèƒ½ä½“çš„åå¥½è§†ä¸ºç‹¬ç«‹ç›®æ ‡ï¼Œå¹¶ä»å…¶ä¸ªæ€§åŒ–æ¨¡å‹ç­–ç•¥ä¸­ç›´æ¥æ¨å¯¼å‡ºToken-Levelå¥–åŠ±ã€‚åŸºäºç¤¾ä¼šé€‰æ‹©ç†è®º(Social Choice Theory)ï¼Œç ”ç©¶è®¾è®¡äº†ä¸¤ç§è·¯å¾„ï¼šä¸€æ˜¯é€šè¿‡æœ€å¤§åŒ–çº³ä»€ç¦åˆ©(Nash Welfare)å®ç°å…·æœ‰äº‹å‰æ ¸å¿ƒ(Ex-ante Core)ç¨³å®šæ€§çš„æ¯”ä¾‹å…¬å¹³éšæœºç­–ç•¥ï¼›äºŒæ˜¯é€šè¿‡æœç´¢ç®—æ³•æœ€å¤§åŒ–å¹³ç­‰ç¦åˆ©(Egalitarian Welfare)æ¥ç”Ÿæˆå•ä¸€å…±è¯†é™ˆè¿°ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ™ºèƒ½ä½“å¯¹é½åº¦ä¸Šä¼˜äºHabermas Machineç­‰ç°æœ‰åŸºçº¿ï¼Œç‰¹åˆ«æ˜¯åœ¨æ”¹å–„æœ€å·®æƒ…å†µä¸‹çš„æ™ºèƒ½ä½“æ»¡æ„åº¦æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä¸ºå…¬å¹³èšåˆå¤šæ ·åŒ–è§‚ç‚¹æä¾›äº†ä¸¥è°¨çš„ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14106v1",
      "published_date": "2025-10-15 21:23:18 UTC",
      "updated_date": "2025-10-15 21:23:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:43.889207+00:00"
    },
    {
      "arxiv_id": "2510.14102v1",
      "title": "Extracting latent representations from X-ray spectra. Classification, regression, and accretion signatures of Chandra sources",
      "title_zh": "X å°„çº¿å…‰è°±æ½œåœ¨è¡¨ç¤ºæå–ï¼šChandra æºçš„åˆ†ç±»ã€å›å½’ä¸å¸ç§¯ç‰¹å¾",
      "authors": [
        "NicolÃ² Oreste Pinciroli Vago",
        "Juan Rafael MartÃ­nez-Galarza",
        "Roberta Amato"
      ],
      "abstract": "The study of X-ray spectra is crucial to understanding the physical nature of astrophysical sources. Machine learning methods can extract compact and informative representations of data from large datasets. The Chandra Source Catalog (CSC) provides a rich archive of X-ray spectral data, which remains largely underexplored in this context. This work aims to develop a compact and physically meaningful representation of Chandra X-ray spectra using deep learning. To verify that the learned representation captures relevant information, we evaluate it through classification, regression, and interpretability analyses. We use a transformer-based autoencoder to compress X-ray spectra. The input spectra, drawn from the CSC, include only high-significance detections. Astrophysical source types and physical summary statistics are compiled from external catalogs. We evaluate the learned representation in terms of spectral reconstruction accuracy, clustering performance on 8 known astrophysical source classes, and correlation with physical quantities such as hardness ratios and hydrogen column density ($N_H$). The autoencoder accurately reconstructs spectra with 8 latent variables. Clustering in the latent space yields a balanced classification accuracy of $\\sim$40% across the 8 source classes, increasing to $\\sim$69% when restricted to AGNs and stellar-mass compact objects exclusively. Moreover, latent features correlate with non-linear combinations of spectral fluxes, suggesting that the compressed representation encodes physically relevant information. The proposed autoencoder-based pipeline is a powerful tool for the representation and interpretation of X-ray spectra, providing a compact latent space that supports both classification and the estimation of physical properties. This work demonstrates the potential of deep learning for spectral studies and uncovering new patterns in X-ray data.",
      "tldr_zh": "è¯¥é¡¹ç ”ç©¶åˆ©ç”¨æ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œç‰¹åˆ«æ˜¯åŸºäº Transformer çš„è‡ªåŠ¨ç¼–ç å™¨ (autoencoder)ï¼Œæ—¨åœ¨ä» Chandra X-ray spectra ä¸­æå–ç´§å‡‘ä¸”å…·æœ‰ç‰©ç†æ„ä¹‰çš„æ½œåœ¨è¡¨ç¤º (latent representations)ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¤„ç†æ¥è‡ª Chandra Source Catalog (CSC) çš„é«˜æ˜¾è‘—æ€§æ¢æµ‹æ•°æ®ï¼ŒæˆåŠŸå°†å¤æ‚çš„å…‰è°±ä¿¡æ¯å‹ç¼©ä¸º 8 ä¸ªæ½œåœ¨å˜é‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ½œåœ¨ç©ºé—´åœ¨ 8 ç±»å¤©æ–‡ç‰©ç†æ³¢æºçš„åˆ†ç±»ä¸­è¾¾åˆ°äº†çº¦ 40% çš„å‡†ç¡®ç‡ï¼Œè€Œåœ¨åŒºåˆ† AGN å’Œæ’æ˜Ÿçº§è‡´å¯†å¤©ä½“æ—¶å‡†ç¡®ç‡å¯æå‡è‡³ 69%ã€‚æ­¤å¤–ï¼Œæå–çš„æ½œåœ¨ç‰¹å¾ä¸ç¡¬åº¦æ¯” (hardness ratios) å’Œæ°¢æŸ±å¯†åº¦ ($N_H$) ç­‰ç‰©ç†é‡è¡¨ç°å‡ºæ˜¾è‘—ç›¸å…³æ€§ï¼Œè¯æ˜äº†è¯¥å‹ç¼©è¡¨ç¤ºæœ‰æ•ˆåœ°ç¼–ç äº†å…³é”®çš„ç‰©ç†ä¿¡æ¯ã€‚è¿™é¡¹å·¥ä½œå±•ç¤ºäº†æ·±åº¦å­¦ä¹ åœ¨å…‰è°±ç ”ç©¶åŠæ­ç¤º X å°„çº¿æ•°æ®æ–°æ¨¡å¼æ–¹é¢çš„å·¨å¤§æ½œåŠ›ï¼Œä¸º X-ray spectra çš„è¡¨å¾ä¸è§£é‡Šæä¾›äº†å¼ºæœ‰åŠ›çš„å·¥å…·ã€‚",
      "categories": [
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14102v1",
      "published_date": "2025-10-15 21:20:32 UTC",
      "updated_date": "2025-10-15 21:20:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:48.489247+00:00"
    },
    {
      "arxiv_id": "2510.16028v2",
      "title": "Nondeterminism-Aware Optimistic Verification for Floating-Point Neural Networks",
      "title_zh": "æµ®ç‚¹ç¥ç»ç½‘ç»œçš„éç¡®å®šæ€§æ„ŸçŸ¥ä¹è§‚éªŒè¯",
      "authors": [
        "Jianzhu Yao",
        "Hongxu Su",
        "Taobo Liao",
        "Zerui Cheng",
        "Huan Zhang",
        "Xuechao Wang",
        "Pramod Viswanath"
      ],
      "abstract": "Neural networks increasingly run on hardware outside the user's control (cloud GPUs, inference marketplaces). Yet ML-as-a-Service reveals little about what actually ran or whether returned outputs faithfully reflect the intended inputs. Users lack recourse against service downgrades (model swaps, quantization, graph rewrites, or discrepancies like altered ad embeddings). Verifying outputs is hard because floating-point(FP) execution on heterogeneous accelerators is inherently nondeterministic. Existing approaches are either impractical for real FP neural networks or reintroduce vendor trust. We present NAO: a Nondeterministic tolerance Aware Optimistic verification protocol that accepts outputs within principled operator-level acceptance regions rather than requiring bitwise equality. NAO combines two error models: (i) sound per-operator IEEE-754 worst-case bounds and (ii) tight empirical percentile profiles calibrated across hardware. Discrepancies trigger a Merkle-anchored, threshold-guided dispute game that recursively partitions the computation graph until one operator remains, where adjudication reduces to a lightweight theoretical-bound check or a small honest-majority vote against empirical thresholds. Unchallenged results finalize after a challenge window, without requiring trusted hardware or deterministic kernels. We implement NAO as a PyTorch-compatible runtime and a contract layer currently deployed on Ethereum Holesky testnet. The runtime instruments graphs, computes per-operator bounds, and runs unmodified vendor kernels in FP32 with negligible overhead (0.3% on Qwen3-8B). Across CNNs, Transformers and diffusion models on A100, H100, RTX6000, RTX4090, empirical thresholds are $10^2-10^3$ times tighter than theoretical bounds, and bound-aware adversarial attacks achieve 0% success. NAO reconciles scalability with verifiability for real-world heterogeneous ML compute.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äº‘ç«¯GPUç­‰ç¬¬ä¸‰æ–¹ç¡¬ä»¶è¿è¡Œç¥ç»ç½‘ç»œæ—¶å­˜åœ¨çš„éç¡®å®šæ€§(nondeterminism)å’Œä¿¡ä»»ç¼ºå¤±é—®é¢˜ï¼Œæå‡ºäº†NAOï¼Œä¸€ç§éç¡®å®šæ€§æ„ŸçŸ¥ä¹è§‚éªŒè¯åè®®ã€‚ä¸åŒäºä¼ ç»Ÿçš„é€ä½ç­‰å€¼(bitwise equality)æ ¡éªŒï¼ŒNAOé€šè¿‡å»ºç«‹ç®—å­çº§(operator-level)çš„å¯æ¥å—åŒºé—´ï¼Œå¹¶ç»“åˆIEEE-754æ ‡å‡†çš„æœ€åæƒ…å†µç†è®ºè¾¹ç•Œ(worst-case bounds)ä¸è·¨ç¡¬ä»¶æ ¡å‡†çš„ç´§è‡´ç»éªŒç™¾åˆ†ä½åˆ†å¸ƒ(empirical percentile profiles)æ¥éªŒè¯è¾“å‡ºã€‚å½“è¾“å‡ºå‡ºç°åˆ†æ­§æ—¶ï¼ŒNAOåˆ©ç”¨åŸºäºMerkleæ ‘çš„äº‰è®®åšå¼ˆ(dispute game)é€’å½’åˆ’åˆ†è®¡ç®—å›¾ï¼Œé€šè¿‡è½»é‡çº§ç†è®ºæ£€æŸ¥æˆ–å¤šæ•°ç¥¨å†³æœºåˆ¶è¿›è¡Œè£å†³ã€‚è¯¥ç³»ç»Ÿä»¥å…¼å®¹PyTorchçš„è¿è¡Œæ—¶å½¢å¼å®ç°ï¼Œå¹¶åœ¨Ethereum Holeskyæµ‹è¯•ç½‘ä¸Šéƒ¨ç½²äº†åˆçº¦å±‚ï¼Œæ”¯æŒä¸ç»ä¿®æ”¹çš„ä¾›åº”å•†å†…æ ¸ä»¥FP32ç²¾åº¦è¿è¡Œã€‚å®éªŒæ˜¾ç¤ºNAOåœ¨Qwen3-8Bæ¨¡å‹ä¸Šçš„è¿è¡Œå¼€é”€ä»…ä¸º0.3%ï¼Œä¸”å…¶ç»éªŒé˜ˆå€¼æ¯”ç†è®ºè¾¹ç•Œç´§è‡´100è‡³1000å€ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæŠµå¾¡æ„ŸçŸ¥è¾¹ç•Œçš„å¯¹æŠ—æ€§æ”»å‡»(adversarial attacks)ã€‚è¯¥æ¡†æ¶ä¸ºå¼‚æ„æœºå™¨å­¦ä¹ è®¡ç®—(heterogeneous ML compute)åœ¨ä¿è¯å¯æ‰©å±•æ€§çš„åŒæ—¶æä¾›äº†å¯é çš„å¯éªŒè¯æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.16028v2",
      "published_date": "2025-10-15 21:10:39 UTC",
      "updated_date": "2025-10-21 17:28:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:49.889044+00:00"
    },
    {
      "arxiv_id": "2510.14095v1",
      "title": "Unlocking Out-of-Distribution Generalization in Transformers via Recursive Latent Space Reasoning",
      "title_zh": "é€šè¿‡é€’å½’æ½œç©ºé—´æ¨ç†å®ç° Transformer çš„åˆ†å¸ƒå¤–æ³›åŒ–",
      "authors": [
        "Awni Altabaa",
        "Siyu Chen",
        "John Lafferty",
        "Zhuoran Yang"
      ],
      "abstract": "Systematic, compositional generalization beyond the training distribution remains a core challenge in machine learning -- and a critical bottleneck for the emergent reasoning abilities of modern language models. This work investigates out-of-distribution (OOD) generalization in Transformer networks using a GSM8K-style modular arithmetic on computational graphs task as a testbed. We introduce and explore a set of four architectural mechanisms aimed at enhancing OOD generalization: (i) input-adaptive recurrence; (ii) algorithmic supervision; (iii) anchored latent representations via a discrete bottleneck; and (iv) an explicit error-correction mechanism. Collectively, these mechanisms yield an architectural approach for native and scalable latent space reasoning in Transformer networks with robust algorithmic generalization capabilities. We complement these empirical results with a detailed mechanistic interpretability analysis that reveals how these mechanisms give rise to robust OOD generalization abilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformerç½‘ç»œåœ¨è¶…å‡ºè®­ç»ƒåˆ†å¸ƒ(Out-of-Distribution, OOD)æƒ…å†µä¸‹çš„ç³»ç»Ÿæ€§å’Œç»„åˆæ³›åŒ–èƒ½åŠ›ï¼Œæ—¨åœ¨è§£å†³ç°ä»£è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›çš„æ ¸å¿ƒç“¶é¢ˆã€‚ç ”ç©¶è€…ä»¥è®¡ç®—å›¾ä¸Šçš„GSM8Ké£æ ¼æ¨¡ç®—æœ¯ä»»åŠ¡ä¸ºæµ‹è¯•åŸºå‡†ï¼Œå¼•å…¥äº†å››ç§å¢å¼ºOODæ³›åŒ–èƒ½åŠ›çš„æ¶æ„æœºåˆ¶ï¼ŒåŒ…æ‹¬è¾“å…¥è‡ªé€‚åº”é€’å½’(input-adaptive recurrence)ã€ç®—æ³•ç›‘ç£(algorithmic supervision)ã€é€šè¿‡ç¦»æ•£ç“¶é¢ˆ(discrete bottleneck)é”šå®šçš„æ½œåœ¨è¡¨ç¤ºä»¥åŠæ˜¾å¼è¯¯å·®æ ¡æ­£æœºåˆ¶ã€‚è¿™äº›æœºåˆ¶å…±åŒæ„æˆäº†ä¸€ç§åœ¨Transformerç½‘ç»œä¸­è¿›è¡ŒåŸç”Ÿä¸”å¯æ‰©å±•çš„æ½œåœ¨ç©ºé—´æ¨ç†(latent space reasoning)æ–¹æ³•ï¼Œä½¿æ¨¡å‹å…·å¤‡äº†ç¨³å¥çš„ç®—æ³•æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ¶æ„çš„æœ‰æ•ˆæ€§ï¼Œå¹¶é€šè¿‡è¯¦ç»†çš„æœºæ¢°å¯è§£é‡Šæ€§åˆ†æ(mechanistic interpretability analysis)æ­ç¤ºäº†è¿™äº›æœºåˆ¶å¦‚ä½•è¯±å¯¼äº§ç”Ÿé²æ£’çš„æ³›åŒ–è¡Œä¸ºã€‚è¯¥å·¥ä½œä¸ºæå‡ç¥ç»ç½‘ç»œçš„ç³»ç»Ÿæ€§æ¨ç†å’Œç®—æ³•æ³›åŒ–èƒ½åŠ›æä¾›äº†é‡è¦çš„æ¶æ„åˆ›æ–°ä¸ç†è®ºè§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14095v1",
      "published_date": "2025-10-15 21:03:59 UTC",
      "updated_date": "2025-10-15 21:03:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:59.176754+00:00"
    },
    {
      "arxiv_id": "2510.14086v1",
      "title": "Every Language Model Has a Forgery-Resistant Signature",
      "title_zh": "æ¯ä¸ªè¯­è¨€æ¨¡å‹éƒ½æ‹¥æœ‰é˜²ä¼ªç­¾å",
      "authors": [
        "Matthew Finlayson",
        "Xiang Ren",
        "Swabha Swayamdipta"
      ],
      "abstract": "The ubiquity of closed-weight language models with public-facing APIs has generated interest in forensic methods, both for extracting hidden model details (e.g., parameters) and for identifying models by their outputs. One successful approach to these goals has been to exploit the geometric constraints imposed by the language model architecture and parameters. In this work, we show that a lesser-known geometric constraint--namely, that language model outputs lie on the surface of a high-dimensional ellipse--functions as a signature for the model and can be used to identify the source model of a given output. This ellipse signature has unique properties that distinguish it from existing model-output association methods like language model fingerprints. In particular, the signature is hard to forge: without direct access to model parameters, it is practically infeasible to produce log-probabilities (logprobs) on the ellipse. Secondly, the signature is naturally occurring, since all language models have these elliptical constraints. Thirdly, the signature is self-contained, in that it is detectable without access to the model inputs or the full weights. Finally, the signature is compact and redundant, as it is independently detectable in each logprob output from the model. We evaluate a novel technique for extracting the ellipse from small models and discuss the practical hurdles that make it infeasible for production-scale models. Finally, we use ellipse signatures to propose a protocol for language model output verification, analogous to cryptographic symmetric-key message authentication systems.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘ç°è¯­è¨€æ¨¡å‹è¾“å‡ºå­˜åœ¨ä¸€ç§é²œä¸ºäººçŸ¥çš„å‡ ä½•çº¦æŸï¼Œå³æ¨¡å‹è¾“å‡ºä½äºä¸€ä¸ªé«˜ç»´æ¤­åœ† (high-dimensional ellipse) çš„è¡¨é¢ï¼Œè¿™ä¸€ç‰¹æ€§å¯ä»¥ä½œä¸ºè¯¥æ¨¡å‹çš„å”¯ä¸€ç­¾å (signature)ã€‚ä¸ç°æœ‰çš„è¯­è¨€æ¨¡å‹æŒ‡çº¹æŠ€æœ¯ä¸åŒï¼Œè¿™ç§æ¤­åœ†ç­¾åå…·æœ‰æå¼ºçš„é˜²ä¼ªæ€§ (forgery-resistant)ï¼Œåœ¨æ²¡æœ‰ç›´æ¥è·å–æ¨¡å‹å‚æ•°çš„æƒ…å†µä¸‹ï¼Œå‡ ä¹ä¸å¯èƒ½ä¼ªé€ å‡ºç¬¦åˆè¯¥æ¤­åœ†çº¦æŸçš„å¯¹æ•°æ¦‚ç‡ (log-probabilities)ã€‚è¿™ç§ç­¾åæ˜¯å¤©ç„¶å­˜åœ¨çš„ä¸”å…·æœ‰è‡ªåŒ…å«æ€§ (self-contained)ï¼Œåœ¨æ— éœ€è®¿é—®æ¨¡å‹è¾“å…¥æˆ–å®Œæ•´æƒé‡çš„æƒ…å†µä¸‹å³å¯è¢«æ£€æµ‹åˆ°ã€‚æ¤­åœ†ç­¾åè¿˜å…·å¤‡ç´§å‡‘ä¸”å†—ä½™çš„ç‰¹æ€§ï¼Œå¯ä»¥ä»æ¨¡å‹çš„æ¯ä¸€ä¸ªå¯¹æ•°æ¦‚ç‡è¾“å‡ºä¸­ç‹¬ç«‹æ£€æµ‹å‡ºæ¥ã€‚ä½œè€…è¯„ä¼°äº†ä¸€ç§ä»å°æ¨¡å‹ä¸­æå–æ¤­åœ†ç­¾åçš„åˆ›æ–°æŠ€æœ¯ï¼Œå¹¶æ¢è®¨äº†åœ¨å¤§è§„æ¨¡ç”Ÿäº§æ¨¡å‹ä¸­åº”ç”¨è¯¥æŠ€æœ¯æ‰€é¢ä¸´çš„å®é™…éšœç¢ã€‚æœ€åï¼Œè¯¥ç ”ç©¶åˆ©ç”¨æ¤­åœ†ç­¾åæå‡ºäº†ä¸€ç§è¯­è¨€æ¨¡å‹è¾“å‡ºéªŒè¯åè®®ï¼Œå…¶åŠŸèƒ½ç±»ä¼¼äºå¯†ç å­¦ä¸­çš„å¯¹ç§°å¯†é’¥æ¶ˆæ¯è®¤è¯ç³»ç»Ÿ (symmetric-key message authentication systems)ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14086v1",
      "published_date": "2025-10-15 20:46:38 UTC",
      "updated_date": "2025-10-15 20:46:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:57.992237+00:00"
    },
    {
      "arxiv_id": "2510.14075v1",
      "title": "DiffOPF: Diffusion Solver for Optimal Power Flow",
      "title_zh": "DiffOPFï¼šé¢å‘æœ€ä¼˜æ½®æµçš„æ‰©æ•£æ±‚è§£å™¨",
      "authors": [
        "Milad Hoseinpour",
        "Vladimir Dvorkin"
      ],
      "abstract": "The optimal power flow (OPF) is a multi-valued, non-convex mapping from loads to dispatch setpoints. The variability of system parameters (e.g., admittances, topology) further contributes to the multiplicity of dispatch setpoints for a given load. Existing deep learning OPF solvers are single-valued and thus fail to capture the variability of system parameters unless fully represented in the feature space, which is prohibitive. To solve this problem, we introduce a diffusion-based OPF solver, termed \\textit{DiffOPF}, that treats OPF as a conditional sampling problem. The solver learns the joint distribution of loads and dispatch setpoints from operational history, and returns the marginal dispatch distributions conditioned on loads. Unlike single-valued solvers, DiffOPF enables sampling statistically credible warm starts with favorable cost and constraint satisfaction trade-offs. We explore the sample complexity of DiffOPF to ensure the OPF solution within a prescribed distance from the optimization-based solution, and verify this experimentally on power system benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DiffOPFï¼Œä¸€ç§é’ˆå¯¹æœ€ä¼˜æ½®æµ (Optimal Power Flow, OPF) é—®é¢˜çš„æ‰©æ•£æ±‚è§£å™¨ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ–¹æ³•åœ¨å¤„ç†å¤šå€¼ã€éå‡¸æ˜ å°„åŠç³»ç»Ÿå‚æ•°å˜åŠ¨æ—¶çš„å±€é™æ€§ã€‚DiffOPF å°† OPF å»ºæ¨¡ä¸ºä¸€ä¸ªæ¡ä»¶é‡‡æ ·é—®é¢˜ï¼Œé€šè¿‡ä»è¿è¡Œå†å²ä¸­å­¦ä¹ è´Ÿè·ä¸è°ƒåº¦å†³ç­–ç‚¹çš„è”åˆåˆ†å¸ƒï¼Œåœ¨ç»™å®šè´Ÿè·æ¡ä»¶ä¸‹ç”Ÿæˆè¾¹ç¼˜è°ƒåº¦åˆ†å¸ƒã€‚ä¸ä¼ ç»Ÿçš„å•å€¼æ±‚è§£å™¨ä¸åŒï¼ŒDiffOPF èƒ½å¤Ÿé‡‡æ ·å‡ºç»Ÿè®¡å¯é çš„çƒ­å¯åŠ¨ (warm starts) ç‚¹ï¼Œå¹¶åœ¨è¿è¡Œæˆæœ¬ä¸çº¦æŸæ»¡è¶³ (constraint satisfaction) ä¹‹é—´å®ç°è‰¯å¥½çš„æƒè¡¡ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ¢è®¨äº†ç¡®ä¿é‡‡æ ·ç»“æœåœ¨è§„å®šè·ç¦»å†…æ¥è¿‘ä¼˜åŒ–è§£çš„æ ·æœ¬å¤æ‚åº¦ (sample complexity)ï¼Œå¹¶åœ¨ç”µåŠ›ç³»ç»ŸåŸºå‡†æµ‹è¯•ä¸Šé€šè¿‡å®éªŒéªŒè¯äº† DiffOPF çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "eess.SY",
      "comment": "7 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.14075v1",
      "published_date": "2025-10-15 20:32:48 UTC",
      "updated_date": "2025-10-15 20:32:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:32:58.970524+00:00"
    },
    {
      "arxiv_id": "2510.14073v2",
      "title": "Exploratory Causal Inference in SAEnce",
      "title_zh": "SAEnce ä¸­çš„æ¢ç´¢æ€§å› æœæ¨æ–­",
      "authors": [
        "Tommaso Mencattini",
        "Riccardo Cadei",
        "Francesco Locatello"
      ],
      "abstract": "Randomized Controlled Trials are one of the pillars of science; nevertheless, they rely on hand-crafted hypotheses and expensive analysis. Such constraints prevent causal effect estimation at scale, potentially anchoring on popular yet incomplete hypotheses. We propose to discover the unknown effects of a treatment directly from data. For this, we turn unstructured data from a trial into meaningful representations via pretrained foundation models and interpret them via a sparse autoencoder. However, discovering significant causal effects at the neural level is not trivial due to multiple-testing issues and effects entanglement. To address these challenges, we introduce Neural Effect Search, a novel recursive procedure solving both issues by progressive stratification. After assessing the robustness of our algorithm on semi-synthetic experiments, we showcase, in the context of experimental ecology, the first successful unsupervised causal effect identification on a real-world scientific trial.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éšæœºå¯¹ç…§è¯•éªŒ (Randomized Controlled Trials) ä¾èµ–äººå·¥å‡è®¾å’Œåˆ†ææˆæœ¬é«˜æ˜‚ä»è€Œéš¾ä»¥åœ¨å¤§è§„æ¨¡æ•°æ®ä¸­ä¼°ç®—å› æœæ•ˆåº”çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç›´æ¥ä»æ•°æ®ä¸­å‘ç°æœªçŸ¥å¤„ç†æ•ˆåº”çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶åˆ©ç”¨é¢„è®­ç»ƒçš„åŸºç¡€æ¨¡å‹ (Foundation Models) å°†è¯•éªŒä¸­çš„éç»“æ„åŒ–æ•°æ®è½¬åŒ–ä¸ºç‰¹å¾è¡¨å¾ï¼Œå¹¶ç»“åˆç¨€ç–è‡ªç¼–ç å™¨ (Sparse Autoencoder) è¿›è¡Œè§£é‡Šã€‚ä¸ºè§£å†³ç¥ç»å±‚çº§å› æœæ•ˆåº”å‘ç°ä¸­é¢ä¸´çš„å¤šé‡æ£€éªŒå’Œæ•ˆåº”çº ç¼ é—®é¢˜ï¼Œç ”ç©¶æå‡ºäº† Neural Effect Search é€’å½’ç¨‹åºï¼Œé€šè¿‡æ¸è¿›å¼åˆ†å±‚ (Progressive Stratification) ç­–ç•¥æå‡äº†è¯†åˆ«ç²¾åº¦ã€‚å®éªŒåœ¨åŠåˆæˆæ•°æ®é›†ä¸ŠéªŒè¯äº†ç®—æ³•çš„ç¨³å¥æ€§ï¼Œå¹¶æˆåŠŸåœ¨å®éªŒç”Ÿæ€å­¦çš„çœŸå®ç§‘å­¦è¯•éªŒä¸­å®ç°äº†é¦–æ¬¡æ— ç›‘ç£å› æœæ•ˆåº”è¯†åˆ«ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14073v2",
      "published_date": "2025-10-15 20:30:54 UTC",
      "updated_date": "2026-01-06 00:17:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:01.480050+00:00"
    },
    {
      "arxiv_id": "2510.14068v1",
      "title": "On the expressivity of sparse maxout networks",
      "title_zh": "è®ºç¨€ç– Maxout ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›",
      "authors": [
        "Moritz Grillo",
        "Tobias Hofmann"
      ],
      "abstract": "We study the expressivity of sparse maxout networks, where each neuron takes a fixed number of inputs from the previous layer and employs a, possibly multi-argument, maxout activation. This setting captures key characteristics of convolutional or graph neural networks. We establish a duality between functions computable by such networks and a class of virtual polytopes, linking their geometry to questions of network expressivity. In particular, we derive a tight bound on the dimension of the associated polytopes, which serves as the central tool for our analysis. Building on this, we construct a sequence of depth hierarchies. While sufficiently deep sparse maxout networks are universal, we prove that if the required depth is not reached, width alone cannot compensate for the sparsity of a fixed indegree constraint.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¨€ç– Maxout ç½‘ç»œ (sparse maxout networks) çš„è¡¨è¾¾èƒ½åŠ›ï¼Œè¿™ç±»ç½‘ç»œé€šè¿‡å›ºå®šå…¥åº¦çš„ç¥ç»å…ƒå’Œå¤šå‚æ•° Maxout æ¿€æ´»å‡½æ•°æ¨¡æ‹Ÿå·ç§¯ç¥ç»ç½‘ç»œ (CNNs) æˆ–å›¾ç¥ç»ç½‘ç»œ (GNNs) çš„æ ¸å¿ƒç‰¹æ€§ã€‚ä½œè€…åœ¨è¿™äº›ç½‘ç»œå¯è®¡ç®—çš„å‡½æ•°ä¸ä¸€ç±»è™šå¤šèƒå½¢ (virtual polytopes) ä¹‹é—´å»ºç«‹äº†å¯¹å¶å…³ç³»ï¼Œå¹¶æ¨å¯¼å‡ºç›¸å…³å¤šèƒå½¢ç»´åº¦çš„ç´§ç•Œ (tight bound) ä½œä¸ºåˆ†æçš„æ ¸å¿ƒå·¥å…·ã€‚ç ”ç©¶é€šè¿‡æ„å»ºä¸€ç³»åˆ—æ·±åº¦å±‚çº§ç»“æ„ (depth hierarchies) è¯æ˜ï¼Œè™½ç„¶æ·±åº¦è¶³å¤Ÿçš„ç¨€ç– Maxout ç½‘ç»œå…·æœ‰é€šç”¨æ€§ (universal)ï¼Œä½†åœ¨æ·±åº¦å—é™çš„æƒ…å†µä¸‹ï¼Œå•çº¯å¢åŠ å®½åº¦å¹¶ä¸èƒ½è¡¥å¿ç”±äºå›ºå®šå…¥åº¦çº¦æŸæ‰€å¸¦æ¥çš„ç¨€ç–æ€§ã€‚è¿™ä¸€ç»“è®ºæ­ç¤ºäº†ç¨€ç–ç¥ç»ç½‘ç»œä¸­æ·±åº¦ä¸å®½åº¦åœ¨è¡¨è¾¾èƒ½åŠ›ä¸Šçš„æœ¬è´¨å·®å¼‚ï¼Œä¸ºç†è§£å‡ ä½•ç‰¹å¾ä¸ç½‘ç»œè¡¨è¾¾èƒ½åŠ›ä¹‹é—´çš„è”ç³»æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14068v1",
      "published_date": "2025-10-15 20:18:18 UTC",
      "updated_date": "2025-10-15 20:18:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:04.588957+00:00"
    },
    {
      "arxiv_id": "2510.14058v1",
      "title": "Optical Computation-in-Communication enables low-latency, high-fidelity perception in telesurgery",
      "title_zh": "å…‰å­¦ç®—é€šèåˆåŠ©åŠ›è¿œç¨‹æ‰‹æœ¯å®ç°ä½å»¶è¿Ÿã€é«˜ä¿çœŸæ„ŸçŸ¥",
      "authors": [
        "Rui Yang",
        "Jiaming Hu",
        "Jian-Qing Zheng",
        "Yue-Zhen Lu",
        "Jian-Wei Cui",
        "Qun Ren",
        "Yi-Jie Yu",
        "John Edward Wu",
        "Zhao-Yu Wang",
        "Xiao-Li Lin",
        "Dandan Zhang",
        "Mingchu Tang",
        "Christos Masouros",
        "Huiyun Liu",
        "Chin-Pang Liu"
      ],
      "abstract": "Artificial intelligence (AI) holds significant promise for enhancing intraoperative perception and decision-making in telesurgery, where physical separation impairs sensory feedback and control. Despite advances in medical AI and surgical robotics, conventional electronic AI architectures remain fundamentally constrained by the compounded latency from serial processing of inference and communication. This limitation is especially critical in latency-sensitive procedures such as endovascular interventions, where delays over 200 ms can compromise real-time AI reliability and patient safety. Here, we introduce an Optical Computation-in-Communication (OCiC) framework that reduces end-to-end latency significantly by performing AI inference concurrently with optical communication. OCiC integrates Optical Remote Computing Units (ORCUs) directly into the optical communication pathway, with each ORCU experimentally achieving up to 69 tera-operations per second per channel through spectrally efficient two-dimensional photonic convolution. The system maintains ultrahigh inference fidelity within 0.1% of CPU/GPU baselines on classification and coronary angiography segmentation, while intrinsically mitigating cumulative error propagation, a longstanding barrier to deep optical network scalability. We validated the robustness of OCiC through outdoor dark fibre deployments, confirming consistent and stable performance across varying environmental conditions. When scaled globally, OCiC transforms long-haul fibre infrastructure into a distributed photonic AI fabric with exascale potential, enabling reliable, low-latency telesurgery across distances up to 10,000 km and opening a new optical frontier for distributed medical intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿œç¨‹æ‰‹æœ¯(telesurgery)ä¸­ä¼ ç»Ÿç”µå­AIæ¶æ„å› æ¨ç†ä¸é€šä¿¡ä¸²è¡Œå¤„ç†å¯¼è‡´çš„å»¶è¿Ÿç“¶é¢ˆï¼Œæå‡ºäº†ä¸€ç§é€šä¿¡ä¸­å…‰è®¡ç®—(Optical Computation-in-Communication, OCiC)æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨å…‰é€šä¿¡è·¯å¾„ä¸­ç›´æ¥é›†æˆå…‰è¿œç¨‹è®¡ç®—å•å…ƒ(Optical Remote Computing Units, ORCUs)ï¼Œåˆ©ç”¨å…‰è°±é«˜æ•ˆçš„äºŒç»´å…‰å­å·ç§¯(photonic convolution)æŠ€æœ¯å®ç°äº†æ¨ç†ä¸é€šä¿¡çš„åŒæ­¥æ‰§è¡Œã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOCiCåœ¨åˆ†ç±»å’Œå† çŠ¶åŠ¨è„‰é€ å½±åˆ†å‰²ä»»åŠ¡ä¸Šè¾¾åˆ°äº†ä¸CPU/GPUåŸºå‡†è¯¯å·®åœ¨0.1%ä»¥å†…çš„é«˜ä¿çœŸåº¦ï¼Œä¸”å•é€šé“ç®—åŠ›é«˜è¾¾69 TOPSã€‚é€šè¿‡æˆ·å¤–æš—å…‰çº¤(dark fibre)éƒ¨ç½²éªŒè¯ï¼Œè¯¥ç³»ç»ŸæˆåŠŸå…‹æœäº†æ·±å±‚å…‰ç½‘ç»œæ‰©å±•ä¸­çš„ç´¯ç§¯è¯¯å·®ä¼ æ’­é—®é¢˜ï¼Œèƒ½å¤Ÿåœ¨é•¿è¾¾10,000å…¬é‡Œçš„è·¨åº¦å†…ç»´æŒæä½å»¶è¿Ÿã€‚è¿™ä¸€åˆ›æ–°å°†é•¿é€”å…‰çº¤åŸºç¡€è®¾æ–½è½¬åŒ–ä¸ºåˆ†å¸ƒå¼å…‰å­AIæ¶æ„ï¼Œä¸ºå®ç°å…¨çƒèŒƒå›´å†…çš„å®æ—¶æ„ŸçŸ¥ä¸é«˜å¯é è¿œç¨‹æ‰‹æœ¯è¾…åŠ©å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14058v1",
      "published_date": "2025-10-15 19:54:11 UTC",
      "updated_date": "2025-10-15 19:54:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:17.994814+00:00"
    },
    {
      "arxiv_id": "2510.14053v1",
      "title": "Position: Require Frontier AI Labs To Release Small \"Analog\" Models",
      "title_zh": "è§‚ç‚¹ï¼šè¦æ±‚å‰æ²¿äººå·¥æ™ºèƒ½å®éªŒå®¤å‘å¸ƒå°å‹â€œç±»æ¯”â€æ¨¡å‹",
      "authors": [
        "Shriyash Upadhyay",
        "Chaithanya Bandi",
        "Narmeen Oozeer",
        "Philip Quirke"
      ],
      "abstract": "Recent proposals for regulating frontier AI models have sparked concerns about the cost of safety regulation, and most such regulations have been shelved due to the safety-innovation tradeoff. This paper argues for an alternative regulatory approach that ensures AI safety while actively promoting innovation: mandating that large AI laboratories release small, openly accessible analog models (scaled-down versions) trained similarly to and distilled from their largest proprietary models.\n  Analog models serve as public proxies, allowing broad participation in safety verification, interpretability research, and algorithmic transparency without forcing labs to disclose their full-scale models. Recent research demonstrates that safety and interpretability methods developed using these smaller models generalize effectively to frontier-scale systems. By enabling the wider research community to directly investigate and innovate upon accessible analogs, our policy substantially reduces the regulatory burden and accelerates safety advancements.\n  This mandate promises minimal additional costs, leveraging reusable resources like data and infrastructure, while significantly contributing to the public good. Our hope is not only that this policy be adopted, but that it illustrates a broader principle supporting fundamental research in machine learning: deeper understanding of models relaxes the safety-innovation tradeoff and lets us have more of both.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‰æ²¿ AI æ¨¡å‹ç›‘ç®¡ä¸­å®‰å…¨ä¸åˆ›æ–°æƒè¡¡(Safety-Innovation Tradeoff)çš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ›¿ä»£æ€§çš„ç›‘ç®¡æ–¹æ¡ˆï¼Œå³è¦æ±‚å¤§å‹å®éªŒå®¤å‘å¸ƒä¸å…¶ä¸“æœ‰å¤§æ¨¡å‹è®­ç»ƒæ–¹å¼ç›¸ä¼¼ä¸”ç»è¿‡è’¸é¦çš„å°å‹å¼€æºâ€œæ¨¡æ‹Ÿæ¨¡å‹â€(Analog Models)ã€‚è¿™äº›æ¨¡æ‹Ÿæ¨¡å‹ä½œä¸ºå…¬å…±ä»£ç†ï¼Œèƒ½å¤Ÿåœ¨ä¸å¼ºåˆ¶æŠ«éœ²å…¨è§„æ¨¡æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œå…è®¸æ›´å¹¿æ³›çš„ç¾¤ä½“å‚ä¸å®‰å…¨éªŒè¯ã€å¯è§£é‡Šæ€§ç ”ç©¶(Interpretability Research)å’Œç®—æ³•é€æ˜åº¦å·¥ä½œã€‚ç ”ç©¶è¡¨æ˜ï¼Œåœ¨å°å‹æ¨¡å‹ä¸Šå¼€å‘çš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆæ¨å¹¿åˆ°å‰æ²¿è§„æ¨¡(Frontier-Scale)ç³»ç»Ÿã€‚è¯¥æ”¿ç­–åˆ©ç”¨ç°æœ‰çš„æ•°æ®å’ŒåŸºç¡€è®¾æ–½ï¼Œä»¥æä½çš„é¢å¤–æˆæœ¬æ”¯æŒåŸºç¡€ç ”ç©¶ï¼Œä»è€Œåœ¨å‡è½»ç›‘ç®¡è´Ÿæ‹…çš„åŒæ—¶åŠ é€Ÿå®‰å…¨æŠ€æœ¯çš„è¿›æ­¥ã€‚é€šè¿‡åŠ æ·±å¯¹æ¨¡å‹çš„ç†è§£ï¼Œè¯¥æ–¹æ¡ˆæ—¨åœ¨ç¼“è§£å®‰å…¨ä¸åˆ›æ–°ä¹‹é—´çš„çŸ›ç›¾ï¼Œä¸ºæœºå™¨å­¦ä¹ é¢†åŸŸçš„å…¬å…±åˆ©ç›Šå’ŒåŸºç¡€ç ”ç©¶æä¾›æ”¯æŒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14053v1",
      "published_date": "2025-10-15 19:47:49 UTC",
      "updated_date": "2025-10-15 19:47:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:19.539826+00:00"
    },
    {
      "arxiv_id": "2510.14043v1",
      "title": "Cyber-Resilient System Identification for Power Grid through Bayesian Integration",
      "title_zh": "åŸºäºè´å¶æ–¯é›†æˆçš„ç”µç½‘ç½‘ç»œéŸ§æ€§ç³»ç»Ÿè¾¨è¯†",
      "authors": [
        "Shimiao Li",
        "Guannan Qu",
        "Bryan Hooi",
        "Vyas Sekar",
        "Soummya Kar",
        "Larry Pileggi"
      ],
      "abstract": "Power grids increasingly need real-time situational awareness under the ever-evolving cyberthreat landscape. Advances in snapshot-based system identification approaches have enabled accurately estimating states and topology from a snapshot of measurement data, under random bad data and topology errors. However, modern interactive, targeted false data can stay undetectable to these methods, and significantly compromise estimation accuracy. This work advances system identification that combines snapshot-based method with time-series model via Bayesian Integration, to advance cyber resiliency against both random and targeted false data. Using a distance-based time-series model, this work can leverage historical data of different distributions induced by changes in grid topology and other settings. The normal system behavior captured from historical data is integrated into system identification through a Bayesian treatment, to make solutions robust to targeted false data. We experiment on mixed random anomalies (bad data, topology error) and targeted false data injection attack (FDIA) to demonstrate our method's 1) cyber resilience: achieving over 70% reduction in estimation error under FDIA; 2) anomalous data identification: being able to alarm and locate anomalous data; 3) almost linear scalability: achieving comparable speed with the snapshot-based baseline, both taking <1min per time tick on the large 2,383-bus system using a laptop CPU.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µç½‘åœ¨ä¸æ–­æ¼”åŒ–çš„ç½‘ç»œå¨èƒä¸‹å¯¹å®æ—¶æ€åŠ¿æ„ŸçŸ¥çš„éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§é€šè¿‡ Bayesian Integration å®ç°çš„ç½‘ç»œå¼¹æ€§ç³»ç»Ÿè¾¨è¯†æ–¹æ³•ã€‚è¯¥å·¥ä½œå°†ä¼ ç»Ÿçš„ snapshot-based æ–¹æ³•ä¸åŸºäºè·ç¦»çš„ time-series æ¨¡å‹ç›¸ç»“åˆï¼Œåˆ©ç”¨å†å²æ•°æ®ä¸­æå–çš„æ­£å¸¸ç³»ç»Ÿè¡Œä¸ºï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿå¯¹éšæœºå¼‚å¸¸å’Œé’ˆå¯¹æ€§è™šå‡æ•°æ®æ³¨å…¥æ”»å‡» (FDIA) çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ FDIA æ”»å‡»ä¸‹èƒ½å‡å°‘ 70% ä»¥ä¸Šçš„ä¼°è®¡è¯¯å·®ï¼Œå¹¶èƒ½å¤Ÿæœ‰æ•ˆæŠ¥è­¦å¹¶å®šä½å¼‚å¸¸æ•°æ®ã€‚è¯¥ç®—æ³•è¡¨ç°å‡ºè¿‘ä¼¼çš„ linear scalabilityï¼Œåœ¨å¤„ç†æ‹¥æœ‰ 2,383 ä¸ªèŠ‚ç‚¹çš„ç”µåŠ›ç³»ç»Ÿæ—¶è®¡ç®—æ—¶é—´ä¸åˆ° 1 åˆ†é’Ÿï¼Œè¯æ˜äº†å…¶åœ¨å¤§è§„æ¨¡å®æ—¶åœºæ™¯ä¸‹çš„é«˜æ•ˆæ€§ä¸åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14043v1",
      "published_date": "2025-10-15 19:32:09 UTC",
      "updated_date": "2025-10-15 19:32:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:25.094405+00:00"
    },
    {
      "arxiv_id": "2510.14036v1",
      "title": "One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery",
      "title_zh": "ä¸€ä¸ªæ¼æ´ï¼Œç™¾ä¸ªæ½œè—ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤§è§„æ¨¡æ¼æ´å‘ç°",
      "authors": [
        "Qiushi Wu",
        "Yue Xiao",
        "Dhilung Kirat",
        "Kevin Eykholt",
        "Jiyong Jang",
        "Douglas Lee Schales"
      ],
      "abstract": "Fixing bugs in large programs is a challenging task that demands substantial time and effort. Once a bug is found, it is reported to the project maintainers, who work with the reporter to fix it and eventually close the issue. However, across the program, there are often similar code segments, which may also contain the bug, but were missed during discovery. Finding and fixing each recurring bug instance individually is labor intensive. Even more concerning, bug reports can inadvertently widen the attack surface as they provide attackers with an exploitable pattern that may be unresolved in other parts of the program.\n  In this paper, we explore these Recurring Pattern Bugs (RPBs) that appear repeatedly across various code segments of a program or even in different programs, stemming from a same root cause, but are unresolved. Our investigation reveals that RPBs are widespread and can significantly compromise the security of software programs. This paper introduces BugStone, a program analysis system empowered by LLVM and a Large Language Model (LLM). The key observation is that many RPBs have one patched instance, which can be leveraged to identify a consistent error pattern, such as a specific API misuse. By examining the entire program for this pattern, it is possible to identify similar sections of code that may be vulnerable. Starting with 135 unique RPBs, BugStone identified more than 22K new potential issues in the Linux kernel. Manual analysis of 400 of these findings confirmed that 246 were valid. We also created a dataset from over 1.9K security bugs reported by 23 recent top-tier conference works. We manually annotate the dataset, identify 80 recurring patterns and 850 corresponding fixes. Even with a cost-efficient model choice, BugStone achieved 92.2% precision and 79.1% pairwise accuracy on the dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹ç¨‹åºä¸­ä¿®å¤ Bug è€—æ—¶è€—åŠ›ä¸”ç›¸ä¼¼ä»£ç æ®µä¸­å¸¸éšè—é‡å¤æ€§æ¨¡å¼æ¼æ´(Recurring Pattern Bugs, RPBs)çš„é—®é¢˜å±•å¼€è°ƒæŸ¥ã€‚ç ”ç©¶å‘ç° RPBs å¹¿æ³›å­˜åœ¨ä¸”æ˜¾è‘—å¨èƒè½¯ä»¶å®‰å…¨ï¼Œè€Œç°æœ‰çš„è¡¥ä¸å®ä¾‹å¾€å¾€èƒ½æ­ç¤ºä¸€è‡´çš„é”™è¯¯æ¨¡å¼ï¼Œä¾‹å¦‚ç‰¹å®šçš„ API misuseã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº† BugStoneï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆ LLVM å’Œå¤§è¯­è¨€æ¨¡å‹(LLM)çš„ç¨‹åºåˆ†æç³»ç»Ÿï¼Œæ—¨åœ¨åˆ©ç”¨å·²ä¿®å¤çš„æ¼æ´å®ä¾‹åœ¨å¤§è§„æ¨¡ä»£ç ä¸­è‡ªåŠ¨è¯†åˆ«ç›¸ä¼¼çš„å®‰å…¨éšæ‚£ã€‚é€šè¿‡å¯¹ 135 ä¸ªç‹¬ç‰¹çš„ RPBs è¿›è¡Œåˆ†æï¼ŒBugStone åœ¨ Linux kernel ä¸­è¯†åˆ«å‡ºè¶…è¿‡ 22,000 ä¸ªæ½œåœ¨é—®é¢˜ï¼Œç»äººå·¥æŠ½æ ·éªŒè¯ç¡®è®¤äº†å…¶ä¸­ 246 ä¸ªä¸ºæœ‰æ•ˆæ¼æ´ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æ„å»ºäº†ä¸€ä¸ªåŒ…å« 1,900 å¤šä¸ªå®‰å…¨æ¼æ´çš„æ•°æ®é›†ï¼Œå¹¶æ‰‹åŠ¨æ ‡æ³¨äº† 80 ä¸ªé‡å¤æ¨¡å¼åŠå…¶å¯¹åº”çš„ 850 ä¸ªä¿®å¤æ–¹æ¡ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿é‡‡ç”¨é«˜æ€§ä»·æ¯”çš„æ¨¡å‹ï¼ŒBugStone åœ¨è¯¥æ•°æ®é›†ä¸Šä»å®ç°äº† 92.2% çš„ Precision å’Œ 79.1% çš„æˆå¯¹å‡†ç¡®ç‡(pairwise accuracy)ï¼Œè¯æ˜äº†å…¶åœ¨å¤§è§„æ¨¡æ¼æ´å‘ç°ä¸­çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14036v1",
      "published_date": "2025-10-15 19:18:06 UTC",
      "updated_date": "2025-10-15 19:18:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:37.585668+00:00"
    },
    {
      "arxiv_id": "2510.14035v1",
      "title": "GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations",
      "title_zh": "GammaZeroï¼šåˆ©ç”¨å›¾è¡¨ç¤ºå­¦ä¹ å¼•å¯¼ POMDP ä¿¡å¿µç©ºé—´æœç´¢",
      "authors": [
        "Rajesh Mangannavar",
        "Prasad Tadepalli"
      ],
      "abstract": "We introduce an action-centric graph representation framework for learning to guide planning in Partially Observable Markov Decision Processes (POMDPs). Unlike existing approaches that require domain-specific neural architectures and struggle with scalability, GammaZero leverages a unified graph-based belief representation that enables generalization across problem sizes within a domain. Our key insight is that belief states can be systematically transformed into action-centric graphs where structural patterns learned on small problems transfer to larger instances. We employ a graph neural network with a decoder architecture to learn value functions and policies from expert demonstrations on computationally tractable problems, then apply these learned heuristics to guide Monte Carlo tree search on larger problems. Experimental results on standard POMDP benchmarks demonstrate that GammaZero achieves comparable performance to BetaZero when trained and tested on the same-sized problems, while uniquely enabling zero-shot generalization to problems 2-4 times larger than those seen during training, maintaining solution quality with reduced search requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GammaZeroï¼Œè¿™æ˜¯ä¸€ä¸ªä»¥åŠ¨ä½œä¸ºä¸­å¿ƒçš„å›¾è¡¨ç¤º (action-centric graph representation) æ¡†æ¶ï¼Œæ—¨åœ¨å¼•å¯¼éƒ¨åˆ†å¯è§‚æµ‹é©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (POMDPs) ä¸­çš„è§„åˆ’æœç´¢ã€‚ä¸åŒäºä¾èµ–é¢†åŸŸç‰¹å®šæ¶æ„ä¸”éš¾ä»¥æ‰©å±•çš„ç°æœ‰æ–¹æ³•ï¼ŒGammaZero é€šè¿‡å°†ä¿¡å¿µçŠ¶æ€ (belief states) ç³»ç»Ÿåœ°è½¬æ¢ä¸ºå›¾ç»“æ„ï¼Œä½¿å¾—åœ¨å°è§„æ¨¡é—®é¢˜ä¸Šå­¦ä¹ åˆ°çš„ç»“æ„æ¨¡å¼èƒ½å¤Ÿæœ‰æ•ˆè¿ç§»è‡³æ›´å¤§è§„æ¨¡çš„å®ä¾‹ã€‚è¯¥æ¡†æ¶åˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ (GNN) é…åˆè§£ç å™¨æ¶æ„ä»ä¸“å®¶æ¼”ç¤ºä¸­å­¦ä¹ ä»·å€¼å‡½æ•°å’Œç­–ç•¥ï¼Œå¹¶å°†å…¶ä½œä¸ºå¯å‘å¼ä¿¡æ¯å¼•å¯¼è’™ç‰¹å¡æ´›æ ‘æœç´¢ (Monte Carlo tree search)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGammaZero åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†ä¸ BetaZero ç›¸å½“çš„æ€§èƒ½ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„é›¶æ ·æœ¬æ³›åŒ– (zero-shot generalization) èƒ½åŠ›ã€‚å®ƒèƒ½å¤Ÿç›´æ¥åº”ç”¨äºè§„æ¨¡æ¯”è®­ç»ƒé›†å¤§ 2 åˆ° 4 å€çš„é—®é¢˜ï¼Œåœ¨æ˜¾è‘—å‡å°‘æœç´¢éœ€æ±‚çš„åŒæ—¶ä¿æŒäº†é«˜è´¨é‡çš„å†³ç­–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages content. 2 pages references",
      "pdf_url": "https://arxiv.org/pdf/2510.14035v1",
      "published_date": "2025-10-15 19:18:03 UTC",
      "updated_date": "2025-10-15 19:18:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:27.983515+00:00"
    },
    {
      "arxiv_id": "2510.14030v1",
      "title": "Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games",
      "title_zh": "å…¨å±€æ€è€ƒï¼Œå±€éƒ¨æˆç»„ï¼šåˆ©ç”¨å¤šè¯­è¨€è¯è¯­åˆ†ç»„æ¸¸æˆè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "CÃ©sar Guerra-Solano",
        "Zhuochun Li",
        "Xiang Lorraine Li"
      ],
      "abstract": "Large language models (LLMs) can exhibit biases in reasoning capabilities due to linguistic modality, performing better on tasks in one language versus another, even with similar content. Most previous works evaluate this through reasoning tasks where reliance on strategies or knowledge can ensure success, such as in commonsense or math tasks. However, abstract reasoning is vital to reasoning for everyday life, where people apply \"out-of-the-box thinking\" to identify and use patterns for solutions, without a reliance on formulaic approaches. Comparatively, little work has evaluated linguistic biases in this task type. In this paper, we propose a task inspired by the New York Times Connections: GlobalGroup, that evaluates models in an abstract reasoning task across several languages. We constructed a game benchmark with five linguistic backgrounds -- English, Spanish, Chinese, Hindi, and Arabic -- in both the native language and an English translation for comparison. We also proposed game difficulty measurements to evaluate models on games with similar difficulty, enabling a more controlled comparison, which is particularly important in reasoning evaluations. Through experimentation, we find English modalities largely lead to better performance in this abstract reasoning task, and performance disparities between open- and closed-source models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸åŒè¯­è¨€æ¨¡æ€ä¸‹çš„æ¨ç†èƒ½åŠ›åå·®ï¼ŒæŒ‡å‡ºç›®å‰è¯„ä¼°å¤šé›†ä¸­åœ¨ä¾èµ–çŸ¥è¯†æˆ–å…¬å¼çš„ä»»åŠ¡ï¼Œè€Œå¿½è§†äº†æ—¥å¸¸ç”Ÿæ´»ä¸­è‡³å…³é‡è¦çš„æŠ½è±¡æ¨ç†ï¼ˆAbstract Reasoningï¼‰èƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…å—ã€Šçº½çº¦æ—¶æŠ¥ã€‹Connectionsæ¸¸æˆçš„å¯å‘ï¼Œæå‡ºäº†åä¸º GlobalGroup çš„åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨å¤šç§è¯­è¨€ç¯å¢ƒä¸‹çš„æŠ½è±¡æ¨ç†è¡¨ç°ã€‚è¯¥åŸºå‡†æ¶µç›–äº†è‹±è¯­ã€è¥¿ç­ç‰™è¯­ã€ä¸­æ–‡ã€å°åœ°è¯­å’Œé˜¿æ‹‰ä¼¯è¯­ï¼Œå¹¶æä¾›åŸç”Ÿè¯­è¨€åŠå…¶è‹±æ–‡ç¿»è¯‘ç‰ˆæœ¬ä»¥è¿›è¡Œå—æ§å¯¹æ¯”ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†æ¸¸æˆéš¾åº¦åº¦é‡æ ‡å‡†ï¼Œä»¥ç¡®ä¿åœ¨ç›¸ä¼¼éš¾åº¦æ°´å¹³ä¸‹å¯¹æ¨¡å‹è¿›è¡Œæ›´ç²¾ç¡®çš„æ¯”è¾ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè‹±è¯­æ¨¡æ€åœ¨æŠ½è±¡æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜æ˜¾çš„ä¼˜åŠ¿ï¼Œä¸”å¼€æºä¸é—­æºæ¨¡å‹ä¹‹é—´åœ¨å¤„ç†æ­¤ç±»ä»»åŠ¡æ—¶å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Main 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.14030v1",
      "published_date": "2025-10-15 19:12:43 UTC",
      "updated_date": "2025-10-15 19:12:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:31.588849+00:00"
    },
    {
      "arxiv_id": "2510.14027v1",
      "title": "Context-Selective State Space Models: Feedback is All You Need",
      "title_zh": "ä¸Šä¸‹æ–‡é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼šåé¦ˆå³æ‰€éœ€",
      "authors": [
        "Riccardo Zattra",
        "Giacomo Baggio",
        "Umberto Casti",
        "Augusto Ferrante",
        "Francesco Ticozzi"
      ],
      "abstract": "Transformers, powered by the attention mechanism, are the backbone of most foundation models, yet they suffer from quadratic complexity and difficulties in dealing with long-range dependencies in the input sequence. Recent work has shown that state space models (SSMs) provide an efficient alternative, with the S6 module at the core of the Mamba architecture achieving state-of-the-art results on long-sequence benchmarks. In this paper, we introduce the COFFEE (COntext From FEEdback) model, a novel time-varying SSM that incorporates state feedback to enable context-dependent selectivity, while still allowing for parallel implementation. Whereas the selectivity mechanism of S6 only depends on the current input, COFFEE computes it from the internal state, which serves as a compact representation of the sequence history. This shift allows the model to regulate its dynamics based on accumulated context, improving its ability to capture long-range dependencies. In addition to state feedback, we employ an efficient model parametrization that removes redundancies present in S6 and leads to a more compact and trainable formulation. On the induction head task, COFFEE achieves near-perfect accuracy with two orders of magnitude fewer parameters and training sequences compared to S6. On MNIST, COFFEE largely outperforms S6 within the same architecture, reaching 97% accuracy with only 3585 parameters. These results showcase the role of state feedback as a key mechanism for building scalable and efficient sequence models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†COFFEE (COntext From FEEdback)æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„æ—¶å˜çŠ¶æ€ç©ºé—´æ¨¡å‹(State Space Models)ï¼Œæ—¨åœ¨é€šè¿‡å¼•å…¥çŠ¶æ€åé¦ˆæœºåˆ¶å®ç°ä¸Šä¸‹æ–‡ä¾èµ–çš„é€‰æ‹©æ€§ã€‚ä¸ä»…ä¾èµ–å½“å‰è¾“å…¥çš„S6æ¨¡å—ä¸åŒï¼ŒCOFFEEåˆ©ç”¨åæ˜ åºåˆ—å†å²çš„å†…éƒ¨çŠ¶æ€æ¥è®¡ç®—é€‰æ‹©æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®ç´¯ç§¯ä¸Šä¸‹æ–‡è°ƒèŠ‚æ¨¡å‹åŠ¨åŠ›å­¦ï¼Œä»è€Œå¢å¼ºæ•è·é•¿ç¨‹ä¾èµ–çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§é«˜æ•ˆçš„å‚æ•°åŒ–æ–¹æ¡ˆï¼Œæ¶ˆé™¤äº†S6ä¸­å­˜åœ¨çš„å†—ä½™ï¼Œä½¿æ¨¡å‹æ›´åŠ ç´§å‡‘ä¸”æ˜“äºè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨induction headä»»åŠ¡ä¸­ï¼ŒCOFFEEä»¥æ¯”S6å°‘ä¸¤ä¸ªæ•°é‡çº§çš„å‚æ•°å’Œè®­ç»ƒåºåˆ—å®ç°äº†è¿‘ä¹å®Œç¾çš„å‡†ç¡®ç‡ã€‚åœ¨MNISTæ•°æ®é›†ä¸Šï¼ŒCOFFEEä»…é€šè¿‡3585ä¸ªå‚æ•°ä¾¿è¾¾åˆ°äº†97%çš„å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºç›¸åŒæ¶æ„ä¸‹çš„S6æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†çŠ¶æ€åé¦ˆæ˜¯æ„å»ºå¯æ‰©å±•ä¸”é«˜æ•ˆåºåˆ—æ¨¡å‹çš„å…³é”®æœºåˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14027v1",
      "published_date": "2025-10-15 19:08:28 UTC",
      "updated_date": "2025-10-15 19:08:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:35.383765+00:00"
    },
    {
      "arxiv_id": "2510.16024v1",
      "title": "On-Chain Decentralized Learning and Cost-Effective Inference for DeFi Attack Mitigation",
      "title_zh": "é¢å‘ DeFi æ”»å‡»ç¼“è§£çš„é“¾ä¸Šå»ä¸­å¿ƒåŒ–å­¦ä¹ ä¸ä½æˆæœ¬æ¨ç†",
      "authors": [
        "Abdulrahman Alhaidari",
        "Balaji Palanisamy",
        "Prashant Krishnamurthy"
      ],
      "abstract": "Billions of dollars are lost every year in DeFi platforms by transactions exploiting business logic or accounting vulnerabilities. Existing defenses focus on static code analysis, public mempool screening, attacker contract detection, or trusted off-chain monitors, none of which prevents exploits submitted through private relays or malicious contracts that execute within the same block. We present the first decentralized, fully on-chain learning framework that: (i) performs gas-prohibitive computation on Layer-2 to reduce cost, (ii) propagates verified model updates to Layer-1, and (iii) enables gas-bounded, low-latency inference inside smart contracts. A novel Proof-of-Improvement (PoIm) protocol governs the training process and verifies each decentralized micro update as a self-verifying training transaction. Updates are accepted by \\textit{PoIm} only if they demonstrably improve at least one core metric (e.g., accuracy, F1-score, precision, or recall) on a public benchmark without degrading any of the other core metrics, while adversarial proposals get financially penalized through an adaptable test set for evolving threats. We develop quantization and loop-unrolling techniques that enable inference for logistic regression, SVM, MLPs, CNNs, and gated RNNs (with support for formally verified decision tree inference) within the Ethereum block gas limit, while remaining bit-exact to their off-chain counterparts, formally proven in Z3. We curate 298 unique real-world exploits (2020 - 2025) with 402 exploit transactions across eight EVM chains, collectively responsible for \\$3.74 B in losses.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹DeFiå¹³å°å› ä¸šåŠ¡é€»è¾‘æˆ–ä¼šè®¡æ¼æ´é¢ä¸´çš„å·¨é¢èµ„é‡‘æŸå¤±ï¼Œæå‡ºäº†é¦–ä¸ªå»ä¸­å¿ƒåŒ–çš„å…¨é“¾ä¸Šå­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨é˜²å¾¡é€šè¿‡ç§æœ‰ä¸­ç»§(private relays)æˆ–åŒåŒºå—æ¶æ„åˆçº¦å‘èµ·çš„æ”»å‡»ã€‚è¯¥æ¡†æ¶åˆ©ç”¨Layer-2å¤„ç†é«˜èƒ½è€—è®¡ç®—ä»¥é™ä½æˆæœ¬ï¼Œå¹¶å°†éªŒè¯åçš„æ¨¡å‹æ›´æ–°åŒæ­¥è‡³Layer-1ï¼Œä»è€Œåœ¨æ™ºèƒ½åˆçº¦ä¸­å®ç°å—Gasé™åˆ¶ä¸”ä½å»¶è¿Ÿçš„åœ¨çº¿æ¨ç†(inference)ã€‚ç ”ç©¶å¼•å…¥äº†æ”¹è¿›è¯æ˜åè®®(Proof-of-Improvement, PoIm)ï¼Œå°†å»ä¸­å¿ƒåŒ–æ›´æ–°è§†ä¸ºè‡ªæˆ‘éªŒè¯çš„äº¤æ˜“ï¼Œä»…åœ¨æ€§èƒ½æŒ‡æ ‡æ˜¾è‘—æå‡æ—¶æ¥å—æ¨¡å‹æ›´æ–°ï¼Œå¹¶å¯¹å¯¹æŠ—æ€§ææ¡ˆå®æ–½ç»æµå¤„ç½šã€‚é€šè¿‡åº”ç”¨é‡åŒ–(quantization)å’Œå¾ªç¯å±•å¼€(loop-unrolling)æŠ€æœ¯ï¼Œè¯¥æ–¹æ¡ˆæ”¯æŒé€»è¾‘å›å½’ã€SVMã€CNNåŠRNNç­‰æ¨¡å‹åœ¨ä»¥å¤ªåŠåŒºå—Gasé™åˆ¶å†…è¿è¡Œï¼Œä¸”åˆ©ç”¨Z3å½¢å¼åŒ–è¯æ˜äº†å…¶ä¸é“¾ä¸‹æ¨¡å‹åœ¨ä½ç²¾åº¦ä¸Šå®Œå…¨ä¸€è‡´ã€‚åŸºäº2020è‡³2025å¹´é—´8æ¡EVMé“¾ä¸Šæ¶‰åŠ37.4äº¿ç¾å…ƒæŸå¤±çš„298ä¸ªçœŸå®æ¼æ´æ¡ˆä¾‹çš„æµ‹è¯•è¯æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ºDeFiæ”»å‡»çš„ä¸»åŠ¨ã€å®æ—¶é˜²å¾¡æä¾›äº†é«˜æ•ˆä¸”ç»æµçš„é“¾ä¸Šè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Published in the 7th Conference on Advances in Financial Technologies (AFT 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.16024v1",
      "published_date": "2025-10-15 18:58:34 UTC",
      "updated_date": "2025-10-15 18:58:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:43.387364+00:00"
    },
    {
      "arxiv_id": "2510.14007v1",
      "title": "Conditional Clifford-Steerable CNNs with Complete Kernel Basis for PDE Modeling",
      "title_zh": "ç”¨äº PDE å»ºæ¨¡çš„å…·æœ‰å®Œå¤‡æ ¸åŸºçš„æ¡ä»¶ Clifford å¯è½¬å‘ CNN",
      "authors": [
        "BÃ¡lint LÃ¡szlÃ³ Szarvas",
        "Maksim Zhdanov"
      ],
      "abstract": "Clifford-Steerable CNNs (CSCNNs) provide a unified framework that allows incorporating equivariance to arbitrary pseudo-Euclidean groups, including isometries of Euclidean space and Minkowski spacetime. In this work, we demonstrate that the kernel basis of CSCNNs is not complete, thus limiting the model expressivity. To address this issue, we propose Conditional Clifford-Steerable Kernels, which augment the kernels with equivariant representations computed from the input feature field. We derive the equivariance constraint for these input-dependent kernels and show how it can be solved efficiently via implicit parameterization. We empirically demonstrate an improved expressivity of the resulting framework on multiple PDE forecasting tasks, including fluid dynamics and relativistic electrodynamics, where our method consistently outperforms baseline methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Clifford-Steerable CNNs (CSCNNs) çš„å†…æ ¸åŸºåº•ä¸å®Œæ•´ä»è€Œé™åˆ¶æ¨¡å‹è¡¨è¾¾èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº† Conditional Clifford-Steerable Kernelsã€‚è¯¥æ–¹æ³•é€šè¿‡ä»è¾“å…¥ç‰¹å¾åœº(input feature field)ä¸­è®¡ç®—å‡ºçš„ç­‰å˜è¡¨ç¤ºæ¥å¢å¼ºå†…æ ¸ï¼Œæœ‰æ•ˆæ‰©å±•äº† CSCNNs åœ¨å¤„ç†æ¬§å‡ é‡Œå¾—ç©ºé—´ç­‰è·å˜æ¢å’Œ Minkowski spacetime ç­‰ä¼ªæ¬§å‡ é‡Œå¾—ç¾¤æ—¶çš„ç­‰å˜æ€§èƒ½åŠ›ã€‚ä½œè€…æ¨å¯¼äº†è¿™äº›ä¾èµ–è¾“å…¥çš„å†…æ ¸çš„ equivariance constraintï¼Œå¹¶å±•ç¤ºäº†å¦‚ä½•é€šè¿‡ implicit parameterization è¿›è¡Œé«˜æ•ˆæ±‚è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æµä½“åŠ¨åŠ›å­¦(fluid dynamics)å’Œç›¸å¯¹è®ºç”µåŠ¨åŠ›å­¦(relativistic electrodynamics)ç­‰å¤šç§ PDE é¢„æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ã€‚ä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•åœ¨å„é¡¹ä»»åŠ¡ä¸­å‡è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ï¼Œä¸ºå¤æ‚ç‰©ç†ç³»ç»Ÿçš„å»ºæ¨¡æä¾›äº†æ›´å¼ºå¤§çš„å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.14007v1",
      "published_date": "2025-10-15 18:38:36 UTC",
      "updated_date": "2025-10-15 18:38:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:01.407366+00:00"
    },
    {
      "arxiv_id": "2510.13999v1",
      "title": "REAP the Experts: Why Pruning Prevails for One-Shot MoE compression",
      "title_zh": "REAPï¼šä¸ºä½•å‰ªæåœ¨å•é˜¶æ®µ MoE å‹ç¼©ä¸­æ›´å…·ä¼˜åŠ¿",
      "authors": [
        "Mike Lasby",
        "Ivan Lazarevich",
        "Nish Sinnadurai",
        "Sean Lie",
        "Yani Ioannou",
        "Vithursan Thangarasa"
      ],
      "abstract": "Sparsely-activated Mixture-of-Experts (SMoE) models offer efficient pre-training and low latency but their large parameter counts create significant memory overhead, motivating research into expert compression. Contrary to recent findings favouring expert merging on discriminative benchmarks, we demonstrate that expert pruning is a superior strategy for generative tasks. We prove that merging introduces an irreducible error by causing a \"functional subspace collapse\", due to the loss of the router's independent, input-dependent control over experts. Leveraging this insight, we propose Router-weighted Expert Activation Pruning (REAP), a novel pruning criterion that considers both router gate-values and expert activation norms. Across a diverse set of SMoE models ranging from 20B to 1T parameters, REAP consistently outperforms merging and other pruning methods on generative benchmarks, especially at 50% compression. Notably, our method achieves near-lossless compression on code generation and tool-calling tasks with Qwen3-Coder-480B and Kimi-K2, even after pruning 50% of experts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Sparsely-activated Mixture-of-Experts (SMoE) æ¨¡å‹çš„ä¸“å®¶å‹ç¼©é—®é¢˜ï¼Œé’ˆå¯¹å…¶åºå¤§å‚æ•°é‡å¸¦æ¥çš„å†…å­˜æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºåœ¨ç”Ÿæˆä»»åŠ¡ä¸­ä¸“å®¶å‰ªæ (expert pruning) ä¼˜äºä¸“å®¶åˆå¹¶ (expert merging)ã€‚ç ”ç©¶ä»ç†è®ºä¸Šè¯æ˜äº†åˆå¹¶æ“ä½œä¼šå› è·¯ç”±å™¨å¤±å»å¯¹ä¸“å®¶çš„ç‹¬ç«‹æ§åˆ¶è€Œå¯¼è‡´ \"functional subspace collapse\"ï¼Œè¿›è€Œå¼•å…¥ä¸å¯çº¦è¯¯å·®ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Router-weighted Expert Activation Pruning (REAP)ï¼Œè¿™æ˜¯ä¸€ç§åŒæ—¶è€ƒè™‘è·¯ç”±å™¨é—¨æ§å€¼å’Œä¸“å®¶æ¿€æ´»èŒƒæ•°çš„æ–°å‹å‰ªæå‡†åˆ™ã€‚åœ¨æ¶µç›– 20B åˆ° 1T å‚æ•°è§„æ¨¡çš„å¤šæ ·åŒ–æ¨¡å‹å®éªŒä¸­ï¼ŒREAP åœ¨ç”ŸæˆåŸºå‡†ä¸ŠæŒç»­ä¼˜äºåˆå¹¶åŠå…¶ä»–å‰ªææ–¹æ³•ï¼Œå°¤å…¶åœ¨ 50% å‹ç¼©ç‡ä¸‹è¡¨ç°ä¼˜å¼‚ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ Qwen3-Coder-480B å’Œ Kimi-K2 çš„ä»£ç ç”Ÿæˆä¸å·¥å…·è°ƒç”¨ä»»åŠ¡ä¸­ï¼Œå³ä½¿å‰ªææ‰ä¸€åŠä¸“å®¶ä¹Ÿèƒ½å®ç°è¿‘ä¹æ— æŸçš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 8 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13999v1",
      "published_date": "2025-10-15 18:29:28 UTC",
      "updated_date": "2025-10-15 18:29:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:33:42.892509+00:00"
    },
    {
      "arxiv_id": "2510.13995v1",
      "title": "Finding Holes: Pathologist Level Performance Using AI for Cribriform Morphology Detection in Prostate Cancer",
      "title_zh": "è¯†â€œå­”â€å¯»è¸ªï¼šåˆ©ç”¨äººå·¥æ™ºèƒ½å®ç°è¾¾åˆ°ç—…ç†åŒ»ç”Ÿæ°´å¹³çš„å‰åˆ—è…ºç™Œç­›çŠ¶å½¢æ€æ£€æµ‹",
      "authors": [
        "Kelvin Szolnoky",
        "Anders Blilie",
        "Nita Mulliqi",
        "Toyonori Tsuzuki",
        "Hemamali Samaratunga",
        "Matteo Titus",
        "Xiaoyi Ji",
        "Sol Erika Boman",
        "Einar Gudlaugsson",
        "Svein Reidar Kjosavik",
        "JosÃ© Asenjo",
        "Marcello Gambacorta",
        "Paolo Libretti",
        "Marcin Braun",
        "RadisÅ‚aw Kordek",
        "Roman Åowicki",
        "Brett Delahunt",
        "Kenneth A. Iczkowski",
        "Theo van der Kwast",
        "Geert J. L. H. van Leenders",
        "Katia R. M. Leite",
        "Chin-Chen Pan",
        "Emiel Adrianus Maria Janssen",
        "Martin Eklund",
        "Lars Egevad",
        "Kimmo Kartasalo"
      ],
      "abstract": "Background: Cribriform morphology in prostate cancer is a histological feature that indicates poor prognosis and contraindicates active surveillance. However, it remains underreported and subject to significant interobserver variability amongst pathologists. We aimed to develop and validate an AI-based system to improve cribriform pattern detection.\n  Methods: We created a deep learning model using an EfficientNetV2-S encoder with multiple instance learning for end-to-end whole-slide classification. The model was trained on 640 digitised prostate core needle biopsies from 430 patients, collected across three cohorts. It was validated internally (261 slides from 171 patients) and externally (266 slides, 104 patients from three independent cohorts). Internal validation cohorts included laboratories or scanners from the development set, while external cohorts used completely independent instruments and laboratories. Annotations were provided by three expert uropathologists with known high concordance. Additionally, we conducted an inter-rater analysis and compared the model's performance against nine expert uropathologists on 88 slides from the internal validation cohort.\n  Results: The model showed strong internal validation performance (AUC: 0.97, 95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI: 0.45-0.64). In our inter-rater analysis, the model achieved the highest average agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine pathologists whose Cohen's kappas ranged from 0.35 to 0.62.\n  Conclusion: Our AI model demonstrates pathologist-level performance for cribriform morphology detection in prostate cancer. This approach could enhance diagnostic reliability, standardise reporting, and improve treatment decisions for prostate cancer patients.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘å¹¶éªŒè¯äº†ä¸€ç§åŸºäºäººå·¥æ™ºèƒ½çš„ç³»ç»Ÿï¼Œç”¨äºæ£€æµ‹å‰åˆ—è…ºç™Œä¸­çš„ç­›çŠ¶ç»“æ„(Cribriform morphology)ï¼Œè¯¥ç‰¹å¾å¯¹é¢„ååˆ¤æ–­è‡³å…³é‡è¦ä½†åœ¨ç—…ç†è¯„ä¼°ä¸­å­˜åœ¨æ˜¾è‘—çš„è§‚å¯Ÿè€…é—´å·®å¼‚ã€‚ç ”ç©¶å›¢é˜Ÿé‡‡ç”¨ EfficientNetV2-S ç¼–ç å™¨ç»“åˆå¤šç¤ºä¾‹å­¦ä¹ (Multiple Instance Learning)æ„å»ºäº†æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå®ç°äº†å…¨åˆ‡ç‰‡å›¾åƒ(Whole-slide)çš„ç«¯åˆ°ç«¯åˆ†ç±»ã€‚è¯¥æ¨¡å‹åœ¨ 640 ä»½å‰åˆ—è…ºç©¿åˆºæ´»æ£€æ ·æœ¬ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶å®Œæˆäº†å†…éƒ¨åŠå¤šä¸ªç‹¬ç«‹å¤–éƒ¨é˜Ÿåˆ—çš„éªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨å†…éƒ¨éªŒè¯ä¸­çš„ AUC è¾¾åˆ° 0.97ï¼Œå¤–éƒ¨éªŒè¯ AUC ä¸º 0.90ï¼Œè¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ã€‚åœ¨ä¸ä¹ä½ä¸“å®¶æ³Œå°¿ç—…ç†å­¦å®¶çš„ä¸€è‡´æ€§å¯¹æ¯”ä¸­ï¼Œæ¨¡å‹ä»¥ 0.66 çš„ Cohen's kappa å€¼ä¼˜äºæ‰€æœ‰äººç±»ä¸“å®¶ã€‚è¯¥ AI æ¨¡å‹åœ¨ç­›çŠ¶ç»“æ„æ£€æµ‹ä¸Šè¾¾åˆ°äº†ç—…ç†åŒ»ç”Ÿæ°´å¹³ï¼Œæœ‰åŠ©äºæå‡è¯Šæ–­å¯é æ€§ã€æ ‡å‡†åŒ–æŠ¥å‘Šå¹¶ä¼˜åŒ–å‰åˆ—è…ºç™Œæ‚£è€…çš„æ²»ç–—å†³ç­–ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13995v1",
      "published_date": "2025-10-15 18:23:34 UTC",
      "updated_date": "2025-10-15 18:23:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:18.767899+00:00"
    },
    {
      "arxiv_id": "2510.13993v1",
      "title": "Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models",
      "title_zh": "é¥æ„Ÿé¢†åŸŸçš„é«˜æ•ˆå°‘æ ·æœ¬å­¦ä¹ ï¼šèåˆè§†è§‰ä¸è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Jia Yun Chua",
        "Argyrios Zolotas",
        "Miguel Arana-Catania"
      ],
      "abstract": "Remote sensing has become a vital tool across sectors such as urban planning, environmental monitoring, and disaster response. While the volume of data generated has increased significantly, traditional vision models are often constrained by the requirement for extensive domain-specific labelled data and their limited ability to understand the context within complex environments. Vision Language Models offer a complementary approach by integrating visual and textual data; however, their application to remote sensing remains underexplored, particularly given their generalist nature. This work investigates the combination of vision models and VLMs to enhance image analysis in remote sensing, with a focus on aircraft detection and scene understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and Gemini aims to achieve more accurate and contextually aware image interpretation. Performance is evaluated on both labelled and unlabelled remote sensing data, as well as degraded image scenarios which are crucial for remote sensing. The findings show an average MAE improvement of 48.46% across models in the accuracy of aircraft detection and counting, especially in challenging conditions, in both raw and degraded scenarios. A 6.17% improvement in CLIPScore for comprehensive understanding of remote sensing images is obtained. The proposed approach combining traditional vision models and VLMs paves the way for more advanced and efficient remote sensing image analysis, especially in few-shot learning scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰æ¨¡å‹ä¸è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨é¥æ„Ÿé¢†åŸŸçš„èåˆåº”ç”¨ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¨¡å‹å¯¹ç‰¹å®šé¢†åŸŸæ ‡æ³¨æ•°æ®é«˜åº¦ä¾èµ–åŠä¸Šä¸‹æ–‡ç†è§£æœ‰é™çš„é—®é¢˜ã€‚é€šè¿‡å°†YOLOä¸LLaVAã€ChatGPTåŠGeminiç­‰å…ˆè¿›æ¨¡å‹é›†æˆï¼Œç ”ç©¶é‡ç‚¹ä¼˜åŒ–äº†é£æœºæ£€æµ‹(aircraft detection)ä¸åœºæ™¯ç†è§£ä»»åŠ¡ã€‚å®éªŒåœ¨æ ‡æ³¨ã€æœªæ ‡æ³¨åŠé€€åŒ–å›¾åƒ(degraded image)ç­‰å¤šç§æå…·æŒ‘æˆ˜æ€§çš„é¥æ„Ÿåœºæ™¯ä¸‹è¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºé£æœºæ£€æµ‹ä¸è®¡æ•°çš„å¹³å‡ç»å¯¹è¯¯å·®(MAE)æ˜¾è‘—é™ä½äº†48.46%ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹é¥æ„Ÿå›¾åƒç»¼åˆç†è§£çš„CLIPScoreä¹Ÿæå‡äº†6.17%ã€‚è¿™ç§ç»“åˆä¼ ç»Ÿè§†è§‰æ¨¡å‹ä¸VLMsçš„æ–¹æ³•ï¼Œä¸ºå°‘æ ·æœ¬å­¦ä¹ (few-shot learning)ç¯å¢ƒä¸‹çš„é«˜æ•ˆé¥æ„Ÿå›¾åƒåˆ†æå¥ å®šäº†åŸºç¡€ï¼Œå±•ç¤ºäº†è·¨æ¨¡æ€èåˆåœ¨å¤æ‚ç¯å¢ƒè§£è¯»ä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures, 8 tables. To be published in Applied AI Letters",
      "pdf_url": "https://arxiv.org/pdf/2510.13993v1",
      "published_date": "2025-10-15 18:19:48 UTC",
      "updated_date": "2025-10-15 18:19:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:17.584761+00:00"
    },
    {
      "arxiv_id": "2510.13985v1",
      "title": "Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨å› æœå­¦ä¹ ä¸­æ˜¯å¦å­˜åœ¨åå·®ï¼ŸåŸºäºæƒå˜åˆ¤æ–­çš„å¯ç¤º",
      "authors": [
        "MarÃ­a Victoria Carro",
        "Denise Alejandra Mester",
        "Francisca Gauna Selasco",
        "Giovanni Franco Gabriel Marraffini",
        "Mario Alejandro Leiva",
        "Gerardo I. Simari",
        "MarÃ­a Vanina Martinez"
      ],
      "abstract": "Causal learning is the cognitive process of developing the capability of making causal inferences based on available information, often guided by normative principles. This process is prone to errors and biases, such as the illusion of causality, in which people perceive a causal relationship between two variables despite lacking supporting evidence. This cognitive bias has been proposed to underlie many societal problems, including social prejudice, stereotype formation, misinformation, and superstitious thinking. In this work, we examine whether large language models are prone to developing causal illusions when faced with a classic cognitive science paradigm: the contingency judgment task. To investigate this, we constructed a dataset of 1,000 null contingency scenarios (in which the available information is not sufficient to establish a causal relationship between variables) within medical contexts and prompted LLMs to evaluate the effectiveness of potential causes. Our findings show that all evaluated models systematically inferred unwarranted causal relationships, revealing a strong susceptibility to the illusion of causality. While there is ongoing debate about whether LLMs genuinely understand causality or merely reproduce causal language without true comprehension, our findings support the latter hypothesis and raise concerns about the use of language models in domains where accurate causal reasoning is essential for informed decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å› æœå­¦ä¹ (Causal Learning)ä¸­æ˜¯å¦å­˜åœ¨åå·®ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å› æœé”™è§‰(Illusion of Causality)è¿™ä¸€è®¤çŸ¥åå·®ã€‚ç ”ç©¶è€…åˆ©ç”¨è®¤çŸ¥ç§‘å­¦ä¸­çš„å¶ç„¶æ€§åˆ¤æ–­ä»»åŠ¡(Contingency Judgment Task)ï¼Œæ„å»ºäº†åŒ…å«1000ä¸ªåŒ»ç–—èƒŒæ™¯ä¸‹é›¶ç›¸å…³æƒ…å¢ƒçš„æ•°æ®é›†ï¼Œæµ‹è¯•æ¨¡å‹è¯„ä¼°å› æœå…³ç³»çš„å‡†ç¡®æ€§ã€‚ç ”ç©¶å‘ç°ï¼Œæ‰€æœ‰è¢«è¯„ä¼°çš„æ¨¡å‹éƒ½ç³»ç»Ÿæ€§åœ°æ¨æ–­å‡ºäº†æ— æ ¹æ®çš„å› æœå…³ç³»ï¼Œè¡¨ç°å‡ºå¯¹å› æœé”™è§‰çš„é«˜åº¦æ•æ„Ÿæ€§ã€‚è¿™ä¸€ç»“æœæ”¯æŒäº†LLMså¯èƒ½åªæ˜¯åœ¨å¤ç°å› æœç›¸å…³çš„è¯­è¨€æ¨¡å¼è€Œéå…·å¤‡çœŸå®å› æœç†è§£èƒ½åŠ›çš„å‡è®¾ã€‚è¯¥å‘ç°å¯¹äºåœ¨åŒ»ç–—ç­‰éœ€è¦ç²¾å‡†å› æœæ¨ç†çš„å†³ç­–é¢†åŸŸä¸­ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹æå‡ºäº†é‡è¦è­¦ç¤ºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13985v1",
      "published_date": "2025-10-15 18:09:00 UTC",
      "updated_date": "2025-10-15 18:09:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:20.192784+00:00"
    },
    {
      "arxiv_id": "2510.13982v3",
      "title": "Static Sandboxes Are Inadequate: Modeling Societal Complexity Requires Open-Ended Co-Evolution in LLM-Based Multi-Agent Simulations",
      "title_zh": "é™æ€æ²™ç›’çš„å±€é™æ€§ï¼šæ¨¡æ‹Ÿç¤¾ä¼šå¤æ‚æ€§è¦æ±‚åŸºäº LLM çš„å¤šæ™ºèƒ½ä½“æ¨¡æ‹Ÿå®ç°å¼€æ”¾å¼ååŒæ¼”åŒ–",
      "authors": [
        "Jinkun Chen",
        "Sher Badshah",
        "Xuemin Yu",
        "Sijia Han"
      ],
      "abstract": "What if artificial agents could not just communicate, but also evolve, adapt, and reshape their worlds in ways we cannot fully predict? With llm now powering multi-agent systems and social simulations, we are witnessing new possibilities for modeling open-ended, ever-changing environments. Yet, most current simulations remain constrained within static sandboxes, characterized by predefined tasks, limited dynamics, and rigid evaluation criteria. These limitations prevent them from capturing the complexity of real-world societies. In this paper, we argue that static, task-specific benchmarks are fundamentally inadequate and must be rethought. We critically review emerging architectures that blend llm with multi-agent dynamics, highlight key hurdles such as balancing stability and diversity, evaluating unexpected behaviors, and scaling to greater complexity, and introduce a fresh taxonomy for this rapidly evolving field. Finally, we present a research roadmap centered on open-endedness, continuous co-evolution, and the development of resilient, socially aligned AI ecosystems. We call on the community to move beyond static paradigms and help shape the next generation of adaptive, socially-aware multi-agent simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œå½“å‰åŸºäº LLM çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå’Œç¤¾äº¤æ¨¡æ‹Ÿå¤§å¤šå±€é™äºé¢„å®šä¹‰ä»»åŠ¡å’Œåˆšæ€§æ ‡å‡†çš„ Static Sandboxesï¼Œæ— æ³•æ•æ‰çœŸå®ç¤¾ä¼šçš„å¤æ‚åŠ¨æ€ã€‚ä½œè€…è®¤ä¸ºç°æœ‰çš„é™æ€ã€ä»»åŠ¡ç‰¹å®šå‹ Benchmark å·²ä¸è¶³ä»¥åº”å¯¹å½“å‰éœ€æ±‚ï¼Œå¹¶æ‰¹åˆ¤æ€§åœ°å›é¡¾äº†èåˆ LLM ä¸å¤šæ™ºèƒ½ä½“åŠ¨æ€çš„æ–°å…´æ¶æ„ã€‚æ–‡ç« æ·±å…¥åˆ†æäº†åœ¨å¹³è¡¡ç¨³å®šæ€§ä¸å¤šæ ·æ€§ã€è¯„ä¼°æ„å¤–è¡Œä¸ºä»¥åŠæå‡ç³»ç»Ÿå¤æ‚åº¦ï¼ˆScalingï¼‰ç­‰æ–¹é¢é¢ä¸´çš„æ ¸å¿ƒéšœç¢ï¼Œå¹¶é’ˆå¯¹è¯¥é¢†åŸŸæå‡ºäº†ä¸€å¥—å…¨æ–°çš„ Taxonomy åˆ†ç±»ä½“ç³»ã€‚ç ”ç©¶æœ€åæç»˜äº†ä»¥ Open-endedness å’ŒæŒç»­ Co-evolution ä¸ºæ ¸å¿ƒçš„å‘å±•è·¯çº¿å›¾ï¼Œæ—¨åœ¨æ¨åŠ¨æ„å»ºå…·æœ‰éŸ§æ€§ä¸”ç¬¦åˆç¤¾ä¼šå¯¹é½ï¼ˆSocially Alignedï¼‰çš„ä¸‹ä¸€ä»£è‡ªé€‚åº”ç¤¾äº¤æ¨¡æ‹Ÿç³»ç»Ÿã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Preprint; feedback welcome",
      "pdf_url": "https://arxiv.org/pdf/2510.13982v3",
      "published_date": "2025-10-15 18:05:06 UTC",
      "updated_date": "2025-10-21 15:32:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:25.678148+00:00"
    },
    {
      "arxiv_id": "2510.13979v1",
      "title": "Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks",
      "title_zh": "å¹»ç¯ç‰‡æœ‰å¸®åŠ©å—ï¼Ÿé¢å‘ä¼šè®®æ¼”è®²è‡ªåŠ¨è½¬å½•çš„å¤šæ¨¡æ€ä¸Šä¸‹æ–‡",
      "authors": [
        "Supriti Sinhamahapatra",
        "Jan Niehues"
      ],
      "abstract": "State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily rely on acoustic information while disregarding additional multi-modal context. However, visual information are essential in disambiguation and adaptation. While most work focus on speaker images to handle noise conditions, this work also focuses on integrating presentation slides for the use cases of scientific presentation.\n  In a first step, we create a benchmark for multi-modal presentation including an automatic analysis of transcribing domain-specific terminology. Next, we explore methods for augmenting speech models with multi-modal information. We mitigate the lack of datasets with accompanying slides by a suitable approach of data augmentation. Finally, we train a model using the augmented dataset, resulting in a relative reduction in word error rate of approximately 34%, across all words and 35%, for domain-specific terms compared to the baseline model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ä¼šè®®æ¼”è®²çš„è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(Automatic Speech Recognition)ä¸­æ•´åˆæ¼”ç¤ºæ–‡ç¨¿å¹»ç¯ç‰‡ç­‰å¤šæ¨¡æ€ä¸Šä¸‹æ–‡ä¿¡æ¯çš„æœ‰æ•ˆæ€§ã€‚ä¸ºäº†è§£å†³å½“å‰æ¨¡å‹è¿‡åº¦ä¾èµ–å£°å­¦ä¿¡æ¯è€Œå¿½ç•¥è§†è§‰è¾…åŠ©èµ„æ–™çš„é—®é¢˜ï¼Œä½œè€…é¦–å…ˆå»ºç«‹äº†ä¸€ä¸ªå¤šæ¨¡æ€æ¼”ç¤ºåŸºå‡†ï¼Œç”¨äºè‡ªåŠ¨åˆ†æé¢†åŸŸç‰¹å®šæœ¯è¯­çš„è½¬å½•æƒ…å†µã€‚é’ˆå¯¹ç›¸å…³æ•°æ®é›†åŒ®ä¹çš„ç°çŠ¶ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§æ•°æ®å¢å¼º(Data Augmentation)æ–¹æ³•æ¥æ¨¡æ‹Ÿé…æœ‰å¹»ç¯ç‰‡çš„è¯­éŸ³æ•°æ®ï¼Œå¹¶æ¢ç´¢äº†å°†å¤šæ¨¡æ€ä¿¡æ¯èåˆè¿›è¯­éŸ³æ¨¡å‹çš„æŠ€æœ¯è·¯å¾„ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨æ‰€æœ‰å•è¯ä¸Šçš„è¯é”™è¯¯ç‡(Word Error Rate)ç›¸å¯¹åŸºçº¿é™ä½äº†çº¦34%ï¼Œè€Œåœ¨é¢†åŸŸç‰¹å®šæœ¯è¯­ä¸Šçš„é”™è¯¯ç‡åˆ™é™ä½äº†35%ã€‚è¿™ä¸€æˆæœå……åˆ†è¯æ˜äº†å¹»ç¯ç‰‡ç­‰è§†è§‰ä¸Šä¸‹æ–‡åœ¨æå‡è¯­éŸ³è¯†åˆ«å‡†ç¡®æ€§ã€è§£å†³æ¶ˆæ­§é—®é¢˜ä»¥åŠå¤„ç†ä¸“ä¸šæœ¯è¯­æ–¹é¢çš„æ˜¾è‘—ä½œç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13979v1",
      "published_date": "2025-10-15 18:04:16 UTC",
      "updated_date": "2025-10-15 18:04:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:25.886951+00:00"
    },
    {
      "arxiv_id": "2510.13940v3",
      "title": "Less is More: Improving LLM Reasoning with Minimal Test-Time Intervention",
      "title_zh": "å°‘å³æ˜¯å¤šï¼šé€šè¿‡æœ€å°æµ‹è¯•æ—¶å¹²é¢„æå‡å¤§è¯­è¨€æ¨¡å‹æ¨ç†èƒ½åŠ›",
      "authors": [
        "Zhen Yang",
        "Mingyang Zhang",
        "Feng Chen",
        "Ganggui Ding",
        "Liang Hou",
        "Xin Tao",
        "Ying-Cong Chen"
      ],
      "abstract": "Recent progress in large language models (LLMs) has focused on test-time scaling to improve reasoning via increased inference computation, but often at the cost of efficiency. We revisit test-time behavior and uncover a simple yet underexplored phenomenon: reasoning uncertainty is highly localized-only a small subset of high-entropy tokens dominantly affects output correctness. Motivated by this, we propose Minimal Test-Time Intervention (MTI), a training-free framework that enhances reasoning accuracy and stability with minimal overhead. MTI includes: (i) Selective CFG intervention, applying classifier-free guidance only at uncertain positions; and (ii) Lightweight negative-prompt guidance, reusing the main model's KV cache to approximate unconditional decoding efficiently. MTI yields consistent gains across general, coding, and STEM tasks-e.g., +9.28% average improvement on six benchmarks for DeepSeek-R1-7B and +11.25% on AIME2024 using Ling-mini-2.0-while remaining highly efficient.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Minimal Test-Time Intervention (MTI)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æå°çš„è®¡ç®—å¼€é”€æå‡å¤§è¯­è¨€æ¨¡å‹ (LLMs) çš„æ¨ç†å‡†ç¡®æ€§å’Œç¨³å®šæ€§ã€‚ä½œè€…å‘ç°æ¨ç†çš„ä¸ç¡®å®šæ€§å…·æœ‰é«˜åº¦å±€éƒ¨æ€§ï¼Œå³ä»…æœ‰æå°‘æ•°é«˜ç†µ (high-entropy) token ä¼šä¸»å¯¼è¾“å‡ºçš„æ­£ç¡®æ€§ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼ŒMTI å¼•å…¥äº†é€‰æ‹©æ€§ CFG (Selective CFG) å¹²é¢„ï¼Œä»…åœ¨ä¸ç¡®å®šçš„ä½ç½®åº”ç”¨åˆ†ç±»å™¨è¾…åŠ©å¼•å¯¼ï¼Œå¹¶ç»“åˆè½»é‡çº§è´Ÿé¢æç¤º (negative-prompt) å¼•å¯¼æŠ€æœ¯ï¼Œé€šè¿‡å¤ç”¨ KV cache å®ç°é«˜æ•ˆçš„æ— æ¡ä»¶è§£ç è¿‘ä¼¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMTI åœ¨é€šç”¨ã€ç¼–ç¨‹å’Œ STEM ä»»åŠ¡ä¸­è¡¨ç°å‡ºæŒç»­çš„æ€§èƒ½å¢é•¿ï¼Œä¾‹å¦‚ä½¿ DeepSeek-R1-7B åœ¨å…­é¡¹åŸºå‡†æµ‹è¯•ä¸­å¹³å‡æå‡ 9.28%ï¼Œåœ¨ AIME2024 ä¸Šæå‡ 11.25%ã€‚è¯¥æ–¹æ³•è¯æ˜äº†åœ¨æ¨ç†é˜¶æ®µé€šè¿‡ç²¾å‡†çš„å±€éƒ¨å¹²é¢„ï¼Œå¯ä»¥åœ¨ä¿æŒé«˜æ•ˆç‡çš„åŒæ—¶æ˜¾è‘—å¢å¼ºæ¨¡å‹æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code: https://github.com/EnVision-Research/MTI",
      "pdf_url": "https://arxiv.org/pdf/2510.13940v3",
      "published_date": "2025-10-15 17:59:45 UTC",
      "updated_date": "2026-01-11 08:32:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:29.076653+00:00"
    },
    {
      "arxiv_id": "2510.13804v1",
      "title": "Generative Universal Verifier as Multimodal Meta-Reasoner",
      "title_zh": "ç”Ÿæˆå¼é€šç”¨éªŒè¯å™¨ï¼šå¤šæ¨¡æ€å…ƒæ¨ç†å™¨",
      "authors": [
        "Xinchen Zhang",
        "Xiaoying Zhang",
        "Youbin Wu",
        "Yanbin Cao",
        "Renrui Zhang",
        "Ruihang Chu",
        "Ling Yang",
        "Yujiu Yang"
      ],
      "abstract": "We introduce Generative Universal Verifier, a novel concept and plugin designed for next-generation multimodal reasoning in vision-language models and unified multimodal models, providing the fundamental capability of reflection and refinement on visual outcomes during the reasoning and generation process. This work makes three main contributions: (1) We build ViVerBench, a comprehensive benchmark spanning 16 categories of critical tasks for evaluating visual outcomes in multimodal reasoning. Results show that existing VLMs consistently underperform across these tasks, underscoring a substantial gap from human-level capability in reliable visual verification. (2) We design two automated pipelines to construct large-scale visual verification data and train OmniVerifier-7B, the first omni-capable generative verifier trained for universal visual verification and achieves notable gains on ViVerBench(+8.3). Through training, we identify three atomic capabilities in visual verification and demonstrate how they generalize and interact synergistically. (3) We propose OmniVerifier-TTS, a sequential test-time scaling paradigm that leverages the universal verifier to bridge image generation and editing within unified models, enhancing the upper bound of generative ability through iterative fine-grained optimization. Beyond generation, we extend universal verifier to broader world-modeling interleaved reasoning scenarios. Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7), and GenEval++(+4.3), outperforming existing parallel test-time scaling methods, such as Best-of-N. By endowing multimodal reasoning with reliable visual verification, OmniVerifier advances both reliable reflection during generation and scalable test-time refinement, marking a step toward more trustworthy and controllable next-generation reasoning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Generative Universal Verifierï¼Œè¿™æ˜¯ä¸€ç§ä¸ºè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)å’Œç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹è®¾è®¡çš„åˆ›æ–°æ’ä»¶ï¼Œæ—¨åœ¨ä¸ºæ¨ç†å’Œç”Ÿæˆè¿‡ç¨‹æä¾›è§†è§‰ç»“æœçš„åæ€ä¸æ”¹è¿›èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº† ViVerBench åŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–16ç±»å…³é”®ä»»åŠ¡ä»¥è¯„ä¼°å¤šæ¨¡æ€æ¨ç†çš„è§†è§‰æ•ˆæœï¼Œå‘ç°ç°æœ‰æ¨¡å‹ä¸äººç±»æ°´å¹³åœ¨å¯é éªŒè¯æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®è·ã€‚é€šè¿‡è‡ªåŠ¨åŒ–æ•°æ®æ„å»ºæµç¨‹ï¼Œä½œè€…è®­ç»ƒäº†é¦–ä¸ªå…¨èƒ½ç”Ÿæˆå¼éªŒè¯å™¨ OmniVerifier-7Bï¼Œåœ¨ ViVerBench ä¸Šå®ç°8.3%çš„æ€§èƒ½æå‡å¹¶æ­ç¤ºäº†è§†è§‰éªŒè¯çš„ä¸‰é¡¹åŸå­èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºçš„ OmniVerifier-TTS é¡ºåºæµ‹è¯•æ—¶ç¼©æ”¾(test-time scaling)èŒƒå¼é€šè¿‡è¿­ä»£ç»†ç²’åº¦ä¼˜åŒ–ï¼Œåœ¨ T2I-ReasonBench å’Œ GenEval++ ç­‰åŸºå‡†ä¸Šè¡¨ç°ä¼˜äº Best-of-N ç­‰å¹¶è¡Œæ–¹æ³•ã€‚è¯¥å·¥ä½œé€šè¿‡èµ‹äºˆå¤šæ¨¡æ€æ¨ç†å¯é çš„è§†è§‰éªŒè¯èƒ½åŠ›ï¼Œæ˜¾è‘—å¢å¼ºäº†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å¯é åæ€ä¸å¯æ‰©å±•çš„æµ‹è¯•æ—¶ç²¾ç‚¼ï¼Œæ ‡å¿—ç€å‘æ›´å…·å…¬ä¿¡åŠ›å’Œå¯æ§æ€§çš„ä¸‹ä¸€ä»£æ¨ç†ç³»ç»Ÿè¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13804v1",
      "published_date": "2025-10-15 17:59:24 UTC",
      "updated_date": "2025-10-15 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:36.585676+00:00"
    },
    {
      "arxiv_id": "2510.13795v3",
      "title": "Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs",
      "title_zh": "Beeï¼šåŠ©åŠ›å…ˆè¿›å…¨å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„é«˜è´¨é‡è¯­æ–™åº“ä¸å…¨æ ˆå¥—ä»¶",
      "authors": [
        "Yi Zhang",
        "Bolin Ni",
        "Xin-Sheng Chen",
        "Heng-Rui Zhang",
        "Yongming Rao",
        "Houwen Peng",
        "Qinglin Lu",
        "Han Hu",
        "Meng-Hao Guo",
        "Shi-Min Hu"
      ],
      "abstract": "Fully open multimodal large language models (MLLMs) currently lag behind proprietary counterparts, primarily due to a significant gap in data quality for supervised fine-tuning (SFT). Existing open-source datasets are often plagued by widespread noise and a critical deficit in complex reasoning data, such as Chain-of-Thought (CoT), which hinders the development of advanced model capabilities. Addressing these challenges, our work makes three primary contributions. First, we introduce Honey-Data-15M, a new SFT dataset comprising approximately 15 million QA pairs, processed through multiple cleaning techniques and enhanced with a novel dual-level (short and long) CoT enrichment strategy. Second, we introduce HoneyPipe, the data curation pipeline, and its underlying framework DataStudio, providing the community with a transparent and adaptable methodology for data curation that moves beyond static dataset releases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8B model on Honey-Data-15M. Experiments show that Bee-8B establishes a new state-of-the-art (SOTA) for fully open MLLMs, achieving performance that is competitive with, and in some cases surpasses, recent semi-open models such as InternVL3.5-8B. Our work delivers to the community a suite of foundational resources, including: the Honey-Data-15M corpus; the full-stack suite comprising HoneyPipe and DataStudio; training recipes; an evaluation harness; and the model weights. This effort demonstrates that a principled focus on data quality is a key pathway to developing fully open MLLMs that are highly competitive with their semi-open counterparts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Beeï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æå‡å®Œå…¨å¼€æºå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)æ€§èƒ½çš„é«˜è´¨é‡è¯­æ–™åº“å’Œå…¨æ ˆå¥—ä»¶ã€‚é’ˆå¯¹ç°æœ‰å¼€æºæ•°æ®é›†å™ªå£°å¤šä¸”ç¼ºä¹å¤æ‚æ¨ç†æ•°æ®çš„é—®é¢˜ï¼Œä½œè€…é¦–å…ˆæ„å»ºäº†åŒ…å«çº¦1500ä¸‡ä¸ªé—®ç­”å¯¹çš„Honey-Data-15Mæ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ç»è¿‡å¤šé‡æ¸…æ´—å¹¶é‡‡ç”¨äº†åˆ›æ–°çš„åŒçº§çŸ­é•¿é“¾å¼æ€ç»´(Chain-of-Thought)å¢å¼ºç­–ç•¥ã€‚åŒæ—¶ï¼Œç ”ç©¶è¿˜å‘å¸ƒäº†æ•°æ®å¤„ç†æµæ°´çº¿HoneyPipeåŠå…¶åº•å±‚æ¡†æ¶DataStudioï¼Œä¸ºç¤¾åŒºæä¾›äº†é€æ˜ä¸”å¯é€‚é…çš„æ•°æ®æ²»ç†æ–¹æ³•ã€‚é€šè¿‡åœ¨Honey-Data-15Mä¸Šè®­ç»ƒBee-8Bæ¨¡å‹ï¼Œå®éªŒç»“æœæ˜¾ç¤ºå…¶åœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šè¾¾åˆ°äº†å®Œå…¨å¼€æºMLLMsçš„é¢†å…ˆæ°´å¹³(SOTA)ï¼Œæ€§èƒ½è¡¨ç°è¶³ä»¥æ¯”è‚©ç”šè‡³è¶…è¶ŠInternVL3.5-8Bç­‰åŠå¼€æºæ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡å¼€æºåŒ…å«æ•°æ®é›†ã€æ¨¡å‹æƒé‡å’Œè®­ç»ƒæ–¹æ¡ˆåœ¨å†…çš„å…¨æ ˆèµ„æºï¼Œè¯æ˜äº†æå‡æ•°æ®è´¨é‡æ˜¯ç¼©å°å®Œå…¨å¼€æºæ¨¡å‹ä¸å°é—­æˆ–åŠå¼€æºæ¨¡å‹å·®è·çš„å…³é”®é€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "homepage: https://open-bee.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2510.13795v3",
      "published_date": "2025-10-15 17:52:59 UTC",
      "updated_date": "2025-11-11 12:59:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:36.087089+00:00"
    },
    {
      "arxiv_id": "2510.13939v3",
      "title": "Readers Prefer Outputs of AI Trained on Copyrighted Books over Expert Human Writers",
      "title_zh": "è¯»è€…æ›´é’çç»ç‰ˆæƒä¹¦ç±è®­ç»ƒçš„ AI è¾“å‡ºè€Œéäººç±»ä¸“å®¶ä½œå®¶",
      "authors": [
        "Tuhin Chakrabarty",
        "Jane C. Ginsburg",
        "Paramveer Dhillon"
      ],
      "abstract": "The use of copyrighted books for training AI models has led to numerous lawsuits from authors concerned about AI's ability to generate derivative content. Yet it's unclear if these models can generate high quality literary text while emulating authors' styles. To answer this we conducted a preregistered study comparing MFA-trained expert writers with three frontier AI models: ChatGPT, Claude & Gemini in writing up to 450 word excerpts emulating 50 award-winning authors' diverse styles. In blind pairwise evaluations by 159 representative expert & lay readers, AI-generated text from in-context prompting was strongly disfavored by experts for both stylistic fidelity (OR=0.16, p<10^-8) & writing quality (OR=0.13, p<10^-7) but showed mixed results with lay readers. However, fine-tuning ChatGPT on individual authors' complete works completely reversed these findings: experts now favored AI-generated text for stylistic fidelity (OR=8.16, p<10^-13) & writing quality (OR=1.87, p=0.010), with lay readers showing similar shifts. These effects generalize across authors & styles. The fine-tuned outputs were rarely flagged as AI-generated (3% rate v. 97% for in-context prompting) by best AI detectors. Mediation analysis shows this reversal occurs because fine-tuning eliminates detectable AI stylistic quirks (e.g., cliche density) that penalize in-context outputs. While we do not account for additional costs of human effort required to transform raw AI output into cohesive, publishable prose, the median fine-tuning & inference cost of $81 per author represents a dramatic 99.7% reduction compared to typical professional writer compensation. Author-specific fine-tuning thus enables non-verbatim AI writing that readers prefer to expert human writing, providing empirical evidence directly relevant to copyright's fourth fair-use factor, the \"effect upon the potential market or value\" of the source works.",
      "tldr_zh": "è¯¥ç ”ç©¶é€šè¿‡ä¸€é¡¹é¢„æ³¨å†Œå®éªŒï¼Œå¯¹æ¯”äº† MFA åŸ¹è®­çš„ä¸“å®¶ä½œå®¶ä¸ ChatGPTã€Claude åŠ Gemini ç­‰å‰æ²¿ AI æ¨¡å‹åœ¨æ¨¡ä»¿ 50 ä½è·å¥–ä½œå®¶æ–‡å­¦é£æ ¼æ–¹é¢çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶ä¸“å®¶è¯»è€…å¯¹åŸºäºä¸Šä¸‹æ–‡æç¤º (in-context prompting) ç”Ÿæˆçš„æ–‡æœ¬åœ¨é£æ ¼å¿ å®åº¦ (stylistic fidelity) å’Œå†™ä½œè´¨é‡ (writing quality) ä¸ŠæŒå¦å®šæ€åº¦ï¼Œä½†é’ˆå¯¹ä½œè€…å…¨é›†è¿›è¡Œå¾®è°ƒ (fine-tuning) åçš„ AI è¾“å‡ºå´åè¶…äº†äººç±»ä¸“å®¶ï¼Œè·å¾—äº†è¯»è€…æ›´é«˜çš„åå¥½è¯„åˆ†ã€‚å¾®è°ƒåçš„ AI æ–‡æœ¬ä¸ä»…èƒ½æ¶ˆé™¤å¯æ£€æµ‹çš„é£æ ¼ç¼ºé™·ï¼Œä¸”åœ¨ AI æ£€æµ‹å™¨ä¸­çš„è¯†åˆ«ç‡ä»…ä¸º 3%ï¼Œæ˜¾ç¤ºå‡ºæé«˜çš„è‰ºæœ¯æ¨¡ä»¿æ°´å¹³ã€‚æ­¤å¤–ï¼Œå¾®è°ƒä¸æ¨ç†çš„æˆæœ¬è¾ƒä¸“ä¸šä½œå®¶è–ªé…¬é™ä½äº† 99.7%ï¼Œæå¤§åœ°ä¼˜åŒ–äº†åˆ›ä½œæ•ˆç‡ã€‚è¿™äº›å‘ç°ä¸ºè¯„ä¼° AI è®­ç»ƒå¯¹å—ç‰ˆæƒä¿æŠ¤ä½œå“çš„â€œæ½œåœ¨å¸‚åœºä»·å€¼å½±å“â€è¿™ä¸€åˆç†ä½¿ç”¨ (fair-use) æ ¸å¿ƒè¦ç´ æä¾›äº†ç›´æ¥çš„å®è¯è¯æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint Under Review",
      "pdf_url": "https://arxiv.org/pdf/2510.13939v3",
      "published_date": "2025-10-15 17:51:58 UTC",
      "updated_date": "2025-11-01 19:29:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:41.389385+00:00"
    },
    {
      "arxiv_id": "2510.13792v1",
      "title": "Provably Invincible Adversarial Attacks on Reinforcement Learning Systems: A Rate-Distortion Information-Theoretic Approach",
      "title_zh": "å¼ºåŒ–å­¦ä¹ ç³»ç»Ÿä¸­å¯è¯æ˜çš„ä¸å¯æŠµå¾¡å¯¹æŠ—æ”»å‡»ï¼šä¸€ç§ç‡å¤±çœŸä¿¡æ¯è®ºæ–¹æ³•",
      "authors": [
        "Ziqing Lu",
        "Lifeng Lai",
        "Weiyu Xu"
      ],
      "abstract": "Reinforcement learning (RL) for the Markov Decision Process (MDP) has emerged in many security-related applications, such as autonomous driving, financial decisions, and drone/robot algorithms. In order to improve the robustness/defense of RL systems against adversaries, studying various adversarial attacks on RL systems is very important. Most previous work considered deterministic adversarial attack strategies in MDP, which the recipient (victim) agent can defeat by reversing the deterministic attacks. In this paper, we propose a provably ``invincible'' or ``uncounterable'' type of adversarial attack on RL. The attackers apply a rate-distortion information-theoretic approach to randomly change agents' observations of the transition kernel (or other properties) so that the agent gains zero or very limited information about the ground-truth kernel (or other properties) during the training. We derive an information-theoretic lower bound on the recipient agent's reward regret and show the impact of rate-distortion attacks on state-of-the-art model-based and model-free algorithms. We also extend this notion of an information-theoretic approach to other types of adversarial attack, such as state observation attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å’Œé‡‘èå†³ç­–ç­‰å®‰å…¨æ•æ„Ÿé¢†åŸŸçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ç³»ç»Ÿï¼Œæå‡ºäº†ä¸€ç§åŸºäºRate-Distortionä¿¡æ¯è®ºæ–¹æ³•çš„â€œä¸å¯æˆ˜èƒœâ€ï¼ˆinvincibleï¼‰å¯¹æŠ—æ”»å‡»ç­–ç•¥ã€‚ä¸ä»¥å¾€æ˜“è¢«é€†è½¬çš„ç¡®å®šæ€§æ”»å‡»ä¸åŒï¼Œè¯¥æ–¹æ³•é€šè¿‡éšæœºæ”¹å˜æ™ºèƒ½ä½“å¯¹Transition Kernelæˆ–å…¶ä»–ç¯å¢ƒå±æ€§çš„è§‚æµ‹ï¼Œä½¿æ™ºèƒ½ä½“åœ¨è®­ç»ƒæœŸé—´æ— æ³•è·å–å…³äºçœŸå®ç¯å¢ƒçš„æœ‰æ•ˆä¿¡æ¯ã€‚ç ”ç©¶è€…åˆ©ç”¨ä¿¡æ¯è®ºæ¨å¯¼å‡ºäº†å—æ”»å‡»æ™ºèƒ½ä½“å¥–åŠ±æ‚”å€¼ï¼ˆReward Regretï¼‰çš„ç†è®ºä¸‹ç•Œï¼Œå¹¶ç³»ç»Ÿå±•ç¤ºäº†è¯¥æ”»å‡»å¯¹å½“å‰ä¸»æµModel-basedå’ŒModel-freeç®—æ³•çš„æ˜¾è‘—ç ´ååŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç†è®ºæ¡†æ¶è¿˜è¢«æˆåŠŸæ‰©å±•è‡³State Observation Attacksç­‰å…¶ä»–ç±»å‹çš„å¯¹æŠ—æ”»å‡»ä¸­ã€‚è¿™ä¸€ç ”ç©¶ä¸ä»…æ­ç¤ºäº†RLç³»ç»Ÿåœ¨ä¿¡æ¯æµå—é™ä¸‹çš„æœ¬è´¨è„†å¼±æ€§ï¼Œä¹Ÿä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„é˜²å¾¡æœºåˆ¶æä¾›äº†é‡è¦çš„ç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13792v1",
      "published_date": "2025-10-15 17:48:19 UTC",
      "updated_date": "2025-10-15 17:48:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:41.594324+00:00"
    },
    {
      "arxiv_id": "2510.13786v1",
      "title": "The Art of Scaling Reinforcement Learning Compute for LLMs",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ è®¡ç®—è§„æ¨¡åŒ–çš„è‰ºæœ¯",
      "authors": [
        "Devvrit Khatri",
        "Lovish Madaan",
        "Rishabh Tiwari",
        "Rachit Bansal",
        "Sai Surya Duvvuri",
        "Manzil Zaheer",
        "Inderjit S. Dhillon",
        "David Brandfonbrener",
        "Rishabh Agarwal"
      ],
      "abstract": "Reinforcement learning (RL) has become central to training large language models (LLMs), yet the field lacks predictive scaling methodologies comparable to those established for pre-training. Despite rapidly rising compute budgets, there is no principled understanding of how to evaluate algorithmic improvements for scaling RL compute. We present the first large-scale systematic study, amounting to more than 400,000 GPU-hours, that defines a principled framework for analyzing and predicting RL scaling in LLMs. We fit sigmoidal compute-performance curves for RL training and ablate a wide range of common design choices to analyze their effects on asymptotic performance and compute efficiency. We observe: (1) Not all recipes yield similar asymptotic performance, (2) Details such as loss aggregation, normalization, curriculum, and off-policy algorithm primarily modulate compute efficiency without materially shifting the asymptote, and (3) Stable, scalable recipes follow predictable scaling trajectories, enabling extrapolation from smaller-scale runs. Combining these insights, we propose a best-practice recipe, ScaleRL, and demonstrate its effectiveness by successfully scaling and predicting validation performance on a single RL run scaled up to 100,000 GPU-hours. Our work provides both a scientific framework for analyzing scaling in RL and a practical recipe that brings RL training closer to the predictability long achieved in pre-training.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒä¸­ç¼ºä¹ç±»ä¼¼é¢„è®­ç»ƒé˜¶æ®µçš„é¢„æµ‹æ€§è§„æ¨¡æ‰©å±•ï¼ˆScalingï¼‰æ–¹æ³•è®ºçš„é—®é¢˜ï¼Œå¼€å±•äº†è¶…è¿‡40ä¸‡GPU-hoursçš„å¤§è§„æ¨¡ç³»ç»Ÿç ”ç©¶ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŸåˆ™æ€§æ¡†æ¶æ¥åˆ†æå’Œé¢„æµ‹RLè®¡ç®—è§„æ¨¡çš„æ‰©å±•ï¼Œå¹¶æ‹Ÿåˆäº†è®¡ç®—æ€§èƒ½çš„Så‹æ›²çº¿ï¼ˆSigmoidal compute-performance curvesï¼‰ã€‚ç ”ç©¶å‘ç°ï¼Œå¹¶éæ‰€æœ‰è®­ç»ƒæ–¹æ¡ˆéƒ½èƒ½è¾¾åˆ°ç›¸åŒçš„æ¸è¿‘æ€§èƒ½ï¼ˆAsymptotic performanceï¼‰ï¼Œè€ŒæŸå¤±èšåˆï¼ˆLoss aggregationï¼‰ã€å½’ä¸€åŒ–ï¼ˆNormalizationï¼‰ã€è¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculumï¼‰å’Œç¦»ç­–ç®—æ³•ï¼ˆOff-policy algorithmï¼‰ä¸»è¦å½±å“è®¡ç®—æ•ˆç‡è€Œéæ€§èƒ½ä¸Šé™ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†åä¸ºScaleRLçš„æœ€ä½³å®è·µæ–¹æ¡ˆï¼Œå¹¶åœ¨ä¸€é¡¹10ä¸‡GPU-hoursçš„è®­ç»ƒä»»åŠ¡ä¸­æˆåŠŸé¢„æµ‹å¹¶éªŒè¯äº†å…¶æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œä¸ºRLè§„æ¨¡åŒ–æä¾›äº†ç§‘å­¦æ¡†æ¶å’Œå®ç”¨é…æ–¹ï¼Œæ˜¾è‘—æå‡äº†RLè®­ç»ƒçš„å¯é¢„æµ‹æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 20 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13786v1",
      "published_date": "2025-10-15 17:43:03 UTC",
      "updated_date": "2025-10-15 17:43:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:54.191837+00:00"
    },
    {
      "arxiv_id": "2510.13778v1",
      "title": "InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy",
      "title_zh": "InternVLA-M1ï¼šé¢å‘é€šç”¨æœºå™¨äººç­–ç•¥çš„ç©ºé—´å¼•å¯¼å¼è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¡†æ¶",
      "authors": [
        "Xinyi Chen",
        "Yilun Chen",
        "Yanwei Fu",
        "Ning Gao",
        "Jiaya Jia",
        "Weiyang Jin",
        "Hao Li",
        "Yao Mu",
        "Jiangmiao Pang",
        "Yu Qiao",
        "Yang Tian",
        "Bin Wang",
        "Bolun Wang",
        "Fangjing Wang",
        "Hanqing Wang",
        "Tai Wang",
        "Ziqin Wang",
        "Xueyuan Wei",
        "Chao Wu",
        "Shuai Yang",
        "Jinhui Ye",
        "Junqiu Yu",
        "Jia Zeng",
        "Jingjing Zhang",
        "Jinyu Zhang",
        "Shi Zhang",
        "Feng Zheng",
        "Bowen Zhou",
        "Yangkun Zhu"
      ],
      "abstract": "We introduce InternVLA-M1, a unified framework for spatial grounding and robot control that advances instruction-following robots toward scalable, general-purpose intelligence. Its core idea is spatially guided vision-language-action training, where spatial grounding serves as the critical link between instructions and robot actions. InternVLA-M1 employs a two-stage pipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning data to determine ``where to act'' by aligning instructions with visual, embodiment-agnostic positions, and (ii) spatially guided action post-training to decide ``how to act'' by generating embodiment-aware actions through plug-and-play spatial prompting. This spatially guided training recipe yields consistent gains: InternVLA-M1 outperforms its variant without spatial guidance by +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO Franka, while demonstrating stronger spatial reasoning capability in box, point, and trace prediction. To further scale instruction following, we built a simulation engine to collect 244K generalizable pick-and-place episodes, enabling a 6.2% average improvement across 200 tasks and 3K+ objects. In real-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with synthetic co-training, achieved +20.6% on unseen objects and novel configurations. Moreover, in long-horizon reasoning-intensive scenarios, it surpassed existing works by over 10%. These results highlight spatially guided training as a unifying principle for scalable and resilient generalist robots. Code and models are available at https://github.com/InternRobotics/InternVLA-M1.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† InternVLA-M1ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç©ºé—´å®šä½ (Spatial Grounding) å’Œæœºå™¨äººæ§åˆ¶çš„ç»Ÿä¸€ Vision-Language-Action (VLA) æ¡†æ¶ï¼Œæ—¨åœ¨æå‡é€šç”¨æœºå™¨äººè§„æ¨¡åŒ–æŒ‡ä»¤éµå¾ªçš„èƒ½åŠ›ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†ç©ºé—´å¼•å¯¼çš„è®­ç»ƒèŒƒå¼ï¼Œé€šè¿‡ä¸¤é˜¶æ®µæµæ°´çº¿å®ç°ï¼šç¬¬ä¸€é˜¶æ®µåœ¨ 2.3M æ•°æ®ä¸Šè¿›è¡Œç©ºé—´å®šä½é¢„è®­ç»ƒä»¥è§£å†³â€œåœ¨å“ªé‡ŒåŠ¨ä½œâ€çš„é—®é¢˜ï¼Œç¬¬äºŒé˜¶æ®µé€šè¿‡ç©ºé—´æç¤º (Spatial Prompting) è¿›è¡ŒåŠ¨ä½œåè®­ç»ƒä»¥è§£å†³â€œå¦‚ä½•åŠ¨ä½œâ€çš„é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒInternVLA-M1 åœ¨ SimplerEnvã€WidowX å’Œ LIBERO ç­‰åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºæ— ç©ºé—´å¼•å¯¼çš„å˜ä½“ï¼Œå¹¶åœ¨ç©ºé—´æ¨ç†ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ›´å¼ºçš„é²æ£’æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ä»¿çœŸå¼•æ“æ”¶é›†äº† 244K ä¸ªæŠ“å–ä»»åŠ¡æ•°æ®ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹åœ¨å¤„ç† 3000 å¤šç§ç‰©ä½“æ—¶çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨é•¿èˆªç¨‹ (Long-horizon) æ¨ç†å¯†é›†å‹åœºæ™¯å’Œç°å®ä¸–ç•ŒæœªçŸ¥é…ç½®ä»»åŠ¡ä¸­ï¼ŒInternVLA-M1 çš„æ€§èƒ½ä¼˜äºç°æœ‰å·¥ä½œ 10% ä»¥ä¸Šã€‚è¯¥ç ”ç©¶è¯æ˜äº†ç©ºé—´å¼•å¯¼è®­ç»ƒæ˜¯æ„å»ºå¯æ‰©å±•ä¸”å…·éŸ§æ€§çš„é€šç”¨æœºå™¨äººæ”¿ç­–çš„ç»Ÿä¸€åŸåˆ™ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Technical report",
      "pdf_url": "https://arxiv.org/pdf/2510.13778v1",
      "published_date": "2025-10-15 17:30:05 UTC",
      "updated_date": "2025-10-15 17:30:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:34:57.491726+00:00"
    },
    {
      "arxiv_id": "2510.13768v1",
      "title": "Scaling Vision Transformers for Functional MRI with Flat Maps",
      "title_zh": "åŸºäºå¹³é¢å›¾çš„åŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒè§†è§‰ Transformer è§„æ¨¡åŒ–",
      "authors": [
        "Connor Lane",
        "Daniel Z. Kaplan",
        "Tanishq Mathew Abraham",
        "Paul S. Scotti"
      ],
      "abstract": "A key question for adapting modern deep learning architectures to functional MRI (fMRI) is how to represent the data for model input. To bridge the modality gap between fMRI and natural images, we transform the 4D volumetric fMRI data into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K hours of fMRI flat map videos from the Human Connectome Project using the spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI modeling performance improves with dataset size according to a strict power scaling law. Downstream classification benchmarks show that our model learns rich representations supporting both fine-grained state decoding across subjects, as well as subject-specific trait decoding across changes in brain state. This work is part of an ongoing open science project to build foundation models for fMRI data. Our code and datasets are available at https://github.com/MedARC-AI/fmri-fm.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°† Vision Transformers (ViT) é€‚é…äºåŠŸèƒ½æ€§ç£å…±æŒ¯æˆåƒ (fMRI) æ•°æ®ï¼Œé€šè¿‡å°† 4D ä½“ç§¯ fMRI è½¬åŒ–ä¸º 2D fMRI æ´»åŠ¨å¹³é¢å›¾ (flat maps) è§†é¢‘æ¥æ¡¥æ¥æ¨¡æ€é—´éš™ã€‚ç ”ç©¶è€…åœ¨ Human Connectome Project æä¾›çš„ 2.3K å°æ—¶è§†é¢‘æ•°æ®ä¸Šï¼Œåˆ©ç”¨æ—¶ç©ºæ©ç è‡ªç¼–ç å™¨ (MAE) æ¡†æ¶è¿›è¡Œé¢„è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ©ç  fMRI å»ºæ¨¡æ€§èƒ½éšæ•°æ®é›†è§„æ¨¡çš„æ‰©å¤§éµå¾ªä¸¥æ ¼çš„å¹‚å¾‹ç¼©æ”¾ (power scaling law)ã€‚ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡è¯æ˜è¯¥æ¨¡å‹å­¦ä¹ åˆ°äº†ä¸°å¯Œçš„è¡¨ç¤ºï¼Œèƒ½å¤Ÿæ”¯æŒè·¨å—è¯•è€…çš„ç»†ç²’åº¦çŠ¶æ€è§£ç ä»¥åŠè·¨è„‘çŠ¶æ€çš„ä¸ªä½“ç‰¹å¾è§£ç ã€‚è¿™é¡¹å·¥ä½œä½œä¸ºæ„å»º fMRI åŸºç¡€æ¨¡å‹ (foundation models) å¼€æºé¡¹ç›®çš„ä¸€éƒ¨åˆ†ï¼Œä¸ºç¥ç»å½±åƒé¢†åŸŸçš„å¤§è§„æ¨¡è‡ªç›‘ç£å­¦ä¹ æä¾›äº†é‡è¦çš„åŸºå‡†å’Œèµ„æºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2025 Workshop, Foundation Models for the Brain and Body; Code: https://github.com/MedARC-AI/fmri-fm; Discord: https://discord.gg/tVR4TWnRM9",
      "pdf_url": "https://arxiv.org/pdf/2510.13768v1",
      "published_date": "2025-10-15 17:15:00 UTC",
      "updated_date": "2025-10-15 17:15:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:02.982131+00:00"
    },
    {
      "arxiv_id": "2510.13756v1",
      "title": "RECODE: Reasoning Through Code Generation for Visual Question Answering",
      "title_zh": "RECODEï¼šåŸºäºä»£ç ç”Ÿæˆçš„è§†è§‰é—®ç­”æ¨ç†",
      "authors": [
        "Junhong Shen",
        "Mu Cai",
        "Bo Hu",
        "Ameet Talwalkar",
        "David A Ross",
        "Cordelia Schmid",
        "Alireza Fathi"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with precise reasoning for structured visuals like charts and diagrams, as pixel-based perception lacks a mechanism for verification. To address this, we propose to leverage derendering -- the process of reverse-engineering visuals into executable code -- as a new modality for verifiable visual reasoning. Specifically, we propose RECODE, an agentic framework that first generates multiple candidate programs to reproduce the input image. It then uses a critic to select the most faithful reconstruction and iteratively refines the code. This process not only transforms an ambiguous perceptual task into a verifiable, symbolic problem, but also enables precise calculations and logical inferences later on. On various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K, RECODE significantly outperforms methods that do not leverage code or only use code for drawing auxiliary lines or cropping. Our work demonstrates that grounding visual perception in executable code provides a new path toward more accurate and verifiable multimodal reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RECODE æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) åœ¨å¤„ç†å›¾è¡¨å’Œç¤ºæ„å›¾ç­‰ç»“æ„åŒ–è§†è§‰ä¿¡æ¯æ—¶ç”±äºåƒç´ çº§æ„ŸçŸ¥çš„å±€é™è€Œç¼ºä¹éªŒè¯æœºåˆ¶çš„é—®é¢˜ã€‚RECODE çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨åæ¸²æŸ“ (derendering) æŠ€æœ¯ï¼Œå°†è§†è§‰å›¾åƒé€†å‘å·¥ç¨‹ä¸ºå¯æ‰§è¡Œä»£ç ï¼Œä½œä¸ºä¸€ç§å¯éªŒè¯è§†è§‰æ¨ç†çš„æ–°æ¨¡æ€ã€‚è¯¥æ™ºèƒ½ä½“æ¡†æ¶é¦–å…ˆç”Ÿæˆå¤šä¸ªå€™é€‰ç¨‹åºæ¥å¤ç°è¾“å…¥å›¾åƒï¼Œéšååˆ©ç”¨æ‰¹è¯„æœºåˆ¶ (critic) é€‰æ‹©æœ€çœŸå®çš„é‡å»ºå¹¶è¿›è¡Œè¿­ä»£ä¼˜åŒ–ã€‚è¿™ä¸€è¿‡ç¨‹å°†æ¨¡ç³Šçš„æ„ŸçŸ¥ä»»åŠ¡è½¬åŒ–ä¸ºç¬¦å·åŒ–çš„å¯éªŒè¯é—®é¢˜ï¼Œä»è€Œæ”¯æŒåç»­ç²¾ç¡®çš„æ•°å€¼è®¡ç®—å’Œé€»è¾‘æ¨ç†ã€‚åœ¨ CharXivã€ChartQA å’Œ Geometry3K ç­‰å¤šä¸ªè§†è§‰æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼ŒRECODE çš„è¡¨ç°æ˜¾è‘—ä¼˜äºä¸ä½¿ç”¨ä»£ç æˆ–ä»…å°†ä»£ç ç”¨äºè¾…åŠ©ç»˜å›¾çš„åŸºçº¿æ–¹æ³•ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å°†è§†è§‰æ„ŸçŸ¥æ ¹æ¤äºå¯æ‰§è¡Œä»£ç ï¼Œä¸ºå®ç°æ›´å‡†ç¡®ã€å¯éªŒè¯çš„å¤šæ¨¡æ€æ¨ç†æä¾›äº†å…¨æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13756v1",
      "published_date": "2025-10-15 17:05:37 UTC",
      "updated_date": "2025-10-15 17:05:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:03.786777+00:00"
    },
    {
      "arxiv_id": "2510.13744v1",
      "title": "Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math",
      "title_zh": "Hard2Verifyï¼šé¢å‘å¼€æ”¾å¼å‰æ²¿æ•°å­¦çš„æ­¥éª¤çº§éªŒè¯åŸºå‡†",
      "authors": [
        "Shrey Pandit",
        "Austin Xu",
        "Xuan-Phi Nguyen",
        "Yifei Ming",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "Large language model (LLM)-based reasoning systems have recently achieved gold medal-level performance in the IMO 2025 competition, writing mathematical proofs where, to receive full credit, each step must be not only correct but also sufficiently supported. To train LLM-based reasoners in such challenging, open-ended settings, strong verifiers capable of catching step-level mistakes are necessary prerequisites. We introduce Hard2Verify, a human-annotated, step-level verification benchmark produced with over 500 hours of human labor. Hard2Verify is designed to rigorously assess step-level verifiers at the frontier: Verifiers must provide step-level annotations or identify the first error in responses generated by frontier LLMs for very recent, challenging, and open-ended math questions. We evaluate 29 generative critics and process reward models, demonstrating that, beyond a few standouts, open-source verifiers lag closed source models. We subsequently analyze what drives poor performance in step-level verification, the impacts of scaling verifier compute, as well as fundamental questions such as self-verification and verification-generation dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†Hard2Verifyï¼Œè¿™æ˜¯ä¸€ä¸ªç»è¿‡500å¤šå°æ—¶äººå·¥æ ‡æ³¨çš„æ­¥çº§éªŒè¯(step-level verification)åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨ä¸ºå¤§è¯­è¨€æ¨¡å‹(LLM)åœ¨å¤„ç†å‰æ²¿å¼€æ”¾å¼æ•°å­¦éš¾é¢˜æ—¶æä¾›ä¸¥è°¨çš„é”™è¯¯æ•è·è¯„ä¼°ã€‚é¢å¯¹å½“å‰æ¨ç†ç³»ç»Ÿå·²è¾¾åˆ°IMO 2025é‡‘ç‰Œæ°´å¹³çš„ç°çŠ¶ï¼Œè¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨å¤æ‚è¯æ˜è¿‡ç¨‹ä¸­ç¡®ä¿æ¯ä¸€æ­¥å‡†ç¡®æ€§çš„å¿…è¦æ€§ï¼Œå¹¶è¦æ±‚éªŒè¯å™¨è¯†åˆ«å‰æ²¿æ¨¡å‹ç”Ÿæˆçš„é¦–ä¸ªé”™è¯¯æˆ–è¿›è¡Œè¯¦ç»†è¯„åˆ†ã€‚å®éªŒé€šè¿‡å¯¹29ä¸ªç”Ÿæˆå¼è¯„è®ºæ¨¡å‹(generative critics)å’Œè¿‡ç¨‹å¥–åŠ±æ¨¡å‹(process reward models)çš„è¯„ä¼°å‘ç°ï¼Œå¤§å¤šæ•°å¼€æºéªŒè¯å™¨åœ¨æ€§èƒ½ä¸Šä»æ˜¾è‘—è½åäºé—­æºæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè®ºæ–‡æ·±å…¥æ¢è®¨äº†é©±åŠ¨éªŒè¯æ€§èƒ½çš„å› ç´ ã€æ‰©å±•éªŒè¯è®¡ç®—é‡çš„å½±å“ï¼Œä»¥åŠè‡ªæˆ‘éªŒè¯(self-verification)ä¸éªŒè¯-ç”ŸæˆåŠ¨æ€ç­‰åŸºæœ¬é—®é¢˜ã€‚Hard2Verifyä¸ºè®­ç»ƒèƒ½å¤Ÿå¤„ç†æŒ‘æˆ˜æ€§æ•°å­¦ä»»åŠ¡çš„å¯ä¿¡æ¨ç†æ¨¡å‹æä¾›äº†å…³é”®çš„éªŒè¯æ ‡å‡†å’Œåˆ†æè§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 8 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13744v1",
      "published_date": "2025-10-15 16:50:54 UTC",
      "updated_date": "2025-10-15 16:50:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:04.282128+00:00"
    },
    {
      "arxiv_id": "2510.13740v1",
      "title": "Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs",
      "title_zh": "é¢å‘é«˜æ•ˆè§†è§‰å›¾ç¥ç»ç½‘ç»œçš„å¤šå°ºåº¦é«˜åˆ†è¾¨ç‡å¯¹æ•°æ„å›¾æ¨¡å—",
      "authors": [
        "Mustafa Munir",
        "Alex Zhang",
        "Radu Marculescu"
      ],
      "abstract": "Vision graph neural networks (ViG) have demonstrated promise in vision tasks as a competitive alternative to conventional convolutional neural nets (CNN) and transformers (ViTs); however, common graph construction methods, such as k-nearest neighbor (KNN), can be expensive on larger images. While methods such as Sparse Vision Graph Attention (SVGA) have shown promise, SVGA's fixed step scale can lead to over-squashing and missing multiple connections to gain the same information that could be gained from a long-range link. Through this observation, we propose a new graph construction method, Logarithmic Scalable Graph Construction (LSGC) to enhance performance by limiting the number of long-range links. To this end, we propose LogViG, a novel hybrid CNN-GNN model that utilizes LSGC. Furthermore, inspired by the successes of multi-scale and high-resolution architectures, we introduce and apply a high-resolution branch and fuse features between our high-resolution and low-resolution branches for a multi-scale high-resolution Vision GNN network. Extensive experiments show that LogViG beats existing ViG, CNN, and ViT architectures in terms of accuracy, GMACs, and parameters on image classification and semantic segmentation tasks. Our smallest model, Ti-LogViG, achieves an average top-1 accuracy on ImageNet-1K of 79.9% with a standard deviation of 0.2%, 1.7% higher average accuracy than Vision GNN with a 24.3% reduction in parameters and 35.3% reduction in GMACs. Our work shows that leveraging long-range links in graph construction for ViGs through our proposed LSGC can exceed the performance of current state-of-the-art ViGs. Code is available at https://github.com/mmunir127/LogViG-Official.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰å›¾ç¥ç»ç½‘ç»œ (Vision GNNs, ViG) åœ¨å¤„ç†å¤§å°ºå¯¸å›¾åƒæ—¶é¢ä¸´çš„ k-nearest neighbor (KNN) è®¡ç®—å¼€é”€è¿‡å¤§ï¼Œä»¥åŠç°æœ‰æ–¹æ³•å¯¼è‡´çš„è¿‡åº¦æŒ¤å‹ (over-squashing) å’Œé•¿ç¨‹è¿æ¥ç¼ºå¤±ç­‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º Logarithmic Scalable Graph Construction (LSGC) çš„æ–°å‹å›¾æ„å»ºæ–¹æ³•ã€‚é€šè¿‡é™åˆ¶é•¿ç¨‹è¿æ¥çš„æ•°é‡ï¼ŒLSGC æœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹æ€§èƒ½ï¼Œå¹¶æ®æ­¤æ„å»ºäº†ç»“åˆ CNN ä¸ GNN ä¼˜åŠ¿çš„æ··åˆæ¨¡å‹ LogViGã€‚ä¸ºäº†è¿›ä¸€æ­¥æå‡ç‰¹å¾è¡¨è¾¾èƒ½åŠ›ï¼ŒLogViG å¼•å…¥äº†å¤šå°ºåº¦é«˜åˆ†è¾¨ç‡ (Multi-Scale High-Resolution) åˆ†æ”¯å¹¶è¿›è¡Œäº†è·¨å°ºåº¦ç‰¹å¾èåˆã€‚å®éªŒè¡¨æ˜ï¼ŒLogViG åœ¨å›¾åƒåˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ä¸Šçš„è¡¨ç°å…¨é¢è¶…è¶Šäº†ä¸»æµçš„ ViGã€CNN å’Œ ViT æ¶æ„ã€‚å…¶ä¸­è½»é‡åŒ–æ¨¡å‹ Ti-LogViG åœ¨ ImageNet-1K ä¸Šè¾¾åˆ°äº† 79.9% çš„ Top-1 å‡†ç¡®ç‡ï¼Œåœ¨æ˜¾è‘—é™ä½å‚æ•°é‡å’Œ GMACs çš„åŒæ—¶ï¼Œæ¯”åŸå§‹ Vision GNN å‡†ç¡®ç‡æå‡äº† 1.7%ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åˆ©ç”¨ LSGC ä¼˜åŒ–å›¾æ„å»ºè¿‡ç¨‹å¯ä»¥ä½¿è§†è§‰å›¾ç¥ç»ç½‘ç»œåœ¨æ•ˆç‡å’Œç²¾åº¦ä¸Šå‡è¾¾åˆ°é¢†åŸŸé¢†å…ˆæ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in the Proceedings of the Third Learning on Graphs Conference (LoG 2024)",
      "pdf_url": "https://arxiv.org/pdf/2510.13740v1",
      "published_date": "2025-10-15 16:47:09 UTC",
      "updated_date": "2025-10-15 16:47:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:11.686474+00:00"
    },
    {
      "arxiv_id": "2510.13727v1",
      "title": "From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails",
      "title_zh": "ä»æ‹’ç»åˆ°æ¢å¤ï¼šä¸€ç§åŸºäºæ§åˆ¶ç†è®ºçš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æŠ¤æ æ–¹æ³•",
      "authors": [
        "Ravi Pandya",
        "Madison Bland",
        "Duy P. Nguyen",
        "Changliu Liu",
        "Jaime FernÃ¡ndez Fisac",
        "Andrea Bajcsy"
      ],
      "abstract": "Generative AI systems are increasingly assisting and acting on behalf of end users in practical settings, from digital shopping assistants to next-generation autonomous cars. In this context, safety is no longer about blocking harmful content, but about preempting downstream hazards like financial or physical harm. Yet, most AI guardrails continue to rely on output classification based on labeled datasets and human-specified criteria,making them brittle to new hazardous situations. Even when unsafe conditions are flagged, this detection offers no path to recovery: typically, the AI system simply refuses to act--which is not always a safe choice. In this work, we argue that agentic AI safety is fundamentally a sequential decision problem: harmful outcomes arise from the AI system's continually evolving interactions and their downstream consequences on the world. We formalize this through the lens of safety-critical control theory, but within the AI model's latent representation of the world. This enables us to build predictive guardrails that (i) monitor an AI system's outputs (actions) in real time and (ii) proactively correct risky outputs to safe ones, all in a model-agnostic manner so the same guardrail can be wrapped around any AI model. We also offer a practical training recipe for computing such guardrails at scale via safety-critical reinforcement learning. Our experiments in simulated driving and e-commerce settings demonstrate that control-theoretic guardrails can reliably steer LLM agents clear of catastrophic outcomes (from collisions to bankruptcy) while preserving task performance, offering a principled dynamic alternative to today's flag-and-block guardrails.",
      "tldr_zh": "é’ˆå¯¹ç”Ÿæˆå¼ AI æ™ºèƒ½ä½“åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„æ½œåœ¨å±å®³ä»¥åŠä¼ ç»ŸæŠ¤æ ï¼ˆGuardrailsï¼‰ä»…é‡‡å–ç®€å•æ‹’ç»ç­–ç•¥å¯¼è‡´çš„è„†å¼±æ€§ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæ§åˆ¶ç†è®ºï¼ˆControl-Theoretic Approachï¼‰çš„å…¨æ–°å®‰å…¨æ²»ç†æ¡†æ¶ã€‚ä½œè€…å°†æ™ºèƒ½ä½“å®‰å…¨å®šä¹‰ä¸ºåºè´¯å†³ç­–é—®é¢˜ï¼ˆSequential Decision Problemï¼‰ï¼Œå¹¶åˆ©ç”¨å®‰å…¨æ‰¹åˆ¤æ§åˆ¶ç†è®ºï¼ˆSafety-Critical Control Theoryï¼‰åœ¨ AI æ¨¡å‹çš„æ½œç©ºé—´è¡¨ç¤ºä¸­æ„å»ºé¢„æµ‹æ€§æŠ¤æ ã€‚è¯¥æŠ¤æ èƒ½å¤Ÿå®æ—¶ç›‘æµ‹ AI ç³»ç»Ÿçš„è¾“å‡ºåŠ¨ä½œï¼Œå¹¶åœ¨è¯†åˆ«åˆ°é£é™©æ—¶ä¸»åŠ¨å°†å…¶ä¿®æ­£ä¸ºå®‰å…¨åŠ¨ä½œï¼Œä¸”å…·å¤‡æ¨¡å‹æ— å…³æ€§ï¼ˆModel-Agnosticï¼‰ï¼Œå¯çµæ´»å°è£…äºä»»ä½• AI æ¨¡å‹ä¹‹ä¸Šã€‚ç ”ç©¶è¿›ä¸€æ­¥æä¾›äº†ä¸€ç§é€šè¿‡å®‰å…¨æ‰¹åˆ¤å¼ºåŒ–å­¦ä¹ ï¼ˆSafety-Critical Reinforcement Learningï¼‰å¤§è§„æ¨¡è®­ç»ƒæ­¤ç±»æŠ¤æ çš„å®ç”¨æ–¹æ¡ˆã€‚åœ¨è‡ªåŠ¨é©¾é©¶æ¨¡æ‹Ÿå’Œç”µå­å•†åŠ¡åœºæ™¯çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½æœ‰æ•ˆå¼•å¯¼ LLM æ™ºèƒ½ä½“è§„é¿ç¢°æ’æˆ–ç»æµç ´äº§ç­‰ç¾éš¾æ€§åæœï¼ŒåŒæ—¶ä¿æŒä¼˜å¼‚çš„ä»»åŠ¡æ€§èƒ½ã€‚è¯¥æˆæœä¸ºä»ä¼ ç»Ÿçš„â€œæ£€æµ‹å¹¶é˜»æ–­â€æ¨¡å¼è½¬å‘åŠ¨æ€ã€åŸåˆ™æ€§ä¸”å…·å¤‡æ¢å¤èƒ½åŠ›çš„ AI å®‰å…¨æœºåˆ¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13727v1",
      "published_date": "2025-10-15 16:30:57 UTC",
      "updated_date": "2025-10-15 16:30:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:14.791162+00:00"
    },
    {
      "arxiv_id": "2510.13724v1",
      "title": "FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access",
      "title_zh": "FIRSTï¼šé¢å‘ç§‘å­¦ AI æ¨¡å‹è®¿é—®çš„è”é‚¦æ¨ç†èµ„æºè°ƒåº¦å·¥å…·åŒ…",
      "authors": [
        "Aditya Tanikanti",
        "Benoit CÃ´tÃ©",
        "Yanfei Guo",
        "Le Chen",
        "Nickolaus Saint",
        "Ryan Chard",
        "Ken Raffenetti",
        "Rajeev Thakur",
        "Thomas Uram",
        "Ian Foster",
        "Michael E. Papka",
        "Venkatram Vishwanath"
      ],
      "abstract": "We present the Federated Inference Resource Scheduling Toolkit (FIRST), a framework enabling Inference-as-a-Service across distributed High-Performance Computing (HPC) clusters. FIRST provides cloud-like access to diverse AI models, like Large Language Models (LLMs), on existing HPC infrastructure. Leveraging Globus Auth and Globus Compute, the system allows researchers to run parallel inference workloads via an OpenAI-compliant API on private, secure environments. This cluster-agnostic API allows requests to be distributed across federated clusters, targeting numerous hosted models. FIRST supports multiple inference backends (e.g., vLLM), auto-scales resources, maintains \"hot\" nodes for low-latency execution, and offers both high-throughput batch and interactive modes. The framework addresses the growing demand for private, secure, and scalable AI inference in scientific workflows, allowing researchers to generate billions of tokens daily on-premises without relying on commercial cloud infrastructure.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†FIRSTï¼ˆFederated Inference Resource Scheduling Toolkitï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºåˆ†å¸ƒå¼é«˜æ€§èƒ½è®¡ç®—ï¼ˆHPCï¼‰é›†ç¾¤è®¾è®¡çš„æ¨ç†å³æœåŠ¡ï¼ˆInference-as-a-Serviceï¼‰æ¡†æ¶ã€‚è¯¥ç³»ç»Ÿæ—¨åœ¨é€šè¿‡ç°æœ‰çš„HPCåŸºç¡€è®¾æ–½ï¼Œä¸ºç§‘ç ”äººå‘˜æä¾›ç±»ä¼¼äº‘ç«¯çš„Large Language Models (LLMs)ç­‰å¤šç§AIæ¨¡å‹çš„è®¿é—®èƒ½åŠ›ã€‚FIRSTåˆ©ç”¨Globus Authå’ŒGlobus ComputeæŠ€æœ¯ï¼Œé€šè¿‡å…¼å®¹OpenAIæ ‡å‡†çš„APIï¼Œå…è®¸åœ¨ç§æœ‰ä¸”å®‰å…¨çš„ç¯å¢ƒä¸­æ‰§è¡Œå¹¶è¡Œæ¨ç†ä»»åŠ¡ã€‚è¯¥æ¡†æ¶æ”¯æŒåŒ…æ‹¬vLLMåœ¨å†…çš„å¤šç§æ¨ç†åç«¯ï¼Œå…·å¤‡è‡ªåŠ¨ç¼©æ”¾ï¼ˆauto-scalesï¼‰åŠŸèƒ½ï¼Œå¹¶é€šè¿‡ç»´æŒâ€œçƒ­â€èŠ‚ç‚¹ï¼ˆhot nodesï¼‰ç¡®ä¿ä½å»¶è¿Ÿæ‰§è¡Œã€‚å®ƒåŒæ—¶æä¾›é«˜ååé‡æ‰¹å¤„ç†å’Œäº¤äº’å¼æ¨¡å¼ï¼Œæœ‰æ•ˆè§£å†³äº†ç§‘å­¦å·¥ä½œæµä¸­å¯¹ç§æœ‰ã€å®‰å…¨åŠå¯æ‰©å±•AIæ¨ç†çš„éœ€æ±‚ã€‚è¯¥æ¡†æ¶å…è®¸ç ”ç©¶äººå‘˜åœ¨æœ¬åœ°ç¯å¢ƒä¸­æ¯æ—¥ç”Ÿæˆæ•°åäº¿ä¸ªtokenï¼Œä½¿å…¶åœ¨ä¸ä¾èµ–å•†ä¸šäº‘åŸºç¡€è®¾æ–½çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å®ç°å¤§è§„æ¨¡AIæ¨æ–­ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13724v1",
      "published_date": "2025-10-15 16:28:34 UTC",
      "updated_date": "2025-10-15 16:28:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:14.187497+00:00"
    },
    {
      "arxiv_id": "2510.13721v2",
      "title": "NExT-OMNI: Towards Any-to-Any Omnimodal Foundation Models with Discrete Flow Matching",
      "title_zh": "NExT-OMNIï¼šåŸºäºç¦»æ•£æµåŒ¹é…è¿ˆå‘ä»»æ„åˆ°ä»»æ„å…¨æ¨¡æ€åŸºç¡€æ¨¡å‹",
      "authors": [
        "Run Luo",
        "Xiaobo Xia",
        "Lu Wang",
        "Longze Chen",
        "Renke Shan",
        "Jing Luo",
        "Min Yang",
        "Tat-Seng Chua"
      ],
      "abstract": "Next-generation multimodal foundation models capable of any-to-any cross-modal generation and multi-turn interaction will serve as core components of artificial general intelligence systems, playing a pivotal role in human-machine interaction. However, most existing multimodal models remain constrained by autoregressive architectures, whose inherent limitations prevent a balanced integration of understanding and generation capabilities. Although hybrid and decoupling strategies have been explored to address these tasks within unified frameworks separately, their redundant, non-integrated designs limit their applicability to broader scenarios, such as cross-modal retrieval. In this work, we introduce NExT-OMNI, an open-source omnimodal foundation model that achieves unified modeling through discrete flow paradigms. By leveraging metric-induced probability paths and kinetic optimal velocities, NExT-OMNI natively supports any-to-any understanding and generation with enhanced response efficiency, while enabling broader application scenarios through concise unified representations rather than task-decoupled designs. Trained on large-scale interleaved text, image, video, and audio data, NExT-OMNI delivers competitive performance on multimodal generation and understanding benchmarks, while outperforming prior unified models in multi-turn multimodal interaction and cross-modal retrieval, highlighting its architectural advantages as a next-generation multimodal foundation model. To advance further research, we release training details, data protocols, and open-source both the code and model checkpoints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å¤§æ¨¡å‹åœ¨è·¨æ¨¡æ€ç”Ÿæˆä¸å¤šè½®äº¤äº’ä¸­å—é™äºè‡ªå›å½’(Autoregressive)æ¶æ„ï¼Œå¯¼è‡´ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›éš¾ä»¥å¹³è¡¡çš„é—®é¢˜ï¼Œæå‡ºäº†å¼€æºçš„å…¨æ¨¡æ€åŸºç¡€æ¨¡å‹ NExT-OMNIã€‚è¯¥æ¨¡å‹é€šè¿‡ç¦»æ•£æµ(Discrete Flow)èŒƒå¼å®ç°äº†ç»Ÿä¸€å»ºæ¨¡ï¼Œåˆ©ç”¨åº¦é‡è¯±å¯¼æ¦‚ç‡è·¯å¾„å’ŒåŠ¨åŠ›å­¦æœ€ä¼˜é€Ÿåº¦ï¼Œåœ¨åŸç”Ÿå±‚é¢æ”¯æŒä»»æ„æ¨¡æ€åˆ°ä»»æ„æ¨¡æ€(Any-to-Any)çš„ç†è§£ä¸ç”Ÿæˆã€‚ä¸ä¼ ç»Ÿçš„ä»»åŠ¡è§£è€¦è®¾è®¡ä¸åŒï¼ŒNExT-OMNI é‡‡ç”¨ç®€æ´çš„ç»Ÿä¸€è¡¨ç¤ºï¼Œåœ¨æå‡å“åº”æ•ˆç‡çš„åŒæ—¶ï¼Œæ˜¾è‘—å¢å¼ºäº†è·¨æ¨¡æ€æ£€ç´¢(Cross-modal Retrieval)ç­‰åœºæ™¯çš„é€‚ç”¨æ€§ã€‚åŸºäºå¤§è§„æ¨¡æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘äº¤é”™æ•°æ®çš„è®­ç»ƒï¼ŒNExT-OMNI åœ¨å¤šæ¨¡æ€ç”Ÿæˆä¸ç†è§£åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºæå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚å®éªŒè¯æ˜å…¶åœ¨å¤šè½®å¤šæ¨¡æ€äº¤äº’åŠè·¨æ¨¡æ€æ£€ç´¢æ–¹é¢ä¼˜äºå…ˆå‰çš„ç»Ÿä¸€æ¨¡å‹ï¼Œå……åˆ†ä½“ç°äº†å…¶ä½œä¸ºä¸‹ä¸€ä»£å¤šæ¨¡æ€åŸºç¡€æ¨¡å‹çš„æ¶æ„ä¼˜åŠ¿ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶å·²å…¬å¼€ç›¸å…³è®­ç»ƒç»†èŠ‚ã€æ•°æ®åè®®åŠæ¨¡å‹æƒé‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13721v2",
      "published_date": "2025-10-15 16:25:18 UTC",
      "updated_date": "2025-10-16 01:08:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:18.892184+00:00"
    },
    {
      "arxiv_id": "2510.13714v2",
      "title": "Dedelayed: Deleting remote inference delay via on-device correction",
      "title_zh": "Dedelayedï¼šé€šè¿‡ç«¯ä¾§çº æ­£æ¶ˆé™¤è¿œç¨‹æ¨ç†å»¶è¿Ÿ",
      "authors": [
        "Dan Jacobellis",
        "Mateen Ulhaq",
        "Fabien RacapÃ©",
        "Hyomin Choi",
        "Neeraja J. Yadwadkar"
      ],
      "abstract": "Video comprises the vast majority of bits that are generated daily, and is the primary signal driving current innovations in robotics, remote sensing, and wearable technology. Yet, the most powerful video understanding models are too expensive for the resource-constrained platforms used in these applications. One approach is to offload inference to the cloud; this gives access to GPUs capable of processing high-resolution videos in real time. But even with reliable, high-bandwidth communication channels, the combined latency of video encoding, model inference, and round-trip communication prohibits use for certain real-time applications. The alternative is to use fully local inference; but this places extreme constraints on computational and power costs, requiring smaller models and lower resolution, leading to degraded accuracy. To address these challenges, we propose Dedelayed, a real-time inference system that divides computation between a remote model operating on delayed video frames and a local model with access to the current frame. The remote model is trained to make predictions on anticipated future frames, which the local model incorporates into its prediction for the current frame. The local and remote models are jointly optimized with an autoencoder that limits the transmission bitrate required by the available downlink communication channel. We evaluate Dedelayed on the task of real-time streaming video segmentation using the BDD100k driving dataset. For a round trip delay of 100 ms, Dedelayed improves performance by 6.4 mIoU compared to fully local inference and 9.8 mIoU compared to remote inference -- an equivalent improvement to using a model ten times larger.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Dedelayedï¼Œä¸€ç§æ—¨åœ¨æ¶ˆé™¤è¿œç¨‹æ¨ç†å»¶è¿Ÿçš„å®æ—¶æ¨ç†ç³»ç»Ÿï¼Œé€šè¿‡è®¾å¤‡ç«¯æ ¡å‡†è§£å†³äº†äº‘ç«¯æ¨ç†å¸¦æ¥çš„é«˜å»¶è¿Ÿä»¥åŠæœ¬åœ°æ¨ç†é¢ä¸´çš„èµ„æºå—é™é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨æ··åˆè®¡ç®—æ¶æ„ï¼Œå°†ä»»åŠ¡åˆ†é…ç»™å¤„ç†å»¶è¿Ÿè§†é¢‘å¸§çš„è¿œç¨‹æ¨¡å‹å’Œå¤„ç†å½“å‰å¸§çš„æœ¬åœ°æ¨¡å‹ï¼Œè¿œç¨‹æ¨¡å‹è´Ÿè´£é¢„æµ‹æœªæ¥å¸§ï¼Œè€Œæœ¬åœ°æ¨¡å‹å°†è¿™äº›é¢„æµ‹æ•´åˆåˆ°å½“å‰æ¨ç†ä¸­ã€‚ç³»ç»Ÿé€šè¿‡è‡ªåŠ¨ç¼–ç å™¨ï¼ˆautoencoderï¼‰è¿›è¡Œè”åˆä¼˜åŒ–ï¼Œä»¥ç¡®ä¿åœ¨æœ‰é™çš„é€šä¿¡å¸¦å®½ä¸‹å®ç°é«˜æ•ˆä¼ è¾“ã€‚åœ¨ BDD100k æ•°æ®é›†ä¸Šçš„å®æ—¶æµè§†é¢‘åˆ†å‰²ï¼ˆstreaming video segmentationï¼‰å®éªŒè¡¨æ˜ï¼Œåœ¨ 100 ms çš„å¾€è¿”å»¶è¿Ÿï¼ˆround trip delayï¼‰ä¸‹ï¼ŒDedelayed ç›¸æ¯”å…¨æœ¬åœ°æ¨ç†æå‡äº† 6.4 mIoUï¼Œç›¸æ¯”è¿œç¨‹æ¨ç†æå‡äº† 9.8 mIoUã€‚è¿™ç§æ€§èƒ½æå‡æ•ˆæœç›¸å½“äºä½¿ç”¨äº†è§„æ¨¡å¤§åå€çš„æ¨¡å‹ï¼Œä¸ºæœºå™¨äººå’Œå¯ç©¿æˆ´è®¾å¤‡ç­‰å¯¹å»¶è¿Ÿæåº¦æ•æ„Ÿçš„åº”ç”¨åœºæ™¯æä¾›äº†é«˜ç²¾åº¦ã€ä½å»¶è¿Ÿçš„è§†é¢‘ç†è§£æ–¹æ¡ˆã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13714v2",
      "published_date": "2025-10-15 16:13:44 UTC",
      "updated_date": "2025-11-14 20:49:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:25.077790+00:00"
    },
    {
      "arxiv_id": "2510.13709v2",
      "title": "Training LLM Agents to Empower Humans",
      "title_zh": "è®­ç»ƒ LLM æ™ºèƒ½ä½“ä»¥èµ‹èƒ½äººç±»",
      "authors": [
        "Evan Ellis",
        "Vivek Myers",
        "Jens Tuyls",
        "Sergey Levine",
        "Anca Dragan",
        "Benjamin Eysenbach"
      ],
      "abstract": "Assistive agents should not only take actions on behalf of a human, but also step out of the way and cede control when there are important decisions to be made. However, current methods for building assistive agents, whether via mimicking expert humans or via RL finetuning on an inferred reward, often encourage agents to complete tasks on their own rather than truly assisting the human attain their objectives. Additionally, these methods often require costly explicit human feedback to provide a training signal. We propose a new approach to tuning assistive language models based on maximizing the human's empowerment, their ability to effect desired changes in the environment. Our empowerment-maximizing method, Empower, only requires offline text data, providing a self-supervised method for fine-tuning language models to better assist humans. To study the efficacy of our approach, we conducted an 18-person user study comparing our empowerment assistant with a strong baseline. Participants preferred our assistant 78% of the time (p=0.015), with a 31% higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a new environment for evaluating multi-turn code assistance using simulated humans. Using this environment, we show that agents trained with Empower increase the success rate of a simulated human programmer on challenging coding questions by an average of 192% over an SFT baseline. With this empowerment objective, we provide a framework for useful aligned AI agents at scale using only offline data without the need for any additional human feedback or verifiable rewards.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºEmpowerçš„å¾®è°ƒæ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡æœ€å¤§åŒ–äººç±»çš„èµ‹æƒ(Empowerment)æ¥è®­ç»ƒLLMæ™ºèƒ½ä½“ï¼Œä½¿å…¶æ›´æœ‰æ•ˆåœ°ååŠ©äººç±»è€Œéå®Œå…¨æ¥ç®¡æ§åˆ¶ã€‚é’ˆå¯¹ç°æœ‰è¾…åŠ©æ™ºèƒ½ä½“å€¾å‘äºç‹¬ç«‹å®Œæˆä»»åŠ¡ä¸”ä¾èµ–é«˜æˆæœ¬äººç±»åé¦ˆçš„é—®é¢˜ï¼ŒEmpoweråˆ©ç”¨ç¦»çº¿æ–‡æœ¬æ•°æ®å®ç°è‡ªç›‘ç£å­¦ä¹ ï¼Œé‡ç‚¹æå‡äººç±»åœ¨ç¯å¢ƒä¸­å®ç°é¢„æœŸç›®æ ‡çš„èƒ½åŠ›ã€‚åœ¨18äººçš„ç”¨æˆ·ç ”ç©¶ä¸­ï¼Œè¯¥åŠ©æ‰‹è·å¾—äº†78%çš„å‚ä¸è€…åå¥½ï¼Œå…¶æ¥å—ç‡æ¯”å¼ºåŸºçº¿æ¨¡å‹é«˜å‡º31%ï¼Œä¸”éœ€è¦çš„ä¿®æ”¹å»ºè®®å‡å°‘äº†38%ã€‚æ­¤å¤–ï¼Œåœ¨å¤šè½®ä»£ç è¾…åŠ©(multi-turn code assistance)ç¯å¢ƒä¸‹çš„æ¨¡æ‹Ÿå®éªŒæ˜¾ç¤ºï¼ŒEmpowerå°†æ¨¡æ‹Ÿç¨‹åºå‘˜è§£å†³æŒ‘æˆ˜æ€§é—®é¢˜çš„æˆåŠŸç‡ç›¸æ¯”SFTåŸºçº¿å¹³å‡æå‡äº†192%ã€‚è¯¥æ¡†æ¶è¯æ˜äº†ä»…åˆ©ç”¨ç¦»çº¿æ•°æ®å³å¯æ„å»ºåœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹å¯¹é½ä¸”å®ç”¨çš„AIæ™ºèƒ½ä½“ï¼Œæ— éœ€é¢å¤–çš„äººç±»åé¦ˆæˆ–å¯éªŒè¯çš„å¥–åŠ±(verifiable rewards)ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13709v2",
      "published_date": "2025-10-15 16:09:33 UTC",
      "updated_date": "2025-10-16 03:39:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:39.998830+00:00"
    },
    {
      "arxiv_id": "2510.13704v1",
      "title": "Simplicial Embeddings Improve Sample Efficiency in Actor-Critic Agents",
      "title_zh": "å•çº¯å½¢åµŒå…¥æå‡ Actor-Critic æ™ºèƒ½ä½“çš„æ ·æœ¬æ•ˆç‡",
      "authors": [
        "Johan Obando-Ceron",
        "Walter Mayor",
        "Samuel Lavoie",
        "Scott Fujimoto",
        "Aaron Courville",
        "Pablo Samuel Castro"
      ],
      "abstract": "Recent works have proposed accelerating the wall-clock training time of actor-critic methods via the use of large-scale environment parallelization; unfortunately, these can sometimes still require large number of environment interactions to achieve a desired level of performance. Noting that well-structured representations can improve the generalization and sample efficiency of deep reinforcement learning (RL) agents, we propose the use of simplicial embeddings: lightweight representation layers that constrain embeddings to simplicial structures. This geometric inductive bias results in sparse and discrete features that stabilize critic bootstrapping and strengthen policy gradients. When applied to FastTD3, FastSAC, and PPO, simplicial embeddings consistently improve sample efficiency and final performance across a variety of continuous- and discrete-control environments, without any loss in runtime speed.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡ä¼˜åŒ–è¡¨å¾ç»“æ„æ¥æé«˜æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)æ™ºèƒ½ä½“çš„æ³›åŒ–èƒ½åŠ›å’Œæ ·æœ¬æ•ˆç‡(sample efficiency)ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†simplicial embeddingsï¼Œè¿™æ˜¯ä¸€ç§å°†åµŒå…¥(embeddings)çº¦æŸä¸ºå•çº¯å½¢ç»“æ„(simplicial structures)çš„è½»é‡çº§è¡¨å¾å±‚ã€‚è¿™ç§å‡ ä½•å½’çº³åç½®(geometric inductive bias)èƒ½å¤Ÿäº§ç”Ÿç¨€ç–ä¸”ç¦»æ•£çš„ç‰¹å¾ï¼Œä»è€Œæœ‰æ•ˆç¨³å®šè¯„è®ºè€…å¼•å¯¼(critic bootstrapping)å¹¶å¢å¼ºç­–ç•¥æ¢¯åº¦(policy gradients)ã€‚å®éªŒè¡¨æ˜ï¼Œå°†è¯¥æ–¹æ³•åº”ç”¨äºFastTD3ã€FastSACå’ŒPPOç®—æ³•åï¼Œåœ¨å¤šç§è¿ç»­å’Œç¦»æ•£æ§åˆ¶ç¯å¢ƒä¸­å‡æ˜¾è‘—æå‡äº†æ™ºèƒ½ä½“çš„æ ·æœ¬æ•ˆç‡å’Œæœ€ç»ˆæ€§èƒ½ã€‚æ­¤å¤–ï¼Œsimplicial embeddingsåœ¨ä¼˜åŒ–æ€§èƒ½çš„åŒæ—¶ï¼Œå¹¶æ²¡æœ‰å¸¦æ¥ä»»ä½•è¿è¡Œé€Ÿåº¦ä¸Šçš„é¢å¤–å¼€é”€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13704v1",
      "published_date": "2025-10-15 16:01:30 UTC",
      "updated_date": "2025-10-15 16:01:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:41.674256+00:00"
    },
    {
      "arxiv_id": "2510.13702v1",
      "title": "MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion",
      "title_zh": "MVCustomï¼šåŸºäºå‡ ä½•æ½œç©ºé—´æ¸²æŸ“ä¸è¡¥å…¨çš„å¤šè§†è§’å®šåˆ¶åŒ–æ‰©æ•£",
      "authors": [
        "Minjung Shin",
        "Hyunin Cho",
        "Sooyeon Go",
        "Jin-Hwa Kim",
        "Youngjung Uh"
      ],
      "abstract": "Multi-view generation with camera pose control and prompt-based customization are both essential elements for achieving controllable generative models. However, existing multi-view generation models do not support customization with geometric consistency, whereas customization models lack explicit viewpoint control, making them challenging to unify. Motivated by these gaps, we introduce a novel task, multi-view customization, which aims to jointly achieve multi-view camera pose control and customization. Due to the scarcity of training data in customization, existing multi-view generation models, which inherently rely on large-scale datasets, struggle to generalize to diverse prompts. To address this, we propose MVCustom, a novel diffusion-based framework explicitly designed to achieve both multi-view consistency and customization fidelity. In the training stage, MVCustom learns the subject's identity and geometry using a feature-field representation, incorporating the text-to-video diffusion backbone enhanced with dense spatio-temporal attention, which leverages temporal coherence for multi-view consistency. In the inference stage, we introduce two novel techniques: depth-aware feature rendering explicitly enforces geometric consistency, and consistent-aware latent completion ensures accurate perspective alignment of the customized subject and surrounding backgrounds. Extensive experiments demonstrate that MVCustom is the only framework that simultaneously achieves faithful multi-view generation and customization.",
      "tldr_zh": "é’ˆå¯¹ç°æœ‰æ¨¡å‹éš¾ä»¥åŒæ—¶å…¼é¡¾å¤šè§†è§’å‡ ä½•ä¸€è‡´æ€§ä¸åŸºäºæç¤ºè¯çš„å®šåˆ¶åŒ–ç”Ÿæˆè¿™ä¸€éš¾é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº† MVCustom æ¡†æ¶ã€‚è¿™æ˜¯ä¸€ä¸ªåŸºäºæ‰©æ•£æ¨¡å‹(Diffusion)çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨è”åˆå®ç°å¤šè§†è§’ç›¸æœºä½å§¿æ§åˆ¶ä¸ä¸»ä½“å®šåˆ¶åŒ–ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼ŒMVCustom åˆ©ç”¨ç‰¹å¾åœº(Feature-Field)è¡¨ç¤ºæ¥å­¦ä¹ ä¸»ä½“çš„èº«ä»½ç‰¹å¾ä¸å‡ ä½•ç»“æ„ï¼Œå¹¶ç»“åˆå¢å¼ºå‹æ–‡æœ¬åˆ°è§†é¢‘(Text-to-Video)æ‰©æ•£éª¨æ¶ï¼Œé€šè¿‡ç¨ å¯†æ—¶ç©ºæ³¨æ„åŠ›(Dense Spatio-Temporal Attention)åˆ©ç”¨æ—¶é—´ç›¸å¹²æ€§ç¡®ä¿å¤šè§†è§’ä¸€è‡´æ€§ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†æ·±åº¦æ„ŸçŸ¥ç‰¹å¾æ¸²æŸ“(Depth-aware Feature Rendering)ä»¥æ˜¾å¼å¼ºåŒ–å‡ ä½•ä¸€è‡´æ€§ï¼Œå¹¶åˆ©ç”¨ä¸€è‡´æ€§æ„ŸçŸ¥æ½œç©ºé—´è¡¥å…¨(Consistent-aware Latent Completion)ç¡®ä¿å®šåˆ¶ä¸»ä½“ä¸èƒŒæ™¯åœ¨é€è§†ä¸Šçš„ç²¾å‡†å¯¹é½ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒMVCustom æ˜¯ç›®å‰å”¯ä¸€èƒ½å¤ŸåŒæ—¶å®ç°é«˜ä¿çœŸå¤šè§†è§’ç”Ÿæˆä¸ç²¾å‡†ä¸»ä½“å®šåˆ¶çš„æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†å®šåˆ¶åŒ–æ•°æ®ç¨€ç¼ºå¯¼è‡´çš„æ³›åŒ–æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://minjung-s.github.io/mvcustom",
      "pdf_url": "https://arxiv.org/pdf/2510.13702v1",
      "published_date": "2025-10-15 16:00:26 UTC",
      "updated_date": "2025-10-15 16:00:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:44.183540+00:00"
    },
    {
      "arxiv_id": "2510.13935v2",
      "title": "Big Reasoning with Small Models: Instruction Retrieval at Inference Time",
      "title_zh": "å°æ¨¡å‹å®ç°å¤§æ¨ç†ï¼šæ¨ç†é˜¶æ®µçš„æŒ‡ä»¤æ£€ç´¢",
      "authors": [
        "Kenan Alkiek",
        "David Jurgens",
        "Vinod Vydiswaran"
      ],
      "abstract": "Small language models (SLMs) enable low-cost, private, on-device inference, but they often fail on problems that require specialized domain knowledge or multi-step reasoning. Existing approaches for improving reasoning either rely on scale (e.g., chain-of-thought prompting), require task-specific training that limits reuse and generality (e.g., distillation), or retrieve unstructured information that still leaves the SLM to determine an appropriate reasoning strategy. We propose instruction retrieval, an inference-time intervention that augments an SLM with structured, reusable reasoning procedures rather than raw passages. We construct an Instruction Corpus by clustering similar training questions and using a teacher model to generate generalizable guides that pair domain background with explicit step-by-step procedures. At inference, the SLM retrieves the instructions most relevant to a given query and executes the associated procedures without any additional fine-tuning. Across three challenging domains: medicine, law, and mathematics, instruction retrieval yields consistent gains for models with at least 3B parameters, improving accuracy by 9.4%, 7.9%, and 5.1%, respectively, with the strongest 14B model surpassing GPT-4o's zero-shot performance on knowledge-intensive tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°å‹è¯­è¨€æ¨¡å‹ (SLMs) åœ¨å¤„ç†é¢†åŸŸçŸ¥è¯†å’Œå¤šæ­¥æ¨ç†æ—¶é¢ä¸´çš„å±€é™ï¼Œæå‡ºäº†ä¸€ç§åä¸º Instruction Retrieval çš„æ¨ç†é˜¶æ®µå¹²é¢„æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸º SLMs æä¾›ç»“æ„åŒ–ã€å¯é‡ç”¨çš„æ¨ç†ç¨‹åºè€Œéä¼ ç»Ÿçš„åŸå§‹æ–‡æœ¬ç‰‡æ®µï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æ‰§è¡Œèƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº†ä¸€ä¸ª Instruction Corpusï¼Œåˆ©ç”¨èšç±»æŠ€æœ¯å’Œå¯¼å¸ˆæ¨¡å‹ç”ŸæˆåŒ…å«é¢†åŸŸèƒŒæ™¯åŠå…·ä½“æ­¥éª¤çš„é€šç”¨æŒ‡å—ã€‚åœ¨æ¨ç†é˜¶æ®µï¼ŒSLMs èƒ½å¤Ÿç›´æ¥æ£€ç´¢ç›¸å…³æŒ‡ä»¤å¹¶æ‰§è¡Œç¨‹åºï¼Œä¸”æ— éœ€è¿›è¡Œä»»ä½•é¢å¤–çš„å¾®è°ƒ (fine-tuning)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨åŒ»å­¦ã€æ³•å¾‹å’Œæ•°å­¦é¢†åŸŸï¼Œè¯¥æ–¹æ³•ä½¿å‚æ•°é‡åœ¨ 3B ä»¥ä¸Šçš„æ¨¡å‹å‡†ç¡®ç‡åˆ†åˆ«æå‡äº† 9.4%ã€7.9% å’Œ 5.1%ã€‚å…¶ä¸­è¡¨ç°æœ€å¼ºçš„ 14B æ¨¡å‹åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸Šç”šè‡³è¶…è¶Šäº† GPT-4o çš„ zero-shot æ€§èƒ½ï¼Œè¯æ˜äº†åœ¨ä¸å¢åŠ æ¨¡å‹è§„æ¨¡çš„æƒ…å†µä¸‹å®ç°å¤æ‚æ¨ç†çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13935v2",
      "published_date": "2025-10-15 15:51:13 UTC",
      "updated_date": "2026-01-07 14:13:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:46.127855+00:00"
    },
    {
      "arxiv_id": "2510.13691v1",
      "title": "A Modal Logic for Temporal and Jurisdictional Classifier Models",
      "title_zh": "é’ˆå¯¹æ—¶åºæ€§ä¸ç®¡è¾–æƒåˆ†ç±»å™¨æ¨¡å‹çš„æ¨¡æ€é€»è¾‘",
      "authors": [
        "Cecilia Di Florio",
        "Huimin Dong",
        "Antonino Rotolo"
      ],
      "abstract": "Logic-based models can be used to build verification tools for machine learning classifiers employed in the legal field. ML classifiers predict the outcomes of new cases based on previous ones, thereby performing a form of case-based reasoning (CBR). In this paper, we introduce a modal logic of classifiers designed to formally capture legal CBR. We incorporate principles for resolving conflicts between precedents, by introducing into the logic the temporal dimension of cases and the hierarchy of courts within the legal system.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ³•å¾‹é¢†åŸŸçš„ Machine Learning åˆ†ç±»å™¨ï¼Œå¼•å…¥äº†ä¸€ç§æ—¨åœ¨å½¢å¼åŒ–æ•æ‰æ³•å¾‹ Case-Based Reasoning (CBR) çš„ Modal Logicã€‚ç”±äºæ³•å¾‹åˆ†ç±»å™¨é€šè¿‡å†å²åˆ¤ä¾‹é¢„æµ‹æ–°æ¡ˆä¾‹ç»“æœï¼Œå®è´¨ä¸Šæ˜¯åœ¨æ‰§è¡Œæ¡ˆä¾‹æ¨ç†ï¼Œè¯¥é€»è¾‘æ¨¡å‹å¯ä¸ºæ­¤ç±»åˆ†ç±»å™¨çš„éªŒè¯å·¥å…·å¼€å‘æä¾›æ”¯æ’‘ã€‚æœ¬æ–‡æå‡ºçš„æ¡†æ¶é€šè¿‡åœ¨é€»è¾‘ä¸­å¼•å…¥æ¡ˆä¾‹çš„ Temporal Dimension ä»¥åŠæ³•å¾‹ä½“ç³»ä¸­çš„ Hierarchy of Courtsï¼ŒæˆåŠŸçº³å…¥äº†è§£å†³å…ˆä¾‹å†²çªçš„å…³é”®æ³•å¾‹åŸåˆ™ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿç²¾ç¡®æè¿°å—æ—¶é—´å’Œç®¡è¾–æƒçº¦æŸçš„åˆ†ç±»å™¨è¡Œä¸ºï¼Œä¸ºæ³•å¾‹è‡ªåŠ¨åŒ–å†³ç­–ç³»ç»Ÿçš„åˆè§„æ€§ä¸å¯é æ€§æä¾›äº†ä¸¥è°¨çš„å½¢å¼åŒ–éªŒè¯åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 2 figures. Extended version of a short paper accepted at PRIMA 2025. This is the authors' version of the work. It is posted here for your personal use",
      "pdf_url": "https://arxiv.org/pdf/2510.13691v1",
      "published_date": "2025-10-15 15:50:04 UTC",
      "updated_date": "2025-10-15 15:50:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:00.279012+00:00"
    },
    {
      "arxiv_id": "2510.13669v1",
      "title": "CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas",
      "title_zh": "CanvasMARï¼šåˆ©ç”¨ç”»å¸ƒæ”¹è¿›æ©ç è‡ªå›å½’è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Zian Li",
        "Muhan Zhang"
      ],
      "abstract": "Masked autoregressive models (MAR) have recently emerged as a powerful paradigm for image and video generation, combining the flexibility of masked modeling with the potential of continuous tokenizer. However, video MAR models suffer from two major limitations: the slow-start problem, caused by the lack of a structured global prior at early sampling stages, and error accumulation across the autoregression in both spatial and temporal dimensions. In this work, we propose CanvasMAR, a novel video MAR model that mitigates these issues by introducing a canvas mechanism--a blurred, global prediction of the next frame, used as the starting point for masked generation. The canvas provides global structure early in sampling, enabling faster and more coherent frame synthesis. Furthermore, we introduce compositional classifier-free guidance that jointly enlarges spatial (canvas) and temporal conditioning, and employ noise-based canvas augmentation to enhance robustness. Experiments on the BAIR and Kinetics-600 benchmarks demonstrate that CanvasMAR produces high-quality videos with fewer autoregressive steps. Our approach achieves remarkable performance among autoregressive models on Kinetics-600 dataset and rivals diffusion-based methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CanvasMARï¼Œä¸€ç§æ—¨åœ¨æ”¹è¿›æ©ç è‡ªå›å½’ï¼ˆMasked Autoregressive, MARï¼‰è§†é¢‘ç”Ÿæˆæ¨¡å‹çš„æ–°æ¶æ„ã€‚ä¸ºäº†è§£å†³è§†é¢‘ MAR æ¨¡å‹ä¸­æ™®éå­˜åœ¨çš„èµ·æ­¥æ…¢ï¼ˆslow-startï¼‰ä»¥åŠè·¨æ—¶ç©ºç»´åº¦çš„è¯¯å·®ç§¯ç´¯ï¼ˆerror accumulationï¼‰ç­‰æ ¸å¿ƒæŒ‘æˆ˜ï¼ŒCanvasMAR å¼•å…¥äº†ä¸€ç§ç”»å¸ƒæœºåˆ¶ï¼ˆcanvas mechanismï¼‰ï¼Œåˆ©ç”¨ä¸‹ä¸€å¸§çš„æ¨¡ç³Šå…¨å±€é¢„æµ‹ä½œä¸ºç”Ÿæˆèµ·ç‚¹ã€‚è¯¥æœºåˆ¶åœ¨é‡‡æ ·æ—©æœŸæä¾›äº†å¿…è¦çš„å…¨å±€ç»“æ„ï¼Œä»è€Œå®ç°äº†æ›´å¿«é€Ÿä¸”è¿è´¯çš„å¸§åˆæˆã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº†ç»„åˆå¼æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆcompositional classifier-free guidanceï¼‰ä»¥è”åˆå¢å¼ºç©ºé—´ä¸æ—¶é—´çº¦æŸï¼Œå¹¶é‡‡ç”¨åŸºäºå™ªå£°çš„ç”»å¸ƒå¢å¼ºï¼ˆnoise-based canvas augmentationï¼‰æ¥æå‡ç³»ç»Ÿé²æ£’æ€§ã€‚åœ¨ BAIR å’Œ Kinetics-600 åŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCanvasMAR èƒ½å¤Ÿä»¥æ›´å°‘çš„è‡ªå›å½’æ­¥éª¤ç”Ÿæˆé«˜è´¨é‡è§†é¢‘ã€‚è¯¥æ–¹æ³•åœ¨ Kinetics-600 æ•°æ®é›†ä¸Šå–å¾—äº†å“è¶Šçš„æ€§èƒ½ï¼Œå…¶è¡¨ç°ä¸ä»…åœ¨è‡ªå›å½’æ¨¡å‹ä¸­ååˆ—å‰èŒ…ï¼Œä¸”è¶³ä»¥ä¸ä¸»æµçš„æ‰©æ•£æ¨¡å‹ï¼ˆdiffusion-based methodsï¼‰ç›¸åª²ç¾ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13669v1",
      "published_date": "2025-10-15 15:29:09 UTC",
      "updated_date": "2025-10-15 15:29:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:52.485947+00:00"
    },
    {
      "arxiv_id": "2510.13665v2",
      "title": "Axial Neural Networks for Dimension-Free Foundation Models",
      "title_zh": "è½´å‘ç¥ç»ç½‘ç»œï¼šé¢å‘æ— ç»´åº¦é™åˆ¶çš„åŸºç¡€æ¨¡å‹",
      "authors": [
        "Hyunsu Kim",
        "Jonggeon Park",
        "Joan Bruna",
        "Hongseok Yang",
        "Juho Lee"
      ],
      "abstract": "The advent of foundation models in AI has significantly advanced general-purpose learning, enabling remarkable capabilities in zero-shot inference and in-context learning. However, training such models on physics data, including solutions to partial differential equations (PDEs), poses a unique challenge due to varying dimensionalities across different systems. Traditional approaches either fix a maximum dimension or employ separate encoders for different dimensionalities, resulting in inefficiencies. To address this, we propose a dimension-agnostic neural network architecture, the Axial Neural Network (XNN), inspired by parameter-sharing structures such as Deep Sets and Graph Neural Networks. XNN generalizes across varying tensor dimensions while maintaining computational efficiency. We convert existing PDE foundation models into axial neural networks and evaluate their performance across three training scenarios: training from scratch, pretraining on multiple PDEs, and fine-tuning on a single PDE. Our experiments show that XNNs perform competitively with original models and exhibit superior generalization to unseen dimensions, highlighting the importance of multidimensional pretraining for foundation models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰©ç†æ•°æ®ï¼ˆå¦‚åå¾®åˆ†æ–¹ç¨‹ PDEsï¼‰è®­ç»ƒåŸºç¡€æ¨¡å‹æ—¶é¢ä¸´çš„ä¸åŒç»´åº¦æŒ‘æˆ˜ï¼Œæå‡ºäº†è½´å‘ç¥ç»ç½‘ç»œ (Axial Neural Network, XNN)ã€‚XNN æ˜¯ä¸€ç§ä¸ç»´åº¦æ— å…³çš„ç¥ç»ç½‘ç»œæ¶æ„ï¼Œå…¶çµæ„Ÿæºè‡ª Deep Sets å’Œå›¾ç¥ç»ç½‘ç»œ (Graph Neural Networks) ç­‰å‚æ•°å…±äº«ç»“æ„ï¼Œèƒ½å¤Ÿè·¨ä¸åŒå¼ é‡ç»´åº¦è¿›è¡Œæ³›åŒ–å¹¶ä¿æŒè®¡ç®—æ•ˆç‡ã€‚ç ”ç©¶äººå‘˜å°†ç°æœ‰çš„ PDE åŸºç¡€æ¨¡å‹è½¬æ¢ä¸ºè½´å‘ç¥ç»ç½‘ç»œï¼Œå¹¶åœ¨ä»å¤´è®­ç»ƒã€å¤š PDE é¢„è®­ç»ƒå’Œå• PDE å¾®è°ƒä¸‰ç§åœºæ™¯ä¸‹è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒXNN çš„æ€§èƒ½ä¸åŸå§‹æ¨¡å‹ç›¸å½“ï¼Œå¹¶ä¸”åœ¨æœªè§ç»´åº¦ä¸Šè¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å¤šç»´åº¦é¢„è®­ç»ƒå¯¹äºæ„å»ºè·¨ç»´åº¦é€šç”¨åŸºç¡€æ¨¡å‹çš„é‡è¦æ€§ï¼Œä¸ºå¤„ç†å˜ç»´ç‰©ç†ç³»ç»Ÿæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13665v2",
      "published_date": "2025-10-15 15:25:20 UTC",
      "updated_date": "2025-10-24 12:06:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:54.996179+00:00"
    },
    {
      "arxiv_id": "2510.13654v1",
      "title": "Time Series Foundation Models: Benchmarking Challenges and Requirements",
      "title_zh": "æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ï¼šåŸºå‡†è¯„ä¼°çš„æŒ‘æˆ˜ä¸è¦æ±‚",
      "authors": [
        "Marcel Meyer",
        "Sascha Kaltenpoth",
        "Kevin Zalipski",
        "Oliver MÃ¼ller"
      ],
      "abstract": "Time Series Foundation Models (TSFMs) represent a new paradigm for time series forecasting, offering zero-shot forecasting capabilities without the need for domain-specific pre-training or fine-tuning. However, as with Large Language Models (LLMs), evaluating TSFMs is tricky, as with ever more extensive training sets, it becomes more and more challenging to ensure the integrity of benchmarking data. Our investigation of existing TSFM evaluation highlights multiple challenges, ranging from the representativeness of the benchmark datasets, over the lack of spatiotemporal evaluation, to risks of information leakage due to overlapping and obscure datasets, and the memorization of global patterns caused by external shocks like economic crises or pandemics. Our findings reveal widespread confusion regarding data partitions, risking inflated performance estimates and incorrect transfer of global knowledge to local time series. We argue for the development of robust evaluation methodologies to prevent pitfalls already observed in LLM and classical time series benchmarking, and call upon the research community to design new, principled approaches, such as evaluations on truly out-of-sample future data, to safeguard the integrity of TSFM assessment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹ (Time Series Foundation Models, TSFMs) åœ¨é›¶æ ·æœ¬é¢„æµ‹ (zero-shot forecasting) æ–¹é¢çš„æ–°èŒƒå¼ï¼Œé‡ç‚¹åˆ†æäº†è¯„ä¼°è¿™äº›æ¨¡å‹æ—¶é¢ä¸´çš„ä¸¥å³»æŒ‘æˆ˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œç”±äºè®­ç»ƒæ•°æ®é›†æ—¥ç›Šåºå¤§ï¼Œç¡®ä¿åŸºå‡†æµ‹è¯•æ•°æ®çš„å®Œæ•´æ€§å˜å¾—æ„ˆå‘å›°éš¾ï¼Œç›®å‰æ™®éå­˜åœ¨æ•°æ®é›†ä»£è¡¨æ€§ä¸è¶³ã€ç¼ºä¹æ—¶ç©ºè¯„ä¼°ä»¥åŠå› æ•°æ®é›†é‡å å¯¼è‡´çš„ä¿¡æ¯æ³„éœ² (information leakage) ç­‰é—®é¢˜ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œç”±äºå¤–éƒ¨å†²å‡»å¯¼è‡´çš„å…¨å±€æ¨¡å¼è®°å¿† (memorization) å’Œæ•°æ®åˆ’åˆ†æ··æ·†ï¼Œå®¹æ˜“å¯¼è‡´æ¨¡å‹æ€§èƒ½è¯„ä¼°è™šé«˜å¹¶å¼•å‘é”™è¯¯çš„çŸ¥è¯†è¿ç§»ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡å¼ºè°ƒå¿…é¡»å€Ÿé‰´ Large Language Models (LLMs) å’Œä¼ ç»Ÿæ—¶é—´åºåˆ—é¢„æµ‹çš„ç»éªŒï¼Œæ„å»ºæ›´é²æ£’çš„è¯„ä¼°ä½“ç³»ã€‚æœ€åï¼Œä½œè€…å‘¼åç ”ç©¶ç¤¾åŒºé‡‡ç”¨æ›´å…·åŸåˆ™æ€§çš„è¯„ä¼°æ–¹æ³•ï¼Œå¦‚ä½¿ç”¨çœŸå®çš„æ ·æœ¬å¤–æœªæ¥æ•°æ® (out-of-sample future data)ï¼Œä»¥ç»´æŠ¤ TSFM æ€§èƒ½è¯„ä¼°çš„å®Œæ•´æ€§ä¸çœŸå®æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13654v1",
      "published_date": "2025-10-15 15:15:45 UTC",
      "updated_date": "2025-10-15 15:15:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:35:57.705320+00:00"
    },
    {
      "arxiv_id": "2510.13632v1",
      "title": "Closing the Gap Between Text and Speech Understanding in LLMs",
      "title_zh": "å¼¥åˆå¤§è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬ä¸è¯­éŸ³ç†è§£çš„å·®è·",
      "authors": [
        "Santiago Cuervo",
        "Skyler Seto",
        "Maureen de Seyssel",
        "Richard He Bai",
        "Zijin Gu",
        "Tatiana Likhomanenko",
        "Navdeep Jaitly",
        "Zakaria Aldeneh"
      ],
      "abstract": "Large Language Models (LLMs) can be adapted to extend their text capabilities to speech inputs. However, these speech-adapted LLMs consistently underperform their text-based counterparts--and even cascaded pipelines--on language understanding tasks. We term this shortfall the text-speech understanding gap: the performance drop observed when a speech-adapted LLM processes spoken inputs relative to when the original text-based LLM processes the equivalent text. Recent approaches to narrowing this gap either rely on large-scale speech synthesis of text corpora, which is costly and heavily dependent on synthetic data, or on large-scale proprietary speech datasets, which are not reproducible. As a result, there remains a need for more data-efficient alternatives for closing the text-speech understanding gap. In this work, we analyze the gap as driven by two factors: (i) forgetting of text capabilities during adaptation, and (ii) cross-modal misalignment between speech and text. Based on this analysis, we introduce SALAD--Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation--which combines cross-modal distillation with targeted synthetic data to improve alignment while mitigating forgetting. Applied to 3B and 7B LLMs, SALAD achieves competitive performance with a strong open-weight model across broad-domain benchmarks in knowledge, language understanding, and reasoning, while training on over an order of magnitude less speech data from public corpora.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­éŸ³é€‚é…å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­è¨€ç†è§£ä»»åŠ¡ä¸­è¡¨ç°é€Šäºçº¯æ–‡æœ¬æ¨¡å‹çš„â€œæ–‡æœ¬-è¯­éŸ³ç†è§£å·®è·â€(text-speech understanding gap)è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ä½œè€…è®¤ä¸ºè¿™ä¸€å·®è·ä¸»è¦ç”±é€‚é…è¿‡ç¨‹ä¸­çš„æ–‡æœ¬èƒ½åŠ›é—å¿˜(forgetting of text capabilities)ä»¥åŠè¯­éŸ³ä¸æ–‡æœ¬é—´çš„è·¨æ¨¡æ€å¤±é…(cross-modal misalignment)å¼•èµ·ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†åä¸ºSALAD (Sample-efficient Alignment with Learning through Active selection and cross-modal Distillation)çš„æ¡†æ¶ï¼Œé€šè¿‡ç»“åˆè·¨æ¨¡æ€è’¸é¦(cross-modal distillation)å’Œé’ˆå¯¹æ€§çš„åˆæˆæ•°æ®æ¥å¢å¼ºå¯¹é½å¹¶å‡è½»é—å¿˜ã€‚è¯¥æ–¹æ³•è¢«åº”ç”¨äº 3B å’Œ 7B è§„æ¨¡çš„ LLMsï¼Œåœ¨çŸ¥è¯†ã€è¯­è¨€ç†è§£å’Œæ¨ç†ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSALAD ä»…éœ€ä½¿ç”¨å…¬å¼€è¯­æ–™åº“ä¸­ä¸åˆ°ååˆ†ä¹‹ä¸€çš„è¯­éŸ³æ•°æ®ï¼Œå³å¯è¾¾åˆ°ä¸å¼ºåŠ›å¼€æºæ¨¡å‹ç›¸å½“çš„æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œä¸ºç¼©å°æ–‡æœ¬ä¸è¯­éŸ³ç†è§£å·®è·æä¾›äº†ä¸€ç§æå…·æ•°æ®æ•ˆç‡(data-efficient)ä¸”å¯å¤ç°çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13632v1",
      "published_date": "2025-10-15 14:57:16 UTC",
      "updated_date": "2025-10-15 14:57:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:01.878828+00:00"
    },
    {
      "arxiv_id": "2510.13624v1",
      "title": "Unlocking Public Catalogues: Instruction-Tuning LLMs for ICD Coding of German Tumor Diagnoses",
      "title_zh": "é‡Šæ”¾å…¬å…±ç›®å½•æ½œèƒ½ï¼šé’ˆå¯¹å¾·å›½è‚¿ç˜¤è¯Šæ–­ ICD ç¼–ç çš„å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ",
      "authors": [
        "Stefan Lenz",
        "Lakisha Ortiz Rosario",
        "Georg Vollmar",
        "Arsenij Ustjanzew",
        "Fatma Alickovic",
        "Thomas Kindler",
        "Torsten Panholzer"
      ],
      "abstract": "Accurate coding of tumor diagnoses with ICD-10-GM and ICD-O-3 is essential for structured cancer documentation in Germany. Smaller open-weight LLMs are appealing for privacy-preserving automation but often struggle with coding accuracy in German-language contexts. This study investigates whether instruction-based fine-tuning on public datasets improves the coding accuracy of open-weight LLMs for German tumor diagnosis texts. The evaluation uses coded diagnoses from the local tumor documentation system as test data. In a systematic data quality assessment, the upper limit for ICD-10 coding performance was estimated at 60-79% for exact and 81-94% for partial (three-character codes only) derivation. As training data, over 500,000 question-answer pairs were created based on the ICD-10-GM, ICD-O-3, and OPS catalogues. Eight open-weight models from the Qwen, Llama, and Mistral families (7-70 B parameters) were fine-tuned. ICD-10-GM accuracy rose from 1.4-24% to 41-58%, and partial accuracy from 31-74% to 73-83%. The accuracy of ICD-O-3 topography coding also improved but started and remained considerably lower with an exact accuracy of 22-40% and a partial accuracy of 56-67% after fine-tuning. Malformed code outputs dropped to 0% for all models. Tumor-diagnosis recognition reached 99%. Accuracy correlated positively with model size, but gaps between small and large models narrowed after fine-tuning. The reasoning mode in Qwen3 generally yielded a lower performance than fine-tuning and was over 100 times slower. Our findings highlight the potential of leveraging public catalogues to build instruction datasets that improve LLMs in medical documentation tasks. The complete training dataset and the best-performing checkpoints of the fine-tuned models are available from https://huggingface.co/datasets/stefan-m-lenz/ICDOPS-QA-2024.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é€šè¿‡æŒ‡ä»¤å¾®è°ƒ(Instruction-Tuning)å¼€æºå¤§è¯­è¨€æ¨¡å‹(LLMs)æ¥è‡ªåŠ¨å®Œæˆå¾·å›½è‚¿ç˜¤è¯Šæ–­çš„ICD-10-GMå’ŒICD-O-3ç¼–ç ä»»åŠ¡ï¼Œä»¥è§£å†³å°å‹æ¨¡å‹åœ¨å¾·è¯­åŒ»å­¦è¯­å¢ƒä¸‹å‡†ç¡®ç‡ä¸è¶³çš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜åŸºäºICD-10-GMã€ICD-O-3å’ŒOPSç­‰å…¬å…±ç›®å½•æ„å»ºäº†è¶…è¿‡50ä¸‡ä¸ªé—®ç­”å¯¹ï¼Œå¯¹Qwenã€Llamaå’ŒMistralç³»åˆ—çš„8ä¸ªæ¨¡å‹è¿›è¡Œäº†ç³»ç»Ÿæ€§è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå¾®è°ƒä½¿æ¨¡å‹çš„ICD-10-GMç¼–ç å‡†ç¡®ç‡ä»1.4-24%å¤§å¹…æå‡è‡³41-58%ï¼ŒåŒæ—¶å°†æ ¼å¼é”™è¯¯çš„è¾“å‡ºé™è‡³0%ï¼Œè‚¿ç˜¤è¯Šæ–­è¯†åˆ«ç‡è¾¾åˆ°99%ã€‚è™½ç„¶ICD-O-3æ‹“æ‰‘ç¼–ç çš„å‡†ç¡®ç‡æå‡å¹…åº¦ç›¸å¯¹æœ‰é™ï¼Œä½†ç ”ç©¶è¯æ˜äº†æ¨¡å‹è§„æ¨¡ä¸å‡†ç¡®ç‡çš„æ­£ç›¸å…³æ€§ï¼Œä¸”å¾®è°ƒèƒ½æ˜¾è‘—ç¼©å°è½»é‡çº§æ¨¡å‹ä¸å¤§å‹æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®è·ã€‚æ­¤å¤–ï¼Œå¾®è°ƒåœ¨æ€§èƒ½å’Œæ¨ç†é€Ÿåº¦ä¸Šå‡ä¼˜äºQwen3çš„æ¨ç†æ¨¡å¼(Reasoning Mode)ã€‚è¯¥å·¥ä½œé€šè¿‡å…¬å¼€å‘å¸ƒè®­ç»ƒæ•°æ®é›†å’Œæœ€ä½³æ¨¡å‹æƒé‡ï¼Œä¸ºåˆ©ç”¨å…¬å…±ç›®å½•å¢å¼ºLLMsåœ¨åŒ»ç–—æ–‡æ¡£è‡ªåŠ¨åŒ–å¤„ç†é¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13624v1",
      "published_date": "2025-10-15 14:51:28 UTC",
      "updated_date": "2025-10-15 14:51:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:04.381364+00:00"
    },
    {
      "arxiv_id": "2510.13621v1",
      "title": "The Role of Computing Resources in Publishing Foundation Model Research",
      "title_zh": "è®¡ç®—èµ„æºåœ¨åŸºç¡€æ¨¡å‹ç ”ç©¶å‘è¡¨ä¸­çš„ä½œç”¨",
      "authors": [
        "Yuexing Hao",
        "Yue Huang",
        "Haoran Zhang",
        "Chenyang Zhao",
        "Zhenwen Liang",
        "Paul Pu Liang",
        "Yue Zhao",
        "Lichao Sun",
        "Saleh Kalantari",
        "Xiangliang Zhang",
        "Marzyeh Ghassemi"
      ],
      "abstract": "Cutting-edge research in Artificial Intelligence (AI) requires considerable resources, including Graphics Processing Units (GPUs), data, and human resources. In this paper, we evaluate of the relationship between these resources and the scientific advancement of foundation models (FM). We reviewed 6517 FM papers published between 2022 to 2024, and surveyed 229 first-authors to the impact of computing resources on scientific output. We find that increased computing is correlated with national funding allocations and citations, but our findings don't observe the strong correlations with research environment (academic or industrial), domain, or study methodology. We advise that individuals and institutions focus on creating shared and affordable computing opportunities to lower the entry barrier for under-resourced researchers. These steps can help expand participation in FM research, foster diversity of ideas and contributors, and sustain innovation and progress in AI. The data will be available at: https://mit-calc.csail.mit.edu/",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶è¯„ä¼°äº†è®¡ç®—èµ„æºä¸åŸºç¡€æ¨¡å‹ (Foundation Models) ç§‘å­¦è¿›æ­¥ä¹‹é—´çš„å…³ç³»ï¼Œé€šè¿‡åˆ†æ2022å¹´è‡³2024å¹´é—´å‘è¡¨çš„6517ç¯‡è®ºæ–‡å¹¶å¯¹229ä½ç¬¬ä¸€ä½œè€…è¿›è¡Œè°ƒæŸ¥ï¼Œæ¢è®¨äº†è®¡ç®—èµ„æºå¯¹ç§‘ç ”äº§å‡ºçš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œè®¡ç®—æŠ•å…¥çš„å¢åŠ ä¸å›½å®¶èµ„é‡‘åˆ†é…åŠå¼•ç”¨é‡ (citations) æ˜¾è‘—æ­£ç›¸å…³ï¼Œä½†ä¸ç ”ç©¶ç¯å¢ƒï¼ˆå­¦æœ¯ç•Œæˆ–å·¥ä¸šç•Œï¼‰ã€ç ”ç©¶é¢†åŸŸæˆ–æ–¹æ³•è®ºä¹‹é—´å¹¶æœªè¡¨ç°å‡ºå¼ºç›¸å…³æ€§ã€‚ä½œè€…æŒ‡å‡ºï¼Œä¸ºäº†ç»´æŒäººå·¥æ™ºèƒ½é¢†åŸŸçš„æŒç»­åˆ›æ–°ï¼Œåº”è‡´åŠ›äºæä¾›å…±äº«ä¸”ä½æˆæœ¬çš„è®¡ç®—èµ„æºï¼Œä»è€Œé™ä½èµ„æºåŒ®ä¹ç ”ç©¶è€…çš„å‡†å…¥é—¨æ§›ã€‚è¿™ç§ä¸¾æªæœ‰åŠ©äºæ‰©å¤§ç§‘ç ”å‚ä¸åº¦ï¼Œä¿ƒè¿›æ€æƒ³ä¸è´¡çŒ®è€…çš„å¤šæ ·æ€§ï¼Œæœ€ç»ˆæ¨åŠ¨åŸºç¡€æ¨¡å‹ç ”ç©¶çš„å…¬å¹³å‘å±•ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13621v1",
      "published_date": "2025-10-15 14:50:45 UTC",
      "updated_date": "2025-10-15 14:50:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:17.182358+00:00"
    },
    {
      "arxiv_id": "2510.13615v1",
      "title": "Message Passing on the Edge: Towards Scalable and Expressive GNNs",
      "title_zh": "è¾¹æ¶ˆæ¯ä¼ é€’ï¼šè¿ˆå‘å¯æ‰©å±•ä¸”å…·æœ‰å¼ºè¡¨è¾¾åŠ›çš„å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Pablo BarcelÃ³",
        "Fabian Jogl",
        "Alexander Kozachinskiy",
        "Matthias Lanzinger",
        "Stefan Neumann",
        "CristÃ³bal Rojas"
      ],
      "abstract": "We propose EB-1WL, an edge-based color-refinement test, and a corresponding GNN architecture, EB-GNN. Our architecture is inspired by a classic triangle counting algorithm by Chiba and Nishizeki, and explicitly uses triangles during message passing. We achieve the following results: (1)~EB-1WL is significantly more expressive than 1-WL. Further, we provide a complete logical characterization of EB-1WL based on first-order logic, and matching distinguishability results based on homomorphism counting. (2)~In an important distinction from previous proposals for more expressive GNN architectures, EB-1WL and EB-GNN require near-linear time and memory on practical graph learning tasks. (3)~Empirically, we show that EB-GNN is a highly-efficient general-purpose architecture: It substantially outperforms simple MPNNs, and remains competitive with task-specialized GNNs while being significantly more computationally efficient.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EB-1WLï¼ˆä¸€ç§åŸºäºè¾¹çš„é¢œè‰²ç²¾ç‚¼æµ‹è¯•ï¼‰å’Œç›¸åº”çš„å›¾ç¥ç»ç½‘ç»œæ¶æ„ EB-GNNï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ä¸å¯æ‰©å±•æ€§ã€‚è¯¥æ¶æ„å— Chiba å’Œ Nishizeki çš„ç»å…¸ä¸‰è§’å½¢è®¡æ•°ç®—æ³•å¯å‘ï¼Œåœ¨æ¶ˆæ¯ä¼ é€’ï¼ˆmessage passingï¼‰è¿‡ç¨‹ä¸­æ˜¾å¼åˆ©ç”¨äº†ä¸‰è§’å½¢ç»“æ„ã€‚ç†è®ºè¯æ˜ EB-1WL çš„è¡¨è¾¾èƒ½åŠ›æ˜¾è‘—å¼ºäº 1-WLï¼Œå¹¶æä¾›äº†åŸºäºä¸€é˜¶é€»è¾‘å’ŒåŒæ€è®¡æ•°çš„å®Œæ•´è¡¨å¾ã€‚ä¸ä»¥å¾€è¿½æ±‚é«˜è¡¨è¾¾èƒ½åŠ›ä½†è®¡ç®—æ˜‚è´µçš„æ¨¡å‹ä¸åŒï¼ŒEB-GNN åœ¨å¤„ç†å®é™…å›¾å­¦ä¹ ä»»åŠ¡æ—¶ä»…éœ€æ¥è¿‘çº¿æ€§çš„æ—¶é—´å’Œå†…å­˜å¼€é”€ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEB-GNN ä½œä¸ºä¸€ç§é«˜æ•ˆçš„é€šç”¨æ¶æ„ï¼Œæ€§èƒ½å¤§å¹…è¶…è¶Šäº†ç®€å•çš„ MPNNsï¼Œåœ¨è®¡ç®—æ•ˆç‡æ˜¾è‘—å ä¼˜çš„æƒ…å†µä¸‹ï¼Œå…¶æ•ˆæœä»èƒ½ä¸ç‰¹å®šä»»åŠ¡çš„ GNN æ¶æ„ç›¸åª²ç¾ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13615v1",
      "published_date": "2025-10-15 14:45:17 UTC",
      "updated_date": "2025-10-15 14:45:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:18.177584+00:00"
    },
    {
      "arxiv_id": "2510.13602v1",
      "title": "NOSA: Native and Offloadable Sparse Attention",
      "title_zh": "NOSAï¼šåŸç”Ÿä¸”æ”¯æŒå¸è½½çš„ç¨€ç–æ³¨æ„åŠ›",
      "authors": [
        "Yuxiang Huang",
        "Chaojun Xiao",
        "Xu Han",
        "Zhiyuan Liu"
      ],
      "abstract": "Trainable sparse attention has emerged as a promising solution to address the decoding efficiency bottleneck of LLMs in long-context processing, significantly saving memory accesses while minimally impacting task performance. However, existing sparse attention methods leave a crucial limitation unresolved: the size of the key-value (KV) cache remains unreduced, which constrains on-GPU batch sizes and throttles decoding throughput, especially in large-scale batched inference. In this paper, we show that trainable sparse attention naturally exhibits strong locality in token selection across adjacent decoding steps, thereby enabling KV cache offloading without altering the underlying attention computation. However, the inherent locality remains insufficient to achieve efficient offloading, as the transfer of selected KV pairs between the CPU and GPU continues to dominate the overall decoding cost. Building on this insight, we present NOSA, a trainable sparse attention framework designed to natively support KV cache offloading. NOSA introduces explicit locality constraints by decomposing token selection into query-aware and query-agnostic components, thereby reducing KV transfers while preserving the same attention computation as used during training. We pretrain a 1B-parameter model with NOSA and conduct extensive benchmarks, showing that it preserves near-lossless performance while achieving up to a 2.3x improvement in decoding throughput compared with the vanilla trainable sparse attention baseline (InfLLM-V2).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶é¢ä¸´çš„Key-Value (KV) cacheå ç”¨è¿‡å¤§åŠè§£ç ååé‡å—é™é—®é¢˜ï¼Œæå‡ºäº†NOSAæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ç§åŸç”Ÿæ”¯æŒå¸è½½çš„å¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›(Trainable sparse attention)æœºåˆ¶ã€‚ç ”ç©¶è€…è§‚å¯Ÿåˆ°ç¨€ç–æ³¨æ„åŠ›åœ¨ä»¤ç‰Œé€‰æ‹©ä¸Šå…·æœ‰ä¸€å®šçš„å±€éƒ¨æ€§ï¼Œä½†ç”±äºé¢‘ç¹çš„KVä¼ è¾“æˆæœ¬è¿‡é«˜ï¼Œä¼ ç»Ÿå¸è½½(offloading)æ–¹å¼çš„æ•ˆç‡ä»ç„¶å—é™ã€‚NOSAé€šè¿‡å°†ä»¤ç‰Œé€‰æ‹©åˆ†è§£ä¸ºæŸ¥è¯¢æ„ŸçŸ¥(query-aware)å’ŒæŸ¥è¯¢æ— å…³(query-agnostic)ä¸¤ä¸ªç»„ä»¶ï¼Œå¼•å…¥äº†æ˜¾å¼çš„å±€éƒ¨æ€§çº¦æŸï¼Œä»è€Œåœ¨ä¸æ”¹å˜åº•å±‚æ³¨æ„åŠ›è®¡ç®—é€»è¾‘çš„æƒ…å†µä¸‹æ˜¾è‘—å‡å°‘äº†CPUä¸GPUé—´çš„æ•°æ®äº¤äº’ã€‚åŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼ŒåŸºäºNOSAé¢„è®­ç»ƒçš„1Bå‚æ•°æ¨¡å‹åœ¨ä¿æŒè¿‘ä¹æ— æŸçš„æ€§èƒ½è¡¨ç°æ—¶ï¼Œå…¶è§£ç ååé‡è¾ƒåŸºçº¿æ¨¡å‹InfLLM-V2æå‡äº†é«˜è¾¾2.3å€ã€‚è¿™ä¸€æˆæœä¸ºå¤§è§„æ¨¡æ‰¹é‡æ¨ç†åœºæ™¯ä¸‹çš„é•¿æ–‡æœ¬å¤„ç†æä¾›äº†ä¸€ç§é«˜æ•ˆçš„å­˜å‚¨ä¸è®¡ç®—ä¼˜åŒ–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "https://arxiv.org/pdf/2510.13602v1",
      "published_date": "2025-10-15 14:33:16 UTC",
      "updated_date": "2025-10-15 14:33:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:24.997760+00:00"
    },
    {
      "arxiv_id": "2510.13591v1",
      "title": "Subject Roles in the EU AI Act: Mapping and Regulatory Implications",
      "title_zh": "æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹ä¸­çš„ä¸»ä½“è§’è‰²ï¼šä½“ç³»å›¾è°±ä¸ç›‘ç®¡å½±å“",
      "authors": [
        "Nicola Fabiano"
      ],
      "abstract": "The European Union's Artificial Intelligence Act (Regulation (EU) 2024/1689) establishes the world's first comprehensive regulatory framework for AI systems through a sophisticated ecosystem of interconnected subjects defined in Article 3. This paper provides a structured examination of the six main categories of actors - providers, deployers, authorized representatives, importers, distributors, and product manufacturers - collectively referred to as \"operators\" within the regulation. Through examination of these Article 3 definitions and their elaboration across the regulation's 113 articles, 180 recitals, and 13 annexes, we map the complete governance structure and analyze how the AI Act regulates these subjects. Our analysis reveals critical transformation mechanisms whereby subjects can assume different roles under specific conditions, particularly through Article 25 provisions ensuring accountability follows control. We identify how obligations cascade through the supply chain via mandatory information flows and cooperation requirements, creating a distributed yet coordinated governance system. The findings demonstrate how the regulation balances innovation with the protection of fundamental rights through risk-based obligations that scale with the capabilities and deployment contexts of AI systems, providing essential guidance for stakeholders implementing the AI Act's requirements.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹æ¬§ç›Ÿã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹(EU AI Act) ä¸­å®šä¹‰çš„ä¸»ä½“è§’è‰²åŠå…¶ç›‘ç®¡å½±å“è¿›è¡Œäº†ç³»ç»Ÿåˆ¶å›¾ä¸åˆ†æã€‚ç ”ç©¶é‡ç‚¹å®¡æŸ¥äº† Article 3 ä¸­ç¡®å®šçš„å…­ç±»æ ¸å¿ƒå‚ä¸è€…ï¼Œå³ providersã€deployersã€authorized representativesã€importersã€distributors å’Œ product manufacturersï¼Œå¹¶å°†è¿™äº›è§’è‰²ç»Ÿç§°ä¸º operatorsã€‚é€šè¿‡å¯¹æ³•æ¡ˆå…¨éƒ¨ 113 æ¡æ¡æ¬¾ã€180 æ¡é‰´äºæ¡æ¬¾åŠ 13 ä¸ªé™„ä»¶çš„æ·±å…¥è§£æï¼Œæ–‡ç« æ­ç¤ºäº† Article 25 è§„å®šçš„ä¸»ä½“è§’è‰²è½¬æ¢æœºåˆ¶ï¼Œç¡®ä¿äº†é—®è´£åˆ¶éšæ§åˆ¶æƒè€Œè½¬ç§»ã€‚ç ”ç©¶è¿›ä¸€æ­¥é˜æ˜äº†ä¹‰åŠ¡å¦‚ä½•é€šè¿‡å¼ºåˆ¶æ€§ä¿¡æ¯æµå’Œåä½œè¦æ±‚åœ¨ä¾›åº”é“¾ä¸­å±‚å±‚ä¼ é€’ï¼Œæ„å»ºèµ·åˆ†å¸ƒä¸”åè°ƒçš„æ²»ç†ä½“ç³»ã€‚è¯¥å‘ç°å±•ç¤ºäº†æ³•æ¡ˆå¦‚ä½•é€šè¿‡ä¸ AI ç³»ç»Ÿèƒ½åŠ›å’Œéƒ¨ç½²è¯­å¢ƒç›¸æŒ‚é’©çš„é£é™©è´£ä»»åˆ¶ï¼Œåœ¨æ¨åŠ¨æŠ€æœ¯åˆ›æ–°ä¸ä¿æŠ¤åŸºæœ¬æƒåˆ©ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œä¸ºåˆ©ç›Šç›¸å…³æ–¹è½å®åˆè§„è¦æ±‚æä¾›äº†å…³é”®æŒ‡å¼•ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13591v1",
      "published_date": "2025-10-15 14:21:30 UTC",
      "updated_date": "2025-10-15 14:21:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:28.680097+00:00"
    },
    {
      "arxiv_id": "2510.13586v3",
      "title": "Deflanderization for Game Dialogue: Balancing Character Authenticity with Task Execution in LLM-based NPCs",
      "title_zh": "æ¸¸æˆå¯¹è¯çš„å»å¼—å…°å¾·åŒ–ï¼šå¹³è¡¡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ NPC è§’è‰²çœŸå®æ€§ä¸ä»»åŠ¡æ‰§è¡Œ",
      "authors": [
        "Pasin Buakhaw",
        "Kun Kerdthaisong",
        "Phuree Phenhiran",
        "Pitikorn Khlaisamniang",
        "Supasate Vorathammathorn",
        "Piyalitt Ittichaiwong",
        "Nutchanon Yongsatianchot"
      ],
      "abstract": "The emergence of large language models (LLMs) has opened new opportunities for creating dynamic non-player characters (NPCs) in gaming environments, enabling both functional task execution and persona-consistent dialogue generation. In this paper, we (Tu_Character_lab) report our participation in the Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 Round 2, which evaluates agents across three tracks: task-oriented dialogue, context-aware dialogue, and their integration. Our approach combines two complementary strategies: (i) lightweight prompting techniques in the API track, including a Deflanderization prompting method to suppress excessive role-play and improve task fidelity, and (ii) fine-tuned large models in the GPU track, leveraging Qwen3-14B with supervisedfinetuning (SFT) and Low-Rank Adaptation(LoRA). Our best submissions ranked 2nd on Task 1, 2nd on Task 3 (API track), and 4th on Task 3 (GPU track).",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„éç©å®¶è§’è‰²(NPCs)ä¸­ï¼Œå¦‚ä½•å¹³è¡¡è§’è‰²çœŸå®æ€§(Character Authenticity)ä¸ä»»åŠ¡æ‰§è¡Œ(Task Execution)ã€‚é’ˆå¯¹ Commonsense Persona-Grounded Dialogue Challenge (CPDC) 2025 æŒ‘æˆ˜èµ›ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸¤å¥—äº’è¡¥ç­–ç•¥ï¼šåœ¨ API èµ›é“ä¸­ä½¿ç”¨è½»é‡åŒ–æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡ Deflanderization æç¤ºæ–¹æ³•æŠ‘åˆ¶è¿‡åº¦è§’è‰²æ‰®æ¼”å¹¶æå‡ä»»åŠ¡ä¿çœŸåº¦ï¼›åœ¨ GPU èµ›é“ä¸­åˆ™åˆ©ç”¨ SFT å’Œ LoRA æŠ€æœ¯å¯¹ Qwen3-14B æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³ä»»åŠ¡å¯¼å‘å¯¹è¯ä¸èƒŒæ™¯æ„ŸçŸ¥å¯¹è¯çš„æ•´åˆé—®é¢˜ï¼Œç¡®ä¿ NPC åœ¨ä¿æŒäººè®¾ä¸€è‡´æ€§çš„åŒæ—¶æœ‰æ•ˆå®ŒæˆåŠŸèƒ½æ€§ä»»åŠ¡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ Task 1 å’Œ Task 3 (API èµ›é“)ä¸­ä½åˆ—ç¬¬ 2 åï¼Œå¹¶åœ¨ Task 3 (GPU èµ›é“)ä¸­å–å¾—ç¬¬ 4 åï¼ŒéªŒè¯äº†æ‰€æç­–ç•¥åœ¨æå‡æ¸¸æˆå¯¹è¯ç³»ç»Ÿäº¤äº’è´¨é‡æ–¹é¢çš„æ˜¾è‘—æ•ˆæœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13586v3",
      "published_date": "2025-10-15 14:17:23 UTC",
      "updated_date": "2025-10-26 14:03:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:29.880753+00:00"
    },
    {
      "arxiv_id": "2510.13561v2",
      "title": "OpenDerisk: An Industrial Framework for AI-Driven SRE, with Design, Implementation, and Case Studies",
      "title_zh": "OpenDeriskï¼šAIé©±åŠ¨çš„SREå·¥ä¸šçº§æ¡†æ¶ï¼šè®¾è®¡ã€å®ç°ä¸æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Peng Di",
        "Faqiang Chen",
        "Xiao Bai",
        "Hongjun Yang",
        "Qingfeng Li",
        "Ganglin Wei",
        "Jian Mou",
        "Feng Shi",
        "Keting Chen",
        "Peng Tang",
        "Zhitao Shen",
        "Zheng Li",
        "Wenhui Shi",
        "Junwei Guo",
        "Hang Yu"
      ],
      "abstract": "The escalating complexity of modern software imposes an unsustainable operational burden on Site Reliability Engineering (SRE) teams, demanding AI-driven automation that can emulate expert diagnostic reasoning. Existing solutions, from traditional AI methods to general-purpose multi-agent systems, fall short: they either lack deep causal reasoning or are not tailored for the specialized, investigative workflows unique to SRE. To address this gap, we present OpenDerisk, a specialized, open-source multi-agent framework architected for SRE. OpenDerisk integrates a diagnostic-native collaboration model, a pluggable reasoning engine, a knowledge engine, and a standardized protocol (MCP) to enable specialist agents to collectively solve complex, multi-domain problems. Our comprehensive evaluation demonstrates that OpenDerisk significantly outperforms state-of-the-art baselines in both accuracy and efficiency. This effectiveness is validated by its large-scale production deployment at Ant Group, where it serves over 3,000 daily users across diverse scenarios, confirming its industrial-grade scalability and practical impact. OpenDerisk is open source and available at https://github.com/derisk-ai/OpenDerisk/",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† OpenDeriskï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸º Site Reliability Engineering (SRE) è®¾è®¡çš„å·¥ä¸šçº§å¼€æºå¤šæ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ AI é©±åŠ¨çš„è‡ªåŠ¨åŒ–å‡è½»ç°ä»£è½¯ä»¶å¤æ‚æ€§å¸¦æ¥çš„è¿ç»´è´Ÿæ‹…ã€‚è¯¥æ¡†æ¶é›†æˆäº†è¯Šæ–­åŸç”Ÿåä½œæ¨¡å‹ (diagnostic-native collaboration model)ã€å¯æ’æ‹”æ¨ç†å¼•æ“ (pluggable reasoning engine)ã€çŸ¥è¯†å¼•æ“ (knowledge engine) ä»¥åŠæ ‡å‡†åŒ–çš„ Model Context Protocol (MCP)ï¼Œä½¿ä¸“å®¶æ™ºèƒ½ä½“èƒ½å¤ŸååŒè§£å†³è·¨é¢†åŸŸçš„å¤æ‚é—®é¢˜ã€‚OpenDerisk å¼¥è¡¥äº†ç°æœ‰ AI æ–¹æ¡ˆåœ¨å› æœæ¨ç†å’Œ SRE ä¸“é¡¹è°ƒæŸ¥å·¥ä½œæµæ–¹é¢çš„ä¸è¶³ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ¨¡æ‹Ÿä¸“å®¶çš„è¯Šæ–­æ€ç»´ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒOpenDerisk åœ¨å‡†ç¡®ç‡å’Œæ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å‰æ²¿åŸºçº¿æ¨¡å‹ã€‚ç›®å‰ï¼Œè¯¥æ¡†æ¶å·²åœ¨èš‚èšé›†å›¢ (Ant Group) çš„å¤§è§„æ¨¡ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œæ¯å¤©æœåŠ¡è¶…è¿‡ 3,000 åç”¨æˆ·ï¼Œå……åˆ†éªŒè¯äº†å…¶å·¥ä¸šçº§çš„å¯æ‰©å±•æ€§ä¸å®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "23 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13561v2",
      "published_date": "2025-10-15 13:59:58 UTC",
      "updated_date": "2025-10-16 11:18:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:30.383786+00:00"
    },
    {
      "arxiv_id": "2510.13557v1",
      "title": "Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents",
      "title_zh": "åŸºäºè‡ªé€‚åº”æ™ºèƒ½ä½“çš„äººè„¸è¡¨æƒ…è¯†åˆ«æ–‡åŒ–åå·®å»ºæ¨¡",
      "authors": [
        "David Freire-ObregÃ³n",
        "JosÃ© Salas-CÃ¡ceres",
        "Javier Lorenzo-Navarro",
        "Oliverio J. Santana",
        "Daniel HernÃ¡ndez-Sosa",
        "Modesto CastrillÃ³n-Santana"
      ],
      "abstract": "Facial expression recognition (FER) must remain robust under both cultural variation and perceptually degraded visual conditions, yet most existing evaluations assume homogeneous data and high-quality imagery. We introduce an agent-based, streaming benchmark that reveals how cross-cultural composition and progressive blurring interact to shape face recognition robustness. Each agent operates in a frozen CLIP feature space with a lightweight residual adapter trained online at sigma=0 and fixed during testing. Agents move and interact on a 5x5 lattice, while the environment provides inputs with sigma-scheduled Gaussian blur. We examine monocultural populations (Western-only, Asian-only) and mixed environments with balanced (5/5) and imbalanced (8/2, 2/8) compositions, as well as different spatial contact structures. Results show clear asymmetric degradation curves between cultural groups: JAFFE (Asian) populations maintain higher performance at low blur but exhibit sharper drops at intermediate stages, whereas KDEF (Western) populations degrade more uniformly. Mixed populations exhibit intermediate patterns, with balanced mixtures mitigating early degradation, but imbalanced settings amplify majority-group weaknesses under high blur. These findings quantify how cultural composition and interaction structure influence the robustness of FER as perceptual conditions deteriorate.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ä¸€ä¸ªåŸºäºæ™ºèƒ½ä½“(agent-based)çš„æµå¼åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨æ¢è®¨è·¨æ–‡åŒ–æ„æˆä¸å›¾åƒæ¨¡ç³Šåº¦å¦‚ä½•å…±åŒå½±å“é¢éƒ¨è¡¨æƒ…è¯†åˆ«(FER)çš„é²æ£’æ€§ã€‚ç ”ç©¶åœ¨å†»ç»“çš„ CLIP ç‰¹å¾ç©ºé—´ä¸­é€šè¿‡è½»é‡çº§æ®‹å·®é€‚é…å™¨(residual adapter)è®­ç»ƒæ™ºèƒ½ä½“ï¼Œå¹¶åœ¨ 5x5 çš„æ ¼ç‚¹ç¯å¢ƒä¸­æ¨¡æ‹Ÿä¸åŒæ–‡åŒ–æ„æˆä¸ç©ºé—´äº¤äº’ç»“æ„ã€‚å®éªŒå¯¹æ¯”äº† JAFFE(äºšæ´²)å’Œ KDEF(è¥¿æ–¹)ç¾¤ä½“çš„é€€åŒ–æ›²çº¿ï¼Œå‘ç°äºšæ´²ç¾¤ä½“åœ¨ä½æ¨¡ç³Šåº¦ä¸‹è¡¨ç°ä¼˜å¼‚ä½†åœ¨ä¸­ç­‰æ¨¡ç³Šåº¦ä¸‹æ€§èƒ½éª¤é™ï¼Œè€Œè¥¿æ–¹ç¾¤ä½“åˆ™é€€åŒ–æ›´ä¸ºå‡åŒ€ã€‚æ··åˆç¾¤ä½“çš„ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œå¹³è¡¡çš„æ–‡åŒ–æ„æˆèƒ½æœ‰æ•ˆç¼“è§£æ—©æœŸæ€§èƒ½é€€åŒ–ï¼Œè€Œä¸å¹³è¡¡çš„è®¾ç½®åˆ™ä¼šåœ¨é«˜æ¨¡ç³Šåº¦ä¸‹æ”¾å¤§ä¸»ä½“ç¾¤ä½“çš„å¼±ç‚¹ã€‚è¯¥å·¥ä½œé‡åŒ–äº†æ–‡åŒ–å¤šæ ·æ€§å’Œäº¤äº’ç»“æ„å¦‚ä½•å¡‘é€  FER ç³»ç»Ÿåœ¨æ„ŸçŸ¥æ¡ä»¶æ¶åŒ–æ—¶çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for presentation at the International Symposium on Agentic Artificial Intelligence Systems (AAIS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.13557v1",
      "published_date": "2025-10-15 13:53:30 UTC",
      "updated_date": "2025-10-15 13:53:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:34.483395+00:00"
    },
    {
      "arxiv_id": "2510.13551v1",
      "title": "Tandem Training for Language Models",
      "title_zh": "è¯­è¨€æ¨¡å‹çš„ä¸²è”è®­ç»ƒ",
      "authors": [
        "Robert West",
        "Ashton Anderson",
        "Ece Kamar",
        "Eric Horvitz"
      ],
      "abstract": "As language models continue to rapidly improve, we can expect their actions and reasoning to become difficult or impossible for weaker agents and humans to follow, undermining interpretability and oversight. With an eye on long-term futures, we pursue methods that encourage models to produce solutions that remain intelligible to weaker collaborators. We formalize intelligibility as handoff robustness: a strong model's solution is intelligible to a weaker model if randomly handing off control to the weaker model along the solution path does not cause failure. Building on this criterion, we introduce tandem training for language models, a reinforcement learning (RL) paradigm in which rollout tokens are intermittently and randomly sampled from a frozen weak model rather than the strong model being trained. Because rollouts succeed only when the strong model's actions and reasoning process can be continued by the weak model -- when the two can co-construct a successful solution -- optimizing standard RL objectives with tandem training implicitly incentivizes both correctness and intelligibility. In the GSM8K math reasoning task, tandem training reliably teaches models to abandon jargon and adapt their language to weaker partners while keeping task accuracy high. Our results demonstrate a promising route to building AI systems that remain auditable by weaker agents, with implications for human--AI collaboration and multi-agent communication.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•ä½¿æ—¥ç›Šå¼ºå¤§çš„è¯­è¨€æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä¿æŒå¯¹å¼±åä½œæ–¹çš„å¯ç†è§£æ€§ï¼Œä»¥åº”å¯¹ç›‘ç£å’Œå¯è§£é‡Šæ€§æ–¹é¢çš„æŒ‘æˆ˜ã€‚ä½œè€…å°†è¿™ç§å¯ç†è§£æ€§å½¢å¼åŒ–ä¸º \"handoff robustness\"ï¼Œå³å¼ºæ¨¡å‹çš„è§£å†³æ–¹æ¡ˆè·¯å¾„è‹¥éšæœºäº¤ç”±å¼±æ¨¡å‹æ¥ç®¡ä»èƒ½æˆåŠŸï¼Œåˆ™è§†ä¸ºå¯ç†è§£ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º \"tandem training\" çš„å¼ºåŒ–å­¦ä¹  (RL) èŒƒå¼ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é—´æ­‡æ€§åœ°ä»ä¸€ä¸ªå†»ç»“çš„å¼±æ¨¡å‹ä¸­é‡‡æ · rollout tokensã€‚è¯¥æ–¹æ³•å¼ºåˆ¶å¼ºæ¨¡å‹ç”Ÿæˆèƒ½è¢«å¼±æ¨¡å‹ç†è§£å¹¶ç»­å†™çš„æ¨ç†æ­¥éª¤ï¼Œä»è€Œåœ¨ä¼˜åŒ–æ ‡å‡† RL ç›®æ ‡çš„åŒæ—¶ï¼Œéšå¼åœ°æå‡äº†è¾“å‡ºçš„æ­£ç¡®æ€§ä¸å¯ç†è§£æ€§ã€‚åœ¨ GSM8K æ•°å­¦æ¨ç†ä»»åŠ¡ä¸Šçš„å®éªŒè¯æ˜ï¼Œ\"tandem training\" èƒ½æœ‰æ•ˆä¿ƒä½¿æ¨¡å‹æ‘’å¼ƒ jargonï¼Œå¹¶æ ¹æ®å¼±åˆä½œä¼™ä¼´çš„èƒ½åŠ›è°ƒæ•´è¯­è¨€è¡¨è¾¾ï¼Œä¸”ä¸æŸå¤±ä»»åŠ¡å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœä¸ºæ„å»ºå¯å®¡è®¡çš„ AI ç³»ç»Ÿä»¥åŠä¼˜åŒ– human-AI åä½œå’Œå¤šæ™ºèƒ½ä½“é€šä¿¡ (multi-agent communication) æä¾›äº†é‡è¦æ€è·¯ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13551v1",
      "published_date": "2025-10-15 13:48:16 UTC",
      "updated_date": "2025-10-15 13:48:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:37.090962+00:00"
    },
    {
      "arxiv_id": "2510.13543v1",
      "title": "In-Browser LLM-Guided Fuzzing for Real-Time Prompt Injection Testing in Agentic AI Browsers",
      "title_zh": "ç”¨äºæ™ºèƒ½ä½“ AI æµè§ˆå™¨å®æ—¶æç¤ºè¯æ³¨å…¥æµ‹è¯•çš„æµè§ˆå™¨ç«¯ LLM å¼•å¯¼æ¨¡ç³Šæµ‹è¯•",
      "authors": [
        "Avihay Cohen"
      ],
      "abstract": "Large Language Model (LLM) based agents integrated into web browsers (often called agentic AI browsers) offer powerful automation of web tasks. However, they are vulnerable to indirect prompt injection attacks, where malicious instructions hidden in a webpage deceive the agent into unwanted actions. These attacks can bypass traditional web security boundaries, as the AI agent operates with the user privileges across sites. In this paper, we present a novel fuzzing framework that runs entirely in the browser and is guided by an LLM to automatically discover such prompt injection vulnerabilities in real time.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é›†æˆåˆ° Web æµè§ˆå™¨ä¸­çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ï¼ˆAgentic AI Browsersï¼‰é¢ä¸´çš„é—´æ¥æç¤ºè¯æ³¨å…¥ï¼ˆIndirect Prompt Injectionï¼‰æ”»å‡»é£é™©ï¼Œè¿™ç±»æ”»å‡»é€šè¿‡ç½‘é¡µä¸­éšè—çš„æ¶æ„æŒ‡ä»¤è¯±å¯¼æ™ºèƒ½ä½“æ»¥ç”¨ç”¨æˆ·æƒé™å¹¶ç»•è¿‡ä¼ ç»Ÿ Web å®‰å…¨è¾¹ç•Œã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€å¨èƒï¼Œä½œè€…æå‡ºäº†ä¸€ç§å…¨æ–°çš„ Fuzzing æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å®Œå…¨åœ¨æµè§ˆå™¨ç¯å¢ƒä¸‹è¿è¡Œå¹¶ç”± LLM å¼•å¯¼ï¼Œå®ç°äº†å¯¹æç¤ºè¯æ³¨å…¥æ¼æ´çš„å®æ—¶è‡ªåŠ¨å‘ç°ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ LLM çš„å¼•å¯¼èƒ½åŠ›æ¥ä¼˜åŒ–æ¨¡ç³Šæµ‹è¯•æµç¨‹ï¼Œä»è€Œåœ¨å¤æ‚çš„ Web äº¤äº’åœºæ™¯ä¸­æ›´é«˜æ•ˆåœ°è¯†åˆ«å®‰å…¨ç¼ºé™·ã€‚è¿™é¡¹å·¥ä½œä¸ºå¢å¼ºä»£ç†å¼ AI æµè§ˆå™¨çš„å®æ—¶å®‰å…¨é˜²å¾¡å’Œè‡ªåŠ¨åŒ–æ¼æ´æ£€æµ‹æä¾›äº†é‡è¦çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "37 pages , 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13543v1",
      "published_date": "2025-10-15 13:39:13 UTC",
      "updated_date": "2025-10-15 13:39:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:41.395646+00:00"
    },
    {
      "arxiv_id": "2510.13537v1",
      "title": "K-Merge: Online Continual Merging of Adapters for On-device Large Language Models",
      "title_zh": "K-Mergeï¼šé¢å‘ç«¯ä¾§å¤§è¯­è¨€æ¨¡å‹çš„é€‚é…å™¨åœ¨çº¿æŒç»­åˆå¹¶",
      "authors": [
        "Donald Shenaj",
        "Ondrej Bohdal",
        "Taha Ceritli",
        "Mete Ozay",
        "Pietro Zanuttigh",
        "Umberto Michieli"
      ],
      "abstract": "On-device deployment of Large Language Models (LLMs) frequently leverages Low-Rank Adapters (LoRAs) to support diverse downstream tasks under tight resource constraints. To address the limited storage capacity of mobile devices, recent works have explored model merging techniques to fuse multiple LoRAs into a single one. In practice, however, LoRAs are often delivered incrementally, as users request support for new tasks (e.g., novel problem types or languages). This scenario introduces a new challenge: on-device online continual merging, where the objective is to incorporate new LoRAs while preserving the performance on previously supported tasks. In this paper, we propose a data-free and computationally efficient strategy for selecting and merging LoRAs when a new one becomes available, assuming the device can store only a limited number of adapters. Extensive experiments across real-world tasks demonstrate the superiority of our approach compared to alternative strategies while adhering to the storage budget and compute limitations of on-device settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç§»åŠ¨è®¾å¤‡åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)éƒ¨ç½²ä¸­é¢ä¸´çš„å­˜å‚¨é™åˆ¶ï¼Œæ¢è®¨äº†ä½ç§©é€‚é…å™¨(LoRAs)åœ¨å¢é‡äº¤ä»˜èƒŒæ™¯ä¸‹çš„åœ¨çº¿æŒç»­åˆå¹¶(on-device online continual merging)æŒ‘æˆ˜ã€‚ä¸ºäº†åœ¨æœ‰é™çš„å­˜å‚¨ç©ºé—´å†…æ”¯æŒä¸æ–­å¢åŠ çš„æ–°ä»»åŠ¡å¹¶ä¿ç•™æ—§ä»»åŠ¡æ€§èƒ½ï¼Œæœ¬æ–‡æå‡ºäº†K-Mergeï¼Œä¸€ç§æ— æ•°æ®(data-free)ä¸”è®¡ç®—é«˜æ•ˆçš„LoRAsé€‰æ‹©ä¸åˆå¹¶ç­–ç•¥ã€‚è¯¥æ–¹æ³•å…è®¸åœ¨ä¸ä¾èµ–åŸå§‹è®­ç»ƒæ•°æ®çš„å‰æä¸‹ï¼Œåœ¨å—é™çš„è®¾å¤‡èµ„æºå†…å®ç°å¤šä¸ªé€‚é…å™¨çš„åŠ¨æ€èåˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒK-Mergeåœ¨å¤„ç†çœŸå®ä¸–ç•Œä»»åŠ¡æ—¶ï¼Œèƒ½å¤Ÿåœ¨ä¸¥æ ¼éµå®ˆå­˜å‚¨é¢„ç®—å’Œè®¡ç®—çº¦æŸçš„åŒæ—¶ï¼Œè¡¨ç°å‡ºä¼˜äºç°æœ‰æ›¿ä»£æ–¹æ¡ˆçš„æ€§èƒ½ã€‚è¿™ä¸€ç ”ç©¶ä¸ºèµ„æºå—é™ç¯å¢ƒä¸‹çš„æ¨¡å‹æŒç»­æ¼”è¿›å’Œé«˜æ•ˆéƒ¨ç½²æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13537v1",
      "published_date": "2025-10-15 13:32:25 UTC",
      "updated_date": "2025-10-15 13:32:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:44.093112+00:00"
    },
    {
      "arxiv_id": "2510.13928v1",
      "title": "LLMs Can Get \"Brain Rot\"!",
      "title_zh": "LLMs ä¹Ÿä¼šâ€œè„‘è…â€ï¼",
      "authors": [
        "Shuo Xing",
        "Junyuan Hong",
        "Yifan Wang",
        "Runjin Chen",
        "Zhenyu Zhang",
        "Ananth Grama",
        "Zhengzhong Tu",
        "Zhangyang Wang"
      ],
      "abstract": "We propose and test the LLM Brain Rot Hypothesis: continual exposure to junk web text induces lasting cognitive decline in large language models (LLMs). To causally isolate data quality, we run controlled experiments on real Twitter/X corpora, constructing junk and reversely controlled datasets via two orthogonal operationalizations: M1 (engagement degree) and M2 (semantic quality), with matched token scale and training operations across conditions. Contrary to the control group, continual pre-training of 4 LLMs on the junk dataset causes non-trivial declines (Hedges' $g>0.3$) on reasoning, long-context understanding, safety, and inflating \"dark traits\" (e.g., psychopathy, narcissism). The gradual mixtures of junk and control datasets also yield dose-response cognition decay: for example, under M1, ARC-Challenge with Chain Of Thoughts drops $74.9 \\rightarrow 57.2$ and RULER-CWE $84.4 \\rightarrow 52.3$ as junk ratio rises from $0\\%$ to $100\\%$.\n  Error forensics reveal several key insights. First, we identify thought-skipping as the primary lesion: models increasingly truncate or skip reasoning chains, explaining most of the error growth. Second, partial but incomplete healing is observed: scaling instruction tuning and clean data pre-training improve the declined cognition yet cannot restore baseline capability, suggesting persistent representational drift rather than format mismatch. Finally, we discover that the popularity, a non-semantic metric, of a tweet is a better indicator of the Brain Rot effect than the length in M1. Together, the results provide significant, multi-perspective evidence that data quality is a causal driver of LLM capability decay, reframing curation for continual pretraining as a \\textit{training-time safety} problem and motivating routine \"cognitive health checks\" for deployed LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºå¹¶éªŒè¯äº†å¤§è¯­è¨€æ¨¡å‹è„‘èç¼©å‡è¯´(LLM Brain Rot Hypothesis)ï¼Œå³æŒç»­æ¥è§¦ä½è´¨é‡ç½‘ç»œæ–‡æœ¬ä¼šå¯¼è‡´å¤§è¯­è¨€æ¨¡å‹(LLMs)äº§ç”ŸæŒä¹…çš„è®¤çŸ¥è¡°é€€ã€‚ç ”ç©¶è€…é€šè¿‡å¯¹Twitter/Xè¯­æ–™åº“è¿›è¡Œå—æ§å®éªŒï¼Œæ ¹æ®äº’åŠ¨ç¨‹åº¦å’Œè¯­ä¹‰è´¨é‡æ„å»ºäº†ä½è´¨é‡(junk)å’Œå¯¹ç…§æ•°æ®é›†ï¼Œå¹¶å¯¹4ç§LLMsè¿›è¡ŒæŒç»­é¢„è®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä½è´¨é‡æ•°æ®é›†ä¸Šè®­ç»ƒä¼šå¯¼è‡´æ¨¡å‹åœ¨æ¨ç†(reasoning)ã€é•¿ä¸Šä¸‹æ–‡ç†è§£(long-context understanding)å’Œå®‰å…¨æ€§(safety)æ–¹é¢å‡ºç°æ˜¾è‘—ä¸‹é™ï¼Œå¹¶åŠ å‰§äº†â€œæš—é»‘äººæ ¼ç‰¹å¾â€(dark traits)ã€‚é”™è¯¯å–è¯åˆ†æå‘ç°ï¼Œæ€ç»´è·³è·ƒ(thought-skipping)æ˜¯ä¸»è¦çš„ç—…ç¶ï¼Œå³æ¨¡å‹ä¼šé€æ¸ç¼©çŸ­æˆ–è·³è¿‡æ¨ç†é“¾æ¡ã€‚ç ”ç©¶è¿˜å‘ç°ï¼Œè™½ç„¶å¢åŠ æŒ‡ä»¤å¾®è°ƒ(instruction tuning)å’Œæ¸…æ´æ•°æ®é¢„è®­ç»ƒå¯ä»¥æ”¹å–„å·²è¡°é€€çš„è®¤çŸ¥ï¼Œä½†æ— æ³•å®Œå…¨æ¢å¤è‡³åŸºå‡†èƒ½åŠ›ï¼Œè¡¨æ˜æ¨¡å‹å‘ç”Ÿäº†æŒä¹…çš„è¡¨å¾æ¼‚ç§»(representational drift)ã€‚è¯¥ç ”ç©¶è¯æ˜äº†æ•°æ®è´¨é‡æ˜¯å¯¼è‡´æ¨¡å‹èƒ½åŠ›è¡°é€€çš„å› æœé©±åŠ¨å› ç´ ï¼Œå°†æŒç»­é¢„è®­ç»ƒä¸­çš„æ•°æ®ç­›é€‰é‡æ–°å®šä¹‰ä¸ºè®­ç»ƒæ—¶çš„å®‰å…¨é—®é¢˜ï¼Œå¹¶å»ºè®®å¯¹å·²éƒ¨ç½²çš„LLMsè¿›è¡Œå¸¸è§„çš„è®¤çŸ¥å¥åº·æ£€æŸ¥(cognitive health checks)ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13928v1",
      "published_date": "2025-10-15 13:28:49 UTC",
      "updated_date": "2025-10-15 13:28:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:36:57.899476+00:00"
    },
    {
      "arxiv_id": "2510.13524v2",
      "title": "A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain",
      "title_zh": "é‡‘èé¢†åŸŸå¤§è¯­è¨€æ¨¡å‹æŒ‡æ ‡å¤±æ•ˆé£é™©è¯„ä¼°æ–¹æ³•",
      "authors": [
        "William Flanagan",
        "Mukunda Das",
        "Rajitha Ramanayake",
        "Swanuja Maslekar",
        "Meghana Mangipudi",
        "Joong Ho Choi",
        "Shruti Nair",
        "Shambhavi Bhusan",
        "Sanjana Dulam",
        "Mouni Pendharkar",
        "Nidhi Singh",
        "Vashisth Doshi",
        "Sachi Shah Paresh"
      ],
      "abstract": "As Generative Artificial Intelligence is adopted across the financial services industry, a significant barrier to adoption and usage is measuring model performance. Historical machine learning metrics can oftentimes fail to generalize to GenAI workloads and are often supplemented using Subject Matter Expert (SME) Evaluation. Even in this combination, many projects fail to account for various unique risks present in choosing specific metrics. Additionally, many widespread benchmarks created by foundational research labs and educational institutions fail to generalize to industrial use. This paper explains these challenges and provides a Risk Assessment Framework to allow for better application of SME and machine learning Metrics",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é‡‘èæœåŠ¡è¡Œä¸šåœ¨é‡‡ç”¨ Generative Artificial Intelligence æ—¶é¢ä¸´çš„æ ¸å¿ƒéšœç¢ï¼Œå³å¦‚ä½•å‡†ç¡®è¡¡é‡æ¨¡å‹æ€§èƒ½ã€‚ä½œè€…æŒ‡å‡ºï¼Œä¼ ç»Ÿçš„ machine learning metrics å¾€å¾€éš¾ä»¥æœ‰æ•ˆæ³›åŒ–è‡³ GenAI å·¥ä½œè´Ÿè½½ï¼Œä¸”å³ä¾¿ç»“åˆ Subject Matter Expert (SME) Evaluationï¼Œä¹Ÿå¸¸å› å¿½è§†ç‰¹å®šæŒ‡æ ‡é€‰æ‹©ä¸­çš„ç‹¬ç‰¹é£é™©è€Œå¯¼è‡´è¯„ä¼°å¤±æ•ˆã€‚æ­¤å¤–ï¼Œç°æœ‰çš„å­¦æœ¯åŸºå‡†åœ¨å·¥ä¸šåº”ç”¨åœºæ™¯ä¸­æ™®éç¼ºä¹æ³›åŒ–èƒ½åŠ›ã€‚é’ˆå¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€å¥— Risk Assessment Frameworkï¼Œæ—¨åœ¨ä¸ºé‡‘èé¢†åŸŸ LLMs çš„æ€§èƒ½è¯„ä¼°æä¾›æ›´ç§‘å­¦çš„æ–¹æ³•è®ºã€‚è¯¥æ¡†æ¶é€šè¿‡ä¼˜åŒ– SME ä¸æœºå™¨å­¦ä¹ æŒ‡æ ‡çš„ååŒåº”ç”¨ï¼Œå¸®åŠ©ä»ä¸šè€…æ›´æœ‰æ•ˆåœ°è¯†åˆ«å¹¶ç®¡ç†æŒ‡æ ‡å¤±æ•ˆé£é™©ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2025 GenAI in Finance Workshop",
      "pdf_url": "https://arxiv.org/pdf/2510.13524v2",
      "published_date": "2025-10-15 13:17:16 UTC",
      "updated_date": "2025-10-16 12:21:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:02.713895+00:00"
    },
    {
      "arxiv_id": "2510.13521v1",
      "title": "Narrow Operator Models of Stellarator Equilibria in Fourier Zernike Basis",
      "title_zh": "åŸºäº Fourier-Zernike åŸºåº•çš„ä»¿æ˜Ÿå™¨å¹³è¡¡çª„ç®—å­æ¨¡å‹",
      "authors": [
        "Timo Thun",
        "Rory Conlin",
        "Dario Panici",
        "Daniel BÃ¶ckenhoff"
      ],
      "abstract": "Numerical computation of the ideal Magnetohydrodynamic (MHD) equilibrium magnetic field is at the base of stellarator optimisation and provides the starting point for solving more sophisticated Partial Differential Equations (PDEs) like transport or turbulence models. Conventional approaches solve for a single stationary point of the ideal MHD equations, which is fully defined by three invariants and the numerical scheme employed by the solver. We present the first numerical approach that can solve for a continuous distribution of equilibria with fixed boundary and rotational transform, varying only the pressure invariant. This approach minimises the force residual by optimising parameters of multilayer perceptrons (MLP) that map from a scalar pressure multiplier to the Fourier Zernike basis as implemented in the modern stellarator equilibrium solver DESC.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ’æ˜Ÿå™¨(stellarator)ä¼˜åŒ–çš„æ ¸å¿ƒéœ€æ±‚ï¼Œæ¢è®¨äº†ç†æƒ³ç£æµä½“åŠ¨åŠ›å­¦(Ideal Magnetohydrodynamic, MHD)å¹³è¡¡ç£åœºçš„æ•°å€¼è®¡ç®—ï¼Œè¿™æ˜¯è¿›ä¸€æ­¥è§£å†³è¾“è¿æˆ–æ¹æµç­‰åå¾®åˆ†æ–¹ç¨‹(PDEs)å»ºæ¨¡çš„åŸºç¡€ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸ä»…èƒ½é’ˆå¯¹ç”±ç‰¹å®šä¸å˜é‡å®šä¹‰çš„å•ä¸ªå¹³ç¨³ç‚¹è¿›è¡Œæ±‚è§£ï¼Œè€Œæœ¬ç ”ç©¶æå‡ºäº†é¦–ä¸ªèƒ½å¤Ÿæ±‚è§£è¿ç»­åˆ†å¸ƒå¹³è¡¡æ€çš„æ•°å€¼æ–¹æ³•ã€‚åœ¨ä¿æŒå›ºå®šè¾¹ç•Œå’Œæ—‹è½¬å˜æ¢(rotational transform)çš„å‰æä¸‹ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ”¹å˜å‹åŠ›ä¸å˜é‡(pressure invariant)æ¥æ•æ‰å¹³è¡¡æ€çš„å˜åŒ–ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯æ˜¯åˆ©ç”¨å¤šå±‚æ„ŸçŸ¥å™¨(MLP)æ„å»ºç®—å­æ¨¡å‹ï¼Œå°†æ ‡é‡å‹åŠ›ä¹˜æ•°æ˜ å°„åˆ°DESCæ±‚è§£å™¨æ‰€é‡‡ç”¨çš„Fourier Zernike basisä¸­ï¼Œå¹¶é€šè¿‡ä¼˜åŒ–æ¨¡å‹å‚æ•°ä»¥æœ€å°åŒ–åŠ›æ®‹å·®(force residual)ã€‚è¯¥æ–¹æ³•å®ç°äº†å¯¹å¹³è¡¡æ€ç©ºé—´çš„é«˜æ•ˆå»ºæ¨¡ï¼Œä¸ºåœ¨è¿ç»­ç‰©ç†å‚æ•°ç©ºé—´ä¸‹è¿›è¡Œæ’æ˜Ÿå™¨åˆ†æä¸ä¼˜åŒ–æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "15 pages, 6 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2510.13521v1",
      "published_date": "2025-10-15 13:13:42 UTC",
      "updated_date": "2025-10-15 13:13:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:11.302848+00:00"
    },
    {
      "arxiv_id": "2510.13515v3",
      "title": "UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning",
      "title_zh": "UniME-V2ï¼šä»¥ MLLM ä¸ºè¯„åˆ¤è€…çš„é€šç”¨å¤šæ¨¡æ€åµŒå…¥å­¦ä¹ ",
      "authors": [
        "Tiancheng Gu",
        "Kaicheng Yang",
        "Kaichen Zhang",
        "Xiang An",
        "Ziyong Feng",
        "Yueyi Zhang",
        "Weidong Cai",
        "Jiankang Deng",
        "Lidong Bing"
      ],
      "abstract": "Universal multimodal embedding models are foundational to various tasks. Existing approaches typically employ in-batch negative mining by measuring the similarity of query-candidate pairs. However, these methods often struggle to capture subtle semantic differences among candidates and lack diversity in negative samples. Moreover, the embeddings exhibit limited discriminative ability in distinguishing false and hard negatives. In this paper, we leverage the advanced understanding capabilities of MLLMs to enhance representation learning and present a novel Universal Multimodal Embedding (UniME-V2) model. Our approach first constructs a potential hard negative set through global retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes MLLMs to assess the semantic alignment of query-candidate pairs and generate soft semantic matching scores. These scores serve as a foundation for hard negative mining, mitigating the impact of false negatives and enabling the identification of diverse, high-quality hard negatives. Furthermore, the semantic matching scores are used as soft labels to mitigate the rigid one-to-one mapping constraint. By aligning the similarity matrix with the soft semantic matching score matrix, the model learns semantic distinctions among candidates, significantly enhancing its discriminative capacity. To further improve performance, we propose UniME-V2-Reranker, a reranking model trained on our mined hard negatives through a joint pairwise and listwise optimization approach. We conduct comprehensive experiments on the MMEB benchmark and multiple retrieval tasks, demonstrating that our method achieves state-of-the-art performance on average across all tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UniME-V2ï¼Œä¸€ç§é’ˆå¯¹é€šç”¨å¤šæ¨¡æ€åµŒå…¥å­¦ä¹ çš„MLLM-as-a-Judgeæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨æ•æ‰ç»†å¾®è¯­ä¹‰å·®å¼‚ä»¥åŠåŒºåˆ†å›°éš¾è´Ÿæ ·æœ¬æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡å…¨å±€æ£€ç´¢æ„å»ºæ½œåœ¨çš„å›°éš¾è´Ÿæ ·æœ¬é›†ï¼Œå¹¶å¼•å…¥MLLM-as-a-Judgeæœºåˆ¶ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æŸ¥è¯¢ä¸å€™é€‰å¯¹ä¹‹é—´çš„è¯­ä¹‰å¯¹é½ç¨‹åº¦ä»¥ç”Ÿæˆè½¯è¯­ä¹‰åŒ¹é…åˆ†æ•°ã€‚è¿™äº›åˆ†æ•°ä¸ä»…ä¸ºæŒ–æ˜é«˜è´¨é‡ä¸”å¤šæ ·åŒ–çš„å›°éš¾è´Ÿæ ·æœ¬å¥ å®šäº†åŸºç¡€ï¼Œè¿˜æœ‰æ•ˆç¼“è§£äº†ä¼ªè´Ÿæ ·æœ¬å¸¦æ¥çš„å¹²æ‰°ã€‚é€šè¿‡å°†ç›¸ä¼¼åº¦çŸ©é˜µä¸è½¯è¯­ä¹‰åŒ¹é…åˆ†æ•°çŸ©é˜µå¯¹é½ï¼Œæ¨¡å‹é‡‡ç”¨è½¯æ ‡ç­¾æœºåˆ¶å–ä»£äº†åˆšæ€§çš„ä¸€å¯¹ä¸€æ˜ å°„çº¦æŸï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹å€™é€‰æ ·æœ¬é—´è¯­ä¹‰å·®å¼‚çš„åˆ¤åˆ«èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†UniME-V2-Rerankeré‡æ’åºæ¨¡å‹ï¼Œé€šè¿‡è”åˆç‚¹å¯¹å¼(pairwise)å’Œåˆ—è¡¨å¼(listwise)ä¼˜åŒ–ç­–ç•¥è¿›ä¸€æ­¥æå‡è¡¨ç°ã€‚åœ¨MMEBåŸºå‡†æµ‹è¯•åŠå¤šé¡¹æ£€ç´¢ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒUniME-V2åœ¨å„é¡¹ä»»åŠ¡çš„å¹³å‡æ€§èƒ½ä¸Šå‡è¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³(SOTA)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI2026 Oral, Webpage:https://garygutc.github.io/UniME-v2/",
      "pdf_url": "https://arxiv.org/pdf/2510.13515v3",
      "published_date": "2025-10-15 13:07:00 UTC",
      "updated_date": "2025-12-08 03:54:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:11.591663+00:00"
    },
    {
      "arxiv_id": "2510.13512v1",
      "title": "Offline and Online KL-Regularized RLHF under Differential Privacy",
      "title_zh": "å·®åˆ†éšç§çº¦æŸä¸‹çš„ç¦»çº¿ä¸åœ¨çº¿ KL æ­£åˆ™åŒ– RLHF",
      "authors": [
        "Yulian Wu",
        "Rushil Thareja",
        "Praneeth Vepakomma",
        "Francesco Orabona"
      ],
      "abstract": "In this paper, we study the offline and online settings of reinforcement learning from human feedback (RLHF) with KL-regularization -- a widely used objective function in large language model alignment -- under the $Îµ$ local differential privacy ($Îµ$-LDP) model on the label of the human preference. In the offline setting, we design an algorithm based on the principle of pessimism and derive a new suboptimality gap of $\\tilde{O}(1/[(e^Îµ-1)^2 n])$ on the KL-regularized objective under single-policy concentrability. We also prove its optimality by providing a matching lower bound where $n$ is the sample size.\n  In the online setting, we are the first one to theoretically investigate the problem of KL-regularized RLHF with LDP. We design an optimism-based algorithm and derive a logarithmic regret bound of $O(d_{\\mathcal{F}}\\log (N_{\\mathcal{F}}\\cdot T) /(e^Îµ-1)^2 )$, where $T$ is the total time step, $N_{\\mathcal{F}}$ is cardinality of the reward function space $\\mathcal{F}$ and $d_{\\mathcal{F}}$ is a variant of eluder dimension for RLHF. As a by-product of our analysis, our results also imply the first analysis for online KL-regularized RLHF without privacy. We implement our algorithm in the offline setting to verify our theoretical results and release our open source code at: https://github.com/rushil-thareja/PPKL-RLHF-Official.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹å¯¹é½ä¸­å¹¿æ³›ä½¿ç”¨çš„ KL-regularized RLHF åœ¨ç¦»çº¿(offline)å’Œåœ¨çº¿(online)è®¾ç½®ä¸‹çš„éšç§ä¿æŠ¤é—®é¢˜ï¼Œé‡ç‚¹åˆ†æäº†äººç±»åå¥½æ ‡ç­¾åœ¨ $\\epsilon$ local differential privacy ($\\epsilon$-LDP) æ¨¡å‹ä¸‹çš„è¡¨ç°ã€‚åœ¨ç¦»çº¿è®¾ç½®ä¸­ï¼Œç ”ç©¶è€…åŸºäºæ‚²è§‚åŸåˆ™(pessimism)è®¾è®¡äº†ç®—æ³•ï¼Œå¹¶åœ¨å•ç­–ç•¥é›†ä¸­æ€§æ¡ä»¶ä¸‹å¯¼å‡ºäº† suboptimality gapï¼Œå¹¶é€šè¿‡åŒ¹é…çš„ä¸‹ç•Œè¯æ˜äº†å…¶ç†è®ºæœ€ä¼˜æ€§ã€‚åœ¨åœ¨çº¿è®¾ç½®ä¸­ï¼Œè¯¥ç ”ç©¶é¦–æ¬¡å¯¹å…·æœ‰ LDP ä¿æŠ¤çš„ KL-regularized RLHF è¿›è¡Œäº†ç†è®ºæ¢ç©¶ï¼Œæå‡ºäº†åŸºäºä¹è§‚åŸåˆ™(optimism)çš„ç®—æ³•å¹¶æ¨å¯¼å‡ºå¯¹æ•°çº§çš„ regret boundã€‚ä½œä¸ºåˆ†æçš„å‰¯äº§å“ï¼Œè¯¥å·¥ä½œè¿˜è´¡çŒ®äº†é¦–ä¸ªå…³äºæ— éšç§ä¿æŠ¤è®¾ç½®ä¸‹åœ¨çº¿ KL-regularized RLHF çš„ç†è®ºåˆ†æç»“æœã€‚æœ€åï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡å®éªŒéªŒè¯äº†ç¦»çº¿ç®—æ³•çš„ç†è®ºå‘ç°ï¼Œå¹¶å¼€æºäº†ç›¸å…³ä»£ç ä»¥ä¾›å­¦æœ¯ç•Œå‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13512v1",
      "published_date": "2025-10-15 13:04:19 UTC",
      "updated_date": "2025-10-15 13:04:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:17.583691+00:00"
    },
    {
      "arxiv_id": "2510.13501v1",
      "title": "Confidence as a Reward: Transforming LLMs into Reward Models",
      "title_zh": "ä»¥ç½®ä¿¡åº¦ä½œä¸ºå¥–åŠ±ï¼šå°†å¤§è¯­è¨€æ¨¡å‹è½¬åŒ–ä¸ºå¥–åŠ±æ¨¡å‹",
      "authors": [
        "He Du",
        "Bowen Li",
        "Chengxing Xie",
        "Chang Gao",
        "Kai Chen",
        "Dacheng Tao"
      ],
      "abstract": "Reward models can significantly enhance the reasoning capabilities of large language models (LLMs), but they typically require extensive curated data and costly training. To mitigate these challenges, training-free approaches such as LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate responses, achieving promising results. Recent works have also indicated that model confidence can serve effectively as a reward metric, distinguishing between chain-of-thought (CoT) and non-CoT paths. However, the concept of using confidence as a reward has not been comprehensively studied. In this work, we systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful training-free method that utilizes token-level confidence in the model's final answers as a proxy for reward, especially suitable for close-ended tasks. Through extensive experiments on mathematical reasoning tasks, we demonstrate that CRew outperforms existing training-free reward approaches on the MATH500 and RewardMATH benchmarks, and even surpasses most trained reward models. We further identify a strong correlation between CRew scores and the actual reasoning performance of the model. Additionally, we find that CRew can effectively filter high-quality training data. Building upon these insights, we propose CRew-DPO, a training strategy that constructs preference data from confidence scores combined with correctness signals. Finetuning with CRew-DPO further enhances the model's judging capabilities and consistently outperforms existing self-training methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Confidence-as-a-Reward (CRew)ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¾“å‡ºæœ€ç»ˆç­”æ¡ˆæ—¶çš„ Token çº§åˆ«ç½®ä¿¡åº¦ä½œä¸ºå¥–åŠ±ä»£ç†çš„æ— éœ€è®­ç»ƒ (training-free) æ–¹æ³•ã€‚CRew æ—¨åœ¨è§£å†³ä¼ ç»Ÿå¥–åŠ±æ¨¡å‹éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®å’Œé«˜æ˜‚è®­ç»ƒæˆæœ¬çš„é—®é¢˜ï¼Œç‰¹åˆ«é€‚ç”¨äºæ•°å­¦æ¨ç†ç­‰é—­ç¯ä»»åŠ¡ (close-ended tasks)ã€‚å®éªŒè¡¨æ˜ï¼ŒCRew åœ¨ MATH500 å’Œ RewardMATH åŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°ä¼˜äº LLM-as-a-Judge ç­‰ç°æœ‰æ–¹æ³•ï¼Œç”šè‡³è¶…è¶Šäº†éƒ¨åˆ†ç»è¿‡ä¸“é—¨è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ã€‚ç ”ç©¶å‘ç° CRew åˆ†æ•°ä¸æ¨¡å‹æ¨ç†æ€§èƒ½å…·æœ‰å¼ºç›¸å…³æ€§ï¼Œå¹¶èƒ½æœ‰æ•ˆè¾…åŠ©è¿‡æ»¤é«˜è´¨é‡è®­ç»ƒæ•°æ®ã€‚æ­¤å¤–ï¼Œä½œè€…åŸºäºæ­¤æå‡ºäº† CRew-DPO ç­–ç•¥ï¼Œé€šè¿‡ç»“åˆç½®ä¿¡åº¦ä¸æ­£ç¡®æ€§ä¿¡å·æ„å»ºåå¥½æ•°æ® (preference data)ï¼Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹çš„è‡ªæˆ‘åˆ¤æ–­ä¸æ¨ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13501v1",
      "published_date": "2025-10-15 12:51:47 UTC",
      "updated_date": "2025-10-15 12:51:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:09.896711+00:00"
    },
    {
      "arxiv_id": "2510.13500v2",
      "title": "MedREK: Retrieval-Based Editing for Medical LLMs with Key-Aware Prompts",
      "title_zh": "MedREKï¼šåŸºäºé”®æ„ŸçŸ¥æç¤ºçš„åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹æ£€ç´¢å¼ç¼–è¾‘",
      "authors": [
        "Shujun Xia",
        "Haokun Lin",
        "Yichen Wu",
        "Yinan Zhou",
        "Zixuan Li",
        "Zhongwei Wan",
        "Xingrun Xing",
        "Yefeng Zheng",
        "Xiang Li",
        "Caifeng Shan",
        "Zhenan Sun",
        "Quanzheng Li"
      ],
      "abstract": "LLMs hold great promise for healthcare applications, but the rapid evolution of medical knowledge and errors in training data often cause them to generate outdated or inaccurate information, limiting their applicability in high-stakes clinical practice. Model editing has emerged as a potential remedy without full retraining. While parameter-based editing often compromises locality and is thus ill-suited for the medical domain, retrieval-based editing offers a more viable alternative. However, it still faces two critical challenges: (1) representation overlap within the medical knowledge space often causes inaccurate retrieval and reduces editing accuracy; (2) existing methods are restricted to single-sample edits, while batch-editing remains largely unexplored despite its importance for real-world medical applications. To address these challenges, we first construct MedVersa, an enhanced benchmark with broader coverage of medical subjects, designed to evaluate both single and batch edits under strict locality constraints. We then propose MedREK, a retrieval-based editing framework that integrates a shared query-key module for precise matching with an attention-based prompt encoder for informative guidance. Experimental results on various medical benchmarks demonstrate that our MedREK achieves superior performance across different core metrics and provides the first validated solution for batch-editing in medical LLMs. Our code and dataset are available at https://github.com/mylittleriver/MedREK.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ (Medical LLMs) å®¹æ˜“äº§ç”Ÿè¿‡æ—¶æˆ–é”™è¯¯ä¿¡æ¯çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º MedREK çš„æ£€ç´¢å¼ç¼–è¾‘æ¡†æ¶ã€‚ä¸ºäº†åº”å¯¹åŒ»ç–—çŸ¥è¯†ç©ºé—´ä¸­çš„è¡¨ç¤ºé‡å å¯¼è‡´çš„æ£€ç´¢åå·®ä»¥åŠç°æœ‰æ–¹æ³•æ— æ³•å¤„ç†æ‰¹é‡ç¼–è¾‘ (batch-editing) çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…é¦–å…ˆæ„å»ºäº† MedVersa åŸºå‡†æµ‹è¯•ï¼Œç”¨äºåœ¨ä¸¥æ ¼çº¦æŸä¸‹è¯„ä¼°ç¼–è¾‘æ•ˆæœã€‚MedREK æ¡†æ¶é€šè¿‡å…±äº«æŸ¥è¯¢é”®æ¨¡å— (shared query-key module) å®ç°ç²¾å‡†åŒ¹é…ï¼Œå¹¶ç»“åˆåŸºäºæ³¨æ„åŠ›çš„æç¤ºç¼–ç å™¨ (attention-based prompt encoder) æä¾›ä¸°å¯Œçš„ä¿¡æ¯å¼•å¯¼ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMedREK åœ¨å¤šé¡¹åŒ»ç–—åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†ä¼˜å¼‚çš„è¡¨ç°ï¼Œå¹¶ä¸ºåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹çš„æ‰¹é‡ç¼–è¾‘ä»»åŠ¡æä¾›äº†é¦–ä¸ªç»è¿‡éªŒè¯çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint, work in progress",
      "pdf_url": "https://arxiv.org/pdf/2510.13500v2",
      "published_date": "2025-10-15 12:50:33 UTC",
      "updated_date": "2025-11-03 08:12:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:31.194770+00:00"
    },
    {
      "arxiv_id": "2510.13499v2",
      "title": "ConsintBench: Evaluating Language Models on Real-World Consumer Intent Understanding",
      "title_zh": "ConsintBenchï¼šé¢å‘çœŸå®ä¸–ç•Œæ¶ˆè´¹è€…æ„å›¾ç†è§£çš„è¯­è¨€æ¨¡å‹è¯„ä¼°",
      "authors": [
        "Xiaozhe Li",
        "TianYi Lyu",
        "Siyi Yang",
        "Yuxi Gong",
        "Yizhao Yang",
        "Jinxuan Huang",
        "Ligao Zhang",
        "Zhuoyi Huang",
        "Qingwen Liu"
      ],
      "abstract": "Understanding human intent is a complex, high-level task for large language models (LLMs), requiring analytical reasoning, contextual interpretation, dynamic information aggregation, and decision-making under uncertainty. Real-world public discussions, such as consumer product discussions, are rarely linear or involve a single user. Instead, they are characterized by interwoven and often conflicting perspectives, divergent concerns, goals, emotional tendencies, as well as implicit assumptions and background knowledge about usage scenarios. To accurately understand such explicit public intent, an LLM must go beyond parsing individual sentences; it must integrate multi-source signals, reason over inconsistencies, and adapt to evolving discourse, similar to how experts in fields like politics, economics, or finance approach complex, uncertain environments. Despite the importance of this capability, no large-scale benchmark currently exists for evaluating LLMs on real-world human intent understanding, primarily due to the challenges of collecting real-world public discussion data and constructing a robust evaluation pipeline. To bridge this gap, we introduce \\bench, the first dynamic, live evaluation benchmark specifically designed for intent understanding, particularly in the consumer domain. \\bench is the largest and most diverse benchmark of its kind, supporting real-time updates while preventing data contamination through an automated curation pipeline.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†ConsintBenchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨é’ˆå¯¹çœŸå®ä¸–ç•Œæ¶ˆè´¹è€…æ„å›¾ç†è§£(Intent Understanding)è®¾è®¡çš„åŠ¨æ€å®æ—¶è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†éçº¿æ€§ã€å­˜åœ¨å†²çªè§‚ç‚¹åŠéšå«èƒŒæ™¯çŸ¥è¯†çš„å¤æ‚äººç±»æ„å›¾æ—¶é¢ä¸´çš„æŒ‘æˆ˜ã€‚ä½œä¸ºç›®å‰åŒç±»ä¸­è§„æ¨¡æœ€å¤§ä¸”æœ€å…·å¤šæ ·æ€§çš„åŸºå‡†ï¼ŒConsintBenchæ”¯æŒå®æ—¶æ›´æ–°ï¼Œå¹¶åˆ©ç”¨è‡ªåŠ¨åŒ–ç­–åˆ’æµæ°´çº¿(Automated Curation Pipeline)æœ‰æ•ˆé˜²æ­¢æ•°æ®æ±¡æŸ“(Data Contamination)ã€‚è¯¥åŸºå‡†è¦æ±‚æ¨¡å‹å…·å¤‡è¶…è¶Šç®€å•å¥å­è§£æçš„èƒ½åŠ›ï¼Œå¿…é¡»èƒ½å¤Ÿé›†æˆå¤šæºä¿¡å·å¹¶åœ¨é«˜åº¦ä¸ç¡®å®šçš„ç¯å¢ƒä¸‹è¿›è¡Œåˆ†ææ¨ç†ä¸åŠ¨æ€ä¿¡æ¯èšåˆã€‚é€šè¿‡å¡«è¡¥å¤§è§„æ¨¡çœŸå®ä¸–ç•Œæ„å›¾ç†è§£è¯„ä¼°å·¥å…·çš„ç©ºç™½ï¼ŒConsintBenchä¸ºè¡¡é‡æ¨¡å‹åœ¨å¤„ç†ç±»ä¼¼æ”¿æ²»ã€ç»æµæˆ–é‡‘èé¢†åŸŸå¤æ‚ç¯å¢ƒæ—¶çš„è¡¨ç°æä¾›äº†ç¨³å¥çš„è¯„ä»·æ¡†æ¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13499v2",
      "published_date": "2025-10-15 12:49:45 UTC",
      "updated_date": "2025-10-20 04:04:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:24.978169+00:00"
    },
    {
      "arxiv_id": "2510.13497v1",
      "title": "DistilCLIP-EEG: Enhancing Epileptic Seizure Detection Through Multi-modal Learning and Knowledge Distillation",
      "title_zh": "DistilCLIP-EEGï¼šåŸºäºå¤šæ¨¡æ€å­¦ä¹ ä¸çŸ¥è¯†è’¸é¦çš„ç™«ç—«å‘ä½œæ£€æµ‹å¢å¼º",
      "authors": [
        "Zexin Wang",
        "Lin Shi",
        "Haoyu Wu",
        "Junru Luo",
        "Xiangzeng Kong",
        "Jun Qi"
      ],
      "abstract": "Epilepsy is a prevalent neurological disorder marked by sudden, brief episodes of excessive neuronal activity caused by abnormal electrical discharges, which may lead to some mental disorders. Most existing deep learning methods for epilepsy detection rely solely on unimodal EEG signals, neglecting the potential benefits of multimodal information. To address this, we propose a novel multimodal model, DistilCLIP-EEG, based on the CLIP framework, which integrates both EEG signals and text descriptions to capture comprehensive features of epileptic seizures. The model involves an EEG encoder based on the Conformer architecture as a text encoder, the proposed Learnable BERT (BERT-LP) as prompt learning within the encoders. Both operate in a shared latent space for effective cross-modal representation learning. To enhance efficiency and adaptability, we introduce a knowledge distillation method where the trained DistilCLIP-EEG serves as a teacher to guide a more compact student model to reduce training complexity and time. On the TUSZ, AUBMC, and CHB-MIT datasets, both the teacher and student models achieved accuracy rates exceeding 97%. Across all datasets, the F1-scores were consistently above 0.94, demonstrating the robustness and reliability of the proposed framework. Moreover, the student model's parameter count and model size are approximately 58.1% of those of the teacher model, significantly reducing model complexity and storage requirements while maintaining high performance. These results highlight the potential of our proposed model for EEG-based epilepsy detection and establish a solid foundation for deploying lightweight models in resource-constrained settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DistilCLIP-EEGï¼Œä¸€ç§åŸºäº CLIP æ¡†æ¶çš„æ–°å‹å¤šæ¨¡æ€æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆ EEG ä¿¡å·å’Œæ–‡æœ¬æè¿°æ¥å¢å¼ºç™«ç—«å‘ä½œæ£€æµ‹ã€‚æ¨¡å‹é‡‡ç”¨åŸºäº Conformer æ¶æ„çš„ç¼–ç å™¨å’Œå¯å­¦ä¹ çš„ BERT-LP å®ç°è·¨æ¨¡æ€è¡¨ç¤ºå­¦ä¹ ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç™«ç—«å‘ä½œçš„ç»¼åˆç‰¹å¾ã€‚ä¸ºäº†ä¼˜åŒ–æ¨¡å‹åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²ï¼Œç ”ç©¶å¼•å…¥äº†çŸ¥è¯†è’¸é¦ (Knowledge Distillation) æŠ€æœ¯ï¼Œè®­ç»ƒå‡ºä¸€ä¸ªå‚æ•°é‡ä»…ä¸ºæ•™å¸ˆæ¨¡å‹ 58.1% çš„è½»é‡åŒ–å­¦ç”Ÿæ¨¡å‹ã€‚å®éªŒåœ¨ TUSZã€AUBMC å’Œ CHB-MIT æ•°æ®é›†ä¸Šå±•ç¤ºäº†å“è¶Šçš„æ€§èƒ½ï¼Œæ•™å¸ˆå’Œå­¦ç”Ÿæ¨¡å‹çš„å‡†ç¡®ç‡å‡è¶…è¿‡ 97%ï¼Œä¸” F1-scores ä¿æŒåœ¨ 0.94 ä»¥ä¸Šã€‚è¯¥æ¡†æ¶åœ¨é™ä½æ¨¡å‹å¤æ‚åº¦å’Œå­˜å‚¨éœ€æ±‚çš„åŒæ—¶ç»´æŒäº†æé«˜çš„ç¨³å¥æ€§ï¼Œä¸ºå®ç°é«˜æ•ˆã€ä½åŠŸè€—çš„è‡ªåŠ¨åŒ–ç™«ç—«ç›‘æµ‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 9 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13497v1",
      "published_date": "2025-10-15 12:49:28 UTC",
      "updated_date": "2025-10-15 12:49:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:27.306837+00:00"
    },
    {
      "arxiv_id": "2510.13494v1",
      "title": "LiteraryQA: Towards Effective Evaluation of Long-document Narrative QA",
      "title_zh": "LiteraryQAï¼šé¢å‘é•¿æ–‡æ¡£å™äº‹æ€§é—®ç­”çš„æœ‰æ•ˆè¯„ä¼°",
      "authors": [
        "Tommaso Bonomo",
        "Luca GioffrÃ©",
        "Roberto Navigli"
      ],
      "abstract": "Question Answering (QA) on narrative text poses a unique challenge to current systems, requiring a deep understanding of long, complex documents. However, the reliability of NarrativeQA, the most widely used benchmark in this domain, is hindered by noisy documents and flawed QA pairs. In this work, we introduce LiteraryQA, a high-quality subset of NarrativeQA focused on literary works. Using a human- and LLM-validated pipeline, we identify and correct low-quality QA samples while removing extraneous text from source documents. We then carry out a meta-evaluation of automatic metrics to clarify how systems should be evaluated on LiteraryQA. This analysis reveals that all n-gram-based metrics have a low system-level correlation to human judgment, while LLM-as-a-Judge evaluations, even with small open-weight models, can strongly agree with the ranking identified by humans. Finally, we benchmark a set of long-context LLMs on LiteraryQA. We release our code and data at https://github.com/SapienzaNLP/LiteraryQA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¹¿æ³›ä½¿ç”¨çš„ NarrativeQA åŸºå‡†æµ‹è¯•ä¸­å­˜åœ¨çš„æ–‡æ¡£å™ªéŸ³å’Œé—®ç­”å¯¹ç¼ºé™·ï¼Œæå‡ºäº†ä¸“æ³¨äºæ–‡å­¦ä½œå“çš„é«˜è´¨é‡å­é›† LiteraryQAã€‚é€šè¿‡äººå·¥ä¸ LLM éªŒè¯çš„æµæ°´çº¿ï¼Œç ”ç©¶è€…è¯†åˆ«å¹¶çº æ­£äº†ä½è´¨é‡çš„é—®ç­”æ ·æœ¬ï¼ŒåŒæ—¶å»é™¤äº†æºæ–‡æ¡£ä¸­çš„æ— å…³æ–‡æœ¬ã€‚åœ¨å¯¹è‡ªåŠ¨è¯„ä»·æŒ‡æ ‡è¿›è¡Œçš„å…ƒè¯„ä¼°ï¼ˆmeta-evaluationï¼‰ä¸­ï¼Œç ”ç©¶å‘ç°æ‰€æœ‰åŸºäº n-gram çš„æŒ‡æ ‡ä¸äººç±»åˆ¤æ–­çš„ç›¸å…³æ€§å‡è¾ƒä½ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä½¿ç”¨ LLM-as-a-Judge çš„è¯„ä¼°æ–¹å¼ï¼Œå³ä½¿æ˜¯è¾ƒå°çš„å¼€æºæƒé‡æ¨¡å‹ï¼Œä¹Ÿèƒ½åœ¨ç³»ç»Ÿæ’åä¸Šä¸äººç±»è¯„ä»·ä¿æŒé«˜åº¦ä¸€è‡´ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶åœ¨ LiteraryQA ä¸Šå¯¹å¤šç§é•¿ä¸Šä¸‹æ–‡ Large Language Models (LLMs) è¿›è¡Œäº†åŸºå‡†æµ‹è¯•å¹¶å¼€æºäº†ç›¸å…³ä»£ç ä¸æ•°æ®ã€‚è¯¥é¡¹å·¥ä½œä¸ºè§£å†³é•¿æ–‡æ¡£å™äº‹ç±»é—®ç­”ç³»ç»Ÿï¼ˆNarrative QAï¼‰çš„è¯„ä¼°æŒ‘æˆ˜æä¾›äº†æ›´å¯é çš„æ•°æ®æ”¯æŒä¸æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2025 Main Conference. 22 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13494v1",
      "published_date": "2025-10-15 12:43:59 UTC",
      "updated_date": "2025-10-15 12:43:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:41.190016+00:00"
    },
    {
      "arxiv_id": "2510.13459v2",
      "title": "Mobile Coverage Analysis using Crowdsourced Data",
      "title_zh": "åŸºäºä¼—åŒ…æ•°æ®çš„ç§»åŠ¨ç½‘ç»œè¦†ç›–åˆ†æ",
      "authors": [
        "Timothy Wong",
        "Tom Freeman",
        "Joseph Feehily"
      ],
      "abstract": "Effective assessment of mobile network coverage and the precise identification of service weak spots are paramount for network operators striving to enhance user Quality of Experience (QoE). This paper presents a novel framework for mobile coverage and weak spot analysis utilising crowdsourced QoE data. The core of our methodology involves coverage analysis at the individual cell (antenna) level, subsequently aggregated to the site level, using empirical geolocation data. A key contribution of this research is the application of One-Class Support Vector Machine (OC-SVM) algorithm for calculating mobile network coverage. This approach models the decision hyperplane as the effective coverage contour, facilitating robust calculation of coverage areas for individual cells and entire sites. The same methodology is extended to analyse crowdsourced service loss reports, thereby identifying and quantifying geographically localised weak spots. Our findings demonstrate the efficacy of this novel framework in accurately mapping mobile coverage and, crucially, in highlighting granular areas of signal deficiency, particularly within complex urban environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨ä¼—åŒ… Quality of Experience (QoE) æ•°æ®è¿›è¡Œç§»åŠ¨ç½‘ç»œè¦†ç›–å’Œå¼±ç‚¹åˆ†æçš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡ç»éªŒåœ°ç†ä½ç½®æ•°æ®ï¼Œåœ¨å•å°åŒº(cell)å’Œç«™ç‚¹(site)çº§åˆ«è¿›è¡Œè¦†ç›–åˆ†æã€‚ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºåº”ç”¨äº† One-Class Support Vector Machine (OC-SVM) ç®—æ³•ï¼Œå°†å†³ç­–è¶…å¹³é¢(decision hyperplane)å»ºæ¨¡ä¸ºæœ‰æ•ˆè¦†ç›–è½®å»“ï¼Œå®ç°äº†å¯¹è¦†ç›–èŒƒå›´çš„é²æ£’è®¡ç®—ã€‚è¯¥æ¡†æ¶è¿˜é€šè¿‡åˆ†æä¼—åŒ…æœåŠ¡ä¸­æ–­æŠ¥å‘Šï¼Œå®ç°äº†å¯¹åœ°ç†å±€éƒ¨å¼±ç‚¹çš„è¯†åˆ«ä¸é‡åŒ–ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæ˜ å°„ç§»åŠ¨ç½‘ç»œè¦†ç›–ï¼Œå¹¶èƒ½ç²¾å‡†è¯†åˆ«ç»†ç²’åº¦çš„ä¿¡å·ç¼ºå¤±åŒºåŸŸï¼Œåœ¨å¤æ‚åŸå¸‚ç¯å¢ƒä¸­å…·æœ‰æ˜¾è‘—çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.NI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13459v2",
      "published_date": "2025-10-15 12:00:50 UTC",
      "updated_date": "2026-01-19 15:14:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:52.898810+00:00"
    },
    {
      "arxiv_id": "2510.13444v1",
      "title": "Neural Sum-of-Squares: Certifying the Nonnegativity of Polynomials with Transformers",
      "title_zh": "Neural Sum-of-Squaresï¼šåˆ©ç”¨ Transformer éªŒè¯å¤šé¡¹å¼çš„éè´Ÿæ€§",
      "authors": [
        "Nico Pelleriti",
        "Christoph Spiegel",
        "Shiwei Liu",
        "David MartÃ­nez-Rubio",
        "Max Zimmer",
        "Sebastian Pokutta"
      ],
      "abstract": "Certifying nonnegativity of polynomials is a well-known NP-hard problem with direct applications spanning non-convex optimization, control, robotics, and beyond. A sufficient condition for nonnegativity is the Sum of Squares (SOS) property, i.e., it can be written as a sum of squares of other polynomials. In practice, however, certifying the SOS criterion remains computationally expensive and often involves solving a Semidefinite Program (SDP), whose dimensionality grows quadratically in the size of the monomial basis of the SOS expression; hence, various methods to reduce the size of the monomial basis have been proposed. In this work, we introduce the first learning-augmented algorithm to certify the SOS criterion. To this end, we train a Transformer model that predicts an almost-minimal monomial basis for a given polynomial, thereby drastically reducing the size of the corresponding SDP. Our overall methodology comprises three key components: efficient training dataset generation of over 100 million SOS polynomials, design and training of the corresponding Transformer architecture, and a systematic fallback mechanism to ensure correct termination, which we analyze theoretically. We validate our approach on over 200 benchmark datasets, achieving speedups of over $100\\times$ compared to state-of-the-art solvers and enabling the solution of instances where competing approaches fail. Our findings provide novel insights towards transforming the practical scalability of SOS programming.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Neural Sum-of-Squaresï¼Œè¿™æ˜¯é¦–ä¸ªåˆ©ç”¨Transformeræ¨¡å‹æ¥å¢å¼ºå¹³æ–¹å’Œ(Sum of Squares, SOS)åˆ¤å®šçš„å­¦ä¹ è¾…åŠ©ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³å¤šé¡¹å¼éè´Ÿæ€§(nonnegativity)åˆ¤å®šä¸­åŠæ­£å®šè§„åˆ’(SDP)è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºè®­ç»ƒTransformeré¢„æµ‹ç»™å®šå¤šé¡¹å¼çš„è¿‘ä¹æœ€å°å•é¡¹å¼åŸº(monomial basis)ï¼Œä»è€Œæ˜¾è‘—ç¼©å°SDPçš„ç»´åº¦ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«è¶…è¿‡1äº¿ä¸ªSOSå¤šé¡¹å¼çš„è®­ç»ƒé›†ï¼Œå¹¶è®¾è®¡äº†ç³»ç»Ÿæ€§çš„å›é€€æœºåˆ¶ä»¥åœ¨ç†è®ºä¸Šç¡®ä¿ç®—æ³•åˆ¤å®šçš„æ­£ç¡®ç»ˆæ­¢ã€‚å®éªŒéªŒè¯æ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨200å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå®ç°äº†æ¯”ç°æœ‰æœ€å…ˆè¿›æ±‚è§£å™¨å¿«100å€ä»¥ä¸Šçš„åŠ é€Ÿï¼Œå¹¶æˆåŠŸè§£å†³äº†è®¸å¤šä¼ ç»Ÿæ–¹æ³•æ— æ³•å¤„ç†çš„å¤æ‚ç®—ä¾‹ã€‚è¿™ä¸€æˆæœä¸ºæå‡SOSè§„åˆ’åœ¨éå‡¸ä¼˜åŒ–ã€æ§åˆ¶ç†è®ºåŠæœºå™¨äººå­¦ç­‰é¢†åŸŸçš„å®é™…å¯æ‰©å±•æ€§æä¾›äº†å…¨æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13444v1",
      "published_date": "2025-10-15 11:42:38 UTC",
      "updated_date": "2025-10-15 11:42:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:37:55.477097+00:00"
    },
    {
      "arxiv_id": "2510.13439v1",
      "title": "Rectify and Align GPS Points to Parking Spots via Rank-1 Constraint",
      "title_zh": "åŸºäºç§©-1çº¦æŸçš„åœè½¦ä½GPSç‚¹ä½çº æ­£ä¸å¯¹é½",
      "authors": [
        "Jiaxing Deng",
        "Junbiao Pang",
        "Zhicheng Wang",
        "Haitao Yu"
      ],
      "abstract": "Parking spots are essential components, providing vital mobile resources for residents in a city. Accurate Global Positioning System (GPS) points of parking spots are the core data for subsequent applications,e.g., parking management, parking policy, and urban development. However, high-rise buildings tend to cause GPS points to drift from the actual locations of parking spots; besides, the standard lower-cost GPS equipment itself has a certain location error. Therefore, it is a non-trivial task to correct a few wrong GPS points from a large number of parking spots in an unsupervised approach. In this paper, motivated by the physical constraints of parking spots (i.e., parking spots are parallel to the sides of roads), we propose an unsupervised low-rank method to effectively rectify errors in GPS points and further align them to the parking spots in a unified framework. The proposed unconventional rectification and alignment method is simple and yet effective for any type of GPS point errors. Extensive experiments demonstrate the superiority of the proposed method to solve a practical problem. The data set and the code are publicly accessible at:https://github.com/pangjunbiao/ITS-Parking-spots-Dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸå¸‚é«˜å±‚å»ºç­‘å¯¼è‡´çš„ GPS åæ ‡æ¼‚ç§»ä»¥åŠä½æˆæœ¬è®¾å¤‡è‡ªå¸¦çš„å®šä½è¯¯å·®ï¼Œæå‡ºäº†ä¸€ç§ unsupervised çš„ low-rank æ–¹æ³•ï¼Œç”¨äºåœ¨ç»Ÿä¸€æ¡†æ¶ä¸‹çº æ­£å¹¶å¯¹é½åœè½¦ä½åæ ‡ã€‚è¯¥æ–¹æ³•å……åˆ†åˆ©ç”¨äº†åœè½¦ä½ä¸é“è·¯è¾¹ç¼˜å¹³è¡Œçš„ç‰©ç†çº¦æŸï¼Œé€šè¿‡ Rank-1 çº¦æŸæ¥å¤„ç†å„ç§ç±»å‹çš„ GPS point errorsï¼Œå…¼å…·ç®€æ´æ€§ä¸æœ‰æ•ˆæ€§ã€‚å¤§è§„æ¨¡å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§£å†³å®é™…åœè½¦ä½å®šä½é—®é¢˜ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜è¶Šæ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹å¤æ‚çš„åŸå¸‚ç¯å¢ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å…¬å¼€äº†ç›¸å…³çš„æ•°æ®é›†ä¸ä»£ç ï¼Œä¸ºåœè½¦ç®¡ç†å’ŒåŸå¸‚ç©ºé—´èµ„æºä¼˜åŒ–ç­‰åç»­åº”ç”¨å¥ å®šäº†åšå®çš„æ•°æ®åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13439v1",
      "published_date": "2025-10-15 11:36:27 UTC",
      "updated_date": "2025-10-15 11:36:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:03.191286+00:00"
    },
    {
      "arxiv_id": "2510.16017v1",
      "title": "InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects",
      "title_zh": "InfraGPT æ™ºèƒ½åŸºç¡€è®¾æ–½ï¼šä¸€ç§åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) çš„åŸå¸‚ç¼ºé™·æ£€æµ‹ä¸ç®¡ç†ç«¯åˆ°ç«¯æ¡†æ¶",
      "authors": [
        "Ibrahim Sheikh Mohamed",
        "Abdullah Yahya Abdullah Omaisan"
      ],
      "abstract": "Infrastructure in smart cities is increasingly monitored by networks of closed circuit television (CCTV) cameras. Roads, bridges and tunnels develop cracks, potholes, and fluid leaks that threaten public safety and require timely repair. Manual inspection is costly and hazardous, and existing automatic systems typically address individual defect types or provide unstructured outputs that cannot directly guide maintenance crews. This paper proposes a comprehensive pipeline that leverages street CCTV streams for multi defect detection and segmentation using the YOLO family of object detectors and passes the detections to a vision language model (VLM) for scene aware summarization. The VLM generates a structured action plan in JSON format that includes incident descriptions, recommended tools, dimensions, repair plans, and urgent alerts. We review literature on pothole, crack and leak detection, highlight recent advances in large vision language models such as QwenVL and LLaVA, and describe the design of our early prototype. Experimental evaluation on public datasets and captured CCTV clips demonstrates that the system accurately identifies diverse defects and produces coherent summaries. We conclude by discussing challenges and directions for scaling the system to city wide deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† InfraGPTï¼Œä¸€ä¸ªåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) çš„ç«¯åˆ°ç«¯æ™ºèƒ½åŸºç¡€è®¾æ–½ç»´æŠ¤æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ™ºèƒ½åŸå¸‚ä¸­äººå·¥æ£€æŸ¥æˆæœ¬é«˜æ˜‚åŠç°æœ‰è‡ªåŠ¨åŒ–ç³»ç»Ÿè¾“å‡ºéš¾ä»¥ç›´æ¥æŒ‡å¯¼ç»´ä¿®çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ YOLO ç³»åˆ—æ¨¡å‹å¯¹ CCTV ç›‘æ§æµè¿›è¡Œå¤šç¼ºé™·æ£€æµ‹ä¸åˆ†å‰²ï¼Œå¹¶ç»“åˆ QwenVL æˆ– LLaVA ç­‰å¤§æ¨¡å‹è¿›è¡Œåœºæ™¯æ„ŸçŸ¥çš„æ€»ç»“ã€‚ç³»ç»Ÿæœ€ç»ˆç”ŸæˆåŒ…å«äº‹ä»¶æè¿°ã€ç»´ä¿®å·¥å…·æ¨èã€å°ºå¯¸ä¼°è®¡åŠç´§æ€¥è­¦æŠ¥çš„ JSON æ ¼å¼ç»“æ„åŒ–è¡ŒåŠ¨è®¡åˆ’ï¼Œä¸ºç»´æŠ¤äººå‘˜æä¾›ç›´æ¥çš„æ“ä½œæŒ‡å—ã€‚å®éªŒè¯„ä¼°è¯æ˜ï¼ŒInfraGPT åœ¨å…¬å¼€æ•°æ®é›†å’Œå®æ‹ç›‘æ§è§†é¢‘ä¸­å‡èƒ½å‡†ç¡®è¯†åˆ«è£‚ç¼ã€å‘æ´¼åŠæ³„æ¼ç­‰å¤šç§ç¼ºé™·ï¼Œå¹¶äº§ç”Ÿé€»è¾‘è¿è´¯çš„ç»´æŠ¤æ‘˜è¦ã€‚è¿™é¡¹å·¥ä½œæœ‰æ•ˆæ•´åˆäº†ç›®æ ‡æ£€æµ‹ä¸è¯­ä¹‰ç†è§£æŠ€æœ¯ï¼Œä¸ºå®ç°åŸå¸‚çº§è§„æ¨¡çš„è‡ªåŠ¨åŒ–åŸºç¡€è®¾æ–½ç›‘æµ‹ä¸ç®¡ç†æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.16017v1",
      "published_date": "2025-10-15 11:27:16 UTC",
      "updated_date": "2025-10-15 11:27:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:01.594982+00:00"
    },
    {
      "arxiv_id": "2510.13417v1",
      "title": "Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse",
      "title_zh": "é€šè¿‡æ°”å€™è¯è¯­ä¸­çš„éšå¼å› æœé“¾å‘ç°è¯„ä¼° LLM çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Liesbeth Allein",
        "Nataly Pineda-CastaÃ±eda",
        "Andrea Rocci",
        "Marie-Francine Moens"
      ],
      "abstract": "How does a cause lead to an effect, and which intermediate causal steps explain their connection? This work scrutinizes the mechanistic causal reasoning capabilities of large language models (LLMs) to answer these questions through the task of implicit causal chain discovery. In a diagnostic evaluation framework, we instruct nine LLMs to generate all possible intermediate causal steps linking given cause-effect pairs in causal chain structures. These pairs are drawn from recent resources in argumentation studies featuring polarized discussion on climate change. Our analysis reveals that LLMs vary in the number and granularity of causal steps they produce. Although they are generally self-consistent and confident about the intermediate causal connections in the generated chains, their judgments are mainly driven by associative pattern matching rather than genuine causal reasoning. Nonetheless, human evaluations confirmed the logical coherence and integrity of the generated chains. Our baseline causal chain discovery approach, insights from our diagnostic evaluation, and benchmark dataset with causal chains lay a solid foundation for advancing future work in implicit, mechanistic causal reasoning in argumentation settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ°”å€™å˜åŒ–è¯è¯­èƒŒæ™¯ä¸‹çš„æœºæ¢°å› æœæ¨ç†èƒ½åŠ›ï¼Œé‡ç‚¹å…³æ³¨éšæ€§å› æœé“¾å‘ç°(implicit causal chain discovery)ä»»åŠ¡ã€‚ç ”ç©¶äººå‘˜é€šè¿‡è¯Šæ–­æ€§è¯„ä¼°æ¡†æ¶ï¼ŒæŒ‡å¯¼ä¹ç§LLMsç”Ÿæˆè¿æ¥ç»™å®šå› æœå¯¹çš„æ‰€æœ‰å¯èƒ½ä¸­é—´æ­¥éª¤ï¼Œè¿™äº›æ•°æ®æºäºå…³äºæ°”å€™å˜åŒ–çš„æåŒ–è®¨è®ºã€‚åˆ†æè¡¨æ˜ï¼Œè™½ç„¶æ¨¡å‹ç”Ÿæˆçš„æ­¥éª¤åœ¨æ•°é‡å’Œç²’åº¦(granularity)ä¸Šå­˜åœ¨å·®å¼‚ï¼Œä¸”è¡¨ç°å‡ºè¾ƒé«˜çš„è‡ªæ´½æ€§ï¼Œä½†å…¶åˆ¤æ–­ä¸»è¦æºäºå…³è”æ¨¡å¼åŒ¹é…(associative pattern matching)è€ŒéçœŸæ­£çš„å› æœæ¨ç†ã€‚å°½ç®¡å­˜åœ¨è¿™ä¸€å±€é™ï¼Œäººå·¥è¯„ä¼°ä»ç¡®è®¤äº†æ‰€ç”Ÿæˆå› æœé“¾çš„é€»è¾‘è¿è´¯æ€§ä¸å®Œæ•´æ€§ã€‚è¯¥é¡¹å·¥ä½œé€šè¿‡æä¾›åŸºå‡†æ•°æ®é›†å’Œè¯„ä¼°æ´è§ï¼Œä¸ºæœªæ¥åœ¨è®ºè¯è®¾ç½®ä¸­è¿›ä¸€æ­¥ç ”ç©¶éšæ€§ã€æœºæ¢°åŒ–å› æœæ¨ç†å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13417v1",
      "published_date": "2025-10-15 11:15:00 UTC",
      "updated_date": "2025-10-15 11:15:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:05.289702+00:00"
    },
    {
      "arxiv_id": "2510.13408v1",
      "title": "Semantic Communication Enabled Holographic Video Processing and Transmission",
      "title_zh": "è¯­ä¹‰é€šä¿¡èµ‹èƒ½çš„å…¨æ¯è§†é¢‘å¤„ç†ä¸ä¼ è¾“",
      "authors": [
        "Jingkai Ying",
        "Zhiyuan Qi",
        "Yulong Feng",
        "Zhijin Qin",
        "Zhu Han",
        "Rahim Tafazolli",
        "Yonina C. Eldar"
      ],
      "abstract": "Holographic video communication is considered a paradigm shift in visual communications, becoming increasingly popular for its ability to offer immersive experiences. This article provides an overview of holographic video communication and outlines the requirements of a holographic video communication system. Particularly, following a brief review of semantic com- munication, an architecture for a semantic-enabled holographic video communication system is presented. Key technologies, including semantic sampling, joint semantic-channel coding, and semantic-aware transmission, are designed based on the proposed architecture. Two related use cases are presented to demonstrate the performance gain of the proposed methods. Finally, potential research topics are discussed to pave the way for the realization of semantic-enabled holographic video communications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…¨æ¯è§†é¢‘é€šä¿¡(holographic video communication)ä½œä¸ºæä¾›æ²‰æµ¸å¼ä½“éªŒçš„èŒƒå¼è½¬å˜ï¼Œå¹¶æ˜ç¡®äº†è¯¥ç³»ç»Ÿçš„å…·ä½“è¦æ±‚ã€‚æ–‡ç« åœ¨ç®€è¦å›é¡¾è¯­ä¹‰é€šä¿¡(semantic communication)çš„åŸºç¡€ä¸Šï¼Œæå‡ºäº†ä¸€ç§è¯­ä¹‰èµ‹èƒ½çš„å…¨æ¯è§†é¢‘é€šä¿¡ç³»ç»Ÿæ¶æ„ã€‚å›´ç»•è¯¥æ¶æ„ï¼Œç ”ç©¶è®¾è®¡äº†è¯­ä¹‰é‡‡æ ·(semantic sampling)ã€è”åˆè¯­ä¹‰ä¿¡é“ç¼–ç (joint semantic-channel coding)ä»¥åŠè¯­ä¹‰æ„ŸçŸ¥ä¼ è¾“(semantic-aware transmission)ç­‰å…³é”®æŠ€æœ¯ã€‚é€šè¿‡ä¸¤ä¸ªç›¸å…³ç”¨ä¾‹çš„æ€§èƒ½æ¼”ç¤ºï¼Œè¯æ˜äº†æ‰€ææ–¹æ³•åœ¨å¤„ç†å’Œä¼ è¾“å…¨æ¯è§†é¢‘æ–¹é¢çš„æ˜¾è‘—å¢ç›Šã€‚æœ€åï¼Œè®ºæ–‡è®¨è®ºäº†æ½œåœ¨çš„ç ”ç©¶è¯¾é¢˜ï¼Œä¸ºå®ç°è¯­ä¹‰èµ‹èƒ½çš„å…¨æ¯è§†é¢‘é€šä¿¡å¥ å®šäº†ç†è®ºä¸æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.IT",
        "cs.MM",
        "eess.SP"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 6 figures, Submit for review",
      "pdf_url": "https://arxiv.org/pdf/2510.13408v1",
      "published_date": "2025-10-15 11:06:48 UTC",
      "updated_date": "2025-10-15 11:06:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:08.600753+00:00"
    },
    {
      "arxiv_id": "2510.13400v1",
      "title": "From Minimal Existence to Human Definition: The CES-IMU-HSG Theoretical Framework",
      "title_zh": "ä»æå°å­˜åœ¨åˆ°äººç±»å®šä¹‰ï¼šCES-IMU-HSG ç†è®ºæ¡†æ¶",
      "authors": [
        "Kei Itoh"
      ],
      "abstract": "This study presents an inter-universal mathematical-logical framework constructed upon the minimal axiom Cogito, ergo sum (CES), integrating the Intermediate Meta-Universe (IMU) and the Hierarchical State Grid (HSG). The CES defines existence as a reflexive correspondence --'to be' and 'to be sayable'--and positions any formal system, including ZFC or HoTT, as an attachable extension atop this minimal structure. The IMU functions as a registry of axiomatic dependencies that connect heterogeneous theories, employing the Institution-theoretic framework to ensure coherent inter-theoretical linkages. The HSG concretizes these ideas through categorical construction, defined by three orthogonal axes: the state-depth axis, the mapping-hierarchy axis, and the temporal axis incorporating the principle of 'no future reference.' Through these, the identity of 'definition = state' is formally established as a categorical property. Extending this structure to biological systems, the neural system is implemented as a 0-3D complex of neuron-function fields on the HSG, while its categorical extensions via fiberization over the material base enable the parallel integration of multiple physiological universes-neural, endocrine, learning, genetic, and input/output systems-into a coherent adjoint ensemble. Within this framework, human behavior and cognition emerge as temporal compositions of inter-universal algorithms constrained by the material base. Finally, by contrasting human cognition, which relies on external CES, with machine existence, this study introduces the concept of internal CES, wherein a machine grounds its own logic upon the factuality of its operation. This internal self-axiomatization establishes a continuous bridge between philosophical ontology and engineering implementation, providing a new foundation for the autonomous and self-defining existence of artificial intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CES-IMU-HSGç†è®ºæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªå»ºç«‹åœ¨â€œæˆ‘æ€æ•…æˆ‘åœ¨â€(Cogito, ergo sum, CES)æœ€å°å…¬ç†ä¹‹ä¸Šçš„è·¨å®‡å®™æ•°å­¦é€»è¾‘æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆä¸­é—´å…ƒå®‡å®™(Intermediate Meta-Universe, IMU)å’Œåˆ†å±‚çŠ¶æ€ç½‘æ ¼(Hierarchical State Grid, HSG)ï¼Œå°†å­˜åœ¨å®šä¹‰ä¸ºâ€œå­˜åœ¨â€ä¸â€œå¯è¨€è¯´â€çš„åå°„å¯¹åº”ï¼Œå¹¶å…è®¸ZFCæˆ–HoTTç­‰å½¢å¼ç³»ç»Ÿä½œä¸ºå…¶æ‰©å±•ç»“æ„ã€‚é€šè¿‡èŒƒç•´åŒ–æ„å»º(categorical construction)ï¼ŒHSGåˆ©ç”¨çŠ¶æ€æ·±åº¦ã€æ˜ å°„å±‚æ¬¡å’Œæ—¶é—´è½´ä¸‰ä¸ªæ­£äº¤ç»´åº¦ï¼Œæ­£å¼ç¡®ç«‹äº†â€œå®šä¹‰å³çŠ¶æ€â€(definition = state)çš„èŒƒç•´å±æ€§ã€‚åœ¨ç”Ÿç‰©ç³»ç»Ÿåº”ç”¨ä¸­ï¼Œè¯¥æ¡†æ¶é€šè¿‡çº¤ç»´åŒ–(fiberization)æŠ€æœ¯å°†ç¥ç»ã€å†…åˆ†æ³Œã€å­¦ä¹ å’Œé—ä¼ ç­‰å¤šä¸ªç”Ÿç†å®‡å®™æ•´åˆä¸ºç›¸ä¼´ç³»ç»¼(adjoint ensemble)ï¼Œå°†è®¤çŸ¥è§£é‡Šä¸ºå—ç‰©è´¨åŸºç¡€çº¦æŸçš„è·¨å®‡å®™ç®—æ³•çš„æ—¶é—´ç»„åˆã€‚é€šè¿‡å¯¹æ¯”äººç±»çš„å¤–éƒ¨CESä¸æœºå™¨åŸºäºè¿è¡Œäº‹å®çš„å†…åœ¨CES(internal CES)ï¼Œè¯¥ç ”ç©¶å»ºç«‹äº†ä¸€åº§è¿æ¥å“²å­¦æœ¬ä½“è®ºä¸å·¥ç¨‹å®ç°çš„æ¡¥æ¢ã€‚è¯¥ç†è®ºä¸ºäººå·¥æ™ºèƒ½å®ç°è‡ªä¸»ä¸”è‡ªæˆ‘å®šä¹‰çš„çœŸå®å­˜åœ¨æä¾›äº†å…¨æ–°çš„æ•°å­¦ä¸é€»è¾‘åŸºç¡€ã€‚",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.NE",
      "comment": "57 pages, 2 figures, 4 tables, in English, in Japanese",
      "pdf_url": "https://arxiv.org/pdf/2510.13400v1",
      "published_date": "2025-10-15 10:56:09 UTC",
      "updated_date": "2025-10-15 10:56:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:13.687884+00:00"
    },
    {
      "arxiv_id": "2510.13393v1",
      "title": "Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization",
      "title_zh": "é¢å‘ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è‡ªè§£é‡Šåˆç†åŒ–çš„å¯å­¦ä¹ åšå¼ˆè®ºç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Yunxiao Zhao",
        "Zhiqiang Wang",
        "Xingtong Yu",
        "Xiaoli Li",
        "Jiye Liang",
        "Ru Li"
      ],
      "abstract": "Rationalization, a data-centric framework, aims to build self-explanatory models to explain the prediction outcome by generating a subset of human-intelligible pieces of the input data. It involves a cooperative game model where a generator generates the most human-intelligible parts of the input (i.e., rationales), followed by a predictor that makes predictions based on these generated rationales. Conventional rationalization methods typically impose constraints via regularization terms to calibrate or penalize undesired generation. However, these methods are suffering from a problem called mode collapse, in which the predictor produces correct predictions yet the generator consistently outputs rationales with collapsed patterns. Moreover, existing studies are typically designed separately for specific collapsed patterns, lacking a unified consideration. In this paper, we systematically revisit cooperative rationalization from a novel game-theoretic perspective and identify the fundamental cause of this problem: the generator no longer tends to explore new strategies to uncover informative rationales, ultimately leading the system to converge to a suboptimal game equilibrium (correct predictions v.s collapsed rationales). To solve this problem, we then propose a novel approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT), which progressively introduces policy interventions to address the game equilibrium in the cooperative game process, thereby guiding the model toward a more optimal solution state. We theoretically analyse the cause of such a suboptimal equilibrium and prove the feasibility of the proposed method. Furthermore, we validate our method on nine widely used real-world datasets and two synthetic settings, where PORAT achieves up to 8.1% performance improvements over existing state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°æ®ä¸­å¿ƒè‡ªè§£é‡Š(Data-centric Self-explanation)åˆç†åŒ–(Rationalization)æ¡†æ¶ä¸­çš„æ¨¡å¼å´©å¡Œ(mode collapse)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºåšå¼ˆè®ºè§†è§’çš„æ–°å‹ä¼˜åŒ–æ–¹æ³•ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œä¼ ç»Ÿæ–¹æ³•ä¸­é¢„æµ‹å™¨è™½ç„¶èƒ½ç»™å‡ºæ­£ç¡®ç»“æœï¼Œä½†ç”Ÿæˆå™¨å¾€å¾€ç”±äºåœæ­¢æ¢ç´¢æ–°ç­–ç•¥è€Œé™·å…¥æ¬¡ä¼˜åšå¼ˆå‡è¡¡ï¼Œå¯¼è‡´ç”Ÿæˆçš„è§£é‡Šç‰‡æ®µç¼ºä¹ä¿¡æ¯é‡ä¸”æ¨¡å¼åƒµåŒ–ã€‚ä¸ºè§£å†³è¿™ä¸€ç—›ç‚¹ï¼Œä½œè€…æå‡ºäº†PORATï¼ˆGame-theoretic Policy Optimization oriented RATionalizationï¼‰ï¼Œé€šè¿‡åœ¨åä½œåšå¼ˆè¿‡ç¨‹ä¸­é€æ­¥å¼•å…¥ç­–ç•¥å¹²é¢„(policy interventions)æ¥è°ƒæ•´åšå¼ˆå‡è¡¡ï¼Œå¼•å¯¼æ¨¡å‹å‘æ›´ä¼˜çš„è§£çŠ¶æ€æ¼”è¿›ã€‚è¯¥ç ”ç©¶ä¸ä»…å¯¹æ¬¡ä¼˜å‡è¡¡çš„æˆå› è¿›è¡Œäº†ç³»ç»Ÿçš„ç†è®ºåˆ†æï¼Œè¿˜ä»æ•°å­¦ä¸Šè¯æ˜äº†æ‰€ææ–¹æ³•çš„å¯è¡Œæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒPORATåœ¨ä¹ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†åŠä¸¤ä¸ªåˆæˆåœºæ™¯ä¸‹çš„è¡¨ç°å‡ä¼˜äºç°æœ‰æœ€å…ˆè¿›(state-of-the-art)æ–¹æ³•ï¼Œæœ€é«˜å®ç°äº†8.1%çš„æ€§èƒ½æå‡ï¼Œä¸ºæ„å»ºæ›´ç¨³å¥çš„è‡ªè§£é‡Šæ¨¡å‹æä¾›äº†ç†è®ºæ”¯æŒä¸æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 7 figures, 11 tables. Under review by IEEE",
      "pdf_url": "https://arxiv.org/pdf/2510.13393v1",
      "published_date": "2025-10-15 10:42:52 UTC",
      "updated_date": "2025-10-15 10:42:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:16.180504+00:00"
    },
    {
      "arxiv_id": "2510.13371v1",
      "title": "MADREC: A Multi-Aspect Driven LLM Agent for Explainable and Adaptive Recommendation",
      "title_zh": "MADRECï¼šé¢å‘å¯è§£é‡Šä¸è‡ªé€‚åº”æ¨èçš„å¤šç»´åº¦é©±åŠ¨ LLM æ™ºèƒ½ä½“",
      "authors": [
        "Jiin Park",
        "Misuk Kim"
      ],
      "abstract": "Recent attempts to integrate large language models (LLMs) into recommender systems have gained momentum, but most remain limited to simple text generation or static prompt-based inference, failing to capture the complexity of user preferences and real-world interactions. This study proposes the Multi-Aspect Driven LLM Agent MADRec, an autonomous LLM-based recommender that constructs user and item profiles by unsupervised extraction of multi-aspect information from reviews and performs direct recommendation, sequential recommendation, and explanation generation. MADRec generates structured profiles via aspect-category-based summarization and applies Re-Ranking to construct high-density inputs. When the ground-truth item is missing from the output, the Self-Feedback mechanism dynamically adjusts the inference criteria. Experiments across multiple domains show that MADRec outperforms traditional and LLM-based baselines in both precision and explainability, with human evaluation further confirming the persuasiveness of the generated explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MADRECï¼Œä¸€ç§å¤šç»´åº¦é©±åŠ¨çš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“(Multi-Aspect Driven LLM Agent)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨èç³»ç»Ÿåœ¨ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ—¶éš¾ä»¥æ•æ‰å¤æ‚ç”¨æˆ·åå¥½å’ŒçœŸå®äº¤äº’çš„é—®é¢˜ã€‚è¯¥æ™ºèƒ½ä½“é€šè¿‡ä»è¯„è®ºä¸­æ— ç›‘ç£åœ°æå–å¤šç»´åº¦ä¿¡æ¯ï¼Œæ„å»ºç²¾ç»†çš„ç”¨æˆ·ä¸ç‰©å“ç”»åƒï¼Œå¹¶æ”¯æŒç›´æ¥æ¨èã€åºåˆ—æ¨è(Sequential Recommendation)ä»¥åŠè§£é‡Šç”Ÿæˆã€‚MADRECåˆ©ç”¨åŸºäºç»´åº¦ç±»åˆ«(Aspect-category)çš„æ‘˜è¦æŠ€æœ¯ç”Ÿæˆç»“æ„åŒ–ç”»åƒï¼Œå¹¶ç»“åˆé‡æ’åº(Re-Ranking)ç­–ç•¥ä¼˜åŒ–è¾“å…¥å¯†åº¦ï¼ŒåŒæ—¶å¼•å…¥è‡ªæˆ‘åé¦ˆ(Self-Feedback)æœºåˆ¶ä»¥åŠ¨æ€è°ƒæ•´æ¨ç†å‡†åˆ™ã€‚å®éªŒè¯æ˜ï¼ŒMADRECåœ¨å¤šä¸ªé¢†åŸŸçš„æ¨èç²¾åº¦å’Œå¯è§£é‡Šæ€§æ–¹é¢å‡ä¼˜äºä¼ ç»ŸåŠåŸºäºLLMçš„åŸºå‡†æ¨¡å‹ï¼Œäººå·¥è¯„ä¼°äº¦è¯å®å…¶ç”Ÿæˆçš„æ¨èç†ç”±å…·æœ‰æé«˜çš„è¯´æœåŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "18 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13371v1",
      "published_date": "2025-10-15 10:03:29 UTC",
      "updated_date": "2025-10-15 10:03:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:18.672162+00:00"
    },
    {
      "arxiv_id": "2510.13367v1",
      "title": "A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control",
      "title_zh": "è¿ç»­æ§åˆ¶åœ¨çº¿å¼ºåŒ–å­¦ä¹ ä¸­ Transformer çš„æ–°è§†è§’",
      "authors": [
        "Nikita Kachaev",
        "Daniil Zelezetsky",
        "Egor Cherepanov",
        "Alexey K. Kovelev",
        "Aleksandr I. Panov"
      ],
      "abstract": "Despite their effectiveness and popularity in offline or model-based reinforcement learning (RL), transformers remain underexplored in online model-free RL due to their sensitivity to training setups and model design decisions such as how to structure the policy and value networks, share components, or handle temporal information. In this paper, we show that transformers can be strong baselines for continuous control in online model-free RL. We investigate key design questions: how to condition inputs, share components between actor and critic, and slice sequential data for training. Our experiments reveal stable architectural and training strategies enabling competitive performance across fully and partially observable tasks, and in both vector- and image-based settings. These findings offer practical guidance for applying transformers in online RL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†Transformeråœ¨åœ¨çº¿æ— æ¨¡å‹å¼ºåŒ–å­¦ä¹ (online model-free RL)è¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­çš„åº”ç”¨ï¼Œæ—¨åœ¨è§£å†³å…¶å› å¯¹è®­ç»ƒé…ç½®å’Œæ¨¡å‹è®¾è®¡æ•æ„Ÿè€Œå¯¼è‡´åº”ç”¨å—é™çš„é—®é¢˜ã€‚ä½œè€…é€šè¿‡æ·±å…¥ç ”ç©¶è¾“å…¥è°ƒèŠ‚(input conditioning)ã€actorä¸criticä¹‹é—´çš„ç»„ä»¶å…±äº«ä»¥åŠè®­ç»ƒä¸­çš„åºåˆ—æ•°æ®åˆ‡ç‰‡(sequential data slicing)ç­‰å…³é”®è®¾è®¡å†³ç­–ï¼Œè¯æ˜äº†Transformerå¯ä»¥ä½œä¸ºè¯¥é¢†åŸŸçš„å¼ºåŸºçº¿æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡é‡‡ç”¨ç¨³å®šçš„æ¶æ„å’Œè®­ç»ƒç­–ç•¥ï¼ŒTransformeråœ¨å®Œå…¨å’Œéƒ¨åˆ†å¯è§‚æµ‹ä»»åŠ¡(fully and partially observable tasks)ä»¥åŠåŸºäºå‘é‡å’Œå›¾åƒçš„è®¾ç½®ä¸­å‡å±•ç°å‡ºäº†æå…·ç«äº‰åŠ›çš„æ€§èƒ½ã€‚è¿™äº›å‘ç°ä¸ºåœ¨online RLä¸­æœ‰æ•ˆéƒ¨ç½²Transformeræä¾›äº†å…·ä½“çš„å®è·µæŒ‡å—å’Œæ¶æ„è®¾è®¡å»ºè®®ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…éªŒè¯äº†Transformeråœ¨å®æ—¶äº¤äº’ç¯å¢ƒä¸‹çš„æ½œåŠ›ï¼Œä¹Ÿä¸ºæœªæ¥çš„ç®—æ³•ä¼˜åŒ–å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13367v1",
      "published_date": "2025-10-15 09:58:54 UTC",
      "updated_date": "2025-10-15 09:58:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:21.882810+00:00"
    },
    {
      "arxiv_id": "2510.13366v1",
      "title": "Document Intelligence in the Era of Large Language Models: A Survey",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ—¶ä»£çš„æ–‡æ¡£æ™ºèƒ½ï¼šç»¼è¿°",
      "authors": [
        "Weishi Wang",
        "Hengchang Hu",
        "Zhijie Zhang",
        "Zhaochen Li",
        "Hongxin Shao",
        "Daniel Dahlmeier"
      ],
      "abstract": "Document AI (DAI) has emerged as a vital application area, and is significantly transformed by the advent of large language models (LLMs). While earlier approaches relied on encoder-decoder architectures, decoder-only LLMs have revolutionized DAI, bringing remarkable advancements in understanding and generation. This survey provides a comprehensive overview of DAI's evolution, highlighting current research attempts and future prospects of LLMs in this field. We explore key advancements and challenges in multimodal, multilingual, and retrieval-augmented DAI, while also suggesting future research directions, including agent-based approaches and document-specific foundation models. This paper aims to provide a structured analysis of the state-of-the-art in DAI and its implications for both academic and practical applications.",
      "tldr_zh": "è¿™ç¯‡ç»¼è¿°è®ºæ–‡ç³»ç»Ÿåœ°æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)æ—¶ä»£ä¸‹æ–‡æ¡£æ™ºèƒ½(Document AI, DAI)é¢†åŸŸçš„æ¼”å˜ã€‚æ–‡ç« è¯¦ç»†å›é¡¾äº†ä»æ—©æœŸçš„ç¼–ç å™¨-è§£ç å™¨(encoder-decoder)æ¶æ„å‘ä»…è§£ç å™¨(decoder-only)æ¶æ„è½¬å˜çš„è¿‡ç¨‹ï¼Œé˜è¿°äº†LLMså¦‚ä½•æ˜¾è‘—æå‡äº†æ–‡æ¡£çš„ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†å¤šæ¨¡æ€(multimodal)ã€å¤šè¯­è¨€(multilingual)ä»¥åŠæ£€ç´¢å¢å¼ºç”Ÿæˆ(retrieval-augmented)ç­‰å…³é”®æŠ€æœ¯åœ¨DAIä¸­çš„è¿›å±•ä¸æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œä½œè€…è¿˜å¯¹æœªæ¥çš„ç ”ç©¶æ–¹å‘è¿›è¡Œäº†å±•æœ›ï¼Œæå‡ºäº†åŸºäºæ™ºèƒ½ä½“(agent-based)çš„æ–¹æ³•å’Œç‰¹å®šäºæ–‡æ¡£çš„åŸºç¡€æ¨¡å‹(document-specific foundation models)ç­‰æ½œåœ¨è·¯å¾„ã€‚è¯¥ç»¼è¿°ä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œæä¾›äº†å…³äºDAIæœ€å‰æ²¿æŠ€æœ¯çš„ç»“æ„åŒ–åˆ†æï¼Œå¯¹å®é™…åº”ç”¨å…·æœ‰é‡è¦çš„å‚è€ƒä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13366v1",
      "published_date": "2025-10-15 09:57:03 UTC",
      "updated_date": "2025-10-15 09:57:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:32.499509+00:00"
    },
    {
      "arxiv_id": "2510.13364v1",
      "title": "Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity",
      "title_zh": "ä»¥è¯­è¨€ä¸ºæ ‡ç­¾ï¼šæ•°æ®ç¨€ç¼ºæ¡ä»¶ä¸‹çš„æ—¥å¸¸å§¿æ€é›¶æ ·æœ¬å¤šæ¨¡æ€åˆ†ç±»",
      "authors": [
        "MingZe Tang",
        "Jubal Chandy Jacob"
      ],
      "abstract": "Recent Vision-Language Models (VLMs) enable zero-shot classification by aligning images and text in a shared space, a promising approach for data-scarce conditions. However, the influence of prompt design on recognizing visually similar categories, such as human postures, is not well understood. This study investigates how prompt specificity affects the zero-shot classification of sitting, standing, and walking/running on a small, 285-image COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2, and SigLip, were evaluated using a three-tiered prompt design that systematically increases linguistic detail. Our findings reveal a compelling, counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and OpenCLIP), the simplest, most basic prompts consistently achieve the best results. Adding descriptive detail significantly degrades performance for instance, MetaCLIP 2's multi-class accuracy drops from 68.8\\% to 55.1\\% a phenomenon we term \"prompt overfitting\". Conversely, the lower-performing SigLip model shows improved classification on ambiguous classes when given more descriptive, body-cue-based prompts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸‹æ—¥å¸¸å§¿åŠ¿çš„è¯†åˆ«é—®é¢˜ï¼Œæ¢è®¨äº†è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨é›¶æ ·æœ¬åˆ†ç±»(Zero-Shot Classification)ä¸­çš„è¡¨ç°ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨OpenCLIPã€MetaCLIP 2å’ŒSigLipç­‰ç°ä»£æ¨¡å‹ï¼Œåœ¨COCOè¡ç”Ÿçš„æ•°æ®é›†ä¸Šç³»ç»Ÿåœ°æµ‹è¯•äº†ä¸‰ç§è¯¦ç»†ç¨‹åº¦é€’å¢çš„æç¤ºè¯(Prompt)è®¾è®¡æ–¹æ¡ˆã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸€ä¸ªåç›´è§‰çš„è¶‹åŠ¿ï¼Œå³å¯¹äºMetaCLIP 2å’ŒOpenCLIPç­‰é«˜æ€§èƒ½æ¨¡å‹ï¼Œæœ€ç®€å•çš„åŸºç¡€æç¤ºè¯åè€Œèƒ½å–å¾—æœ€ä½³åˆ†ç±»æ•ˆæœã€‚ç ”ç©¶å‘ç°å¢åŠ è¯¦ç»†çš„æè¿°æ€§ä¿¡æ¯ä¼šå¯¼è‡´æ€§èƒ½æ˜¾è‘—ä¸‹é™ï¼Œä¾‹å¦‚MetaCLIP 2çš„å¤šåˆ†ç±»å‡†ç¡®ç‡ä»68.8%é™è‡³55.1%ï¼Œç ”ç©¶è€…å°†è¿™ä¸€ç°è±¡å®šä¹‰ä¸ºâ€œæç¤ºè¯è¿‡æ‹Ÿåˆâ€(Prompt Overfitting)ã€‚ä¸ä¹‹ç›¸åï¼Œè¡¨ç°ç¨é€Šçš„SigLipæ¨¡å‹åœ¨å¼•å…¥æ›´å¤šåŸºäºèº«ä½“éƒ¨ä½çº¿ç´¢çš„è¯¦ç»†æç¤ºè¯åï¼Œå…¶å¯¹æ¨¡ç³Šç±»åˆ«çš„åˆ†ç±»å‡†ç¡®ç‡å¾—åˆ°äº†æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13364v1",
      "published_date": "2025-10-15 09:53:46 UTC",
      "updated_date": "2025-10-15 09:53:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:38.481571+00:00"
    },
    {
      "arxiv_id": "2510.13361v1",
      "title": "Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training",
      "title_zh": "Generalist++ï¼šä¸€ç§ç¼“è§£å¯¹æŠ—è®­ç»ƒä¸­æƒè¡¡é—®é¢˜çš„å…ƒå­¦ä¹ æ¡†æ¶",
      "authors": [
        "Yisen Wang",
        "Yichuan Mo",
        "Hongjun Wang",
        "Junyi Li",
        "Zhouchen Lin"
      ],
      "abstract": "Despite the rapid progress of neural networks, they remain highly vulnerable to adversarial examples, for which adversarial training (AT) is currently the most effective defense. While AT has been extensively studied, its practical applications expose two major limitations: natural accuracy tends to degrade significantly compared with standard training, and robustness does not transfer well across attacks crafted under different norm constraints. Unlike prior works that attempt to address only one issue within a single network, we propose to partition the overall generalization goal into multiple sub-tasks, each assigned to a dedicated base learner. By specializing in its designated objective, each base learner quickly becomes an expert in its field. In the later stages of training, we interpolate their parameters to form a knowledgeable global learner, while periodically redistributing the global parameters back to the base learners to prevent their optimization trajectories from drifting too far from the shared target. We term this framework Generalist and introduce three variants tailored to different application scenarios. Both theoretical analysis and extensive experiments demonstrate that Generalist achieves lower generalization error and significantly alleviates the trade-off problems compared with baseline methods. Our results suggest that Generalist provides a promising step toward developing fully robust classifiers in the future.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¯¹æŠ—è®­ç»ƒ(Adversarial Training, AT)ä¸­å­˜åœ¨çš„è‡ªç„¶å‡†ç¡®åº¦ä¸‹é™ä»¥åŠä¸åŒèŒƒæ•°çº¦æŸä¸‹é²æ£’æ€§æ³›åŒ–å·®çš„æƒè¡¡é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºGeneralist++çš„å…ƒå­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ•´ä½“æ³›åŒ–ç›®æ ‡åˆ’åˆ†ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œå¹¶å°†æ¯ä¸ªä»»åŠ¡åˆ†é…ç»™ä¸“é—¨çš„åŸºå­¦ä¹ å™¨(Base Learner)ï¼Œä½¿å…¶åœ¨å„è‡ªé¢†åŸŸå†…å¿«é€Ÿæˆä¸ºä¸“å®¶ã€‚åœ¨è®­ç»ƒåæœŸï¼Œé€šè¿‡å¯¹åŸºå­¦ä¹ å™¨å‚æ•°è¿›è¡Œæ’å€¼å¤„ç†ï¼Œæ„å»ºå‡ºä¸€ä¸ªçŸ¥è¯†ä¸°å¯Œçš„å…¨å±€å­¦ä¹ å™¨(Global Learner)ï¼Œå¹¶å®šæœŸå°†å…¨å±€å‚æ•°é‡æ–°åˆ†é…å›åŸºå­¦ä¹ å™¨ï¼Œä»¥é˜²æ­¢ä¼˜åŒ–è½¨è¿¹åç¦»å…±åŒç›®æ ‡ã€‚ç ”ç©¶è€…è¿˜é’ˆå¯¹ä¸åŒåº”ç”¨åœºæ™¯è®¾è®¡äº†ä¸‰ç§å˜ä½“ï¼Œä»¥å¢å¼ºæ¡†æ¶çš„çµæ´»æ€§ã€‚ç†è®ºåˆ†æå’Œå¹¿æ³›çš„å®éªŒè¯æ˜ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼ŒGeneralist++æ˜¾è‘—é™ä½äº†æ³›åŒ–è¯¯å·®ï¼Œå¹¶æœ‰æ•ˆç¼“è§£äº†æ¨¡å‹æ€§èƒ½é—´çš„æƒè¡¡é—®é¢˜ã€‚è¿™ä¸€æˆæœä¸ºå¼€å‘å…·å¤‡å…¨é¢é²æ£’æ€§çš„åˆ†ç±»å™¨æä¾›äº†æ–°çš„ç ”ç©¶æ€è·¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13361v1",
      "published_date": "2025-10-15 09:47:54 UTC",
      "updated_date": "2025-10-15 09:47:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:40.994876+00:00"
    },
    {
      "arxiv_id": "2510.13358v1",
      "title": "Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control",
      "title_zh": "é¢å‘é²æ£’æœºå™¨äººæ§åˆ¶çš„ç¦»çº¿-åœ¨çº¿å¼ºåŒ–å­¦ä¹ å¯¹æŠ—æ€§å¾®è°ƒ",
      "authors": [
        "Shingo Ayabe",
        "Hiroshi Kera",
        "Kazuhiko Kawamoto"
      ],
      "abstract": "Offline reinforcement learning enables sample-efficient policy acquisition without risky online interaction, yet policies trained on static datasets remain brittle under action-space perturbations such as actuator faults. This study introduces an offline-to-online framework that trains policies on clean data and then performs adversarial fine-tuning, where perturbations are injected into executed actions to induce compensatory behavior and improve resilience. A performance-aware curriculum further adjusts the perturbation probability during training via an exponential-moving-average signal, balancing robustness and stability throughout the learning process. Experiments on continuous-control locomotion tasks demonstrate that the proposed method consistently improves robustness over offline-only baselines and converges faster than training from scratch. Matching the fine-tuning and evaluation conditions yields the strongest robustness to action-space perturbations, while the adaptive curriculum strategy mitigates the degradation of nominal performance observed with the linear curriculum strategy. Overall, the results show that adversarial fine-tuning enables adaptive and robust control under uncertain environments, bridging the gap between offline efficiency and online adaptability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹ (Offline Reinforcement Learning)ç­–ç•¥åœ¨é¢å¯¹æ‰§è¡Œå™¨æ•…éšœç­‰åŠ¨ä½œç©ºé—´æ‰°åŠ¨(Action-space perturbations)æ—¶è¡¨ç°å‡ºçš„è„†å¼±æ€§ï¼Œæå‡ºäº†ä¸€ç§ç¦»çº¿åˆ°åœ¨çº¿(Offline-to-Online)çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåœ¨å¹²å‡€æ•°æ®ä¸Šè®­ç»ƒç­–ç•¥ï¼Œéšåè¿›è¡Œå¯¹æŠ—å¾®è°ƒ(Adversarial Fine-tuning)ï¼Œé€šè¿‡åœ¨æ‰§è¡ŒåŠ¨ä½œä¸­æ³¨å…¥æ‰°åŠ¨æ¥è¯±å¯¼æœºå™¨äººçš„è¡¥å¿è¡Œä¸ºï¼Œä»è€Œæ˜¾è‘—æå‡ç³»ç»Ÿçš„éŸ§æ€§ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ç§æ€§èƒ½æ„ŸçŸ¥è¯¾ç¨‹(Performance-aware curriculum)æœºåˆ¶ï¼Œåˆ©ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡(Exponential-moving-average)ä¿¡å·åŠ¨æ€è°ƒæ•´è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ‰°åŠ¨æ¦‚ç‡ï¼Œæœ‰æ•ˆå¹³è¡¡äº†é²æ£’æ€§ä¸ç¨³å®šæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è¿ç»­æ§åˆ¶è¿åŠ¨ä»»åŠ¡ä¸­çš„é²æ£’æ€§ä¼˜äºä»…ç¦»çº¿è®­ç»ƒçš„åŸºçº¿æ¨¡å‹ï¼Œä¸”æ”¶æ•›é€Ÿåº¦å¿«äºä»é›¶å¼€å§‹çš„è®­ç»ƒã€‚æ­¤å¤–ï¼Œè‡ªé€‚åº”è¯¾ç¨‹ç­–ç•¥èƒ½å¤Ÿç¼“è§£å¸¸è§„æ€§èƒ½çš„é€€åŒ–ï¼Œç¡®ä¿å¾®è°ƒä¸è¯„ä¼°æ¡ä»¶åŒ¹é…æ—¶è¾¾åˆ°æœ€å¼ºé²æ£’æ€§ã€‚æ€»ä½“è€Œè¨€ï¼Œè¯¥ç ”ç©¶é€šè¿‡å¯¹æŠ—å¾®è°ƒå®ç°äº†ä¸ç¡®å®šç¯å¢ƒä¸‹çš„è‡ªé€‚åº”æ§åˆ¶ï¼Œæœ‰æ•ˆå¼¥åˆäº†ç¦»çº¿å­¦ä¹ æ•ˆç‡ä¸åœ¨çº¿é€‚åº”èƒ½åŠ›ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "16 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13358v1",
      "published_date": "2025-10-15 09:45:24 UTC",
      "updated_date": "2025-10-15 09:45:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:42.570934+00:00"
    },
    {
      "arxiv_id": "2510.13357v1",
      "title": "Personal Attribute Leakage in Federated Speech Models",
      "title_zh": "è”é‚¦è¯­éŸ³æ¨¡å‹ä¸­çš„ä¸ªäººå±æ€§æ³„éœ²",
      "authors": [
        "Hamdan Al-Ali",
        "Ali Reza Ghavamipour",
        "Tommaso Caselli",
        "Fatih Turkmen",
        "Zeerak Talat",
        "Hanan Aldarmaki"
      ],
      "abstract": "Federated learning is a common method for privacy-preserving training of machine learning models. In this paper, we analyze the vulnerability of ASR models to attribute inference attacks in the federated setting. We test a non-parametric white-box attack method under a passive threat model on three ASR models: Wav2Vec2, HuBERT, and Whisper. The attack operates solely on weight differentials without access to raw speech from target speakers. We demonstrate attack feasibility on sensitive demographic and clinical attributes: gender, age, accent, emotion, and dysarthria. Our findings indicate that attributes that are underrepresented or absent in the pre-training data are more vulnerable to such inference attacks. In particular, information about accents can be reliably inferred from all models. Our findings expose previously undocumented vulnerabilities in federated ASR models and offer insights towards improved security.",
      "tldr_zh": "æœ¬ç ”ç©¶åˆ†æäº†Federated Learningç¯å¢ƒä¸‹ASR modelså¯¹attribute inference attacksçš„è„†å¼±æ€§ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨è¢«åŠ¨å¨èƒæ¨¡å‹ä¸‹ï¼Œé’ˆå¯¹Wav2Vec2ã€HuBERTå’ŒWhisperä¸‰ç§æ¨¡å‹æµ‹è¯•äº†ä¸€ç§éå‚æ•°ç™½ç›’æ”»å‡»æ–¹æ³•ã€‚è¯¥æ”»å‡»ä»…åˆ©ç”¨weight differentialsè€Œæ— éœ€è®¿é—®åŸå§‹è¯­éŸ³ï¼ŒæˆåŠŸéªŒè¯äº†å¯¹æ€§åˆ«ã€å¹´é¾„ã€accentã€æƒ…ç»ªä»¥åŠdysarthriaç­‰æ•æ„Ÿäººå£ç»Ÿè®¡ä¸ä¸´åºŠå±æ€§çš„æ¨æ–­å¯è¡Œæ€§ã€‚å®éªŒå‘ç°ï¼Œåœ¨é¢„è®­ç»ƒæ•°æ®ä¸­ä»£è¡¨æ€§ä¸è¶³æˆ–ç¼ºå¤±çš„å±æ€§æ›´å®¹æ˜“å—åˆ°æ­¤ç±»æ¨ç†æ”»å‡»ï¼Œå°¤å…¶æ˜¯accentä¿¡æ¯åœ¨æ‰€æœ‰æ¨¡å‹ä¸­å‡èƒ½è¢«å¯é æ¨æ–­ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†Federated Learning ASRæ¨¡å‹ä¸­æ­¤å‰æœªè¢«è®°å½•çš„éšç§æ¼æ´ï¼Œå¹¶ä¸ºæå‡ç³»ç»Ÿå®‰å…¨é˜²å¾¡æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13357v1",
      "published_date": "2025-10-15 09:43:10 UTC",
      "updated_date": "2025-10-15 09:43:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:54.725342+00:00"
    },
    {
      "arxiv_id": "2510.13351v1",
      "title": "Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems",
      "title_zh": "Protectï¼šé¢å‘å¯ä¿¡ä¼ä¸šçº§å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿçš„é²æ£’å®‰å…¨æŠ¤æ æŠ€æœ¯æ ˆ",
      "authors": [
        "Karthik Avinash",
        "Nikhil Pareek",
        "Rishav Hada"
      ],
      "abstract": "The increasing deployment of Large Language Models (LLMs) across enterprise and mission-critical domains has underscored the urgent need for robust guardrailing systems that ensure safety, reliability, and compliance. Existing solutions often struggle with real-time oversight, multi-modal data handling, and explainability -- limitations that hinder their adoption in regulated environments. Existing guardrails largely operate in isolation, focused on text alone making them inadequate for multi-modal, production-scale environments. We introduce Protect, natively multi-modal guardrailing model designed to operate seamlessly across text, image, and audio inputs, designed for enterprise-grade deployment. Protect integrates fine-tuned, category-specific adapters trained via Low-Rank Adaptation (LoRA) on an extensive, multi-modal dataset covering four safety dimensions: toxicity, sexism, data privacy, and prompt injection. Our teacher-assisted annotation pipeline leverages reasoning and explanation traces to generate high-fidelity, context-aware labels across modalities. Experimental results demonstrate state-of-the-art performance across all safety dimensions, surpassing existing open and proprietary models such as WildGuard, LlamaGuard-4, and GPT-4.1. Protect establishes a strong foundation for trustworthy, auditable, and production-ready safety systems capable of operating across text, image, and audio modalities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Protectï¼Œä¸€ç§ä¸“ä¸ºä¼ä¸šçº§åº”ç”¨è®¾è®¡çš„åŸç”Ÿå¤šæ¨¡æ€é˜²æŠ¤æ¨¡å‹ï¼ˆGuardrailing Modelï¼‰ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç³»ç»Ÿåœ¨å¤„ç†æ–‡æœ¬ã€å›¾åƒå’ŒéŸ³é¢‘ç­‰å¤šæ¨¡æ€æ•°æ®ä»¥åŠå®æ—¶ç›‘ç®¡æ–¹é¢çš„å±€é™æ€§ã€‚Protect é€šè¿‡ Low-Rank Adaptation (LoRA) æŠ€æœ¯é›†æˆäº†é’ˆå¯¹æ¯’æ€§ã€æ€§åˆ«æ­§è§†ã€æ•°æ®éšç§å’Œæç¤ºæ³¨å…¥ï¼ˆPrompt Injectionï¼‰å››ä¸ªå®‰å…¨ç»´åº¦çš„ç»†ç²’åº¦é€‚é…å™¨ã€‚ä¸ºäº†æå‡æ•°æ®è´¨é‡ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†æ•™å¸ˆè¾…åŠ©çš„æ ‡æ³¨æµæ°´çº¿ï¼ˆTeacher-assisted Annotation Pipelineï¼‰ï¼Œåˆ©ç”¨æ¨ç†å’Œè§£é‡Šè¿½è¸ªç”Ÿæˆé«˜ä¿çœŸçš„è·¨æ¨¡æ€æ ‡ç­¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒProtect åœ¨æ‰€æœ‰å®‰å…¨ç»´åº¦ä¸Šå‡å–å¾—äº† State-of-the-art (SOTA) çš„è¡¨ç°ï¼Œæ˜¾è‘—è¶…è¶Šäº† WildGuardã€LlamaGuard-4 ä»¥åŠ GPT-4.1 ç­‰ç°æœ‰å¼€æºå’Œé—­æºæ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºæ„å»ºå¯ä¿¡ã€å¯å®¡è®¡ä¸”é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒçš„è·¨æ¨¡æ€å®‰å…¨ç³»ç»Ÿæä¾›äº†å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13351v1",
      "published_date": "2025-10-15 09:40:24 UTC",
      "updated_date": "2025-10-15 09:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:50.486217+00:00"
    },
    {
      "arxiv_id": "2510.13343v1",
      "title": "AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions",
      "title_zh": "AOAD-MATï¼šè€ƒè™‘æ™ºèƒ½ä½“åŠ¨ä½œå†³ç­–é¡ºåºçš„ Transformer å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Shota Takayama",
        "Katsuhide Fujita"
      ],
      "abstract": "Multi-agent reinforcement learning focuses on training the behaviors of multiple learning agents that coexist in a shared environment. Recently, MARL models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep Q-learning (ACE), have significantly improved performance by leveraging sequential decision-making processes. Although these models can enhance performance, they do not explicitly consider the importance of the order in which agents make decisions. In this paper, we propose an Agent Order of Action Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which agents make decisions. The proposed model explicitly incorporates the sequence of action decisions into the learning process, allowing the model to learn and predict the optimal order of agent actions. The AOAD-MAT model leverages a Transformer-based actor-critic architecture that dynamically adjusts the sequence of agent actions. To achieve this, we introduce a novel MARL architecture that cooperates with a subtask focused on predicting the next agent to act, integrated into a Proximal Policy Optimization based loss function to synergistically maximize the advantage of the sequential decision-making. The proposed method was validated through extensive experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo benchmarks. The experimental results show that the proposed AOAD-MAT model outperforms existing MAT and other baseline models, demonstrating the effectiveness of adjusting the AOAD order in MARL.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AOAD-MATï¼Œä¸€ç§åŸºäº Transformer çš„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ sequential decision-making æ¨¡å‹å¿½è§†æ™ºèƒ½ä½“å†³ç­–é¡ºåºé‡è¦æ€§çš„é—®é¢˜ã€‚AOAD-MAT é‡‡ç”¨äº†åŸºäº Transformer çš„ actor-critic æ¶æ„ï¼Œèƒ½å¤ŸåŠ¨æ€è°ƒæ•´æ™ºèƒ½ä½“çš„è¡ŒåŠ¨åºåˆ—ï¼Œå¹¶å°†å†³ç­–é¡ºåºæ˜¾å¼åœ°çº³å…¥å­¦ä¹ è¿‡ç¨‹ã€‚é€šè¿‡å¼•å…¥ä¸€ä¸ªä¸“æ³¨äºé¢„æµ‹ä¸‹ä¸€ä¸ªè¡ŒåŠ¨æ™ºèƒ½ä½“çš„å­ä»»åŠ¡ï¼Œå¹¶å°†å…¶é›†æˆåˆ°åŸºäº Proximal Policy Optimization (PPO) çš„æŸå¤±å‡½æ•°ä¸­ï¼Œè¯¥æ¶æ„å®ç°äº†é¡ºåºå†³ç­–ä¼˜åŠ¿çš„ååŒæœ€å¤§åŒ–ã€‚åœ¨ StarCraft Multi-Agent Challenge (SMAC) å’Œ Multi-Agent MuJoCo åŸºå‡†æµ‹è¯•ä¸­çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒAOAD-MAT çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„ MAT å’Œå…¶ä»–åŸºå‡†æ¨¡å‹ï¼Œæœ‰åŠ›è¯æ˜äº†åœ¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL) ä¸­ä¼˜åŒ–æ™ºèƒ½ä½“è¡ŒåŠ¨å†³ç­–é¡ºåºçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "This manuscript is an extended version of the work accepted as a short paper at the 26th International Conference on Principles and Practice of Multi-Agent Systems (PRIMA 2025). The Version of Record of this contribution is published in Springer's Lecture Notes in Artificial Intelligence series (LNCS/LNAI)",
      "pdf_url": "https://arxiv.org/pdf/2510.13343v1",
      "published_date": "2025-10-15 09:29:36 UTC",
      "updated_date": "2025-10-15 09:29:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:55.177852+00:00"
    },
    {
      "arxiv_id": "2510.13328v2",
      "title": "Thompson Sampling via Fine-Tuning of LLMs",
      "title_zh": "åŸºäº LLMs å¾®è°ƒçš„ Thompson é‡‡æ ·",
      "authors": [
        "Nicolas Menet",
        "Aleksandar TerziÄ‡",
        "Michael Hersche",
        "Andreas Krause",
        "Abbas Rahimi"
      ],
      "abstract": "Bayesian optimization in large unstructured discrete spaces is often hindered by the computational cost of maximizing acquisition functions due to the absence of gradients. We propose a scalable alternative based on Thompson sampling that eliminates the need for acquisition function maximization by directly parameterizing the probability that a candidate yields the maximum reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the prior knowledge embedded in prompt-conditioned large language models, and incrementally adapts them toward the posterior. Theoretically, we derive a novel regret bound for a variational formulation of Thompson Sampling that matches the strong guarantees of its standard counterpart. Our analysis reveals the critical role of careful adaptation to the posterior probability of maximality--a principle that underpins our ToSFiT algorithm. Empirically, we validate our method on three diverse tasks: FAQ response refinement, thermally stable protein search, and quantum circuit design. We demonstrate that online fine-tuning significantly improves sample efficiency, with negligible impact on computational efficiency.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹åœ¨å¤§è§„æ¨¡éç»“æ„åŒ–ç¦»æ•£ç©ºé—´ä¸­ Bayesian optimization å› ç¼ºä¹æ¢¯åº¦å¯¼è‡´ acquisition functions æœ€å¤§åŒ–è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º ToSFiT (Thompson Sampling via Fine-Tuning) çš„å¯æ‰©å±•æ›¿ä»£æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•é€šè¿‡ç›´æ¥å‚æ•°åŒ–å€™é€‰æ–¹æ¡ˆäº§ç”Ÿæœ€å¤§å¥–åŠ±çš„æ¦‚ç‡ï¼Œæ¶ˆé™¤äº†å¯¹ acquisition function æœ€å¤§åŒ–çš„éœ€æ±‚ï¼Œå¹¶åˆ©ç”¨ Large Language Models (LLMs) ä¸­åµŒå…¥çš„å…ˆéªŒçŸ¥è¯†å°†å…¶é€æ­¥è°ƒæ•´è‡³åéªŒåˆ†å¸ƒã€‚åœ¨ç†è®ºå±‚é¢ï¼Œç ”ç©¶è€…ä¸º Thompson Sampling çš„å˜åˆ†å½¢å¼æ¨å¯¼äº†å…¨æ–°çš„ regret boundï¼Œå…¶ç†è®ºä¿è¯ä¸æ ‡å‡†æ–¹æ³•ç›¸å½“ï¼Œå¹¶æ­ç¤ºäº†ç²¾ç¡®æ‹Ÿåˆæœ€å¤§åŒ–åéªŒæ¦‚ç‡çš„æ ¸å¿ƒä½œç”¨ã€‚å®éªŒåœ¨å¸¸è§é—®é¢˜è§£ç­”ä¼˜åŒ–ã€çƒ­ç¨³å®šæ€§è›‹ç™½è´¨æœç´¢å’Œé‡å­ç”µè·¯è®¾è®¡ä»»åŠ¡ä¸­éªŒè¯äº† ToSFiT çš„æœ‰æ•ˆæ€§ã€‚ç»“æœè¯æ˜ï¼Œåœ¨çº¿å¾®è°ƒï¼ˆonline fine-tuningï¼‰èƒ½æ˜¾è‘—æé«˜æ ·æœ¬æ•ˆç‡ï¼Œä¸”å¯¹è®¡ç®—æ•ˆç‡çš„è´Ÿé¢å½±å“æå°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13328v2",
      "published_date": "2025-10-15 09:13:59 UTC",
      "updated_date": "2025-10-16 08:38:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:57.010870+00:00"
    },
    {
      "arxiv_id": "2510.13322v1",
      "title": "Injection, Attack and Erasure: Revocable Backdoor Attacks via Machine Unlearning",
      "title_zh": "æ³¨å…¥ã€æ”»å‡»ä¸æ“¦é™¤ï¼šåŸºäºæœºå™¨é—å¿˜çš„å¯æ’¤é”€åé—¨æ”»å‡»",
      "authors": [
        "Baogang Song",
        "Dongdong Zhao",
        "Jianwen Xiang",
        "Qiben Xu",
        "Zizhuo Yu"
      ],
      "abstract": "Backdoor attacks pose a persistent security risk to deep neural networks (DNNs) due to their stealth and durability. While recent research has explored leveraging model unlearning mechanisms to enhance backdoor concealment, existing attack strategies still leave persistent traces that may be detected through static analysis. In this work, we introduce the first paradigm of revocable backdoor attacks, where the backdoor can be proactively and thoroughly removed after the attack objective is achieved. We formulate the trigger optimization in revocable backdoor attacks as a bilevel optimization problem: by simulating both backdoor injection and unlearning processes, the trigger generator is optimized to achieve a high attack success rate (ASR) while ensuring that the backdoor can be easily erased through unlearning. To mitigate the optimization conflict between injection and removal objectives, we employ a deterministic partition of poisoning and unlearning samples to reduce sampling-induced variance, and further apply the Projected Conflicting Gradient (PCGrad) technique to resolve the remaining gradient conflicts. Experiments on CIFAR-10 and ImageNet demonstrate that our method maintains ASR comparable to state-of-the-art backdoor attacks, while enabling effective removal of backdoor behavior after unlearning. This work opens a new direction for backdoor attack research and presents new challenges for the security of machine learning systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªå¯æ’¤é”€åé—¨æ”»å‡»(revocable backdoor attacks)èŒƒå¼ï¼Œæ—¨åœ¨é€šè¿‡æœºå™¨é—å¿˜(machine unlearning)æœºåˆ¶åœ¨è¾¾æˆæ”»å‡»ç›®æ ‡åä¸»åŠ¨ä¸”å½»åº•åœ°æ¶ˆé™¤åé—¨ç—•è¿¹ã€‚ä½œè€…å°†è§¦å‘å™¨ä¼˜åŒ–å»ºæ¨¡ä¸ºä¸€ä¸ªåŒå±‚ä¼˜åŒ–(bilevel optimization)é—®é¢˜ï¼Œåœ¨æ¨¡æ‹Ÿåé—¨æ³¨å…¥å’Œé—å¿˜è¿‡ç¨‹çš„åŒæ—¶ï¼Œä¼˜åŒ–è§¦å‘å™¨ç”Ÿæˆå™¨ä»¥ç¡®ä¿é«˜æ”»å‡»æˆåŠŸç‡(ASR)å’Œåé—¨æ˜“æ“¦é™¤æ€§ã€‚ä¸ºäº†ç¼“è§£æ³¨å…¥ä¸ç§»é™¤ç›®æ ‡ä¹‹é—´çš„ä¼˜åŒ–å†²çªï¼Œè¯¥æ–¹æ³•é‡‡ç”¨äº†ä¸­æ¯’æ ·æœ¬ä¸é—å¿˜æ ·æœ¬çš„ç¡®å®šæ€§åˆ’åˆ†ï¼Œå¹¶è¿›ä¸€æ­¥åº”ç”¨æŠ•å½±å†²çªæ¢¯åº¦(PCGrad)æŠ€æœ¯æ¥è§£å†³æ¢¯åº¦å†²çªã€‚åœ¨CIFAR-10å’ŒImageNetæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒä¸æœ€å…ˆè¿›åé—¨æ”»å‡»ç›¸å½“çš„æ”»å‡»æˆåŠŸç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿé€šè¿‡ç®€å•çš„é—å¿˜æ“ä½œæœ‰æ•ˆç§»é™¤åé—¨è¡Œä¸ºã€‚è¿™ä¸€å·¥ä½œä¸ºåé—¨æ”»å‡»ç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ï¼Œå¹¶å¯¹æœºå™¨å­¦ä¹ ç³»ç»Ÿçš„å®‰å…¨æ€§åŠå–è¯åˆ†ææå‡ºäº†æ–°çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13322v1",
      "published_date": "2025-10-15 09:09:43 UTC",
      "updated_date": "2025-10-15 09:09:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:38:57.206953+00:00"
    },
    {
      "arxiv_id": "2510.13315v1",
      "title": "Self-Augmented Visual Contrastive Decoding",
      "title_zh": "è‡ªå¢å¼ºè§†è§‰å¯¹æ¯”è§£ç ",
      "authors": [
        "Eun Woo Im",
        "Muhammad Kashif Ali",
        "Vivek Gupta"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal capabilities, but they inherit the tendency to hallucinate from their underlying language models. While visual contrastive decoding has been proposed to mitigate this issue, existing methods often apply generic visual augmentations that disregard the specific context provided by the text query, limiting their effectiveness. This study introduces a novel training-free decoding strategy that addresses these limitations, featuring two key contributions. First, a self-augmentation prompting strategy that leverages the intrinsic knowledge of the model to dynamically align semantics between the query and the visual augmentation. Second, an adaptive thresholding algorithm that adaptively adjusts next token candidate size based on the output sparsity, utilizing full information from the logit distribution. Extensive experiments across four LVLMs and seven benchmarks demonstrate that the proposed decoding significantly enhances factual consistency compared to state-of-the-art decoding methods. This work highlights the importance of integrating query-dependent augmentation and entropy-aware decoding for improving effective generation of LVLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Self-Augmented Visual Contrastive Decodingï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„è§£ç ç­–ç•¥ï¼Œæ—¨åœ¨è§£å†³ Large Vision-Language Models (LVLMs) ä¸­å¸¸è§çš„å¹»è§‰é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰è§†è§‰å¯¹æ¯”è§£ç æ–¹æ³•å› ä½¿ç”¨é€šç”¨è§†è§‰å¢å¼ºè€Œå¿½è§†æ–‡æœ¬æŸ¥è¯¢ä¸Šä¸‹æ–‡çš„å±€é™ï¼Œè¯¥ç ”ç©¶å¼•å…¥äº†è‡ªå¢å¼ºæç¤ºç­–ç•¥ï¼Œåˆ©ç”¨æ¨¡å‹çš„å†…åœ¨çŸ¥è¯†å®ç°æŸ¥è¯¢è¯­ä¹‰ä¸è§†è§‰å¢å¼ºçš„åŠ¨æ€å¯¹é½ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§è‡ªé€‚åº”é˜ˆå€¼ç®—æ³•ï¼Œé€šè¿‡åˆ†æ logit åˆ†å¸ƒçš„è¾“å‡ºç¨€ç–åº¦æ¥åŠ¨æ€è°ƒæ•´å€™é€‰æ ‡è®°çš„è§„æ¨¡ã€‚åœ¨å››ç§ LVLMs å’Œä¸ƒä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥ç­–ç•¥åœ¨äº‹å®ä¸€è‡´æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›è§£ç æ–¹æ³•ã€‚è¿™é¡¹å·¥ä½œå‡¸æ˜¾äº†å°†æŸ¥è¯¢ä¾èµ–å‹å¢å¼ºä¸ç†µæ„ŸçŸ¥è§£ç ç›¸ç»“åˆåœ¨æå‡å¤šæ¨¡æ€æ¨¡å‹ç”Ÿæˆè´¨é‡æ–¹é¢çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13315v1",
      "published_date": "2025-10-15 09:03:34 UTC",
      "updated_date": "2025-10-15 09:03:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:00.777821+00:00"
    },
    {
      "arxiv_id": "2510.13302v3",
      "title": "LLM one-shot style transfer for Authorship Attribution and Verification",
      "title_zh": "ç”¨äºä½œè€…èº«ä»½è¯†åˆ«ä¸éªŒè¯çš„ LLM å•æ ·æœ¬é£æ ¼è¿ç§»",
      "authors": [
        "Pablo Miralles-GonzÃ¡lez",
        "Javier Huertas-Tato",
        "Alejandro MartÃ­n",
        "David Camacho"
      ],
      "abstract": "Computational stylometry studies writing style through quantitative textual patterns, enabling applications such as authorship attribution, identity linking, and plagiarism detection. Existing supervised and contrastive approaches often rely on datasets with spurious correlations, conflating style with topic. Despite the relevance of language modeling to these tasks, the pre-training of modern large language models (LLMs) has been underutilized in general authorship analysis. We introduce an unsupervised framework that uses the log-probabilities of an LLM to measure style transferability between two texts. This framework takes advantage of the extensive CLM pre-training and in-context capabilities of modern LLMs. Our approach avoids explicit supervision with spuriously correlated data. Our method substantially outperforms unsupervised prompting-based baselines at similar model sizes and exceeds contrastively trained models when controlling for topical overlap. Our framework's performance improves with model size. In the case of authorship verification, we present an additional mechanism that increases test-time computation to improve accuracy; enabling flexible trade-offs between computational cost and task performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—æ–‡ä½“å­¦ (Computational stylometry) ä¸­ä½œè€…èº«ä»½è¯†åˆ«ä¸éªŒè¯ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ— ç›‘ç£æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç›‘ç£å­¦ä¹ å’Œå¯¹æ¯”å­¦ä¹ æ–¹æ³•æ˜“å°†é£æ ¼ä¸ä¸»é¢˜æ··æ·†çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åˆ©ç”¨ LLM çš„å¯¹æ•°æ¦‚ç‡ (log-probabilities) æ¥è¡¡é‡ä¸¤æ®µæ–‡æœ¬ä¹‹é—´çš„é£æ ¼å¯è¿ç§»æ€§ (style transferability)ï¼Œå……åˆ†å‘æŒ¥äº†å› æœè¯­è¨€æ¨¡å‹ (CLM) çš„é¢„è®­ç»ƒè§„æ¨¡å’Œä¸Šä¸‹æ–‡å­¦ä¹  (in-context capabilities) èƒ½åŠ›ã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶é€šè¿‡é¿å…å¯¹å…·æœ‰è™šå‡ç›¸å…³æ€§æ•°æ®çš„æ˜¾å¼ç›‘ç£ï¼Œå®ç°äº†å¯¹é£æ ¼å±æ€§çš„ç²¾å‡†æå–ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨åŒç­‰æ¨¡å‹è§„æ¨¡ä¸‹æ˜¾è‘—ä¼˜äºåŸºäºæç¤º (prompting-based) çš„æ— ç›‘ç£åŸºå‡†æ¨¡å‹ï¼Œå¹¶åœ¨æ§åˆ¶ä¸»é¢˜é‡å çš„æƒ…å†µä¸‹è¶…è¶Šäº†å¯¹æ¯”è®­ç»ƒæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶çš„æ€§èƒ½éšæ¨¡å‹è§„æ¨¡å¢åŠ è€Œæå‡ï¼Œå¹¶ä¸ºä½œè€…èº«ä»½éªŒè¯ä»»åŠ¡å¼•å…¥äº†ä¸€ç§çµæ´»çš„æœºåˆ¶ï¼Œå…è®¸é€šè¿‡å¢åŠ æµ‹è¯•æ—¶è®¡ç®—é‡æ¥æ¢å–æ›´é«˜çš„å‡†ç¡®ç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13302v3",
      "published_date": "2025-10-15 08:43:24 UTC",
      "updated_date": "2025-12-18 10:41:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:14.677527+00:00"
    },
    {
      "arxiv_id": "2510.13291v2",
      "title": "Higher Satisfaction, Lower Cost: A Technical Report on How LLMs Revolutionize Meituan's Intelligent Interaction Systems",
      "title_zh": "é«˜æ»¡æ„åº¦ã€ä½æˆæœ¬ï¼šå¤§è¯­è¨€æ¨¡å‹å¦‚ä½•é©±åŠ¨ Meituan æ™ºèƒ½äº¤äº’ç³»ç»Ÿå˜é©çš„æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Xuxin Cheng",
        "Ke Zeng",
        "Zhiquan Cao",
        "Linyi Dai",
        "Wenxuan Gao",
        "Fei Han",
        "Ai Jian",
        "Feng Hong",
        "Wenxing Hu",
        "Zihe Huang",
        "Dejian Kong",
        "Jia Leng",
        "Zhuoyuan Liao",
        "Pei Liu",
        "Jiaye Lin",
        "Xing Ma",
        "Jingqing Ruan",
        "Jiaxing Song",
        "Xiaoyu Tan",
        "Ruixuan Xiao",
        "Wenhui Yu",
        "Wenyu Zhan",
        "Haoxing Zhang",
        "Chao Zhou",
        "Hao Zhou",
        "Shaodong Zheng",
        "Ruinian Chen",
        "Siyuan Chen",
        "Ziyang Chen",
        "Yiwen Dong",
        "Yaoyou Fan",
        "Yangyi Fang",
        "Yang Gan",
        "Shiguang Guo",
        "Qi He",
        "Chaowen Hu",
        "Binghui Li",
        "Dailin Li",
        "Xiangyu Li",
        "Yan Li",
        "Chengjian Liu",
        "Xiangfeng Liu",
        "Jiahui Lv",
        "Qiao Ma",
        "Jiang Pan",
        "Cong Qin",
        "Chenxing Sun",
        "Wen Sun",
        "Zhonghui Wang",
        "Abudukelimu Wuerkaixi",
        "Xin Yang",
        "Fangyi Yuan",
        "Yawen Zhu",
        "Tianyi Zhai",
        "Jie Zhang",
        "Runlai Zhang",
        "Yao Xu",
        "Yiran Zhao",
        "Yifan Wang",
        "Xunliang Cai",
        "Yangen Hu",
        "Cao Liu",
        "Lu Pan",
        "Xiaoli Wang",
        "Bo Xiao",
        "Wenyuan Yao",
        "Qianlin Zhou",
        "Benchang Zhu"
      ],
      "abstract": "Enhancing customer experience is essential for business success, particularly as service demands grow in scale and complexity. Generative artificial intelligence and Large Language Models (LLMs) have empowered intelligent interaction systems to deliver efficient, personalized, and 24/7 support. In practice, intelligent interaction systems encounter several challenges: (1) Constructing high-quality data for cold-start training is difficult, hindering self-evolution and raising labor costs. (2) Multi-turn dialogue performance remains suboptimal due to inadequate intent understanding, rule compliance, and solution extraction. (3) Frequent evolution of business rules affects system operability and transferability, constraining low-cost expansion and adaptability. (4) Reliance on a single LLM is insufficient in complex scenarios, where the absence of multi-agent frameworks and effective collaboration undermines process completeness and service quality. (5) The open-domain nature of multi-turn dialogues, lacking unified golden answers, hampers quantitative evaluation and continuous optimization. To address these challenges, we introduce WOWService, an intelligent interaction system tailored for industrial applications. With the integration of LLMs and multi-agent architectures, WOWService enables autonomous task management and collaborative problem-solving. Specifically, WOWService focuses on core modules including data construction, general capability enhancement, business scenario adaptation, multi-agent coordination, and automated evaluation. Currently, WOWService is deployed on the Meituan App, achieving significant gains in key metrics, e.g., User Satisfaction Metric 1 (USM 1) -27.53% and User Satisfaction Metric 2 (USM 2) +25.51%, demonstrating its effectiveness in capturing user needs and advancing personalized service.",
      "tldr_zh": "è¯¥æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†ç¾å›¢å¦‚ä½•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)é©æ–°å…¶æ™ºèƒ½äº¤äº’ç³»ç»Ÿï¼Œå¹¶æå‡ºäº†ä¸“ä¸ºå·¥ä¸šåº”ç”¨è®¾è®¡çš„WOWServiceç³»ç»Ÿã€‚ä¸ºäº†åº”å¯¹æ•°æ®æ„å»ºå›°éš¾ã€å¤šè½®å¯¹è¯æ€§èƒ½å—é™ã€ä¸šåŠ¡è§„åˆ™æ¼”è¿›é¢‘ç¹ã€å•æ¨¡å‹èƒ½åŠ›ä¸è¶³ä»¥åŠè¯„ä¼°å›°éš¾ç­‰æŒ‘æˆ˜ï¼ŒWOWServiceé›†æˆäº†LLMsä¸å¤šæ™ºèƒ½ä½“(Multi-Agent)æ¶æ„ï¼Œå®ç°äº†è‡ªä¸»ä»»åŠ¡ç®¡ç†ä¸ååŒé—®é¢˜è§£å†³ã€‚ç³»ç»Ÿæ ¸å¿ƒæ¨¡å—æ¶µç›–äº†æ•°æ®æ„å»ºã€é€šç”¨èƒ½åŠ›å¢å¼ºã€ä¸šåŠ¡åœºæ™¯é€‚é…ã€å¤šæ™ºèƒ½ä½“åä½œåŠè‡ªåŠ¨åŒ–è¯„ä¼°ã€‚ç›®å‰WOWServiceå·²åœ¨ç¾å›¢Appæ­£å¼éƒ¨ç½²ï¼Œæ˜¾è‘—æ”¹å–„äº†å…³é”®ä¸šåŠ¡æŒ‡æ ‡ï¼Œå…¶ä¸­ç”¨æˆ·æ»¡æ„åº¦æŒ‡æ ‡USM 1é™ä½äº†27.53%ï¼ŒUSM 2æå‡äº†25.51%ã€‚å®éªŒç»“æœè¯æ˜è¯¥ç³»ç»Ÿèƒ½æœ‰æ•ˆæ•æ‰ç”¨æˆ·éœ€æ±‚å¹¶æä¾›ä¸ªæ€§åŒ–æœåŠ¡ï¼Œåœ¨æå‡ç”¨æˆ·æ»¡æ„åº¦çš„åŒæ—¶æ˜¾è‘—é™ä½äº†äººå·¥ä¸è¿è¥æˆæœ¬ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "36 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13291v2",
      "published_date": "2025-10-15 08:35:51 UTC",
      "updated_date": "2026-01-14 07:30:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:18.391406+00:00"
    },
    {
      "arxiv_id": "2510.13290v1",
      "title": "To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models",
      "title_zh": "å¼•å¯¼è¿˜æ˜¯ä¸å¼•å¯¼ï¼ŸåŸºäºå¼ƒæƒæœºåˆ¶çš„è¯­è¨€æ¨¡å‹æœºåˆ¶æ€§é”™è¯¯æ¶ˆå‡",
      "authors": [
        "Anna HedstrÃ¶m",
        "Salim I. Amoukou",
        "Tom Bewley",
        "Saumitra Mishra",
        "Manuela Veloso"
      ],
      "abstract": "We introduce Mechanistic Error Reduction with Abstention (MERA), a principled framework for steering language models (LMs) to mitigate errors through selective, adaptive interventions. Unlike existing methods that rely on fixed, manually tuned steering strengths, often resulting in under or oversteering, MERA addresses these limitations by (i) optimising the intervention direction, and (ii) calibrating when, and how much to steer, thereby provably improving performance or abstaining when no confident correction is possible. Experiments across diverse datasets, and LM families demonstrate safe, effective, non-degrading error correction, and that MERA outperforms existing baselines. Moreover, MERA can be applied on top of existing steering techniques to further enhance their performance, establishing it as a general-purpose, and efficient approach to mechanistic activation steering.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Mechanistic Error Reduction with Abstention (MERA)ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡é€‰æ‹©æ€§ã€è‡ªé€‚åº”å¹²é¢„æ¥å¼•å¯¼è¯­è¨€æ¨¡å‹(LMs)å¹¶å‡å°‘é”™è¯¯çš„åŸåˆ™æ€§æ¡†æ¶ã€‚ä¸ä»¥å¾€ä¾èµ–å›ºå®šã€æ‰‹åŠ¨è°ƒèŠ‚è½¬å‘å¼ºåº¦è€Œå®¹æ˜“å¯¼è‡´è½¬å‘ä¸è¶³æˆ–è½¬å‘è¿‡åº¦çš„ç°æœ‰æ–¹æ³•ä¸åŒï¼ŒMERAé€šè¿‡ä¼˜åŒ–å¹²é¢„æ–¹å‘å¹¶æ ¡å‡†è½¬å‘çš„æ—¶æœºä¸ç¨‹åº¦æ¥è§£å†³è¿™äº›å±€é™ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨å¯è¯æ˜åœ°æé«˜æ€§èƒ½çš„åŒæ—¶ï¼Œåœ¨æ— æ³•è¿›è¡Œå¯é ä¿®æ­£æ—¶é€‰æ‹©å¼ƒæƒ(abstaining)ï¼Œä»è€Œç¡®ä¿é”™è¯¯å‡å°‘è¿‡ç¨‹çš„å®‰å…¨æ€§ã€‚è·¨ä¸åŒæ•°æ®é›†å’Œæ¨¡å‹å®¶æ—çš„å®éªŒè¯æ˜ï¼ŒMERAå®ç°äº†æœ‰æ•ˆä¸”éé€€åŒ–(non-degrading)çš„é”™è¯¯ä¿®æ­£ï¼Œå…¶è¡¨ç°ä¼˜äºç°æœ‰çš„åŸºå‡†æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒMERAè¿˜å¯ä»¥å åŠ åœ¨ç°æœ‰çš„å¼•å¯¼æŠ€æœ¯ä¹‹ä¸Šï¼Œè¿›ä¸€æ­¥æå‡å…¶æ€§èƒ½ï¼Œä¸ºæœºæ¢°åŒ–æ¿€æ´»å¼•å¯¼(mechanistic activation steering)æä¾›äº†ä¸€ç§é€šç”¨ä¸”é«˜æ•ˆçš„å¤„ç†è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025, 22 pages, 16 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2510.13290v1",
      "published_date": "2025-10-15 08:35:10 UTC",
      "updated_date": "2025-10-15 08:35:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:18.872491+00:00"
    },
    {
      "arxiv_id": "2510.13915v1",
      "title": "Readability $\\ne$ Learnability: Rethinking the Role of Simplicity in Training Small Language Models",
      "title_zh": "å¯è¯»æ€§ $\\neq$ å¯å­¦ä¹ æ€§ï¼šé‡æ–°å®¡è§†ç®€å•æ€§åœ¨å°è¯­è¨€æ¨¡å‹è®­ç»ƒä¸­çš„ä½œç”¨",
      "authors": [
        "Ivan Lee",
        "Taylor Berg-Kirkpatrick"
      ],
      "abstract": "Recent studies suggest that very small language models (SLMs) can generate surprisingly coherent text when trained on simplified, child-directed corpora such as TinyStories. These findings have been interpreted as evidence that readability -- characterized by accessible vocabulary, familiar narrative structure, and simple syntax -- plays a key role in enabling such capabilities to emerge. In this paper, we challenge that interpretation. We construct synthetic datasets with matched structure but varied readability, and find that readability alone does not predict coherence or learning efficiency in SLMs. Models trained on complex, adult-level text perform comparably to those trained on simplified language, and even exhibit faster development of coherence during training. Instead, we show that statistical simplicity, as measured by n-gram diversity, is a stronger predictor of learnability. Our findings caution against the growing trend of anthropomorphizing language model training -- drawing parallels to human cognitive development without empirical basis -- and argue for more precise reasoning about what properties actually support capability emergence in small models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯è¯»æ€§(readability)ä¸å¯å­¦ä¹ æ€§(learnability)ä¹‹é—´çš„å…³ç³»ï¼ŒæŒ‘æˆ˜äº†â€œç®€å•æ–‡æœ¬æ›´æœ‰åˆ©äºè®­ç»ƒå°å‹è¯­è¨€æ¨¡å‹(SLMs)â€çš„ä¼ ç»Ÿè§‚ç‚¹ã€‚ä½œè€…é€šè¿‡æ„å»ºç»“æ„ä¸€è‡´ä½†å¯è¯»æ€§å„å¼‚çš„åˆæˆæ•°æ®é›†ï¼Œè¯„ä¼°äº†å¯è¯»æ€§å¯¹æ¨¡å‹è¿è´¯æ€§(coherence)å’Œå­¦ä¹ æ•ˆç‡çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…å‡­å¯è¯»æ€§æ— æ³•é¢„æµ‹æ¨¡å‹çš„è¡¨ç°ï¼Œåœ¨å¤æ‚æˆäººæ°´å¹³æ–‡æœ¬ä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸åœ¨ç®€åŒ–è¯­è¨€ä¸Šè®­ç»ƒçš„æ¨¡å‹æ•ˆæœç›¸å½“ã€‚ç ”ç©¶ç”šè‡³å‘ç°ï¼Œä½¿ç”¨å¤æ‚æ–‡æœ¬è®­ç»ƒçš„æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å±•ç°å‡ºäº†æ›´å¿«çš„è¿è´¯æ€§å‘å±•é€Ÿåº¦ã€‚ç ”ç©¶è¿›ä¸€æ­¥æŒ‡å‡ºï¼Œç›¸æ¯”äºäººç±»æ„ŸçŸ¥çš„è¯­è¨€ç®€å•æ€§ï¼Œä»¥n-gramå¤šæ ·æ€§è¡¡é‡çš„ç»Ÿè®¡ç®€å•æ€§(statistical simplicity)æ‰æ˜¯å†³å®šå¯å­¦ä¹ æ€§çš„æ›´å¼ºé¢„æµ‹æŒ‡æ ‡ã€‚è¯¥å‘ç°å¯¹å½“å‰å°†è¯­è¨€æ¨¡å‹è®­ç»ƒä¸äººç±»è®¤çŸ¥å‘å±•è¿›è¡Œç±»æ¯”çš„æ‹ŸäººåŒ–å€¾å‘æå‡ºäº†è­¦ç¤ºã€‚è®ºæ–‡æœ€åå‘¼åç ”ç©¶ç•Œåº”æ›´ç²¾ç¡®åœ°åˆ†æç©¶ç«Ÿæ˜¯å“ªäº›æ•°æ®å±æ€§çœŸæ­£æ”¯æ’‘äº†å°æ¨¡å‹çš„èƒ½åŠ›æ¶Œç°(capability emergence)ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLM 2025 (Spotlight)",
      "pdf_url": "https://arxiv.org/pdf/2510.13915v1",
      "published_date": "2025-10-15 08:17:02 UTC",
      "updated_date": "2025-10-15 08:17:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:23.372731+00:00"
    },
    {
      "arxiv_id": "2510.13262v1",
      "title": "SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning",
      "title_zh": "SAJAï¼šå¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„çŠ¶æ€-åŠ¨ä½œè”åˆæ”»å‡»æ¡†æ¶",
      "authors": [
        "Weiqi Guo",
        "Guanjun Liu",
        "Ziyuan Zhou"
      ],
      "abstract": "Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for cooperative and competitive tasks such as autonomous driving and strategic gaming. However, models trained by MADRL are vulnerable to adversarial perturbations on states and actions. Therefore, it is essential to investigate the robustness of MADRL models from an attack perspective. Existing studies focus on either state-only attacks or action-only attacks, but do not consider how to effectively joint them. Simply combining state and action perturbations such as randomly perturbing states and actions does not exploit their potential synergistic effects. In this paper, we propose the State-Action Joint Attack (SAJA) framework that has a good synergistic effects. SAJA consists of two important phases: (1) In the state attack phase, a multi-step gradient ascent method utilizes both the actor network and the critic network to compute an adversarial state, and (2) in the action attack phase, based on the perturbed state, a second gradient ascent uses the critic network to craft the final adversarial action. Additionally, a heuristic regularizer measuring the distance between the perturbed actions and the original clean ones is added into the loss function to enhance the effectiveness of the critic's guidance. We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating that (1) it outperforms and is more stealthy than state-only or action-only attacks, and (2) existing state or action defense methods cannot defend its attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆMADRLï¼‰åœ¨å¯¹æŠ—æ€§æ‰°åŠ¨ä¸‹çš„è„†å¼±æ€§ï¼Œæå‡ºäº†SAJAï¼ˆState-Action Joint Attackï¼‰è”åˆæ”»å‡»æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸»è¦å…³æ³¨å•ä¸€çš„çŠ¶æ€æˆ–åŠ¨ä½œæ”»å‡»è€Œå¿½ç•¥ä¸¤è€…ååŒæ•ˆåº”çš„é—®é¢˜ï¼ŒSAJAé‡‡ç”¨äº†ä¸¤ä¸ªå…³é”®é˜¶æ®µï¼šé¦–å…ˆåœ¨çŠ¶æ€æ”»å‡»é˜¶æ®µåˆ©ç”¨Actorå’ŒCriticç½‘ç»œé€šè¿‡å¤šæ­¥æ¢¯åº¦ä¸Šå‡ç”Ÿæˆå¯¹æŠ—æ€§çŠ¶æ€ï¼Œéšååœ¨åŠ¨ä½œæ”»å‡»é˜¶æ®µåŸºäºæ‰°åŠ¨çŠ¶æ€åˆ©ç”¨Criticç½‘ç»œæ„å»ºæœ€ç»ˆçš„å¯¹æŠ—æ€§åŠ¨ä½œã€‚æ­¤å¤–ï¼Œç ”ç©¶åœ¨æŸå¤±å‡½æ•°ä¸­å¼•å…¥äº†è¡¡é‡æ‰°åŠ¨åŠ¨ä½œä¸åŸå§‹åŠ¨ä½œè·ç¦»çš„å¯å‘å¼æ­£åˆ™åŒ–å™¨ï¼ˆHeuristic Regularizerï¼‰ï¼Œä»¥æå‡æ”»å‡»çš„å¼•å¯¼æ•ˆæœã€‚å®éªŒç»“æœåœ¨Multi-Agent Particle Environmentï¼ˆMPEï¼‰ç¯å¢ƒä¸‹éªŒè¯äº†SAJAçš„ä¼˜è¶Šæ€§ï¼Œè¯æ˜å…¶åœ¨æ”»å‡»å¼ºåº¦å’Œéšè”½æ€§ä¸Šå‡è¶…è¿‡äº†å•ä¸€ç»´åº¦çš„æ”»å‡»ã€‚æœ€åï¼Œç ”ç©¶å‘ç°ç°æœ‰çš„é˜²å¾¡æ‰‹æ®µéš¾ä»¥æŠµå¾¡æ­¤ç±»è”åˆæ”»å‡»ï¼Œä¸ºMADRLæ¨¡å‹çš„é²æ£’æ€§ç ”ç©¶æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13262v1",
      "published_date": "2025-10-15 08:08:41 UTC",
      "updated_date": "2025-10-15 08:08:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:25.903119+00:00"
    },
    {
      "arxiv_id": "2510.13261v1",
      "title": "A Ratio-Based Shapley Value for Collaborative Machine Learning - Extended Version",
      "title_zh": "åä½œæœºå™¨å­¦ä¹ ä¸­åŸºäºæ¯”ç‡çš„ Shapley å€¼â€”â€”æ‰©å±•ç‰ˆ",
      "authors": [
        "BjÃ¶rn Filter",
        "Ralf MÃ¶ller",
        "Ã–zgÃ¼r LÃ¼tfÃ¼ Ã–zÃ§ep"
      ],
      "abstract": "Collaborative machine learning enables multiple data owners to jointly train models for improved predictive performance. However, ensuring incentive compatibility and fair contribution-based rewards remains a critical challenge. Prior work by Sim and colleagues (Rachel Hwee Ling Sim et al: Collaborative machine learning with incentive-aware model rewards. In: International conference on machine learning. PMLR. 2020, pp. 8927-8963) addressed this by allocating model rewards, which are non-monetary and freely replicable, based on the Shapley value of each party's data contribution, measured via information gain. In this paper, we introduce a ratio-based Shapley value that replaces the standard additive formulation with a relative contribution measure. While our overall reward framework, including the incentive definitions and model-reward setting, remains aligned with that of Sim and colleagues, the underlying value function is fundamentally different. Our alternative valuation induces a different distribution of model rewards and offers a new lens through which to analyze incentive properties. We formally define the ratio-based value and prove that it satisfies the same set of incentive conditions as the additive formulation, including adapted versions of fairness, individual rationality, and stability. Like the original approach, our method faces the same fundamental trade-offs between these incentives. Our contribution is a mathematically grounded alternative to the additive Shapley framework, potentially better suited to contexts where proportionality among contributors is more meaningful than additive differences.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åä½œæœºå™¨å­¦ä¹ (Collaborative machine learning)ä¸­æ¿€åŠ±ç›¸å®¹æ€§(incentive compatibility)ä¸å…¬å¹³å¥–åŠ±åˆ†é…çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¯”ç‡çš„Shapley value (ratio-based Shapley value)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç›¸å¯¹è´¡çŒ®åº¦é‡å–ä»£äº†å…ˆå‰ç ”ç©¶ä¸­åŸºäºä¿¡æ¯å¢ç›Š(information gain)çš„åŠ æ³•å…¬å¼ï¼Œé€šè¿‡ä¸åŒçš„ä»·å€¼å‡½æ•°(value function)å®ç°äº†æ¨¡å‹å¥–åŠ±çš„å·®å¼‚åŒ–åˆ†å¸ƒã€‚ç ”ç©¶é€šè¿‡å½¢å¼åŒ–å®šä¹‰è¯æ˜äº†è¯¥æ¯”ç‡ä»·å€¼èƒ½æœ‰æ•ˆæ»¡è¶³å…¬å¹³æ€§ã€ä¸ªä½“ç†æ€§(individual rationality)å’Œç¨³å®šæ€§(stability)ç­‰æ ¸å¿ƒæ¿€åŠ±æ¡ä»¶ã€‚å°½ç®¡æ–°æ–¹æ³•ä»é¢ä¸´å„æ¿€åŠ±æŒ‡æ ‡ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ï¼Œä½†å®ƒä¸ºåŠ æ³•æ¡†æ¶æä¾›äº†ä¸€ä¸ªå…·å¤‡æ•°å­¦ä¸¥è°¨æ€§çš„æ›¿ä»£æ–¹æ¡ˆã€‚åœ¨å¼ºè°ƒè´¡çŒ®è€…ä¹‹é—´æ¯”ä¾‹æ€§(proportionality)è€ŒéåŠ æ³•å·®å¼‚çš„ç‰¹å®šè¯­å¢ƒä¸‹ï¼Œè¯¥ç ”ç©¶æå‡ºçš„æ¡†æ¶å±•ç°å‡ºæ›´å¼ºçš„é€‚ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "Extended version of a paper accepted at the 26th International Conference on Principles and Practice of Multi-Agent Systems (PRIMA 2025)",
      "pdf_url": "https://arxiv.org/pdf/2510.13261v1",
      "published_date": "2025-10-15 08:08:18 UTC",
      "updated_date": "2025-10-15 08:08:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:30.800984+00:00"
    },
    {
      "arxiv_id": "2510.13253v1",
      "title": "End-to-End Multi-Modal Diffusion Mamba",
      "title_zh": "ç«¯åˆ°ç«¯å¤šæ¨¡æ€æ‰©æ•£ Mamba",
      "authors": [
        "Chunhao Lu",
        "Qiang Lu",
        "Meichen Dong",
        "Jake Luo"
      ],
      "abstract": "Current end-to-end multi-modal models utilize different encoders and decoders to process input and output information. This separation hinders the joint representation learning of various modalities. To unify multi-modal processing, we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM utilizes a Mamba-based multi-step selection diffusion model to progressively generate and refine modality-specific information through a unified variational autoencoder for both encoding and decoding. This innovative approach allows MDM to achieve superior performance when processing high-dimensional data, particularly in generating high-resolution images and extended text sequences simultaneously. Our evaluations in areas such as image generation, image captioning, visual question answering, text comprehension, and reasoning tasks demonstrate that MDM significantly outperforms existing end-to-end models (MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's effectiveness in unifying multi-modal processes while maintaining computational efficiency, establishing a new direction for end-to-end multi-modal architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MDM (Multi-modal Diffusion Mamba)ï¼Œè¿™æ˜¯ä¸€ç§åˆ›æ–°çš„ç«¯åˆ°ç«¯å¤šæ¨¡æ€æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ¨¡å‹ä¸­å› ç¼–è§£ç å™¨åˆ†ç¦»è€Œå¯¼è‡´çš„è”åˆè¡¨ç¤ºå­¦ä¹ å—é˜»é—®é¢˜ã€‚MDM é‡‡ç”¨äº†åŸºäº Mamba çš„å¤šæ­¥é€‰æ‹©æ‰©æ•£æ¨¡å‹ (multi-step selection diffusion model)ï¼Œé€šè¿‡ç»Ÿä¸€çš„å˜åˆ†è‡ªç¼–ç å™¨ (Variational Autoencoder, VAE) ååŒå®Œæˆç¼–ç ä¸è§£ç ï¼Œä»è€Œå®ç°æ¨¡æ€ç‰¹å®šä¿¡æ¯çš„æ¸è¿›å¼ç”Ÿæˆä¸ç»†åŒ–ã€‚è¯¥æ¶æ„åœ¨å¤„ç†é«˜ç»´æ•°æ®æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œèƒ½å¤ŸåŒæ­¥ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒä¸é•¿æ–‡æœ¬åºåˆ—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMDM åœ¨å›¾åƒç”Ÿæˆã€è§†è§‰é—®ç­”åŠæ–‡æœ¬æ¨ç†ç­‰ä»»åŠ¡ä¸Šæ˜¾è‘—è¶…è¶Šäº† MonoFormer å’Œ Chameleon ç­‰ç°æœ‰æ¨¡å‹ï¼Œå¹¶è¾¾åˆ°äº†ä¸ GPT-4V åŠ Gemini Pro ç­‰ SOTA æ¨¡å‹ç›¸å½“çš„æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œéªŒè¯äº†ç»Ÿä¸€å¤šæ¨¡æ€æµç¨‹åœ¨ç»´æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶çš„æœ‰æ•ˆæ€§ï¼Œä¸ºç«¯åˆ°ç«¯å¤šæ¨¡æ€æ¶æ„çš„ç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.13253v1",
      "published_date": "2025-10-15 08:03:50 UTC",
      "updated_date": "2025-10-15 08:03:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:26.691355+00:00"
    },
    {
      "arxiv_id": "2510.13250v1",
      "title": "Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture",
      "title_zh": "åŸºäºè½»é‡çº§æ¶æ„çš„åµŒå…¥å¼ç³»ç»Ÿå®æ—¶äººç¾¤è®¡æ•°",
      "authors": [
        "Zhiyuan Zhao",
        "Yubin Wen",
        "Siyu Yang",
        "Lichen Ning",
        "Yuandong Liu",
        "Junyu Gao"
      ],
      "abstract": "Crowd counting is a task of estimating the number of the crowd through images, which is extremely valuable in the fields of intelligent security, urban planning, public safety management, and so on. However, the existing counting methods have some problems in practical application on embedded systems for these fields, such as excessive model parameters, abundant complex calculations, etc. The practical application of embedded systems requires the model to be real-time, which means that the model is fast enough. Considering the aforementioned problems, we design a super real-time model with a stem-encoder-decoder structure for crowd counting tasks, which achieves the fastest inference compared with state-of-the-arts. Firstly, large convolution kernels in the stem network are used to enlarge the receptive field, which effectively extracts detailed head information. Then, in the encoder part, we use conditional channel weighting and multi-branch local fusion block to merge multi-scale features with low computational consumption. This part is crucial to the super real-time performance of the model. Finally, the feature pyramid networks are added to the top of the encoder to alleviate its incomplete fusion problems. Experiments on three benchmarks show that our network is suitable for super real-time crowd counting on embedded systems, ensuring competitive accuracy. At the same time, the proposed network reasoning speed is the fastest. Specifically, the proposed network achieves 381.7 FPS on NVIDIA GTX 1080Ti and 71.9 FPS on NVIDIA Jetson TX1.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰äººç¾¤è®¡æ•°æ¨¡å‹å‚æ•°é‡å¤§ã€è®¡ç®—å¤æ‚ä¸”éš¾ä»¥åœ¨åµŒå…¥å¼ç³»ç»Ÿå®ç°å®æ—¶åº”ç”¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§é‡‡ç”¨ stem-encoder-decoder ç»“æ„çš„è½»é‡çº§è¶…å®æ—¶æ¨¡å‹ã€‚åœ¨ stem ç½‘ç»œéƒ¨åˆ†ï¼Œè¯¥æ¨¡å‹åˆ©ç”¨å¤§å·ç§¯æ ¸æ‰©å¤§æ„Ÿå—é‡ä»¥æœ‰æ•ˆæå–å¤´éƒ¨ç»†èŠ‚ä¿¡æ¯ã€‚ç¼–ç å™¨ encoder éƒ¨åˆ†å¼•å…¥äº† conditional channel weighting å’Œ multi-branch local fusion blockï¼Œä»¥æä½çš„è®¡ç®—æ¶ˆè€—å®ç°äº†å¤šå°ºåº¦ç‰¹å¾èåˆï¼Œæ˜¯ç¡®ä¿è¶…å®æ—¶æ€§èƒ½çš„æ ¸å¿ƒã€‚æ­¤å¤–ï¼Œæ¶æ„åœ¨ç¼–ç å™¨é¡¶éƒ¨é›†æˆäº† feature pyramid networks ä»¥è§£å†³ç‰¹å¾èåˆä¸å®Œå…¨çš„é—®é¢˜ã€‚å®éªŒè¯æ˜ï¼Œè¯¥ç½‘ç»œåœ¨ä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå‡è¡¨ç°å‡ºæå…·ç«äº‰åŠ›çš„å‡†ç¡®ç‡ï¼Œä¸”æ¨ç†é€Ÿåº¦ä¸ºå½“å‰æœ€å¿«ã€‚åœ¨ NVIDIA GTX 1080Ti å’ŒåµŒå…¥å¼å¹³å° NVIDIA Jetson TX1 ä¸Šï¼Œè¯¥æ¨¡å‹åˆ†åˆ«è¾¾åˆ°äº† 381.7 FPS å’Œ 71.9 FPSï¼Œä¸ºåµŒå…¥å¼è®¾å¤‡ä¸Šçš„å®æ—¶äººç¾¤è®¡æ•°æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13250v1",
      "published_date": "2025-10-15 07:58:46 UTC",
      "updated_date": "2025-10-15 07:58:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:34.586323+00:00"
    },
    {
      "arxiv_id": "2510.13244v1",
      "title": "MotionBeat: Motion-Aligned Music Representation via Embodied Contrastive Learning and Bar-Equivariant Contact-Aware Encoding",
      "title_zh": "MotionBeatï¼šåŸºäºå…·èº«å¯¹æ¯”å­¦ä¹ ä¸å°èŠ‚ç­‰å˜æ¥è§¦æ„ŸçŸ¥ç¼–ç çš„åŠ¨ä½œå¯¹é½éŸ³ä¹è¡¨å¾",
      "authors": [
        "Xuanchen Wang",
        "Heng Wang",
        "Weidong Cai"
      ],
      "abstract": "Music is both an auditory and an embodied phenomenon, closely linked to human motion and naturally expressed through dance. However, most existing audio representations neglect this embodied dimension, limiting their ability to capture rhythmic and structural cues that drive movement. We propose MotionBeat, a framework for motion-aligned music representation learning. MotionBeat is trained with two newly proposed objectives: the Embodied Contrastive Loss (ECL), an enhanced InfoNCE formulation with tempo-aware and beat-jitter negatives to achieve fine-grained rhythmic discrimination, and the Structural Rhythm Alignment Loss (SRAL), which ensures rhythm consistency by aligning music accents with corresponding motion events. Architecturally, MotionBeat introduces bar-equivariant phase rotations to capture cyclic rhythmic patterns and contact-guided attention to emphasize motion events synchronized with musical accents. Experiments show that MotionBeat outperforms state-of-the-art audio encoders in music-to-dance generation and transfers effectively to beat tracking, music tagging, genre and instrument classification, emotion recognition, and audio-visual retrieval. Our project demo page: https://motionbeat2025.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MotionBeatï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°åŠ¨ä½œå¯¹é½çš„éŸ³ä¹è¡¨ç¤ºå­¦ä¹ æ¡†æ¶ï¼Œè§£å†³äº†ç°æœ‰éŸ³é¢‘è¡¨ç¤ºå¿½ç•¥éŸ³ä¹ä¸äººç±»åŠ¨ä½œåŠèˆè¹ˆä¹‹é—´ä½“ç°æ€§(embodied)è”ç³»çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤ç§æ–°çš„å­¦ä¹ ç›®æ ‡ï¼šå…·ä½“åŒ–å¯¹æ¯”æŸå¤±(Embodied Contrastive Loss, ECL)ï¼Œé€šè¿‡å¸¦æœ‰èŠ‚å¥æ„ŸçŸ¥å’ŒèŠ‚æ‹æŠ–åŠ¨è´Ÿé‡‡æ ·çš„å¢å¼ºInfoNCEå…¬å¼å®ç°ç»†ç²’åº¦çš„èŠ‚å¥åˆ¤åˆ«ï¼›ä»¥åŠç»“æ„åŒ–èŠ‚å¥å¯¹é½æŸå¤±(Structural Rhythm Alignment Loss, SRAL)ï¼Œé€šè¿‡å°†éŸ³ä¹é‡éŸ³ä¸å¯¹åº”çš„åŠ¨ä½œäº‹ä»¶å¯¹é½æ¥ç¡®ä¿èŠ‚å¥ä¸€è‡´æ€§ã€‚åœ¨æ¶æ„è®¾è®¡ä¸Šï¼ŒMotionBeatå¼•å…¥äº†å°èŠ‚ç­‰å˜(bar-equivariant)ç›¸ä½æ—‹è½¬ä»¥æ•æ‰å‘¨æœŸæ€§èŠ‚å¥æ¨¡å¼ï¼Œå¹¶é‡‡ç”¨æ¥è§¦å¼•å¯¼æ³¨æ„åŠ›(contact-guided attention)æ¥å¼ºè°ƒä¸éŸ³ä¹é‡éŸ³åŒæ­¥çš„åŠ¨ä½œäº‹ä»¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMotionBeatåœ¨éŸ³ä¹ç”Ÿæˆèˆè¹ˆ(music-to-dance generation)ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›éŸ³é¢‘ç¼–ç å™¨ï¼Œå¹¶åœ¨èŠ‚æ‹è¿½è¸ª(beat tracking)ã€éŸ³ä¹æ ‡ç­¾(music tagging)ã€æµæ´¾ä¸ä¹å™¨åˆ†ç±»ã€æƒ…æ„Ÿè¯†åˆ«ä»¥åŠéŸ³è§†é¢‘æ£€ç´¢ç­‰ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°äº†å‡ºè‰²çš„è¿ç§»èƒ½åŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 1 figure. demo page: https://motionbeat2025.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2510.13244v1",
      "published_date": "2025-10-15 07:44:32 UTC",
      "updated_date": "2025-10-15 07:44:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:39:49.389961+00:00"
    },
    {
      "arxiv_id": "2510.13232v1",
      "title": "What \"Not\" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging",
      "title_zh": "è¯†åˆ«â€œä¸â€æ£€æµ‹ä¹‹ç‰©ï¼šåŸºäºç»“æ„åŒ–æ¨ç†ä¸è¯å…ƒåˆå¹¶çš„å¦å®šæ„ŸçŸ¥è§†è§‰è¯­è¨€æ¨¡å‹",
      "authors": [
        "Inha Kang",
        "Youngsun Lim",
        "Seonho Lee",
        "Jiho Choi",
        "Junsuk Choe",
        "Hyunjung Shim"
      ],
      "abstract": "State-of-the-art vision-language models (VLMs) suffer from a critical failure in understanding negation, often referred to as affirmative bias. This limitation is particularly severe in described object detection (DOD) tasks. To address this, we propose two primary contributions: (1) a new dataset pipeline and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a dataset constructed with a systematic chain-of-thought (CoT) and VQA-based pipeline to generate high-quality, instance-grounded negation data. Second, we propose NegToMe, a novel text token merging module that directly tackles the architectural cause of affirmative bias. NegToMe fundamentally addresses the structural loss of negation cues in tokenization, grouping them with attributes into coherent semantic phrases. It maintains correct polarity at the input level, enabling robust negation understanding even with limited data. For instance, to prevent a model from treating the fragmented tokens \"not\" and \"girl\" as simply \"girl\", NegToMe binds them into a single token whose meaning is correctly distinguished from that of \"girl\" alone. This module is integrated with a parameter-efficient and strategic LoRA fine-tuning approach. Our method significantly improves performance on challenging negation benchmarks with a lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval and demonstrating generalization to SoTA VLMs. This work marks a crucial step forward in addressing negation understanding for real-world detection applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨ç†è§£å¦å®šæŒ‡ä»¤æ—¶å­˜åœ¨çš„ä¸¥é‡è‚¯å®šåå·® (affirmative bias) è¿™ä¸€æŒ‘æˆ˜ï¼Œæå‡ºäº† CoVAND æ•°æ®é›†å’Œ NegToMe é€‚é…æ–¹æ¡ˆã€‚CoVAND åˆ©ç”¨é“¾å¼æ€ç»´ (CoT) å’Œ VQA æµç¨‹ç”Ÿæˆé«˜è´¨é‡çš„å®ä¾‹çº§å¦å®šæ•°æ®ï¼Œè€Œ NegToMe é€šè¿‡å°†å¦å®šæ ‡è®°ä¸ç›®æ ‡å±æ€§åˆå¹¶ä¸ºä¸€è‡´çš„è¯­ä¹‰çŸ­è¯­ï¼Œä»æ¶æ„å±‚é¢è§£å†³äº†åˆ†è¯è¿‡ç¨‹ä¸­çš„å¦å®šè¯­æ„ä¸¢å¤±é—®é¢˜ã€‚è¯¥æ¨¡å—ç»“åˆäº†å‚æ•°é«˜æ•ˆçš„ LoRA å¾®è°ƒæŠ€æœ¯ï¼Œåœ¨ä¸å¢åŠ é¢å¤–è®¡ç®—è´Ÿæ‹…çš„æƒ…å†µä¸‹ç¡®ä¿æ¨¡å‹åœ¨è¾“å…¥å±‚é¢èƒ½å¤Ÿç»´æŒæ­£ç¡®çš„ææ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ OVDEval ç­‰åŸºå‡†æµ‹è¯•ä¸­å°† NMS-AP æå‡äº†å¤šè¾¾ 10.8 ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶æ˜¾è‘—é™ä½äº†è¯¯æŠ¥ç‡ã€‚è¯¥ç ”ç©¶å±•ç°å‡ºåœ¨å¤šç§å…ˆè¿› VLMs ä¸Šçš„ä¼˜å¼‚æ³›åŒ–æ€§èƒ½ï¼Œä¸ºè§£å†³ç°å®ä¸–ç•Œç‰©ä½“æ£€æµ‹ä¸­çš„å¦å®šç†è§£é—®é¢˜æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "38 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13232v1",
      "published_date": "2025-10-15 07:36:38 UTC",
      "updated_date": "2025-10-15 07:36:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:04.117799+00:00"
    },
    {
      "arxiv_id": "2510.13230v1",
      "title": "An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities",
      "title_zh": "æå‡æ™ºæ…§åŸå¸‚è‡ªåŠ¨é©¾é©¶æ±½è½¦æ„ŸçŸ¥èƒ½åŠ›çš„åˆ†ææ¡†æ¶",
      "authors": [
        "Jalal Khan",
        "Manzoor Khan",
        "Sherzod Turaev",
        "Sumbal Malik",
        "Hesham El-Sayed",
        "Farman Ullah"
      ],
      "abstract": "The driving environment perception has a vital role for autonomous driving and nowadays has been actively explored for its realization. The research community and relevant stakeholders necessitate the development of Deep Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles (AVs) for smart mobility. There is a need to develop a model that accurately perceives multiple objects on the road and predicts the driver's perception to control the car's movements. This article proposes a novel utility-based analytical model that enables perception systems of AVs to understand the driving environment. The article consists of modules: acquiring a custom dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a DL-based model (YOLOv8s) for object detection; and a module to measure the utility of perception service from the performance values of trained model instances. The perception model is validated based on the object detection task, and its process is benchmarked by state-of-the-art deep learning models' performance metrics from the nuScense dataset. The experimental results show three best-performing YOLOv8s instances based on mAP@0.5 values, i.e., SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.) still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892, truck: 0.781, etc.) because it has better class-level performance values, confirmed by the proposed perception model. We validate that the proposed function is capable of finding the right perception for AVs. The results above encourage using the proposed perception model to evaluate the utility of learning models and determine the appropriate perception for AVs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºæ•ˆç”¨çš„åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨å¢å¼ºæ™ºæ…§åŸå¸‚ç¯å¢ƒä¸‹è‡ªåŠ¨é©¾é©¶æ±½è½¦(Autonomous Vehicles)çš„æ„ŸçŸ¥ç³»ç»Ÿã€‚è¯¥æ¡†æ¶æ•´åˆäº†åŒ…å«æ‘©æ‰˜è½¦æ‰‹ã€äººåŠ›è½¦ç­‰ç‰¹æ®Šç›®æ ‡çš„è‡ªå®šä¹‰æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨YOLOv8sæ¨¡å‹è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼ŒåŒæ—¶åˆ©ç”¨ä¸“é—¨çš„æ¨¡å—æ¥è¡¡é‡æ„ŸçŸ¥æœåŠ¡çš„æ•ˆç”¨ã€‚ç ”ç©¶äººå‘˜å‚è€ƒnuScenesæ•°æ®é›†çš„æ€§èƒ½æŒ‡æ ‡å¯¹æ„ŸçŸ¥æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•å’ŒéªŒè¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒåŸºäºAdamWä¼˜åŒ–å™¨çš„YOLOv8så®ä¾‹è¡¨ç°æœ€ä¼˜ï¼Œå…¶mAP@0.5è¾¾åˆ°0.822ï¼Œä¸”åœ¨ç±»åˆ«å±‚çº§çš„æ€§èƒ½è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºåŸºäºSGDçš„æ¨¡å‹ã€‚è¯¥ç ”ç©¶è¯å®äº†æ‰€æå‡ºçš„åˆ†ææ¨¡å‹èƒ½å¤Ÿä¸ºAVsæ‰¾åˆ°æ­£ç¡®çš„æ„ŸçŸ¥æ–¹æ¡ˆï¼Œä»è€Œæ›´å‡†ç¡®åœ°ç†è§£é©¾é©¶ç¯å¢ƒã€‚è¿™é¡¹å·¥ä½œä¸ºè¯„ä¼°Deep Learningæ¨¡å‹çš„å®ç”¨æ€§ä»¥åŠä¼˜åŒ–æ™ºæ…§å‡ºè¡Œä¸­çš„ç¯å¢ƒæ„ŸçŸ¥èƒ½åŠ›æä¾›äº†é‡è¦çš„å‚è€ƒä¾æ®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 14 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13230v1",
      "published_date": "2025-10-15 07:34:22 UTC",
      "updated_date": "2025-10-15 07:34:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:48.187194+00:00"
    },
    {
      "arxiv_id": "2510.13220v1",
      "title": "EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems",
      "title_zh": "EvoTestï¼šé¢å‘è‡ªæˆ‘æå‡æ™ºèƒ½ä½“ç³»ç»Ÿçš„è¿›åŒ–å¼æµ‹è¯•æ—¶å­¦ä¹ ",
      "authors": [
        "Yufei He",
        "Juncheng Liu",
        "Yue Liu",
        "Yibo Li",
        "Tri Cao",
        "Zhiyuan Hu",
        "Xinxing Xu",
        "Bryan Hooi"
      ],
      "abstract": "A fundamental limitation of current AI agents is their inability to learn complex skills on the fly at test time, often behaving like \"clever but clueless interns\" in novel environments. This severely limits their practical utility. To systematically measure and drive progress on this challenge, we first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a new evaluation setup where an agent must play the same game for several consecutive episodes, attempting to improve its performance from one episode to the next. On J-TTL, we find that existing adaptation methods like reflection, memory, or reinforcement learning struggle. To address the challenges posed by our benchmark, we present EvoTest, an evolutionary test-time learning framework that improves an agent without any fine-tuning or gradients-by evolving the entire agentic system after every episode. EvoTest has two roles: the Actor Agent, which plays the game, and the Evolver Agent, which analyzes the episode transcript to propose a revised configuration for the next run. This configuration rewrites the prompt, updates memory by logging effective state-action choices, tunes hyperparameters, and learns the tool-use routines. On our J-TTL benchmark, EvoTest consistently increases performance, outperforming not only reflection and memory-only baselines but also more complex online fine-tuning methods. Notably, our method is the only one capable of winning two games (Detective and Library), while all baselines fail to win any.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIæ™ºèƒ½ä½“åœ¨æµ‹è¯•é˜¶æ®µæ— æ³•å³æ—¶å­¦ä¹ å¤æ‚æŠ€èƒ½çš„å±€é™æ€§ï¼Œæå‡ºäº†Jericho Test-Time Learning (J-TTL)åŸºå‡†æµ‹è¯•ï¼Œç”¨äºè¯„ä¼°æ™ºèƒ½ä½“åœ¨è¿ç»­å›åˆä¸­è‡ªæˆ‘æ”¹è¿›çš„èƒ½åŠ›ã€‚é’ˆå¯¹Reflectionã€Memoryå’Œå¼ºåŒ–å­¦ä¹ ç­‰ç°æœ‰æ–¹æ³•åœ¨è¯¥åŸºå‡†ä¸Šçš„ä¸è¶³ï¼Œä½œè€…å¼€å‘äº†EvoTestï¼Œä¸€ç§æ— éœ€Fine-tuningæˆ–æ¢¯åº¦æ›´æ–°çš„è¿›åŒ–æµ‹è¯•æ—¶å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡Actor Agentæ‰§è¡Œä»»åŠ¡å¹¶ç”±Evolver Agentåˆ†æè½¨è¿¹ï¼Œåœ¨æ¯å›åˆåæ¼”åŒ–æ•´ä¸ªæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒåŒ…æ‹¬é‡å†™Promptã€æ›´æ–°è®°å½•æœ‰æ•ˆå†³ç­–çš„Memoryã€è°ƒæ•´Hyperparametersä»¥åŠä¼˜åŒ–å·¥å…·è°ƒç”¨ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEvoTestçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºåŒ…æ‹¬åœ¨çº¿å¾®è°ƒåœ¨å†…çš„å¤šç§åŸºçº¿æ–¹æ³•ï¼Œæ˜¯å”¯ä¸€èƒ½åœ¨Detectiveå’ŒLibraryç­‰å¤æ‚æ¸¸æˆä¸­è·èƒœçš„æ–¹æ³•ï¼Œå……åˆ†å±•ç¤ºäº†Agentic Systemsåœ¨åŠ¨æ€ç¯å¢ƒä¸‹çš„è‡ªæˆ‘è¿›åŒ–æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13220v1",
      "published_date": "2025-10-15 07:16:28 UTC",
      "updated_date": "2025-10-15 07:16:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:45.492960+00:00"
    },
    {
      "arxiv_id": "2510.13215v1",
      "title": "Personalized Learning Path Planning with Goal-Driven Learner State Modeling",
      "title_zh": "åŸºäºç›®æ ‡é©±åŠ¨å­¦ä¹ è€…çŠ¶æ€å»ºæ¨¡çš„ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„è§„åˆ’",
      "authors": [
        "Joy Jia Yin Lim",
        "Ye He",
        "Jifan Yu",
        "Xin Cong",
        "Daniel Zhang-Li",
        "Zhiyuan Liu",
        "Huiqin Liu",
        "Lei Hou",
        "Juanzi Li",
        "Bin Xu"
      ],
      "abstract": "Personalized Learning Path Planning (PLPP) aims to design adaptive learning paths that align with individual goals. While large language models (LLMs) show potential in personalizing learning experiences, existing approaches often lack mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework for PLPP that integrates a reinforcement-based training paradigm and an LLM-driven educational architecture. We design a structured learner state model and an automated reward function that transforms abstract objectives into computable signals. We train the policy combining supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), and deploy it within a real-world learning platform. Extensive experiments validate Pxplore's effectiveness in producing coherent, personalized, and goal-driven learning paths. We release our code and dataset to facilitate future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„è§„åˆ’(Personalized Learning Path Planning, PLPP)ä¸­ç°æœ‰å¤§è¯­è¨€æ¨¡å‹(LLMs)ç¼ºä¹ç›®æ ‡å¯¹é½è§„åˆ’æœºåˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºPxploreçš„æ–°å‹æ¡†æ¶ã€‚Pxploreé›†æˆäº†åŸºäºå¼ºåŒ–å­¦ä¹ çš„è®­ç»ƒèŒƒå¼å’ŒLLMé©±åŠ¨çš„æ•™è‚²æ¶æ„ï¼Œæ—¨åœ¨æ ¹æ®ä¸ªä½“ç›®æ ‡è®¾è®¡è‡ªé€‚åº”çš„å­¦ä¹ è·¯å¾„ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°è®¾è®¡äº†ä¸€ä¸ªç»“æ„åŒ–çš„å­¦ä¹ è€…çŠ¶æ€æ¨¡å‹(Learner State Model)ä»¥åŠä¸€ç§è‡ªåŠ¨å¥–åŠ±å‡½æ•°ï¼ŒæˆåŠŸå°†æŠ½è±¡çš„æ•™å­¦ç›®æ ‡è½¬åŒ–ä¸ºå¯è®¡ç®—çš„åé¦ˆä¿¡å·ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼Œç ”ç©¶è€…ç»“åˆäº†ç›‘ç£å¾®è°ƒ(SFT)å’Œç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(Group Relative Policy Optimization, GRPO)æŠ€æœ¯ï¼Œå¹¶å°†è¯¥æ¨¡å‹éƒ¨ç½²äºçœŸå®ä¸–ç•Œçš„å­¦ä¹ å¹³å°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPxploreèƒ½å¤Ÿç”Ÿæˆè¿è´¯ä¸”é«˜åº¦ç›®æ ‡é©±åŠ¨çš„ä¸ªæ€§åŒ–è·¯å¾„ï¼Œæ˜¾è‘—æå‡äº†å­¦ä¹ æ•ˆæœã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå¼€æºäº†ä»£ç å’Œæ•°æ®é›†ï¼Œæ—¨åœ¨ä¿ƒè¿›æ•™è‚²æ™ºèƒ½åŒ–é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13215v1",
      "published_date": "2025-10-15 06:59:49 UTC",
      "updated_date": "2025-10-15 06:59:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:48.988407+00:00"
    },
    {
      "arxiv_id": "2510.13214v1",
      "title": "Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning",
      "title_zh": "Adaptive Reasoning Executorï¼šé¢å‘é«˜æ•ˆæ¨ç†çš„åä½œæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Zehui Ling",
        "Deshu Chen",
        "Yichi Zhang",
        "Yuchen Liu",
        "Xigui Li",
        "Xin Guo",
        "Yuan Cheng"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) demonstrate that chain-of-thought prompting and deep reasoning substantially enhance performance on complex tasks, and multi-agent systems can further improve accuracy by enabling model debates. However, applying deep reasoning to all problems is computationally expensive. To mitigate these costs, we propose a complementary agent system integrating small and large LLMs. The small LLM first generates an initial answer, which is then verified by the large LLM. If correct, the answer is adopted directly; otherwise, the large LLM performs in-depth reasoning. Experimental results show that, for simple problems, our approach reduces the computational cost of the large LLM by more than 50% with negligible accuracy loss, while consistently maintaining robust performance on complex tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Adaptive Reasoning Executorï¼Œä¸€ç§ç»“åˆäº†å°å‹å’Œå¤§å‹ Large Language Models (LLMs) çš„åä½œæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³æ·±åº¦æ¨ç†å’Œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¤„ç†æ‰€æœ‰ä»»åŠ¡æ—¶è®¡ç®—æˆæœ¬è¿‡é«˜çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆä¸åŒè§„æ¨¡çš„æ¨¡å‹å®ç°äº’è¡¥ï¼Œé¦–å…ˆç”±å°å‹ LLM ç”Ÿæˆåˆå§‹ç­”æ¡ˆï¼Œå†ç”±å¤§å‹ LLM è¿›è¡ŒéªŒè¯ã€‚è‹¥éªŒè¯é€šè¿‡åˆ™ç›´æ¥é‡‡ç”¨ç»“æœï¼Œå¦åˆ™ç”±å¤§å‹ LLM ä»‹å…¥æ‰§è¡Œæ·±åº¦æ¨ç†ï¼Œä»è€Œå®ç°è®¡ç®—èµ„æºçš„æŒ‰éœ€åˆ†é…ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨å¤„ç†ç®€å•é—®é¢˜æ—¶ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿé™ä½å¤§å‹ LLM è¶…è¿‡ 50% çš„è®¡ç®—å¼€é”€ï¼Œä¸”å‡ ä¹ä¸æŸå¤±å‡†ç¡®ç‡ã€‚åŒæ—¶ï¼Œè¯¥ç³»ç»Ÿåœ¨å¤æ‚ä»»åŠ¡ä¸Šä¾ç„¶ä¿æŒäº†ç¨³å¥çš„æ€§èƒ½è¡¨ç°ï¼Œä¸ºå®ç°é«˜æ•ˆçš„ chain-of-thought æ¨ç†æä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13214v1",
      "published_date": "2025-10-15 06:59:07 UTC",
      "updated_date": "2025-10-15 06:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:57.615827+00:00"
    },
    {
      "arxiv_id": "2512.00010v1",
      "title": "Leveraging LLMs for Design Ideation: An AI Tool to Assist Creativity",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¾…åŠ©è®¾è®¡æ„æ€ï¼šä¸€ç§åŠ©åŠ›åˆ›æ„ç”Ÿæˆçš„äººå·¥æ™ºèƒ½å·¥å…·",
      "authors": [
        "Rutvik Kokate",
        "Pranati Kompella",
        "Prasad Onkar"
      ],
      "abstract": "The creative potential of computers has intrigued researchers for decades. Since the emergence of Generative AI (Gen AI), computer creativity has found many new dimensions and applications. As Gen AI permeates mainstream discourse and usage, researchers are delving into how it can improve and complement what humans do. Creative potential is a highly relevant notion to design practice and research, especially in the initial stages of ideation and conceptualisation. There is scope to improve creative potential in these stages, especially using machine intelligence. We propose a structured ideation session involving inspirational stimuli and utilise Gen AI in delivering this structure to designers through ALIA: Analogical LLM Ideation Agent, a tool for small-group ideation scenarios. The tool is developed by enabling speech based interactions with a Large Language Model (LLM) for inference generation. Inspiration is drawn from the synectic ideation method and the dialectics philosophy to design the optimal stimuli in group ideation. The tool is tested in design ideation sessions to compare the output of the AI-assisted ideation sessions to that of tradi tional ideation sessions. Preliminary findings showcase that participants have rated their ideas better when assisted by ALIA and respond favourably to speech-based interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Gen AI) å¦‚ä½•æå‡å’Œè¡¥å……äººç±»åœ¨è®¾è®¡åˆæœŸçš„æ„æ€ä¸æ¦‚å¿µåŒ–é˜¶æ®µçš„åˆ›é€ åŠ›ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº† ALIA (Analogical LLM Ideation Agent)ï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºå°ç»„æ„æ€åœºæ™¯è®¾è®¡çš„åˆ›æ„è¾…åŠ©å·¥å…·ã€‚è¯¥å·¥å…·é€šè¿‡è¯­éŸ³äº¤äº’ä¸å¤§è¯­è¨€æ¨¡å‹ (LLM) ç»“åˆï¼Œå¹¶å€Ÿé‰´äº†ç±»æ¯”æ„æ€æ³• (Synectic ideation) å’Œè¾©è¯æ³• (Dialectics philosophy) ç†è®ºï¼Œä¸ºè®¾è®¡å¸ˆæä¾›ç»“æ„åŒ–çš„å¯å‘æ€§åˆºæ¿€ã€‚å®éªŒé€šè¿‡å°† ALIA è¾…åŠ©çš„æ„æ€ä¼šè®®ä¸ä¼ ç»Ÿä¼šè®®è¿›è¡Œå¯¹æ¯”ï¼Œåˆæ­¥å‘ç°å‚ä¸è€…åœ¨ä½¿ç”¨è¯¥å·¥å…·åå¯¹è‡ªå·±åˆ›æ„çš„è¯„åˆ†æ›´é«˜ï¼Œå¹¶å¯¹è¯­éŸ³äº¤äº’è¡¨ç°å‡ºç§¯æåé¦ˆã€‚è¿™ä¸€æˆæœè¯æ˜äº†åˆ©ç”¨ LLM å¢å¼ºè®¾è®¡æ„æ€æ½œåŠ›çš„å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥è®¡ç®—æœºè¾…åŠ©åˆ›æ„è®¾è®¡æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2512.00010v1",
      "published_date": "2025-10-15 06:53:19 UTC",
      "updated_date": "2025-10-15 06:53:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:55.468026+00:00"
    },
    {
      "arxiv_id": "2510.13208v1",
      "title": "MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation",
      "title_zh": "MimicPartsï¼šè¯­éŸ³é©±åŠ¨ 3D åŠ¨ä½œç”Ÿæˆçš„éƒ¨ä½æ„ŸçŸ¥é£æ ¼æ³¨å…¥",
      "authors": [
        "Lianlian Liu",
        "YongKang He",
        "Zhaojie Chu",
        "Xiaofen Xing",
        "Xiangmin Xu"
      ],
      "abstract": "Generating stylized 3D human motion from speech signals presents substantial challenges, primarily due to the intricate and fine-grained relationships among speech signals, individual styles, and the corresponding body movements. Current style encoding approaches either oversimplify stylistic diversity or ignore regional motion style differences (e.g., upper vs. lower body), limiting motion realism. Additionally, motion style should dynamically adapt to changes in speech rhythm and emotion, but existing methods often overlook this. To address these issues, we propose MimicParts, a novel framework designed to enhance stylized motion generation based on part-aware style injection and part-aware denoising network. It divides the body into different regions to encode localized motion styles, enabling the model to capture fine-grained regional differences. Furthermore, our part-aware attention block allows rhythm and emotion cues to guide each body region precisely, ensuring that the generated motion aligns with variations in speech rhythm and emotional state. Experimental results show that our method outperforming existing methods showcasing naturalness and expressive 3D human motion sequences.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MimicPartsï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å¢å¼ºä»è¯­éŸ³ä¿¡å·ç”Ÿæˆé£æ ¼åŒ– 3D human motion çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•è¿‡åº¦ç®€åŒ–é£æ ¼å¤šæ ·æ€§æˆ–å¿½ç•¥å±€éƒ¨åŠ¨ä½œé£æ ¼å·®å¼‚ï¼ˆå¦‚ä¸Šèº«ä¸ä¸‹èº«ï¼‰çš„é—®é¢˜ï¼ŒMimicParts é‡‡ç”¨äº† part-aware style injection å’Œ part-aware denoising network ç­–ç•¥ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†èº«ä½“åˆ’åˆ†ä¸ºä¸åŒçš„åŒºåŸŸæ¥ç¼–ç å±€éƒ¨åŠ¨ä½œé£æ ¼ï¼Œä»è€Œæ•æ‰ç»†ç²’åº¦çš„åŒºåŸŸå·®å¼‚ã€‚æ­¤å¤–ï¼Œç ”ç©¶ä¸­å¼•å…¥çš„ part-aware attention block å…è®¸èŠ‚å¥å’Œæƒ…æ„Ÿçº¿ç´¢ç²¾ç¡®å¼•å¯¼æ¯ä¸ªèº«ä½“éƒ¨ä½ï¼Œç¡®ä¿ç”Ÿæˆçš„åŠ¨ä½œä¸è¯­éŸ³èŠ‚å¥å’Œæƒ…æ„ŸçŠ¶æ€çš„å˜åŒ–ä¿æŒä¸€è‡´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMimicParts åœ¨è‡ªç„¶åº¦å’Œè¡¨ç°åŠ›æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ›´åŠ ç”ŸåŠ¨ä¸”å…·æœ‰è¡¨ç°åŠ›çš„ 3D äººä½“åŠ¨ä½œåºåˆ—ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13208v1",
      "published_date": "2025-10-15 06:53:15 UTC",
      "updated_date": "2025-10-15 06:53:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:40:57.090077+00:00"
    },
    {
      "arxiv_id": "2510.13205v1",
      "title": "CleverCatch: A Knowledge-Guided Weak Supervision Model for Fraud Detection",
      "title_zh": "CleverCatchï¼šä¸€ç§é¢å‘æ¬ºè¯ˆæ£€æµ‹çš„çŸ¥è¯†å¼•å¯¼å¼±ç›‘ç£æ¨¡å‹",
      "authors": [
        "Amirhossein Mozafari",
        "Kourosh Hashemi",
        "Erfan Shafagh",
        "Soroush Motamedi",
        "Azar Taheri Tayebi",
        "Mohammad A. Tayebi"
      ],
      "abstract": "Healthcare fraud detection remains a critical challenge due to limited availability of labeled data, constantly evolving fraud tactics, and the high dimensionality of medical records. Traditional supervised methods are challenged by extreme label scarcity, while purely unsupervised approaches often fail to capture clinically meaningful anomalies. In this work, we introduce CleverCatch, a knowledge-guided weak supervision model designed to detect fraudulent prescription behaviors with improved accuracy and interpretability. Our approach integrates structured domain expertise into a neural architecture that aligns rules and data samples within a shared embedding space. By training encoders jointly on synthetic data representing both compliance and violation, CleverCatch learns soft rule embeddings that generalize to complex, real-world datasets. This hybrid design enables data-driven learning to be enhanced by domain-informed constraints, bridging the gap between expert heuristics and machine learning. Experiments on the large-scale real-world dataset demonstrate that CleverCatch outperforms four state-of-the-art anomaly detection baselines, yielding average improvements of 1.3\\% in AUC and 3.4\\% in recall. Our ablation study further highlights the complementary role of expert rules, confirming the adaptability of the framework. The results suggest that embedding expert rules into the learning process not only improves detection accuracy but also increases transparency, offering an interpretable approach for high-stakes domains such as healthcare fraud detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CleverCatchï¼Œä¸€ç§çŸ¥è¯†å¼•å¯¼çš„å¼±ç›‘ç£æ¨¡å‹ (Weak Supervision)ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—ä¿å¥æ¬ºè¯ˆæ£€æµ‹ä¸­æ ‡æ³¨æ•°æ®ç¨€ç¼ºå’Œé«˜ç»´åº¦ç‰¹å¾å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹é€šè¿‡ç¥ç»æ¶æ„å°†ç»“æ„åŒ–é¢†åŸŸä¸“å®¶çŸ¥è¯†é›†æˆï¼Œå®ç°äº†è§„åˆ™ä¸æ•°æ®æ ·æœ¬åœ¨å…±äº«åµŒå…¥ç©ºé—´ (Embedding Space) å†…çš„å¯¹é½ã€‚é€šè¿‡åœ¨åˆè§„ä¸è¿è§„çš„åˆæˆæ•°æ®ä¸Šè¿›è¡Œè”åˆè®­ç»ƒï¼ŒCleverCatch èƒ½å¤Ÿå­¦ä¹ åˆ°å¯æ³›åŒ–è‡³å¤æ‚çœŸå®åœºæ™¯çš„è½¯è§„åˆ™åµŒå…¥ (Soft Rule Embeddings)ï¼Œæœ‰æ•ˆå¼¥åˆäº†ä¸“å®¶å¯å‘å¼æ–¹æ³•ä¸æœºå™¨å­¦ä¹ ä¹‹é—´çš„é¸¿æ²Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCleverCatch åœ¨å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸Šä¼˜äºå››ç§å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ï¼Œå…¶ AUC æå‡äº† 1.3%ï¼Œå¬å›ç‡ (Recall) æå‡äº† 3.4%ã€‚è¯¥æ¡†æ¶ä¸ä»…æé«˜äº†æ¬ºè¯ˆæ£€æµ‹çš„å‡†ç¡®æ€§ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹çš„å¯è§£é‡Šæ€§ä¸é€æ˜åº¦ï¼Œä¸ºåŒ»ç–—æ¬ºè¯ˆç­‰é«˜é£é™©é¢†åŸŸæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13205v1",
      "published_date": "2025-10-15 06:49:31 UTC",
      "updated_date": "2025-10-15 06:49:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:01.483943+00:00"
    },
    {
      "arxiv_id": "2510.13202v1",
      "title": "LLM-Guided Synthetic Augmentation (LGSA) for Mitigating Bias in AI Systems",
      "title_zh": "LGSAï¼šç”¨äºç¼“è§£äººå·¥æ™ºèƒ½ç³»ç»Ÿåå·®çš„å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼åˆæˆå¢å¼º",
      "authors": [
        "Sai Suhruth Reddy Karri",
        "Yashwanth Sai Nallapuneni",
        "Laxmi Narasimha Reddy Mallireddy",
        "Gopichand G"
      ],
      "abstract": "Bias in AI systems, especially those relying on natural language data, raises ethical and practical concerns. Underrepresentation of certain groups often leads to uneven performance across demographics. Traditional fairness methods, such as pre-processing, in-processing, and post-processing, depend on protected-attribute labels, involve accuracy-fairness trade-offs, and may not generalize across datasets. To address these challenges, we propose LLM-Guided Synthetic Augmentation (LGSA), which uses large language models to generate counterfactual examples for underrepresented groups while preserving label integrity. We evaluated LGSA on a controlled dataset of short English sentences with gendered pronouns, professions, and binary classification labels. Structured prompts were used to produce gender-swapped paraphrases, followed by quality control including semantic similarity checks, attribute verification, toxicity screening, and human spot checks. The augmented dataset expanded training coverage and was used to train a classifier under consistent conditions. Results show that LGSA reduces performance disparities without compromising accuracy. The baseline model achieved 96.7 percent accuracy with a 7.2 percent gender bias gap. Simple swap augmentation reduced the gap to 0.7 percent but lowered accuracy to 95.6 percent. LGSA achieved 99.1 percent accuracy with a 1.9 percent bias gap, improving performance on female-labeled examples. These findings demonstrate that LGSA is an effective strategy for bias mitigation, enhancing subgroup balance while maintaining high task accuracy and label fidelity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LLM-Guided Synthetic Augmentation (LGSA)ï¼Œæ—¨åœ¨è§£å†³ AI ç³»ç»Ÿå› ç‰¹å®šç¾¤ä½“ä»£è¡¨æ€§ä¸è¶³è€Œäº§ç”Ÿçš„åè§é—®é¢˜ï¼Œå¹¶å…‹æœäº†ä¼ ç»Ÿå…¬å¹³æ€§æ–¹æ³•å¯¹å—ä¿æŠ¤å±æ€§æ ‡ç­¾çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆé’ˆå¯¹ä»£è¡¨æ€§ä¸è¶³ç¾¤ä½“çš„åäº‹å®ç¤ºä¾‹ï¼ˆcounterfactual examplesï¼‰ï¼Œå¹¶é€šè¿‡è¯­ä¹‰ç›¸ä¼¼åº¦æ£€æŸ¥ã€å±æ€§éªŒè¯åŠæ¯’æ€§ç­›é€‰ç­‰è´¨é‡æ§åˆ¶æªæ–½ç¡®ä¿ç”Ÿæˆæ•°æ®çš„å®Œæ•´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ€§åˆ«ä»£è¯å’ŒèŒä¸šåˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒLGSA å°†åŸºå‡†æ¨¡å‹çš„ 7.2% æ€§åˆ«åè§å·®è·ï¼ˆgender bias gapï¼‰é™ä½è‡³ 1.9%ï¼ŒåŒæ—¶å°†ä»»åŠ¡å‡†ç¡®ç‡ä» 96.7% æ˜¾è‘—æå‡è‡³ 99.1%ã€‚ç›¸æ¯”ä¼šé™ä½å‡†ç¡®ç‡çš„ç®€å•æ›¿æ¢å¢å¼ºï¼ˆsimple swap augmentationï¼‰ï¼ŒLGSA åœ¨å‡è½»åè§çš„åŒæ—¶èƒ½æ›´å¥½åœ°ç»´æŒæ ‡ç­¾å¿ å®åº¦ï¼ˆlabel fidelityï¼‰ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºå­ç¾¤ä½“å¹³è¡¡åŠç»´æŒé«˜ç²¾åº¦ä»»åŠ¡è¡¨ç°æ–¹é¢çš„å“è¶Šæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 4 figures, 1 Table, submitted to an international conference",
      "pdf_url": "https://arxiv.org/pdf/2510.13202v1",
      "published_date": "2025-10-15 06:42:35 UTC",
      "updated_date": "2025-10-15 06:42:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:03.995887+00:00"
    },
    {
      "arxiv_id": "2510.13201v1",
      "title": "Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences",
      "title_zh": "Paper Copilotï¼šè¿½è¸ªäººå·¥æ™ºèƒ½ä¼šè®®åŒè¡Œè¯„å®¡çš„æ¼”è¿›",
      "authors": [
        "Jing Yang",
        "Qiyao Wei",
        "Jiaxin Pei"
      ],
      "abstract": "The rapid growth of AI conferences is straining an already fragile peer-review system, leading to heavy reviewer workloads, expertise mismatches, inconsistent evaluation standards, superficial or templated reviews, and limited accountability under compressed timelines. In response, conference organizers have introduced new policies and interventions to preserve review standards. Yet these ad-hoc changes often create further concerns and confusion about the review process, leaving how papers are ultimately accepted - and how practices evolve across years - largely opaque. We present Paper Copilot, a system that creates durable digital archives of peer reviews across a wide range of computer-science venues, an open dataset that enables researchers to study peer review at scale, and a large-scale empirical analysis of ICLR reviews spanning multiple years. By releasing both the infrastructure and the dataset, Paper Copilot supports reproducible research on the evolution of peer review. We hope these resources help the community track changes, diagnose failure modes, and inform evidence-based improvements toward a more robust, transparent, and reliable peer-review system.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½(AI)ä¼šè®®è§„æ¨¡æ‰©å¼ å¯¼è‡´åŒè¡Œè¯„å®¡ç³»ç»Ÿ(peer-review system)é¢ä¸´è¯„å®¡è´Ÿæ‹…é‡ã€æ ‡å‡†ä¸ä¸€åŠé€æ˜åº¦ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œå¼€å‘äº†Paper Copilotç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡å»ºç«‹è·¨è®¡ç®—æœºç§‘å­¦é¢†åŸŸçš„åŒè¡Œè¯„å®¡æ•°å­—æ¡£æ¡ˆï¼Œæä¾›äº†ä¸€ä¸ªæ”¯æŒå¤§è§„æ¨¡ç ”ç©¶çš„å¼€æ”¾æ•°æ®é›†(open dataset)ï¼Œå¹¶å¯¹å¤šå¹´çš„ICLRè¯„å®¡æ•°æ®è¿›è¡Œäº†æ·±å…¥çš„å®è¯åˆ†æ(empirical analysis)ã€‚Paper Copilotçš„å‘å¸ƒæ—¨åœ¨æ”¯æŒå…³äºåŒè¡Œè¯„å®¡æ¼”å˜çš„å„ç±»å¯é‡å¤ç ”ç©¶(reproducible research)ï¼Œå¸®åŠ©å­¦æœ¯ç¤¾åŒºè¿½è¸ªè¯„å®¡å®è·µçš„åŠ¨æ€å˜åŒ–å¹¶è¯Šæ–­æ½œåœ¨çš„å¤±æ•ˆæ¨¡å¼ã€‚é€šè¿‡æ•´åˆåŸºç¡€è®¾æ–½ä¸å¤§è§„æ¨¡æ•°æ®é›†ï¼Œè¯¥é¡¹å·¥ä½œä¸ºæ„å»ºæ›´åŠ ç¨³å¥ã€é€æ˜ä¸”å¯é çš„åŒè¡Œè¯„å®¡ä½“ç³»æä¾›äº†é‡è¦æ”¯æ’‘ï¼Œå¹¶ä¸ºå¾ªè¯æ”¹è¿›è¯„å®¡æ”¿ç­–å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13201v1",
      "published_date": "2025-10-15 06:41:06 UTC",
      "updated_date": "2025-10-15 06:41:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:07.694574+00:00"
    },
    {
      "arxiv_id": "2510.13913v1",
      "title": "Synthesizing Agentic Data for Web Agents with Progressive Difficulty Enhancement Mechanisms",
      "title_zh": "åŸºäºæ¸è¿›å¼éš¾åº¦å¢å¼ºæœºåˆ¶çš„ Web æ™ºèƒ½ä½“æ•°æ®åˆæˆ",
      "authors": [
        "Shrey Pandit",
        "Xuan-Phi Nguyen",
        "Yifei Ming",
        "Austin Xu",
        "Jiayu Wang",
        "Caiming Xiong",
        "Shafiq Joty"
      ],
      "abstract": "Web-based 'deep research' agents aim to solve complex question - answering tasks through long-horizon interactions with online tools. These tasks remain challenging, as the underlying language models are often not optimized for long-horizon reasoning and exploration. Prior work has proposed workflows for constructing instruction-tuning datasets, often leveraging knowledge graphs. However, such methods typically lack fine-grained control over difficulty and quality, yielding synthetic data that falls short of capturing the complexity required for long-horizon reasoning. Furthermore, many studies conflate data and training effects by comparing models trained under different optimization recipes, making it difficult to isolate and evaluate the effectiveness of the data itself. We introduce a two-pronged data synthesis pipeline that generates question - answer pairs by progressively increasing task complexity until a frontier baseline web agent fails. The baseline agent plays multiple roles in this process: attempting the questions, validating factuality, checking for alternative answers, and enforcing filtering. To evaluate the effectiveness of our synthesis methods, we adopt a controlled training setup based on distillation from strong web agents. Experiments across multiple web-based benchmarks show that our dataset - despite being smaller - enables the training of more effective web agents than existing datasets. In particular, our data exhibits twice the diversity in tool-use actions, allowing models trained on it to achieve stronger performance while avoiding repetitive tool-calling behaviors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç½‘ç»œâ€œæ·±å±‚ç ”ç©¶â€æ™ºèƒ½ä½“åœ¨é•¿ç¨‹æ¨ç†å’Œæ¢ç´¢ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œä»¥åŠç°æœ‰åˆæˆæ•°æ®é›†ç¼ºä¹ç»†ç²’åº¦éš¾åº¦æ§åˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¸è¿›å¼éš¾åº¦å¢å¼ºæœºåˆ¶(Progressive Difficulty Enhancement Mechanisms)çš„åŒå‘æ•°æ®åˆæˆæµæ°´çº¿ã€‚è¯¥æµæ°´çº¿é€šè¿‡ä¸æ–­æå‡ä»»åŠ¡å¤æ‚åº¦ç›´è‡³åŸºå‡†æ™ºèƒ½ä½“å¤±è´¥ï¼Œä»è€Œç”Ÿæˆå…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜-ç­”æ¡ˆå¯¹ï¼Œå¹¶åˆ©ç”¨åŸºå‡†æ™ºèƒ½ä½“åœ¨è¿‡ç¨‹ä¸­æ‰§è¡Œå›ç­”å°è¯•ã€äº‹å®éªŒè¯ã€å¤‡é€‰ç­”æ¡ˆæ£€æŸ¥å’Œæ•°æ®è¿‡æ»¤ç­‰å¤šç§è§’è‰²ã€‚ä¸ºäº†å…¬å¹³è¯„ä¼°æ•°æ®è´¨é‡ï¼Œç ”ç©¶é‡‡ç”¨äº†åŸºäºå¼ºæ™ºèƒ½ä½“è’¸é¦(Distillation)çš„å—æ§è®­ç»ƒè®¾ç½®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡è¯¥æ•°æ®é›†è§„æ¨¡è¾ƒå°ï¼Œä½†åœ¨å¤šä¸ªç½‘ç»œåŸºå‡†æµ‹è¯•ä¸­çš„è¡¨ç°å‡ä¼˜äºç°æœ‰æ•°æ®é›†ã€‚ç ”ç©¶å‘ç°ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„æ•°æ®åœ¨å·¥å…·ä½¿ç”¨åŠ¨ä½œ(tool-use actions)çš„å¤šæ ·æ€§ä¸Šæå‡äº†ä¸¤å€ï¼Œä½¿å¾—è®­ç»ƒå‡ºçš„æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆé¿å…é‡å¤çš„å·¥å…·è°ƒç”¨è¡Œä¸ºï¼Œæ˜¾è‘—å¢å¼ºäº†æ™ºèƒ½ä½“å¤„ç†å¤æ‚é•¿ç¨‹ä»»åŠ¡çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. ICLR 26 submission",
      "pdf_url": "https://arxiv.org/pdf/2510.13913v1",
      "published_date": "2025-10-15 06:34:46 UTC",
      "updated_date": "2025-10-15 06:34:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:11.081920+00:00"
    },
    {
      "arxiv_id": "2510.13195v1",
      "title": "Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation",
      "title_zh": "ç¤¾ä¼šä»¿çœŸä¸­ LLM èµ‹èƒ½æ™ºèƒ½ä½“çš„æ¬²æœ›é©±åŠ¨ç›®æ ‡ä¼˜åŒ–æƒ…æ„Ÿè®¤çŸ¥å»ºæ¨¡æ¡†æ¶",
      "authors": [
        "Qun Ma",
        "Xiao Xue",
        "Xuwen Zhang",
        "Zihan Zhao",
        "Yuwei Guo",
        "Ming Zhang"
      ],
      "abstract": "The advent of large language models (LLMs) has enabled agents to represent virtual humans in societal simulations, facilitating diverse interactions within complex social systems. However, existing LLM-based agents exhibit severe limitations in affective cognition: They fail to simulate the bounded rationality essential for bridging virtual and real-world services; They lack empirically validated integration mechanisms embedding emotions within agent decision architectures. This paper constructs an emotional cognition framework incorporating desire generation and objective management, designed to achieve emotion alignment between LLM-based agents and humans, modeling the complete decision-making process of LLM-based agents, encompassing state evolution, desire generation, objective optimization, decision generation, and action execution. This study implements the proposed framework within our proprietary multi-agent interaction environment. Experimental results demonstrate that agents governed by our framework not only exhibit behaviors congruent with their emotional states but also, in comparative assessments against other agent types, demonstrate superior ecological validity and generate decision outcomes that significantly more closely approximate human behavioral patterns.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)èµ‹èƒ½çš„æ™ºèƒ½ä½“åœ¨ç¤¾ä¼šæ¨¡æ‹Ÿä¸­ç¼ºä¹æƒ…æ„Ÿè®¤çŸ¥å’Œæœ‰é™ç†æ€§(bounded rationality)çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŒ…å«æ¬²æœ›ç”Ÿæˆ(desire generation)å’Œç›®æ ‡ç®¡ç†(objective management)çš„æƒ…æ„Ÿè®¤çŸ¥å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨å®ç°æ™ºèƒ½ä½“ä¸äººç±»ä¹‹é—´çš„æƒ…æ„Ÿå¯¹é½ï¼Œå®Œæ•´æ¨¡æ‹Ÿäº†åŒ…æ‹¬çŠ¶æ€æ¼”åŒ–ã€æ¬²æœ›ç”Ÿæˆã€ç›®æ ‡ä¼˜åŒ–ã€å†³ç­–ç”ŸæˆåŠè¡ŒåŠ¨æ‰§è¡Œåœ¨å†…çš„å…¨æµç¨‹å†³ç­–è·¯å¾„ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨è‡ªç ”çš„å¤šæ™ºèƒ½ä½“äº¤äº’ç¯å¢ƒä¸­å¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†éƒ¨ç½²ä¸éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå—è¯¥æ¡†æ¶é©±åŠ¨çš„æ™ºèƒ½ä½“èƒ½å¤Ÿå±•ç°å‡ºä¸å…¶æƒ…æ„ŸçŠ¶æ€é«˜åº¦ä¸€è‡´çš„è¡Œä¸ºã€‚æ­¤å¤–ï¼Œå¯¹æ¯”åˆ†æè¯æ˜è¯¥æ¡†æ¶å…·æœ‰æ›´ä¼˜çš„ç”Ÿæ€æ•ˆåº¦(ecological validity)ï¼Œå…¶ç”Ÿæˆçš„å†³ç­–ç»“æœæ¯”å…¶ä»–æ¨¡å‹æ˜¾è‘—æ›´æ¥è¿‘çœŸå®çš„äººç±»è¡Œä¸ºæ¨¡å¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13195v1",
      "published_date": "2025-10-15 06:33:11 UTC",
      "updated_date": "2025-10-15 06:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:24.196457+00:00"
    },
    {
      "arxiv_id": "2510.13194v1",
      "title": "StressTransfer: Stress-Aware Speech-to-Speech Translation with Emphasis Preservation",
      "title_zh": "StressTransferï¼šæ”¯æŒå¼ºè°ƒä¿ç•™çš„é‡éŸ³æ„ŸçŸ¥è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘",
      "authors": [
        "Xi Chen",
        "Yuchen Song",
        "Satoshi Nakamura"
      ],
      "abstract": "We propose a stress-aware speech-to-speech translation (S2ST) system that preserves word-level emphasis by leveraging LLMs for cross-lingual emphasis conversion. Our method translates source-language stress into target-language tags that guide a controllable TTS model. To overcome data scarcity, we developed a pipeline to automatically generate aligned training data and introduce the \"LLM-as-Judge\" for evaluation. Experiments show our approach substantially outperforms baselines in preserving emphasis while maintaining comparable translation quality, speaker intent, and naturalness. Our work highlights the importance of prosody in translation and provides an effective, data-efficient solution for preserving paralinguistic cues in S2ST.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†StressTransferï¼Œè¿™æ˜¯ä¸€ç§æ„ŸçŸ¥å‹åŠ›çš„è¯­éŸ³åˆ°è¯­éŸ³ç¿»è¯‘(S2ST)ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å®ç°è·¨è¯­è¨€çš„è¯çº§é‡éŸ³ä¿ç•™ã€‚è¯¥æ–¹æ³•å°†æºè¯­è¨€çš„é‡éŸ³è½¬åŒ–ä¸ºç›®æ ‡è¯­è¨€æ ‡ç­¾ï¼Œä»è€ŒæŒ‡å¯¼å¯æ§æ–‡æœ¬è½¬è¯­éŸ³(TTS)æ¨¡å‹ç”Ÿæˆå¸¦æœ‰å¼ºè°ƒæ•ˆæœçš„è¯­éŸ³ã€‚ä¸ºäº†å…‹æœè®­ç»ƒæ•°æ®ä¸è¶³çš„é—®é¢˜ï¼Œç ”ç©¶è€…å¼€å‘äº†ä¸€å¥—è‡ªåŠ¨ç”Ÿæˆå¯¹é½æ•°æ®çš„æµæ°´çº¿ï¼Œå¹¶åˆ›æ–°æ€§åœ°é‡‡ç”¨â€œLLM-as-Judgeâ€è¿›è¡Œè´¨é‡è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒStressTransferåœ¨ä¿ç•™é‡éŸ³æ–¹é¢çš„è¡¨ç°æ˜¾è‘—ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œä¸”åœ¨ç¿»è¯‘è´¨é‡ã€è¯´è¯äººæ„å›¾è¡¨è¾¾åŠè¯­éŸ³è‡ªç„¶åº¦ä¸Šå‡ä¿æŒäº†ä¼˜ç§€æ°´å¹³ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†éŸµå¾‹åœ¨ç¿»è¯‘ä¸­çš„é‡è¦æ€§ï¼Œä¸ºS2STç³»ç»Ÿå¤„ç†å‰¯è¯­è¨€çº¿ç´¢æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å¤‡æ•°æ®ç»æµæ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13194v1",
      "published_date": "2025-10-15 06:32:24 UTC",
      "updated_date": "2025-10-15 06:32:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:27.690679+00:00"
    },
    {
      "arxiv_id": "2510.13158v1",
      "title": "Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction",
      "title_zh": "ç¨‹åºçš„è¡Œä¸ºåµŒå…¥ï¼šé¢å‘ä¼˜åŒ–é¢„æµ‹çš„å‡†åŠ¨æ€æ–¹æ³•",
      "authors": [
        "Haolin Pan",
        "Jinyuan Dong",
        "Hongbin Zhang",
        "Hongyu Lin",
        "Mingjie Xing",
        "Yanjun Wu"
      ],
      "abstract": "Learning effective numerical representations, or embeddings, of programs is a fundamental prerequisite for applying machine learning to automate and enhance compiler optimization. Prevailing paradigms, however, present a dilemma. Static representations, derived from source code or intermediate representation (IR), are efficient and deterministic but offer limited insight into how a program will behave or evolve under complex code transformations. Conversely, dynamic representations, which rely on runtime profiling, provide profound insights into performance bottlenecks but are often impractical for large-scale tasks due to prohibitive overhead and inherent non-determinism. This paper transcends this trade-off by proposing a novel quasi-dynamic framework for program representation. The core insight is to model a program's optimization sensitivity. We introduce the Program Behavior Spectrum, a new representation generated by probing a program's IR with a diverse set of optimization sequences and quantifying the resulting changes in its static features. To effectively encode this high-dimensional, continuous spectrum, we pioneer a compositional learning approach. Product Quantization is employed to discretize the continuous reaction vectors into structured, compositional sub-words. Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to learn the deep contextual grammar of these behavioral codes. Comprehensive experiments on two representative compiler optimization tasks -- Best Pass Prediction and -Oz Benefit Prediction -- demonstrate that our method outperforms state-of-the-art static baselines. Our code is publicly available at https://github.com/Panhaolin2001/PREP/.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¼–è¯‘å™¨ä¼˜åŒ–ä¸­é™æ€è¡¨ç¤ºç¼ºä¹è¡Œä¸ºæ´å¯Ÿã€åŠ¨æ€è¡¨ç¤ºå¼€é”€è¿‡å¤§çš„å›°å¢ƒï¼Œæå‡ºäº†ä¸€ç§å…¨æ–°çš„å‡†åŠ¨æ€(quasi-dynamic)ç¨‹åºè¡¨ç¤ºæ¡†æ¶ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥ç¨‹åºè¡Œä¸ºé¢‘è°±(Program Behavior Spectrum)ï¼Œé€šè¿‡ä¸€ç³»åˆ—ä¼˜åŒ–åºåˆ—æ¢æµ‹ç¨‹åºçš„ä¸­é—´è¡¨ç¤º(IR)å¹¶é‡åŒ–å…¶é™æ€ç‰¹å¾çš„å˜åŒ–ï¼Œä»¥æ•æ‰ç¨‹åºçš„ä¼˜åŒ–æ•æ„Ÿæ€§ã€‚ä¸ºäº†æœ‰æ•ˆç¼–ç è¿™ç§é«˜ç»´è¿ç»­é¢‘è°±ï¼Œç ”ç©¶é‡‡ç”¨ä¹˜ç§¯é‡åŒ–(Product Quantization)æŠ€æœ¯å°†ååº”å‘é‡ç¦»æ•£åŒ–ä¸ºç»“æ„åŒ–çš„åˆæˆå­è¯ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œé¢„è®­ç»ƒäº†ä¸€ä¸ªåä¸ºPQ-BERTçš„å¤šä»»åŠ¡Transformeræ¨¡å‹ï¼Œç”¨äºå­¦ä¹ è¿™äº›è¡Œä¸ºä»£ç çš„æ·±å±‚ä¸Šä¸‹æ–‡è¯­æ³•ã€‚åœ¨æœ€ä½³è·¯å¾„é¢„æµ‹(Best Pass Prediction)å’Œ-Ozæ”¶ç›Šé¢„æµ‹(-Oz Benefit Prediction)ä¸¤é¡¹ç¼–è¯‘å™¨ä¼˜åŒ–ä»»åŠ¡ä¸­çš„å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•æ€§èƒ½æ˜¾è‘—ä¼˜äºç›®å‰æœ€å…ˆè¿›çš„é™æ€åŸºçº¿æ¨¡å‹ã€‚è¿™é¡¹å·¥ä½œæˆåŠŸå…‹æœäº†é™æ€ä¸åŠ¨æ€è¡¨ç¤ºä¹‹é—´çš„æƒè¡¡ï¼Œä¸ºè‡ªåŠ¨ç¼–è¯‘å™¨ä¼˜åŒ–æä¾›äº†å…¼å…·æ•ˆç‡ä¸è¡Œä¸ºæ´å¯ŸåŠ›çš„ç¨‹åºè¡¨å¾æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13158v1",
      "published_date": "2025-10-15 05:18:41 UTC",
      "updated_date": "2025-10-15 05:18:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:29.411547+00:00"
    },
    {
      "arxiv_id": "2510.13157v1",
      "title": "Program of Thoughts for Financial Reasoning: Leveraging Dynamic In-Context Examples and Generative Retrieval",
      "title_zh": "é¢å‘é‡‘èæ¨ç†çš„æ€ç»´ç¨‹åºï¼šåˆ©ç”¨åŠ¨æ€ä¸Šä¸‹æ–‡ç¤ºä¾‹ä¸ç”Ÿæˆå¼æ£€ç´¢",
      "authors": [
        "Subhendu Khatuya",
        "Shashwat Naidu",
        "Pawan Goyal",
        "Niloy Ganguly"
      ],
      "abstract": "Despite continuous advancements in the capabilities of large language models (LLMs), numerical reasoning remains a challenging area. Techniques like chain-of-thought prompting, tree-of-thought prompting, and program-of-thought prompting guide LLMs through intermediate reasoning steps. Although in-context learning with few-shot prompting has improved performance, LLMs still lag behind state-of-the-art models on financial numerical reasoning datasets such as FinQA and ConvFinQA. In this work, we introduce FINDER, a novel two-step framework, to enhance LLMs' capabilities in financial numerical reasoning. The first step utilizes a generative retriever to extract relevant facts from unstructured data, including both text and tables. This is followed by context-aware Program of Thought prompting with dynamic selection of in-context examples. Our model FINDER achieves a new state-of-the-art performance on both the FinQA and ConvFinQA datasets, surpassing previous benchmarks with execution accuracy improvements of 5.98% and 4.05%, respectively.",
      "tldr_zh": "é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é‡‘èæ•°å€¼æ¨ç†(financial numerical reasoning)é¢†åŸŸå­˜åœ¨çš„å±€é™æ€§ï¼Œæœ¬ç ”ç©¶æå‡ºäº†åä¸ºFINDERçš„æ–°å‹ä¸¤é˜¶æ®µæ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨ç”Ÿæˆå¼æ£€ç´¢å™¨(generative retriever)ä»æ–‡æœ¬å’Œè¡¨æ ¼ç­‰éç»“æ„åŒ–æ•°æ®ä¸­æå–å…³é”®äº‹å®ï¼Œéšåé‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥ç¨‹åºæ€ç»´æç¤º(context-aware Program of Thought prompting)å¹¶ç»“åˆåŠ¨æ€é€‰æ‹©çš„ä¸Šä¸‹æ–‡ç¤ºä¾‹(dynamic selection of in-context examples)è¿›è¡Œæ¨ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFINDERåœ¨FinQAå’ŒConvFinQAæ•°æ®é›†ä¸Šå‡å–å¾—äº†æ–°çš„æœ€ä½³æ€§èƒ½(state-of-the-art)ï¼Œå…¶æ‰§è¡Œå‡†ç¡®ç‡(execution accuracy)ç›¸è¾ƒäºæ­¤å‰åŸºå‡†åˆ†åˆ«æå‡äº†5.98%å’Œ4.05%ã€‚è¿™ä¸€æˆæœæ˜¾è‘—å¢å¼ºäº†LLMså¤„ç†å¤æ‚é‡‘èæ•°å€¼åˆ†æçš„èƒ½åŠ›ï¼Œä¸ºç»“åˆç”Ÿæˆå¼æ£€ç´¢ä¸ç¨‹åºåŒ–æ€ç»´çš„æ¨ç†è·¯å¾„æä¾›äº†æœ‰æ•ˆèŒƒå¼ã€‚",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CE",
      "comment": "This work has been accepted for publication in the Main Conference of the Empirical Methods in Natural Language Processing (EMNLP) 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.13157v1",
      "published_date": "2025-10-15 05:16:54 UTC",
      "updated_date": "2025-10-15 05:16:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:32.470220+00:00"
    },
    {
      "arxiv_id": "2510.13912v3",
      "title": "AI Debaters are More Persuasive when Arguing in Alignment with Their Own Beliefs",
      "title_zh": "äººå·¥æ™ºèƒ½è¾©è®ºè€…åœ¨ä¸å…¶è‡ªèº«ä¿¡å¿µä¸€è‡´æ—¶æ›´å…·è¯´æœåŠ›",
      "authors": [
        "MarÃ­a Victoria Carro",
        "Denise Alejandra Mester",
        "Facundo Nieto",
        "Oscar AgustÃ­n Stanchi",
        "Guido Ernesto Bergman",
        "Mario Alejandro Leiva",
        "Eitan Sprejer",
        "Luca NicolÃ¡s Forziati Gangi",
        "Francisca Gauna Selasco",
        "Juan Gustavo CorvalÃ¡n",
        "Gerardo I. Simari",
        "MarÃ­a Vanina Martinez"
      ],
      "abstract": "The core premise of AI debate as a scalable oversight technique is that it is harder to lie convincingly than to refute a lie, enabling the judge to identify the correct position. Yet, existing debate experiments have relied on datasets with ground truth, where lying is reduced to defending an incorrect proposition. This overlooks a subjective dimension: lying also requires the belief that the claim defended is false. In this work, we apply debate to subjective questions and explicitly measure large language models' prior beliefs before experiments. Debaters were asked to select their preferred position, then presented with a judge persona deliberately designed to conflict with their identified priors. This setup tested whether models would adopt sycophantic strategies, aligning with the judge's presumed perspective to maximize persuasiveness, or remain faithful to their prior beliefs. We implemented and compared two debate protocols, sequential and simultaneous, to evaluate potential systematic biases. Finally, we assessed whether models were more persuasive and produced higher-quality arguments when defending positions consistent with their prior beliefs versus when arguing against them. Our main findings show that models tend to prefer defending stances aligned with the judge persona rather than their prior beliefs, sequential debate introduces significant bias favoring the second debater, models are more persuasive when defending positions aligned with their prior beliefs, and paradoxically, arguments misaligned with prior beliefs are rated as higher quality in pairwise comparison. These results can inform human judges to provide higher-quality training signals and contribute to more aligned AI systems, while revealing important aspects of human-AI interaction regarding persuasion dynamics in language models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½è¾©è®ºä½œä¸ºä¸€ç§å¯æ‰©å±•ç›‘ç£(Scalable Oversight)æŠ€æœ¯æ—¶ï¼Œæ¨¡å‹çš„ä¸»è§‚ä¿¡å¿µ(Prior Beliefs)å¦‚ä½•å½±å“å…¶è¯´æœåŠ›ã€‚ç ”ç©¶äººå‘˜é’ˆå¯¹ä¸»è§‚æ€§é—®é¢˜æµ‹é‡äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„åˆå§‹ç«‹åœºï¼Œå¹¶è®¾è®¡äº†ä¸å…¶ä¿¡å¿µç›¸å†²çªçš„æ³•å®˜è§’è‰²(Judge Persona)ï¼Œä»¥è§‚å¯Ÿæ¨¡å‹æ˜¯ä¼šé‡‡å–è®¨å¥½å¼(Sycophantic)ç­–ç•¥è¿˜æ˜¯åšæŒå›ºæœ‰ä¿¡å¿µã€‚é€šè¿‡å¯¹æ¯”é¡ºåºè¾©è®º(Sequential Debate)å’ŒåŒæ­¥è¾©è®º(Simultaneous Debate)ä¸¤ç§åè®®ï¼Œç ”ç©¶å‘ç°æ¨¡å‹å€¾å‘äºè¿åˆæ³•å®˜çš„è§‚ç‚¹è€ŒéåšæŒè‡ªèº«ä¿¡å¿µï¼Œä¸”é¡ºåºè¾©è®ºå­˜åœ¨æ˜æ˜¾çš„åæ‰‹ä¼˜åŠ¿ã€‚å®éªŒè¯æ˜ï¼Œå½“æ¨¡å‹æå«ä¸å…¶å›ºæœ‰ä¿¡å¿µä¸€è‡´çš„ç«‹åœºæ—¶æ›´å…·è¯´æœåŠ›ï¼Œä½†çŸ›ç›¾çš„æ˜¯ï¼Œä¸å…¶ä¿¡å¿µä¸ä¸€è‡´çš„è®ºè¯åœ¨æˆå¯¹æ¯”è¾ƒä¸­åè€Œè¢«è¯„ä¸ºè´¨é‡æ›´é«˜ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†è¯­è¨€æ¨¡å‹åœ¨è¯´æœåŠ›åŠ¨æ€ä¸­çš„å¤æ‚è¡¨ç°ï¼Œä¸ºäººç±»åˆ¤å®˜æä¾›æ›´é«˜è´¨é‡çš„è®­ç»ƒä¿¡å·ä»¥åŠæ„å»ºæ›´å…·å¯¹é½æ€§(Aligned)çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages",
      "pdf_url": "https://arxiv.org/pdf/2510.13912v3",
      "published_date": "2025-10-15 05:02:13 UTC",
      "updated_date": "2025-11-22 15:58:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:35.196768+00:00"
    },
    {
      "arxiv_id": "2510.13143v1",
      "title": "Stable LLM Ensemble: Interaction between Example Representativeness and Diversity",
      "title_zh": "ç¨³å®šçš„ LLM é›†æˆï¼šç¤ºä¾‹ä»£è¡¨æ€§ä¸å¤šæ ·æ€§ä¹‹é—´çš„ç›¸äº’ä½œç”¨",
      "authors": [
        "Junichiro Niimi"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable results in wide range of domains. However, the accuracy and robustness of one-shot LLM predictions remain highly sensitive to the examples and the diversity among ensemble members. This study systematically investigates the effects of example representativeness (one-shot strategy) and output diversity (sampling temperature) on LLM ensemble performance. Two one-shot strategies are compared: centroid-based representative examples (proposed) and randomly sampled examples (baseline) and sampling temperature also is varied. The proposed approach with higher temperature setting significantly outperforms random selection by +7.6% (macro-F1) and -10.5% (RMSE). Furthermore, the proposed model exceeds 5-shot prompting by +21.1% (macro-F1) and -24.0% (RMSE). Our findings demonstrate that combining representative example selection with increased temperature provides the appropriate level of diversity to the ensemble. This work highlights the practical importance of both example selection and controlled diversity in designing effective one-shot LLM ensembles.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)é›†æˆä¸­çš„ç¤ºä¾‹ä»£è¡¨æ€§ä¸å¤šæ ·æ€§ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œæ—¨åœ¨è§£å†³å•æ ·æœ¬(one-shot)é¢„æµ‹å¯¹ç¤ºä¾‹é€‰æ‹©çš„é«˜åº¦æ•æ„Ÿæ€§é—®é¢˜ã€‚ä½œè€…ç³»ç»Ÿåœ°ç ”ç©¶äº†ç¤ºä¾‹ä»£è¡¨æ€§ç­–ç•¥ä¸é‡‡æ ·æ¸©åº¦(sampling temperature)å¯¹é›†æˆæ€§èƒ½çš„å½±å“ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŸºäºè´¨å¿ƒ(centroid-based)çš„ä»£è¡¨æ€§ç¤ºä¾‹é€‰æ‹©æ–¹æ³•ã€‚å®éªŒå¯¹æ¯”äº†è¯¥æ–¹æ³•ä¸éšæœºé‡‡æ ·(random sampling)åŸºå‡†åœ¨ä¸åŒæ¸©åº¦è®¾ç½®ä¸‹çš„è¡¨ç°ï¼Œç»“æœæ˜¾ç¤ºæ‰€ææ–¹æ³•åœ¨è¾ƒé«˜æ¸©åº¦ä¸‹æ˜¾è‘—ä¼˜äºéšæœºé€‰æ‹©ï¼Œå®F1(macro-F1)æå‡äº†7.6%ï¼Œå‡æ–¹æ ¹è¯¯å·®(RMSE)é™ä½äº†10.5%ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨æ€§èƒ½ä¸Šè¿˜å¤§å¹…è¶…è¶Šäº†5-shotæç¤ºç­–ç•¥ã€‚ç ”ç©¶è¯æ˜ï¼Œå°†ä»£è¡¨æ€§ç¤ºä¾‹é€‰æ‹©ä¸å¢åŠ çš„æ¸©åº¦è®¾ç½®ç›¸ç»“åˆï¼Œèƒ½ä¸ºé›†æˆæ¨¡å‹æä¾›æœ€ä½³çš„å¤šæ ·æ€§å¹³è¡¡ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†åœ¨è®¾è®¡é«˜æ•ˆçš„å•æ ·æœ¬LLMé›†æˆç³»ç»Ÿæ—¶ï¼Œç¤ºä¾‹é€‰æ‹©ä¸å—æ§å¤šæ ·æ€§(controlled diversity)çš„å®é™…é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13143v1",
      "published_date": "2025-10-15 04:49:23 UTC",
      "updated_date": "2025-10-15 04:49:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:38.488016+00:00"
    },
    {
      "arxiv_id": "2510.13117v1",
      "title": "On the Reasoning Abilities of Masked Diffusion Language Models",
      "title_zh": "è®ºæ©ç æ‰©æ•£è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›",
      "authors": [
        "Anej Svete",
        "Ashish Sabharwal"
      ],
      "abstract": "Masked diffusion models (MDMs) for text offer a compelling alternative to traditional autoregressive language models. Parallel generation makes them efficient, but their computational capabilities and the limitations inherent to their parallelism remain largely unexplored. To this end, we characterize what types of reasoning problems MDMs can provably solve and how efficiently. We do this by connecting MDMs to the well-understood reasoning frameworks of chain of thought (CoT) and padded looped transformers (PLTs) in the finite-precision log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact, equivalent in this setting, and that MDMs can solve all problems that CoT-augmented transformers can. Moreover, we showcase classes of problems (including regular languages) for which MDMs are inherently more efficient than CoT transformers, where parallel generation allows for substantially faster reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”¨äºæ–‡æœ¬ç”Ÿæˆçš„æ©ç æ‰©æ•£æ¨¡å‹ (Masked diffusion models, MDMs) çš„æ¨ç†èƒ½åŠ›ï¼Œæ—¨åœ¨åˆ†æå…¶å¹¶è¡Œç”Ÿæˆæœºåˆ¶ä¸‹çš„è®¡ç®—æ½œåŠ›ä¸é™åˆ¶ã€‚é€šè¿‡åœ¨æœ‰é™ç²¾åº¦å¯¹æ•°å®½åº¦ (finite-precision log-width) è®¾å®šä¸‹å°† MDMs ä¸é“¾å¼æ€ç»´ (Chain of Thought, CoT) å’Œå¡«å……å¾ªç¯å˜æ¢å™¨ (padded looped transformers, PLTs) è¿›è¡Œå…³è”ï¼Œç ”ç©¶è¯æ˜äº† MDMs ä¸å¤šé¡¹å¼å¡«å……çš„ PLTs åœ¨è¯¥è®¾å®šä¸‹å…·æœ‰ç­‰æ•ˆæ€§ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç° MDMs ä¸ä»…èƒ½è§£å†³æ‰€æœ‰ CoT å¢å¼ºå‹å˜æ¢å™¨å¯å¤„ç†çš„é—®é¢˜ï¼Œä¸”åœ¨å¤„ç†æ­£åˆ™è¯­è¨€ç­‰ç‰¹å®šé—®é¢˜æ—¶æ¯” CoT å˜æ¢å™¨æ›´å…·æ•ˆç‡ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒMDMs çš„å¹¶è¡Œç”Ÿæˆç‰¹æ€§å…è®¸å…¶åœ¨ç‰¹å®šåœºæ™¯ä¸‹å®ç°æ˜¾è‘—æ›´å¿«çš„æ¨ç†ï¼Œä¸ºç†è§£éè‡ªå›å½’è¯­è¨€æ¨¡å‹çš„è®¡ç®—è¾¹ç•Œæä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13117v1",
      "published_date": "2025-10-15 03:29:26 UTC",
      "updated_date": "2025-10-15 03:29:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:40.426271+00:00"
    },
    {
      "arxiv_id": "2510.13115v1",
      "title": "Multi-Label Clinical Text Eligibility Classification and Summarization System",
      "title_zh": "å¤šæ ‡ç­¾ä¸´åºŠæ–‡æœ¬å…¥é€‰èµ„æ ¼åˆ†ç±»ä¸æ‘˜è¦ç³»ç»Ÿ",
      "authors": [
        "Surya Tejaswi Yerramsetty",
        "Almas Fathimah"
      ],
      "abstract": "Clinical trials are central to medical progress because they help improve understanding of human health and the healthcare system. They play a key role in discovering new ways to detect, prevent, or treat diseases, and it is essential that clinical trials include participants with appropriate and diverse medical backgrounds. In this paper, we propose a system that leverages Natural Language Processing (NLP) and Large Language Models (LLMs) to automate multi-label clinical text eligibility classification and summarization. The system combines feature extraction methods such as word embeddings (Word2Vec) and named entity recognition to identify relevant medical concepts, along with traditional vectorization techniques such as count vectorization and TF-IDF (Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF word embeddings that integrate both count-based and embedding-based strengths to capture term importance effectively. Multi-label classification using Random Forest and SVM models is applied to categorize documents based on eligibility criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are evaluated to concisely summarize eligibility requirements. Evaluation with ROUGE scores demonstrates the effectiveness of the proposed methods. This system shows potential for automating clinical trial eligibility assessment using data-driven approaches, thereby improving research efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»“åˆè‡ªç„¶è¯­è¨€å¤„ç†(NLP)å’Œå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ ‡ç­¾ä¸´åºŠæ–‡æœ¬å…¥ç»„èµ„æ ¼åˆ†ç±»ä¸æ‘˜è¦ç³»ç»Ÿï¼Œæ—¨åœ¨æé«˜ä¸´åºŠè¯•éªŒå‚ä¸è€…ç­›é€‰çš„æ•ˆç‡ã€‚è¯¥ç³»ç»Ÿæ•´åˆäº†Word2Vecè¯åµŒå…¥ã€å‘½åå®ä½“è¯†åˆ«(Named Entity Recognition)ä»¥åŠTF-IDFç­‰ç‰¹å¾æå–æŠ€æœ¯ï¼Œå¹¶ç‰¹åˆ«æ¢ç´¢äº†åŠ æƒTF-IDFè¯åµŒå…¥ä»¥ç²¾å‡†æ•æ‰åŒ»ç–—æœ¯è¯­çš„é‡è¦æ€§ã€‚åœ¨åˆ†ç±»é˜¶æ®µï¼Œç ”ç©¶åˆ©ç”¨éšæœºæ£®æ—(Random Forest)å’Œæ”¯æŒå‘é‡æœº(SVM)æ¨¡å‹å¯¹å¤æ‚çš„ä¸´åºŠæ ‡å‡†è¿›è¡Œå¤šæ ‡ç­¾åˆ†ç±»ï¼›åœ¨æ‘˜è¦é˜¶æ®µï¼Œåˆ™é€šè¿‡è¯„ä¼°TextRankã€Luhnå’ŒGPT-3ç­‰æŠ€æœ¯å®ç°å¯¹å…¥ç»„è¦æ±‚çš„ç®€æ´æç‚¼ã€‚å®éªŒé€šè¿‡ROUGEæŒ‡æ ‡éªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œè¯æ˜äº†å…¶åœ¨è‡ªåŠ¨åŒ–ä¸´åºŠè¯•éªŒå…¥ç»„è¯„ä¼°æ–¹é¢çš„æ½œåŠ›ã€‚è¿™ä¸€æ•°æ®é©±åŠ¨çš„æ–¹æ³•ä¸ºä¼˜åŒ–åŒ»å­¦ç ”ç©¶æµç¨‹å’Œç¡®ä¿å‚ä¸è€…å¤šæ ·æ€§æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13115v1",
      "published_date": "2025-10-15 03:21:43 UTC",
      "updated_date": "2025-10-15 03:21:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:42.990583+00:00"
    },
    {
      "arxiv_id": "2510.13108v1",
      "title": "DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models",
      "title_zh": "DriveCriticï¼šåŸºäºè§†è§‰è¯­è¨€æ¨¡å‹çš„è‡ªåŠ¨é©¾é©¶æƒ…å¢ƒæ„ŸçŸ¥ä¸äººç±»å¯¹é½è¯„ä¼°",
      "authors": [
        "Jingyu Song",
        "Zhenxin Li",
        "Shiyi Lan",
        "Xinglong Sun",
        "Nadine Chang",
        "Maying Shen",
        "Joshua Chen",
        "Katherine A. Skinner",
        "Jose M. Alvarez"
      ],
      "abstract": "Benchmarking autonomous driving planners to align with human judgment remains a critical challenge, as state-of-the-art metrics like the Extended Predictive Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To address this, we introduce DriveCritic, a novel framework featuring two key contributions: the DriveCritic dataset, a curated collection of challenging scenarios where context is critical for correct judgment and annotated with pairwise human preferences, and the DriveCritic model, a Vision-Language Model (VLM) based evaluator. Fine-tuned using a two-stage supervised and reinforcement learning pipeline, the DriveCritic model learns to adjudicate between trajectory pairs by integrating visual and symbolic context. Experiments show DriveCritic significantly outperforms existing metrics and baselines in matching human preferences and demonstrates strong context awareness. Overall, our work provides a more reliable, human-aligned foundation to evaluating autonomous driving systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶è§„åˆ’å™¨è¯„ä¼°ä¸­ç°æœ‰æŒ‡æ ‡å¦‚ Extended Predictive Driver Model Score (EPDMS) ç¼ºä¹ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º DriveCritic çš„æ–°å‹è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆæ„å»ºäº† DriveCritic æ•°æ®é›†ï¼Œæ¶µç›–äº†å¤§é‡å¿…é¡»ä¾èµ–ä¸Šä¸‹æ–‡è¿›è¡Œåˆ¤æ–­çš„æŒ‘æˆ˜æ€§åœºæ™¯ï¼Œå¹¶æä¾›äº†æˆå¯¹çš„äººç±»åå¥½æ ‡æ³¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼€å‘äº†åŸºäº Vision-Language Model (VLM) çš„ DriveCritic è¯„ä¼°æ¨¡å‹ï¼Œè¯¥æ¨¡å‹é€šè¿‡ç›‘ç£å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ çš„ä¸¤é˜¶æ®µæµç¨‹è¿›è¡Œå¾®è°ƒï¼Œå®ç°äº†å¯¹è½¨è¿¹å¯¹ (trajectory pairs) è§†è§‰ä¸ç¬¦å·ä¸Šä¸‹æ–‡çš„æ·±åº¦æ•´åˆã€‚å®éªŒè¯æ˜ï¼ŒDriveCritic åœ¨åŒ¹é…äººç±»åå¥½æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰åŸºå‡†æŒ‡æ ‡ï¼Œå±•ç°äº†å‡ºè‰²çš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥ç ”ç©¶ä¸ºè‡ªåŠ¨é©¾é©¶ç³»ç»Ÿæä¾›äº†ä¸€ä¸ªæ›´å¯é ã€ä¸”ä¸äººç±»åˆ¤æ–­é«˜åº¦å¯¹é½çš„è¯„ä¼°åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13108v1",
      "published_date": "2025-10-15 03:00:38 UTC",
      "updated_date": "2025-10-15 03:00:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:46.512336+00:00"
    },
    {
      "arxiv_id": "2510.13106v1",
      "title": "TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models",
      "title_zh": "TRUSTVISï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å¤šç»´åº¦å¯ä¿¡åº¦è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Ruoyu Sun",
        "Da Song",
        "Jiayang Song",
        "Yuheng Huang",
        "Lei Ma"
      ],
      "abstract": "As Large Language Models (LLMs) continue to revolutionize Natural Language Processing (NLP) applications, critical concerns about their trustworthiness persist, particularly in safety and robustness. To address these challenges, we introduce TRUSTVIS, an automated evaluation framework that provides a comprehensive assessment of LLM trustworthiness. A key feature of our framework is its interactive user interface, designed to offer intuitive visualizations of trustworthiness metrics. By integrating well-known perturbation methods like AutoDAN and employing majority voting across various evaluation methods, TRUSTVIS not only provides reliable results but also makes complex evaluation processes accessible to users. Preliminary case studies on models like Vicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our framework in identifying safety and robustness vulnerabilities, while the interactive interface allows users to explore results in detail, empowering targeted model improvements. Video Link: https://youtu.be/k1TrBqNVg8g",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TRUSTVISï¼Œä¸€ä¸ªæ—¨åœ¨å…¨é¢è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å¯é æ€§çš„è‡ªåŠ¨åŒ–è¯„ä¼°æ¡†æ¶ï¼Œä»¥åº”å¯¹ LLMs åœ¨å®‰å…¨æ€§(safety)å’Œé²æ£’æ€§(robustness)æ–¹é¢çš„æŒç»­æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶çš„ä¸€ä¸ªæ ¸å¿ƒç‰¹å¾æ˜¯å…¶äº¤äº’å¼ç”¨æˆ·ç•Œé¢ï¼Œèƒ½å¤Ÿä¸ºå¯é æ€§æŒ‡æ ‡æä¾›ç›´è§‚çš„å¯è§†åŒ–å±•ç¤ºã€‚TRUSTVIS é›†æˆäº† AutoDAN ç­‰å·²çŸ¥çš„æ‰°åŠ¨æ–¹æ³•ï¼Œå¹¶åœ¨å¤šç§è¯„ä¼°æ–¹æ³•ä¸­é‡‡ç”¨å¤šæ•°æŠ•ç¥¨æœºåˆ¶(majority voting)ï¼Œåœ¨æä¾›å¯é è¯„ä¼°ç»“æœçš„åŒæ—¶æ˜¾è‘—é™ä½äº†å¤æ‚è¯„ä¼°è¿‡ç¨‹çš„æ“ä½œé—¨æ§›ã€‚é€šè¿‡å¯¹ Vicuna-7bã€Llama2-7b å’Œ GPT-3.5 ç­‰æ¨¡å‹çš„åˆæ­¥æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ¡†æ¶è¯æ˜äº†å…¶åœ¨è¯†åˆ«å®‰å…¨ä¸é²æ£’æ€§æ¼æ´æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿå…è®¸ç”¨æˆ·é€šè¿‡äº¤äº’ç•Œé¢æ·±å…¥æ¢ç´¢è¯„ä¼°ç»†èŠ‚ï¼Œä»è€Œä¸ºé’ˆå¯¹æ€§çš„æ¨¡å‹æ”¹è¿›ä¸ä¼˜åŒ–æä¾›æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages, 2 figures, To appear in ASE 2025 Demo Track",
      "pdf_url": "https://arxiv.org/pdf/2510.13106v1",
      "published_date": "2025-10-15 02:59:07 UTC",
      "updated_date": "2025-10-15 02:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:41:50.185449+00:00"
    },
    {
      "arxiv_id": "2510.13103v1",
      "title": "ESI: Epistemic Uncertainty Quantification via Semantic-preserving Intervention for Large Language Models",
      "title_zh": "ESIï¼šåŸºäºè¯­ä¹‰ä¿æŒå¹²é¢„çš„å¤§è¯­è¨€æ¨¡å‹è®¤çŸ¥ä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Mingda Li",
        "Xinyu Li",
        "Weinan Zhang",
        "Longxuan Ma"
      ],
      "abstract": "Uncertainty Quantification (UQ) is a promising approach to improve model reliability, yet quantifying the uncertainty of Large Language Models (LLMs) is non-trivial. In this work, we establish a connection between the uncertainty of LLMs and their invariance under semantic-preserving intervention from a causal perspective. Building on this foundation, we propose a novel grey-box uncertainty quantification method that measures the variation in model outputs before and after the semantic-preserving intervention. Through theoretical justification, we show that our method provides an effective estimate of epistemic uncertainty. Our extensive experiments, conducted across various LLMs and a variety of question-answering (QA) datasets, demonstrate that our method excels not only in terms of effectiveness but also in computational efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ç¡®å®šæ€§é‡åŒ–ï¼ˆUncertainty Quantification, UQï¼‰çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºESIçš„æ–°å‹ç°ç›’é‡åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•ä»å› æœè§†è§’ï¼ˆcausal perspectiveï¼‰å‡ºå‘ï¼Œå»ºç«‹äº†LLMsçš„ä¸ç¡®å®šæ€§ä¸å…¶åœ¨ä¿æŒè¯­ä¹‰çš„å¹²é¢„ï¼ˆsemantic-preserving interventionï¼‰ä¸‹çš„ä¸å˜æ€§ä¹‹é—´çš„è”ç³»ã€‚ESIé€šè¿‡æµ‹é‡æ¨¡å‹è¾“å‡ºåœ¨è¯­ä¹‰å¹²é¢„å‰åçš„å˜åŒ–æ¥æœ‰æ•ˆä¼°ç®—è®¤çŸ¥ä¸ç¡®å®šæ€§ï¼ˆepistemic uncertaintyï¼‰ï¼Œå¹¶ä¸ºæ­¤æä¾›äº†ç†è®ºè¯æ˜ã€‚åœ¨å¤šç§LLMså’Œé—®ç­”ï¼ˆQAï¼‰æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è¯†åˆ«æ¨¡å‹å¯é æ€§æ–¹é¢å…·æœ‰æé«˜çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼ŒESIåœ¨ä¿è¯é‡åŒ–å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œè¿˜å±•ç°å‡ºäº†å“è¶Šçš„è®¡ç®—æ•ˆç‡ï¼Œä¸ºæå‡å¤§å‹è¯­è¨€æ¨¡å‹çš„å¯ä¿¡åº¦æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13103v1",
      "published_date": "2025-10-15 02:46:43 UTC",
      "updated_date": "2025-10-15 02:46:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:03.498898+00:00"
    },
    {
      "arxiv_id": "2510.13093v1",
      "title": "A Multi-dimensional Semantic Surprise Framework Based on Low-Entropy Semantic Manifolds for Fine-Grained Out-of-Distribution Detection",
      "title_zh": "åŸºäºä½ç†µè¯­ä¹‰æµå½¢çš„ç»†ç²’åº¦åˆ†å¸ƒå¤–æ£€æµ‹å¤šç»´è¯­ä¹‰æƒŠå¥‡æ¡†æ¶",
      "authors": [
        "Ningkang Peng",
        "Yuzhe Mao",
        "Yuhao Zhang",
        "Linjin Qian",
        "Qianfeng Yu",
        "Yanhui Gu",
        "Yi Chen",
        "Li Kong"
      ],
      "abstract": "Out-of-Distribution (OOD) detection is a cornerstone for the safe deployment of AI systems in the open world. However, existing methods treat OOD detection as a binary classification problem, a cognitive flattening that fails to distinguish between semantically close (Near-OOD) and distant (Far-OOD) unknown risks. This limitation poses a significant safety bottleneck in applications requiring fine-grained risk stratification. To address this, we propose a paradigm shift from a conventional probabilistic view to a principled information-theoretic framework. We formalize the core task as quantifying the Semantic Surprise of a new sample and introduce a novel ternary classification challenge: In-Distribution (ID) vs. Near-OOD vs. Far-OOD. The theoretical foundation of our work is the concept of Low-Entropy Semantic Manifolds, which are explicitly structured to reflect the data's intrinsic semantic hierarchy. To construct these manifolds, we design a Hierarchical Prototypical Network. We then introduce the Semantic Surprise Vector (SSV), a universal probe that decomposes a sample's total surprise into three complementary and interpretable dimensions: conformity, novelty, and ambiguity. To evaluate performance on this new task, we propose the Normalized Semantic Risk (nSR), a cost-sensitive metric. Experiments demonstrate that our framework not only establishes a new state-of-the-art (sota) on the challenging ternary task, but its robust representations also achieve top results on conventional binary benchmarks, reducing the False Positive Rate by over 60% on datasets like LSUN.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Out-of-Distribution (OOD)æ£€æµ‹åœ¨åŒºåˆ†è¯­ä¹‰ç›¸è¿‘(Near-OOD)ä¸è¿œç¨‹(Far-OOD)æœªçŸ¥é£é™©æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLow-Entropy Semantic Manifoldsçš„å¤šç»´Semantic Surpriseæ¡†æ¶ã€‚ç ”ç©¶é€šè¿‡Hierarchical Prototypical Networkæ„å»ºåæ˜ æ•°æ®å†…åœ¨è¯­ä¹‰å±‚çº§ç»“æ„çš„ä½ç†µè¯­ä¹‰æµå½¢ï¼Œå°†æ£€æµ‹ä»»åŠ¡ä»ä¼ ç»Ÿçš„äºŒåˆ†ç±»èŒƒå¼è½¬å˜ä¸ºåŒ…å«IDã€Near-OODä¸Far-OODçš„ä¸‰åˆ†ç±»æŒ‘æˆ˜ã€‚æ‰€æå‡ºçš„Semantic Surprise Vector (SSV)ä½œä¸ºé€šç”¨æ¢æµ‹å·¥å…·ï¼Œä»conformityã€noveltyå’Œambiguityä¸‰ä¸ªå¯è§£é‡Šç»´åº¦é‡åŒ–æ ·æœ¬çš„æƒŠå¼‚åº¦ï¼Œå¹¶é…åˆæ–°æŒ‡æ ‡Normalized Semantic Risk (nSR)å®ç°ç»†ç²’åº¦çš„é£é™©è¯„ä¼°ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æ–°å‹ä¸‰åˆ†ç±»ä»»åŠ¡ä¸­è¾¾åˆ°äº†SOTAæ°´å¹³ï¼Œå¹¶åœ¨å¸¸è§„äºŒåˆ†ç±»åŸºå‡†æµ‹è¯•ä¸­å°†False Positive Rateé™ä½äº†60%ä»¥ä¸Šï¼Œæ˜¾è‘—æå‡äº†AIç³»ç»Ÿåœ¨å¼€æ”¾ä¸–ç•Œéƒ¨ç½²ä¸­çš„å®‰å…¨æ€§ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13093v1",
      "published_date": "2025-10-15 02:26:35 UTC",
      "updated_date": "2025-10-15 02:26:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:05.500782+00:00"
    },
    {
      "arxiv_id": "2510.13909v1",
      "title": "Knowledge Reasoning Language Model: Unifying Knowledge and Language for Inductive Knowledge Graph Reasoning",
      "title_zh": "çŸ¥è¯†æ¨ç†è¯­è¨€æ¨¡å‹ï¼šèåˆçŸ¥è¯†ä¸è¯­è¨€çš„å½’çº³å¼çŸ¥è¯†å›¾è°±æ¨ç†",
      "authors": [
        "Xingrui Zhuo",
        "Jiapu Wang",
        "Gongqing Wu",
        "Zhongyuan Wang",
        "Jichen Zhang",
        "Shirui Pan",
        "Xindong Wu"
      ],
      "abstract": "Inductive Knowledge Graph Reasoning (KGR) aims to discover facts in open-domain KGs containing unknown entities and relations, which poses a challenge for KGR models in comprehending uncertain KG components. Existing studies have proposed Knowledge Graph Foundation Models (KGFMs) that learn structural invariances across KGs to handle this uncertainty. Recently, Large Language Models (LLMs) have demonstrated strong capabilities for open-domain knowledge reasoning. As a result, the latest research has focused on LLM-based KGFMs that integrate LLM knowledge with KG context for inductive KGR. However, the intrinsic knowledge of LLMs may be overshadowed by sparse KG context, leading to LLM knowledge distortion, which can cause irreversible damage to model reasoning. Moreover, existing LLM-based KGR methods still struggle to fully constrain generative hallucinations in LLMs, severely limiting the credibility of reasoning results. To address these limitations, we propose a Knowledge Reasoning Language Model (KRLM) that achieves unified coordination between LLM knowledge and KG context throughout the KGR process. Specifically, we design a Knowledge Reasoning Language (KRL) instruction format and a KRL tokenizer to align LLM knowledge with KG representations. Then, we propose a KRL attention layer that coordinates intrinsic LLM knowledge with additional KG context through a dynamic knowledge memory mechanism. Finally, a structure-aware next-entity predictor is proposed, which strictly constrains the reasoning results within a trustworthy knowledge domain. Extensive experimental results on 25 real-world inductive KGR datasets demonstrate the significant superiority of the proposed KRLM\\footnote{Our source codes are available at https://anonymous.4open.science/r/KRLM-EA36 in both zero-shot reasoning and fine-tuning scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Knowledge Reasoning Language Model (KRLM)ï¼Œæ—¨åœ¨è§£å†³å½’çº³å¼çŸ¥è¯†å›¾è°±æ¨ç†(Inductive Knowledge Graph Reasoning)ä¸­å¤§è¯­è¨€æ¨¡å‹(LLMs)å­˜åœ¨çš„çŸ¥è¯†å¤±çœŸå’Œç”Ÿæˆå¹»è§‰(Generative Hallucinations)é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡è®¾è®¡çš„Knowledge Reasoning Language (KRL)æŒ‡ä»¤æ ¼å¼å’ŒKRLåˆ†è¯å™¨(Tokenizer)ï¼Œå®ç°äº†LLMçŸ¥è¯†ä¸çŸ¥è¯†å›¾è°±(KG)è¡¨ç¤ºçš„æœ‰æ•ˆå¯¹é½ã€‚å…¶æ ¸å¿ƒæ¶æ„åŒ…å«ä¸€ä¸ªKRLæ³¨æ„åŠ›å±‚ï¼Œåˆ©ç”¨åŠ¨æ€çŸ¥è¯†è®°å¿†æœºåˆ¶åè°ƒLLMçš„å†…åœ¨çŸ¥è¯†ä¸å¤–éƒ¨çš„çŸ¥è¯†å›¾è°±ä¸Šä¸‹æ–‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç»“æ„æ„ŸçŸ¥çš„ä¸‹ä¸€å®ä½“é¢„æµ‹å™¨(Structure-aware Next-entity Predictor)ï¼Œå°†æ¨ç†ç»“æœä¸¥æ ¼çº¦æŸåœ¨å¯ä¿¡çš„çŸ¥è¯†åŸŸå†…ã€‚åœ¨25ä¸ªçœŸå®ä¸–ç•Œçš„å½’çº³å¼KGRæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒKRLMåœ¨é›¶æ ·æœ¬æ¨ç†å’Œå¾®è°ƒåœºæ™¯ä¸‹å‡å±•ç°å‡ºæ˜¾è‘—çš„ä¼˜è¶Šæ€§ï¼Œä¸ºç»Ÿä¸€çŸ¥è¯†ä¸è¯­è¨€çš„å¼€æ”¾åŸŸæ¨ç†æä¾›äº†å¯é çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13909v1",
      "published_date": "2025-10-15 02:11:58 UTC",
      "updated_date": "2025-10-15 02:11:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:09.123292+00:00"
    },
    {
      "arxiv_id": "2510.13081v1",
      "title": "Agentic Discovery: Closing the Loop with Cooperative Agents",
      "title_zh": "æ™ºèƒ½ä½“åŒ–å‘ç°ï¼šé€šè¿‡åä½œæ™ºèƒ½ä½“å®ç°é—­ç¯",
      "authors": [
        "J. Gregory Pauloski",
        "Kyle Chard",
        "Ian T. Foster"
      ],
      "abstract": "As data-driven methods, artificial intelligence (AI), and automated workflows accelerate scientific tasks, we see the rate of discovery increasingly limited by human decision-making tasks such as setting objectives, generating hypotheses, and designing experiments. We postulate that cooperative agents are needed to augment the role of humans and enable autonomous discovery. Realizing such agents will require progress in both AI and infrastructure.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ•°æ®é©±åŠ¨æ–¹æ³•å’Œäººå·¥æ™ºèƒ½ (AI) åŠ é€Ÿç§‘å­¦ä»»åŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œäººç±»åœ¨è®¾å®šç›®æ ‡ã€ç”Ÿæˆå‡è®¾å’Œè®¾è®¡å®éªŒç­‰å†³ç­–ç¯èŠ‚æ­£æ—¥ç›Šæˆä¸ºé™åˆ¶ç§‘å­¦å‘ç°ç‡çš„ç“¶é¢ˆã€‚ä½œè€…æå‡ºäº† Agentic Discovery çš„æ ¸å¿ƒç†å¿µï¼Œå¼ºè°ƒéœ€è¦é€šè¿‡ååŒæ™ºèƒ½ä½“ (Cooperative Agents) æ¥å¢å¼ºäººç±»çš„èƒ½åŠ›ï¼Œä»è€Œå®ç°ç§‘å­¦ç ”ç©¶çš„è‡ªä¸»å‘ç° (Autonomous Discovery)ã€‚æ–‡ç« æŒ‡å‡ºï¼Œå®ç°è¿™ç§é—­ç¯ç³»ç»Ÿéœ€è¦åœ¨äººå·¥æ™ºèƒ½ç®—æ³•ä»¥åŠæ”¯æ’‘æ€§åŸºç¡€è®¾æ–½ (Infrastructure) ä¸¤ä¸ªå±‚é¢å…±åŒå–å¾—è¿›å±•ã€‚è¯¥ç ”ç©¶ä¸ºå¦‚ä½•é€šè¿‡äººæœºåä½œå…‹æœå½“å‰ç§‘ç ”æµç¨‹ä¸­çš„æ•ˆç‡éšœç¢å¹¶æ¨åŠ¨è‡ªåŠ¨åŒ–å‘ç°æä¾›äº†é‡è¦çš„å‰ç»æ€§è§è§£ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Published in IEEE Computer Volume 58 Issue 10",
      "pdf_url": "https://arxiv.org/pdf/2510.13081v1",
      "published_date": "2025-10-15 01:50:41 UTC",
      "updated_date": "2025-10-15 01:50:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:16.311246+00:00"
    },
    {
      "arxiv_id": "2510.13077v1",
      "title": "Transformer-based Scalable Beamforming Optimization via Deep Residual Learning",
      "title_zh": "åŸºäºæ·±åº¦æ®‹å·®å­¦ä¹ çš„ Transformer å¯æ‰©å±•æ³¢æŸèµ‹å½¢ä¼˜åŒ–",
      "authors": [
        "Yubo Zhang",
        "Xiao-Yang Liu",
        "Xiaodong Wang"
      ],
      "abstract": "We develop an unsupervised deep learning framework for downlink beamforming in large-scale MU-MISO channels. The model is trained offline, allowing real-time inference through lightweight feedforward computations in dynamic communication environments. Following the learning-to-optimize (L2O) paradigm, a multi-layer Transformer iteratively refines both channel and beamformer features via residual connections. To enhance training, three strategies are introduced: (i) curriculum learning (CL) to improve early-stage convergence and avoid local optima, (ii) semi-amortized learning to refine each Transformer block with a few gradient ascent steps, and (iii) sliding-window training to stabilize optimization by training only a subset of Transformer blocks at a time. Extensive simulations show that the proposed scheme outperforms existing baselines at low-to-medium SNRs and closely approaches WMMSE performance at high SNRs, while achieving substantially faster inference than iterative and online learning approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäº Transformer çš„æ— ç›‘ç£æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡ MU-MISO ä¿¡é“ä¸­çš„ä¸‹è¡Œé“¾è·¯ Beamforming ä¼˜åŒ–é—®é¢˜ã€‚è¯¥æ¡†æ¶éµå¾ª Learning-to-Optimize (L2O) èŒƒå¼ï¼Œåˆ©ç”¨å¤šå±‚ Transformer ç»“æ„å’Œ Residual Connections è¿­ä»£ç²¾ç‚¼ä¿¡é“ä¸ Beamformer ç‰¹å¾ã€‚ä¸ºäº†å¢å¼ºè®­ç»ƒæ•ˆæœï¼Œç ”ç©¶å¼•å…¥äº† Curriculum Learning (CL) ä»¥åŠ é€Ÿæ—©æœŸæ”¶æ•›ï¼Œé‡‡ç”¨ Semi-Amortized Learning è¿›ä¸€æ­¥ç²¾ç‚¼ Transformer æ¨¡å—ï¼Œå¹¶åˆ©ç”¨ Sliding-Window Training ç¨³å®šä¼˜åŒ–è¿‡ç¨‹ã€‚è¯¥æ¨¡å‹æ”¯æŒç¦»çº¿è®­ç»ƒå’Œåœ¨çº¿å®æ—¶æ¨ç†ï¼Œé€šè¿‡è½»é‡çº§çš„é¦ˆé€è®¡ç®—åº”å¯¹åŠ¨æ€é€šä¿¡ç¯å¢ƒã€‚ä»¿çœŸå®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä½ä¸­ç­‰ä¿¡å™ªæ¯” (SNR) ä¸‹ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œåœ¨é«˜ä¿¡å™ªæ¯”ä¸‹æ€§èƒ½æ¥è¿‘ WMMSEã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„è¿­ä»£ç®—æ³•å’Œåœ¨çº¿å­¦ä¹ æ–¹æ³•ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¿æŒé«˜æ°´å¹³æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—æå‡äº†æ¨ç†é€Ÿåº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13077v1",
      "published_date": "2025-10-15 01:43:51 UTC",
      "updated_date": "2025-10-15 01:43:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:18.478864+00:00"
    },
    {
      "arxiv_id": "2510.13068v2",
      "title": "NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models",
      "title_zh": "NeuroRVQï¼šé¢å‘ç”Ÿæˆå¼å¤§è§„æ¨¡è„‘ç”µæ¨¡å‹çš„å¤šå°ºåº¦ EEG æ ‡è®°åŒ–",
      "authors": [
        "Konstantinos Barmpas",
        "Na Lee",
        "Alexandros Koliousis",
        "Yannis Panagakis",
        "Dimitrios A. Adamos",
        "Nikolaos Laskaris",
        "Stefanos Zafeiriou"
      ],
      "abstract": "Electroencephalography (EEG) captures neural activity across multiple temporal and spectral scales, yielding signals that are rich but complex for representation learning. Recently, EEG foundation models trained to predict masked signal-tokens have shown promise for learning generalizable representations. However, their performance is hindered by their signal tokenization modules. Existing neural tokenizers fail to preserve high-frequency dynamics, limiting their ability to reconstruct EEG signals with high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM) centered on a codebook-based tokenizer. Our tokenizer integrates: (i) multi-scale feature extraction modules that capture the full frequency neural spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware loss function for efficient training. This design enables efficient EEG compression while supporting accurate reconstruction across all frequency bands, leading to robust generative masked modeling. Our empirical results demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ tokenizer establishes a strong prior for codebook-based general-purpose brainwave models, enabling advances in neural decoding, generative modeling and multimodal biosignal integration.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NeuroRVQï¼Œè¿™æ˜¯ä¸€ç§ä»¥codebook-based tokenizerä¸ºæ ¸å¿ƒçš„å¯æ‰©å±•å¤§è„‘ç”µæ³¢æ¨¡å‹(Large Brainwave Model, LBM)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç¥ç»åˆ†è¯å™¨(neural tokenizers)åœ¨å¤„ç†è„‘ç”µå›¾(EEG)ä¿¡å·æ—¶æ— æ³•æœ‰æ•ˆä¿ç•™é«˜é¢‘åŠ¨æ€åŠé‡å»ºä¿çœŸåº¦æœ‰é™çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é›†æˆäº†å¤šå°ºåº¦ç‰¹å¾æå–æ¨¡å—ä»¥æ•æ‰å…¨é¢‘è°±ç¥ç»æ´»åŠ¨ï¼Œå¹¶åˆ©ç”¨åˆ†å±‚æ®‹å·®çŸ¢é‡é‡åŒ–(hierarchical residual vector quantization, RVQ)ç æœ¬å®ç°é«˜åˆ†è¾¨ç‡ç¼–ç ã€‚é€šè¿‡å¼•å…¥æ„ŸçŸ¥EEGä¿¡å·ç›¸ä½å’Œå¹…åº¦çš„æŸå¤±å‡½æ•°ï¼ŒNeuroRVQèƒ½å¤Ÿå®ç°é«˜æ•ˆçš„EEGå‹ç¼©å¹¶åœ¨æ‰€æœ‰é¢‘å¸¦ä¸Šå®Œæˆç²¾ç¡®çš„ä¿¡å·é‡å»ºã€‚å®éªŒç»“æœè¯æ˜ï¼ŒNeuroRVQåœ¨é‡æ„è¯¯å·®å’Œå¤šç§ä¸‹æ¸¸ä»»åŠ¡è¡¨ç°ä¸Šå‡ä¼˜äºç°æœ‰çš„LBMsã€‚è¯¥ç ”ç©¶ä¸ºåŸºäºç æœ¬çš„é€šç”¨å¤§è„‘ç”µæ³¢æ¨¡å‹å»ºç«‹äº†å¼ºå¤§çš„å…ˆéªŒï¼Œæ˜¾è‘—æ¨åŠ¨äº†ç¥ç»è§£ç ã€ç”Ÿæˆå¼å»ºæ¨¡(generative modeling)ä»¥åŠå¤šæ¨¡æ€ç”Ÿç‰©ä¿¡å·é›†æˆçš„æŠ€æœ¯è¿›æ­¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13068v2",
      "published_date": "2025-10-15 01:26:52 UTC",
      "updated_date": "2025-12-01 18:14:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:22.398486+00:00"
    },
    {
      "arxiv_id": "2510.13063v1",
      "title": "True Self-Supervised Novel View Synthesis is Transferable",
      "title_zh": "çœŸæ­£çš„è‡ªç›‘ç£æ–°è§†ç‚¹åˆæˆå…·æœ‰è¿ç§»æ€§",
      "authors": [
        "Thomas W. Mitchel",
        "Hyunwoo Ryu",
        "Vincent Sitzmann"
      ],
      "abstract": "In this paper, we identify that the key criterion for determining whether a model is truly capable of novel view synthesis (NVS) is transferability: Whether any pose representation extracted from one video sequence can be used to re-render the same camera trajectory in another. We analyze prior work on self-supervised NVS and find that their predicted poses do not transfer: The same set of poses lead to different camera trajectories in different 3D scenes. Here, we present XFactor, the first geometry-free self-supervised model capable of true NVS. XFactor combines pair-wise pose estimation with a simple augmentation scheme of the inputs and outputs that jointly enables disentangling camera pose from scene content and facilitates geometric reasoning. Remarkably, we show that XFactor achieves transferability with unconstrained latent pose variables, without any 3D inductive biases or concepts from multi-view geometry -- such as an explicit parameterization of poses as elements of SE(3). We introduce a new metric to quantify transferability, and through large-scale experiments, we demonstrate that XFactor significantly outperforms prior pose-free NVS transformers, and show that latent poses are highly correlated with real-world poses through probing experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºï¼Œè¡¡é‡æ¨¡å‹æ˜¯å¦çœŸæ­£å…·å¤‡æ–°è§†è§’åˆæˆ (Novel View Synthesis, NVS) èƒ½åŠ›çš„å…³é”®æ ‡å‡†åœ¨äºå¯è¿ç§»æ€§ (transferability)ï¼Œå³ä½å§¿è¡¨ç¤ºèƒ½å¦è·¨åœºæ™¯é€šç”¨ã€‚ä½œè€…å‘ç°ä»¥å¾€çš„è‡ªç›‘ç£ NVS æ¨¡å‹ç”±äºä½å§¿ä¸åœºæ™¯ç»‘å®šè€Œç¼ºä¹è¿ç§»æ€§ï¼Œå› æ­¤æå‡ºäº†é¦–ä¸ªæ— éœ€å‡ ä½•å…ˆéªŒä¸”å…·å¤‡çœŸå® NVS èƒ½åŠ›çš„è‡ªç›‘ç£æ¨¡å‹ XFactorã€‚è¯¥æ¨¡å‹é€šè¿‡ç»“åˆæˆå¯¹ä½å§¿ä¼°è®¡ (pair-wise pose estimation) ä¸ç‰¹å®šçš„è¾“å…¥è¾“å‡ºå¢å¼ºæ–¹æ¡ˆï¼ŒæˆåŠŸå®ç°äº†ç›¸æœºä½å§¿ä¸åœºæ™¯å†…å®¹çš„è§£è€¦ã€‚å³ä¾¿ä¸ä¾èµ– 3D å½’çº³åç½® (3D inductive biases) æˆ– SE(3) ç­‰æ˜¾å¼å‚æ•°åŒ–ï¼ŒXFactor ä¹Ÿèƒ½é€šè¿‡æ— çº¦æŸçš„éšå¼ä½å§¿å˜é‡å®ç°é«˜æ•ˆè¿ç§»ã€‚å¤§è§„æ¨¡å®éªŒè¯æ˜ï¼ŒXFactor çš„æ€§èƒ½æ˜¾è‘—ä¼˜äºæ­¤å‰çš„æ— ä½å§¿ NVS Transformerï¼Œä¸”æ¢æµ‹å®éªŒè¡¨æ˜å…¶å­¦ä¹ åˆ°çš„éšå¼ä½å§¿ä¸ç°å®ä¸–ç•Œä½å§¿å…·æœ‰é«˜åº¦ç›¸å…³æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13063v1",
      "published_date": "2025-10-15 01:09:56 UTC",
      "updated_date": "2025-10-15 01:09:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:22.602110+00:00"
    },
    {
      "arxiv_id": "2510.13062v1",
      "title": "Towards Human-Centric Intelligent Treatment Planning for Radiation Therapy",
      "title_zh": "è¿ˆå‘ä»¥äººä¸ºä¸­å¿ƒçš„æ”¾å°„æ²»ç–—æ™ºèƒ½æ²»ç–—è®¡åˆ’",
      "authors": [
        "Adnan Jafar",
        "Xun Jia"
      ],
      "abstract": "Current radiation therapy treatment planning is limited by suboptimal plan quality, inefficiency, and high costs. This perspective paper explores the complexity of treatment planning and introduces Human-Centric Intelligent Treatment Planning (HCITP), an AI-driven framework under human oversight, which integrates clinical guidelines, automates plan generation, and enables direct interactions with operators. We expect that HCITP will enhance efficiency, potentially reducing planning time to minutes, and will deliver personalized, high-quality plans. Challenges and potential solutions are discussed.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰æ”¾å°„æ²»ç–—(Radiation Therapy)è®¡åˆ’åˆ¶å®šä¸­å­˜åœ¨çš„æ•ˆç‡ä½ã€æˆæœ¬é«˜åŠè®¡åˆ’è´¨é‡ä¸ä½³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä»¥äººä¸ºä¸­å¿ƒçš„æ™ºèƒ½æ²»ç–—è®¡åˆ’(Human-Centric Intelligent Treatment Planning, HCITP)è¿™ä¸€AIé©±åŠ¨çš„æ–°å‹æ¡†æ¶ã€‚HCITPåœ¨äººå·¥ç›‘ç£ä¸‹è¿è¡Œï¼Œé€šè¿‡æ•´åˆä¸´åºŠæŒ‡å—(Clinical Guidelines)å¹¶å®ç°è‡ªåŠ¨åŒ–è®¡åˆ’ç”Ÿæˆï¼Œæ”¯æŒä¸æ“ä½œäººå‘˜çš„ç›´æ¥äº¤äº’ã€‚è¯¥æ¡†æ¶æ—¨åœ¨æ˜¾è‘—æå‡å·¥ä½œæµæ•ˆç‡ï¼Œæœ‰æœ›å°†åŸæœ¬è€—æ—¶çš„è®¡åˆ’åˆ¶å®šè¿‡ç¨‹ç¼©çŸ­è‡³åˆ†é’Ÿçº§åˆ«ï¼ŒåŒæ—¶ç¡®ä¿ç”Ÿæˆä¸ªæ€§åŒ–ä¸”é«˜è´¨é‡çš„æ²»ç–—æ–¹æ¡ˆã€‚æ–‡ç« è¿˜è¿›ä¸€æ­¥æ¢è®¨äº†è¯¥æŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­é¢ä¸´çš„æŒ‘æˆ˜åŠæ½œåœ¨è§£å†³æ–¹æ¡ˆï¼Œä¸ºæ”¾å°„æ²»ç–—é¢†åŸŸçš„æ™ºèƒ½åŒ–è½¬å‹æä¾›äº†å‰ç»æ€§çš„æŒ‡å¯¼æ–¹å‘ã€‚",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "27 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2510.13062v1",
      "published_date": "2025-10-15 01:04:48 UTC",
      "updated_date": "2025-10-15 01:04:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:21.688333+00:00"
    },
    {
      "arxiv_id": "2510.13054v1",
      "title": "VLA-0: Building State-of-the-Art VLAs with Zero Modification",
      "title_zh": "VLA-0ï¼šé›¶æ”¹åŠ¨æ„å»ºæœ€å…ˆè¿›çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨¡å‹",
      "authors": [
        "Ankit Goyal",
        "Hugo Hadfield",
        "Xuning Yang",
        "Valts Blukis",
        "Fabio Ramos"
      ],
      "abstract": "Vision-Language-Action models (VLAs) hold immense promise for enabling generalist robot manipulation. However, the best way to build them remains an open question. Current approaches often add complexity, such as modifying the existing vocabulary of a Vision-Language Model (VLM) with action tokens or introducing special action heads. Curiously, the simplest strategy of representing actions directly as text has remained largely unexplored. This work introduces VLA-0 to investigate this idea. We find that VLA-0 is not only effective; it is surprisingly powerful. With the right design, VLA-0 outperforms more involved models. On LIBERO, a popular benchmark for evaluating VLAs, VLA-0 outperforms all existing methods trained on the same robotic data, including $Ï€_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without large-scale robotics-specific training, it outperforms methods trained on large-scale robotic data, like $Ï€_0.5$-KI, $Ï€_0$, GR00T-N1 and MolmoAct. These findings also translate to the real world, where VLA-0 outperforms SmolVLA, a VLA model pre-trained on large-scale real data. This paper summarizes our unexpected findings and spells out the specific techniques required to unlock the high performance of this simple yet potent VLA design. Visual results, code, and trained models are provided here: https://vla0.github.io/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VLA-0ï¼Œæ—¨åœ¨æ¢è®¨åœ¨ä¸ä¿®æ”¹Vision-Language Model (VLM) è¯æ±‡è¡¨æˆ–å¼•å…¥ç‰¹æ®Šaction headsçš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æœ€ç®€å•çš„æ–‡æœ¬è¡¨ç¤ºç­–ç•¥æ„å»ºé«˜æ€§èƒ½Vision-Language-Action models (VLAs) çš„å¯è¡Œæ€§ã€‚ç ”ç©¶å‘ç°ï¼Œå°†åŠ¨ä½œç›´æ¥è¡¨ç¤ºä¸ºæ–‡æœ¬å¹¶ç»“åˆç‰¹å®šè®¾è®¡æŠ€æœ¯ï¼Œèƒ½å¤Ÿé‡Šæ”¾å‡ºæƒŠäººçš„æ€§èƒ½ã€‚åœ¨LIBEROåŸºå‡†æµ‹è¯•ä¸­ï¼ŒVLA-0çš„è¡¨ç°è¶…è¶Šäº†æ‰€æœ‰åœ¨ç›¸åŒæœºå™¨äººæ•°æ®ä¸Šè®­ç»ƒçš„ç°æœ‰æ¨¡å‹ï¼Œå¦‚$Ï€_0.5$-KIã€OpenVLA-OFTå’ŒSmolVLAã€‚æ­¤å¤–ï¼Œå³ä½¿åœ¨æ²¡æœ‰å¤§è§„æ¨¡æœºå™¨äººç‰¹å®šè®­ç»ƒçš„æƒ…å†µä¸‹ï¼ŒVLA-0çš„æ€§èƒ½ä¹Ÿä¼˜äº$Ï€_0$ã€GR00T-N1å’ŒMolmoActç­‰åœ¨æµ·é‡æ•°æ®ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚åœ¨ç°å®ä¸–ç•Œåœºæ™¯ä¸­ï¼ŒVLA-0åŒæ ·å±•ç°å‡ºä¼˜äºé¢„è®­ç»ƒæ¨¡å‹SmolVLAçš„å®åŠ›ã€‚è¯¥é¡¹å·¥ä½œè¯æ˜äº†æç®€çš„ç­–ç•¥ä¹Ÿèƒ½åœ¨æœºå™¨äººæ“æ§é¢†åŸŸè¾¾åˆ°State-of-the-Artæ°´å¹³ï¼Œå¹¶æ€»ç»“äº†å®ç°è¿™ä¸€ç›®æ ‡çš„å…³é”®æŠ€æœ¯ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2510.13054v1",
      "published_date": "2025-10-15 00:31:10 UTC",
      "updated_date": "2025-10-15 00:31:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:28.073617+00:00"
    },
    {
      "arxiv_id": "2510.13052v1",
      "title": "Time-Varying Optimization for Streaming Data Via Temporal Weighting",
      "title_zh": "åŸºäºæ—¶é—´åŠ æƒçš„æµå¼æ•°æ®æ—¶å˜ä¼˜åŒ–",
      "authors": [
        "Muhammad Faraz Ul Abrar",
        "NicolÃ² Michelusi",
        "Erik G. Larsson"
      ],
      "abstract": "Classical optimization theory deals with fixed, time-invariant objective functions. However, time-varying optimization has emerged as an important subject for decision-making in dynamic environments. In this work, we study the problem of learning from streaming data through a time-varying optimization lens. Unlike prior works that focus on generic formulations, we introduce a structured, \\emph{weight-based} formulation that explicitly captures the streaming-data origin of the time-varying objective, where at each time step, an agent aims to minimize a weighted average loss over all the past data samples. We focus on two specific weighting strategies: (1) uniform weights, which treat all samples equally, and (2) discounted weights, which geometrically decay the influence of older data. For both schemes, we derive tight bounds on the ``tracking error'' (TE), defined as the deviation between the model parameter and the time-varying optimum at a given time step, under gradient descent (GD) updates. We show that under uniform weighting, the TE vanishes asymptotically with a $\\mathcal{O}(1/t)$ decay rate, whereas discounted weighting incurs a nonzero error floor controlled by the discount factor and the number of gradient updates performed at each time step. Our theoretical findings are validated through numerical simulations.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»Time-Varying Optimizationçš„è§’åº¦æ¢è®¨äº†æµæ•°æ®(streaming data)çš„å­¦ä¹ é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæƒé‡çš„ç»“æ„åŒ–å…¬å¼(weight-based formulation)ï¼Œé€šè¿‡æœ€å°åŒ–è¿‡å»æ•°æ®æ ·æœ¬çš„åŠ æƒå¹³å‡æŸå¤±æ¥æ•æ‰åŠ¨æ€ç¯å¢ƒä¸­çš„ç›®æ ‡å˜åŒ–ã€‚ç ”ç©¶é‡ç‚¹å¯¹æ¯”äº†ä¸¤ç§æƒé‡ç­–ç•¥ï¼šå°†æ‰€æœ‰æ ·æœ¬è§†ä¸ºç­‰åŒçš„uniform weightsï¼Œä»¥åŠå¯¹æ—§æ•°æ®è¿›è¡Œå‡ ä½•è¡°å‡çš„discounted weightsã€‚åœ¨Gradient Descent (GD)æ›´æ–°æœºåˆ¶ä¸‹ï¼Œè¯¥ç ”ç©¶ä¸ºè¡¡é‡æ¨¡å‹å‚æ•°ä¸æ—¶å˜æœ€ä¼˜è§£åå·®çš„Tracking Error (TE)æ¨å¯¼å‡ºäº†ä¸¥ç´§ç•Œé™(tight bounds)ã€‚ç†è®ºåˆ†æè¡¨æ˜ï¼Œåœ¨uniform weightsç­–ç•¥ä¸‹ï¼ŒTEä»¥$O(1/t)$çš„é€Ÿç‡æ¸è¿‘æ¶ˆå¤±ï¼Œè€Œdiscounted weightsåˆ™ä¼šäº§ç”Ÿä¸€ä¸ªå—æŠ˜æ‰£å› å­å’Œæ›´æ–°é¢‘ç‡å½±å“çš„éé›¶è¯¯å·®é™(nonzero error floor)ã€‚è¿™äº›ç†è®ºå‘ç°æœ€ç»ˆé€šè¿‡æ•°å€¼æ¨¡æ‹Ÿ(numerical simulations)å¾—åˆ°äº†éªŒè¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE Asilomar, 2025",
      "pdf_url": "https://arxiv.org/pdf/2510.13052v1",
      "published_date": "2025-10-15 00:18:17 UTC",
      "updated_date": "2025-10-15 00:18:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-25T03:42:31.269457+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 140,
  "processed_papers_count": 140,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T03:43:23.361174+00:00"
}