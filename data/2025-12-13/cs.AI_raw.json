[
  {
    "arxiv_id": "2512.14750v1",
    "title": "Multiscale Cross-Modal Mapping of Molecular, Pathologic, and Radiologic Phenotypes in Lipid-Deficient Clear Cell Renal CellCarcinoma",
    "authors": [
      "Ying Cui",
      "Dongzhe Zheng",
      "Ke Yu",
      "Xiyin Zheng",
      "Xiaorui Wang",
      "Xinxiang Li",
      "Yan Gu",
      "Lin Fu",
      "Xinyi Chen",
      "Wenjie Mei",
      "Xin-Gui Peng"
    ],
    "abstract": "Clear cell renal cell carcinoma (ccRCC) exhibits extensive intratumoral heterogeneity on multiple biological scales, contributing to variable clinical outcomes and limiting the effectiveness of conventional TNM staging, which highlights the urgent need for multiscale integrative analytic frameworks. The lipid-deficient de-clear cell differentiated (DCCD) ccRCC subtype, defined by multi-omics analyses, is associated with adverse outcomes even in early-stage disease. Here, we establish a hierarchical cross-scale framework for the preoperative identification of DCCD-ccRCC. At the highest layer, cross-modal mapping transferred molecular signatures to histological and CT phenotypes, establishing a molecular-to-pathology-to-radiology supervisory bridge. Within this framework, each modality-specific model is designed to mirror the inherent hierarchical structure of tumor biology. PathoDCCD captured multi-scale microscopic features, from cellular morphology and tissue architecture to meso-regional organization. RadioDCCD integrated complementary macroscopic information by combining whole-tumor and its habitat-subregions radiomics with a 2D maximal-section heterogeneity metric. These nested models enabled integrated molecular subtype prediction and clinical risk stratification. Across five cohorts totaling 1,659 patients, PathoDCCD reliably recapitulated molecular subtypes, while RadioDCCD provided reliable preoperative prediction. The consistent predictions identified patients with the poorest clinical outcomes. This cross-scale paradigm unifies molecular biology, computational pathology, and quantitative radiology into a biologically grounded strategy for preoperative noninvasive molecular phenotyping of ccRCC.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.14750v1",
    "published_date": "2025-12-13 23:49:41 UTC",
    "updated_date": "2025-12-13 23:49:41 UTC"
  },
  {
    "arxiv_id": "2512.12483v3",
    "title": "Mage: Cracking Elliptic Curve Cryptography with Cross-Axis Transformers",
    "authors": [
      "Lily Erickson"
    ],
    "abstract": "With the advent of machine learning and quantum computing, the 21st century has gone from a place of relative algorithmic security, to one of speculative unease and possibly, cyber catastrophe.\n  Modern algorithms like Elliptic Curve Cryptography (ECC) are the bastion of current cryptographic security protocols that form the backbone of consumer protection ranging from Hypertext Transfer Protocol Secure (HTTPS) in the modern internet browser, to cryptographic financial instruments like Bitcoin.\n  And there's been very little work put into testing the strength of these ciphers. Practically the only study that I could find was on side-channel recognition, a joint paper from the University of Milan, Italy and King's College, London\\cite{battistello2025ecc}.\n  These algorithms are already considered bulletproof by many consumers, but exploits already exist for them, and with computing power and distributed, federated compute on the rise, it's only a matter of time before these current bastions fade away into obscurity, and it's on all of us to stand up when we notice something is amiss, lest we see such passages claim victims in that process.\n  In this paper, we seek to explore the use of modern language model architecture in cracking the association between a known public key, and its associated private key, by intuitively learning to reverse engineer the public keypair generation process, effectively solving the curve.\n  Additonally, we attempt to ascertain modern machine learning's ability to memorize public-private secp256r1 keypairs, and to then test their ability to reverse engineer the public keypair generation process.\n  It is my belief that proof-for would be equally valuable as proof-against in either of these categories.\n  Finally, we'll conclude with some number crunching on where we see this particular field heading in the future.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.12483v3",
    "published_date": "2025-12-13 22:45:35 UTC",
    "updated_date": "2026-01-01 20:09:52 UTC"
  },
  {
    "arxiv_id": "2512.13729v1",
    "title": "Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution",
    "authors": [
      "Jacob Schnell",
      "Aditya Makkar",
      "Gunadi Gani",
      "Aniket Srinivasan Ashok",
      "Darren Lo",
      "Mike Optis",
      "Alexander Wong",
      "Yuhao Chen"
    ],
    "abstract": "Various weather modelling problems (e.g., weather forecasting, optimizing turbine placements, etc.) require ample access to high-resolution, highly accurate wind data. Acquiring such high-resolution wind data, however, remains a challenging and expensive endeavour. Traditional reconstruction approaches are typically either cost-effective or accurate, but not both. Deep learning methods, including diffusion models, have been proposed to resolve this trade-off by leveraging advances in natural image super-resolution. Wind data, however, is distinct from natural images, and wind super-resolvers often use upwards of 10 input channels, significantly more than the usual 3-channel RGB inputs in natural images. To better leverage a large number of conditioning variables in diffusion models, we present a generalization of classifier-free guidance (CFG) to multiple conditioning inputs. Our novel composite classifier-free guidance (CCFG) can be dropped into any pre-trained diffusion model trained with standard CFG dropout. We demonstrate that CCFG outputs are higher-fidelity than those from CFG on wind super-resolution tasks. We present WindDM, a diffusion model trained for industrial-scale wind dynamics reconstruction and leveraging CCFG. WindDM achieves state-of-the-art reconstruction quality among deep learning models and costs up to $1000\\times$ less than classical methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13729v1",
    "published_date": "2025-12-13 22:44:41 UTC",
    "updated_date": "2025-12-13 22:44:41 UTC"
  },
  {
    "arxiv_id": "2512.13728v1",
    "title": "CurvaDion: Curvature-Adaptive Distributed Orthonormalization",
    "authors": [
      "Bhavesh Kumar",
      "Roger Jin",
      "Jeffrey Quesnelle"
    ],
    "abstract": "As language models scale to trillions of parameters, distributed training across many GPUs becomes essential, yet gradient synchronization over high-bandwidth, low-latency networks remains a critical bottleneck. While recent methods like Dion reduce per-step communication through low-rank updates, they synchronize at every step regardless of the optimization landscape. We observe that synchronization requirements vary dramatically throughout training: workers naturally compute similar gradients in flat regions, making frequent synchronization redundant, while high-curvature regions require coordination to prevent divergence. We introduce CurvaDion, which uses Relative Maximum Momentum Change (RMMC) to detect high-curvature regions requiring synchronization. RMMC leverages momentum dynamics which are already computed during optimization as a computationally tractable proxy for directional curvature, adding only $\\mathcal{O}(d)$ operations per layer. We establish theoretical connections between RMMC and loss curvature and demonstrate that CurvaDion achieves 99\\% communication reduction while matching baseline convergence across models from 160M to 1.3B parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Nous Research",
    "pdf_url": "https://arxiv.org/pdf/2512.13728v1",
    "published_date": "2025-12-13 22:38:51 UTC",
    "updated_date": "2025-12-13 22:38:51 UTC"
  },
  {
    "arxiv_id": "2512.12477v1",
    "title": "MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs",
    "authors": [
      "Jiawen Chen",
      "Yanyan He",
      "Qi Shao",
      "Mengli Wei",
      "Duxin Chen",
      "Wenwu Yu",
      "Yanlong Zhao"
    ],
    "abstract": "Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12477v1",
    "published_date": "2025-12-13 22:21:33 UTC",
    "updated_date": "2025-12-13 22:21:33 UTC"
  },
  {
    "arxiv_id": "2512.12474v1",
    "title": "AI-Driven Real-Time Kick Classification in Olympic Taekwondo Using Sensor Fusion",
    "authors": [
      "Jamsheed Mistri"
    ],
    "abstract": "Olympic Taekwondo has faced challenges in spectator engagement due to static, defensive gameplay and contentious scoring. Current Protector and Scoring Systems (PSS) rely on impact sensors and simplistic logic, encouraging safe strategies that diminish the sport's dynamism. This paper proposes an AI-powered scoring system that integrates existing PSS sensors with additional accelerometers, gyroscopes, magnetic/RFID, and impact force sensors in a sensor fusion framework. The system classifies kicks in real-time to identify technique type, contact location, impact force, and even the part of the foot used. A machine learning pipeline employing sensor fusion and Support Vector Machines (SVMs) is detailed, enabling automatic kick technique recognition for scoring. We present a novel kick scoring rubric that awards points based on specific kick techniques (e.g., turning and spinning kicks) to incentivize dynamic attacks. Drawing on a 2024 study achieving 96-98% accuracy, we validate the feasibility of real-time kick classification and further propose enhancements to this methodology, such as ensemble SVM classifiers and expanded datasets, to achieve the high-stakes accuracy required by the sport. We analyze how the proposed system can improve scoring fairness, reduce rule exploitation and illegitimate tactics, encourage more dynamic techniques, and enhance spectator understanding and excitement. The paper includes system design illustrations, a kick scoring table from an AI-augmented rule set, and discusses anticipated impacts on Olympic Taekwondo.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SY",
    "comment": "13 pages, 4 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.12474v1",
    "published_date": "2025-12-13 22:17:51 UTC",
    "updated_date": "2025-12-13 22:17:51 UTC"
  },
  {
    "arxiv_id": "2512.12465v1",
    "title": "Exploring the Design Space of Transition Matching",
    "authors": [
      "Uriel Singer",
      "Yaron Lipman"
    ],
    "abstract": "Transition Matching (TM) is an emerging paradigm for generative modeling that generalizes diffusion and flow-matching models as well as continuous-state autoregressive models. TM, similar to previous paradigms, gradually transforms noise samples to data samples, however it uses a second ``internal'' generative model to implement the transition steps, making the transitions more expressive compared to diffusion and flow models. To make this paradigm tractable, TM employs a large backbone network and a smaller \"head\" module to efficiently execute the generative transition step. In this work, we present a large-scale, systematic investigation into the design, training and sampling of the head in TM frameworks, focusing on its time-continuous bidirectional variant. Through comprehensive ablations and experimentation involving training 56 different 1.7B text-to-image models (resulting in 549 unique evaluations) we evaluate the affect of the head module architecture and modeling during training as-well as a useful family of stochastic TM samplers. We analyze the impact on generation quality, training, and inference efficiency. We find that TM with an MLP head, trained with a particular time weighting and sampled with high frequency sampler provides best ranking across all metrics reaching state-of-the-art among all tested baselines, while Transformer head with sequence scaling and low frequency sampling is a runner up excelling at image aesthetics. Lastly, we believe the experiments presented highlight the design aspects that are likely to provide most quality and efficiency gains, while at the same time indicate what design choices are not likely to provide further gains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12465v1",
    "published_date": "2025-12-13 21:34:47 UTC",
    "updated_date": "2025-12-13 21:34:47 UTC"
  },
  {
    "arxiv_id": "2512.12462v1",
    "title": "Dynamical modeling of nonlinear latent factors in multiscale neural activity with real-time inference",
    "authors": [
      "Eray Erturk",
      "Maryam M. Shanechi"
    ],
    "abstract": "Real-time decoding of target variables from multiple simultaneously recorded neural time-series modalities, such as discrete spiking activity and continuous field potentials, is important across various neuroscience applications. However, a major challenge for doing so is that different neural modalities can have different timescales (i.e., sampling rates) and different probabilistic distributions, or can even be missing at some time-steps. Existing nonlinear models of multimodal neural activity do not address different timescales or missing samples across modalities. Further, some of these models do not allow for real-time decoding. Here, we develop a learning framework that can enable real-time recursive decoding while nonlinearly aggregating information across multiple modalities with different timescales and distributions and with missing samples. This framework consists of 1) a multiscale encoder that nonlinearly aggregates information after learning within-modality dynamics to handle different timescales and missing samples in real time, 2) a multiscale dynamical backbone that extracts multimodal temporal dynamics and enables real-time recursive decoding, and 3) modality-specific decoders to account for different probabilistic distributions across modalities. In both simulations and three distinct multiscale brain datasets, we show that our model can aggregate information across modalities with different timescales and distributions and missing samples to improve real-time target decoding. Further, our method outperforms various linear and nonlinear multimodal benchmarks in doing so.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems 2025. Code is available at https://github.com/ShanechiLab/mrine",
    "pdf_url": "https://arxiv.org/pdf/2512.12462v1",
    "published_date": "2025-12-13 21:20:21 UTC",
    "updated_date": "2025-12-13 21:20:21 UTC"
  },
  {
    "arxiv_id": "2512.12461v1",
    "title": "Cross-Modal Representational Knowledge Distillation for Enhanced Spike-Informed LFP Modeling",
    "authors": [
      "Eray Erturk",
      "Saba Hashemi",
      "Maryam M. Shanechi"
    ],
    "abstract": "Local field potentials (LFPs) can be routinely recorded alongside spiking activity in intracortical neural experiments, measure a larger complementary spatiotemporal scale of brain activity for scientific inquiry, and can offer practical advantages over spikes, including greater long-term stability, robustness to electrode degradation, and lower power requirements. Despite these advantages, recent neural modeling frameworks have largely focused on spiking activity since LFP signals pose inherent modeling challenges due to their aggregate, population-level nature, often leading to lower predictive power for downstream task variables such as motor behavior. To address this challenge, we introduce a cross-modal knowledge distillation framework that transfers high-fidelity representational knowledge from pretrained multi-session spike transformer models to LFP transformer models. Specifically, we first train a teacher spike model across multiple recording sessions using a masked autoencoding objective with a session-specific neural tokenization strategy. We then align the latent representations of the student LFP model to those of the teacher spike model. Our results show that the Distilled LFP models consistently outperform single- and multi-session LFP baselines in both fully unsupervised and supervised settings, and can generalize to other sessions without additional distillation while maintaining superior performance. These findings demonstrate that cross-modal knowledge distillation is a powerful and scalable approach for leveraging high-performing spike models to develop more accurate LFP models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems 2025. Code is available at https://github.com/ShanechiLab/CrossModalDistillation",
    "pdf_url": "https://arxiv.org/pdf/2512.12461v1",
    "published_date": "2025-12-13 21:20:13 UTC",
    "updated_date": "2025-12-13 21:20:13 UTC"
  },
  {
    "arxiv_id": "2512.13726v1",
    "title": "Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce",
    "authors": [
      "Sayak Chakrabarty",
      "Souradip Pal"
    ],
    "abstract": "Unlike traditional recommendation tasks, finite user time budgets introduce a critical resource constraint, requiring the recommender system to balance item relevance and evaluation cost. For example, in a mobile shopping interface, users interact with recommendations by scrolling, where each scroll triggers a list of items called slate. Users incur an evaluation cost - time spent assessing item features before deciding to click. Highly relevant items having higher evaluation costs may not fit within the user's time budget, affecting engagement. In this position paper, our objective is to evaluate reinforcement learning algorithms that learn patterns in user preferences and time budgets simultaneously, crafting recommendations with higher engagement potential under resource constraints. Our experiments explore the use of reinforcement learning to recommend items for users using Alibaba's Personalized Re-ranking dataset supporting slate optimization in e-commerce contexts. Our contributions include (i) a unified formulation of time-constrained slate recommendation modeled as Markov Decision Processes (MDPs) with budget-aware utilities; (ii) a simulation framework to study policy behavior on re-ranking data; and (iii) empirical evidence that on-policy and off-policy control can improve performance under tight time budgets than traditional contextual bandit-based methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.13726v1",
    "published_date": "2025-12-13 20:32:47 UTC",
    "updated_date": "2025-12-13 20:32:47 UTC"
  },
  {
    "arxiv_id": "2512.12443v1",
    "title": "AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline",
    "authors": [
      "Akhmadillo Mamirov",
      "Faiaz Azmain",
      "Hanyu Wang"
    ],
    "abstract": "AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12443v1",
    "published_date": "2025-12-13 19:48:44 UTC",
    "updated_date": "2025-12-13 19:48:44 UTC"
  },
  {
    "arxiv_id": "2512.12436v1",
    "title": "Rough Sets for Explainability of Spectral Graph Clustering",
    "authors": [
      "Bartłomiej Starosta",
      "Sławomir T. Wierzchoń",
      "Piotr Borkowski",
      "Dariusz Czerski",
      "Marcin Sydow",
      "Eryk Laskowski",
      "Mieczysław A. Kłopotek"
    ],
    "abstract": "Graph Spectral Clustering methods (GSC) allow representing clusters of diverse shapes, densities, etc. However, the results of such algorithms, when applied e.g. to text documents, are hard to explain to the user, especially due to embedding in the spectral space which has no obvious relation to document contents. Furthermore, the presence of documents without clear content meaning and the stochastic nature of the clustering algorithms deteriorate explainability. This paper proposes an enhancement to the explanation methodology, proposed in an earlier research of our team. It allows us to overcome the latter problems by taking inspiration from rough set theory.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 figures, 21tables",
    "pdf_url": "https://arxiv.org/pdf/2512.12436v1",
    "published_date": "2025-12-13 19:29:04 UTC",
    "updated_date": "2025-12-13 19:29:04 UTC"
  },
  {
    "arxiv_id": "2512.19707v1",
    "title": "Bidirectional human-AI collaboration in brain tumour assessments improves both expert human and AI agent performance",
    "authors": [
      "James K Ruffle",
      "Samia Mohinta",
      "Guilherme Pombo",
      "Asthik Biswas",
      "Alan Campbell",
      "Indran Davagnanam",
      "David Doig",
      "Ahmed Hamman",
      "Harpreet Hyare",
      "Farrah Jabeen",
      "Emma Lim",
      "Dermot Mallon",
      "Stephanie Owen",
      "Sophie Wilkinson",
      "Sebastian Brandner",
      "Parashkev Nachev"
    ],
    "abstract": "The benefits of artificial intelligence (AI) human partnerships-evaluating how AI agents enhance expert human performance-are increasingly studied. Though rarely evaluated in healthcare, an inverse approach is possible: AI benefiting from the support of an expert human agent. Here, we investigate both human-AI clinical partnership paradigms in the magnetic resonance imaging-guided characterisation of patients with brain tumours. We reveal that human-AI partnerships improve accuracy and metacognitive ability not only for radiologists supported by AI, but also for AI agents supported by radiologists. Moreover, the greatest patient benefit was evident with an AI agent supported by a human one. Synergistic improvements in agent accuracy, metacognitive performance, and inter-rater agreement suggest that AI can create more capable, confident, and consistent clinical agents, whether human or model-based. Our work suggests that the maximal value of AI in healthcare could emerge not from replacing human intelligence, but from AI agents that routinely leverage and amplify it.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "38 pages, 6 figures, 7 supplementary figures",
    "pdf_url": "https://arxiv.org/pdf/2512.19707v1",
    "published_date": "2025-12-13 18:56:50 UTC",
    "updated_date": "2025-12-13 18:56:50 UTC"
  },
  {
    "arxiv_id": "2512.12413v1",
    "title": "Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale",
    "authors": [
      "Gabriel R. Lau",
      "Wei Yan Low",
      "Louis Tay",
      "Ysabel Guevarra",
      "Dragan Gašević",
      "Andree Hartanto"
    ],
    "abstract": "Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12413v1",
    "published_date": "2025-12-13 17:56:12 UTC",
    "updated_date": "2025-12-13 17:56:12 UTC"
  },
  {
    "arxiv_id": "2512.13725v2",
    "title": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy",
    "authors": [
      "Steve Nwaiwu",
      "Nipat Jongsawat",
      "Anucha Tungkasthan"
    ],
    "abstract": "Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematically evaluate quantization effects across all three levels of Pearls Causal Ladder. Using a 3000 sample stratified CLadder benchmark, we find that rung level accuracy in Llama 3 8B remains broadly stable under quantization, with NF4 showing less than one percent overall degradation. Interventional queries at rung 2 are the most sensitive to precision loss, whereas counterfactual reasoning at rung 3 is comparatively stable but exhibits heterogeneous weaknesses across query types such as collider bias and backdoor adjustment. Experiments on the CRASS benchmark show near identical performance across precisions, indicating that existing commonsense counterfactual datasets lack the structural sensitivity needed to reveal quantization induced reasoning drift. We further evaluate Graph Retrieval Augmented Generation using ground truth causal graphs and observe a consistent improvement in NF4 interventional accuracy of plus 1.7 percent, partially offsetting compression related degradation. These results suggest that causal reasoning is unexpectedly robust to four bit quantization, graph structured augmentation can selectively reinforce interventional reasoning, and current counterfactual benchmarks fail to capture deeper causal brittleness. This work provides an initial empirical map of compressed causal reasoning and practical guidance for deploying efficient and structurally supported causal AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13725v2",
    "published_date": "2025-12-13 17:54:15 UTC",
    "updated_date": "2025-12-24 05:31:23 UTC"
  },
  {
    "arxiv_id": "2512.12411v1",
    "title": "Feeling the Strength but Not the Source: Partial Introspection in LLMs",
    "authors": [
      "Ely Hahami",
      "Lavik Jain",
      "Ishaan Sinha"
    ],
    "abstract": "Recent work from Anthropic claims that frontier models can sometimes detect and name injected \"concepts\" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn \"emergent introspection\" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages (+ 5 pages for appendix), 5 figures, 1 table",
    "pdf_url": "https://arxiv.org/pdf/2512.12411v1",
    "published_date": "2025-12-13 17:51:13 UTC",
    "updated_date": "2025-12-13 17:51:13 UTC"
  },
  {
    "arxiv_id": "2512.12410v1",
    "title": "A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams",
    "authors": [
      "Khalfalla Awedat",
      "Mohamed Abidalrekab",
      "Mohammad El-Yabroudi"
    ],
    "abstract": "Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12410v1",
    "published_date": "2025-12-13 17:50:57 UTC",
    "updated_date": "2025-12-13 17:50:57 UTC"
  },
  {
    "arxiv_id": "2512.15776v1",
    "title": "Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying",
    "authors": [
      "Shaun Baek",
      "Sam Liu",
      "Joseph Ukpong"
    ],
    "abstract": "Large Language Models (LLMs) act as powerful reasoning engines but struggle with \"symbol grounding\" in embodied environments, particularly when information is asymmetrically distributed. We investigate the Privileged Information Bias (or \"Curse of Knowledge\"), where a knowledgeable \"Leader\" agent fails to guide a sensor-limited \"Follower\" due to a lack of Theory of Mind. To quantify this phenomenon, we propose a novel Asymmetric Assistive Reasoning framework within AI2-THOR. Our experiments reveal a significant \"Success Gap\": while the Leader successfully perceives the target in 35.0% of episodes, the collaborative team succeeds only 17.0% of the time, implying that nearly 50% of feasible plans fail solely due to communicative grounding errors. We demonstrate that a \"Pull-based\" protocol (active querying) is significantly more robust than standard \"Push-based\" instruction, with successful episodes featuring 2x the frequency of clarification requests. This research isolates the mechanism of active uncertainty reduction as a prerequisite for safe human-AI and robot-robot collaboration.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 9 pages of content, 6 tables, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.15776v1",
    "published_date": "2025-12-13 17:17:51 UTC",
    "updated_date": "2025-12-13 17:17:51 UTC"
  },
  {
    "arxiv_id": "2512.12381v1",
    "title": "Entropy Collapse: A Universal Failure Mode of Intelligent Systems",
    "authors": [
      "Truong Xuan Khanh",
      "Truong Quynh Hoa"
    ],
    "abstract": "Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.\n  We identify \\emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.\n  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.\n  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.\n  \\noindent\\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.12381v1",
    "published_date": "2025-12-13 16:12:27 UTC",
    "updated_date": "2025-12-13 16:12:27 UTC"
  },
  {
    "arxiv_id": "2512.15775v1",
    "title": "Enhanced Web User Interface Design Via Cross-Device Responsiveness Assessment Using An Improved HCI-INTEGRATED DL Schemes",
    "authors": [
      "Shrinivass Arunachalam Balasubramanian"
    ],
    "abstract": "User Interface (UI) optimization is essential in the digital era to enhance user satisfaction in web environments. Nevertheless, the existing UI optimization models had overlooked the Cross-Responsiveness (CR) assessment, affecting the user interaction efficiency. Consequently, this article proposes a dynamic web UI optimization through CR assessment using Finite Exponential Continuous State Machine (FECSM) and Quokka Nonlinear Difference Swarm Optimization Algorithm (QNDSOA). Initially, the design and user interaction related information is collected as well as pre-processed for min-max normalization. Next, the Human-Computer Interaction (HCI)-based features are extracted, followed by user behaviour pattern grouping. Meanwhile, the CR assessment is done using FECSM. Then, the proposed Bidirectional Gated Luong and Mish Recurrent Unit (BiGLMRU) is used to classify the User eXperience (UX) change type, which is labelled based on the User Interface Change Prediction Index (UICPI). Lastly, a novel QNDSOA is utilized to optimize the UI design with an average fitness of 98.5632%. Feedback monitoring is done after optimal deployment.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "17 Pages, 8 Figures",
    "pdf_url": "https://arxiv.org/pdf/2512.15775v1",
    "published_date": "2025-12-13 15:58:07 UTC",
    "updated_date": "2025-12-13 15:58:07 UTC"
  },
  {
    "arxiv_id": "2512.12337v1",
    "title": "SCIR: A Self-Correcting Iterative Refinement Framework for Enhanced Information Extraction Based on Schema",
    "authors": [
      "Yushen Fang",
      "Jianjun Li",
      "Mingqian Ding",
      "Chang Liu",
      "Xinchi Zou",
      "Wenqi Yang"
    ],
    "abstract": "Although Large language Model (LLM)-powered information extraction (IE) systems have shown impressive capabilities, current fine-tuning paradigms face two major limitations: high training costs and difficulties in aligning with LLM preferences. To address these issues, we propose a novel universal IE paradigm, the Self-Correcting Iterative Refinement (SCIR) framework, along with a Multi-task Bilingual (Chinese-English) Self-Correcting (MBSC) dataset containing over 100,000 entries. The SCIR framework achieves plug-and-play compatibility with existing LLMs and IE systems through its Dual-Path Self-Correcting module and feedback-driven optimization, thereby significantly reducing training costs. Concurrently, the MBSC dataset tackles the challenge of preference alignment by indirectly distilling GPT-4's capabilities into IE result detection models. Experimental results demonstrate that SCIR outperforms state-of-the-art IE methods across three key tasks: named entity recognition, relation extraction, and event extraction, achieving a 5.27 percent average improvement in span-based Micro-F1 while reducing training costs by 87 percent compared to baseline approaches. These advancements not only enhance the flexibility and accuracy of IE systems but also pave the way for lightweight and efficient IE paradigms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12337v1",
    "published_date": "2025-12-13 14:07:25 UTC",
    "updated_date": "2025-12-13 14:07:25 UTC"
  },
  {
    "arxiv_id": "2512.12332v1",
    "title": "Dynamic Homophily with Imperfect Recall: Modeling Resilience in Adversarial Networks",
    "authors": [
      "Saad Alqithami"
    ],
    "abstract": "The purpose of this study is to investigate how homophily, memory constraints, and adversarial disruptions collectively shape the resilience and adaptability of complex networks. To achieve this, we develop a new framework that integrates explicit memory decay mechanisms into homophily-based models and systematically evaluate their performance across diverse graph structures and adversarial settings. Our methods involve extensive experimentation on synthetic datasets, where we vary decay functions, reconnection probabilities, and similarity measures, primarily comparing cosine similarity with traditional metrics such as Jaccard similarity and baseline edge weights. The results show that cosine similarity achieves up to a 30\\% improvement in stability metrics in sparse, convex, and modular networks. Moreover, the refined value-of-recall metric demonstrates that strategic forgetting can bolster resilience by balancing network robustness and adaptability. The findings underscore the critical importance of aligning memory and similarity parameters with the structural and adversarial dynamics of the network. By quantifying the tangible benefits of incorporating memory constraints into homophily-based analyses, this study offers actionable insights for optimizing real-world applications, including social systems, collaborative platforms, and cybersecurity contexts.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CR",
      "cs.IT"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12332v1",
    "published_date": "2025-12-13 13:45:27 UTC",
    "updated_date": "2025-12-13 13:45:27 UTC"
  },
  {
    "arxiv_id": "2512.12324v2",
    "title": "UniMark: Artificial Intelligence Generated Content Identification Toolkit",
    "authors": [
      "Meilin Li",
      "Ji He",
      "Yi Yu",
      "Jia Xu",
      "Shanzhe Lei",
      "Yan Teng",
      "Yingchun Wang",
      "Xuhong Wang"
    ],
    "abstract": "The rapid proliferation of Artificial Intelligence Generated Content has precipitated a crisis of trust and urgent regulatory demands. However, existing identification tools suffer from fragmentation and a lack of support for visible compliance marking. To address these gaps, we introduce the \\textbf{UniMark}, an open-source, unified framework for multimodal content governance. Our system features a modular unified engine that abstracts complexities across text, image, audio, and video modalities. Crucially, we propose a novel dual-operation strategy, natively supporting both \\emph{Hidden Watermarking} for copyright protection and \\emph{Visible Marking} for regulatory compliance. Furthermore, we establish a standardized evaluation framework with three specialized benchmarks (Image/Video/Audio-Bench) to ensure rigorous performance assessment. This toolkit bridges the gap between advanced algorithms and engineering implementation, fostering a more transparent and secure digital ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "5 Pages",
    "pdf_url": "https://arxiv.org/pdf/2512.12324v2",
    "published_date": "2025-12-13 13:30:48 UTC",
    "updated_date": "2025-12-26 07:22:58 UTC"
  },
  {
    "arxiv_id": "2512.12288v1",
    "title": "Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases",
    "authors": [
      "Mahule Roy",
      "Guillaume Lambard"
    ],
    "abstract": "Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.12288v1",
    "published_date": "2025-12-13 11:17:21 UTC",
    "updated_date": "2025-12-13 11:17:21 UTC"
  },
  {
    "arxiv_id": "2512.12285v1",
    "title": "Fractional Differential Equation Physics-Informed Neural Network and Its Application in Battery State Estimation",
    "authors": [
      "Lujuan Dang",
      "Zilai Wang"
    ],
    "abstract": "Accurate estimation of the State of Charge (SOC) is critical for ensuring the safety, reliability, and performance optimization of lithium-ion battery systems. Conventional data-driven neural network models often struggle to fully characterize the inherent complex nonlinearities and memory-dependent dynamics of electrochemical processes, significantly limiting their predictive accuracy and physical interpretability under dynamic operating conditions. To address this challenge, this study proposes a novel neural architecture termed the Fractional Differential Equation Physics-Informed Neural Network (FDIFF-PINN), which integrates fractional calculus with deep learning. The main contributions of this paper include: (1) Based on a fractional-order equivalent circuit model, a discretized fractional-order partial differential equation is constructed. (2) Comparative experiments were conducted using a dynamic charge/discharge dataset of Panasonic 18650PF batteries under multi-temperature conditions (from -10$^{\\circ}$C to 20$^{\\circ}$C).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12285v1",
    "published_date": "2025-12-13 11:11:03 UTC",
    "updated_date": "2025-12-13 11:11:03 UTC"
  },
  {
    "arxiv_id": "2512.12284v3",
    "title": "V-Rex: Real-Time Streaming Video LLM Acceleration via Dynamic KV Cache Retrieval",
    "authors": [
      "Donghyuk Kim",
      "Sejeong Yang",
      "Wonjin Shin",
      "Joo-Young Kim"
    ],
    "abstract": "Streaming video large language models (LLMs) are increasingly used for real-time multimodal tasks such as video captioning, question answering, conversational agents, and augmented reality. However, these models face fundamental memory and computational challenges because their key-value (KV) caches grow substantially with continuous streaming video input. This process requires an iterative prefill stage, which is a unique feature of streaming video LLMs. Due to its iterative prefill stage, it suffers from significant limitations, including extensive computation, substantial data transfer, and degradation in accuracy. Crucially, this issue is exacerbated for edge deployment, which is the primary target for these models.\n  In this work, we propose V-Rex, the first software-hardware co-designed accelerator that comprehensively addresses both algorithmic and hardware bottlenecks in streaming video LLM inference. At its core, V-Rex introduces ReSV, a training-free dynamic KV cache retrieval algorithm. ReSV exploits temporal and spatial similarity-based token clustering to reduce excessive KV cache memory across video frames. To fully realize these algorithmic benefits, V-Rex offers a compact, low-latency hardware accelerator with a dynamic KV cache retrieval engine (DRE), featuring bit-level and early-exit based computing units. V-Rex achieves unprecedented real-time of 3.9-8.3 FPS and energy-efficient streaming video LLM inference on edge deployment with negligible accuracy loss. While DRE only accounts for 2.2% power and 2.0% area, the system delivers 1.9-19.7x speedup and 3.1-18.5x energy efficiency improvements over AGX Orin GPU. This work is the first to comprehensively tackle KV cache retrieval across algorithms and hardware, enabling real-time streaming video LLM inference on resource-constrained edge devices.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "eess.IV",
    "comment": "14 pages, 20 figures, conference, accepted by HPCA 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.12284v3",
    "published_date": "2025-12-13 11:02:04 UTC",
    "updated_date": "2025-12-24 07:46:59 UTC"
  },
  {
    "arxiv_id": "2512.12273v1",
    "title": "GRC-Net: Gram Residual Co-attention Net for epilepsy prediction",
    "authors": [
      "Bihao You",
      "Jiping Cui"
    ],
    "abstract": "Prediction of epilepsy based on electroencephalogram (EEG) signals is a rapidly evolving field. Previous studies have traditionally applied 1D processing to the entire EEG signal. However, we have adopted the Gram Matrix method to transform the signals into a 3D representation, enabling modeling of signal relationships across dimensions while preserving the temporal dependencies of the one-dimensional signals. Additionally, we observed an imbalance between local and global signals within the EEG data. Therefore, we introduced multi-level feature extraction, utilizing coattention for capturing global signal characteristics and an inception structure for processing local signals, achieving multi-granular feature extraction. Our experiments on the BONN dataset demonstrate that for the most challenging five-class classification task, GRC-Net achieved an accuracy of 93.66%, outperforming existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12273v1",
    "published_date": "2025-12-13 10:29:28 UTC",
    "updated_date": "2025-12-13 10:29:28 UTC"
  },
  {
    "arxiv_id": "2512.12272v1",
    "title": "Accurate de novo sequencing of the modified proteome with OmniNovo",
    "authors": [
      "Yuhan Chen",
      "Shang Qu",
      "Zhiqiang Gao",
      "Yuejin Yang",
      "Xiang Zhang",
      "Sheng Xu",
      "Xinjie Mao",
      "Liujia Qian",
      "Jiaqi Wei",
      "Zijie Qiu",
      "Chenyu You",
      "Lei Bai",
      "Ning Ding",
      "Tiannan Guo",
      "Bowen Zhou",
      "Siqi Sun"
    ],
    "abstract": "Post-translational modifications (PTMs) serve as a dynamic chemical language regulating protein function, yet current proteomic methods remain blind to a vast portion of the modified proteome. Standard database search algorithms suffer from a combinatorial explosion of search spaces, limiting the identification of uncharacterized or complex modifications. Here we introduce OmniNovo, a unified deep learning framework for reference-free sequencing of unmodified and modified peptides directly from tandem mass spectra. Unlike existing tools restricted to specific modification types, OmniNovo learns universal fragmentation rules to decipher diverse PTMs within a single coherent model. By integrating a mass-constrained decoding algorithm with rigorous false discovery rate estimation, OmniNovo achieves state-of-the-art accuracy, identifying 51\\% more peptides than standard approaches at a 1\\% false discovery rate. Crucially, the model generalizes to biological sites unseen during training, illuminating the dark matter of the proteome and enabling unbiased comprehensive analysis of cellular regulation.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12272v1",
    "published_date": "2025-12-13 10:27:14 UTC",
    "updated_date": "2025-12-13 10:27:14 UTC"
  },
  {
    "arxiv_id": "2512.12260v1",
    "title": "A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure",
    "authors": [
      "Ege Atacan Doğan",
      "Peter F. Patel-Schneider"
    ],
    "abstract": "Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12260v1",
    "published_date": "2025-12-13 09:59:22 UTC",
    "updated_date": "2025-12-13 09:59:22 UTC"
  },
  {
    "arxiv_id": "2512.12250v1",
    "title": "Stochastic Volatility Modelling with LSTM Networks: A Hybrid Approach for S&P 500 Index Volatility Forecasting",
    "authors": [
      "Anna Perekhodko",
      "Robert Ślepaczuk"
    ],
    "abstract": "Accurate volatility forecasting is essential in banking, investment, and risk management, because expectations about future market movements directly influence current decisions. This study proposes a hybrid modelling framework that integrates a Stochastic Volatility model with a Long Short Term Memory neural network. The SV model improves statistical precision and captures latent volatility dynamics, especially in response to unforeseen events, while the LSTM network enhances the model's ability to detect complex nonlinear patterns in financial time series. The forecasting is conducted using daily data from the S and P 500 index, covering the period from January 1 1998 to December 31 2024. A rolling window approach is employed to train the model and generate one step ahead volatility forecasts. The performance of the hybrid SV-LSTM model is evaluated through both statistical testing and investment simulations. The results show that the hybrid approach outperforms both the standalone SV and LSTM models and contributes to the development of volatility modelling techniques, providing a foundation for improving risk assessment and strategic investment planning in the context of the S and P 500.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "q-fin.PM"
    ],
    "primary_category": "q-fin.TR",
    "comment": "32 pages, 15 tables, 11 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.12250v1",
    "published_date": "2025-12-13 09:21:43 UTC",
    "updated_date": "2025-12-13 09:21:43 UTC"
  },
  {
    "arxiv_id": "2512.12245v1",
    "title": "Adversarially Probing Cross-Family Sound Symbolism in 27 Languages",
    "authors": [
      "Anika Sharma",
      "Tianyi Niu",
      "Emma Wrenn",
      "Shashank Srivastava"
    ],
    "abstract": "The phenomenon of sound symbolism, the non-arbitrary mapping between word sounds and meanings, has long been demonstrated through anecdotal experiments like Bouba Kiki, but rarely tested at scale. We present the first computational cross-linguistic analysis of sound symbolism in the semantic domain of size. We compile a typologically broad dataset of 810 adjectives (27 languages, 30 words each), each phonemically transcribed and validated with native-speaker audio. Using interpretable classifiers over bag-of-segment features, we find that phonological form predicts size semantics above chance even across unrelated languages, with both vowels and consonants contributing. To probe universality beyond genealogy, we train an adversarial scrubber that suppresses language identity while preserving size signal (also at family granularity). Language prediction averaged across languages and settings falls below chance while size prediction remains significantly above chance, indicating cross-family sound-symbolic bias. We release data, code, and diagnostic tools for future large-scale studies of iconicity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12245v1",
    "published_date": "2025-12-13 09:06:50 UTC",
    "updated_date": "2025-12-13 09:06:50 UTC"
  },
  {
    "arxiv_id": "2512.12238v1",
    "title": "Semantic Distance Measurement based on Multi-Kernel Gaussian Processes",
    "authors": [
      "Yinzhu Cheng",
      "Haihua Xie",
      "Yaqing Wang",
      "Miao He",
      "Mingming Sun"
    ],
    "abstract": "Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining Matérn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12238v1",
    "published_date": "2025-12-13 08:34:00 UTC",
    "updated_date": "2025-12-13 08:34:00 UTC"
  },
  {
    "arxiv_id": "2512.15773v1",
    "title": "TS-DP: Reinforcement Speculative Decoding For Temporal Adaptive Diffusion Policy Acceleration",
    "authors": [
      "Ye Li",
      "Jiahe Feng",
      "Yuan Meng",
      "Kangye Ji",
      "Chen Tang",
      "Xinwan Wen",
      "Shutao Xia",
      "Zhi Wang",
      "Wenwu Zhu"
    ],
    "abstract": "Diffusion Policy (DP) excels in embodied control but suffers from high inference latency and computational cost due to multiple iterative denoising steps. The temporal complexity of embodied tasks demands a dynamic and adaptable computation mode. Static and lossy acceleration methods, such as quantization, fail to handle such dynamic embodied tasks, while speculative decoding offers a lossless and adaptive yet underexplored alternative for DP. However, it is non-trivial to address the following challenges: how to match the base model's denoising quality at lower cost under time-varying task difficulty in embodied settings, and how to dynamically and interactively adjust computation based on task difficulty in such environments. In this paper, we propose Temporal-aware Reinforcement-based Speculative Diffusion Policy (TS-DP), the first framework that enables speculative decoding for DP with temporal adaptivity. First, to handle dynamic environments where task difficulty varies over time, we distill a Transformer-based drafter to imitate the base model and replace its costly denoising calls. Second, an RL-based scheduler further adapts to time-varying task difficulty by adjusting speculative parameters to maintain accuracy while improving efficiency. Extensive experiments across diverse embodied environments demonstrate that TS-DP achieves up to 4.17 times faster inference with over 94% accepted drafts, reaching an inference frequency of 25 Hz and enabling real-time diffusion-based control without performance degradation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15773v1",
    "published_date": "2025-12-13 07:53:14 UTC",
    "updated_date": "2025-12-13 07:53:14 UTC"
  },
  {
    "arxiv_id": "2512.17943v1",
    "title": "NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction",
    "authors": [
      "Karthik Prabhakar"
    ],
    "abstract": "Nystagmus patients with photosensitivity face significant daily challenges due to involuntary eye movements exacerbated by environmental brightness conditions. Current assistive solutions are limited to symptomatic treatments without predictive personalization. This paper proposes NystagmusNet, an AI-driven system that predicts high-risk visual environments and recommends real-time visual adaptations. Using a dual-branch convolutional neural network trained on synthetic and augmented datasets, the system estimates a photosensitivity risk score based on environmental brightness and eye movement variance. The model achieves 75% validation accuracy on synthetic data. Explainability techniques including SHAP and GradCAM are integrated to highlight environmental risk zones, improving clinical trust and model interpretability. The system includes a rule-based recommendation engine for adaptive filter suggestions. Future directions include deployment via smart glasses and reinforcement learning for personalized recommendations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 7 figures, 2 tables, code available at https://github.com/knkarthik01/nystagmus-photosensitivity-ai",
    "pdf_url": "https://arxiv.org/pdf/2512.17943v1",
    "published_date": "2025-12-13 07:40:42 UTC",
    "updated_date": "2025-12-13 07:40:42 UTC"
  },
  {
    "arxiv_id": "2512.12225v2",
    "title": "A Geometric Theory of Cognition",
    "authors": [
      "Laha Ale"
    ],
    "abstract": "Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12225v2",
    "published_date": "2025-12-13 07:39:53 UTC",
    "updated_date": "2025-12-31 16:33:03 UTC"
  },
  {
    "arxiv_id": "2512.12222v1",
    "title": "Comparison of different segmentation algorithms on brain volume and fractal dimension in infant brain MRIs",
    "authors": [
      "Nathalie Alexander",
      "Arnaud Gucciardi",
      "Umberto Michelucci"
    ],
    "abstract": "Accurate segmentation of infant brain MRI is essential for quantifying developmental changes in structure and complexity. However, ongoing myelination and reduced tissue contrast make automated segmentation particularly challenging. This study systematically compared segmentation accuracy and its impact on volumetric and fractal dimension (FD) estimates in infant brain MRI using the Baby Open Brains (BOB) dataset (71 scans, 1-9 months). Two methods, SynthSeg and SamSeg, were evaluated against expert annotations using Dice, Intersection over Union, 95th-percentile Hausdorff distance, and Normalised Mutual Information. SynthSeg outperformed SamSeg across all quality metrics (mean Dice > 0.8 for major regions) and provided volumetric estimates closely matching the manual reference (mean +4% [-28% - 71%]). SamSeg systematically overestimated ventricular and whole-brain volumes (mean +76% [-12% - 190%]). Segmentation accuracy improved with age, consistent with increasing tissue contrast during myelination. Fractal dimension a(FD) nalyses revealed significant regional differences between SynthSeg and expert segmentations, and Bland-Altman limits of agreement indicated that segmentation-related FD variability exceeded most group differences reported in developmental cohorts. Volume and FD deviations were positively correlated across structures, indicating that segmentation bias directly affects FD estimation. Overall, SynthSeg provided the most reliable volumetric and FD results for paediatric MRI, yet small morphological differences in volume and FD should be interpreted with caution due to segmentation-related uncertainty.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12222v1",
    "published_date": "2025-12-13 07:23:32 UTC",
    "updated_date": "2025-12-13 07:23:32 UTC"
  },
  {
    "arxiv_id": "2512.12216v2",
    "title": "Training Versatile Coding Agents in Synthetic Environments",
    "authors": [
      "Yiqi Zhu",
      "Apurva Gandhi",
      "Graham Neubig"
    ],
    "abstract": "Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12216v2",
    "published_date": "2025-12-13 07:02:28 UTC",
    "updated_date": "2026-01-11 10:24:25 UTC"
  },
  {
    "arxiv_id": "2512.13724v1",
    "title": "Graph AI generates neurological hypotheses validated in molecular, organoid, and clinical systems",
    "authors": [
      "Ayush Noori",
      "Joaquín Polonuer",
      "Katharina Meyer",
      "Bogdan Budnik",
      "Shad Morton",
      "Xinyuan Wang",
      "Sumaiya Nazeen",
      "Yingnan He",
      "Iñaki Arango",
      "Lucas Vittor",
      "Matthew Woodworth",
      "Richard C. Krolewski",
      "Michelle M. Li",
      "Ninning Liu",
      "Tushar Kamath",
      "Evan Macosko",
      "Dylan Ritter",
      "Jalwa Afroz",
      "Alexander B. H. Henderson",
      "Lorenz Studer",
      "Samuel G. Rodriques",
      "Andrew White",
      "Noa Dagan",
      "David A. Clifton",
      "George M. Church",
      "Sudeshna Das",
      "Jenny M. Tam",
      "Vikram Khurana",
      "Marinka Zitnik"
    ],
    "abstract": "Neurological diseases are the leading global cause of disability, yet most lack disease-modifying treatments. We present PROTON, a heterogeneous graph transformer that generates testable hypotheses across molecular, organoid, and clinical systems. To evaluate PROTON, we apply it to Parkinson's disease (PD), bipolar disorder (BD), and Alzheimer's disease (AD). In PD, PROTON linked genetic risk loci to genes essential for dopaminergic neuron survival and predicted pesticides toxic to patient-derived neurons, including the insecticide endosulfan, which ranked within the top 1.29% of predictions. In silico screens performed by PROTON reproduced six genome-wide $α$-synuclein experiments, including a split-ubiquitin yeast two-hybrid system (normalized enrichment score [NES] = 2.30, FDR-adjusted $p < 1 \\times 10^{-4}$), an ascorbate peroxidase proximity labeling assay (NES = 2.16, FDR $< 1 \\times 10^{-4}$), and a high-depth targeted exome sequencing study in 496 synucleinopathy patients (NES = 2.13, FDR $< 1 \\times 10^{-4}$). In BD, PROTON predicted calcitriol as a candidate drug that reversed proteomic alterations observed in cortical organoids derived from BD patients. In AD, we evaluated PROTON predictions in health records from $n = 610,524$ patients at Mass General Brigham, confirming that five PROTON-predicted drugs were associated with reduced seven-year dementia risk (minimum hazard ratio = 0.63, 95% CI: 0.53-0.75, $p < 1 \\times 10^{-7}$). PROTON generated neurological hypotheses that were evaluated across molecular, organoid, and clinical systems, defining a path for AI-driven discovery in neurological disease.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13724v1",
    "published_date": "2025-12-13 06:55:20 UTC",
    "updated_date": "2025-12-13 06:55:20 UTC"
  },
  {
    "arxiv_id": "2512.12211v1",
    "title": "Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving",
    "authors": [
      "Longchao Da",
      "David Isele",
      "Hua Wei",
      "Manish Saroya"
    ],
    "abstract": "Being able to anticipate the motion of surrounding agents is essential for the safe operation of autonomous driving systems in dynamic situations. While various methods have been proposed for trajectory prediction, the current evaluation practices still rely on error-based metrics (e.g., ADE, FDE), which reveal the accuracy from a post-hoc view but ignore the actual effect the predictor brings to the self-driving vehicles (SDVs), especially in complex interactive scenarios: a high-quality predictor not only chases accuracy, but should also captures all possible directions a neighbor agent might move, to support the SDVs' cautious decision-making. Given that the existing metrics hardly account for this standard, in our work, we propose a comprehensive pipeline that adaptively evaluates the predictor's performance by two dimensions: accuracy and diversity. Based on the criticality of the driving scenario, these two dimensions are dynamically combined and result in a final score for the predictor's performance. Extensive experiments on a closed-loop benchmark using real-world datasets show that our pipeline yields a more reasonable evaluation than traditional metrics by better reflecting the correlation of the predictors' evaluation with the autonomous vehicles' driving performance. This evaluation pipeline shows a robust way to select a predictor that potentially contributes most to the SDV's driving performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "9 Pages, 8 Figures",
    "pdf_url": "https://arxiv.org/pdf/2512.12211v1",
    "published_date": "2025-12-13 06:48:32 UTC",
    "updated_date": "2025-12-13 06:48:32 UTC"
  },
  {
    "arxiv_id": "2512.12207v1",
    "title": "Not All Transparency Is Equal: Source Presentation Effects on Attention, Interaction, and Persuasion in Conversational Search",
    "authors": [
      "Jiangen He",
      "Jiqun Liu"
    ],
    "abstract": "Conversational search systems increasingly provide source citations, yet how citation or source presentation formats influence user engagement remains unclear. We conducted a crowdsourcing user experiment with 394 participants comparing four source presentation designs that varied citation visibility and accessibility: collapsible lists, hover cards, footer lists, and aligned sidebars.High-visibility interfaces generated substantially more hovering on sources, though clicking remained infrequent across all conditions. While interface design showed limited effects on user experience and perception measures, it significantly influenced knowledge, interest, and agreement changes. High-visibility interfaces initially reduced knowledge gain and interest, but these positive effects emerged with increasing source usage. The sidebar condition uniquely increased agreement change. Our findings demonstrate that source presentation alone may not enhance engagement and can even reduce it when insufficient sources are provided.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "CHIIR 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.12207v1",
    "published_date": "2025-12-13 06:39:45 UTC",
    "updated_date": "2025-12-13 06:39:45 UTC"
  },
  {
    "arxiv_id": "2512.12206v1",
    "title": "ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB",
    "authors": [
      "Jeongjun Park",
      "Sunwook Hwang",
      "Hyeonho Noh",
      "Jin Mo Yang",
      "Hyun Jong Yang",
      "Saewoong Bahk"
    ],
    "abstract": "Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.\n  This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.\n  Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12206v1",
    "published_date": "2025-12-13 06:33:02 UTC",
    "updated_date": "2025-12-13 06:33:02 UTC"
  },
  {
    "arxiv_id": "2512.12201v1",
    "title": "Epistemoverse: Toward an AI-Driven Knowledge Metaverse for Intellectual Heritage Preservation",
    "authors": [
      "Predrag K. Nikolić",
      "Robert Prentner"
    ],
    "abstract": "Large language models (LLMs) have often been characterized as \"stochastic parrots\" that merely reproduce fragments of their training data. This study challenges that assumption by demonstrating that, when placed in an appropriate dialogical context, LLMs can develop emergent conceptual structures and exhibit interaction-driven (re-)structuring of cognitive interfaces and reflective question-asking. Drawing on the biological principle of cloning and Socrates' maieutic method, we analyze authentic philosophical debates generated among AI-reincarnated philosophers within the interactive art installations of the Syntropic Counterpoints project. By engaging digital counterparts of Aristotle, Nietzsche, Machiavelli, and Sun Tzu in iterative discourse, the study reveals how machine dialogue can give rise to inferential coherence, reflective questioning, and creative synthesis. Based on these findings, we propose the concept of the Epistemoverse--a metaverse of knowledge where human and machine cognition intersect to preserve, reinterpret, and extend intellectual heritage through AI-driven interaction. This framework positions virtual and immersive environments as new spaces for epistemic exchange, digital heritage, and collaborative creativity.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "7 pages, 7 figures, presented at SIGGRAPH VRCAI 25",
    "pdf_url": "https://arxiv.org/pdf/2512.12201v1",
    "published_date": "2025-12-13 06:18:50 UTC",
    "updated_date": "2025-12-13 06:18:50 UTC"
  },
  {
    "arxiv_id": "2512.12199v1",
    "title": "Thermal RGB Fusion for Micro-UAV Wildfire Perimeter Tracking with Minimal Comms",
    "authors": [
      "Ercan Erkalkan",
      "Vedat Topuz",
      "Ayça Ak"
    ],
    "abstract": "This study introduces a lightweight perimeter tracking method designed for micro UAV teams operating over wildfire environments under limited bandwidth conditions. Thermal image frames generate coarse hot region masks through adaptive thresholding and morphological refinement, while RGB frames contribute edge cues and suppress texture related false detections using gradient based filtering. A rule level merging strategy selects boundary candidates and simplifies them via the Ramer Douglas Peucker algorithm. The system incorporates periodic beacons and an inertial feedback loop that maintains trajectory stability in the presence of GPS degradation. The guidance loop targets sub 50 ms latency on embedded System on Chip (SoC) platforms by constraining per frame pixel operations and precomputing gradient tables. Small scale simulations demonstrate reductions in average path length and boundary jitter compared to a pure edge tracking baseline, while maintaining environmental coverage measured through intersection merge analysis. Battery consumption and computational utilization confirm the feasibility of achieving 10, 15 m/s forward motion on standard micro platforms. This approach enables rapid deployment in the field, requiring robust sensing and minimal communications for emergency reconnaissance applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Conference paper in 17th International Scientific Studies Congress proceedings. Topic: thermal+RGB rule level fusion, RDP boundary simplification, leader follower guidance, sub 50ms embedded SoC, minimal communications for wildfire perimeter tracking. Thermal RGB Fusion for Micro-UAV",
    "pdf_url": "https://arxiv.org/pdf/2512.12199v1",
    "published_date": "2025-12-13 06:08:28 UTC",
    "updated_date": "2025-12-13 06:08:28 UTC"
  },
  {
    "arxiv_id": "2512.17941v1",
    "title": "Accelerated Digital Twin Learning for Edge AI: A Comparison of FPGA and Mobile GPU",
    "authors": [
      "Bin Xu",
      "Ayan Banerjee",
      "Midhat Urooj",
      "Sandeep K. S. Gupta"
    ],
    "abstract": "Digital twins (DTs) can enable precision healthcare by continually learning a mathematical representation of patient-specific dynamics. However, mission critical healthcare applications require fast, resource-efficient DT learning, which is often infeasible with existing model recovery (MR) techniques due to their reliance on iterative solvers and high compute/memory demands. In this paper, we present a general DT learning framework that is amenable to acceleration on reconfigurable hardware such as FPGAs, enabling substantial speedup and energy efficiency. We compare our FPGA-based implementation with a multi-processing implementation in mobile GPU, which is a popular choice for AI in edge devices. Further, we compare both edge AI implementations with cloud GPU baseline. Specifically, our FPGA implementation achieves an 8.8x improvement in \\text{performance-per-watt} for the MR task, a 28.5x reduction in DRAM footprint, and a 1.67x runtime speedup compared to cloud GPU baselines. On the other hand, mobile GPU achieves 2x better performance per watts but has 2x increase in runtime and 10x more DRAM footprint than FPGA. We show the usage of this technique in DT guided synthetic data generation for Type 1 Diabetes and proactive coronary artery disease detection.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.17941v1",
    "published_date": "2025-12-13 05:51:26 UTC",
    "updated_date": "2025-12-13 05:51:26 UTC"
  },
  {
    "arxiv_id": "2512.12182v1",
    "title": "TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion",
    "authors": [
      "Xinyu Gao"
    ],
    "abstract": "Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12182v1",
    "published_date": "2025-12-13 05:04:59 UTC",
    "updated_date": "2025-12-13 05:04:59 UTC"
  },
  {
    "arxiv_id": "2512.12177v1",
    "title": "Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation",
    "authors": [
      "Aydin Ayanzadeh",
      "Tim Oates"
    ],
    "abstract": "Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in the proceedings of the IEEE International Conference on Big Data (IEEE BigData 2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.12177v1",
    "published_date": "2025-12-13 04:49:26 UTC",
    "updated_date": "2025-12-13 04:49:26 UTC"
  },
  {
    "arxiv_id": "2512.12175v1",
    "title": "Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective",
    "authors": [
      "Haoyang Chen",
      "Richong Zhang",
      "Junfan Chen"
    ],
    "abstract": "Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12175v1",
    "published_date": "2025-12-13 04:41:31 UTC",
    "updated_date": "2025-12-13 04:41:31 UTC"
  },
  {
    "arxiv_id": "2512.12168v1",
    "title": "Diffusion Language Model Inference with Monte Carlo Tree Search",
    "authors": [
      "Zheng Huang",
      "Kiran Ramnath",
      "Yueyan Chen",
      "Aosong Feng",
      "Sangmin Woo",
      "Balasubramaniam Srinivasan",
      "Zhichao Xu",
      "Kang Zhou",
      "Shuai Wang",
      "Haibo Ding",
      "Lin Lee Cheong"
    ],
    "abstract": "Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12168v1",
    "published_date": "2025-12-13 04:30:02 UTC",
    "updated_date": "2025-12-13 04:30:02 UTC"
  },
  {
    "arxiv_id": "2512.12167v1",
    "title": "Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings",
    "authors": [
      "Yoav Gelberg",
      "Koshi Eguchi",
      "Takuya Akiba",
      "Edoardo Cetin"
    ],
    "abstract": "So far, expensive finetuning beyond the pretraining sequence length has been a requirement for effectively extending the context of language models (LM). In this work, we break this key bottleneck by Dropping the Positional Embeddings of LMs after training (DroPE). Our simple method is motivated by three key theoretical and empirical observations. First, positional embeddings (PEs) serve a crucial role during pretraining, providing an important inductive bias that significantly facilitates convergence. Second, over-reliance on this explicit positional information is also precisely what prevents test-time generalization to sequences of unseen length, even when using popular PE-scaling methods. Third, positional embeddings are not an inherent requirement of effective language modeling and can be safely removed after pretraining, following a short recalibration phase. Empirically, DroPE yields seamless zero-shot context extension without any long-context finetuning, quickly adapting pretrained LMs without compromising their capabilities in the original training context. Our findings hold across different models and dataset sizes, far outperforming previous specialized architectures and established rotary positional embedding scaling methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12167v1",
    "published_date": "2025-12-13 04:23:47 UTC",
    "updated_date": "2025-12-13 04:23:47 UTC"
  },
  {
    "arxiv_id": "2512.13723v1",
    "title": "Made-in China, Thinking in America:U.S. Values Persist in Chinese LLMs",
    "authors": [
      "David Haslett",
      "Linus Ta-Lun Huang",
      "Leila Khalatbari",
      "Janet Hui-wen Hsiao",
      "Antoni B. Chan"
    ],
    "abstract": "As large language models increasingly mediate access to information and facilitate decision-making, they are becoming instruments in soft power competitions between global actors such as the United States and China. So far, language models seem to be aligned with the values of Western countries, but evidence for this ethical bias comes mostly from models made by American companies. The current crop of state-of-the-art models includes several made in China, so we conducted the first large-scale investigation of how models made in China and the USA align with people from China and the USA. We elicited responses to the Moral Foundations Questionnaire 2.0 and the World Values Survey from ten Chinese models and ten American models, and we compared their responses to responses from thousands of Chinese and American people. We found that all models respond to both surveys more like American people than like Chinese people. This skew toward American values is only slightly mitigated when prompting the models in Chinese or imposing a Chinese persona on the models. These findings have important implications for a near future in which large language models generate much of the content people consume and shape normative influence in geopolitics.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13723v1",
    "published_date": "2025-12-13 02:52:57 UTC",
    "updated_date": "2025-12-13 02:52:57 UTC"
  },
  {
    "arxiv_id": "2512.12142v1",
    "title": "MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater",
    "authors": [
      "Björn Lütjens",
      "Patrick Alexander",
      "Raf Antwerpen",
      "Til Widmann",
      "Guido Cervone",
      "Marco Tedesco"
    ],
    "abstract": "The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolution by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as \"ground truth\", we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a gridded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at $\\href{https://github.com/blutjens/hrmelt}{github.com/blutjens/hrmelt}$.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "physics.ao-ph",
      "physics.data-an"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12142v1",
    "published_date": "2025-12-13 02:43:05 UTC",
    "updated_date": "2025-12-13 02:43:05 UTC"
  },
  {
    "arxiv_id": "2512.15771v2",
    "title": "TENG++: Time-Evolving Natural Gradient for Solving PDEs With Deep Neural Nets under General Boundary Conditions",
    "authors": [
      "Xinjie He",
      "Chenggong Zhang"
    ],
    "abstract": "Partial Differential Equations (PDEs) are central to modeling complex systems across physical, biological, and engineering domains, yet traditional numerical methods often struggle with high-dimensional or complex problems. Physics-Informed Neural Networks (PINNs) have emerged as an efficient alternative by embedding physics-based constraints into deep learning frameworks, but they face challenges in achieving high accuracy and handling complex boundary conditions. In this work, we extend the Time-Evolving Natural Gradient (TENG) framework to address Dirichlet boundary conditions, integrating natural gradient optimization with numerical time-stepping schemes, including Euler and Heun methods, to ensure both stability and accuracy. By incorporating boundary condition penalty terms into the loss function, the proposed approach enables precise enforcement of Dirichlet constraints. Experiments on the heat equation demonstrate the superior accuracy of the Heun method due to its second-order corrections and the computational efficiency of the Euler method for simpler scenarios. This work establishes a foundation for extending the framework to Neumann and mixed boundary conditions, as well as broader classes of PDEs, advancing the applicability of neural network-based solvers for real-world problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.NA",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.15771v2",
    "published_date": "2025-12-13 02:32:45 UTC",
    "updated_date": "2025-12-27 00:18:22 UTC"
  },
  {
    "arxiv_id": "2512.12135v1",
    "title": "BaRISTA: Brain Scale Informed Spatiotemporal Representation of Human Intracranial Neural Activity",
    "authors": [
      "Lucine L. Oganesian",
      "Saba Hashemi",
      "Maryam M. Shanechi"
    ],
    "abstract": "Intracranial recordings have opened a unique opportunity to simultaneously measure activity across multiregional networks in the human brain. Recent works have focused on developing transformer-based neurofoundation models of such recordings that can generalize across subjects and datasets. However, these recordings exhibit highly complex spatiotemporal interactions across diverse spatial scales, from the single-channel scale to the scale of brain regions. As such, there remain critical open questions regarding how best to encode spatial information and how to design self-supervision tasks that enable the learning of brain network patterns and enhance downstream decoding performance using such high-dimensional, multiregional recordings. To allow for exploring these questions, we propose a new spatiotemporal transformer model of multiregional neural activity and a corresponding self-supervised masked latent reconstruction task, designed to enable flexibility in the spatial scale used for token encoding and masking. Applying this model on publicly available multiregional intracranial electrophysiology (iEEG) data, we demonstrate that adjusting the spatial scale for both token encoding and masked reconstruction significantly impacts downstream decoding. Further, we find that spatial encoding at larger scales than channel-level encoding, which is commonly used in existing iEEG transformer models, improves downstream decoding performance. Finally, we demonstrate that our method allows for region-level token encoding while also maintaining accurate channel-level neural reconstruction. Taken together, our modeling framework enables exploration of the spatial scales used for token encoding and masking, reveals their importance towards self-supervised pretraining of neurofoundation models of multiregional human brain activity, and enhances downstream decoding performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 39th Annual Conference on Neural Information Processing Systems (NeurIPS 2025). Code available at https://github.com/ShanechiLab/BaRISTA",
    "pdf_url": "https://arxiv.org/pdf/2512.12135v1",
    "published_date": "2025-12-13 02:19:33 UTC",
    "updated_date": "2025-12-13 02:19:33 UTC"
  },
  {
    "arxiv_id": "2512.12128v1",
    "title": "A Benchmark Dataset for Spatially Aligned Road Damage Assessment in Small Uncrewed Aerial Systems Disaster Imagery",
    "authors": [
      "Thomas Manzini",
      "Priyankari Perali",
      "Raisa Karnik",
      "Robin R. Murphy"
    ],
    "abstract": "This paper presents the largest known benchmark dataset for road damage assessment and road alignment, and provides 18 baseline models trained on the CRASAR-U-DRIODs dataset's post-disaster small uncrewed aerial systems (sUAS) imagery from 10 federally declared disasters, addressing three challenges within prior post-disaster road damage assessment datasets. While prior disaster road damage assessment datasets exist, there is no current state of practice, as prior public datasets have either been small-scale or reliant on low-resolution imagery insufficient for detecting phenomena of interest to emergency managers. Further, while machine learning (ML) systems have been developed for this task previously, none are known to have been operationally validated. These limitations are overcome in this work through the labeling of 657.25km of roads according to a 10-class labeling schema, followed by training and deploying ML models during the operational response to Hurricanes Debby and Helene in 2024. Motivated by observed road line misalignment in practice, 9,184 road line adjustments were provided for spatial alignment of a priori road lines, as it was found that when the 18 baseline models are deployed against real-world misaligned road lines, model performance degraded on average by 5.596\\% Macro IoU. If spatial alignment is not considered, approximately 8\\% (11km) of adverse conditions on road lines will be labeled incorrectly, with approximately 9\\% (59km) of road lines misaligned off the actual road. These dynamics are gaps that should be addressed by the ML, CV, and robotics communities to enable more effective and informed decision-making during disasters.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures, 6 tables. To appear AAAI'26",
    "pdf_url": "https://arxiv.org/pdf/2512.12128v1",
    "published_date": "2025-12-13 01:42:49 UTC",
    "updated_date": "2025-12-13 01:42:49 UTC"
  },
  {
    "arxiv_id": "2512.12121v1",
    "title": "MixtureKit: A General Framework for Composing, Training, and Visualizing Mixture-of-Experts Models",
    "authors": [
      "Ahmad Chamma",
      "Omar El Herraoui",
      "Guokan Shang"
    ],
    "abstract": "We introduce MixtureKit, a modular open-source framework for constructing, training, and analyzing Mixture-of-Experts (MoE) models from arbitrary pre-trained or fine-tuned models. MixtureKit currently supports three complementary methods: (i) \\emph{Traditional MoE}, which uses a single router per transformer block to select experts, (ii) \\emph{BTX} (Branch-Train-Mix), which introduces separate routers for each specified sub-layer enabling fine-grained token routing, and (iii) \\emph{BTS} (Branch-Train-Stitch), which keeps experts fully intact and introduces trainable stitch layers for controlled information exchange between hub and experts. MixtureKit automatically modifies the model configuration, patches decoder and causal LM classes, and saves a unified checkpoint ready for inference or fine-tuning. We further provide a visualization interface to inspect per-token routing decisions, expert weight distributions, and layer-wise contributions. Experiments with multilingual code-switched data (e.g. Arabic-Latin) show that a BTX-based model trained using MixtureKit can outperform baseline dense models on multiple benchmarks. We release MixtureKit as a practical foundation for research and development of MoE-based systems across diverse domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.12121v1",
    "published_date": "2025-12-13 01:22:10 UTC",
    "updated_date": "2025-12-13 01:22:10 UTC"
  },
  {
    "arxiv_id": "2512.12109v2",
    "title": "A Neuro-Symbolic Framework for Accountability in Public-Sector AI",
    "authors": [
      "Allen Daniel Sunny"
    ],
    "abstract": "Automated eligibility systems increasingly determine access to essential public benefits, but the explanations they generate often fail to reflect the legal rules that authorize those decisions. This thesis develops a legally grounded explainability framework that links system-generated decision justifications to the statutory constraints of CalFresh, California's Supplemental Nutrition Assistance Program. The framework combines a structured ontology of eligibility requirements derived from the state's Manual of Policies and Procedures (MPP), a rule extraction pipeline that expresses statutory logic in a verifiable formal representation, and a solver-based reasoning layer to evaluate whether the explanation aligns with governing law. Case evaluations demonstrate the framework's ability to detect legally inconsistent explanations, highlight violated eligibility rules, and support procedural accountability by making the basis of automated determinations traceable and contestable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CY",
    "comment": "Master's thesis, University of Maryland, College Park (2025)",
    "pdf_url": "https://arxiv.org/pdf/2512.12109v2",
    "published_date": "2025-12-13 00:53:26 UTC",
    "updated_date": "2025-12-16 22:41:53 UTC"
  }
]