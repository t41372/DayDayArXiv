[
  {
    "arxiv_id": "2501.06965v1",
    "title": "Kolmogorov-Arnold Recurrent Network for Short Term Load Forecasting Across Diverse Consumers",
    "authors": [
      "Muhammad Umair Danish",
      "Katarina Grolinger"
    ],
    "abstract": "Load forecasting plays a crucial role in energy management, directly\nimpacting grid stability, operational efficiency, cost reduction, and\nenvironmental sustainability. Traditional Vanilla Recurrent Neural Networks\n(RNNs) face issues such as vanishing and exploding gradients, whereas\nsophisticated RNNs such as LSTMs have shown considerable success in this\ndomain. However, these models often struggle to accurately capture complex and\nsudden variations in energy consumption, and their applicability is typically\nlimited to specific consumer types, such as offices or schools. To address\nthese challenges, this paper proposes the Kolmogorov-Arnold Recurrent Network\n(KARN), a novel load forecasting approach that combines the flexibility of\nKolmogorov-Arnold Networks with RNN's temporal modeling capabilities. KARN\nutilizes learnable temporal spline functions and edge-based activations to\nbetter model non-linear relationships in load data, making it adaptable across\na diverse range of consumer types. The proposed KARN model was rigorously\nevaluated on a variety of real-world datasets, including student residences,\ndetached homes, a home with electric vehicle charging, a townhouse, and\nindustrial buildings. Across all these consumer categories, KARN consistently\noutperformed traditional Vanilla RNNs, while it surpassed LSTM and Gated\nRecurrent Units (GRUs) in six buildings. The results demonstrate KARN's\nsuperior accuracy and applicability, making it a promising tool for enhancing\nload forecasting in diverse energy management scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06965v1",
    "published_date": "2025-01-12 22:49:41 UTC",
    "updated_date": "2025-01-12 22:49:41 UTC"
  },
  {
    "arxiv_id": "2501.06964v1",
    "title": "Enhancing Patient-Centric Communication: Leveraging LLMs to Simulate Patient Perspectives",
    "authors": [
      "Xinyao Ma",
      "Rui Zhu",
      "Zihao Wang",
      "Jingwei Xiong",
      "Qingyu Chen",
      "Haixu Tang",
      "L. Jean Camp",
      "Lucila Ohno-Machado"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in\nrole-playing scenarios, particularly in simulating domain-specific experts\nusing tailored prompts. This ability enables LLMs to adopt the persona of\nindividuals with specific backgrounds, offering a cost-effective and efficient\nalternative to traditional, resource-intensive user studies. By mimicking human\nbehavior, LLMs can anticipate responses based on concrete demographic or\nprofessional profiles. In this paper, we evaluate the effectiveness of LLMs in\nsimulating individuals with diverse backgrounds and analyze the consistency of\nthese simulated behaviors compared to real-world outcomes. In particular, we\nexplore the potential of LLMs to interpret and respond to discharge summaries\nprovided to patients leaving the Intensive Care Unit (ICU). We evaluate and\ncompare with human responses the comprehensibility of discharge summaries among\nindividuals with varying educational backgrounds, using this analysis to assess\nthe strengths and limitations of LLM-driven simulations. Notably, when LLMs are\nprimed with educational background information, they deliver accurate and\nactionable medical guidance 88% of the time. However, when other information is\nprovided, performance significantly drops, falling below random chance levels.\nThis preliminary study shows the potential benefits and pitfalls of\nautomatically generating patient-specific health information from diverse\npopulations. While LLMs show promise in simulating health personas, our results\nhighlight critical gaps that must be addressed before they can be reliably used\nin clinical settings. Our findings suggest that a straightforward\nquery-response model could outperform a more tailored approach in delivering\nhealth information. This is a crucial first step in understanding how LLMs can\nbe optimized for personalized health communication while maintaining accuracy.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06964v1",
    "published_date": "2025-01-12 22:49:32 UTC",
    "updated_date": "2025-01-12 22:49:32 UTC"
  },
  {
    "arxiv_id": "2501.06963v1",
    "title": "Generative Artificial Intelligence-Supported Pentesting: A Comparison between Claude Opus, GPT-4, and Copilot",
    "authors": [
      "Antonio López Martínez",
      "Alejandro Cano",
      "Antonio Ruiz-Martínez"
    ],
    "abstract": "The advent of Generative Artificial Intelligence (GenAI) has brought a\nsignificant change to our society. GenAI can be applied across numerous fields,\nwith particular relevance in cybersecurity. Among the various areas of\napplication, its use in penetration testing (pentesting) or ethical hacking\nprocesses is of special interest. In this paper, we have analyzed the potential\nof leading generic-purpose GenAI tools-Claude Opus, GPT-4 from ChatGPT, and\nCopilot-in augmenting the penetration testing process as defined by the\nPenetration Testing Execution Standard (PTES). Our analysis involved evaluating\neach tool across all PTES phases within a controlled virtualized environment.\nThe findings reveal that, while these tools cannot fully automate the\npentesting process, they provide substantial support by enhancing efficiency\nand effectiveness in specific tasks. Notably, all tools demonstrated utility;\nhowever, Claude Opus consistently outperformed the others in our experimental\nscenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06963v1",
    "published_date": "2025-01-12 22:48:37 UTC",
    "updated_date": "2025-01-12 22:48:37 UTC"
  },
  {
    "arxiv_id": "2501.06962v1",
    "title": "Compact Bayesian Neural Networks via pruned MCMC sampling",
    "authors": [
      "Ratneel Deo",
      "Scott Sisson",
      "Jody M. Webster",
      "Rohitash Chandra"
    ],
    "abstract": "Bayesian Neural Networks (BNNs) offer robust uncertainty quantification in\nmodel predictions, but training them presents a significant computational\nchallenge. This is mainly due to the problem of sampling multimodal posterior\ndistributions using Markov Chain Monte Carlo (MCMC) sampling and variational\ninference algorithms. Moreover, the number of model parameters scales\nexponentially with additional hidden layers, neurons, and features in the\ndataset. Typically, a significant portion of these densely connected parameters\nare redundant and pruning a neural network not only improves portability but\nalso has the potential for better generalisation capabilities. In this study,\nwe address some of the challenges by leveraging MCMC sampling with network\npruning to obtain compact probabilistic models having removed redundant\nparameters. We sample the posterior distribution of model parameters (weights\nand biases) and prune weights with low importance, resulting in a compact\nmodel. We ensure that the compact BNN retains its ability to estimate\nuncertainty via the posterior distribution while retaining the model training\nand generalisation performance accuracy by adapting post-pruning resampling. We\nevaluate the effectiveness of our MCMC pruning strategy on selected benchmark\ndatasets for regression and classification problems through empirical result\nanalysis. We also consider two coral reef drill-core lithology classification\ndatasets to test the robustness of the pruning model in complex real-world\ndatasets. We further investigate if refining compact BNN can retain any loss of\nperformance. Our results demonstrate the feasibility of training and pruning\nBNNs using MCMC whilst retaining generalisation performance with over 75%\nreduction in network size. This paves the way for developing compact BNN models\nthat provide uncertainty estimates for real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06962v1",
    "published_date": "2025-01-12 22:48:04 UTC",
    "updated_date": "2025-01-12 22:48:04 UTC"
  },
  {
    "arxiv_id": "2501.06956v1",
    "title": "Patent Novelty Assessment Accelerating Innovation and Patent Prosecution",
    "authors": [
      "Kapil Kashyap",
      "Sean Fargose",
      "Gandhar Dhonde",
      "Aditya Mishra"
    ],
    "abstract": "In the rapidly evolving landscape of technological innovation, safeguarding\nintellectual property rights through patents is crucial for fostering progress\nand stimulating research and development investments. This report introduces a\nground-breaking Patent Novelty Assessment and Claim Generation System,\nmeticulously crafted to dissect the inventive aspects of intellectual property\nand simplify access to extensive patent claim data. Addressing a crucial gap in\nacademic institutions, our system provides college students and researchers\nwith an intuitive platform to navigate and grasp the intricacies of patent\nclaims, particularly tailored for the nuances of Chinese patents. Unlike\nconventional analysis systems, our initiative harnesses a proprietary Chinese\nAPI to ensure unparalleled precision and relevance. The primary challenge lies\nin the complexity of accessing and comprehending diverse patent claims,\ninhibiting effective innovation upon existing ideas. Our solution aims to\novercome these barriers by offering a bespoke approach that seamlessly\nretrieves comprehensive claim information, finely tuned to the specifics of the\nChinese patent landscape. By equipping users with efficient access to\ncomprehensive patent claim information, our transformative platform seeks to\nignite informed exploration and innovation in the ever-evolving domain of\nintellectual property. Its envisioned impact transcends individual colleges,\nnurturing an environment conducive to research and development while deepening\nthe understanding of patented concepts within the academic community.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06956v1",
    "published_date": "2025-01-12 22:25:46 UTC",
    "updated_date": "2025-01-12 22:25:46 UTC"
  },
  {
    "arxiv_id": "2501.06948v1",
    "title": "The Einstein Test: Towards a Practical Test of a Machine's Ability to Exhibit Superintelligence",
    "authors": [
      "David Benrimoh",
      "Nace Mikus",
      "Ariel Rosenfeld"
    ],
    "abstract": "Creative and disruptive insights (CDIs), such as the development of the\ntheory of relativity, have punctuated human history, marking pivotal shifts in\nour intellectual trajectory. Recent advancements in artificial intelligence\n(AI) have sparked debates over whether state of the art models possess the\ncapacity to generate CDIs. We argue that the ability to create CDIs should be\nregarded as a significant feature of machine superintelligence (SI).To this\nend, we propose a practical test to evaluate whether an approach to AI\ntargeting SI can yield novel insights of this kind. We propose the Einstein\ntest: given the data available prior to the emergence of a known CDI, can an AI\nindependently reproduce that insight (or one that is formally equivalent)? By\nachieving such a milestone, a machine can be considered to at least match\nhumanity's past top intellectual achievements, and therefore to have the\npotential to surpass them.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06948v1",
    "published_date": "2025-01-12 21:55:04 UTC",
    "updated_date": "2025-01-12 21:55:04 UTC"
  },
  {
    "arxiv_id": "2501.06937v1",
    "title": "An Empirical Study of Deep Reinforcement Learning in Continuing Tasks",
    "authors": [
      "Yi Wan",
      "Dmytro Korenkevych",
      "Zheqing Zhu"
    ],
    "abstract": "In reinforcement learning (RL), continuing tasks refer to tasks where the\nagent-environment interaction is ongoing and can not be broken down into\nepisodes. These tasks are suitable when environment resets are unavailable,\nagent-controlled, or predefined but where all rewards-including those beyond\nresets-are critical. These scenarios frequently occur in real-world\napplications and can not be modeled by episodic tasks. While modern deep RL\nalgorithms have been extensively studied and well understood in episodic tasks,\ntheir behavior in continuing tasks remains underexplored. To address this gap,\nwe provide an empirical study of several well-known deep RL algorithms using a\nsuite of continuing task testbeds based on Mujoco and Atari environments,\nhighlighting several key insights concerning continuing tasks. Using these\ntestbeds, we also investigate the effectiveness of a method for improving\ntemporal-difference-based RL algorithms in continuing tasks by centering\nrewards, as introduced by Naik et al. (2024). While their work primarily\nfocused on this method in conjunction with Q-learning, our results extend their\nfindings by demonstrating that this method is effective across a broader range\nof algorithms, scales to larger tasks, and outperforms two other\nreward-centering approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06937v1",
    "published_date": "2025-01-12 21:24:27 UTC",
    "updated_date": "2025-01-12 21:24:27 UTC"
  },
  {
    "arxiv_id": "2501.06929v1",
    "title": "Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic",
    "authors": [
      "Tapio Pitkäranta"
    ],
    "abstract": "Today a four-year-old child who does not know how to read or write can now\ncreate bedtime stories with graphical illustrations and narrated audio, using\nAI tools that seamlessly transform speech into text, generate visuals, and\nconvert text back into speech in a natural and engaging manner. This remarkable\nexample demonstrates why we are living in the age of AI applications. This\npaper examines contemporary leading AI applications and traces their historical\ndevelopment, highlighting the major advancements that have enabled their\nrealization. Five key factors are identified: 1) The evolution of computational\nhardware (CPUs and GPUs), enabling the training of complex AI models 2) The\nvast digital archives provided by the World Wide Web, which serve as a\nfoundational data resource for AI systems 3) The ubiquity of mobile computing,\nwith smartphones acting as powerful, accessible small computers in the hands of\nbillions 4) The rise of industrial-scale cloud infrastructures, offering\nelastic computational power for AI training and deployment 5) Breakthroughs in\nAI research, including neural networks, backpropagation, and the \"Attention is\nAll You Need\" framework, which underpin modern AI capabilities. These\ninnovations have elevated AI from solving narrow tasks to enabling applications\nlike ChatGPT that are adaptable for numerous use cases, redefining\nhuman-computer interaction. By situating these developments within a historical\ncontext, the paper highlights the critical milestones that have made AI's\ncurrent capabilities both possible and widely accessible, offering profound\nimplications for society.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06929v1",
    "published_date": "2025-01-12 20:50:24 UTC",
    "updated_date": "2025-01-12 20:50:24 UTC"
  },
  {
    "arxiv_id": "2501.06911v1",
    "title": "Risk-Averse Finetuning of Large Language Models",
    "authors": [
      "Sapana Chaudhary",
      "Ujwal Dinesha",
      "Dileep Kalathil",
      "Srinivas Shakkottai"
    ],
    "abstract": "We consider the challenge of mitigating the generation of negative or toxic\ncontent by the Large Language Models (LLMs) in response to certain prompts. We\npropose integrating risk-averse principles into LLM fine-tuning to minimize the\noccurrence of harmful outputs, particularly rare but significant events. By\noptimizing the risk measure of Conditional Value at Risk (CVaR), our\nmethodology trains LLMs to exhibit superior performance in avoiding toxic\noutputs while maintaining effectiveness in generative tasks. Empirical\nevaluations on sentiment modification and toxicity mitigation tasks demonstrate\nthe efficacy of risk-averse reinforcement learning with human feedback (RLHF)\nin promoting a safer and more constructive online discourse environment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.06911v1",
    "published_date": "2025-01-12 19:48:21 UTC",
    "updated_date": "2025-01-12 19:48:21 UTC"
  },
  {
    "arxiv_id": "2501.06887v1",
    "title": "MedGrad E-CLIP: Enhancing Trust and Transparency in AI-Driven Skin Lesion Diagnosis",
    "authors": [
      "Sadia Kamal",
      "Tim Oates"
    ],
    "abstract": "As deep learning models gain attraction in medical data, ensuring transparent\nand trustworthy decision-making is essential. In skin cancer diagnosis, while\nadvancements in lesion detection and classification have improved accuracy, the\nblack-box nature of these methods poses challenges in understanding their\ndecision processes, leading to trust issues among physicians. This study\nleverages the CLIP (Contrastive Language-Image Pretraining) model, trained on\ndifferent skin lesion datasets, to capture meaningful relationships between\nvisual features and diagnostic criteria terms. To further enhance transparency,\nwe propose a method called MedGrad E-CLIP, which builds on gradient-based\nE-CLIP by incorporating a weighted entropy mechanism designed for complex\nmedical imaging like skin lesions. This approach highlights critical image\nregions linked to specific diagnostic descriptions. The developed integrated\npipeline not only classifies skin lesions by matching corresponding\ndescriptions but also adds an essential layer of explainability developed\nespecially for medical data. By visually explaining how different features in\nan image relates to diagnostic criteria, this approach demonstrates the\npotential of advanced vision-language models in medical image analysis,\nultimately improving transparency, robustness, and trust in AI-driven\ndiagnostic systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision Workshops (WACVW)",
    "pdf_url": "http://arxiv.org/pdf/2501.06887v1",
    "published_date": "2025-01-12 17:50:47 UTC",
    "updated_date": "2025-01-12 17:50:47 UTC"
  },
  {
    "arxiv_id": "2501.06879v1",
    "title": "Defect Detection Network In PCB Circuit Devices Based on GAN Enhanced YOLOv11",
    "authors": [
      "Jiayi Huang",
      "Feiyun Zhao",
      "Lieyang Chen"
    ],
    "abstract": "This study proposes an advanced method for surface defect detection in\nprinted circuit boards (PCBs) using an improved YOLOv11 model enhanced with a\ngenerative adversarial network (GAN). The approach focuses on identifying six\ncommon defect types: missing hole, rat bite, open circuit, short circuit, burr,\nand virtual welding. By employing GAN to generate synthetic defect images, the\ndataset is augmented with diverse and realistic patterns, improving the model's\nability to generalize, particularly for complex and infrequent defects like\nburrs. The enhanced YOLOv11 model is evaluated on a PCB defect dataset,\ndemonstrating significant improvements in accuracy, recall, and robustness,\nespecially when dealing with defects in complex environments or small targets.\nThis research contributes to the broader field of electronic design automation\n(EDA), where efficient defect detection is a crucial step in ensuring\nhigh-quality PCB manufacturing. By integrating advanced deep learning\ntechniques, this approach enhances the automation and precision of defect\ndetection, reducing reliance on manual inspection and accelerating\ndesign-to-production workflows. The findings underscore the importance of\nincorporating GAN-based data augmentation and optimized detection architectures\nin EDA processes, providing valuable insights for improving reliability and\nefficiency in PCB defect detection within industrial applications.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06879v1",
    "published_date": "2025-01-12 17:26:24 UTC",
    "updated_date": "2025-01-12 17:26:24 UTC"
  },
  {
    "arxiv_id": "2501.06869v1",
    "title": "A Foundational Generative Model for Breast Ultrasound Image Analysis",
    "authors": [
      "Haojun Yu",
      "Youcheng Li",
      "Nan Zhang",
      "Zihan Niu",
      "Xuantong Gong",
      "Yanwen Luo",
      "Haotian Ye",
      "Siyu He",
      "Quanlin Wu",
      "Wangyan Qin",
      "Mengyuan Zhou",
      "Jie Han",
      "Jia Tao",
      "Ziwei Zhao",
      "Di Dai",
      "Di He",
      "Dong Wang",
      "Binghui Tang",
      "Ling Huo",
      "James Zou",
      "Qingli Zhu",
      "Yong Wang",
      "Liwei Wang"
    ],
    "abstract": "Foundational models have emerged as powerful tools for addressing various\ntasks in clinical settings. However, their potential development to breast\nultrasound analysis remains untapped. In this paper, we present BUSGen, the\nfirst foundational generative model specifically designed for breast ultrasound\nimage analysis. Pretrained on over 3.5 million breast ultrasound images, BUSGen\nhas acquired extensive knowledge of breast structures, pathological features,\nand clinical variations. With few-shot adaptation, BUSGen can generate\nrepositories of realistic and informative task-specific data, facilitating the\ndevelopment of models for a wide range of downstream tasks. Extensive\nexperiments highlight BUSGen's exceptional adaptability, significantly\nexceeding real-data-trained foundational models in breast cancer screening,\ndiagnosis, and prognosis. In breast cancer early diagnosis, our approach\noutperformed all board-certified radiologists (n=9), achieving an average\nsensitivity improvement of 16.5% (P-value<0.0001). Additionally, we\ncharacterized the scaling effect of using generated data which was as effective\nas the collected real-world data for training diagnostic models. Moreover,\nextensive experiments demonstrated that our approach improved the\ngeneralization ability of downstream models. Importantly, BUSGen protected\npatient privacy by enabling fully de-identified data sharing, making progress\nforward in secure medical data utilization. An online demo of BUSGen is\navailable at https://aibus.bio.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Peking University; Stanford University; Peking University Cancer\n  Hospital & Institute; Peking Union Medical College Hospital; Cancer Hospital,\n  Chinese Academy of Medical Sciences",
    "pdf_url": "http://arxiv.org/pdf/2501.06869v1",
    "published_date": "2025-01-12 16:39:13 UTC",
    "updated_date": "2025-01-12 16:39:13 UTC"
  },
  {
    "arxiv_id": "2501.06863v1",
    "title": "Transfer Learning of Tabular Data by Finetuning Large Language Models",
    "authors": [
      "Shourav B. Rabbani",
      "Ibna Kowsar",
      "Manar D. Samad"
    ],
    "abstract": "Despite the artificial intelligence (AI) revolution, deep learning has yet to\nachieve much success with tabular data due to heterogeneous feature space and\nlimited sample sizes without viable transfer learning. The new era of\ngenerative AI, powered by large language models (LLM), brings unprecedented\nlearning opportunities to diverse data and domains. This paper investigates the\neffectiveness of an LLM application programming interface (API) and transfer\nlearning of LLM in tabular data classification. LLM APIs respond to input text\nprompts with tokenized data and instructions, whereas transfer learning\nfinetunes an LLM for a target classification task. This paper proposes an\nend-to-end finetuning of LLM to demonstrate cross-data transfer learning on ten\nbenchmark data sets when large pre-trained tabular data models do not exist to\nfacilitate transfer learning. The proposed LLM finetuning method outperforms\nstate-of-the-art machine and deep learning methods on tabular data with less\nthan ten features - a standard feature size for tabular data sets. The transfer\nlearning approach uses a fraction of the computational cost of other deep\nlearning or API-based solutions while ensuring competitive or superior\nclassification performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06863v1",
    "published_date": "2025-01-12 16:23:18 UTC",
    "updated_date": "2025-01-12 16:23:18 UTC"
  },
  {
    "arxiv_id": "2501.06862v1",
    "title": "LarvSeg: Exploring Image Classification Data For Large Vocabulary Semantic Segmentation via Category-wise Attentive Classifier",
    "authors": [
      "Haojun Yu",
      "Di Dai",
      "Ziwei Zhao",
      "Di He",
      "Han Hu",
      "Liwei Wang"
    ],
    "abstract": "Scaling up the vocabulary of semantic segmentation models is extremely\nchallenging because annotating large-scale mask labels is labour-intensive and\ntime-consuming. Recently, language-guided segmentation models have been\nproposed to address this challenge. However, their performance drops\nsignificantly when applied to out-of-distribution categories. In this paper, we\npropose a new large vocabulary semantic segmentation framework, called LarvSeg.\nDifferent from previous works, LarvSeg leverages image classification data to\nscale the vocabulary of semantic segmentation models as large-vocabulary\nclassification datasets usually contain balanced categories and are much easier\nto obtain. However, for classification tasks, the category is image-level,\nwhile for segmentation we need to predict the label at pixel level. To address\nthis issue, we first propose a general baseline framework to incorporate\nimage-level supervision into the training process of a pixel-level segmentation\nmodel, making the trained network perform semantic segmentation on newly\nintroduced categories in the classification data. We then observe that a model\ntrained on segmentation data can group pixel features of categories beyond the\ntraining vocabulary. Inspired by this finding, we design a category-wise\nattentive classifier to apply supervision to the precise regions of\ncorresponding categories to improve the model performance. Extensive\nexperiments demonstrate that LarvSeg significantly improves the large\nvocabulary semantic segmentation performance, especially in the categories\nwithout mask labels. For the first time, we provide a 21K-category semantic\nsegmentation model with the help of ImageNet21K. The code is available at\nhttps://github.com/HaojunYu1998/large_voc_seg.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "PRCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.06862v1",
    "published_date": "2025-01-12 16:22:17 UTC",
    "updated_date": "2025-01-12 16:22:17 UTC"
  },
  {
    "arxiv_id": "2501.06859v1",
    "title": "A Comprehensive Evaluation of Large Language Models on Mental Illnesses in Arabic Context",
    "authors": [
      "Noureldin Zahran",
      "Aya E. Fouda",
      "Radwa J. Hanafy",
      "Mohammed E. Fouda"
    ],
    "abstract": "Mental health disorders pose a growing public health concern in the Arab\nworld, emphasizing the need for accessible diagnostic and intervention tools.\nLarge language models (LLMs) offer a promising approach, but their application\nin Arabic contexts faces challenges including limited labeled datasets,\nlinguistic complexity, and translation biases. This study comprehensively\nevaluates 8 LLMs, including general multi-lingual models, as well as bi-lingual\nones, on diverse mental health datasets (such as AraDepSu, Dreaddit, MedMCQA),\ninvestigating the impact of prompt design, language configuration (native\nArabic vs. translated English, and vice versa), and few-shot prompting on\ndiagnostic performance. We find that prompt engineering significantly\ninfluences LLM scores mainly due to reduced instruction following, with our\nstructured prompt outperforming a less structured variant on multi-class\ndatasets, with an average difference of 14.5\\%. While language influence on\nperformance was modest, model selection proved crucial: Phi-3.5 MoE excelled in\nbalanced accuracy, particularly for binary classification, while Mistral NeMo\nshowed superior performance in mean absolute error for severity prediction\ntasks. Few-shot prompting consistently improved performance, with particularly\nsubstantial gains observed for GPT-4o Mini on multi-class classification,\nboosting accuracy by an average factor of 1.58. These findings underscore the\nimportance of prompt optimization, multilingual analysis, and few-shot learning\nfor developing culturally sensitive and effective LLM-based mental health tools\nfor Arabic-speaking populations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06859v1",
    "published_date": "2025-01-12 16:17:25 UTC",
    "updated_date": "2025-01-12 16:17:25 UTC"
  },
  {
    "arxiv_id": "2501.06857v1",
    "title": "What Is a Counterfactual Cause in Action Theories?",
    "authors": [
      "Daxin Liu",
      "Vaishak Belle"
    ],
    "abstract": "Since the proposal by Halpern and Pearl, reasoning about actual causality has\ngained increasing attention in artificial intelligence, ranging from domains\nsuch as model-checking and verification to reasoning about actions and\nknowledge. More recently, Batusov and Soutchanski proposed a notion of actual\nachievement cause in the situation calculus, amongst others, they can determine\nthe cause of quantified effects in a given action history. While intuitively\nappealing, this notion of cause is not defined in a counterfactual perspective.\nIn this paper, we propose a notion of cause based on counterfactual analysis.\nIn the context of action history, we show that our notion of cause generalizes\nnaturally to a notion of achievement cause. We analyze the relationship between\nour notion of the achievement cause and the achievement cause by Batusov and\nSoutchanski. Finally, we relate our account of cause to Halpern and Pearl's\naccount of actual causality. Particularly, we note some nuances in applying a\ncounterfactual viewpoint to disjunctive goals, a common thorn to definitions of\nactual causes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This is an extended report of our short paper accepted at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06857v1",
    "published_date": "2025-01-12 16:15:12 UTC",
    "updated_date": "2025-01-12 16:15:12 UTC"
  },
  {
    "arxiv_id": "2501.09029v1",
    "title": "Enhancing Data Integrity through Provenance Tracking in Semantic Web Frameworks",
    "authors": [
      "Nilesh Jain"
    ],
    "abstract": "This paper explores the integration of provenance tracking systems within the\ncontext of Semantic Web technologies to enhance data integrity in diverse\noperational environments. SURROUND Australia Pty Ltd demonstrates innovative\napplica-tions of the PROV Data Model (PROV-DM) and its Semantic Web variant,\nPROV-O, to systematically record and manage provenance information across\nmultiple data processing domains. By employing RDF and Knowledge Graphs,\nSURROUND ad-dresses the critical challenges of shared entity identification and\nprovenance granularity. The paper highlights the company's architecture for\ncapturing comprehensive provenance data, en-abling robust validation,\ntraceability, and knowledge inference. Through the examination of two projects,\nwe illustrate how provenance mechanisms not only improve data reliability but\nalso facilitate seamless integration across heterogeneous systems. Our findings\nunderscore the importance of sophisticated provenance solutions in maintaining\ndata integrity, serving as a reference for industry peers and academics engaged\nin provenance research and implementation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68T30, 68T35, 68P15: Covers knowledge representation, Semantic Web\n  applications, and database theory for provenance tracking and data integrity"
    ],
    "primary_category": "cs.CR",
    "comment": "This 10-page manuscript with 5 figures focuses on leveraging Semantic\n  Web frameworks to enhance data integrity through provenance tracking.\n  Intended for conference submission, it aligns with the cs.AI category,\n  addressing knowledge representation, data modeling, and uncertainty in AI\n  using advanced tools like PROV-DM and PROV-O",
    "pdf_url": "http://arxiv.org/pdf/2501.09029v1",
    "published_date": "2025-01-12 16:13:27 UTC",
    "updated_date": "2025-01-12 16:13:27 UTC"
  },
  {
    "arxiv_id": "2501.06842v2",
    "title": "SPAM: Spike-Aware Adam with Momentum Reset for Stable LLM Training",
    "authors": [
      "Tianjin Huang",
      "Ziquan Zhu",
      "Gaojie Jin",
      "Lu Liu",
      "Zhangyang Wang",
      "Shiwei Liu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance across\ndiverse tasks, yet their training remains highly resource-intensive and\nsusceptible to critical challenges such as training instability. A predominant\nsource of this instability stems from gradient and loss spikes, which disrupt\nthe learning process, often leading to costly interventions like checkpoint\nrecovery and experiment restarts, further amplifying inefficiencies. This paper\npresents a comprehensive investigation into gradient spikes observed during LLM\ntraining, revealing their prevalence across multiple architectures and\ndatasets. Our analysis shows that these spikes can be up to $1000\\times$ larger\nthan typical gradients, substantially deteriorating model performance. To\naddress this issue, we propose Spike-Aware Adam with Momentum Reset SPAM, a\nnovel optimizer designed to counteract gradient spikes through momentum reset\nand spike-aware gradient clipping. Extensive experiments, including both\npre-training and fine-tuning, demonstrate that SPAM consistently surpasses Adam\nand its variants across various tasks, including (1) LLM pre-training from 60M\nto 1B, (2) 4-bit LLM pre-training,(3) reinforcement learning, and (4) Time\nSeries Forecasting. Additionally, SPAM facilitates memory-efficient training by\nenabling sparse momentum, where only a subset of momentum terms are maintained\nand updated. When operating under memory constraints, SPAM outperforms\nstate-of-the-art memory-efficient optimizers such as GaLore and Adam-Mini. Our\nwork underscores the importance of mitigating gradient spikes in LLM training\nand introduces an effective optimization strategy that enhances both training\nstability and resource efficiency at scale. Code is available at\nhttps://github.com/TianjinYellow/SPAM-Optimizer.git",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06842v2",
    "published_date": "2025-01-12 15:21:22 UTC",
    "updated_date": "2025-02-28 15:15:31 UTC"
  },
  {
    "arxiv_id": "2501.06837v1",
    "title": "An efficient approach to represent enterprise web application structure using Large Language Model in the service of Intelligent Quality Engineering",
    "authors": [
      "Zaber Al Hassan Ayon",
      "Gulam Husain",
      "Roshankumar Bisoi",
      "Waliur Rahman",
      "Dr Tom Osborn"
    ],
    "abstract": "This paper presents a novel approach to represent enterprise web application\nstructures using Large Language Models (LLMs) to enable intelligent quality\nengineering at scale. We introduce a hierarchical representation methodology\nthat optimizes the few-shot learning capabilities of LLMs while preserving the\ncomplex relationships and interactions within web applications. The approach\nencompasses five key phases: comprehensive DOM analysis, multi-page synthesis,\ntest suite generation, execution, and result analysis. Our methodology\naddresses existing challenges around usage of Generative AI techniques in\nautomated software testing by developing a structured format that enables LLMs\nto understand web application architecture through in-context learning. We\nevaluated our approach using two distinct web applications: an e-commerce\nplatform (Swag Labs) and a healthcare application (MediBox) which is deployed\nwithin Atalgo engineering environment. The results demonstrate success rates of\n90\\% and 70\\%, respectively, in achieving automated testing, with high\nrelevance scores for test cases across multiple evaluation criteria. The\nfindings suggest that our representation approach significantly enhances LLMs'\nability to generate contextually relevant test cases and provide better quality\nassurance overall, while reducing the time and effort required for testing.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 1 figure and 4 tables, relevant for Gen AI and enterprise\n  AI use cases",
    "pdf_url": "http://arxiv.org/pdf/2501.06837v1",
    "published_date": "2025-01-12 15:10:57 UTC",
    "updated_date": "2025-01-12 15:10:57 UTC"
  },
  {
    "arxiv_id": "2501.06834v1",
    "title": "LLMs Model Non-WEIRD Populations: Experiments with Synthetic Cultural Agents",
    "authors": [
      "Augusto Gonzalez-Bonorino",
      "Monica Capra",
      "Emilio Pantoja"
    ],
    "abstract": "Despite its importance, studying economic behavior across diverse, non-WEIRD\n(Western, Educated, Industrialized, Rich, and Democratic) populations presents\nsignificant challenges. We address this issue by introducing a novel\nmethodology that uses Large Language Models (LLMs) to create synthetic cultural\nagents (SCAs) representing these populations. We subject these SCAs to classic\nbehavioral experiments, including the dictator and ultimatum games. Our results\ndemonstrate substantial cross-cultural variability in experimental behavior.\nNotably, for populations with available data, SCAs' behaviors qualitatively\nresemble those of real human subjects. For unstudied populations, our method\ncan generate novel, testable hypotheses about economic behavior. By integrating\nAI into experimental economics, this approach offers an effective and ethical\nmethod to pilot experiments and refine protocols for hard-to-reach populations.\nOur study provides a new tool for cross-cultural economic studies and\ndemonstrates how LLMs can help experimental behavioral research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06834v1",
    "published_date": "2025-01-12 15:06:28 UTC",
    "updated_date": "2025-01-12 15:06:28 UTC"
  },
  {
    "arxiv_id": "2501.06831v1",
    "title": "Towards Counterfactual and Contrastive Explainability and Transparency of DCNN Image Classifiers",
    "authors": [
      "Syed Ali Tariq",
      "Tehseen Zia",
      "Mubeen Ghafoor"
    ],
    "abstract": "Explainability of deep convolutional neural networks (DCNNs) is an important\nresearch topic that tries to uncover the reasons behind a DCNN model's\ndecisions and improve their understanding and reliability in high-risk\nenvironments. In this regard, we propose a novel method for generating\ninterpretable counterfactual and contrastive explanations for DCNN models. The\nproposed method is model intrusive that probes the internal workings of a DCNN\ninstead of altering the input image to generate explanations. Given an input\nimage, we provide contrastive explanations by identifying the most important\nfilters in the DCNN representing features and concepts that separate the\nmodel's decision between classifying the image to the original inferred class\nor some other specified alter class. On the other hand, we provide\ncounterfactual explanations by specifying the minimal changes necessary in such\nfilters so that a contrastive output is obtained.\n  Using these identified filters and concepts, our method can provide\ncontrastive and counterfactual reasons behind a model's decisions and makes the\nmodel more transparent. One of the interesting applications of this method is\nmisclassification analysis, where we compare the identified concepts from a\nparticular input image and compare them with class-specific concepts to\nestablish the validity of the model's decisions. The proposed method is\ncompared with state-of-the-art and evaluated on the Caltech-UCSD Birds (CUB)\n2011 dataset to show the usefulness of the explanations provided.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06831v1",
    "published_date": "2025-01-12 14:54:02 UTC",
    "updated_date": "2025-01-12 14:54:02 UTC"
  },
  {
    "arxiv_id": "2501.06827v1",
    "title": "Leveraging Taxonomy and LLMs for Improved Multimodal Hierarchical Classification",
    "authors": [
      "Shijing Chen",
      "Mohamed Reda Bouadjenek",
      "Shoaib Jameel",
      "Usman Naseem",
      "Basem Suleiman",
      "Flora D. Salim",
      "Hakim Hacid",
      "Imran Razzak"
    ],
    "abstract": "Multi-level Hierarchical Classification (MLHC) tackles the challenge of\ncategorizing items within a complex, multi-layered class structure. However,\ntraditional MLHC classifiers often rely on a backbone model with independent\noutput layers, which tend to ignore the hierarchical relationships between\nclasses. This oversight can lead to inconsistent predictions that violate the\nunderlying taxonomy. Leveraging Large Language Models (LLMs), we propose a\nnovel taxonomy-embedded transitional LLM-agnostic framework for multimodality\nclassification. The cornerstone of this advancement is the ability of models to\nenforce consistency across hierarchical levels. Our evaluations on the MEP-3M\ndataset - a multi-modal e-commerce product dataset with various hierarchical\nlevels - demonstrated a significant performance improvement compared to\nconventional LLM structures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 7 figures, 2 tables, and accepted by COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06827v1",
    "published_date": "2025-01-12 14:43:06 UTC",
    "updated_date": "2025-01-12 14:43:06 UTC"
  },
  {
    "arxiv_id": "2501.06823v1",
    "title": "MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction",
    "authors": [
      "Yiqing Zhang",
      "Xiaozhong Liu",
      "Fabricio Murai"
    ],
    "abstract": "Clinical trials are the gold standard for assessing the effectiveness and\nsafety of drugs for treating diseases. Given the vast design space of drug\nmolecules, elevated financial cost, and multi-year timeline of these trials,\nresearch on clinical trial outcome prediction has gained immense traction.\nAccurate predictions must leverage data of diverse modes such as drug\nmolecules, target diseases, and eligibility criteria to infer successes and\nfailures. Previous Deep Learning approaches for this task, such as HINT, often\nrequire wet lab data from synthesized molecules and/or rely on prior knowledge\nto encode interactions as part of the model architecture. To address these\nlimitations, we propose a light-weight attention-based model, MEXA-CTP, to\nintegrate readily-available multi-modal data and generate effective\nrepresentations via specialized modules dubbed \"mode experts\", while avoiding\nhuman biases in model design. We optimize MEXA-CTP with the Cauchy loss to\ncapture relevant interactions across modes. Our experiments on the Trial\nOutcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon\nexisting approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC,\nand 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to\nquantify the effectiveness of each component in our proposed method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted and to be published in SDM2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06823v1",
    "published_date": "2025-01-12 14:35:31 UTC",
    "updated_date": "2025-01-12 14:35:31 UTC"
  },
  {
    "arxiv_id": "2501.06819v1",
    "title": "A Study on Educational Data Analysis and Personalized Feedback Report Generation Based on Tags and ChatGPT",
    "authors": [
      "Yizhou Zhou",
      "Mengqiao Zhang",
      "Yuan-Hao Jiang",
      "Xinyu Gao",
      "Naijie Liu",
      "Bo Jiang"
    ],
    "abstract": "This study introduces a novel method that employs tag annotation coupled with\nthe ChatGPT language model to analyze student learning behaviors and generate\npersonalized feedback. Central to this approach is the conversion of complex\nstudent data into an extensive set of tags, which are then decoded through\ntailored prompts to deliver constructive feedback that encourages rather than\ndiscourages students. This methodology focuses on accurately feeding student\ndata into large language models and crafting prompts that enhance the\nconstructive nature of feedback. The effectiveness of this approach was\nvalidated through surveys conducted with over 20 mathematics teachers, who\nconfirmed the reliability of the generated reports. This method can be\nseamlessly integrated into intelligent adaptive learning systems or provided as\na tool to significantly reduce the workload of teachers, providing accurate and\ntimely feedback to students. By transforming raw educational data into\ninterpretable tags, this method supports the provision of efficient and timely\npersonalized learning feedback that offers constructive suggestions tailored to\nindividual learner needs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06819v1",
    "published_date": "2025-01-12 14:23:17 UTC",
    "updated_date": "2025-01-12 14:23:17 UTC"
  },
  {
    "arxiv_id": "2501.06802v2",
    "title": "Unifying Two Types of Scaling Laws from the Perspective of Conditional Kolmogorov Complexity",
    "authors": [
      "Jun Wan"
    ],
    "abstract": "In 2020, OpenAI proposed the first type of Scaling Laws, describing the\nrelationships between model loss and the scale of parameters, data, and\ntraining computation. In 2024, OpenAI proposed the second type of Scaling Laws,\ndescribing the relationship between model inference performance and inference\ncomputation. In this paper, we analyze LLMs training and inference processes\nfrom the perspective of lossless compression using conditional Kolmogorov\ncomplexity, and unify these two types of Scaling Laws. We find that both types\nof Scaling Laws improve approximation of conditional Kolmogorov complexity by\nincreasing execution steps of Turing machine. The first type of Scaling Laws\nincreases execution steps by increasing number of model parameters. The second\ntype of Scaling Laws increases execution steps by increasing the number of\nintermediate tokens.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06802v2",
    "published_date": "2025-01-12 12:52:52 UTC",
    "updated_date": "2025-02-10 13:55:12 UTC"
  },
  {
    "arxiv_id": "2501.06795v1",
    "title": "Bridging the Fairness Gap: Enhancing Pre-trained Models with LLM-Generated Sentences",
    "authors": [
      "Liu Yu",
      "Ludie Guo",
      "Ping Kuang",
      "Fan Zhou"
    ],
    "abstract": "Pre-trained language models (PLMs) are trained on data that inherently\ncontains gender biases, leading to undesirable impacts. Traditional debiasing\nmethods often rely on external corpora, which may lack quality, diversity, or\ndemographic balance, affecting the effectiveness of debiasing. With the rise of\nlarge language models and their extensive knowledge, we propose enhancing\nfairness (Fair-Gender) in PLMs by absorbing coherent, attribute-balanced, and\nsemantically rich sentences. However, these sentences cannot be directly used\nfor debiasing due to alignment issues and the risk of negative transfer. We\naddress this by applying causal analysis to estimate causal effects, filtering\nout unaligned sentences, and identifying aligned ones for incorporation into\nPLMs, thereby ensuring positive transfer. Experiments show that our approach\nsignificantly reduces gender biases in PLMs while preserving their language\nexpressiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06795v1",
    "published_date": "2025-01-12 12:32:43 UTC",
    "updated_date": "2025-01-12 12:32:43 UTC"
  },
  {
    "arxiv_id": "2501.06787v3",
    "title": "Improving Pain Classification using Spatio-Temporal Deep Learning Approaches with Facial Expressions",
    "authors": [
      "Aafaf Ridouan",
      "Amine Bohi",
      "Youssef Mourchid"
    ],
    "abstract": "Pain management and severity detection are crucial for effective treatment,\nyet traditional self-reporting methods are subjective and may be unsuitable for\nnon-verbal individuals (people with limited speaking skills). To address this\nlimitation, we explore automated pain detection using facial expressions. Our\nstudy leverages deep learning techniques to improve pain assessment by\nanalyzing facial images from the Pain Emotion Faces Database (PEMF). We propose\ntwo novel approaches1: (1) a hybrid ConvNeXt model combined with Long\nShort-Term Memory (LSTM) blocks to analyze video frames and predict pain\npresence, and (2) a Spatio-Temporal Graph Convolution Network (STGCN)\nintegrated with LSTM to process landmarks from facial images for pain\ndetection. Our work represents the first use of the PEMF dataset for binary\npain classification and demonstrates the effectiveness of these models through\nextensive experimentation. The results highlight the potential of combining\nspatial and temporal features for enhanced pain detection, offering a promising\nadvancement in objective pain assessment methodologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 3 figures, 3 tables. Accepted and presented at the 18th\n  International Conference on Machine Vision (ICMV 2024), Edinburgh, UK",
    "pdf_url": "http://arxiv.org/pdf/2501.06787v3",
    "published_date": "2025-01-12 11:54:46 UTC",
    "updated_date": "2025-02-26 09:33:44 UTC"
  },
  {
    "arxiv_id": "2501.06783v2",
    "title": "Cost-Effective Robotic Handwriting System with AI Integration",
    "authors": [
      "Tianyi Huang",
      "Richard Xiong"
    ],
    "abstract": "This paper introduces a cost-effective robotic handwriting system designed to\nreplicate human-like handwriting with high precision. Combining a Raspberry Pi\nPico microcontroller, 3D-printed components, and a machine learning-based\nhandwriting generation model implemented via TensorFlow, the system converts\nuser-supplied text into realistic stroke trajectories. By leveraging\nlightweight 3D-printed materials and efficient mechanical designs, the system\nachieves a total hardware cost of approximately \\$56, significantly\nundercutting commercial alternatives. Experimental evaluations demonstrate\nhandwriting precision within $\\pm$0.3 millimeters and a writing speed of\napproximately 200 mm/min, positioning the system as a viable solution for\neducational, research, and assistive applications. This study seeks to lower\nthe barriers to personalized handwriting technologies, making them accessible\nto a broader audience.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "This is an updated version of a paper originally presented at the\n  2024 IEEE Long Island Systems, Applications and Technology Conference (LISAT)",
    "pdf_url": "http://arxiv.org/pdf/2501.06783v2",
    "published_date": "2025-01-12 11:42:28 UTC",
    "updated_date": "2025-01-14 03:16:01 UTC"
  },
  {
    "arxiv_id": "2501.06781v2",
    "title": "Eliza: A Web3 friendly AI Agent Operating System",
    "authors": [
      "Shaw Walters",
      "Sam Gao",
      "Shakker Nerd",
      "Feng Da",
      "Warren Williams",
      "Ting-Chien Meng",
      "Amie Chow",
      "Hunter Han",
      "Frank He",
      "Allen Zhang",
      "Ming Wu",
      "Timothy Shen",
      "Maxwell Hu",
      "Jerry Yan"
    ],
    "abstract": "AI Agent, powered by large language models (LLMs) as its cognitive core, is\nan intelligent agentic system capable of autonomously controlling and\ndetermining the execution paths under user's instructions. With the burst of\ncapabilities of LLMs and various plugins, such as RAG, text-to-image/video/3D,\netc., the potential of AI Agents has been vastly expanded, with their\ncapabilities growing stronger by the day. However, at the intersection between\nAI and web3, there is currently no ideal agentic framework that can seamlessly\nintegrate web3 applications into AI agent functionalities. In this paper, we\npropose Eliza, the first open-source web3-friendly Agentic framework that makes\nthe deployment of web3 applications effortless. We emphasize that every aspect\nof Eliza is a regular Typescript program under the full control of its user,\nand it seamlessly integrates with web3 (i.e., reading and writing blockchain\ndata, interacting with smart contracts, etc.). Furthermore, we show how stable\nperformance is achieved through the pragmatic implementation of the key\ncomponents of Eliza's runtime. Our code is publicly available at\nhttps://github.com/ai16z/eliza.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06781v2",
    "published_date": "2025-01-12 11:35:04 UTC",
    "updated_date": "2025-01-24 03:37:45 UTC"
  },
  {
    "arxiv_id": "2501.06766v1",
    "title": "On the Complexity of Global Necessary Reasons to Explain Classification",
    "authors": [
      "Marco Calautti",
      "Enrico Malizia",
      "Cristian Molinaro"
    ],
    "abstract": "Explainable AI has garnered considerable attention in recent years, as\nunderstanding the reasons behind decisions or predictions made by AI systems is\ncrucial for their successful adoption. Explaining classifiers' behavior is one\nprominent problem. Work in this area has proposed notions of both local and\nglobal explanations, where the former are concerned with explaining a\nclassifier's behavior for a specific instance, while the latter are concerned\nwith explaining the overall classifier's behavior regardless of any specific\ninstance. In this paper, we focus on global explanations, and explain\nclassification in terms of ``minimal'' necessary conditions for the classifier\nto assign a specific class to a generic instance. We carry out a thorough\ncomplexity analysis of the problem for natural minimality criteria and\nimportant families of classifiers considered in the literature.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06766v1",
    "published_date": "2025-01-12 10:25:14 UTC",
    "updated_date": "2025-01-12 10:25:14 UTC"
  },
  {
    "arxiv_id": "2501.06749v1",
    "title": "Static Segmentation by Tracking: A Frustratingly Label-Efficient Approach to Fine-Grained Segmentation",
    "authors": [
      "Zhenyang Feng",
      "Zihe Wang",
      "Saul Ibaven Bueno",
      "Tomasz Frelek",
      "Advikaa Ramesh",
      "Jingyan Bai",
      "Lemeng Wang",
      "Zanming Huang",
      "Jianyang Gu",
      "Jinsu Yoo",
      "Tai-Yu Pan",
      "Arpita Chowdhury",
      "Michelle Ramirez",
      "Elizabeth G. Campolongo",
      "Matthew J. Thompson",
      "Christopher G. Lawrence",
      "Sydne Record",
      "Neil Rosser",
      "Anuj Karpatne",
      "Daniel Rubenstein",
      "Hilmar Lapp",
      "Charles V. Stewart",
      "Tanya Berger-Wolf",
      "Yu Su",
      "Wei-Lun Chao"
    ],
    "abstract": "We study image segmentation in the biological domain, particularly trait and\npart segmentation from specimen images (e.g., butterfly wing stripes or beetle\nbody parts). This is a crucial, fine-grained task that aids in understanding\nthe biology of organisms. The conventional approach involves hand-labeling\nmasks, often for hundreds of images per species, and training a segmentation\nmodel to generalize these labels to other images, which can be exceedingly\nlaborious. We present a label-efficient method named Static Segmentation by\nTracking (SST). SST is built upon the insight: while specimens of the same\nspecies have inherent variations, the traits and parts we aim to segment show\nup consistently. This motivates us to concatenate specimen images into a\n``pseudo-video'' and reframe trait and part segmentation as a tracking problem.\nConcretely, SST generates masks for unlabeled images by propagating annotated\nor predicted masks from the ``pseudo-preceding'' images. Powered by Segment\nAnything Model 2 (SAM~2) initially developed for video segmentation, we show\nthat SST can achieve high-quality trait and part segmentation with merely one\nlabeled image per species -- a breakthrough for analyzing specimen images. We\nfurther develop a cycle-consistent loss to fine-tune the model, again using one\nlabeled image. Additionally, we highlight the broader potential of SST,\nincluding one-shot instance segmentation on images taken in the wild and\ntrait-based image retrieval.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06749v1",
    "published_date": "2025-01-12 08:27:14 UTC",
    "updated_date": "2025-01-12 08:27:14 UTC"
  },
  {
    "arxiv_id": "2501.08347v1",
    "title": "SCOT: Self-Supervised Contrastive Pretraining For Zero-Shot Compositional Retrieval",
    "authors": [
      "Bhavin Jawade",
      "Joao V. B. Soares",
      "Kapil Thadani",
      "Deen Dayal Mohan",
      "Amir Erfan Eshratifar",
      "Benjamin Culpepper",
      "Paloma de Juan",
      "Srirangaraj Setlur",
      "Venu Govindaraju"
    ],
    "abstract": "Compositional image retrieval (CIR) is a multimodal learning task where a\nmodel combines a query image with a user-provided text modification to retrieve\na target image. CIR finds applications in a variety of domains including\nproduct retrieval (e-commerce) and web search. Existing methods primarily focus\non fully-supervised learning, wherein models are trained on datasets of labeled\ntriplets such as FashionIQ and CIRR. This poses two significant challenges: (i)\ncurating such triplet datasets is labor intensive; and (ii) models lack\ngeneralization to unseen objects and domains. In this work, we propose SCOT\n(Self-supervised COmpositional Training), a novel zero-shot compositional\npretraining strategy that combines existing large image-text pair datasets with\nthe generative capabilities of large language models to contrastively train an\nembedding composition network. Specifically, we show that the text embedding\nfrom a large-scale contrastively-pretrained vision-language model can be\nutilized as proxy target supervision during compositional pretraining,\nreplacing the target image embedding. In zero-shot settings, this strategy\nsurpasses SOTA zero-shot compositional retrieval methods as well as many\nfully-supervised methods on standard benchmarks such as FashionIQ and CIRR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper accepted at WACV 2025 in round 1",
    "pdf_url": "http://arxiv.org/pdf/2501.08347v1",
    "published_date": "2025-01-12 07:23:49 UTC",
    "updated_date": "2025-01-12 07:23:49 UTC"
  },
  {
    "arxiv_id": "2501.06720v1",
    "title": "Multi-Label Scene Classification in Remote Sensing Benefits from Image Super-Resolution",
    "authors": [
      "Ashitha Mudraje",
      "Brian B. Moser",
      "Stanislav Frolov",
      "Andreas Dengel"
    ],
    "abstract": "Satellite imagery is a cornerstone for numerous Remote Sensing (RS)\napplications; however, limited spatial resolution frequently hinders the\nprecision of such systems, especially in multi-label scene classification tasks\nas it requires a higher level of detail and feature differentiation. In this\nstudy, we explore the efficacy of image Super-Resolution (SR) as a\npre-processing step to enhance the quality of satellite images and thus improve\ndownstream classification performance. We investigate four SR models -\nSRResNet, HAT, SeeSR, and RealESRGAN - and evaluate their impact on multi-label\nscene classification across various CNN architectures, including ResNet-50,\nResNet-101, ResNet-152, and Inception-v4. Our results show that applying SR\nsignificantly improves downstream classification performance across various\nmetrics, demonstrating its ability to preserve spatial details critical for\nmulti-label tasks. Overall, this work offers valuable insights into the\nselection of SR techniques for multi-label prediction in remote sensing and\npresents an easy-to-integrate framework to improve existing RS systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06720v1",
    "published_date": "2025-01-12 05:25:16 UTC",
    "updated_date": "2025-01-12 05:25:16 UTC"
  },
  {
    "arxiv_id": "2501.06715v1",
    "title": "ZNO-Eval: Benchmarking reasoning capabilities of large language models in Ukrainian",
    "authors": [
      "Mykyta Syromiatnikov",
      "Victoria Ruvinskaya",
      "Anastasiya Troynina"
    ],
    "abstract": "As the usage of large language models for problems outside of simple text\nunderstanding or generation increases, assessing their abilities and\nlimitations becomes crucial. While significant progress has been made in this\narea over the last few years, most research has focused on benchmarking\nEnglish, leaving other languages underexplored. This makes evaluating the\nreasoning and robustness level of language models in Ukrainian particularly\nchallenging. The purpose of this work is to establish a comprehensive benchmark\nfor the reasoning capabilities evaluation of large language models in the\nUkrainian language. This paper presents the ZNO-Eval benchmark based on real\nexam tasks from Ukraine's standardized educational testing system: the External\nIndependent Evaluation and the National Multi-subject Test. With single-answer\noptions, multiple-choice, matching, and open-ended questions from diverse\nsubjects, including Ukrainian language, mathematics, history, and geography,\nthis dataset paves the way toward a thorough analysis of reasoning capabilities\nacross different domains and complexities. Evaluation of several well-known\nlanguage models, such as GPT-3.5-Turbo, GPT-4o, GPT-4-Turbo, Mistral Large,\nClaude 3 Opus, and Gemini-1.5 Pro on this benchmark demonstrated the\nsuperiority of GPT-4o in both common knowledge reasoning and intricate language\ntasks. At the same time, Gemini Pro and GPT-4 Turbo excelled in the arithmetic\ndomain, leading in single-answer and open-ended math problems. While all models\nwere close to max performance in text-only common knowledge tasks like history\nand geography, there still is a gap for Ukrainian language and math, thus\nhighlighting the importance of developing specialized language benchmarks for\nmore accurate assessments of model capabilities and limitations across\ndifferent languages and contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 5 figures. X International conference \"Informatics. Culture.\n  Technology.\" (2024)",
    "pdf_url": "http://arxiv.org/pdf/2501.06715v1",
    "published_date": "2025-01-12 04:49:06 UTC",
    "updated_date": "2025-01-12 04:49:06 UTC"
  },
  {
    "arxiv_id": "2501.06713v3",
    "title": "MiniRAG: Towards Extremely Simple Retrieval-Augmented Generation",
    "authors": [
      "Tianyu Fan",
      "Jingyuan Wang",
      "Xubin Ren",
      "Chao Huang"
    ],
    "abstract": "The growing demand for efficient and lightweight Retrieval-Augmented\nGeneration (RAG) systems has highlighted significant challenges when deploying\nSmall Language Models (SLMs) in existing RAG frameworks. Current approaches\nface severe performance degradation due to SLMs' limited semantic understanding\nand text processing capabilities, creating barriers for widespread adoption in\nresource-constrained scenarios. To address these fundamental limitations, we\npresent MiniRAG, a novel RAG system designed for extreme simplicity and\nefficiency. MiniRAG introduces two key technical innovations: (1) a\nsemantic-aware heterogeneous graph indexing mechanism that combines text chunks\nand named entities in a unified structure, reducing reliance on complex\nsemantic understanding, and (2) a lightweight topology-enhanced retrieval\napproach that leverages graph structures for efficient knowledge discovery\nwithout requiring advanced language capabilities. Our extensive experiments\ndemonstrate that MiniRAG achieves comparable performance to LLM-based methods\neven when using SLMs while requiring only 25\\% of the storage space.\nAdditionally, we contribute a comprehensive benchmark dataset for evaluating\nlightweight RAG systems under realistic on-device scenarios with complex\nqueries. We fully open-source our implementation and datasets at:\nhttps://github.com/HKUDS/MiniRAG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06713v3",
    "published_date": "2025-01-12 04:44:06 UTC",
    "updated_date": "2025-01-26 08:17:35 UTC"
  },
  {
    "arxiv_id": "2501.06710v1",
    "title": "Multi-task Visual Grounding with Coarse-to-Fine Consistency Constraints",
    "authors": [
      "Ming Dai",
      "Jian Li",
      "Jiedong Zhuang",
      "Xian Zhang",
      "Wankou Yang"
    ],
    "abstract": "Multi-task visual grounding involves the simultaneous execution of\nlocalization and segmentation in images based on textual expressions. The\nmajority of advanced methods predominantly focus on transformer-based\nmultimodal fusion, aiming to extract robust multimodal representations.\nHowever, ambiguity between referring expression comprehension (REC) and\nreferring image segmentation (RIS) is error-prone, leading to inconsistencies\nbetween multi-task predictions. Besides, insufficient multimodal understanding\ndirectly contributes to biased target perception. To overcome these challenges,\nwe propose a Coarse-to-fine Consistency Constraints Visual Grounding\narchitecture ($\\text{C}^3\\text{VG}$), which integrates implicit and explicit\nmodeling approaches within a two-stage framework. Initially, query and pixel\ndecoders are employed to generate preliminary detection and segmentation\noutputs, a process referred to as the Rough Semantic Perception (RSP) stage.\nThese coarse predictions are subsequently refined through the proposed\nMask-guided Interaction Module (MIM) and a novel explicit bidirectional\nconsistency constraint loss to ensure consistent representations across tasks,\nwhich we term the Refined Consistency Interaction (RCI) stage. Furthermore, to\naddress the challenge of insufficient multimodal understanding, we leverage\npre-trained models based on visual-linguistic fusion representations. Empirical\nevaluations on the RefCOCO, RefCOCO+, and RefCOCOg datasets demonstrate the\nefficacy and soundness of $\\text{C}^3\\text{VG}$, which significantly\noutperforms state-of-the-art REC and RIS methods by a substantial margin. Code\nand model will be available at \\url{https://github.com/Dmmm1997/C3VG}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06710v1",
    "published_date": "2025-01-12 04:30:13 UTC",
    "updated_date": "2025-01-12 04:30:13 UTC"
  },
  {
    "arxiv_id": "2501.06708v2",
    "title": "Evaluating Sample Utility for Data Selection by Mimicking Model Weights",
    "authors": [
      "Tzu-Heng Huang",
      "Manjot Bilkhu",
      "Frederic Sala",
      "Javier Movellan"
    ],
    "abstract": "Foundation models are trained on large-scale web-crawled datasets, which\noften contain noise, biases, and irrelevant information. This motivates the use\nof data selection techniques, which can be divided into model-free variants --\nrelying on heuristic rules and downstream datasets -- and model-based, e.g.,\nusing influence functions. The former can be expensive to design and risk\nintroducing unwanted dependencies, while the latter are often computationally\nprohibitive. Instead, we propose an efficient, model-based approach using the\nMimic Score, a new data quality metric that leverages the weights of a\nreference model to assess the usefulness of individual samples for training a\nnew model. It relies on the alignment between gradients and a target direction\ninduced by the reference model. Using the derived Mimic Scores, we develop\nGrad-Mimic, a framework that prioritizes samples for learning, creates\neffective filters, and automates data selection. Empirically, using Mimic\nScores to guide training improves data efficiency, results in consistent\nperformance gains across six image datasets, and includes enhancements to CLIP\nmodels. Moreover, Mimic Score-based filters improve upon existing filtering\nmethods, e.g., cutting 4.7 million samples to train better CLIP models while\noffering accurate estimation of training dataset quality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06708v2",
    "published_date": "2025-01-12 04:28:14 UTC",
    "updated_date": "2025-02-02 18:34:01 UTC"
  },
  {
    "arxiv_id": "2501.06707v1",
    "title": "ELIZA Reanimated: The world's first chatbot restored on the world's first time sharing system",
    "authors": [
      "Rupert Lane",
      "Anthony Hay",
      "Arthur Schwarz",
      "David M. Berry",
      "Jeff Shrager"
    ],
    "abstract": "ELIZA, created by Joseph Weizenbaum at MIT in the early 1960s, is usually\nconsidered the world's first chatbot. It was developed in MAD-SLIP on MIT's\nCTSS, the world's first time-sharing system, on an IBM 7094. We discovered an\noriginal ELIZA printout in Prof. Weizenbaum's archives at MIT, including an\nearly version of the famous DOCTOR script, a nearly complete version of the\nMAD-SLIP code, and various support functions in MAD and FAP. Here we describe\nthe reanimation of this original ELIZA on a restored CTSS, itself running on an\nemulated IBM 7094. The entire stack is open source, so that any user of a\nunix-like OS can run the world's first chatbot on the world's first\ntime-sharing system.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "In review",
    "pdf_url": "http://arxiv.org/pdf/2501.06707v1",
    "published_date": "2025-01-12 04:23:34 UTC",
    "updated_date": "2025-01-12 04:23:34 UTC"
  },
  {
    "arxiv_id": "2501.06706v1",
    "title": "AIOpsLab: A Holistic Framework to Evaluate AI Agents for Enabling Autonomous Clouds",
    "authors": [
      "Yinfang Chen",
      "Manish Shetty",
      "Gagan Somashekar",
      "Minghua Ma",
      "Yogesh Simmhan",
      "Jonathan Mace",
      "Chetan Bansal",
      "Rujia Wang",
      "Saravan Rajmohan"
    ],
    "abstract": "AI for IT Operations (AIOps) aims to automate complex operational tasks, such\nas fault localization and root cause analysis, to reduce human workload and\nminimize customer impact. While traditional DevOps tools and AIOps algorithms\noften focus on addressing isolated operational tasks, recent advances in Large\nLanguage Models (LLMs) and AI agents are revolutionizing AIOps by enabling\nend-to-end and multitask automation. This paper envisions a future where AI\nagents autonomously manage operational tasks throughout the entire incident\nlifecycle, leading to self-healing cloud systems, a paradigm we term AgentOps.\nRealizing this vision requires a comprehensive framework to guide the design,\ndevelopment, and evaluation of these agents. To this end, we present AIOPSLAB,\na framework that not only deploys microservice cloud environments, injects\nfaults, generates workloads, and exports telemetry data but also orchestrates\nthese components and provides interfaces for interacting with and evaluating\nagents. We discuss the key requirements for such a holistic framework and\ndemonstrate how AIOPSLAB can facilitate the evaluation of next-generation AIOps\nagents. Through evaluations of state-of-the-art LLM agents within the benchmark\ncreated by AIOPSLAB, we provide insights into their capabilities and\nlimitations in handling complex operational tasks in cloud environments.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06706v1",
    "published_date": "2025-01-12 04:17:39 UTC",
    "updated_date": "2025-01-12 04:17:39 UTC"
  },
  {
    "arxiv_id": "2501.06704v1",
    "title": "Fine-tuning ChatGPT for Automatic Scoring of Written Scientific Explanations in Chinese",
    "authors": [
      "Jie Yang",
      "Ehsan Latif",
      "Yuze He",
      "Xiaoming Zhai"
    ],
    "abstract": "The development of explanations for scientific phenomena is essential in\nscience assessment, but scoring student-written explanations remains\nchallenging and resource-intensive. Large language models (LLMs) have shown\npromise in addressing this issue, particularly in alphabetic languages like\nEnglish. However, their applicability to logographic languages is less\nexplored. This study investigates the potential of fine-tuning ChatGPT, a\nleading LLM, to automatically score scientific explanations written in Chinese.\nStudent responses to seven scientific explanation tasks were collected and\nautomatically scored, with scoring accuracy examined in relation to reasoning\ncomplexity using the Kendall correlation. A qualitative analysis explored how\nlinguistic features influenced scoring accuracy. The results show that\ndomain-specific adaptation enables ChatGPT to score Chinese scientific\nexplanations with accuracy. However, scoring accuracy correlates with reasoning\ncomplexity: a negative correlation for lower-level responses and a positive one\nfor higher-level responses. The model overrates complex reasoning in low-level\nresponses with intricate sentence structures and underrates high-level\nresponses using concise causal reasoning. These correlations stem from\nlinguistic features--simplicity and clarity enhance accuracy for lower-level\nresponses, while comprehensiveness improves accuracy for higher-level ones.\nSimpler, shorter responses tend to score more accurately at lower levels,\nwhereas longer, information-rich responses yield better accuracy at higher\nlevels. These findings demonstrate the effectiveness of LLMs in automatic\nscoring within a Chinese context and emphasize the importance of linguistic\nfeatures and reasoning complexity in fine-tuning scoring models for educational\nassessments.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06704v1",
    "published_date": "2025-01-12 04:10:56 UTC",
    "updated_date": "2025-01-12 04:10:56 UTC"
  },
  {
    "arxiv_id": "2501.06699v1",
    "title": "Large Language Models, Knowledge Graphs and Search Engines: A Crossroads for Answering Users' Questions",
    "authors": [
      "Aidan Hogan",
      "Xin Luna Dong",
      "Denny Vrandečić",
      "Gerhard Weikum"
    ],
    "abstract": "Much has been discussed about how Large Language Models, Knowledge Graphs and\nSearch Engines can be combined in a synergistic manner. A dimension largely\nabsent from current academic discourse is the user perspective. In particular,\nthere remain many open questions regarding how best to address the diverse\ninformation needs of users, incorporating varying facets and levels of\ndifficulty. This paper introduces a taxonomy of user information needs, which\nguides us to study the pros, cons and possible synergies of Large Language\nModels, Knowledge Graphs and Search Engines. From this study, we derive a\nroadmap for future research.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.SC",
      "I.2.4; I.2.7; H.3.3"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06699v1",
    "published_date": "2025-01-12 03:32:12 UTC",
    "updated_date": "2025-01-12 03:32:12 UTC"
  },
  {
    "arxiv_id": "2501.06697v2",
    "title": "Mamba-MOC: A Multicategory Remote Object Counting via State Space Model",
    "authors": [
      "Peng Liu",
      "Sen Lei",
      "Heng-Chao Li"
    ],
    "abstract": "Multicategory remote object counting is a fundamental task in computer\nvision, aimed at accurately estimating the number of objects of various\ncategories in remote images. Existing methods rely on CNNs and Transformers,\nbut CNNs struggle to capture global dependencies, and Transformers are\ncomputationally expensive, which limits their effectiveness in remote\napplications. Recently, Mamba has emerged as a promising solution in the field\nof computer vision, offering a linear complexity for modeling global\ndependencies. To this end, we propose Mamba-MOC, a mamba-based network designed\nfor multi-category remote object counting, which represents the first\napplication of Mamba to remote sensing object counting. Specifically, we\npropose a cross-scale interaction module to facilitate the deep integration of\nhierarchical features. Then we design a context state space model to capture\nboth global and local contextual information and provide local neighborhood\ninformation during the scan process. Experimental results in large-scale\nrealistic scenarios demonstrate that our proposed method achieves\nstate-of-the-art performance compared with some mainstream counting algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06697v2",
    "published_date": "2025-01-12 03:13:54 UTC",
    "updated_date": "2025-05-18 02:59:50 UTC"
  },
  {
    "arxiv_id": "2501.06695v1",
    "title": "DVM: Towards Controllable LLM Agents in Social Deduction Games",
    "authors": [
      "Zheng Zhang",
      "Yihuai Lan",
      "Yangsen Chen",
      "Lei Wang",
      "Xiang Wang",
      "Hao Wang"
    ],
    "abstract": "Large Language Models (LLMs) have advanced the capability of game agents in\nsocial deduction games (SDGs). These games rely heavily on conversation-driven\ninteractions and require agents to infer, make decisions, and express based on\nsuch information. While this progress leads to more sophisticated and strategic\nnon-player characters (NPCs) in SDGs, there exists a need to control the\nproficiency of these agents. This control not only ensures that NPCs can adapt\nto varying difficulty levels during gameplay, but also provides insights into\nthe safety and fairness of LLM agents. In this paper, we present DVM, a novel\nframework for developing controllable LLM agents for SDGs, and demonstrate its\nimplementation on one of the most popular SDGs, Werewolf. DVM comprises three\nmain components: Predictor, Decider, and Discussor. By integrating\nreinforcement learning with a win rate-constrained decision chain reward\nmechanism, we enable agents to dynamically adjust their gameplay proficiency to\nachieve specified win rates. Experiments show that DVM not only outperforms\nexisting methods in the Werewolf game, but also successfully modulates its\nperformance levels to meet predefined win rate targets. These results pave the\nway for LLM agents' adaptive and balanced gameplay in SDGs, opening new avenues\nfor research in controllable game agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06695v1",
    "published_date": "2025-01-12 03:11:20 UTC",
    "updated_date": "2025-01-12 03:11:20 UTC"
  },
  {
    "arxiv_id": "2501.06692v1",
    "title": "PGP-SAM: Prototype-Guided Prompt Learning for Efficient Few-Shot Medical Image Segmentation",
    "authors": [
      "Zhonghao Yan",
      "Zijin Yin",
      "Tianyu Lin",
      "Xiangzhu Zeng",
      "Kongming Liang",
      "Zhanyu Ma"
    ],
    "abstract": "The Segment Anything Model (SAM) has demonstrated strong and versatile\nsegmentation capabilities, along with intuitive prompt-based interactions.\nHowever, customizing SAM for medical image segmentation requires massive\namounts of pixel-level annotations and precise point- or box-based prompt\ndesigns. To address these challenges, we introduce PGP-SAM, a novel\nprototype-based few-shot tuning approach that uses limited samples to replace\ntedious manual prompts. Our key idea is to leverage inter- and intra-class\nprototypes to capture class-specific knowledge and relationships. We propose\ntwo main components: (1) a plug-and-play contextual modulation module that\nintegrates multi-scale information, and (2) a class-guided cross-attention\nmechanism that fuses prototypes and features for automatic prompt generation.\nExperiments on a public multi-organ dataset and a private ventricle dataset\ndemonstrate that PGP-SAM achieves superior mean Dice scores compared with\nexisting prompt-free SAM variants, while using only 10\\% of the 2D slices.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 2 figures, Accepted at ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.06692v1",
    "published_date": "2025-01-12 02:57:04 UTC",
    "updated_date": "2025-01-12 02:57:04 UTC"
  },
  {
    "arxiv_id": "2501.06682v1",
    "title": "Generative AI in Education: From Foundational Insights to the Socratic Playground for Learning",
    "authors": [
      "Xiangen Hu",
      "Sheng Xu",
      "Richard Tong",
      "Art Graesser"
    ],
    "abstract": "This paper explores the synergy between human cognition and Large Language\nModels (LLMs), highlighting how generative AI can drive personalized learning\nat scale. We discuss parallels between LLMs and human cognition, emphasizing\nboth the promise and new perspectives on integrating AI systems into education.\nAfter examining challenges in aligning technology with pedagogy, we review\nAutoTutor-one of the earliest Intelligent Tutoring Systems (ITS)-and detail its\nsuccesses, limitations, and unfulfilled aspirations. We then introduce the\nSocratic Playground, a next-generation ITS that uses advanced transformer-based\nmodels to overcome AutoTutor's constraints and provide personalized, adaptive\ntutoring. To illustrate its evolving capabilities, we present a JSON-based\ntutoring prompt that systematically guides learner reflection while tracking\nmisconceptions. Throughout, we underscore the importance of placing pedagogy at\nthe forefront, ensuring that technology's power is harnessed to enhance\nteaching and learning rather than overshadow it.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06682v1",
    "published_date": "2025-01-12 01:43:39 UTC",
    "updated_date": "2025-01-12 01:43:39 UTC"
  },
  {
    "arxiv_id": "2501.06680v1",
    "title": "Application of Vision-Language Model to Pedestrians Behavior and Scene Understanding in Autonomous Driving",
    "authors": [
      "Haoxiang Gao",
      "Yu Zhao"
    ],
    "abstract": "Autonomous driving (AD) has experienced significant improvements in recent\nyears and achieved promising 3D detection, classification, and localization\nresults. However, many challenges remain, e.g. semantic understanding of\npedestrians' behaviors, and downstream handling for pedestrian interactions.\nRecent studies in applications of Large Language Models (LLM) and\nVision-Language Models (VLM) have achieved promising results in scene\nunderstanding and high-level maneuver planning in diverse traffic scenarios.\nHowever, deploying the billion-parameter LLMs to vehicles requires significant\ncomputation and memory resources. In this paper, we analyzed effective\nknowledge distillation of semantic labels to smaller Vision networks, which can\nbe used for the semantic representation of complex scenes for downstream\ndecision-making for planning and control.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06680v1",
    "published_date": "2025-01-12 01:31:07 UTC",
    "updated_date": "2025-01-12 01:31:07 UTC"
  },
  {
    "arxiv_id": "2501.06678v1",
    "title": "Imbalanced Medical Image Segmentation with Pixel-dependent Noisy Labels",
    "authors": [
      "Erjian Guo",
      "Zicheng Wang",
      "Zhen Zhao",
      "Luping Zhou"
    ],
    "abstract": "Accurate medical image segmentation is often hindered by noisy labels in\ntraining data, due to the challenges of annotating medical images. Prior\nresearch works addressing noisy labels tend to make class-dependent\nassumptions, overlooking the pixel-dependent nature of most noisy labels.\nFurthermore, existing methods typically apply fixed thresholds to filter out\nnoisy labels, risking the removal of minority classes and consequently\ndegrading segmentation performance. To bridge these gaps, our proposed\nframework, Collaborative Learning with Curriculum Selection (CLCS), addresses\npixel-dependent noisy labels with class imbalance. CLCS advances the existing\nworks by i) treating noisy labels as pixel-dependent and addressing them\nthrough a collaborative learning framework, and ii) employing a curriculum\ndynamic thresholding approach adapting to model learning progress to select\nclean data samples to mitigate the class imbalance issue, and iii) applying a\nnoise balance loss to noisy data samples to improve data utilization instead of\ndiscarding them outright. Specifically, our CLCS contains two modules:\nCurriculum Noisy Label Sample Selection (CNS) and Noise Balance Loss (NBL). In\nthe CNS module, we designed a two-branch network with discrepancy loss for\ncollaborative learning so that different feature representations of the same\ninstance could be extracted from distinct views and used to vote the class\nprobabilities of pixels. Besides, a curriculum dynamic threshold is adopted to\nselect clean-label samples through probability voting. In the NBL module,\ninstead of directly dropping the suspiciously noisy labels, we further adopt a\nrobust loss to leverage such instances to boost the performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06678v1",
    "published_date": "2025-01-12 00:59:57 UTC",
    "updated_date": "2025-01-12 00:59:57 UTC"
  }
]