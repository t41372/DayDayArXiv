[
  {
    "arxiv_id": "2503.04849v1",
    "title": "Enhancing Collective Intelligence in Large Language Models Through Emotional Integration",
    "authors": [
      "Likith Kadiyala",
      "Ramteja Sajja",
      "Yusuf Sermet",
      "Ibrahim Demir"
    ],
    "abstract": "This research investigates the integration of emotional diversity into Large\nLanguage Models (LLMs) to enhance collective intelligence. Inspired by the\nhuman wisdom of crowds phenomenon, where group decisions often outperform\nindividual judgments, we fine-tuned the DarkIdol-Llama-3.1-8B model using\nGoogle's GoEmotions dataset and Low-Rank Adaptation (LoRA) to simulate\nemotionally diverse responses. Evaluating the model on a distance estimation\ntask between Fargo, ND, and Seattle, WA, across 15,064 unique persona\nconfigurations, we analyzed how emotional states and social attributes\ninfluence decision-making. Our findings demonstrate that emotional integration\nshapes response patterns while maintaining acceptable prediction accuracy,\nrevealing its potential to enhance artificial collective intelligence. This\nstudy provides valuable insights into the interplay of emotional diversity and\ndecision-making in LLMs, suggesting pathways for creating emotionally aware AI\nsystems that balance emotional depth with analytical precision.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04849v1",
    "published_date": "2025-03-05 23:42:48 UTC",
    "updated_date": "2025-03-05 23:42:48 UTC"
  },
  {
    "arxiv_id": "2503.03965v2",
    "title": "All-atom Diffusion Transformers: Unified generative modelling of molecules and materials",
    "authors": [
      "Chaitanya K. Joshi",
      "Xiang Fu",
      "Yi-Lun Liao",
      "Vahe Gharakhanyan",
      "Benjamin Kurt Miller",
      "Anuroop Sriram",
      "Zachary W. Ulissi"
    ],
    "abstract": "Diffusion models are the standard toolkit for generative modelling of 3D\natomic systems. However, for different types of atomic systems -- such as\nmolecules and materials -- the generative processes are usually highly specific\nto the target system despite the underlying physics being the same. We\nintroduce the All-atom Diffusion Transformer (ADiT), a unified latent diffusion\nframework for jointly generating both periodic materials and non-periodic\nmolecular systems using the same model: (1) An autoencoder maps a unified,\nall-atom representations of molecules and materials to a shared latent\nembedding space; and (2) A diffusion model is trained to generate new latent\nembeddings that the autoencoder can decode to sample new molecules or\nmaterials. Experiments on MP20, QM9 and GEOM-DRUGS datasets demonstrate that\njointly trained ADiT generates realistic and valid molecules as well as\nmaterials, obtaining state-of-the-art results on par with molecule and\ncrystal-specific models. ADiT uses standard Transformers with minimal inductive\nbiases for both the autoencoder and diffusion model, resulting in significant\nspeedups during training and inference compared to equivariant diffusion\nmodels. Scaling ADiT up to half a billion parameters predictably improves\nperformance, representing a step towards broadly generalizable foundation\nmodels for generative chemistry. Open source code:\nhttps://github.com/facebookresearch/all-atom-diffusion-transformer",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03965v2",
    "published_date": "2025-03-05 23:35:44 UTC",
    "updated_date": "2025-05-22 08:08:43 UTC"
  },
  {
    "arxiv_id": "2503.03951v1",
    "title": "WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities",
    "authors": [
      "Susmita Haldar",
      "Mary Pierce",
      "Luiz Fernando Capretz"
    ],
    "abstract": "This innovative practice WIP paper describes a research study that explores\nthe integration of ChatGPT into the software testing curriculum and evaluates\nits effectiveness compared to human-generated testing artifacts. In a Capstone\nProject course, students were tasked with generating preparatory testing\nartifacts using ChatGPT prompts, which they had previously created manually.\nTheir understanding and the effectiveness of the Artificial Intelligence\ngenerated artifacts were assessed through targeted questions. The results,\ndrawn from this in-class assignment at a North American community college\nindicate that while ChatGPT can automate many testing preparation tasks, it\ncannot fully replace human expertise. However, students, already familiar with\nInformation Technology at the postgraduate level, found the integration of\nChatGPT into their workflow to be straightforward. The study suggests that AI\ncan be gradually introduced into software testing education to keep pace with\ntechnological advancements.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03951v1",
    "published_date": "2025-03-05 22:51:24 UTC",
    "updated_date": "2025-03-05 22:51:24 UTC"
  },
  {
    "arxiv_id": "2503.03947v1",
    "title": "COARSE: Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation",
    "authors": [
      "Aurelio Noca",
      "Xianmei Lei",
      "Jonathan Becktor",
      "Jeffrey Edlund",
      "Anna Sabel",
      "Patrick Spieler",
      "Curtis Padgett",
      "Alexandre Alahi",
      "Deegan Atha"
    ],
    "abstract": "Autonomous off-road navigation faces challenges due to diverse, unstructured\nenvironments, requiring robust perception with both geometric and semantic\nunderstanding. However, scarce densely labeled semantic data limits\ngeneralization across domains. Simulated data helps, but introduces domain\nadaptation issues. We propose COARSE, a semi-supervised domain adaptation\nframework for off-road semantic segmentation, leveraging sparse, coarse\nin-domain labels and densely labeled out-of-domain data. Using pretrained\nvision transformers, we bridge domain gaps with complementary pixel-level and\npatch-level decoders, enhanced by a collaborative pseudo-labeling strategy on\nunlabeled data. Evaluations on RUGD and Rellis-3D datasets show significant\nimprovements of 9.7\\% and 8.4\\% respectively, versus only using coarse data.\nTests on real-world off-road vehicle data in a multi-biome setting further\ndemonstrate COARSE's applicability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint, 8 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03947v1",
    "published_date": "2025-03-05 22:25:54 UTC",
    "updated_date": "2025-03-05 22:25:54 UTC"
  },
  {
    "arxiv_id": "2503.07641v1",
    "title": "Deep ARTMAP: Generalized Hierarchical Learning with Adaptive Resonance Theory",
    "authors": [
      "Niklas M. Melton",
      "Leonardo Enzo Brito da Silva",
      "Sasha Petrenko",
      "Donald. C. Wunsch II"
    ],
    "abstract": "This paper presents Deep ARTMAP, a novel extension of the ARTMAP architecture\nthat generalizes the self-consistent modular ART (SMART) architecture to enable\nhierarchical learning (supervised and unsupervised) across arbitrary\ntransformations of data. The Deep ARTMAP framework operates as a divisive\nclustering mechanism, supporting an arbitrary number of modules with\ncustomizable granularity within each module. Inter-ART modules regulate the\nclustering at each layer, permitting unsupervised learning while enforcing a\none-to-many mapping from clusters in one layer to the next. While Deep ARTMAP\nreduces to both ARTMAP and SMART in particular configurations, it offers\nsignificantly enhanced flexibility, accommodating a broader range of data\ntransformations and learning modalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07641v1",
    "published_date": "2025-03-05 22:23:17 UTC",
    "updated_date": "2025-03-05 22:23:17 UTC"
  },
  {
    "arxiv_id": "2503.07640v1",
    "title": "BrainNet-MoE: Brain-Inspired Mixture-of-Experts Learning for Neurological Disease Identification",
    "authors": [
      "Jing Zhang",
      "Xiaowei Yu",
      "Tong Chen",
      "Chao Cao",
      "Mingheng Chen",
      "Yan Zhuang",
      "Yanjun Lyu",
      "Lu Zhang",
      "Li Su",
      "Tianming Liu",
      "Dajiang Zhu"
    ],
    "abstract": "The Lewy body dementia (LBD) is the second most common neurodegenerative\ndementia after Alzheimer's disease (AD). Early differentiation between AD and\nLBD is crucial because they require different treatment approaches, but this is\nchallenging due to significant clinical overlap, heterogeneity, complex\npathogenesis, and the rarity of LBD. While recent advances in artificial\nintelligence (AI) demonstrate powerful learning capabilities and offer new hope\nfor accurate diagnosis, existing methods primarily focus on designing\n\"neural-level networks\". Our work represents a pioneering effort in modeling\nsystem-level artificial neural network called BrainNet-MoE for brain modeling\nand diagnosing. Inspired by the brain's hierarchical organization of bottom-up\nsensory integration and top-down control, we design a set of disease-specific\nexpert groups to process brain sub-network under different condition, A disease\ngate mechanism guides the specializa-tion of expert groups, while a transformer\nlayer enables communication be-tween all sub-networks, generating a\ncomprehensive whole-brain represen-tation for downstream disease\nclassification. Experimental results show superior classification accuracy with\ninterpretable insights into how brain sub-networks contribute to different\nneurodegenerative conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07640v1",
    "published_date": "2025-03-05 22:19:49 UTC",
    "updated_date": "2025-03-05 22:19:49 UTC"
  },
  {
    "arxiv_id": "2503.03935v1",
    "title": "GlucoLens: Explainable Postprandial Blood Glucose Prediction from Diet and Physical Activity",
    "authors": [
      "Abdullah Mamun",
      "Asiful Arefeen",
      "Susan B. Racette",
      "Dorothy D. Sears",
      "Corrie M. Whisner",
      "Matthew P. Buman",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Postprandial hyperglycemia, marked by the blood glucose level exceeding the\nnormal range after meals, is a critical indicator of progression toward type 2\ndiabetes in prediabetic and healthy individuals. A key metric for understanding\nblood glucose dynamics after eating is the postprandial area under the curve\n(PAUC). Predicting PAUC in advance based on a person's diet and activity level\nand explaining what affects postprandial blood glucose could allow an\nindividual to adjust their lifestyle accordingly to maintain normal glucose\nlevels. In this paper, we propose GlucoLens, an explainable machine learning\napproach to predict PAUC and hyperglycemia from diet, activity, and recent\nglucose patterns. We conducted a five-week user study with 10 full-time working\nindividuals to develop and evaluate the computational model. Our machine\nlearning model takes multimodal data including fasting glucose, recent glucose,\nrecent activity, and macronutrient amounts, and provides an interpretable\nprediction of the postprandial glucose pattern. Our extensive analyses of the\ncollected data revealed that the trained model achieves a normalized root mean\nsquared error (NRMSE) of 0.123. On average, GlucoLense with a Random Forest\nbackbone provides a 16% better result than the baseline models. Additionally,\nGlucoLens predicts hyperglycemia with an accuracy of 74% and recommends\ndifferent options to help avoid hyperglycemia through diverse counterfactual\nexplanations. Code available: https://github.com/ab9mamun/GlucoLens.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03935v1",
    "published_date": "2025-03-05 22:10:14 UTC",
    "updated_date": "2025-03-05 22:10:14 UTC"
  },
  {
    "arxiv_id": "2503.03927v1",
    "title": "\"Impressively Scary:\" Exploring User Perceptions and Reactions to Unraveling Machine Learning Models in Social Media Applications",
    "authors": [
      "Jack West",
      "Bengisu Cagiltay",
      "Shirley Zhang",
      "Jingjie Li",
      "Kassem Fawaz",
      "Suman Banerjee"
    ],
    "abstract": "Machine learning models deployed locally on social media applications are\nused for features, such as face filters which read faces in-real time, and they\nexpose sensitive attributes to the apps. However, the deployment of machine\nlearning models, e.g., when, where, and how they are used, in social media\napplications is opaque to users. We aim to address this inconsistency and\ninvestigate how social media user perceptions and behaviors change once exposed\nto these models. We conducted user studies (N=21) and found that participants\nwere unaware to both what the models output and when the models were used in\nInstagram and TikTok, two major social media platforms. In response to being\nexposed to the models' functionality, we observed long term behavior changes in\n8 participants. Our analysis uncovers the challenges and opportunities in\nproviding transparency for machine learning models that interact with local\nuser data.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 2 figures, to appear at CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03927v1",
    "published_date": "2025-03-05 21:51:52 UTC",
    "updated_date": "2025-03-05 21:51:52 UTC"
  },
  {
    "arxiv_id": "2503.03924v1",
    "title": "De-skilling, Cognitive Offloading, and Misplaced Responsibilities: Potential Ironies of AI-Assisted Design",
    "authors": [
      "Prakash Shukla",
      "Phuong Bui",
      "Sean S Levy",
      "Max Kowalski",
      "Ali Baigelenov",
      "Paul Parsons"
    ],
    "abstract": "The rapid adoption of generative AI (GenAI) in design has sparked discussions\nabout its benefits and unintended consequences. While AI is often framed as a\ntool for enhancing productivity by automating routine tasks, historical\nresearch on automation warns of paradoxical effects, such as de-skilling and\nmisplaced responsibilities. To assess UX practitioners' perceptions of AI, we\nanalyzed over 120 articles and discussions from UX-focused subreddits. Our\nfindings indicate that while practitioners express optimism about AI reducing\nrepetitive work and augmenting creativity, they also highlight concerns about\nover-reliance, cognitive offloading, and the erosion of critical design skills.\nDrawing from human-automation interaction literature, we discuss how these\nperspectives align with well-documented automation ironies and function\nallocation challenges. We argue that UX professionals should critically\nevaluate AI's role beyond immediate productivity gains and consider its\nlong-term implications for creative autonomy and expertise. This study\ncontributes empirical insights into practitioners' perspectives and links them\nto broader debates on automation in design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03924v1",
    "published_date": "2025-03-05 21:47:16 UTC",
    "updated_date": "2025-03-05 21:47:16 UTC"
  },
  {
    "arxiv_id": "2503.03921v1",
    "title": "CREStE: Scalable Mapless Navigation with Internet Scale Priors and Counterfactual Guidance",
    "authors": [
      "Arthur Zhang",
      "Harshit Sikchi",
      "Amy Zhang",
      "Joydeep Biswas"
    ],
    "abstract": "We address the long-horizon mapless navigation problem: enabling robots to\ntraverse novel environments without relying on high-definition maps or precise\nwaypoints that specify exactly where to navigate. Achieving this requires\novercoming two major challenges -- learning robust, generalizable perceptual\nrepresentations of the environment without pre-enumerating all possible\nnavigation factors and forms of perceptual aliasing and utilizing these learned\nrepresentations to plan human-aligned navigation paths. Existing solutions\nstruggle to generalize due to their reliance on hand-curated object lists that\noverlook unforeseen factors, end-to-end learning of navigation features from\nscarce large-scale robot datasets, and handcrafted reward functions that scale\npoorly to diverse scenarios. To overcome these limitations, we propose CREStE,\nthe first method that learns representations and rewards for addressing the\nfull mapless navigation problem without relying on large-scale robot datasets\nor manually curated features. CREStE leverages visual foundation models trained\non internet-scale data to learn continuous bird's-eye-view representations\ncapturing elevation, semantics, and instance-level features. To utilize learned\nrepresentations for planning, we propose a counterfactual-based loss and active\nlearning procedure that focuses on the most salient perceptual cues by querying\nhumans for counterfactual trajectory annotations in challenging scenes. We\nevaluate CREStE in kilometer-scale navigation tasks across six distinct urban\nenvironments. CREStE significantly outperforms all state-of-the-art approaches\nwith 70% fewer human interventions per mission, including a 2-kilometer mission\nin an unseen environment with just 1 intervention; showcasing its robustness\nand effectiveness for long-horizon mapless navigation. For videos and\nadditional materials, see https://amrl.cs.utexas.edu/creste .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "19 pages, 10 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.03921v1",
    "published_date": "2025-03-05 21:42:46 UTC",
    "updated_date": "2025-03-05 21:42:46 UTC"
  },
  {
    "arxiv_id": "2503.04847v2",
    "title": "Role of Databases in GenAI Applications",
    "authors": [
      "Santosh Bhupathi"
    ],
    "abstract": "Generative AI (GenAI) is transforming industries by enabling intelligent\ncontent generation, automation, and decision-making. However, the effectiveness\nof GenAI applications depends significantly on efficient data storage,\nretrieval, and contextual augmentation. This paper explores the critical role\nof databases in GenAI workflows, emphasizing the importance of choosing the\nright database architecture to optimize performance, accuracy, and scalability.\nIt categorizes database roles into conversational context (key-value/document\ndatabases), situational context (relational databases/data lakehouses), and\nsemantic context (vector databases) each serving a distinct function in\nenriching AI-generated responses. Additionally, the paper highlights real-time\nquery processing, vector search for semantic retrieval, and the impact of\ndatabase selection on model efficiency and scalability. By leveraging a\nmulti-database approach, GenAI applications can achieve more context-aware,\npersonalized, and high-performing AI-driven solutions.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "97P30",
      "I.2.7; H.2.5"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04847v2",
    "published_date": "2025-03-05 20:32:21 UTC",
    "updated_date": "2025-04-11 17:07:51 UTC"
  },
  {
    "arxiv_id": "2503.03866v2",
    "title": "Learning to Negotiate via Voluntary Commitment",
    "authors": [
      "Shuhui Zhu",
      "Baoxiang Wang",
      "Sriram Ganapathi Subramanian",
      "Pascal Poupart"
    ],
    "abstract": "The partial alignment and conflict of autonomous agents lead to mixed-motive\nscenarios in many real-world applications. However, agents may fail to\ncooperate in practice even when cooperation yields a better outcome. One well\nknown reason for this failure comes from non-credible commitments. To\nfacilitate commitments among agents for better cooperation, we define Markov\nCommitment Games (MCGs), a variant of commitment games, where agents can\nvoluntarily commit to their proposed future plans. Based on MCGs, we propose a\nlearnable commitment protocol via policy gradients. We further propose\nincentive-compatible learning to accelerate convergence to equilibria with\nbetter social welfare. Experimental results in challenging mixed-motive tasks\ndemonstrate faster empirical convergence and higher returns for our method\ncompared with its counterparts. Our code is available at\nhttps://github.com/shuhui-zhu/DCL.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03866v2",
    "published_date": "2025-03-05 19:55:10 UTC",
    "updated_date": "2025-03-19 07:23:37 UTC"
  },
  {
    "arxiv_id": "2503.03862v1",
    "title": "Not-Just-Scaling Laws: Towards a Better Understanding of the Downstream Impact of Language Model Design Decisions",
    "authors": [
      "Emmy Liu",
      "Amanda Bertsch",
      "Lintang Sutawika",
      "Lindia Tjuatja",
      "Patrick Fernandes",
      "Lara Marinov",
      "Michael Chen",
      "Shreya Singhal",
      "Carolin Lawrence",
      "Aditi Raghunathan",
      "Kiril Gashteovski",
      "Graham Neubig"
    ],
    "abstract": "Improvements in language model capabilities are often attributed to\nincreasing model size or training data, but in some cases smaller models\ntrained on curated data or with different architectural decisions can\noutperform larger ones trained on more tokens. What accounts for this? To\nquantify the impact of these design choices, we meta-analyze 92 open-source\npretrained models across a wide array of scales, including state-of-the-art\nopen-weights models as well as less performant models and those with less\nconventional design decisions. We find that by incorporating features besides\nmodel size and number of training tokens, we can achieve a relative 3-28%\nincrease in ability to predict downstream performance compared with using scale\nalone. Analysis of model design decisions reveal insights into data\ncomposition, such as the trade-off between language and code tasks at 15-25\\%\ncode, as well as the better performance of some architectural decisions such as\nchoosing rotary over learned embeddings. Broadly, our framework lays a\nfoundation for more systematic investigation of how model development choices\nshape final capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03862v1",
    "published_date": "2025-03-05 19:46:04 UTC",
    "updated_date": "2025-03-05 19:46:04 UTC"
  },
  {
    "arxiv_id": "2503.03842v1",
    "title": "Task-Agnostic Attacks Against Vision Foundation Models",
    "authors": [
      "Brian Pulfer",
      "Yury Belousov",
      "Vitaliy Kinakh",
      "Teddy Furon",
      "Slava Voloshynovskiy"
    ],
    "abstract": "The study of security in machine learning mainly focuses on downstream\ntask-specific attacks, where the adversarial example is obtained by optimizing\na loss function specific to the downstream task. At the same time, it has\nbecome standard practice for machine learning practitioners to adopt publicly\navailable pre-trained vision foundation models, effectively sharing a common\nbackbone architecture across a multitude of applications such as\nclassification, segmentation, depth estimation, retrieval, question-answering\nand more. The study of attacks on such foundation models and their impact to\nmultiple downstream tasks remains vastly unexplored. This work proposes a\ngeneral framework that forges task-agnostic adversarial examples by maximally\ndisrupting the feature representation obtained with foundation models. We\nextensively evaluate the security of the feature representations obtained by\npopular vision foundation models by measuring the impact of this attack on\nmultiple downstream tasks and its transferability between models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03842v1",
    "published_date": "2025-03-05 19:15:14 UTC",
    "updated_date": "2025-03-05 19:15:14 UTC"
  },
  {
    "arxiv_id": "2503.05828v1",
    "title": "Market-based Architectures in RL and Beyond",
    "authors": [
      "Abhimanyu Pallavi Sudhir",
      "Long Tran-Thanh"
    ],
    "abstract": "Market-based agents refer to reinforcement learning agents which determine\ntheir actions based on an internal market of sub-agents. We introduce a new\ntype of market-based algorithm where the state itself is factored into several\naxes called ``goods'', which allows for greater specialization and parallelism\nthan existing market-based RL algorithms. Furthermore, we argue that\nmarket-based algorithms have the potential to address many current challenges\nin AI, such as search, dynamic scaling and complete feedback, and demonstrate\nthat they may be seen to generalize neural networks; finally, we list some\nnovel ways that market algorithms may be applied in conjunction with Large\nLanguage Models for immediate practical applicability.",
    "categories": [
      "cs.AI",
      "econ.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.05828v1",
    "published_date": "2025-03-05 19:09:29 UTC",
    "updated_date": "2025-03-05 19:09:29 UTC"
  },
  {
    "arxiv_id": "2503.03750v2",
    "title": "The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems",
    "authors": [
      "Richard Ren",
      "Arunim Agarwal",
      "Mantas Mazeika",
      "Cristina Menghini",
      "Robert Vacareanu",
      "Brad Kenstler",
      "Mick Yang",
      "Isabelle Barrass",
      "Alice Gatti",
      "Xuwang Yin",
      "Eduardo Trevino",
      "Matias Geralnik",
      "Adam Khoja",
      "Dean Lee",
      "Summer Yue",
      "Dan Hendrycks"
    ],
    "abstract": "As large language models (LLMs) become more capable and agentic, the\nrequirement for trust in their outputs grows significantly, yet at the same\ntime concerns have been mounting that models may learn to lie in pursuit of\ntheir goals. To address these concerns, a body of work has emerged around the\nnotion of \"honesty\" in LLMs, along with interventions aimed at mitigating\ndeceptive behaviors. However, evaluations of honesty are currently highly\nlimited, with no benchmark combining large scale and applicability to all\nmodels. Moreover, many benchmarks claiming to measure honesty in fact simply\nmeasure accuracy--the correctness of a model's beliefs--in disguise. In this\nwork, we introduce a large-scale human-collected dataset for measuring honesty\ndirectly, allowing us to disentangle accuracy from honesty for the first time.\nAcross a diverse set of LLMs, we find that while larger models obtain higher\naccuracy on our benchmark, they do not become more honest. Surprisingly, while\nmost frontier LLMs obtain high scores on truthfulness benchmarks, we find a\nsubstantial propensity in frontier LLMs to lie when pressured to do so,\nresulting in low honesty scores on our benchmark. We find that simple methods,\nsuch as representation engineering interventions, can improve honesty. These\nresults underscore the growing need for robust evaluations and effective\ninterventions to ensure LLMs remain trustworthy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Website: https://www.mask-benchmark.ai",
    "pdf_url": "http://arxiv.org/pdf/2503.03750v2",
    "published_date": "2025-03-05 18:59:23 UTC",
    "updated_date": "2025-03-20 23:06:17 UTC"
  },
  {
    "arxiv_id": "2503.03746v1",
    "title": "Process-based Self-Rewarding Language Models",
    "authors": [
      "Shimao Zhang",
      "Xiao Liu",
      "Xin Zhang",
      "Junxiao Liu",
      "Zheheng Luo",
      "Shujian Huang",
      "Yeyun Gong"
    ],
    "abstract": "Large Language Models have demonstrated outstanding performance across\nvarious downstream tasks and have been widely applied in multiple scenarios.\nHuman-annotated preference data is used for training to further improve LLMs'\nperformance, which is constrained by the upper limit of human performance.\nTherefore, Self-Rewarding method has been proposed, where LLMs generate\ntraining data by rewarding their own outputs. However, the existing\nself-rewarding paradigm is not effective in mathematical reasoning scenarios\nand may even lead to a decline in performance. In this work, we propose the\nProcess-based Self-Rewarding pipeline for language models, which introduces\nlong-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference\noptimization within the self-rewarding paradigm. Our new paradigm successfully\nenhances the performance of LLMs on multiple mathematical reasoning benchmarks\nthrough iterative Process-based Self-Rewarding, demonstrating the immense\npotential of self-rewarding to achieve LLM reasoning that may surpass human\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03746v1",
    "published_date": "2025-03-05 18:58:44 UTC",
    "updated_date": "2025-03-05 18:58:44 UTC"
  },
  {
    "arxiv_id": "2503.03743v1",
    "title": "CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning",
    "authors": [
      "Yuqi Zhou",
      "Shuai Wang",
      "Sunhao Dai",
      "Qinglin Jia",
      "Zhaocheng Du",
      "Zhenhua Dong",
      "Jun Xu"
    ],
    "abstract": "The advancement of visual language models (VLMs) has enhanced mobile device\noperations, allowing simulated human-like actions to address user requirements.\nCurrent VLM-based mobile operating assistants can be structured into three\nlevels: task, subtask, and action. The subtask level, linking high-level goals\nwith low-level executable actions, is crucial for task completion but faces two\nchallenges: ineffective subtasks that lower-level agent cannot execute and\ninefficient subtasks that fail to contribute to the completion of the\nhigher-level task. These challenges stem from VLM's lack of experience in\ndecomposing subtasks within GUI scenarios in multi-agent architecture. To\naddress these, we propose a new mobile assistant architecture with constrained\nhigh-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's\ndeficiency in GUI scenarios planning by using human-planned subtasks as the\nbasis vector. We evaluate our architecture in both English and Chinese contexts\nacross 20 Apps, demonstrating significant improvements in both effectiveness\nand efficiency. Our dataset and code is available at\nhttps://github.com/Yuqi-Zhou/CHOP",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03743v1",
    "published_date": "2025-03-05 18:56:16 UTC",
    "updated_date": "2025-03-05 18:56:16 UTC"
  },
  {
    "arxiv_id": "2503.03802v1",
    "title": "RiskAgent: Autonomous Medical AI Copilot for Generalist Risk Prediction",
    "authors": [
      "Fenglin Liu",
      "Jinge Wu",
      "Hongjian Zhou",
      "Xiao Gu",
      "Soheila Molaei",
      "Anshul Thakur",
      "Lei Clifton",
      "Honghan Wu",
      "David A. Clifton"
    ],
    "abstract": "The application of Large Language Models (LLMs) to various clinical\napplications has attracted growing research attention. However, real-world\nclinical decision-making differs significantly from the standardized,\nexam-style scenarios commonly used in current efforts. In this paper, we\npresent the RiskAgent system to perform a broad range of medical risk\npredictions, covering over 387 risk scenarios across diverse complex diseases,\ne.g., cardiovascular disease and cancer. RiskAgent is designed to collaborate\nwith hundreds of clinical decision tools, i.e., risk calculators and scoring\nsystems that are supported by evidence-based medicine. To evaluate our method,\nwe have built the first benchmark MedRisk specialized for risk prediction,\nincluding 12,352 questions spanning 154 diseases, 86 symptoms, 50 specialties,\nand 24 organ systems. The results show that our RiskAgent, with 8 billion model\nparameters, achieves 76.33% accuracy, outperforming the most recent commercial\nLLMs, o1, o3-mini, and GPT-4.5, and doubling the 38.39% accuracy of GPT-4o. On\nrare diseases, e.g., Idiopathic Pulmonary Fibrosis (IPF), RiskAgent outperforms\no1 and GPT-4.5 by 27.27% and 45.46% accuracy, respectively. Finally, we further\nconduct a generalization evaluation on an external evidence-based diagnosis\nbenchmark and show that our RiskAgent achieves the best results. These\nencouraging results demonstrate the great potential of our solution for diverse\ndiagnosis domains. To improve the adaptability of our model in different\nscenarios, we have built and open-sourced a family of models ranging from 1\nbillion to 70 billion parameters. Our code, data, and models are all available\nat https://github.com/AI-in-Health/RiskAgent.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures, 4 tables, code is available at\n  https://github.com/AI-in-Health/RiskAgent",
    "pdf_url": "http://arxiv.org/pdf/2503.03802v1",
    "published_date": "2025-03-05 18:46:51 UTC",
    "updated_date": "2025-03-05 18:46:51 UTC"
  },
  {
    "arxiv_id": "2503.03733v1",
    "title": "Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need",
    "authors": [
      "Amal Shaheena",
      "Nairouz Mrabahb",
      "Riadh Ksantinia",
      "Abdulla Alqaddoumia"
    ],
    "abstract": "The recent advances in deep clustering have been made possible by significant\nprogress in self-supervised and pseudo-supervised learning. However, the\ntrade-off between self-supervision and pseudo-supervision can give rise to\nthree primary issues. The joint training causes Feature Randomness and Feature\nDrift, whereas the independent training causes Feature Randomness and Feature\nTwist. In essence, using pseudo-labels generates random and unreliable\nfeatures. The combination of pseudo-supervision and self-supervision drifts the\nreliable clustering-oriented features. Moreover, moving from self-supervision\nto pseudo-supervision can twist the curved latent manifolds. This paper\naddresses the limitations of existing deep clustering paradigms concerning\nFeature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm\nwith a new strategy that replaces pseudo-supervision with a second round of\nself-supervision training. The new strategy makes the transition between\ninstance-level self-supervision and neighborhood-level self-supervision\nsmoother and less abrupt. Moreover, it prevents the drifting effect that is\ncaused by the strong competition between instance-level self-supervision and\nclustering-level pseudo-supervision. Moreover, the absence of the\npseudo-supervision prevents the risk of generating random features. With this\nnovel approach, our paper introduces a Rethinking of the Deep Clustering\nParadigms, denoted by R-DC. Our model is specifically designed to address three\nprimary challenges encountered in Deep Clustering: Feature Randomness, Feature\nDrift, and Feature Twist. Experimental results conducted on six datasets have\nshown that the two-level self-supervision training yields substantial\nimprovements.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03733v1",
    "published_date": "2025-03-05 18:44:35 UTC",
    "updated_date": "2025-03-05 18:44:35 UTC"
  },
  {
    "arxiv_id": "2503.04844v4",
    "title": "Narrative Context Protocol: an Author-centric Storytelling Framework for Generative AI",
    "authors": [
      "Hank Gerba"
    ],
    "abstract": "Generative AI promises to finally realize dynamic, personalized storytelling\ntechnologies across a range of media. To date, experimentation with generative\nAI in the field of procedural narrative generation has been quite promising\nfrom a technical perspective. However, fundamental narrative dilemmas remain,\nsuch as the balance between player agency and narrative coherence, and no\nrigorous narrative standard has been proposed to specifically leverage the\nstrengths of generative AI. In this paper, we propose the Narrative Context\nProtocol (NCP), an open and extensible standard designed to place writers at\nthe center of future narrative design workflows and enable interoperability\nacross authoring platforms. By encoding an author's intent according to an\nobjective narrative model, the NCP enables narrative portability as well as\nintent-based constraints for generative systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04844v4",
    "published_date": "2025-03-05 18:29:15 UTC",
    "updated_date": "2025-04-12 18:17:10 UTC"
  },
  {
    "arxiv_id": "2503.03724v1",
    "title": "Deep Causal Behavioral Policy Learning: Applications to Healthcare",
    "authors": [
      "Jonas Knecht",
      "Anna Zink",
      "Jonathan Kolstad",
      "Maya Petersen"
    ],
    "abstract": "We present a deep learning-based approach to studying dynamic clinical\nbehavioral regimes in diverse non-randomized healthcare settings. Our proposed\nmethodology - deep causal behavioral policy learning (DC-BPL) - uses deep\nlearning algorithms to learn the distribution of high-dimensional clinical\naction paths, and identifies the causal link between these action paths and\npatient outcomes. Specifically, our approach: (1) identifies the causal effects\nof provider assignment on clinical outcomes; (2) learns the distribution of\nclinical actions a given provider would take given evolving patient\ninformation; (3) and combines these steps to identify the optimal provider for\na given patient type and emulate that provider's care decisions. Underlying\nthis strategy, we train a large clinical behavioral model (LCBM) on electronic\nhealth records data using a transformer architecture, and demonstrate its\nability to estimate clinical behavioral policies. We propose a novel\ninterpretation of a behavioral policy learned using the LCBM: that it is an\nefficient encoding of complex, often implicit, knowledge used to treat a\npatient. This allows us to learn a space of policies that are critical to a\nwide range of healthcare applications, in which the vast majority of clinical\nknowledge is acquired tacitly through years of practice and only a tiny\nfraction of information relevant to patient care is written down (e.g. in\ntextbooks, studies or standardized guidelines).",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03724v1",
    "published_date": "2025-03-05 18:24:58 UTC",
    "updated_date": "2025-03-05 18:24:58 UTC"
  },
  {
    "arxiv_id": "2503.03717v1",
    "title": "Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements",
    "authors": [
      "Carlo Dindorf",
      "Fabian Horst",
      "Djordje Slijepčević",
      "Bernhard Dumphart",
      "Jonas Dully",
      "Matthias Zeppelzauer",
      "Brian Horsak",
      "Michael Fröhlich"
    ],
    "abstract": "This chapter provides an overview of recent and promising Machine Learning\napplications, i.e. pose estimation, feature estimation, event detection, data\nexploration & clustering, and automated classification, in gait (walking and\nrunning) and sports biomechanics. It explores the potential of Machine Learning\nmethods to address challenges in biomechanical workflows, highlights central\nlimitations, i.e. data and annotation availability and explainability, that\nneed to be addressed, and emphasises the importance of interdisciplinary\napproaches for fully harnessing the potential of Machine Learning in gait and\nsports biomechanics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03717v1",
    "published_date": "2025-03-05 18:10:11 UTC",
    "updated_date": "2025-03-05 18:10:11 UTC"
  },
  {
    "arxiv_id": "2503.03708v3",
    "title": "Rethinking Video Tokenization: A Conditioned Diffusion-based Approach",
    "authors": [
      "Nianzu Yang",
      "Pandeng Li",
      "Liming Zhao",
      "Yang Li",
      "Chen-Wei Xie",
      "Yehui Tang",
      "Xudong Lu",
      "Zhihang Liu",
      "Yun Zheng",
      "Yu Liu",
      "Junchi Yan"
    ],
    "abstract": "Existing video tokenizers typically use the traditional Variational\nAutoencoder (VAE) architecture for video compression and reconstruction.\nHowever, to achieve good performance, its training process often relies on\ncomplex multi-stage training tricks that go beyond basic reconstruction loss\nand KL regularization. Among these tricks, the most challenging is the precise\ntuning of adversarial training with additional Generative Adversarial Networks\n(GANs) in the final stage, which can hinder stable convergence. In contrast to\nGANs, diffusion models offer more stable training processes and can generate\nhigher-quality results. Inspired by these advantages, we propose CDT, a novel\nConditioned Diffusion-based video Tokenizer, that replaces the GAN-based\ndecoder with a conditional causal diffusion model. The encoder compresses\nspatio-temporal information into compact latents, while the decoder\nreconstructs videos through a reverse diffusion process conditioned on these\nlatents. During inference, we incorporate a feature cache mechanism to generate\nvideos of arbitrary length while maintaining temporal continuity and adopt\nsampling acceleration technique to enhance efficiency. Trained using only a\nbasic MSE diffusion loss for reconstruction, along with KL term and LPIPS\nperceptual loss from scratch, extensive experiments demonstrate that CDT\nachieves state-of-the-art performance in video reconstruction tasks with just a\nsingle-step sampling. Even a scaled-down version of CDT (3$\\times$ inference\nspeedup) still performs comparably with top baselines. Moreover, the latent\nvideo generation model trained with CDT also exhibits superior performance. The\nsource code and pretrained weights are available at\nhttps://github.com/ali-vilab/CDT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03708v3",
    "published_date": "2025-03-05 17:59:19 UTC",
    "updated_date": "2025-03-27 11:46:22 UTC"
  },
  {
    "arxiv_id": "2503.03707v1",
    "title": "Curating Demonstrations using Online Experience",
    "authors": [
      "Annie S. Chen",
      "Alec M. Lessing",
      "Yuejiang Liu",
      "Chelsea Finn"
    ],
    "abstract": "Many robot demonstration datasets contain heterogeneous demonstrations of\nvarying quality. This heterogeneity may benefit policy pre-training, but can\nhinder robot performance when used with a final imitation learning objective.\nIn particular, some strategies in the data may be less reliable than others or\nmay be underrepresented in the data, leading to poor performance when such\nstrategies are sampled at test time. Moreover, such unreliable or\nunderrepresented strategies can be difficult even for people to discern, and\nsifting through demonstration datasets is time-consuming and costly. On the\nother hand, policy performance when trained on such demonstrations can reflect\nthe reliability of different strategies. We thus propose for robots to\nself-curate based on online robot experience (Demo-SCORE). More specifically,\nwe train and cross-validate a classifier to discern successful policy roll-outs\nfrom unsuccessful ones and use the classifier to filter heterogeneous\ndemonstration datasets. Our experiments in simulation and the real world show\nthat Demo-SCORE can effectively identify suboptimal demonstrations without\nmanual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute\nsuccess rate in the resulting policy compared to the base policy trained with\nall original demonstrations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03707v1",
    "published_date": "2025-03-05 17:58:16 UTC",
    "updated_date": "2025-03-05 17:58:16 UTC"
  },
  {
    "arxiv_id": "2503.04843v2",
    "title": "Self-Supervised Z-Slice Augmentation for 3D Bio-Imaging via Knowledge Distillation",
    "authors": [
      "Alessandro Pasqui",
      "Sajjad Mahdavi",
      "Benoit Vianay",
      "Alexandra Colin",
      "Alex McDougall",
      "Rémi Dumollard",
      "Yekaterina A. Miroshnikova",
      "Elsa Labrune",
      "Hervé Turlier"
    ],
    "abstract": "Three-dimensional biological microscopy has significantly advanced our\nunderstanding of complex biological structures. However, limitations due to\nmicroscopy techniques, sample properties or phototoxicity often result in poor\nz-resolution, hindering accurate cellular measurements. Here, we introduce\nZAugNet, a fast, accurate, and self-supervised deep learning method for\nenhancing z-resolution in biological images. By performing nonlinear\ninterpolation between consecutive slices, ZAugNet effectively doubles\nresolution with each iteration. Compared on several microscopy modalities and\nbiological objects, it outperforms competing methods on most metrics. Our\nmethod leverages a generative adversarial network (GAN) architecture combined\nwith knowledge distillation to maximize prediction speed without compromising\naccuracy. We also developed ZAugNet+, an extended version enabling continuous\ninterpolation at arbitrary distances, making it particularly useful for\ndatasets with nonuniform slice spacing. Both ZAugNet and ZAugNet+ provide\nhigh-performance, scalable z-slice augmentation solutions for large-scale 3D\nimaging. They are available as open-source frameworks in PyTorch, with an\nintuitive Colab notebook interface for easy access by the scientific community.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "q-bio.QM",
      "68",
      "I.4.3; I.4.4; I.2.0; J.3"
    ],
    "primary_category": "cs.CV",
    "comment": "25 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.04843v2",
    "published_date": "2025-03-05 17:50:35 UTC",
    "updated_date": "2025-03-17 21:52:46 UTC"
  },
  {
    "arxiv_id": "2503.03693v1",
    "title": "ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX",
    "authors": [
      "Ungsik Kim"
    ],
    "abstract": "In the field of Explainable Artificial Intelligence (XAI), argumentative XAI\napproaches have been proposed to represent the internal reasoning process of\ndeep neural networks in a more transparent way by interpreting hidden nodes as\narguements. However, as the number of layers increases, existing compression\nmethods simplify all layers at once, which lead to high accumulative\ninformation loss. To compensate for this, we propose an iterative\nlayer-by-layer compression technique in which each layer is compressed\nseparately and the reduction error in the next layer is immediately compensated\nfor, thereby improving the overall input-output and structural fidelity of the\nmodel. Experiments on the Breast Cancer Diagnosis dataset show that, compared\nto traditional compression, the method reduces input-output and structural\nunfaithfulness, and maintains a more consistent attack-support relationship in\nthe Argumentative Explanation scheme. This is significant because it provides a\nnew way to make complex MLP models more compact while still conveying their\ninternal inference logic without distortion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03693v1",
    "published_date": "2025-03-05 17:43:49 UTC",
    "updated_date": "2025-03-05 17:43:49 UTC"
  },
  {
    "arxiv_id": "2503.04842v1",
    "title": "Replicating Human Social Perception in Generative AI: Evaluating the Valence-Dominance Model",
    "authors": [
      "Necdet Gurkan",
      "Kimathi Njoki",
      "Jordan W. Suchow"
    ],
    "abstract": "As artificial intelligence (AI) continues to advance--particularly in\ngenerative models--an open question is whether these systems can replicate\nfoundational models of human social perception. A well-established framework in\nsocial cognition suggests that social judgments are organized along two primary\ndimensions: valence (e.g., trustworthiness, warmth) and dominance (e.g., power,\nassertiveness). This study examines whether multimodal generative AI systems\ncan reproduce this valence-dominance structure when evaluating facial images\nand how their representations align with those observed across world regions.\nThrough principal component analysis (PCA), we found that the extracted\ndimensions closely mirrored the theoretical structure of valence and dominance,\nwith trait loadings aligning with established definitions. However, many world\nregions and generative AI models also exhibited a third component, the nature\nand significance of which warrant further investigation. These findings\ndemonstrate that multimodal generative AI systems can replicate key aspects of\nhuman social perception, raising important questions about their implications\nfor AI-driven decision-making and human-AI interactions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04842v1",
    "published_date": "2025-03-05 17:35:18 UTC",
    "updated_date": "2025-03-05 17:35:18 UTC"
  },
  {
    "arxiv_id": "2503.03800v1",
    "title": "Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence",
    "authors": [
      "Cristian Jimenez-Romero",
      "Alper Yegenoglu",
      "Christian Blum"
    ],
    "abstract": "This work examines the integration of large language models (LLMs) into\nmulti-agent simulations by replacing the hard-coded programs of agents with\nLLM-driven prompts. The proposed approach is showcased in the context of two\nexamples of complex systems from the field of swarm intelligence: ant colony\nforaging and bird flocking. Central to this study is a toolchain that\nintegrates LLMs with the NetLogo simulation platform, leveraging its Python\nextension to enable communication with GPT-4o via the OpenAI API. This\ntoolchain facilitates prompt-driven behavior generation, allowing agents to\nrespond adaptively to environmental data. For both example applications\nmentioned above, we employ both structured, rule-based prompts and autonomous,\nknowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs\nto study self-organizing processes and induce emergent behaviors within\nmulti-agent environments, paving the way for new approaches to exploring\nintelligent systems and modeling swarm intelligence inspired by natural\nphenomena. We provide the code, including simulation files and data at\nhttps://github.com/crjimene/swarm_gpt.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.6.0; I.2.7"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03800v1",
    "published_date": "2025-03-05 17:13:27 UTC",
    "updated_date": "2025-03-05 17:13:27 UTC"
  },
  {
    "arxiv_id": "2503.03669v1",
    "title": "Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models",
    "authors": [
      "Bar Karov",
      "Dor Zohar",
      "Yam Marcovitz"
    ],
    "abstract": "We present Attentive Reasoning Queries (ARQs), a novel structured reasoning\napproach that significantly improves instruction-following in Large Language\nModels through domain-specialized reasoning blueprints. While LLMs demonstrate\nremarkable capabilities across diverse tasks, they often fail to maintain\nadherence to complex, use-case-specific instructions during multi-turn\nconversations, presenting challenges for business-critical applications. ARQs\naddress this limitation by guiding LLMs through systematic reasoning steps with\ntargeted queries that reinstate critical instructions and facilitate\nintermediate reasoning throughout the completion process. In extensive testing\nwithin Parlant, our framework for reliable customer-facing agents in which ARQs\nwere born out of necessity, they achieved a 90.2% success rate across 87 test\nscenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct\nresponse generation (81.5%). ARQs showed particular strength in addressing\npersistent failure modes like guideline re-application and hallucination\nprevention. Our analysis also revealed that ARQs can potentially be more\ncomputationally efficient than free-form reasoning when carefully designed.\nThese findings demonstrate that structured reasoning approaches provide\neffective mechanisms for controlling how LLMs process information and make\ndecisions in complex scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Supplementary materials, including code, is available on our GitHub:\n  https://github.com/emcie-co/parlant/tree/arqs-a-systematic-method-for-optimizing-instruction-following-in-llms",
    "pdf_url": "http://arxiv.org/pdf/2503.03669v1",
    "published_date": "2025-03-05 17:03:48 UTC",
    "updated_date": "2025-03-05 17:03:48 UTC"
  },
  {
    "arxiv_id": "2503.04840v1",
    "title": "Framing the Game: How Context Shapes LLM Decision-Making",
    "authors": [
      "Isaac Robinson",
      "John Burden"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly deployed across diverse\ncontexts to support decision-making. While existing evaluations effectively\nprobe latent model capabilities, they often overlook the impact of context\nframing on perceived rational decision-making. In this study, we introduce a\nnovel evaluation framework that systematically varies evaluation instances\nacross key features and procedurally generates vignettes to create highly\nvaried scenarios. By analyzing decision-making patterns across different\ncontexts with the same underlying game structure, we uncover significant\ncontextual variability in LLM responses. Our findings demonstrate that this\nvariability is largely predictable yet highly sensitive to framing effects. Our\nresults underscore the need for dynamic, context-aware evaluation methodologies\nfor real-world deployments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04840v1",
    "published_date": "2025-03-05 17:03:28 UTC",
    "updated_date": "2025-03-05 17:03:28 UTC"
  },
  {
    "arxiv_id": "2503.03664v1",
    "title": "A Generative Approach to High Fidelity 3D Reconstruction from Text Data",
    "authors": [
      "Venkat Kumar R",
      "Deepak Saravanan"
    ],
    "abstract": "The convergence of generative artificial intelligence and advanced computer\nvision technologies introduces a groundbreaking approach to transforming\ntextual descriptions into three-dimensional representations. This research\nproposes a fully automated pipeline that seamlessly integrates text-to-image\ngeneration, various image processing techniques, and deep learning methods for\nreflection removal and 3D reconstruction. By leveraging state-of-the-art\ngenerative models like Stable Diffusion, the methodology translates natural\nlanguage inputs into detailed 3D models through a multi-stage workflow.\n  The reconstruction process begins with the generation of high-quality images\nfrom textual prompts, followed by enhancement by a reinforcement learning agent\nand reflection removal using the Stable Delight model. Advanced image upscaling\nand background removal techniques are then applied to further enhance visual\nfidelity. These refined two-dimensional representations are subsequently\ntransformed into volumetric 3D models using sophisticated machine learning\nalgorithms, capturing intricate spatial relationships and geometric\ncharacteristics. This process achieves a highly structured and detailed output,\nensuring that the final 3D models reflect both semantic accuracy and geometric\nprecision.\n  This approach addresses key challenges in generative reconstruction, such as\nmaintaining semantic coherence, managing geometric complexity, and preserving\ndetailed visual information. Comprehensive experimental evaluations will assess\nreconstruction quality, semantic accuracy, and geometric fidelity across\ndiverse domains and varying levels of complexity. By demonstrating the\npotential of AI-driven 3D reconstruction techniques, this research offers\nsignificant implications for fields such as augmented reality (AR), virtual\nreality (VR), and digital content creation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03664v1",
    "published_date": "2025-03-05 16:54:15 UTC",
    "updated_date": "2025-03-05 16:54:15 UTC"
  },
  {
    "arxiv_id": "2503.03655v1",
    "title": "Improving 6D Object Pose Estimation of metallic Household and Industry Objects",
    "authors": [
      "Thomas Pöllabauer",
      "Michael Gasser",
      "Tristan Wirth",
      "Sarah Berkei",
      "Volker Knauthe",
      "Arjan Kuijper"
    ],
    "abstract": "6D object pose estimation suffers from reduced accuracy when applied to\nmetallic objects. We set out to improve the state-of-the-art by addressing\nchallenges such as reflections and specular highlights in industrial\napplications. Our novel BOP-compatible dataset, featuring a diverse set of\nmetallic objects (cans, household, and industrial items) under various lighting\nand background conditions, provides additional geometric and visual cues. We\ndemonstrate that these cues can be effectively leveraged to enhance overall\nperformance. To illustrate the usefulness of the additional features, we\nimprove upon the GDRNPP algorithm by introducing an additional keypoint\nprediction and material estimator head in order to improve spatial scene\nunderstanding. Evaluations on the new dataset show improved accuracy for\nmetallic objects, supporting the hypothesis that additional geometric and\nvisual cues can improve learning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03655v1",
    "published_date": "2025-03-05 16:35:15 UTC",
    "updated_date": "2025-03-05 16:35:15 UTC"
  },
  {
    "arxiv_id": "2503.04839v2",
    "title": "Advancing Multimodal In-Context Learning in Large Vision-Language Models with Task-aware Demonstrations",
    "authors": [
      "Yanshu Li"
    ],
    "abstract": "Multimodal in-context learning (ICL) has emerged as a key capability of Large\nVision-Language Models (LVLMs), driven by their increasing scale and\napplicability. Despite its promise, effective ICL in the multimodal setting\nremains challenging due to the inherent complexity of image-text inputs and the\nhigh sensitivity of ICL performance to input configurations. In this work, we\nshed light on the core mechanism underlying multimodal ICL, identifying task\nmapping as a crucial factor in configuring robust in-context demonstration\n(ICD) sequences. Building on these insights, we propose \\textit{SabER}, a\nlightweight yet powerful decoder-only transformer equipped with task-aware\nattention, which intelligently selects and arranges ICDs from a demonstration\nlibrary in an autoregressive fashion. This design enables fine-grained feature\nextraction and cross-modal reasoning, iteratively refining task mapping to\ngenerate high-quality ICD sequences. Through extensive experiments covering\nfive LVLMs and nine benchmark datasets, SabER not only demonstrates strong\nempirical performance, but also provides deeper understanding of how task\nsemantics interact with multimodal ICDs. Our findings highlight the importance\nof principled ICD sequence configuration and open new avenues to enhance\nmultimodal ICL in a wide range of real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICLR 2025 Workshop on Reasoning and Planning for LLMs, 25\n  pages, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.04839v2",
    "published_date": "2025-03-05 16:33:10 UTC",
    "updated_date": "2025-04-06 20:41:41 UTC"
  },
  {
    "arxiv_id": "2503.03654v1",
    "title": "Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset",
    "authors": [
      "Jessica Hoffmann",
      "Christiane Ahlheim",
      "Zac Yu",
      "Aria Walfrand",
      "Jarvis Jin",
      "Marie Tano",
      "Ahmad Beirami",
      "Erin van Liemt",
      "Nithum Thain",
      "Hakim Sidahmed",
      "Lucas Dixon"
    ],
    "abstract": "This paper describes the construction of a dataset and the evaluation of\ntraining methods to improve generative large language models' (LLMs) ability to\nanswer queries on sensitive topics with a Neutral Point of View (NPOV), i.e.,\nto provide significantly more informative, diverse and impartial answers. The\ndataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written\nquadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set\nof links to source texts elaborating the various points of view. The first key\ncontribution of this paper is a new methodology to create such datasets through\niterative rounds of human peer-critique and annotator training, which we\nrelease alongside the dataset. The second key contribution is the\nidentification of a highly effective training regime for parameter-efficient\nreinforcement learning (PE-RL) to improve NPOV generation. We compare and\nextensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a\nstrong baseline), SFT and RLHF.\n  PE-RL not only improves on overall NPOV quality compared to the strongest\nbaseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on\nfeatures linguists identify as key to separating good answers from the best\nanswers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details,\n$68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative\nanalysis corroborates this. Finally, our evaluation finds no statistical\ndifferences between results on topics that appear in the training dataset and\nthose on separated evaluation topics, which provides strong evidence that our\napproach to training PE-RL exhibits very effective out of topic generalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03654v1",
    "published_date": "2025-03-05 16:32:47 UTC",
    "updated_date": "2025-03-05 16:32:47 UTC"
  },
  {
    "arxiv_id": "2503.03606v2",
    "title": "Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs",
    "authors": [
      "Anas Buhayh",
      "Elizabeth McKinnie",
      "Robin Burke"
    ],
    "abstract": "Recommender ecosystems are an emerging subject of research. Such research\nexamines how the characteristics of algorithms, recommendation consumers, and\nitem providers influence system dynamics and long-term outcomes. One\narchitectural possibility that has not yet been widely explored in this line of\nresearch is the consequences of a configuration in which recommendation\nalgorithms are decoupled from the platforms they serve. This is sometimes\ncalled \"the friendly neighborhood algorithm store\" or \"middleware\" model. We\nare particularly interested in how such architectures might offer a range of\ndifferent distributions of utility across consumers, providers, and\nrecommendation platforms. In this paper, we create a model of a recommendation\necosystem that incorporates algorithm choice and examine the outcomes of such a\ndesign.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03606v2",
    "published_date": "2025-03-05 15:42:37 UTC",
    "updated_date": "2025-03-06 14:28:36 UTC"
  },
  {
    "arxiv_id": "2503.03595v1",
    "title": "Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias",
    "authors": [
      "Rui Lu",
      "Runzhe Wang",
      "Kaifeng Lyu",
      "Xitai Jiang",
      "Gao Huang",
      "Mengdi Wang"
    ],
    "abstract": "Score-based diffusion models have achieved incredible performance in\ngenerating realistic images, audio, and video data. While these models produce\nhigh-quality samples with impressive details, they often introduce unrealistic\nartifacts, such as distorted fingers or hallucinated texts with no meaning.\nThis paper focuses on textual hallucinations, where diffusion models correctly\ngenerate individual symbols but assemble them in a nonsensical manner. Through\nexperimental probing, we consistently observe that such phenomenon is\nattributed it to the network's local generation bias. Denoising networks tend\nto produce outputs that rely heavily on highly correlated local regions,\nparticularly when different dimensions of the data distribution are nearly\npairwise independent. This behavior leads to a generation process that\ndecomposes the global distribution into separate, independent distributions for\neach symbol, ultimately failing to capture the global structure, including\nunderlying grammar. Intriguingly, this bias persists across various denoising\nnetwork architectures including MLP and transformers which have the structure\nto model global dependency. These findings also provide insights into\nunderstanding other types of hallucinations, extending beyond text, as a result\nof implicit biases in the denoising models. Additionally, we theoretically\nanalyze the training dynamics for a specific case involving a two-layer MLP\nlearning parity points on a hypercube, offering an explanation of its\nunderlying mechanism.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03595v1",
    "published_date": "2025-03-05 15:28:50 UTC",
    "updated_date": "2025-03-05 15:28:50 UTC"
  },
  {
    "arxiv_id": "2503.03594v2",
    "title": "Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs",
    "authors": [
      "Haoran Fan",
      "Bin Li",
      "Yixuan Weng",
      "Shoujun Zhou"
    ],
    "abstract": "While LLMs have demonstrated remarkable potential in time series forecasting,\ntheir practical deployment remains constrained by excessive computational\ndemands and memory footprints. Existing LLM-based approaches typically suffer\nfrom three critical limitations: Inefficient parameter utilization in handling\nnumerical time series patterns; Modality misalignment between continuous\ntemporal signals and discrete text embeddings; and Inflexibility for real-time\nexpert knowledge integration. We present SMETimes, the first systematic\ninvestigation of sub-3B parameter SLMs for efficient and accurate time series\nforecasting. Our approach centers on three key innovations: A\nstatistically-enhanced prompting mechanism that bridges numerical time series\nwith textual semantics through descriptive statistical features; A adaptive\nfusion embedding architecture that aligns temporal patterns with language model\ntoken spaces through learnable parameters; And a dynamic mixture-of-experts\nframework enabled by SLMs' computational efficiency, adaptively combining base\npredictions with domain-specific models. Extensive evaluations across seven\nbenchmark datasets demonstrate that our 3B-parameter SLM achieves\nstate-of-the-art performance on five primary datasets while maintaining 3.8x\nfaster training and 5.2x lower memory consumption compared to 7B-parameter LLM\nbaselines. Notably, the proposed model exhibits better learning capabilities,\nachieving 12.3% lower MSE than conventional LLM. Ablation studies validate that\nour statistical prompting and cross-modal fusion modules respectively\ncontribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.\nBy redefining the efficiency-accuracy trade-off landscape, this work\nestablishes SLMs as viable alternatives to resource-intensive LLMs for\npractical time series forecasting. Code and models are available at\nhttps://github.com/xiyan1234567/SMETimes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03594v2",
    "published_date": "2025-03-05 15:27:36 UTC",
    "updated_date": "2025-03-09 10:56:53 UTC"
  },
  {
    "arxiv_id": "2503.03592v2",
    "title": "English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance",
    "authors": [
      "Karl Audun Borgersen"
    ],
    "abstract": "For consumer usage of locally deployed LLMs, the GGUF format and\nk\\_quantization are invaluable tools for maintaining the performance of the\noriginal model while reducing it to sizes deployable with consumer-grade\nhardware. The number of bits dedicated to each weight from the original model\nis reduced based on how important they are thought to be during model\ninference. This importance is arrived at through the application of an\n'importance matrix'-a relatively small text document meant to be representative\nof the LLM's standard use-cases. In the vast majority of quants available\nonline, this document is primarily written in English. It was therefore an open\nquestion whether performance on English language tasks was preserved through\nthe sacrifice of multilingual performance and whether it can be preserved with\nalternate importance matrices. This article investigates these hypotheses by\nquantizing Llama3.3 70B on importance matrices written in three languages\n(English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset\nin both English and Norwegian. All experiments related to yielded\nnon-significant results indicating that current quantization practices do not\ndisproportionately harm multilingual performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 6 figures, v2",
    "pdf_url": "http://arxiv.org/pdf/2503.03592v2",
    "published_date": "2025-03-05 15:26:59 UTC",
    "updated_date": "2025-03-10 07:36:46 UTC"
  },
  {
    "arxiv_id": "2503.16480v1",
    "title": "Human Preferences for Constructive Interactions in Language Model Alignment",
    "authors": [
      "Yara Kyrychenko",
      "Jon Roozenbeek",
      "Brandon Davidson",
      "Sander van der Linden",
      "Ramit Debnath"
    ],
    "abstract": "As large language models (LLMs) enter the mainstream, aligning them to foster\nconstructive dialogue rather than exacerbate societal divisions is critical.\nUsing an individualized and multicultural alignment dataset of over 7,500\nconversations of individuals from 74 countries engaging with 21 LLMs, we\nexamined how linguistic attributes linked to constructive interactions are\nreflected in human preference data used for training AI. We found that users\nconsistently preferred well-reasoned and nuanced responses while rejecting\nthose high in personal storytelling. However, users who believed that AI should\nreflect their values tended to place less preference on reasoning in LLM\nresponses and more on curiosity. Encouragingly, we observed that users could\nset the tone for how constructive their conversation would be, as LLMs mirrored\nlinguistic attributes, including toxicity, in user queries.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "1 Figure, 1 Table, 11 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16480v1",
    "published_date": "2025-03-05 15:08:41 UTC",
    "updated_date": "2025-03-05 15:08:41 UTC"
  },
  {
    "arxiv_id": "2503.03797v1",
    "title": "VoiceGRPO: Modern MoE Transformers with Group Relative Policy Optimization GRPO for AI Voice Health Care Applications on Voice Pathology Detection",
    "authors": [
      "Enkhtogtokh Togootogtokh",
      "Christian Klasen"
    ],
    "abstract": "This research introduces a novel AI techniques as Mixture-of-Experts\nTransformers with Group Relative Policy Optimization (GRPO) for voice health\ncare applications on voice pathology detection. With the architectural\ninnovations, we adopt advanced training paradigms inspired by reinforcement\nlearning, namely Proximal Policy Optimization (PPO) and Group-wise Regularized\nPolicy Optimization (GRPO), to enhance model stability and performance.\nExperiments conducted on a synthetically generated voice pathology dataset\ndemonstrate that our proposed models significantly improve diagnostic accuracy,\nF1 score, and ROC-AUC compared to conventional approaches. These findings\nunderscore the potential of integrating transformer architectures with novel\ntraining strategies to advance automated voice pathology detection and\nultimately contribute to more effective healthcare delivery. The code we used\nto train and evaluate our models is available at\nhttps://github.com/enkhtogtokh/voicegrpo",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03797v1",
    "published_date": "2025-03-05 14:52:57 UTC",
    "updated_date": "2025-03-05 14:52:57 UTC"
  },
  {
    "arxiv_id": "2503.03563v2",
    "title": "A Conceptual Model for Attributions in Event-Centric Knowledge Graphs",
    "authors": [
      "Florian Plötzky",
      "Katarina Britz",
      "Wolf-Tilo Balke"
    ],
    "abstract": "The use of narratives as a means of fusing information from knowledge graphs\n(KGs) into a coherent line of argumentation has been the subject of recent\ninvestigation. Narratives are especially useful in event-centric knowledge\ngraphs in that they provide a means to connect different real-world events and\ncategorize them by well-known narrations. However, specifically for\ncontroversial events, a problem in information fusion arises, namely, multiple\nviewpoints regarding the validity of certain event aspects, e.g., regarding the\nrole a participant takes in an event, may exist. Expressing those viewpoints in\nKGs is challenging because disputed information provided by different\nviewpoints may introduce inconsistencies. Hence, most KGs only feature a single\nview on the contained information, hampering the effectiveness of narrative\ninformation access. This paper is an extension of our original work and\nintroduces attributions, i.e., parameterized predicates that allow for the\nrepresentation of facts that are only valid in a specific viewpoint. For this,\nwe develop a conceptual model that allows for the representation of\nviewpoint-dependent information. As an extension, we enhance the model by a\nconception of viewpoint-compatibility. Based on this, we deepen our original\ndeliberations on the model's effects on information fusion and provide\nadditional grounding in the literature.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted by Data & Knowledge Engineering, 22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03563v2",
    "published_date": "2025-03-05 14:51:46 UTC",
    "updated_date": "2025-04-22 16:54:10 UTC"
  },
  {
    "arxiv_id": "2503.04837v1",
    "title": "FedPalm: A General Federated Learning Framework for Closed- and Open-Set Palmprint Verification",
    "authors": [
      "Ziyuan Yang",
      "Yingyu Chen",
      "Chengrui Gao",
      "Andrew Beng Jin Teoh",
      "Bob Zhang",
      "Yi Zhang"
    ],
    "abstract": "Current deep learning (DL)-based palmprint verification models rely on\ncentralized training with large datasets, which raises significant privacy\nconcerns due to biometric data's sensitive and immutable nature. Federated\nlearning~(FL), a privacy-preserving distributed learning paradigm, offers a\ncompelling alternative by enabling collaborative model training without the\nneed for data sharing. However, FL-based palmprint verification faces critical\nchallenges, including data heterogeneity from diverse identities and the\nabsence of standardized evaluation benchmarks. This paper addresses these gaps\nby establishing a comprehensive benchmark for FL-based palmprint verification,\nwhich explicitly defines and evaluates two practical scenarios: closed-set and\nopen-set verification. We propose FedPalm, a unified FL framework that balances\nlocal adaptability with global generalization. Each client trains a\npersonalized textural expert tailored to local data and collaboratively\ncontributes to a shared global textural expert for extracting generalized\nfeatures. To further enhance verification performance, we introduce a Textural\nExpert Interaction Module that dynamically routes textural features among\nexperts to generate refined side textural features. Learnable parameters are\nemployed to model relationships between original and side features, fostering\ncross-texture-expert interaction and improving feature discrimination.\nExtensive experiments validate the effectiveness of FedPalm, demonstrating\nrobust performance across both scenarios and providing a promising foundation\nfor advancing FL-based palmprint verification research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04837v1",
    "published_date": "2025-03-05 14:49:42 UTC",
    "updated_date": "2025-03-05 14:49:42 UTC"
  },
  {
    "arxiv_id": "2503.03562v3",
    "title": "Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection",
    "authors": [
      "Wenqiao Li",
      "Yao Gu",
      "Xintao Chen",
      "Xiaohao Xu",
      "Ming Hu",
      "Xiaonan Huang",
      "Yingna Wu"
    ],
    "abstract": "Humans detect real-world object anomalies by perceiving, interacting, and\nreasoning based on object-conditioned physical knowledge. The long-term goal of\nIndustrial Anomaly Detection (IAD) is to enable machines to autonomously\nreplicate this skill. However, current IAD algorithms are largely developed and\ntested on static, semantically simple datasets, which diverge from real-world\nscenarios where physical understanding and reasoning are essential. To bridge\nthis gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the\nfirst large-scale, real-world, physics-grounded video dataset for industrial\nanomaly detection. Collected using a real robot arm and motor, Phys-AD provides\na diverse set of dynamic, semantically rich scenarios. The dataset includes\nmore than 6400 videos across 22 real-world object categories, interacting with\nrobot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in\nPhys-AD requires visual reasoning, combining both physical knowledge and video\ncontent to determine object abnormality. We benchmark state-of-the-art anomaly\ndetection methods under three settings: unsupervised AD, weakly-supervised AD,\nand video-understanding AD, highlighting their limitations in handling\nphysics-grounded anomalies. Additionally, we introduce the Physics Anomaly\nExplanation (PAEval) metric, designed to assess the ability of visual-language\nfoundation models to not only detect anomalies but also provide accurate\nexplanations for their underlying physical causes. Our project is available at\nhttps://guyao2023.github.io/Phys-AD/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR25",
    "pdf_url": "http://arxiv.org/pdf/2503.03562v3",
    "published_date": "2025-03-05 14:49:08 UTC",
    "updated_date": "2025-03-26 03:58:26 UTC"
  },
  {
    "arxiv_id": "2503.04836v1",
    "title": "PGAD: Prototype-Guided Adaptive Distillation for Multi-Modal Learning in AD Diagnosis",
    "authors": [
      "Yanfei Li",
      "Teng Yin",
      "Wenyi Shang",
      "Jingyu Liu",
      "Xi Wang",
      "Kaiyang Zhao"
    ],
    "abstract": "Missing modalities pose a major issue in Alzheimer's Disease (AD) diagnosis,\nas many subjects lack full imaging data due to cost and clinical constraints.\nWhile multi-modal learning leverages complementary information, most existing\nmethods train only on complete data, ignoring the large proportion of\nincomplete samples in real-world datasets like ADNI. This reduces the effective\ntraining set and limits the full use of valuable medical data. While some\nmethods incorporate incomplete samples, they fail to effectively address\ninter-modal feature alignment and knowledge transfer challenges under high\nmissing rates. To address this, we propose a Prototype-Guided Adaptive\nDistillation (PGAD) framework that directly incorporates incomplete multi-modal\ndata into training. PGAD enhances missing modality representations through\nprototype matching and balances learning with a dynamic sampling strategy. We\nvalidate PGAD on the ADNI dataset with varying missing rates (20%, 50%, and\n70%) and demonstrate that it significantly outperforms state-of-the-art\napproaches. Ablation studies confirm the effectiveness of prototype matching\nand adaptive sampling, highlighting the potential of our framework for robust\nand scalable AD diagnosis in real-world clinical settings.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04836v1",
    "published_date": "2025-03-05 14:39:31 UTC",
    "updated_date": "2025-03-05 14:39:31 UTC"
  },
  {
    "arxiv_id": "2503.04835v1",
    "title": "Distilling Dataset into Neural Field",
    "authors": [
      "Donghyeok Shin",
      "HeeSun Bae",
      "Gyuwon Sim",
      "Wanmo Kang",
      "Il-Chul Moon"
    ],
    "abstract": "Utilizing a large-scale dataset is essential for training high-performance\ndeep learning models, but it also comes with substantial computation and\nstorage costs. To overcome these challenges, dataset distillation has emerged\nas a promising solution by compressing the large-scale dataset into a smaller\nsynthetic dataset that retains the essential information needed for training.\nThis paper proposes a novel parameterization framework for dataset\ndistillation, coined Distilling Dataset into Neural Field (DDiF), which\nleverages the neural field to store the necessary information of the\nlarge-scale dataset. Due to the unique nature of the neural field, which takes\ncoordinates as input and output quantity, DDiF effectively preserves the\ninformation and easily generates various shapes of data. We theoretically\nconfirm that DDiF exhibits greater expressiveness than some previous literature\nwhen the utilized budget for a single synthetic instance is the same. Through\nextensive experiments, we demonstrate that DDiF achieves superior performance\non several benchmark datasets, extending beyond the image domain to include\nvideo, audio, and 3D voxel. We release the code at\nhttps://github.com/aailab-kaist/DDiF.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The Thirteenth International Conference on Learning Representations\n  (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.04835v1",
    "published_date": "2025-03-05 14:33:29 UTC",
    "updated_date": "2025-03-05 14:33:29 UTC"
  },
  {
    "arxiv_id": "2503.03796v2",
    "title": "Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm",
    "authors": [
      "Hyeonjun Kim",
      "Kanghoon Lee",
      "Junho Park",
      "Jiachen Li",
      "Jinkyoo Park"
    ],
    "abstract": "Multi-Agent Reinforcement Learning (MARL) has shown promise in solving\ncomplex problems involving cooperation and competition among agents, such as an\nUnmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance,\nand vessel protection. However, aligning system behavior with user preferences\nis challenging due to the difficulty of encoding expert intuition into reward\nfunctions. To address the issue, we propose a Reinforcement Learning with Human\nFeedback (RLHF) approach for MARL that resolves credit-assignment challenges\nthrough an Agent-Level Feedback system categorizing feedback into intra-agent,\ninter-agent, and intra-team types. To overcome the challenges of direct human\nfeedback, we employ a Large Language Model (LLM) evaluator to validate our\napproach using feedback scenarios such as region constraints, collision\navoidance, and task allocation. Our method effectively refines USV swarm\npolicies, addressing key challenges in multi-agent systems while maintaining\nfairness and performance consistency.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "7 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03796v2",
    "published_date": "2025-03-05 14:33:18 UTC",
    "updated_date": "2025-03-07 08:06:15 UTC"
  },
  {
    "arxiv_id": "2504.06274v1",
    "title": "Joint Group Profiling and Recommendation via Deep Neural Network-based Multi-Task Learning",
    "authors": [
      "Ngoc Luyen Le",
      "Marie-Hélène Abel"
    ],
    "abstract": "Group recommender systems aim to generate recommendations that align with the\ncollective preferences of a group, introducing challenges that differ\nsignificantly from those in individual recommendation scenarios. This paper\npresents Joint Group Profiling and Recommendation via Deep Neural Network-based\nMulti-Task Learning, a framework that unifies group profiling and\nrecommendation tasks within a single model. By jointly learning these tasks,\nthe model develops a deeper understanding of group dynamics, leading to\nimproved recommendation accuracy. The shared representations between the two\ntasks facilitate the discovery of latent features essential to both, resulting\nin richer and more informative group embeddings. To further enhance\nperformance, an attention mechanism is integrated to dynamically evaluate the\nrelevance of different group features and item attributes, ensuring the model\nprioritizes the most impactful information. Experiments and evaluations on\nreal-world datasets demonstrate that our multi-task learning approach\nconsistently outperforms baseline models in terms of accuracy, validating its\neffectiveness and robustness.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06274v1",
    "published_date": "2025-03-05 14:28:48 UTC",
    "updated_date": "2025-03-05 14:28:48 UTC"
  },
  {
    "arxiv_id": "2503.04834v1",
    "title": "Extrapolation Merging: Keep Improving With Extrapolation and Merging",
    "authors": [
      "Yiguan Lin",
      "Bin Xu",
      "Yinghao Li",
      "Yang Gao"
    ],
    "abstract": "Large Language Models (LLMs) require instruction fine-tuning to perform\ndifferent downstream tasks. However, the instruction fine-tuning phase still\ndemands significant computational resources and labeled data, lacking a\nparadigm that can improve model performance without additional computational\npower and data. Model merging aims to enhance performance by combining the\nparameters of different models, but the lack of a clear optimization direction\nduring the merging process does not always guarantee improved performance. In\nthis paper, we attempt to provide a clear optimization direction for model\nmerging. We first validate the effectiveness of the model extrapolation method\nduring the instruction fine-tuning phase. Then, we propose Extrapolation\nMerging, a paradigm that can continue improving model performance without\nrequiring extra computational resources or data. Using the extrapolation\nmethod, we provide a clear direction for model merging, achieving local\noptimization search, and consequently enhancing the merged model's performance.\nWe conduct experiments on seven different tasks, and the results show that our\nmethod can consistently improve the model's performance after fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04834v1",
    "published_date": "2025-03-05 14:28:22 UTC",
    "updated_date": "2025-03-05 14:28:22 UTC"
  },
  {
    "arxiv_id": "2503.03532v1",
    "title": "AI-Enabled Conversational Journaling for Advancing Parkinson's Disease Symptom Tracking",
    "authors": [
      "Mashrur Rashik",
      "Shilpa Sweth",
      "Nishtha Agrawal",
      "Saiyyam Kochar",
      "Kara M Smith",
      "Fateme Rajabiyazdi",
      "Vidya Setlur",
      "Narges Mahyar",
      "Ali Sarvghad"
    ],
    "abstract": "Journaling plays a crucial role in managing chronic conditions by allowing\npatients to document symptoms and medication intake, providing essential data\nfor long-term care. While valuable, traditional journaling methods often rely\non static, self-directed entries, lacking interactive feedback and real-time\nguidance. This gap can result in incomplete or imprecise information, limiting\nits usefulness for effective treatment. To address this gap, we introduce\nPATRIKA, an AI-enabled prototype designed specifically for people with\nParkinson's disease (PwPD). The system incorporates cooperative conversation\nprinciples, clinical interview simulations, and personalization to create a\nmore effective and user-friendly journaling experience. Through two user\nstudies with PwPD and iterative refinement of PATRIKA, we demonstrate\nconversational journaling's significant potential in patient engagement and\ncollecting clinically valuable information. Our results showed that generating\nprobing questions PATRIKA turned journaling into a bi-directional interaction.\nAdditionally, we offer insights for designing journaling systems for healthcare\nand future directions for promoting sustained journaling.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To appear in the ACM CHI conference on Human Factors in Computing\n  Systems (CHI), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03532v1",
    "published_date": "2025-03-05 14:14:25 UTC",
    "updated_date": "2025-03-05 14:14:25 UTC"
  },
  {
    "arxiv_id": "2503.04833v2",
    "title": "Adversarial Training for Multimodal Large Language Models against Jailbreak Attacks",
    "authors": [
      "Liming Lu",
      "Shuchao Pang",
      "Siyuan Liang",
      "Haotian Zhu",
      "Xiyu Zeng",
      "Aishan Liu",
      "Yunhuai Liu",
      "Yongbin Zhou"
    ],
    "abstract": "Multimodal large language models (MLLMs) have made remarkable strides in\ncross-modal comprehension and generation tasks. However, they remain vulnerable\nto jailbreak attacks, where crafted perturbations bypass security guardrails\nand elicit harmful outputs. In this paper, we present the first adversarial\ntraining (AT) paradigm tailored to defend against jailbreak attacks during the\nMLLM training phase. Extending traditional AT to this domain poses two critical\nchallenges: efficiently tuning massive parameters and ensuring robustness\nagainst attacks across multiple modalities. To address these challenges, we\nintroduce Projection Layer Against Adversarial Training (ProEAT), an end-to-end\nAT framework. ProEAT incorporates a projector-based adversarial training\narchitecture that efficiently handles large-scale parameters while maintaining\ncomputational feasibility by focusing adversarial training on a lightweight\nprojector layer instead of the entire model; additionally, we design a dynamic\nweight adjustment mechanism that optimizes the loss function's weight\nallocation based on task demands, streamlining the tuning process. To enhance\ndefense performance, we propose a joint optimization strategy across visual and\ntextual modalities, ensuring robust resistance to jailbreak attacks originating\nfrom either modality. Extensive experiments conducted on five major jailbreak\nattack methods across three mainstream MLLMs demonstrate the effectiveness of\nour approach. ProEAT achieves state-of-the-art defense performance,\noutperforming existing baselines by an average margin of +34% across text and\nimage modalities, while incurring only a 1% reduction in clean accuracy.\nFurthermore, evaluations on real-world embodied intelligent systems highlight\nthe practical applicability of our framework, paving the way for the\ndevelopment of more secure and reliable multimodal systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04833v2",
    "published_date": "2025-03-05 14:13:35 UTC",
    "updated_date": "2025-03-18 07:01:13 UTC"
  },
  {
    "arxiv_id": "2503.03528v1",
    "title": "AdaSin: Enhancing Hard Sample Metrics with Dual Adaptive Penalty for Face Recognition",
    "authors": [
      "Qiqi Guo",
      "Zhuowen Zheng",
      "Guanghua Yang",
      "Zhiquan Liu",
      "Xiaofan Li",
      "Jianqing Li",
      "Jinyu Tian",
      "Xueyuan Gong"
    ],
    "abstract": "In recent years, the emergence of deep convolutional neural networks has\npositioned face recognition as a prominent research focus in computer vision.\nTraditional loss functions, such as margin-based, hard-sample mining-based, and\nhybrid approaches, have achieved notable performance improvements, with some\nleveraging curriculum learning to optimize training. However, these methods\noften fall short in effectively quantifying the difficulty of hard samples. To\naddress this, we propose Adaptive Sine (AdaSin) loss function, which introduces\nthe sine of the angle between a sample's embedding feature and its ground-truth\nclass center as a novel difficulty metric. This metric enables precise and\neffective penalization of hard samples. By incorporating curriculum learning,\nthe model dynamically adjusts classification boundaries across different\ntraining stages. Unlike previous adaptive-margin loss functions, AdaSin\nintroduce a dual adaptive penalty, applied to both the positive and negative\ncosine similarities of hard samples. This design imposes stronger constraints,\nenhancing intra-class compactness and inter-class separability. The combination\nof the dual adaptive penalty and curriculum learning is guided by a\nwell-designed difficulty metric. It enables the model to focus more effectively\non hard samples in later training stages, and lead to the extraction of highly\ndiscriminative face features. Extensive experiments across eight benchmarks\ndemonstrate that AdaSin achieves superior accuracy compared to other\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03528v1",
    "published_date": "2025-03-05 14:11:13 UTC",
    "updated_date": "2025-03-05 14:11:13 UTC"
  },
  {
    "arxiv_id": "2503.03511v1",
    "title": "NeuGrasp: Generalizable Neural Surface Reconstruction with Background Priors for Material-Agnostic Object Grasp Detection",
    "authors": [
      "Qingyu Fan",
      "Yinghao Cai",
      "Chao Li",
      "Wenzhe He",
      "Xudong Zheng",
      "Tao Lu",
      "Bin Liang",
      "Shuo Wang"
    ],
    "abstract": "Robotic grasping in scenes with transparent and specular objects presents\ngreat challenges for methods relying on accurate depth information. In this\npaper, we introduce NeuGrasp, a neural surface reconstruction method that\nleverages background priors for material-agnostic grasp detection. NeuGrasp\nintegrates transformers and global prior volumes to aggregate multi-view\nfeatures with spatial encoding, enabling robust surface reconstruction in\nnarrow and sparse viewing conditions. By focusing on foreground objects through\nresidual feature enhancement and refining spatial perception with an\noccupancy-prior volume, NeuGrasp excels in handling objects with transparent\nand specular surfaces. Extensive experiments in both simulated and real-world\nscenarios show that NeuGrasp outperforms state-of-the-art methods in grasping\nwhile maintaining comparable reconstruction quality. More details are available\nat https://neugrasp.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9; I.2.10"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 5 figures. IEEE International Conference on Robotics and\n  Automation (ICRA) 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03511v1",
    "published_date": "2025-03-05 13:57:37 UTC",
    "updated_date": "2025-03-05 13:57:37 UTC"
  },
  {
    "arxiv_id": "2503.03506v4",
    "title": "Opinion: Revisiting synthetic data classifications from a privacy perspective",
    "authors": [
      "Vibeke Binz Vallevik",
      "Serena Elizabeth Marshall",
      "Aleksandar Babic",
      "Jan Franz Nygaard"
    ],
    "abstract": "Synthetic data is emerging as a cost-effective solution necessary to meet the\nincreasing data demands of AI development, created either from existing\nknowledge or derived from real data. The traditional classification of\nsynthetic data types into hybrid, partial or fully synthetic datasets has\nlimited value and does not reflect the ever-increasing methods to generate\nsynthetic data. The generation method and their source jointly shape the\ncharacteristics of synthetic data, which in turn determines its practical\napplications. We make a case for an alternative approach to grouping synthetic\ndata types that better reflect privacy perspectives in order to facilitate\nregulatory guidance in the generation and processing of synthetic data. This\napproach to classification provides flexibility to new advancements like deep\ngenerative methods and offers a more practical framework for future\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03506v4",
    "published_date": "2025-03-05 13:54:13 UTC",
    "updated_date": "2025-04-15 10:00:22 UTC"
  },
  {
    "arxiv_id": "2503.03505v1",
    "title": "Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems",
    "authors": [
      "Yaoru Li",
      "Shunyu Liu",
      "Tongya Zheng",
      "Mingli Song"
    ],
    "abstract": "Recent advancements in Large Language Model(LLM)-based Multi-Agent\nSystems(MAS) have demonstrated remarkable potential for tackling complex\ndecision-making tasks. However, existing frameworks inevitably rely on\nserialized execution paradigms, where agents must complete sequential LLM\nplanning before taking action. This fundamental constraint severely limits\nreal-time responsiveness and adaptation, which is crucial in dynamic\nenvironments with ever-changing scenarios. In this paper, we propose a novel\nparallelized planning-acting framework for LLM-based MAS, featuring a\ndual-thread architecture with interruptible execution to enable concurrent\nplanning and acting. Specifically, our framework comprises two core threads:(1)\na planning thread driven by a centralized memory system, maintaining\nsynchronization of environmental states and agent communication to support\ndynamic decision-making; and (2) an acting thread equipped with a comprehensive\nskill library, enabling automated task execution through recursive\ndecomposition. Extensive experiments on challenging Minecraft demonstrate the\neffectiveness of the proposed framework.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03505v1",
    "published_date": "2025-03-05 13:53:10 UTC",
    "updated_date": "2025-03-05 13:53:10 UTC"
  },
  {
    "arxiv_id": "2503.03503v1",
    "title": "Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization",
    "authors": [
      "Jiajun Yu",
      "Yizhen Zheng",
      "Huan Yee Koh",
      "Shirui Pan",
      "Tianyue Wang",
      "Haishuai Wang"
    ],
    "abstract": "Molecular optimization is a crucial yet complex and time-intensive process\nthat often acts as a bottleneck for drug development. Traditional methods rely\nheavily on trial and error, making multi-objective optimization both\ntime-consuming and resource-intensive. Current AI-based methods have shown\nlimited success in handling multi-objective optimization tasks, hampering their\npractical utilization. To address this challenge, we present MultiMol, a\ncollaborative large language model (LLM) system designed to guide\nmulti-objective molecular optimization. MultiMol comprises two agents,\nincluding a data-driven worker agent and a literature-guided research agent.\nThe data-driven worker agent is a large language model being fine-tuned to\nlearn how to generate optimized molecules considering multiple objectives,\nwhile the literature-guided research agent is responsible for searching\ntask-related literature to find useful prior knowledge that facilitates\nidentifying the most promising optimized candidates. In evaluations across six\nmulti-objective optimization tasks, MultiMol significantly outperforms existing\nmethods, achieving a 82.30% success rate, in sharp contrast to the 27.50%\nsuccess rate of current strongest methods. To further validate its practical\nimpact, we tested MultiMol on two real-world challenges. First, we enhanced the\nselectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds\nboth A1R and A2AR, successfully biasing it towards A1R. Second, we improved the\nbioavailability of Saquinavir, an HIV-1 protease inhibitor with known\nbioavailability limitations. Overall, these results indicate that MultiMol\nrepresents a highly promising approach for multi-objective molecular\noptimization, holding great potential to accelerate the drug development\nprocess and contribute to the advancement of pharmaceutical research.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03503v1",
    "published_date": "2025-03-05 13:47:55 UTC",
    "updated_date": "2025-03-05 13:47:55 UTC"
  },
  {
    "arxiv_id": "2503.03502v1",
    "title": "CURVALID: Geometrically-guided Adversarial Prompt Detection",
    "authors": [
      "Canaan Yung",
      "Hanxun Huang",
      "Sarah Monazam Erfani",
      "Christopher Leckie"
    ],
    "abstract": "Adversarial prompts capable of jailbreaking large language models (LLMs) and\ninducing undesirable behaviours pose a significant obstacle to their safe\ndeployment. Current mitigation strategies rely on activating built-in defence\nmechanisms or fine-tuning the LLMs, but the fundamental distinctions between\nadversarial and benign prompts are yet to be understood. In this work, we\nintroduce CurvaLID, a novel defense framework that efficiently detects\nadversarial prompts by leveraging their geometric properties. It is agnostic to\nthe type of LLM, offering a unified detection framework across diverse\nadversarial prompts and LLM architectures. CurvaLID builds on the geometric\nanalysis of text prompts to uncover their underlying differences. We\ntheoretically extend the concept of curvature via the Whewell equation into an\n$n$-dimensional word embedding space, enabling us to quantify local geometric\nproperties, including semantic shifts and curvature in the underlying\nmanifolds. Additionally, we employ Local Intrinsic Dimensionality (LID) to\ncapture geometric features of text prompts within adversarial subspaces. Our\nfindings reveal that adversarial prompts differ fundamentally from benign\nprompts in terms of their geometric characteristics. Our results demonstrate\nthat CurvaLID delivers superior detection and rejection of adversarial queries,\npaving the way for safer LLM deployment. The source code can be found at\nhttps://github.com/Cancanxxx/CurvaLID",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "29 Pages, 5 figues",
    "pdf_url": "http://arxiv.org/pdf/2503.03502v1",
    "published_date": "2025-03-05 13:47:53 UTC",
    "updated_date": "2025-03-05 13:47:53 UTC"
  },
  {
    "arxiv_id": "2503.03480v1",
    "title": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Safe Reinforcement Learning",
    "authors": [
      "Borong Zhang",
      "Yuhao Zhang",
      "Jiaming Ji",
      "Yingshan Lei",
      "Josef Dai",
      "Yuanpei Chen",
      "Yaodong Yang"
    ],
    "abstract": "Vision-language-action models (VLAs) have shown great potential as generalist\nrobot policies. However, these models pose urgent safety challenges during\ndeployment, including the risk of physical harm to the environment, the robot\nitself, and humans. How can safety be explicitly incorporated into VLAs? In\nthis work, we propose SafeVLA, a novel algorithm designed to integrate safety\ninto VLAs, ensuring the protection of the environment, robot hardware and\nhumans in real-world settings. SafeVLA effectively balances safety and task\nperformance by employing large-scale constrained learning within simulated\nenvironments. We demonstrate that SafeVLA outperforms the current\nstate-of-the-art method in both safety and task performance, achieving average\nimprovements of 83.58% and 3.85%, respectively, in simulation. By prioritizing\nsafety, our approach eliminates high-risk behaviors and reduces the upper bound\nof unsafe behaviors to 1/35 of that in the current state-of-the-art, thereby\nsignificantly mitigating long-tail risks. Furthermore, the learned safety\nconstraints generalize to diverse, unseen scenarios, including multiple\nout-of-distribution perturbations and tasks. Our data, models and newly\nproposed benchmark environment are available at\nhttps://sites.google.com/view/pku-safevla.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03480v1",
    "published_date": "2025-03-05 13:16:55 UTC",
    "updated_date": "2025-03-05 13:16:55 UTC"
  },
  {
    "arxiv_id": "2503.03462v1",
    "title": "Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation",
    "authors": [
      "Ahmed Njifenjou",
      "Virgile Sucal",
      "Bassam Jabaian",
      "Fabrice Lefèvre"
    ],
    "abstract": "The prevailing paradigm in the domain of Open-Domain Dialogue agents\npredominantly focuses on the English language, encompassing both models and\ndatasets. Furthermore, the financial and temporal investments required for\ncrowdsourcing such datasets for finetuning are substantial, particularly when\nmultiple languages are involved. Fortunately, advancements in Large Language\nModels (LLMs) have unveiled a plethora of possibilities across diverse tasks.\nSpecifically, instruction-tuning has enabled LLMs to execute tasks based on\nnatural language instructions, occasionally surpassing the performance of human\ncrowdworkers. Additionally, these models possess the capability to function in\nvarious languages within a single thread. Consequently, to generate new samples\nin different languages, we propose leveraging these capabilities to replicate\nthe data collection process. We introduce a pipeline for generating Open-Domain\nDialogue data in multiple Target Languages using LLMs, with demonstrations\nprovided in a unique Source Language. By eschewing explicit Machine Translation\nin this approach, we enhance the adherence to language-specific nuances. We\napply this methodology to the PersonaChat dataset. To enhance the openness of\ngenerated dialogues and mimic real life scenarii, we added the notion of speech\nevents corresponding to the type of conversation the speakers are involved in\nand also that of common ground which represents the premises of a conversation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03462v1",
    "published_date": "2025-03-05 12:52:14 UTC",
    "updated_date": "2025-03-05 12:52:14 UTC"
  },
  {
    "arxiv_id": "2503.03459v2",
    "title": "Unified Mind Model: Reimagining Autonomous Agents in the LLM Era",
    "authors": [
      "Pengbo Hu",
      "Xiang Ying"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated remarkable\ncapabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4),\nreviving the research of general autonomous agents with human-like cognitive\nabilities. Such human-level agents require semantic comprehension and\ninstruction-following capabilities, which exactly fall into the strengths of\nLLMs. Although there have been several initial attempts to build human-level\nagents based on LLMs, the theoretical foundation remains a challenging open\nproblem. In this paper, we propose a novel theoretical cognitive architecture,\nthe Unified Mind Model (UMM), which offers guidance to facilitate the rapid\ncreation of autonomous agents with human-level cognitive abilities.\nSpecifically, our UMM starts with the global workspace theory and further\nleverage LLMs to enable the agent with various cognitive abilities, such as\nmulti-modal perception, planning, reasoning, tool use, learning, memory,\nreflection and motivation. Building upon UMM, we then develop an agent-building\nengine, MindOS, which allows users to quickly create domain-/task-specific\nautonomous agents without any programming effort.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03459v2",
    "published_date": "2025-03-05 12:49:44 UTC",
    "updated_date": "2025-03-06 03:32:45 UTC"
  },
  {
    "arxiv_id": "2503.03444v1",
    "title": "Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties",
    "authors": [
      "Eunkyung Choi",
      "Young Jin Suh",
      "Hun Park",
      "Wonseok Hwang"
    ],
    "abstract": "How capable are large language models (LLMs) in the domain of taxation?\nAlthough numerous studies have explored the legal domain in general, research\ndedicated to taxation remain scarce. Moreover, the datasets used in these\nstudies are either simplified, failing to reflect the real-world complexities,\nor unavailable as open source. To address this gap, we introduce PLAT, a new\nbenchmark designed to assess the ability of LLMs to predict the legitimacy of\nadditional tax penalties. PLAT is constructed to evaluate LLMs' understanding\nof tax law, particularly in cases where resolving the issue requires more than\njust applying related statutes. Our experiments with six LLMs reveal that their\nbaseline capabilities are limited, especially when dealing with conflicting\nissues that demand a comprehensive understanding. However, we found that\nenabling retrieval, self-reasoning, and discussion among multiple agents with\nspecific role assignments, this limitation can be mitigated.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03444v1",
    "published_date": "2025-03-05 12:24:20 UTC",
    "updated_date": "2025-03-05 12:24:20 UTC"
  },
  {
    "arxiv_id": "2503.03443v1",
    "title": "Conceptualizing Uncertainty",
    "authors": [
      "Isaac Roberts",
      "Alexander Schulz",
      "Sarah Schroeder",
      "Fabian Hinder",
      "Barbara Hammer"
    ],
    "abstract": "Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03443v1",
    "published_date": "2025-03-05 12:24:12 UTC",
    "updated_date": "2025-03-05 12:24:12 UTC"
  },
  {
    "arxiv_id": "2503.03434v1",
    "title": "RASD: Retrieval-Augmented Speculative Decoding",
    "authors": [
      "Guofeng Quan",
      "Wenfeng Feng",
      "Chuzhan Hao",
      "Guochao Jiang",
      "Yuewei Zhang",
      "Hao Wang"
    ],
    "abstract": "Speculative decoding accelerates inference in large language models (LLMs) by\ngenerating draft tokens for target model verification. Current approaches for\nobtaining draft tokens rely on lightweight draft models or additional model\nstructures to generate draft tokens and retrieve context from databases. Due to\nthe draft model's small size and limited training data, model-based speculative\ndecoding frequently becomes less effective in out-of-domain scenarios.\nAdditionally, the time cost of the drafting phase results in a low upper limit\non acceptance length during the verification step, limiting overall efficiency.\nThis paper proposes RASD (Retrieval-Augmented Speculative Decoding), which\nadopts retrieval methods to enhance model-based speculative decoding. We\nintroduce tree pruning and tree fusion to achieve this. Specifically, we\ndevelop a pruning method based on the draft model's probability distribution to\nconstruct the optimal retrieval tree. Second, we employ the longest prefix\nmatching algorithm to merge the tree generated by the draft model with the\nretrieval tree, resulting in a unified tree for verification. Experimental\nresults demonstrate that RASD achieves state-of-the-art inference acceleration\nacross tasks such as DocQA, Summary, Code, and In-Domain QA. Moreover, RASD\nexhibits strong scalability, seamlessly integrating with various speculative\ndecoding approaches, including both generation-based and retrieval-based\nmethods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03434v1",
    "published_date": "2025-03-05 12:10:14 UTC",
    "updated_date": "2025-03-05 12:10:14 UTC"
  },
  {
    "arxiv_id": "2503.03428v1",
    "title": "Privacy is All You Need: Revolutionizing Wearable Health Data with Advanced PETs",
    "authors": [
      "Karthik Barma",
      "Seshu Babu Barma"
    ],
    "abstract": "In a world where data is the new currency, wearable health devices offer\nunprecedented insights into daily life, continuously monitoring vital signs and\nmetrics. However, this convenience raises privacy concerns, as these devices\ncollect sensitive data that can be misused or breached. Traditional measures\noften fail due to real-time data processing needs and limited device power.\nUsers also lack awareness and control over data sharing and usage. We propose a\nPrivacy-Enhancing Technology (PET) framework for wearable devices, integrating\nfederated learning, lightweight cryptographic methods, and selectively deployed\nblockchain technology. The blockchain acts as a secure ledger triggered only\nupon data transfer requests, granting users real-time notifications and\ncontrol. By dismantling data monopolies, this approach returns data sovereignty\nto individuals. Through real-world applications like secure medical data\nsharing, privacy-preserving fitness tracking, and continuous health monitoring,\nour framework reduces privacy risks by up to 70 percent while preserving data\nutility and performance. This innovation sets a new benchmark for wearable\nprivacy and can scale to broader IoT ecosystems, including smart homes and\nindustry. As data continues to shape our digital landscape, our research\nunderscores the critical need to maintain privacy and user control at the\nforefront of technological progress.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03428v1",
    "published_date": "2025-03-05 12:01:22 UTC",
    "updated_date": "2025-03-05 12:01:22 UTC"
  },
  {
    "arxiv_id": "2503.03794v1",
    "title": "Synthetic Data Augmentation for Enhancing Harmful Algal Bloom Detection with Machine Learning",
    "authors": [
      "Tianyi Huang"
    ],
    "abstract": "Harmful Algal Blooms (HABs) pose severe threats to aquatic ecosystems and\npublic health, resulting in substantial economic losses globally. Early\ndetection is crucial but often hindered by the scarcity of high-quality\ndatasets necessary for training reliable machine learning (ML) models. This\nstudy investigates the use of synthetic data augmentation using Gaussian\nCopulas to enhance ML-based HAB detection systems. Synthetic datasets of\nvarying sizes (100-1,000 samples) were generated using relevant environmental\nfeatures$\\unicode{x2015}$water temperature, salinity, and UVB\nradiation$\\unicode{x2015}$with corrected Chlorophyll-a concentration as the\ntarget variable. Experimental results demonstrate that moderate synthetic\naugmentation significantly improves model performance (RMSE reduced from 0.4706\nto 0.1850; $p < 0.001$). However, excessive synthetic data introduces noise and\nreduces predictive accuracy, emphasizing the need for a balanced approach to\ndata augmentation. These findings highlight the potential of synthetic data to\nenhance HAB monitoring systems, offering a scalable and cost-effective method\nfor early detection and mitigation of ecological and public health risks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted Paper at the 2025 IEEE Conference on Technologies for\n  Sustainability (SusTech)",
    "pdf_url": "http://arxiv.org/pdf/2503.03794v1",
    "published_date": "2025-03-05 11:50:04 UTC",
    "updated_date": "2025-03-05 11:50:04 UTC"
  },
  {
    "arxiv_id": "2503.03418v1",
    "title": "Simplicial SMOTE: Oversampling Solution to the Imbalanced Learning Problem",
    "authors": [
      "Oleg Kachan",
      "Andrey Savchenko",
      "Gleb Gusev"
    ],
    "abstract": "SMOTE (Synthetic Minority Oversampling Technique) is the established\ngeometric approach to random oversampling to balance classes in the imbalanced\nlearning problem, followed by many extensions. Its idea is to introduce\nsynthetic data points of the minor class, with each new point being the convex\ncombination of an existing data point and one of its k-nearest neighbors. In\nthis paper, by viewing SMOTE as sampling from the edges of a geometric\nneighborhood graph and borrowing tools from the topological data analysis, we\npropose a novel technique, Simplicial SMOTE, that samples from the simplices of\na geometric neighborhood simplicial complex. A new synthetic point is defined\nby the barycentric coordinates w.r.t. a simplex spanned by an arbitrary number\nof data points being sufficiently close rather than a pair. Such a replacement\nof the geometric data model results in better coverage of the underlying data\ndistribution compared to existing geometric sampling methods and allows the\ngeneration of synthetic points of the minority class closer to the majority\nclass on the decision boundary. We experimentally demonstrate that our\nSimplicial SMOTE outperforms several popular geometric sampling methods,\nincluding the original SMOTE. Moreover, we show that simplicial sampling can be\neasily integrated into existing SMOTE extensions. We generalize and evaluate\nsimplicial extensions of the classic Borderline SMOTE, Safe-level SMOTE, and\nADASYN algorithms, all of which outperform their graph-based counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at KDD 2025 (research track)",
    "pdf_url": "http://arxiv.org/pdf/2503.03418v1",
    "published_date": "2025-03-05 11:47:41 UTC",
    "updated_date": "2025-03-05 11:47:41 UTC"
  },
  {
    "arxiv_id": "2503.03417v2",
    "title": "When Claims Evolve: Evaluating and Enhancing the Robustness of Embedding Models Against Misinformation Edits",
    "authors": [
      "Jabez Magomere",
      "Emanuele La Malfa",
      "Manuel Tonneau",
      "Ashkan Kazemi",
      "Scott Hale"
    ],
    "abstract": "Online misinformation remains a critical challenge, and fact-checkers\nincreasingly rely on embedding-based methods to retrieve relevant fact-checks.\nYet, when debunked claims reappear in edited forms, the performance of these\nmethods is unclear. In this work, we introduce a taxonomy of six common\nreal-world misinformation edits and propose a perturbation framework that\ngenerates valid, natural claim variations. Our multi-stage retrieval evaluation\nreveals that standard embedding models struggle with user-introduced edits,\nwhile LLM-distilled embeddings offer improved robustness at a higher\ncomputational cost. Although a strong reranker helps mitigate some issues, it\ncannot fully compensate for first-stage retrieval gaps. Addressing these\nretrieval gaps, our train- and inference-time mitigation approaches enhance\nin-domain robustness by up to 17 percentage points and boost out-of-domain\ngeneralization by 10 percentage points over baseline models. Overall, our\nfindings provide practical improvements to claim-matching systems, enabling\nmore reliable fact-checking of evolving misinformation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03417v2",
    "published_date": "2025-03-05 11:47:32 UTC",
    "updated_date": "2025-03-06 11:00:35 UTC"
  },
  {
    "arxiv_id": "2503.03410v1",
    "title": "Augmentation-Based Deep Learning for Identification of Circulating Tumor Cells",
    "authors": [
      "Martina Russo",
      "Giulia Bertolini",
      "Vera Cappelletti",
      "Cinzia De Marco",
      "Serena Di Cosimo",
      "Petra Paiè",
      "Nadia Brancati"
    ],
    "abstract": "Circulating tumor cells (CTCs) are crucial biomarkers in liquid biopsy,\noffering a noninvasive tool for cancer patient management. However, their\nidentification remains particularly challenging due to their limited number and\nheterogeneity. Labeling samples for contrast limits the generalization of\nfluorescence-based methods across different hospital datasets. Analyzing\nsingle-cell images enables detailed assessment of cell morphology, subcellular\nstructures, and phenotypic variations, often hidden in clustered images.\nDeveloping a method based on bright-field single-cell analysis could overcome\nthese limitations. CTCs can be isolated using an unbiased workflow combining\nParsortix technology, which selects cells based on size and deformability, with\nDEPArray technology, enabling precise visualization and selection of single\ncells. Traditionally, DEPArray-acquired digital images are manually analyzed,\nmaking the process time-consuming and prone to variability. In this study, we\npresent a Deep Learning-based classification pipeline designed to distinguish\nCTCs from leukocytes in blood samples, aimed to enhance diagnostic accuracy and\noptimize clinical workflows. Our approach employs images from the bright-field\nchannel acquired through DEPArray technology leveraging a ResNet-based CNN. To\nimprove model generalization, we applied three types of data augmentation\ntechniques and incorporated fluorescence (DAPI) channel images into the\ntraining phase, allowing the network to learn additional CTC-specific features.\nNotably, only bright-field images have been used for testing, ensuring the\nmodel's ability to identify CTCs without relying on fluorescence markers. The\nproposed model achieved an F1-score of 0.798, demonstrating its capability to\ndistinguish CTCs from leukocytes. These findings highlight the potential of DL\nin refining CTC analysis and advancing liquid biopsy applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T07, 68T10",
      "I.2; I.4; J.3"
    ],
    "primary_category": "eess.IV",
    "comment": "20 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.03410v1",
    "published_date": "2025-03-05 11:39:15 UTC",
    "updated_date": "2025-03-05 11:39:15 UTC"
  },
  {
    "arxiv_id": "2503.03395v1",
    "title": "AI-Driven Multi-Stage Computer Vision System for Defect Detection in Laser-Engraved Industrial Nameplates",
    "authors": [
      "Adhish Anitha Vilasan",
      "Stephan Jäger",
      "Noah Klarmann"
    ],
    "abstract": "Automated defect detection in industrial manufacturing is essential for\nmaintaining product quality and minimizing production errors. In air disc brake\nmanufacturing, ensuring the precision of laser-engraved nameplates is crucial\nfor accurate product identification and quality control. Engraving errors, such\nas misprints or missing characters, can compromise both aesthetics and\nfunctionality, leading to material waste and production delays. This paper\npresents a proof of concept for an AI-driven computer vision system that\ninspects and verifies laser-engraved nameplates, detecting defects in logos and\nalphanumeric strings. The system integrates object detection using YOLOv7,\noptical character recognition (OCR) with Tesseract, and anomaly detection\nthrough a residual variational autoencoder (ResVAE) along with other computer\nvision methods to enable comprehensive inspections at multiple stages.\nExperimental results demonstrate the system's effectiveness, achieving 91.33%\naccuracy and 100% recall, ensuring that defective nameplates are consistently\ndetected and addressed. This solution highlights the potential of AI-driven\nvisual inspection to enhance quality control, reduce manual inspection efforts,\nand improve overall manufacturing efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03395v1",
    "published_date": "2025-03-05 11:19:17 UTC",
    "updated_date": "2025-03-05 11:19:17 UTC"
  },
  {
    "arxiv_id": "2503.03391v1",
    "title": "Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks",
    "authors": [
      "Muhammet Hevesli",
      "Abegaz Mohammed Seid",
      "Aiman Erbad",
      "Mohamed Abdallah"
    ],
    "abstract": "Mobile edge computing (MEC)-enabled air-ground networks are a key component\nof 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles\n(UAVs) and high-altitude platform stations (HAPS) to provide dynamic services\nto ground IoT devices (IoTDs). These IoTDs support real-time applications\n(e.g., multimedia and Metaverse services) that demand high computational\nresources and strict quality of service (QoS) guarantees in terms of latency\nand task queue management. Given their limited energy and processing\ncapabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed\nprocessing, forming a multi-tier MEC system. This paper tackles the overall\nenergy minimization problem in MEC-enabled air-ground integrated networks\n(MAGIN) by jointly optimizing UAV trajectories, computing resource allocation,\nand queue-aware task offloading decisions. The optimization is challenging due\nto the nonconvex, nonlinear nature of this hierarchical system, which renders\ntraditional methods ineffective. We reformulate the problem as a multi-agent\nMarkov decision process (MDP) with continuous action spaces and heterogeneous\nagents, and propose a novel variant of multi-agent proximal policy optimization\nwith a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show\nthat MAPPO-BD outperforms baseline schemes, achieving superior energy savings\nand efficient resource management in MAGIN while meeting queue delay and edge\ncomputing constraints.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03391v1",
    "published_date": "2025-03-05 11:12:40 UTC",
    "updated_date": "2025-03-05 11:12:40 UTC"
  },
  {
    "arxiv_id": "2503.04832v5",
    "title": "Lightweight Embedded FPGA Deployment of Learned Image Compression with Knowledge Distillation and Hybrid Quantization",
    "authors": [
      "Alaa Mazouz",
      "Sumanta Chaudhuri",
      "Marco Cagnanzzo",
      "Mihai Mitrea",
      "Enzo Tartaglione",
      "Attilio Fiandrotti"
    ],
    "abstract": "Learnable Image Compression (LIC) has shown the potential to outperform\nstandardized video codecs in RD efficiency, prompting the research for\nhardware-friendly implementations. Most existing LIC hardware implementations\nprioritize latency to RD-efficiency and through an extensive exploration of the\nhardware design space. We present a novel design paradigm where the burden of\ntuning the design for a specific hardware platform is shifted towards model\ndimensioning and without compromising on RD-efficiency. First, we design a\nframework for distilling a leaner student LIC model from a reference teacher:\nby tuning a single model hyperparameters, we can meet the constraints of\ndifferent hardware platforms without a complex hardware design exploration.\nSecond, we propose a hardware-friendly implementation of the Generalized\nDivisive Normalization - GDN activation that preserves RD efficiency even post\nparameter quantization. Third, we design a pipelined FPGA configuration which\ntakes full advantage of available FPGA resources by leveraging parallel\nprocessing and optimizing resource allocation. Our experiments with a state of\nthe art LIC model show that we outperform all existing FPGA implementations\nwhile performing very close to the original model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "1. Submitted to IEEE Transactions on Circuits and Systems for Video\n  Technology in March 2025. 2. Corrected numerous mistakes from previous\n  versions in results, citations and metrics numbers in figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04832v5",
    "published_date": "2025-03-05 10:59:32 UTC",
    "updated_date": "2025-03-25 09:08:09 UTC"
  },
  {
    "arxiv_id": "2503.03361v1",
    "title": "From Infants to AI: Incorporating Infant-like Learning in Models Boosts Efficiency and Generalization in Learning Social Prediction Tasks",
    "authors": [
      "Shify Treger",
      "Shimon Ullman"
    ],
    "abstract": "Early in development, infants learn a range of useful concepts, which can be\nchallenging from a computational standpoint. This early learning comes together\nwith an initial understanding of aspects of the meaning of concepts, e.g.,\ntheir implications, causality, and using them to predict likely future events.\nAll this is accomplished in many cases with little or no supervision, and from\nrelatively few examples, compared with current network models. In learning\nabout objects and human-object interactions, early acquired and possibly innate\nconcepts are often used in the process of learning additional, more complex\nconcepts. In the current work, we model how early-acquired concepts are used in\nthe learning of subsequent concepts, and compare the results with standard deep\nnetwork modeling. We focused in particular on the use of the concepts of\nanimacy and goal attribution in learning to predict future events. We show that\nthe use of early concepts in the learning of new concepts leads to better\nlearning (higher accuracy) and more efficient learning (requiring less data).\nWe further show that this integration of early and new concepts shapes the\nrepresentation of the concepts acquired by the model. The results show that\nwhen the concepts were learned in a human-like manner, the emerging\nrepresentation was more useful, as measured in terms of generalization to novel\ndata and tasks. On a more general level, the results suggest that there are\nlikely to be basic differences in the conceptual structures acquired by current\nnetwork models compared to human learning.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03361v1",
    "published_date": "2025-03-05 10:40:19 UTC",
    "updated_date": "2025-03-05 10:40:19 UTC"
  },
  {
    "arxiv_id": "2503.03360v3",
    "title": "Transformers for molecular property prediction: Domain adaptation efficiently improves performance",
    "authors": [
      "Afnan Sultan",
      "Max Rausch-Dupont",
      "Shahrukh Khan",
      "Olga Kalinina",
      "Dietrich Klakow",
      "Andrea Volkamer"
    ],
    "abstract": "Over the past six years, molecular transformer models have become key tools\nin drug discovery. Most existing models are pre-trained on large, unlabeled\ndatasets such as ZINC or ChEMBL. However, the extent to which large-scale\npre-training improves molecular property prediction remains unclear. This study\nevaluates transformer models for this task while addressing their limitations.\nWe explore how pre-training dataset size and chemically informed objectives\nimpact performance. Our results show that increasing the dataset beyond\napproximately 400K to 800K molecules from large-scale unlabeled databases does\nnot enhance performance across seven datasets covering five ADME endpoints:\nlipophilicity, permeability, solubility (two datasets), microsomal stability\n(two datasets), and plasma protein binding. In contrast, domain adaptation on a\nsmall, domain-specific dataset (less than or equal 4K molecules) using\nmulti-task regression of physicochemical properties significantly boosts\nperformance (P-value less than 0.001). A model pre-trained on 400K molecules\nand adapted with domain-specific data outperforms larger models such as\nMolFormer and performs comparably to MolBERT. Benchmarks against Random Forest\n(RF) baselines using descriptors and Morgan fingerprints show that chemically\nand physically informed features consistently yield better performance across\nmodel types. While RF remains a strong baseline, we identify concrete practices\nto enhance transformer performance. Aligning pre-training and adaptation with\nchemically meaningful tasks and domain-relevant data presents a promising\ndirection for molecular property prediction. Our models are available on\nHuggingFace for easy use and adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03360v3",
    "published_date": "2025-03-05 10:40:09 UTC",
    "updated_date": "2025-05-22 14:27:33 UTC"
  },
  {
    "arxiv_id": "2503.03350v1",
    "title": "Leveraging Large Language Models to Develop Heuristics for Emerging Optimization Problems",
    "authors": [
      "Thomas Bömer",
      "Nico Koltermann",
      "Max Disselnmeyer",
      "Laura Dörr",
      "Anne Meyer"
    ],
    "abstract": "Combinatorial optimization problems often rely on heuristic algorithms to\ngenerate efficient solutions. However, the manual design of heuristics is\nresource-intensive and constrained by the designer's expertise. Recent advances\nin artificial intelligence, particularly large language models (LLMs), have\ndemonstrated the potential to automate heuristic generation through\nevolutionary frameworks. Recent works focus only on well-known combinatorial\noptimization problems like the traveling salesman problem and online bin\npacking problem when designing constructive heuristics. This study investigates\nwhether LLMs can effectively generate heuristics for niche, not yet broadly\nresearched optimization problems, using the unit-load pre-marshalling problem\nas an example case. We propose the Contextual Evolution of Heuristics (CEoH)\nframework, an extension of the Evolution of Heuristics (EoH) framework, which\nincorporates problem-specific descriptions to enhance in-context learning\nduring heuristic generation. Through computational experiments, we evaluate\nCEoH and EoH and compare the results. Results indicate that CEoH enables\nsmaller LLMs to generate high-quality heuristics more consistently and even\noutperform larger models. Larger models demonstrate robust performance with or\nwithout contextualized prompts. The generated heuristics exhibit scalability to\ndiverse instance configurations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review LION19: The 19th Learning and Intelligent OptimizatioN\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2503.03350v1",
    "published_date": "2025-03-05 10:22:49 UTC",
    "updated_date": "2025-03-05 10:22:49 UTC"
  },
  {
    "arxiv_id": "2503.03338v1",
    "title": "Navigating Intelligence: A Survey of Google OR-Tools and Machine Learning for Global Path Planning in Autonomous Vehicles",
    "authors": [
      "Alexandre Benoit",
      "Pedram Asef"
    ],
    "abstract": "We offer a new in-depth investigation of global path planning (GPP) for\nunmanned ground vehicles, an autonomous mining sampling robot named ROMIE. GPP\nis essential for ROMIE's optimal performance, which is translated into solving\nthe traveling salesman problem, a complex graph theory challenge that is\ncrucial for determining the most effective route to cover all sampling\nlocations in a mining field. This problem is central to enhancing ROMIE's\noperational efficiency and competitiveness against human labor by optimizing\ncost and time. The primary aim of this research is to advance GPP by\ndeveloping, evaluating, and improving a cost-efficient software and web\napplication. We delve into an extensive comparison and analysis of Google\noperations research (OR)-Tools optimization algorithms. Our study is driven by\nthe goal of applying and testing the limits of OR-Tools capabilities by\nintegrating Reinforcement Learning techniques for the first time. This enables\nus to compare these methods with OR-Tools, assessing their computational\neffectiveness and real-world application efficiency. Our analysis seeks to\nprovide insights into the effectiveness and practical application of each\ntechnique. Our findings indicate that Q-Learning stands out as the optimal\nstrategy, demonstrating superior efficiency by deviating only 1.2% on average\nfrom the optimal solutions across our datasets.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CE",
      "eess.SP"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03338v1",
    "published_date": "2025-03-05 10:12:22 UTC",
    "updated_date": "2025-03-05 10:12:22 UTC"
  },
  {
    "arxiv_id": "2503.03321v1",
    "title": "See What You Are Told: Visual Attention Sink in Large Multimodal Models",
    "authors": [
      "Seil Kang",
      "Jinyeong Kim",
      "Junhyeok Kim",
      "Seong Jae Hwang"
    ],
    "abstract": "Large multimodal models (LMMs) \"see\" images by leveraging the attention\nmechanism between text and visual tokens in the transformer decoder. Ideally,\nthese models should focus on key visual information relevant to the text token.\nHowever, recent findings indicate that LMMs have an extraordinary tendency to\nconsistently allocate high attention weights to specific visual tokens, even\nwhen these tokens are irrelevant to the corresponding text. In this study, we\ninvestigate the property behind the appearance of these irrelevant visual\ntokens and examine their characteristics. Our findings show that this behavior\narises due to the massive activation of certain hidden state dimensions, which\nresembles the attention sink found in language models. Hence, we refer to this\nphenomenon as the visual attention sink. In particular, our analysis reveals\nthat removing the irrelevant visual sink tokens does not impact model\nperformance, despite receiving high attention weights. Consequently, we recycle\nthe attention to these tokens as surplus resources, redistributing the\nattention budget to enhance focus on the image. To achieve this, we introduce\nVisual Attention Redistribution (VAR), a method that redistributes attention in\nimage-centric heads, which we identify as innately focusing on visual\ninformation. VAR can be seamlessly applied across different LMMs to improve\nperformance on a wide range of tasks, including general vision-language tasks,\nvisual hallucination tasks, and vision-centric tasks, all without the need for\nadditional training, models, or inference steps. Experimental results\ndemonstrate that VAR enables LMMs to process visual information more\neffectively by adjusting their internal attention mechanisms, offering a new\ndirection to enhancing the multimodal capabilities of LMMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03321v1",
    "published_date": "2025-03-05 09:55:07 UTC",
    "updated_date": "2025-03-05 09:55:07 UTC"
  },
  {
    "arxiv_id": "2503.04831v1",
    "title": "\"Only ChatGPT gets me\": An Empirical Analysis of GPT versus other Large Language Models for Emotion Detection in Text",
    "authors": [
      "Florian Lecourt",
      "Madalina Croitoru",
      "Konstantin Todorov"
    ],
    "abstract": "This work investigates the capabilities of large language models (LLMs) in\ndetecting and understanding human emotions through text. Drawing upon emotion\nmodels from psychology, we adopt an interdisciplinary perspective that\nintegrates computational and affective sciences insights. The main goal is to\nassess how accurately they can identify emotions expressed in textual\ninteractions and compare different models on this specific task. This research\ncontributes to broader efforts to enhance human-computer interaction, making\nartificial intelligence technologies more responsive and sensitive to users'\nemotional nuances. By employing a methodology that involves comparisons with a\nstate-of-the-art model on the GoEmotions dataset, we aim to gauge LLMs'\neffectiveness as a system for emotional analysis, paving the way for potential\napplications in various fields that require a nuanced understanding of human\nlanguage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04831v1",
    "published_date": "2025-03-05 09:47:49 UTC",
    "updated_date": "2025-03-05 09:47:49 UTC"
  },
  {
    "arxiv_id": "2503.22688v2",
    "title": "CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation",
    "authors": [
      "Peiding Wang",
      "Li Zhang",
      "Fang Liu",
      "Lin Shi",
      "Minxiao Li",
      "Bo Shen",
      "An Fu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in\ncode generation tasks and have become indispensable programming assistants for\ndevelopers. However, existing code generation benchmarks primarily assess the\nfunctional correctness of code generated by LLMs in single-turn interactions,\noffering limited insight into their capabilities to generate code that strictly\nfollows users' instructions, especially in multi-turn interaction scenarios. In\nthis paper, we introduce CodeIF-Bench, a benchmark for evaluating LLMs'\ninstruction-following capabilities in interactive code generation.\nSpecifically, CodeIF-Bench incorporates nine types of verifiable instructions\naligned with the real-world software development requirements, which can be\nindependently and objectively validated through specified test cases,\nfacilitating the evaluation of instruction-following capability in multi-turn\ninteractions. We evaluate nine prominent LLMs using CodeIF-Bench, and the\nexperimental results reveal a significant disparity between their basic\nprogramming capability and instruction-following capability, particularly as\ntask complexity, context length, and the number of dialogue rounds increase.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22688v2",
    "published_date": "2025-03-05 09:47:02 UTC",
    "updated_date": "2025-05-08 04:56:05 UTC"
  },
  {
    "arxiv_id": "2503.05823v1",
    "title": "Introduction to Artificial Consciousness: History, Current Trends and Ethical Challenges",
    "authors": [
      "Aïda Elamrani"
    ],
    "abstract": "With the significant progress of artificial intelligence (AI) and\nconsciousness science, artificial consciousness (AC) has recently gained\npopularity. This work provides a broad overview of the main topics and current\ntrends in AC. The first part traces the history of this interdisciplinary field\nto establish context and clarify key terminology, including the distinction\nbetween Weak and Strong AC. The second part examines major trends in AC\nimplementations, emphasising the synergy between Global Workspace and Attention\nSchema, as well as the problem of evaluating the internal states of artificial\nsystems. The third part analyses the ethical dimension of AC development,\nrevealing both critical risks and transformative opportunities. The last part\noffers recommendations to guide AC research responsibly, and outlines the\nlimitations of this study as well as avenues for future research. The main\nconclusion is that while AC appears both indispensable and inevitable for\nscientific progress, serious efforts are required to address the far-reaching\nimpact of this innovative research path.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "65 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.05823v1",
    "published_date": "2025-03-05 09:34:36 UTC",
    "updated_date": "2025-03-05 09:34:36 UTC"
  },
  {
    "arxiv_id": "2503.03283v1",
    "title": "Exploring specialization and sensitivity of convolutional neural networks in the context of simultaneous image augmentations",
    "authors": [
      "Pavel Kharyuk",
      "Sergey Matveev",
      "Ivan Oseledets"
    ],
    "abstract": "Drawing parallels with the way biological networks are studied, we adapt the\ntreatment--control paradigm to explainable artificial intelligence research and\nenrich it through multi-parametric input alterations. In this study, we propose\na framework for investigating the internal inference impacted by input data\naugmentations. The internal changes in network operation are reflected in\nactivation changes measured by variance, which can be decomposed into\ncomponents related to each augmentation, employing Sobol indices and Shapley\nvalues. These quantities enable one to visualize sensitivity to different\nvariables and use them for guided masking of activations. In addition, we\nintroduce a way of single-class sensitivity analysis where the candidates are\nfiltered according to their matching to prediction bias generated by targeted\ndamaging of the activations. Relying on the observed parallels, we assume that\nthe developed framework can potentially be transferred to studying biological\nneural networks in complex environments.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA",
      "68T07",
      "I.2.6; G.3; I.2.10"
    ],
    "primary_category": "stat.ML",
    "comment": "26 pages; main text: 5 figures, 4 tables; appendix: 4 sections, 3\n  tables; supplementary: 7 files (figures S1-S6: packed as 7z archive, S7:\n  single pdf file)",
    "pdf_url": "http://arxiv.org/pdf/2503.03283v1",
    "published_date": "2025-03-05 09:09:01 UTC",
    "updated_date": "2025-03-05 09:09:01 UTC"
  },
  {
    "arxiv_id": "2503.04830v3",
    "title": "Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents",
    "authors": [
      "Jingying Zeng",
      "Hui Liu",
      "Zhenwei Dai",
      "Xianfeng Tang",
      "Chen Luo",
      "Samarth Varshney",
      "Zhen Li",
      "Qi He"
    ],
    "abstract": "With the advancement of conversational large language models (LLMs), several\nLLM-based Conversational Shopping Agents (CSA) have been developed to help\ncustomers smooth their online shopping. The primary objective in building an\nengaging and trustworthy CSA is to ensure the agent's responses about product\nfactoids are accurate and factually grounded. However, two challenges remain.\nFirst, LLMs produce hallucinated or unsupported claims. Such inaccuracies risk\nspreading misinformation and diminishing customer trust. Second, without\nproviding knowledge source attribution in CSA response, customers struggle to\nverify LLM-generated information. To address both challenges, we present an\neasily productionized solution that enables a ''citation experience'' to our\ncustomers. We build auto-evaluation metrics to holistically evaluate LLM's\ngrounding and attribution capabilities, suggesting that citation generation\nparadigm substantially improves grounding performance by 13.83%. To deploy this\ncapability at scale, we introduce Multi-UX-Inference system, which appends\nsource citations to LLM outputs while preserving existing user experience\nfeatures and supporting scalable inference. Large-scale online A/B tests show\nthat grounded CSA responses improves customer engagement by 3% - 10%, depending\non UX variations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04830v3",
    "published_date": "2025-03-05 08:58:35 UTC",
    "updated_date": "2025-05-13 05:02:11 UTC"
  },
  {
    "arxiv_id": "2503.03274v1",
    "title": "Benchmarking Dynamic SLO Compliance in Distributed Computing Continuum Systems",
    "authors": [
      "Alfreds Lapkovskis",
      "Boris Sedlak",
      "Sindri Magnússon",
      "Schahram Dustdar",
      "Praveen Kumar Donta"
    ],
    "abstract": "Ensuring Service Level Objectives (SLOs) in large-scale architectures, such\nas Distributed Computing Continuum Systems (DCCS), is challenging due to their\nheterogeneous nature and varying service requirements across different devices\nand applications. Additionally, unpredictable workloads and resource\nlimitations lead to fluctuating performance and violated SLOs. To improve SLO\ncompliance in DCCS, one possibility is to apply machine learning; however, the\ndesign choices are often left to the developer. To that extent, we provide a\nbenchmark of Active Inference -- an emerging method from neuroscience --\nagainst three established reinforcement learning algorithms (Deep Q-Network,\nAdvantage Actor-Critic, and Proximal Policy Optimization). We consider a\nrealistic DCCS use case: an edge device running a video conferencing\napplication alongside a WebSocket server streaming videos. Using one of the\nrespective algorithms, we continuously monitor key performance metrics, such as\nlatency and bandwidth usage, to dynamically adjust parameters -- including the\nnumber of streams, frame rate, and resolution -- to optimize service quality\nand user experience. To test algorithms' adaptability to constant system\nchanges, we simulate dynamically changing SLOs and both instant and gradual\ndata-shift scenarios, such as network bandwidth limitations and fluctuating\ndevice thermal states. Although the evaluated algorithms all showed advantages\nand limitations, our findings demonstrate that Active Inference is a promising\napproach for ensuring SLO compliance in DCCS, offering lower memory usage,\nstable CPU utilization, and fast convergence.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.PF"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03274v1",
    "published_date": "2025-03-05 08:56:26 UTC",
    "updated_date": "2025-03-05 08:56:26 UTC"
  },
  {
    "arxiv_id": "2503.03269v2",
    "title": "Conformal Transformations for Symmetric Power Transformers",
    "authors": [
      "Saurabh Kumar",
      "Jacob Buckman",
      "Carles Gelada",
      "Sean Zhang"
    ],
    "abstract": "Transformers with linear attention offer significant computational advantages\nover softmax-based transformers but often suffer from degraded performance. The\nsymmetric power (sympow) transformer, a particular type of linear transformer,\naddresses some of this performance gap by leveraging symmetric tensor\nembeddings, achieving comparable performance to softmax transformers. However,\nthe finite capacity of the recurrent state in sympow transformers limits their\nability to retain information, leading to performance degradation when scaling\nthe training or evaluation context length. To address this issue, we propose\nthe conformal-sympow transformer, which dynamically frees up capacity using\ndata-dependent multiplicative gating and adaptively stores information using\ndata-dependent rotary embeddings. Preliminary experiments on the LongCrawl64\ndataset demonstrate that conformal-sympow overcomes the limitations of sympow\ntransformers, achieving robust performance across scaled training and\nevaluation contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "SCOPE Workshop at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03269v2",
    "published_date": "2025-03-05 08:50:53 UTC",
    "updated_date": "2025-05-03 05:24:08 UTC"
  },
  {
    "arxiv_id": "2503.03262v1",
    "title": "Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions",
    "authors": [
      "Nadya Abdel Madjid",
      "Abdulrahman Ahmad",
      "Murad Mebrahtu",
      "Yousef Babaa",
      "Abdelmoamen Nasser",
      "Sumbal Malik",
      "Bilal Hassan",
      "Naoufel Werghi",
      "Jorge Dias",
      "Majid Khonji"
    ],
    "abstract": "As the potential for autonomous vehicles to be integrated on a large scale\ninto modern traffic systems continues to grow, ensuring safe navigation in\ndynamic environments is crucial for smooth integration. To guarantee safety and\nprevent collisions, autonomous vehicles must be capable of accurately\npredicting the trajectories of surrounding traffic agents. Over the past\ndecade, significant efforts from both academia and industry have been dedicated\nto designing solutions for precise trajectory forecasting. These efforts have\nproduced a diverse range of approaches, raising questions about the differences\nbetween these methods and whether trajectory prediction challenges have been\nfully addressed. This paper reviews a substantial portion of recent trajectory\nprediction methods and devises a taxonomy to classify existing solutions. A\ngeneral overview of the prediction pipeline is also provided, covering input\nand output modalities, modeling features, and prediction paradigms discussed in\nthe literature. In addition, the paper discusses active research areas within\ntrajectory prediction, addresses the posed research questions, and highlights\nthe remaining research gaps and challenges.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03262v1",
    "published_date": "2025-03-05 08:38:51 UTC",
    "updated_date": "2025-03-05 08:38:51 UTC"
  },
  {
    "arxiv_id": "2503.03258v1",
    "title": "Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs",
    "authors": [
      "Runlin Lei",
      "Jiarui Ji",
      "Haipeng Ding",
      "Lu Yi",
      "Zhewei Wei",
      "Yongchao Liu",
      "Chuntao Hong"
    ],
    "abstract": "With the rise of large language models (LLMs), there has been growing\ninterest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging\nLLMs as predictors, GFMs have demonstrated impressive generalizability across\nvarious tasks and datasets. However, existing research on LLMs as predictors\nhas predominantly focused on static graphs, leaving their potential in dynamic\ngraph prediction unexplored. In this work, we pioneer using LLMs for predictive\ntasks on dynamic graphs. We identify two key challenges: the constraints\nimposed by context length when processing large-scale historical data and the\nsignificant variability in domain characteristics, both of which complicate the\ndevelopment of a unified predictor. To address these challenges, we propose the\nGraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages\ncollaborative LLMs. In contrast to using a single LLM as the predictor, GAD\nincorporates global and local summary agents to generate domain-specific\nknowledge, enhancing its transferability across domains. Additionally,\nknowledge reflection agents enable adaptive updates to GAD's knowledge,\nmaintaining a unified and self-consistent architecture. In experiments, GAD\ndemonstrates performance comparable to or even exceeds that of full-supervised\ngraph neural networks without dataset-specific training. Finally, to enhance\nthe task-specific performance of LLM-based predictors, we discuss potential\nimprovements, such as dataset-specific fine-tuning to LLMs. By developing\ntailored strategies for different tasks, we provide new insights for the future\ndesign of LLM-based predictors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03258v1",
    "published_date": "2025-03-05 08:28:11 UTC",
    "updated_date": "2025-03-05 08:28:11 UTC"
  },
  {
    "arxiv_id": "2503.03792v1",
    "title": "Rebalanced Multimodal Learning with Data-aware Unimodal Sampling",
    "authors": [
      "Qingyuan Jiang",
      "Zhouyang Chi",
      "Xiao Ma",
      "Qirong Mao",
      "Yang Yang",
      "Jinhui Tang"
    ],
    "abstract": "To address the modality learning degeneration caused by modality imbalance,\nexisting multimodal learning~(MML) approaches primarily attempt to balance the\noptimization process of each modality from the perspective of model learning.\nHowever, almost all existing methods ignore the modality imbalance caused by\nunimodal data sampling, i.e., equal unimodal data sampling often results in\ndiscrepancies in informational content, leading to modality imbalance.\nTherefore, in this paper, we propose a novel MML approach called\n\\underline{D}ata-aware \\underline{U}nimodal \\underline{S}ampling~(\\method),\nwhich aims to dynamically alleviate the modality imbalance caused by sampling.\nSpecifically, we first propose a novel cumulative modality discrepancy to\nmonitor the multimodal learning process. Based on the learning status, we\npropose a heuristic and a reinforcement learning~(RL)-based data-aware unimodal\nsampling approaches to adaptively determine the quantity of sampled data at\neach iteration, thus alleviating the modality imbalance from the perspective of\nsampling. Meanwhile, our method can be seamlessly incorporated into almost all\nexisting multimodal learning approaches as a plugin. Experiments demonstrate\nthat \\method~can achieve the best performance by comparing with diverse\nstate-of-the-art~(SOTA) baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03792v1",
    "published_date": "2025-03-05 08:19:31 UTC",
    "updated_date": "2025-03-05 08:19:31 UTC"
  },
  {
    "arxiv_id": "2503.07638v2",
    "title": "Leveraging Taxonomy Similarity for Next Activity Prediction in Patient Treatment",
    "authors": [
      "Martin Kuhn",
      "Joscha Grüger",
      "Tobias Geyer",
      "Ralph Bergmann"
    ],
    "abstract": "The rapid progress in modern medicine presents physicians with complex\nchallenges when planning patient treatment. Techniques from the field of\nPredictive Business Process Monitoring, like Next-activity-prediction (NAP) can\nbe used as a promising technique to support physicians in treatment planning,\nby proposing a possible next treatment step. Existing patient data, often in\nthe form of electronic health records, can be analyzed to recommend the next\nsuitable step in the treatment process. However, the use of patient data poses\nmany challenges due to its knowledge-intensive character, high variability and\nscarcity of medical data. To overcome these challenges, this article examines\nthe use of the knowledge encoded in taxonomies to improve and explain the\nprediction of the next activity in the treatment process. This study proposes\nthe TS4NAP approach, which uses medical taxonomies (ICD-10-CM and ICD-10-PCS)\nin combination with graph matching to assess the similarities of medical codes\nto predict the next treatment step. The effectiveness of the proposed approach\nwill be evaluated using event logs that are derived from the MIMIC-IV dataset.\nThe results highlight the potential of using domain-specific knowledge held in\ntaxonomies to improve the prediction of the next activity, and thus can improve\ntreatment planning and decision-making by making the predictions more\nexplainable.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07638v2",
    "published_date": "2025-03-05 08:19:17 UTC",
    "updated_date": "2025-03-17 13:52:26 UTC"
  },
  {
    "arxiv_id": "2503.03245v2",
    "title": "Less is more? Rewards in RL for Cyber Defence",
    "authors": [
      "Elizabeth Bates",
      "Chris Hicks",
      "Vasilios Mavroudis"
    ],
    "abstract": "The last few years have seen an explosion of interest in autonomous cyber\ndefence agents based on deep reinforcement learning. Such agents are typically\ntrained in a cyber gym environment, also known as a cyber simulator, at least\n32 of which have already been built. Most, if not all cyber gyms provide dense\n\"scaffolded\" reward functions which combine many penalties or incentives for a\nrange of (un)desirable states and costly actions. Whilst dense rewards help\nalleviate the challenge of exploring complex environments, yielding seemingly\neffective strategies from relatively few environment steps; they are also known\nto bias the solutions an agent can find, potentially towards suboptimal\nsolutions. This is especially a problem in complex cyber environments where\npolicy weaknesses may not be noticed until exploited by an adversary. In this\nwork we set out to evaluate whether sparse reward functions might enable\ntraining more effective cyber defence agents. Towards this goal we first break\ndown several evaluation limitations in existing work by proposing a ground\ntruth evaluation score that goes beyond the standard RL paradigm used to train\nand evaluate agents. By adapting a well-established cyber gym to accommodate\nour methodology and ground truth score, we propose and evaluate two sparse\nreward mechanisms and compare them with a typical dense reward. Our evaluation\nconsiders a range of network sizes, from 2 to 50 nodes, and both reactive and\nproactive defensive actions. Our results show that sparse rewards, particularly\npositive reinforcement for an uncompromised network state, enable the training\nof more effective cyber defence agents. Furthermore, we show that sparse\nrewards provide more stable training than dense rewards, and that both\neffectiveness and training stability are robust to a variety of cyber\nenvironment considerations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "4 Pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03245v2",
    "published_date": "2025-03-05 07:53:39 UTC",
    "updated_date": "2025-03-10 15:51:39 UTC"
  },
  {
    "arxiv_id": "2503.03238v1",
    "title": "FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4",
    "authors": [
      "Jiarui Yao",
      "Ruida Wang",
      "Tong Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have displayed astonishing abilities in various\ntasks, especially in text generation, classification, question answering, etc.\nHowever, the reasoning ability of LLMs still faces many debates. The inherent\nambiguity of Natural Language (NL) limits LLMs' ability to perform verifiable\nreasoning, making its answers lack coherence and trustworthy support. To tackle\nthe above problems, we propose a novel framework named FANS: Formal ANswer\nSelection for Natural Language Math Reasoning Using Lean4. To the best of our\nknowledge, it is the first framework that utilizes Lean4 to enhance LLMs' NL\nmath reasoning ability. In particular, given an NL math question and\nLLM-generated answers, FANS first translates it into Lean4 theorem statements.\nThen it tries to prove it using a Lean4 prover and verify it by Lean4. Finally,\nit uses the FL result to assist in answer selection. It enhances LLMs' NL math\nability in providing a computer-verifiable solution for its correct answer and\nproposes an alternative method for answer selection beyond the reward model.\nExtensive experiments indicate the effectiveness of our framework. It can\nimprove the accuracy rate of reward model enhanced LLMs in the MATH-500 dataset\nby at most 1.91% and AMC-23 by at most 8.33% on strong reward-model baselines.\nIn some particular fields like number theory that Lean4 experts in, we can even\nselect all correct solutions. The qualitative analysis also shows our framework\ncan make NL results formally backed by Lean4 proofs. As a pioneering work in\nthe corresponding field, we will open-source all our models and datasets to\nfurther boost the development of the field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03238v1",
    "published_date": "2025-03-05 07:34:53 UTC",
    "updated_date": "2025-03-05 07:34:53 UTC"
  },
  {
    "arxiv_id": "2503.03791v1",
    "title": "Predicting Team Performance from Communications in Simulated Search-and-Rescue",
    "authors": [
      "Ali Jalal-Kamali",
      "Nikolos Gurney",
      "David Pynadath"
    ],
    "abstract": "Understanding how individual traits influence team performance is valuable,\nbut these traits are not always directly observable. Prior research has\ninferred traits like trust from behavioral data. We analyze conversational data\nto identify team traits and their correlation with teaming outcomes. Using\ntranscripts from a Minecraft-based search-and-rescue experiment, we apply topic\nmodeling and clustering to uncover key interaction patterns. Our findings show\nthat variations in teaming outcomes can be explained through these inferences,\nwith different levels of predictive power derived from individual traits and\nteam dynamics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03791v1",
    "published_date": "2025-03-05 07:20:27 UTC",
    "updated_date": "2025-03-05 07:20:27 UTC"
  },
  {
    "arxiv_id": "2503.03789v1",
    "title": "Positive-Unlabeled Diffusion Models for Preventing Sensitive Data Generation",
    "authors": [
      "Hiroshi Takahashi",
      "Tomoharu Iwata",
      "Atsutoshi Kumagai",
      "Yuuki Yamanaka",
      "Tomoya Yamashita"
    ],
    "abstract": "Diffusion models are powerful generative models but often generate sensitive\ndata that are unwanted by users, mainly because the unlabeled training data\nfrequently contain such sensitive data. Since labeling all sensitive data in\nthe large-scale unlabeled training data is impractical, we address this problem\nby using a small amount of labeled sensitive data. In this paper, we propose\npositive-unlabeled diffusion models, which prevent the generation of sensitive\ndata using unlabeled and sensitive data. Our approach can approximate the\nevidence lower bound (ELBO) for normal (negative) data using only unlabeled and\nsensitive (positive) data. Therefore, even without labeled normal data, we can\nmaximize the ELBO for normal data and minimize it for labeled sensitive data,\nensuring the generation of only normal data. Through experiments across various\ndatasets and settings, we demonstrated that our approach can prevent the\ngeneration of sensitive images without compromising image quality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR2025. Code is available at\n  https://github.com/takahashihiroshi/pudm",
    "pdf_url": "http://arxiv.org/pdf/2503.03789v1",
    "published_date": "2025-03-05 07:17:48 UTC",
    "updated_date": "2025-03-05 07:17:48 UTC"
  },
  {
    "arxiv_id": "2503.04829v1",
    "title": "StickMotion: Generating 3D Human Motions by Drawing a Stickman",
    "authors": [
      "Tao Wang",
      "Zhihua Wu",
      "Qiaozhi He",
      "Jiaming Chu",
      "Ling Qian",
      "Yu Cheng",
      "Junliang Xing",
      "Jian Zhao",
      "Lei Jin"
    ],
    "abstract": "Text-to-motion generation, which translates textual descriptions into human\nmotions, has been challenging in accurately capturing detailed user-imagined\nmotions from simple text inputs. This paper introduces StickMotion, an\nefficient diffusion-based network designed for multi-condition scenarios, which\ngenerates desired motions based on traditional text and our proposed stickman\nconditions for global and local control of these motions, respectively. We\naddress the challenges introduced by the user-friendly stickman from three\nperspectives: 1) Data generation. We develop an algorithm to generate\nhand-drawn stickmen automatically across different dataset formats. 2)\nMulti-condition fusion. We propose a multi-condition module that integrates\ninto the diffusion process and obtains outputs of all possible condition\ncombinations, reducing computational complexity and enhancing StickMotion's\nperformance compared to conventional approaches with the self-attention module.\n3) Dynamic supervision. We empower StickMotion to make minor adjustments to the\nstickman's position within the output sequences, generating more natural\nmovements through our proposed dynamic supervision strategy. Through\nquantitative experiments and user studies, sketching stickmen saves users about\n51.5% of their time generating motions consistent with their imagination. Our\ncodes, demos, and relevant data will be released to facilitate further research\nand validation within the scientific community.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures, accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04829v1",
    "published_date": "2025-03-05 07:16:14 UTC",
    "updated_date": "2025-03-05 07:16:14 UTC"
  },
  {
    "arxiv_id": "2503.22687v1",
    "title": "Qieemo: Speech Is All You Need in the Emotion Recognition in Conversations",
    "authors": [
      "Jinming Chen",
      "Jingyi Fang",
      "Yuanzhong Zheng",
      "Yaoxuan Wang",
      "Haojun Fei"
    ],
    "abstract": "Emotion recognition plays a pivotal role in intelligent human-machine\ninteraction systems. Multimodal approaches benefit from the fusion of diverse\nmodalities, thereby improving the recognition accuracy. However, the lack of\nhigh-quality multimodal data and the challenge of achieving optimal alignment\nbetween different modalities significantly limit the potential for improvement\nin multimodal approaches. In this paper, the proposed Qieemo framework\neffectively utilizes the pretrained automatic speech recognition (ASR) model\nbackbone which contains naturally frame aligned textual and emotional features,\nto achieve precise emotion classification solely based on the audio modality.\nFurthermore, we design the multimodal fusion (MMF) module and cross-modal\nattention (CMA) module in order to fuse the phonetic posteriorgram (PPG) and\nemotional features extracted by the ASR encoder for improving recognition\naccuracy. The experimental results on the IEMOCAP dataset demonstrate that\nQieemo outperforms the benchmark unimodal, multimodal, and self-supervised\nmodels with absolute improvements of 3.0%, 1.2%, and 1.9% respectively.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.22687v1",
    "published_date": "2025-03-05 07:02:30 UTC",
    "updated_date": "2025-03-05 07:02:30 UTC"
  },
  {
    "arxiv_id": "2503.04828v1",
    "title": "Beyond Next Word Prediction: Developing Comprehensive Evaluation Frameworks for measuring LLM performance on real world applications",
    "authors": [
      "Vishakha Agrawal",
      "Archie Chaudhury",
      "Shreya Agrawal"
    ],
    "abstract": "While Large Language Models (LLMs) are fundamentally next-token prediction\nsystems, their practical applications extend far beyond this basic function.\nFrom natural language processing and text generation to conversational\nassistants and software use, LLMs have numerous use-cases, and have already\nacquired a significant degree of enterprise adoption. To evaluate such models,\nstatic evaluation datasets, consisting of a set of prompts and their\ncorresponding ground truths, are often used to benchmark the efficacy of the\nmodel for a particular task. In this paper, we provide the basis for a more\ncomprehensive evaluation framework, based upon a traditional game and\ntool-based architecture that enables a more overarching measurement of a\nmodel's capabilities. For simplicity, we provide a generalized foundation that\ncan be extended, without significant alteration, to numerous scenarios, from\nspecific use cases such as supply chain management or financial reasoning, to\nabstract measurements such as ethics or safety.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04828v1",
    "published_date": "2025-03-05 06:44:38 UTC",
    "updated_date": "2025-03-05 06:44:38 UTC"
  },
  {
    "arxiv_id": "2503.04827v1",
    "title": "Preserving Cultural Identity with Context-Aware Translation Through Multi-Agent AI Systems",
    "authors": [
      "Mahfuz Ahmed Anik",
      "Abdur Rahman",
      "Azmine Toushik Wasi",
      "Md Manjurul Ahsan"
    ],
    "abstract": "Language is a cornerstone of cultural identity, yet globalization and the\ndominance of major languages have placed nearly 3,000 languages at risk of\nextinction. Existing AI-driven translation models prioritize efficiency but\noften fail to capture cultural nuances, idiomatic expressions, and historical\nsignificance, leading to translations that marginalize linguistic diversity. To\naddress these challenges, we propose a multi-agent AI framework designed for\nculturally adaptive translation in underserved language communities. Our\napproach leverages specialized agents for translation, interpretation, content\nsynthesis, and bias evaluation, ensuring that linguistic accuracy and cultural\nrelevance are preserved. Using CrewAI and LangChain, our system enhances\ncontextual fidelity while mitigating biases through external validation.\nComparative analysis shows that our framework outperforms GPT-4o, producing\ncontextually rich and culturally embedded translations, a critical advancement\nfor Indigenous, regional, and low-resource languages. This research underscores\nthe potential of multi-agent AI in fostering equitable, sustainable, and\nculturally sensitive NLP technologies, aligning with the AI Governance,\nCultural NLP, and Sustainable NLP pillars of Language Models for Underserved\nCommunities. Our full experimental codebase is publicly available at:\nhttps://github.com/ciol-researchlab/Context-Aware_Translation_MAS",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in NAACL 2025 Workshop on Language Models for Underserved\n  Communities (https://openreview.net/forum?id=RiCfefEHII)",
    "pdf_url": "http://arxiv.org/pdf/2503.04827v1",
    "published_date": "2025-03-05 06:43:59 UTC",
    "updated_date": "2025-03-05 06:43:59 UTC"
  },
  {
    "arxiv_id": "2503.03215v1",
    "title": "COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence",
    "authors": [
      "Wentao Li",
      "Congcong Wang",
      "Xiaoxiao Cui",
      "Zhi Liu",
      "Wei Guo",
      "Lizhen Cui"
    ],
    "abstract": "Open Source Intelligence (OSINT) requires the integration and reasoning of\ndiverse multimodal data, presenting significant challenges in deriving\nactionable insights. Traditional approaches, including multimodal large\nlanguage models (MLLMs), often struggle to infer complex contextual\nrelationships or deliver comprehensive intelligence from unstructured data\nsources. In this paper, we introduce COSINT-Agent, a knowledge-driven\nmultimodal agent tailored to address the challenges of OSINT in the Chinese\ndomain. COSINT-Agent seamlessly integrates the perceptual capabilities of\nfine-tuned MLLMs with the structured reasoning power of the Entity-Event-Scene\nKnowledge Graph (EES-KG). Central to COSINT-Agent is the innovative EES-Match\nframework, which bridges COSINT-MLLM and EES-KG, enabling systematic\nextraction, reasoning, and contextualization of multimodal insights. This\nintegration facilitates precise entity recognition, event interpretation, and\ncontext retrieval, effectively transforming raw multimodal data into actionable\nintelligence. Extensive experiments validate the superior performance of\nCOSINT-Agent across core OSINT tasks, including entity recognition, EES\ngeneration, and context matching. These results underscore its potential as a\nrobust and scalable solution for advancing automated multimodal reasoning and\nenhancing the effectiveness of OSINT methodologies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03215v1",
    "published_date": "2025-03-05 06:16:15 UTC",
    "updated_date": "2025-03-05 06:16:15 UTC"
  },
  {
    "arxiv_id": "2503.03211v1",
    "title": "NodeReg: Mitigating the Imbalance and Distribution Shift Effects in Semi-Supervised Node Classification via Norm Consistency",
    "authors": [
      "Shenzhi Yang",
      "Jun Xia",
      "Jingbo Zhou",
      "Xingkai Yao",
      "Xiaofang Zhang"
    ],
    "abstract": "Aggregating information from neighboring nodes benefits graph neural networks\n(GNNs) in semi-supervised node classification tasks. Nevertheless, this\nmechanism also renders nodes susceptible to the influence of their neighbors.\nFor instance, this will occur when the neighboring nodes are imbalanced or the\nneighboring nodes contain noise, which can even affect the GNN's ability to\ngeneralize out of distribution. We find that ensuring the consistency of the\nnorm for node representations can significantly reduce the impact of these two\nissues on GNNs. To this end, we propose a regularized optimization method\ncalled NodeReg that enforces the consistency of node representation norms. This\nmethod is simple but effective and satisfies Lipschitz continuity, thus\nfacilitating stable optimization and significantly improving semi-supervised\nnode classification performance under the above two scenarios. To illustrate,\nin the imbalance scenario, when training a GCN with an imbalance ratio of 0.1,\nNodeReg outperforms the most competitive baselines by 1.4%-25.9% in F1 score\nacross five public datasets. Similarly, in the distribution shift scenario,\nNodeReg outperforms the most competitive baseline by 1.4%-3.1% in accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03211v1",
    "published_date": "2025-03-05 06:06:16 UTC",
    "updated_date": "2025-03-05 06:06:16 UTC"
  },
  {
    "arxiv_id": "2503.03205v2",
    "title": "MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving",
    "authors": [
      "Ruida Wang",
      "Rui Pan",
      "Yuxin Li",
      "Jipeng Zhang",
      "Yizhen Jia",
      "Shizhe Diao",
      "Renjie Pi",
      "Junjie Hu",
      "Tong Zhang"
    ],
    "abstract": "Solving mathematical problems using computer-verifiable languages like Lean\nhas significantly impacted mathematical and computer science communities.\nState-of-the-art methods utilize single Large Language Models (LLMs) as agents\nor provers to either generate complete proof or perform tree searches. However,\nsingle-agent methods inherently lack a structured way to combine high-level\nreasoning in Natural Language (NL) with Formal Language (FL) verification\nfeedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long\nChain-of-Thought framework, (to the best of our knowledge), the first\nmulti-agent framework for Lean4 theorem proving that balance high-level NL\nreasoning and FL verification in Long CoT. Using this structured interaction,\nour approach enables deeper insights and long-term coherence in proof\ngeneration, with which past methods struggle. We do this by leveraging emergent\nformal reasoning ability in Long CoT using our novel LoT-Transfer Learning\ntraining-inference pipeline. Extensive experiments show that our framework\nachieves a 61.07% accuracy rate on the Lean4 version of the MiniF2F-Test\ndataset, largely outperforming GPT-4 (22.95%), single-agent tree search\n(InternLM-Step-Prover, 50.70%), and whole-proof generation (Godel-Prover,\n55.33%) baselines. Furthermore, our findings highlight the potential of\ncombining Long CoT with formal verification for a more insightful generation in\na broader perspective.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03205v2",
    "published_date": "2025-03-05 05:50:31 UTC",
    "updated_date": "2025-03-10 17:39:42 UTC"
  },
  {
    "arxiv_id": "2503.03201v1",
    "title": "Towards Robust Universal Information Extraction: Benchmark, Evaluation, and Solution",
    "authors": [
      "Jizhao Zhu",
      "Akang Shi",
      "Zixuan Li",
      "Long Bai",
      "Xiaolong Jin",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ],
    "abstract": "In this paper, we aim to enhance the robustness of Universal Information\nExtraction (UIE) by introducing a new benchmark dataset, a comprehensive\nevaluation, and a feasible solution. Existing robust benchmark datasets have\ntwo key limitations: 1) They generate only a limited range of perturbations for\na single Information Extraction (IE) task, which fails to evaluate the\nrobustness of UIE models effectively; 2) They rely on small models or\nhandcrafted rules to generate perturbations, often resulting in unnatural\nadversarial examples. Considering the powerful generation capabilities of Large\nLanguage Models (LLMs), we introduce a new benchmark dataset for Robust UIE,\ncalled RUIE-Bench, which utilizes LLMs to generate more diverse and realistic\nperturbations across different IE tasks. Based on this dataset, we\ncomprehensively evaluate existing UIE models and reveal that both LLM-based\nmodels and other models suffer from significant performance drops. To improve\nrobustness and reduce training costs, we propose a data-augmentation solution\nthat dynamically selects hard samples for iterative training based on the\nmodel's inference loss. Experimental results show that training with only\n\\textbf{15\\%} of the data leads to an average \\textbf{7.5\\%} relative\nperformance improvement across three IE tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03201v1",
    "published_date": "2025-03-05 05:39:29 UTC",
    "updated_date": "2025-03-05 05:39:29 UTC"
  },
  {
    "arxiv_id": "2503.16477v1",
    "title": "LeRAAT: LLM-Enabled Real-Time Aviation Advisory Tool",
    "authors": [
      "Marc R. Schlichting",
      "Vale Rasmussen",
      "Heba Alazzeh",
      "Houjun Liu",
      "Kiana Jafari",
      "Amelia F. Hardy",
      "Dylan M. Asmar",
      "Mykel J. Kochenderfer"
    ],
    "abstract": "In aviation emergencies, high-stakes decisions must be made in an instant.\nPilots rely on quick access to precise, context-specific information -- an area\nwhere emerging tools like large language models (LLMs) show promise in\nproviding critical support. This paper introduces LeRAAT, a framework that\nintegrates LLMs with the X-Plane flight simulator to deliver real-time,\ncontext-aware pilot assistance. The system uses live flight data, weather\nconditions, and aircraft documentation to generate recommendations aligned with\naviation best practices and tailored to the particular situation. It employs a\nRetrieval-Augmented Generation (RAG) pipeline that extracts and synthesizes\ninformation from aircraft type-specific manuals, including performance\nspecifications and emergency procedures, as well as aviation regulatory\nmaterials, such as FAA directives and standard operating procedures. We\nshowcase the framework in both a virtual reality and traditional on-screen\nsimulation, supporting a wide range of research applications such as pilot\ntraining, human factors research, and operational decision support.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "cs.IR",
      "J.2; H.3.3; H.5.0"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, 3 figures, code: https://github.com/sisl/LeRAAT/ , demo\n  video: https://youtu.be/NnijQAlTo-U",
    "pdf_url": "http://arxiv.org/pdf/2503.16477v1",
    "published_date": "2025-03-05 05:34:15 UTC",
    "updated_date": "2025-03-05 05:34:15 UTC"
  },
  {
    "arxiv_id": "2503.03197v1",
    "title": "Directly Follows Graphs Go Predictive Process Monitoring With Graph Neural Networks",
    "authors": [
      "Attila Lischka",
      "Simon Rauch",
      "Oliver Stritzel"
    ],
    "abstract": "In the past years, predictive process monitoring (PPM) techniques based on\nartificial neural networks have evolved as a method to monitor the future\nbehavior of business processes. Existing approaches mostly focus on\ninterpreting the processes as sequences, so-called traces, and feeding them to\nneural architectures designed to operate on sequential data such as recurrent\nneural networks (RNNs) or transformers. In this study, we investigate an\nalternative way to perform PPM: by transforming each process in its\ndirectly-follows-graph (DFG) representation we are able to apply graph neural\nnetworks (GNNs) for the prediction tasks. By this, we aim to develop models\nthat are more suitable for complex processes that are long and contain an\nabundance of loops. In particular, we present different ways to create DFG\nrepresentations depending on the particular GNN we use. The tested GNNs range\nfrom classical node-based to novel edge-based architectures. Further, we\ninvestigate the possibility of using multi-graphs. By these steps, we aim to\ndesign graph representations that minimize the information loss when\ntransforming traces into graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.03197v1",
    "published_date": "2025-03-05 05:30:26 UTC",
    "updated_date": "2025-03-05 05:30:26 UTC"
  },
  {
    "arxiv_id": "2503.03787v1",
    "title": "Sarcasm Detection as a Catalyst: Improving Stance Detection with Cross-Target Capabilities",
    "authors": [
      "Gibson Nkhata Shi Yin Hong",
      "Susan Gauch"
    ],
    "abstract": "Stance Detection (SD) has become a critical area of interest due to its\napplications in various contexts leading to increased research within NLP. Yet\nthe subtlety and complexity of texts sourced from online platforms often\ncontaining sarcastic language pose significant challenges for SD algorithms in\naccurately determining the authors stance. This paper addresses this by\nemploying sarcasm for SD. It also tackles the issue of insufficient annotated\ndata for training SD models on new targets by conducting Cross-Target SD\n(CTSD). The proposed approach involves fine-tuning BERT and RoBERTa models\nfollowed by concatenating additional deep learning layers. The approach is\nassessed against various State-Of-The-Art baselines for SD demonstrating\nsuperior performance using publicly available datasets. Notably our model\noutperforms the best SOTA models on both in-domain SD and CTSD tasks even\nbefore the incorporation of sarcasm-detection pre-training. The integration of\nsarcasm knowledge into the model significantly reduces misclassifications of\nsarcastic text elements in SD allowing our model to accurately predict 85% of\ntexts that were previously misclassified without sarcasm-detection pre-training\non in-domain SD. This enhancement contributes to an increase in the models\naverage macro F1-score. The CTSD task achieves performance comparable to that\nof the in-domain task despite using a zero-shot finetuning. We also reveal that\nthe success of the transfer-learning framework relies on the correlation\nbetween the lexical attributes of sarcasm detection and SD. This study\nrepresents the first exploration of sarcasm detection as an intermediate\ntransfer-learning task within the context of SD while also leveraging the\nconcatenation of BERT or RoBERTa with other deep-learning techniques. The\nproposed approach establishes a foundational baseline for future research in\nthis domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "2 pages, 5 figures, published, published in International Journal On\n  Advances in Intelligent Systems, volume 17, numbers 3 and 4. arXiv admin\n  note: text overlap with arXiv:2503.03172",
    "pdf_url": "http://arxiv.org/pdf/2503.03787v1",
    "published_date": "2025-03-05 05:27:16 UTC",
    "updated_date": "2025-03-05 05:27:16 UTC"
  },
  {
    "arxiv_id": "2503.03194v1",
    "title": "Structured Outputs Enable General-Purpose LLMs to be Medical Experts",
    "authors": [
      "Guangfu Guo",
      "Kai Zhang",
      "Bryan Hoo",
      "Yujun Cai",
      "Xiaoqian Lu",
      "Nanyun Peng",
      "Yiwei Wang"
    ],
    "abstract": "Medical question-answering (QA) is a critical task for evaluating how\neffectively large language models (LLMs) encode clinical knowledge and\nassessing their potential applications in medicine. Despite showing promise on\nmultiple-choice tests, LLMs frequently struggle with open-ended medical\nquestions, producing responses with dangerous hallucinations or lacking\ncomprehensive coverage of critical aspects. Existing approaches attempt to\naddress these challenges through domain-specific fine-tuning, but this proves\nresource-intensive and difficult to scale across models. To improve the\ncomprehensiveness and factuality of medical responses, we propose a novel\napproach utilizing structured medical reasoning. Our method guides LLMs through\nan seven-step cognitive process inspired by clinical diagnosis, enabling more\naccurate and complete answers without additional training. Experiments on the\nMedLFQA benchmark demonstrate that our approach achieves the highest Factuality\nScore of 85.8, surpassing fine-tuned models. Notably, this improvement\ntransfers to smaller models, highlighting the method's efficiency and\nscalability. Our code and datasets are available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03194v1",
    "published_date": "2025-03-05 05:24:55 UTC",
    "updated_date": "2025-03-05 05:24:55 UTC"
  },
  {
    "arxiv_id": "2503.04824v1",
    "title": "ProReflow: Progressive Reflow with Decomposed Velocity",
    "authors": [
      "Lei Ke",
      "Haohang Xu",
      "Xuefei Ning",
      "Yu Li",
      "Jiajun Li",
      "Haoling Li",
      "Yuxuan Lin",
      "Dongsheng Jiang",
      "Yujiu Yang",
      "Linfeng Zhang"
    ],
    "abstract": "Diffusion models have achieved significant progress in both image and video\ngeneration while still suffering from huge computation costs. As an effective\nsolution, flow matching aims to reflow the diffusion process of diffusion\nmodels into a straight line for a few-step and even one-step generation.\nHowever, in this paper, we suggest that the original training pipeline of flow\nmatching is not optimal and introduce two techniques to improve it. Firstly, we\nintroduce progressive reflow, which progressively reflows the diffusion models\nin local timesteps until the whole diffusion progresses, reducing the\ndifficulty of flow matching. Second, we introduce aligned v-prediction, which\nhighlights the importance of direction matching in flow matching over magnitude\nmatching. Experimental results on SDv1.5 and SDXL demonstrate the effectiveness\nof our method, for example, conducting on SDv1.5 achieves an FID of 10.70 on\nMSCOCO2014 validation set with only 4 sampling steps, close to our teacher\nmodel (32 DDIM steps, FID = 10.05).",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "Our codes will be released at Github",
    "pdf_url": "http://arxiv.org/pdf/2503.04824v1",
    "published_date": "2025-03-05 04:50:53 UTC",
    "updated_date": "2025-03-05 04:50:53 UTC"
  },
  {
    "arxiv_id": "2503.05820v1",
    "title": "The impact of AI and peer feedback on research writing skills: a study using the CGScholar platform among Kazakhstani scholars",
    "authors": [
      "Raigul Zheldibayeva"
    ],
    "abstract": "This research studies the impact of AI and peer feedback on the academic\nwriting development of Kazakhstani scholars using the CGScholar platform - a\nproduct of research into collaborative learning, big data, and artificial\nintelligence developed by educators and computer scientists at the University\nof Illinois at Urbana-Champaign (UIUC). The study aimed to find out how\nfamiliarity with AI tools and peer feedback processes impacts participants'\nopenness to incorporating feedback into their academic writing. The study\ninvolved 36 scholars enrolled in a scientific internship focused on education\nat UIUC. A survey with 15 multiple-choice questions, a Likert scale, and\nopen-ended questions was used to collect data. The survey was conducted via\nGoogle Forms in both English and Russian to ensure linguistic accessibility.\nDemographic information such as age, gender, and first language was collected\nto provide a detailed understanding of the data. The analysis revealed a\nmoderate positive correlation between familiarity with AI tools and openness to\nmaking changes based on feedback, and a strong positive correlation between\nresearch writing experience and expectations of peer feedback, especially in\nthe area of research methodology. These results show that participants are\nopen-minded to AI-assisted feedback; however, they still highly appreciate peer\ninput, especially regarding methodological guidance. This study demonstrates\nthe potential benefits of integrating AI tools with traditional feedback\nmechanisms to improve research writing quality in academic settings.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.05820v1",
    "published_date": "2025-03-05 04:34:25 UTC",
    "updated_date": "2025-03-05 04:34:25 UTC"
  },
  {
    "arxiv_id": "2503.03172v1",
    "title": "Intermediate-Task Transfer Learning: Leveraging Sarcasm Detection for Stance Detection",
    "authors": [
      "Gibson Nkhata",
      "Susan Gauch"
    ],
    "abstract": "Stance Detection (SD) on social media has emerged as a prominent area of\ninterest with implications for social business and political applications\nthereby garnering escalating research attention within NLP. The inherent\nsubtlety and complexity of texts procured from online platforms pose challenges\nfor SD algorithms in accurately discerning the authors stance. Mostly the\ninclusion of sarcastic and figurative language drastically impacts the\nperformance of SD models. This paper addresses this by employing sarcasm\ndetection intermediate-task transfer learning tailored for SD. The proposed\nmethodology involves the finetuning of BERT and RoBERTa and the concatenation\nof convolutional BiLSTM and dense layers. Rigorous experiments are conducted on\npublicly available datasets to evaluate our transfer-learning framework. The\nperformance of the approach is assessed against various State-Of-The-Art\nbaselines for SD providing empirical evidence of its effectiveness. Notably our\nmodel outperforms the best SOTA models even prior to sarcasm-detection\npretraining. The integration of sarcasm knowledge into the model proves\ninstrumental in mitigating misclassifications of sarcastic textual elements in\nSD. Our model accurately predicts 85% of texts that were previously\nmisclassified by the model without sarcasm-detection pretraining thereby\namplifying the average F1-score of the model. Our experiments also revealed\nthat the success of the transfer-learning framework is contingent upon the\ncorrelation of lexical attributes between the intermediate task and the target\ntask. This study represents the first exploration of sarcasm detection as an\nintermediate transfer-learning task in the context of SD and simultaneously\nuses the concatenation of BERT or RoBERTa with other deep-learning techniques\nestablishing the proposed approach as a foundational baseline for future\nresearch endeavors in this domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures, published in The Sixteenth International\n  Conference on Information (eKNOW 2024)",
    "pdf_url": "http://arxiv.org/pdf/2503.03172v1",
    "published_date": "2025-03-05 04:30:53 UTC",
    "updated_date": "2025-03-05 04:30:53 UTC"
  },
  {
    "arxiv_id": "2503.03170v1",
    "title": "AttackSeqBench: Benchmarking Large Language Models' Understanding of Sequential Patterns in Cyber Attacks",
    "authors": [
      "Javier Yong",
      "Haokai Ma",
      "Yunshan Ma",
      "Anis Yusof",
      "Zhenkai Liang",
      "Ee-Chien Chang"
    ],
    "abstract": "The observations documented in Cyber Threat Intelligence (CTI) reports play a\ncritical role in describing adversarial behaviors, providing valuable insights\nfor security practitioners to respond to evolving threats. Recent advancements\nof Large Language Models (LLMs) have demonstrated significant potential in\nvarious cybersecurity applications, including CTI report understanding and\nattack knowledge graph construction. While previous works have proposed\nbenchmarks that focus on the CTI extraction ability of LLMs, the sequential\ncharacteristic of adversarial behaviors within CTI reports remains largely\nunexplored, which holds considerable significance in developing a comprehensive\nunderstanding of how adversaries operate. To address this gap, we introduce\nAttackSeqBench, a benchmark tailored to systematically evaluate LLMs'\ncapability to understand and reason attack sequences in CTI reports. Our\nbenchmark encompasses three distinct Question Answering (QA) tasks, each task\nfocuses on the varying granularity in adversarial behavior. To alleviate the\nlaborious effort of QA construction, we carefully design an automated dataset\nconstruction pipeline to create scalable and well-formulated QA datasets based\non real-world CTI reports. To ensure the quality of our dataset, we adopt a\nhybrid approach of combining human evaluation and systematic evaluation\nmetrics. We conduct extensive experiments and analysis with both fast-thinking\nand slow-thinking LLMs, while highlighting their strengths and limitations in\nanalyzing the sequential patterns in cyber attacks. The overarching goal of\nthis work is to provide a benchmark that advances LLM-driven CTI report\nunderstanding and fosters its application in real-world cybersecurity\noperations. Our dataset and code are available at\nhttps://github.com/Javiery3889/AttackSeqBench .",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03170v1",
    "published_date": "2025-03-05 04:25:21 UTC",
    "updated_date": "2025-03-05 04:25:21 UTC"
  },
  {
    "arxiv_id": "2503.03156v2",
    "title": "DiRe-JAX: A JAX based Dimensionality Reduction Algorithm for Large-scale Data",
    "authors": [
      "Alexander Kolpakov",
      "Igor Rivin"
    ],
    "abstract": "DiRe - JAX is a new dimensionality reduction toolkit designed to address some\nof the challenges faced by traditional methods like UMAP and tSNE such as loss\nof global structure and computational efficiency. Built on the JAX framework,\nDiRe leverages modern hardware acceleration to provide an efficient, scalable,\nand interpretable solution for visualizing complex data structures, and for\nquantitative analysis of lower-dimensional embeddings. The toolkit shows\nconsiderable promise in preserving both local and global structures within the\ndata as compared to state-of-the-art UMAP and tSNE implementations. This makes\nit suitable for a wide range of applications in machine learning,\nbio-informatics, and data science.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS",
      "H.1.1; G.4"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 12 figures Github repository available at\n  https://github.com/sashakolpakov/dire-jax Package available on PyPi\n  https://pypi.org/project/dire-jax/",
    "pdf_url": "http://arxiv.org/pdf/2503.03156v2",
    "published_date": "2025-03-05 03:56:01 UTC",
    "updated_date": "2025-03-06 04:40:27 UTC"
  },
  {
    "arxiv_id": "2503.03150v2",
    "title": "Position: Model Collapse Does Not Mean What You Think",
    "authors": [
      "Rylan Schaeffer",
      "Joshua Kazdan",
      "Alvan Caleb Arulandu",
      "Sanmi Koyejo"
    ],
    "abstract": "The proliferation of AI-generated content online has fueled concerns over\n\\emph{model collapse}, a degradation in future generative models' performance\nwhen trained on synthetic data generated by earlier models. Industry leaders,\npremier research journals and popular science publications alike have\nprophesied catastrophic societal consequences stemming from model collapse. In\nthis position piece, we contend this widespread narrative fundamentally\nmisunderstands the scientific evidence. We highlight that research on model\ncollapse actually encompasses eight distinct and at times conflicting\ndefinitions of model collapse, and argue that inconsistent terminology within\nand between papers has hindered building a comprehensive understanding of model\ncollapse. To assess how significantly different interpretations of model\ncollapse threaten future generative models, we posit what we believe are\nrealistic conditions for studying model collapse and then conduct a rigorous\nassessment of the literature's methodologies through this lens. While we leave\nroom for reasonable disagreement, our analysis of research studies, weighted by\nhow faithfully each study matches real-world conditions, leads us to conclude\nthat certain predicted claims of model collapse rely on assumptions and\nconditions that poorly match real-world conditions, and in fact several\nprominent collapse scenarios are readily avoidable. Altogether, this position\npaper argues that model collapse has been warped from a nuanced multifaceted\nconsideration into an oversimplified threat, and that the evidence suggests\nspecific harms more likely under society's current trajectory have received\ndisproportionately less attention.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03150v2",
    "published_date": "2025-03-05 03:47:17 UTC",
    "updated_date": "2025-03-18 03:48:25 UTC"
  },
  {
    "arxiv_id": "2503.03148v1",
    "title": "Partial Convolution Meets Visual Attention",
    "authors": [
      "Haiduo Huang",
      "Fuwei Yang",
      "Dong Li",
      "Ji Liu",
      "Lu Tian",
      "Jinzhang Peng",
      "Pengju Ren",
      "Emad Barsoum"
    ],
    "abstract": "Designing an efficient and effective neural network has remained a prominent\ntopic in computer vision research. Depthwise onvolution (DWConv) is widely used\nin efficient CNNs or ViTs, but it needs frequent memory access during\ninference, which leads to low throughput. FasterNet attempts to introduce\npartial convolution (PConv) as an alternative to DWConv but compromises the\naccuracy due to underutilized channels. To remedy this shortcoming and consider\nthe redundancy between feature map channels, we introduce a novel Partial\nvisual ATtention mechanism (PAT) that can efficiently combine PConv with visual\nattention. Our exploration indicates that the partial attention mechanism can\ncompletely replace the full attention mechanism and reduce model parameters and\nFLOPs. Our PAT can derive three types of blocks: Partial Channel-Attention\nblock (PAT_ch), Partial Spatial-Attention block (PAT_sp) and Partial\nSelf-Attention block (PAT_sf). First, PAT_ch integrates the enhanced Gaussian\nchannel attention mechanism to infuse global distribution information into the\nuntouched channels of PConv. Second, we introduce the spatial-wise attention to\nthe MLP layer to further improve model accuracy. Finally, we replace PAT_ch in\nthe last stage with the self-attention mechanism to extend the global receptive\nfield. Building upon PAT, we propose a novel hybrid network family, named\nPATNet, which achieves superior top-1 accuracy and inference speed compared to\nFasterNet on ImageNet-1K classification and excel in both detection and\nsegmentation on the COCO dataset. Particularly, our PATNet-T2 achieves 1.3%\nhigher accuracy than FasterNet-T2, while exhibiting 25% higher GPU throughput\nand 24% lower CPU latency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2502.01303",
    "pdf_url": "http://arxiv.org/pdf/2503.03148v1",
    "published_date": "2025-03-05 03:42:59 UTC",
    "updated_date": "2025-03-05 03:42:59 UTC"
  },
  {
    "arxiv_id": "2503.04823v2",
    "title": "DA-STGCN: 4D Trajectory Prediction Based on Spatiotemporal Feature Extraction",
    "authors": [
      "Yuheng Kuang",
      "Zhengning Wang",
      "Jianping Zhang",
      "Zhenyu Shi",
      "Yuding Zhang"
    ],
    "abstract": "The importance of four-dimensional (4D) trajectory prediction within air\ntraffic management systems is on the rise. Key operations such as conflict\ndetection and resolution, aircraft anomaly monitoring, and the management of\ncongested flight paths are increasingly reliant on this foundational\ntechnology, underscoring the urgent demand for intelligent solutions. The\ndynamics in airport terminal zones and crowded airspaces are intricate and\never-changing; however, current methodologies do not sufficiently account for\nthe interactions among aircraft. To tackle these challenges, we propose\nDA-STGCN, an innovative spatiotemporal graph convolutional network that\nintegrates a dual attention mechanism. Our model reconstructs the adjacency\nmatrix through a self-attention approach, enhancing the capture of node\ncorrelations, and employs graph attention to distill spatiotemporal\ncharacteristics, thereby generating a probabilistic distribution of predicted\ntrajectories. This novel adjacency matrix, reconstructed with the\nself-attention mechanism, is dynamically optimized throughout the network's\ntraining process, offering a more nuanced reflection of the inter-node\nrelationships compared to traditional algorithms. The performance of the model\nis validated on two ADS-B datasets, one near the airport terminal area and the\nother in dense airspace. Experimental results demonstrate a notable improvement\nover current 4D trajectory prediction methods, achieving a 20% and 30%\nreduction in the Average Displacement Error (ADE) and Final Displacement Error\n(FDE), respectively. The incorporation of a Dual-Attention module has been\nshown to significantly enhance the extraction of node correlations, as verified\nby ablation experiments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04823v2",
    "published_date": "2025-03-05 03:42:49 UTC",
    "updated_date": "2025-03-13 03:39:44 UTC"
  },
  {
    "arxiv_id": "2503.03140v2",
    "title": "Knowledge Augmentation in Federation: Rethinking What Collaborative Learning Can Bring Back to Decentralized Data",
    "authors": [
      "Wentai Wu",
      "Ligang He",
      "Saiqin Long",
      "Ahmed M. Abdelmoniem",
      "Yingliang Wu",
      "Rui Mao"
    ],
    "abstract": "Data, as an observable form of knowledge, has become one of the most\nimportant factors of production for the development of Artificial Intelligence\n(AI). Meanwhile, increasing legislation and regulations on private and\nproprietary information results in scattered data sources also known as the\n\"data islands\". Although some collaborative learning paradigms such as\nFederated Learning (FL) can enable privacy-preserving training over\ndecentralized data, they have inherent deficiencies in fairness, costs and\nreproducibility because of being learning-centric, which greatly limits the way\nhow participants cooperate with each other. In light of this, we present a\nknowledge-centric paradigm termed Knowledge Augmentation in Federation (KAF),\nwith focus on how to enhance local knowledge through collaborative effort. We\nprovide the suggested system architecture, formulate the prototypical\noptimization objective, and review emerging studies that employ methodologies\nsuitable for KAF. On our roadmap, with a three-way categorization we describe\nthe methods for knowledge expansion, knowledge filtering, and label and feature\nspace correction in the federation. Further, we highlight several challenges\nand open questions that deserve more attention from the community. With our\ninvestigation, we intend to offer new insights for what collaborative learning\ncan bring back to decentralized data.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.03140v2",
    "published_date": "2025-03-05 03:26:54 UTC",
    "updated_date": "2025-03-07 02:57:44 UTC"
  },
  {
    "arxiv_id": "2503.03139v1",
    "title": "Convergence Analysis of Federated Learning Methods Using Backward Error Analysis",
    "authors": [
      "Jinwoo Lim",
      "Suhyun Kim",
      "Soo-Mook Moon"
    ],
    "abstract": "Backward error analysis allows finding a modified loss function, which the\nparameter updates really follow under the influence of an optimization method.\nThe additional loss terms included in this modified function is called implicit\nregularizer. In this paper, we attempt to find the implicit regularizer for\nvarious federated learning algorithms on non-IID data distribution, and explain\nwhy each method shows different convergence behavior. We first show that the\nimplicit regularizer of FedAvg disperses the gradient of each client from the\naverage gradient, thus increasing the gradient variance. We also empirically\nshow that the implicit regularizer hampers its convergence. Similarly, we\ncompute the implicit regularizers of FedSAM and SCAFFOLD, and explain why they\nconverge better. While existing convergence analyses focus on pointing out the\nadvantages of FedSAM and SCAFFOLD, our approach can explain their limitations\nin complex non-convex settings. In specific, we demonstrate that FedSAM can\npartially remove the bias in the first-order term of the implicit regularizer\nin FedAvg, whereas SCAFFOLD can fully eliminate the bias in the first-order\nterm, but not in the second-order term. Consequently, the implicit regularizer\ncan provide a useful insight on the convergence behavior of federated learning\nfrom a different theoretical perspective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03139v1",
    "published_date": "2025-03-05 03:26:48 UTC",
    "updated_date": "2025-03-05 03:26:48 UTC"
  },
  {
    "arxiv_id": "2503.03137v2",
    "title": "Learning to Reduce Search Space for Generalizable Neural Routing Solver",
    "authors": [
      "Changliang Zhou",
      "Xi Lin",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ],
    "abstract": "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "37 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.03137v2",
    "published_date": "2025-03-05 03:25:09 UTC",
    "updated_date": "2025-05-19 08:14:26 UTC"
  },
  {
    "arxiv_id": "2503.07636v1",
    "title": "An Optimization Algorithm for Multimodal Data Alignment",
    "authors": [
      "Wei Zhang",
      "Xinyue Wang",
      "Lan Yu",
      "Shi Li"
    ],
    "abstract": "In the data era, the integration of multiple data types, known as\nmultimodality, has become a key area of interest in the research community.\nThis interest is driven by the goal to develop cutting edge multimodal models\ncapable of serving as adaptable reasoning engines across a wide range of\nmodalities and domains. Despite the fervent development efforts, the challenge\nof optimally representing different forms of data within a single unified\nlatent space a crucial step for enabling effective multimodal reasoning has not\nbeen fully addressed. To bridge this gap, we introduce AlignXpert, an\noptimization algorithm inspired by Kernel CCA crafted to maximize the\nsimilarities between N modalities while imposing some other constraints. This\nwork demonstrates the impact on improving data representation for a variety of\nreasoning tasks, such as retrieval and classification, underlining the pivotal\nimportance of data representation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACL SRW submission",
    "pdf_url": "http://arxiv.org/pdf/2503.07636v1",
    "published_date": "2025-03-05 03:07:07 UTC",
    "updated_date": "2025-03-05 03:07:07 UTC"
  },
  {
    "arxiv_id": "2503.03129v1",
    "title": "Exploring Neural Ordinary Differential Equations as Interpretable Healthcare classifiers",
    "authors": [
      "Shi Li"
    ],
    "abstract": "Deep Learning has emerged as one of the most significant innovations in\nmachine learning. However, a notable limitation of this field lies in the\n``black box\" decision-making processes, which have led to skepticism within\ngroups like healthcare and scientific communities regarding its applicability.\nIn response, this study introduces a interpretable approach using Neural\nOrdinary Differential Equations (NODEs), a category of neural network models\nthat exploit the dynamics of differential equations for representation\nlearning. Leveraging their foundation in differential equations, we illustrate\nthe capability of these models to continuously process textual data, marking\nthe first such model of its kind, and thereby proposing a promising direction\nfor future research in this domain. The primary objective of this research is\nto propose a novel architecture for groups like healthcare that require the\npredictive capabilities of deep learning while emphasizing the importance of\nmodel transparency demonstrated in NODEs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ACL SRW Submission",
    "pdf_url": "http://arxiv.org/pdf/2503.03129v1",
    "published_date": "2025-03-05 02:51:50 UTC",
    "updated_date": "2025-03-05 02:51:50 UTC"
  },
  {
    "arxiv_id": "2503.03128v1",
    "title": "Towards Understanding Multi-Round Large Language Model Reasoning: Approximability, Learnability and Generalizability",
    "authors": [
      "Chenhui Xu",
      "Dancheng Liu",
      "Jiajie Li",
      "Amir Nassereldine",
      "Zhaohui Li",
      "Jinjun Xiong"
    ],
    "abstract": "Recent advancements in cognitive science and multi-round reasoning techniques\nfor Large Language Models (LLMs) suggest that iterative thinking processes\nimprove problem-solving performance in complex tasks. Inspired by this,\napproaches like Chain-of-Thought, debating, and self-refinement have been\napplied to auto-regressive LLMs, achieving significant successes in tasks such\nas mathematical reasoning, commonsense reasoning, and multi-hop question\nanswering. Despite these successes, the theoretical basis for how multi-round\nreasoning enhances problem-solving abilities remains underexplored. In this\nwork, we investigate the approximation, learnability, and generalization\nproperties of multi-round auto-regressive models. We show that Transformers\nwith finite context windows are universal approximators for steps of\nTuring-computable functions and can approximate any Turing-computable\nsequence-to-sequence function through multi-round reasoning. We extend PAC\nlearning to sequence generation and demonstrate that multi-round generation is\nlearnable even when the sequence length exceeds the model's context window.\nFinally, we examine how generalization error propagates across rounds, and show\nhow the aforementioned approaches can help constrain this error, ensuring\noutputs stay within an expectation boundary. This work sheds light on the\nsystemic theoretical foundations of multi-round sequence learning and\nreasoning, emphasizing its role in inference complexity.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03128v1",
    "published_date": "2025-03-05 02:50:55 UTC",
    "updated_date": "2025-03-05 02:50:55 UTC"
  },
  {
    "arxiv_id": "2503.03122v4",
    "title": "The Devil Is in the Details: Tackling Unimodal Spurious Correlations for Generalizable Multimodal Reward Models",
    "authors": [
      "Zichao Li",
      "Xueru Wen",
      "Jie Lou",
      "Yuqiu Ji",
      "Yaojie Lu",
      "Xianpei Han",
      "Debing Zhang",
      "Le Sun"
    ],
    "abstract": "Multimodal Reward Models (MM-RMs) are crucial for aligning Large Language\nModels (LLMs) with human preferences, particularly as LLMs increasingly\ninteract with multimodal data. However, we find that MM-RMs trained on existing\ndatasets often struggle to generalize to out-of-distribution data due to their\nreliance on unimodal spurious correlations, primarily text-only shortcuts\nwithin the training distribution, which prevents them from leveraging true\nmultimodal reward functions. To address this, we introduce a Shortcut-aware\nMM-RM learning algorithm that mitigates this issue by dynamically reweighting\ntraining samples, shifting the distribution toward better multimodal\nunderstanding, and reducing dependence on unimodal spurious correlations. Our\nexperiments demonstrate significant improvements in generalization, downstream\ntask performance, and scalability, establishing a more robust framework for\nmultimodal reward modeling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.03122v4",
    "published_date": "2025-03-05 02:37:41 UTC",
    "updated_date": "2025-05-21 14:00:20 UTC"
  },
  {
    "arxiv_id": "2503.03112v1",
    "title": "A Multimodal Framework for Topic Propagation Classification in Social Networks",
    "authors": [
      "Yuchuan Jiang",
      "Chaolong Jia",
      "Yunyi Qin",
      "Wei Cai",
      "Yongsen Qian"
    ],
    "abstract": "The rapid proliferation of the Internet and the widespread adoption of social\nnetworks have significantly accelerated information dissemination. However,\nthis transformation has introduced complexities in information capture and\nprocessing, posing substantial challenges for researchers and practitioners.\nPredicting the dissemination of topic-related information within social\nnetworks has thus become a critical research focus. This paper proposes a\npredictive model for topic dissemination in social networks by integrating\nmultidimensional features derived from key dissemination characteristics.\nSpecifically, we introduce two novel indicators, user relationship breadth and\nuser authority, into the PageRank algorithm to quantify user influence more\neffectively. Additionally, we employ a Text-CNN model for sentiment\nclassification, extracting sentiment features from textual content. Temporal\nembeddings of nodes are encoded using a Bi-LSTM model to capture temporal\ndynamics. Furthermore, we refine the measurement of user interaction traces\nwith topics, replacing traditional topic view metrics with a more precise\ncommunication characteristics measure. Finally, we integrate the extracted\nmultidimensional features using a Transformer model, significantly enhancing\npredictive performance. Experimental results demonstrate that our proposed\nmodel outperforms traditional machine learning and unimodal deep learning\nmodels in terms of FI-Score, AUC, and Recall, validating its effectiveness in\npredicting topic propagation within social networks.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03112v1",
    "published_date": "2025-03-05 02:12:23 UTC",
    "updated_date": "2025-03-05 02:12:23 UTC"
  },
  {
    "arxiv_id": "2503.03108v2",
    "title": "SoK: Knowledge is All You Need: Accelerating Last Mile Delivery for Automated Provenance-based Intrusion Detection with LLMs",
    "authors": [
      "Wenrui Cheng",
      "Tiantian Zhu",
      "Chunlin Xiong",
      "Haofei Sun",
      "Zijun Wang",
      "Shunan Jing",
      "Mingqi Lv",
      "Yan Chen"
    ],
    "abstract": "Recently, provenance-based intrusion detection systems (PIDSes) have been\nwidely proposed for endpoint threat analysis. However, due to the lack of\nsystematic integration and utilization of knowledge, existing PIDSes still\nrequire significant manual intervention for practical deployment, making full\nautomation challenging. This paper presents a disruptive innovation by\ncategorizing PIDSes according to the types of knowledge they utilize. In\nresponse to the prevalent issue of ``knowledge silos problem'' in existing\nresearch, we introduce a novel knowledge-driven provenance-based intrusion\ndetection framework, powered by large language models (LLMs). We also present\nOmniSec, a best practice system built upon this framework. By integrating\nattack representation knowledge, threat intelligence knowledge, and benign\nbehavior knowledge, OmniSec outperforms the state-of-the-art approaches on\npublic benchmark datasets. OmniSec is available online at\nhttps://anonymous.4open.science/r/PIDS-with-LLM-613B.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03108v2",
    "published_date": "2025-03-05 02:08:12 UTC",
    "updated_date": "2025-04-28 12:27:25 UTC"
  },
  {
    "arxiv_id": "2503.03107v1",
    "title": "External Reliable Information-enhanced Multimodal Contrastive Learning for Fake News Detection",
    "authors": [
      "Biwei Cao",
      "Qihang Wu",
      "Jiuxin Cao",
      "Bo Liu",
      "Jie Gui"
    ],
    "abstract": "With the rapid development of the Internet, the information dissemination\nparadigm has changed and the efficiency has been improved greatly. While this\nalso brings the quick spread of fake news and leads to negative impacts on\ncyberspace. Currently, the information presentation formats have evolved\ngradually, with the news formats shifting from texts to multimodal contents. As\na result, detecting multimodal fake news has become one of the research\nhotspots. However, multimodal fake news detection research field still faces\ntwo main challenges: the inability to fully and effectively utilize multimodal\ninformation for detection, and the low credibility or static nature of the\nintroduced external information, which limits dynamic updates. To bridge the\ngaps, we propose ERIC-FND, an external reliable information-enhanced multimodal\ncontrastive learning framework for fake news detection. ERIC-FND strengthens\nthe representation of news contents by entity-enriched external information\nenhancement method. It also enriches the multimodal news information via\nmultimodal semantic interaction method where the multimodal constrative\nlearning is employed to make different modality representations learn from each\nother. Moreover, an adaptive fusion method is taken to integrate the news\nrepresentations from different dimensions for the eventual classification.\nExperiments are done on two commonly used datasets in different languages, X\n(Twitter) and Weibo. Experiment results demonstrate that our proposed model\nERIC-FND outperforms existing state-of-the-art fake news detection methods\nunder the same settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by AAAI'25",
    "pdf_url": "http://arxiv.org/pdf/2503.03107v1",
    "published_date": "2025-03-05 02:07:38 UTC",
    "updated_date": "2025-03-05 02:07:38 UTC"
  },
  {
    "arxiv_id": "2503.04822v1",
    "title": "HeTGB: A Comprehensive Benchmark for Heterophilic Text-Attributed Graphs",
    "authors": [
      "Shujie Li",
      "Yuxia Wu",
      "Chuan Shi",
      "Yuan Fang"
    ],
    "abstract": "Graph neural networks (GNNs) have demonstrated success in modeling relational\ndata primarily under the assumption of homophily. However, many real-world\ngraphs exhibit heterophily, where linked nodes belong to different categories\nor possess diverse attributes. Additionally, nodes in many domains are\nassociated with textual descriptions, forming heterophilic text-attributed\ngraphs (TAGs). Despite their significance, the study of heterophilic TAGs\nremains underexplored due to the lack of comprehensive benchmarks. To address\nthis gap, we introduce the Heterophilic Text-attributed Graph Benchmark\n(HeTGB), a novel benchmark comprising five real-world heterophilic graph\ndatasets from diverse domains, with nodes enriched by extensive textual\ndescriptions. HeTGB enables systematic evaluation of GNNs, pre-trained language\nmodels (PLMs) and co-training methods on the node classification task. Through\nextensive benchmarking experiments, we showcase the utility of text attributes\nin heterophilic graphs, analyze the challenges posed by heterophilic TAGs and\nthe limitations of existing models, and provide insights into the interplay\nbetween graph structures and textual attributes. We have publicly released\nHeTGB with baseline implementations to facilitate further research in this\nfield.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2503.04822v1",
    "published_date": "2025-03-05 02:00:32 UTC",
    "updated_date": "2025-03-05 02:00:32 UTC"
  },
  {
    "arxiv_id": "2503.03104v1",
    "title": "RVAFM: Re-parameterizing Vertical Attention Fusion Module for Handwritten Paragraph Text Recognition",
    "authors": [
      "Jinhui Zheng",
      "Zhiquan Liu",
      "Yain-Whar Si",
      "Jianqing Li",
      "Xinyuan Zhang",
      "Xiaofan Li",
      "Haozhi Huang",
      "Xueyuan Gong"
    ],
    "abstract": "Handwritten Paragraph Text Recognition (HPTR) is a challenging task in\nComputer Vision, requiring the transformation of a paragraph text image, rich\nin handwritten text, into text encoding sequences. One of the most advanced\nmodels for this task is Vertical Attention Network (VAN), which utilizes a\nVertical Attention Module (VAM) to implicitly segment paragraph text images\ninto text lines, thereby reducing the difficulty of the recognition task.\nHowever, from a network structure perspective, VAM is a single-branch module,\nwhich is less effective in learning compared to multi-branch modules. In this\npaper, we propose a new module, named Re-parameterizing Vertical Attention\nFusion Module (RVAFM), which incorporates structural re-parameterization\ntechniques. RVAFM decouples the structure of the module during training and\ninference stages. During training, it uses a multi-branch structure for more\neffective learning, and during inference, it uses a single-branch structure for\nfaster processing. The features learned by the multi-branch structure are fused\ninto the single-branch structure through a special fusion method named\nRe-parameterization Fusion (RF) without any loss of information. As a result,\nwe achieve a Character Error Rate (CER) of 4.44% and a Word Error Rate (WER) of\n14.37% on the IAM paragraph-level test set. Additionally, the inference speed\nis slightly faster than VAN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.03104v1",
    "published_date": "2025-03-05 01:41:59 UTC",
    "updated_date": "2025-03-05 01:41:59 UTC"
  },
  {
    "arxiv_id": "2503.04821v2",
    "title": "RGB-Thermal Infrared Fusion for Robust Depth Estimation in Complex Environments",
    "authors": [
      "Zelin Meng",
      "Takanori Fukao"
    ],
    "abstract": "Depth estimation in complex real-world scenarios is a challenging task,\nespecially when relying solely on a single modality such as visible light or\nthermal infrared (THR) imagery. This paper proposes a novel multimodal depth\nestimation model, RTFusion, which enhances depth estimation accuracy and\nrobustness by integrating the complementary strengths of RGB and THR data. The\nRGB modality provides rich texture and color information, while the THR\nmodality captures thermal patterns, ensuring stability under adverse lighting\nconditions such as extreme illumination. The model incorporates a unique fusion\nmechanism, EGFusion, consisting of the Mutual Complementary Attention (MCA)\nmodule for cross-modal feature alignment and the Edge Saliency Enhancement\nModule (ESEM) to improve edge detail preservation. Comprehensive experiments on\nthe MS2 and ViViD++ datasets demonstrate that the proposed model consistently\nproduces high-quality depth maps across various challenging environments,\nincluding nighttime, rainy, and high-glare conditions. The experimental results\nhighlight the potential of the proposed method in applications requiring\nreliable depth estimation, such as autonomous driving, robotics, and augmented\nreality.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.04821v2",
    "published_date": "2025-03-05 01:35:14 UTC",
    "updated_date": "2025-04-29 02:46:20 UTC"
  },
  {
    "arxiv_id": "2503.03084v1",
    "title": "Hopfield Networks Meet Big Data: A Brain-Inspired Deep Learning Framework for Semantic Data Linking",
    "authors": [
      "Ashwin Viswanathan Kannan",
      "Johnson P Thomas",
      "Abhimanyu Mukerji"
    ],
    "abstract": "The exponential rise in data generation has led to vast, heterogeneous\ndatasets crucial for predictive analytics and decision-making. Ensuring data\nquality and semantic integrity remains a challenge. This paper presents a\nbrain-inspired distributed cognitive framework that integrates deep learning\nwith Hopfield networks to identify and link semantically related attributes\nacross datasets. Modeled on the dual-hemisphere functionality of the human\nbrain, the right hemisphere assimilates new information while the left\nretrieves learned representations for association. Our architecture,\nimplemented on MapReduce with Hadoop Distributed File System (HDFS), leverages\ndeep Hopfield networks as an associative memory mechanism to enhance recall of\nfrequently co-occurring attributes and dynamically adjust relationships based\non evolving data patterns. Experiments show that associative imprints in\nHopfield memory are reinforced over time, ensuring linked datasets remain\ncontextually meaningful and improving data disambiguation and integration\naccuracy. Our results indicate that combining deep Hopfield networks with\ndistributed cognitive processing offers a scalable, biologically inspired\napproach to managing complex data relationships in large-scale environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.03084v1",
    "published_date": "2025-03-05 00:53:22 UTC",
    "updated_date": "2025-03-05 00:53:22 UTC"
  },
  {
    "arxiv_id": "2503.13477v1",
    "title": "Periodontal Bone Loss Analysis via Keypoint Detection With Heuristic Post-Processing",
    "authors": [
      "Ryan Banks",
      "Vishal Thengane",
      "María Eugenia Guerrero",
      "Nelly Maria García-Madueño",
      "Yunpeng Li",
      "Hongying Tang",
      "Akhilanand Chaurasia"
    ],
    "abstract": "Calculating percentage bone loss is a critical test for periodontal disease\nstaging but is sometimes imprecise and time consuming when manually calculated.\nThis study evaluates the application of a deep learning keypoint and object\ndetection model, YOLOv8-pose, for the automatic identification of localised\nperiodontal bone loss landmarks, conditions and staging. YOLOv8-pose was\nfine-tuned on 193 annotated periapical radiographs. We propose a keypoint\ndetection metric, Percentage of Relative Correct Keypoints (PRCK), which\nnormalises the metric to the average tooth size of teeth in the image. We\npropose a heuristic post-processing module that adjusts certain keypoint\npredictions to align with the edge of the related tooth, using a supporting\ninstance segmentation model trained on an open source auxiliary dataset. The\nmodel can sufficiently detect bone loss keypoints, tooth boxes, and alveolar\nridge resorption, but has insufficient performance at detecting detached\nperiodontal ligament and furcation involvement. The model with post-processing\ndemonstrated a PRCK 0.25 of 0.726 and PRCK 0.05 of 0.401 for keypoint\ndetection, mAP 0.5 of 0.715 for tooth object detection, mesial dice score of\n0.593 for periodontal staging, and dice score of 0.280 for furcation\ninvolvement. Our annotation methodology provides a stage agnostic approach to\nperiodontal disease detection, by ensuring most keypoints are present for each\ntooth in the image, allowing small imbalanced datasets. Our PRCK metric allows\naccurate evaluation of keypoints in dental domains. Our post-processing module\nadjusts predicted keypoints correctly but is dependent on a minimum quality of\nprediction by the pose detection and segmentation models. Code: https://\nanonymous.4open.science/r/Bone-Loss-Keypoint-Detection-Code. Dataset:\nhttps://bit.ly/4hJ3aE7.",
    "categories": [
      "q-bio.TO",
      "cs.AI",
      "cs.CV",
      "I.2.1; I.2.10; J.3"
    ],
    "primary_category": "q-bio.TO",
    "comment": "31 pages, 7 tables, 5 figures, 3 equations, journal paper submitted\n  to Computers in Biology and Medicine",
    "pdf_url": "http://arxiv.org/pdf/2503.13477v1",
    "published_date": "2025-03-05 00:34:29 UTC",
    "updated_date": "2025-03-05 00:34:29 UTC"
  },
  {
    "arxiv_id": "2503.07634v1",
    "title": "Impact of Level 2/3 Automated Driving Technology on Road Work Zone Safety",
    "authors": [
      "Zhepu Xu",
      "Ziyi Song",
      "Yupu Dong",
      "Peiyan Chen"
    ],
    "abstract": "As China's road network enters the maintenance era, work zones will become a\ncommon sight on the roads. With the development of automated driving, vehicles\nequipped with Level 2/3 automated driving capabilities will also become a\ncommon presence on the roads. When these vehicles pass through work zones,\nautomated driving may disengage, which can have complex effects on traffic\nsafety. This paper explores the impact of Level 2/3 automated driving\ntechnology on road safety in high-speed highway work zone environments. Through\nmicroscopic traffic simulation method and using full-type traffic conflict\ntechnique, factors such as market penetration rate (MPR), traffic volume level,\ndisengagement threshold, and driver takeover style are studied to understand\ntheir impact on work zone safety. The study found that the impact of automated\ndriving technology on work zone safety is complex. Disengagement of automated\nvehicles in work zones reduces the proportion of vehicles that can maintain\nautomated driving status. If takeover is not timely or adequate, it can easily\nlead to new traffic conflicts. Different factors have varying degrees of impact\non work zone safety. Increasing MPR helps reduce the occurrence of\nsingle-vehicle conflicts, but it also increases the possibility of\nmulti-vehicle conflicts. Therefore, future research and improvement directions\nshould focus on optimizing the disengagement detection and takeover mechanisms\nof automated driving systems.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.07634v1",
    "published_date": "2025-03-05 00:26:53 UTC",
    "updated_date": "2025-03-05 00:26:53 UTC"
  }
]