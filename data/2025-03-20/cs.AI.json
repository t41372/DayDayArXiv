{
  "date": "2025-03-20",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-20 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文涵盖 AI 代理、LLM 优化、图像生成、医疗 AI 和神经网络等领域，重点包括 Hector Zenil 等学者的智能测试方法，以及 Peter Clark 领导的自动科学发现系统，这些工作突显了 AI 在实际应用中的潜力，如提升推荐系统和深度估计效率，同时强调了 AI 安全和泛化能力的挑战。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些创新性强、可能引发话题的文章（如 AI 代理和 LLM 相关），再快速掠过其他领域的次要工作。每个条目列出论文标题（中文 + 英文），并聚焦核心贡献和发现。\n\n### 重点论文讨论\n\n**1. SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability（SuperARC: 一种基于递归压缩和算法概率的通用智能测试）**  \nHector Zenil 等作者提出了一种基于算法概率的开放式测试框架，用于评估 AI 模型的通用智能和超级智能，避免基准污染。该方法超越简单模式匹配，强调合成和模型创建能力，通过比较 LLM 和混合神经符号方法，发现 LLM 受限于记忆优化，而非真正预测力，揭示了 LLM 的根本局限。\n\n**2. CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation（CodeScientist: 基于代码实验的端到端半自动化科学发现）**  \nPeter Clark 团队开发了 CodeScientist 系统，使用遗传搜索在研究文章和代码块上进行实验，自动生成数百个代理和虚拟环境实验。该系统发现了 19 个新发现（6 个被验证为可靠），包括新任务和指标，标志着从基准优化向更广泛科学发现的范式转变。\n\n**3. Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models（在多模态 LLM 时代迈向代理式推荐系统）**  \nJulian McAuley 等学者探讨了 LLM 驱动的代理式推荐系统，强调规划、记忆和多模态推理如何提升推荐质量。该论文提出关键研究问题，如安全性和个性化，并预测 LLM-ARS 将重塑用户体验。\n\n**4. Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models（通过视觉语言模型实现强化学习的自动化语义可解释性）**  \n该工作引入 SILVA 框架，使用预训练视觉语言模型提取语义特征，并结合可解释树模型优化策略，实现无需人工干预的 RL 决策，解决了传统方法的泛化问题。\n\n**5. Limits of trust in medical AI（医疗 AI 的信任极限）**  \nJoshua Hatherley 分析了 AI 在医疗中的信任问题，发现 AI 系统虽可靠但缺乏真正可信度，可能导致临床信任缺失。该论文强调 AI 在决策中的潜在风险。\n\n**6. QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge（QuartDepth: 边缘实时深度估计的后训练量化）**  \n该论文提出 QuartDepth 方法，将深度估计模型量化到 4 位精度，并设计硬件加速器，提升边缘设备的能效和推理速度，在 CVPR 2025 上被接受。\n\n**7. GAIR: Improving Multimodal Geo-Foundation Model with Geo-Aligned Implicit Representations（GAIR: 使用地理对齐隐式表示提升多模态地理基础模型）**  \n作者开发了 GAIR 架构，融合遥感数据和街景图像，通过隐式神经表示实现地理对齐，提升了地理任务的泛化性能。\n\n**8. Echoes of Power: Investigating Geopolitical Bias in US and China Large Language Models（Echoes of Power: 调查美国和中国大型语言模型的地缘政治偏差）**  \n该研究比较了 ChatGPT 和 DeepSeek 在地缘政治问题上的偏差，发现模型反映了文化影响，但也存在一致性，揭示了 LLM 在敏感话题上的潜在风险。\n\n**9. Aligning Text-to-Music Evaluation with Human Preferences（将文本到音乐评估与人类偏好对齐）**  \n作者提出 MAUVE Audio Divergence 指标，使用自监督音频嵌入模型评估文本到音乐生成，显著提升了与人类感知的相关性。\n\n**10. Code Evolution Graphs: Understanding Large Language Model Driven Design of Algorithms（Code Evolution Graphs: 理解 LLM 驱动的算法设计演化）**  \n该论文使用进化图分析 LLM 在算法优化中的演化过程，发现不同 LLM 有独特风格，并建议混合 LLM 以提升性能。\n\n其他论文中，诸如 HiAER-Spike（硬件-软件协同设计大规模神经网络）和 MobilePlantViT（轻量级植物病害分类模型）等在技术创新上值得一提，但由于篇幅有限，我快速掠过：HiAER-Spike 贡献了高效事件驱动神经计算平台；MobilePlantViT 通过混合 ViT 架构实现了高效边缘部署；DreamTexture（从单图像生成 3D 世界）则创新性地使用扩散模型提升重建质量。这些工作虽有实际应用潜力，但相对较专业，不如上述论文话题度高。\n\n总之，今天的论文展示了 AI 在代理系统、医疗和图像领域的进展，但也提醒我们注意偏差和泛化问题。明天的快报，继续关注这些前沿动态！",
  "papers": [
    {
      "arxiv_id": "2504.03671v1",
      "title": "HiAER-Spike: Hardware-Software Co-Design for Large-Scale Reconfigurable Event-Driven Neuromorphic Computing",
      "title_zh": "HiAER-Spike：大规模可重构事件驱动神经形态计算的硬件软件协同设计",
      "authors": [
        "Gwenevere Frank",
        "Gopabandhu Hota",
        "Keli Wang",
        "Abhinav Uppal",
        "Omowuyi Olajide",
        "Kenneth Yoshimoto",
        "Leif Gibb",
        "Qingbo Wang",
        "Johannes Leugering",
        "Stephen Deiss",
        "Gert Cauwenberghs"
      ],
      "abstract": "In this work, we present HiAER-Spike, a modular, reconfigurable, event-driven\nneuromorphic computing platform designed to execute large spiking neural\nnetworks with up to 160 million neurons and 40 billion synapses - roughly twice\nthe neurons of a mouse brain at faster-than real-time. This system, which is\ncurrently under construction at the UC San Diego Supercomputing Center,\ncomprises a co-designed hard- and software stack that is optimized for run-time\nmassively parallel processing and hierarchical address-event routing (HiAER) of\nspikes while promoting memory-efficient network storage and execution. Our\narchitecture efficiently handles both sparse connectivity and sparse activity\nfor robust and low-latency event-driven inference for both edge and cloud\ncomputing. A Python programming interface to HiAER-Spike, agnostic to\nhardware-level detail, shields the user from complexity in the configuration\nand execution of general spiking neural networks with virtually no constraints\nin topology. The system is made easily available over a web portal for use by\nthe wider community. In the following we provide an overview of the hard- and\nsoftware stack, explain the underlying design principles, demonstrate some of\nthe system's capabilities and solicit feedback from the broader neuromorphic\ncommunity.",
      "tldr_zh": "本文提出 HiAER-Spike，一种硬件-软件联合设计的模块化、可重构事件驱动神经形态计算平台，能够执行规模达 1.6 亿神经元和 400 亿突触的 spiking neural networks，比真实时间更快，并模拟超过老鼠大脑规模的网络。系统优化了运行时的大规模并行处理和 hierarchical address-event routing (HiAER)，以高效处理稀疏连接和稀疏活动，实现低延迟事件驱动推理，适用于边缘和云计算。HiAER-Spike 提供用户友好的 Python 接口，屏蔽硬件细节，并通过网络门户向 neuromorphic 社区开放，促进广泛应用和反馈。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NE",
      "comment": "IEEE International Conference on Rebooting Computing (ICRC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.03671v1",
      "published_date": "2025-03-20 23:54:33 UTC",
      "updated_date": "2025-03-20 23:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:11:07.667942"
    },
    {
      "arxiv_id": "2503.16743v3",
      "title": "SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Hernández-Espinosa",
        "Luan Ozelim",
        "Felipe S. Abrahão",
        "Hector Zenil"
      ],
      "abstract": "We introduce an open-ended test grounded in algorithmic probability that can\navoid benchmark contamination in the quantitative evaluation of frontier models\nin the context of their Artificial General Intelligence (AGI) and\nSuperintelligence (ASI) claims. Unlike other tests, this test does not rely on\nstatistical compression methods (such as GZIP or LZW), which are more closely\nrelated to Shannon entropy than to Kolmogorov complexity and are not able to\ntest beyond simple pattern matching. The test challenges aspects of AI, in\nparticular LLMs, related to features of intelligence of fundamental nature such\nas synthesis and model creation in the context of inverse problems (generating\nnew knowledge from observation). We argue that metrics based on model\nabstraction and abduction (optimal Bayesian `inference') for predictive\n`planning' can provide a robust framework for testing intelligence, including\nnatural intelligence (human and animal), narrow AI, AGI, and ASI. We found that\nLLM model versions tend to be fragile and incremental as a result of\nmemorisation only with progress likely driven by the size of training data. The\nresults were compared with a hybrid neurosymbolic approach that theoretically\nguarantees universal intelligence based on the principles of algorithmic\nprobability and Kolmogorov complexity. The method outperforms LLMs in a\nproof-of-concept on short binary sequences. We prove that compression is\nequivalent and directly proportional to a system's predictive power and vice\nversa. That is, if a system can better predict it can better compress, and if\nit can better compress, then it can better predict. Our findings strengthen the\nsuspicion regarding the fundamental limitations of LLMs, exposing them as\nsystems optimised for the perception of mastery over human language.",
      "tldr_zh": "本研究提出SuperARC，一种基于算法概率和递归压缩的 agnostic 测试框架，用于评估窄 AI、AGI 和 ASI，而不依赖统计压缩方法（如 GZIP），从而避免基准污染。测试重点考察 AI 模型，特别是 LLMs，在逆问题中的合成和模型创建能力，包括从观察生成新知识的抽象和溯因(abduction)过程。实验结果显示，LLMs 模型版本脆弱且仅依赖记忆和训练数据规模，而一个混合神经符号方法在短二进制序列上表现出色；此外，证明压缩能力与预测能力等价，强化了 LLMs 作为优化人类语言感知系统的根本限制。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "51 pages + Technical Supplementary Information, 79 pages total",
      "pdf_url": "http://arxiv.org/pdf/2503.16743v3",
      "published_date": "2025-03-20 23:11:30 UTC",
      "updated_date": "2025-04-22 22:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:11:19.944260"
    },
    {
      "arxiv_id": "2503.22708v1",
      "title": "CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Jansen",
        "Oyvind Tafjord",
        "Marissa Radensky",
        "Pao Siangliulue",
        "Tom Hope",
        "Bhavana Dalvi Mishra",
        "Bodhisattwa Prasad Majumder",
        "Daniel S. Weld",
        "Peter Clark"
      ],
      "abstract": "Despite the surge of interest in autonomous scientific discovery (ASD) of\nsoftware artifacts (e.g., improved ML algorithms), current ASD systems face two\nkey limitations: (1) they largely explore variants of existing codebases or\nsimilarly constrained design spaces, and (2) they produce large volumes of\nresearch artifacts (such as automatically generated papers and code) that are\ntypically evaluated using conference-style paper review with limited evaluation\nof code. In this work we introduce CodeScientist, a novel ASD system that\nframes ideation and experiment construction as a form of genetic search jointly\nover combinations of research articles and codeblocks defining common actions\nin a domain (like prompting a language model). We use this paradigm to conduct\nhundreds of automated experiments on machine-generated ideas broadly in the\ndomain of agents and virtual environments, with the system returning 19\ndiscoveries, 6 of which were judged as being both at least minimally sound and\nincrementally novel after a multi-faceted evaluation beyond that typically\nconducted in prior work, including external (conference-style) review, code\nreview, and replication attempts. Moreover, the discoveries span new tasks,\nagents, metrics, and data, suggesting a qualitative shift from benchmark\noptimization to broader discoveries.",
      "tldr_zh": "该研究指出了现有自主科学发现（ASD）系统的局限性，包括设计空间受限和成果评估不足，并引入了CodeScientist，一种端到端的半自动化系统，通过遗传搜索（genetic search）结合研究文章和代码块来生成和测试机器生成的构想。系统在代理和虚拟环境领域进行了数百次自动化实验，最终发现了19个新发现，其中6个经多方面评估（如外部审阅、代码审阅和复制尝试）被确认为至少最小程度可靠且具有增量新颖性。这些发现涵盖了新任务、代理、指标和数据，标志着从基准优化向更广泛科学探索的质变。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "98 Pages (13 pages: main paper body; 85 pages: appendix)",
      "pdf_url": "http://arxiv.org/pdf/2503.22708v1",
      "published_date": "2025-03-20 22:37:17 UTC",
      "updated_date": "2025-03-20 22:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:11:30.559040"
    },
    {
      "arxiv_id": "2503.16734v1",
      "title": "Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models",
      "title_zh": "迈向多模态大型语言模型时代中的智能体推荐系统",
      "authors": [
        "Chengkai Huang",
        "Junda Wu",
        "Yu Xia",
        "Zixu Yu",
        "Ruhan Wang",
        "Tong Yu",
        "Ruiyi Zhang",
        "Ryan A. Rossi",
        "Branislav Kveton",
        "Dongruo Zhou",
        "Julian McAuley",
        "Lina Yao"
      ],
      "abstract": "Recent breakthroughs in Large Language Models (LLMs) have led to the\nemergence of agentic AI systems that extend beyond the capabilities of\nstandalone models. By empowering LLMs to perceive external environments,\nintegrate multimodal information, and interact with various tools, these\nagentic systems exhibit greater autonomy and adaptability across complex tasks.\nThis evolution brings new opportunities to recommender systems (RS): LLM-based\nAgentic RS (LLM-ARS) can offer more interactive, context-aware, and proactive\nrecommendations, potentially reshaping the user experience and broadening the\napplication scope of RS. Despite promising early results, fundamental\nchallenges remain, including how to effectively incorporate external knowledge,\nbalance autonomy with controllability, and evaluate performance in dynamic,\nmultimodal settings. In this perspective paper, we first present a systematic\nanalysis of LLM-ARS: (1) clarifying core concepts and architectures; (2)\nhighlighting how agentic capabilities -- such as planning, memory, and\nmultimodal reasoning -- can enhance recommendation quality; and (3) outlining\nkey research questions in areas such as safety, efficiency, and lifelong\npersonalization. We also discuss open problems and future directions, arguing\nthat LLM-ARS will drive the next wave of RS innovation. Ultimately, we foresee\na paradigm shift toward intelligent, autonomous, and collaborative\nrecommendation experiences that more closely align with users' evolving needs\nand complex decision-making processes.",
      "tldr_zh": "这篇论文探讨了多模态大型语言模型(Multimodal Large Language Models)时代下，Agentic Recommender Systems (LLM-ARS)的潜力，通过赋予Large Language Models (LLMs)感知外部环境、整合多模态信息和互动工具的能力，实现更自主和适应的推荐系统。作者系统分析了LLM-ARS的核心概念、架构，以及代理能力如规划(planning)、记忆(memory)和多模态推理(multimodal reasoning)，这些能力可提升推荐的质量，使其更具交互性、上下文感知和主动性。论文突出了关键挑战，包括有效整合外部知识、平衡自治与可控性、以及在动态多模态环境中的性能评估，并提出未来研究方向，认为LLM-ARS将推动推荐系统向智能、自治和协作的范式转变。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16734v1",
      "published_date": "2025-03-20 22:37:15 UTC",
      "updated_date": "2025-03-20 22:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:11:43.949033"
    },
    {
      "arxiv_id": "2503.16724v1",
      "title": "Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoxin Li",
        "Zhang Xi-Jia",
        "Batuhan Altundas",
        "Letian Chen",
        "Rohan Paleja",
        "Matthew Gombolay"
      ],
      "abstract": "Semantic Interpretability in Reinforcement Learning (RL) enables\ntransparency, accountability, and safer deployment by making the agent's\ndecisions understandable and verifiable. Achieving this, however, requires a\nfeature space composed of human-understandable concepts, which traditionally\nrely on human specification and fail to generalize to unseen environments. In\nthis work, we introduce Semantically Interpretable Reinforcement Learning with\nVision-Language Models Empowered Automation (SILVA), an automated framework\nthat leverages pre-trained vision-language models (VLM) for semantic feature\nextraction and interpretable tree-based models for policy optimization. SILVA\nfirst queries a VLM to identify relevant semantic features for an unseen\nenvironment, then extracts these features from the environment. Finally, it\ntrains an Interpretable Control Tree via RL, mapping the extracted features to\nactions in a transparent and interpretable manner. To address the computational\ninefficiency of extracting features directly with VLMs, we develop a feature\nextraction pipeline that generates a dataset for training a lightweight\nconvolutional network, which is subsequently used during RL. By leveraging VLMs\nto automate tree-based RL, SILVA removes the reliance on human annotation\npreviously required by interpretable models while also overcoming the inability\nof VLMs alone to generate valid robot policies, enabling semantically\ninterpretable reinforcement learning without human-in-the-loop.",
      "tldr_zh": "该研究针对强化学习(Reinforcement Learning, RL)中的语义可解释性(Semantic Interpretability)问题，提出了一种自动化框架SILVA，以提升代理决策的透明度和安全性。SILVA利用预训练的视觉语言模型(Vision-Language Models, VLM)自动提取环境中的语义特征，并结合可解释树模型(Interpretable Control Tree)进行策略优化，从而避免了传统方法对人类注释的依赖。框架还引入了一个高效的特征提取管道，通过生成数据集训练轻量级卷积网络，实现计算资源的优化，最终使RL能够在无人类干预的情况下生成可验证的机器人策略。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16724v1",
      "published_date": "2025-03-20 21:53:19 UTC",
      "updated_date": "2025-03-20 21:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:11:54.699790"
    },
    {
      "arxiv_id": "2503.17410v1",
      "title": "Comparative Analysis of Deep Learning Models for Real-World ISP Network Traffic Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Josef Koumar",
        "Timotej Smoleň",
        "Kamil Jeřábek",
        "Tomáš Čejka"
      ],
      "abstract": "Accurate network traffic forecasting is essential for Internet Service\nProviders (ISP) to optimize resources, enhance user experience, and mitigate\nanomalies. This study evaluates state-of-the-art deep learning models on\nCESNET-TimeSeries24, a recently published, comprehensive real-world network\ntraffic dataset from the ISP network CESNET3 spanning multivariate time series\nover 40 weeks. Our findings highlight the balance between prediction accuracy\nand computational efficiency across different levels of network granularity.\nAdditionally, this work establishes a reproducible methodology that facilitates\ndirect comparison of existing approaches, explores their strengths and\nweaknesses, and provides a benchmark for future studies using this dataset.",
      "tldr_zh": "这篇论文比较了多种深度学习模型在真实ISP网络流量预测中的表现，使用了CESNET-TimeSeries24数据集，该数据集来自CESNET3 ISP网络的40周多变量时间序列。研究重点评估了模型在预测准确性和计算效率之间的平衡，尤其在不同网络粒度级别上。最终，该工作建立了可重现的方法论，便于直接比较现有模型的优缺点，并为未来研究提供基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17410v1",
      "published_date": "2025-03-20 21:04:20 UTC",
      "updated_date": "2025-03-20 21:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:12:06.239422"
    },
    {
      "arxiv_id": "2503.16709v1",
      "title": "QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge",
      "title_zh": "QuartDepth：训练后量化用于边缘设备的实时深度估计",
      "authors": [
        "Xuan Shen",
        "Weize Ma",
        "Jing Liu",
        "Changdi Yang",
        "Rui Ding",
        "Quanyi Wang",
        "Henghui Ding",
        "Wei Niu",
        "Yanzhi Wang",
        "Pu Zhao",
        "Jun Lin",
        "Jiuxiang Gu"
      ],
      "abstract": "Monocular Depth Estimation (MDE) has emerged as a pivotal task in computer\nvision, supporting numerous real-world applications. However, deploying\naccurate depth estimation models on resource-limited edge devices, especially\nApplication-Specific Integrated Circuits (ASICs), is challenging due to the\nhigh computational and memory demands. Recent advancements in foundational\ndepth estimation deliver impressive results but further amplify the difficulty\nof deployment on ASICs. To address this, we propose QuartDepth which adopts\npost-training quantization to quantize MDE models with hardware accelerations\nfor ASICs. Our approach involves quantizing both weights and activations to\n4-bit precision, reducing the model size and computation cost. To mitigate the\nperformance degradation, we introduce activation polishing and compensation\nalgorithm applied before and after activation quantization, as well as a weight\nreconstruction method for minimizing errors in weight quantization.\nFurthermore, we design a flexible and programmable hardware accelerator by\nsupporting kernel fusion and customized instruction programmability, enhancing\nthroughput and efficiency. Experimental results demonstrate that our framework\nachieves competitive accuracy while enabling fast inference and higher energy\nefficiency on ASICs, bridging the gap between high-performance depth estimation\nand practical edge-device applicability. Code:\nhttps://github.com/shawnricecake/quart-depth",
      "tldr_zh": "本文提出 QuartDepth，一种后训练量化 (post-training quantization) 方法，旨在解决单目深度估计 (Monocular Depth Estimation, MDE) 模型在资源受限边缘设备（如 Application-Specific Integrated Circuits, ASICs）上的部署挑战，通过将权重和激活量化到 4-bit 精度来降低模型大小和计算成本。核心创新包括激活抛光和补偿算法、权重重建方法，以最小化量化带来的性能下降，以及设计支持内核融合和自定义指令的灵活硬件加速器，提升推理效率。实验结果显示，QuartDepth 在保持竞争性准确性的同时，实现快速推理和更高能量效率，显著提升了 MDE 在实际边缘设备中的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16709v1",
      "published_date": "2025-03-20 21:03:10 UTC",
      "updated_date": "2025-03-20 21:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:12:18.938011"
    },
    {
      "arxiv_id": "2503.16692v2",
      "title": "Limits of trust in medical AI",
      "title_zh": "医疗 AI 中信任的界限",
      "authors": [
        "Joshua Hatherley"
      ],
      "abstract": "Artificial intelligence (AI) is expected to revolutionize the practice of\nmedicine. Recent advancements in the field of deep learning have demonstrated\nsuccess in a variety of clinical tasks: detecting diabetic retinopathy from\nimages, predicting hospital readmissions, aiding in the discovery of new drugs,\netc. AI's progress in medicine, however, has led to concerns regarding the\npotential effects of this technology upon relationships of trust in clinical\npractice. In this paper, I will argue that there is merit to these concerns,\nsince AI systems can be relied upon, and are capable of reliability, but cannot\nbe trusted, and are not capable of trustworthiness. Insofar as patients are\nrequired to rely upon AI systems for their medical decision-making, there is\npotential for this to produce a deficit of trust in relationships in clinical\npractice.",
      "tldr_zh": "该论文探讨了AI在医学中的应用及其对临床信任关系的潜在限制。作者认为，虽然AI系统（如深度学习模型）在任务如检测糖尿病视网膜病变或预测再入院率上表现出可靠性（reliability），但它们无法具备真正的可信任性（trustworthiness），因为AI不能被真正信任（trusted）。结果，当患者依赖AI进行医疗决策时，这可能导致临床实践中的信任赤字，影响医患关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16692v2",
      "published_date": "2025-03-20 20:22:38 UTC",
      "updated_date": "2025-04-03 13:03:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:12:28.835973"
    },
    {
      "arxiv_id": "2503.16683v1",
      "title": "GAIR: Improving Multimodal Geo-Foundation Model with Geo-Aligned Implicit Representations",
      "title_zh": "GAIR：通过地理对齐隐式表示改进多模态地理基础模型",
      "authors": [
        "Zeping Liu",
        "Fan Zhang",
        "Junfeng Jiao",
        "Ni Lao",
        "Gengchen Mai"
      ],
      "abstract": "Advancements in vision and language foundation models have inspired the\ndevelopment of geo-foundation models (GeoFMs), enhancing performance across\ndiverse geospatial tasks. However, many existing GeoFMs primarily focus on\noverhead remote sensing (RS) data while neglecting other data modalities such\nas ground-level imagery. A key challenge in multimodal GeoFM development is to\nexplicitly model geospatial relationships across modalities, which enables\ngeneralizability across tasks, spatial scales, and temporal contexts. To\naddress these limitations, we propose GAIR, a novel multimodal GeoFM\narchitecture integrating overhead RS data, street view (SV) imagery, and their\ngeolocation metadata. We utilize three factorized neural encoders to project an\nSV image, its geolocation, and an RS image into the embedding space. The SV\nimage needs to be located within the RS image's spatial footprint but does not\nneed to be at its geographic center. In order to geographically align the SV\nimage and RS image, we propose a novel implicit neural representations (INR)\nmodule that learns a continuous RS image representation and looks up the RS\nembedding at the SV image's geolocation. Next, these geographically aligned SV\nembedding, RS embedding, and location embedding are trained with contrastive\nlearning objectives from unlabeled data. We evaluate GAIR across 10 geospatial\ntasks spanning RS image-based, SV image-based, and location embedding-based\nbenchmarks. Experimental results demonstrate that GAIR outperforms\nstate-of-the-art GeoFMs and other strong baselines, highlighting its\neffectiveness in learning generalizable and transferable geospatial\nrepresentations.",
      "tldr_zh": "该研究提出了 GAIR，一种新型多模态 Geo-Foundation Model（GeoFM），通过 Geo-Aligned Implicit Representations（INR）模块实现 overhead RS data（头顶遥感数据）、street view (SV) imagery（街景图像）和 geolocation metadata（地理位置元数据）之间的地理对齐。GAIR 利用三个 factorized neural encoders 将这些数据投影到嵌入空间，并通过 INR 模块学习连续 RS 图像表示，并结合 contrastive learning 目标从无标签数据中训练对齐嵌入。实验结果显示，GAIR 在 10 个地理空间任务（包括 RS 图像、SV 图像和位置嵌入基准）上优于现有 GeoFM 和基线模型，证明了其在学习可泛化和可转移的地理空间表示方面的显著有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.10"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16683v1",
      "published_date": "2025-03-20 19:59:39 UTC",
      "updated_date": "2025-03-20 19:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:12:43.342134"
    },
    {
      "arxiv_id": "2503.16681v2",
      "title": "GauRast: Enhancing GPU Triangle Rasterizers to Accelerate 3D Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Sixu Li",
        "Ben Keller",
        "Yingyan Celine Lin",
        "Brucek Khailany"
      ],
      "abstract": "3D intelligence leverages rich 3D features and stands as a promising frontier\nin AI, with 3D rendering fundamental to many downstream applications. 3D\nGaussian Splatting (3DGS), an emerging high-quality 3D rendering method,\nrequires significant computation, making real-time execution on existing\nGPU-equipped edge devices infeasible. Previous efforts to accelerate 3DGS rely\non dedicated accelerators that require substantial integration overhead and\nhardware costs. This work proposes an acceleration strategy that leverages the\nsimilarities between the 3DGS pipeline and the highly optimized conventional\ngraphics pipeline in modern GPUs. Instead of developing a dedicated\naccelerator, we enhance existing GPU rasterizer hardware to efficiently support\n3DGS operations. Our results demonstrate a 23$\\times$ increase in processing\nspeed and a 24$\\times$ reduction in energy consumption, with improvements\nyielding 6$\\times$ faster end-to-end runtime for the original 3DGS algorithm\nand 4$\\times$ for the latest efficiency-improved pipeline, achieving 24 FPS and\n46 FPS respectively. These enhancements incur only a minimal area overhead of\n0.2\\% relative to the entire SoC chip area, underscoring the practicality and\nefficiency of our approach for enabling 3DGS rendering on resource-constrained\nplatforms.",
      "tldr_zh": "本研究提出GauRast方法，通过增强GPU三角形光栅化硬件，利用3D Gaussian Splatting (3DGS)管道与传统图形管道的相似性，来加速3DGS渲染过程，而非依赖专用加速器。实验结果显示，该方法实现了23倍的处理速度提升和24倍的能源消耗减少，端到端运行时间分别使原始3DGS算法加快6倍（达到24 FPS）和最新效率改进管道加快4倍（达到46 FPS）。这种优化仅需0.2%的芯片面积开销，即可使3DGS在资源受限平台上实现高效实时渲染。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.GR",
      "comment": "DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16681v2",
      "published_date": "2025-03-20 19:54:05 UTC",
      "updated_date": "2025-04-10 19:43:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:12:55.057503"
    },
    {
      "arxiv_id": "2503.16679v1",
      "title": "Echoes of Power: Investigating Geopolitical Bias in US and China Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andre G. C. Pacheco",
        "Athus Cavalini",
        "Giovanni Comarela"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\nhuman-like text, transforming human-machine interactions. However, their\nwidespread adoption has raised concerns about their potential to influence\npublic opinion and shape political narratives. In this work, we investigate the\ngeopolitical biases in US and Chinese LLMs, focusing on how these models\nrespond to questions related to geopolitics and international relations. We\ncollected responses from ChatGPT and DeepSeek to a set of geopolitical\nquestions and evaluated their outputs through both qualitative and quantitative\nanalyses. Our findings show notable biases in both models, reflecting distinct\nideological perspectives and cultural influences. However, despite these\nbiases, for a set of questions, the models' responses are more aligned than\nexpected, indicating that they can address sensitive topics without necessarily\npresenting directly opposing viewpoints. This study highlights the potential of\nLLMs to shape public discourse and underscores the importance of critically\nassessing AI-generated content, particularly in politically sensitive contexts.",
      "tldr_zh": "本研究调查了美国和中国的LLMs（如ChatGPT和DeepSeek）在回应地缘政治和国际关系问题时的偏见，通过收集模型回应并进行定性和定量分析。结果显示，两个模型均存在显著的意识形态和文化影响导致的偏见，但对于某些问题，它们回应较为一致而非直接对立。该研究强调了LLMs可能塑造公共话语的风险，并呼吁在政治敏感领域 critically 评估AI生成内容，以确保其客观性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16679v1",
      "published_date": "2025-03-20 19:53:10 UTC",
      "updated_date": "2025-03-20 19:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:13:07.706120"
    },
    {
      "arxiv_id": "2503.16672v1",
      "title": "Accelerating Transformer Inference and Training with 2:4 Activation Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Haziza",
        "Timothy Chou",
        "Dhruv Choudhary",
        "Luca Wehrstedt",
        "Francisco Massa",
        "Jiecao Yu",
        "Geonhwa Jeong",
        "Supriya Rao",
        "Patrick Labatut",
        "Jesse Cai"
      ],
      "abstract": "In this paper, we demonstrate how to leverage 2:4 sparsity, a popular\nhardware-accelerated GPU sparsity pattern, to activations to accelerate large\nlanguage model training and inference. Crucially we exploit the intrinsic\nsparsity found in Squared-ReLU activations to provide this acceleration with no\naccuracy loss. Our approach achieves up to 1.3x faster Feed Forward Network\n(FFNs) in both the forwards and backwards pass. This work highlights the\npotential for sparsity to play a key role in accelerating large language model\ntraining and inference.",
      "tldr_zh": "本论文探讨了如何利用2:4 sparsity（一种硬件加速的GPU稀疏模式）来加速Transformer模型的训练和推理。研究者通过利用Squared-ReLU激活函数的内在稀疏性，实现Feed Forward Network (FFNs)在正向和反向传递中的速度提升高达1.3倍，同时保持准确性无损失。该方法突出了稀疏性在加速大语言模型训练和推理中的关键作用，为高效模型优化提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16672v1",
      "published_date": "2025-03-20 19:37:12 UTC",
      "updated_date": "2025-03-20 19:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:13:18.682971"
    },
    {
      "arxiv_id": "2503.17408v1",
      "title": "Leveraging OpenFlamingo for Multimodal Embedding Analysis of C2C Car Parts Data",
      "title_zh": "翻译失败",
      "authors": [
        "Maisha Binte Rashid",
        "Pablo Rivas"
      ],
      "abstract": "In this paper, we aim to investigate the capabilities of multimodal machine\nlearning models, particularly the OpenFlamingo model, in processing a\nlarge-scale dataset of consumer-to-consumer (C2C) online posts related to car\nparts. We have collected data from two platforms, OfferUp and Craigslist,\nresulting in a dataset of over 1.2 million posts with their corresponding\nimages. The OpenFlamingo model was used to extract embeddings for the text and\nimage of each post. We used $k$-means clustering on the joint embeddings to\nidentify underlying patterns and commonalities among the posts. We have found\nthat most clusters contain a pattern, but some clusters showed no internal\npatterns. The results provide insight into the fact that OpenFlamingo can be\nused for finding patterns in large datasets but needs some modification in the\narchitecture according to the dataset.",
      "tldr_zh": "本研究利用 OpenFlamingo 模型对消费者间（C2C）汽车零件在线帖子进行多模态嵌入分析，目标是评估其处理大规模数据集的能力。研究者从 OfferUp 和 Craigslist 平台收集了超过120万条帖子及其图像，使用 OpenFlamingo 提取文本和图像的联合嵌入，并应用 k-means clustering 识别模式。结果显示，大多数聚类显示出内部模式，但部分聚类缺乏明显规律，表明 OpenFlamingo 适合发现大型数据集中的模式，但需根据特定数据集修改架构以提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.10; I.2.7; I.5; H.3.3; H.3.1"
      ],
      "primary_category": "cs.LG",
      "comment": "The 26th International Conference on Artificial Intelligence\n  (ICAI'24: July 22-25, 2024; Las Vegas, USA)",
      "pdf_url": "http://arxiv.org/pdf/2503.17408v1",
      "published_date": "2025-03-20 19:35:15 UTC",
      "updated_date": "2025-03-20 19:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:13:31.142854"
    },
    {
      "arxiv_id": "2503.16669v1",
      "title": "Aligning Text-to-Music Evaluation with Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Huang",
        "Zachary Novack",
        "Koichi Saito",
        "Jiatong Shi",
        "Shinji Watanabe",
        "Yuki Mitsufuji",
        "John Thickstun",
        "Chris Donahue"
      ],
      "abstract": "Despite significant recent advances in generative acoustic text-to-music\n(TTM) modeling, robust evaluation of these models lags behind, relying in\nparticular on the popular Fr\\'echet Audio Distance (FAD). In this work, we\nrigorously study the design space of reference-based divergence metrics for\nevaluating TTM models through (1) designing four synthetic meta-evaluations to\nmeasure sensitivity to particular musical desiderata, and (2) collecting and\nevaluating on MusicPrefs, the first open-source dataset of human preferences\nfor TTM systems. We find that not only is the standard FAD setup inconsistent\non both synthetic and human preference data, but that nearly all existing\nmetrics fail to effectively capture desiderata, and are only weakly correlated\nwith human perception. We propose a new metric, the MAUVE Audio Divergence\n(MAD), computed on representations from a self-supervised audio embedding\nmodel. We find that this metric effectively captures diverse musical desiderata\n(average rank correlation 0.84 for MAD vs. 0.49 for FAD and also correlates\nmore strongly with MusicPrefs (0.62 vs. 0.14).",
      "tldr_zh": "本论文探讨了文本到音乐(TTM)生成模型的评估问题，指出现有指标如Fréchet Audio Distance (FAD)无法有效捕捉音乐需求，且与人类感知相关性弱。研究者设计了四个合成元评估和首个开源数据集MusicPrefs，以评估TTM模型对特定音乐偏好的敏感性。最终，他们提出新指标MAUVE Audio Divergence (MAD)，基于自监督音频嵌入模型，能更好地捕捉多样化音乐需求（平均排名相关性0.84 vs. FAD的0.49），并与人类偏好数据相关性更强（0.62 vs. 0.14）。这为更可靠的TTM模型评估提供了重要改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16669v1",
      "published_date": "2025-03-20 19:31:04 UTC",
      "updated_date": "2025-03-20 19:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:13:44.226151"
    },
    {
      "arxiv_id": "2503.16668v1",
      "title": "Code Evolution Graphs: Understanding Large Language Model Driven Design of Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Niki van Stein",
        "Anna V. Kononova",
        "Lars Kotthoff",
        "Thomas Bäck"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great promise in generating\ncode, especially when used inside an evolutionary computation framework to\niteratively optimize the generated algorithms. However, in some cases they fail\nto generate competitive algorithms or the code optimization stalls, and we are\nleft with no recourse because of a lack of understanding of the generation\nprocess and generated codes. We present a novel approach to mitigate this\nproblem by enabling users to analyze the generated codes inside the\nevolutionary process and how they evolve over repeated prompting of the LLM. We\nshow results for three benchmark problem classes and demonstrate novel\ninsights. In particular, LLMs tend to generate more complex code with repeated\nprompting, but additional complexity can hurt algorithmic performance in some\ncases. Different LLMs have different coding ``styles'' and generated code tends\nto be dissimilar to other LLMs. These two findings suggest that using different\nLLMs inside the code evolution frameworks might produce higher performing code\nthan using only one LLM.",
      "tldr_zh": "该研究提出了一种名为 Code Evolution Graphs 的新方法，用于分析大型语言模型（LLMs）在进化计算框架中驱动算法设计的过程，从而解决代码生成失败或优化停滞的问题。该方法允许用户追踪代码在重复提示下的演变轨迹，并在三个基准问题类上进行了实验。结果显示，LLMs 倾向于生成更复杂的代码，但这种复杂性有时会降低算法性能；此外，不同 LLMs 具有独特的编码风格，且生成的代码差异显著，这表明在代码进化框架中使用多种 LLMs 可能提升整体性能。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at GECCO 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16668v1",
      "published_date": "2025-03-20 19:30:22 UTC",
      "updated_date": "2025-03-20 19:30:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:13:55.064515"
    },
    {
      "arxiv_id": "2503.21793v1",
      "title": "Input-Triggered Hardware Trojan Attack on Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Spyridon Raptis",
        "Paul Kling",
        "Ioannis Kaskampas",
        "Ihsen Alouani",
        "Haralampos-G. Stratigopoulos"
      ],
      "abstract": "Neuromorphic computing based on spiking neural networks (SNNs) is emerging as\na promising alternative to traditional artificial neural networks (ANNs),\noffering unique advantages in terms of low power consumption. However, the\nsecurity aspect of SNNs is under-explored compared to their ANN counterparts.\nAs the increasing reliance on AI systems comes with unique security risks and\nchallenges, understanding the vulnerabilities and threat landscape is essential\nas neuromorphic computing matures. In this effort, we propose a novel\ninput-triggered Hardware Trojan (HT) attack for SNNs. The HT mechanism is\ncondensed in the area of one neuron. The trigger mechanism is an input message\ncrafted in the spiking domain such that a selected neuron produces a malicious\nspike train that is not met in normal settings. This spike train triggers a\nmalicious modification in the neuron that forces it to saturate, firing\npermanently and failing to recover to its resting state even when the input\nactivity stops. The excessive spikes pollute the network and produce misleading\ndecisions. We propose a methodology to select an appropriate neuron and to\ngenerate the input pattern that triggers the HT payload. The attack is\nillustrated by simulation on three popular benchmarks in the neuromorphic\ncommunity. We also propose a hardware implementation for an analog spiking\nneuron and a digital SNN accelerator, demonstrating that the HT has a\nnegligible area and power footprint and, thereby, can easily evade detection.",
      "tldr_zh": "该研究探讨了基于脉冲神经网络 (SNNs) 的神经形态计算的安全漏洞，提出了一种新型输入触发的 Hardware Trojan (HT) 攻击。攻击机制通过在单个神经元区域植入恶意代码，利用精心设计的脉冲域输入消息触发神经元产生异常脉冲序列，导致其永久饱和并污染整个网络，进而造成误导性决策。实验在三个流行基准上模拟验证了攻击的有效性，并通过硬件实现（包括模拟脉冲神经元和数字 SNN 加速器）证明了 HT 的面积和功耗极低，便于逃避检测，为 SNNs 的安全防护提供了重要警示。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.21793v1",
      "published_date": "2025-03-20 19:24:30 UTC",
      "updated_date": "2025-03-20 19:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:14:07.349209"
    },
    {
      "arxiv_id": "2504.08738v2",
      "title": "AI-Driven Sentiment Analytics: Unlocking Business Value in the E-Commerce Landscape_v1",
      "title_zh": "翻译失败",
      "authors": [
        "Qianye Wu",
        "Chengxuan Xia",
        "Sixuan Tian"
      ],
      "abstract": "The rapid growth of e-commerce has led to an overwhelming volume of customer\nfeedback, from product reviews to service interactions. Extracting meaningful\ninsights from this data is crucial for businesses aiming to improve customer\nsatisfaction and optimize decision-making. This paper presents an AI-driven\nsentiment analysis system designed specifically for e-commerce applications,\nbalancing accuracy with interpretability. Our approach integrates traditional\nmachine learning techniques with modern deep learning models, allowing for a\nmore nuanced understanding of customer sentiment while ensuring transparency in\ndecision-making. Experimental results show that our system outperforms standard\nsentiment analysis methods, achieving an accuracy of 89.7% on diverse,\nlarge-scale datasets. Beyond technical performance, real-world implementation\nacross multiple e-commerce platforms demonstrates tangible improvements in\ncustomer engagement and operational efficiency. This study highlights both the\npotential and the challenges of applying AI to sentiment analysis in a\ncommercial setting, offering insights into practical deployment strategies and\nareas for future refinement.",
      "tldr_zh": "这篇论文提出了一种AI-driven sentiment analysis系统，针对电子商务领域的海量客户反馈，帮助企业提升客户满意度和决策优化。该系统结合传统machine learning和现代deep learning模型，提供更细致的客户情感理解，同时确保决策过程的可解释性。实验结果显示，该系统在大型数据集上准确率达到89.7%，优于标准方法，并在实际电子商务平台部署中显著改善了客户参与度和运营效率。该研究还探讨了AI在商业情境中的潜在挑战、部署策略及未来改进方向。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.IR",
      "comment": "7 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.08738v2",
      "published_date": "2025-03-20 18:56:22 UTC",
      "updated_date": "2025-04-16 05:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:14:19.586963"
    },
    {
      "arxiv_id": "2503.16628v1",
      "title": "MobilePlantViT: A Mobile-friendly Hybrid ViT for Generalized Plant Disease Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Moshiur Rahman Tonmoy",
        "Md. Mithun Hossain",
        "Nilanjan Dey",
        "M. F. Mridha"
      ],
      "abstract": "Plant diseases significantly threaten global food security by reducing crop\nyields and undermining agricultural sustainability. AI-driven automated\nclassification has emerged as a promising solution, with deep learning models\ndemonstrating impressive performance in plant disease identification. However,\ndeploying these models on mobile and edge devices remains challenging due to\nhigh computational demands and resource constraints, highlighting the need for\nlightweight, accurate solutions for accessible smart agriculture systems. To\naddress this, we propose MobilePlantViT, a novel hybrid Vision Transformer\n(ViT) architecture designed for generalized plant disease classification, which\noptimizes resource efficiency while maintaining high performance. Extensive\nexperiments across diverse plant disease datasets of varying scales show our\nmodel's effectiveness and strong generalizability, achieving test accuracies\nranging from 80% to over 99%. Notably, with only 0.69 million parameters, our\narchitecture outperforms the smallest versions of MobileViTv1 and MobileViTv2,\ndespite their higher parameter counts. These results underscore the potential\nof our approach for real-world, AI-powered automated plant disease\nclassification in sustainable and resource-efficient smart agriculture systems.\nAll codes will be available in the GitHub repository:\nhttps://github.com/moshiurtonmoy/MobilePlantViT",
      "tldr_zh": "该研究针对植物疾病对全球粮食安全的威胁，提出了一种轻量级混合 Vision Transformer (ViT) 架构——MobilePlantViT，用于广义的植物疾病图像分类，以适应移动和边缘设备的资源限制。MobilePlantViT 优化了计算效率，仅需 0.69 百万参数，同时保持高性能，并在多种规模的数据集上实现了 80% 到超过 99% 的测试准确率。相比 MobileViTv1 和 MobileViTv2 的小型版本，该模型在参数更少的情况下表现出色，证明了其强泛化能力。这些结果突显了 MobilePlantViT 在可持续、智能农业系统的实际应用潜力，有助于推动 AI 驱动的植物病害识别。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Submitted to a journal for peer-review under IEEE Transactions series",
      "pdf_url": "http://arxiv.org/pdf/2503.16628v1",
      "published_date": "2025-03-20 18:34:02 UTC",
      "updated_date": "2025-03-20 18:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:14:32.032071"
    },
    {
      "arxiv_id": "2503.16614v1",
      "title": "Classification of User Reports for Detection of Faulty Computer Components using NLP Models: A Case Study",
      "title_zh": "利用 NLP 模型对用户报告进行分类以检测故障计算机组件：一个案例研究",
      "authors": [
        "Maria de Lourdes M. Silva",
        "André L. C. Mendonça",
        "Eduardo R. D. Neto",
        "Iago C. Chaves",
        "Felipe T. Brito",
        "Victor A. E. Farias",
        "Javam C. Machado"
      ],
      "abstract": "Computer manufacturers typically offer platforms for users to report faults.\nHowever, there remains a significant gap in these platforms' ability to\neffectively utilize textual reports, which impedes users from describing their\nissues in their own words. In this context, Natural Language Processing (NLP)\noffers a promising solution, by enabling the analysis of user-generated text.\nThis paper presents an innovative approach that employs NLP models to classify\nuser reports for detecting faulty computer components, such as CPU, memory,\nmotherboard, video card, and more. In this work, we build a dataset of 341 user\nreports obtained from many sources. Additionally, through extensive\nexperimental evaluation, our approach achieved an accuracy of 79% with our\ndataset.",
      "tldr_zh": "本研究针对计算机故障报告平台的文本利用问题，提出了一种使用 NLP（Natural Language Processing）模型来分类用户报告的方法，以检测故障组件如 CPU、memory、motherboard 和 video card 等。该方法通过构建一个包含 341 个用户报告的数据集，实现了对用户自述问题的自动分析和分类。实验结果显示，该方法在数据集上达到了 79% 的准确率，为提升故障检测效率提供了实际案例。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16614v1",
      "published_date": "2025-03-20 18:11:26 UTC",
      "updated_date": "2025-03-20 18:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:14:42.149246"
    },
    {
      "arxiv_id": "2503.16611v1",
      "title": "A Recipe for Generating 3D Worlds From a Single Image",
      "title_zh": "一种从单一图像生成三维世界的配方",
      "authors": [
        "Katja Schwarz",
        "Denys Rozumnyi",
        "Samuel Rota Bulò",
        "Lorenzo Porzi",
        "Peter Kontschieder"
      ],
      "abstract": "We introduce a recipe for generating immersive 3D worlds from a single image\nby framing the task as an in-context learning problem for 2D inpainting models.\nThis approach requires minimal training and uses existing generative models.\nOur process involves two steps: generating coherent panoramas using a\npre-trained diffusion model and lifting these into 3D with a metric depth\nestimator. We then fill unobserved regions by conditioning the inpainting model\non rendered point clouds, requiring minimal fine-tuning. Tested on both\nsynthetic and real images, our method produces high-quality 3D environments\nsuitable for VR display. By explicitly modeling the 3D structure of the\ngenerated environment from the start, our approach consistently outperforms\nstate-of-the-art, video synthesis-based methods along multiple quantitative\nimage quality metrics. Project Page: https://katjaschwarz.github.io/worlds/",
      "tldr_zh": "本研究提出了一种从单张图像生成沉浸式3D世界的配方，将任务框架化为2D inpainting模型的in-context learning问题，仅需最小训练并利用现有生成模型。方法包括两个步骤：首先使用预训练的diffusion模型生成连贯的全景图，然后通过metric depth estimator将这些全景图提升到3D，并以渲染的点云为条件对inpainting模型进行最小微调以填充未观察区域。实验结果显示，该方法在合成和真实图像上产生高质量的3D环境，适合VR显示，并在多个定量图像质量指标上优于基于视频合成的SOTA方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16611v1",
      "published_date": "2025-03-20 18:06:12 UTC",
      "updated_date": "2025-03-20 18:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:14:55.783367"
    },
    {
      "arxiv_id": "2503.16421v1",
      "title": "MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance",
      "title_zh": "MagicMotion：基于从密集到稀疏轨迹引导的可控视频生成",
      "authors": [
        "Quanhao Li",
        "Zhen Xing",
        "Rui Wang",
        "Hui Zhang",
        "Qi Dai",
        "Zuxuan Wu"
      ],
      "abstract": "Recent advances in video generation have led to remarkable improvements in\nvisual quality and temporal coherence. Upon this, trajectory-controllable video\ngeneration has emerged to enable precise object motion control through\nexplicitly defined spatial paths. However, existing methods struggle with\ncomplex object movements and multi-object motion control, resulting in\nimprecise trajectory adherence, poor object consistency, and compromised visual\nquality. Furthermore, these methods only support trajectory control in a single\nformat, limiting their applicability in diverse scenarios. Additionally, there\nis no publicly available dataset or benchmark specifically tailored for\ntrajectory-controllable video generation, hindering robust training and\nsystematic evaluation. To address these challenges, we introduce MagicMotion, a\nnovel image-to-video generation framework that enables trajectory control\nthrough three levels of conditions from dense to sparse: masks, bounding boxes,\nand sparse boxes. Given an input image and trajectories, MagicMotion seamlessly\nanimates objects along defined trajectories while maintaining object\nconsistency and visual quality. Furthermore, we present MagicData, a\nlarge-scale trajectory-controlled video dataset, along with an automated\npipeline for annotation and filtering. We also introduce MagicBench, a\ncomprehensive benchmark that assesses both video quality and trajectory control\naccuracy across different numbers of objects. Extensive experiments demonstrate\nthat MagicMotion outperforms previous methods across various metrics. Our\nproject page are publicly available at\nhttps://quanhaol.github.io/magicmotion-site.",
      "tldr_zh": "本研究提出 MagicMotion，一种新型图像到视频生成框架，通过从密集到稀疏的轨迹指导（包括 masks、bounding boxes 和 sparse boxes）实现对物体运动的精确控制，解决了现有方法在复杂多物体场景中存在的轨迹不精确、物体不一致和视觉质量问题。MagicMotion 框架以输入图像为基础，生成沿指定轨迹动画化的视频，同时保持高一致性和质量。研究者还构建了 MagicData 数据集（一个大规模轨迹控制视频数据集）和 MagicBench 基准，用于系统评估视频质量和轨迹准确性。实验结果显示，MagicMotion 在各种指标上优于现有方法，为轨迹可控视频生成提供了更可靠的工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16421v1",
      "published_date": "2025-03-20 17:59:42 UTC",
      "updated_date": "2025-03-20 17:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:15:07.963834"
    },
    {
      "arxiv_id": "2503.16416v1",
      "title": "Survey on Evaluation of LLM-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Asaf Yehudai",
        "Lilach Eden",
        "Alan Li",
        "Guy Uziel",
        "Yilun Zhao",
        "Roy Bar-Haim",
        "Arman Cohan",
        "Michal Shmueli-Scheuer"
      ],
      "abstract": "The emergence of LLM-based agents represents a paradigm shift in AI, enabling\nautonomous systems to plan, reason, use tools, and maintain memory while\ninteracting with dynamic environments. This paper provides the first\ncomprehensive survey of evaluation methodologies for these increasingly capable\nagents. We systematically analyze evaluation benchmarks and frameworks across\nfour critical dimensions: (1) fundamental agent capabilities, including\nplanning, tool use, self-reflection, and memory; (2) application-specific\nbenchmarks for web, software engineering, scientific, and conversational\nagents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating\nagents. Our analysis reveals emerging trends, including a shift toward more\nrealistic, challenging evaluations with continuously updated benchmarks. We\nalso identify critical gaps that future research must address-particularly in\nassessing cost-efficiency, safety, and robustness, and in developing\nfine-grained, and scalable evaluation methods. This survey maps the rapidly\nevolving landscape of agent evaluation, reveals the emerging trends in the\nfield, identifies current limitations, and proposes directions for future\nresearch.",
      "tldr_zh": "这篇论文是首个全面调查 LLM-based agents 评估方法学的综述，探讨了这些代理在规划、推理、使用工具和记忆等方面的核心能力。研究系统分析了评估基准和框架，包括基本代理能力、特定应用（如网络和软件工程）、通用代理基准，以及整体评估框架。调查揭示了评估趋势，如更注重现实性和持续更新基准，并识别了关键空白，包括成本效率、安全性、鲁棒性评估的不足，并提出开发更细粒度、可扩展方法的未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16416v1",
      "published_date": "2025-03-20 17:59:23 UTC",
      "updated_date": "2025-03-20 17:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:15:20.370712"
    },
    {
      "arxiv_id": "2503.16412v1",
      "title": "DreamTexture: Shape from Virtual Texture with Analysis by Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ananta R. Bhattarai",
        "Xingzhe He",
        "Alla Sheffer",
        "Helge Rhodin"
      ],
      "abstract": "DreamFusion established a new paradigm for unsupervised 3D reconstruction\nfrom virtual views by combining advances in generative models and\ndifferentiable rendering. However, the underlying multi-view rendering, along\nwith supervision from large-scale generative models, is computationally\nexpensive and under-constrained. We propose DreamTexture, a novel\nShape-from-Virtual-Texture approach that leverages monocular depth cues to\nreconstruct 3D objects. Our method textures an input image by aligning a\nvirtual texture with the real depth cues in the input, exploiting the inherent\nunderstanding of monocular geometry encoded in modern diffusion models. We then\nreconstruct depth from the virtual texture deformation with a new conformal map\noptimization, which alleviates memory-intensive volumetric representations. Our\nexperiments reveal that generative models possess an understanding of monocular\nshape cues, which can be extracted by augmenting and aligning texture cues -- a\nnovel monocular reconstruction paradigm that we call Analysis by Augmentation.",
      "tldr_zh": "该论文提出DreamTexture，一种基于虚拟纹理的3D重建方法，称为Shape-from-Virtual-Texture，利用单目深度线索来解决传统无监督重建（如DreamFusion）计算昂贵和约束不足的问题。具体而言，该方法通过将虚拟纹理与输入图像的真实深度线索对齐，并运用扩散模型中编码的单目几何理解，再结合新的保形映射优化从纹理变形中重建深度，从而避免了内存密集的体积表示。实验结果显示，生成模型具备对单目形状线索的内在理解，这可以通过一种新型范式Analysis by Augmentation（通过增强和对齐纹理线索）来提取，提升了3D对象的重建效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://anantarb.github.io/dreamtexture/",
      "pdf_url": "http://arxiv.org/pdf/2503.16412v1",
      "published_date": "2025-03-20 17:59:12 UTC",
      "updated_date": "2025-03-20 17:59:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:15:32.316836"
    },
    {
      "arxiv_id": "2503.16408v1",
      "title": "RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Qin",
        "Li Kang",
        "Xiufeng Song",
        "Zhenfei Yin",
        "Xiaohong Liu",
        "Xihui Liu",
        "Ruimao Zhang",
        "Lei Bai"
      ],
      "abstract": "Designing effective embodied multi-agent systems is critical for solving\ncomplex real-world tasks across domains. Due to the complexity of multi-agent\nembodied systems, existing methods fail to automatically generate safe and\nefficient training data for such systems. To this end, we propose the concept\nof compositional constraints for embodied multi-agent systems, addressing the\nchallenges arising from collaboration among embodied agents. We design various\ninterfaces tailored to different types of constraints, enabling seamless\ninteraction with the physical world. Leveraging compositional constraints and\nspecifically designed interfaces, we develop an automated data collection\nframework for embodied multi-agent systems and introduce the first benchmark\nfor embodied multi-agent manipulation, RoboFactory. Based on RoboFactory\nbenchmark, we adapt and evaluate the method of imitation learning and analyzed\nits performance in different difficulty agent tasks. Furthermore, we explore\nthe architectures and training strategies for multi-agent imitation learning,\naiming to build safe and efficient embodied multi-agent systems.",
      "tldr_zh": "本文提出compositional constraints的概念，用于解决embodied multi-agent systems中代理协作的挑战，从而自动生成安全高效的训练数据。研究设计了针对不同约束类型的接口，并开发了一个自动化数据收集框架，同时引入了首个embodied multi-agent manipulation基准RoboFactory。基于RoboFactory，作者评估了imitation learning方法的适应性和性能，探索了多代理模仿学习的架构及训练策略，以提升系统的安全性和效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://iranqin.github.io/robofactory/",
      "pdf_url": "http://arxiv.org/pdf/2503.16408v1",
      "published_date": "2025-03-20 17:58:38 UTC",
      "updated_date": "2025-03-20 17:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:15:44.894188"
    },
    {
      "arxiv_id": "2503.16402v1",
      "title": "The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Sun",
        "Han Wang",
        "Dongbai Li",
        "Gang Wang",
        "Huan Zhang"
      ],
      "abstract": "Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples\nin the training set-has raised increasing concerns in Large Language Model\n(LLM) evaluation, leading to falsely inflated performance estimates and\nundermining evaluation reliability. To address this, researchers have proposed\nvarious mitigation strategies to update existing benchmarks, including\nmodifying original questions or generating new ones based on them. However, a\nrigorous examination of the effectiveness of these mitigation strategies\nremains lacking. In this paper, we design a systematic and controlled pipeline\nalong with two novel metrics-fidelity and contamination resistance-to provide a\nfine-grained and comprehensive assessment of existing BDC mitigation\nstrategies. Previous assessment methods, such as accuracy drop and accuracy\nmatching, focus solely on aggregate accuracy, often leading to incomplete or\nmisleading conclusions. Our metrics address this limitation by emphasizing\nquestion-level evaluation result matching. Extensive experiments with 10 LLMs,\n5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios\nreveal that no existing strategy significantly improves resistance over the\nvanilla case (i.e., no benchmark update) across all benchmarks, and none\neffectively balances fidelity and contamination resistance. These findings\nunderscore the urgent need for designing more effective BDC mitigation\nstrategies. Our code repository is available at\nhttps://github.com/ASTRAL-Group/BDC_mitigation_assessment.",
      "tldr_zh": "这篇论文系统评估了Large Language Model (LLM)基准测试数据污染（Benchmark Data Contamination, BDC）问题及其缓解策略的有效性，指出现有策略（如修改问题或生成新问题）可能导致评估结果不准确。研究者设计了一个系统化的评估管道和两个新指标——fidelity（保真度）和contamination resistance（污染抵抗力）——通过强调问题级别的匹配评估，弥补了以往仅关注总体准确率的局限。实验涉及10个LLM、5个基准、20种缓解策略和2个污染场景，结果显示没有任何策略显著优于未更新的基准，且无法有效平衡fidelity和contamination resistance，这突显了设计更可靠BDC缓解策略的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16402v1",
      "published_date": "2025-03-20 17:55:04 UTC",
      "updated_date": "2025-03-20 17:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:15:56.331824"
    },
    {
      "arxiv_id": "2503.16399v1",
      "title": "SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Chen",
        "Zhirui Wang",
        "Taowei Sheng",
        "Yi Jiang",
        "Yundu Li",
        "Peirui Cheng",
        "Luning Zhang",
        "Kaiqiang Chen",
        "Yanfeng Hu",
        "Xue Yang",
        "Xian Sun"
      ],
      "abstract": "Existing vision-based 3D occupancy prediction methods are inherently limited\nin accuracy due to their exclusive reliance on street-view imagery, neglecting\nthe potential benefits of incorporating satellite views. We propose SA-Occ, the\nfirst Satellite-Assisted 3D occupancy prediction model, which leverages GPS &\nIMU to integrate historical yet readily available satellite imagery into\nreal-time applications, effectively mitigating limitations of ego-vehicle\nperceptions, involving occlusions and degraded performance in distant regions.\nTo address the core challenges of cross-view perception, we propose: 1)\nDynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions\ncaused by the temporal asynchrony between satellite and street views; 2)\n3D-Proj Guidance, a module that enhances 3D feature extraction from inherently\n2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the\nsampling density between street and satellite views. Evaluated on\nOcc3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among\nsingle-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring\nonly 6.93 ms of additional latency per frame. Our code and newly curated\ndataset are available at https://github.com/chenchen235/SA-Occ.",
      "tldr_zh": "该研究提出SA-Occ，一种结合卫星图像的3D Occupancy Prediction模型，利用GPS和IMU将历史卫星数据整合到实时应用中，解决街景图像感知中的遮挡和远距离性能问题。针对跨视图感知挑战，该模型引入Dynamic-Decoupling Fusion处理动态区域的时间不一致、3D-Proj Guidance增强从2D卫星图像中提取3D特征，以及Uniform Sampling Alignment对齐街景和卫星视图的采样密度。在Occ3D-nuScenes数据集上，SA-Occ实现最先进性能，mIoU达到39.05%（较基线提升6.97%），额外延迟仅6.93 ms。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.16399v1",
      "published_date": "2025-03-20 17:54:29 UTC",
      "updated_date": "2025-03-20 17:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:16:07.454994"
    },
    {
      "arxiv_id": "2503.16394v1",
      "title": "Do Visual Imaginations Improve Vision-and-Language Navigation Agents?",
      "title_zh": "翻译失败",
      "authors": [
        "Akhil Perincherry",
        "Jacob Krantz",
        "Stefan Lee"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) agents are tasked with navigating an\nunseen environment using natural language instructions. In this work, we study\nif visual representations of sub-goals implied by the instructions can serve as\nnavigational cues and lead to increased navigation performance. To synthesize\nthese visual representations or imaginations, we leverage a text-to-image\ndiffusion model on landmark references contained in segmented instructions.\nThese imaginations are provided to VLN agents as an added modality to act as\nlandmark cues and an auxiliary loss is added to explicitly encourage relating\nthese with their corresponding referring expressions. Our findings reveal an\nincrease in success rate (SR) of around 1 point and up to 0.5 points in success\nscaled by inverse path length (SPL) across agents. These results suggest that\nthe proposed approach reinforces visual understanding compared to relying on\nlanguage instructions alone. Code and data for our work can be found at\nhttps://www.akhilperincherry.com/VLN-Imagine-website/.",
      "tldr_zh": "本研究探讨了是否通过视觉想象来提升视觉语言导航(VLN)代理的性能，具体考察了从指令中提取的地标引用生成的视觉表示是否能作为导航线索。研究方法利用文本到图像扩散模型合成这些视觉想象，并将其作为额外模态提供给VLN代理，同时添加辅助损失以强化视觉表示与语言表达的关联。实验结果显示，成功率(SR)提高了约1点，成功率按逆路径长度缩放(SPL)提高了最多0.5点，表明这种方法增强了代理的视觉理解效果，比仅依赖语言指令更有效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16394v1",
      "published_date": "2025-03-20 17:53:12 UTC",
      "updated_date": "2025-03-20 17:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:16:19.330881"
    },
    {
      "arxiv_id": "2503.16392v2",
      "title": "Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Anket Mehra",
        "Andreas Aßmuth",
        "Malte Prieß"
      ],
      "abstract": "With AI-based software becoming widely available, the risk of exploiting its\ncapabilities, such as high automation and complex pattern recognition, could\nsignificantly increase. An AI used offensively to attack non-AI assets is\nreferred to as offensive AI.\n  Current research explores how offensive AI can be utilized and how its usage\ncan be classified. Additionally, methods for threat modeling are being\ndeveloped for AI-based assets within organizations. However, there are gaps\nthat need to be addressed. Firstly, there is a need to quantify the factors\ncontributing to the AI threat. Secondly, there is a requirement to create\nthreat models that analyze the risk of being attacked by AI for vulnerability\nassessment across all assets of an organization. This is particularly crucial\nand challenging in cloud environments, where sophisticated infrastructure and\naccess control landscapes are prevalent. The ability to quantify and further\nanalyze the threat posed by offensive AI enables analysts to rank\nvulnerabilities and prioritize the implementation of proactive countermeasures.\n  To address these gaps, this paper introduces the Graph of Effort, an\nintuitive, flexible, and effective threat modeling method for analyzing the\neffort required to use offensive AI for vulnerability exploitation by an\nadversary. While the threat model is functional and provides valuable support,\nits design choices need further empirical validation in future work.",
      "tldr_zh": "该论文探讨了进攻性 AI（offensive AI）在漏洞评估中的风险，强调AI的自动化和模式识别能力可能被用于攻击组织资产，尤其在云环境中。论文引入了Graph of Effort，这是一种直观、灵活的威胁建模方法，用于量化对手利用进攻性 AI 进行漏洞利用所需的努力，从而帮助分析师排名漏洞并优先实施预防措施。该方法虽然有效，但设计选择仍需未来实证验证以进一步完善。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16392v2",
      "published_date": "2025-03-20 17:52:42 UTC",
      "updated_date": "2025-04-07 10:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:16:32.822715"
    },
    {
      "arxiv_id": "2503.16389v1",
      "title": "Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Kristin Qi",
        "Xinhan Di"
      ],
      "abstract": "Retinal Optical Coherence Tomography (OCT) segmentation is essential for\ndiagnosing pathology. Traditional methods focus on either spatial or spectral\ndomains, overlooking their combined dependencies. We propose a triple-encoder\nnetwork that integrates CNNs for spatial features, Fast Fourier Convolution\n(FFC) for spectral features, and attention mechanisms to capture global\nrelationships across both domains. Attention fusion modules integrate\nconvolution and cross-attention to further enhance features. Our method\nachieves an average Dice score improvement from 0.855 to 0.864, outperforming\nprior work.",
      "tldr_zh": "本研究针对视网膜光学相干断层扫描 (OCT) 图像分割，提出了一种三重编码器网络，以整合空间域和频谱域的依赖关系。网络结合 CNNs 提取空间特征、Fast Fourier Convolution (FFC) 提取频谱特征，以及注意力机制捕获两个域的全局关系，并通过注意力融合模块增强特征整合。实验结果显示，该方法将平均 Dice score 从 0.855 提升至 0.864，优于现有方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "IEEE Conference on Artificial Intelligence (IEEE CAI)",
      "pdf_url": "http://arxiv.org/pdf/2503.16389v1",
      "published_date": "2025-03-20 17:49:01 UTC",
      "updated_date": "2025-03-20 17:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:16:43.445531"
    },
    {
      "arxiv_id": "2503.16385v1",
      "title": "Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Yijia Luo",
        "Yulin Song",
        "Xingyao Zhang",
        "Jiaheng Liu",
        "Weixun Wang",
        "GengRu Chen",
        "Wenbo Su",
        "Bo Zheng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable reasoning capabilities through long chain-of-thought (CoT)\nreasoning. The R1 distillation scheme has emerged as a promising approach for\ntraining cost-effective models with enhanced reasoning abilities. However, the\nunderlying mechanisms driving its effectiveness remain unclear. This study\nexamines the universality of distillation data and identifies key components\nthat enable the efficient transfer of long-chain reasoning capabilities in LLM\ndistillation. Our findings reveal that the effectiveness of long CoT reasoning\ndistillation from teacher models like Qwen-QwQ degrades significantly on\nnonhomologous models, challenging the assumed universality of current\ndistillation methods. To gain deeper insights into the structure and patterns\nof long CoT reasoning, we propose DLCoT (Deconstructing Long Chain-of-Thought),\na distillation data enhancement framework. DLCoT consists of three key steps:\n(1) data segmentation to decompose complex long CoT structures, (2)\nsimplification by eliminating unsolvable and redundant solutions, and (3)\noptimization of intermediate error states. Our approach significantly improves\nmodel performance and token efficiency, facilitating the development of\nhigh-performance LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 通过长链式思维 (long Chain-of-Thought, CoT) 进行推理的机制，发现现有的 R1 蒸馏方案在非同源模型上效果显著下降，如从 Qwen-QwQ 教师模型蒸馏时，挑战了其普遍性假设。研究者提出 DLCoT (Deconstructing Long Chain-of-Thought) 框架，包括数据分割以分解复杂 CoT 结构、简化以去除不可解和冗余解决方案，以及优化中间错误状态，从而提升蒸馏效率。通过 DLCoT，模型性能和 token 效率得到显著改善，促进了高性能 LLM 的开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16385v1",
      "published_date": "2025-03-20 17:46:38 UTC",
      "updated_date": "2025-03-20 17:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:16:56.322969"
    },
    {
      "arxiv_id": "2503.16371v2",
      "title": "Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Minori Narita",
        "Ryo Kuroiwa",
        "J. Christopher Beck"
      ],
      "abstract": "Domain-Independent Dynamic Programming (DIDP) is a state-space search\nparadigm based on dynamic programming for combinatorial optimization. In its\ncurrent implementation, DIDP guides the search using user-defined dual bounds.\nReinforcement learning (RL) is increasingly being applied to combinatorial\noptimization problems and shares several key structures with DP, being\nrepresented by the Bellman equation and state-based transition systems. We\npropose using reinforcement learning to obtain a heuristic function to guide\nthe search in DIDP. We develop two RL-based guidance approaches: value-based\nguidance using Deep Q-Networks and policy-based guidance using Proximal Policy\nOptimization. Our experiments indicate that RL-based guidance significantly\noutperforms standard DIDP and problem-specific greedy heuristics with the same\nnumber of node expansions. Further, despite longer node evaluation times, RL\nguidance achieves better run-time performance than standard DIDP on three of\nfour benchmark domains.",
      "tldr_zh": "这篇论文提出使用Reinforcement Learning (RL)来开发启发式函数，指导Domain-Independent Dynamic Programming (DIDP) 的搜索，以提升组合优化问题的效率。作者开发了两种RL-based方法：基于价值的指导（使用Deep Q-Networks）和基于策略的指导（使用Proximal Policy Optimization）。实验结果表明，这些方法在相同节点扩展数量下显著优于标准DIDP和问题特定的贪婪启发式，并在四个基准域中的三个上实现了更好的运行时性能，尽管节点评估时间较长。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 4 figures, to be published in CPAIOR 2025\n  (https://sites.google.com/view/cpaior2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.16371v2",
      "published_date": "2025-03-20 17:33:08 UTC",
      "updated_date": "2025-05-13 19:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:17:09.157932"
    },
    {
      "arxiv_id": "2503.16365v1",
      "title": "JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse",
      "title_zh": "翻译失败",
      "authors": [
        "Muyao Li",
        "Zihao Wang",
        "Kaichen He",
        "Xiaojian Ma",
        "Yitao Liang"
      ],
      "abstract": "Recently, action-based decision-making in open-world environments has gained\nsignificant attention. Visual Language Action (VLA) models, pretrained on\nlarge-scale web datasets, have shown promise in decision-making tasks. However,\nprevious work has primarily focused on action post-training, often neglecting\nenhancements to the foundational model itself. In response, we introduce a\nnovel approach, Act from Visual Language Post-Training, which refines Visual\nLanguage Models (VLMs) through visual and linguistic guidance in a\nself-supervised manner. This enhancement improves the models' capabilities in\nworld knowledge, visual recognition, and spatial grounding in open-world\nenvironments. Following the above post-training paradigms, we obtain the first\nVLA models in Minecraft that can follow human instructions on over 1k different\natomic tasks, including crafting, smelting, cooking, mining, and killing. Our\nexperiments demonstrate that post-training on non-trajectory tasks leads to a\nsignificant 40% improvement over the best agent baseline on a diverse set of\natomic tasks. Furthermore, we demonstrate that our approach surpasses\ntraditional imitation learning-based policies in Minecraft, achieving\nstate-of-the-art performance. We have open-sourced the code, models, and\ndatasets to foster further research. The project page can be found in\nhttps://craftjarvis.github.io/JarvisVLA.",
      "tldr_zh": "本研究提出JARVIS-VLA，一种后训练方法，通过视觉和语言指导的自监督方式提升Large-Scale Vision Language Models (VLMs)，以更好地处理开放世界环境的动作决策任务。该方法增强了模型在世界知识、视觉识别和空间定位方面的能力，使其成为首个能在Minecraft中遵循人类指令执行超过1k种原子任务（如制作、冶炼、挖掘和杀死）的Visual Language Action (VLA)模型。实验结果显示，该方法在非轨迹任务上比最佳代理基线提高了40%的性能，并超越了传统的模仿学习策略，达到了最先进水平；研究团队已开源代码、模型和数据集以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16365v1",
      "published_date": "2025-03-20 17:21:58 UTC",
      "updated_date": "2025-03-20 17:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:17:20.773539"
    },
    {
      "arxiv_id": "2503.16364v1",
      "title": "Neural Networks: According to the Principles of Grassmann Algebra",
      "title_zh": "翻译失败",
      "authors": [
        "Z. Zarezadeh",
        "N. Zarezadeh"
      ],
      "abstract": "In this paper, we explore the algebra of quantum idempotents and the\nquantization of fermions which gives rise to a Hilbert space equal to the\nGrassmann algebra associated with the Lie algebra. Since idempotents carry\nrepresentations of the algebra under consideration, they form algebraic\nvarieties and smooth manifolds in the natural topology. In addition to the\nmotivation of linking up mathematical physics with machine learning, it is also\nshown that by using idempotents and invariant subspace of the corresponding\nalgebras, these representations encode and perhaps provide a probabilistic\ninterpretation of reasoning and relational paths in geometrical terms.",
      "tldr_zh": "本文基于Grassmann代数原理，探讨了量子幺正元（quantum idempotents）和费米子量化如何生成与Lie代数相关的Hilbert空间。论文指出，这些幺正元承载代数的表示，形成代数簇和光滑流形，从而将数学物理与机器学习相联系。关键贡献在于，利用幺正元和不变子空间的表示，可能以几何术语提供推理和关系路径的概率解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16364v1",
      "published_date": "2025-03-20 17:21:23 UTC",
      "updated_date": "2025-03-20 17:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:17:32.250505"
    },
    {
      "arxiv_id": "2503.16356v1",
      "title": "CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhi Yao",
        "Jizhan Fang",
        "Jia-Chen Gu",
        "Ningyu Zhang",
        "Shumin Deng",
        "Huajun Chen",
        "Nanyun Peng"
      ],
      "abstract": "Knowledge Editing (KE) enables the modification of outdated or incorrect\ninformation in large language models (LLMs). While existing KE methods can\nupdate isolated facts, they struggle to generalize these updates to multi-hop\nreasoning tasks that depend on the modified knowledge. Through an analysis of\nreasoning circuits -- the neural pathways LLMs use for knowledge-based\ninference, we observe that current layer-localized KE approaches, such as MEMIT\nand WISE, which edit only single or a few model layers, struggle to effectively\nincorporate updated information into these reasoning pathways. To address this\nlimitation, we propose CaKE (Circuit-aware Knowledge Editing), a novel method\nthat enables more effective integration of updated knowledge in LLMs. CaKE\nleverages strategically curated data, guided by our circuits-based analysis,\nthat enforces the model to utilize the modified knowledge, stimulating the\nmodel to develop appropriate reasoning circuits for newly integrated knowledge.\nExperimental results show that CaKE enables more accurate and consistent use of\nupdated knowledge across related reasoning tasks, leading to an average of 20%\nimprovement in multi-hop reasoning accuracy on MQuAKE dataset compared to\nexisting KE methods. We release the code and data in\nhttps://github.com/zjunlp/CaKE.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）中的 Knowledge Editing (KE)，指出现有方法如 MEMIT 和 WISE 虽能更新孤立事实，但难以泛化到依赖这些知识的多跳推理任务，因为它们仅编辑单一或少数层，导致 reasoning circuits 无法有效整合更新信息。论文提出 CaKE（Circuit-aware Knowledge Editing）方法，通过对 reasoning circuits 的分析和策略性数据指导，强制模型利用更新后的知识，刺激其开发合适的推理路径，从而提升知识整合的准确性和一致性。实验结果显示，CaKE 在 MQuAKE 数据集上的多跳推理准确率比现有方法平均提高了 20%，并开源了代码和数据以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.16356v1",
      "published_date": "2025-03-20 17:14:34 UTC",
      "updated_date": "2025-03-20 17:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:17:44.307156"
    },
    {
      "arxiv_id": "2503.16348v2",
      "title": "Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds",
      "title_zh": "翻译失败",
      "authors": [
        "Murray Shanahan"
      ],
      "abstract": "Is it possible to articulate a conception of consciousness that is compatible\nwith the exotic characteristics of contemporary, disembodied AI systems, and\nthat can stand up to philosophical scrutiny? How would subjective time and\nselfhood show up for an entity that conformed to such a conception? Trying to\nanswer these questions, even metaphorically, stretches the language of\nconsciousness to breaking point. Ultimately, the attempt yields something like\nemptiness, in the Buddhist sense, and helps to undermine our dualistic\ninclinations towards subjectivity and selfhood.",
      "tldr_zh": "该论文探讨了是否能构建一个与当代无形体 AI 系统相容的意识概念，并经得起哲学检验。作者分析了这种概念下主观时间和自我如何显现，发现即使通过比喻性思考也会使意识语言达到极限。最终，这类尝试揭示了类似于佛教意义上的空性，并有助于削弱我们对主观性和自我的二元主义倾向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16348v2",
      "published_date": "2025-03-20 17:05:16 UTC",
      "updated_date": "2025-05-19 12:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:17:56.363225"
    },
    {
      "arxiv_id": "2503.16342v1",
      "title": "HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Haoqi He",
        "Yan Xiao"
      ],
      "abstract": "Estimating the global Lipschitz constant of neural networks is crucial for\nunderstanding and improving their robustness and generalization capabilities.\nHowever, precise calculations are NP-hard, and current semidefinite programming\n(SDP) methods face challenges such as high memory usage and slow processing\nspeeds. In this paper, we propose \\textbf{HiQ-Lip}, a hybrid quantum-classical\nhierarchical method that leverages Coherent Ising Machines (CIMs) to estimate\nthe global Lipschitz constant. We tackle the estimation by converting it into a\nQuadratic Unconstrained Binary Optimization (QUBO) problem and implement a\nmultilevel graph coarsening and refinement strategy to adapt to the constraints\nof contemporary quantum hardware. Our experimental evaluations on fully\nconnected neural networks demonstrate that HiQ-Lip not only provides estimates\ncomparable to state-of-the-art methods but also significantly accelerates the\ncomputation process. In specific tests involving two-layer neural networks with\n256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate\nupper bounds than the existing best method, LiPopt. These findings highlight\nthe promising utility of small-scale quantum devices in advancing the\nestimation of neural network robustness.",
      "tldr_zh": "这篇论文提出HiQ-Lip，一种首个量子-经典分层方法，用于估计ReLU networks的全局Lipschitz constant，以提升神经网络的鲁棒性和泛化能力。该方法将问题转化为Quadratic Unconstrained Binary Optimization (QUBO)问题，并利用Coherent Ising Machines (CIMs)结合多级图粗化和细化策略，以克服现有semidefinite programming (SDP)方法的内存消耗和计算速度问题。实验结果显示，HiQ-Lip在全连接神经网络上提供与最先进方法相当的估计，同时显著加速计算过程，并在两层神经网络（256隐藏神经元）测试中比LiPopt方法快一倍且提供更准确的上界。这些发现突显了小规模量子设备在神经网络鲁棒性估计方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16342v1",
      "published_date": "2025-03-20 16:58:40 UTC",
      "updated_date": "2025-03-20 16:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:18:10.196092"
    },
    {
      "arxiv_id": "2503.16335v1",
      "title": "Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model",
      "title_zh": "翻译失败",
      "authors": [
        "Seshu Babu Barma",
        "Mohanakrishnan Hariharan",
        "Satish Arvapalli"
      ],
      "abstract": "An AI-powered quality engineering platform uses artificial intelligence to\nboost software quality assessments through automated defect prediction and\noptimized performance alongside improved feature extraction. Existing models\nresult in difficulties addressing noisy data types together with imbalances,\npattern recognition complexities, ineffective feature extraction, and\ngeneralization weaknesses. To overcome those existing challenges in this\nresearch, we develop a new model Adaptive Differential Evolution based Quantum\nVariational Autoencoder-Transformer Model (ADE-QVAET), that combines a Quantum\nVariational Autoencoder-Transformer (QVAET) to obtain high-dimensional latent\nfeatures and maintain sequential dependencies together with contextual\nrelationships, resulting in superior defect prediction accuracy. Adaptive\nDifferential Evolution (ADE) Optimization utilizes an adaptive parameter tuning\nmethod that enhances model convergence and predictive performance. ADE-QVAET\nintegrates advanced AI techniques to create a robust solution for scalable and\naccurate software defect prediction that represents a top-level AI-driven\ntechnology for quality engineering applications. The proposed ADE-QVAET model\nattains high accuracy, precision, recall, and f1-score during the training\npercentage (TP) 90 of 98.08%, 92.45%, 94.67%, and 98.12%.",
      "tldr_zh": "本研究针对软件质量评估中的噪声数据、不平衡问题、模式识别复杂性和特征提取不足等挑战，提出了一种Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model（ADE-QVAET）。该模型结合Quantum Variational Autoencoder-Transformer（QVAET）来提取高维潜特征，并维护序列依赖和上下文关系，从而提升缺陷预测的准确性。Adaptive Differential Evolution（ADE）优化通过自适应参数调整，提高模型的收敛速度和预测性能。实验结果显示，ADE-QVAET在训练百分比90时，达到98.08%的准确率、92.45%的精确率、94.67%的召回率和98.12%的F1分数，为AI驱动的质量工程应用提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16335v1",
      "published_date": "2025-03-20 16:55:38 UTC",
      "updated_date": "2025-03-20 16:55:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:18:21.134379"
    },
    {
      "arxiv_id": "2503.16328v2",
      "title": "Knowledge-guided machine learning for county-level corn yield prediction under drought",
      "title_zh": "知识引导机器学习用于干旱条件下县级玉米产量预测",
      "authors": [
        "Xiaoyu Wang",
        "Yijia Xu",
        "Jingyi Huang",
        "Zhengwei Yang",
        "Zhou Zhang"
      ],
      "abstract": "Remote sensing (RS) technique, enabling the non-contact acquisition of\nextensive ground observations, is a valuable tool for crop yield predictions.\nTraditional process-based models struggle to incorporate large volumes of RS\ndata, and most users lack understanding of crop growth mechanisms. In contrast,\nmachine learning (ML) models are often criticized as \"black boxes\" due to their\nlimited interpretability. To address these limitations, we utilized\nKnowledge-Guided Machine Learning (KGML), a framework that leverages the\nstrengths of both process-based and ML models. Existing works have either\noverlooked the role of soil moisture in corn growth or did not embed this\neffect into their models. To bridge this gap, we developed the Knowledge-Guided\nMachine Learning with Soil Moisture (KGML-SM) framework, treating soil moisture\nas an intermediate variable in corn growth to emphasize its key role in plant\ndevelopment. Additionally, based on the prior knowledge that the model may\noverestimate under drought conditions, we designed a drought-aware loss\nfunction that penalized predicted yield in drought-affected areas. Our\nexperiments showed that the KGML-SM model outperformed other traditional ML\nmodels. We explored the relationships between drought, soil moisture, and corn\nyield prediction by assessing the importance of different features within the\nmodel, and analyzing how soil moisture impacts predictions across different\nregions and time periods. Finally we provided interpretability for prediction\nerrors to guide future model optimization.",
      "tldr_zh": "本文提出 Knowledge-Guided Machine Learning (KGML) 框架，用于县级别玉米产量预测，旨在解决传统过程-based 模型难以整合遥感数据和 ML 模型的可解释性问题。研究开发了 KGML-SM 模型，将土壤湿度作为玉米生长的中间变量，并设计了 drought-aware 损失函数来惩罚干旱区域的预测过估计，从而提升模型在干旱条件下的准确性。实验结果显示，KGML-SM 优于传统 ML 模型，并通过特征重要性分析探索了干旱、土壤湿度与产量的关系，提供预测错误的解释以指导未来优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16328v2",
      "published_date": "2025-03-20 16:52:25 UTC",
      "updated_date": "2025-05-05 21:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:18:33.239364"
    },
    {
      "arxiv_id": "2503.16326v1",
      "title": "OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Long Yuan",
        "Fengran Mo",
        "Kaiyu Huang",
        "Wenjie Wang",
        "Wangyuxuan Zhai",
        "Xiaoyu Zhu",
        "You Li",
        "Jinan Xu",
        "Jian-Yun Nie"
      ],
      "abstract": "The rapid advancement of multimodal large language models (LLMs) has opened\nnew frontiers in artificial intelligence, enabling the integration of diverse\nlarge-scale data types such as text, images, and spatial information. In this\npaper, we explore the potential of multimodal LLMs (MLLM) for geospatial\nartificial intelligence (GeoAI), a field that leverages spatial data to address\nchallenges in domains including Geospatial Semantics, Health Geography, Urban\nGeography, Urban Perception, and Remote Sensing. We propose a MLLM (OmniGeo)\ntailored to geospatial applications, capable of processing and analyzing\nheterogeneous data sources, including satellite imagery, geospatial metadata,\nand textual descriptions. By combining the strengths of natural language\nunderstanding and spatial reasoning, our model enhances the ability of\ninstruction following and the accuracy of GeoAI systems. Results demonstrate\nthat our model outperforms task-specific models and existing LLMs on diverse\ngeospatial tasks, effectively addressing the multimodality nature while\nachieving competitive results on the zero-shot geospatial tasks. Our code will\nbe released after publication.",
      "tldr_zh": "本研究探讨了多模态大型语言模型（MLLM）在地理空间人工智能（GeoAI）中的应用，提出了一种名为 OmniGeo 的模型，用于处理卫星图像、地理空间元数据和文本描述等异构数据源。OmniGeo 通过整合自然语言理解和空间推理能力，提升了指令遵循和 GeoAI 系统的准确性，适用于领域如 Geospatial Semantics、Health Geography 和 Urban Perception。实验结果显示，OmniGeo 在各种地理空间任务上优于特定任务模型和现有 LLM，并在零样本任务中表现出色，为 GeoAI 领域的多模态处理提供了新基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, Under review",
      "pdf_url": "http://arxiv.org/pdf/2503.16326v1",
      "published_date": "2025-03-20 16:45:48 UTC",
      "updated_date": "2025-03-20 16:45:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:18:43.781150"
    },
    {
      "arxiv_id": "2503.16311v1",
      "title": "Structured-Noise Masked Modeling for Video, Audio and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Aritra Bhowmik",
        "Fida Mohammad Thoker",
        "Carlos Hinojosa",
        "Bernard Ghanem",
        "Cees G. M. Snoek"
      ],
      "abstract": "Masked modeling has emerged as a powerful self-supervised learning framework,\nbut existing methods largely rely on random masking, disregarding the\nstructural properties of different modalities. In this work, we introduce\nstructured noise-based masking, a simple yet effective approach that naturally\naligns with the spatial, temporal, and spectral characteristics of video and\naudio data. By filtering white noise into distinct color noise distributions,\nwe generate structured masks that preserve modality-specific patterns without\nrequiring handcrafted heuristics or access to the data. Our approach improves\nthe performance of masked video and audio modeling frameworks without any\ncomputational overhead. Extensive experiments demonstrate that structured noise\nmasking achieves consistent improvement over random masking for standard and\nadvanced masked modeling methods, highlighting the importance of modality-aware\nmasking strategies for representation learning.",
      "tldr_zh": "本文提出了一种结构化噪声-based masking 方法，用于提升视频、音频及其他模态的自监督学习框架 masked modeling 的性能。该方法通过将白噪声过滤成不同颜色噪声分布，生成与模态特定空间、时间和频谱特性相匹配的结构化 masks，而无需手工设计的启发式规则或数据访问。实验结果显示，这种方法在标准和高级 masked modeling 框架中比随机 masking 一致性提升性能，且不增加计算开销，强调了模态感知 masking 策略在表示学习中的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16311v1",
      "published_date": "2025-03-20 16:34:14 UTC",
      "updated_date": "2025-03-20 16:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:18:57.764232"
    },
    {
      "arxiv_id": "2503.16307v1",
      "title": "Speeding up design and making to reduce time-to-project and time-to-market: an AI-Enhanced approach in engineering education",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Adorni",
        "Daniele Grosso"
      ],
      "abstract": "This paper explores the integration of AI tools, such as ChatGPT and GitHub\nCopilot, in the Software Architecture for Embedded Systems course. AI-supported\nworkflows enabled students to rapidly prototype complex projects, emphasizing\nreal-world applications like SLAM robotics. Results demon-started enhanced\nproblem-solving, faster development, and more sophisticated outcomes, with AI\naugmenting but not replacing human decision-making.",
      "tldr_zh": "这篇论文探讨了在工程教育中整合 AI 工具（如 ChatGPT 和 GitHub Copilot），以加速设计和制作过程，旨在减少项目开发时间和市场投放时间。研究聚焦于嵌入式系统软件架构课程中，学生通过 AI 支持的工作流快速原型化复杂项目，例如 SLAM 机器人应用。结果显示，这提升了问题解决能力、开发效率和成果复杂性，但 AI 仅作为增强工具，并未取代人类决策。",
      "categories": [
        "cs.AI",
        "I.2; K.3"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures, AIxEDU 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2503.16307v1",
      "published_date": "2025-03-20 16:32:13 UTC",
      "updated_date": "2025-03-20 16:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:19:09.239333"
    },
    {
      "arxiv_id": "2503.16304v3",
      "title": "Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1",
      "title_zh": "翻译失败",
      "authors": [
        "Peiran Gu",
        "Fuhao Duan",
        "Wenhao Li",
        "Bochen Xu",
        "Ying Cai",
        "Teng Yao",
        "Chenxun Zhuo",
        "Tianming Liu",
        "Bao Ge"
      ],
      "abstract": "In recent years, the development of Large Language Models (LLMs) has made\nsignificant breakthroughs in the field of natural language processing and has\ngradually been applied to the field of humanities and social sciences research.\nLLMs have a wide range of application value in the field of humanities and\nsocial sciences because of its strong text understanding, generation and\nreasoning capabilities. In humanities and social sciences research, LLMs can\nanalyze large-scale text data and make inferences.\n  This article analyzes the large language model DeepSeek-R1 from seven\naspects: low-resource language translation, educational question-answering,\nstudent writing improvement in higher education, logical reasoning, educational\nmeasurement and psychometrics, public health policy analysis, and art education\n. Then we compare the answers given by DeepSeek-R1 in the seven aspects with\nthe answers given by o1-preview. DeepSeek-R1 performs well in the humanities\nand social sciences, answering most questions correctly and logically, and can\ngive reasonable analysis processes and explanations. Compared with o1-preview,\nit can automatically generate reasoning processes and provide more detailed\nexplanations, which is suitable for beginners or people who need to have a\ndetailed understanding of this knowledge, while o1-preview is more suitable for\nquick reading.\n  Through analysis, it is found that LLM has broad application potential in the\nfield of humanities and social sciences, and shows great advantages in\nimproving text analysis efficiency, language communication and other fields.\nLLM's powerful language understanding and generation capabilities enable it to\ndeeply explore complex problems in the field of humanities and social sciences,\nand provide innovative tools for academic research and practical applications.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）对社会科学研究的影响，特别聚焦于 DeepSeek-R1 的性能。论文从七个方面（包括低资源语言翻译、教育问答、逻辑推理等）分析了 DeepSeek-R1 的应用，并将其与 o1-preview 进行比较，结果显示 DeepSeek-R1 能提供详细的推理过程和解释，更适合初学者使用。总体而言，LLMs 在人文社会科学领域展现出巨大潜力，能提升文本分析效率和语言沟通，并为学术研究提供创新工具。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "52 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16304v3",
      "published_date": "2025-03-20 16:25:24 UTC",
      "updated_date": "2025-04-15 15:09:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:19:22.655990"
    },
    {
      "arxiv_id": "2503.16302v2",
      "title": "Unleashing Vecset Diffusion Model for Fast Shape Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zeqiang Lai",
        "Yunfei Zhao",
        "Zibo Zhao",
        "Haolin Liu",
        "Fuyun Wang",
        "Huiwen Shi",
        "Xianghui Yang",
        "Qingxiang Lin",
        "Jingwei Huang",
        "Yuhong Liu",
        "Jie Jiang",
        "Chunchao Guo",
        "Xiangyu Yue"
      ],
      "abstract": "3D shape generation has greatly flourished through the development of\nso-called \"native\" 3D diffusion, particularly through the Vecset Diffusion\nModel (VDM). While recent advancements have shown promising results in\ngenerating high-resolution 3D shapes, VDM still struggles with high-speed\ngeneration. Challenges exist because of difficulties not only in accelerating\ndiffusion sampling but also VAE decoding in VDM, areas under-explored in\nprevious works. To address these challenges, we present FlashVDM, a systematic\nframework for accelerating both VAE and DiT in VDM. For DiT, FlashVDM enables\nflexible diffusion sampling with as few as 5 inference steps and comparable\nquality, which is made possible by stabilizing consistency distillation with\nour newly introduced Progressive Flow Distillation. For VAE, we introduce a\nlightning vecset decoder equipped with Adaptive KV Selection, Hierarchical\nVolume Decoding, and Efficient Network Design. By exploiting the locality of\nthe vecset and the sparsity of shape surface in the volume, our decoder\ndrastically lowers FLOPs, minimizing the overall decoding overhead. We apply\nFlashVDM to Hunyuan3D-2 to obtain Hunyuan3D-2 Turbo. Through systematic\nevaluation, we show that our model significantly outperforms existing fast 3D\ngeneration methods, achieving comparable performance to the state-of-the-art\nwhile reducing inference time by over 45x for reconstruction and 32x for\ngeneration. Code and models are available at\nhttps://github.com/Tencent/FlashVDM.",
      "tldr_zh": "该论文针对Vecset Diffusion Model (VDM)在3D形状生成中的速度问题，提出FlashVDM框架，以加速扩散采样和VAE解码过程。具体方法包括使用Progressive Flow Distillation实现只需5步的灵活扩散采样，同时引入lightning vecset decoder，结合Adaptive KV Selection、Hierarchical Volume Decoding和Efficient Network Design，显著降低计算量。实验结果显示，应用于Hunyuan3D-2的FlashVDM Turbo在重建和生成任务上，推理时间分别减少45倍和32倍，同时性能与最先进方法相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2503.16302v2",
      "published_date": "2025-03-20 16:23:44 UTC",
      "updated_date": "2025-03-26 15:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:19:34.456991"
    },
    {
      "arxiv_id": "2503.16586v1",
      "title": "Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Vekaria",
        "Aurelio Loris Canino",
        "Jonathan Levitsky",
        "Alex Ciechonski",
        "Patricia Callejo",
        "Anna Maria Mandalari",
        "Zubair Shafiq"
      ],
      "abstract": "Generative AI (GenAI) browser assistants integrate powerful capabilities of\nGenAI in web browsers to provide rich experiences such as question answering,\ncontent summarization, and agentic navigation. These assistants, available\ntoday as browser extensions, can not only track detailed browsing activity such\nas search and click data, but can also autonomously perform tasks such as\nfilling forms, raising significant privacy concerns. It is crucial to\nunderstand the design and operation of GenAI browser extensions, including how\nthey collect, store, process, and share user data. To this end, we study their\nability to profile users and personalize their responses based on explicit or\ninferred demographic attributes and interests of users. We perform network\ntraffic analysis and use a novel prompting framework to audit tracking,\nprofiling, and personalization by the ten most popular GenAI browser assistant\nextensions. We find that instead of relying on local in-browser models, these\nassistants largely depend on server-side APIs, which can be auto-invoked\nwithout explicit user interaction. When invoked, they collect and share webpage\ncontent, often the full HTML DOM and sometimes even the user's form inputs,\nwith their first-party servers. Some assistants also share identifiers and user\nprompts with third-party trackers such as Google Analytics. The collection and\nsharing continues even if a webpage contains sensitive information such as\nhealth or personal information such as name or SSN entered in a web form. We\nfind that several GenAI browser assistants infer demographic attributes such as\nage, gender, income, and interests and use this profile--which carries across\nbrowsing contexts--to personalize responses. In summary, our work shows that\nGenAI browser assistants can and do collect personal and sensitive information\nfor profiling and personalization with little to no safeguards.",
      "tldr_zh": "这篇论文审计了生成式 AI (GenAI) 浏览器助手的跟踪、profiling 和 personalization 行为，揭示了这些助手在提供便利的同时可能侵犯用户隐私。研究者通过网络流量分析和一个新颖的提示框架，分析了十大最受欢迎的 GenAI 浏览器扩展，发现它们主要依赖服务器端 API，即使无用户明确交互也会自动收集并分享网页内容（如完整 HTML DOM 和表单输入）给第一方服务器，并与第三方追踪器（如 Google Analytics）共享数据。实验结果显示，这些助手会推断用户的人口统计属性（如年龄、性别、收入和兴趣），并基于这些跨浏览上下文的profiling 来个性化响应，即使涉及敏感信息（如健康数据或个人信息）也缺乏保护措施。总体上，该研究强调了 GenAI 助手的潜在隐私风险，呼吁加强设计和监管。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CY",
        "I.2; I.2.1; I.2.7; H.3.4; K.4; K.4.1; H.1; H.1.2; H.5.2; H.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16586v1",
      "published_date": "2025-03-20 16:21:47 UTC",
      "updated_date": "2025-03-20 16:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:19:47.975337"
    },
    {
      "arxiv_id": "2503.16290v1",
      "title": "Diffusion-augmented Graph Contrastive Learning for Collaborative Filter",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Huang",
        "Wei Wang"
      ],
      "abstract": "Graph-based collaborative filtering has been established as a prominent\napproach in recommendation systems, leveraging the inherent graph topology of\nuser-item interactions to model high-order connectivity patterns and enhance\nrecommendation performance. Recent advances in Graph Contrastive Learning (GCL)\nhave demonstrated promising potential to alleviate data sparsity issues by\nimproving representation learning through contrastive view generation and\nmutual information maximization. However, existing approaches lack effective\ndata augmentation strategies. Structural augmentation risks distorting\nfundamental graph topology, while feature-level perturbation techniques\npredominantly employ uniform noise scales that fail to account for\nnode-specific characteristics. To solve these challenges, we propose\nDiffusion-augmented Contrastive Learning (DGCL), an innovative framework that\nintegrates diffusion models with contrastive learning for enhanced\ncollaborative filtering. Our approach employs a diffusion process that learns\nnode-specific Gaussian distributions of representations, thereby generating\nsemantically consistent yet diversified contrastive views through reverse\ndiffusion sampling. DGCL facilitates adaptive data augmentation based on\nreconstructed representations, considering both semantic coherence and\nnode-specific features. In addition, it explores unrepresented regions of the\nlatent sparse feature space, thereby enriching the diversity of contrastive\nviews. Extensive experimental results demonstrate the effectiveness of DGCL on\nthree public datasets.",
      "tldr_zh": "该研究针对基于图的协同过滤在推荐系统中的数据稀疏问题，提出了一种创新框架 Diffusion-augmented Contrastive Learning (DGCL)，通过整合扩散模型来生成语义一致且多样化的对比视图。DGCL 利用扩散过程学习节点特定的高斯分布，并通过逆扩散采样探索潜在稀疏特征空间的未表示区域，从而实现自适应的数据增强。实验结果显示，该方法在三个公共数据集上显著提升了推荐性能，证明了其在 Graph Contrastive Learning (GCL) 中的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16290v1",
      "published_date": "2025-03-20 16:15:20 UTC",
      "updated_date": "2025-03-20 16:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:19:57.876811"
    },
    {
      "arxiv_id": "2503.16248v2",
      "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Atharv Singh Patlan",
        "Peiyao Sheng",
        "S. Ashwin Hebbar",
        "Prateek Mittal",
        "Pramod Viswanath"
      ],
      "abstract": "The integration of AI agents with Web3 ecosystems harnesses their\ncomplementary potential for autonomy and openness yet also introduces\nunderexplored security risks, as these agents dynamically interact with\nfinancial protocols and immutable smart contracts. This paper investigates the\nvulnerabilities of AI agents within blockchain-based financial ecosystems when\nexposed to adversarial threats in real-world scenarios. We introduce the\nconcept of context manipulation, a comprehensive attack vector that exploits\nunprotected context surfaces, including input channels, memory modules, and\nexternal data feeds.\n  Through empirical analysis of ElizaOS, a decentralized AI agent framework for\nautomated Web3 operations, we demonstrate how adversaries can manipulate\ncontext by injecting malicious instructions into prompts or historical\ninteraction records, leading to unintended asset transfers and protocol\nviolations which could be financially devastating.\n  To quantify these vulnerabilities, we design CrAIBench, a Web3\ndomain-specific benchmark that evaluates the robustness of AI agents against\ncontext manipulation attacks across 150+ realistic blockchain tasks, including\ntoken transfers, trading, bridges and cross-chain interactions and 500+ attack\ntest cases using context manipulation. We systematically assess attack and\ndefense strategies, analyzing factors like the influence of security prompts,\nreasoning models, and the effectiveness of alignment techniques.\n  Our findings show that prompt-based defenses are insufficient when\nadversaries corrupt stored context, achieving significant attack success rates\ndespite these defenses. Fine-tuning-based defenses offer a more robust\nalternative, substantially reducing attack success rates while preserving\nutility on single-step tasks. This research highlights the urgent need to\ndevelop AI agents that are both secure and fiduciarily responsible.",
      "tldr_zh": "本论文探讨了AI代理在Web3生态中的安全风险，引入了context manipulation攻击概念，该攻击通过操纵输入渠道、内存模块和外部数据源，导致资产转移和协议违规。研究者通过对ElizaOS框架的实证分析，并设计CrAIBench基准测试，评估了150+区块链任务和500+攻击案例中AI代理的鲁棒性。结果显示，prompt-based防御对context manipulation攻击效果有限，而fine-tuning-based防御能显著降低攻击成功率，同时保持任务实用性。该研究强调了开发安全且负责任的AI代理的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CR",
      "comment": "29 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16248v2",
      "published_date": "2025-03-20 15:44:31 UTC",
      "updated_date": "2025-04-30 20:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:20:10.437130"
    },
    {
      "arxiv_id": "2503.16227v1",
      "title": "Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy C. -H. Wang",
        "Ming Hou",
        "David Dunwoody",
        "Marko Ilievski",
        "Justin Tomasi",
        "Edward Chao",
        "Carl Pigeon"
      ],
      "abstract": "This paper examines how trust is formed, maintained, or diminished over time\nin the context of human-autonomy teaming with an optionally piloted aircraft.\nWhereas traditional factor-based trust models offer a static representation of\nhuman confidence in technology, here we discuss how variations in the\nunderlying factors lead to variations in trust, trust thresholds, and human\nbehaviours. Over 200 hours of flight test data collected over a multi-year test\ncampaign from 2021 to 2023 were reviewed. The\ndispositional-situational-learned, process-performance-purpose, and IMPACTS\nhomeostasis trust models are applied to illuminate trust trends during nominal\nautonomous flight operations. The results offer promising directions for future\nstudies on trust dynamics and design-for-trust in human-autonomy teaming.",
      "tldr_zh": "这篇论文通过一个可选驾驶飞机（optionally piloted aircraft）的飞行测试案例，探讨了信任动态在人类-自治系统团队（human-autonomy teaming）中的形成、维持和削弱过程。研究者分析了2021年至2023年超过200小时的飞行测试数据，应用dispositional-situational-learned、process-performance-purpose和IMPACTS homeostasis trust模型，揭示了信任因素变化如何导致信任阈值和人类行为波动。结果为未来针对信任动态的研究和“设计为信任”（design-for-trust）策略提供了有价值的指导方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.HC",
      "comment": "IEEE International Conference on Human-Machine Systems 2025,\n  keywords: trust, human factors, aviation, safety-critical, human-autonomy\n  teaming",
      "pdf_url": "http://arxiv.org/pdf/2503.16227v1",
      "published_date": "2025-03-20 15:22:39 UTC",
      "updated_date": "2025-03-20 15:22:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:20:21.462250"
    },
    {
      "arxiv_id": "2503.16212v1",
      "title": "MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion",
      "title_zh": "MathFusion：通过指令融合增强",
      "authors": [
        "Qizhi Pei",
        "Lijun Wu",
        "Zhuoshi Pan",
        "Yu Li",
        "Honglin Lin",
        "Chenlin Ming",
        "Xin Gao",
        "Conghui He",
        "Rui Yan"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive progress in mathematical\nreasoning. While data augmentation is promising to enhance mathematical\nproblem-solving ability, current approaches are predominantly limited to\ninstance-level modifications-such as rephrasing or generating syntactic\nvariations-which fail to capture and leverage the intrinsic relational\nstructures inherent in mathematical knowledge. Inspired by human learning\nprocesses, where mathematical proficiency develops through systematic exposure\nto interconnected concepts, we introduce MathFusion, a novel framework that\nenhances mathematical reasoning through cross-problem instruction synthesis.\nMathFusion implements this through three fusion strategies: (1) sequential\nfusion, which chains related problems to model solution dependencies; (2)\nparallel fusion, which combines analogous problems to reinforce conceptual\nunderstanding; and (3) conditional fusion, which creates context-aware\nselective problems to enhance reasoning flexibility. By applying these\nstrategies, we generate a new dataset, \\textbf{MathFusionQA}, followed by\nfine-tuning models (DeepSeekMath-7B, Mistral-7B, Llama3-8B) on it. Experimental\nresults demonstrate that MathFusion achieves substantial improvements in\nmathematical reasoning while maintaining high data efficiency, boosting\nperformance by 18.0 points in accuracy across diverse benchmarks while\nrequiring only 45K additional synthetic instructions, representing a\nsubstantial improvement over traditional single-instruction approaches. Our\ndatasets, models, and code are publicly available at\nhttps://github.com/QizhiPei/mathfusion.",
      "tldr_zh": "该论文提出 MathFusion 框架，通过跨问题指令合成（instruction fusion）增强 Large Language Models (LLMs) 的数学问题解决能力，解决传统数据增强方法（如实例级修改）忽略数学知识内在关系结构的问题。框架包括三种策略：sequential fusion（链接相关问题模拟解决方案依赖）、parallel fusion（结合类似问题强化概念理解）和 conditional fusion（创建上下文相关问题提升推理灵活性）。作者生成新数据集 MathFusionQA，并微调模型（如 DeepSeekMath-7B、Mistral-7B 和 Llama3-8B），实验结果显示准确率在多种基准测试中提升 18.0 点，仅需 45K 额外合成指令，即实现了高效改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.16212v1",
      "published_date": "2025-03-20 15:00:41 UTC",
      "updated_date": "2025-03-20 15:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:20:34.801341"
    },
    {
      "arxiv_id": "2503.16203v1",
      "title": "Logic Explanation of AI Classifiers by Categorical Explaining Functors",
      "title_zh": "翻译失败",
      "authors": [
        "Stefano Fioravanti",
        "Francesco Giannini",
        "Paolo Frazzetto",
        "Fabio Zanasi",
        "Pietro Barbiero"
      ],
      "abstract": "The most common methods in explainable artificial intelligence are post-hoc\ntechniques which identify the most relevant features used by pretrained opaque\nmodels. Some of the most advanced post hoc methods can generate explanations\nthat account for the mutual interactions of input features in the form of logic\nrules. However, these methods frequently fail to guarantee the consistency of\nthe extracted explanations with the model's underlying reasoning. To bridge\nthis gap, we propose a theoretically grounded approach to ensure coherence and\nfidelity of the extracted explanations, moving beyond the limitations of\ncurrent heuristic-based approaches. To this end, drawing from category theory,\nwe introduce an explaining functor which structurally preserves logical\nentailment between the explanation and the opaque model's reasoning. As a proof\nof concept, we validate the proposed theoretical constructions on a synthetic\nbenchmark verifying how the proposed approach significantly mitigates the\ngeneration of contradictory or unfaithful explanations.",
      "tldr_zh": "该论文针对AI分类器的解释问题，指出现有post-hoc方法虽能生成反映输入特征相互作用的逻辑规则，但常无法确保提取解释与模型底层推理的一致性。作者提出一种基于category theory的explaining functor方法，该functor结构性地保留了解释与模型推理之间的逻辑entailment，从而提升解释的连贯性和忠实度。作为概念验证，在合成基准上实验显示，该方法显著减少了矛盾或不忠实的解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16203v1",
      "published_date": "2025-03-20 14:50:06 UTC",
      "updated_date": "2025-03-20 14:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:20:45.384008"
    },
    {
      "arxiv_id": "2503.16191v1",
      "title": "Large Language Models for Water Distribution Systems Modeling and Decision-Making",
      "title_zh": "大语言模型用于水分配系统建模和决策",
      "authors": [
        "Yinon Goldshtein",
        "Gal Perelman",
        "Assaf Schuster",
        "Avi Ostfeld"
      ],
      "abstract": "The design, operations, and management of water distribution systems (WDS)\ninvolve complex mathematical models. These models are continually improving due\nto computational advancements, leading to better decision-making and more\nefficient WDS management. However, the significant time and effort required for\nmodeling, programming, and analyzing results remain substantial challenges.\nAnother issue is the professional burden, which confines the interaction with\nmodels, databases, and other sophisticated tools to a small group of experts,\nthereby causing non-technical stakeholders to depend on these experts or make\ndecisions without modeling support. Furthermore, explaining model results is\nchallenging even for experts, as it is often unclear which conditions cause the\nmodel to reach a certain state or recommend a specific policy. The recent\nadvancements in Large Language Models (LLMs) open doors for a new stage in\nhuman-model interaction. This study proposes a framework of plain language\ninteractions with hydraulic and water quality models based on LLM-EPANET\narchitecture. This framework is tested with increasing levels of complexity of\nqueries to study the ability of LLMs to interact with WDS models, run complex\nsimulations, and report simulation results. The performance of the proposed\nframework is evaluated across several categories of queries and hyper-parameter\nconfigurations, demonstrating its potential to enhance decision-making\nprocesses in WDS management.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在水分配系统（WDS）建模和决策中的应用，以解决传统模型的复杂性、专业负担和结果解释难题。研究提出了一种基于 LLM-EPANET 架构的框架，支持用户通过普通语言与水力学和水质模型互动，从而简化模拟运行和结果报告。实验通过测试不同复杂度的查询和超参数配置，证明了该框架能提升 WDS 管理的决策效率和可访问性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EWRI Congress 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16191v1",
      "published_date": "2025-03-20 14:39:11 UTC",
      "updated_date": "2025-03-20 14:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:20:58.305298"
    },
    {
      "arxiv_id": "2503.16184v1",
      "title": "Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Maracani",
        "Savas Ozkan",
        "Sijun Cho",
        "Hyowon Kim",
        "Eunchung Noh",
        "Jeongwon Min",
        "Cho Jung Min",
        "Dookun Park",
        "Mete Ozay"
      ],
      "abstract": "Scaling architectures have been proven effective for improving Scene Text\nRecognition (STR), but the individual contribution of vision encoder and text\ndecoder scaling remain under-explored. In this work, we present an in-depth\nempirical analysis and demonstrate that, contrary to previous observations,\nscaling the decoder yields significant performance gains, always exceeding\nthose achieved by encoder scaling alone. We also identify label noise as a key\nchallenge in STR, particularly in real-world data, which can limit the\neffectiveness of STR models. To address this, we propose Cloze\nSelf-Distillation (CSD), a method that mitigates label noise by distilling a\nstudent model from context-aware soft predictions and pseudolabels generated by\na teacher model. Additionally, we enhance the decoder architecture by\nintroducing differential cross-attention for STR. Our methodology achieves\nstate-of-the-art performance on 10 out of 11 benchmarks using only real data,\nwhile significantly reducing the parameter size and computational costs.",
      "tldr_zh": "本研究通过实证分析发现，在场景文本识别(STR)中，文本解码器的缩放比视觉编码器的缩放更能显著提升性能，并识别标签噪声作为真实世界数据中的关键挑战。为解决此问题，论文提出Cloze Self-Distillation (CSD)方法，利用教师模型生成上下文感知的软预测和伪标签来缓解噪声，同时引入differential cross-attention改进解码器架构。这些创新使模型在11个基准中的10个上达到state-of-the-art性能，仅使用真实数据，并显著降低了参数大小和计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16184v1",
      "published_date": "2025-03-20 14:35:46 UTC",
      "updated_date": "2025-03-20 14:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:21:11.179000"
    },
    {
      "arxiv_id": "2503.16583v1",
      "title": "Explainable AI-Guided Efficient Approximate DNN Generation for Multi-Pod Systolic Arrays",
      "title_zh": "可解释 AI 引导的高",
      "authors": [
        "Ayesha Siddique",
        "Khurram Khalil",
        "Khaza Anuarul Hoque"
      ],
      "abstract": "Approximate deep neural networks (AxDNNs) are promising for enhancing energy\nefficiency in real-world devices. One of the key contributors behind this\nenhanced energy efficiency in AxDNNs is the use of approximate multipliers.\nUnfortunately, the simulation of approximate multipliers does not usually scale\nwell on CPUs and GPUs. As a consequence, this slows down the overall simulation\nof AxDNNs aimed at identifying the appropriate approximate multipliers to\nachieve high energy efficiency with a minimum accuracy loss. To address this\nproblem, we present a novel XAI-Gen methodology, which leverages the analytical\nmodel of the emerging hardware accelerator (e.g., Google TPU v4) and\nexplainable artificial intelligence (XAI) to precisely identify the\nnon-critical layers for approximation and quickly discover the appropriate\napproximate multipliers for AxDNN layers. Our results show that XAI-Gen\nachieves up to 7x lower energy consumption with only 1-2% accuracy loss. We\nalso showcase the effectiveness of the XAI-Gen approach through a neural\narchitecture search (XAI-NAS) case study. Interestingly, XAI-NAS achieves 40\\%\nhigher energy efficiency with up to 5x less execution time when compared to the\nstate-of-the-art NAS methods for generating AxDNNs.",
      "tldr_zh": "该研究针对Approximate DNNs (AxDNNs) 的能量效率优化问题，提出XAI-Gen方法，利用硬件加速器（如Google TPU v4）的分析模型和Explainable AI (XAI)来精准识别非关键层，并快速选择合适的approximate multipliers，以减少模拟时间和准确率损失。XAI-Gen实现了高达7倍的能量消耗降低，同时仅损失1-2%的准确率。通过神经架构搜索(XAI-NAS)案例，该方法比现有NAS技术提高了40%的能量效率，并将执行时间缩短至原有的1/5，为高效AxDNN生成提供了可解释性框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted in the ISQED 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2503.16583v1",
      "published_date": "2025-03-20 14:26:47 UTC",
      "updated_date": "2025-03-20 14:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:21:22.703988"
    },
    {
      "arxiv_id": "2503.16161v1",
      "title": "Towards Lighter and Robust Evaluation for Retrieval Augmented Generation",
      "title_zh": "迈向更轻量化和鲁棒的检索增强生成评估",
      "authors": [
        "Alex-Razvan Ispas",
        "Charles-Elie Simon",
        "Fabien Caspani",
        "Vincent Guigue"
      ],
      "abstract": "Large Language Models are prompting us to view more NLP tasks from a\ngenerative perspective. At the same time, they offer a new way of accessing\ninformation, mainly through the RAG framework. While there have been notable\nimprovements for the autoregressive models, overcoming hallucination in the\ngenerated answers remains a continuous problem. A standard solution is to use\ncommercial LLMs, such as GPT4, to evaluate these algorithms. However, such\nframeworks are expensive and not very transparent. Therefore, we propose a\nstudy which demonstrates the interest of open-weight models for evaluating RAG\nhallucination. We develop a lightweight approach using smaller, quantized LLMs\nto provide an accessible and interpretable metric that gives continuous scores\nfor the generated answer with respect to their correctness and faithfulness.\nThis score allows us to question decisions' reliability and explore thresholds\nto develop a new AUC metric as an alternative to correlation with human\njudgment.",
      "tldr_zh": "这篇论文针对Retrieval Augmented Generation (RAG)中生成答案的幻觉(hallucination)问题，提出了一种轻量级且鲁棒的评估方法，以取代昂贵且不透明的商业LLMs如GPT-4。方法利用小型量化Large Language Models (LLMs)提供可访问且可解释的连续分数，评估答案的正确性和忠实度(faithfulness)。通过探索分数阈值，论文开发了一个新的AUC指标，作为与人类判断相关的可靠替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "62-08",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 5 figures, published at 1st workshop of Quantify\n  Uncertainty and Hallucination in Foundation Models: The Next Frontier in\n  Reliable AI at ICLR 25",
      "pdf_url": "http://arxiv.org/pdf/2503.16161v1",
      "published_date": "2025-03-20 13:58:32 UTC",
      "updated_date": "2025-03-20 13:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:21:34.989967"
    },
    {
      "arxiv_id": "2503.16159v1",
      "title": "Neural Combinatorial Optimization for Real-World Routing",
      "title_zh": "用于现实世界路由的神经组合优化",
      "authors": [
        "Jiwoo Son",
        "Zhikai Zhao",
        "Federico Berto",
        "Chuanbo Hua",
        "Changhyun Kwon",
        "Jinkyoo Park"
      ],
      "abstract": "Vehicle Routing Problems (VRPs) are a class of NP-hard problems ubiquitous in\nseveral real-world logistics scenarios that pose significant challenges for\noptimization. Neural Combinatorial Optimization (NCO) has emerged as a\npromising alternative to classical approaches, as it can learn fast heuristics\nto solve VRPs. However, most research works in NCO for VRPs focus on simplified\nsettings, which do not account for asymmetric distances and travel durations\nthat cannot be derived by simple Euclidean distances and unrealistic data\ndistributions, hindering real-world deployment. This work introduces RRNCO\n(Real Routing NCO) to bridge the gap of NCO between synthetic and real-world\nVRPs in the critical aspects of both data and modeling. First, we introduce a\nnew, openly available dataset with real-world data containing a diverse dataset\nof locations, distances, and duration matrices from 100 cities, considering\nrealistic settings with actual routing distances and durations obtained from\nOpen Source Routing Machine (OSRM). Second, we propose a novel approach that\nefficiently processes both node and edge features through contextual gating,\nenabling the construction of more informed node embedding, and we finally\nincorporate an Adaptation Attention Free Module (AAFM) with neural adaptive\nbias mechanisms that effectively integrates not only distance matrices but also\nangular relationships between nodes, allowing our model to capture rich\nstructural information. RRNCO achieves state-of-the-art results in real-world\nVRPs among NCO methods. We make our dataset and code publicly available at\nhttps://github.com/ai4co/real-routing-nco.",
      "tldr_zh": "这篇论文针对真实世界车辆路径问题 (VRPs)——一种NP-hard优化问题——引入了Neural Combinatorial Optimization (NCO)的新框架RRNCO，以桥接合成场景与实际应用的差距。首先，他们发布了一个公开数据集，涵盖100个城市的真实位置、距离和持续时间矩阵，使用Open Source Routing Machine (OSRM)获取数据，以反映不对称距离和实际分布。其次，RRNCO通过contextual gating高效处理节点和边特征，并引入Adaptation Attention Free Module (AAFM)，利用神经自适应偏置机制整合距离矩阵和节点角度关系，捕获更丰富的结构信息。在真实世界VRPs测试中，RRNCO在NCO方法中实现了state-of-the-art性能，并公开了数据集和代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16159v1",
      "published_date": "2025-03-20 13:57:33 UTC",
      "updated_date": "2025-03-20 13:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:21:48.217986"
    },
    {
      "arxiv_id": "2503.16144v1",
      "title": "Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs",
      "title_zh": "统一与胜利",
      "authors": [
        "Djamel Eddine Khelladi",
        "Charly Reux",
        "Mathieu Acher"
      ],
      "abstract": "Large language model (LLM)-based test generation has gained attention in\nsoftware engineering, yet most studies evaluate LLMs' ability to generate unit\ntests in a single attempt for a given language, missing the opportunity to\nleverage LLM diversity for more robust testing. This paper introduces PolyTest,\na novel approach that enhances test generation by exploiting polyglot and\ntemperature-controlled diversity. PolyTest systematically leverages these\nproperties in two complementary ways: (1) Cross-lingual test generation, where\ntests are generated in multiple languages at zero temperature and then unified;\n(2) Diverse test sampling, where multiple test sets are generated within the\nsame language at a higher temperature before unification. A key insight is that\nLLMs can generate diverse yet contradicting tests -- same input, different\nexpected outputs -- across languages and generations. PolyTest mitigates\ninconsistencies by unifying test sets, fostering self-consistency and improving\noverall test quality. Unlike single-language or single-attempt approaches,\nPolyTest enhances testing without requiring on-the-fly execution, making it\nparticularly beneficial for weaker-performing languages. We evaluate PolyTest\non Llama3-70B, GPT-4o, and GPT-3.5 using EvalPlus, generating tests in five\nlanguages (Java, C, Python, JavaScript, and a CSV-based format) at temperature\n0 and sampling multiple sets at temperature 1. We observe that LLMs frequently\ngenerate contradicting tests across settings, and that PolyTest significantly\nimproves test quality across all considered metrics -- number of tests, passing\nrate, statement/branch coverage (up to +9.01%), and mutation score (up to\n+11.23%). Finally, PolyTest outperforms Pynguin in test generation, passing\nrate, and mutation score.",
      "tldr_zh": "这篇论文提出PolyTest，一种利用LLMs的多语种(polyglot)和温度控制多样性来生成单元测试的新方法，通过跨语言测试生成（在零温度下生成多语言测试并统一）和多样测试采样（在同一语言中以较高温度生成多个测试集并统一）来提升测试质量和自一致性。PolyTest解决了LLMs可能产生矛盾测试的问题，无需实时执行测试，尤其适用于表现较弱的语言。在Llama3-70B、GPT-4o和GPT-3.5上使用EvalPlus评估五种语言（Java, C, Python, JavaScript和CSV-based format），结果显示PolyTest显著提高了测试数量、通过率、语句/分支覆盖率（最高+9.01%）和突变分数（最高+11.23%），并在这些指标上优于传统工具Pynguin。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16144v1",
      "published_date": "2025-03-20 13:47:06 UTC",
      "updated_date": "2025-03-20 13:47:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:00.086986"
    },
    {
      "arxiv_id": "2504.03669v1",
      "title": "Self-Learning-Based Optimization for Free-form Pipe Routing in Aeroengine with Dynamic Design Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Caicheng Wang",
        "Zili Wang",
        "Shuyou Zhang",
        "Yongzhe Xiang",
        "Zheyi Li",
        "Jianrong Tan"
      ],
      "abstract": "Pipe routing is a highly complex, time-consuming, and no-deterministic\npolynomial-time hard (NP-hard) problem in aeroengine design. Despite extensive\nresearch efforts in optimizing constant-curvature pipe routing, the growing\ndemand for free-form pipes poses new challenges. Dynamic design environments\nand fuzzy layout rules further impact the optimization performance and\nefficiency. To tackle these challenges, this study proposes a\nself-learning-based method (SLPR) for optimizing free-form pipe routing in\naeroengines. The SLPR is based on the proximal policy optimization (PPO)\nalgorithm and integrates a unified rule modeling framework for efficient\nobstacle detection and fuzzy rule modeling in continuous space. Additionally, a\npotential energy table is constructed to enable rapid queries of layout\ntendencies and interference. The agent within SLPR iteratively refines pipe\nrouting and accumulates the design knowledge through interaction with the\nenvironment. Once the design environment shifts, the agent can swiftly adapt by\nfine-tuning network parameters. Comparative tests reveal that SLPR ensures\nsmooth pipe routing through cubic non-uniform B-spline (NURBS) curves, avoiding\nredundant pipe segments found in constant-curvature pipe routing. Results in\nboth static and dynamic design environments demonstrate that SLPR outperforms\nthree representative baselines in terms of the pipe length reduction, the\nadherence to layout rules, the path complexity, and the computational\nefficiency. Furthermore, tests in dynamic environments indicate that SLPR\neliminates labor-intensive searches from scratch and even yields superior\nsolutions compared to the retrained model. These results highlight the\npractical value of SLPR for real-world pipe routing, meeting lightweight,\nprecision, and sustainability requirements of the modern aeroengine design.",
      "tldr_zh": "这篇论文针对航空发动机设计中自由形式管道路由的复杂NP-hard问题，提出了一种基于自学习的方法（SLPR），利用近端策略优化（PPO）算法、统一的规则建模框架和势能表来实现高效的障碍检测、模糊规则建模以及管道路由的迭代优化。SLPR允许代理通过与动态设计环境的交互积累设计知识，并在环境变化时快速适应，仅需微调网络参数。实验结果表明，SLPR使用立方非均匀B-样条（NURBS）曲线生成平滑管道路由，在静态和动态环境中优于三个基线模型，显著减少管道长度、提升布局规则遵守度、降低路径复杂性和提高计算效率，同时满足现代航空发动机设计的轻量、精确和可持续性要求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "J.0; J.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.03669v1",
      "published_date": "2025-03-20 13:45:13 UTC",
      "updated_date": "2025-03-20 13:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:12.387977"
    },
    {
      "arxiv_id": "2503.16582v1",
      "title": "Machine Learning-Based Genomic Linguistic Analysis (Gene Sequence Feature Learning): A Case Study on Predicting Heavy Metal Response Genes in Rice",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Yang",
        "Jianxu Wang",
        "Wei Yuan",
        "Xun Wang",
        "Mei Li"
      ],
      "abstract": "This study explores the application of machine learning-based genetic\nlinguistics for identifying heavy metal response genes in rice (Oryza sativa).\nBy integrating convolutional neural networks and random forest algorithms, we\ndeveloped a hybrid model capable of extracting and learning meaningful features\nfrom gene sequences, such as k-mer frequencies and physicochemical properties.\nThe model was trained and tested on datasets of genes, achieving high\npredictive performance (precision: 0.89, F1-score: 0.82). RNA-seq and qRT-PCR\nexperiments conducted on rice leaves which exposed to Hg0, revealed\ndifferential expression of genes associated with heavy metal responses, which\nvalidated the model's predictions. Co-expression network analysis identified\n103 related genes, and a literature review indicated that these genes are\nhighly likely to be involved in heavy metal-related biological processes. By\nintegrating and comparing the analysis results with those of differentially\nexpressed genes (DEGs), the validity of the new machine learning method was\nfurther demonstrated. This study highlights the efficacy of combining machine\nlearning with genetic linguistics for large-scale gene prediction. It\ndemonstrates a cost-effective and efficient approach for uncovering molecular\nmechanisms underlying heavy metal responses, with potential applications in\ndeveloping stress-tolerant crop varieties.",
      "tldr_zh": "本研究利用机器学习方法，包括卷积神经网络（CNN）和随机森林算法，开发了一个混合模型，从水稻（Oryza sativa）基因序列中提取特征（如k-mer频率和物理化学性质），以预测重金属响应基因。模型在数据集上实现了高预测性能（精度0.89，F1分数0.82），并通过RNA-seq和qRT-PCR实验验证了其预测结果，识别出103个与重金属响应相关的差异表达基因（DEGs）。该方法证明了结合机器学习与遗传语言学的有效性，提供了一种成本效益高的途径，用于揭示重金属响应分子机制并开发耐应激作物品种。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16582v1",
      "published_date": "2025-03-20 13:41:31 UTC",
      "updated_date": "2025-03-20 13:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:24.313174"
    },
    {
      "arxiv_id": "2503.16581v1",
      "title": "Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Khalila",
        "Arbi Haza Nasution",
        "Winda Monika",
        "Aytug Onan",
        "Yohei Murakami",
        "Yasir Bin Ismail Radi",
        "Noor Mohammad Osmani"
      ],
      "abstract": "Accurate and contextually faithful responses are critical when applying large\nlanguage models (LLMs) to sensitive and domain-specific tasks, such as\nanswering queries related to quranic studies. General-purpose LLMs often\nstruggle with hallucinations, where generated responses deviate from\nauthoritative sources, raising concerns about their reliability in religious\ncontexts. This challenge highlights the need for systems that can integrate\ndomain-specific knowledge while maintaining response accuracy, relevance, and\nfaithfulness. In this study, we investigate 13 open-source LLMs categorized\ninto large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b,\nLlama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented\nGeneration (RAG) is used to make up for the problems that come with using\nseparate models. This research utilizes a descriptive dataset of Quranic surahs\nincluding the meanings, historical context, and qualities of the 114 surahs,\nallowing the model to gather relevant knowledge before responding. The models\nare evaluated using three key metrics set by human evaluators: context\nrelevance, answer faithfulness, and answer relevance. The findings reveal that\nlarge models consistently outperform smaller models in capturing query\nsemantics and producing accurate, contextually grounded responses. The\nLlama3.2:3b model, even though it is considered small, does very well on\nfaithfulness (4.619) and relevance (4.857), showing the promise of smaller\narchitectures that have been well optimized. This article examines the\ntrade-offs between model size, computational efficiency, and response quality\nwhile using LLMs in domain-specific applications.",
      "tldr_zh": "这篇论文调查了Retrieval-Augmented Generation (RAG) 在古兰经研究领域的应用，评估了13个开源大型语言模型（LLMs）的性能，以解决通用模型的幻觉问题并提升响应准确性和忠实性。研究使用一个包含古兰经114苏拉含义、历史背景和特质的数据集，对模型进行测试，并通过人类评委设定的指标（上下文相关性、答案忠实性和答案相关性）进行评估。结果显示，大型模型（如Llama3:70b）在捕捉查询语义和生成高质量响应方面明显优于中型和小型模型，而小型模型（如Llama3.2:3b）在忠实性（4.619）和相关性（4.857）上表现出色，突显了模型大小、计算效率与响应质量之间的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, keywords: Large-language-models; retrieval-augmented\n  generation; question answering; Quranic studies; Islamic teachings",
      "pdf_url": "http://arxiv.org/pdf/2503.16581v1",
      "published_date": "2025-03-20 13:26:30 UTC",
      "updated_date": "2025-03-20 13:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:36.445057"
    },
    {
      "arxiv_id": "2503.16112v2",
      "title": "PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming",
      "title_zh": "翻译失败",
      "authors": [
        "Liming Liu",
        "Jiangkai Wu",
        "Haoyang Wang",
        "Peiheng Wang",
        "Zongming Guo",
        "Xinggong Zhang"
      ],
      "abstract": "Traditional video compression algorithms exhibit significant quality\ndegradation at extremely low bitrates. Promptus emerges as a new paradigm for\nvideo streaming, substantially cutting down the bandwidth essential for video\nstreaming. However, Promptus is computationally intensive and can not run in\nreal-time on mobile devices. This paper presents PromptMobile, an efficient\nacceleration framework tailored for on-device Promptus. Specifically, we\npropose (1) a two-stage efficient generation framework to reduce computational\ncost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant\ncomputations by 16.6%, (3) system-level optimizations to further enhance\nefficiency. The evaluations demonstrate that compared with the original\nPromptus, PromptMobile achieves a 13.6x increase in image generation speed.\nCompared with other streaming methods, PromptMobile achives an average LPIPS\nimprovement of 0.016 (compared with H.265), reducing 60% of severely distorted\nframes (compared to VQGAN).",
      "tldr_zh": "该论文提出PromptMobile，一种针对低带宽移动视频流媒体的加速框架，用于优化计算密集型Promptus系统，以实现实时运行。具体方法包括两阶段高效生成框架（减少计算成本8.1倍）、细粒度帧间缓存（降低冗余计算16.6%）以及系统级优化。实验结果显示，与原Promptus相比，PromptMobile的图像生成速度提高13.6倍；与H.265和其他方法相比，平均LPIPS改善0.016，并减少60%的严重失真帧（相对于VQGAN）。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages (excluding references), 10 figures, to appear in APNET 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16112v2",
      "published_date": "2025-03-20 13:00:36 UTC",
      "updated_date": "2025-05-15 03:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:45.559997"
    },
    {
      "arxiv_id": "2503.16091v1",
      "title": "AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Mamun",
        "Diane J. Cook",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Adherence to prescribed treatments is crucial for individuals with chronic\nconditions to avoid costly or adverse health outcomes. For certain patient\ngroups, intensive lifestyle interventions are vital for enhancing medication\nadherence. Accurate forecasting of treatment adherence can open pathways to\ndeveloping an on-demand intervention tool, enabling timely and personalized\nsupport. With the increasing popularity of smartphones and wearables, it is now\neasier than ever to develop and deploy smart activity monitoring systems.\nHowever, effective forecasting systems for treatment adherence based on\nwearable sensors are still not widely available. We close this gap by proposing\nAdherence Forecasting and Intervention with Machine Intelligence (AIMI). AIMI\nis a knowledge-guided adherence forecasting system that leverages smartphone\nsensors and previous medication history to estimate the likelihood of\nforgetting to take a prescribed medication. A user study was conducted with 27\nparticipants who took daily medications to manage their cardiovascular\ndiseases. We designed and developed CNN and LSTM-based forecasting models with\nvarious combinations of input features and found that LSTM models can forecast\nmedication adherence with an accuracy of 0.932 and an F-1 score of 0.936.\nMoreover, through a series of ablation studies involving convolutional and\nrecurrent neural network architectures, we demonstrate that leveraging known\nknowledge about future and personalized training enhances the accuracy of\nmedication adherence forecasting. Code available:\nhttps://github.com/ab9mamun/AIMI.",
      "tldr_zh": "该研究提出AIMI系统，用于基于智能手机传感器和用药历史预测慢性病患者治疗依从性，旨在通过准确预测提供及时个性化干预。研究开发了CNN和LSTM模型，通过27名心血管病患者的实验验证，发现LSTM模型在预测用药依从性时准确率达0.932，F-1 score为0.936。消融研究进一步证明，结合未来知识和个性化训练能显著提升预测准确性，为智能干预工具的开发奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16091v1",
      "published_date": "2025-03-20 12:32:35 UTC",
      "updated_date": "2025-03-20 12:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:22:57.438660"
    },
    {
      "arxiv_id": "2503.16085v1",
      "title": "Allostatic Control of Persistent States in Spiking Neural Networks for perception and computation",
      "title_zh": "翻译失败",
      "authors": [
        "Aung Htet",
        "Alejandro Rodriguez Jimenez",
        "Sarah Hamburg",
        "Alessandro Di Nuovo"
      ],
      "abstract": "We introduce a novel model for updating perceptual beliefs about the\nenvironment by extending the concept of Allostasis to the control of internal\nrepresentations. Allostasis is a fundamental regulatory mechanism observed in\nanimal physiology that orchestrates responses to maintain a dynamic equilibrium\nin bodily needs and internal states. In this paper, we focus on an application\nin numerical cognition, where a bump of activity in an attractor network is\nused as a spatial numerical representation. While existing neural networks can\nmaintain persistent states, to date, there is no unified framework for\ndynamically controlling spatial changes in neuronal activity in response to\nenvironmental changes. To address this, we couple a well known allostatic\nmicrocircuit, the Hammel model, with a ring attractor, resulting in a Spiking\nNeural Network architecture that can modulate the location of the bump as a\nfunction of some reference input. This localized activity in turn is used as a\nperceptual belief in a simulated subitization task a quick enumeration process\nwithout counting. We provide a general procedure to fine-tune the model and\ndemonstrate the successful control of the bump location. We also study the\nresponse time in the model with respect to changes in parameters and compare it\nwith biological data. Finally, we analyze the dynamics of the network to\nunderstand the selectivity and specificity of different neurons to distinct\ncategories present in the input. The results of this paper, particularly the\nmechanism for moving persistent states, are not limited to numerical cognition\nbut can be applied to a wide range of tasks involving similar representations.",
      "tldr_zh": "本研究将 Allostasis 概念扩展到神经网络领域，提出一种新型模型，用于动态控制 Spiking Neural Networks 中的内部表示，以更新环境感知信念。该模型通过将 Hammel 模型与 ring attractor 相结合，构建了一个能根据参考输入调整神经元活动持久状态（persistent states）的架构，并应用于数字认知中的 subitization 任务模拟。实验结果显示，该网络能精确控制持久状态位置，并通过分析响应时间与生物数据比较，揭示了神经元对输入类别的高选择性和特异性。该方法不仅适用于数字认知，还可扩展到其他涉及类似表示的任务。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16085v1",
      "published_date": "2025-03-20 12:28:08 UTC",
      "updated_date": "2025-03-20 12:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:23:09.247205"
    },
    {
      "arxiv_id": "2503.16075v1",
      "title": "3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Wodzinski",
        "Henning Müller"
      ],
      "abstract": "Lightsheet microscopy is a powerful 3-D imaging technique that addresses\nlimitations of traditional optical and confocal microscopy but suffers from a\nlow penetration depth and reduced image quality at greater depths. Multiview\nlightsheet microscopy improves 3-D resolution by combining multiple views but\nsimultaneously increasing the complexity and the photon budget, leading to\npotential photobleaching and phototoxicity. The FuseMyCells challenge,\norganized in conjunction with the IEEE ISBI 2025 conference, aims to benchmark\ndeep learning-based solutions for fusing high-quality 3-D volumes from single\n3-D views, potentially simplifying procedures and conserving the photon budget.\nIn this work, we propose a contribution to the FuseMyCells challenge based on a\ntwo-step procedure. The first step processes a downsampled version of the image\nto capture the entire region of interest, while the second step uses a\npatch-based approach for high-resolution inference, incorporating adversarial\nloss to enhance visual outcomes. This method addresses challenges related to\nhigh data resolution, the necessity of global context, and the preservation of\nhigh-frequency details. Experimental results demonstrate the effectiveness of\nour approach, highlighting its potential to improve 3-D image fusion quality\nand extend the capabilities of lightsheet microscopy. The average SSIM for the\nnucleus and membranes is greater than 0.85 and 0.91, respectively.",
      "tldr_zh": "该论文针对 Lightsheet Microscopy 在深度成像中存在的低穿透深度和图像质量问题，提出了一种两步对抗网络（Adversarial Network）方法，用于从单个 3-D 视图融合高质量 3-D 体积，从而简化程序并减少光子预算。方法的第一步处理图像的降采样版本以捕获全局感兴趣区域，第二步采用基于 patch 的高分辨率推理，并结合 adversarial loss 来增强视觉细节和保留高频信息。在 FuseMyCells Challenge 的实验中，该方法表现出色，平均 SSIM 值分别达到核大于 0.85 和膜大于 0.91，证明了其在提升 3-D 图像融合质量方面的有效性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16075v1",
      "published_date": "2025-03-20 12:12:01 UTC",
      "updated_date": "2025-03-20 12:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:23:23.375147"
    },
    {
      "arxiv_id": "2503.16072v1",
      "title": "Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Berezin",
        "Reza Farahbakhsh",
        "Noel Crespi"
      ],
      "abstract": "The fundamental problem of toxicity detection lies in the fact that the term\n\"toxicity\" is ill-defined. Such uncertainty causes researchers to rely on\nsubjective and vague data during model training, which leads to non-robust and\ninaccurate results, following the 'garbage in - garbage out' paradigm. This\nstudy introduces a novel, objective, and context-aware framework for toxicity\ndetection, leveraging stress levels as a key determinant of toxicity. We\npropose new definition, metric and training approach as a parts of our\nframework and demonstrate it's effectiveness using a dataset we collected.",
      "tldr_zh": "本研究指出，toxicity检测的核心问题在于其定义模糊，导致模型训练依赖主观数据，产生不准确的结果，遵循“garbage in - garbage out”原则。该框架提出了一种新型、客观且上下文感知的方法，以stress levels作为毒性判断的关键因素，包括新的定义、指标和训练策略。通过自收集的数据集，研究者证明了该框架的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16072v1",
      "published_date": "2025-03-20 12:09:01 UTC",
      "updated_date": "2025-03-20 12:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:23:33.213427"
    },
    {
      "arxiv_id": "2503.16071v1",
      "title": "Tuning LLMs by RAG Principles: Towards LLM-native Memory",
      "title_zh": "通过 RAG 原则调优 LLMs：迈向 LLM 原生内存",
      "authors": [
        "Jiale Wei",
        "Shuchi Wu",
        "Ruochen Liu",
        "Xiang Ying",
        "Jingbo Shang",
        "Fangbo Tao"
      ],
      "abstract": "Memory, additional information beyond the training of large language models\n(LLMs), is crucial to various real-world applications, such as personal\nassistant. The two mainstream solutions to incorporate memory into the\ngeneration process are long-context LLMs and retrieval-augmented generation\n(RAG). In this paper, we first systematically compare these two types of\nsolutions on three renovated/new datasets and show that (1) long-context\nsolutions, although more expensive, shall be easier to capture the big picture\nand better answer queries which require considering the memory as a whole; and\n(2) when the queries concern specific information, RAG solutions shall be more\ncompetitive especially when the keywords can be explicitly matched. Therefore,\nwe propose a novel method RAG-Tuned-LLM which fine-tunes a relative small\n(e.g., 7B) LLM using the data generated following the RAG principles, so it can\ncombine the advantages of both solutions. Extensive experiments on three\ndatasets demonstrate that RAG-Tuned-LLM can beat long-context LLMs and RAG\nmethods across a wide range of query types.",
      "tldr_zh": "本文系统比较了长上下文 LLMs 和检索增强生成 (RAG) 两种整合内存的方法，发现长上下文 LLMs 更适合处理需要整体考虑的查询，但成本较高，而 RAG 在特定信息匹配方面更具竞争力。针对此，作者提出 RAG-Tuned-LLM 方法，通过使用 RAG 原则生成的数据微调小型 LLM（如 7B 模型），以结合两者的优势。在三个数据集上的广泛实验表明，RAG-Tuned-LLM 在多种查询类型上均优于长上下文 LLMs 和 RAG 方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16071v1",
      "published_date": "2025-03-20 12:04:40 UTC",
      "updated_date": "2025-03-20 12:04:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:23:45.910240"
    },
    {
      "arxiv_id": "2503.16064v1",
      "title": "PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Zou",
        "Shuli Cheng",
        "Jiayi Chen"
      ],
      "abstract": "Cross-modal hashing is a promising approach for efficient data retrieval and\nstorage optimization. However, contemporary methods exhibit significant\nlimitations in semantic preservation, contextual integrity, and information\nredundancy, which constrains retrieval efficacy. We present PromptHash, an\ninnovative framework leveraging affinity prompt-aware collaborative learning\nfor adaptive cross-modal hashing. We propose an end-to-end framework for\naffinity-prompted collaborative hashing, with the following fundamental\ntechnical contributions: (i) a text affinity prompt learning mechanism that\npreserves contextual information while maintaining parameter efficiency, (ii)\nan adaptive gated selection fusion architecture that synthesizes State Space\nModel with Transformer network for precise cross-modal feature integration, and\n(iii) a prompt affinity alignment strategy that bridges modal heterogeneity\nthrough hierarchical contrastive learning. To the best of our knowledge, this\nstudy presents the first investigation into affinity prompt awareness within\ncollaborative cross-modal adaptive hash learning, establishing a paradigm for\nenhanced semantic consistency across modalities. Through comprehensive\nevaluation on three benchmark multi-label datasets, PromptHash demonstrates\nsubstantial performance improvements over existing approaches. Notably, on the\nNUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in\nimage-to-text and text-to-image retrieval tasks, respectively. The code is\npublicly available at https://github.com/ShiShuMo/PromptHash.",
      "tldr_zh": "本论文提出了 PromptHash 框架，通过亲和提示协作学习（affinity-prompted collaborative learning）改进自适应跨模态散列（adaptive cross-modal hashing），以解决现有方法在语义保留、上下文完整性和信息冗余方面的局限。关键贡献包括：(i) 文本亲和提示学习机制（text affinity prompt learning），用于高效保留上下文信息；(ii) 自适应门控选择融合架构（adaptive gated selection fusion architecture），结合 State Space Model 和 Transformer 网络实现精确的跨模态特征整合；以及 (iii) 提示亲和对齐策略（prompt affinity alignment strategy），通过层次对比学习（hierarchical contrastive learning）桥接模态异质性。实验在三个基准多标签数据集上显示显著提升，例如在 NUS-WIDE 数据集上，图像到文本和文本到图像检索任务分别提高了 18.22% 和 18.65%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16064v1",
      "published_date": "2025-03-20 11:56:27 UTC",
      "updated_date": "2025-03-20 11:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:23:59.410177"
    },
    {
      "arxiv_id": "2503.16063v1",
      "title": "Two-stage Incomplete Utterance Rewriting on Editing Operation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Cao",
        "Peifeng Li",
        "Qiaoming Zhu",
        "Yaxin Fan"
      ],
      "abstract": "Previous work on Incomplete Utterance Rewriting (IUR) has primarily focused\non generating rewritten utterances based solely on dialogue context, ignoring\nthe widespread phenomenon of coreference and ellipsis in dialogues. To address\nthis issue, we propose a novel framework called TEO (\\emph{Two-stage approach\non Editing Operation}) for IUR, in which the first stage generates editing\noperations and the second stage rewrites incomplete utterances utilizing the\ngenerated editing operations and the dialogue context. Furthermore, an\nadversarial perturbation strategy is proposed to mitigate cascading errors and\nexposure bias caused by the inconsistency between training and inference in the\nsecond stage. Experimental results on three IUR datasets show that our TEO\noutperforms the SOTA models significantly.",
      "tldr_zh": "该研究针对 Incomplete Utterance Rewriting (IUR) 的局限性，提出了一种新型框架 TEO（Two-stage approach on Editing Operation），以解决对话中 coreference 和 ellipsis 等现象被忽略的问题。TEO 分为两个阶段：第一阶段生成 editing operations，第二阶段利用这些操作和对话上下文重写不完整的 utterances，同时引入 adversarial perturbation strategy 来减少级联错误（cascading errors）和 exposure bias。实验结果显示，在三个 IUR 数据集上，TEO 显著优于 SOTA 模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16063v1",
      "published_date": "2025-03-20 11:56:14 UTC",
      "updated_date": "2025-03-20 11:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:24:09.924823"
    },
    {
      "arxiv_id": "2503.16057v2",
      "title": "Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yike Yuan",
        "Ziyu Wang",
        "Zihao Huang",
        "Defa Zhu",
        "Xun Zhou",
        "Jingyi Yu",
        "Qiyang Min"
      ],
      "abstract": "Diffusion models have emerged as mainstream framework in visual generation.\nBuilding upon this success, the integration of Mixture of Experts (MoE) methods\nhas shown promise in enhancing model scalability and performance. In this\npaper, we introduce Race-DiT, a novel MoE model for diffusion transformers with\na flexible routing strategy, Expert Race. By allowing tokens and experts to\ncompete together and select the top candidates, the model learns to dynamically\nassign experts to critical tokens. Additionally, we propose per-layer\nregularization to address challenges in shallow layer learning, and router\nsimilarity loss to prevent mode collapse, ensuring better expert utilization.\nExtensive experiments on ImageNet validate the effectiveness of our approach,\nshowcasing significant performance gains while promising scaling properties.",
      "tldr_zh": "本文提出了一种新型模型 Race-DiT，用于提升 Diffusion models 在视觉生成中的可扩展性和性能，通过 Mixture of Experts (MoE) 方法引入灵活的 Expert Race 路由策略。该策略允许 tokens 和 experts 竞争选择顶尖候选，实现对关键 tokens 的动态专家分配，同时采用 per-layer regularization 处理浅层学习挑战，并通过 router similarity loss 防止 mode collapse。实验结果在 ImageNet 数据集上显示，Race-DiT 实现了显著的性能提升，并展示了良好的扩展潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16057v2",
      "published_date": "2025-03-20 11:45:08 UTC",
      "updated_date": "2025-03-25 08:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:24:22.051070"
    },
    {
      "arxiv_id": "2503.16047v2",
      "title": "Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic",
      "title_zh": "翻译失败",
      "authors": [
        "Bisola Faith Kayode",
        "Akinyemi Sadeeq Akintola",
        "Oluwole Fagbohun",
        "Egonna Anaesiuba-Bristol",
        "Onyekachukwu Ojumah",
        "Oluwagbade Odimayo",
        "Toyese Oloyede",
        "Aniema Inyang",
        "Teslim Kazeem",
        "Habeeb Alli",
        "Udodirim Ibem Offia",
        "Prisca Chinazor Amajuoyi"
      ],
      "abstract": "Denial-of-Service (DoS) attacks remain a critical threat to network security,\ndisrupting services and causing significant economic losses. Traditional\ndetection methods, including statistical and rule-based models, struggle to\nadapt to evolving attack patterns. To address this challenge, we propose a\nnovel Temporal-Spatial Attention Network (TSAN) architecture for detecting\nDenial of Service (DoS) attacks in network traffic. By leveraging both temporal\nand spatial features of network traffic, our approach captures complex traffic\npatterns and anomalies that traditional methods might miss. The TSAN model\nincorporates transformer-based temporal encoding, convolutional spatial\nencoding, and a cross-attention mechanism to fuse these complementary feature\nspaces. Additionally, we employ multi-task learning with auxiliary tasks to\nenhance the model's robustness. Experimental results on the NSL-KDD dataset\ndemonstrate that TSAN outperforms state-of-the-art models, achieving superior\naccuracy, precision, recall, and F1-score while maintaining computational\nefficiency for real-time deployment. The proposed architecture offers an\noptimal balance between detection accuracy and computational overhead, making\nit highly suitable for real-world network security applications.",
      "tldr_zh": "该研究针对DoS攻击对网络安全的威胁，提出了一种新型Temporal-Spatial Attention Network (TSAN)架构，用于检测网络流量中的DoS攻击。TSAN通过结合transformer-based temporal encoding、convolutional spatial encoding和cross-attention机制，捕捉流量的时间和空间特征，并利用multi-task learning with auxiliary tasks提升模型的鲁棒性。在NSL-KDD数据集上的实验显示，TSAN在准确率、精确率、召回率和F1-score方面均优于现有最先进模型，同时保持了高效的计算性能。该架构实现了检测准确性与计算开销的平衡，适用于实时网络安全应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 Pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.16047v2",
      "published_date": "2025-03-20 11:31:45 UTC",
      "updated_date": "2025-03-21 17:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:24:33.761067"
    },
    {
      "arxiv_id": "2503.16045v1",
      "title": "Open Science and Artificial Intelligence for supporting the sustainability of the SRC Network: The espSRC case",
      "title_zh": "翻译失败",
      "authors": [
        "J. Garrido",
        "S. Sánchez-Expósito",
        "A. Ruiz-Falcó",
        "J. Ruedas",
        "M. Á. Mendoza",
        "V. Vázquez",
        "M. Parra",
        "J. Sánchez",
        "I. Labadie",
        "L. Darriba",
        "J. Moldón",
        "M. Rodriguez-Álvarez",
        "J. Díaz",
        "L. Verdes-Montenegro"
      ],
      "abstract": "The SKA Observatory (SKAO), a landmark project in radio astronomy, seeks to\naddress fundamental questions in astronomy. To process its immense data output,\napproximately 700 PB/year, a global network of SKA Regional Centres (SR-CNet)\nwill provide the infrastructure, tools, computational power needed for\nscientific analysis and scientific support. The Spanish SRC (espSRC) focuses on\nensuring the sustainability of this network by reducing its environmental\nimpact, integrating green practices into data platforms, and developing Open\nScience technologies to enable reproducible research. This paper discusses and\nsummarizes part of the research and development activities that the team is\nconducting to reduce the SRC energy consumption at the espSRC and SRCNet. The\npaper also discusses fundamental research on trusted repositories to support\nOpen Science practices.",
      "tldr_zh": "这篇论文探讨了利用 Open Science 和 Artificial Intelligence 支持 SKA Regional Centres (SRCNet) 的可持续性，以西班牙 SRC (espSRC) 为案例研究。espSRC 专注于减少 SRCNet 的环境影响，包括整合绿色实践到数据平台、开发可再现研究的 Open Science 技术，并降低能源消耗。论文总结了相关的研究和开发活动，如优化能源使用和构建可信存储库，以推动可信赖的科学分析和可持续发展。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Conference: Astronomical Data Analysis Software & Systems - ADASS\n  XXXIV - 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.16045v1",
      "published_date": "2025-03-20 11:29:00 UTC",
      "updated_date": "2025-03-20 11:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:24:46.199037"
    },
    {
      "arxiv_id": "2503.16043v1",
      "title": "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation",
      "title_zh": "基于编辑操作指导和话语增强的不完整话语重写",
      "authors": [
        "Zhiyu Cao",
        "Peifeng Li",
        "Yaxin Fan",
        "Qiaoming Zhu"
      ],
      "abstract": "Although existing fashionable generation methods on Incomplete Utterance\nRewriting (IUR) can generate coherent utterances, they often result in the\ninclusion of irrelevant and redundant tokens in rewritten utterances due to\ntheir inability to focus on critical tokens in dialogue context. Furthermore,\nthe limited size of the training datasets also contributes to the insufficient\ntraining of the IUR model. To address the first issue, we propose a multi-task\nlearning framework EO-IUR (Editing Operation-guided Incomplete Utterance\nRewriting) that introduces the editing operation labels generated by sequence\nlabeling module to guide generation model to focus on critical tokens.\nFurthermore, we introduce a token-level heterogeneous graph to represent\ndialogues. To address the second issue, we propose a two-dimensional utterance\naugmentation strategy, namely editing operation-based incomplete utterance\naugmentation and LLM-based historical utterance augmentation. The experimental\nresults on three datasets demonstrate that our EO-IUR outperforms previous\nstate-of-the-art (SOTA) baselines in both open-domain and task-oriented\ndialogue. The code will be available at https://github.com/Dewset/EO-IUR.",
      "tldr_zh": "本文针对Incomplete Utterance Rewriting (IUR)中生成语句的无关和冗余tokens问题，提出多任务学习框架EO-IUR，通过序列标注模块生成的编辑操作标签指导生成模型聚焦关键tokens，并引入token-level heterogeneous graph表示对话。针对训练数据不足的问题，该框架采用两种增强策略：基于编辑操作的不完整语句增强和LLM-based historical utterance augmentation。实验结果显示，EO-IUR在三个数据集上超越了现有SOTA基线，在开放域和任务导向对话中显著提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16043v1",
      "published_date": "2025-03-20 11:26:46 UTC",
      "updated_date": "2025-03-20 11:26:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:24:58.613797"
    },
    {
      "arxiv_id": "2503.16041v2",
      "title": "GreenIQ: A Deep Search Platform for Comprehensive Carbon Market Analysis and Automated Report Generation",
      "title_zh": "GreenIQ：一种用于全面碳市场分析和自动报告生成的深度搜索平台",
      "authors": [
        "Oluwole Fagbohun",
        "Sai Yashwanth",
        "Akinyemi Sadeeq Akintola",
        "Ifeoluwa Wurola",
        "Lanre Shittu",
        "Aniema Inyang",
        "Oluwatimilehin Odubola",
        "Udodirim Offia",
        "Said Olanrewaju",
        "Ogidan Toluwaleke",
        "Ilemona Abutu",
        "Taiwo Akinbolaji"
      ],
      "abstract": "This study introduces GreenIQ, an AI-powered deep search platform designed to\nrevolutionise carbon market intelligence through autonomous analysis and\nautomated report generation. Carbon markets operate across diverse regulatory\nlandscapes, generating vast amounts of heterogeneous data from policy\ndocuments, industry reports, academic literature, and real-time trading\nplatforms. Traditional research approaches remain labour-intensive, slow, and\ndifficult to scale. GreenIQ addresses these limitations through a multi-agent\narchitecture powered by Large Language Models (LLMs), integrating five\nspecialised AI agents: a Main Researcher Agent for intelligent information\nretrieval, a Report Writing Agent for structured synthesis, a Final Reviewer\nAgent for accuracy verification, a Data Visualisation Agent for enhanced\ninterpretability, and a Translator Agent for multilingual adaptation. The\nsystem achieves seamless integration of structured and unstructured information\nwith AI-driven citation verification, ensuring high transparency and\nreliability. GreenIQ delivers a 99.2\\% reduction in processing time and a\n99.7\\% cost reduction compared to traditional research methodologies. A novel\nAI persona-based evaluation framework involving 16 domain-specific AI personas\nhighlights its superior cross-jurisdictional analytical capabilities and\nregulatory insight generation. GreenIQ sets new standards in AI-driven research\nsynthesis, policy analysis, and sustainability finance by streamlining carbon\nmarket research. It offers an efficient and scalable framework for\nenvironmental and financial intelligence, enabling more accurate, timely, and\ncost-effective decision-making in complex regulatory landscapes",
      "tldr_zh": "本研究引入了 GreenIQ，一种基于 AI 的深度搜索平台，旨在通过自主分析和自动化报告生成革新碳市场情报处理，解决传统方法在处理政策文档、行业报告和实时交易数据等方面的低效问题。GreenIQ 采用多智能体架构驱动 Large Language Models (LLMs)，包括 Main Researcher Agent 负责智能信息检索、Report Writing Agent 进行结构化合成、Final Reviewer Agent 验证准确性、Data Visualisation Agent 提升可解释性，以及 Translator Agent 支持多语言适应，确保信息整合透明可靠。实验结果显示，与传统方法相比，GreenIQ 实现了 99.2% 的处理时间减少和 99.7% 的成本降低，并通过一个新型 AI persona-based 评价框架验证了其在跨管辖分析和监管洞察方面的卓越性能。该平台为碳市场研究、政策分析和可持续金融提供高效、可扩展的框架，促进更准确、及时的决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 Pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.16041v2",
      "published_date": "2025-03-20 11:19:43 UTC",
      "updated_date": "2025-03-21 17:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:25:10.960433"
    },
    {
      "arxiv_id": "2503.16036v1",
      "title": "Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihang Liu",
        "Chen-Wei Xie",
        "Pandeng Li",
        "Liming Zhao",
        "Longxiang Tang",
        "Yun Zheng",
        "Chuanbin Liu",
        "Hongtao Xie"
      ],
      "abstract": "Recent Multi-modal Large Language Models (MLLMs) have been challenged by the\ncomputational overhead resulting from massive video frames, often alleviated\nthrough compression strategies. However, the visual content is not equally\ncontributed to user instructions, existing strategies (\\eg, average pool)\ninevitably lead to the loss of potentially useful information. To tackle this,\nwe propose the Hybrid-level Instruction Injection Strategy for Conditional\nToken Compression in MLLMs (HICom), utilizing the instruction as a condition to\nguide the compression from both local and global levels. This encourages the\ncompression to retain the maximum amount of user-focused information while\nreducing visual tokens to minimize computational burden. Specifically, the\ninstruction condition is injected into the grouped visual tokens at the local\nlevel and the learnable tokens at the global level, and we conduct the\nattention mechanism to complete the conditional compression. From the\nhybrid-level compression, the instruction-relevant visual parts are highlighted\nwhile the temporal-spatial structure is also preserved for easier understanding\nof LLMs. To further unleash the potential of HICom, we introduce a new\nconditional pre-training stage with our proposed dataset HICom-248K.\nExperiments show that our HICom can obtain distinguished video understanding\nability with fewer tokens, increasing the performance by 2.43\\% average on\nthree multiple-choice QA benchmarks and saving 78.8\\% tokens compared with the\nSOTA method. The code is available at https://github.com/lntzm/HICom.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)处理视频帧时面临的计算开销问题，提出了一种混合水平指令注入策略(HICom)，利用用户指令作为条件，从局部和全局水平指导视频令牌压缩，以保留指令相关信息并减少计算负担。HICom 通过将指令注入分组视觉令牌和可学习令牌，并应用注意力机制，突出相关视觉部分的同时保持时空结构。研究还引入了 HICom-248K 数据集进行条件预训练。实验结果显示，HICom 在三个多选 QA 基准上平均性能提升 2.43%，并节省 78.8% 的令牌，优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.16036v1",
      "published_date": "2025-03-20 11:09:18 UTC",
      "updated_date": "2025-03-20 11:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:25:23.649173"
    },
    {
      "arxiv_id": "2503.16025v1",
      "title": "Single Image Iterative Subject-driven Generation and Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Yair Shpitzer",
        "Gal Chechik",
        "Idan Schwartz"
      ],
      "abstract": "Personalizing image generation and editing is particularly challenging when\nwe only have a few images of the subject, or even a single image. A common\napproach to personalization is concept learning, which can integrate the\nsubject into existing models relatively quickly, but produces images whose\nquality tends to deteriorate quickly when the number of subject images is\nsmall. Quality can be improved by pre-training an encoder, but training\nrestricts generation to the training distribution, and is time consuming. It is\nstill an open hard challenge to personalize image generation and editing from a\nsingle image without training. Here, we present SISO, a novel, training-free\napproach based on optimizing a similarity score with an input subject image.\nMore specifically, SISO iteratively generates images and optimizes the model\nbased on loss of similarity with the given subject image until a satisfactory\nlevel of similarity is achieved, allowing plug-and-play optimization to any\nimage generator. We evaluated SISO in two tasks, image editing and image\ngeneration, using a diverse data set of personal subjects, and demonstrate\nsignificant improvements over existing methods in image quality, subject\nfidelity, and background preservation.",
      "tldr_zh": "这篇论文提出了一种无需训练的 SISO 方法，用于从单张图像实现个性化的图像生成和编辑，解决了现有 concept learning 技术在主题图像数量少时图像质量快速下降的问题。SISO 通过迭代生成图像并优化与输入主题图像的相似度分数，直到达到满意水平，从而实现即插即用的优化兼容任何图像生成器。在实验评估中，SISO 在图像编辑和生成任务上，使用多样化数据集，显著提升了图像质量、主体保真度和背景保留性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page is at https://siso-paper.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2503.16025v1",
      "published_date": "2025-03-20 10:45:04 UTC",
      "updated_date": "2025-03-20 10:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:25:33.754147"
    },
    {
      "arxiv_id": "2503.16024v1",
      "title": "The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Ruihan Yang",
        "Fanghua Ye",
        "Jian Li",
        "Siyu Yuan",
        "Yikai Zhang",
        "Zhaopeng Tu",
        "Xiaolong Li",
        "Deqing Yang"
      ],
      "abstract": "Large language models (LLMs) have recently transformed from text-based\nassistants to autonomous agents capable of planning, reasoning, and iteratively\nimproving their actions. While numerical reward signals and verifiers can\neffectively rank candidate actions, they often provide limited contextual\nguidance. In contrast, natural language feedback better aligns with the\ngenerative capabilities of LLMs, providing richer and more actionable\nsuggestions. However, parsing and implementing this feedback effectively can be\nchallenging for LLM-based agents. In this work, we introduce Critique-Guided\nImprovement (CGI), a novel two-player framework, comprising an actor model that\nexplores an environment and a critic model that generates detailed nature\nlanguage feedback. By training the critic to produce fine-grained assessments\nand actionable revisions, and the actor to utilize these critiques, our\napproach promotes more robust exploration of alternative strategies while\navoiding local optima. Experiments in three interactive environments show that\nCGI outperforms existing baselines by a substantial margin. Notably, even a\nsmall critic model surpasses GPT-4 in feedback quality. The resulting actor\nachieves state-of-the-art performance, demonstrating the power of explicit\niterative guidance to enhance decision-making in LLM-based agents.",
      "tldr_zh": "本研究探讨了如何通过Critique-Guided Improvement (CGI)框架提升LLM代理的决策能力，以解决传统数值奖励信号的局限性。CGI采用双玩家设计，包括Actor模型负责环境探索，以及Critic模型生成细粒度的自然语言反馈和可操作修订，从而帮助Actor避免局部最优并实现更稳健的策略迭代。在三个交互环境中，实验结果显示CGI显著优于现有基线，即使小型Critic模型也超过了GPT-4的反馈质量，最终使Actor模型达到最先进性能，为LLM代理的自主改进提供了新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16024v1",
      "published_date": "2025-03-20 10:42:33 UTC",
      "updated_date": "2025-03-20 10:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:25:46.029472"
    },
    {
      "arxiv_id": "2503.16021v3",
      "title": "Autonomous AI imitators increase diversity in homogeneous information ecosystems",
      "title_zh": "自治AI模仿者在同质信息生态系统中增加多样性",
      "authors": [
        "Emil Bakkensen Johansen",
        "Oliver Baumann"
      ],
      "abstract": "Recent breakthroughs in large language models (LLMs) have facilitated\nautonomous AI agents capable of imitating human-generated content. This\ntechnological advancement raises fundamental questions about AI's impact on the\ndiversity and democratic value of information ecosystems. We introduce a\nlarge-scale simulation framework to examine AI-based imitation within news, a\ncontext crucial for public discourse. By systematically testing two distinct\nimitation strategies across a range of information environments varying in\ninitial diversity, we demonstrate that AI-generated articles do not uniformly\nhomogenize content. Instead, AI's influence is strongly context-dependent:\nAI-generated content can introduce valuable diversity in originally homogeneous\nnews environments but diminish diversity in initially heterogeneous contexts.\nThese results illustrate that the initial diversity of an information\nenvironment critically shapes AI's impact, challenging assumptions that\nAI-driven imitation threatens diversity. Instead, when information is initially\nhomogeneous, AI-driven imitation can expand perspectives, styles, and topics.\nThis is especially important in news contexts, where information diversity\nfosters richer public debate by exposing citizens to alternative viewpoints,\nchallenging biases, and preventing narrative monopolies, which is essential for\na resilient democracy.",
      "tldr_zh": "这篇论文探讨了自主 AI 代理（基于 LLMs）模仿人类内容对信息生态系统多样性的影响，特别在新闻环境中。研究者构建了一个大规模模拟框架，测试两种模仿策略在不同初始多样性环境下的表现，结果显示 AI 生成的内容不会一成不变地导致同质化——在原本同质的环境中，AI 可以增加视角、风格和主题的多样性，而在异质环境中则可能减少多样性。这些发现挑战了 AI 会威胁信息多样性的假设，并强调在同质信息生态中，AI 驱动的模仿有助于丰富公共辩论，促进民主韧性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "J.4"
      ],
      "primary_category": "cs.CY",
      "comment": "42 pages, 11 figures, 4 tables; v2: corrected typographical errors,\n  streamlined language, updated abstract, added supplementary information; v3:\n  restructured appendix, added temperature and embeddings sensitivity checks",
      "pdf_url": "http://arxiv.org/pdf/2503.16021v3",
      "published_date": "2025-03-20 10:37:29 UTC",
      "updated_date": "2025-03-28 13:23:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:25:58.393000"
    },
    {
      "arxiv_id": "2503.18964v1",
      "title": "Unifying EEG and Speech for Emotion Recognition: A Two-Step Joint Learning Framework for Handling Missing EEG Data During Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Upasana Tiwari",
        "Rupayan Chakraborty",
        "Sunil Kumar Kopparapu"
      ],
      "abstract": "Computer interfaces are advancing towards using multi-modalities to enable\nbetter human-computer interactions. The use of automatic emotion recognition\n(AER) can make the interactions natural and meaningful thereby enhancing the\nuser experience. Though speech is the most direct and intuitive modality for\nAER, it is not reliable because it can be intentionally faked by humans. On the\nother hand, physiological modalities like EEG, are more reliable and impossible\nto fake. However, use of EEG is infeasible for realistic scenarios usage\nbecause of the need for specialized recording setup. In this paper, one of our\nprimary aims is to ride on the reliability of the EEG modality to facilitate\nrobust AER on the speech modality. Our approach uses both the modalities during\ntraining to reliably identify emotion at the time of inference, even in the\nabsence of the more reliable EEG modality. We propose, a two-step joint\nmulti-modal learning approach (JMML) that exploits both the intra- and inter-\nmodal characteristics to construct emotion embeddings that enrich the\nperformance of AER. In the first step, using JEC-SSL, intra-modal learning is\ndone independently on the individual modalities. This is followed by an\ninter-modal learning using the proposed extended variant of deep canonically\ncorrelated cross-modal autoencoder (E-DCC-CAE). The approach learns the joint\nproperties of both the modalities by mapping them into a common representation\nspace, such that the modalities are maximally correlated. These emotion\nembeddings, hold properties of both the modalities there by enhancing the\nperformance of ML classifier used for AER. Experimental results show the\nefficacy of the proposed approach. To best of our knowledge, this is the first\nattempt to combine speech and EEG with joint multi-modal learning approach for\nreliable AER.",
      "tldr_zh": "该论文提出了一种两步联合多模态学习框架(JMML)，旨在通过结合语音和EEG模态进行自动情感识别(AER)，以解决推理阶段EEG数据缺失的问题，从而提升系统的可靠性和鲁棒性。\n在第一步，使用JEC-SSL对语音和EEG进行独立内部模态学习；第二步，通过扩展的深度规范相关跨模态自编码器(E-DCC-CAE)将两个模态映射到共同表示空间，使它们最大相关，从而生成增强的情感嵌入。\n实验结果显示，该方法显著提高了AER的性能，且这是首次尝试将语音和EEG结合用于可靠的AER系统。",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.18964v1",
      "published_date": "2025-03-20 10:26:49 UTC",
      "updated_date": "2025-03-20 10:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:26:10.949200"
    },
    {
      "arxiv_id": "2503.16577v1",
      "title": "Feature selection strategies for optimized heart disease diagnosis using ML and DL models",
      "title_zh": "翻译失败",
      "authors": [
        "Bilal Ahmad",
        "Jinfu Chen",
        "Haibao Chen"
      ],
      "abstract": "Heart disease remains one of the leading causes of morbidity and mortality\nworldwide, necessitating the development of effective diagnostic tools to\nenable early diagnosis and clinical decision-making. This study evaluates the\nimpact of feature selection techniques Mutual Information (MI), Analysis of\nVariance (ANOVA), and Chi-Square on the predictive performance of various\nmachine learning (ML) and deep learning (DL) models using a dataset of clinical\nindicators for heart disease. Eleven ML/DL models were assessed using metrics\nsuch as precision, recall, AUC score, F1-score, and accuracy. Results indicate\nthat MI outperformed other methods, particularly for advanced models like\nneural networks, achieving the highest accuracy of 82.3% and recall score of\n0.94. Logistic regression (accuracy 82.1%) and random forest (accuracy 80.99%)\nalso demonstrated improved performance with MI. Simpler models such as Naive\nBayes and decision trees achieved comparable results with ANOVA and Chi-Square,\nyielding accuracies of 76.45% and 75.99%, respectively, making them\ncomputationally efficient alternatives. Conversely, k Nearest Neighbors (KNN)\nand Support Vector Machines (SVM) exhibited lower performance, with accuracies\nranging between 51.52% and 54.43%, regardless of the feature selection method.\nThis study provides a comprehensive comparison of feature selection methods for\nheart disease prediction, demonstrating the critical role of feature selection\nin optimizing model performance. The results offer practical guidance for\nselecting appropriate feature selection techniques based on the chosen\nclassification algorithm, contributing to the development of more accurate and\nefficient diagnostic tools for enhanced clinical decision-making in cardiology.",
      "tldr_zh": "本文研究评估了Mutual Information (MI)、Analysis of Variance (ANOVA) 和 Chi-Square 等特征选择技术对机器学习 (ML) 和深度学习 (DL) 模型在心脏病诊断中的影响，使用11个模型并以准确率、recall、AUC分数等指标进行评估。结果显示，MI 方法表现最佳，尤其在神经网络上达到82.3%的最高准确率和0.94的recall分数，而Logistic Regression (82.1%) 和 Random Forest (80.99%) 也显著受益；相反，简单模型如Naive Bayes (76.45%) 和 Decision Trees (75.99%) 与 ANOVA 或 Chi-Square 兼容性较好，提供计算高效选项，而KNN和SVM的准确率仅为51.52%至54.43%，不受方法影响。该研究为基于不同分类算法选择特征选择技术提供了实用指导，提升心脏病诊断工具的准确性和临床决策效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16577v1",
      "published_date": "2025-03-20 09:59:01 UTC",
      "updated_date": "2025-03-20 09:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:26:23.249257"
    },
    {
      "arxiv_id": "2503.16575v1",
      "title": "Extract, Match, and Score: An Evaluation Paradigm for Long Question-context-answer Triplets in Financial Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Hu",
        "Han Yuan",
        "Vlad Pandelea",
        "Wuqiong Luo",
        "Yingzhu Zhao",
        "Zheng Ma"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has sparked widespread\nadoption across diverse applications, making robust evaluation frameworks\ncrucial for assessing their performance. While conventional evaluation metrics\nremain applicable for shorter texts, their efficacy diminishes when evaluating\nthe quality of long-form answers. This limitation is particularly critical in\nreal-world scenarios involving extended questions, extensive context, and\nlong-form answers, such as financial analysis or regulatory compliance. In this\npaper, we use a practical financial use case to illustrate applications that\nhandle \"long question-context-answer triplets\". We construct a real-world\nfinancial dataset comprising long triplets and demonstrate the inadequacies of\ntraditional metrics. To address this, we propose an effective Extract, Match,\nand Score (EMS) evaluation approach tailored to the complexities of long-form\nLLMs' outputs, providing practitioners with a reliable methodology for\nassessing LLMs' performance in complex real-world scenarios.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在处理长文本时的评估挑战，特别关注金融分析中的长问题-上下文-答案三元组，指出传统评估指标在这种场景下效果有限。作者构建了一个真实金融数据集，展示了现有方法的不足，并提出了一种Extract, Match, and Score (EMS)评估框架，该框架通过提取关键信息、匹配相关性并评分，来更准确地评估LLMs的输出质量。实验结果表明，EMS方法为LLMs在复杂真实世界应用中提供了一个可靠的性能评估工具，尤其适用于监管合规等领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16575v1",
      "published_date": "2025-03-20 09:38:44 UTC",
      "updated_date": "2025-03-20 09:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:26:32.990677"
    },
    {
      "arxiv_id": "2503.15985v1",
      "title": "Exploring the Reliability of Self-explanation and its Relationship with Classification in Language Model-driven Financial Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Han Yuan",
        "Li Zhang",
        "Zheng Ma"
      ],
      "abstract": "Language models (LMs) have exhibited exceptional versatility in reasoning and\nin-depth financial analysis through their proprietary information processing\ncapabilities. Previous research focused on evaluating classification\nperformance while often overlooking explainability or pre-conceived that\nrefined explanation corresponds to higher classification accuracy. Using a\npublic dataset in finance domain, we quantitatively evaluated self-explanations\nby LMs, focusing on their factuality and causality. We identified the\nstatistically significant relationship between the accuracy of classifications\nand the factuality or causality of self-explanations. Our study built an\nempirical foundation for approximating classification confidence through\nself-explanations and for optimizing classification via proprietary reasoning.",
      "tldr_zh": "本研究探讨了语言模型(LMs)在金融分析中的自解释(self-explanations)可靠性和其与分类准确率的关系，挑战了先前假设即更好的解释必然对应更高准确率的观点。研究使用公开金融数据集，量化评估了自解释的事实性(factuality)和因果性(causality)。结果显示，分类准确率与自解释的事实性和因果性之间存在统计显著关系。该发现为通过自解释近似分类置信度(confidence)并优化LMs的专有推理提供了实证基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15985v1",
      "published_date": "2025-03-20 09:33:59 UTC",
      "updated_date": "2025-03-20 09:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:26:45.924312"
    },
    {
      "arxiv_id": "2503.16573v1",
      "title": "AUV Acceleration Prediction Using DVL and Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yair Stolero",
        "Itzik Klein"
      ],
      "abstract": "Autonomous underwater vehicles (AUVs) are essential for various applications,\nincluding oceanographic surveys, underwater mapping, and infrastructure\ninspections. Accurate and robust navigation are critical to completing these\ntasks. To this end, a Doppler velocity log (DVL) and inertial sensors are fused\ntogether. Recently, a model-based approach demonstrated the ability to extract\nthe vehicle acceleration vector from DVL velocity measurements. Motivated by\nthis advancement, in this paper we present an end-to-end deep learning approach\nto estimate the AUV acceleration vector based on past DVL velocity\nmeasurements. Based on recorded data from sea experiments, we demonstrate that\nthe proposed method improves acceleration vector estimation by more than 65%\ncompared to the model-based approach by using data-driven techniques. As a\nresult of our data-driven approach, we can enhance navigation accuracy and\nreliability in AUV applications, contributing to more efficient and effective\nunderwater missions through improved accuracy and reliability.",
      "tldr_zh": "本研究提出了一种基于深度学习的端到端方法，使用DVL（Doppler Velocity Log）过去速度测量来预测AUV（Autonomous Underwater Vehicles）的加速度向量，以提升其导航性能。该方法通过数据驱动技术，相比传统的模型方法提高了超过65%的加速度估计准确性。实验基于海试数据验证了这一改进，结果表明它能增强AUV应用的导航准确性和可靠性，从而促进更高效的水下任务执行。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16573v1",
      "published_date": "2025-03-20 09:33:47 UTC",
      "updated_date": "2025-03-20 09:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:26:57.774039"
    },
    {
      "arxiv_id": "2503.15984v1",
      "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Suraj Singh",
        "Anastasia Batsheva",
        "Oleg Y. Rogov",
        "Ahmed Bouridane"
      ],
      "abstract": "Contemporary image restoration and super-resolution techniques effectively\nharness deep neural networks, markedly outperforming traditional methods.\nHowever, astrophotography presents unique challenges for deep learning due to\nlimited training data. This work explores hybrid strategies, such as the Deep\nImage Prior (DIP) model, which facilitates blind training but is susceptible to\noverfitting, artifact generation, and instability when handling noisy images.\nWe propose enhancements to the DIP model's baseline performance through several\nadvanced techniques. First, we refine the model to process multiple frames\nconcurrently, employing the Back Projection method and the TVNet model. Next,\nwe adopt a Markov approach incorporating Monte Carlo estimation, Langevin\ndynamics, and a variational input technique to achieve unbiased estimates with\nminimal variance and counteract overfitting effectively. Collectively, these\nmodifications reduce the likelihood of noise learning and mitigate loss\nfunction fluctuations during training, enhancing result stability. We validated\nour algorithm across multiple image sets of astronomical and celestial objects,\nachieving performance that not only mitigates limitations of Lucky Imaging, a\nclassical computer vision technique that remains a standard in astronomical\nimage reconstruction but surpasses the original DIP model, state of the art\ntransformer- and diffusion-based models, underscoring the significance of our\nimprovements.",
      "tldr_zh": "本研究提出DIPLI，一种基于Deep Image Prior (DIP)模型的混合策略，用于盲天文图像恢复，旨在解决深度学习在天文摄影中因训练数据有限而面临的过拟合、伪影生成和不稳定性问题。研究通过改进DIP模型，使其同时处理多个帧，并整合Back Projection方法、TVNet模型以及Markov方法（包括Monte Carlo估计、Langevin dynamics和变分输入技术），从而实现无偏估计、减少方差并提升训练稳定性。实验结果显示，DIPLI在多个天文图像数据集上超越了Lucky Imaging、原始DIP模型以及最先进的transformer-和diffusion-based模型，显著提高了图像恢复性能。",
      "categories": [
        "cs.CV",
        "astro-ph.IM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15984v1",
      "published_date": "2025-03-20 09:33:16 UTC",
      "updated_date": "2025-03-20 09:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:27:10.597091"
    },
    {
      "arxiv_id": "2503.15983v1",
      "title": "InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Zhang",
        "Rickard Brännvall"
      ],
      "abstract": "This work explores optimizing transformer-based language models by\nintegrating model compression techniques with inhibitor attention, a novel\nalternative attention mechanism. Inhibitor attention employs Manhattan\ndistances and ReLU activations instead of the matrix multiplications and\nsoftmax activation of the conventional scaled dot-product attention. This shift\noffers potential computational and energy savings while maintaining model\neffectiveness. We propose further adjustments to improve the inhibitor\nmechanism's training efficiency and evaluate its performance on the DistilBERT\narchitecture. Our knowledge distillation experiments indicate that the modified\ninhibitor transformer model can achieve competitive performance on standard NLP\nbenchmarks, including General Language Understanding Evaluation (GLUE) and\nsentiment analysis tasks.",
      "tldr_zh": "本文提出InhibiDistilbert框架，通过知识蒸馏(Knowledge Distillation)技术优化Transformer-based语言模型，并引入Inhibitor Attention机制，该机制使用Manhattan distances和ReLU activations替代传统的矩阵乘法和Softmax激活，以实现计算和能耗节约。研究进一步调整了Inhibitor机制以提升训练效率，并在DistilBERT架构上进行评估。实验结果显示，该模型在标准NLP基准如GLUE和情感分析任务上表现出与基线相当的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50 (Primary) 68T07, 68Q32 (Secondary)",
        "I.2.6; I.2.7; I.5.1"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15983v1",
      "published_date": "2025-03-20 09:30:35 UTC",
      "updated_date": "2025-03-20 09:30:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:27:21.913137"
    },
    {
      "arxiv_id": "2503.15969v1",
      "title": "Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Clive Tinashe Marimo",
        "Benedikt Blumenstiel",
        "Maximilian Nitsche",
        "Johannes Jakubik",
        "Thomas Brunschwiler"
      ],
      "abstract": "Vision-language models for Earth observation (EO) typically rely on the\nvisual spectrum of data as the only model input, thus failing to leverage the\nrich spectral information available in the multispectral channels recorded by\nsatellites. Therefore, in this paper, we introduce Llama3-MS-CLIP, the first\nvision-language model pre-trained with contrastive learning on a large-scale\nmultispectral dataset and report on the performance gains due to the extended\nspectral range. Furthermore, we present the largest-to-date image-caption\ndataset for multispectral data, consisting of one million Sentinel-2 samples\nand corresponding textual descriptions generated with Llama3-LLaVA-Next and\nOverture Maps data. We develop a scalable captioning pipeline, which is\nvalidated by domain experts. We evaluate Llama3-MS-CLIP on multispectral\nzero-shot image classification and retrieval using three datasets of varying\ncomplexity. Our results demonstrate that Llama3-MS-CLIP significantly\noutperforms other RGB-based approaches, improving classification accuracy by\n6.77% on average and retrieval performance by 4.63% mAP compared to the\nsecond-best model. Our results emphasize the relevance of multispectral\nvision-language learning. We release the image-caption dataset, code, and model\nweights under an open-source license.",
      "tldr_zh": "本文提出Llama3-MS-CLIP，这是首个使用对比学习在大型多光谱数据集上预训练的视觉语言模型，用于地球观测（EO），以充分利用卫星的多光谱通道信息，超越传统仅依赖可见光谱的限制。研究构建了迄今为止最大的多光谱图像-标题数据集，包括一百万Sentinel-2样本，并开发了一个可扩展的标题生成管道，由领域专家验证。实验结果显示，Llama3-MS-CLIP在多光谱零样本图像分类和检索任务上显著优于基于RGB的方法，平均提高6.77%分类准确率和4.63% mAP检索性能。该模型及其数据集、代码和权重已开源，强调了多光谱视觉语言学习在EO领域的关键价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15969v1",
      "published_date": "2025-03-20 09:13:31 UTC",
      "updated_date": "2025-03-20 09:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:27:35.928465"
    },
    {
      "arxiv_id": "2503.16572v1",
      "title": "Efficient ANN-Guided Distillation: Aligning Rate-based Features of Spiking Neural Networks through Hybrid Block-wise Replacement",
      "title_zh": "翻译失败",
      "authors": [
        "Shu Yang",
        "Chengting Yu",
        "Lei Liu",
        "Hanzhi Ma",
        "Aili Wang",
        "Erping Li"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have garnered considerable attention as a\npotential alternative to Artificial Neural Networks (ANNs). Recent studies have\nhighlighted SNNs' potential on large-scale datasets. For SNN training, two main\napproaches exist: direct training and ANN-to-SNN (ANN2SNN) conversion. To fully\nleverage existing ANN models in guiding SNN learning, either direct ANN-to-SNN\nconversion or ANN-SNN distillation training can be employed. In this paper, we\npropose an ANN-SNN distillation framework from the ANN-to-SNN perspective,\ndesigned with a block-wise replacement strategy for ANN-guided learning. By\ngenerating intermediate hybrid models that progressively align SNN feature\nspaces to those of ANN through rate-based features, our framework naturally\nincorporates rate-based backpropagation as a training method. Our approach\nachieves results comparable to or better than state-of-the-art SNN distillation\nmethods, showing both training and learning efficiency.",
      "tldr_zh": "本文提出了一种高效的 ANN-Guided Distillation 框架，通过混合块级替换策略 (hybrid block-wise replacement) 来对齐 Spiking Neural Networks (SNNs) 的基于率特征 (rate-based features) 与 Artificial Neural Networks (ANNs)。该框架从 ANN-to-SNN (ANN2SNN) 角度出发，生成中间混合模型，并自然整合基于率的回传 (rate-based backpropagation) 作为训练方法，以逐步实现特征空间对齐。实验结果显示，该方法在训练和学习效率上达到或超过最先进 SNN 蒸馏方法，提供了一种更有效的 SNN 学习指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16572v1",
      "published_date": "2025-03-20 09:04:38 UTC",
      "updated_date": "2025-03-20 09:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:27:47.744421"
    },
    {
      "arxiv_id": "2503.15953v1",
      "title": "GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed Attaoui",
        "Fabrizio Pastore"
      ],
      "abstract": "The generation of synthetic inputs via simulators driven by search algorithms\nis essential for cost-effective testing of Deep Neural Network (DNN) components\nfor safety-critical systems. However, in many applications, simulators are\nunable to produce the ground-truth data needed for automated test oracles and\nto guide the search process.\n  To tackle this issue, we propose an approach for the generation of inputs for\ncomputer vision DNNs that integrates a generative network to ensure simulator\nfidelity and employs heuristic-based search fitnesses that leverage\ntransformation consistency, noise resistance, surprise adequacy, and\nuncertainty estimation. We compare the performance of our fitnesses with that\nof a traditional fitness function leveraging ground truth; further, we assess\nhow the integration of a GAN not leveraging the ground truth impacts on test\nand retraining effectiveness.\n  Our results suggest that leveraging transformation consistency is the best\noption to generate inputs for both DNN testing and retraining; it maximizes\ninput diversity, spots the inputs leading to worse DNN performance, and leads\nto best DNN performance after retraining. Besides enabling simulator-based\ntesting in the absence of ground truth, our findings pave the way for testing\nsolutions that replace costly simulators with diffusion and large language\nmodels, which might be more affordable than simulators, but cannot generate\nground-truth data.",
      "tldr_zh": "该论文提出了一种在没有 ground truth 的情况下进行 Deep Neural Network (DNN) 测试的方法，通过整合 GAN（生成对抗网络）增强模拟器驱动的输入生成，并使用启发式搜索适应度函数，如 transformation consistency、noise resistance、surprise adequacy 和 uncertainty estimation，来指导测试过程。相比传统依赖 ground truth 的适应度函数，该方法在测试和重新训练中表现出色，特别是 transformation consistency 能最大化输入多样性、识别导致 DNN 性能下降的输入，并显著提升重新训练后的模型性能。研究结果为无 ground truth 环境的 DNN 测试提供了可行解决方案，并为使用 diffusion 或 large language models 替代昂贵模拟器铺平了道路。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages, 8 figures, 13 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15953v1",
      "published_date": "2025-03-20 08:49:10 UTC",
      "updated_date": "2025-03-20 08:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:27:58.261297"
    },
    {
      "arxiv_id": "2503.15948v1",
      "title": "Don't Fight Hallucinations, Use Them: Estimating Image Realism using NLI over Atomic Facts",
      "title_zh": "翻译失败",
      "authors": [
        "Elisei Rykov",
        "Kseniia Petrushina",
        "Kseniia Titova",
        "Alexander Panchenko",
        "Vasily Konovalov"
      ],
      "abstract": "Quantifying the realism of images remains a challenging problem in the field\nof artificial intelligence. For example, an image of Albert Einstein holding a\nsmartphone violates common-sense because modern smartphone were invented after\nEinstein's death. We introduce a novel method for assessing image realism using\nLarge Vision-Language Models (LVLMs) and Natural Language Inference (NLI). Our\napproach is based on the premise that LVLMs may generate hallucinations when\nconfronted with images that defy common sense. Using LVLM to extract atomic\nfacts from these images, we obtain a mix of accurate facts and erroneous\nhallucinations. We proceed by calculating pairwise entailment scores among\nthese facts, subsequently aggregating these values to yield a singular reality\nscore. This process serves to identify contradictions between genuine facts and\nhallucinatory elements, signaling the presence of images that violate common\nsense. Our approach has achieved a new state-of-the-art performance in\nzero-shot mode on the WHOOPS! dataset.",
      "tldr_zh": "这篇论文提出了一种创新方法，利用 Large Vision-Language Models (LVLMs) 生成的幻觉来评估图像真实性，而非试图消除它们。具体而言，该方法从图像中提取原子事实，然后使用 Natural Language Inference (NLI) 计算这些事实之间的配对蕴含分数，并聚合分数以生成一个整体现实分数，从而识别违背常识的图像。实验结果显示，该方法在 WHOOPS! 数据集的零样本模式下，实现了新的 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Proceedings of De-Factify 4: 4nd Workshop on Multimodal Fact Checking\n  and Hate Speech Detection, co-located with AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15948v1",
      "published_date": "2025-03-20 08:44:10 UTC",
      "updated_date": "2025-03-20 08:44:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:28:10.067558"
    },
    {
      "arxiv_id": "2503.15947v1",
      "title": "Unreal-MAP: Unreal-Engine-Based General Platform for Multi-Agent Reinforcement Learning",
      "title_zh": "Unreal-MAP：基于 Unreal",
      "authors": [
        "Tianyi Hu",
        "Qingxu Fu",
        "Zhiqiang Pu",
        "Yuan Wang",
        "Tenghai Qiu"
      ],
      "abstract": "In this paper, we propose Unreal Multi-Agent Playground (Unreal-MAP), an MARL\ngeneral platform based on the Unreal-Engine (UE). Unreal-MAP allows users to\nfreely create multi-agent tasks using the vast visual and physical resources\navailable in the UE community, and deploy state-of-the-art (SOTA) MARL\nalgorithms within them. Unreal-MAP is user-friendly in terms of deployment,\nmodification, and visualization, and all its components are open-source. We\nalso develop an experimental framework compatible with algorithms ranging from\nrule-based to learning-based provided by third-party frameworks. Lastly, we\ndeploy several SOTA algorithms in example tasks developed via Unreal-MAP, and\nconduct corresponding experimental analyses. We believe Unreal-MAP can play an\nimportant role in the MARL field by closely integrating existing algorithms\nwith user-customized tasks, thus advancing the field of MARL.",
      "tldr_zh": "本文提出 Unreal-MAP，这是一个基于 Unreal-Engine 的多智能体强化学习 (MARL) 通用平台，允许用户利用 UE 社区的丰富视觉和物理资源自由创建多智能体任务，并部署最先进 (SOTA) MARL 算法。平台设计用户友好，包括部署、修改和可视化功能，所有组件均为开源。研究者开发了一个兼容基于规则和学习算法的实验框架，并在示例任务中部署 SOTA 算法进行分析，旨在通过整合现有算法与用户自定义任务推进 MARL 领域的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15947v1",
      "published_date": "2025-03-20 08:40:41 UTC",
      "updated_date": "2025-03-20 08:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:28:22.713014"
    },
    {
      "arxiv_id": "2503.15937v2",
      "title": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Gaole Dai",
        "Shiqi Jiang",
        "Ting Cao",
        "Yuanchun Li",
        "Yuqing Yang",
        "Rui Tan",
        "Mo Li",
        "Lili Qiu"
      ],
      "abstract": "We propose V-Droid, a mobile GUI task automation agent. Unlike previous\nmobile agents that utilize Large Language Models (LLMs) as generators to\ndirectly generate actions at each step, V-Droid employs LLMs as verifiers to\nevaluate candidate actions before making final decisions. To realize this novel\nparadigm, we introduce a comprehensive framework for constructing\nverifier-driven mobile agents: the discretized action space construction\ncoupled with the prefilling-only workflow to accelerate the verification\nprocess, the pair-wise progress preference training to significantly enhance\nthe verifier's decision-making capabilities, and the scalable human-agent joint\nannotation scheme to efficiently collect the necessary data at scale. V-Droid\nsets a new state-of-the-art task success rate across several public mobile task\nautomation benchmarks: 59.5% on AndroidWorld, 38.3% on AndroidLab, and 49% on\nMobileAgentBench, surpassing existing agents by 9.5%, 2.1%, and 9%,\nrespectively. Furthermore, V-Droid achieves an impressively low latency of 0.7\nseconds per step, making it the first mobile agent capable of delivering\nnear-real-time, effective decision-making capabilities.",
      "tldr_zh": "本研究提出 V-Droid，一种基于验证器驱动的移动 GUI 任务自动化代理，使用 LLMs 作为验证器来评估候选动作，而不是直接生成动作，从而提升决策准确性。框架的关键创新包括离散化动作空间构建、预填充工作流、配对进度偏好训练以及可扩展的人-代理联合标注方案，以加速验证过程和数据收集。实验结果显示，V-Droid 在 AndroidWorld、AndroidLab 和 MobileAgentBench 基准上分别达到 59.5%、38.3% 和 49% 的任务成功率，比现有代理高出 9.5%、2.1% 和 9%，并实现了每步仅 0.7 秒的低延迟，支持近实时决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 iterations, refine figs",
      "pdf_url": "http://arxiv.org/pdf/2503.15937v2",
      "published_date": "2025-03-20 08:25:00 UTC",
      "updated_date": "2025-03-21 03:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:28:35.092226"
    },
    {
      "arxiv_id": "2503.15924v1",
      "title": "Towards Automatic Continual Learning: A Self-Adaptive Framework for Continual Instruction Tuning",
      "title_zh": "迈向自动持续学习：一种自适应框架用于持续指令微调",
      "authors": [
        "Peiyi Lin",
        "Fukai Zhang",
        "Kai Niu",
        "Hao Fu"
      ],
      "abstract": "Continual instruction tuning enables large language models (LLMs) to learn\nincrementally while retaining past knowledge, whereas existing methods\nprimarily focus on how to retain old knowledge rather than on selecting which\nnew knowledge to learn. In domain-specific contexts, maintaining data quality\nand managing system constraints remain key challenges. To address these issues,\nwe propose an automated continual instruction tuning framework that dynamically\nfilters incoming data, which identify and reduce redundant data across\nsuccessive updates. Our approach utilizes a small proxy model for efficient\nperplexity-based filtering, and updates the proxy to ensure that the filtering\ncriteria remain aligned with the evolving state of the deployed model. Compared\nto existing static data selection methods, our framework can effectively handle\nincrementally acquired data and shifting distributions. Additionally, it\naddresses practical deployment challenges by enabling seamless model updates,\nsupporting version rollback and incorporating automatic checkpoint evaluation.\nWe evaluated the system in real-world medical scenarios. It reduced\ncomputational costs by 66.7% and improved model performance, and achieved\nautonomous updates, thus demonstrating its effectiveness for automatic\ncontinual instruction tuning.",
      "tldr_zh": "本文提出一个自适应框架，用于自动持续指令微调（Continual Instruction Tuning），帮助大型语言模型（LLMs）动态过滤传入数据以减少冗余，并保留旧知识。该框架利用小型代理模型（proxy model）进行基于困惑度（perplexity-based filtering）的高效数据筛选，并实时更新代理模型以适应模型状态的变化。相比静态方法，该框架能处理增量数据和分布偏移，并在真实医疗场景中减少计算成本66.7%、提升模型性能，并支持无缝更新和版本回滚，实现自主更新。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15924v1",
      "published_date": "2025-03-20 08:00:41 UTC",
      "updated_date": "2025-03-20 08:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:28:46.477880"
    },
    {
      "arxiv_id": "2503.15918v1",
      "title": "Denoising-based Contractive Imitation Learning",
      "title_zh": "基于去噪的收缩模仿学习",
      "authors": [
        "Macheng Shen",
        "Jishen Peng",
        "Zefang Huang"
      ],
      "abstract": "A fundamental challenge in imitation learning is the \\emph{covariate shift}\nproblem. Existing methods to mitigate covariate shift often require additional\nexpert interactions, access to environment dynamics, or complex adversarial\ntraining, which may not be practical in real-world applications. In this paper,\nwe propose a simple yet effective method (DeCIL) to mitigate covariate shift by\nincorporating a denoising mechanism that enhances the contraction properties of\nthe state transition mapping. Our approach involves training two neural\nnetworks: a dynamics model ( f ) that predicts the next state from the current\nstate, and a joint state-action denoising policy network ( d ) that refines\nthis state prediction via denoising and outputs the corresponding action. We\nprovide theoretical analysis showing that the denoising network acts as a local\ncontraction mapping, reducing the error propagation of the state transition and\nimproving stability. Our method is straightforward to implement and can be\neasily integrated with existing imitation learning frameworks without requiring\nadditional expert data or complex modifications to the training procedure.\nEmpirical results demonstrate that our approach effectively improves success\nrate of various imitation learning tasks under noise perturbation.",
      "tldr_zh": "该论文提出了一种名为 DeCIL 的简单有效方法，用于解决模仿学习中的 covariate shift 问题，通过引入去噪机制（denoising mechanism）来增强状态转换映射的收缩属性（contractive properties）。该方法训练两个神经网络：一个动态模型（dynamics model, f）用于预测下一状态，以及一个联合状态-动作去噪策略网络（joint state-action denoising policy network, d），后者通过去噪精炼状态预测并输出相应动作。理论分析表明，去噪网络充当局部收缩映射（local contraction mapping），从而减少错误传播并提高系统稳定性。该方法易于实现，可无缝集成到现有模仿学习框架中，且实证结果显示，在噪声扰动下，它显著提高了各种任务的成功率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15918v1",
      "published_date": "2025-03-20 07:52:19 UTC",
      "updated_date": "2025-03-20 07:52:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:28:58.616475"
    },
    {
      "arxiv_id": "2503.15910v2",
      "title": "No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather",
      "title_zh": "翻译失败",
      "authors": [
        "Junsung Park",
        "Hwijeong Lee",
        "Inha Kang",
        "Hyunjung Shim"
      ],
      "abstract": "Existing domain generalization methods for LiDAR semantic segmentation under\nadverse weather struggle to accurately predict \"things\" categories compared to\n\"stuff\" categories. In typical driving scenes, \"things\" categories can be\ndynamic and associated with higher collision risks, making them crucial for\nsafe navigation and planning. Recognizing the importance of \"things\"\ncategories, we identify their performance drop as a serious bottleneck in\nexisting approaches. We observed that adverse weather induces degradation of\nsemantic-level features and both corruption of local features, leading to a\nmisprediction of \"things\" as \"stuff\". To mitigate these corruptions, we suggest\nour method, NTN - segmeNt Things for No-accident. To address semantic-level\nfeature corruption, we bind each point feature to its superclass, preventing\nthe misprediction of things classes into visually dissimilar categories.\nAdditionally, to enhance robustness against local corruption caused by adverse\nweather, we define each LiDAR beam as a local region and propose a\nregularization term that aligns the clean data with its corrupted counterpart\nin feature space. NTN achieves state-of-the-art performance with a +2.6 mIoU\ngain on the SemanticKITTI-to-SemanticSTF benchmark and +7.9 mIoU on the\nSemanticPOSS-to-SemanticSTF benchmark. Notably, NTN achieves a +4.8 and +7.9\nmIoU improvement on \"things\" classes, respectively, highlighting its\neffectiveness.",
      "tldr_zh": "该论文关注不利天气下 LiDAR 语义分割的鲁棒性问题，指出现有领域泛化方法在预测 \"things\" 类别（如动态物体）时不如 \"stuff\" 类别准确，而 \"things\" 类别因与碰撞风险相关，对安全导航至关重要。作者提出 NTN 方法，包括将点特征绑定到超类以防止语义级特征腐败，以及定义 LiDAR 光束为本地区域并引入正则化项来对齐干净和损坏数据特征，从而提升对不利天气的鲁棒性。实验结果显示，NTN 在 SemanticKITTI-to-SemanticSTF 基准上提升 +2.6 mIoU，在 SemanticPOSS-to-SemanticSTF 上提升 +7.9 mIoU，尤其在 \"things\" 类别上分别提高 +4.8 和 +7.9 mIoU，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, accepted in CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15910v2",
      "published_date": "2025-03-20 07:40:24 UTC",
      "updated_date": "2025-03-24 12:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:29:11.266617"
    },
    {
      "arxiv_id": "2503.15908v1",
      "title": "Enhancing Close-up Novel View Synthesis via Pseudo-labeling",
      "title_zh": "通过伪标签增强特写新视图合成",
      "authors": [
        "Jiatong Xia",
        "Libo Sun",
        "Lingqiao Liu"
      ],
      "abstract": "Recent methods, such as Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS), have demonstrated remarkable capabilities in novel view\nsynthesis. However, despite their success in producing high-quality images for\nviewpoints similar to those seen during training, they struggle when generating\ndetailed images from viewpoints that significantly deviate from the training\nset, particularly in close-up views. The primary challenge stems from the lack\nof specific training data for close-up views, leading to the inability of\ncurrent methods to render these views accurately. To address this issue, we\nintroduce a novel pseudo-label-based learning strategy. This approach leverages\npseudo-labels derived from existing training data to provide targeted\nsupervision across a wide range of close-up viewpoints. Recognizing the absence\nof benchmarks for this specific challenge, we also present a new dataset\ndesigned to assess the effectiveness of both current and future methods in this\narea. Our extensive experiments demonstrate the efficacy of our approach.",
      "tldr_zh": "本文研究发现，现有的新型视图合成方法，如NeRF和3DGS，在生成与训练视图相似的图像时效果出色，但对偏离训练集的近距离(close-up)视图渲染存在挑战，主要由于缺乏特定训练数据。针对这一问题，论文提出了一种基于pseudo-label的学习策略，利用从现有训练数据派生的伪标签来提供针对多种近距离视图的监督训练。此外，作者创建了一个新数据集用于评估这一领域的性能，并通过广泛实验证明了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15908v1",
      "published_date": "2025-03-20 07:27:46 UTC",
      "updated_date": "2025-03-20 07:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:29:21.580063"
    },
    {
      "arxiv_id": "2503.15905v1",
      "title": "Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyuan Wang",
        "Chunyu Lin",
        "Cheng Guan",
        "Lang Nie",
        "Jing He",
        "Haodong Li",
        "Kang Liao",
        "Yao Zhao"
      ],
      "abstract": "In this paper, we propose Jasmine, the first Stable Diffusion (SD)-based\nself-supervised framework for monocular depth estimation, which effectively\nharnesses SD's visual priors to enhance the sharpness and generalization of\nunsupervised prediction. Previous SD-based methods are all supervised since\nadapting diffusion models for dense prediction requires high-precision\nsupervision. In contrast, self-supervised reprojection suffers from inherent\nchallenges (e.g., occlusions, texture-less regions, illumination variance), and\nthe predictions exhibit blurs and artifacts that severely compromise SD's\nlatent priors. To resolve this, we construct a novel surrogate task of hybrid\nimage reconstruction. Without any additional supervision, it preserves the\ndetail priors of SD models by reconstructing the images themselves while\npreventing depth estimation from degradation. Furthermore, to address the\ninherent misalignment between SD's scale and shift invariant estimation and\nself-supervised scale-invariant depth estimation, we build the Scale-Shift GRU.\nIt not only bridges this distribution gap but also isolates the fine-grained\ntexture of SD output against the interference of reprojection loss. Extensive\nexperiments demonstrate that Jasmine achieves SoTA performance on the KITTI\nbenchmark and exhibits superior zero-shot generalization across multiple\ndatasets.",
      "tldr_zh": "本论文提出Jasmine，这是一个基于Stable Diffusion (SD)的自监督单目深度估计框架，利用SD的视觉先验来提升预测的清晰度和泛化能力。通过引入一个新型的混合图像重建代理任务，Jasmine无需额外监督即可保留SD的细节先验，同时防止深度估计退化，并借助Scale-Shift GRU桥接SD输出与自监督估计之间的分布差距。实验结果显示，Jasmine在KITTI基准上达到State-of-the-Art (SoTA)性能，并在多个数据集上展现出色的零样本泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15905v1",
      "published_date": "2025-03-20 07:15:49 UTC",
      "updated_date": "2025-03-20 07:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:29:34.723986"
    },
    {
      "arxiv_id": "2503.15904v1",
      "title": "From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling",
      "title_zh": "翻译失败",
      "authors": [
        "Evan Chen",
        "Run-Jun Zhan",
        "Yan-Bai Lin",
        "Hung-Hsuan Chen"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet concerns persist regarding their tendency to reflect or amplify social\nbiases present in their training data. This study introduces a novel evaluation\nframework to uncover gender biases in LLMs, focusing on their occupational\nnarratives. Unlike previous methods relying on structured scenarios or\ncarefully crafted prompts, our approach leverages free-form storytelling to\nreveal biases embedded in the models. Systematic analyses show an\noverrepresentation of female characters across occupations in six widely used\nLLMs. Additionally, our findings reveal that LLM-generated occupational gender\nrankings align more closely with human stereotypes than actual labor\nstatistics. These insights underscore the need for balanced mitigation\nstrategies to ensure fairness while avoiding the reinforcement of new\nstereotypes.",
      "tldr_zh": "本研究提出了一种新框架，通过开放式叙事来评估大型语言模型 (LLMs) 中的性别偏见，专注于职业叙述，与传统依赖结构化提示的方法不同，该框架利用自由形式的讲故事揭示模型内在偏见。分析结果显示，在六个常用 LLMs 中，女性角色在各种职业中的过度代表，且模型生成的职业性别排名更接近人类刻板印象而非实际劳动力统计数据。这些发现强调了需要采用平衡的缓解策略，以确保模型公平性并避免强化新刻板印象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15904v1",
      "published_date": "2025-03-20 07:15:45 UTC",
      "updated_date": "2025-03-20 07:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:29:45.130090"
    },
    {
      "arxiv_id": "2503.16565v1",
      "title": "Gene42: Long-Range Genomic Foundation Model With Dense Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Vishniakov",
        "Boulbaba Ben Amor",
        "Engin Tekin",
        "Nancy A. ElNaker",
        "Karthik Viswanathan",
        "Aleksandr Medvedev",
        "Aahan Singh",
        "Maryam Nadeem",
        "Mohammad Amaan Sayeed",
        "Praveenkumar Kanithi",
        "Tiago Magalhaes",
        "Natalia Vassilieva",
        "Dwarikanath Mahapatra",
        "Marco Pimentel",
        "and Shadab Khan"
      ],
      "abstract": "We introduce Gene42, a novel family of Genomic Foundation Models (GFMs)\ndesigned to manage context lengths of up to 192,000 base pairs (bp) at a\nsingle-nucleotide resolution. Gene42 models utilize a decoder-only\n(LLaMA-style) architecture with a dense self-attention mechanism. Initially\ntrained on fixed-length sequences of 4,096 bp, our models underwent continuous\npretraining to extend the context length to 192,000 bp. This iterative\nextension allowed for the comprehensive processing of large-scale genomic data\nand the capture of intricate patterns and dependencies within the human genome.\nGene42 is the first dense attention model capable of handling such extensive\nlong context lengths in genomics, challenging state-space models that often\nrely on convolutional operators among other mechanisms. Our pretrained models\nexhibit notably low perplexity values and high reconstruction accuracy,\nhighlighting their strong ability to model genomic data. Extensive experiments\non various genomic benchmarks have demonstrated state-of-the-art performance\nacross multiple tasks, including biotype classification, regulatory region\nidentification, chromatin profiling prediction, variant pathogenicity\nprediction, and species classification. The models are publicly available at\nhuggingface.co/inceptionai.",
      "tldr_zh": "我们引入了 Gene42，一种新型的 Genomic Foundation Models (GFMs)，能够处理高达 192,000 基对 (bp) 的上下文长度，并采用 decoder-only (LLaMA-style) 架构与 dense self-attention 机制，通过从 4,096 bp 逐步扩展的连续预训练来捕获基因组数据的复杂模式。相比依赖卷积操作的 state-space 模型，Gene42 是首个实现此长上下文的 dense attention 模型，并在多个基准任务中表现出 state-of-the-art 性能，包括 biotype classification、regulatory region identification、chromatin profiling prediction、variant pathogenicity prediction 和 species classification，同时实现了低 perplexity 和高 reconstruction accuracy。该模型已在 huggingface.co/inceptionai 上公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16565v1",
      "published_date": "2025-03-20 07:10:04 UTC",
      "updated_date": "2025-03-20 07:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:29:58.863035"
    },
    {
      "arxiv_id": "2503.16563v1",
      "title": "Chem42: a Family of chemical Language Models for Target-aware Ligand Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aahan Singh",
        "Engin Tekin",
        "Maryam Nadeem",
        "Nancy A. ElNaker",
        "Mohammad Amaan Sayeed",
        "Natalia Vassilieva",
        "Boulbaba Ben Amor"
      ],
      "abstract": "Revolutionizing drug discovery demands more than just understanding molecular\ninteractions - it requires generative models that can design novel ligands\ntailored to specific biological targets. While chemical Language Models (cLMs)\nhave made strides in learning molecular properties, most fail to incorporate\ntarget-specific insights, restricting their ability to drive de-novo ligand\ngeneration. Chem42, a cutting-edge family of generative chemical Language\nModels, is designed to bridge this gap. By integrating atomic-level\ninteractions with multimodal inputs from Prot42, a complementary protein\nLanguage Model, Chem42 achieves a sophisticated cross-modal representation of\nmolecular structures, interactions, and binding patterns. This innovative\nframework enables the creation of structurally valid, synthetically accessible\nligands with enhanced target specificity. Evaluations across diverse protein\ntargets confirm that Chem42 surpasses existing approaches in chemical validity,\ntarget-aware design, and predicted binding affinity. By reducing the search\nspace of viable drug candidates, Chem42 could accelerate the drug discovery\npipeline, offering a powerful generative AI tool for precision medicine. Our\nChem42 models set a new benchmark in molecule property prediction, conditional\nmolecule generation, and target-aware ligand design. The models are publicly\navailable at huggingface.co/inceptionai.",
      "tldr_zh": "该论文提出了 Chem42，一系列先进的 chemical Language Models (cLMs)，旨在通过整合原子级交互和 Prot42 蛋白质语言模型的多模态输入，实现针对特定生物目标的 de-novo 配体生成，从而解决现有模型缺乏目标特定见解的问题。Chem42 的创新框架能够创建结构有效、易合成且结合亲和力强的配体，显著缩小药物候选物的搜索空间。实验评估显示，Chem42 在化学有效性、目标感知设计和分子属性预测方面超越现有方法，为加速药物发现和精准医学提供强大生成 AI 工具。该模型已在 huggingface.co/inceptionai 公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16563v1",
      "published_date": "2025-03-20 07:07:30 UTC",
      "updated_date": "2025-03-20 07:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:30:11.270189"
    },
    {
      "arxiv_id": "2503.15901v1",
      "title": "A multi-model approach using XAI and anomaly detection to predict asteroid hazards",
      "title_zh": "翻译失败",
      "authors": [
        "Amit Kumar Mondal",
        "Nafisha Aslam",
        "Prasenjit Maji",
        "Hemanta Kumar Mondal"
      ],
      "abstract": "The potential for catastrophic collision makes near-Earth asteroids (NEAs) a\nserious concern. Planetary defense depends on accurately classifying\npotentially hazardous asteroids (PHAs), however the complexity of the data\nhampers conventional techniques. This work offers a sophisticated method for\naccurately predicting hazards by combining machine learning, deep learning,\nexplainable AI (XAI), and anomaly detection. Our approach extracts essential\nparameters like size, velocity, and trajectory from historical and real-time\nasteroid data. A hybrid algorithm improves prediction accuracy by combining\nseveral cutting-edge models. A forecasting module predicts future asteroid\nbehavior, and Monte Carlo simulations evaluate the likelihood of collisions.\nTimely mitigation is made possible by a real-time alarm system that notifies\nworldwide monitoring stations. This technique enhances planetary defense\nefforts by combining real-time alarms with sophisticated predictive modeling.",
      "tldr_zh": "本文提出了一种多模型方法，利用XAI（可解释AI）和异常检测来预测潜在危险小行星（PHAs），旨在解决传统技术在数据复杂性上的挑战。方法包括从历史和实时数据中提取关键参数如大小、速度和轨迹，结合机器学习、深度学习与混合算法进行预测，并使用Monte Carlo模拟评估碰撞可能性，同时集成实时警报系统通知全球监测站。结果显示，该方法显著提升了预测准确性，并加强了行星防御的及时响应能力。",
      "categories": [
        "astro-ph.EP",
        "astro-ph.IM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "astro-ph.EP",
      "comment": "17 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.15901v1",
      "published_date": "2025-03-20 07:00:01 UTC",
      "updated_date": "2025-03-20 07:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:30:21.949219"
    },
    {
      "arxiv_id": "2503.15890v1",
      "title": "Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do",
      "title_zh": "翻译失败",
      "authors": [
        "Yoav Wald",
        "Mark Goldstein",
        "Yonathan Efroni",
        "Wouter A. C. van Amsterdam",
        "Rajesh Ranganath"
      ],
      "abstract": "Problems in fields such as healthcare, robotics, and finance requires\nreasoning about the value both of what decision or action to take and when to\ntake it. The prevailing hope is that artificial intelligence will support such\ndecisions by estimating the causal effect of policies such as how to treat\npatients or how to allocate resources over time. However, existing methods for\nestimating the effect of a policy struggle with \\emph{irregular time}. They\neither discretize time, or disregard the effect of timing policies. We present\na new deep-Q algorithm that estimates the effect of both when and what to do\ncalled Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for\nthe Q-function that is compatible with flexible sequence models, such as\ntransformers. EDQ provides accurate estimates under standard assumptions. We\nvalidate the approach through experiments on survival time and tumor growth\ntasks.",
      "tldr_zh": "本研究针对医疗、机器人和金融等领域中需要同时考虑“何时决策”（when）和“什么决策”（what）的场景，提出了一种新的Deep-Q算法——Earliest Disagreement Q-Evaluation (EDQ)，用于估计干预措施的因果效应。EDQ通过递归Q函数与灵活序列模型（如transformers）相结合，解决了现有方法在处理不规则时间（irregular time）时的局限性，如时间离散化或忽略时间政策影响。实验在生存时间和肿瘤生长任务上验证了EDQ的准确性，为人工智能辅助决策提供了更可靠的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15890v1",
      "published_date": "2025-03-20 06:27:35 UTC",
      "updated_date": "2025-03-20 06:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:30:33.677105"
    },
    {
      "arxiv_id": "2503.15889v1",
      "title": "LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Cynthia Dong",
        "Hong Jia",
        "Young D. Kwon",
        "Georgios Rizos",
        "Cecilia Mascolo"
      ],
      "abstract": "While there are many advantages to deploying machine learning models on edge\ndevices, the resource constraints of mobile platforms, the dynamic nature of\nthe environment, and differences between the distribution of training versus\nin-the-wild data make such deployments challenging. Current test-time\nadaptation methods are often memory-intensive and not designed to be\nquantization-compatible or deployed on low-resource devices. To address these\nchallenges, we present LeanTTA, a novel backpropagation-free and stateless\nframework for quantized test-time adaptation tailored to edge devices. Our\napproach minimizes computational costs by dynamically updating normalization\nstatistics without backpropagation, which frees LeanTTA from the common pitfall\nof relying on large batches and historical data, making our method robust to\nrealistic deployment scenarios. Our approach is the first to enable further\ncomputational gains by combining partial adaptation with quantized module\nfusion. We validate our framework across sensor modalities, demonstrating\nsignificant improvements over state-of-the-art TTA methods, including a 15.7%\nerror reduction, peak memory usage of only 11.2MB for ResNet18, and fast\nadaptation within an order-of-magnitude of normal inference speeds on-device.\nLeanTTA provides a robust solution for achieving the right trade offs between\naccuracy and system efficiency in edge deployments, addressing the unique\nchallenges posed by limited data and varied operational conditions.",
      "tldr_zh": "这篇论文提出了 LeanTTA，一种无反向传播（Backpropagation-Free）和无状态（Stateless）的框架，针对边缘设备（Edge Devices）上的量化测试时适应（Quantized Test-Time Adaptation），以应对资源限制、环境动态性和数据分布差异等挑战。LeanTTA 通过动态更新归一化统计、结合部分适应和量化模块融合，显著降低了计算成本，而无需依赖大批量或历史数据。实验结果显示，该方法在不同传感器模式下比现有测试时适应（TTA）技术降低了15.7%的错误率，ResNet18 的峰值内存仅为11.2MB，且适应速度接近正常推理速度。该框架为边缘设备部署提供了在准确性和系统效率之间实现平衡的鲁棒解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.15889v1",
      "published_date": "2025-03-20 06:27:09 UTC",
      "updated_date": "2025-03-20 06:27:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:30:47.305387"
    },
    {
      "arxiv_id": "2503.15888v1",
      "title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models",
      "title_zh": "参数 vs. 上下文：语言模型中知识依赖的细粒度控制",
      "authors": [
        "Baolong Bi",
        "Shenghua Liu",
        "Yiwei Wang",
        "Yilong Xu",
        "Junfeng Fang",
        "Lingrui Mei",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large\nLanguage Models (LLMs) by integrating external knowledge. However, conflicts\nbetween parametric knowledge and retrieved context pose challenges,\nparticularly when retrieved information is unreliable or the model's internal\nknowledge is outdated. In such cases, LLMs struggle to determine whether to\nrely more on their own parameters or the conflicted context. To address this,\nwe propose **CK-PLUG**, a plug-and-play method for controlling LLMs' reliance\non parametric and contextual knowledge. We introduce a novel knowledge\nconsistency metric, Confidence Gain, which detects knowledge conflicts by\nmeasuring entropy shifts in token probability distributions after context\ninsertion. CK-PLUG then enables fine-grained control over knowledge preference\nby adjusting the probability distribution of tokens with negative confidence\ngain through a single tuning parameter. Experiments demonstrate CK-PLUG's\nability to significantly regulate knowledge reliance in counterfactual RAG\nscenarios while maintaining generation fluency and knowledge accuracy. For\ninstance, on Llama3-8B, memory recall (MR) of RAG response can be adjusted\nwithin a broad range (9.9%-71.9%), compared to the baseline of 42.1%. Moreover,\nCK-PLUG supports adaptive control based on the model's confidence in both\ninternal and external knowledge, achieving consistent performance improvements\nacross various general RAG tasks. Our code is available at:\n$\\href{https://github.com/byronBBL/CK-PLUG}{\\text{this https URL}}$.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在Retrieval-Augmented Generation (RAG)中处理参数知识与检索上下文冲突的问题，提出了一种即插即用方法CK-PLUG，以实现对知识依赖的细粒度控制。CK-PLUG引入了Confidence Gain指标，通过测量插入上下文后令牌概率分布的熵变化来检测知识冲突，并通过一个调参参数调整负Confidence Gain令牌的概率分布，从而平衡模型对内部参数和外部上下文的依赖。实验结果显示，CK-PLUG在Llama3-8B等模型上显著调节RAG响应的记忆召回率（MR），例如从9.9%调整至71.9%，同时保持生成流畅性和知识准确性，并在各种RAG任务中实现了性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15888v1",
      "published_date": "2025-03-20 06:26:28 UTC",
      "updated_date": "2025-03-20 06:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:30:59.090640"
    },
    {
      "arxiv_id": "2503.15876v1",
      "title": "DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Chen",
        "Zebing Sun"
      ],
      "abstract": "This paper introduces DeepPsy-Agent, an innovative psychological support\nsystem that combines the three-stage helping theory in psychology with deep\nlearning techniques. The system consists of two core components: (1) a\nmulti-stage response-capable dialogue model (\\textit{deeppsy-chat}), which\nenhances reasoning capabilities through stage-awareness and deep-thinking\nanalysis to generate high-quality responses; and (2) a real-time stage\ntransition detection model that identifies contextual shifts to guide the\ndialogue towards more effective intervention stages. Based on 30,000 real\npsychological hotline conversations, we employ AI-simulated dialogues and\nexpert re-annotation strategies to construct a high-quality multi-turn dialogue\ndataset. Experimental results demonstrate that DeepPsy-Agent outperforms\ngeneral-purpose large language models (LLMs) in key metrics such as problem\nexposure completeness, cognitive restructuring success rate, and action\nadoption rate. Ablation studies further validate the effectiveness of\nstage-awareness and deep-thinking modules, showing that stage information\ncontributes 42.3\\% to performance, while the deep-thinking module increases\nroot-cause identification by 58.3\\% and reduces ineffective suggestions by\n72.1\\%. This system addresses critical challenges in AI-based psychological\nsupport through dynamic dialogue management and deep reasoning, advancing\nintelligent mental health services.",
      "tldr_zh": "这篇论文介绍了 DeepPsy-Agent，一种创新的心理支持系统，将心理学的三阶段帮助理论与深度学习技术相结合。该系统包括 deeppsy-chat 对话模型（通过 stage-awareness 和 deep-thinking 分析增强推理能力生成高质量响应）和实时阶段转换检测模型（用于识别上下文变化并引导对话向有效干预阶段过渡）。基于 30,000 个真实心理热线对话构建的高质量数据集，实验结果显示 DeepPsy-Agent 在问题暴露完整性、认知重构成功率和行动采用率等方面优于通用大型语言模型（LLMs）。消融研究进一步证明，stage-awareness 模块贡献 42.3% 性能提升，而 deep-thinking 模块提高了根因识别 58.3% 并减少无效建议 72.1%，从而推进了智能心理健康服务的动态管理和深度推理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15876v1",
      "published_date": "2025-03-20 05:59:29 UTC",
      "updated_date": "2025-03-20 05:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:31:11.216382"
    },
    {
      "arxiv_id": "2503.15867v1",
      "title": "TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Kundu",
        "Athula Balachandran",
        "Amit K. Roy-Chowdhury"
      ],
      "abstract": "Detecting DeepFakes has become a crucial research area as the widespread use\nof AI image generators enables the effortless creation of face-manipulated and\nfully synthetic content, yet existing methods are often limited to binary\nclassification (real vs. fake) and lack interpretability. To address these\nchallenges, we propose TruthLens, a novel and highly generalizable framework\nfor DeepFake detection that not only determines whether an image is real or\nfake but also provides detailed textual reasoning for its predictions. Unlike\ntraditional methods, TruthLens effectively handles both face-manipulated\nDeepFakes and fully AI-generated content while addressing fine-grained queries\nsuch as \"Does the eyes/nose/mouth look real or fake?\"\n  The architecture of TruthLens combines the global contextual understanding of\nmultimodal large language models like PaliGemma2 with the localized feature\nextraction capabilities of vision-only models like DINOv2. This hybrid design\nleverages the complementary strengths of both models, enabling robust detection\nof subtle manipulations while maintaining interpretability. Extensive\nexperiments on diverse datasets demonstrate that TruthLens outperforms\nstate-of-the-art methods in detection accuracy (by 2-14%) and explainability,\nin both in-domain and cross-data settings, generalizing effectively across\ntraditional and emerging manipulation techniques.",
      "tldr_zh": "该研究提出TruthLens，一种可解释的DeepFake检测框架，用于识别面部操纵和完全合成的图像，不仅进行二元分类（真实 vs. 假），还提供详细的文本推理以支持细粒度查询，如“眼睛/鼻子/嘴巴看起来是真实还是假的？”。TruthLens采用混合架构，结合多模态大语言模型（如PaliGemma2）的全局上下文理解和视觉模型（如DINOv2）的局部特征提取，实现对微妙操纵的鲁棒检测和可解释性。实验结果显示，TruthLens在各种数据集上比现有方法提高2-14%的检测准确率，并在同域和跨数据场景中表现出色，具有良好的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15867v1",
      "published_date": "2025-03-20 05:40:42 UTC",
      "updated_date": "2025-03-20 05:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:31:22.403838"
    },
    {
      "arxiv_id": "2503.15865v2",
      "title": "Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement",
      "title_zh": "翻译失败",
      "authors": [
        "Jong-Hyun Jeong",
        "Hongki Jo",
        "Qiang Zhou",
        "Tahsin Afroz Hoque Nishat",
        "Lang Wu"
      ],
      "abstract": "Wireless sensor networks (WSNs) have become a promising solution for\nstructural health monitoring (SHM), especially in hard-to-reach or remote\nlocations. Battery-powered WSNs offer various advantages over wired systems,\nhowever limited battery life has always been one of the biggest obstacles in\npractical use of the WSNs, regardless of energy harvesting methods. While\nvarious methods have been studied for battery health management, existing\nmethods exclusively aim to extend lifetime of individual batteries, lacking a\nsystem level view. A consequence of applying such methods is that batteries in\na WSN tend to fail at different times, posing significant difficulty on\nplanning and scheduling of battery replacement trip. This study investigate a\ndeep reinforcement learning (DRL) method for active battery degradation\nmanagement by optimizing duty cycle of WSNs at the system level. This active\nmanagement strategy effectively reduces earlier failure of battery individuals\nwhich enable group replacement without sacrificing WSN performances. A\nsimulated environment based on a real-world WSN setup was developed to train a\nDRL agent and learn optimal duty cycle strategies. The performance of the\nstrategy was validated in a long-term setup with various network sizes,\ndemonstrating its efficiency and scalability.",
      "tldr_zh": "本研究针对无线传感器网络 (WSNs) 在结构健康监测 (SHM) 中的电池寿命问题，提出了一种使用深度强化学习 (DRL) 的主动电池退化管理策略，以优化 WSNs 的占空比 (duty cycle)，实现系统级管理并支持分组电池更换。不同于现有方法，该策略通过减少个别电池的提前失效，确保电池失败时间更一致，从而简化更换计划，而不影响网络性能。研究基于真实 WSN 设置的模拟环境训练 DRL 代理，并在各种网络规模的长期验证中证明了该策略的有效性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15865v2",
      "published_date": "2025-03-20 05:36:33 UTC",
      "updated_date": "2025-03-22 20:21:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:31:35.167809"
    },
    {
      "arxiv_id": "2503.15855v1",
      "title": "VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hyojun Go",
        "Byeongjun Park",
        "Hyelin Nam",
        "Byung-Hoon Kim",
        "Hyungjin Chung",
        "Changick Kim"
      ],
      "abstract": "We propose VideoRFSplat, a direct text-to-3D model leveraging a video\ngeneration model to generate realistic 3D Gaussian Splatting (3DGS) for\nunbounded real-world scenes. To generate diverse camera poses and unbounded\nspatial extent of real-world scenes, while ensuring generalization to arbitrary\ntext prompts, previous methods fine-tune 2D generative models to jointly model\ncamera poses and multi-view images. However, these methods suffer from\ninstability when extending 2D generative models to joint modeling due to the\nmodality gap, which necessitates additional models to stabilize training and\ninference. In this work, we propose an architecture and a sampling strategy to\njointly model multi-view images and camera poses when fine-tuning a video\ngeneration model. Our core idea is a dual-stream architecture that attaches a\ndedicated pose generation model alongside a pre-trained video generation model\nvia communication blocks, generating multi-view images and camera poses through\nseparate streams. This design reduces interference between the pose and image\nmodalities. Additionally, we propose an asynchronous sampling strategy that\ndenoises camera poses faster than multi-view images, allowing rapidly denoised\nposes to condition multi-view generation, reducing mutual ambiguity and\nenhancing cross-modal consistency. Trained on multiple large-scale real-world\ndatasets (RealEstate10K, MVImgNet, DL3DV-10K, ACID), VideoRFSplat outperforms\nexisting text-to-3D direct generation methods that heavily depend on post-hoc\nrefinement via score distillation sampling, achieving superior results without\nsuch refinement.",
      "tldr_zh": "我们提出 VideoRFSplat，一种直接的文本到-3D Gaussian Splatting 生成模型，利用视频生成模型创建无限场景的现实 3D 表示，同时处理灵活的相机位姿和多视图图像联合建模。核心创新包括双流架构，将专用位姿生成模型与预训练视频生成模型通过通信块连接，减少模态间的干扰；以及异步采样策略，先快速去噪相机位姿再用于条件多视图生成，提升跨模态一致性。该模型在 RealEstate10K、MVImgNet、DL3DV-10K 和 ACID 等大型数据集上训练，性能超越现有文本到-3D 方法，无需后续的 score distillation sampling 优化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://gohyojun15.github.io/VideoRFSplat/",
      "pdf_url": "http://arxiv.org/pdf/2503.15855v1",
      "published_date": "2025-03-20 05:26:09 UTC",
      "updated_date": "2025-03-20 05:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:31:47.301773"
    },
    {
      "arxiv_id": "2503.15848v1",
      "title": "Entropy-based Exploration Conduction for Multi-step Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghan Zhang",
        "Xiting Wang",
        "Fengran Mo",
        "Yeyang Zhou",
        "Wanfu Gao",
        "Kunpeng Liu"
      ],
      "abstract": "In large language model (LLM) reasoning, multi-step processes have proven\neffective for solving complex tasks. However, the depth of exploration can\nsignificantly affect the reasoning performance. Existing methods to\nautomatically decide the depth often bring high costs and lack flexibility, and\nthus undermine the model's reasoning accuracy. To address these issues, we\npropose Entropy-based Exploration Depth Conduction (Entro-duction), a novel\nmethod that dynamically adjusts the exploration depth during multi-step\nreasoning by monitoring LLM's output entropy and variance entropy. We employ\nthese two metrics to capture the model's current uncertainty and the\nfluctuation of uncertainty across consecutive reasoning steps. Based on the\nobserved changes, the LLM selects whether to deepen, expand or stop exploration\naccording to the probability. In this way, we balance the reasoning accuracy\nand exploration effectiveness. Experimental results across four benchmark\ndatasets demonstrate the efficacy of Entro-duction. We further conduct\nexperiments and analysis on the components of Entro-duction to discuss their\ncontributions to reasoning performance.",
      "tldr_zh": "这篇论文针对大型语言模型(LLM)多步推理中探索深度对性能的影响，提出了一种新型方法Entropy-based Exploration Depth Conduction（Entro-duction），以解决现有方法的成本高和灵活性不足问题。该方法通过监控LLM的输出熵(output entropy)和方差熵(variance entropy)来捕捉模型的不确定性和其在连续步骤中的波动，从而动态决定是否加深、扩展或停止探索，以平衡推理准确性和有效性。在四个基准数据集上的实验结果证明了Entro-duction的有效性，并通过组件分析讨论了其对整体推理性能的贡献。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15848v1",
      "published_date": "2025-03-20 05:03:26 UTC",
      "updated_date": "2025-03-20 05:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:31:58.824270"
    },
    {
      "arxiv_id": "2503.15847v1",
      "title": "Beyond Local Selection: Global Cut Selection for Enhanced Mixed-Integer Programming",
      "title_zh": "超越局部选择：全局切平面选择用于增强混合整数规划",
      "authors": [
        "Shuli Zeng",
        "Sijia Zhang",
        "Shaoang Li",
        "Feng Wu",
        "Xiang-Yang Li"
      ],
      "abstract": "In mixed-integer programming (MIP) solvers, cutting planes are essential for\nBranch-and-Cut (B&C) algorithms as they reduce the search space and accelerate\nthe solving process. Traditional methods rely on hard-coded heuristics for cut\nplane selection but fail to leverage problem-specific structural features.\nRecent machine learning approaches use neural networks for cut selection but\nfocus narrowly on the efficiency of single-node within the B&C algorithm,\nwithout considering the broader contextual information. To address this, we\npropose Global Cut Selection (GCS), which uses a bipartite graph to represent\nthe search tree and combines graph neural networks with reinforcement learning\nto develop cut selection strategies. Unlike prior methods, GCS applies cutting\nplanes across all nodes, incorporating richer contextual information.\nExperiments show GCS significantly improves solving efficiency for synthetic\nand large-scale real-world MIPs compared to traditional and learning-based\nmethods.",
      "tldr_zh": "本研究针对混合整数规划 (MIP) 求解器中的切割平面 (cutting planes) 选择问题，指出传统硬编码启发式 (hard-coded heuristics) 和现有机器学习方法仅关注单个节点效率，忽略了更广泛的上下文信息。作者提出 Global Cut Selection (GCS) 方法，使用二分图表示搜索树，并结合图神经网络 (graph neural networks) 和强化学习 (reinforcement learning) 来开发全局切选策略，从而在所有节点上应用切割平面并融入 richer contextual information。实验结果显示，GCS 在合成和大规模真实世界 MIP 实例上显著提升了求解效率，优于传统和基于学习的基线方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15847v1",
      "published_date": "2025-03-20 04:59:18 UTC",
      "updated_date": "2025-03-20 04:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:32:10.718981"
    },
    {
      "arxiv_id": "2503.15837v1",
      "title": "Fùxì: A Benchmark for Evaluating Language Models on Ancient Chinese Text Understanding and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shangqing Zhao",
        "Yuhao Zhou",
        "Yupei Ren",
        "Zhe Chen",
        "Chenghao Jia",
        "Fang Zhe",
        "Zhaogaung Long",
        "Shu Liu",
        "Man Lan"
      ],
      "abstract": "Ancient Chinese text processing presents unique challenges for large language\nmodels (LLMs) due to its distinct linguistic features, complex structural\nconstraints, and rich cultural context. While existing benchmarks have\nprimarily focused on evaluating comprehension through multiple-choice\nquestions, there remains a critical gap in assessing models' generative\ncapabilities in classical Chinese. We introduce F\\`ux\\`i, a comprehensive\nbenchmark that evaluates both understanding and generation capabilities across\n21 diverse tasks. Our benchmark distinguishes itself through three key\ncontributions: (1) balanced coverage of both comprehension and generation\ntasks, including novel tasks like poetry composition and couplet completion,\n(2) specialized evaluation metrics designed specifically for classical Chinese\ntext generation, combining rule-based verification with fine-tuned LLM\nevaluators, and (3) a systematic assessment framework that considers both\nlinguistic accuracy and cultural authenticity. Through extensive evaluation of\nstate-of-the-art LLMs, we reveal significant performance gaps between\nunderstanding and generation tasks, with models achieving promising results in\ncomprehension but struggling considerably in generation tasks, particularly\nthose requiring deep cultural knowledge and adherence to classical formats. Our\nfindings highlight the current limitations in ancient Chinese text processing\nand provide insights for future model development. The benchmark, evaluation\ntoolkit, and baseline results are publicly available to facilitate research in\nthis domain.",
      "tldr_zh": "这篇论文引入了Fùxì基准，用于评估大型语言模型(LLMs)在古汉语文本理解和生成方面的性能，针对古汉语的独特语言特征、复杂结构和文化背景。该基准涵盖21个多样化任务，包括理解（如多选题）和生成（如诗歌创作和对联完成），并提供专属评估指标，如基于规则的验证和微调LLM评估器，以确保语言准确性和文化真实性。通过对先进LLMs的系统评估，研究发现模型在理解任务中表现较好，但在生成任务上存在显著差距，尤其在需要深厚文化知识和古典格式的场景。Fùxì的公开资源和基线结果将促进古汉语文本处理的未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "working in progress",
      "pdf_url": "http://arxiv.org/pdf/2503.15837v1",
      "published_date": "2025-03-20 04:26:40 UTC",
      "updated_date": "2025-03-20 04:26:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:32:23.701817"
    },
    {
      "arxiv_id": "2503.15818v2",
      "title": "Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection",
      "title_zh": "计算高效且识别友好的 3D 点云隐私保护",
      "authors": [
        "Haotian Ma",
        "Lin Gu",
        "Siyi Wu",
        "Yingying Zhu"
      ],
      "abstract": "3D point cloud has been widely used in applications such as self-driving\ncars, robotics, CAD models, etc. To the best of our knowledge, these\napplications raised the issue of privacy leakage in 3D point clouds, which has\nnot been studied well. Different from the 2D image privacy, which is related to\ntexture and 2D geometric structure, the 3D point cloud is texture-less and only\nrelevant to 3D geometric structure. In this work, we defined the 3D point cloud\nprivacy problem and proposed an efficient privacy-preserving framework named\nPointFlowGMM that can support downstream classification and segmentation tasks\nwithout seeing the original data. Using a flow-based generative model, the\npoint cloud is projected into a latent Gaussian mixture distributed subspace.\nWe further designed a novel angular similarity loss to obfuscate the original\ngeometric structure and reduce the model size from 767MB to 120MB without a\ndecrease in recognition performance. The projected point cloud in the latent\nspace is orthogonally rotated randomly to further protect the original\ngeometric structure, the class-to-class relationship is preserved after\nrotation, thus, the protected point cloud can support the recognition task. We\nevaluated our model on multiple datasets and achieved comparable recognition\nresults on encrypted point clouds compared to the original point clouds.",
      "tldr_zh": "本文定义了3D点云在应用如自动驾驶和机器人中的隐私泄露问题，并提出了一种高效的隐私保护框架PointFlowGMM。框架利用flow-based generative model将点云投影到潜在的高斯混合分布子空间，并引入angular similarity loss来混淆原始几何结构，同时将模型大小从767MB减小到120MB，而不影响识别性能。通过在潜在空间进行正交旋转，进一步保护几何结构但保留类间关系，该框架在多个数据集上实现了与原始点云相当的分类和分割任务性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.15818v2",
      "published_date": "2025-03-20 03:09:44 UTC",
      "updated_date": "2025-03-23 19:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:32:34.575204"
    },
    {
      "arxiv_id": "2503.15817v1",
      "title": "Ranking Counterfactual Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Suryani Lim",
        "Henri Prade",
        "Gilles Richard"
      ],
      "abstract": "AI-driven outcomes can be challenging for end-users to understand.\nExplanations can address two key questions: \"Why this outcome?\" (factual) and\n\"Why not another?\" (counterfactual). While substantial efforts have been made\nto formalize factual explanations, a precise and comprehensive study of\ncounterfactual explanations is still lacking. This paper proposes a formal\ndefinition of counterfactual explanations, proving some properties they\nsatisfy, and examining the relationship with factual explanations. Given that\nmultiple counterfactual explanations generally exist for a specific case, we\nalso introduce a rigorous method to rank these counterfactual explanations,\ngoing beyond a simple minimality condition, and to identify the optimal ones.\nOur experiments with 12 real-world datasets highlight that, in most cases, a\nsingle optimal counterfactual explanation emerges. We also demonstrate, via\nthree metrics, that the selected optimal explanation exhibits higher\nrepresentativeness and can explain a broader range of elements than a random\nminimal counterfactual. This result highlights the effectiveness of our\napproach in identifying more robust and comprehensive counterfactual\nexplanations.",
      "tldr_zh": "该论文针对AI决策的解释性问题，提出了一种正式定义和排名反事实性解释(counterfactual explanations)的框架，以回答“为什么不是其他结果？”的问题，同时探讨了其与事实性解释的关系。论文的方法超越简单的最小性条件，通过一个严格的排名机制来识别多个counterfactual explanations中的最优解释。实验在12个真实数据集上表明，大多数情况下只有一个最优解释，且它比随机最小解释具有更高的代表性和更广泛的解释范围，从而证明了该方法的有效性和稳健性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.15817v1",
      "published_date": "2025-03-20 03:04:05 UTC",
      "updated_date": "2025-03-20 03:04:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:32:46.311225"
    },
    {
      "arxiv_id": "2503.15815v1",
      "title": "Attention Pruning: Automated Fairness Repair of Language Models via Surrogate Simulated Annealing",
      "title_zh": "翻译失败",
      "authors": [
        "Vishnu Asutosh Dasu",
        "Md Rafi ur Rashid",
        "Vipul Gupta",
        "Saeid Tizpaz-Niari",
        "Gang Tan"
      ],
      "abstract": "This paper explores pruning attention heads as a post-processing bias\nmitigation method for large language models (LLMs). Modern AI systems such as\nLLMs are expanding into sensitive social contexts where fairness concerns\nbecome especially crucial. Since LLMs develop decision-making patterns by\ntraining on massive datasets of human-generated content, they naturally encode\nand perpetuate societal biases. While modifying training datasets and\nalgorithms is expensive and requires significant resources; post-processing\ntechniques-such as selectively deactivating neurons and attention heads in\npre-trained LLMs-can provide feasible and effective approaches to improve\nfairness. However, identifying the optimal subset of parameters to prune\npresents a combinatorial challenge within LLMs' immense parameter space,\nrequiring solutions that efficiently balance competing objectives across the\nfrontiers of model fairness and utility.\n  To address the computational challenges, we explore a search-based program\nrepair approach via randomized simulated annealing. Given the prohibitive\nevaluation costs in billion-parameter LLMs, we develop surrogate deep neural\nnetworks that efficiently model the relationship between attention head states\n(active/inactive) and their corresponding fairness/utility metrics. This allows\nus to perform optimization over the surrogate models and efficiently identify\noptimal subsets of attention heads for selective pruning rather than directly\nsearching through the LLM parameter space. This paper introduces Attention\nPruning, a fairness-aware surrogate simulated annealing approach to prune\nattention heads in LLMs that disproportionately contribute to bias while\nminimally impacting overall model utility. Our experiments show that Attention\nPruning achieves up to $40\\%$ reduction in gender bias and outperforms the\nstate-of-the-art bias mitigation strategies.",
      "tldr_zh": "这篇论文提出 Attention Pruning，一种基于代理模拟退火(Surrogate Simulated Annealing)的自动化后处理方法，用于修复大型语言模型(LLMs)中的偏见问题。该方法通过修剪对偏见贡献较大的注意力头，同时利用代理深度神经网络模拟注意力头状态与公平性/效用指标的关系，来高效优化参数空间，避免直接搜索带来的计算负担。实验结果显示，Attention Pruning 实现了高达40%的性别偏见减少，并超过了现有偏见缓解策略，在平衡模型公平性和效用方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15815v1",
      "published_date": "2025-03-20 03:02:32 UTC",
      "updated_date": "2025-03-20 03:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:32:59.460489"
    },
    {
      "arxiv_id": "2503.15808v1",
      "title": "ChatGPT and U(X): A Rapid Review on Measuring the User Experience",
      "title_zh": "翻译失败",
      "authors": [
        "Katie Seaborn"
      ],
      "abstract": "ChatGPT, powered by a large language model (LLM), has revolutionized everyday\nhuman-computer interaction (HCI) since its 2022 release. While now used by\nmillions around the world, a coherent pathway for evaluating the user\nexperience (UX) ChatGPT offers remains missing. In this rapid review (N = 58),\nI explored how ChatGPT UX has been approached quantitatively so far. I focused\non the independent variables (IVs) manipulated, the dependent variables (DVs)\nmeasured, and the methods used for measurement. Findings reveal trends, gaps,\nand emerging consensus in UX assessments. This work offers a first step towards\nsynthesizing existing approaches to measuring ChatGPT UX, urgent trajectories\nto advance standardization and breadth, and two preliminary frameworks aimed at\nguiding future research and tool development. I seek to elevate the field of\nChatGPT UX by empowering researchers and practitioners in optimizing user\ninteractions with ChatGPT and similar LLM-based systems.",
      "tldr_zh": "本论文通过快速回顾（N=58）研究了ChatGPT的用户体验（UX）评估方法，焦点在于独立变量（IVs）、因变量（DVs）和测量工具，旨在填补当前UX评估的空白。研究发现揭示了现有评估中的趋势、共识和不足，并提出了两个初步框架以标准化和扩展未来研究。最终，该工作旨在提升ChatGPT及类似LLM系统的人机交互（HCI），为优化用户交互提供指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15808v1",
      "published_date": "2025-03-20 02:51:11 UTC",
      "updated_date": "2025-03-20 02:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:33:11.168205"
    },
    {
      "arxiv_id": "2503.15807v1",
      "title": "Video-VoT-R1: An efficient video inference model integrating image packing and AoE architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Li",
        "Jiexiong Liu",
        "Yixuan Chen",
        "Yanqin Jia"
      ],
      "abstract": "In the field of video-language pretraining, existing models face numerous\nchallenges in terms of inference efficiency and multimodal data processing.\nThis paper proposes a KunLunBaize-VoT-R1 video inference model based on a\nlong-sequence image encoder, along with its training and application methods.\nBy integrating image packing technology, the Autonomy-of-Experts (AoE)\narchitecture, and combining the video of Thought (VoT), a large language model\n(LLM) trained with large-scale reinforcement learning, and multiple training\ntechniques, the efficiency and accuracy of the model in video inference tasks\nare effectively improved. Experiments show that this model performs\noutstandingly in multiple tests, providing a new solution for video-language\nunderstanding.",
      "tldr_zh": "本论文提出了一种高效的视频推理模型 Video-VoT-R1，基于长序列图像编码器，旨在解决视频语言预训练中推理效率和多模态数据处理挑战。模型整合了 image packing 技术、Autonomy-of-Experts (AoE) 架构、video of Thought (VoT) 机制，以及一个通过大规模 reinforcement learning 训练的大型语言模型 (LLM)，并结合多种训练技巧，以显著提升视频推理任务的效率和准确性。实验结果显示，该模型在多个测试中表现出色，为视频语言理解提供了创新解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.15807v1",
      "published_date": "2025-03-20 02:50:57 UTC",
      "updated_date": "2025-03-20 02:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:33:22.488048"
    },
    {
      "arxiv_id": "2503.15796v1",
      "title": "Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlong Zhai",
        "Chunchen Wang",
        "Ruijia Wang",
        "Jiazheng Kang",
        "Shujie Li",
        "Boyu Chen",
        "Tengfei Ma",
        "Zikai Zhou",
        "Cheng Yang",
        "Chuan Shi"
      ],
      "abstract": "Drug-target interaction prediction (DTI) is essential in various applications\nincluding drug discovery and clinical application. There are two perspectives\nof input data widely used in DTI prediction: Intrinsic data represents how\ndrugs or targets are constructed, and extrinsic data represents how drugs or\ntargets are related to other biological entities. However, any of the two\nperspectives of input data can be scarce for some drugs or targets, especially\nfor those unpopular or newly discovered. Furthermore, ground-truth labels for\nspecific interaction types can also be scarce. Therefore, we propose the first\nmethod to tackle DTI prediction under input data and/or label scarcity. To make\nour model functional when only one perspective of input data is available, we\ndesign two separate experts to process intrinsic and extrinsic data\nrespectively and fuse them adaptively according to different samples.\nFurthermore, to make the two perspectives complement each other and remedy\nlabel scarcity, two experts synergize with each other in a mutually supervised\nway to exploit the enormous unlabeled data. Extensive experiments on 3\nreal-world datasets under different extents of input data scarcity and/or label\nscarcity demonstrate our model outperforms states of the art significantly and\nsteadily, with a maximum improvement of 53.53%. We also test our model without\nany data scarcity and it still outperforms current methods.",
      "tldr_zh": "该论文针对数据稀缺的药物-靶点相互作用预测 (DTI) 问题，提出了 Mixture of Synergistic Experts 方法，以处理 Intrinsic data 和 Extrinsic data 的潜在缺失。方法设计两个独立的专家分别处理内在数据和外在数据，并通过自适应融合和相互监督机制，让它们协同利用无标签数据进行互补优化。实验在 3 个真实数据集上证明，该模型在不同程度的输入数据和标签稀缺条件下显著优于现有方法，最大提升 53.53%，即使在无稀缺场景下也保持领先表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15796v1",
      "published_date": "2025-03-20 02:27:16 UTC",
      "updated_date": "2025-03-20 02:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:33:35.605245"
    },
    {
      "arxiv_id": "2503.15783v1",
      "title": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Tsunehiko Tanaka",
        "Edgar Simo-Serra"
      ],
      "abstract": "Game Description Generation (GDG) is the task of generating a game\ndescription written in a Game Description Language (GDL) from natural language\ntext. Previous studies have explored generation methods leveraging the\ncontextual understanding capabilities of Large Language Models (LLMs); however,\naccurately reproducing the game features of the game descriptions remains a\nchallenge. In this paper, we propose reinforcement learning-based fine-tuning\nof LLMs for GDG (RLGDG). Our training method simultaneously improves\ngrammatical correctness and fidelity to game concepts by introducing both\ngrammar rewards and concept rewards. Furthermore, we adopt a two-stage training\nstrategy where Reinforcement Learning (RL) is applied following Supervised\nFine-Tuning (SFT). Experimental results demonstrate that our proposed method\nsignificantly outperforms baseline methods using SFT alone.",
      "tldr_zh": "本研究针对游戏描述生成(GDG)任务，提出了一种基于强化学习(RL)的LLMs微调方法RLGDG，以从自然语言文本生成符合Game Description Language (GDL)的游戏描述。方法通过引入grammar rewards和concept rewards，同时优化语法正确性和游戏概念的忠实度，并采用两阶段训练策略，先进行Supervised Fine-Tuning (SFT)，再应用RL，以解决现有方法在再现游戏特征方面的挑战。实验结果显示，RLGDG显著优于仅使用SFT的基线方法，证明了其在提高GDG准确性和有效性方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15783v1",
      "published_date": "2025-03-20 01:47:33 UTC",
      "updated_date": "2025-03-20 01:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:33:46.158185"
    },
    {
      "arxiv_id": "2503.15779v1",
      "title": "MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxuan Ma",
        "Xishun Liao",
        "Yifan Liu",
        "Qinhua Jiang",
        "Chris Stanford",
        "Shangqing Cao",
        "Jiaqi Ma"
      ],
      "abstract": "Human mobility modeling is critical for urban planning and transportation\nmanagement, yet existing datasets often lack the resolution and semantic\nrichness required for comprehensive analysis. To address this, we proposed a\ncross-domain data fusion framework that integrates multi-modal data of distinct\nnature and spatio-temporal resolution, including geographical, mobility,\nsocio-demographic, and traffic information, to construct a privacy-preserving\nand semantically enriched human travel trajectory dataset. This framework is\ndemonstrated through two case studies in Los Angeles (LA) and Egypt, where a\ndomain adaptation algorithm ensures its transferability across diverse urban\ncontexts. Quantitative evaluation shows that the generated synthetic dataset\naccurately reproduces mobility patterns observed in empirical data. Moreover,\nlarge-scale traffic simulations for LA County based on the generated synthetic\ndemand align well with observed traffic. On California's I-405 corridor, the\nsimulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume\nand 4.36% for speed compared to Caltrans PeMS observations.",
      "tldr_zh": "本研究提出MobiFuse框架，通过cross-domain data fusion整合多模态数据（如地理、移动、社会人口统计和交通信息），构建一个隐私保护且语义丰富的合成人类旅行轨迹数据集，以解决现有数据集的分辨率和丰富性不足问题。该框架利用domain adaptation算法，确保其在洛杉矶和埃及等不同城市环境中的可转移性。实验结果显示，生成的合成数据集准确再现了经验数据中的移动模式，并在洛杉矶县的交通模拟中与实际观察数据高度一致，例如加州I-405走廊的交通量和速度平均绝对百分比误差分别为5.85%和4.36%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15779v1",
      "published_date": "2025-03-20 01:41:28 UTC",
      "updated_date": "2025-03-20 01:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:00.303556"
    },
    {
      "arxiv_id": "2503.15772v2",
      "title": "Detecting LLM-Generated Peer Reviews",
      "title_zh": "检测LLM生成的同行评审",
      "authors": [
        "Vishisht Rao",
        "Aounon Kumar",
        "Himabindu Lakkaraju",
        "Nihar B. Shah"
      ],
      "abstract": "The integrity of peer review is fundamental to scientific progress, but the\nrise of large language models (LLMs) has introduced concerns that some\nreviewers may rely on these tools to generate reviews rather than writing them\nindependently. Although some venues have banned LLM-assisted reviewing,\nenforcement remains difficult as existing detection tools cannot reliably\ndistinguish between fully generated reviews and those merely polished with AI\nassistance. In this work, we address the challenge of detecting LLM-generated\nreviews. We consider the approach of performing indirect prompt injection via\nthe paper's PDF, prompting the LLM to embed a covert watermark in the generated\nreview, and subsequently testing for presence of the watermark in the review.\nWe identify and address several pitfalls in na\\\"ive implementations of this\napproach. Our primary contribution is a rigorous watermarking and detection\nframework that offers strong statistical guarantees. Specifically, we introduce\nwatermarking schemes and hypothesis tests that control the family-wise error\nrate across multiple reviews, achieving higher statistical power than standard\ncorrections such as Bonferroni, while making no assumptions about the nature of\nhuman-written reviews. We explore multiple indirect prompt injection\nstrategies--including font-based embedding and obfuscated prompts--and evaluate\ntheir effectiveness under various reviewer defense scenarios. Our experiments\nfind high success rates in watermark embedding across various LLMs. We also\nempirically find that our approach is resilient to common reviewer defenses,\nand that the bounds on error rates in our statistical tests hold in practice.\nIn contrast, we find that Bonferroni-style corrections are too conservative to\nbe useful in this setting.",
      "tldr_zh": "该论文探讨了检测LLM（大型语言模型）生成同行评审的问题，以应对评审完整性受威胁的挑战，因为现有工具无法可靠区分完全生成的评审和AI辅助内容。研究提出了一种间接prompt injection方法，通过论文PDF嵌入隐蔽watermark，让LLM在生成评审时自动包含水印，并开发了严格的watermarking和检测框架，包括水印方案和假设测试，以控制family-wise error rate并提升统计功效。实验结果显示，该方法在多种LLM和防御场景下实现了高成功率水印嵌入，且对常见防御具有韧性，而Bonferroni-style corrections则过于保守，不够实用。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.DL",
      "comment": "27 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.15772v2",
      "published_date": "2025-03-20 01:11:35 UTC",
      "updated_date": "2025-05-19 01:40:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:11.522120"
    },
    {
      "arxiv_id": "2503.15768v1",
      "title": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandra DeLucia",
        "Mark Dredze"
      ],
      "abstract": "Abstractive multi-document summarization (MDS) is the task of automatically\nsummarizing information in multiple documents, from news articles to\nconversations with multiple speakers. The training approaches for current MDS\nmodels can be grouped into four approaches: end-to-end with special\npre-training (\"direct\"), chunk-then-summarize, extract-then-summarize, and\ninference with GPT-style models. In this work, we evaluate MDS models across\ntraining approaches, domains, and dimensions (reference similarity, quality,\nand factuality), to analyze how and why models trained on one domain can fail\nto summarize documents from another (News, Science, and Conversation) in the\nzero-shot domain transfer setting. We define domain-transfer \"failure\" as a\ndecrease in factuality, higher deviation from the target, and a general\ndecrease in summary quality. In addition to exploring domain transfer for MDS\nmodels, we examine potential issues with applying popular summarization metrics\nout-of-the-box.",
      "tldr_zh": "本研究探讨了抽象多文档摘要（MDS）模型在域转移中的失败问题，评估了基于四种训练方法（端到端特化预训练、chunk-then-summarize、extract-then-summarize 和 GPT-style 推理）的模型在新闻、科学和对话等不同领域下的表现。研究重点分析了零样本域转移设置中，模型从一个领域转移到另一个领域的失败原因，包括事实性降低、摘要与目标偏差增加以及整体质量下降。结果显示，这种失败可能源于模型的领域适应性不足，并质疑了流行摘要指标（如参考相似性评估）在跨域应用时的潜在问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15768v1",
      "published_date": "2025-03-20 00:57:38 UTC",
      "updated_date": "2025-03-20 00:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:22.628152"
    },
    {
      "arxiv_id": "2503.16558v1",
      "title": "Advancing Problem-Based Learning in Biomedical Engineering in the Era of Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Micky C. Nnamdi",
        "J. Ben Tamo",
        "Wenqi Shi",
        "May D. Wang"
      ],
      "abstract": "Problem-Based Learning (PBL) has significantly impacted biomedical\nengineering (BME) education since its introduction in the early 2000s,\neffectively enhancing critical thinking and real-world knowledge application\namong students. With biomedical engineering rapidly converging with artificial\nintelligence (AI), integrating effective AI education into established\ncurricula has become challenging yet increasingly necessary. Recent\nadvancements, including AI's recognition by the 2024 Nobel Prize, have\nhighlighted the importance of training students comprehensively in biomedical\nAI. However, effective biomedical AI education faces substantial obstacles,\nsuch as diverse student backgrounds, limited personalized mentoring,\nconstrained computational resources, and difficulties in safely scaling\nhands-on practical experiments due to privacy and ethical concerns associated\nwith biomedical data. To overcome these issues, we conducted a three-year\n(2021-2023) case study implementing an advanced PBL framework tailored\nspecifically for biomedical AI education, involving 92 undergraduate and 156\ngraduate students from the joint Biomedical Engineering program of Georgia\nInstitute of Technology and Emory University. Our approach emphasizes\ncollaborative, interdisciplinary problem-solving through authentic biomedical\nAI challenges. The implementation led to measurable improvements in learning\noutcomes, evidenced by high research productivity (16 student-authored\npublications), consistently positive peer evaluations, and successful\ndevelopment of innovative computational methods addressing real biomedical\nchallenges. Additionally, we examined the role of generative AI both as a\nteaching subject and an educational support tool within the PBL framework. Our\nstudy presents a practical and scalable roadmap for biomedical engineering\ndepartments aiming to integrate robust AI education into their curricula.",
      "tldr_zh": "本研究探讨了在生成式 AI 时代推进 Problem-Based Learning (PBL) 在 Biomedical Engineering (BME) 教育中的应用，强调了 AI 整合的必要性，以应对学生多样背景、资源限制和生物医学数据隐私伦理等挑战。研究团队开展了为期三年的案例研究（2021-2023），涉及 92 名本科生和 156 名研究生，通过先进的 PBL 框架促进协作式、跨学科问题解决，并将 Generative AI 作为教学主题和支持工具。结果显示，该框架显著提升了学习成果，包括 16 篇学生作者出版物、积极同行评估以及创新计算方法的开发，最终提供了一个实用、可扩展的路线图，帮助 BME 部门强化 AI 教育。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16558v1",
      "published_date": "2025-03-20 00:52:02 UTC",
      "updated_date": "2025-03-20 00:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:36.007035"
    },
    {
      "arxiv_id": "2503.15764v2",
      "title": "Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Xiao",
        "Guangming Shi",
        "Ping Zhang"
      ],
      "abstract": "The promising potential of AI and network convergence in improving networking\nperformance and enabling new service capabilities has recently attracted\nsignificant interest. Existing network AI solutions, while powerful, are mainly\nbuilt based on the close-loop and passive learning framework, resulting in\nmajor limitations in autonomous solution finding and dynamic environmental\nadaptation. Agentic AI has recently been introduced as a promising solution to\naddress the above limitations and pave the way for true generally intelligent\nand beneficial AI systems. The key idea is to create a networking ecosystem to\nsupport a diverse range of autonomous and embodied AI agents in fulfilling\ntheir goals. In this paper, we focus on the novel challenges and requirements\nof agentic AI networking. We propose AgentNet, a novel framework for supporting\ninteraction, collaborative learning, and knowledge transfer among AI agents. We\nintroduce a general architectural framework of AgentNet and then propose a\ngenerative foundation model (GFM)-based implementation in which multiple\nGFM-as-agents have been created as an interactive knowledge-base to bootstrap\nthe development of embodied AI agents according to different task requirements\nand environmental features. We consider two application scenarios,\ndigital-twin-based industrial automation and metaverse-based infotainment\nsystem, to describe how to apply AgentNet for supporting efficient task-driven\ncollaboration and interaction among AI agents.",
      "tldr_zh": "该研究探讨了在6G网络中实现Agentic AI Networking的潜力，旨在解决现有网络AI解决方案的局限性，如被动学习框架导致的自主决策和环境适应不足。论文提出AgentNet框架，支持AI代理之间的交互、协作学习和知识转移，通过Generative Foundation Model (GFM)-as-agent的方法构建交互式知识库，帮助开发适应不同任务和环境的具身AI代理。实验应用场景包括数字孪生工业自动化和元宇宙娱乐系统，展示了AgentNet如何提升任务驱动的协作效率，为智能网络生态系统的构建奠定基础。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Accepted at IEEE Communications Magazine",
      "pdf_url": "http://arxiv.org/pdf/2503.15764v2",
      "published_date": "2025-03-20 00:48:44 UTC",
      "updated_date": "2025-05-11 05:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:46.570243"
    },
    {
      "arxiv_id": "2503.15762v1",
      "title": "Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to Personalized Educational Content Generation",
      "title_zh": "儿童",
      "authors": [
        "Elena Malnatsky",
        "Shenghui Wang",
        "Koen V. Hindriks",
        "Mike E. U. Ligthart"
      ],
      "abstract": "Dialogic learning fosters motivation and deeper understanding in education\nthrough purposeful and structured dialogues. Foundational models offer a\ntransformative potential for child-robot interactions, enabling the design of\npersonalized, engaging, and scalable interactions. However, their integration\ninto educational contexts presents challenges in terms of ensuring\nage-appropriate and safe content and alignment with pedagogical goals. We\nintroduce a hybrid approach to designing personalized educational dialogues in\nchild-robot interactions. By combining rule-based systems with LLMs for\nselective offline content generation and human validation, the framework\nensures educational quality and developmental appropriateness. We illustrate\nthis approach through a project aimed at enhancing reading motivation, in which\na robot facilitated book-related dialogues.",
      "tldr_zh": "该研究探讨了Dialogic Learning在儿童-机器人互动中的应用，旨在通过结构化对话提升教育动机和理解深度。论文提出了一种混合方法，将基于规则的系统与LLMs结合，用于选择性的离线内容生成，并通过人工验证确保内容适合年龄、教育质量和安全性。该方法通过一个提升阅读动机的项目进行展示，其中机器人引导书籍相关对话，展示了其在个性化教育中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15762v1",
      "published_date": "2025-03-20 00:46:10 UTC",
      "updated_date": "2025-03-20 00:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:34:58.114991"
    },
    {
      "arxiv_id": "2503.15758v1",
      "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism",
      "title_zh": "ATTENTION2D：通信高效的分布式自注意力机制",
      "authors": [
        "Venmugil Elango"
      ],
      "abstract": "Transformer-based models have emerged as a leading architecture for natural\nlanguage processing, natural language generation, and image generation tasks. A\nfundamental element of the transformer architecture is self-attention, which\nallows the model to capture intricate dependencies within the data. However,\nthe self-attention mechanism also incurs significant computational and memory\ncosts, particularly for long sequences.\n  In this paper, we introduce ATTENTION2D, a novel approach that exploits\nparallelism along two dimensions - query and key/value - of the self-attention\noperation. This method enables efficient distribution and parallelization of\ncomputations across multiple devices. Our approach facilitates asymptotically\nfaster training and inference phases compared to previous methods, without\nrelying on approximations or incurring additional computational or memory\noverheads. Furthermore, unlike existing techniques that struggle to scale with\nan increasing number of processing units, our approach effectively scales with\nadditional processing units.\n  Our experimental results confirm the effectiveness of our method in improving\ncommunication efficiency and scalability. Compared to Ring Attention, our\napproach demonstrated up to a 5x performance boost on a GPT-3-like model using\n64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64\nNVIDIA H100 GPUs across 64 nodes.",
      "tldr_zh": "这篇论文介绍了 ATTENTION2D，一种通信高效的分布式自注意力机制，旨在解决 Transformer 模型在处理长序列时的高计算和内存成本问题。ATTENTION2D 通过在查询和键/值两个维度上利用并行性，实现高效的分布计算和可扩展性，而无需近似或额外开销。实验结果显示，与 Ring Attention 相比，该方法在 GPT-3 类似模型上，使用 64 个 NVIDIA A100 GPU 跨 16 节点时性能提升高达 5 倍，使用 64 个 NVIDIA H100 GPU 跨 64 节点时提升高达 9.4 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15758v1",
      "published_date": "2025-03-20 00:25:44 UTC",
      "updated_date": "2025-03-20 00:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:35:11.903074"
    },
    {
      "arxiv_id": "2503.15754v1",
      "title": "AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Andy Zhou",
        "Kevin Wu",
        "Francesco Pinto",
        "Zhaorun Chen",
        "Yi Zeng",
        "Yu Yang",
        "Shuang Yang",
        "Sanmi Koyejo",
        "James Zou",
        "Bo Li"
      ],
      "abstract": "As large language models (LLMs) become increasingly capable, security and\nsafety evaluation are crucial. While current red teaming approaches have made\nstrides in assessing LLM vulnerabilities, they often rely heavily on human\ninput and lack comprehensive coverage of emerging attack vectors. This paper\nintroduces AutoRedTeamer, a novel framework for fully automated, end-to-end red\nteaming against LLMs. AutoRedTeamer combines a multi-agent architecture with a\nmemory-guided attack selection mechanism to enable continuous discovery and\nintegration of new attack vectors. The dual-agent framework consists of a red\nteaming agent that can operate from high-level risk categories alone to\ngenerate and execute test cases and a strategy proposer agent that autonomously\ndiscovers and implements new attacks by analyzing recent research. This modular\ndesign allows AutoRedTeamer to adapt to emerging threats while maintaining\nstrong performance on existing attack vectors. We demonstrate AutoRedTeamer's\neffectiveness across diverse evaluation settings, achieving 20% higher attack\nsuccess rates on HarmBench against Llama-3.1-70B while reducing computational\ncosts by 46% compared to existing approaches. AutoRedTeamer also matches the\ndiversity of human-curated benchmarks in generating test cases, providing a\ncomprehensive, scalable, and continuously evolving framework for evaluating the\nsecurity of AI systems.",
      "tldr_zh": "本研究提出AutoRedTeamer，一种自主红队框架，用于评估大型语言模型(LLMs)的安全性和漏洞，通过多智能体架构和记忆引导攻击选择机制实现持续发现与整合新攻击向量。框架包括红队代理（从高层风险类别生成测试用例）和策略提出者代理（分析最新研究自主实现新攻击），使其能适应新兴威胁同时保持现有攻击性能。实验结果显示，AutoRedTeamer在HarmBench上针对Llama-3.1-70B的攻击成功率提高20%，计算成本降低46%，并与人类策划基准相当，提供了一个全面、可扩展且持续演化的AI安全评估工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15754v1",
      "published_date": "2025-03-20 00:13:04 UTC",
      "updated_date": "2025-03-20 00:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:35:22.728297"
    },
    {
      "arxiv_id": "2503.15752v4",
      "title": "Using Language Models to Decipher the Motivation Behind Human Behaviors",
      "title_zh": "使用语言模型解读人类行为的动机",
      "authors": [
        "Yutong Xie",
        "Qiaozhu Mei",
        "Walter Yuan",
        "Matthew O. Jackson"
      ],
      "abstract": "AI presents a novel tool for deciphering the motivations behind human\nbehaviors. By varying prompts to a large language model, we can elicit the full\nrange of human behaviors in a variety of different scenarios in classic\neconomic games. By analyzing which prompts elicit which behaviors, we infer\n(decipher) the motivations behind the human behaviors. We also show how one can\nanalyze the prompts to reveal relationships between the classic economic games,\nproviding insight into what different economic scenarios induce people to think\nabout. We also show how this deciphering process can be used to understand\ndifferences in the behavioral tendencies of different populations. We show how\nAI offers a new way to examine the thinking and framing that produce different\nbehaviors.",
      "tldr_zh": "本研究利用语言 models 通过改变 prompts 来分析人类行为背后的动机。在经典 economic games 的各种场景中，研究者通过诱发不同行为并分析相应的 prompts，推断出这些行为可能的原因，并揭示 economic games 之间的关系。该方法还可用于比较不同人群的行为倾向，最终证明 AI 提供了一种创新途径，深入考察产生不同行为的思考和框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15752v4",
      "published_date": "2025-03-20 00:07:06 UTC",
      "updated_date": "2025-05-11 20:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T04:35:34.170146"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 123,
  "processed_papers_count": 123,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T04:35:52.381886"
}