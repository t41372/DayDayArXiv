[
  {
    "arxiv_id": "2504.03671v1",
    "title": "HiAER-Spike: Hardware-Software Co-Design for Large-Scale Reconfigurable Event-Driven Neuromorphic Computing",
    "authors": [
      "Gwenevere Frank",
      "Gopabandhu Hota",
      "Keli Wang",
      "Abhinav Uppal",
      "Omowuyi Olajide",
      "Kenneth Yoshimoto",
      "Leif Gibb",
      "Qingbo Wang",
      "Johannes Leugering",
      "Stephen Deiss",
      "Gert Cauwenberghs"
    ],
    "abstract": "In this work, we present HiAER-Spike, a modular, reconfigurable, event-driven\nneuromorphic computing platform designed to execute large spiking neural\nnetworks with up to 160 million neurons and 40 billion synapses - roughly twice\nthe neurons of a mouse brain at faster-than real-time. This system, which is\ncurrently under construction at the UC San Diego Supercomputing Center,\ncomprises a co-designed hard- and software stack that is optimized for run-time\nmassively parallel processing and hierarchical address-event routing (HiAER) of\nspikes while promoting memory-efficient network storage and execution. Our\narchitecture efficiently handles both sparse connectivity and sparse activity\nfor robust and low-latency event-driven inference for both edge and cloud\ncomputing. A Python programming interface to HiAER-Spike, agnostic to\nhardware-level detail, shields the user from complexity in the configuration\nand execution of general spiking neural networks with virtually no constraints\nin topology. The system is made easily available over a web portal for use by\nthe wider community. In the following we provide an overview of the hard- and\nsoftware stack, explain the underlying design principles, demonstrate some of\nthe system's capabilities and solicit feedback from the broader neuromorphic\ncommunity.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.NE",
    "comment": "IEEE International Conference on Rebooting Computing (ICRC) 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.03671v1",
    "published_date": "2025-03-20 23:54:33 UTC",
    "updated_date": "2025-03-20 23:54:33 UTC"
  },
  {
    "arxiv_id": "2503.16743v3",
    "title": "SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability",
    "authors": [
      "Alberto Hernández-Espinosa",
      "Luan Ozelim",
      "Felipe S. Abrahão",
      "Hector Zenil"
    ],
    "abstract": "We introduce an open-ended test grounded in algorithmic probability that can\navoid benchmark contamination in the quantitative evaluation of frontier models\nin the context of their Artificial General Intelligence (AGI) and\nSuperintelligence (ASI) claims. Unlike other tests, this test does not rely on\nstatistical compression methods (such as GZIP or LZW), which are more closely\nrelated to Shannon entropy than to Kolmogorov complexity and are not able to\ntest beyond simple pattern matching. The test challenges aspects of AI, in\nparticular LLMs, related to features of intelligence of fundamental nature such\nas synthesis and model creation in the context of inverse problems (generating\nnew knowledge from observation). We argue that metrics based on model\nabstraction and abduction (optimal Bayesian `inference') for predictive\n`planning' can provide a robust framework for testing intelligence, including\nnatural intelligence (human and animal), narrow AI, AGI, and ASI. We found that\nLLM model versions tend to be fragile and incremental as a result of\nmemorisation only with progress likely driven by the size of training data. The\nresults were compared with a hybrid neurosymbolic approach that theoretically\nguarantees universal intelligence based on the principles of algorithmic\nprobability and Kolmogorov complexity. The method outperforms LLMs in a\nproof-of-concept on short binary sequences. We prove that compression is\nequivalent and directly proportional to a system's predictive power and vice\nversa. That is, if a system can better predict it can better compress, and if\nit can better compress, then it can better predict. Our findings strengthen the\nsuspicion regarding the fundamental limitations of LLMs, exposing them as\nsystems optimised for the perception of mastery over human language.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "51 pages + Technical Supplementary Information, 79 pages total",
    "pdf_url": "http://arxiv.org/pdf/2503.16743v3",
    "published_date": "2025-03-20 23:11:30 UTC",
    "updated_date": "2025-04-22 22:30:20 UTC"
  },
  {
    "arxiv_id": "2503.22708v1",
    "title": "CodeScientist: End-to-End Semi-Automated Scientific Discovery with Code-based Experimentation",
    "authors": [
      "Peter Jansen",
      "Oyvind Tafjord",
      "Marissa Radensky",
      "Pao Siangliulue",
      "Tom Hope",
      "Bhavana Dalvi Mishra",
      "Bodhisattwa Prasad Majumder",
      "Daniel S. Weld",
      "Peter Clark"
    ],
    "abstract": "Despite the surge of interest in autonomous scientific discovery (ASD) of\nsoftware artifacts (e.g., improved ML algorithms), current ASD systems face two\nkey limitations: (1) they largely explore variants of existing codebases or\nsimilarly constrained design spaces, and (2) they produce large volumes of\nresearch artifacts (such as automatically generated papers and code) that are\ntypically evaluated using conference-style paper review with limited evaluation\nof code. In this work we introduce CodeScientist, a novel ASD system that\nframes ideation and experiment construction as a form of genetic search jointly\nover combinations of research articles and codeblocks defining common actions\nin a domain (like prompting a language model). We use this paradigm to conduct\nhundreds of automated experiments on machine-generated ideas broadly in the\ndomain of agents and virtual environments, with the system returning 19\ndiscoveries, 6 of which were judged as being both at least minimally sound and\nincrementally novel after a multi-faceted evaluation beyond that typically\nconducted in prior work, including external (conference-style) review, code\nreview, and replication attempts. Moreover, the discoveries span new tasks,\nagents, metrics, and data, suggesting a qualitative shift from benchmark\noptimization to broader discoveries.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "98 Pages (13 pages: main paper body; 85 pages: appendix)",
    "pdf_url": "http://arxiv.org/pdf/2503.22708v1",
    "published_date": "2025-03-20 22:37:17 UTC",
    "updated_date": "2025-03-20 22:37:17 UTC"
  },
  {
    "arxiv_id": "2503.16734v1",
    "title": "Towards Agentic Recommender Systems in the Era of Multimodal Large Language Models",
    "authors": [
      "Chengkai Huang",
      "Junda Wu",
      "Yu Xia",
      "Zixu Yu",
      "Ruhan Wang",
      "Tong Yu",
      "Ruiyi Zhang",
      "Ryan A. Rossi",
      "Branislav Kveton",
      "Dongruo Zhou",
      "Julian McAuley",
      "Lina Yao"
    ],
    "abstract": "Recent breakthroughs in Large Language Models (LLMs) have led to the\nemergence of agentic AI systems that extend beyond the capabilities of\nstandalone models. By empowering LLMs to perceive external environments,\nintegrate multimodal information, and interact with various tools, these\nagentic systems exhibit greater autonomy and adaptability across complex tasks.\nThis evolution brings new opportunities to recommender systems (RS): LLM-based\nAgentic RS (LLM-ARS) can offer more interactive, context-aware, and proactive\nrecommendations, potentially reshaping the user experience and broadening the\napplication scope of RS. Despite promising early results, fundamental\nchallenges remain, including how to effectively incorporate external knowledge,\nbalance autonomy with controllability, and evaluate performance in dynamic,\nmultimodal settings. In this perspective paper, we first present a systematic\nanalysis of LLM-ARS: (1) clarifying core concepts and architectures; (2)\nhighlighting how agentic capabilities -- such as planning, memory, and\nmultimodal reasoning -- can enhance recommendation quality; and (3) outlining\nkey research questions in areas such as safety, efficiency, and lifelong\npersonalization. We also discuss open problems and future directions, arguing\nthat LLM-ARS will drive the next wave of RS innovation. Ultimately, we foresee\na paradigm shift toward intelligent, autonomous, and collaborative\nrecommendation experiences that more closely align with users' evolving needs\nand complex decision-making processes.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16734v1",
    "published_date": "2025-03-20 22:37:15 UTC",
    "updated_date": "2025-03-20 22:37:15 UTC"
  },
  {
    "arxiv_id": "2503.16724v1",
    "title": "Towards Automated Semantic Interpretability in Reinforcement Learning via Vision-Language Models",
    "authors": [
      "Zhaoxin Li",
      "Zhang Xi-Jia",
      "Batuhan Altundas",
      "Letian Chen",
      "Rohan Paleja",
      "Matthew Gombolay"
    ],
    "abstract": "Semantic Interpretability in Reinforcement Learning (RL) enables\ntransparency, accountability, and safer deployment by making the agent's\ndecisions understandable and verifiable. Achieving this, however, requires a\nfeature space composed of human-understandable concepts, which traditionally\nrely on human specification and fail to generalize to unseen environments. In\nthis work, we introduce Semantically Interpretable Reinforcement Learning with\nVision-Language Models Empowered Automation (SILVA), an automated framework\nthat leverages pre-trained vision-language models (VLM) for semantic feature\nextraction and interpretable tree-based models for policy optimization. SILVA\nfirst queries a VLM to identify relevant semantic features for an unseen\nenvironment, then extracts these features from the environment. Finally, it\ntrains an Interpretable Control Tree via RL, mapping the extracted features to\nactions in a transparent and interpretable manner. To address the computational\ninefficiency of extracting features directly with VLMs, we develop a feature\nextraction pipeline that generates a dataset for training a lightweight\nconvolutional network, which is subsequently used during RL. By leveraging VLMs\nto automate tree-based RL, SILVA removes the reliance on human annotation\npreviously required by interpretable models while also overcoming the inability\nof VLMs alone to generate valid robot policies, enabling semantically\ninterpretable reinforcement learning without human-in-the-loop.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16724v1",
    "published_date": "2025-03-20 21:53:19 UTC",
    "updated_date": "2025-03-20 21:53:19 UTC"
  },
  {
    "arxiv_id": "2503.17410v1",
    "title": "Comparative Analysis of Deep Learning Models for Real-World ISP Network Traffic Forecasting",
    "authors": [
      "Josef Koumar",
      "Timotej Smoleň",
      "Kamil Jeřábek",
      "Tomáš Čejka"
    ],
    "abstract": "Accurate network traffic forecasting is essential for Internet Service\nProviders (ISP) to optimize resources, enhance user experience, and mitigate\nanomalies. This study evaluates state-of-the-art deep learning models on\nCESNET-TimeSeries24, a recently published, comprehensive real-world network\ntraffic dataset from the ISP network CESNET3 spanning multivariate time series\nover 40 weeks. Our findings highlight the balance between prediction accuracy\nand computational efficiency across different levels of network granularity.\nAdditionally, this work establishes a reproducible methodology that facilitates\ndirect comparison of existing approaches, explores their strengths and\nweaknesses, and provides a benchmark for future studies using this dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17410v1",
    "published_date": "2025-03-20 21:04:20 UTC",
    "updated_date": "2025-03-20 21:04:20 UTC"
  },
  {
    "arxiv_id": "2503.16709v1",
    "title": "QuartDepth: Post-Training Quantization for Real-Time Depth Estimation on the Edge",
    "authors": [
      "Xuan Shen",
      "Weize Ma",
      "Jing Liu",
      "Changdi Yang",
      "Rui Ding",
      "Quanyi Wang",
      "Henghui Ding",
      "Wei Niu",
      "Yanzhi Wang",
      "Pu Zhao",
      "Jun Lin",
      "Jiuxiang Gu"
    ],
    "abstract": "Monocular Depth Estimation (MDE) has emerged as a pivotal task in computer\nvision, supporting numerous real-world applications. However, deploying\naccurate depth estimation models on resource-limited edge devices, especially\nApplication-Specific Integrated Circuits (ASICs), is challenging due to the\nhigh computational and memory demands. Recent advancements in foundational\ndepth estimation deliver impressive results but further amplify the difficulty\nof deployment on ASICs. To address this, we propose QuartDepth which adopts\npost-training quantization to quantize MDE models with hardware accelerations\nfor ASICs. Our approach involves quantizing both weights and activations to\n4-bit precision, reducing the model size and computation cost. To mitigate the\nperformance degradation, we introduce activation polishing and compensation\nalgorithm applied before and after activation quantization, as well as a weight\nreconstruction method for minimizing errors in weight quantization.\nFurthermore, we design a flexible and programmable hardware accelerator by\nsupporting kernel fusion and customized instruction programmability, enhancing\nthroughput and efficiency. Experimental results demonstrate that our framework\nachieves competitive accuracy while enabling fast inference and higher energy\nefficiency on ASICs, bridging the gap between high-performance depth estimation\nand practical edge-device applicability. Code:\nhttps://github.com/shawnricecake/quart-depth",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16709v1",
    "published_date": "2025-03-20 21:03:10 UTC",
    "updated_date": "2025-03-20 21:03:10 UTC"
  },
  {
    "arxiv_id": "2503.16692v2",
    "title": "Limits of trust in medical AI",
    "authors": [
      "Joshua Hatherley"
    ],
    "abstract": "Artificial intelligence (AI) is expected to revolutionize the practice of\nmedicine. Recent advancements in the field of deep learning have demonstrated\nsuccess in a variety of clinical tasks: detecting diabetic retinopathy from\nimages, predicting hospital readmissions, aiding in the discovery of new drugs,\netc. AI's progress in medicine, however, has led to concerns regarding the\npotential effects of this technology upon relationships of trust in clinical\npractice. In this paper, I will argue that there is merit to these concerns,\nsince AI systems can be relied upon, and are capable of reliability, but cannot\nbe trusted, and are not capable of trustworthiness. Insofar as patients are\nrequired to rely upon AI systems for their medical decision-making, there is\npotential for this to produce a deficit of trust in relationships in clinical\npractice.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16692v2",
    "published_date": "2025-03-20 20:22:38 UTC",
    "updated_date": "2025-04-03 13:03:18 UTC"
  },
  {
    "arxiv_id": "2503.16683v1",
    "title": "GAIR: Improving Multimodal Geo-Foundation Model with Geo-Aligned Implicit Representations",
    "authors": [
      "Zeping Liu",
      "Fan Zhang",
      "Junfeng Jiao",
      "Ni Lao",
      "Gengchen Mai"
    ],
    "abstract": "Advancements in vision and language foundation models have inspired the\ndevelopment of geo-foundation models (GeoFMs), enhancing performance across\ndiverse geospatial tasks. However, many existing GeoFMs primarily focus on\noverhead remote sensing (RS) data while neglecting other data modalities such\nas ground-level imagery. A key challenge in multimodal GeoFM development is to\nexplicitly model geospatial relationships across modalities, which enables\ngeneralizability across tasks, spatial scales, and temporal contexts. To\naddress these limitations, we propose GAIR, a novel multimodal GeoFM\narchitecture integrating overhead RS data, street view (SV) imagery, and their\ngeolocation metadata. We utilize three factorized neural encoders to project an\nSV image, its geolocation, and an RS image into the embedding space. The SV\nimage needs to be located within the RS image's spatial footprint but does not\nneed to be at its geographic center. In order to geographically align the SV\nimage and RS image, we propose a novel implicit neural representations (INR)\nmodule that learns a continuous RS image representation and looks up the RS\nembedding at the SV image's geolocation. Next, these geographically aligned SV\nembedding, RS embedding, and location embedding are trained with contrastive\nlearning objectives from unlabeled data. We evaluate GAIR across 10 geospatial\ntasks spanning RS image-based, SV image-based, and location embedding-based\nbenchmarks. Experimental results demonstrate that GAIR outperforms\nstate-of-the-art GeoFMs and other strong baselines, highlighting its\neffectiveness in learning generalizable and transferable geospatial\nrepresentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.10"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16683v1",
    "published_date": "2025-03-20 19:59:39 UTC",
    "updated_date": "2025-03-20 19:59:39 UTC"
  },
  {
    "arxiv_id": "2503.16681v2",
    "title": "GauRast: Enhancing GPU Triangle Rasterizers to Accelerate 3D Gaussian Splatting",
    "authors": [
      "Sixu Li",
      "Ben Keller",
      "Yingyan Celine Lin",
      "Brucek Khailany"
    ],
    "abstract": "3D intelligence leverages rich 3D features and stands as a promising frontier\nin AI, with 3D rendering fundamental to many downstream applications. 3D\nGaussian Splatting (3DGS), an emerging high-quality 3D rendering method,\nrequires significant computation, making real-time execution on existing\nGPU-equipped edge devices infeasible. Previous efforts to accelerate 3DGS rely\non dedicated accelerators that require substantial integration overhead and\nhardware costs. This work proposes an acceleration strategy that leverages the\nsimilarities between the 3DGS pipeline and the highly optimized conventional\ngraphics pipeline in modern GPUs. Instead of developing a dedicated\naccelerator, we enhance existing GPU rasterizer hardware to efficiently support\n3DGS operations. Our results demonstrate a 23$\\times$ increase in processing\nspeed and a 24$\\times$ reduction in energy consumption, with improvements\nyielding 6$\\times$ faster end-to-end runtime for the original 3DGS algorithm\nand 4$\\times$ for the latest efficiency-improved pipeline, achieving 24 FPS and\n46 FPS respectively. These enhancements incur only a minimal area overhead of\n0.2\\% relative to the entire SoC chip area, underscoring the practicality and\nefficiency of our approach for enabling 3DGS rendering on resource-constrained\nplatforms.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.GR",
    "comment": "DAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16681v2",
    "published_date": "2025-03-20 19:54:05 UTC",
    "updated_date": "2025-04-10 19:43:24 UTC"
  },
  {
    "arxiv_id": "2503.16679v1",
    "title": "Echoes of Power: Investigating Geopolitical Bias in US and China Large Language Models",
    "authors": [
      "Andre G. C. Pacheco",
      "Athus Cavalini",
      "Giovanni Comarela"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\nhuman-like text, transforming human-machine interactions. However, their\nwidespread adoption has raised concerns about their potential to influence\npublic opinion and shape political narratives. In this work, we investigate the\ngeopolitical biases in US and Chinese LLMs, focusing on how these models\nrespond to questions related to geopolitics and international relations. We\ncollected responses from ChatGPT and DeepSeek to a set of geopolitical\nquestions and evaluated their outputs through both qualitative and quantitative\nanalyses. Our findings show notable biases in both models, reflecting distinct\nideological perspectives and cultural influences. However, despite these\nbiases, for a set of questions, the models' responses are more aligned than\nexpected, indicating that they can address sensitive topics without necessarily\npresenting directly opposing viewpoints. This study highlights the potential of\nLLMs to shape public discourse and underscores the importance of critically\nassessing AI-generated content, particularly in politically sensitive contexts.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16679v1",
    "published_date": "2025-03-20 19:53:10 UTC",
    "updated_date": "2025-03-20 19:53:10 UTC"
  },
  {
    "arxiv_id": "2503.16672v1",
    "title": "Accelerating Transformer Inference and Training with 2:4 Activation Sparsity",
    "authors": [
      "Daniel Haziza",
      "Timothy Chou",
      "Dhruv Choudhary",
      "Luca Wehrstedt",
      "Francisco Massa",
      "Jiecao Yu",
      "Geonhwa Jeong",
      "Supriya Rao",
      "Patrick Labatut",
      "Jesse Cai"
    ],
    "abstract": "In this paper, we demonstrate how to leverage 2:4 sparsity, a popular\nhardware-accelerated GPU sparsity pattern, to activations to accelerate large\nlanguage model training and inference. Crucially we exploit the intrinsic\nsparsity found in Squared-ReLU activations to provide this acceleration with no\naccuracy loss. Our approach achieves up to 1.3x faster Feed Forward Network\n(FFNs) in both the forwards and backwards pass. This work highlights the\npotential for sparsity to play a key role in accelerating large language model\ntraining and inference.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16672v1",
    "published_date": "2025-03-20 19:37:12 UTC",
    "updated_date": "2025-03-20 19:37:12 UTC"
  },
  {
    "arxiv_id": "2503.17408v1",
    "title": "Leveraging OpenFlamingo for Multimodal Embedding Analysis of C2C Car Parts Data",
    "authors": [
      "Maisha Binte Rashid",
      "Pablo Rivas"
    ],
    "abstract": "In this paper, we aim to investigate the capabilities of multimodal machine\nlearning models, particularly the OpenFlamingo model, in processing a\nlarge-scale dataset of consumer-to-consumer (C2C) online posts related to car\nparts. We have collected data from two platforms, OfferUp and Craigslist,\nresulting in a dataset of over 1.2 million posts with their corresponding\nimages. The OpenFlamingo model was used to extract embeddings for the text and\nimage of each post. We used $k$-means clustering on the joint embeddings to\nidentify underlying patterns and commonalities among the posts. We have found\nthat most clusters contain a pattern, but some clusters showed no internal\npatterns. The results provide insight into the fact that OpenFlamingo can be\nused for finding patterns in large datasets but needs some modification in the\narchitecture according to the dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.10; I.2.7; I.5; H.3.3; H.3.1"
    ],
    "primary_category": "cs.LG",
    "comment": "The 26th International Conference on Artificial Intelligence\n  (ICAI'24: July 22-25, 2024; Las Vegas, USA)",
    "pdf_url": "http://arxiv.org/pdf/2503.17408v1",
    "published_date": "2025-03-20 19:35:15 UTC",
    "updated_date": "2025-03-20 19:35:15 UTC"
  },
  {
    "arxiv_id": "2503.16669v1",
    "title": "Aligning Text-to-Music Evaluation with Human Preferences",
    "authors": [
      "Yichen Huang",
      "Zachary Novack",
      "Koichi Saito",
      "Jiatong Shi",
      "Shinji Watanabe",
      "Yuki Mitsufuji",
      "John Thickstun",
      "Chris Donahue"
    ],
    "abstract": "Despite significant recent advances in generative acoustic text-to-music\n(TTM) modeling, robust evaluation of these models lags behind, relying in\nparticular on the popular Fr\\'echet Audio Distance (FAD). In this work, we\nrigorously study the design space of reference-based divergence metrics for\nevaluating TTM models through (1) designing four synthetic meta-evaluations to\nmeasure sensitivity to particular musical desiderata, and (2) collecting and\nevaluating on MusicPrefs, the first open-source dataset of human preferences\nfor TTM systems. We find that not only is the standard FAD setup inconsistent\non both synthetic and human preference data, but that nearly all existing\nmetrics fail to effectively capture desiderata, and are only weakly correlated\nwith human perception. We propose a new metric, the MAUVE Audio Divergence\n(MAD), computed on representations from a self-supervised audio embedding\nmodel. We find that this metric effectively captures diverse musical desiderata\n(average rank correlation 0.84 for MAD vs. 0.49 for FAD and also correlates\nmore strongly with MusicPrefs (0.62 vs. 0.14).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16669v1",
    "published_date": "2025-03-20 19:31:04 UTC",
    "updated_date": "2025-03-20 19:31:04 UTC"
  },
  {
    "arxiv_id": "2503.16668v1",
    "title": "Code Evolution Graphs: Understanding Large Language Model Driven Design of Algorithms",
    "authors": [
      "Niki van Stein",
      "Anna V. Kononova",
      "Lars Kotthoff",
      "Thomas Bäck"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great promise in generating\ncode, especially when used inside an evolutionary computation framework to\niteratively optimize the generated algorithms. However, in some cases they fail\nto generate competitive algorithms or the code optimization stalls, and we are\nleft with no recourse because of a lack of understanding of the generation\nprocess and generated codes. We present a novel approach to mitigate this\nproblem by enabling users to analyze the generated codes inside the\nevolutionary process and how they evolve over repeated prompting of the LLM. We\nshow results for three benchmark problem classes and demonstrate novel\ninsights. In particular, LLMs tend to generate more complex code with repeated\nprompting, but additional complexity can hurt algorithmic performance in some\ncases. Different LLMs have different coding ``styles'' and generated code tends\nto be dissimilar to other LLMs. These two findings suggest that using different\nLLMs inside the code evolution frameworks might produce higher performing code\nthan using only one LLM.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted at GECCO 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16668v1",
    "published_date": "2025-03-20 19:30:22 UTC",
    "updated_date": "2025-03-20 19:30:22 UTC"
  },
  {
    "arxiv_id": "2503.21793v1",
    "title": "Input-Triggered Hardware Trojan Attack on Spiking Neural Networks",
    "authors": [
      "Spyridon Raptis",
      "Paul Kling",
      "Ioannis Kaskampas",
      "Ihsen Alouani",
      "Haralampos-G. Stratigopoulos"
    ],
    "abstract": "Neuromorphic computing based on spiking neural networks (SNNs) is emerging as\na promising alternative to traditional artificial neural networks (ANNs),\noffering unique advantages in terms of low power consumption. However, the\nsecurity aspect of SNNs is under-explored compared to their ANN counterparts.\nAs the increasing reliance on AI systems comes with unique security risks and\nchallenges, understanding the vulnerabilities and threat landscape is essential\nas neuromorphic computing matures. In this effort, we propose a novel\ninput-triggered Hardware Trojan (HT) attack for SNNs. The HT mechanism is\ncondensed in the area of one neuron. The trigger mechanism is an input message\ncrafted in the spiking domain such that a selected neuron produces a malicious\nspike train that is not met in normal settings. This spike train triggers a\nmalicious modification in the neuron that forces it to saturate, firing\npermanently and failing to recover to its resting state even when the input\nactivity stops. The excessive spikes pollute the network and produce misleading\ndecisions. We propose a methodology to select an appropriate neuron and to\ngenerate the input pattern that triggers the HT payload. The attack is\nillustrated by simulation on three popular benchmarks in the neuromorphic\ncommunity. We also propose a hardware implementation for an analog spiking\nneuron and a digital SNN accelerator, demonstrating that the HT has a\nnegligible area and power footprint and, thereby, can easily evade detection.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.21793v1",
    "published_date": "2025-03-20 19:24:30 UTC",
    "updated_date": "2025-03-20 19:24:30 UTC"
  },
  {
    "arxiv_id": "2504.08738v2",
    "title": "AI-Driven Sentiment Analytics: Unlocking Business Value in the E-Commerce Landscape_v1",
    "authors": [
      "Qianye Wu",
      "Chengxuan Xia",
      "Sixuan Tian"
    ],
    "abstract": "The rapid growth of e-commerce has led to an overwhelming volume of customer\nfeedback, from product reviews to service interactions. Extracting meaningful\ninsights from this data is crucial for businesses aiming to improve customer\nsatisfaction and optimize decision-making. This paper presents an AI-driven\nsentiment analysis system designed specifically for e-commerce applications,\nbalancing accuracy with interpretability. Our approach integrates traditional\nmachine learning techniques with modern deep learning models, allowing for a\nmore nuanced understanding of customer sentiment while ensuring transparency in\ndecision-making. Experimental results show that our system outperforms standard\nsentiment analysis methods, achieving an accuracy of 89.7% on diverse,\nlarge-scale datasets. Beyond technical performance, real-world implementation\nacross multiple e-commerce platforms demonstrates tangible improvements in\ncustomer engagement and operational efficiency. This study highlights both the\npotential and the challenges of applying AI to sentiment analysis in a\ncommercial setting, offering insights into practical deployment strategies and\nareas for future refinement.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.IR",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.08738v2",
    "published_date": "2025-03-20 18:56:22 UTC",
    "updated_date": "2025-04-16 05:59:02 UTC"
  },
  {
    "arxiv_id": "2503.16628v1",
    "title": "MobilePlantViT: A Mobile-friendly Hybrid ViT for Generalized Plant Disease Image Classification",
    "authors": [
      "Moshiur Rahman Tonmoy",
      "Md. Mithun Hossain",
      "Nilanjan Dey",
      "M. F. Mridha"
    ],
    "abstract": "Plant diseases significantly threaten global food security by reducing crop\nyields and undermining agricultural sustainability. AI-driven automated\nclassification has emerged as a promising solution, with deep learning models\ndemonstrating impressive performance in plant disease identification. However,\ndeploying these models on mobile and edge devices remains challenging due to\nhigh computational demands and resource constraints, highlighting the need for\nlightweight, accurate solutions for accessible smart agriculture systems. To\naddress this, we propose MobilePlantViT, a novel hybrid Vision Transformer\n(ViT) architecture designed for generalized plant disease classification, which\noptimizes resource efficiency while maintaining high performance. Extensive\nexperiments across diverse plant disease datasets of varying scales show our\nmodel's effectiveness and strong generalizability, achieving test accuracies\nranging from 80% to over 99%. Notably, with only 0.69 million parameters, our\narchitecture outperforms the smallest versions of MobileViTv1 and MobileViTv2,\ndespite their higher parameter counts. These results underscore the potential\nof our approach for real-world, AI-powered automated plant disease\nclassification in sustainable and resource-efficient smart agriculture systems.\nAll codes will be available in the GitHub repository:\nhttps://github.com/moshiurtonmoy/MobilePlantViT",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted to a journal for peer-review under IEEE Transactions series",
    "pdf_url": "http://arxiv.org/pdf/2503.16628v1",
    "published_date": "2025-03-20 18:34:02 UTC",
    "updated_date": "2025-03-20 18:34:02 UTC"
  },
  {
    "arxiv_id": "2503.16614v1",
    "title": "Classification of User Reports for Detection of Faulty Computer Components using NLP Models: A Case Study",
    "authors": [
      "Maria de Lourdes M. Silva",
      "André L. C. Mendonça",
      "Eduardo R. D. Neto",
      "Iago C. Chaves",
      "Felipe T. Brito",
      "Victor A. E. Farias",
      "Javam C. Machado"
    ],
    "abstract": "Computer manufacturers typically offer platforms for users to report faults.\nHowever, there remains a significant gap in these platforms' ability to\neffectively utilize textual reports, which impedes users from describing their\nissues in their own words. In this context, Natural Language Processing (NLP)\noffers a promising solution, by enabling the analysis of user-generated text.\nThis paper presents an innovative approach that employs NLP models to classify\nuser reports for detecting faulty computer components, such as CPU, memory,\nmotherboard, video card, and more. In this work, we build a dataset of 341 user\nreports obtained from many sources. Additionally, through extensive\nexperimental evaluation, our approach achieved an accuracy of 79% with our\ndataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16614v1",
    "published_date": "2025-03-20 18:11:26 UTC",
    "updated_date": "2025-03-20 18:11:26 UTC"
  },
  {
    "arxiv_id": "2503.16611v1",
    "title": "A Recipe for Generating 3D Worlds From a Single Image",
    "authors": [
      "Katja Schwarz",
      "Denys Rozumnyi",
      "Samuel Rota Bulò",
      "Lorenzo Porzi",
      "Peter Kontschieder"
    ],
    "abstract": "We introduce a recipe for generating immersive 3D worlds from a single image\nby framing the task as an in-context learning problem for 2D inpainting models.\nThis approach requires minimal training and uses existing generative models.\nOur process involves two steps: generating coherent panoramas using a\npre-trained diffusion model and lifting these into 3D with a metric depth\nestimator. We then fill unobserved regions by conditioning the inpainting model\non rendered point clouds, requiring minimal fine-tuning. Tested on both\nsynthetic and real images, our method produces high-quality 3D environments\nsuitable for VR display. By explicitly modeling the 3D structure of the\ngenerated environment from the start, our approach consistently outperforms\nstate-of-the-art, video synthesis-based methods along multiple quantitative\nimage quality metrics. Project Page: https://katjaschwarz.github.io/worlds/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16611v1",
    "published_date": "2025-03-20 18:06:12 UTC",
    "updated_date": "2025-03-20 18:06:12 UTC"
  },
  {
    "arxiv_id": "2503.16421v1",
    "title": "MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance",
    "authors": [
      "Quanhao Li",
      "Zhen Xing",
      "Rui Wang",
      "Hui Zhang",
      "Qi Dai",
      "Zuxuan Wu"
    ],
    "abstract": "Recent advances in video generation have led to remarkable improvements in\nvisual quality and temporal coherence. Upon this, trajectory-controllable video\ngeneration has emerged to enable precise object motion control through\nexplicitly defined spatial paths. However, existing methods struggle with\ncomplex object movements and multi-object motion control, resulting in\nimprecise trajectory adherence, poor object consistency, and compromised visual\nquality. Furthermore, these methods only support trajectory control in a single\nformat, limiting their applicability in diverse scenarios. Additionally, there\nis no publicly available dataset or benchmark specifically tailored for\ntrajectory-controllable video generation, hindering robust training and\nsystematic evaluation. To address these challenges, we introduce MagicMotion, a\nnovel image-to-video generation framework that enables trajectory control\nthrough three levels of conditions from dense to sparse: masks, bounding boxes,\nand sparse boxes. Given an input image and trajectories, MagicMotion seamlessly\nanimates objects along defined trajectories while maintaining object\nconsistency and visual quality. Furthermore, we present MagicData, a\nlarge-scale trajectory-controlled video dataset, along with an automated\npipeline for annotation and filtering. We also introduce MagicBench, a\ncomprehensive benchmark that assesses both video quality and trajectory control\naccuracy across different numbers of objects. Extensive experiments demonstrate\nthat MagicMotion outperforms previous methods across various metrics. Our\nproject page are publicly available at\nhttps://quanhaol.github.io/magicmotion-site.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16421v1",
    "published_date": "2025-03-20 17:59:42 UTC",
    "updated_date": "2025-03-20 17:59:42 UTC"
  },
  {
    "arxiv_id": "2503.16416v1",
    "title": "Survey on Evaluation of LLM-based Agents",
    "authors": [
      "Asaf Yehudai",
      "Lilach Eden",
      "Alan Li",
      "Guy Uziel",
      "Yilun Zhao",
      "Roy Bar-Haim",
      "Arman Cohan",
      "Michal Shmueli-Scheuer"
    ],
    "abstract": "The emergence of LLM-based agents represents a paradigm shift in AI, enabling\nautonomous systems to plan, reason, use tools, and maintain memory while\ninteracting with dynamic environments. This paper provides the first\ncomprehensive survey of evaluation methodologies for these increasingly capable\nagents. We systematically analyze evaluation benchmarks and frameworks across\nfour critical dimensions: (1) fundamental agent capabilities, including\nplanning, tool use, self-reflection, and memory; (2) application-specific\nbenchmarks for web, software engineering, scientific, and conversational\nagents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating\nagents. Our analysis reveals emerging trends, including a shift toward more\nrealistic, challenging evaluations with continuously updated benchmarks. We\nalso identify critical gaps that future research must address-particularly in\nassessing cost-efficiency, safety, and robustness, and in developing\nfine-grained, and scalable evaluation methods. This survey maps the rapidly\nevolving landscape of agent evaluation, reveals the emerging trends in the\nfield, identifies current limitations, and proposes directions for future\nresearch.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16416v1",
    "published_date": "2025-03-20 17:59:23 UTC",
    "updated_date": "2025-03-20 17:59:23 UTC"
  },
  {
    "arxiv_id": "2503.16412v1",
    "title": "DreamTexture: Shape from Virtual Texture with Analysis by Augmentation",
    "authors": [
      "Ananta R. Bhattarai",
      "Xingzhe He",
      "Alla Sheffer",
      "Helge Rhodin"
    ],
    "abstract": "DreamFusion established a new paradigm for unsupervised 3D reconstruction\nfrom virtual views by combining advances in generative models and\ndifferentiable rendering. However, the underlying multi-view rendering, along\nwith supervision from large-scale generative models, is computationally\nexpensive and under-constrained. We propose DreamTexture, a novel\nShape-from-Virtual-Texture approach that leverages monocular depth cues to\nreconstruct 3D objects. Our method textures an input image by aligning a\nvirtual texture with the real depth cues in the input, exploiting the inherent\nunderstanding of monocular geometry encoded in modern diffusion models. We then\nreconstruct depth from the virtual texture deformation with a new conformal map\noptimization, which alleviates memory-intensive volumetric representations. Our\nexperiments reveal that generative models possess an understanding of monocular\nshape cues, which can be extracted by augmenting and aligning texture cues -- a\nnovel monocular reconstruction paradigm that we call Analysis by Augmentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://anantarb.github.io/dreamtexture/",
    "pdf_url": "http://arxiv.org/pdf/2503.16412v1",
    "published_date": "2025-03-20 17:59:12 UTC",
    "updated_date": "2025-03-20 17:59:12 UTC"
  },
  {
    "arxiv_id": "2503.16408v1",
    "title": "RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints",
    "authors": [
      "Yiran Qin",
      "Li Kang",
      "Xiufeng Song",
      "Zhenfei Yin",
      "Xiaohong Liu",
      "Xihui Liu",
      "Ruimao Zhang",
      "Lei Bai"
    ],
    "abstract": "Designing effective embodied multi-agent systems is critical for solving\ncomplex real-world tasks across domains. Due to the complexity of multi-agent\nembodied systems, existing methods fail to automatically generate safe and\nefficient training data for such systems. To this end, we propose the concept\nof compositional constraints for embodied multi-agent systems, addressing the\nchallenges arising from collaboration among embodied agents. We design various\ninterfaces tailored to different types of constraints, enabling seamless\ninteraction with the physical world. Leveraging compositional constraints and\nspecifically designed interfaces, we develop an automated data collection\nframework for embodied multi-agent systems and introduce the first benchmark\nfor embodied multi-agent manipulation, RoboFactory. Based on RoboFactory\nbenchmark, we adapt and evaluate the method of imitation learning and analyzed\nits performance in different difficulty agent tasks. Furthermore, we explore\nthe architectures and training strategies for multi-agent imitation learning,\naiming to build safe and efficient embodied multi-agent systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page: https://iranqin.github.io/robofactory/",
    "pdf_url": "http://arxiv.org/pdf/2503.16408v1",
    "published_date": "2025-03-20 17:58:38 UTC",
    "updated_date": "2025-03-20 17:58:38 UTC"
  },
  {
    "arxiv_id": "2503.16402v1",
    "title": "The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination",
    "authors": [
      "Yifan Sun",
      "Han Wang",
      "Dongbai Li",
      "Gang Wang",
      "Huan Zhang"
    ],
    "abstract": "Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples\nin the training set-has raised increasing concerns in Large Language Model\n(LLM) evaluation, leading to falsely inflated performance estimates and\nundermining evaluation reliability. To address this, researchers have proposed\nvarious mitigation strategies to update existing benchmarks, including\nmodifying original questions or generating new ones based on them. However, a\nrigorous examination of the effectiveness of these mitigation strategies\nremains lacking. In this paper, we design a systematic and controlled pipeline\nalong with two novel metrics-fidelity and contamination resistance-to provide a\nfine-grained and comprehensive assessment of existing BDC mitigation\nstrategies. Previous assessment methods, such as accuracy drop and accuracy\nmatching, focus solely on aggregate accuracy, often leading to incomplete or\nmisleading conclusions. Our metrics address this limitation by emphasizing\nquestion-level evaluation result matching. Extensive experiments with 10 LLMs,\n5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios\nreveal that no existing strategy significantly improves resistance over the\nvanilla case (i.e., no benchmark update) across all benchmarks, and none\neffectively balances fidelity and contamination resistance. These findings\nunderscore the urgent need for designing more effective BDC mitigation\nstrategies. Our code repository is available at\nhttps://github.com/ASTRAL-Group/BDC_mitigation_assessment.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16402v1",
    "published_date": "2025-03-20 17:55:04 UTC",
    "updated_date": "2025-03-20 17:55:04 UTC"
  },
  {
    "arxiv_id": "2503.16399v1",
    "title": "SA-Occ: Satellite-Assisted 3D Occupancy Prediction in Real World",
    "authors": [
      "Chen Chen",
      "Zhirui Wang",
      "Taowei Sheng",
      "Yi Jiang",
      "Yundu Li",
      "Peirui Cheng",
      "Luning Zhang",
      "Kaiqiang Chen",
      "Yanfeng Hu",
      "Xue Yang",
      "Xian Sun"
    ],
    "abstract": "Existing vision-based 3D occupancy prediction methods are inherently limited\nin accuracy due to their exclusive reliance on street-view imagery, neglecting\nthe potential benefits of incorporating satellite views. We propose SA-Occ, the\nfirst Satellite-Assisted 3D occupancy prediction model, which leverages GPS &\nIMU to integrate historical yet readily available satellite imagery into\nreal-time applications, effectively mitigating limitations of ego-vehicle\nperceptions, involving occlusions and degraded performance in distant regions.\nTo address the core challenges of cross-view perception, we propose: 1)\nDynamic-Decoupling Fusion, which resolves inconsistencies in dynamic regions\ncaused by the temporal asynchrony between satellite and street views; 2)\n3D-Proj Guidance, a module that enhances 3D feature extraction from inherently\n2D satellite imagery; and 3) Uniform Sampling Alignment, which aligns the\nsampling density between street and satellite views. Evaluated on\nOcc3D-nuScenes, SA-Occ achieves state-of-the-art performance, especially among\nsingle-frame methods, with a 39.05% mIoU (a 6.97% improvement), while incurring\nonly 6.93 ms of additional latency per frame. Our code and newly curated\ndataset are available at https://github.com/chenchen235/SA-Occ.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16399v1",
    "published_date": "2025-03-20 17:54:29 UTC",
    "updated_date": "2025-03-20 17:54:29 UTC"
  },
  {
    "arxiv_id": "2503.16394v1",
    "title": "Do Visual Imaginations Improve Vision-and-Language Navigation Agents?",
    "authors": [
      "Akhil Perincherry",
      "Jacob Krantz",
      "Stefan Lee"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) agents are tasked with navigating an\nunseen environment using natural language instructions. In this work, we study\nif visual representations of sub-goals implied by the instructions can serve as\nnavigational cues and lead to increased navigation performance. To synthesize\nthese visual representations or imaginations, we leverage a text-to-image\ndiffusion model on landmark references contained in segmented instructions.\nThese imaginations are provided to VLN agents as an added modality to act as\nlandmark cues and an auxiliary loss is added to explicitly encourage relating\nthese with their corresponding referring expressions. Our findings reveal an\nincrease in success rate (SR) of around 1 point and up to 0.5 points in success\nscaled by inverse path length (SPL) across agents. These results suggest that\nthe proposed approach reinforces visual understanding compared to relying on\nlanguage instructions alone. Code and data for our work can be found at\nhttps://www.akhilperincherry.com/VLN-Imagine-website/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16394v1",
    "published_date": "2025-03-20 17:53:12 UTC",
    "updated_date": "2025-03-20 17:53:12 UTC"
  },
  {
    "arxiv_id": "2503.16392v2",
    "title": "Graph of Effort: Quantifying Risk of AI Usage for Vulnerability Assessment",
    "authors": [
      "Anket Mehra",
      "Andreas Aßmuth",
      "Malte Prieß"
    ],
    "abstract": "With AI-based software becoming widely available, the risk of exploiting its\ncapabilities, such as high automation and complex pattern recognition, could\nsignificantly increase. An AI used offensively to attack non-AI assets is\nreferred to as offensive AI.\n  Current research explores how offensive AI can be utilized and how its usage\ncan be classified. Additionally, methods for threat modeling are being\ndeveloped for AI-based assets within organizations. However, there are gaps\nthat need to be addressed. Firstly, there is a need to quantify the factors\ncontributing to the AI threat. Secondly, there is a requirement to create\nthreat models that analyze the risk of being attacked by AI for vulnerability\nassessment across all assets of an organization. This is particularly crucial\nand challenging in cloud environments, where sophisticated infrastructure and\naccess control landscapes are prevalent. The ability to quantify and further\nanalyze the threat posed by offensive AI enables analysts to rank\nvulnerabilities and prioritize the implementation of proactive countermeasures.\n  To address these gaps, this paper introduces the Graph of Effort, an\nintuitive, flexible, and effective threat modeling method for analyzing the\neffort required to use offensive AI for vulnerability exploitation by an\nadversary. While the threat model is functional and provides valuable support,\nits design choices need further empirical validation in future work.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16392v2",
    "published_date": "2025-03-20 17:52:42 UTC",
    "updated_date": "2025-04-07 10:01:44 UTC"
  },
  {
    "arxiv_id": "2503.16389v1",
    "title": "Attentional Triple-Encoder Network in Spatiospectral Domains for Medical Image Segmentation",
    "authors": [
      "Kristin Qi",
      "Xinhan Di"
    ],
    "abstract": "Retinal Optical Coherence Tomography (OCT) segmentation is essential for\ndiagnosing pathology. Traditional methods focus on either spatial or spectral\ndomains, overlooking their combined dependencies. We propose a triple-encoder\nnetwork that integrates CNNs for spatial features, Fast Fourier Convolution\n(FFC) for spectral features, and attention mechanisms to capture global\nrelationships across both domains. Attention fusion modules integrate\nconvolution and cross-attention to further enhance features. Our method\nachieves an average Dice score improvement from 0.855 to 0.864, outperforming\nprior work.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "IEEE Conference on Artificial Intelligence (IEEE CAI)",
    "pdf_url": "http://arxiv.org/pdf/2503.16389v1",
    "published_date": "2025-03-20 17:49:01 UTC",
    "updated_date": "2025-03-20 17:49:01 UTC"
  },
  {
    "arxiv_id": "2503.16385v1",
    "title": "Deconstructing Long Chain-of-Thought: A Structured Reasoning Optimization Framework for Long CoT Distillation",
    "authors": [
      "Yijia Luo",
      "Yulin Song",
      "Xingyao Zhang",
      "Jiaheng Liu",
      "Weixun Wang",
      "GengRu Chen",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable reasoning capabilities through long chain-of-thought (CoT)\nreasoning. The R1 distillation scheme has emerged as a promising approach for\ntraining cost-effective models with enhanced reasoning abilities. However, the\nunderlying mechanisms driving its effectiveness remain unclear. This study\nexamines the universality of distillation data and identifies key components\nthat enable the efficient transfer of long-chain reasoning capabilities in LLM\ndistillation. Our findings reveal that the effectiveness of long CoT reasoning\ndistillation from teacher models like Qwen-QwQ degrades significantly on\nnonhomologous models, challenging the assumed universality of current\ndistillation methods. To gain deeper insights into the structure and patterns\nof long CoT reasoning, we propose DLCoT (Deconstructing Long Chain-of-Thought),\na distillation data enhancement framework. DLCoT consists of three key steps:\n(1) data segmentation to decompose complex long CoT structures, (2)\nsimplification by eliminating unsolvable and redundant solutions, and (3)\noptimization of intermediate error states. Our approach significantly improves\nmodel performance and token efficiency, facilitating the development of\nhigh-performance LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16385v1",
    "published_date": "2025-03-20 17:46:38 UTC",
    "updated_date": "2025-03-20 17:46:38 UTC"
  },
  {
    "arxiv_id": "2503.16371v2",
    "title": "Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming",
    "authors": [
      "Minori Narita",
      "Ryo Kuroiwa",
      "J. Christopher Beck"
    ],
    "abstract": "Domain-Independent Dynamic Programming (DIDP) is a state-space search\nparadigm based on dynamic programming for combinatorial optimization. In its\ncurrent implementation, DIDP guides the search using user-defined dual bounds.\nReinforcement learning (RL) is increasingly being applied to combinatorial\noptimization problems and shares several key structures with DP, being\nrepresented by the Bellman equation and state-based transition systems. We\npropose using reinforcement learning to obtain a heuristic function to guide\nthe search in DIDP. We develop two RL-based guidance approaches: value-based\nguidance using Deep Q-Networks and policy-based guidance using Proximal Policy\nOptimization. Our experiments indicate that RL-based guidance significantly\noutperforms standard DIDP and problem-specific greedy heuristics with the same\nnumber of node expansions. Further, despite longer node evaluation times, RL\nguidance achieves better run-time performance than standard DIDP on three of\nfour benchmark domains.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 4 figures, to be published in CPAIOR 2025\n  (https://sites.google.com/view/cpaior2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.16371v2",
    "published_date": "2025-03-20 17:33:08 UTC",
    "updated_date": "2025-05-13 19:08:33 UTC"
  },
  {
    "arxiv_id": "2503.16365v1",
    "title": "JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse",
    "authors": [
      "Muyao Li",
      "Zihao Wang",
      "Kaichen He",
      "Xiaojian Ma",
      "Yitao Liang"
    ],
    "abstract": "Recently, action-based decision-making in open-world environments has gained\nsignificant attention. Visual Language Action (VLA) models, pretrained on\nlarge-scale web datasets, have shown promise in decision-making tasks. However,\nprevious work has primarily focused on action post-training, often neglecting\nenhancements to the foundational model itself. In response, we introduce a\nnovel approach, Act from Visual Language Post-Training, which refines Visual\nLanguage Models (VLMs) through visual and linguistic guidance in a\nself-supervised manner. This enhancement improves the models' capabilities in\nworld knowledge, visual recognition, and spatial grounding in open-world\nenvironments. Following the above post-training paradigms, we obtain the first\nVLA models in Minecraft that can follow human instructions on over 1k different\natomic tasks, including crafting, smelting, cooking, mining, and killing. Our\nexperiments demonstrate that post-training on non-trajectory tasks leads to a\nsignificant 40% improvement over the best agent baseline on a diverse set of\natomic tasks. Furthermore, we demonstrate that our approach surpasses\ntraditional imitation learning-based policies in Minecraft, achieving\nstate-of-the-art performance. We have open-sourced the code, models, and\ndatasets to foster further research. The project page can be found in\nhttps://craftjarvis.github.io/JarvisVLA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16365v1",
    "published_date": "2025-03-20 17:21:58 UTC",
    "updated_date": "2025-03-20 17:21:58 UTC"
  },
  {
    "arxiv_id": "2503.16364v1",
    "title": "Neural Networks: According to the Principles of Grassmann Algebra",
    "authors": [
      "Z. Zarezadeh",
      "N. Zarezadeh"
    ],
    "abstract": "In this paper, we explore the algebra of quantum idempotents and the\nquantization of fermions which gives rise to a Hilbert space equal to the\nGrassmann algebra associated with the Lie algebra. Since idempotents carry\nrepresentations of the algebra under consideration, they form algebraic\nvarieties and smooth manifolds in the natural topology. In addition to the\nmotivation of linking up mathematical physics with machine learning, it is also\nshown that by using idempotents and invariant subspace of the corresponding\nalgebras, these representations encode and perhaps provide a probabilistic\ninterpretation of reasoning and relational paths in geometrical terms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16364v1",
    "published_date": "2025-03-20 17:21:23 UTC",
    "updated_date": "2025-03-20 17:21:23 UTC"
  },
  {
    "arxiv_id": "2503.16356v1",
    "title": "CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners",
    "authors": [
      "Yunzhi Yao",
      "Jizhan Fang",
      "Jia-Chen Gu",
      "Ningyu Zhang",
      "Shumin Deng",
      "Huajun Chen",
      "Nanyun Peng"
    ],
    "abstract": "Knowledge Editing (KE) enables the modification of outdated or incorrect\ninformation in large language models (LLMs). While existing KE methods can\nupdate isolated facts, they struggle to generalize these updates to multi-hop\nreasoning tasks that depend on the modified knowledge. Through an analysis of\nreasoning circuits -- the neural pathways LLMs use for knowledge-based\ninference, we observe that current layer-localized KE approaches, such as MEMIT\nand WISE, which edit only single or a few model layers, struggle to effectively\nincorporate updated information into these reasoning pathways. To address this\nlimitation, we propose CaKE (Circuit-aware Knowledge Editing), a novel method\nthat enables more effective integration of updated knowledge in LLMs. CaKE\nleverages strategically curated data, guided by our circuits-based analysis,\nthat enforces the model to utilize the modified knowledge, stimulating the\nmodel to develop appropriate reasoning circuits for newly integrated knowledge.\nExperimental results show that CaKE enables more accurate and consistent use of\nupdated knowledge across related reasoning tasks, leading to an average of 20%\nimprovement in multi-hop reasoning accuracy on MQuAKE dataset compared to\nexisting KE methods. We release the code and data in\nhttps://github.com/zjunlp/CaKE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.16356v1",
    "published_date": "2025-03-20 17:14:34 UTC",
    "updated_date": "2025-03-20 17:14:34 UTC"
  },
  {
    "arxiv_id": "2503.16348v2",
    "title": "Palatable Conceptions of Disembodied Being: Terra Incognita in the Space of Possible Minds",
    "authors": [
      "Murray Shanahan"
    ],
    "abstract": "Is it possible to articulate a conception of consciousness that is compatible\nwith the exotic characteristics of contemporary, disembodied AI systems, and\nthat can stand up to philosophical scrutiny? How would subjective time and\nselfhood show up for an entity that conformed to such a conception? Trying to\nanswer these questions, even metaphorically, stretches the language of\nconsciousness to breaking point. Ultimately, the attempt yields something like\nemptiness, in the Buddhist sense, and helps to undermine our dualistic\ninclinations towards subjectivity and selfhood.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16348v2",
    "published_date": "2025-03-20 17:05:16 UTC",
    "updated_date": "2025-05-19 12:35:35 UTC"
  },
  {
    "arxiv_id": "2503.16342v1",
    "title": "HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks",
    "authors": [
      "Haoqi He",
      "Yan Xiao"
    ],
    "abstract": "Estimating the global Lipschitz constant of neural networks is crucial for\nunderstanding and improving their robustness and generalization capabilities.\nHowever, precise calculations are NP-hard, and current semidefinite programming\n(SDP) methods face challenges such as high memory usage and slow processing\nspeeds. In this paper, we propose \\textbf{HiQ-Lip}, a hybrid quantum-classical\nhierarchical method that leverages Coherent Ising Machines (CIMs) to estimate\nthe global Lipschitz constant. We tackle the estimation by converting it into a\nQuadratic Unconstrained Binary Optimization (QUBO) problem and implement a\nmultilevel graph coarsening and refinement strategy to adapt to the constraints\nof contemporary quantum hardware. Our experimental evaluations on fully\nconnected neural networks demonstrate that HiQ-Lip not only provides estimates\ncomparable to state-of-the-art methods but also significantly accelerates the\ncomputation process. In specific tests involving two-layer neural networks with\n256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate\nupper bounds than the existing best method, LiPopt. These findings highlight\nthe promising utility of small-scale quantum devices in advancing the\nestimation of neural network robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16342v1",
    "published_date": "2025-03-20 16:58:40 UTC",
    "updated_date": "2025-03-20 16:58:40 UTC"
  },
  {
    "arxiv_id": "2503.16335v1",
    "title": "Enhancing Software Quality Assurance with an Adaptive Differential Evolution based Quantum Variational Autoencoder-Transformer Model",
    "authors": [
      "Seshu Babu Barma",
      "Mohanakrishnan Hariharan",
      "Satish Arvapalli"
    ],
    "abstract": "An AI-powered quality engineering platform uses artificial intelligence to\nboost software quality assessments through automated defect prediction and\noptimized performance alongside improved feature extraction. Existing models\nresult in difficulties addressing noisy data types together with imbalances,\npattern recognition complexities, ineffective feature extraction, and\ngeneralization weaknesses. To overcome those existing challenges in this\nresearch, we develop a new model Adaptive Differential Evolution based Quantum\nVariational Autoencoder-Transformer Model (ADE-QVAET), that combines a Quantum\nVariational Autoencoder-Transformer (QVAET) to obtain high-dimensional latent\nfeatures and maintain sequential dependencies together with contextual\nrelationships, resulting in superior defect prediction accuracy. Adaptive\nDifferential Evolution (ADE) Optimization utilizes an adaptive parameter tuning\nmethod that enhances model convergence and predictive performance. ADE-QVAET\nintegrates advanced AI techniques to create a robust solution for scalable and\naccurate software defect prediction that represents a top-level AI-driven\ntechnology for quality engineering applications. The proposed ADE-QVAET model\nattains high accuracy, precision, recall, and f1-score during the training\npercentage (TP) 90 of 98.08%, 92.45%, 94.67%, and 98.12%.",
    "categories": [
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16335v1",
    "published_date": "2025-03-20 16:55:38 UTC",
    "updated_date": "2025-03-20 16:55:38 UTC"
  },
  {
    "arxiv_id": "2503.16328v2",
    "title": "Knowledge-guided machine learning for county-level corn yield prediction under drought",
    "authors": [
      "Xiaoyu Wang",
      "Yijia Xu",
      "Jingyi Huang",
      "Zhengwei Yang",
      "Zhou Zhang"
    ],
    "abstract": "Remote sensing (RS) technique, enabling the non-contact acquisition of\nextensive ground observations, is a valuable tool for crop yield predictions.\nTraditional process-based models struggle to incorporate large volumes of RS\ndata, and most users lack understanding of crop growth mechanisms. In contrast,\nmachine learning (ML) models are often criticized as \"black boxes\" due to their\nlimited interpretability. To address these limitations, we utilized\nKnowledge-Guided Machine Learning (KGML), a framework that leverages the\nstrengths of both process-based and ML models. Existing works have either\noverlooked the role of soil moisture in corn growth or did not embed this\neffect into their models. To bridge this gap, we developed the Knowledge-Guided\nMachine Learning with Soil Moisture (KGML-SM) framework, treating soil moisture\nas an intermediate variable in corn growth to emphasize its key role in plant\ndevelopment. Additionally, based on the prior knowledge that the model may\noverestimate under drought conditions, we designed a drought-aware loss\nfunction that penalized predicted yield in drought-affected areas. Our\nexperiments showed that the KGML-SM model outperformed other traditional ML\nmodels. We explored the relationships between drought, soil moisture, and corn\nyield prediction by assessing the importance of different features within the\nmodel, and analyzing how soil moisture impacts predictions across different\nregions and time periods. Finally we provided interpretability for prediction\nerrors to guide future model optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16328v2",
    "published_date": "2025-03-20 16:52:25 UTC",
    "updated_date": "2025-05-05 21:01:27 UTC"
  },
  {
    "arxiv_id": "2503.16326v1",
    "title": "OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence",
    "authors": [
      "Long Yuan",
      "Fengran Mo",
      "Kaiyu Huang",
      "Wenjie Wang",
      "Wangyuxuan Zhai",
      "Xiaoyu Zhu",
      "You Li",
      "Jinan Xu",
      "Jian-Yun Nie"
    ],
    "abstract": "The rapid advancement of multimodal large language models (LLMs) has opened\nnew frontiers in artificial intelligence, enabling the integration of diverse\nlarge-scale data types such as text, images, and spatial information. In this\npaper, we explore the potential of multimodal LLMs (MLLM) for geospatial\nartificial intelligence (GeoAI), a field that leverages spatial data to address\nchallenges in domains including Geospatial Semantics, Health Geography, Urban\nGeography, Urban Perception, and Remote Sensing. We propose a MLLM (OmniGeo)\ntailored to geospatial applications, capable of processing and analyzing\nheterogeneous data sources, including satellite imagery, geospatial metadata,\nand textual descriptions. By combining the strengths of natural language\nunderstanding and spatial reasoning, our model enhances the ability of\ninstruction following and the accuracy of GeoAI systems. Results demonstrate\nthat our model outperforms task-specific models and existing LLMs on diverse\ngeospatial tasks, effectively addressing the multimodality nature while\nachieving competitive results on the zero-shot geospatial tasks. Our code will\nbe released after publication.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, Under review",
    "pdf_url": "http://arxiv.org/pdf/2503.16326v1",
    "published_date": "2025-03-20 16:45:48 UTC",
    "updated_date": "2025-03-20 16:45:48 UTC"
  },
  {
    "arxiv_id": "2503.16311v1",
    "title": "Structured-Noise Masked Modeling for Video, Audio and Beyond",
    "authors": [
      "Aritra Bhowmik",
      "Fida Mohammad Thoker",
      "Carlos Hinojosa",
      "Bernard Ghanem",
      "Cees G. M. Snoek"
    ],
    "abstract": "Masked modeling has emerged as a powerful self-supervised learning framework,\nbut existing methods largely rely on random masking, disregarding the\nstructural properties of different modalities. In this work, we introduce\nstructured noise-based masking, a simple yet effective approach that naturally\naligns with the spatial, temporal, and spectral characteristics of video and\naudio data. By filtering white noise into distinct color noise distributions,\nwe generate structured masks that preserve modality-specific patterns without\nrequiring handcrafted heuristics or access to the data. Our approach improves\nthe performance of masked video and audio modeling frameworks without any\ncomputational overhead. Extensive experiments demonstrate that structured noise\nmasking achieves consistent improvement over random masking for standard and\nadvanced masked modeling methods, highlighting the importance of modality-aware\nmasking strategies for representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16311v1",
    "published_date": "2025-03-20 16:34:14 UTC",
    "updated_date": "2025-03-20 16:34:14 UTC"
  },
  {
    "arxiv_id": "2503.16307v1",
    "title": "Speeding up design and making to reduce time-to-project and time-to-market: an AI-Enhanced approach in engineering education",
    "authors": [
      "Giovanni Adorni",
      "Daniele Grosso"
    ],
    "abstract": "This paper explores the integration of AI tools, such as ChatGPT and GitHub\nCopilot, in the Software Architecture for Embedded Systems course. AI-supported\nworkflows enabled students to rapidly prototype complex projects, emphasizing\nreal-world applications like SLAM robotics. Results demon-started enhanced\nproblem-solving, faster development, and more sophisticated outcomes, with AI\naugmenting but not replacing human decision-making.",
    "categories": [
      "cs.AI",
      "I.2; K.3"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures, AIxEDU 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2503.16307v1",
    "published_date": "2025-03-20 16:32:13 UTC",
    "updated_date": "2025-03-20 16:32:13 UTC"
  },
  {
    "arxiv_id": "2503.16304v3",
    "title": "Bridging Technology and Humanities: Evaluating the Impact of Large Language Models on Social Sciences Research with DeepSeek-R1",
    "authors": [
      "Peiran Gu",
      "Fuhao Duan",
      "Wenhao Li",
      "Bochen Xu",
      "Ying Cai",
      "Teng Yao",
      "Chenxun Zhuo",
      "Tianming Liu",
      "Bao Ge"
    ],
    "abstract": "In recent years, the development of Large Language Models (LLMs) has made\nsignificant breakthroughs in the field of natural language processing and has\ngradually been applied to the field of humanities and social sciences research.\nLLMs have a wide range of application value in the field of humanities and\nsocial sciences because of its strong text understanding, generation and\nreasoning capabilities. In humanities and social sciences research, LLMs can\nanalyze large-scale text data and make inferences.\n  This article analyzes the large language model DeepSeek-R1 from seven\naspects: low-resource language translation, educational question-answering,\nstudent writing improvement in higher education, logical reasoning, educational\nmeasurement and psychometrics, public health policy analysis, and art education\n. Then we compare the answers given by DeepSeek-R1 in the seven aspects with\nthe answers given by o1-preview. DeepSeek-R1 performs well in the humanities\nand social sciences, answering most questions correctly and logically, and can\ngive reasonable analysis processes and explanations. Compared with o1-preview,\nit can automatically generate reasoning processes and provide more detailed\nexplanations, which is suitable for beginners or people who need to have a\ndetailed understanding of this knowledge, while o1-preview is more suitable for\nquick reading.\n  Through analysis, it is found that LLM has broad application potential in the\nfield of humanities and social sciences, and shows great advantages in\nimproving text analysis efficiency, language communication and other fields.\nLLM's powerful language understanding and generation capabilities enable it to\ndeeply explore complex problems in the field of humanities and social sciences,\nand provide innovative tools for academic research and practical applications.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "52 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16304v3",
    "published_date": "2025-03-20 16:25:24 UTC",
    "updated_date": "2025-04-15 15:09:24 UTC"
  },
  {
    "arxiv_id": "2503.16302v2",
    "title": "Unleashing Vecset Diffusion Model for Fast Shape Generation",
    "authors": [
      "Zeqiang Lai",
      "Yunfei Zhao",
      "Zibo Zhao",
      "Haolin Liu",
      "Fuyun Wang",
      "Huiwen Shi",
      "Xianghui Yang",
      "Qingxiang Lin",
      "Jingwei Huang",
      "Yuhong Liu",
      "Jie Jiang",
      "Chunchao Guo",
      "Xiangyu Yue"
    ],
    "abstract": "3D shape generation has greatly flourished through the development of\nso-called \"native\" 3D diffusion, particularly through the Vecset Diffusion\nModel (VDM). While recent advancements have shown promising results in\ngenerating high-resolution 3D shapes, VDM still struggles with high-speed\ngeneration. Challenges exist because of difficulties not only in accelerating\ndiffusion sampling but also VAE decoding in VDM, areas under-explored in\nprevious works. To address these challenges, we present FlashVDM, a systematic\nframework for accelerating both VAE and DiT in VDM. For DiT, FlashVDM enables\nflexible diffusion sampling with as few as 5 inference steps and comparable\nquality, which is made possible by stabilizing consistency distillation with\nour newly introduced Progressive Flow Distillation. For VAE, we introduce a\nlightning vecset decoder equipped with Adaptive KV Selection, Hierarchical\nVolume Decoding, and Efficient Network Design. By exploiting the locality of\nthe vecset and the sparsity of shape surface in the volume, our decoder\ndrastically lowers FLOPs, minimizing the overall decoding overhead. We apply\nFlashVDM to Hunyuan3D-2 to obtain Hunyuan3D-2 Turbo. Through systematic\nevaluation, we show that our model significantly outperforms existing fast 3D\ngeneration methods, achieving comparable performance to the state-of-the-art\nwhile reducing inference time by over 45x for reconstruction and 32x for\ngeneration. Code and models are available at\nhttps://github.com/Tencent/FlashVDM.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical report",
    "pdf_url": "http://arxiv.org/pdf/2503.16302v2",
    "published_date": "2025-03-20 16:23:44 UTC",
    "updated_date": "2025-03-26 15:08:12 UTC"
  },
  {
    "arxiv_id": "2503.16586v1",
    "title": "Big Help or Big Brother? Auditing Tracking, Profiling, and Personalization in Generative AI Assistants",
    "authors": [
      "Yash Vekaria",
      "Aurelio Loris Canino",
      "Jonathan Levitsky",
      "Alex Ciechonski",
      "Patricia Callejo",
      "Anna Maria Mandalari",
      "Zubair Shafiq"
    ],
    "abstract": "Generative AI (GenAI) browser assistants integrate powerful capabilities of\nGenAI in web browsers to provide rich experiences such as question answering,\ncontent summarization, and agentic navigation. These assistants, available\ntoday as browser extensions, can not only track detailed browsing activity such\nas search and click data, but can also autonomously perform tasks such as\nfilling forms, raising significant privacy concerns. It is crucial to\nunderstand the design and operation of GenAI browser extensions, including how\nthey collect, store, process, and share user data. To this end, we study their\nability to profile users and personalize their responses based on explicit or\ninferred demographic attributes and interests of users. We perform network\ntraffic analysis and use a novel prompting framework to audit tracking,\nprofiling, and personalization by the ten most popular GenAI browser assistant\nextensions. We find that instead of relying on local in-browser models, these\nassistants largely depend on server-side APIs, which can be auto-invoked\nwithout explicit user interaction. When invoked, they collect and share webpage\ncontent, often the full HTML DOM and sometimes even the user's form inputs,\nwith their first-party servers. Some assistants also share identifiers and user\nprompts with third-party trackers such as Google Analytics. The collection and\nsharing continues even if a webpage contains sensitive information such as\nhealth or personal information such as name or SSN entered in a web form. We\nfind that several GenAI browser assistants infer demographic attributes such as\nage, gender, income, and interests and use this profile--which carries across\nbrowsing contexts--to personalize responses. In summary, our work shows that\nGenAI browser assistants can and do collect personal and sensitive information\nfor profiling and personalization with little to no safeguards.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.CY",
      "I.2; I.2.1; I.2.7; H.3.4; K.4; K.4.1; H.1; H.1.2; H.5.2; H.4.3"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16586v1",
    "published_date": "2025-03-20 16:21:47 UTC",
    "updated_date": "2025-03-20 16:21:47 UTC"
  },
  {
    "arxiv_id": "2503.16290v1",
    "title": "Diffusion-augmented Graph Contrastive Learning for Collaborative Filter",
    "authors": [
      "Fan Huang",
      "Wei Wang"
    ],
    "abstract": "Graph-based collaborative filtering has been established as a prominent\napproach in recommendation systems, leveraging the inherent graph topology of\nuser-item interactions to model high-order connectivity patterns and enhance\nrecommendation performance. Recent advances in Graph Contrastive Learning (GCL)\nhave demonstrated promising potential to alleviate data sparsity issues by\nimproving representation learning through contrastive view generation and\nmutual information maximization. However, existing approaches lack effective\ndata augmentation strategies. Structural augmentation risks distorting\nfundamental graph topology, while feature-level perturbation techniques\npredominantly employ uniform noise scales that fail to account for\nnode-specific characteristics. To solve these challenges, we propose\nDiffusion-augmented Contrastive Learning (DGCL), an innovative framework that\nintegrates diffusion models with contrastive learning for enhanced\ncollaborative filtering. Our approach employs a diffusion process that learns\nnode-specific Gaussian distributions of representations, thereby generating\nsemantically consistent yet diversified contrastive views through reverse\ndiffusion sampling. DGCL facilitates adaptive data augmentation based on\nreconstructed representations, considering both semantic coherence and\nnode-specific features. In addition, it explores unrepresented regions of the\nlatent sparse feature space, thereby enriching the diversity of contrastive\nviews. Extensive experimental results demonstrate the effectiveness of DGCL on\nthree public datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16290v1",
    "published_date": "2025-03-20 16:15:20 UTC",
    "updated_date": "2025-03-20 16:15:20 UTC"
  },
  {
    "arxiv_id": "2503.16248v2",
    "title": "Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents",
    "authors": [
      "Atharv Singh Patlan",
      "Peiyao Sheng",
      "S. Ashwin Hebbar",
      "Prateek Mittal",
      "Pramod Viswanath"
    ],
    "abstract": "The integration of AI agents with Web3 ecosystems harnesses their\ncomplementary potential for autonomy and openness yet also introduces\nunderexplored security risks, as these agents dynamically interact with\nfinancial protocols and immutable smart contracts. This paper investigates the\nvulnerabilities of AI agents within blockchain-based financial ecosystems when\nexposed to adversarial threats in real-world scenarios. We introduce the\nconcept of context manipulation, a comprehensive attack vector that exploits\nunprotected context surfaces, including input channels, memory modules, and\nexternal data feeds.\n  Through empirical analysis of ElizaOS, a decentralized AI agent framework for\nautomated Web3 operations, we demonstrate how adversaries can manipulate\ncontext by injecting malicious instructions into prompts or historical\ninteraction records, leading to unintended asset transfers and protocol\nviolations which could be financially devastating.\n  To quantify these vulnerabilities, we design CrAIBench, a Web3\ndomain-specific benchmark that evaluates the robustness of AI agents against\ncontext manipulation attacks across 150+ realistic blockchain tasks, including\ntoken transfers, trading, bridges and cross-chain interactions and 500+ attack\ntest cases using context manipulation. We systematically assess attack and\ndefense strategies, analyzing factors like the influence of security prompts,\nreasoning models, and the effectiveness of alignment techniques.\n  Our findings show that prompt-based defenses are insufficient when\nadversaries corrupt stored context, achieving significant attack success rates\ndespite these defenses. Fine-tuning-based defenses offer a more robust\nalternative, substantially reducing attack success rates while preserving\nutility on single-step tasks. This research highlights the urgent need to\ndevelop AI agents that are both secure and fiduciarily responsible.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CR",
    "comment": "29 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16248v2",
    "published_date": "2025-03-20 15:44:31 UTC",
    "updated_date": "2025-04-30 20:40:47 UTC"
  },
  {
    "arxiv_id": "2503.16227v1",
    "title": "Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming",
    "authors": [
      "Jeremy C. -H. Wang",
      "Ming Hou",
      "David Dunwoody",
      "Marko Ilievski",
      "Justin Tomasi",
      "Edward Chao",
      "Carl Pigeon"
    ],
    "abstract": "This paper examines how trust is formed, maintained, or diminished over time\nin the context of human-autonomy teaming with an optionally piloted aircraft.\nWhereas traditional factor-based trust models offer a static representation of\nhuman confidence in technology, here we discuss how variations in the\nunderlying factors lead to variations in trust, trust thresholds, and human\nbehaviours. Over 200 hours of flight test data collected over a multi-year test\ncampaign from 2021 to 2023 were reviewed. The\ndispositional-situational-learned, process-performance-purpose, and IMPACTS\nhomeostasis trust models are applied to illuminate trust trends during nominal\nautonomous flight operations. The results offer promising directions for future\nstudies on trust dynamics and design-for-trust in human-autonomy teaming.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.HC",
    "comment": "IEEE International Conference on Human-Machine Systems 2025,\n  keywords: trust, human factors, aviation, safety-critical, human-autonomy\n  teaming",
    "pdf_url": "http://arxiv.org/pdf/2503.16227v1",
    "published_date": "2025-03-20 15:22:39 UTC",
    "updated_date": "2025-03-20 15:22:39 UTC"
  },
  {
    "arxiv_id": "2503.16212v1",
    "title": "MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion",
    "authors": [
      "Qizhi Pei",
      "Lijun Wu",
      "Zhuoshi Pan",
      "Yu Li",
      "Honglin Lin",
      "Chenlin Ming",
      "Xin Gao",
      "Conghui He",
      "Rui Yan"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive progress in mathematical\nreasoning. While data augmentation is promising to enhance mathematical\nproblem-solving ability, current approaches are predominantly limited to\ninstance-level modifications-such as rephrasing or generating syntactic\nvariations-which fail to capture and leverage the intrinsic relational\nstructures inherent in mathematical knowledge. Inspired by human learning\nprocesses, where mathematical proficiency develops through systematic exposure\nto interconnected concepts, we introduce MathFusion, a novel framework that\nenhances mathematical reasoning through cross-problem instruction synthesis.\nMathFusion implements this through three fusion strategies: (1) sequential\nfusion, which chains related problems to model solution dependencies; (2)\nparallel fusion, which combines analogous problems to reinforce conceptual\nunderstanding; and (3) conditional fusion, which creates context-aware\nselective problems to enhance reasoning flexibility. By applying these\nstrategies, we generate a new dataset, \\textbf{MathFusionQA}, followed by\nfine-tuning models (DeepSeekMath-7B, Mistral-7B, Llama3-8B) on it. Experimental\nresults demonstrate that MathFusion achieves substantial improvements in\nmathematical reasoning while maintaining high data efficiency, boosting\nperformance by 18.0 points in accuracy across diverse benchmarks while\nrequiring only 45K additional synthetic instructions, representing a\nsubstantial improvement over traditional single-instruction approaches. Our\ndatasets, models, and code are publicly available at\nhttps://github.com/QizhiPei/mathfusion.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.16212v1",
    "published_date": "2025-03-20 15:00:41 UTC",
    "updated_date": "2025-03-20 15:00:41 UTC"
  },
  {
    "arxiv_id": "2503.16203v1",
    "title": "Logic Explanation of AI Classifiers by Categorical Explaining Functors",
    "authors": [
      "Stefano Fioravanti",
      "Francesco Giannini",
      "Paolo Frazzetto",
      "Fabio Zanasi",
      "Pietro Barbiero"
    ],
    "abstract": "The most common methods in explainable artificial intelligence are post-hoc\ntechniques which identify the most relevant features used by pretrained opaque\nmodels. Some of the most advanced post hoc methods can generate explanations\nthat account for the mutual interactions of input features in the form of logic\nrules. However, these methods frequently fail to guarantee the consistency of\nthe extracted explanations with the model's underlying reasoning. To bridge\nthis gap, we propose a theoretically grounded approach to ensure coherence and\nfidelity of the extracted explanations, moving beyond the limitations of\ncurrent heuristic-based approaches. To this end, drawing from category theory,\nwe introduce an explaining functor which structurally preserves logical\nentailment between the explanation and the opaque model's reasoning. As a proof\nof concept, we validate the proposed theoretical constructions on a synthetic\nbenchmark verifying how the proposed approach significantly mitigates the\ngeneration of contradictory or unfaithful explanations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16203v1",
    "published_date": "2025-03-20 14:50:06 UTC",
    "updated_date": "2025-03-20 14:50:06 UTC"
  },
  {
    "arxiv_id": "2503.16191v1",
    "title": "Large Language Models for Water Distribution Systems Modeling and Decision-Making",
    "authors": [
      "Yinon Goldshtein",
      "Gal Perelman",
      "Assaf Schuster",
      "Avi Ostfeld"
    ],
    "abstract": "The design, operations, and management of water distribution systems (WDS)\ninvolve complex mathematical models. These models are continually improving due\nto computational advancements, leading to better decision-making and more\nefficient WDS management. However, the significant time and effort required for\nmodeling, programming, and analyzing results remain substantial challenges.\nAnother issue is the professional burden, which confines the interaction with\nmodels, databases, and other sophisticated tools to a small group of experts,\nthereby causing non-technical stakeholders to depend on these experts or make\ndecisions without modeling support. Furthermore, explaining model results is\nchallenging even for experts, as it is often unclear which conditions cause the\nmodel to reach a certain state or recommend a specific policy. The recent\nadvancements in Large Language Models (LLMs) open doors for a new stage in\nhuman-model interaction. This study proposes a framework of plain language\ninteractions with hydraulic and water quality models based on LLM-EPANET\narchitecture. This framework is tested with increasing levels of complexity of\nqueries to study the ability of LLMs to interact with WDS models, run complex\nsimulations, and report simulation results. The performance of the proposed\nframework is evaluated across several categories of queries and hyper-parameter\nconfigurations, demonstrating its potential to enhance decision-making\nprocesses in WDS management.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to EWRI Congress 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16191v1",
    "published_date": "2025-03-20 14:39:11 UTC",
    "updated_date": "2025-03-20 14:39:11 UTC"
  },
  {
    "arxiv_id": "2503.16184v1",
    "title": "Accurate Scene Text Recognition with Efficient Model Scaling and Cloze Self-Distillation",
    "authors": [
      "Andrea Maracani",
      "Savas Ozkan",
      "Sijun Cho",
      "Hyowon Kim",
      "Eunchung Noh",
      "Jeongwon Min",
      "Cho Jung Min",
      "Dookun Park",
      "Mete Ozay"
    ],
    "abstract": "Scaling architectures have been proven effective for improving Scene Text\nRecognition (STR), but the individual contribution of vision encoder and text\ndecoder scaling remain under-explored. In this work, we present an in-depth\nempirical analysis and demonstrate that, contrary to previous observations,\nscaling the decoder yields significant performance gains, always exceeding\nthose achieved by encoder scaling alone. We also identify label noise as a key\nchallenge in STR, particularly in real-world data, which can limit the\neffectiveness of STR models. To address this, we propose Cloze\nSelf-Distillation (CSD), a method that mitigates label noise by distilling a\nstudent model from context-aware soft predictions and pseudolabels generated by\na teacher model. Additionally, we enhance the decoder architecture by\nintroducing differential cross-attention for STR. Our methodology achieves\nstate-of-the-art performance on 10 out of 11 benchmarks using only real data,\nwhile significantly reducing the parameter size and computational costs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16184v1",
    "published_date": "2025-03-20 14:35:46 UTC",
    "updated_date": "2025-03-20 14:35:46 UTC"
  },
  {
    "arxiv_id": "2503.16583v1",
    "title": "Explainable AI-Guided Efficient Approximate DNN Generation for Multi-Pod Systolic Arrays",
    "authors": [
      "Ayesha Siddique",
      "Khurram Khalil",
      "Khaza Anuarul Hoque"
    ],
    "abstract": "Approximate deep neural networks (AxDNNs) are promising for enhancing energy\nefficiency in real-world devices. One of the key contributors behind this\nenhanced energy efficiency in AxDNNs is the use of approximate multipliers.\nUnfortunately, the simulation of approximate multipliers does not usually scale\nwell on CPUs and GPUs. As a consequence, this slows down the overall simulation\nof AxDNNs aimed at identifying the appropriate approximate multipliers to\nachieve high energy efficiency with a minimum accuracy loss. To address this\nproblem, we present a novel XAI-Gen methodology, which leverages the analytical\nmodel of the emerging hardware accelerator (e.g., Google TPU v4) and\nexplainable artificial intelligence (XAI) to precisely identify the\nnon-critical layers for approximation and quickly discover the appropriate\napproximate multipliers for AxDNN layers. Our results show that XAI-Gen\nachieves up to 7x lower energy consumption with only 1-2% accuracy loss. We\nalso showcase the effectiveness of the XAI-Gen approach through a neural\narchitecture search (XAI-NAS) case study. Interestingly, XAI-NAS achieves 40\\%\nhigher energy efficiency with up to 5x less execution time when compared to the\nstate-of-the-art NAS methods for generating AxDNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted in the ISQED 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2503.16583v1",
    "published_date": "2025-03-20 14:26:47 UTC",
    "updated_date": "2025-03-20 14:26:47 UTC"
  },
  {
    "arxiv_id": "2503.16161v1",
    "title": "Towards Lighter and Robust Evaluation for Retrieval Augmented Generation",
    "authors": [
      "Alex-Razvan Ispas",
      "Charles-Elie Simon",
      "Fabien Caspani",
      "Vincent Guigue"
    ],
    "abstract": "Large Language Models are prompting us to view more NLP tasks from a\ngenerative perspective. At the same time, they offer a new way of accessing\ninformation, mainly through the RAG framework. While there have been notable\nimprovements for the autoregressive models, overcoming hallucination in the\ngenerated answers remains a continuous problem. A standard solution is to use\ncommercial LLMs, such as GPT4, to evaluate these algorithms. However, such\nframeworks are expensive and not very transparent. Therefore, we propose a\nstudy which demonstrates the interest of open-weight models for evaluating RAG\nhallucination. We develop a lightweight approach using smaller, quantized LLMs\nto provide an accessible and interpretable metric that gives continuous scores\nfor the generated answer with respect to their correctness and faithfulness.\nThis score allows us to question decisions' reliability and explore thresholds\nto develop a new AUC metric as an alternative to correlation with human\njudgment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "62-08",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 5 figures, published at 1st workshop of Quantify\n  Uncertainty and Hallucination in Foundation Models: The Next Frontier in\n  Reliable AI at ICLR 25",
    "pdf_url": "http://arxiv.org/pdf/2503.16161v1",
    "published_date": "2025-03-20 13:58:32 UTC",
    "updated_date": "2025-03-20 13:58:32 UTC"
  },
  {
    "arxiv_id": "2503.16159v1",
    "title": "Neural Combinatorial Optimization for Real-World Routing",
    "authors": [
      "Jiwoo Son",
      "Zhikai Zhao",
      "Federico Berto",
      "Chuanbo Hua",
      "Changhyun Kwon",
      "Jinkyoo Park"
    ],
    "abstract": "Vehicle Routing Problems (VRPs) are a class of NP-hard problems ubiquitous in\nseveral real-world logistics scenarios that pose significant challenges for\noptimization. Neural Combinatorial Optimization (NCO) has emerged as a\npromising alternative to classical approaches, as it can learn fast heuristics\nto solve VRPs. However, most research works in NCO for VRPs focus on simplified\nsettings, which do not account for asymmetric distances and travel durations\nthat cannot be derived by simple Euclidean distances and unrealistic data\ndistributions, hindering real-world deployment. This work introduces RRNCO\n(Real Routing NCO) to bridge the gap of NCO between synthetic and real-world\nVRPs in the critical aspects of both data and modeling. First, we introduce a\nnew, openly available dataset with real-world data containing a diverse dataset\nof locations, distances, and duration matrices from 100 cities, considering\nrealistic settings with actual routing distances and durations obtained from\nOpen Source Routing Machine (OSRM). Second, we propose a novel approach that\nefficiently processes both node and edge features through contextual gating,\nenabling the construction of more informed node embedding, and we finally\nincorporate an Adaptation Attention Free Module (AAFM) with neural adaptive\nbias mechanisms that effectively integrates not only distance matrices but also\nangular relationships between nodes, allowing our model to capture rich\nstructural information. RRNCO achieves state-of-the-art results in real-world\nVRPs among NCO methods. We make our dataset and code publicly available at\nhttps://github.com/ai4co/real-routing-nco.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16159v1",
    "published_date": "2025-03-20 13:57:33 UTC",
    "updated_date": "2025-03-20 13:57:33 UTC"
  },
  {
    "arxiv_id": "2503.16144v1",
    "title": "Unify and Triumph: Polyglot, Diverse, and Self-Consistent Generation of Unit Tests with LLMs",
    "authors": [
      "Djamel Eddine Khelladi",
      "Charly Reux",
      "Mathieu Acher"
    ],
    "abstract": "Large language model (LLM)-based test generation has gained attention in\nsoftware engineering, yet most studies evaluate LLMs' ability to generate unit\ntests in a single attempt for a given language, missing the opportunity to\nleverage LLM diversity for more robust testing. This paper introduces PolyTest,\na novel approach that enhances test generation by exploiting polyglot and\ntemperature-controlled diversity. PolyTest systematically leverages these\nproperties in two complementary ways: (1) Cross-lingual test generation, where\ntests are generated in multiple languages at zero temperature and then unified;\n(2) Diverse test sampling, where multiple test sets are generated within the\nsame language at a higher temperature before unification. A key insight is that\nLLMs can generate diverse yet contradicting tests -- same input, different\nexpected outputs -- across languages and generations. PolyTest mitigates\ninconsistencies by unifying test sets, fostering self-consistency and improving\noverall test quality. Unlike single-language or single-attempt approaches,\nPolyTest enhances testing without requiring on-the-fly execution, making it\nparticularly beneficial for weaker-performing languages. We evaluate PolyTest\non Llama3-70B, GPT-4o, and GPT-3.5 using EvalPlus, generating tests in five\nlanguages (Java, C, Python, JavaScript, and a CSV-based format) at temperature\n0 and sampling multiple sets at temperature 1. We observe that LLMs frequently\ngenerate contradicting tests across settings, and that PolyTest significantly\nimproves test quality across all considered metrics -- number of tests, passing\nrate, statement/branch coverage (up to +9.01%), and mutation score (up to\n+11.23%). Finally, PolyTest outperforms Pynguin in test generation, passing\nrate, and mutation score.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16144v1",
    "published_date": "2025-03-20 13:47:06 UTC",
    "updated_date": "2025-03-20 13:47:06 UTC"
  },
  {
    "arxiv_id": "2504.03669v1",
    "title": "Self-Learning-Based Optimization for Free-form Pipe Routing in Aeroengine with Dynamic Design Environment",
    "authors": [
      "Caicheng Wang",
      "Zili Wang",
      "Shuyou Zhang",
      "Yongzhe Xiang",
      "Zheyi Li",
      "Jianrong Tan"
    ],
    "abstract": "Pipe routing is a highly complex, time-consuming, and no-deterministic\npolynomial-time hard (NP-hard) problem in aeroengine design. Despite extensive\nresearch efforts in optimizing constant-curvature pipe routing, the growing\ndemand for free-form pipes poses new challenges. Dynamic design environments\nand fuzzy layout rules further impact the optimization performance and\nefficiency. To tackle these challenges, this study proposes a\nself-learning-based method (SLPR) for optimizing free-form pipe routing in\naeroengines. The SLPR is based on the proximal policy optimization (PPO)\nalgorithm and integrates a unified rule modeling framework for efficient\nobstacle detection and fuzzy rule modeling in continuous space. Additionally, a\npotential energy table is constructed to enable rapid queries of layout\ntendencies and interference. The agent within SLPR iteratively refines pipe\nrouting and accumulates the design knowledge through interaction with the\nenvironment. Once the design environment shifts, the agent can swiftly adapt by\nfine-tuning network parameters. Comparative tests reveal that SLPR ensures\nsmooth pipe routing through cubic non-uniform B-spline (NURBS) curves, avoiding\nredundant pipe segments found in constant-curvature pipe routing. Results in\nboth static and dynamic design environments demonstrate that SLPR outperforms\nthree representative baselines in terms of the pipe length reduction, the\nadherence to layout rules, the path complexity, and the computational\nefficiency. Furthermore, tests in dynamic environments indicate that SLPR\neliminates labor-intensive searches from scratch and even yields superior\nsolutions compared to the retrained model. These results highlight the\npractical value of SLPR for real-world pipe routing, meeting lightweight,\nprecision, and sustainability requirements of the modern aeroengine design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "J.0; J.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03669v1",
    "published_date": "2025-03-20 13:45:13 UTC",
    "updated_date": "2025-03-20 13:45:13 UTC"
  },
  {
    "arxiv_id": "2503.16582v1",
    "title": "Machine Learning-Based Genomic Linguistic Analysis (Gene Sequence Feature Learning): A Case Study on Predicting Heavy Metal Response Genes in Rice",
    "authors": [
      "Ruiqi Yang",
      "Jianxu Wang",
      "Wei Yuan",
      "Xun Wang",
      "Mei Li"
    ],
    "abstract": "This study explores the application of machine learning-based genetic\nlinguistics for identifying heavy metal response genes in rice (Oryza sativa).\nBy integrating convolutional neural networks and random forest algorithms, we\ndeveloped a hybrid model capable of extracting and learning meaningful features\nfrom gene sequences, such as k-mer frequencies and physicochemical properties.\nThe model was trained and tested on datasets of genes, achieving high\npredictive performance (precision: 0.89, F1-score: 0.82). RNA-seq and qRT-PCR\nexperiments conducted on rice leaves which exposed to Hg0, revealed\ndifferential expression of genes associated with heavy metal responses, which\nvalidated the model's predictions. Co-expression network analysis identified\n103 related genes, and a literature review indicated that these genes are\nhighly likely to be involved in heavy metal-related biological processes. By\nintegrating and comparing the analysis results with those of differentially\nexpressed genes (DEGs), the validity of the new machine learning method was\nfurther demonstrated. This study highlights the efficacy of combining machine\nlearning with genetic linguistics for large-scale gene prediction. It\ndemonstrates a cost-effective and efficient approach for uncovering molecular\nmechanisms underlying heavy metal responses, with potential applications in\ndeveloping stress-tolerant crop varieties.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16582v1",
    "published_date": "2025-03-20 13:41:31 UTC",
    "updated_date": "2025-03-20 13:41:31 UTC"
  },
  {
    "arxiv_id": "2503.16581v1",
    "title": "Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models",
    "authors": [
      "Zahra Khalila",
      "Arbi Haza Nasution",
      "Winda Monika",
      "Aytug Onan",
      "Yohei Murakami",
      "Yasir Bin Ismail Radi",
      "Noor Mohammad Osmani"
    ],
    "abstract": "Accurate and contextually faithful responses are critical when applying large\nlanguage models (LLMs) to sensitive and domain-specific tasks, such as\nanswering queries related to quranic studies. General-purpose LLMs often\nstruggle with hallucinations, where generated responses deviate from\nauthoritative sources, raising concerns about their reliability in religious\ncontexts. This challenge highlights the need for systems that can integrate\ndomain-specific knowledge while maintaining response accuracy, relevance, and\nfaithfulness. In this study, we investigate 13 open-source LLMs categorized\ninto large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b,\nLlama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented\nGeneration (RAG) is used to make up for the problems that come with using\nseparate models. This research utilizes a descriptive dataset of Quranic surahs\nincluding the meanings, historical context, and qualities of the 114 surahs,\nallowing the model to gather relevant knowledge before responding. The models\nare evaluated using three key metrics set by human evaluators: context\nrelevance, answer faithfulness, and answer relevance. The findings reveal that\nlarge models consistently outperform smaller models in capturing query\nsemantics and producing accurate, contextually grounded responses. The\nLlama3.2:3b model, even though it is considered small, does very well on\nfaithfulness (4.619) and relevance (4.857), showing the promise of smaller\narchitectures that have been well optimized. This article examines the\ntrade-offs between model size, computational efficiency, and response quality\nwhile using LLMs in domain-specific applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, keywords: Large-language-models; retrieval-augmented\n  generation; question answering; Quranic studies; Islamic teachings",
    "pdf_url": "http://arxiv.org/pdf/2503.16581v1",
    "published_date": "2025-03-20 13:26:30 UTC",
    "updated_date": "2025-03-20 13:26:30 UTC"
  },
  {
    "arxiv_id": "2503.16112v2",
    "title": "PromptMobile: Efficient Promptus for Low Bandwidth Mobile Video Streaming",
    "authors": [
      "Liming Liu",
      "Jiangkai Wu",
      "Haoyang Wang",
      "Peiheng Wang",
      "Zongming Guo",
      "Xinggong Zhang"
    ],
    "abstract": "Traditional video compression algorithms exhibit significant quality\ndegradation at extremely low bitrates. Promptus emerges as a new paradigm for\nvideo streaming, substantially cutting down the bandwidth essential for video\nstreaming. However, Promptus is computationally intensive and can not run in\nreal-time on mobile devices. This paper presents PromptMobile, an efficient\nacceleration framework tailored for on-device Promptus. Specifically, we\npropose (1) a two-stage efficient generation framework to reduce computational\ncost by 8.1x, (2) a fine-grained inter-frame caching to reduce redundant\ncomputations by 16.6%, (3) system-level optimizations to further enhance\nefficiency. The evaluations demonstrate that compared with the original\nPromptus, PromptMobile achieves a 13.6x increase in image generation speed.\nCompared with other streaming methods, PromptMobile achives an average LPIPS\nimprovement of 0.016 (compared with H.265), reducing 60% of severely distorted\nframes (compared to VQGAN).",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.NI",
    "comment": "6 pages (excluding references), 10 figures, to appear in APNET 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16112v2",
    "published_date": "2025-03-20 13:00:36 UTC",
    "updated_date": "2025-05-15 03:27:28 UTC"
  },
  {
    "arxiv_id": "2503.16091v1",
    "title": "AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence",
    "authors": [
      "Abdullah Mamun",
      "Diane J. Cook",
      "Hassan Ghasemzadeh"
    ],
    "abstract": "Adherence to prescribed treatments is crucial for individuals with chronic\nconditions to avoid costly or adverse health outcomes. For certain patient\ngroups, intensive lifestyle interventions are vital for enhancing medication\nadherence. Accurate forecasting of treatment adherence can open pathways to\ndeveloping an on-demand intervention tool, enabling timely and personalized\nsupport. With the increasing popularity of smartphones and wearables, it is now\neasier than ever to develop and deploy smart activity monitoring systems.\nHowever, effective forecasting systems for treatment adherence based on\nwearable sensors are still not widely available. We close this gap by proposing\nAdherence Forecasting and Intervention with Machine Intelligence (AIMI). AIMI\nis a knowledge-guided adherence forecasting system that leverages smartphone\nsensors and previous medication history to estimate the likelihood of\nforgetting to take a prescribed medication. A user study was conducted with 27\nparticipants who took daily medications to manage their cardiovascular\ndiseases. We designed and developed CNN and LSTM-based forecasting models with\nvarious combinations of input features and found that LSTM models can forecast\nmedication adherence with an accuracy of 0.932 and an F-1 score of 0.936.\nMoreover, through a series of ablation studies involving convolutional and\nrecurrent neural network architectures, we demonstrate that leveraging known\nknowledge about future and personalized training enhances the accuracy of\nmedication adherence forecasting. Code available:\nhttps://github.com/ab9mamun/AIMI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16091v1",
    "published_date": "2025-03-20 12:32:35 UTC",
    "updated_date": "2025-03-20 12:32:35 UTC"
  },
  {
    "arxiv_id": "2503.16085v1",
    "title": "Allostatic Control of Persistent States in Spiking Neural Networks for perception and computation",
    "authors": [
      "Aung Htet",
      "Alejandro Rodriguez Jimenez",
      "Sarah Hamburg",
      "Alessandro Di Nuovo"
    ],
    "abstract": "We introduce a novel model for updating perceptual beliefs about the\nenvironment by extending the concept of Allostasis to the control of internal\nrepresentations. Allostasis is a fundamental regulatory mechanism observed in\nanimal physiology that orchestrates responses to maintain a dynamic equilibrium\nin bodily needs and internal states. In this paper, we focus on an application\nin numerical cognition, where a bump of activity in an attractor network is\nused as a spatial numerical representation. While existing neural networks can\nmaintain persistent states, to date, there is no unified framework for\ndynamically controlling spatial changes in neuronal activity in response to\nenvironmental changes. To address this, we couple a well known allostatic\nmicrocircuit, the Hammel model, with a ring attractor, resulting in a Spiking\nNeural Network architecture that can modulate the location of the bump as a\nfunction of some reference input. This localized activity in turn is used as a\nperceptual belief in a simulated subitization task a quick enumeration process\nwithout counting. We provide a general procedure to fine-tune the model and\ndemonstrate the successful control of the bump location. We also study the\nresponse time in the model with respect to changes in parameters and compare it\nwith biological data. Finally, we analyze the dynamics of the network to\nunderstand the selectivity and specificity of different neurons to distinct\ncategories present in the input. The results of this paper, particularly the\nmechanism for moving persistent states, are not limited to numerical cognition\nbut can be applied to a wide range of tasks involving similar representations.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16085v1",
    "published_date": "2025-03-20 12:28:08 UTC",
    "updated_date": "2025-03-20 12:28:08 UTC"
  },
  {
    "arxiv_id": "2503.16075v1",
    "title": "3-D Image-to-Image Fusion in Lightsheet Microscopy by Two-Step Adversarial Network: Contribution to the FuseMyCells Challenge",
    "authors": [
      "Marek Wodzinski",
      "Henning Müller"
    ],
    "abstract": "Lightsheet microscopy is a powerful 3-D imaging technique that addresses\nlimitations of traditional optical and confocal microscopy but suffers from a\nlow penetration depth and reduced image quality at greater depths. Multiview\nlightsheet microscopy improves 3-D resolution by combining multiple views but\nsimultaneously increasing the complexity and the photon budget, leading to\npotential photobleaching and phototoxicity. The FuseMyCells challenge,\norganized in conjunction with the IEEE ISBI 2025 conference, aims to benchmark\ndeep learning-based solutions for fusing high-quality 3-D volumes from single\n3-D views, potentially simplifying procedures and conserving the photon budget.\nIn this work, we propose a contribution to the FuseMyCells challenge based on a\ntwo-step procedure. The first step processes a downsampled version of the image\nto capture the entire region of interest, while the second step uses a\npatch-based approach for high-resolution inference, incorporating adversarial\nloss to enhance visual outcomes. This method addresses challenges related to\nhigh data resolution, the necessity of global context, and the preservation of\nhigh-frequency details. Experimental results demonstrate the effectiveness of\nour approach, highlighting its potential to improve 3-D image fusion quality\nand extend the capabilities of lightsheet microscopy. The average SSIM for the\nnucleus and membranes is greater than 0.85 and 0.91, respectively.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16075v1",
    "published_date": "2025-03-20 12:12:01 UTC",
    "updated_date": "2025-03-20 12:12:01 UTC"
  },
  {
    "arxiv_id": "2503.16072v1",
    "title": "Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection",
    "authors": [
      "Sergey Berezin",
      "Reza Farahbakhsh",
      "Noel Crespi"
    ],
    "abstract": "The fundamental problem of toxicity detection lies in the fact that the term\n\"toxicity\" is ill-defined. Such uncertainty causes researchers to rely on\nsubjective and vague data during model training, which leads to non-robust and\ninaccurate results, following the 'garbage in - garbage out' paradigm. This\nstudy introduces a novel, objective, and context-aware framework for toxicity\ndetection, leveraging stress levels as a key determinant of toxicity. We\npropose new definition, metric and training approach as a parts of our\nframework and demonstrate it's effectiveness using a dataset we collected.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16072v1",
    "published_date": "2025-03-20 12:09:01 UTC",
    "updated_date": "2025-03-20 12:09:01 UTC"
  },
  {
    "arxiv_id": "2503.16071v1",
    "title": "Tuning LLMs by RAG Principles: Towards LLM-native Memory",
    "authors": [
      "Jiale Wei",
      "Shuchi Wu",
      "Ruochen Liu",
      "Xiang Ying",
      "Jingbo Shang",
      "Fangbo Tao"
    ],
    "abstract": "Memory, additional information beyond the training of large language models\n(LLMs), is crucial to various real-world applications, such as personal\nassistant. The two mainstream solutions to incorporate memory into the\ngeneration process are long-context LLMs and retrieval-augmented generation\n(RAG). In this paper, we first systematically compare these two types of\nsolutions on three renovated/new datasets and show that (1) long-context\nsolutions, although more expensive, shall be easier to capture the big picture\nand better answer queries which require considering the memory as a whole; and\n(2) when the queries concern specific information, RAG solutions shall be more\ncompetitive especially when the keywords can be explicitly matched. Therefore,\nwe propose a novel method RAG-Tuned-LLM which fine-tunes a relative small\n(e.g., 7B) LLM using the data generated following the RAG principles, so it can\ncombine the advantages of both solutions. Extensive experiments on three\ndatasets demonstrate that RAG-Tuned-LLM can beat long-context LLMs and RAG\nmethods across a wide range of query types.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16071v1",
    "published_date": "2025-03-20 12:04:40 UTC",
    "updated_date": "2025-03-20 12:04:40 UTC"
  },
  {
    "arxiv_id": "2503.16064v1",
    "title": "PromptHash: Affinity-Prompted Collaborative Cross-Modal Learning for Adaptive Hashing Retrieval",
    "authors": [
      "Qiang Zou",
      "Shuli Cheng",
      "Jiayi Chen"
    ],
    "abstract": "Cross-modal hashing is a promising approach for efficient data retrieval and\nstorage optimization. However, contemporary methods exhibit significant\nlimitations in semantic preservation, contextual integrity, and information\nredundancy, which constrains retrieval efficacy. We present PromptHash, an\ninnovative framework leveraging affinity prompt-aware collaborative learning\nfor adaptive cross-modal hashing. We propose an end-to-end framework for\naffinity-prompted collaborative hashing, with the following fundamental\ntechnical contributions: (i) a text affinity prompt learning mechanism that\npreserves contextual information while maintaining parameter efficiency, (ii)\nan adaptive gated selection fusion architecture that synthesizes State Space\nModel with Transformer network for precise cross-modal feature integration, and\n(iii) a prompt affinity alignment strategy that bridges modal heterogeneity\nthrough hierarchical contrastive learning. To the best of our knowledge, this\nstudy presents the first investigation into affinity prompt awareness within\ncollaborative cross-modal adaptive hash learning, establishing a paradigm for\nenhanced semantic consistency across modalities. Through comprehensive\nevaluation on three benchmark multi-label datasets, PromptHash demonstrates\nsubstantial performance improvements over existing approaches. Notably, on the\nNUS-WIDE dataset, our method achieves significant gains of 18.22% and 18.65% in\nimage-to-text and text-to-image retrieval tasks, respectively. The code is\npublicly available at https://github.com/ShiShuMo/PromptHash.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16064v1",
    "published_date": "2025-03-20 11:56:27 UTC",
    "updated_date": "2025-03-20 11:56:27 UTC"
  },
  {
    "arxiv_id": "2503.16063v1",
    "title": "Two-stage Incomplete Utterance Rewriting on Editing Operation",
    "authors": [
      "Zhiyu Cao",
      "Peifeng Li",
      "Qiaoming Zhu",
      "Yaxin Fan"
    ],
    "abstract": "Previous work on Incomplete Utterance Rewriting (IUR) has primarily focused\non generating rewritten utterances based solely on dialogue context, ignoring\nthe widespread phenomenon of coreference and ellipsis in dialogues. To address\nthis issue, we propose a novel framework called TEO (\\emph{Two-stage approach\non Editing Operation}) for IUR, in which the first stage generates editing\noperations and the second stage rewrites incomplete utterances utilizing the\ngenerated editing operations and the dialogue context. Furthermore, an\nadversarial perturbation strategy is proposed to mitigate cascading errors and\nexposure bias caused by the inconsistency between training and inference in the\nsecond stage. Experimental results on three IUR datasets show that our TEO\noutperforms the SOTA models significantly.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16063v1",
    "published_date": "2025-03-20 11:56:14 UTC",
    "updated_date": "2025-03-20 11:56:14 UTC"
  },
  {
    "arxiv_id": "2503.16057v2",
    "title": "Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts",
    "authors": [
      "Yike Yuan",
      "Ziyu Wang",
      "Zihao Huang",
      "Defa Zhu",
      "Xun Zhou",
      "Jingyi Yu",
      "Qiyang Min"
    ],
    "abstract": "Diffusion models have emerged as mainstream framework in visual generation.\nBuilding upon this success, the integration of Mixture of Experts (MoE) methods\nhas shown promise in enhancing model scalability and performance. In this\npaper, we introduce Race-DiT, a novel MoE model for diffusion transformers with\na flexible routing strategy, Expert Race. By allowing tokens and experts to\ncompete together and select the top candidates, the model learns to dynamically\nassign experts to critical tokens. Additionally, we propose per-layer\nregularization to address challenges in shallow layer learning, and router\nsimilarity loss to prevent mode collapse, ensuring better expert utilization.\nExtensive experiments on ImageNet validate the effectiveness of our approach,\nshowcasing significant performance gains while promising scaling properties.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16057v2",
    "published_date": "2025-03-20 11:45:08 UTC",
    "updated_date": "2025-03-25 08:56:54 UTC"
  },
  {
    "arxiv_id": "2503.16047v2",
    "title": "Temporal-Spatial Attention Network (TSAN) for DoS Attack Detection in Network Traffic",
    "authors": [
      "Bisola Faith Kayode",
      "Akinyemi Sadeeq Akintola",
      "Oluwole Fagbohun",
      "Egonna Anaesiuba-Bristol",
      "Onyekachukwu Ojumah",
      "Oluwagbade Odimayo",
      "Toyese Oloyede",
      "Aniema Inyang",
      "Teslim Kazeem",
      "Habeeb Alli",
      "Udodirim Ibem Offia",
      "Prisca Chinazor Amajuoyi"
    ],
    "abstract": "Denial-of-Service (DoS) attacks remain a critical threat to network security,\ndisrupting services and causing significant economic losses. Traditional\ndetection methods, including statistical and rule-based models, struggle to\nadapt to evolving attack patterns. To address this challenge, we propose a\nnovel Temporal-Spatial Attention Network (TSAN) architecture for detecting\nDenial of Service (DoS) attacks in network traffic. By leveraging both temporal\nand spatial features of network traffic, our approach captures complex traffic\npatterns and anomalies that traditional methods might miss. The TSAN model\nincorporates transformer-based temporal encoding, convolutional spatial\nencoding, and a cross-attention mechanism to fuse these complementary feature\nspaces. Additionally, we employ multi-task learning with auxiliary tasks to\nenhance the model's robustness. Experimental results on the NSL-KDD dataset\ndemonstrate that TSAN outperforms state-of-the-art models, achieving superior\naccuracy, precision, recall, and F1-score while maintaining computational\nefficiency for real-time deployment. The proposed architecture offers an\noptimal balance between detection accuracy and computational overhead, making\nit highly suitable for real-world network security applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "19 Pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.16047v2",
    "published_date": "2025-03-20 11:31:45 UTC",
    "updated_date": "2025-03-21 17:40:15 UTC"
  },
  {
    "arxiv_id": "2503.16045v1",
    "title": "Open Science and Artificial Intelligence for supporting the sustainability of the SRC Network: The espSRC case",
    "authors": [
      "J. Garrido",
      "S. Sánchez-Expósito",
      "A. Ruiz-Falcó",
      "J. Ruedas",
      "M. Á. Mendoza",
      "V. Vázquez",
      "M. Parra",
      "J. Sánchez",
      "I. Labadie",
      "L. Darriba",
      "J. Moldón",
      "M. Rodriguez-Álvarez",
      "J. Díaz",
      "L. Verdes-Montenegro"
    ],
    "abstract": "The SKA Observatory (SKAO), a landmark project in radio astronomy, seeks to\naddress fundamental questions in astronomy. To process its immense data output,\napproximately 700 PB/year, a global network of SKA Regional Centres (SR-CNet)\nwill provide the infrastructure, tools, computational power needed for\nscientific analysis and scientific support. The Spanish SRC (espSRC) focuses on\nensuring the sustainability of this network by reducing its environmental\nimpact, integrating green practices into data platforms, and developing Open\nScience technologies to enable reproducible research. This paper discusses and\nsummarizes part of the research and development activities that the team is\nconducting to reduce the SRC energy consumption at the espSRC and SRCNet. The\npaper also discusses fundamental research on trusted repositories to support\nOpen Science practices.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Conference: Astronomical Data Analysis Software & Systems - ADASS\n  XXXIV - 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.16045v1",
    "published_date": "2025-03-20 11:29:00 UTC",
    "updated_date": "2025-03-20 11:29:00 UTC"
  },
  {
    "arxiv_id": "2503.16043v1",
    "title": "Incomplete Utterance Rewriting with Editing Operation Guidance and Utterance Augmentation",
    "authors": [
      "Zhiyu Cao",
      "Peifeng Li",
      "Yaxin Fan",
      "Qiaoming Zhu"
    ],
    "abstract": "Although existing fashionable generation methods on Incomplete Utterance\nRewriting (IUR) can generate coherent utterances, they often result in the\ninclusion of irrelevant and redundant tokens in rewritten utterances due to\ntheir inability to focus on critical tokens in dialogue context. Furthermore,\nthe limited size of the training datasets also contributes to the insufficient\ntraining of the IUR model. To address the first issue, we propose a multi-task\nlearning framework EO-IUR (Editing Operation-guided Incomplete Utterance\nRewriting) that introduces the editing operation labels generated by sequence\nlabeling module to guide generation model to focus on critical tokens.\nFurthermore, we introduce a token-level heterogeneous graph to represent\ndialogues. To address the second issue, we propose a two-dimensional utterance\naugmentation strategy, namely editing operation-based incomplete utterance\naugmentation and LLM-based historical utterance augmentation. The experimental\nresults on three datasets demonstrate that our EO-IUR outperforms previous\nstate-of-the-art (SOTA) baselines in both open-domain and task-oriented\ndialogue. The code will be available at https://github.com/Dewset/EO-IUR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16043v1",
    "published_date": "2025-03-20 11:26:46 UTC",
    "updated_date": "2025-03-20 11:26:46 UTC"
  },
  {
    "arxiv_id": "2503.16041v2",
    "title": "GreenIQ: A Deep Search Platform for Comprehensive Carbon Market Analysis and Automated Report Generation",
    "authors": [
      "Oluwole Fagbohun",
      "Sai Yashwanth",
      "Akinyemi Sadeeq Akintola",
      "Ifeoluwa Wurola",
      "Lanre Shittu",
      "Aniema Inyang",
      "Oluwatimilehin Odubola",
      "Udodirim Offia",
      "Said Olanrewaju",
      "Ogidan Toluwaleke",
      "Ilemona Abutu",
      "Taiwo Akinbolaji"
    ],
    "abstract": "This study introduces GreenIQ, an AI-powered deep search platform designed to\nrevolutionise carbon market intelligence through autonomous analysis and\nautomated report generation. Carbon markets operate across diverse regulatory\nlandscapes, generating vast amounts of heterogeneous data from policy\ndocuments, industry reports, academic literature, and real-time trading\nplatforms. Traditional research approaches remain labour-intensive, slow, and\ndifficult to scale. GreenIQ addresses these limitations through a multi-agent\narchitecture powered by Large Language Models (LLMs), integrating five\nspecialised AI agents: a Main Researcher Agent for intelligent information\nretrieval, a Report Writing Agent for structured synthesis, a Final Reviewer\nAgent for accuracy verification, a Data Visualisation Agent for enhanced\ninterpretability, and a Translator Agent for multilingual adaptation. The\nsystem achieves seamless integration of structured and unstructured information\nwith AI-driven citation verification, ensuring high transparency and\nreliability. GreenIQ delivers a 99.2\\% reduction in processing time and a\n99.7\\% cost reduction compared to traditional research methodologies. A novel\nAI persona-based evaluation framework involving 16 domain-specific AI personas\nhighlights its superior cross-jurisdictional analytical capabilities and\nregulatory insight generation. GreenIQ sets new standards in AI-driven research\nsynthesis, policy analysis, and sustainability finance by streamlining carbon\nmarket research. It offers an efficient and scalable framework for\nenvironmental and financial intelligence, enabling more accurate, timely, and\ncost-effective decision-making in complex regulatory landscapes",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 Pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.16041v2",
    "published_date": "2025-03-20 11:19:43 UTC",
    "updated_date": "2025-03-21 17:33:33 UTC"
  },
  {
    "arxiv_id": "2503.16036v1",
    "title": "Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models",
    "authors": [
      "Zhihang Liu",
      "Chen-Wei Xie",
      "Pandeng Li",
      "Liming Zhao",
      "Longxiang Tang",
      "Yun Zheng",
      "Chuanbin Liu",
      "Hongtao Xie"
    ],
    "abstract": "Recent Multi-modal Large Language Models (MLLMs) have been challenged by the\ncomputational overhead resulting from massive video frames, often alleviated\nthrough compression strategies. However, the visual content is not equally\ncontributed to user instructions, existing strategies (\\eg, average pool)\ninevitably lead to the loss of potentially useful information. To tackle this,\nwe propose the Hybrid-level Instruction Injection Strategy for Conditional\nToken Compression in MLLMs (HICom), utilizing the instruction as a condition to\nguide the compression from both local and global levels. This encourages the\ncompression to retain the maximum amount of user-focused information while\nreducing visual tokens to minimize computational burden. Specifically, the\ninstruction condition is injected into the grouped visual tokens at the local\nlevel and the learnable tokens at the global level, and we conduct the\nattention mechanism to complete the conditional compression. From the\nhybrid-level compression, the instruction-relevant visual parts are highlighted\nwhile the temporal-spatial structure is also preserved for easier understanding\nof LLMs. To further unleash the potential of HICom, we introduce a new\nconditional pre-training stage with our proposed dataset HICom-248K.\nExperiments show that our HICom can obtain distinguished video understanding\nability with fewer tokens, increasing the performance by 2.43\\% average on\nthree multiple-choice QA benchmarks and saving 78.8\\% tokens compared with the\nSOTA method. The code is available at https://github.com/lntzm/HICom.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.16036v1",
    "published_date": "2025-03-20 11:09:18 UTC",
    "updated_date": "2025-03-20 11:09:18 UTC"
  },
  {
    "arxiv_id": "2503.16025v1",
    "title": "Single Image Iterative Subject-driven Generation and Editing",
    "authors": [
      "Yair Shpitzer",
      "Gal Chechik",
      "Idan Schwartz"
    ],
    "abstract": "Personalizing image generation and editing is particularly challenging when\nwe only have a few images of the subject, or even a single image. A common\napproach to personalization is concept learning, which can integrate the\nsubject into existing models relatively quickly, but produces images whose\nquality tends to deteriorate quickly when the number of subject images is\nsmall. Quality can be improved by pre-training an encoder, but training\nrestricts generation to the training distribution, and is time consuming. It is\nstill an open hard challenge to personalize image generation and editing from a\nsingle image without training. Here, we present SISO, a novel, training-free\napproach based on optimizing a similarity score with an input subject image.\nMore specifically, SISO iteratively generates images and optimizes the model\nbased on loss of similarity with the given subject image until a satisfactory\nlevel of similarity is achieved, allowing plug-and-play optimization to any\nimage generator. We evaluated SISO in two tasks, image editing and image\ngeneration, using a diverse data set of personal subjects, and demonstrate\nsignificant improvements over existing methods in image quality, subject\nfidelity, and background preservation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page is at https://siso-paper.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2503.16025v1",
    "published_date": "2025-03-20 10:45:04 UTC",
    "updated_date": "2025-03-20 10:45:04 UTC"
  },
  {
    "arxiv_id": "2503.16024v1",
    "title": "The Lighthouse of Language: Enhancing LLM Agents via Critique-Guided Improvement",
    "authors": [
      "Ruihan Yang",
      "Fanghua Ye",
      "Jian Li",
      "Siyu Yuan",
      "Yikai Zhang",
      "Zhaopeng Tu",
      "Xiaolong Li",
      "Deqing Yang"
    ],
    "abstract": "Large language models (LLMs) have recently transformed from text-based\nassistants to autonomous agents capable of planning, reasoning, and iteratively\nimproving their actions. While numerical reward signals and verifiers can\neffectively rank candidate actions, they often provide limited contextual\nguidance. In contrast, natural language feedback better aligns with the\ngenerative capabilities of LLMs, providing richer and more actionable\nsuggestions. However, parsing and implementing this feedback effectively can be\nchallenging for LLM-based agents. In this work, we introduce Critique-Guided\nImprovement (CGI), a novel two-player framework, comprising an actor model that\nexplores an environment and a critic model that generates detailed nature\nlanguage feedback. By training the critic to produce fine-grained assessments\nand actionable revisions, and the actor to utilize these critiques, our\napproach promotes more robust exploration of alternative strategies while\navoiding local optima. Experiments in three interactive environments show that\nCGI outperforms existing baselines by a substantial margin. Notably, even a\nsmall critic model surpasses GPT-4 in feedback quality. The resulting actor\nachieves state-of-the-art performance, demonstrating the power of explicit\niterative guidance to enhance decision-making in LLM-based agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16024v1",
    "published_date": "2025-03-20 10:42:33 UTC",
    "updated_date": "2025-03-20 10:42:33 UTC"
  },
  {
    "arxiv_id": "2503.16021v3",
    "title": "Autonomous AI imitators increase diversity in homogeneous information ecosystems",
    "authors": [
      "Emil Bakkensen Johansen",
      "Oliver Baumann"
    ],
    "abstract": "Recent breakthroughs in large language models (LLMs) have facilitated\nautonomous AI agents capable of imitating human-generated content. This\ntechnological advancement raises fundamental questions about AI's impact on the\ndiversity and democratic value of information ecosystems. We introduce a\nlarge-scale simulation framework to examine AI-based imitation within news, a\ncontext crucial for public discourse. By systematically testing two distinct\nimitation strategies across a range of information environments varying in\ninitial diversity, we demonstrate that AI-generated articles do not uniformly\nhomogenize content. Instead, AI's influence is strongly context-dependent:\nAI-generated content can introduce valuable diversity in originally homogeneous\nnews environments but diminish diversity in initially heterogeneous contexts.\nThese results illustrate that the initial diversity of an information\nenvironment critically shapes AI's impact, challenging assumptions that\nAI-driven imitation threatens diversity. Instead, when information is initially\nhomogeneous, AI-driven imitation can expand perspectives, styles, and topics.\nThis is especially important in news contexts, where information diversity\nfosters richer public debate by exposing citizens to alternative viewpoints,\nchallenging biases, and preventing narrative monopolies, which is essential for\na resilient democracy.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "J.4"
    ],
    "primary_category": "cs.CY",
    "comment": "42 pages, 11 figures, 4 tables; v2: corrected typographical errors,\n  streamlined language, updated abstract, added supplementary information; v3:\n  restructured appendix, added temperature and embeddings sensitivity checks",
    "pdf_url": "http://arxiv.org/pdf/2503.16021v3",
    "published_date": "2025-03-20 10:37:29 UTC",
    "updated_date": "2025-03-28 13:23:05 UTC"
  },
  {
    "arxiv_id": "2503.18964v1",
    "title": "Unifying EEG and Speech for Emotion Recognition: A Two-Step Joint Learning Framework for Handling Missing EEG Data During Inference",
    "authors": [
      "Upasana Tiwari",
      "Rupayan Chakraborty",
      "Sunil Kumar Kopparapu"
    ],
    "abstract": "Computer interfaces are advancing towards using multi-modalities to enable\nbetter human-computer interactions. The use of automatic emotion recognition\n(AER) can make the interactions natural and meaningful thereby enhancing the\nuser experience. Though speech is the most direct and intuitive modality for\nAER, it is not reliable because it can be intentionally faked by humans. On the\nother hand, physiological modalities like EEG, are more reliable and impossible\nto fake. However, use of EEG is infeasible for realistic scenarios usage\nbecause of the need for specialized recording setup. In this paper, one of our\nprimary aims is to ride on the reliability of the EEG modality to facilitate\nrobust AER on the speech modality. Our approach uses both the modalities during\ntraining to reliably identify emotion at the time of inference, even in the\nabsence of the more reliable EEG modality. We propose, a two-step joint\nmulti-modal learning approach (JMML) that exploits both the intra- and inter-\nmodal characteristics to construct emotion embeddings that enrich the\nperformance of AER. In the first step, using JEC-SSL, intra-modal learning is\ndone independently on the individual modalities. This is followed by an\ninter-modal learning using the proposed extended variant of deep canonically\ncorrelated cross-modal autoencoder (E-DCC-CAE). The approach learns the joint\nproperties of both the modalities by mapping them into a common representation\nspace, such that the modalities are maximally correlated. These emotion\nembeddings, hold properties of both the modalities there by enhancing the\nperformance of ML classifier used for AER. Experimental results show the\nefficacy of the proposed approach. To best of our knowledge, this is the first\nattempt to combine speech and EEG with joint multi-modal learning approach for\nreliable AER.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.18964v1",
    "published_date": "2025-03-20 10:26:49 UTC",
    "updated_date": "2025-03-20 10:26:49 UTC"
  },
  {
    "arxiv_id": "2503.16577v1",
    "title": "Feature selection strategies for optimized heart disease diagnosis using ML and DL models",
    "authors": [
      "Bilal Ahmad",
      "Jinfu Chen",
      "Haibao Chen"
    ],
    "abstract": "Heart disease remains one of the leading causes of morbidity and mortality\nworldwide, necessitating the development of effective diagnostic tools to\nenable early diagnosis and clinical decision-making. This study evaluates the\nimpact of feature selection techniques Mutual Information (MI), Analysis of\nVariance (ANOVA), and Chi-Square on the predictive performance of various\nmachine learning (ML) and deep learning (DL) models using a dataset of clinical\nindicators for heart disease. Eleven ML/DL models were assessed using metrics\nsuch as precision, recall, AUC score, F1-score, and accuracy. Results indicate\nthat MI outperformed other methods, particularly for advanced models like\nneural networks, achieving the highest accuracy of 82.3% and recall score of\n0.94. Logistic regression (accuracy 82.1%) and random forest (accuracy 80.99%)\nalso demonstrated improved performance with MI. Simpler models such as Naive\nBayes and decision trees achieved comparable results with ANOVA and Chi-Square,\nyielding accuracies of 76.45% and 75.99%, respectively, making them\ncomputationally efficient alternatives. Conversely, k Nearest Neighbors (KNN)\nand Support Vector Machines (SVM) exhibited lower performance, with accuracies\nranging between 51.52% and 54.43%, regardless of the feature selection method.\nThis study provides a comprehensive comparison of feature selection methods for\nheart disease prediction, demonstrating the critical role of feature selection\nin optimizing model performance. The results offer practical guidance for\nselecting appropriate feature selection techniques based on the chosen\nclassification algorithm, contributing to the development of more accurate and\nefficient diagnostic tools for enhanced clinical decision-making in cardiology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16577v1",
    "published_date": "2025-03-20 09:59:01 UTC",
    "updated_date": "2025-03-20 09:59:01 UTC"
  },
  {
    "arxiv_id": "2503.16575v1",
    "title": "Extract, Match, and Score: An Evaluation Paradigm for Long Question-context-answer Triplets in Financial Analysis",
    "authors": [
      "Bo Hu",
      "Han Yuan",
      "Vlad Pandelea",
      "Wuqiong Luo",
      "Yingzhu Zhao",
      "Zheng Ma"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has sparked widespread\nadoption across diverse applications, making robust evaluation frameworks\ncrucial for assessing their performance. While conventional evaluation metrics\nremain applicable for shorter texts, their efficacy diminishes when evaluating\nthe quality of long-form answers. This limitation is particularly critical in\nreal-world scenarios involving extended questions, extensive context, and\nlong-form answers, such as financial analysis or regulatory compliance. In this\npaper, we use a practical financial use case to illustrate applications that\nhandle \"long question-context-answer triplets\". We construct a real-world\nfinancial dataset comprising long triplets and demonstrate the inadequacies of\ntraditional metrics. To address this, we propose an effective Extract, Match,\nand Score (EMS) evaluation approach tailored to the complexities of long-form\nLLMs' outputs, providing practitioners with a reliable methodology for\nassessing LLMs' performance in complex real-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16575v1",
    "published_date": "2025-03-20 09:38:44 UTC",
    "updated_date": "2025-03-20 09:38:44 UTC"
  },
  {
    "arxiv_id": "2503.15985v1",
    "title": "Exploring the Reliability of Self-explanation and its Relationship with Classification in Language Model-driven Financial Analysis",
    "authors": [
      "Han Yuan",
      "Li Zhang",
      "Zheng Ma"
    ],
    "abstract": "Language models (LMs) have exhibited exceptional versatility in reasoning and\nin-depth financial analysis through their proprietary information processing\ncapabilities. Previous research focused on evaluating classification\nperformance while often overlooking explainability or pre-conceived that\nrefined explanation corresponds to higher classification accuracy. Using a\npublic dataset in finance domain, we quantitatively evaluated self-explanations\nby LMs, focusing on their factuality and causality. We identified the\nstatistically significant relationship between the accuracy of classifications\nand the factuality or causality of self-explanations. Our study built an\nempirical foundation for approximating classification confidence through\nself-explanations and for optimizing classification via proprietary reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15985v1",
    "published_date": "2025-03-20 09:33:59 UTC",
    "updated_date": "2025-03-20 09:33:59 UTC"
  },
  {
    "arxiv_id": "2503.16573v1",
    "title": "AUV Acceleration Prediction Using DVL and Deep Learning",
    "authors": [
      "Yair Stolero",
      "Itzik Klein"
    ],
    "abstract": "Autonomous underwater vehicles (AUVs) are essential for various applications,\nincluding oceanographic surveys, underwater mapping, and infrastructure\ninspections. Accurate and robust navigation are critical to completing these\ntasks. To this end, a Doppler velocity log (DVL) and inertial sensors are fused\ntogether. Recently, a model-based approach demonstrated the ability to extract\nthe vehicle acceleration vector from DVL velocity measurements. Motivated by\nthis advancement, in this paper we present an end-to-end deep learning approach\nto estimate the AUV acceleration vector based on past DVL velocity\nmeasurements. Based on recorded data from sea experiments, we demonstrate that\nthe proposed method improves acceleration vector estimation by more than 65%\ncompared to the model-based approach by using data-driven techniques. As a\nresult of our data-driven approach, we can enhance navigation accuracy and\nreliability in AUV applications, contributing to more efficient and effective\nunderwater missions through improved accuracy and reliability.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16573v1",
    "published_date": "2025-03-20 09:33:47 UTC",
    "updated_date": "2025-03-20 09:33:47 UTC"
  },
  {
    "arxiv_id": "2503.15984v1",
    "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration",
    "authors": [
      "Suraj Singh",
      "Anastasia Batsheva",
      "Oleg Y. Rogov",
      "Ahmed Bouridane"
    ],
    "abstract": "Contemporary image restoration and super-resolution techniques effectively\nharness deep neural networks, markedly outperforming traditional methods.\nHowever, astrophotography presents unique challenges for deep learning due to\nlimited training data. This work explores hybrid strategies, such as the Deep\nImage Prior (DIP) model, which facilitates blind training but is susceptible to\noverfitting, artifact generation, and instability when handling noisy images.\nWe propose enhancements to the DIP model's baseline performance through several\nadvanced techniques. First, we refine the model to process multiple frames\nconcurrently, employing the Back Projection method and the TVNet model. Next,\nwe adopt a Markov approach incorporating Monte Carlo estimation, Langevin\ndynamics, and a variational input technique to achieve unbiased estimates with\nminimal variance and counteract overfitting effectively. Collectively, these\nmodifications reduce the likelihood of noise learning and mitigate loss\nfunction fluctuations during training, enhancing result stability. We validated\nour algorithm across multiple image sets of astronomical and celestial objects,\nachieving performance that not only mitigates limitations of Lucky Imaging, a\nclassical computer vision technique that remains a standard in astronomical\nimage reconstruction but surpasses the original DIP model, state of the art\ntransformer- and diffusion-based models, underscoring the significance of our\nimprovements.",
    "categories": [
      "cs.CV",
      "astro-ph.IM",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.15984v1",
    "published_date": "2025-03-20 09:33:16 UTC",
    "updated_date": "2025-03-20 09:33:16 UTC"
  },
  {
    "arxiv_id": "2503.15983v1",
    "title": "InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer",
    "authors": [
      "Tony Zhang",
      "Rickard Brännvall"
    ],
    "abstract": "This work explores optimizing transformer-based language models by\nintegrating model compression techniques with inhibitor attention, a novel\nalternative attention mechanism. Inhibitor attention employs Manhattan\ndistances and ReLU activations instead of the matrix multiplications and\nsoftmax activation of the conventional scaled dot-product attention. This shift\noffers potential computational and energy savings while maintaining model\neffectiveness. We propose further adjustments to improve the inhibitor\nmechanism's training efficiency and evaluate its performance on the DistilBERT\narchitecture. Our knowledge distillation experiments indicate that the modified\ninhibitor transformer model can achieve competitive performance on standard NLP\nbenchmarks, including General Language Understanding Evaluation (GLUE) and\nsentiment analysis tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50 (Primary) 68T07, 68Q32 (Secondary)",
      "I.2.6; I.2.7; I.5.1"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.15983v1",
    "published_date": "2025-03-20 09:30:35 UTC",
    "updated_date": "2025-03-20 09:30:35 UTC"
  },
  {
    "arxiv_id": "2503.15969v1",
    "title": "Beyond the Visible: Multispectral Vision-Language Learning for Earth Observation",
    "authors": [
      "Clive Tinashe Marimo",
      "Benedikt Blumenstiel",
      "Maximilian Nitsche",
      "Johannes Jakubik",
      "Thomas Brunschwiler"
    ],
    "abstract": "Vision-language models for Earth observation (EO) typically rely on the\nvisual spectrum of data as the only model input, thus failing to leverage the\nrich spectral information available in the multispectral channels recorded by\nsatellites. Therefore, in this paper, we introduce Llama3-MS-CLIP, the first\nvision-language model pre-trained with contrastive learning on a large-scale\nmultispectral dataset and report on the performance gains due to the extended\nspectral range. Furthermore, we present the largest-to-date image-caption\ndataset for multispectral data, consisting of one million Sentinel-2 samples\nand corresponding textual descriptions generated with Llama3-LLaVA-Next and\nOverture Maps data. We develop a scalable captioning pipeline, which is\nvalidated by domain experts. We evaluate Llama3-MS-CLIP on multispectral\nzero-shot image classification and retrieval using three datasets of varying\ncomplexity. Our results demonstrate that Llama3-MS-CLIP significantly\noutperforms other RGB-based approaches, improving classification accuracy by\n6.77% on average and retrieval performance by 4.63% mAP compared to the\nsecond-best model. Our results emphasize the relevance of multispectral\nvision-language learning. We release the image-caption dataset, code, and model\nweights under an open-source license.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15969v1",
    "published_date": "2025-03-20 09:13:31 UTC",
    "updated_date": "2025-03-20 09:13:31 UTC"
  },
  {
    "arxiv_id": "2503.16572v1",
    "title": "Efficient ANN-Guided Distillation: Aligning Rate-based Features of Spiking Neural Networks through Hybrid Block-wise Replacement",
    "authors": [
      "Shu Yang",
      "Chengting Yu",
      "Lei Liu",
      "Hanzhi Ma",
      "Aili Wang",
      "Erping Li"
    ],
    "abstract": "Spiking Neural Networks (SNNs) have garnered considerable attention as a\npotential alternative to Artificial Neural Networks (ANNs). Recent studies have\nhighlighted SNNs' potential on large-scale datasets. For SNN training, two main\napproaches exist: direct training and ANN-to-SNN (ANN2SNN) conversion. To fully\nleverage existing ANN models in guiding SNN learning, either direct ANN-to-SNN\nconversion or ANN-SNN distillation training can be employed. In this paper, we\npropose an ANN-SNN distillation framework from the ANN-to-SNN perspective,\ndesigned with a block-wise replacement strategy for ANN-guided learning. By\ngenerating intermediate hybrid models that progressively align SNN feature\nspaces to those of ANN through rate-based features, our framework naturally\nincorporates rate-based backpropagation as a training method. Our approach\nachieves results comparable to or better than state-of-the-art SNN distillation\nmethods, showing both training and learning efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16572v1",
    "published_date": "2025-03-20 09:04:38 UTC",
    "updated_date": "2025-03-20 09:04:38 UTC"
  },
  {
    "arxiv_id": "2503.15953v1",
    "title": "GAN-enhanced Simulation-driven DNN Testing in Absence of Ground Truth",
    "authors": [
      "Mohammed Attaoui",
      "Fabrizio Pastore"
    ],
    "abstract": "The generation of synthetic inputs via simulators driven by search algorithms\nis essential for cost-effective testing of Deep Neural Network (DNN) components\nfor safety-critical systems. However, in many applications, simulators are\nunable to produce the ground-truth data needed for automated test oracles and\nto guide the search process.\n  To tackle this issue, we propose an approach for the generation of inputs for\ncomputer vision DNNs that integrates a generative network to ensure simulator\nfidelity and employs heuristic-based search fitnesses that leverage\ntransformation consistency, noise resistance, surprise adequacy, and\nuncertainty estimation. We compare the performance of our fitnesses with that\nof a traditional fitness function leveraging ground truth; further, we assess\nhow the integration of a GAN not leveraging the ground truth impacts on test\nand retraining effectiveness.\n  Our results suggest that leveraging transformation consistency is the best\noption to generate inputs for both DNN testing and retraining; it maximizes\ninput diversity, spots the inputs leading to worse DNN performance, and leads\nto best DNN performance after retraining. Besides enabling simulator-based\ntesting in the absence of ground truth, our findings pave the way for testing\nsolutions that replace costly simulators with diffusion and large language\nmodels, which might be more affordable than simulators, but cannot generate\nground-truth data.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "15 pages, 8 figures, 13 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.15953v1",
    "published_date": "2025-03-20 08:49:10 UTC",
    "updated_date": "2025-03-20 08:49:10 UTC"
  },
  {
    "arxiv_id": "2503.15948v1",
    "title": "Don't Fight Hallucinations, Use Them: Estimating Image Realism using NLI over Atomic Facts",
    "authors": [
      "Elisei Rykov",
      "Kseniia Petrushina",
      "Kseniia Titova",
      "Alexander Panchenko",
      "Vasily Konovalov"
    ],
    "abstract": "Quantifying the realism of images remains a challenging problem in the field\nof artificial intelligence. For example, an image of Albert Einstein holding a\nsmartphone violates common-sense because modern smartphone were invented after\nEinstein's death. We introduce a novel method for assessing image realism using\nLarge Vision-Language Models (LVLMs) and Natural Language Inference (NLI). Our\napproach is based on the premise that LVLMs may generate hallucinations when\nconfronted with images that defy common sense. Using LVLM to extract atomic\nfacts from these images, we obtain a mix of accurate facts and erroneous\nhallucinations. We proceed by calculating pairwise entailment scores among\nthese facts, subsequently aggregating these values to yield a singular reality\nscore. This process serves to identify contradictions between genuine facts and\nhallucinatory elements, signaling the presence of images that violate common\nsense. Our approach has achieved a new state-of-the-art performance in\nzero-shot mode on the WHOOPS! dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Proceedings of De-Factify 4: 4nd Workshop on Multimodal Fact Checking\n  and Hate Speech Detection, co-located with AAAI-2025",
    "pdf_url": "http://arxiv.org/pdf/2503.15948v1",
    "published_date": "2025-03-20 08:44:10 UTC",
    "updated_date": "2025-03-20 08:44:10 UTC"
  },
  {
    "arxiv_id": "2503.15947v1",
    "title": "Unreal-MAP: Unreal-Engine-Based General Platform for Multi-Agent Reinforcement Learning",
    "authors": [
      "Tianyi Hu",
      "Qingxu Fu",
      "Zhiqiang Pu",
      "Yuan Wang",
      "Tenghai Qiu"
    ],
    "abstract": "In this paper, we propose Unreal Multi-Agent Playground (Unreal-MAP), an MARL\ngeneral platform based on the Unreal-Engine (UE). Unreal-MAP allows users to\nfreely create multi-agent tasks using the vast visual and physical resources\navailable in the UE community, and deploy state-of-the-art (SOTA) MARL\nalgorithms within them. Unreal-MAP is user-friendly in terms of deployment,\nmodification, and visualization, and all its components are open-source. We\nalso develop an experimental framework compatible with algorithms ranging from\nrule-based to learning-based provided by third-party frameworks. Lastly, we\ndeploy several SOTA algorithms in example tasks developed via Unreal-MAP, and\nconduct corresponding experimental analyses. We believe Unreal-MAP can play an\nimportant role in the MARL field by closely integrating existing algorithms\nwith user-customized tasks, thus advancing the field of MARL.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15947v1",
    "published_date": "2025-03-20 08:40:41 UTC",
    "updated_date": "2025-03-20 08:40:41 UTC"
  },
  {
    "arxiv_id": "2503.15937v2",
    "title": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment",
    "authors": [
      "Gaole Dai",
      "Shiqi Jiang",
      "Ting Cao",
      "Yuanchun Li",
      "Yuqing Yang",
      "Rui Tan",
      "Mo Li",
      "Lili Qiu"
    ],
    "abstract": "We propose V-Droid, a mobile GUI task automation agent. Unlike previous\nmobile agents that utilize Large Language Models (LLMs) as generators to\ndirectly generate actions at each step, V-Droid employs LLMs as verifiers to\nevaluate candidate actions before making final decisions. To realize this novel\nparadigm, we introduce a comprehensive framework for constructing\nverifier-driven mobile agents: the discretized action space construction\ncoupled with the prefilling-only workflow to accelerate the verification\nprocess, the pair-wise progress preference training to significantly enhance\nthe verifier's decision-making capabilities, and the scalable human-agent joint\nannotation scheme to efficiently collect the necessary data at scale. V-Droid\nsets a new state-of-the-art task success rate across several public mobile task\nautomation benchmarks: 59.5% on AndroidWorld, 38.3% on AndroidLab, and 49% on\nMobileAgentBench, surpassing existing agents by 9.5%, 2.1%, and 9%,\nrespectively. Furthermore, V-Droid achieves an impressively low latency of 0.7\nseconds per step, making it the first mobile agent capable of delivering\nnear-real-time, effective decision-making capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 4 iterations, refine figs",
    "pdf_url": "http://arxiv.org/pdf/2503.15937v2",
    "published_date": "2025-03-20 08:25:00 UTC",
    "updated_date": "2025-03-21 03:19:57 UTC"
  },
  {
    "arxiv_id": "2503.15924v1",
    "title": "Towards Automatic Continual Learning: A Self-Adaptive Framework for Continual Instruction Tuning",
    "authors": [
      "Peiyi Lin",
      "Fukai Zhang",
      "Kai Niu",
      "Hao Fu"
    ],
    "abstract": "Continual instruction tuning enables large language models (LLMs) to learn\nincrementally while retaining past knowledge, whereas existing methods\nprimarily focus on how to retain old knowledge rather than on selecting which\nnew knowledge to learn. In domain-specific contexts, maintaining data quality\nand managing system constraints remain key challenges. To address these issues,\nwe propose an automated continual instruction tuning framework that dynamically\nfilters incoming data, which identify and reduce redundant data across\nsuccessive updates. Our approach utilizes a small proxy model for efficient\nperplexity-based filtering, and updates the proxy to ensure that the filtering\ncriteria remain aligned with the evolving state of the deployed model. Compared\nto existing static data selection methods, our framework can effectively handle\nincrementally acquired data and shifting distributions. Additionally, it\naddresses practical deployment challenges by enabling seamless model updates,\nsupporting version rollback and incorporating automatic checkpoint evaluation.\nWe evaluated the system in real-world medical scenarios. It reduced\ncomputational costs by 66.7% and improved model performance, and achieved\nautonomous updates, thus demonstrating its effectiveness for automatic\ncontinual instruction tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15924v1",
    "published_date": "2025-03-20 08:00:41 UTC",
    "updated_date": "2025-03-20 08:00:41 UTC"
  },
  {
    "arxiv_id": "2503.15918v1",
    "title": "Denoising-based Contractive Imitation Learning",
    "authors": [
      "Macheng Shen",
      "Jishen Peng",
      "Zefang Huang"
    ],
    "abstract": "A fundamental challenge in imitation learning is the \\emph{covariate shift}\nproblem. Existing methods to mitigate covariate shift often require additional\nexpert interactions, access to environment dynamics, or complex adversarial\ntraining, which may not be practical in real-world applications. In this paper,\nwe propose a simple yet effective method (DeCIL) to mitigate covariate shift by\nincorporating a denoising mechanism that enhances the contraction properties of\nthe state transition mapping. Our approach involves training two neural\nnetworks: a dynamics model ( f ) that predicts the next state from the current\nstate, and a joint state-action denoising policy network ( d ) that refines\nthis state prediction via denoising and outputs the corresponding action. We\nprovide theoretical analysis showing that the denoising network acts as a local\ncontraction mapping, reducing the error propagation of the state transition and\nimproving stability. Our method is straightforward to implement and can be\neasily integrated with existing imitation learning frameworks without requiring\nadditional expert data or complex modifications to the training procedure.\nEmpirical results demonstrate that our approach effectively improves success\nrate of various imitation learning tasks under noise perturbation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15918v1",
    "published_date": "2025-03-20 07:52:19 UTC",
    "updated_date": "2025-03-20 07:52:19 UTC"
  },
  {
    "arxiv_id": "2503.15910v2",
    "title": "No Thing, Nothing: Highlighting Safety-Critical Classes for Robust LiDAR Semantic Segmentation in Adverse Weather",
    "authors": [
      "Junsung Park",
      "Hwijeong Lee",
      "Inha Kang",
      "Hyunjung Shim"
    ],
    "abstract": "Existing domain generalization methods for LiDAR semantic segmentation under\nadverse weather struggle to accurately predict \"things\" categories compared to\n\"stuff\" categories. In typical driving scenes, \"things\" categories can be\ndynamic and associated with higher collision risks, making them crucial for\nsafe navigation and planning. Recognizing the importance of \"things\"\ncategories, we identify their performance drop as a serious bottleneck in\nexisting approaches. We observed that adverse weather induces degradation of\nsemantic-level features and both corruption of local features, leading to a\nmisprediction of \"things\" as \"stuff\". To mitigate these corruptions, we suggest\nour method, NTN - segmeNt Things for No-accident. To address semantic-level\nfeature corruption, we bind each point feature to its superclass, preventing\nthe misprediction of things classes into visually dissimilar categories.\nAdditionally, to enhance robustness against local corruption caused by adverse\nweather, we define each LiDAR beam as a local region and propose a\nregularization term that aligns the clean data with its corrupted counterpart\nin feature space. NTN achieves state-of-the-art performance with a +2.6 mIoU\ngain on the SemanticKITTI-to-SemanticSTF benchmark and +7.9 mIoU on the\nSemanticPOSS-to-SemanticSTF benchmark. Notably, NTN achieves a +4.8 and +7.9\nmIoU improvement on \"things\" classes, respectively, highlighting its\neffectiveness.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, accepted in CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.15910v2",
    "published_date": "2025-03-20 07:40:24 UTC",
    "updated_date": "2025-03-24 12:16:42 UTC"
  },
  {
    "arxiv_id": "2503.15908v1",
    "title": "Enhancing Close-up Novel View Synthesis via Pseudo-labeling",
    "authors": [
      "Jiatong Xia",
      "Libo Sun",
      "Lingqiao Liu"
    ],
    "abstract": "Recent methods, such as Neural Radiance Fields (NeRF) and 3D Gaussian\nSplatting (3DGS), have demonstrated remarkable capabilities in novel view\nsynthesis. However, despite their success in producing high-quality images for\nviewpoints similar to those seen during training, they struggle when generating\ndetailed images from viewpoints that significantly deviate from the training\nset, particularly in close-up views. The primary challenge stems from the lack\nof specific training data for close-up views, leading to the inability of\ncurrent methods to render these views accurately. To address this issue, we\nintroduce a novel pseudo-label-based learning strategy. This approach leverages\npseudo-labels derived from existing training data to provide targeted\nsupervision across a wide range of close-up viewpoints. Recognizing the absence\nof benchmarks for this specific challenge, we also present a new dataset\ndesigned to assess the effectiveness of both current and future methods in this\narea. Our extensive experiments demonstrate the efficacy of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.15908v1",
    "published_date": "2025-03-20 07:27:46 UTC",
    "updated_date": "2025-03-20 07:27:46 UTC"
  },
  {
    "arxiv_id": "2503.15905v1",
    "title": "Jasmine: Harnessing Diffusion Prior for Self-supervised Depth Estimation",
    "authors": [
      "Jiyuan Wang",
      "Chunyu Lin",
      "Cheng Guan",
      "Lang Nie",
      "Jing He",
      "Haodong Li",
      "Kang Liao",
      "Yao Zhao"
    ],
    "abstract": "In this paper, we propose Jasmine, the first Stable Diffusion (SD)-based\nself-supervised framework for monocular depth estimation, which effectively\nharnesses SD's visual priors to enhance the sharpness and generalization of\nunsupervised prediction. Previous SD-based methods are all supervised since\nadapting diffusion models for dense prediction requires high-precision\nsupervision. In contrast, self-supervised reprojection suffers from inherent\nchallenges (e.g., occlusions, texture-less regions, illumination variance), and\nthe predictions exhibit blurs and artifacts that severely compromise SD's\nlatent priors. To resolve this, we construct a novel surrogate task of hybrid\nimage reconstruction. Without any additional supervision, it preserves the\ndetail priors of SD models by reconstructing the images themselves while\npreventing depth estimation from degradation. Furthermore, to address the\ninherent misalignment between SD's scale and shift invariant estimation and\nself-supervised scale-invariant depth estimation, we build the Scale-Shift GRU.\nIt not only bridges this distribution gap but also isolates the fine-grained\ntexture of SD output against the interference of reprojection loss. Extensive\nexperiments demonstrate that Jasmine achieves SoTA performance on the KITTI\nbenchmark and exhibits superior zero-shot generalization across multiple\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15905v1",
    "published_date": "2025-03-20 07:15:49 UTC",
    "updated_date": "2025-03-20 07:15:49 UTC"
  },
  {
    "arxiv_id": "2503.15904v1",
    "title": "From Structured Prompts to Open Narratives: Measuring Gender Bias in LLMs Through Open-Ended Storytelling",
    "authors": [
      "Evan Chen",
      "Run-Jun Zhan",
      "Yan-Bai Lin",
      "Hung-Hsuan Chen"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing,\nyet concerns persist regarding their tendency to reflect or amplify social\nbiases present in their training data. This study introduces a novel evaluation\nframework to uncover gender biases in LLMs, focusing on their occupational\nnarratives. Unlike previous methods relying on structured scenarios or\ncarefully crafted prompts, our approach leverages free-form storytelling to\nreveal biases embedded in the models. Systematic analyses show an\noverrepresentation of female characters across occupations in six widely used\nLLMs. Additionally, our findings reveal that LLM-generated occupational gender\nrankings align more closely with human stereotypes than actual labor\nstatistics. These insights underscore the need for balanced mitigation\nstrategies to ensure fairness while avoiding the reinforcement of new\nstereotypes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15904v1",
    "published_date": "2025-03-20 07:15:45 UTC",
    "updated_date": "2025-03-20 07:15:45 UTC"
  },
  {
    "arxiv_id": "2503.16565v1",
    "title": "Gene42: Long-Range Genomic Foundation Model With Dense Attention",
    "authors": [
      "Kirill Vishniakov",
      "Boulbaba Ben Amor",
      "Engin Tekin",
      "Nancy A. ElNaker",
      "Karthik Viswanathan",
      "Aleksandr Medvedev",
      "Aahan Singh",
      "Maryam Nadeem",
      "Mohammad Amaan Sayeed",
      "Praveenkumar Kanithi",
      "Tiago Magalhaes",
      "Natalia Vassilieva",
      "Dwarikanath Mahapatra",
      "Marco Pimentel",
      "and Shadab Khan"
    ],
    "abstract": "We introduce Gene42, a novel family of Genomic Foundation Models (GFMs)\ndesigned to manage context lengths of up to 192,000 base pairs (bp) at a\nsingle-nucleotide resolution. Gene42 models utilize a decoder-only\n(LLaMA-style) architecture with a dense self-attention mechanism. Initially\ntrained on fixed-length sequences of 4,096 bp, our models underwent continuous\npretraining to extend the context length to 192,000 bp. This iterative\nextension allowed for the comprehensive processing of large-scale genomic data\nand the capture of intricate patterns and dependencies within the human genome.\nGene42 is the first dense attention model capable of handling such extensive\nlong context lengths in genomics, challenging state-space models that often\nrely on convolutional operators among other mechanisms. Our pretrained models\nexhibit notably low perplexity values and high reconstruction accuracy,\nhighlighting their strong ability to model genomic data. Extensive experiments\non various genomic benchmarks have demonstrated state-of-the-art performance\nacross multiple tasks, including biotype classification, regulatory region\nidentification, chromatin profiling prediction, variant pathogenicity\nprediction, and species classification. The models are publicly available at\nhuggingface.co/inceptionai.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16565v1",
    "published_date": "2025-03-20 07:10:04 UTC",
    "updated_date": "2025-03-20 07:10:04 UTC"
  },
  {
    "arxiv_id": "2503.16563v1",
    "title": "Chem42: a Family of chemical Language Models for Target-aware Ligand Generation",
    "authors": [
      "Aahan Singh",
      "Engin Tekin",
      "Maryam Nadeem",
      "Nancy A. ElNaker",
      "Mohammad Amaan Sayeed",
      "Natalia Vassilieva",
      "Boulbaba Ben Amor"
    ],
    "abstract": "Revolutionizing drug discovery demands more than just understanding molecular\ninteractions - it requires generative models that can design novel ligands\ntailored to specific biological targets. While chemical Language Models (cLMs)\nhave made strides in learning molecular properties, most fail to incorporate\ntarget-specific insights, restricting their ability to drive de-novo ligand\ngeneration. Chem42, a cutting-edge family of generative chemical Language\nModels, is designed to bridge this gap. By integrating atomic-level\ninteractions with multimodal inputs from Prot42, a complementary protein\nLanguage Model, Chem42 achieves a sophisticated cross-modal representation of\nmolecular structures, interactions, and binding patterns. This innovative\nframework enables the creation of structurally valid, synthetically accessible\nligands with enhanced target specificity. Evaluations across diverse protein\ntargets confirm that Chem42 surpasses existing approaches in chemical validity,\ntarget-aware design, and predicted binding affinity. By reducing the search\nspace of viable drug candidates, Chem42 could accelerate the drug discovery\npipeline, offering a powerful generative AI tool for precision medicine. Our\nChem42 models set a new benchmark in molecule property prediction, conditional\nmolecule generation, and target-aware ligand design. The models are publicly\navailable at huggingface.co/inceptionai.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16563v1",
    "published_date": "2025-03-20 07:07:30 UTC",
    "updated_date": "2025-03-20 07:07:30 UTC"
  },
  {
    "arxiv_id": "2503.15901v1",
    "title": "A multi-model approach using XAI and anomaly detection to predict asteroid hazards",
    "authors": [
      "Amit Kumar Mondal",
      "Nafisha Aslam",
      "Prasenjit Maji",
      "Hemanta Kumar Mondal"
    ],
    "abstract": "The potential for catastrophic collision makes near-Earth asteroids (NEAs) a\nserious concern. Planetary defense depends on accurately classifying\npotentially hazardous asteroids (PHAs), however the complexity of the data\nhampers conventional techniques. This work offers a sophisticated method for\naccurately predicting hazards by combining machine learning, deep learning,\nexplainable AI (XAI), and anomaly detection. Our approach extracts essential\nparameters like size, velocity, and trajectory from historical and real-time\nasteroid data. A hybrid algorithm improves prediction accuracy by combining\nseveral cutting-edge models. A forecasting module predicts future asteroid\nbehavior, and Monte Carlo simulations evaluate the likelihood of collisions.\nTimely mitigation is made possible by a real-time alarm system that notifies\nworldwide monitoring stations. This technique enhances planetary defense\nefforts by combining real-time alarms with sophisticated predictive modeling.",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "astro-ph.EP",
    "comment": "17 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.15901v1",
    "published_date": "2025-03-20 07:00:01 UTC",
    "updated_date": "2025-03-20 07:00:01 UTC"
  },
  {
    "arxiv_id": "2503.15890v1",
    "title": "Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do",
    "authors": [
      "Yoav Wald",
      "Mark Goldstein",
      "Yonathan Efroni",
      "Wouter A. C. van Amsterdam",
      "Rajesh Ranganath"
    ],
    "abstract": "Problems in fields such as healthcare, robotics, and finance requires\nreasoning about the value both of what decision or action to take and when to\ntake it. The prevailing hope is that artificial intelligence will support such\ndecisions by estimating the causal effect of policies such as how to treat\npatients or how to allocate resources over time. However, existing methods for\nestimating the effect of a policy struggle with \\emph{irregular time}. They\neither discretize time, or disregard the effect of timing policies. We present\na new deep-Q algorithm that estimates the effect of both when and what to do\ncalled Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for\nthe Q-function that is compatible with flexible sequence models, such as\ntransformers. EDQ provides accurate estimates under standard assumptions. We\nvalidate the approach through experiments on survival time and tumor growth\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15890v1",
    "published_date": "2025-03-20 06:27:35 UTC",
    "updated_date": "2025-03-20 06:27:35 UTC"
  },
  {
    "arxiv_id": "2503.15889v1",
    "title": "LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices",
    "authors": [
      "Cynthia Dong",
      "Hong Jia",
      "Young D. Kwon",
      "Georgios Rizos",
      "Cecilia Mascolo"
    ],
    "abstract": "While there are many advantages to deploying machine learning models on edge\ndevices, the resource constraints of mobile platforms, the dynamic nature of\nthe environment, and differences between the distribution of training versus\nin-the-wild data make such deployments challenging. Current test-time\nadaptation methods are often memory-intensive and not designed to be\nquantization-compatible or deployed on low-resource devices. To address these\nchallenges, we present LeanTTA, a novel backpropagation-free and stateless\nframework for quantized test-time adaptation tailored to edge devices. Our\napproach minimizes computational costs by dynamically updating normalization\nstatistics without backpropagation, which frees LeanTTA from the common pitfall\nof relying on large batches and historical data, making our method robust to\nrealistic deployment scenarios. Our approach is the first to enable further\ncomputational gains by combining partial adaptation with quantized module\nfusion. We validate our framework across sensor modalities, demonstrating\nsignificant improvements over state-of-the-art TTA methods, including a 15.7%\nerror reduction, peak memory usage of only 11.2MB for ResNet18, and fast\nadaptation within an order-of-magnitude of normal inference speeds on-device.\nLeanTTA provides a robust solution for achieving the right trade offs between\naccuracy and system efficiency in edge deployments, addressing the unique\nchallenges posed by limited data and varied operational conditions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.15889v1",
    "published_date": "2025-03-20 06:27:09 UTC",
    "updated_date": "2025-03-20 06:27:09 UTC"
  },
  {
    "arxiv_id": "2503.15888v1",
    "title": "Parameters vs. Context: Fine-Grained Control of Knowledge Reliance in Language Models",
    "authors": [
      "Baolong Bi",
      "Shenghua Liu",
      "Yiwei Wang",
      "Yilong Xu",
      "Junfeng Fang",
      "Lingrui Mei",
      "Xueqi Cheng"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) mitigates hallucinations in Large\nLanguage Models (LLMs) by integrating external knowledge. However, conflicts\nbetween parametric knowledge and retrieved context pose challenges,\nparticularly when retrieved information is unreliable or the model's internal\nknowledge is outdated. In such cases, LLMs struggle to determine whether to\nrely more on their own parameters or the conflicted context. To address this,\nwe propose **CK-PLUG**, a plug-and-play method for controlling LLMs' reliance\non parametric and contextual knowledge. We introduce a novel knowledge\nconsistency metric, Confidence Gain, which detects knowledge conflicts by\nmeasuring entropy shifts in token probability distributions after context\ninsertion. CK-PLUG then enables fine-grained control over knowledge preference\nby adjusting the probability distribution of tokens with negative confidence\ngain through a single tuning parameter. Experiments demonstrate CK-PLUG's\nability to significantly regulate knowledge reliance in counterfactual RAG\nscenarios while maintaining generation fluency and knowledge accuracy. For\ninstance, on Llama3-8B, memory recall (MR) of RAG response can be adjusted\nwithin a broad range (9.9%-71.9%), compared to the baseline of 42.1%. Moreover,\nCK-PLUG supports adaptive control based on the model's confidence in both\ninternal and external knowledge, achieving consistent performance improvements\nacross various general RAG tasks. Our code is available at:\n$\\href{https://github.com/byronBBL/CK-PLUG}{\\text{this https URL}}$.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15888v1",
    "published_date": "2025-03-20 06:26:28 UTC",
    "updated_date": "2025-03-20 06:26:28 UTC"
  },
  {
    "arxiv_id": "2503.15876v1",
    "title": "DeepPsy-Agent: A Stage-Aware and Deep-Thinking Emotional Support Agent System",
    "authors": [
      "Kai Chen",
      "Zebing Sun"
    ],
    "abstract": "This paper introduces DeepPsy-Agent, an innovative psychological support\nsystem that combines the three-stage helping theory in psychology with deep\nlearning techniques. The system consists of two core components: (1) a\nmulti-stage response-capable dialogue model (\\textit{deeppsy-chat}), which\nenhances reasoning capabilities through stage-awareness and deep-thinking\nanalysis to generate high-quality responses; and (2) a real-time stage\ntransition detection model that identifies contextual shifts to guide the\ndialogue towards more effective intervention stages. Based on 30,000 real\npsychological hotline conversations, we employ AI-simulated dialogues and\nexpert re-annotation strategies to construct a high-quality multi-turn dialogue\ndataset. Experimental results demonstrate that DeepPsy-Agent outperforms\ngeneral-purpose large language models (LLMs) in key metrics such as problem\nexposure completeness, cognitive restructuring success rate, and action\nadoption rate. Ablation studies further validate the effectiveness of\nstage-awareness and deep-thinking modules, showing that stage information\ncontributes 42.3\\% to performance, while the deep-thinking module increases\nroot-cause identification by 58.3\\% and reduces ineffective suggestions by\n72.1\\%. This system addresses critical challenges in AI-based psychological\nsupport through dynamic dialogue management and deep reasoning, advancing\nintelligent mental health services.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15876v1",
    "published_date": "2025-03-20 05:59:29 UTC",
    "updated_date": "2025-03-20 05:59:29 UTC"
  },
  {
    "arxiv_id": "2503.15867v1",
    "title": "TruthLens: Explainable DeepFake Detection for Face Manipulated and Fully Synthetic Data",
    "authors": [
      "Rohit Kundu",
      "Athula Balachandran",
      "Amit K. Roy-Chowdhury"
    ],
    "abstract": "Detecting DeepFakes has become a crucial research area as the widespread use\nof AI image generators enables the effortless creation of face-manipulated and\nfully synthetic content, yet existing methods are often limited to binary\nclassification (real vs. fake) and lack interpretability. To address these\nchallenges, we propose TruthLens, a novel and highly generalizable framework\nfor DeepFake detection that not only determines whether an image is real or\nfake but also provides detailed textual reasoning for its predictions. Unlike\ntraditional methods, TruthLens effectively handles both face-manipulated\nDeepFakes and fully AI-generated content while addressing fine-grained queries\nsuch as \"Does the eyes/nose/mouth look real or fake?\"\n  The architecture of TruthLens combines the global contextual understanding of\nmultimodal large language models like PaliGemma2 with the localized feature\nextraction capabilities of vision-only models like DINOv2. This hybrid design\nleverages the complementary strengths of both models, enabling robust detection\nof subtle manipulations while maintaining interpretability. Extensive\nexperiments on diverse datasets demonstrate that TruthLens outperforms\nstate-of-the-art methods in detection accuracy (by 2-14%) and explainability,\nin both in-domain and cross-data settings, generalizing effectively across\ntraditional and emerging manipulation techniques.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15867v1",
    "published_date": "2025-03-20 05:40:42 UTC",
    "updated_date": "2025-03-20 05:40:42 UTC"
  },
  {
    "arxiv_id": "2503.15865v2",
    "title": "Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement",
    "authors": [
      "Jong-Hyun Jeong",
      "Hongki Jo",
      "Qiang Zhou",
      "Tahsin Afroz Hoque Nishat",
      "Lang Wu"
    ],
    "abstract": "Wireless sensor networks (WSNs) have become a promising solution for\nstructural health monitoring (SHM), especially in hard-to-reach or remote\nlocations. Battery-powered WSNs offer various advantages over wired systems,\nhowever limited battery life has always been one of the biggest obstacles in\npractical use of the WSNs, regardless of energy harvesting methods. While\nvarious methods have been studied for battery health management, existing\nmethods exclusively aim to extend lifetime of individual batteries, lacking a\nsystem level view. A consequence of applying such methods is that batteries in\na WSN tend to fail at different times, posing significant difficulty on\nplanning and scheduling of battery replacement trip. This study investigate a\ndeep reinforcement learning (DRL) method for active battery degradation\nmanagement by optimizing duty cycle of WSNs at the system level. This active\nmanagement strategy effectively reduces earlier failure of battery individuals\nwhich enable group replacement without sacrificing WSN performances. A\nsimulated environment based on a real-world WSN setup was developed to train a\nDRL agent and learn optimal duty cycle strategies. The performance of the\nstrategy was validated in a long-term setup with various network sizes,\ndemonstrating its efficiency and scalability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15865v2",
    "published_date": "2025-03-20 05:36:33 UTC",
    "updated_date": "2025-03-22 20:21:34 UTC"
  },
  {
    "arxiv_id": "2503.15855v1",
    "title": "VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling",
    "authors": [
      "Hyojun Go",
      "Byeongjun Park",
      "Hyelin Nam",
      "Byung-Hoon Kim",
      "Hyungjin Chung",
      "Changick Kim"
    ],
    "abstract": "We propose VideoRFSplat, a direct text-to-3D model leveraging a video\ngeneration model to generate realistic 3D Gaussian Splatting (3DGS) for\nunbounded real-world scenes. To generate diverse camera poses and unbounded\nspatial extent of real-world scenes, while ensuring generalization to arbitrary\ntext prompts, previous methods fine-tune 2D generative models to jointly model\ncamera poses and multi-view images. However, these methods suffer from\ninstability when extending 2D generative models to joint modeling due to the\nmodality gap, which necessitates additional models to stabilize training and\ninference. In this work, we propose an architecture and a sampling strategy to\njointly model multi-view images and camera poses when fine-tuning a video\ngeneration model. Our core idea is a dual-stream architecture that attaches a\ndedicated pose generation model alongside a pre-trained video generation model\nvia communication blocks, generating multi-view images and camera poses through\nseparate streams. This design reduces interference between the pose and image\nmodalities. Additionally, we propose an asynchronous sampling strategy that\ndenoises camera poses faster than multi-view images, allowing rapidly denoised\nposes to condition multi-view generation, reducing mutual ambiguity and\nenhancing cross-modal consistency. Trained on multiple large-scale real-world\ndatasets (RealEstate10K, MVImgNet, DL3DV-10K, ACID), VideoRFSplat outperforms\nexisting text-to-3D direct generation methods that heavily depend on post-hoc\nrefinement via score distillation sampling, achieving superior results without\nsuch refinement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://gohyojun15.github.io/VideoRFSplat/",
    "pdf_url": "http://arxiv.org/pdf/2503.15855v1",
    "published_date": "2025-03-20 05:26:09 UTC",
    "updated_date": "2025-03-20 05:26:09 UTC"
  },
  {
    "arxiv_id": "2503.15848v1",
    "title": "Entropy-based Exploration Conduction for Multi-step Reasoning",
    "authors": [
      "Jinghan Zhang",
      "Xiting Wang",
      "Fengran Mo",
      "Yeyang Zhou",
      "Wanfu Gao",
      "Kunpeng Liu"
    ],
    "abstract": "In large language model (LLM) reasoning, multi-step processes have proven\neffective for solving complex tasks. However, the depth of exploration can\nsignificantly affect the reasoning performance. Existing methods to\nautomatically decide the depth often bring high costs and lack flexibility, and\nthus undermine the model's reasoning accuracy. To address these issues, we\npropose Entropy-based Exploration Depth Conduction (Entro-duction), a novel\nmethod that dynamically adjusts the exploration depth during multi-step\nreasoning by monitoring LLM's output entropy and variance entropy. We employ\nthese two metrics to capture the model's current uncertainty and the\nfluctuation of uncertainty across consecutive reasoning steps. Based on the\nobserved changes, the LLM selects whether to deepen, expand or stop exploration\naccording to the probability. In this way, we balance the reasoning accuracy\nand exploration effectiveness. Experimental results across four benchmark\ndatasets demonstrate the efficacy of Entro-duction. We further conduct\nexperiments and analysis on the components of Entro-duction to discuss their\ncontributions to reasoning performance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15848v1",
    "published_date": "2025-03-20 05:03:26 UTC",
    "updated_date": "2025-03-20 05:03:26 UTC"
  },
  {
    "arxiv_id": "2503.15847v1",
    "title": "Beyond Local Selection: Global Cut Selection for Enhanced Mixed-Integer Programming",
    "authors": [
      "Shuli Zeng",
      "Sijia Zhang",
      "Shaoang Li",
      "Feng Wu",
      "Xiang-Yang Li"
    ],
    "abstract": "In mixed-integer programming (MIP) solvers, cutting planes are essential for\nBranch-and-Cut (B&C) algorithms as they reduce the search space and accelerate\nthe solving process. Traditional methods rely on hard-coded heuristics for cut\nplane selection but fail to leverage problem-specific structural features.\nRecent machine learning approaches use neural networks for cut selection but\nfocus narrowly on the efficiency of single-node within the B&C algorithm,\nwithout considering the broader contextual information. To address this, we\npropose Global Cut Selection (GCS), which uses a bipartite graph to represent\nthe search tree and combines graph neural networks with reinforcement learning\nto develop cut selection strategies. Unlike prior methods, GCS applies cutting\nplanes across all nodes, incorporating richer contextual information.\nExperiments show GCS significantly improves solving efficiency for synthetic\nand large-scale real-world MIPs compared to traditional and learning-based\nmethods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15847v1",
    "published_date": "2025-03-20 04:59:18 UTC",
    "updated_date": "2025-03-20 04:59:18 UTC"
  },
  {
    "arxiv_id": "2503.15837v1",
    "title": "Fùxì: A Benchmark for Evaluating Language Models on Ancient Chinese Text Understanding and Generation",
    "authors": [
      "Shangqing Zhao",
      "Yuhao Zhou",
      "Yupei Ren",
      "Zhe Chen",
      "Chenghao Jia",
      "Fang Zhe",
      "Zhaogaung Long",
      "Shu Liu",
      "Man Lan"
    ],
    "abstract": "Ancient Chinese text processing presents unique challenges for large language\nmodels (LLMs) due to its distinct linguistic features, complex structural\nconstraints, and rich cultural context. While existing benchmarks have\nprimarily focused on evaluating comprehension through multiple-choice\nquestions, there remains a critical gap in assessing models' generative\ncapabilities in classical Chinese. We introduce F\\`ux\\`i, a comprehensive\nbenchmark that evaluates both understanding and generation capabilities across\n21 diverse tasks. Our benchmark distinguishes itself through three key\ncontributions: (1) balanced coverage of both comprehension and generation\ntasks, including novel tasks like poetry composition and couplet completion,\n(2) specialized evaluation metrics designed specifically for classical Chinese\ntext generation, combining rule-based verification with fine-tuned LLM\nevaluators, and (3) a systematic assessment framework that considers both\nlinguistic accuracy and cultural authenticity. Through extensive evaluation of\nstate-of-the-art LLMs, we reveal significant performance gaps between\nunderstanding and generation tasks, with models achieving promising results in\ncomprehension but struggling considerably in generation tasks, particularly\nthose requiring deep cultural knowledge and adherence to classical formats. Our\nfindings highlight the current limitations in ancient Chinese text processing\nand provide insights for future model development. The benchmark, evaluation\ntoolkit, and baseline results are publicly available to facilitate research in\nthis domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "working in progress",
    "pdf_url": "http://arxiv.org/pdf/2503.15837v1",
    "published_date": "2025-03-20 04:26:40 UTC",
    "updated_date": "2025-03-20 04:26:40 UTC"
  },
  {
    "arxiv_id": "2503.15818v2",
    "title": "Computation-Efficient and Recognition-Friendly 3D Point Cloud Privacy Protection",
    "authors": [
      "Haotian Ma",
      "Lin Gu",
      "Siyi Wu",
      "Yingying Zhu"
    ],
    "abstract": "3D point cloud has been widely used in applications such as self-driving\ncars, robotics, CAD models, etc. To the best of our knowledge, these\napplications raised the issue of privacy leakage in 3D point clouds, which has\nnot been studied well. Different from the 2D image privacy, which is related to\ntexture and 2D geometric structure, the 3D point cloud is texture-less and only\nrelevant to 3D geometric structure. In this work, we defined the 3D point cloud\nprivacy problem and proposed an efficient privacy-preserving framework named\nPointFlowGMM that can support downstream classification and segmentation tasks\nwithout seeing the original data. Using a flow-based generative model, the\npoint cloud is projected into a latent Gaussian mixture distributed subspace.\nWe further designed a novel angular similarity loss to obfuscate the original\ngeometric structure and reduce the model size from 767MB to 120MB without a\ndecrease in recognition performance. The projected point cloud in the latent\nspace is orthogonally rotated randomly to further protect the original\ngeometric structure, the class-to-class relationship is preserved after\nrotation, thus, the protected point cloud can support the recognition task. We\nevaluated our model on multiple datasets and achieved comparable recognition\nresults on encrypted point clouds compared to the original point clouds.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.15818v2",
    "published_date": "2025-03-20 03:09:44 UTC",
    "updated_date": "2025-03-23 19:45:16 UTC"
  },
  {
    "arxiv_id": "2503.15817v1",
    "title": "Ranking Counterfactual Explanations",
    "authors": [
      "Suryani Lim",
      "Henri Prade",
      "Gilles Richard"
    ],
    "abstract": "AI-driven outcomes can be challenging for end-users to understand.\nExplanations can address two key questions: \"Why this outcome?\" (factual) and\n\"Why not another?\" (counterfactual). While substantial efforts have been made\nto formalize factual explanations, a precise and comprehensive study of\ncounterfactual explanations is still lacking. This paper proposes a formal\ndefinition of counterfactual explanations, proving some properties they\nsatisfy, and examining the relationship with factual explanations. Given that\nmultiple counterfactual explanations generally exist for a specific case, we\nalso introduce a rigorous method to rank these counterfactual explanations,\ngoing beyond a simple minimality condition, and to identify the optimal ones.\nOur experiments with 12 real-world datasets highlight that, in most cases, a\nsingle optimal counterfactual explanation emerges. We also demonstrate, via\nthree metrics, that the selected optimal explanation exhibits higher\nrepresentativeness and can explain a broader range of elements than a random\nminimal counterfactual. This result highlights the effectiveness of our\napproach in identifying more robust and comprehensive counterfactual\nexplanations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.15817v1",
    "published_date": "2025-03-20 03:04:05 UTC",
    "updated_date": "2025-03-20 03:04:05 UTC"
  },
  {
    "arxiv_id": "2503.15815v1",
    "title": "Attention Pruning: Automated Fairness Repair of Language Models via Surrogate Simulated Annealing",
    "authors": [
      "Vishnu Asutosh Dasu",
      "Md Rafi ur Rashid",
      "Vipul Gupta",
      "Saeid Tizpaz-Niari",
      "Gang Tan"
    ],
    "abstract": "This paper explores pruning attention heads as a post-processing bias\nmitigation method for large language models (LLMs). Modern AI systems such as\nLLMs are expanding into sensitive social contexts where fairness concerns\nbecome especially crucial. Since LLMs develop decision-making patterns by\ntraining on massive datasets of human-generated content, they naturally encode\nand perpetuate societal biases. While modifying training datasets and\nalgorithms is expensive and requires significant resources; post-processing\ntechniques-such as selectively deactivating neurons and attention heads in\npre-trained LLMs-can provide feasible and effective approaches to improve\nfairness. However, identifying the optimal subset of parameters to prune\npresents a combinatorial challenge within LLMs' immense parameter space,\nrequiring solutions that efficiently balance competing objectives across the\nfrontiers of model fairness and utility.\n  To address the computational challenges, we explore a search-based program\nrepair approach via randomized simulated annealing. Given the prohibitive\nevaluation costs in billion-parameter LLMs, we develop surrogate deep neural\nnetworks that efficiently model the relationship between attention head states\n(active/inactive) and their corresponding fairness/utility metrics. This allows\nus to perform optimization over the surrogate models and efficiently identify\noptimal subsets of attention heads for selective pruning rather than directly\nsearching through the LLM parameter space. This paper introduces Attention\nPruning, a fairness-aware surrogate simulated annealing approach to prune\nattention heads in LLMs that disproportionately contribute to bias while\nminimally impacting overall model utility. Our experiments show that Attention\nPruning achieves up to $40\\%$ reduction in gender bias and outperforms the\nstate-of-the-art bias mitigation strategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15815v1",
    "published_date": "2025-03-20 03:02:32 UTC",
    "updated_date": "2025-03-20 03:02:32 UTC"
  },
  {
    "arxiv_id": "2503.15808v1",
    "title": "ChatGPT and U(X): A Rapid Review on Measuring the User Experience",
    "authors": [
      "Katie Seaborn"
    ],
    "abstract": "ChatGPT, powered by a large language model (LLM), has revolutionized everyday\nhuman-computer interaction (HCI) since its 2022 release. While now used by\nmillions around the world, a coherent pathway for evaluating the user\nexperience (UX) ChatGPT offers remains missing. In this rapid review (N = 58),\nI explored how ChatGPT UX has been approached quantitatively so far. I focused\non the independent variables (IVs) manipulated, the dependent variables (DVs)\nmeasured, and the methods used for measurement. Findings reveal trends, gaps,\nand emerging consensus in UX assessments. This work offers a first step towards\nsynthesizing existing approaches to measuring ChatGPT UX, urgent trajectories\nto advance standardization and breadth, and two preliminary frameworks aimed at\nguiding future research and tool development. I seek to elevate the field of\nChatGPT UX by empowering researchers and practitioners in optimizing user\ninteractions with ChatGPT and similar LLM-based systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15808v1",
    "published_date": "2025-03-20 02:51:11 UTC",
    "updated_date": "2025-03-20 02:51:11 UTC"
  },
  {
    "arxiv_id": "2503.15807v1",
    "title": "Video-VoT-R1: An efficient video inference model integrating image packing and AoE architecture",
    "authors": [
      "Cheng Li",
      "Jiexiong Liu",
      "Yixuan Chen",
      "Yanqin Jia"
    ],
    "abstract": "In the field of video-language pretraining, existing models face numerous\nchallenges in terms of inference efficiency and multimodal data processing.\nThis paper proposes a KunLunBaize-VoT-R1 video inference model based on a\nlong-sequence image encoder, along with its training and application methods.\nBy integrating image packing technology, the Autonomy-of-Experts (AoE)\narchitecture, and combining the video of Thought (VoT), a large language model\n(LLM) trained with large-scale reinforcement learning, and multiple training\ntechniques, the efficiency and accuracy of the model in video inference tasks\nare effectively improved. Experiments show that this model performs\noutstandingly in multiple tests, providing a new solution for video-language\nunderstanding.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.15807v1",
    "published_date": "2025-03-20 02:50:57 UTC",
    "updated_date": "2025-03-20 02:50:57 UTC"
  },
  {
    "arxiv_id": "2503.15796v1",
    "title": "Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction",
    "authors": [
      "Xinlong Zhai",
      "Chunchen Wang",
      "Ruijia Wang",
      "Jiazheng Kang",
      "Shujie Li",
      "Boyu Chen",
      "Tengfei Ma",
      "Zikai Zhou",
      "Cheng Yang",
      "Chuan Shi"
    ],
    "abstract": "Drug-target interaction prediction (DTI) is essential in various applications\nincluding drug discovery and clinical application. There are two perspectives\nof input data widely used in DTI prediction: Intrinsic data represents how\ndrugs or targets are constructed, and extrinsic data represents how drugs or\ntargets are related to other biological entities. However, any of the two\nperspectives of input data can be scarce for some drugs or targets, especially\nfor those unpopular or newly discovered. Furthermore, ground-truth labels for\nspecific interaction types can also be scarce. Therefore, we propose the first\nmethod to tackle DTI prediction under input data and/or label scarcity. To make\nour model functional when only one perspective of input data is available, we\ndesign two separate experts to process intrinsic and extrinsic data\nrespectively and fuse them adaptively according to different samples.\nFurthermore, to make the two perspectives complement each other and remedy\nlabel scarcity, two experts synergize with each other in a mutually supervised\nway to exploit the enormous unlabeled data. Extensive experiments on 3\nreal-world datasets under different extents of input data scarcity and/or label\nscarcity demonstrate our model outperforms states of the art significantly and\nsteadily, with a maximum improvement of 53.53%. We also test our model without\nany data scarcity and it still outperforms current methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15796v1",
    "published_date": "2025-03-20 02:27:16 UTC",
    "updated_date": "2025-03-20 02:27:16 UTC"
  },
  {
    "arxiv_id": "2503.15783v1",
    "title": "Grammar and Gameplay-aligned RL for Game Description Generation with LLMs",
    "authors": [
      "Tsunehiko Tanaka",
      "Edgar Simo-Serra"
    ],
    "abstract": "Game Description Generation (GDG) is the task of generating a game\ndescription written in a Game Description Language (GDL) from natural language\ntext. Previous studies have explored generation methods leveraging the\ncontextual understanding capabilities of Large Language Models (LLMs); however,\naccurately reproducing the game features of the game descriptions remains a\nchallenge. In this paper, we propose reinforcement learning-based fine-tuning\nof LLMs for GDG (RLGDG). Our training method simultaneously improves\ngrammatical correctness and fidelity to game concepts by introducing both\ngrammar rewards and concept rewards. Furthermore, we adopt a two-stage training\nstrategy where Reinforcement Learning (RL) is applied following Supervised\nFine-Tuning (SFT). Experimental results demonstrate that our proposed method\nsignificantly outperforms baseline methods using SFT alone.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15783v1",
    "published_date": "2025-03-20 01:47:33 UTC",
    "updated_date": "2025-03-20 01:47:33 UTC"
  },
  {
    "arxiv_id": "2503.15779v1",
    "title": "MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion",
    "authors": [
      "Haoxuan Ma",
      "Xishun Liao",
      "Yifan Liu",
      "Qinhua Jiang",
      "Chris Stanford",
      "Shangqing Cao",
      "Jiaqi Ma"
    ],
    "abstract": "Human mobility modeling is critical for urban planning and transportation\nmanagement, yet existing datasets often lack the resolution and semantic\nrichness required for comprehensive analysis. To address this, we proposed a\ncross-domain data fusion framework that integrates multi-modal data of distinct\nnature and spatio-temporal resolution, including geographical, mobility,\nsocio-demographic, and traffic information, to construct a privacy-preserving\nand semantically enriched human travel trajectory dataset. This framework is\ndemonstrated through two case studies in Los Angeles (LA) and Egypt, where a\ndomain adaptation algorithm ensures its transferability across diverse urban\ncontexts. Quantitative evaluation shows that the generated synthetic dataset\naccurately reproduces mobility patterns observed in empirical data. Moreover,\nlarge-scale traffic simulations for LA County based on the generated synthetic\ndemand align well with observed traffic. On California's I-405 corridor, the\nsimulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume\nand 4.36% for speed compared to Caltrans PeMS observations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15779v1",
    "published_date": "2025-03-20 01:41:28 UTC",
    "updated_date": "2025-03-20 01:41:28 UTC"
  },
  {
    "arxiv_id": "2503.15772v2",
    "title": "Detecting LLM-Generated Peer Reviews",
    "authors": [
      "Vishisht Rao",
      "Aounon Kumar",
      "Himabindu Lakkaraju",
      "Nihar B. Shah"
    ],
    "abstract": "The integrity of peer review is fundamental to scientific progress, but the\nrise of large language models (LLMs) has introduced concerns that some\nreviewers may rely on these tools to generate reviews rather than writing them\nindependently. Although some venues have banned LLM-assisted reviewing,\nenforcement remains difficult as existing detection tools cannot reliably\ndistinguish between fully generated reviews and those merely polished with AI\nassistance. In this work, we address the challenge of detecting LLM-generated\nreviews. We consider the approach of performing indirect prompt injection via\nthe paper's PDF, prompting the LLM to embed a covert watermark in the generated\nreview, and subsequently testing for presence of the watermark in the review.\nWe identify and address several pitfalls in na\\\"ive implementations of this\napproach. Our primary contribution is a rigorous watermarking and detection\nframework that offers strong statistical guarantees. Specifically, we introduce\nwatermarking schemes and hypothesis tests that control the family-wise error\nrate across multiple reviews, achieving higher statistical power than standard\ncorrections such as Bonferroni, while making no assumptions about the nature of\nhuman-written reviews. We explore multiple indirect prompt injection\nstrategies--including font-based embedding and obfuscated prompts--and evaluate\ntheir effectiveness under various reviewer defense scenarios. Our experiments\nfind high success rates in watermark embedding across various LLMs. We also\nempirically find that our approach is resilient to common reviewer defenses,\nand that the bounds on error rates in our statistical tests hold in practice.\nIn contrast, we find that Bonferroni-style corrections are too conservative to\nbe useful in this setting.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.DL",
    "comment": "27 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.15772v2",
    "published_date": "2025-03-20 01:11:35 UTC",
    "updated_date": "2025-05-19 01:40:25 UTC"
  },
  {
    "arxiv_id": "2503.15768v1",
    "title": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer",
    "authors": [
      "Alexandra DeLucia",
      "Mark Dredze"
    ],
    "abstract": "Abstractive multi-document summarization (MDS) is the task of automatically\nsummarizing information in multiple documents, from news articles to\nconversations with multiple speakers. The training approaches for current MDS\nmodels can be grouped into four approaches: end-to-end with special\npre-training (\"direct\"), chunk-then-summarize, extract-then-summarize, and\ninference with GPT-style models. In this work, we evaluate MDS models across\ntraining approaches, domains, and dimensions (reference similarity, quality,\nand factuality), to analyze how and why models trained on one domain can fail\nto summarize documents from another (News, Science, and Conversation) in the\nzero-shot domain transfer setting. We define domain-transfer \"failure\" as a\ndecrease in factuality, higher deviation from the target, and a general\ndecrease in summary quality. In addition to exploring domain transfer for MDS\nmodels, we examine potential issues with applying popular summarization metrics\nout-of-the-box.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15768v1",
    "published_date": "2025-03-20 00:57:38 UTC",
    "updated_date": "2025-03-20 00:57:38 UTC"
  },
  {
    "arxiv_id": "2503.16558v1",
    "title": "Advancing Problem-Based Learning in Biomedical Engineering in the Era of Generative AI",
    "authors": [
      "Micky C. Nnamdi",
      "J. Ben Tamo",
      "Wenqi Shi",
      "May D. Wang"
    ],
    "abstract": "Problem-Based Learning (PBL) has significantly impacted biomedical\nengineering (BME) education since its introduction in the early 2000s,\neffectively enhancing critical thinking and real-world knowledge application\namong students. With biomedical engineering rapidly converging with artificial\nintelligence (AI), integrating effective AI education into established\ncurricula has become challenging yet increasingly necessary. Recent\nadvancements, including AI's recognition by the 2024 Nobel Prize, have\nhighlighted the importance of training students comprehensively in biomedical\nAI. However, effective biomedical AI education faces substantial obstacles,\nsuch as diverse student backgrounds, limited personalized mentoring,\nconstrained computational resources, and difficulties in safely scaling\nhands-on practical experiments due to privacy and ethical concerns associated\nwith biomedical data. To overcome these issues, we conducted a three-year\n(2021-2023) case study implementing an advanced PBL framework tailored\nspecifically for biomedical AI education, involving 92 undergraduate and 156\ngraduate students from the joint Biomedical Engineering program of Georgia\nInstitute of Technology and Emory University. Our approach emphasizes\ncollaborative, interdisciplinary problem-solving through authentic biomedical\nAI challenges. The implementation led to measurable improvements in learning\noutcomes, evidenced by high research productivity (16 student-authored\npublications), consistently positive peer evaluations, and successful\ndevelopment of innovative computational methods addressing real biomedical\nchallenges. Additionally, we examined the role of generative AI both as a\nteaching subject and an educational support tool within the PBL framework. Our\nstudy presents a practical and scalable roadmap for biomedical engineering\ndepartments aiming to integrate robust AI education into their curricula.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16558v1",
    "published_date": "2025-03-20 00:52:02 UTC",
    "updated_date": "2025-03-20 00:52:02 UTC"
  },
  {
    "arxiv_id": "2503.15764v2",
    "title": "Towards Agentic AI Networking in 6G: A Generative Foundation Model-as-Agent Approach",
    "authors": [
      "Yong Xiao",
      "Guangming Shi",
      "Ping Zhang"
    ],
    "abstract": "The promising potential of AI and network convergence in improving networking\nperformance and enabling new service capabilities has recently attracted\nsignificant interest. Existing network AI solutions, while powerful, are mainly\nbuilt based on the close-loop and passive learning framework, resulting in\nmajor limitations in autonomous solution finding and dynamic environmental\nadaptation. Agentic AI has recently been introduced as a promising solution to\naddress the above limitations and pave the way for true generally intelligent\nand beneficial AI systems. The key idea is to create a networking ecosystem to\nsupport a diverse range of autonomous and embodied AI agents in fulfilling\ntheir goals. In this paper, we focus on the novel challenges and requirements\nof agentic AI networking. We propose AgentNet, a novel framework for supporting\ninteraction, collaborative learning, and knowledge transfer among AI agents. We\nintroduce a general architectural framework of AgentNet and then propose a\ngenerative foundation model (GFM)-based implementation in which multiple\nGFM-as-agents have been created as an interactive knowledge-base to bootstrap\nthe development of embodied AI agents according to different task requirements\nand environmental features. We consider two application scenarios,\ndigital-twin-based industrial automation and metaverse-based infotainment\nsystem, to describe how to apply AgentNet for supporting efficient task-driven\ncollaboration and interaction among AI agents.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "Accepted at IEEE Communications Magazine",
    "pdf_url": "http://arxiv.org/pdf/2503.15764v2",
    "published_date": "2025-03-20 00:48:44 UTC",
    "updated_date": "2025-05-11 05:41:17 UTC"
  },
  {
    "arxiv_id": "2503.15762v1",
    "title": "Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to Personalized Educational Content Generation",
    "authors": [
      "Elena Malnatsky",
      "Shenghui Wang",
      "Koen V. Hindriks",
      "Mike E. U. Ligthart"
    ],
    "abstract": "Dialogic learning fosters motivation and deeper understanding in education\nthrough purposeful and structured dialogues. Foundational models offer a\ntransformative potential for child-robot interactions, enabling the design of\npersonalized, engaging, and scalable interactions. However, their integration\ninto educational contexts presents challenges in terms of ensuring\nage-appropriate and safe content and alignment with pedagogical goals. We\nintroduce a hybrid approach to designing personalized educational dialogues in\nchild-robot interactions. By combining rule-based systems with LLMs for\nselective offline content generation and human validation, the framework\nensures educational quality and developmental appropriateness. We illustrate\nthis approach through a project aimed at enhancing reading motivation, in which\na robot facilitated book-related dialogues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15762v1",
    "published_date": "2025-03-20 00:46:10 UTC",
    "updated_date": "2025-03-20 00:46:10 UTC"
  },
  {
    "arxiv_id": "2503.15758v1",
    "title": "ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism",
    "authors": [
      "Venmugil Elango"
    ],
    "abstract": "Transformer-based models have emerged as a leading architecture for natural\nlanguage processing, natural language generation, and image generation tasks. A\nfundamental element of the transformer architecture is self-attention, which\nallows the model to capture intricate dependencies within the data. However,\nthe self-attention mechanism also incurs significant computational and memory\ncosts, particularly for long sequences.\n  In this paper, we introduce ATTENTION2D, a novel approach that exploits\nparallelism along two dimensions - query and key/value - of the self-attention\noperation. This method enables efficient distribution and parallelization of\ncomputations across multiple devices. Our approach facilitates asymptotically\nfaster training and inference phases compared to previous methods, without\nrelying on approximations or incurring additional computational or memory\noverheads. Furthermore, unlike existing techniques that struggle to scale with\nan increasing number of processing units, our approach effectively scales with\nadditional processing units.\n  Our experimental results confirm the effectiveness of our method in improving\ncommunication efficiency and scalability. Compared to Ring Attention, our\napproach demonstrated up to a 5x performance boost on a GPT-3-like model using\n64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64\nNVIDIA H100 GPUs across 64 nodes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15758v1",
    "published_date": "2025-03-20 00:25:44 UTC",
    "updated_date": "2025-03-20 00:25:44 UTC"
  },
  {
    "arxiv_id": "2503.15754v1",
    "title": "AutoRedTeamer: Autonomous Red Teaming with Lifelong Attack Integration",
    "authors": [
      "Andy Zhou",
      "Kevin Wu",
      "Francesco Pinto",
      "Zhaorun Chen",
      "Yi Zeng",
      "Yu Yang",
      "Shuang Yang",
      "Sanmi Koyejo",
      "James Zou",
      "Bo Li"
    ],
    "abstract": "As large language models (LLMs) become increasingly capable, security and\nsafety evaluation are crucial. While current red teaming approaches have made\nstrides in assessing LLM vulnerabilities, they often rely heavily on human\ninput and lack comprehensive coverage of emerging attack vectors. This paper\nintroduces AutoRedTeamer, a novel framework for fully automated, end-to-end red\nteaming against LLMs. AutoRedTeamer combines a multi-agent architecture with a\nmemory-guided attack selection mechanism to enable continuous discovery and\nintegration of new attack vectors. The dual-agent framework consists of a red\nteaming agent that can operate from high-level risk categories alone to\ngenerate and execute test cases and a strategy proposer agent that autonomously\ndiscovers and implements new attacks by analyzing recent research. This modular\ndesign allows AutoRedTeamer to adapt to emerging threats while maintaining\nstrong performance on existing attack vectors. We demonstrate AutoRedTeamer's\neffectiveness across diverse evaluation settings, achieving 20% higher attack\nsuccess rates on HarmBench against Llama-3.1-70B while reducing computational\ncosts by 46% compared to existing approaches. AutoRedTeamer also matches the\ndiversity of human-curated benchmarks in generating test cases, providing a\ncomprehensive, scalable, and continuously evolving framework for evaluating the\nsecurity of AI systems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15754v1",
    "published_date": "2025-03-20 00:13:04 UTC",
    "updated_date": "2025-03-20 00:13:04 UTC"
  },
  {
    "arxiv_id": "2503.15752v4",
    "title": "Using Language Models to Decipher the Motivation Behind Human Behaviors",
    "authors": [
      "Yutong Xie",
      "Qiaozhu Mei",
      "Walter Yuan",
      "Matthew O. Jackson"
    ],
    "abstract": "AI presents a novel tool for deciphering the motivations behind human\nbehaviors. By varying prompts to a large language model, we can elicit the full\nrange of human behaviors in a variety of different scenarios in classic\neconomic games. By analyzing which prompts elicit which behaviors, we infer\n(decipher) the motivations behind the human behaviors. We also show how one can\nanalyze the prompts to reveal relationships between the classic economic games,\nproviding insight into what different economic scenarios induce people to think\nabout. We also show how this deciphering process can be used to understand\ndifferences in the behavioral tendencies of different populations. We show how\nAI offers a new way to examine the thinking and framing that produce different\nbehaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15752v4",
    "published_date": "2025-03-20 00:07:06 UTC",
    "updated_date": "2025-05-11 20:47:51 UTC"
  }
]