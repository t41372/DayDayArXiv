[
  {
    "arxiv_id": "2404.11803v2",
    "title": "TempBEV: Improving Learned BEV Encoders with Combined Image and BEV Space Temporal Aggregation",
    "authors": [
      "Thomas Monninger",
      "Vandana Dokkadi",
      "Md Zafar Anwar",
      "Steffen Staab"
    ],
    "abstract": "Autonomous driving requires an accurate representation of the environment. A\nstrategy toward high accuracy is to fuse data from several sensors. Learned\nBird's-Eye View (BEV) encoders can achieve this by mapping data from individual\nsensors into one joint latent space. For cost-efficient camera-only systems,\nthis provides an effective mechanism to fuse data from multiple cameras with\ndifferent views. Accuracy can further be improved by aggregating sensor\ninformation over time. This is especially important in monocular camera systems\nto account for the lack of explicit depth and velocity measurements. Thereby,\nthe effectiveness of developed BEV encoders crucially depends on the operators\nused to aggregate temporal information and on the used latent representation\nspaces. We analyze BEV encoders proposed in the literature and compare their\neffectiveness, quantifying the effects of aggregation operators and latent\nrepresentations. While most existing approaches aggregate temporal information\neither in image or in BEV latent space, our analyses and performance\ncomparisons suggest that these latent representations exhibit complementary\nstrengths. Therefore, we develop a novel temporal BEV encoder, TempBEV, which\nintegrates aggregated temporal information from both latent spaces. We consider\nsubsequent image frames as stereo through time and leverage methods from\noptical flow estimation for temporal stereo encoding. Empirical evaluation on\nthe NuScenes dataset shows a significant improvement by TempBEV over the\nbaseline for 3D object detection and BEV segmentation. The ablation uncovers a\nstrong synergy of joint temporal aggregation in the image and BEV latent space.\nThese results indicate the overall effectiveness of our approach and make a\nstrong case for aggregating temporal information in both image and BEV latent\nspaces.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.11803v2",
    "published_date": "2024-04-17 23:49:00 UTC",
    "updated_date": "2024-09-19 03:21:08 UTC"
  },
  {
    "arxiv_id": "2404.11800v1",
    "title": "Developing Situational Awareness for Joint Action with Autonomous Vehicles",
    "authors": [
      "Robert Kaufman",
      "David Kirsh",
      "Nadir Weibel"
    ],
    "abstract": "Unanswered questions about how human-AV interaction designers can support\nrider's informational needs hinders Autonomous Vehicles (AV) adoption. To\nachieve joint human-AV action goals - such as safe transportation, trust, or\nlearning from an AV - sufficient situational awareness must be held by the\nhuman, AV, and human-AV system collectively. We present a systems-level\nframework that integrates cognitive theories of joint action and situational\nawareness as a means to tailor communications that meet the criteria necessary\nfor goal success. This framework is based on four components of the shared\nsituation: AV traits, action goals, subject-specific traits and states, and the\nsituated driving context. AV communications should be tailored to these factors\nand be sensitive when they change. This framework can be useful for\nunderstanding individual, shared, and distributed human-AV situational\nawareness and designing for future AV communications that meet the\ninformational needs and goals of diverse groups and in diverse driving\ncontexts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.11800v1",
    "published_date": "2024-04-17 23:41:48 UTC",
    "updated_date": "2024-04-17 23:41:48 UTC"
  },
  {
    "arxiv_id": "2404.15360v1",
    "title": "Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning",
    "authors": [
      "Simon Tam",
      "Shriram Tallam Puranam Raghu",
      "Étienne Buteau",
      "Erik Scheme",
      "Mounir Boukadoum",
      "Alexandre Campeau-Lecours",
      "Benoit Gosselin"
    ],
    "abstract": "Current electromyography (EMG) pattern recognition (PR) models have been\nshown to generalize poorly in unconstrained environments, setting back their\nadoption in applications such as hand gesture control. This problem is often\ndue to limited training data, exacerbated by the use of supervised\nclassification frameworks that are known to be suboptimal in such settings. In\nthis work, we propose a shift to deep metric-based meta-learning in EMG PR to\nsupervise the creation of meaningful and interpretable representations. We use\na Siamese Deep Convolutional Neural Network (SDCNN) and contrastive triplet\nloss to learn an EMG feature embedding space that captures the distribution of\nthe different classes. A nearest-centroid approach is subsequently employed for\ninference, relying on how closely a test sample aligns with the established\ndata distributions. We derive a robust class proximity-based confidence\nestimator that leads to a better rejection of incorrect decisions, i.e. false\npositives, especially when operating beyond the training data domain. We show\nour approach's efficacy by testing the trained SDCNN's predictions and\nconfidence estimations on unseen data, both in and out of the training domain.\nThe evaluation metrics include the accuracy-rejection curve and the\nKullback-Leibler divergence between the confidence distributions of accurate\nand inaccurate predictions. Outperforming comparable models on both metrics,\nour results demonstrate that the proposed meta-learning approach improves the\nclassifier's precision in active decisions (after rejection), thus leading to\nbetter generalization and applicability.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "eess.SP",
    "comment": "11 pages, 9 figures, submitted to IEEE Transactions on Neural\n  Networks and Learning Systems",
    "pdf_url": "http://arxiv.org/pdf/2404.15360v1",
    "published_date": "2024-04-17 23:37:50 UTC",
    "updated_date": "2024-04-17 23:37:50 UTC"
  },
  {
    "arxiv_id": "2404.11797v1",
    "title": "When are Foundation Models Effective? Understanding the Suitability for Pixel-Level Classification Using Multispectral Imagery",
    "authors": [
      "Yiqun Xie",
      "Zhihao Wang",
      "Weiye Chen",
      "Zhili Li",
      "Xiaowei Jia",
      "Yanhua Li",
      "Ruichen Wang",
      "Kangyang Chai",
      "Ruohan Li",
      "Sergii Skakun"
    ],
    "abstract": "Foundation models, i.e., very large deep learning models, have demonstrated\nimpressive performances in various language and vision tasks that are otherwise\ndifficult to reach using smaller-size models. The major success of GPT-type of\nlanguage models is particularly exciting and raises expectations on the\npotential of foundation models in other domains including satellite remote\nsensing. In this context, great efforts have been made to build foundation\nmodels to test their capabilities in broader applications, and examples include\nPrithvi by NASA-IBM, Segment-Anything-Model, ViT, etc. This leads to an\nimportant question: Are foundation models always a suitable choice for\ndifferent remote sensing tasks, and when or when not? This work aims to enhance\nthe understanding of the status and suitability of foundation models for\npixel-level classification using multispectral imagery at moderate resolution,\nthrough comparisons with traditional machine learning (ML) and regular-size\ndeep learning models. Interestingly, the results reveal that in many scenarios\ntraditional ML models still have similar or better performance compared to\nfoundation models, especially for tasks where texture is less useful for\nclassification. On the other hand, deep learning models did show more promising\nresults for tasks where labels partially depend on texture (e.g., burn scar),\nwhile the difference in performance between foundation models and deep learning\nmodels is not obvious. The results conform with our analysis: The suitability\nof foundation models depend on the alignment between the self-supervised\nlearning tasks and the real downstream tasks, and the typical masked\nautoencoder paradigm is not necessarily suitable for many remote sensing\nproblems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11797v1",
    "published_date": "2024-04-17 23:30:48 UTC",
    "updated_date": "2024-04-17 23:30:48 UTC"
  },
  {
    "arxiv_id": "2404.11795v1",
    "title": "Prompt-Driven Feature Diffusion for Open-World Semi-Supervised Learning",
    "authors": [
      "Marzi Heidari",
      "Hanping Zhang",
      "Yuhong Guo"
    ],
    "abstract": "In this paper, we present a novel approach termed Prompt-Driven Feature\nDiffusion (PDFD) within a semi-supervised learning framework for Open World\nSemi-Supervised Learning (OW-SSL). At its core, PDFD deploys an efficient\nfeature-level diffusion model with the guidance of class-specific prompts to\nsupport discriminative feature representation learning and feature generation,\ntackling the challenge of the non-availability of labeled data for unseen\nclasses in OW-SSL. In particular, PDFD utilizes class prototypes as prompts in\nthe diffusion model, leveraging their class-discriminative and semantic\ngeneralization ability to condition and guide the diffusion process across all\nthe seen and unseen classes. Furthermore, PDFD incorporates a class-conditional\nadversarial loss for diffusion model training, ensuring that the features\ngenerated via the diffusion process can be discriminatively aligned with the\nclass-conditional features of the real data. Additionally, the class prototypes\nof the unseen classes are computed using only unlabeled instances with\nconfident predictions within a semi-supervised learning framework. We conduct\nextensive experiments to evaluate the proposed PDFD. The empirical results show\nPDFD exhibits remarkable performance enhancements over many state-of-the-art\nexisting methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11795v1",
    "published_date": "2024-04-17 23:10:11 UTC",
    "updated_date": "2024-04-17 23:10:11 UTC"
  },
  {
    "arxiv_id": "2404.11792v2",
    "title": "Enhancing Q&A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study",
    "authors": [
      "Zooey Nguyen",
      "Anthony Annunziata",
      "Vinh Luong",
      "Sang Dinh",
      "Quynh Le",
      "Anh Hai Ha",
      "Chanh Le",
      "Hong An Phan",
      "Shruti Raghavan",
      "Christopher Nguyen"
    ],
    "abstract": "This paper investigates the impact of domain-specific model fine-tuning and\nof reasoning mechanisms on the performance of question-answering (Q&A) systems\npowered by large language models (LLMs) and Retrieval-Augmented Generation\n(RAG). Using the FinanceBench SEC financial filings dataset, we observe that,\nfor RAG, combining a fine-tuned embedding model with a fine-tuned LLM achieves\nbetter accuracy than generic models, with relatively greater gains attributable\nto fine-tuned embedding models. Additionally, employing reasoning iterations on\ntop of RAG delivers an even bigger jump in performance, enabling the Q&A\nsystems to get closer to human-expert quality. We discuss the implications of\nsuch findings, propose a structured technical design space capturing major\ntechnical components of Q&A AI, and provide recommendations for making\nhigh-impact technical choices for such components. We plan to follow up on this\nwork with actionable guides for AI teams and further investigations into the\nimpact of domain-specific augmentation in RAG and into agentic AI capabilities\nsuch as advanced planning and reasoning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Fixed typo of OODA's score on harder-question set in Table 2",
    "pdf_url": "http://arxiv.org/pdf/2404.11792v2",
    "published_date": "2024-04-17 23:00:03 UTC",
    "updated_date": "2024-04-19 20:28:16 UTC"
  },
  {
    "arxiv_id": "2404.11782v1",
    "title": "REQUAL-LM: Reliability and Equity through Aggregation in Large Language Models",
    "authors": [
      "Sana Ebrahimi",
      "Nima Shahbazi",
      "Abolfazl Asudeh"
    ],
    "abstract": "The extensive scope of large language models (LLMs) across various domains\nunderscores the critical importance of responsibility in their application,\nbeyond natural language processing. In particular, the randomized nature of\nLLMs, coupled with inherent biases and historical stereotypes in data, raises\ncritical concerns regarding reliability and equity. Addressing these challenges\nare necessary before using LLMs for applications with societal impact. Towards\naddressing this gap, we introduce REQUAL-LM, a novel method for finding\nreliable and equitable LLM outputs through aggregation. Specifically, we\ndevelop a Monte Carlo method based on repeated sampling to find a reliable\noutput close to the mean of the underlying distribution of possible outputs. We\nformally define the terms such as reliability and bias, and design an\nequity-aware aggregation to minimize harmful bias while finding a highly\nreliable output. REQUAL-LM does not require specialized hardware, does not\nimpose a significant computing load, and uses LLMs as a blackbox. This design\nchoice enables seamless scalability alongside the rapid advancement of LLM\ntechnologies. Our system does not require retraining the LLMs, which makes it\ndeployment ready and easy to adapt. Our comprehensive experiments using various\ntasks and datasets demonstrate that REQUAL- LM effectively mitigates bias and\nselects a more equitable response, specifically the outputs that properly\nrepresents minority groups.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11782v1",
    "published_date": "2024-04-17 22:12:41 UTC",
    "updated_date": "2024-04-17 22:12:41 UTC"
  },
  {
    "arxiv_id": "2404.11773v2",
    "title": "Behavior Alignment: A New Perspective of Evaluating LLM-based Conversational Recommender Systems",
    "authors": [
      "Dayu Yang",
      "Fumian Chen",
      "Hui Fang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated great potential in\nConversational Recommender Systems (CRS). However, the application of LLMs to\nCRS has exposed a notable discrepancy in behavior between LLM-based CRS and\nhuman recommenders: LLMs often appear inflexible and passive, frequently\nrushing to complete the recommendation task without sufficient inquiry.This\nbehavior discrepancy can lead to decreased accuracy in recommendations and\nlower user satisfaction. Despite its importance, existing studies in CRS lack a\nstudy about how to measure such behavior discrepancy. To fill this gap, we\npropose Behavior Alignment, a new evaluation metric to measure how well the\nrecommendation strategies made by a LLM-based CRS are consistent with human\nrecommenders'. Our experiment results show that the new metric is better\naligned with human preferences and can better differentiate how systems perform\nthan existing evaluation metrics. As Behavior Alignment requires explicit and\ncostly human annotations on the recommendation strategies, we also propose a\nclassification-based method to implicitly measure the Behavior Alignment based\non the responses. The evaluation results confirm the robustness of the method.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by the 47th International ACM SIGIR Conference on Research\n  and Development in Information Retrieval",
    "pdf_url": "http://arxiv.org/pdf/2404.11773v2",
    "published_date": "2024-04-17 21:56:27 UTC",
    "updated_date": "2024-10-17 18:59:18 UTC"
  },
  {
    "arxiv_id": "2404.11770v1",
    "title": "Event-Based Eye Tracking. AIS 2024 Challenge Survey",
    "authors": [
      "Zuowen Wang",
      "Chang Gao",
      "Zongwei Wu",
      "Marcos V. Conde",
      "Radu Timofte",
      "Shih-Chii Liu",
      "Qinyu Chen",
      "Zheng-jun Zha",
      "Wei Zhai",
      "Han Han",
      "Bohao Liao",
      "Yuliang Wu",
      "Zengyu Wan",
      "Zhong Wang",
      "Yang Cao",
      "Ganchao Tan",
      "Jinze Chen",
      "Yan Ru Pei",
      "Sasskia Brüers",
      "Sébastien Crouzet",
      "Douglas McLelland",
      "Oliver Coenen",
      "Baoheng Zhang",
      "Yizhao Gao",
      "Jingyuan Li",
      "Hayden Kwok-Hay So",
      "Philippe Bich",
      "Chiara Boretti",
      "Luciano Prono",
      "Mircea Lică",
      "David Dinucu-Jianu",
      "Cătălin Grîu",
      "Xiaopeng Lin",
      "Hongwei Ren",
      "Bojun Cheng",
      "Xinan Zhang",
      "Valentin Vial",
      "Anthony Yezzi",
      "James Tsai"
    ],
    "abstract": "This survey reviews the AIS 2024 Event-Based Eye Tracking (EET) Challenge.\nThe task of the challenge focuses on processing eye movement recorded with\nevent cameras and predicting the pupil center of the eye. The challenge\nemphasizes efficient eye tracking with event cameras to achieve good task\naccuracy and efficiency trade-off. During the challenge period, 38 participants\nregistered for the Kaggle competition, and 8 teams submitted a challenge\nfactsheet. The novel and diverse methods from the submitted factsheets are\nreviewed and analyzed in this survey to advance future event-based eye tracking\nresearch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Qinyu Chen is the corresponding author",
    "pdf_url": "http://arxiv.org/pdf/2404.11770v1",
    "published_date": "2024-04-17 21:53:01 UTC",
    "updated_date": "2024-04-17 21:53:01 UTC"
  },
  {
    "arxiv_id": "2404.11754v3",
    "title": "Improved Generalization Bounds for Communication Efficient Federated Learning",
    "authors": [
      "Peyman Gholami",
      "Hulya Seferoglu"
    ],
    "abstract": "This paper focuses on reducing the communication cost of federated learning\nby exploring generalization bounds and representation learning. We first\ncharacterize a tighter generalization bound for one-round federated learning\nbased on local clients' generalizations and heterogeneity of data distribution\n(non-iid scenario). We also characterize a generalization bound in R-round\nfederated learning and its relation to the number of local updates (local\nstochastic gradient descents (SGDs)). Then, based on our generalization bound\nanalysis and our representation learning interpretation of this analysis, we\nshow for the first time that less frequent aggregations, hence more local\nupdates, for the representation extractor (usually corresponds to initial\nlayers) leads to the creation of more generalizable models, particularly for\nnon-iid scenarios. We design a novel Federated Learning with Adaptive Local\nSteps (FedALS) algorithm based on our generalization bound and representation\nlearning analysis. FedALS employs varying aggregation frequencies for different\nparts of the model, so reduces the communication cost. The paper is followed\nwith experimental results showing the effectiveness of FedALS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11754v3",
    "published_date": "2024-04-17 21:17:48 UTC",
    "updated_date": "2024-05-27 23:20:52 UTC"
  },
  {
    "arxiv_id": "2404.11744v1",
    "title": "Incremental Bootstrapping and Classification of Structured Scenes in a Fuzzy Ontology",
    "authors": [
      "Luca Buoncompagni",
      "Fulvio Mastrogiovanni"
    ],
    "abstract": "We foresee robots that bootstrap knowledge representations and use them for\nclassifying relevant situations and making decisions based on future\nobservations. Particularly for assistive robots, the bootstrapping mechanism\nmight be supervised by humans who should not repeat a training phase several\ntimes and should be able to refine the taught representation. We consider\nrobots that bootstrap structured representations to classify some intelligible\ncategories. Such a structure should be incrementally bootstrapped, i.e.,\nwithout invalidating the identified category models when a new additional\ncategory is considered. To tackle this scenario, we presented the Scene\nIdentification and Tagging (SIT) algorithm, which bootstraps structured\nknowledge representation in a crisp OWL-DL ontology. Over time, SIT bootstraps\na graph representing scenes, sub-scenes and similar scenes. Then, SIT can\nclassify new scenes within the bootstrapped graph through logic-based\nreasoning. However, SIT has issues with sensory data because its crisp\nimplementation is not robust to perception noises. This paper presents a\nreformulation of SIT within the fuzzy domain, which exploits a fuzzy DL\nontology to overcome the robustness issues. By comparing the performances of\nfuzzy and crisp implementations of SIT, we show that fuzzy SIT is robust,\npreserves the properties of its crisp formulation, and enhances the\nbootstrapped representations. On the contrary, the fuzzy implementation of SIT\nleads to less intelligible knowledge representations than the one bootstrapped\nin the crisp domain.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LO",
      "cs.RO",
      "68T40 (Primary) 68T30, 68T27, 68T37, 03B52 (Secondary)",
      "I.2.4; I.2.6; I.2.3; I.2.9; I.2.10"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11744v1",
    "published_date": "2024-04-17 20:51:13 UTC",
    "updated_date": "2024-04-17 20:51:13 UTC"
  },
  {
    "arxiv_id": "2404.11742v1",
    "title": "Meta-Decomposition: Dynamic Segmentation Approach Selection in IoT-based Activity Recognition",
    "authors": [
      "Seyed M. R. Modaresi",
      "Aomar Osmani",
      "Mohammadreza Razzazi",
      "Abdelghani Chibani"
    ],
    "abstract": "Internet of Things (IoT) devices generate heterogeneous data over time; and\nrelying solely on individual data points is inadequate for accurate analysis.\n  Segmentation is a common preprocessing step in many IoT applications,\nincluding IoT-based activity recognition, aiming to address the limitations of\nindividual events and streamline the process. However, this step introduces at\nleast two families of uncontrollable biases. The first is caused by the changes\nmade by the segmentation process on the initial problem space, such as dividing\nthe input data into 60 seconds windows. The second category of biases results\nfrom the segmentation process itself, including the fixation of the\nsegmentation method and its parameters.\n  To address these biases, we propose to redefine the segmentation problem as a\nspecial case of a decomposition problem, including three key components: a\ndecomposer, resolutions, and a composer.\n  The inclusion of the composer task in the segmentation process facilitates an\nassessment of the relationship between the original problem and the problem\nafter the segmentation. Therefore, It leads to an improvement in the evaluation\nprocess and, consequently, in the selection of the appropriate segmentation\nmethod.\n  Then, we formally introduce our novel meta-decomposition or\nlearning-to-decompose approach. It reduces the segmentation biases by\nconsidering the segmentation as a hyperparameter to be optimized by the outer\nlearning problem. Therefore, meta-decomposition improves the overall system\nperformance by dynamically selecting the appropriate segmentation method\nwithout including the mentioned biases. Extensive experiments on four\nreal-world datasets demonstrate the effectiveness of our proposal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11742v1",
    "published_date": "2024-04-17 20:50:28 UTC",
    "updated_date": "2024-04-17 20:50:28 UTC"
  },
  {
    "arxiv_id": "2404.11730v2",
    "title": "Missed Connections: Lateral Thinking Puzzles for Large Language Models",
    "authors": [
      "Graham Todd",
      "Tim Merino",
      "Sam Earle",
      "Julian Togelius"
    ],
    "abstract": "The Connections puzzle published each day by the New York Times tasks players\nwith dividing a bank of sixteen words into four groups of four words that each\nrelate to a common theme. Solving the puzzle requires both common linguistic\nknowledge (i.e. definitions and typical usage) as well as, in many cases,\nlateral or abstract thinking. This is because the four categories ascend in\ncomplexity, with the most challenging category often requiring thinking about\nwords in uncommon ways or as parts of larger phrases. We investigate the\ncapacity for automated AI systems to play Connections and explore the game's\npotential as an automated benchmark for abstract reasoning and a way to measure\nthe semantic information encoded by data-driven linguistic systems. In\nparticular, we study both a sentence-embedding baseline and modern large\nlanguage models (LLMs). We report their accuracy on the task, measure the\nimpacts of chain-of-thought prompting, and discuss their failure modes.\nOverall, we find that the Connections task is challenging yet feasible, and a\nstrong test-bed for future work.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11730v2",
    "published_date": "2024-04-17 20:31:05 UTC",
    "updated_date": "2024-04-21 15:38:19 UTC"
  },
  {
    "arxiv_id": "2404.11720v1",
    "title": "GEOBIND: Binding Text, Image, and Audio through Satellite Images",
    "authors": [
      "Aayush Dhakal",
      "Subash Khanal",
      "Srikumar Sastry",
      "Adeel Ahmad",
      "Nathan Jacobs"
    ],
    "abstract": "In remote sensing, we are interested in modeling various modalities for some\ngeographic location. Several works have focused on learning the relationship\nbetween a location and type of landscape, habitability, audio, textual\ndescriptions, etc. Recently, a common way to approach these problems is to\ntrain a deep-learning model that uses satellite images to infer some unique\ncharacteristics of the location. In this work, we present a deep-learning\nmodel, GeoBind, that can infer about multiple modalities, specifically text,\nimage, and audio, from satellite imagery of a location. To do this, we use\nsatellite images as the binding element and contrastively align all other\nmodalities to the satellite image data. Our training results in a joint\nembedding space with multiple types of data: satellite image, ground-level\nimage, audio, and text. Furthermore, our approach does not require a single\ncomplex dataset that contains all the modalities mentioned above. Rather it\nonly requires multiple satellite-image paired data. While we only align three\nmodalities in this paper, we present a general framework that can be used to\ncreate an embedding space with any number of modalities by using satellite\nimages as the binding element. Our results show that, unlike traditional\nunimodal models, GeoBind is versatile and can reason about multiple modalities\nfor a given satellite image input.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2024 IEEE International Geoscience and Remote Sensing Symposium",
    "pdf_url": "http://arxiv.org/pdf/2404.11720v1",
    "published_date": "2024-04-17 20:13:37 UTC",
    "updated_date": "2024-04-17 20:13:37 UTC"
  },
  {
    "arxiv_id": "2404.11716v1",
    "title": "A Survey on Semantic Modeling for Building Energy Management",
    "authors": [
      "Miracle Aniakor",
      "Vinicius V. Cogo",
      "Pedro M. Ferreira"
    ],
    "abstract": "Buildings account for a substantial portion of global energy consumption.\nReducing buildings' energy usage primarily involves obtaining data from\nbuilding systems and environment, which are instrumental in assessing and\noptimizing the building's performance. However, as devices from various\nmanufacturers represent their data in unique ways, this disparity introduces\nchallenges for semantic interoperability and creates obstacles in developing\nscalable building applications. This survey explores the leading semantic\nmodeling techniques deployed for energy management in buildings. Furthermore,\nit aims to offer tangible use cases for applying semantic models, shedding\nlight on the pivotal concepts and limitations intrinsic to each model. Our\nfindings will assist researchers in discerning the appropriate circumstances\nand methodologies for employing these models in various use cases.",
    "categories": [
      "cs.AI",
      "I.2.4; C.m; H.m"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages, 6 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.11716v1",
    "published_date": "2024-04-17 20:10:43 UTC",
    "updated_date": "2024-04-17 20:10:43 UTC"
  },
  {
    "arxiv_id": "2404.11714v1",
    "title": "Implementation and Evaluation of a Gradient Descent-Trained Defensible Blackboard Architecture System",
    "authors": [
      "Jordan Milbrath",
      "Jonathan Rivard",
      "Jeremy Straub"
    ],
    "abstract": "A variety of forms of artificial intelligence systems have been developed.\nTwo well-known techniques are neural networks and rule-fact expert systems. The\nformer can be trained from presented data while the latter is typically\ndeveloped by human domain experts. A combined implementation that uses gradient\ndescent to train a rule-fact expert system has been previously proposed. A\nrelated system type, the Blackboard Architecture, adds an actualization\ncapability to expert systems. This paper proposes and evaluates the\nincorporation of a defensible-style gradient descent training capability into\nthe Blackboard Architecture. It also introduces the use of activation functions\nfor defensible artificial intelligence systems and implements and evaluates a\nnew best path-based training algorithm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11714v1",
    "published_date": "2024-04-17 19:55:58 UTC",
    "updated_date": "2024-04-17 19:55:58 UTC"
  },
  {
    "arxiv_id": "2404.11706v1",
    "title": "Pretraining Billion-scale Geospatial Foundational Models on Frontier",
    "authors": [
      "Aristeidis Tsaris",
      "Philipe Ambrozio Dias",
      "Abhishek Potnis",
      "Junqi Yin",
      "Feiyi Wang",
      "Dalton Lunga"
    ],
    "abstract": "As AI workloads increase in scope, generalization capability becomes\nchallenging for small task-specific models and their demand for large amounts\nof labeled training samples increases. On the contrary, Foundation Models (FMs)\nare trained with internet-scale unlabeled data via self-supervised learning and\nhave been shown to adapt to various tasks with minimal fine-tuning. Although\nlarge FMs have demonstrated significant impact in natural language processing\nand computer vision, efforts toward FMs for geospatial applications have been\nrestricted to smaller size models, as pretraining larger models requires very\nlarge computing resources equipped with state-of-the-art hardware accelerators.\nCurrent satellite constellations collect 100+TBs of data a day, resulting in\nimages that are billions of pixels and multimodal in nature. Such geospatial\ndata poses unique challenges opening up new opportunities to develop FMs. We\ninvestigate billion scale FMs and HPC training profiles for geospatial\napplications by pretraining on publicly available data. We studied from\nend-to-end the performance and impact in the solution by scaling the model\nsize. Our larger 3B parameter size model achieves up to 30% improvement in top1\nscene classification accuracy when comparing a 100M parameter model. Moreover,\nwe detail performance experiments on the Frontier supercomputer, America's\nfirst exascale system, where we study different model and data parallel\napproaches using PyTorch's Fully Sharded Data Parallel library. Specifically,\nwe study variants of the Vision Transformer architecture (ViT), conducting\nperformance analysis for ViT models with size up to 15B parameters. By\ndiscussing throughput and performance bottlenecks under different parallelism\nconfigurations, we offer insights on how to leverage such leadership-class HPC\nresources when developing large models for geospatial imagery applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11706v1",
    "published_date": "2024-04-17 19:16:32 UTC",
    "updated_date": "2024-04-17 19:16:32 UTC"
  },
  {
    "arxiv_id": "2404.11698v1",
    "title": "A Secure and Trustworthy Network Architecture for Federated Learning Healthcare Applications",
    "authors": [
      "Antonio Boiano",
      "Marco Di Gennaro",
      "Luca Barbieri",
      "Michele Carminati",
      "Monica Nicoli",
      "Alessandro Redondi",
      "Stefano Savazzi",
      "Albert Sund Aillet",
      "Diogo Reis Santos",
      "Luigi Serio"
    ],
    "abstract": "Federated Learning (FL) has emerged as a promising approach for\nprivacy-preserving machine learning, particularly in sensitive domains such as\nhealthcare. In this context, the TRUSTroke project aims to leverage FL to\nassist clinicians in ischemic stroke prediction. This paper provides an\noverview of the TRUSTroke FL network infrastructure. The proposed architecture\nadopts a client-server model with a central Parameter Server (PS). We introduce\na Docker-based design for the client nodes, offering a flexible solution for\nimplementing FL processes in clinical settings. The impact of different\ncommunication protocols (HTTP or MQTT) on FL network operation is analyzed,\nwith MQTT selected for its suitability in FL scenarios. A control plane to\nsupport the main operations required by FL processes is also proposed. The\npaper concludes with an analysis of security aspects of the FL architecture,\naddressing potential threats and proposing mitigation strategies to increase\nthe trustworthiness level.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11698v1",
    "published_date": "2024-04-17 18:55:41 UTC",
    "updated_date": "2024-04-17 18:55:41 UTC"
  },
  {
    "arxiv_id": "2404.11677v3",
    "title": "Cross-Problem Learning for Solving Vehicle Routing Problems",
    "authors": [
      "Zhuoyi Lin",
      "Yaoxin Wu",
      "Bangjian Zhou",
      "Zhiguang Cao",
      "Wen Song",
      "Yingqian Zhang",
      "Senthilnath Jayavelu"
    ],
    "abstract": "Existing neural heuristics often train a deep architecture from scratch for\neach specific vehicle routing problem (VRP), ignoring the transferable\nknowledge across different VRP variants. This paper proposes the cross-problem\nlearning to assist heuristics training for different downstream VRP variants.\nParticularly, we modularize neural architectures for complex VRPs into 1) the\nbackbone Transformer for tackling the travelling salesman problem (TSP), and 2)\nthe additional lightweight modules for processing problem-specific features in\ncomplex VRPs. Accordingly, we propose to pre-train the backbone Transformer for\nTSP, and then apply it in the process of fine-tuning the Transformer models for\neach target VRP variant. On the one hand, we fully fine-tune the trained\nbackbone Transformer and problem-specific modules simultaneously. On the other\nhand, we only fine-tune small adapter networks along with the modules, keeping\nthe backbone Transformer still. Extensive experiments on typical VRPs\nsubstantiate that 1) the full fine-tuning achieves significantly better\nperformance than the one trained from scratch, and 2) the adapter-based\nfine-tuning also delivers comparable performance while being notably\nparameter-efficient. Furthermore, we empirically demonstrate the favorable\neffect of our method in terms of cross-distribution application and\nversatility.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IJCAI'24",
    "pdf_url": "http://arxiv.org/pdf/2404.11677v3",
    "published_date": "2024-04-17 18:17:50 UTC",
    "updated_date": "2024-06-18 09:03:08 UTC"
  },
  {
    "arxiv_id": "2404.11667v1",
    "title": "Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification",
    "authors": [
      "Shivvrat Arya",
      "Yu Xiang",
      "Vibhav Gogate"
    ],
    "abstract": "We present a unified framework called deep dependency networks (DDNs) that\ncombines dependency networks and deep learning architectures for multi-label\nclassification, with a particular emphasis on image and video data. The primary\nadvantage of dependency networks is their ease of training, in contrast to\nother probabilistic graphical models like Markov networks. In particular, when\ncombined with deep learning architectures, they provide an intuitive,\neasy-to-use loss function for multi-label classification. A drawback of DDNs\ncompared to Markov networks is their lack of advanced inference schemes,\nnecessitating the use of Gibbs sampling. To address this challenge, we propose\nnovel inference schemes based on local search and integer linear programming\nfor computing the most likely assignment to the labels given observations. We\nevaluate our novel methods on three video datasets (Charades, TACoS, Wetlab)\nand three image datasets (MS-COCO, PASCAL VOC, NUS-WIDE), comparing their\nperformance with (a) basic neural architectures and (b) neural architectures\ncombined with Markov networks equipped with advanced inference and learning\ntechniques. Our results demonstrate the superiority of our new DDN methods over\nthe two competing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Will appear in AISTATS 2024. arXiv admin note: substantial text\n  overlap with arXiv:2302.00633",
    "pdf_url": "http://arxiv.org/pdf/2404.11667v1",
    "published_date": "2024-04-17 18:04:37 UTC",
    "updated_date": "2024-04-17 18:04:37 UTC"
  },
  {
    "arxiv_id": "2404.11606v1",
    "title": "Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models",
    "authors": [
      "Shivvrat Arya",
      "Tahrima Rahman",
      "Vibhav Gogate"
    ],
    "abstract": "We propose a self-supervised learning approach for solving the following\nconstrained optimization task in log-linear models or Markov networks. Let $f$\nand $g$ be two log-linear models defined over the sets $\\mathbf{X}$ and\n$\\mathbf{Y}$ of random variables respectively. Given an assignment $\\mathbf{x}$\nto all variables in $\\mathbf{X}$ (evidence) and a real number $q$, the\nconstrained most-probable explanation (CMPE) task seeks to find an assignment\n$\\mathbf{y}$ to all variables in $\\mathbf{Y}$ such that $f(\\mathbf{x},\n\\mathbf{y})$ is maximized and $g(\\mathbf{x}, \\mathbf{y})\\leq q$. In our\nproposed self-supervised approach, given assignments $\\mathbf{x}$ to\n$\\mathbf{X}$ (data), we train a deep neural network that learns to output\nnear-optimal solutions to the CMPE problem without requiring access to any\npre-computed solutions. The key idea in our approach is to use first principles\nand approximate inference methods for CMPE to derive novel loss functions that\nseek to push infeasible solutions towards feasible ones and feasible solutions\ntowards optimal ones. We analyze the properties of our proposed method and\nexperimentally demonstrate its efficacy on several benchmark problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Will appear in AISTATS 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11606v1",
    "published_date": "2024-04-17 17:55:17 UTC",
    "updated_date": "2024-04-17 17:55:17 UTC"
  },
  {
    "arxiv_id": "2404.11605v1",
    "title": "VG4D: Vision-Language Model Goes 4D Video Recognition",
    "authors": [
      "Zhichao Deng",
      "Xiangtai Li",
      "Xia Li",
      "Yunhai Tong",
      "Shen Zhao",
      "Mengyuan Liu"
    ],
    "abstract": "Understanding the real world through point cloud video is a crucial aspect of\nrobotics and autonomous driving systems. However, prevailing methods for 4D\npoint cloud recognition have limitations due to sensor resolution, which leads\nto a lack of detailed information. Recent advances have shown that\nVision-Language Models (VLM) pre-trained on web-scale text-image datasets can\nlearn fine-grained visual concepts that can be transferred to various\ndownstream tasks. However, effectively integrating VLM into the domain of 4D\npoint clouds remains an unresolved problem. In this work, we propose the\nVision-Language Models Goes 4D (VG4D) framework to transfer VLM knowledge from\nvisual-text pre-trained models to a 4D point cloud network. Our approach\ninvolves aligning the 4D encoder's representation with a VLM to learn a shared\nvisual and text space from training on large-scale image-text pairs. By\ntransferring the knowledge of the VLM to the 4D encoder and combining the VLM,\nour VG4D achieves improved recognition performance. To enhance the 4D encoder,\nwe modernize the classic dynamic point cloud backbone and propose an improved\nversion of PSTNet, im-PSTNet, which can efficiently model point cloud videos.\nExperiments demonstrate that our method achieves state-of-the-art performance\nfor action recognition on both the NTU RGB+D 60 dataset and the NTU RGB+D 120\ndataset. Code is available at \\url{https://github.com/Shark0-0/VG4D}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11605v1",
    "published_date": "2024-04-17 17:54:49 UTC",
    "updated_date": "2024-04-17 17:54:49 UTC"
  },
  {
    "arxiv_id": "2404.11597v2",
    "title": "Explainable Artificial Intelligence Techniques for Accurate Fault Detection and Diagnosis: A Review",
    "authors": [
      "Ahmed Maged",
      "Salah Haridy",
      "Herman Shen"
    ],
    "abstract": "As the manufacturing industry advances with sensor integration and\nautomation, the opaque nature of deep learning models in machine learning poses\na significant challenge for fault detection and diagnosis. And despite the\nrelated predictive insights Artificial Intelligence (AI) can deliver, advanced\nmachine learning engines often remain a black box. This paper reviews the\neXplainable AI (XAI) tools and techniques in this context. We explore various\nXAI methodologies, focusing on their role in making AI decision-making\ntransparent, particularly in critical scenarios where humans are involved. We\nalso discuss current limitations and potential future research that aims to\nbalance explainability with model performance while improving trustworthiness\nin the context of AI applications for critical industrial use cases.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11597v2",
    "published_date": "2024-04-17 17:49:38 UTC",
    "updated_date": "2024-06-10 17:04:10 UTC"
  },
  {
    "arxiv_id": "2404.11589v1",
    "title": "Prompt Optimizer of Text-to-Image Diffusion Models for Abstract Concept Understanding",
    "authors": [
      "Zezhong Fan",
      "Xiaohan Li",
      "Chenhao Fang",
      "Topojoy Biswas",
      "Kaushiki Nag",
      "Jianpeng Xu",
      "Kannan Achan"
    ],
    "abstract": "The rapid evolution of text-to-image diffusion models has opened the door of\ngenerative AI, enabling the translation of textual descriptions into visually\ncompelling images with remarkable quality. However, a persistent challenge\nwithin this domain is the optimization of prompts to effectively convey\nabstract concepts into concrete objects. For example, text encoders can hardly\nexpress \"peace\", while can easily illustrate olive branches and white doves.\nThis paper introduces a novel approach named Prompt Optimizer for Abstract\nConcepts (POAC) specifically designed to enhance the performance of\ntext-to-image diffusion models in interpreting and generating images from\nabstract concepts. We propose a Prompt Language Model (PLM), which is\ninitialized from a pre-trained language model, and then fine-tuned with a\ncurated dataset of abstract concept prompts. The dataset is created with GPT-4\nto extend the abstract concept to a scene and concrete objects. Our framework\nemploys a Reinforcement Learning (RL)-based optimization strategy, focusing on\nthe alignment between the generated images by a stable diffusion model and\noptimized prompts. Through extensive experiments, we demonstrate that our\nproposed POAC significantly improves the accuracy and aesthetic quality of\ngenerated images, particularly in the description of abstract concepts and\nalignment with optimized prompts. We also present a comprehensive analysis of\nour model's performance across diffusion models under different settings,\nshowcasing its versatility and effectiveness in enhancing abstract concept\nrepresentation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "WWW 2024 Companion",
    "pdf_url": "http://arxiv.org/pdf/2404.11589v1",
    "published_date": "2024-04-17 17:38:56 UTC",
    "updated_date": "2024-04-17 17:38:56 UTC"
  },
  {
    "arxiv_id": "2404.11585v2",
    "title": "Spatial Context-based Self-Supervised Learning for Handwritten Text Recognition",
    "authors": [
      "Carlos Penarrubia",
      "Carlos Garrido-Munoz",
      "Jose J. Valero-Mas",
      "Jorge Calvo-Zaragoza"
    ],
    "abstract": "Handwritten Text Recognition (HTR) is a relevant problem in computer vision,\nand implies unique challenges owing to its inherent variability and the rich\ncontextualization required for its interpretation. Despite the success of\nSelf-Supervised Learning (SSL) in computer vision, its application to HTR has\nbeen rather scattered, leaving key SSL methodologies unexplored. This work\nfocuses on one of them, namely Spatial Context-based SSL. We investigate how\nthis family of approaches can be adapted and optimized for HTR and propose new\nworkflows that leverage the unique features of handwritten text. Our\nexperiments demonstrate that the methods considered lead to advancements in the\nstate-of-the-art of SSL for HTR in a number of benchmark cases.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2404.11585v2",
    "published_date": "2024-04-17 17:33:32 UTC",
    "updated_date": "2025-02-25 09:57:55 UTC"
  },
  {
    "arxiv_id": "2404.11584v1",
    "title": "The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey",
    "authors": [
      "Tula Masterman",
      "Sandi Besen",
      "Mason Sawtell",
      "Alex Chao"
    ],
    "abstract": "This survey paper examines the recent advancements in AI agent\nimplementations, with a focus on their ability to achieve complex goals that\nrequire enhanced reasoning, planning, and tool execution capabilities. The\nprimary objectives of this work are to a) communicate the current capabilities\nand limitations of existing AI agent implementations, b) share insights gained\nfrom our observations of these systems in action, and c) suggest important\nconsiderations for future developments in AI agent design. We achieve this by\nproviding overviews of single-agent and multi-agent architectures, identifying\nkey patterns and divergences in design choices, and evaluating their overall\nimpact on accomplishing a provided goal. Our contribution outlines key themes\nwhen selecting an agentic architecture, the impact of leadership on agent\nsystems, agent communication styles, and key phases for planning, execution,\nand reflection that enable robust AI agent systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages,6 figures,38 references",
    "pdf_url": "http://arxiv.org/pdf/2404.11584v1",
    "published_date": "2024-04-17 17:32:41 UTC",
    "updated_date": "2024-04-17 17:32:41 UTC"
  },
  {
    "arxiv_id": "2404.11581v3",
    "title": "E2ETune: End-to-End Knob Tuning via Fine-tuned Generative Language Model",
    "authors": [
      "Xinmei Huang",
      "Haoyang Li",
      "Jing Zhang",
      "Xinxin Zhao",
      "Zhiming Yao",
      "Yiyan Li",
      "Tieying Zhang",
      "Jianjun Chen",
      "Hong Chen",
      "Cuiping Li"
    ],
    "abstract": "Database knob tuning is a significant challenge for database administrators,\nas it involves tuning a large number of configuration knobs with continuous or\ndiscrete values to achieve optimal database performance. Traditional methods,\nsuch as manual tuning or learning-based approaches, typically require numerous\nworkload replays and are both time-consuming and resource-intensive. To address\nthis challenge, we introduce E2ETune, an end-to-end knob tuner powered by a\nfine-tuned generative language model. The key idea is to leverage the\nexceptional sequence-to-sequence modeling capabilities of generative language\nmodels to capture the complex mapping between workloads (inputs) and their\ncorresponding promising configurations (outputs). To achieve this goal, we\npropose a novel data generation framework to efficiently produce a large amount\nof training data, where each data sample consists of a workload and its\npromising configuration. Then, these data are used to fine-tune a generative\nlanguage model, yielding an end-to-end knob tuner. This tuner offers\nout-of-the-box configuration recommendations for new workloads. We conduct\nextensive experiments to evaluate E2ETune's efficiency and effectiveness using\n10 representative and 3 real-world benchmarks. Compared to state-of-the-art\nmethods, E2ETune can identify competitive configurations in significantly less\ntime.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by VLDB 2025",
    "pdf_url": "http://arxiv.org/pdf/2404.11581v3",
    "published_date": "2024-04-17 17:28:05 UTC",
    "updated_date": "2025-03-19 06:19:58 UTC"
  },
  {
    "arxiv_id": "2404.11578v3",
    "title": "LTL-Constrained Policy Optimization with Cycle Experience Replay",
    "authors": [
      "Ameesh Shah",
      "Cameron Voloshin",
      "Chenxi Yang",
      "Abhinav Verma",
      "Swarat Chaudhuri",
      "Sanjit A. Seshia"
    ],
    "abstract": "Linear Temporal Logic (LTL) offers a precise means for constraining the\nbehavior of reinforcement learning agents. However, in many settings where both\nsatisfaction and optimality conditions are present, LTL is insufficient to\ncapture both. Instead, LTL-constrained policy optimization, where the goal is\nto optimize a scalar reward under LTL constraints, is needed. This constrained\noptimization problem proves difficult in deep Reinforcement Learning (DRL)\nsettings, where learned policies often ignore the LTL constraint due to the\nsparse nature of LTL satisfaction. To alleviate the sparsity issue, we\nintroduce Cycle Experience Replay (CyclER), a novel reward shaping technique\nthat exploits the underlying structure of the LTL constraint to guide a policy\ntowards satisfaction by encouraging partial behaviors compliant with the\nconstraint. We provide a theoretical guarantee that optimizing CyclER will\nachieve policies that satisfy the LTL constraint with near-optimal probability.\nWe evaluate CyclER in three continuous control domains. Our experimental\nresults show that optimizing CyclER in tandem with the existing scalar reward\noutperforms existing reward-shaping methods at finding performant\nLTL-satisfying policies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.FL",
      "I.2.6; I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in TMLR, 12 pages in main text",
    "pdf_url": "http://arxiv.org/pdf/2404.11578v3",
    "published_date": "2024-04-17 17:24:44 UTC",
    "updated_date": "2025-03-24 23:37:28 UTC"
  },
  {
    "arxiv_id": "2404.11577v3",
    "title": "Towards Reliable Empirical Machine Unlearning Evaluation: A Cryptographic Game Perspective",
    "authors": [
      "Yiwen Tu",
      "Pingbang Hu",
      "Jiaqi Ma"
    ],
    "abstract": "Machine unlearning updates machine learning models to remove information from\nspecific training samples, complying with data protection regulations that\nallow individuals to request the removal of their personal data. Despite the\nrecent development of numerous unlearning algorithms, reliable evaluation of\nthese algorithms remains an open research question. In this work, we focus on\nmembership inference attack (MIA) based evaluation, one of the most common\napproaches for evaluating unlearning algorithms, and address various pitfalls\nof existing evaluation metrics lacking theoretical understanding and\nreliability. Specifically, by modeling the proposed evaluation process as a\n\\emph{cryptographic game} between unlearning algorithms and MIA adversaries,\nthe naturally-induced evaluation metric measures the data removal efficacy of\nunlearning algorithms and enjoys provable guarantees that existing evaluation\nmetrics fail to satisfy. Furthermore, we propose a practical and efficient\napproximation of the induced evaluation metric and demonstrate its\neffectiveness through both theoretical analysis and empirical experiments.\nOverall, this work presents a novel and reliable approach to empirically\nevaluating unlearning algorithms, paving the way for the development of more\neffective unlearning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11577v3",
    "published_date": "2024-04-17 17:20:27 UTC",
    "updated_date": "2025-02-14 03:03:45 UTC"
  },
  {
    "arxiv_id": "2404.11565v2",
    "title": "MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation",
    "authors": [
      "Kuan-Chieh Wang",
      "Daniil Ostashev",
      "Yuwei Fang",
      "Sergey Tulyakov",
      "Kfir Aberman"
    ],
    "abstract": "We introduce a new architecture for personalization of text-to-image\ndiffusion models, coined Mixture-of-Attention (MoA). Inspired by the\nMixture-of-Experts mechanism utilized in large language models (LLMs), MoA\ndistributes the generation workload between two attention pathways: a\npersonalized branch and a non-personalized prior branch. MoA is designed to\nretain the original model's prior by fixing its attention layers in the prior\nbranch, while minimally intervening in the generation process with the\npersonalized branch that learns to embed subjects in the layout and context\ngenerated by the prior branch. A novel routing mechanism manages the\ndistribution of pixels in each layer across these branches to optimize the\nblend of personalized and generic content creation. Once trained, MoA\nfacilitates the creation of high-quality, personalized images featuring\nmultiple subjects with compositions and interactions as diverse as those\ngenerated by the original model. Crucially, MoA enhances the distinction\nbetween the model's pre-existing capability and the newly augmented\npersonalized intervention, thereby offering a more disentangled subject-context\ncontrol that was previously unattainable. Project page:\nhttps://snap-research.github.io/mixture-of-attention",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Website:\n  https://snap-research.github.io/mixture-of-attention, Same as previous\n  version, only updated metadata because bib was missing an author name",
    "pdf_url": "http://arxiv.org/pdf/2404.11565v2",
    "published_date": "2024-04-17 17:08:05 UTC",
    "updated_date": "2024-05-06 16:29:15 UTC"
  },
  {
    "arxiv_id": "2404.11553v3",
    "title": "Language Ranker: A Metric for Quantifying LLM Performance Across High and Low-Resource Languages",
    "authors": [
      "Zihao Li",
      "Yucheng Shi",
      "Zirui Liu",
      "Fan Yang",
      "Ali Payani",
      "Ninghao Liu",
      "Mengnan Du"
    ],
    "abstract": "The development of Large Language Models (LLMs) relies on extensive text\ncorpora, which are often unevenly distributed across languages. This imbalance\nresults in LLMs performing significantly better on high-resource languages like\nEnglish, German, and French, while their capabilities in low-resource languages\nremain inadequate. Currently, there is a lack of quantitative methods to\nevaluate the performance of LLMs in these low-resource languages. To address\nthis gap, we propose the Language Ranker, an intrinsic metric designed to\nbenchmark and rank languages based on LLM performance using internal\nrepresentations. By comparing the LLM's internal representation of various\nlanguages against a baseline derived from English, we can assess the model's\nmultilingual capabilities in a robust and language-agnostic manner. Our\nanalysis reveals that high-resource languages exhibit higher similarity scores\nwith English, demonstrating superior performance, while low-resource languages\nshow lower similarity scores, underscoring the effectiveness of our metric in\nassessing language-specific capabilities. Besides, the experiments show that\nthere is a strong correlation between the LLM's performance in different\nlanguages and the proportion of those languages in its pre-training corpus.\nThese insights underscore the efficacy of the Language Ranker as a tool for\nevaluating LLM performance across different languages, particularly those with\nlimited resources.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2025 (Social Impact Track)",
    "pdf_url": "http://arxiv.org/pdf/2404.11553v3",
    "published_date": "2024-04-17 16:53:16 UTC",
    "updated_date": "2024-12-11 09:04:18 UTC"
  },
  {
    "arxiv_id": "2404.11536v2",
    "title": "FedPFT: Federated Proxy Fine-Tuning of Foundation Models",
    "authors": [
      "Zhaopeng Peng",
      "Xiaoliang Fan",
      "Yufan Chen",
      "Zheng Wang",
      "Shirui Pan",
      "Chenglu Wen",
      "Ruisheng Zhang",
      "Cheng Wang"
    ],
    "abstract": "Adapting Foundation Models (FMs) for downstream tasks through Federated\nLearning (FL) emerges a promising strategy for protecting data privacy and\nvaluable FMs. Existing methods fine-tune FM by allocating sub-FM to clients in\nFL, however, leading to suboptimal performance due to insufficient tuning and\ninevitable error accumulations of gradients. In this paper, we propose\nFederated Proxy Fine-Tuning (FedPFT), a novel method enhancing FMs adaptation\nin downstream tasks through FL by two key modules. First, the sub-FM\nconstruction module employs a layer-wise compression approach, facilitating\ncomprehensive FM fine-tuning across all layers by emphasizing those crucial\nneurons. Second, the sub-FM alignment module conducts a two-step\ndistillations-layer-level and neuron-level-before and during FL fine-tuning\nrespectively, to reduce error of gradient by accurately aligning sub-FM with FM\nunder theoretical guarantees. Experimental results on seven commonly used\ndatasets (i.e., four text and three vision) demonstrate the superiority of\nFedPFT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI'24",
    "pdf_url": "http://arxiv.org/pdf/2404.11536v2",
    "published_date": "2024-04-17 16:30:06 UTC",
    "updated_date": "2024-04-28 11:11:16 UTC"
  },
  {
    "arxiv_id": "2404.11534v1",
    "title": "Decomposing and Editing Predictions by Modeling Model Computation",
    "authors": [
      "Harshay Shah",
      "Andrew Ilyas",
      "Aleksander Madry"
    ],
    "abstract": "How does the internal computation of a machine learning model transform\ninputs into predictions? In this paper, we introduce a task called component\nmodeling that aims to address this question. The goal of component modeling is\nto decompose an ML model's prediction in terms of its components -- simple\nfunctions (e.g., convolution filters, attention heads) that are the \"building\nblocks\" of model computation. We focus on a special case of this task,\ncomponent attribution, where the goal is to estimate the counterfactual impact\nof individual components on a given prediction. We then present COAR, a\nscalable algorithm for estimating component attributions; we demonstrate its\neffectiveness across models, datasets, and modalities. Finally, we show that\ncomponent attributions estimated with COAR directly enable model editing across\nfive tasks, namely: fixing model errors, ``forgetting'' specific classes,\nboosting subpopulation robustness, localizing backdoor attacks, and improving\nrobustness to typographic attacks. We provide code for COAR at\nhttps://github.com/MadryLab/modelcomponents .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11534v1",
    "published_date": "2024-04-17 16:28:08 UTC",
    "updated_date": "2024-04-17 16:28:08 UTC"
  },
  {
    "arxiv_id": "2404.11515v2",
    "title": "Embedding Privacy in Computational Social Science and Artificial Intelligence Research",
    "authors": [
      "Keenan Jones",
      "Fatima Zahrah",
      "Jason R. C. Nurse"
    ],
    "abstract": "Privacy is a human right. It ensures that individuals are free to engage in\ndiscussions, participate in groups, and form relationships online or offline\nwithout fear of their data being inappropriately harvested, analyzed, or\notherwise used to harm them. Preserving privacy has emerged as a critical\nfactor in research, particularly in the computational social science (CSS),\nartificial intelligence (AI) and data science domains, given their reliance on\nindividuals' data for novel insights. The increasing use of advanced\ncomputational models stands to exacerbate privacy concerns because, if\ninappropriately used, they can quickly infringe privacy rights and lead to\nadverse effects for individuals -- especially vulnerable groups -- and society.\nWe have already witnessed a host of privacy issues emerge with the advent of\nlarge language models (LLMs), such as ChatGPT, which further demonstrate the\nimportance of embedding privacy from the start. This article contributes to the\nfield by discussing the role of privacy and the issues that researchers working\nin CSS, AI, data science and related domains are likely to face. It then\npresents several key considerations for researchers to ensure participant\nprivacy is best preserved in their research design, data collection and use,\nanalysis, and dissemination of research results.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "International Association for the Advancement of Artificial\n  Intelligence (AAAI) Conference on Web and Social Media (ICWSM) Workshops\n  (Disrupt, Ally, Resist, Embrace (DARE) Workshop), 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11515v2",
    "published_date": "2024-04-17 16:07:53 UTC",
    "updated_date": "2024-06-03 14:32:04 UTC"
  },
  {
    "arxiv_id": "2404.11502v1",
    "title": "Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models",
    "authors": [
      "Yushuo Chen",
      "Tianyi Tang",
      "Erge Xiang",
      "Linjiang Li",
      "Wayne Xin Zhao",
      "Jing Wang",
      "Yunpeng Chai",
      "Ji-Rong Wen"
    ],
    "abstract": "In real world, large language models (LLMs) can serve as the assistant to\nhelp users accomplish their jobs, and also support the development of advanced\napplications. For the wide application of LLMs, the inference efficiency is an\nessential concern, which has been widely studied in existing work, and numerous\noptimization algorithms and code libraries have been proposed to improve it.\nNonetheless, users still find it challenging to compare the effectiveness of\nall the above methods and understand the underlying mechanisms. In this work,\nwe perform a detailed coarse-to-fine analysis of the inference performance of\nvarious code libraries. To evaluate the overall effectiveness, we examine four\nusage scenarios within two practical applications. We further provide both\ntheoretical and empirical fine-grained analyses of each module in the\nTransformer architecture. Our experiments yield comprehensive results that are\ninvaluable for researchers to evaluate code libraries and improve inference\nstrategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11502v1",
    "published_date": "2024-04-17 15:57:50 UTC",
    "updated_date": "2024-04-17 15:57:50 UTC"
  },
  {
    "arxiv_id": "2404.11500v1",
    "title": "Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models",
    "authors": [
      "Yue Zhou",
      "Yada Zhu",
      "Diego Antognini",
      "Yoon Kim",
      "Yang Zhang"
    ],
    "abstract": "This paper studies the relationship between the surface form of a\nmathematical problem and its solvability by large language models. We find that\nsubtle alterations in the surface form can significantly impact the answer\ndistribution and the solve rate, exposing the language model's lack of\nrobustness and sensitivity to the surface form in reasoning through complex\nproblems. To improve mathematical reasoning performance, we propose\nSelf-Consistency-over-Paraphrases (SCoP), which diversifies reasoning paths\nfrom specific surface forms of the problem. We evaluate our approach on four\nmathematics reasoning benchmarks over three large language models and show that\nSCoP improves mathematical reasoning performance over vanilla self-consistency,\nparticularly for problems initially deemed unsolvable. Finally, we provide\nadditional experiments and discussion regarding problem difficulty and surface\nforms, including cross-model difficulty agreement and paraphrasing\ntransferability, and Variance of Variations (VOV) for language model\nevaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the main conference of NAACL (2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.11500v1",
    "published_date": "2024-04-17 15:53:49 UTC",
    "updated_date": "2024-04-17 15:53:49 UTC"
  },
  {
    "arxiv_id": "2404.11499v1",
    "title": "A Data-Driven Representation for Sign Language Production",
    "authors": [
      "Harry Walsh",
      "Abolfazl Ravanshad",
      "Mariam Rahmani",
      "Richard Bowden"
    ],
    "abstract": "Phonetic representations are used when recording spoken languages, but no\nequivalent exists for recording signed languages. As a result, linguists have\nproposed several annotation systems that operate on the gloss or sub-unit\nlevel; however, these resources are notably irregular and scarce.\n  Sign Language Production (SLP) aims to automatically translate spoken\nlanguage sentences into continuous sequences of sign language. However, current\nstate-of-the-art approaches rely on scarce linguistic resources to work. This\nhas limited progress in the field. This paper introduces an innovative solution\nby transforming the continuous pose generation problem into a discrete sequence\ngeneration problem. Thus, overcoming the need for costly annotation. Although,\nif available, we leverage the additional information to enhance our approach.\n  By applying Vector Quantisation (VQ) to sign language data, we first learn a\ncodebook of short motions that can be combined to create a natural sequence of\nsign. Where each token in the codebook can be thought of as the lexicon of our\nrepresentation. Then using a transformer we perform a translation from spoken\nlanguage text to a sequence of codebook tokens. Each token can be directly\nmapped to a sequence of poses allowing the translation to be performed by a\nsingle network. Furthermore, we present a sign stitching method to effectively\njoin tokens together. We evaluate on the RWTH-PHOENIX-Weather-2014T\n(PHOENIX14T) and the more challenging Meine DGS Annotated (mDGS) datasets. An\nextensive evaluation shows our approach outperforms previous methods,\nincreasing the BLEU-1 back translation score by up to 72%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 Pages, 3 Figures, 7 Tables, 18th IEEE International Conference on\n  Automatic Face and Gesture Recognition 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11499v1",
    "published_date": "2024-04-17 15:52:38 UTC",
    "updated_date": "2024-04-17 15:52:38 UTC"
  },
  {
    "arxiv_id": "2404.11496v2",
    "title": "Runtime Analysis of Evolutionary Diversity Optimization on the Multi-objective (LeadingOnes, TrailingZeros) Problem",
    "authors": [
      "Denis Antipov",
      "Aneta Neumann",
      "Frank Neumann",
      "Andrew M. Sutton"
    ],
    "abstract": "The diversity optimization is the class of optimization problems, in which we\naim at finding a diverse set of good solutions. One of the frequently used\napproaches to solve such problems is to use evolutionary algorithms which\nevolve a desired diverse population. This approach is called evolutionary\ndiversity optimization (EDO).\n  In this paper, we analyse EDO on a 3-objective function LOTZ$_k$, which is a\nmodification of the 2-objective benchmark function (LeadingOnes,\nTrailingZeros). We prove that the GSEMO computes a set of all Pareto-optimal\nsolutions in $O(kn^3)$ expected iterations. We also analyze the runtime of the\nGSEMO$_D$ (a modification of the GSEMO for diversity optimization) until it\nfinds a population with the best possible diversity for two different diversity\nmeasures, the total imbalance and the sorted imbalances vector. For the first\nmeasure we show that the GSEMO$_D$ optimizes it asymptotically faster than it\nfinds a Pareto-optimal population, in $O(kn^2\\log(n))$ expected iterations, and\nfor the second measure we show an upper bound of $O(k^2n^3\\log(n))$ expected\niterations. We complement our theoretical analysis with an empirical study,\nwhich shows a very similar behavior for both diversity measures that is close\nto the theory predictions.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11496v2",
    "published_date": "2024-04-17 15:51:15 UTC",
    "updated_date": "2024-04-19 00:31:21 UTC"
  },
  {
    "arxiv_id": "2404.11492v1",
    "title": "arcjetCV: an open-source software to analyze material ablation",
    "authors": [
      "Alexandre Quintart",
      "Magnus Haw",
      "Federico Semeraro"
    ],
    "abstract": "arcjetCV is an open-source Python software designed to automate time-resolved\nmeasurements of heatshield material recession and recession rates from arcjet\ntest video footage. This new automated and accessible capability greatly\nexceeds previous manual extraction methods, enabling rapid and detailed\ncharacterization of material recession for any sample with a profile video.\narcjetCV automates the video segmentation process using machine learning\nmodels, including a one-dimensional (1D) Convolutional Neural Network (CNN) to\ninfer the time-window of interest, a two-dimensional (2D) CNN for image and\nedge segmentation, and a Local Outlier Factor (LOF) for outlier filtering. A\ngraphical user interface (GUI) simplifies the user experience and an\napplication programming interface (API) allows users to call the core functions\nfrom scripts, enabling video batch processing. arcjetCV's capability to measure\ntime-resolved recession in turn enables characterization of non-linear\nprocesses (shrinkage, swelling, melt flows, etc.), contributing to higher\nfidelity validation and improved modeling of heatshield material performance.\nThe source code associated with this article can be found at\nhttps://github.com/magnus-haw/arcjetCV.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11492v1",
    "published_date": "2024-04-17 15:47:26 UTC",
    "updated_date": "2024-04-17 15:47:26 UTC"
  },
  {
    "arxiv_id": "2404.11488v1",
    "title": "Multi-resolution Rescored ByteTrack for Video Object Detection on Ultra-low-power Embedded Systems",
    "authors": [
      "Luca Bompani",
      "Manuele Rusci",
      "Daniele Palossi",
      "Francesco Conti",
      "Luca Benini"
    ],
    "abstract": "This paper introduces Multi-Resolution Rescored Byte-Track (MR2-ByteTrack), a\nnovel video object detection framework for ultra-low-power embedded processors.\nThis method reduces the average compute load of an off-the-shelf Deep Neural\nNetwork (DNN) based object detector by up to 2.25$\\times$ by alternating the\nprocessing of high-resolution images (320$\\times$320 pixels) with multiple\ndown-sized frames (192$\\times$192 pixels). To tackle the accuracy degradation\ndue to the reduced image input size, MR2-ByteTrack correlates the output\ndetections over time using the ByteTrack tracker and corrects potential\nmisclassification using a novel probabilistic Rescore algorithm. By\ninterleaving two down-sized images for every high-resolution one as the input\nof different state-of-the-art DNN object detectors with our MR2-ByteTrack, we\ndemonstrate an average accuracy increase of 2.16% and a latency reduction of\n43% on the GAP9 microcontroller compared to a baseline frame-by-frame inference\nscheme using exclusively full-resolution images. Code available at:\nhttps://github.com/Bomps4/Multi_Resolution_Rescored_ByteTrack",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 3 figures Accepted for publication at the Embedded Vision\n  Workshop of the Computer Vision and Pattern Recognition conference, Seattle,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11488v1",
    "published_date": "2024-04-17 15:45:49 UTC",
    "updated_date": "2024-04-17 15:45:49 UTC"
  },
  {
    "arxiv_id": "2404.11483v2",
    "title": "AgentKit: Structured LLM Reasoning with Dynamic Graphs",
    "authors": [
      "Yue Wu",
      "Yewen Fan",
      "So Yeon Min",
      "Shrimai Prabhumoye",
      "Stephen McAleer",
      "Yonatan Bisk",
      "Ruslan Salakhutdinov",
      "Yuanzhi Li",
      "Tom Mitchell"
    ],
    "abstract": "We propose an intuitive LLM prompting framework (AgentKit) for\nmultifunctional agents. AgentKit offers a unified framework for explicitly\nconstructing a complex \"thought process\" from simple natural language prompts.\nThe basic building block in AgentKit is a node, containing a natural language\nprompt for a specific subtask. The user then puts together chains of nodes,\nlike stacking LEGO pieces. The chains of nodes can be designed to explicitly\nenforce a naturally structured \"thought process\". For example, for the task of\nwriting a paper, one may start with the thought process of 1) identify a core\nmessage, 2) identify prior research gaps, etc. The nodes in AgentKit can be\ndesigned and combined in different ways to implement multiple advanced\ncapabilities including on-the-fly hierarchical planning, reflection, and\nlearning from interactions. In addition, due to the modular nature and the\nintuitive design to simulate explicit human thought process, a basic agent\ncould be implemented as simple as a list of prompts for the subtasks and\ntherefore could be designed and tuned by someone without any programming\nexperience. Quantitatively, we show that agents designed through AgentKit\nachieve SOTA performance on WebShop and Crafter. These advances underscore\nAgentKit's potential in making LLM agents effective and accessible for a wider\nrange of applications. https://github.com/holmeswww/AgentKit",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11483v2",
    "published_date": "2024-04-17 15:40:45 UTC",
    "updated_date": "2024-07-24 20:53:10 UTC"
  },
  {
    "arxiv_id": "2404.11477v3",
    "title": "Discovering Nuclear Models from Symbolic Machine Learning",
    "authors": [
      "Jose M. Munoz",
      "Silviu M. Udrescu",
      "Ronald F. Garcia Ruiz"
    ],
    "abstract": "Numerous phenomenological nuclear models have been proposed to describe\nspecific observables within different regions of the nuclear chart. However,\ndeveloping a unified model that describes the complex behavior of all nuclei\nremains an open challenge. Here, we explore whether novel symbolic Machine\nLearning (ML) can rediscover traditional nuclear physics models or identify\nalternatives with improved simplicity, fidelity, and predictive power. To\naddress this challenge, we developed a Multi-objective Iterated Symbolic\nRegression approach that handles symbolic regressions over multiple target\nobservables, accounts for experimental uncertainties and is robust against\nhigh-dimensional problems. As a proof of principle, we applied this method to\ndescribe the nuclear binding energies and charge radii of light and medium mass\nnuclei. Our approach identified simple analytical relationships based on the\nnumber of protons and neutrons, providing interpretable models with precision\ncomparable to state-of-the-art nuclear models. Additionally, we integrated this\nML-discovered model with an existing complementary model to estimate the limits\nof nuclear stability. These results highlight the potential of symbolic ML to\ndevelop accurate nuclear models and guide our description of complex many-body\nproblems.",
    "categories": [
      "nucl-th",
      "cs.AI",
      "cs.LG",
      "nucl-ex"
    ],
    "primary_category": "nucl-th",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11477v3",
    "published_date": "2024-04-17 15:32:58 UTC",
    "updated_date": "2024-07-03 14:47:09 UTC"
  },
  {
    "arxiv_id": "2404.11476v1",
    "title": "Taxonomy to Regulation: A (Geo)Political Taxonomy for AI Risks and Regulatory Measures in the EU AI Act",
    "authors": [
      "Sinan Arda"
    ],
    "abstract": "Technological innovations have shown remarkable capabilities to benefit and\nharm society alike. AI constitutes a democratized sophisticated technology\naccessible to large parts of society, including malicious actors. This work\nproposes a taxonomy focusing on on (geo)political risks associated with AI. It\nidentifies 12 risks in total divided into four categories: (1) Geopolitical\nPressures, (2) Malicious Usage, (3) Environmental, Social, and Ethical Risks,\nand (4) Privacy and Trust Violations. Incorporating a regulatory side, this\npaper conducts a policy assessment of the EU AI Act. Adopted in March 2023, the\nlandmark regulation has the potential to have a positive top-down impact\nconcerning AI risk reduction but needs regulatory adjustments to mitigate risks\nmore comprehensively. Regulatory exceptions for open-source models, excessively\nhigh parameters for the classification of GPAI models as a systemic risk, and\nthe exclusion of systems designed exclusively for military purposes from the\nregulation's obligations leave room for future action.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "68T01",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11476v1",
    "published_date": "2024-04-17 15:32:56 UTC",
    "updated_date": "2024-04-17 15:32:56 UTC"
  },
  {
    "arxiv_id": "2404.11475v1",
    "title": "AdaIR: Exploiting Underlying Similarities of Image Restoration Tasks with Adapters",
    "authors": [
      "Hao-Wei Chen",
      "Yu-Syuan Xu",
      "Kelvin C. K. Chan",
      "Hsien-Kai Kuo",
      "Chun-Yi Lee",
      "Ming-Hsuan Yang"
    ],
    "abstract": "Existing image restoration approaches typically employ extensive networks\nspecifically trained for designated degradations. Despite being effective, such\nmethods inevitably entail considerable storage costs and computational\noverheads due to the reliance on task-specific networks. In this work, we go\nbeyond this well-established framework and exploit the inherent commonalities\namong image restoration tasks. The primary objective is to identify components\nthat are shareable across restoration tasks and augment the shared components\nwith modules specifically trained for individual tasks. Towards this goal, we\npropose AdaIR, a novel framework that enables low storage cost and efficient\ntraining without sacrificing performance. Specifically, a generic restoration\nnetwork is first constructed through self-supervised pre-training using\nsynthetic degradations. Subsequent to the pre-training phase, adapters are\ntrained to adapt the pre-trained network to specific degradations. AdaIR\nrequires solely the training of lightweight, task-specific modules, ensuring a\nmore efficient storage and training regimen. We have conducted extensive\nexperiments to validate the effectiveness of AdaIR and analyze the influence of\nthe pre-training strategy on discovering shareable components. Extensive\nexperimental results show that AdaIR achieves outstanding results on multi-task\nrestoration while utilizing significantly fewer parameters (1.9 MB) and less\ntraining time (7 hours) for each restoration task. The source codes and trained\nmodels will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11475v1",
    "published_date": "2024-04-17 15:31:06 UTC",
    "updated_date": "2024-04-17 15:31:06 UTC"
  },
  {
    "arxiv_id": "2404.11461v2",
    "title": "Using Game Engines and Machine Learning to Create Synthetic Satellite Imagery for a Tabletop Verification Exercise",
    "authors": [
      "Johannes Hoster",
      "Sara Al-Sayed",
      "Felix Biessmann",
      "Alexander Glaser",
      "Kristian Hildebrand",
      "Igor Moric",
      "Tuong Vy Nguyen"
    ],
    "abstract": "Satellite imagery is regarded as a great opportunity for citizen-based\nmonitoring of activities of interest. Relevant imagery may however not be\navailable at sufficiently high resolution, quality, or cadence -- let alone be\nuniformly accessible to open-source analysts. This limits an assessment of the\ntrue long-term potential of citizen-based monitoring of nuclear activities\nusing publicly available satellite imagery. In this article, we demonstrate how\nmodern game engines combined with advanced machine-learning techniques can be\nused to generate synthetic imagery of sites of interest with the ability to\nchoose relevant parameters upon request; these include time of day, cloud\ncover, season, or level of activity onsite. At the same time, resolution and\noff-nadir angle can be adjusted to simulate different characteristics of the\nsatellite. While there are several possible use-cases for synthetic imagery,\nhere we focus on its usefulness to support tabletop exercises in which simple\nmonitoring scenarios can be examined to better understand verification\ncapabilities enabled by new satellite constellations and very short revisit\ntimes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Annual Meeting of the Institute of Nuclear Materials Management\n  (INMM), Vienna",
    "pdf_url": "http://arxiv.org/pdf/2404.11461v2",
    "published_date": "2024-04-17 15:09:31 UTC",
    "updated_date": "2024-06-23 10:38:22 UTC"
  },
  {
    "arxiv_id": "2404.11458v1",
    "title": "Learn to Tour: Operator Design For Solution Feasibility Mapping in Pickup-and-delivery Traveling Salesman Problem",
    "authors": [
      "Bowen Fang",
      "Xu Chen",
      "Xuan Di"
    ],
    "abstract": "This paper aims to develop a learning method for a special class of traveling\nsalesman problems (TSP), namely, the pickup-and-delivery TSP (PDTSP), which\nfinds the shortest tour along a sequence of one-to-one pickup-and-delivery\nnodes. One-to-one here means that the transported people or goods are\nassociated with designated pairs of pickup and delivery nodes, in contrast to\nthat indistinguishable goods can be delivered to any nodes. In PDTSP,\nprecedence constraints need to be satisfied that each pickup node must be\nvisited before its corresponding delivery node. Classic operations research\n(OR) algorithms for PDTSP are difficult to scale to large-sized problems.\nRecently, reinforcement learning (RL) has been applied to TSPs. The basic idea\nis to explore and evaluate visiting sequences in a solution space. However,\nthis approach could be less computationally efficient, as it has to potentially\nevaluate many infeasible solutions of which precedence constraints are\nviolated. To restrict solution search within a feasible space, we utilize\noperators that always map one feasible solution to another, without spending\ntime exploring the infeasible solution space. Such operators are evaluated and\nselected as policies to solve PDTSPs in an RL framework. We make a comparison\nof our method and baselines, including classic OR algorithms and existing\nlearning methods. Results show that our approach can find tours shorter than\nbaselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11458v1",
    "published_date": "2024-04-17 15:05:51 UTC",
    "updated_date": "2024-04-17 15:05:51 UTC"
  },
  {
    "arxiv_id": "2404.11457v2",
    "title": "Bias and Unfairness in Information Retrieval Systems: New Challenges in the LLM Era",
    "authors": [
      "Sunhao Dai",
      "Chen Xu",
      "Shicheng Xu",
      "Liang Pang",
      "Zhenhua Dong",
      "Jun Xu"
    ],
    "abstract": "With the rapid advancements of large language models (LLMs), information\nretrieval (IR) systems, such as search engines and recommender systems, have\nundergone a significant paradigm shift. This evolution, while heralding new\nopportunities, introduces emerging challenges, particularly in terms of biases\nand unfairness, which may threaten the information ecosystem. In this paper, we\npresent a comprehensive survey of existing works on emerging and pressing bias\nand unfairness issues in IR systems when the integration of LLMs. We first\nunify bias and unfairness issues as distribution mismatch problems, providing a\ngroundwork for categorizing various mitigation strategies through distribution\nalignment. Subsequently, we systematically delve into the specific bias and\nunfairness issues arising from three critical stages of LLMs integration into\nIR systems: data collection, model development, and result evaluation. In doing\nso, we meticulously review and analyze recent literature, focusing on the\ndefinitions, characteristics, and corresponding mitigation strategies\nassociated with these issues. Finally, we identify and highlight some open\nproblems and challenges for future work, aiming to inspire researchers and\nstakeholders in the IR field and beyond to better understand and mitigate bias\nand unfairness issues of IR in this LLM era. We also consistently maintain a\nGitHub repository for the relevant papers and resources in this rising\ndirection at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "KDD 2024 Tutorial&Survey; Tutorial Website:\n  https://llm-ir-bias-fairness.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2404.11457v2",
    "published_date": "2024-04-17 15:05:03 UTC",
    "updated_date": "2024-08-21 17:23:03 UTC"
  },
  {
    "arxiv_id": "2404.11447v1",
    "title": "Research on emotionally intelligent dialogue generation based on automatic dialogue system",
    "authors": [
      "Jin Wang",
      "JinFei Wang",
      "Shuying Dai",
      "Jiqiang Yu",
      "Keqin Li"
    ],
    "abstract": "Automated dialogue systems are important applications of artificial\nintelligence, and traditional systems struggle to understand user emotions and\nprovide empathetic feedback. This study integrates emotional intelligence\ntechnology into automated dialogue systems and creates a dialogue generation\nmodel with emotional intelligence through deep learning and natural language\nprocessing techniques. The model can detect and understand a wide range of\nemotions and specific pain signals in real time, enabling the system to provide\nempathetic interaction. By integrating the results of the study \"Can artificial\nintelligence detect pain and express pain empathy?\", the model's ability to\nunderstand the subtle elements of pain empathy has been enhanced, setting\nhigher standards for emotional intelligence dialogue systems. The project aims\nto provide theoretical understanding and practical suggestions to integrate\nadvanced emotional intelligence capabilities into dialogue systems, thereby\nimproving user experience and interaction quality.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11447v1",
    "published_date": "2024-04-17 14:55:03 UTC",
    "updated_date": "2024-04-17 14:55:03 UTC"
  },
  {
    "arxiv_id": "2404.11446v1",
    "title": "Open-Ended Wargames with Large Language Models",
    "authors": [
      "Daniel P. Hogan",
      "Andrea Brennen"
    ],
    "abstract": "Wargames are a powerful tool for understanding and rehearsing real-world\ndecision making. Automated play of wargames using artificial intelligence (AI)\nenables possibilities beyond those of human-conducted games, such as playing\nthe game many times over to see a range of possible outcomes. There are two\ncategories of wargames: quantitative games, with discrete types of moves, and\nqualitative games, which revolve around open-ended responses. Historically,\nautomation efforts have focused on quantitative games, but large language\nmodels (LLMs) make it possible to automate qualitative wargames. We introduce\n\"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative\nwargames. With Snow Globe, every stage of a text-based qualitative wargame from\nscenario preparation to post-game analysis can be optionally carried out by AI,\nhumans, or a combination thereof. We describe its software architecture\nconceptually and release an open-source implementation alongside this\npublication. As case studies, we simulate a tabletop exercise about an AI\nincident response and a political wargame about a geopolitical crisis. We\ndiscuss potential applications of the approach and how it fits into the broader\nwargaming ecosystem.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11446v1",
    "published_date": "2024-04-17 14:54:58 UTC",
    "updated_date": "2024-04-17 14:54:58 UTC"
  },
  {
    "arxiv_id": "2404.11443v1",
    "title": "Prediction of Unmanned Surface Vessel Motion Attitude Based on CEEMDAN-PSO-SVM",
    "authors": [
      "Zhuoya Geng",
      "Jianmei Chen",
      "Wanqiang Zhu"
    ],
    "abstract": "Unmanned boats, while navigating at sea, utilize active compensation systems\nto mitigate wave disturbances experienced by onboard instruments and equipment.\nHowever, there exists a lag in the measurement of unmanned boat attitudes, thus\nintroducing unmanned boat motion attitude prediction to compensate for the lag\nin the signal acquisition process. This paper, based on the basic principles of\nwaves, derives the disturbance patterns of waves on unmanned boats from the\nwave energy spectrum. Through simulation analysis of unmanned boat motion\nattitudes, motion attitude data is obtained, providing experimental data for\nsubsequent work. A combined prediction model based on Complete Ensemble\nEmpirical Mode Decomposition with Adaptive Noise (CEEMDAN), Particle Swarm\nOptimization (PSO), and Support Vector Machine (SVM) is designed to predict the\nmotion attitude of unmanned boats. Simulation results validate its superior\nprediction accuracy compared to traditional prediction models. For example, in\nterms of mean absolute error, it improves by 17% compared to the EMD-PSO-SVM\nmodel.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11443v1",
    "published_date": "2024-04-17 14:53:03 UTC",
    "updated_date": "2024-04-17 14:53:03 UTC"
  },
  {
    "arxiv_id": "2404.11431v2",
    "title": "Instantiations and Computational Aspects of Non-Flat Assumption-based Argumentation",
    "authors": [
      "Tuomo Lehtonen",
      "Anna Rapberger",
      "Francesca Toni",
      "Markus Ulbricht",
      "Johannes P. Wallner"
    ],
    "abstract": "Most existing computational tools for assumption-based argumentation (ABA)\nfocus on so-called flat frameworks, disregarding the more general case. In this\npaper, we study an instantiation-based approach for reasoning in possibly\nnon-flat ABA. We make use of a semantics-preserving translation between ABA and\nbipolar argumentation frameworks (BAFs). By utilizing compilability theory, we\nestablish that the constructed BAFs will in general be of exponential size. In\norder to keep the number of arguments and computational cost low, we present\nthree ways of identifying redundant arguments. Moreover, we identify fragments\nof ABA which admit a poly-sized instantiation. We propose two algorithmic\napproaches for reasoning in possibly non-flat ABA. The first approach utilizes\nthe BAF instantiation while the second works directly without constructing\narguments. An empirical evaluation shows that the former outperforms the latter\non many instances, reflecting the lower complexity of BAF reasoning. This\nresult is in contrast to flat ABA, where direct approaches dominate\ninstantiation-based approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11431v2",
    "published_date": "2024-04-17 14:36:47 UTC",
    "updated_date": "2024-05-24 13:42:44 UTC"
  },
  {
    "arxiv_id": "2404.11422v2",
    "title": "Short-term wind speed forecasting model based on an attention-gated recurrent neural network and error correction strategy",
    "authors": [
      "Haojian Huang"
    ],
    "abstract": "The accurate wind speed series forecast is very pivotal to security of grid\ndispatching and the application of wind power. Nevertheless, on account of\ntheir nonlinear and non-stationary nature, their short-term forecast is\nextremely challenging. Therefore, this dissertation raises one short-term wind\nspeed forecast pattern on the foundation of attention with an improved gated\nrecurrent neural network (AtGRU) and a tactic of error correction. That model\nuses the AtGRU model as the preliminary predictor and the GRU model as the\nerror corrector. At the beginning, SSA (singular spectrum analysis) is employed\nin previous wind speed series for lessening the noise. Subsequently, historical\nwind speed series is going to be used for the predictor training. During this\nprocess, the prediction can have certain errors. The sequence of these errors\nprocessed by variational modal decomposition (VMD) is used to train the\ncorrector of error. The eventual forecast consequence is just the sum of\npredictor forecast and error corrector. The proposed SSA-AtGRU-VMD-GRU model\noutperforms the compared models in three case studies on Woodburn, St. Thomas,\nand Santa Cruz. It is indicated that the model evidently enhances the\ncorrection of the wind speed forecast.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 11 figures, 6 tables, Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2404.11422v2",
    "published_date": "2024-04-17 14:27:45 UTC",
    "updated_date": "2024-04-22 11:21:31 UTC"
  },
  {
    "arxiv_id": "2404.11408v1",
    "title": "DUPE: Detection Undermining via Prompt Engineering for Deepfake Text",
    "authors": [
      "James Weichert",
      "Chinecherem Dimobi"
    ],
    "abstract": "As large language models (LLMs) become increasingly commonplace, concern\nabout distinguishing between human and AI text increases as well. The growing\npower of these models is of particular concern to teachers, who may worry that\nstudents will use LLMs to write school assignments. Facing a technology with\nwhich they are unfamiliar, teachers may turn to publicly-available AI text\ndetectors. Yet the accuracy of many of these detectors has not been thoroughly\nverified, posing potential harm to students who are falsely accused of academic\ndishonesty. In this paper, we evaluate three different AI text\ndetectors-Kirchenbauer et al. watermarks, ZeroGPT, and GPTZero-against human\nand AI-generated essays. We find that watermarking results in a high false\npositive rate, and that ZeroGPT has both high false positive and false negative\nrates. Further, we are able to significantly increase the false negative rate\nof all detectors by using ChatGPT 3.5 to paraphrase the original AI-generated\ntexts, thereby effectively bypassing the detectors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11408v1",
    "published_date": "2024-04-17 14:10:27 UTC",
    "updated_date": "2024-04-17 14:10:27 UTC"
  },
  {
    "arxiv_id": "2404.11370v3",
    "title": "Characterizing and modeling harms from interactions with design patterns in AI interfaces",
    "authors": [
      "Lujain Ibrahim",
      "Luc Rocher",
      "Ana Valdivia"
    ],
    "abstract": "The proliferation of applications using artificial intelligence (AI) systems\nhas led to a growing number of users interacting with these systems through\nsophisticated interfaces. Human-computer interaction research has long shown\nthat interfaces shape both user behavior and user perception of technical\ncapabilities and risks. Yet, practitioners and researchers evaluating the\nsocial and ethical risks of AI systems tend to overlook the impact of\nanthropomorphic, deceptive, and immersive interfaces on human-AI interactions.\nHere, we argue that design features of interfaces with adaptive AI systems can\nhave cascading impacts, driven by feedback loops, which extend beyond those\npreviously considered. We first conduct a scoping review of AI interface\ndesigns and their negative impact to extract salient themes of potentially\nharmful design patterns in AI interfaces. Then, we propose Design-Enhanced\nControl of AI systems (DECAI), a conceptual model to structure and facilitate\nimpact assessments of AI interface designs. DECAI draws on principles from\ncontrol systems theory -- a theory for the analysis and design of dynamic\nphysical systems -- to dissect the role of the interface in human-AI systems.\nThrough two case studies on recommendation systems and conversational language\nmodel systems, we show how DECAI can be used to evaluate AI interface designs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Fixed issue with subsection titles",
    "pdf_url": "http://arxiv.org/pdf/2404.11370v3",
    "published_date": "2024-04-17 13:30:45 UTC",
    "updated_date": "2024-05-20 19:23:52 UTC"
  },
  {
    "arxiv_id": "2404.11350v2",
    "title": "Calibrating Bayesian Learning via Regularization, Confidence Minimization, and Selective Inference",
    "authors": [
      "Jiayi Huang",
      "Sangwoo Park",
      "Osvaldo Simeone"
    ],
    "abstract": "The application of artificial intelligence (AI) models in fields such as\nengineering is limited by the known difficulty of quantifying the reliability\nof an AI's decision. A well-calibrated AI model must correctly report its\naccuracy on in-distribution (ID) inputs, while also enabling the detection of\nout-of-distribution (OOD) inputs. A conventional approach to improve\ncalibration is the application of Bayesian ensembling. However, owing to\ncomputational limitations and model misspecification, practical ensembling\nstrategies do not necessarily enhance calibration. This paper proposes an\nextension of variational inference (VI)-based Bayesian learning that integrates\ncalibration regularization for improved ID performance, confidence minimization\nfor OOD detection, and selective calibration to ensure a synergistic use of\ncalibration regularization and confidence minimization. The scheme is\nconstructed successively by first introducing calibration-regularized Bayesian\nlearning (CBNN), then incorporating out-of-distribution confidence minimization\n(OCM) to yield CBNN-OCM, and finally integrating also selective calibration to\nproduce selective CBNN-OCM (SCBNN-OCM). Selective calibration rejects inputs\nfor which the calibration performance is expected to be insufficient. Numerical\nresults illustrate the trade-offs between ID accuracy, ID calibration, and OOD\ncalibration attained by both frequentist and Bayesian learning methods. Among\nthe main conclusions, SCBNN-OCM is seen to achieve best ID and OOD performance\nas compared to existing state-of-the-art approaches at the cost of rejecting a\nsufficiently large number of inputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2404.11350v2",
    "published_date": "2024-04-17 13:08:26 UTC",
    "updated_date": "2024-12-31 23:02:54 UTC"
  },
  {
    "arxiv_id": "2404.11343v2",
    "title": "Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System",
    "authors": [
      "Sein Kim",
      "Hongseok Kang",
      "Seungyoon Choi",
      "Donghyun Kim",
      "Minchul Yang",
      "Chanyoung Park"
    ],
    "abstract": "Collaborative filtering recommender systems (CF-RecSys) have shown successive\nresults in enhancing the user experience on social media and e-commerce\nplatforms. However, as CF-RecSys struggles under cold scenarios with sparse\nuser-item interactions, recent strategies have focused on leveraging modality\ninformation of user/items (e.g., text or images) based on pre-trained modality\nencoders and Large Language Models (LLMs). Despite their effectiveness under\ncold scenarios, we observe that they underperform simple traditional\ncollaborative filtering models under warm scenarios due to the lack of\ncollaborative knowledge. In this work, we propose an efficient All-round\nLLM-based Recommender system, called A-LLMRec, that excels not only in the cold\nscenario but also in the warm scenario. Our main idea is to enable an LLM to\ndirectly leverage the collaborative knowledge contained in a pre-trained\nstate-of-the-art CF-RecSys so that the emergent ability of the LLM as well as\nthe high-quality user/item embeddings that are already trained by the\nstate-of-the-art CF-RecSys can be jointly exploited. This approach yields two\nadvantages: (1) model-agnostic, allowing for integration with various existing\nCF-RecSys, and (2) efficiency, eliminating the extensive fine-tuning typically\nrequired for LLM-based recommenders. Our extensive experiments on various\nreal-world datasets demonstrate the superiority of A-LLMRec in various\nscenarios, including cold/warm, few-shot, cold user, and cross-domain\nscenarios. Beyond the recommendation task, we also show the potential of\nA-LLMRec in generating natural language outputs based on the understanding of\nthe collaborative knowledge by performing a favorite genre prediction task. Our\ncode is available at https://github.com/ghdtjr/A-LLMRec .",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11343v2",
    "published_date": "2024-04-17 13:03:07 UTC",
    "updated_date": "2024-06-01 07:08:49 UTC"
  },
  {
    "arxiv_id": "2404.11341v2",
    "title": "The Causal Chambers: Real Physical Systems as a Testbed for AI Methodology",
    "authors": [
      "Juan L. Gamella",
      "Jonas Peters",
      "Peter Bühlmann"
    ],
    "abstract": "In some fields of AI, machine learning and statistics, the validation of new\nmethods and algorithms is often hindered by the scarcity of suitable real-world\ndatasets. Researchers must often turn to simulated data, which yields limited\ninformation about the applicability of the proposed methods to real problems.\nAs a step forward, we have constructed two devices that allow us to quickly and\ninexpensively produce large datasets from non-trivial but well-understood\nphysical systems. The devices, which we call causal chambers, are\ncomputer-controlled laboratories that allow us to manipulate and measure an\narray of variables from these physical systems, providing a rich testbed for\nalgorithms from a variety of fields. We illustrate potential applications\nthrough a series of case studies in fields such as causal discovery,\nout-of-distribution generalization, change point detection, independent\ncomponent analysis, and symbolic regression. For applications to causal\ninference, the chambers allow us to carefully perform interventions. We also\nprovide and empirically validate a causal model of each chamber, which can be\nused as ground truth for different tasks. All hardware and software is made\nopen source, and the datasets are publicly available at causalchamber.org or\nthrough the Python package causalchamber.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "40 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11341v2",
    "published_date": "2024-04-17 13:00:52 UTC",
    "updated_date": "2024-08-26 12:14:31 UTC"
  },
  {
    "arxiv_id": "2404.11335v1",
    "title": "SoccerNet Game State Reconstruction: End-to-End Athlete Tracking and Identification on a Minimap",
    "authors": [
      "Vladimir Somers",
      "Victor Joos",
      "Anthony Cioppa",
      "Silvio Giancola",
      "Seyed Abolfazl Ghasemzadeh",
      "Floriane Magera",
      "Baptiste Standaert",
      "Amir Mohammad Mansourian",
      "Xin Zhou",
      "Shohreh Kasaei",
      "Bernard Ghanem",
      "Alexandre Alahi",
      "Marc Van Droogenbroeck",
      "Christophe De Vleeschouwer"
    ],
    "abstract": "Tracking and identifying athletes on the pitch holds a central role in\ncollecting essential insights from the game, such as estimating the total\ndistance covered by players or understanding team tactics. This tracking and\nidentification process is crucial for reconstructing the game state, defined by\nthe athletes' positions and identities on a 2D top-view of the pitch, (i.e. a\nminimap). However, reconstructing the game state from videos captured by a\nsingle camera is challenging. It requires understanding the position of the\nathletes and the viewpoint of the camera to localize and identify players\nwithin the field. In this work, we formalize the task of Game State\nReconstruction and introduce SoccerNet-GSR, a novel Game State Reconstruction\ndataset focusing on football videos. SoccerNet-GSR is composed of 200 video\nsequences of 30 seconds, annotated with 9.37 million line points for pitch\nlocalization and camera calibration, as well as over 2.36 million athlete\npositions on the pitch with their respective role, team, and jersey number.\nFurthermore, we introduce GS-HOTA, a novel metric to evaluate game state\nreconstruction methods. Finally, we propose and release an end-to-end baseline\nfor game state reconstruction, bootstrapping the research on this task. Our\nexperiments show that GSR is a challenging novel task, which opens the field\nfor future research. Our dataset and codebase are publicly available at\nhttps://github.com/SoccerNet/sn-gamestate.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11335v1",
    "published_date": "2024-04-17 12:53:45 UTC",
    "updated_date": "2024-04-17 12:53:45 UTC"
  },
  {
    "arxiv_id": "2404.11317v2",
    "title": "Improving Composed Image Retrieval via Contrastive Learning with Scaling Positives and Negatives",
    "authors": [
      "Zhangchi Feng",
      "Richong Zhang",
      "Zhijie Nie"
    ],
    "abstract": "The Composed Image Retrieval (CIR) task aims to retrieve target images using\na composed query consisting of a reference image and a modified text. Advanced\nmethods often utilize contrastive learning as the optimization objective, which\nbenefits from adequate positive and negative examples. However, the triplet for\nCIR incurs high manual annotation costs, resulting in limited positive\nexamples. Furthermore, existing methods commonly use in-batch negative\nsampling, which reduces the negative number available for the model. To address\nthe problem of lack of positives, we propose a data generation method by\nleveraging a multi-modal large language model to construct triplets for CIR. To\nintroduce more negatives during fine-tuning, we design a two-stage fine-tuning\nframework for CIR, whose second stage introduces plenty of static\nrepresentations of negatives to optimize the representation space rapidly. The\nabove two improvements can be effectively stacked and designed to be\nplug-and-play, easily applied to existing CIR models without changing their\noriginal architectures. Extensive experiments and ablation analysis demonstrate\nthat our method effectively scales positives and negatives and achieves\nstate-of-the-art results on both FashionIQ and CIRR datasets. In addition, our\nmethod also performs well in zero-shot composed image retrieval, providing a\nnew CIR solution for the low-resources scenario. Our code and data are released\nat https://github.com/BUAADreamer/SPN4CIR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ACM MM 2024 Regular Papers",
    "pdf_url": "http://arxiv.org/pdf/2404.11317v2",
    "published_date": "2024-04-17 12:30:54 UTC",
    "updated_date": "2024-08-07 13:20:30 UTC"
  },
  {
    "arxiv_id": "2404.11313v1",
    "title": "NTIRE 2024 Challenge on Short-form UGC Video Quality Assessment: Methods and Results",
    "authors": [
      "Xin Li",
      "Kun Yuan",
      "Yajing Pei",
      "Yiting Lu",
      "Ming Sun",
      "Chao Zhou",
      "Zhibo Chen",
      "Radu Timofte",
      "Wei Sun",
      "Haoning Wu",
      "Zicheng Zhang",
      "Jun Jia",
      "Zhichao Zhang",
      "Linhan Cao",
      "Qiubo Chen",
      "Xiongkuo Min",
      "Weisi Lin",
      "Guangtao Zhai",
      "Jianhui Sun",
      "Tianyi Wang",
      "Lei Li",
      "Han Kong",
      "Wenxuan Wang",
      "Bing Li",
      "Cheng Luo",
      "Haiqiang Wang",
      "Xiangguang Chen",
      "Wenhui Meng",
      "Xiang Pan",
      "Huiying Shi",
      "Han Zhu",
      "Xiaozhong Xu",
      "Lei Sun",
      "Zhenzhong Chen",
      "Shan Liu",
      "Fangyuan Kong",
      "Haotian Fan",
      "Yifang Xu",
      "Haoran Xu",
      "Mengduo Yang",
      "Jie Zhou",
      "Jiaze Li",
      "Shijie Wen",
      "Mai Xu",
      "Da Li",
      "Shunyu Yao",
      "Jiazhi Du",
      "Wangmeng Zuo",
      "Zhibo Li",
      "Shuai He",
      "Anlong Ming",
      "Huiyuan Fu",
      "Huadong Ma",
      "Yong Wu",
      "Fie Xue",
      "Guozhi Zhao",
      "Lina Du",
      "Jie Guo",
      "Yu Zhang",
      "Huimin Zheng",
      "Junhao Chen",
      "Yue Liu",
      "Dulan Zhou",
      "Kele Xu",
      "Qisheng Xu",
      "Tao Sun",
      "Zhixiang Ding",
      "Yuhang Hu"
    ],
    "abstract": "This paper reviews the NTIRE 2024 Challenge on Shortform UGC Video Quality\nAssessment (S-UGC VQA), where various excellent solutions are submitted and\nevaluated on the collected dataset KVQ from popular short-form video platform,\ni.e., Kuaishou/Kwai Platform. The KVQ database is divided into three parts,\nincluding 2926 videos for training, 420 videos for validation, and 854 videos\nfor testing. The purpose is to build new benchmarks and advance the development\nof S-UGC VQA. The competition had 200 participants and 13 teams submitted valid\nsolutions for the final testing phase. The proposed solutions achieved\nstate-of-the-art performances for S-UGC VQA. The project can be found at\nhttps://github.com/lixinustc/KVQChallenge-CVPR-NTIRE2024.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by CVPR2024 Workshop. The challenge report for CVPR\n  NTIRE2024 Short-form UGC Video Quality Assessment Challenge",
    "pdf_url": "http://arxiv.org/pdf/2404.11313v1",
    "published_date": "2024-04-17 12:26:13 UTC",
    "updated_date": "2024-04-17 12:26:13 UTC"
  },
  {
    "arxiv_id": "2406.15377v1",
    "title": "Model Callers for Transforming Predictive and Generative AI Applications",
    "authors": [
      "Mukesh Dalal"
    ],
    "abstract": "We introduce a novel software abstraction termed \"model caller,\" acting as an\nintermediary for AI and ML model calling, advocating its transformative utility\nbeyond existing model-serving frameworks. This abstraction offers multiple\nadvantages: enhanced accuracy and reduced latency in model predictions,\nsuperior monitoring and observability of models, more streamlined AI system\narchitectures, simplified AI development and management processes, and improved\ncollaboration and accountability across AI/ML/Data Science, software, data, and\noperations teams. Model callers are valuable for both creators and users of\nmodels within both predictive and generative AI applications. Additionally, we\nhave developed and released a prototype Python library for model callers,\naccessible for installation via pip or for download from GitHub.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "cs.PL",
      "cs.SE",
      "68T05 (Primary) 68T07, 68N19, 68T35 (Secondary)",
      "I.2.0; I.2.1; I.2.5; I.2.11; D.2.11; D.3.3; H.1.2; J.0"
    ],
    "primary_category": "cs.CY",
    "comment": "18 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.15377v1",
    "published_date": "2024-04-17 12:21:06 UTC",
    "updated_date": "2024-04-17 12:21:06 UTC"
  },
  {
    "arxiv_id": "2404.11296v2",
    "title": "How to Exhibit More Predictable Behaviors",
    "authors": [
      "Salomé Lepers",
      "Sophie Lemonnier",
      "Vincent Thomas",
      "Olivier Buffet"
    ],
    "abstract": "This paper looks at predictability problems, i.e., wherein an agent must\nchoose its strategy in order to optimize the predictions that an external\nobserver could make. We address these problems while taking into account\nuncertainties on the environment dynamics and on the observed agent's policy.\nTo that end, we assume that the observer 1. seeks to predict the agent's future\naction or state at each time step, and 2. models the agent using a stochastic\npolicy computed from a known underlying problem, and we leverage on the\nframework of observer-aware Markov decision processes (OAMDPs). We propose\naction and state predictability performance criteria through reward functions\nbuilt on the observer's belief about the agent policy; show that these induced\npredictable OAMDPs can be represented by goal-oriented or discounted MDPs; and\nanalyze the properties of the proposed reward functions both theoretically and\nempirically on two types of grid-world problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages, 14 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.11296v2",
    "published_date": "2024-04-17 12:06:17 UTC",
    "updated_date": "2024-10-07 13:06:01 UTC"
  },
  {
    "arxiv_id": "2404.11290v1",
    "title": "Inductive Cognitive Diagnosis for Fast Student Learning in Web-Based Online Intelligent Education Systems",
    "authors": [
      "Shuo Liu",
      "Junhao Shen",
      "Hong Qian",
      "Aimin Zhou"
    ],
    "abstract": "Cognitive diagnosis aims to gauge students' mastery levels based on their\nresponse logs. Serving as a pivotal module in web-based online intelligent\neducation systems (WOIESs), it plays an upstream and fundamental role in\ndownstream tasks like learning item recommendation and computerized adaptive\ntesting. WOIESs are open learning environment where numerous new students\nconstantly register and complete exercises. In WOIESs, efficient cognitive\ndiagnosis is crucial to fast feedback and accelerating student learning.\nHowever, the existing cognitive diagnosis methods always employ intrinsically\ntransductive student-specific embeddings, which become slow and costly due to\nretraining when dealing with new students who are unseen during training. To\nthis end, this paper proposes an inductive cognitive diagnosis model (ICDM) for\nfast new students' mastery levels inference in WOIESs. Specifically, in ICDM,\nwe propose a novel student-centered graph (SCG). Rather than inferring mastery\nlevels through updating student-specific embedding, we derive the inductive\nmastery levels as the aggregated outcomes of students' neighbors in SCG.\nNamely, SCG enables to shift the task from finding the most suitable\nstudent-specific embedding that fits the response logs to finding the most\nsuitable representations for different node types in SCG, and the latter is\nmore efficient since it no longer requires retraining. To obtain this\nrepresentation, ICDM consists of a\nconstruction-aggregation-generation-transformation process to learn the final\nrepresentation of students, exercises and concepts. Extensive experiments\nacross real-world datasets show that, compared with the existing cognitive\ndiagnosis methods that are always transductive, ICDM is much more faster while\nmaintains the competitive inference performance for new students.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "WWW 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11290v1",
    "published_date": "2024-04-17 11:55:43 UTC",
    "updated_date": "2024-04-17 11:55:43 UTC"
  },
  {
    "arxiv_id": "2404.11280v2",
    "title": "Image Generative Semantic Communication with Multi-Modal Similarity Estimation for Resource-Limited Networks",
    "authors": [
      "Eri Hosonuma",
      "Taku Yamazaki",
      "Takumi Miyoshi",
      "Akihito Taya",
      "Yuuki Nishiyama",
      "Kaoru Sezaki"
    ],
    "abstract": "To reduce network traffic and support environments with limited resources, a\nmethod for transmitting images with minimal transmission data is required.\nSeveral machine learning-based image compression methods, which compress the\ndata size of images while maintaining their features, have been proposed.\nHowever, in certain situations, reconstructing only the semantic information of\nimages at the receiver end may be sufficient. To realize this concept,\nsemantic-information-based communication, called semantic communication, has\nbeen proposed, along with an image transmission method using semantic\ncommunication. This method transmits only the semantic information of an image,\nand the receiver reconstructs it using an image-generation model. This method\nutilizes a single type of semantic information for image reconstruction, but\nreconstructing images similar to the original image using only this information\nis challenging. This study proposes a multi-modal image transmission method\nthat leverages various types of semantic information for efficient semantic\ncommunication. The proposed method extracts multi-modal semantic information\nfrom an original image and transmits only that to a receiver. Subsequently, the\nreceiver generates multiple images using an image-generation model and selects\nan output image based on semantic similarity. The receiver must select the\nresult based only on the received features; however, evaluating the similarity\nusing conventional metrics is challenging. Therefore, this study explores new\nmetrics to evaluate the similarity between semantic features of images and\nproposes two scoring procedures for evaluating semantic similarity between\nimages based on multiple semantic features. The results indicate that the\nproposed procedures can compare semantic similarities, such as position and\ncomposition, between the semantic features of the original and generated\nimages.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "14 pages, 15 figures, this paper has been submitted to IEICE\n  Transactions on Communications",
    "pdf_url": "http://arxiv.org/pdf/2404.11280v2",
    "published_date": "2024-04-17 11:42:39 UTC",
    "updated_date": "2024-08-03 04:49:55 UTC"
  },
  {
    "arxiv_id": "2404.11276v2",
    "title": "Towards Data-Centric Automatic R&D",
    "authors": [
      "Haotian Chen",
      "Xinjie Shen",
      "Zeqi Ye",
      "Wenjun Feng",
      "Haoxue Wang",
      "Xiao Yang",
      "Xu Yang",
      "Weiqing Liu",
      "Jiang Bian"
    ],
    "abstract": "The progress of humanity is driven by those successful discoveries\naccompanied by countless failed experiments. Researchers often seek the\npotential research directions by reading and then verifying them through\nexperiments. The process imposes a significant burden on researchers. In the\npast decade, the data-driven black-box deep learning method has demonstrated\nits effectiveness in a wide range of real-world scenarios, which exacerbates\nthe experimental burden of researchers and thus renders the potential\nsuccessful discoveries veiled. Therefore, automating such a research and\ndevelopment (R&D) process is an urgent need. In this paper, we serve as the\nfirst effort to formalize the goal by proposing a Real-world Data-centric\nautomatic R&D Benchmark, namely RD2Bench. RD2Bench benchmarks all the\noperations in data-centric automatic R&D (D-CARD) as a whole to navigate future\nwork toward our goal directly. We focus on evaluating the interaction and\nsynergistic effects of various model capabilities and aiding in selecting\nwell-performing trustworthy models. Although RD2Bench is very challenging to\nthe state-of-the-art (SOTA) large language model (LLM) named GPT-4, indicating\nample research opportunities and more research efforts, LLMs possess promising\npotential to bring more significant development to D-CARD: They are able to\nimplement some simple methods without adopting any additional techniques. We\nappeal to future work to take developing techniques for tackling automatic R&D\ninto consideration, thus bringing the opportunities of the potential\nrevolutionary upgrade to human productivity.",
    "categories": [
      "cs.AI",
      "q-fin.GN"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11276v2",
    "published_date": "2024-04-17 11:33:21 UTC",
    "updated_date": "2024-07-30 04:10:53 UTC"
  },
  {
    "arxiv_id": "2404.11269v3",
    "title": "DACAD: Domain Adaptation Contrastive Learning for Anomaly Detection in Multivariate Time Series",
    "authors": [
      "Zahra Zamanzadeh Darban",
      "Yiyuan Yang",
      "Geoffrey I. Webb",
      "Charu C. Aggarwal",
      "Qingsong Wen",
      "Shirui Pan",
      "Mahsa Salehi"
    ],
    "abstract": "In time series anomaly detection (TSAD), the scarcity of labeled data poses a\nchallenge to the development of accurate models. Unsupervised domain adaptation\n(UDA) offers a solution by leveraging labeled data from a related domain to\ndetect anomalies in an unlabeled target domain. However, existing UDA methods\nassume consistent anomalous classes across domains. To address this limitation,\nwe propose a novel Domain Adaptation Contrastive learning model for Anomaly\nDetection in multivariate time series (DACAD), combining UDA with contrastive\nlearning. DACAD utilizes an anomaly injection mechanism that enhances\ngeneralization across unseen anomalous classes, improving adaptability and\nrobustness. Additionally, our model employs supervised contrastive loss for the\nsource domain and self-supervised contrastive triplet loss for the target\ndomain, ensuring comprehensive feature representation learning and\ndomain-invariant feature extraction. Finally, an effective Center-based Entropy\nClassifier (CEC) accurately learns normal boundaries in the source domain.\nExtensive evaluations on multiple real-world datasets and a synthetic dataset\nhighlight DACAD's superior performance in transferring knowledge across domains\nand mitigating the challenge of limited labeled data in TSAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 3 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.11269v3",
    "published_date": "2024-04-17 11:20:14 UTC",
    "updated_date": "2025-05-14 13:06:20 UTC"
  },
  {
    "arxiv_id": "2404.11243v4",
    "title": "Multi-Sensor Diffusion-Driven Optical Image Translation for Large-Scale Applications",
    "authors": [
      "João Gabriel Vinholi",
      "Marco Chini",
      "Anis Amziane",
      "Renato Machado",
      "Danilo Silva",
      "Patrick Matgen"
    ],
    "abstract": "Comparing images captured by disparate sensors is a common challenge in\nremote sensing. This requires image translation -- converting imagery from one\nsensor domain to another while preserving the original content. Denoising\nDiffusion Implicit Models (DDIM) are potential state-of-the-art solutions for\nsuch domain translation due to their proven superiority in multiple\nimage-to-image translation tasks in computer vision. However, these models\nstruggle with reproducing radiometric features of large-scale multi-patch\nimagery, resulting in inconsistencies across the full image. This renders\ndownstream tasks like Heterogeneous Change Detection impractical. To overcome\nthese limitations, we propose a method that leverages denoising diffusion for\neffective multi-sensor optical image translation over large areas. Our approach\nsuper-resolves large-scale low spatial resolution images into high-resolution\nequivalents from disparate optical sensors, ensuring uniformity across hundreds\nof patches. Our contributions lie in new forward and reverse diffusion\nprocesses that address the challenges of large-scale image translation.\nExtensive experiments using paired Sentinel-II (10m) and Planet Dove (3m)\nimages demonstrate that our approach provides precise domain adaptation,\npreserving image content while improving radiometric accuracy and feature\nrepresentation. A thorough image quality assessment and comparisons with the\nstandard DDIM framework and five other leading methods are presented. We reach\na mean Learned Perceptual Image Patch Similarity (mLPIPS) of 0.1884 and a\nFr\\'echet Inception Distance (FID) of 45.64, expressively outperforming all\ncompared methods, including DDIM, ShuffleMixer, and SwinIR. The usefulness of\nour approach is further demonstrated in two Heterogeneous Change Detection\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This is the accepted version of the manuscript published in IEEE\n  Journal of Selected Topics in Applied Earth Observations and Remote Sensing\n  (JSTARS). Please access the final version at IEEEXplore (Open Access). DOI\n  10.1109/JSTARS.2024.3506032. This technology is protected by a patent filed\n  on 23 december 2023 at Office Luxembourgeois de la propri\\'et\\'e\n  intellectuelle (LU505861)",
    "pdf_url": "http://arxiv.org/pdf/2404.11243v4",
    "published_date": "2024-04-17 10:49:00 UTC",
    "updated_date": "2024-12-04 11:23:37 UTC"
  },
  {
    "arxiv_id": "2404.11230v1",
    "title": "Energy-Efficient Uncertainty-Aware Biomass Composition Prediction at the Edge",
    "authors": [
      "Muhammad Zawish",
      "Paul Albert",
      "Flavio Esposito",
      "Steven Davy",
      "Lizy Abraham"
    ],
    "abstract": "Clover fixates nitrogen from the atmosphere to the ground, making\ngrass-clover mixtures highly desirable to reduce external nitrogen\nfertilization. Herbage containing clover additionally promotes higher food\nintake, resulting in higher milk production. Herbage probing however remains\nlargely unused as it requires a time-intensive manual laboratory analysis.\nWithout this information, farmers are unable to perform localized clover sowing\nor take targeted fertilization decisions. Deep learning algorithms have been\nproposed with the goal to estimate the dry biomass composition from images of\nthe grass directly in the fields. The energy-intensive nature of deep learning\nhowever limits deployment to practical edge devices such as smartphones. This\npaper proposes to fill this gap by applying filter pruning to reduce the energy\nrequirement of existing deep learning solutions. We report that although pruned\nnetworks are accurate on controlled, high-quality images of the grass, they\nstruggle to generalize to real-world smartphone images that are blurry or taken\nfrom challenging angles. We address this challenge by training filter-pruned\nmodels using a variance attenuation loss so they can predict the uncertainty of\ntheir predictions. When the uncertainty exceeds a threshold, we re-infer using\na more accurate unpruned model. This hybrid approach allows us to reduce energy\nconsumption while retaining a high accuracy. We evaluate our algorithm on two\ndatasets: the GrassClover and the Irish clover using an NVIDIA Jetson Nano edge\ndevice. We find that we reduce energy reduction with respect to\nstate-of-the-art solutions by 50% on average with only 4% accuracy loss.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The paper has been accepted to CVPR 2024 5th Workshop on Vision for\n  Agriculture",
    "pdf_url": "http://arxiv.org/pdf/2404.11230v1",
    "published_date": "2024-04-17 10:26:49 UTC",
    "updated_date": "2024-04-17 10:26:49 UTC"
  },
  {
    "arxiv_id": "2404.11225v2",
    "title": "In-Context Learning State Vector with Inner and Momentum Optimization",
    "authors": [
      "Dongfang Li",
      "Zhenyu Liu",
      "Xinshuo Hu",
      "Zetian Sun",
      "Baotian Hu",
      "Min Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited an impressive ability to perform\nIn-Context Learning (ICL) from only a few examples. Recent works have indicated\nthat the functions learned by ICL can be represented through compressed vectors\nderived from the transformer. However, the working mechanisms and optimization\nof these vectors are yet to be thoroughly explored. In this paper, we address\nthis gap by presenting a comprehensive analysis of these compressed vectors,\ndrawing parallels to the parameters trained with gradient descent, and\nintroduce the concept of state vector. Inspired by the works on model soup and\nmomentum-based gradient descent, we propose inner and momentum optimization\nmethods that are applied to refine the state vector progressively as test-time\nadaptation. Moreover, we simulate state vector aggregation in the multiple\nexample setting, where demonstrations comprising numerous examples are usually\ntoo lengthy for regular ICL, and further propose a divide-and-conquer\naggregation method to address this challenge. We conduct extensive experiments\nusing Llama-2 and GPT-J in both zero-shot setting and few-shot setting. The\nexperimental results show that our optimization method effectively enhances the\nstate vector and achieves the state-of-the-art performance on diverse tasks.\nCode is available at https://github.com/HITsz-TMG/ICL-State-Vector",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2404.11225v2",
    "published_date": "2024-04-17 10:19:15 UTC",
    "updated_date": "2024-07-04 11:52:11 UTC"
  },
  {
    "arxiv_id": "2404.11216v2",
    "title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation",
    "authors": [
      "Zhiyuan He",
      "Huiqiang Jiang",
      "Zilong Wang",
      "Yuqing Yang",
      "Luna Qiu",
      "Lili Qiu"
    ],
    "abstract": "The performance of large language models (LLMs) is significantly influenced\nby the quality of the prompts provided. In response, researchers have developed\nenormous prompt engineering strategies aimed at modifying the prompt text to\nenhance task performance. In this paper, we introduce a novel technique termed\nposition engineering, which offers a more efficient way to guide large language\nmodels. Unlike prompt engineering, which requires substantial effort to modify\nthe text provided to LLMs, position engineering merely involves altering the\npositional information in the prompt without modifying the text itself. We have\nevaluated position engineering in two widely-used LLM scenarios:\nretrieval-augmented generation (RAG) and in-context learning (ICL). Our\nfindings show that position engineering substantially improves upon the\nbaseline in both cases. Position engineering thus represents a promising new\nstrategy for exploiting the capabilities of large language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11216v2",
    "published_date": "2024-04-17 10:00:56 UTC",
    "updated_date": "2024-10-22 05:45:46 UTC"
  },
  {
    "arxiv_id": "2404.11214v2",
    "title": "Feature Corrective Transfer Learning: End-to-End Solutions to Object Detection in Non-Ideal Visual Conditions",
    "authors": [
      "Chuheng Wei",
      "Guoyuan Wu",
      "Matthew J. Barth"
    ],
    "abstract": "A significant challenge in the field of object detection lies in the system's\nperformance under non-ideal imaging conditions, such as rain, fog, low\nillumination, or raw Bayer images that lack ISP processing. Our study\nintroduces \"Feature Corrective Transfer Learning\", a novel approach that\nleverages transfer learning and a bespoke loss function to facilitate the\nend-to-end detection of objects in these challenging scenarios without the need\nto convert non-ideal images into their RGB counterparts. In our methodology, we\ninitially train a comprehensive model on a pristine RGB image dataset.\nSubsequently, non-ideal images are processed by comparing their feature maps\nagainst those from the initial ideal RGB model. This comparison employs the\nExtended Area Novel Structural Discrepancy Loss (EANSDL), a novel loss function\ndesigned to quantify similarities and integrate them into the detection loss.\nThis approach refines the model's ability to perform object detection across\nvarying conditions through direct feature map correction, encapsulating the\nessence of Feature Corrective Transfer Learning. Experimental validation on\nvariants of the KITTI dataset demonstrates a significant improvement in mean\nAverage Precision (mAP), resulting in a 3.8-8.1% relative enhancement in\ndetection under non-ideal conditions compared to the baseline model, and a less\nmarginal performance difference within 1.3% of the mAP@[0.5:0.95] achieved\nunder ideal conditions by the standard Faster RCNN algorithm.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "2024 CVPR UG2+ Workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.11214v2",
    "published_date": "2024-04-17 09:58:53 UTC",
    "updated_date": "2024-04-19 14:26:06 UTC"
  },
  {
    "arxiv_id": "2404.11213v1",
    "title": "Revisiting Noise Resilience Strategies in Gesture Recognition: Short-Term Enhancement in Surface Electromyographic Signal Analysis",
    "authors": [
      "Weiyu Guo",
      "Ziyue Qiao",
      "Ying Sun",
      "Hui Xiong"
    ],
    "abstract": "Gesture recognition based on surface electromyography (sEMG) has been gaining\nimportance in many 3D Interactive Scenes. However, sEMG is easily influenced by\nvarious forms of noise in real-world environments, leading to challenges in\nproviding long-term stable interactions through sEMG. Existing methods often\nstruggle to enhance model noise resilience through various predefined data\naugmentation techniques. In this work, we revisit the problem from a short term\nenhancement perspective to improve precision and robustness against various\ncommon noisy scenarios with learnable denoise using sEMG intrinsic pattern\ninformation and sliding-window attention. We propose a Short Term Enhancement\nModule(STEM) which can be easily integrated with various models. STEM offers\nseveral benefits: 1) Learnable denoise, enabling noise reduction without manual\ndata augmentation; 2) Scalability, adaptable to various models; and 3)\nCost-effectiveness, achieving short-term enhancement through minimal\nweight-sharing in an efficient attention mechanism. In particular, we\nincorporate STEM into a transformer, creating the Short Term Enhanced\nTransformer (STET). Compared with best-competing approaches, the impact of\nnoise on STET is reduced by more than 20%. We also report promising results on\nboth classification and regression datasets and demonstrate that STEM\ngeneralizes across different gesture recognition tasks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11213v1",
    "published_date": "2024-04-17 09:57:40 UTC",
    "updated_date": "2024-04-17 09:57:40 UTC"
  },
  {
    "arxiv_id": "2404.11209v1",
    "title": "Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM",
    "authors": [
      "Hongzhao Li",
      "Hongyu Wang",
      "Xia Sun",
      "Hua He",
      "Jun Feng"
    ],
    "abstract": "Medical report generation automates radiology descriptions from images,\neasing the burden on physicians and minimizing errors. However, current methods\nlack structured outputs and physician interactivity for clear, clinically\nrelevant reports. Our method introduces a prompt-guided approach to generate\nstructured chest X-ray reports using a pre-trained large language model (LLM).\nFirst, we identify anatomical regions in chest X-rays to generate focused\nsentences that center on key visual elements, thereby establishing a structured\nreport foundation with anatomy-based sentences. We also convert the detected\nanatomy into textual prompts conveying anatomical comprehension to the LLM.\nAdditionally, the clinical context prompts guide the LLM to emphasize\ninteractivity and clinical requirements. By integrating anatomy-focused\nsentences and anatomy/clinical prompts, the pre-trained LLM can generate\nstructured chest X-ray reports tailored to prompted anatomical regions and\nclinical contexts. We evaluate using language generation and clinical\neffectiveness metrics, demonstrating strong performance.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE Conference on Multimedia Expo 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11209v1",
    "published_date": "2024-04-17 09:45:43 UTC",
    "updated_date": "2024-04-17 09:45:43 UTC"
  },
  {
    "arxiv_id": "2404.11208v1",
    "title": "CAGE: Causality-Aware Shapley Value for Global Explanations",
    "authors": [
      "Nils Ole Breuer",
      "Andreas Sauter",
      "Majid Mohammadi",
      "Erman Acar"
    ],
    "abstract": "As Artificial Intelligence (AI) is having more influence on our everyday\nlives, it becomes important that AI-based decisions are transparent and\nexplainable. As a consequence, the field of eXplainable AI (or XAI) has become\npopular in recent years. One way to explain AI models is to elucidate the\npredictive importance of the input features for the AI model in general, also\nreferred to as global explanations. Inspired by cooperative game theory,\nShapley values offer a convenient way for quantifying the feature importance as\nexplanations. However many methods based on Shapley values are built on the\nassumption of feature independence and often overlook causal relations of the\nfeatures which could impact their importance for the ML model. Inspired by\nstudies of explanations at the local level, we propose CAGE (Causally-Aware\nShapley Values for Global Explanations). In particular, we introduce a novel\nsampling procedure for out-coalition features that respects the causal\nrelations of the input features. We derive a practical approach that\nincorporates causal knowledge into global explanation and offers the\npossibility to interpret the predictive feature importance considering their\ncausal relation. We evaluate our method on synthetic data and real-world data.\nThe explanations from our approach suggest that they are not only more\nintuitive but also more faithful compared to previous global explanation\nmethods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11208v1",
    "published_date": "2024-04-17 09:43:54 UTC",
    "updated_date": "2024-04-17 09:43:54 UTC"
  },
  {
    "arxiv_id": "2404.11207v1",
    "title": "Exploring the Transferability of Visual Prompting for Multimodal Large Language Models",
    "authors": [
      "Yichi Zhang",
      "Yinpeng Dong",
      "Siyuan Zhang",
      "Tianzan Min",
      "Hang Su",
      "Jun Zhu"
    ],
    "abstract": "Although Multimodal Large Language Models (MLLMs) have demonstrated promising\nversatile capabilities, their performance is still inferior to specialized\nmodels on downstream tasks, which makes adaptation necessary to enhance their\nutility. However, fine-tuning methods require independent training for every\nmodel, leading to huge computation and memory overheads. In this paper, we\npropose a novel setting where we aim to improve the performance of diverse\nMLLMs with a group of shared parameters optimized for a downstream task. To\nachieve this, we propose Transferable Visual Prompting (TVP), a simple and\neffective approach to generate visual prompts that can transfer to different\nmodels and improve their performance on downstream tasks after trained on only\none model. We introduce two strategies to address the issue of cross-model\nfeature corruption of existing visual prompting methods and enhance the\ntransferability of the learned prompts, including 1) Feature Consistency\nAlignment: which imposes constraints to the prompted feature changes to\nmaintain task-agnostic knowledge; 2) Task Semantics Enrichment: which\nencourages the prompted images to contain richer task-specific semantics with\nlanguage guidance. We validate the effectiveness of TVP through extensive\nexperiments with 6 modern MLLMs on a wide variety of tasks ranging from object\nrecognition and counting to multimodal reasoning and hallucination correction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in CVPR 2024 as Poster (Highlight)",
    "pdf_url": "http://arxiv.org/pdf/2404.11207v1",
    "published_date": "2024-04-17 09:39:07 UTC",
    "updated_date": "2024-04-17 09:39:07 UTC"
  },
  {
    "arxiv_id": "2404.11181v2",
    "title": "KI-GAN: Knowledge-Informed Generative Adversarial Networks for Enhanced Multi-Vehicle Trajectory Forecasting at Signalized Intersections",
    "authors": [
      "Chuheng Wei",
      "Guoyuan Wu",
      "Matthew J. Barth",
      "Amr Abdelraouf",
      "Rohit Gupta",
      "Kyungtae Han"
    ],
    "abstract": "Reliable prediction of vehicle trajectories at signalized intersections is\ncrucial to urban traffic management and autonomous driving systems. However, it\npresents unique challenges, due to the complex roadway layout at intersections,\ninvolvement of traffic signal controls, and interactions among different types\nof road users. To address these issues, we present in this paper a novel model\ncalled Knowledge-Informed Generative Adversarial Network (KI-GAN), which\nintegrates both traffic signal information and multi-vehicle interactions to\npredict vehicle trajectories accurately. Additionally, we propose a specialized\nattention pooling method that accounts for vehicle orientation and proximity at\nintersections. Based on the SinD dataset, our KI-GAN model is able to achieve\nan Average Displacement Error (ADE) of 0.05 and a Final Displacement Error\n(FDE) of 0.12 for a 6-second observation and 6-second prediction cycle. When\nthe prediction window is extended to 9 seconds, the ADE and FDE values are\nfurther reduced to 0.11 and 0.26, respectively. These results demonstrate the\neffectiveness of the proposed KI-GAN model in vehicle trajectory prediction\nunder complex scenarios at signalized intersections, which represents a\nsignificant advancement in the target field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "2024 CVPR AICity Workshop",
    "pdf_url": "http://arxiv.org/pdf/2404.11181v2",
    "published_date": "2024-04-17 08:53:59 UTC",
    "updated_date": "2024-04-19 14:28:00 UTC"
  },
  {
    "arxiv_id": "2404.11172v2",
    "title": "Deep Neural Networks via Complex Network Theory: a Perspective",
    "authors": [
      "Emanuele La Malfa",
      "Gabriele La Malfa",
      "Giuseppe Nicosia",
      "Vito Latora"
    ],
    "abstract": "Deep Neural Networks (DNNs) can be represented as graphs whose links and\nvertices iteratively process data and solve tasks sub-optimally. Complex\nNetwork Theory (CNT), merging statistical physics with graph theory, provides a\nmethod for interpreting neural networks by analysing their weights and neuron\nstructures. However, classic works adapt CNT metrics that only permit a\ntopological analysis as they do not account for the effect of the input data.\nIn addition, CNT metrics have been applied to a limited range of architectures,\nmainly including Fully Connected neural networks. In this work, we extend the\nexisting CNT metrics with measures that sample from the DNNs' training\ndistribution, shifting from a purely topological analysis to one that connects\nwith the interpretability of deep learning. For the novel metrics, in addition\nto the existing ones, we provide a mathematical formalisation for Fully\nConnected, AutoEncoder, Convolutional and Recurrent neural networks, of which\nwe vary the activation functions and the number of hidden layers. We show that\nthese metrics differentiate DNNs based on the architecture, the number of\nhidden layers, and the activation function. Our contribution provides a method\nrooted in physics for interpreting DNNs that offers insights beyond the\ntraditional input-output relationship and the CNT topological analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IJCAI'24 (full paper, main track)",
    "pdf_url": "http://arxiv.org/pdf/2404.11172v2",
    "published_date": "2024-04-17 08:42:42 UTC",
    "updated_date": "2024-04-18 11:17:43 UTC"
  },
  {
    "arxiv_id": "2404.11171v2",
    "title": "Personalized Heart Disease Detection via ECG Digital Twin Generation",
    "authors": [
      "Yaojun Hu",
      "Jintai Chen",
      "Lianting Hu",
      "Dantong Li",
      "Jiahuan Yan",
      "Haochao Ying",
      "Huiying Liang",
      "Jian Wu"
    ],
    "abstract": "Heart diseases rank among the leading causes of global mortality,\ndemonstrating a crucial need for early diagnosis and intervention. Most\ntraditional electrocardiogram (ECG) based automated diagnosis methods are\ntrained at population level, neglecting the customization of personalized ECGs\nto enhance individual healthcare management. A potential solution to address\nthis limitation is to employ digital twins to simulate symptoms of diseases in\nreal patients. In this paper, we present an innovative prospective learning\napproach for personalized heart disease detection, which generates digital\ntwins of healthy individuals' anomalous ECGs and enhances the model sensitivity\nto the personalized symptoms. In our approach, a vector quantized feature\nseparator is proposed to locate and isolate the disease symptom and normal\nsegments in ECG signals with ECG report guidance. Thus, the ECG digital twins\ncan simulate specific heart diseases used to train a personalized heart disease\ndetection model. Experiments demonstrate that our approach not only excels in\ngenerating high-fidelity ECG signals but also improves personalized heart\ndisease detection. Moreover, our approach ensures robust privacy protection,\nsafeguarding patient data in model development.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11171v2",
    "published_date": "2024-04-17 08:40:54 UTC",
    "updated_date": "2024-05-11 18:15:15 UTC"
  },
  {
    "arxiv_id": "2404.11160v2",
    "title": "Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation",
    "authors": [
      "Jessica López Espejel",
      "Mahaman Sanoussi Yahaya Alassan",
      "Merieme Bouhandi",
      "Walid Dahhane",
      "El Hassane Ettifouri"
    ],
    "abstract": "Large Language Models (LLMs) have become a popular choice for many Natural\nLanguage Processing (NLP) tasks due to their versatility and ability to produce\nhigh-quality results. Specifically, they are increasingly used for automatic\ncode generation to help developers tackle repetitive coding tasks. However,\nLLMs' substantial computational and memory requirements often make them\ninaccessible to users with limited resources. This paper focuses on very\nlow-cost models which offer a more accessible alternative to resource-intensive\nLLMs. We notably: (1) propose a thorough semi-manual evaluation of their\nperformance in generating Python code, (2) introduce a Chain-of-Thought (CoT)\nprompting strategy to improve model reasoning and code quality, and (3) propose\na new dataset of 60 programming problems, with varied difficulty levels,\ndesigned to extend existing benchmarks like HumanEval and EvalPlus. Our\nfindings show that some low-cost compatible models achieve competitive results\ncompared to larger models like ChatGPT despite using significantly fewer\nresources. We will make our dataset and prompts publicly available to support\nfurther research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review at Elsevier's Engineering Applications of Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2404.11160v2",
    "published_date": "2024-04-17 08:16:48 UTC",
    "updated_date": "2024-08-29 13:23:15 UTC"
  },
  {
    "arxiv_id": "2404.11148v1",
    "title": "Explainable Machine Learning System for Predicting Chronic Kidney Disease in High-Risk Cardiovascular Patients",
    "authors": [
      "Nantika Nguycharoen"
    ],
    "abstract": "As the global population ages, the incidence of Chronic Kidney Disease (CKD)\nis rising. CKD often remains asymptomatic until advanced stages, which\nsignificantly burdens both the healthcare system and patient quality of life.\nThis research developed an explainable machine learning system for predicting\nCKD in patients with cardiovascular risks, utilizing medical history and\nlaboratory data. The Random Forest model achieved the highest sensitivity of\n88.2%. The study introduces a comprehensive explainability framework that\nextends beyond traditional feature importance methods, incorporating global and\nlocal interpretations, bias inspection, biomedical relevance, and safety\nassessments. Key predictive features identified in global interpretation were\nthe use of diabetic and ACEI/ARB medications, and initial eGFR values. Local\ninterpretation provided model insights through counterfactual explanations,\nwhich aligned with other system parts. After conducting a bias inspection, it\nwas found that the initial eGFR values and CKD predictions exhibited some bias,\nbut no significant gender bias was identified. The model's logic, extracted by\nscoped rules, was confirmed to align with existing medical literature. The\nsafety assessment tested potentially dangerous cases and confirmed that the\nmodel behaved safely. This system enhances the explainability, reliability, and\naccountability of the model, promoting its potential integration into\nhealthcare settings and compliance with upcoming regulatory standards, and\nshowing promise for broader applications in healthcare machine learning.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "J.3; I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.11148v1",
    "published_date": "2024-04-17 07:59:33 UTC",
    "updated_date": "2024-04-17 07:59:33 UTC"
  },
  {
    "arxiv_id": "2404.11144v1",
    "title": "Self-adaptive PSRO: Towards an Automatic Population-based Game Solver",
    "authors": [
      "Pengdeng Li",
      "Shuxin Li",
      "Chang Yang",
      "Xinrun Wang",
      "Xiao Huang",
      "Hau Chan",
      "Bo An"
    ],
    "abstract": "Policy-Space Response Oracles (PSRO) as a general algorithmic framework has\nachieved state-of-the-art performance in learning equilibrium policies of\ntwo-player zero-sum games. However, the hand-crafted hyperparameter value\nselection in most of the existing works requires extensive domain knowledge,\nforming the main barrier to applying PSRO to different games. In this work, we\nmake the first attempt to investigate the possibility of self-adaptively\ndetermining the optimal hyperparameter values in the PSRO framework. Our\ncontributions are three-fold: (1) Using several hyperparameters, we propose a\nparametric PSRO that unifies the gradient descent ascent (GDA) and different\nPSRO variants. (2) We propose the self-adaptive PSRO (SPSRO) by casting the\nhyperparameter value selection of the parametric PSRO as a hyperparameter\noptimization (HPO) problem where our objective is to learn an HPO policy that\ncan self-adaptively determine the optimal hyperparameter values during the\nrunning of the parametric PSRO. (3) To overcome the poor performance of online\nHPO methods, we propose a novel offline HPO approach to optimize the HPO policy\nbased on the Transformer architecture. Experiments on various two-player\nzero-sum games demonstrate the superiority of SPSRO over different baselines.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.11144v1",
    "published_date": "2024-04-17 07:40:57 UTC",
    "updated_date": "2024-04-17 07:40:57 UTC"
  },
  {
    "arxiv_id": "2404.11124v2",
    "title": "What's under the hood: Investigating Automatic Metrics on Meeting Summarization",
    "authors": [
      "Frederic Kirstein",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ],
    "abstract": "Meeting summarization has become a critical task considering the increase in\nonline interactions. While new techniques are introduced regularly, their\nevaluation uses metrics not designed to capture meeting-specific errors,\nundermining effective evaluation. This paper investigates what the frequently\nused automatic metrics capture and which errors they mask by correlating\nautomatic metric scores with human evaluations across a broad error taxonomy.\nWe commence with a comprehensive literature review on English meeting\nsummarization to define key challenges like speaker dynamics and contextual\nturn-taking and error types such as missing information and linguistic\ninaccuracy, concepts previously loosely defined in the field. We examine the\nrelationship between characteristic challenges and errors by using annotated\ntranscripts and summaries from Transformer-based sequence-to-sequence and\nautoregressive models from the general summary QMSum dataset. Through\nexperimental validation, we find that different model architectures respond\nvariably to challenges in meeting transcripts, resulting in different\npronounced links between challenges and errors. Current default-used metrics\nstruggle to capture observable errors, showing weak to mid-correlations, while\na third of the correlations show trends of error masking. Only a subset reacts\naccurately to specific errors, while most correlations show either\nunresponsiveness or failure to reflect the error's impact on summary quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11124v2",
    "published_date": "2024-04-17 07:15:07 UTC",
    "updated_date": "2024-10-18 15:34:41 UTC"
  },
  {
    "arxiv_id": "2404.11122v1",
    "title": "Small Language Models are Good Too: An Empirical Study of Zero-Shot Classification",
    "authors": [
      "Pierre Lepagnol",
      "Thomas Gerald",
      "Sahar Ghannay",
      "Christophe Servan",
      "Sophie Rosset"
    ],
    "abstract": "This study is part of the debate on the efficiency of large versus small\nlanguage models for text classification by prompting.We assess the performance\nof small language models in zero-shot text classification, challenging the\nprevailing dominance of large models.Across 15 datasets, our investigation\nbenchmarks language models from 77M to 40B parameters using different\narchitectures and scoring functions. Our findings reveal that small models can\neffectively classify texts, getting on par with or surpassing their larger\ncounterparts.We developed and shared a comprehensive open-source repository\nthat encapsulates our methodologies. This research underscores the notion that\nbigger isn't always better, suggesting that resource-efficient small models may\noffer viable solutions for specific data classification challenges.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11122v1",
    "published_date": "2024-04-17 07:10:28 UTC",
    "updated_date": "2024-04-17 07:10:28 UTC"
  },
  {
    "arxiv_id": "2404.11121v2",
    "title": "TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment",
    "authors": [
      "Qinfeng Li",
      "Zhiqiang Shen",
      "Zhenghan Qin",
      "Yangfan Xie",
      "Xuhong Zhang",
      "Tianyu Du",
      "Jianwei Yin"
    ],
    "abstract": "Proprietary large language models (LLMs) have been widely applied in various\nscenarios. Additionally, deploying LLMs on edge devices is trending for\nefficiency and privacy reasons. However, edge deployment of proprietary LLMs\nintroduces new security challenges: edge-deployed models are exposed as\nwhite-box accessible to users, enabling adversaries to conduct effective model\nstealing (MS) attacks. Unfortunately, existing defense mechanisms fail to\nprovide effective protection. Specifically, we identify four critical\nprotection properties that existing methods fail to simultaneously satisfy: (1)\nmaintaining protection after a model is physically copied; (2) authorizing\nmodel access at request level; (3) safeguarding runtime reverse engineering;\n(4) achieving high security with negligible runtime overhead. To address the\nabove issues, we propose TransLinkGuard, a plug-and-play model protection\napproach against model stealing on edge devices. The core part of\nTransLinkGuard is a lightweight authorization module residing in a secure\nenvironment, e.g., TEE. The authorization module can freshly authorize each\nrequest based on its input. Extensive experiments show that TransLinkGuard\nachieves the same security protection as the black-box security guarantees with\nnegligible overhead.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ACM MM24 Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.11121v2",
    "published_date": "2024-04-17 07:08:45 UTC",
    "updated_date": "2024-11-21 02:16:53 UTC"
  },
  {
    "arxiv_id": "2404.11116v1",
    "title": "Music Enhancement with Deep Filters: A Technical Report for The ICASSP 2024 Cadenza Challenge",
    "authors": [
      "Keren Shao",
      "Ke Chen",
      "Shlomo Dubnov"
    ],
    "abstract": "In this challenge, we disentangle the deep filters from the original\nDeepfilterNet and incorporate them into our Spec-UNet-based network to further\nimprove a hybrid Demucs (hdemucs) based remixing pipeline. The motivation\nbehind the use of the deep filter component lies at its potential in better\nhandling temporal fine structures. We demonstrate an incremental improvement in\nboth the Signal-to-Distortion Ratio (SDR) and the Hearing Aid Audio Quality\nIndex (HAAQI) metrics when comparing the performance of hdemucs against\ndifferent versions of our model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "2 pages, 2 figures, 1 tables, Proceedings of the International\n  Conference on Acoustics, Speech, and Signal Processing, ICASSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.11116v1",
    "published_date": "2024-04-17 07:01:29 UTC",
    "updated_date": "2024-04-17 07:01:29 UTC"
  },
  {
    "arxiv_id": "2404.11095v2",
    "title": "Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues",
    "authors": [
      "Jiao Ou",
      "Jiayu Wu",
      "Che Liu",
      "Fuzheng Zhang",
      "Di Zhang",
      "Kun Gai"
    ],
    "abstract": "Aligning large language models (LLMs) with human expectations requires\nhigh-quality instructional dialogues, which usually require instructions that\nare diverse and in-depth. Existing methods leverage two LLMs to interact for\nautomatic collection: one simulating a user to pose instructions, and the other\nacting as a system agent to respond. However, these user simulators struggle to\nmodel the rules behind how dialogues can pose different instructions without\nexplicit guidance, resulting in general instructions. In this paper, we propose\nto explicitly capture the complex rules to help the user simulator pose diverse\nand in-depth instruction. Specifically, we first induce high-level instruction\nstrategies from various real instruction dialogues serving as rules. Afterward,\ndifferent possible strategies are applied to the newly given dialogue scenario\ndeductively to pose various instructions. Experimental results show that our\nmethod can generate diverse and in-depth instructions. The constructed\nmulti-turn instructional dialogues can outperform competitive baselines on the\ndownstream chat model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.11095v2",
    "published_date": "2024-04-17 06:26:32 UTC",
    "updated_date": "2024-09-29 12:38:13 UTC"
  },
  {
    "arxiv_id": "2404.11086v2",
    "title": "ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large Language Models",
    "authors": [
      "Trong-Hieu Nguyen",
      "Anh-Cuong Le",
      "Viet-Cuong Nguyen"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) necessitates the\ndevelopment of new benchmarks to accurately assess their capabilities. To\naddress this need for Vietnamese, this work aims to introduce ViLLM-Eval, the\ncomprehensive evaluation suite designed to measure the advanced knowledge and\nreasoning abilities of foundation models within a Vietnamese context.\nViLLM-Eval consists of multiple-choice questions and predict next word tasks\nspanning various difficulty levels and diverse disciplines, ranging from\nhumanities to science and engineering. A thorough evaluation of the most\nadvanced LLMs on ViLLM-Eval revealed that even the best performing models have\nsignificant room for improvement in understanding and responding to Vietnamese\nlanguage tasks. ViLLM-Eval is believed to be instrumental in identifying key\nstrengths and weaknesses of foundation models, ultimately promoting their\ndevelopment and enhancing their performance for Vietnamese users. This paper\nprovides a thorough overview of ViLLM-Eval as part of the Vietnamese Large\nLanguage Model shared task, held within the 10th International Workshop on\nVietnamese Language and Speech Processing (VLSP 2023).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2305.08322 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2404.11086v2",
    "published_date": "2024-04-17 05:57:17 UTC",
    "updated_date": "2024-04-18 07:41:23 UTC"
  },
  {
    "arxiv_id": "2404.13082v2",
    "title": "Efficient Contextual LLM Cascades through Budget-Constrained Policy Learning",
    "authors": [
      "Xuechen Zhang",
      "Zijian Huang",
      "Ege Onur Taga",
      "Carlee Joe-Wong",
      "Samet Oymak",
      "Jiasi Chen"
    ],
    "abstract": "Recent successes in natural language processing have led to the proliferation\nof large language models (LLMs) by multiple providers. Each LLM offering has\ndifferent inference accuracy, monetary cost, and latency, and their accuracy\nfurther depends on the exact wording of the question (i.e., the specific\nprompt). At the same time, users often have a limit on monetary budget and\nlatency to answer all their questions, and they do not know which LLMs to\nchoose for each question to meet their accuracy and long term budget\nrequirements. To navigate this rich design space, we propose TREACLE\n($\\underline{T}$hrifty $\\underline{Rea}$soning via $\\underline{C}$ontext-Aware\n$\\underline{L}$LM and Prompt S$\\underline{e}$lection), a reinforcement learning\npolicy that jointly selects the model and prompting scheme while respecting the\nuser's monetary cost and latency constraints. TREACLE uses the problem context,\nincluding question text embeddings (reflecting the type or difficulty of a\nquery) and the response history (reflecting the consistency of previous\nresponses) to make smart decisions. Our evaluations on standard reasoning\ndatasets (GSM8K, CSQA, and LLC) with various LLMs and prompts show that TREACLE\nenables cost savings of up to 85% compared to baselines, while maintaining high\naccuracy. Importantly, it provides the user with the ability to gracefully\ntrade off accuracy for cost.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.13082v2",
    "published_date": "2024-04-17 05:56:49 UTC",
    "updated_date": "2024-11-19 22:02:49 UTC"
  },
  {
    "arxiv_id": "2404.11075v1",
    "title": "EEG_GLT-Net: Optimising EEG Graphs for Real-time Motor Imagery Signals Classification",
    "authors": [
      "Htoo Wai Aung",
      "Jiao Jiao Li",
      "Yang An",
      "Steven W. Su"
    ],
    "abstract": "Brain-Computer Interfaces connect the brain to external control devices,\nnecessitating the accurate translation of brain signals such as from\nelectroencephalography (EEG) into executable commands. Graph Neural Networks\n(GCN) have been increasingly applied for classifying EEG Motor Imagery signals,\nprimarily because they incorporates the spatial relationships among EEG\nchannels, resulting in improved accuracy over traditional convolutional\nmethods. Recent advances by GCNs-Net in real-time EEG MI signal classification\nutilised Pearson Coefficient Correlation (PCC) for constructing adjacency\nmatrices, yielding significant results on the PhysioNet dataset. Our paper\nintroduces the EEG Graph Lottery Ticket (EEG_GLT) algorithm, an innovative\ntechnique for constructing adjacency matrices for EEG channels. It does not\nrequire pre-existing knowledge of inter-channel relationships, and it can be\ntailored to suit both individual subjects and GCN model architectures. Our\nfindings demonstrated that the PCC method outperformed the Geodesic approach by\n9.65% in mean accuracy, while our EEG_GLT matrix consistently exceeded the\nperformance of the PCC method by a mean accuracy of 13.39%. Also, we found that\nthe construction of the adjacency matrix significantly influenced accuracy, to\na greater extent than GCN model configurations. A basic GCN configuration\nutilising our EEG_GLT matrix exceeded the performance of even the most complex\nGCN setup with a PCC matrix in average accuracy. Our EEG_GLT method also\nreduced MACs by up to 97% compared to the PCC method, while maintaining or\nenhancing accuracy. In conclusion, the EEG_GLT algorithm marks a breakthrough\nin the development of optimal adjacency matrices, effectively boosting both\ncomputational accuracy and efficiency, making it well-suited for real-time\nclassification of EEG MI signals that demand intensive computational resources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11075v1",
    "published_date": "2024-04-17 05:16:12 UTC",
    "updated_date": "2024-04-17 05:16:12 UTC"
  },
  {
    "arxiv_id": "2404.11072v1",
    "title": "Large Language Models Meet User Interfaces: The Case of Provisioning Feedback",
    "authors": [
      "Stanislav Pozdniakov",
      "Jonathan Brazil",
      "Solmaz Abdi",
      "Aneesha Bakharia",
      "Shazia Sadiq",
      "Dragan Gasevic",
      "Paul Denny",
      "Hassan Khosravi"
    ],
    "abstract": "Incorporating Generative AI (GenAI) and Large Language Models (LLMs) in\neducation can enhance teaching efficiency and enrich student learning. Current\nLLM usage involves conversational user interfaces (CUIs) for tasks like\ngenerating materials or providing feedback. However, this presents challenges\nincluding the need for educator expertise in AI and CUIs, ethical concerns with\nhigh-stakes decisions, and privacy risks. CUIs also struggle with complex\ntasks. To address these, we propose transitioning from CUIs to user-friendly\napplications leveraging LLMs via API calls. We present a framework for\nethically incorporating GenAI into educational tools and demonstrate its\napplication in our tool, Feedback Copilot, which provides personalized feedback\non student assignments. Our evaluation shows the effectiveness of this\napproach, with implications for GenAI researchers, educators, and\ntechnologists. This work charts a course for the future of GenAI in education.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "submission to C&E AI",
    "pdf_url": "http://arxiv.org/pdf/2404.11072v1",
    "published_date": "2024-04-17 05:05:05 UTC",
    "updated_date": "2024-04-17 05:05:05 UTC"
  },
  {
    "arxiv_id": "2404.11068v1",
    "title": "ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours",
    "authors": [
      "Feiwen Zhu",
      "Arkadiusz Nowaczynski",
      "Rundong Li",
      "Jie Xin",
      "Yifei Song",
      "Michal Marcinkiewicz",
      "Sukru Burc Eryilmaz",
      "Jun Yang",
      "Michael Andersch"
    ],
    "abstract": "AlphaFold2 has been hailed as a breakthrough in protein folding. It can\nrapidly predict protein structures with lab-grade accuracy. However, its\nimplementation does not include the necessary training code. OpenFold is the\nfirst trainable public reimplementation of AlphaFold. AlphaFold training\nprocedure is prohibitively time-consuming, and gets diminishing benefits from\nscaling to more compute resources. In this work, we conducted a comprehensive\nanalysis on the AlphaFold training procedure based on Openfold, identified that\ninefficient communications and overhead-dominated computations were the key\nfactors that prevented the AlphaFold training from effective scaling. We\nintroduced ScaleFold, a systematic training method that incorporated\noptimizations specifically for these factors. ScaleFold successfully scaled the\nAlphaFold training to 2080 NVIDIA H100 GPUs with high resource utilization. In\nthe MLPerf HPC v3.0 benchmark, ScaleFold finished the OpenFold benchmark in\n7.51 minutes, shown over $6\\times$ speedup than the baseline. For training the\nAlphaFold model from scratch, ScaleFold completed the pretraining in 10 hours,\na significant improvement over the seven days required by the original\nAlphaFold pretraining baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11068v1",
    "published_date": "2024-04-17 04:55:33 UTC",
    "updated_date": "2024-04-17 04:55:33 UTC"
  },
  {
    "arxiv_id": "2404.11064v3",
    "title": "Rethinking 3D Dense Caption and Visual Grounding in A Unified Framework through Prompt-based Localization",
    "authors": [
      "Yongdong Luo",
      "Haojia Lin",
      "Xiawu Zheng",
      "Yigeng Jiang",
      "Fei Chao",
      "Jie Hu",
      "Guannan Jiang",
      "Songan Zhang",
      "Rongrong Ji"
    ],
    "abstract": "3D Visual Grounding (3DVG) and 3D Dense Captioning (3DDC) are two crucial\ntasks in various 3D applications, which require both shared and complementary\ninformation in localization and visual-language relationships. Therefore,\nexisting approaches adopt the two-stage \"detect-then-describe/discriminate\"\npipeline, which relies heavily on the performance of the detector, resulting in\nsuboptimal performance. Inspired by DETR, we propose a unified framework,\n3DGCTR, to jointly solve these two distinct but closely related tasks in an\nend-to-end fashion. The key idea is to reconsider the prompt-based localization\nability of the 3DVG model. In this way, the 3DVG model with a well-designed\nprompt as input can assist the 3DDC task by extracting localization information\nfrom the prompt. In terms of implementation, we integrate a Lightweight Caption\nHead into the existing 3DVG network with a Caption Text Prompt as a connection,\neffectively harnessing the existing 3DVG model's inherent localization\ncapacity, thereby boosting 3DDC capability. This integration facilitates\nsimultaneous multi-task training on both tasks, mutually enhancing their\nperformance. Extensive experimental results demonstrate the effectiveness of\nthis approach. Specifically, on the ScanRefer dataset, 3DGCTR surpasses the\nstate-of-the-art 3DDC method by 4.3% in CIDEr@0.5IoU in MLE training and\nimproves upon the SOTA 3DVG method by 3.16% in Acc@0.25IoU. The codes are at\nhttps://github.com/Leon1207/3DGCTR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11064v3",
    "published_date": "2024-04-17 04:46:27 UTC",
    "updated_date": "2024-12-18 04:23:29 UTC"
  },
  {
    "arxiv_id": "2404.11056v1",
    "title": "LMEraser: Large Model Unlearning through Adaptive Prompt Tuning",
    "authors": [
      "Jie Xu",
      "Zihan Wu",
      "Cong Wang",
      "Xiaohua Jia"
    ],
    "abstract": "To address the growing demand for privacy protection in machine learning, we\npropose a novel and efficient machine unlearning approach for \\textbf{L}arge\n\\textbf{M}odels, called \\textbf{LM}Eraser. Existing unlearning research suffers\nfrom entangled training data and complex model architectures, incurring\nextremely high computational costs for large models. LMEraser takes a\ndivide-and-conquer strategy with a prompt tuning architecture to isolate data\ninfluence. The training dataset is partitioned into public and private\ndatasets. Public data are used to train the backbone of the model. Private data\nare adaptively clustered based on their diversity, and each cluster is used to\noptimize a prompt separately. This adaptive prompt tuning mechanism reduces\nunlearning costs and maintains model performance. Experiments demonstrate that\nLMEraser achieves a $100$-fold reduction in unlearning costs without\ncompromising accuracy compared to prior work. Our code is available at:\n\\url{https://github.com/lmeraser/lmeraser}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11056v1",
    "published_date": "2024-04-17 04:08:38 UTC",
    "updated_date": "2024-04-17 04:08:38 UTC"
  },
  {
    "arxiv_id": "2404.11049v3",
    "title": "Stepwise Alignment for Constrained Language Model Policy Optimization",
    "authors": [
      "Akifumi Wachi",
      "Thien Q. Tran",
      "Rei Sato",
      "Takumi Tanabe",
      "Youhei Akimoto"
    ],
    "abstract": "Safety and trustworthiness are indispensable requirements for real-world\napplications of AI systems using large language models (LLMs). This paper\nformulates human value alignment as an optimization problem of the language\nmodel policy to maximize reward under a safety constraint, and then proposes an\nalgorithm, Stepwise Alignment for Constrained Policy Optimization (SACPO). One\nkey idea behind SACPO, supported by theory, is that the optimal policy\nincorporating reward and safety can be directly obtained from a reward-aligned\npolicy. Building on this key idea, SACPO aligns LLMs step-wise with each metric\nwhile leveraging simple yet powerful alignment algorithms such as direct\npreference optimization (DPO). SACPO offers several advantages, including\nsimplicity, stability, computational efficiency, and flexibility of algorithms\nand datasets. Under mild assumptions, our theoretical analysis provides the\nupper bounds on optimality and safety constraint violation. Our experimental\nresults show that SACPO can fine-tune Alpaca-7B better than the\nstate-of-the-art method in terms of both helpfulness and harmlessness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024. Code and models are available at\n  https://github.com/line/sacpo",
    "pdf_url": "http://arxiv.org/pdf/2404.11049v3",
    "published_date": "2024-04-17 03:44:58 UTC",
    "updated_date": "2024-10-21 00:42:51 UTC"
  },
  {
    "arxiv_id": "2404.11046v1",
    "title": "Lightweight Unsupervised Federated Learning with Pretrained Vision Language Model",
    "authors": [
      "Hao Yan",
      "Yuhong Guo"
    ],
    "abstract": "Federated learning aims to tackle the ``isolated data island\" problem, where\nit trains a collective model from physically isolated clients while\nsafeguarding the privacy of users' data. However, supervised federated learning\nnecessitates that each client labels their data for training, which can be both\ntime-consuming and resource-intensive, and may even be impractical for edge\ndevices. Moreover, the training and transmission of deep models present\nchallenges to the computation and communication capabilities of the clients. To\naddress these two inherent challenges in supervised federated learning, we\npropose a novel lightweight unsupervised federated learning approach that\nleverages unlabeled data on each client to perform lightweight model training\nand communication by harnessing pretrained vision-language models, such as\nCLIP. By capitalizing on the zero-shot prediction capability and the\nwell-trained image encoder of the pre-trained CLIP model, we have carefully\ncrafted an efficient and resilient self-training approach. This method refines\nthe initial zero-shot predicted pseudo-labels of unlabeled instances through\nthe sole training of a linear classifier on top of the fixed image encoder.\nAdditionally, to address data heterogeneity within each client, we propose a\nclass-balanced text feature sampling strategy for generating synthetic\ninstances in the feature space to support local training. Experiments are\nconducted on multiple benchmark datasets. The experimental results demonstrate\nthat our proposed method greatly enhances model performance in comparison to\nCLIP's zero-shot predictions and even outperforms supervised federated learning\nbenchmark methods given limited computational and communication overhead.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11046v1",
    "published_date": "2024-04-17 03:42:48 UTC",
    "updated_date": "2024-04-17 03:42:48 UTC"
  },
  {
    "arxiv_id": "2404.11041v2",
    "title": "On the Empirical Complexity of Reasoning and Planning in LLMs",
    "authors": [
      "Liwei Kang",
      "Zirui Zhao",
      "David Hsu",
      "Wee Sun Lee"
    ],
    "abstract": "Chain-of-thought (CoT), tree-of-thought (ToT), and related techniques work\nsurprisingly well in practice for some complex reasoning tasks with Large\nLanguage Models (LLMs), but why? This work seeks the underlying reasons by\nconducting experimental case studies and linking the performance benefits to\nwell-established sample and computational complexity principles in machine\nlearning. We experimented with 6 reasoning tasks, ranging from grade school\nmath, air travel planning, ..., to Blocksworld. The results suggest that (i)\nboth CoT and ToT benefit significantly from task decomposition, which breaks a\ncomplex reasoning task into a sequence of steps with low sample complexity and\nexplicitly outlines the reasoning structure, and (ii) for computationally hard\nreasoning tasks, the more sophisticated tree structure of ToT outperforms the\nlinear structure of CoT. These findings provide useful guidelines for the use\nof LLM in solving reasoning tasks in practice.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11041v2",
    "published_date": "2024-04-17 03:34:27 UTC",
    "updated_date": "2024-06-18 02:03:35 UTC"
  },
  {
    "arxiv_id": "2404.11027v1",
    "title": "Empowering Large Language Models on Robotic Manipulation with Affordance Prompting",
    "authors": [
      "Guangran Cheng",
      "Chuheng Zhang",
      "Wenzhe Cai",
      "Li Zhao",
      "Changyin Sun",
      "Jiang Bian"
    ],
    "abstract": "While large language models (LLMs) are successful in completing various\nlanguage processing tasks, they easily fail to interact with the physical world\nby generating control sequences properly. We find that the main reason is that\nLLMs are not grounded in the physical world. Existing LLM-based approaches\ncircumvent this problem by relying on additional pre-defined skills or\npre-trained sub-policies, making it hard to adapt to new tasks. In contrast, we\naim to address this problem and explore the possibility to prompt pre-trained\nLLMs to accomplish a series of robotic manipulation tasks in a training-free\nparadigm. Accordingly, we propose a framework called LLM+A(ffordance) where the\nLLM serves as both the sub-task planner (that generates high-level plans) and\nthe motion controller (that generates low-level control sequences). To ground\nthese plans and control sequences on the physical world, we develop the\naffordance prompting technique that stimulates the LLM to 1) predict the\nconsequences of generated plans and 2) generate affordance values for relevant\nobjects. Empirically, we evaluate the effectiveness of LLM+A in various\nlanguage-conditioned robotic manipulation tasks, which show that our approach\nsubstantially improves performance by enhancing the feasibility of generated\nplans and control and can easily generalize to different environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11027v1",
    "published_date": "2024-04-17 03:06:32 UTC",
    "updated_date": "2024-04-17 03:06:32 UTC"
  },
  {
    "arxiv_id": "2404.11018v3",
    "title": "Many-Shot In-Context Learning",
    "authors": [
      "Rishabh Agarwal",
      "Avi Singh",
      "Lei M. Zhang",
      "Bernd Bohnet",
      "Luis Rosias",
      "Stephanie Chan",
      "Biao Zhang",
      "Ankesh Anand",
      "Zaheer Abbas",
      "Azade Nova",
      "John D. Co-Reyes",
      "Eric Chu",
      "Feryal Behbahani",
      "Aleksandra Faust",
      "Hugo Larochelle"
    ],
    "abstract": "Large language models (LLMs) excel at few-shot in-context learning (ICL) --\nlearning from a few examples provided in context at inference, without any\nweight updates. Newly expanded context windows allow us to investigate ICL with\nhundreds or thousands of examples -- the many-shot regime. Going from few-shot\nto many-shot, we observe significant performance gains across a wide variety of\ngenerative and discriminative tasks. While promising, many-shot ICL can be\nbottlenecked by the available amount of human-generated examples. To mitigate\nthis limitation, we explore two new settings: Reinforced and Unsupervised ICL.\nReinforced ICL uses model-generated chain-of-thought rationales in place of\nhuman examples. Unsupervised ICL removes rationales from the prompt altogether,\nand prompts the model only with domain-specific questions. We find that both\nReinforced and Unsupervised ICL can be quite effective in the many-shot regime,\nparticularly on complex reasoning tasks. Finally, we demonstrate that, unlike\nfew-shot learning, many-shot learning is effective at overriding pretraining\nbiases, can learn high-dimensional functions with numerical inputs, and\nperforms comparably to fine-tuning. We also find that inference cost increases\nlinearly in the many-shot regime, and frontier LLMs benefit from many-shot ICL\nto varying degrees. Our analysis also reveals the limitations of next-token\nprediction loss as an indicator of downstream ICL performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2404.11018v3",
    "published_date": "2024-04-17 02:49:26 UTC",
    "updated_date": "2024-10-17 17:45:09 UTC"
  },
  {
    "arxiv_id": "2404.11016v2",
    "title": "MaeFuse: Transferring Omni Features with Pretrained Masked Autoencoders for Infrared and Visible Image Fusion via Guided Training",
    "authors": [
      "Jiayang Li",
      "Junjun Jiang",
      "Pengwei Liang",
      "Jiayi Ma",
      "Liqiang Nie"
    ],
    "abstract": "In this paper, we introduce MaeFuse, a novel autoencoder model designed for\nInfrared and Visible Image Fusion (IVIF). The existing approaches for image\nfusion often rely on training combined with downstream tasks to obtain\nhighlevel visual information, which is effective in emphasizing target objects\nand delivering impressive results in visual quality and task-specific\napplications. Instead of being driven by downstream tasks, our model called\nMaeFuse utilizes a pretrained encoder from Masked Autoencoders (MAE), which\nfacilities the omni features extraction for low-level reconstruction and\nhigh-level vision tasks, to obtain perception friendly features with a low\ncost. In order to eliminate the domain gap of different modal features and the\nblock effect caused by the MAE encoder, we further develop a guided training\nstrategy. This strategy is meticulously crafted to ensure that the fusion layer\nseamlessly adjusts to the feature space of the encoder, gradually enhancing the\nfusion performance. The proposed method can facilitate the comprehensive\nintegration of feature vectors from both infrared and visible modalities, thus\npreserving the rich details inherent in each modal. MaeFuse not only introduces\na novel perspective in the realm of fusion techniques but also stands out with\nimpressive performance across various public datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11016v2",
    "published_date": "2024-04-17 02:47:39 UTC",
    "updated_date": "2025-02-09 09:23:34 UTC"
  },
  {
    "arxiv_id": "2404.11015v2",
    "title": "FedFa: A Fully Asynchronous Training Paradigm for Federated Learning",
    "authors": [
      "Haotian Xu",
      "Zhaorui Zhang",
      "Sheng Di",
      "Benben Liu",
      "Khalid Ayed Alharthi",
      "Jiannong Cao"
    ],
    "abstract": "Federated learning has been identified as an efficient decentralized training\nparadigm for scaling the machine learning model training on a large number of\ndevices while guaranteeing the data privacy of the trainers. FedAvg has become\na foundational parameter update strategy for federated learning, which has been\npromising to eliminate the effect of the heterogeneous data across clients and\nguarantee convergence. However, the synchronization parameter update barriers\nfor each communication round during the training significant time on waiting,\nslowing down the training procedure. Therefore, recent state-of-the-art\nsolutions propose using semi-asynchronous approaches to mitigate the waiting\ntime cost with guaranteed convergence. Nevertheless, emerging semi-asynchronous\napproaches are unable to eliminate the waiting time completely.\n  We propose a full asynchronous training paradigm, called FedFa, which can\nguarantee model convergence and eliminate the waiting time completely for\nfederated learning by using a few buffered results on the server for parameter\nupdating. Further, we provide theoretical proof of the convergence rate for our\nproposed FedFa. Extensive experimental results indicate our approach\neffectively improves the training performance of federated learning by up to 6x\nand 4x speedup compared to the state-of-the-art synchronous and\nsemi-asynchronous strategies while retaining high accuracy in both IID and\nNon-IID scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11015v2",
    "published_date": "2024-04-17 02:46:59 UTC",
    "updated_date": "2024-04-20 14:26:07 UTC"
  },
  {
    "arxiv_id": "2404.11014v2",
    "title": "Towards Multi-agent Reinforcement Learning based Traffic Signal Control through Spatio-temporal Hypergraphs",
    "authors": [
      "Kang Wang",
      "Zhishu Shen",
      "Zhen Lei",
      "Tiehua Zhang"
    ],
    "abstract": "Traffic signal control systems (TSCSs) are integral to intelligent traffic\nmanagement, fostering efficient vehicle flow. Traditional approaches often\nsimplify road networks into standard graphs, which results in a failure to\nconsider the dynamic nature of traffic data at neighboring intersections,\nthereby neglecting higher-order interconnections necessary for real-time\ncontrol. To address this, we propose a novel TSCS framework to realize\nintelligent traffic control. This framework collaborates with multiple\nneighboring edge computing servers to collect traffic information across the\nroad network. To elevate the efficiency of traffic signal control, we have\ncrafted a multi-agent soft actor-critic (MA-SAC) reinforcement learning\nalgorithm. Within this algorithm, individual agents are deployed at each\nintersection with a mandate to optimize traffic flow across the road network\ncollectively. Furthermore, we introduce hypergraph learning into the critic\nnetwork of MA-SAC to enable the spatio-temporal interactions from multiple\nintersections in the road network. This method fuses hypergraph and\nspatio-temporal graph structures to encode traffic data and capture the complex\nspatio-temporal correlations between multiple intersections. Our empirical\nevaluation, tested on varied datasets, demonstrates the superiority of our\nframework in minimizing average vehicle travel times and sustaining\nhigh-throughput performance. This work facilitates the development of more\nintelligent urban traffic management solutions. We release the code to support\nthe reproducibility of this work at https://github.com/Edun-Eyes/TSC",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted by IEEE Transactions on Mobile Computing",
    "pdf_url": "http://arxiv.org/pdf/2404.11014v2",
    "published_date": "2024-04-17 02:46:18 UTC",
    "updated_date": "2025-04-03 13:50:50 UTC"
  },
  {
    "arxiv_id": "2404.11008v1",
    "title": "AKGNet: Attribute Knowledge-Guided Unsupervised Lung-Infected Area Segmentation",
    "authors": [
      "Qing En",
      "Yuhong Guo"
    ],
    "abstract": "Lung-infected area segmentation is crucial for assessing the severity of lung\ndiseases. However, existing image-text multi-modal methods typically rely on\nlabour-intensive annotations for model training, posing challenges regarding\ntime and expertise. To address this issue, we propose a novel attribute\nknowledge-guided framework for unsupervised lung-infected area segmentation\n(AKGNet), which achieves segmentation solely based on image-text data without\nany mask annotation. AKGNet facilitates text attribute knowledge learning,\nattribute-image cross-attention fusion, and high-confidence-based pseudo-label\nexploration simultaneously. It can learn statistical information and capture\nspatial correlations between image and text attributes in the embedding space,\niteratively refining the mask to enhance segmentation. Specifically, we\nintroduce a text attribute knowledge learning module by extracting attribute\nknowledge and incorporating it into feature representations, enabling the model\nto learn statistical information and adapt to different attributes. Moreover,\nwe devise an attribute-image cross-attention module by calculating the\ncorrelation between attributes and images in the embedding space to capture\nspatial dependency information, thus selectively focusing on relevant regions\nwhile filtering irrelevant areas. Finally, a self-training mask improvement\nprocess is employed by generating pseudo-labels using high-confidence\npredictions to iteratively enhance the mask and segmentation. Experimental\nresults on a benchmark medical image dataset demonstrate the superior\nperformance of our method compared to state-of-the-art segmentation techniques\nin unsupervised scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.11008v1",
    "published_date": "2024-04-17 02:36:02 UTC",
    "updated_date": "2024-04-17 02:36:02 UTC"
  },
  {
    "arxiv_id": "2404.10991v1",
    "title": "Function Approximation for Reinforcement Learning Controller for Energy from Spread Waves",
    "authors": [
      "Soumyendu Sarkar",
      "Vineet Gundecha",
      "Sahand Ghorbanpour",
      "Alexander Shmakov",
      "Ashwin Ramesh Babu",
      "Avisek Naug",
      "Alexandre Pichard",
      "Mathieu Cocho"
    ],
    "abstract": "The industrial multi-generator Wave Energy Converters (WEC) must handle\nmultiple simultaneous waves coming from different directions called spread\nwaves. These complex devices in challenging circumstances need controllers with\nmultiple objectives of energy capture efficiency, reduction of structural\nstress to limit maintenance, and proactive protection against high waves. The\nMulti-Agent Reinforcement Learning (MARL) controller trained with the Proximal\nPolicy Optimization (PPO) algorithm can handle these complexities. In this\npaper, we explore different function approximations for the policy and critic\nnetworks in modeling the sequential nature of the system dynamics and find that\nthey are key to better performance. We investigated the performance of a fully\nconnected neural network (FCN), LSTM, and Transformer model variants with\nvarying depths and gated residual connections. Our results show that the\ntransformer model of moderate depth with gated residual connections around the\nmulti-head attention, multi-layer perceptron, and the transformer block (STrXL)\nproposed in this paper is optimal and boosts energy efficiency by an average of\n22.1% for these complex spread waves over the existing spring damper (SD)\ncontroller. Furthermore, unlike the default SD controller, the transformer\ncontroller almost eliminated the mechanical stress from the rotational yaw\nmotion for angled waves. Demo: https://tinyurl.com/yueda3jh",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2023, Proceedings of the Thirty-Second International Joint\n  Conference on Artificial IntelligenceAugust 2023",
    "pdf_url": "http://arxiv.org/pdf/2404.10991v1",
    "published_date": "2024-04-17 02:04:10 UTC",
    "updated_date": "2024-04-17 02:04:10 UTC"
  },
  {
    "arxiv_id": "2404.10981v2",
    "title": "A Survey on Retrieval-Augmented Text Generation for Large Language Models",
    "authors": [
      "Yizheng Huang",
      "Jimmy Huang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) merges retrieval methods with deep\nlearning advancements to address the static limitations of large language\nmodels (LLMs) by enabling the dynamic integration of up-to-date external\ninformation. This methodology, focusing primarily on the text domain, provides\na cost-effective solution to the generation of plausible but possibly incorrect\nresponses by LLMs, thereby enhancing the accuracy and reliability of their\noutputs through the use of real-world data. As RAG grows in complexity and\nincorporates multiple concepts that can influence its performance, this paper\norganizes the RAG paradigm into four categories: pre-retrieval, retrieval,\npost-retrieval, and generation, offering a detailed perspective from the\nretrieval viewpoint. It outlines RAG's evolution and discusses the field's\nprogression through the analysis of significant studies. Additionally, the\npaper introduces evaluation methods for RAG, addressing the challenges faced\nand proposing future research directions. By offering an organized framework\nand categorization, the study aims to consolidate existing research on RAG,\nclarify its technological underpinnings, and highlight its potential to broaden\nthe adaptability and applications of LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Ongoing Work",
    "pdf_url": "http://arxiv.org/pdf/2404.10981v2",
    "published_date": "2024-04-17 01:27:42 UTC",
    "updated_date": "2024-08-23 00:17:02 UTC"
  },
  {
    "arxiv_id": "2404.10978v1",
    "title": "Leveraging 3D LiDAR Sensors to Enable Enhanced Urban Safety and Public Health: Pedestrian Monitoring and Abnormal Activity Detection",
    "authors": [
      "Nawfal Guefrachi",
      "Jian Shi",
      "Hakim Ghazzai",
      "Ahmad Alsharoa"
    ],
    "abstract": "The integration of Light Detection and Ranging (LiDAR) and Internet of Things\n(IoT) technologies offers transformative opportunities for public health\ninformatics in urban safety and pedestrian well-being. This paper proposes a\nnovel framework utilizing these technologies for enhanced 3D object detection\nand activity classification in urban traffic scenarios. By employing elevated\nLiDAR, we obtain detailed 3D point cloud data, enabling precise pedestrian\nactivity monitoring. To overcome urban data scarcity, we create a specialized\ndataset through simulated traffic environments in Blender, facilitating\ntargeted model training. Our approach employs a modified Point\nVoxel-Region-based Convolutional Neural Network (PV-RCNN) for robust 3D\ndetection and PointNet for classifying pedestrian activities, significantly\nbenefiting urban traffic management and public health by offering insights into\npedestrian behavior and promoting safer urban environments. Our dual-model\napproach not only enhances urban traffic management but also contributes\nsignificantly to public health by providing insights into pedestrian behavior\nand promoting safer urban environment.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.10978v1",
    "published_date": "2024-04-17 01:23:49 UTC",
    "updated_date": "2024-04-17 01:23:49 UTC"
  },
  {
    "arxiv_id": "2404.10976v3",
    "title": "Group-Aware Coordination Graph for Multi-Agent Reinforcement Learning",
    "authors": [
      "Wei Duan",
      "Jie Lu",
      "Junyu Xuan"
    ],
    "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) necessitates seamless\ncollaboration among agents, often represented by an underlying relation graph.\nExisting methods for learning this graph primarily focus on agent-pair\nrelations, neglecting higher-order relationships. While several approaches\nattempt to extend cooperation modelling to encompass behaviour similarities\nwithin groups, they commonly fall short in concurrently learning the latent\ngraph, thereby constraining the information exchange among partially observed\nagents. To overcome these limitations, we present a novel approach to infer the\nGroup-Aware Coordination Graph (GACG), which is designed to capture both the\ncooperation between agent pairs based on current observations and group-level\ndependencies from behaviour patterns observed across trajectories. This graph\nis further used in graph convolution for information exchange between agents\nduring decision-making. To further ensure behavioural consistency among agents\nwithin the same group, we introduce a group distance loss, which promotes group\ncohesion and encourages specialization between groups. Our evaluations,\nconducted on StarCraft II micromanagement tasks, demonstrate GACG's superior\nperformance. An ablation study further provides experimental evidence of the\neffectiveness of each component of our method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.10976v3",
    "published_date": "2024-04-17 01:17:10 UTC",
    "updated_date": "2024-05-11 23:50:21 UTC"
  },
  {
    "arxiv_id": "2404.13081v1",
    "title": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs",
    "authors": [
      "Jaehyung Kim",
      "Jaehyun Nam",
      "Sangwoo Mo",
      "Jongjin Park",
      "Sang-Woo Lee",
      "Minjoon Seo",
      "Jung-Woo Ha",
      "Jinwoo Shin"
    ],
    "abstract": "Large language models (LLMs) have made significant advancements in various\nnatural language processing tasks, including question answering (QA) tasks.\nWhile incorporating new information with the retrieval of relevant passages is\na promising way to improve QA with LLMs, the existing methods often require\nadditional fine-tuning which becomes infeasible with recent LLMs. Augmenting\nretrieved passages via prompting has the potential to address this limitation,\nbut this direction has been limitedly explored. To this end, we design a simple\nyet effective framework to enhance open-domain QA (ODQA) with LLMs, based on\nthe summarized retrieval (SuRe). SuRe helps LLMs predict more accurate answers\nfor a given question, which are well-supported by the summarized retrieval that\ncould be viewed as an explicit rationale extracted from the retrieved passages.\nSpecifically, SuRe first constructs summaries of the retrieved passages for\neach of the multiple answer candidates. Then, SuRe confirms the most plausible\nanswer from the candidate set by evaluating the validity and ranking of the\ngenerated summaries. Experimental results on diverse ODQA benchmarks\ndemonstrate the superiority of SuRe, with improvements of up to 4.6% in exact\nmatch (EM) and 4.0% in F1 score over standard prompting approaches. SuRe also\ncan be integrated with a broad range of retrieval methods and LLMs. Finally,\nthe generated summaries from SuRe show additional advantages to measure the\nimportance of retrieved passages and serve as more preferred rationales by\nmodels and humans.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.13081v1",
    "published_date": "2024-04-17 01:15:54 UTC",
    "updated_date": "2024-04-17 01:15:54 UTC"
  }
]