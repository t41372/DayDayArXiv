{
  "date": "2024-09-04",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-04 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、多模态处理、机器人导航和医疗应用等领域，强调大型语言模型（LLM）在强化学习和任务适应中的创新潜力，令人印象深刻的是如 Prompt Baking 的 LLM 自提升技术和 RoboTwin 的生成式数字孪生框架，而知名学者如 Paul Christiano 等参与的论文则突出 AI 安全与学习理论。\n\n### 重点论文讨论\n以下挑选并分组讨论最具影响力和话题度的论文，先从 LLM 和 AI 优化入手，再聊机器人与视觉导航，最后快速掠过其他领域。每个条目列出论文标题（中文 + 英文），并简要描述核心贡献和发现。\n\n#### LLM 和 AI 模型优化（高话题度领域）\n- **Prompt Baking（Prompt Baking）**  \n  这篇论文探索将提示信息“烘焙”进 LLM 权重，实现高效行为调整。主要贡献是通过最小化 KL 散度优化模型，实验显示在 GSM8K 等基准上提升性能，同时支持迭代自提升，潜在应用包括 AI 安全和代理训练。\n\n- **Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning（大型语言模型作为高效奖励函数搜索器，用于自定义环境的多目标强化学习）**  \n  作者提出 ERFSL 框架，使用 LLM 搜索奖励函数权重，提升强化学习效率。发现 LLM 可在零样本场景下快速适应，实验在水下数据收集任务中证明其有效性，显著减少迭代次数。\n\n- **RouterRetriever: Routing over a Mixture of Expert Embedding Models（RouterRetriever: 在专家嵌入模型混合体上进行路由）**  \n  这篇工作引入混合专家路由机制，提升检索性能。核心发现是路由策略在 BEIR 基准上比单一模型提高 2.1% nDCG@10，提供更高效的多域检索，支持 LLM 在知识密集任务中的应用。\n\n- **More is More: Addition Bias in Large Language Models（More is More: 大型语言模型中的加法偏差）**  \n  论文揭示 LLM 存在类似人类的加法偏差，倾向于添加而非删除元素。实验在多种 LLM 上验证此偏差，可能影响资源使用和 AI 决策，呼吁优化训练以平衡偏差。\n\n#### 机器人和视觉导航（创新应用突出）\n- **RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins（RoboTwin: 基于生成式数字孪生的双臂机器人基准）**  \n  作者开发 RoboTwin 框架，使用 3D 生成模型创建双臂机器人任务数据集。主要发现是预训练策略在真实平台上提升成功率 40%，为机器人操作提供高效模拟基准。\n\n- **Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments（Cog-GA: 基于大型语言模型的生成式代理，用于连续环境的视觉语言导航）**  \n  这篇论文提出 Cog-GA 代理，利用 LLM 构建认知地图和路径预测。贡献包括双通道场景描述提升导航效率，实验在 VLN-CE 基准上达到 SOTA，促进 AI 在动态环境中的自主决策。\n\n- **TASAR: Transfer-based Attack on Skeletal Action Recognition（TASAR: 基于转移的骨骼动作识别攻击）**  \n  论文解决骨骼动作识别中的转移攻击问题，通过平滑损失函数提升鲁棒性。发现新方法显著改善攻击转移性，并在首个大规模基准上超越基线，强调 AI 安全。\n\n#### 医疗和生物应用（实际影响强）\n- **MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation（MobileUNETR: 轻量级端到端混合视觉 Transformer，用于高效医学图像分割）**  \n  作者设计 MobileUNETR 模型，结合 CNN 和 Transformer 进行皮肤癌分割。核心发现是仅用 3M 参数和 1.3 GFLOP 就超越大型模型，在 ISIC 数据集上表现优异，适合资源受限设备。\n\n- **UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views（UC-NeRF: 基于内窥镜稀疏视图的不确定性感知条件神经辐射场）**  \n  这篇工作提出 UC-NeRF 处理内窥镜图像重建。贡献包括不确定性估计提升光度一致性，实验在 SCARED 数据集上优于 SOTA，促进手术场景可视化。\n\n#### 其他领域（快速掠过）\n- **Backdoor defense, learnability and obfuscation（后门防御、可学习性和混淆）**  \n  作者（包括 Paul Christiano）定义后门防御游戏，关联 VC 维度和 PAC 可学习性。主要发现是高效防御框架，适用于 AI 安全。\n\n- **Brain-Inspired AI with Hyperbolic Geometry（基于双曲几何的脑启发 AI）**  \n  论文探索双曲几何提升神经网络性能，发现它在 NLP 和视觉任务中减少参数并提升泛化。\n\n- **NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls（NESTFUL: 评估 LLM 在嵌套 API 调用序列上的基准）**  \n  引入 NESTFUL 基准测试 LLM 的 API 调用能力。发现最佳模型准确率仅 25%，突出改进需求。\n\n其他论文如金融预测、文本摘要或纯理论模型（如波浪 GPT），虽有贡献但影响力较小，仅提要：它们分别在股票预测、摘要生成和信号处理上提出新方法，但细节较常规，快速掠过不展开。\n\n总之，今天的论文强调 AI 模型的优化和应用潜力，LLM 在强化学习和导航中的进展尤为值得关注，未来可探索更多实际部署挑战。明日见！",
  "papers": [
    {
      "arxiv_id": "2409.03077v2",
      "title": "Backdoor defense, learnability and obfuscation",
      "title_zh": "后门防御、可学习性与混淆",
      "authors": [
        "Paul Christiano",
        "Jacob Hilton",
        "Victor Lecomte",
        "Mark Xu"
      ],
      "abstract": "We introduce a formal notion of defendability against backdoors using a game\nbetween an attacker and a defender. In this game, the attacker modifies a\nfunction to behave differently on a particular input known as the \"trigger\",\nwhile behaving the same almost everywhere else. The defender then attempts to\ndetect the trigger at evaluation time. If the defender succeeds with high\nenough probability, then the function class is said to be defendable. The key\nconstraint on the attacker that makes defense possible is that the attacker's\nstrategy must work for a randomly-chosen trigger.\n  Our definition is simple and does not explicitly mention learning, yet we\ndemonstrate that it is closely connected to learnability. In the\ncomputationally unbounded setting, we use a voting algorithm of Hanneke et al.\n(2022) to show that defendability is essentially determined by the VC dimension\nof the function class, in much the same way as PAC learnability. In the\ncomputationally bounded setting, we use a similar argument to show that\nefficient PAC learnability implies efficient defendability, but not conversely.\nOn the other hand, we use indistinguishability obfuscation to show that the\nclass of polynomial size circuits is not efficiently defendable. Finally, we\npresent polynomial size decision trees as a natural example for which defense\nis strictly easier than learning. Thus, we identify efficient defendability as\na notable intermediate concept in between efficient learnability and\nobfuscation.",
      "tldr_zh": "本研究引入了“defendability”这一正式概念，用于评估函数类对 backdoor 攻击的防御能力，通过攻击者和防御者之间的游戏定义：攻击者修改函数，使其在特定“trigger”输入上行为不同，而防御者试图检测该 trigger，且策略需适用于随机 trigger。研究发现，在计算无界设置中，defendability 主要由函数类的 VC dimension 决定，与 PAC learnability 类似；在计算有界设置中，高效 PAC learnability 意味着高效 defendability，但反之不成立。利用 indistinguishability obfuscation，该文证明多项式大小电路不是高效可防御的，并以多项式大小决策树为例，显示防御可能比学习更容易，从而将高效 defendability 定位为学习和 obfuscation 之间的中间概念。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.03077v2",
      "published_date": "2024-09-04 21:05:42 UTC",
      "updated_date": "2024-11-18 17:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:15:06.323714"
    },
    {
      "arxiv_id": "2409.03062v1",
      "title": "MobileUNETR: A Lightweight End-To-End Hybrid Vision Transformer For Efficient Medical Image Segmentation",
      "title_zh": "MobileUNETR：一种轻量级端到端混合视觉Transformer，用于高效医学图像分割",
      "authors": [
        "Shehan Perera",
        "Yunus Erzurumlu",
        "Deepak Gulati",
        "Alper Yilmaz"
      ],
      "abstract": "Skin cancer segmentation poses a significant challenge in medical image\nanalysis. Numerous existing solutions, predominantly CNN-based, face issues\nrelated to a lack of global contextual understanding. Alternatively, some\napproaches resort to large-scale Transformer models to bridge the global\ncontextual gaps, but at the expense of model size and computational complexity.\nFinally many Transformer based approaches rely primarily on CNN based decoders\noverlooking the benefits of Transformer based decoding models. Recognizing\nthese limitations, we address the need efficient lightweight solutions by\nintroducing MobileUNETR, which aims to overcome the performance constraints\nassociated with both CNNs and Transformers while minimizing model size,\npresenting a promising stride towards efficient image segmentation. MobileUNETR\nhas 3 main features. 1) MobileUNETR comprises of a lightweight hybrid\nCNN-Transformer encoder to help balance local and global contextual feature\nextraction in an efficient manner; 2) A novel hybrid decoder that\nsimultaneously utilizes low-level and global features at different resolutions\nwithin the decoding stage for accurate mask generation; 3) surpassing large and\ncomplex architectures, MobileUNETR achieves superior performance with 3 million\nparameters and a computational complexity of 1.3 GFLOP resulting in 10x and 23x\nreduction in parameters and FLOPS, respectively. Extensive experiments have\nbeen conducted to validate the effectiveness of our proposed method on four\npublicly available skin lesion segmentation datasets, including ISIC 2016, ISIC\n2017, ISIC 2018, and PH2 datasets. The code will be publicly available at:\nhttps://github.com/OSUPCVLab/MobileUNETR.git",
      "tldr_zh": "这篇论文针对皮肤癌分割等医疗图像分析的挑战，提出了 MobileUNETR，一种轻量级端到端混合 Vision Transformer 模型，以解决传统 CNN 模型缺乏全局上下文理解和 Transformer 模型计算复杂度高的局限性。MobileUNETR 采用混合 CNN-Transformer 编码器来平衡局部和全局特征提取，并引入新型混合解码器，同时利用不同分辨率的低级和全局特征生成精确掩码。该模型仅需 3 百万参数和 1.3 GFLOP 计算复杂度，比大型架构减少 10 倍参数和 23 倍 FLOPS，并在 ISIC 2016、2017、2018 和 PH2 等公开数据集上表现出优越性能，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ECCV 2024 - BioImage Computing Workshop (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2409.03062v1",
      "published_date": "2024-09-04 20:23:37 UTC",
      "updated_date": "2024-09-04 20:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:15:19.656595"
    },
    {
      "arxiv_id": "2409.03060v1",
      "title": "Better Verified Explanations with Applications to Incorrectness and Out-of-Distribution Detection",
      "title_zh": "更好的验证解释及其在错误检测和分布外检测中的应用",
      "authors": [
        "Min Wu",
        "Xiaofu Li",
        "Haoze Wu",
        "Clark Barrett"
      ],
      "abstract": "Building on VeriX (Verified eXplainability, arXiv:2212.01051), a system for\nproducing optimal verified explanations for machine learning model outputs, we\npresent VeriX+, which significantly improves both the size and the generation\ntime of verified explanations. We introduce a bound propagation-based\nsensitivity technique to improve the size, and a binary search-based traversal\nwith confidence ranking for improving time -- the two techniques are orthogonal\nand can be used independently or together. We also show how to adapt the\nQuickXplain (Junker 2004) algorithm to our setting to provide a trade-off\nbetween size and time. Experimental evaluations on standard benchmarks\ndemonstrate significant improvements on both metrics, e.g., a size reduction of\n38% on the GTSRB dataset and a time reduction of 90% on MNIST. We also explore\napplications of our verified explanations and show that explanation size is a\nuseful proxy for both incorrectness detection and out-of-distribution\ndetection.",
      "tldr_zh": "本文基于 VeriX 系统开发了 VeriX+，显著改善了机器学习模型输出验证解释的大小和生成时间，通过引入边界传播-based sensitivity technique 优化解释大小，以及二分搜索-based traversal with confidence ranking 提升效率。实验在标准基准上显示了显著改进，例如 GTSRB 数据集解释大小减少38%，MNIST 数据集生成时间减少90%。此外，作者展示了解释大小作为错误检测和异常分布检测的代理应用，提供了一种大小与时间权衡的 QuickXplain 算法适应方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03060v1",
      "published_date": "2024-09-04 20:20:37 UTC",
      "updated_date": "2024-09-04 20:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:15:29.038882"
    },
    {
      "arxiv_id": "2409.12990v3",
      "title": "Brain-Inspired AI with Hyperbolic Geometry",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Joseph",
        "Nathan Francis",
        "Meijke Balay"
      ],
      "abstract": "Artificial neural networks (ANNs) were inspired by the architecture and\nfunctions of the human brain and have revolutionised the field of artificial\nintelligence (AI). Inspired by studies on the latent geometry of the brain, in\nthis perspective paper we posit that an increase in the research and\napplication of hyperbolic geometry in ANNs and machine learning will lead to\nincreased accuracy, improved feature space representations and more efficient\nmodels across a range of tasks. We examine the structure and functions of the\nhuman brain, emphasising the correspondence between its scale-free hierarchical\norganization and hyperbolic geometry, and reflecting on the central role\nhyperbolic geometry plays in facilitating human intelligence. Empirical\nevidence indicates that hyperbolic neural networks outperform Euclidean models\nfor tasks including natural language processing, computer vision and complex\nnetwork analysis, requiring fewer parameters and exhibiting better\ngeneralisation. Despite its nascent adoption, hyperbolic geometry holds promise\nfor improving machine learning models through brain-inspired geometric\nrepresentations.",
      "tldr_zh": "本论文探讨了受人类大脑启发的人工神经网络（ANNs），提出在机器学习中增加双曲几何（hyperbolic geometry）应用，以提升模型准确性、特征空间表示和效率。作者强调人类大脑的无标度分层组织（scale-free hierarchical organization）与双曲几何的对应关系，这有助于模拟大脑功能并促进智能发展。实证证据显示，双曲神经网络在自然语言处理、计算机视觉和复杂网络分析等任务中优于欧氏模型（Euclidean models），需更少参数且泛化能力更强。尽管仍处于初步阶段，这种脑启发式几何表示有望显著改进机器学习模型。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "q-bio.NC",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.12990v3",
      "published_date": "2024-09-04 19:58:25 UTC",
      "updated_date": "2025-02-03 17:14:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:15:41.556641"
    },
    {
      "arxiv_id": "2409.08297v1",
      "title": "Comparative Study of Long Short-Term Memory (LSTM) and Quantum Long Short-Term Memory (QLSTM): Prediction of Stock Market Movement",
      "title_zh": "翻译失败",
      "authors": [
        "Tariq Mahmood",
        "Ibtasam Ahmad",
        "Malik Muhammad Zeeshan Ansar",
        "Jumanah Ahmed Darwish",
        "Rehan Ahmad Khan Sherwani"
      ],
      "abstract": "In recent years, financial analysts have been trying to develop models to\npredict the movement of a stock price index. The task becomes challenging in\nvague economic, social, and political situations like in Pakistan. In this\nstudy, we employed efficient models of machine learning such as long short-term\nmemory (LSTM) and quantum long short-term memory (QLSTM) to predict the Karachi\nStock Exchange (KSE) 100 index by taking monthly data of twenty-six economic,\nsocial, political, and administrative indicators from February 2004 to December\n2020. The comparative results of LSTM and QLSTM predicted values of the KSE 100\nindex with the actual values suggested QLSTM a potential technique to predict\nstock market trends.",
      "tldr_zh": "本研究比较了 Long Short-Term Memory (LSTM) 和 Quantum Long Short-Term Memory (QLSTM) 两种机器学习模型在预测股票市场运动方面的性能，针对巴基斯坦的 Karachi Stock Exchange (KSE) 100 指数进行分析。研究使用了从 2004 年 2 月到 2020 年 12 月的 26 个经济、社会、政治和行政指标作为数据源，通过模型预测来评估其准确性。结果表明，QLSTM 的预测值与实际值更接近，证明其是预测股票市场趋势的潜在有效技术。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08297v1",
      "published_date": "2024-09-04 19:34:37 UTC",
      "updated_date": "2024-09-04 19:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:15:52.697993"
    },
    {
      "arxiv_id": "2409.03043v2",
      "title": "Can Your Generative Model Detect Out-of-Distribution Covariate Shift?",
      "title_zh": "你的生成模型能检测分布外协变量偏移吗？",
      "authors": [
        "Christiaan Viviers",
        "Amaan Valiuddin",
        "Francisco Caetano",
        "Lemar Abdi",
        "Lena Filatova",
        "Peter de With",
        "Fons van der Sommen"
      ],
      "abstract": "Detecting Out-of-Distribution (OOD) sensory data and covariate distribution\nshift aims to identify new test examples with different high-level image\nstatistics to the captured, normal and In-Distribution (ID) set. Existing OOD\ndetection literature largely focuses on semantic shift with little-to-no\nconsensus over covariate shift. Generative models capture the ID data in an\nunsupervised manner, enabling them to effectively identify samples that deviate\nsignificantly from this learned distribution, irrespective of the downstream\ntask. In this work, we elucidate the ability of generative models to detect and\nquantify domain-specific covariate shift through extensive analyses that\ninvolves a variety of models. To this end, we conjecture that it is sufficient\nto detect most occurring sensory faults (anomalies and deviations in global\nsignals statistics) by solely modeling high-frequency signal-dependent and\nindependent details. We propose a novel method, CovariateFlow, for OOD\ndetection, specifically tailored to covariate heteroscedastic high-frequency\nimage-components using conditional Normalizing Flows (cNFs). Our results on\nCIFAR10 vs. CIFAR10-C and ImageNet200 vs. ImageNet200-C demonstrate the\neffectiveness of the method by accurately detecting OOD covariate shift. This\nwork contributes to enhancing the fidelity of imaging systems and aiding\nmachine learning models in OOD detection in the presence of covariate shift.",
      "tldr_zh": "该论文探讨生成模型是否能有效检测 Out-of-Distribution (OOD) covariate shift，特别是图像数据中高频信号统计的偏差。作者分析了生成模型的无监督能力，发现通过建模高频信号相关细节即可识别大多数sensory faults，并提出新方法CovariateFlow，使用conditional Normalizing Flows (cNFs)针对covariate heteroscedastic高频图像组件进行OOD检测。在CIFAR10 vs. CIFAR10-C和ImageNet200 vs. ImageNet200-C数据集上的实验结果显示，该方法显著提高了OOD covariate shift的检测准确性，从而提升了图像系统的保真度和机器学习模型的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024, typos corrected",
      "pdf_url": "http://arxiv.org/pdf/2409.03043v2",
      "published_date": "2024-09-04 19:27:56 UTC",
      "updated_date": "2024-10-09 15:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:16:07.332053"
    },
    {
      "arxiv_id": "2409.02920v3",
      "title": "RoboTwin: Dual-Arm Robot Benchmark with Generative Digital Twins (early version)",
      "title_zh": "RoboTwin：双臂机器人基准测试，使用生成式数字孪生（早期版本）",
      "authors": [
        "Yao Mu",
        "Tianxing Chen",
        "Shijia Peng",
        "Zanxin Chen",
        "Zeyu Gao",
        "Yude Zou",
        "Lunkai Lin",
        "Zhiqiang Xie",
        "Ping Luo"
      ],
      "abstract": "In the rapidly advancing field of robotics, dual-arm coordination and complex\nobject manipulation are essential capabilities for developing advanced\nautonomous systems. However, the scarcity of diverse, high-quality\ndemonstration data and real-world-aligned evaluation benchmarks severely limits\nsuch development. To address this, we introduce RoboTwin, a generative digital\ntwin framework that uses 3D generative foundation models and large language\nmodels to produce diverse expert datasets and provide a real-world-aligned\nevaluation platform for dual-arm robotic tasks. Specifically, RoboTwin creates\nvaried digital twins of objects from single 2D images, generating realistic and\ninteractive scenarios. It also introduces a spatial relation-aware code\ngeneration framework that combines object annotations with large language\nmodels to break down tasks, determine spatial constraints, and generate precise\nrobotic movement code. Our framework offers a comprehensive benchmark with both\nsimulated and real-world data, enabling standardized evaluation and better\nalignment between simulated training and real-world performance. We validated\nour approach using the open-source COBOT Magic Robot platform. Policies\npre-trained on RoboTwin-generated data and fine-tuned with limited real-world\nsamples improve the success rate of over 70% for single-arm tasks and over 40%\nfor dual-arm tasks compared to models trained solely on real-world data. This\nsignificant improvement demonstrates RoboTwin's potential to enhance the\ndevelopment and evaluation of dual-arm robotic manipulation systems. Project\nPage: https://robotwin-benchmark.github.io/early-version/.",
      "tldr_zh": "该研究引入了RoboTwin，一种基于生成式数字孪生（generative digital twins）的框架，用于双臂机器人基准测试，旨在解决高质数据和评估标准的缺失问题。该框架利用3D generative foundation models和large language models（LLMs）从单张2D图像生成多样化的物体数字孪生，并结合空间关系感知代码生成框架来分解任务、确定空间约束并输出精确机器人运动代码。RoboTwin提供模拟和真实世界数据的综合基准，促进标准化评估和训练与实际性能的对齐。在COBOT Magic Robot平台上的实验验证显示，使用RoboTwin生成数据预训练并微调的模型，使单臂任务成功率提升超过70%，双臂任务超过40%，显著提升了双臂机器人操纵系统的开发潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://robotwin-benchmark.github.io/early-version/",
      "pdf_url": "http://arxiv.org/pdf/2409.02920v3",
      "published_date": "2024-09-04 17:59:52 UTC",
      "updated_date": "2025-04-16 17:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:16:19.007707"
    },
    {
      "arxiv_id": "2409.02917v2",
      "title": "UC-NeRF: Uncertainty-aware Conditional Neural Radiance Fields from Endoscopic Sparse Views",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "Jiangliu Wang",
        "Ruofeng Wei",
        "Di Kang",
        "Qi Dou",
        "Yun-hui Liu"
      ],
      "abstract": "Visualizing surgical scenes is crucial for revealing internal anatomical\nstructures during minimally invasive procedures. Novel View Synthesis is a\nvital technique that offers geometry and appearance reconstruction, enhancing\nunderstanding, planning, and decision-making in surgical scenes. Despite the\nimpressive achievements of Neural Radiance Field (NeRF), its direct application\nto surgical scenes produces unsatisfying results due to two challenges:\nendoscopic sparse views and significant photometric inconsistencies. In this\npaper, we propose uncertainty-aware conditional NeRF for novel view synthesis\nto tackle the severe shape-radiance ambiguity from sparse surgical views. The\ncore of UC-NeRF is to incorporate the multi-view uncertainty estimation to\ncondition the neural radiance field for modeling the severe photometric\ninconsistencies adaptively. Specifically, our UC-NeRF first builds a\nconsistency learner in the form of multi-view stereo network, to establish the\ngeometric correspondence from sparse views and generate uncertainty estimation\nand feature priors. In neural rendering, we design a base-adaptive NeRF network\nto exploit the uncertainty estimation for explicitly handling the photometric\ninconsistencies. Furthermore, an uncertainty-guided geometry distillation is\nemployed to enhance geometry learning. Experiments on the SCARED and Hamlyn\ndatasets demonstrate our superior performance in rendering appearance and\ngeometry, consistently outperforming the current state-of-the-art approaches.\nOur code will be released at https://github.com/wrld/UC-NeRF.",
      "tldr_zh": "这篇论文提出 UC-NeRF，一种不确定性感知的条件 Neural Radiance Fields，用于从内窥镜稀疏视图合成新视图，解决手术场景中形状-辐射模糊和光度不一致性问题。核心方法包括构建 multi-view stereo network 来估计多视图不确定性和特征先验，并设计 base-adaptive NeRF 网络结合不确定性引导的几何蒸馏，以适应性处理光度不一致性。实验在 SCARED 和 Hamlyn 数据集上显示，UC-NeRF 在渲染外观和几何方面显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE Transactions on Medical Imaging",
      "pdf_url": "http://arxiv.org/pdf/2409.02917v2",
      "published_date": "2024-09-04 17:53:42 UTC",
      "updated_date": "2024-11-09 15:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:16:31.271138"
    },
    {
      "arxiv_id": "2409.03797v2",
      "title": "NESTFUL: A Benchmark for Evaluating LLMs on Nested Sequences of API Calls",
      "title_zh": "翻译失败",
      "authors": [
        "Kinjal Basu",
        "Ibrahim Abdelaziz",
        "Kiran Kate",
        "Mayank Agarwal",
        "Maxwell Crouse",
        "Yara Rizk",
        "Kelsey Bradford",
        "Asim Munawar",
        "Sadhana Kumaravel",
        "Saurabh Goyal",
        "Xin Wang",
        "Luis A. Lastras",
        "Pavan Kapanipathi"
      ],
      "abstract": "The resurgence of autonomous agents built using large language models (LLMs)\nto solve complex real-world tasks has brought increased focus on LLMs'\nfundamental ability of tool or function calling. At the core of these agents,\nan LLM must plan, execute, and respond using external tools, APIs, and custom\nfunctions. Research on tool calling has gathered momentum, but evaluation\nbenchmarks and datasets representing the complexity of the tasks have lagged\nbehind. In this work, we focus on one such complexity, nested sequencing, with\nthe goal of extending existing benchmarks and evaluation. Specifically, we\npresent NESTFUL, a benchmark to evaluate LLMs on nested sequences of API calls,\ni.e., sequences where the output of one API call is passed as input to a\nsubsequent call. NESTFUL contains 1800+ nested sequences where all the function\ncalls are executable. Experimental results on multiple models and settings show\nthat the best-performing model on the dataset has a full sequence match\naccuracy of 25% and win-rate of 34% necessitating a large scope for improvement\nin the nested sequencing aspect of function calling. Our analysis of these\nresults provides possible future research directions for the community, in\naddition to a benchmark to track progress. We have released the NESTFUL dataset\nunder the Apache 2.0 license at https://github.com/IBM/NESTFUL.",
      "tldr_zh": "这篇论文介绍了 NESTFUL，这是一个基准数据集，用于评估大型语言模型 (LLMs) 在处理嵌套 API 调用序列方面的能力，这些序列涉及一个 API 的输出作为后续调用的输入。\nNESTFUL 包含超过 1800 个可执行的嵌套序列，旨在解决现有基准在任务复杂性上的不足，并聚焦于 LLMs 的规划、执行和响应功能。\n实验结果显示，最佳模型的完整序列匹配准确率仅为 25%，胜率 34%，表明当前模型在嵌套序列处理方面仍有较大改进空间。\n作者开源了 NESTFUL 数据集（Apache 2.0 许可），并提供了可能的未来研究方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03797v2",
      "published_date": "2024-09-04 17:53:24 UTC",
      "updated_date": "2025-01-23 18:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:16:43.875172"
    },
    {
      "arxiv_id": "2409.02908v6",
      "title": "Masked Diffusion Models are Secretly Time-Agnostic Masked Models and Exploit Inaccurate Categorical Sampling",
      "title_zh": "掩码扩散模型其实是时间",
      "authors": [
        "Kaiwen Zheng",
        "Yongxin Chen",
        "Hanzi Mao",
        "Ming-Yu Liu",
        "Jun Zhu",
        "Qinsheng Zhang"
      ],
      "abstract": "Masked diffusion models (MDMs) have emerged as a popular research topic for\ngenerative modeling of discrete data, thanks to their superior performance over\nother discrete diffusion models, and are rivaling the auto-regressive models\n(ARMs) for language modeling tasks. The recent effort in simplifying the masked\ndiffusion framework further leads to alignment with continuous-space diffusion\nmodels and more principled training and sampling recipes. In this paper,\nhowever, we reveal that both training and sampling of MDMs are theoretically\nfree from the time variable, arguably the key signature of diffusion models,\nand are instead equivalent to masked models. The connection on the sampling\naspect is drawn by our proposed first-hitting sampler (FHS). Specifically, we\nshow that the FHS is theoretically equivalent to MDMs' original generation\nprocess while significantly alleviating the time-consuming categorical sampling\nand achieving a 20$\\times$ speedup. In addition, our investigation raises\ndoubts about whether MDMs can truly beat ARMs in text generation. We identify,\nfor the first time, an underlying numerical issue, even with the commonly used\n32-bit floating-point precision, which results in inaccurate categorical\nsampling. We show that it lowers the effective temperature both theoretically\nand empirically, and the resulting decrease in token diversity makes previous\nevaluations, which assess the generation quality solely through the incomplete\ngenerative perplexity metric, somewhat unfair.",
      "tldr_zh": "本论文揭示了 Masked Diffusion Models (MDMs) 的训练和采样过程实际上不依赖于时间变量，而是等价于 Masked Models，这挑战了传统扩散模型的核心特征。同时，作者提出了 First-Hitting Sampler (FHS)，它与 MDMs 的原始生成过程理论等效，但显著减少了类别采样的计算开销，实现 20 倍的加速。研究还首次识别出 MDMs 在使用 32-bit 浮点精度时存在的数值问题，导致类别采样不准确，从而降低了 token 多样性，并质疑了 MDMs 与 Auto-Regressive Models (ARMs) 在文本生成任务中的性能比较公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.02908v6",
      "published_date": "2024-09-04 17:48:19 UTC",
      "updated_date": "2025-04-30 08:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:16:55.448966"
    },
    {
      "arxiv_id": "2409.02889v2",
      "title": "LongLLaVA: Scaling Multi-modal LLMs to 1000 Images Efficiently via a Hybrid Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Xidong Wang",
        "Dingjie Song",
        "Shunian Chen",
        "Chen Zhang",
        "Benyou Wang"
      ],
      "abstract": "Expanding the long-context capabilities of Multi-modal Large Language\nModels~(MLLMs) is crucial for video understanding, high-resolution image\nunderstanding, and multi-modal agents. This involves a series of systematic\noptimizations, including model architecture, data construction and training\nstrategy, particularly addressing challenges such as \\textit{degraded\nperformance with more images} and \\textit{high computational costs}. In this\npaper, we adapt the model architecture to a hybrid of Mamba and Transformer\nblocks, approach data construction with both temporal and spatial dependencies\namong multiple images and employ a progressive training strategy. The released\nmodel \\textbf{LongLLaVA}~(\\textbf{Long}-Context \\textbf{L}arge\n\\textbf{L}anguage \\textbf{a}nd \\textbf{V}ision \\textbf{A}ssistant) is the first\nhybrid MLLM, which achieved a better balance between efficiency and\neffectiveness. LongLLaVA not only achieves competitive results across various\nbenchmarks, but also maintains high throughput and low memory consumption.\nEspecially, it could process nearly a thousand images on a single A100 80GB\nGPU, showing promising application prospects for a wide range of tasks.",
      "tldr_zh": "该研究旨在扩展多模态大型语言模型 (MLLMs) 的长上下文能力，以支持视频理解、高分辨率图像理解和多模态代理，通过解决性能下降和高计算成本等挑战。论文提出了一种混合架构，将 Mamba 和 Transformer 块结合，并采用考虑时间和空间依赖性的数据构建方法以及渐进式训练策略，开发出首个混合 MLLM 模型 LongLLaVA。实验结果显示，LongLLaVA 在各种基准上取得竞争性性能，同时保持高吞吐量和低内存消耗，能够在单个 A100 80GB GPU 上处理近千张图像，具有广阔的应用前景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 9 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.02889v2",
      "published_date": "2024-09-04 17:25:21 UTC",
      "updated_date": "2024-10-03 11:01:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:17:12.207023"
    },
    {
      "arxiv_id": "2409.02883v1",
      "title": "Multi-stream deep learning framework to predict mild cognitive impairment with Rey Complex Figure Test",
      "title_zh": "基于 Rey Complex Figure Test 的多流深度学习框架用于预测轻度认知障碍",
      "authors": [
        "Junyoung Park",
        "Eun Hyun Seo",
        "Sunjun Kim",
        "SangHak Yi",
        "Kun Ho Lee",
        "Sungho Won"
      ],
      "abstract": "Drawing tests like the Rey Complex Figure Test (RCFT) are widely used to\nassess cognitive functions such as visuospatial skills and memory, making them\nvaluable tools for detecting mild cognitive impairment (MCI). Despite their\nutility, existing predictive models based on these tests often suffer from\nlimitations like small sample sizes and lack of external validation, which\nundermine their reliability. We developed a multi-stream deep learning\nframework that integrates two distinct processing streams: a multi-head\nself-attention based spatial stream using raw RCFT images and a scoring stream\nemploying a previously developed automated scoring system. Our model was\ntrained on data from 1,740 subjects in the Korean cohort and validated on an\nexternal hospital dataset of 222 subjects from Korea. The proposed multi-stream\nmodel demonstrated superior performance over baseline models (AUC = 0.872,\nAccuracy = 0.781) in external validation. The integration of both spatial and\nscoring streams enables the model to capture intricate visual details from the\nraw images while also incorporating structured scoring data, which together\nenhance its ability to detect subtle cognitive impairments. This dual approach\nnot only improves predictive accuracy but also increases the robustness of the\nmodel, making it more reliable in diverse clinical settings. Our model has\npractical implications for clinical settings, where it could serve as a\ncost-effective tool for early MCI screening.",
      "tldr_zh": "这篇论文提出了一种多流深度学习框架，用于利用Rey Complex Figure Test (RCFT)预测轻度认知障碍 (MCI)，以解决现有模型样本量小和缺乏外部验证的问题。该框架整合了多头自注意力 (multi-head self-attention) 基于的空间流（处理原始RCFT图像）和评分流（采用先前开发的自动评分系统），并在韩国队列的1740个受试者数据上训练，在外部医院数据集的222个受试者上验证。结果显示，该模型在外部验证中优于基线模型（AUC=0.872，Accuracy=0.781），通过结合视觉细节和结构化数据提升了对微妙认知障碍的检测能力。该方法为临床环境提供了一个可靠且成本效益高的早期MCI筛查工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.02883v1",
      "published_date": "2024-09-04 17:08:04 UTC",
      "updated_date": "2024-09-04 17:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:17:24.042773"
    },
    {
      "arxiv_id": "2409.02877v1",
      "title": "Configurable Foundation Models: Building LLMs from a Modular Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Chaojun Xiao",
        "Zhengyan Zhang",
        "Chenyang Song",
        "Dazhi Jiang",
        "Feng Yao",
        "Xu Han",
        "Xiaozhi Wang",
        "Shuo Wang",
        "Yufei Huang",
        "Guanyu Lin",
        "Yingfa Chen",
        "Weilin Zhao",
        "Yuge Tu",
        "Zexuan Zhong",
        "Ao Zhang",
        "Chenglei Si",
        "Khai Hao Moo",
        "Chenyang Zhao",
        "Huimin Chen",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Jingbo Shang",
        "Maosong Sun"
      ],
      "abstract": "Advancements in LLMs have recently unveiled challenges tied to computational\nefficiency and continual scalability due to their requirements of huge\nparameters, making the applications and evolution of these models on devices\nwith limited computation resources and scenarios requiring various abilities\nincreasingly cumbersome. Inspired by modularity within the human brain, there\nis a growing tendency to decompose LLMs into numerous functional modules,\nallowing for inference with part of modules and dynamic assembly of modules to\ntackle complex tasks, such as mixture-of-experts. To highlight the inherent\nefficiency and composability of the modular approach, we coin the term brick to\nrepresent each functional module, designating the modularized structure as\nconfigurable foundation models. In this paper, we offer a comprehensive\noverview and investigation of the construction, utilization, and limitation of\nconfigurable foundation models. We first formalize modules into emergent bricks\n- functional neuron partitions that emerge during the pre-training phase, and\ncustomized bricks - bricks constructed via additional post-training to improve\nthe capabilities and knowledge of LLMs. Based on diverse functional bricks, we\nfurther present four brick-oriented operations: retrieval and routing, merging,\nupdating, and growing. These operations allow for dynamic configuration of LLMs\nbased on instructions to handle complex tasks. To verify our perspective, we\nconduct an empirical analysis on widely-used LLMs. We find that the FFN layers\nfollow modular patterns with functional specialization of neurons and\nfunctional neuron partitions. Finally, we highlight several open issues and\ndirections for future research. Overall, this paper aims to offer a fresh\nmodular perspective on existing LLM research and inspire the future creation of\nmore efficient and scalable foundational models.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）的计算效率和可扩展性挑战，提出从模块化视角构建configurable foundation models，将LLMs分解为多个功能模块（bricks）。他们形式化了两种bricks：emergent bricks（在预训练阶段出现的神经元分区）和customized bricks（通过后训练增强能力的模块），并定义了四种brick-oriented operations，包括retrieval and routing、merging、updating和growing，以实现基于指令的动态配置处理复杂任务。实证分析显示，FFN layers 存在模块化模式和功能专业化，验证了这种方法的效率优势。最终，论文强调了这一视角的潜力，并指出了未来研究中的开放问题，以推动更高效、可扩展的LLMs发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02877v1",
      "published_date": "2024-09-04 17:01:02 UTC",
      "updated_date": "2024-09-04 17:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:17:36.469887"
    },
    {
      "arxiv_id": "2409.02871v2",
      "title": "Hybrid Imitation-Learning Motion Planner for Urban Driving",
      "title_zh": "混合模仿学习城市驾驶运动规划器",
      "authors": [
        "Cristian Gariboldi",
        "Matteo Corno",
        "Beng Jin"
      ],
      "abstract": "With the release of open source datasets such as nuPlan and Argoverse, the\nresearch around learning-based planners has spread a lot in the last years.\nExisting systems have shown excellent capabilities in imitating the human\ndriver behaviour, but they struggle to guarantee safe closed-loop driving.\nConversely, optimization-based planners offer greater security in short-term\nplanning scenarios. To confront this challenge, in this paper we propose a\nnovel hybrid motion planner that integrates both learning-based and\noptimization-based techniques. Initially, a multilayer perceptron (MLP)\ngenerates a human-like trajectory, which is then refined by an\noptimization-based component. This component not only minimizes tracking errors\nbut also computes a trajectory that is both kinematically feasible and\ncollision-free with obstacles and road boundaries. Our model effectively\nbalances safety and human-likeness, mitigating the trade-off inherent in these\nobjectives. We validate our approach through simulation experiments and further\ndemonstrate its efficacy by deploying it in real-world self-driving vehicles.",
      "tldr_zh": "本论文提出了一种混合模仿学习运动规划器，用于城市驾驶环境，旨在解决现有学习-based规划器虽能模仿人类行为但难以保证安全闭环驾驶的问题。方法包括先使用Multilayer Perceptron (MLP)生成类似人类的轨迹，然后通过optimization-based组件精炼轨迹，确保其kinematically feasible、collision-free并最小化跟踪错误。该框架有效平衡了安全性和人类驾驶风格，在模拟实验和真实自驾车部署中验证了其效能，展示了显著的改进潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "2024 IEEE 27th International Conference on Intelligent Transportation\n  Systems (ITSC)",
      "pdf_url": "http://arxiv.org/pdf/2409.02871v2",
      "published_date": "2024-09-04 16:54:31 UTC",
      "updated_date": "2025-04-19 06:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:17:44.845913"
    },
    {
      "arxiv_id": "2409.02864v3",
      "title": "Language Model Powered Digital Biology with BRAD",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Pickard",
        "Ram Prakash",
        "Marc Andrew Choi",
        "Natalie Oliven",
        "Cooper Stansbury",
        "Jillian Cwycyshyn",
        "Alex Gorodetsky",
        "Alvaro Velasquez",
        "Indika Rajapakse"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) are transforming biology,\ncomputer science, engineering, and every day life. However, integrating the\nwide array of computational tools, databases, and scientific literature\ncontinues to pose a challenge to biological research. LLMs are well-suited for\nunstructured integration, efficient information retrieval, and automating\nstandard workflows and actions from these diverse resources. To harness these\ncapabilities in bioinformatics, we present a prototype Bioinformatics Retrieval\nAugmented Digital assistant (BRAD). BRAD is a chatbot and agentic system that\nintegrates a variety of bioinformatics tools. The Python package implements an\nAI \\texttt{Agent} that is powered by LLMs and connects to a local file system,\nonline databases, and a user's software. The \\texttt{Agent} is highly\nconfigurable, enabling tasks such as Retrieval-Augmented Generation, searches\nacross bioinformatics databases, and the execution of software pipelines.\nBRAD's coordinated integration of bioinformatics tools delivers a context-aware\nand semi-autonomous system that extends beyond the capabilities of conventional\nLLM-based chatbots. A graphical user interface (GUI) provides an intuitive\ninterface to the system.",
      "tldr_zh": "本研究提出 BRAD，这是一个基于 Large Language Models (LLMs) 的生物信息学检索增强数字助手，用于整合计算工具、数据库和科学文献，解决生物研究中的资源整合挑战。BRAD 作为聊天机器人和代理系统，支持 Retrieval-Augmented Generation、跨数据库搜索以及软件管道执行，并连接本地文件系统和在线资源，提供高度可配置的自动化工作流。相比传统 LLM 聊天机器人，BRAD 通过图形用户界面 (GUI) 实现上下文感知和半自治功能，提升了生物信息学的效率和可用性。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures, 1 table. See: https://github.com/Jpickard1/BRAD",
      "pdf_url": "http://arxiv.org/pdf/2409.02864v3",
      "published_date": "2024-09-04 16:43:14 UTC",
      "updated_date": "2024-12-08 15:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:17:57.437986"
    },
    {
      "arxiv_id": "2409.02850v2",
      "title": "Oops, I Sampled it Again: Reinterpreting Confidence Intervals in Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Raphael Lafargue",
        "Luke Smith",
        "Franck Vermet",
        "Mathias Löwe",
        "Ian Reid",
        "Vincent Gripon",
        "Jack Valmadre"
      ],
      "abstract": "The predominant method for computing confidence intervals (CI) in few-shot\nlearning (FSL) is based on sampling the tasks with replacement, i.e.\\ allowing\nthe same samples to appear in multiple tasks. This makes the CI misleading in\nthat it takes into account the randomness of the sampler but not the data\nitself. To quantify the extent of this problem, we conduct a comparative\nanalysis between CIs computed with and without replacement. These reveal a\nnotable underestimation by the predominant method. This observation calls for a\nreevaluation of how we interpret confidence intervals and the resulting\nconclusions in FSL comparative studies. Our research demonstrates that the use\nof paired tests can partially address this issue. Additionally, we explore\nmethods to further reduce the (size of the) CI by strategically sampling tasks\nof a specific size. We also introduce a new optimized benchmark, which can be\naccessed at https://github.com/RafLaf/FSL-benchmark-again",
      "tldr_zh": "本研究揭示了 few-shot learning (FSL) 中使用带有替换的采样方法计算 confidence intervals (CI) 的问题，这种方法仅考虑采样器的随机性而忽略数据本身，导致 CI 被显著低估。作者通过比较带有替换和不带有替换的 CI 计算，证明了现有方法的不足，并呼吁重新评估 FSL 比较研究中的 CI 解释。研究建议采用 paired tests 来部分解决此问题，并探索战略性地采样特定大小的任务以缩小 CI。最终，他们提供了一个新的优化基准，详情可访问 https://github.com/RafLaf/FSL-benchmark-again。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "68T06",
        "I.2; I.4; I.5; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02850v2",
      "published_date": "2024-09-04 16:20:57 UTC",
      "updated_date": "2024-09-06 08:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:18:09.454516"
    },
    {
      "arxiv_id": "2409.02840v1",
      "title": "R2GQA: Retriever-Reader-Generator Question Answering System to Support Students Understanding Legal Regulations in Higher Education",
      "title_zh": "R2GQA：检索器-阅读",
      "authors": [
        "Phuc-Tinh Pham Do",
        "Duy-Ngoc Dinh Cao",
        "Khanh Quoc Tran",
        "Kiet Van Nguyen"
      ],
      "abstract": "In this article, we propose the R2GQA system, a Retriever-Reader-Generator\nQuestion Answering system, consisting of three main components: Document\nRetriever, Machine Reader, and Answer Generator. The Retriever module employs\nadvanced information retrieval techniques to extract the context of articles\nfrom a dataset of legal regulation documents. The Machine Reader module\nutilizes state-of-the-art natural language understanding algorithms to\ncomprehend the retrieved documents and extract answers. Finally, the Generator\nmodule synthesizes the extracted answers into concise and informative responses\nto questions of students regarding legal regulations. Furthermore, we built the\nViRHE4QA dataset in the domain of university training regulations, comprising\n9,758 question-answer pairs with a rigorous construction process. This is the\nfirst Vietnamese dataset in the higher regulations domain with various types of\nanswers, both extractive and abstractive. In addition, the R2GQA system is the\nfirst system to offer abstractive answers in Vietnamese. This paper discusses\nthe design and implementation of each module within the R2GQA system on the\nViRHE4QA dataset, highlighting their functionalities and interactions.\nFurthermore, we present experimental results demonstrating the effectiveness\nand utility of the proposed system in supporting the comprehension of students\nof legal regulations in higher education settings. In general, the R2GQA system\nand the ViRHE4QA dataset promise to contribute significantly to related\nresearch and help students navigate complex legal documents and regulations,\nempowering them to make informed decisions and adhere to institutional policies\neffectively. Our dataset is available for research purposes.",
      "tldr_zh": "本文提出 R2GQA 系统，一个由 Retriever-Reader-Generator 组件组成的问答系统，旨在帮助高等教育学生理解法律法规。具体而言，Retriever 模块使用高级信息检索技术提取相关文档上下文，Reader 模块通过自然语言理解算法提取答案，而 Generator 模块合成简洁的响应。研究者构建了 ViRHE4QA 数据集，包含 9,758 个越南语问题-答案对，这是首个涵盖提取式和抽象式答案的越南语高等教育法规数据集，且 R2GQA 是首个提供越南语抽象式答案的系统。实验结果证明，该系统在 ViRHE4QA 上表现出色，有效提升了学生的法律法规理解，并为相关研究提供宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02840v1",
      "published_date": "2024-09-04 16:12:30 UTC",
      "updated_date": "2024-09-04 16:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:18:25.089685"
    },
    {
      "arxiv_id": "2409.02836v1",
      "title": "Exploring Sentiment Dynamics and Predictive Behaviors in Cryptocurrency Discussions by Few-Shot Learning with Large Language Models",
      "title_zh": "通过少样本学习与大型语言模型探索加密货币讨论中的情感动态和预测行为",
      "authors": [
        "Moein Shahiki Tash",
        "Zahra Ahani",
        "Mohim Tash",
        "Olga Kolesnikova",
        "Grigori Sidorov"
      ],
      "abstract": "This study performs analysis of Predictive statements, Hope speech, and\nRegret Detection behaviors within cryptocurrency-related discussions,\nleveraging advanced natural language processing techniques. We introduce a\nnovel classification scheme named \"Prediction statements,\" categorizing\ncomments into Predictive Incremental, Predictive Decremental, Predictive\nNeutral, or Non-Predictive categories. Employing GPT-4o, a cutting-edge large\nlanguage model, we explore sentiment dynamics across five prominent\ncryptocurrencies: Cardano, Binance, Matic, Fantom, and Ripple. Our analysis\nreveals distinct patterns in predictive sentiments, with Matic demonstrating a\nnotably higher propensity for optimistic predictions. Additionally, we\ninvestigate hope and regret sentiments, uncovering nuanced interplay between\nthese emotions and predictive behaviors. Despite encountering limitations\nrelated to data volume and resource availability, our study reports valuable\ndiscoveries concerning investor behavior and sentiment trends within the\ncryptocurrency market, informing strategic decision-making and future research\nendeavors.",
      "tldr_zh": "本研究利用Few-Shot Learning和Large Language Models（如GPT-4o）分析加密货币讨论中的预测语句、希望言论和遗憾行为，引入了\"Prediction statements\"的新分类方案，将评论分为预测增量、预测减量、预测中性或非预测类别。针对Cardano、Binance、Matic、Fantom和Ripple等五种主要加密货币，他们揭示了情感动态的独特模式，例如Matic显示出更高的乐观预测倾向，并探讨了希望和遗憾情感与预测行为之间的细微互动。尽管受数据量和资源限制，该研究提供了宝贵见解，帮助理解投资者行为和市场情感趋势，支持战略决策和未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02836v1",
      "published_date": "2024-09-04 16:02:30 UTC",
      "updated_date": "2024-09-04 16:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:18:35.514736"
    },
    {
      "arxiv_id": "2409.02977v1",
      "title": "Large Language Model-Based Agents for Software Engineering: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Junwei Liu",
        "Kaixin Wang",
        "Yixuan Chen",
        "Xin Peng",
        "Zhenpeng Chen",
        "Lingming Zhang",
        "Yiling Lou"
      ],
      "abstract": "The recent advance in Large Language Models (LLMs) has shaped a new paradigm\nof AI agents, i.e., LLM-based agents. Compared to standalone LLMs, LLM-based\nagents substantially extend the versatility and expertise of LLMs by enhancing\nLLMs with the capabilities of perceiving and utilizing external resources and\ntools. To date, LLM-based agents have been applied and shown remarkable\neffectiveness in Software Engineering (SE). The synergy between multiple agents\nand human interaction brings further promise in tackling complex real-world SE\nproblems. In this work, we present a comprehensive and systematic survey on\nLLM-based agents for SE. We collect 106 papers and categorize them from two\nperspectives, i.e., the SE and agent perspectives. In addition, we discuss open\nchallenges and future directions in this critical domain. The repository of\nthis survey is at https://github.com/FudanSELab/Agent4SE-Paper-List.",
      "tldr_zh": "这篇调查论文探讨了基于Large Language Models (LLMs)的代理在Software Engineering (SE)领域的应用，强调这些代理通过感知和利用外部资源，扩展了LLMs的功能，并已在SE任务中展现出显著成效。作者收集了106篇相关论文，从SE视角（如具体应用）和代理视角（如设计和交互）进行分类，分析了多代理协同和人类交互在解决复杂SE问题的潜力。论文还讨论了当前挑战和未来方向，并提供了GitHub仓库（https://github.com/FudanSELab/Agent4SE-Paper-List）以供进一步参考。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02977v1",
      "published_date": "2024-09-04 15:59:41 UTC",
      "updated_date": "2024-09-04 15:59:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:18:56.143695"
    },
    {
      "arxiv_id": "2409.03796v1",
      "title": "Protecting Activity Sensing Data Privacy Using Hierarchical Information Dissociation",
      "title_zh": "利用分层信息分离保护活动感知数据隐私",
      "authors": [
        "Guangjing Wang",
        "Hanqing Guo",
        "Yuanda Wang",
        "Bocheng Chen",
        "Ce Zhou",
        "Qiben Yan"
      ],
      "abstract": "Smartphones and wearable devices have been integrated into our daily lives,\noffering personalized services. However, many apps become overprivileged as\ntheir collected sensing data contains unnecessary sensitive information. For\nexample, mobile sensing data could reveal private attributes (e.g., gender and\nage) and unintended sensitive features (e.g., hand gestures when entering\npasswords). To prevent sensitive information leakage, existing methods must\nobtain private labels and users need to specify privacy policies. However, they\nonly achieve limited control over information disclosure. In this work, we\npresent Hippo to dissociate hierarchical information including private metadata\nand multi-grained activity information from the sensing data. Hippo achieves\nfine-grained control over the disclosure of sensitive information without\nrequiring private labels. Specifically, we design a latent guidance-based\ndiffusion model, which generates multi-grained versions of raw sensor data\nconditioned on hierarchical latent activity features. Hippo enables users to\ncontrol the disclosure of sensitive information in sensing data, ensuring their\nprivacy while preserving the necessary features to meet the utility\nrequirements of applications. Hippo is the first unified model that achieves\ntwo goals: perturbing the sensitive attributes and controlling the disclosure\nof sensitive information in mobile sensing data. Extensive experiments show\nthat Hippo can anonymize personal attributes and transform activity information\nat various resolutions across different types of sensing data.",
      "tldr_zh": "该研究针对智能手机和可穿戴设备中感知数据隐私泄露问题（如性别、年龄或手势信息），提出了一种名为 Hippo 的方法，利用 Hierarchical Information Dissociation 来分离私有元数据和多粒度活动信息。Hippo 采用基于潜在指导的 diffusion model 生成原始传感器数据的多粒度版本，允许用户在不需私密标签的情况下实现细粒度控制敏感信息披露，同时保留应用所需的功能特性。该方法是首个统一模型，能扰动敏感属性并控制移动感知数据中的信息披露，实验证明其在不同类型感知数据上有效匿名化个人属性并转换活动信息分辨率。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03796v1",
      "published_date": "2024-09-04 15:38:00 UTC",
      "updated_date": "2024-09-04 15:38:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:18:57.851926"
    },
    {
      "arxiv_id": "2409.02810v1",
      "title": "A hybrid FEM-PINN method for time-dependent partial differential equations",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodong Feng",
        "Haojiong Shangguan",
        "Tao Tang",
        "Xiaoliang Wan",
        "Tao Zhou"
      ],
      "abstract": "In this work, we present a hybrid numerical method for solving evolution\npartial differential equations (PDEs) by merging the time finite element method\nwith deep neural networks. In contrast to the conventional deep learning-based\nformulation where the neural network is defined on a spatiotemporal domain, our\nmethodology utilizes finite element basis functions in the time direction where\nthe space-dependent coefficients are defined as the output of a neural network.\nWe then apply the Galerkin or collocation projection in the time direction to\nobtain a system of PDEs for the space-dependent coefficients which is\napproximated in the framework of PINN. The advantages of such a hybrid\nformulation are twofold: statistical errors are avoided for the integral in the\ntime direction, and the neural network's output can be regarded as a set of\nreduced spatial basis functions. To further alleviate the difficulties from\nhigh dimensionality and low regularity, we have developed an adaptive sampling\nstrategy that refines the training set. More specifically, we use an explicit\ndensity model to approximate the distribution induced by the PDE residual and\nthen augment the training set with new time-dependent random samples given by\nthe learned density model. The effectiveness and efficiency of our proposed\nmethod have been demonstrated through a series of numerical experiments.",
      "tldr_zh": "本研究提出了一种混合数值方法，用于求解时间相关的偏微分方程（PDEs），将时间有限元方法（FEM）与深度神经网络相结合。不同于传统深度学习方法，该方法在时间方向使用有限元基函数，空间相关系数由神经网络输出，然后通过 Galerkin 或 collocation 投影得到空间系数的 PDE 系统，并采用 Physics-Informed Neural Networks (PINN) 进行逼近。优势包括避免时间方向的统计误差，并将神经网络输出视为一组减少的空间基函数；此外，引入自适应采样策略，使用显式密度模型近似 PDE 残差分布，以优化高维和低正则性问题。数值实验证明，该方法在有效性和效率上表现出色。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "25pages",
      "pdf_url": "http://arxiv.org/pdf/2409.02810v1",
      "published_date": "2024-09-04 15:28:25 UTC",
      "updated_date": "2024-09-04 15:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:19:15.767648"
    },
    {
      "arxiv_id": "2409.02808v1",
      "title": "Towards Edge-Based Data Lake Architecture for Intelligent Transportation System",
      "title_zh": "翻译失败",
      "authors": [
        "Danilo Fernandes",
        "Douglas L. L. Moura",
        "Gean Santos",
        "Geymerson S. Ramos",
        "Fabiane Queiroz",
        "Andre L. L. Aquino"
      ],
      "abstract": "The rapid urbanization growth has underscored the need for innovative\nsolutions to enhance transportation efficiency and safety. Intelligent\nTransportation Systems (ITS) have emerged as a promising solution in this\ncontext. However, analyzing and processing the massive and intricate data\ngenerated by ITS presents significant challenges for traditional data\nprocessing systems. This work proposes an Edge-based Data Lake Architecture to\nintegrate and analyze the complex data from ITS efficiently. The architecture\noffers scalability, fault tolerance, and performance, improving decision-making\nand enhancing innovative services for a more intelligent transportation\necosystem. We demonstrate the effectiveness of the architecture through an\nanalysis of three different use cases: (i) Vehicular Sensor Network, (ii)\nMobile Network, and (iii) Driver Identification applications.",
      "tldr_zh": "本研究针对智能交通系统（Intelligent Transportation Systems, ITS）中海量复杂数据的处理挑战，提出了一种基于边缘计算的Data Lake Architecture。该架构通过整合和分析ITS数据，提供可扩展性（scalability）、容错性（fault tolerance）和性能（performance）提升，从而改善决策过程并推动创新交通服务。研究通过三个实际用例——Vehicular Sensor Network、Mobile Network和Driver Identification应用——验证了该架构的有效性，为构建更智能的交通生态系统奠定了基础。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02808v1",
      "published_date": "2024-09-04 15:25:28 UTC",
      "updated_date": "2024-09-04 15:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:19:25.808283"
    },
    {
      "arxiv_id": "2409.02779v1",
      "title": "Governing dual-use technologies: Case studies of international security agreements and lessons for AI governance",
      "title_zh": "翻译失败",
      "authors": [
        "Akash R. Wasil",
        "Peter Barnett",
        "Michael Gerovitch",
        "Roman Hauksson",
        "Tom Reed",
        "Jack William Miller"
      ],
      "abstract": "International AI governance agreements and institutions may play an important\nrole in reducing global security risks from advanced AI. To inform the design\nof such agreements and institutions, we conducted case studies of historical\nand contemporary international security agreements. We focused specifically on\nthose arrangements around dual-use technologies, examining agreements in\nnuclear security, chemical weapons, biosecurity, and export controls. For each\nagreement, we examined four key areas: (a) purpose, (b) core powers, (c)\ngovernance structure, and (d) instances of non-compliance. From these case\nstudies, we extracted lessons for the design of international AI agreements and\ngovernance institutions. We discuss the importance of robust verification\nmethods, strategies for balancing power between nations, mechanisms for\nadapting to rapid technological change, approaches to managing trade-offs\nbetween transparency and security, incentives for participation, and effective\nenforcement mechanisms.",
      "tldr_zh": "这篇论文通过对核安全、化学武器、生物安全和出口控制等双重用途技术（dual-use technologies）的国际安全协议进行案例研究，探讨了这些协议的目的、核心权力、治理结构以及不遵守实例。研究从这些案例中提取教训，包括robust verification methods、权力平衡策略、适应快速技术变化的机制、透明与安全权衡、参与激励以及有效执行机制。最终，这些教训被应用于指导国际AI governance agreements的设计，以降低先进AI带来的全球安全风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02779v1",
      "published_date": "2024-09-04 14:56:59 UTC",
      "updated_date": "2024-09-04 14:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:19:36.363767"
    },
    {
      "arxiv_id": "2409.02760v1",
      "title": "An incremental preference elicitation-based approach to learning potentially non-monotonic preferences in multi-criteria sorting",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuolin Li",
        "Zhen Zhang",
        "Witold Pedrycz"
      ],
      "abstract": "This paper introduces a novel incremental preference elicitation-based\napproach to learning potentially non-monotonic preferences in multi-criteria\nsorting (MCS) problems, enabling decision makers to progressively provide\nassignment example preference information. Specifically, we first construct a\nmax-margin optimization-based model to model potentially non-monotonic\npreferences and inconsistent assignment example preference information in each\niteration of the incremental preference elicitation process. Using the optimal\nobjective function value of the max-margin optimization-based model, we devise\ninformation amount measurement methods and question selection strategies to\npinpoint the most informative alternative in each iteration within the\nframework of uncertainty sampling in active learning. Once the termination\ncriterion is satisfied, the sorting result for non-reference alternatives can\nbe determined through the use of two optimization models, i.e., the max-margin\noptimization-based model and the complexity controlling optimization model.\nSubsequently, two incremental preference elicitation-based algorithms are\ndeveloped to learn potentially non-monotonic preferences, considering different\ntermination criteria. Ultimately, we apply the proposed approach to a credit\nrating problem to elucidate the detailed implementation steps, and perform\ncomputational experiments on both artificial and real-world data sets to\ncompare the proposed question selection strategies with several benchmark\nstrategies.",
      "tldr_zh": "本研究提出了一种基于增量偏好收集（incremental preference elicitation）的创新方法，用于学习多标准排序（multi-criteria sorting, MCS）问题中的潜在非单调偏好（potentially non-monotonic preferences）。该方法通过构建最大边距优化（max-margin optimization）模型来处理不一致的偏好信息，并在主动学习（active learning）的框架下，使用信息量测量和问题选择策略（如uncertainty sampling）来逐步选择最有价值的备选方案。研究开发了两种考虑不同终止标准的增量算法，并在信用评级问题上进行了详细实现，并通过人工和真实数据集的计算实验证明，该方法比基准策略更有效，提升了偏好学习的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "37 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02760v1",
      "published_date": "2024-09-04 14:36:20 UTC",
      "updated_date": "2024-09-04 14:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:19:49.163990"
    },
    {
      "arxiv_id": "2409.02747v1",
      "title": "Tractable Offline Learning of Regular Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Ahana Deb",
        "Roberto Cipollone",
        "Anders Jonsson",
        "Alessandro Ronca",
        "Mohammad Sadegh Talebi"
      ],
      "abstract": "This work studies offline Reinforcement Learning (RL) in a class of\nnon-Markovian environments called Regular Decision Processes (RDPs). In RDPs,\nthe unknown dependency of future observations and rewards from the past\ninteractions can be captured by some hidden finite-state automaton. For this\nreason, many RDP algorithms first reconstruct this unknown dependency using\nautomata learning techniques. In this paper, we show that it is possible to\novercome two strong limitations of previous offline RL algorithms for RDPs,\nnotably RegORL. This can be accomplished via the introduction of two original\ntechniques: the development of a new pseudometric based on formal languages,\nwhich removes a problematic dependency on\n$L_\\infty^\\mathsf{p}$-distinguishability parameters, and the adoption of\nCount-Min-Sketch (CMS), instead of naive counting. The former reduces the\nnumber of samples required in environments that are characterized by a low\ncomplexity in language-theoretic terms. The latter alleviates the memory\nrequirements for long planning horizons. We derive the PAC sample complexity\nbounds associated to each of these techniques, and we validate the approach\nexperimentally.",
      "tldr_zh": "这篇论文研究了在 Regular Decision Processes (RDPs) 中的离线强化学习 (Offline RL)，这些是非马尔可夫环境，通过隐藏的有限状态自动机捕捉过去交互对未来观察和奖励的依赖。论文引入了两个新技巧：一个基于形式语言的新 pseudometric，以减少在语言理论复杂度低的环境中所需的样本数量，以及采用 Count-Min-Sketch (CMS) 来缓解长规划视野的内存需求。这些创新显著改善了现有算法如 RegORL 的局限性，并通过导出的 PAC sample complexity 边界和实验验证，证明了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in EWRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02747v1",
      "published_date": "2024-09-04 14:26:58 UTC",
      "updated_date": "2024-09-04 14:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:20:12.139096"
    },
    {
      "arxiv_id": "2409.02976v2",
      "title": "Hallucination Detection in LLMs: Fast and Memory-Efficient Fine-Tuned Models",
      "title_zh": "大型语言模型中的幻觉检测：快速且内存高效的微调模型",
      "authors": [
        "Gabriel Y. Arteaga",
        "Thomas B. Schön",
        "Nicolas Pielawski"
      ],
      "abstract": "Uncertainty estimation is a necessary component when implementing AI in\nhigh-risk settings, such as autonomous cars, medicine, or insurances. Large\nLanguage Models (LLMs) have seen a surge in popularity in recent years, but\nthey are subject to hallucinations, which may cause serious harm in high-risk\nsettings. Despite their success, LLMs are expensive to train and run: they need\na large amount of computations and memory, preventing the use of ensembling\nmethods in practice. In this work, we present a novel method that allows for\nfast and memory-friendly training of LLM ensembles. We show that the resulting\nensembles can detect hallucinations and are a viable approach in practice as\nonly one GPU is needed for training and inference.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在高风险领域（如自动驾驶、医学）的幻觉（hallucinations）问题，提出了一种快速且内存高效的细调方法，用于训练LLMs集成模型（ensembles）。该方法克服了传统LLMs训练的计算和内存开销问题，仅需一个GPU即可实现训练和推理。实验结果表明，这种集成模型能够有效检测幻觉，提供可靠的不确定性估计（uncertainty estimation），从而提升LLMs在实际应用中的安全性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02976v2",
      "published_date": "2024-09-04 13:59:38 UTC",
      "updated_date": "2024-12-06 12:39:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:20:11.140782"
    },
    {
      "arxiv_id": "2409.12197v3",
      "title": "Nteasee: A mixed methods study of expert and general population perspectives on deploying AI for health in African countries",
      "title_zh": "Nteasee：专家和一般人群对在非洲国家部署AI用于健康的观点的混合方法研究",
      "authors": [
        "Mercy Nyamewaa Asiedu",
        "Iskandar Haykel",
        "Awa Dieng",
        "Kerrie Kauer",
        "Tousif Ahmed",
        "Florence Ofori",
        "Charisma Chan",
        "Stephen Pfohl",
        "Negar Rostamzadeh",
        "Katherine Heller"
      ],
      "abstract": "Artificial Intelligence (AI) for health has the potential to significantly\nchange and improve healthcare. However in most African countries, identifying\nculturally and contextually attuned approaches for deploying these solutions is\nnot well understood. To bridge this gap, we conduct a qualitative study to\ninvestigate the best practices, fairness indicators, and potential biases to\nmitigate when deploying AI for health in African countries, as well as explore\nopportunities where artificial intelligence could make a positive impact in\nhealth. We used a mixed methods approach combining in-depth interviews (IDIs)\nand surveys. We conduct 1.5-2 hour long IDIs with 50 experts in health, policy,\nand AI across 17 countries, and through an inductive approach we conduct a\nqualitative thematic analysis on expert IDI responses. We administer a blinded\n30-minute survey with case studies to 672 general population participants\nacross 5 countries in Africa and analyze responses on quantitative scales,\nstatistically comparing responses by country, age, gender, and level of\nfamiliarity with AI. We thematically summarize open-ended responses from\nsurveys. Our results find generally positive attitudes, high levels of trust,\naccompanied by moderate levels of concern among general population participants\nfor AI usage for health in Africa. This contrasts with expert responses, where\nmajor themes revolved around trust/mistrust, ethical concerns, and systemic\nbarriers to integration, among others. This work presents the first-of-its-kind\nqualitative research study of the potential of AI for health in Africa from an\nalgorithmic fairness angle, with perspectives from both experts and the general\npopulation. We hope that this work guides policymakers and drives home the need\nfor further research and the inclusion of general population perspectives in\ndecision-making around AI usage.",
      "tldr_zh": "本研究采用混合方法（mixed methods）调查了非洲国家部署AI用于健康领域的专家和普通民众观点，旨在探讨最佳实践、公平指标（fairness indicators）、潜在偏见及积极影响。研究包括对50位跨17个国家的健康、政策和AI专家进行1.5-2小时深度访谈（IDIs），并通过定性主题分析处理回应；同时，对672位普通民众进行30分钟匿名调查，包括案例研究，并统计比较定量数据（如按国家、年龄、性别和AI熟悉度）。结果显示，普通民众对AI用于健康的总体态度积极、信任度高但有中度担忧，而专家主要关注信任/不信任、伦理问题和系统性障碍。研究首次从算法公平（algorithmic fairness）角度呈现AI在非洲健康领域的潜力，为政策制定者提供指导，并呼吁更多包容普通民众观点的研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "added illustrative figures",
      "pdf_url": "http://arxiv.org/pdf/2409.12197v3",
      "published_date": "2024-09-04 13:56:49 UTC",
      "updated_date": "2024-11-11 18:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:20:25.620835"
    },
    {
      "arxiv_id": "2409.02711v1",
      "title": "Creating a Gen-AI based Track and Trace Assistant MVP (SuperTracy) for PostNL",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Reshadati"
      ],
      "abstract": "The developments in the field of generative AI has brought a lot of\nopportunities for companies, for instance to improve efficiency in customer\nservice and automating tasks. PostNL, the biggest parcel and E-commerce\ncorporation of the Netherlands wants to use generative AI to enhance the\ncommunication around track and trace of parcels. During the internship a\nMinimal Viable Product (MVP) is created to showcase the value of using\ngenerative AI technologies, to enhance parcel tracking, analyzing the parcel's\njourney and being able to communicate about it in an easy to understand manner.\nThe primary goal was to develop an in-house LLM-based system, reducing\ndependency on external platforms and establishing the feasibility of a\ndedicated generative AI team within the company. This multi-agent LLM based\nsystem aimed to construct parcel journey stories and identify logistical\ndisruptions with heightened efficiency and accuracy. The research involved\ndeploying a sophisticated AI-driven communication system, employing\nRetrieval-Augmented Generation (RAG) for enhanced response precision, and\noptimizing large language models (LLMs) tailored to domain specific tasks.\n  The MVP successfully implemented a multi-agent open-source LLM system, called\nSuperTracy. SuperTracy is capable of autonomously managing a broad spectrum of\nuser inquiries and improving internal knowledge handling. Results and\nevaluation demonstrated technological innovation and feasibility, notably in\ncommunication about the track and trace of a parcel, which exceeded initial\nexpectations. These advancements highlight the potential of AI-driven solutions\nin logistics, suggesting many opportunities for further refinement and broader\nimplementation within PostNL operational framework.",
      "tldr_zh": "该研究针对PostNL公司开发了一个基于Generative AI的MVP系统SuperTracy，旨在提升包裹追踪和通信效率，通过自动化任务分析包裹旅程并以易懂方式回应用户查询。主要方法包括构建多智能体LLM系统，并采用Retrieval-Augmented Generation (RAG)技术优化响应精度和领域特定任务。结果显示，SuperTracy成功减少了对外部平台的依赖，提高了物流效率和准确性，并证明了在PostNL内部建立专属Generative AI团队的可行性，为AI在物流领域的进一步应用提供了宝贵机会。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02711v1",
      "published_date": "2024-09-04 13:49:19 UTC",
      "updated_date": "2024-09-04 13:49:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:20:39.917222"
    },
    {
      "arxiv_id": "2409.02702v2",
      "title": "Incorporating Like-Minded Peers to Overcome Friend Data Sparsity in Session-Based Social Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyan An",
        "Yunhan Li",
        "Qiang Yang",
        "Winston K. G. Seah",
        "Zhixu Li",
        "Conghao Yang"
      ],
      "abstract": "Session-based Social Recommendation (SSR) leverages social relationships\nwithin online networks to enhance the performance of Session-based\nRecommendation (SR). However, existing SSR algorithms often encounter the\nchallenge of \"friend data sparsity\". Moreover, significant discrepancies can\nexist between the purchase preferences of social network friends and those of\nthe target user, reducing the influence of friends relative to the target\nuser's own preferences. To address these challenges, this paper introduces the\nconcept of \"Like-minded Peers\" (LMP), representing users whose preferences\nalign with the target user's current session based on their historical\nsessions. This is the first work, to our knowledge, that uses LMP to enhance\nthe modeling of social influence in SSR. This approach not only alleviates the\nproblem of friend data sparsity but also effectively incorporates users with\nsimilar preferences to the target user. We propose a novel model named\nTransformer Encoder with Graph Attention Aggregator Recommendation (TEGAARec),\nwhich includes the TEGAA module and the GAT-based social aggregation module.\nThe TEGAA module captures and merges both long-term and short-term interests\nfor target users and LMP users. Concurrently, the GAT-based social aggregation\nmodule is designed to aggregate the target users' dynamic interests and social\ninfluence in a weighted manner. Extensive experiments on four real-world\ndatasets demonstrate the efficacy and superiority of our proposed model and\nablation studies are done to illustrate the contributions of each component in\nTEGAARec.",
      "tldr_zh": "本研究针对 Session-Based Social Recommendation (SSR) 中的朋友数据稀疏问题和偏好不一致挑战，首次引入 Like-minded Peers (LMP) 概念，即基于历史会话与目标用户当前偏好相似的用户，以增强社会影响建模。论文提出新模型 Transformer Encoder with Graph Attention Aggregator Recommendation (TEGAARec)，其中 TEGAA 模块捕捉并融合目标用户和 LMP 用户的长期及短期兴趣，而 GAT-based 社会聚合模块则通过加权方式整合动态兴趣和社会影响。在四个真实数据集上的广泛实验证明，TEGAARec 模型显著提升了推荐性能，且消融研究验证了各组件的贡献。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "None",
      "pdf_url": "http://arxiv.org/pdf/2409.02702v2",
      "published_date": "2024-09-04 13:39:12 UTC",
      "updated_date": "2024-09-07 00:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:20:49.193914"
    },
    {
      "arxiv_id": "2409.02697v2",
      "title": "Decision Transformer for Enhancing Neural Local Search on the Job Shop Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Constantin Waubert de Puiseau",
        "Fabian Wolz",
        "Merlin Montag",
        "Jannik Peters",
        "Hasan Tercan",
        "Tobias Meisen"
      ],
      "abstract": "The job shop scheduling problem (JSSP) and its solution algorithms have been\nof enduring interest in both academia and industry for decades. In recent\nyears, machine learning (ML) is playing an increasingly important role in\nadvancing existing and building new heuristic solutions for the JSSP, aiming to\nfind better solutions in shorter computation times. In this paper we build on\ntop of a state-of-the-art deep reinforcement learning (DRL) agent, called\nNeural Local Search (NLS), which can efficiently and effectively control a\nlarge local neighborhood search on the JSSP. In particular, we develop a method\nfor training the decision transformer (DT) algorithm on search trajectories\ntaken by a trained NLS agent to further improve upon the learned\ndecision-making sequences. Our experiments show that the DT successfully learns\nlocal search strategies that are different and, in many cases, more effective\nthan those of the NLS agent itself. In terms of the tradeoff between solution\nquality and acceptable computational time needed for the search, the DT is\nparticularly superior in application scenarios where longer computational times\nare acceptable. In this case, it makes up for the longer inference times\nrequired per search step, which are caused by the larger neural network\narchitecture, through better quality decisions per step. Thereby, the DT\nachieves state-of-the-art results for solving the JSSP with ML-enhanced search.",
      "tldr_zh": "本论文针对作业车间调度问题 (JSSP)，提出使用 Decision Transformer (DT) 算法来增强 Neural Local Search (NLS) 代理的性能，通过在 NLS 的搜索轨迹上训练 DT，以改进决策序列并实现更有效的本地搜索策略。实验表明，DT 学习了不同于 NLS 的策略，在许多情况下更高效，尤其在允许较长计算时间的应用场景中，它通过更好的决策质量抵消了每步推理时间增加的影响。最终，DT 在 ML 增强搜索中达到了解决 JSSP 的最先进结果，在解决方案质量与计算时间权衡上表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02697v2",
      "published_date": "2024-09-04 13:33:38 UTC",
      "updated_date": "2025-02-04 09:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:21:02.694140"
    },
    {
      "arxiv_id": "2409.02693v1",
      "title": "The Role of Artificial Intelligence and Machine Learning in Software Testing",
      "title_zh": "人工智能和机器学习在软件测试中的作用",
      "authors": [
        "Ahmed Ramadan",
        "Husam Yasin",
        "Burhan Pektas"
      ],
      "abstract": "Artificial Intelligence (AI) and Machine Learning (ML) have significantly\nimpacted various industries, including software development. Software testing,\na crucial part of the software development lifecycle (SDLC), ensures the\nquality and reliability of software products. Traditionally, software testing\nhas been a labor-intensive process requiring significant manual effort.\nHowever, the advent of AI and ML has transformed this landscape by introducing\nautomation and intelligent decision-making capabilities. AI and ML technologies\nenhance the efficiency and effectiveness of software testing by automating\ncomplex tasks such as test case generation, test execution, and result\nanalysis. These technologies reduce the time required for testing and improve\nthe accuracy of defect detection, ultimately leading to higher quality\nsoftware. AI can predict potential areas of failure by analyzing historical\ndata and identifying patterns, which allows for more targeted and efficient\ntesting. This paper explores the role of AI and ML in software testing by\nreviewing existing literature, analyzing current tools and techniques, and\npresenting case studies that demonstrate the practical benefits of these\ntechnologies. The literature review provides a comprehensive overview of the\nadvancements in AI and ML applications in software testing, highlighting key\nmethodologies and findings from various studies. The analysis of current tools\nshowcases the capabilities of popular AI-driven testing tools such as Eggplant\nAI, Test.ai, Selenium, Appvance, Applitools Eyes, Katalon Studio, and Tricentis\nTosca, each offering unique features and advantages. Case studies included in\nthis paper illustrate real-world applications of AI and ML in software testing,\nshowing significant improvements in testing efficiency, accuracy, and overall\nsoftware quality.",
      "tldr_zh": "这篇论文探讨了 Artificial Intelligence (AI) 和 Machine Learning (ML) 在软件测试中的作用，强调这些技术如何通过自动化测试任务（如测试用例生成、执行和结果分析）来提升效率和缺陷检测准确性。论文通过文献回顾、分析当前工具（如 Eggplant AI、Test.ai 和 Selenium）以及呈现真实案例研究，展示了 AI 和 ML 如何基于历史数据预测潜在故障，并显著改善软件质量。总体而言，这些进展使软件测试从劳动密集型过程转变为更智能化的方法，有助于缩短测试时间并提升可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02693v1",
      "published_date": "2024-09-04 13:25:13 UTC",
      "updated_date": "2024-09-04 13:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:21:17.819726"
    },
    {
      "arxiv_id": "2409.02691v1",
      "title": "LLM-Assisted Visual Analytics: Opportunities and Challenges",
      "title_zh": "LLM辅助的视觉分析：机遇和挑战",
      "authors": [
        "Maeve Hutchinson",
        "Radu Jianu",
        "Aidan Slingsby",
        "Pranava Madhyastha"
      ],
      "abstract": "We explore the integration of large language models (LLMs) into visual\nanalytics (VA) systems to transform their capabilities through intuitive\nnatural language interactions. We survey current research directions in this\nemerging field, examining how LLMs are integrated into data management,\nlanguage interaction, visualisation generation, and language generation\nprocesses. We highlight the new possibilities that LLMs bring to VA, especially\nhow they can change VA processes beyond the usual use cases. We especially\nhighlight building new visualisation-language models, allowing access of a\nbreadth of domain knowledge, multimodal interaction, and opportunities with\nguidance. Finally, we carefully consider the prominent challenges of using\ncurrent LLMs in VA tasks. Our discussions in this paper aim to guide future\nresearchers working on LLM-assisted VA systems and help them navigate common\nobstacles when developing these systems.",
      "tldr_zh": "这篇论文探讨了将大型语言模型（LLMs）整合到视觉分析（VA）系统中的机会和挑战，通过自然语言交互提升VA系统的能力。研究调查了LLMs在数据管理、语言交互、可视化生成和语言生成等过程中的应用，并突出了新可能性，如构建可视化-语言模型、访问领域知识、多模态交互以及提供指导功能。论文强调LLMs能扩展VA的传统用例，但也指出了当前LLMs在VA任务中的突出挑战，包括潜在的局限性。最终，该讨论旨在指导未来研究者开发LLM辅助VA系统，并帮助他们应对常见障碍。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at EG UK Computer Graphics & Visual Computing 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02691v1",
      "published_date": "2024-09-04 13:24:03 UTC",
      "updated_date": "2024-09-04 13:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:21:39.943763"
    },
    {
      "arxiv_id": "2409.02686v2",
      "title": "Deconfounded Causality-aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoyu Wang",
        "Xiaoxuan Li",
        "Lina Yao"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable efficiency in\ntackling various tasks based on human instructions, but studies reveal that\nthey often struggle with tasks requiring reasoning, such as math or physics.\nThis limitation raises questions about whether LLMs truly comprehend embedded\nknowledge or merely learn to replicate the token distribution without a true\nunderstanding of the content. In this paper, we delve into this problem and aim\nto enhance the reasoning capabilities of LLMs. First, we investigate if the\nmodel has genuine reasoning capabilities by visualizing the text generation\nprocess at the attention and representation level. Then, we formulate the\nreasoning process of LLMs into a causal framework, which provides a formal\nexplanation of the problems observed in the visualization. Finally, building\nupon this causal framework, we propose Deconfounded Causal Adaptation (DCA), a\nnovel parameter-efficient fine-tuning (PEFT) method to enhance the model's\nreasoning capabilities by encouraging the model to extract the general\nproblem-solving skills and apply these skills to different questions.\nExperiments show that our method outperforms the baseline consistently across\nmultiple benchmarks, and with only 1.2M tunable parameters, we achieve better\nor comparable results to other fine-tuning methods. This demonstrates the\neffectiveness and efficiency of our method in improving the overall accuracy\nand reliability of LLMs.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在推理任务（如数学或物理问题）上的局限性，可能仅依赖 token 分布而非真正理解知识。作者通过可视化注意力层和表示层分析模型的推理过程，并将其形式化为一个因果框架，以解释这些问题。基于此框架，他们提出 Deconfounded Causal Adaptation (DCA)，一种参数高效微调 (PEFT) 方法，旨在增强 LLMs 的推理能力，鼓励模型提取通用的问题解决技能并应用于不同问题。实验结果显示，DCA 在多个基准上 consistently 优于基线，且仅使用 1.2M 可调参数，就实现了与全微调方法相当或更好的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02686v2",
      "published_date": "2024-09-04 13:17:09 UTC",
      "updated_date": "2024-10-05 11:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:21:42.574730"
    },
    {
      "arxiv_id": "2409.02685v2",
      "title": "RouterRetriever: Routing over a Mixture of Expert Embedding Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunji Lee",
        "Luca Soldaini",
        "Arman Cohan",
        "Minjoon Seo",
        "Kyle Lo"
      ],
      "abstract": "Information retrieval methods often rely on a single embedding model trained\non large, general-domain datasets like MSMARCO. While this approach can produce\na retriever with reasonable overall performance, they often underperform models\ntrained on domain-specific data when testing on their respective domains. Prior\nwork in information retrieval has tackled this through multi-task training, but\nthe idea of routing over a mixture of domain-specific expert retrievers remains\nunexplored despite the popularity of such ideas in language model generation\nresearch. In this work, we introduce RouterRetriever, a retrieval model that\nleverages a mixture of domain-specific experts by using a routing mechanism to\nselect the most appropriate expert for each query. RouterRetriever is\nlightweight and allows easy addition or removal of experts without additional\ntraining. Evaluation on the BEIR benchmark demonstrates that RouterRetriever\noutperforms both models trained on MSMARCO (+2.1 absolute nDCG@10) and\nmulti-task models (+3.2). This is achieved by employing our routing mechanism,\nwhich surpasses other routing techniques (+1.8 on average) commonly used in\nlanguage modeling. Furthermore, the benefit generalizes well to other datasets,\neven in the absence of a specific expert on the dataset. RouterRetriever is the\nfirst work to demonstrate the advantages of routing over a mixture of\ndomain-specific expert embedding models as an alternative to a single,\ngeneral-purpose embedding model, especially when retrieving from diverse,\nspecialized domains.",
      "tldr_zh": "该研究提出 RouterRetriever，一种新型信息检索模型，通过路由机制在混合专家嵌入模型（Mixture of Expert）中选择最适合的领域特定专家，从而解决单一通用模型（如在 MSMARCO 上训练的）在特定领域表现不足的问题。RouterRetriever 设计轻量级，便于动态添加或移除专家，无需额外训练。在 BEIR 基准测试中，该模型超过了 MSMARCO 训练模型（提升 2.1 绝对 nDCG@10）和多任务模型（提升 3.2），其路由机制也优于语言模型中常见技术（平均提升 1.8），并在其他数据集上显示出良好的泛化性，即使缺少特定专家。总的来说，这首次证明了使用混合领域特定专家路由作为单一通用嵌入模型的替代方案，在多样化专用领域中具有显著优势。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "published at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.02685v2",
      "published_date": "2024-09-04 13:16:55 UTC",
      "updated_date": "2025-02-26 06:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:21:55.160813"
    },
    {
      "arxiv_id": "2409.02681v6",
      "title": "Neural Networks with LSTM and GRU in Modeling Active Fires in the Amazon",
      "title_zh": "翻译失败",
      "authors": [
        "Ramon Tavares",
        "Ricardo Olinda"
      ],
      "abstract": "This study presents a comprehensive methodology for modeling and forecasting\nthe historical time series of active fire spots detected by the AQUA\\_M-T\nsatellite in the Amazon, Brazil. The approach employs a mixed Recurrent Neural\nNetwork (RNN) model, combining Long Short-Term Memory (LSTM) and Gated\nRecurrent Unit (GRU) architectures to predict the monthly accumulations of\ndaily detected active fire spots. Data analysis revealed a consistent\nseasonality over time, with annual maximum and minimum values tending to repeat\nat the same periods each year. The primary objective is to verify whether the\nforecasts capture this inherent seasonality through machine learning\ntechniques. The methodology involved careful data preparation, model\nconfiguration, and training using cross-validation with two seeds, ensuring\nthat the data generalizes well to both the test and validation sets for both\nseeds. The results indicate that the combined LSTM and GRU model delivers\nexcellent forecasting performance, demonstrating its effectiveness in capturing\ncomplex temporal patterns and modeling the observed time series. This research\nsignificantly contributes to the application of deep learning techniques in\nenvironmental monitoring, specifically in forecasting active fire spots. The\nproposed approach highlights the potential for adaptation to other time series\nforecasting challenges, opening new opportunities for research and development\nin machine learning and prediction of natural phenomena.\n  Keywords: Time Series Forecasting; Recurrent Neural Networks; Deep Learning.",
      "tldr_zh": "本研究使用结合 Long Short-Term Memory (LSTM) 和 Gated Recurrent Unit (GRU) 的混合 Recurrent Neural Networks (RNN) 模型，来预测和建模亚马逊地区 AQUA_M-T 卫星检测到的活跃火点时间序列。数据分析揭示了稳定的季节性模式，每年最大和最小值在相同时期重复，研究目标是验证模型是否能有效捕捉这些模式。实验通过数据准备、模型配置和交叉验证训练，证明了该混合模型在预测性能上表现出色，能够处理复杂的时间模式。整体贡献在于推进了深度学习技术在环境监测中的应用，特别是活跃火点预测，并为其他时间序列预测挑战提供了可扩展的方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages and 24 figures, in Portuguese language",
      "pdf_url": "http://arxiv.org/pdf/2409.02681v6",
      "published_date": "2024-09-04 13:11:59 UTC",
      "updated_date": "2024-11-01 23:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:22:06.526173"
    },
    {
      "arxiv_id": "2409.02672v2",
      "title": "Independence Constrained Disentangled Representation Learning from Epistemological Perspective",
      "title_zh": "基于认识论视角的独立性约束解耦表示学习",
      "authors": [
        "Ruoyu Wang",
        "Lina Yao"
      ],
      "abstract": "Disentangled Representation Learning aims to improve the explainability of\ndeep learning methods by training a data encoder that identifies semantically\nmeaningful latent variables in the data generation process. Nevertheless, there\nis no consensus regarding a universally accepted definition for the objective\nof disentangled representation learning. In particular, there is a considerable\namount of discourse regarding whether should the latent variables be mutually\nindependent or not. In this paper, we first investigate these arguments on the\ninterrelationships between latent variables by establishing a conceptual bridge\nbetween Epistemology and Disentangled Representation Learning. Then, inspired\nby these interdisciplinary concepts, we introduce a two-level latent space\nframework to provide a general solution to the prior arguments on this issue.\nFinally, we propose a novel method for disentangled representation learning by\nemploying an integration of mutual information constraint and independence\nconstraint within the Generative Adversarial Network (GAN) framework.\nExperimental results demonstrate that our proposed method consistently\noutperforms baseline approaches in both quantitative and qualitative\nevaluations. The method exhibits strong performance across multiple commonly\nused metrics and demonstrates a great capability in disentangling various\nsemantic factors, leading to an improved quality of controllable generation,\nwhich consequently benefits the explainability of the algorithm.",
      "tldr_zh": "本论文从认识论（Epistemology）的视角探讨了 Disentangled Representation Learning 的目标，特别是潜在变量是否应相互独立的问题。通过建立认识论与该领域的概念桥梁，作者引入了一个两级潜在空间框架，以提供一个通用的解决方案。论文提出了一种新方法，在 Generative Adversarial Network (GAN) 框架中整合 mutual information constraint 和 independence constraint，实现更有效的潜在变量解耦。实验结果显示，该方法在定量和定性评估中优于基线模型，提升了语义因素的解耦能力，并显著提高了可控生成质量和算法的可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02672v2",
      "published_date": "2024-09-04 13:00:59 UTC",
      "updated_date": "2024-10-05 11:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:22:16.816806"
    },
    {
      "arxiv_id": "2409.02669v2",
      "title": "Causality-Aware Transformer Networks for Robotic Navigation",
      "title_zh": "因果感知 Transformer 网络用于机器人导航",
      "authors": [
        "Ruoyu Wang",
        "Yao Liu",
        "Yuanjiang Cao",
        "Lina Yao"
      ],
      "abstract": "Current research in Visual Navigation reveals opportunities for improvement.\nFirst, the direct adoption of RNNs and Transformers often overlooks the\nspecific differences between Embodied AI and traditional sequential data\nmodelling, potentially limiting its performance in Embodied AI tasks. Second,\nthe reliance on task-specific configurations, such as pre-trained modules and\ndataset-specific logic, compromises the generalizability of these methods. We\naddress these constraints by initially exploring the unique differences between\nNavigation tasks and other sequential data tasks through the lens of Causality,\npresenting a causal framework to elucidate the inadequacies of conventional\nsequential methods for Navigation. By leveraging this causal perspective, we\npropose Causality-Aware Transformer (CAT) Networks for Navigation, featuring a\nCausal Understanding Module to enhance the models's Environmental Understanding\ncapability. Meanwhile, our method is devoid of task-specific inductive biases\nand can be trained in an End-to-End manner, which enhances the method's\ngeneralizability across various contexts. Empirical evaluations demonstrate\nthat our methodology consistently surpasses benchmark performances across a\nspectrum of settings, tasks and simulation environments. Extensive ablation\nstudies reveal that the performance gains can be attributed to the Causal\nUnderstanding Module, which demonstrates effectiveness and efficiency in both\nReinforcement Learning and Supervised Learning settings.",
      "tldr_zh": "本研究指出，现有的RNNs和Transformers在机器人导航(Embodied AI)任务中直接应用存在局限性，包括忽略任务独特性和依赖任务特定配置导致的泛化性不足。作者通过因果性(Causality)框架分析这些差异，提出Causality-Aware Transformer (CAT) Networks，该方法包括Causal Understanding Module，以增强模型的环境理解能力，并支持端到端训练。实验结果显示，CAT Networks在多种设置、任务和模拟环境中均超越基准性能，消融研究证实了Causal Understanding Module在强化学习和监督学习中的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02669v2",
      "published_date": "2024-09-04 12:53:26 UTC",
      "updated_date": "2024-10-05 11:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:22:30.879557"
    },
    {
      "arxiv_id": "2409.02657v1",
      "title": "PoseTalk: Text-and-Audio-based Pose Control and Motion Refinement for One-Shot Talking Head Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Ling",
        "Yiwen Wang",
        "Han Xue",
        "Rong Xie",
        "Li Song"
      ],
      "abstract": "While previous audio-driven talking head generation (THG) methods generate\nhead poses from driving audio, the generated poses or lips cannot match the\naudio well or are not editable. In this study, we propose \\textbf{PoseTalk}, a\nTHG system that can freely generate lip-synchronized talking head videos with\nfree head poses conditioned on text prompts and audio. The core insight of our\nmethod is using head pose to connect visual, linguistic, and audio signals.\nFirst, we propose to generate poses from both audio and text prompts, where the\naudio offers short-term variations and rhythm correspondence of the head\nmovements and the text prompts describe the long-term semantics of head\nmotions. To achieve this goal, we devise a Pose Latent Diffusion (PLD) model to\ngenerate motion latent from text prompts and audio cues in a pose latent space.\nSecond, we observe a loss-imbalance problem: the loss for the lip region\ncontributes less than 4\\% of the total reconstruction loss caused by both pose\nand lip, making optimization lean towards head movements rather than lip\nshapes. To address this issue, we propose a refinement-based learning strategy\nto synthesize natural talking videos using two cascaded networks, i.e.,\nCoarseNet, and RefineNet. The CoarseNet estimates coarse motions to produce\nanimated images in novel poses and the RefineNet focuses on learning finer lip\nmotions by progressively estimating lip motions from low-to-high resolutions,\nyielding improved lip-synchronization performance. Experiments demonstrate our\npose prediction strategy achieves better pose diversity and realness compared\nto text-only or audio-only, and our video generator model outperforms\nstate-of-the-art methods in synthesizing talking videos with natural head\nmotions. Project: https://junleen.github.io/projects/posetalk.",
      "tldr_zh": "该研究提出PoseTalk系统，用于基于文本提示和音频的单次生成（One-Shot）头部视频生成，允许自由控制头部姿势并提升动作精炼。核心方法包括使用Pose Latent Diffusion (PLD)模型从音频（提供短时变化和节奏）和文本（提供长时语义）生成头部姿势潜在变量，以及采用两级级联网络（CoarseNet生成粗略动作，RefineNet专注于细化唇部动作从低到高分辨率）来解决唇部同步的损失不平衡问题。实验结果显示，PoseTalk在姿势多样性和真实性上优于仅文本或仅音频的方法，其视频生成模型在合成自然头部动作的视频方面也超过了现有THG技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "7+5 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02657v1",
      "published_date": "2024-09-04 12:30:25 UTC",
      "updated_date": "2024-09-04 12:30:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:22:43.372843"
    },
    {
      "arxiv_id": "2409.02649v2",
      "title": "OpenFact at CheckThat! 2024: Combining Multiple Attack Methods for Effective Adversarial Text Generation",
      "title_zh": "OpenFact at CheckThat! ",
      "authors": [
        "Włodzimierz Lewoniewski",
        "Piotr Stolarski",
        "Milena Stróżyna",
        "Elzbieta Lewańska",
        "Aleksandra Wojewoda",
        "Ewelina Księżniak",
        "Marcin Sawiński"
      ],
      "abstract": "This paper presents the experiments and results for the CheckThat! Lab at\nCLEF 2024 Task 6: Robustness of Credibility Assessment with Adversarial\nExamples (InCrediblAE). The primary objective of this task was to generate\nadversarial examples in five problem domains in order to evaluate the\nrobustness of widely used text classification methods (fine-tuned BERT, BiLSTM,\nand RoBERTa) when applied to credibility assessment issues.\n  This study explores the application of ensemble learning to enhance\nadversarial attacks on natural language processing (NLP) models. We\nsystematically tested and refined several adversarial attack methods, including\nBERT-Attack, Genetic algorithms, TextFooler, and CLARE, on five datasets across\nvarious misinformation tasks. By developing modified versions of BERT-Attack\nand hybrid methods, we achieved significant improvements in attack\neffectiveness. Our results demonstrate the potential of modification and\ncombining multiple methods to create more sophisticated and effective\nadversarial attack strategies, contributing to the development of more robust\nand secure systems.",
      "tldr_zh": "本研究参与了 CheckThat! 2024 任务 6（InCrediblAE），旨在通过生成对抗样本来评估 NLP 模型（如 fine-tuned BERT、BiLSTM 和 RoBERTa）在信誉评估领域的鲁棒性。研究者采用 ensemble learning 结合多种攻击方法，包括 BERT-Attack、Genetic algorithms、TextFooler 和 CLARE，并在五个数据集上进行测试和修改。结果显示，通过开发改进版 BERT-Attack 和混合方法，攻击效果显著提升，为构建更鲁棒的 NLP 系统提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CLEF 2024 - Conference and Labs of the Evaluation Forum",
      "pdf_url": "http://arxiv.org/pdf/2409.02649v2",
      "published_date": "2024-09-04 12:26:26 UTC",
      "updated_date": "2024-09-05 06:20:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:22:53.398606"
    },
    {
      "arxiv_id": "2409.02632v1",
      "title": "Evaluating Environments Using Exploratory Agents",
      "title_zh": "利用探索性代理评估环境",
      "authors": [
        "Bobby Khaleque",
        "Mike Cook",
        "Jeremy Gow"
      ],
      "abstract": "Exploration is a key part of many video games. We investigate the using an\nexploratory agent to provide feedback on the design of procedurally generated\ngame levels, 5 engaging levels and 5 unengaging levels. We expand upon a\nframework introduced in previous research which models motivations for\nexploration and introduce a fitness function for evaluating an environment's\npotential for exploration. Our study showed that our exploratory agent can\nclearly distinguish between engaging and unengaging levels. The findings\nsuggest that our agent has the potential to serve as an effective tool for\nassessing procedurally generated levels, in terms of exploration. This work\ncontributes to the growing field of AI-driven game design by offering new\ninsights into how game environments can be evaluated and optimised for player\nexploration.",
      "tldr_zh": "这篇论文探讨了使用 exploratory agents 来评估程序生成游戏关卡的设计，通过测试5个吸引人的和5个不吸引人的关卡。研究扩展了之前的框架，建模探索动机并引入 fitness function 来量化环境的探索潜力。结果表明，exploratory agents 能有效区分不同关卡的吸引力，为 AI-driven game design 提供新工具，帮助优化游戏环境以提升玩家探索体验。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 Pages, 9 figures, 2 tables, work in progress",
      "pdf_url": "http://arxiv.org/pdf/2409.02632v1",
      "published_date": "2024-09-04 11:51:26 UTC",
      "updated_date": "2024-09-04 11:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:23:04.403090"
    },
    {
      "arxiv_id": "2409.02629v1",
      "title": "AdvSecureNet: A Python Toolkit for Adversarial Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Melih Catal",
        "Manuel Günther"
      ],
      "abstract": "Machine learning models are vulnerable to adversarial attacks. Several tools\nhave been developed to research these vulnerabilities, but they often lack\ncomprehensive features and flexibility. We introduce AdvSecureNet, a PyTorch\nbased toolkit for adversarial machine learning that is the first to natively\nsupport multi-GPU setups for attacks, defenses, and evaluation. It is the first\ntoolkit that supports both CLI and API interfaces and external YAML\nconfiguration files to enhance versatility and reproducibility. The toolkit\nincludes multiple attacks, defenses and evaluation metrics. Rigiorous software\nengineering practices are followed to ensure high code quality and\nmaintainability. The project is available as an open-source project on GitHub\nat https://github.com/melihcatal/advsecurenet and installable via PyPI.",
      "tldr_zh": "本研究引入了 AdvSecureNet，一种基于 PyTorch 的 Python 工具包，用于对抗机器学习，旨在解决现有工具在功能和灵活性上的不足。该工具包是首个原生支持多 GPU 设置的框架，同时提供 CLI 和 API 接口，以及外部 YAML 配置文件，以提升实验的可重复性和易用性。AdvSecureNet 包含多种攻击、防御和评估指标，并遵循严格的软件工程实践，确保代码的高质量和可维护性；它已作为开源项目发布在 GitHub，并可通过 PyPI 安装。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02629v1",
      "published_date": "2024-09-04 11:47:00 UTC",
      "updated_date": "2024-09-04 11:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:23:18.695809"
    },
    {
      "arxiv_id": "2409.15299v1",
      "title": "Irrelevant Alternatives Bias Large Language Model Hiring Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Kremena Valkanova",
        "Pencho Yordanov"
      ],
      "abstract": "We investigate whether LLMs display a well-known human cognitive bias, the\nattraction effect, in hiring decisions. The attraction effect occurs when the\npresence of an inferior candidate makes a superior candidate more appealing,\nincreasing the likelihood of the superior candidate being chosen over a\nnon-dominated competitor. Our study finds consistent and significant evidence\nof the attraction effect in GPT-3.5 and GPT-4 when they assume the role of a\nrecruiter. Irrelevant attributes of the decoy, such as its gender, further\namplify the observed bias. GPT-4 exhibits greater bias variation than GPT-3.5.\nOur findings remain robust even when warnings against the decoy effect are\nincluded and the recruiter role definition is varied.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）如GPT-3.5和GPT-4在招聘决策中是否表现出attraction effect（吸引效应），即劣势候选人（decoy）的存在会使优势候选人更具吸引力，从而增加其被选中的概率。结果显示，LLMs在扮演招聘者角色时 consistently 表现出显著的attraction effect，且decoy的无关属性（如性别）会进一步放大这一偏差，GPT-4的偏差变化比GPT-3.5更大。即使加入警告或改变角色定义，该效应依然稳健。这揭示了LLMs在决策中的认知偏差，强调了改进模型公平性的必要性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.15299v1",
      "published_date": "2024-09-04 10:37:36 UTC",
      "updated_date": "2024-09-04 10:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:23:31.368788"
    },
    {
      "arxiv_id": "2409.02598v1",
      "title": "SurgTrack: CAD-Free 3D Tracking of Real-world Surgical Instruments",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwu Guo",
        "Jinlin Wu",
        "Zhen Chen",
        "Qingxiang Zhao",
        "Miao Xu",
        "Zhen Lei",
        "Hongbin Liu"
      ],
      "abstract": "Vision-based surgical navigation has received increasing attention due to its\nnon-invasive, cost-effective, and flexible advantages. In particular, a\ncritical element of the vision-based navigation system is tracking surgical\ninstruments. Compared with 2D instrument tracking methods, 3D instrument\ntracking has broader value in clinical practice, but is also more challenging\ndue to weak texture, occlusion, and lack of Computer-Aided Design (CAD) models\nfor 3D registration. To solve these challenges, we propose the SurgTrack, a\ntwo-stage 3D instrument tracking method for CAD-free and robust real-world\napplications. In the first registration stage, we incorporate an Instrument\nSigned Distance Field (SDF) modeling the 3D representation of instruments,\nachieving CAD-freed 3D registration. Due to this, we can obtain the location\nand orientation of instruments in the 3D space by matching the video stream\nwith the registered SDF model. In the second tracking stage, we devise a\nposture graph optimization module, leveraging the historical tracking results\nof the posture memory pool to optimize the tracking results and improve the\nocclusion robustness. Furthermore, we collect the Instrument3D dataset to\ncomprehensively evaluate the 3D tracking of surgical instruments. The extensive\nexperiments validate the superiority and scalability of our SurgTrack, by\noutperforming the state-of-the-arts with a remarkable improvement. The code and\ndataset are available at https://github.com/wenwucode/SurgTrack.",
      "tldr_zh": "该研究提出SurgTrack，一种无CAD模型的3D手术器械跟踪方法，旨在解决视觉-based手术导航中的弱纹理、遮挡和缺乏CAD模型等挑战。该方法采用两阶段设计：第一阶段利用Instrument Signed Distance Field (SDF)建模3D器械表示，通过匹配视频流实现CAD-free的3D注册；第二阶段引入姿态图优化模块，利用历史跟踪结果提升遮挡鲁棒性。实验在自收集的Instrument3D数据集上验证了SurgTrack的优越性，比现有方法有显著改进，并公开了代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02598v1",
      "published_date": "2024-09-04 10:29:59 UTC",
      "updated_date": "2024-09-04 10:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:23:44.425951"
    },
    {
      "arxiv_id": "2409.02580v1",
      "title": "AlignGroup: Learning and Aligning Group Consensus with Member Preferences for Group Recommendation",
      "title_zh": "Align",
      "authors": [
        "Jinfeng Xu",
        "Zheyu Chen",
        "Jinze Li",
        "Shuo Yang",
        "Hewei Wang",
        "Edith C. -H. Ngai"
      ],
      "abstract": "Group activities are important behaviors in human society, providing\npersonalized recommendations for groups is referred to as the group\nrecommendation task. Existing methods can usually be categorized into two\nstrategies to infer group preferences: 1) determining group preferences by\naggregating members' personalized preferences, and 2) inferring group consensus\nby capturing group members' coherent decisions after common compromises.\nHowever, the former would suffer from the lack of group-level considerations,\nand the latter overlooks the fine-grained preferences of individual users. To\nthis end, we propose a novel group recommendation method AlignGroup, which\nfocuses on both group consensus and individual preferences of group members to\ninfer the group decision-making. Specifically, AlignGroup explores group\nconsensus through a well-designed hypergraph neural network that efficiently\nlearns intra- and inter-group relationships. Moreover, AlignGroup innovatively\nutilizes a self-supervised alignment task to capture fine-grained group\ndecision-making by aligning the group consensus with members' common\npreferences. Extensive experiments on two real-world datasets validate that our\nAlignGroup outperforms the state-of-the-art on both the group recommendation\ntask and the user recommendation task, as well as outperforms the efficiency of\nmost baselines.",
      "tldr_zh": "本文提出 AlignGroup，一种新型群组推荐方法，旨在同时考虑群组共识和成员的个体偏好，以解决现有方法的局限性，如忽略群组级考虑或细粒度用户偏好。AlignGroup 利用精心设计的 hypergraph neural network 来学习 intra- 和 inter-group 关系，并通过 self-supervised alignment task 将群组共识与成员的共同偏好对齐，从而实现更精确的群组决策。实验在两个真实数据集上表明，AlignGroup 在群组推荐和用户推荐任务上优于最先进基线，并在效率上表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages, accepted by CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02580v1",
      "published_date": "2024-09-04 10:03:09 UTC",
      "updated_date": "2024-09-04 10:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:23:57.811858"
    },
    {
      "arxiv_id": "2409.09063v1",
      "title": "TS-EoH: An Edge Server Task Scheduling Algorithm Based on Evolution of Heuristic",
      "title_zh": "翻译失败",
      "authors": [
        "Wang Yatong",
        "Pei Yuchen",
        "Zhao Yuqi"
      ],
      "abstract": "With the widespread adoption of 5G and Internet of Things (IoT) technologies,\nthe low latency provided by edge computing has great importance for real-time\nprocessing. However, managing numerous simultaneous service requests poses a\nsignificant challenge to maintaining low latency. Current edge server task\nscheduling methods often fail to balance multiple optimization goals\neffectively. This paper introduces a novel task-scheduling approach based on\nEvolutionary Computing (EC) theory and heuristic algorithms. We model service\nrequests as task sequences and evaluate various scheduling schemes during each\nevolutionary process using Large Language Models (LLMs) services. Experimental\nresults show that our task-scheduling algorithm outperforms existing heuristic\nand traditional reinforcement learning methods. Additionally, we investigate\nthe effects of different heuristic strategies and compare the evolutionary\noutcomes across various LLM services.",
      "tldr_zh": "这篇论文针对边缘计算中处理大量服务请求的低延迟挑战，提出了一种名为 TS-EoH 的任务调度算法，该算法基于 Evolutionary Computing (EC) 理论和启发式算法，将服务请求建模为任务序列，并利用 Large Language Models (LLMs) 服务在进化过程中评估调度方案。实验结果显示，TS-EoH 优于现有的启发式和传统强化学习方法，在多目标优化方面表现出色。此外，论文还探讨了不同启发式策略和各种 LLM 服务对演化结果的影响。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09063v1",
      "published_date": "2024-09-04 10:00:32 UTC",
      "updated_date": "2024-09-04 10:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:24:07.606117"
    },
    {
      "arxiv_id": "2409.11414v1",
      "title": "RTLRewriter: Methodologies for Large Models aided RTL Code Optimization",
      "title_zh": "RTLRewriter：大型模型辅助 RTL 代码优化的方法论",
      "authors": [
        "Xufeng Yao",
        "Yiwen Wang",
        "Xing Li",
        "Yingzhao Lian",
        "Ran Chen",
        "Lei Chen",
        "Mingxuan Yuan",
        "Hong Xu",
        "Bei Yu"
      ],
      "abstract": "Register Transfer Level (RTL) code optimization is crucial for enhancing the\nefficiency and performance of digital circuits during early synthesis stages.\nCurrently, optimization relies heavily on manual efforts by skilled engineers,\noften requiring multiple iterations based on synthesis feedback. In contrast,\nexisting compiler-based methods fall short in addressing complex designs. This\npaper introduces RTLRewriter, an innovative framework that leverages large\nmodels to optimize RTL code. A circuit partition pipeline is utilized for fast\nsynthesis and efficient rewriting. A multi-modal program analysis is proposed\nto incorporate vital visual diagram information as optimization cues. A\nspecialized search engine is designed to identify useful optimization guides,\nalgorithms, and code snippets that enhance the model ability to generate\noptimized RTL. Additionally, we introduce a Cost-aware Monte Carlo Tree Search\n(C-MCTS) algorithm for efficient rewriting, managing diverse retrieved contents\nand steering the rewriting results. Furthermore, a fast verification pipeline\nis proposed to reduce verification cost. To cater to the needs of both industry\nand academia, we propose two benchmarking suites: the Large Rewriter Benchmark,\ntargeting complex scenarios with extensive circuit partitioning, optimization\ntrade-offs, and verification challenges, and the Small Rewriter Benchmark,\ndesigned for a wider range of scenarios and patterns. Our comparative analysis\nwith established compilers such as Yosys and E-graph demonstrates significant\nimprovements, highlighting the benefits of integrating large models into the\nearly stages of circuit design. We provide our benchmarks at\nhttps://github.com/yaoxufeng/RTLRewriter-Bench.",
      "tldr_zh": "本论文引入了 RTLRewriter 框架，利用大型模型（Large Models）辅助 RTL 代码优化，以解决传统手动优化和编译器不足的问题。该框架包括电路分区管道（Circuit partition pipeline）、多模态程序分析（Multi-modal program analysis）整合视觉图信息、专用搜索引擎获取优化指导，以及 Cost-aware Monte Carlo Tree Search (C-MCTS) 算法进行高效重写和快速验证管道降低成本。论文提出两个基准测试套件——Large Rewriter Benchmark 和 Small Rewriter Benchmark，并通过与 Yosys 和 E-graph 等编译器的比较，展示了显著性能提升，为电路设计早期阶段的优化提供了新方法。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AR",
      "comment": "ICCAD2024",
      "pdf_url": "http://arxiv.org/pdf/2409.11414v1",
      "published_date": "2024-09-04 09:59:37 UTC",
      "updated_date": "2024-09-04 09:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:24:19.903006"
    },
    {
      "arxiv_id": "2409.02574v3",
      "title": "Solving Video Inverse Problems Using Image Diffusion Models",
      "title_zh": "使用图像扩散模型解决视频逆问题",
      "authors": [
        "Taesung Kwon",
        "Jong Chul Ye"
      ],
      "abstract": "Recently, diffusion model-based inverse problem solvers (DIS) have emerged as\nstate-of-the-art approaches for addressing inverse problems, including image\nsuper-resolution, deblurring, inpainting, etc. However, their application to\nvideo inverse problems arising from spatio-temporal degradation remains largely\nunexplored due to the challenges in training video diffusion models. To address\nthis issue, here we introduce an innovative video inverse solver that leverages\nonly image diffusion models. Specifically, by drawing inspiration from the\nsuccess of the recent decomposed diffusion sampler (DDS), our method treats the\ntime dimension of a video as the batch dimension of image diffusion models and\nsolves spatio-temporal optimization problems within denoised spatio-temporal\nbatches derived from each image diffusion model. Moreover, we introduce a\nbatch-consistent diffusion sampling strategy that encourages consistency across\nbatches by synchronizing the stochastic noise components in image diffusion\nmodels. Our approach synergistically combines batch-consistent sampling with\nsimultaneous optimization of denoised spatio-temporal batches at each reverse\ndiffusion step, resulting in a novel and efficient diffusion sampling strategy\nfor video inverse problems. Experimental results demonstrate that our method\neffectively addresses various spatio-temporal degradations in video inverse\nproblems, achieving state-of-the-art reconstructions. Project page:\nhttps://svi-diffusion.github.io/",
      "tldr_zh": "这篇论文提出了一种创新方法，使用图像扩散模型（image diffusion models）来解决视频逆问题（video inverse problems），从而避免了训练视频扩散模型的挑战。方法将视频的时间维度视为图像扩散模型的批量维度，并引入 decomposed diffusion sampler (DDS) 灵感，结合 batch-consistent diffusion sampling 策略，通过同步随机噪声组件和同时优化去噪时空批量，实现高效的时空优化。实验结果显示，该方法在处理各种时空退化（spatio-temporal degradation）问题时，取得了 state-of-the-art 的重建效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025; 25 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02574v3",
      "published_date": "2024-09-04 09:48:27 UTC",
      "updated_date": "2025-02-27 09:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:24:31.822845"
    },
    {
      "arxiv_id": "2409.02572v4",
      "title": "GenDFIR: Advancing Cyber Incident Timeline Analysis Through Retrieval Augmented Generation and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fatma Yasmine Loumachi",
        "Mohamed Chahine Ghanem",
        "Mohamed Amine Ferrag"
      ],
      "abstract": "Cyber timeline analysis, or forensic timeline analysis, is crucial in Digital\nForensics and Incident Response (DFIR). It examines artefacts and events\nparticularly timestamps and metadata to detect anomalies, establish\ncorrelations, and reconstruct incident timelines. Traditional methods rely on\nstructured artefacts, such as logs and filesystem metadata, using specialised\ntools for evidence identification and feature extraction. This paper introduces\nGenDFIR, a framework leveraging large language models (LLMs), specifically\nLlama 3.1 8B in zero shot mode, integrated with a Retrieval-Augmented\nGeneration (RAG) agent. Incident data is preprocessed into a structured\nknowledge base, enabling the RAG agent to retrieve relevant events based on\nuser prompts. The LLM interprets this context, offering semantic enrichment.\nTested on synthetic data in a controlled environment, results demonstrate\nGenDFIR's reliability and robustness, showcasing LLMs potential to automate\ntimeline analysis and advance threat detection.",
      "tldr_zh": "该论文提出 GenDFIR 框架，通过结合大型语言模型（LLMs）和检索增强生成（RAG）技术，推进数字取证和事件响应（DFIR）中的网络事件时间线分析。框架使用 Llama 3.1 8B 在零样本模式下，将事件数据预处理成结构化知识库，并通过 RAG 代理检索相关事件，LLMs 则提供语义解释和丰富。测试结果显示，GenDFIR 在受控合成数据环境中表现出色，提高了时间线分析的自动化和威胁检测潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "24 pages V5.3",
      "pdf_url": "http://arxiv.org/pdf/2409.02572v4",
      "published_date": "2024-09-04 09:46:33 UTC",
      "updated_date": "2024-12-27 13:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:24:43.226818"
    },
    {
      "arxiv_id": "2409.02569v1",
      "title": "More is More: Addition Bias in Large Language Models",
      "title_zh": "多多益善：大语言模型中的添加偏见",
      "authors": [
        "Luca Santagata",
        "Cristiano De Nobili"
      ],
      "abstract": "In this paper, we investigate the presence of additive bias in Large Language\nModels (LLMs), drawing a parallel to the cognitive bias observed in humans\nwhere individuals tend to favor additive over subtractive changes. Using a\nseries of controlled experiments, we tested various LLMs, including GPT-3.5\nTurbo, Claude 3.5 Sonnet, Mistral, Math$\\Sigma$tral, and Llama 3.1, on tasks\ndesigned to measure their propensity for additive versus subtractive\nmodifications. Our findings demonstrate a significant preference for additive\nchanges across all tested models. For example, in a palindrome creation task,\nLlama 3.1 favored adding letters 97.85% of the time over removing them.\nSimilarly, in a Lego tower balancing task, GPT-3.5 Turbo chose to add a brick\n76.38% of the time rather than remove one. In a text summarization task,\nMistral 7B produced longer summaries in 59.40% to 75.10% of cases when asked to\nimprove its own or others' writing. These results indicate that, similar to\nhumans, LLMs exhibit a marked additive bias, which might have implications when\nLLMs are used on a large scale. Addittive bias might increase resource use and\nenvironmental impact, leading to higher economic costs due to overconsumption\nand waste. This bias should be considered in the development and application of\nLLMs to ensure balanced and efficient problem-solving approaches.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）中存在的addition bias，即倾向于选择加法修改而非减法修改，类似于人类的认知偏见。研究者通过控制实验测试了包括GPT-3.5 Turbo、Claude 3.5 Sonnet、Mistral、MathΣtral和Llama 3.1在内的多种LLMs，在任务如创建回文、平衡乐高塔和文本总结中评估它们的偏见。结果显示，所有模型均表现出显著的addition bias，例如Llama 3.1在97.85%的回文任务中选择添加字母，而GPT-3.5 Turbo在76.38%的乐高塔任务中偏好添加砖块。论文强调，这种偏见可能导致资源浪费、环境影响和经济成本增加，建议在LLMs的开发和应用中考虑这一问题以实现更平衡的决策。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02569v1",
      "published_date": "2024-09-04 09:39:07 UTC",
      "updated_date": "2024-09-04 09:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:24:56.737863"
    },
    {
      "arxiv_id": "2409.02561v2",
      "title": "Vision-Language Navigation with Continual Learning",
      "title_zh": "视觉语言导航与持续学习",
      "authors": [
        "Zhiyuan Li",
        "Yanfeng Lv",
        "Ziqin Tu",
        "Di Shang",
        "Hong Qiao"
      ],
      "abstract": "Vision-language navigation (VLN) is a critical domain within embedded\nintelligence, requiring agents to navigate 3D environments based on natural\nlanguage instructions. Traditional VLN research has focused on improving\nenvironmental understanding and decision accuracy. However, these approaches\noften exhibit a significant performance gap when agents are deployed in novel\nenvironments, mainly due to the limited diversity of training data. Expanding\ndatasets to cover a broader range of environments is impractical and costly. We\npropose the Vision-Language Navigation with Continual Learning (VLNCL) paradigm\nto address this challenge. In this paradigm, agents incrementally learn new\nenvironments while retaining previously acquired knowledge. VLNCL enables\nagents to maintain an environmental memory and extract relevant knowledge,\nallowing rapid adaptation to new environments while preserving existing\ninformation. We introduce a novel dual-loop scenario replay method (Dual-SR)\ninspired by brain memory replay mechanisms integrated with VLN agents. This\nmethod facilitates consolidating past experiences and enhances generalization\nacross new tasks. By utilizing a multi-scenario memory buffer, the agent\nefficiently organizes and replays task memories, thereby bolstering its ability\nto adapt quickly to new environments and mitigating catastrophic forgetting.\nOur work pioneers continual learning in VLN agents, introducing a novel\nexperimental setup and evaluation metrics. We demonstrate the effectiveness of\nour approach through extensive evaluations and establish a benchmark for the\nVLNCL paradigm. Comparative experiments with existing continual learning and\nVLN methods show significant improvements, achieving state-of-the-art\nperformance in continual learning ability and highlighting the potential of our\napproach in enabling rapid adaptation while preserving prior knowledge.",
      "tldr_zh": "本研究针对视觉语言导航（Vision-Language Navigation, VLN）中的问题，提出了一种结合持续学习（Continual Learning）的范式，即VLNCL，以帮助代理在学习新环境的同时保留先前知识，从而解决传统方法在新环境下的性能下降问题。VLNCL引入了新型双循环场景重放方法（Dual-SR），灵感来源于大脑记忆机制，通过多场景记忆缓冲区组织和重放任务记忆，巩固过去经验、增强泛化能力，并缓解灾难性遗忘（catastrophic forgetting）。实验结果显示，该方法在持续学习能力和快速适应性上显著优于现有方法，建立了VLNCL的基准，并证明了其在VLN代理中的潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02561v2",
      "published_date": "2024-09-04 09:28:48 UTC",
      "updated_date": "2024-09-23 03:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:25:06.772765"
    },
    {
      "arxiv_id": "2409.03795v1",
      "title": "Security Implications and Mitigation Strategies in MPLS Networks",
      "title_zh": "MPLS 网络中的安全影响及缓解策略",
      "authors": [
        "Ayush Thakur"
      ],
      "abstract": "Multiprotocol Label Switching (MPLS) is a high-performance telecommunications\ntechnology that directs data from one network node to another based on short\npath labels rather than long network addresses. Its efficiency and scalability\nhave made it a popular choice for large-scale and enterprise networks. However,\nas MPLS networks grow and evolve, they encounter various security challenges.\nThis paper explores the security implications associated with MPLS networks,\nincluding risks such as label spoofing, traffic interception, and denial of\nservice attacks. Additionally, it evaluates advanced mitigation strategies to\naddress these vulnerabilities, leveraging mathematical models and security\nprotocols to enhance MPLS network resilience. By integrating theoretical\nanalysis with practical solutions, this paper aims to provide a comprehensive\nunderstanding of MPLS security and propose effective methods for safeguarding\nnetwork infrastructure.",
      "tldr_zh": "这篇论文探讨了多协议标签交换（MPLS）网络的安全风险，包括 label spoofing、traffic interception 和 denial of service attacks 等挑战，这些问题在大型企业和网络环境中日益突出。论文评估了高级缓解策略，通过数学模型和安全协议来增强网络弹性，并结合理论分析与实际解决方案。最终，该研究为保护 MPLS 网络基础设施提供了全面的理解和有效防护方法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.03795v1",
      "published_date": "2024-09-04 09:21:47 UTC",
      "updated_date": "2024-09-04 09:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:25:19.848125"
    },
    {
      "arxiv_id": "2409.02555v1",
      "title": "Low-Resolution Object Recognition with Cross-Resolution Relational Contrastive Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Kangkai Zhang",
        "Shiming Ge",
        "Ruixin Shi",
        "Dan Zeng"
      ],
      "abstract": "Recognizing objects in low-resolution images is a challenging task due to the\nlack of informative details. Recent studies have shown that knowledge\ndistillation approaches can effectively transfer knowledge from a\nhigh-resolution teacher model to a low-resolution student model by aligning\ncross-resolution representations. However, these approaches still face\nlimitations in adapting to the situation where the recognized objects exhibit\nsignificant representation discrepancies between training and testing images.\nIn this study, we propose a cross-resolution relational contrastive\ndistillation approach to facilitate low-resolution object recognition. Our\napproach enables the student model to mimic the behavior of a well-trained\nteacher model which delivers high accuracy in identifying high-resolution\nobjects. To extract sufficient knowledge, the student learning is supervised\nwith contrastive relational distillation loss, which preserves the similarities\nin various relational structures in contrastive representation space. In this\nmanner, the capability of recovering missing details of familiar low-resolution\nobjects can be effectively enhanced, leading to a better knowledge transfer.\nExtensive experiments on low-resolution object classification and\nlow-resolution face recognition clearly demonstrate the effectiveness and\nadaptability of our approach.",
      "tldr_zh": "该论文针对低分辨率图像中物体识别的挑战，提出了一种跨分辨率关系对比蒸馏（cross-resolution relational contrastive distillation）方法，以解决现有知识蒸馏（knowledge distillation）方法在训练和测试图像表示差异方面的局限性。该方法通过对比关系蒸馏损失（contrastive relational distillation loss）监督学生模型，保留对比表示空间中的各种关系结构，从而增强学生模型恢复低分辨率物体细节的能力。实验结果显示，该方法在低分辨率物体分类和面部识别任务上表现出色，证明了其有效性和适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted by IEEE Transactions on Circuits and Systems\n  for Video Technology (TCSVT)",
      "pdf_url": "http://arxiv.org/pdf/2409.02555v1",
      "published_date": "2024-09-04 09:21:13 UTC",
      "updated_date": "2024-09-04 09:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:25:33.974090"
    },
    {
      "arxiv_id": "2409.02549v2",
      "title": "A Sequential Decision-Making Model for Perimeter Identification",
      "title_zh": "一种用于周界识别的顺序决策模型",
      "authors": [
        "Ayal Taitler"
      ],
      "abstract": "Perimeter identification involves ascertaining the boundaries of a designated\narea or zone, requiring traffic flow monitoring, control, or optimization.\nVarious methodologies and technologies exist for accurately defining these\nperimeters; however, they often necessitate specialized equipment, precise\nmapping, or comprehensive data for effective problem delineation. In this\nstudy, we propose a sequential decision-making framework for perimeter search,\ndesigned to operate efficiently in real-time and require only publicly\naccessible information. We conceptualize the perimeter search as a game between\na playing agent and an artificial environment, where the agent's objective is\nto identify the optimal perimeter by sequentially improving the current\nperimeter. We detail the model for the game and discuss its adaptability in\ndetermining the definition of an optimal perimeter. Ultimately, we showcase the\nmodel's efficacy through a real-world scenario, highlighting the identification\nof corresponding optimal perimeters.",
      "tldr_zh": "本研究针对周界识别（perimeter identification）的挑战，提出了一种顺序决策模型（sequential decision-making model），旨在通过公开可访问的信息实现高效实时操作，而非依赖专业设备或精确映射。\n该模型将周界搜索概念化为代理与环境之间的游戏，代理的目标是通过顺序改进当前周界来识别最优周界，并讨论了其适应性。\n实验结果通过真实场景证明，该模型在周界定义和优化方面表现出色，展示了其实用价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02549v2",
      "published_date": "2024-09-04 09:11:39 UTC",
      "updated_date": "2024-09-05 06:58:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:25:45.090613"
    },
    {
      "arxiv_id": "2409.02530v1",
      "title": "Understanding eGFR Trajectories and Kidney Function Decline via Large Multimodal Models",
      "title_zh": "通过大型多模态模型理解 eGFR 轨迹和肾功能衰退",
      "authors": [
        "Chih-Yuan Li",
        "Jun-Ting Wu",
        "Chan Hsu",
        "Ming-Yen Lin",
        "Yihuang Kang"
      ],
      "abstract": "The estimated Glomerular Filtration Rate (eGFR) is an essential indicator of\nkidney function in clinical practice. Although traditional equations and\nMachine Learning (ML) models using clinical and laboratory data can estimate\neGFR, accurately predicting future eGFR levels remains a significant challenge\nfor nephrologists and ML researchers. Recent advances demonstrate that Large\nLanguage Models (LLMs) and Large Multimodal Models (LMMs) can serve as robust\nfoundation models for diverse applications. This study investigates the\npotential of LMMs to predict future eGFR levels with a dataset consisting of\nlaboratory and clinical values from 50 patients. By integrating various\nprompting techniques and ensembles of LMMs, our findings suggest that these\nmodels, when combined with precise prompts and visual representations of eGFR\ntrajectories, offer predictive performance comparable to existing ML models.\nThis research extends the application of foundation models and suggests avenues\nfor future studies to harness these models in addressing complex medical\nforecasting challenges.",
      "tldr_zh": "这篇论文探讨了使用 Large Multimodal Models (LMMs) 来理解和预测 eGFR 轨迹及肾功能下降问题，以解决传统方程和 Machine Learning (ML) 模型在准确预测未来 eGFR 水平上的挑战。研究利用来自 50 名患者的实验室和临床数据，通过整合各种提示技巧以及 LMMs 的集成方法，实现了与现有 ML 模型相当的预测性能，并利用视觉表示增强模型效果。主要贡献在于扩展了基础模型在复杂医疗预测中的应用，为未来研究提供新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint version includes corrections of typographical errors\n  related to numerical values in Table 2, which were present in the version\n  published at the BDH workshop in MIPR 2024. These corrections do not affect\n  the overall conclusions of the study",
      "pdf_url": "http://arxiv.org/pdf/2409.02530v1",
      "published_date": "2024-09-04 08:44:36 UTC",
      "updated_date": "2024-09-04 08:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:25:56.751632"
    },
    {
      "arxiv_id": "2409.02522v2",
      "title": "Cog-GA: A Large Language Models-based Generative Agent for Vision-Language Navigation in Continuous Environments",
      "title_zh": "Cog-GA：基于大型语言模型的生成式代理，用于连续环境中的视觉-语言导航",
      "authors": [
        "Zhiyuan Li",
        "Yanfeng Lu",
        "Yao Mu",
        "Hong Qiao"
      ],
      "abstract": "Vision Language Navigation in Continuous Environments (VLN-CE) represents a\nfrontier in embodied AI, demanding agents to navigate freely in unbounded 3D\nspaces solely guided by natural language instructions. This task introduces\ndistinct challenges in multimodal comprehension, spatial reasoning, and\ndecision-making. To address these challenges, we introduce Cog-GA, a generative\nagent founded on large language models (LLMs) tailored for VLN-CE tasks. Cog-GA\nemploys a dual-pronged strategy to emulate human-like cognitive processes.\nFirstly, it constructs a cognitive map, integrating temporal, spatial, and\nsemantic elements, thereby facilitating the development of spatial memory\nwithin LLMs. Secondly, Cog-GA employs a predictive mechanism for waypoints,\nstrategically optimizing the exploration trajectory to maximize navigational\nefficiency. Each waypoint is accompanied by a dual-channel scene description,\ncategorizing environmental cues into 'what' and 'where' streams as the brain.\nThis segregation enhances the agent's attentional focus, enabling it to discern\npertinent spatial information for navigation. A reflective mechanism\ncomplements these strategies by capturing feedback from prior navigation\nexperiences, facilitating continual learning and adaptive replanning. Extensive\nevaluations conducted on VLN-CE benchmarks validate Cog-GA's state-of-the-art\nperformance and ability to simulate human-like navigation behaviors. This\nresearch significantly contributes to the development of strategic and\ninterpretable VLN-CE agents.",
      "tldr_zh": "该研究针对Vision Language Navigation in Continuous Environments (VLN-CE)任务提出Cog-GA，一种基于Large Language Models (LLMs)的生成代理，帮助代理在无界3D空间中通过自然语言指令进行导航。Cog-GA采用双重策略，包括构建整合时间、空间和语义的cognitive map以增强空间记忆，以及预测waypoints优化探索轨迹，并通过双通道场景描述（'what'和'where'流）和反射机制实现注意力聚焦和持续学习。实验在VLN-CE基准上验证了Cog-GA的state-of-the-art性能，并展示了其模拟人类-like导航行为的潜力，为战略性和可解释的导航代理发展做出了重要贡献。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02522v2",
      "published_date": "2024-09-04 08:30:03 UTC",
      "updated_date": "2024-09-23 03:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:26:09.877209"
    },
    {
      "arxiv_id": "2409.02512v2",
      "title": "Continual Diffuser (CoD): Mastering Continual Offline Reinforcement Learning with Experience Rehearsal",
      "title_zh": "翻译失败",
      "authors": [
        "Jifeng Hu",
        "Li Shen",
        "Sili Huang",
        "Zhejian Yang",
        "Hechang Chen",
        "Lichao Sun",
        "Yi Chang",
        "Dacheng Tao"
      ],
      "abstract": "Artificial neural networks, especially recent diffusion-based models, have\nshown remarkable superiority in gaming, control, and QA systems, where the\ntraining tasks' datasets are usually static. However, in real-world\napplications, such as robotic control of reinforcement learning (RL), the tasks\nare changing, and new tasks arise in a sequential order. This situation poses\nthe new challenge of plasticity-stability trade-off for training an agent who\ncan adapt to task changes and retain acquired knowledge. In view of this, we\npropose a rehearsal-based continual diffusion model, called Continual Diffuser\n(CoD), to endow the diffuser with the capabilities of quick adaptation\n(plasticity) and lasting retention (stability). Specifically, we first\nconstruct an offline benchmark that contains 90 tasks from multiple domains.\nThen, we train the CoD on each task with sequential modeling and conditional\ngeneration for making decisions. Next, we preserve a small portion of previous\ndatasets as the rehearsal buffer and replay it to retain the acquired\nknowledge. Extensive experiments on a series of tasks show CoD can achieve a\npromising plasticity-stability trade-off and outperform existing\ndiffusion-based methods and other representative baselines on most tasks.",
      "tldr_zh": "该论文提出Continual Diffuser (CoD)，一种基于经验排练的持续离线强化学习框架，旨在解决任务动态变化时神经网络的塑性-稳定性权衡问题，即实现快速适应新任务的同时保留旧知识。CoD 通过构建一个包含90个多领域任务的离线基准，使用顺序建模和条件生成进行决策，并通过保留部分历史数据集作为排练缓冲区进行回放来维持模型性能。实验结果显示，CoD 在一系列任务上表现出色的塑性-稳定性权衡，并优于现有扩散模型和其他基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2409.02512v2",
      "published_date": "2024-09-04 08:21:47 UTC",
      "updated_date": "2025-01-15 03:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:26:21.234255"
    },
    {
      "arxiv_id": "2409.07486v2",
      "title": "MarS: a Financial Market Simulation Engine Powered by Generative Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Li",
        "Yang Liu",
        "Weiqing Liu",
        "Shikai Fang",
        "Lewen Wang",
        "Chang Xu",
        "Jiang Bian"
      ],
      "abstract": "Generative models aim to simulate realistic effects of various actions across\ndifferent contexts, from text generation to visual effects. Despite significant\nefforts to build real-world simulators, the application of generative models to\nvirtual worlds, like financial markets, remains under-explored. In financial\nmarkets, generative models can simulate complex market effects of participants\nwith various behaviors, enabling interaction under different market conditions,\nand training strategies without financial risk. This simulation relies on the\nfinest structured data in financial market like orders thus building the finest\nrealistic simulation. We propose Large Market Model (LMM), an order-level\ngenerative foundation model, for financial market simulation, akin to language\nmodeling in the digital world. Our financial Market Simulation engine (MarS),\npowered by LMM, addresses the domain-specific need for realistic, interactive\nand controllable order generation. Key observations include LMM's strong\nscalability across data size and model complexity, and MarS's robust and\npracticable realism in controlled generation with market impact. We showcase\nMarS as a forecast tool, detection system, analysis platform, and agent\ntraining environment, thus demonstrating MarS's \"paradigm shift\" potential for\na variety of financial applications. We release the code of MarS at\nhttps://github.com/microsoft/MarS/.",
      "tldr_zh": "本研究提出Large Market Model (LMM)，一个基于订单级的生成基础模型，用于模拟金融市场的复杂行为，类似于语言模型的应用。该模型驱动的MarS引擎（Financial Market Simulation Engine）能够生成真实、可交互和可控的订单序列，支持在不同市场条件下进行策略训练，而无需实际金融风险。关键发现包括LMM在数据规模和模型复杂度上的强扩展性，以及MarS在受控生成中的稳健真实性；实验展示了MarS作为预测工具、检测系统、分析平台和代理训练环境的潜力，标志着金融应用领域的“范式转变”。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "q-fin.TR"
      ],
      "primary_category": "q-fin.CP",
      "comment": "35 pages, 26 figures, ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.07486v2",
      "published_date": "2024-09-04 08:16:22 UTC",
      "updated_date": "2025-03-13 09:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:26:32.232430"
    },
    {
      "arxiv_id": "2409.02495v1",
      "title": "CoAst: Validation-Free Contribution Assessment for Federated Learning based on Cross-Round Valuation",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wu",
        "Likun Zhang",
        "Shucheng Li",
        "Fengyuan Xu",
        "Sheng Zhong"
      ],
      "abstract": "In the federated learning (FL) process, since the data held by each\nparticipant is different, it is necessary to figure out which participant has a\nhigher contribution to the model performance. Effective contribution assessment\ncan help motivate data owners to participate in the FL training. Research works\nin this field can be divided into two directions based on whether a validation\ndataset is required. Validation-based methods need to use representative\nvalidation data to measure the model accuracy, which is difficult to obtain in\npractical FL scenarios. Existing validation-free methods assess the\ncontribution based on the parameters and gradients of local models and the\nglobal model in a single training round, which is easily compromised by the\nstochasticity of model training. In this work, we propose CoAst, a practical\nmethod to assess the FL participants' contribution without access to any\nvalidation data. The core idea of CoAst involves two aspects: one is to only\ncount the most important part of model parameters through a weights\nquantization, and the other is a cross-round valuation based on the similarity\nbetween the current local parameters and the global parameter updates in\nseveral subsequent communication rounds. Extensive experiments show that CoAst\nhas comparable assessment reliability to existing validation-based methods and\noutperforms existing validation-free methods.",
      "tldr_zh": "在联邦学习（FL）中，评估参与者对模型性能的贡献至关重要，但现有方法要么依赖难以获取的验证数据集，要么易受训练随机性影响。论文提出 CoAst，一种无需验证数据集的贡献评估方法，其核心包括通过 weights quantization 只关注模型参数的重要部分，以及基于 cross-round valuation 计算当前本地参数与后续全局参数更新的相似性。实验结果表明，CoAst 的评估可靠性与现有 validation-based 方法相当，并显著优于现有 validation-free 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02495v1",
      "published_date": "2024-09-04 07:46:28 UTC",
      "updated_date": "2024-09-04 07:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:26:43.527352"
    },
    {
      "arxiv_id": "2409.02489v2",
      "title": "NeuroSpex: Neuro-Guided Speaker Extraction with Cross-Modal Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Dashanka De Silva",
        "Siqi Cai",
        "Saurav Pahuja",
        "Tanja Schultz",
        "Haizhou Li"
      ],
      "abstract": "In the study of auditory attention, it has been revealed that there exists a\nrobust correlation between attended speech and elicited neural responses,\nmeasurable through electroencephalography (EEG). Therefore, it is possible to\nuse the attention information available within EEG signals to guide the\nextraction of the target speaker in a cocktail party computationally. In this\npaper, we present a neuro-guided speaker extraction model, i.e. NeuroSpex,\nusing the EEG response of the listener as the sole auxiliary reference cue to\nextract attended speech from monaural speech mixtures. We propose a novel EEG\nsignal encoder that captures the attention information. Additionally, we\npropose a cross-attention (CA) mechanism to enhance the speech feature\nrepresentations, generating a speaker extraction mask. Experimental results on\na publicly available dataset demonstrate that our proposed model outperforms\ntwo baseline models across various evaluation metrics.",
      "tldr_zh": "该研究探讨了听觉注意力与EEG信号之间的相关性，提出NeuroSpex模型，使用EEG信号作为唯一辅助参考，从单声道语音混合中提取目标说话者语音。模型包括一个新型EEG信号编码器来捕捉注意力信息，以及一个cross-attention机制来增强语音特征表示并生成说话者提取掩码。在公开数据集上的实验结果显示，NeuroSpex在多种评估指标上优于两个基线模型，证明了其在神经指导型说话者提取方面的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02489v2",
      "published_date": "2024-09-04 07:33:01 UTC",
      "updated_date": "2024-09-16 06:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:26:55.498640"
    },
    {
      "arxiv_id": "2409.02486v1",
      "title": "Boosting Generalizability towards Zero-Shot Cross-Dataset Single-Image Indoor Depth by Meta-Initialization",
      "title_zh": "翻译失败",
      "authors": [
        "Cho-Ying Wu",
        "Yiqi Zhong",
        "Junying Wang",
        "Ulrich Neumann"
      ],
      "abstract": "Indoor robots rely on depth to perform tasks like navigation or obstacle\ndetection, and single-image depth estimation is widely used to assist\nperception. Most indoor single-image depth prediction focuses less on model\ngeneralizability to unseen datasets, concerned with in-the-wild robustness for\nsystem deployment. This work leverages gradient-based meta-learning to gain\nhigher generalizability on zero-shot cross-dataset inference. Unlike the\nmost-studied meta-learning of image classification associated with explicit\nclass labels, no explicit task boundaries exist for continuous depth values\ntied to highly varying indoor environments regarding object arrangement and\nscene composition. We propose fine-grained task that treats each RGB-D\nmini-batch as a task in our meta-learning formulation. We first show that our\nmethod on limited data induces a much better prior (max 27.8% in RMSE). Then,\nfinetuning on meta-learned initialization consistently outperforms baselines\nwithout the meta approach. Aiming at generalization, we propose zero-shot\ncross-dataset protocols and validate higher generalizability induced by our\nmeta-initialization, as a simple and useful plugin to many existing depth\nestimation methods. The work at the intersection of depth and meta-learning\npotentially drives both research to step closer to practical robotic and\nmachine perception usage.",
      "tldr_zh": "本研究针对室内单图像深度估计（single-image depth estimation）在零样本跨数据集（zero-shot cross-dataset）推断中的泛化性问题，提出了一种基于元学习（meta-learning）的初始化方法。作者将每个 RGB-D 小批量视为一个细粒度任务，通过梯度-based meta-learning 训练来获得更好的先验模型，在有限数据上将 RMSE 降低最多 27.8%。实验结果显示，在元学习初始化基础上进行微调，该方法显著优于基线模型，并在新提出的零样本跨数据集协议中验证了更高的泛化性，从而为深度估计和机器人感知的实际应用提供了一个简单有效的插件。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IROS 2024. The version supersedes 2305.07269. arXiv admin note: text\n  overlap with arXiv:2305.07269",
      "pdf_url": "http://arxiv.org/pdf/2409.02486v1",
      "published_date": "2024-09-04 07:25:50 UTC",
      "updated_date": "2024-09-04 07:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:27:09.573087"
    },
    {
      "arxiv_id": "2409.02485v2",
      "title": "Adversarial Attacks on Machine Learning-Aided Visualizations",
      "title_zh": "针对机器学习辅助可视化的对抗攻击",
      "authors": [
        "Takanori Fujiwara",
        "Kostiantyn Kucher",
        "Junpeng Wang",
        "Rafael M. Martins",
        "Andreas Kerren",
        "Anders Ynnerman"
      ],
      "abstract": "Research in ML4VIS investigates how to use machine learning (ML) techniques\nto generate visualizations, and the field is rapidly growing with high societal\nimpact. However, as with any computational pipeline that employs ML processes,\nML4VIS approaches are susceptible to a range of ML-specific adversarial\nattacks. These attacks can manipulate visualization generations, causing\nanalysts to be tricked and their judgments to be impaired. Due to a lack of\nsynthesis from both visualization and ML perspectives, this security aspect is\nlargely overlooked by the current ML4VIS literature. To bridge this gap, we\ninvestigate the potential vulnerabilities of ML-aided visualizations from\nadversarial attacks using a holistic lens of both visualization and ML\nperspectives. We first identify the attack surface (i.e., attack entry points)\nthat is unique in ML-aided visualizations. We then exemplify five different\nadversarial attacks. These examples highlight the range of possible attacks\nwhen considering the attack surface and multiple different adversary\ncapabilities. Our results show that adversaries can induce various attacks,\nsuch as creating arbitrary and deceptive visualizations, by systematically\nidentifying input attributes that are influential in ML inferences. Based on\nour observations of the attack surface characteristics and the attack examples,\nwe underline the importance of comprehensive studies of security issues and\ndefense mechanisms as a call of urgency for the ML4VIS community.",
      "tldr_zh": "该论文探讨了机器学习辅助可视化（ML4VIS）系统面临的对抗攻击（adversarial attacks）风险，这些攻击可能操纵可视化生成，导致分析师判断失误。研究从可视化和ML视角进行整体分析，首次识别了ML-aided visualizations特有的攻击面（attack surface），并举例了五种不同攻击示例，展示了攻击者如何通过影响ML推理的输入属性创建任意欺骗性可视化。结果强调了这些漏洞的严重性，并呼吁ML4VIS社区紧急开展全面的安全研究和防御机制，以提升系统的鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CR",
      "comment": "This version of the article has been accepted for publication, after\n  peer review (when applicable) but is not the Version of Record and does not\n  reflect post-acceptance improvements, or any corrections. The Version of\n  Record is available online at: http://dx.doi.org/10.1007/s12650-024-01029-2",
      "pdf_url": "http://arxiv.org/pdf/2409.02485v2",
      "published_date": "2024-09-04 07:23:12 UTC",
      "updated_date": "2024-09-24 13:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:27:22.825935"
    },
    {
      "arxiv_id": "2409.02483v5",
      "title": "TASAR: Transfer-based Attack on Skeletal Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yunfeng Diao",
        "Baiqi Wu",
        "Ruixuan Zhang",
        "Ajian Liu",
        "Xiaoshuai Hao",
        "Xingxing Wei",
        "Meng Wang",
        "He Wang"
      ],
      "abstract": "Skeletal sequence data, as a widely employed representation of human actions,\nare crucial in Human Activity Recognition (HAR). Recently, adversarial attacks\nhave been proposed in this area, which exposes potential security concerns, and\nmore importantly provides a good tool for model robustness test. Within this\nresearch, transfer-based attack is an important tool as it mimics the\nreal-world scenario where an attacker has no knowledge of the target model, but\nis under-explored in Skeleton-based HAR (S-HAR). Consequently, existing S-HAR\nattacks exhibit weak adversarial transferability and the reason remains largely\nunknown. In this paper, we investigate this phenomenon via the characterization\nof the loss function. We find that one prominent indicator of poor\ntransferability is the low smoothness of the loss function. Led by this\nobservation, we improve the transferability by properly smoothening the loss\nwhen computing the adversarial examples. This leads to the first Transfer-based\nAttack on Skeletal Action Recognition, TASAR. TASAR explores the smoothened\nmodel posterior of pre-trained surrogates, which is achieved by a new\npost-train Dual Bayesian optimization strategy. Furthermore, unlike existing\ntransfer-based methods which overlook the temporal coherence within sequences,\nTASAR incorporates motion dynamics into the Bayesian attack, effectively\ndisrupting the spatial-temporal coherence of S-HARs. For exhaustive evaluation,\nwe build the first large-scale robust S-HAR benchmark, comprising 7 S-HAR\nmodels, 10 attack methods, 3 S-HAR datasets and 2 defense models. Extensive\nresults demonstrate the superiority of TASAR. Our benchmark enables easy\ncomparisons for future studies, with the code available in the\nhttps://github.com/yunfengdiao/Skeleton-Robustness-Benchmark.",
      "tldr_zh": "本研究针对骨骼序列数据在人类活动识别(HAR)中的应用，探讨了Transfer-based Attack在Skeleton-based HAR (S-HAR)中的不足，特别是在转移性弱的问题上。通过分析损失函数的平滑性，论文提出TASAR方法，该方法通过平滑损失函数、后训练Dual Bayesian优化策略以及融入运动动态来生成更有效的对抗样本，从而破坏S-HAR的空间-时间一致性。TASAR的实验评估基于首个大规模S-HAR鲁棒性基准，包括7个S-HAR模型、10个攻击方法、3个数据集和2个防御模型，结果显示其显著优于现有方法，并提供了开源代码以便后续研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.02483v5",
      "published_date": "2024-09-04 07:20:01 UTC",
      "updated_date": "2025-02-12 09:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:27:36.009787"
    },
    {
      "arxiv_id": "2409.02451v1",
      "title": "Fast, High-Quality and Parameter-Efficient Articulatory Synthesis using Differentiable DSP",
      "title_zh": "翻译失败",
      "authors": [
        "Yisi Liu",
        "Bohan Yu",
        "Drake Lin",
        "Peter Wu",
        "Cheol Jun Cho",
        "Gopala Krishna Anumanchipalli"
      ],
      "abstract": "Articulatory trajectories like electromagnetic articulography (EMA) provide a\nlow-dimensional representation of the vocal tract filter and have been used as\nnatural, grounded features for speech synthesis. Differentiable digital signal\nprocessing (DDSP) is a parameter-efficient framework for audio synthesis.\nTherefore, integrating low-dimensional EMA features with DDSP can significantly\nenhance the computational efficiency of speech synthesis. In this paper, we\npropose a fast, high-quality, and parameter-efficient DDSP articulatory vocoder\nthat can synthesize speech from EMA, F0, and loudness. We incorporate several\ntechniques to solve the harmonics / noise imbalance problem, and add a\nmulti-resolution adversarial loss for better synthesis quality. Our model\nachieves a transcription word error rate (WER) of 6.67% and a mean opinion\nscore (MOS) of 3.74, with an improvement of 1.63% and 0.16 compared to the\nstate-of-the-art (SOTA) baseline. Our DDSP vocoder is 4.9x faster than the\nbaseline on CPU during inference, and can generate speech of comparable quality\nwith only 0.4M parameters, in contrast to the 9M parameters required by the\nSOTA.",
      "tldr_zh": "本论文提出了一种快速、高质量且参数高效的 DDSP 发音合成器，使用电磁关节成像 (EMA) 特征、F0 和响度作为输入，与 Differentiable Digital Signal Processing (DDSP) 框架整合。\n该方法通过解决谐波/噪声不平衡问题并添加多分辨率对抗损失，显著提升了语音合成的准确性和质量。\n实验结果显示，该模型的转录词错误率 (WER) 为 6.67%、主观意见分数 (MOS) 为 3.74，比现有 SOTA 基线分别改善 1.63% 和 0.16，且在 CPU 上推理速度快 4.9 倍，仅需 0.4M 参数。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "accepted for Spoken Language Technology Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.02451v1",
      "published_date": "2024-09-04 05:12:15 UTC",
      "updated_date": "2024-09-04 05:12:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:27:48.464594"
    },
    {
      "arxiv_id": "2409.02449v4",
      "title": "What is lost in Normalization? Exploring Pitfalls in Multilingual ASR Model Evaluations",
      "title_zh": "翻译失败",
      "authors": [
        "Kavya Manohar",
        "Leena G Pillai",
        "Elizabeth Sherly"
      ],
      "abstract": "This paper explores the pitfalls in evaluating multilingual automatic speech\nrecognition (ASR) models, with a particular focus on Indic language scripts. We\ninvestigate the text normalization routine employed by leading ASR models,\nincluding OpenAI Whisper, Meta's MMS, Seamless, and Assembly AI's Conformer,\nand their unintended consequences on performance metrics. Our research reveals\nthat current text normalization practices, while aiming to standardize ASR\noutputs for fair comparison, by removing inconsistencies such as variations in\nspelling, punctuation, and special characters, are fundamentally flawed when\napplied to Indic scripts. Through empirical analysis using text similarity\nscores and in-depth linguistic examination, we demonstrate that these flaws\nlead to artificially improved performance metrics for Indic languages. We\nconclude by proposing a shift towards developing text normalization routines\nthat leverage native linguistic expertise, ensuring more robust and accurate\nevaluations of multilingual ASR models.",
      "tldr_zh": "这篇论文探讨了多语言自动语音识别 (ASR) 模型评估中的潜在陷阱，特别是针对 Indic 语言脚本的文本归一化问题。作者调查了如 OpenAI Whisper、Meta's MMS 和 Assembly AI's Conformer 等领先模型的文本归一化例程，发现这些方法在移除拼写、标点和特殊字符的不一致时，会导致 Indic 语言的性能指标被人为夸大。最终，论文提出应转向利用本土语言专家开发更稳健的文本归一化策略，以确保多语言 ASR 模型评估的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "68T50, 91F20, 68T10",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2409.02449v4",
      "published_date": "2024-09-04 05:08:23 UTC",
      "updated_date": "2024-11-09 06:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:28:00.064876"
    },
    {
      "arxiv_id": "2409.02448v1",
      "title": "Detecting Korean Food Using Image using Hierarchical Model",
      "title_zh": "翻译失败",
      "authors": [
        "Hoang Khanh Lam",
        "Kahandakanaththage Maduni Pramuditha Perera"
      ],
      "abstract": "A solution was made available for Korean Food lovers who have dietary\nrestrictions to identify the Korean food before consuming. Just by uploading a\nclear photo of the dish, people can get to know what they are eating. Image\nprocessing techniques together with machine learning helped to come up with\nthis solution.",
      "tldr_zh": "本研究针对有饮食限制的韩国食物爱好者，开发了一个基于图像检测的系统，使用 Hierarchical Model 帮助用户通过上传清晰照片识别菜肴。系统结合图像处理技术和机器学习算法，实现食物的自动识别和信息提供。该方法为日常饮食管理提供了简单便捷的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02448v1",
      "published_date": "2024-09-04 05:06:34 UTC",
      "updated_date": "2024-09-04 05:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:28:10.035925"
    },
    {
      "arxiv_id": "2409.02428v3",
      "title": "Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning",
      "title_zh": "大语言模型作为高效奖励函数搜索器，用于自定义环境的多目标强化学习",
      "authors": [
        "Guanwen Xie",
        "Jingzehua Xu",
        "Yiyuan Yang",
        "Yimian Ding",
        "Shuai Zhang"
      ],
      "abstract": "Achieving the effective design and improvement of reward functions in\nreinforcement learning (RL) tasks with complex custom environments and multiple\nrequirements presents considerable challenges. In this paper, we propose ERFSL,\nan efficient reward function searcher using LLMs, which enables LLMs to be\neffective white-box searchers and highlights their advanced semantic\nunderstanding capabilities. Specifically, we generate reward components for\neach numerically explicit user requirement and employ a reward critic to\nidentify the correct code form. Then, LLMs assign weights to the reward\ncomponents to balance their values and iteratively adjust the weights without\nambiguity and redundant adjustments by flexibly adopting directional mutation\nand crossover strategies, similar to genetic algorithms, based on the context\nprovided by the training log analyzer. We applied the framework to an\nunderwater data collection RL task without direct human feedback or reward\nexamples (zero-shot learning). The reward critic successfully corrects the\nreward code with only one feedback instance for each requirement, effectively\npreventing unrectifiable errors. The initialization of weights enables the\nacquisition of different reward functions within the Pareto solution set\nwithout the need for weight search. Even in cases where a weight is 500 times\noff, on average, only 5.2 iterations are needed to meet user requirements. The\nERFSL also works well with most prompts utilizing GPT-4o mini, as we decompose\nthe weight searching process to reduce the requirement for numerical and\nlong-context understanding capabilities",
      "tldr_zh": "该论文提出 ERFSL 框架，利用大型语言模型 (LLMs) 作为高效的奖励函数搜索器，针对自定义环境下的多目标强化学习 (Multi-Objective Reinforcement Learning) 任务，解决复杂奖励函数设计挑战。框架通过为每个用户需求生成奖励组件 (reward components)，并使用奖励批评者 (reward critic) 修正代码形式，同时 LLMs 分配权重并采用类似于遗传算法的定向变异和交叉策略 (directional mutation and crossover) 进行迭代调整。实验结果显示，在零样本 (zero-shot) 水下数据收集任务中，ERFSL 仅需一个反馈实例即可修正错误，且即使权重偏差高达 500 倍，平均仅需 5.2 次迭代即可满足要求，与 GPT-4o mini 兼容，显著提升了奖励函数优化的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02428v3",
      "published_date": "2024-09-04 04:15:14 UTC",
      "updated_date": "2024-11-01 03:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:28:28.166958"
    },
    {
      "arxiv_id": "2409.13697v1",
      "title": "Prompt Baking",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Bhargava",
        "Cameron Witkowski",
        "Alexander Detkov",
        "Matt Thomson"
      ],
      "abstract": "Two primary ways to change LLM behavior are prompting and weight updates\n(e.g., fine-tuning). Prompting LLMs is simple and effective, specifying the\ndesired changes explicitly in natural language, whereas weight updates provide\nmore expressive and permanent behavior changes, specified implicitly via\ntraining on large datasets. We present a technique for \"baking\" prompts into\nthe weights of an LLM. Prompt Baking converts a prompt $u$ and initial weights\n$\\theta$ to a new set of weights $\\theta_u$ such that new \"baked\" LLM behaves\nlike the original prompted LLM. Mathematically, we minimize the KL divergence\nbetween $P_\\theta(\\cdot | u)$ and $P_{\\theta_u}(\\cdot)$, where $P$ is the LLM's\nprobability distribution over token sequences. Across all our experiments, we\nfind prompts can be readily baked into weight updates. Baking chain-of-thought\nprompts improves zero-shot performance on GSM8K, ASDiv, MBPP, ARC-Easy,\nARC-Challenge, and CommonsenseQA benchmarks. Baking news headlines directly\nupdates an LLM's knowledge. And baking instructions & personas alleviates\n\"prompt forgetting\" over long sequences. Furthermore, stopping baking early\ncreates \"half-baked\" models, continuously scaling prompt strength. Baked models\nretain their sensitivity to further prompting and baking, including\nre-prompting with the baked-in prompt. Surprisingly, the re-prompted models\nyield further performance gains in instruction following, as well as math\nreasoning and coding benchmarks. Taking re-prompting and re-baking to the limit\nyields a form of iterative self-improvement we call Prompt Pursuit, and\npreliminary results on instruction following exhibit dramatic performance\ngains. Finally, we discuss implications for AI safety, continuous model\nupdating, enhancing real-time learning capabilities in LLM-based agents, and\ngenerating more stable AI personas.",
      "tldr_zh": "本论文提出了一种名为 Prompt Baking 的技术，将提示词嵌入大型语言模型（LLM）的权重中，通过最小化 KL divergence，使新权重 θ_u 的行为类似于原提示模型 P_θ(· | u)，从而实现更持久和表达性的模型调整。实验结果显示，烘焙 chain-of-thought 提示提升了零样本性能，在 GSM8K、ASDiv、MBPP、ARC-Easy、ARC-Challenge 和 CommonsenseQA 等基准上表现显著改善；此外，烘焙新闻标题更新模型知识，并缓解了提示遗忘问题。进一步探索表明，早期停止烘焙可创建“半烘焙”模型，并通过重新提示和再烘焙实现迭代自提升（Prompt Pursuit），为 AI 安全、持续更新和实时学习提供新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.13697v1",
      "published_date": "2024-09-04 04:13:16 UTC",
      "updated_date": "2024-09-04 04:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:28:38.232518"
    },
    {
      "arxiv_id": "2409.02423v1",
      "title": "Accelerating Large Language Model Training with Hybrid GPU-based Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Xu",
        "Quentin Anthony",
        "Qinghua Zhou",
        "Nawras Alnaasan",
        "Radha R. Gulhane",
        "Aamir Shafi",
        "Hari Subramoni",
        "Dhabaleswar K. Panda"
      ],
      "abstract": "Data Parallelism (DP), Tensor Parallelism (TP), and Pipeline Parallelism (PP)\nare the three strategies widely adopted to enable fast and efficient Large\nLanguage Model (LLM) training. However, these approaches rely on data-intensive\ncommunication routines to collect, aggregate, and re-distribute gradients,\nactivations, and other important model information, which pose significant\noverhead. Co-designed with GPU-based compression libraries, MPI libraries have\nbeen proven to reduce message size significantly, and leverage interconnect\nbandwidth, thus increasing training efficiency while maintaining acceptable\naccuracy.\n  In this work, we investigate the efficacy of compression-assisted MPI\ncollectives under the context of distributed LLM training using 3D parallelism\nand ZeRO optimizations. We scaled up to 192 V100 GPUs on the Lassen\nsupercomputer. First, we enabled a na\\\"ive compression scheme across all\ncollectives and observed a 22.5\\% increase in TFLOPS per GPU and a 23.6\\%\nincrease in samples per second for GPT-NeoX-20B training. Nonetheless, such a\nstrategy ignores the sparsity discrepancy among messages communicated in each\nparallelism degree, thus introducing more errors and causing degradation in\ntraining loss. Therefore, we incorporated hybrid compression settings toward\neach parallel dimension and adjusted the compression intensity accordingly.\nGiven their low-rank structure (arXiv:2301.02654), we apply aggressive\ncompression on gradients when performing DP All-reduce. We adopt milder\ncompression to preserve precision while communicating activations, optimizer\nstates, and model parameters in TP and PP. Using the adjusted hybrid\ncompression scheme, we demonstrate a 17.3\\% increase in TFLOPS per GPU and a\n12.7\\% increase in samples per second while reaching baseline loss convergence.",
      "tldr_zh": "本论文提出了一种混合 GPU-based compression 方法，用于加速 Large Language Model (LLM) 训练，针对 Data Parallelism (DP)、Tensor Parallelism (TP) 和 Pipeline Parallelism (PP) 中的通信开销问题。方法结合 3D parallelism 和 ZeRO optimizations，根据消息类型调整压缩强度，例如对 DP 中的梯度采用激进压缩，而对 TP 和 PP 中的激活、优化器状态和模型参数使用温和压缩，以平衡效率和精度。实验结果显示，在 192 V100 GPUs 上训练 GPT-NeoX-20B 时，该方案实现了 17.3% 的 TFLOPS 提升和 12.7% 的样本处理速度增加，同时保持了基线损失收敛。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02423v1",
      "published_date": "2024-09-04 04:05:30 UTC",
      "updated_date": "2024-09-04 04:05:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:28:50.151284"
    },
    {
      "arxiv_id": "2409.02413v1",
      "title": "Abstractive Text Summarization: State of the Art, Challenges, and Improvements",
      "title_zh": "抽象文本摘要：最先进技术",
      "authors": [
        "Hassan Shakil",
        "Ahmad Farooq",
        "Jugal Kalita"
      ],
      "abstract": "Specifically focusing on the landscape of abstractive text summarization, as\nopposed to extractive techniques, this survey presents a comprehensive\noverview, delving into state-of-the-art techniques, prevailing challenges, and\nprospective research directions. We categorize the techniques into traditional\nsequence-to-sequence models, pre-trained large language models, reinforcement\nlearning, hierarchical methods, and multi-modal summarization. Unlike prior\nworks that did not examine complexities, scalability and comparisons of\ntechniques in detail, this review takes a comprehensive approach encompassing\nstate-of-the-art methods, challenges, solutions, comparisons, limitations and\ncharts out future improvements - providing researchers an extensive overview to\nadvance abstractive summarization research. We provide vital comparison tables\nacross techniques categorized - offering insights into model complexity,\nscalability and appropriate applications. The paper highlights challenges such\nas inadequate meaning representation, factual consistency, controllable text\nsummarization, cross-lingual summarization, and evaluation metrics, among\nothers. Solutions leveraging knowledge incorporation and other innovative\nstrategies are proposed to address these challenges. The paper concludes by\nhighlighting emerging research areas like factual inconsistency,\ndomain-specific, cross-lingual, multilingual, and long-document summarization,\nas well as handling noisy data. Our objective is to provide researchers and\npractitioners with a structured overview of the domain, enabling them to better\nunderstand the current landscape and identify potential areas for further\nresearch and improvement.",
      "tldr_zh": "这篇论文对抽象文本摘要(abstractive text summarization)进行了全面调查，聚焦于最新技术、主要挑战和未来改进方向，与提取式方法形成对比。论文将技术分类为传统序列到序列(sequence-to-sequence)模型、预训练大型语言模型(large language models)、强化学习(reinforcement learning)、层次化方法(hierarchical methods)以及多模态摘要(multi-modal summarization)，并通过比较表分析了模型复杂度、扩展性和适用场景。核心挑战包括事实一致性(factual consistency)、可控摘要(controllable text summarization)和跨语言摘要(cross-lingual summarization)等，论文提出解决方案如整合知识(knowledge incorporation)，并指出未来研究重点，如处理噪声数据和领域特定摘要。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 Tables, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02413v1",
      "published_date": "2024-09-04 03:39:23 UTC",
      "updated_date": "2024-09-04 03:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:29:00.536086"
    },
    {
      "arxiv_id": "2409.12924v4",
      "title": "Wavelet GPT: Wavelet Inspired Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Verma"
      ],
      "abstract": "Large Language Models (LLMs) have ushered in a new wave of artificial\nintelligence advancements impacting every scientific field and discipline. We\nlive in a world where most of the data around us, e.g., text, audio, and music,\nhas a multi-scale structure. This paper infuses LLMs with a traditional signal\nprocessing idea, namely wavelets, during pre-training to take advantage of the\nstructure. Without adding \\textbf{any extra parameters} to a GPT-style LLM\narchitecture in an academic setup, we achieve the same pre-training performance\nalmost twice as fast in text, audio, and images. This is done by imposing a\nstructure on intermediate embeddings. When trained for the same number of\ntraining steps, we achieve significant gains in performance, which is\ncomparable to pre-training a larger neural architecture. Further, we show this\nextends to the Long Range Arena benchmark and several input representations\nsuch as characters, BPE tokens, bytes, waveform, math expression, and image\npixels. Our architecture allows every next token prediction access to\nintermediate embeddings at different temporal resolutions in every decoder\nblock. We hope this will pave the way for incorporating multi-rate signal\nprocessing into pre-training.",
      "tldr_zh": "这篇论文提出了一种受 wavelets 启发的 LLM 架构，名为 Wavelet GPT，旨在利用文本、音频和图像等数据的多尺度结构来提升模型性能。研究方法在预训练过程中通过结构化中间 embeddings，而不增加任何额外参数，实现训练速度几乎快一倍，并在相同步数下获得显著性能提升，相当于使用更大的神经架构。该框架扩展到 Long Range Arena 基准和多种输入表示（如字符、BPE tokens、字节、波形、数学表达式和图像像素），允许每个下一 token 预测访问不同时间分辨率的嵌入，最终为将多速率信号处理融入 LLM 预训练铺平道路。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "eess.SP",
      "comment": "12 pages, 4 figures;",
      "pdf_url": "http://arxiv.org/pdf/2409.12924v4",
      "published_date": "2024-09-04 03:17:19 UTC",
      "updated_date": "2025-02-09 23:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:29:12.728078"
    },
    {
      "arxiv_id": "2409.02404v1",
      "title": "Learning Privacy-Preserving Student Networks via Discriminative-Generative Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Shiming Ge",
        "Bochao Liu",
        "Pengju Wang",
        "Yong Li",
        "Dan Zeng"
      ],
      "abstract": "While deep models have proved successful in learning rich knowledge from\nmassive well-annotated data, they may pose a privacy leakage risk in practical\ndeployment. It is necessary to find an effective trade-off between high utility\nand strong privacy. In this work, we propose a discriminative-generative\ndistillation approach to learn privacy-preserving deep models. Our key idea is\ntaking models as bridge to distill knowledge from private data and then\ntransfer it to learn a student network via two streams. First, discriminative\nstream trains a baseline classifier on private data and an ensemble of teachers\non multiple disjoint private subsets, respectively. Then, generative stream\ntakes the classifier as a fixed discriminator and trains a generator in a\ndata-free manner. After that, the generator is used to generate massive\nsynthetic data which are further applied to train a variational autoencoder\n(VAE). Among these synthetic data, a few of them are fed into the teacher\nensemble to query labels via differentially private aggregation, while most of\nthem are embedded to the trained VAE for reconstructing synthetic data.\nFinally, a semi-supervised student learning is performed to simultaneously\nhandle two tasks: knowledge transfer from the teachers with distillation on few\nprivately labeled synthetic data, and knowledge enhancement with tangent-normal\nadversarial regularization on many triples of reconstructed synthetic data. In\nthis way, our approach can control query cost over private data and mitigate\naccuracy degradation in a unified manner, leading to a privacy-preserving\nstudent model. Extensive experiments and analysis clearly show the\neffectiveness of the proposed approach.",
      "tldr_zh": "本研究提出了一种通过判别-生成蒸馏(discriminative-generative distillation)方法学习隐私保护学生网络的框架，旨在在深度模型高性能与数据隐私之间实现平衡。方法包括判别流（训练基线分类器和教师集合于私有数据子集）和生成流（使用分类器作为判别器训练生成器，生成合成数据并训练变分自动编码器(VAE)）。随后，通过差分隐私聚合查询少量标签合成数据进行知识转移，并利用大量重建合成数据进行切线-法线对抗正则化以增强学习。实验结果表明，该方法有效控制了对私有数据的查询成本，同时减少准确性下降，生成隐私保护且性能优越的学生模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by IEEE Transactions on Image Processing (TIP)",
      "pdf_url": "http://arxiv.org/pdf/2409.02404v1",
      "published_date": "2024-09-04 03:06:13 UTC",
      "updated_date": "2024-09-04 03:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:29:28.200017"
    },
    {
      "arxiv_id": "2409.02391v2",
      "title": "Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Merali"
      ],
      "abstract": "This paper derives \"scaling laws\"--empirical relationships between the\ntraining compute of Large Language Models (LLMs) and their performance--for\neconomic outcomes. In a preregistered online experiment, 300 professional\ntranslators completed 1,800 tasks using one of 13 LLMs (or a control). A\ntenfold increase in model compute improved task completion speed by 12.3%,\ngrades by 0.18 standard deviations, and earnings per minute by 16.1%. Gains\nwere four times larger for lower-skilled workers. These findings suggest\ncontinued model scaling could boost U.S. productivity by at least 6.9% over the\nnext decade.",
      "tldr_zh": "本论文研究了大型语言模型（LLMs）的训练计算量与经济生产力之间的“scaling laws”，通过实验证据探讨其在翻译任务中的影响。在一个预注册的在线实验中，300 名专业翻译人员使用 13 个 LLMs（或对照组）完成 1,800 个任务，结果显示模型计算量增加 10 倍可提高任务完成速度 12.3%、成绩 0.18 标准差，以及单位时间收入 16.1%。低技能工人的收益是其他工人的四倍。这些发现表明，继续扩展模型规模可能在未来十年内将美国生产力提升至少 6.9%。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02391v2",
      "published_date": "2024-09-04 02:39:31 UTC",
      "updated_date": "2024-12-07 08:56:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:29:41.030068"
    },
    {
      "arxiv_id": "2409.02390v1",
      "title": "Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts",
      "title_zh": "视觉决策的神经动力学模型：从人类专家学习",
      "authors": [
        "Jie Su",
        "Fang Cai",
        "Shu-Kuo Zhao",
        "Xin-Yi Wang",
        "Tian-Yi Qian",
        "Da-Hui Wang",
        "Bo Hong"
      ],
      "abstract": "Uncovering the fundamental neural correlates of biological intelligence,\ndeveloping mathematical models, and conducting computational simulations are\ncritical for advancing new paradigms in artificial intelligence (AI). In this\nstudy, we implemented a comprehensive visual decision-making model that spans\nfrom visual input to behavioral output, using a neural dynamics modeling\napproach. Drawing inspiration from the key components of the dorsal visual\npathway in primates, our model not only aligns closely with human behavior but\nalso reflects neural activities in primates, and achieving accuracy comparable\nto convolutional neural networks (CNNs). Moreover, magnetic resonance imaging\n(MRI) identified key neuroimaging features such as structural connections and\nfunctional connectivity that are associated with performance in perceptual\ndecision-making tasks. A neuroimaging-informed fine-tuning approach was\nintroduced and applied to the model, leading to performance improvements that\nparalleled the behavioral variations observed among subjects. Compared to\nclassical deep learning models, our model more accurately replicates the\nbehavioral performance of biological intelligence, relying on the structural\ncharacteristics of biological neural networks rather than extensive training\ndata, and demonstrating enhanced resilience to perturbation.",
      "tldr_zh": "本研究提出了一种神经动力学模型，用于模拟视觉决策过程，从人类专家和灵长类动物的背侧视觉通路(dorsal visual pathway)中获取灵感，实现从视觉输入到行为输出的全面建模。模型不仅与人类行为和神经活动高度一致，且准确性可与卷积神经网络(CNNs)媲美，通过磁共振成像(MRI)识别的结构连接和功能连接等神经影像特征，进一步优化了模型性能。相比传统深度学习模型，该方法依赖生物神经网络的结构特性而非大量训练数据，实现了更精确的生物智能行为复制，并提升了对扰动的鲁棒性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02390v1",
      "published_date": "2024-09-04 02:38:52 UTC",
      "updated_date": "2024-09-04 02:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:29:52.069528"
    },
    {
      "arxiv_id": "2409.02389v2",
      "title": "Multi-modal Situated Reasoning in 3D Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongkun Linghu",
        "Jiangyong Huang",
        "Xuesong Niu",
        "Xiaojian Ma",
        "Baoxiong Jia",
        "Siyuan Huang"
      ],
      "abstract": "Situation awareness is essential for understanding and reasoning about 3D\nscenes in embodied AI agents. However, existing datasets and benchmarks for\nsituated understanding are limited in data modality, diversity, scale, and task\nscope. To address these limitations, we propose Multi-modal Situated Question\nAnswering (MSQA), a large-scale multi-modal situated reasoning dataset,\nscalably collected leveraging 3D scene graphs and vision-language models (VLMs)\nacross a diverse range of real-world 3D scenes. MSQA includes 251K situated\nquestion-answering pairs across 9 distinct question categories, covering\ncomplex scenarios within 3D scenes. We introduce a novel interleaved\nmulti-modal input setting in our benchmark to provide text, image, and point\ncloud for situation and question description, resolving ambiguity in previous\nsingle-modality convention (e.g., text). Additionally, we devise the\nMulti-modal Situated Next-step Navigation (MSNN) benchmark to evaluate models'\nsituated reasoning for navigation. Comprehensive evaluations on MSQA and MSNN\nhighlight the limitations of existing vision-language models and underscore the\nimportance of handling multi-modal interleaved inputs and situation modeling.\nExperiments on data scaling and cross-domain transfer further demonstrate the\nefficacy of leveraging MSQA as a pre-training dataset for developing more\npowerful situated reasoning models.",
      "tldr_zh": "本论文提出 Multi-modal Situated Question Answering (MSQA)，一个大规模多模态情境推理数据集，包含251K个问答对，基于3D场景图和视觉语言模型(VLMs)生成，覆盖9个问题类别和多样化的真实3D场景，以解决现有数据集在模态、多样性、规模和任务范围上的局限性。MSQA采用新型交错多模态输入设置，包括文本、图像和点云，减少单模态（如文本）描述的模糊性，同时引入Multi-modal Situated Next-step Navigation (MSNN)基准来评估模型在导航中的情境推理能力。实验结果显示，现有的VLMs在处理多模态输入和情境建模方面存在显著局限性，而使用MSQA作为预训练数据集能有效提升模型的性能，并证明其在数据扩展和跨域转移中的效能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024 Datasets and Benchmarks Track. Project page:\n  https://msr3d.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2409.02389v2",
      "published_date": "2024-09-04 02:37:38 UTC",
      "updated_date": "2024-11-18 02:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:30:04.059012"
    },
    {
      "arxiv_id": "2409.02387v6",
      "title": "Large Language Models and Cognitive Science: A Comprehensive Review of Similarities, Differences, and Challenges",
      "title_zh": "大语言模型与认知科学：相似性、差异性和挑战的全面综述",
      "authors": [
        "Qian Niu",
        "Junyu Liu",
        "Ziqian Bi",
        "Pohsun Feng",
        "Benji Peng",
        "Keyu Chen",
        "Ming Li",
        "Lawrence KQ Yan",
        "Yichao Zhang",
        "Caitlyn Heqi Yin",
        "Cheng Fei",
        "Tianyang Wang",
        "Yunze Wang",
        "Silin Chen",
        "Ming Liu"
      ],
      "abstract": "This comprehensive review explores the intersection of Large Language Models\n(LLMs) and cognitive science, examining similarities and differences between\nLLMs and human cognitive processes. We analyze methods for evaluating LLMs\ncognitive abilities and discuss their potential as cognitive models. The review\ncovers applications of LLMs in various cognitive fields, highlighting insights\ngained for cognitive science research. We assess cognitive biases and\nlimitations of LLMs, along with proposed methods for improving their\nperformance. The integration of LLMs with cognitive architectures is examined,\nrevealing promising avenues for enhancing artificial intelligence (AI)\ncapabilities. Key challenges and future research directions are identified,\nemphasizing the need for continued refinement of LLMs to better align with\nhuman cognition. This review provides a balanced perspective on the current\nstate and future potential of LLMs in advancing our understanding of both\nartificial and human intelligence.",
      "tldr_zh": "这篇综述探讨了Large Language Models (LLMs)与认知科学的交叉点，分析了LLMs与人类认知过程的相似性（如语言处理能力）和差异（如认知偏差和局限性）。作者评估了评估LLMs认知能力的多种方法，并讨论了其作为认知模型的潜力，包括在认知领域（如记忆和推理）的应用以及与认知架构的整合，以提升人工智能(AI)性能。综述突出了LLMs的挑战，如认知偏差和改进策略，并指出了未来研究方向，以更好地将LLMs与人类认知对齐，从而推进对人工和人类智能的理解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.02387v6",
      "published_date": "2024-09-04 02:30:12 UTC",
      "updated_date": "2024-12-11 04:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:30:13.599591"
    },
    {
      "arxiv_id": "2409.15292v1",
      "title": "SketcherX: AI-Driven Interactive Robotic drawing with Diffusion model and Vectorization Techniques",
      "title_zh": "SketcherX：AI驱动的交互式机器人绘图，使用扩散模型和矢量化技术",
      "authors": [
        "Jookyung Song",
        "Mookyoung Kang",
        "Nojun Kwak"
      ],
      "abstract": "We introduce SketcherX, a novel robotic system for personalized portrait\ndrawing through interactive human-robot engagement. Unlike traditional robotic\nart systems that rely on analog printing techniques, SketcherX captures and\nprocesses facial images to produce vectorized drawings in a distinctive,\nhuman-like artistic style. The system comprises two 6-axis robotic arms : a\nface robot, which is equipped with a head-mounted camera and Large Language\nModel (LLM) for real-time interaction, and a drawing robot, utilizing a\nfine-tuned Stable Diffusion model, ControlNet, and Vision-Language models for\ndynamic, stylized drawing. Our contributions include the development of a\ncustom Vector Low Rank Adaptation model (LoRA), enabling seamless adaptation to\nvarious artistic styles, and integrating a pair-wise fine-tuning approach to\nenhance stroke quality and stylistic accuracy. Experimental results demonstrate\nthe system's ability to produce high-quality, personalized portraits within two\nminutes, highlighting its potential as a new paradigm in robotic creativity.\nThis work advances the field of robotic art by positioning robots as active\nparticipants in the creative process, paving the way for future explorations in\ninteractive, human-robot artistic collaboration.",
      "tldr_zh": "我们介绍了 SketcherX，一种 AI 驱动的互动机器人系统，用于通过人机互动生成个性化肖像绘图，该系统利用 Diffusion 模型和矢量化技术，将面部图像转化为独特的人类风格艺术。SketcherX 包括两个 6 轴机器人臂：面部机器人配备头部摄像头和 Large Language Model (LLM) 进行实时互动，以及绘图机器人使用微调的 Stable Diffusion 模型、ControlNet 和视觉语言模型来实现动态风格化绘图。关键贡献是开发了自定义 Vector Low Rank Adaptation (LoRA) 模型和成对微调方法，以提升笔触质量和艺术风格适应性。实验结果显示，该系统能在两分钟内产生高质量个性化肖像，推动机器人艺术领域的发展，使机器人成为创意过程的积极参与者。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.15292v1",
      "published_date": "2024-09-04 02:20:22 UTC",
      "updated_date": "2024-09-04 02:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:30:27.789568"
    },
    {
      "arxiv_id": "2409.02376v1",
      "title": "Coral Model Generation from Single Images for Virtual Reality Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Fu",
        "Shun Fu",
        "Mick Grierson"
      ],
      "abstract": "With the rapid development of VR technology, the demand for high-quality 3D\nmodels is increasing. Traditional methods struggle with efficiency and quality\nin large-scale customization. This paper introduces a deep-learning framework\nthat generates high-precision 3D coral models from a single image. Using the\nCoral dataset, the framework extracts geometric and texture features, performs\n3D reconstruction, and optimizes design and material blending. Advanced\noptimization and polygon count control ensure shape accuracy, detail retention,\nand flexible output for various complexities, catering to high-quality\nrendering and real-time interaction needs.The project incorporates Explainable\nAI (XAI) to transform AI-generated models into interactive \"artworks,\" best\nviewed in VR and XR. This enhances model interpretability and human-machine\ncollaboration. Real-time feedback in VR interactions displays information like\ncoral species and habitat, enriching user experience. The generated models\nsurpass traditional methods in detail, visual quality, and efficiency. This\nresearch offers an intelligent approach to 3D content creation for VR, lowering\nproduction barriers, and promoting widespread VR applications. Additionally,\nintegrating XAI provides new insights into AI-generated visual content and\nadvances research in 3D vision interpretability.",
      "tldr_zh": "这篇论文提出一个深度学习框架，从单张图像生成高精度 3D 珊瑚模型，以满足 VR 应用对高效高质量模型的需求。框架利用 Coral 数据集提取几何和纹理特征，进行 3D 重建，并通过高级优化和多边形计数控制，确保模型形状准确、细节保留，并支持各种复杂度的输出。整合 Explainable AI (XAI) 技术，将 AI 生成模型转化为交互式“艺术品”，在 VR 和 XR 环境中提供实时反馈，如珊瑚物种和栖息地信息，从而提升模型可解释性和人机协作。实验结果表明，该方法在细节、视觉质量和效率上优于传统方法，并为 3D 内容创建和 3D 视觉可解释性研究提供新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of Explainable AI for the Arts Workshop 2024 (XAIxArts\n  2024) arXiv:2406.14485",
      "pdf_url": "http://arxiv.org/pdf/2409.02376v1",
      "published_date": "2024-09-04 01:54:20 UTC",
      "updated_date": "2024-09-04 01:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:30:42.403956"
    },
    {
      "arxiv_id": "2409.02370v4",
      "title": "Do Large Language Models Possess Sensitive to Sentiment?",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Xichou Zhu",
        "Zhou Shen",
        "Yi Liu",
        "Min Li",
        "Yujun Chen",
        "Benzi John",
        "Zhenzhen Ma",
        "Tao Hu",
        "Zhi Li",
        "Zhiyang Xu",
        "Wei Luo",
        "Junhui Wang"
      ],
      "abstract": "Large Language Models (LLMs) have recently displayed their extraordinary\ncapabilities in language understanding. However, how to comprehensively assess\nthe sentiment capabilities of LLMs continues to be a challenge. This paper\ninvestigates the ability of LLMs to detect and react to sentiment in text\nmodal. As the integration of LLMs into diverse applications is on the rise, it\nbecomes highly critical to comprehend their sensitivity to emotional tone, as\nit can influence the user experience and the efficacy of sentiment-driven\ntasks. We conduct a series of experiments to evaluate the performance of\nseveral prominent LLMs in identifying and responding appropriately to\nsentiments like positive, negative, and neutral emotions. The models' outputs\nare analyzed across various sentiment benchmarks, and their responses are\ncompared with human evaluations. Our discoveries indicate that although LLMs\nshow a basic sensitivity to sentiment, there are substantial variations in\ntheir accuracy and consistency, emphasizing the requirement for further\nenhancements in their training processes to better capture subtle emotional\ncues. Take an example in our findings, in some cases, the models might wrongly\nclassify a strongly positive sentiment as neutral, or fail to recognize sarcasm\nor irony in the text. Such misclassifications highlight the complexity of\nsentiment analysis and the areas where the models need to be refined. Another\naspect is that different LLMs might perform differently on the same set of\ndata, depending on their architecture and training datasets. This variance\ncalls for a more in-depth study of the factors that contribute to the\nperformance differences and how they can be optimized.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 是否具备对情感的敏感性，通过一系列实验评估了多个著名 LLMs 在识别和响应文本中积极、消极及中性情感的能力。研究方法包括在各种情感基准上测试模型输出，并与人类评估进行比较。结果显示，LLMs 表现出基本情感敏感性，但准确性和一致性存在显著差异，例如可能将强烈积极情感误判为中性，或无法正确识别讽刺和反讽。作者强调，需要进一步优化 LLMs 的训练过程，以更好地捕捉微妙情感线索并提升整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02370v4",
      "published_date": "2024-09-04 01:40:20 UTC",
      "updated_date": "2025-02-14 10:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:30:51.778917"
    },
    {
      "arxiv_id": "2409.02343v1",
      "title": "NUDGE: Lightweight Non-Parametric Fine-Tuning of Embeddings for Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Sepanta Zeighami",
        "Zac Wellmer",
        "Aditya Parameswaran"
      ],
      "abstract": "$k$-Nearest Neighbor search on dense vector embeddings ($k$-NN retrieval)\nfrom pre-trained embedding models is the predominant retrieval method for text\nand images, as well as Retrieval-Augmented Generation (RAG) pipelines. In\npractice, application developers often fine-tune the embeddings to improve\ntheir accuracy on the dataset and query workload in hand. Existing approaches\neither fine-tune the pre-trained model itself or, more efficiently, but at the\ncost of accuracy, train adaptor models to transform the output of the\npre-trained model. We present NUDGE, a family of novel non-parametric embedding\nfine-tuning approaches that are significantly more accurate and efficient than\nboth sets of existing approaches. NUDGE directly modifies the embeddings of\ndata records to maximize the accuracy of $k$-NN retrieval. We present a\nthorough theoretical and experimental study of NUDGE's non-parametric approach.\nWe show that even though the underlying problem is NP-Hard, constrained\nvariations can be solved efficiently. These constraints additionally ensure\nthat the changes to the embeddings are modest, avoiding large distortions to\nthe semantics learned during pre-training. In experiments across five\npre-trained models and nine standard text and image retrieval datasets, NUDGE\nruns in minutes and often improves NDCG@10 by more than 10% over existing\nfine-tuning methods. On average, NUDGE provides 3.3x and 4.3x higher increase\nin accuracy and runs 200x and 3x faster, respectively, over fine-tuning the\npre-trained model and training adaptors.",
      "tldr_zh": "本论文提出 NUDGE，一种轻量级非参数嵌入微调方法，旨在提升 k-NN retrieval 在文本和图像检索以及 Retrieval-Augmented Generation (RAG) 管道中的准确性，通过直接修改数据记录的嵌入来最大化检索性能，同时使用约束确保嵌入变化适中，避免对预训练语义的重大扭曲。研究证明，尽管底层问题为 NP-Hard，通过高效的约束变体可快速求解。实验结果显示，在五种预训练模型和九个标准数据集上，NUDGE 平均使 NDCG@10 提升超过 10%，并在准确性上比微调预训练模型或训练适配器分别高出 3.3 倍和 4.3 倍，同时运行速度快 200 倍和 3 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02343v1",
      "published_date": "2024-09-04 00:10:36 UTC",
      "updated_date": "2024-09-04 00:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T21:31:06.101187"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 79,
  "processed_papers_count": 79,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T21:31:32.813577"
}