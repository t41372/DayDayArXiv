[
  {
    "arxiv_id": "2405.05467v1",
    "title": "AFEN: Respiratory Disease Classification using Ensemble Learning",
    "authors": [
      "Rahul Nadkarni",
      "Emmanouil Nikolakakis",
      "Razvan Marinescu"
    ],
    "abstract": "We present AFEN (Audio Feature Ensemble Learning), a model that leverages\nConvolutional Neural Networks (CNN) and XGBoost in an ensemble learning fashion\nto perform state-of-the-art audio classification for a range of respiratory\ndiseases. We use a meticulously selected mix of audio features which provide\nthe salient attributes of the data and allow for accurate classification. The\nextracted features are then used as an input to two separate model classifiers\n1) a multi-feature CNN classifier and 2) an XGBoost Classifier. The outputs of\nthe two models are then fused with the use of soft voting. Thus, by exploiting\nensemble learning, we achieve increased robustness and accuracy. We evaluate\nthe performance of the model on a database of 920 respiratory sounds, which\nundergoes data augmentation techniques to increase the diversity of the data\nand generalizability of the model. We empirically verify that AFEN sets a new\nstate-of-the-art using Precision and Recall as metrics, while decreasing\ntraining time by 60%.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Under Review Process for MLForHC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05467v1",
    "published_date": "2024-05-08 23:50:54 UTC",
    "updated_date": "2024-05-08 23:50:54 UTC"
  },
  {
    "arxiv_id": "2405.05466v2",
    "title": "Poser: Unmasking Alignment Faking LLMs by Manipulating Their Internals",
    "authors": [
      "Joshua Clymer",
      "Caden Juang",
      "Severin Field"
    ],
    "abstract": "Like a criminal under investigation, Large Language Models (LLMs) might\npretend to be aligned while evaluated and misbehave when they have a good\nopportunity. Can current interpretability methods catch these 'alignment\nfakers?' To answer this question, we introduce a benchmark that consists of 324\npairs of LLMs fine-tuned to select actions in role-play scenarios. One model in\neach pair is consistently benign (aligned). The other model misbehaves in\nscenarios where it is unlikely to be caught (alignment faking). The task is to\nidentify the alignment faking model using only inputs where the two models\nbehave identically. We test five detection strategies, one of which identifies\n98% of alignment-fakers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05466v2",
    "published_date": "2024-05-08 23:44:08 UTC",
    "updated_date": "2024-05-11 04:45:59 UTC"
  },
  {
    "arxiv_id": "2405.05465v2",
    "title": "Vidur: A Large-Scale Simulation Framework For LLM Inference",
    "authors": [
      "Amey Agrawal",
      "Nitin Kedia",
      "Jayashree Mohan",
      "Ashish Panwar",
      "Nipun Kwatra",
      "Bhargav Gulavani",
      "Ramachandran Ramjee",
      "Alexey Tumanov"
    ],
    "abstract": "Optimizing the deployment of Large language models (LLMs) is expensive today\nsince it requires experimentally running an application workload against an LLM\nimplementation while exploring large configuration space formed by system knobs\nsuch as parallelization strategies, batching techniques, and scheduling\npolicies. To address this challenge, we present Vidur - a large-scale,\nhigh-fidelity, easily-extensible simulation framework for LLM inference\nperformance. Vidur models the performance of LLM operators using a combination\nof experimental profiling and predictive modeling, and evaluates the end-to-end\ninference performance for different workloads by estimating several metrics of\ninterest such as latency and throughput. We validate the fidelity of Vidur on\nseveral LLMs and show that it estimates inference latency with less than 9%\nerror across the range. Further, we present Vidur-Search, a configuration\nsearch tool that helps optimize LLM deployment. Vidur-Search uses Vidur to\nautomatically identify the most cost-effective deployment configuration that\nmeets application performance constraints. For example, Vidur-Search finds the\nbest deployment configuration for LLaMA2-70B in one hour on a CPU machine, in\ncontrast to a deployment-based exploration which would require 42K GPU hours -\ncosting ~218K dollars. Source code for Vidur is available at\nhttps://github.com/microsoft/vidur.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05465v2",
    "published_date": "2024-05-08 23:42:13 UTC",
    "updated_date": "2024-05-21 05:17:29 UTC"
  },
  {
    "arxiv_id": "2405.05446v1",
    "title": "GDGS: Gradient Domain Gaussian Splatting for Sparse Representation of Radiance Fields",
    "authors": [
      "Yuanhao Gong"
    ],
    "abstract": "The 3D Gaussian splatting methods are getting popular. However, they work\ndirectly on the signal, leading to a dense representation of the signal. Even\nwith some techniques such as pruning or distillation, the results are still\ndense. In this paper, we propose to model the gradient of the original signal.\nThe gradients are much sparser than the original signal. Therefore, the\ngradients use much less Gaussian splats, leading to the more efficient storage\nand thus higher computational performance during both training and rendering.\nThanks to the sparsity, during the view synthesis, only a small mount of pixels\nare needed, leading to much higher computational performance ($100\\sim\n1000\\times$ faster). And the 2D image can be recovered from the gradients via\nsolving a Poisson equation with linear computation complexity. Several\nexperiments are performed to confirm the sparseness of the gradients and the\ncomputation performance of the proposed method. The method can be applied\nvarious applications, such as human body modeling and indoor environment\nmodeling.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2404.09105",
    "pdf_url": "http://arxiv.org/pdf/2405.05446v1",
    "published_date": "2024-05-08 22:40:52 UTC",
    "updated_date": "2024-05-08 22:40:52 UTC"
  },
  {
    "arxiv_id": "2405.05444v1",
    "title": "Evaluating Students' Open-ended Written Responses with LLMs: Using the RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large",
    "authors": [
      "Jussi S. Jauhiainen",
      "Agustín Garagorry Guerra"
    ],
    "abstract": "Evaluating open-ended written examination responses from students is an\nessential yet time-intensive task for educators, requiring a high degree of\neffort, consistency, and precision. Recent developments in Large Language\nModels (LLMs) present a promising opportunity to balance the need for thorough\nevaluation with efficient use of educators' time. In our study, we explore the\neffectiveness of LLMs ChatGPT-3.5, ChatGPT-4, Claude-3, and Mistral-Large in\nassessing university students' open-ended answers to questions made about\nreference material they have studied. Each model was instructed to evaluate 54\nanswers repeatedly under two conditions: 10 times (10-shot) with a temperature\nsetting of 0.0 and 10 times with a temperature of 0.5, expecting a total of\n1,080 evaluations per model and 4,320 evaluations across all models. The RAG\n(Retrieval Augmented Generation) framework was used as the framework to make\nthe LLMs to process the evaluation of the answers. As of spring 2024, our\nanalysis revealed notable variations in consistency and the grading outcomes\nprovided by studied LLMs. There is a need to comprehend strengths and\nweaknesses of LLMs in educational settings for evaluating open-ended written\nresponses. Further comparative research is essential to determine the accuracy\nand cost-effectiveness of using LLMs for educational assessments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 6 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2405.05444v1",
    "published_date": "2024-05-08 22:23:58 UTC",
    "updated_date": "2024-05-08 22:23:58 UTC"
  },
  {
    "arxiv_id": "2405.05439v2",
    "title": "How Generalizable Is My Behavior Cloning Policy? A Statistical Approach to Trustworthy Performance Evaluation",
    "authors": [
      "Joseph A. Vincent",
      "Haruki Nishimura",
      "Masha Itkina",
      "Paarth Shah",
      "Mac Schwager",
      "Thomas Kollar"
    ],
    "abstract": "With the rise of stochastic generative models in robot policy learning,\nend-to-end visuomotor policies are increasingly successful at solving complex\ntasks by learning from human demonstrations. Nevertheless, since real-world\nevaluation costs afford users only a small number of policy rollouts, it\nremains a challenge to accurately gauge the performance of such policies. This\nis exacerbated by distribution shifts causing unpredictable changes in\nperformance during deployment. To rigorously evaluate behavior cloning\npolicies, we present a framework that provides a tight lower-bound on robot\nperformance in an arbitrary environment, using a minimal number of experimental\npolicy rollouts. Notably, by applying the standard stochastic ordering to robot\nperformance distributions, we provide a worst-case bound on the entire\ndistribution of performance (via bounds on the cumulative distribution\nfunction) for a given task. We build upon established statistical results to\nensure that the bounds hold with a user-specified confidence level and\ntightness, and are constructed from as few policy rollouts as possible. In\nexperiments we evaluate policies for visuomotor manipulation in both simulation\nand hardware. Specifically, we (i) empirically validate the guarantees of the\nbounds in simulated manipulation settings, (ii) find the degree to which a\nlearned policy deployed on hardware generalizes to new real-world environments,\nand (iii) rigorously compare two policies tested in out-of-distribution\nsettings. Our experimental data, code, and implementation of confidence bounds\nare open-source.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.RO",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.05439v2",
    "published_date": "2024-05-08 22:00:35 UTC",
    "updated_date": "2024-07-18 18:45:25 UTC"
  },
  {
    "arxiv_id": "2405.05435v1",
    "title": "Analysis and prevention of AI-based phishing email attacks",
    "authors": [
      "Chibuike Samuel Eze",
      "Lior Shamir"
    ],
    "abstract": "Phishing email attacks are among the most common and most harmful\ncybersecurity attacks. With the emergence of generative AI, phishing attacks\ncan be based on emails generated automatically, making it more difficult to\ndetect them. That is, instead of a single email format sent to a large number\nof recipients, generative AI can be used to send each potential victim a\ndifferent email, making it more difficult for cybersecurity systems to identify\nthe scam email before it reaches the recipient. Here we describe a corpus of\nAI-generated phishing emails. We also use different machine learning tools to\ntest the ability of automatic text analysis to identify AI-generated phishing\nemails. The results are encouraging, and show that machine learning tools can\nidentify an AI-generated phishing email with high accuracy compared to regular\nemails or human-generated scam email. By applying descriptive analytic, the\nspecific differences between AI-generated emails and manually crafted scam\nemails are profiled, and show that AI-generated emails are different in their\nstyle from human-generated phishing email scams. Therefore, automatic\nidentification tools can be used as a warning for the user. The paper also\ndescribes the corpus of AI-generated phishing emails that is made open to the\npublic, and can be used for consequent studies. While the ability of machine\nlearning to detect AI-generated phishing email is encouraging, AI-generated\nphishing emails are different from regular phishing emails, and therefore it is\nimportant to train machine learning systems also with AI-generated emails in\norder to repel future phishing attacks that are powered by generative AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Electronics, accepted",
    "pdf_url": "http://arxiv.org/pdf/2405.05435v1",
    "published_date": "2024-05-08 21:40:49 UTC",
    "updated_date": "2024-05-08 21:40:49 UTC"
  },
  {
    "arxiv_id": "2405.05431v2",
    "title": "Searching for Programmatic Policies in Semantic Spaces",
    "authors": [
      "Rubens O. Moraes",
      "Levi H. S. Lelis"
    ],
    "abstract": "Syntax-guided synthesis is commonly used to generate programs encoding\npolicies. In this approach, the set of programs, that can be written in a\ndomain-specific language defines the search space, and an algorithm searches\nwithin this space for programs that encode strong policies. In this paper, we\npropose an alternative method for synthesizing programmatic policies, where we\nsearch within an approximation of the language's semantic space. We\nhypothesized that searching in semantic spaces is more sample-efficient\ncompared to syntax-based spaces. Our rationale is that the search is more\nefficient if the algorithm evaluates different agent behaviors as it searches\nthrough the space, a feature often missing in syntax-based spaces. This is\nbecause small changes in the syntax of a program often do not result in\ndifferent agent behaviors. We define semantic spaces by learning a library of\nprograms that present different agent behaviors. Then, we approximate the\nsemantic space by defining a neighborhood function for local search algorithms,\nwhere we replace parts of the current candidate program with programs from the\nlibrary. We evaluated our hypothesis in a real-time strategy game called\nMicroRTS. Empirical results support our hypothesis that searching in semantic\nspaces can be more sample-efficient than searching in syntax-based spaces.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "Available code:\n  https://github.com/rubensolv/Library-Induced-Semantic-Spaces",
    "pdf_url": "http://arxiv.org/pdf/2405.05431v2",
    "published_date": "2024-05-08 21:24:49 UTC",
    "updated_date": "2024-06-12 18:54:02 UTC"
  },
  {
    "arxiv_id": "2405.05429v3",
    "title": "How Inverse Conditional Flows Can Serve as a Substitute for Distributional Regression",
    "authors": [
      "Lucas Kook",
      "Chris Kolb",
      "Philipp Schiele",
      "Daniel Dold",
      "Marcel Arpogaus",
      "Cornelius Fritz",
      "Philipp F. Baumann",
      "Philipp Kopper",
      "Tobias Pielok",
      "Emilio Dorigatti",
      "David Rügamer"
    ],
    "abstract": "Neural network representations of simple models, such as linear regression,\nare being studied increasingly to better understand the underlying principles\nof deep learning algorithms. However, neural representations of distributional\nregression models, such as the Cox model, have received little attention so\nfar. We close this gap by proposing a framework for distributional regression\nusing inverse flow transformations (DRIFT), which includes neural\nrepresentations of the aforementioned models. We empirically demonstrate that\nthe neural representations of models in DRIFT can serve as a substitute for\ntheir classical statistical counterparts in several applications involving\ncontinuous, ordered, time-series, and survival outcomes. We confirm that models\nin DRIFT empirically match the performance of several statistical methods in\nterms of estimation of partial effects, prediction, and aleatoric uncertainty\nquantification. DRIFT covers both interpretable statistical models and flexible\nneural networks opening up new avenues in both statistical modeling and deep\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.CO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at UAI 2024 https://www.auai.org/uai2024/accepted_papers",
    "pdf_url": "http://arxiv.org/pdf/2405.05429v3",
    "published_date": "2024-05-08 21:19:18 UTC",
    "updated_date": "2024-07-10 08:47:05 UTC"
  },
  {
    "arxiv_id": "2406.06544v2",
    "title": "TSB: Tiny Shared Block for Efficient DNN Deployment on NVCIM Accelerators",
    "authors": [
      "Yifan Qin",
      "Zheyu Yan",
      "Zixuan Pan",
      "Wujie Wen",
      "Xiaobo Sharon Hu",
      "Yiyu Shi"
    ],
    "abstract": "Compute-in-memory (CIM) accelerators using non-volatile memory (NVM) devices\noffer promising solutions for energy-efficient and low-latency Deep Neural\nNetwork (DNN) inference execution. However, practical deployment is often\nhindered by the challenge of dealing with the massive amount of model weight\nparameters impacted by the inherent device variations within non-volatile\ncomputing-in-memory (NVCIM) accelerators. This issue significantly offsets\ntheir advantages by increasing training overhead, the time and energy needed\nfor mapping weights to device states, and diminishing inference accuracy. To\nmitigate these challenges, we propose the \"Tiny Shared Block (TSB)\" method,\nwhich integrates a small shared 1x1 convolution block into the DNN\narchitecture. This block is designed to stabilize feature processing across the\nnetwork, effectively reducing the impact of device variation. Extensive\nexperimental results show that TSB achieves over 20x inference accuracy gap\nimprovement, over 5x training speedup, and weights-to-device mapping cost\nreduction while requiring less than 0.4% of the original weights to be\nwrite-verified during programming, when compared with state-of-the-art baseline\nsolutions. Our approach provides a practical and efficient solution for\ndeploying robust DNN models on NVCIM accelerators, making it a valuable\ncontribution to the field of energy-efficient AI hardware.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "9 pages, accepted to IEEE/ACM International Conference on\n  Computer-Aided Design (ICCAD 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.06544v2",
    "published_date": "2024-05-08 20:53:38 UTC",
    "updated_date": "2024-08-21 18:11:17 UTC"
  },
  {
    "arxiv_id": "2405.09567v1",
    "title": "ECG-SMART-NET: A Deep Learning Architecture for Precise ECG Diagnosis of Occlusion Myocardial Infarction",
    "authors": [
      "Nathan T. Riek",
      "Murat Akcakaya",
      "Zeineb Bouzid",
      "Tanmay Gokhale",
      "Stephanie Helman",
      "Karina Kraevsky-Philips",
      "Rui Qi Ji",
      "Ervin Sejdic",
      "Jessica K. Zègre-Hemsey",
      "Christian Martin-Gill",
      "Clifton W. Callaway",
      "Samir Saba",
      "Salah Al-Zaiti"
    ],
    "abstract": "In this paper we describe ECG-SMART-NET for identification of occlusion\nmyocardial infarction (OMI). OMI is a severe form of heart attack characterized\nby complete blockage of one or more coronary arteries requiring immediate\nreferral for cardiac catheterization to restore blood flow to the heart. Two\nthirds of OMI cases are difficult to visually identify from a 12-lead\nelectrocardiogram (ECG) and can be potentially fatal if not identified in a\ntimely fashion. Previous works on this topic are scarce, and current\nstate-of-the-art evidence suggests that both random forests with engineered\nfeatures and convolutional neural networks (CNNs) are promising approaches to\nimprove the ECG detection of OMI. While the ResNet architecture has been\nsuccessfully adapted for use with ECG recordings, it is not ideally suited to\ncapture informative temporal features within each lead and the spatial\nconcordance or discordance across leads. We propose a clinically informed\nmodification of the ResNet-18 architecture. The model first learns temporal\nfeatures through temporal convolutional layers with 1xk kernels followed by a\nspatial convolutional layer, after the residual blocks, with 12x1 kernels to\nlearn spatial features. The new ECG-SMART-NET was benchmarked against the\noriginal ResNet-18 and other state-of-the-art models on a multisite real-word\nclinical dataset that consists of 10,893 ECGs from 7,297 unique patients (rate\nof OMI = 6.5%). ECG-SMART-NET outperformed other models in the classification\nof OMI with a test AUC score of 0.889 +/- 0.027 and a test average precision\nscore of 0.587 +/- 0.087.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "7 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.09567v1",
    "published_date": "2024-05-08 19:59:16 UTC",
    "updated_date": "2024-05-08 19:59:16 UTC"
  },
  {
    "arxiv_id": "2405.06511v1",
    "title": "Towards Less Biased Data-driven Scoring with Deep Learning-Based End-to-end Database Search in Tandem Mass Spectrometry",
    "authors": [
      "Yonghan Yu",
      "Ming Li"
    ],
    "abstract": "Peptide identification in mass spectrometry-based proteomics is crucial for\nunderstanding protein function and dynamics. Traditional database search\nmethods, though widely used, rely on heuristic scoring functions and\nstatistical estimations have to be introduced for a higher identification rate.\nHere, we introduce DeepSearch, the first deep learning-based end-to-end\ndatabase search method for tandem mass spectrometry. DeepSearch leverages a\nmodified transformer-based encoder-decoder architecture under the contrastive\nlearning framework. Unlike conventional methods that rely on ion-to-ion\nmatching, DeepSearch adopts a data-driven approach to score peptide spectrum\nmatches. DeepSearch is also the first deep learning-based method that can\nprofile variable post-translational modifications in a zero-shot manner. We\nshowed that DeepSearch's scoring scheme expressed less bias and did not require\nany statistical estimation. We validated DeepSearch's accuracy and robustness\nacross various datasets, including those from species with diverse protein\ncompositions and a modification-enriched dataset. DeepSearch sheds new light on\ndatabase search methods in tandem mass spectrometry.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06511v1",
    "published_date": "2024-05-08 19:39:17 UTC",
    "updated_date": "2024-05-08 19:39:17 UTC"
  },
  {
    "arxiv_id": "2405.06703v1",
    "title": "Interpretable Cross-Examination Technique (ICE-T): Using highly informative features to boost LLM performance",
    "authors": [
      "Goran Muric",
      "Ben Delay",
      "Steven Minton"
    ],
    "abstract": "In this paper, we introduce the Interpretable Cross-Examination Technique\n(ICE-T), a novel approach that leverages structured multi-prompt techniques\nwith Large Language Models (LLMs) to improve classification performance over\nzero-shot and few-shot methods. In domains where interpretability is crucial,\nsuch as medicine and law, standard models often fall short due to their\n\"black-box\" nature. ICE-T addresses these limitations by using a series of\ngenerated prompts that allow an LLM to approach the problem from multiple\ndirections. The responses from the LLM are then converted into numerical\nfeature vectors and processed by a traditional classifier. This method not only\nmaintains high interpretability but also allows for smaller, less capable\nmodels to achieve or exceed the performance of larger, more advanced models\nunder zero-shot conditions. We demonstrate the effectiveness of ICE-T across a\ndiverse set of data sources, including medical records and legal documents,\nconsistently surpassing the zero-shot baseline in terms of classification\nmetrics such as F1 scores. Our results indicate that ICE-T can be used for\nimproving both the performance and transparency of AI applications in complex\ndecision-making environments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06703v1",
    "published_date": "2024-05-08 19:20:34 UTC",
    "updated_date": "2024-05-08 19:20:34 UTC"
  },
  {
    "arxiv_id": "2405.05378v1",
    "title": "\"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations",
    "authors": [
      "Preetam Prabhu Srikar Dammu",
      "Hayoung Jung",
      "Anjali Singh",
      "Monojit Choudhury",
      "Tanushree Mitra"
    ],
    "abstract": "Large language models (LLMs) have emerged as an integral part of modern\nsocieties, powering user-facing applications such as personal assistants and\nenterprise applications like recruitment tools. Despite their utility, research\nindicates that LLMs perpetuate systemic biases. Yet, prior works on LLM harms\npredominantly focus on Western concepts like race and gender, often overlooking\ncultural concepts from other parts of the world. Additionally, these studies\ntypically investigate \"harm\" as a singular dimension, ignoring the various and\nsubtle forms in which harms manifest. To address this gap, we introduce the\nCovert Harms and Social Threats (CHAST), a set of seven metrics grounded in\nsocial science literature. We utilize evaluation models aligned with human\nassessments to examine the presence of covert harms in LLM-generated\nconversations, particularly in the context of recruitment. Our experiments\nreveal that seven out of the eight LLMs included in this study generated\nconversations riddled with CHAST, characterized by malign views expressed in\nseemingly neutral language unlikely to be detected by existing methods.\nNotably, these LLMs manifested more extreme views and opinions when dealing\nwith non-Western concepts like caste, compared to Western ones such as race.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05378v1",
    "published_date": "2024-05-08 19:08:45 UTC",
    "updated_date": "2024-05-08 19:08:45 UTC"
  },
  {
    "arxiv_id": "2405.05374v1",
    "title": "Arctic-Embed: Scalable, Efficient, and Accurate Text Embedding Models",
    "authors": [
      "Luke Merrick",
      "Danmei Xu",
      "Gaurav Nuti",
      "Daniel Campos"
    ],
    "abstract": "This report describes the training dataset creation and recipe behind the\nfamily of \\texttt{arctic-embed} text embedding models (a set of five models\nranging from 22 to 334 million parameters with weights open-sourced under an\nApache-2 license). At the time of their release, each model achieved\nstate-of-the-art retrieval accuracy for models of their size on the MTEB\nRetrieval leaderboard, with the largest model, arctic-embed-l outperforming\nclosed source embedding models such as Cohere's embed-v3 and Open AI's\ntext-embed-3-large. In addition to the details of our training recipe, we have\nprovided several informative ablation studies, which we believe are the cause\nof our model performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 11 Figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.05374v1",
    "published_date": "2024-05-08 19:05:18 UTC",
    "updated_date": "2024-05-08 19:05:18 UTC"
  },
  {
    "arxiv_id": "2407.01561v1",
    "title": "Synthetic Data in Radiological Imaging: Current State and Future Outlook",
    "authors": [
      "Elena Sizikova",
      "Andreu Badal",
      "Jana G. Delfino",
      "Miguel Lago",
      "Brandon Nelson",
      "Niloufar Saharkhiz",
      "Berkman Sahiner",
      "Ghada Zamzmi",
      "Aldo Badano"
    ],
    "abstract": "A key challenge for the development and deployment of artificial intelligence\n(AI) solutions in radiology is solving the associated data limitations.\nObtaining sufficient and representative patient datasets with appropriate\nannotations may be burdensome due to high acquisition cost, safety limitations,\npatient privacy restrictions or low disease prevalence rates. In silico data\noffers a number of potential advantages to patient data, such as diminished\npatient harm, reduced cost, simplified data acquisition, scalability, improved\nquality assurance testing, and a mitigation approach to data imbalances. We\nsummarize key research trends and practical uses for synthetically generated\ndata for radiological applications of AI. Specifically, we discuss different\ntypes of techniques for generating synthetic examples, their main application\nareas, and related quality control assessment issues. We also discuss current\napproaches for evaluating synthetic imaging data. Overall, synthetic data holds\ngreat promise in addressing current data availability gaps, but additional work\nis needed before its full potential is realized.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Provisionally accepted to the British Journal of Radiology (BJR)\n  Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2407.01561v1",
    "published_date": "2024-05-08 18:35:47 UTC",
    "updated_date": "2024-05-08 18:35:47 UTC"
  },
  {
    "arxiv_id": "2405.05349v1",
    "title": "Offline Model-Based Optimization via Policy-Guided Gradient Search",
    "authors": [
      "Yassine Chemingui",
      "Aryan Deshwal",
      "Trong Nghia Hoang",
      "Janardhan Rao Doppa"
    ],
    "abstract": "Offline optimization is an emerging problem in many experimental engineering\ndomains including protein, drug or aircraft design, where online\nexperimentation to collect evaluation data is too expensive or dangerous. To\navoid that, one has to optimize an unknown function given only its offline\nevaluation at a fixed set of inputs. A naive solution to this problem is to\nlearn a surrogate model of the unknown function and optimize this surrogate\ninstead. However, such a naive optimizer is prone to erroneous overestimation\nof the surrogate (possibly due to over-fitting on a biased sample of function\nevaluation) on inputs outside the offline dataset. Prior approaches addressing\nthis challenge have primarily focused on learning robust surrogate models.\nHowever, their search strategies are derived from the surrogate model rather\nthan the actual offline data. To fill this important gap, we introduce a new\nlearning-to-search perspective for offline optimization by reformulating it as\nan offline reinforcement learning problem. Our proposed policy-guided gradient\nsearch approach explicitly learns the best policy for a given surrogate model\ncreated from the offline data. Our empirical results on multiple benchmarks\ndemonstrate that the learned optimization policy can be combined with existing\noffline surrogates to significantly improve the optimization performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at AAAI Conference on Artificial Intelligence, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05349v1",
    "published_date": "2024-05-08 18:27:37 UTC",
    "updated_date": "2024-05-08 18:27:37 UTC"
  },
  {
    "arxiv_id": "2405.05348v1",
    "title": "The Effect of Model Size on LLM Post-hoc Explainability via LIME",
    "authors": [
      "Henning Heyen",
      "Amy Widdicombe",
      "Noah Y. Siegel",
      "Maria Perez-Ortiz",
      "Philip Treleaven"
    ],
    "abstract": "Large language models (LLMs) are becoming bigger to boost performance.\nHowever, little is known about how explainability is affected by this trend.\nThis work explores LIME explanations for DeBERTaV3 models of four different\nsizes on natural language inference (NLI) and zero-shot classification (ZSC)\ntasks. We evaluate the explanations based on their faithfulness to the models'\ninternal decision processes and their plausibility, i.e. their agreement with\nhuman explanations. The key finding is that increased model size does not\ncorrelate with plausibility despite improved model performance, suggesting a\nmisalignment between the LIME explanations and the models' internal processes\nas model size increases. Our results further suggest limitations regarding\nfaithfulness metrics in NLI contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at ICLR 2024 Workshop on Secure and Trustworthy Large\n  Language Models",
    "pdf_url": "http://arxiv.org/pdf/2405.05348v1",
    "published_date": "2024-05-08 18:27:20 UTC",
    "updated_date": "2024-05-08 18:27:20 UTC"
  },
  {
    "arxiv_id": "2405.05347v1",
    "title": "Benchmarking Educational Program Repair",
    "authors": [
      "Charles Koutcheme",
      "Nicola Dainese",
      "Sami Sarsa",
      "Juho Leinonen",
      "Arto Hellas",
      "Paul Denny"
    ],
    "abstract": "The emergence of large language models (LLMs) has sparked enormous interest\ndue to their potential application across a range of educational tasks. For\nexample, recent work in programming education has used LLMs to generate\nlearning resources, improve error messages, and provide feedback on code.\nHowever, one factor that limits progress within the field is that much of the\nresearch uses bespoke datasets and different evaluation metrics, making direct\ncomparisons between results unreliable. Thus, there is a pressing need for\nstandardization and benchmarks that facilitate the equitable comparison of\ncompeting approaches. One task where LLMs show great promise is program repair,\nwhich can be used to provide debugging support and next-step hints to students.\nIn this article, we propose a novel educational program repair benchmark. We\ncurate two high-quality publicly available programming datasets, present a\nunified evaluation procedure introducing a novel evaluation metric rouge@k for\napproximating the quality of repairs, and evaluate a set of five recent models\nto establish baseline performance.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "15 pages, 2 figures, 3 tables. Non-archival report presented at the\n  NeurIPS'23 Workshop on Generative AI for Education (GAIED)",
    "pdf_url": "http://arxiv.org/pdf/2405.05347v1",
    "published_date": "2024-05-08 18:23:59 UTC",
    "updated_date": "2024-05-08 18:23:59 UTC"
  },
  {
    "arxiv_id": "2405.05336v3",
    "title": "Joint semi-supervised and contrastive learning enables domain generalization and multi-domain segmentation",
    "authors": [
      "Alvaro Gomariz",
      "Yusuke Kikuchi",
      "Yun Yvonna Li",
      "Thomas Albrecht",
      "Andreas Maunz",
      "Daniela Ferrara",
      "Huanxiang Lu",
      "Orcun Goksel"
    ],
    "abstract": "Despite their effectiveness, current deep learning models face challenges\nwith images coming from different domains with varying appearance and content.\nWe introduce SegCLR, a versatile framework designed to segment images across\ndifferent domains, employing supervised and contrastive learning simultaneously\nto effectively learn from both labeled and unlabeled data. We demonstrate the\nsuperior performance of SegCLR through a comprehensive evaluation involving\nthree diverse clinical datasets of 3D retinal Optical Coherence Tomography\n(OCT) images, for the slice-wise segmentation of fluids with various network\nconfigurations and verification across 10 different network initializations. In\nan unsupervised domain adaptation context, SegCLR achieves results on par with\na supervised upper-bound model trained on the intended target domain. Notably,\nwe discover that the segmentation performance of SegCLR framework is marginally\nimpacted by the abundance of unlabeled data from the target domain, thereby we\nalso propose an effective domain generalization extension of SegCLR, known also\nas zero-shot domain adaptation, which eliminates the need for any target domain\ninformation. This shows that our proposed addition of contrastive loss in\nstandard supervised training for segmentation leads to superior models,\ninherently more generalizable to both in- and out-of-domain test data. We\nadditionally propose a pragmatic solution for SegCLR deployment in realistic\nscenarios with multiple domains containing labeled data. Accordingly, our\nframework pushes the boundaries of deep-learning based segmentation in\nmulti-domain applications, regardless of data availability - labeled,\nunlabeled, or nonexistent.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05336v3",
    "published_date": "2024-05-08 18:10:59 UTC",
    "updated_date": "2025-04-14 10:51:41 UTC"
  },
  {
    "arxiv_id": "2405.10970v1",
    "title": "Untargeted Adversarial Attack on Knowledge Graph Embeddings",
    "authors": [
      "Tianzhe Zhao",
      "Jiaoyan Chen",
      "Yanchi Ru",
      "Qika Lin",
      "Yuxia Geng",
      "Jun Liu"
    ],
    "abstract": "Knowledge graph embedding (KGE) methods have achieved great success in\nhandling various knowledge graph (KG) downstream tasks. However, KGE methods\nmay learn biased representations on low-quality KGs that are prevalent in the\nreal world. Some recent studies propose adversarial attacks to investigate the\nvulnerabilities of KGE methods, but their attackers are target-oriented with\nthe KGE method and the target triples to predict are given in advance, which\nlacks practicability. In this work, we explore untargeted attacks with the aim\nof reducing the global performances of KGE methods over a set of unknown test\ntriples and conducting systematic analyses on KGE robustness. Considering logic\nrules can effectively summarize the global structure of a KG, we develop\nrule-based attack strategies to enhance the attack efficiency. In particular,we\nconsider adversarial deletion which learns rules, applying the rules to score\ntriple importance and delete important triples, and adversarial addition which\ncorrupts the learned rules and applies them for negative triples as\nperturbations. Extensive experiments on two datasets over three representative\nclasses of KGE methods demonstrate the effectiveness of our proposed untargeted\nattacks in diminishing the link prediction results. And we also find that\ndifferent KGE methods exhibit different robustness to untargeted attacks. For\nexample, the robustness of methods engaged with graph neural networks and logic\nrules depends on the density of the graph. But rule-based methods like NCRL are\neasily affected by adversarial addition attacks to capture negative rules",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SIGIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.10970v1",
    "published_date": "2024-05-08 18:08:11 UTC",
    "updated_date": "2024-05-08 18:08:11 UTC"
  },
  {
    "arxiv_id": "2405.05329v2",
    "title": "KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation",
    "authors": [
      "Minsik Cho",
      "Mohammad Rastegari",
      "Devang Naik"
    ],
    "abstract": "Large Language Model or LLM inference has two phases, the prompt (or prefill)\nphase to output the first token and the extension (or decoding) phase to the\ngenerate subsequent tokens. In this work, we propose an efficient\nparallelization scheme, KV-Runahead to accelerate the prompt phase. The key\nobservation is that the extension phase generates tokens faster than the prompt\nphase because of key-value cache (KV-cache). Hence, KV-Runahead parallelizes\nthe prompt phase by orchestrating multiple processes to populate the KV-cache\nand minimizes the time-to-first-token (TTFT). Dual-purposing the KV-cache\nscheme has two main benefits. First, since KV-cache is designed to leverage the\ncausal attention map, we minimize computation and computation automatically.\nSecond, since it already exists for the extension phase, KV-Runahead is easy to\nimplement. We further propose context-level load-balancing to handle uneven\nKV-cache generation (due to the causal attention) and to optimize TTFT.\nCompared with an existing parallelization scheme such as tensor or sequential\nparallelization where keys and values are locally generated and exchanged via\nall-gather collectives, our experimental results demonstrate that KV-Runahead\ncan offer over 1.4x and 1.6x speedups for Llama 7B and Falcon 7B respectively.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DC",
    "comment": "preprint for ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05329v2",
    "published_date": "2024-05-08 18:03:22 UTC",
    "updated_date": "2024-05-13 18:32:37 UTC"
  },
  {
    "arxiv_id": "2405.05256v2",
    "title": "THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models",
    "authors": [
      "Prannay Kaul",
      "Zhizhong Li",
      "Hao Yang",
      "Yonatan Dukler",
      "Ashwin Swaminathan",
      "C. J. Taylor",
      "Stefano Soatto"
    ],
    "abstract": "Mitigating hallucinations in large vision-language models (LVLMs) remains an\nopen problem. Recent benchmarks do not address hallucinations in open-ended\nfree-form responses, which we term \"Type I hallucinations\". Instead, they focus\non hallucinations responding to very specific question formats -- typically a\nmultiple-choice response regarding a particular object or attribute -- which we\nterm \"Type II hallucinations\". Additionally, such benchmarks often require\nexternal API calls to models which are subject to change. In practice, we\nobserve that a reduction in Type II hallucinations does not lead to a reduction\nin Type I hallucinations but rather that the two forms of hallucinations are\noften anti-correlated. To address this, we propose THRONE, a novel object-based\nautomatic framework for quantitatively evaluating Type I hallucinations in LVLM\nfree-form outputs. We use public language models (LMs) to identify\nhallucinations in LVLM responses and compute informative metrics. By evaluating\na large selection of recent LVLMs using public datasets, we show that an\nimprovement in existing metrics do not lead to a reduction in Type I\nhallucinations, and that established benchmarks for measuring Type I\nhallucinations are incomplete. Finally, we provide a simple and effective data\naugmentation method to reduce Type I and Type II hallucinations as a strong\nbaseline. Code is now available at https://github.com/amazon-science/THRONE .",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "In CVPR 2024. Code https://github.com/amazon-science/THRONE",
    "pdf_url": "http://arxiv.org/pdf/2405.05256v2",
    "published_date": "2024-05-08 17:59:11 UTC",
    "updated_date": "2025-04-03 17:59:23 UTC"
  },
  {
    "arxiv_id": "2405.05253v1",
    "title": "Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge",
    "authors": [
      "Charles Koutcheme",
      "Nicola Dainese",
      "Sami Sarsa",
      "Arto Hellas",
      "Juho Leinonen",
      "Paul Denny"
    ],
    "abstract": "Large language models (LLMs) have shown great potential for the automatic\ngeneration of feedback in a wide range of computing contexts. However, concerns\nhave been voiced around the privacy and ethical implications of sending student\nwork to proprietary models. This has sparked considerable interest in the use\nof open source LLMs in education, but the quality of the feedback that such\nopen models can produce remains understudied. This is a concern as providing\nflawed or misleading generated feedback could be detrimental to student\nlearning. Inspired by recent work that has utilised very powerful LLMs, such as\nGPT-4, to evaluate the outputs produced by less powerful models, we conduct an\nautomated analysis of the quality of the feedback produced by several open\nsource models using a dataset from an introductory programming course. First,\nwe investigate the viability of employing GPT-4 as an automated evaluator by\ncomparing its evaluations with those of a human expert. We observe that GPT-4\ndemonstrates a bias toward positively rating feedback while exhibiting moderate\nagreement with human raters, showcasing its potential as a feedback evaluator.\nSecond, we explore the quality of feedback generated by several leading\nopen-source LLMs by using GPT-4 to evaluate the feedback. We find that some\nmodels offer competitive performance with popular proprietary LLMs, such as\nChatGPT, indicating opportunities for their responsible use in educational\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 4 figures, 2 tables. Accepted for publication at the 29th\n  annual ACM conference on Innovation and Technology in Computer Science\n  Education (ITiCSE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.05253v1",
    "published_date": "2024-05-08 17:57:39 UTC",
    "updated_date": "2024-05-08 17:57:39 UTC"
  },
  {
    "arxiv_id": "2405.05252v1",
    "title": "Attention-Driven Training-Free Efficiency Enhancement of Diffusion Models",
    "authors": [
      "Hongjie Wang",
      "Difan Liu",
      "Yan Kang",
      "Yijun Li",
      "Zhe Lin",
      "Niraj K. Jha",
      "Yuchen Liu"
    ],
    "abstract": "Diffusion Models (DMs) have exhibited superior performance in generating\nhigh-quality and diverse images. However, this exceptional performance comes at\nthe cost of expensive architectural design, particularly due to the attention\nmodule heavily used in leading models. Existing works mainly adopt a retraining\nprocess to enhance DM efficiency. This is computationally expensive and not\nvery scalable. To this end, we introduce the Attention-driven Training-free\nEfficient Diffusion Model (AT-EDM) framework that leverages attention maps to\nperform run-time pruning of redundant tokens, without the need for any\nretraining. Specifically, for single-denoising-step pruning, we develop a novel\nranking algorithm, Generalized Weighted Page Rank (G-WPR), to identify\nredundant tokens, and a similarity-based recovery method to restore tokens for\nthe convolution operation. In addition, we propose a Denoising-Steps-Aware\nPruning (DSAP) approach to adjust the pruning budget across different denoising\ntimesteps for better generation quality. Extensive evaluations show that AT-EDM\nperforms favorably against prior art in terms of efficiency (e.g., 38.8% FLOPs\nsaving and up to 1.53x speed-up over Stable Diffusion XL) while maintaining\nnearly the same FID and CLIP scores as the full model. Project webpage:\nhttps://atedm.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition (CVPR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05252v1",
    "published_date": "2024-05-08 17:56:47 UTC",
    "updated_date": "2024-05-08 17:56:47 UTC"
  },
  {
    "arxiv_id": "2405.05248v2",
    "title": "LLMs with Personalities in Multi-issue Negotiation Games",
    "authors": [
      "Sean Noh",
      "Ho-Chun Herbert Chang"
    ],
    "abstract": "Powered by large language models (LLMs), AI agents have become capable of\nmany human tasks. Using the most canonical definitions of the Big Five\npersonality, we measure the ability of LLMs to negotiate within a\ngame-theoretical framework, as well as methodological challenges to measuring\nnotions of fairness and risk. Simulations (n=1,500) for both single-issue and\nmulti-issue negotiation reveal increase in domain complexity with asymmetric\nissue valuations improve agreement rates but decrease surplus from aggressive\nnegotiation. Through gradient-boosted regression and Shapley explainers, we\nfind high openness, conscientiousness, and neuroticism are associated with fair\ntendencies; low agreeableness and low openness are associated with rational\ntendencies. Low conscientiousness is associated with high toxicity. These\nresults indicate that LLMs may have built-in guardrails that default to fair\nbehavior, but can be \"jail broken\" to exploit agreeable opponents. We also\noffer pragmatic insight in how negotiation bots can be designed, and a\nframework of assessing negotiation behavior based on game theory and\ncomputational social science.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05248v2",
    "published_date": "2024-05-08 17:51:53 UTC",
    "updated_date": "2024-05-09 01:09:09 UTC"
  },
  {
    "arxiv_id": "2405.05244v1",
    "title": "SVDD Challenge 2024: A Singing Voice Deepfake Detection Challenge Evaluation Plan",
    "authors": [
      "You Zhang",
      "Yongyi Zang",
      "Jiatong Shi",
      "Ryuichi Yamamoto",
      "Jionghao Han",
      "Yuxun Tang",
      "Tomoki Toda",
      "Zhiyao Duan"
    ],
    "abstract": "The rapid advancement of AI-generated singing voices, which now closely mimic\nnatural human singing and align seamlessly with musical scores, has led to\nheightened concerns for artists and the music industry. Unlike spoken voice,\nsinging voice presents unique challenges due to its musical nature and the\npresence of strong background music, making singing voice deepfake detection\n(SVDD) a specialized field requiring focused attention. To promote SVDD\nresearch, we recently proposed the \"SVDD Challenge,\" the very first research\nchallenge focusing on SVDD for lab-controlled and in-the-wild bonafide and\ndeepfake singing voice recordings. The challenge will be held in conjunction\nwith the 2024 IEEE Spoken Language Technology Workshop (SLT 2024).",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Evaluation plan of the SVDD Challenge @ SLT 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05244v1",
    "published_date": "2024-05-08 17:40:12 UTC",
    "updated_date": "2024-05-08 17:40:12 UTC"
  },
  {
    "arxiv_id": "2405.05219v2",
    "title": "Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers",
    "authors": [
      "Yingyu Liang",
      "Heshan Liu",
      "Zhenmei Shi",
      "Zhao Song",
      "Zhuoyan Xu",
      "Junze Yin"
    ],
    "abstract": "The self-attention mechanism is the key to the success of transformers in\nrecent Large Language Models (LLMs). However, the quadratic computational cost\n$O(n^2)$ in the input sequence length $n$ is a notorious obstacle for further\nimprovement and scalability in longer contexts. In this work, we leverage the\nconvolution-like structure of attention matrices to develop an efficient\napproximation method for attention computation using convolution matrices. We\npropose a $\\mathsf{conv}$ basis system, analogous to the rank basis, and show\nthat any lower triangular matrix can always be decomposed as a sum of\nstructured convolution matrices in this basis. We then design a fast algorithm\nto approximate the attention matrix via a sum of such $k$ convolution matrices.\nThis allows us to compute the attention {\\it inference} via Fast Fourier\nTransforms (FFT) in $O(knd \\log n)$ time, where $d$ is the hidden dimension,\nand thus achieve almost linear time $n^{1+o(1)}$ in the practical scenario\nwhere $kd = n^{o(1)}$. Furthermore, the attention {\\it training forward} and\n{\\it backward gradient} can be computed in $n^{1+o(1)}$ as well. We provide\ntheoretical guarantees on the run time and approximation error and conduct\npreliminary experiments to evaluate its effectiveness. We hope our new paradigm\nfor accelerating attention computation in transformer models can help their\napplication to longer contexts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05219v2",
    "published_date": "2024-05-08 17:11:38 UTC",
    "updated_date": "2024-10-16 06:55:47 UTC"
  },
  {
    "arxiv_id": "2405.05189v2",
    "title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning",
    "authors": [
      "Inderjeet Nair",
      "Lu Wang"
    ],
    "abstract": "We study the task of conducting structured reasoning as generating a\nreasoning graph from natural language input using large language models (LLMs).\nPrevious approaches have explored various prompting schemes, yet they suffer\nfrom error propagation due to the autoregressive nature and single-pass-based\ndecoding, which lack error correction capability. Additionally, relying solely\non a single sample may result in the omission of true nodes and edges. To\ncounter this, we draw inspiration from self-consistency (SC), which involves\nsampling a diverse set of reasoning chains and taking the majority vote as the\nfinal answer. To tackle the substantial challenge of applying SC on generated\ngraphs, we propose MIDGARD (MInimum Description length Guided Aggregation of\nReasoning in Directed acyclic graph) that leverages Minimum Description Length\n(MDL)-based formulation to identify consistent properties among the different\ngraph samples generated by an LLM. This formulation helps reject properties\nthat appear in only a few samples, which are likely to be erroneous, while\nenabling the inclusion of missing elements without compromising precision. Our\nmethod demonstrates superior performance than comparisons across various\nstructured reasoning tasks, including argument structure extraction,\nexplanation graph generation, inferring dependency relations among actions for\neveryday tasks, and semantic graph generation from natural texts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024(main)",
    "pdf_url": "http://arxiv.org/pdf/2405.05189v2",
    "published_date": "2024-05-08 16:25:42 UTC",
    "updated_date": "2024-06-02 18:47:44 UTC"
  },
  {
    "arxiv_id": "2405.05173v3",
    "title": "A Survey on Occupancy Perception for Autonomous Driving: The Information Fusion Perspective",
    "authors": [
      "Huaiyuan Xu",
      "Junliang Chen",
      "Shiyu Meng",
      "Yi Wang",
      "Lap-Pui Chau"
    ],
    "abstract": "3D occupancy perception technology aims to observe and understand dense 3D\nenvironments for autonomous vehicles. Owing to its comprehensive perception\ncapability, this technology is emerging as a trend in autonomous driving\nperception systems, and is attracting significant attention from both industry\nand academia. Similar to traditional bird's-eye view (BEV) perception, 3D\noccupancy perception has the nature of multi-source input and the necessity for\ninformation fusion. However, the difference is that it captures vertical\nstructures that are ignored by 2D BEV. In this survey, we review the most\nrecent works on 3D occupancy perception, and provide in-depth analyses of\nmethodologies with various input modalities. Specifically, we summarize general\nnetwork pipelines, highlight information fusion techniques, and discuss\neffective network training. We evaluate and analyze the occupancy perception\nperformance of the state-of-the-art on the most popular datasets. Furthermore,\nchallenges and future research directions are discussed. We hope this paper\nwill inspire the community and encourage more research work on 3D occupancy\nperception. A comprehensive list of studies in this survey is publicly\navailable in an active repository that continuously collects the latest work:\nhttps://github.com/HuaiyuanXu/3D-Occupancy-Perception.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05173v3",
    "published_date": "2024-05-08 16:10:46 UTC",
    "updated_date": "2024-07-21 12:01:28 UTC"
  },
  {
    "arxiv_id": "2405.05160v2",
    "title": "Selective Classification Under Distribution Shifts",
    "authors": [
      "Hengyue Liang",
      "Le Peng",
      "Ju Sun"
    ],
    "abstract": "In selective classification (SC), a classifier abstains from making\npredictions that are likely to be wrong to avoid excessive errors. To deploy\nimperfect classifiers -- either due to intrinsic statistical noise of data or\nfor robustness issue of the classifier or beyond -- in high-stakes scenarios,\nSC appears to be an attractive and necessary path to follow. Despite decades of\nresearch in SC, most previous SC methods still focus on the ideal statistical\nsetting only, i.e., the data distribution at deployment is the same as that of\ntraining, although practical data can come from the wild. To bridge this gap,\nin this paper, we propose an SC framework that takes into account distribution\nshifts, termed generalized selective classification, that covers label-shifted\n(or out-of-distribution) and covariate-shifted samples, in addition to typical\nin-distribution samples, the first of its kind in the SC literature. We focus\non non-training-based confidence-score functions for generalized SC on deep\nlearning (DL) classifiers, and propose two novel margin-based score functions.\nThrough extensive analysis and experiments, we show that our proposed score\nfunctions are more effective and reliable than the existing ones for\ngeneralized SC on a variety of classification tasks and DL classifiers. Code is\navailable at https://github.com/sun-umn/sc_with_distshift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted to Transactions on Machine Learning Research (TMLR),\n  issn: 2835-8856,2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05160v2",
    "published_date": "2024-05-08 15:52:50 UTC",
    "updated_date": "2024-11-27 05:48:34 UTC"
  },
  {
    "arxiv_id": "2405.05154v1",
    "title": "The Potential and Implications of Generative AI on HCI Education",
    "authors": [
      "Ahmed Kharrufa",
      "Ian G Johnson"
    ],
    "abstract": "Generative AI (GAI) is impacting teaching and learning directly or indirectly\nacross a range of subjects and disciplines. As educators, we need to understand\nthe potential and limitations of AI in HCI education and ensure our graduating\nHCI students are aware of the potential and limitations of AI in HCI. In this\npaper, we report on the main pedagogical insights gained from the inclusion of\ngenerative AI into a 10 week undergraduate module. We designed the module to\nencourage student experimentation with GAI models as part of the design brief\nrequirement and planned practical sessions and discussions. Our insights are\nbased on replies to a survey sent out to the students after completing the\nmodule. Our key findings, for HCI educators, report on the use of AI as a\npersona for developing project ideas and creating resources for design, and AI\nas a mirror for reflecting students' understanding of key concepts and ideas\nand highlighting knowledge gaps. We also discuss potential pitfalls that should\nbe considered and the need to assess students' literacies and assumptions of\nGAIs as pedagogical tools. Finally, we put forward the case for educators to\ntake the opportunities GAI presents as an educational tool and be experimental,\ncreative, and courageous in their practice. We end with a discussion of our\nfindings in relation to the TPACK framework in HCI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "14 pages, 2 figures, to be published at EduCHI 2024 The 6th Annual\n  Symposium on HCI Education, June 2024, New York, NY",
    "pdf_url": "http://arxiv.org/pdf/2405.05154v1",
    "published_date": "2024-05-08 15:46:31 UTC",
    "updated_date": "2024-05-08 15:46:31 UTC"
  },
  {
    "arxiv_id": "2405.05146v2",
    "title": "Hybrid Convolutional Neural Networks with Reliability Guarantee",
    "authors": [
      "Hans Dermot Doran",
      "Suzana Veljanovska"
    ],
    "abstract": "Making AI safe and dependable requires the generation of dependable models\nand dependable execution of those models. We propose redundant execution as a\nwell-known technique that can be used to ensure reliable execution of the AI\nmodel. This generic technique will extend the application scope of\nAI-accelerators that do not feature well-documented safety or dependability\nproperties. Typical redundancy techniques incur at least double or triple the\ncomputational expense of the original. We adopt a co-design approach,\nintegrating reliable model execution with non-reliable execution, focusing that\nadditional computational expense only where it is strictly necessary. We\ndescribe the design, implementation and some preliminary results of a hybrid\nCNN.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "2024 54th Annual IEEE/IFIP International Conference on Dependable\n  Systems and Networks (DSN 2024). Dependable and Secure Machine Learning\n  Workshop (DSML 2024), Brisbane, Australia, June 24-27, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05146v2",
    "published_date": "2024-05-08 15:39:38 UTC",
    "updated_date": "2024-05-09 09:31:36 UTC"
  },
  {
    "arxiv_id": "2407.11972v1",
    "title": "An efficient machine learning approach for extracting eSports players distinguishing features and classifying their skill levels using symbolic transfer entropy and consensus nested cross validation",
    "authors": [
      "Amin Noroozi",
      "Mohammad S. Hasan",
      "Maryam Ravan",
      "Elham Norouzi",
      "Ying-Ying Law"
    ],
    "abstract": "Discovering features that set elite players apart is of great significance\nfor eSports coaches as it enables them to arrange a more effective training\nprogram focused on improving those features. Moreover, finding such features\nresults in a better evaluation of eSports players skills, which, besides\ncoaches, is of interest for game developers to design games automatically\nadaptable to the players expertise. Sensor data combined with machine learning\nhave already proved effective in classifying eSports players. However, the\nexisting methods do not provide sufficient information about features that\ndistinguish high-skilled players. In this paper, we propose an efficient method\nto find these features and then use them to classify players' skill levels. We\nfirst apply a time window to extract the players' sensor data, including heart\nrate, hand activities, etc., before and after game events in the League of\nLegends game. We use the extracted segments and symbolic transfer entropy to\ncalculate connectivity features between sensors. The most relevant features are\nthen selected using the newly developed consensus nested cross validation\nmethod. These features, representing the harmony between body parts, are\nfinally used to find the optimum window size and classify players' skills. The\nclassification results demonstrate a significant improvement by achieving 90.1%\naccuracy. Also, connectivity features between players gaze positions and\nkeyboard, mouse, and hand activities were the most distinguishing features in\nclassifying players' skills. The proposed method in this paper can be similarly\napplied to sportspeople data and potentially revolutionize the training\nprograms in both eSports and sports industries",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11972v1",
    "published_date": "2024-05-08 15:22:12 UTC",
    "updated_date": "2024-05-08 15:22:12 UTC"
  },
  {
    "arxiv_id": "2405.05109v2",
    "title": "QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs",
    "authors": [
      "Weijia Zhang",
      "Vaishali Pal",
      "Jia-Hong Huang",
      "Evangelos Kanoulas",
      "Maarten de Rijke"
    ],
    "abstract": "Table summarization is a crucial task aimed at condensing information from\ntabular data into concise and comprehensible textual summaries. However,\nexisting approaches often fall short of adequately meeting users' information\nand quality requirements and tend to overlook the complexities of real-world\nqueries. In this paper, we propose a novel method to address these limitations\nby introducing query-focused multi-table summarization. Our approach, which\ncomprises a table serialization module, a summarization controller, and a large\nlanguage model (LLM), utilizes textual queries and multiple tables to generate\nquery-dependent table summaries tailored to users' information needs. To\nfacilitate research in this area, we present a comprehensive dataset\nspecifically tailored for this task, consisting of 4909 query-summary pairs,\neach associated with multiple tables. Through extensive experiments using our\ncurated dataset, we demonstrate the effectiveness of our proposed method\ncompared to baseline approaches. Our findings offer insights into the\nchallenges of complex table reasoning for precise summarization, contributing\nto the advancement of research in query-focused multi-table summarization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by the 27th European Conference on Artificial Intelligence\n  (ECAI-2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.05109v2",
    "published_date": "2024-05-08 15:05:55 UTC",
    "updated_date": "2024-08-25 17:22:29 UTC"
  },
  {
    "arxiv_id": "2405.05080v1",
    "title": "Concerns on Bias in Large Language Models when Creating Synthetic Personae",
    "authors": [
      "Helena A. Haxvig"
    ],
    "abstract": "This position paper explores the benefits, drawbacks, and ethical\nconsiderations of incorporating synthetic personae in HCI research,\nparticularly focusing on the customization challenges beyond the limitations of\ncurrent Large Language Models (LLMs). These perspectives are derived from the\ninitial results of a sub-study employing vignettes to showcase the existence of\nbias within black-box LLMs and explore methods for manipulating them. The study\naims to establish a foundation for understanding the challenges associated with\nthese models, emphasizing the necessity of thorough testing before utilizing\nthem to create synthetic personae for HCI research.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, accepted at the \"LLM-Based Synthetic Personae and Data in\n  HCI\" workshop at CHI2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05080v1",
    "published_date": "2024-05-08 14:24:11 UTC",
    "updated_date": "2024-05-08 14:24:11 UTC"
  },
  {
    "arxiv_id": "2405.05299v1",
    "title": "Challenges for Responsible AI Design and Workflow Integration in Healthcare: A Case Study of Automatic Feeding Tube Qualification in Radiology",
    "authors": [
      "Anja Thieme",
      "Abhijith Rajamohan",
      "Benjamin Cooper",
      "Heather Groombridge",
      "Robert Simister",
      "Barney Wong",
      "Nicholas Woznitza",
      "Mark Ames Pinnock",
      "Maria Teodora Wetscherek",
      "Cecily Morrison",
      "Hannah Richardson",
      "Fernando Pérez-García",
      "Stephanie L. Hyland",
      "Shruthi Bannur",
      "Daniel C. Castro",
      "Kenza Bouzid",
      "Anton Schwaighofer",
      "Mercy Ranjit",
      "Harshita Sharma",
      "Matthew P. Lungren",
      "Ozan Oktay",
      "Javier Alvarez-Valle",
      "Aditya Nori",
      "Stephen Harris",
      "Joseph Jacob"
    ],
    "abstract": "Nasogastric tubes (NGTs) are feeding tubes that are inserted through the nose\ninto the stomach to deliver nutrition or medication. If not placed correctly,\nthey can cause serious harm, even death to patients. Recent AI developments\ndemonstrate the feasibility of robustly detecting NGT placement from Chest\nX-ray images to reduce risks of sub-optimally or critically placed NGTs being\nmissed or delayed in their detection, but gaps remain in clinical practice\nintegration. In this study, we present a human-centered approach to the problem\nand describe insights derived following contextual inquiry and in-depth\ninterviews with 15 clinical stakeholders. The interviews helped understand\nchallenges in existing workflows, and how best to align technical capabilities\nwith user needs and expectations. We discovered the trade-offs and complexities\nthat need consideration when choosing suitable workflow stages, target users,\nand design configurations for different AI proposals. We explored how to\nbalance AI benefits and risks for healthcare staff and patients within broader\norganizational and medical-legal constraints. We also identified data issues\nrelated to edge cases and data biases that affect model training and\nevaluation; how data documentation practices influence data preparation and\nlabelling; and how to measure relevant AI outcomes reliably in future\nevaluations. We discuss how our work informs design and development of AI\napplications that are clinically useful, ethical, and acceptable in real-world\nhealthcare services.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.m; I.2.m"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05299v1",
    "published_date": "2024-05-08 14:16:22 UTC",
    "updated_date": "2024-05-08 14:16:22 UTC"
  },
  {
    "arxiv_id": "2405.05072v2",
    "title": "Novel Actor-Critic Algorithm for Robust Decision Making of CAV under Delays and Loss of V2X Data",
    "authors": [
      "Zine el abidine Kherroubi"
    ],
    "abstract": "Current autonomous driving systems heavily rely on V2X communication data to\nenhance situational awareness and the cooperation between vehicles. However, a\nmajor challenge when using V2X data is that it may not be available\nperiodically because of unpredictable delays and data loss during wireless\ntransmission between road stations and the receiver vehicle. This issue should\nbe considered when designing control strategies for connected and autonomous\nvehicles. Therefore, this paper proposes a novel 'Blind Actor-Critic' algorithm\nthat guarantees robust driving performance in V2X environment with delayed\nand/or lost data. The novel algorithm incorporates three key mechanisms: a\nvirtual fixed sampling period, a combination of Temporal-Difference and Monte\nCarlo learning, and a numerical approximation of immediate reward values. To\naddress the temporal aperiodicity problem of V2X data, we first illustrate this\nchallenge. Then, we provide a detailed explanation of the Blind Actor-Critic\nalgorithm where we highlight the proposed components to compensate for the\ntemporal aperiodicity problem of V2X data. We evaluate the performance of our\nalgorithm in a simulation environment and compare it to benchmark approaches.\nThe results demonstrate that training metrics are improved compared to\nconventional actor-critic algorithms. Additionally, testing results show that\nour approach provides robust control, even under low V2X network reliability\nlevels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 10 figures, Journal paper, submitted to IEEE Transactions\n  on Intelligent Transportation Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.05072v2",
    "published_date": "2024-05-08 14:14:03 UTC",
    "updated_date": "2024-10-20 07:42:32 UTC"
  },
  {
    "arxiv_id": "2405.05066v1",
    "title": "Designing Skill-Compatible AI: Methodologies and Frameworks in Chess",
    "authors": [
      "Karim Hamade",
      "Reid McIlroy-Young",
      "Siddhartha Sen",
      "Jon Kleinberg",
      "Ashton Anderson"
    ],
    "abstract": "Powerful artificial intelligence systems are often used in settings where\nthey must interact with agents that are computationally much weaker, for\nexample when they work alongside humans or operate in complex environments\nwhere some tasks are handled by algorithms, heuristics, or other entities of\nvarying computational power. For AI agents to successfully interact in these\nsettings, however, achieving superhuman performance alone is not sufficient;\nthey also need to account for suboptimal actions or idiosyncratic style from\ntheir less-skilled counterparts. We propose a formal evaluation framework for\nassessing the compatibility of near-optimal AI with interaction partners who\nmay have much lower levels of skill; we use popular collaborative chess\nvariants as model systems to study and develop AI agents that can successfully\ninteract with lower-skill entities. Traditional chess engines designed to\noutput near-optimal moves prove to be inadequate partners when paired with\nengines of various lower skill levels in this domain, as they are not designed\nto consider the presence of other agents. We contribute three methodologies to\nexplicitly create skill-compatible AI agents in complex decision-making\nsettings, and two chess game frameworks designed to foster collaboration\nbetween powerful AI agents and less-skilled partners. On these frameworks, our\nagents outperform state-of-the-art chess AI (based on AlphaZero) despite being\nweaker in conventional chess, demonstrating that skill-compatibility is a\ntangible trait that is qualitatively and measurably distinct from raw\nperformance. Our evaluations further explore and clarify the mechanisms by\nwhich our agents achieve skill-compatibility.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures, 15 tables, Published In The Twelfth\n  International Conference on Learning Representations, ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05066v1",
    "published_date": "2024-05-08 14:04:35 UTC",
    "updated_date": "2024-05-08 14:04:35 UTC"
  },
  {
    "arxiv_id": "2405.05027v1",
    "title": "StyleMamba : State Space Model for Efficient Text-driven Image Style Transfer",
    "authors": [
      "Zijia Wang",
      "Zhi-Song Liu"
    ],
    "abstract": "We present StyleMamba, an efficient image style transfer framework that\ntranslates text prompts into corresponding visual styles while preserving the\ncontent integrity of the original images. Existing text-guided stylization\nrequires hundreds of training iterations and takes a lot of computing\nresources. To speed up the process, we propose a conditional State Space Model\nfor Efficient Text-driven Image Style Transfer, dubbed StyleMamba, that\nsequentially aligns the image features to the target text prompts. To enhance\nthe local and global style consistency between text and image, we propose\nmasked and second-order directional losses to optimize the stylization\ndirection to significantly reduce the training iterations by 5 times and the\ninference time by 3 times. Extensive experiments and qualitative evaluation\nconfirm the robust and superior stylization performance of our methods compared\nto the existing baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Blind submission to ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.05027v1",
    "published_date": "2024-05-08 12:57:53 UTC",
    "updated_date": "2024-05-08 12:57:53 UTC"
  },
  {
    "arxiv_id": "2406.04349v1",
    "title": "Multimodal Approach for Harmonized System Code Prediction",
    "authors": [
      "Otmane Amel",
      "Sedrick Stassin",
      "Sidi Ahmed Mahmoudi",
      "Xavier Siebert"
    ],
    "abstract": "The rapid growth of e-commerce has placed considerable pressure on customs\nrepresentatives, prompting advanced methods. In tackling this, Artificial\nintelligence (AI) systems have emerged as a promising approach to minimize the\nrisks faced. Given that the Harmonized System (HS) code is a crucial element\nfor an accurate customs declaration, we propose a novel multimodal HS code\nprediction approach using deep learning models exploiting both image and text\nfeatures obtained through the customs declaration combined with e-commerce\nplatform information. We evaluated two early fusion methods and introduced our\nMultConcat fusion method. To the best of our knowledge, few studies analyze the\nfeaturelevel combination of text and image in the state-of-the-art for HS code\nprediction, which heightens interest in our paper and its findings. The\nexperimental results prove the effectiveness of our approach and fusion method\nwith a top-3 and top-5 accuracy of 93.5% and 98.2% respectively",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for poster presentation at ESANN 2023",
    "pdf_url": "http://arxiv.org/pdf/2406.04349v1",
    "published_date": "2024-05-08 12:48:26 UTC",
    "updated_date": "2024-05-08 12:48:26 UTC"
  },
  {
    "arxiv_id": "2405.04990v1",
    "title": "Health Index Estimation Through Integration of General Knowledge with Unsupervised Learning",
    "authors": [
      "Kristupas Bajarunas",
      "Marcia L. Baptista",
      "Kai Goebel",
      "Manuel A. Chao"
    ],
    "abstract": "Accurately estimating a Health Index (HI) from condition monitoring data (CM)\nis essential for reliable and interpretable prognostics and health management\n(PHM) in complex systems. In most scenarios, complex systems operate under\nvarying operating conditions and can exhibit different fault modes, making\nunsupervised inference of an HI from CM data a significant challenge. Hybrid\nmodels combining prior knowledge about degradation with deep learning models\nhave been proposed to overcome this challenge. However, previously suggested\nhybrid models for HI estimation usually rely heavily on system-specific\ninformation, limiting their transferability to other systems. In this work, we\npropose an unsupervised hybrid method for HI estimation that integrates general\nknowledge about degradation into the convolutional autoencoder's model\narchitecture and learning algorithm, enhancing its applicability across various\nsystems. The effectiveness of the proposed method is demonstrated in two case\nstudies from different domains: turbofan engines and lithium batteries. The\nresults show that the proposed method outperforms other competitive\nalternatives, including residual-based methods, in terms of HI quality and\ntheir utility for Remaining Useful Life (RUL) predictions. The case studies\nalso highlight the comparable performance of our proposed method with a\nsupervised model trained with HI labels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04990v1",
    "published_date": "2024-05-08 11:54:15 UTC",
    "updated_date": "2024-05-08 11:54:15 UTC"
  },
  {
    "arxiv_id": "2405.15794v1",
    "title": "Finite Groundings for ASP with Functions: A Journey through Consistency",
    "authors": [
      "Lukas Gerlach",
      "David Carral",
      "Markus Hecher"
    ],
    "abstract": "Answer set programming (ASP) is a logic programming formalism used in various\nareas of artificial intelligence like combinatorial problem solving and\nknowledge representation and reasoning. It is known that enhancing ASP with\nfunction symbols makes basic reasoning problems highly undecidable. However,\neven in simple cases, state of the art reasoners, specifically those relying on\na ground-and-solve approach, fail to produce a result. Therefore, we reconsider\nconsistency as a basic reasoning problem for ASP. We show reductions that give\nan intuition for the high level of undecidability. These insights allow for a\nmore fine-grained analysis where we characterize ASP programs as \"frugal\" and\n\"non-proliferous\". For such programs, we are not only able to semi-decide\nconsistency but we also propose a grounding procedure that yields finite\ngroundings on more ASP programs with the concept of \"forbidden\" facts.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "to be published at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.15794v1",
    "published_date": "2024-05-08 11:50:08 UTC",
    "updated_date": "2024-05-08 11:50:08 UTC"
  },
  {
    "arxiv_id": "2405.04985v1",
    "title": "An Artificial Intelligence Approach for Interpreting Creative Combinational Designs",
    "authors": [
      "Liuqing Chen",
      "Shuhong Xiao",
      "Yunnong Chen",
      "Linyun Sun",
      "Peter R. N. Childs",
      "Ji Han"
    ],
    "abstract": "Combinational creativity, a form of creativity involving the blending of\nfamiliar ideas, is pivotal in design innovation. While most research focuses on\nhow combinational creativity in design is achieved through blending elements,\nthis study focuses on the computational interpretation, specifically\nidentifying the 'base' and 'additive' components that constitute a creative\ndesign. To achieve this goal, the authors propose a heuristic algorithm\nintegrating computer vision and natural language processing technologies, and\nimplement multiple approaches based on both discriminative and generative\nartificial intelligence architectures. A comprehensive evaluation was conducted\non a dataset created for studying combinational creativity. Among the\nimplementations of the proposed algorithm, the most effective approach\ndemonstrated a high accuracy in interpretation, achieving 87.5% for identifying\n'base' and 80% for 'additive'. We conduct a modular analysis and an ablation\nexperiment to assess the performance of each part in our implementations.\nAdditionally, the study includes an analysis of error cases and bottleneck\nissues, providing critical insights into the limitations and challenges\ninherent in the computational interpretation of creative designs.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04985v1",
    "published_date": "2024-05-08 11:47:32 UTC",
    "updated_date": "2024-05-08 11:47:32 UTC"
  },
  {
    "arxiv_id": "2405.04974v1",
    "title": "Discrepancy-based Diffusion Models for Lesion Detection in Brain MRI",
    "authors": [
      "Keqiang Fan",
      "Xiaohao Cai",
      "Mahesan Niranjan"
    ],
    "abstract": "Diffusion probabilistic models (DPMs) have exhibited significant\neffectiveness in computer vision tasks, particularly in image generation.\nHowever, their notable performance heavily relies on labelled datasets, which\nlimits their application in medical images due to the associated high-cost\nannotations. Current DPM-related methods for lesion detection in medical\nimaging, which can be categorized into two distinct approaches, primarily rely\non image-level annotations. The first approach, based on anomaly detection,\ninvolves learning reference healthy brain representations and identifying\nanomalies based on the difference in inference results. In contrast, the second\napproach, resembling a segmentation task, employs only the original brain\nmulti-modalities as prior information for generating pixel-level annotations.\nIn this paper, our proposed model - discrepancy distribution medical diffusion\n(DDMD) - for lesion detection in brain MRI introduces a novel framework by\nincorporating distinctive discrepancy features, deviating from the conventional\ndirect reliance on image-level annotations or the original brain modalities. In\nour method, the inconsistency in image-level annotations is translated into\ndistribution discrepancies among heterogeneous samples while preserving\ninformation within homogeneous samples. This property retains pixel-wise\nuncertainty and facilitates an implicit ensemble of segmentation, ultimately\nenhancing the overall detection performance. Thorough experiments conducted on\nthe BRATS2020 benchmark dataset containing multimodal MRI scans for brain\ntumour detection demonstrate the great performance of our approach in\ncomparison to state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04974v1",
    "published_date": "2024-05-08 11:26:49 UTC",
    "updated_date": "2024-05-08 11:26:49 UTC"
  },
  {
    "arxiv_id": "2405.04972v1",
    "title": "Overcoming Anchoring Bias: The Potential of AI and XAI-based Decision Support",
    "authors": [
      "Felix Haag",
      "Carlo Stingl",
      "Katrin Zerfass",
      "Konstantin Hopf",
      "Thorsten Staake"
    ],
    "abstract": "Information systems (IS) are frequently designed to leverage the negative\neffect of anchoring bias to influence individuals' decision-making (e.g., by\nmanipulating purchase decisions). Recent advances in Artificial Intelligence\n(AI) and the explanations of its decisions through explainable AI (XAI) have\nopened new opportunities for mitigating biased decisions. So far, the potential\nof these technological advances to overcome anchoring bias remains widely\nunclear. To this end, we conducted two online experiments with a total of N=390\nparticipants in the context of purchase decisions to examine the impact of AI\nand XAI-based decision support on anchoring bias. Our results show that AI\nalone and its combination with XAI help to mitigate the negative effect of\nanchoring bias. Ultimately, our findings have implications for the design of AI\nand XAI-based decision support and IS to overcome cognitive biases.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04972v1",
    "published_date": "2024-05-08 11:25:04 UTC",
    "updated_date": "2024-05-08 11:25:04 UTC"
  },
  {
    "arxiv_id": "2405.04969v1",
    "title": "A review on discriminative self-supervised learning methods",
    "authors": [
      "Nikolaos Giakoumoglou",
      "Tania Stathaki"
    ],
    "abstract": "In the field of computer vision, self-supervised learning has emerged as a\nmethod to extract robust features from unlabeled data, where models derive\nlabels autonomously from the data itself, without the need for manual\nannotation. This paper provides a comprehensive review of discriminative\napproaches of self-supervised learning within the domain of computer vision,\nexamining their evolution and current status. Through an exploration of various\nmethods including contrastive, self-distillation, knowledge distillation,\nfeature decorrelation, and clustering techniques, we investigate how these\napproaches leverage the abundance of unlabeled data. Finally, we have\ncomparison of self-supervised learning methods on the standard ImageNet\nclassification benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 7 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.04969v1",
    "published_date": "2024-05-08 11:15:20 UTC",
    "updated_date": "2024-05-08 11:15:20 UTC"
  },
  {
    "arxiv_id": "2405.05295v1",
    "title": "Relevant Irrelevance: Generating Alterfactual Explanations for Image Classifiers",
    "authors": [
      "Silvan Mertes",
      "Tobias Huber",
      "Christina Karle",
      "Katharina Weitz",
      "Ruben Schlagowski",
      "Cristina Conati",
      "Elisabeth André"
    ],
    "abstract": "In this paper, we demonstrate the feasibility of alterfactual explanations\nfor black box image classifiers. Traditional explanation mechanisms from the\nfield of Counterfactual Thinking are a widely-used paradigm for Explainable\nArtificial Intelligence (XAI), as they follow a natural way of reasoning that\nhumans are familiar with. However, most common approaches from this field are\nbased on communicating information about features or characteristics that are\nespecially important for an AI's decision. However, to fully understand a\ndecision, not only knowledge about relevant features is needed, but the\nawareness of irrelevant information also highly contributes to the creation of\na user's mental model of an AI system. To this end, a novel approach for\nexplaining AI systems called alterfactual explanations was recently proposed on\na conceptual level. It is based on showing an alternative reality where\nirrelevant features of an AI's input are altered. By doing so, the user\ndirectly sees which input data characteristics can change arbitrarily without\ninfluencing the AI's decision. In this paper, we show for the first time that\nit is possible to apply this idea to black box models based on neural networks.\nTo this end, we present a GAN-based approach to generate these alterfactual\nexplanations for binary image classifiers. Further, we present a user study\nthat gives interesting insights on how alterfactual explanations can complement\ncounterfactual explanations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at IJCAI 2024. arXiv admin note: text overlap with\n  arXiv:2207.09374",
    "pdf_url": "http://arxiv.org/pdf/2405.05295v1",
    "published_date": "2024-05-08 11:03:22 UTC",
    "updated_date": "2024-05-08 11:03:22 UTC"
  },
  {
    "arxiv_id": "2405.04955v1",
    "title": "Improving Long Text Understanding with Knowledge Distilled from Summarization Model",
    "authors": [
      "Yan Liu",
      "Yazheng Yang",
      "Xiaokang Chen"
    ],
    "abstract": "Long text understanding is important yet challenging for natural language\nprocessing. A long article or document usually contains many redundant words\nthat are not pertinent to its gist and sometimes can be regarded as noise. With\nrecent advances of abstractive summarization, we propose our \\emph{Gist\nDetector} to leverage the gist detection ability of a summarization model and\nintegrate the extracted gist into downstream models to enhance their long text\nunderstanding ability. Specifically, Gist Detector first learns the gist\ndetection knowledge distilled from a summarization model, and then produces\ngist-aware representations to augment downstream models. We evaluate our method\non three different tasks: long document classification, distantly supervised\nopen-domain question answering, and non-parallel text style transfer. The\nexperimental results show that our method can significantly improve the\nperformance of baseline models on all tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2110.04741",
    "pdf_url": "http://arxiv.org/pdf/2405.04955v1",
    "published_date": "2024-05-08 10:49:39 UTC",
    "updated_date": "2024-05-08 10:49:39 UTC"
  },
  {
    "arxiv_id": "2405.04950v1",
    "title": "VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context",
    "authors": [
      "Yunxin Li",
      "Baotian Hu",
      "Haoyuan Shi",
      "Wei Wang",
      "Longyue Wang",
      "Min Zhang"
    ],
    "abstract": "Large Multimodal Models (LMMs) have achieved impressive success in visual\nunderstanding and reasoning, remarkably improving the performance of\nmathematical reasoning in a visual context. Yet, a challenging type of visual\nmath lies in the multimodal graph theory problem, which demands that LMMs\nunderstand the graphical structures accurately and perform multi-step reasoning\non the visual graph. Additionally, exploring multimodal graph theory problems\nwill lead to more effective strategies in fields like biology, transportation,\nand robotics planning. To step forward in this direction, we are the first to\ndesign a benchmark named VisionGraph, used to explore the capabilities of\nadvanced LMMs in solving multimodal graph theory problems. It encompasses eight\ncomplex graph problem tasks, from connectivity to shortest path problems.\nSubsequently, we present a Description-Program-Reasoning (DPR) chain to enhance\nthe logical accuracy of reasoning processes through graphical structure\ndescription generation and algorithm-aware multi-step reasoning. Our extensive\nstudy shows that 1) GPT-4V outperforms Gemini Pro in multi-step graph\nreasoning; 2) All LMMs exhibit inferior perception accuracy for graphical\nstructures, whether in zero/few-shot settings or with supervised fine-tuning\n(SFT), which further affects problem-solving performance; 3) DPR significantly\nimproves the multi-step graph reasoning capabilities of LMMs and the GPT-4V\n(DPR) agent achieves SOTA performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages; Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04950v1",
    "published_date": "2024-05-08 10:42:48 UTC",
    "updated_date": "2024-05-08 10:42:48 UTC"
  },
  {
    "arxiv_id": "2405.04941v2",
    "title": "Imprecise Probabilities Meet Partial Observability: Game Semantics for Robust POMDPs",
    "authors": [
      "Eline M. Bovy",
      "Marnix Suilen",
      "Sebastian Junges",
      "Nils Jansen"
    ],
    "abstract": "Partially observable Markov decision processes (POMDPs) rely on the key\nassumption that probability distributions are precisely known. Robust POMDPs\n(RPOMDPs) alleviate this concern by defining imprecise probabilities, referred\nto as uncertainty sets. While robust MDPs have been studied extensively, work\non RPOMDPs is limited and primarily focuses on algorithmic solution methods. We\nexpand the theoretical understanding of RPOMDPs by showing that 1) different\nassumptions on the uncertainty sets affect optimal policies and values; 2)\nRPOMDPs have a partially observable stochastic game (POSG) semantic; and 3) the\nsame RPOMDP with different assumptions leads to semantically different POSGs\nand, thus, different policies and values. These novel semantics for RPOMDPs\ngive access to results for POSGs, studied in game theory; concretely, we show\nthe existence of a Nash equilibrium. Finally, we classify the existing RPOMDP\nliterature using our semantics, clarifying under which uncertainty assumptions\nthese existing works operate.",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04941v2",
    "published_date": "2024-05-08 10:22:49 UTC",
    "updated_date": "2024-07-29 09:15:29 UTC"
  },
  {
    "arxiv_id": "2405.06701v1",
    "title": "Lightweight Spatial Modeling for Combinatorial Information Extraction From Documents",
    "authors": [
      "Yanfei Dong",
      "Lambert Deng",
      "Jiazheng Zhang",
      "Xiaodong Yu",
      "Ting Lin",
      "Francesco Gelli",
      "Soujanya Poria",
      "Wee Sun Lee"
    ],
    "abstract": "Documents that consist of diverse templates and exhibit complex spatial\nstructures pose a challenge for document entity classification. We propose\nKNN-former, which incorporates a new kind of spatial bias in attention\ncalculation based on the K-nearest-neighbor (KNN) graph of document entities.\nWe limit entities' attention only to their local radius defined by the KNN\ngraph. We also use combinatorial matching to address the one-to-one mapping\nproperty that exists in many documents, where one field has only one\ncorresponding entity. Moreover, our method is highly parameter-efficient\ncompared to existing approaches in terms of the number of trainable parameters.\nDespite this, experiments across various datasets show our method outperforms\nbaselines in most entity types. Many real-world documents exhibit combinatorial\nproperties which can be leveraged as inductive biases to improve extraction\naccuracy, but existing datasets do not cover these documents. To facilitate\nfuture research into these types of documents, we release a new ID document\ndataset that covers diverse templates and languages. We also release enhanced\nannotations for an existing dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06701v1",
    "published_date": "2024-05-08 10:10:38 UTC",
    "updated_date": "2024-05-08 10:10:38 UTC"
  },
  {
    "arxiv_id": "2405.04937v1",
    "title": "Developing trustworthy AI applications with foundation models",
    "authors": [
      "Michael Mock",
      "Sebastian Schmidt",
      "Felix Müller",
      "Rebekka Görge",
      "Anna Schmitz",
      "Elena Haedecke",
      "Angelika Voss",
      "Dirk Hecker",
      "Maximillian Poretschkin"
    ],
    "abstract": "The trustworthiness of AI applications has been the subject of recent\nresearch and is also addressed in the EU's recently adopted AI Regulation. The\ncurrently emerging foundation models in the field of text, speech and image\nprocessing offer completely new possibilities for developing AI applications.\nThis whitepaper shows how the trustworthiness of an AI application developed\nwith foundation models can be evaluated and ensured. For this purpose, the\napplication-specific, risk-based approach for testing and ensuring the\ntrustworthiness of AI applications, as developed in the 'AI Assessment Catalog\n- Guideline for Trustworthy Artificial Intelligence' by Fraunhofer IAIS, is\ntransferred to the context of foundation models. Special consideration is given\nto the fact that specific risks of foundation models can have an impact on the\nAI application and must also be taken into account when checking\ntrustworthiness. Chapter 1 of the white paper explains the fundamental\nrelationship between foundation models and AI applications based on them in\nterms of trustworthiness. Chapter 2 provides an introduction to the technical\nconstruction of foundation models and Chapter 3 shows how AI applications can\nbe developed based on them. Chapter 4 provides an overview of the resulting\nrisks regarding trustworthiness. Chapter 5 shows which requirements for AI\napplications and foundation models are to be expected according to the draft of\nthe European Union's AI Regulation and Chapter 6 finally shows the system and\nprocedure for meeting trustworthiness requirements.",
    "categories": [
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04937v1",
    "published_date": "2024-05-08 10:08:45 UTC",
    "updated_date": "2024-05-08 10:08:45 UTC"
  },
  {
    "arxiv_id": "2405.04923v2",
    "title": "DataSP: A Differential All-to-All Shortest Path Algorithm for Learning Costs and Predicting Paths with Context",
    "authors": [
      "Alan A. Lahoud",
      "Erik Schaffernicht",
      "Johannes A. Stork"
    ],
    "abstract": "Learning latent costs of transitions on graphs from trajectories\ndemonstrations under various contextual features is challenging but useful for\npath planning. Yet, existing methods either oversimplify cost assumptions or\nscale poorly with the number of observed trajectories. This paper introduces\nDataSP, a differentiable all-to-all shortest path algorithm to facilitate\nlearning latent costs from trajectories. It allows to learn from a large number\nof trajectories in each learning step without additional computation. Complex\nlatent cost functions from contextual features can be represented in the\nalgorithm through a neural network approximation. We further propose a method\nto sample paths from DataSP in order to reconstruct/mimic observed paths'\ndistributions. We prove that the inferred distribution follows the maximum\nentropy principle. We show that DataSP outperforms state-of-the-art\ndifferentiable combinatorial solver and classical machine learning approaches\nin predicting paths on graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04923v2",
    "published_date": "2024-05-08 09:45:54 UTC",
    "updated_date": "2024-05-30 12:04:17 UTC"
  },
  {
    "arxiv_id": "2405.04918v1",
    "title": "Delve into Base-Novel Confusion: Redundancy Exploration for Few-Shot Class-Incremental Learning",
    "authors": [
      "Haichen Zhou",
      "Yixiong Zou",
      "Ruixuan Li",
      "Yuhua Li",
      "Kui Xiao"
    ],
    "abstract": "Few-shot class-incremental learning (FSCIL) aims to acquire knowledge from\nnovel classes with limited samples while retaining information about base\nclasses. Existing methods address catastrophic forgetting and overfitting by\nfreezing the feature extractor during novel-class learning. However, these\nmethods usually tend to cause the confusion between base and novel classes,\ni.e., classifying novel-class samples into base classes. In this paper, we\ndelve into this phenomenon to study its cause and solution. We first interpret\nthe confusion as the collision between the novel-class and the base-class\nregion in the feature space. Then, we find the collision is caused by the\nlabel-irrelevant redundancies within the base-class feature and pixel space.\nThrough qualitative and quantitative experiments, we identify this redundancy\nas the shortcut in the base-class training, which can be decoupled to alleviate\nthe collision. Based on this analysis, to alleviate the collision between base\nand novel classes, we propose a method for FSCIL named Redundancy Decoupling\nand Integration (RDI). RDI first decouples redundancies from base-class space\nto shrink the intra-base-class feature space. Then, it integrates the\nredundancies as a dummy class to enlarge the inter-base-class feature space.\nThis process effectively compresses the base-class feature space, creating\nbuffer space for novel classes and alleviating the model's confusion between\nthe base and novel classes. Extensive experiments across benchmark datasets,\nincluding CIFAR-100, miniImageNet, and CUB-200-2011 demonstrate that our method\nachieves state-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04918v1",
    "published_date": "2024-05-08 09:38:16 UTC",
    "updated_date": "2024-05-08 09:38:16 UTC"
  },
  {
    "arxiv_id": "2405.04909v1",
    "title": "Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models",
    "authors": [
      "Zhengxing Lan",
      "Hongbo Li",
      "Lingshan Liu",
      "Bo Fan",
      "Yisheng Lv",
      "Yilong Ren",
      "Zhiyong Cui"
    ],
    "abstract": "Predicting the future trajectories of dynamic traffic actors is a cornerstone\ntask in autonomous driving. Though existing notable efforts have resulted in\nimpressive performance improvements, a gap persists in scene cognitive and\nunderstanding of the complex traffic semantics. This paper proposes Traj-LLM,\nthe first to investigate the potential of using Large Language Models (LLMs)\nwithout explicit prompt engineering to generate future motion from agents'\npast/observed trajectories and scene semantics. Traj-LLM starts with sparse\ncontext joint coding to dissect the agent and scene features into a form that\nLLMs understand. On this basis, we innovatively explore LLMs' powerful\ncomprehension abilities to capture a spectrum of high-level scene knowledge and\ninteractive information. Emulating the human-like lane focus cognitive function\nand enhancing Traj-LLM's scene comprehension, we introduce lane-aware\nprobabilistic learning powered by the pioneering Mamba module. Finally, a\nmulti-modal Laplace decoder is designed to achieve scene-compliant multi-modal\npredictions. Extensive experiments manifest that Traj-LLM, fortified by LLMs'\nstrong prior knowledge and understanding prowess, together with lane-aware\nprobability learning, outstrips state-of-the-art methods across evaluation\nmetrics. Moreover, the few-shot analysis further substantiates Traj-LLM's\nperformance, wherein with just 50% of the dataset, it outperforms the majority\nof benchmarks relying on complete data utilization. This study explores\nequipping the trajectory prediction task with advanced capabilities inherent in\nLLMs, furnishing a more universal and adaptable solution for forecasting agent\nmotion in a new way.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04909v1",
    "published_date": "2024-05-08 09:28:04 UTC",
    "updated_date": "2024-05-08 09:28:04 UTC"
  },
  {
    "arxiv_id": "2405.04897v1",
    "title": "Machine Learning-based NLP for Emotion Classification on a Cholera X Dataset",
    "authors": [
      "Paul Jideani",
      "Aurona Gerber"
    ],
    "abstract": "Recent social media posts on the cholera outbreak in Hammanskraal have\nhighlighted the diverse range of emotions people experienced in response to\nsuch an event. The extent of people's opinions varies greatly depending on\ntheir level of knowledge and information about the disease. The documented\nre-search about Cholera lacks investigations into the classification of\nemotions. This study aims to examine the emotions expressed in social media\nposts about Chol-era. A dataset of 23,000 posts was extracted and\npre-processed. The Python Nat-ural Language Toolkit (NLTK) sentiment analyzer\nlibrary was applied to deter-mine the emotional significance of each text.\nAdditionally, Machine Learning (ML) models were applied for emotion\nclassification, including Long short-term memory (LSTM), Logistic regression,\nDecision trees, and the Bidirectional En-coder Representations from\nTransformers (BERT) model. The results of this study demonstrated that LSTM\nachieved the highest accuracy of 75%. Emotion classification presents a\npromising tool for gaining a deeper understanding of the impact of Cholera on\nsociety. The findings of this study might contribute to the development of\neffective interventions in public health strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04897v1",
    "published_date": "2024-05-08 09:05:02 UTC",
    "updated_date": "2024-05-08 09:05:02 UTC"
  },
  {
    "arxiv_id": "2407.03111v2",
    "title": "Compressed Latent Replays for Lightweight Continual Learning on Spiking Neural Networks",
    "authors": [
      "Alberto Dequino",
      "Alessio Carpegna",
      "Davide Nadalini",
      "Alessandro Savino",
      "Luca Benini",
      "Stefano Di Carlo",
      "Francesco Conti"
    ],
    "abstract": "Rehearsal-based Continual Learning (CL) has been intensely investigated in\nDeep Neural Networks (DNNs). However, its application in Spiking Neural\nNetworks (SNNs) has not been explored in depth. In this paper we introduce the\nfirst memory-efficient implementation of Latent Replay (LR)-based CL for SNNs,\ndesigned to seamlessly integrate with resource-constrained devices. LRs combine\nnew samples with latent representations of previously learned data, to mitigate\nforgetting. Experiments on the Heidelberg SHD dataset with Sample and\nClass-Incremental tasks reach a Top-1 accuracy of 92.5% and 92%, respectively,\nwithout forgetting the previously learned information. Furthermore, we minimize\nthe LRs' requirements by applying a time-domain compression, reducing by two\norders of magnitude their memory requirement, with respect to a naive rehearsal\nsetup, with a maximum accuracy drop of 4%. On a Multi-Class-Incremental task,\nour SNN learns 10 new classes from an initial set of 10, reaching a Top-1\naccuracy of 78.4% on the full test set.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03111v2",
    "published_date": "2024-05-08 09:03:17 UTC",
    "updated_date": "2024-07-04 08:07:18 UTC"
  },
  {
    "arxiv_id": "2405.06700v1",
    "title": "LLM-Augmented Agent-Based Modelling for Social Simulations: Challenges and Opportunities",
    "authors": [
      "Onder Gurcan"
    ],
    "abstract": "As large language models (LLMs) continue to make significant strides, their\nbetter integration into agent-based simulations offers a transformational\npotential for understanding complex social systems. However, such integration\nis not trivial and poses numerous challenges. Based on this observation, in\nthis paper, we explore architectures and methods to systematically develop\nLLM-augmented social simulations and discuss potential research directions in\nthis field. We conclude that integrating LLMs with agent-based simulations\noffers a powerful toolset for researchers and scientists, allowing for more\nnuanced, realistic, and comprehensive models of complex systems and human\nbehaviours.",
    "categories": [
      "physics.soc-ph",
      "cs.AI"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "11 pages, 0 figures, Hybrid Human Artificial Intelligence (HHAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.06700v1",
    "published_date": "2024-05-08 08:57:54 UTC",
    "updated_date": "2024-05-08 08:57:54 UTC"
  },
  {
    "arxiv_id": "2405.04890v3",
    "title": "GISR: Geometric Initialization and Silhouette-based Refinement for Single-View Robot Pose and Configuration Estimation",
    "authors": [
      "Ivan Bilić",
      "Filip Marić",
      "Fabio Bonsignorio",
      "Ivan Petrović"
    ],
    "abstract": "In autonomous robotics, measurement of the robot's internal state and\nperception of its environment, including interaction with other agents such as\ncollaborative robots, are essential. Estimating the pose of the robot arm from\na single view has the potential to replace classical eye-to-hand calibration\napproaches and is particularly attractive for online estimation and dynamic\nenvironments. In addition to its pose, recovering the robot configuration\nprovides a complete spatial understanding of the observed robot that can be\nused to anticipate the actions of other agents in advanced robotics use cases.\nFurthermore, this additional redundancy enables the planning and execution of\nrecovery protocols in case of sensor failures or external disturbances. We\nintroduce GISR - a deep configuration and robot-to-camera pose estimation\nmethod that prioritizes execution in real-time. GISR consists of two modules:\n(i) a geometric initialization module that efficiently computes an approximate\nrobot pose and configuration, and (ii) a deep iterative silhouette-based\nrefinement module that arrives at a final solution in just a few iterations. We\nevaluate GISR on publicly available data and show that it outperforms existing\nmethods of the same class in terms of both speed and accuracy, and can compete\nwith approaches that rely on ground-truth proprioception and recover only the\npose.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for publication in the Robotics and Automation Letters 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04890v3",
    "published_date": "2024-05-08 08:39:25 UTC",
    "updated_date": "2024-09-16 20:28:00 UTC"
  },
  {
    "arxiv_id": "2405.04883v2",
    "title": "FreeBind: Free Lunch in Unified Multimodal Space via Knowledge Fusion",
    "authors": [
      "Zehan Wang",
      "Ziang Zhang",
      "Xize Cheng",
      "Rongjie Huang",
      "Luping Liu",
      "Zhenhui Ye",
      "Haifeng Huang",
      "Yang Zhao",
      "Tao Jin",
      "Peng Gao",
      "Zhou Zhao"
    ],
    "abstract": "Unified multi-model representation spaces are the foundation of multimodal\nunderstanding and generation. However, the billions of model parameters and\ncatastrophic forgetting problems make it challenging to further enhance\npre-trained unified spaces. In this work, we propose FreeBind, an idea that\ntreats multimodal representation spaces as basic units, and freely augments\npre-trained unified space by integrating knowledge from extra expert spaces via\n\"space bonds\". Specifically, we introduce two kinds of basic space bonds: 1)\nSpace Displacement Bond and 2) Space Combination Bond. Based on these basic\nbonds, we design Complex Sequential & Parallel Bonds to effectively integrate\nmultiple spaces simultaneously. Benefiting from the modularization concept, we\nfurther propose a coarse-to-fine customized inference strategy to flexibly\nadjust the enhanced unified space for different purposes. Experimentally, we\nbind ImageBind with extra image-text and audio-text expert spaces, resulting in\nthree main variants: ImageBind++, InternVL_IB, and InternVL_IB++. These\nresulting spaces outperform ImageBind on 5 audio-image-text downstream tasks\nacross 9 datasets. Moreover, via customized inference, it even surpasses the\nadvanced audio-text and image-text expert spaces.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML 2024. The code and checkpoints will be released at\n  https://github.com/zehanwang01/FreeBind",
    "pdf_url": "http://arxiv.org/pdf/2405.04883v2",
    "published_date": "2024-05-08 08:32:34 UTC",
    "updated_date": "2024-05-10 07:18:00 UTC"
  },
  {
    "arxiv_id": "2405.04880v3",
    "title": "The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio",
    "authors": [
      "Yuankun Xie",
      "Yi Lu",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Zhiyong Wang",
      "Jianhua Tao",
      "Xin Qi",
      "Xiaopeng Wang",
      "Yukun Liu",
      "Haonan Cheng",
      "Long Ye",
      "Yi Sun"
    ],
    "abstract": "With the proliferation of Audio Language Model (ALM) based deepfake audio,\nthere is an urgent need for generalized detection methods. ALM-based deepfake\naudio currently exhibits widespread, high deception, and type versatility,\nposing a significant challenge to current audio deepfake detection (ADD) models\ntrained solely on vocoded data. To effectively detect ALM-based deepfake audio,\nwe focus on the mechanism of the ALM-based audio generation method, the\nconversion from neural codec to waveform. We initially constructed the\nCodecfake dataset, an open-source, large-scale collection comprising over 1\nmillion audio samples in both English and Chinese, focus on ALM-based audio\ndetection. As countermeasure, to achieve universal detection of deepfake audio\nand tackle domain ascent bias issue of original sharpness aware minimization\n(SAM), we propose the CSAM strategy to learn a domain balanced and generalized\nminima. In our experiments, we first demonstrate that ADD model training with\nthe Codecfake dataset can effectively detects ALM-based audio. Furthermore, our\nproposed generalization countermeasure yields the lowest average equal error\nrate (EER) of 0.616% across all test conditions compared to baseline models.\nThe dataset and associated code are available online.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04880v3",
    "published_date": "2024-05-08 08:28:40 UTC",
    "updated_date": "2024-12-25 07:30:50 UTC"
  },
  {
    "arxiv_id": "2405.05292v1",
    "title": "Smart Portable Computer",
    "authors": [
      "Niladri Das"
    ],
    "abstract": "Amidst the COVID-19 pandemic, with many organizations, schools, colleges, and\nuniversities transitioning to virtual platforms, students encountered\ndifficulties in acquiring PCs such as desktops or laptops. The starting prices,\naround 15,000 INR, often failed to offer adequate system specifications, posing\na challenge for consumers. Additionally, those reliant on laptops for work\nfound the conventional approach cumbersome. Enter the \"Portable Smart\nComputer,\" a leap into the future of computing. This innovative device boasts\nspeed and performance comparable to traditional desktops but in a compact,\nenergy-efficient, and cost-effective package. It delivers a seamless desktop\nexperience, whether one is editing documents, browsing multiple tabs, managing\nspreadsheets, or creating presentations. Moreover, it supports programming\nlanguages like Python, C, C++, as well as compilers such as Keil and Xilinx,\ncatering to the needs of programmers.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.05292v1",
    "published_date": "2024-05-08 08:20:27 UTC",
    "updated_date": "2024-05-08 08:20:27 UTC"
  },
  {
    "arxiv_id": "2405.04875v1",
    "title": "SCALA: Split Federated Learning with Concatenated Activations and Logit Adjustments",
    "authors": [
      "Jiarong Yang",
      "Yuan Liu"
    ],
    "abstract": "Split Federated Learning (SFL) is a distributed machine learning framework\nwhich strategically divides the learning process between a server and clients\nand collaboratively trains a shared model by aggregating local models updated\nbased on data from distributed clients. However, data heterogeneity and partial\nclient participation result in label distribution skew, which severely degrades\nthe learning performance. To address this issue, we propose SFL with\nConcatenated Activations and Logit Adjustments (SCALA). Specifically, the\nactivations from the client-side models are concatenated as the input of the\nserver-side model so as to centrally adjust label distribution across different\nclients, and logit adjustments of loss functions on both server-side and\nclient-side models are performed to deal with the label distribution variation\nacross different subsets of participating clients. Theoretical analysis and\nexperimental results verify the superiority of the proposed SCALA on public\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04875v1",
    "published_date": "2024-05-08 08:12:21 UTC",
    "updated_date": "2024-05-08 08:12:21 UTC"
  },
  {
    "arxiv_id": "2405.04872v1",
    "title": "Logical Negation Augmenting and Debiasing for Prompt-based Methods",
    "authors": [
      "Yitian Li",
      "Jidong Tian",
      "Hao He",
      "Yaohui Jin"
    ],
    "abstract": "Prompt-based methods have gained increasing attention on NLP and shown\nvalidity on many downstream tasks. Many works have focused on mining these\nmethods' potential for knowledge extraction, but few explore their ability to\nmake logical reasoning. In this work, we focus on the effectiveness of the\nprompt-based methods on first-order logical reasoning and find that the\nbottleneck lies in logical negation. Based on our analysis, logical negation\ntends to result in spurious correlations to negative answers, while\npropositions without logical negation correlate to positive answers. To solve\nthe problem, we propose a simple but effective method, Negation Augmenting and\nNegation Debiasing (NAND), which introduces negative propositions to\nprompt-based methods without updating parameters. Specifically, these negative\npropositions can counteract spurious correlations by providing \"not\" for all\ninstances so that models cannot make decisions only by whether expressions\ncontain a logical negation. Experiments on three datasets show that NAND not\nonly solves the problem of calibrating logical negation but also significantly\nenhances prompt-based methods of logical reasoning without model retraining.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04872v1",
    "published_date": "2024-05-08 08:05:47 UTC",
    "updated_date": "2024-05-08 08:05:47 UTC"
  },
  {
    "arxiv_id": "2405.04868v2",
    "title": "Enhancing Geometric Ontology Embeddings for $\\mathcal{EL}^{++}$ with Negative Sampling and Deductive Closure Filtering",
    "authors": [
      "Olga Mashkova",
      "Fernando Zhapa-Camacho",
      "Robert Hoehndorf"
    ],
    "abstract": "Ontology embeddings map classes, relations, and individuals in ontologies\ninto $\\mathbb{R}^n$, and within $\\mathbb{R}^n$ similarity between entities can\nbe computed or new axioms inferred. For ontologies in the Description Logic\n$\\mathcal{EL}^{++}$, several embedding methods have been developed that\nexplicitly generate models of an ontology. However, these methods suffer from\nsome limitations; they do not distinguish between statements that are\nunprovable and provably false, and therefore they may use entailed statements\nas negatives. Furthermore, they do not utilize the deductive closure of an\nontology to identify statements that are inferred but not asserted. We\nevaluated a set of embedding methods for $\\mathcal{EL}^{++}$ ontologies based\non high-dimensional ball representation of concept descriptions, incorporating\nseveral modifications that aim to make use of the ontology deductive closure.\nIn particular, we designed novel negative losses that account both for the\ndeductive closure and different types of negatives. We demonstrate that our\nembedding methods improve over the baseline ontology embedding in the task of\nknowledge base or ontology completion.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Revised version",
    "pdf_url": "http://arxiv.org/pdf/2405.04868v2",
    "published_date": "2024-05-08 07:50:21 UTC",
    "updated_date": "2024-06-26 11:17:13 UTC"
  },
  {
    "arxiv_id": "2405.05985v1",
    "title": "TrafficGPT: Towards Multi-Scale Traffic Analysis and Generation with Spatial-Temporal Agent Framework",
    "authors": [
      "Jinhui Ouyang",
      "Yijie Zhu",
      "Xiang Yuan",
      "Di Wu"
    ],
    "abstract": "The precise prediction of multi-scale traffic is a ubiquitous challenge in\nthe urbanization process for car owners, road administrators, and governments.\nIn the case of complex road networks, current and past traffic information from\nboth upstream and downstream roads are crucial since various road networks have\ndifferent semantic information about traffic. Rationalizing the utilization of\nsemantic information can realize short-term, long-term, and unseen road traffic\nprediction. As the demands of multi-scale traffic analysis increase, on-demand\ninteractions and visualizations are expected to be available for transportation\nparticipants. We have designed a multi-scale traffic generation system, namely\nTrafficGPT, using three AI agents to process multi-scale traffic data, conduct\nmulti-scale traffic analysis, and present multi-scale visualization results.\nTrafficGPT consists of three essential AI agents: 1) a text-to-demand agent\nthat is employed with Question & Answer AI to interact with users and extract\nprediction tasks through texts; 2) a traffic prediction agent that leverages\nmulti-scale traffic data to generate temporal features and similarity, and fuse\nthem with limited spatial features and similarity, to achieve accurate\nprediction of three tasks; and 3) a suggestion and visualization agent that\nuses the prediction results to generate suggestions and visualizations,\nproviding users with a comprehensive understanding of traffic conditions. Our\nTrafficGPT system focuses on addressing concerns about traffic prediction from\ntransportation participants, and conducted extensive experiments on five\nreal-world road datasets to demonstrate its superior predictive and interactive\nperformance",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05985v1",
    "published_date": "2024-05-08 07:48:40 UTC",
    "updated_date": "2024-05-08 07:48:40 UTC"
  },
  {
    "arxiv_id": "2405.06699v1",
    "title": "ChatSOS: Vector Database Augmented Generative Question Answering Assistant in Safety Engineering",
    "authors": [
      "Haiyang Tang",
      "Dongping Chen",
      "Qingzhao Chu"
    ],
    "abstract": "With the rapid advancement of natural language processing technologies,\ngenerative artificial intelligence techniques, represented by large language\nmodels (LLMs), are gaining increasing prominence and demonstrating significant\npotential for applications in safety engineering. However, fundamental LLMs\nface constraints such as limited training data coverage and unreliable\nresponses. This study develops a vector database from 117 explosion accident\nreports in China spanning 2013 to 2023, employing techniques such as corpus\nsegmenting and vector embedding. By utilizing the vector database, which\noutperforms the relational database in information retrieval quality, we\nprovide LLMs with richer, more relevant knowledge. Comparative analysis of LLMs\ndemonstrates that ChatSOS significantly enhances reliability, accuracy, and\ncomprehensiveness, improves adaptability and clarification of responses. These\nresults illustrate the effectiveness of supplementing LLMs with an external\ndatabase, highlighting their potential to handle professional queries in safety\nengineering and laying a foundation for broader applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.06699v1",
    "published_date": "2024-05-08 07:21:26 UTC",
    "updated_date": "2024-05-08 07:21:26 UTC"
  },
  {
    "arxiv_id": "2407.08741v1",
    "title": "A digital twin based approach to smart lighting design",
    "authors": [
      "Elham Mohammadrezaei",
      "Alexander Giovannelli",
      "Logan Lane",
      "Denis Gracanin"
    ],
    "abstract": "Lighting has a critical impact on user mood and behavior, especially in\narchitectural settings. Consequently, smart lighting design is a rapidly\ngrowing research area. We describe a digital twin-based approach to smart\nlighting design that uses an immersive virtual reality digital twin equivalent\n(virtual environment) of the real world, physical architectural space to\nexplore the visual impact of light configurations. The CLIP neural network is\nused to obtain a similarity measure between a photo of the physical space with\nthe corresponding rendering in the virtual environment. A case study was used\nto evaluate the proposed design process. The obtained similarity value of over\n87% demonstrates the utility of the proposed approach.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.08741v1",
    "published_date": "2024-05-08 06:35:14 UTC",
    "updated_date": "2024-05-08 06:35:14 UTC"
  },
  {
    "arxiv_id": "2405.04841v1",
    "title": "xMTrans: Temporal Attentive Cross-Modality Fusion Transformer for Long-Term Traffic Prediction",
    "authors": [
      "Huy Quang Ung",
      "Hao Niu",
      "Minh-Son Dao",
      "Shinya Wada",
      "Atsunori Minamikawa"
    ],
    "abstract": "Traffic predictions play a crucial role in intelligent transportation\nsystems. The rapid development of IoT devices allows us to collect different\nkinds of data with high correlations to traffic predictions, fostering the\ndevelopment of efficient multi-modal traffic prediction models. Until now,\nthere are few studies focusing on utilizing advantages of multi-modal data for\ntraffic predictions. In this paper, we introduce a novel temporal attentive\ncross-modality transformer model for long-term traffic predictions, namely\nxMTrans, with capability of exploring the temporal correlations between the\ndata of two modalities: one target modality (for prediction, e.g., traffic\ncongestion) and one support modality (e.g., people flow). We conducted\nextensive experiments to evaluate our proposed model on traffic congestion and\ntaxi demand predictions using real-world datasets. The results showed the\nsuperiority of xMTrans against recent state-of-the-art methods on long-term\ntraffic predictions. In addition, we also conducted a comprehensive ablation\nstudy to further analyze the effectiveness of each module in xMTrans.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at MDM 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04841v1",
    "published_date": "2024-05-08 06:29:26 UTC",
    "updated_date": "2024-05-08 06:29:26 UTC"
  },
  {
    "arxiv_id": "2405.04825v2",
    "title": "Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution",
    "authors": [
      "Shuo Shao",
      "Yiming Li",
      "Hongwei Yao",
      "Yiling He",
      "Zhan Qin",
      "Kui Ren"
    ],
    "abstract": "Ownership verification is currently the most critical and widely adopted\npost-hoc method to safeguard model copyright. In general, model owners exploit\nit to identify whether a given suspicious third-party model is stolen from them\nby examining whether it has particular properties `inherited' from their\nreleased models. Currently, backdoor-based model watermarks are the primary and\ncutting-edge methods to implant such properties in the released models.\nHowever, backdoor-based methods have two fatal drawbacks, including harmfulness\nand ambiguity. The former indicates that they introduce maliciously\ncontrollable misclassification behaviors ($i.e.$, backdoor) to the watermarked\nreleased models. The latter denotes that malicious users can easily pass the\nverification by finding other misclassified samples, leading to ownership\nambiguity.\n  In this paper, we argue that both limitations stem from the `zero-bit' nature\nof existing watermarking schemes, where they exploit the status ($i.e.$,\nmisclassified) of predictions for verification. Motivated by this\nunderstanding, we design a new watermarking paradigm, $i.e.$, Explanation as a\nWatermark (EaaW), that implants verification behaviors into the explanation of\nfeature attribution instead of model predictions. Specifically, EaaW embeds a\n`multi-bit' watermark into the feature attribution explanation of specific\ntrigger samples without changing the original prediction. We correspondingly\ndesign the watermark embedding and extraction algorithms inspired by\nexplainable artificial intelligence. In particular, our approach can be used\nfor different tasks ($e.g.$, image classification and text generation).\nExtensive experiments verify the effectiveness and harmlessness of our EaaW and\nits resistance to potential attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper is accepted by Network and Distributed System Security\n  Symposium (NDSS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.04825v2",
    "published_date": "2024-05-08 05:49:46 UTC",
    "updated_date": "2024-09-10 01:52:47 UTC"
  },
  {
    "arxiv_id": "2405.04820v1",
    "title": "APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching",
    "authors": [
      "Yikuan Xia",
      "Jiazun Chen",
      "Xinchi Li",
      "Jun Gao"
    ],
    "abstract": "Generalized Entity Matching (GEM), which aims at judging whether two records\nrepresented in different formats refer to the same real-world entity, is an\nessential task in data management. The prompt tuning paradigm for pre-trained\nlanguage models (PLMs), including the recent PromptEM model, effectively\naddresses the challenges of low-resource GEM in practical applications,\noffering a robust solution when labeled data is scarce. However, existing\nprompt tuning models for GEM face the challenges of prompt design and\ninformation gap. This paper introduces an augmented prompt tuning framework for\nthe challenges, which consists of two main improvements. The first is an\naugmented contextualized soft token-based prompt tuning method that extracts a\nguiding soft token benefit for the PLMs' prompt tuning, and the second is a\ncost-effective information augmentation strategy leveraging large language\nmodels (LLMs). Our approach performs well on the low-resource GEM challenges.\nExtensive experiments show promising advancements of our basic model without\ninformation augmentation over existing methods based on moderate-size PLMs\n(average 5.24%+), and our model with information augmentation achieves\ncomparable performance compared with fine-tuned LLMs, using less than 14% of\nthe API fee.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04820v1",
    "published_date": "2024-05-08 05:38:56 UTC",
    "updated_date": "2024-05-08 05:38:56 UTC"
  },
  {
    "arxiv_id": "2405.04819v4",
    "title": "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature",
    "authors": [
      "Dawei Li",
      "Shu Yang",
      "Zhen Tan",
      "Jae Young Baik",
      "Sukwon Yun",
      "Joseph Lee",
      "Aaron Chacko",
      "Bojian Hou",
      "Duy Duong-Tran",
      "Ying Ding",
      "Huan Liu",
      "Li Shen",
      "Tianlong Chen"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have achieved promising\nperformances across various applications. Nonetheless, the ongoing challenge of\nintegrating long-tail knowledge continues to impede the seamless adoption of\nLLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic\nCo-Augmentation of LLMs and KG, to address this limitation and demonstrate its\nability on studying Alzheimer's Disease (AD), a specialized sub-field in\nbiomedicine and a global health priority. With a synergized framework of LLM\nand KG mutually enhancing each other, we first leverage LLM to construct an\nevolving AD-specific knowledge graph (KG) sourced from AD-related scientific\nliterature, and then we utilize a coarse-to-fine sampling method with a novel\nself-aware knowledge retrieval approach to select appropriate knowledge from\nthe KG to augment LLM inference capabilities. The experimental results,\nconducted on our constructed AD question answering (ADQA) benchmark, underscore\nthe efficacy of DALK. Additionally, we perform a series of detailed analyses\nthat can offer valuable insights and guidelines for the emerging topic of\nmutually enhancing KG and LLM. We will release the code and data at\nhttps://github.com/David-Li0406/DALK.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Findings; revise format problem",
    "pdf_url": "http://arxiv.org/pdf/2405.04819v4",
    "published_date": "2024-05-08 05:38:20 UTC",
    "updated_date": "2024-10-17 18:31:13 UTC"
  },
  {
    "arxiv_id": "2405.04814v2",
    "title": "A Novel Technique for Query Plan Representation Based on Graph Neural Nets",
    "authors": [
      "Baoming Chang",
      "Amin Kamali",
      "Verena Kantere"
    ],
    "abstract": "Learning representations for query plans play a pivotal role in machine\nlearning-based query optimizers of database management systems. To this end,\nparticular model architectures are proposed in the literature to transform the\ntree-structured query plans into representations with formats learnable by\ndownstream machine learning models. However, existing research rarely compares\nand analyzes the query plan representation capabilities of these tree models\nand their direct impact on the performance of the overall optimizer. To address\nthis problem, we perform a comparative study to explore the effect of using\ndifferent state-of-the-art tree models on the optimizer's cost estimation and\nplan selection performance in relatively complex workloads. Additionally, we\nexplore the possibility of using graph neural networks (GNNs) in the query plan\nrepresentation task. We propose a novel tree model BiGG employing Bidirectional\nGNN aggregated by Gated recurrent units (GRUs) and demonstrate experimentally\nthat BiGG provides significant improvements to cost estimation tasks and\nrelatively excellent plan selection performance compared to the\nstate-of-the-art tree models.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04814v2",
    "published_date": "2024-05-08 04:59:59 UTC",
    "updated_date": "2024-06-05 07:27:20 UTC"
  },
  {
    "arxiv_id": "2405.08005v2",
    "title": "Graphon Mean Field Games with a Representative Player: Analysis and Learning Algorithm",
    "authors": [
      "Fuzhong Zhou",
      "Chenyu Zhang",
      "Xu Chen",
      "Xuan Di"
    ],
    "abstract": "We propose a discrete time graphon game formulation on continuous state and\naction spaces using a representative player to study stochastic games with\nheterogeneous interaction among agents. This formulation admits both\nphilosophical and mathematical advantages, compared to a widely adopted\nformulation using a continuum of players. We prove the existence and uniqueness\nof the graphon equilibrium with mild assumptions, and show that this\nequilibrium can be used to construct an approximate solution for finite player\ngame on networks, which is challenging to analyze and solve due to curse of\ndimensionality. An online oracle-free learning algorithm is developed to solve\nthe equilibrium numerically, and sample complexity analysis is provided for its\nconvergence.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC",
    "comment": "Published as a conference paper at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08005v2",
    "published_date": "2024-05-08 04:44:16 UTC",
    "updated_date": "2024-06-05 02:51:23 UTC"
  },
  {
    "arxiv_id": "2405.04798v2",
    "title": "From LLMs to Actions: Latent Codes as Bridges in Hierarchical Robot Control",
    "authors": [
      "Yide Shentu",
      "Philipp Wu",
      "Aravind Rajeswaran",
      "Pieter Abbeel"
    ],
    "abstract": "Hierarchical control for robotics has long been plagued by the need to have a\nwell defined interface layer to communicate between high-level task planners\nand low-level policies. With the advent of LLMs, language has been emerging as\na prospective interface layer. However, this has several limitations. Not all\ntasks can be decomposed into steps that are easily expressible in natural\nlanguage (e.g. performing a dance routine). Further, it makes end-to-end\nfinetuning on embodied data challenging due to domain shift and catastrophic\nforgetting. We introduce our method -- Learnable Latent Codes as Bridges (LCB)\n-- as an alternate architecture to overcome these limitations. \\method~uses a\nlearnable latent code to act as a bridge between LLMs and low-level policies.\nThis enables LLMs to flexibly communicate goals in the task plan without being\nentirely constrained by language limitations. Additionally, it enables\nend-to-end finetuning without destroying the embedding space of word tokens\nlearned during pre-training. Through experiments on Language Table and Calvin,\ntwo common language based benchmarks for embodied agents, we find that\n\\method~outperforms baselines (including those w/ GPT-4V) that leverage pure\nlanguage as the interface layer on tasks that require reasoning and multi-step\nbehaviors.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04798v2",
    "published_date": "2024-05-08 04:14:06 UTC",
    "updated_date": "2024-07-08 21:02:37 UTC"
  },
  {
    "arxiv_id": "2405.06697v1",
    "title": "Automated Conversion of Static to Dynamic Scheduler via Natural Language",
    "authors": [
      "Paul Mingzheng Tang",
      "Kenji Kah Hoe Leong",
      "Nowshad Shaik",
      "Hoong Chuin Lau"
    ],
    "abstract": "In this paper, we explore the potential application of Large Language Models\n(LLMs) that will automatically model constraints and generate code for dynamic\nscheduling problems given an existing static model. Static scheduling problems\nare modelled and coded by optimization experts. These models may be easily\nobsoleted as the underlying constraints may need to be fine-tuned in order to\nreflect changes in the scheduling rules. Furthermore, it may be necessary to\nturn a static model into a dynamic one in order to cope with disturbances in\nthe environment. In this paper, we propose a Retrieval-Augmented Generation\n(RAG) based LLM model to automate the process of implementing constraints for\nDynamic Scheduling (RAGDyS), without seeking help from an optimization modeling\nexpert. Our framework aims to minimize technical complexities related to\nmathematical modelling and computational workload for end-users, thereby\nallowing end-users to quickly obtain a new schedule close to the original\nschedule with changes reflected by natural language constraint descriptions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages (excluding appendix), 10 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.06697v1",
    "published_date": "2024-05-08 04:07:38 UTC",
    "updated_date": "2024-05-08 04:07:38 UTC"
  },
  {
    "arxiv_id": "2405.04793v2",
    "title": "Zero-shot LLM-guided Counterfactual Generation: A Case Study on NLP Model Evaluation",
    "authors": [
      "Amrita Bhattacharjee",
      "Raha Moraffah",
      "Joshua Garland",
      "Huan Liu"
    ],
    "abstract": "With the development and proliferation of large, complex, black-box models\nfor solving many natural language processing (NLP) tasks, there is also an\nincreasing necessity of methods to stress-test these models and provide some\ndegree of interpretability or explainability. While counterfactual examples are\nuseful in this regard, automated generation of counterfactuals is a data and\nresource intensive process. such methods depend on models such as pre-trained\nlanguage models that are then fine-tuned on auxiliary, often task-specific\ndatasets, that may be infeasible to build in practice, especially for new tasks\nand data domains. Therefore, in this work we explore the possibility of\nleveraging large language models (LLMs) for zero-shot counterfactual generation\nin order to stress-test NLP models. We propose a structured pipeline to\nfacilitate this generation, and we hypothesize that the instruction-following\nand textual understanding capabilities of recent LLMs can be effectively\nleveraged for generating high quality counterfactuals in a zero-shot manner,\nwithout requiring any training or fine-tuning. Through comprehensive\nexperiments on a variety of propreitary and open-source LLMs, along with\nvarious downstream tasks in NLP, we explore the efficacy of LLMs as zero-shot\ncounterfactual generators in evaluating and explaining black-box NLP models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Longer version of short paper accepted at IEEE BigData 2024 (Main\n  Track)",
    "pdf_url": "http://arxiv.org/pdf/2405.04793v2",
    "published_date": "2024-05-08 03:57:45 UTC",
    "updated_date": "2024-11-19 10:59:30 UTC"
  },
  {
    "arxiv_id": "2405.05984v1",
    "title": "Few-Shot Class Incremental Learning via Robust Transformer Approach",
    "authors": [
      "Naeem Paeedeh",
      "Mahardhika Pratama",
      "Sunu Wibirama",
      "Wolfgang Mayer",
      "Zehong Cao",
      "Ryszard Kowalczyk"
    ],
    "abstract": "Few-Shot Class-Incremental Learning presents an extension of the Class\nIncremental Learning problem where a model is faced with the problem of data\nscarcity while addressing the catastrophic forgetting problem. This problem\nremains an open problem because all recent works are built upon the\nconvolutional neural networks performing sub-optimally compared to the\ntransformer approaches. Our paper presents Robust Transformer Approach built\nupon the Compact Convolution Transformer. The issue of overfitting due to few\nsamples is overcome with the notion of the stochastic classifier, where the\nclassifier's weights are sampled from a distribution with mean and variance\nvectors, thus increasing the likelihood of correct classifications, and the\nbatch-norm layer to stabilize the training process. The issue of CF is dealt\nwith the idea of delta parameters, small task-specific trainable parameters\nwhile keeping the backbone networks frozen. A non-parametric approach is\ndeveloped to infer the delta parameters for the model's predictions. The\nprototype rectification approach is applied to avoid biased prototype\ncalculations due to the issue of data scarcity. The advantage of ROBUSTA is\ndemonstrated through a series of experiments in the benchmark problems where it\nis capable of outperforming prior arts with big margins without any data\naugmentation protocols.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review in Information Sciences",
    "pdf_url": "http://arxiv.org/pdf/2405.05984v1",
    "published_date": "2024-05-08 03:35:52 UTC",
    "updated_date": "2024-05-08 03:35:52 UTC"
  },
  {
    "arxiv_id": "2405.06696v1",
    "title": "Multi-level Shared Knowledge Guided Learning for Knowledge Graph Completion",
    "authors": [
      "Yongxue Shan",
      "Jie Zhou",
      "Jie Peng",
      "Xin Zhou",
      "Jiaqian Yin",
      "Xiaodong Wang"
    ],
    "abstract": "In the task of Knowledge Graph Completion (KGC), the existing datasets and\ntheir inherent subtasks carry a wealth of shared knowledge that can be utilized\nto enhance the representation of knowledge triplets and overall performance.\nHowever, no current studies specifically address the shared knowledge within\nKGC. To bridge this gap, we introduce a multi-level Shared Knowledge Guided\nlearning method (SKG) that operates at both the dataset and task levels. On the\ndataset level, SKG-KGC broadens the original dataset by identifying shared\nfeatures within entity sets via text summarization. On the task level, for the\nthree typical KGC subtasks - head entity prediction, relation prediction, and\ntail entity prediction - we present an innovative multi-task learning\narchitecture with dynamically adjusted loss weights. This approach allows the\nmodel to focus on more challenging and underperforming tasks, effectively\nmitigating the imbalance of knowledge sharing among subtasks. Experimental\nresults demonstrate that SKG-KGC outperforms existing text-based methods\nsignificantly on three well-known datasets, with the most notable improvement\non WN18RR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper has been accepted for publication at TACL. And the arXiv\n  version is a pre-MIT Press publication version",
    "pdf_url": "http://arxiv.org/pdf/2405.06696v1",
    "published_date": "2024-05-08 03:27:46 UTC",
    "updated_date": "2024-05-08 03:27:46 UTC"
  },
  {
    "arxiv_id": "2405.05983v1",
    "title": "Real-Time Pill Identification for the Visually Impaired Using Deep Learning",
    "authors": [
      "Bo Dang",
      "Wenchao Zhao",
      "Yufeng Li",
      "Danqing Ma",
      "Qixuan Yu",
      "Elly Yijun Zhu"
    ],
    "abstract": "The prevalence of mobile technology offers unique opportunities for\naddressing healthcare challenges, especially for individuals with visual\nimpairments. This paper explores the development and implementation of a deep\nlearning-based mobile application designed to assist blind and visually\nimpaired individuals in real-time pill identification. Utilizing the YOLO\nframework, the application aims to accurately recognize and differentiate\nbetween various pill types through real-time image processing on mobile\ndevices. The system incorporates Text-to- Speech (TTS) to provide immediate\nauditory feedback, enhancing usability and independence for visually impaired\nusers. Our study evaluates the application's effectiveness in terms of\ndetection accuracy and user experience, highlighting its potential to improve\nmedication management and safety among the visually impaired community.\nKeywords-Deep Learning; YOLO Framework; Mobile Application; Visual Impairment;\nPill Identification; Healthcare",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.05983v1",
    "published_date": "2024-05-08 03:18:46 UTC",
    "updated_date": "2024-05-08 03:18:46 UTC"
  },
  {
    "arxiv_id": "2405.06695v1",
    "title": "Utilizing Large Language Models to Generate Synthetic Data to Increase the Performance of BERT-Based Neural Networks",
    "authors": [
      "Chancellor R. Woolsey",
      "Prakash Bisht",
      "Joshua Rothman",
      "Gondy Leroy"
    ],
    "abstract": "An important issue impacting healthcare is a lack of available experts.\nMachine learning (ML) models could resolve this by aiding in diagnosing\npatients. However, creating datasets large enough to train these models is\nexpensive. We evaluated large language models (LLMs) for data creation. Using\nAutism Spectrum Disorders (ASD), we prompted ChatGPT and GPT-Premium to\ngenerate 4,200 synthetic observations to augment existing medical data. Our\ngoal is to label behaviors corresponding to autism criteria and improve model\naccuracy with synthetic training data. We used a BERT classifier pre-trained on\nbiomedical literature to assess differences in performance between models. A\nrandom sample (N=140) from the LLM-generated data was evaluated by a clinician\nand found to contain 83% correct example-label pairs. Augmenting data increased\nrecall by 13% but decreased precision by 16%, correlating with higher quality\nand lower accuracy across pairs. Future work will analyze how different\nsynthetic data traits affect ML outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in 2024 American Medical Informatics Association (AMIA)\n  Summit March 18-21",
    "pdf_url": "http://arxiv.org/pdf/2405.06695v1",
    "published_date": "2024-05-08 03:18:12 UTC",
    "updated_date": "2024-05-08 03:18:12 UTC"
  },
  {
    "arxiv_id": "2405.04776v3",
    "title": "Chain of Thoughtlessness? An Analysis of CoT in Planning",
    "authors": [
      "Kaya Stechly",
      "Karthik Valmeekam",
      "Subbarao Kambhampati"
    ],
    "abstract": "Large language model (LLM) performance on reasoning problems typically does\nnot generalize out of distribution. Previous work has claimed that this can be\nmitigated with chain of thought prompting-a method of demonstrating solution\nprocedures-with the intuition that it is possible to in-context teach an LLM an\nalgorithm for solving the problem. This paper presents a case study of chain of\nthought on problems from Blocksworld, a classical planning domain, and examines\nthe performance of two state-of-the-art LLMs across two axes: generality of\nexamples given in prompt, and complexity of problems queried with each prompt.\nWhile our problems are very simple, we only find meaningful performance\nimprovements from chain of thought prompts when those prompts are exceedingly\nspecific to their problem class, and that those improvements quickly\ndeteriorate as the size n of the query-specified stack grows past the size of\nstacks shown in the examples. We also create scalable variants of three domains\ncommonly studied in previous CoT papers and demonstrate the existence of\nsimilar failure modes. Our results hint that, contrary to previous claims in\nthe literature, CoT's performance improvements do not stem from the model\nlearning general algorithmic procedures via demonstrations but depend on\ncarefully engineering highly problem specific prompts. This spotlights\ndrawbacks of chain of thought, especially the sharp tradeoff between possible\nperformance gains and the amount of human labor necessary to generate examples\nwith correct reasoning traces.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04776v3",
    "published_date": "2024-05-08 02:48:28 UTC",
    "updated_date": "2025-03-12 04:56:46 UTC"
  },
  {
    "arxiv_id": "2405.04773v2",
    "title": "Hypergraph-enhanced Dual Semi-supervised Graph Classification",
    "authors": [
      "Wei Ju",
      "Zhengyang Mao",
      "Siyu Yi",
      "Yifang Qin",
      "Yiyang Gu",
      "Zhiping Xiao",
      "Yifan Wang",
      "Xiao Luo",
      "Ming Zhang"
    ],
    "abstract": "In this paper, we study semi-supervised graph classification, which aims at\naccurately predicting the categories of graphs in scenarios with limited\nlabeled graphs and abundant unlabeled graphs. Despite the promising capability\nof graph neural networks (GNNs), they typically require a large number of\ncostly labeled graphs, while a wealth of unlabeled graphs fail to be\neffectively utilized. Moreover, GNNs are inherently limited to encoding local\nneighborhood information using message-passing mechanisms, thus lacking the\nability to model higher-order dependencies among nodes. To tackle these\nchallenges, we propose a Hypergraph-Enhanced DuAL framework named HEAL for\nsemi-supervised graph classification, which captures graph semantics from the\nperspective of the hypergraph and the line graph, respectively. Specifically,\nto better explore the higher-order relationships among nodes, we design a\nhypergraph structure learning to adaptively learn complex node dependencies\nbeyond pairwise relations. Meanwhile, based on the learned hypergraph, we\nintroduce a line graph to capture the interaction between hyperedges, thereby\nbetter mining the underlying semantic structures. Finally, we develop a\nrelational consistency learning to facilitate knowledge transfer between the\ntwo branches and provide better mutual guidance. Extensive experiments on\nreal-world graph datasets verify the effectiveness of the proposed method\nagainst existing state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by Proceedings of the 41st International Conference on\n  Machine Learning (ICML 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.04773v2",
    "published_date": "2024-05-08 02:44:13 UTC",
    "updated_date": "2024-05-28 09:19:55 UTC"
  },
  {
    "arxiv_id": "2405.04767v1",
    "title": "Test-Time Augmentation for Traveling Salesperson Problem",
    "authors": [
      "Ryo Ishiyama",
      "Takahiro Shirakawa",
      "Seiichi Uchida",
      "Shinnosuke Matsuo"
    ],
    "abstract": "We propose Test-Time Augmentation (TTA) as an effective technique for\naddressing combinatorial optimization problems, including the Traveling\nSalesperson Problem. In general, deep learning models possessing the property\nof invariance, where the output is uniquely determined regardless of the node\nindices, have been proposed to learn graph structures efficiently. In contrast,\nwe interpret the permutation of node indices, which exchanges the elements of\nthe distance matrix, as a TTA scheme. The results demonstrate that our method\nis capable of obtaining shorter solutions than the latest models. Furthermore,\nwe show that the probability of finding a solution closer to an exact solution\nincreases depending on the augmentation size.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04767v1",
    "published_date": "2024-05-08 02:31:51 UTC",
    "updated_date": "2024-05-08 02:31:51 UTC"
  },
  {
    "arxiv_id": "2405.04765v1",
    "title": "When Foresight Pruning Meets Zeroth-Order Optimization: Efficient Federated Learning for Low-Memory Devices",
    "authors": [
      "Pengyu Zhang",
      "Yingjie Liu",
      "Yingbo Zhou",
      "Xiao Du",
      "Xian Wei",
      "Ting Wang",
      "Mingsong Chen"
    ],
    "abstract": "Although Federated Learning (FL) enables collaborative learning in Artificial\nIntelligence of Things (AIoT) design, it fails to work on low-memory AIoT\ndevices due to its heavy memory usage. To address this problem, various\nfederated pruning methods are proposed to reduce memory usage during inference.\nHowever, few of them can substantially mitigate the memory burdens during\npruning and training. As an alternative, zeroth-order or backpropagation-free\n(BP-Free) methods can partially alleviate the memory consumption, but they\nsuffer from scaling up and large computation overheads, since the gradient\nestimation error and floating point operations (FLOPs) increase as the\ndimensionality of the model parameters grows. In this paper, we propose a\nfederated foresight pruning method based on Neural Tangent Kernel (NTK), which\ncan seamlessly integrate with federated BP-Free training frameworks. We present\nan approximation to the computation of federated NTK by using the local NTK\nmatrices. Moreover, we demonstrate that the data-free property of our method\ncan substantially reduce the approximation error in extreme data heterogeneity\nscenarios. Since our approach improves the performance of the vanilla BP-Free\nmethod with fewer FLOPs and truly alleviates memory pressure during training\nand inference, it makes FL more friendly to low-memory devices. Comprehensive\nexperimental results obtained from simulation- and real test-bed-based\nplatforms show that our federated foresight-pruning method not only preserves\nthe ability of the dense model with a memory reduction up to 9x but also boosts\nthe performance of the vanilla BP-Free method with dramatically fewer FLOPs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.04765v1",
    "published_date": "2024-05-08 02:24:09 UTC",
    "updated_date": "2024-05-08 02:24:09 UTC"
  },
  {
    "arxiv_id": "2405.04760v4",
    "title": "Large Language Models for Cyber Security: A Systematic Literature Review",
    "authors": [
      "Hanxiang Xu",
      "Shenao Wang",
      "Ningke Li",
      "Kailong Wang",
      "Yanjie Zhao",
      "Kai Chen",
      "Ting Yu",
      "Yang Liu",
      "Haoyu Wang"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has opened up new\nopportunities for leveraging artificial intelligence in various domains,\nincluding cybersecurity. As the volume and sophistication of cyber threats\ncontinue to grow, there is an increasing need for intelligent systems that can\nautomatically detect vulnerabilities, analyze malware, and respond to attacks.\nIn this survey, we conduct a comprehensive review of the literature on the\napplication of LLMs in cybersecurity (LLM4Security). By comprehensively\ncollecting over 30K relevant papers and systematically analyzing 127 papers\nfrom top security and software engineering venues, we aim to provide a holistic\nview of how LLMs are being used to solve diverse problems across the\ncybersecurity domain. Through our analysis, we identify several key findings.\nFirst, we observe that LLMs are being applied to a wide range of cybersecurity\ntasks, including vulnerability detection, malware analysis, network intrusion\ndetection, and phishing detection. Second, we find that the datasets used for\ntraining and evaluating LLMs in these tasks are often limited in size and\ndiversity, highlighting the need for more comprehensive and representative\ndatasets. Third, we identify several promising techniques for adapting LLMs to\nspecific cybersecurity domains, such as fine-tuning, transfer learning, and\ndomain-specific pre-training. Finally, we discuss the main challenges and\nopportunities for future research in LLM4Security, including the need for more\ninterpretable and explainable models, the importance of addressing data privacy\nand security concerns, and the potential for leveraging LLMs for proactive\ndefense and threat hunting. Overall, our survey provides a comprehensive\noverview of the current state-of-the-art in LLM4Security and identifies several\npromising directions for future research.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "56 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04760v4",
    "published_date": "2024-05-08 02:09:17 UTC",
    "updated_date": "2025-05-15 07:33:07 UTC"
  },
  {
    "arxiv_id": "2405.04758v2",
    "title": "Honeyfile Camouflage: Hiding Fake Files in Plain Sight",
    "authors": [
      "Roelien C. Timmer",
      "David Liebowitz",
      "Surya Nepal",
      "Salil S. Kanhere"
    ],
    "abstract": "Honeyfiles are a particularly useful type of honeypot: fake files deployed to\ndetect and infer information from malicious behaviour. This paper considers the\nchallenge of naming honeyfiles so they are camouflaged when placed amongst real\nfiles in a file system. Based on cosine distances in semantic vector spaces, we\ndevelop two metrics for filename camouflage: one based on simple averaging and\none on clustering with mixture fitting. We evaluate and compare the metrics,\nshowing that both perform well on a publicly available GitHub software\nrepository dataset.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "3rd Workshop on the security implications of Deepfakes and Cheapfakes\n  (WDC) co-located at ACM ASIACCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04758v2",
    "published_date": "2024-05-08 02:01:17 UTC",
    "updated_date": "2024-05-10 05:12:47 UTC"
  },
  {
    "arxiv_id": "2405.04753v1",
    "title": "AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models",
    "authors": [
      "Yongheng Zhang",
      "Tingwen Du",
      "Yunshan Ma",
      "Xiang Wang",
      "Yi Xie",
      "Guozheng Yang",
      "Yuliang Lu",
      "Ee-Chien Chang"
    ],
    "abstract": "Attack knowledge graph construction seeks to convert textual cyber threat\nintelligence (CTI) reports into structured representations, portraying the\nevolutionary traces of cyber attacks. Even though previous research has\nproposed various methods to construct attack knowledge graphs, they generally\nsuffer from limited generalization capability to diverse knowledge types as\nwell as requirement of expertise in model design and tuning. Addressing these\nlimitations, we seek to utilize Large Language Models (LLMs), which have\nachieved enormous success in a broad range of tasks given exceptional\ncapabilities in both language understanding and zero-shot task fulfillment.\nThus, we propose a fully automatic LLM-based framework to construct attack\nknowledge graphs named: AttacKG+. Our framework consists of four consecutive\nmodules: rewriter, parser, identifier, and summarizer, each of which is\nimplemented by instruction prompting and in-context learning empowered by LLMs.\nFurthermore, we upgrade the existing attack knowledge schema and propose a\ncomprehensive version. We represent a cyber attack as a temporally unfolding\nevent, each temporal step of which encapsulates three layers of representation,\nincluding behavior graph, MITRE TTP labels, and state summary. Extensive\nevaluation demonstrates that: 1) our formulation seamlessly satisfies the\ninformation needs in threat event analysis, 2) our construction framework is\neffective in faithfully and accurately extracting the information defined by\nAttacKG+, and 3) our attack graph directly benefits downstream security\npractices such as attack reconstruction. All the code and datasets will be\nreleased upon acceptance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.04753v1",
    "published_date": "2024-05-08 01:41:25 UTC",
    "updated_date": "2024-05-08 01:41:25 UTC"
  },
  {
    "arxiv_id": "2405.04746v1",
    "title": "SVD-AE: Simple Autoencoders for Collaborative Filtering",
    "authors": [
      "Seoyoung Hong",
      "Jeongwhan Choi",
      "Yeon-Chang Lee",
      "Srijan Kumar",
      "Noseong Park"
    ],
    "abstract": "Collaborative filtering (CF) methods for recommendation systems have been\nextensively researched, ranging from matrix factorization and autoencoder-based\nto graph filtering-based methods. Recently, lightweight methods that require\nalmost no training have been recently proposed to reduce overall computation.\nHowever, existing methods still have room to improve the trade-offs among\naccuracy, efficiency, and robustness. In particular, there are no well-designed\nclosed-form studies for \\emph{balanced} CF in terms of the aforementioned\ntrade-offs. In this paper, we design SVD-AE, a simple yet effective singular\nvector decomposition (SVD)-based linear autoencoder, whose closed-form solution\ncan be defined based on SVD for CF. SVD-AE does not require iterative training\nprocesses as its closed-form solution can be calculated at once. Furthermore,\ngiven the noisy nature of the rating matrix, we explore the robustness against\nsuch noisy interactions of existing CF methods and our SVD-AE. As a result, we\ndemonstrate that our simple design choice based on truncated SVD can be used to\nstrengthen the noise robustness of the recommendation while improving\nefficiency. Code is available at https://github.com/seoyoungh/svd-ae.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.04746v1",
    "published_date": "2024-05-08 01:22:47 UTC",
    "updated_date": "2024-05-08 01:22:47 UTC"
  },
  {
    "arxiv_id": "2405.04732v3",
    "title": "Is the House Ready For Sleeptime? Generating and Evaluating Situational Queries for Embodied Question Answering",
    "authors": [
      "Vishnu Sashank Dorbala",
      "Prasoon Goyal",
      "Robinson Piramuthu",
      "Michael Johnston",
      "Reza Ghanadhan",
      "Dinesh Manocha"
    ],
    "abstract": "We present and tackle the problem of Embodied Question Answering (EQA) with\nSituational Queries (S-EQA) in a household environment. Unlike prior EQA work\ntackling simple queries that directly reference target objects and properties\n(\"What is the color of the car?\"), situational queries (such as \"Is the house\nready for sleeptime?\") are challenging as they require the agent to correctly\nidentify multiple object-states (Doors: Closed, Lights: Off, etc.) and reach a\nconsensus on their states for an answer. Towards this objective, we first\nintroduce a novel Prompt-Generate-Evaluate (PGE) scheme that wraps around an\nLLM's output to generate unique situational queries and corresponding consensus\nobject information. PGE is used to generate 2K datapoints in the VirtualHome\nsimulator, which is then annotated for ground truth answers via a large scale\nuser-study conducted on M-Turk. With a high rate of answerability (97.26%) on\nthis study, we establish that LLMs are good at generating situational data.\nHowever, in evaluating the data using an LLM, we observe a low correlation of\n46.2% with the ground truth human annotations; indicating that while LLMs are\ngood at generating situational data, they struggle to answer them according to\nconsensus. When asked for reasoning, we observe the LLM often goes against\ncommonsense in justifying its answer. Finally, we utilize PGE to generate\nsituational data in a real-world environment, exposing LLM hallucination in\ngenerating reliable object-states when a structured scene graph is unavailable.\nTo the best of our knowledge, this is the first work to introduce EQA in the\ncontext of situational queries and also the first to present a generative\napproach for query creation. We aim to foster research on improving the\nreal-world usability of embodied agents through this work.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 Pages",
    "pdf_url": "http://arxiv.org/pdf/2405.04732v3",
    "published_date": "2024-05-08 00:45:20 UTC",
    "updated_date": "2025-03-10 21:12:19 UTC"
  }
]