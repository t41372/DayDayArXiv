{
  "date": "2025-02-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-23 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了约 96 篇论文，主要聚焦 AI 模型优化、多模态生成和医疗应用等领域。重点包括大型语言模型（LLMs）在数据库查询和知识转移中的创新突破，以及新基准数据集的提出；令人印象深刻的文章有 DeepSeek 在中国三级医院的医疗应用，以及 Reflective Planning 等机器人规划框架；知名学者如 Google 和 OpenAI 相关团队的作品（如 Gemini 和 ChatGPT 系列）也值得关注，这些论文突显了 AI 在实际领域的潜力。\n\n下面，我挑选了今天最具代表性和话题度的论文进行简要概述，先聊 AI 和 LLMs 相关的内容，再涉及医疗和机器人领域。其他较常规或理论导向的论文（如一些纯优化算法或小数据集实验）将快速掠过。\n\n### AI 和 LLMs 优化\n- **SQLong: Enhanced NL2SQL for Longer Contexts with LLMs**（SQLong: 增强自然语言到 SQL 的长上下文处理）  \n  作者：Dai Quoc Nguyen 等。论文提出 SQLong 框架，使用数据增强方法改善 LLMs 在长数据库查询中的性能。通过在 Spider 和 BIRD 数据集上的实验，证明了它在处理复杂数据库时的优越性，主要贡献是模拟长上下文场景，提升 NL2SQL 任务的实际应用。\n\n- **AUKT: Adaptive Uncertainty-Guided Knowledge Transfer with Conformal Prediction**（AUKT: 自适应不确定性引导知识转移）  \n  作者：Rui Liu 等。引入 AUKT 框架，利用 Conformal Prediction 动态调整教师模型的不确定性，实现更鲁棒的知识转移。在图像分类和机器人学习等应用中表现突出，关键发现是它提高了模型的鲁棒性和泛化能力。\n\n- **DeepSeek reshaping healthcare in China's tertiary hospitals**（DeepSeek 重塑中国三级医院的医疗）  \n  作者：Jishizhan Chen 等。讨论 DeepSeek AI 系统在中国的部署，提升诊断准确性和工作流效率。论文强调 AI 在医疗中的伦理挑战，如责任归属，并预测未来整合多模态数据，这对全球医疗 AI 有重要启发。\n\n- **RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents**（RapidPen: 基于 LLMs 的全自动渗透测试）  \n  作者：Sho Nakatani。开发 RapidPen 框架，使用 LLMs 自动发现和利用漏洞，显著提高渗透测试效率。实验显示它在 200-400 秒内实现 shell 访问，成本低廉，这对网络安全领域有实际价值。\n\n- **Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation**（Reflective Planning: 用于多阶段机器人操作的视觉语言模型）  \n  作者：Yunhai Feng 等。提出一个测试时计算框架，提升 VLMs 在机器人任务中的物理推理能力。通过迭代预测和行动选择，显著超越现有方法，如 Monte Carlo Tree Search。\n\n- **SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance**（SBSC: 用于数学奥林匹克的逐步编码方法）  \n  作者：Kunal Singh 等。引入 SBSC 框架，让 LLMs 通过生成程序序列解决奥林匹克级数学问题。实验在 AMC 和 AIME 数据集上提升了 8-12% 的性能，展示了 LLMs 在复杂推理中的潜力。\n\n### 医疗和生物应用\n- **Liver Cirrhosis Stage Estimation from MRI with Deep Learning**（基于深度学习的 MRI 肝硬化分期估计）  \n  作者：Jun Zeng 等。开发端到端框架，使用多序列 MRI 估计肝硬化分期，准确率达 72.8%，优于传统方法。主要贡献是捕捉微妙组织变化，提供临床决策支持。\n\n- **A Reverse Mamba Attention Network for Pathological Liver Segmentation**（RMA-Mamba: 用于病理肝脏分割的反向 Mamba 注意力网络）  \n  作者：Jun Zeng 等。提出 RMA-Mamba 架构，提升肝脏分割精度，在 CirrMRI600+ 数据集上达 92.08% Dice 系数。关键发现是它在 CT 和 MRI 中的泛化性强，对病理图像分析有重要影响。\n\n- **UniBrain: End-to-End Deep Learning for Structural Brain Imaging**（UniBrain: 脑结构成像的端到端深度学习框架）  \n  作者：Yao Su 等。构建统一框架处理脑成像任务，如提取和分割，仅需最小监督。实验显示它在多任务上优于现有方法，潜力在于减少标注努力。\n\n### 机器人和生成模型\n- **DOSE3: Diffusion-based Out-of-distribution detection on SE(3) trajectories**（DOSE3: 基于扩散的 SE(3) 轨迹异常检测）  \n  作者：Hongzhe Cheng 等。扩展扩散模型到 3D 轨迹异常检测，适用于机器人和计算机视觉。论文在基准数据集上表现出色，贡献是处理复杂轨迹分布。\n\n- **NatSGLD: A Dataset with Speech, Gesture, Logic, and Demonstration for Robot Learning**（NatSGLD: 用于机器人学习的语音、手势、逻辑和演示数据集）  \n  作者：Snehesh Shrestha 等。发布新数据集，支持多模态机器人交互学习，包括 LTL 公式注解。主要发现是它提升了机器人指令遵循和计划识别。\n\n其他论文如 Order-Optimal Projection-Free Algorithm（优化凸优化算法）和 Layer-Wise Evolution（Transformer 微调分析）等虽有技术贡献，但相对专业且不具话题度，故快速掠过：它们分别优化了在线凸优化和特征演化，但未涉及重大应用创新。\n\n总之，今天的论文强调 AI 的实用性和鲁棒性，LLMs 在医疗和机器人中的应用尤其值得跟踪。未来几天，继续关注这些领域的进展！",
  "papers": [
    {
      "arxiv_id": "2502.16747v2",
      "title": "SQLong: Enhanced NL2SQL for Longer Contexts with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Dai Quoc Nguyen",
        "Cong Duy Vu Hoang",
        "Duy Vu",
        "Gioacchino Tangari",
        "Thanh Tien Vu",
        "Don Dharmasiri",
        "Yuan-Fang Li",
        "Long Duong"
      ],
      "abstract": "Open-weight large language models (LLMs) have significantly advanced\nperformance in the Natural Language to SQL (NL2SQL) task. However, their\neffectiveness diminishes when dealing with large database schemas, as the\ncontext length increases. To address this limitation, we present SQLong, a\nnovel and efficient data augmentation framework designed to enhance LLM\nperformance in long-context scenarios for the NL2SQL task. SQLong generates\naugmented datasets by extending existing database schemas with additional\nsynthetic CREATE TABLE commands and corresponding data rows, sampled from\ndiverse schemas in the training data. This approach effectively simulates\nlong-context scenarios during finetuning and evaluation. Through experiments on\nthe Spider and BIRD datasets, we demonstrate that LLMs finetuned with\nSQLong-augmented data significantly outperform those trained on standard\ndatasets. These imply SQLong's practical implementation and its impact on\nimproving NL2SQL capabilities in real-world settings with complex database\nschemas.",
      "tldr_zh": "该论文提出 SQLong，一种新型数据增强框架，旨在提升大型语言模型（LLMs）在自然语言到 SQL（NL2SQL）任务中处理长上下文的能力，以解决大数据库模式带来的性能下降问题。SQLong 通过从训练数据中采样多样模式，生成增强数据集，包括额外的合成 CREATE TABLE 命令和对应数据行，从而模拟长上下文场景。实验在 Spider 和 BIRD 数据集上表明，使用 SQLong 增强数据的 LLMs 显著优于标准数据集训练的模型，提升了 NL2SQL 在复杂真实世界数据库中的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Table Representation Learning Workshop at ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16747v2",
      "published_date": "2025-02-23 23:23:51 UTC",
      "updated_date": "2025-05-20 12:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:36:45.945471"
    },
    {
      "arxiv_id": "2502.16744v1",
      "title": "Order-Optimal Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization",
      "title_zh": "针对对抗性约束在线凸优化的阶最优无投影算法",
      "authors": [
        "Yiyang Lu",
        "Mohammad Pedramfar",
        "Vaneet Aggarwal"
      ],
      "abstract": "Projection-based algorithms for constrained Online Convex Optimization (COCO)\nface scalability challenges in high-dimensional settings due to the\ncomputational complexity of projecting iterates onto constraint sets. This\npaper introduces a projection-free algorithm for COCO that achieves\nstate-of-the-art performance guarantees while eliminating the need for\nprojections. By integrating a separation oracle with adaptive Online Gradient\nDescent (OGD) and employing a Lyapunov-driven surrogate function, while\ndynamically adjusting step sizes using gradient norms, our method jointly\noptimizes the regret and cumulative constraint violation (CCV). We also use a\nblocked version of OGD that helps achieve tradeoffs betweeen the regret and CCV\nwith the number of calls to the separation oracle. For convex cost functions,\nour algorithm attains an optimal regret of $\\mathcal{O}(\\sqrt{T})$ and a CCV of\n$\\mathcal{O}(\\sqrt{T} \\log T)$, matching the best-known projection-based\nresults, while only using $\\tilde{\\mathcal{O}}({T})$ calls to the separation\noracle. The results also demonstrate a tradeoff where lower calls to the\nseparation oracle increase the regret and the CCV. In the strongly convex\nsetting, we further achieve a regret of $\\mathcal{O}(\\log T)$ and a CCV of\n$\\mathcal{O}(\\sqrt{T\\log T} )$, while requiring ${\\mathcal{O}}({T}^2)$ calls to\nthe separation oracle. Further, tradeoff with the decreasing oracle calls is\nstudied. These results close the gap between projection-free and\nprojection-based approaches, demonstrating that projection-free methods can\nachieve performance comparable to projection-based counterparts.",
      "tldr_zh": "这篇论文提出了一种无投影算法，用于对抗约束的在线凸优化（Adversarially Constrained Online Convex Optimization），旨在解决高维设置下投影计算的扩展性挑战。算法通过整合分离预言机（separation oracle）、自适应 Online Gradient Descent (OGD) 和 Lyapunov 驱动的代理函数，并动态调整步长，来优化 regret 和 cumulative constraint violation (CCV)。对于凸成本函数，该算法实现了最优的 regret 为 $\\mathcal{O}(\\sqrt{T})$ 和 CCV 为 $\\mathcal{O}(\\sqrt{T} \\log T)$，仅需 $\\tilde{\\mathcal{O}}(T)$ 次分离预言机调用，与最佳投影算法相当。在强凸设置下，regret 进一步降低至 $\\mathcal{O}(\\log T)$ 和 CCV 为 $\\mathcal{O}(\\sqrt{T \\log T})$，但需 $\\mathcal{O}(T^2)$ 次调用。结果展示了分离预言机调用次数与 regret 和 CCV 之间的权衡，证明无投影方法可与投影方法媲美。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16744v1",
      "published_date": "2025-02-23 23:18:40 UTC",
      "updated_date": "2025-02-23 23:18:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:01.282959"
    },
    {
      "arxiv_id": "2502.16736v2",
      "title": "AUKT: Adaptive Uncertainty-Guided Knowledge Transfer with Conformal Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Liu",
        "Peng Gao",
        "Yu Shen",
        "Ming Lin",
        "Pratap Tokekar"
      ],
      "abstract": "Knowledge transfer between teacher and student models has proven effective\nacross various machine learning applications. However, challenges arise when\nthe teacher's predictions are noisy, or the data domain during student training\nshifts from the teacher's pretraining data. In such scenarios, blindly relying\non the teacher's predictions can lead to suboptimal knowledge transfer. To\naddress these challenges, we propose a novel and universal framework, Adaptive\nUncertainty-guided Knowledge Transfer ($\\textbf{AUKT}$), which leverages\nConformal Prediction (CP) to dynamically adjust the student's reliance on the\nteacher's guidance based on the teacher's prediction uncertainty. CP is a\ndistribution-free, model-agnostic approach that provides reliable prediction\nsets with statistical coverage guarantees and minimal computational overhead.\nThis adaptive mechanism mitigates the risk of learning undesirable or incorrect\nknowledge. We validate the proposed framework across diverse applications,\nincluding image classification, imitation-guided reinforcement learning, and\nautonomous driving. Experimental results consistently demonstrate that our\napproach improves performance, robustness and transferability, offering a\npromising direction for enhanced knowledge transfer in real-world applications.",
      "tldr_zh": "该论文提出了一种新型框架 AUKT（Adaptive Uncertainty-guided Knowledge Transfer），利用 Conformal Prediction 来解决知识转移中教师模型预测噪声和数据域移位的问题。AUKT 通过动态调整学生模型对教师指导的依赖程度，根据教师的预测不确定性来减少学习错误知识的风险，该方法是分布无关且模型无关的，具有统计覆盖保证和低计算开销。在图像分类、模仿引导强化学习和自动驾驶等应用中，实验结果显示 AUKT 显著提升了性能、鲁棒性和可转移性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16736v2",
      "published_date": "2025-02-23 22:39:19 UTC",
      "updated_date": "2025-02-25 04:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:10.060277"
    },
    {
      "arxiv_id": "2502.16732v2",
      "title": "DeepSeek reshaping healthcare in China's tertiary hospitals",
      "title_zh": "翻译失败",
      "authors": [
        "Jishizhan Chen",
        "Qingzeng Zhang"
      ],
      "abstract": "The rapid integration of artificial intelligence (AI) into healthcare is\ntransforming clinical decision-making and hospital operations. DeepSeek has\nemerged as a leading AI system, widely deployed across China's tertiary\nhospitals since January 2025. Initially implemented in Shanghai's major medical\ninstitutions, it has since expanded nationwide, enhancing diagnostic accuracy,\nstreamlining workflows, and improving patient management. AI-powered pathology,\nimaging analysis, and clinical decision support systems have demonstrated\nsignificant potential in optimizing medical processes and reducing the\ncognitive burden on healthcare professionals. However, the widespread adoption\nof AI in healthcare raises critical regulatory and ethical challenges,\nparticularly regarding accountability in AI-assisted diagnosis and the risk of\nautomation bias. The absence of a well-defined liability framework underscores\nthe need for policies that ensure AI functions as an assistive tool rather than\nan autonomous decision-maker. With continued technological advancements, AI is\nexpected to integrate multimodal data sources, such as genomics and radiomics,\npaving the way for precision medicine and personalized treatment strategies.\nThe future of AI in healthcare depends on the development of transparent\nregulatory structures, industry collaboration, and adaptive governance\nframeworks that balance innovation with responsibility, ensuring equitable and\neffective AI-driven medical services.",
      "tldr_zh": "该研究探讨了DeepSeek AI系统在中国的三级医院中的应用，自2025年1月起从上海扩展到全国，提升了诊断准确性、工作流程效率和患者管理。DeepSeek通过AI驱动的病理学、影像分析和临床决策支持系统，优化医疗过程并减轻医务人员的认知负担。论文强调了AI采用的潜在挑战，包括责任归属问题和自动化偏差风险，并呼吁建立明确的监管框架以确保AI作为辅助工具。展望未来，DeepSeek有望整合多模态数据源如genomics和radiomics，推动precision medicine和个性化治疗，同时需要行业合作和适应性治理以平衡创新与伦理责任。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16732v2",
      "published_date": "2025-02-23 22:09:17 UTC",
      "updated_date": "2025-02-27 10:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:21.890180"
    },
    {
      "arxiv_id": "2502.16730v1",
      "title": "RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Sho Nakatani"
      ],
      "abstract": "We present RapidPen, a fully automated penetration testing (pentesting)\nframework that addresses\n  the challenge of achieving an initial foothold (IP-to-Shell) without human\nintervention. Unlike prior\n  approaches that focus primarily on post-exploitation or require a\nhuman-in-the-loop, RapidPen\n  leverages large language models (LLMs) to autonomously discover and exploit\nvulnerabilities, starting from\n  a single IP address. By integrating advanced ReAct-style task planning (Re)\nwith retrieval-augmented\n  knowledge bases of successful exploits, along with a command-generation and\ndirect execution feedback loop\n  (Act), RapidPen systematically scans services, identifies viable attack\nvectors, and executes targeted\n  exploits in a fully automated manner.\n  In our evaluation against a vulnerable target from the Hack The Box platform,\nRapidPen achieved shell\n  access within 200-400 seconds at a per-run cost of approximately \\$0.3-\\$0.6,\ndemonstrating a\n  60\\% success rate when reusing prior \"success-case\" data. These results\nunderscore the potential\n  of truly autonomous pentesting for both security novices and seasoned\nprofessionals. Organizations\n  without dedicated security teams can leverage RapidPen to quickly identify\ncritical vulnerabilities,\n  while expert pentesters can offload repetitive tasks and focus on complex\nchallenges.\n  Ultimately, our work aims to make penetration testing more accessible and\ncost-efficient,\n  thereby enhancing the overall security posture of modern software ecosystems.",
      "tldr_zh": "本文介绍了RapidPen，一种基于LLMs的完全自动化的渗透测试框架，用于从单一IP地址实现初始入侵（IP-to-Shell），无需人工干预。RapidPen整合了ReAct-style任务规划（Re）、检索增强知识库以及命令生成和执行反馈循环（Act），系统地扫描服务、识别攻击向量并执行针对性利用。实验结果显示，在Hack The Box平台的测试中，该框架在200-400秒内成功获得shell访问，成功率达60%，成本仅0.3-0.6美元，从而使渗透测试更易访问、成本高效，并提升软件生态系统的整体安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16730v1",
      "published_date": "2025-02-23 21:57:46 UTC",
      "updated_date": "2025-02-23 21:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:34.270271"
    },
    {
      "arxiv_id": "2502.16725v1",
      "title": "DOSE3 : Diffusion-based Out-of-distribution detection on SE(3) trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhe Cheng",
        "Tianyou Zheng",
        "Tianyi Zhang",
        "Matthew Johnson-Roberson",
        "Weiming Zhi"
      ],
      "abstract": "Out-of-Distribution(OOD) detection, a fundamental machine learning task aimed\nat identifying abnormal samples, traditionally requires model retraining for\ndifferent inlier distributions. While recent research demonstrates the\napplicability of diffusion models to OOD detection, existing approaches are\nlimited to Euclidean or latent image spaces. Our work extends OOD detection to\ntrajectories in the Special Euclidean Group in 3D ($\\mathbb{SE}(3)$),\naddressing a critical need in computer vision, robotics, and engineering\napplications that process object pose sequences in $\\mathbb{SE}(3)$. We present\n$\\textbf{D}$iffusion-based $\\textbf{O}$ut-of-distribution detection on\n$\\mathbb{SE}(3)$ ($\\mathbf{DOSE3}$), a novel OOD framework that extends\ndiffusion to a unified sample space of $\\mathbb{SE}(3)$ pose sequences. Through\nextensive validation on multiple benchmark datasets, we demonstrate\n$\\mathbf{DOSE3}$'s superior performance compared to state-of-the-art OOD\ndetection frameworks.",
      "tldr_zh": "该论文提出了DOSE3，一种基于扩散模型的Out-of-Distribution (OOD)检测框架，将OOD检测扩展到SE(3)轨迹空间，以解决传统方法在计算机视觉、机器人和工程应用中处理物体位姿序列的局限性。DOSE3通过将扩散模型应用于SE(3)的统一样本空间，实现对异常样本的更高效识别，而无需针对不同内部分布重新训练模型。实验结果显示，在多个基准数据集上，DOSE3的性能优于现有最先进框架，为相关领域提供了更可靠的OOD检测解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16725v1",
      "published_date": "2025-02-23 21:32:48 UTC",
      "updated_date": "2025-02-23 21:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:45.432527"
    },
    {
      "arxiv_id": "2502.16722v1",
      "title": "Layer-Wise Evolution of Representations in Fine-Tuned Transformers: Insights from Sparse AutoEncoders",
      "title_zh": "翻译失败",
      "authors": [
        "Suneel Nadipalli"
      ],
      "abstract": "Fine-tuning pre-trained transformers is a powerful technique for enhancing\nthe performance of base models on specific tasks. From early applications in\nmodels like BERT to fine-tuning Large Language Models (LLMs), this approach has\nbeen instrumental in adapting general-purpose architectures for specialized\ndownstream tasks. Understanding the fine-tuning process is crucial for\nuncovering how transformers adapt to specific objectives, retain general\nrepresentations, and acquire task-specific features. This paper explores the\nunderlying mechanisms of fine-tuning, specifically in the BERT transformer, by\nanalyzing activation similarity, training Sparse AutoEncoders (SAEs), and\nvisualizing token-level activations across different layers. Based on\nexperiments conducted across multiple datasets and BERT layers, we observe a\nsteady progression in how features adapt to the task at hand: early layers\nprimarily retain general representations, middle layers act as a transition\nbetween general and task-specific features, and later layers fully specialize\nin task adaptation. These findings provide key insights into the inner workings\nof fine-tuning and its impact on representation learning within transformer\narchitectures.",
      "tldr_zh": "本研究探讨了 fine-tuned transformers（如 BERT）在适应特定任务时的表示演化过程，通过分析激活相似性、训练 Sparse AutoEncoders (SAEs) 以及可视化不同层的 token-level 激活来揭示其内部机制。实验结果显示，在多个数据集上，早期层主要保留一般表示，中间层充当从一般到任务特定特征的过渡，而后期层则完全专于任务适应。总体而言，该工作为理解 fine-tuning 如何平衡一般性和任务专化提供了关键洞见，从而提升 transformer 架构的表示学习效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16722v1",
      "published_date": "2025-02-23 21:29:50 UTC",
      "updated_date": "2025-02-23 21:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:37:57.305924"
    },
    {
      "arxiv_id": "2502.16721v1",
      "title": "Speed and Conversational Large Language Models: Not All Is About Tokens per Second",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Conde",
        "Miguel González",
        "Pedro Reviriego",
        "Zhen Gao",
        "Shanshan Liu",
        "Fabrizio Lombardi"
      ],
      "abstract": "The speed of open-weights large language models (LLMs) and its dependency on\nthe task at hand, when run on GPUs, is studied to present a comparative\nanalysis of the speed of the most popular open LLMs.",
      "tldr_zh": "这篇论文研究了开源大型语言模型（LLMs）的速度及其与任务的依赖性，强调速度不仅仅局限于每秒处理的 tokens（tokens per second）。作者通过在 GPU 上运行最受欢迎的开源 LLMs 进行比较分析，探讨了不同任务对模型性能的影响。研究结果为评估和优化 LLMs 的速度提供了更全面的见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16721v1",
      "published_date": "2025-02-23 21:28:55 UTC",
      "updated_date": "2025-02-23 21:28:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:38:09.672245"
    },
    {
      "arxiv_id": "2502.16718v1",
      "title": "NatSGLD: A Dataset with Speech, Gesture, Logic, and Demonstration for Robot Learning in Natural Human-Robot Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Snehesh Shrestha",
        "Yantian Zha",
        "Saketh Banagiri",
        "Ge Gao",
        "Yiannis Aloimonos",
        "Cornelia Fermüller"
      ],
      "abstract": "Recent advances in multimodal Human-Robot Interaction (HRI) datasets\nemphasize the integration of speech and gestures, allowing robots to absorb\nexplicit knowledge and tacit understanding. However, existing datasets\nprimarily focus on elementary tasks like object pointing and pushing, limiting\ntheir applicability to complex domains. They prioritize simpler human command\ndata but place less emphasis on training robots to correctly interpret tasks\nand respond appropriately. To address these gaps, we present the NatSGLD\ndataset, which was collected using a Wizard of Oz (WoZ) method, where\nparticipants interacted with a robot they believed to be autonomous. NatSGLD\nrecords humans' multimodal commands (speech and gestures), each paired with a\ndemonstration trajectory and a Linear Temporal Logic (LTL) formula that\nprovides a ground-truth interpretation of the commanded tasks. This dataset\nserves as a foundational resource for research at the intersection of HRI and\nmachine learning. By providing multimodal inputs and detailed annotations,\nNatSGLD enables exploration in areas such as multimodal instruction following,\nplan recognition, and human-advisable reinforcement learning from\ndemonstrations. We release the dataset and code under the MIT License at\nhttps://www.snehesh.com/natsgld/ to support future HRI research.",
      "tldr_zh": "该论文介绍了 NatSGLD 数据集，用于提升机器人学习在自然 Human-Robot Interaction (HRI) 中的表现。数据集通过 Wizard of Oz (WoZ) 方法收集，包含人类的 multimodal 命令（如语音和手势）、对应演示轨迹以及 Linear Temporal Logic (LTL) 公式作为任务解释的 ground-truth。相比现有数据集，NatSGLD 扩展了复杂任务的支持，适用于 multimodal 指令跟随、计划识别和人类建议的强化学习研究；数据集及其代码已以 MIT License 开源，供未来 HRI 研究使用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2403.02274",
      "pdf_url": "http://arxiv.org/pdf/2502.16718v1",
      "published_date": "2025-02-23 21:27:06 UTC",
      "updated_date": "2025-02-23 21:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:38:22.711213"
    },
    {
      "arxiv_id": "2502.16713v1",
      "title": "Understanding the Impact of Artificial Intelligence in Academic Writing: Metadata to the Rescue",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Conde",
        "Pedro Reviriego",
        "Joaquín Salvachúa",
        "Gonzalo Martínez",
        "José Alberto Hernández",
        "Fabrizio Lombardi"
      ],
      "abstract": "This column advocates for including artificial intelligence (AI)-specific\nmetadata on those academic papers that are written with the help of AI in an\nattempt to analyze the use of such tools for disseminating research.",
      "tldr_zh": "这篇论文主张在利用人工智能 (AI) 辅助撰写的学术论文中，加入 AI 特定的元数据，以分析这些工具在研究传播中的使用。该方法旨在帮助评估 AI 对学术写作的影响，促进更透明和可追溯的研究实践。通过引入元数据，论文强调这将有助于识别 AI 的作用，并为未来研究提供宝贵的数据支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16713v1",
      "published_date": "2025-02-23 21:10:44 UTC",
      "updated_date": "2025-02-23 21:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:38:33.325762"
    },
    {
      "arxiv_id": "2503.01859v1",
      "title": "Optimizing Retrieval-Augmented Generation of Medical Content for Spaced Repetition Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremi I. Kaczmarek",
        "Jakub Pokrywka",
        "Krzysztof Biedalak",
        "Grzegorz Kurzyp",
        "Łukasz Grzybowski"
      ],
      "abstract": "Advances in Large Language Models revolutionized medical education by\nenabling scalable and efficient learning solutions. This paper presents a\npipeline employing Retrieval-Augmented Generation (RAG) system to prepare\ncomments generation for Poland's State Specialization Examination (PES) based\non verified resources. The system integrates these generated comments and\nsource documents with a spaced repetition learning algorithm to enhance\nknowledge retention while minimizing cognitive overload. By employing a refined\nretrieval system, query rephraser, and an advanced reranker, our modified RAG\nsolution promotes accuracy more than efficiency. Rigorous evaluation by medical\nannotators demonstrates improvements in key metrics such as document relevance,\ncredibility, and logical coherence of generated content, proven by a series of\nexperiments presented in the paper. This study highlights the potential of RAG\nsystems to provide scalable, high-quality, and individualized educational\nresources, addressing non-English speaking users.",
      "tldr_zh": "本研究提出了一种优化 Retrieval-Augmented Generation (RAG) 系统的管道，用于生成波兰国家专业考试 (PES) 的医疗评论，并将其与 spaced repetition learning 算法整合，以提升知识保留并减少认知负担。系统通过 refined retrieval system、query rephraser 和 advanced reranker 等组件，优先提高生成内容的准确性，而非效率。经医疗注释者评估，实验结果显示在 document relevance、credibility 和 logical coherence 等指标上显著改进，最终证明 RAG 系统能为非英语用户提供可扩展、高质量和个性化的医疗教育资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01859v1",
      "published_date": "2025-02-23 20:56:31 UTC",
      "updated_date": "2025-02-23 20:56:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:38:44.799216"
    },
    {
      "arxiv_id": "2502.18225v3",
      "title": "Liver Cirrhosis Stage Estimation from MRI with Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zeng",
        "Debesh Jha",
        "Ertugrul Aktas",
        "Elif Keles",
        "Alpay Medetalibeyoglu",
        "Matthew Antalek",
        "Federica Proietto Salanitri",
        "Amir A. Borhani",
        "Daniela P. Ladner",
        "Gorkem Durak",
        "Ulas Bagci"
      ],
      "abstract": "We present an end-to-end deep learning framework for automated liver\ncirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe\nscarring (fibrosis) of the liver and a common endpoint of various chronic liver\ndiseases. Early diagnosis is vital to prevent complications such as\ndecompensation and cancer, which significantly decreases life expectancy.\nHowever, diagnosing cirrhosis in its early stages is challenging, and patients\noften present with life-threatening complications. Our approach integrates\nmulti-scale feature learning with sequence-specific attention mechanisms to\ncapture subtle tissue variations across cirrhosis progression stages. Using\nCirrMRI600+, a large-scale publicly available dataset of 628 high-resolution\nMRI scans from 339 patients, we demonstrate state-of-the-art performance in\nthree-stage cirrhosis classification. Our best model achieves 72.8% accuracy on\nT1W and 63.8% on T2W sequences, significantly outperforming traditional\nradiomics-based approaches. Through extensive ablation studies, we show that\nour architecture effectively learns stage-specific imaging biomarkers. We\nestablish new benchmarks for automated cirrhosis staging and provide insights\nfor developing clinically applicable deep learning systems. The source code\nwill be available at https://github.com/JunZengz/CirrhosisStage.",
      "tldr_zh": "本研究提出了一种端到端深度学习框架，用于从多序列MRI自动估计肝硬化阶段，通过整合多尺度特征学习和序列特定注意力机制，捕捉肝硬化进展中的微妙组织变化。利用公开数据集CirrMRI600+（包含339名患者的628个高分辨率MRI扫描），该框架在三阶段肝硬化分类中实现了state-of-the-art性能，在T1W序列上达到72.8%的准确率，在T2W序列上达到63.8%，显著优于传统的放射组学方法。消融研究证明，该架构能有效学习阶段特定的成像生物标志物，并为临床应用的深度学习系统提供新基准和见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "7 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2502.18225v3",
      "published_date": "2025-02-23 20:50:08 UTC",
      "updated_date": "2025-05-22 12:46:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:38:58.613984"
    },
    {
      "arxiv_id": "2502.16708v1",
      "title": "Exploring Incremental Unlearning: Techniques, Challenges, and Future Directions",
      "title_zh": "探索增量遗忘：技术、挑战和未来方向",
      "authors": [
        "Sadia Qureshi",
        "Thanveer Shaik",
        "Xiaohui Tao",
        "Haoran Xie",
        "Lin Li",
        "Jianming Yong",
        "Xiaohua Jia"
      ],
      "abstract": "The growing demand for data privacy in Machine Learning (ML) applications has\nseen Machine Unlearning (MU) emerge as a critical area of research. As the\n`right to be forgotten' becomes regulated globally, it is increasingly\nimportant to develop mechanisms that delete user data from AI systems while\nmaintaining performance and scalability of these systems. Incremental\nUnlearning (IU) is a promising MU solution to address the challenges of\nefficiently removing specific data from ML models without the need for\nexpensive and time-consuming full retraining. This paper presents the various\ntechniques and approaches to IU. It explores the challenges faced in designing\nand implementing IU mechanisms. Datasets and metrics for evaluating the\nperformance of unlearning techniques are discussed as well. Finally, potential\nsolutions to the IU challenges alongside future research directions are\noffered. This survey provides valuable insights for researchers and\npractitioners seeking to understand the current landscape of IU and its\npotential for enhancing privacy-preserving intelligent systems.",
      "tldr_zh": "这篇论文探讨了机器取消学习（Machine Unlearning, MU）中的增量取消学习（Incremental Unlearning, IU），旨在解决数据隐私需求和“被遗忘权”法规下，从AI系统中高效删除特定数据的问题，而无需进行昂贵的完整重新训练。论文综述了IU的各种技术和方法，分析了设计与实施中的挑战，并讨论了评估这些技术的相关数据集和指标。最终，它提出了潜在解决方案和未来研究方向，为研究人员和从业者提供宝贵见解，以提升隐私保护的智能系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2502.16708v1",
      "published_date": "2025-02-23 20:47:27 UTC",
      "updated_date": "2025-02-23 20:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:39:10.027383"
    },
    {
      "arxiv_id": "2502.16707v1",
      "title": "Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yunhai Feng",
        "Jiaming Han",
        "Zhuoran Yang",
        "Xiangyu Yue",
        "Sergey Levine",
        "Jianlan Luo"
      ],
      "abstract": "Solving complex long-horizon robotic manipulation problems requires\nsophisticated high-level planning capabilities, the ability to reason about the\nphysical world, and reactively choose appropriate motor skills. Vision-language\nmodels (VLMs) pretrained on Internet data could in principle offer a framework\nfor tackling such problems. However, in their current form, VLMs lack both the\nnuanced understanding of intricate physics required for robotic manipulation\nand the ability to reason over long horizons to address error compounding\nissues. In this paper, we introduce a novel test-time computation framework\nthat enhances VLMs' physical reasoning capabilities for multi-stage\nmanipulation tasks. At its core, our approach iteratively improves a pretrained\nVLM with a \"reflection\" mechanism - it uses a generative model to imagine\nfuture world states, leverages these predictions to guide action selection, and\ncritically reflects on potential suboptimalities to refine its reasoning.\nExperimental results demonstrate that our method significantly outperforms\nseveral state-of-the-art commercial VLMs as well as other post-training\napproaches such as Monte Carlo Tree Search (MCTS). Videos are available at\nhttps://reflect-vlm.github.io.",
      "tldr_zh": "该研究针对复杂多阶段长时段机器人操作任务，提出了一种名为“Reflective Planning”的框架，以提升Vision-Language Models (VLMs) 的物理推理能力和规划性能。该框架通过测试时计算机制，采用“reflection”机制来迭代改进 VLM：利用生成模型预测未来世界状态、指导行动选择，并反思潜在问题以优化推理过程。实验结果显示，该方法显著优于现有商用 VLMs 和其他后训练方法如 Monte Carlo Tree Search (MCTS)，在机器人操作任务中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16707v1",
      "published_date": "2025-02-23 20:42:15 UTC",
      "updated_date": "2025-02-23 20:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:39:21.580249"
    },
    {
      "arxiv_id": "2502.18232v2",
      "title": "A Reverse Mamba Attention Network for Pathological Liver Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zeng",
        "Debesh Jha",
        "Ertugrul Aktas",
        "Elif Keles",
        "Alpay Medetalibeyoglu",
        "Matthew Antalek",
        "Robert Lewandowski",
        "Daniela Ladner",
        "Amir A. Borhani",
        "Gorkem Durak",
        "Ulas Bagci"
      ],
      "abstract": "We present RMA-Mamba, a novel architecture that advances the capabilities of\nvision state space models through a specialized reverse mamba attention module\n(RMA). The key innovation lies in RMA-Mamba's ability to capture long-range\ndependencies while maintaining precise local feature representation through its\nhierarchical processing pipeline. By integrating Vision Mamba (VMamba)'s\nefficient sequence modeling with RMA's targeted feature refinement, our\narchitecture achieves superior feature learning across multiple scales. This\ndual-mechanism approach enables robust handling of complex morphological\npatterns while maintaining computational efficiency. We demonstrate RMA-Mamba's\neffectiveness in the challenging domain of pathological liver segmentation\n(from both CT and MRI), where traditional segmentation approaches often fail\ndue to tissue variations. When evaluated on a newly introduced cirrhotic liver\ndataset (CirrMRI600+) of T2-weighted MRI scans, RMA-Mamba achieves the\nstate-of-the-art performance with a Dice coefficient of 92.08%, mean IoU of\n87.36%, and recall of 92.96%. The architecture's generalizability is further\nvalidated on the cancerous liver segmentation from CT scans (LiTS: Liver Tumor\nSegmentation dataset), yielding a Dice score of 92.9% and mIoU of 88.99%. Our\ncode is available for public: https://github.com/JunZengz/RMAMamba.",
      "tldr_zh": "本研究提出了一种新型架构RMA-Mamba，用于病理肝脏分割，该架构通过集成Vision Mamba的序列建模和reverse mamba attention module (RMA)的特征精炼，实现了长程依赖捕获与局部特征表示的平衡，并通过分层处理管道进行多尺度特征学习。RMA-Mamba在处理CT和MRI图像中的复杂形态模式时表现出色，尤其在新的CirrMRI600+数据集上达到了最先进性能，包括Dice coefficient 92.08%、mean IoU 87.36%和recall 92.96%。此外，在LiTS数据集的癌症肝脏分割任务中，该模型也取得了Dice score 92.9%和mIoU 88.99%的优异结果，证明了其泛化能力和计算效率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.18232v2",
      "published_date": "2025-02-23 20:41:25 UTC",
      "updated_date": "2025-03-05 19:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:39:33.869930"
    },
    {
      "arxiv_id": "2502.16706v1",
      "title": "DISC: Dynamic Decomposition Improves LLM Inference Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Light",
        "Wei Cheng",
        "Wu Yue",
        "Masafumi Oyamada",
        "Mengdi Wang",
        "Santiago Paternain",
        "Haifeng Chen"
      ],
      "abstract": "Many inference scaling methods work by breaking a problem into smaller steps\n(or groups of tokens), then sampling and choosing the best next step. However,\nthese steps and their sizes are usually predetermined based on human intuition\nor domain knowledge. This paper introduces dynamic decomposition, a method that\nautomatically and adaptively splits solution and reasoning traces into steps\nduring inference. This approach improves computational efficiency by focusing\nmore resources on difficult steps, breaking them down further and prioritizing\ntheir sampling. Experiments on coding and math benchmarks (APPS, MATH, and\nLiveCodeBench) show that dynamic decomposition performs better than static\nmethods, which rely on fixed steps like token-level, sentence-level, or\nsingle-step decompositions. These results suggest that dynamic decomposition\ncan enhance many inference scaling techniques.",
      "tldr_zh": "这篇论文提出了动态分解(dynamic decomposition)方法，用于提升大型语言模型(LLM)的推理缩放效率。该方法在推理过程中自动适应地拆分解决方案和推理痕迹，根据步骤难度动态分配资源，进一步分解并优先采样困难部分，从而优化计算性能。与静态方法（如基于token、句子或单步分解）相比，实验在编码和数学基准测试（APPS、MATH和LiveCodeBench）上显示，动态分解的性能更优，提升了整体效果。这些结果表明，动态分解可以增强多种推理缩放技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.SE",
        "I.2.6; I.2.7; I.2.8; D.2.3; F.2.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16706v1",
      "published_date": "2025-02-23 20:37:32 UTC",
      "updated_date": "2025-02-23 20:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:39:46.372086"
    },
    {
      "arxiv_id": "2502.16705v1",
      "title": "Can ChatGPT Learn to Count Letters?",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Conde",
        "Gonzalo Martínez",
        "Pedro Reviriego",
        "Zhen Gao",
        "Shanshan Liu",
        "Fabrizio Lombardi"
      ],
      "abstract": "Large language models (LLMs) struggle on simple tasks such as counting the\nnumber of occurrences of a letter in a word. In this paper, we investigate if\nChatGPT can learn to count letters and propose an efficient solution.",
      "tldr_zh": "大型语言模型 (LLMs) 在简单任务如计数单词中特定字母的出现次数上表现不佳，本文针对 ChatGPT 进行深入调查，探讨其是否能学会这项技能。研究发现，通过特定的方法，ChatGPT 可以改进其计数能力。论文提出了一种高效的解决方案，以提升 LLMs 在基础任务上的准确性和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16705v1",
      "published_date": "2025-02-23 20:31:22 UTC",
      "updated_date": "2025-02-23 20:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:39:56.111158"
    },
    {
      "arxiv_id": "2502.16704v1",
      "title": "Code Summarization Beyond Function Level",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Makharev",
        "Vladimir Ivanov"
      ],
      "abstract": "Code summarization is a critical task in natural language processing and\nsoftware engineering, which aims to generate concise descriptions of source\ncode. Recent advancements have improved the quality of these summaries,\nenhancing code readability and maintainability. However, the content of a\nrepository or a class has not been considered in function code summarization.\nThis study investigated the effectiveness of code summarization models beyond\nthe function level, exploring the impact of class and repository contexts on\nthe summary quality. The study involved revising benchmarks for evaluating\nmodels at class and repository levels, assessing baseline models, and\nevaluating LLMs with in-context learning to determine the enhancement of\nsummary quality with additional context. The findings revealed that the\nfine-tuned state-of-the-art CodeT5+ base model excelled in code summarization,\nwhile incorporating few-shot learning and retrieved code chunks from RAG\nsignificantly enhanced the performance of LLMs in this task. Notably, the\nDeepseek Coder 1.3B and Starcoder2 15B models demonstrated substantial\nimprovements in metrics such as BLEURT, METEOR, and BLEU-4 at both class and\nrepository levels. Repository-level summarization exhibited promising potential\nbut necessitates significant computational resources and gains from the\ninclusion of structured context. Lastly, we employed the recent SIDE code\nsummarization metric in our evaluation. This study contributes to refining\nstrategies for prompt engineering, few-shot learning, and RAG, addressing gaps\nin benchmarks for code summarization at various levels. Finally, we publish all\nstudy details, code, datasets, and results of evaluation in the GitHub\nrepository available at\nhttps://github.com/kilimanj4r0/code-summarization-beyond-function-level.",
      "tldr_zh": "本研究扩展了代码总结任务（Code Summarization）从函数级别到类和仓库级别，探讨了额外上下文（如类和仓库信息）对总结质量的影响。研究团队修订了评估基准，评估了基线模型和LLMs（如Deepseek Coder 1.3B和Starcoder2 15B）结合少样本学习（few-shot learning）和RAG（Retrieval-Augmented Generation）技术，结果显示细调的CodeT5+基模型表现出色，并在BLEURT、METEOR和BLEU-4等指标上显著提升。总体发现表明，仓库级别总结潜力巨大，但需更多计算资源；该研究还优化了提示工程（prompt engineering）策略，并公开了所有代码、数据集和结果于GitHub仓库。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LLM4Code @ ICSE'25; 8 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16704v1",
      "published_date": "2025-02-23 20:31:21 UTC",
      "updated_date": "2025-02-23 20:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:40:09.933167"
    },
    {
      "arxiv_id": "2502.18523v1",
      "title": "End-to-End Deep Learning for Structural Brain Imaging: A Unified Framework",
      "title_zh": "端到端深度学习用于结构脑成像：一个统一框架",
      "authors": [
        "Yao Su",
        "Keqi Han",
        "Mingjie Zeng",
        "Lichao Sun",
        "Liang Zhan",
        "Carl Yang",
        "Lifang He",
        "Xiangnan Kong"
      ],
      "abstract": "Brain imaging analysis is fundamental in neuroscience, providing valuable\ninsights into brain structure and function. Traditional workflows follow a\nsequential pipeline-brain extraction, registration, segmentation, parcellation,\nnetwork generation, and classification-treating each step as an independent\ntask. These methods rely heavily on task-specific training data and expert\nintervention to correct intermediate errors, making them particularly\nburdensome for high-dimensional neuroimaging data, where annotations and\nquality control are costly and time-consuming. We introduce UniBrain, a unified\nend-to-end framework that integrates all processing steps into a single\noptimization process, allowing tasks to interact and refine each other. Unlike\ntraditional approaches that require extensive task-specific annotations,\nUniBrain operates with minimal supervision, leveraging only low-cost labels\n(i.e., classification and extraction) and a single labeled atlas. By jointly\noptimizing extraction, registration, segmentation, parcellation, network\ngeneration, and classification, UniBrain enhances both accuracy and\ncomputational efficiency while significantly reducing annotation effort.\nExperimental results demonstrate its superiority over existing methods across\nmultiple tasks, offering a more scalable and reliable solution for neuroimaging\nanalysis. Our code and data can be found at\nhttps://github.com/Anonymous7852/UniBrain",
      "tldr_zh": "本文提出 UniBrain，一种统一的 End-to-End Deep Learning 框架，用于结构脑成像分析，将传统顺序管道（如脑提取、注册、分割、划分、网络生成和分类）整合到一个联合优化过程中，仅需最小监督（如低成本标签和一个标记的图集），从而减少标注努力并提升计算效率。相较于传统方法，UniBrain 通过任务间互动实现更精确的处理，实验结果显示其在多个任务上优于现有方法，提高了准确性并提供更可扩展的神经影像解决方案。代码和数据可在 https://github.com/Anonymous7852/UniBrain 获取。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18523v1",
      "published_date": "2025-02-23 20:08:24 UTC",
      "updated_date": "2025-02-23 20:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:40:23.694548"
    },
    {
      "arxiv_id": "2502.16701v2",
      "title": "Beyond Release: Access Considerations for Generative AI Systems",
      "title_zh": "超越发布：生成式人工智能系统的访问考虑",
      "authors": [
        "Irene Solaiman",
        "Rishi Bommasani",
        "Dan Hendrycks",
        "Ariel Herbert-Voss",
        "Yacine Jernite",
        "Aviya Skowron",
        "Andrew Trask"
      ],
      "abstract": "Generative AI release decisions determine whether system components are made\navailable, but release does not address many other elements that change how\nusers and stakeholders are able to engage with a system. Beyond release, access\nto system components informs potential risks and benefits. Access refers to\npractical needs, infrastructurally, technically, and societally, in order to\nuse available components in some way. We deconstruct access along three axes:\nresourcing, technical usability, and utility. Within each category, a set of\nvariables per system component clarify tradeoffs. For example, resourcing\nrequires access to computing infrastructure to serve model weights. We also\ncompare the accessibility of four high performance language models, two\nopen-weight and two closed-weight, showing similar considerations for all based\ninstead on access variables. Access variables set the foundation for being able\nto scale or increase access to users; we examine the scale of access and how\nscale affects ability to manage and intervene on risks. This framework better\nencompasses the landscape and risk-benefit tradeoffs of system releases to\ninform system release decisions, research, and policy.",
      "tldr_zh": "该论文探讨了生成式 AI 系统发布之外的访问考虑问题，强调访问（access）如何影响用户和利益相关者的风险与收益。论文将访问分解为三个轴：resourcing（资源需求，如计算基础设施）、technical usability（技术可用性）和utility（实用性），并通过分析这些轴下的变量来阐明系统组件的权衡。作者比较了四个高性能语言模型（两个open-weight和两个closed-weight）的可访问性，揭示了扩展访问规模如何影响风险管理和干预。总体而言，这一框架为生成式 AI 的发布决策、研究和政策提供了更全面的风险-收益评估。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16701v2",
      "published_date": "2025-02-23 20:06:12 UTC",
      "updated_date": "2025-04-11 07:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:40:34.728153"
    },
    {
      "arxiv_id": "2502.16696v1",
      "title": "Dynamic LLM Routing and Selection based on User Preferences: Balancing Performance, Cost, and Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Deepak Babu Piskala",
        "Vijay Raajaa",
        "Sachin Mishra",
        "Bruno Bozza"
      ],
      "abstract": "With the widespread deployment of large language models (LLMs) such as GPT4,\nBART, and LLaMA, the need for a system that can intelligently select the most\nsuitable model for specific tasks while balancing cost, latency, accuracy, and\nethical considerations has become increasingly important. Recognizing that not\nall tasks necessitate models with over 100 billion parameters, we introduce\nOptiRoute, an advanced model routing engine designed to dynamically select and\nroute tasks to the optimal LLM based on detailed user-defined requirements.\nOptiRoute captures both functional (e.g., accuracy, speed, cost) and\nnon-functional (e.g., helpfulness, harmlessness, honesty) criteria, leveraging\nlightweight task analysis and complexity estimation to efficiently match tasks\nwith the best-fit models from a diverse array of LLMs. By employing a hybrid\napproach combining k-nearest neighbors (kNN) search and hierarchical filtering,\nOptiRoute optimizes for user priorities while minimizing computational\noverhead. This makes it ideal for real-time applications in cloud-based ML\nplatforms, personalized AI services, and regulated industries.",
      "tldr_zh": "这篇论文引入了OptiRoute，一种动态LLM路由引擎，能够根据用户偏好智能选择最合适的LLMs（如GPT4、BART和LLaMA），以平衡性能（如准确性和速度）、成本以及道德因素（如帮助性、无害性和诚实性）。OptiRoute采用轻量级任务分析和复杂性估计，结合k-nearest neighbors (kNN)搜索和分层过滤的方法，实现高效的任务匹配和路由，减少计算开销。实验结果显示，该系统适用于实时应用，如云-based ML平台、个性化AI服务和受管行业，提升了整体效率和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16696v1",
      "published_date": "2025-02-23 19:23:22 UTC",
      "updated_date": "2025-02-23 19:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:40:47.609936"
    },
    {
      "arxiv_id": "2502.17524v1",
      "title": "Multimodal Bearing Fault Classification Under Variable Conditions: A 1D CNN with Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tasfiq E. Alam",
        "Md Manjurul Ahsan",
        "Shivakumar Raman"
      ],
      "abstract": "Bearings play an integral role in ensuring the reliability and efficiency of\nrotating machinery - reducing friction and handling critical loads. Bearing\nfailures that constitute up to 90% of mechanical faults highlight the\nimperative need for reliable condition monitoring and fault detection. This\nstudy proposes a multimodal bearing fault classification approach that relies\non vibration and motor phase current signals within a one-dimensional\nconvolutional neural network (1D CNN) framework. The method fuses features from\nmultiple signals to enhance the accuracy of fault detection. Under the baseline\ncondition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the model\nreaches an accuracy of 96% with addition of L2 regularization. This represents\na notable improvement of 2% compared to the non-regularized model. In addition,\nthe model demonstrates robust performance across three distinct operating\nconditions by employing transfer learning (TL) strategies. Among the tested TL\nvariants, the approach that preserves parameters up to the first max-pool layer\nand then adjusts subsequent layers achieves the highest performance. While this\napproach attains excellent accuracy across varied conditions, it requires more\ncomputational time due to its greater number of trainable parameters. To\naddress resource constraints, less computationally intensive models offer\nfeasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal\n1D CNN framework with late fusion and TL strategies lays a foundation for more\naccurate, adaptable, and efficient bearing fault classification in industrial\nenvironments with variable operating conditions.",
      "tldr_zh": "这篇论文提出了一种多模态轴承故障分类方法，使用振动和电机相电流信号结合一维卷积神经网络（1D CNN）框架，以提升故障检测的准确性。在基线条件下（1500 rpm、0.7 Nm 负载扭矩和1000 N 径向力），模型通过L2 正则化达到了96%的准确率，比非正则化模型提高了2%。通过Transfer Learning（TL）策略，该方法在三种不同操作条件下表现出色，其中保留参数到第一个最大池化层并调整后续层的变体取得了最高性能。尽管此方法计算时间较长，但更低计算密集的模型提供了可行的准确率权衡。总体上，该框架为工业环境中可变条件下更准确、适应性和高效的轴承故障分类奠定了基础。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17524v1",
      "published_date": "2025-02-23 19:11:25 UTC",
      "updated_date": "2025-02-23 19:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:00.945496"
    },
    {
      "arxiv_id": "2502.16690v1",
      "title": "From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Martorell"
      ],
      "abstract": "Understanding how large language models (LLMs) represent and reason about\nspatial information is crucial for building robust agentic systems that can\nnavigate real and simulated environments. In this work, we investigate the\ninfluence of different text-based spatial representations on LLM performance\nand internal activations in a grid-world navigation task. By evaluating models\nof various sizes on a task that requires navigating toward a goal, we examine\nhow the format used to encode spatial information impacts decision-making. Our\nexperiments reveal that cartesian representations of space consistently yield\nhigher success rates and path efficiency, with performance scaling markedly\nwith model size. Moreover, probing LLaMA-3.1-8B revealed subsets of internal\nunits, primarily located in intermediate layers, that robustly correlate with\nspatial features, such as the position of the agent in the grid or action\ncorrectness, regardless of how that information is represented, and are also\nactivated by unrelated spatial reasoning tasks. This work advances our\nunderstanding of how LLMs process spatial information and provides valuable\ninsights for developing more interpretable and robust agentic AI systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在网格世界导航任务中如何表示和推理空间信息，以提升代理系统的鲁棒性。研究通过评估不同模型大小和文本-based 空间表示格式，发现笛卡尔表示 (Cartesian representations) 显著提高了成功率和路径效率，且性能随模型规模而提升。此外，探测 LLaMA-3.1-8B 的内部激活揭示了与空间特征（如代理位置或动作正确性）相关的子集单位，这些单位在不同表示下保持相关，并适用于其他空间推理任务，从而为构建更可解释和稳健的代理 AI 系统提供了关键洞见。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16690v1",
      "published_date": "2025-02-23 19:09:01 UTC",
      "updated_date": "2025-02-23 19:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:11.427188"
    },
    {
      "arxiv_id": "2502.16682v2",
      "title": "Automatic Input Rewriting Improves Translation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dayeon Ki",
        "Marine Carpuat"
      ],
      "abstract": "Can we improve machine translation (MT) with LLMs by rewriting their inputs\nautomatically? Users commonly rely on the intuition that well-written text is\neasier to translate when using off-the-shelf MT systems. LLMs can rewrite text\nin many ways but in the context of MT, these capabilities have been primarily\nexploited to rewrite outputs via post-editing. We present an empirical study of\n21 input rewriting methods with 3 open-weight LLMs for translating from English\ninto 6 target languages. We show that text simplification is the most effective\nMT-agnostic rewrite strategy and that it can be improved further when using\nquality estimation to assess translatability. Human evaluation further confirms\nthat simplified rewrites and their MT outputs both largely preserve the\noriginal meaning of the source and MT. These results suggest LLM-assisted input\nrewriting as a promising direction for improving translations.",
      "tldr_zh": "本研究探讨了通过自动重写输入来提升大型语言模型 (LLMs) 在机器翻译 (MT) 方面的性能，用户通常认为结构良好的文本更易翻译。研究者测试了21种输入重写方法，使用3个开源LLMs，将英语翻译到6种目标语言，结果显示文本简化是效果最佳的MT无关策略，并可通过质量估计进一步优化。人工评估确认，简化后的重写文本及其翻译输出基本保留了原意。这些发现表明，LLM辅助输入重写是一种有前景的方向，可显著改善翻译质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16682v2",
      "published_date": "2025-02-23 18:56:56 UTC",
      "updated_date": "2025-04-15 21:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:23.072139"
    },
    {
      "arxiv_id": "2502.16681v1",
      "title": "Are Sparse Autoencoders Useful? A Case Study in Sparse Probing",
      "title_zh": "稀疏自编码器有用吗？ ",
      "authors": [
        "Subhash Kantamneni",
        "Joshua Engels",
        "Senthooran Rajamanoharan",
        "Max Tegmark",
        "Neel Nanda"
      ],
      "abstract": "Sparse autoencoders (SAEs) are a popular method for interpreting concepts\nrepresented in large language model (LLM) activations. However, there is a lack\nof evidence regarding the validity of their interpretations due to the lack of\na ground truth for the concepts used by an LLM, and a growing number of works\nhave presented problems with current SAEs. One alternative source of evidence\nwould be demonstrating that SAEs improve performance on downstream tasks beyond\nexisting baselines. We test this by applying SAEs to the real-world task of LLM\nactivation probing in four regimes: data scarcity, class imbalance, label\nnoise, and covariate shift. Due to the difficulty of detecting concepts in\nthese challenging settings, we hypothesize that SAEs' basis of interpretable,\nconcept-level latents should provide a useful inductive bias. However, although\nSAEs occasionally perform better than baselines on individual datasets, we are\nunable to design ensemble methods combining SAEs with baselines that\nconsistently outperform ensemble methods solely using baselines. Additionally,\nalthough SAEs initially appear promising for identifying spurious correlations,\ndetecting poor dataset quality, and training multi-token probes, we are able to\nachieve similar results with simple non-SAE baselines as well. Though we cannot\ndiscount SAEs' utility on other tasks, our findings highlight the shortcomings\nof current SAEs and the need to rigorously evaluate interpretability methods on\ndownstream tasks with strong baselines.",
      "tldr_zh": "本研究探讨了 Sparse Autoencoders (SAEs) 在解释大型语言模型 (LLM) 激活概念方面的实用性，通过一个案例研究在数据稀缺、类别不平衡、标签噪声和协变量偏移等四个挑战性场景下进行 LLM 激活探测任务。研究假设 SAEs 的可解释概念级潜在变量能提供有益的归纳偏差，但实验结果显示 SAEs 仅在某些数据集上优于基线，无法设计出一致超越纯基线集成方法的组合。总体而言，虽然 SAEs 在识别虚假相关、检测数据集质量和训练多标记探测器方面显示潜力，但简单非-SAE 基线也能实现类似性能，突显了当前 SAEs 的局限性，并强调需要通过下游任务的严格评估来验证其效用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16681v1",
      "published_date": "2025-02-23 18:54:15 UTC",
      "updated_date": "2025-02-23 18:54:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:35.725219"
    },
    {
      "arxiv_id": "2503.05760v4",
      "title": "The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its Own",
      "title_zh": "懒惰学生的梦想：ChatGPT 独立通过一门工程课程",
      "authors": [
        "Gokul Puthumanaillam",
        "Timothy Bretl",
        "Melkior Ornik"
      ],
      "abstract": "This paper presents a comprehensive investigation into the capability of\nLarge Language Models (LLMs) to successfully complete a semester-long\nundergraduate control systems course. Through evaluation of 115 course\ndeliverables, we assess LLM performance using ChatGPT under a \"minimal effort\"\nprotocol that simulates realistic student usage patterns. The investigation\nemploys a rigorous testing methodology across multiple assessment formats, from\nauto-graded multiple choice questions to complex Python programming tasks and\nlong-form analytical writing. Our analysis provides quantitative insights into\nAI's strengths and limitations in handling mathematical formulations, coding\nchallenges, and theoretical concepts in control systems engineering. The LLM\nachieved a B-grade performance (82.24\\%), approaching but not exceeding the\nclass average (84.99\\%), with strongest results in structured assignments and\ngreatest limitations in open-ended projects. The findings inform discussions\nabout course design adaptation in response to AI advancement, moving beyond\nsimple prohibition towards thoughtful integration of these tools in engineering\neducation. Additional materials including syllabus, examination papers, design\nprojects, and example responses can be found at the project website:\nhttps://gradegpt.github.io.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）如 ChatGPT 是否能独立完成一个本科控制系统课程，通过模拟“最小努力”协议评估 115 个课程 deliverables，包括多选题、Python 编程和分析写作任务。结果显示，ChatGPT 获得了 B 级成绩（82.24%），接近班级平均分（84.99%），在结构化任务中表现出色，但在开放式项目中存在明显局限。论文提供了 AI 在数学、编码和理论概念方面的优缺点洞见，并建议工程教育从单纯禁止转向积极整合这些工具，以适应 AI 技术的发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05760v4",
      "published_date": "2025-02-23 18:47:14 UTC",
      "updated_date": "2025-05-16 04:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:46.389336"
    },
    {
      "arxiv_id": "2502.16671v1",
      "title": "MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hengzhi Li",
        "Megan Tjandrasuwita",
        "Yi R. Fung",
        "Armando Solar-Lezama",
        "Paul Pu Liang"
      ],
      "abstract": "Socially intelligent AI that can understand and interact seamlessly with\nhumans in daily lives is increasingly important as AI becomes more closely\nintegrated with peoples' daily activities. However, current works in artificial\nsocial reasoning all rely on language-only, or language-dominant approaches to\nbenchmark and training models, resulting in systems that are improving in\nverbal communication but struggle with nonverbal social understanding. To\naddress this limitation, we tap into a novel source of data rich in nonverbal\nand social interactions -- mime videos. Mimes refer to the art of expression\nthrough gesture and movement without spoken words, which presents unique\nchallenges and opportunities in interpreting non-verbal social communication.\nWe contribute a new dataset called MimeQA, obtained by sourcing 221 videos from\nYouTube, through rigorous annotation and verification, resulting in a benchmark\nwith 101 videos and 806 question-answer pairs. Using MimeQA, we evaluate\nstate-of-the-art video large language models (vLLMs) and find that their\noverall accuracy ranges from 15-30%. Our analysis reveals that vLLMs often fail\nto ground imagined objects and over-rely on the text prompt while ignoring\nsubtle nonverbal interactions. Our data resources are released at\nhttps://github.com/MIT-MI/MimeQA to inspire future work in foundation models\nthat embody true social intelligence capable of interpreting non-verbal human\ninteractions.",
      "tldr_zh": "该论文旨在提升AI的社会智能，特别是非语言（Nonverbal）互动理解，以适应AI在日常生活中的无缝整合。研究者创建了MimeQA数据集，通过从YouTube收集221个哑剧（mime）视频，并经过严格标注和验证，生成包含101个视频和806个问答对的基准，用于评估视频大语言模型（vLLMs）。实验结果显示，state-of-the-art vLLMs的准确率仅为15-30%，主要问题包括无法正确关联想象对象和过度依赖文本提示而忽略微妙非语言互动。该数据集已开源（https://github.com/MIT-MI/MimeQA），为开发更具Socially-Intelligent Nonverbal Foundation Models奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16671v1",
      "published_date": "2025-02-23 18:05:49 UTC",
      "updated_date": "2025-02-23 18:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:41:59.440141"
    },
    {
      "arxiv_id": "2503.11666v1",
      "title": "Optimizing Coverage-Driven Verification Using Machine Learning and PyUVM: A Novel Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Suruchi Kumari",
        "Deepak Narayan Gadde",
        "Aman Kumar"
      ],
      "abstract": "The escalating complexity of System-on-Chip (SoC) designs has created a\nbottleneck in verification, with traditional techniques struggling to achieve\ncomplete coverage. Existing techniques, such as Constrained Random Verification\n(CRV) and coverage-driven methodologies, rely on time-consuming and redundant\nsimulation regression, leading to higher verification costs and longer\ntime-to-market due to the manual effort required to adjust constraints and\ndrive the stimuli to achieve coverage objectives. To address this challenge, we\npropose a novel methodology that leverages supervised Machine Learning (ML) to\noptimize simulation regressions, resulting in reduced simulation run-time and\nthe number of test simulations required to achieve target coverage goals. We\nalso investigate and compare the effectiveness of various supervised learning\nalgorithms from scikit-learn. Our results demonstrate that these algorithms can\nachieve at least 99% coverage regain with significantly reduced simulation\ncycles. We utilize Python Universal Verification Methodology (PyUVM) over\nSystemVerilog-Universal Verification Methodology (SV-UVM) for testbench\ncreation, enabling simpler constructs using Python and facilitating the reuse\nof existing ML libraries. Our methodology is applied to three diverse designs,\nand our results show that it can significantly reduce verification costs,\nmanual efforts, and time-to-market, while enhancing verification productivity\nand completeness, by automating the testbench update process and achieving\ntarget coverage goals.",
      "tldr_zh": "本研究针对 System-on-Chip (SoC) 设计的验证复杂性问题，提出了一种新方法，使用监督 Machine Learning (ML) 优化覆盖驱动验证，从而减少模拟回归时间和测试模拟次数，缓解传统 Constrained Random Verification (CRV) 的手动调整负担。\n该方法比较了 scikit-learn 中的各种监督学习算法，并采用 Python Universal Verification Methodology (PyUVM) 代替 SystemVerilog-Universal Verification Methodology (SV-UVM) 来创建测试台，便于 Python 构造和 ML 库复用。\n实验结果显示，在三个不同设计上应用后，这些算法实现了至少 99% 的覆盖率重获，同时显著降低了验证成本、手动努力和上市时间，提高了验证生产力和完整性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "To appear at 2025 IEEE International Symposium on Circuits and\n  Systems, May 25-28 2025, London, United Kingdom",
      "pdf_url": "http://arxiv.org/pdf/2503.11666v1",
      "published_date": "2025-02-23 17:54:23 UTC",
      "updated_date": "2025-02-23 17:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:42:12.095282"
    },
    {
      "arxiv_id": "2502.16666v1",
      "title": "SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Kunal Singh",
        "Ankan Biswas",
        "Sayandeep Bhowmick",
        "Pradeep Moturi",
        "Siva Kishore Gollapalli"
      ],
      "abstract": "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework\nthat enables Large Language Models (LLMs) to generate sequence of programs for\nsolving Olympiad level math problems. At each step/turn, by leveraging the code\nexecution outputs and programs of previous steps, the model generates the next\nsub-task and the corresponding program to solve it. This way, SBSC,\nsequentially navigates to reach the final answer. SBSC allows more granular,\nflexible and precise approach to problem-solving compared to existing methods.\nExtensive experiments highlight the effectiveness of SBSC in tackling\ncompetition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe\nSBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program\ngeneration based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME\nand 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark\nSBSC's greedy decoding against self-consistency decoding results of existing\nSOTA math reasoning strategies and observe performance gain by absolute 6.2% on\nAMC, 6.7% on AIME and 7.4% on MathOdyssey.",
      "tldr_zh": "本研究提出 SBSC（Step-by-Step Coding），一种多轮数学推理框架，用于提升大型语言模型（LLMs）在数学奥林匹克问题上的性能。\nSBSC 通过在每个步骤利用前序代码执行输出和程序，生成下一个子任务及对应程序，实现更细粒度、灵活和精确的逐步求解。\n实验结果显示，SBSC 在 Claude-3.5-Sonnet 上以贪婪解码模式，比现有 SOTA 策略在 AMC12 上提高 10.7%、在 AIME 上提高 8%、在 MathOdyssey 上提高 12.6%；与 SOTA 的自一致性解码相比，也分别在 AMC、AIME 和 MathOdyssey 上获得 6.2%、6.7% 和 7.4% 的绝对性能提升。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a full conference paper at ICLR 2025. Shorter(Early)\n  Version accepted at NeurIPS'24 MATH-AI track",
      "pdf_url": "http://arxiv.org/pdf/2502.16666v1",
      "published_date": "2025-02-23 17:51:26 UTC",
      "updated_date": "2025-02-23 17:51:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:42:24.904818"
    },
    {
      "arxiv_id": "2502.16662v2",
      "title": "Saarthi: The First AI Formal Verification Engineer",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Kumar",
        "Deepak Narayan Gadde",
        "Keerthan Kopparam Radhakrishna",
        "Djones Lettnin"
      ],
      "abstract": "Recently, Devin has made a significant buzz in the Artificial Intelligence\n(AI) community as the world's first fully autonomous AI software engineer,\ncapable of independently developing software code. Devin uses the concept of\nagentic workflow in Generative AI (GenAI), which empowers AI agents to engage\nin a more dynamic, iterative, and self-reflective process. In this paper, we\npresent a similar fully autonomous AI formal verification engineer, Saarthi,\ncapable of verifying a given RTL design end-to-end using an agentic workflow.\nWith Saarthi, verification engineers can focus on more complex problems, and\nverification teams can strive for more ambitious goals. The domain-agnostic\nimplementation of Saarthi makes it scalable for use across various domains such\nas RTL design, UVM-based verification, and others.",
      "tldr_zh": "本文提出 Saarthi，这是第一个完全自治的 AI 正式验证工程师，能够使用 agentic workflow 端到端验证 RTL 设计。Saarthi 借鉴 Generative AI (GenAI) 的动态、迭代和自我反思过程，帮助验证工程师专注于更复杂的问题，并使团队实现更雄心勃勃的目标。其领域无关的实现使其可扩展应用于 RTL 设计、UVM-based verification 等多种领域，为 AI 在软件验证中的应用开辟了新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the DVCon U.S. 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16662v2",
      "published_date": "2025-02-23 17:42:50 UTC",
      "updated_date": "2025-03-01 13:02:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:42:35.975191"
    },
    {
      "arxiv_id": "2502.16660v4",
      "title": "BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning",
      "title_zh": "BioMaze：生物途径推理的大语言模型基准测试与增强",
      "authors": [
        "Haiteng Zhao",
        "Chang Ma",
        "Fangzhi Xu",
        "Lingpeng Kong",
        "Zhi-Hong Deng"
      ],
      "abstract": "The applications of large language models (LLMs) in various biological\ndomains have been explored recently, but their reasoning ability in complex\nbiological systems, such as pathways, remains underexplored, which is crucial\nfor predicting biological phenomena, formulating hypotheses, and designing\nexperiments. This work explores the potential of LLMs in pathway reasoning. We\nintroduce BioMaze, a dataset with 5.1K complex pathway problems derived from\nreal research, covering various biological contexts including natural dynamic\nchanges, disturbances, additional intervention conditions, and multi-scale\nresearch targets. Our evaluation of methods such as CoT and graph-augmented\nreasoning, shows that LLMs struggle with pathway reasoning, especially in\nperturbed systems. To address this, we propose PathSeeker, an LLM agent that\nenhances reasoning through interactive subgraph-based navigation, enabling a\nmore effective approach to handling the complexities of biological systems in a\nscientifically aligned manner. The dataset and code are available at\nhttps://github.com/zhao-ht/BioMaze.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在生物途径推理中的能力，引入了 BioMaze 数据集，该数据集包含 5.1K 个真实研究衍生的复杂问题，覆盖自然动态变化、干扰条件和多尺度目标。评估结果显示，LLMs 在使用 CoT (Chain-of-Thought) 和图增强推理等方法时，尤其在扰动系统中，表现出明显的不足。针对这一问题，论文提出了 PathSeeker，一个基于交互式子图导航的 LLM 代理，能够更有效地处理生物系统的复杂性，并为预测生物现象、制定假设和设计实验提供科学对齐的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16660v4",
      "published_date": "2025-02-23 17:38:10 UTC",
      "updated_date": "2025-04-16 16:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:42:49.890294"
    },
    {
      "arxiv_id": "2502.16648v1",
      "title": "Few-shot Continual Relation Extraction via Open Information Extraction",
      "title_zh": "基于开放信息抽取的少样本",
      "authors": [
        "Thiem Nguyen",
        "Anh Nguyen",
        "Quyen Tran",
        "Tu Vu",
        "Diep Nguyen",
        "Linh Ngo",
        "Thien Nguyen"
      ],
      "abstract": "Typically, Few-shot Continual Relation Extraction (FCRE) models must balance\nretaining prior knowledge while adapting to new tasks with extremely limited\ndata. However, real-world scenarios may also involve unseen or undetermined\nrelations that existing methods still struggle to handle. To address these\nchallenges, we propose a novel approach that leverages the Open Information\nExtraction concept of Knowledge Graph Construction (KGC). Our method not only\nexposes models to all possible pairs of relations, including determined and\nundetermined labels not available in the training set, but also enriches model\nknowledge with diverse relation descriptions, thereby enhancing knowledge\nretention and adaptability in this challenging scenario. In the perspective of\nKGC, this is the first work explored in the setting of Continual Learning,\nallowing efficient expansion of the graph as the data evolves. Experimental\nresults demonstrate our superior performance compared to other state-of-the-art\nFCRE baselines, as well as the efficiency in handling dynamic graph\nconstruction in this setting.",
      "tldr_zh": "本文提出了一种针对Few-shot Continual Relation Extraction (FCRE)的创新方法，通过整合Open Information Extraction的Knowledge Graph Construction (KGC)概念，解决模型在保留先前知识的同时适应新任务和未见relations的挑战。该方法使模型能够接触所有可能的relation pairs，包括训练集中未有的determined和undetermined labels，并通过多样化的relation descriptions增强知识保留和适应性，在Continual Learning设置下首次实现高效的图结构扩展。实验结果表明，该方法在FCRE基准上优于现有最先进基线，并在动态图构建中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16648v1",
      "published_date": "2025-02-23 16:52:59 UTC",
      "updated_date": "2025-02-23 16:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:01.030346"
    },
    {
      "arxiv_id": "2502.16645v1",
      "title": "CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Chenlong Wang",
        "Zhaoyang Chu",
        "Zhengxiang Cheng",
        "Xuyi Yang",
        "Kaiyue Qiu",
        "Yao Wan",
        "Zhou Zhao",
        "Xuanhua Shi",
        "Dongping Chen"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited exceptional performance in\nsoftware engineering yet face challenges in adapting to continually evolving\ncode knowledge, particularly regarding the frequent updates of third-party\nlibrary APIs. This limitation, stemming from static pre-training datasets,\noften results in non-executable code or implementations with suboptimal safety\nand efficiency. To this end, this paper introduces CODESYNC, a data engine for\nidentifying outdated code patterns and collecting real-time code knowledge\nupdates from Python third-party libraries. Building upon CODESYNC, we develop\nCODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay\nsynchronized with code evolution, which covers real-world updates for 220 APIs\nfrom six Python libraries. Our benchmark offers 3,300 test cases across three\nevaluation tasks and an update-aware instruction tuning dataset consisting of\n2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs\nreveal that they struggle with dynamic code evolution, even with the support of\nadvanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe\nthat our benchmark can offer a strong foundation for the development of more\neffective methods for real-time code knowledge updating in the future. The\nexperimental code and dataset are publicly available at:\nhttps://github.com/Lucky-voyage/Code-Sync.",
      "tldr_zh": "该论文提出CODESYNC，一种数据引擎，用于识别过时的代码模式并从Python第三方库实时收集代码知识更新，以帮助Large Language Models (LLMs)适应动态代码演变。基于此，作者开发了CODESYNCBENCH基准，涵盖220个API的真实更新、3300个测试案例和2200个指令微调数据集，用于评估LLMs在代码同步方面的表现。实验结果显示，14个state-of-the-art LLMs即使使用DPO、ORPO和SimPO等高级知识更新方法，仍然在处理动态代码演变时存在显著挑战。该基准为未来实时代码知识更新方法的发展提供了坚实基础，并已公开数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16645v1",
      "published_date": "2025-02-23 16:46:18 UTC",
      "updated_date": "2025-02-23 16:46:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:13.530153"
    },
    {
      "arxiv_id": "2502.16638v1",
      "title": "Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression",
      "title_zh": "自动联合结构化剪枝和量化，用于高效神经网络训练和压缩",
      "authors": [
        "Xiaoyi Qu",
        "David Aponte",
        "Colby Banbury",
        "Daniel P. Robinson",
        "Tianyu Ding",
        "Kazuhito Koishida",
        "Ilya Zharkov",
        "Tianyi Chen"
      ],
      "abstract": "Structured pruning and quantization are fundamental techniques used to reduce\nthe size of deep neural networks (DNNs) and typically are applied\nindependently. Applying these techniques jointly via co-optimization has the\npotential to produce smaller, high-quality models. However, existing joint\nschemes are not widely used because of (1) engineering difficulties\n(complicated multi-stage processes), (2) black-box optimization (extensive\nhyperparameter tuning to control the overall compression), and (3) insufficient\narchitecture generalization. To address these limitations, we present the\nframework GETA, which automatically and efficiently performs joint structured\npruning and quantization-aware training on any DNNs. GETA introduces three key\ninnovations: (i) a quantization-aware dependency graph (QADG) that constructs a\npruning search space for generic quantization-aware DNN, (ii) a partially\nprojected stochastic gradient method that guarantees layerwise bit constraints\nare satisfied, and (iii) a new joint learning strategy that incorporates\ninterpretable relationships between pruning and quantization. We present\nnumerical experiments on both convolutional neural networks and transformer\narchitectures that show that our approach achieves competitive (often superior)\nperformance compared to existing joint pruning and quantization methods.",
      "tldr_zh": "本论文提出GETA框架，用于自动高效地联合结构化剪枝和量化感知训练，以减少深度神经网络(DNNs)的规模并提升性能。GETA通过三个关键创新解决现有方法的局限性：(i)量化感知依赖图(QADG)构建剪枝搜索空间，(ii)部分投影随机梯度方法确保层级位约束，(iii)新的联合学习策略整合剪枝和量化之间的可解释关系。实验结果显示，在卷积神经网络和Transformer架构上，GETA的性能与现有方法相当或更优越。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16638v1",
      "published_date": "2025-02-23 16:28:18 UTC",
      "updated_date": "2025-02-23 16:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:24.399923"
    },
    {
      "arxiv_id": "2502.16637v1",
      "title": "Time Series Domain Adaptation via Latent Invariant Causal Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Ruichu Cai",
        "Junxian Huang",
        "Zhenhui Yang",
        "Zijian Li",
        "Emadeldeen Eldele",
        "Min Wu",
        "Fuchun Sun"
      ],
      "abstract": "Time series domain adaptation aims to transfer the complex temporal\ndependence from the labeled source domain to the unlabeled target domain.\nRecent advances leverage the stable causal mechanism over observed variables to\nmodel the domain-invariant temporal dependence. However, modeling precise\ncausal structures in high-dimensional data, such as videos, remains\nchallenging. Additionally, direct causal edges may not exist among observed\nvariables (e.g., pixels). These limitations hinder the applicability of\nexisting approaches to real-world scenarios. To address these challenges, we\nfind that the high-dimension time series data are generated from the\nlow-dimension latent variables, which motivates us to model the causal\nmechanisms of the temporal latent process. Based on this intuition, we propose\na latent causal mechanism identification framework that guarantees the\nuniqueness of the reconstructed latent causal structures. Specifically, we\nfirst identify latent variables by utilizing sufficient changes in historical\ninformation. Moreover, by enforcing the sparsity of the relationships of latent\nvariables, we can achieve identifiable latent causal structures. Built on the\ntheoretical results, we develop the Latent Causality Alignment (LCA) model that\nleverages variational inference, which incorporates an intra-domain latent\nsparsity constraint for latent structure reconstruction and an inter-domain\nlatent sparsity constraint for domain-invariant structure reconstruction.\nExperiment results on eight benchmarks show a general improvement in the\ndomain-adaptive time series classification and forecasting tasks, highlighting\nthe effectiveness of our method in real-world scenarios. Codes are available at\nhttps://github.com/DMIRLAB-Group/LCA.",
      "tldr_zh": "本文提出一种基于潜在不变因果机制的时间序列域适应方法，旨在解决现有方法在高维数据（如视频）中建模因果结构困难的问题，通过识别低维潜在变量并强制关系稀疏性，确保潜在因果结构的唯一性。作者开发了Latent Causality Alignment (LCA)模型，利用变分推断结合域内和域间潜在稀疏性约束，实现源域和目标域的因果机制对齐。实验结果显示，该方法在八个基准上的时间序列分类和预测任务中取得了普遍改进，证明了其在实际场景中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16637v1",
      "published_date": "2025-02-23 16:25:58 UTC",
      "updated_date": "2025-02-23 16:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:38.628647"
    },
    {
      "arxiv_id": "2502.16634v3",
      "title": "OptionZero: Planning with Learned Options",
      "title_zh": "翻译失败",
      "authors": [
        "Po-Wei Huang",
        "Pei-Chiun Peng",
        "Hung Guei",
        "Ti-Rong Wu"
      ],
      "abstract": "Planning with options -- a sequence of primitive actions -- has been shown\neffective in reinforcement learning within complex environments. Previous\nstudies have focused on planning with predefined options or learned options\nthrough expert demonstration data. Inspired by MuZero, which learns superhuman\nheuristics without any human knowledge, we propose a novel approach, named\nOptionZero. OptionZero incorporates an option network into MuZero, providing\nautonomous discovery of options through self-play games. Furthermore, we modify\nthe dynamics network to provide environment transitions when using options,\nallowing searching deeper under the same simulation constraints. Empirical\nexperiments conducted in 26 Atari games demonstrate that OptionZero outperforms\nMuZero, achieving a 131.58% improvement in mean human-normalized score. Our\nbehavior analysis shows that OptionZero not only learns options but also\nacquires strategic skills tailored to different game characteristics. Our\nfindings show promising directions for discovering and using options in\nplanning. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/optionzero.",
      "tldr_zh": "该论文提出OptionZero，一种在强化学习中通过自主学习options（选项）来进行规划的方法，受MuZero启发，不依赖人类知识，而是通过self-play games（自玩游戏）自动发现options。OptionZero将option network集成到MuZero框架中，并修改dynamics network（动态网络），以支持options的使用，从而在相同模拟约束下实现更深层的搜索。在26个Atari games上进行的实验显示，OptionZero比MuZero提高了131.58%的均一人归一化分数，并展示了针对不同游戏特点的学习options和战略技能。这一方法为强化学习中的规划提供了有前景的方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the Thirteenth International Conference on Learning\n  Representations (ICLR 2025) as oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2502.16634v3",
      "published_date": "2025-02-23 16:20:15 UTC",
      "updated_date": "2025-03-21 13:30:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:49.123013"
    },
    {
      "arxiv_id": "2502.16627v4",
      "title": "Energy-Efficient Transformer Inference: Optimization Strategies for Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Arshia Kermani",
        "Ehsan Zeraatkar",
        "Habib Irani"
      ],
      "abstract": "The increasing computational demands of transformer models in time series\nclassification necessitate effective optimization strategies for\nenergy-efficient deployment. Our study presents a systematic investigation of\noptimization techniques, focusing on structured pruning and quantization\nmethods for transformer architectures. Through extensive experimentation on\nthree distinct datasets (RefrigerationDevices, ElectricDevices, and PLAID), we\nquantitatively evaluate model performance and energy efficiency across\ndifferent transformer configurations. Our experimental results demonstrate that\nstatic quantization reduces energy consumption by 29.14% while maintaining\nclassification performance, and L1 pruning achieves a 63% improvement in\ninference speed with minimal accuracy degradation. Our findings provide\nvaluable insights into the effectiveness of optimization strategies for\ntransformer-based time series classification, establishing a foundation for\nefficient model deployment in resource-constrained environments.",
      "tldr_zh": "该研究探讨了Transformer模型在时间序列分类中的能量高效优化策略，重点关注structured pruning和quantization方法，以应对日益增长的计算需求。通过在RefrigerationDevices、ElectricDevices和PLAID数据集上的广泛实验，论文评估了不同Transformer配置的性能和能量效率。结果显示，static quantization可减少29.14%的能量消耗，同时保持分类性能；L1 pruning则提升63%的推理速度，准确率下降最小。该工作为Transformer-based时间序列分类在资源受限环境中的高效部署提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16627v4",
      "published_date": "2025-02-23 16:04:56 UTC",
      "updated_date": "2025-05-21 00:52:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:43:59.987040"
    },
    {
      "arxiv_id": "2503.16460v1",
      "title": "Beyond Final Answers: Evaluating Large Language Models for Math Tutoring",
      "title_zh": "超越最终答案：评估大型语言模型用于数学辅导",
      "authors": [
        "Adit Gupta",
        "Jennifer Reddig",
        "Tommaso Calo",
        "Daniel Weitekamp",
        "Christopher J. MacLellan"
      ],
      "abstract": "Researchers have made notable progress in applying Large Language Models\n(LLMs) to solve math problems, as demonstrated through efforts like GSM8k,\nProofNet, AlphaGeometry, and MathOdyssey. This progress has sparked interest in\ntheir potential use for tutoring students in mathematics. However, the\nreliability of LLMs in tutoring contexts -- where correctness and instructional\nquality are crucial -- remains underexplored. Moreover, LLM problem-solving\ncapabilities may not necessarily translate into effective tutoring support for\nstudents. In this work, we present two novel approaches to evaluate the\ncorrectness and quality of LLMs in math tutoring contexts. The first approach\nuses an intelligent tutoring system for college algebra as a testbed to assess\nLLM problem-solving capabilities. We generate benchmark problems using the\ntutor, prompt a diverse set of LLMs to solve them, and compare the solutions to\nthose generated by the tutor. The second approach evaluates LLM as tutors\nrather than problem solvers. We employ human evaluators, who act as students\nseeking tutoring support from each LLM. We then assess the quality and\ncorrectness of the support provided by the LLMs via a qualitative coding\nprocess. We applied these methods to evaluate several ChatGPT models, including\n3.5 Turbo, 4, 4o, o1-mini, and o1-preview. Our findings show that when used as\nproblem solvers, LLMs generate correct final answers for 85.5% of the college\nalgebra problems tested. When employed interactively as tutors, 90% of LLM\ndialogues show high-quality instructional support; however, many contain errors\n-- only 56.6% are entirely correct. We conclude that, despite their potential,\nLLMs are not yet suitable as intelligent tutors for math without human\noversight or additional mechanisms to ensure correctness and quality.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在数学辅导中的可靠性和教学质量，超越了其在问题求解（如 GSM8k 和 ProofNet）方面的表现。研究者提出两种方法：一是使用大学代数智能辅导系统生成基准问题，并比较 LLMs 的求解结果；二是通过人类评估者模拟学生互动，采用定性编码评估 LLMs 的辅导正确性和质量。结果显示，LLMs 作为问题求解器时，85.5% 的大学代数问题给出正确最终答案，但作为互动辅导者时，仅56.6% 的对话完全正确。总体结论是，尽管 LLMs 潜力巨大，但目前仍需人类监督或额外机制来确保辅导的准确性和可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16460v1",
      "published_date": "2025-02-23 15:43:45 UTC",
      "updated_date": "2025-02-23 15:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:44:14.286183"
    },
    {
      "arxiv_id": "2502.16618v1",
      "title": "Can Large Vision-Language Models Detect Images Copyright Infringement from GenAI?",
      "title_zh": "大型视觉语言模型能检测从 GenAI 产生的图像版权侵权吗？",
      "authors": [
        "Qipan Xu",
        "Zhenting Wang",
        "Xiaoxiao He",
        "Ligong Han",
        "Ruixiang Tang"
      ],
      "abstract": "Generative AI models, renowned for their ability to synthesize high-quality\ncontent, have sparked growing concerns over the improper generation of\ncopyright-protected material. While recent studies have proposed various\napproaches to address copyright issues, the capability of large vision-language\nmodels (LVLMs) to detect copyright infringements remains largely unexplored. In\nthis work, we focus on evaluating the copyright detection abilities of\nstate-of-the-art LVLMs using a various set of image samples. Recognizing the\nabsence of a comprehensive dataset that includes both IP-infringement samples\nand ambiguous non-infringement negative samples, we construct a benchmark\ndataset comprising positive samples that violate the copyright protection of\nwell-known IP figures, as well as negative samples that resemble these figures\nbut do not raise copyright concerns. This dataset is created using advanced\nprompt engineering techniques. We then evaluate leading LVLMs using our\nbenchmark dataset. Our experimental results reveal that LVLMs are prone to\noverfitting, leading to the misclassification of some negative samples as\nIP-infringement cases. In the final section, we analyze these failure cases and\npropose potential solutions to mitigate the overfitting problem.",
      "tldr_zh": "本文研究了大型视觉语言模型 (LVLMs) 是否能有效检测生成式 AI (GenAI) 产生的图像版权侵权问题。作者构建了一个基准数据集，包括侵犯知识产权 (IP) 的正样本和类似但不侵权的负样本，使用高级提示工程技术生成。实验评估了领先的 LVLMs，发现这些模型容易过拟合，导致将部分负样本误分类为侵权案例。最后，论文分析了这些失败案例，并提出了潜在解决方案来缓解过拟合问题。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16618v1",
      "published_date": "2025-02-23 15:41:12 UTC",
      "updated_date": "2025-02-23 15:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:44:24.406976"
    },
    {
      "arxiv_id": "2502.16613v1",
      "title": "Intelligent Tutors Beyond K-12: An Observational Study of Adult Learner Engagement and Academic Impact",
      "title_zh": "超越 K-12 的智能导师：对成人学习者参与",
      "authors": [
        "Adit Gupta",
        "Christopher MacLellan"
      ],
      "abstract": "Intelligent tutors have proven to be effective in K-12 education, though\ntheir impact on adult learners -- especially as a supplementary resource --\nremains underexplored. Understanding how adults voluntarily engage with\neducational technologies can inform the design of tools that support skill\nre-learning and enhancement. More critically, it helps determine whether\ntutoring systems, which are typically built for K-12 learners, can also support\nadult populations. This study examines the adoption, usage patterns, and\neffectiveness of a novel tutoring system, Apprentice Tutors, among adult\nlearners at a state technical college. We analyze three types of data\nincluding, user demographics, grades, and tutor interactions, to assess whether\nvoluntary tutor usage translates into measurable learning gains. Our findings\nreveal key temporal patterns in tutor engagement and provide evidence of\nlearning within tutors, as determined through skill improvement in knowledge\ncomponents across tutors. We also found evidence that this learning transferred\noutside the tutor, as observed through higher course assessment scores\nfollowing tutor usage. These results suggest that intelligent tutors are a\nviable tool for adult learners, warranting further research into their\nlong-term impact on this population.",
      "tldr_zh": "本研究考察了 intelligent tutors 在成人学习者中的应用，探讨其作为补充资源是否能提升技能再学和学习效果。\n研究采用观察性方法，分析了 Apprentice Tutors 系统在州立技术学院成人学习者的采用、使用模式及相关数据，包括用户 demographics、成绩和互动记录。\n结果显示，成人学习者表现出关键时间参与模式，并在知识组件上实现技能改善，且学习收益转移到更高的课程评估分数。\n这些发现表明，intelligent tutors 是成人学习者的有效工具，值得进一步探索其长期影响。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16613v1",
      "published_date": "2025-02-23 15:36:22 UTC",
      "updated_date": "2025-02-23 15:36:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:44:37.158358"
    },
    {
      "arxiv_id": "2502.16612v1",
      "title": "MemeIntel: Explainable Detection of Propagandistic and Hateful Memes",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Bayan Kmainasi",
        "Abul Hasnat",
        "Md Arid Hasan",
        "Ali Ezzat Shahroor",
        "Firoj Alam"
      ],
      "abstract": "The proliferation of multimodal content on social media presents significant\nchallenges in understanding and moderating complex, context-dependent issues\nsuch as misinformation, hate speech, and propaganda. While efforts have been\nmade to develop resources and propose new methods for automatic detection,\nlimited attention has been given to label detection and the generation of\nexplanation-based rationales for predicted labels. To address this challenge,\nwe introduce MemeIntel, an explanation-enhanced dataset for propaganda memes in\nArabic and hateful memes in English, making it the first large-scale resource\nfor these tasks. To solve these tasks, we propose a multi-stage optimization\napproach and train Vision-Language Models (VLMs). Our results demonstrate that\nthis approach significantly improves performance over the base model for both\n\\textbf{label detection} and explanation generation, outperforming the current\nstate-of-the-art with an absolute improvement of ~3% on ArMeme and ~7% on\nHateful Memes. For reproducibility and future research, we aim to make the\nMemeIntel dataset and experimental resources publicly available.",
      "tldr_zh": "这篇论文介绍了 MemeIntel，一个新的解释增强数据集，用于检测阿拉伯语的宣传模因和英语的仇恨模因，这是该领域的首个大规模资源。作者提出了一种多阶段优化方法来训练 Vision-Language Models (VLMs)，以实现标签检测和基于解释的理由生成。实验结果显示，该方法显著提升了性能，在 ArMeme 数据集上比现有最先进方法提高了约 3%，在 Hateful Memes 数据集上提高了约 7%。为了促进可重复性和未来研究，作者计划公开 MemeIntel 数据集和实验资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, hateful meme, multimodality, text, images",
      "pdf_url": "http://arxiv.org/pdf/2502.16612v1",
      "published_date": "2025-02-23 15:35:48 UTC",
      "updated_date": "2025-02-23 15:35:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:44:51.144294"
    },
    {
      "arxiv_id": "2502.16611v1",
      "title": "Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments",
      "title_zh": "翻译失败",
      "authors": [
        "Shitong Xu",
        "Yiyuan Yang",
        "Niki Trigoni",
        "Andrew Markham"
      ],
      "abstract": "Target speaker extraction focuses on isolating a specific speaker's voice\nfrom an audio mixture containing multiple speakers. To provide information\nabout the target speaker's identity, prior works have utilized clean audio\nexamples as conditioning inputs. However, such clean audio examples are not\nalways readily available (e.g. It is impractical to obtain a clean audio\nexample of a stranger's voice at a cocktail party without stepping away from\nthe noisy environment). Limited prior research has explored extracting the\ntarget speaker's characteristics from noisy audio examples, which may include\noverlapping speech from disturbing speakers. In this work, we focus on target\nspeaker extraction when multiple speakers are present during the enrollment\nstage, through leveraging differences between audio segments where the target\nspeakers are speaking (Positive Enrollments) and segments where they are not\n(Negative Enrollments). Experiments show the effectiveness of our model\narchitecture and the dedicated pretraining method for the proposed task. Our\nmethod achieves state-of-the-art performance in the proposed application\nsettings and demonstrates strong generalizability across challenging and\nrealistic scenarios.",
      "tldr_zh": "这篇论文针对Target Speaker Extraction问题，提出一种新方法，通过比较嘈杂音频中的Positive Enrollments（目标说话者在说话的段落）和Negative Enrollments（目标说话者不在说话的段落），来提取目标说话者声音，而非依赖传统的干净音频样本。  \n该方法解决了现实场景中难以获取干净音频的挑战，采用了专有的模型架构和预训练策略。  \n实验结果表明，该方法在各种复杂环境中达到了最先进性能，并展示了强大的泛化能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "16 pages, 5 figures, appendix included",
      "pdf_url": "http://arxiv.org/pdf/2502.16611v1",
      "published_date": "2025-02-23 15:33:44 UTC",
      "updated_date": "2025-02-23 15:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:45:01.333102"
    },
    {
      "arxiv_id": "2502.16610v1",
      "title": "AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Caetano",
        "Christiaan Viviers",
        "Lena Filatova",
        "Peter H. N. de With",
        "Fons van der Sommen"
      ],
      "abstract": "Ensuring the quality and integrity of medical images is crucial for\nmaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosis\nand Computer-Aided Detection (CAD) systems. Covariate shifts are subtle\nvariations in the data distribution caused by different imaging devices or\nsettings and can severely degrade model performance, similar to the effects of\nadversarial attacks. Therefore, it is vital to have a lightweight and fast\nmethod to assess the quality of these images prior to using CAD models.\nAdverX-Ray addresses this need by serving as an image-quality assessment layer,\ndesigned to detect covariate shifts effectively. This Adversarial Variational\nAutoencoder prioritizes the discriminator's role, using the suboptimal outputs\nof the generator as negative samples to fine-tune the discriminator's ability\nto identify high-frequency artifacts. Images generated by adversarial networks\noften exhibit severe high-frequency artifacts, guiding the discriminator to\nfocus excessively on these components. This makes the discriminator ideal for\nthis approach. Trained on patches from X-ray images of specific machine models,\nAdverX-Ray can evaluate whether a scan matches the training distribution, or if\na scan from the same machine is captured under different settings. Extensive\ncomparisons with various OOD detection methods show that AdverX-Ray\nsignificantly outperforms existing techniques, achieving a 96.2% average AUROC\nusing only 64 random patches from an X-ray. Its lightweight and fast\narchitecture makes it suitable for real-time applications, enhancing the\nreliability of medical imaging systems. The code and pretrained models are\npublicly available.",
      "tldr_zh": "该研究提出AdverX-Ray，一种基于对抗变分自编码器(Adversarial VAEs)的图像质量评估框架，旨在检测医疗X光图像中的协变量偏移(covariate shifts)，从而提升深度学习辅助诊断系统的可靠性。该框架强调鉴别器的作用，通过使用生成器的次优输出作为负样本，专注于高频伪影的识别，并使用特定机器模型的图像补丁进行训练，以评估图像是否符合训练分布。实验结果显示，AdverX-Ray在OOD检测方法中显著优于现有技术，平均AUROC达到96.2%，且其轻量级架构适合实时应用，代码和预训练模型已公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "SPIE Medical Imaging 2025 Runner-up 2025 Robert F. Wagner\n  All-Conference Best Student Paper Award",
      "pdf_url": "http://arxiv.org/pdf/2502.16610v1",
      "published_date": "2025-02-23 15:32:40 UTC",
      "updated_date": "2025-02-23 15:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:45:14.352201"
    },
    {
      "arxiv_id": "2502.16608v1",
      "title": "Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control",
      "title_zh": "翻译失败",
      "authors": [
        "Yuli Zhang",
        "Shangbo Wang",
        "Dongyao Jia",
        "Pengfei Fan",
        "Ruiyuan Jiang",
        "Hankang Gu",
        "Andy H. F. Chow"
      ],
      "abstract": "Reinforcement learning (RL) emerges as a promising data-driven approach for\nadaptive traffic signal control (ATSC) in complex urban traffic networks, with\ndeep neural networks substantially augmenting its learning capabilities.\nHowever, centralized RL becomes impractical for ATSC involving multiple agents\ndue to the exceedingly high dimensionality of the joint action space.\nMulti-agent RL (MARL) mitigates this scalability issue by decentralizing\ncontrol to local RL agents. Nevertheless, this decentralized method introduces\nnew challenges: the environment becomes partially observable from the\nperspective of each local agent due to constrained inter-agent communication.\nBoth centralized RL and MARL exhibit distinct strengths and weaknesses,\nparticularly under heavy intersectional traffic conditions. In this paper, we\njustify that MARL can achieve the optimal global Q-value by separating into\nmultiple IRL (Independent Reinforcement Learning) processes when no spill-back\ncongestion occurs (no agent dependency) among agents (intersections). In the\npresence of spill-back congestion (with agent dependency), the maximum global\nQ-value can be achieved by using centralized RL. Building upon the conclusions,\nwe propose a novel Dynamic Parameter Update Strategy for Deep Q-Network\n(DQN-DPUS), which updates the weights and bias based on the dependency dynamics\namong agents, i.e. updating only the diagonal sub-matrices for the scenario\nwithout spill-back congestion. We validate the DQN-DPUS in a simple network\nwith two intersections under varying traffic, and show that the proposed\nstrategy can speed up the convergence rate without sacrificing optimal\nexploration. The results corroborate our theoretical findings, demonstrating\nthe efficacy of DQN-DPUS in optimizing traffic signal control.",
      "tldr_zh": "本研究探讨了多代理强化学习(MARL)在交通信号控制(ATSC)中的依赖动态问题，指出在无溢出拥堵（无代理依赖）时，MARL可通过独立强化学习(IRL)进程实现最优全局Q值，而有拥堵（有代理依赖）时则需依赖集中式RL。基于这一分析，提出了一种新型策略Dynamic Parameter Update Strategy for Deep Q-Network(DQN-DPUS)，它根据代理间的依赖动态动态更新参数，仅在无拥堵场景更新对角子矩阵，以加速收敛过程。实验在两个交汇点的简单网络中验证了DQN-DPUS，能显著提高收敛速度而不牺牲最优探索，从而优化ATSC的性能。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16608v1",
      "published_date": "2025-02-23 15:29:12 UTC",
      "updated_date": "2025-02-23 15:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:45:28.371179"
    },
    {
      "arxiv_id": "2502.16606v1",
      "title": "Reasoning about Affordances: Causal and Compositional Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Magnus F. Gjerde",
        "Vanessa Cheung",
        "David Lagnado"
      ],
      "abstract": "With the rapid progress of Large Language Models (LLMs), it becomes\nincreasingly important to understand their abilities and limitations. In two\nexperiments, we investigate the causal and compositional reasoning abilities of\nLLMs and humans in the domain of object affordances, an area traditionally\nlinked to embodied cognition. The tasks, designed from scratch to avoid data\ncontamination, require decision-makers to select unconventional objects to\nreplace a typical tool for a particular purpose, such as using a table tennis\nracket to dig a hole. In Experiment 1, we evaluated GPT-3.5 and GPT-4o, finding\nthat GPT-4o, when given chain-of-thought prompting, performed on par with human\nparticipants, while GPT-3.5 lagged significantly. In Experiment 2, we\nintroduced two new conditions, Distractor (more object choices, increasing\ndifficulty) and Image (object options presented visually), and evaluated Claude\n3 Sonnet and Claude 3.5 Sonnet in addition to the GPT models. The Distractor\ncondition significantly impaired performance across humans and models, although\nGPT-4o and Claude 3.5 still performed well above chance. Surprisingly, the\nImage condition had little impact on humans or GPT-4o, but significantly\nlowered Claude 3.5's accuracy. Qualitative analysis showed that GPT-4o and\nClaude 3.5 have a stronger ability than their predecessors to identify and\nflexibly apply causally relevant object properties. The improvement from\nGPT-3.5 and Claude 3 to GPT-4o and Claude 3.5 suggests that models are\nincreasingly capable of causal and compositional reasoning in some domains,\nalthough further mechanistic research is necessary to understand how LLMs\nreason.",
      "tldr_zh": "本研究评估了大型语言模型(LLMs)在物体 affordances 领域的因果和组合推理能力，通过两个实验与人类比较，任务涉及选择非传统物体替代工具，如用乒乓球拍挖洞。实验1显示，使用 chain-of-thought prompting 的 GPT-4o 与人类表现相当，而 GPT-3.5 显著落后；实验2引入 Distractor（增加物体选择难度）和 Image（视觉呈现）条件，结果表明 Distractor 显著降低所有参与者的性能，但 GPT-4o 和 Claude 3.5 仍高于随机水平，而 Image 条件对人类和 GPT-4o 影响小，却显著降低 Claude 3.5 的准确率。定性分析发现，GPT-4o 和 Claude 3.5 比前代模型更能识别并灵活应用物体的因果相关属性，表明 LLMs 在此类推理能力上持续改进，但仍需深入机制研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16606v1",
      "published_date": "2025-02-23 15:21:47 UTC",
      "updated_date": "2025-02-23 15:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:45:41.381347"
    },
    {
      "arxiv_id": "2502.16602v1",
      "title": "VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Yang",
        "Yangyang Guo",
        "Hui Lu",
        "Yan Wang"
      ],
      "abstract": "Recently, Large Vision-Language Models (LVLMs) have made significant strides\nacross diverse multimodal tasks and benchmarks. This paper reveals a largely\nunder-explored problem from existing video-involved LVLMs - language bias,\nwhere models tend to prioritize language over video and thus result in\nincorrect responses. To address this research gap, we first collect a Video\nLanguage Bias Evaluation Benchmark, which is specifically designed to assess\nthe language bias in video-involved LVLMs through two key tasks: ambiguous\nvideo contrast and interrogative question probing. Accordingly, we design\naccompanied evaluation metrics that aim to penalize LVLMs being biased by\nlanguage. In addition, we also propose Multi-branch Contrastive Decoding (MCD),\nintroducing two expert branches to simultaneously counteract language bias\npotentially generated by the amateur text-only branch. Our experiments\ndemonstrate that i) existing video-involved LVLMs, including both proprietary\nand open-sourced, are largely limited by the language bias problem; ii) our MCD\ncan effectively mitigate this issue and maintain general-purpose capabilities\nin various video-involved LVLMs without any additional retraining or alteration\nto model architectures.",
      "tldr_zh": "该研究揭示了视频涉及的大型视觉语言模型 (LVLMs) 存在的语言偏置问题，即模型更依赖语言而非视频，导致错误响应。作者构建了 Video Language Bias Evaluation Benchmark，包括模糊视频对比和疑问句探测任务，并设计了相应评价指标来惩罚这种偏置。针对此问题，他们提出了 Multi-branch Contrastive Decoding (MCD) 方法，通过两个专家分支对抗文本-only 分支的偏置，而无需额外训练或修改模型架构。实验结果显示，现有的视频涉及 LVLMs 普遍受语言偏置影响，而 MCD 能有效缓解这一问题，同时保持模型的通用能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16602v1",
      "published_date": "2025-02-23 15:04:23 UTC",
      "updated_date": "2025-02-23 15:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:45:49.898426"
    },
    {
      "arxiv_id": "2502.16593v1",
      "title": "Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images",
      "title_zh": "通过参数学习对抗图像追踪大型视觉语言模型的版权",
      "authors": [
        "Yubo Wang",
        "Jianting Tang",
        "Chaohu Liu",
        "Linli Xu"
      ],
      "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable image\nunderstanding and dialogue capabilities, allowing them to handle a variety of\nvisual question answering tasks. However, their widespread availability raises\nconcerns about unauthorized usage and copyright infringement, where users or\nindividuals can develop their own LVLMs by fine-tuning published models. In\nthis paper, we propose a novel method called Parameter Learning Attack (PLA)\nfor tracking the copyright of LVLMs without modifying the original model.\nSpecifically, we construct adversarial images through targeted attacks against\nthe original model, enabling it to generate specific outputs. To ensure these\nattacks remain effective on potential fine-tuned models to trigger copyright\ntracking, we allow the original model to learn the trigger images by updating\nparameters in the opposite direction during the adversarial attack process.\nNotably, the proposed method can be applied after the release of the original\nmodel, thus not affecting the model's performance and behavior. To simulate\nreal-world applications, we fine-tune the original model using various\nstrategies across diverse datasets, creating a range of models for copyright\nverification. Extensive experiments demonstrate that our method can more\neffectively identify the original copyright of fine-tuned models compared to\nbaseline methods. Therefore, this work provides a powerful tool for tracking\ncopyrights and detecting unlicensed usage of LVLMs.",
      "tldr_zh": "本研究针对大型视觉语言模型(Large Vision-Language Models, LVLMs)的版权追踪问题，提出了一种名为Parameter Learning Attack (PLA)的新方法，该方法无需修改原模型即可检测未经授权的微调。PLA通过针对原模型的定向攻击生成对抗图像(adversarial images)，并在攻击过程中反向更新模型参数，确保这些图像在微调模型上仍能触发特定输出，从而实现版权验证。该方法可在模型发布后应用，不会影响原模型的表现。实验结果显示，在多种数据集和微调策略下，PLA比基线方法更有效地识别原模型版权，为防范LVLMs的未授权使用提供了强大工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16593v1",
      "published_date": "2025-02-23 14:49:34 UTC",
      "updated_date": "2025-02-23 14:49:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:46:01.033959"
    },
    {
      "arxiv_id": "2503.04780v1",
      "title": "MV-CLAM: Multi-View Molecular Interpretation with Cross-Modal Projection via Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Sumin Ha",
        "Jun Hyeong Kim",
        "Yinhua Piao",
        "Sun Kim"
      ],
      "abstract": "Human expertise in chemistry and biomedicine relies on contextual molecular\nunderstanding, a capability that large language models (LLMs) can extend\nthrough fine-grained alignment between molecular structures and text. Recent\nmultimodal learning advances focus on cross-modal alignment, but existing\nmolecule-text models ignore complementary information in different molecular\nviews and rely on single-view representations, limiting molecular\nunderstanding. Moreover, na\\\"ive multi-view alignment strategies face two\nchallenges: (1) separate aligned spaces with inconsistent mappings between\nmolecule and text embeddings, and that (2) existing loss objectives fail to\npreserve complementary information for fine-grained alignment. This can limit\nthe LLM's ability to fully understand the molecular properties. To address\nthese issues, we propose MV-CLAM, a novel framework that aligns multi-view\nmolecular representations into a unified textual space using a multi-query\ntransformer (MQ-Former). Our approach ensures cross-view consistency while a\ntoken-level contrastive loss preserves diverse molecular features across\ntextual queries. MV-CLAM enhances molecular reasoning, improving retrieval and\ncaptioning accuracy. The source code of MV-CLAM is available in\nhttps://github.com/sumin124/mv-clam.git.",
      "tldr_zh": "本文研究了如何通过大语言模型 (LLMs) 提升分子结构与文本的细粒度对齐，以扩展化学和生物医学中的上下文分子理解。现有分子-文本模型忽略了多视图分子信息的互补性，并面临对齐空间不一致和损失函数不足的问题。为解决这些挑战，提出 MV-CLAM 框架，使用多查询 transformer (MQ-Former) 将多视图分子表示对齐到统一的文本空间，并通过 token-level contrastive loss 保留多样分子特征。该框架显著提高了分子推理性能，提升了检索和标题生成的准确性，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "physics.atom-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04780v1",
      "published_date": "2025-02-23 14:38:29 UTC",
      "updated_date": "2025-02-23 14:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:46:14.981933"
    },
    {
      "arxiv_id": "2502.16589v2",
      "title": "Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhang",
        "Zewei Zhou",
        "Zhaoyi Wang",
        "Yangjie Ji",
        "Yanjun Huang",
        "Hong Chen"
      ],
      "abstract": "Vehicle-to-everything technologies (V2X) have become an ideal paradigm to\nextend the perception range and see through the occlusion. Exiting efforts\nfocus on single-frame cooperative perception, however, how to capture the\ntemporal cue between frames with V2X to facilitate the prediction task even the\nplanning task is still underexplored. In this paper, we introduce the Co-MTP, a\ngeneral cooperative trajectory prediction framework with multi-temporal fusion\nfor autonomous driving, which leverages the V2X system to fully capture the\ninteraction among agents in both history and future domains to benefit the\nplanning. In the history domain, V2X can complement the incomplete history\ntrajectory in single-vehicle perception, and we design a heterogeneous graph\ntransformer to learn the fusion of the history feature from multiple agents and\ncapture the history interaction. Moreover, the goal of prediction is to support\nfuture planning. Thus, in the future domain, V2X can provide the prediction\nresults of surrounding objects, and we further extend the graph transformer to\ncapture the future interaction among the ego planning and the other vehicles'\nintentions and obtain the final future scenario state under a certain planning\naction. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and\nthe results show that Co-MTP achieves state-of-the-art performance and that\nboth history and future fusion can greatly benefit prediction.",
      "tldr_zh": "本研究提出Co-MTP框架，一种基于多时间融合的合作轨迹预测方法，利用V2X技术扩展自动驾驶的感知范围，并在历史域和未来域捕获代理间交互。在历史域，框架通过异构图transformer融合多代理历史轨迹特征，弥补单车感知的不足；在未来域，进一步扩展图transformer以整合周围车辆意图，支持规划决策。在V2X-Seq真实数据集上评估，Co-MTP实现最先进性能，历史和未来融合显著提升预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO",
        "68T07",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures, ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16589v2",
      "published_date": "2025-02-23 14:38:13 UTC",
      "updated_date": "2025-02-25 14:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:46:25.621395"
    },
    {
      "arxiv_id": "2502.16584v1",
      "title": "Audio-FLAN: A Preliminary Release",
      "title_zh": "Audio-FLAN：初步发布",
      "authors": [
        "Liumeng Xue",
        "Ziya Zhou",
        "Jiahao Pan",
        "Zixuan Li",
        "Shuai Fan",
        "Yinghao Ma",
        "Sitong Cheng",
        "Dongchao Yang",
        "Haohan Guo",
        "Yujia Xiao",
        "Xinsheng Wang",
        "Zixuan Shen",
        "Chuanbo Zhu",
        "Xinshen Zhang",
        "Tianchi Liu",
        "Ruibin Yuan",
        "Zeyue Tian",
        "Haohe Liu",
        "Emmanouil Benetos",
        "Ge Zhang",
        "Yike Guo",
        "Wei Xue"
      ],
      "abstract": "Recent advancements in audio tokenization have significantly enhanced the\nintegration of audio capabilities into large language models (LLMs). However,\naudio understanding and generation are often treated as distinct tasks,\nhindering the development of truly unified audio-language models. While\ninstruction tuning has demonstrated remarkable success in improving\ngeneralization and zero-shot learning across text and vision, its application\nto audio remains largely unexplored. A major obstacle is the lack of\ncomprehensive datasets that unify audio understanding and generation. To\naddress this, we introduce Audio-FLAN, a large-scale instruction-tuning dataset\ncovering 80 diverse tasks across speech, music, and sound domains, with over\n100 million instances. Audio-FLAN lays the foundation for unified\naudio-language models that can seamlessly handle both understanding (e.g.,\ntranscription, comprehension) and generation (e.g., speech, music, sound) tasks\nacross a wide range of audio domains in a zero-shot manner. The Audio-FLAN\ndataset is available on HuggingFace and GitHub and will be continuously\nupdated.",
      "tldr_zh": "该研究指出，音频理解和生成任务通常被视为独立，阻碍了音频与大型语言模型（LLMs）的统一整合，而指令微调（instruction tuning）在文本和视觉领域的成功尚未充分应用于音频领域。为解决数据集缺失问题，研究团队引入了 Audio-FLAN，这是一个大规模指令微调数据集，涵盖语音、音乐和声音等80个多样化任务，总计超过1亿实例。Audio-FLAN 支持统一的音频语言模型，实现零-shot处理，包括理解（如转录和理解）和生成（如语音、音乐、声音）任务，并已在HuggingFace和GitHub上发布，将持续更新。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16584v1",
      "published_date": "2025-02-23 14:24:15 UTC",
      "updated_date": "2025-02-23 14:24:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:46:37.704533"
    },
    {
      "arxiv_id": "2502.16573v1",
      "title": "LawPal : A Retrieval Augmented Generation Based System for Enhanced Legal Accessibility in India",
      "title_zh": "LawPal：一种基于检索增强生成的系统，用于增强印度法律可访问性",
      "authors": [
        "Dnyanesh Panchal",
        "Aaryan Gole",
        "Vaibhav Narute",
        "Raunak Joshi"
      ],
      "abstract": "Access to legal knowledge in India is often hindered by a lack of awareness,\nmisinformation and limited accessibility to judicial resources. Many\nindividuals struggle to navigate complex legal frameworks, leading to the\nfrequent misuse of laws and inadequate legal protection. To address these\nissues, we propose a Retrieval-Augmented Generation (RAG)-based legal chatbot\npowered by vectorstore oriented FAISS for efficient and accurate legal\ninformation retrieval. Unlike traditional chatbots, our model is trained using\nan extensive dataset comprising legal books, official documentation and the\nIndian Constitution, ensuring accurate responses to even the most complex or\nmisleading legal queries. The chatbot leverages FAISS for rapid vector-based\nsearch, significantly improving retrieval speed and accuracy. It is also\nprompt-engineered to handle twisted or ambiguous legal questions, reducing the\nchances of incorrect interpretations. Apart from its core functionality of\nanswering legal queries, the platform includes additional features such as\nreal-time legal news updates, legal blogs, and access to law-related books,\nmaking it a comprehensive resource for users. By integrating advanced AI\ntechniques with an optimized retrieval system, our chatbot aims to democratize\nlegal knowledge, enhance legal literacy, and prevent the spread of\nmisinformation. The study demonstrates that our approach effectively improves\nlegal accessibility while maintaining high accuracy and efficiency, thereby\ncontributing to a more informed and empowered society.",
      "tldr_zh": "这篇论文提出 LawPal，一个基于 Retrieval-Augmented Generation (RAG) 的法律聊天机器人，旨在解决印度法律知识获取的障碍，如缺乏意识、错误信息和资源限制。系统利用 FAISS 进行高效向量检索，并通过训练于法律书籍、官方文件和印度宪法的模型来处理复杂或模糊查询，确保响应准确性。LawPal 还提供实时法律新闻、博客和书籍访问等额外功能，提升了用户的综合体验。研究结果显示，该系统显著提高了法律可访问性、准确性和效率，从而促进法律素养的提升和 misinformation 的减少。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16573v1",
      "published_date": "2025-02-23 13:45:47 UTC",
      "updated_date": "2025-02-23 13:45:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:46:50.438324"
    },
    {
      "arxiv_id": "2502.16570v1",
      "title": "Entropy-Lens: The Information Signature of Transformer Computations",
      "title_zh": "熵透镜：Transformer 计算的信息签名",
      "authors": [
        "Riccardo Ali",
        "Francesco Caso",
        "Christopher Irwin",
        "Pietro Liò"
      ],
      "abstract": "Transformer models have revolutionized fields from natural language\nprocessing to computer vision, yet their internal computational dynamics remain\npoorly understood raising concerns about predictability and robustness. In this\nwork, we introduce Entropy-Lens, a scalable, model-agnostic framework that\nleverages information theory to interpret frozen, off-the-shelf large-scale\ntransformers. By quantifying the evolution of Shannon entropy within\nintermediate residual streams, our approach extracts computational signatures\nthat distinguish model families, categorize task-specific prompts, and\ncorrelate with output accuracy. We further demonstrate the generality of our\nmethod by extending the analysis to vision transformers. Our results suggest\nthat entropy-based metrics can serve as a principled tool for unveiling the\ninner workings of modern transformer architectures.",
      "tldr_zh": "Transformer 模型在自然语言处理和计算机视觉等领域带来了革命性变革，但其内部计算动态仍不为人知，引发了可预测性和鲁棒性的担忧。  \n本文引入 Entropy-Lens，一种可扩展的、模型无关框架，利用信息理论量化中间 residual streams 中 Shannon entropy 的演化，从而提取计算签名，以区分模型家族、分类任务特定提示，并与输出准确率相关联。  \n此外，通过扩展分析到 vision transformers，该方法证明了其通用性。  \n总体而言，基于熵的指标可作为揭示现代 Transformer 架构内部工作原理的可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16570v1",
      "published_date": "2025-02-23 13:33:27 UTC",
      "updated_date": "2025-02-23 13:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:47:02.754086"
    },
    {
      "arxiv_id": "2502.16565v2",
      "title": "The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems",
      "title_zh": "分歧的隐藏",
      "authors": [
        "Zengqing Wu",
        "Takayuki Ito"
      ],
      "abstract": "Consensus formation is pivotal in multi-agent systems (MAS), balancing\ncollective coherence with individual diversity. Conventional LLM-based MAS\nprimarily rely on explicit coordination, e.g., prompts or voting, risking\npremature homogenization. We argue that implicit consensus, where agents\nexchange information yet independently form decisions via in-context learning,\ncan be more effective in dynamic environments that require long-horizon\nadaptability. By retaining partial diversity, systems can better explore novel\nstrategies and cope with external shocks. We formalize a consensus-diversity\ntradeoff, showing conditions where implicit methods outperform explicit ones.\nExperiments on three scenarios -- Dynamic Disaster Response, Information Spread\nand Manipulation, and Dynamic Public-Goods Provision -- confirm partial\ndeviation from group norms boosts exploration, robustness, and performance. We\nhighlight emergent coordination via in-context learning, underscoring the value\nof preserving diversity for resilient decision-making.",
      "tldr_zh": "该论文探讨了自适应多智能体系统（MAS）中共识-多样性权衡的核心问题，强调隐式共识（agents 通过信息交换和 in-context learning 独立决策）比传统显式协调（如提示或投票）更适合动态环境，从而避免过早同质化。作者形式化了这一权衡，证明隐式方法在保留部分多样性时，能提升系统对新策略的探索和外部冲击的应对能力。实验在动态灾害响应、信息传播和操纵以及动态公共物品提供等三个场景中验证，结果显示部分偏离群体规范显著提高了系统的鲁棒性和整体性能，突显了多样性对弹性决策的价值。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "Source codes are available at\n  https://github.com/wuzengqing001225/ConsensusDiversityTradeoffMAS",
      "pdf_url": "http://arxiv.org/pdf/2502.16565v2",
      "published_date": "2025-02-23 13:12:53 UTC",
      "updated_date": "2025-05-19 15:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:47:13.887544"
    },
    {
      "arxiv_id": "2502.17522v1",
      "title": "Spectral Theory for Edge Pruning in Asynchronous Recurrent Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Bessone"
      ],
      "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for learning on\ngraph-structured data, finding applications in numerous domains including\nsocial network analysis and molecular biology. Within this broad category,\nAsynchronous Recurrent Graph Neural Networks (ARGNNs) stand out for their\nability to capture complex dependencies in dynamic graphs, resembling living\norganisms' intricate and adaptive nature. However, their complexity often leads\nto large and computationally expensive models. Therefore, pruning unnecessary\nedges becomes crucial for enhancing efficiency without significantly\ncompromising performance. This paper presents a dynamic pruning method based on\ngraph spectral theory, leveraging the imaginary component of the eigenvalues of\nthe network graph's Laplacian.",
      "tldr_zh": "本文提出了一种基于图谱理论的动态边剪枝方法，针对异步循环图神经网络 (ARGNNs) 的复杂性和计算开销问题。方法利用网络图拉普拉斯矩阵 (Laplacian) 特征值的虚部来识别并去除不必要的边，从而提升模型效率。实验结果表明，这种剪枝策略能够在不显著降低性能的情况下，优化 ARGNNs 在动态图数据（如社交网络和分子生物学）中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17522v1",
      "published_date": "2025-02-23 13:05:08 UTC",
      "updated_date": "2025-02-23 13:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:47:25.998668"
    },
    {
      "arxiv_id": "2502.16560v2",
      "title": "An Analytical Emotion Framework of Rumour Threads on Social Media",
      "title_zh": "社交媒体谣言线程的分析情感框架",
      "authors": [
        "Rui Xing",
        "Boyang Sun",
        "Kun Zhang",
        "Preslav Nakov",
        "Timothy Baldwin",
        "Jey Han Lau"
      ],
      "abstract": "Rumours in online social media pose significant risks to modern society,\nmotivating the need for better understanding of how they develop. We focus\nspecifically on the interface between emotion and rumours in threaded\ndiscourses, building on the surprisingly sparse literature on the topic which\nhas largely focused on single aspect of emotions within the original rumour\nposts themselves, and largely overlooked the comparative differences between\nrumours and non-rumours. In this work, we take one step further to provide a\ncomprehensive analytical emotion framework with multi-aspect emotion detection,\ncontrasting rumour and non-rumour threads and provide both correlation and\ncausal analysis of emotions. We applied our framework on existing widely-used\nrumour datasets to further understand the emotion dynamics in online social\nmedia threads. Our framework reveals that rumours trigger more negative\nemotions (e.g., anger, fear, pessimism), while non-rumours evoke more positive\nones. Emotions are contagious, rumours spread negativity, non-rumours spread\npositivity. Causal analysis shows surprise bridges rumours and other emotions;\npessimism comes from sadness and fear, while optimism arises from joy and love.",
      "tldr_zh": "本研究提出了一种分析情绪框架（Analytical Emotion Framework），旨在深入理解在线社交媒体上谣言线程（Rumour Threads）的动态发展，通过多方面情绪检测对比谣言和非谣言线程，并进行相关性和因果分析。框架应用于现有谣言数据集，结果显示谣言往往引发负面情绪（如愤怒、恐惧和悲观），而非谣言则激发正面情绪（如喜悦和爱）。此外，情绪具有传染性，因果分析揭示惊讶（surprise）桥接谣言与其他情绪，悲观（pessimism）源于悲伤和恐惧，而乐观（optimism）源于喜悦和爱。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICWSM 2025 MisD Workshop",
      "pdf_url": "http://arxiv.org/pdf/2502.16560v2",
      "published_date": "2025-02-23 12:57:40 UTC",
      "updated_date": "2025-05-13 22:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:47:37.791301"
    },
    {
      "arxiv_id": "2502.16556v1",
      "title": "Beyond Words: How Large Language Models Perform in Quantitative Management Problem-Solving",
      "title_zh": "超越文字：大型语言模型在定量管理问题求解中的表现如何",
      "authors": [
        "Jonathan Kuzmanko"
      ],
      "abstract": "This study examines how Large Language Models (LLMs) perform when tackling\nquantitative management decision problems in a zero-shot setting. Drawing on\n900 responses generated by five leading models across 20 diverse managerial\nscenarios, our analysis explores whether these base models can deliver accurate\nnumerical decisions under varying presentation formats, scenario complexities,\nand repeated attempts. Contrary to prior findings, we observed no significant\neffects of text presentation format (direct, narrative, or tabular) or text\nlength on accuracy. However, scenario complexity -- particularly in terms of\nconstraints and irrelevant parameters -- strongly influenced performance, often\ndegrading accuracy. Surprisingly, the models handled tasks requiring multiple\nsolution steps more effectively than expected. Notably, only 28.8\\% of\nresponses were exactly correct, highlighting limitations in precision. We\nfurther found no significant ``learning effect'' across iterations: performance\nremained stable across repeated queries. Nonetheless, significant variations\nemerged among the five tested LLMs, with some showing superior binary accuracy.\nOverall, these findings underscore both the promise and the pitfalls of\nharnessing LLMs for complex quantitative decision-making, informing managers\nand researchers about optimal deployment strategies.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在零样本设置下处理定量管理决策问题的性能，通过分析五种领先模型生成的900个响应，涵盖20个多样化管理场景。结果显示，文本呈现格式（直接、叙述或表格）和长度对准确性无显著影响，但场景复杂性（如约束和无关参数）会显著降低性能，而多步骤任务的处理效果超出预期。总体而言，只有28.8%的响应完全正确，且模型在重复查询中无学习效果，不同LLMs之间存在显著差异，这突显了LLMs在复杂定量决策中的潜力与局限性，为优化部署策略提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 5 figures, 19 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.16556v1",
      "published_date": "2025-02-23 12:39:39 UTC",
      "updated_date": "2025-02-23 12:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:47:51.364985"
    },
    {
      "arxiv_id": "2502.16548v1",
      "title": "Composable Strategy Framework with Integrated Video-Text based Large Language Models for Heart Failure Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Jianzhou Chen",
        "Xiumei Wang",
        "Jinyang Sun",
        "Xi Chen",
        "Heyu Chu",
        "Guo Song",
        "Yuji Luo",
        "Xingping Zhou",
        "Rong Gu"
      ],
      "abstract": "Heart failure is one of the leading causes of death worldwide, with millons\nof deaths each year, according to data from the World Health Organization (WHO)\nand other public health agencies. While significant progress has been made in\nthe field of heart failure, leading to improved survival rates and improvement\nof ejection fraction, there remains substantial unmet needs, due to the\ncomplexity and multifactorial characteristics. Therefore, we propose a\ncomposable strategy framework for assessment and treatment optimization in\nheart failure. This framework simulates the doctor-patient consultation process\nand leverages multi-modal algorithms to analyze a range of data, including\nvideo, physical examination, text results as well as medical history. By\nintegrating these various data sources, our framework offers a more holistic\nevaluation and optimized treatment plan for patients. Our results demonstrate\nthat this multi-modal approach outperforms single-modal artificial intelligence\n(AI) algorithms in terms of accuracy in heart failure (HF) prognosis\nprediction. Through this method, we can further evaluate the impact of various\npathological indicators on HF prognosis,providing a more comprehensive\nevaluation.",
      "tldr_zh": "该研究针对心力衰竭（Heart Failure）这一全球主要死亡原因，提出了一种可组合策略框架（Composable Strategy Framework），整合视频-文本基于的大型语言模型（Large Language Models），以模拟医生-患者咨询过程。框架利用多模态算法分析视频、身体检查、文本结果和医疗历史等多源数据，提供更全面的评估和优化治疗计划。结果显示，该多模态方法在心力衰竭预后预测的准确性上优于单模态 AI 算法，并能评估各种病理指标对 HF 预后的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16548v1",
      "published_date": "2025-02-23 12:06:08 UTC",
      "updated_date": "2025-02-23 12:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:48:01.720291"
    },
    {
      "arxiv_id": "2504.05319v1",
      "title": "Predictive Modeling: BIM Command Recommendation Based on Large-scale Usage Logs",
      "title_zh": "预测建模：基于大规模使用日志的 BIM 命令推荐",
      "authors": [
        "Changyu Du",
        "Zihan Deng",
        "Stavros Nousias",
        "André Borrmann"
      ],
      "abstract": "The adoption of Building Information Modeling (BIM) and model-based design\nwithin the Architecture, Engineering, and Construction (AEC) industry has been\nhindered by the perception that using BIM authoring tools demands more effort\nthan conventional 2D drafting. To enhance design efficiency, this paper\nproposes a BIM command recommendation framework that predicts the optimal next\nactions in real-time based on users' historical interactions. We propose a\ncomprehensive filtering and enhancement method for large-scale raw BIM log data\nand introduce a novel command recommendation model. Our model builds upon the\nstate-of-the-art Transformer backbones originally developed for large language\nmodels (LLMs), incorporating a custom feature fusion module, dedicated loss\nfunction, and targeted learning strategy. In a case study, the proposed method\nis applied to over 32 billion rows of real-world log data collected globally\nfrom the BIM authoring software Vectorworks. Experimental results demonstrate\nthat our method can learn universal and generalizable modeling patterns from\nanonymous user interaction sequences across different countries, disciplines,\nand projects. When generating recommendations for the next command, our\napproach achieves a Recall@10 of approximately 84%.",
      "tldr_zh": "该研究针对建筑、工程和施工（AEC）行业中BIM工具使用效率低的问题，提出了一种基于大规模使用日志的BIM命令推荐框架，用于实时预测用户的最佳下一个动作。该框架包括一个全面的日志数据过滤和增强方法，以及一个新型命令推荐模型，该模型基于Transformer骨干（源自LLMs），并整合了自定义特征融合模块、专用损失函数和针对性学习策略。在实际案例中，该方法分析了超过320亿行全球Vectorworks软件日志数据，结果显示模型从匿名用户交互序列中学习到通用和可泛化的建模模式，实现了约84%的Recall@10性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05319v1",
      "published_date": "2025-02-23 11:47:57 UTC",
      "updated_date": "2025-02-23 11:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:48:13.705250"
    },
    {
      "arxiv_id": "2502.16540v1",
      "title": "Advanced Chain-of-Thought Reasoning for Parameter Extraction from Documents Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Cai Chen",
        "Yi Pin Xu",
        "Yang Zhang"
      ],
      "abstract": "Extracting parameters from technical documentation is crucial for ensuring\ndesign precision and simulation reliability in electronic design. However,\ncurrent methods struggle to handle high-dimensional design data and meet the\ndemands of real-time processing. In electronic design automation (EDA),\nengineers often manually search through extensive documents to retrieve\ncomponent parameters required for constructing PySpice models, a process that\nis both labor-intensive and time-consuming. To address this challenge, we\npropose an innovative framework that leverages large language models (LLMs) to\nautomate the extraction of parameters and the generation of PySpice models\ndirectly from datasheets. Our framework introduces three Chain-of-Thought (CoT)\nbased techniques: (1) Targeted Document Retrieval (TDR), which enables the\nrapid identification of relevant technical sections; (2) Iterative Retrieval\nOptimization (IRO), which refines the parameter search through iterative\nimprovements; and (3) Preference Optimization (PO), which dynamically\nprioritizes key document sections based on relevance. Experimental results show\nthat applying all three methods together improves retrieval precision by 47.69%\nand reduces processing latency by 37.84%. Furthermore, effect size analysis\nusing Cohen's d reveals that PO significantly reduces latency, while IRO\ncontributes most to precision enhancement. These findings underscore the\npotential of our framework to streamline EDA processes, enhance design\naccuracy, and shorten development timelines. Additionally, our algorithm has\nmodel-agnostic generalization, meaning it can improve parameter search\nperformance across different LLMs.",
      "tldr_zh": "该研究提出一个创新框架，使用 Large Language Models (LLMs) 结合高级 Chain-of-Thought (CoT) 推理，从技术文档中自动提取参数并生成 PySpice 模型，以解决电子设计自动化 (EDA) 中手动搜索的低效问题。框架包括三个关键技术：Targeted Document Retrieval (TDR) 用于快速识别相关部分、Iterative Retrieval Optimization (IRO) 通过迭代改进搜索过程，以及 Preference Optimization (PO) 动态优先关键文档部分。实验结果显示，结合这些方法，提高检索精度 47.69% 并减少处理延迟 37.84%，Cohen's d 分析进一步证实 PO 显著降低延迟，而 IRO 最贡献于精度提升。该框架具有模型无关的泛化性，能优化 EDA 流程、提升设计准确性和缩短开发时间。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.AR",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16540v1",
      "published_date": "2025-02-23 11:19:44 UTC",
      "updated_date": "2025-02-23 11:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:48:28.530522"
    },
    {
      "arxiv_id": "2502.18520v1",
      "title": "Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features",
      "title_zh": "翻译失败",
      "authors": [
        "Mingli Zhu",
        "Shaokui Wei",
        "Hongyuan Zha",
        "Baoyuan Wu"
      ],
      "abstract": "Recent studies have highlighted the vulnerability of deep neural networks to\nbackdoor attacks, where models are manipulated to rely on embedded triggers\nwithin poisoned samples, despite the presence of both benign and trigger\ninformation. While several defense methods have been proposed, they often\nstruggle to balance backdoor mitigation with maintaining benign performance.In\nthis work, inspired by the concept of optical polarizer-which allows light\nwaves of specific polarizations to pass while filtering others-we propose a\nlightweight backdoor defense approach, NPD. This method integrates a neural\npolarizer (NP) as an intermediate layer within the compromised model,\nimplemented as a lightweight linear transformation optimized via bi-level\noptimization. The learnable NP filters trigger information from poisoned\nsamples while preserving benign content. Despite its effectiveness, we identify\nthrough empirical studies that NPD's performance degrades when the target\nlabels (required for purification) are inaccurately estimated. To address this\nlimitation while harnessing the potential of targeted adversarial mitigation,\nwe propose class-conditional neural polarizer-based defense (CNPD). The key\ninnovation is a fusion module that integrates the backdoored model's predicted\nlabel with the features to be purified. This architecture inherently mimics\ntargeted adversarial defense mechanisms without requiring label estimation used\nin NPD. We propose three implementations of CNPD: the first is r-CNPD, which\ntrains a replicated NP layer for each class and, during inference, selects the\nappropriate NP layer for defense based on the predicted class from the\nbackdoored model. To efficiently handle a large number of classes, two variants\nare designed: e-CNPD, which embeds class information as additional features,\nand a-CNPD, which directs network attention using class information.",
      "tldr_zh": "这篇论文提出了一种轻量级的后门防御方法NPD（Neural Polarizer Defense），受光学偏光器启发，通过在受损模型中插入一个神经偏光器（neural polarizer）作为中间层，并利用双层优化（bi-level optimization）过滤中毒样本的触发信息，同时保留良性性能。针对NPD依赖目标标签估计可能导致性能下降的问题，作者开发了改进版CNPD（Class-Conditional Neural Polarizer-based Defense），其关键创新是融合模块，将后门模型的预测标签与特征结合，模仿目标对抗防御机制。CNPD的三个变体包括r-CNPD（为每个类训练复制的NP层）、e-CNPD（嵌入类信息作为额外特征）和a-CNPD（使用类信息引导网络注意力），这些设计提高了防御的鲁棒性和效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18520v1",
      "published_date": "2025-02-23 11:11:16 UTC",
      "updated_date": "2025-02-23 11:11:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:48:39.306066"
    },
    {
      "arxiv_id": "2502.16535v1",
      "title": "Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance",
      "title_zh": "翻译失败",
      "authors": [
        "Pankaj Yadav",
        "Gulshan Sihag",
        "Vivek Vijay"
      ],
      "abstract": "Machine learning algorithms are used in diverse domains, many of which face\nsignificant challenges due to data imbalance. Studies have explored various\napproaches to address the issue, like data preprocessing, cost-sensitive\nlearning, and ensemble methods. Generative Adversarial Networks (GANs) showed\nimmense potential as a data preprocessing technique that generates good quality\nsynthetic data. This study employs a systematic mapping methodology to analyze\n3041 papers on GAN-based sampling techniques for imbalanced data sourced from\nfour digital libraries. A filtering process identified 100 key studies spanning\ndomains such as healthcare, finance, and cybersecurity. Through comprehensive\nquantitative analysis, this research introduces three categorization mappings\nas application domains, GAN techniques, and GAN variants used to handle the\nimbalanced nature of the data. GAN-based over-sampling emerges as an effective\npreprocessing method. Advanced architectures and tailored frameworks helped\nGANs to improve further in the case of data imbalance. GAN variants like\nvanilla GAN, CTGAN, and CGAN show great adaptability in structured imbalanced\ndata cases. Interest in GANs for imbalanced data has grown tremendously,\ntouching a peak in recent years, with journals and conferences playing crucial\nroles in transmitting foundational theories and practical applications. While\nwith these advances, none of the reviewed studies explicitly explore hybridized\nGAN frameworks with diffusion models or reinforcement learning techniques. This\ngap leads to a future research idea develop innovative approaches for\neffectively handling data imbalance.",
      "tldr_zh": "这篇论文通过系统映射研究分析了 3041 篇关于 Generative Adversarial Networks (GANs) 处理数据不平衡的论文，筛选出 100 篇关键研究，涵盖医疗、金融和网络安全等领域。研究引入了三个分类映射，包括应用领域、GAN 技术以及 GAN 变体（如 vanilla GAN、CTGAN 和 CGAN），证明 GAN-based over-sampling 作为数据预处理方法能有效生成高质量合成数据并提升模型性能。结果显示，对 GANs 在数据不平衡中的兴趣近年来急剧增加，但未来研究可探索混合框架，如将 GANs 与扩散模型或强化学习技术结合，以进一步优化处理不平衡数据。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "49 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16535v1",
      "published_date": "2025-02-23 11:03:29 UTC",
      "updated_date": "2025-02-23 11:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:48:52.971085"
    },
    {
      "arxiv_id": "2502.16534v1",
      "title": "Multilingual != Multicultural: Evaluating Gaps Between Multilingual Capabilities and Cultural Alignment in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Rystrøm",
        "Hannah Rose Kirk",
        "Scott Hale"
      ],
      "abstract": "Large Language Models (LLMs) are becoming increasingly capable across global\nlanguages. However, the ability to communicate across languages does not\nnecessarily translate to appropriate cultural representations. A key concern is\nUS-centric bias, where LLMs reflect US rather than local cultural values. We\npropose a novel methodology that compares LLM-generated response distributions\nagainst population-level opinion data from the World Value Survey across four\nlanguages (Danish, Dutch, English, and Portuguese). Using a rigorous linear\nmixed-effects regression framework, we compare two families of models: Google's\nGemma models (2B--27B parameters) and successive iterations of OpenAI's\nturbo-series. Across the families of models, we find no consistent\nrelationships between language capabilities and cultural alignment. While the\nGemma models have a positive correlation between language capability and\ncultural alignment across languages, the OpenAI models do not. Importantly, we\nfind that self-consistency is a stronger predictor of multicultural alignment\nthan multilingual capabilities. Our results demonstrate that achieving\nmeaningful cultural alignment requires dedicated effort beyond improving\ngeneral language capabilities.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在多语言能力（multilingual capabilities）和文化适应性（cultural alignment）之间的差距，强调了美国中心偏见的问题。研究者提出了一种新方法，通过比较LLMs生成的响应分布与世界价值观调查（World Value Survey）的人口意见数据，涉及四种语言（Danish, Dutch, English, and Portuguese），并使用线性混合效应回归（linear mixed-effects regression）框架分析Google的Gemma模型和OpenAI的turbo系列模型。结果显示，多语言能力与文化适应性无一致相关性，Gemma模型显示正相关，而OpenAI模型则不然；此外，一致性（self-consistency）比多语言能力更能预测多文化适应性。总体而言，该研究证明，实现真正文化适应需要超出一般语言能力的额外努力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16534v1",
      "published_date": "2025-02-23 11:02:41 UTC",
      "updated_date": "2025-02-23 11:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:49:04.085806"
    },
    {
      "arxiv_id": "2502.16533v2",
      "title": "A Survey of Graph Transformers: Architectures, Theories and Applications",
      "title_zh": "图 Transformer 的综述：架构、理论和应用",
      "authors": [
        "Chaohao Yuan",
        "Kangfei Zhao",
        "Ercan Engin Kuruoglu",
        "Liang Wang",
        "Tingyang Xu",
        "Wenbing Huang",
        "Deli Zhao",
        "Hong Cheng",
        "Yu Rong"
      ],
      "abstract": "Graph Transformers (GTs) have demonstrated a strong capability in modeling\ngraph structures by addressing the intrinsic limitations of graph neural\nnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies have\nproposed diverse architectures, enhanced explainability, and practical\napplications for Graph Transformers. In light of these rapid developments, we\nconduct a comprehensive review of Graph Transformers, covering aspects such as\ntheir architectures, theoretical foundations, and applications within this\nsurvey. We categorize the architecture of Graph Transformers according to their\nstrategies for processing structural information, including graph tokenization,\npositional encoding, structure-aware attention and model ensemble. Furthermore,\nfrom the theoretical perspective, we examine the expressivity of Graph\nTransformers in various discussed architectures and contrast them with other\nadvanced graph learning algorithms to discover the connections. Furthermore, we\nprovide a summary of the practical applications where Graph Transformers have\nbeen utilized, such as molecule, protein, language, vision, traffic, brain and\nmaterial data. At the end of this survey, we will discuss the current\nchallenges and prospective directions in Graph Transformers for potential\nfuture research.",
      "tldr_zh": "本综述论文系统地审视了 Graph Transformers (GTs)，其通过解决 Graph Neural Networks (GNNs) 的固有问题，如 over-smoothing 和 over-squashing，在图结构建模方面展现出强大能力。论文根据处理结构信息的方法，将 GTs 的架构分为 graph tokenization、positional encoding、structure-aware attention 和 model ensemble 等类别，并从理论视角分析了其 expressivity，与其他图学习算法进行了比较。论文还总结了 GTs 在分子、蛋白质、语言、视觉、交通、脑科学和材料数据等领域的实际应用，最后讨论了当前挑战和潜在未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16533v2",
      "published_date": "2025-02-23 10:55:19 UTC",
      "updated_date": "2025-02-27 06:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:49:17.380053"
    },
    {
      "arxiv_id": "2502.16529v1",
      "title": "Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation",
      "title_zh": "检索增强微调结合偏好优化用于视觉程序生成",
      "authors": [
        "Deokhyung Kang",
        "Jeonghun Cho",
        "Yejin Jeon",
        "Sunbin Jang",
        "Minsub Lee",
        "Jawoon Cho",
        "Gary Geunbae Lee"
      ],
      "abstract": "Visual programming languages (VPLs) allow users to create programs through\ngraphical interfaces, which results in easier accessibility and their\nwidespread usage in various domains. To further enhance this accessibility,\nrecent research has focused on generating VPL code from user instructions using\nlarge language models (LLMs). Specifically, by employing prompting-based\nmethods, these studies have shown promising results. Nevertheless, such\napproaches can be less effective for industrial VPLs such as Ladder Diagram\n(LD). LD is a pivotal language used in industrial automation processes and\ninvolves extensive domain-specific configurations, which are difficult to\ncapture in a single prompt. In this work, we demonstrate that training-based\nmethods outperform prompting-based methods for LD generation accuracy, even\nwith smaller backbone models. Building on these findings, we propose a\ntwo-stage training strategy to further enhance VPL generation. First, we employ\nretrieval-augmented fine-tuning to leverage the repetitive use of subroutines\ncommonly seen in industrial VPLs. Second, we apply direct preference\noptimization (DPO) to further guide the model toward accurate outputs, using\nsystematically generated preference pairs through graph editing operations.\nExtensive experiments on real-world LD data demonstrate that our approach\nimproves program-level accuracy by over 10% compared to supervised fine-tuning,\nwhich highlights its potential to advance industrial automation.",
      "tldr_zh": "本研究针对视觉编程语言 (VPLs) 的生成问题，特别是工业自动化中的 Ladder Diagram (LD)，发现基于提示的方法难以捕捉领域特定配置，从而提出一种基于训练的改进策略。作者采用两阶段方法：首先进行检索增强微调 (retrieval-augmented fine-tuning)，利用工业 VPLs 中的重复子程序来提升模型性能；其次应用直接偏好优化 (DPO)，通过图编辑操作生成偏好对以指导模型输出准确性。在真实 LD 数据上的广泛实验显示，该方法比监督微调提高了超过 10% 的程序级准确率，为推进工业自动化领域提供了重要潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16529v1",
      "published_date": "2025-02-23 10:27:44 UTC",
      "updated_date": "2025-02-23 10:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:49:28.750725"
    },
    {
      "arxiv_id": "2502.16523v1",
      "title": "Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension",
      "title_zh": "关注真实世界的扰动！机器阅读理解中的自然鲁棒性评估",
      "authors": [
        "Yulong Wu",
        "Viktor Schlegel",
        "Riza Batista-Navarro"
      ],
      "abstract": "As neural language models achieve human-comparable performance on Machine\nReading Comprehension (MRC) and see widespread adoption, ensuring their\nrobustness in real-world scenarios has become increasingly important. Current\nrobustness evaluation research, though, primarily develops synthetic\nperturbation methods, leaving unclear how well they reflect real life\nscenarios. Considering this, we present a framework to automatically examine\nMRC models on naturally occurring textual perturbations, by replacing paragraph\nin MRC benchmarks with their counterparts based on available Wikipedia edit\nhistory. Such perturbation type is natural as its design does not stem from an\narteficial generative process, inherently distinct from the previously\ninvestigated synthetic approaches. In a large-scale study encompassing SQUAD\ndatasets and various model architectures we observe that natural perturbations\nresult in performance degradation in pre-trained encoder language models. More\nworryingly, these state-of-the-art Flan-T5 and Large Language Models (LLMs)\ninherit these errors. Further experiments demonstrate that our findings\ngeneralise to natural perturbations found in other more challenging MRC\nbenchmarks. In an effort to mitigate these errors, we show that it is possible\nto improve the robustness to natural perturbations by training on naturally or\nsynthetically perturbed examples, though a noticeable gap still remains\ncompared to performance on unperturbed data.",
      "tldr_zh": "本研究强调了机器阅读理解(MRC)模型在真实世界文本扰动下的鲁棒性问题，提出一个框架使用Wikipedia编辑历史自动替换MRC基准中的段落，以模拟自然发生的扰动。实验结果显示，在SQUAD数据集和各种模型架构上，包括预训练编码器语言模型(Flan-T5和Large Language Models)均出现性能下降。进一步验证表明，这种现象在其他更具挑战性的MRC基准中也普遍存在，通过在自然或合成扰动数据上训练可以部分缓解错误，但与未扰动数据相比仍存在显著差距。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16523v1",
      "published_date": "2025-02-23 10:04:21 UTC",
      "updated_date": "2025-02-23 10:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:49:39.579426"
    },
    {
      "arxiv_id": "2502.16520v2",
      "title": "Predicting Bad Goods Risk Scores with ARIMA Time Series: A Novel Risk Assessment Approach",
      "title_zh": "使用 ARIMA 时间序列预测坏货风险分数：一种新颖的风险评估方法",
      "authors": [
        "Bishwajit Prasad Gond"
      ],
      "abstract": "The increasing complexity of supply chains and the rising costs associated\nwith defective or substandard goods (bad goods) highlight the urgent need for\nadvanced predictive methodologies to mitigate risks and enhance operational\nefficiency. This research presents a novel framework that integrates Time\nSeries ARIMA (AutoRegressive Integrated Moving Average) models with a\nproprietary formula specifically designed to calculate bad goods after time\nseries forecasting. By leveraging historical data patterns, including sales,\nreturns, and capacity, the model forecasts potential quality failures, enabling\nproactive decision-making. ARIMA is employed to capture temporal trends in time\nseries data, while the newly developed formula quantifies the likelihood and\nimpact of defects with greater precision. Experimental results, validated on a\ndataset spanning 2022-2024 for Organic Beer-G 1 Liter, demonstrate that the\nproposed method outperforms traditional statistical models, such as Exponential\nSmoothing and Holt-Winters, in both prediction accuracy and risk evaluation.\nThis study advances the field of predictive analytics by bridging time series\nforecasting, ARIMA, and risk management in supply chain quality control,\noffering a scalable and practical solution for minimizing losses due to bad\ngoods.",
      "tldr_zh": "本研究提出了一种新颖的风险评估框架，使用ARIMA（AutoRegressive Integrated Moving Average）时间序列模型结合专有公式，来预测供应链中次品（bad goods）的风险分数。该方法利用历史数据（如销售、退货和产能）的时序趋势进行预测，并通过新公式精确量化缺陷的可能性和影响。实验在2022-2024年Organic Beer-G 1 Liter数据集上验证，显示该框架在预测准确性和风险评估方面优于传统模型如Exponential Smoothing和Holt-Winters。整体而言，此研究桥接了时间序列预测、ARIMA和风险管理，提供了一个可扩展的解决方案，以提升供应链质量控制并减少损失。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16520v2",
      "published_date": "2025-02-23 09:52:11 UTC",
      "updated_date": "2025-02-25 11:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:49:50.796281"
    },
    {
      "arxiv_id": "2502.16510v1",
      "title": "Gaussian Process Regression for Improved Underwater Navigation",
      "title_zh": "高斯过程回归用于改进水下导航",
      "authors": [
        "Nadav Cohen",
        "Itzik Klein"
      ],
      "abstract": "Accurate underwater navigation is a challenging task due to the absence of\nglobal navigation satellite system signals and the reliance on inertial\nnavigation systems that suffer from drift over time. Doppler velocity logs\n(DVLs) are typically used to mitigate this drift through velocity measurements,\nwhich are commonly estimated using a parameter estimation approach such as\nleast squares (LS). However, LS works under the assumption of ideal conditions\nand does not account for sensor biases, leading to suboptimal performance. This\npaper proposes a data-driven alternative based on multi-output Gaussian process\nregression (MOGPR) to improve DVL velocity estimation. MOGPR provides velocity\nestimates and associated measurement covariances, enabling an adaptive\nintegration within an error-state Extended Kalman Filter (EKF). We evaluate our\nproposed approach using real-world AUV data and compare it against LS and a\nstate-of-the-art deep learning model, BeamsNet. Results demonstrate that MOGPR\nreduces velocity estimation errors by approximately 20% while simultaneously\nenhancing overall navigation accuracy, particularly in the orientation states.\nAdditionally, the incorporation of uncertainty estimates from MOGPR enables an\nadaptive EKF framework, improving navigation robustness in dynamic underwater\nenvironments.",
      "tldr_zh": "本研究针对水下导航的挑战，指出传统依赖惯性导航系统（INS）和Doppler Velocity Logs (DVLs)的最小二乘（LS）方法因忽略传感器偏差而导致漂移和性能不佳。论文提出一种基于多输出高斯过程回归（MOGPR）的数据驱动方法，用于改进DVL速度估计，并提供测量协方差以实现与错误状态扩展卡尔曼滤波器（EKF）的自适应整合。实验结果显示，MOGPR相较于LS和BeamsNet减少了约20%的速度估计错误，提升了整体导航准确性，尤其在方向状态，并增强了动态水下环境的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16510v1",
      "published_date": "2025-02-23 09:13:41 UTC",
      "updated_date": "2025-02-23 09:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:50:04.944557"
    },
    {
      "arxiv_id": "2502.16503v1",
      "title": "FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis",
      "title_zh": "FanChuan：多语言和图结构化基准，用于模仿检测和分析",
      "authors": [
        "Yilun Zheng",
        "Sha Li",
        "Fangkun Wu",
        "Yang Ziyi",
        "Lin Hongchao",
        "Zhichao Hu",
        "Cai Xinjun",
        "Ziming Wang",
        "Jinxuan Chen",
        "Sitao Luan",
        "Jiahao Xu",
        "Lihui Chen"
      ],
      "abstract": "Parody is an emerging phenomenon on social media, where individuals imitate a\nrole or position opposite to their own, often for humor, provocation, or\ncontroversy. Detecting and analyzing parody can be challenging and is often\nreliant on context, yet it plays a crucial role in understanding cultural\nvalues, promoting subcultures, and enhancing self-expression. However, the\nstudy of parody is hindered by limited available data and deficient diversity\nin current datasets. To bridge this gap, we built seven parody datasets from\nboth English and Chinese corpora, with 14,755 annotated users and 21,210\nannotated comments in total. To provide sufficient context information, we also\ncollect replies and construct user-interaction graphs to provide richer\ncontextual information, which is lacking in existing datasets. With these\ndatasets, we test traditional methods and Large Language Models (LLMs) on three\nkey tasks: (1) parody detection, (2) comment sentiment analysis with parody,\nand (3) user sentiment analysis with parody. Our extensive experiments reveal\nthat parody-related tasks still remain challenging for all models, and\ncontextual information plays a critical role. Interestingly, we find that, in\ncertain scenarios, traditional sentence embedding methods combined with simple\nclassifiers can outperform advanced LLMs, i.e. DeepSeek-R1 and GPT-o3,\nhighlighting parody as a significant challenge for LLMs.",
      "tldr_zh": "本研究引入了FanChuan，一个多语言且基于图结构的基准数据集，用于parody（模仿现象）检测和分析，以解决现有数据集的多样性和上下文不足问题。该基准包括七个数据集，涵盖英语和中文语料，总计14,755个标注用户和21,210个标注评论，并通过收集回复和构建用户互动图提供更丰富的上下文信息。研究评估了传统方法和Large Language Models (LLMs) 在三个关键任务上的性能：parody检测、带有parody的评论情感分析，以及带有parody的用户情感分析，结果显示这些任务对模型仍具挑战，上下文信息至关重要，且在某些场景下，传统句子嵌入方法结合简单分类器可优于先进的LLMs如DeepSeek-R1和GPT-3。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16503v1",
      "published_date": "2025-02-23 08:52:46 UTC",
      "updated_date": "2025-02-23 08:52:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:50:17.343408"
    },
    {
      "arxiv_id": "2502.16496v1",
      "title": "PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning",
      "title_zh": "PMAT：在多智能体强化学习中优化动作生成顺序",
      "authors": [
        "Kun Hu",
        "Muning Wen",
        "Xihuai Wang",
        "Shao Zhang",
        "Yiwei Shi",
        "Minne Li",
        "Minglong Li",
        "Ying Wen"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) faces challenges in coordinating\nagents due to complex interdependencies within multi-agent systems. Most MARL\nalgorithms use the simultaneous decision-making paradigm but ignore the\naction-level dependencies among agents, which reduces coordination efficiency.\nIn contrast, the sequential decision-making paradigm provides finer-grained\nsupervision for agent decision order, presenting the potential for handling\ndependencies via better decision order management. However, determining the\noptimal decision order remains a challenge. In this paper, we introduce Action\nGeneration with Plackett-Luce Sampling (AGPS), a novel mechanism for agent\ndecision order optimization. We model the order determination task as a\nPlackett-Luce sampling process to address issues such as ranking instability\nand vanishing gradient during the network training process. AGPS realizes\ncredit-based decision order determination by establishing a bridge between the\nsignificance of agents' local observations and their decision credits, thus\nfacilitating order optimization and dependency management. Integrating AGPS\nwith the Multi-Agent Transformer, we propose the Prioritized Multi-Agent\nTransformer (PMAT), a sequential decision-making MARL algorithm with decision\norder optimization. Experiments on benchmarks including StarCraft II\nMulti-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show\nthat PMAT outperforms state-of-the-art algorithms, greatly enhancing\ncoordination efficiency.",
      "tldr_zh": "该论文针对多智能体强化学习 (MARL) 中的行动级依赖性问题，提出优化代理决策顺序的方法，以提升协调效率。作者引入了 Action Generation with Plackett-Luce Sampling (AGPS) 机制，将决策顺序建模为 Plackett-Luce 采样过程，解决排名不稳定和梯度消失问题，并通过代理本地观察的重要性来确定决策信用。基于此，他们开发了 Prioritized Multi-Agent Transformer (PMAT)，一个集成了 AGPS 的顺序决策 MARL 算法。实验结果显示，PMAT 在 StarCraft II Multi-Agent Challenge、Google Research Football 和 Multi-Agent MuJoCo 等基准上，超过了最先进算法，大大提高了代理协调效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.16496v1",
      "published_date": "2025-02-23 08:30:14 UTC",
      "updated_date": "2025-02-23 08:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:50:29.352138"
    },
    {
      "arxiv_id": "2502.17521v1",
      "title": "Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Simin Chen",
        "Yiming Chen",
        "Zexin Li",
        "Yifan Jiang",
        "Zhongwei Wan",
        "Yixin He",
        "Dezhi Ran",
        "Tianle Gu",
        "Haizhou Li",
        "Tao Xie",
        "Baishakhi Ray"
      ],
      "abstract": "Data contamination has received increasing attention in the era of large\nlanguage models (LLMs) due to their reliance on vast Internet-derived training\ncorpora. To mitigate the risk of potential data contamination, LLM benchmarking\nhas undergone a transformation from static to dynamic benchmarking. In this\nwork, we conduct an in-depth analysis of existing static to dynamic\nbenchmarking methods aimed at reducing data contamination risks. We first\nexamine methods that enhance static benchmarks and identify their inherent\nlimitations. We then highlight a critical gap-the lack of standardized criteria\nfor evaluating dynamic benchmarks. Based on this observation, we propose a\nseries of optimal design principles for dynamic benchmarking and analyze the\nlimitations of existing dynamic benchmarks. This survey provides a concise yet\ncomprehensive overview of recent advancements in data contamination research,\noffering valuable insights and a clear guide for future research efforts. We\nmaintain a GitHub repository to continuously collect both static and dynamic\nbenchmarking methods for LLMs. The repository can be found at this link.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)中数据污染(data contamination)问题的最新进展，强调基准测试从静态到动态的转变，以降低训练数据风险。作者分析了现有静态基准的增强方法及其固有局限性，并首次提出动态基准的标准化设计原则，包括评估标准和潜在不足。总体上，该研究提供了数据污染研究的简明概述和未来指导，并维护了一个GitHub仓库收集相关基准方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Github Link:\n  https://github.com/SeekingDream/Static-to-Dynamic-LLMEval",
      "pdf_url": "http://arxiv.org/pdf/2502.17521v1",
      "published_date": "2025-02-23 08:18:37 UTC",
      "updated_date": "2025-02-23 08:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:50:40.506107"
    },
    {
      "arxiv_id": "2502.16490v1",
      "title": "On Computational Limits of FlowAR Models: Expressivity and Efficiency",
      "title_zh": "关于 FlowAR 模型的计算极限：表达性和效率",
      "authors": [
        "Chengyue Gong",
        "Yekun Ke",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhizhou Sha",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "The expressive power and computational complexity of deep visual generative\nmodels, such as flow-based and autoregressive (AR) models, have gained\nconsiderable interest for their wide-ranging applications in generative tasks.\nHowever, the theoretical characterization of their expressiveness through the\nlens of circuit complexity remains underexplored, particularly for the\nstate-of-the-art architecture like FlowAR proposed by [Ren et al., 2024], which\nintegrates flow-based and autoregressive mechanisms. This gap limits our\nunderstanding of their inherent computational limits and practical efficiency.\nIn this study, we address this gap by analyzing the circuit complexity of the\nFlowAR architecture. We demonstrate that when the largest feature map produced\nby the FlowAR model has dimensions $n \\times n \\times c$, the FlowAR model is\nsimulable by a family of threshold circuits $\\mathsf{TC}^0$, which have\nconstant depth $O(1)$ and polynomial width $\\mathrm{poly}(n)$. This is the\nfirst study to rigorously highlight the limitations in the expressive power of\nFlowAR models. Furthermore, we identify the conditions under which the FlowAR\nmodel computations can achieve almost quadratic time. To validate our\ntheoretical findings, we present efficient model variant constructions based on\nlow-rank approximations that align with the derived criteria. Our work provides\na foundation for future comparisons with other generative paradigms and guides\nthe development of more efficient and expressive implementations.",
      "tldr_zh": "这篇论文探讨了 FlowAR 模型的表达能力和计算效率，分析了深度视觉生成模型（如基于流的和自回归模型）的电路复杂性。研究证明，当 FlowAR 模型的特征图尺寸为 $n \\times n \\times c$ 时，它可以用阈值电路 $\\mathsf{TC}^0$ 模拟，这些电路具有常量深度 $O(1)$ 和多项式宽度 $\\mathrm{poly}(n)$，从而首次严格突显了 FlowAR 模型的表达能力限制。此外，论文识别了 FlowAR 计算几乎达到二次时间的条件，并通过低秩逼近构建高效模型变体，以验证理论发现。该工作为与其他生成范式的比较和更高效实现的开发奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16490v1",
      "published_date": "2025-02-23 08:07:35 UTC",
      "updated_date": "2025-02-23 08:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:50:54.211532"
    },
    {
      "arxiv_id": "2502.16483v1",
      "title": "A Split-Window Transformer for Multi-Model Sequence Spammer Detection using Multi-Model Variational Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Zhou Yang",
        "Yucai Pang",
        "Hongbo Yin",
        "Yunpeng Xiao"
      ],
      "abstract": "This paper introduces a new Transformer, called MS$^2$Dformer, that can be\nused as a generalized backbone for multi-modal sequence spammer detection.\nSpammer detection is a complex multi-modal task, thus the challenges of\napplying Transformer are two-fold. Firstly, complex multi-modal noisy\ninformation about users can interfere with feature mining. Secondly, the long\nsequence of users' historical behaviors also puts a huge GPU memory pressure on\nthe attention computation. To solve these problems, we first design a user\nbehavior Tokenization algorithm based on the multi-modal variational\nautoencoder (MVAE). Subsequently, a hierarchical split-window multi-head\nattention (SW/W-MHA) mechanism is proposed. The split-window strategy\ntransforms the ultra-long sequences hierarchically into a combination of\nintra-window short-term and inter-window overall attention. Pre-trained on the\npublic datasets, MS$^2$Dformer's performance far exceeds the previous state of\nthe art. The experiments demonstrate MS$^2$Dformer's ability to act as a\nbackbone.",
      "tldr_zh": "本研究提出了一种新的 Transformer 模型 MS²Dformer，作为多模态序列垃圾邮件检测的通用骨干网络，旨在解决多模态噪声信息干扰特征挖掘以及用户历史行为超长序列导致的 GPU 内存压力问题。研究首先设计了基于多模态变分自编码器 (MVAE) 的用户行为 Tokenization 算法，以有效提取和处理多模态数据。随后，引入了分层分裂窗口多头注意力 (SW/W-MHA) 机制，将超长序列层次化转化为窗口内短时注意力和窗口间整体注意力。实验结果显示，在公开数据集上预训练后，MS²Dformer 的性能远超现有最先进方法，并证明其作为骨干网络的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16483v1",
      "published_date": "2025-02-23 07:53:08 UTC",
      "updated_date": "2025-02-23 07:53:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:51:04.486108"
    },
    {
      "arxiv_id": "2502.16477v1",
      "title": "Unmasking Societal Biases in Respiratory Support for ICU Patients through Social Determinants of Health",
      "title_zh": "翻译失败",
      "authors": [
        "Mira Moukheiber",
        "Lama Moukheiber",
        "Dana Moukheiber",
        "Hyung-Chul Lee"
      ],
      "abstract": "In critical care settings, where precise and timely interventions are crucial\nfor health outcomes, evaluating disparities in patient outcomes is essential.\nCurrent approaches often fail to fully capture the impact of respiratory\nsupport interventions on individuals affected by social determinants of health.\nWhile attributes such as gender, race, and age are commonly assessed and\nprovide valuable insights, they offer only a partial view of the complexities\nfaced by diverse populations. In this study, we focus on two clinically\nmotivated tasks: prolonged mechanical ventilation and successful weaning.\nAdditionally, we conduct fairness audits on the models' predictions across\ndemographic groups and social determinants of health to better understand\nhealth inequities in respiratory interventions within the intensive care unit.\nFurthermore, we release a temporal benchmark dataset, verified by clinical\nexperts, to facilitate benchmarking of clinical respiratory intervention tasks.",
      "tldr_zh": "这篇论文探讨了社会决定因素（Social Determinants of Health）对 ICU 患者呼吸支持的影响，揭示了现有方法在评估健康不平等方面的局限性，如仅依赖性别、种族和年龄等属性。研究聚焦于两个临床任务：延长机械通气（prolonged mechanical ventilation）和成功撤机（successful weaning），并通过公平性审计（fairness audits）分析模型预测在不同人口群体中的偏差，以更好地理解呼吸干预中的不平等。最终，论文发布了一个由临床专家验证的时间基准数据集，用于促进相关任务的基准测试和未来研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16477v1",
      "published_date": "2025-02-23 07:23:15 UTC",
      "updated_date": "2025-02-23 07:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:51:17.444285"
    },
    {
      "arxiv_id": "2502.16475v1",
      "title": "Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control",
      "title_zh": "Dragen3D：多视图几何一致的 3D 高斯生成，带有基于拖拽的控制",
      "authors": [
        "Jinbo Yan",
        "Alan Zhao",
        "Yixin Hu"
      ],
      "abstract": "Single-image 3D generation has emerged as a prominent research topic, playing\na vital role in virtual reality, 3D modeling, and digital content creation.\nHowever, existing methods face challenges such as a lack of multi-view\ngeometric consistency and limited controllability during the generation\nprocess, which significantly restrict their usability. % To tackle these\nchallenges, we introduce Dragen3D, a novel approach that achieves geometrically\nconsistent and controllable 3D generation leveraging 3D Gaussian Splatting\n(3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GS\nVAE), which encodes a point cloud and a single image into anchor latents and\ndecode these latents into 3DGS, enabling efficient latent-space generation. To\nenable multi-view geometry consistent and controllable generation, we propose a\nSeed-Point-Driven strategy: first generate sparse seed points as a coarse\ngeometry representation, then map them to anchor latents via the Seed-Anchor\nMapping Module. Geometric consistency is ensured by the easily learned sparse\nseed points, and users can intuitively drag the seed points to deform the final\n3DGS geometry, with changes propagated through the anchor latents. To the best\nof our knowledge, we are the first to achieve geometrically controllable 3D\nGaussian generation and editing without relying on 2D diffusion priors,\ndelivering comparable 3D generation quality to state-of-the-art methods.",
      "tldr_zh": "该论文提出Dragen3D，一种基于3D Gaussian Splatting (3DGS)的创新方法，用于实现单图像的多视图几何一致3D生成，同时提供拖拽式控制。核心技术包括Anchor-Gaussian Variational Autoencoder (Anchor-GS VAE)，它将点云和单图像编码为锚点潜在变量，并解码为3DGS模型。论文引入Seed-Point-Driven策略，通过生成稀疏种子点作为粗糙几何表示，并利用Seed-Anchor Mapping Module确保几何一致性，用户可直观拖拽种子点来变形最终3DGS几何。实验结果显示，Dragen3D无需依赖2D扩散先验，即可实现可控的3D生成和编辑，其质量与最先进方法相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16475v1",
      "published_date": "2025-02-23 07:19:03 UTC",
      "updated_date": "2025-02-23 07:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:51:29.241138"
    },
    {
      "arxiv_id": "2502.18519v1",
      "title": "FreeTumor: Large-Scale Generative Tumor Synthesis in Computed Tomography Images for Improving Tumor Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Linshan Wu",
        "Jiaxin Zhuang",
        "Yanning Zhou",
        "Sunan He",
        "Jiabo Ma",
        "Luyang Luo",
        "Xi Wang",
        "Xuefeng Ni",
        "Xiaoling Zhong",
        "Mingxiang Wu",
        "Yinghua Zhao",
        "Xiaohui Duan",
        "Varut Vardhanabhuti",
        "Pranav Rajpurkar",
        "Hao Chen"
      ],
      "abstract": "Tumor is a leading cause of death worldwide, with an estimated 10 million\ndeaths attributed to tumor-related diseases every year. AI-driven tumor\nrecognition unlocks new possibilities for more precise and intelligent tumor\nscreening and diagnosis. However, the progress is heavily hampered by the\nscarcity of annotated datasets, which demands extensive annotation efforts by\nradiologists. To tackle this challenge, we introduce FreeTumor, an innovative\nGenerative AI (GAI) framework to enable large-scale tumor synthesis for\nmitigating data scarcity. Specifically, FreeTumor effectively leverages a\ncombination of limited labeled data and large-scale unlabeled data for tumor\nsynthesis training. Unleashing the power of large-scale data, FreeTumor is\ncapable of synthesizing a large number of realistic tumors on images for\naugmenting training datasets. To this end, we create the largest training\ndataset for tumor synthesis and recognition by curating 161,310 publicly\navailable Computed Tomography (CT) volumes from 33 sources, with only 2.3%\ncontaining annotated tumors. To validate the fidelity of synthetic tumors, we\nengaged 13 board-certified radiologists in a Visual Turing Test to discern\nbetween synthetic and real tumors. Rigorous clinician evaluation validates the\nhigh quality of our synthetic tumors, as they achieved only 51.1% sensitivity\nand 60.8% accuracy in distinguishing our synthetic tumors from real ones.\nThrough high-quality tumor synthesis, FreeTumor scales up the recognition\ntraining datasets by over 40 times, showcasing a notable superiority over\nstate-of-the-art AI methods including various synthesis methods and foundation\nmodels. These findings indicate promising prospects of FreeTumor in clinical\napplications, potentially advancing tumor treatments and improving the survival\nrates of patients.",
      "tldr_zh": "该研究提出FreeTumor，一种创新的Generative AI框架，用于在Computed Tomography (CT)图像中进行大规模肿瘤合成，以缓解肿瘤识别训练数据稀缺的问题。FreeTumor通过结合有限的标注数据和大量未标注数据（共计161,310个CT卷，仅2.3%有标注），生成高质量的合成肿瘤图像，从而将识别训练数据集扩大40倍以上。经13名放射科医生进行的Visual Turing Test评估显示，合成肿瘤的区分准确率仅为60.8%，证明其真实性高，并优于现有AI方法。最终结果表明，FreeTumor显著提升了肿瘤识别性能，具有广阔的临床应用前景，可改善肿瘤筛查和患者生存率。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18519v1",
      "published_date": "2025-02-23 07:00:09 UTC",
      "updated_date": "2025-02-23 07:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:51:42.119798"
    },
    {
      "arxiv_id": "2502.16469v1",
      "title": "Cross-domain Few-shot Object Detection with Multi-modal Textual Enrichment",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Shangguan",
        "Daniel Seita",
        "Mohammad Rostami"
      ],
      "abstract": "Advancements in cross-modal feature extraction and integration have\nsignificantly enhanced performance in few-shot learning tasks. However, current\nmulti-modal object detection (MM-OD) methods often experience notable\nperformance degradation when encountering substantial domain shifts. We propose\nthat incorporating rich textual information can enable the model to establish a\nmore robust knowledge relationship between visual instances and their\ncorresponding language descriptions, thereby mitigating the challenges of\ndomain shift. Specifically, we focus on the problem of Cross-Domain Multi-Modal\nFew-Shot Object Detection (CDMM-FSOD) and introduce a meta-learning-based\nframework designed to leverage rich textual semantics as an auxiliary modality\nto achieve effective domain adaptation. Our new architecture incorporates two\nkey components: (i) A multi-modal feature aggregation module, which aligns\nvisual and linguistic feature embeddings to ensure cohesive integration across\nmodalities. (ii) A rich text semantic rectification module, which employs\nbidirectional text feature generation to refine multi-modal feature alignment,\nthereby enhancing understanding of language and its application in object\ndetection. We evaluate the proposed method on common cross-domain object\ndetection benchmarks and demonstrate that it significantly surpasses existing\nfew-shot object detection approaches.",
      "tldr_zh": "这篇论文针对跨领域 few-shot object detection 的挑战，提出了一种基于 meta-learning 的框架，通过整合多模态文本信息来缓解领域偏移问题。具体方法包括多模态特征聚合模块（用于对齐视觉和语言特征嵌入）和丰富的文本语义修正模块（通过双向文本特征生成来优化多模态对齐）。实验结果显示，该方法在常见跨领域物体检测基准上显著超过了现有 few-shot object detection 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2403.16188",
      "pdf_url": "http://arxiv.org/pdf/2502.16469v1",
      "published_date": "2025-02-23 06:59:22 UTC",
      "updated_date": "2025-02-23 06:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:51:53.236953"
    },
    {
      "arxiv_id": "2502.18518v1",
      "title": "Swallowing the Poison Pills: Insights from Vulnerability Disparity Among LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Yifeng",
        "Wu Zhizheng",
        "Chen Chen"
      ],
      "abstract": "Modern large language models (LLMs) exhibit critical vulnerabilities to\npoison pill attacks: localized data poisoning that alters specific factual\nknowledge while preserving overall model utility. We systematically demonstrate\nthese attacks exploit inherent architectural properties of LLMs, achieving\n54.6% increased retrieval inaccuracy on long-tail knowledge versus dominant\ntopics and up to 25.5% increase retrieval inaccuracy on compressed models\nversus original architectures. Through controlled mutations (e.g.,\ntemporal/spatial/entity alterations) and, our method induces localized\nmemorization deterioration with negligible impact on models' performance on\nregular standard benchmarks (e.g., <2% performance drop on MMLU/GPQA), leading\nto potential detection evasion. Our findings suggest: (1) Disproportionate\nvulnerability in long-tail knowledge may result from reduced parameter\nredundancy; (2) Model compression may increase attack surfaces, with\npruned/distilled models requiring 30% fewer poison samples for equivalent\ndamage; (3) Associative memory enables both spread of collateral damage to\nrelated concepts and amplification of damage from simultaneous attack,\nparticularly for dominant topics. These findings raise concerns over current\nscaling paradigms since attack costs are lowering while defense complexity is\nrising. Our work establishes poison pills as both a security threat and\ndiagnostic tool, revealing critical security-efficiency trade-offs in language\nmodel compression that challenges prevailing safety assumptions.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）对poison pill attacks的脆弱性，这些攻击通过局部数据中毒来改变特定事实知识，同时保持模型整体性能（如在MMLU和GPQA基准测试中性能下降不到2%）。研究者通过控制变异（如时间/空间/实体改变）的方法，展示了长尾知识的检索不准确率比主导主题高出54.6%，而压缩模型（如修剪或蒸馏模型）比原架构更易受攻击，需要30%更少的poison样本即可造成等效损害。关键发现包括：参数冗余减少导致长尾知识的过度脆弱性，以及关联记忆可能放大损害并扩散到相关概念，这突显了模型压缩的安全性权衡，并将poison pill视为一种潜在的安全威胁和诊断工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18518v1",
      "published_date": "2025-02-23 06:34:55 UTC",
      "updated_date": "2025-02-23 06:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:52:06.346221"
    },
    {
      "arxiv_id": "2502.16459v1",
      "title": "Deep learning approaches to surgical video segmentation and object detection: A Scoping Review",
      "title_zh": "深度学习在手术视频分割和物体检测中的方法：一项范围综述",
      "authors": [
        "Devanish N. Kamtam",
        "Joseph B. Shrager",
        "Satya Deepya Malla",
        "Nicole Lin",
        "Juan J. Cardona",
        "Jake J. Kim",
        "Clarence Hu"
      ],
      "abstract": "Introduction: Computer vision (CV) has had a transformative impact in\nbiomedical fields such as radiology, dermatology, and pathology. Its real-world\nadoption in surgical applications, however, remains limited. We review the\ncurrent state-of-the-art performance of deep learning (DL)-based CV models for\nsegmentation and object detection of anatomical structures in videos obtained\nduring surgical procedures.\n  Methods: We conducted a scoping review of studies on semantic segmentation\nand object detection of anatomical structures published between 2014 and 2024\nfrom 3 major databases - PubMed, Embase, and IEEE Xplore. The primary objective\nwas to evaluate the state-of-the-art performance of semantic segmentation in\nsurgical videos. Secondary objectives included examining DL models, progress\ntoward clinical applications, and the specific challenges with segmentation of\norgans/tissues in surgical videos.\n  Results: We identified 58 relevant published studies. These focused\npredominantly on procedures from general surgery [20(34.4%)], colorectal\nsurgery [9(15.5%)], and neurosurgery [8(13.8%)]. Cholecystectomy [14(24.1%)]\nand low anterior rectal resection [5(8.6%)] were the most common procedures\naddressed. Semantic segmentation [47(81%)] was the primary CV task. U-Net\n[14(24.1%)] and DeepLab [13(22.4%)] were the most widely used models. Larger\norgans such as the liver (Dice score: 0.88) had higher accuracy compared to\nsmaller structures such as nerves (Dice score: 0.49). Models demonstrated\nreal-time inference potential ranging from 5-298 frames-per-second (fps).\n  Conclusion: This review highlights the significant progress made in DL-based\nsemantic segmentation for surgical videos with real-time applicability,\nparticularly for larger organs. Addressing challenges with smaller structures,\ndata availability, and generalizability remains crucial for future\nadvancements.",
      "tldr_zh": "这篇综述论文回顾了2014-2024年间使用深度学习（DL）模型进行手术视频中解剖结构语义分割（semantic segmentation）和物体检测（object detection）的现状，分析了58个相关研究，主要聚焦于一般外科、结直肠外科和神经外科等程序。研究发现，U-Net和DeepLab是最常用的模型，较大器官如肝脏的分割准确率较高（Dice score: 0.88），而较小结构如神经的准确率较低（Dice score: 0.49），且模型支持实时推理（5-298 fps）。总体而言，论文突出了DL在手术视频分析的进展，但强调需解决数据可用性、泛化性和小结构挑战，以推动临床应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "38 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16459v1",
      "published_date": "2025-02-23 06:31:23 UTC",
      "updated_date": "2025-02-23 06:31:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:52:19.964985"
    },
    {
      "arxiv_id": "2502.16449v1",
      "title": "Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Su"
      ],
      "abstract": "Emergency Response Time (ERT) is crucial for urban safety, measuring cities'\nability to handle medical, fire, and crime emergencies. In NYC, medical ERT\nincreased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of\ndelays due to Emergency Vehicle (EMV) travel times. Each minute's delay in\nstroke response costs 2 million brain cells, while cardiac arrest survival\ndrops 7-10% per minute.\n  This dissertation advances EMV facilitation through three contributions.\nFirst, EMVLight, a decentralized multi-agent reinforcement learning framework,\nintegrates EMV routing with traffic signal pre-emption. It achieved 42.6%\nfaster EMV travel times and 23.5% improvement for other vehicles.\n  Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy\nOptimization for coordinated lane-clearing in mixed autonomous and human-driven\ntraffic, reducing EMV travel times by 40%.\n  Third, an equity study of NYC Emergency Medical Services revealed disparities\nacross boroughs: Staten Island faces delays due to sparse signalized\nintersections, while Manhattan struggles with congestion. Solutions include\noptimized EMS stations and improved intersection designs.\n  These contributions enhance EMV mobility and emergency service equity,\noffering insights for policymakers and urban planners to develop safer, more\nefficient transportation systems.",
      "tldr_zh": "本论文探讨了使用多智能体深度强化学习（Multi-agent Deep Reinforcement Learning）来改善拥挤城市中紧急车辆（EMV）的通行问题，针对纽约市紧急响应时间（ERT）增加的严峻现实，如医疗ERT从2014年的7.89分钟上升至2024年的14.27分钟。论文的主要贡献包括：第一，提出EMVLight框架，该框架整合EMV路由与交通信号优先处理，通过去中心化多智能体强化学习，实现EMV旅行时间缩短42.6%，其他车辆通行改善23.5%。第二，开发Dynamic Queue-Jump Lane系统，利用Multi-Agent Proximal Policy Optimization协调车道清理，在混合交通环境中减少EMV旅行时间40%。第三，通过对纽约市紧急医疗服务的公平性研究，揭示不同行政区的延迟差异（如斯塔顿岛和曼哈顿的特定挑战），并建议优化EMS站点和交叉路口设计，以提升整体紧急服务公平性和城市交通效率。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Ph.D. dissertation in Transportation Systems",
      "pdf_url": "http://arxiv.org/pdf/2502.16449v1",
      "published_date": "2025-02-23 05:34:32 UTC",
      "updated_date": "2025-02-23 05:34:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:52:30.675473"
    },
    {
      "arxiv_id": "2502.16446v1",
      "title": "Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haocheng Tang",
        "Jing Long",
        "Junmei Wang"
      ],
      "abstract": "In this work, we introduce Auxiliary Discriminator Sequence Generative\nAdversarial Networks (ADSeqGAN), a novel approach for molecular generation in\nsmall-sample datasets. Traditional generative models often struggle with\nlimited training data, particularly in drug discovery, where molecular datasets\nfor specific therapeutic targets, such as nucleic acids binders and central\nnervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by\nintegrating an auxiliary random forest classifier as an additional\ndiscriminator into the GAN framework, significantly improves molecular\ngeneration quality and class specificity.\n  Our method incorporates pretrained generator and Wasserstein distance to\nenhance training stability and diversity. We evaluate ADSeqGAN on a dataset\ncomprising nucleic acid-targeting and protein-targeting small molecules,\ndemonstrating its superior ability to generate nucleic acid binders compared to\nbaseline models such as SeqGAN, ORGAN, and MolGPT. Through an oversampling\nstrategy, ADSeqGAN also significantly improves CNS drug generation, achieving a\nhigher yield than traditional de novo models. Critical assessments, including\ndocking simulations and molecular property analysis, confirm that\nADSeqGAN-generated molecules exhibit strong binding affinities, enhanced\nchemical diversity, and improved synthetic feasibility.\n  Overall, ADSeqGAN presents a novel framework for generative molecular design\nin data-scarce scenarios, offering potential applications in computational drug\ndiscovery. We have demonstrated the successful applications of ADSeqGAN in\ngenerating synthetic nucleic acid-targeting and CNS drugs in this work.",
      "tldr_zh": "本研究提出了一种新方法Auxiliary Discriminator Sequence Generative Adversarial Networks (ADSeqGAN)，用于在小样本数据集上生成分子，特别针对药物发现中数据稀缺的场景，如核酸结合物和中枢神经系统 (CNS) 药物。ADSeqGAN 通过整合辅助随机森林分类器作为额外鉴别器，并结合预训练生成器和Wasserstein distance，提升了训练稳定性和分子生成的质量及类别特异性。在实验中，该方法在核酸靶向小分子数据集上优于SeqGAN、ORGAN和MolGPT等基线模型，并通过过采样策略显著提高了CNS药物的生成效率。生成的分子经对接模拟和分子属性分析验证，展现出强的结合亲和力、增强的化学多样性和更好的合成可行性，为数据稀缺环境下的计算药物发现提供了一个创新框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16446v1",
      "published_date": "2025-02-23 05:22:53 UTC",
      "updated_date": "2025-02-23 05:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:52:41.388656"
    },
    {
      "arxiv_id": "2502.16445v3",
      "title": "Iterative Flow Matching -- Path Correction and Gradual Refinement for Enhanced Generative Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Eldad Haber",
        "Shadab Ahamed",
        "Md. Shahriar Rahim Siddiqui",
        "Niloufar Zakariaei",
        "Moshe Eliasof"
      ],
      "abstract": "Generative models for image generation are now commonly used for a wide\nvariety of applications, ranging from guided image generation for entertainment\nto solving inverse problems. Nonetheless, training a generator is a non-trivial\nfeat that requires fine-tuning and can lead to so-called hallucinations, that\nis, the generation of images that are unrealistic. In this work, we explore\nimage generation using flow matching. We explain and demonstrate why flow\nmatching can generate hallucinations, and propose an iterative process to\nimprove the generation process. Our iterative process can be integrated into\nvirtually $\\textit{any}$ generative modeling technique, thereby enhancing the\nperformance and robustness of image synthesis systems.",
      "tldr_zh": "本论文探讨了生成模型在图像生成中的问题，如幻觉（hallucinations），并提出了一种基于 flow matching 的改进方法。作者解释了 flow matching 可能导致不现实图像生成的原因，并引入迭代过程，包括 path correction 和 gradual refinement，以逐步优化生成路径。该方法可以无缝整合到任何生成建模（generative modeling）技术中，提升图像合成的性能和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16445v3",
      "published_date": "2025-02-23 05:08:06 UTC",
      "updated_date": "2025-03-06 03:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:52:53.926047"
    },
    {
      "arxiv_id": "2503.01858v1",
      "title": "A Review of Artificial Intelligence Impacting Statistical Process Monitoring and Future Directions",
      "title_zh": "人工智能影响统计过程监控的综述及未来方向",
      "authors": [
        "Shing I Chang",
        "Parviz Ghafariasl"
      ],
      "abstract": "It has been 100 years since statistical process control (SPC) or statistical\nprocess monitoring (SPM) was first introduced for production processes and\nlater applied to service, healthcare, and other industries. The techniques\napplied to SPM applications are mostly statistically oriented. Recent advances\nin Artificial Intelligence (AI) have reinvigorated the imagination of adopting\nAI for SPM applications. This manuscript begins with a concise review of the\nhistorical development of the statistically based SPM methods. Next, this\nmanuscript explores AI and Machine Learning (ML) algorithms and methods applied\nin various SPM applications, addressing quality characteristics of univariate,\nmultivariate, profile, and image. These AI methods can be classified into the\nfollowing categories: classification, pattern recognition, time series\napplications, and generative AI. Specifically, different kinds of neural\nnetworks, such as artificial neural networks (ANN), convolutional neural\nnetworks (CNN), recurrent neural networks (RNN), and generative adversarial\nnetworks (GAN), are among the most implemented AI methods impacting SPM.\nFinally, this manuscript outlines a couple of future directions that harness\nthe potential of the Large Multimodal Model (LMM) for advancing SPM research\nand applications in complex systems. The ultimate objective is to transform\nstatistical process monitoring (SPM) into smart process control (SMPC), where\ncorrective actions are autonomously implemented to either prevent quality\nissues or restore process performance.",
      "tldr_zh": "这篇论文回顾了统计过程监测 (SPM) 的历史发展，从统计方法入手，探讨了人工智能 (AI) 和机器学习 (ML) 在处理单变量、多变量、轮廓和图像质量特征方面的应用。AI 方法被分类为分类、模式识别、时间序列应用和生成式 AI，其中人工神经网络 (ANN)、卷积神经网络 (CNN)、循环神经网络 (RNN) 和生成对抗网络 (GAN) 等技术被广泛采用。论文最后提出未来方向，利用大型多模态模型 (LMM) 推进 SPM 研究，并旨在将 SPM 转变为智能过程控制 (SMPC)，实现自主纠正行动以预防或修复质量问题。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "44 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01858v1",
      "published_date": "2025-02-23 04:19:58 UTC",
      "updated_date": "2025-02-23 04:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:53:06.294838"
    },
    {
      "arxiv_id": "2502.17518v1",
      "title": "Ensemble RL through Classifier Models: Enhancing Risk-Return Trade-offs in Trading Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Zheli Xiong"
      ],
      "abstract": "This paper presents a comprehensive study on the use of ensemble\nReinforcement Learning (RL) models in financial trading strategies, leveraging\nclassifier models to enhance performance. By combining RL algorithms such as\nA2C, PPO, and SAC with traditional classifiers like Support Vector Machines\n(SVM), Decision Trees, and Logistic Regression, we investigate how different\nclassifier groups can be integrated to improve risk-return trade-offs. The\nstudy evaluates the effectiveness of various ensemble methods, comparing them\nwith individual RL models across key financial metrics, including Cumulative\nReturns, Sharpe Ratios (SR), Calmar Ratios, and Maximum Drawdown (MDD). Our\nresults demonstrate that ensemble methods consistently outperform base models\nin terms of risk-adjusted returns, providing better management of drawdowns and\noverall stability. However, we identify the sensitivity of ensemble performance\nto the choice of variance threshold {\\tau}, highlighting the importance of\ndynamic {\\tau} adjustment to achieve optimal performance. This study emphasizes\nthe value of combining RL with classifiers for adaptive decision-making, with\nimplications for financial trading, robotics, and other dynamic environments.",
      "tldr_zh": "这篇论文探讨了通过分类器模型增强集成强化学习(Ensemble RL)在金融交易策略中的应用，结合A2C、PPO和SAC等RL算法与SVM、Decision Trees和Logistic Regression等传统分类器，以改善风险-回报权衡。研究通过评估各种集成方法与单个RL模型的比较，发现集成方法在Cumulative Returns、Sharpe Ratios (SR)、Calmar Ratios和Maximum Drawdown (MDD)等方面表现出色，提供更好的风险调整回报和稳定性。论文强调了方差阈值τ对性能的敏感性，并建议动态调整τ，以实现优化效果，这为金融交易、机器人和其他动态环境的自适应决策提供重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "stat.ML",
        "68T42"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages,5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2502.17518v1",
      "published_date": "2025-02-23 04:18:05 UTC",
      "updated_date": "2025-02-23 04:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:53:18.821385"
    },
    {
      "arxiv_id": "2502.16433v1",
      "title": "Sequence-level Large Language Model Training with Contrastive Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili Feng",
        "Dhananjay Ram",
        "Cole Hawkins",
        "Aditya Rawal",
        "Jinman Zhao",
        "Sheng Zha"
      ],
      "abstract": "The next token prediction loss is the dominant self-supervised training\nobjective for large language models and has achieved promising results in a\nvariety of downstream tasks. However, upon closer investigation of this\nobjective, we find that it lacks an understanding of sequence-level signals,\nleading to a mismatch between training and inference processes. To bridge this\ngap, we introduce a contrastive preference optimization (CPO) procedure that\ncan inject sequence-level information into the language model at any training\nstage without expensive human labeled data. Our experiments show that the\nproposed objective surpasses the next token prediction in terms of win rate in\nthe instruction-following and text generation tasks.",
      "tldr_zh": "这项研究发现，大型语言模型（Large Language Models）的传统训练目标 next token prediction loss 缺乏对序列级信号的理解，导致训练和推理过程不匹配。为解决这一问题，研究者引入了 contrastive preference optimization (CPO) 程序，该方法能在任何训练阶段注入序列级信息，而无需昂贵的标注数据。实验结果显示，CPO 在指令遵循和文本生成任务中胜过 next token prediction loss，提高了模型的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16433v1",
      "published_date": "2025-02-23 04:13:27 UTC",
      "updated_date": "2025-02-23 04:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:53:28.734011"
    },
    {
      "arxiv_id": "2502.16428v1",
      "title": "Visual Reasoning Evaluation of Grok, Deepseek Janus, Gemini, Qwen, Mistral, and ChatGPT",
      "title_zh": "Grok、Deepseek Janus、Gemini、Qwen、Mistral 和 ChatGPT 的视觉推理评估",
      "authors": [
        "Nidhal Jegham",
        "Marwan Abdelatti",
        "Abdeltawab Hendawi"
      ],
      "abstract": "Traditional evaluations of multimodal large language models (LLMs) have been\nlimited by their focus on single-image reasoning, failing to assess crucial\naspects like contextual understanding, reasoning stability, and uncertainty\ncalibration. This study addresses these limitations by introducing a novel\nbenchmark that integrates multi-image reasoning tasks with rejection-based\nevaluation and positional bias detection. To evaluate these dimensions, we\nfurther introduce entropy as a novel metric for quantifying reasoning\nconsistency across reordered answer variants. We applied this benchmark to\nassess Grok 3, ChatGPT-4o, ChatGPT-o1, Gemini 2.0 Flash Experimental, DeepSeek\nJanus models, Qwen2.5-VL-72B-Instruct, QVQ-72B-Preview, and Pixtral 12B across\neight visual reasoning tasks, including difference spotting and diagram\ninterpretation. Our findings reveal ChatGPT-o1 leading in overall accuracy\n(82.5\\%) and rejection accuracy (70.0\\%), closely followed by Gemini 2.0 Flash\nExperimental (70.8\\%). QVQ-72B-Preview demonstrated superior rejection accuracy\n(85.5\\%). Notably, Pixtral 12B (51.7\\%) showed promise in specific domains,\nwhile Janus models exhibited challenges in bias and uncertainty calibration,\nreflected in low rejection accuracies and high entropy scores. High entropy\nscores in Janus models (Janus 7B: 0.8392, Janus 1B: 0.787) underscore their\nsusceptibility to positional bias and unstable reasoning, contrasting with the\nlow entropy and robust reasoning of ChatGPT models. The study further\ndemonstrates that model size is not the sole determinant of performance, as\nevidenced by Grok 3 underperformance despite its substantial parameter count.\nBy employing multi-image contexts, rejection mechanisms, and entropy-based\nconsistency metrics, this benchmark sets a new standard for evaluating\nmultimodal LLMs, enabling a more robust and reliable assessment of\nnext-generation AI systems.",
      "tldr_zh": "这篇论文针对多模态大型语言模型(multimodal LLMs)的传统评估局限性（如单图像推理），引入了一个新基准，整合多图像推理任务、基于拒绝的评估(rejection-based evaluation)和位置偏差检测，以评估上下文理解、推理稳定性(reasoning stability)和不确定性校准(uncertainty calibration)。他们使用熵(entropy)作为新指标，量化模型在重新排序答案变体中的推理一致性，并评估了Grok 3、ChatGPT-o1、Gemini 2.0 Flash Experimental等八个模型在八个视觉推理任务（如差异检测和图表解释）上的表现。结果显示，ChatGPT-o1在整体准确率(82.5%)和拒绝准确率(70.0%)上领先，QVQ-72B-Preview在拒绝准确率(85.5%)上出色，而Janus模型显示出高熵分数(Janus 7B: 0.8392)和不稳定推理，证明模型大小并非性能决定因素。该新基准通过多图像上下文和熵-based一致性指标，为更可靠的多模态LLMs评估设定了标准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16428v1",
      "published_date": "2025-02-23 04:01:43 UTC",
      "updated_date": "2025-02-23 04:01:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:53:47.717505"
    },
    {
      "arxiv_id": "2502.17517v1",
      "title": "Attention-based UAV Trajectory Optimization for Wireless Power Transfer-assisted IoT Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Li Dong",
        "Feibo Jiang",
        "Yubo Peng"
      ],
      "abstract": "Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted\nInternet of Things (IoT) systems face the following challenges: limited\nresources and suboptimal trajectory planning. Reinforcement learning-based\ntrajectory planning schemes face issues of low search efficiency and learning\ninstability when optimizing large-scale systems. To address these issues, we\npresent an Attention-based UAV Trajectory Optimization (AUTO) framework based\non the graph transformer, which consists of an Attention Trajectory\nOptimization Model (ATOM) and a Trajectory lEarNing Method based on\nActor-critic (TENMA). In ATOM, a graph encoder is used to calculate the\nself-attention characteristics of all IoTDs, and a trajectory decoder is\ndeveloped to optimize the number and trajectories of UAVs. TENMA then trains\nthe ATOM using an improved Actor-Critic method, in which the real reward of the\nsystem is applied as the baseline to reduce variances in the critic network.\nThis method is suitable for high-quality and large-scale multi-UAV trajectory\nplanning. Finally, we develop numerous experiments, including a hardware\nexperiment in the field case, to verify the feasibility and efficiency of the\nAUTO framework.",
      "tldr_zh": "这篇论文针对 Unmanned Aerial Vehicles (UAVs) 在 Wireless Power Transfer (WPT)-assisted Internet of Things (IoT) 系统中的资源限制和轨迹规划问题，提出了一种 Attention-based UAV Trajectory Optimization (AUTO) 框架。AUTO 框架包括 Attention Trajectory Optimization Model (ATOM)，它利用图编码器计算 IoTDs 的自注意力特征，并通过轨迹解码器优化 UAV 的数量和路径；以及 Trajectory lEarNing Method based on Actor-critic (TENMA)，采用改进的 Actor-Critic 方法以减少 critic 网络的方差，从而提升训练效率和稳定性。实验结果显示，该框架在大规模多 UAV 轨迹规划中表现出色，并通过硬件实验验证了其可行性和高效性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17517v1",
      "published_date": "2025-02-23 02:57:06 UTC",
      "updated_date": "2025-02-23 02:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:53:54.951108"
    },
    {
      "arxiv_id": "2502.18517v1",
      "title": "RewardDS: Privacy-Preserving Fine-Tuning for Large Language Models via Reward Driven Data Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Jianwei Wang",
        "Junyao Yang",
        "Haoran Li",
        "Huiping Zhuang",
        "Cen Chen",
        "Ziqian Zeng"
      ],
      "abstract": "The success of large language models (LLMs) has attracted many individuals to\nfine-tune them for domain-specific tasks by uploading their data. However, in\nsensitive areas like healthcare and finance, privacy concerns often arise. One\npromising solution is to sample synthetic data with Differential Privacy (DP)\nguarantees to replace private data. However, these synthetic data contain\nsignificant flawed data, which are considered as noise. Existing solutions\ntypically rely on naive filtering by comparing ROUGE-L scores or embedding\nsimilarities, which are ineffective in addressing the noise. To address this\nissue, we propose RewardDS, a novel privacy-preserving framework that\nfine-tunes a reward proxy model and uses reward signals to guide the synthetic\ndata generation. Our RewardDS introduces two key modules, Reward Guided\nFiltering and Self-Optimizing Refinement, to both filter and refine the\nsynthetic data, effectively mitigating the noise. Extensive experiments across\nmedical, financial, and code generation domains demonstrate the effectiveness\nof our method.",
      "tldr_zh": "该论文提出 RewardDS，一种基于奖励驱动数据合成的框架，用于在保护隐私的前提下对 Large Language Models (LLMs) 进行 fine-tuning，以解决合成数据中 Differential Privacy (DP) 带来的噪声问题。RewardDS 引入了两个关键模块：Reward Guided Filtering 用于根据奖励信号过滤无效数据，以及 Self-Optimizing Refinement 用于优化和精炼合成数据，从而提升数据质量。实验结果显示，该方法在医疗、金融和代码生成领域显著优于现有基于 ROUGE-L 分数或嵌入相似度的简单过滤技术，证明了其在隐私保护和模型性能提升方面的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.18517v1",
      "published_date": "2025-02-23 02:52:23 UTC",
      "updated_date": "2025-02-23 02:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:54:05.774084"
    },
    {
      "arxiv_id": "2502.16414v1",
      "title": "TabGen-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Liancheng Fang",
        "Aiwei Liu",
        "Hengrui Zhang",
        "Henry Peng Zou",
        "Weizhi Zhang",
        "Philip S. Yu"
      ],
      "abstract": "Large Language models (LLMs) have achieved encouraging results in tabular\ndata generation. However, existing approaches require fine-tuning, which is\ncomputationally expensive. This paper explores an alternative: prompting a\nfixed LLM with in-context examples. We observe that using randomly selected\nin-context examples hampers the LLM's performance, resulting in sub-optimal\ngeneration quality. To address this, we propose a novel in-context learning\nframework: TabGen-ICL, to enhance the in-context learning ability of LLMs for\ntabular data generation. TabGen-ICL operates iteratively, retrieving a subset\nof real samples that represent the residual between currently generated samples\nand true data distributions. This approach serves two purposes: locally, it\nprovides more effective in-context learning examples for the LLM in each\niteration; globally, it progressively narrows the gap between generated and\nreal data. Extensive experiments on five real-world tabular datasets\ndemonstrate that TabGen-ICL significantly outperforms the random selection\nstrategy. Specifically, it reduces the error rate by a margin of $3.5\\%-42.2\\%$\non fidelity metrics. We demonstrate for the first time that prompting a fixed\nLLM can yield high-quality synthetic tabular data. The code is provided in the\n\\href{https://github.com/fangliancheng/TabGEN-ICL}{link}.",
      "tldr_zh": "本研究提出TabGen-ICL框架，一种基于residual-aware的in-context example选择方法，用于提升LLMs在表格数据生成中的性能，而无需昂贵的微调过程。TabGen-ICL通过迭代方式检索代表当前生成样本与真实数据分布残差的子集，作为in-context学习示例，既 locally 提供更有效的学习样本，又 globally 缩小生成数据与真实数据的差距。在五个真实世界表格数据集上的实验表明，该框架显著优于随机选择策略，在保真度指标上减少错误率3.5%-42.2%，首次证明通过提示固定LLMs即可生成高质量合成表格数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16414v1",
      "published_date": "2025-02-23 02:51:58 UTC",
      "updated_date": "2025-02-23 02:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:54:19.550101"
    },
    {
      "arxiv_id": "2502.16411v3",
      "title": "Tool or Tutor? Experimental evidence from AI deployment in cancer diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Vivianna Fang He",
        "Sihan Li",
        "Phanish Puranam",
        "Feng Lin"
      ],
      "abstract": "Professionals increasingly use Artificial Intelligence (AI) to enhance their\ncapabilities and assist with task execution. While prior research has examined\nthese uses separately, their potential interaction remains underexplored. We\npropose that AI-driven training (\"tutor\") and AI-assisted task completion\n(\"tool\") can have a joint effect on human capability and test this hypothesis\nin the context of lung cancer diagnosis. In a field experiment with 336 medical\nstudents, we manipulated AI deployment in training, in practice, and in both.\nOur findings reveal that while AI-integrated training and AI assistance\nindependently improved diagnostic performance, their combination yielded the\nhighest accuracy. These results underscore AI's dual role in enhancing human\nperformance through both learning and real-time support, offering insights into\nAI deployment in professional settings where human expertise remains essential.",
      "tldr_zh": "本研究探讨了 AI 在专业领域中作为工具（协助任务）和导师（驱动训练）的双重作用及其互动效果，通过一个涉及 336 名医学生的现场实验（field experiment）来检验肺癌诊断的性能提升。实验操纵了 AI 在训练、实践或两者中的部署，结果显示 AI 训练和 AI 辅助单独使用均能改善诊断准确性，而二者结合时取得了最高准确率。这些发现强调了 AI 通过学习支持和实时辅助的双重机制，在依赖人类专业知识的场景中增强整体表现。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16411v3",
      "published_date": "2025-02-23 02:47:49 UTC",
      "updated_date": "2025-03-30 09:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:54:31.148127"
    },
    {
      "arxiv_id": "2502.16406v1",
      "title": "TrustChain: A Blockchain Framework for Auditing and Verifying Aggregators in Decentralized Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Hallaji",
        "Roozbeh Razavi-Far",
        "Mehrdad Saif"
      ],
      "abstract": "The server-less nature of Decentralized Federated Learning (DFL) requires\nallocating the aggregation role to specific participants in each federated\nround. Current DFL architectures ensure the trustworthiness of the aggregator\nnode upon selection. However, most of these studies overlook the possibility\nthat the aggregating node may turn rogue and act maliciously after being\nnominated. To address this problem, this paper proposes a DFL structure, called\nTrustChain, that scores the aggregators before selection based on their past\nbehavior and additionally audits them after the aggregation. To do this, the\nstatistical independence between the client updates and the aggregated model is\ncontinuously monitored using the Hilbert-Schmidt Independence Criterion (HSIC).\nThe proposed method relies on several principles, including blockchain, anomaly\ndetection, and concept drift analysis. The designed structure is evaluated on\nseveral federated datasets and attack scenarios with different numbers of\nByzantine nodes.",
      "tldr_zh": "该论文提出TrustChain框架，用于在Decentralized Federated Learning (DFL)中审计和验证聚合器，以解决聚合器在选定后可能变得恶意的风险。框架在选择前基于聚合器的过去行为进行评分，并在聚合后使用Hilbert-Schmidt Independence Criterion (HSIC)监控客户端更新和聚合模型之间的统计独立性，同时整合blockchain、anomaly detection和concept drift analysis等原理。实验结果显示，该结构在多种联邦数据集和攻击场景中表现出色，尤其在不同数量的Byzantine节点环境下，提升了DFL的安全性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16406v1",
      "published_date": "2025-02-23 02:26:17 UTC",
      "updated_date": "2025-02-23 02:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:54:42.814561"
    },
    {
      "arxiv_id": "2504.05318v1",
      "title": "Efficient Multi-Task Learning via Generalist Recommender",
      "title_zh": "翻译失败",
      "authors": [
        "Luyang Wang",
        "Cangcheng Tang",
        "Chongyang Zhang",
        "Jun Ruan",
        "Kai Huang",
        "Jason Dai"
      ],
      "abstract": "Multi-task learning (MTL) is a common machine learning technique that allows\nthe model to share information across different tasks and improve the accuracy\nof recommendations for all of them. Many existing MTL implementations suffer\nfrom scalability issues as the training and inference performance can degrade\nwith the increasing number of tasks, which can limit production use case\nscenarios for MTL-based recommender systems. Inspired by the recent advances of\nlarge language models, we developed an end-to-end efficient and scalable\nGeneralist Recommender (GRec). GRec takes comprehensive data signals by\nutilizing NLP heads, parallel Transformers, as well as a wide and deep\nstructure to process multi-modal inputs. These inputs are then combined and fed\nthrough a newly proposed task-sentence level routing mechanism to scale the\nmodel capabilities on multiple tasks without compromising performance. Offline\nevaluations and online experiments show that GRec significantly outperforms our\nprevious recommender solutions. GRec has been successfully deployed on one of\nthe largest telecom websites and apps, effectively managing high volumes of\nonline traffic every day.",
      "tldr_zh": "这篇论文针对多任务学习 (MTL) 的可伸缩性问题，提出了一种高效的 Generalist Recommender (GRec)，它通过利用 NLP heads、并行 Transformers 和宽深结构来处理多模态输入，并引入 task-sentence level routing 机制，以在不牺牲性能的情况下扩展模型到多个任务。GRec 允许模型共享信息并提高推荐准确性，相比现有系统在离线评估和在线实验中表现出显著优势。最终，该系统已在大型电信网站和应用上成功部署，高效处理高流量场景。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05318v1",
      "published_date": "2025-02-23 02:05:28 UTC",
      "updated_date": "2025-02-23 02:05:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:54:55.258399"
    },
    {
      "arxiv_id": "2502.16402v1",
      "title": "Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models for Navigation Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Feng Ma",
        "Xiu-min Wang",
        "Chen Chen",
        "Xiao-bin Xu",
        "Xin-ping Yan"
      ],
      "abstract": "Existing navigation decision support systems often perform poorly when\nhandling non-predefined navigation scenarios. Leveraging the generalization\ncapabilities of large language model (LLM) in handling unknown scenarios, this\nresearch proposes a dual-core framework for LLM applications to address this\nissue. Firstly, through ReAct-based prompt engineering, a larger LLM core\ndecomposes intricate navigation tasks into manageable sub-tasks, which\nautonomously invoke corresponding external tools to gather relevant\ninformation, using this feedback to mitigate the risk of LLM hallucinations.\nSubsequently, a fine-tuned and compact LLM core, acting like a first-mate is\ndesigned to process such information and unstructured external data, then to\ngenerates context-aware recommendations, ultimately delivering lookout insights\nand navigation hints that adhere to the International Regulations for\nPreventing Collisions at Sea (COLREGs) and other rules. Extensive experiments\ndemonstrate the proposed framework not only excels in traditional ship\ncollision avoidance tasks but also adapts effectively to unstructured,\nnon-predefined, and unpredictable scenarios. A comparative analysis with\nDeepSeek-R1, GPT-4o and other SOTA models highlights the efficacy and\nrationality of the proposed framework. This research bridges the gap between\nconventional navigation systems and LLMs, offering a framework to enhance\nsafety and operational efficiency across diverse navigation applications.",
      "tldr_zh": "本文提出 Navigation-GPT 框架，利用 Large Language Models (LLM) 的泛化能力，解决现有导航系统在处理非预定义场景时的不足。该框架采用双核心设计：一个较大的 LLM 通过 ReAct-based 提示工程分解复杂任务、调用外部工具收集信息以减少 hallucinations；另一个微调的紧凑 LLM 处理数据并生成遵守 COLREGs 等规则的上下文感知推荐。实验结果显示，该框架在传统船舶避撞任务中表现卓越，并能有效适应非结构化和不可预测场景，与 DeepSeek-R1、GPT-4o 等 SOTA 模型相比，显著提升了安全性和操作效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16402v1",
      "published_date": "2025-02-23 01:41:58 UTC",
      "updated_date": "2025-02-23 01:41:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:55:08.399291"
    },
    {
      "arxiv_id": "2502.16399v1",
      "title": "Ensemble ToT of LLMs and Its Application to Automatic Grading System for Supporting Self-Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuki Ito",
        "Qiang Ma"
      ],
      "abstract": "Providing students with detailed and timely grading feedback is essential for\nself-learning. While existing LLM-based grading systems are promising, most of\nthem rely on one single model, which limits their performance. To address this,\nwe propose Ensemble Tree-of-Thought (ToT), a framework that enhances LLM\noutputs by integrating multiple models. Using this framework, we develop a\ngrading system. Ensemble ToT follows three steps: (1) analyzing LLM\nperformance, (2) generating candidate answers, and (3) refining them into a\nfinal result. Based on this, our grading system first evaluates the grading\ntendencies of LLMs, then generates multiple results, and finally integrates\nthem via a simulated debate. Experimental results demonstrate our approach's\nability to provide accurate and explainable grading by effectively coordinating\nmultiple LLMs.",
      "tldr_zh": "本研究提出 Ensemble ToT 框架，通过整合多个大型语言模型 (LLMs) 来提升输出质量，并将其应用于自动评分系统，以支持学生的自学。该框架包括三个步骤：分析 LLM 性能、生成候选答案，以及通过模拟辩论精炼最终结果，从而协调多个模型的评分倾向。实验结果显示，该方法能提供准确且可解释的评分反馈，显著改善现有单模型系统的局限性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "I.2.7; K.3.1; K.3.2"
      ],
      "primary_category": "cs.IR",
      "comment": "33 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.16399v1",
      "published_date": "2025-02-23 01:17:46 UTC",
      "updated_date": "2025-02-23 01:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:55:18.121938"
    },
    {
      "arxiv_id": "2502.16396v1",
      "title": "FedNIA: Noise-Induced Activation Analysis for Mitigating Data Poisoning in FL",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Hallaji",
        "Roozbeh Razavi-Far",
        "Mehrdad Saif"
      ],
      "abstract": "Federated learning systems are increasingly threatened by data poisoning\nattacks, where malicious clients compromise global models by contributing\ntampered updates. Existing defenses often rely on impractical assumptions, such\nas access to a central test dataset, or fail to generalize across diverse\nattack types, particularly those involving multiple malicious clients working\ncollaboratively. To address this, we propose Federated Noise-Induced Activation\nAnalysis (FedNIA), a novel defense framework to identify and exclude\nadversarial clients without relying on any central test dataset. FedNIA injects\nrandom noise inputs to analyze the layerwise activation patterns in client\nmodels leveraging an autoencoder that detects abnormal behaviors indicative of\ndata poisoning. FedNIA can defend against diverse attack types, including\nsample poisoning, label flipping, and backdoors, even in scenarios with\nmultiple attacking nodes. Experimental results on non-iid federated datasets\ndemonstrate its effectiveness and robustness, underscoring its potential as a\nfoundational approach for enhancing the security of federated learning systems.",
      "tldr_zh": "该论文提出 FedNIA，一种新型防御框架，用于缓解联邦学习（Federated Learning, FL）中的数据中毒攻击（Data Poisoning Attacks），无需依赖中心测试数据集即可识别和排除恶意客户端。FedNIA 通过注入随机噪声输入来分析客户端模型的层级激活模式，并利用自编码器（Autoencoder）检测异常行为，从而防御多种攻击类型，包括样本中毒、标签翻转和后门攻击（Backdoors），即使在多个恶意节点协作的场景下。实验结果在非独立同分布（Non-IID）联邦数据集上证明了 FedNIA 的有效性和鲁棒性，为提升联邦学习系统的安全性提供了基础方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16396v1",
      "published_date": "2025-02-23 01:16:01 UTC",
      "updated_date": "2025-02-23 01:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:55:30.981700"
    },
    {
      "arxiv_id": "2502.16395v1",
      "title": "An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuhai Zeng",
        "Claire Jin",
        "Xinyue Wang",
        "Yuhan Zheng",
        "Qunhua Li"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated potential for data science\ntasks via code generation. However, the exploratory nature of data science,\nalongside the stochastic and opaque outputs of LLMs, raise concerns about their\nreliability. While prior work focuses on benchmarking LLM accuracy,\nreproducibility remains underexplored, despite being critical to establishing\ntrust in LLM-driven analysis.\n  We propose a novel analyst-inspector framework to automatically evaluate and\nenforce the reproducibility of LLM-generated data science workflows - the first\nrigorous approach to the best of our knowledge. Defining reproducibility as the\nsufficiency and completeness of workflows for reproducing functionally\nequivalent code, this framework enforces computational reproducibility\nprinciples, ensuring transparent, well-documented LLM workflows while\nminimizing reliance on implicit model assumptions.\n  Using this framework, we systematically evaluate five state-of-the-art LLMs\non 1,032 data analysis tasks across three diverse benchmark datasets. We also\nintroduce two novel reproducibility-enhancing prompting strategies. Our results\nshow that higher reproducibility strongly correlates with improved accuracy and\nreproducibility-enhancing prompts are effective, demonstrating structured\nprompting's potential to enhance automated data science workflows and enable\ntransparent, robust AI-driven analysis. Our code is publicly available.",
      "tldr_zh": "本论文提出一个名为“analyst-inspector framework”的新框架，用于自动评估和强制执行大型语言模型（LLMs）在数据科学任务中的可重复性，这是首个严格的方法，以解决LLMs输出随机性和不透明性的可靠性问题。框架将可重复性定义为工作流的充分性和完整性，确保计算可重复性原则的遵守，并引入两种新型提示策略来提升工作流的透明度和文档化。在对五种最先进LLMs的系统评估中，涵盖1032个数据分析任务，结果显示更高的可重复性与improved accuracy显著相关，且增强提示策略有效，证明了结构化提示在促进透明、稳健的AI驱动分析方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.16395v1",
      "published_date": "2025-02-23 01:15:50 UTC",
      "updated_date": "2025-02-23 01:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:55:45.399203"
    },
    {
      "arxiv_id": "2503.00020v1",
      "title": "A Systematic Review of Open Datasets Used in Text-to-Image (T2I) Gen AI Model Safety",
      "title_zh": "翻译失败",
      "authors": [
        "Rakeen Rouf",
        "Trupti Bavalatti",
        "Osama Ahmed",
        "Dhaval Potdar",
        "Faraz Jawed"
      ],
      "abstract": "Novel research aimed at text-to-image (T2I) generative AI safety often relies\non publicly available datasets for training and evaluation, making the quality\nand composition of these datasets crucial. This paper presents a comprehensive\nreview of the key datasets used in the T2I research, detailing their collection\nmethods, compositions, semantic and syntactic diversity of prompts and the\nquality, coverage, and distribution of harm types in the datasets. By\nhighlighting the strengths and limitations of the datasets, this study enables\nresearchers to find the most relevant datasets for a use case, critically\nassess the downstream impacts of their work given the dataset distribution,\nparticularly regarding model safety and ethical considerations, and also\nidentify the gaps in dataset coverage and quality that future research may\naddress.",
      "tldr_zh": "这篇论文对用于文本到图像 (T2I) 生成AI模型安全的公开数据集进行了系统性审查，涵盖了数据集的收集方法、组成、提示的语义和句法多样性，以及危害类型的质量、覆盖和分布。研究突出了这些数据集的优点和局限性，帮助研究者根据具体需求选择合适的数据集，并评估其对模型安全和伦理考虑的潜在影响。最终，该工作识别了数据集覆盖和质量的空白，为未来研究提供改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in IEEE Access, DOI:\n  10.1109/ACCESS.2025.3539933",
      "pdf_url": "http://arxiv.org/pdf/2503.00020v1",
      "published_date": "2025-02-23 00:59:04 UTC",
      "updated_date": "2025-02-23 00:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:55:54.300826"
    },
    {
      "arxiv_id": "2502.16389v1",
      "title": "An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Tianchen Ji",
        "Neeloy Chakraborty",
        "Andre Schreiber",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "As automated vehicles enter public roads, safety in a near-infinite number of\ndriving scenarios becomes one of the major concerns for the widespread adoption\nof fully autonomous driving. The ability to detect anomalous situations outside\nof the operational design domain is a key component in self-driving cars,\nenabling us to mitigate the impact of abnormal ego behaviors and to realize\ntrustworthy driving systems. On-road anomaly detection in egocentric videos\nremains a challenging problem due to the difficulties introduced by complex and\ninteractive scenarios. We conduct a holistic analysis of common on-road anomaly\npatterns, from which we propose three unsupervised anomaly detection experts: a\nscene expert that focuses on frame-level appearances to detect abnormal scenes\nand unexpected scene motions; an interaction expert that models normal relative\nmotions between two road participants and raises alarms whenever anomalous\ninteractions emerge; and a behavior expert which monitors abnormal behaviors of\nindividual objects by future trajectory prediction. To combine the strengths of\nall the modules, we propose an expert ensemble (Xen) using a Kalman filter, in\nwhich the final anomaly score is absorbed as one of the states and the\nobservations are generated by the experts. Our experiments employ a novel\nevaluation protocol for realistic model performance, demonstrate superior\nanomaly detection performance than previous methods, and show that our\nframework has potential in classifying anomaly types using unsupervised\nlearning on a large-scale on-road anomaly dataset.",
      "tldr_zh": "该研究针对自动驾驶车辆的安全问题，提出了一种专家集成框架（Expert Ensemble，简称Xen），用于检测超出操作设计域的异常场景、互动和行为。该框架包括三个无监督异常检测专家：scene expert 专注于帧级外观以识别异常场景和运动、interaction expert 建模正常相对运动以检测异常互动，以及 behavior expert 通过未来轨迹预测监控个体对象的异常行为。这些专家的输出通过 Kalman filter 融合，形成统一的异常分数。实验结果显示，该框架在大型数据集上比现有方法表现出色，能够有效检测异常并潜在分类异常类型，从而提升自动驾驶系统的可靠性和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by International Journal of Robotics Research (IJRR)",
      "pdf_url": "http://arxiv.org/pdf/2502.16389v1",
      "published_date": "2025-02-23 00:43:23 UTC",
      "updated_date": "2025-02-23 00:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T17:56:05.556137"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 97,
  "processed_papers_count": 97,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T17:56:28.295856"
}