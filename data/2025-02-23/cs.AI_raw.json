[
  {
    "arxiv_id": "2502.16747v2",
    "title": "SQLong: Enhanced NL2SQL for Longer Contexts with LLMs",
    "authors": [
      "Dai Quoc Nguyen",
      "Cong Duy Vu Hoang",
      "Duy Vu",
      "Gioacchino Tangari",
      "Thanh Tien Vu",
      "Don Dharmasiri",
      "Yuan-Fang Li",
      "Long Duong"
    ],
    "abstract": "Open-weight large language models (LLMs) have significantly advanced\nperformance in the Natural Language to SQL (NL2SQL) task. However, their\neffectiveness diminishes when dealing with large database schemas, as the\ncontext length increases. To address this limitation, we present SQLong, a\nnovel and efficient data augmentation framework designed to enhance LLM\nperformance in long-context scenarios for the NL2SQL task. SQLong generates\naugmented datasets by extending existing database schemas with additional\nsynthetic CREATE TABLE commands and corresponding data rows, sampled from\ndiverse schemas in the training data. This approach effectively simulates\nlong-context scenarios during finetuning and evaluation. Through experiments on\nthe Spider and BIRD datasets, we demonstrate that LLMs finetuned with\nSQLong-augmented data significantly outperform those trained on standard\ndatasets. These imply SQLong's practical implementation and its impact on\nimproving NL2SQL capabilities in real-world settings with complex database\nschemas.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Table Representation Learning Workshop at ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16747v2",
    "published_date": "2025-02-23 23:23:51 UTC",
    "updated_date": "2025-05-20 12:14:20 UTC"
  },
  {
    "arxiv_id": "2502.16744v1",
    "title": "Order-Optimal Projection-Free Algorithm for Adversarially Constrained Online Convex Optimization",
    "authors": [
      "Yiyang Lu",
      "Mohammad Pedramfar",
      "Vaneet Aggarwal"
    ],
    "abstract": "Projection-based algorithms for constrained Online Convex Optimization (COCO)\nface scalability challenges in high-dimensional settings due to the\ncomputational complexity of projecting iterates onto constraint sets. This\npaper introduces a projection-free algorithm for COCO that achieves\nstate-of-the-art performance guarantees while eliminating the need for\nprojections. By integrating a separation oracle with adaptive Online Gradient\nDescent (OGD) and employing a Lyapunov-driven surrogate function, while\ndynamically adjusting step sizes using gradient norms, our method jointly\noptimizes the regret and cumulative constraint violation (CCV). We also use a\nblocked version of OGD that helps achieve tradeoffs betweeen the regret and CCV\nwith the number of calls to the separation oracle. For convex cost functions,\nour algorithm attains an optimal regret of $\\mathcal{O}(\\sqrt{T})$ and a CCV of\n$\\mathcal{O}(\\sqrt{T} \\log T)$, matching the best-known projection-based\nresults, while only using $\\tilde{\\mathcal{O}}({T})$ calls to the separation\noracle. The results also demonstrate a tradeoff where lower calls to the\nseparation oracle increase the regret and the CCV. In the strongly convex\nsetting, we further achieve a regret of $\\mathcal{O}(\\log T)$ and a CCV of\n$\\mathcal{O}(\\sqrt{T\\log T} )$, while requiring ${\\mathcal{O}}({T}^2)$ calls to\nthe separation oracle. Further, tradeoff with the decreasing oracle calls is\nstudied. These results close the gap between projection-free and\nprojection-based approaches, demonstrating that projection-free methods can\nachieve performance comparable to projection-based counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16744v1",
    "published_date": "2025-02-23 23:18:40 UTC",
    "updated_date": "2025-02-23 23:18:40 UTC"
  },
  {
    "arxiv_id": "2502.16736v2",
    "title": "AUKT: Adaptive Uncertainty-Guided Knowledge Transfer with Conformal Prediction",
    "authors": [
      "Rui Liu",
      "Peng Gao",
      "Yu Shen",
      "Ming Lin",
      "Pratap Tokekar"
    ],
    "abstract": "Knowledge transfer between teacher and student models has proven effective\nacross various machine learning applications. However, challenges arise when\nthe teacher's predictions are noisy, or the data domain during student training\nshifts from the teacher's pretraining data. In such scenarios, blindly relying\non the teacher's predictions can lead to suboptimal knowledge transfer. To\naddress these challenges, we propose a novel and universal framework, Adaptive\nUncertainty-guided Knowledge Transfer ($\\textbf{AUKT}$), which leverages\nConformal Prediction (CP) to dynamically adjust the student's reliance on the\nteacher's guidance based on the teacher's prediction uncertainty. CP is a\ndistribution-free, model-agnostic approach that provides reliable prediction\nsets with statistical coverage guarantees and minimal computational overhead.\nThis adaptive mechanism mitigates the risk of learning undesirable or incorrect\nknowledge. We validate the proposed framework across diverse applications,\nincluding image classification, imitation-guided reinforcement learning, and\nautonomous driving. Experimental results consistently demonstrate that our\napproach improves performance, robustness and transferability, offering a\npromising direction for enhanced knowledge transfer in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16736v2",
    "published_date": "2025-02-23 22:39:19 UTC",
    "updated_date": "2025-02-25 04:07:57 UTC"
  },
  {
    "arxiv_id": "2502.16732v2",
    "title": "DeepSeek reshaping healthcare in China's tertiary hospitals",
    "authors": [
      "Jishizhan Chen",
      "Qingzeng Zhang"
    ],
    "abstract": "The rapid integration of artificial intelligence (AI) into healthcare is\ntransforming clinical decision-making and hospital operations. DeepSeek has\nemerged as a leading AI system, widely deployed across China's tertiary\nhospitals since January 2025. Initially implemented in Shanghai's major medical\ninstitutions, it has since expanded nationwide, enhancing diagnostic accuracy,\nstreamlining workflows, and improving patient management. AI-powered pathology,\nimaging analysis, and clinical decision support systems have demonstrated\nsignificant potential in optimizing medical processes and reducing the\ncognitive burden on healthcare professionals. However, the widespread adoption\nof AI in healthcare raises critical regulatory and ethical challenges,\nparticularly regarding accountability in AI-assisted diagnosis and the risk of\nautomation bias. The absence of a well-defined liability framework underscores\nthe need for policies that ensure AI functions as an assistive tool rather than\nan autonomous decision-maker. With continued technological advancements, AI is\nexpected to integrate multimodal data sources, such as genomics and radiomics,\npaving the way for precision medicine and personalized treatment strategies.\nThe future of AI in healthcare depends on the development of transparent\nregulatory structures, industry collaboration, and adaptive governance\nframeworks that balance innovation with responsibility, ensuring equitable and\neffective AI-driven medical services.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16732v2",
    "published_date": "2025-02-23 22:09:17 UTC",
    "updated_date": "2025-02-27 10:24:58 UTC"
  },
  {
    "arxiv_id": "2502.16730v1",
    "title": "RapidPen: Fully Automated IP-to-Shell Penetration Testing with LLM-based Agents",
    "authors": [
      "Sho Nakatani"
    ],
    "abstract": "We present RapidPen, a fully automated penetration testing (pentesting)\nframework that addresses\n  the challenge of achieving an initial foothold (IP-to-Shell) without human\nintervention. Unlike prior\n  approaches that focus primarily on post-exploitation or require a\nhuman-in-the-loop, RapidPen\n  leverages large language models (LLMs) to autonomously discover and exploit\nvulnerabilities, starting from\n  a single IP address. By integrating advanced ReAct-style task planning (Re)\nwith retrieval-augmented\n  knowledge bases of successful exploits, along with a command-generation and\ndirect execution feedback loop\n  (Act), RapidPen systematically scans services, identifies viable attack\nvectors, and executes targeted\n  exploits in a fully automated manner.\n  In our evaluation against a vulnerable target from the Hack The Box platform,\nRapidPen achieved shell\n  access within 200-400 seconds at a per-run cost of approximately \\$0.3-\\$0.6,\ndemonstrating a\n  60\\% success rate when reusing prior \"success-case\" data. These results\nunderscore the potential\n  of truly autonomous pentesting for both security novices and seasoned\nprofessionals. Organizations\n  without dedicated security teams can leverage RapidPen to quickly identify\ncritical vulnerabilities,\n  while expert pentesters can offload repetitive tasks and focus on complex\nchallenges.\n  Ultimately, our work aims to make penetration testing more accessible and\ncost-efficient,\n  thereby enhancing the overall security posture of modern software ecosystems.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16730v1",
    "published_date": "2025-02-23 21:57:46 UTC",
    "updated_date": "2025-02-23 21:57:46 UTC"
  },
  {
    "arxiv_id": "2502.16725v1",
    "title": "DOSE3 : Diffusion-based Out-of-distribution detection on SE(3) trajectories",
    "authors": [
      "Hongzhe Cheng",
      "Tianyou Zheng",
      "Tianyi Zhang",
      "Matthew Johnson-Roberson",
      "Weiming Zhi"
    ],
    "abstract": "Out-of-Distribution(OOD) detection, a fundamental machine learning task aimed\nat identifying abnormal samples, traditionally requires model retraining for\ndifferent inlier distributions. While recent research demonstrates the\napplicability of diffusion models to OOD detection, existing approaches are\nlimited to Euclidean or latent image spaces. Our work extends OOD detection to\ntrajectories in the Special Euclidean Group in 3D ($\\mathbb{SE}(3)$),\naddressing a critical need in computer vision, robotics, and engineering\napplications that process object pose sequences in $\\mathbb{SE}(3)$. We present\n$\\textbf{D}$iffusion-based $\\textbf{O}$ut-of-distribution detection on\n$\\mathbb{SE}(3)$ ($\\mathbf{DOSE3}$), a novel OOD framework that extends\ndiffusion to a unified sample space of $\\mathbb{SE}(3)$ pose sequences. Through\nextensive validation on multiple benchmark datasets, we demonstrate\n$\\mathbf{DOSE3}$'s superior performance compared to state-of-the-art OOD\ndetection frameworks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16725v1",
    "published_date": "2025-02-23 21:32:48 UTC",
    "updated_date": "2025-02-23 21:32:48 UTC"
  },
  {
    "arxiv_id": "2502.16722v1",
    "title": "Layer-Wise Evolution of Representations in Fine-Tuned Transformers: Insights from Sparse AutoEncoders",
    "authors": [
      "Suneel Nadipalli"
    ],
    "abstract": "Fine-tuning pre-trained transformers is a powerful technique for enhancing\nthe performance of base models on specific tasks. From early applications in\nmodels like BERT to fine-tuning Large Language Models (LLMs), this approach has\nbeen instrumental in adapting general-purpose architectures for specialized\ndownstream tasks. Understanding the fine-tuning process is crucial for\nuncovering how transformers adapt to specific objectives, retain general\nrepresentations, and acquire task-specific features. This paper explores the\nunderlying mechanisms of fine-tuning, specifically in the BERT transformer, by\nanalyzing activation similarity, training Sparse AutoEncoders (SAEs), and\nvisualizing token-level activations across different layers. Based on\nexperiments conducted across multiple datasets and BERT layers, we observe a\nsteady progression in how features adapt to the task at hand: early layers\nprimarily retain general representations, middle layers act as a transition\nbetween general and task-specific features, and later layers fully specialize\nin task adaptation. These findings provide key insights into the inner workings\nof fine-tuning and its impact on representation learning within transformer\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16722v1",
    "published_date": "2025-02-23 21:29:50 UTC",
    "updated_date": "2025-02-23 21:29:50 UTC"
  },
  {
    "arxiv_id": "2502.16721v1",
    "title": "Speed and Conversational Large Language Models: Not All Is About Tokens per Second",
    "authors": [
      "Javier Conde",
      "Miguel González",
      "Pedro Reviriego",
      "Zhen Gao",
      "Shanshan Liu",
      "Fabrizio Lombardi"
    ],
    "abstract": "The speed of open-weights large language models (LLMs) and its dependency on\nthe task at hand, when run on GPUs, is studied to present a comparative\nanalysis of the speed of the most popular open LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16721v1",
    "published_date": "2025-02-23 21:28:55 UTC",
    "updated_date": "2025-02-23 21:28:55 UTC"
  },
  {
    "arxiv_id": "2502.16718v1",
    "title": "NatSGLD: A Dataset with Speech, Gesture, Logic, and Demonstration for Robot Learning in Natural Human-Robot Interaction",
    "authors": [
      "Snehesh Shrestha",
      "Yantian Zha",
      "Saketh Banagiri",
      "Ge Gao",
      "Yiannis Aloimonos",
      "Cornelia Fermüller"
    ],
    "abstract": "Recent advances in multimodal Human-Robot Interaction (HRI) datasets\nemphasize the integration of speech and gestures, allowing robots to absorb\nexplicit knowledge and tacit understanding. However, existing datasets\nprimarily focus on elementary tasks like object pointing and pushing, limiting\ntheir applicability to complex domains. They prioritize simpler human command\ndata but place less emphasis on training robots to correctly interpret tasks\nand respond appropriately. To address these gaps, we present the NatSGLD\ndataset, which was collected using a Wizard of Oz (WoZ) method, where\nparticipants interacted with a robot they believed to be autonomous. NatSGLD\nrecords humans' multimodal commands (speech and gestures), each paired with a\ndemonstration trajectory and a Linear Temporal Logic (LTL) formula that\nprovides a ground-truth interpretation of the commanded tasks. This dataset\nserves as a foundational resource for research at the intersection of HRI and\nmachine learning. By providing multimodal inputs and detailed annotations,\nNatSGLD enables exploration in areas such as multimodal instruction following,\nplan recognition, and human-advisable reinforcement learning from\ndemonstrations. We release the dataset and code under the MIT License at\nhttps://www.snehesh.com/natsgld/ to support future HRI research.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2403.02274",
    "pdf_url": "http://arxiv.org/pdf/2502.16718v1",
    "published_date": "2025-02-23 21:27:06 UTC",
    "updated_date": "2025-02-23 21:27:06 UTC"
  },
  {
    "arxiv_id": "2502.16713v1",
    "title": "Understanding the Impact of Artificial Intelligence in Academic Writing: Metadata to the Rescue",
    "authors": [
      "Javier Conde",
      "Pedro Reviriego",
      "Joaquín Salvachúa",
      "Gonzalo Martínez",
      "José Alberto Hernández",
      "Fabrizio Lombardi"
    ],
    "abstract": "This column advocates for including artificial intelligence (AI)-specific\nmetadata on those academic papers that are written with the help of AI in an\nattempt to analyze the use of such tools for disseminating research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16713v1",
    "published_date": "2025-02-23 21:10:44 UTC",
    "updated_date": "2025-02-23 21:10:44 UTC"
  },
  {
    "arxiv_id": "2503.01859v1",
    "title": "Optimizing Retrieval-Augmented Generation of Medical Content for Spaced Repetition Learning",
    "authors": [
      "Jeremi I. Kaczmarek",
      "Jakub Pokrywka",
      "Krzysztof Biedalak",
      "Grzegorz Kurzyp",
      "Łukasz Grzybowski"
    ],
    "abstract": "Advances in Large Language Models revolutionized medical education by\nenabling scalable and efficient learning solutions. This paper presents a\npipeline employing Retrieval-Augmented Generation (RAG) system to prepare\ncomments generation for Poland's State Specialization Examination (PES) based\non verified resources. The system integrates these generated comments and\nsource documents with a spaced repetition learning algorithm to enhance\nknowledge retention while minimizing cognitive overload. By employing a refined\nretrieval system, query rephraser, and an advanced reranker, our modified RAG\nsolution promotes accuracy more than efficiency. Rigorous evaluation by medical\nannotators demonstrates improvements in key metrics such as document relevance,\ncredibility, and logical coherence of generated content, proven by a series of\nexperiments presented in the paper. This study highlights the potential of RAG\nsystems to provide scalable, high-quality, and individualized educational\nresources, addressing non-English speaking users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01859v1",
    "published_date": "2025-02-23 20:56:31 UTC",
    "updated_date": "2025-02-23 20:56:31 UTC"
  },
  {
    "arxiv_id": "2502.18225v3",
    "title": "Liver Cirrhosis Stage Estimation from MRI with Deep Learning",
    "authors": [
      "Jun Zeng",
      "Debesh Jha",
      "Ertugrul Aktas",
      "Elif Keles",
      "Alpay Medetalibeyoglu",
      "Matthew Antalek",
      "Federica Proietto Salanitri",
      "Amir A. Borhani",
      "Daniela P. Ladner",
      "Gorkem Durak",
      "Ulas Bagci"
    ],
    "abstract": "We present an end-to-end deep learning framework for automated liver\ncirrhosis stage estimation from multi-sequence MRI. Cirrhosis is the severe\nscarring (fibrosis) of the liver and a common endpoint of various chronic liver\ndiseases. Early diagnosis is vital to prevent complications such as\ndecompensation and cancer, which significantly decreases life expectancy.\nHowever, diagnosing cirrhosis in its early stages is challenging, and patients\noften present with life-threatening complications. Our approach integrates\nmulti-scale feature learning with sequence-specific attention mechanisms to\ncapture subtle tissue variations across cirrhosis progression stages. Using\nCirrMRI600+, a large-scale publicly available dataset of 628 high-resolution\nMRI scans from 339 patients, we demonstrate state-of-the-art performance in\nthree-stage cirrhosis classification. Our best model achieves 72.8% accuracy on\nT1W and 63.8% on T2W sequences, significantly outperforming traditional\nradiomics-based approaches. Through extensive ablation studies, we show that\nour architecture effectively learns stage-specific imaging biomarkers. We\nestablish new benchmarks for automated cirrhosis staging and provide insights\nfor developing clinically applicable deep learning systems. The source code\nwill be available at https://github.com/JunZengz/CirrhosisStage.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "7 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.18225v3",
    "published_date": "2025-02-23 20:50:08 UTC",
    "updated_date": "2025-05-22 12:46:31 UTC"
  },
  {
    "arxiv_id": "2502.16708v1",
    "title": "Exploring Incremental Unlearning: Techniques, Challenges, and Future Directions",
    "authors": [
      "Sadia Qureshi",
      "Thanveer Shaik",
      "Xiaohui Tao",
      "Haoran Xie",
      "Lin Li",
      "Jianming Yong",
      "Xiaohua Jia"
    ],
    "abstract": "The growing demand for data privacy in Machine Learning (ML) applications has\nseen Machine Unlearning (MU) emerge as a critical area of research. As the\n`right to be forgotten' becomes regulated globally, it is increasingly\nimportant to develop mechanisms that delete user data from AI systems while\nmaintaining performance and scalability of these systems. Incremental\nUnlearning (IU) is a promising MU solution to address the challenges of\nefficiently removing specific data from ML models without the need for\nexpensive and time-consuming full retraining. This paper presents the various\ntechniques and approaches to IU. It explores the challenges faced in designing\nand implementing IU mechanisms. Datasets and metrics for evaluating the\nperformance of unlearning techniques are discussed as well. Finally, potential\nsolutions to the IU challenges alongside future research directions are\noffered. This survey provides valuable insights for researchers and\npractitioners seeking to understand the current landscape of IU and its\npotential for enhancing privacy-preserving intelligent systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2502.16708v1",
    "published_date": "2025-02-23 20:47:27 UTC",
    "updated_date": "2025-02-23 20:47:27 UTC"
  },
  {
    "arxiv_id": "2502.16707v1",
    "title": "Reflective Planning: Vision-Language Models for Multi-Stage Long-Horizon Robotic Manipulation",
    "authors": [
      "Yunhai Feng",
      "Jiaming Han",
      "Zhuoran Yang",
      "Xiangyu Yue",
      "Sergey Levine",
      "Jianlan Luo"
    ],
    "abstract": "Solving complex long-horizon robotic manipulation problems requires\nsophisticated high-level planning capabilities, the ability to reason about the\nphysical world, and reactively choose appropriate motor skills. Vision-language\nmodels (VLMs) pretrained on Internet data could in principle offer a framework\nfor tackling such problems. However, in their current form, VLMs lack both the\nnuanced understanding of intricate physics required for robotic manipulation\nand the ability to reason over long horizons to address error compounding\nissues. In this paper, we introduce a novel test-time computation framework\nthat enhances VLMs' physical reasoning capabilities for multi-stage\nmanipulation tasks. At its core, our approach iteratively improves a pretrained\nVLM with a \"reflection\" mechanism - it uses a generative model to imagine\nfuture world states, leverages these predictions to guide action selection, and\ncritically reflects on potential suboptimalities to refine its reasoning.\nExperimental results demonstrate that our method significantly outperforms\nseveral state-of-the-art commercial VLMs as well as other post-training\napproaches such as Monte Carlo Tree Search (MCTS). Videos are available at\nhttps://reflect-vlm.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16707v1",
    "published_date": "2025-02-23 20:42:15 UTC",
    "updated_date": "2025-02-23 20:42:15 UTC"
  },
  {
    "arxiv_id": "2502.18232v2",
    "title": "A Reverse Mamba Attention Network for Pathological Liver Segmentation",
    "authors": [
      "Jun Zeng",
      "Debesh Jha",
      "Ertugrul Aktas",
      "Elif Keles",
      "Alpay Medetalibeyoglu",
      "Matthew Antalek",
      "Robert Lewandowski",
      "Daniela Ladner",
      "Amir A. Borhani",
      "Gorkem Durak",
      "Ulas Bagci"
    ],
    "abstract": "We present RMA-Mamba, a novel architecture that advances the capabilities of\nvision state space models through a specialized reverse mamba attention module\n(RMA). The key innovation lies in RMA-Mamba's ability to capture long-range\ndependencies while maintaining precise local feature representation through its\nhierarchical processing pipeline. By integrating Vision Mamba (VMamba)'s\nefficient sequence modeling with RMA's targeted feature refinement, our\narchitecture achieves superior feature learning across multiple scales. This\ndual-mechanism approach enables robust handling of complex morphological\npatterns while maintaining computational efficiency. We demonstrate RMA-Mamba's\neffectiveness in the challenging domain of pathological liver segmentation\n(from both CT and MRI), where traditional segmentation approaches often fail\ndue to tissue variations. When evaluated on a newly introduced cirrhotic liver\ndataset (CirrMRI600+) of T2-weighted MRI scans, RMA-Mamba achieves the\nstate-of-the-art performance with a Dice coefficient of 92.08%, mean IoU of\n87.36%, and recall of 92.96%. The architecture's generalizability is further\nvalidated on the cancerous liver segmentation from CT scans (LiTS: Liver Tumor\nSegmentation dataset), yielding a Dice score of 92.9% and mIoU of 88.99%. Our\ncode is available for public: https://github.com/JunZengz/RMAMamba.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "8 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18232v2",
    "published_date": "2025-02-23 20:41:25 UTC",
    "updated_date": "2025-03-05 19:18:00 UTC"
  },
  {
    "arxiv_id": "2502.16706v1",
    "title": "DISC: Dynamic Decomposition Improves LLM Inference Scaling",
    "authors": [
      "Jonathan Light",
      "Wei Cheng",
      "Wu Yue",
      "Masafumi Oyamada",
      "Mengdi Wang",
      "Santiago Paternain",
      "Haifeng Chen"
    ],
    "abstract": "Many inference scaling methods work by breaking a problem into smaller steps\n(or groups of tokens), then sampling and choosing the best next step. However,\nthese steps and their sizes are usually predetermined based on human intuition\nor domain knowledge. This paper introduces dynamic decomposition, a method that\nautomatically and adaptively splits solution and reasoning traces into steps\nduring inference. This approach improves computational efficiency by focusing\nmore resources on difficult steps, breaking them down further and prioritizing\ntheir sampling. Experiments on coding and math benchmarks (APPS, MATH, and\nLiveCodeBench) show that dynamic decomposition performs better than static\nmethods, which rely on fixed steps like token-level, sentence-level, or\nsingle-step decompositions. These results suggest that dynamic decomposition\ncan enhance many inference scaling techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.SE",
      "I.2.6; I.2.7; I.2.8; D.2.3; F.2.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16706v1",
    "published_date": "2025-02-23 20:37:32 UTC",
    "updated_date": "2025-02-23 20:37:32 UTC"
  },
  {
    "arxiv_id": "2502.16705v1",
    "title": "Can ChatGPT Learn to Count Letters?",
    "authors": [
      "Javier Conde",
      "Gonzalo Martínez",
      "Pedro Reviriego",
      "Zhen Gao",
      "Shanshan Liu",
      "Fabrizio Lombardi"
    ],
    "abstract": "Large language models (LLMs) struggle on simple tasks such as counting the\nnumber of occurrences of a letter in a word. In this paper, we investigate if\nChatGPT can learn to count letters and propose an efficient solution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16705v1",
    "published_date": "2025-02-23 20:31:22 UTC",
    "updated_date": "2025-02-23 20:31:22 UTC"
  },
  {
    "arxiv_id": "2502.16704v1",
    "title": "Code Summarization Beyond Function Level",
    "authors": [
      "Vladimir Makharev",
      "Vladimir Ivanov"
    ],
    "abstract": "Code summarization is a critical task in natural language processing and\nsoftware engineering, which aims to generate concise descriptions of source\ncode. Recent advancements have improved the quality of these summaries,\nenhancing code readability and maintainability. However, the content of a\nrepository or a class has not been considered in function code summarization.\nThis study investigated the effectiveness of code summarization models beyond\nthe function level, exploring the impact of class and repository contexts on\nthe summary quality. The study involved revising benchmarks for evaluating\nmodels at class and repository levels, assessing baseline models, and\nevaluating LLMs with in-context learning to determine the enhancement of\nsummary quality with additional context. The findings revealed that the\nfine-tuned state-of-the-art CodeT5+ base model excelled in code summarization,\nwhile incorporating few-shot learning and retrieved code chunks from RAG\nsignificantly enhanced the performance of LLMs in this task. Notably, the\nDeepseek Coder 1.3B and Starcoder2 15B models demonstrated substantial\nimprovements in metrics such as BLEURT, METEOR, and BLEU-4 at both class and\nrepository levels. Repository-level summarization exhibited promising potential\nbut necessitates significant computational resources and gains from the\ninclusion of structured context. Lastly, we employed the recent SIDE code\nsummarization metric in our evaluation. This study contributes to refining\nstrategies for prompt engineering, few-shot learning, and RAG, addressing gaps\nin benchmarks for code summarization at various levels. Finally, we publish all\nstudy details, code, datasets, and results of evaluation in the GitHub\nrepository available at\nhttps://github.com/kilimanj4r0/code-summarization-beyond-function-level.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to LLM4Code @ ICSE'25; 8 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.16704v1",
    "published_date": "2025-02-23 20:31:21 UTC",
    "updated_date": "2025-02-23 20:31:21 UTC"
  },
  {
    "arxiv_id": "2502.18523v1",
    "title": "End-to-End Deep Learning for Structural Brain Imaging: A Unified Framework",
    "authors": [
      "Yao Su",
      "Keqi Han",
      "Mingjie Zeng",
      "Lichao Sun",
      "Liang Zhan",
      "Carl Yang",
      "Lifang He",
      "Xiangnan Kong"
    ],
    "abstract": "Brain imaging analysis is fundamental in neuroscience, providing valuable\ninsights into brain structure and function. Traditional workflows follow a\nsequential pipeline-brain extraction, registration, segmentation, parcellation,\nnetwork generation, and classification-treating each step as an independent\ntask. These methods rely heavily on task-specific training data and expert\nintervention to correct intermediate errors, making them particularly\nburdensome for high-dimensional neuroimaging data, where annotations and\nquality control are costly and time-consuming. We introduce UniBrain, a unified\nend-to-end framework that integrates all processing steps into a single\noptimization process, allowing tasks to interact and refine each other. Unlike\ntraditional approaches that require extensive task-specific annotations,\nUniBrain operates with minimal supervision, leveraging only low-cost labels\n(i.e., classification and extraction) and a single labeled atlas. By jointly\noptimizing extraction, registration, segmentation, parcellation, network\ngeneration, and classification, UniBrain enhances both accuracy and\ncomputational efficiency while significantly reducing annotation effort.\nExperimental results demonstrate its superiority over existing methods across\nmultiple tasks, offering a more scalable and reliable solution for neuroimaging\nanalysis. Our code and data can be found at\nhttps://github.com/Anonymous7852/UniBrain",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18523v1",
    "published_date": "2025-02-23 20:08:24 UTC",
    "updated_date": "2025-02-23 20:08:24 UTC"
  },
  {
    "arxiv_id": "2502.16701v2",
    "title": "Beyond Release: Access Considerations for Generative AI Systems",
    "authors": [
      "Irene Solaiman",
      "Rishi Bommasani",
      "Dan Hendrycks",
      "Ariel Herbert-Voss",
      "Yacine Jernite",
      "Aviya Skowron",
      "Andrew Trask"
    ],
    "abstract": "Generative AI release decisions determine whether system components are made\navailable, but release does not address many other elements that change how\nusers and stakeholders are able to engage with a system. Beyond release, access\nto system components informs potential risks and benefits. Access refers to\npractical needs, infrastructurally, technically, and societally, in order to\nuse available components in some way. We deconstruct access along three axes:\nresourcing, technical usability, and utility. Within each category, a set of\nvariables per system component clarify tradeoffs. For example, resourcing\nrequires access to computing infrastructure to serve model weights. We also\ncompare the accessibility of four high performance language models, two\nopen-weight and two closed-weight, showing similar considerations for all based\ninstead on access variables. Access variables set the foundation for being able\nto scale or increase access to users; we examine the scale of access and how\nscale affects ability to manage and intervene on risks. This framework better\nencompasses the landscape and risk-benefit tradeoffs of system releases to\ninform system release decisions, research, and policy.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16701v2",
    "published_date": "2025-02-23 20:06:12 UTC",
    "updated_date": "2025-04-11 07:07:21 UTC"
  },
  {
    "arxiv_id": "2502.16696v1",
    "title": "Dynamic LLM Routing and Selection based on User Preferences: Balancing Performance, Cost, and Ethics",
    "authors": [
      "Deepak Babu Piskala",
      "Vijay Raajaa",
      "Sachin Mishra",
      "Bruno Bozza"
    ],
    "abstract": "With the widespread deployment of large language models (LLMs) such as GPT4,\nBART, and LLaMA, the need for a system that can intelligently select the most\nsuitable model for specific tasks while balancing cost, latency, accuracy, and\nethical considerations has become increasingly important. Recognizing that not\nall tasks necessitate models with over 100 billion parameters, we introduce\nOptiRoute, an advanced model routing engine designed to dynamically select and\nroute tasks to the optimal LLM based on detailed user-defined requirements.\nOptiRoute captures both functional (e.g., accuracy, speed, cost) and\nnon-functional (e.g., helpfulness, harmlessness, honesty) criteria, leveraging\nlightweight task analysis and complexity estimation to efficiently match tasks\nwith the best-fit models from a diverse array of LLMs. By employing a hybrid\napproach combining k-nearest neighbors (kNN) search and hierarchical filtering,\nOptiRoute optimizes for user priorities while minimizing computational\noverhead. This makes it ideal for real-time applications in cloud-based ML\nplatforms, personalized AI services, and regulated industries.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16696v1",
    "published_date": "2025-02-23 19:23:22 UTC",
    "updated_date": "2025-02-23 19:23:22 UTC"
  },
  {
    "arxiv_id": "2502.17524v1",
    "title": "Multimodal Bearing Fault Classification Under Variable Conditions: A 1D CNN with Transfer Learning",
    "authors": [
      "Tasfiq E. Alam",
      "Md Manjurul Ahsan",
      "Shivakumar Raman"
    ],
    "abstract": "Bearings play an integral role in ensuring the reliability and efficiency of\nrotating machinery - reducing friction and handling critical loads. Bearing\nfailures that constitute up to 90% of mechanical faults highlight the\nimperative need for reliable condition monitoring and fault detection. This\nstudy proposes a multimodal bearing fault classification approach that relies\non vibration and motor phase current signals within a one-dimensional\nconvolutional neural network (1D CNN) framework. The method fuses features from\nmultiple signals to enhance the accuracy of fault detection. Under the baseline\ncondition (1,500 rpm, 0.7 Nm load torque, and 1,000 N radial force), the model\nreaches an accuracy of 96% with addition of L2 regularization. This represents\na notable improvement of 2% compared to the non-regularized model. In addition,\nthe model demonstrates robust performance across three distinct operating\nconditions by employing transfer learning (TL) strategies. Among the tested TL\nvariants, the approach that preserves parameters up to the first max-pool layer\nand then adjusts subsequent layers achieves the highest performance. While this\napproach attains excellent accuracy across varied conditions, it requires more\ncomputational time due to its greater number of trainable parameters. To\naddress resource constraints, less computationally intensive models offer\nfeasible trade-offs, albeit at a slight accuracy cost. Overall, this multimodal\n1D CNN framework with late fusion and TL strategies lays a foundation for more\naccurate, adaptable, and efficient bearing fault classification in industrial\nenvironments with variable operating conditions.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17524v1",
    "published_date": "2025-02-23 19:11:25 UTC",
    "updated_date": "2025-02-23 19:11:25 UTC"
  },
  {
    "arxiv_id": "2502.16690v1",
    "title": "From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task",
    "authors": [
      "Nicolas Martorell"
    ],
    "abstract": "Understanding how large language models (LLMs) represent and reason about\nspatial information is crucial for building robust agentic systems that can\nnavigate real and simulated environments. In this work, we investigate the\ninfluence of different text-based spatial representations on LLM performance\nand internal activations in a grid-world navigation task. By evaluating models\nof various sizes on a task that requires navigating toward a goal, we examine\nhow the format used to encode spatial information impacts decision-making. Our\nexperiments reveal that cartesian representations of space consistently yield\nhigher success rates and path efficiency, with performance scaling markedly\nwith model size. Moreover, probing LLaMA-3.1-8B revealed subsets of internal\nunits, primarily located in intermediate layers, that robustly correlate with\nspatial features, such as the position of the agent in the grid or action\ncorrectness, regardless of how that information is represented, and are also\nactivated by unrelated spatial reasoning tasks. This work advances our\nunderstanding of how LLMs process spatial information and provides valuable\ninsights for developing more interpretable and robust agentic AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16690v1",
    "published_date": "2025-02-23 19:09:01 UTC",
    "updated_date": "2025-02-23 19:09:01 UTC"
  },
  {
    "arxiv_id": "2502.16682v2",
    "title": "Automatic Input Rewriting Improves Translation with Large Language Models",
    "authors": [
      "Dayeon Ki",
      "Marine Carpuat"
    ],
    "abstract": "Can we improve machine translation (MT) with LLMs by rewriting their inputs\nautomatically? Users commonly rely on the intuition that well-written text is\neasier to translate when using off-the-shelf MT systems. LLMs can rewrite text\nin many ways but in the context of MT, these capabilities have been primarily\nexploited to rewrite outputs via post-editing. We present an empirical study of\n21 input rewriting methods with 3 open-weight LLMs for translating from English\ninto 6 target languages. We show that text simplification is the most effective\nMT-agnostic rewrite strategy and that it can be improved further when using\nquality estimation to assess translatability. Human evaluation further confirms\nthat simplified rewrites and their MT outputs both largely preserve the\noriginal meaning of the source and MT. These results suggest LLM-assisted input\nrewriting as a promising direction for improving translations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16682v2",
    "published_date": "2025-02-23 18:56:56 UTC",
    "updated_date": "2025-04-15 21:11:11 UTC"
  },
  {
    "arxiv_id": "2502.16681v1",
    "title": "Are Sparse Autoencoders Useful? A Case Study in Sparse Probing",
    "authors": [
      "Subhash Kantamneni",
      "Joshua Engels",
      "Senthooran Rajamanoharan",
      "Max Tegmark",
      "Neel Nanda"
    ],
    "abstract": "Sparse autoencoders (SAEs) are a popular method for interpreting concepts\nrepresented in large language model (LLM) activations. However, there is a lack\nof evidence regarding the validity of their interpretations due to the lack of\na ground truth for the concepts used by an LLM, and a growing number of works\nhave presented problems with current SAEs. One alternative source of evidence\nwould be demonstrating that SAEs improve performance on downstream tasks beyond\nexisting baselines. We test this by applying SAEs to the real-world task of LLM\nactivation probing in four regimes: data scarcity, class imbalance, label\nnoise, and covariate shift. Due to the difficulty of detecting concepts in\nthese challenging settings, we hypothesize that SAEs' basis of interpretable,\nconcept-level latents should provide a useful inductive bias. However, although\nSAEs occasionally perform better than baselines on individual datasets, we are\nunable to design ensemble methods combining SAEs with baselines that\nconsistently outperform ensemble methods solely using baselines. Additionally,\nalthough SAEs initially appear promising for identifying spurious correlations,\ndetecting poor dataset quality, and training multi-token probes, we are able to\nachieve similar results with simple non-SAE baselines as well. Though we cannot\ndiscount SAEs' utility on other tasks, our findings highlight the shortcomings\nof current SAEs and the need to rigorously evaluate interpretability methods on\ndownstream tasks with strong baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16681v1",
    "published_date": "2025-02-23 18:54:15 UTC",
    "updated_date": "2025-02-23 18:54:15 UTC"
  },
  {
    "arxiv_id": "2503.05760v4",
    "title": "The Lazy Student's Dream: ChatGPT Passing an Engineering Course on Its Own",
    "authors": [
      "Gokul Puthumanaillam",
      "Timothy Bretl",
      "Melkior Ornik"
    ],
    "abstract": "This paper presents a comprehensive investigation into the capability of\nLarge Language Models (LLMs) to successfully complete a semester-long\nundergraduate control systems course. Through evaluation of 115 course\ndeliverables, we assess LLM performance using ChatGPT under a \"minimal effort\"\nprotocol that simulates realistic student usage patterns. The investigation\nemploys a rigorous testing methodology across multiple assessment formats, from\nauto-graded multiple choice questions to complex Python programming tasks and\nlong-form analytical writing. Our analysis provides quantitative insights into\nAI's strengths and limitations in handling mathematical formulations, coding\nchallenges, and theoretical concepts in control systems engineering. The LLM\nachieved a B-grade performance (82.24\\%), approaching but not exceeding the\nclass average (84.99\\%), with strongest results in structured assignments and\ngreatest limitations in open-ended projects. The findings inform discussions\nabout course design adaptation in response to AI advancement, moving beyond\nsimple prohibition towards thoughtful integration of these tools in engineering\neducation. Additional materials including syllabus, examination papers, design\nprojects, and example responses can be found at the project website:\nhttps://gradegpt.github.io.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05760v4",
    "published_date": "2025-02-23 18:47:14 UTC",
    "updated_date": "2025-05-16 04:45:08 UTC"
  },
  {
    "arxiv_id": "2502.16671v1",
    "title": "MimeQA: Towards Socially-Intelligent Nonverbal Foundation Models",
    "authors": [
      "Hengzhi Li",
      "Megan Tjandrasuwita",
      "Yi R. Fung",
      "Armando Solar-Lezama",
      "Paul Pu Liang"
    ],
    "abstract": "Socially intelligent AI that can understand and interact seamlessly with\nhumans in daily lives is increasingly important as AI becomes more closely\nintegrated with peoples' daily activities. However, current works in artificial\nsocial reasoning all rely on language-only, or language-dominant approaches to\nbenchmark and training models, resulting in systems that are improving in\nverbal communication but struggle with nonverbal social understanding. To\naddress this limitation, we tap into a novel source of data rich in nonverbal\nand social interactions -- mime videos. Mimes refer to the art of expression\nthrough gesture and movement without spoken words, which presents unique\nchallenges and opportunities in interpreting non-verbal social communication.\nWe contribute a new dataset called MimeQA, obtained by sourcing 221 videos from\nYouTube, through rigorous annotation and verification, resulting in a benchmark\nwith 101 videos and 806 question-answer pairs. Using MimeQA, we evaluate\nstate-of-the-art video large language models (vLLMs) and find that their\noverall accuracy ranges from 15-30%. Our analysis reveals that vLLMs often fail\nto ground imagined objects and over-rely on the text prompt while ignoring\nsubtle nonverbal interactions. Our data resources are released at\nhttps://github.com/MIT-MI/MimeQA to inspire future work in foundation models\nthat embody true social intelligence capable of interpreting non-verbal human\ninteractions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16671v1",
    "published_date": "2025-02-23 18:05:49 UTC",
    "updated_date": "2025-02-23 18:05:49 UTC"
  },
  {
    "arxiv_id": "2503.11666v1",
    "title": "Optimizing Coverage-Driven Verification Using Machine Learning and PyUVM: A Novel Approach",
    "authors": [
      "Suruchi Kumari",
      "Deepak Narayan Gadde",
      "Aman Kumar"
    ],
    "abstract": "The escalating complexity of System-on-Chip (SoC) designs has created a\nbottleneck in verification, with traditional techniques struggling to achieve\ncomplete coverage. Existing techniques, such as Constrained Random Verification\n(CRV) and coverage-driven methodologies, rely on time-consuming and redundant\nsimulation regression, leading to higher verification costs and longer\ntime-to-market due to the manual effort required to adjust constraints and\ndrive the stimuli to achieve coverage objectives. To address this challenge, we\npropose a novel methodology that leverages supervised Machine Learning (ML) to\noptimize simulation regressions, resulting in reduced simulation run-time and\nthe number of test simulations required to achieve target coverage goals. We\nalso investigate and compare the effectiveness of various supervised learning\nalgorithms from scikit-learn. Our results demonstrate that these algorithms can\nachieve at least 99% coverage regain with significantly reduced simulation\ncycles. We utilize Python Universal Verification Methodology (PyUVM) over\nSystemVerilog-Universal Verification Methodology (SV-UVM) for testbench\ncreation, enabling simpler constructs using Python and facilitating the reuse\nof existing ML libraries. Our methodology is applied to three diverse designs,\nand our results show that it can significantly reduce verification costs,\nmanual efforts, and time-to-market, while enhancing verification productivity\nand completeness, by automating the testbench update process and achieving\ntarget coverage goals.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear at 2025 IEEE International Symposium on Circuits and\n  Systems, May 25-28 2025, London, United Kingdom",
    "pdf_url": "http://arxiv.org/pdf/2503.11666v1",
    "published_date": "2025-02-23 17:54:23 UTC",
    "updated_date": "2025-02-23 17:54:23 UTC"
  },
  {
    "arxiv_id": "2502.16666v1",
    "title": "SBSC: Step-By-Step Coding for Improving Mathematical Olympiad Performance",
    "authors": [
      "Kunal Singh",
      "Ankan Biswas",
      "Sayandeep Bhowmick",
      "Pradeep Moturi",
      "Siva Kishore Gollapalli"
    ],
    "abstract": "We propose Step-by-Step Coding (SBSC): a multi-turn math reasoning framework\nthat enables Large Language Models (LLMs) to generate sequence of programs for\nsolving Olympiad level math problems. At each step/turn, by leveraging the code\nexecution outputs and programs of previous steps, the model generates the next\nsub-task and the corresponding program to solve it. This way, SBSC,\nsequentially navigates to reach the final answer. SBSC allows more granular,\nflexible and precise approach to problem-solving compared to existing methods.\nExtensive experiments highlight the effectiveness of SBSC in tackling\ncompetition and Olympiad-level math problems. For Claude-3.5-Sonnet, we observe\nSBSC (greedy decoding) surpasses existing state-of-the-art (SOTA) program\ngeneration based reasoning strategies by absolute 10.7% on AMC12, 8% on AIME\nand 12.6% on MathOdyssey. Given SBSC is multi-turn in nature, we also benchmark\nSBSC's greedy decoding against self-consistency decoding results of existing\nSOTA math reasoning strategies and observe performance gain by absolute 6.2% on\nAMC, 6.7% on AIME and 7.4% on MathOdyssey.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a full conference paper at ICLR 2025. Shorter(Early)\n  Version accepted at NeurIPS'24 MATH-AI track",
    "pdf_url": "http://arxiv.org/pdf/2502.16666v1",
    "published_date": "2025-02-23 17:51:26 UTC",
    "updated_date": "2025-02-23 17:51:26 UTC"
  },
  {
    "arxiv_id": "2502.16662v2",
    "title": "Saarthi: The First AI Formal Verification Engineer",
    "authors": [
      "Aman Kumar",
      "Deepak Narayan Gadde",
      "Keerthan Kopparam Radhakrishna",
      "Djones Lettnin"
    ],
    "abstract": "Recently, Devin has made a significant buzz in the Artificial Intelligence\n(AI) community as the world's first fully autonomous AI software engineer,\ncapable of independently developing software code. Devin uses the concept of\nagentic workflow in Generative AI (GenAI), which empowers AI agents to engage\nin a more dynamic, iterative, and self-reflective process. In this paper, we\npresent a similar fully autonomous AI formal verification engineer, Saarthi,\ncapable of verifying a given RTL design end-to-end using an agentic workflow.\nWith Saarthi, verification engineers can focus on more complex problems, and\nverification teams can strive for more ambitious goals. The domain-agnostic\nimplementation of Saarthi makes it scalable for use across various domains such\nas RTL design, UVM-based verification, and others.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at the DVCon U.S. 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16662v2",
    "published_date": "2025-02-23 17:42:50 UTC",
    "updated_date": "2025-03-01 13:02:14 UTC"
  },
  {
    "arxiv_id": "2502.16660v4",
    "title": "BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning",
    "authors": [
      "Haiteng Zhao",
      "Chang Ma",
      "Fangzhi Xu",
      "Lingpeng Kong",
      "Zhi-Hong Deng"
    ],
    "abstract": "The applications of large language models (LLMs) in various biological\ndomains have been explored recently, but their reasoning ability in complex\nbiological systems, such as pathways, remains underexplored, which is crucial\nfor predicting biological phenomena, formulating hypotheses, and designing\nexperiments. This work explores the potential of LLMs in pathway reasoning. We\nintroduce BioMaze, a dataset with 5.1K complex pathway problems derived from\nreal research, covering various biological contexts including natural dynamic\nchanges, disturbances, additional intervention conditions, and multi-scale\nresearch targets. Our evaluation of methods such as CoT and graph-augmented\nreasoning, shows that LLMs struggle with pathway reasoning, especially in\nperturbed systems. To address this, we propose PathSeeker, an LLM agent that\nenhances reasoning through interactive subgraph-based navigation, enabling a\nmore effective approach to handling the complexities of biological systems in a\nscientifically aligned manner. The dataset and code are available at\nhttps://github.com/zhao-ht/BioMaze.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16660v4",
    "published_date": "2025-02-23 17:38:10 UTC",
    "updated_date": "2025-04-16 16:49:34 UTC"
  },
  {
    "arxiv_id": "2502.16648v1",
    "title": "Few-shot Continual Relation Extraction via Open Information Extraction",
    "authors": [
      "Thiem Nguyen",
      "Anh Nguyen",
      "Quyen Tran",
      "Tu Vu",
      "Diep Nguyen",
      "Linh Ngo",
      "Thien Nguyen"
    ],
    "abstract": "Typically, Few-shot Continual Relation Extraction (FCRE) models must balance\nretaining prior knowledge while adapting to new tasks with extremely limited\ndata. However, real-world scenarios may also involve unseen or undetermined\nrelations that existing methods still struggle to handle. To address these\nchallenges, we propose a novel approach that leverages the Open Information\nExtraction concept of Knowledge Graph Construction (KGC). Our method not only\nexposes models to all possible pairs of relations, including determined and\nundetermined labels not available in the training set, but also enriches model\nknowledge with diverse relation descriptions, thereby enhancing knowledge\nretention and adaptability in this challenging scenario. In the perspective of\nKGC, this is the first work explored in the setting of Continual Learning,\nallowing efficient expansion of the graph as the data evolves. Experimental\nresults demonstrate our superior performance compared to other state-of-the-art\nFCRE baselines, as well as the efficiency in handling dynamic graph\nconstruction in this setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16648v1",
    "published_date": "2025-02-23 16:52:59 UTC",
    "updated_date": "2025-02-23 16:52:59 UTC"
  },
  {
    "arxiv_id": "2502.16645v1",
    "title": "CODESYNC: Synchronizing Large Language Models with Dynamic Code Evolution at Scale",
    "authors": [
      "Chenlong Wang",
      "Zhaoyang Chu",
      "Zhengxiang Cheng",
      "Xuyi Yang",
      "Kaiyue Qiu",
      "Yao Wan",
      "Zhou Zhao",
      "Xuanhua Shi",
      "Dongping Chen"
    ],
    "abstract": "Large Language Models (LLMs) have exhibited exceptional performance in\nsoftware engineering yet face challenges in adapting to continually evolving\ncode knowledge, particularly regarding the frequent updates of third-party\nlibrary APIs. This limitation, stemming from static pre-training datasets,\noften results in non-executable code or implementations with suboptimal safety\nand efficiency. To this end, this paper introduces CODESYNC, a data engine for\nidentifying outdated code patterns and collecting real-time code knowledge\nupdates from Python third-party libraries. Building upon CODESYNC, we develop\nCODESYNCBENCH, a comprehensive benchmark for assessing LLMs' ability to stay\nsynchronized with code evolution, which covers real-world updates for 220 APIs\nfrom six Python libraries. Our benchmark offers 3,300 test cases across three\nevaluation tasks and an update-aware instruction tuning dataset consisting of\n2,200 training samples. Extensive experiments on 14 state-of-the-art LLMs\nreveal that they struggle with dynamic code evolution, even with the support of\nadvanced knowledge updating methods (e.g., DPO, ORPO, and SimPO). We believe\nthat our benchmark can offer a strong foundation for the development of more\neffective methods for real-time code knowledge updating in the future. The\nexperimental code and dataset are publicly available at:\nhttps://github.com/Lucky-voyage/Code-Sync.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16645v1",
    "published_date": "2025-02-23 16:46:18 UTC",
    "updated_date": "2025-02-23 16:46:18 UTC"
  },
  {
    "arxiv_id": "2502.16638v1",
    "title": "Automatic Joint Structured Pruning and Quantization for Efficient Neural Network Training and Compression",
    "authors": [
      "Xiaoyi Qu",
      "David Aponte",
      "Colby Banbury",
      "Daniel P. Robinson",
      "Tianyu Ding",
      "Kazuhito Koishida",
      "Ilya Zharkov",
      "Tianyi Chen"
    ],
    "abstract": "Structured pruning and quantization are fundamental techniques used to reduce\nthe size of deep neural networks (DNNs) and typically are applied\nindependently. Applying these techniques jointly via co-optimization has the\npotential to produce smaller, high-quality models. However, existing joint\nschemes are not widely used because of (1) engineering difficulties\n(complicated multi-stage processes), (2) black-box optimization (extensive\nhyperparameter tuning to control the overall compression), and (3) insufficient\narchitecture generalization. To address these limitations, we present the\nframework GETA, which automatically and efficiently performs joint structured\npruning and quantization-aware training on any DNNs. GETA introduces three key\ninnovations: (i) a quantization-aware dependency graph (QADG) that constructs a\npruning search space for generic quantization-aware DNN, (ii) a partially\nprojected stochastic gradient method that guarantees layerwise bit constraints\nare satisfied, and (iii) a new joint learning strategy that incorporates\ninterpretable relationships between pruning and quantization. We present\nnumerical experiments on both convolutional neural networks and transformer\narchitectures that show that our approach achieves competitive (often superior)\nperformance compared to existing joint pruning and quantization methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16638v1",
    "published_date": "2025-02-23 16:28:18 UTC",
    "updated_date": "2025-02-23 16:28:18 UTC"
  },
  {
    "arxiv_id": "2502.16637v1",
    "title": "Time Series Domain Adaptation via Latent Invariant Causal Mechanism",
    "authors": [
      "Ruichu Cai",
      "Junxian Huang",
      "Zhenhui Yang",
      "Zijian Li",
      "Emadeldeen Eldele",
      "Min Wu",
      "Fuchun Sun"
    ],
    "abstract": "Time series domain adaptation aims to transfer the complex temporal\ndependence from the labeled source domain to the unlabeled target domain.\nRecent advances leverage the stable causal mechanism over observed variables to\nmodel the domain-invariant temporal dependence. However, modeling precise\ncausal structures in high-dimensional data, such as videos, remains\nchallenging. Additionally, direct causal edges may not exist among observed\nvariables (e.g., pixels). These limitations hinder the applicability of\nexisting approaches to real-world scenarios. To address these challenges, we\nfind that the high-dimension time series data are generated from the\nlow-dimension latent variables, which motivates us to model the causal\nmechanisms of the temporal latent process. Based on this intuition, we propose\na latent causal mechanism identification framework that guarantees the\nuniqueness of the reconstructed latent causal structures. Specifically, we\nfirst identify latent variables by utilizing sufficient changes in historical\ninformation. Moreover, by enforcing the sparsity of the relationships of latent\nvariables, we can achieve identifiable latent causal structures. Built on the\ntheoretical results, we develop the Latent Causality Alignment (LCA) model that\nleverages variational inference, which incorporates an intra-domain latent\nsparsity constraint for latent structure reconstruction and an inter-domain\nlatent sparsity constraint for domain-invariant structure reconstruction.\nExperiment results on eight benchmarks show a general improvement in the\ndomain-adaptive time series classification and forecasting tasks, highlighting\nthe effectiveness of our method in real-world scenarios. Codes are available at\nhttps://github.com/DMIRLAB-Group/LCA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16637v1",
    "published_date": "2025-02-23 16:25:58 UTC",
    "updated_date": "2025-02-23 16:25:58 UTC"
  },
  {
    "arxiv_id": "2502.16634v3",
    "title": "OptionZero: Planning with Learned Options",
    "authors": [
      "Po-Wei Huang",
      "Pei-Chiun Peng",
      "Hung Guei",
      "Ti-Rong Wu"
    ],
    "abstract": "Planning with options -- a sequence of primitive actions -- has been shown\neffective in reinforcement learning within complex environments. Previous\nstudies have focused on planning with predefined options or learned options\nthrough expert demonstration data. Inspired by MuZero, which learns superhuman\nheuristics without any human knowledge, we propose a novel approach, named\nOptionZero. OptionZero incorporates an option network into MuZero, providing\nautonomous discovery of options through self-play games. Furthermore, we modify\nthe dynamics network to provide environment transitions when using options,\nallowing searching deeper under the same simulation constraints. Empirical\nexperiments conducted in 26 Atari games demonstrate that OptionZero outperforms\nMuZero, achieving a 131.58% improvement in mean human-normalized score. Our\nbehavior analysis shows that OptionZero not only learns options but also\nacquires strategic skills tailored to different game characteristics. Our\nfindings show promising directions for discovering and using options in\nplanning. Our code is available at\nhttps://rlg.iis.sinica.edu.tw/papers/optionzero.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the Thirteenth International Conference on Learning\n  Representations (ICLR 2025) as oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2502.16634v3",
    "published_date": "2025-02-23 16:20:15 UTC",
    "updated_date": "2025-03-21 13:30:42 UTC"
  },
  {
    "arxiv_id": "2502.16627v4",
    "title": "Energy-Efficient Transformer Inference: Optimization Strategies for Time Series Classification",
    "authors": [
      "Arshia Kermani",
      "Ehsan Zeraatkar",
      "Habib Irani"
    ],
    "abstract": "The increasing computational demands of transformer models in time series\nclassification necessitate effective optimization strategies for\nenergy-efficient deployment. Our study presents a systematic investigation of\noptimization techniques, focusing on structured pruning and quantization\nmethods for transformer architectures. Through extensive experimentation on\nthree distinct datasets (RefrigerationDevices, ElectricDevices, and PLAID), we\nquantitatively evaluate model performance and energy efficiency across\ndifferent transformer configurations. Our experimental results demonstrate that\nstatic quantization reduces energy consumption by 29.14% while maintaining\nclassification performance, and L1 pruning achieves a 63% improvement in\ninference speed with minimal accuracy degradation. Our findings provide\nvaluable insights into the effectiveness of optimization strategies for\ntransformer-based time series classification, establishing a foundation for\nefficient model deployment in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16627v4",
    "published_date": "2025-02-23 16:04:56 UTC",
    "updated_date": "2025-05-21 00:52:31 UTC"
  },
  {
    "arxiv_id": "2503.16460v1",
    "title": "Beyond Final Answers: Evaluating Large Language Models for Math Tutoring",
    "authors": [
      "Adit Gupta",
      "Jennifer Reddig",
      "Tommaso Calo",
      "Daniel Weitekamp",
      "Christopher J. MacLellan"
    ],
    "abstract": "Researchers have made notable progress in applying Large Language Models\n(LLMs) to solve math problems, as demonstrated through efforts like GSM8k,\nProofNet, AlphaGeometry, and MathOdyssey. This progress has sparked interest in\ntheir potential use for tutoring students in mathematics. However, the\nreliability of LLMs in tutoring contexts -- where correctness and instructional\nquality are crucial -- remains underexplored. Moreover, LLM problem-solving\ncapabilities may not necessarily translate into effective tutoring support for\nstudents. In this work, we present two novel approaches to evaluate the\ncorrectness and quality of LLMs in math tutoring contexts. The first approach\nuses an intelligent tutoring system for college algebra as a testbed to assess\nLLM problem-solving capabilities. We generate benchmark problems using the\ntutor, prompt a diverse set of LLMs to solve them, and compare the solutions to\nthose generated by the tutor. The second approach evaluates LLM as tutors\nrather than problem solvers. We employ human evaluators, who act as students\nseeking tutoring support from each LLM. We then assess the quality and\ncorrectness of the support provided by the LLMs via a qualitative coding\nprocess. We applied these methods to evaluate several ChatGPT models, including\n3.5 Turbo, 4, 4o, o1-mini, and o1-preview. Our findings show that when used as\nproblem solvers, LLMs generate correct final answers for 85.5% of the college\nalgebra problems tested. When employed interactively as tutors, 90% of LLM\ndialogues show high-quality instructional support; however, many contain errors\n-- only 56.6% are entirely correct. We conclude that, despite their potential,\nLLMs are not yet suitable as intelligent tutors for math without human\noversight or additional mechanisms to ensure correctness and quality.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16460v1",
    "published_date": "2025-02-23 15:43:45 UTC",
    "updated_date": "2025-02-23 15:43:45 UTC"
  },
  {
    "arxiv_id": "2502.16618v1",
    "title": "Can Large Vision-Language Models Detect Images Copyright Infringement from GenAI?",
    "authors": [
      "Qipan Xu",
      "Zhenting Wang",
      "Xiaoxiao He",
      "Ligong Han",
      "Ruixiang Tang"
    ],
    "abstract": "Generative AI models, renowned for their ability to synthesize high-quality\ncontent, have sparked growing concerns over the improper generation of\ncopyright-protected material. While recent studies have proposed various\napproaches to address copyright issues, the capability of large vision-language\nmodels (LVLMs) to detect copyright infringements remains largely unexplored. In\nthis work, we focus on evaluating the copyright detection abilities of\nstate-of-the-art LVLMs using a various set of image samples. Recognizing the\nabsence of a comprehensive dataset that includes both IP-infringement samples\nand ambiguous non-infringement negative samples, we construct a benchmark\ndataset comprising positive samples that violate the copyright protection of\nwell-known IP figures, as well as negative samples that resemble these figures\nbut do not raise copyright concerns. This dataset is created using advanced\nprompt engineering techniques. We then evaluate leading LVLMs using our\nbenchmark dataset. Our experimental results reveal that LVLMs are prone to\noverfitting, leading to the misclassification of some negative samples as\nIP-infringement cases. In the final section, we analyze these failure cases and\npropose potential solutions to mitigate the overfitting problem.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16618v1",
    "published_date": "2025-02-23 15:41:12 UTC",
    "updated_date": "2025-02-23 15:41:12 UTC"
  },
  {
    "arxiv_id": "2502.16613v1",
    "title": "Intelligent Tutors Beyond K-12: An Observational Study of Adult Learner Engagement and Academic Impact",
    "authors": [
      "Adit Gupta",
      "Christopher MacLellan"
    ],
    "abstract": "Intelligent tutors have proven to be effective in K-12 education, though\ntheir impact on adult learners -- especially as a supplementary resource --\nremains underexplored. Understanding how adults voluntarily engage with\neducational technologies can inform the design of tools that support skill\nre-learning and enhancement. More critically, it helps determine whether\ntutoring systems, which are typically built for K-12 learners, can also support\nadult populations. This study examines the adoption, usage patterns, and\neffectiveness of a novel tutoring system, Apprentice Tutors, among adult\nlearners at a state technical college. We analyze three types of data\nincluding, user demographics, grades, and tutor interactions, to assess whether\nvoluntary tutor usage translates into measurable learning gains. Our findings\nreveal key temporal patterns in tutor engagement and provide evidence of\nlearning within tutors, as determined through skill improvement in knowledge\ncomponents across tutors. We also found evidence that this learning transferred\noutside the tutor, as observed through higher course assessment scores\nfollowing tutor usage. These results suggest that intelligent tutors are a\nviable tool for adult learners, warranting further research into their\nlong-term impact on this population.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16613v1",
    "published_date": "2025-02-23 15:36:22 UTC",
    "updated_date": "2025-02-23 15:36:22 UTC"
  },
  {
    "arxiv_id": "2502.16612v1",
    "title": "MemeIntel: Explainable Detection of Propagandistic and Hateful Memes",
    "authors": [
      "Mohamed Bayan Kmainasi",
      "Abul Hasnat",
      "Md Arid Hasan",
      "Ali Ezzat Shahroor",
      "Firoj Alam"
    ],
    "abstract": "The proliferation of multimodal content on social media presents significant\nchallenges in understanding and moderating complex, context-dependent issues\nsuch as misinformation, hate speech, and propaganda. While efforts have been\nmade to develop resources and propose new methods for automatic detection,\nlimited attention has been given to label detection and the generation of\nexplanation-based rationales for predicted labels. To address this challenge,\nwe introduce MemeIntel, an explanation-enhanced dataset for propaganda memes in\nArabic and hateful memes in English, making it the first large-scale resource\nfor these tasks. To solve these tasks, we propose a multi-stage optimization\napproach and train Vision-Language Models (VLMs). Our results demonstrate that\nthis approach significantly improves performance over the base model for both\n\\textbf{label detection} and explanation generation, outperforming the current\nstate-of-the-art with an absolute improvement of ~3% on ArMeme and ~7% on\nHateful Memes. For reproducibility and future research, we aim to make the\nMemeIntel dataset and experimental resources publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, hateful meme, multimodality, text, images",
    "pdf_url": "http://arxiv.org/pdf/2502.16612v1",
    "published_date": "2025-02-23 15:35:48 UTC",
    "updated_date": "2025-02-23 15:35:48 UTC"
  },
  {
    "arxiv_id": "2502.16611v1",
    "title": "Target Speaker Extraction through Comparing Noisy Positive and Negative Audio Enrollments",
    "authors": [
      "Shitong Xu",
      "Yiyuan Yang",
      "Niki Trigoni",
      "Andrew Markham"
    ],
    "abstract": "Target speaker extraction focuses on isolating a specific speaker's voice\nfrom an audio mixture containing multiple speakers. To provide information\nabout the target speaker's identity, prior works have utilized clean audio\nexamples as conditioning inputs. However, such clean audio examples are not\nalways readily available (e.g. It is impractical to obtain a clean audio\nexample of a stranger's voice at a cocktail party without stepping away from\nthe noisy environment). Limited prior research has explored extracting the\ntarget speaker's characteristics from noisy audio examples, which may include\noverlapping speech from disturbing speakers. In this work, we focus on target\nspeaker extraction when multiple speakers are present during the enrollment\nstage, through leveraging differences between audio segments where the target\nspeakers are speaking (Positive Enrollments) and segments where they are not\n(Negative Enrollments). Experiments show the effectiveness of our model\narchitecture and the dedicated pretraining method for the proposed task. Our\nmethod achieves state-of-the-art performance in the proposed application\nsettings and demonstrates strong generalizability across challenging and\nrealistic scenarios.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "16 pages, 5 figures, appendix included",
    "pdf_url": "http://arxiv.org/pdf/2502.16611v1",
    "published_date": "2025-02-23 15:33:44 UTC",
    "updated_date": "2025-02-23 15:33:44 UTC"
  },
  {
    "arxiv_id": "2502.16610v1",
    "title": "AdverX-Ray: Ensuring X-Ray Integrity Through Frequency-Sensitive Adversarial VAEs",
    "authors": [
      "Francisco Caetano",
      "Christiaan Viviers",
      "Lena Filatova",
      "Peter H. N. de With",
      "Fons van der Sommen"
    ],
    "abstract": "Ensuring the quality and integrity of medical images is crucial for\nmaintaining diagnostic accuracy in deep learning-based Computer-Aided Diagnosis\nand Computer-Aided Detection (CAD) systems. Covariate shifts are subtle\nvariations in the data distribution caused by different imaging devices or\nsettings and can severely degrade model performance, similar to the effects of\nadversarial attacks. Therefore, it is vital to have a lightweight and fast\nmethod to assess the quality of these images prior to using CAD models.\nAdverX-Ray addresses this need by serving as an image-quality assessment layer,\ndesigned to detect covariate shifts effectively. This Adversarial Variational\nAutoencoder prioritizes the discriminator's role, using the suboptimal outputs\nof the generator as negative samples to fine-tune the discriminator's ability\nto identify high-frequency artifacts. Images generated by adversarial networks\noften exhibit severe high-frequency artifacts, guiding the discriminator to\nfocus excessively on these components. This makes the discriminator ideal for\nthis approach. Trained on patches from X-ray images of specific machine models,\nAdverX-Ray can evaluate whether a scan matches the training distribution, or if\na scan from the same machine is captured under different settings. Extensive\ncomparisons with various OOD detection methods show that AdverX-Ray\nsignificantly outperforms existing techniques, achieving a 96.2% average AUROC\nusing only 64 random patches from an X-ray. Its lightweight and fast\narchitecture makes it suitable for real-time applications, enhancing the\nreliability of medical imaging systems. The code and pretrained models are\npublicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "SPIE Medical Imaging 2025 Runner-up 2025 Robert F. Wagner\n  All-Conference Best Student Paper Award",
    "pdf_url": "http://arxiv.org/pdf/2502.16610v1",
    "published_date": "2025-02-23 15:32:40 UTC",
    "updated_date": "2025-02-23 15:32:40 UTC"
  },
  {
    "arxiv_id": "2502.16608v1",
    "title": "Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control",
    "authors": [
      "Yuli Zhang",
      "Shangbo Wang",
      "Dongyao Jia",
      "Pengfei Fan",
      "Ruiyuan Jiang",
      "Hankang Gu",
      "Andy H. F. Chow"
    ],
    "abstract": "Reinforcement learning (RL) emerges as a promising data-driven approach for\nadaptive traffic signal control (ATSC) in complex urban traffic networks, with\ndeep neural networks substantially augmenting its learning capabilities.\nHowever, centralized RL becomes impractical for ATSC involving multiple agents\ndue to the exceedingly high dimensionality of the joint action space.\nMulti-agent RL (MARL) mitigates this scalability issue by decentralizing\ncontrol to local RL agents. Nevertheless, this decentralized method introduces\nnew challenges: the environment becomes partially observable from the\nperspective of each local agent due to constrained inter-agent communication.\nBoth centralized RL and MARL exhibit distinct strengths and weaknesses,\nparticularly under heavy intersectional traffic conditions. In this paper, we\njustify that MARL can achieve the optimal global Q-value by separating into\nmultiple IRL (Independent Reinforcement Learning) processes when no spill-back\ncongestion occurs (no agent dependency) among agents (intersections). In the\npresence of spill-back congestion (with agent dependency), the maximum global\nQ-value can be achieved by using centralized RL. Building upon the conclusions,\nwe propose a novel Dynamic Parameter Update Strategy for Deep Q-Network\n(DQN-DPUS), which updates the weights and bias based on the dependency dynamics\namong agents, i.e. updating only the diagonal sub-matrices for the scenario\nwithout spill-back congestion. We validate the DQN-DPUS in a simple network\nwith two intersections under varying traffic, and show that the proposed\nstrategy can speed up the convergence rate without sacrificing optimal\nexploration. The results corroborate our theoretical findings, demonstrating\nthe efficacy of DQN-DPUS in optimizing traffic signal control.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16608v1",
    "published_date": "2025-02-23 15:29:12 UTC",
    "updated_date": "2025-02-23 15:29:12 UTC"
  },
  {
    "arxiv_id": "2502.16606v1",
    "title": "Reasoning about Affordances: Causal and Compositional Reasoning in LLMs",
    "authors": [
      "Magnus F. Gjerde",
      "Vanessa Cheung",
      "David Lagnado"
    ],
    "abstract": "With the rapid progress of Large Language Models (LLMs), it becomes\nincreasingly important to understand their abilities and limitations. In two\nexperiments, we investigate the causal and compositional reasoning abilities of\nLLMs and humans in the domain of object affordances, an area traditionally\nlinked to embodied cognition. The tasks, designed from scratch to avoid data\ncontamination, require decision-makers to select unconventional objects to\nreplace a typical tool for a particular purpose, such as using a table tennis\nracket to dig a hole. In Experiment 1, we evaluated GPT-3.5 and GPT-4o, finding\nthat GPT-4o, when given chain-of-thought prompting, performed on par with human\nparticipants, while GPT-3.5 lagged significantly. In Experiment 2, we\nintroduced two new conditions, Distractor (more object choices, increasing\ndifficulty) and Image (object options presented visually), and evaluated Claude\n3 Sonnet and Claude 3.5 Sonnet in addition to the GPT models. The Distractor\ncondition significantly impaired performance across humans and models, although\nGPT-4o and Claude 3.5 still performed well above chance. Surprisingly, the\nImage condition had little impact on humans or GPT-4o, but significantly\nlowered Claude 3.5's accuracy. Qualitative analysis showed that GPT-4o and\nClaude 3.5 have a stronger ability than their predecessors to identify and\nflexibly apply causally relevant object properties. The improvement from\nGPT-3.5 and Claude 3 to GPT-4o and Claude 3.5 suggests that models are\nincreasingly capable of causal and compositional reasoning in some domains,\nalthough further mechanistic research is necessary to understand how LLMs\nreason.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.16606v1",
    "published_date": "2025-02-23 15:21:47 UTC",
    "updated_date": "2025-02-23 15:21:47 UTC"
  },
  {
    "arxiv_id": "2502.16602v1",
    "title": "VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs",
    "authors": [
      "Yiming Yang",
      "Yangyang Guo",
      "Hui Lu",
      "Yan Wang"
    ],
    "abstract": "Recently, Large Vision-Language Models (LVLMs) have made significant strides\nacross diverse multimodal tasks and benchmarks. This paper reveals a largely\nunder-explored problem from existing video-involved LVLMs - language bias,\nwhere models tend to prioritize language over video and thus result in\nincorrect responses. To address this research gap, we first collect a Video\nLanguage Bias Evaluation Benchmark, which is specifically designed to assess\nthe language bias in video-involved LVLMs through two key tasks: ambiguous\nvideo contrast and interrogative question probing. Accordingly, we design\naccompanied evaluation metrics that aim to penalize LVLMs being biased by\nlanguage. In addition, we also propose Multi-branch Contrastive Decoding (MCD),\nintroducing two expert branches to simultaneously counteract language bias\npotentially generated by the amateur text-only branch. Our experiments\ndemonstrate that i) existing video-involved LVLMs, including both proprietary\nand open-sourced, are largely limited by the language bias problem; ii) our MCD\ncan effectively mitigate this issue and maintain general-purpose capabilities\nin various video-involved LVLMs without any additional retraining or alteration\nto model architectures.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16602v1",
    "published_date": "2025-02-23 15:04:23 UTC",
    "updated_date": "2025-02-23 15:04:23 UTC"
  },
  {
    "arxiv_id": "2502.16593v1",
    "title": "Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images",
    "authors": [
      "Yubo Wang",
      "Jianting Tang",
      "Chaohu Liu",
      "Linli Xu"
    ],
    "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable image\nunderstanding and dialogue capabilities, allowing them to handle a variety of\nvisual question answering tasks. However, their widespread availability raises\nconcerns about unauthorized usage and copyright infringement, where users or\nindividuals can develop their own LVLMs by fine-tuning published models. In\nthis paper, we propose a novel method called Parameter Learning Attack (PLA)\nfor tracking the copyright of LVLMs without modifying the original model.\nSpecifically, we construct adversarial images through targeted attacks against\nthe original model, enabling it to generate specific outputs. To ensure these\nattacks remain effective on potential fine-tuned models to trigger copyright\ntracking, we allow the original model to learn the trigger images by updating\nparameters in the opposite direction during the adversarial attack process.\nNotably, the proposed method can be applied after the release of the original\nmodel, thus not affecting the model's performance and behavior. To simulate\nreal-world applications, we fine-tune the original model using various\nstrategies across diverse datasets, creating a range of models for copyright\nverification. Extensive experiments demonstrate that our method can more\neffectively identify the original copyright of fine-tuned models compared to\nbaseline methods. Therefore, this work provides a powerful tool for tracking\ncopyrights and detecting unlicensed usage of LVLMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16593v1",
    "published_date": "2025-02-23 14:49:34 UTC",
    "updated_date": "2025-02-23 14:49:34 UTC"
  },
  {
    "arxiv_id": "2503.04780v1",
    "title": "MV-CLAM: Multi-View Molecular Interpretation with Cross-Modal Projection via Language Model",
    "authors": [
      "Sumin Ha",
      "Jun Hyeong Kim",
      "Yinhua Piao",
      "Sun Kim"
    ],
    "abstract": "Human expertise in chemistry and biomedicine relies on contextual molecular\nunderstanding, a capability that large language models (LLMs) can extend\nthrough fine-grained alignment between molecular structures and text. Recent\nmultimodal learning advances focus on cross-modal alignment, but existing\nmolecule-text models ignore complementary information in different molecular\nviews and rely on single-view representations, limiting molecular\nunderstanding. Moreover, na\\\"ive multi-view alignment strategies face two\nchallenges: (1) separate aligned spaces with inconsistent mappings between\nmolecule and text embeddings, and that (2) existing loss objectives fail to\npreserve complementary information for fine-grained alignment. This can limit\nthe LLM's ability to fully understand the molecular properties. To address\nthese issues, we propose MV-CLAM, a novel framework that aligns multi-view\nmolecular representations into a unified textual space using a multi-query\ntransformer (MQ-Former). Our approach ensures cross-view consistency while a\ntoken-level contrastive loss preserves diverse molecular features across\ntextual queries. MV-CLAM enhances molecular reasoning, improving retrieval and\ncaptioning accuracy. The source code of MV-CLAM is available in\nhttps://github.com/sumin124/mv-clam.git.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.atom-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04780v1",
    "published_date": "2025-02-23 14:38:29 UTC",
    "updated_date": "2025-02-23 14:38:29 UTC"
  },
  {
    "arxiv_id": "2502.16589v2",
    "title": "Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving",
    "authors": [
      "Xinyu Zhang",
      "Zewei Zhou",
      "Zhaoyi Wang",
      "Yangjie Ji",
      "Yanjun Huang",
      "Hong Chen"
    ],
    "abstract": "Vehicle-to-everything technologies (V2X) have become an ideal paradigm to\nextend the perception range and see through the occlusion. Exiting efforts\nfocus on single-frame cooperative perception, however, how to capture the\ntemporal cue between frames with V2X to facilitate the prediction task even the\nplanning task is still underexplored. In this paper, we introduce the Co-MTP, a\ngeneral cooperative trajectory prediction framework with multi-temporal fusion\nfor autonomous driving, which leverages the V2X system to fully capture the\ninteraction among agents in both history and future domains to benefit the\nplanning. In the history domain, V2X can complement the incomplete history\ntrajectory in single-vehicle perception, and we design a heterogeneous graph\ntransformer to learn the fusion of the history feature from multiple agents and\ncapture the history interaction. Moreover, the goal of prediction is to support\nfuture planning. Thus, in the future domain, V2X can provide the prediction\nresults of surrounding objects, and we further extend the graph transformer to\ncapture the future interaction among the ego planning and the other vehicles'\nintentions and obtain the final future scenario state under a certain planning\naction. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and\nthe results show that Co-MTP achieves state-of-the-art performance and that\nboth history and future fusion can greatly benefit prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.RO",
      "68T07",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures, ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16589v2",
    "published_date": "2025-02-23 14:38:13 UTC",
    "updated_date": "2025-02-25 14:38:44 UTC"
  },
  {
    "arxiv_id": "2502.16584v1",
    "title": "Audio-FLAN: A Preliminary Release",
    "authors": [
      "Liumeng Xue",
      "Ziya Zhou",
      "Jiahao Pan",
      "Zixuan Li",
      "Shuai Fan",
      "Yinghao Ma",
      "Sitong Cheng",
      "Dongchao Yang",
      "Haohan Guo",
      "Yujia Xiao",
      "Xinsheng Wang",
      "Zixuan Shen",
      "Chuanbo Zhu",
      "Xinshen Zhang",
      "Tianchi Liu",
      "Ruibin Yuan",
      "Zeyue Tian",
      "Haohe Liu",
      "Emmanouil Benetos",
      "Ge Zhang",
      "Yike Guo",
      "Wei Xue"
    ],
    "abstract": "Recent advancements in audio tokenization have significantly enhanced the\nintegration of audio capabilities into large language models (LLMs). However,\naudio understanding and generation are often treated as distinct tasks,\nhindering the development of truly unified audio-language models. While\ninstruction tuning has demonstrated remarkable success in improving\ngeneralization and zero-shot learning across text and vision, its application\nto audio remains largely unexplored. A major obstacle is the lack of\ncomprehensive datasets that unify audio understanding and generation. To\naddress this, we introduce Audio-FLAN, a large-scale instruction-tuning dataset\ncovering 80 diverse tasks across speech, music, and sound domains, with over\n100 million instances. Audio-FLAN lays the foundation for unified\naudio-language models that can seamlessly handle both understanding (e.g.,\ntranscription, comprehension) and generation (e.g., speech, music, sound) tasks\nacross a wide range of audio domains in a zero-shot manner. The Audio-FLAN\ndataset is available on HuggingFace and GitHub and will be continuously\nupdated.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16584v1",
    "published_date": "2025-02-23 14:24:15 UTC",
    "updated_date": "2025-02-23 14:24:15 UTC"
  },
  {
    "arxiv_id": "2502.16573v1",
    "title": "LawPal : A Retrieval Augmented Generation Based System for Enhanced Legal Accessibility in India",
    "authors": [
      "Dnyanesh Panchal",
      "Aaryan Gole",
      "Vaibhav Narute",
      "Raunak Joshi"
    ],
    "abstract": "Access to legal knowledge in India is often hindered by a lack of awareness,\nmisinformation and limited accessibility to judicial resources. Many\nindividuals struggle to navigate complex legal frameworks, leading to the\nfrequent misuse of laws and inadequate legal protection. To address these\nissues, we propose a Retrieval-Augmented Generation (RAG)-based legal chatbot\npowered by vectorstore oriented FAISS for efficient and accurate legal\ninformation retrieval. Unlike traditional chatbots, our model is trained using\nan extensive dataset comprising legal books, official documentation and the\nIndian Constitution, ensuring accurate responses to even the most complex or\nmisleading legal queries. The chatbot leverages FAISS for rapid vector-based\nsearch, significantly improving retrieval speed and accuracy. It is also\nprompt-engineered to handle twisted or ambiguous legal questions, reducing the\nchances of incorrect interpretations. Apart from its core functionality of\nanswering legal queries, the platform includes additional features such as\nreal-time legal news updates, legal blogs, and access to law-related books,\nmaking it a comprehensive resource for users. By integrating advanced AI\ntechniques with an optimized retrieval system, our chatbot aims to democratize\nlegal knowledge, enhance legal literacy, and prevent the spread of\nmisinformation. The study demonstrates that our approach effectively improves\nlegal accessibility while maintaining high accuracy and efficiency, thereby\ncontributing to a more informed and empowered society.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16573v1",
    "published_date": "2025-02-23 13:45:47 UTC",
    "updated_date": "2025-02-23 13:45:47 UTC"
  },
  {
    "arxiv_id": "2502.16570v1",
    "title": "Entropy-Lens: The Information Signature of Transformer Computations",
    "authors": [
      "Riccardo Ali",
      "Francesco Caso",
      "Christopher Irwin",
      "Pietro Liò"
    ],
    "abstract": "Transformer models have revolutionized fields from natural language\nprocessing to computer vision, yet their internal computational dynamics remain\npoorly understood raising concerns about predictability and robustness. In this\nwork, we introduce Entropy-Lens, a scalable, model-agnostic framework that\nleverages information theory to interpret frozen, off-the-shelf large-scale\ntransformers. By quantifying the evolution of Shannon entropy within\nintermediate residual streams, our approach extracts computational signatures\nthat distinguish model families, categorize task-specific prompts, and\ncorrelate with output accuracy. We further demonstrate the generality of our\nmethod by extending the analysis to vision transformers. Our results suggest\nthat entropy-based metrics can serve as a principled tool for unveiling the\ninner workings of modern transformer architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16570v1",
    "published_date": "2025-02-23 13:33:27 UTC",
    "updated_date": "2025-02-23 13:33:27 UTC"
  },
  {
    "arxiv_id": "2502.16565v2",
    "title": "The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems",
    "authors": [
      "Zengqing Wu",
      "Takayuki Ito"
    ],
    "abstract": "Consensus formation is pivotal in multi-agent systems (MAS), balancing\ncollective coherence with individual diversity. Conventional LLM-based MAS\nprimarily rely on explicit coordination, e.g., prompts or voting, risking\npremature homogenization. We argue that implicit consensus, where agents\nexchange information yet independently form decisions via in-context learning,\ncan be more effective in dynamic environments that require long-horizon\nadaptability. By retaining partial diversity, systems can better explore novel\nstrategies and cope with external shocks. We formalize a consensus-diversity\ntradeoff, showing conditions where implicit methods outperform explicit ones.\nExperiments on three scenarios -- Dynamic Disaster Response, Information Spread\nand Manipulation, and Dynamic Public-Goods Provision -- confirm partial\ndeviation from group norms boosts exploration, robustness, and performance. We\nhighlight emergent coordination via in-context learning, underscoring the value\nof preserving diversity for resilient decision-making.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "Source codes are available at\n  https://github.com/wuzengqing001225/ConsensusDiversityTradeoffMAS",
    "pdf_url": "http://arxiv.org/pdf/2502.16565v2",
    "published_date": "2025-02-23 13:12:53 UTC",
    "updated_date": "2025-05-19 15:45:13 UTC"
  },
  {
    "arxiv_id": "2502.17522v1",
    "title": "Spectral Theory for Edge Pruning in Asynchronous Recurrent Graph Neural Networks",
    "authors": [
      "Nicolas Bessone"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as a powerful tool for learning on\ngraph-structured data, finding applications in numerous domains including\nsocial network analysis and molecular biology. Within this broad category,\nAsynchronous Recurrent Graph Neural Networks (ARGNNs) stand out for their\nability to capture complex dependencies in dynamic graphs, resembling living\norganisms' intricate and adaptive nature. However, their complexity often leads\nto large and computationally expensive models. Therefore, pruning unnecessary\nedges becomes crucial for enhancing efficiency without significantly\ncompromising performance. This paper presents a dynamic pruning method based on\ngraph spectral theory, leveraging the imaginary component of the eigenvalues of\nthe network graph's Laplacian.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17522v1",
    "published_date": "2025-02-23 13:05:08 UTC",
    "updated_date": "2025-02-23 13:05:08 UTC"
  },
  {
    "arxiv_id": "2502.16560v2",
    "title": "An Analytical Emotion Framework of Rumour Threads on Social Media",
    "authors": [
      "Rui Xing",
      "Boyang Sun",
      "Kun Zhang",
      "Preslav Nakov",
      "Timothy Baldwin",
      "Jey Han Lau"
    ],
    "abstract": "Rumours in online social media pose significant risks to modern society,\nmotivating the need for better understanding of how they develop. We focus\nspecifically on the interface between emotion and rumours in threaded\ndiscourses, building on the surprisingly sparse literature on the topic which\nhas largely focused on single aspect of emotions within the original rumour\nposts themselves, and largely overlooked the comparative differences between\nrumours and non-rumours. In this work, we take one step further to provide a\ncomprehensive analytical emotion framework with multi-aspect emotion detection,\ncontrasting rumour and non-rumour threads and provide both correlation and\ncausal analysis of emotions. We applied our framework on existing widely-used\nrumour datasets to further understand the emotion dynamics in online social\nmedia threads. Our framework reveals that rumours trigger more negative\nemotions (e.g., anger, fear, pessimism), while non-rumours evoke more positive\nones. Emotions are contagious, rumours spread negativity, non-rumours spread\npositivity. Causal analysis shows surprise bridges rumours and other emotions;\npessimism comes from sadness and fear, while optimism arises from joy and love.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICWSM 2025 MisD Workshop",
    "pdf_url": "http://arxiv.org/pdf/2502.16560v2",
    "published_date": "2025-02-23 12:57:40 UTC",
    "updated_date": "2025-05-13 22:37:48 UTC"
  },
  {
    "arxiv_id": "2502.16556v1",
    "title": "Beyond Words: How Large Language Models Perform in Quantitative Management Problem-Solving",
    "authors": [
      "Jonathan Kuzmanko"
    ],
    "abstract": "This study examines how Large Language Models (LLMs) perform when tackling\nquantitative management decision problems in a zero-shot setting. Drawing on\n900 responses generated by five leading models across 20 diverse managerial\nscenarios, our analysis explores whether these base models can deliver accurate\nnumerical decisions under varying presentation formats, scenario complexities,\nand repeated attempts. Contrary to prior findings, we observed no significant\neffects of text presentation format (direct, narrative, or tabular) or text\nlength on accuracy. However, scenario complexity -- particularly in terms of\nconstraints and irrelevant parameters -- strongly influenced performance, often\ndegrading accuracy. Surprisingly, the models handled tasks requiring multiple\nsolution steps more effectively than expected. Notably, only 28.8\\% of\nresponses were exactly correct, highlighting limitations in precision. We\nfurther found no significant ``learning effect'' across iterations: performance\nremained stable across repeated queries. Nonetheless, significant variations\nemerged among the five tested LLMs, with some showing superior binary accuracy.\nOverall, these findings underscore both the promise and the pitfalls of\nharnessing LLMs for complex quantitative decision-making, informing managers\nand researchers about optimal deployment strategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 5 figures, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.16556v1",
    "published_date": "2025-02-23 12:39:39 UTC",
    "updated_date": "2025-02-23 12:39:39 UTC"
  },
  {
    "arxiv_id": "2502.16548v1",
    "title": "Composable Strategy Framework with Integrated Video-Text based Large Language Models for Heart Failure Assessment",
    "authors": [
      "Jianzhou Chen",
      "Xiumei Wang",
      "Jinyang Sun",
      "Xi Chen",
      "Heyu Chu",
      "Guo Song",
      "Yuji Luo",
      "Xingping Zhou",
      "Rong Gu"
    ],
    "abstract": "Heart failure is one of the leading causes of death worldwide, with millons\nof deaths each year, according to data from the World Health Organization (WHO)\nand other public health agencies. While significant progress has been made in\nthe field of heart failure, leading to improved survival rates and improvement\nof ejection fraction, there remains substantial unmet needs, due to the\ncomplexity and multifactorial characteristics. Therefore, we propose a\ncomposable strategy framework for assessment and treatment optimization in\nheart failure. This framework simulates the doctor-patient consultation process\nand leverages multi-modal algorithms to analyze a range of data, including\nvideo, physical examination, text results as well as medical history. By\nintegrating these various data sources, our framework offers a more holistic\nevaluation and optimized treatment plan for patients. Our results demonstrate\nthat this multi-modal approach outperforms single-modal artificial intelligence\n(AI) algorithms in terms of accuracy in heart failure (HF) prognosis\nprediction. Through this method, we can further evaluate the impact of various\npathological indicators on HF prognosis,providing a more comprehensive\nevaluation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16548v1",
    "published_date": "2025-02-23 12:06:08 UTC",
    "updated_date": "2025-02-23 12:06:08 UTC"
  },
  {
    "arxiv_id": "2504.05319v1",
    "title": "Predictive Modeling: BIM Command Recommendation Based on Large-scale Usage Logs",
    "authors": [
      "Changyu Du",
      "Zihan Deng",
      "Stavros Nousias",
      "André Borrmann"
    ],
    "abstract": "The adoption of Building Information Modeling (BIM) and model-based design\nwithin the Architecture, Engineering, and Construction (AEC) industry has been\nhindered by the perception that using BIM authoring tools demands more effort\nthan conventional 2D drafting. To enhance design efficiency, this paper\nproposes a BIM command recommendation framework that predicts the optimal next\nactions in real-time based on users' historical interactions. We propose a\ncomprehensive filtering and enhancement method for large-scale raw BIM log data\nand introduce a novel command recommendation model. Our model builds upon the\nstate-of-the-art Transformer backbones originally developed for large language\nmodels (LLMs), incorporating a custom feature fusion module, dedicated loss\nfunction, and targeted learning strategy. In a case study, the proposed method\nis applied to over 32 billion rows of real-world log data collected globally\nfrom the BIM authoring software Vectorworks. Experimental results demonstrate\nthat our method can learn universal and generalizable modeling patterns from\nanonymous user interaction sequences across different countries, disciplines,\nand projects. When generating recommendations for the next command, our\napproach achieves a Recall@10 of approximately 84%.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05319v1",
    "published_date": "2025-02-23 11:47:57 UTC",
    "updated_date": "2025-02-23 11:47:57 UTC"
  },
  {
    "arxiv_id": "2502.16540v1",
    "title": "Advanced Chain-of-Thought Reasoning for Parameter Extraction from Documents Using Large Language Models",
    "authors": [
      "Hong Cai Chen",
      "Yi Pin Xu",
      "Yang Zhang"
    ],
    "abstract": "Extracting parameters from technical documentation is crucial for ensuring\ndesign precision and simulation reliability in electronic design. However,\ncurrent methods struggle to handle high-dimensional design data and meet the\ndemands of real-time processing. In electronic design automation (EDA),\nengineers often manually search through extensive documents to retrieve\ncomponent parameters required for constructing PySpice models, a process that\nis both labor-intensive and time-consuming. To address this challenge, we\npropose an innovative framework that leverages large language models (LLMs) to\nautomate the extraction of parameters and the generation of PySpice models\ndirectly from datasheets. Our framework introduces three Chain-of-Thought (CoT)\nbased techniques: (1) Targeted Document Retrieval (TDR), which enables the\nrapid identification of relevant technical sections; (2) Iterative Retrieval\nOptimization (IRO), which refines the parameter search through iterative\nimprovements; and (3) Preference Optimization (PO), which dynamically\nprioritizes key document sections based on relevance. Experimental results show\nthat applying all three methods together improves retrieval precision by 47.69%\nand reduces processing latency by 37.84%. Furthermore, effect size analysis\nusing Cohen's d reveals that PO significantly reduces latency, while IRO\ncontributes most to precision enhancement. These findings underscore the\npotential of our framework to streamline EDA processes, enhance design\naccuracy, and shorten development timelines. Additionally, our algorithm has\nmodel-agnostic generalization, meaning it can improve parameter search\nperformance across different LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.AR",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16540v1",
    "published_date": "2025-02-23 11:19:44 UTC",
    "updated_date": "2025-02-23 11:19:44 UTC"
  },
  {
    "arxiv_id": "2502.18520v1",
    "title": "Class-Conditional Neural Polarizer: A Lightweight and Effective Backdoor Defense by Purifying Poisoned Features",
    "authors": [
      "Mingli Zhu",
      "Shaokui Wei",
      "Hongyuan Zha",
      "Baoyuan Wu"
    ],
    "abstract": "Recent studies have highlighted the vulnerability of deep neural networks to\nbackdoor attacks, where models are manipulated to rely on embedded triggers\nwithin poisoned samples, despite the presence of both benign and trigger\ninformation. While several defense methods have been proposed, they often\nstruggle to balance backdoor mitigation with maintaining benign performance.In\nthis work, inspired by the concept of optical polarizer-which allows light\nwaves of specific polarizations to pass while filtering others-we propose a\nlightweight backdoor defense approach, NPD. This method integrates a neural\npolarizer (NP) as an intermediate layer within the compromised model,\nimplemented as a lightweight linear transformation optimized via bi-level\noptimization. The learnable NP filters trigger information from poisoned\nsamples while preserving benign content. Despite its effectiveness, we identify\nthrough empirical studies that NPD's performance degrades when the target\nlabels (required for purification) are inaccurately estimated. To address this\nlimitation while harnessing the potential of targeted adversarial mitigation,\nwe propose class-conditional neural polarizer-based defense (CNPD). The key\ninnovation is a fusion module that integrates the backdoored model's predicted\nlabel with the features to be purified. This architecture inherently mimics\ntargeted adversarial defense mechanisms without requiring label estimation used\nin NPD. We propose three implementations of CNPD: the first is r-CNPD, which\ntrains a replicated NP layer for each class and, during inference, selects the\nappropriate NP layer for defense based on the predicted class from the\nbackdoored model. To efficiently handle a large number of classes, two variants\nare designed: e-CNPD, which embeds class information as additional features,\nand a-CNPD, which directs network attention using class information.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18520v1",
    "published_date": "2025-02-23 11:11:16 UTC",
    "updated_date": "2025-02-23 11:11:16 UTC"
  },
  {
    "arxiv_id": "2502.16535v1",
    "title": "Rebalancing the Scales: A Systematic Mapping Study of Generative Adversarial Networks (GANs) in Addressing Data Imbalance",
    "authors": [
      "Pankaj Yadav",
      "Gulshan Sihag",
      "Vivek Vijay"
    ],
    "abstract": "Machine learning algorithms are used in diverse domains, many of which face\nsignificant challenges due to data imbalance. Studies have explored various\napproaches to address the issue, like data preprocessing, cost-sensitive\nlearning, and ensemble methods. Generative Adversarial Networks (GANs) showed\nimmense potential as a data preprocessing technique that generates good quality\nsynthetic data. This study employs a systematic mapping methodology to analyze\n3041 papers on GAN-based sampling techniques for imbalanced data sourced from\nfour digital libraries. A filtering process identified 100 key studies spanning\ndomains such as healthcare, finance, and cybersecurity. Through comprehensive\nquantitative analysis, this research introduces three categorization mappings\nas application domains, GAN techniques, and GAN variants used to handle the\nimbalanced nature of the data. GAN-based over-sampling emerges as an effective\npreprocessing method. Advanced architectures and tailored frameworks helped\nGANs to improve further in the case of data imbalance. GAN variants like\nvanilla GAN, CTGAN, and CGAN show great adaptability in structured imbalanced\ndata cases. Interest in GANs for imbalanced data has grown tremendously,\ntouching a peak in recent years, with journals and conferences playing crucial\nroles in transmitting foundational theories and practical applications. While\nwith these advances, none of the reviewed studies explicitly explore hybridized\nGAN frameworks with diffusion models or reinforcement learning techniques. This\ngap leads to a future research idea develop innovative approaches for\neffectively handling data imbalance.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "49 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16535v1",
    "published_date": "2025-02-23 11:03:29 UTC",
    "updated_date": "2025-02-23 11:03:29 UTC"
  },
  {
    "arxiv_id": "2502.16534v1",
    "title": "Multilingual != Multicultural: Evaluating Gaps Between Multilingual Capabilities and Cultural Alignment in LLMs",
    "authors": [
      "Jonathan Rystrøm",
      "Hannah Rose Kirk",
      "Scott Hale"
    ],
    "abstract": "Large Language Models (LLMs) are becoming increasingly capable across global\nlanguages. However, the ability to communicate across languages does not\nnecessarily translate to appropriate cultural representations. A key concern is\nUS-centric bias, where LLMs reflect US rather than local cultural values. We\npropose a novel methodology that compares LLM-generated response distributions\nagainst population-level opinion data from the World Value Survey across four\nlanguages (Danish, Dutch, English, and Portuguese). Using a rigorous linear\nmixed-effects regression framework, we compare two families of models: Google's\nGemma models (2B--27B parameters) and successive iterations of OpenAI's\nturbo-series. Across the families of models, we find no consistent\nrelationships between language capabilities and cultural alignment. While the\nGemma models have a positive correlation between language capability and\ncultural alignment across languages, the OpenAI models do not. Importantly, we\nfind that self-consistency is a stronger predictor of multicultural alignment\nthan multilingual capabilities. Our results demonstrate that achieving\nmeaningful cultural alignment requires dedicated effort beyond improving\ngeneral language capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16534v1",
    "published_date": "2025-02-23 11:02:41 UTC",
    "updated_date": "2025-02-23 11:02:41 UTC"
  },
  {
    "arxiv_id": "2502.16533v2",
    "title": "A Survey of Graph Transformers: Architectures, Theories and Applications",
    "authors": [
      "Chaohao Yuan",
      "Kangfei Zhao",
      "Ercan Engin Kuruoglu",
      "Liang Wang",
      "Tingyang Xu",
      "Wenbing Huang",
      "Deli Zhao",
      "Hong Cheng",
      "Yu Rong"
    ],
    "abstract": "Graph Transformers (GTs) have demonstrated a strong capability in modeling\ngraph structures by addressing the intrinsic limitations of graph neural\nnetworks (GNNs), such as over-smoothing and over-squashing. Recent studies have\nproposed diverse architectures, enhanced explainability, and practical\napplications for Graph Transformers. In light of these rapid developments, we\nconduct a comprehensive review of Graph Transformers, covering aspects such as\ntheir architectures, theoretical foundations, and applications within this\nsurvey. We categorize the architecture of Graph Transformers according to their\nstrategies for processing structural information, including graph tokenization,\npositional encoding, structure-aware attention and model ensemble. Furthermore,\nfrom the theoretical perspective, we examine the expressivity of Graph\nTransformers in various discussed architectures and contrast them with other\nadvanced graph learning algorithms to discover the connections. Furthermore, we\nprovide a summary of the practical applications where Graph Transformers have\nbeen utilized, such as molecule, protein, language, vision, traffic, brain and\nmaterial data. At the end of this survey, we will discuss the current\nchallenges and prospective directions in Graph Transformers for potential\nfuture research.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16533v2",
    "published_date": "2025-02-23 10:55:19 UTC",
    "updated_date": "2025-02-27 06:17:29 UTC"
  },
  {
    "arxiv_id": "2502.16529v1",
    "title": "Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation",
    "authors": [
      "Deokhyung Kang",
      "Jeonghun Cho",
      "Yejin Jeon",
      "Sunbin Jang",
      "Minsub Lee",
      "Jawoon Cho",
      "Gary Geunbae Lee"
    ],
    "abstract": "Visual programming languages (VPLs) allow users to create programs through\ngraphical interfaces, which results in easier accessibility and their\nwidespread usage in various domains. To further enhance this accessibility,\nrecent research has focused on generating VPL code from user instructions using\nlarge language models (LLMs). Specifically, by employing prompting-based\nmethods, these studies have shown promising results. Nevertheless, such\napproaches can be less effective for industrial VPLs such as Ladder Diagram\n(LD). LD is a pivotal language used in industrial automation processes and\ninvolves extensive domain-specific configurations, which are difficult to\ncapture in a single prompt. In this work, we demonstrate that training-based\nmethods outperform prompting-based methods for LD generation accuracy, even\nwith smaller backbone models. Building on these findings, we propose a\ntwo-stage training strategy to further enhance VPL generation. First, we employ\nretrieval-augmented fine-tuning to leverage the repetitive use of subroutines\ncommonly seen in industrial VPLs. Second, we apply direct preference\noptimization (DPO) to further guide the model toward accurate outputs, using\nsystematically generated preference pairs through graph editing operations.\nExtensive experiments on real-world LD data demonstrate that our approach\nimproves program-level accuracy by over 10% compared to supervised fine-tuning,\nwhich highlights its potential to advance industrial automation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16529v1",
    "published_date": "2025-02-23 10:27:44 UTC",
    "updated_date": "2025-02-23 10:27:44 UTC"
  },
  {
    "arxiv_id": "2502.16523v1",
    "title": "Pay Attention to Real World Perturbations! Natural Robustness Evaluation in Machine Reading Comprehension",
    "authors": [
      "Yulong Wu",
      "Viktor Schlegel",
      "Riza Batista-Navarro"
    ],
    "abstract": "As neural language models achieve human-comparable performance on Machine\nReading Comprehension (MRC) and see widespread adoption, ensuring their\nrobustness in real-world scenarios has become increasingly important. Current\nrobustness evaluation research, though, primarily develops synthetic\nperturbation methods, leaving unclear how well they reflect real life\nscenarios. Considering this, we present a framework to automatically examine\nMRC models on naturally occurring textual perturbations, by replacing paragraph\nin MRC benchmarks with their counterparts based on available Wikipedia edit\nhistory. Such perturbation type is natural as its design does not stem from an\narteficial generative process, inherently distinct from the previously\ninvestigated synthetic approaches. In a large-scale study encompassing SQUAD\ndatasets and various model architectures we observe that natural perturbations\nresult in performance degradation in pre-trained encoder language models. More\nworryingly, these state-of-the-art Flan-T5 and Large Language Models (LLMs)\ninherit these errors. Further experiments demonstrate that our findings\ngeneralise to natural perturbations found in other more challenging MRC\nbenchmarks. In an effort to mitigate these errors, we show that it is possible\nto improve the robustness to natural perturbations by training on naturally or\nsynthetically perturbed examples, though a noticeable gap still remains\ncompared to performance on unperturbed data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16523v1",
    "published_date": "2025-02-23 10:04:21 UTC",
    "updated_date": "2025-02-23 10:04:21 UTC"
  },
  {
    "arxiv_id": "2502.16520v2",
    "title": "Predicting Bad Goods Risk Scores with ARIMA Time Series: A Novel Risk Assessment Approach",
    "authors": [
      "Bishwajit Prasad Gond"
    ],
    "abstract": "The increasing complexity of supply chains and the rising costs associated\nwith defective or substandard goods (bad goods) highlight the urgent need for\nadvanced predictive methodologies to mitigate risks and enhance operational\nefficiency. This research presents a novel framework that integrates Time\nSeries ARIMA (AutoRegressive Integrated Moving Average) models with a\nproprietary formula specifically designed to calculate bad goods after time\nseries forecasting. By leveraging historical data patterns, including sales,\nreturns, and capacity, the model forecasts potential quality failures, enabling\nproactive decision-making. ARIMA is employed to capture temporal trends in time\nseries data, while the newly developed formula quantifies the likelihood and\nimpact of defects with greater precision. Experimental results, validated on a\ndataset spanning 2022-2024 for Organic Beer-G 1 Liter, demonstrate that the\nproposed method outperforms traditional statistical models, such as Exponential\nSmoothing and Holt-Winters, in both prediction accuracy and risk evaluation.\nThis study advances the field of predictive analytics by bridging time series\nforecasting, ARIMA, and risk management in supply chain quality control,\noffering a scalable and practical solution for minimizing losses due to bad\ngoods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16520v2",
    "published_date": "2025-02-23 09:52:11 UTC",
    "updated_date": "2025-02-25 11:40:32 UTC"
  },
  {
    "arxiv_id": "2502.16510v1",
    "title": "Gaussian Process Regression for Improved Underwater Navigation",
    "authors": [
      "Nadav Cohen",
      "Itzik Klein"
    ],
    "abstract": "Accurate underwater navigation is a challenging task due to the absence of\nglobal navigation satellite system signals and the reliance on inertial\nnavigation systems that suffer from drift over time. Doppler velocity logs\n(DVLs) are typically used to mitigate this drift through velocity measurements,\nwhich are commonly estimated using a parameter estimation approach such as\nleast squares (LS). However, LS works under the assumption of ideal conditions\nand does not account for sensor biases, leading to suboptimal performance. This\npaper proposes a data-driven alternative based on multi-output Gaussian process\nregression (MOGPR) to improve DVL velocity estimation. MOGPR provides velocity\nestimates and associated measurement covariances, enabling an adaptive\nintegration within an error-state Extended Kalman Filter (EKF). We evaluate our\nproposed approach using real-world AUV data and compare it against LS and a\nstate-of-the-art deep learning model, BeamsNet. Results demonstrate that MOGPR\nreduces velocity estimation errors by approximately 20% while simultaneously\nenhancing overall navigation accuracy, particularly in the orientation states.\nAdditionally, the incorporation of uncertainty estimates from MOGPR enables an\nadaptive EKF framework, improving navigation robustness in dynamic underwater\nenvironments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SP",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16510v1",
    "published_date": "2025-02-23 09:13:41 UTC",
    "updated_date": "2025-02-23 09:13:41 UTC"
  },
  {
    "arxiv_id": "2502.16503v1",
    "title": "FanChuan: A Multilingual and Graph-Structured Benchmark For Parody Detection and Analysis",
    "authors": [
      "Yilun Zheng",
      "Sha Li",
      "Fangkun Wu",
      "Yang Ziyi",
      "Lin Hongchao",
      "Zhichao Hu",
      "Cai Xinjun",
      "Ziming Wang",
      "Jinxuan Chen",
      "Sitao Luan",
      "Jiahao Xu",
      "Lihui Chen"
    ],
    "abstract": "Parody is an emerging phenomenon on social media, where individuals imitate a\nrole or position opposite to their own, often for humor, provocation, or\ncontroversy. Detecting and analyzing parody can be challenging and is often\nreliant on context, yet it plays a crucial role in understanding cultural\nvalues, promoting subcultures, and enhancing self-expression. However, the\nstudy of parody is hindered by limited available data and deficient diversity\nin current datasets. To bridge this gap, we built seven parody datasets from\nboth English and Chinese corpora, with 14,755 annotated users and 21,210\nannotated comments in total. To provide sufficient context information, we also\ncollect replies and construct user-interaction graphs to provide richer\ncontextual information, which is lacking in existing datasets. With these\ndatasets, we test traditional methods and Large Language Models (LLMs) on three\nkey tasks: (1) parody detection, (2) comment sentiment analysis with parody,\nand (3) user sentiment analysis with parody. Our extensive experiments reveal\nthat parody-related tasks still remain challenging for all models, and\ncontextual information plays a critical role. Interestingly, we find that, in\ncertain scenarios, traditional sentence embedding methods combined with simple\nclassifiers can outperform advanced LLMs, i.e. DeepSeek-R1 and GPT-o3,\nhighlighting parody as a significant challenge for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16503v1",
    "published_date": "2025-02-23 08:52:46 UTC",
    "updated_date": "2025-02-23 08:52:46 UTC"
  },
  {
    "arxiv_id": "2502.16496v1",
    "title": "PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning",
    "authors": [
      "Kun Hu",
      "Muning Wen",
      "Xihuai Wang",
      "Shao Zhang",
      "Yiwei Shi",
      "Minne Li",
      "Minglong Li",
      "Ying Wen"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) faces challenges in coordinating\nagents due to complex interdependencies within multi-agent systems. Most MARL\nalgorithms use the simultaneous decision-making paradigm but ignore the\naction-level dependencies among agents, which reduces coordination efficiency.\nIn contrast, the sequential decision-making paradigm provides finer-grained\nsupervision for agent decision order, presenting the potential for handling\ndependencies via better decision order management. However, determining the\noptimal decision order remains a challenge. In this paper, we introduce Action\nGeneration with Plackett-Luce Sampling (AGPS), a novel mechanism for agent\ndecision order optimization. We model the order determination task as a\nPlackett-Luce sampling process to address issues such as ranking instability\nand vanishing gradient during the network training process. AGPS realizes\ncredit-based decision order determination by establishing a bridge between the\nsignificance of agents' local observations and their decision credits, thus\nfacilitating order optimization and dependency management. Integrating AGPS\nwith the Multi-Agent Transformer, we propose the Prioritized Multi-Agent\nTransformer (PMAT), a sequential decision-making MARL algorithm with decision\norder optimization. Experiments on benchmarks including StarCraft II\nMulti-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show\nthat PMAT outperforms state-of-the-art algorithms, greatly enhancing\ncoordination efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAMAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16496v1",
    "published_date": "2025-02-23 08:30:14 UTC",
    "updated_date": "2025-02-23 08:30:14 UTC"
  },
  {
    "arxiv_id": "2502.17521v1",
    "title": "Recent Advances in Large Langauge Model Benchmarks against Data Contamination: From Static to Dynamic Evaluation",
    "authors": [
      "Simin Chen",
      "Yiming Chen",
      "Zexin Li",
      "Yifan Jiang",
      "Zhongwei Wan",
      "Yixin He",
      "Dezhi Ran",
      "Tianle Gu",
      "Haizhou Li",
      "Tao Xie",
      "Baishakhi Ray"
    ],
    "abstract": "Data contamination has received increasing attention in the era of large\nlanguage models (LLMs) due to their reliance on vast Internet-derived training\ncorpora. To mitigate the risk of potential data contamination, LLM benchmarking\nhas undergone a transformation from static to dynamic benchmarking. In this\nwork, we conduct an in-depth analysis of existing static to dynamic\nbenchmarking methods aimed at reducing data contamination risks. We first\nexamine methods that enhance static benchmarks and identify their inherent\nlimitations. We then highlight a critical gap-the lack of standardized criteria\nfor evaluating dynamic benchmarks. Based on this observation, we propose a\nseries of optimal design principles for dynamic benchmarking and analyze the\nlimitations of existing dynamic benchmarks. This survey provides a concise yet\ncomprehensive overview of recent advancements in data contamination research,\noffering valuable insights and a clear guide for future research efforts. We\nmaintain a GitHub repository to continuously collect both static and dynamic\nbenchmarking methods for LLMs. The repository can be found at this link.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Github Link:\n  https://github.com/SeekingDream/Static-to-Dynamic-LLMEval",
    "pdf_url": "http://arxiv.org/pdf/2502.17521v1",
    "published_date": "2025-02-23 08:18:37 UTC",
    "updated_date": "2025-02-23 08:18:37 UTC"
  },
  {
    "arxiv_id": "2502.16490v1",
    "title": "On Computational Limits of FlowAR Models: Expressivity and Efficiency",
    "authors": [
      "Chengyue Gong",
      "Yekun Ke",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhizhou Sha",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "The expressive power and computational complexity of deep visual generative\nmodels, such as flow-based and autoregressive (AR) models, have gained\nconsiderable interest for their wide-ranging applications in generative tasks.\nHowever, the theoretical characterization of their expressiveness through the\nlens of circuit complexity remains underexplored, particularly for the\nstate-of-the-art architecture like FlowAR proposed by [Ren et al., 2024], which\nintegrates flow-based and autoregressive mechanisms. This gap limits our\nunderstanding of their inherent computational limits and practical efficiency.\nIn this study, we address this gap by analyzing the circuit complexity of the\nFlowAR architecture. We demonstrate that when the largest feature map produced\nby the FlowAR model has dimensions $n \\times n \\times c$, the FlowAR model is\nsimulable by a family of threshold circuits $\\mathsf{TC}^0$, which have\nconstant depth $O(1)$ and polynomial width $\\mathrm{poly}(n)$. This is the\nfirst study to rigorously highlight the limitations in the expressive power of\nFlowAR models. Furthermore, we identify the conditions under which the FlowAR\nmodel computations can achieve almost quadratic time. To validate our\ntheoretical findings, we present efficient model variant constructions based on\nlow-rank approximations that align with the derived criteria. Our work provides\na foundation for future comparisons with other generative paradigms and guides\nthe development of more efficient and expressive implementations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16490v1",
    "published_date": "2025-02-23 08:07:35 UTC",
    "updated_date": "2025-02-23 08:07:35 UTC"
  },
  {
    "arxiv_id": "2502.16483v1",
    "title": "A Split-Window Transformer for Multi-Model Sequence Spammer Detection using Multi-Model Variational Autoencoder",
    "authors": [
      "Zhou Yang",
      "Yucai Pang",
      "Hongbo Yin",
      "Yunpeng Xiao"
    ],
    "abstract": "This paper introduces a new Transformer, called MS$^2$Dformer, that can be\nused as a generalized backbone for multi-modal sequence spammer detection.\nSpammer detection is a complex multi-modal task, thus the challenges of\napplying Transformer are two-fold. Firstly, complex multi-modal noisy\ninformation about users can interfere with feature mining. Secondly, the long\nsequence of users' historical behaviors also puts a huge GPU memory pressure on\nthe attention computation. To solve these problems, we first design a user\nbehavior Tokenization algorithm based on the multi-modal variational\nautoencoder (MVAE). Subsequently, a hierarchical split-window multi-head\nattention (SW/W-MHA) mechanism is proposed. The split-window strategy\ntransforms the ultra-long sequences hierarchically into a combination of\nintra-window short-term and inter-window overall attention. Pre-trained on the\npublic datasets, MS$^2$Dformer's performance far exceeds the previous state of\nthe art. The experiments demonstrate MS$^2$Dformer's ability to act as a\nbackbone.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MM",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16483v1",
    "published_date": "2025-02-23 07:53:08 UTC",
    "updated_date": "2025-02-23 07:53:08 UTC"
  },
  {
    "arxiv_id": "2502.16477v1",
    "title": "Unmasking Societal Biases in Respiratory Support for ICU Patients through Social Determinants of Health",
    "authors": [
      "Mira Moukheiber",
      "Lama Moukheiber",
      "Dana Moukheiber",
      "Hyung-Chul Lee"
    ],
    "abstract": "In critical care settings, where precise and timely interventions are crucial\nfor health outcomes, evaluating disparities in patient outcomes is essential.\nCurrent approaches often fail to fully capture the impact of respiratory\nsupport interventions on individuals affected by social determinants of health.\nWhile attributes such as gender, race, and age are commonly assessed and\nprovide valuable insights, they offer only a partial view of the complexities\nfaced by diverse populations. In this study, we focus on two clinically\nmotivated tasks: prolonged mechanical ventilation and successful weaning.\nAdditionally, we conduct fairness audits on the models' predictions across\ndemographic groups and social determinants of health to better understand\nhealth inequities in respiratory interventions within the intensive care unit.\nFurthermore, we release a temporal benchmark dataset, verified by clinical\nexperts, to facilitate benchmarking of clinical respiratory intervention tasks.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16477v1",
    "published_date": "2025-02-23 07:23:15 UTC",
    "updated_date": "2025-02-23 07:23:15 UTC"
  },
  {
    "arxiv_id": "2502.16475v1",
    "title": "Dragen3D: Multiview Geometry Consistent 3D Gaussian Generation with Drag-Based Control",
    "authors": [
      "Jinbo Yan",
      "Alan Zhao",
      "Yixin Hu"
    ],
    "abstract": "Single-image 3D generation has emerged as a prominent research topic, playing\na vital role in virtual reality, 3D modeling, and digital content creation.\nHowever, existing methods face challenges such as a lack of multi-view\ngeometric consistency and limited controllability during the generation\nprocess, which significantly restrict their usability. % To tackle these\nchallenges, we introduce Dragen3D, a novel approach that achieves geometrically\nconsistent and controllable 3D generation leveraging 3D Gaussian Splatting\n(3DGS). We introduce the Anchor-Gaussian Variational Autoencoder (Anchor-GS\nVAE), which encodes a point cloud and a single image into anchor latents and\ndecode these latents into 3DGS, enabling efficient latent-space generation. To\nenable multi-view geometry consistent and controllable generation, we propose a\nSeed-Point-Driven strategy: first generate sparse seed points as a coarse\ngeometry representation, then map them to anchor latents via the Seed-Anchor\nMapping Module. Geometric consistency is ensured by the easily learned sparse\nseed points, and users can intuitively drag the seed points to deform the final\n3DGS geometry, with changes propagated through the anchor latents. To the best\nof our knowledge, we are the first to achieve geometrically controllable 3D\nGaussian generation and editing without relying on 2D diffusion priors,\ndelivering comparable 3D generation quality to state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16475v1",
    "published_date": "2025-02-23 07:19:03 UTC",
    "updated_date": "2025-02-23 07:19:03 UTC"
  },
  {
    "arxiv_id": "2502.18519v1",
    "title": "FreeTumor: Large-Scale Generative Tumor Synthesis in Computed Tomography Images for Improving Tumor Recognition",
    "authors": [
      "Linshan Wu",
      "Jiaxin Zhuang",
      "Yanning Zhou",
      "Sunan He",
      "Jiabo Ma",
      "Luyang Luo",
      "Xi Wang",
      "Xuefeng Ni",
      "Xiaoling Zhong",
      "Mingxiang Wu",
      "Yinghua Zhao",
      "Xiaohui Duan",
      "Varut Vardhanabhuti",
      "Pranav Rajpurkar",
      "Hao Chen"
    ],
    "abstract": "Tumor is a leading cause of death worldwide, with an estimated 10 million\ndeaths attributed to tumor-related diseases every year. AI-driven tumor\nrecognition unlocks new possibilities for more precise and intelligent tumor\nscreening and diagnosis. However, the progress is heavily hampered by the\nscarcity of annotated datasets, which demands extensive annotation efforts by\nradiologists. To tackle this challenge, we introduce FreeTumor, an innovative\nGenerative AI (GAI) framework to enable large-scale tumor synthesis for\nmitigating data scarcity. Specifically, FreeTumor effectively leverages a\ncombination of limited labeled data and large-scale unlabeled data for tumor\nsynthesis training. Unleashing the power of large-scale data, FreeTumor is\ncapable of synthesizing a large number of realistic tumors on images for\naugmenting training datasets. To this end, we create the largest training\ndataset for tumor synthesis and recognition by curating 161,310 publicly\navailable Computed Tomography (CT) volumes from 33 sources, with only 2.3%\ncontaining annotated tumors. To validate the fidelity of synthetic tumors, we\nengaged 13 board-certified radiologists in a Visual Turing Test to discern\nbetween synthetic and real tumors. Rigorous clinician evaluation validates the\nhigh quality of our synthetic tumors, as they achieved only 51.1% sensitivity\nand 60.8% accuracy in distinguishing our synthetic tumors from real ones.\nThrough high-quality tumor synthesis, FreeTumor scales up the recognition\ntraining datasets by over 40 times, showcasing a notable superiority over\nstate-of-the-art AI methods including various synthesis methods and foundation\nmodels. These findings indicate promising prospects of FreeTumor in clinical\napplications, potentially advancing tumor treatments and improving the survival\nrates of patients.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18519v1",
    "published_date": "2025-02-23 07:00:09 UTC",
    "updated_date": "2025-02-23 07:00:09 UTC"
  },
  {
    "arxiv_id": "2502.16469v1",
    "title": "Cross-domain Few-shot Object Detection with Multi-modal Textual Enrichment",
    "authors": [
      "Zeyu Shangguan",
      "Daniel Seita",
      "Mohammad Rostami"
    ],
    "abstract": "Advancements in cross-modal feature extraction and integration have\nsignificantly enhanced performance in few-shot learning tasks. However, current\nmulti-modal object detection (MM-OD) methods often experience notable\nperformance degradation when encountering substantial domain shifts. We propose\nthat incorporating rich textual information can enable the model to establish a\nmore robust knowledge relationship between visual instances and their\ncorresponding language descriptions, thereby mitigating the challenges of\ndomain shift. Specifically, we focus on the problem of Cross-Domain Multi-Modal\nFew-Shot Object Detection (CDMM-FSOD) and introduce a meta-learning-based\nframework designed to leverage rich textual semantics as an auxiliary modality\nto achieve effective domain adaptation. Our new architecture incorporates two\nkey components: (i) A multi-modal feature aggregation module, which aligns\nvisual and linguistic feature embeddings to ensure cohesive integration across\nmodalities. (ii) A rich text semantic rectification module, which employs\nbidirectional text feature generation to refine multi-modal feature alignment,\nthereby enhancing understanding of language and its application in object\ndetection. We evaluate the proposed method on common cross-domain object\ndetection benchmarks and demonstrate that it significantly surpasses existing\nfew-shot object detection approaches.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2403.16188",
    "pdf_url": "http://arxiv.org/pdf/2502.16469v1",
    "published_date": "2025-02-23 06:59:22 UTC",
    "updated_date": "2025-02-23 06:59:22 UTC"
  },
  {
    "arxiv_id": "2502.18518v1",
    "title": "Swallowing the Poison Pills: Insights from Vulnerability Disparity Among LLMs",
    "authors": [
      "Peng Yifeng",
      "Wu Zhizheng",
      "Chen Chen"
    ],
    "abstract": "Modern large language models (LLMs) exhibit critical vulnerabilities to\npoison pill attacks: localized data poisoning that alters specific factual\nknowledge while preserving overall model utility. We systematically demonstrate\nthese attacks exploit inherent architectural properties of LLMs, achieving\n54.6% increased retrieval inaccuracy on long-tail knowledge versus dominant\ntopics and up to 25.5% increase retrieval inaccuracy on compressed models\nversus original architectures. Through controlled mutations (e.g.,\ntemporal/spatial/entity alterations) and, our method induces localized\nmemorization deterioration with negligible impact on models' performance on\nregular standard benchmarks (e.g., <2% performance drop on MMLU/GPQA), leading\nto potential detection evasion. Our findings suggest: (1) Disproportionate\nvulnerability in long-tail knowledge may result from reduced parameter\nredundancy; (2) Model compression may increase attack surfaces, with\npruned/distilled models requiring 30% fewer poison samples for equivalent\ndamage; (3) Associative memory enables both spread of collateral damage to\nrelated concepts and amplification of damage from simultaneous attack,\nparticularly for dominant topics. These findings raise concerns over current\nscaling paradigms since attack costs are lowering while defense complexity is\nrising. Our work establishes poison pills as both a security threat and\ndiagnostic tool, revealing critical security-efficiency trade-offs in language\nmodel compression that challenges prevailing safety assumptions.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18518v1",
    "published_date": "2025-02-23 06:34:55 UTC",
    "updated_date": "2025-02-23 06:34:55 UTC"
  },
  {
    "arxiv_id": "2502.16459v1",
    "title": "Deep learning approaches to surgical video segmentation and object detection: A Scoping Review",
    "authors": [
      "Devanish N. Kamtam",
      "Joseph B. Shrager",
      "Satya Deepya Malla",
      "Nicole Lin",
      "Juan J. Cardona",
      "Jake J. Kim",
      "Clarence Hu"
    ],
    "abstract": "Introduction: Computer vision (CV) has had a transformative impact in\nbiomedical fields such as radiology, dermatology, and pathology. Its real-world\nadoption in surgical applications, however, remains limited. We review the\ncurrent state-of-the-art performance of deep learning (DL)-based CV models for\nsegmentation and object detection of anatomical structures in videos obtained\nduring surgical procedures.\n  Methods: We conducted a scoping review of studies on semantic segmentation\nand object detection of anatomical structures published between 2014 and 2024\nfrom 3 major databases - PubMed, Embase, and IEEE Xplore. The primary objective\nwas to evaluate the state-of-the-art performance of semantic segmentation in\nsurgical videos. Secondary objectives included examining DL models, progress\ntoward clinical applications, and the specific challenges with segmentation of\norgans/tissues in surgical videos.\n  Results: We identified 58 relevant published studies. These focused\npredominantly on procedures from general surgery [20(34.4%)], colorectal\nsurgery [9(15.5%)], and neurosurgery [8(13.8%)]. Cholecystectomy [14(24.1%)]\nand low anterior rectal resection [5(8.6%)] were the most common procedures\naddressed. Semantic segmentation [47(81%)] was the primary CV task. U-Net\n[14(24.1%)] and DeepLab [13(22.4%)] were the most widely used models. Larger\norgans such as the liver (Dice score: 0.88) had higher accuracy compared to\nsmaller structures such as nerves (Dice score: 0.49). Models demonstrated\nreal-time inference potential ranging from 5-298 frames-per-second (fps).\n  Conclusion: This review highlights the significant progress made in DL-based\nsemantic segmentation for surgical videos with real-time applicability,\nparticularly for larger organs. Addressing challenges with smaller structures,\ndata availability, and generalizability remains crucial for future\nadvancements.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "38 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16459v1",
    "published_date": "2025-02-23 06:31:23 UTC",
    "updated_date": "2025-02-23 06:31:23 UTC"
  },
  {
    "arxiv_id": "2502.16449v1",
    "title": "Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning",
    "authors": [
      "Haoran Su"
    ],
    "abstract": "Emergency Response Time (ERT) is crucial for urban safety, measuring cities'\nability to handle medical, fire, and crime emergencies. In NYC, medical ERT\nincreased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of\ndelays due to Emergency Vehicle (EMV) travel times. Each minute's delay in\nstroke response costs 2 million brain cells, while cardiac arrest survival\ndrops 7-10% per minute.\n  This dissertation advances EMV facilitation through three contributions.\nFirst, EMVLight, a decentralized multi-agent reinforcement learning framework,\nintegrates EMV routing with traffic signal pre-emption. It achieved 42.6%\nfaster EMV travel times and 23.5% improvement for other vehicles.\n  Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy\nOptimization for coordinated lane-clearing in mixed autonomous and human-driven\ntraffic, reducing EMV travel times by 40%.\n  Third, an equity study of NYC Emergency Medical Services revealed disparities\nacross boroughs: Staten Island faces delays due to sparse signalized\nintersections, while Manhattan struggles with congestion. Solutions include\noptimized EMS stations and improved intersection designs.\n  These contributions enhance EMV mobility and emergency service equity,\noffering insights for policymakers and urban planners to develop safer, more\nefficient transportation systems.",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Ph.D. dissertation in Transportation Systems",
    "pdf_url": "http://arxiv.org/pdf/2502.16449v1",
    "published_date": "2025-02-23 05:34:32 UTC",
    "updated_date": "2025-02-23 05:34:32 UTC"
  },
  {
    "arxiv_id": "2502.16446v1",
    "title": "Auxiliary Discrminator Sequence Generative Adversarial Networks (ADSeqGAN) for Few Sample Molecule Generation",
    "authors": [
      "Haocheng Tang",
      "Jing Long",
      "Junmei Wang"
    ],
    "abstract": "In this work, we introduce Auxiliary Discriminator Sequence Generative\nAdversarial Networks (ADSeqGAN), a novel approach for molecular generation in\nsmall-sample datasets. Traditional generative models often struggle with\nlimited training data, particularly in drug discovery, where molecular datasets\nfor specific therapeutic targets, such as nucleic acids binders and central\nnervous system (CNS) drugs, are scarce. ADSeqGAN addresses this challenge by\nintegrating an auxiliary random forest classifier as an additional\ndiscriminator into the GAN framework, significantly improves molecular\ngeneration quality and class specificity.\n  Our method incorporates pretrained generator and Wasserstein distance to\nenhance training stability and diversity. We evaluate ADSeqGAN on a dataset\ncomprising nucleic acid-targeting and protein-targeting small molecules,\ndemonstrating its superior ability to generate nucleic acid binders compared to\nbaseline models such as SeqGAN, ORGAN, and MolGPT. Through an oversampling\nstrategy, ADSeqGAN also significantly improves CNS drug generation, achieving a\nhigher yield than traditional de novo models. Critical assessments, including\ndocking simulations and molecular property analysis, confirm that\nADSeqGAN-generated molecules exhibit strong binding affinities, enhanced\nchemical diversity, and improved synthetic feasibility.\n  Overall, ADSeqGAN presents a novel framework for generative molecular design\nin data-scarce scenarios, offering potential applications in computational drug\ndiscovery. We have demonstrated the successful applications of ADSeqGAN in\ngenerating synthetic nucleic acid-targeting and CNS drugs in this work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16446v1",
    "published_date": "2025-02-23 05:22:53 UTC",
    "updated_date": "2025-02-23 05:22:53 UTC"
  },
  {
    "arxiv_id": "2502.16445v3",
    "title": "Iterative Flow Matching -- Path Correction and Gradual Refinement for Enhanced Generative Modeling",
    "authors": [
      "Eldad Haber",
      "Shadab Ahamed",
      "Md. Shahriar Rahim Siddiqui",
      "Niloufar Zakariaei",
      "Moshe Eliasof"
    ],
    "abstract": "Generative models for image generation are now commonly used for a wide\nvariety of applications, ranging from guided image generation for entertainment\nto solving inverse problems. Nonetheless, training a generator is a non-trivial\nfeat that requires fine-tuning and can lead to so-called hallucinations, that\nis, the generation of images that are unrealistic. In this work, we explore\nimage generation using flow matching. We explain and demonstrate why flow\nmatching can generate hallucinations, and propose an iterative process to\nimprove the generation process. Our iterative process can be integrated into\nvirtually $\\textit{any}$ generative modeling technique, thereby enhancing the\nperformance and robustness of image synthesis systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16445v3",
    "published_date": "2025-02-23 05:08:06 UTC",
    "updated_date": "2025-03-06 03:55:58 UTC"
  },
  {
    "arxiv_id": "2503.01858v1",
    "title": "A Review of Artificial Intelligence Impacting Statistical Process Monitoring and Future Directions",
    "authors": [
      "Shing I Chang",
      "Parviz Ghafariasl"
    ],
    "abstract": "It has been 100 years since statistical process control (SPC) or statistical\nprocess monitoring (SPM) was first introduced for production processes and\nlater applied to service, healthcare, and other industries. The techniques\napplied to SPM applications are mostly statistically oriented. Recent advances\nin Artificial Intelligence (AI) have reinvigorated the imagination of adopting\nAI for SPM applications. This manuscript begins with a concise review of the\nhistorical development of the statistically based SPM methods. Next, this\nmanuscript explores AI and Machine Learning (ML) algorithms and methods applied\nin various SPM applications, addressing quality characteristics of univariate,\nmultivariate, profile, and image. These AI methods can be classified into the\nfollowing categories: classification, pattern recognition, time series\napplications, and generative AI. Specifically, different kinds of neural\nnetworks, such as artificial neural networks (ANN), convolutional neural\nnetworks (CNN), recurrent neural networks (RNN), and generative adversarial\nnetworks (GAN), are among the most implemented AI methods impacting SPM.\nFinally, this manuscript outlines a couple of future directions that harness\nthe potential of the Large Multimodal Model (LMM) for advancing SPM research\nand applications in complex systems. The ultimate objective is to transform\nstatistical process monitoring (SPM) into smart process control (SMPC), where\ncorrective actions are autonomously implemented to either prevent quality\nissues or restore process performance.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "44 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01858v1",
    "published_date": "2025-02-23 04:19:58 UTC",
    "updated_date": "2025-02-23 04:19:58 UTC"
  },
  {
    "arxiv_id": "2502.17518v1",
    "title": "Ensemble RL through Classifier Models: Enhancing Risk-Return Trade-offs in Trading Strategies",
    "authors": [
      "Zheli Xiong"
    ],
    "abstract": "This paper presents a comprehensive study on the use of ensemble\nReinforcement Learning (RL) models in financial trading strategies, leveraging\nclassifier models to enhance performance. By combining RL algorithms such as\nA2C, PPO, and SAC with traditional classifiers like Support Vector Machines\n(SVM), Decision Trees, and Logistic Regression, we investigate how different\nclassifier groups can be integrated to improve risk-return trade-offs. The\nstudy evaluates the effectiveness of various ensemble methods, comparing them\nwith individual RL models across key financial metrics, including Cumulative\nReturns, Sharpe Ratios (SR), Calmar Ratios, and Maximum Drawdown (MDD). Our\nresults demonstrate that ensemble methods consistently outperform base models\nin terms of risk-adjusted returns, providing better management of drawdowns and\noverall stability. However, we identify the sensitivity of ensemble performance\nto the choice of variance threshold {\\tau}, highlighting the importance of\ndynamic {\\tau} adjustment to achieve optimal performance. This study emphasizes\nthe value of combining RL with classifiers for adaptive decision-making, with\nimplications for financial trading, robotics, and other dynamic environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.CP",
      "stat.ML",
      "68T42"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages,5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.17518v1",
    "published_date": "2025-02-23 04:18:05 UTC",
    "updated_date": "2025-02-23 04:18:05 UTC"
  },
  {
    "arxiv_id": "2502.16433v1",
    "title": "Sequence-level Large Language Model Training with Contrastive Preference Optimization",
    "authors": [
      "Zhili Feng",
      "Dhananjay Ram",
      "Cole Hawkins",
      "Aditya Rawal",
      "Jinman Zhao",
      "Sheng Zha"
    ],
    "abstract": "The next token prediction loss is the dominant self-supervised training\nobjective for large language models and has achieved promising results in a\nvariety of downstream tasks. However, upon closer investigation of this\nobjective, we find that it lacks an understanding of sequence-level signals,\nleading to a mismatch between training and inference processes. To bridge this\ngap, we introduce a contrastive preference optimization (CPO) procedure that\ncan inject sequence-level information into the language model at any training\nstage without expensive human labeled data. Our experiments show that the\nproposed objective surpasses the next token prediction in terms of win rate in\nthe instruction-following and text generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16433v1",
    "published_date": "2025-02-23 04:13:27 UTC",
    "updated_date": "2025-02-23 04:13:27 UTC"
  },
  {
    "arxiv_id": "2502.16428v1",
    "title": "Visual Reasoning Evaluation of Grok, Deepseek Janus, Gemini, Qwen, Mistral, and ChatGPT",
    "authors": [
      "Nidhal Jegham",
      "Marwan Abdelatti",
      "Abdeltawab Hendawi"
    ],
    "abstract": "Traditional evaluations of multimodal large language models (LLMs) have been\nlimited by their focus on single-image reasoning, failing to assess crucial\naspects like contextual understanding, reasoning stability, and uncertainty\ncalibration. This study addresses these limitations by introducing a novel\nbenchmark that integrates multi-image reasoning tasks with rejection-based\nevaluation and positional bias detection. To evaluate these dimensions, we\nfurther introduce entropy as a novel metric for quantifying reasoning\nconsistency across reordered answer variants. We applied this benchmark to\nassess Grok 3, ChatGPT-4o, ChatGPT-o1, Gemini 2.0 Flash Experimental, DeepSeek\nJanus models, Qwen2.5-VL-72B-Instruct, QVQ-72B-Preview, and Pixtral 12B across\neight visual reasoning tasks, including difference spotting and diagram\ninterpretation. Our findings reveal ChatGPT-o1 leading in overall accuracy\n(82.5\\%) and rejection accuracy (70.0\\%), closely followed by Gemini 2.0 Flash\nExperimental (70.8\\%). QVQ-72B-Preview demonstrated superior rejection accuracy\n(85.5\\%). Notably, Pixtral 12B (51.7\\%) showed promise in specific domains,\nwhile Janus models exhibited challenges in bias and uncertainty calibration,\nreflected in low rejection accuracies and high entropy scores. High entropy\nscores in Janus models (Janus 7B: 0.8392, Janus 1B: 0.787) underscore their\nsusceptibility to positional bias and unstable reasoning, contrasting with the\nlow entropy and robust reasoning of ChatGPT models. The study further\ndemonstrates that model size is not the sole determinant of performance, as\nevidenced by Grok 3 underperformance despite its substantial parameter count.\nBy employing multi-image contexts, rejection mechanisms, and entropy-based\nconsistency metrics, this benchmark sets a new standard for evaluating\nmultimodal LLMs, enabling a more robust and reliable assessment of\nnext-generation AI systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16428v1",
    "published_date": "2025-02-23 04:01:43 UTC",
    "updated_date": "2025-02-23 04:01:43 UTC"
  },
  {
    "arxiv_id": "2502.17517v1",
    "title": "Attention-based UAV Trajectory Optimization for Wireless Power Transfer-assisted IoT Systems",
    "authors": [
      "Li Dong",
      "Feibo Jiang",
      "Yubo Peng"
    ],
    "abstract": "Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted\nInternet of Things (IoT) systems face the following challenges: limited\nresources and suboptimal trajectory planning. Reinforcement learning-based\ntrajectory planning schemes face issues of low search efficiency and learning\ninstability when optimizing large-scale systems. To address these issues, we\npresent an Attention-based UAV Trajectory Optimization (AUTO) framework based\non the graph transformer, which consists of an Attention Trajectory\nOptimization Model (ATOM) and a Trajectory lEarNing Method based on\nActor-critic (TENMA). In ATOM, a graph encoder is used to calculate the\nself-attention characteristics of all IoTDs, and a trajectory decoder is\ndeveloped to optimize the number and trajectories of UAVs. TENMA then trains\nthe ATOM using an improved Actor-Critic method, in which the real reward of the\nsystem is applied as the baseline to reduce variances in the critic network.\nThis method is suitable for high-quality and large-scale multi-UAV trajectory\nplanning. Finally, we develop numerous experiments, including a hardware\nexperiment in the field case, to verify the feasibility and efficiency of the\nAUTO framework.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17517v1",
    "published_date": "2025-02-23 02:57:06 UTC",
    "updated_date": "2025-02-23 02:57:06 UTC"
  },
  {
    "arxiv_id": "2502.18517v1",
    "title": "RewardDS: Privacy-Preserving Fine-Tuning for Large Language Models via Reward Driven Data Synthesis",
    "authors": [
      "Jianwei Wang",
      "Junyao Yang",
      "Haoran Li",
      "Huiping Zhuang",
      "Cen Chen",
      "Ziqian Zeng"
    ],
    "abstract": "The success of large language models (LLMs) has attracted many individuals to\nfine-tune them for domain-specific tasks by uploading their data. However, in\nsensitive areas like healthcare and finance, privacy concerns often arise. One\npromising solution is to sample synthetic data with Differential Privacy (DP)\nguarantees to replace private data. However, these synthetic data contain\nsignificant flawed data, which are considered as noise. Existing solutions\ntypically rely on naive filtering by comparing ROUGE-L scores or embedding\nsimilarities, which are ineffective in addressing the noise. To address this\nissue, we propose RewardDS, a novel privacy-preserving framework that\nfine-tunes a reward proxy model and uses reward signals to guide the synthetic\ndata generation. Our RewardDS introduces two key modules, Reward Guided\nFiltering and Self-Optimizing Refinement, to both filter and refine the\nsynthetic data, effectively mitigating the noise. Extensive experiments across\nmedical, financial, and code generation domains demonstrate the effectiveness\nof our method.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18517v1",
    "published_date": "2025-02-23 02:52:23 UTC",
    "updated_date": "2025-02-23 02:52:23 UTC"
  },
  {
    "arxiv_id": "2502.16414v1",
    "title": "TabGen-ICL: Residual-Aware In-Context Example Selection for Tabular Data Generation",
    "authors": [
      "Liancheng Fang",
      "Aiwei Liu",
      "Hengrui Zhang",
      "Henry Peng Zou",
      "Weizhi Zhang",
      "Philip S. Yu"
    ],
    "abstract": "Large Language models (LLMs) have achieved encouraging results in tabular\ndata generation. However, existing approaches require fine-tuning, which is\ncomputationally expensive. This paper explores an alternative: prompting a\nfixed LLM with in-context examples. We observe that using randomly selected\nin-context examples hampers the LLM's performance, resulting in sub-optimal\ngeneration quality. To address this, we propose a novel in-context learning\nframework: TabGen-ICL, to enhance the in-context learning ability of LLMs for\ntabular data generation. TabGen-ICL operates iteratively, retrieving a subset\nof real samples that represent the residual between currently generated samples\nand true data distributions. This approach serves two purposes: locally, it\nprovides more effective in-context learning examples for the LLM in each\niteration; globally, it progressively narrows the gap between generated and\nreal data. Extensive experiments on five real-world tabular datasets\ndemonstrate that TabGen-ICL significantly outperforms the random selection\nstrategy. Specifically, it reduces the error rate by a margin of $3.5\\%-42.2\\%$\non fidelity metrics. We demonstrate for the first time that prompting a fixed\nLLM can yield high-quality synthetic tabular data. The code is provided in the\n\\href{https://github.com/fangliancheng/TabGEN-ICL}{link}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16414v1",
    "published_date": "2025-02-23 02:51:58 UTC",
    "updated_date": "2025-02-23 02:51:58 UTC"
  },
  {
    "arxiv_id": "2502.16411v3",
    "title": "Tool or Tutor? Experimental evidence from AI deployment in cancer diagnosis",
    "authors": [
      "Vivianna Fang He",
      "Sihan Li",
      "Phanish Puranam",
      "Feng Lin"
    ],
    "abstract": "Professionals increasingly use Artificial Intelligence (AI) to enhance their\ncapabilities and assist with task execution. While prior research has examined\nthese uses separately, their potential interaction remains underexplored. We\npropose that AI-driven training (\"tutor\") and AI-assisted task completion\n(\"tool\") can have a joint effect on human capability and test this hypothesis\nin the context of lung cancer diagnosis. In a field experiment with 336 medical\nstudents, we manipulated AI deployment in training, in practice, and in both.\nOur findings reveal that while AI-integrated training and AI assistance\nindependently improved diagnostic performance, their combination yielded the\nhighest accuracy. These results underscore AI's dual role in enhancing human\nperformance through both learning and real-time support, offering insights into\nAI deployment in professional settings where human expertise remains essential.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16411v3",
    "published_date": "2025-02-23 02:47:49 UTC",
    "updated_date": "2025-03-30 09:36:10 UTC"
  },
  {
    "arxiv_id": "2502.16406v1",
    "title": "TrustChain: A Blockchain Framework for Auditing and Verifying Aggregators in Decentralized Federated Learning",
    "authors": [
      "Ehsan Hallaji",
      "Roozbeh Razavi-Far",
      "Mehrdad Saif"
    ],
    "abstract": "The server-less nature of Decentralized Federated Learning (DFL) requires\nallocating the aggregation role to specific participants in each federated\nround. Current DFL architectures ensure the trustworthiness of the aggregator\nnode upon selection. However, most of these studies overlook the possibility\nthat the aggregating node may turn rogue and act maliciously after being\nnominated. To address this problem, this paper proposes a DFL structure, called\nTrustChain, that scores the aggregators before selection based on their past\nbehavior and additionally audits them after the aggregation. To do this, the\nstatistical independence between the client updates and the aggregated model is\ncontinuously monitored using the Hilbert-Schmidt Independence Criterion (HSIC).\nThe proposed method relies on several principles, including blockchain, anomaly\ndetection, and concept drift analysis. The designed structure is evaluated on\nseveral federated datasets and attack scenarios with different numbers of\nByzantine nodes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16406v1",
    "published_date": "2025-02-23 02:26:17 UTC",
    "updated_date": "2025-02-23 02:26:17 UTC"
  },
  {
    "arxiv_id": "2504.05318v1",
    "title": "Efficient Multi-Task Learning via Generalist Recommender",
    "authors": [
      "Luyang Wang",
      "Cangcheng Tang",
      "Chongyang Zhang",
      "Jun Ruan",
      "Kai Huang",
      "Jason Dai"
    ],
    "abstract": "Multi-task learning (MTL) is a common machine learning technique that allows\nthe model to share information across different tasks and improve the accuracy\nof recommendations for all of them. Many existing MTL implementations suffer\nfrom scalability issues as the training and inference performance can degrade\nwith the increasing number of tasks, which can limit production use case\nscenarios for MTL-based recommender systems. Inspired by the recent advances of\nlarge language models, we developed an end-to-end efficient and scalable\nGeneralist Recommender (GRec). GRec takes comprehensive data signals by\nutilizing NLP heads, parallel Transformers, as well as a wide and deep\nstructure to process multi-modal inputs. These inputs are then combined and fed\nthrough a newly proposed task-sentence level routing mechanism to scale the\nmodel capabilities on multiple tasks without compromising performance. Offline\nevaluations and online experiments show that GRec significantly outperforms our\nprevious recommender solutions. GRec has been successfully deployed on one of\nthe largest telecom websites and apps, effectively managing high volumes of\nonline traffic every day.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05318v1",
    "published_date": "2025-02-23 02:05:28 UTC",
    "updated_date": "2025-02-23 02:05:28 UTC"
  },
  {
    "arxiv_id": "2502.16402v1",
    "title": "Navigation-GPT: A Robust and Adaptive Framework Utilizing Large Language Models for Navigation Applications",
    "authors": [
      "Feng Ma",
      "Xiu-min Wang",
      "Chen Chen",
      "Xiao-bin Xu",
      "Xin-ping Yan"
    ],
    "abstract": "Existing navigation decision support systems often perform poorly when\nhandling non-predefined navigation scenarios. Leveraging the generalization\ncapabilities of large language model (LLM) in handling unknown scenarios, this\nresearch proposes a dual-core framework for LLM applications to address this\nissue. Firstly, through ReAct-based prompt engineering, a larger LLM core\ndecomposes intricate navigation tasks into manageable sub-tasks, which\nautonomously invoke corresponding external tools to gather relevant\ninformation, using this feedback to mitigate the risk of LLM hallucinations.\nSubsequently, a fine-tuned and compact LLM core, acting like a first-mate is\ndesigned to process such information and unstructured external data, then to\ngenerates context-aware recommendations, ultimately delivering lookout insights\nand navigation hints that adhere to the International Regulations for\nPreventing Collisions at Sea (COLREGs) and other rules. Extensive experiments\ndemonstrate the proposed framework not only excels in traditional ship\ncollision avoidance tasks but also adapts effectively to unstructured,\nnon-predefined, and unpredictable scenarios. A comparative analysis with\nDeepSeek-R1, GPT-4o and other SOTA models highlights the efficacy and\nrationality of the proposed framework. This research bridges the gap between\nconventional navigation systems and LLMs, offering a framework to enhance\nsafety and operational efficiency across diverse navigation applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16402v1",
    "published_date": "2025-02-23 01:41:58 UTC",
    "updated_date": "2025-02-23 01:41:58 UTC"
  },
  {
    "arxiv_id": "2502.16399v1",
    "title": "Ensemble ToT of LLMs and Its Application to Automatic Grading System for Supporting Self-Learning",
    "authors": [
      "Yuki Ito",
      "Qiang Ma"
    ],
    "abstract": "Providing students with detailed and timely grading feedback is essential for\nself-learning. While existing LLM-based grading systems are promising, most of\nthem rely on one single model, which limits their performance. To address this,\nwe propose Ensemble Tree-of-Thought (ToT), a framework that enhances LLM\noutputs by integrating multiple models. Using this framework, we develop a\ngrading system. Ensemble ToT follows three steps: (1) analyzing LLM\nperformance, (2) generating candidate answers, and (3) refining them into a\nfinal result. Based on this, our grading system first evaluates the grading\ntendencies of LLMs, then generates multiple results, and finally integrates\nthem via a simulated debate. Experimental results demonstrate our approach's\nability to provide accurate and explainable grading by effectively coordinating\nmultiple LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "I.2.7; K.3.1; K.3.2"
    ],
    "primary_category": "cs.IR",
    "comment": "33 pages, 25 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.16399v1",
    "published_date": "2025-02-23 01:17:46 UTC",
    "updated_date": "2025-02-23 01:17:46 UTC"
  },
  {
    "arxiv_id": "2502.16396v1",
    "title": "FedNIA: Noise-Induced Activation Analysis for Mitigating Data Poisoning in FL",
    "authors": [
      "Ehsan Hallaji",
      "Roozbeh Razavi-Far",
      "Mehrdad Saif"
    ],
    "abstract": "Federated learning systems are increasingly threatened by data poisoning\nattacks, where malicious clients compromise global models by contributing\ntampered updates. Existing defenses often rely on impractical assumptions, such\nas access to a central test dataset, or fail to generalize across diverse\nattack types, particularly those involving multiple malicious clients working\ncollaboratively. To address this, we propose Federated Noise-Induced Activation\nAnalysis (FedNIA), a novel defense framework to identify and exclude\nadversarial clients without relying on any central test dataset. FedNIA injects\nrandom noise inputs to analyze the layerwise activation patterns in client\nmodels leveraging an autoencoder that detects abnormal behaviors indicative of\ndata poisoning. FedNIA can defend against diverse attack types, including\nsample poisoning, label flipping, and backdoors, even in scenarios with\nmultiple attacking nodes. Experimental results on non-iid federated datasets\ndemonstrate its effectiveness and robustness, underscoring its potential as a\nfoundational approach for enhancing the security of federated learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16396v1",
    "published_date": "2025-02-23 01:16:01 UTC",
    "updated_date": "2025-02-23 01:16:01 UTC"
  },
  {
    "arxiv_id": "2502.16395v1",
    "title": "An Analyst-Inspector Framework for Evaluating Reproducibility of LLMs in Data Science",
    "authors": [
      "Qiuhai Zeng",
      "Claire Jin",
      "Xinyue Wang",
      "Yuhan Zheng",
      "Qunhua Li"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated potential for data science\ntasks via code generation. However, the exploratory nature of data science,\nalongside the stochastic and opaque outputs of LLMs, raise concerns about their\nreliability. While prior work focuses on benchmarking LLM accuracy,\nreproducibility remains underexplored, despite being critical to establishing\ntrust in LLM-driven analysis.\n  We propose a novel analyst-inspector framework to automatically evaluate and\nenforce the reproducibility of LLM-generated data science workflows - the first\nrigorous approach to the best of our knowledge. Defining reproducibility as the\nsufficiency and completeness of workflows for reproducing functionally\nequivalent code, this framework enforces computational reproducibility\nprinciples, ensuring transparent, well-documented LLM workflows while\nminimizing reliance on implicit model assumptions.\n  Using this framework, we systematically evaluate five state-of-the-art LLMs\non 1,032 data analysis tasks across three diverse benchmark datasets. We also\nintroduce two novel reproducibility-enhancing prompting strategies. Our results\nshow that higher reproducibility strongly correlates with improved accuracy and\nreproducibility-enhancing prompts are effective, demonstrating structured\nprompting's potential to enhance automated data science workflows and enable\ntransparent, robust AI-driven analysis. Our code is publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.16395v1",
    "published_date": "2025-02-23 01:15:50 UTC",
    "updated_date": "2025-02-23 01:15:50 UTC"
  },
  {
    "arxiv_id": "2503.00020v1",
    "title": "A Systematic Review of Open Datasets Used in Text-to-Image (T2I) Gen AI Model Safety",
    "authors": [
      "Rakeen Rouf",
      "Trupti Bavalatti",
      "Osama Ahmed",
      "Dhaval Potdar",
      "Faraz Jawed"
    ],
    "abstract": "Novel research aimed at text-to-image (T2I) generative AI safety often relies\non publicly available datasets for training and evaluation, making the quality\nand composition of these datasets crucial. This paper presents a comprehensive\nreview of the key datasets used in the T2I research, detailing their collection\nmethods, compositions, semantic and syntactic diversity of prompts and the\nquality, coverage, and distribution of harm types in the datasets. By\nhighlighting the strengths and limitations of the datasets, this study enables\nresearchers to find the most relevant datasets for a use case, critically\nassess the downstream impacts of their work given the dataset distribution,\nparticularly regarding model safety and ethical considerations, and also\nidentify the gaps in dataset coverage and quality that future research may\naddress.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for publication in IEEE Access, DOI:\n  10.1109/ACCESS.2025.3539933",
    "pdf_url": "http://arxiv.org/pdf/2503.00020v1",
    "published_date": "2025-02-23 00:59:04 UTC",
    "updated_date": "2025-02-23 00:59:04 UTC"
  },
  {
    "arxiv_id": "2502.16389v1",
    "title": "An Expert Ensemble for Detecting Anomalous Scenes, Interactions, and Behaviors in Autonomous Driving",
    "authors": [
      "Tianchen Ji",
      "Neeloy Chakraborty",
      "Andre Schreiber",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "As automated vehicles enter public roads, safety in a near-infinite number of\ndriving scenarios becomes one of the major concerns for the widespread adoption\nof fully autonomous driving. The ability to detect anomalous situations outside\nof the operational design domain is a key component in self-driving cars,\nenabling us to mitigate the impact of abnormal ego behaviors and to realize\ntrustworthy driving systems. On-road anomaly detection in egocentric videos\nremains a challenging problem due to the difficulties introduced by complex and\ninteractive scenarios. We conduct a holistic analysis of common on-road anomaly\npatterns, from which we propose three unsupervised anomaly detection experts: a\nscene expert that focuses on frame-level appearances to detect abnormal scenes\nand unexpected scene motions; an interaction expert that models normal relative\nmotions between two road participants and raises alarms whenever anomalous\ninteractions emerge; and a behavior expert which monitors abnormal behaviors of\nindividual objects by future trajectory prediction. To combine the strengths of\nall the modules, we propose an expert ensemble (Xen) using a Kalman filter, in\nwhich the final anomaly score is absorbed as one of the states and the\nobservations are generated by the experts. Our experiments employ a novel\nevaluation protocol for realistic model performance, demonstrate superior\nanomaly detection performance than previous methods, and show that our\nframework has potential in classifying anomaly types using unsupervised\nlearning on a large-scale on-road anomaly dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by International Journal of Robotics Research (IJRR)",
    "pdf_url": "http://arxiv.org/pdf/2502.16389v1",
    "published_date": "2025-02-23 00:43:23 UTC",
    "updated_date": "2025-02-23 00:43:23 UTC"
  }
]