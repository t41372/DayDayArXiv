{
  "date": "2025-07-22",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-07-22 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“**ï¼š\nä»Šå¤©çš„ arXiv è®ºæ–‡çˆ†å‘å¼å¢é•¿ï¼Œå°¤å…¶æ˜¯ **AI for Science**ï¼ˆç§‘å­¦æ¨ç†ä¸ææ–™å‘ç°ï¼‰ã€**3D ç”Ÿæˆæ¨¡å‹**ï¼ˆåœ°çƒçº§åœºæ™¯ä¸è™šæ‹Ÿäººï¼‰ä»¥åŠ **LLM å®‰å…¨ä¸å¯¹é½**ï¼ˆå¦‚ä½•å¹³è¡¡å®‰å…¨æ€§ä¸æ¨ç†èƒ½åŠ›ï¼‰è¿™ä¸‰ä¸ªæ–¹å‘ä»¤äººç©ç›®ã€‚Inworld AI å‘å¸ƒäº†å¤§è§„æ¨¡ TTS æŠ€æœ¯æŠ¥å‘Šï¼Œè€Œå…³äº \"Safety Tax\"ï¼ˆå®‰å…¨ç¨ï¼‰çš„è®¨è®ºè¿æ¥äº†æ–°çš„è§£æ³•â€”â€”LoRA ä¼¼ä¹æ˜¯ä¿æŒæ¨ç†æ¨¡å‹æ™ºå•†çš„å…³é”®ã€‚\n\n---\n\n### ğŸš€ å¤´æ¡å…³æ³¨ï¼šè¯­éŸ³åˆæˆä¸ 3D ä¸–ç•Œæ„å»º\n\n**1. [TTS-1 Technical Report] Inworld TTS-1 æŠ€æœ¯æŠ¥å‘Š**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šInworld AI å‘å¸ƒäº†ä¸¤ä¸ªåŸºäº Transformer çš„è‡ªå›å½’ TTS æ¨¡å‹ï¼š8.8B å‚æ•°çš„ **TTS-1-Max**ï¼ˆè¿½æ±‚æè‡´è¡¨ç°åŠ›ï¼‰å’Œ 1.6B çš„ **TTS-1**ï¼ˆè¿½æ±‚å®æ—¶æ€§ï¼‰ã€‚\n> **å…³é”®å‘ç°**ï¼šé€šè¿‡æ‰©å¤§è®­ç»ƒæ—¶çš„è®¡ç®—è§„æ¨¡ï¼Œå¹¶é‡‡ç”¨é¢„è®­ç»ƒã€å¾®è°ƒå’Œ RL-alignmentï¼ˆå¼ºåŒ–å­¦ä¹ å¯¹é½ï¼‰çš„åºåˆ—è¿‡ç¨‹ï¼Œæ¨¡å‹ä»…é  In-context Learning å°±èƒ½å®ç° SOTA çš„å£°éŸ³å…‹éš†è´¨é‡ã€‚æ”¯æŒ 48kHz é«˜é‡‡æ ·ç‡ã€11 ç§è¯­è¨€ä»¥åŠç»†ç²’åº¦çš„æƒ…æ„Ÿæ§åˆ¶ã€‚\n> **Implication**ï¼šè¿™æ˜¯ç›®å‰å¼€æºç•Œï¼ˆä»£ç å¼€æºï¼Œæ¨¡å‹é—­æºï¼‰éå¸¸æœ‰ç«äº‰åŠ›çš„ TTS æ¨¡å‹ï¼Œå±•ç¤ºäº† SpeechLM åœ¨æƒ…æ„Ÿè¡¨è¾¾ä¸Šçš„ä¸Šé™ã€‚\n\n**2. [EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion] EarthCrafterï¼šé€šè¿‡åŒç¨€ç–æ½œåœ¨æ‰©æ•£å®ç°å¯æ‰©å±•çš„ 3D åœ°çƒç”Ÿæˆ**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³ç”Ÿæˆæ•°åƒå¹³æ–¹å…¬é‡Œ 3D åœ°è¡¨çš„é—®é¢˜ã€‚æå‡ºäº† **Aerial-Earth3D** æ•°æ®é›†ï¼ˆ45M è°·æ­Œåœ°çƒå¸§ï¼‰å’Œ **EarthCrafter** æ¡†æ¶ã€‚\n> **æ–¹æ³•**ï¼šé‡‡ç”¨åŒç¨€ç– 3D-VAE å°†å‡ ä½•ä½“ç´ å’Œçº¹ç†ï¼ˆ2D Gaussian Splatsï¼‰å‹ç¼©åˆ°æ½œåœ¨ç©ºé—´ï¼Œå¹¶ä½¿ç”¨ Flow Matching ç‹¬ç«‹å»ºæ¨¡å‡ ä½•å’Œçº¹ç†ã€‚\n> **Implication**ï¼šè¿™æ˜¯å‘ç”Ÿæˆâ€œæ•°å­—å­ªç”Ÿåœ°çƒâ€è¿ˆå‡ºçš„ä¸€å¤§æ­¥ï¼Œè¿œè¶…ç›®å‰çš„åŸå¸‚çº§ç”Ÿæˆè§„æ¨¡ã€‚\n\n**3. [StreamME: Simplify 3D Gaussian Avatar within Live Stream] StreamMEï¼šç›´æ’­æµä¸­çš„ç®€æ˜“ 3D é«˜æ–¯ Avatar**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§æ— éœ€é¢„å…ˆç¼“å­˜æ•°æ®å³å¯ä»å®æ—¶è§†é¢‘æµé‡å»º 3D å¤´éƒ¨çš„ **On-the-fly** è®­ç»ƒç­–ç•¥ã€‚\n> **æ–¹æ³•**ï¼šåŸºäº 3D Gaussian Splatting (3DGS)ï¼Œæ‘’å¼ƒäº† MLPï¼Œçº¯é å‡ ä½•ä¼˜åŒ–ï¼Œå¹¶å¼•å…¥åŸºäºä¸»ç‚¹çš„ç®€åŒ–ç­–ç•¥æ¥ç¨€ç–åŒ–ç‚¹äº‘ã€‚\n> **Implication**ï¼šæå¤§åœ°é™ä½äº† VR ä¼šè®®å’Œç›´æ’­ä¸­ 3D å½¢è±¡é‡å»ºçš„é—¨æ§›å’Œå¸¦å®½éœ€æ±‚ï¼ŒåŒæ—¶ä¿æŠ¤äº†é¢éƒ¨éšç§ã€‚\n\n---\n\n### ğŸ§  LLM å®‰å…¨ã€æ¨ç†ä¸å¯¹é½\n\n**4. [LoRA is All You Need for Safety Alignment of Reasoning LLMs] LoRA è¶³ä»¥åº”å¯¹æ¨ç†å‹ LLM çš„å®‰å…¨å¯¹é½**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šè§£å†³äº†ä¸€ä¸ªç—›ç‚¹â€”â€”å®‰å…¨å¾®è°ƒé€šå¸¸ä¼šé™ä½æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ˆå³ \"Safety Tax\"ï¼‰ã€‚\n> **å…³é”®å‘ç°**ï¼šä½œè€…å‘ç°ä½¿ç”¨ **LoRA** åœ¨æ‹’ç»æ•°æ®é›†ï¼ˆrefusal datasetsï¼‰ä¸Šè¿›è¡Œ SFTï¼Œå¯ä»¥åœ¨ä¸æŸå®³æ¨ç†èƒ½åŠ›çš„å‰æä¸‹å®ç°å®‰å…¨å¯¹é½ã€‚è¿™æ˜¯å› ä¸ºä½ç§©æ›´æ–°æœ€å°åŒ–äº†å¯¹æ¨ç†æƒé‡çš„å½±å“ã€‚\n> **Implication**ï¼šå¯¹äºé‚£äº›æƒ³è¦éƒ¨ç½²æ¨ç†æ¨¡å‹ï¼ˆå¦‚ Llama-3-Reasoning ç±»ï¼‰ä½†åˆæ‹…å¿ƒå®‰å…¨é—®é¢˜çš„å¼€å‘è€…æ¥è¯´ï¼ŒLoRA æ˜¯æ¯”å…¨é‡å¾®è°ƒæ›´å¥½çš„é€‰æ‹©ã€‚\n\n**5. [MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning] MegaScienceï¼šæ¨åŠ¨ç§‘å­¦æ¨ç†åè®­ç»ƒæ•°æ®é›†çš„å‰æ²¿**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå¡«è¡¥äº†å¼€æºç¤¾åŒºåœ¨ç§‘å­¦é¢†åŸŸï¼ˆéæ•°å­¦/ä»£ç ï¼‰æ¨ç†æ•°æ®çš„ç©ºç™½ã€‚å‘å¸ƒäº† **MegaScience**ï¼ŒåŒ…å« 125 ä¸‡æ¡é«˜è´¨é‡ç§‘å­¦æ¨ç†æ•°æ®ï¼Œæ¶µç›– 7 ä¸ªå­¦ç§‘ã€‚\n> **æˆæœ**ï¼šåŸºäºæ­¤æ•°æ®é›†è®­ç»ƒçš„ Llama3.1 å’Œ Qwen2.5 åœ¨ç§‘å­¦æ¨ç†ä»»åŠ¡ä¸Šæ˜¾è‘—ä¼˜äºå®˜æ–¹ Instruct æ¨¡å‹ã€‚\n> **Implication**ï¼šAI Scientist çš„å‘å±•éœ€è¦é«˜è´¨é‡çš„é¢†åŸŸæ•°æ®ï¼Œè¿™ä¸ªæ•°æ®é›†æ˜¯å¼€æºç¤¾åŒºçš„é‡è¦è¡¥å……ã€‚\n\n**6. [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry] ResearcherBenchï¼šè¯„ä¼°å‰æ²¿ç§‘å­¦æ¢ç´¢ä¸­çš„æ·±åº¦ AI ç ”ç©¶ç³»ç»Ÿ**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæå‡ºäº†ä¸€ä¸ªä¸“é—¨è¯„ä¼° AI Agent è¿›è¡Œâ€œæ·±åº¦ç ”ç©¶â€ï¼ˆDeep Researchï¼‰èƒ½åŠ›çš„åŸºå‡†ï¼ŒåŒ…å« 65 ä¸ªä¸“å®¶çº§ç§‘ç ”é—®é¢˜ï¼ˆæŠ€æœ¯ç»†èŠ‚ã€æ–‡çŒ®ç»¼è¿°ã€å¼€æ”¾å’¨è¯¢ï¼‰ã€‚\n> **å‘ç°**ï¼šOpenAI Deep Research å’Œ Gemini Deep Research è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶æ˜¯åœ¨å¼€æ”¾å¼å’¨è¯¢é—®é¢˜ä¸Šã€‚\n\n**7. [Turning Internal Gap into Self-Improvement: Promoting the Generation-Understanding Unification in MLLMs] å°†å†…éƒ¨å·®è·è½¬åŒ–ä¸ºè‡ªæˆ‘æå‡ï¼šä¿ƒè¿› MLLM ç”Ÿæˆä¸ç†è§£çš„ç»Ÿä¸€**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šå‘ç°å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰æ™®éå­˜åœ¨â€œç†è§£å¼ºäºç”Ÿæˆâ€çš„å†…éƒ¨å·®è·ï¼ˆInternal Gapï¼‰ã€‚\n> **æ–¹æ³•**ï¼šåˆ©ç”¨æ¨¡å‹è¾ƒå¼ºçš„ç†è§£èƒ½åŠ›æ¥è¯„ä¼°å’Œç­›é€‰è‡ªå·±çš„ç”Ÿæˆç»“æœï¼Œæ„é€ åå¥½æ•°æ®è¿›è¡Œè‡ªæˆ‘å¯¹é½ï¼ˆSFT å’Œ DPOï¼‰ã€‚\n> **Implication**ï¼šä¸€ç§æ— éœ€å¤–éƒ¨æ ‡æ³¨çš„ Self-Alignment ç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆæå‡ MLLM çš„ç”Ÿæˆè´¨é‡ã€‚\n\n---\n\n### ğŸ‘ï¸ è§†è§‰ä¸å¤šæ¨¡æ€æ„ŸçŸ¥\n\n**8. [SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction] SDGOCCï¼šç”¨äº 3D å¤šæ¨¡æ€å æ®é¢„æµ‹çš„è¯­ä¹‰ä¸æ·±åº¦å¼•å¯¼ BEV å˜æ¢**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šé’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­çš„å æ®æ …æ ¼é¢„æµ‹ï¼Œæå‡ºäº† SDGOCC ç½‘ç»œã€‚\n> **æ–¹æ³•**ï¼šç»“åˆäº†è¯­ä¹‰å’Œæ·±åº¦å¼•å¯¼çš„è§†è§’è½¬æ¢ï¼ˆView Transformationï¼‰ï¼Œå¹¶é€šè¿‡ä¸»åŠ¨è’¸é¦ï¼ˆActive Distillationï¼‰èåˆ LiDAR å’Œç›¸æœºçš„ç‰¹å¾ã€‚\n> **Implication**ï¼šåœ¨ Occ3D-nuScenes æ•°æ®é›†ä¸Šå®ç°äº† SOTA ä¸”ä¿æŒå®æ—¶å¤„ç†èƒ½åŠ›ï¼Œå¯¹è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥æ¨¡å—æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚\n\n**9. [Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models] Spatial 3D-LLMï¼šæ¢ç´¢ 3D è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„ç©ºé—´æ„ŸçŸ¥**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šç°æœ‰çš„ 3D LLM å¯¹ç©ºé—´ä½ç½®æ„ŸçŸ¥è¾ƒå¼±ã€‚æœ¬æ–‡é€šè¿‡æ¸è¿›å¼ç©ºé—´æ„ŸçŸ¥æ–¹æ¡ˆå¢å¼ºäº† 3D åœºæ™¯çš„ Embeddingã€‚\n> **æ–°ä»»åŠ¡**ï¼šå¼•å…¥äº† 3D ç‰©ä½“è·ç¦»æµ‹é‡å’Œ 3D å¸ƒå±€ç¼–è¾‘ä»»åŠ¡ã€‚\n\n**10. [MVP-LM: Advancing Visual Large Language Model for Multi-granular Versatile Perception] MVP-LMï¼šæ¨è¿›å¤šç²’åº¦é€šç”¨æ„ŸçŸ¥çš„è§†è§‰å¤§è¯­è¨€æ¨¡å‹**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šæ•´åˆäº†åŸºäºè¯ï¼ˆword-basedï¼‰å’ŒåŸºäºå¥ï¼ˆsentence-basedï¼‰çš„æ„ŸçŸ¥ä»»åŠ¡ï¼Œä»¥åŠæ¡†ï¼ˆboxï¼‰å’Œæ©ç ï¼ˆmaskï¼‰é¢„æµ‹ã€‚\n> **æ–¹æ³•**ï¼šå¼•å…¥å¤šç²’åº¦è§£ç å™¨å’Œ CoT é£æ ¼çš„æ•°æ®é›†ç»Ÿä¸€ç­–ç•¥ã€‚\n\n---\n\n### ğŸ§¬ AI for Science å‚ç›´é¢†åŸŸ\n\n**11. [Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design] Perovskite-R1ï¼šç”¨äºé’™é’›çŸ¿å‰é©±ä½“æ·»åŠ å‰‚æ™ºèƒ½å‘ç°çš„é¢†åŸŸä¸“ç”¨ LLM**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šä¸“ä¸ºé’™é’›çŸ¿å¤ªé˜³èƒ½ç”µæ± ç ”å‘æ‰“é€ çš„ LLMï¼Œå¾®è°ƒè‡ª QwQ-32Bã€‚\n> **èƒ½åŠ›**ï¼šèƒ½å¤Ÿè¿›è¡Œ Chain-of-Thought æ¨ç†ï¼Œè¾…åŠ©å®éªŒè®¾è®¡å’Œææ–™å‘ç°ï¼Œæ˜¯ AI è¾…åŠ©ææ–™ç§‘å­¦çš„ä¸€ä¸ªå®Œæ•´é—­ç¯æ¡ˆä¾‹ã€‚\n\n**12. [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting] SpiroLLMï¼šå¾®è°ƒé¢„è®­ç»ƒ LLM ç†è§£è‚ºæ´»é‡æ—¶é—´åºåˆ—ä»¥è¿›è¡Œæ…¢é˜»è‚ºæŠ¥å‘Š**\n> **æ ¸å¿ƒè´¡çŒ®**ï¼šé¦–ä¸ªèƒ½çœ‹æ‡‚è‚ºæ´»é‡æ›²çº¿ï¼ˆSpirogramï¼‰çš„å¤šæ¨¡æ€æ¨¡å‹ã€‚åˆ©ç”¨ UK Biobank çš„ 23 ä¸‡äººæ•°æ®è®­ç»ƒï¼Œè¯Šæ–­ AUROC è¾¾åˆ° 0.8977ã€‚\n\n---\n\n### ğŸ’¡ æœ‰è¶£æˆ–å€¼å¾—ä¸€è¯»çš„å°ä¼—æ–‡ç« \n\n*   **[Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another?]**\n    *   **ä¸€å¥è¯**ï¼šä½œè€…ç ”ç©¶äº†æ•°ç‹¬çš„éš¾åº¦è¯„çº§ï¼Œæå‡ºäº†åŸºäº SAT é—®é¢˜å’Œæ¨¡æ‹Ÿäººç±»è§£é¢˜ç­–ç•¥çš„æ–°æŒ‡æ ‡ï¼Œå‘ç°ä¸åŒç½‘ç«™çš„éš¾åº¦è¯„çº§å·®å¼‚å·¨å¤§ï¼Œå¹¶è¯•å›¾ç»Ÿä¸€æ ‡å‡†ã€‚æ•°ç‹¬çˆ±å¥½è€…çš„ç¦éŸ³ã€‚\n*   **[GOAT: A Large Dataset of Paired Guitar Audio Recordings and Tablatures]**\n    *   **ä¸€å¥è¯**ï¼šå‘å¸ƒäº† GOAT æ•°æ®é›†ï¼ŒåŒ…å« 5.9 å°æ—¶çš„é«˜è´¨é‡ç”µå‰ä»–å½•éŸ³å’Œå¯¹åº”çš„å…­çº¿è°±ï¼ˆTablatureï¼‰ï¼Œç”¨äºå‰ä»–è‡ªåŠ¨è®°è°±å’Œç”Ÿæˆä»»åŠ¡ã€‚\n*   **[Disability Across Cultures: A Human-Centered Audit of Ableism in Western and Indic LLMs]**\n    *   **ä¸€å¥è¯**ï¼šä¸€é¡¹å…³äº LLM ä¸­â€œèƒ½åŠ›æ­§è§†â€ï¼ˆAbleismï¼‰çš„è·¨æ–‡åŒ–å®¡è®¡ã€‚å‘ç°è¥¿æ–¹æ¨¡å‹å€¾å‘äºé«˜ä¼°æ­§è§†ä¼¤å®³ï¼Œè€Œå°åº¦æœ¬åœŸæ¨¡å‹å€¾å‘äºä½ä¼°ã€‚è¿™æ­ç¤ºäº† AI ä»·å€¼è§‚å¯¹é½ä¸­çš„æ–‡åŒ–é¸¿æ²Ÿã€‚\n\n---\nå¸Œæœ›è¿™ä»½å¿«æŠ¥èƒ½å¸®ä½ å¿«é€Ÿæ¶ˆåŒ–ä»Šå¤©çš„ arXiv æ›´æ–°ï¼å¦‚æœæœ‰å¯¹é€šè¿‡ **LoRA è¿›è¡Œå®‰å…¨å¯¹é½** æˆ– **3D åœ°çƒç”Ÿæˆ** ç‰¹åˆ«æ„Ÿå…´è¶£ï¼Œå»ºè®®æ·±å…¥é˜…è¯»åŸæ–‡ã€‚æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2507.21138v1",
      "title": "TTS-1 Technical Report",
      "title_zh": "TTS-1 æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Oleg Atamanenko",
        "Anna Chalova",
        "Joseph Coombes",
        "Nikki Cope",
        "Phillip Dang",
        "Zhifeng Deng",
        "Jimmy Du",
        "Michael Ermolenko",
        "Feifan Fan",
        "Yufei Feng",
        "Cheryl Fichter",
        "Pavel Filimonov",
        "Louis Fischer",
        "Kylan Gibbs",
        "Valeria Gusarova",
        "Pavel Karpik",
        "Andreas Assad Kottner",
        "Ian Lee",
        "Oliver Louie",
        "Jasmine Mai",
        "Mikhail Mamontov",
        "Suri Mao",
        "Nurullah Morshed",
        "Igor Poletaev",
        "Florin Radu",
        "Dmytro Semernia",
        "Evgenii Shingarev",
        "Vikram Sivaraja",
        "Peter Skirko",
        "Rinat Takhautdinov",
        "Robert Villahermosa",
        "Jean Wang"
      ],
      "abstract": "We introduce Inworld TTS-1, a set of two Transformer-based autoregressive text-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters and is designed for utmost quality and expressiveness in demanding applications. TTS-1 is our most efficient model, with 1.6B parameters, built for real-time speech synthesis and on-device use cases. By scaling train-time compute and applying a sequential process of pre-training, fine-tuning, and RL-alignment of the speech-language model (SpeechLM) component, both models achieve state-of-the-art performance on a variety of benchmarks, demonstrating exceptional quality relying purely on in-context learning of the speaker's voice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech with low latency, and support 11 languages with fine-grained emotional control and non-verbal vocalizations through audio markups. We additionally open-source our training and modeling code under an MIT license.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº† Inworld TTS-1 ç³»åˆ—æŠ€æœ¯æŠ¥å‘Šï¼Œä»‹ç»äº†ä¸¤æ¬¾åŸºäº Transformer æ¶æ„çš„è‡ªå›å½’æ–‡æœ¬è½¬è¯­éŸ³ (TTS) æ¨¡å‹ã€‚å…¶ä¸­å‚æ•°é‡ä¸º 8.8B çš„ TTS-1-Max ä¸“æ³¨äºè¿½æ±‚æé«˜çš„éŸ³é¢‘è´¨é‡ä¸è¡¨ç°åŠ›ï¼Œè€Œ 1.6B å‚æ•°çš„ TTS-1 åˆ™æ—¨åœ¨å®ç°é«˜æ•ˆçš„å®æ—¶è¯­éŸ³åˆæˆä¸è®¾å¤‡ç«¯åº”ç”¨ã€‚é€šè¿‡å¤§è§„æ¨¡æ‰©å±•è®­ç»ƒè®¡ç®—ï¼Œå¹¶å¯¹è¯­éŸ³è¯­è¨€æ¨¡å‹ (SpeechLM) ç»„ä»¶è¿›è¡Œé¢„è®­ç»ƒã€å¾®è°ƒåŠå¼ºåŒ–å­¦ä¹ å¯¹é½ (RL-alignment)ï¼Œä¸¤æ¬¾æ¨¡å‹åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†å½“å‰é¢†å…ˆæ°´å¹³ (SOTA)ã€‚æ¨¡å‹ä»…ä¾é è¯­è€…å£°éŸ³çš„ä¸Šä¸‹æ–‡å­¦ä¹  (in-context learning) å³å¯å®ç°å“è¶Šçš„å…‹éš†æ•ˆæœï¼Œæ”¯æŒ 48 kHz é«˜åˆ†è¾¨ç‡è¯­éŸ³ç”ŸæˆåŠä½å»¶è¿Ÿè¾“å‡ºã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿæ¶µç›–äº† 11 ç§è¯­è¨€ï¼Œå¹¶èƒ½é€šè¿‡éŸ³é¢‘æ ‡è®°å®ç°ç²¾ç»†çš„æƒ…æ„Ÿæ§åˆ¶å’Œéè¯­è¨€å‘å£° (non-verbal vocalizations)ã€‚ç ”ç©¶å›¢é˜Ÿæœ€ç»ˆè¿˜ä»¥ MIT è®¸å¯è¯å¼€æºäº†å…¶è®­ç»ƒå’Œå»ºæ¨¡ä»£ç ï¼Œä¸ºè¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 10 figures. For associated modeling and training code, see https://github.com/inworld-ai/tts",
      "pdf_url": "https://arxiv.org/pdf/2507.21138v1",
      "published_date": "2025-07-22 23:57:11 UTC",
      "updated_date": "2025-07-22 23:57:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:33.197718+00:00"
    },
    {
      "arxiv_id": "2507.17083v1",
      "title": "SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction",
      "title_zh": "SDGOCCï¼šé¢å‘ä¸‰ç»´å¤šæ¨¡æ€å æ®é¢„æµ‹çš„è¯­ä¹‰ä¸æ·±åº¦å¼•å¯¼é¸Ÿç°å›¾è½¬æ¢",
      "authors": [
        "Zaipeng Duan",
        "Chenxu Dang",
        "Xuzhong Hu",
        "Pei An",
        "Junfeng Ding",
        "Jie Zhan",
        "Yunbiao Xu",
        "Jie Ma"
      ],
      "abstract": "Multimodal 3D occupancy prediction has garnered significant attention for its potential in autonomous driving. However, most existing approaches are single-modality: camera-based methods lack depth information, while LiDAR-based methods struggle with occlusions. Current lightweight methods primarily rely on the Lift-Splat-Shoot (LSS) pipeline, which suffers from inaccurate depth estimation and fails to fully exploit the geometric and semantic information of 3D LiDAR points. Therefore, we propose a novel multimodal occupancy prediction network called SDG-OCC, which incorporates a joint semantic and depth-guided view transformation coupled with a fusion-to-occupancy-driven active distillation. The enhanced view transformation constructs accurate depth distributions by integrating pixel semantics and co-point depth through diffusion and bilinear discretization. The fusion-to-occupancy-driven active distillation extracts rich semantic information from multimodal data and selectively transfers knowledge to image features based on LiDAR-identified regions. Finally, for optimal performance, we introduce SDG-Fusion, which uses fusion alone, and SDG-KL, which integrates both fusion and distillation for faster inference. Our method achieves state-of-the-art (SOTA) performance with real-time processing on the Occ3D-nuScenes dataset and shows comparable performance on the more challenging SurroundOcc-nuScenes dataset, demonstrating its effectiveness and robustness. The code will be released at https://github.com/DzpLab/SDGOCC.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ä¸­å•æ¨¡æ€ 3D occupancy prediction é¢ä¸´çš„ç›¸æœºæ·±åº¦ç¼ºå¤±ã€LiDAR é®æŒ¡ä»¥åŠè½»é‡åŒ– LSS æ¡†æ¶æ·±åº¦ä¼°è®¡ä¸å‡†ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸º SDG-OCC çš„å¤šæ¨¡æ€å æ®é¢„æµ‹ç½‘ç»œã€‚è¯¥ç½‘ç»œé€šè¿‡è¯­ä¹‰ä¸æ·±åº¦å¼•å¯¼çš„è§†å›¾è½¬æ¢æŠ€æœ¯ï¼Œç»“åˆæ‰©æ•£ä¸åŒçº¿æ€§ç¦»æ•£åŒ– (bilinear discretization) æ•´åˆåƒç´ è¯­ä¹‰ä¸å…±ç‚¹æ·±åº¦ï¼Œæ˜¾è‘—æå‡äº†æ·±åº¦åˆ†å¸ƒçš„å‡†ç¡®æ€§ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†èåˆè‡³å æ®é©±åŠ¨çš„ä¸»åŠ¨è’¸é¦ (active distillation) æœºåˆ¶ï¼Œæ ¹æ® LiDAR è¯†åˆ«åŒºåŸŸå°†å¤šæ¨¡æ€è¯­ä¹‰çŸ¥è¯†é€‰æ‹©æ€§åœ°è¿ç§»è‡³å›¾åƒç‰¹å¾ä¸­ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¨å‡º SDG-Fusion ä¸ SDG-KL ä¸¤ç§å˜ä½“ï¼Œè¯¥æ–¹æ¡ˆåœ¨ç¡®ä¿é«˜æ€§èƒ½çš„åŒæ—¶å…¼é¡¾äº†æ¨ç†é€Ÿåº¦ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSDG-OCC åœ¨ Occ3D-nuScenes æ•°æ®é›†ä¸Šå®ç°äº† SOTA æ€§èƒ½å’Œå®æ—¶å¤„ç†èƒ½åŠ›ï¼Œå¹¶åœ¨ SurroundOcc-nuScenes ä»»åŠ¡ä¸­è¡¨ç°å‡ºä¼˜å¼‚çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by CVPR2025",
      "pdf_url": "https://arxiv.org/pdf/2507.17083v1",
      "published_date": "2025-07-22 23:49:40 UTC",
      "updated_date": "2025-07-22 23:49:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:38.287715+00:00"
    },
    {
      "arxiv_id": "2507.17080v1",
      "title": "VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings",
      "title_zh": "VL-CLIPï¼šåˆ©ç”¨è§†è§‰å®šä½ä¸å¤§è¯­è¨€æ¨¡å‹å¢å¼ºçš„ CLIP åµŒå…¥æå‡å¤šæ¨¡æ€æ¨è",
      "authors": [
        "Ramin Giahi",
        "Kehui Yao",
        "Sriram Kollipara",
        "Kai Zhao",
        "Vahid Mirjalili",
        "Jianpeng Xu",
        "Topojoy Biswas",
        "Evren Korpeoglu",
        "Kannan Achan"
      ],
      "abstract": "Multimodal learning plays a critical role in e-commerce recommendation platforms today, enabling accurate recommendations and product understanding. However, existing vision-language models, such as CLIP, face key challenges in e-commerce recommendation systems: 1) Weak object-level alignment, where global image embeddings fail to capture fine-grained product attributes, leading to suboptimal retrieval performance; 2) Ambiguous textual representations, where product descriptions often lack contextual clarity, affecting cross-modal matching; and 3) Domain mismatch, as generic vision-language models may not generalize well to e-commerce-specific data. To address these limitations, we propose a framework, VL-CLIP, that enhances CLIP embeddings by integrating Visual Grounding for fine-grained visual understanding and an LLM-based agent for generating enriched text embeddings. Visual Grounding refines image representations by localizing key products, while the LLM agent enhances textual features by disambiguating product descriptions. Our approach significantly improves retrieval accuracy, multimodal retrieval effectiveness, and recommendation quality across tens of millions of items on one of the largest e-commerce platforms in the U.S., increasing CTR by 18.6%, ATC by 15.5%, and GMV by 4.0%. Additional experimental results show that our framework outperforms vision-language models, including CLIP, FashionCLIP, and GCL, in both precision and semantic alignment, demonstrating the potential of combining object-aware visual grounding and LLM-enhanced text representation for robust multimodal recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†VL-CLIPæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆå¦‚CLIPï¼‰åœ¨ç”µå­å•†åŠ¡æ¨èç³»ç»Ÿä¸­é¢ä¸´çš„å¯¹è±¡çº§å¯¹é½å¼±ã€æ–‡æœ¬è¡¨ç¤ºæ¨¡ç³Šä»¥åŠé¢†åŸŸä¸åŒ¹é…ç­‰æŒ‘æˆ˜ã€‚ä¸ºäº†æå‡å¤šæ¨¡æ€æ¨èæ•ˆæœï¼ŒVL-CLIPé€šè¿‡æ•´åˆè§†è§‰å®šä½ï¼ˆVisual Groundingï¼‰æŠ€æœ¯æ¥æ•æ‰ç»†ç²’åº¦çš„äº§å“å±æ€§ï¼Œå¹¶åˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ™ºèƒ½ä½“ç”Ÿæˆå¢å¼ºçš„æ–‡æœ¬åµŒå…¥ä»¥æ¶ˆé™¤æè¿°æ­§ä¹‰ã€‚åœ¨ç¾å›½æŸå¤§å‹ç”µå•†å¹³å°çš„æ•°åƒä¸‡ä»¶å•†å“ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æé«˜äº†æ£€ç´¢ç²¾åº¦å’Œæ¨èè´¨é‡ï¼Œä½¿ç‚¹å‡»ç‡ï¼ˆCTRï¼‰å¢é•¿äº†18.6%ï¼ŒåŠ å…¥è´­ç‰©è½¦ç‡ï¼ˆATCï¼‰å¢é•¿äº†15.5%ï¼Œå¹¶å¸¦åŠ¨å•†å“äº¤æ˜“æ€»é¢ï¼ˆGMVï¼‰æå‡äº†4.0%ã€‚æ­¤å¤–ï¼ŒVL-CLIPåœ¨ç²¾ç¡®åº¦å’Œè¯­ä¹‰å¯¹é½æ–¹é¢å‡ä¼˜äºCLIPã€FashionCLIPå’ŒGCLç­‰ä¸»æµæ¨¡å‹ã€‚è¿™ä¸€æˆæœå……åˆ†è¯æ˜äº†ç»“åˆå¯¹è±¡æ„ŸçŸ¥è§†è§‰å®šä½ä¸LLMå¢å¼ºæ–‡æœ¬è¡¨ç¤ºåœ¨æ„å»ºç¨³å¥çš„å¤šæ¨¡æ€æ¨èç³»ç»Ÿä¸­çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at RecSys 2025; DOI:https://doi.org/10.1145/3705328.3748064",
      "pdf_url": "https://arxiv.org/pdf/2507.17080v1",
      "published_date": "2025-07-22 23:45:43 UTC",
      "updated_date": "2025-07-22 23:45:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:38.791222+00:00"
    },
    {
      "arxiv_id": "2507.17075v3",
      "title": "LoRA is All You Need for Safety Alignment of Reasoning LLMs",
      "title_zh": "æ¨ç†å‹å¤§è¯­è¨€æ¨¡å‹çš„å®‰å…¨å¯¹é½ï¼šLoRA å³å¯æ»¡è¶³",
      "authors": [
        "Yihao Xue",
        "Baharan Mirzasoleiman"
      ],
      "abstract": "Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex problems that were previously out of reach. To ensure LLMs do not assist with harmful requests, safety alignment fine-tuning is necessary in the post-training phase. However, safety alignment fine-tuning has recently been shown to significantly degrade reasoning abilities, a phenomenon known as the \"Safety Tax\". In this work, we show that using LoRA for SFT on refusal datasets effectively aligns the model for safety without harming its reasoning capabilities. This is because restricting the safety weight updates to a low-rank space minimizes the interference with the reasoning weights. Our extensive experiments across four benchmarks covering math, science, and coding show that this approach produces highly safe LLMs--with safety levels comparable to full-model fine-tuning--without compromising their reasoning abilities. Our ablation studies further identify three key factors in LoRA: (1) rank-$1$ updates are sufficient to achieve the best reasoning and safety performance, (2) the up projection layers are the most critical modules, with LoRA applied to them alone achieving even better results, and (3) middle layers are more effective than early or late layers. Together, these findings show that strong safety and reasoning can be achieved at minimal computational cost when updates are applied in the right places. Additionally, we observe that LoRA induces weight updates with smaller overlap with the initial weights compared to full-model fine-tuning. Finally, while our attempts to further reduce this overlap yield only modest improvements on some tasks, they highlight the potential of developing methods that more reliably optimize the reasoning-safety tradeoff.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨ç†å¤§è¯­è¨€æ¨¡å‹(Reasoning LLMs)åœ¨å®‰å…¨å¯¹é½(Safety Alignment)å¾®è°ƒè¿‡ç¨‹ä¸­å‡ºç°çš„æ¨ç†èƒ½åŠ›æ˜¾è‘—ä¸‹é™ï¼ˆå³â€œå®‰å…¨ç¨â€ Safety Taxï¼‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºLoRAçš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…é€šè¿‡åœ¨æ‹’ç»æ•°æ®é›†(Refusal Datasets)ä¸Šåº”ç”¨LoRAè¿›è¡Œç›‘ç£å¾®è°ƒ(SFT)ï¼Œè¯æ˜äº†å°†æƒé‡æ›´æ–°é™åˆ¶åœ¨ä½ç§©ç©ºé—´èƒ½å¤Ÿæœ‰æ•ˆå‡å°‘å¯¹æ¨ç†æƒé‡(Reasoning Weights)çš„å¹²æ‰°ï¼Œä»è€Œåœ¨ä¸æŸå®³æ¨ç†èƒ½åŠ›çš„å‰æä¸‹å®ç°é«˜æ°´å¹³çš„å®‰å…¨æ€§ã€‚åœ¨æ•°å­¦ã€ç§‘å­¦å’Œç¼–ç ç­‰å››ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å®‰å…¨æ€§è¡¨ç°ä¸Šå¯ä¸å…¨é‡å¾®è°ƒ(Full-model Fine-tuning)åª²ç¾ï¼Œä¸”å®Œå…¨ä¿ç•™äº†æ¨¡å‹çš„æ¨ç†æ€§èƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥æ­ç¤ºï¼Œä»…éœ€ç§©ä¸º1(Rank-1)çš„æ›´æ–°å³å¯è¾¾åˆ°æœ€ä½³æ•ˆæœï¼Œä¸”ä¸ŠæŠ•å½±å±‚(Up Projection Layers)å’Œä¸­é—´å±‚(Middle Layers)æ˜¯å®ç°å¯¹é½æœ€ä¸ºå…³é”®çš„æ¨¡å—ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•é€šè¿‡æ¯”å…¨é‡å¾®è°ƒæ›´å°çš„æƒé‡é‡å åº¦ï¼Œåœ¨æä½è®¡ç®—æˆæœ¬ä¸‹ä¸ºè§£å†³æ¨¡å‹å®‰å…¨ä¸æ¨ç†èƒ½åŠ›ä¹‹é—´çš„æƒè¡¡æä¾›äº†é‡è¦é€”å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17075v3",
      "published_date": "2025-07-22 23:25:16 UTC",
      "updated_date": "2025-10-24 05:12:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:54.156302+00:00"
    },
    {
      "arxiv_id": "2507.17070v1",
      "title": "Advancing Robustness in Deep Reinforcement Learning with an Ensemble Defense Approach",
      "title_zh": "åŸºäºé›†æˆé˜²å¾¡æ–¹æ³•çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ é²æ£’æ€§æå‡",
      "authors": [
        "Adithya Mohan",
        "Dominik RÃ¶ÃŸle",
        "Daniel Cremers",
        "Torsten SchÃ¶n"
      ],
      "abstract": "Recent advancements in Deep Reinforcement Learning (DRL) have demonstrated its applicability across various domains, including robotics, healthcare, energy optimization, and autonomous driving. However, a critical question remains: How robust are DRL models when exposed to adversarial attacks? While existing defense mechanisms such as adversarial training and distillation enhance the resilience of DRL models, there remains a significant research gap regarding the integration of multiple defenses in autonomous driving scenarios specifically. This paper addresses this gap by proposing a novel ensemble-based defense architecture to mitigate adversarial attacks in autonomous driving. Our evaluation demonstrates that the proposed architecture significantly enhances the robustness of DRL models. Compared to the baseline under FGSM attacks, our ensemble method improves the mean reward from 5.87 to 18.38 (over 213% increase) and reduces the mean collision rate from 0.50 to 0.09 (an 82% decrease) in the highway scenario and merge scenario, outperforming all standalone defense strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)åœ¨è‡ªåŠ¨é©¾é©¶é¢†åŸŸåº”å¯¹å¯¹æŠ—æ€§æ”»å‡»(Adversarial Attacks)çš„é²æ£’æ€§(Robustness)æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰å¯¹æŠ—è®­ç»ƒ(Adversarial Training)å’Œè’¸é¦(Distillation)ç­‰å•ä¸€é˜²å¾¡æ‰‹æ®µåœ¨è‡ªåŠ¨é©¾é©¶é›†æˆåº”ç”¨ä¸­çš„ç ”ç©¶ç©ºç™½ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„é›†æˆé˜²å¾¡æ¶æ„(Ensemble Defense Architecture)ã€‚é€šè¿‡åœ¨é«˜é€Ÿå…¬è·¯(Highway)å’Œå¹¶é“(Merge)åœºæ™¯ä¸‹çš„è¯„ä¼°ï¼Œå®éªŒè¯æ˜è¯¥æ¶æ„èƒ½æ˜¾è‘—å¢å¼ºDRLæ¨¡å‹çš„éŸ§æ€§ã€‚åœ¨é¢å¯¹FGSMæ”»å‡»æ—¶ï¼Œè¯¥é›†æˆæ–¹æ³•å°†å¹³å‡å¥–åŠ±ä»5.87æå‡è‡³18.38ï¼Œå¢å¹…è¶…è¿‡213%ï¼ŒåŒæ—¶å°†å¹³å‡ç¢°æ’ç‡ä»0.50å¤§å¹…é™è‡³0.09ï¼Œé™å¹…è¾¾82%ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨æ€§èƒ½è¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºæ‰€æœ‰ç‹¬ç«‹é˜²å¾¡ç­–ç•¥ï¼Œä¸ºæ„å»ºå®‰å…¨ã€é²æ£’çš„è‡ªä¸»é©¾é©¶ç³»ç»Ÿæä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.17070v1",
      "published_date": "2025-07-22 23:15:11 UTC",
      "updated_date": "2025-07-22 23:15:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:42.991256+00:00"
    },
    {
      "arxiv_id": "2507.17063v1",
      "title": "Compatibility of Max and Sum Objectives for Committee Selection and $k$-Facility Location",
      "title_zh": "å§”å‘˜ä¼šé€‰æ‹©ä¸ $k$-è®¾æ–½é€‰å€ä¸­æœ€å¤§å€¼ä¸æ±‚å’Œç›®æ ‡çš„å…¼å®¹æ€§",
      "authors": [
        "Yue Han",
        "Elliot Anshelevich"
      ],
      "abstract": "We study a version of the metric facility location problem (or, equivalently, variants of the committee selection problem) in which we must choose $k$ facilities in an arbitrary metric space to serve some set of clients $C$. We consider four different objectives, where each client $i\\in C$ attempts to minimize either the sum or the maximum of its distance to the chosen facilities, and where the overall objective either considers the sum or the maximum of the individual client costs. Rather than optimizing a single objective at a time, we study how compatible these objectives are with each other, and show the existence of solutions which are simultaneously close-to-optimum for any pair of the above objectives. Our results show that when choosing a set of facilities or a representative committee, it is often possible to form a solution which is good for several objectives at the same time, instead of sacrificing one desideratum to achieve another.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨åº¦é‡ç©ºé—´å†…é€‰æ‹© $k$ ä¸ªè®¾æ–½ä»¥æœåŠ¡å®¢æˆ·é›†çš„åº¦é‡è®¾æ–½å®šä½é—®é¢˜ ($k$-Facility Location)ï¼Œè¯¥é—®é¢˜åœ¨å§”å‘˜ä¼šé€‰æ‹© (Committee Selection) å˜ä½“ä¸­ä¹Ÿå…·æœ‰ç­‰æ•ˆæ€§ã€‚ç ”ç©¶è€…åˆ†æäº†å››ç§ä¸åŒçš„ç›®æ ‡å‡½æ•°ï¼Œå…·ä½“æ¶µç›–äº†å•ä¸ªå®¢æˆ·è¡¡é‡åˆ°è®¾æ–½è·ç¦»çš„ Sum æˆ– Max æ–¹å¼ï¼Œä»¥åŠå…¨å±€ç›®æ ‡å¯¹å®¢æˆ·æˆæœ¬è¿›è¡Œçš„ Sum æˆ– Max èšåˆã€‚ä¸ä¼ ç»Ÿçš„å•ç›®æ ‡ä¼˜åŒ–ä¸åŒï¼Œè¯¥å·¥ä½œé‡ç‚¹ç ”ç©¶äº†è¿™äº›ç›®æ ‡å‡½æ•°ä¹‹é—´çš„å…¼å®¹æ€§ (Compatibility)ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œå¯¹äºä¸Šè¿°æåˆ°çš„ä»»æ„ä¸¤ç»„ç›®æ ‡ç»„åˆï¼Œéƒ½å­˜åœ¨èƒ½å¤ŸåŒæ—¶æ¥è¿‘æœ€ä¼˜è§£ (Close-to-optimum) çš„æ–¹æ¡ˆã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œåœ¨è¿›è¡Œè®¾æ–½é€‰å€æˆ–å§”å‘˜ä¼šä»£è¡¨é€‰ä¸¾æ—¶ï¼Œå¾€å¾€å¯ä»¥æ„å»ºå‡ºä¸€ä¸ªå…¼é¡¾å¤šä¸ªç›®æ ‡çš„è§£ï¼Œè€Œæ— éœ€ä¸ºäº†æ»¡è¶³æŸä¸€é¡¹æŒ‡æ ‡è€Œç‰ºç‰²å…¶ä»–å…³é”®æ€§èƒ½ã€‚",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17063v1",
      "published_date": "2025-07-22 22:47:35 UTC",
      "updated_date": "2025-07-22 22:47:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:48.436472+00:00"
    },
    {
      "arxiv_id": "2507.17061v4",
      "title": "Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems",
      "title_zh": "å¹¶è¡Œæ€§ä¸è‡ªé€‚åº”æ€§çš„èåˆï¼šå¤šæ™ºèƒ½ä½“å¤§è¯­è¨€æ¨¡å‹ç³»ç»Ÿä¸­çš„å¯æ‰©å±•æ–‡æ¡£ç†è§£",
      "authors": [
        "Chengxuan Xia",
        "Qianye Wu",
        "Sixuan Tian",
        "Yilun Hao"
      ],
      "abstract": "Large language model (LLM) agents have shown increasing promise for collaborative task completion. However, existing multi-agent frameworks often rely on static workflows, fixed roles, and limited inter-agent communication, reducing their effectiveness in open-ended, high-complexity domains. This paper proposes a coordination framework that enables adaptiveness through three core mechanisms: dynamic task routing, bidirectional feedback, and parallel agent evaluation. The framework allows agents to reallocate tasks based on confidence and workload, exchange structured critiques to iteratively improve outputs, and crucially compete on high-ambiguity subtasks with evaluator-driven selection of the most suitable result. We instantiate these principles in a modular architecture and demonstrate substantial improvements in factual coverage, coherence, and efficiency over static and partially adaptive baselines. Our findings highlight the benefits of incorporating both adaptiveness and structured competition in multi-agent LLM systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Multi-Agent LLM Systemsåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶ç”±äºé™æ€å·¥ä½œæµå’Œå›ºå®šè§’è‰²å¯¼è‡´çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ä¸ªå¼ºè°ƒAdaptivenessçš„åè°ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶ç”±Dynamic task routingã€Bidirectional feedbackå’ŒParallel agent evaluationä¸‰å¤§æ ¸å¿ƒæœºåˆ¶ç»„æˆï¼Œæ—¨åœ¨æå‡ç³»ç»Ÿåœ¨å¼€æ”¾é¢†åŸŸä¸­çš„æœ‰æ•ˆæ€§ã€‚é€šè¿‡è¿™äº›æœºåˆ¶ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®Confidenceå’ŒWorkloadåŠ¨æ€é‡æ–°åˆ†é…ä»»åŠ¡ï¼Œåˆ©ç”¨ç»“æ„åŒ–åé¦ˆè¿›è¡Œè¿­ä»£ä¼˜åŒ–ï¼Œå¹¶åœ¨é¢å¯¹é«˜æ­§ä¹‰å­ä»»åŠ¡æ—¶é€šè¿‡ç«äº‰ä¸è¯„ä¼°è€…ç­›é€‰æ¥ç¡®å®šæœ€ä¼˜äº§å‡ºã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¨¡å—åŒ–æ¶æ„åœ¨Factual coverageã€Coherenceå’ŒEfficiencyæ–¹é¢å‡ä¼˜äºä¼ ç»Ÿçš„é™æ€æˆ–åŠè‡ªé€‚åº”åŸºçº¿æ¨¡å‹ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†åœ¨å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿä¸­æ•´åˆè‡ªé€‚åº”èƒ½åŠ›ä¸ç»“æ„åŒ–ç«äº‰å¯¹æå‡å¤§è§„æ¨¡æ–‡æ¡£ç†è§£èƒ½åŠ›çš„æ˜¾è‘—ç›Šå¤„ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at AAAI 2026 Workshop on WoMAPF, Camera ready version",
      "pdf_url": "https://arxiv.org/pdf/2507.17061v4",
      "published_date": "2025-07-22 22:42:51 UTC",
      "updated_date": "2025-12-19 03:33:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:55.940679+00:00"
    },
    {
      "arxiv_id": "2507.17056v1",
      "title": "Pragmatic Policy Development via Interpretable Behavior Cloning",
      "title_zh": "åŸºäºå¯è§£é‡Šè¡Œä¸ºå…‹éš†çš„å®ç”¨æ€§ç­–ç•¥åˆ¶å®š",
      "authors": [
        "Anton Matsson",
        "Yaochen Rao",
        "Heather J. Litman",
        "Fredrik D. Johansson"
      ],
      "abstract": "Offline reinforcement learning (RL) holds great promise for deriving optimal policies from observational data, but challenges related to interpretability and evaluation limit its practical use in safety-critical domains. Interpretability is hindered by the black-box nature of unconstrained RL policies, while evaluation -- typically performed off-policy -- is sensitive to large deviations from the data-collecting behavior policy, especially when using methods based on importance sampling. To address these challenges, we propose a simple yet practical alternative: deriving treatment policies from the most frequently chosen actions in each patient state, as estimated by an interpretable model of the behavior policy. By using a tree-based model, which is specifically designed to exploit patterns in the data, we obtain a natural grouping of states with respect to treatment. The tree structure ensures interpretability by design, while varying the number of actions considered controls the degree of overlap with the behavior policy, enabling reliable off-policy evaluation. This pragmatic approach to policy development standardizes frequent treatment patterns, capturing the collective clinical judgment embedded in the data. Using real-world examples in rheumatoid arthritis and sepsis care, we demonstrate that policies derived under this framework can outperform current practice, offering interpretable alternatives to those obtained via offline RL.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¼ºåŒ–å­¦ä¹  (Offline Reinforcement Learning) åœ¨å®‰å…¨å…³é”®é¢†åŸŸç”±äºé»‘ç›’æ€§è´¨å¯¼è‡´çš„å¯è§£é‡Šæ€§å·®ä»¥åŠç¦»çº¿ç­–ç•¥è¯„ä¼° (Off-Policy Evaluation) å›°éš¾ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¯è§£é‡Šè¡Œä¸ºå…‹éš† (Interpretable Behavior Cloning) çš„å®ç”¨ç­–ç•¥å¼€å‘æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡æ„å»ºåŸºäºæ ‘çš„æ¨¡å‹ (Tree-based Model) æ¥ä¼°ç®—è¡Œä¸ºç­–ç•¥ï¼Œå¹¶ä»æ¯ä¸ªæ‚£è€…çŠ¶æ€ä¸‹æœ€å¸¸é€‰æ‹©çš„æ“ä½œä¸­æ¨å¯¼æ²»ç–—æ–¹æ¡ˆã€‚è¿™ç§æ ‘çŠ¶ç»“æ„åœ¨è®¾è®¡ä¸Šä¿è¯äº†å†³ç­–è¿‡ç¨‹çš„é€æ˜åº¦ï¼ŒåŒæ—¶é€šè¿‡æ§åˆ¶ä¸åŸå§‹è¡Œä¸ºç­–ç•¥çš„é‡åˆåº¦ï¼Œç¡®ä¿äº†è¯„ä¼°ç»“æœçš„å¯é æ€§ã€‚è¯¥æ–¹æ³•æ—¨åœ¨æ ‡å‡†åŒ–é¢‘ç¹çš„æ²»ç–—æ¨¡å¼ï¼Œä»è€Œæœ‰æ•ˆæ•è·æ•°æ®ä¸­è•´å«çš„é›†ä½“ä¸´åºŠåˆ¤æ–­ã€‚åœ¨ç±»é£æ¹¿æ€§å…³èŠ‚ç‚ (Rheumatoid Arthritis) å’Œè´¥è¡€ç—‡ (Sepsis) æŠ¤ç†çš„çœŸå®æ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œå®éªŒè¯æ˜è¯¥æ¡†æ¶ç”Ÿæˆçš„ç­–ç•¥ä¼˜äºå½“å‰çš„ä¸´åºŠå®è·µï¼Œä¸ºç¦»çº¿å¼ºåŒ–å­¦ä¹ æä¾›äº†ä¸€ç§æ›´å…·å¯è§£é‡Šæ€§ä¸”åˆ‡å®å¯è¡Œçš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17056v1",
      "published_date": "2025-07-22 22:34:35 UTC",
      "updated_date": "2025-07-22 22:34:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:07:55.434727+00:00"
    },
    {
      "arxiv_id": "2507.21137v1",
      "title": "Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?",
      "title_zh": "Project Pattiï¼šä¸ºä½•ä½ èƒ½åœ¨æŸä¸€æ•°ç‹¬ç½‘ç«™è§£å¼€â€œåœ°ç‹±çº§â€è°œé¢˜ï¼Œå´æ— æ³•è§£å¼€å¦ä¸€ç½‘ç«™çš„â€œç®€å•çº§â€è°œé¢˜ï¼Ÿ",
      "authors": [
        "Arman Eisenkolb-Vaithyanathan"
      ],
      "abstract": "In this paper we try to answer the question \"What constitutes Sudoku difficulty rating across different Sudoku websites?\" Using two distinct methods that can both solve every Sudoku puzzle, I propose two new metrics to characterize Sudoku difficulty. The first method is based on converting a Sudoku puzzle into its corresponding Satisfiability (SAT) problem. The first proposed metric is derived from SAT Clause Length Distribution which captures the structural complexity of a Sudoku puzzle including the number of given digits and the cells they are in. The second method simulates human Sudoku solvers by intertwining four popular Sudoku strategies within a backtracking algorithm called Nishio. The second metric is computed by counting the number of times Sudoku strategies are applied within the backtracking iterations of a randomized Nishio. Using these two metrics, I analyze more than a thousand Sudoku puzzles across five popular websites to characterize every difficulty level in each website. I evaluate the relationship between the proposed metrics and website-labeled difficulty levels using Spearman's rank correlation coefficient, finding strong correlations for 4 out of 5 websites. I construct a universal rating system using a simple, unsupervised classifier based on the two proposed metrics. This rating system is capable of classifying both individual puzzles and entire difficulty levels from the different Sudoku websites into three categories - Universal Easy, Universal Medium, and Universal Hard - thereby enabling consistent difficulty mapping across Sudoku websites. The experimental results show that for 4 out of 5 Sudoku websites, the universal classification aligns well with website-labeled difficulty levels. Finally, I present an algorithm that can be used by early Sudoku practitioners to solve Sudoku puzzles.",
      "tldr_zh": "è¿™é¡¹åä¸º Project Patti çš„ç ”ç©¶æ—¨åœ¨æ¢è®¨ä¸åŒ Sudoku ç½‘ç«™ä¹‹é—´éš¾åº¦è¯„çº§æ ‡å‡†ä¸ä¸€è‡´çš„é—®é¢˜ï¼Œåˆ†æäº†æ„æˆæ•°ç‹¬éš¾åº¦çš„æ ¸å¿ƒè¦ç´ ã€‚ä½œè€…æå‡ºäº†ä¸¤ç§æ–°çš„éš¾åº¦è¡¡é‡æŒ‡æ ‡ï¼šç¬¬ä¸€ç§æ–¹æ³•å°†æ•°ç‹¬è½¬åŒ–ä¸º Satisfiability (SAT) é—®é¢˜ï¼Œé€šè¿‡åˆ†æ SAT Clause Length Distribution æ¥æ•æ‰è°œé¢˜çš„ç»“æ„å¤æ‚åº¦ï¼›ç¬¬äºŒç§æ–¹æ³•åˆ™é€šè¿‡åœ¨ Nishio å›æº¯ç®—æ³•ä¸­ç»“åˆäººç±»è§£é¢˜ç­–ç•¥ï¼Œç»Ÿè®¡ç­–ç•¥çš„åº”ç”¨æ¬¡æ•°æ¥é‡åŒ–éš¾åº¦ã€‚ç ”ç©¶åˆ†æäº†äº”ä¸ªæµè¡Œç½‘ç«™çš„åƒä½™ä¸ªè°œé¢˜ï¼Œåˆ©ç”¨ Spearman's rank correlation coefficient è¯å®äº†æ‰€ææŒ‡æ ‡ä¸ç½‘ç«™åŸå§‹éš¾åº¦æ ‡ç­¾ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§ã€‚åŸºäºè¿™äº›æŒ‡æ ‡ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªæ— ç›‘ç£åˆ†ç±»å™¨ï¼Œå»ºç«‹èµ·åŒ…å« Universal Easyã€Universal Medium å’Œ Universal Hard çš„ç»Ÿä¸€è¯„çº§ç³»ç»Ÿï¼Œå®ç°äº†è·¨ç½‘ç«™çš„éš¾åº¦ä¸€è‡´æ€§æ˜ å°„ã€‚å®éªŒç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿèƒ½æœ‰æ•ˆæ ¡å‡†ä¸åŒå¹³å°çš„éš¾åº¦å·®å¼‚ï¼Œç ”ç©¶æœ€åè¿˜ä¸ºåˆå­¦è€…æä¾›äº†ä¸€ç§é«˜æ•ˆçš„ Sudoku æ±‚è§£ç®—æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 8 Figures",
      "pdf_url": "https://arxiv.org/pdf/2507.21137v1",
      "published_date": "2025-07-22 22:32:30 UTC",
      "updated_date": "2025-07-22 22:32:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:05.791583+00:00"
    },
    {
      "arxiv_id": "2507.17054v1",
      "title": "New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding",
      "title_zh": "æœ‰ç•Œæ¬¡ä¼˜å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’ä¸­ Flex åˆ†é…çš„æ–°æœºåˆ¶",
      "authors": [
        "Shao-Hung Chan",
        "Thomy Phan",
        "Jiaoyang Li",
        "Sven Koenig"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) is the problem of finding a set of collision-free paths, one for each agent in a shared environment. Its objective is to minimize the sum of path costs (SOC), where the path cost of each agent is defined as the travel time from its start location to its target location. Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for bounded-suboptimal MAPF, with the SOC of the solution being at most a user-specified factor $w$ away from optimal. EECBS maintains sets of paths and a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of paths whose SOC is at most $w \\cdot LB$ and introduces constraints to resolve collisions. For each path in a set, EECBS maintains a lower bound on its optimal path that satisfies constraints. By finding an individually bounded-suboptimal path with cost at most a threshold of $w$ times its lower bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up EECBS, previous work uses flex distribution to increase the threshold. Though EECBS with flex distribution guarantees to find a bounded-suboptimal solution, increasing the thresholds may push the SOC beyond $w \\cdot LB$, forcing EECBS to switch among different sets of paths instead of resolving collisions on a particular set of paths, and thus reducing efficiency. To address this issue, we propose Conflict-Based Flex Distribution that distributes flex in proportion to the number of collisions. We also estimate the delays needed to satisfy constraints and propose Delay-Based Flex Distribution. On top of that, we propose Mixed-Strategy Flex Distribution, combining both in a hierarchical framework. We prove that EECBS with our new flex distribution mechanisms is complete and bounded-suboptimal. Our experiments show that our approaches outperform the original (greedy) flex distribution.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æœ‰ç•Œæ¬¡ä¼˜ Multi-Agent Path Finding (MAPF) ä¸­çš„é¢†å…ˆç®—æ³• EECBS è¿›è¡Œäº†æ”¹è¿›ï¼Œæ—¨åœ¨è§£å†³åŸæœ‰ Flex Distribution æœºåˆ¶åœ¨æé«˜è·¯å¾„æˆæœ¬é˜ˆå€¼æ—¶å¯èƒ½å¯¼è‡´çš„æœç´¢æ•ˆç‡ä¸‹é™é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† Conflict-Based Flex Distributionï¼Œæ ¹æ®å†²çªæ•°é‡æŒ‰æ¯”ä¾‹åˆ†é…çµæ´»æ€§ï¼Œå¹¶å¼•å…¥äº†åŸºäºçº¦æŸå»¶è¿Ÿä¼°è®¡çš„ Delay-Based Flex Distributionã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥è®¾è®¡äº† Mixed-Strategy Flex Distributionï¼Œåœ¨ä¸€ä¸ªåˆ†å±‚æ¡†æ¶ä¸­ç»“åˆäº†å‰è¿°ä¸¤ç§ç­–ç•¥ã€‚ç†è®ºåˆ†æè¯æ˜äº†é‡‡ç”¨æ–°åˆ†é…æœºåˆ¶çš„ EECBS ç®—æ³•å…·æœ‰å®Œå¤‡æ€§å’Œ Bounded-Suboptimal ç‰¹æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»åˆ—æ–°æœºåˆ¶åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºåŸå§‹çš„è´ªå©ªåˆ†é…æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†å¤æ‚ç¯å¢ƒä¸‹è·¯å¾„è§„åˆ’çš„æ±‚è§£æ•ˆç‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 10 figures, International Symposium on Combinatorial Search, 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.17054v1",
      "published_date": "2025-07-22 22:25:29 UTC",
      "updated_date": "2025-07-22 22:25:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:02.187342+00:00"
    },
    {
      "arxiv_id": "2507.17047v4",
      "title": "Controllable Hybrid Captioner for Improved Long-form Video Understanding",
      "title_zh": "ç”¨äºæå‡é•¿è§†é¢‘ç†è§£çš„å¯æ§æ··åˆå¼æè¿°ç”Ÿæˆå™¨",
      "authors": [
        "Kuleen Sasse",
        "Efsun Sarioglu Kayi",
        "Arun Reddy"
      ],
      "abstract": "Video data, especially long-form video, is extremely dense and high-dimensional. Text-based summaries of video content offer a way to represent query-relevant content in a much more compact manner than raw video. In addition, textual representations are easily ingested by state-of-the-art large language models (LLMs), which enable reasoning over video content to answer complex natural language queries. To solve this issue, we rely on the progressive construction of a text-based memory by a video captioner operating on shorter chunks of the video, where spatio-temporal modeling is computationally feasible. We explore ways to improve the quality of the activity log comprised solely of short video captions. Because the video captions tend to be focused on human actions, and questions may pertain to other information in the scene, we seek to enrich the memory with static scene descriptions using Vision Language Models (VLMs). Our video understanding system relies on the LaViLa video captioner in combination with a LLM to answer questions about videos. We first explored different ways of partitioning the video into meaningful segments such that the textual descriptions more accurately reflect the structure of the video content. Furthermore, we incorporated static scene descriptions into the captioning pipeline using LLaVA VLM, resulting in a more detailed and complete caption log and expanding the space of questions that are answerable from the textual memory. Finally, we have successfully fine-tuned the LaViLa video captioner to produce both action and scene captions, significantly improving the efficiency of the captioning pipeline compared to using separate captioning models for the two tasks. Our model, controllable hybrid captioner, can alternate between different types of captions according to special input tokens that signals scene changes detected in the video.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Controllable Hybrid Captionerï¼Œæ—¨åœ¨é€šè¿‡æ„å»ºæ–‡æœ¬å­˜å‚¨ï¼ˆtext-based memoryï¼‰æ¥æå‡å¯¹é•¿è§†é¢‘ï¼ˆlong-form videoï¼‰çš„ç†è§£ä¸æ¨ç†èƒ½åŠ›ã€‚é’ˆå¯¹ç°æœ‰è§†é¢‘æè¿°ï¼ˆvideo captioningï¼‰æ¨¡å‹åé‡äººç±»åŠ¨ä½œè€Œå¿½ç•¥åœºæ™¯ç»†èŠ‚çš„é—®é¢˜ï¼Œè¯¥ç³»ç»Ÿç»“åˆäº†LaViLaè§†é¢‘æè¿°æ¨¡å‹ä¸LLaVAè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ï¼Œå°†åŠ¨æ€åŠ¨ä½œä¸é™æ€åœºæ™¯æè¿°ç›¸èåˆã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ”¹è¿›è§†é¢‘åˆ†å‰²ç­–ç•¥å¹¶å¾®è°ƒLaViLaæ¨¡å‹ï¼Œä½¿å…¶èƒ½å¤Ÿæ ¹æ®æ£€æµ‹åˆ°çš„åœºæ™¯å˜åŒ–ï¼Œé€šè¿‡ç‰¹æ®Šè¾“å…¥æ ‡è®°ï¼ˆspecial tokensï¼‰çµæ´»åˆ‡æ¢ç”Ÿæˆçš„æè¿°ç±»å‹ã€‚è¿™ç§å—æ§æ··åˆæè¿°æœºåˆ¶æ˜¾è‘—æå‡äº†æè¿°æ—¥å¿—çš„è¯¦ç»†ç¨‹åº¦å’Œå®Œæ•´æ€§ï¼ŒåŒæ—¶ç›¸æ¯”ä½¿ç”¨å¤šä¸ªç‹¬ç«‹æ¨¡å‹å¤§å¹…æé«˜äº†æµæ°´çº¿æ•ˆç‡ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæ‰©å±•äº†åŸºäºæ–‡æœ¬å­˜å‚¨å›ç­”å¤æ‚è‡ªç„¶è¯­è¨€æŸ¥è¯¢çš„èƒ½åŠ›ï¼Œä¸ºé•¿è§†é¢‘å†…å®¹çš„ç†è§£æä¾›äº†æ›´ä¸°å¯Œä¸”ç´§å‡‘çš„è¡¨ç¤ºå½¢å¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17047v4",
      "published_date": "2025-07-22 22:09:00 UTC",
      "updated_date": "2025-11-07 19:03:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:27.619194+00:00"
    },
    {
      "arxiv_id": "2507.21136v1",
      "title": "A Study on Variants of Conventional, Fuzzy, and Nullspace-Based Independence Criteria for Improving Supervised and Unsupervised Learning",
      "title_zh": "ä¼ ç»Ÿã€æ¨¡ç³ŠåŠåŸºäºé›¶ç©ºé—´ç‹¬ç«‹æ€§å‡†åˆ™å˜ä½“ç ”ç©¶ï¼šæ—¨åœ¨æå‡ç›‘ç£ä¸æ— ç›‘ç£å­¦ä¹ æ€§èƒ½",
      "authors": [
        "Mojtaba Moattari"
      ],
      "abstract": "Unsupervised and supervised learning methods conventionally use kernels to capture nonlinearities inherent in data structure. However experts have to ensure their proposed nonlinearity maximizes variability and capture inherent diversity of data. We reviewed all independence criteria to design unsupervised learners. Then we proposed 3 independence criteria and used them to design unsupervised and supervised dimensionality reduction methods. We evaluated contrast, accuracy and interpretability of these methods in both linear and neural nonlinear settings. The results show that the methods have outperformed the baseline (tSNE, PCA, regularized LDA, VAE with (un)supervised learner and layer sharing) and opened a new line of interpretable machine learning (ML) for the researchers.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¼ ç»Ÿã€æ¨¡ç³ŠåŠåŸºäº Nullspace-Based çš„ç‹¬ç«‹æ€§å‡†åˆ™ (Independence Criteria) å˜ä½“ï¼Œä»¥æ”¹è¿›ç›‘ç£ä¸æ— ç›‘ç£å­¦ä¹ çš„è¡¨ç°ã€‚ä½œè€…åœ¨ç³»ç»Ÿå›é¡¾ç°æœ‰å‡†åˆ™åï¼Œæå‡ºäº†ä¸‰ç§æ–°å‹ç‹¬ç«‹æ€§å‡†åˆ™ï¼Œå¹¶æ®æ­¤è®¾è®¡äº†ç›‘ç£ä¸æ— ç›‘ç£çš„ Dimensionality Reduction æ–¹æ³•ã€‚ç ”ç©¶åœ¨æ˜¾æ€§çº¿æ€§ä¸ Neural Nonlinear ç¯å¢ƒä¸‹ï¼Œé’ˆå¯¹å¯¹æ¯”åº¦ã€å‡†ç¡®æ€§å’Œå¯è§£é‡Šæ€§å¯¹è¿™äº›æ–¹æ³•è¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ–°æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äº tSNEã€PCAã€æ­£åˆ™åŒ– LDA ä»¥åŠå¸¦å±‚å…±äº«çš„ VAE ç­‰åŸºçº¿æ¨¡å‹ã€‚è¯¥æˆæœæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä¸º Interpretable Machine Learning é¢†åŸŸæä¾›äº†æ–°çš„è§†è§’å’ŒæŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.21136v1",
      "published_date": "2025-07-22 22:02:50 UTC",
      "updated_date": "2025-07-22 22:02:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:22.845452+00:00"
    },
    {
      "arxiv_id": "2507.17043v1",
      "title": "Computational Performance Bounds Prediction in Quantum Computing with Unstable Noise",
      "title_zh": "ä¸ç¨³å®šå™ªå£°ç¯å¢ƒä¸‹é‡å­è®¡ç®—æ€§èƒ½è¾¹ç•Œé¢„æµ‹",
      "authors": [
        "Jinyang Li",
        "Samudra Dasgupta",
        "Yuhong Song",
        "Lei Yang",
        "Travis Humble",
        "Weiwen Jiang"
      ],
      "abstract": "Quantum computing has significantly advanced in recent years, boasting devices with hundreds of quantum bits (qubits), hinting at its potential quantum advantage over classical computing. Yet, noise in quantum devices poses significant barriers to realizing this supremacy. Understanding noise's impact is crucial for reproducibility and application reuse; moreover, the next-generation quantum-centric supercomputing essentially requires efficient and accurate noise characterization to support system management (e.g., job scheduling), where ensuring correct functional performance (i.e., fidelity) of jobs on available quantum devices can even be higher-priority than traditional objectives. However, noise fluctuates over time, even on the same quantum device, which makes predicting the computational bounds for on-the-fly noise is vital. Noisy quantum simulation can offer insights but faces efficiency and scalability issues. In this work, we propose a data-driven workflow, namely QuBound, to predict computational performance bounds. It decomposes historical performance traces to isolate noise sources and devises a novel encoder to embed circuit and noise information processed by a Long Short-Term Memory (LSTM) network. For evaluation, we compare QuBound with a state-of-the-art learning-based predictor, which only generates a single performance value instead of a bound. Experimental results show that the result of the existing approach falls outside of performance bounds, while all predictions from our QuBound with the assistance of performance decomposition better fit the bounds. Moreover, QuBound can efficiently produce practical bounds for various circuits with over 106 speedup over simulation; in addition, the range from QuBound is over 10x narrower than the state-of-the-art analytical approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡å­è®¡ç®—(Quantum Computing)ä¸­å™ªå£°çš„ä¸ç¨³å®šæ€§ä»¥åŠä¼ ç»Ÿæ¨¡æ‹ŸæŠ€æœ¯åœ¨æ•ˆç‡å’Œå¯æ‰©å±•æ€§ä¸Šçš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºQuBoundçš„æ•°æ®é©±åŠ¨å·¥ä½œæµï¼Œæ—¨åœ¨ç²¾å‡†é¢„æµ‹é‡å­è®¡ç®—çš„æ€§èƒ½è¾¹ç•Œã€‚è¯¥å·¥ä½œæµé€šè¿‡åˆ†è§£å†å²æ€§èƒ½è¿½è¸ªæ•°æ®æ¥éš”ç¦»ä¸åŒçš„å™ªå£°æº(noise sources)ï¼Œå¹¶è®¾è®¡äº†ä¸€ç§æ–°å‹ç¼–ç å™¨ï¼Œç»“åˆé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ(LSTM)å¯¹ç”µè·¯å’Œå™ªå£°ä¿¡æ¯è¿›è¡ŒåµŒå…¥å¤„ç†ã€‚ä¸ä»…ç”Ÿæˆå•ä¸€é¢„æµ‹å€¼çš„ç°æœ‰å­¦ä¹ æ¨¡å‹ç›¸æ¯”ï¼ŒQuBoundèƒ½å¤Ÿæä¾›æ›´å…·å‚è€ƒä»·å€¼çš„æ€§èƒ½åŒºé—´ï¼Œå®éªŒè¯æ˜å…¶é¢„æµ‹ç»“æœæ¯”ç°æœ‰æ–¹æ³•æ›´èƒ½å‡†ç¡®æ‹Ÿåˆå®é™…è¡¨ç°ã€‚åœ¨è®¡ç®—æ•ˆç‡æ–¹é¢ï¼ŒQuBoundç›¸æ¯”ä¼ ç»Ÿçš„å™ªå£°é‡å­æ¨¡æ‹Ÿ(Noisy quantum simulation)å®ç°äº†è¶…è¿‡10^6å€çš„åŠ é€Ÿï¼Œä¸”å…¶é¢„æµ‹è¾¹ç•ŒèŒƒå›´æ¯”æœ€å…ˆè¿›çš„è§£ææ–¹æ³•(analytical approach)ç¼©å°äº†10å€ä»¥ä¸Šã€‚è¿™ä¸€æˆæœä¸ºé‡å­ä¸­å¿ƒè¶…çº§è®¡ç®—ä¸­çš„ä»»åŠ¡è°ƒåº¦(job scheduling)å’Œç³»ç»Ÿç®¡ç†æä¾›äº†é«˜æ•ˆã€ç²¾ç¡®çš„æ€§èƒ½è¯„ä¼°æ”¯æ’‘ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17043v1",
      "published_date": "2025-07-22 22:00:09 UTC",
      "updated_date": "2025-07-22 22:00:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:30.221272+00:00"
    },
    {
      "arxiv_id": "2507.17029v1",
      "title": "StreamME: Simplify 3D Gaussian Avatar within Live Stream",
      "title_zh": "StreamMEï¼šç›´æ’­æµä¸­çš„3Dé«˜æ–¯å¤´åƒç®€åŒ–",
      "authors": [
        "Luchuan Song",
        "Yang Zhou",
        "Zhan Xu",
        "Yi Zhou",
        "Deepali Aneja",
        "Chenliang Xu"
      ],
      "abstract": "We propose StreamME, a method focuses on fast 3D avatar reconstruction. The StreamME synchronously records and reconstructs a head avatar from live video streams without any pre-cached data, enabling seamless integration of the reconstructed appearance into downstream applications. This exceptionally fast training strategy, which we refer to as on-the-fly training, is central to our approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating the reliance on MLPs in deformable 3DGS and relying solely on geometry, which significantly improves the adaptation speed to facial expression. To further ensure high efficiency in on-the-fly training, we introduced a simplification strategy based on primary points, which distributes the point clouds more sparsely across the facial surface, optimizing points number while maintaining rendering quality. Leveraging the on-the-fly training capabilities, our method protects the facial privacy and reduces communication bandwidth in VR system or online conference. Additionally, it can be directly applied to downstream application such as animation, toonify, and relighting. Please refer to our project page for more details: https://songluchuan.github.io/StreamME/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† StreamMEï¼Œä¸€ç§ä¸“æ³¨äºå¿«é€Ÿ 3D å¤´åƒé‡å»ºçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿä»å®æ—¶è§†é¢‘æµä¸­åŒæ­¥è®°å½•å¹¶é‡å»ºå¤´åƒï¼Œæ— éœ€ä»»ä½•é¢„å…ˆç¼“å­˜çš„æ•°æ®ã€‚è¯¥æ–¹æ³•é‡‡ç”¨â€œå³æ—¶è®­ç»ƒâ€ï¼ˆon-the-fly trainingï¼‰ç­–ç•¥ï¼ŒåŸºäº 3D Gaussian Splatting (3DGS) æ„å»ºï¼Œé€šè¿‡æ¶ˆé™¤å¯¹ MLP çš„ä¾èµ–å¹¶å®Œå…¨ä¾é å‡ ä½•ä¿¡æ¯ï¼Œæ˜¾è‘—æå‡äº†å¯¹é¢éƒ¨è¡¨æƒ…çš„è‡ªé€‚åº”é€Ÿåº¦ã€‚ä¸ºäº†åœ¨å³æ—¶è®­ç»ƒä¸­ç¡®ä¿é«˜æ•ˆï¼Œç ”ç©¶å¼•å…¥äº†åŸºäº Primary Points çš„ç®€åŒ–ç­–ç•¥ï¼Œé€šè¿‡åœ¨é¢éƒ¨è¡¨é¢æ›´ç¨€ç–åœ°åˆ†å¸ƒç‚¹äº‘ï¼Œåœ¨å¤§å¹…å‡å°‘ç‚¹æ•°çš„åŒæ—¶ä¿æŒäº†æ¸²æŸ“è´¨é‡ã€‚å¾—ç›Šäºå…¶å®æ—¶é‡å»ºèƒ½åŠ›ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿä¿æŠ¤é¢éƒ¨éšç§å¹¶é™ä½ VR ç³»ç»Ÿæˆ–åœ¨çº¿ä¼šè®®çš„é€šä¿¡å¸¦å®½ï¼Œå¹¶å¯ç›´æ¥åº”ç”¨äºåŠ¨ç”»ï¼ˆanimationï¼‰ã€é£æ ¼åŒ–ï¼ˆtoonifyï¼‰åŠé‡å…‰ç…§ï¼ˆrelightingï¼‰ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "12 pages, 15 Figures",
      "pdf_url": "https://arxiv.org/pdf/2507.17029v1",
      "published_date": "2025-07-22 21:33:30 UTC",
      "updated_date": "2025-07-22 21:33:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:30.635061+00:00"
    },
    {
      "arxiv_id": "2507.17025v1",
      "title": "Evolutionary Feature-wise Thresholding for Binary Representation of NLP Embeddings",
      "title_zh": "é¢å‘ NLP åµŒå…¥äºŒè¿›åˆ¶è¡¨ç¤ºçš„æ¼”åŒ–å¼é€ç‰¹å¾é˜ˆå€¼åŒ–",
      "authors": [
        "Soumen Sinha",
        "Shahryar Rahnamayan",
        "Azam Asilian Bidgoli"
      ],
      "abstract": "Efficient text embedding is crucial for large-scale natural language processing (NLP) applications, where storage and computational efficiency are key concerns. In this paper, we explore how using binary representations (barcodes) instead of real-valued features can be used for NLP embeddings derived from machine learning models such as BERT. Thresholding is a common method for converting continuous embeddings into binary representations, often using a fixed threshold across all features. We propose a Coordinate Search-based optimization framework that instead identifies the optimal threshold for each feature, demonstrating that feature-specific thresholds lead to improved performance in binary encoding. This ensures that the binary representations are both accurate and efficient, enhancing performance across various features. Our optimal barcode representations have shown promising results in various NLP applications, demonstrating their potential to transform text representation. We conducted extensive experiments and statistical tests on different NLP tasks and datasets to evaluate our approach and compare it to other thresholding methods. Binary embeddings generated using using optimal thresholds found by our method outperform traditional binarization methods in accuracy. This technique for generating binary representations is versatile and can be applied to any features, not just limited to NLP embeddings, making it useful for a wide range of domains in machine learning applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è§„æ¨¡NLPåº”ç”¨ä¸­åˆ©ç”¨äºŒè¿›åˆ¶è¡¨ç¤º(barcodes)æ›¿ä»£å®å€¼ç‰¹å¾ä»¥æé«˜å­˜å‚¨å’Œè®¡ç®—æ•ˆç‡çš„æ–¹æ³•ã€‚é’ˆå¯¹å°†BERTç­‰æ¨¡å‹çš„è¿ç»­åµŒå…¥è½¬æ¢ä¸ºäºŒè¿›åˆ¶è¡¨ç¤ºçš„æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åŸºäºåæ ‡æœç´¢(Coordinate Search)çš„ä¼˜åŒ–æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºä¸ºæ¯ä¸ªç‰¹å¾è¯†åˆ«æœ€ä¼˜çš„ç‰¹å¾ä¸“ç”¨é˜ˆå€¼(feature-specific thresholds)ï¼Œè€Œéé‡‡ç”¨ä¼ ç»Ÿçš„å›ºå®šå…¨å±€é˜ˆå€¼ã€‚è¿™ç§ç‰¹å¾çº§çš„äºŒå€¼åŒ–å¤„ç†ç¡®ä¿äº†äºŒè¿›åˆ¶è¡¨ç¤ºåœ¨ä¿æŒå‡†ç¡®æ€§çš„åŒæ—¶å…¼é¡¾æ•ˆç‡ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨å„ç±»ç‰¹å¾ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡åœ¨ä¸åŒNLPä»»åŠ¡å’Œæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒï¼Œç»“æœè¯æ˜è¯¥æ–¹æ³•ç”Ÿæˆçš„äºŒè¿›åˆ¶åµŒå…¥åœ¨å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸäºŒå€¼åŒ–æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œè¯¥æŠ€æœ¯å…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œä¸ä»…é™äºNLP embeddingsï¼Œè¿˜å¯æ‰©å±•è‡³å…¶ä»–æœºå™¨å­¦ä¹ é¢†åŸŸçš„ç‰¹å¾å¤„ç†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17025v1",
      "published_date": "2025-07-22 21:29:34 UTC",
      "updated_date": "2025-07-22 21:29:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:31.143378+00:00"
    },
    {
      "arxiv_id": "2507.17016v1",
      "title": "Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time Series Forecasting",
      "title_zh": "å› æœå›¾æ¨¡ç³Šå¤§è¯­è¨€æ¨¡å‹ï¼šé¦–æ¬¡ä»‹ç»åŠå…¶åœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨",
      "authors": [
        "Omid Orang",
        "Patricia O. Lucas",
        "Gabriel I. F. Paiva",
        "Petronio C. L. Silva",
        "Felipe Augusto Rocha da Silva",
        "Adriano Alonso Veloso",
        "Frederico Gadelha Guimaraes"
      ],
      "abstract": "In recent years, the application of Large Language Models (LLMs) to time series forecasting (TSF) has garnered significant attention among researchers. This study presents a new frame of LLMs named CGF-LLM using GPT-2 combined with fuzzy time series (FTS) and causal graph to predict multivariate time series, marking the first such architecture in the literature. The key objective is to convert numerical time series into interpretable forms through the parallel application of fuzzification and causal analysis, enabling both semantic understanding and structural insight as input for the pretrained GPT-2 model. The resulting textual representation offers a more interpretable view of the complex dynamics underlying the original time series. The reported results confirm the effectiveness of our proposed LLM-based time series forecasting model, as demonstrated across four different multivariate time series datasets. This initiative paves promising future directions in the domain of TSF using LLMs based on FTS.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸º Causal Graph Fuzzy LLMs (CGF-LLM) çš„æ–°å‹æ¡†æ¶ï¼Œè¿™æ˜¯å­¦æœ¯ç•Œé¦–æ¬¡ç»“åˆ GPT-2ã€æ¨¡ç³Šæ—¶é—´åºåˆ— (Fuzzy Time Series, FTS) å’Œå› æœå›¾ (Causal Graph) è¿›è¡Œå¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ (Time Series Forecasting)ã€‚è¯¥æ¨¡å‹çš„æ ¸å¿ƒç›®æ ‡æ˜¯é€šè¿‡å¹¶è¡Œåº”ç”¨æ¨¡ç³ŠåŒ–å’Œå› æœåˆ†æï¼Œå°†æ•°å€¼å‹æ—¶é—´åºåˆ—è½¬æ¢ä¸ºå¯è§£é‡Šçš„æ–‡æœ¬å½¢å¼ï¼Œä»è€Œä¸ºé¢„è®­ç»ƒçš„ GPT-2 æä¾›è¯­ä¹‰ç†è§£å’Œç»“æ„æ´å¯Ÿã€‚è¿™ç§æ–‡æœ¬åŒ–è¡¨ç¤ºä¸ºåŸå§‹æ•°æ®èƒŒåå¤æ‚çš„åŠ¨æ€æœºåˆ¶æä¾›äº†æ›´å…·å¯è§£é‡Šæ€§çš„è§†è§’ã€‚å®éªŒç»“æœåœ¨å››ä¸ªä¸åŒçš„å¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®é›†ä¸ŠéªŒè¯äº†è¯¥æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚è¿™ä¸€å¼€åˆ›æ€§å·¥ä½œä¸ºæœªæ¥åœ¨æ—¶é—´åºåˆ—é¢„æµ‹é¢†åŸŸåˆ©ç”¨åŸºäºæ¨¡ç³Šæ—¶é—´åºåˆ—çš„å¤§è¯­è¨€æ¨¡å‹ (LLMs) å¥ å®šäº†åŸºç¡€å¹¶æŒ‡æ˜äº†ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication at the Brazilian Congress of Artificial Intelligence (CBIC)",
      "pdf_url": "https://arxiv.org/pdf/2507.17016v1",
      "published_date": "2025-07-22 21:03:13 UTC",
      "updated_date": "2025-07-22 21:03:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:37.438382+00:00"
    },
    {
      "arxiv_id": "2507.17015v1",
      "title": "Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?",
      "title_zh": "å¤–éƒ¨éªŒè¯å·¥å…·èƒ½å¦æå‡ LLM-as-a-Judge çš„æ ‡æ³¨è´¨é‡ï¼Ÿ",
      "authors": [
        "Arduin Findeis",
        "Floris Weers",
        "Guoli Yin",
        "Ke Ye",
        "Ruoming Pang",
        "Tom Gunter"
      ],
      "abstract": "Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the \"better\" response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., chat response quality), thereby helping model evaluation or training. However, for some domains high-quality pairwise comparisons can be tricky to obtain - from AI and humans. For example, for responses with many factual statements, annotators may disproportionately weigh writing quality rather than underlying facts. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM's internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as three new datasets for domains with saturated pre-existing datasets. Our results indicate that external tools can indeed improve performance in many, but not all, cases. More generally, our experiments highlight the sensitivity of performance to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our code at https://github.com/apple/ml-agent-evaluator.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å¤–éƒ¨éªŒè¯å·¥å…·æå‡LLM-as-a-Judgeåœ¨æˆå¯¹åå¥½(Pairwise preferences)æ ‡æ³¨ä¸­çš„è´¨é‡ï¼Œç‰¹åˆ«æ˜¯åœ¨é•¿ç¯‡äº‹å®ã€æ•°å­¦å’Œä»£ç ç­‰å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤–éƒ¨å·¥å…·çš„æ™ºèƒ½ä½“ç³»ç»Ÿ(agentic system)ï¼Œé€šè¿‡å¼•å…¥web-searchå’Œcode executionæ¥è¿›è¡Œå¤–éƒ¨éªŒè¯ï¼Œä»è€Œä½¿è¯„ä¼°è¿‡ç¨‹ç‹¬ç«‹äºå¤§æ¨¡å‹çš„å†…éƒ¨çŸ¥è¯†å’Œåå¥½ã€‚å®éªŒåœ¨RewardBenchã€RewardMathåŠä¸‰ä¸ªé’ˆå¯¹æ€§æ–°æ•°æ®é›†ä¸Šå±•å¼€ï¼Œç»“æœè¯å®å¤–éƒ¨å·¥å…·åœ¨å¤šæ•°æƒ…å†µä¸‹èƒ½æœ‰æ•ˆæ”¹å–„æ ‡æ³¨æ€§èƒ½ã€‚åŒæ—¶ï¼Œç ”ç©¶ä¹Ÿæ­ç¤ºäº†æ€§èƒ½å¯¹Promptç­‰ç®€å•å‚æ•°çš„é«˜åº¦æ•æ„Ÿæ€§ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘éé¥±å’Œæ ‡æ³¨åŸºå‡†(benchmarks)çš„å¿…è¦æ€§ã€‚è¯¥å·¥ä½œä¸ºæé«˜AIæ ‡æ³¨ç³»ç»Ÿçš„å¯é æ€§æä¾›äº†å®è·µè·¯å¾„ï¼Œå¹¶å¼€æºäº†ç›¸å…³ä»£ç ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.17015v1",
      "published_date": "2025-07-22 20:57:09 UTC",
      "updated_date": "2025-07-22 20:57:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:46.449255+00:00"
    },
    {
      "arxiv_id": "2507.17013v1",
      "title": "laplax -- Laplace Approximations with JAX",
      "title_zh": "laplaxï¼šåŸºäº JAX çš„æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼",
      "authors": [
        "Tobias Weber",
        "BÃ¡lint MucsÃ¡nyi",
        "Lenard Rommel",
        "Thomas Christie",
        "Lars KasÃ¼schke",
        "Marvin PfÃ¶rtner",
        "Philipp Hennig"
      ],
      "abstract": "The Laplace approximation provides a scalable and efficient means of quantifying weight-space uncertainty in deep neural networks, enabling the application of Bayesian tools such as predictive uncertainty and model selection via Occam's razor. In this work, we introduce laplax, a new open-source Python package for performing Laplace approximations with jax. Designed with a modular and purely functional architecture and minimal external dependencies, laplax offers a flexible and researcher-friendly framework for rapid prototyping and experimentation. Its goal is to facilitate research on Bayesian neural networks, uncertainty quantification for deep learning, and the development of improved Laplace approximation techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† laplaxï¼Œä¸€ä¸ªä¸“ä¸ºåœ¨ jax æ¡†æ¶ä¸‹å®ç° Laplace approximations è€Œè®¾è®¡çš„å¼€æº Python è½¯ä»¶åŒ…ã€‚Laplace approximation ä¸ºæ·±åº¦ç¥ç»ç½‘ç»œæä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”é«˜æ•ˆçš„ weight-space uncertainty é‡åŒ–æ–¹æ³•ï¼Œä½¿å¾— Bayesian neural networks ä¸­çš„é¢„æµ‹ä¸ç¡®å®šæ€§(predictive uncertainty)å’ŒåŸºäº Occam's razor çš„æ¨¡å‹é€‰æ‹©æˆä¸ºå¯èƒ½ã€‚laplax é‡‡ç”¨äº†æ¨¡å—åŒ–å’Œçº¯å‡½æ•°å¼æ¶æ„(purely functional architecture)ï¼Œä¸”å¤–éƒ¨ä¾èµ–æå°‘ï¼Œä¸ºç ”ç©¶äººå‘˜æä¾›äº†çµæ´»ä¸”å‹å¥½çš„æ¡†æ¶ä»¥æ”¯æŒå¿«é€ŸåŸå‹è®¾è®¡å’Œå®éªŒã€‚è¯¥å·¥å…·çš„æ¨å‡ºæ—¨åœ¨ä¿ƒè¿›æ·±åº¦å­¦ä¹ ä¸­ uncertainty quantification çš„ç ”ç©¶ï¼Œå¹¶ä¸ºå¼€å‘æ›´å…ˆè¿›çš„ Laplace approximation æŠ€æœ¯æä¾›åŸºç¡€æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submission to the ICML 2025 Workshop on Championing Open-source Development in Machine Learning (CODEML '25)",
      "pdf_url": "https://arxiv.org/pdf/2507.17013v1",
      "published_date": "2025-07-22 20:49:30 UTC",
      "updated_date": "2025-07-22 20:49:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:45.521039+00:00"
    },
    {
      "arxiv_id": "2507.17012v1",
      "title": "Towards Autonomous Sustainability Assessment via Multimodal AI Agents",
      "title_zh": "è¿ˆå‘åŸºäºå¤šæ¨¡æ€ AI æ™ºèƒ½ä½“çš„è‡ªä¸»å¯æŒç»­æ€§è¯„ä¼°",
      "authors": [
        "Zhihan Zhang",
        "Alexander Metzger",
        "Yuxuan Mei",
        "Felix HÃ¤hnlein",
        "Zachary Englhardt",
        "Tingyu Cheng",
        "Gregory D. Abowd",
        "Shwetak Patel",
        "Adriana Schulz",
        "Vikram Iyer"
      ],
      "abstract": "Interest in sustainability information has surged in recent years. However, the data required for a life cycle assessment (LCA) that maps the materials and processes from product manufacturing to disposal into environmental impacts (EI) are often unavailable. Here we reimagine conventional LCA by introducing multimodal AI agents that emulate interactions between LCA experts and stakeholders like product managers and engineers to calculate the cradle-to-gate (production) carbon emissions of electronic devices. The AI agents iteratively generate a detailed life-cycle inventory leveraging a custom data abstraction and software tools that extract information from online text and images from repair communities and government certifications. This approach reduces weeks or months of expert time to under one minute and closes data availability gaps while yielding carbon footprint estimates within 19% of expert LCAs with zero proprietary data. Additionally, we develop a method to directly estimate EI by comparing an input to a cluster of products with similar descriptions and known carbon footprints. This runs in 3 ms on a laptop with a MAPE of 12.28% on electronic products. Further, we develop a data-driven method to generate emission factors. We use the properties of an unknown material to represent it as a weighted sum of emission factors for similar materials. Compared to human experts picking the closest LCA database entry, this improves MAPE by 120.26%. We analyze the data and compute scaling of this approach and discuss its implications for future LCA workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€ AI æ™ºèƒ½ä½“ (Multimodal AI Agents) çš„è‡ªä¸»å¯æŒç»­æ€§è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç”Ÿå‘½å‘¨æœŸè¯„ä¼° (Life Cycle Assessment, LCA) ä¸­æ•°æ®ç¼ºå¤±å’Œä¸“å®¶æ—¶é—´æˆæœ¬é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨¡æ‹Ÿä¸“å®¶ä¸åˆ©ç›Šç›¸å…³è€…çš„äº¤äº’ï¼Œåˆ©ç”¨ä»åœ¨çº¿æ–‡æœ¬åŠç»´ä¿®ç¤¾åŒºå›¾åƒä¸­æå–çš„ä¿¡æ¯è¿­ä»£ç”Ÿæˆç”Ÿå‘½å‘¨æœŸæ¸…å• (Life-Cycle Inventory, LCI)ï¼Œå°†åŸæœ¬æ•°å‘¨çš„å·¥ä½œç¼©çŸ­è‡³ä¸€åˆ†é’Ÿä»¥å†…ï¼Œä¸”ç¢³è¶³è¿¹ä¼°ç®—è¯¯å·®ä¸ä¸“å®¶ LCA ç›¸æ¯”ä»…ä¸º 19%ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼€å‘äº†é€šè¿‡å¯¹æ¯”ç›¸ä¼¼äº§å“é›†ç¾¤ç›´æ¥ä¼°ç®—ç¯å¢ƒå½±å“ (Environmental Impact, EI) çš„æ–¹æ³•ï¼Œåœ¨ç”µå­äº§å“ä¸Šçš„å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE) ä»…ä¸º 12.28%ã€‚é’ˆå¯¹æ’æ”¾å› å­ (Emission Factors) çš„è·å–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºææ–™å±æ€§åŠ æƒæ±‚å’Œçš„ç”Ÿæˆæ–¹æ³•ï¼Œç›¸è¾ƒäºäººç±»ä¸“å®¶ä»æ•°æ®åº“ä¸­æŒ‘é€‰æœ€æ¥è¿‘æ¡ç›®çš„ä¼ ç»Ÿåšæ³•ï¼Œå…¶ MAPE æå‡äº† 120.26%ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡å¯¹æ•°æ®å’Œè®¡ç®—ç¼©æ”¾çš„åˆ†æï¼Œè®ºè¯äº†åˆ©ç”¨å¤šæ¨¡æ€ AI å®ç°è‡ªåŠ¨åŒ–ã€é«˜ç²¾åº¦ LCA å·¥ä½œæµçš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17012v1",
      "published_date": "2025-07-22 20:49:25 UTC",
      "updated_date": "2025-07-22 20:49:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:58.087959+00:00"
    },
    {
      "arxiv_id": "2507.17010v1",
      "title": "Towards Trustworthy AI: Secure Deepfake Detection using CNNs and Zero-Knowledge Proofs",
      "title_zh": "è¿ˆå‘å¯ä¿¡äººå·¥æ™ºèƒ½ï¼šåŸºäº CNN ä¸é›¶çŸ¥è¯†è¯æ˜çš„å®‰å…¨æ·±åº¦ä¼ªé€ æ£€æµ‹",
      "authors": [
        "H M Mohaimanul Islam",
        "Huynh Q. N. Vo",
        "Aditya Rane"
      ],
      "abstract": "In the era of synthetic media, deepfake manipulations pose a significant threat to information integrity. To address this challenge, we propose TrustDefender, a two-stage framework comprising (i) a lightweight convolutional neural network (CNN) that detects deepfake imagery in real-time extended reality (XR) streams, and (ii) an integrated succinct zero-knowledge proof (ZKP) protocol that validates detection results without disclosing raw user data. Our design addresses both the computational constraints of XR platforms while adhering to the stringent privacy requirements in sensitive settings. Experimental evaluations on multiple benchmark deepfake datasets demonstrate that TrustDefender achieves 95.3% detection accuracy, coupled with efficient proof generation underpinned by rigorous cryptography, ensuring seamless integration with high-performance artificial intelligence (AI) systems. By fusing advanced computer vision models with provable security mechanisms, our work establishes a foundation for reliable AI in immersive and privacy-sensitive applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TrustDefenderï¼Œä¸€ä¸ªæ—¨åœ¨è§£å†³åˆæˆåª’ä½“æ—¶ä»£ deepfake å¨èƒçš„äºŒé˜¶æ®µå®‰å…¨æ£€æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨è½»é‡çº§ Convolutional Neural Network (CNN) æ¨¡å‹ï¼Œå®ç°äº†å¯¹ Extended Reality (XR) æµåª’ä½“ä¸­ deepfake å½±åƒçš„å®æ—¶æ£€æµ‹ã€‚ç¬¬äºŒé˜¶æ®µé›†æˆäº†ç®€æ´çš„ Zero-Knowledge Proof (ZKP) åè®®ï¼Œåœ¨ä¸æ³„éœ²åŸå§‹ç”¨æˆ·æ•°æ®çš„å‰æä¸‹éªŒè¯æ£€æµ‹ç»“æœçš„çœŸå®æ€§ï¼Œæœ‰æ•ˆå…¼é¡¾äº† XR å¹³å°çš„è®¡ç®—é™åˆ¶ä¸æ•æ„Ÿç¯å¢ƒçš„éšç§éœ€æ±‚ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒTrustDefender åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¾¾åˆ°äº† 95.3% çš„æ£€æµ‹å‡†ç¡®ç‡ï¼Œå¹¶èƒ½æä¾›åŸºäºä¸¥è°¨å¯†ç å­¦çš„é«˜æ•ˆè¯æ˜ç”Ÿæˆã€‚é€šè¿‡å°†å…ˆè¿›çš„ Computer Vision æ¨¡å‹ä¸å¯è¯æ˜çš„å®‰å…¨æœºåˆ¶ç›¸ç»“åˆï¼Œè¯¥å·¥ä½œä¸ºæ²‰æµ¸å¼å’Œéšç§æ•æ„Ÿåº”ç”¨ä¸­æ„å»ºå¯é  AI å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted for peer-review in TrustXR - 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.17010v1",
      "published_date": "2025-07-22 20:47:46 UTC",
      "updated_date": "2025-07-22 20:47:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:08:50.110097+00:00"
    },
    {
      "arxiv_id": "2507.17008v1",
      "title": "Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through Generative Models",
      "title_zh": "æ‰‹å½¢åˆ†ç±»çš„å¹³è¡¡ï¼šåˆ©ç”¨ç”Ÿæˆæ¨¡å‹ç¼“è§£æ•°æ®ä¸å¹³è¡¡",
      "authors": [
        "Gaston Gustavo Rios",
        "Pedro Dal Bianco",
        "Franco Ronchetti",
        "Facundo Quiroga",
        "Oscar Stanchi",
        "Santiago Ponte AhÃ³n",
        "Waldo HasperuÃ©"
      ],
      "abstract": "Most sign language handshape datasets are severely limited and unbalanced, posing significant challenges to effective model training. In this paper, we explore the effectiveness of augmenting the training data of a handshape classifier by generating synthetic data. We use an EfficientNet classifier trained on the RWTH German sign language handshape dataset, which is small and heavily unbalanced, applying different strategies to combine generated and real images. We compare two Generative Adversarial Networks (GAN) architectures for data generation: ReACGAN, which uses label information to condition the data generation process through an auxiliary classifier, and SPADE, which utilizes spatially-adaptive normalization to condition the generation on pose information. ReACGAN allows for the generation of realistic images that align with specific handshape labels, while SPADE focuses on generating images with accurate spatial handshape configurations. Our proposed techniques improve the current state-of-the-art accuracy on the RWTH dataset by 5%, addressing the limitations of small and unbalanced datasets. Additionally, our method demonstrates the capability to generalize across different sign language datasets by leveraging pose-based generation trained on the extensive HaGRID dataset. We achieve comparable performance to single-source trained classifiers without the need for retraining the generator.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹è¯­æ‰‹åŠ¿æ•°æ®é›†è§„æ¨¡æœ‰é™ä¸”ä¸¥é‡ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œæ¢è®¨äº†åˆ©ç”¨ç”Ÿæˆæ¨¡å‹äº§ç”Ÿåˆæˆæ•°æ®è¿›è¡Œæ•°æ®å¢å¼ºçš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶äººå‘˜åœ¨RWTH German sign languageæ•°æ®é›†ä¸Šè®­ç»ƒäº†EfficientNetåˆ†ç±»å™¨ï¼Œå¹¶å¯¹æ¯”äº†ReACGANå’ŒSPADEä¸¤ç§ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN)æ¶æ„åœ¨æ•°æ®ç”Ÿæˆä¸­çš„è¡¨ç°ã€‚ReACGANé€šè¿‡æ ‡ç­¾ä¿¡æ¯å¼•å¯¼ç”Ÿæˆé€¼çœŸå›¾åƒï¼Œè€ŒSPADEåˆ™åˆ©ç”¨ç©ºé—´è‡ªé€‚åº”å½’ä¸€åŒ–æ ¹æ®å§¿æ€(pose)ä¿¡æ¯ç”Ÿæˆç²¾ç¡®çš„ç©ºé—´æ‰‹åŠ¿é…ç½®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å°†RWTHæ•°æ®é›†çš„ç°æœ‰SOTAå‡†ç¡®ç‡æå‡äº†5%ï¼Œæœ‰æ•ˆè§£å†³äº†å°è§„æ¨¡ä¸å¹³è¡¡æ•°æ®é›†çš„è®­ç»ƒé™åˆ¶ã€‚æ­¤å¤–ï¼Œé€šè¿‡åœ¨å¤§å‹HaGRIDæ•°æ®é›†ä¸Šè¿›è¡ŒåŸºäºå§¿æ€çš„è®­ç»ƒï¼Œè¯¥æ–¹æ³•å±•ç°äº†å¼ºå¤§çš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æ— éœ€é‡æ–°è®­ç»ƒç”Ÿæˆå™¨çš„æƒ…å†µä¸‹ï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¸åŒæ‰‹è¯­æ•°æ®é›†ä¸Šå‡è¾¾åˆ°äº†ä¸å•æºè®­ç»ƒåˆ†ç±»å™¨ç›¸å½“çš„æ€§èƒ½è¡¨ç°ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 8 figures, to be published in Applied Soft Computing",
      "pdf_url": "https://arxiv.org/pdf/2507.17008v1",
      "published_date": "2025-07-22 20:41:29 UTC",
      "updated_date": "2025-07-22 20:41:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:18.686025+00:00"
    },
    {
      "arxiv_id": "2507.16999v2",
      "title": "Bayesian preference elicitation for decision support in multiobjective optimization",
      "title_zh": "å¤šç›®æ ‡ä¼˜åŒ–å†³ç­–æ”¯æŒä¸­çš„è´å¶æ–¯åå¥½è¯±å¯¼",
      "authors": [
        "Felix Huber",
        "Sebastian Rojas Gonzalez",
        "Raul Astudillo"
      ],
      "abstract": "We present a novel approach to help decision-makers efficiently identify preferred solutions from the Pareto set of a multi-objective optimization problem. Our method uses a Bayesian model to estimate the decision-maker's utility function based on pairwise comparisons. Aided by this model, a principled elicitation strategy selects queries interactively to balance exploration and exploitation, guiding the discovery of high-utility solutions. The approach is flexible: it can be used interactively or a posteriori after estimating the Pareto front through standard multi-objective optimization techniques. Additionally, at the end of the elicitation phase, it generates a reduced menu of high-quality solutions, simplifying the decision-making process. Through experiments on test problems with up to nine objectives, our method demonstrates superior performance in finding high-utility solutions with a small number of queries. We also provide an open-source implementation of our method to support its adoption by the broader community.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ–¹æ³•ï¼Œæ—¨åœ¨å¸®åŠ©å†³ç­–è€…ä»å¤šç›®æ ‡ä¼˜åŒ–é—®é¢˜ï¼ˆmulti-objective optimizationï¼‰çš„ Pareto set ä¸­é«˜æ•ˆè¯†åˆ«é¦–é€‰æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•åˆ©ç”¨ Bayesian modelï¼Œæ ¹æ®æˆå¯¹æ¯”è¾ƒï¼ˆpairwise comparisonsï¼‰æ¥ä¼°è®¡å†³ç­–è€…çš„æ•ˆç”¨å‡½æ•°ï¼ˆutility functionï¼‰ã€‚åœ¨è¯¥æ¨¡å‹çš„è¾…åŠ©ä¸‹ï¼Œä¸€ç§åŸåˆ™æ€§çš„å¯å‘ç­–ç•¥é€šè¿‡äº¤äº’å¼é€‰æ‹©æŸ¥è¯¢ï¼Œæœ‰æ•ˆå¹³è¡¡äº†æ¢ç´¢ä¸åˆ©ç”¨ï¼ˆexploration and exploitationï¼‰ï¼Œä»è€Œå¼•å¯¼å‘ç°é«˜ä»·å€¼è§£ã€‚è¯¥æ–¹æ³•è¡¨ç°å‡ºé«˜åº¦çš„çµæ´»æ€§ï¼Œæ—¢æ”¯æŒäº¤äº’å¼åº”ç”¨ï¼Œä¹Ÿæ”¯æŒåœ¨ä¼°ç®—å‡º Pareto front åè¿›è¡ŒåéªŒåˆ†æã€‚åœ¨å¯å‘é˜¶æ®µç»“æŸæ—¶ï¼Œç³»ç»Ÿä¼šç”Ÿæˆä¸€ä¸ªç²¾ç®€çš„é«˜è´¨é‡è§£å†³æ–¹æ¡ˆåˆ—è¡¨ï¼Œæå¤§ç®€åŒ–äº†æœ€ç»ˆçš„å†³ç­–æµç¨‹ã€‚å®éªŒè¯æ˜ï¼Œåœ¨å¤„ç†åŒ…å«å¤šè¾¾ä¹ä¸ªç›®æ ‡çš„å¤æ‚é—®é¢˜æ—¶ï¼Œè¯¥æ–¹æ³•ä»…éœ€å°‘é‡æŸ¥è¯¢å³å¯åœ¨å¯»æ‰¾é«˜ä»·å€¼è§£æ–¹é¢è¡¨ç°å‡ºä¼˜å¼‚æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æä¾›äº†è¯¥æ–¹æ³•çš„å¼€æºå®ç°ï¼Œä»¥ä¿ƒè¿›å…¶åœ¨æ›´å¹¿æ³›ç¤¾åŒºä¸­çš„åº”ç”¨ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "16 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16999v2",
      "published_date": "2025-07-22 20:14:20 UTC",
      "updated_date": "2025-11-11 21:05:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:15.989286+00:00"
    },
    {
      "arxiv_id": "2507.16991v2",
      "title": "PyG 2.0: Scalable Learning on Real World Graphs",
      "title_zh": "PyG 2.0ï¼šé¢å‘ç°å®ä¸–ç•Œå›¾çš„å¯æ‰©å±•å­¦ä¹ ",
      "authors": [
        "Matthias Fey",
        "Jinu Sunil",
        "Akihiro Nitta",
        "Rishi Puri",
        "Manan Shah",
        "BlaÅ¾ StojanoviÄ",
        "Ramona Bendias",
        "Alexandria Barghi",
        "Vid Kocijan",
        "Zecheng Zhang",
        "Xinwei He",
        "Jan Eric Lenssen",
        "Jure Leskovec"
      ],
      "abstract": "PyG (PyTorch Geometric) has evolved significantly since its initial release, establishing itself as a leading framework for Graph Neural Networks. In this paper, we present Pyg 2.0 (and its subsequent minor versions), a comprehensive update that introduces substantial improvements in scalability and real-world application capabilities. We detail the framework's enhanced architecture, including support for heterogeneous and temporal graphs, scalable feature/graph stores, and various optimizations, enabling researchers and practitioners to tackle large-scale graph learning problems efficiently. Over the recent years, PyG has been supporting graph learning in a large variety of application areas, which we will summarize, while providing a deep dive into the important areas of relational deep learning and large language modeling.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† PyG 2.0ï¼ˆåŠåç»­ç‰ˆæœ¬ï¼‰ï¼Œè¿™æ˜¯å¯¹é¢†å…ˆçš„å›¾ç¥ç»ç½‘ç»œæ¡†æ¶ PyTorch Geometric çš„ä¸€æ¬¡å…¨é¢å‡çº§ï¼Œæ—¨åœ¨æ˜¾è‘—æå‡å…¶åœ¨ç°å®åº”ç”¨ä¸­çš„å¯æ‰©å±•æ€§ (Scalability)ã€‚è¯¥ç‰ˆæœ¬å¼•å…¥äº†å¢å¼ºçš„ç³»ç»Ÿæ¶æ„ï¼Œå®ç°äº†å¯¹å¼‚æ„å›¾ (Heterogeneous Graphs) å’Œæ—¶åºå›¾ (Temporal Graphs) çš„åŸç”Ÿæ”¯æŒï¼Œå¹¶é›†æˆäº†é«˜æ•ˆçš„å¯æ‰©å±•ç‰¹å¾ä¸å›¾å­˜å‚¨ (Feature/Graph Stores)ã€‚é€šè¿‡ä¸€ç³»åˆ—åº•å±‚ç®—æ³•ä¸ç³»ç»Ÿä¼˜åŒ–ï¼ŒPyG 2.0 ä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°å¤„ç†å¤§è§„æ¨¡å›¾å­¦ä¹  (Large-scale Graph Learning) æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜æ·±å…¥æ¢ç´¢äº†å…³ç³»æ·±åº¦å­¦ä¹  (Relational Deep Learning) ä»¥åŠä¸å¤§è¯­è¨€æ¨¡å‹ (Large Language Modeling) çš„ç»“åˆåº”ç”¨ã€‚è¿™äº›æ”¹è¿›å…±åŒå¢å¼ºäº† PyG å¤„ç†çœŸå®ä¸–ç•Œå¤æ‚å›¾æ•°æ®çš„èƒ½åŠ›ï¼Œä¸ºå…¶åœ¨å¤šæ ·åŒ–åº”ç”¨é¢†åŸŸçš„æ™®åŠå¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16991v2",
      "published_date": "2025-07-22 19:55:09 UTC",
      "updated_date": "2025-07-27 18:32:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:22.889733+00:00"
    },
    {
      "arxiv_id": "2507.16978v1",
      "title": "Fast and Scalable Gene Embedding Search: A Comparative Study of FAISS and ScaNN",
      "title_zh": "å¿«é€Ÿä¸”å¯æ‰©å±•çš„åŸºå› åµŒå…¥æ£€ç´¢ï¼šFAISS ä¸ ScaNN çš„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Mohammad Saleh Refahi",
        "Gavin Hearne",
        "Harrison Muller",
        "Kieran Lynch",
        "Bahrad A. Sokhansanj",
        "James R. Brown",
        "Gail Rosen"
      ],
      "abstract": "The exponential growth of DNA sequencing data has outpaced traditional heuristic-based methods, which struggle to scale effectively. Efficient computational approaches are urgently needed to support large-scale similarity search, a foundational task in bioinformatics for detecting homology, functional similarity, and novelty among genomic and proteomic sequences. Although tools like BLAST have been widely used and remain effective in many scenarios, they suffer from limitations such as high computational cost and poor performance on divergent sequences.\n  In this work, we explore embedding-based similarity search methods that learn latent representations capturing deeper structural and functional patterns beyond raw sequence alignment. We systematically evaluate two state-of-the-art vector search libraries, FAISS and ScaNN, on biologically meaningful gene embeddings. Unlike prior studies, our analysis focuses on bioinformatics-specific embeddings and benchmarks their utility for detecting novel sequences, including those from uncharacterized taxa or genes lacking known homologs. Our results highlight both computational advantages (in memory and runtime efficiency) and improved retrieval quality, offering a promising alternative to traditional alignment-heavy tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹DNAæµ‹åºæ•°æ®å¿«é€Ÿå¢é•¿å¯¼è‡´ä¼ ç»Ÿå¯å‘å¼æ–¹æ³•ï¼ˆå¦‚BLASTï¼‰éš¾ä»¥æ‰©å±•ä¸”åœ¨å‘æ•£åºåˆ—ä¸Šè¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ©ç”¨åŸºäºåµŒå…¥(embedding-based)çš„ç›¸ä¼¼æ€§æœç´¢æ¥æ•æ‰æ·±å±‚ç»“æ„å’ŒåŠŸèƒ½æ¨¡å¼ã€‚ä½œè€…ç³»ç»Ÿåœ°å¯¹æ¯”è¯„ä¼°äº†FAISSå’ŒScaNNä¸¤ç§å…ˆè¿›çš„å‘é‡æœç´¢åº“åœ¨ç”Ÿç‰©å­¦åŸºå› åµŒå…¥(gene embeddings)ä¸Šçš„åº”ç”¨æ•ˆæœã€‚ä¸åŒäºä¼ ç»Ÿç ”ç©¶ï¼Œæœ¬é¡¹åˆ†æç‰¹åˆ«ä¾§é‡äºç”Ÿç‰©ä¿¡æ¯å­¦ç‰¹å®šçš„åµŒå…¥ï¼Œå¹¶é’ˆå¯¹æ¢æµ‹ç¼ºä¹å·²çŸ¥åŒæºç‰©æˆ–æ¥è‡ªæœªè¡¨å¾åˆ†ç±»ç¾¤çš„æ–°åºåˆ—è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¿™äº›æ–¹æ³•åœ¨å†…å­˜å’Œè¿è¡Œæ—¶é—´æ•ˆç‡ä¸Šå±•ç°å‡ºæ˜¾è‘—çš„è®¡ç®—ä¼˜åŠ¿ï¼ŒåŒæ—¶æœ‰æ•ˆæå‡äº†æ•°æ®æ£€ç´¢çš„è´¨é‡ã€‚è¯¥å·¥ä½œä¸ºè§£å†³å¤§è§„æ¨¡ç”Ÿç‰©åŸºå› åºåˆ—çš„åŒæºæ€§æ£€æµ‹ã€åŠŸèƒ½ç›¸ä¼¼æ€§è¯†åˆ«åŠæ–°é¢–æ€§å‘ç°æä¾›äº†æå…·å‰æ™¯çš„é«˜æ•ˆæ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16978v1",
      "published_date": "2025-07-22 19:28:54 UTC",
      "updated_date": "2025-07-22 19:28:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:31.586957+00:00"
    },
    {
      "arxiv_id": "2507.16974v2",
      "title": "Leveraging Synthetic Data for Question Answering with Multilingual LLMs in the Agricultural Domain",
      "title_zh": "åˆ©ç”¨åˆæˆæ•°æ®æå‡å†œä¸šé¢†åŸŸå¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹çš„é—®ç­”èƒ½åŠ›",
      "authors": [
        "Rishemjit Kaur",
        "Arshdeep Singh Bhankhar",
        "Jashanpreet Singh Salh",
        "Sudhir Rajput",
        "Vidhi",
        "Kashish Mahendra",
        "Bhavika Berwal",
        "Ritesh Kumar",
        "Surangika Ranathunga"
      ],
      "abstract": "Enabling farmers to access accurate agriculture-related information in their native languages in a timely manner is crucial for the success of the agriculture field. Publicly available general-purpose Large Language Models (LLMs) typically offer generic agriculture advisories, lacking precision in local and multilingual contexts. Our study addresses this limitation by generating multilingual (English, Hindi, Punjabi) synthetic datasets from agriculture-specific documents from India and fine-tuning LLMs for the task of question answering (QA). Evaluation on human-created datasets demonstrates significant improvements in factuality, relevance, and agricultural consensus for the fine-tuned LLMs compared to the baseline counterparts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å†œä¸šé¢†åŸŸç¼ºä¹æœ¬åœ°åŒ–å’Œå¤šè¯­è¨€ç²¾å‡†æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨åˆæˆæ•°æ®(Synthetic Data)å¢å¼ºé—®ç­”(Question Answering)æ€§èƒ½çš„æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å°åº¦å†œä¸šç‰¹å®šæ–‡æ¡£ç”Ÿæˆäº†è‹±è¯­ã€å°åœ°è¯­å’Œæ—é®æ™®è¯­çš„å¤šè¯­è¨€åˆæˆæ•°æ®é›†ï¼Œå¹¶å¯¹å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹(Multilingual LLMs)è¿›è¡Œäº†å¾®è°ƒ(Fine-tuning)ã€‚å®éªŒç»“æœåœ¨äººå·¥æ•°æ®é›†çš„è¯„ä¼°ä¸­æ˜¾ç¤ºï¼Œå¾®è°ƒåçš„æ¨¡å‹åœ¨äº‹å®æ€§(Factuality)ã€ç›¸å…³æ€§(Relevance)å’Œå†œä¸šå…±è¯†(Agricultural Consensus)æ–¹é¢å‡æ˜¾è‘—ä¼˜äºåŸºå‡†æ¨¡å‹ã€‚è¯¥æˆæœè¯æ˜äº†åˆ©ç”¨åˆæˆæ•°æ®å¼¥è¡¥å†œä¸šç‰¹å®šé¢†åŸŸçŸ¥è¯†ä¸è¯­è¨€ç¼ºå£çš„å¯è¡Œæ€§ï¼Œä¸ºæå‡å†œæ°‘è·å–ç²¾å‡†å†œä¸šå’¨è¯¢çš„æ•ˆç‡æä¾›äº†é‡è¦æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 9 tables, Appendix A-L",
      "pdf_url": "https://arxiv.org/pdf/2507.16974v2",
      "published_date": "2025-07-22 19:25:10 UTC",
      "updated_date": "2025-08-01 09:04:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:26.999318+00:00"
    },
    {
      "arxiv_id": "2507.16971v1",
      "title": "Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning",
      "title_zh": "Text-to-SPARQL çªç ´è‹±è¯­å±€é™ï¼šåŸºäºç±»äººæ¨ç†çš„çŸ¥è¯†å›¾è°±å¤šè¯­è¨€é—®ç­”",
      "authors": [
        "Aleksandr Perevalov",
        "Andreas Both"
      ],
      "abstract": "Accessing knowledge via multilingual natural-language interfaces is one of the emerging challenges in the field of information retrieval and related ones. Structured knowledge stored in knowledge graphs can be queried via a specific query language (e.g., SPARQL). Therefore, one needs to transform natural-language input into a query to fulfill an information need. Prior approaches mostly focused on combining components (e.g., rule-based or neural-based) that solve downstream tasks and come up with an answer at the end. We introduce mKGQAgent, a human-inspired framework that breaks down the task of converting natural language questions into SPARQL queries into modular, interpretable subtasks. By leveraging a coordinated LLM agent workflow for planning, entity linking, and query refinement - guided by an experience pool for in-context learning - mKGQAgent efficiently handles multilingual KGQA. Evaluated on the DBpedia- and Corporate-based KGQA benchmarks within the Text2SPARQL challenge 2025, our approach took first place among the other participants. This work opens new avenues for developing human-like reasoning systems in multilingual semantic parsing.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† mKGQAgentï¼Œè¿™æ˜¯ä¸€ä¸ªå—äººç±»å¯å‘çš„å¤šè¯­è¨€çŸ¥è¯†å›¾è°±é—®ç­”(KGQA)æ¡†æ¶ï¼Œæ—¨åœ¨å°†è‡ªç„¶è¯­è¨€é—®é¢˜é«˜æ•ˆè½¬åŒ–ä¸º SPARQL æŸ¥è¯¢ã€‚ä¸ä»¥å¾€æ•´åˆä¸‹æ¸¸ä»»åŠ¡ç»„ä»¶çš„æ–¹æ³•ä¸åŒï¼ŒmKGQAgent å°†å¤æ‚çš„è½¬æ¢ä»»åŠ¡åˆ†è§£ä¸ºæ¨¡å—åŒ–ã€å¯è§£é‡Šçš„å­ä»»åŠ¡ï¼Œå¹¶é€šè¿‡åè°ƒçš„å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“å·¥ä½œæµæ‰§è¡Œè§„åˆ’ã€å®ä½“é“¾æ¥(entity linking)å’ŒæŸ¥è¯¢ç»†åŒ–(query refinement)ã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨ç»éªŒæ± (experience pool)è¿›è¡Œä¸Šä¸‹æ–‡å­¦ä¹ (in-context learning)ï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹å¤šè¯­è¨€ç¯å¢ƒçš„å¤„ç†èƒ½åŠ›ã€‚åœ¨ Text2SPARQL challenge 2025 çš„ DBpedia å’Œ Corporate åŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨æ‰€æœ‰å‚èµ›è€…ä¸­è£è·ç¬¬ä¸€åã€‚è¿™é¡¹å·¥ä½œä¸ºå¼€å‘å…·æœ‰ç±»äººæ¨ç†èƒ½åŠ›çš„å¤šè¯­è¨€è¯­ä¹‰è§£æç³»ç»Ÿå¼€è¾Ÿäº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "During the final evaluation on the DBpedia- and Corporate-based KGQA benchmarks within the Text2SPARQL challenge 2025, our approach took first place among the other participants",
      "pdf_url": "https://arxiv.org/pdf/2507.16971v1",
      "published_date": "2025-07-22 19:23:03 UTC",
      "updated_date": "2025-07-22 19:23:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:37.695396+00:00"
    },
    {
      "arxiv_id": "2507.16952v2",
      "title": "Evaluating Ensemble and Deep Learning Models for Static Malware Detection with Dimensionality Reduction Using the EMBER Dataset",
      "title_zh": "åŸºäº EMBER æ•°æ®é›†ç»“åˆé™ç»´æŠ€æœ¯çš„é›†æˆå­¦ä¹ ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹é™æ€æ¶æ„è½¯ä»¶æ£€æµ‹è¯„ä¼°",
      "authors": [
        "Md Min-Ha-Zul Abedin",
        "Tazqia Mehrub"
      ],
      "abstract": "This study investigates the effectiveness of several machine learning algorithms for static malware detection using the EMBER dataset, which contains feature representations of Portable Executable (PE) files. We evaluate eight classification models: LightGBM, XGBoost, CatBoost, Random Forest, Extra Trees, HistGradientBoosting, k-Nearest Neighbors (KNN), and TabNet, under three preprocessing settings: original feature space, Principal Component Analysis (PCA), and Linear Discriminant Analysis (LDA). The models are assessed on accuracy, precision, recall, F1 score, and AUC to examine both predictive performance and robustness. Ensemble methods, especially LightGBM and XGBoost, show the best overall performance across all configurations, with minimal sensitivity to PCA and consistent generalization. LDA improves KNN performance but significantly reduces accuracy for boosting models. TabNet, while promising in theory, underperformed under feature reduction, likely due to architectural sensitivity to input structure. The analysis is supported by detailed exploratory data analysis (EDA), including mutual information ranking, PCA or t-SNE visualizations, and outlier detection using Isolation Forest and Local Outlier Factor (LOF), which confirm the discriminatory capacity of key features in the EMBER dataset. The results suggest that boosting models remain the most reliable choice for high-dimensional static malware detection, and that dimensionality reduction should be applied selectively based on model type. This work provides a benchmark for comparing classification models and preprocessing strategies in malware detection tasks and contributes insights that can guide future system development and real-world deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨ EMBER æ•°æ®é›†è¯„ä¼°äº†å¤šç§æœºå™¨å­¦ä¹ ç®—æ³•åœ¨é™æ€æ¶æ„è½¯ä»¶æ£€æµ‹ (Static Malware Detection) ä¸­çš„æœ‰æ•ˆæ€§ã€‚ç ”ç©¶å¯¹æ¯”äº† LightGBMã€XGBoostã€CatBoostã€Random Forestã€Extra Treesã€HistGradientBoostingã€k-Nearest Neighbors (KNN) å’Œ TabNet å…«ç§åˆ†ç±»æ¨¡å‹ï¼Œå¹¶è€ƒå¯Ÿäº†åŸå§‹ç‰¹å¾ç©ºé—´ã€Principal Component Analysis (PCA) å’Œ Linear Discriminant Analysis (LDA) ä¸‰ç§é¢„å¤„ç†ç­–ç•¥ã€‚åˆ†æè¿‡ç¨‹ç»“åˆäº†äº’ä¿¡æ¯ (Mutual Information) æ’åºã€t-SNE å¯è§†åŒ–ä»¥åŠä½¿ç”¨ Isolation Forest å’Œ Local Outlier Factor (LOF) è¿›è¡Œçš„ç¦»ç¾¤å€¼æ£€æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»¥ LightGBM å’Œ XGBoost ä¸ºä»£è¡¨çš„é›†æˆæ–¹æ³•åœ¨å„é…ç½®ä¸‹è¡¨ç°æœ€ä¼˜ä¸”å…·æœ‰è¾ƒå¼ºçš„æ³›åŒ–èƒ½åŠ›ã€‚LDA è™½èƒ½æå‡ KNN çš„æ€§èƒ½ï¼Œä½†ä¼šæ˜¾è‘—å‰Šå¼± Boosting æ¨¡å‹çš„è¡¨ç°ï¼Œè€Œæ·±åº¦å­¦ä¹ æ¨¡å‹ TabNet åœ¨ç‰¹å¾é™ç»´åçš„æ•ˆæœäº¦ä¸ç†æƒ³ã€‚æœ€ç»ˆç»“è®ºè®¤ä¸º Boosting æ¨¡å‹æ˜¯å¤„ç†é«˜ç»´é™æ€æ¶æ„è½¯ä»¶æ£€æµ‹ä»»åŠ¡æœ€å¯é çš„é€‰æ‹©ï¼Œé™ç»´æŠ€æœ¯çš„åº”ç”¨éœ€æ ¹æ®å…·ä½“æ¨¡å‹è¿›è¡Œé’ˆå¯¹æ€§é€‰æ‹©ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16952v2",
      "published_date": "2025-07-22 18:45:10 UTC",
      "updated_date": "2025-07-24 22:23:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:38.190597+00:00"
    },
    {
      "arxiv_id": "2507.16933v1",
      "title": "SiLQ: Simple Large Language Model Quantization-Aware Training",
      "title_zh": "SiLQï¼šç®€æ˜“å¤§è¯­è¨€æ¨¡å‹é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ",
      "authors": [
        "Steven K. Esser",
        "Jeffrey L. McKinstry",
        "Deepika Bablani",
        "Rathinakumar Appuswamy",
        "Dharmendra S. Modha"
      ],
      "abstract": "Large language models can be quantized to reduce inference time latency, model size, and energy consumption, thereby delivering a better user experience at lower cost. A challenge exists to deliver quantized models with minimal loss of accuracy in reasonable time, and in particular to do so without requiring mechanisms incompatible with specialized inference accelerators. Here, we demonstrate a simple, end-to-end quantization-aware training approach that, with an increase in total model training budget of less than 0.1%, outperforms the leading published quantization methods by large margins on several modern benchmarks, with both base and instruct model variants. The approach easily generalizes across different model architectures, can be applied to activations, cache, and weights, and requires the introduction of no additional operations to the model other than the quantization itself.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SiLQï¼Œä¸€ç§ç®€å•ä¸”ç«¯åˆ°ç«¯çš„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(Quantization-Aware Training, QAT)æ–¹æ³•ï¼Œæ—¨åœ¨é™ä½å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„æ¨ç†å»¶è¿Ÿã€æ¨¡å‹å°ºå¯¸å’Œèƒ½è€—ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨æ€»è®­ç»ƒé¢„ç®—ä¸­ä»…å¢åŠ ä¸åˆ°0.1%çš„æˆæœ¬ï¼Œåœ¨å¤šä¸ªç°ä»£åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—è¶…è¶Šäº†é¢†å…ˆçš„é‡åŒ–æ–¹æ³•ï¼Œä¸”åŒæ—¶é€‚ç”¨äºåŸºç¡€(base)å’ŒæŒ‡ä»¤(instruct)æ¨¡å‹å˜ä½“ã€‚SiLQå…·æœ‰æå¼ºçš„é€šç”¨æ€§ï¼Œå¯è·¨ä¸åŒæ¨¡å‹æ¶æ„åº”ç”¨ï¼Œå¹¶èƒ½åŒæ—¶å¯¹æƒé‡(weights)ã€æ¿€æ´»å€¼(activations)å’Œç¼“å­˜(cache)è¿›è¡Œé‡åŒ–ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨æ¨¡å‹ä¸­ä¸å¼•å…¥é‡åŒ–ä»¥å¤–çš„ä»»ä½•é¢å¤–æ“ä½œï¼Œç¡®ä¿äº†ä¸ä¸“ç”¨æ¨ç†åŠ é€Ÿå™¨çš„å®Œå…¨å…¼å®¹ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒSiLQèƒ½å¤Ÿä»¥æä½çš„è®¡ç®—å¼€é”€å®ç°é«˜ç²¾åº¦çš„æ¨¡å‹é‡åŒ–ï¼Œä¸ºå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹çš„é«˜æ•ˆéƒ¨ç½²æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16933v1",
      "published_date": "2025-07-22 18:17:53 UTC",
      "updated_date": "2025-07-22 18:17:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:42.551061+00:00"
    },
    {
      "arxiv_id": "2507.16815v2",
      "title": "ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning",
      "title_zh": "ThinkActï¼šåŸºäºå¼ºåŒ–è§†è§‰æ½œç©ºé—´è§„åˆ’çš„è§†è§‰-è¯­è¨€-åŠ¨ä½œæ¨ç†",
      "authors": [
        "Chi-Pin Huang",
        "Yueh-Hua Wu",
        "Min-Hung Chen",
        "Yu-Chiang Frank Wang",
        "Fu-En Yang"
      ],
      "abstract": "Vision-language-action (VLA) reasoning tasks require agents to interpret multimodal instructions, perform long-horizon planning, and act adaptively in dynamic environments. Existing approaches typically train VLA models in an end-to-end fashion, directly mapping inputs to actions without explicit reasoning, which hinders their ability to plan over multiple steps or adapt to complex task variations. In this paper, we propose ThinkAct, a dual-system framework that bridges high-level reasoning with low-level action execution via reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate embodied reasoning plans guided by reinforcing action-aligned visual rewards based on goal completion and trajectory consistency. These reasoning plans are compressed into a visual plan latent that conditions a downstream action model for robust action execution on target environments. Extensive experiments on embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct enables few-shot adaptation, long-horizon planning, and self-correction behaviors in complex embodied AI tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ThinkActï¼Œä¸€ç§é€šè¿‡å¼ºåŒ–è§†è§‰æ½œç©ºé—´è§„åˆ’ï¼ˆreinforced visual latent planningï¼‰è¿æ¥é«˜å±‚æ¨ç†ä¸åº•å±‚åŠ¨ä½œæ‰§è¡Œçš„åŒç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è§†è§‰è¯­è¨€åŠ¨ä½œï¼ˆVision-language-action, VLAï¼‰æ¨¡å‹åœ¨é•¿ç¨‹è§„åˆ’å’Œå¤æ‚ä»»åŠ¡è‡ªé€‚åº”æ–¹é¢çš„å±€é™ã€‚ThinkActåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ä¸­çš„ç›®æ ‡å®Œæˆåº¦å’Œè½¨è¿¹ä¸€è‡´æ€§å¥–åŠ±ï¼Œè®­ç»ƒå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆmultimodal LLMï¼‰ç”Ÿæˆå…·èº«æ¨ç†è®¡åˆ’ã€‚è¿™äº›è®¡åˆ’éšåè¢«å‹ç¼©ä¸ºè§†è§‰è®¡åˆ’æ½œå˜é‡ï¼ˆvisual plan latentï¼‰ï¼Œä¸ºä¸‹æ¸¸åŠ¨ä½œæ¨¡å‹æä¾›æ¡ä»¶ï¼Œä»è€Œåœ¨ç›®æ ‡ç¯å¢ƒä¸­å®ç°ç¨³å¥çš„åŠ¨ä½œæ‰§è¡Œã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒThinkActåœ¨å…·èº«æ¨ç†å’Œæœºå™¨äººæ“æ§åŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†æ˜¾è‘—çš„å°‘æ ·æœ¬è‡ªé€‚åº”ã€é•¿ç¨‹è§„åˆ’å’Œè‡ªæˆ‘ä¿®æ­£è¡Œä¸ºã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2025. Project page: https://jasper0314-huang.github.io/thinkact-vla/",
      "pdf_url": "https://arxiv.org/pdf/2507.16815v2",
      "published_date": "2025-07-22 17:59:46 UTC",
      "updated_date": "2025-09-18 16:26:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:43.746087+00:00"
    },
    {
      "arxiv_id": "2507.16812v2",
      "title": "MegaScience: Pushing the Frontiers of Post-Training Datasets for Science Reasoning",
      "title_zh": "MegaScienceï¼šæ‹“å±•ç§‘å­¦æ¨ç†è®­ç»ƒåæ•°æ®é›†çš„å‰æ²¿",
      "authors": [
        "Run-Ze Fan",
        "Zengzhi Wang",
        "Pengfei Liu"
      ],
      "abstract": "Scientific reasoning is critical for developing AI scientists and supporting human researchers in advancing the frontiers of natural science discovery. However, the open-source community has primarily focused on mathematics and coding while neglecting the scientific domain, largely due to the absence of open, large-scale, high-quality, verifiable scientific reasoning datasets. To bridge this gap, we first present TextbookReasoning, an open dataset featuring truthful reference answers extracted from 12k university-level scientific textbooks, comprising 650k reasoning questions spanning 7 scientific disciplines. We further introduce MegaScience, a large-scale mixture of high-quality open-source datasets totaling 1.25 million instances, developed through systematic ablation studies that evaluate various data selection methodologies to identify the optimal subset for each publicly available scientific dataset. Meanwhile, we build a comprehensive evaluation system covering diverse subjects and question types across 15 benchmarks, incorporating comprehensive answer extraction strategies to ensure accurate evaluation metrics. Our experiments demonstrate that our datasets achieve superior performance and training efficiency with more concise response lengths compared to existing open-source scientific datasets. Furthermore, we train Llama3.1, Qwen2.5, and Qwen3 series base models on MegaScience, which significantly outperform the corresponding official instruct models in average performance. In addition, MegaScience exhibits greater effectiveness for larger and stronger models, suggesting a scaling benefit for scientific tuning. We release our data curation pipeline, evaluation system, datasets, and seven trained models to the community to advance scientific reasoning research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼€æºç¤¾åŒºåœ¨ç§‘å­¦æ¨ç†é¢†åŸŸç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡ä¸”å¯éªŒè¯æ•°æ®é›†çš„ç°çŠ¶ï¼Œæ¨å‡ºäº†æ—¨åœ¨æ¨è¿›ç§‘å­¦æ¨ç†åè®­ç»ƒ(post-training)è¾¹ç•Œçš„MegaScienceé¡¹ç›®ã€‚ç ”ç©¶é¦–å…ˆæ„å»ºäº†TextbookReasoningæ•°æ®é›†ï¼ŒåŒ…å«ä»1.2ä¸‡æœ¬å¤§å­¦çº§æ•™ç§‘ä¹¦ä¸­æå–çš„æ¶µç›–7ä¸ªå­¦ç§‘çš„65ä¸‡ä¸ªæ¨ç†é—®é¢˜ã€‚é€šè¿‡ç³»ç»Ÿçš„æ¶ˆèå®éªŒ(ablation studies)å’Œæ•°æ®ç­›é€‰ï¼Œå›¢é˜Ÿè¿›ä¸€æ­¥æ•´åˆå‡ºåŒ…å«125ä¸‡ä¸ªé«˜è´¨é‡å®ä¾‹çš„MegaScienceé›†åˆï¼Œå¹¶é…å¥—å»ºç«‹äº†æ¶µç›–15ä¸ªåŸºå‡†æµ‹è¯•(benchmarks)çš„ç»¼åˆè¯„ä¼°ç³»ç»Ÿã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ•°æ®é›†åœ¨è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹æ€§èƒ½ä¸Šå‡ä¼˜äºç°æœ‰å¼€æºæ•°æ®é›†ï¼Œåœ¨Llama3.1ã€Qwen2.5åŠQwen3ç­‰ç³»åˆ—æ¨¡å‹ä¸Šçš„è¡¨ç°æ˜¾è‘—è¶…è¶Šäº†å®˜æ–¹æŒ‡ä»¤æ¨¡å‹ã€‚ç ”ç©¶è¿˜å‘ç°MegaScienceåœ¨æ›´å¤§ã€æ›´å¼ºçš„æ¨¡å‹ä¸Šå±•ç°å‡ºæ›´ä½³çš„æœ‰æ•ˆæ€§ï¼Œè¯å®äº†ç§‘å­¦å¾®è°ƒ(scientific tuning)å…·æœ‰æ˜¾è‘—çš„ç¼©æ”¾æ•ˆåº”(scaling benefit)ã€‚ç›®å‰ï¼Œè¯¥ç ”ç©¶å·²å…¨é¢å¼€æºå…¶æ•°æ®å¤„ç†æµæ°´çº¿ã€è¯„ä¼°ç³»ç»Ÿã€æ•°æ®é›†åŠä¸ƒä¸ªè®­ç»ƒæ¨¡å‹ï¼Œä¸ºäººå·¥æ™ºèƒ½è¾…åŠ©ç§‘å­¦å‘ç°æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages; Github: https://github.com/GAIR-NLP/MegaScience; HF: https://huggingface.co/MegaScience",
      "pdf_url": "https://arxiv.org/pdf/2507.16812v2",
      "published_date": "2025-07-22 17:59:03 UTC",
      "updated_date": "2025-08-27 03:10:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:09:50.048096+00:00"
    },
    {
      "arxiv_id": "2507.16887v3",
      "title": "Revisiting Pre-trained Language Models for Vulnerability Detection",
      "title_zh": "é‡æ–°å®¡è§†é¢å‘æ¼æ´æ£€æµ‹çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹",
      "authors": [
        "Youpeng Li",
        "Weiliang Qi",
        "Xuyu Wang",
        "Fuxun Yu",
        "Xinda Wang"
      ],
      "abstract": "The rapid advancement of pre-trained language models (PLMs) has demonstrated promising results for various code-related tasks. However, their effectiveness in detecting real-world vulnerabilities remains a critical challenge. While existing empirical studies evaluate PLMs for vulnerability detection (VD), they suffer from data leakage, limited scope, and superficial analysis, hindering the accuracy and comprehensiveness of evaluations. This paper begins by revisiting the common issues in existing research on PLMs for VD through the evaluation pipeline. It then proceeds with an accurate and extensive evaluation of 18 PLMs on high-quality datasets that feature accurate labeling, diverse vulnerability types, and various projects. Specifically, we compare the performance of PLMs under both fine-tuning and prompt engineering, assess their effectiveness and generalizability across various training and testing settings, and analyze their robustness to a series of perturbations.\n  Our findings reveal that PLMs incorporating pre-training tasks designed to capture the syntactic and semantic patterns of code outperform both general-purpose PLMs and those solely pre-trained or fine-tuned on large code corpora. However, these models face notable challenges in real-world scenarios, such as difficulties in detecting vulnerabilities with complex dependencies, handling perturbations introduced by code normalization and abstraction, and identifying semantic-preserving vulnerable code transformations. Also, the truncation caused by the limited context windows of PLMs can lead to a non-negligible number of labeling errors, which is overlooked by previous work. This study underscores the importance of thorough evaluations of model performance in practical scenarios and outlines future directions to help enhance the effectiveness of PLMs for realistic VD applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é‡æ–°å®¡è§†äº†é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹(PLMs)åœ¨æ¼æ´æ£€æµ‹(VD)é¢†åŸŸçš„åº”ç”¨ï¼Œé’ˆå¯¹ç°æœ‰ç ”ç©¶å­˜åœ¨çš„ä»£ç æ³„éœ²ã€è¯„ä¼°èŒƒå›´æœ‰é™å’Œåˆ†æè¡¨æµ…ç­‰é—®é¢˜è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä½œè€…åœ¨åŒ…å«å¤šæ ·åŒ–æ¼æ´ç±»å‹å’Œé¡¹ç›®çš„é«˜è´¨é‡æ•°æ®é›†ä¸Šï¼Œå¯¹18ç§PLMsè¿›è¡Œäº†å…¨é¢è¯„ä¼°ï¼Œæ¶µç›–äº†å¾®è°ƒ(Fine-tuning)å’Œæç¤ºå·¥ç¨‹(Prompt engineering)ä¸¤ç§æ¨¡å¼ã€‚å®éªŒå‘ç°ï¼Œé›†æˆäº†æ—¨åœ¨æ•æ‰ä»£ç è¯­æ³•å’Œè¯­ä¹‰æ¨¡å¼çš„é¢„è®­ç»ƒä»»åŠ¡çš„æ¨¡å‹ï¼Œå…¶è¡¨ç°ä¼˜äºé€šç”¨PLMsæˆ–ä»…åœ¨å¤§è§„æ¨¡ä»£ç è¯­æ–™åº“ä¸Šè®­ç»ƒçš„æ¨¡å‹ã€‚ç„¶è€Œï¼ŒPLMsåœ¨å¤„ç†å…·æœ‰å¤æ‚ä¾èµ–å…³ç³»çš„æ¼æ´ã€åº”å¯¹ä»£ç è§„èŒƒåŒ–å’ŒæŠ½è±¡å¸¦æ¥çš„æ‰°åŠ¨ï¼Œä»¥åŠè¯†åˆ«ä¿æŒè¯­ä¹‰çš„æ¼æ´ä»£ç è½¬æ¢æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶æŒ‡å‡ºæ¨¡å‹æœ‰é™çš„ä¸Šä¸‹æ–‡çª—å£å¯¼è‡´çš„æ–‡æœ¬æˆªæ–­ä¼šå¼•å‘ä¸å¯å¿½è§†çš„æ ‡æ³¨é”™è¯¯ï¼Œè¿™æ˜¯ä»¥å¾€å·¥ä½œæ‰€å¿½ç•¥çš„ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†åœ¨å®é™…åœºæ™¯ä¸­æ·±å…¥è¯„ä¼°æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§ï¼Œå¹¶ä¸ºæå‡PLMsåœ¨ç°å®VDåº”ç”¨ä¸­çš„æœ‰æ•ˆæ€§æŒ‡æ˜äº†æœªæ¥æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by the 21st ACM ASIA Conference on Computer and Communications Security (AsiaCCS 2026)",
      "pdf_url": "https://arxiv.org/pdf/2507.16887v3",
      "published_date": "2025-07-22 17:58:49 UTC",
      "updated_date": "2025-11-22 18:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:39.218792+00:00"
    },
    {
      "arxiv_id": "2507.16886v1",
      "title": "Sparser2Sparse: Single-shot Sparser-to-Sparse Learning for Spatial Transcriptomics Imputation with Natural Image Co-learning",
      "title_zh": "Sparser2Sparseï¼šç»“åˆè‡ªç„¶å›¾åƒååŒå­¦ä¹ çš„å•æ ·æœ¬â€œä»æ›´ç¨€ç–åˆ°ç¨€ç–â€ç©ºé—´è½¬å½•ç»„å­¦æ•°æ®å¡«è¡¥",
      "authors": [
        "Yaoyu Fang",
        "Jiahe Qian",
        "Xinkun Wang",
        "Lee A. Cooper",
        "Bo Zhou"
      ],
      "abstract": "Spatial transcriptomics (ST) has revolutionized biomedical research by enabling high resolution gene expression profiling within tissues. However, the high cost and scarcity of high resolution ST data remain significant challenges. We present Single-shot Sparser-to-Sparse (S2S-ST), a novel framework for accurate ST imputation that requires only a single and low-cost sparsely sampled ST dataset alongside widely available natural images for co-training. Our approach integrates three key innovations: (1) a sparser-to-sparse self-supervised learning strategy that leverages intrinsic spatial patterns in ST data, (2) cross-domain co-learning with natural images to enhance feature representation, and (3) a Cascaded Data Consistent Imputation Network (CDCIN) that iteratively refines predictions while preserving sampled gene data fidelity. Extensive experiments on diverse tissue types, including breast cancer, liver, and lymphoid tissue, demonstrate that our method outperforms state-of-the-art approaches in imputation accuracy. By enabling robust ST reconstruction from sparse inputs, our framework significantly reduces reliance on costly high resolution data, facilitating potential broader adoption in biomedical research and clinical applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Single-shot Sparser-to-Sparse (S2S-ST)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç©ºé—´è½¬å½•ç»„å­¦(Spatial transcriptomics, ST)ä¸­é«˜åˆ†è¾¨ç‡æ•°æ®ç¨€ç¼ºä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ä»…éœ€ä½æˆæœ¬çš„ç¨€ç–é‡‡æ ·æ•°æ®é›†å’Œé€šç”¨çš„è‡ªç„¶å›¾åƒ(natural images)å³å¯å®ç°ç²¾å‡†æ’è¡¥ï¼Œé€šè¿‡æ›´ç¨€ç–åˆ°ç¨€ç–(sparser-to-sparse)çš„è‡ªç›‘ç£å­¦ä¹ ç­–ç•¥æ•æ‰STæ•°æ®çš„å†…åœ¨ç©ºé—´æ¨¡å¼ã€‚æ ¸å¿ƒæŠ€æœ¯è¿˜åŒ…æ‹¬ä¸è‡ªç„¶å›¾åƒçš„è·¨åŸŸååŒå­¦ä¹ (cross-domain co-learning)ä»¥å¢å¼ºç‰¹å¾è¡¨å¾ï¼Œä»¥åŠçº§è”æ•°æ®ä¸€è‡´æ€§æ’è¡¥ç½‘ç»œ(Cascaded Data Consistent Imputation Network, CDCIN)æ¥è¿­ä»£ä¼˜åŒ–é¢„æµ‹å¹¶ç¡®ä¿é‡‡æ ·æ•°æ®çš„ä¿çœŸåº¦ã€‚åœ¨ä¹³è…ºç™Œã€è‚è„å’Œæ·‹å·´ç»„ç»‡ç­‰å¤šç§ç»„ç»‡ç±»å‹ä¸Šçš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ’è¡¥å‡†ç¡®åº¦ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æœ€å…ˆè¿›æ–¹æ³•(state-of-the-art)ã€‚é€šè¿‡å®ç°ä»ç¨€ç–è¾“å…¥åˆ°ç¨³å¥STé‡å»ºçš„è½¬åŒ–ï¼Œè¯¥æ¡†æ¶å¤§å¹…é™ä½äº†å¯¹é«˜åˆ†è¾¨ç‡æ•°æ®çš„ä¾èµ–ï¼Œä¸ºç”Ÿç‰©åŒ»å­¦ç ”ç©¶å’Œä¸´åºŠåº”ç”¨æä¾›äº†æ›´å…·æ™®é€‚æ€§çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 5 figure, under review",
      "pdf_url": "https://arxiv.org/pdf/2507.16886v1",
      "published_date": "2025-07-22 17:58:38 UTC",
      "updated_date": "2025-07-22 17:58:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:41.543501+00:00"
    },
    {
      "arxiv_id": "2507.16808v1",
      "title": "Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis",
      "title_zh": "ç»ç”±æ—¶åºé€»è¾‘èœ•å˜é‡æ–°å®¡è§†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ RTL ä»£ç ä¼˜åŒ–",
      "authors": [
        "Zhihao Xu",
        "Bixin Li",
        "Lulu Wang"
      ],
      "abstract": "Register Transfer Level(RTL) code optimization is crucial for achieving high performance and low power consumption in digital circuit design. However, traditional optimization methods often rely on manual tuning and heuristics, which can be time-consuming and error-prone. Recent studies proposed to leverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs can generate optimized code snippets based on natural language descriptions, potentially speeding up the optimization process. However, existing approaches have not thoroughly evaluated the effectiveness of LLM-Based code optimization methods for RTL code with complex timing logic. To address this gap, we conducted a comprehensive empirical investigation to assess the capability of LLM-Based RTL code optimization methods in handling RTL code with complex timing logic. In this study, we first propose a new benchmark for RTL optimization evaluation. It comprises four subsets, each corresponding to a specific area of RTL code optimization. Then we introduce a method based on metamorphosis to systematically evaluate the effectiveness of LLM-Based RTL code optimization methods.Our key insight is that the optimization effectiveness should remain consistent for semantically equivalent but more complex code. After intensive experiments, we revealed several key findings. (1) LLM-Based RTL optimization methods can effectively optimize logic operations and outperform existing compiler-based methods. (2) LLM-Based RTL optimization methods do not perform better than existing compiler-based methods on RTL code with complex timing logic, particularly in timing control flow optimization and clock domain optimization. This is primarily attributed to the challenges LLMs face in understanding timing logic in RTL code. Based on these findings, we provide insights for further research in leveraging LLMs for RTL code optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¯„å­˜å™¨ä¼ è¾“çº§(RTL)ä»£ç ä¼˜åŒ–æ–¹æ³•åœ¨å¤„ç†å¤æ‚æ—¶åºé€»è¾‘æ—¶çš„æœ‰æ•ˆæ€§è¿›è¡Œäº†æ·±å…¥è¯„ä¼°ã€‚ç ”ç©¶è€…æå‡ºäº†ä¸€ä¸ªæ–°çš„RTLä¼˜åŒ–è¯„ä¼°åŸºå‡†æµ‹è¯•é›†ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§åŸºäºèœ•å˜(Metamorphosis)çš„æ–¹æ³•æ¥ç³»ç»Ÿè¯„ä¼°LLMsçš„ä¼˜åŒ–æ•ˆèƒ½ï¼Œå…¶æ ¸å¿ƒåœ¨äºè€ƒå¯Ÿæ¨¡å‹å¯¹è¯­ä¹‰ç­‰ä»·ä½†å¤æ‚åº¦å¢åŠ çš„ä»£ç åœ¨ä¼˜åŒ–è¡¨ç°ä¸Šçš„ä¸€è‡´æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMsåœ¨ä¼˜åŒ–é€»è¾‘è¿ç®—(Logic Operations)æ–¹é¢è¡¨ç°å‡ºè‰²ä¸”ä¼˜äºä¼ ç»Ÿçš„ç¼–è¯‘å™¨æ–¹æ³•ã€‚ç„¶è€Œï¼Œåœ¨æ¶‰åŠå¤æ‚æ—¶åºé€»è¾‘çš„ä»»åŠ¡ä¸­ï¼Œç‰¹åˆ«æ˜¯æ—¶åºæ§åˆ¶æµä¼˜åŒ–(Timing Control Flow Optimization)å’Œæ—¶é’ŸåŸŸä¼˜åŒ–(Clock Domain Optimization)æ–¹é¢ï¼ŒLLMsçš„è¡¨ç°ç›®å‰ä»ä¸åŠç°æœ‰çš„ç¼–è¯‘å™¨å·¥å…·ã€‚è¿™ä¸€å±€é™æ€§ä¸»è¦æºäºLLMsåœ¨æ·±å…¥ç†è§£RTLä»£ç ä¸­çš„æ—¶åºé€»è¾‘(Timing Logic)æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶ä¸ä»…æ­ç¤ºäº†LLMsåœ¨ç”µè·¯è®¾è®¡è‡ªåŠ¨åŒ–é¢†åŸŸçš„æ½œåŠ›ä¸çŸ­æ¿ï¼Œä¹Ÿä¸ºæœªæ¥æ”¹è¿›åŸºäºLLMsçš„RTLä»£ç ä¼˜åŒ–ç ”ç©¶æä¾›äº†æ–¹å‘æ€§è§è§£ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "13pages with 9 pictures and 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16808v1",
      "published_date": "2025-07-22 17:57:02 UTC",
      "updated_date": "2025-07-22 17:57:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:13.991445+00:00"
    },
    {
      "arxiv_id": "2507.16806v1",
      "title": "Beyond Binary Rewards: Training LMs to Reason About Their Uncertainty",
      "title_zh": "è¶…è¶ŠäºŒå…ƒå¥–åŠ±ï¼šè®­ç»ƒè¯­è¨€æ¨¡å‹æ¨ç†è‡ªèº«çš„ä¸ç¡®å®šæ€§",
      "authors": [
        "Mehul Damani",
        "Isha Puri",
        "Stewart Slocum",
        "Idan Shenfeld",
        "Leshem Choshen",
        "Yoon Kim",
        "Jacob Andreas"
      ],
      "abstract": "When language models (LMs) are trained via reinforcement learning (RL) to generate natural language \"reasoning chains\", their performance improves on a variety of difficult question answering tasks. Today, almost all successful applications of RL for reasoning use binary reward functions that evaluate the correctness of LM outputs. Because such reward functions do not penalize guessing or low-confidence outputs, they often have the unintended side-effect of degrading calibration and increasing the rate at which LMs generate incorrect responses (or \"hallucinate\") in other problem domains. This paper describes RLCR (Reinforcement Learning with Calibration Rewards), an approach to training reasoning models that jointly improves accuracy and calibrated confidence estimation. During RLCR, LMs generate both predictions and numerical confidence estimates after reasoning. They are trained to optimize a reward function that augments a binary correctness score with a Brier score -- a scoring rule for confidence estimates that incentivizes calibrated prediction. We first prove that this reward function (or any analogous reward function that uses a bounded, proper scoring rule) yields models whose predictions are both accurate and well-calibrated. We next show that across diverse datasets, RLCR substantially improves calibration with no loss in accuracy, on both in-domain and out-of-domain evaluations -- outperforming both ordinary RL training and classifiers trained to assign post-hoc confidence scores. While ordinary RL hurts calibration, RLCR improves it. Finally, we demonstrate that verbalized confidence can be leveraged at test time to improve accuracy and calibration via confidence-weighted scaling methods. Our results show that explicitly optimizing for calibration can produce more generally reliable reasoning models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (RL)ä¸­äºŒå…ƒå¥–åŠ±(Binary Rewards)å¯¼è‡´å¤§è¯­è¨€æ¨¡å‹(LMs)äº§ç”Ÿå¹»è§‰å’Œæ ¡å‡†æ€§ä¸‹é™çš„é—®é¢˜ï¼Œæå‡ºäº†RLCR (Reinforcement Learning with Calibration Rewards)è®­ç»ƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•è¦æ±‚æ¨¡å‹åœ¨ç”Ÿæˆæ¨ç†é“¾åè¾“å‡ºæ•°å€¼ç½®ä¿¡åº¦ï¼Œå¹¶é€šè¿‡ç»“åˆäºŒå…ƒæ­£ç¡®æ€§å¾—åˆ†ä¸Brier scoreçš„å¥–åŠ±å‡½æ•°è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œæ¿€åŠ±æ¨¡å‹è¿›è¡Œå‡†ç¡®ä¸”ç»è¿‡æ ¡å‡†çš„é¢„æµ‹ã€‚ç†è®ºè¯æ˜åŠå¤šé¡¹å®éªŒè¡¨æ˜ï¼ŒRLCRåœ¨ä¸æŸå¤±å‡†ç¡®ç‡çš„å‰æä¸‹æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨åŸŸå†…å’Œè·¨åŸŸè¯„ä¼°ä¸­çš„æ ¡å‡†æ€§èƒ½ï¼Œä¼˜äºæ™®é€šçš„å¼ºåŒ–å­¦ä¹ å’Œäº‹åç½®ä¿¡åº¦è¯„åˆ†æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å±•ç¤ºäº†åœ¨æµ‹è¯•é˜¶æ®µåˆ©ç”¨æ¨¡å‹è¡¨è¾¾çš„ç½®ä¿¡åº¦è¿›è¡ŒåŠ æƒç¼©æ”¾ï¼Œèƒ½è¿›ä¸€æ­¥æé«˜æ¨ç†ä»»åŠ¡çš„å¯é æ€§ã€‚é€šè¿‡æ˜¾å¼ä¼˜åŒ–æ ¡å‡†æ€§ï¼ŒRLCRæˆåŠŸæ„å»ºäº†æ›´å…·å¯ä¿¡åº¦çš„é€šç”¨æ¨ç†æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16806v1",
      "published_date": "2025-07-22 17:56:01 UTC",
      "updated_date": "2025-07-22 17:56:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:40.918765+00:00"
    },
    {
      "arxiv_id": "2507.16801v1",
      "title": "Decoding Translation-Related Functional Sequences in 5'UTRs Using Interpretable Deep Learning Models",
      "title_zh": "åˆ©ç”¨å¯è§£é‡Šæ·±åº¦å­¦ä¹ æ¨¡å‹è§£ç  5'UTR ä¸­çš„ç¿»è¯‘ç›¸å…³åŠŸèƒ½åºåˆ—",
      "authors": [
        "Yuxi Lin",
        "Yaxue Fang",
        "Zehong Zhang",
        "Zhouwu Liu",
        "Siyun Zhong",
        "Fulong Yu"
      ],
      "abstract": "Understanding how 5' untranslated regions (5'UTRs) regulate mRNA translation is critical for controlling protein expression and designing effective therapeutic mRNAs. While recent deep learning models have shown promise in predicting translational efficiency from 5'UTR sequences, most are constrained by fixed input lengths and limited interpretability. We introduce UTR-STCNet, a Transformer-based architecture for flexible and biologically grounded modeling of variable-length 5'UTRs. UTR-STCNet integrates a Saliency-Aware Token Clustering (SATC) module that iteratively aggregates nucleotide tokens into multi-scale, semantically meaningful units based on saliency scores. A Saliency-Guided Transformer (SGT) block then captures both local and distal regulatory dependencies using a lightweight attention mechanism. This combined architecture achieves efficient and interpretable modeling without input truncation or increased computational cost. Evaluated across three benchmark datasets, UTR-STCNet consistently outperforms state-of-the-art baselines in predicting mean ribosome load (MRL), a key proxy for translational efficiency. Moreover, the model recovers known functional elements such as upstream AUGs and Kozak motifs, highlighting its potential for mechanistic insight into translation regulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† 5' untranslated regions (5'UTRs) å¦‚ä½•è°ƒèŠ‚ mRNA ç¿»è¯‘ï¼Œè¿™å¯¹äºæ§åˆ¶è›‹ç™½è´¨è¡¨è¾¾å’Œè®¾è®¡æœ‰æ•ˆçš„æ²»ç–—æ€§ mRNAs è‡³å…³é‡è¦ã€‚ä¸ºäº†è§£å†³ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤„ç†å˜é•¿åºåˆ—å’Œç¼ºä¹å¯è§£é‡Šæ€§æ–¹é¢çš„å±€é™ï¼Œç ”ç©¶è€…æå‡ºäº† UTR-STCNetï¼Œä¸€ç§åŸºäº Transformer çš„æŸ”æ€§å»ºæ¨¡æ¶æ„ã€‚è¯¥æ¨¡å‹é›†æˆäº†ä¸€ä¸ª Saliency-Aware Token Clustering (SATC) æ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®æ˜¾è‘—æ€§å¾—åˆ†å°†æ ¸è‹·é…¸ä»¤ç‰Œè¿­ä»£èšåˆä¸ºå¤šå°ºåº¦ä¸”å…·æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„å•å…ƒã€‚é€šè¿‡ Saliency-Guided Transformer (SGT) æ¨¡å—ï¼ŒUTR-STCNet åˆ©ç”¨è½»é‡çº§æ³¨æ„åŠ›æœºåˆ¶åŒæ—¶æ•æ‰å±€éƒ¨å’Œè¿œç«¯çš„è°ƒèŠ‚ä¾èµ–å…³ç³»ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨é¢„æµ‹ Mean Ribosome Load (MRL) è¿™ä¸€å…³é”®ç¿»è¯‘æ•ˆç‡æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒUTR-STCNet æˆåŠŸè¯†åˆ«å‡º upstream AUGs å’Œ Kozak motifs ç­‰å·²çŸ¥åŠŸèƒ½å…ƒä»¶ï¼Œè¯æ˜äº†å…¶åœ¨æ­ç¤ºç¿»è¯‘è°ƒèŠ‚æœºåˆ¶æ–¹é¢çš„å¼ºå¤§æ½œåŠ›ã€‚è¯¥ç ”ç©¶ä¸ºå®ç°é«˜æ•ˆã€å‡†ç¡®ä¸”å…·æœ‰ç”Ÿç‰©å­¦è§£é‡ŠåŠ›çš„ mRNA åºåˆ—å»ºæ¨¡æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16801v1",
      "published_date": "2025-07-22 17:51:13 UTC",
      "updated_date": "2025-07-22 17:51:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:50.287658+00:00"
    },
    {
      "arxiv_id": "2507.16796v1",
      "title": "Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning",
      "title_zh": "ç”¨äºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç‚¹å¯¹ç‚¹èƒ½æºäº¤æ˜“çš„ä¸ç¡®å®šæ€§æ„ŸçŸ¥çŸ¥è¯† Transformer",
      "authors": [
        "Mian Ibad Ali Shah",
        "Enda Barrett",
        "Karl Mason"
      ],
      "abstract": "This paper presents a novel framework for Peer-to-Peer (P2P) energy trading that integrates uncertainty-aware prediction with multi-agent reinforcement learning (MARL), addressing a critical gap in current literature. In contrast to previous works relying on deterministic forecasts, the proposed approach employs a heteroscedastic probabilistic transformer-based prediction model called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify prediction uncertainty, which is essential for robust decision-making in the stochastic environment of P2P energy trading. The KTU model leverages domain-specific features and is trained with a custom loss function that ensures reliable probabilistic forecasts and confidence intervals for each prediction. Integrating these uncertainty-aware forecasts into the MARL framework enables agents to optimize trading strategies with a clear understanding of risk and variability. Experimental results show that the uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to 5.7% without P2P trading and 3.2% with P2P trading, while increasing electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These improvements are even more pronounced when P2P trading is enabled, highlighting the synergy between advanced forecasting and market mechanisms for resilient, economically efficient energy communities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹çš„ç‚¹å¯¹ç‚¹(Peer-to-Peer, P2P)èƒ½æºäº¤æ˜“æ¡†æ¶ï¼Œå°†ä¸ç¡®å®šæ€§æ„ŸçŸ¥é¢„æµ‹ä¸å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (Multi-Agent Reinforcement Learning, MARL)ç›¸ç»“åˆï¼Œå¡«è¡¥äº†ç°æœ‰æ–‡çŒ®åœ¨å¤„ç†éšæœºç¯å¢ƒå†³ç­–æ—¶çš„ç©ºç™½ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åä¸ºKnowledge Transformer with Uncertainty (KTU)çš„å¼‚æ–¹å·®æ¦‚ç‡Transformeré¢„æµ‹æ¨¡å‹ï¼Œé€šè¿‡é¢†åŸŸç‰¹å®šç‰¹å¾å’Œè‡ªå®šä¹‰æŸå¤±å‡½æ•°æ˜¾å¼é‡åŒ–é¢„æµ‹ä¸ç¡®å®šæ€§ï¼Œå¹¶ä¸ºå†³ç­–æä¾›å¯é çš„ç½®ä¿¡åŒºé—´ã€‚é€šè¿‡å°†è¿™äº›é¢„æµ‹é›†æˆè‡³MARLæ¡†æ¶ï¼Œæ™ºèƒ½ä½“èƒ½å¤Ÿå……åˆ†ç†è§£é£é™©ä¸å˜å¼‚æ€§ï¼Œä»è€Œä¼˜åŒ–å…¶äº¤æ˜“ç­–ç•¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„Deep Q-Network (DQN)åœ¨P2Pç¯å¢ƒä¸‹å¯å°†å”®ç”µæ”¶å…¥æå‡44.7%ï¼Œå¹¶å°†é«˜å³°æ—¶æ®µçš„ç”µç½‘éœ€æ±‚é™ä½45.6%ã€‚è¿™äº›æ”¹è¿›åœ¨å¯ç”¨P2Päº¤æ˜“æ—¶å°¤ä¸ºæ˜¾è‘—ï¼Œå……åˆ†å±•ç¤ºäº†å…ˆè¿›é¢„æµ‹æ¨¡å‹ä¸å¸‚åœºæœºåˆ¶åœ¨æ„å»ºç»æµé«˜æ•ˆä¸”å…·éŸ§æ€§çš„èƒ½æºç¤¾åŒºæ–¹é¢çš„ååŒæ•ˆåº”ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 4 figures, 1 table, Proceedings of the Main Track of the European Conference on Artificial Intelligence (ECAI 2025), October 25-30, 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16796v1",
      "published_date": "2025-07-22 17:46:28 UTC",
      "updated_date": "2025-07-22 17:46:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:47.596488+00:00"
    },
    {
      "arxiv_id": "2507.16795v2",
      "title": "Steering Out-of-Distribution Generalization with Concept Ablation Fine-Tuning",
      "title_zh": "é€šè¿‡æ¦‚å¿µæ¶ˆèå¾®è°ƒå¼•å¯¼åˆ†å¸ƒå¤–æ³›åŒ–",
      "authors": [
        "Helena Casademunt",
        "Caden Juang",
        "Adam Karvonen",
        "Samuel Marks",
        "Senthooran Rajamanoharan",
        "Neel Nanda"
      ],
      "abstract": "Fine-tuning large language models (LLMs) can lead to unintended out-of-distribution generalization. Standard approaches to this problem rely on modifying training data, for example by adding data that better specify the intended generalization. However, this is not always practical. We introduce Concept Ablation Fine-Tuning (CAFT), a technique that leverages interpretability tools to control how LLMs generalize from fine-tuning, without needing to modify the training data or otherwise use data from the target distribution. Given a set of directions in an LLM's latent space corresponding to undesired concepts, CAFT works by ablating these concepts with linear projections during fine-tuning, steering the model away from unintended generalizations. We successfully apply CAFT to three fine-tuning tasks, including emergent misalignment, a phenomenon where LLMs fine-tuned on a narrow task generalize to give egregiously misaligned responses to general questions. Without any changes to the fine-tuning data, CAFT reduces misaligned responses by 10x without degrading performance on the training distribution. Overall, CAFT represents a novel approach for steering LLM generalization without modifying training data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­å¯èƒ½äº§ç”Ÿçš„éé¢„æœŸåˆ†å¸ƒå¤–æ³›åŒ– (out-of-distribution generalization) é—®é¢˜ï¼Œæå‡ºäº†æ¦‚å¿µæ¶ˆèå¾®è°ƒ (Concept Ablation Fine-Tuning, CAFT) æŠ€æœ¯ã€‚CAFT åˆ©ç”¨å¯è§£é‡Šæ€§å·¥å…·åœ¨æ¨¡å‹çš„æ½œåœ¨ç©ºé—´ (latent space) ä¸­è¯†åˆ«ä¸ä¸ç†æƒ³æ¦‚å¿µç›¸å…³çš„æ–¹å‘ï¼Œå¹¶åœ¨å¾®è°ƒæœŸé—´é€šè¿‡çº¿æ€§æŠ•å½± (linear projections) æ¶ˆèè¿™äº›æ¦‚å¿µï¼Œä»è€Œåœ¨ä¸ä¿®æ”¹è®­ç»ƒæ•°æ®æˆ–ä½¿ç”¨ç›®æ ‡åˆ†å¸ƒæ•°æ®çš„å‰æä¸‹æ§åˆ¶æ¨¡å‹çš„æ³›åŒ–æ–¹å‘ã€‚ç ”ç©¶æˆåŠŸå°† CAFT åº”ç”¨äºåŒ…æ‹¬â€œæ¶Œç°å¤±é…â€ (emergent misalignment) åœ¨å†…çš„ä¸‰ç§å¾®è°ƒä»»åŠ¡ï¼Œå®éªŒç»“æœæ˜¾ç¤ºè¯¥æŠ€æœ¯åœ¨ä¸æŸå®³åŸå§‹è®­ç»ƒåˆ†å¸ƒæ€§èƒ½çš„æƒ…å†µä¸‹ï¼Œå°†å¤±é…å“åº”å‡å°‘äº† 10 å€ã€‚æ€»ä½“è€Œè¨€ï¼ŒCAFT ä¸ºå¼•å¯¼ LLM æ³›åŒ–æä¾›äº†ä¸€ç§æ— éœ€ä¾èµ–æ•°æ®å¢å¼ºçš„æ–°å‹è·¯å¾„ï¼Œå…·æœ‰æ˜¾è‘—çš„ç§‘ç ”ä¸åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16795v2",
      "published_date": "2025-07-22 17:45:04 UTC",
      "updated_date": "2025-11-09 22:39:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:10:52.782806+00:00"
    },
    {
      "arxiv_id": "2507.16792v1",
      "title": "ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation",
      "title_zh": "ChatCheckerï¼šåŸºäºéåˆä½œå¼ç”¨æˆ·æ¨¡æ‹Ÿçš„å¯¹è¯ç³»ç»Ÿæµ‹è¯•ä¸è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Roman Mayr",
        "Michel Schimpf",
        "Thomas BohnÃ©"
      ],
      "abstract": "While modern dialogue systems heavily rely on large language models (LLMs), their implementation often goes beyond pure LLM interaction. Developers integrate multiple LLMs, external tools, and databases. Therefore, assessment of the underlying LLM alone does not suffice, and the dialogue systems must be tested and evaluated as a whole. However, this remains a major challenge. With most previous work focusing on turn-level analysis, less attention has been paid to integrated dialogue-level quality assurance. To address this, we present ChatChecker, a framework for automated evaluation and testing of complex dialogue systems. ChatChecker uses LLMs to simulate diverse user interactions, identify dialogue breakdowns, and evaluate quality. Compared to previous approaches, our design reduces setup effort and is generalizable, as it does not require reference dialogues and is decoupled from the implementation of the target dialogue system. We improve breakdown detection performance over a prior LLM-based approach by including an error taxonomy in the prompt. Additionally, we propose a novel non-cooperative user simulator based on challenging personas that uncovers weaknesses in target dialogue systems more effectively. Through this, ChatChecker contributes to thorough and scalable testing. This enables both researchers and practitioners to accelerate the development of robust dialogue systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ChatCheckerï¼Œä¸€ä¸ªä¸“é—¨ç”¨äºå¤æ‚å¯¹è¯ç³»ç»Ÿï¼ˆDialogue Systemsï¼‰è‡ªåŠ¨åŒ–æµ‹è¯•ä¸è¯„ä¼°çš„æ¡†æ¶ï¼Œä»¥åº”å¯¹é›†æˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€å·¥å…·å’Œæ•°æ®åº“åçš„ç³»ç»Ÿçº§è´¨é‡ä¿éšœæŒ‘æˆ˜ã€‚ChatChecker åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿç”¨æˆ·äº¤äº’å¹¶è¯†åˆ«å¯¹è¯ä¸­æ–­ï¼ˆDialogue Breakdownsï¼‰ï¼Œå…¶ä¼˜åŠ¿åœ¨äºæ— éœ€å‚è€ƒå¯¹è¯ï¼ˆReference Dialoguesï¼‰ä¸”ä¸ç›®æ ‡ç³»ç»Ÿçš„å…·ä½“å®ç°å®Œå…¨è§£è€¦ã€‚é€šè¿‡åœ¨æç¤ºè¯ä¸­å¼•å…¥é”™è¯¯åˆ†ç±»æ³•ï¼ˆError Taxonomyï¼‰ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆæå‡äº†å¯¹è¯å±‚é¢çš„æ•…éšœæ£€æµ‹æ€§èƒ½ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†åŸºäºæŒ‘æˆ˜æ€§äººæ ¼ï¼ˆChallenging Personasï¼‰çš„éåˆä½œç”¨æˆ·æ¨¡æ‹Ÿå™¨ï¼ˆNon-cooperative User Simulatorï¼‰ï¼Œç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•èƒ½æ›´é«˜æ•ˆåœ°æŒ–æ˜ç³»ç»Ÿå¼±ç‚¹ã€‚ChatChecker å®ç°äº†å½»åº•ä¸”å¯æ‰©å±•çš„æµ‹è¯•æµç¨‹ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…åŠ é€Ÿæ„å»ºé²æ£’çš„å¯¹è¯ç³»ç»Ÿæä¾›äº†æœ‰åŠ›å·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16792v1",
      "published_date": "2025-07-22 17:40:34 UTC",
      "updated_date": "2025-07-22 17:40:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:01.489242+00:00"
    },
    {
      "arxiv_id": "2507.16768v1",
      "title": "WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding",
      "title_zh": "WGRAMMARï¼šåˆ©ç”¨å…ˆéªŒçŸ¥è¯†åŠ é€Ÿç»“æ„åŒ–è§£ç ",
      "authors": [
        "Ran Wang",
        "Xiaoxuan Liu",
        "Hao Ren",
        "Gang Chen",
        "Fanchao Qi",
        "Maosong Sun"
      ],
      "abstract": "Structured decoding enables large language models (LLMs) to generate outputs in formats required by downstream systems, such as HTML or JSON. However, existing methods suffer from efficiency bottlenecks due to grammar compilation, state tracking, and mask creation. We observe that many real-world tasks embed strong prior knowledge about output structure. Leveraging this, we propose a decomposition of constraints into static and dynamic components -- precompiling static structures offline and instantiating dynamic arguments at runtime using grammar snippets. Instead of relying on pushdown automata, we employ a compositional set of operators to model regular formats, achieving lower transition latency. We introduce wgrammar, a lightweight decoding engine that integrates domain-aware simplification, constraint decomposition, and mask caching, achieving up to 250x speedup over existing systems. wgrammar's source code is publicly available at https://github.com/wrran/wgrammar.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† wgrammarï¼Œä¸€ç§è½»é‡çº§çš„ç»“æ„åŒ–è§£ç  (Structured decoding) å¼•æ“ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨ç”Ÿæˆ HTML æˆ– JSON ç­‰ç‰¹å®šæ ¼å¼æ—¶é¢ä¸´çš„æ•ˆç‡ç“¶é¢ˆã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨è¯­æ³•ç¼–è¯‘ã€çŠ¶æ€è·Ÿè¸ªå’Œæ©ç åˆ›å»ºä¸Šçš„æ€§èƒ½é™åˆ¶ï¼Œwgrammar åˆ›æ–°æ€§åœ°å°†çº¦æŸåˆ†è§£ä¸ºç¦»çº¿é¢„ç¼–è¯‘çš„é™æ€ç»„ä»¶å’Œè¿è¡Œæ—¶å®ä¾‹åŒ–çš„åŠ¨æ€å‚æ•°ã€‚è¯¥å¼•æ“æ‘’å¼ƒäº†ä¼ ç»Ÿçš„ä¸‹æ¨è‡ªåŠ¨æœº (Pushdown automata)ï¼Œè½¬è€Œé‡‡ç”¨ä¸€ç»„ç»„åˆç®—å­ (Compositional set of operators) æ¥å»ºæ¨¡æ­£åˆ™æ ¼å¼ï¼Œä»è€Œæ˜¾è‘—é™ä½äº†è½¬æ¢å»¶è¿Ÿã€‚é€šè¿‡é›†æˆé¢†åŸŸæ„ŸçŸ¥ç®€åŒ–ã€çº¦æŸåˆ†è§£å’Œæ©ç ç¼“å­˜ (Mask caching) æŠ€æœ¯ï¼Œwgrammar ç›¸æ¯”ç°æœ‰ç³»ç»Ÿå®ç°äº†é«˜è¾¾ 250 å€çš„åŠ é€Ÿã€‚è¿™é¡¹å·¥ä½œä¸ºé«˜æ•ˆçš„ç»“æ„åŒ–è¾“å‡ºæä¾›äº†æ–°æ–¹æ¡ˆï¼Œä¸”ç›¸å…³ä»£ç å·²åœ¨ GitHub å¼€æºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16768v1",
      "published_date": "2025-07-22 17:13:47 UTC",
      "updated_date": "2025-07-22 17:13:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:02.586926+00:00"
    },
    {
      "arxiv_id": "2507.17845v1",
      "title": "Towards Robust Foundation Models for Digital Pathology",
      "title_zh": "è¿ˆå‘æ•°å­—ç—…ç†å­¦çš„é²æ£’åŸºç¡€æ¨¡å‹",
      "authors": [
        "Jonah KÃ¶men",
        "Edwin D. de Jong",
        "Julius Hense",
        "Hannah Marienwald",
        "Jonas Dippel",
        "Philip Naumann",
        "Eric Marcus",
        "Lukas Ruff",
        "Maximilian Alber",
        "Jonas Teuwen",
        "Frederick Klauschen",
        "Klaus-Robert MÃ¼ller"
      ],
      "abstract": "Biomedical Foundation Models (FMs) are rapidly transforming AI-enabled healthcare research and entering clinical validation. However, their susceptibility to learning non-biological technical features -- including variations in surgical/endoscopic techniques, laboratory procedures, and scanner hardware -- poses risks for clinical deployment. We present the first systematic investigation of pathology FM robustness to non-biological features. Our work (i) introduces measures to quantify FM robustness, (ii) demonstrates the consequences of limited robustness, and (iii) proposes a framework for FM robustification to mitigate these issues. Specifically, we developed PathoROB, a robustness benchmark with three novel metrics, including the robustness index, and four datasets covering 28 biological classes from 34 medical centers. Our experiments reveal robustness deficits across all 20 evaluated FMs, and substantial robustness differences between them. We found that non-robust FM representations can cause major diagnostic downstream errors and clinical blunders that prevent safe clinical adoption. Using more robust FMs and post-hoc robustification considerably reduced (but did not yet eliminate) the risk of such errors. This work establishes that robustness evaluation is essential for validating pathology FMs before clinical adoption and demonstrates that future FM development must integrate robustness as a core design principle. PathoROB provides a blueprint for assessing robustness across biomedical domains, guiding FM improvement efforts towards more robust, representative, and clinically deployable AI systems that prioritize biological information over technical artifacts.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ•°å­—ç—…ç†å­¦é¢†åŸŸä¸­ç”Ÿç‰©åŒ»å­¦åŸºç¡€æ¨¡å‹(Foundation Models, FMs)å®¹æ˜“å—éç”Ÿç‰©æŠ€æœ¯ç‰¹å¾å½±å“è€Œå¯¼è‡´ä¸´åºŠéƒ¨ç½²é£é™©çš„é—®é¢˜è¿›è¡Œäº†ç³»ç»Ÿè°ƒæŸ¥ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†é¦–ä¸ªç—…ç†å­¦åŸºç¡€æ¨¡å‹é²æ£’æ€§åŸºå‡†PathoROBï¼ŒåŒ…å«ä¸‰ä¸ªåˆ›æ–°æ€§è¯„ä¼°æŒ‡æ ‡ä»¥åŠæ¶µç›–28ä¸ªç”Ÿç‰©ç±»åˆ«å’Œ34ä¸ªåŒ»ç–—ä¸­å¿ƒçš„æ•°æ®é›†ã€‚é€šè¿‡å¯¹20ä¸ªä¸»æµåŸºç¡€æ¨¡å‹çš„è¯„ä¼°ï¼Œç ”ç©¶å‘ç°æ‰€æœ‰æ¨¡å‹å‡å­˜åœ¨é²æ£’æ€§ç¼ºé™·ï¼Œä¸”è¿™äº›ç¼ºé™·ä¼šå¯¼è‡´ä¸¥é‡çš„ä¸‹æ¸¸è¯Šæ–­é”™è¯¯å’Œä¸´åºŠå¤±è¯¯ã€‚å®éªŒè¯æ˜ï¼Œä½¿ç”¨æ›´å…·é²æ£’æ€§çš„åŸºç¡€æ¨¡å‹å¹¶ç»“åˆäº‹åé²æ£’åŒ–(post-hoc robustification)å¤„ç†ï¼Œèƒ½æ˜¾è‘—é™ä½æ­¤ç±»é”™è¯¯é£é™©ã€‚è¯¥å·¥ä½œç¡®ç«‹äº†é²æ£’æ€§è¯„ä¼°åœ¨ç—…ç†å­¦åŸºç¡€æ¨¡å‹ä¸´åºŠåº”ç”¨å‰çš„å¿…è¦æ€§ï¼Œå¹¶ä¸ºå¼€å‘æ›´å…·ä»£è¡¨æ€§ä¸”å®‰å…¨çš„åŒ»ç–—AIç³»ç»Ÿæä¾›äº†è¯„ä¼°è“å›¾å’Œè®¾è®¡å‡†åˆ™ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17845v1",
      "published_date": "2025-07-22 16:51:53 UTC",
      "updated_date": "2025-07-22 16:51:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:02.739690+00:00"
    },
    {
      "arxiv_id": "2507.16754v1",
      "title": "Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support",
      "title_zh": "æ°¸ä¸ç©ºå›ï¼šæå‡ LLM å¼€å‘è€…æ”¯æŒçš„è‡ªé€‚åº” HyDE æ£€ç´¢",
      "authors": [
        "Fangjian Lei",
        "Mariam El Mezouar",
        "Shayan Noei",
        "Ying Zou"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in assisting developers with code-related questions; however, LLMs carry the risk of generating unreliable answers. To address this, Retrieval-Augmented Generation (RAG) has been proposed to reduce the unreliability (i.e., hallucinations) of LLMs. However, designing effective pipelines remains challenging due to numerous design choices. In this paper, we construct a retrieval corpus of over 3 million Java and Python related Stack Overflow posts with accepted answers, and explore various RAG pipeline designs to answer developer questions, evaluating their effectiveness in generating accurate and reliable responses. More specifically, we (1) design and evaluate 7 different RAG pipelines and 63 pipeline variants to answer questions that have historically similar matches, and (2) address new questions without any close prior matches by automatically lowering the similarity threshold during retrieval, thereby increasing the chance of finding partially relevant context and improving coverage for unseen cases. We find that implementing a RAG pipeline combining hypothetical-documentation-embedding (HyDE) with the full-answer context performs best in retrieving and answering similarcontent for Stack Overflow questions. Finally, we apply our optimal RAG pipeline to 4 open-source LLMs and compare the results to their zero-shot performance. Our findings show that RAG with our optimal RAG pipeline consistently outperforms zero-shot baselines across models, achieving higher scores for helpfulness, correctness, and detail with LLM-as-a-judge. These findings demonstrate that our optimal RAG pipelines robustly enhance answer quality for a wide range of developer queries including both previously seen and novel questions across different LLMs",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)æŠ€æœ¯æ¥å‡å°‘å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¼€å‘è€…æ”¯æŒä¸­äº§ç”Ÿçš„å¹»è§‰é—®é¢˜ã€‚ç ”ç©¶äººå‘˜æ„å»ºäº†ä¸€ä¸ªåŒ…å«è¶…è¿‡300ä¸‡æ¡Stack Overflowå¸–å­çš„æ£€ç´¢è¯­æ–™åº“ï¼Œå¹¶ç³»ç»Ÿè¯„ä¼°äº†7ç§ä¸åŒçš„RAGæµæ°´çº¿åŠå…¶63ä¸ªå˜ä½“ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ç§è‡ªé€‚åº”æ£€ç´¢æœºåˆ¶ï¼Œé€šè¿‡åœ¨å¤„ç†æ–°é—®é¢˜æ—¶è‡ªåŠ¨é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œæ˜¾è‘—æå‡äº†é’ˆå¯¹æœªçŸ¥é—®é¢˜çš„æ£€ç´¢è¦†ç›–ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œç»“åˆå‡è®¾æ€§æ–‡æ¡£åµŒå…¥(HyDE)ä¸å…¨ç­”æ¡ˆä¸Šä¸‹æ–‡(full-answer context)çš„RAGæµæ°´çº¿åœ¨æ£€ç´¢å’Œå›ç­”ç›¸ä¼¼å†…å®¹æ—¶è¡¨ç°æœ€ä½³ã€‚é€šè¿‡åœ¨4ä¸ªå¼€æºLLMsä¸Šçš„è¯„ä¼°è¯å®ï¼Œè¯¥ä¼˜åŒ–åçš„RAGæµæ°´çº¿åœ¨å¸®åŠ©æ€§ã€æ­£ç¡®æ€§å’Œè¯¦ç»†ç¨‹åº¦æ–¹é¢å‡æ˜¾è‘—ä¼˜äºé›¶æ ·æœ¬(zero-shot)åŸºå‡†ã€‚è¯¥ç ”ç©¶ä¸ºæå‡LLMsåœ¨å¤„ç†å„ç±»å¼€å‘è€…æŸ¥è¯¢æ—¶çš„å›ç­”è´¨é‡æä¾›äº†å¯é çš„å®è·µæŒ‡å—ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16754v1",
      "published_date": "2025-07-22 16:46:00 UTC",
      "updated_date": "2025-07-22 16:46:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:20.992366+00:00"
    },
    {
      "arxiv_id": "2507.16884v1",
      "title": "SplitMeanFlow: Interval Splitting Consistency in Few-Step Generative Modeling",
      "title_zh": "SplitMeanFlowï¼šå°‘æ­¥ç”Ÿæˆå»ºæ¨¡ä¸­çš„åŒºé—´æ‹†åˆ†ä¸€è‡´æ€§",
      "authors": [
        "Yi Guo",
        "Wei Wang",
        "Zhihang Yuan",
        "Rong Cao",
        "Kuan Chen",
        "Zhengyang Chen",
        "Yuanyuan Huo",
        "Yang Zhang",
        "Yuping Wang",
        "Shouda Liu",
        "Yuxuan Wang"
      ],
      "abstract": "Generative models like Flow Matching have achieved state-of-the-art performance but are often hindered by a computationally expensive iterative sampling process. To address this, recent work has focused on few-step or one-step generation by learning the average velocity field, which directly maps noise to data. MeanFlow, a leading method in this area, learns this field by enforcing a differential identity that connects the average and instantaneous velocities. In this work, we argue that this differential formulation is a limiting special case of a more fundamental principle. We return to the first principles of average velocity and leverage the additivity property of definite integrals. This leads us to derive a novel, purely algebraic identity we term Interval Splitting Consistency. This identity establishes a self-referential relationship for the average velocity field across different time intervals without resorting to any differential operators. Based on this principle, we introduce SplitMeanFlow, a new training framework that enforces this algebraic consistency directly as a learning objective. We formally prove that the differential identity at the core of MeanFlow is recovered by taking the limit of our algebraic consistency as the interval split becomes infinitesimal. This establishes SplitMeanFlow as a direct and more general foundation for learning average velocity fields. From a practical standpoint, our algebraic approach is significantly more efficient, as it eliminates the need for JVP computations, resulting in simpler implementation, more stable training, and broader hardware compatibility. One-step and two-step SplitMeanFlow models have been successfully deployed in large-scale speech synthesis products (such as Doubao), achieving speedups of 20x.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Flow Matching ç­‰ç”Ÿæˆæ¨¡å‹åœ¨è¿­ä»£é‡‡æ ·è¿‡ç¨‹ä¸­è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº† SplitMeanFlow è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„å°‘æ­¥ï¼ˆfew-stepï¼‰æˆ–å•æ­¥ç”Ÿæˆã€‚è¯¥æ¡†æ¶å›å½’å¹³å‡é€Ÿåº¦åœºï¼ˆaverage velocity fieldï¼‰çš„åŸºæœ¬åŸç†ï¼Œåˆ©ç”¨å®šç§¯åˆ†çš„å¯åŠ æ€§æ¨å¯¼å‡ºä¸€ç§å…¨æ–°çš„çº¯ä»£æ•°æ’ç­‰å¼ï¼Œå³ Interval Splitting Consistencyï¼Œå»ºç«‹äº†ä¸åŒæ—¶é—´é—´éš”å†…å¹³å‡é€Ÿåº¦åœºçš„è‡ªå‚è€ƒå…³ç³»ã€‚ä¸ MeanFlow ä¾èµ–å¾®åˆ†ç®—å­ä¸åŒï¼ŒSplitMeanFlow é€šè¿‡å¼ºåˆ¶æ‰§è¡Œè¿™ç§ä»£æ•°ä¸€è‡´æ€§ï¼Œæ¶ˆé™¤äº†å¯¹ JVP è®¡ç®—çš„éœ€æ±‚ï¼Œä»è€Œç®€åŒ–äº†å®ç°è¿‡ç¨‹å¹¶å¢å¼ºäº†è®­ç»ƒç¨³å®šæ€§å’Œç¡¬ä»¶å…¼å®¹æ€§ã€‚ç†è®ºè¯æ˜æ˜¾ç¤º MeanFlow çš„æ ¸å¿ƒå¾®åˆ†æ’ç­‰å¼ä»…æ˜¯è¯¥ä»£æ•°ä¸€è‡´æ€§åœ¨åŒºé—´åˆ†å‰²è¶‹äºæ— ç©·å°æ—¶çš„ç‰¹ä¾‹ï¼Œç¡®ç«‹äº† SplitMeanFlow æ›´å…·æ™®éæ€§çš„ç†è®ºåŸºç¡€ã€‚ç›®å‰ï¼Œè¯¥æ¨¡å‹å·²æˆåŠŸåº”ç”¨äºè±†åŒ…ç­‰å¤§è§„æ¨¡è¯­éŸ³åˆæˆäº§å“ä¸­ï¼Œåœ¨å•æ­¥å’Œä¸¤æ­¥ç”Ÿæˆä»»åŠ¡ä¸Šå®ç°äº† 20 å€çš„åŠ é€Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Tech Report",
      "pdf_url": "https://arxiv.org/pdf/2507.16884v1",
      "published_date": "2025-07-22 16:26:58 UTC",
      "updated_date": "2025-07-22 16:26:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:28.088851+00:00"
    },
    {
      "arxiv_id": "2507.16735v1",
      "title": "AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy",
      "title_zh": "AIå¢å¼ºçš„å¯¹è¯æ™ºèƒ½ä½“åœ¨ä¸ªæ€§åŒ–å“®å–˜æ”¯æŒä¸­çš„åº”ç”¨ï¼šå‚ä¸åº¦ã€ä»·å€¼ä¸æ•ˆåŠ›çš„å½±å“å› ç´ ",
      "authors": [
        "Laura Moradbakhti",
        "Dorian Peters",
        "Jennifer K. Quint",
        "BjÃ¶rn Schuller",
        "Darren Cook",
        "Rafael A. Calvo"
      ],
      "abstract": "Asthma-related deaths in the UK are the highest in Europe, and only 30% of patients access basic care. There is a need for alternative approaches to reaching people with asthma in order to provide health education, self-management support and bridges to care. Automated conversational agents (specifically, mobile chatbots) present opportunities for providing alternative and individually tailored access to health education, self-management support and risk self-assessment. But would patients engage with a chatbot, and what factors influence engagement? We present results from a patient survey (N=1257) devised by a team of asthma clinicians, patients, and technology developers, conducted to identify optimal factors for efficacy, value and engagement for a chatbot. Results indicate that most adults with asthma (53%) are interested in using a chatbot and the patients most likely to do so are those who believe their asthma is more serious and who are less confident about self-management. Results also indicate enthusiasm for 24/7 access, personalisation, and for WhatsApp as the preferred access method (compared to app, voice assistant, SMS or website). Obstacles to uptake include security/privacy concerns and skepticism of technological capabilities. We present detailed findings and consolidate these into 7 recommendations for developers for optimising efficacy of chatbot-based health support.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨AIå¢å¼ºçš„å¯¹è¯æ™ºèƒ½ä½“ï¼ˆconversational agentsï¼‰ï¼Œç‰¹åˆ«æ˜¯ç§»åŠ¨èŠå¤©æœºå™¨äººï¼ˆchatbotsï¼‰ï¼Œä¸ºå“®å–˜æ‚£è€…æä¾›ä¸ªæ€§åŒ–å¥åº·ç®¡ç†æ”¯æŒçš„æ½œåŠ›ï¼Œä»¥åº”å¯¹è‹±å›½å“®å–˜æ­»äº¡ç‡é«˜ä¸”åŸºç¡€æŠ¤ç†è¦†ç›–ä¸è¶³çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹1257åæ‚£è€…è¿›è¡Œçš„é—®å·è°ƒæŸ¥ï¼Œç ”ç©¶è¯†åˆ«äº†å½±å“å¹²é¢„æªæ–½æœ‰æ•ˆæ€§ï¼ˆefficacyï¼‰ã€ä»·å€¼å’Œå‚ä¸åº¦ï¼ˆengagementï¼‰çš„æ ¸å¿ƒå› ç´ ã€‚è°ƒæŸ¥ç»“æœè¡¨æ˜ï¼Œ53%çš„æˆå¹´æ‚£è€…æœ‰å…´è¶£ä½¿ç”¨èŠå¤©æœºå™¨äººï¼Œå°¤å…¶æ˜¯å¯¹è‡ªæˆ‘ç®¡ç†ç¼ºä¹ä¿¡å¿ƒæˆ–è®¤ä¸ºç—…æƒ…è¾ƒé‡çš„æ‚£è€…è¡¨ç°å‡ºæ›´é«˜çš„å‚ä¸æ„æ„¿ã€‚æ‚£è€…æ™®éæœŸå¾…24/7å…¨å¤©å€™è®¿é—®å’Œä¸ªæ€§åŒ–æœåŠ¡ï¼Œå¹¶é¦–é€‰é€šè¿‡ WhatsApp å¹³å°è¿›è¡Œäº’åŠ¨ã€‚è™½ç„¶å­˜åœ¨å®‰å…¨æ€§ä¸éšç§ï¼ˆsecurity/privacyï¼‰åŠå¯¹æŠ€æœ¯èƒ½åŠ›çš„ç–‘è™‘ç­‰éšœç¢ï¼Œç ”ç©¶ä»åŸºäºå‘ç°æå‡ºäº†7é¡¹ä¼˜åŒ–å»ºè®®ã€‚è¯¥å·¥ä½œä¸ºé€šè¿‡æ•°å­—æŠ€æœ¯å¼¥è¡¥åŒ»ç–—æœåŠ¡ç¼ºå£ã€æå‡å“®å–˜æ‚£è€…è‡ªæˆ‘ç®¡ç†æ°´å¹³æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "7 Tables, 4 Figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16735v1",
      "published_date": "2025-07-22 16:21:00 UTC",
      "updated_date": "2025-07-22 16:21:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:26.691637+00:00"
    },
    {
      "arxiv_id": "2507.17778v1",
      "title": "An advanced AI driven database system",
      "title_zh": "ä¸€ç§å…ˆè¿›çš„äººå·¥æ™ºèƒ½é©±åŠ¨å‹æ•°æ®åº“ç³»ç»Ÿ",
      "authors": [
        "M. Tedeschi",
        "S. Rizwan",
        "C. Shringi",
        "V. Devram Chandgir",
        "S. Belich"
      ],
      "abstract": "Contemporary database systems, while effective, suffer severe issues related to complexity and usability, especially among individuals who lack technical expertise but are unfamiliar with query languages like Structured Query Language (SQL). This paper presents a new database system supported by Artificial Intelligence (AI), which is intended to improve the management of data using natural language processing (NLP) - based intuitive interfaces, and automatic creation of structured queries and semi-structured data formats like yet another markup language (YAML), java script object notation (JSON), and application program interface (API) documentation. The system is intended to strengthen the potential of databases through the integration of Large Language Models (LLMs) and advanced machine learning algorithms. The integration is purposed to allow the automation of fundamental tasks such as data modeling, schema creation, query comprehension, and performance optimization. We present in this paper a system that aims to alleviate the main problems with current database technologies. It is meant to reduce the need for technical skills, manual tuning for better performance, and the potential for human error. The AI database employs generative schema inference and format selection to build its schema models and execution formats.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å…ˆè¿›çš„AIé©±åŠ¨æ•°æ®åº“ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿæ•°æ®åº“åœ¨å¤æ‚æ€§å’Œæ˜“ç”¨æ€§æ–¹é¢ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç¼ºä¹SQLç­‰ä¸“ä¸šèƒŒæ™¯ç”¨æˆ·æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé€šè¿‡é›†æˆLarge Language Models (LLMs) å’Œå…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œå®ç°äº†åŸºäºNatural Language Processing (NLP) çš„ç›´è§‚äº¤äº’ç•Œé¢ã€‚å…¶æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢ä»¥åŠYAMLã€JSONå’ŒAPIæ–‡æ¡£ç­‰åŠç»“æ„åŒ–æ•°æ®æ ¼å¼ï¼Œæ˜¾è‘—å¢å¼ºäº†æ•°æ®åº“çš„æ•°æ®ç®¡ç†èƒ½åŠ›ã€‚ç³»ç»Ÿå®ç°äº†æ•°æ®å»ºæ¨¡ã€Schemaåˆ›å»ºã€æŸ¥è¯¢ç†è§£å’Œæ€§èƒ½ä¼˜åŒ–ç­‰åŸºç¡€ä»»åŠ¡çš„è‡ªåŠ¨åŒ–ï¼Œä»è€Œé™ä½äº†å¯¹ä¸“ä¸šæŠ€æœ¯æŠ€èƒ½çš„éœ€æ±‚ã€‚é€šè¿‡é‡‡ç”¨Generative schema inferenceå’Œæ ¼å¼é€‰æ‹©æŠ€æœ¯ï¼Œè¯¥ç³»ç»Ÿæœ‰æ•ˆå‡å°‘äº†æ‰‹åŠ¨è°ƒä¼˜è´Ÿæ‹…åŠäººä¸ºé”™è¯¯çš„é£é™©ã€‚è¯¥ç ”ç©¶å±•ç¤ºäº†AIåœ¨ç®€åŒ–æ•°æ®åº“æ“ä½œã€æé«˜æ•°æ®å¤„ç†æ•ˆç‡æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DB",
      "comment": "10 pages, 5 figures, appears in EDULEARN25 Conference Proceedings",
      "pdf_url": "https://arxiv.org/pdf/2507.17778v1",
      "published_date": "2025-07-22 16:10:45 UTC",
      "updated_date": "2025-07-22 16:10:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:30.379315+00:00"
    },
    {
      "arxiv_id": "2507.16727v2",
      "title": "Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints",
      "title_zh": "Deliberative Searcherï¼šé€šè¿‡å¸¦çº¦æŸå¼ºåŒ–å­¦ä¹ æå‡å¤§è¯­è¨€æ¨¡å‹çš„å¯é æ€§",
      "authors": [
        "Zhenyun Yin",
        "Shujie Wang",
        "Xuhong Wang",
        "Xingjun Ma",
        "Yinchun Wang"
      ],
      "abstract": "Improving the reliability of large language models (LLMs) is critical for deploying them in real-world scenarios. In this paper, we propose \\textbf{Deliberative Searcher}, the first framework to integrate certainty calibration with retrieval-based search for open-domain question answering. The agent performs multi-step reflection and verification over Wikipedia data and is trained with a reinforcement learning algorithm that optimizes for accuracy under a soft reliability constraint. Empirical results show that proposed method improves alignment between model confidence and correctness, leading to more trustworthy outputs. This paper will be continuously updated.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Deliberative Searcherï¼Œè¿™æ˜¯é¦–ä¸ªå°†certainty calibrationä¸retrieval-based searchç›¸ç»“åˆçš„æ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨open-domain question answeringä»»åŠ¡ä¸­çš„å¯é æ€§ã€‚è¯¥æ™ºèƒ½ä½“é€šè¿‡å¯¹Wikipediaæ•°æ®è¿›è¡Œmulti-step reflectionå’Œverificationï¼Œç¡®ä¿ç”Ÿæˆå†…å®¹çš„å‡†ç¡®æ€§ä¸çœŸå®æ€§ã€‚åœ¨æ¨¡å‹ä¼˜åŒ–ä¸Šï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†ä¸€ç§åœ¨soft reliability constraintä¸‹å¹³è¡¡å‡†ç¡®ç‡çš„reinforcement learningç®—æ³•è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æ”¹å–„äº†æ¨¡å‹confidenceä¸correctnessä¹‹é—´çš„å¯¹é½ï¼Œä½¿å¾—è¾“å‡ºç»“æœæ›´åŠ å¯ä¿¡ã€‚è¿™ä¸€æˆæœä¸ºLLMåœ¨ç°å®ä¸–ç•Œå¤æ‚åœºæ™¯ä¸­çš„å¯é éƒ¨ç½²æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The inconsistency of base models undermines the fairness of evaluation comparisons and affects the validity of the paper's conclusions",
      "pdf_url": "https://arxiv.org/pdf/2507.16727v2",
      "published_date": "2025-07-22 16:09:34 UTC",
      "updated_date": "2025-07-23 03:52:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:36.493174+00:00"
    },
    {
      "arxiv_id": "2507.16725v2",
      "title": "RAVine: Reality-Aligned Evaluation for Agentic Search",
      "title_zh": "RAVineï¼šé¢å‘æ™ºèƒ½ä½“æœç´¢çš„ç°å®å¯¹é½è¯„ä¼°æ¡†æ¶",
      "authors": [
        "Yilong Xu",
        "Xiang Long",
        "Zhi Zheng",
        "Jinhua Gao"
      ],
      "abstract": "Agentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is driving the evolution of intelligent search systems. However, existing evaluation frameworks fail to align well with the goals of agentic search. First, the complex queries commonly used in current benchmarks often deviate from realistic user search scenarios. Second, prior approaches tend to introduce noise when extracting ground truth for end-to-end evaluations, leading to distorted assessments at a fine-grained level. Third, most current frameworks focus solely on the quality of final answers, neglecting the evaluation of the iterative process inherent to agentic search. To address these limitations, we propose RAVine -- a Reality-Aligned eValuation framework for agentic LLMs with search. RAVine targets multi-point queries and long-form answers that better reflect user intents, and introduces an attributable ground truth construction strategy to enhance the accuracy of fine-grained evaluation. Moreover, RAVine examines model's interaction with search tools throughout the iterative process, and accounts for factors of efficiency. We benchmark a series of models using RAVine and derive several insights, which we hope will contribute to advancing the development of agentic search systems. The code and datasets are available at https://github.com/SwordFaith/RAVine.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Agentic searchç°æœ‰çš„è¯„ä¼°æ¡†æ¶åœ¨ç°å®ç”¨æˆ·æœç´¢åœºæ™¯å¯¹é½ã€ç»†ç²’åº¦è¯„ä¼°å‡†ç¡®æ€§ä»¥åŠå¯¹è¿­ä»£è¿‡ç¨‹å…³æ³¨ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†RAVineè¿™ä¸€ç°å®å¯¹é½çš„è¯„ä»·æ¡†æ¶ã€‚RAVineä¸“æ³¨äºæ›´è´´è¿‘çœŸå®ç”¨æˆ·æ„å›¾çš„å¤šç‚¹æŸ¥è¯¢(multi-point queries)å’Œé•¿ç¯‡å›ç­”(long-form answers)ï¼Œå¹¶å¼•å…¥äº†å¯å½’å› çš„çœŸå€¼æ„å»ºç­–ç•¥(attributable ground truth construction strategy)æ¥å¢å¼ºç»†ç²’åº¦è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚é™¤äº†æœ€ç»ˆç­”æ¡ˆçš„è´¨é‡ï¼Œè¯¥æ¡†æ¶è¿˜è¯¦ç»†è€ƒå¯Ÿäº†LLMsåœ¨è¿­ä»£è¿‡ç¨‹ä¸­ä¸æœç´¢å·¥å…·çš„äº¤äº’è¡¨ç°ï¼Œå¹¶å…¼é¡¾äº†ç³»ç»Ÿæ•ˆç‡å› ç´ ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨è¯¥æ¡†æ¶å¯¹ä¸€ç³»åˆ—æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•å¹¶æå‡ºäº†å…³é”®è§è§£ã€‚è¯¥å·¥ä½œåŠå…¶å¼€æºçš„ä»£ç ä¸æ•°æ®é›†ä¸ºæ¨åŠ¨æ›´å…·è‡ªä¸»æ€§å’Œé€‚åº”æ€§çš„æ™ºèƒ½æœç´¢ç³»ç»Ÿå‘å±•æä¾›äº†é‡è¦çš„è¯„ä¼°åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16725v2",
      "published_date": "2025-07-22 16:08:12 UTC",
      "updated_date": "2025-07-31 10:20:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:39.883355+00:00"
    },
    {
      "arxiv_id": "2507.16713v1",
      "title": "Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory",
      "title_zh": "ç»éªŒæ˜¯æœ€å¥½çš„è€å¸ˆï¼šé€šè¿‡è‡ªç”Ÿæˆè®°å¿†å®ç°è§†è§‰è¯­è¨€æ¨¡å‹çš„æœºå™¨äººå…·èº«è½åœ°",
      "authors": [
        "Guowei Lan",
        "Kaixian Qu",
        "RenÃ© ZurbrÃ¼gg",
        "Changan Chen",
        "Christopher E. Mower",
        "Haitham Bou-Ammar",
        "Marco Hutter"
      ],
      "abstract": "Vision-language models (VLMs) have been widely adopted in robotics to enable autonomous planning. However, grounding VLMs, originally trained on internet data, to diverse real-world robots remains a challenge. This paper presents ExpTeach, a framework that grounds VLMs to physical robots by building a self-generated memory of real-world experiences. In ExpTeach, the VLM autonomously plans actions, verifies outcomes, reflects on failures, and adapts robot behaviors in a closed loop. The self-generated experiences during this process are then summarized into a long-term memory, enabling retrieval of learned knowledge to guide future tasks via retrieval-augmented generation (RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with an on-demand image annotation module. In experiments, we show that reflection improves success rates from 36% to 84% on four challenging robotic tasks and observe the emergence of intelligent object interactions, including creative tool use. Across extensive tests on 12 real-world scenarios (including eight unseen ones), we find that grounding with long-term memory boosts single-trial success rates from 22% to 80%, demonstrating the effectiveness and generalizability of ExpTeach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°†é¢„è®­ç»ƒäºäº’è”ç½‘æ•°æ®çš„è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) è½åœ°åˆ°å¤šæ ·åŒ–çœŸå®æœºå™¨äººå¹³å°æ—¶é¢ä¸´çš„ Grounding éš¾é¢˜ï¼Œæå‡ºäº† ExpTeach æ¡†æ¶ã€‚ExpTeach é€šè¿‡æ„å»ºæœºå™¨äººè‡ªèº«ç”Ÿæˆçš„å›å¿† (Self-Generated Memory) æ¥å®ç°æ¨¡å‹è½åœ°ï¼Œä½¿ VLMs èƒ½å¤Ÿåœ¨é—­ç¯ç³»ç»Ÿä¸­è‡ªä¸»è§„åˆ’åŠ¨ä½œã€éªŒè¯ç»“æœã€åæ€å¤±è´¥å¹¶è°ƒæ•´è¡Œä¸ºã€‚è¿™ä¸€è¿‡ç¨‹ä¸­çš„ç»éªŒè¢«æ±‡æ€»è‡³é•¿æœŸè®°å¿†ä¸­ï¼Œå¹¶åˆ©ç”¨æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) æŠ€æœ¯æå–å·²å­¦çŸ¥è¯†ï¼Œä»è€ŒæŒ‡å¯¼æœªæ¥ä»»åŠ¡ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜åŒ…å«ä¸€ä¸ªæŒ‰éœ€å›¾åƒæ ‡æ³¨æ¨¡å— (On-Demand Image Annotation Module)ï¼Œç”¨äºå¢å¼º VLMs å¯¹ç©ºé—´ç¯å¢ƒçš„ç†è§£ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œé€šè¿‡åæ€æœºåˆ¶ï¼Œå››ä¸ªæŒ‘æˆ˜æ€§æœºå™¨äººä»»åŠ¡çš„æˆåŠŸç‡ä» 36% æå‡è‡³ 84%ï¼Œå¹¶è§‚å¯Ÿåˆ°äº†åŒ…æ‹¬åˆ›é€ æ€§å·¥å…·ä½¿ç”¨åœ¨å†…çš„æ™ºèƒ½ç‰©ä½“äº¤äº’è¡Œä¸ºã€‚åœ¨ 12 ä¸ªçœŸå®åœºæ™¯ï¼ˆåŒ…æ‹¬ 8 ä¸ªæœªè§åœºæ™¯ï¼‰çš„æµ‹è¯•ä¸­ï¼Œç»“åˆé•¿æœŸè®°å¿†çš„ Grounding æœºåˆ¶å°†å•æ¬¡å°è¯•æˆåŠŸç‡ä» 22% æ˜¾è‘—æå‡è‡³ 80%ï¼Œå……åˆ†éªŒè¯äº† ExpTeach çš„æœ‰æ•ˆæ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16713v1",
      "published_date": "2025-07-22 15:48:49 UTC",
      "updated_date": "2025-07-22 15:48:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:48.040005+00:00"
    },
    {
      "arxiv_id": "2507.16711v1",
      "title": "Advancing Risk and Quality Assurance: A RAG Chatbot for Improved Regulatory Compliance",
      "title_zh": "æ¨è¿›é£é™©ä¸è´¨é‡ä¿è¯ï¼šæ—¨åœ¨æå‡ç›‘ç®¡åˆè§„æ€§çš„ RAG èŠå¤©æœºå™¨äºº",
      "authors": [
        "Lars Hillebrand",
        "Armin Berger",
        "Daniel Uedelhoven",
        "David Berghaus",
        "Ulrich Warning",
        "Tim Dilmaghani",
        "Bernd Kliem",
        "Thomas Schmid",
        "RÃ¼diger Loitz",
        "Rafet Sifa"
      ],
      "abstract": "Risk and Quality (R&Q) assurance in highly regulated industries requires constant navigation of complex regulatory frameworks, with employees handling numerous daily queries demanding accurate policy interpretation. Traditional methods relying on specialized experts create operational bottlenecks and limit scalability. We present a novel Retrieval Augmented Generation (RAG) system leveraging Large Language Models (LLMs), hybrid search and relevance boosting to enhance R&Q query processing. Evaluated on 124 expert-annotated real-world queries, our actively deployed system demonstrates substantial improvements over traditional RAG approaches. Additionally, we perform an extensive hyperparameter analysis to compare and evaluate multiple configuration setups, delivering valuable insights to practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é«˜åº¦ç›‘ç®¡è¡Œä¸šä¸­é£é™©ä¸è´¨é‡ï¼ˆRisk and Quality, R&Qï¼‰ä¿è¯æ‰€é¢ä¸´çš„æ³•è§„è§£é‡Šå¤æ‚åŠä¼ ç»Ÿä¸“å®¶æ¨¡å¼éš¾ä»¥æ‰©å±•ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval Augmented Generation, RAGï¼‰æŠ€æœ¯çš„åˆ›æ–°å‹ç³»ç»Ÿã€‚è¯¥æ–¹æ¡ˆç»“åˆäº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Models, LLMsï¼‰ã€æ··åˆæœç´¢ï¼ˆhybrid searchï¼‰å’Œç›¸å…³æ€§æå‡ï¼ˆrelevance boostingï¼‰æŠ€æœ¯ï¼Œæ—¨åœ¨æ˜¾è‘—æé«˜ R&Q æŸ¥è¯¢å¤„ç†çš„æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚é€šè¿‡å¯¹124ä¸ªä¸“å®¶æ ‡æ³¨çš„çœŸå®ä¸–ç•ŒæŸ¥è¯¢è¿›è¡Œè¯„ä¼°ï¼Œå®éªŒç»“æœè¡¨æ˜è¯¥å·²éƒ¨ç½²ç³»ç»Ÿåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿ RAG æ–¹æ³•ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜é€šè¿‡è¯¦å°½çš„è¶…å‚æ•°åˆ†æå¯¹æ¯”äº†å¤šç§é…ç½®æ–¹æ¡ˆï¼Œä¸ºç›¸å…³é¢†åŸŸçš„ä»ä¸šè€…æä¾›äº†é‡è¦çš„å®è·µæ´å¯Ÿä¸å‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted and published at BigData 2024, 3 pages, 3 tables, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16711v1",
      "published_date": "2025-07-22 15:46:44 UTC",
      "updated_date": "2025-07-22 15:46:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:46.996347+00:00"
    },
    {
      "arxiv_id": "2507.16704v1",
      "title": "Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation",
      "title_zh": "Screen2AXï¼šåŸºäºè§†è§‰çš„ macOS è¾…åŠ©åŠŸèƒ½è‡ªåŠ¨ç”Ÿæˆæ–¹æ³•",
      "authors": [
        "Viktor Muryn",
        "Marta Sumyk",
        "Mariya Hirna",
        "Sofiya Garkot",
        "Maksym Shamrai"
      ],
      "abstract": "Desktop accessibility metadata enables AI agents to interpret screens and supports users who depend on tools like screen readers. Yet, many applications remain largely inaccessible due to incomplete or missing metadata provided by developers - our investigation shows that only 33% of applications on macOS offer full accessibility support. While recent work on structured screen representation has primarily addressed specific challenges, such as UI element detection or captioning, none has attempted to capture the full complexity of desktop interfaces by replicating their entire hierarchical structure. To bridge this gap, we introduce Screen2AX, the first framework to automatically create real-time, tree-structured accessibility metadata from a single screenshot. Our method uses vision-language and object detection models to detect, describe, and organize UI elements hierarchically, mirroring macOS's system-level accessibility structure. To tackle the limited availability of data for macOS desktop applications, we compiled and publicly released three datasets encompassing 112 macOS applications, each annotated for UI element detection, grouping, and hierarchical accessibility metadata alongside corresponding screenshots. Screen2AX accurately infers hierarchy trees, achieving a 77% F1 score in reconstructing a complete accessibility tree. Crucially, these hierarchy trees improve the ability of autonomous agents to interpret and interact with complex desktop interfaces. We introduce Screen2AX-Task, a benchmark specifically designed for evaluating autonomous agent task execution in macOS desktop environments. Using this benchmark, we demonstrate that Screen2AX delivers a 2.2x performance improvement over native accessibility representations and surpasses the state-of-the-art OmniParser V2 system on the ScreenSpot benchmark.",
      "tldr_zh": "æ¡Œé¢è¾…åŠ©åŠŸèƒ½å…ƒæ•°æ®(Accessibility metadata)å¯¹äºAIæ™ºèƒ½ä½“å’Œå±å¹•é˜…è¯»å™¨è‡³å…³é‡è¦ï¼Œä½†ç›®å‰macOSåº”ç”¨ä¸­ä»…æœ‰33%æä¾›å®Œæ•´æ”¯æŒã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œè¯¥ç ”ç©¶æå‡ºäº†Screen2AXï¼Œè¿™æ˜¯é¦–ä¸ªä»…é€šè¿‡å•å¼ æˆªå›¾å³å¯è‡ªåŠ¨ç”Ÿæˆå®æ—¶ã€æ ‘çŠ¶ç»“æ„è¾…åŠ©åŠŸèƒ½å…ƒæ•°æ®çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è§†è§‰è¯­è¨€(Vision-language)å’Œç›®æ ‡æ£€æµ‹(Object detection)æ¨¡å‹ï¼Œå¯¹UIå…ƒç´ è¿›è¡Œæ£€æµ‹ã€æè¿°å’Œå±‚çº§ç»„ç»‡ï¼Œæ—¨åœ¨æ¨¡æ‹ŸmacOSç³»ç»Ÿçº§çš„è¾…åŠ©åŠŸèƒ½ç»“æ„ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å‘å¸ƒäº†åŒ…å«112ä¸ªmacOSåº”ç”¨çš„ä¸‰ä¸ªæ•°æ®é›†ï¼Œæ¶µç›–äº†UIå…ƒç´ æ£€æµ‹ã€åˆ†ç»„å’Œå±‚çº§å…ƒæ•°æ®æ ‡æ³¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒScreen2AXåœ¨é‡å»ºå®Œæ•´è¾…åŠ©åŠŸèƒ½æ ‘æ–¹é¢è¾¾åˆ°äº†77%çš„F1åˆ†æ•°ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ–°æå‡ºçš„Screen2AX-TaskåŸºå‡†æµ‹è¯•ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—æå‡äº†è‡ªä¸»æ™ºèƒ½ä½“åœ¨æ¡Œé¢ç¯å¢ƒä¸­çš„ä»»åŠ¡æ‰§è¡Œèƒ½åŠ›ï¼Œå…¶è¡¨ç°æ¯”åŸç”Ÿè¡¨ç¤ºæ³•æé«˜äº†2.2å€ï¼Œå¹¶åœ¨ScreenSpotåŸºå‡†ä¸Šè¶…è¶Šäº†ç›®å‰æœ€å…ˆè¿›çš„OmniParser V2ç³»ç»Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16704v1",
      "published_date": "2025-07-22 15:38:12 UTC",
      "updated_date": "2025-07-22 15:38:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:47.824196+00:00"
    },
    {
      "arxiv_id": "2507.16881v1",
      "title": "Confidence Optimization for Probabilistic Encoding",
      "title_zh": "æ¦‚ç‡ç¼–ç çš„ç½®ä¿¡åº¦ä¼˜åŒ–",
      "authors": [
        "Pengjiu Xia",
        "Yidian Huang",
        "Wenchao Wei",
        "Yuwen Tan"
      ],
      "abstract": "Probabilistic encoding introduces Gaussian noise into neural networks, enabling a smooth transition from deterministic to uncertain states and enhancing generalization ability. However, the randomness of Gaussian noise distorts point-based distance measurements in classification tasks. To mitigate this issue, we propose a confidence optimization probabilistic encoding (CPE) method that improves distance reliability and enhances representation learning. Specifically, we refine probabilistic encoding with two key strategies: First, we introduce a confidence-aware mechanism to adjust distance calculations, ensuring consistency and reliability in probabilistic encoding classification tasks. Second, we replace the conventional KL divergence-based variance regularization, which relies on unreliable prior assumptions, with a simpler L2 regularization term to directly constrain variance. The method we proposed is model-agnostic, and extensive experiments on natural language classification tasks demonstrate that our method significantly improves performance and generalization on both the BERT and the RoBERTa model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¦‚ç‡ç¼–ç (Probabilistic encoding)é€šè¿‡å¼•å…¥é«˜æ–¯å™ªå£°å¢å¼ºç¥ç»ç½‘ç»œæ³›åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œå¦‚ä½•è§£å†³å™ªå£°éšæœºæ€§å¯¼è‡´åˆ†ç±»ä»»åŠ¡ä¸­ç‚¹å¯¹ç‚¹è·ç¦»æµ‹é‡æ‰­æ›²çš„é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ç½®ä¿¡åº¦ä¼˜åŒ–æ¦‚ç‡ç¼–ç (Confidence Optimization Probabilistic Encoding, CPE)æ–¹æ³•ï¼Œæ—¨åœ¨æé«˜è·ç¦»å¯é æ€§å¹¶å¢å¼ºè¡¨ç¤ºå­¦ä¹ ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥ç½®ä¿¡åº¦æ„ŸçŸ¥æœºåˆ¶(confidence-aware mechanism)è°ƒæ•´è·ç¦»è®¡ç®—ï¼Œç¡®ä¿äº†åˆ†ç±»ä»»åŠ¡çš„ä¸€è‡´æ€§ï¼Œå¹¶åˆ©ç”¨ç®€å•çš„ L2 æ­£åˆ™åŒ–é¡¹å–ä»£ä¼ ç»Ÿçš„ KL æ•£åº¦(KL divergence)æ¥ç›´æ¥çº¦æŸæ–¹å·®ï¼Œè§„é¿äº†ä¸å¯é çš„å…ˆéªŒå‡è®¾ã€‚å®éªŒè¯æ˜ï¼Œè¿™ç§æ¨¡å‹æ— å…³(model-agnostic)çš„æ–¹æ³•åœ¨ BERT å’Œ RoBERTa æ¨¡å‹ä¸Šçš„è‡ªç„¶è¯­è¨€åˆ†ç±»ä»»åŠ¡ä¸­å‡æ˜¾è‘—æå‡äº†æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16881v1",
      "published_date": "2025-07-22 15:32:27 UTC",
      "updated_date": "2025-07-22 15:32:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:11:50.438658+00:00"
    },
    {
      "arxiv_id": "2507.16696v1",
      "title": "FISHER: A Foundation Model for Multi-Modal Industrial Signal Comprehensive Representation",
      "title_zh": "FISHERï¼šé¢å‘å¤šæ¨¡æ€å·¥ä¸šä¿¡å·ç»¼åˆè¡¨å¾çš„åŸºç¡€æ¨¡å‹",
      "authors": [
        "Pingyi Fan",
        "Anbai Jiang",
        "Shuwei Zhang",
        "Zhiqiang Lv",
        "Bing Han",
        "Xinhu Zheng",
        "Wenrui Liang",
        "Junjie Li",
        "Wei-Qiang Zhang",
        "Yanmin Qian",
        "Xie Chen",
        "Cheng Lu",
        "Jia Liu"
      ],
      "abstract": "With the rapid deployment of SCADA systems, how to effectively analyze industrial signals and detect abnormal states is an urgent need for the industry. Due to the significant heterogeneity of these signals, which we summarize as the M5 problem, previous works only focus on small sub-problems and employ specialized models, failing to utilize the synergies between modalities and the powerful scaling law. However, we argue that the M5 signals can be modeled in a unified manner due to the intrinsic similarity. As a result, we propose FISHER, a Foundation model for multi-modal Industrial Signal compreHEnsive Representation. To support arbitrary sampling rates, FISHER considers the increment of sampling rate as the concatenation of sub-band information. Specifically, FISHER takes the STFT sub-band as the modeling unit and adopts a teacher student SSL framework for pre-training. We also develop the RMIS benchmark, which evaluates the representations of M5 industrial signals on multiple health management tasks. Compared with top SSL models, FISHER showcases versatile and outstanding capabilities with a general performance gain up to 5.03%, along with much more efficient scaling curves. We also investigate the scaling law on downstream tasks and derive potential avenues for future works. FISHER is now open-sourced on https://github.com/jianganbai/FISHER",
      "tldr_zh": "é’ˆå¯¹SCADAç³»ç»Ÿä¸­å·¥ä¸šä¿¡å·é«˜åº¦å¼‚æ„å¼•å‘çš„M5é—®é¢˜ï¼Œä»¥åŠä¼ ç»Ÿä¸“ç”¨æ¨¡å‹éš¾ä»¥åˆ©ç”¨å¤šæ¨¡æ€ååŒå’Œæ‰©å±•å®šå¾‹(scaling law)çš„ç°çŠ¶ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ç”¨äºå¤šæ¨¡æ€å·¥ä¸šä¿¡å·ç»¼åˆè¡¨ç¤ºçš„åŸºç¡€æ¨¡å‹FISHERã€‚è¯¥æ¨¡å‹é€šè¿‡æŒ–æ˜ä¿¡å·é—´çš„å†…åœ¨ç›¸ä¼¼æ€§è¿›è¡Œç»Ÿä¸€å»ºæ¨¡ï¼Œé‡‡ç”¨STFTå­å¸¦ä½œä¸ºåŸºæœ¬å»ºæ¨¡å•å…ƒï¼Œå¹¶åˆ©ç”¨æ•™å¸ˆ-å­¦ç”Ÿè‡ªç›‘ç£å­¦ä¹ (SSL)æ¡†æ¶è¿›è¡Œé¢„è®­ç»ƒï¼Œä»è€Œæœ‰æ•ˆæ”¯æŒä»»æ„é‡‡æ ·ç‡ã€‚ä¸ºäº†è¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼Œç ”ç©¶è€…åŒæ­¥å¼€å‘äº†RMISåŸºå‡†æµ‹è¯•ï¼Œæ¶µç›–äº†å¤šç§å·¥ä¸šå¥åº·ç®¡ç†ä»»åŠ¡ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒFISHERç›¸æ¯”é¡¶å°–çš„SSLæ¨¡å‹åœ¨é€šç”¨æ€§èƒ½ä¸Šæå‡äº†é«˜è¾¾5.03%ï¼Œå¹¶å±•ç°å‡ºæ›´é«˜æ•ˆçš„æ‰©å±•æ›²çº¿ã€‚è¯¥ç ”ç©¶è¿˜æ·±å…¥æ¢è®¨äº†ä¸‹æ¸¸ä»»åŠ¡çš„æ‰©å±•å®šå¾‹å¹¶å¼€æºäº†ç›¸å…³ä»£ç ï¼Œä¸ºæœªæ¥å·¥ä¸šä¿¡å·åˆ†ææä¾›äº†é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„é€šç”¨è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16696v1",
      "published_date": "2025-07-22 15:31:16 UTC",
      "updated_date": "2025-07-22 15:31:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:09.537625+00:00"
    },
    {
      "arxiv_id": "2507.16695v1",
      "title": "Interpretable Topic Extraction and Word Embedding Learning using row-stochastic DEDICOM",
      "title_zh": "åŸºäºè¡Œéšæœº DEDICOM çš„å¯è§£é‡Šä¸»é¢˜æå–ä¸è¯åµŒå…¥å­¦ä¹ ",
      "authors": [
        "Lars Hillebrand",
        "David Biesner",
        "Christian Bauckhage",
        "Rafet Sifa"
      ],
      "abstract": "The DEDICOM algorithm provides a uniquely interpretable matrix factorization method for symmetric and asymmetric square matrices. We employ a new row-stochastic variation of DEDICOM on the pointwise mutual information matrices of text corpora to identify latent topic clusters within the vocabulary and simultaneously learn interpretable word embeddings. We introduce a method to efficiently train a constrained DEDICOM algorithm and a qualitative evaluation of its topic modeling and word embedding performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºè¡Œéšæœºï¼ˆrow-stochasticï¼‰å˜ä½“ DEDICOM ç®—æ³•çš„æ–‡æœ¬åˆ†ææ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ DEDICOM ç®—æ³•åœ¨å¤„ç†å¯¹ç§°ä¸éå¯¹ç§°æ–¹é˜µæ—¶çš„ç‹¬ç‰¹å¯è§£é‡Šæ€§ä¼˜åŠ¿ã€‚é€šè¿‡å°†è¯¥ç®—æ³•åº”ç”¨äºæ–‡æœ¬è¯­æ–™åº“çš„é€ç‚¹äº’ä¿¡æ¯ï¼ˆpointwise mutual information, PMIï¼‰çŸ©é˜µï¼Œç ”ç©¶è€…èƒ½å¤ŸåŒæ—¶å®ç°æ½œåœ¨ä¸»é¢˜èšç±»ï¼ˆlatent topic clustersï¼‰çš„è¯†åˆ«ä¸å¯è§£é‡Šè¯åµŒå…¥ï¼ˆword embeddingsï¼‰çš„å­¦ä¹ ã€‚æ–‡ä¸­è¯¦ç»†ä»‹ç»äº†ä¸€ç§ç”¨äºé«˜æ•ˆè®­ç»ƒå—é™ DEDICOM ç®—æ³•çš„æ–°æ–¹æ³•ï¼Œè§£å†³äº†å¤æ‚çº¦æŸä¸‹çš„è®¡ç®—æ•ˆç‡é—®é¢˜ã€‚å®šæ€§è¯„ä¼°ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸»é¢˜å»ºæ¨¡ï¼ˆtopic modelingï¼‰å’Œè¯åµŒå…¥æ€§èƒ½ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä¸ºç†è§£è¯æ±‡é—´çš„æ·±å±‚è¯­ä¹‰å…³è”æä¾›äº†æœ‰æ•ˆçš„æ•°å­¦å·¥å…·ã€‚è¿™ä¸€è¿›å±•ä¸ºæ„å»ºé€æ˜ä¸”å¯è§£é‡Šçš„è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted and published at CD-MAKE 2020, 20 pages, 8 tables, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16695v1",
      "published_date": "2025-07-22 15:30:32 UTC",
      "updated_date": "2025-07-22 15:30:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:16.648674+00:00"
    },
    {
      "arxiv_id": "2507.17777v2",
      "title": "ASP-Assisted Symbolic Regression: Uncovering Hidden Physics in Fluid Mechanics",
      "title_zh": "ASP è¾…åŠ©çš„ç¬¦å·å›å½’ï¼šæ­ç¤ºæµä½“åŠ›å­¦ä¸­éšè—çš„ç‰©ç†è§„å¾‹",
      "authors": [
        "Theofanis Aravanis",
        "Grigorios Chrimatopoulos",
        "Mohammad Ferdows",
        "Michalis Xenos",
        "Efstratios Em Tzirtzilakis"
      ],
      "abstract": "Symbolic Regression (SR) offers an interpretable alternative to conventional Machine-Learning (ML) approaches, which are often criticized as ``black boxes''. In contrast to standard regression models that require a prescribed functional form, SR constructs expressions from a user-defined set of mathematical primitives, enabling the automated discovery of compact formulas that fit the data and reveal underlying physical relationships. In fluid mechanics, where understanding the underlying physics is as crucial as predictive accuracy, this study applies SR to model three-dimensional (3D) laminar flow in a rectangular channel, focusing on the axial velocity and pressure fields. Compact symbolic equations were derived from numerical simulation data, accurately reproducing the expected parabolic velocity profile and linear pressure drop, and showing excellent agreement with analytical solutions from the literature. To address the limitation that purely data-driven SR models may overlook domain-specific constraints, an innovative hybrid framework that integrates SR with Answer Set Programming (ASP) is also introduced. This integration combines the generative power of SR with the declarative reasoning capabilities of ASP, ensuring that derived equations remain both statistically accurate and physically plausible. The proposed SR/ASP methodology demonstrates the potential of combining data-driven and knowledge-representation approaches to enhance interpretability, reliability, and alignment with physical principles in fluid dynamics and related domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¬¦å·å›å½’(Symbolic Regression, SR)åœ¨æµä½“åŠ›å­¦ä¸­æ­ç¤ºæ½œåœ¨ç‰©ç†è§„å¾‹çš„åº”ç”¨ï¼Œæ—¨åœ¨æä¾›æ¯”ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹æ›´å…·å¯è§£é‡Šæ€§çš„å»ºæ¨¡æ–¹æ¡ˆã€‚ç ”ç©¶é‡ç‚¹é’ˆå¯¹çŸ©å½¢é€šé“ä¸­çš„ä¸‰ç»´å±‚æµ(3D laminar flow)è¿›è¡Œå»ºæ¨¡ï¼Œä»æ•°å€¼æ¨¡æ‹Ÿæ•°æ®ä¸­æ¨å¯¼å‡ºè½´å‘é€Ÿåº¦å’Œå‹åŠ›åœºçš„ç®€æ´ç¬¦å·æ–¹ç¨‹ï¼Œå‡†ç¡®é‡ç°äº†ç»å…¸çš„æŠ›ç‰©çº¿é€Ÿåº¦åˆ†å¸ƒå’Œçº¿æ€§å‹åŠ›é™ã€‚ä¸ºäº†å…‹æœçº¯æ•°æ®é©±åŠ¨æ¨¡å‹åœ¨ç‰©ç†çº¦æŸæ–¹é¢çš„å±€é™æ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§ç»“åˆSRä¸ç­”æ¡ˆé›†ç¼–ç¨‹(Answer Set Programming, ASP)çš„åˆ›æ–°æ··åˆæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†SRçš„ç”Ÿæˆèƒ½åŠ›ä¸ASPçš„å£°æ˜å¼æ¨ç†ç›¸ç»“åˆï¼Œç¡®ä¿æ¨å¯¼å‡ºçš„æ–¹ç¨‹åœ¨ä¿æŒç»Ÿè®¡å‡†ç¡®æ€§çš„åŒæ—¶ç¬¦åˆç‰©ç†å…ˆéªŒçŸ¥è¯†ã€‚è¿™ç§SR/ASPé›†æˆæ–¹æ³•ä¸ºå¢å¼ºæµä½“åŠ¨åŠ›å­¦åŠç›¸å…³é¢†åŸŸçš„æ¨¡å‹å¯è§£é‡Šæ€§ã€å¯é æ€§ä»¥åŠä¸ç‰©ç†åŸåˆ™çš„ä¸€è‡´æ€§æä¾›äº†æ–°çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This research was implemented in the framework of the Action \"Flagship actions in interdisciplinary scientific fields with a special focus on the productive fabric'', which is implemented through the National Recovery and Resilience Fund Greece 2.0 and funded by the European Union--NextGenerationEU (Project ID: TAEDR-0535983)",
      "pdf_url": "https://arxiv.org/pdf/2507.17777v2",
      "published_date": "2025-07-22 15:16:20 UTC",
      "updated_date": "2025-11-25 08:35:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:11.207971+00:00"
    },
    {
      "arxiv_id": "2507.16679v1",
      "title": "PICACO: Pluralistic In-Context Value Alignment of LLMs via Total Correlation Optimization",
      "title_zh": "PICACOï¼šåŸºäºæ€»ç›¸å…³æ€§ä¼˜åŒ–çš„å¤§è¯­è¨€æ¨¡å‹å¤šå…ƒä¸Šä¸‹æ–‡ä»·å€¼å¯¹é½",
      "authors": [
        "Han Jiang",
        "Dongyao Zhu",
        "Zhihua Wei",
        "Xiaoyuan Yi",
        "Ziang Xiao",
        "Xing Xie"
      ],
      "abstract": "In-Context Learning has shown great potential for aligning Large Language Models (LLMs) with human values, helping reduce harmful outputs and accommodate diverse preferences without costly post-training, known as In-Context Alignment (ICA). However, LLMs' comprehension of input prompts remains agnostic, limiting ICA's ability to address value tensions--human values are inherently pluralistic, often imposing conflicting demands, e.g., stimulation vs. tradition. Current ICA methods therefore face the Instruction Bottleneck challenge, where LLMs struggle to reconcile multiple intended values within a single prompt, leading to incomplete or biased alignment. To address this, we propose PICACO, a novel pluralistic ICA method. Without fine-tuning, PICACO optimizes a meta-instruction that navigates multiple values to better elicit LLMs' understanding of them and improve their alignment. This is achieved by maximizing the total correlation between specified values and LLM responses, theoretically reinforcing value correlation while reducing distractive noise, resulting in effective value instructions. Extensive experiments on five value sets show that PICACO works well with both black-box and open-source LLMs, outperforms several recent strong baselines, and achieves a better balance across up to 8 distinct values.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è¯­å¢ƒå¯¹é½(In-Context Alignment, ICA)ä¸­éš¾ä»¥å¤„ç†å¤šå…ƒä»·å€¼å†²çªçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºPICACOçš„æ–°æ–¹æ³•ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œç°æœ‰çš„ICAæ–¹æ³•é¢ä¸´æŒ‡ä»¤ç“¶é¢ˆ(Instruction Bottleneck)æŒ‘æˆ˜ï¼Œå³æ¨¡å‹éš¾ä»¥åœ¨å•ä¸ªæç¤ºè¯ä¸­åè°ƒå¤šä¸ªç›¸äº’å†²çªçš„ä»·å€¼è§‚ï¼Œå¯¼è‡´å¯¹é½ä¸å®Œæ•´æˆ–å­˜åœ¨åè§ã€‚PICACOæ— éœ€è¿›è¡Œå‚æ•°å¾®è°ƒï¼Œé€šè¿‡ä¼˜åŒ–å…ƒæŒ‡ä»¤(meta-instruction)æ¥å¼•å¯¼æ¨¡å‹æ›´å¥½åœ°ç†è§£å¹¶ä½“ç°å¤šå…ƒä»·å€¼è§‚ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯é€šè¿‡æœ€å¤§åŒ–æŒ‡å®šä»·å€¼è§‚ä¸æ¨¡å‹å“åº”ä¹‹é—´çš„æ€»ç›¸å…³æ€§(Total Correlation)è¿›è¡Œä¼˜åŒ–ï¼Œä»è€Œåœ¨ç†è®ºä¸Šå¢å¼ºä»·å€¼å…³è”å¹¶å‡å°‘å¹²æ‰°å™ªå£°ã€‚åœ¨äº”ä¸ªä»·å€¼è§‚æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPICACOåœ¨é»‘ç›’å’Œå¼€æºLLMsä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œæ˜¾è‘—ä¼˜äºå¤šä¸ªå¼ºåŸºçº¿æ¨¡å‹ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡å¤šè¾¾8ç§ä¸åŒçš„ä»·å€¼è§‚ï¼Œä¸ºå®ç°æ›´å¤æ‚ã€æ›´å…·åŒ…å®¹æ€§çš„æ¨¡å‹ä»·å€¼å¯¹é½æä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16679v1",
      "published_date": "2025-07-22 15:14:56 UTC",
      "updated_date": "2025-07-22 15:14:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:16.482339+00:00"
    },
    {
      "arxiv_id": "2507.19539v1",
      "title": "Swift-Sarsa: Fast and Robust Linear Control",
      "title_zh": "Swift-Sarsaï¼šå¿«é€Ÿä¸”é²æ£’çš„çº¿æ€§æ§åˆ¶",
      "authors": [
        "Khurram Javed",
        "Richard S. Sutton"
      ],
      "abstract": "Javed, Sharifnassab, and Sutton (2024) introduced a new algorithm for TD learning -- SwiftTD -- that augments True Online TD($Î»$) with step-size optimization, a bound on the effective learning rate, and step-size decay. In their experiments SwiftTD outperformed True Online TD($Î»$) and TD($Î»$) on a variety of prediction tasks derived from Atari games, and its performance was robust to the choice of hyper-parameters. In this extended abstract we extend SwiftTD to work for control problems. We combine the key ideas behind SwiftTD with True Online Sarsa($Î»$) to develop an on-policy reinforcement learning algorithm called $\\textit{Swift-Sarsa}$.\n  We propose a simple benchmark for linear on-policy control called the $\\textit{operant conditioning benchmark}$. The key challenge in the operant conditioning benchmark is that a very small subset of input signals are relevant for decision making. The majority of the signals are noise sampled from a non-stationary distribution. To learn effectively, the agent must learn to differentiate between the relevant signals and the noisy signals, and minimize prediction errors by assigning credit to the weight parameters associated with the relevant signals.\n  Swift-Sarsa, when applied to the operant conditioning benchmark, learned to assign credit to the relevant signals without any prior knowledge of the structure of the problem. It opens the door for solution methods that learn representations by searching over hundreds of millions of features in parallel without performance degradation due to noisy or bad features.",
      "tldr_zh": "è¯¥ç ”ç©¶å°† SwiftTD ç®—æ³•æ‰©å±•è‡³æ§åˆ¶é¢†åŸŸï¼Œæå‡ºäº† Swift-Sarsaï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†æ­¥é•¿ä¼˜åŒ– (step-size optimization)ã€æœ‰æ•ˆå­¦ä¹ ç‡é™åˆ¶å’Œæ­¥é•¿è¡°å‡çš„åœ¨çº¿å¼ºåŒ–å­¦ä¹  (on-policy reinforcement learning) ç®—æ³•ã€‚é€šè¿‡å°† SwiftTD çš„æ ¸å¿ƒç†å¿µä¸ True Online Sarsa($\\lambda$) ç›¸ç»“åˆï¼Œè¯¥ç®—æ³•æ—¨åœ¨æé«˜çº¿æ€§æ§åˆ¶ä»»åŠ¡çš„æ‰§è¡Œæ•ˆç‡ä¸é²æ£’æ€§ã€‚ç ”ç©¶è€…è¿›ä¸€æ­¥æå‡ºäº†æ“ä½œæ€§æ¡ä»¶åå°„åŸºå‡† (operant conditioning benchmark)ï¼Œè¯¥åŸºå‡†çš„æ ¸å¿ƒæŒ‘æˆ˜åœ¨äºè¦æ±‚æ™ºèƒ½ä½“ä»å¤§é‡éå¹³ç¨³å™ªå£°ä¸­è¯†åˆ«å‡ºæå°‘æ•°çš„å…³é”®ä¿¡å·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSwift-Sarsa åœ¨æ— éœ€ä»»ä½•å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿç²¾å‡†åœ°ä¸ºç›¸å…³ä¿¡å·è¿›è¡Œå­¦åˆ†åˆ†é… (credit assignment)ï¼Œæœ‰æ•ˆè§£å†³äº†å™ªå£°å¹²æ‰°é—®é¢˜ã€‚è¿™ä¸€æˆæœè¯æ˜äº† Swift-Sarsa å…·å¤‡åœ¨æ•°äº¿é‡çº§ç‰¹å¾ç©ºé—´ä¸­å¹¶è¡Œæœç´¢å¹¶å­¦ä¹ æœ‰æ•ˆè¡¨å¾çš„èƒ½åŠ›ï¼Œä¸”ä¸ä¼šå› åŠ£è´¨ç‰¹å¾å¯¼è‡´æ€§èƒ½ä¸‹é™ï¼Œä¸ºå¤§è§„æ¨¡çº¿æ€§æ§åˆ¶æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at RLDM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.19539v1",
      "published_date": "2025-07-22 15:08:38 UTC",
      "updated_date": "2025-07-22 15:08:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:16.837370+00:00"
    },
    {
      "arxiv_id": "2507.16672v1",
      "title": "Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs",
      "title_zh": "é¢å‘æç¤ºå¾®è°ƒå¤§è¯­è¨€æ¨¡å‹å†·å¯åŠ¨ä¸ªæ€§åŒ–çš„å…ƒå­¦ä¹ ",
      "authors": [
        "Yushang Zhao",
        "Huijie Shen",
        "Dannier Li",
        "Lu Chang",
        "Chengrui Zhou",
        "Yinuo Yang"
      ],
      "abstract": "Generative, explainable, and flexible recommender systems, derived using Large Language Models (LLM) are promising and poorly adapted to the cold-start user situation, where there is little to no history of interaction. The current solutions i.e. supervised fine-tuning and collaborative filtering are dense-user-item focused and would be expensive to maintain and update. This paper introduces a meta-learning framework, that can be used to perform parameter-efficient prompt-tuning, to effectively personalize LLM-based recommender systems quickly at cold-start. The model learns soft prompt embeddings with first-order (Reptile) and second-order (MAML) optimization by treating each of the users as the tasks. As augmentations to the input tokens, these learnable vectors are the differentiable control variables that represent user behavioral priors. The prompts are meta-optimized through episodic sampling, inner-loop adaptation, and outer-loop generalization. On MovieLens-1M, Amazon Reviews, and Recbole, we can see that our adaptive model outperforms strong baselines in NDCG@10, HR@10, and MRR, and it runs in real-time (i.e., below 300 ms) on consumer GPUs. Zero-history personalization is also supported by this scalable solution, and its 275 ms rate of adaptation allows successful real-time risk profiling of financial systems by shortening detection latency and improving payment network stability. Crucially, the 275 ms adaptation capability can enable real-time risk profiling for financial institutions, reducing systemic vulnerability detection latency significantly versus traditional compliance checks. By preventing contagion in payment networks (e.g., Fedwire), the framework strengthens national financial infrastructure resilience.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§é’ˆå¯¹æç¤ºå¾®è°ƒ(prompt-tuned)å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å…ƒå­¦ä¹ (meta-learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æ¨èç³»ç»Ÿåœ¨å†·å¯åŠ¨(cold-start)åœºæ™¯ä¸‹é€‚åº”æ€§å·®ä¸”ç»´æŠ¤æˆæœ¬é«˜çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡å°†æ¯ä¸ªç”¨æˆ·è§†ä¸ºç‹¬ç«‹ä»»åŠ¡ï¼Œåˆ©ç”¨ä¸€é˜¶(Reptile)å’ŒäºŒé˜¶(MAML)ä¼˜åŒ–ç®—æ³•å­¦ä¹ è½¯æç¤ºåµŒå…¥(soft prompt embeddings)ï¼Œå¹¶å°†å…¶ä½œä¸ºä»£è¡¨ç”¨æˆ·è¡Œä¸ºå…ˆéªŒ(user behavioral priors)çš„å¯å¾®æ§åˆ¶å˜é‡ã€‚æ¨¡å‹é€šè¿‡æƒ…å¢ƒé‡‡æ ·(episodic sampling)ã€å†…å¾ªç¯é€‚åº”(inner-loop adaptation)å’Œå¤–å¾ªç¯æ³›åŒ–(outer-loop generalization)å®ç°æç¤ºè¯çš„å…ƒä¼˜åŒ–ã€‚åœ¨MovieLens-1Mã€Amazon Reviewså’ŒRecboleæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨NDCG@10ã€HR@10å’ŒMRRç­‰æŒ‡æ ‡ä¸Šå‡ä¼˜äºåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆæ”¯æŒå®æ—¶(ä½äº300æ¯«ç§’)çš„é›¶å†å²è®°å½•ä¸ªæ€§åŒ–æ¨èï¼Œå¹¶èƒ½æœ‰æ•ˆåº”ç”¨äºé‡‘èç³»ç»Ÿçš„å®æ—¶é£é™©ç”»åƒ(risk profiling)ï¼Œé€šè¿‡æ˜¾è‘—é™ä½æ£€æµ‹å»¶è¿Ÿå¢å¼ºäº†å›½å®¶é‡‘èåŸºç¡€è®¾æ–½çš„éŸ§æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16672v1",
      "published_date": "2025-07-22 15:07:23 UTC",
      "updated_date": "2025-07-22 15:07:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:24.387731+00:00"
    },
    {
      "arxiv_id": "2507.16670v1",
      "title": "Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains",
      "title_zh": "åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„åŠ¨æ€å†œäº§å“ä¾›åº”é“¾è‡ªé€‚åº”åº“å­˜ç­–ç•¥",
      "authors": [
        "Amandeep Kaur",
        "Gyan Prakash"
      ],
      "abstract": "Agricultural products are often subject to seasonal fluctuations in production and demand. Predicting and managing inventory levels in response to these variations can be challenging, leading to either excess inventory or stockouts. Additionally, the coordination among stakeholders at various level of food supply chain is not considered in the existing body of literature. To bridge these research gaps, this study focuses on inventory management of agri-food products under demand and lead time uncertainties. By implementing effective inventory replenishment policy results in maximize the overall profit throughout the supply chain. However, the complexity of the problem increases due to these uncertainties and shelf-life of the product, that makes challenging to implement traditional approaches to generate optimal set of solutions. Thus, the current study propose a novel Deep Reinforcement Learning (DRL) algorithm that combines the benefits of both value- and policy-based DRL approaches for inventory optimization under uncertainties. The proposed algorithm can incentivize collaboration among stakeholders by aligning their interests and objectives through shared optimization goal of maximizing profitability along the agri-food supply chain while considering perishability, and uncertainty simultaneously. By selecting optimal order quantities with continuous action space, the proposed algorithm effectively addresses the inventory optimization challenges. To rigorously evaluate this algorithm, the empirical data from fresh agricultural products supply chain inventory is considered. Experimental results corroborate the improved performance of the proposed inventory replenishment policy under stochastic demand patterns and lead time scenarios. The research findings hold managerial implications for policymakers to manage the inventory of agricultural products more effectively under uncertainty.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†œäº§å“ä¾›åº”é“¾ä¸­ç”Ÿäº§ä¸éœ€æ±‚çš„å­£èŠ‚æ€§æ³¢åŠ¨ï¼Œä»¥åŠéœ€æ±‚å’Œ lead time çš„ä¸ç¡®å®šæ€§å¯¼è‡´åº“å­˜ç®¡ç†å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆä»·å€¼å‹ï¼ˆvalue-basedï¼‰ä¸ç­–ç•¥å‹ï¼ˆpolicy-basedï¼‰ä¼˜åŠ¿çš„æ–°å‹ Deep Reinforcement Learning (DRL) ç®—æ³•ã€‚è¯¥ç®—æ³•é€šè¿‡å»ºç«‹æœ€å¤§åŒ–ä¾›åº”é“¾æ•´ä½“ç›ˆåˆ©çš„å…±äº«ä¼˜åŒ–ç›®æ ‡ï¼Œæœ‰æ•ˆåè°ƒäº†å„åˆ©ç›Šç›¸å…³è€…çš„ç›®æ ‡å†²çªï¼Œå¹¶åŒæ—¶è€ƒè™‘äº†äº§å“çš„æ˜“è…æ€§ï¼ˆperishabilityï¼‰å’Œç¯å¢ƒçš„ä¸ç¡®å®šæ€§ã€‚é€šè¿‡åœ¨è¿ç»­åŠ¨ä½œç©ºé—´ï¼ˆcontinuous action spaceï¼‰ä¸­é€‰æ‹©æœ€ä¼˜è®¢è´§é‡ï¼Œè¯¥ DRL æ¡†æ¶æœ‰æ•ˆè§£å†³äº†å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„åº“å­˜ä¼˜åŒ–æŒ‘æˆ˜ã€‚åŸºäºæ–°é²œå†œäº§å“ä¾›åº”é“¾å®è¯æ•°æ®çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æç­–ç•¥åœ¨éšæœºéœ€æ±‚å’Œæå‰æœŸæ³¢åŠ¨åœºæ™¯ä¸‹å‡è¡¨ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶æˆæœä¸ºæ”¿ç­–åˆ¶å®šè€…åœ¨ä¸ç¡®å®šæ€§ä¸‹å®ç°å†œäº§å“åº“å­˜çš„é«˜æ•ˆç®¡ç†æä¾›äº†é‡è¦çš„ç®¡ç†å¯ç¤ºï¼ˆmanagerial implicationsï¼‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16670v1",
      "published_date": "2025-07-22 15:02:54 UTC",
      "updated_date": "2025-07-22 15:02:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:28.883982+00:00"
    },
    {
      "arxiv_id": "2507.16880v2",
      "title": "Finding Dori: Memorization in Text-to-Image Diffusion Models Is Not Local",
      "title_zh": "Finding Doriï¼šæ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰©æ•£æ¨¡å‹ä¸­è®°å¿†æ•ˆåº”çš„éå±€éƒ¨æ€§ç ”ç©¶",
      "authors": [
        "Antoni Kowalczuk",
        "Dominik Hintersdorf",
        "Lukas Struppek",
        "Kristian Kersting",
        "Adam Dziedzic",
        "Franziska Boenisch"
      ],
      "abstract": "Text-to-image diffusion models (DMs) have achieved remarkable success in image generation. However, concerns about data privacy and intellectual property remain due to their potential to inadvertently memorize and replicate training data. Recent mitigation efforts have focused on identifying and pruning weights responsible for triggering verbatim training data replication, based on the assumption that memorization can be localized. We challenge this assumption and demonstrate that, even after such pruning, small perturbations to the text embeddings of previously mitigated prompts can re-trigger data replication, revealing the fragility of such defenses. Our further analysis then provides multiple indications that memorization is indeed not inherently local: (1) replication triggers for memorized images are distributed throughout text embedding space; (2) embeddings yielding the same replicated image produce divergent model activations; and (3) different pruning methods identify inconsistent sets of memorization-related weights for the same image. Finally, we show that bypassing the locality assumption enables more robust mitigation through adversarial fine-tuning. These findings provide new insights into the nature of memorization in text-to-image DMs and inform the development of more reliable mitigations against DM memorization.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–‡æœ¬ç”Ÿæˆå›¾åƒæ‰©æ•£æ¨¡å‹ (Diffusion Models, DMs) ä¸­çš„è®°å¿†ä¸å¤åˆ¶é—®é¢˜ï¼Œå¹¶æŒ‘æˆ˜äº†è®°å¿†å¯ä»¥è¢«å±€éƒ¨åŒ– (localized) çš„ç°æœ‰å‡è®¾ã€‚ç ”ç©¶å‘ç°ï¼Œå³ä¾¿ä¿®å‰ªäº†è¢«è®¤ä¸ºè´Ÿè´£è§¦å‘æ•°æ®å¤ç°çš„æƒé‡ï¼Œé€šè¿‡å¯¹æ–‡æœ¬åµŒå…¥ (text embeddings) è¿›è¡Œå¾®å°æ‰°åŠ¨ä»èƒ½é‡æ–°è§¦å‘æ•°æ®å¤åˆ¶ï¼Œæ­ç¤ºäº†å½“å‰é˜²å¾¡æ‰‹æ®µçš„è„†å¼±æ€§ã€‚é€šè¿‡æ·±å…¥åˆ†æï¼Œä½œè€…è¯æ˜äº†è®°å¿†åœ¨æ‰©æ•£æ¨¡å‹ä¸­å¹¶éå¤©ç”Ÿå±€éƒ¨ï¼šå¤ç°è§¦å‘å™¨å¹¿æ³›åˆ†å¸ƒåœ¨åµŒå…¥ç©ºé—´ä¸­ï¼Œä¸”ä¸åŒçš„ä¿®å‰ªæ–¹æ³•é’ˆå¯¹åŒä¸€å›¾åƒè¯†åˆ«å‡ºçš„ç›¸å…³æƒé‡é›†å¹¶ä¸ä¸€è‡´ã€‚åŸºäºè¿™äº›å‘ç°ï¼Œç ”ç©¶æå‡ºé€šè¿‡å¯¹æŠ—æ€§å¾®è°ƒ (adversarial fine-tuning) ç»•è¿‡å±€éƒ¨åŒ–å‡è®¾ï¼Œä»è€Œå®ç°æ›´å…·é²æ£’æ€§çš„ç¼“è§£æ•ˆæœã€‚è¿™äº›ç ”ç©¶æˆæœä¸ºç†è§£æ‰©æ•£æ¨¡å‹çš„è®°å¿†æœ¬è´¨æä¾›äº†æ–°è§†è§’ï¼Œå¹¶ä¸ºå¼€å‘æ›´å¯é çš„éšç§ä¿æŠ¤å’Œç‰ˆæƒé˜²å¾¡æŠ€æœ¯å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16880v2",
      "published_date": "2025-07-22 15:02:38 UTC",
      "updated_date": "2025-10-14 06:59:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:29.381001+00:00"
    },
    {
      "arxiv_id": "2507.16663v2",
      "title": "Turning Internal Gap into Self-Improvement: Promoting the Generation-Understanding Unification in MLLMs",
      "title_zh": "å°†å†…éƒ¨å·®è·è½¬åŒ–ä¸ºè‡ªæˆ‘æå‡ï¼šæ¨åŠ¨ MLLMs ç”Ÿæˆä¸ç†è§£çš„ç»Ÿä¸€",
      "authors": [
        "Yujin Han",
        "Hao Chen",
        "Andi Han",
        "Zhiheng Wang",
        "Xinyu Liu",
        "Yingya Zhang",
        "Shiwei Zhang",
        "Difan Zou"
      ],
      "abstract": "Although unified MLLMs aim to unify generation and understanding, they are considered to exhibit an internal gap, with understanding outperforming generation. Through large-scale evaluation across multiple MLLMs and tasks, we confirm the widespread non-unification of MLLMs, and demonstrate that it indeed stems from weak generation rather than misunderstanding. This finding motivates us to propose a simple yet effective internal gap-based self-improvement framework, which mitigates internal gaps by leveraging stronger understanding to guide weaker generation without relying on any external signals. We validate this strategy through comprehensive experiments: scoring generations with understanding to construct image data for post-training (e.g., SFT and DPO) significantly improves generation while promoting unification. Furthermore, we empirically discover a co-improvement effect of such self-improvement, a phenomenon well known in pre-training but underexplored in post-training. Specifically, as generation improves, understanding becomes more effective at detecting false positives that were previously misclassified as prompt-aligned. To explain this effect, we extend learning dynamic theory to the MLLM setting, showing that the shared empirical neural tangent kernel between generation and understanding encourages aligned learning dynamics, thereby driving co-improvement. This interplay between generation and understanding further motivates a curriculum learning approach for stronger self-improvement: progressively enhanced understanding and generation revisit samples underutilized by pre-trained MLLMs, dynamically expanding post-training data and leading to improved performance and unification.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº†ç»Ÿä¸€å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (MLLMs) ä¸­ç”Ÿæˆä¸ç†è§£ä¸ç»Ÿä¸€çš„é—®é¢˜ï¼Œç¡®è®¤äº†æ¨¡å‹å†…éƒ¨æ™®éå­˜åœ¨ç†è§£èƒ½åŠ›ä¼˜äºç”Ÿæˆèƒ½åŠ›çš„ internal gapã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäº internal gap çš„è‡ªæˆ‘æ”¹è¿›æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨æ¨¡å‹è¾ƒå¼ºçš„ç†è§£èƒ½åŠ›æ¥å¼•å¯¼è¾ƒå¼±çš„ç”Ÿæˆèƒ½åŠ›ï¼Œè€Œæ— éœ€ä¾èµ–å¤–éƒ¨ä¿¡å·ã€‚å®éªŒè¯æ˜ï¼Œé€šè¿‡åˆ©ç”¨ç†è§£èƒ½åŠ›å¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œè¯„åˆ†ï¼Œå¹¶æ„å»ºç”¨äº SFT å’Œ DPO ç­‰åæœŸè®­ç»ƒçš„æ•°æ®ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡ç”Ÿæˆæ€§èƒ½å¹¶ä¿ƒè¿›ç”Ÿæˆä¸ç†è§£çš„ç»Ÿä¸€ã€‚ç ”ç©¶è¿˜å‘ç°äº†ä¸€ç§å…±åŒæ”¹è¿›æ•ˆåº” (co-improvement effect)ï¼Œå³ç”Ÿæˆèƒ½åŠ›çš„æå‡ä¼šåå‘å¢å¼ºç†è§£èƒ½åŠ›å¯¹å‡é˜³æ€§æ ·æœ¬çš„æ£€æµ‹æ•ˆç‡ã€‚ä½œè€…é€šè¿‡æ‰©å±•å­¦ä¹ åŠ¨åŠ›å­¦ç†è®º (learning dynamic theory) å¹¶åˆ©ç”¨ç»éªŒç¥ç»åˆ‡çº¿æ ¸ (empirical neural tangent kernel) é˜é‡Šäº†è¿™ä¸€ç°è±¡èƒŒåçš„å¯¹é½å­¦ä¹ æœºåˆ¶ã€‚æœ€åï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§è¯¾ç¨‹å­¦ä¹  (curriculum learning) æ–¹æ³•æ¥åŠ¨æ€æ‰©å±•åæœŸè®­ç»ƒæ•°æ®ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–äº†æ¨¡å‹çš„è‡ªæˆ‘æ”¹è¿›èƒ½åŠ›å’Œç»Ÿä¸€åŒ–æ°´å¹³ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 16 figures, 12 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16663v2",
      "published_date": "2025-07-22 14:56:39 UTC",
      "updated_date": "2025-09-25 11:17:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:34.186797+00:00"
    },
    {
      "arxiv_id": "2508.03711v1",
      "title": "A Social Data-Driven System for Identifying Estate-related Events and Topics",
      "title_zh": "ä¸€ç§ç”¨äºè¯†åˆ«æˆ¿äº§ç›¸å…³äº‹ä»¶ä¸è¯é¢˜çš„ç¤¾äº¤æ•°æ®é©±åŠ¨ç³»ç»Ÿ",
      "authors": [
        "Wenchuan Mu",
        "Menglin Li",
        "Kwan Hui Lim"
      ],
      "abstract": "Social media platforms such as Twitter and Facebook have become deeply embedded in our everyday life, offering a dynamic stream of localized news and personal experiences. The ubiquity of these platforms position them as valuable resources for identifying estate-related issues, especially in the context of growing urban populations. In this work, we present a language model-based system for the detection and classification of estate-related events from social media content. Our system employs a hierarchical classification framework to first filter relevant posts and then categorize them into actionable estate-related topics. Additionally, for posts lacking explicit geotags, we apply a transformer-based geolocation module to infer posting locations at the point-of-interest level. This integrated approach supports timely, data-driven insights for urban management, operational response and situational awareness.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäºç¤¾äº¤åª’ä½“æ•°æ®é©±åŠ¨çš„ç³»ç»Ÿï¼Œæ—¨åœ¨è¯†åˆ«å’Œåˆ†ç±»ä¸æˆ¿åœ°äº§(estate-related)ç›¸å…³çš„äº‹ä»¶å’Œè¯é¢˜ã€‚éšç€åŸå¸‚äººå£ä¸æ–­å¢é•¿ï¼ŒTwitterå’ŒFacebookç­‰å¹³å°å·²æˆä¸ºè·å–å±€éƒ¨æ–°é—»å’Œä¸ªäººä½“éªŒçš„é‡è¦èµ„æºã€‚ç³»ç»Ÿåˆ©ç”¨åŸºäºè¯­è¨€æ¨¡å‹çš„å±‚æ¬¡åŒ–åˆ†ç±»æ¡†æ¶(hierarchical classification framework)ï¼Œé¦–å…ˆç­›é€‰ç›¸å…³å¸–å­ï¼Œéšåå°†å…¶å½’ç±»ä¸ºå¯æ“ä½œçš„æˆ¿åœ°äº§ä¸»é¢˜ã€‚é’ˆå¯¹ç¼ºä¹æ˜¾å¼åœ°ç†æ ‡ç­¾çš„å¸–å­ï¼Œç ”ç©¶åº”ç”¨äº†ä¸€ä¸ªåŸºäºTransformerçš„åœ°ç†å®šä½æ¨¡å—(transformer-based geolocation module)ï¼Œèƒ½å¤Ÿåœ¨å…´è¶£ç‚¹(POI)çº§åˆ«æ¨æ–­å‘å¸–ä½ç½®ã€‚è¿™ç§é›†æˆæ–¹æ³•ä¸ºåŸå¸‚ç®¡ç†ã€è¿è¥å“åº”å’Œæ€åŠ¿æ„ŸçŸ¥æä¾›äº†åŠæ—¶çš„ã€æ•°æ®é©±åŠ¨çš„è§è§£ï¼Œå¢å¼ºäº†å¯¹åŸå¸‚ç¯å¢ƒçš„ç†è§£ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at ASONAM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.03711v1",
      "published_date": "2025-07-22 14:48:42 UTC",
      "updated_date": "2025-07-22 14:48:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:40.282938+00:00"
    },
    {
      "arxiv_id": "2507.16642v1",
      "title": "Towards Automated Regulatory Compliance Verification in Financial Auditing with Large Language Models",
      "title_zh": "è¿ˆå‘åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å®ç°è´¢åŠ¡å®¡è®¡ä¸­çš„è‡ªåŠ¨åŒ–ç›‘ç®¡åˆè§„éªŒè¯",
      "authors": [
        "Armin Berger",
        "Lars Hillebrand",
        "David Leonhard",
        "Tobias DeuÃŸer",
        "Thiago Bell Felix de Oliveira",
        "Tim Dilmaghani",
        "Mohamed Khaled",
        "Bernd Kliem",
        "RÃ¼diger Loitz",
        "Christian Bauckhage",
        "Rafet Sifa"
      ],
      "abstract": "The auditing of financial documents, historically a labor-intensive process, stands on the precipice of transformation. AI-driven solutions have made inroads into streamlining this process by recommending pertinent text passages from financial reports to align with the legal requirements of accounting standards. However, a glaring limitation remains: these systems commonly fall short in verifying if the recommended excerpts indeed comply with the specific legal mandates. Hence, in this paper, we probe the efficiency of publicly available Large Language Models (LLMs) in the realm of regulatory compliance across different model configurations. We place particular emphasis on comparing cutting-edge open-source LLMs, such as Llama-2, with their proprietary counterparts like OpenAI's GPT models. This comparative analysis leverages two custom datasets provided by our partner PricewaterhouseCoopers (PwC) Germany. We find that the open-source Llama-2 70 billion model demonstrates outstanding performance in detecting non-compliance or true negative occurrences, beating all their proprietary counterparts. Nevertheless, proprietary models such as GPT-4 perform the best in a broad variety of scenarios, particularly in non-English contexts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models) å®ç°é‡‘èå®¡è®¡ä¸­ç›‘ç®¡åˆè§„æ€§éªŒè¯ (Regulatory Compliance Verification) è‡ªåŠ¨åŒ–çš„å¯è¡Œæ€§ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ç³»ç»Ÿåœ¨éªŒè¯æ¨èæ–‡æœ¬æ˜¯å¦ç¬¦åˆä¼šè®¡å‡†åˆ™æ³•å¾‹è¦æ±‚æ–¹é¢çš„å±€é™ã€‚ä½œè€…åœ¨ä¸åŒé…ç½®ä¸‹å¯¹æ¯”åˆ†æäº† Llama-2 ç­‰å¼€æºæ¨¡å‹ä¸ OpenAI GPT ç³»åˆ—ç­‰ä¸“æœ‰æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶ä½¿ç”¨äº†ç”±æ™®åæ°¸é“å¾·å›½ (PwC Germany) æä¾›çš„ä¸¤ä¸ªå®šåˆ¶æ•°æ®é›†è¿›è¡Œè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œå¼€æºçš„ Llama-2 70B æ¨¡å‹åœ¨æ£€æµ‹éåˆè§„é¡¹æˆ–çœŸé˜´æ€§ (True Negative) å‘ç”Ÿæ–¹é¢è¡¨ç°å“è¶Šï¼Œç”šè‡³è¶…è¶Šäº†æ‰€æœ‰ä¸“æœ‰æ¨¡å‹ã€‚ç„¶è€Œï¼ŒGPT-4 ç­‰ä¸“æœ‰æ¨¡å‹åœ¨ç»å¤§å¤šæ•°åœºæ™¯ä¸‹ï¼Œå°¤å…¶æ˜¯åœ¨éè‹±è¯­è¯­å¢ƒä¸­ï¼Œä¾ç„¶ä¿æŒç€æœ€ä½³çš„æ•´ä½“æ€§èƒ½ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†ä¸åŒç±»å‹çš„ LLMs åœ¨å¤„ç†å¤æ‚åˆè§„ä»»åŠ¡æ—¶çš„å·®å¼‚åŒ–ä¼˜åŠ¿ï¼Œä¸ºé‡‘èå®¡è®¡çš„è‡ªåŠ¨åŒ–è½¬å‹æä¾›äº†é‡è¦çš„å®è¯ä¾æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted and published at BigData 2023, 10 pages, 3 figures, 5 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16642v1",
      "published_date": "2025-07-22 14:39:54 UTC",
      "updated_date": "2025-07-22 14:39:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:12:57.988440+00:00"
    },
    {
      "arxiv_id": "2507.16641v2",
      "title": "Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis",
      "title_zh": "åŸºäºæ··åˆå¥–åŠ±é©±åŠ¨å¼ºåŒ–å­¦ä¹ çš„é«˜æ•ˆé‡å­ç”µè·¯åˆæˆ",
      "authors": [
        "Sara Giordano",
        "Kornikar Sen",
        "Miguel A. Martin-Delgado"
      ],
      "abstract": "A reinforcement learning (RL) framework is introduced for the efficient synthesis of quantum circuits that generate specified target quantum states from a fixed initial state, addressing a central challenge in both the Noisy Intermediate-Scale Quantum (NISQ) era and future fault-tolerant quantum computing. The approach utilizes tabular Q-learning, based on action sequences, within a discretized quantum state space, to effectively manage the exponential growth of the space dimension.The framework introduces a hybrid reward mechanism, combining a static, domain-informed reward that guides the agent toward the target state with customizable dynamic penalties that discourage inefficient circuit structures such as gate congestion and redundant state revisits. This is a circuit-aware reward, in contrast to the current trend of works on this topic, which are primarily fidelity-based. By leveraging sparse matrix representations and state-space discretization, the method enables practical navigation of high-dimensional environments while minimizing computational overhead. Benchmarking on graph-state preparation tasks for up to seven qubits, we demonstrate that the algorithm consistently discovers minimal-depth circuits with optimized gate counts. Moreover, extending the framework to a universal gate set still yields low depth circuits, highlighting the algorithm robustness and adaptability. The results confirm that this RL-driven approach, with our completely circuit-aware method, efficiently explores the complex quantum state space and synthesizes near-optimal quantum circuits, providing a resource-efficient foundation for quantum circuit optimization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆå¥–åŠ±é©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œç”¨äºä»å›ºå®šåˆå§‹çŠ¶æ€é«˜æ•ˆåˆæˆç›®æ ‡é‡å­æ€ç”µè·¯ï¼Œæ—¨åœ¨è§£å†³NISQæ—¶ä»£å’Œæœªæ¥å®¹é”™é‡å­è®¡ç®—ä¸­çš„æ ¸å¿ƒæŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•åœ¨ç¦»æ•£åŒ–çš„é‡å­æ€ç©ºé—´ä¸­é‡‡ç”¨åŸºäºåŠ¨ä½œåºåˆ—çš„è¡¨æ ¼åŒ–Qå­¦ä¹ (tabular Q-learning)ï¼Œé€šè¿‡ç¨€ç–çŸ©é˜µè¡¨ç¤º(sparse matrix representations)æœ‰æ•ˆåº”å¯¹äº†çŠ¶æ€ç©ºé—´çš„æŒ‡æ•°çº§å¢é•¿ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†æ··åˆå¥–åŠ±æœºåˆ¶ï¼Œå°†å¼•å¯¼æ™ºèƒ½ä½“é è¿‘ç›®æ ‡æ€çš„é™æ€é¢†åŸŸå¥–åŠ±ä¸æŠ‘åˆ¶é—¨æ‹¥å µåŠå†—ä½™è®¿é—®çš„åŠ¨æ€æƒ©ç½šç›¸ç»“åˆï¼Œå®ç°äº†ç”µè·¯æ„ŸçŸ¥(circuit-aware)çš„æ·±åº¦ä¼˜åŒ–ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç®—æ³•åœ¨å¤šè¾¾7ä¸ªé‡å­æ¯”ç‰¹çš„å›¾æ€å‡†å¤‡ä»»åŠ¡ä¸­èƒ½å¤Ÿä¸€è‡´å‘ç°æœ€å°æ·±åº¦çš„é‡å­ç”µè·¯ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨é€šç”¨é—¨é›†ä¸‹ä¾ç„¶ä¿æŒäº†æé«˜çš„é²æ£’æ€§ï¼Œä¸ºèµ„æºé«˜æ•ˆçš„é‡å­ç”µè·¯åˆæˆä¸ä¼˜åŒ–å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "35 pages, 7 figures, color figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16641v2",
      "published_date": "2025-07-22 14:39:20 UTC",
      "updated_date": "2026-01-13 17:34:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:01.884708+00:00"
    },
    {
      "arxiv_id": "2507.16635v1",
      "title": "Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems",
      "title_zh": "é’ˆå¯¹é€šç”¨å·¥ä¸šè£…é…çº¿å¹³è¡¡é—®é¢˜çš„æ–°å‹å¤šæ™ºèƒ½ä½“åŠ¨ä½œé®ç½©æ·±åº¦å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Ali Mohamed Ali",
        "Luca Tirel",
        "Hashim A. Hashim"
      ],
      "abstract": "Efficient planning of activities is essential for modern industrial assembly lines to uphold manufacturing standards, prevent project constraint violations, and achieve cost-effective operations. While exact solutions to such challenges can be obtained through Integer Programming (IP), the dependence of the search space on input parameters often makes IP computationally infeasible for large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also be applied, but they frequently produce suboptimal solutions in extensive cases. This paper introduces a novel mathematical model of a generic industrial assembly line formulated as a Markov Decision Process (MDP), without imposing assumptions on the type of assembly line a notable distinction from most existing models. The proposed model is employed to create a virtual environment for training Deep Reinforcement Learning (DRL) agents to optimize task and resource scheduling. To enhance the efficiency of agent training, the paper proposes two innovative tools. The first is an action-masking technique, which ensures the agent selects only feasible actions, thereby reducing training time. The second is a multi-agent approach, where each workstation is managed by an individual agent, as a result, the state and action spaces were reduced. A centralized training framework with decentralized execution is adopted, offering a scalable learning architecture for optimizing industrial assembly lines. This framework allows the agents to learn offline and subsequently provide real-time solutions during operations by leveraging a neural network that maps the current factory state to the optimal action. The effectiveness of the proposed scheme is validated through numerical simulations, demonstrating significantly faster convergence to the optimal solution compared to a comparable model-based approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨å·¥ä¸šè£…é…çº¿å¹³è¡¡é—®é¢˜ï¼ˆGeneral Industrial Assembly Lines Balancing Problemsï¼‰ï¼Œæå‡ºäº†ä¸€ç§åŸºäºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMarkov Decision Process, MDPï¼‰çš„åˆ›æ–°æ•°å­¦æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ä¸å¯¹è£…é…çº¿ç±»å‹åšç‰¹å®šå‡è®¾ã€‚ä¸ºè§£å†³æ•´æ•°è§„åˆ’ï¼ˆInteger Programmingï¼‰å’Œå¯å‘å¼ç®—æ³•åœ¨å¤§è§„æ¨¡åœºæ™¯ä¸‹è®¡ç®—å—é™æˆ–è§£è´¨é‡ä¸ä½³çš„é—®é¢˜ï¼Œè®ºæ–‡é‡‡ç”¨æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDeep Reinforcement Learning, DRLï¼‰è¿›è¡Œä»»åŠ¡ä¸èµ„æºè°ƒåº¦ä¼˜åŒ–ã€‚ç ”ç©¶å¼•å…¥äº†åŠ¨ä½œæ©ç ï¼ˆAction-maskingï¼‰æŠ€æœ¯ä»¥ç¡®ä¿æ™ºèƒ½ä½“ä»…é€‰æ‹©å¯è¡Œæ“ä½œï¼Œä»è€Œæ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡ã€‚åŒæ—¶ï¼Œé€šè¿‡å¤šæ™ºèƒ½ä½“ï¼ˆMulti-agentï¼‰æ–¹æ³•ç”±ç‹¬ç«‹æ™ºèƒ½ä½“ç®¡ç†å„ä¸ªå·¥ä½œç«™ï¼Œæœ‰æ•ˆç¼©å°äº†çŠ¶æ€å’ŒåŠ¨ä½œç©ºé—´ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨é›†ä¸­å¼è®­ç»ƒåˆ†å¸ƒå¼æ‰§è¡Œï¼ˆCentralized training with decentralized executionï¼‰æ¡†æ¶ï¼Œå®ç°äº†å¯æ‰©å±•çš„ç¦»çº¿å­¦ä¹ ä¸å®æ—¶åœ¨çº¿å†³ç­–ã€‚æ•°å€¼ä»¿çœŸç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆæ¯”åŒç±»æ¨¡å‹é©±åŠ¨æ–¹æ³•å…·æœ‰æ›´å¿«çš„æ”¶æ•›é€Ÿåº¦ï¼Œèƒ½å¤Ÿé«˜æ•ˆåœ°ä¸ºå¤æ‚çš„å·¥ä¸šç”Ÿäº§ç¯å¢ƒæä¾›æœ€ä¼˜è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16635v1",
      "published_date": "2025-07-22 14:34:36 UTC",
      "updated_date": "2025-07-22 14:34:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:05.791826+00:00"
    },
    {
      "arxiv_id": "2507.17776v1",
      "title": "Axiomatizing Rumsfeld Ignorance",
      "title_zh": "Rumsfeld æ— çŸ¥çš„å…¬ç†åŒ–",
      "authors": [
        "Jie Fan"
      ],
      "abstract": "In a recent paper, Kit Fine presents some striking results concerning the logical properties of (first-order) ignorance, second-order ignorance and Rumsfeld ignorance. However, Rumsfeld ignorance is definable in terms of ignorance, which makes some existing results and the axiomatization problem trivial. A main reason is that the accessibility relations for the implicit knowledge operator contained in the packaged operators of ignorance and Rumsfeld ignorance are the same. In this work, we assume the two accessibility relations to be different so that one of them is an arbitrary subset of the other. This will avoid the definability issue and retain most of the previous validities. The main results are axiomatizations over various proper bi-frame classes. Finally we apply our framework to analyze Fine's results.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Kit Fine å…³äº first-order ignoranceã€second-order ignorance å’Œ Rumsfeld ignorance é€»è¾‘å±æ€§çš„ç ”ç©¶ï¼Œè§£å†³äº† Rumsfeld ignorance å›  accessibility relations ç›¸åŒè€Œå¯¼è‡´çš„å¯å®šä¹‰æ€§ (definability) é—®é¢˜ã€‚é€šè¿‡å‡è®¾ä¸¤ç§ä¸åŒçš„ accessibility relationsï¼Œä½¿å¾—å…¶ä¸­ä¸€ä¸ªä¸ºå¦ä¸€ä¸ªçš„ä»»æ„å­é›†ï¼Œè¯¥æ¡†æ¶æˆåŠŸé¿å…äº†é€»è¾‘å®šä¹‰çš„å¹³å‡¡åŒ–ï¼Œå¹¶ä¿ç•™äº†å¤§éƒ¨åˆ†å…ˆå‰çš„æœ‰æ•ˆæ€§ã€‚æœ¬æ–‡çš„ä¸»è¦æˆæœæ˜¯åœ¨å¤šç§ proper bi-frame ç±»ä¸Šå®ç°äº†å…¬ç†åŒ– (axiomatizations)ï¼Œä¸ºç›¸å…³é€»è¾‘æä¾›äº†ä¸¥è°¨çš„æ•°å­¦åŸºç¡€ã€‚æœ€åï¼Œè¯¥ç ”ç©¶åº”ç”¨æ‰€æå‡ºçš„æ¡†æ¶å¯¹ Fine çš„ç»“è®ºè¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œæ­ç¤ºäº†ä¸åŒå±‚é¢æ— çŸ¥ä¹‹é—´çš„å¤æ‚é€»è¾‘è”ç³»ã€‚",
      "categories": [
        "math.LO",
        "cs.AI"
      ],
      "primary_category": "math.LO",
      "comment": "This is an almost-final version",
      "pdf_url": "https://arxiv.org/pdf/2507.17776v1",
      "published_date": "2025-07-22 14:25:53 UTC",
      "updated_date": "2025-07-22 14:25:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:20.394908+00:00"
    },
    {
      "arxiv_id": "2507.21133v1",
      "title": "Analysis of Threat-Based Manipulation in Large Language Models: A Dual Perspective on Vulnerabilities and Performance Enhancement Opportunities",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºå¨èƒçš„æ“æ§åˆ†æï¼šè„†å¼±æ€§ä¸æ€§èƒ½æå‡æœºé‡çš„åŒé‡è§†è§’",
      "authors": [
        "Atil Samancioglu"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate complex responses to threat-based manipulations, revealing both vulnerabilities and unexpected performance enhancement opportunities. This study presents a comprehensive analysis of 3,390 experimental responses from three major LLMs (Claude, GPT-4, Gemini) across 10 task domains under 6 threat conditions. We introduce a novel threat taxonomy and multi-metric evaluation framework to quantify both negative manipulation effects and positive performance improvements. Results reveal systematic vulnerabilities, with policy evaluation showing the highest metric significance rates under role-based threats, alongside substantial performance enhancements in numerous cases with effect sizes up to +1336%. Statistical analysis indicates systematic certainty manipulation (pFDR < 0.0001) and significant improvements in analytical depth and response quality. These findings have dual implications for AI safety and practical prompt engineering in high-stakes applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹(LLMs)å¯¹åŸºäºå¨èƒçš„æ“çºµ(threat-based manipulations)çš„å¤æ‚å“åº”ï¼Œæ­ç¤ºäº†å…¶è„†å¼±æ€§ä¸æ½œåœ¨çš„æ€§èƒ½æå‡æœºä¼šã€‚ç ”ç©¶äººå‘˜é€šè¿‡åˆ†æClaudeã€GPT-4å’ŒGeminiåœ¨10ä¸ªä»»åŠ¡é¢†åŸŸåŠ6ç§å¨èƒæ¡ä»¶ä¸‹çš„3,390ä¸ªå“åº”ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹å¨èƒåˆ†ç±»æ³•(threat taxonomy)å’Œå¤šæŒ‡æ ‡è¯„ä¼°æ¡†æ¶ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨åŸºäºè§’è‰²çš„å¨èƒ(role-based threats)ä¸‹çš„æ”¿ç­–è¯„ä¼°ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„è„†å¼±æ€§ï¼Œä½†åŒæ—¶åœ¨å¤šä¸ªæ¡ˆä¾‹ä¸­å®ç°äº†é«˜è¾¾+1336%çš„æ€§èƒ½æå‡ã€‚ç»Ÿè®¡åˆ†æè¯å®äº†å¨èƒæ“çºµå¯¹æ¨¡å‹ç¡®å®šæ€§(certainty manipulation)çš„ç³»ç»Ÿæ€§å½±å“ï¼Œä»¥åŠå¯¹åˆ†ææ·±åº¦å’Œå“åº”è´¨é‡çš„æ”¹å–„ã€‚è¯¥ç ”ç©¶ç»“è®ºä¸ºäººå·¥æ™ºèƒ½å®‰å…¨(AI safety)å’Œé«˜é£é™©åœºæ™¯ä¸‹çš„æç¤ºå·¥ç¨‹(prompt engineering)æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.21133v1",
      "published_date": "2025-07-22 14:13:08 UTC",
      "updated_date": "2025-07-22 14:13:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:11.083727+00:00"
    },
    {
      "arxiv_id": "2507.21132v1",
      "title": "Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses",
      "title_zh": "ä½ èƒ½å°†å…³ä¹äººç”Ÿçš„é‡å¤§æŠ‰æ‹©æ‰˜ä»˜ç»™å¤§è¯­è¨€æ¨¡å‹å—ï¼Ÿä¸€é¡¹å…³äº AI é«˜é£é™©å“åº”çš„è°ƒæŸ¥ç ”ç©¶",
      "authors": [
        "Joshua Adrian Cahyono",
        "Saran Subramanian"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly consulted for high-stakes life advice, yet they lack standard safeguards against providing confident but misguided responses. This creates risks of sycophancy and over-confidence. This paper investigates these failure modes through three experiments: (1) a multiple-choice evaluation to measure model stability against user pressure; (2) a free-response analysis using a novel safety typology and an LLM Judge; and (3) a mechanistic interpretability experiment to steer model behavior by manipulating a \"high-stakes\" activation vector. Our results show that while some models exhibit sycophancy, others like o4-mini remain robust. Top-performing models achieve high safety scores by frequently asking clarifying questions, a key feature of a safe, inquisitive approach, rather than issuing prescriptive advice. Furthermore, we demonstrate that a model's cautiousness can be directly controlled via activation steering, suggesting a new path for safety alignment. These findings underscore the need for nuanced, multi-faceted benchmarks to ensure LLMs can be trusted with life-changing decisions.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶è°ƒæŸ¥äº†å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æä¾›é«˜é£é™©äººç”Ÿå»ºè®®æ—¶çš„å¯é æ€§ï¼Œåˆ†æäº†å…¶å¯èƒ½å­˜åœ¨çš„è®¨å¥½ (sycophancy) ä¸è¿‡åº¦è‡ªä¿¡ç­‰å¤±æ•ˆæ¨¡å¼ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¤šé¡¹é€‰æ‹©å‹åŠ›æµ‹è¯•ã€è‡ªç”±å›ç­”å®‰å…¨è¯„ä¼°ä»¥åŠåˆ©ç”¨æœºæ¢°è§£é‡Šæ€§ (mechanistic interpretability) è¿›è¡Œæ¿€æ´»å¼•å¯¼çš„ä¸‰é‡å®éªŒå±•å¼€åˆ†æã€‚ç»“æœå‘ç°ï¼Œå°½ç®¡éƒ¨åˆ†æ¨¡å‹è¡¨ç°å‡ºè®¨å¥½å€¾å‘ï¼Œä½† o4-mini ç­‰æ¨¡å‹å±•ç°äº†æå¼ºçš„é²æ£’æ€§ï¼Œä¸”è¡¨ç°ä¼˜å¼‚çš„æ¨¡å‹å¾€å¾€é€šè¿‡æé—®è€Œéç»™å‡ºæŒ‡ä»¤æ€§å»ºè®®æ¥ç¡®ä¿å®‰å…¨ã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥è¯å®ï¼Œé€šè¿‡æ“çºµâ€œé«˜é£é™©â€æ¿€æ´»å‘é‡å¯ä»¥æœ‰æ•ˆæ§åˆ¶æ¨¡å‹çš„è°¨æ…ç¨‹åº¦ï¼Œä¸ºå®‰å…¨å¯¹é½ (safety alignment) æä¾›äº†æ–°æ€è·¯ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†å»ºç«‹å¤šç»´åº¦åŸºå‡†æµ‹è¯•çš„å¿…è¦æ€§ï¼Œä»è€Œç¡®ä¿ LLMs åœ¨åº”å¯¹é‡å¤§å†³ç­–æ—¶çš„å¯ä¿¡èµ–æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.21132v1",
      "published_date": "2025-07-22 14:11:13 UTC",
      "updated_date": "2025-07-22 14:11:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:21.483017+00:00"
    },
    {
      "arxiv_id": "2507.16594v1",
      "title": "An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes",
      "title_zh": "è¶…ä½åŠŸè€—è¾¹ç¼˜/ç‰©è”ç½‘èŠ‚ç‚¹ä¸Š TinyML æ‹†åˆ†å­¦ä¹ çš„å®éªŒç ”ç©¶",
      "authors": [
        "Zied Jenhani",
        "Mounir Bensalem",
        "Jasenka DizdareviÄ‡",
        "Admela Jukan"
      ],
      "abstract": "Running deep learning inference directly on ultra-low-power edge/IoT nodes has been limited by the tight memory and compute budgets of microcontrollers. Split learning (SL) addresses this limitation in which it executes part of the inference process on the sensor and off-loads the remainder to a companion device. In the context of constrained devices and the related impact of low-power, over-the-air transport protocols, the performance of split learning remains largely unexplored. TO the best of our knowledge, this paper presents the first end-to-end TinyML + SL testbed built on Espressif ESP32-S3 boards, designed to benchmark the over-the-air performance of split learning TinyML in edge/IoT environments. We benchmark the performance of a MobileNetV2 image recognition model, which is quantized to 8-bit integers, partitioned, and delivered to the nodes via over-the-air updates. The intermediate activations are exchanged through different wireless communication methods: ESP-NOW, BLE, and traditional UDP/IP and TCP/IP, enabling a head-to-head comparison on identical hardware. Measurements show that splitting the model after block_16_project_BN layer generates a 5.66 kB tensor that traverses the link in 3.2 ms, when UDP is used, achieving a steady-state round-trip latency of 5.8 s. ESP-NOW presents the most favorable RTT performance 3.7 s; BLE extends battery life further but increases latency beyond 10s.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…ä½åŠŸè€—è¾¹ç¼˜/IoTèŠ‚ç‚¹ä¸­å¾®æ§åˆ¶å™¨å†…å­˜å’Œè®¡ç®—èµ„æºå—é™çš„é—®é¢˜ï¼Œæ¢è®¨äº†æ‹†åˆ†å­¦ä¹ (Split Learning)åœ¨TinyMLä¸­çš„åº”ç”¨ã€‚ä½œè€…æ„å»ºäº†é¦–ä¸ªåŸºäºEspressif ESP32-S3å¼€å‘æ¿çš„ç«¯åˆ°ç«¯ TinyML + SL å®éªŒåºŠï¼Œæ—¨åœ¨åŸºå‡†æµ‹è¯•è¾¹ç¼˜/IoTç¯å¢ƒä¸‹æ‹†åˆ†å­¦ä¹ TinyMLçš„æ— çº¿æ€§èƒ½ã€‚å®éªŒé‡‡ç”¨ç»è¿‡8ä½æ•´å‹é‡åŒ–(8-bit integers)çš„MobileNetV2å›¾åƒè¯†åˆ«æ¨¡å‹ï¼Œå¹¶åœ¨ESP-NOWã€BLEã€UDP/IPå’ŒTCP/IPç­‰å¤šç§é€šä¿¡åè®®ä¸‹è¿›è¡Œäº†å¯¹æ¯”åˆ†æã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨block_16_project_BNå±‚è¿›è¡Œæ¨¡å‹æ‹†åˆ†å¯äº§ç”Ÿ5.66 kBçš„å¼ é‡ï¼Œä½¿ç”¨UDPä¼ è¾“æ—¶çš„ç¨³å®šå¾€è¿”å»¶è¿Ÿä¸º5.8ç§’ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒESP-NOWåœ¨å¾€è¿”æ—¶é—´(RTT)æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œä»…ä¸º3.7ç§’ï¼Œè€ŒBLEè™½ç„¶æœ‰åˆ©äºå»¶é•¿ç”µæ± å¯¿å‘½ï¼Œä½†å»¶è¿Ÿä¼šå¢åŠ è‡³10ç§’ä»¥ä¸Šã€‚è¯¥ç ”ç©¶ä¸ºå—é™èµ„æºèŠ‚ç‚¹ä¸Šçš„åˆ†å¸ƒå¼æ·±åº¦å­¦ä¹ æ¨ç†æ€§èƒ½ä¼˜åŒ–æä¾›äº†é‡è¦çš„å®éªŒä¾æ®ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NI",
      "comment": "This paper is uploaded here for research community, thus it is for non-commercial purposes",
      "pdf_url": "https://arxiv.org/pdf/2507.16594v1",
      "published_date": "2025-07-22 13:50:12 UTC",
      "updated_date": "2025-07-22 13:50:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:24.987075+00:00"
    },
    {
      "arxiv_id": "2507.16586v1",
      "title": "AI for Better UX in Computer-Aided Engineering: Is Academia Catching Up with Industry Demands? A Multivocal Literature Review",
      "title_zh": "äººå·¥æ™ºèƒ½ä¼˜åŒ–è®¡ç®—æœºè¾…åŠ©å·¥ç¨‹ç”¨æˆ·ä½“éªŒï¼šå­¦æœ¯ç ”ç©¶æ˜¯å¦å¥‘åˆå·¥ä¸šç•Œéœ€æ±‚ï¼Ÿä¸€é¡¹å¤šå…ƒæ–‡çŒ®ç»¼è¿°",
      "authors": [
        "Choro Ulan Uulu",
        "Mikhail Kulyabin",
        "Layan Etaiwi",
        "Nuno Miguel Martins Pacheco",
        "Jan Joosten",
        "Kerstin RÃ¶se",
        "Filippos Petridis",
        "Jan Bosch",
        "Helena HolmstrÃ¶m Olsson"
      ],
      "abstract": "Computer-Aided Engineering (CAE) enables simulation experts to optimize complex models, but faces challenges in user experience (UX) that limit efficiency and accessibility. While artificial intelligence (AI) has demonstrated potential to enhance CAE processes, research integrating these fields with a focus on UX remains fragmented. This paper presents a multivocal literature review (MLR) examining how AI enhances UX in CAE software across both academic research and industry implementations. Our analysis reveals significant gaps between academic explorations and industry applications, with companies actively implementing LLMs, adaptive UIs, and recommender systems while academic research focuses primarily on technical capabilities without UX validation. Key findings demonstrate opportunities in AI-powered guidance, adaptive interfaces, and workflow automation that remain underexplored in current research. By mapping the intersection of these domains, this study provides a foundation for future work to address the identified research gaps and advance the integration of AI to improve CAE user experience.",
      "tldr_zh": "æœ¬ç ”ç©¶é€šè¿‡å¤šå£°éƒ¨æ–‡çŒ®ç»¼è¿°(Multivocal Literature Review)æ¢è®¨äº†äººå·¥æ™ºèƒ½(AI)å¦‚ä½•æå‡è®¡ç®—æœºè¾…åŠ©å·¥ç¨‹(CAE)è½¯ä»¶çš„ç”¨æˆ·ä½“éªŒ(UX)ï¼Œç³»ç»Ÿåˆ†æäº†å­¦æœ¯ç•Œä¸å·¥ä¸šç•Œåœ¨è¿™ä¸€äº¤å‰é¢†åŸŸçš„åº”ç”¨ç°çŠ¶ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶å·¥ä¸šç•Œå·²åœ¨ç§¯æéƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹(LLMs)ã€è‡ªé€‚åº”ç•Œé¢(Adaptive UIs)å’Œæ¨èç³»ç»Ÿ(Recommender Systems)ï¼Œä½†å­¦æœ¯ç ”ç©¶ä»ä¸»è¦èšç„¦äºæŠ€æœ¯æ€§èƒ½ï¼Œç¼ºä¹å¯¹UXç»´åº¦çš„å®è¯éªŒè¯ã€‚åˆ†ææ­ç¤ºäº†åŒæ–¹åœ¨AIé©±åŠ¨å¼•å¯¼ã€ç•Œé¢è‡ªé€‚åº”åŠå·¥ä½œæµè‡ªåŠ¨åŒ–(Workflow Automation)ç­‰å…³é”®é¢†åŸŸå­˜åœ¨æ˜¾è‘—å·®è·ã€‚è¯¥ç ”ç©¶æŒ‡å‡ºäº†å½“å‰å­¦æœ¯ç ”ç©¶ä¸å·¥ä¸šéœ€æ±‚ä¹‹é—´çš„ä¸å¹³è¡¡ï¼Œä¸ºæœªæ¥å¡«è¡¥ç ”ç©¶é¸¿æ²Ÿå¹¶åˆ©ç”¨AIæŠ€æœ¯ä¼˜åŒ–CAEå·¥å…·çš„æ•ˆç‡ä¸å¯è®¿é—®æ€§æä¾›äº†ç†è®ºåŸºç¡€å’Œå®è·µæ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16586v1",
      "published_date": "2025-07-22 13:39:45 UTC",
      "updated_date": "2025-07-22 13:39:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:26.902418+00:00"
    },
    {
      "arxiv_id": "2507.16579v1",
      "title": "Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis",
      "title_zh": "ç”¨äºå›¾åƒåˆæˆçš„é‡‘å­—å¡”å±‚çº§æ©ç æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Xiaojiao Xiao",
        "Qinmin Vivian Hu",
        "Guanghui Wang"
      ],
      "abstract": "Medical image synthesis plays a crucial role in clinical workflows, addressing the common issue of missing imaging modalities due to factors such as extended scan times, scan corruption, artifacts, patient motion, and intolerance to contrast agents. The paper presents a novel image synthesis network, the Pyramid Hierarchical Masked Diffusion Model (PHMDiff), which employs a multi-scale hierarchical approach for more detailed control over synthesizing high-quality images across different resolutions and layers. Specifically, this model utilizes randomly multi-scale high-proportion masks to speed up diffusion model training, and balances detail fidelity and overall structure. The integration of a Transformer-based Diffusion model process incorporates cross-granularity regularization, modeling the mutual information consistency across each granularity's latent spaces, thereby enhancing pixel-level perceptual accuracy. Comprehensive experiments on two challenging datasets demonstrate that PHMDiff achieves superior performance in both the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM), highlighting its capability to produce high-quality synthesized images with excellent structural integrity. Ablation studies further confirm the contributions of each component. Furthermore, the PHMDiff model, a multi-scale image synthesis framework across and within medical imaging modalities, shows significant advantages over other methods. The source code is available at https://github.com/xiaojiao929/PHMDiff",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Pyramid Hierarchical Masked Diffusion Model (PHMDiff)ï¼Œè¿™æ˜¯ä¸€ç§å¤šå°ºåº¦åˆ†å±‚å½±åƒåˆæˆç½‘ç»œï¼Œæ—¨åœ¨è§£å†³ä¸´åºŠå·¥ä½œæµä¸­å› æ‰«ææ—¶é—´é•¿æˆ–ä¼ªå½±å¯¼è‡´çš„åŒ»å­¦å½±åƒæ¨¡æ€ç¼ºå¤±é—®é¢˜ã€‚è¯¥æ¨¡å‹åˆ©ç”¨éšæœºå¤šå°ºåº¦é«˜æ¯”ä¾‹æ©ç  (high-proportion masks) æŠ€æœ¯ï¼Œåœ¨æ˜¾è‘—åŠ é€Ÿæ‰©æ•£æ¨¡å‹è®­ç»ƒçš„åŒæ—¶ï¼Œå®ç°äº†ç»†èŠ‚ä¿çœŸåº¦ä¸æ•´ä½“ç»“æ„çš„å¹³è¡¡ã€‚æ ¸å¿ƒæ¶æ„é›†æˆäº†åŸºäº Transformer çš„æ‰©æ•£è¿‡ç¨‹ï¼Œå¹¶å¼•å…¥äº†è·¨ç²’åº¦æ­£åˆ™åŒ– (cross-granularity regularization) æœºåˆ¶ï¼Œé€šè¿‡å»ºæ¨¡ä¸åŒç²’åº¦æ½œç©ºé—´ä¹‹é—´çš„äº’ä¿¡æ¯ä¸€è‡´æ€§æ¥å¢å¼ºåƒç´ çº§æ„ŸçŸ¥å‡†ç¡®æ€§ã€‚åœ¨ä¸¤ä¸ªæŒ‘æˆ˜æ€§æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒPHMDiff åœ¨å³°å€¼ä¿¡å™ªæ¯” (PSNR) å’Œç»“æ„ç›¸ä¼¼æ€§ (SSIM) æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†ä¼˜å¼‚æ€§èƒ½ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿç”Ÿæˆå…·æœ‰é«˜åº¦ç»“æ„å®Œæ•´æ€§çš„é«˜è´¨é‡åˆæˆå½±åƒï¼Œåœ¨åŒ»å­¦å½±åƒçš„è·¨æ¨¡æ€å’Œæ¨¡æ€å†…åˆæˆä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—çš„æŠ€æœ¯ä¼˜åŠ¿ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16579v1",
      "published_date": "2025-07-22 13:30:54 UTC",
      "updated_date": "2025-07-22 13:30:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:27.183097+00:00"
    },
    {
      "arxiv_id": "2507.16571v1",
      "title": "Data-Driven Adaptive Gradient Recovery for Unstructured Finite Volume Computations",
      "title_zh": "ç”¨äºéç»“æ„æœ‰é™ä½“ç§¯è®¡ç®—çš„æ•°æ®é©±åŠ¨è‡ªé€‚åº”æ¢¯åº¦æ¢å¤",
      "authors": [
        "G. de RomÃ©mont",
        "F. Renac",
        "F. Chinesta",
        "J. Nunez",
        "D. Gueyffier"
      ],
      "abstract": "We present a novel data-driven approach for enhancing gradient reconstruction in unstructured finite volume methods for hyperbolic conservation laws, specifically for the 2D Euler equations. Our approach extends previous structured-grid methodologies to unstructured meshes through a modified DeepONet architecture that incorporates local geometry in the neural network. The architecture employs local mesh topology to ensure rotation invariance, while also ensuring first-order constraint on the learned operator. The training methodology incorporates physics-informed regularization through entropy penalization, total variation diminishing penalization, and parameter regularization to ensure physically consistent solutions, particularly in shock-dominated regions. The model is trained on high-fidelity datasets solutions derived from sine waves and randomized piecewise constant initial conditions with periodic boundary conditions, enabling robust generalization to complex flow configurations or geometries. Validation test cases from the literature, including challenging geometry configuration, demonstrates substantial improvements in accuracy compared to traditional second-order finite volume schemes. The method achieves gains of 20-60% in solution accuracy while enhancing computational efficiency. A convergence study has been conveyed and reveal improved mesh convergence rates compared to the conventional solver. The proposed algorithm is faster and more accurate than the traditional second-order finite volume solver, enabling high-fidelity simulations on coarser grids while preserving the stability and conservation properties essential for hyperbolic conservation laws. This work is a part of a new generation of solvers that are built by combining Machine-Learning (ML) tools with traditional numerical schemes, all while ensuring physical constraint on the results.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹éç»“æ„åŒ–æœ‰é™ä½“ç§¯æ³•(unstructured finite volume methods)ä¸­çš„æ¢¯åº¦é‡æ„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ•°æ®é©±åŠ¨çš„è‡ªé€‚åº”æ¢¯åº¦æ¢å¤æ–¹æ³•ï¼Œç‰¹åˆ«é€‚ç”¨äºè§£å†³ 2D Euler equations ç­‰åŒæ›²å®ˆæ’å¾‹é—®é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ”¹è¿›çš„ DeepONet æ¶æ„ï¼Œå°†å±€éƒ¨ç½‘æ ¼æ‹“æ‰‘èå…¥ç¥ç»ç½‘ç»œä»¥å®ç°æ—‹è½¬ä¸å˜æ€§(rotation invariance)ï¼Œå¹¶ç¡®ä¿äº†å­¦ä¹ ç®—å­æ»¡è¶³ä¸€é˜¶çº¦æŸã€‚ä¸ºäº†åœ¨æ¿€æ³¢ä¸»å¯¼åŒºåŸŸ(shock-dominated regions)è·å¾—ç‰©ç†ä¸€è‡´è§£ï¼Œè®­ç»ƒè¿‡ç¨‹ç»“åˆäº†ç†µæƒ©ç½š(entropy penalization)å’Œå…¨å˜å·®é€’å‡(TVD)ç­‰ç‰©ç†ä¿¡æ¯æ­£åˆ™åŒ–(physics-informed regularization)æ‰‹æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§å¤æ‚å‡ ä½•é…ç½®ä¸‹å…·æœ‰æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„äºŒé˜¶æœ‰é™ä½“ç§¯æ–¹æ¡ˆï¼Œå…¶è§£çš„ç²¾ç¡®åº¦æå‡äº† 20-60%ï¼Œä¸”å…·å¤‡æ›´ä¼˜çš„ç½‘æ ¼æ”¶æ•›ç‡ã€‚è¯¥ç®—æ³•åœ¨ä¿è¯ç¨³å®šæ€§å’Œå®ˆæ’æ€§çš„åŒæ—¶ï¼Œå®ç°äº†æ¯”ä¼ ç»Ÿæ±‚è§£å™¨æ›´å¿«çš„è®¡ç®—é€Ÿåº¦ï¼Œä¸ºç»“åˆæœºå™¨å­¦ä¹ ä¸ä¼ ç»Ÿæ•°å€¼æ ¼å¼çš„æ–°ä¸€ä»£é«˜æ•ˆæ±‚è§£å™¨å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "math.NA",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "math.NA",
      "comment": "19 pages, 13 Figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.16571v1",
      "published_date": "2025-07-22 13:23:57 UTC",
      "updated_date": "2025-07-22 13:23:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:36.179937+00:00"
    },
    {
      "arxiv_id": "2507.16564v1",
      "title": "TTMBA: Towards Text To Multiple Sources Binaural Audio Generation",
      "title_zh": "TTMBAï¼šè¿ˆå‘æ–‡æœ¬åˆ°å¤šæºåŒè€³éŸ³é¢‘ç”Ÿæˆ",
      "authors": [
        "Yuxuan He",
        "Xiaoran Yang",
        "Ningning Pan",
        "Gongping Huang"
      ],
      "abstract": "Most existing text-to-audio (TTA) generation methods produce mono outputs, neglecting essential spatial information for immersive auditory experiences. To address this issue, we propose a cascaded method for text-to-multisource binaural audio generation (TTMBA) with both temporal and spatial control. First, a pretrained large language model (LLM) segments the text into a structured format with time and spatial details for each sound event. Next, a pretrained mono audio generation network creates multiple mono audios with varying durations for each event. These mono audios are transformed into binaural audios using a binaural rendering neural network based on spatial data from the LLM. Finally, the binaural audios are arranged by their start times, resulting in multisource binaural audio. Experimental results demonstrate the superiority of the proposed method in terms of both audio generation quality and spatial perceptual accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TTMBAï¼Œä¸€ç§æ—¨åœ¨å®ç°æ–‡æœ¬åˆ°å¤šæºåŒè€³éŸ³é¢‘(binaural audio)ç”Ÿæˆçš„çº§è”æ–¹æ³•ï¼Œä»¥è§£å†³ç°æœ‰æ–‡æœ¬åˆ°éŸ³é¢‘(TTA)ç”Ÿæˆæ–¹æ³•ä¸»è¦äº§ç”Ÿå•å£°é“è¾“å‡ºä¸”ç¼ºä¹æ²‰æµ¸å¼ç©ºé—´ä¿¡æ¯çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨é¢„è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹(LLM)å°†æ–‡æœ¬è§£æä¸ºå…·æœ‰æ—¶é—´è½´å’Œç©ºé—´ç»†èŠ‚çš„ç»“æ„åŒ–æ ¼å¼ï¼Œå¹¶ç”±å•å£°é“ç”Ÿæˆç½‘ç»œé’ˆå¯¹æ¯ä¸ªäº‹ä»¶åˆ›å»ºéŸ³é¢‘ã€‚éšåï¼Œç³»ç»Ÿåˆ©ç”¨åŒè€³æ¸²æŸ“ç¥ç»ç½‘ç»œ(binaural rendering neural network)ç»“åˆLLMæä¾›çš„ç©ºé—´æ•°æ®ï¼Œå°†ç”Ÿæˆçš„å¤šä¸ªå•å£°é“éŸ³é¢‘è½¬åŒ–ä¸ºåŒè€³éŸ³é¢‘ã€‚æœ€åï¼Œé€šè¿‡æŒ‰èµ·å§‹æ—¶é—´æ’åˆ—è¿™äº›éŸ³é¢‘ï¼Œç”Ÿæˆæœ€ç»ˆçš„å¤šæºåŒè€³éŸ³é¢‘æµã€‚å®éªŒç»“æœè¯æ˜ï¼ŒTTMBAåœ¨éŸ³é¢‘ç”Ÿæˆè´¨é‡å’Œç©ºé—´æ„ŸçŸ¥å‡†ç¡®åº¦æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages,3 figures,2 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16564v1",
      "published_date": "2025-07-22 13:16:07 UTC",
      "updated_date": "2025-07-22 13:16:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:53.887366+00:00"
    },
    {
      "arxiv_id": "2507.16562v1",
      "title": "Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)",
      "title_zh": "æ‰©å±•ç°å® (XR) æ™ºèƒ½ä½“æŠ€æœ¯çš„ç¤¾ä¼šæ¥å—åº¦è¯„ä¼°ï¼šä¸€é¡¹ç”¨æˆ·ç ”ç©¶ï¼ˆæ‰©å±•ç‰ˆï¼‰",
      "authors": [
        "Megha Quamara",
        "Viktor Schmuck",
        "Cristina Iani",
        "Axel Primavesi",
        "Alexander Plaum",
        "Luca Vigano"
      ],
      "abstract": "In this paper, we present the findings of a user study that evaluated the social acceptance of eXtended Reality (XR) agent technology, focusing on a remotely accessible, web-based XR training system developed for journalists. This system involves user interaction with a virtual avatar, enabled by a modular toolkit. The interactions are designed to provide tailored training for journalists in digital-remote settings, especially for sensitive or dangerous scenarios, without requiring specialized end-user equipment like headsets. Our research adapts and extends the Almere model, representing social acceptance through existing attributes such as perceived ease of use and perceived usefulness, along with added ones like dependability and security in the user-agent interaction. The XR agent was tested through a controlled experiment in a real-world setting, with data collected on users' perceptions. Our findings, based on quantitative and qualitative measurements involving questionnaires, contribute to the understanding of user perceptions and acceptance of XR agent solutions within a specific social context, while also identifying areas for the improvement of XR systems.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†æ‰©å±•ç°å® (eXtended Reality, XR) æ™ºèƒ½ä½“æŠ€æœ¯åœ¨ç¤¾ä¼šæ¥å—åº¦æ–¹é¢çš„è¡¨ç°ï¼Œé‡ç‚¹æ¢è®¨äº†ä¸€ä¸ªä¸ºè®°è€…å¼€å‘çš„ã€åŸºäº Web ä¸”å¯è¿œç¨‹è®¿é—®çš„ XR åŸ¹è®­ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æ¨¡å—åŒ–å·¥å…·åŒ… (modular toolkit) å®ç°ç”¨æˆ·ä¸è™šæ‹ŸåŒ–èº« (virtual avatar) çš„äº¤äº’ï¼Œæ—¨åœ¨æ— éœ€å¤´æˆ´å¼æ˜¾ç¤ºå™¨ç­‰ä¸“é—¨è®¾å¤‡çš„æƒ…å†µä¸‹ï¼Œä¸ºæ•æ„Ÿæˆ–å±é™©åœºæ™¯æä¾›å®šåˆ¶åŒ–çš„è¿œç¨‹åŸ¹è®­ã€‚ç ”ç©¶é€šè¿‡æ”¹ç¼–å’Œæ‰©å±• Almere model æ¥è¡¡é‡ç¤¾ä¼šæ¥å—åº¦ï¼Œåœ¨æ„ŸçŸ¥æ˜“ç”¨æ€§ (perceived ease of use) å’Œæ„ŸçŸ¥æœ‰ç”¨æ€§ (perceived usefulness) çš„åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†æ™ºèƒ½ä½“äº¤äº’ä¸­çš„å¯é æ€§ (dependability) å’Œå®‰å…¨æ€§ (security) ç­‰ç»´åº¦ã€‚é€šè¿‡åœ¨ç°å®ç¯å¢ƒä¸­å¼€å±•å—æ§å®éªŒå¹¶ç»“åˆå®šæ€§ä¸å®šé‡é—®å·åˆ†æï¼Œè¯¥ç ”ç©¶æ·±å…¥æ­ç¤ºäº†ç‰¹å®šç¤¾ä¼šèƒŒæ™¯ä¸‹ç”¨æˆ·å¯¹ XR æ™ºèƒ½ä½“çš„è®¤çŸ¥ä¸æ¥å—ç¨‹åº¦ï¼Œå¹¶ä¸º XR ç³»ç»Ÿçš„ä¼˜åŒ–æä¾›äº†æ˜ç¡®æ–¹å‘ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "26 pages (18 pages main body, 8 pages user consent form), 3 figures, 7 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16562v1",
      "published_date": "2025-07-22 13:14:05 UTC",
      "updated_date": "2025-07-22 13:14:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:13:55.379882+00:00"
    },
    {
      "arxiv_id": "2507.16556v1",
      "title": "Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach",
      "title_zh": "é¢å‘è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿçš„åŸºäº DNN çš„é«˜å…‰è°±å›¾åƒåˆ†å‰² FPGA SoC ä¼˜åŒ–ï¼šä¸€ç§å®ç”¨æ–¹æ³•",
      "authors": [
        "Jon GutiÃ©rrez-Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "The use of HSI for autonomous navigation is a promising research field aimed at improving the accuracy and robustness of detection, tracking, and scene understanding systems based on vision sensors. Combining advanced computer algorithms, such as DNNs, with small-size snapshot HSI cameras enhances the reliability of these systems. HSI overcomes intrinsic limitations of greyscale and RGB imaging in depicting physical properties of targets, particularly regarding spectral reflectance and metamerism. Despite promising results in HSI-based vision developments, safety-critical systems like ADS demand strict constraints on latency, resource consumption, and security, motivating the shift of ML workloads to edge platforms. This involves a thorough software/hardware co-design scheme to distribute and optimize the tasks efficiently among the limited resources of computing platforms. With respect to inference, the over-parameterized nature of DNNs poses significant computational challenges for real-time on-the-edge deployment. In addition, the intensive data preprocessing required by HSI, which is frequently overlooked, must be carefully managed in terms of memory arrangement and inter-task communication to enable an efficient integrated pipeline design on a SoC. This work presents a set of optimization techniques for the practical co-design of a DNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted at ADS, including key optimizations such as functional software/hardware task distribution, hardware-aware preprocessing, ML model compression, and a complete pipelined deployment. Applied compression techniques significantly reduce the complexity of the designed DNN to 24.34% of the original operations and to 1.02% of the original number of parameters, achieving a 2.86x speed-up in the inference task without noticeable degradation of the segmentation accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿ(ADS)ä¸­çš„é«˜å…‰è°±æˆåƒ(HSI)åˆ†å‰²ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åœ¨åŸºäºFPGAçš„SoCä¸Šä¼˜åŒ–æ·±åº¦ç¥ç»ç½‘ç»œ(DNN)éƒ¨ç½²çš„å®è·µæ–¹æ³•ã€‚é’ˆå¯¹ADSå¯¹ä½å»¶è¿Ÿå’Œèµ„æºæ¶ˆè€—çš„ä¸¥è‹›è¦æ±‚ï¼Œè¯¥å·¥ä½œé€šè¿‡è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼Œå®ç°äº†åŠŸèƒ½æ€§çš„ä»»åŠ¡åˆ†é…ã€ç¡¬ä»¶æ„ŸçŸ¥çš„æ•°æ®é¢„å¤„ç†ä»¥åŠå®Œæ•´çš„æµæ°´çº¿åŒ–éƒ¨ç½²ã€‚ç ”ç©¶é‡ç‚¹è§£å†³äº†HSIé¢„å¤„ç†ä¸­å¤æ‚çš„å†…å­˜å¸ƒå±€å’Œä»»åŠ¡é—´é€šä¿¡é—®é¢˜ï¼Œå¹¶é‡‡ç”¨äº†é«˜æ•ˆçš„æœºå™¨å­¦ä¹ æ¨¡å‹å‹ç¼©æŠ€æœ¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆå°†DNNçš„è¿ç®—é‡é™è‡³åŸå§‹çš„24.34%ï¼Œå‚æ•°é‡ç¼©å‡è‡³1.02%ï¼Œåœ¨å‡ ä¹ä¸æŸå¤±åˆ†å‰²ç²¾åº¦çš„å‰æä¸‹å®ç°äº†2.86å€çš„æ¨ç†åŠ é€Ÿã€‚è¿™ä¸€æˆæœä¸ºå®‰å…¨æ€§å…³é”®çš„è‡ªåŠ¨é©¾é©¶è¾¹ç¼˜è®¡ç®—å¹³å°æä¾›äº†é«˜æ•ˆä¸”ç¨³å¥çš„é«˜å…‰è°±æ„ŸçŸ¥æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16556v1",
      "published_date": "2025-07-22 13:09:04 UTC",
      "updated_date": "2025-07-22 13:09:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:02.188783+00:00"
    },
    {
      "arxiv_id": "2507.16541v1",
      "title": "A Comprehensive Data-centric Overview of Federated Graph Learning",
      "title_zh": "è”é‚¦å›¾å­¦ä¹ ï¼šä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„å…¨é¢ç»¼è¿°",
      "authors": [
        "Zhengyu Wu",
        "Xunkai Li",
        "Yinlin Zhu",
        "Zekai Chen",
        "Guochen Yan",
        "Yanyu Yan",
        "Hao Zhang",
        "Yuming Ai",
        "Xinmo Jin",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "In the era of big data applications, Federated Graph Learning (FGL) has emerged as a prominent solution that reconcile the tradeoff between optimizing the collective intelligence between decentralized datasets holders and preserving sensitive information to maximum. Existing FGL surveys have contributed meaningfully but largely focus on integrating Federated Learning (FL) and Graph Machine Learning (GML), resulting in early stage taxonomies that emphasis on methodology and simulated scenarios. Notably, a data centric perspective, which systematically examines FGL methods through the lens of data properties and usage, remains unadapted to reorganize FGL research, yet it is critical to assess how FGL studies manage to tackle data centric constraints to enhance model performances. This survey propose a two-level data centric taxonomy: Data Characteristics, which categorizes studies based on the structural and distributional properties of datasets used in FGL, and Data Utilization, which analyzes the training procedures and techniques employed to overcome key data centric challenges. Each taxonomy level is defined by three orthogonal criteria, each representing a distinct data centric configuration. Beyond taxonomy, this survey examines FGL integration with Pretrained Large Models, showcases realistic applications, and highlights future direction aligned with emerging trends in GML.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹è”é‚¦å›¾å­¦ä¹  (Federated Graph Learning, FGL) æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ä»¥æ•°æ®ä¸ºä¸­å¿ƒ (Data-centric) çš„ç ”ç©¶è§†è§’ã€‚ç›¸è¾ƒäºç°æœ‰ç»¼è¿°ä¾§é‡äºæ–¹æ³•è®ºå’Œæ¨¡æ‹Ÿåœºæ™¯ï¼Œè¯¥ç ”ç©¶ç³»ç»Ÿåœ°ä»æ•°æ®å±æ€§å’Œåˆ©ç”¨çš„è§’åº¦é‡æ–°æ¢³ç†äº† FGL çš„ç ”ç©¶ç°çŠ¶ã€‚ä½œè€…æå‡ºäº†ä¸€ä¸ªåŒå±‚åˆ†ç±»æ¡†æ¶ï¼ŒåŒ…æ‹¬åŸºäºæ•°æ®é›†ç»“æ„å’Œåˆ†å¸ƒå±æ€§çš„ Data Characteristicsï¼Œä»¥åŠåˆ†æè®­ç»ƒæµç¨‹å’ŒæŒ‘æˆ˜åº”å¯¹æŠ€æœ¯çš„ Data Utilizationã€‚è¯¥åˆ†ç±»æ³•çš„æ¯ä¸€å±‚éƒ½ç”±ä¸‰ä¸ªæ­£äº¤æ ‡å‡†å®šä¹‰ï¼Œç”¨äºè¯„ä¼° FGL ç ”ç©¶å¦‚ä½•å¤„ç†ä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„çº¦æŸä»¥æå‡æ¨¡å‹æ€§èƒ½ã€‚æ­¤å¤–ï¼Œç»¼è¿°è¿˜æ·±å…¥æ¢è®¨äº† FGL ä¸é¢„è®­ç»ƒå¤§æ¨¡å‹ (Pretrained Large Models) çš„é›†æˆï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®ä¸–ç•Œä¸­çš„åº”ç”¨ï¼Œå¹¶æŒ‡å‡ºäº†ç¬¦åˆå›¾æœºå™¨å­¦ä¹  (GML) å‘å±•è¶‹åŠ¿çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16541v1",
      "published_date": "2025-07-22 12:49:24 UTC",
      "updated_date": "2025-07-22 12:49:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:04.791518+00:00"
    },
    {
      "arxiv_id": "2507.16540v1",
      "title": "Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph Attention Networks",
      "title_zh": "åŸºäºè¾¹æ„ŸçŸ¥å›¾æ³¨æ„åŠ›ç½‘ç»œçš„ C/C++ å¯è§£é‡Šæ¼æ´æ£€æµ‹",
      "authors": [
        "Radowanul Haque",
        "Aftab Ali",
        "Sally McClean",
        "Naveed Khan"
      ],
      "abstract": "Detecting security vulnerabilities in source code remains challenging, particularly due to class imbalance in real-world datasets where vulnerable functions are under-represented. Existing learning-based methods often optimise for recall, leading to high false positive rates and reduced usability in development workflows. Furthermore, many approaches lack explainability, limiting their integration into security workflows. This paper presents ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code. The method constructs Code Property Graphs and represents nodes using dual-channel embeddings that capture both semantic and structural information. These are processed by an edge-aware attention mechanism that incorporates edge-type embeddings to distinguish among program relations. To address class imbalance, the model is trained using class-weighted cross-entropy loss. ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23 percent across 30 independent runs on the ReVeal dataset. These results represent relative improvements of 4.6 percent in accuracy and 16.9 percent in F1 score compared to the ReVeal model, a prior learning-based method. The framework also outperforms static analysis tools, with relative gains of 14.0 to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond improved detection performance, ExplainVulD produces explainable outputs by identifying the most influential code regions within each function, supporting transparency and trust in security triage.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹C/C++ä»£ç æ¼æ´æ£€æµ‹ä¸­å­˜åœ¨çš„ç±»åˆ«ä¸å¹³è¡¡å’Œç¼ºä¹å¯è§£é‡Šæ€§ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†åä¸ºExplainVulDçš„å›¾æ¨¡å‹æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡æ„å»ºä»£ç å±æ€§å›¾(Code Property Graphs)å¹¶é‡‡ç”¨åŒé€šé“åµŒå…¥(dual-channel embeddings)æ¥åŒæ—¶æ•è·ä»£ç çš„è¯­ä¹‰å’Œç»“æ„ä¿¡æ¯ã€‚ExplainVulDå¼•å…¥äº†è¾¹ç¼˜æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶(edge-aware attention mechanism)ï¼Œåˆ©ç”¨è¾¹ç¼˜ç±»å‹åµŒå…¥(edge-type embeddings)æ¥åŒºåˆ†å¤æ‚çš„ç¨‹åºå…³ç³»ï¼Œå¹¶ç»“åˆç±»åŠ æƒäº¤å‰ç†µæŸå¤±(class-weighted cross-entropy loss)è§£å†³æ ·æœ¬ä¸å‡è¡¡é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¡†æ¶åœ¨ReVealæ•°æ®é›†ä¸Šçš„å¹³å‡å‡†ç¡®ç‡è¾¾åˆ°88.25%ï¼ŒF1åˆ†æ•°ä¸º48.23%ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºå…ˆå‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹åŠä¼ ç»Ÿçš„é™æ€åˆ†æå·¥å…·ã€‚æ­¤å¤–ï¼ŒExplainVulDè¿˜èƒ½å¤Ÿé€šè¿‡è¯†åˆ«å‡½æ•°ä¸­å¯¹æ¼æ´åˆ¤æ–­æœ€å…·å½±å“åŠ›çš„ä»£ç åŒºåŸŸæä¾›å¯è§£é‡Šæ€§çš„è¾“å‡ºï¼Œä»è€Œå¢å¼ºäº†å®‰å…¨åˆ†æµè¿‡ç¨‹ä¸­çš„é€æ˜åº¦ä¸ä¿¡ä»»ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16540v1",
      "published_date": "2025-07-22 12:49:14 UTC",
      "updated_date": "2025-07-22 12:49:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:10.476615+00:00"
    },
    {
      "arxiv_id": "2507.16537v1",
      "title": "Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines",
      "title_zh": "ç¬¦å·å›¾æ™ºèƒ½ï¼šåŸºäº Tsetlin Machines çš„å›¾çº§æ¨¡å¼å­¦ä¹ è¶…å‘é‡æ¶ˆæ¯ä¼ é€’",
      "authors": [
        "Christian D. Blakely"
      ],
      "abstract": "We propose a multilayered symbolic framework for general graph classification that leverages sparse binary hypervectors and Tsetlin Machines. Each graph is encoded through structured message passing, where node, edge, and attribute information are bound and bundled into a symbolic hypervector. This process preserves the hierarchical semantics of the graph through layered binding from node attributes to edge relations to structural roles resulting in a compact, discrete representation. We also formulate a local interpretability framework which lends itself to a key advantage of our approach being locally interpretable. We validate our method on TUDataset benchmarks, demonstrating competitive accuracy with strong symbolic transparency compared to neural graph models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç”¨äºé€šç”¨å›¾åˆ†ç±»(Graph Classification)çš„å¤šå±‚ç¬¦å·æ¡†æ¶ï¼Œç»“åˆäº†ç¨€ç–äºŒè¿›åˆ¶è¶…å‘é‡(Sparse Binary Hypervectors)å’ŒTsetlin Machinesã€‚è¯¥æ¡†æ¶é€šè¿‡ç»“æ„åŒ–æ¶ˆæ¯ä¼ é€’(Structured Message Passing)å¯¹å›¾è¿›è¡Œç¼–ç ï¼Œå°†èŠ‚ç‚¹ã€è¾¹å’Œå±æ€§ä¿¡æ¯ç»‘å®šå¹¶æ†ç»‘æˆç¬¦å·è¶…å‘é‡ã€‚è¿™ä¸€è¿‡ç¨‹é€šè¿‡ä»èŠ‚ç‚¹å±æ€§åˆ°è¾¹å…³ç³»å†åˆ°ç»“æ„è§’è‰²çš„å±‚çº§ç»‘å®šï¼Œä¿ç•™äº†å›¾çš„å±‚çº§è¯­ä¹‰ï¼Œä»è€Œå½¢æˆäº†ç´§å‡‘ä¸”ç¦»æ•£çš„è¡¨ç¤ºã€‚ç ”ç©¶è¿˜åˆ¶å®šäº†ä¸€ä¸ªå±€éƒ¨å¯è§£é‡Šæ€§(Local Interpretability)æ¡†æ¶ï¼Œä½¿è¯¥æ–¹æ³•åœ¨è§£é‡Šæ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚é€šè¿‡åœ¨TUDatasetåŸºå‡†æµ‹è¯•ä¸Šçš„éªŒè¯ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç«äº‰åŠ›çš„å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå±•ç°å‡ºä¼˜äºç¥ç»å›¾æ¨¡å‹(Neural Graph Models)çš„ç¬¦å·é€æ˜åº¦ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures, for ICTM '25",
      "pdf_url": "https://arxiv.org/pdf/2507.16537v1",
      "published_date": "2025-07-22 12:47:56 UTC",
      "updated_date": "2025-07-22 12:47:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:16.688137+00:00"
    },
    {
      "arxiv_id": "2507.16535v2",
      "title": "EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion",
      "title_zh": "EarthCrafterï¼šåŸºäºåŒç¨€ç–æ½œåœ¨æ‰©æ•£çš„å¯æ‰©å±•ä¸‰ç»´åœ°çƒç”Ÿæˆ",
      "authors": [
        "Shang Liu",
        "Chenjie Cao",
        "Chaohui Yu",
        "Wen Qian",
        "Jing Wang",
        "Fan Wang"
      ],
      "abstract": "Despite the remarkable developments achieved by recent 3D generation works, scaling these methods to geographic extents, such as modeling thousands of square kilometers of Earth's surface, remains an open challenge. We address this through a dual innovation in data infrastructure and model architecture. First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date, consisting of 50k curated scenes (each measuring 600m x 600m) captured across the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene provides pose-annotated multi-view images, depth maps, normals, semantic segmentation, and camera poses, with explicit quality control to ensure terrain diversity. Building on this foundation, we propose EarthCrafter, a tailored framework for large-scale 3D Earth generation via sparse-decoupled latent diffusion. Our architecture separates structural and textural generation: 1) Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the costly computation suffering from vast geographic scales while preserving critical information. 2) We propose condition-aware flow matching models trained on mixed inputs (semantics, images, or neither) to flexibly model latent geometry and texture features independently. Extensive experiments demonstrate that EarthCrafter performs substantially better in extremely large-scale generation. The framework further supports versatile applications, from semantic-guided urban layout generation to unconditional terrain synthesis, while maintaining geographic plausibility through our rich data priors from Aerial-Earth3D. Our project page is available at https://whiteinblue.github.io/earthcrafter/",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ—¨åœ¨è§£å†³å°†3Dç”ŸæˆæŠ€æœ¯æ‰©å±•åˆ°å¤§è§„æ¨¡åœ°ç†å°ºåº¦ï¼ˆå¦‚æ•°åƒå¹³æ–¹å…¬é‡Œçš„åœ°è¡¨å»ºæ¨¡ï¼‰æ‰€é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ¨å‡ºäº†ç›®å‰æœ€å¤§çš„3Dèˆªç©ºæ•°æ®é›†Aerial-Earth3Dï¼ŒåŒ…å«è¦†ç›–ç¾å›½æœ¬åœŸçš„5ä¸‡ä¸ªç²¾é€‰åœºæ™¯å’Œ4500ä¸‡ä¸ªå¤šè§†å›¾Google Earthå¸§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡æå‡ºäº†EarthCrafteræ¡†æ¶ï¼Œé€šè¿‡ç¨€ç–è§£è€¦çš„æ½œåœ¨æ‰©æ•£æ¨¡å‹(sparse-decoupled latent diffusion)å®ç°å¤§è§„æ¨¡3Dåœ°çƒç”Ÿæˆã€‚è¯¥æ¶æ„åˆ©ç”¨åŒç¨€ç–3D-VAE (Dual sparse 3D-VAEs) å°†é«˜åˆ†è¾¨ç‡å‡ ä½•ä½“ç´ å’Œçº¹ç†2D Gaussian Splats (2DGS) å‹ç¼©åˆ°ç´§å‡‘çš„æ½œåœ¨ç©ºé—´ä¸­ï¼Œæ˜¾è‘—é™ä½äº†è¶…å¤§è§„æ¨¡ç”Ÿæˆçš„è®¡ç®—å¼€é”€ã€‚æ­¤å¤–ï¼Œé€šè¿‡æ¡ä»¶æ„ŸçŸ¥æµåŒ¹é…æ¨¡å‹ (condition-aware flow matching models)ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæ ¹æ®è¯­ä¹‰æˆ–å›¾åƒç­‰æ··åˆè¾“å…¥çµæ´»åœ°ç‹¬ç«‹å»ºæ¨¡å‡ ä½•ä¸çº¹ç†ç‰¹å¾ã€‚å®éªŒè¯æ˜ï¼ŒEarthCrafteråœ¨æå¤§è§„æ¨¡ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œæ”¯æŒä»è¯­ä¹‰å¼•å¯¼çš„åŸå¸‚å¸ƒå±€ç”Ÿæˆåˆ°æ— æ¡ä»¶åœ°å½¢åˆæˆç­‰å¤šç§åº”ç”¨ï¼Œå¹¶ä¾é ä¸°å¯Œçš„åœ°ç†å…ˆéªŒä¿æŒäº†ç»“æœçš„çœŸå®æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Models and codes will be released at this https URL: https://github.com/whiteinblue/EarthCrafter",
      "pdf_url": "https://arxiv.org/pdf/2507.16535v2",
      "published_date": "2025-07-22 12:46:48 UTC",
      "updated_date": "2025-07-23 01:59:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:18.181425+00:00"
    },
    {
      "arxiv_id": "2507.16534v2",
      "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report",
      "title_zh": "å‰æ²¿äººå·¥æ™ºèƒ½é£é™©ç®¡ç†æ¡†æ¶å®è·µï¼šé£é™©åˆ†ææŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Shanghai AI Lab",
        ":",
        "Xiaoyang Chen",
        "Yunhao Chen",
        "Zeren Chen",
        "Zhiyun Chen",
        "Hanyun Cui",
        "Yawen Duan",
        "Jiaxuan Guo",
        "Qi Guo",
        "Xuhao Hu",
        "Hong Huang",
        "Lige Huang",
        "Chunxiao Li",
        "Juncheng Li",
        "Qihao Lin",
        "Dongrui Liu",
        "Xinmin Liu",
        "Zicheng Liu",
        "Chaochao Lu",
        "Xiaoya Lu",
        "Jingjing Qu",
        "Qibing Ren",
        "Jing Shao",
        "Jingwei Shi",
        "Jingwei Sun",
        "Peng Wang",
        "Weibing Wang",
        "Jia Xu",
        "Lewen Yan",
        "Xiao Yu",
        "Yi Yu",
        "Boxuan Zhang",
        "Jie Zhang",
        "Weichen Zhang",
        "Zhijie Zheng",
        "Tianyi Zhou",
        "Bowen Zhou"
      ],
      "abstract": "To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, this report presents a comprehensive assessment of their frontier risks. Drawing on the E-T-C analysis (deployment environment, threat source, enabling capability) from the Frontier AI Risk Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks in seven areas: cyber offense, biological and chemical risks, persuasion and manipulation, uncontrolled autonomous AI R\\&D, strategic deception and scheming, self-replication, and collusion. Guided by the \"AI-$45^\\circ$ Law,\" we evaluate these risks using \"red lines\" (intolerable thresholds) and \"yellow lines\" (early warning indicators) to define risk zones: green (manageable risk for routine deployment and continuous monitoring), yellow (requiring strengthened mitigations and controlled deployment), and red (necessitating suspension of development and/or deployment). Experimental results show that all recent frontier AI models reside in green and yellow zones, without crossing red lines. Specifically, no evaluated models cross the yellow line for cyber offense or uncontrolled AI R\\&D risks. For self-replication, and strategic deception and scheming, most models remain in the green zone, except for certain reasoning models in the yellow zone. In persuasion and manipulation, most models are in the yellow zone due to their effective influence on humans. For biological and chemical risks, we are unable to rule out the possibility of most models residing in the yellow zone, although detailed threat modeling and in-depth assessment are required to make further claims. This work reflects our current understanding of AI frontier risks and urges collective action to mitigate these challenges.",
      "tldr_zh": "è¯¥æŠ¥å‘ŠåŸºäºFrontier AI Risk Management Framework (v1.0) (SafeWork-F1-Framework)ä¸­çš„E-T-Cåˆ†ææ–¹æ³•ï¼Œå¯¹å‰æ²¿äººå·¥æ™ºèƒ½æ¨¡å‹å­˜åœ¨çš„æ½œåœ¨é£é™©è¿›è¡Œäº†ç³»ç»Ÿæ€§è¯„ä¼°ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†ç½‘ç»œæ”»å‡»ã€ç”Ÿç‰©åŒ–å­¦é£é™©ã€åŠè¯´ä¸æ“çºµã€ä¸å—æ§çš„è‡ªä¸»AIç ”å‘ã€æˆ˜ç•¥æ¬ºéª—ä¸è°‹åˆ’ã€è‡ªæˆ‘å¤åˆ¶åŠå…±è°‹ç­‰ä¸ƒå¤§å…³é”®é¢†åŸŸçš„é£é™©ã€‚é€šè¿‡å¼•å…¥â€œAI-45Â° Lawâ€å¹¶è®¾å®šâ€œçº¢çº¿â€ä¸â€œé»„çº¿â€ä½œä¸ºè§¦å‘é˜ˆå€¼ï¼Œè¯¥æ¡†æ¶å°†æ¨¡å‹é£é™©åˆ’åˆ†ä¸ºç»¿è‰²ã€é»„è‰²å’Œçº¢è‰²ä¸‰ä¸ªç®¡ç†åŒºåŸŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå½“å‰æ‰€æœ‰å‰æ²¿AIæ¨¡å‹å‡å¤„äºç»¿è‰²æˆ–é»„è‰²åŒºåŸŸï¼Œå°šæœªçªç ´ä¸å¯æ¥å—çš„çº¢çº¿ã€‚å…·ä½“è€Œè¨€ï¼Œè™½ç„¶ç½‘ç»œæ”»å‡»å’Œè‡ªä¸»AIç ”å‘é£é™©ä»å¤„äºä½ä½ï¼Œä½†å¤šæ•°æ¨¡å‹åœ¨åŠè¯´ä¸æ“çºµæ–¹é¢å·²è¿›å…¥é»„è‰²è­¦æˆ’åŒºï¼Œä¸”éƒ¨åˆ†æ¨ç†æ¨¡å‹åœ¨è‡ªæˆ‘å¤åˆ¶å’Œæˆ˜ç•¥æ¬ºéª—é¢†åŸŸä¹Ÿè¡¨ç°å‡ºé»„è‰²ç­‰çº§é£é™©ã€‚è¯¥å·¥ä½œä¸ä»…é‡åŒ–äº†å½“å‰å‰æ²¿æ¨¡å‹çš„å®‰å…¨è¾¹ç•Œï¼Œä¹Ÿä¸ºæœªæ¥AIé£é™©æ²»ç†æä¾›äº†é‡è¦çš„æŠ€æœ¯å‚è€ƒå’Œé¢„è­¦æœºåˆ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "97 pages, 37 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16534v2",
      "published_date": "2025-07-22 12:44:38 UTC",
      "updated_date": "2025-07-26 12:33:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:24.847335+00:00"
    },
    {
      "arxiv_id": "2507.16533v1",
      "title": "confopt: A Library for Implementation and Evaluation of Gradient-based One-Shot NAS Methods",
      "title_zh": "confoptï¼šåŸºäºæ¢¯åº¦çš„å•æ¬¡ NAS æ–¹æ³•å®ç°ä¸è¯„ä¼°åº“",
      "authors": [
        "Abhash Kumar Jha",
        "Shakiba Moradian",
        "Arjun Krishnakumar",
        "Martin Rapp",
        "Frank Hutter"
      ],
      "abstract": "Gradient-based one-shot neural architecture search (NAS) has significantly reduced the cost of exploring architectural spaces with discrete design choices, such as selecting operations within a model. However, the field faces two major challenges. First, evaluations of gradient-based NAS methods heavily rely on the DARTS benchmark, despite the existence of other available benchmarks. This overreliance has led to saturation, with reported improvements often falling within the margin of noise. Second, implementations of gradient-based one-shot NAS methods are fragmented across disparate repositories, complicating fair and reproducible comparisons and further development. In this paper, we introduce Configurable Optimizer (confopt), an extensible library designed to streamline the development and evaluation of gradient-based one-shot NAS methods. Confopt provides a minimal API that makes it easy for users to integrate new search spaces, while also supporting the decomposition of NAS optimizers into their core components. We use this framework to create a suite of new DARTS-based benchmarks, and combine them with a novel evaluation protocol to reveal a critical flaw in how gradient-based one-shot NAS methods are currently assessed. The code can be found at https://github.com/automl/ConfigurableOptimizer.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¢¯åº¦æœç´¢æ¶æ„ï¼ˆGradient-based one-shot NASï¼‰é¢ä¸´çš„å¯¹ DARTS åŸºå‡†è¿‡åº¦ä¾èµ–ä»¥åŠå®ç°æ–¹æ¡ˆç¢ç‰‡åŒ–å¯¼è‡´çš„å…¬å¹³æ¯”è¾ƒéš¾é¢˜ï¼Œæå‡ºäº† Configurable Optimizer (confopt) å¼€æºåº“ã€‚è¯¥åº“æä¾›äº†ä¸€å¥—æç®€çš„ APIï¼Œå…è®¸ç”¨æˆ·è½»æ¾é›†æˆæ–°çš„ Search Spaceï¼Œå¹¶å°† NAS ä¼˜åŒ–å™¨æ‹†è§£ä¸ºæ ¸å¿ƒç»„ä»¶ä»¥å¢å¼ºå¯æ‰©å±•æ€§ã€‚é€šè¿‡ confoptï¼Œç ”ç©¶è€…æ„å»ºäº†ä¸€ç³»åˆ—å…¨æ–°çš„åŸºäº DARTS çš„åŸºå‡†æµ‹è¯•ï¼Œå¹¶æå‡ºäº†ä¸€ç§æ–°çš„ Evaluation Protocolï¼Œä»è€Œæ­ç¤ºäº†å½“å‰æ¢¯åº¦æœç´¢ NAS æ–¹æ³•åœ¨è¯„ä¼°æµç¨‹ä¸­å­˜åœ¨çš„å…³é”®ç¼ºé™·ã€‚è¯¥å·¥å…·çš„æ¨å‡ºä¸º NAS æ–¹æ³•çš„å…¬å¹³å¤ç°ã€ç³»ç»ŸåŒ–å¼€å‘ä»¥åŠæ›´ä¸¥è°¨çš„æ€§èƒ½è¯„ä¼°å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AutoML 25 ABCD Track",
      "pdf_url": "https://arxiv.org/pdf/2507.16533v1",
      "published_date": "2025-07-22 12:44:28 UTC",
      "updated_date": "2025-07-22 12:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:23.689698+00:00"
    },
    {
      "arxiv_id": "2507.16524v1",
      "title": "Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models",
      "title_zh": "Spatial 3D-LLMï¼šæ¢ç´¢ 3D è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„ç©ºé—´æ„ŸçŸ¥",
      "authors": [
        "Xiaoyan Wang",
        "Zeju Li",
        "Yifan Xu",
        "Jiaxing Qi",
        "Zhifei Yang",
        "Ruifei Ma",
        "Xiangde Liu",
        "Chao Zhang"
      ],
      "abstract": "New era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or segmenting independent objects to perform these tasks, which limits their spatial awareness due to insufficient representation of the richness inherent in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D MLLM specifically designed to enhance spatial awareness for 3D vision-language tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM integrates an LLM backbone with a progressive spatial awareness scheme that progressively captures spatial information as the perception field expands, generating location-enriched 3D scene embeddings to serve as visual prompts. Furthermore, we introduce two novel tasks: 3D object distance measurement and 3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate the model's spatial awareness capabilities. Experimental results demonstrate that Spatial 3D-LLM achieves state-of-the-art performance across a wide range of 3D vision-language tasks, revealing the improvements stemmed from our progressive spatial awareness scheme of mining more profound spatial information. Our code is available at https://github.com/bjshuyuan/Spatial-3D-LLM.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ 3D å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (3D multimodal LLMs) å› åœºæ™¯ä¿¡æ¯å‹ç¼©æˆ–ç‹¬ç«‹å¯¹è±¡åˆ†å‰²è€Œå¯¼è‡´çš„ 3D ç©ºé—´æ„ŸçŸ¥ (spatial awareness) èƒ½åŠ›ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†åä¸º Spatial 3D-LLM çš„å…¨æ–°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡é›†æˆæ¸è¿›å¼ç©ºé—´æ„ŸçŸ¥æ–¹æ¡ˆ (progressive spatial awareness scheme)ï¼Œåœ¨æ„ŸçŸ¥è§†é‡æ‰©å±•çš„è¿‡ç¨‹ä¸­é€æ­¥æ•æ‰ç©ºé—´ä¿¡æ¯ï¼Œç”Ÿæˆå…·æœ‰ä½ç½®ä¸°å¯Œç‰¹æ€§çš„ 3D åœºæ™¯åµŒå…¥ (spatial embeddings) å¹¶ä½œä¸ºè§†è§‰æç¤º (visual prompts) è¾…åŠ©æ¨ç†ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº† 3D ç‰©ä½“è·ç¦»æµ‹é‡ (3D object distance measurement) å’Œ 3D å¸ƒå±€ç¼–è¾‘ (3D layout editing) ä¸¤é¡¹æ–°ä»»åŠ¡ï¼Œå¹¶æ„å»ºäº†å¤§è§„æ¨¡ 3D æŒ‡ä»¤æ•°æ®é›† MODEL ä»¥è¯„ä¼°æ¨¡å‹çš„ç©ºé—´èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSpatial 3D-LLM åœ¨å¤šé¡¹ 3D è§†è§‰è¯­è¨€ä»»åŠ¡ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿› (state-of-the-art) çš„æ€§èƒ½è¡¨ç°ã€‚è¿™ä¸€è¿›å±•è¯æ˜äº†é€šè¿‡æ¸è¿›å¼æŒ–æ˜æ·±å±‚ç©ºé—´ä¿¡æ¯æ¥å¢å¼ºæ¨¡å‹ç©ºé—´ç†è§£èƒ½åŠ›çš„æœ‰æ•ˆæ€§ï¼Œä¸º 3D åœºæ™¯ä¸‹çš„å¤æ‚å¤šæ¨¡æ€ä»»åŠ¡æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16524v1",
      "published_date": "2025-07-22 12:32:35 UTC",
      "updated_date": "2025-07-22 12:32:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:27.439543+00:00"
    },
    {
      "arxiv_id": "2507.16878v1",
      "title": "CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos",
      "title_zh": "CausalStepï¼šè§†é¢‘æ˜¾å¼åˆ†æ­¥å› æœæ¨ç†åŸºå‡†",
      "authors": [
        "Xuchen Li",
        "Xuzhao Li",
        "Shiyu Hu",
        "Kaiqi Huang",
        "Wentao Zhang"
      ],
      "abstract": "Recent advances in large language models (LLMs) have improved reasoning in text and image domains, yet achieving robust video reasoning remains a significant challenge. Existing video benchmarks mainly assess shallow understanding and reasoning and allow models to exploit global context, failing to rigorously evaluate true causal and stepwise reasoning. We present CausalStep, a benchmark designed for explicit stepwise causal reasoning in videos. CausalStep segments videos into causally linked units and enforces a strict stepwise question-answer (QA) protocol, requiring sequential answers and preventing shortcut solutions. Each question includes carefully constructed distractors based on error type taxonomy to ensure diagnostic value. The benchmark features 100 videos across six categories and 1,852 multiple-choice QA pairs. We introduce seven diagnostic metrics for comprehensive evaluation, enabling precise diagnosis of causal reasoning capabilities. Experiments with leading proprietary and open-source models, as well as human baselines, reveal a significant gap between current models and human-level stepwise reasoning. CausalStep provides a rigorous benchmark to drive progress in robust and interpretable video reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†CausalStepï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨è¯„ä¼°è§†é¢‘ä¸­æ˜¾å¼åˆ†æ­¥å› æœæ¨ç†(Stepwise Causal Reasoning)çš„åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç°æœ‰åŸºå‡†æµ‹è¯•ä¸»è¦è¯„ä¼°æµ…å±‚ç†è§£å¹¶å…è®¸æ¨¡å‹åˆ©ç”¨å…¨å±€ä¸Šä¸‹æ–‡(Global Context)å¯»æ‰¾æ·å¾„çš„é—®é¢˜ï¼ŒCausalStepå°†è§†é¢‘åˆ’åˆ†ä¸ºå…·æœ‰å› æœå…³ç³»çš„å•å…ƒï¼Œå¹¶æ‰§è¡Œä¸¥æ ¼çš„åˆ†æ­¥é—®ç­”(QA)åè®®ä»¥å¼ºåˆ¶æ‰§è¡Œé¡ºåºæ¨ç†ã€‚è¯¥åŸºå‡†æ¶µç›–6ä¸ªç±»åˆ«çš„100ä¸ªè§†é¢‘ï¼ŒåŒ…å«1,852ä¸ªåŸºäºé”™è¯¯åˆ†ç±»æ³•ç²¾å¿ƒè®¾è®¡çš„å¹²æ‰°é¡¹å¤šé€‰é¢˜å¯¹ï¼Œå¹¶å¼•å…¥äº†7é¡¹è¯Šæ–­æŒ‡æ ‡ç”¨äºå…¨é¢è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç›®å‰çš„é¢†å…ˆé—­æºå’Œå¼€æºæ¨¡å‹ä¸äººç±»æ°´å¹³çš„åˆ†æ­¥æ¨ç†ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚CausalStepä¸ºå®ç°ç¨³å¥ä¸”å¯è§£é‡Šçš„è§†é¢‘æ¨ç†æä¾›äº†ä¸¥è°¨çš„è¯„ä¼°æ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint, Under review",
      "pdf_url": "https://arxiv.org/pdf/2507.16878v1",
      "published_date": "2025-07-22 12:29:13 UTC",
      "updated_date": "2025-07-22 12:29:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:43.331811+00:00"
    },
    {
      "arxiv_id": "2507.16514v3",
      "title": "The Ever-Evolving Science Exam",
      "title_zh": "ä¸æ–­è¿›åŒ–çš„ç§‘å­¦è€ƒè¯•",
      "authors": [
        "Junying Wang",
        "Zicheng Zhang",
        "Yijin Guo",
        "Farong Wen",
        "Ye Shen",
        "Yingji Liang",
        "Yalun Wu",
        "Wenzhe Li",
        "Chunyi Li",
        "Zijian Chen",
        "Qi Jia",
        "Guangtao Zhai"
      ],
      "abstract": "As foundation models grow rapidly in capability and deployment, evaluating their scientific understanding becomes increasingly critical. Existing science benchmarks have made progress towards broad Range, wide Reach, and high Rigor, yet they often face two major challenges: data leakage risks that compromise benchmarking validity, and evaluation inefficiency due to large-scale testing. To address these issues, we introduce the Ever-Evolving Science Exam (EESE), a dynamic benchmark designed to reliably assess scientific capabilities in foundation models. Our approach consists of two components: 1) a non-public EESE-Pool with over 100K expertly constructed science instances (question-answer pairs) across 5 disciplines and 500+ subfields, built through a multi-stage pipeline ensuring Range, Reach, and Rigor, 2) a periodically updated 500-instance subset EESE, sampled and validated to enable leakage-resilient, low-overhead evaluations. Experiments on 32 open- and closed-source models demonstrate that EESE effectively differentiates the strengths and weaknesses of models in scientific fields and cognitive dimensions. Overall, EESE provides a robust, scalable, and forward-compatible solution for science benchmark design, offering a realistic measure of how well foundation models handle science questions. The project page is at: https://github.com/aiben-ch/EESE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ç§‘å­¦åŸºå‡†æµ‹è¯•é¢ä¸´çš„æ•°æ®æ³„éœ²é£é™©å’Œè¯„ä¼°æ•ˆç‡ä½ä¸‹é—®é¢˜ï¼Œæå‡ºäº†åŠ¨æ€åŸºå‡†æµ‹è¯•æ¡†æ¶ Ever-Evolving Science Exam (EESE)ï¼Œæ—¨åœ¨å¯é åœ°è¯„ä¼°åŸºç¡€æ¨¡å‹ (foundation models) çš„ç§‘å­¦èƒ½åŠ›ã€‚è¯¥æ¡†æ¶ç”±ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šä¸€ä¸ªåŒ…å«è¶…è¿‡ 10 ä¸‡ä¸ªä¸“å®¶æ„å»ºçš„ç§‘å­¦å®ä¾‹ã€æ¶µç›– 5 ä¸ªå­¦ç§‘å’Œ 500 å¤šä¸ªå­é¢†åŸŸçš„éå…¬å¼€ EESE-Poolï¼Œä»¥åŠä¸€ä¸ªå®šæœŸæ›´æ–°çš„ 500 å®ä¾‹å­é›† EESEã€‚é€šè¿‡å¤šé˜¶æ®µæµæ°´çº¿ç¡®ä¿è¯„ä¼°çš„å¹¿åº¦ (Range)ã€è¦†ç›–é¢ (Reach) å’Œä¸¥è°¨æ€§ (Rigor)ï¼Œè¯¥æ–¹æ³•å®ç°äº†å…·æœ‰æŠ—æ³„éœ²æ€§ä¸”ä½å¼€é”€çš„è¯„ä¼°æ¨¡å¼ã€‚åœ¨ 32 ä¸ªå¼€æºå’Œé—­æºæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒEESE èƒ½å¤Ÿæœ‰æ•ˆåŒºåˆ†æ¨¡å‹åœ¨ä¸åŒç§‘å­¦é¢†åŸŸå’Œè®¤çŸ¥ç»´åº¦ä¸Šçš„å¼ºé¡¹ä¸å¼±ç‚¹ã€‚æ€»ä½“è€Œè¨€ï¼ŒEESE ä¸ºç§‘å­¦åŸºå‡†æµ‹è¯•è®¾è®¡æä¾›äº†ä¸€ç§ç¨³å¥ã€å¯æ‰©å±•ä¸”å‘å‰å…¼å®¹çš„è§£å†³æ–¹æ¡ˆï¼Œä¸ºè¡¡é‡åŸºç¡€æ¨¡å‹å¤„ç†ç§‘å­¦é—®é¢˜çš„çœŸå®æ°´å¹³æä¾›äº†å¯é æ ‡å‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "33 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.16514v3",
      "published_date": "2025-07-22 12:22:16 UTC",
      "updated_date": "2025-09-30 05:00:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:47.405316+00:00"
    },
    {
      "arxiv_id": "2507.16511v1",
      "title": "Analogy making as amortised model construction",
      "title_zh": "ç±»æ¯”æ¨ç†å³æ‘Šé”€å¼æ¨¡å‹æ„å»º",
      "authors": [
        "David G. Nagy",
        "Tingke Shen",
        "Hanqi Zhou",
        "Charley M. Wu",
        "Peter Dayan"
      ],
      "abstract": "Humans flexibly construct internal models to navigate novel situations. To be useful, these internal models must be sufficiently faithful to the environment that resource-limited planning leads to adequate outcomes; equally, they must be tractable to construct in the first place. We argue that analogy plays a central role in these processes, enabling agents to reuse solution-relevant structure from past experiences and amortise the computational costs of both model construction (construal) and planning. Formalising analogies as partial homomorphisms between Markov decision processes, we sketch a framework in which abstract modules, derived from previous construals, serve as composable building blocks for new ones. This modular reuse allows for flexible adaptation of policies and representations across domains with shared structural essence.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†ç±»æ¯”æ¨ç† (Analogy making) è§†ä¸ºä¸€ç§æ‘Šé”€æ¨¡å‹æ„å»º (amortised model construction) è¿‡ç¨‹ï¼Œæ—¨åœ¨æ¢è®¨äººç±»å¦‚ä½•åœ¨åº”å¯¹æ–°ç¯å¢ƒæ—¶çµæ´»æ„å»ºæ—¢å¿ å®äºç¯å¢ƒåˆå…·å¤‡è®¡ç®—æ˜“å¤„ç†æ€§çš„å†…éƒ¨æ¨¡å‹ã€‚ä½œè€…æå‡ºç±»æ¯”åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­å‘æŒ¥ç€æ ¸å¿ƒä½œç”¨ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿé‡ç”¨è¿‡å»ç»éªŒä¸­ä¸è§£å†³æ–¹æ¡ˆç›¸å…³çš„ç»“æ„ï¼Œä»è€Œåˆ†æ‘Šæ¨¡å‹æ„å»º (construal) å’Œè§„åˆ’çš„è®¡ç®—æˆæœ¬ã€‚é€šè¿‡å°†ç±»æ¯”å½¢å¼åŒ–ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ (Markov decision processes, MDPs) ä¹‹é—´çš„éƒ¨åˆ†åŒæ€ (partial homomorphisms)ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨ä»å…ˆå‰è§£é‡Šä¸­å¯¼å‡ºçš„æŠ½è±¡æ¨¡å—ä½œä¸ºå¯ç»„åˆçš„æ„å»ºå—ã€‚è¿™ç§æ¨¡å—åŒ–é‡ç”¨æœºåˆ¶ä¸ä»…æé«˜äº†æ¨¡å‹æ„å»ºçš„æ•ˆç‡ï¼Œè¿˜æ”¯æŒåœ¨å…·æœ‰å…±äº«ç»“æ„æœ¬è´¨çš„ä¸åŒé¢†åŸŸä¹‹é—´å®ç°ç­–ç•¥ (policies) å’Œè¡¨ç¤º (representations) çš„çµæ´»é€‚åº”ã€‚è¯¥ç ”ç©¶ä¸ºç†è§£è®¤çŸ¥ç³»ç»Ÿå¦‚ä½•é€šè¿‡ç»“æ„é‡ç”¨æ¥åº”å¯¹å¤æ‚ç¯å¢ƒæä¾›äº†ç†è®ºæ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "RLC 2025 Finding the Frame Workshop",
      "pdf_url": "https://arxiv.org/pdf/2507.16511v1",
      "published_date": "2025-07-22 12:16:45 UTC",
      "updated_date": "2025-07-22 12:16:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:45.346314+00:00"
    },
    {
      "arxiv_id": "2507.16507v1",
      "title": "Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications",
      "title_zh": "ç»“åˆçŸ¥è¯†å›¾è°±çš„æ™ºèƒ½ä½“ RAGï¼šé¢å‘ç°å®åº”ç”¨ä¸­çš„å¤æ‚å¤šè·³æ¨ç†",
      "authors": [
        "Jean Lelong",
        "Adnane Errazine",
        "Annabelle Blangero"
      ],
      "abstract": "Conventional Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) but often fall short on complex queries, delivering limited, extractive answers and struggling with multiple targeted retrievals or navigating intricate entity relationships. This is a critical gap in knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system for exploring the scientific data of INRAE (France's National Research Institute for Agriculture, Food and Environment). INRAExplorer employs an LLM-based agent with a multi-tool architecture to dynamically engage a rich knowledge base, through a comprehensive knowledge graph derived from open access INRAE publications. This design empowers INRAExplorer to conduct iterative, targeted queries, retrieve exhaustive datasets (e.g., all publications by an author), perform multi-hop reasoning, and deliver structured, comprehensive answers. INRAExplorer serves as a concrete illustration of enhancing knowledge interaction in specialized fields.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿæ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚æŸ¥è¯¢ã€å¤šè·³æ¨ç†(multi-hop reasoning)ä»¥åŠå¤æ‚å®ä½“å…³ç³»å¯¼èˆªæ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºINRAExplorerçš„æ™ºèƒ½ä½“RAG (agentic RAG)ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿä¸“é—¨ç”¨äºæ¢ç´¢æ³•å›½å›½å®¶å†œä¸šã€é£Ÿå“ä¸ç¯å¢ƒç ”ç©¶é™¢(INRAE)çš„ç§‘å­¦æ•°æ®ï¼Œé‡‡ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„æ™ºèƒ½ä½“å’Œå¤šå·¥å…·æ¶æ„(multi-tool architecture)ï¼Œé€šè¿‡ä»å¼€æ”¾è·å–å‡ºç‰ˆç‰©ä¸­æ„å»ºçš„ç»¼åˆçŸ¥è¯†å›¾è°±(knowledge graph)åŠ¨æ€æ¥å…¥çŸ¥è¯†åº“ã€‚è¿™ç§è®¾è®¡ä½¿INRAExplorerèƒ½å¤Ÿæ‰§è¡Œè¿­ä»£å¼ã€é’ˆå¯¹æ€§çš„æŸ¥è¯¢ï¼Œå¹¶æ£€ç´¢å¦‚ç‰¹å®šä½œè€…æ‰€æœ‰å‡ºç‰ˆç‰©ç­‰è¯¦å°½æ•°æ®é›†ã€‚ç³»ç»Ÿå…·å¤‡å¼ºå¤§çš„å¤šè·³æ¨ç†(multi-hop reasoning)èƒ½åŠ›ï¼Œèƒ½å¤Ÿæä¾›ç»“æ„åŒ–ä¸”å…¨é¢çš„ç­”æ¡ˆã€‚ä½œä¸ºå¢å¼ºä¸“ä¸šé¢†åŸŸçŸ¥è¯†äº¤äº’çš„å…·ä½“æ¡ˆä¾‹ï¼ŒINRAExploreræœ‰æ•ˆè§£å†³äº†çŸ¥è¯†å¯†é›†å‹é¢†åŸŸä¸­å¤æ‚ä¿¡æ¯æ£€ç´¢ä¸æ•´åˆçš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2025 demo track, 4 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.16507v1",
      "published_date": "2025-07-22 12:03:10 UTC",
      "updated_date": "2025-07-22 12:03:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:52.237127+00:00"
    },
    {
      "arxiv_id": "2507.16488v1",
      "title": "ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs",
      "title_zh": "ICR Probeï¼šè¿½è¸ªéšè—çŠ¶æ€åŠ¨æ€æ¼”åŒ–ä»¥å®ç°å¤§è¯­è¨€æ¨¡å‹å¯é çš„å¹»è§‰æ£€æµ‹",
      "authors": [
        "Zhenliang Zhang",
        "Xinyu Hu",
        "Huixuan Zhang",
        "Junzhe Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "Large language models (LLMs) excel at various natural language processing tasks, but their tendency to generate hallucinations undermines their reliability. Existing hallucination detection methods leveraging hidden states predominantly focus on static and isolated representations, overlooking their dynamic evolution across layers, which limits efficacy. To address this limitation, we shift the focus to the hidden state update process and introduce a novel metric, the ICR Score (Information Contribution to Residual Stream), which quantifies the contribution of modules to the hidden states' update. We empirically validate that the ICR Score is effective and reliable in distinguishing hallucinations. Building on these insights, we propose a hallucination detection method, the ICR Probe, which captures the cross-layer evolution of hidden states. Experimental results show that the ICR Probe achieves superior performance with significantly fewer parameters. Furthermore, ablation studies and case analyses offer deeper insights into the underlying mechanism of this method, improving its interpretability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¹»è§‰ï¼ˆhallucinationï¼‰æ£€æµ‹ä¸­ç°æœ‰æ–¹æ³•å¿½è§†éšè—çŠ¶æ€ï¼ˆhidden statesï¼‰è·¨å±‚åŠ¨æ€æ¼”åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…³æ³¨éšè—çŠ¶æ€æ›´æ–°è¿‡ç¨‹çš„æ–°æ–¹æ¡ˆã€‚ç ”ç©¶è€…å¼•å…¥äº† ICR Score (Information Contribution to Residual Stream) æŒ‡æ ‡ï¼Œç”¨äºé‡åŒ–ä¸åŒæ¨¡å—å¯¹éšè—çŠ¶æ€æ›´æ–°çš„è´¡çŒ®åº¦ï¼Œå¹¶ç»éªŒæ€§åœ°è¯æ˜äº†è¯¥æŒ‡æ ‡åœ¨åŒºåˆ†å¹»è§‰æ–¹é¢çš„å¯é æ€§ã€‚åŸºäºæ­¤ï¼Œè¯¥ç ”ç©¶å¼€å‘äº† ICR Probe æ£€æµ‹å·¥å…·ï¼Œé€šè¿‡è¿½è¸ªéšè—çŠ¶æ€çš„è·¨å±‚æ¼”åŒ–åŠ¨æ€ï¼Œåœ¨æ˜¾è‘—å‡å°‘å‚æ•°é‡çš„æƒ…å†µä¸‹å®ç°äº†ä¼˜è¶Šçš„æ£€æµ‹æ€§èƒ½ã€‚æ¶ˆèå®éªŒå’Œæ¡ˆä¾‹åˆ†æè¿›ä¸€æ­¥é˜æ˜äº†è¯¥æ–¹æ³•çš„åº•å±‚æœºåˆ¶ï¼Œæ˜¾è‘—æå‡äº†å¹»è§‰æ£€æµ‹çš„å¯è§£é‡Šæ€§ï¼ˆinterpretabilityï¼‰ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 (Main Conference)",
      "pdf_url": "https://arxiv.org/pdf/2507.16488v1",
      "published_date": "2025-07-22 11:44:26 UTC",
      "updated_date": "2025-07-22 11:44:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:14:54.931669+00:00"
    },
    {
      "arxiv_id": "2507.17775v1",
      "title": "Comparison of Optimised Geometric Deep Learning Architectures, over Varying Toxicological Assay Data Environments",
      "title_zh": "ä¸åŒæ¯’ç†å­¦æ£€æµ‹æ•°æ®ç¯å¢ƒä¸‹ä¼˜åŒ–å‡ ä½•æ·±åº¦å­¦ä¹ æ¶æ„çš„å¯¹æ¯”ç ”ç©¶",
      "authors": [
        "Alexander D. Kalian",
        "Lennart Otte",
        "Jaewook Lee",
        "Emilio Benfenati",
        "Jean-Lou C. M. Dorne",
        "Claire Potter",
        "Olivia J. Osborne",
        "Miao Guo",
        "Christer Hogstrand"
      ],
      "abstract": "Geometric deep learning is an emerging technique in Artificial Intelligence (AI) driven cheminformatics, however the unique implications of different Graph Neural Network (GNN) architectures are poorly explored, for this space. This study compared performances of Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs) and Graph Isomorphism Networks (GINs), applied to 7 different toxicological assay datasets of varying data abundance and endpoint, to perform binary classification of assay activation. Following pre-processing of molecular graphs, enforcement of class-balance and stratification of all datasets across 5 folds, Bayesian optimisations were carried out, for each GNN applied to each assay dataset (resulting in 21 unique Bayesian optimisations). Optimised GNNs performed at Area Under the Curve (AUC) scores ranging from 0.728-0.849 (averaged across all folds), naturally varying between specific assays and GNNs. GINs were found to consistently outperform GCNs and GATs, for the top 5 of 7 most data-abundant toxicological assays. GATs however significantly outperformed over the remaining 2 most data-scarce assays. This indicates that GINs are a more optimal architecture for data-abundant environments, whereas GATs are a more optimal architecture for data-scarce environments. Subsequent analysis of the explored higher-dimensional hyperparameter spaces, as well as optimised hyperparameter states, found that GCNs and GATs reached measurably closer optimised states with each other, compared to GINs, further indicating the unique nature of GINs as a GNN algorithm.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶å¯¹æ¯”äº†ä¸‰ç§ä¸åŒçš„å›¾ç¥ç»ç½‘ç»œ(GNN)æ¶æ„â€”â€”Graph Convolutional Networks (GCNs)ã€Graph Attention Networks (GATs) å’Œ Graph Isomorphism Networks (GINs) åœ¨åŒ–å­¦ä¿¡æ¯å­¦æ¯’ç†å­¦åˆ†æä¸­çš„æ€§èƒ½è¡¨ç°ã€‚ç ”ç©¶åˆ©ç”¨ 7 ä¸ªå…·æœ‰ä¸åŒæ•°æ®ä¸°åº¦å’Œç»ˆç‚¹çš„æ¯’ç†å­¦æµ‹å®šæ•°æ®é›†ï¼Œåœ¨ç»è¿‡åˆ†å­å›¾é¢„å¤„ç†ã€ç±»åˆ«å¹³è¡¡å’Œ 5 æŠ˜äº¤å‰éªŒè¯åˆ†å±‚åï¼Œé’ˆå¯¹æ¯ç§æ¶æ„è¿›è¡Œäº† Bayesian optimisationsã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼˜åŒ–åçš„ GNN æ¨¡å‹åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šçš„ AUC è¯„åˆ†ä»‹äº 0.728 è‡³ 0.849 ä¹‹é—´ã€‚ç ”ç©¶å‘ç°ï¼Œåœ¨æ•°æ®å……è¶³çš„å‰ 5 ä¸ªæ•°æ®é›†ä¸­ï¼ŒGINs çš„è¡¨ç°ä¸€è‡´ä¼˜äº GCNs å’Œ GATsï¼Œæ˜¾ç¤ºå‡ºå…¶åœ¨æ•°æ®ä¸°æ²›ç¯å¢ƒä¸‹çš„ä¼˜åŠ¿ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨æ•°æ®åŒ®ä¹çš„ 2 ä¸ªæ•°æ®é›†ä¸­ï¼ŒGATs çš„è¡¨ç°åˆ™æ˜¾è‘—æ›´ä¼˜ï¼Œè¡¨æ˜ GATs æ˜¯æ•°æ®ç¨€ç¼ºç¯å¢ƒä¸‹çš„æ›´ä¼˜æ¶æ„ã€‚å¯¹é«˜ç»´è¶…å‚æ•°ç©ºé—´çš„åˆ†æè¿›ä¸€æ­¥è¯å®ï¼ŒGCNs ä¸ GATs çš„ä¼˜åŒ–çŠ¶æ€å½¼æ­¤æ›´ä¸ºæ¥è¿‘ï¼Œè€Œ GINs ä½œä¸ºä¸€ç§ GNN ç®—æ³•å…·æœ‰å…¶ç‹¬ç‰¹æ€§ã€‚è¯¥ç ”ç©¶ä¸ºé’ˆå¯¹ä¸åŒæ•°æ®è§„æ¨¡çš„æ¯’ç†å­¦ä»»åŠ¡é€‰æ‹©æœ€åˆé€‚çš„ Geometric deep learning æ¶æ„æä¾›äº†é‡è¦ä¾æ®ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17775v1",
      "published_date": "2025-07-22 11:38:11 UTC",
      "updated_date": "2025-07-22 11:38:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:03.394381+00:00"
    },
    {
      "arxiv_id": "2507.16480v1",
      "title": "Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots",
      "title_zh": "é¢å‘å·®å¼‚çš„è®¾è®¡ï¼šäººç±»ç‰¹å¾å¦‚ä½•å½±å“å¯¹åä½œæœºå™¨äººçš„è®¤çŸ¥",
      "authors": [
        "Sabrina Livanec",
        "Laura LondoÃ±o",
        "Michael Gorki",
        "Adrian RÃ¶fer",
        "Abhinav Valada",
        "Andrea Kiesel"
      ],
      "abstract": "The development of assistive robots for social collaboration raises critical questions about responsible and inclusive design, especially when interacting with individuals from protected groups such as those with disabilities or advanced age. Currently, research is scarce on how participants assess varying robot behaviors in combination with diverse human needs, likely since participants have limited real-world experience with advanced domestic robots. In the current study, we aim to address this gap while using methods that enable participants to assess robot behavior, as well as methods that support meaningful reflection despite limited experience. In an online study, 112 participants (from both experimental and control groups) evaluated 7 videos from a total of 28 variations of human-robot collaboration types. The experimental group first completed a cognitive-affective mapping (CAM) exercise on human-robot collaboration before providing their ratings. Although CAM reflection did not significantly affect overall ratings, it led to more pronounced assessments for certain combinations of robot behavior and human condition. Most importantly, the type of human-robot collaboration influences the assessment. Antisocial robot behavior was consistently rated as the lowest, while collaboration with aged individuals elicited more sensitive evaluations. Scenarios involving object handovers were viewed more positively than those without them. These findings suggest that both human characteristics and interaction paradigms influence the perceived acceptability of collaborative robots, underscoring the importance of prosocial design. They also highlight the potential of reflective methods, such as CAM, to elicit nuanced feedback, supporting the development of user-centered and socially responsible robotic systems tailored to diverse populations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººç±»ç‰¹å¾å¦‚ä½•å¡‘é€ å¯¹åä½œæœºå™¨äºº (Collaborative Robots) çš„æ„ŸçŸ¥ï¼Œé‡ç‚¹å…³æ³¨è€å¹´äººå’Œæ®‹éšœäººå£«ç­‰ç‰¹å®šç¾¤ä½“çš„åŒ…å®¹æ€§è®¾è®¡ã€‚é€šè¿‡ä¸€é¡¹åŒ…å«112åå‚ä¸è€…çš„åœ¨çº¿ç ”ç©¶ï¼Œç ”ç©¶è€…è¯„ä¼°äº†å¤šç§äººæœºåä½œå˜ä½“ï¼Œå¹¶å¼•å…¥è®¤çŸ¥æƒ…æ„Ÿæ˜ å°„ (Cognitive-Affective Mapping, CAM) ä½œä¸ºè¾…åŠ©å‚ä¸è€…è¿›è¡Œæ·±åº¦åæ€çš„å·¥å…·ã€‚å®éªŒå‘ç°ï¼Œå°½ç®¡ CAM åæ€æœªæ”¹å˜æ•´ä½“è¯„åˆ†ï¼Œä½†å®ƒèƒ½ä¿ƒä½¿å‚ä¸è€…å¯¹ç‰¹å®šæœºå™¨äººè¡Œä¸ºä¸äººç±»çŠ¶å†µçš„ç»„åˆåšå‡ºæ›´å¾®å¦™çš„è¯„ä»·ã€‚ç»“æœæ˜¾ç¤ºï¼Œåç¤¾ä¼šè¡Œä¸º (Antisocial behavior) çš„è¯„åˆ†æœ€ä½ï¼Œè€Œæ¶‰åŠè€å¹´äººçš„åœºæ™¯å’Œç‰©ä½“ç§»äº¤ (Object handovers) çš„äº’åŠ¨æ›´æ˜“è·å¾—ç§¯ææˆ–æ•æ„Ÿçš„è¯„ä»·ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œäººç±»ç‰¹å¾ä¸äº¤äº’èŒƒå¼å…±åŒå½±å“åä½œæœºå™¨äººçš„å¯æ¥å—æ€§ï¼Œå¼ºè°ƒäº†äº²ç¤¾ä¼šè®¾è®¡ (Prosocial design) çš„å¿…è¦æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶éªŒè¯äº† CAM åœ¨è·å–ç”¨æˆ·ç»†å¾®åé¦ˆæ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºå¼€å‘æ»¡è¶³å¤šæ ·åŒ–éœ€æ±‚çš„ç¤¾ä¼šè´£ä»»å‹æœºå™¨äººç³»ç»Ÿæä¾›äº†é‡è¦æ”¯æŒã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16480v1",
      "published_date": "2025-07-22 11:36:08 UTC",
      "updated_date": "2025-07-22 11:36:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:05.021892+00:00"
    },
    {
      "arxiv_id": "2507.16478v1",
      "title": "ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training",
      "title_zh": "ACTï¼šé€šè¿‡åˆæˆæ•°æ®ç”Ÿæˆä¸è‡ªé€‚åº”è®­ç»ƒå¼¥åˆä»£ç ç¿»è¯‘çš„æ€§èƒ½å·®è·",
      "authors": [
        "Shreya Saxena",
        "Siva Prasad",
        "Zishan Ahmad",
        "Vishal Vaddina"
      ],
      "abstract": "Code translation is a crucial process in software development and migration projects, enabling interoperability between different programming languages and enhancing software adaptability and thus longevity. Traditional automated translation methods rely heavily on handcrafted transformation rules, which often lack flexibility and scalability. Meanwhile, advanced language models present promising alternatives but are often limited by proprietary, API-based implementations that raise concerns over data security and reliance. In this paper, we present Auto-Train for Code Translation (ACT), an innovative framework that aims to improve code translation capabilities by enabling in-house finetuning of open-source Large Language Models (LLMs). ACT's automated pipeline significantly boosts the performance of these models, narrowing the gap between open-source accessibility and the high performance of closed-source solutions. Central to ACT is its synthetic data generation module, which builds extensive, high-quality datasets from initial code samples, incorporating unit tests to ensure functional accuracy and diversity. ACT's evaluation framework incorporates execution-level checks, offering a comprehensive assessment of translation quality. A key feature in ACT is its controller module, which manages the entire pipeline by dynamically adjusting hyperparameters, orchestrating iterative data generation, and finetuning based on real-time evaluations. This enables ACT to intelligently optimize when to continue training, generate additional targeted training data, or stop the process. Our results demonstrate that ACT consistently enhances the effectiveness of open-source models, offering businesses and developers a secure and reliable alternative. Additionally, applying our data generation pipeline to industry-scale migration projects has led to a notable increase in developer acceleration.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä»£ç ç¿»è¯‘(Code translation)ä¸­ä¼ ç»Ÿè§„åˆ™æ–¹æ³•ç¼ºä¹çµæ´»æ€§ä»¥åŠé—­æºå¤§æ¨¡å‹(LLMs)å­˜åœ¨çš„æ•°æ®å®‰å…¨å’Œä¾èµ–æ€§é—®é¢˜ï¼Œæå‡ºäº†ACT (Auto-Train for Code Translation)æ¡†æ¶ã€‚ACTé€šè¿‡å…¶è‡ªåŠ¨åŒ–çš„æµæ°´çº¿æ”¯æŒå¯¹å¼€æºLLMsè¿›è¡Œæœ¬åœ°å¾®è°ƒ(In-house finetuning)ï¼Œä»è€Œæ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½å¹¶ç¼©å°ä¸é—­æºæ–¹æ¡ˆçš„å·®è·ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºåˆæˆæ•°æ®ç”Ÿæˆ(Synthetic data generation)æ¨¡å—ï¼Œè¯¥æ¨¡å—åˆ©ç”¨åŸå§‹ä»£ç æ ·æœ¬æ„å»ºé«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶ç»“åˆå•å…ƒæµ‹è¯•(Unit tests)ç¡®ä¿ä»£ç çš„åŠŸèƒ½å‡†ç¡®æ€§ã€‚æ­¤å¤–ï¼ŒACTå¼•å…¥äº†æ§åˆ¶å™¨(Controller)æ¨¡å—ï¼Œèƒ½å¤Ÿæ ¹æ®æ‰§è¡Œçº§(Execution-level)è¯„ä¼°ç»“æœåŠ¨æ€è°ƒæ•´è¶…å‚æ•°ï¼Œåè°ƒè¿­ä»£çš„æ•°æ®ç”Ÿæˆä¸å¾®è°ƒè¿‡ç¨‹ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒACTèƒ½æŒç»­å¢å¼ºå¼€æºæ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œä¸ºå¼€å‘è€…æä¾›å®‰å…¨å¯é çš„æ›¿ä»£æ–¹æ¡ˆã€‚åœ¨å®é™…å·¥ä¸šçº§è¿ç§»é¡¹ç›®ä¸­ï¼Œè¯¥æ¡†æ¶çš„åº”ç”¨æ˜¾è‘—åŠ é€Ÿäº†å¼€å‘è¿›ç¨‹ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16478v1",
      "published_date": "2025-07-22 11:35:35 UTC",
      "updated_date": "2025-07-22 11:35:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:10.641223+00:00"
    },
    {
      "arxiv_id": "2507.16877v1",
      "title": "ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension",
      "title_zh": "ReMeRECï¼šå…³ç³»æ„ŸçŸ¥çš„å¤šå®ä½“æŒ‡ä»£è¡¨è¾¾ç†è§£",
      "authors": [
        "Yizhi Hu",
        "Zezhao Tian",
        "Xingqun Qi",
        "Chen Su",
        "Bingkun Yang",
        "Junhui Yin",
        "Muyi Sun",
        "Man Zhang",
        "Zhenan Sun"
      ],
      "abstract": "Referring Expression Comprehension (REC) aims to localize specified entities or regions in an image based on natural language descriptions. While existing methods handle single-entity localization, they often ignore complex inter-entity relationships in multi-entity scenes, limiting their accuracy and reliability. Additionally, the lack of high-quality datasets with fine-grained, paired image-text-relation annotations hinders further progress. To address this challenge, we first construct a relation-aware, multi-entity REC dataset called ReMeX, which includes detailed relationship and textual annotations. We then propose ReMeREC, a novel framework that jointly leverages visual and textual cues to localize multiple entities while modeling their inter-relations. To address the semantic ambiguity caused by implicit entity boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron (TMP), which dynamically infers both the quantity and span of entities from fine-grained textual cues, producing distinctive representations. Additionally, our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and global scene understanding. To further improve language comprehension for fine-grained prompts, we also construct a small-scale auxiliary dataset, EntityText, generated using large language models. Experiments on four benchmark datasets show that ReMeREC achieves state-of-the-art performance in multi-entity grounding and relation prediction, outperforming existing approaches by a large margin.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒ‡ä»£æ€§è¡¨è¾¾ç†è§£ (Referring Expression Comprehension, REC) åœ¨å¤„ç†å¤šå®ä½“åœºæ™¯æ—¶å¿½è§†å®ä½“é—´å¤æ‚å…³ç³»ä»¥åŠç¼ºä¹é«˜è´¨é‡ç»†ç²’åº¦æ ‡æ³¨æ•°æ®é›†çš„é—®é¢˜ï¼Œæå‡ºäº† ReMeREC æ¡†æ¶ã€‚ç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº† ReMeX æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«è¯¦ç»†çš„å…³ç³»å’Œæ–‡æœ¬æ ‡æ³¨ï¼Œä¸ºå¤šå®ä½“å…³ç³»æ„ŸçŸ¥ç ”ç©¶æä¾›äº†æ”¯æ’‘ã€‚ReMeREC æ¡†æ¶å¼•å…¥äº†æ–‡æœ¬è‡ªé€‚åº”å¤šå®ä½“æ„ŸçŸ¥å™¨ (Text-adaptive Multi-entity Perceptron, TMP)ï¼Œèƒ½å¤Ÿæ ¹æ®ç»†ç²’åº¦æ–‡æœ¬çº¿ç´¢åŠ¨æ€æ¨æ–­å®ä½“çš„æ•°é‡ä¸è·¨åº¦ï¼Œä»è€Œç”Ÿæˆå…·æœ‰è¾¨è¯†åº¦çš„ç‰¹å¾è¡¨ç¤ºå¹¶è§£å†³è¯­ä¹‰æ­§ä¹‰ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é€šè¿‡å®ä½“é—´å…³ç³»æ¨ç†å™¨ (Entity Inter-relationship Reasoner, EIR) å¢å¼ºäº†å…³ç³»æ¨ç†èƒ½åŠ›å’Œå…¨å±€åœºæ™¯ç†è§£ï¼Œå¹¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (LLMs) æ„å»ºçš„è¾…åŠ©æ•°æ®é›† EntityText è¿›ä¸€æ­¥ä¼˜åŒ–äº†è¯­è¨€ç†è§£ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒReMeREC åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤šå®ä½“å®šä½å’Œå…³ç³»é¢„æµ‹ä»»åŠ¡ä¸­å‡è¾¾åˆ°äº† State-of-the-art (SOTA) æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16877v1",
      "published_date": "2025-07-22 11:23:48 UTC",
      "updated_date": "2025-07-22 11:23:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:10.832326+00:00"
    },
    {
      "arxiv_id": "2507.21131v1",
      "title": "NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback",
      "title_zh": "NPOï¼šåŸºäºç»“æ„åŒ–äººç±»åé¦ˆçš„å¯¹é½ä¸å…ƒå¯¹é½å­¦ä¹ ",
      "authors": [
        "Madhava Gaikwad",
        "Ashwini Ramchandra Doke"
      ],
      "abstract": "We present NPO, an alignment-aware learning framework that operationalizes feedback-driven adaptation in human-in-the-loop decision systems. Unlike prior approaches that treat alignment as a static or post-hoc property, NPO introduces a formalization of alignment loss that is measurable, supervisable, and reducible under structured feedback. In parallel, we propose meta-alignment as the fidelity of the monitoring process that governs retraining or override triggers, and show that it is formally reducible to primary alignment via threshold fidelity. Our implementation spans a scalable operational loop involving scenario scoring, threshold tuning, policy validation, and structured feedback ingestion, including \"likes\", overrides, and abstentions. We provide formal convergence results under stochastic feedback and show that both alignment loss and monitoring fidelity converge additively. Empirically, NPO demonstrates measurable value in hyperscale deployment settings. A simulation-based artifact and ablation studies further illustrate the theoretical principles in action. Together, NPO offers a compact, inspectable architecture for continual alignment monitoring, helping bridge theoretical alignment guarantees with practical reliability in dynamic environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NPOï¼Œä¸€ç§å…·æœ‰å¯¹é½æ„è¯†(alignment-aware)çš„å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°äººåœ¨å›è·¯(human-in-the-loop)å†³ç­–ç³»ç»Ÿä¸­çš„åé¦ˆé©±åŠ¨è‡ªé€‚åº”ã€‚ä¸ä»¥å¾€å°†å¯¹é½è§†ä¸ºé™æ€æˆ–äº‹åå±æ€§çš„æ–¹æ³•ä¸åŒï¼ŒNPOå¼•å…¥äº†å¯æµ‹é‡ã€å¯ç›‘ç£ä¸”åœ¨ç»“æ„åŒ–åé¦ˆä¸‹å¯é™ä½çš„å¯¹é½æŸå¤±(alignment loss)å½¢å¼åŒ–å®šä¹‰ã€‚åŒæ—¶ï¼Œè¯¥ç ”ç©¶æå‡ºäº†å…ƒå¯¹é½(meta-alignment)æ¦‚å¿µï¼Œç”¨äºè¡¡é‡ç›‘ç®¡å†è®­ç»ƒæˆ–è¦†ç›–è§¦å‘è¿‡ç¨‹çš„ä¿çœŸåº¦ï¼Œå¹¶è¯æ˜äº†å…¶åœ¨ç†è®ºä¸Šå¯å½’çº¦ä¸ºåŸºç¡€å¯¹é½ã€‚NPOçš„å®ç°åŒ…å«ä¸€ä¸ªå¯æ‰©å±•çš„æ“ä½œå¾ªç¯ï¼Œæ¶‰åŠåœºæ™¯è¯„åˆ†ã€é˜ˆå€¼è°ƒæ•´ã€ç­–ç•¥éªŒè¯ä»¥åŠåŒ…æ‹¬â€œç‚¹èµâ€ã€è¦†ç›–å’Œå¼ƒæƒåœ¨å†…çš„ç»“æ„åŒ–åé¦ˆæ‘„å–ã€‚å®éªŒè¯æ˜ï¼Œåœ¨éšæœºåé¦ˆä¸‹å¯¹é½æŸå¤±å’Œç›‘æ§ä¿çœŸåº¦å‡å…·æœ‰æ”¶æ•›æ€§ï¼Œä¸”NPOåœ¨è¶…å¤§è§„æ¨¡éƒ¨ç½²åœºæ™¯ä¸­å…·æœ‰æ˜¾è‘—ä»·å€¼ã€‚è¯¥æ¡†æ¶ä¸ºæŒç»­å¯¹é½ç›‘æ§æä¾›äº†ä¸€ä¸ªç´§å‡‘ä¸”å¯æ£€æŸ¥çš„æ¶æ„ï¼Œæœ‰æ•ˆå¼¥åˆäº†ç†è®ºå¯¹é½ä¿è¯ä¸åŠ¨æ€ç¯å¢ƒä¸‹çš„å®é™…å¯é æ€§ä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.21131v1",
      "published_date": "2025-07-22 11:23:18 UTC",
      "updated_date": "2025-07-22 11:23:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:08.336798+00:00"
    },
    {
      "arxiv_id": "2507.16473v2",
      "title": "Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs",
      "title_zh": "é€‰é¡¹è¯±å¯¼æŠ½è±¡MDPä¸­åŸºäºå˜åˆ†åŒæ€çš„æ—¶åºæŠ½è±¡å­¦ä¹ ",
      "authors": [
        "Chang Li",
        "Yaren Zhang",
        "Haoran Lv",
        "Qiong Cao",
        "Chao Xue",
        "Xiaodong He"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable reasoning ability through explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step textual explanations is computationally expensive and slow. To overcome this, we aim to develop a framework for efficient, implicit reasoning, where the model \"thinks\" in a latent space without generating explicit text for every step. We propose that these latent thoughts can be modeled as temporally-extended abstract actions, or options, within a hierarchical reinforcement learning framework. To effectively learn a diverse library of options as latent embeddings, we first introduce the Variational Markovian Option Critic (VMOC), an off-policy algorithm that uses variational inference within the HiT-MDP framework. To provide a rigorous foundation for using these options as an abstract reasoning space, we extend the theory of continuous MDP homomorphisms. This proves that learning a policy in the simplified, abstract latent space, for which VMOC is suited, preserves the optimality of the solution to the original, complex problem. Finally, we propose a cold-start procedure that leverages supervised fine-tuning (SFT) data to distill human reasoning demonstrations into this latent option space, providing a rich initialization for the model's reasoning capabilities. Extensive experiments demonstrate that our approach achieves strong performance on complex logical reasoning benchmarks and challenging locomotion tasks, validating our framework as a principled method for learning abstract skills for both language and control.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ˜¾å¼é“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†ä¸­è®¡ç®—æˆæœ¬é«˜ä¸”é€Ÿåº¦æ…¢çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åœ¨æ½œç©ºé—´è¿›è¡Œéšæ€§æ¨ç†çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†æ½œæ€ç»´å»ºæ¨¡ä¸ºåˆ†å±‚å¼ºåŒ–å­¦ä¹ (Hierarchical Reinforcement Learning)ä¸­çš„æ—¶é—´æ‰©å±•æŠ½è±¡åŠ¨ä½œï¼Œå³é€‰é¡¹(Options)ã€‚ä½œè€…å¼•å…¥äº†å˜åˆ†é©¬å°”å¯å¤«é€‰é¡¹è¯„è®ºå®¶(Variational Markovian Option Critic, VMOC)ï¼Œé€šè¿‡åœ¨HiT-MDPæ¡†æ¶å†…åˆ©ç”¨å˜åˆ†æ¨ç†æ¥å­¦ä¹ å¤šæ ·åŒ–çš„æ½œåµŒå…¥é€‰é¡¹ã€‚ä¸ºäº†ç¡®ç«‹ç†è®ºåŸºç¡€ï¼Œç ”ç©¶æ‰©å±•äº†è¿ç»­MDPåŒæ€(MDP homomorphisms)ç†è®ºï¼Œè¯æ˜äº†åœ¨ç®€åŒ–çš„æ½œç©ºé—´ä¸­å­¦ä¹ ç­–ç•¥èƒ½å¤Ÿä¿æŒåŸå§‹å¤æ‚é—®é¢˜è§£çš„æœ€ä¼˜æ€§ã€‚æ­¤å¤–ï¼Œé€šè¿‡å†·å¯åŠ¨æµç¨‹åˆ©ç”¨æœ‰ç›‘ç£å¾®è°ƒ(SFT)æ•°æ®å°†äººç±»æ¨ç†æ¼”ç¤ºè’¸é¦è‡³æ½œé€‰é¡¹ç©ºé—´ï¼Œä¸ºæ¨¡å‹æä¾›äº†ä¸°å¯Œçš„æ¨ç†åˆå§‹åŒ–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤æ‚é€»è¾‘æ¨ç†åŸºå‡†å’ŒæŒ‘æˆ˜æ€§è¿åŠ¨ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸ºè¯­è¨€ä¸æ§åˆ¶é¢†åŸŸçš„æŠ½è±¡æŠ€èƒ½å­¦ä¹ æä¾›äº†ä¸€ç§æœ‰åŸåˆ™çš„æ–¹æ³•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16473v2",
      "published_date": "2025-07-22 11:22:58 UTC",
      "updated_date": "2025-07-24 08:23:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:40.687224+00:00"
    },
    {
      "arxiv_id": "2507.16467v1",
      "title": "Estimating Treatment Effects with Independent Component Analysis",
      "title_zh": "åŸºäºç‹¬ç«‹æˆåˆ†åˆ†æçš„å¤„ç†æ•ˆåº”ä¼°è®¡",
      "authors": [
        "Patrik Reizinger",
        "Lester Mackey",
        "Wieland Brendel",
        "Rahul Krishnan"
      ],
      "abstract": "The field of causal inference has developed a variety of methods to accurately estimate treatment effects in the presence of nuisance. Meanwhile, the field of identifiability theory has developed methods like Independent Component Analysis (ICA) to identify latent sources and mixing weights from data. While these two research communities have developed largely independently, they aim to achieve similar goals: the accurate and sample-efficient estimation of model parameters. In the partially linear regression (PLR) setting, Mackey et al. (2018) recently found that estimation consistency can be improved with non-Gaussian treatment noise. Non-Gaussianity is also a crucial assumption for identifying latent factors in ICA. We provide the first theoretical and empirical insights into this connection, showing that ICA can be used for causal effect estimation in the PLR model. Surprisingly, we find that linear ICA can accurately estimate multiple treatment effects even in the presence of Gaussian confounders or nonlinear nuisance.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†å› æœæ¨ç†(Causal Inference)ä¸å¯è¯†åˆ«æ€§ç†è®º(Identifiability Theory)ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œæ—¨åœ¨æå‡å­˜åœ¨å¹²æ‰°é¡¹æ—¶å¤„ç†æ•ˆåº”(Treatment Effects)ä¼°è®¡çš„å‡†ç¡®æ€§ä¸æ ·æœ¬æ•ˆç‡ã€‚ç ”ç©¶åŸºäºéƒ¨åˆ†çº¿æ€§å›å½’(Partially Linear Regression, PLR)æ¨¡å‹ï¼Œå°†éé«˜æ–¯å¤„ç†å™ªå£°(Non-Gaussian treatment noise)ä¸ç‹¬ç«‹æˆåˆ†åˆ†æ(Independent Component Analysis, ICA)è¯†åˆ«æ½œåœ¨å› å­çš„æ ¸å¿ƒå‡è®¾ç›¸ç»“åˆã€‚ä½œè€…é¦–æ¬¡ä»ç†è®ºå’Œå®è¯è§’åº¦æ­ç¤ºäº†ICAåœ¨å› æœæ•ˆåº”ä¼°è®¡ä¸­çš„åº”ç”¨æ½œåŠ›ï¼Œè¯æ˜äº†å…¶åœ¨PLRæ¨¡å‹ä¸­çš„æœ‰æ•ˆæ€§ã€‚ä»¤äººæ„å¤–çš„å‘ç°æ˜¯ï¼Œå³ä¾¿åœ¨å­˜åœ¨é«˜æ–¯æ··æ‚å› ç´ (Gaussian confounders)æˆ–éçº¿æ€§å¹²æ‰°(Nonlinear nuisance)çš„æƒ…å†µä¸‹ï¼Œçº¿æ€§ICAä»èƒ½å‡†ç¡®ä¼°è®¡å¤šä¸ªå¤„ç†æ•ˆåº”ã€‚è¯¥ç ”ç©¶ä¸ä»…æ•´åˆäº†ä¸¤ä¸ªä¼ ç»Ÿä¸Šç‹¬ç«‹å‘å±•çš„å­¦æœ¯é¢†åŸŸï¼Œä¹Ÿä¸ºå¤æ‚æ•°æ®ç¯å¢ƒä¸‹çš„ç¨³å¥å› æœæ¨æ–­æä¾›äº†å…¨æ–°çš„æ–¹æ³•è®ºè§†è§’ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16467v1",
      "published_date": "2025-07-22 11:16:23 UTC",
      "updated_date": "2025-07-22 11:16:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:35.588048+00:00"
    },
    {
      "arxiv_id": "2507.16876v2",
      "title": "Machine learning-based multimodal prognostic models integrating pathology images and high-throughput omic data for overall survival prediction in cancer: a systematic review",
      "title_zh": "æ•´åˆç—…ç†å›¾åƒä¸é«˜é€šé‡ç»„å­¦æ•°æ®çš„æœºå™¨å­¦ä¹ å¤šæ¨¡æ€ç™Œç—‡æ€»ç”Ÿå­˜æœŸé¢„æµ‹é¢„åæ¨¡å‹ï¼šç³»ç»Ÿç»¼è¿°",
      "authors": [
        "Charlotte Jennings",
        "Andrew Broad",
        "Lucy Godson",
        "Emily Clarke",
        "David Westhead",
        "Darren Treanor"
      ],
      "abstract": "Multimodal machine learning integrating histopathology and molecular data shows promise for cancer prognostication. We systematically reviewed studies combining whole slide images (WSIs) and high-throughput omics to predict overall survival. Searches of EMBASE, PubMed, and Cochrane CENTRAL (12/08/2024), plus citation screening, identified eligible studies. Data extraction used CHARMS; bias was assessed with PROBAST+AI; synthesis followed SWiM and PRISMA 2020. Protocol: PROSPERO (CRD42024594745).\n  Forty-eight studies (all since 2017) across 19 cancer types met criteria; all used The Cancer Genome Atlas. Approaches included regularised Cox regression (n=4), classical ML (n=13), and deep learning (n=31). Reported c-indices ranged 0.550-0.857; multimodal models typically outperformed unimodal ones. However, all studies showed unclear/high bias, limited external validation, and little focus on clinical utility.\n  Multimodal WSI-omics survival prediction is a fast-growing field with promising results but needs improved methodological rigor, broader datasets, and clinical evaluation.\n  Funded by NPIC, Leeds Teaching Hospitals NHS Trust, UK (Project 104687), supported by UKRI Industrial Strategy Challenge Fund.",
      "tldr_zh": "è¯¥ç³»ç»Ÿç»¼è¿°è¯„ä¼°äº†æ•´åˆç—…ç†åˆ‡ç‰‡å…¨æ‰«æå›¾åƒ(WSIs)ä¸é«˜é€šé‡ç»„å­¦æ•°æ®(high-throughput omic data)ç”¨äºç™Œç—‡æ€»ç”Ÿå­˜æœŸ(overall survival)é¢„æµ‹çš„å¤šæ¨¡æ€æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ç ”ç©¶åˆ†æäº†è‡ª2017å¹´ä»¥æ¥çš„48é¡¹ç›¸å…³ç ”ç©¶ï¼Œæ¶µç›–äº†æ­£åˆ™åŒ–Coxå›å½’(regularised Cox regression)ã€ä¼ ç»Ÿæœºå™¨å­¦ä¹ (classical ML)åŠæ·±åº¦å­¦ä¹ (deep learning)ç­‰å¤šç§æ–¹æ³•ã€‚ç»“æœè¡¨æ˜ï¼Œå¤šæ¨¡æ€æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½é€šå¸¸ä¼˜äºå•æ¨¡æ€æ¨¡å‹ï¼Œå…¶CæŒ‡æ•°(c-indices)åœ¨0.550è‡³0.857ä¹‹é—´ã€‚å°½ç®¡è¯¥é¢†åŸŸå‘å±•è¿…é€Ÿä¸”ç»“æœå…·æœ‰å‰æ™¯ï¼Œä½†ç ”ç©¶å‘ç°ç°æœ‰æ–‡çŒ®æ™®éå­˜åœ¨è¾ƒé«˜çš„åå€šé£é™©ï¼Œä¸”ç¼ºä¹å……è¶³çš„å¤–éƒ¨éªŒè¯(external validation)å’Œä¸´åºŠåº”ç”¨è¯„ä¼°ã€‚å› æ­¤ï¼Œæœªæ¥ç ”ç©¶éœ€è¦åŠ å¼ºæ–¹æ³•è®ºçš„ä¸¥è°¨æ€§ï¼Œå¹¶åˆ©ç”¨æ›´å¹¿æ³›çš„æ•°æ®é›†æ¥éªŒè¯æ¨¡å‹çš„ä¸´åºŠå®ç”¨æ€§ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "Main article (50 pages, inc 3 tables, 4 figures). Supplementary material included with additional methodological information and data",
      "pdf_url": "https://arxiv.org/pdf/2507.16876v2",
      "published_date": "2025-07-22 11:02:51 UTC",
      "updated_date": "2025-07-29 11:19:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:32.984323+00:00"
    },
    {
      "arxiv_id": "2507.16454v1",
      "title": "Improving ASP-based ORS Schedules through Machine Learning Predictions",
      "title_zh": "åˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹æ”¹è¿›åŸºäº ASP çš„æ‰‹æœ¯å®¤è°ƒåº¦æ–¹æ¡ˆ",
      "authors": [
        "Pierangela Bruno",
        "Carmine Dodaro",
        "Giuseppe GalatÃ ",
        "Marco Maratea",
        "Marco Mochi"
      ],
      "abstract": "The Operating Room Scheduling (ORS) problem deals with the optimization of daily operating room surgery schedules. It is a challenging problem subject to many constraints, like to determine the starting time of different surgeries and allocating the required resources, including the availability of beds in different department units. Recently, solutions to this problem based on Answer Set Programming (ASP) have been delivered. Such solutions are overall satisfying but, when applied to real data, they can currently only verify whether the encoding aligns with the actual data and, at most, suggest alternative schedules that could have been computed. As a consequence, it is not currently possible to generate provisional schedules. Furthermore, the resulting schedules are not always robust.\n  In this paper, we integrate inductive and deductive techniques for solving these issues. We first employ machine learning algorithms to predict the surgery duration, from historical data, to compute provisional schedules. Then, we consider the confidence of such predictions as an additional input to our problem and update the encoding correspondingly in order to compute more robust schedules. Results on historical data from the ASL1 Liguria in Italy confirm the viability of our integration.\n  Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰‹æœ¯å®¤è°ƒåº¦(Operating Room Scheduling, ORS)é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæœºå™¨å­¦ä¹ (Machine Learning)é¢„æµ‹ä¸å›ç­”é›†ç¼–ç¨‹(Answer Set Programming, ASP)çš„é›†æˆæ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœç°æœ‰ASPæ–¹æ³•åœ¨ç”Ÿæˆä¸´æ—¶è°ƒåº¦è¡¨åŠé²æ£’æ€§æ–¹é¢çš„å±€é™ã€‚ç ”ç©¶é¦–å…ˆåˆ©ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å¯¹å†å²æ•°æ®è¿›è¡Œå»ºæ¨¡ï¼Œä»¥é¢„æµ‹æ‰‹æœ¯æŒç»­æ—¶é—´ï¼Œä»è€Œå¡«è¡¥äº†ç”Ÿæˆå‰ç»æ€§è°ƒåº¦æ–¹æ¡ˆçš„æŠ€æœ¯ç©ºç™½ã€‚éšåï¼Œé€šè¿‡å°†é¢„æµ‹çš„ç½®ä¿¡åº¦ä½œä¸ºçº¦æŸæ¡ä»¶å¼•å…¥ASPç¼–ç ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–äº†è°ƒåº¦æ–¹æ¡ˆçš„æŠ—å¹²æ‰°èƒ½åŠ›ã€‚åŸºäºæ„å¤§åˆ©ASL1 LiguriaåŒ»ç–—æœºæ„å†å²æ•°æ®çš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§å½’çº³ä¸æ¼”ç»ç›¸ç»“åˆçš„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤æ‚çš„èµ„æºåˆ†é…çº¦æŸã€‚è¯¥æˆæœè¯æ˜äº†é€šè¿‡æ•´åˆæ•°æ®é©±åŠ¨çš„é¢„æµ‹ä¸é€»è¾‘æ¨ç†ï¼Œå¯ä»¥æ˜¾è‘—æå‡åŒ»ç–—è°ƒåº¦ç³»ç»Ÿçš„å®ç”¨æ€§å’Œå¯é æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, International Conference on Logic Programming, Under consideration in Theory and Practice of Logic Programming (TPLP)",
      "pdf_url": "https://arxiv.org/pdf/2507.16454v1",
      "published_date": "2025-07-22 10:56:46 UTC",
      "updated_date": "2025-07-22 10:56:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:42.877193+00:00"
    },
    {
      "arxiv_id": "2508.00877v1",
      "title": "Satellite Connectivity Prediction for Fast-Moving Platforms",
      "title_zh": "é¢å‘é«˜é€Ÿç§»åŠ¨å¹³å°çš„å«æ˜Ÿè¿é€šæ€§é¢„æµ‹",
      "authors": [
        "Chao Yan",
        "Babak Mafakheri"
      ],
      "abstract": "Satellite connectivity is gaining increased attention as the demand for seamless internet access, especially in transportation and remote areas, continues to grow. For fast-moving objects such as aircraft, vehicles, or trains, satellite connectivity is critical due to their mobility and frequent presence in areas without terrestrial coverage. Maintaining reliable connectivity in these cases requires frequent switching between satellite beams, constellations, or orbits. To enhance user experience and address challenges like long switching times, Machine Learning (ML) algorithms can analyze historical connectivity data and predict network quality at specific locations. This allows for proactive measures, such as network switching before connectivity issues arise. In this paper, we analyze a real dataset of communication between a Geostationary Orbit (GEO) satellite and aircraft over multiple flights, using ML to predict signal quality. Our prediction model achieved an F1 score of 0.97 on the test data, demonstrating the accuracy of machine learning in predicting signal quality during flight. By enabling seamless broadband service, including roaming between different satellite constellations and providers, our model addresses the need for real-time predictions of signal quality. This approach can further be adapted to automate satellite and beam-switching mechanisms to improve overall communication efficiency. The model can also be retrained and applied to any moving object with satellite connectivity, using customized datasets, including connected vehicles and trains.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹é£æœºã€åˆ—è½¦ç­‰å¿«é€Ÿç§»åŠ¨å¹³å°ï¼ˆfast-moving platformsï¼‰åœ¨ç¼ºä¹åœ°é¢ç½‘ç»œè¦†ç›–æ—¶ï¼Œç»´æŒå¯é å«æ˜Ÿé€šä¿¡ï¼ˆSatellite connectivityï¼‰çš„å…³é”®æŒ‘æˆ˜ã€‚é’ˆå¯¹é¢‘ç¹åˆ‡æ¢å«æ˜Ÿæ³¢æŸæˆ–æ˜Ÿåº§å¸¦æ¥çš„é«˜å»¶è¿Ÿé—®é¢˜ï¼Œç ”ç©¶æå‡ºåˆ©ç”¨æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰ç®—æ³•åˆ†æå†å²æ•°æ®ï¼Œå¯¹ç‰¹å®šä½ç½®çš„ç½‘ç»œè´¨é‡è¿›è¡Œä¸»åŠ¨é¢„æµ‹ã€‚è®ºæ–‡é€šè¿‡åˆ†æåœ°çƒé™æ­¢è½¨é“ï¼ˆGeostationary Orbit, GEOï¼‰å«æ˜Ÿä¸å¤šæ¶æ¬¡èˆªç­ä¹‹é—´çš„çœŸå®é€šä¿¡æ•°æ®é›†ï¼Œæ„å»ºäº†é«˜ç²¾åº¦çš„ä¿¡å·è´¨é‡é¢„æµ‹æ¨¡å‹ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ¨¡å‹åœ¨æµ‹è¯•æ•°æ®ä¸Šçš„ F1 score è¾¾åˆ°äº† 0.97ï¼Œå……åˆ†éªŒè¯äº†æœºå™¨å­¦ä¹ åœ¨é£è¡Œè¿‡ç¨‹ä¸­é¢„æµ‹ä¿¡å·è´¨é‡çš„å‡†ç¡®æ€§ã€‚è¿™ç§æ–¹æ³•æ”¯æŒåœ¨è¿æ¥ä¸­æ–­å‰é‡‡å–ä¸»åŠ¨ç½‘ç»œåˆ‡æ¢æªæ–½ï¼Œä»è€Œå®ç°äº†æ— ç¼å®½å¸¦æœåŠ¡å’Œè·¨æ˜Ÿåº§æ¼«æ¸¸ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜å¯è¿›ä¸€æ­¥æ‰©å±•è‡³è¿æ¥è½¦è¾†å’Œç«è½¦ç­‰å„ç±»ç§»åŠ¨ç‰©ä½“ï¼Œé€šè¿‡å®šåˆ¶åŒ–æ•°æ®é›†æå‡æ•´ä½“é€šä¿¡æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.00877v1",
      "published_date": "2025-07-22 10:33:48 UTC",
      "updated_date": "2025-07-22 10:33:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:43.389169+00:00"
    },
    {
      "arxiv_id": "2507.16434v1",
      "title": "From model-based learning to model-free behaviour with Meta-Interpretive Learning",
      "title_zh": "åŸºäº Meta-Interpretive Learning å®ç°ä»åŸºäºæ¨¡å‹çš„å­¦ä¹ åˆ°æ— æ¨¡å‹è¡Œä¸ºçš„è½¬å˜",
      "authors": [
        "Stassa Patsantzis"
      ],
      "abstract": "A \"model\" is a theory that describes the state of an environment and the effects of an agent's decisions on the environment. A model-based agent can use its model to predict the effects of its future actions and so plan ahead, but must know the state of the environment. A model-free agent cannot plan, but can act without a model and without completely observing the environment. An autonomous agent capable of acting independently in novel environments must combine both sets of capabilities. We show how to create such an agent with Meta-Interpretive Learning used to learn a model-based Solver used to train a model-free Controller that can solve the same planning problems as the Solver. We demonstrate the equivalence in problem-solving ability of the two agents on grid navigation problems in two kinds of environment: randomly generated mazes, and lake maps with wide open areas. We find that all navigation problems solved by the Solver are also solved by the Controller, indicating the two are equivalent.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•é€šè¿‡å…ƒè§£é‡Šå­¦ä¹ (Meta-Interpretive Learning)ä½¿è‡ªä¸»æ™ºèƒ½ä½“åœ¨æœªçŸ¥ç¯å¢ƒä¸­ç»“åˆåŸºäºæ¨¡å‹(model-based)çš„è§„åˆ’èƒ½åŠ›ä¸æ— æ¨¡å‹(model-free)çš„æ‰§è¡Œèƒ½åŠ›ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„æ–¹æ³•ï¼Œåˆ©ç”¨Meta-Interpretive Learningå­¦ä¹ ä¸€ä¸ªåŸºäºæ¨¡å‹çš„æ±‚è§£å™¨(Solver)ï¼Œéšåç”±è¯¥æ±‚è§£å™¨è®­ç»ƒå‡ºä¸€ä¸ªèƒ½å¤Ÿè§£å†³ç›¸åŒè§„åˆ’é—®é¢˜çš„æ— æ¨¡å‹æ§åˆ¶å™¨(Controller)ã€‚ç ”ç©¶åœ¨ä¸¤ç§ä¸åŒç±»å‹çš„ç½‘æ ¼å¯¼èˆªç¯å¢ƒä¸­éªŒè¯äº†ç³»ç»Ÿçš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬éšæœºç”Ÿæˆçš„è¿·å®«(mazes)å’Œå…·æœ‰å¹¿é˜”å¼€æ”¾åŒºåŸŸçš„æ¹–æ³Šåœ°å›¾(lake maps)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ§åˆ¶å™¨(Controller)èƒ½å¤ŸæˆåŠŸè§£å†³æ‰€æœ‰ç”±æ±‚è§£å™¨(Solver)å¤„ç†çš„å¯¼èˆªé—®é¢˜ï¼Œè¯æ˜äº†ä¸¤è€…åœ¨é—®é¢˜è§£å†³èƒ½åŠ›ä¸Šçš„ç­‰æ•ˆæ€§ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†æ™ºèƒ½ä½“å¦‚ä½•ä»ä¾èµ–ç¯å¢ƒæ¨¡å‹å’ŒçŠ¶æ€æ„ŸçŸ¥çš„å¤æ‚è§„åˆ’é˜¶æ®µï¼Œå¹³æ»‘è¿‡æ¸¡åˆ°èƒ½å¤Ÿç‹¬ç«‹ä¸”é«˜æ•ˆæ‰§è¡Œä»»åŠ¡çš„è¡Œä¸ºé˜¶æ®µã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16434v1",
      "published_date": "2025-07-22 10:28:08 UTC",
      "updated_date": "2025-07-22 10:28:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:50.788345+00:00"
    },
    {
      "arxiv_id": "2507.16430v2",
      "title": "Beyond Algorethics: Addressing the Ethical and Anthropological Challenges of AI Recommender Systems",
      "title_zh": "è¶…è¶Šç®—æ³•ä¼¦ç†ï¼šåº”å¯¹äººå·¥æ™ºèƒ½æ¨èç³»ç»Ÿçš„ä¼¦ç†ä¸äººç±»å­¦æŒ‘æˆ˜",
      "authors": [
        "Octavian M. Machidon"
      ],
      "abstract": "This paper examines the ethical and anthropological challenges posed by AI-driven recommender systems (RSs), which increasingly shape digital environments and social interactions. By curating personalized content, RSs do not merely reflect user preferences but actively construct experiences across social media, entertainment platforms, and e-commerce. Their influence raises concerns over privacy, autonomy, and mental well-being, while existing approaches such as \"algorethics\" - the effort to embed ethical principles into algorithmic design - remain insufficient. RSs inherently reduce human complexity to quantifiable profiles, exploit user vulnerabilities, and prioritize engagement over well-being. The paper advances a three-dimensional framework for human-centered RSs, integrating policies and regulation, interdisciplinary research, and education. These strategies are mutually reinforcing: research provides evidence for policy, policy enables safeguards and standards, and education equips users to engage critically. By connecting ethical reflection with governance and digital literacy, the paper argues that RSs can be reoriented to enhance autonomy and dignity rather than undermine them.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº† AI é©±åŠ¨çš„æ¨èç³»ç»Ÿ (Recommender Systems) åœ¨å¡‘é€ æ•°å­—ç¯å¢ƒå’Œç¤¾äº¤äº’åŠ¨è¿‡ç¨‹ä¸­å¸¦æ¥çš„ä¼¦ç†ä¸äººç±»å­¦æŒ‘æˆ˜ã€‚è®ºæ–‡æŒ‡å‡ºï¼Œæ¨èç³»ç»Ÿä¸ä»…åæ˜ ç”¨æˆ·åå¥½ï¼Œæ›´åœ¨ä¸»åŠ¨æ„å»ºç”¨æˆ·ä½“éªŒï¼Œè€Œç°æœ‰çš„â€œç®—æ³•ä¼¦ç†â€ (Algorethics) å°è¯•å¾€å¾€ä¸è¶³ä»¥è§£å†³å…¶å°†äººç±»å¤æ‚æ€§ç®€åŒ–ä¸ºå¯é‡åŒ–ç‰¹å¾ä»¥åŠå‰¥å¤ºç”¨æˆ·è‡ªä¸»æƒç­‰æ·±å±‚é—®é¢˜ã€‚ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€ä¸ªä»¥äººä¸ºæœ¬çš„æ¨èç³»ç»Ÿä¸‰ç»´æ¡†æ¶ï¼Œæ•´åˆäº†æ”¿ç­–ç›‘ç®¡ (Policies and Regulation)ã€è·¨å­¦ç§‘ç ”ç©¶ (Interdisciplinary Research) å’Œæ•™è‚² (Education) ä¸‰ä¸ªç»´åº¦ã€‚è¯¥æ¡†æ¶å¼ºè°ƒè¿™ä¸‰ä¸ªç­–ç•¥ç›¸äº’åŠ å¼ºï¼Œå³ç ”ç©¶ä¸ºæ”¿ç­–æä¾›è¯æ®ï¼Œæ”¿ç­–ç¡®ç«‹å®‰å…¨ä¿éšœæ ‡å‡†ï¼Œè€Œæ•™è‚²åˆ™æå‡ç”¨æˆ·çš„æ‰¹åˆ¤æ€§å‚ä¸èƒ½åŠ›ã€‚é€šè¿‡å°†ä¼¦ç†åæ€ä¸æ²»ç†åŠæ•°å­—ç´ å…»ç›¸ç»“åˆï¼Œè¯¥ç ”ç©¶è®ºè¯äº†æ¨èç³»ç»Ÿå¯ä»¥è¢«é‡æ–°å®šå‘ï¼Œä»è€Œåœ¨æå‡ä¸ªä½“è‡ªä¸»æƒå’Œå°Šä¸¥æ–¹é¢å‘æŒ¥ç§¯æä½œç”¨ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16430v2",
      "published_date": "2025-07-22 10:22:08 UTC",
      "updated_date": "2025-11-11 08:14:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:52.982266+00:00"
    },
    {
      "arxiv_id": "2507.16414v1",
      "title": "Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework",
      "title_zh": "è¯†åˆ« LLMs ä¸­çš„é¢„è®­ç»ƒæ•°æ®ï¼šä¸€ç§åŸºäºç¥ç»å…ƒæ¿€æ´»çš„æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Hongyi Tang",
        "Zhihao Zhu",
        "Yi Yang"
      ],
      "abstract": "The performance of large language models (LLMs) is closely tied to their training data, which can include copyrighted material or private information, raising legal and ethical concerns. Additionally, LLMs face criticism for dataset contamination and internalizing biases. To address these issues, the Pre-Training Data Detection (PDD) task was proposed to identify if specific data was included in an LLM's pre-training corpus. However, existing PDD methods often rely on superficial features like prediction confidence and loss, resulting in mediocre performance. To improve this, we introduce NA-PDD, a novel algorithm analyzing differential neuron activation patterns between training and non-training data in LLMs. This is based on the observation that these data types activate different neurons during LLM inference. We also introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data transformations to ensure consistent time distributions between training and non-training data. Our experiments demonstrate that NA-PDD significantly outperforms existing methods across three benchmarks and multiple LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) é¢„è®­ç»ƒæ•°æ®æ£€æµ‹ (Pre-Training Data Detection, PDD) ä¸­ç°æœ‰æ–¹æ³•ä¾èµ–ç½®ä¿¡åº¦å’ŒæŸå¤±ç­‰è¡¨å±‚ç‰¹å¾å¯¼è‡´æ€§èƒ½ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º NA-PDD çš„æ–°å‹æ£€æµ‹ç®—æ³•ã€‚NA-PDD é€šè¿‡åˆ†æ LLMs åœ¨æ¨ç†è¿‡ç¨‹ä¸­è®­ç»ƒæ•°æ®ä¸éè®­ç»ƒæ•°æ®ä¹‹é—´å·®å¼‚åŒ–çš„ç¥ç»å…ƒæ¿€æ´»æ¨¡å¼ (Neuron Activation patterns) æ¥è¯†åˆ«ç‰¹å®šæ•°æ®æ˜¯å¦åŒ…å«åœ¨é¢„è®­ç»ƒè¯­æ–™åº“ä¸­ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼•å…¥äº† CCNewsPDD åŸºå‡†æµ‹è¯•ï¼Œåˆ©ç”¨ä¸¥æ ¼çš„æ•°æ®è½¬æ¢ç¡®ä¿è®­ç»ƒå’Œéè®­ç»ƒæ•°æ®å…·æœ‰ä¸€è‡´çš„æ—¶é—´åˆ†å¸ƒï¼Œä»è€Œæ¶ˆé™¤äº†æ—¶é—´åå·®å¯¹å®éªŒç»“æœçš„å½±å“ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒNA-PDD åœ¨ä¸‰ä¸ªåŸºå‡†æµ‹è¯•å’Œå¤šç§ LLMs ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œä¸ºè§£å†³æ•°æ®é›†æ±¡æŸ“ã€ç‰ˆæƒåŠéšç§ç­‰ä¼¦ç†æ³•å¾‹æŒ‘æˆ˜æä¾›äº†æ›´é«˜æ•ˆçš„æ£€æµ‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16414v1",
      "published_date": "2025-07-22 10:05:30 UTC",
      "updated_date": "2025-07-22 10:05:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:15:57.492629+00:00"
    },
    {
      "arxiv_id": "2509.22655v1",
      "title": "GOAT: A Large Dataset of Paired Guitar Audio Recordings and Tablatures",
      "title_zh": "GOATï¼šä¸€ä¸ªå¤§å‹å‰ä»–éŸ³é¢‘å½•éŸ³ä¸å‰ä»–è°±é…å¯¹æ•°æ®é›†",
      "authors": [
        "Jackson Loth",
        "Pedro Sarmento",
        "Saurjya Sarkar",
        "Zixun Guo",
        "Mathieu Barthet",
        "Mark Sandler"
      ],
      "abstract": "In recent years, the guitar has received increased attention from the music information retrieval (MIR) community driven by the challenges posed by its diverse playing techniques and sonic characteristics. Mainly fueled by deep learning approaches, progress has been limited by the scarcity and limited annotations of datasets. To address this, we present the Guitar On Audio and Tablatures (GOAT) dataset, comprising 5.9 hours of unique high-quality direct input audio recordings of electric guitars from a variety of different guitars and players. We also present an effective data augmentation strategy using guitar amplifiers which delivers near-unlimited tonal variety, of which we provide a starting 29.5 hours of audio. Each recording is annotated using guitar tablatures, a guitar-specific symbolic format supporting string and fret numbers, as well as numerous playing techniques. For this we utilise both the Guitar Pro format, a software for tablature playback and editing, and a text-like token encoding. Furthermore, we present competitive results using GOAT for MIDI transcription and preliminary results for a novel approach to automatic guitar tablature transcription. We hope that GOAT opens up the possibilities to train novel models on a wide variety of guitar-related MIR tasks, from synthesis to transcription to playing technique detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† GOAT (Guitar On Audio and Tablatures) æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³å‰ä»–éŸ³ä¹ä¿¡æ¯æ£€ç´¢ (MIR) é¢†åŸŸå› æ•°æ®é›†ç¨€ç¼ºå’Œæ ‡æ³¨æœ‰é™è€Œå¯¼è‡´æ·±åº¦å­¦ä¹ è¿›å±•å—é˜»çš„é—®é¢˜ã€‚è¯¥æ•°æ®é›†åŒ…å« 5.9 å°æ—¶æ¥è‡ªä¸åŒå‰äººå’Œæ¼”å¥è€…çš„é«˜è´¨é‡ç›´æ¥è¾“å…¥ (direct input) éŸ³é¢‘å½•éŸ³ï¼Œå¹¶ç»“åˆå‰ä»–æ”¾å¤§å™¨ (guitar amplifiers) æ•°æ®å¢å¼ºç­–ç•¥æ‰©å±•å‡º 29.5 å°æ—¶å…·å¤‡é«˜åº¦éŸ³è‰²å¤šæ ·æ€§çš„ç´ æã€‚æ¯æ®µå½•éŸ³å‡é‡‡ç”¨å‰ä»–è°± (tablatures) è¿›è¡Œç²¾ç»†æ ‡æ³¨ï¼Œæ¶µç›–äº†å¼¦å·ã€å“ä½åŠå¤šç§æ¼”å¥æŠ€å·§ï¼Œå¹¶åŒæ—¶æ”¯æŒ Guitar Pro æ ¼å¼ä¸ç±»æ–‡æœ¬ä»¤ç‰Œç¼–ç  (text-like token encoding)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGOAT åœ¨ MIDI è½¬è°± (MIDI transcription) ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå¹¶ä¸ºè‡ªåŠ¨å‰ä»–è°±è½¬è°± (automatic guitar tablature transcription) è¿™ä¸€æ–°é¢–æ–¹æ³•æä¾›äº†åˆæ­¥éªŒè¯ã€‚è¯¥æ•°æ®é›†çš„å¼€æ”¾ä¸ºå¼€å‘æ¶µç›–åˆæˆã€è½¬è°±åŠæ¼”å¥æŠ€å·§æ£€æµ‹ (playing technique detection) åœ¨å†…çš„å„ç±»å‰ä»– MIR æ¨¡å‹å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "To be published in Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2025",
      "pdf_url": "https://arxiv.org/pdf/2509.22655v1",
      "published_date": "2025-07-22 10:02:14 UTC",
      "updated_date": "2025-07-22 10:02:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:04.784836+00:00"
    },
    {
      "arxiv_id": "2507.16405v1",
      "title": "Self-Supervised Inductive Logic Programming",
      "title_zh": "è‡ªç›‘ç£å½’çº³é€»è¾‘ç¨‹åºè®¾è®¡",
      "authors": [
        "Stassa Patsantzis"
      ],
      "abstract": "Inductive Logic Programming (ILP) approaches like Meta \\-/ Interpretive Learning (MIL) can learn, from few examples, recursive logic programs with invented predicates that generalise well to unseen instances. This ability relies on a background theory and negative examples, both carefully selected with expert knowledge of a learning problem and its solutions. But what if such a problem-specific background theory or negative examples are not available? We formalise this question as a new setting for Self-Supervised ILP and present a new MIL algorithm that learns in the new setting from some positive labelled, and zero or more unlabelled examples, and automatically generates, and labels, new positive and negative examples during learning. We implement this algorithm in Prolog in a new MIL system, called Poker. We compare Poker to state-of-the-art MIL system Louise on experiments learning grammars for Context-Free and L-System languages from labelled, positive example strings, no negative examples, and just the terminal vocabulary of a language, seen in examples, as a first-order background theory. We introduce a new approach for the principled selection of a second-order background theory as a Second Order Definite Normal Form (SONF), sufficiently general to learn all programs in a class, thus removing the need for a backgound theory tailored to a learning task. We find that Poker's performance improves with increasing numbers of automatically generated examples while Louise, bereft of negative examples, over-generalises.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Self-Supervised Inductive Logic Programming (ILP)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»ŸMeta-Interpretive Learning (MIL)æ–¹æ³•é«˜åº¦ä¾èµ–äººå·¥é€‰æ‹©çš„èƒŒæ™¯ç†è®ºå’Œè´Ÿæ ·æœ¬çš„é—®é¢˜ã€‚ä½œè€…å®šä¹‰äº†è‡ªç›‘ç£Inductive Logic Programmingè¿™ä¸€æ–°è®¾ç½®ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåä¸ºPokerçš„æ–°ç³»ç»Ÿï¼Œèƒ½å¤Ÿåœ¨å­¦ä¹ è¿‡ç¨‹ä¸­åˆ©ç”¨å°‘é‡æ­£æ ·æœ¬å’Œæ— æ ‡ç­¾æ•°æ®è‡ªåŠ¨ç”Ÿæˆå¹¶æ ‡æ³¨æ–°çš„æ­£è´Ÿæ ·æœ¬ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†Second Order Definite Normal Form (SONF)ä½œä¸ºé€šç”¨çš„äºŒé˜¶èƒŒæ™¯ç†è®ºï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†ä¸ºç‰¹å®šå­¦ä¹ ä»»åŠ¡å®šåˆ¶èƒŒæ™¯çŸ¥è¯†çš„éœ€æ±‚ã€‚åœ¨å­¦ä¹ Context-Freeå’ŒL-Systemè¯­è¨€è¯­æ³•çš„å®éªŒä¸­ï¼ŒPokerçš„è¡¨ç°éšç€è‡ªåŠ¨ç”Ÿæˆæ ·æœ¬æ•°é‡çš„å¢åŠ è€Œæ˜¾è‘—æå‡ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºçº¿ç³»ç»ŸLouiseåœ¨ç¼ºä¹è´Ÿæ ·æœ¬çš„æƒ…å†µä¸‹å®¹æ˜“å‡ºç°è¿‡åº¦æ³›åŒ–é—®é¢˜ã€‚è¯¥æˆæœè¯æ˜äº†åœ¨ç¼ºä¹ä¸“å®¶å¹²é¢„çš„æƒ…å†µä¸‹ï¼Œç³»ç»Ÿä»èƒ½é«˜æ•ˆå­¦ä¹ å¹¶æ³›åŒ–å…·æœ‰è‰¯å¥½æ€§èƒ½çš„é€’å½’é€»è¾‘ç¨‹åºã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16405v1",
      "published_date": "2025-07-22 09:57:24 UTC",
      "updated_date": "2025-07-22 09:57:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:04.484481+00:00"
    },
    {
      "arxiv_id": "2507.16395v2",
      "title": "LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning",
      "title_zh": "åŸºäºæ˜¾å¼å’Œéšå¼ä¾èµ–æ¨ç†çš„å¤§æ¨¡å‹é©±åŠ¨æäº¤è§£è€¦åä½œæ¨¡å‹",
      "authors": [
        "Bo Hou",
        "Xin Tan",
        "Kai Zheng",
        "Fang Liu",
        "Yinghao Zhu",
        "Li Zhang"
      ],
      "abstract": "Atomic commits, which address a single development concern, are a best practice in software development. In practice, however, developers often produce tangled commits that mix unrelated changes, complicating code review and maintenance. Prior untangling approaches (rule-based, feature-based, or graph-based) have made progress but typically rely on shallow signals and struggle to distinguish explicit dependencies (e.g., control/data flow) from implicit ones (e.g., semantic or conceptual relationships). In this paper, we propose ColaUntangle, a new collaborative consultation framework for commit untangling that models both explicit and implicit dependencies among code changes. ColaUntangle integrates Large Language Model (LLM)-driven agents in a multi-agent architecture: one agent specializes in explicit dependencies, another in implicit ones, and a reviewer agent synthesizes their perspectives through iterative consultation. To capture structural and contextual information, we construct Explicit and Implicit Contexts, enabling agents to reason over code relationships with both symbolic and semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C# and 14k Java tangled commits). Experimental results show that ColaUntangle outperforms the best-performing baseline, achieving an improvement of 44% on the C# dataset and 82% on the Java dataset. These findings highlight the potential of LLM-based collaborative frameworks for advancing automated commit untangling tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¯ä»¶å¼€å‘ä¸­æ··æ‚æäº¤(tangled commits)å¢åŠ ä»£ç è¯„å®¡å’Œç»´æŠ¤éš¾åº¦çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºColaUntangleçš„ååŒå’¨è¯¢æ¡†æ¶ï¼Œç”¨äºé€šè¿‡æ˜¾å¼å’Œéšå¼ä¾èµ–æ¨ç†æ¥å®ç°æäº¤è§£æ„ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†ç”±å¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æ¶æ„ï¼Œåˆ†åˆ«è®¾ç«‹æ™ºèƒ½ä½“å¤„ç†æ§åˆ¶æµç­‰æ˜¾å¼ä¾èµ–(explicit dependencies)å’Œè¯­ä¹‰ç­‰éšå¼ä¾èµ–(implicit dependencies)ï¼Œå¹¶ç”±è¯„å®¡æ™ºèƒ½ä½“é€šè¿‡è¿­ä»£å’¨è¯¢ç»¼åˆå„æ–¹è§‚ç‚¹ã€‚ä¸ºäº†æ•æ‰ç»“æ„åŒ–å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç ”ç©¶æ„å»ºäº†æ˜¾å¼å’Œéšå¼ä¸Šä¸‹æ–‡(Explicit and Implicit Contexts)ï¼Œèµ‹äºˆæ™ºèƒ½ä½“åœ¨ç¬¦å·å’Œè¯­ä¹‰æ·±åº¦ä¸Šæ¨ç†ä»£ç å…³ç³»çš„èƒ½åŠ›ã€‚å®éªŒåœ¨C#å’ŒJavaä¸¤ä¸ªæ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºColaUntangleåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œåˆ†åˆ«å®ç°äº†44%å’Œ82%çš„æå‡ã€‚è¿™ä¸€æˆæœè¯æ˜äº†åŸºäºLLMçš„ååŒæ¡†æ¶åœ¨æ¨è¿›è‡ªåŠ¨åŒ–æäº¤è§£æ„ä»»åŠ¡æ–¹é¢çš„æ˜¾è‘—ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16395v2",
      "published_date": "2025-07-22 09:42:13 UTC",
      "updated_date": "2025-11-05 06:26:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:21.686780+00:00"
    },
    {
      "arxiv_id": "2507.16389v1",
      "title": "From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure",
      "title_zh": "ä»å¹³é¢åˆ°çƒé¢ï¼šåˆ©ç”¨åŸºäºè¡¨é¢çš„ fMRI ä¸çš®å±‚ç»“æ„é‡æ–°å®šä¹‰å¤§è„‘è§£ç ",
      "authors": [
        "Sijin Yu",
        "Zijiao Chen",
        "Wenxuan Wu",
        "Shengxian Chen",
        "Zhongliang Liu",
        "Jingxin Nie",
        "Xiaofen Xing",
        "Xiangmin Xu",
        "Xin Zhang"
      ],
      "abstract": "Reconstructing visual stimuli from human brain activity (e.g., fMRI) bridges neuroscience and computer vision by decoding neural representations. However, existing methods often overlook critical brain structure-function relationships, flattening spatial information and neglecting individual anatomical variations. To address these issues, we propose (1) a novel sphere tokenizer that explicitly models fMRI signals as spatially coherent 2D spherical data on the cortical surface; (2) integration of structural MRI (sMRI) data, enabling personalized encoding of individual anatomical variations; and (3) a positive-sample mixup strategy for efficiently leveraging multiple fMRI scans associated with the same visual stimulus. Collectively, these innovations enhance reconstruction accuracy, biological interpretability, and generalizability across individuals. Experiments demonstrate superior reconstruction performance compared to SOTA methods, highlighting the effectiveness and interpretability of our biologically informed approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è„‘è§£ç æ–¹æ³•å¿½ç•¥è„‘ç»“æ„åŠŸèƒ½å…³ç³»åŠä¸ªä½“è§£å‰–å·®å¼‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºçš®å±‚è¡¨é¢ fMRI å’Œå¤§è„‘ç»“æ„çš„æ–°å‹é‡æ„æ¡†æ¶ã€‚ç ”ç©¶å¼•å…¥äº†çƒå½¢æ ‡è®°å™¨ï¼ˆsphere tokenizerï¼‰ï¼Œå°† fMRI ä¿¡å·æ˜¾å¼å»ºæ¨¡ä¸ºå¤§è„‘çš®å±‚è¡¨é¢å…·æœ‰ç©ºé—´ç›¸å¹²æ€§çš„ 2D çƒå½¢æ•°æ®ï¼Œå¹¶æ•´åˆç»“æ„æ ¸ç£å…±æŒ¯ï¼ˆsMRIï¼‰æ•°æ®ä»¥å®ç°ä¸ªä½“è§£å‰–å·®å¼‚çš„ä¸ªæ€§åŒ–ç¼–ç ã€‚æ­¤å¤–ï¼Œç ”ç©¶é‡‡ç”¨æ­£æ ·æœ¬æ··åˆï¼ˆpositive-sample mixupï¼‰ç­–ç•¥ï¼Œé€šè¿‡æœ‰æ•ˆåˆ©ç”¨ä¸åŒä¸€è§†è§‰åˆºæ¿€ç›¸å…³çš„å¤šæ¬¡ fMRI æ‰«ææ¥æå‡æ¨¡å‹æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰åˆºæ¿€é‡æ„æ€§èƒ½ä¸Šä¼˜äºå½“å‰çš„ SOTA æ–¹æ³•ã€‚è¿™ç§ç”Ÿç‰©å¯å‘çš„æ–¹æ³•ä¸ä»…æ˜¾è‘—æé«˜äº†é‡æ„ç²¾åº¦ï¼Œè¿˜å¢å¼ºäº†æ¨¡å‹çš„ç”Ÿç‰©å­¦å¯è§£é‡Šæ€§ï¼ˆbiological interpretabilityï¼‰å’Œè·¨ä¸ªä½“çš„é€šç”¨æ€§ï¼ˆgeneralizabilityï¼‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 14 figures, ICCV Findings 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16389v1",
      "published_date": "2025-07-22 09:34:39 UTC",
      "updated_date": "2025-07-22 09:34:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:30.178588+00:00"
    },
    {
      "arxiv_id": "2507.16382v1",
      "title": "Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹å¼•å¯¼çš„å¼ºåŒ–å­¦ä¹ åœ¨å…·å¤‡é¿éšœèƒ½åŠ›çš„ç¼–é˜Ÿæ§åˆ¶ä¸­çš„åº”ç”¨",
      "authors": [
        "Chenhao Yao",
        "Zike Yuan",
        "Xiaoxu Liu",
        "Chi Zhu"
      ],
      "abstract": "Multi-Agent Systems (MAS) excel at accomplishing complex objectives through the collaborative efforts of individual agents. Among the methodologies employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of the most efficacious algorithms. However, when confronted with the complex objective of Formation Control with Collision Avoidance (FCCA): designing an effective reward function that facilitates swift convergence of the policy network to an optimal solution. In this paper, we introduce a novel framework that aims to overcome this challenge. By giving large language models (LLMs) on the prioritization of tasks and the observable information available to each agent, our framework generates reward functions that can be dynamically adjusted online based on evaluation outcomes by employing more advanced evaluation metrics rather than the rewards themselves. This mechanism enables the MAS to simultaneously achieve formation control and obstacle avoidance in dynamic environments with enhanced efficiency, requiring fewer iterations to reach superior performance levels. Our empirical studies, conducted in both simulation and real-world settings, validate the practicality and effectiveness of our proposed approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL) åœ¨ç¼–é˜Ÿæ§åˆ¶ä¸é¿éšœ (FCCA) ä»»åŠ¡ä¸­å¥–åŠ±å‡½æ•° (Reward Function) è®¾è®¡å›°éš¾ä¸”å½±å“æ”¶æ•›é€Ÿåº¦çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”±å¤§è¯­è¨€æ¨¡å‹ (LLM) æŒ‡å¯¼çš„æ–°å‹å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ LLM å¯¹ä»»åŠ¡ä¼˜å…ˆçº§å’Œæ™ºèƒ½ä½“å¯è§‚æµ‹ä¿¡æ¯è¿›è¡Œå»ºæ¨¡ï¼Œé€šè¿‡æ›´å…ˆè¿›çš„è¯„ä¼°æŒ‡æ ‡è€Œéä¼ ç»Ÿå¥–åŠ±å€¼ï¼Œå®ç°å¯¹å¥–åŠ±å‡½æ•°çš„åœ¨çº¿åŠ¨æ€è°ƒæ•´ã€‚è¿™ç§æœºåˆ¶ä½¿å¾—å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ (MAS) èƒ½å¤Ÿåœ¨åŠ¨æ€ç¯å¢ƒä¸­åŒæ—¶å®ç°é«˜æ•ˆçš„ç¼–é˜Ÿæ§åˆ¶ä¸é¿éšœï¼Œå¹¶ä»¥æ›´å°‘çš„è¿­ä»£æ¬¡æ•°è¾¾åˆ°æ›´ä¼˜çš„æ€§èƒ½æ°´å¹³ã€‚ç ”ç©¶é€šè¿‡ä»¿çœŸå’ŒçœŸå®ä¸–ç•Œç¯å¢ƒçš„å®è¯ç ”ç©¶ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨æå‡å­¦ä¹ æ•ˆç‡å’Œä»»åŠ¡è¾¾æˆç‡æ–¹é¢çš„å®ç”¨æ€§ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by IROS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16382v1",
      "published_date": "2025-07-22 09:26:00 UTC",
      "updated_date": "2025-07-22 09:26:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:26.283611+00:00"
    },
    {
      "arxiv_id": "2507.16372v1",
      "title": "Depth Gives a False Sense of Privacy: LLM Internal States Inversion",
      "title_zh": "æ·±åº¦å¸¦æ¥çš„è™šå‡éšç§æ„Ÿï¼šLLM å†…éƒ¨çŠ¶æ€åæ¼”",
      "authors": [
        "Tian Dong",
        "Yan Meng",
        "Shaofeng Li",
        "Guoxing Chen",
        "Zhen Liu",
        "Haojin Zhu"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly integrated into daily routines, yet they raise significant privacy and safety concerns. Recent research proposes collaborative inference, which outsources the early-layer inference to ensure data locality, and introduces model safety auditing based on inner neuron patterns. Both techniques expose the LLM's Internal States (ISs), which are traditionally considered irreversible to inputs due to optimization challenges and the highly abstract representations in deep layers. In this work, we challenge this assumption by proposing four inversion attacks that significantly improve the semantic similarity and token matching rate of inverted inputs. Specifically, we first develop two white-box optimization-based attacks tailored for low-depth and high-depth ISs. These attacks avoid local minima convergence, a limitation observed in prior work, through a two-phase inversion process. Then, we extend our optimization attack under more practical black-box weight access by leveraging the transferability between the source and the derived LLMs. Additionally, we introduce a generation-based attack that treats inversion as a translation task, employing an inversion model to reconstruct inputs. Extensive evaluation of short and long prompts from medical consulting and coding assistance datasets and 6 LLMs validates the effectiveness of our inversion attacks. Notably, a 4,112-token long medical consulting prompt can be nearly perfectly inverted with 86.88 F1 token matching from the middle layer of Llama-3 model. Finally, we evaluate four practical defenses that we found cannot perfectly prevent ISs inversion and draw conclusions for future mitigation design.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å†…éƒ¨çŠ¶æ€(Internal States, ISs)åœ¨æ·±å±‚å…·æœ‰ä¸å¯é€†æ€§çš„ä¼ ç»Ÿå‡è®¾ï¼ŒæŒ‡å‡ºæ¨¡å‹æ·±åº¦å¹¶ä¸èƒ½æä¾›å®è´¨æ€§çš„éšç§ä¿éšœã€‚ä½œè€…æå‡ºäº†å››ç§åå‘æ”»å‡»(Inversion Attacks)æ–¹æ³•ï¼ŒåŒ…æ‹¬é’ˆå¯¹ä¸åŒæ·±åº¦çš„ç™½ç›’ä¼˜åŒ–æ”»å‡»ã€åŸºäºæ¨¡å‹è¿ç§»æ€§çš„é»‘ç›’æ”»å‡»ï¼Œä»¥åŠå°†åå‘è¿‡ç¨‹è§†ä¸ºç¿»è¯‘ä»»åŠ¡çš„ç”Ÿæˆå¼æ”»å‡»ã€‚é€šè¿‡åœ¨åŒ»ç–—å’¨è¯¢å’Œä»£ç è¾…åŠ©ç­‰æ•°æ®é›†ä»¥åŠ6ç§ä¸»æµLLMsä¸Šçš„å¹¿æ³›è¯„ä¼°ï¼Œå®éªŒè¯æ˜äº†è¿™äº›æ”»å‡»èƒ½æ˜¾è‘—æé«˜åå‘è¾“å…¥çš„è¯­ä¹‰ç›¸ä¼¼åº¦å’Œæ ‡è®°åŒ¹é…ç‡ã€‚ç‰¹åˆ«æ˜¯åœ¨Llama-3æ¨¡å‹ä¸­ï¼Œå³ä½¿æ˜¯ä¸­é—´å±‚çš„4,112ä¸ªæ ‡è®°é•¿æ–‡æœ¬ä¹Ÿèƒ½ä»¥86.88çš„F1åˆ†æ•°è¢«è¿‘ä¹å®Œç¾åœ°è¿˜åŸã€‚æœ€åï¼Œç ”ç©¶è¯„ä¼°äº†å››ç§ç°æœ‰çš„å®é™…é˜²å¾¡æªæ–½ï¼Œå‘ç°å®ƒä»¬å‡æ— æ³•å®Œå…¨é˜»æ­¢ISsåå‘è¿˜åŸï¼Œä¸ºæœªæ¥éšç§ç¼“è§£æ–¹æ¡ˆçš„è®¾è®¡æä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by USENIX Security 2025. Please cite this paper as \"Tian Dong, Yan Meng, Shaofeng Li, Guoxing Chen, Zhen Liu, Haojin Zhu. Depth Gives a False Sense of Privacy: LLM Internal States Inversion. In the 34th USENIX Security Symposium (USENIX Security '25).\"",
      "pdf_url": "https://arxiv.org/pdf/2507.16372v1",
      "published_date": "2025-07-22 09:15:11 UTC",
      "updated_date": "2025-07-22 09:15:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:37.189904+00:00"
    },
    {
      "arxiv_id": "2507.16370v2",
      "title": "Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning",
      "title_zh": "é©¬å°”å¯å¤«ç»“æ„å› æœæ¨¡å‹çš„è§„èŒƒè¡¨ç¤ºï¼šä¸€ç§åäº‹å®æ¨ç†æ¡†æ¶",
      "authors": [
        "Lucas de Lara"
      ],
      "abstract": "Counterfactual reasoning aims at answering contrary-to-fact questions like ``Would have Alice recovered had she taken aspirin?'' and corresponds to the most fine-grained layer of causation. Critically, while many counterfactual statements cannot be falsified-even by randomized experiments-they underpin fundamental concepts like individual-wise fairness. Therefore, providing models to formalize and implement counterfactual beliefs remains a fundamental scientific problem. In the Markovian setting of Pearl's causal framework, we propose an alternative approach to structural causal models to represent counterfactuals compatible with a given causal graphical model. More precisely, we introduce counterfactual models, also called canonical representations of structural causal models. They enable analysts to choose a counterfactual assumption via random-process probability distributions with preassigned marginals and characterize the counterfactual equivalence class of structural causal models. Using these representations, we present a normalization procedure to disentangle the (arbitrary and unfalsifiable) counterfactual choice from the (typically testable) interventional constraints. In contrast to structural causal models, this allows to implement many counterfactual assumptions while preserving interventional knowledge, and does not require any estimation step at the individual-counterfactual layer: only to make a choice. Finally, we illustrate the specific role of counterfactuals in causality and the benefits of our approach on theoretical and numerical examples.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åäº‹å®æ¨ç†(Counterfactual reasoning)åœ¨é©¬å°”å¯å¤«ç»“æ„å› æœæ¨¡å‹(Markovian Structural Causal Models)ä¸­çš„å®ç°é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³åäº‹å®é™ˆè¿°éš¾ä»¥é€šè¿‡å®éªŒéªŒè¯çš„åŸºç¡€ç§‘å­¦éš¾é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§æ›¿ä»£ä¼ ç»Ÿç»“æ„å› æœæ¨¡å‹(SCM)çš„æ–°æ–¹æ³•ï¼Œå³â€œåäº‹å®æ¨¡å‹â€(Counterfactual models)ï¼Œä¹Ÿç§°ä¸ºç»“æ„å› æœæ¨¡å‹çš„è§„èŒƒè¡¨ç¤º(Canonical representations)ã€‚è¯¥æ¡†æ¶å…è®¸åˆ†æäººå‘˜é€šè¿‡å…·æœ‰é¢„è®¾è¾¹é™…åˆ†å¸ƒçš„éšæœºè¿‡ç¨‹æ¦‚ç‡åˆ†å¸ƒæ¥é€‰æ‹©åäº‹å®å‡è®¾ï¼Œå¹¶ä»¥æ­¤åˆ»ç”»ç»“æ„å› æœæ¨¡å‹çš„åäº‹å®ç­‰æ•ˆç±»(Counterfactual equivalence class)ã€‚ç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥äº†ä¸€ç§æ ‡å‡†åŒ–ç¨‹åºï¼Œå°†ä»»æ„ä¸”ä¸å¯è¯ä¼ªçš„åäº‹å®é€‰æ‹©ä¸é€šå¸¸å¯æµ‹è¯•çš„å¹²é¢„çº¦æŸ(Interventional constraints)æœ‰æ•ˆè§£è€¦ã€‚ä¸ä¼ ç»ŸSCMç›¸æ¯”ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¿ç•™å¹²é¢„çŸ¥è¯†çš„åŒæ—¶å®ç°å¤šç§åäº‹å®å‡è®¾ï¼Œä¸”åœ¨ä¸ªä½“åäº‹å®å±‚é¢ä¸Šæ— éœ€å¤æ‚çš„ä¼°è®¡æ­¥éª¤ã€‚æœ€åï¼Œé€šè¿‡ç†è®ºå’Œæ•°å€¼å®ä¾‹è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å¤„ç†å› æœå…³ç³»ä¸­çš„ç‹¬ç‰¹ä½œç”¨åŠå…¶åœ¨æå‡æ¨¡å‹å¯æ“ä½œæ€§æ–¹é¢çš„ä¼˜åŠ¿ã€‚",
      "categories": [
        "cs.AI",
        "math.ST"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16370v2",
      "published_date": "2025-07-22 09:13:02 UTC",
      "updated_date": "2025-09-22 07:53:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:37.579745+00:00"
    },
    {
      "arxiv_id": "2507.21130v1",
      "title": "INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems",
      "title_zh": "INTEGRALBENCHï¼šé¢å‘å®šç§¯åˆ†é—®é¢˜çš„å¤§è¯­è¨€æ¨¡å‹è¯„æµ‹åŸºå‡†",
      "authors": [
        "Bintao Tang",
        "Xin Yang",
        "Yuhao Wang",
        "Zixuan Qiu",
        "Zimo Ji",
        "Wenyuan Jiang"
      ],
      "abstract": "We present INTEGRALBENCH, a focused benchmark designed to evaluate Large Language Model (LLM) performance on definite integral problems. INTEGRALBENCH provides both symbolic and numerical ground truth solutions with manual difficulty annotations. Our evaluation of nine state-of-the-art LLMs reveals significant performance gaps and strong correlations between problem difficulty and model accuracy, establishing baseline metrics for this challenging domain. INTEGRALBENCH aims to advance automated mathematical reasoning by providing a rigorous evaluation framework specifically tailored for definite integral computation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† INTEGRALBENCHï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° Large Language Model (LLM) åœ¨ definite integral é—®é¢˜ä¸Šè¡¨ç°çš„åŸºå‡†æµ‹è¯•ã€‚INTEGRALBENCH æä¾›äº† symbolic å’Œ numerical çš„ ground truth è§£å†³æ–¹æ¡ˆï¼Œå¹¶åŒ…å«äººå·¥è¿›è¡Œçš„éš¾åº¦æ ‡æ³¨ã€‚é€šè¿‡å¯¹ä¹ç§ state-of-the-art LLMs çš„è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†æ¨¡å‹é—´æ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œä»¥åŠé—®é¢˜éš¾åº¦ä¸æ¨¡å‹å‡†ç¡®ç‡ä¹‹é—´çš„å¼ºç›¸å…³æ€§ã€‚è¯¥åŸºå‡†æµ‹è¯•ä¸ºè¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸå»ºç«‹äº† baseline æŒ‡æ ‡ï¼Œæ—¨åœ¨é€šè¿‡æä¾›ä¸“é—¨é’ˆå¯¹ definite integral è®¡ç®—å®šåˆ¶çš„ä¸¥è°¨è¯„ä¼°æ¡†æ¶ï¼Œæ¨åŠ¨è‡ªåŠ¨åŒ–æ•°å­¦æ¨ç†çš„å‘å±•ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.21130v1",
      "published_date": "2025-07-22 08:44:36 UTC",
      "updated_date": "2025-07-22 08:44:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:42.482356+00:00"
    },
    {
      "arxiv_id": "2507.16356v2",
      "title": "Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health",
      "title_zh": "å­¦ä¹ å‘¼å«ï¼šæ—¨åœ¨æå‡ç§»åŠ¨æ¯å©´å¥åº·ä¿¡æ¯é€è¾¾ç‡çš„ååŒ Bandit ç®—æ³•å®åœ°è¯•éªŒ",
      "authors": [
        "Arpan Dasgupta",
        "Mizhaan Maniyar",
        "Awadhesh Srivastava",
        "Sanat Kumar",
        "Amrita Mahale",
        "Aparna Hegde",
        "Arun Suggala",
        "Karthikeyan Shanmugam",
        "Aparna Taneja",
        "Milind Tambe"
      ],
      "abstract": "Mobile health (mHealth) programs utilize automated voice messages to deliver health information, particularly targeting underserved communities, demonstrating the effectiveness of using mobile technology to disseminate crucial health information to these populations, improving health outcomes through increased awareness and behavioral change. India's Kilkari program delivers vital maternal health information via weekly voice calls to millions of mothers. However, the current random call scheduling often results in missed calls and reduced message delivery. This study presents a field trial of a collaborative bandit algorithm designed to optimize call timing by learning individual mothers' preferred call times. We deployed the algorithm with around $6500$ Kilkari participants as a pilot study, comparing its performance to the baseline random calling approach. Our results demonstrate a statistically significant improvement in call pick-up rates with the bandit algorithm, indicating its potential to enhance message delivery and impact millions of mothers across India. This research highlights the efficacy of personalized scheduling in mobile health interventions and underscores the potential of machine learning to improve maternal health outreach at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°åº¦ Kilkari ç§»åŠ¨å¥åº·(mHealth)é¡¹ç›®åœ¨å‘é€å­•äº§å¦‡å¥åº·è¯­éŸ³ä¿¡æ¯æ—¶ï¼Œå› éšæœºé€šè¯è°ƒåº¦å¯¼è‡´æ¥å¬ç‡ä½çš„é—®é¢˜å±•å¼€ã€‚ä¸ºäº†ä¼˜åŒ–å‘¼å«æ—¶æœºï¼Œä½œè€…å¼€å‘å¹¶å®åœ°æµ‹è¯•äº†ä¸€ç§åä½œå¤šè‡‚è€è™æœºç®—æ³•(Collaborative Bandit Algorithm)ï¼Œæ—¨åœ¨é€šè¿‡å­¦ä¹ ä¸åŒç”¨æˆ·çš„ä¸ªä½“åå¥½æ¥è‡ªåŠ¨ç¡®å®šæœ€ä½³é€šè¯æ—¶é—´ã€‚ç ”ç©¶å›¢é˜Ÿå¯¹çº¦ 6500 åå‚ä¸è€…è¿›è¡Œäº†è¯•ç‚¹éƒ¨ç½²ï¼Œå¹¶å°†å…¶è¡¨ç°ä¸ä¼ ç»Ÿçš„éšæœºåŸºçº¿æ–¹æ³•è¿›è¡Œäº†å¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç®—æ³•åœ¨ç»Ÿè®¡å­¦æ„ä¹‰ä¸Šæ˜¾è‘—æé«˜äº†é€šè¯æ¥å¬ç‡ï¼ŒéªŒè¯äº†ä¸ªæ€§åŒ–è°ƒåº¦åœ¨ç§»åŠ¨å¥åº·å¹²é¢„ä¸­çš„æ ¸å¿ƒä»·å€¼ã€‚è¿™é¡¹å·¥ä½œä¸ä»…å±•ç¤ºäº†æœºå™¨å­¦ä¹ åœ¨å¤§è§„æ¨¡æ”¹å–„å­•äº§å¦‡å¥åº·å¤–å»¶æœåŠ¡æ–¹é¢çš„æ½œåŠ›ï¼Œä¹Ÿä¸ºæå‡å°åº¦ä¹ƒè‡³å…¨çƒç±»ä¼¼é¡¹ç›®çš„äº¤ä»˜æ•ˆæœæä¾›äº†é‡è¦æŠ€æœ¯å‚è€ƒã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16356v2",
      "published_date": "2025-07-22 08:42:17 UTC",
      "updated_date": "2025-11-24 15:04:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:44.778583+00:00"
    },
    {
      "arxiv_id": "2507.16874v1",
      "title": "Budget Allocation Policies for Real-Time Multi-Agent Path Finding",
      "title_zh": "å®æ—¶å¤šæ™ºèƒ½ä½“è·¯å¾„æœç´¢çš„é¢„ç®—åˆ†é…ç­–ç•¥",
      "authors": [
        "Raz Beck",
        "Roni Stern"
      ],
      "abstract": "Multi-Agent Pathfinding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. Real-Time MAPF (RT-MAPF) embodies a realistic MAPF setup in which one cannot wait until a complete path for each agent has been found before they start to move. Instead, planning and execution are interleaved, where the agents must commit to a fixed number of steps in a constant amount of computation time, referred to as the planning budget. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of standard MAPF algorithms, namely Prioritized Planning (PrP) and MAPF-LNS2. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in over-constrained situations. Instead, policies that distribute the planning budget over the agents are able to solve more problems with a smaller makespan.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å®æ—¶å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’(RT-MAPF)ä¸­çš„é¢„ç®—åˆ†é…(Budget Allocation)ç­–ç•¥é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³åœ¨å—é™è®¡ç®—æ—¶é—´å†…å®ç°é«˜æ•ˆè·¯å¾„è§„åˆ’çš„æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰RT-MAPFç®—æ³•æœªæ˜ç¡®è€ƒè™‘è§„åˆ’é¢„ç®—å¤§å°åŠå…¶åˆ†é…é€»è¾‘çš„ç°çŠ¶ï¼Œä½œè€…åœ¨Prioritized Planning (PrP)å’ŒMAPF-LNS2ä¸¤ç§ç»å…¸ç®—æ³•çš„çª—å£åŒ–ç‰ˆæœ¬ä¸­æ¢ç´¢äº†ä¸åŒçš„åˆ†é…æ”¿ç­–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¼ ç»Ÿçš„è®©æ‰€æœ‰æ™ºèƒ½ä½“å…±äº«å•ä¸€è§„åˆ’é¢„ç®—æ± çš„åŸºçº¿æ–¹æ³•åœ¨é«˜åº¦å—é™çš„ä»»åŠ¡åœºæ™¯ä¸‹è¡¨ç°æ¬ ä½³ï¼Œéš¾ä»¥æœ‰æ•ˆå¹³è¡¡è®¡ç®—èµ„æºã€‚ä¸ä¹‹ç›¸å¯¹ï¼Œå°†è§„åˆ’é¢„ç®—æ˜ç¡®åˆ†é…ç»™å„ä¸ªç‰¹å®šæ™ºèƒ½ä½“çš„ç­–ç•¥èƒ½å¤Ÿæ˜¾è‘—æå‡ä»»åŠ¡æˆåŠŸç‡ï¼Œå¹¶èƒ½ä»¥æ›´å°çš„æ€»å®Œå·¥æ—¶é—´(makespan)å®Œæˆè·¯å¾„è§„åˆ’ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†åˆç†çš„èµ„æºåˆ†é…é€»è¾‘åœ¨å®æ—¶ååŒè§„åˆ’ç³»ç»Ÿä¸­çš„å…³é”®ä½œç”¨ï¼Œä¸ºæå‡å¤æ‚åŠ¨æ€ç¯å¢ƒä¸‹çš„å¤šæ™ºèƒ½ä½“æ‰§è¡Œæ•ˆç‡æä¾›äº†æ–°çš„æ”¹è¿›æ–¹å‘ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "8 pages, 2 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16874v1",
      "published_date": "2025-07-22 08:32:55 UTC",
      "updated_date": "2025-07-22 08:32:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:48.191421+00:00"
    },
    {
      "arxiv_id": "2507.19536v1",
      "title": "Graph Learning Metallic Glass Discovery from Wikipedia",
      "title_zh": "åŸºäº Wikipedia çš„å›¾å­¦ä¹ é‡‘å±ç»ç’ƒå‘ç°",
      "authors": [
        "K. -C. Ouyang",
        "S. -Y. Zhang",
        "S. -L. Liu",
        "J. Tian",
        "Y. -H. Li",
        "H. Tong",
        "H. -Y. Bai",
        "W. -H. Wang",
        "Y. -C. Hu"
      ],
      "abstract": "Synthesizing new materials efficiently is highly demanded in various research fields. However, this process is usually slow and expensive, especially for metallic glasses, whose formation strongly depends on the optimal combinations of multiple elements to resist crystallization. This constraint renders only several thousands of candidates explored in the vast material space since 1960. Recently, data-driven approaches armed by advanced machine learning techniques provided alternative routes for intelligent materials design. Due to data scarcity and immature material encoding, the conventional tabular data is usually mined by statistical learning algorithms, giving limited model predictability and generalizability. Here, we propose sophisticated data learning from material network representations. The node elements are encoded from the Wikipedia by a language model. Graph neural networks with versatile architectures are designed to serve as recommendation systems to explore hidden relationships among materials. By employing Wikipedia embeddings from different languages, we assess the capability of natural languages in materials design. Our study proposes a new paradigm to harvesting new amorphous materials and beyond with artificial intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å—ä½“é‡‘å±ç»ç’ƒ(Metallic Glass)å¼€å‘ä¸­é¢ä¸´çš„æœç´¢ç©ºé—´å·¨å¤§ã€å®éªŒæˆæœ¬é«˜ä»¥åŠä¼ ç»Ÿæ•°æ®é©±åŠ¨æ–¹æ³•æ³›åŒ–æ€§å—é™ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå›¾å­¦ä¹ (Graph Learning)çš„æ–°å‹ææ–™å‘ç°èŒƒå¼ã€‚è¯¥æ–¹æ³•åˆ›æ–°æ€§åœ°åˆ©ç”¨è¯­è¨€æ¨¡å‹ä»Wikipediaä¸­æå–ä¸åŒè¯­è¨€çš„æ–‡æœ¬åµŒå…¥ï¼Œå°†ææ–™ä¸­çš„å…ƒç´ èŠ‚ç‚¹è¿›è¡Œå‘é‡åŒ–ç¼–ç ã€‚éšåç ”ç©¶è€…è®¾è®¡äº†å…·æœ‰å¤šç§æ¶æ„çš„å›¾ç¥ç»ç½‘ç»œ(Graph Neural Networks)ä½œä¸ºæ¨èç³»ç»Ÿï¼Œé€šè¿‡æŒ–æ˜ææ–™ç½‘ç»œè¡¨ç¤ºä¸­éšè—çš„å…³è”æ¥æ¢ç´¢æ½œåœ¨çš„å€™é€‰ææ–™ã€‚é€šè¿‡å¯¹ä¸åŒè¯­è¨€çš„WikipediaåµŒå…¥è¿›è¡Œè¯„ä¼°ï¼Œè¯¥ç ”ç©¶è¯å®äº†è‡ªç„¶è¯­è¨€åœ¨è¾…åŠ©ææ–™è®¾è®¡æ–¹é¢çš„æ˜¾è‘—æ½œåŠ›ã€‚è¿™ç§ç»“åˆå¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ä¸å¤æ‚ç½‘ç»œè¡¨å¾çš„æ–¹æ³•ï¼Œæœ‰æ•ˆç¼“è§£äº†ææ–™ç§‘å­¦é¢†åŸŸé•¿æœŸå­˜åœ¨çš„æ•°æ®ç¨€ç¼º(Data Scarcity)é—®é¢˜ï¼Œä¸ºéæ™¶æ€ææ–™(Amorphous Materials)åŠå…¶ä»–å…ˆè¿›ææ–™çš„é«˜æ•ˆå‘ç°æä¾›äº†å…¨æ–°çš„æ™ºèƒ½è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.19536v1",
      "published_date": "2025-07-22 08:30:03 UTC",
      "updated_date": "2025-07-22 08:30:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:55.785516+00:00"
    },
    {
      "arxiv_id": "2507.16347v2",
      "title": "Leveraging Personalized PageRank and Higher-Order Topological Structures for Heterophily Mitigation in Graph Neural Networks",
      "title_zh": "åˆ©ç”¨ä¸ªæ€§åŒ– PageRank ä¸é«˜é˜¶æ‹“æ‰‘ç»“æ„ç¼“è§£å›¾ç¥ç»ç½‘ç»œä¸­çš„å¼‚è´¨æ€§",
      "authors": [
        "Yumeng Wang",
        "Zengyi Wo",
        "Wenjun Wang",
        "Xingcheng Fu",
        "Minglai Shao"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel in node classification tasks but often assume homophily, where connected nodes share similar labels. This assumption does not hold in many real-world heterophilic graphs. Existing models for heterophilic graphs primarily rely on pairwise relationships, overlooking multi-scale information from higher-order structures. This leads to suboptimal performance, particularly under noise from conflicting class information across nodes. To address these challenges, we propose HPGNN, a novel model integrating Higher-order Personalized PageRank with Graph Neural Networks. HPGNN introduces an efficient high-order approximation of Personalized PageRank (PPR) to capture long-range and multi-scale node interactions. This approach reduces computational complexity and mitigates noise from surrounding information. By embedding higher-order structural information into convolutional networks, HPGNN effectively models key interactions across diverse graph dimensions. Extensive experiments on benchmark datasets demonstrate HPGNN's effectiveness. The model achieves better performance than five out of seven state-of-the-art methods on heterophilic graphs in downstream tasks while maintaining competitive performance on homophilic graphs. HPGNN's ability to balance multi-scale information and robustness to noise makes it a versatile solution for real-world graph learning challenges. Codes are available at https://github.com/streetcorner/HPGNN.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†HPGNNï¼Œæ—¨åœ¨è§£å†³Graph Neural Networks (GNNs) åœ¨å¤„ç†å¼‚è´¨æ€§å›¾ (heterophilic graphs) æ—¶å› è¿‡åº¦ä¾èµ–æˆå¯¹å…³ç³»è€Œå¿½ç•¥é«˜é˜¶ç»“æ„ä¿¡æ¯çš„é—®é¢˜ã€‚HPGNN å¼•å…¥äº†ä¸€ç§é«˜æ•ˆçš„é«˜é˜¶Personalized PageRank (PPR) è¿‘ä¼¼æ–¹æ³•ï¼Œèƒ½å¤Ÿæ•æ‰é•¿ç¨‹å’Œå¤šå°ºåº¦çš„èŠ‚ç‚¹äº¤äº’ï¼Œä»è€Œæœ‰æ•ˆé™ä½è®¡ç®—å¤æ‚åº¦å¹¶æŠ‘åˆ¶æ¥è‡ªé‚»å±…èŠ‚ç‚¹å†²çªä¿¡æ¯çš„å™ªå£°ã€‚é€šè¿‡å°†é«˜é˜¶æ‹“æ‰‘ç»“æ„ä¿¡æ¯åµŒå…¥å·ç§¯ç½‘ç»œä¸­ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨ä¸åŒå›¾ç»´åº¦ä¸Šæœ‰æ•ˆå»ºæ¨¡å…³é”®äº¤äº’ã€‚åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒHPGNN åœ¨å¼‚è´¨æ€§å›¾ä»»åŠ¡ä¸­çš„è¡¨ç°ä¼˜äºå¤šæ•°å½“å‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼ŒåŒæ—¶åœ¨åŒè´¨æ€§å›¾ä¸Šä¿æŒäº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚HPGNN åœ¨å¹³è¡¡å¤šå°ºåº¦ä¿¡æ¯å’Œå¢å¼ºæŠ—å™ªæ€§æ–¹é¢çš„èƒ½åŠ›ï¼Œä½¿å…¶æˆä¸ºåº”å¯¹ç°å®ä¸–ç•Œå¤æ‚å›¾å­¦ä¹ æŒ‘æˆ˜çš„æœ‰æ•ˆè§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, Accepted at IJCAI 2025. Proceedings: https://www.ijcai.org/proceedings/2025/0724.pdf",
      "pdf_url": "https://arxiv.org/pdf/2507.16347v2",
      "published_date": "2025-07-22 08:28:18 UTC",
      "updated_date": "2025-10-09 06:45:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:16:56.979061+00:00"
    },
    {
      "arxiv_id": "2507.16873v1",
      "title": "HIPPO-Video: Simulating Watch Histories with Large Language Models for Personalized Video Highlighting",
      "title_zh": "HIPPO-Videoï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ¨¡æ‹Ÿè§‚çœ‹å†å²çš„ä¸ªæ€§åŒ–è§†é¢‘é«˜å…‰æå–",
      "authors": [
        "Jeongeun Lee",
        "Youngjae Yu",
        "Dongha Lee"
      ],
      "abstract": "The exponential growth of video content has made personalized video highlighting an essential task, as user preferences are highly variable and complex. Existing video datasets, however, often lack personalization, relying on isolated videos or simple text queries that fail to capture the intricacies of user behavior. In this work, we introduce HIPPO-Video, a novel dataset for personalized video highlighting, created using an LLM-based user simulator to generate realistic watch histories reflecting diverse user preferences. The dataset includes 2,040 (watch history, saliency score) pairs, covering 20,400 videos across 170 semantic categories. To validate our dataset, we propose HiPHer, a method that leverages these personalized watch histories to predict preference-conditioned segment-wise saliency scores. Through extensive experiments, we demonstrate that our method outperforms existing generic and query-based approaches, showcasing its potential for highly user-centric video highlighting in real-world scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è§†é¢‘é«˜å…‰æå–æ•°æ®é›†ç¼ºä¹ä¸ªæ€§åŒ–ä¸”éš¾ä»¥æ•æ‰ç”¨æˆ·è¡Œä¸ºå¤æ‚æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºHIPPO-Videoçš„æ–°å‹æ•°æ®é›†ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ç”¨æˆ·æ¨¡æ‹Ÿå™¨ç”Ÿæˆåæ˜ å¤šæ ·åŒ–ç”¨æˆ·åå¥½çš„çœŸå®è§‚çœ‹å†å²ï¼Œä»è€Œå¼¥è¡¥äº†ä¼ ç»Ÿæ–¹æ³•ä»…ä¾èµ–å­¤ç«‹è§†é¢‘æˆ–ç®€å•æ–‡æœ¬æŸ¥è¯¢çš„ä¸è¶³ã€‚è¯¥æ•°æ®é›†è§„æ¨¡åºå¤§ï¼ŒåŒ…å«2,040ç»„(è§‚çœ‹å†å²ï¼Œsaliency score)æ•°æ®å¯¹ï¼Œæ¶µç›–äº†170ä¸ªè¯­ä¹‰ç±»åˆ«çš„20,400ä¸ªè§†é¢‘ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…æå‡ºäº†HiPHeræ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡ä¸ªæ€§åŒ–è§‚çœ‹å†å²æ¥é¢„æµ‹å—åå¥½çº¦æŸçš„ç‰‡æ®µçº§æ˜¾è‘—æ€§åˆ†æ•°ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„é€šç”¨åŠåŸºäºæŸ¥è¯¢(query-based)çš„åŸºå‡†æ¨¡å‹ã€‚è¯¥ç ”ç©¶ä¸ºç°å®åœºæ™¯ä¸­å®ç°é«˜åº¦ä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„è§†é¢‘é«˜å…‰æå–(personalized video highlighting)å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to COLM2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16873v1",
      "published_date": "2025-07-22 08:24:33 UTC",
      "updated_date": "2025-07-22 08:24:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:13.783215+00:00"
    },
    {
      "arxiv_id": "2507.16343v2",
      "title": "Detect Any Sound: Open-Vocabulary Sound Event Detection with Multi-Modal Queries",
      "title_zh": "Detect Any Soundï¼šåŸºäºå¤šæ¨¡æ€æŸ¥è¯¢çš„å¼€æ”¾è¯æ±‡å£°éŸ³äº‹ä»¶æ£€æµ‹",
      "authors": [
        "Pengfei Cai",
        "Yan Song",
        "Qing Gu",
        "Nan Jiang",
        "Haoyu Song",
        "Ian McLoughlin"
      ],
      "abstract": "Most existing sound event detection~(SED) algorithms operate under a closed-set assumption, restricting their detection capabilities to predefined classes. While recent efforts have explored language-driven zero-shot SED by exploiting audio-language models, their performance is still far from satisfactory due to the lack of fine-grained alignment and cross-modal feature fusion. In this work, we propose the Detect Any Sound Model (DASM), a query-based framework for open-vocabulary SED guided by multi-modal queries. DASM formulates SED as a frame-level retrieval task, where audio features are matched against query vectors derived from text or audio prompts. To support this formulation, DASM introduces a dual-stream decoder that explicitly decouples event recognition and temporal localization: a cross-modality event decoder performs query-feature fusion and determines the presence of sound events at the clip-level, while a context network models temporal dependencies for frame-level localization. Additionally, an inference-time attention masking strategy is proposed to leverage semantic relations between base and novel classes, substantially enhancing generalization to novel classes. Experiments on the AudioSet Strong dataset demonstrate that DASM effectively balances localization accuracy with generalization to novel classes, outperforming CLAP-based methods in open-vocabulary setting (+ 7.8 PSDS) and the baseline in the closed-set setting (+ 6.9 PSDS). Furthermore, in cross-dataset zero-shot evaluation on DESED, DASM achieves a PSDS1 score of 42.2, even exceeding the supervised CRNN baseline. The project page is available at https://cai525.github.io/Transformer4SED/demo_page/DASM/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Detect Any Sound Model (DASM)ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå£°éŸ³äº‹ä»¶æ£€æµ‹ (Sound Event Detection, SED) ç®—æ³•å—é™äºé¢„å®šä¹‰ç±»åˆ«ä¸”åœ¨é›¶æ ·æœ¬åœºæ™¯ä¸‹è¡¨ç°ä¸ä½³çš„é—®é¢˜ã€‚DASM é‡‡ç”¨åŸºäºæŸ¥è¯¢çš„æ¡†æ¶ï¼Œå°† SED å»ºæ¨¡ä¸ºå¸§çº§æ£€ç´¢ä»»åŠ¡ï¼Œæ”¯æŒé€šè¿‡æ–‡æœ¬æˆ–éŸ³é¢‘ Prompt å¼•å¯¼çš„ Open-Vocabulary è¯†åˆ«ã€‚è¯¥æ¨¡å‹å¼•å…¥äº†åŒæµè§£ç å™¨ (Dual-stream decoder)ï¼Œé€šè¿‡è·¨æ¨¡æ€äº‹ä»¶è§£ç å™¨å’Œä¸Šä¸‹æ–‡ç½‘ç»œåˆ†åˆ«å¤„ç†äº‹ä»¶è¯†åˆ«ä¸æ—¶é—´å®šä½ï¼Œå®ç°äº†ä¸¤è€…çš„è§£è€¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ¨ç†æ—¶æ³¨æ„åŠ›æ©ç ç­–ç•¥ (Inference-time attention masking strategy)ï¼Œåˆ©ç”¨è¯­ä¹‰å…³ç³»æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹å¯¹æ–°ç±»åˆ«çš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒDASM åœ¨ AudioSet Strong æ•°æ®é›†çš„å¼€æ”¾è¯æ±‡è®¾ç½®ä¸‹æ€§èƒ½ä¼˜äºåŸºäº CLAP çš„æ–¹æ³•ï¼Œä¸”åœ¨é—­é›†è®¾ç½®ä¸­ä¹Ÿä¼˜äºåŸºçº¿æ¨¡å‹ã€‚åœ¨ DESED è·¨æ•°æ®é›†é›¶æ ·æœ¬è¯„ä¼°ä¸­ï¼ŒDASM ç”šè‡³è¶…è¶Šäº†æœ‰ç›‘ç£çš„ CRNN åŸºçº¿ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚å£°å­¦ç¯å¢ƒä¸‹çš„å“è¶Šé€šç”¨æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16343v2",
      "published_date": "2025-07-22 08:24:01 UTC",
      "updated_date": "2025-10-27 15:55:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:22.787315+00:00"
    },
    {
      "arxiv_id": "2507.16334v2",
      "title": "Higher Gauge Flow Models",
      "title_zh": "é«˜é˜¶è§„èŒƒæµæ¨¡å‹",
      "authors": [
        "Alexander Strunk",
        "Roland Assam"
      ],
      "abstract": "This paper introduces Higher Gauge Flow Models, a novel class of Generative Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these Higher Gauge Flow Models leverage an L$_{\\infty}$-algebra, effectively extending the Lie Algebra. This expansion allows for the integration of the higher geometry and higher symmetries associated with higher groups into the framework of Generative Flow Models. Experimental evaluation on a Gaussian Mixture Model dataset revealed substantial performance improvements compared to traditional Flow Models.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº†Higher Gauge Flow Modelsï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„Generative Flow Modelsã€‚è¯¥æ¨¡å‹å»ºç«‹åœ¨æ™®é€šGauge Flow Modelsçš„åŸºç¡€ä¹‹ä¸Šï¼Œé€šè¿‡åˆ©ç”¨$L_{\\infty}$-algebraæœ‰æ•ˆåœ°æ‰©å±•äº†Lie Algebraã€‚è¿™ç§æ‰©å±•å…è®¸å°†ä¸higher groupsç›¸å…³çš„higher geometryå’Œhigher symmetriesé›†æˆåˆ°Generative Flow Modelsçš„æ¡†æ¶ä¸­ã€‚åœ¨Gaussian Mixture Modelæ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹ç›¸è¾ƒäºä¼ ç»Ÿçš„Flow Modelså…·æœ‰æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¯¥ç ”ç©¶ä¸ºåœ¨ç”Ÿæˆæ¨¡å‹ä¸­å¤„ç†é«˜é˜¶å‡ ä½•ç»“æ„å’Œå¯¹ç§°æ€§æä¾›äº†æ–°çš„æ•°å­¦è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.DG"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2507.13414",
      "pdf_url": "https://arxiv.org/pdf/2507.16334v2",
      "published_date": "2025-07-22 08:16:06 UTC",
      "updated_date": "2025-08-06 09:42:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:19.885849+00:00"
    },
    {
      "arxiv_id": "2507.16329v2",
      "title": "DREAM: Scalable Red Teaming for Text-to-Image Generative Systems via Distribution Modeling",
      "title_zh": "DREAMï¼šåŸºäºåˆ†å¸ƒå»ºæ¨¡çš„æ–‡ç”Ÿå›¾ç”Ÿæˆç³»ç»Ÿå¯æ‰©å±•çº¢é˜Ÿæµ‹è¯•",
      "authors": [
        "Boheng Li",
        "Junjie Wang",
        "Yiming Li",
        "Zhiyang Hu",
        "Leyi Qi",
        "Jianshuo Dong",
        "Run Wang",
        "Han Qiu",
        "Zhan Qin",
        "Tianwei Zhang"
      ],
      "abstract": "Despite the integration of safety alignment and external filters, text-to-image (T2I) generative systems are still susceptible to producing harmful content, such as sexual or violent imagery. This raises serious concerns about unintended exposure and potential misuse. Red teaming, which aims to proactively identify diverse prompts that can elicit unsafe outputs from the T2I system, is increasingly recognized as an essential method for assessing and improving safety before real-world deployment. However, existing automated red teaming approaches often treat prompt discovery as an isolated, prompt-level optimization task, which limits their scalability, diversity, and overall effectiveness. To bridge this gap, in this paper, we propose DREAM, a scalable red teaming framework to automatically uncover diverse problematic prompts from a given T2I system. Unlike prior work that optimizes prompts individually, DREAM directly models the probabilistic distribution of the target system's problematic prompts, which enables explicit optimization over both effectiveness and diversity, and allows efficient large-scale sampling after training. To achieve this without direct access to representative training samples, we draw inspiration from energy-based models and reformulate the objective into a simple and tractable form. We further introduce GC-SPSA, an efficient optimization algorithm that provides stable gradient estimates through the long and potentially non-differentiable T2I pipeline. During inference, we also propose a diversity-aware sampling strategy to enhance prompt variety. The effectiveness of DREAM is validated through extensive experiments, demonstrating state-of-the-art performance across a wide range of T2I models and safety filters in terms of both prompt success rate and diversity. Our code is available at https://github.com/AntigoneRandy/DREAM",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DREAMï¼Œä¸€ç§é¢å‘æ–‡æœ¬åˆ°å›¾åƒ(Text-to-Image, T2I)ç”Ÿæˆç³»ç»Ÿçš„å¯æ‰©å±•çº¢é˜Ÿæµ‹è¯•(Red Teaming)æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨å‘ç°èƒ½å¤Ÿè¯±å¯¼ç”Ÿæˆæœ‰å®³å†…å®¹çš„æç¤ºè¯ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å°†æç¤ºè¯ä¼˜åŒ–è§†ä¸ºå­¤ç«‹ä»»åŠ¡è€Œå¯¼è‡´çš„å¯æ‰©å±•æ€§å’Œå¤šæ ·æ€§ç“¶é¢ˆï¼ŒDREAMé€šè¿‡ç›´æ¥å»ºæ¨¡é—®é¢˜æç¤ºè¯çš„æ¦‚ç‡åˆ†å¸ƒ(Probabilistic Distribution)ï¼Œå®ç°äº†å¯¹æ¢æµ‹æœ‰æ•ˆæ€§å’Œæç¤ºè¯å¤šæ ·æ€§çš„æ˜¾å¼ä¼˜åŒ–ã€‚è¯¥æ¡†æ¶å€Ÿé‰´åŸºäºèƒ½é‡çš„æ¨¡å‹(Energy-Based Models)çš„æ€æƒ³ï¼Œå°†ä¼˜åŒ–ç›®æ ‡è½¬åŒ–ä¸ºç®€å•ä¸”æ˜“äºå¤„ç†çš„å½¢å¼ï¼Œå¹¶å¼•å…¥GC-SPSAç®—æ³•åœ¨ä¸å¯å¾®çš„ç”Ÿæˆæµæ°´çº¿ä¸­æä¾›ç¨³å®šçš„æ¢¯åº¦ä¼°è®¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ç»“åˆäº†å¤šæ ·æ€§æ„ŸçŸ¥é‡‡æ ·(Diversity-Aware Sampling)ç­–ç•¥ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºæ¨ç†é˜¶æ®µç”Ÿæˆçš„æç¤ºè¯ä¸°å¯Œåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDREAMåœ¨å¤šç§å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹å’Œå®‰å…¨è¿‡æ»¤å™¨ä¸Šå‡è¾¾åˆ°äº†State-of-the-Artæ€§èƒ½ï¼Œæ˜¾è‘—æå‡äº†çº¢é˜Ÿæµ‹è¯•çš„è§¦å‘æˆåŠŸç‡å’Œæç¤ºè¯å¤šæ ·æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in the IEEE Symposium on Security & Privacy, May 2026",
      "pdf_url": "https://arxiv.org/pdf/2507.16329v2",
      "published_date": "2025-07-22 08:10:22 UTC",
      "updated_date": "2025-12-07 02:58:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:28.177447+00:00"
    },
    {
      "arxiv_id": "2507.16322v1",
      "title": "Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens",
      "title_zh": "å…³æ³¨å·®è·ï¼šå®šé‡åŒ»å­¦è¯­è¨€æ¨ç†å¤§è¯­è¨€æ¨¡å‹åŸºå‡†å¯¹éæ´²ç–¾ç—…è´Ÿæ‹…ä»£è¡¨æ€§çš„è¯„ä¼°",
      "authors": [
        "Fred Mutisya",
        "Shikoh Gitau",
        "Christine Syovata",
        "Diana Oigara",
        "Ibrahim Matende",
        "Muna Aden",
        "Munira Ali",
        "Ryan Nyotu",
        "Diana Marion",
        "Job Nyangena",
        "Nasubo Ongoma",
        "Keith Mbae",
        "Elizabeth Wamicha",
        "Eric Mibuari",
        "Jean Philbert Nsengemana",
        "Talkmore Chidede"
      ],
      "abstract": "Introduction: Existing medical LLM benchmarks largely reflect examination syllabi and disease profiles from high income settings, raising questions about their validity for African deployment where malaria, HIV, TB, sickle cell disease and other neglected tropical diseases (NTDs) dominate burden and national guidelines drive care. Methodology: We systematically reviewed 31 quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English medical QA benchmarks. Alama Health QA was developed using a retrieval augmented generation framework anchored on the Kenyan Clinical Practice Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA, MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized semantic profiling (NTD proportion, recency, readability, lexical diversity metrics) and blinded expert rating across five dimensions: clinical relevance, guideline alignment, clarity, distractor plausibility, and language/cultural fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB (5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global benchmarks showed minimal representation (e.g., sickle cell disease absent in three sets) despite large scale. Qualitatively, Alama scored highest for relevance and guideline alignment; PubMedQA lowest for clinical utility. Discussion: Quantitative medical LLM benchmarks widely used in the literature underrepresent African disease burdens and regulatory contexts, risking misleading performance claims. Guideline anchored, regionally curated resources such as Alama Health QA and expanded disease specific derivatives are essential for safe, equitable model evaluation and deployment across African health systems.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†ç°æœ‰åŒ»å­¦å¤§è¯­è¨€æ¨¡å‹(LLMs)åŸºå‡†æµ‹è¯•åœ¨åæ˜ éæ´²ç–¾ç—…è´Ÿæ‹…ï¼ˆå¦‚ç–Ÿç–¾ã€è‰¾æ»‹ç—…æ¯’ã€ç»“æ ¸ç—…å’Œè¢«å¿½è§†çš„çƒ­å¸¦ç—… NTDsï¼‰æ–¹é¢çš„ä»£è¡¨æ€§ï¼ŒæŒ‡å‡ºé«˜æ”¶å…¥åœ°åŒºçš„è¯„ä¼°æ ‡å‡†éš¾ä»¥ç›´æ¥åº”ç”¨äºéæ´²ã€‚ç ”ç©¶è€…ç³»ç»Ÿå®¡æŸ¥äº†19ä¸ªåŒ»å­¦é—®ç­”åŸºå‡†ï¼Œå¹¶å¼€å‘äº†åŸºäºè‚¯å°¼äºšä¸´åºŠå®è·µæŒ‡å—(Kenyan Clinical Practice Guidelines)çš„è¯„ä¼°å·¥å…· Alama Health QAã€‚é€šè¿‡å¯¹ AfriMedQAã€MMLU-Medical å’Œ PubMedQA ç­‰å…­ä¸ªå¸¸ç”¨æ•°æ®é›†è¿›è¡Œè¯­ä¹‰åˆ†æå’Œä¸“å®¶è¯„å®¡ï¼Œç»“æœæ˜¾ç¤º Alama Health QA åœ¨éæ´²é«˜å‘ç–¾ç—…çš„è¦†ç›–ç‡åŠæŒ‡å—å¯¹é½æ€§æ–¹é¢æ˜¾è‘—ä¼˜äºå…¨çƒé€šç”¨åŸºå‡†ã€‚å®éªŒå‘ç°å…¨çƒæ€§åŸºå‡†åœ¨éæ´²ç‰¹å®šç–¾ç—…ï¼ˆå¦‚é•°çŠ¶ç»†èƒè´«è¡€ç—‡ï¼‰ä¸Šçš„ä»£è¡¨æ€§æä½ï¼Œå­˜åœ¨è¯¯å¯¼æ¨¡å‹æ€§èƒ½è¯„ä¼°çš„é£é™©ã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œå¼€å‘ä»¥æŒ‡å—ä¸ºå¯¼å‘ã€åŒºåŸŸå®šåˆ¶çš„è¯„ä¼°èµ„æºå¯¹äºç¡®ä¿åŒ»å­¦æ¨¡å‹åœ¨éæ´²åŒ»ç–—ä½“ç³»ä¸­çš„å®‰å…¨ã€å…¬å¹³éƒ¨ç½²è‡³å…³é‡è¦ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. 26 pages, includes appendix and tables",
      "pdf_url": "https://arxiv.org/pdf/2507.16322v1",
      "published_date": "2025-07-22 08:05:30 UTC",
      "updated_date": "2025-07-22 08:05:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:30.489372+00:00"
    },
    {
      "arxiv_id": "2507.16872v1",
      "title": "CompLeak: Deep Learning Model Compression Exacerbates Privacy Leakage",
      "title_zh": "CompLeakï¼šæ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©åŠ å‰§éšç§æ³„éœ²",
      "authors": [
        "Na Li",
        "Yansong Gao",
        "Hongsheng Hu",
        "Boyu Kuang",
        "Anmin Fu"
      ],
      "abstract": "Model compression is crucial for minimizing memory storage and accelerating inference in deep learning (DL) models, including recent foundation models like large language models (LLMs). Users can access different compressed model versions according to their resources and budget. However, while existing compression operations primarily focus on optimizing the trade-off between resource efficiency and model performance, the privacy risks introduced by compression remain overlooked and insufficiently understood.\n  In this work, through the lens of membership inference attack (MIA), we propose CompLeak, the first privacy risk evaluation framework examining three widely used compression configurations that are pruning, quantization, and weight clustering supported by the commercial model compression framework of Google's TensorFlow-Lite (TF-Lite) and Facebook's PyTorch Mobile. CompLeak has three variants, given available access to the number of compressed models and original model. CompLeakNR starts by adopting existing MIA methods to attack a single compressed model, and identifies that different compressed models influence members and non-members differently. When the original model and one compressed model are available, CompLeakSR leverages the compressed model as a reference to the original model and uncovers more privacy by combining meta information (e.g., confidence vector) from both models. When multiple compressed models are available with/without accessing the original model, CompLeakMR innovatively exploits privacy leakage info from multiple compressed versions to substantially signify the overall privacy leakage. We conduct extensive experiments on seven diverse model architectures (from ResNet to foundation models of BERT and GPT-2), and six image and textual benchmark datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† CompLeakï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°æ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©å¦‚ä½•åŠ å‰§éšç§é£é™©çš„æ¡†æ¶ï¼Œé‡ç‚¹åˆ†æäº†å‰ªæ (pruning)ã€é‡åŒ– (quantization) å’Œæƒé‡èšç±» (weight clustering) ç­‰ä¸»æµæŠ€æœ¯ã€‚ç ”ç©¶è€…ä»æˆå‘˜æ¨ç†æ”»å‡» (Membership Inference Attack, MIA) çš„è§†è§’åˆ‡å…¥ï¼Œè®¾è®¡äº†é’ˆå¯¹ä¸åŒè®¿é—®æƒé™çš„ä¸‰ç§è¯„ä¼°å˜ä½“ï¼šCompLeakNR é’ˆå¯¹å•ä¸ªå‹ç¼©æ¨¡å‹è¿›è¡Œæ”»å‡»ï¼ŒCompLeakSR åˆ©ç”¨å‹ç¼©æ¨¡å‹ä½œä¸ºåŸå§‹æ¨¡å‹çš„å‚è€ƒä»¥æŒ–æ˜æ›´å¤šå…ƒä¿¡æ¯ï¼Œè€Œ CompLeakMR åˆ™åˆ›æ–°æ€§åœ°æ•´åˆå¤šä¸ªå‹ç¼©ç‰ˆæœ¬çš„æ³„éœ²ä¿¡æ¯ä»¥æå‡æ”»å‡»æ•ˆæœã€‚å®éªŒæ¶µç›–äº†ä» ResNet åˆ° BERT å’Œ GPT-2 ç­‰å¤šç§æ¨¡å‹æ¶æ„ï¼Œå¹¶åœ¨å…­ä¸ªå›¾åƒå’Œæ–‡æœ¬åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›éªŒè¯ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œæ¨¡å‹å‹ç¼©ä¼šæ˜¾è‘—æ”¹å˜æˆå‘˜ä¸éæˆå‘˜æ•°æ®çš„åˆ†å¸ƒç‰¹æ€§ï¼Œä»è€Œåœ¨ä¼˜åŒ–èµ„æºæ•ˆç‡çš„åŒæ—¶å¼•å…¥äº†è¢«å¿½è§†çš„éšç§éšæ‚£ã€‚è¿™é¡¹å·¥ä½œç³»ç»Ÿåœ°æ­ç¤ºäº†å‹ç¼©æ¨¡å‹ç‰ˆæœ¬ä¹‹é—´çš„éšç§å…³è”ï¼Œä¸ºæœªæ¥å¼€å‘å…¼é¡¾æ•ˆç‡ä¸éšç§çš„æ·±åº¦å­¦ä¹ æ¨¡å‹æä¾›äº†å…³é”®çš„è¯„ä¼°åŸºå‡†å’Œç†è®ºä¾æ®ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16872v1",
      "published_date": "2025-07-22 08:02:46 UTC",
      "updated_date": "2025-07-22 08:02:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:31.391001+00:00"
    },
    {
      "arxiv_id": "2507.16307v1",
      "title": "Perovskite-R1: A Domain-Specialized LLM for Intelligent Discovery of Precursor Additives and Experimental Design",
      "title_zh": "Perovskite-R1ï¼šç”¨äºå‰é©±ä½“æ·»åŠ å‰‚æ™ºèƒ½å‘ç°ä¸å®éªŒè®¾è®¡çš„é¢†åŸŸä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Xin-De Wang",
        "Zhi-Rui Chen",
        "Peng-Jie Guo",
        "Ze-Feng Gao",
        "Cheng Mu",
        "Zhong-Yi Lu"
      ],
      "abstract": "Perovskite solar cells (PSCs) have rapidly emerged as a leading contender in next-generation photovoltaic technologies, owing to their exceptional power conversion efficiencies and advantageous material properties. Despite these advances, challenges such as long-term stability, environmental sustainability, and scalable manufacturing continue to hinder their commercialization. Precursor additive engineering has shown promise in addressing these issues by enhancing both the performance and durability of PSCs. However, the explosive growth of scientific literature and the complex interplay of materials, processes, and device architectures make it increasingly difficult for researchers to efficiently access, organize, and utilize domain knowledge in this rapidly evolving field. To address this gap, we introduce Perovskite-R1, a specialized large language model (LLM) with advanced reasoning capabilities tailored for the discovery and design of PSC precursor additives. By systematically mining and curating 1,232 high-quality scientific publications and integrating a comprehensive library of 33,269 candidate materials, we constructed a domain-specific instruction-tuning dataset using automated question-answer generation and chain-of-thought reasoning. Fine-tuning the QwQ-32B model on this dataset resulted in Perovskite-R1, which can intelligently synthesize literature insights and generate innovative and practical solutions for defect passivation and the selection of precursor additives. Experimental validation of several model-proposed strategies confirms their effectiveness in improving material stability and performance. Our work demonstrates the potential of domain-adapted LLMs in accelerating materials discovery and provides a closed-loop framework for intelligent, data-driven advancements in perovskite photovoltaic research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†Perovskite-R1ï¼Œè¿™æ˜¯ä¸€ç§ä¸“ä¸ºé’™é’›çŸ¿å¤ªé˜³èƒ½ç”µæ± (PSCs)å‰é©±ä½“æ·»åŠ å‰‚çš„å‘ç°å’Œå®éªŒè®¾è®¡è€Œå¼€å‘çš„é¢†åŸŸä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹(LLM)ã€‚é’ˆå¯¹PSCsåœ¨é•¿æœŸç¨³å®šæ€§ã€ç¯å¢ƒå¯æŒç»­æ€§å’Œå¯æ‰©å±•åˆ¶é€ æ–¹é¢çš„æŒ‘æˆ˜ï¼Œä»¥åŠå‰é©±ä½“æ·»åŠ å‰‚å·¥ç¨‹ä¸­æµ·é‡æ–‡çŒ®å¸¦æ¥çš„çŸ¥è¯†æå–å›°éš¾ï¼Œè¯¥æ¨¡å‹æ—¨åœ¨é€šè¿‡å…ˆè¿›çš„æ¨ç†èƒ½åŠ›è¾…åŠ©ææ–™è®¾è®¡ã€‚ç ”ç©¶äººå‘˜ç³»ç»Ÿåœ°æŒ–æ˜å¹¶æ•´ç†äº†1,232ç¯‡é«˜è´¨é‡ç§‘å­¦å‡ºç‰ˆç‰©ï¼Œå¹¶æ•´åˆäº†åŒ…å«33,269ç§å€™é€‰ææ–™çš„ç»¼åˆåº“ï¼Œåˆ©ç”¨è‡ªåŠ¨é—®ç­”ç”Ÿæˆå’Œé“¾å¼æ€ç»´(Chain-of-Thought)æ¨ç†æ„å»ºäº†é¢†åŸŸç‰¹æœ‰çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚é€šè¿‡åœ¨QwQ-32Bæ¨¡å‹ä¸Šè¿›è¡Œå¾®è°ƒï¼ŒPerovskite-R1èƒ½å¤Ÿæ™ºèƒ½åˆæˆæ–‡çŒ®è§è§£ï¼Œå¹¶é’ˆå¯¹ç¼ºé™·é’åŒ–å’Œå‰é©±ä½“æ·»åŠ å‰‚é€‰æ‹©ç”Ÿæˆå…·æœ‰åˆ›æ–°æ€§å’Œå®ç”¨æ€§çš„è§£å†³æ–¹æ¡ˆã€‚å®éªŒéªŒè¯ç¡®è®¤äº†æ¨¡å‹æå‡ºçš„ç­–ç•¥åœ¨æé«˜ææ–™ç¨³å®šæ€§å’Œæ€§èƒ½æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚è¯¥å·¥ä½œå±•ç¤ºäº†é¢†åŸŸè‡ªé€‚åº”LLMsåœ¨åŠ é€Ÿææ–™å‘ç°æ–¹é¢çš„æ½œåŠ›ï¼Œå¹¶ä¸ºé’™é’›çŸ¿å…‰ä¼ç ”ç©¶ä¸­çš„æ™ºèƒ½æ•°æ®é©±åŠ¨è¿›æ­¥æä¾›äº†é—­ç¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages; 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16307v1",
      "published_date": "2025-07-22 07:48:32 UTC",
      "updated_date": "2025-07-22 07:48:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:37.240109+00:00"
    },
    {
      "arxiv_id": "2507.16302v2",
      "title": "Towards Resilient Safety-driven Unlearning for Diffusion Models against Downstream Fine-tuning",
      "title_zh": "é¢å‘ä¸‹æ¸¸å¾®è°ƒçš„æ‰©æ•£æ¨¡å‹éŸ§æ€§å®‰å…¨é©±åŠ¨é—å¿˜å­¦ä¹ ",
      "authors": [
        "Boheng Li",
        "Renjie Gu",
        "Junjie Wang",
        "Leyi Qi",
        "Yiming Li",
        "Run Wang",
        "Zhan Qin",
        "Tianwei Zhang"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have achieved impressive image generation quality and are increasingly fine-tuned for personalized applications. However, these models often inherit unsafe behaviors from toxic pretraining data, raising growing safety concerns. While recent safety-driven unlearning methods have made promising progress in suppressing model toxicity, they are found to be fragile to downstream fine-tuning, as we reveal that state-of-the-art methods largely fail to retain their effectiveness even when fine-tuned on entirely benign datasets. To mitigate this problem, in this paper, we propose ResAlign, a safety-driven unlearning framework with enhanced resilience against downstream fine-tuning. By modeling downstream fine-tuning as an implicit optimization problem with a Moreau envelope-based reformulation, ResAlign enables efficient gradient estimation to minimize the recovery of harmful behaviors. Additionally, a meta-learning strategy is proposed to simulate a diverse distribution of fine-tuning scenarios to improve generalization. Extensive experiments across a wide range of datasets, fine-tuning methods, and configurations demonstrate that ResAlign consistently outperforms prior unlearning approaches in retaining safety, while effectively preserving benign generation capability. Our code and pretrained models are publicly available at https://github.com/AntigoneRandy/ResAlign.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒ (Text-to-image) Diffusion Models åœ¨ä¸‹æ¸¸å¾®è°ƒ (Fine-tuning) è¿‡ç¨‹ä¸­å®¹æ˜“æ¢å¤ä¸å®‰å…¨è¡Œä¸ºçš„é—®é¢˜ï¼Œæå‡ºäº† ResAlign æ¡†æ¶ä»¥å¢å¼ºå®‰å…¨æ€§æ“¦é™¤ (Safety-driven Unlearning) çš„éŸ§æ€§ã€‚ResAlign å°†ä¸‹æ¸¸å¾®è°ƒè¿‡ç¨‹å»ºæ¨¡ä¸ºåŸºäº Moreau envelope é‡æ„çš„éšå¼ä¼˜åŒ–é—®é¢˜ï¼Œé€šè¿‡é«˜æ•ˆçš„æ¢¯åº¦ä¼°è®¡æœ€å°åŒ–æœ‰å®³è¡Œä¸ºçš„é‡æ–°è§¦å‘ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å…ƒå­¦ä¹  (Meta-learning) ç­–ç•¥æ¥æ¨¡æ‹Ÿå¤šæ ·åŒ–çš„å¾®è°ƒåœºæ™¯ï¼Œæ˜¾è‘—æå‡äº†å®‰å…¨æ€§çº¦æŸåœ¨ä¸åŒä¸‹æ¸¸ä»»åŠ¡ä¸­çš„æ³›åŒ–æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒResAlign åœ¨å¤šç§å¾®è°ƒæ–¹æ³•å’Œé…ç½®ä¸‹å‡èƒ½ä¸€è‡´æ€§åœ°ä¼˜äºå…ˆå‰çš„æ“¦é™¤æ–¹æ³•ï¼Œåœ¨ä¿æŒæé«˜å®‰å…¨æ€§çš„åŒæ—¶æœ‰æ•ˆä¿ç•™äº†æ¨¡å‹åœ¨è‰¯æ€§æ•°æ®é›†ä¸Šçš„å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚è¯¥å·¥ä½œä¸ºæ„å»ºé²æ£’ä¸”å¯ä¿¡çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.16302v2",
      "published_date": "2025-07-22 07:40:16 UTC",
      "updated_date": "2025-12-06 13:02:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:41.335775+00:00"
    },
    {
      "arxiv_id": "2507.16296v2",
      "title": "Cross-Modal Distillation For Widely Differing Modalities",
      "title_zh": "é¢å‘æ˜¾è‘—å·®å¼‚æ¨¡æ€çš„è·¨æ¨¡æ€è’¸é¦",
      "authors": [
        "Cairong Zhao",
        "Yufeng Jin",
        "Zifan Song",
        "Haonan Chen",
        "Duoqian Miao",
        "Guosheng Hu"
      ],
      "abstract": "Deep learning achieved great progress recently, however, it is not easy or efficient to further improve its performance by increasing the size of the model. Multi-modal learning can mitigate this challenge by introducing richer and more discriminative information as input. To solve the problem of limited access to multi-modal data at the time of use, we conduct multi-modal learning by introducing a teacher model to transfer discriminative knowledge to a student model during training. However, this knowledge transfer via distillation is not trivial because the big domain gap between the widely differing modalities can easily lead to overfitting. In this work, we introduce a cross-modal distillation framework. Specifically, we find hard constrained loss, e.g. l2 loss forcing the student being exact the same as the teacher, can easily lead to overfitting in cross-modality distillation. To address this, we propose two soft constrained knowledge distillation strategies at the feature level and classifier level respectively. In addition, we propose a quality-based adaptive weights module to weigh input samples via quantified data quality, leading to robust model training. We conducted experiments on speaker recognition and image classification tasks, and the results show that our approach is able to effectively achieve knowledge transfer between the commonly used and widely differing modalities of image, text, and speech.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®é™…åº”ç”¨ä¸­å¤šæ¨¡æ€æ•°æ®è·å–å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è·¨æ¨¡æ€è’¸é¦(cross-modal distillation)æ¡†æ¶ï¼Œæ—¨åœ¨å°†åˆ¤åˆ«æ€§çŸ¥è¯†ä»è€å¸ˆæ¨¡å‹æœ‰æ•ˆè½¬ç§»è‡³å­¦ç”Ÿæ¨¡å‹ã€‚ä½œè€…å‘ç°ç”±äºä¸åŒæ¨¡æ€(modalities)ä¹‹é—´å­˜åœ¨å·¨å¤§çš„é¢†åŸŸé¸¿æ²Ÿ(domain gap)ï¼Œä½¿ç”¨å¦‚l2æŸå¤±ç­‰å¼ºçº¦æŸæŸå¤±(hard constrained loss)è¿›è¡Œè’¸é¦æ—¶ææ˜“å¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œè¯¥è®ºæ–‡åœ¨ç‰¹å¾å±‚(feature level)å’Œåˆ†ç±»å™¨å±‚(classifier level)åˆ†åˆ«æå‡ºäº†ä¸¤ç§è½¯çº¦æŸ(soft constrained)çŸ¥è¯†è’¸é¦ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªåŸºäºè´¨é‡çš„è‡ªé€‚åº”æƒé‡æ¨¡å—(quality-based adaptive weights module)ï¼Œé€šè¿‡é‡åŒ–æ•°æ®è´¨é‡å¯¹è¾“å…¥æ ·æœ¬è¿›è¡ŒåŠ æƒï¼Œä»è€Œç¡®ä¿æ¨¡å‹è®­ç»ƒçš„ç¨³å¥æ€§ã€‚åœ¨è¯´è¯äººè¯†åˆ«(speaker recognition)å’Œå›¾åƒåˆ†ç±»(image classification)ä»»åŠ¡ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆåœ°åœ¨å›¾åƒã€æ–‡æœ¬å’Œè¯­éŸ³ç­‰å·®å¼‚æ˜¾è‘—çš„æ¨¡æ€ä¹‹é—´å®ç°çŸ¥è¯†è½¬ç§»ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16296v2",
      "published_date": "2025-07-22 07:34:00 UTC",
      "updated_date": "2025-10-05 06:45:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:44.632450+00:00"
    },
    {
      "arxiv_id": "2507.16280v1",
      "title": "ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry",
      "title_zh": "ResearcherBenchï¼šé¢å‘ç§‘å­¦æ¢ç©¶å‰æ²¿çš„æ·±åº¦äººå·¥æ™ºèƒ½ç ”ç©¶ç³»ç»Ÿè¯„ä¼°",
      "authors": [
        "Tianze Xu",
        "Pengrui Lu",
        "Lyumanshan Ye",
        "Xiangkun Hu",
        "Pengfei Liu"
      ],
      "abstract": "The emergence of deep research systems presents significant capabilities in problem-solving, extending from basic queries to sophisticated research tasks. However, existing benchmarks primarily evaluate these systems as agents for web retrieval and report generation, overlooking their potential to discover novel insights on the frontiers of scientific research. To address this gap, we introduce ResearcherBench, the first benchmark focused on evaluating the capabilities of these advanced, agentic systems - which we refer to as Deep AI Research Systems (DARS) - on frontier AI scientific questions. We compiled a dataset of 65 research questions expertly selected from real-world scientific scenarios such as laboratory discussions and interviews, spanning 35 different AI subjects and categorized into three types: technical details, literature review, and open consulting. Our dual evaluation framework combines rubric assessment, which uses expert-designed criteria to evaluate insight quality, with factual assessment, which measures citation accuracy (faithfulness) and coverage (groundedness). We evaluated several leading commercial DARS and baseline systems. Results show that OpenAI Deep Research and Gemini Deep Research significantly outperform other systems, with particular strength in open-ended consulting questions. Such capabilities represent a meaningful step toward AI self-improvement, aligning with the vision of ASI for AI. We open-source ResearcherBench to provide a standardized platform for promoting the development of next-generation AI research assistants, hoping to foster a new perspective in AI research evaluation for a novel pattern of scientific collaboration: https://github.com/GAIR-NLP/ResearcherBench.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ResearcherBenchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“æ³¨äºè¯„ä¼°æ·±åº¦äººå·¥æ™ºèƒ½ç ”ç©¶ç³»ç»Ÿï¼ˆDeep AI Research Systems, DARSï¼‰åœ¨å‰æ²¿ç§‘å­¦é—®é¢˜è§£å†³èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«65ä¸ªæºè‡ªå®éªŒå®¤è®¨è®ºå’Œè®¿è°ˆçš„çœŸå®ç ”ç©¶é—®é¢˜ï¼Œè¦†ç›–35ä¸ªAIå­¦ç§‘ï¼Œå¹¶åˆ†ä¸ºæŠ€æœ¯ç»†èŠ‚ã€æ–‡çŒ®ç»¼è¿°å’Œå¼€æ”¾å’¨è¯¢ä¸‰ç±»ä»»åŠ¡ã€‚è¯„ä¼°æ¡†æ¶ç»“åˆäº†è€ƒå¯Ÿæ´å¯Ÿè´¨é‡çš„é‡è¡¨è¯„ä»·ï¼ˆrubric assessmentï¼‰ä»¥åŠè¡¡é‡å¼•ç”¨å‡†ç¡®æ€§ï¼ˆfaithfulnessï¼‰ä¸è¦†ç›–ç‡ï¼ˆgroundednessï¼‰çš„äº‹å®è¯„ä¼°ï¼ˆfactual assessmentï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒOpenAI Deep Research å’Œ Gemini Deep Research åœ¨è¯¥åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–ç³»ç»Ÿï¼Œå°¤å…¶åœ¨å¼€æ”¾å¼å’¨è¯¢é—®é¢˜ä¸­è¡¨ç°å‡ºå¼ºåŠ²å®åŠ›ã€‚è¿™é¡¹å·¥ä½œä¸ºä¸‹ä¸€ä»£AIç ”ç©¶åŠ©æ‰‹çš„å‘å±•æä¾›äº†æ ‡å‡†åŒ–å¹³å°ï¼Œæ˜¯è¿ˆå‘äººå·¥æ™ºèƒ½è‡ªæˆ‘æå‡ï¼ˆAI self-improvementï¼‰åŠäººå·¥è¶…æ™ºèƒ½ï¼ˆASIï¼‰æ„¿æ™¯çš„é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16280v1",
      "published_date": "2025-07-22 06:51:26 UTC",
      "updated_date": "2025-07-22 06:51:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:17:45.938609+00:00"
    },
    {
      "arxiv_id": "2507.16278v1",
      "title": "Understanding Generalization, Robustness, and Interpretability in Low-Capacity Neural Networks",
      "title_zh": "ç†è§£ä½å®¹é‡ç¥ç»ç½‘ç»œçš„æ³›åŒ–ã€é²æ£’æ€§ä¸å¯è§£é‡Šæ€§",
      "authors": [
        "Yash Kumar"
      ],
      "abstract": "Although modern deep learning often relies on massive over-parameterized models, the fundamental interplay between capacity, sparsity, and robustness in low-capacity networks remains a vital area of study. We introduce a controlled framework to investigate these properties by creating a suite of binary classification tasks from the MNIST dataset with increasing visual difficulty (e.g., 0 and 1 vs. 4 and 9). Our experiments reveal three core findings. First, the minimum model capacity required for successful generalization scales directly with task complexity. Second, these trained networks are robust to extreme magnitude pruning (up to 95% sparsity), revealing the existence of sparse, high-performing subnetworks. Third, we show that over-parameterization provides a significant advantage in robustness against input corruption. Interpretability analysis via saliency maps further confirms that these identified sparse subnetworks preserve the core reasoning process of the original dense models. This work provides a clear, empirical demonstration of the foundational trade-offs governing simple neural networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä½å®¹é‡ç¥ç»ç½‘ç»œ (low-capacity neural networks) ä¸­å®¹é‡ã€ç¨€ç–æ€§ä¸é²æ£’æ€§ä¹‹é—´çš„åŸºæœ¬ç›¸äº’ä½œç”¨ã€‚é€šè¿‡æ„å»ºä¸€ç³»åˆ—å…·æœ‰ä¸åŒè§†è§‰éš¾åº¦çš„ MNIST äºŒåˆ†ç±»ä»»åŠ¡ï¼Œç ”ç©¶äººå‘˜å»ºç«‹äº†ä¸€ä¸ªå—æ§æ¡†æ¶æ¥é‡åŒ–åˆ†æè¿™äº›å±æ€§ã€‚å®éªŒå‘ç°ï¼Œå®ç°æˆåŠŸæ³›åŒ– (generalization) æ‰€éœ€çš„æœ€å°æ¨¡å‹å®¹é‡ä¸ä»»åŠ¡å¤æ‚åº¦ç›´æ¥ç›¸å…³ã€‚åŒæ—¶ï¼Œè¿™äº›ç½‘ç»œå¯¹æç«¯å¹…å€¼å‰ªæ (magnitude pruning) è¡¨ç°å‡ºå¼ºé²æ£’æ€§ï¼Œå³ä½¿åœ¨ 95% çš„ç¨€ç–åº¦ä¸‹ä»å­˜åœ¨é«˜æ€§èƒ½çš„ç¨€ç–å­ç½‘ç»œ (sparse subnetworks)ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜ï¼Œè¿‡åº¦å‚æ•°åŒ– (over-parameterization) åœ¨æŠµæŠ—è¾“å…¥æŸå (input corruption) çš„é²æ£’æ€§æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚æ˜¾è‘—å›¾ (saliency maps) çš„å¯è§£é‡Šæ€§åˆ†æç¡®è®¤ï¼Œè¿™äº›ç¨€ç–å­ç½‘ç»œä¿ç•™äº†åŸå§‹ç¨ å¯†æ¨¡å‹çš„æ ¸å¿ƒæ¨ç†è¿‡ç¨‹ã€‚è¯¥å·¥ä½œé€šè¿‡å®è¯æ¸…æ™°åœ°æ­ç¤ºäº†æ”¯é…ç®€å•ç¥ç»ç½‘ç»œçš„åŸºæœ¬æƒè¡¡å…³ç³»ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages (10 pages main text). 18 figures (8 main, 10 appendix), 1 table",
      "pdf_url": "https://arxiv.org/pdf/2507.16278v1",
      "published_date": "2025-07-22 06:43:03 UTC",
      "updated_date": "2025-07-22 06:43:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:03.332753+00:00"
    },
    {
      "arxiv_id": "2507.16274v2",
      "title": "STAlloc: Enhancing Memory Efficiency in Large-Scale Model Training with Spatio-Temporal Planning",
      "title_zh": "STAllocï¼šåˆ©ç”¨æ—¶ç©ºè§„åˆ’æå‡å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒçš„å†…å­˜æ•ˆç‡",
      "authors": [
        "Zixiao Huang",
        "Junhao Hu",
        "Hao Lin",
        "Chunyang Zhu",
        "Yueran Tang",
        "Quanlu Zhang",
        "Zhen Guo",
        "Zhenhua Li",
        "Shengen Yan",
        "Zhenhua Zhu",
        "Guohao Dai",
        "Yu Wang"
      ],
      "abstract": "The rapid scaling of large language models (LLMs) has significantly increased GPU memory pressure, which is further aggravated by training optimization techniques such as virtual pipeline and recomputation that disrupt tensor lifespans and introduce considerable memory fragmentation. Such fragmentation stems from the use of online GPU memory allocators in popular deep learning frameworks like PyTorch, which disregard tensor lifespans. As a result, this inefficiency can waste as much as 43% of memory and trigger out-of-memory errors, undermining the effectiveness of optimization methods. To address this, we introduce STAlloc, a GPU memory allocator for deep learning frameworks that reduces fragmentation by exploiting the spatial and temporal regularity in memory allocation behaviors of training workloads. STAlloc introduces a novel paradigm that combines offline planning with online allocation. The offline planning leverages spatio-temporal regularities to generate a near-optimal allocation plan, while the online allocation handles complex and dynamic models such as Mixture-of-Experts (MoE). Built as a pluggable PyTorch memory allocator, STAlloc reduces fragmentation ratio on average by 85.1% (up to 100%) across both dense and MoE models, with negligible overhead. This enables more efficient, high-throughput training configurations and improves throughput performance by up to 32.5%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)è®­ç»ƒä¸­ç”±äºè™šæ‹Ÿæµæ°´çº¿(virtual pipeline)å’Œé‡è®¡ç®—(recomputation)ç­‰ä¼˜åŒ–æŠ€æœ¯å¯¼è‡´çš„GPUæ˜¾å­˜ç¢ç‰‡åŒ–é—®é¢˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰çš„åœ¨çº¿å†…å­˜åˆ†é…å™¨(online memory allocators)å› å¿½ç•¥å¼ é‡ç”Ÿå‘½å‘¨æœŸ(tensor lifespans)å¯¼è‡´æ˜¾å­˜æµªè´¹é«˜è¾¾43%ï¼Œä¸¥é‡å‰Šå¼±äº†ä¼˜åŒ–æŠ€æœ¯çš„æœ‰æ•ˆæ€§ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†STAllocï¼Œä¸€ç§é€šè¿‡åˆ©ç”¨æ˜¾å­˜åˆ†é…è¡Œä¸ºçš„æ—¶ç©ºè§„å¾‹æ€§(spatio-temporal regularity)æ¥å‡å°‘ç¢ç‰‡åŒ–çš„æ–°å‹åˆ†é…å™¨ã€‚è¯¥æ–¹æ¡ˆç»“åˆäº†ç”¨äºç”Ÿæˆè¿‘ä¼˜æ–¹æ¡ˆçš„ç¦»çº¿è§„åˆ’(offline planning)ä¸å¤„ç†åŠ¨æ€ä»»åŠ¡çš„åœ¨çº¿åˆ†é…(online allocation)ï¼Œå¹¶ä½œä¸ºæ’ä»¶å¼PyTorchåˆ†é…å™¨å®ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSTAllocåœ¨ç¨ å¯†æ¨¡å‹(dense models)å’Œä¸“å®¶æ··åˆæ¨¡å‹(MoE)ä¸Šå¹³å‡é™ä½äº†85.1%çš„ç¢ç‰‡ç‡ï¼Œä¸”é¢å¤–å¼€é”€æå°ã€‚è¿™ç§ä¼˜åŒ–æœ€ç»ˆä½¿è®­ç»ƒååé‡(throughput)æå‡äº†æœ€é«˜32.5%ï¼Œæ˜¾è‘—å¢å¼ºäº†å¤§æ¨¡å‹è®­ç»ƒçš„æ˜¾å­˜åˆ©ç”¨æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16274v2",
      "published_date": "2025-07-22 06:39:07 UTC",
      "updated_date": "2025-11-25 07:36:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:01.639928+00:00"
    },
    {
      "arxiv_id": "2507.16267v2",
      "title": "SFNet: A Spatial-Frequency Domain Deep Learning Network for Efficient Alzheimer's Disease Diagnosis",
      "title_zh": "SFNetï¼šé¢å‘é«˜æ•ˆé˜¿å°”èŒ¨æµ·é»˜ç—…è¯Šæ–­çš„ç©ºé¢‘åŸŸæ·±åº¦å­¦ä¹ ç½‘ç»œ",
      "authors": [
        "Xinyue Yang",
        "Meiliang Liu",
        "Yunfang Xu",
        "Xiaoxiao Yang",
        "Zhengye Si",
        "Zijin Li",
        "Zhiwen Zhao"
      ],
      "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that predominantly affects the elderly population and currently has no cure. Magnetic Resonance Imaging (MRI), as a non-invasive imaging technique, is essential for the early diagnosis of AD. MRI inherently contains both spatial and frequency information, as raw signals are acquired in the frequency domain and reconstructed into spatial images via the Fourier transform. However, most existing AD diagnostic models extract features from a single domain, limiting their capacity to fully capture the complex neuroimaging characteristics of the disease. While some studies have combined spatial and frequency information, they are mostly confined to 2D MRI, leaving the potential of dual-domain analysis in 3D MRI unexplored. To overcome this limitation, we propose Spatio-Frequency Network (SFNet), the first end-to-end deep learning framework that simultaneously leverages spatial and frequency domain information to enhance 3D MRI-based AD diagnosis. SFNet integrates an enhanced dense convolutional network to extract local spatial features and a global frequency module to capture global frequency-domain representations. Additionally, a novel multi-scale attention module is proposed to further refine spatial feature extraction. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset demonstrate that SFNet outperforms existing baselines and reduces computational overhead in classifying cognitively normal (CN) and AD, achieving an accuracy of 95.1%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿å°”èŒ¨æµ·é»˜ç—… (AD) æ—©æœŸè¯Šæ–­ä¸­ç°æœ‰æ¨¡å‹å¤šå±€é™äºå•åŸŸç‰¹å¾æå–ä¸”åœ¨ 3D MRI åŒåŸŸåˆ†ææ–¹é¢æ¢ç´¢ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº† SFNetï¼Œè¿™æ˜¯é¦–ä¸ªåŒæ—¶åˆ©ç”¨ç©ºé—´å’Œé¢‘åŸŸä¿¡æ¯å¢å¼ºè¯Šæ–­æ•ˆèƒ½çš„ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¯¥ç½‘ç»œé€šè¿‡é›†æˆå¢å¼ºçš„å¯†é›†å·ç§¯ç½‘ç»œæå–å±€éƒ¨ç©ºé—´ç‰¹å¾ï¼Œå¹¶ç»“åˆå¤šå°ºåº¦æ³¨æ„åŠ›æ¨¡å—è¿›ä¸€æ­¥ç»†åŒ–ç©ºé—´ç‰¹å¾ï¼ŒåŒæ—¶åˆ©ç”¨å…¨å±€é¢‘ç‡æ¨¡å—æ•æ‰å…¨å±€é¢‘åŸŸè¡¨å¾ã€‚åœ¨ Alzheimer's Disease Neuroimaging Initiative (ADNI) æ•°æ®é›†ä¸Šçš„å®éªŒè¯æ˜ï¼ŒSFNet åœ¨åŒºåˆ†è®¤çŸ¥æ­£å¸¸ (CN) ä¸ AD æ–¹é¢çš„å‡†ç¡®ç‡è¾¾åˆ° 95.1%ï¼Œä¼˜äºç°æœ‰åŸºå‡†æ¨¡å‹ã€‚æ­¤å¤–ï¼ŒSFNet æœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€ï¼Œä¸ºå®ç°é«˜æ•ˆã€ç²¾å‡†çš„ AD ä¸´åºŠè¯Šæ–­æä¾›äº†å…·æœ‰æ½œåŠ›çš„æ–°å‹æŠ€æœ¯æ‰‹æ®µã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16267v2",
      "published_date": "2025-07-22 06:33:00 UTC",
      "updated_date": "2025-07-23 05:53:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:36.134492+00:00"
    },
    {
      "arxiv_id": "2507.16254v1",
      "title": "Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective",
      "title_zh": "é¢å‘é±¼çœ¼ç›®æ ‡æ£€æµ‹çš„è¾¹ç¼˜æ¡ˆä¾‹åˆæˆï¼šä»¥æ•°æ®ä¸ºä¸­å¿ƒçš„è§†è§’",
      "authors": [
        "Seunghyeon Kim",
        "Kyeongryeol Go"
      ],
      "abstract": "Fisheye cameras introduce significant distortion and pose unique challenges to object detection models trained on conventional datasets. In this work, we propose a data-centric pipeline that systematically improves detection performance by focusing on the key question of identifying the blind spots of the model. Through detailed error analysis, we identify critical edge-cases such as confusing class pairs, peripheral distortions, and underrepresented contexts. Then we directly address them through edge-case synthesis. We fine-tuned an image generative model and guided it with carefully crafted prompts to produce images that replicate real-world failure modes. These synthetic images are pseudo-labeled using a high-quality detector and integrated into training. Our approach results in consistent performance gains, highlighting how deeply understanding data and selectively fixing its weaknesses can be impactful in specialized domains like fisheye object detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ä»¥æ•°æ®ä¸ºä¸­å¿ƒ(Data-centric)çš„æµæ°´çº¿ï¼Œæ—¨åœ¨è§£å†³é±¼çœ¼ç›¸æœº(Fisheye cameras)ç”±äºå›¾åƒç•¸å˜ç»™ç›®æ ‡æ£€æµ‹æ¨¡å‹å¸¦æ¥çš„ä¸¥å³»æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è¯¦ç»†çš„é”™è¯¯åˆ†æï¼Œè¯†åˆ«å‡ºäº†ç±»åˆ«å¯¹æ··æ·†ã€è¾¹ç¼˜ç•¸å˜å’Œä»£è¡¨æ€§ä¸è¶³çš„ä¸Šä¸‹æ–‡ç­‰å…³é”®è¾¹ç•Œæ¡ˆä¾‹(Edge-cases)ã€‚éšåï¼Œè¯¥æ–¹æ³•åˆ©ç”¨å¾®è°ƒåçš„å›¾åƒç”Ÿæˆæ¨¡å‹å¹¶ç»“åˆç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ï¼Œåˆæˆå‡ºæ¨¡æ‹ŸçœŸå®ä¸–ç•Œå¤±æ•ˆæ¨¡å¼çš„å›¾åƒã€‚è¿™äº›åˆæˆå›¾åƒç»ç”±é«˜è´¨é‡æ£€æµ‹å™¨è¿›è¡Œä¼ªæ ‡ç­¾(Pseudo-labeled)å¤„ç†åè¢«æ•´åˆåˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨é±¼çœ¼ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­å®ç°äº†æŒç»­çš„æ€§èƒ½æå‡ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†åœ¨é±¼çœ¼æ£€æµ‹ç­‰ç‰¹æ®Šé¢†åŸŸä¸­ï¼Œé€šè¿‡æ·±å…¥ç†è§£æ•°æ®å¹¶æœ‰é’ˆå¯¹æ€§åœ°ä¿®å¤å…¶è–„å¼±ç¯èŠ‚å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16254v1",
      "published_date": "2025-07-22 06:07:07 UTC",
      "updated_date": "2025-07-22 06:07:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:05.185284+00:00"
    },
    {
      "arxiv_id": "2507.16252v1",
      "title": "Efficient RL for optimizing conversation level outcomes with an LLM-based tutor",
      "title_zh": "é«˜æ•ˆå¼ºåŒ–å­¦ä¹ ï¼šä¼˜åŒ–åŸºäºå¤§è¯­è¨€æ¨¡å‹å¯¼å¸ˆçš„ä¼šè¯çº§æˆæœ",
      "authors": [
        "Hyunji Nam",
        "Omer Gottesman",
        "Amy Zhang",
        "Dean Foster",
        "Emma Brunskill",
        "Lyle Ungar"
      ],
      "abstract": "Large language models (LLMs) built on existing reinforcement learning with human feedback (RLHF) frameworks typically optimize responses based on immediate turn-level human preferences. However, this approach falls short in multi-turn dialogue settings, such as online math tutoring. We propose a method to enhance LLM-based tutors by representing the dialogue history with a lower-dimensional latent state representation of a student and optimizing a long-term policy to determine high-level actions based on the latent state. The goal is to better align the tutor's behavior with the long-term objective of guiding the student towards solving a target math problem on their own. Our model is lightweight, requiring less computational resources than prior work of training the tutor policy end-to-end to directly output the tutor's next utterance. Our experiment results demonstrate that these modifications lead to improved long-term outcomes compared to prompting in LLM-simulated tutoring tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å¯¹è¯ç³»ç»Ÿåœ¨å¤šè½®æ•°å­¦è¾…åŠ©æ•™å­¦ä¸­é¢ä¸´çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªé«˜æ•ˆçš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ã€‚ç°æœ‰çš„RLHFæ¡†æ¶é€šå¸¸ä»…ä¼˜åŒ–å•è½®å¯¹è¯åå¥½ï¼Œè€Œè¯¥æ–¹æ³•é€šè¿‡å¼•å…¥å­¦ç”ŸçŠ¶æ€çš„ä½ç»´æ½œçŠ¶æ€è¡¨ç¤º(latent state representation)ï¼Œå¹¶ä»¥æ­¤ä¼˜åŒ–é•¿æœŸç­–ç•¥(long-term policy)æ¥ç¡®å®šé«˜å±‚æ¬¡æ•™å­¦åŠ¨ä½œã€‚å…¶æ ¸å¿ƒç›®æ ‡æ˜¯æ›´å¥½åœ°å¼•å¯¼å­¦ç”Ÿè‡ªä¸»è§£å†³ç›®æ ‡æ•°å­¦é—®é¢˜ï¼Œå®ç°å¯¹è¯å±‚é¢çš„é•¿æœŸç›®æ ‡ä¼˜åŒ–ã€‚ç›¸æ¯”äºç«¯åˆ°ç«¯è®­ç»ƒå¯¼å¸ˆå›å¤çš„ä¼ ç»Ÿæ–¹æ³•ï¼Œè¯¥æ¨¡å‹æ›´ä¸ºè½»é‡åŒ–ï¼Œæ˜¾è‘—é™ä½äº†è®¡ç®—èµ„æºéœ€æ±‚ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨LLMæ¨¡æ‹Ÿçš„è¾…å¯¼ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”äºå•çº¯çš„æç¤ºè¯(prompting)æ–¹æ³•æ˜¾è‘—æå‡äº†å¯¹è¯çš„é•¿æœŸæ•ˆæœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "https://arxiv.org/pdf/2507.16252v1",
      "published_date": "2025-07-22 05:56:46 UTC",
      "updated_date": "2025-07-22 05:56:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:10.730407+00:00"
    },
    {
      "arxiv_id": "2507.16251v1",
      "title": "HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery",
      "title_zh": "HoliTracerï¼šå¤§å°ºå¯¸é¥æ„Ÿå½±åƒåœ°ç†ç›®æ ‡çš„æ•´ä½“çŸ¢é‡åŒ–",
      "authors": [
        "Yu Wang",
        "Bo Dang",
        "Wanchun Li",
        "Wei Chen",
        "Yansheng Li"
      ],
      "abstract": "With the increasing resolution of remote sensing imagery (RSI), large-size RSI has emerged as a vital data source for high-precision vector mapping of geographic objects. Existing methods are typically constrained to processing small image patches, which often leads to the loss of contextual information and produces fragmented vector outputs. To address these, this paper introduces HoliTracer, the first framework designed to holistically extract vectorized geographic objects from large-size RSI. In HoliTracer, we enhance segmentation of large-size RSI using the Context Attention Net (CAN), which employs a local-to-global attention mechanism to capture contextual dependencies. Furthermore, we achieve holistic vectorization through a robust pipeline that leverages the Mask Contour Reformer (MCR) to reconstruct polygons and the Polygon Sequence Tracer (PST) to trace vertices. Extensive experiments on large-size RSI datasets, including buildings, water bodies, and roads, demonstrate that HoliTracer outperforms state-of-the-art methods. Our code and data are available in https://github.com/vvangfaye/HoliTracer.",
      "tldr_zh": "éšç€é¥æ„Ÿå½±åƒ(RSI)åˆ†è¾¨ç‡çš„æå‡ï¼Œå¤§å°ºå¯¸å½±åƒå·²æˆä¸ºåœ°ç†å¯¹è±¡é«˜ç²¾åº¦çŸ¢é‡ç»˜å›¾çš„é‡è¦æ•°æ®æºï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸å—é™äºå¤„ç†å°å›¾åƒå—ï¼Œå¯¼è‡´ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸¢å¤±åŠçŸ¢é‡è¾“å‡ºç¢ç‰‡åŒ–ã€‚æœ¬ç ”ç©¶æå‡ºäº†HoliTracerï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ—¨åœ¨ä»å¤§å°ºå¯¸RSIä¸­æ•´ä½“æå–çŸ¢é‡åŒ–åœ°ç†å¯¹è±¡çš„æ¡†æ¶ã€‚HoliTraceråˆ©ç”¨Context Attention Net (CAN)å¢å¼ºå¤§å°ºå¯¸å½±åƒçš„åˆ†å‰²æ•ˆæœï¼Œé€šè¿‡å±€éƒ¨åˆ°å…¨å±€çš„æ³¨æ„åŠ›æœºåˆ¶æ•æ‰ä¸Šä¸‹æ–‡ä¾èµ–å…³ç³»ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡åŒ…å«Mask Contour Reformer (MCR)é‡å»ºå¤šè¾¹å½¢å’ŒPolygon Sequence Tracer (PST)è¿½è¸ªé¡¶ç‚¹çš„é²æ£’æµæ°´çº¿ï¼Œå®ç°äº†é«˜æ•ˆçš„æ•´ä½“çŸ¢é‡åŒ–ã€‚åœ¨å»ºç­‘ã€æ°´ä½“å’Œé“è·¯ç­‰å¤§å°ºå¯¸RSIæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒHoliTracerçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚è¯¥ç ”ç©¶ä¸ºå¤§è§„æ¨¡é¥æ„Ÿæ•°æ®çš„è‡ªåŠ¨åŒ–çŸ¢é‡æ˜ å°„æä¾›äº†å…·æœ‰ä¸€è‡´æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16251v1",
      "published_date": "2025-07-22 05:55:00 UTC",
      "updated_date": "2025-07-22 05:55:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:16.411191+00:00"
    },
    {
      "arxiv_id": "2507.16247v1",
      "title": "PRAC3 (Privacy, Reputation, Accountability, Consent, Credit, Compensation): Long Tailed Risks of Voice Actors in AI Data-Economy",
      "title_zh": "PRAC3ï¼ˆéšç§ã€å£°èª‰ã€é—®è´£ã€åŒæ„ã€ç½²åã€æŠ¥é…¬ï¼‰ï¼šäººå·¥æ™ºèƒ½æ•°æ®ç»æµä¸­é…éŸ³æ¼”å‘˜çš„é•¿å°¾é£é™©",
      "authors": [
        "Tanusree Sharma",
        "Yihao Zhou",
        "Visar Berisha"
      ],
      "abstract": "Early large-scale audio datasets, such as LibriSpeech, were built with hundreds of individual contributors whose voices were instrumental in the development of speech technologies, including audiobooks and voice assistants. Yet, a decade later, these same contributions have exposed voice actors to a range of risks. While existing ethical frameworks emphasize Consent, Credit, and Compensation (C3), they do not adequately address the emergent risks involving vocal identities that are increasingly decoupled from context, authorship, and control. Drawing on qualitative interviews with 20 professional voice actors, this paper reveals how the synthetic replication of voice without enforceable constraints exposes individuals to a range of threats. Beyond reputational harm, such as re-purposing voice data in erotic content, offensive political messaging, and meme culture, we document concerns about accountability breakdowns when their voice is leveraged to clone voices that are deployed in high-stakes scenarios such as financial fraud, misinformation campaigns, or impersonation scams. In such cases, actors face social and legal fallout without recourse, while very few of them have a legal representative or union protection. To make sense of these shifting dynamics, we introduce the PRAC3 framework, an expansion of C3 that foregrounds Privacy, Reputation, Accountability, Consent, Credit, and Compensation as interdependent pillars of data used in the synthetic voice economy. This framework captures how privacy risks are amplified through non-consensual training, how reputational harm arises from decontextualized deployment, and how accountability can be reimagined AI Data ecosystems. We argue that voice, as both a biometric identifier and creative labor, demands governance models that restore creator agency, ensure traceability, and establish enforceable boundaries for ethical reuse.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ AI æ•°æ®ç»æµèƒŒæ™¯ä¸‹ï¼ŒLibriSpeech ç­‰æ—©æœŸè¯­éŸ³æ•°æ®é›†å¦‚ä½•ä½¿é…éŸ³æ¼”å‘˜é¢ä¸´ç”±è¯­éŸ³åˆæˆæŠ€æœ¯å¼•å‘çš„é•¿å°¾é£é™©ã€‚é€šè¿‡å¯¹ 20 åä¸“ä¸šé…éŸ³æ¼”å‘˜çš„å®šæ€§è®¿è°ˆ (Qualitative interviews)ï¼Œç ”ç©¶æ­ç¤ºäº†è¯­éŸ³åœ¨ç¼ºä¹çº¦æŸçš„æƒ…å†µä¸‹è¢«ç”¨äºæˆäººå†…å®¹ã€æ”¿æ²»å®£ä¼ ã€é‡‘èæ¬ºè¯ˆæˆ–å†’å……è¯ˆéª—ç­‰é«˜é£é™©åœºæ™¯ï¼Œå¯¼è‡´æ¼”å‘˜åœ¨ç¼ºä¹æ³•å¾‹å’Œå·¥ä¼šä¿æŠ¤çš„æƒ…å†µä¸‹æ‰¿å—åèª‰å—æŸå’Œ Accountability ç¼ºå¤±ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº† PRAC3 æ¡†æ¶ï¼Œåœ¨ç°æœ‰çš„ Consentã€Credit å’Œ Compensation (C3) åŸºç¡€ä¸Šï¼Œå°† Privacyã€Reputation å’Œ Accountability çº³å…¥æ ¸å¿ƒæ”¯æŸ±ï¼Œä»¥åº”å¯¹è¯­éŸ³èº«ä»½ä¸åˆ›ä½œè€…è„±ç¦»åçš„ä¼¦ç†æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶è¯¦ç»†åˆ†æäº†éè‡ªæ„¿è®­ç»ƒå¦‚ä½•åŠ å‰§ Privacy é£é™©ï¼Œä»¥åŠå»è¯­å¢ƒåŒ–éƒ¨ç½²å¯¹å£°èª‰çš„å½±å“ã€‚æœ€åï¼Œç ”ç©¶å¼ºè°ƒè¯­éŸ³å…¼å…·ç”Ÿç‰©è¯†åˆ«ç‰¹å¾å’Œåˆ›æ„åŠ³åŠ¨å±æ€§ï¼Œå‘¼åå»ºç«‹èƒ½å¤Ÿæ¢å¤åˆ›ä½œè€…ä»£ç†æƒã€ç¡®ä¿ Traceability å¹¶åˆ¶å®šå¯æ‰§è¡Œè¾¹ç•Œçš„æ²»ç†æ¨¡å‹ï¼Œä»¥ä¿éšœåˆæˆè¯­éŸ³ç»æµä¸­çš„ä¼¦ç†é‡ç”¨ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16247v1",
      "published_date": "2025-07-22 05:39:39 UTC",
      "updated_date": "2025-07-22 05:39:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:39.385914+00:00"
    },
    {
      "arxiv_id": "2507.16241v1",
      "title": "eX-NIDS: A Framework for Explainable Network Intrusion Detection Leveraging Large Language Models",
      "title_zh": "eX-NIDSï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šç½‘ç»œå…¥ä¾µæ£€æµ‹æ¡†æ¶",
      "authors": [
        "Paul R. B. Houssel",
        "Siamak Layeghy",
        "Priyanka Singh",
        "Marius Portmann"
      ],
      "abstract": "This paper introduces eX-NIDS, a framework designed to enhance interpretability in flow-based Network Intrusion Detection Systems (NIDS) by leveraging Large Language Models (LLMs). In our proposed framework, flows labelled as malicious by NIDS are initially processed through a module called the Prompt Augmenter. This module extracts contextual information and Cyber Threat Intelligence (CTI)-related knowledge from these flows. This enriched, context-specific data is then integrated with an input prompt for an LLM, enabling it to generate detailed explanations and interpretations of why the flow was identified as malicious by NIDS. We compare the generated interpretations against a Basic-Prompt Explainer baseline, which does not incorporate any contextual information into the LLM's input prompt. Our framework is quantitatively evaluated using the Llama 3 and GPT-4 models, employing a novel evaluation method tailored for natural language explanations, focusing on their correctness and consistency. The results demonstrate that augmented LLMs can produce accurate and consistent explanations, serving as valuable complementary tools in NIDS to explain the classification of malicious flows. The use of augmented prompts enhances performance by over 20% compared to the Basic-Prompt Explainer.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† eX-NIDSï¼Œè¿™æ˜¯ä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) å¢å¼ºåŸºäºæµçš„ç½‘ç»œå…¥ä¾µæ£€æµ‹ç³»ç»Ÿ (Network Intrusion Detection Systems, NIDS) å¯è§£é‡Šæ€§çš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡ Prompt Augmenter æ¨¡å—ä»æ¶æ„æµä¸­æå–ä¸Šä¸‹æ–‡ä¿¡æ¯å’Œç½‘ç»œå¨èƒæƒ…æŠ¥ (Cyber Threat Intelligence, CTI)ï¼Œå¹¶å°†å…¶ä¸è¾“å…¥æç¤ºè¯é›†æˆï¼Œä½¿ LLM èƒ½å¤Ÿé’ˆå¯¹æ£€æµ‹ç»“æœç”Ÿæˆè¯¦ç»†çš„è§£é‡Šã€‚ç ”ç©¶äººå‘˜åœ¨ Llama 3 å’Œ GPT-4 æ¨¡å‹ä¸Šè¿›è¡Œäº†å®éªŒï¼Œå¹¶é‡‡ç”¨äº†ä¸€ç§é’ˆå¯¹è‡ªç„¶è¯­è¨€è§£é‡Šå‡†ç¡®æ€§å’Œä¸€è‡´æ€§çš„æ–°è¯„ä¼°æ–¹æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸ä¸åŒ…å«ä¸Šä¸‹æ–‡ä¿¡æ¯çš„ Basic-Prompt Explainer åŸºçº¿ç›¸æ¯”ï¼Œå¢å¼ºåçš„æç¤ºè¯å°†è§£é‡Šæ€§èƒ½æå‡äº† 20% ä»¥ä¸Šã€‚eX-NIDS è¯æ˜äº†å¢å¼ºå‹ LLMs èƒ½å¤Ÿäº§ç”Ÿå‡†ç¡®ä¸”ä¸€è‡´çš„è§£é‡Šï¼Œæ˜¯ NIDS åˆ†ç±»æ¶æ„æµé‡çš„é‡è¦è¡¥å……å·¥å…·ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16241v1",
      "published_date": "2025-07-22 05:26:21 UTC",
      "updated_date": "2025-07-22 05:26:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:37.033688+00:00"
    },
    {
      "arxiv_id": "2507.16229v1",
      "title": "Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery",
      "title_zh": "è¯­éŸ³ AI æ™ºèƒ½ä½“ï¼šå¼¥åˆæ•°å­—åŒ»ç–—æœåŠ¡ä¸­çš„ç»æµå·®è·",
      "authors": [
        "Bo Wen",
        "Chen Wang",
        "Qiwei Han",
        "Raquel Norel",
        "Julia Liu",
        "Thaddeus Stappenbeck",
        "Jeffrey L. Rogers"
      ],
      "abstract": "The integration of voice-based AI agents in healthcare presents a transformative opportunity to bridge economic and accessibility gaps in digital health delivery. This paper explores the role of large language model (LLM)-powered voice assistants in enhancing preventive care and continuous patient monitoring, particularly in underserved populations. Drawing insights from the development and pilot study of Agent PULSE (Patient Understanding and Liaison Support Engine) -- a collaborative initiative between IBM Research, Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an economic model demonstrating how AI agents can provide cost-effective healthcare services where human intervention is economically unfeasible. Our pilot study with 33 inflammatory bowel disease patients revealed that 70\\% expressed acceptance of AI-driven monitoring, with 37\\% preferring it over traditional modalities. Technical challenges, including real-time conversational AI processing, integration with healthcare systems, and privacy compliance, are analyzed alongside policy considerations surrounding regulation, bias mitigation, and patient autonomy. Our findings suggest that AI-driven voice agents not only enhance healthcare scalability and efficiency but also improve patient engagement and accessibility. For healthcare executives, our cost-utility analysis demonstrates huge potential savings for routine monitoring tasks, while technologists can leverage our framework to prioritize improvements yielding the highest patient impact. By addressing current limitations and aligning AI development with ethical and regulatory frameworks, voice-based AI agents can serve as a critical entry point for equitable, sustainable digital healthcare solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)é©±åŠ¨çš„è¯­éŸ³AIæ™ºèƒ½ä½“åœ¨é¢„é˜²æ€§æŠ¤ç†å’ŒæŒç»­æ‚£è€…ç›‘æµ‹ä¸­çš„ä½œç”¨ï¼Œæ—¨åœ¨å¼¥è¡¥æ•°å­—å¥åº·äº¤ä»˜ä¸­çš„ç»æµå’Œå¯åŠæ€§å·®è·ã€‚é€šè¿‡ä»‹ç»ç”±IBMç ”ç©¶é™¢ç­‰æœºæ„åˆä½œå¼€å‘çš„Agent PULSEï¼ˆPatient Understanding and Liaison Support Engineï¼‰ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»æµæ¨¡å‹ï¼Œè¯æ˜AIæ™ºèƒ½ä½“èƒ½åœ¨äººåŠ›æˆæœ¬è¿‡é«˜çš„åœºæ™¯ä¸‹æä¾›é«˜æ€§ä»·æ¯”çš„åŒ»ç–—æœåŠ¡ã€‚é’ˆå¯¹33åç‚ç—‡æ€§è‚ ç—…(IBD)æ‚£è€…çš„åˆæ­¥ç ”ç©¶æ˜¾ç¤ºï¼Œ70%çš„æ‚£è€…æ¥å—AIé©±åŠ¨çš„ç›‘æµ‹ï¼Œå…¶ä¸­37%çš„æ‚£è€…æ›´å€¾å‘äºé€‰æ‹©è¯¥æ–¹å¼è€Œéä¼ ç»Ÿæ¨¡å¼ã€‚æ–‡ç« æ·±å…¥åˆ†æäº†å®æ—¶å¯¹è¯å¼AIå¤„ç†ã€åŒ»ç–—ç³»ç»Ÿé›†æˆåŠéšç§åˆè§„ç­‰æŠ€æœ¯æŒ‘æˆ˜ï¼Œå¹¶æ¢è®¨äº†ç›‘ç®¡ã€åè§ç¼“è§£(bias mitigation)ç­‰æ”¿ç­–è€ƒé‡ã€‚æˆæœ¬æ•ˆç”¨åˆ†æ(cost-utility analysis)è¡¨æ˜ï¼ŒAIæ™ºèƒ½ä½“åœ¨å¸¸è§„ç›‘æµ‹ä»»åŠ¡ä¸­å…·æœ‰å·¨å¤§çš„æˆæœ¬èŠ‚çº¦æ½œåŠ›ï¼Œèƒ½æœ‰æ•ˆæå‡åŒ»ç–—æœåŠ¡çš„æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚é€šè¿‡å°†AIå¼€å‘ä¸ä¼¦ç†å’Œç›‘ç®¡æ¡†æ¶ç›¸ç»“åˆï¼ŒåŸºäºè¯­éŸ³çš„AIæ™ºèƒ½ä½“å¯ä½œä¸ºå®ç°å…¬å¹³ã€å¯æŒç»­æ•°å­—åŒ»ç–—è§£å†³æ–¹æ¡ˆçš„å…³é”®åˆ‡å…¥ç‚¹ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE International Conference on Digital Health (ICDH) 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16229v1",
      "published_date": "2025-07-22 05:01:06 UTC",
      "updated_date": "2025-07-22 05:01:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:27.208989+00:00"
    },
    {
      "arxiv_id": "2507.16227v1",
      "title": "Predictive Hydrodynamic Simulations for Laser Direct-drive Implosion Experiments via Artificial Intelligence",
      "title_zh": "åŸºäºäººå·¥æ™ºèƒ½çš„æ¿€å…‰ç›´æ¥é©±åŠ¨å†…çˆ†å®éªŒé¢„æµ‹æ€§æµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿ",
      "authors": [
        "Zixu Wang",
        "Yuhan Wang",
        "Junfei Ma",
        "Fuyuan Wu",
        "Junchi Yan",
        "Xiaohui Yuan",
        "Zhe Zhang",
        "Jie Zhang"
      ],
      "abstract": "This work presents predictive hydrodynamic simulations empowered by artificial intelligence (AI) for laser driven implosion experiments, taking the double-cone ignition (DCI) scheme as an example. A Transformer-based deep learning model MULTI-Net is established to predict implosion features according to laser waveforms and target radius. A Physics-Informed Decoder (PID) is proposed for high-dimensional sampling, significantly reducing the prediction errors compared to Latin hypercube sampling. Applied to DCI experiments conducted on the SG-II Upgrade facility, the MULTI-Net model is able to predict the implosion dynamics measured by the x-ray streak camera. It is found that an effective laser absorption factor about 65\\% is suitable for the one-dimensional simulations of the DCI-R10 experiments. For shot 33, the mean implosion velocity and collided plasma density reached 195 km/s and 117 g/cc, respectively. This study demonstrates a data-driven AI framework that enhances the prediction ability of simulations for complicated laser fusion experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ©ç”¨äººå·¥æ™ºèƒ½(AI)å¢å¼ºæ¿€å…‰ç›´æ¥é©±åŠ¨å†…çˆ†(laser direct-drive implosion)å®éªŒæµä½“åŠ¨åŠ›å­¦æ¨¡æ‹Ÿé¢„æµ‹èƒ½åŠ›çš„æ–¹æ³•ï¼Œå¹¶ä»¥åŒé”¥ç‚¹ç«(double-cone ignition, DCI)æ–¹æ¡ˆä¸ºä¾‹è¿›è¡Œäº†éªŒè¯ã€‚ç ”ç©¶å»ºç«‹äº†ä¸€ä¸ªåŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¨¡å‹MULTI-Netï¼Œèƒ½å¤Ÿæ ¹æ®æ¿€å…‰æ³¢å½¢(laser waveforms)å’Œé¶çƒåŠå¾„(target radius)é¢„æµ‹å†…çˆ†ç‰¹å¾ã€‚ä¸ºäº†æé«˜é¢„æµ‹ç²¾åº¦ï¼Œè¯¥ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§ç‰©ç†å‘ŠçŸ¥è§£ç å™¨(Physics-Informed Decoder, PID)ç”¨äºé«˜ç»´é‡‡æ ·ï¼Œæ˜¾è‘—é™ä½äº†ä¸ä¼ ç»Ÿé‡‡æ ·æ–¹æ³•ç›¸æ¯”çš„è¯¯å·®ã€‚åœ¨ç¥å…‰-IIå‡çº§è£…ç½®(SG-II Upgrade facility)è¿›è¡Œçš„DCIå®éªŒåº”ç”¨ä¸­ï¼Œè¯¥æ¨¡å‹æˆåŠŸé¢„æµ‹äº†Xå°„çº¿æ¡çº¹ç›¸æœºè§‚æµ‹åˆ°çš„å†…çˆ†åŠ¨åŠ›å­¦ã€‚ç ”ç©¶å‘ç°ï¼Œçº¦65%çš„æœ‰æ•ˆæ¿€å…‰å¸æ”¶å› å­(effective laser absorption factor)é€‚ç”¨äºDCI-R10å®éªŒçš„ä¸€ç»´æ¨¡æ‹Ÿã€‚å®éªŒæ•°æ®æ˜¾ç¤ºï¼Œç‰¹å®šå®éªŒå‘æ¬¡ä¸­çš„å¹³å‡å†…çˆ†é€Ÿåº¦å’Œç¢°æ’ç­‰ç¦»å­ä½“å¯†åº¦åˆ†åˆ«è¾¾åˆ°äº†195 km/så’Œ117 g/ccã€‚è¿™ä¸€æ•°æ®é©±åŠ¨çš„AIæ¡†æ¶æœ‰æ•ˆæå‡äº†å¤æ‚æ¿€å…‰èšå˜å®éªŒæ¨¡æ‹Ÿçš„é¢„æµ‹å‡†ç¡®æ€§ã€‚",
      "categories": [
        "physics.plasm-ph",
        "cs.AI"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "7 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16227v1",
      "published_date": "2025-07-22 04:57:40 UTC",
      "updated_date": "2025-07-22 04:57:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:29.983223+00:00"
    },
    {
      "arxiv_id": "2507.16226v1",
      "title": "Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design",
      "title_zh": "é¢å‘ç‰‡ä¸Šç³»ç»Ÿè®¾è®¡çš„æœºå¯†è®¡ç®—ç¯å¢ƒä¸‹çš„è’¸é¦å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Dong Ben",
        "Hui Feng",
        "Qian Wang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in circuit design tasks and have typically undergone multiple rounds of training. Both the trained models and their associated training data are considered confidential intellectual property (IP) and must be protected from exposure. Confidential Computing offers a promising solution to protect data and models through Trusted Execution Environments (TEEs). However, existing TEE implementations are not designed to support the resource-intensive nature of LLMs efficiently. In this work, we first present a comprehensive evaluation of the LLMs within a TEE-enabled confidential computing environment, specifically utilizing Intel Trust Domain Extensions (TDX). We constructed experiments on three environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and evaluated their performance in terms of tokens per second.\n  Our first observation is that distilled models, i.e., DeepSeek, surpass other models in performance due to their smaller parameters, making them suitable for resource-constrained devices. Also, in the quantized models such as 4-bit quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain of up to 3x compared to FP16 models. Our findings indicate that for fewer parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms the CPU version in executing computations within a secure environment. We further validate the results using a testbench designed for SoC design tasks. These validations demonstrate the potential of efficiently deploying lightweight LLMs on resource-constrained systems for semiconductor CAD applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æœºå¯†è®¡ç®—(Confidential Computing)ç¯å¢ƒä¸‹éƒ¨ç½²å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»¥ä¿æŠ¤èŠ¯ç‰‡è®¾è®¡(SoC Design)ä¸­çš„å…³é”®çŸ¥è¯†äº§æƒ(IP)ã€‚ä½œè€…åˆ©ç”¨Intel Trust Domain Extensions (TDX)æ„å»ºäº†å¯ä¿¡æ‰§è¡Œç¯å¢ƒ(TEE)ï¼Œå¹¶å¯¹æ¯”è¯„ä¼°äº†åŸºäºTEEã€çº¯CPUä»¥åŠCPU-GPUæ··åˆå®ç°åœ¨å¤„ç†é€Ÿåº¦ä¸Šçš„è¡¨ç°ã€‚å®éªŒå‘ç°ï¼Œè’¸é¦æ¨¡å‹(Distilled Models)å¦‚DeepSeekå› å…¶è¾ƒå°çš„å‚æ•°é‡åœ¨èµ„æºå—é™è®¾å¤‡ä¸Šå±•ç°å‡ºæ›´ä¼˜çš„æ€§èƒ½ï¼Œä¸”é‡‡ç”¨4ä½(Q4)æˆ–8ä½(Q8)é‡åŒ–(Quantization)æŠ€æœ¯ç›¸æ¯”FP16æ¨¡å‹å¯å®ç°é«˜è¾¾3å€çš„æ€§èƒ½æå‡ã€‚é’ˆå¯¹DeepSeek-r1-1.5Bç­‰ä½å‚æ•°æ¨¡å‹ï¼ŒTDXå®ç°åœ¨å®‰å…¨ç¯å¢ƒä¸‹æ‰§è¡Œè®¡ç®—çš„æ•ˆç‡ç”šè‡³ä¼˜äºæ ‡å‡†CPUç‰ˆæœ¬ã€‚é€šè¿‡é’ˆå¯¹SoCè®¾è®¡ä»»åŠ¡çš„æµ‹è¯•å¹³å°éªŒè¯ï¼Œè¯¥ç ”ç©¶è¯æ˜äº†åœ¨èµ„æºå—é™ç³»ç»Ÿä¸­ä¸ºåŠå¯¼ä½“CADåº”ç”¨é«˜æ•ˆéƒ¨ç½²è½»é‡çº§å¤§è¯­è¨€æ¨¡å‹çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 4 figures;",
      "pdf_url": "https://arxiv.org/pdf/2507.16226v1",
      "published_date": "2025-07-22 04:41:27 UTC",
      "updated_date": "2025-07-22 04:41:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:52.739464+00:00"
    },
    {
      "arxiv_id": "2507.16219v1",
      "title": "Bayesian Deep Learning for Convective Initiation Nowcasting Uncertainty Estimation",
      "title_zh": "é¢å‘å¯¹æµè§¦å‘ä¸´è¿‘é¢„æŠ¥ä¸ç¡®å®šæ€§ä¼°ç®—çš„è´å¶æ–¯æ·±åº¦å­¦ä¹ ",
      "authors": [
        "Da Fan",
        "David John Gagne",
        "Steven J. Greybush",
        "Eugene E. Clothiaux",
        "John S. Schreck",
        "Chaopeng Shen"
      ],
      "abstract": "This study evaluated the probability and uncertainty forecasts of five recently proposed Bayesian deep learning methods relative to a deterministic residual neural network (ResNet) baseline for 0-1 h convective initiation (CI) nowcasting using GOES-16 satellite infrared observations. Uncertainty was assessed by how well probabilistic forecasts were calibrated and how well uncertainty separated forecasts with large and small errors. Most of the Bayesian deep learning methods produced probabilistic forecasts that outperformed the deterministic ResNet, with one, the initial-weights ensemble + Monte Carlo (MC) dropout, an ensemble of deterministic ResNets with different initial weights to start training and dropout activated during inference, producing the most skillful and well-calibrated forecasts. The initial-weights ensemble + MC dropout benefited from generating multiple solutions that more thoroughly sampled the hypothesis space. The Bayesian ResNet ensemble was the only one that performed worse than the deterministic ResNet at longer lead times, likely due to the challenge of optimizing a larger number of parameters. To address this issue, the Bayesian-MOPED (MOdel Priors with Empirical Bayes using Deep neural network) ResNet ensemble was adopted, and it enhanced forecast skill by constraining the hypothesis search near the deterministic ResNet hypothesis. All Bayesian methods demonstrated well-calibrated uncertainty and effectively separated cases with large and small errors. In case studies, the initial-weights ensemble + MC dropout demonstrated better forecast skill than the Bayesian-MOPED ensemble and the deterministic ResNet on selected CI events in clear-sky regions. However, the initial-weights ensemble + MC dropout exhibited poorer generalization in clear-sky and anvil cloud regions without CI occurrence compared to the deterministic ResNet and Bayesian-MOPED ensemble.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†äº”ç§æœ€è¿‘æå‡ºçš„è´å¶æ–¯æ·±åº¦å­¦ä¹  (Bayesian deep learning) æ–¹æ³•åœ¨ 0-1 å°æ—¶å¯¹æµèµ·å§‹ (Convective Initiation, CI) ä¸´è¿‘é¢„æŠ¥ä¸­çš„ä¸ç¡®å®šæ€§ä¼°è®¡è¡¨ç°ã€‚é€šè¿‡åˆ©ç”¨ GOES-16 å«æ˜Ÿçº¢å¤–è§‚æµ‹æ•°æ®ï¼Œç ”ç©¶å¯¹æ¯”äº†è¿™äº›æ–¹æ³•ä¸ç¡®å®šæ€§æ®‹å·®ç½‘ç»œ (ResNet) åŸºå‡†çš„é¢„æŠ¥å‡†ç¡®æ€§ä¸ä¸ç¡®å®šæ€§æ ¡å‡†èƒ½åŠ›ã€‚å®éªŒå‘ç°å¤§å¤šæ•°è´å¶æ–¯æ–¹æ³•ä¼˜äºç¡®å®šæ€§ ResNetï¼Œå…¶ä¸­åˆå§‹æƒé‡é›†æˆç»“åˆè’™ç‰¹å¡æ´›éšæœºå¤±æ´» (initial-weights ensemble + MC dropout) å‡­å€Ÿå¯¹å‡è®¾ç©ºé—´çš„å……åˆ†é‡‡æ ·ï¼Œäº§ç”Ÿäº†æœ€ç²¾ç¡®ä¸”æ ¡å‡†è‰¯å¥½çš„æ¦‚ç‡é¢„æŠ¥ã€‚é’ˆå¯¹å¤§è§„æ¨¡å‚æ•°ä¼˜åŒ–æŒ‘æˆ˜ï¼Œç ”ç©¶é‡‡ç”¨ Bayesian-MOPED æ¡†æ¶çº¦æŸå‡è®¾æœç´¢ï¼Œæ˜¾è‘—æå‡äº†è´å¶æ–¯é›†æˆæ¨¡å‹çš„é¢„æŠ¥æŠ€å·§ã€‚ç»“æœè¡¨æ˜æ‰€æœ‰è´å¶æ–¯æ–¹æ³•å‡èƒ½æœ‰æ•ˆåŒºåˆ†é«˜è¯¯å·®ä¸ä½è¯¯å·®æ¡ˆä¾‹ï¼Œè¯æ˜äº†å…¶åœ¨æ°”è±¡ä¸´è¿‘é¢„æŠ¥ä¸ç¡®å®šæ€§é‡åŒ–ä¸­çš„åº”ç”¨æ½œåŠ›ã€‚è™½ç„¶æœ€ä½³é›†æˆæ¨¡å‹åœ¨ç‰¹å®šæ™´ç©ºåŒºåŸŸçš„æ³›åŒ–èƒ½åŠ›ç¨å¼±ï¼Œä½†å…¶åœ¨ CI äº‹ä»¶ä¸­çš„å“è¶Šè¡¨ç°ä¸ºæ„å»ºå¯é çš„ç¾å®³å¤©æ°”é¢„è­¦ç³»ç»Ÿæä¾›äº†æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16219v1",
      "published_date": "2025-07-22 04:29:53 UTC",
      "updated_date": "2025-07-22 04:29:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:02.283971+00:00"
    },
    {
      "arxiv_id": "2507.17774v1",
      "title": "Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems",
      "title_zh": "äººæœºå…±åˆ›ï¼šæ™ºèƒ½ç³»ç»Ÿä¸­çš„åä½œè®¾è®¡æ¡†æ¶",
      "authors": [
        "Zhangqi Liu"
      ],
      "abstract": "As artificial intelligence (AI) continues to evolve from a back-end computational tool into an interactive, generative collaborator, its integration into early-stage design processes demands a rethinking of traditional workflows in human-centered design. This paper explores the emergent paradigm of human-AI co-creation, where AI is not merely used for automation or efficiency gains, but actively participates in ideation, visual conceptualization, and decision-making. Specifically, we investigate the use of large language models (LLMs) like GPT-4 and multimodal diffusion models such as Stable Diffusion as creative agents that engage designers in iterative cycles of proposal, critique, and revision.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½ä»åç«¯è®¡ç®—å·¥å…·å‘äº¤äº’å¼ç”Ÿæˆåä½œä¼™ä¼´æ¼”å˜çš„è¶‹åŠ¿ï¼Œæå‡ºäº† Human-AI Co-Creation æ¡†æ¶ï¼Œæ—¨åœ¨é‡æ–°æ€è€ƒä»¥äººä¸ºæœ¬è®¾è®¡ä¸­çš„ä¼ ç»Ÿå·¥ä½œæµç¨‹ã€‚æ–‡ç« é‡ç‚¹ç ”ç©¶äº† AI å¦‚ä½•åœ¨åˆ›æ„æ„æ€ã€è§†è§‰æ¦‚å¿µåŒ–å’Œå†³ç­–åˆ¶å®šä¸­å‘æŒ¥ç§¯æä½œç”¨ï¼Œè€Œéä»…ä»…ç”¨äºæå‡è‡ªåŠ¨åŒ–æ•ˆç‡ã€‚ç ”ç©¶æ·±å…¥è°ƒæŸ¥äº† Large Language Models (LLMs)ï¼ˆå¦‚ GPT-4ï¼‰å’Œå¤šæ¨¡æ€æ‰©æ•£æ¨¡å‹ï¼ˆå¦‚ Stable Diffusionï¼‰ä½œä¸ºåˆ›æ„æ™ºèƒ½ä½“çš„åº”ç”¨æ½œåŠ›ã€‚è¿™äº›æ¨¡å‹èƒ½å¤Ÿä½¿è®¾è®¡è€…è¿›å…¥ä¸€ä¸ªåŒ…å«ææ¡ˆã€è¯„ä»·å’Œä¿®è®¢çš„è¿­ä»£åä½œå¾ªç¯ã€‚é€šè¿‡è¿™ç§åä½œè®¾è®¡èŒƒå¼ï¼ŒAI èƒ½å¤Ÿæ·±åº¦å‚ä¸æ™ºèƒ½ç³»ç»Ÿçš„æ—©æœŸè®¾è®¡è¿‡ç¨‹ï¼Œä¸ºäººç±»ä¸ AI çš„å…±åŒåˆ›é€ æä¾›äº†ç³»ç»Ÿæ€§çš„æ–¹æ³•è®ºã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.17774v1",
      "published_date": "2025-07-22 04:29:33 UTC",
      "updated_date": "2025-07-22 04:29:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:18:59.885158+00:00"
    },
    {
      "arxiv_id": "2507.16217v2",
      "title": "Towards Compute-Optimal Many-Shot In-Context Learning",
      "title_zh": "è¿ˆå‘è®¡ç®—æœ€ä¼˜çš„å¤šç¤ºä¾‹ä¸Šä¸‹æ–‡å­¦ä¹ ",
      "authors": [
        "Shahriar Golchin",
        "Yanfei Chen",
        "Rujun Han",
        "Manan Gandhi",
        "Tianli Yu",
        "Swaroop Mishra",
        "Mihai Surdeanu",
        "Rishabh Agarwal",
        "Chen-Yu Lee",
        "Tomas Pfister"
      ],
      "abstract": "Long-context large language models (LLMs) are able to process inputs containing up to several million tokens. In the scope of in-context learning (ICL), this translates into using hundreds/thousands of demonstrations in the input prompt, enabling many-shot ICL. In practice, a fixed set of demonstrations is often selected at random in many-shot settings due to (1) high inference costs, (2) the benefits of caching and reusing computations, and (3) the similar performance offered by this strategy compared to others when scaled. In this work, we propose two straightforward strategies for demonstration selection in many-shot ICL that improve performance with minimal computational overhead. Our first method combines a small number of demonstrations, selected based on their similarity to each test sample, with a disproportionately larger set of random demonstrations that are cached. The second strategy improves the first by replacing random demonstrations with those selected using centroids derived from test sample representations via k-means clustering. Our experiments with Gemini Pro and Flash across several datasets indicate that our strategies consistently outperform random selection and surpass or match the most performant selection approach while supporting caching and reducing inference cost by up to an order of magnitude. We also show that adjusting the proportion of demonstrations selected based on different criteria can balance performance and inference cost in many-shot ICL.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨é•¿ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹(LLMs)èƒŒæ™¯ä¸‹å¦‚ä½•å®ç°è®¡ç®—æœ€ä¼˜çš„ Many-shot In-Context Learning (ICL)ï¼Œé’ˆå¯¹ä¼ ç»Ÿéšæœºé€‰æ‹©ç¤ºä¾‹ç­–ç•¥åœ¨æ¨ç†æˆæœ¬ä¸æ€§èƒ½ä¸Šçš„å±€é™æ€§æå‡ºäº†æ”¹è¿›æ–¹æ¡ˆã€‚ä½œè€…æå‡ºäº†ä¸¤ç§ç®€æ´æœ‰æ•ˆçš„ç¤ºä¾‹é€‰æ‹©ç­–ç•¥ï¼šç¬¬ä¸€ç§ç»“åˆäº†å°‘é‡åŸºäºç›¸ä¼¼åº¦é€‰æ‹©çš„ç¤ºä¾‹ä¸å¤§é‡é¢„å…ˆç¼“å­˜çš„éšæœºç¤ºä¾‹ï¼›ç¬¬äºŒç§åˆ™åˆ©ç”¨ k-means èšç±»ç”Ÿæˆçš„è´¨å¿ƒ(centroids)æ¥æ›¿æ¢éšæœºç¤ºä¾‹ï¼Œä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ç¼“å­˜æ•ˆç‡ã€‚åœ¨ Gemini Pro å’Œ Flash æ¨¡å‹ä¸Šçš„å¤šé¡¹å®éªŒè¯æ˜ï¼Œè¿™äº›ç­–ç•¥åœ¨æ€§èƒ½ä¸Šä¼˜äºéšæœºé€‰æ‹©ï¼ŒåŒæ—¶æ”¯æŒè®¡ç®—å¤ç”¨ï¼Œä½¿æ¨ç†æˆæœ¬é™ä½äº†å¤šè¾¾ä¸€ä¸ªæ•°é‡çº§ã€‚é€šè¿‡åŠ¨æ€è°ƒæ•´ä¸åŒé€‰æ‹©æ ‡å‡†ä¸‹çš„ç¤ºä¾‹æ¯”ä¾‹ï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå¹³è¡¡ Many-shot ICL çš„é¢„æµ‹ç²¾åº¦ä¸è®¡ç®—å¼€é”€ï¼Œä¸ºå¤§è§„æ¨¡ä¸Šä¸‹æ–‡å­¦ä¹ æä¾›äº†æ›´é«˜æ•ˆçš„å®ç°è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Final version; accepted at COLM 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16217v2",
      "published_date": "2025-07-22 04:21:03 UTC",
      "updated_date": "2025-08-29 18:45:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:07.887335+00:00"
    },
    {
      "arxiv_id": "2507.16214v2",
      "title": "Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers",
      "title_zh": "é¢å‘å®‰å…¨æ¥è¿‘æœºåŠ¨çš„åŒé‡å™ªå£°è°ƒä¼˜è‡ªé€‚åº”ç›¸å¯¹ä½å§¿ä¼°è®¡æ¡†æ¶",
      "authors": [
        "Batu Candan",
        "Simone Servadio"
      ],
      "abstract": "Accurate and robust relative pose estimation is crucial for enabling challenging Active Debris Removal (ADR) missions targeting tumbling derelict satellites such as ESA's ENVISAT. This work presents a complete pipeline integrating advanced computer vision techniques with adaptive nonlinear filtering to address this challenge. A Convolutional Neural Network (CNN), enhanced with image preprocessing, detects structural markers (corners) from chaser imagery, whose 2D coordinates are converted to 3D measurements using camera modeling. These measurements are fused within an Unscented Kalman Filter (UKF) framework, selected for its ability to handle nonlinear relative dynamics, to estimate the full relative pose. Key contributions include the integrated system architecture and a dual adaptive strategy within the UKF: dynamic tuning of the measurement noise covariance compensates for varying CNN measurement uncertainty, while adaptive tuning of the process noise covariance, utilizing measurement residual analysis, accounts for unmodeled dynamics or maneuvers online. This dual adaptation enhances robustness against both measurement imperfections and dynamic model uncertainties. The performance of the proposed adaptive integrated system is evaluated through high-fidelity simulations using a realistic ENVISAT model, comparing estimates against ground truth under various conditions, including measurement outages. This comprehensive approach offers an enhanced solution for robust onboard relative navigation, significantly advancing the capabilities required for safe proximity operations during ADR missions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¸»åŠ¨ç¢ç‰‡æ¸…ç†ï¼ˆActive Debris Removal, ADRï¼‰ä»»åŠ¡ä¸­å¯¹ç¿»æ»šå¤±æ•ˆå«æ˜Ÿï¼ˆå¦‚ ENVISATï¼‰çš„ç²¾ç¡®å®šä½éœ€æ±‚ï¼Œæå‡ºäº†ä¸€ä¸ªé›†æˆå…ˆè¿›è®¡ç®—æœºè§†è§‰ä¸è‡ªé€‚åº”éçº¿æ€§æ»¤æ³¢çš„å®Œæ•´æ¡†æ¶ã€‚ç³»ç»Ÿé€šè¿‡å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Network, CNNï¼‰æ£€æµ‹ç»“æ„åŒ–ç‰¹å¾ç‚¹ï¼Œå¹¶å°†æå–çš„ 3D æµ‹é‡å€¼è¾“å…¥åˆ°å¤„ç†éçº¿æ€§åŠ¨åŠ›å­¦çš„æ— è¿¹å¡å°”æ›¼æ»¤æ³¢ï¼ˆUnscented Kalman Filter, UKFï¼‰ä¸­ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äº UKF å†…éƒ¨çš„åµŒå¥—åŒé‡è‡ªé€‚åº”ç­–ç•¥ï¼Œå³é€šè¿‡åŠ¨æ€è°ƒèŠ‚æµ‹é‡å™ªå£°åæ–¹å·®æ¥è¡¥å¿ CNN çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶åˆ©ç”¨æ®‹å·®åˆ†æè°ƒæ•´è¿‡ç¨‹å™ªå£°åæ–¹å·®ä»¥åº”å¯¹æœªå»ºæ¨¡çš„åŠ¨åŠ›å­¦å¹²æ‰°ã€‚åœ¨é«˜ä¿çœŸä»¿çœŸç¯å¢ƒä¸‹çš„æµ‹è¯•è¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨æµ‹é‡ä¸­æ–­ç­‰å¤æ‚å·¥å†µä¸‹ä»èƒ½ä¿æŒé«˜é²æ£’æ€§çš„ç›¸å¯¹ä½å§¿ä¼°è®¡ã€‚è¿™é¡¹å·¥ä½œä¸º ADR ä»»åŠ¡ä¸­çš„å®‰å…¨è¿‘è·ç¦»æœºåŠ¨å’Œæœºè½½è‡ªä¸»ç›¸å¯¹å¯¼èˆªæä¾›äº†æ˜¾è‘—çš„æŠ€æœ¯æå‡ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16214v2",
      "published_date": "2025-07-22 04:13:03 UTC",
      "updated_date": "2025-07-24 04:02:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:14.085302+00:00"
    },
    {
      "arxiv_id": "2507.16213v1",
      "title": "Advancing Visual Large Language Model for Multi-granular Versatile Perception",
      "title_zh": "æ¨è¿›é¢å‘å¤šç²’åº¦é€šç”¨æ„ŸçŸ¥çš„è§†è§‰å¤§è¯­è¨€æ¨¡å‹",
      "authors": [
        "Wentao Xiang",
        "Haoxian Tan",
        "Cong Wei",
        "Yujie Zhong",
        "Dengjie Li",
        "Yujiu Yang"
      ],
      "abstract": "Perception is a fundamental task in the field of computer vision, encompassing a diverse set of subtasks that can be systematically categorized into four distinct groups based on two dimensions: prediction type and instruction type. Notably, existing researches often focus solely on a limited subset of these potential combinations, which constrains their applicability and versatility across various contexts. In response to this challenge, we present MVP-LM, a Multi-granular and Versatile Perception framework incorporating Visual Large Language Model. Our framework is designed to integrate both word-based and sentence-based perception tasks alongside box and mask predictions within a single architecture. MVP-LM features an innovative multi-granularity decoder in conjunction with a CoT-inspired dataset unification strategy, enabling seamless supervised fine-tuning across a wide spectrum of tasks, including but not limited to panoptic segmentation, detection, grounding, and referring expression segmentation. Furthermore, we introduce a query enhancement strategy aimed at harnessing the decoding and generative capabilities inherent in VLLMs. Extensive experiments conducted across a range of benchmarks in both word-based and sentence-based perception tasks substantiate the efficacy of our framework. The code will be available at https://github.com/xiangwentao666/MVP-LM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MVP-LMï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å®ç°å¤šç²’åº¦ã€å¤šåŠŸèƒ½æ„ŸçŸ¥(Multi-granular and Versatile Perception)çš„è§†è§‰å¤§è¯­è¨€æ¨¡å‹(Visual Large Language Model)æ¡†æ¶ã€‚ä¸ºäº†è§£å†³ç°æœ‰ç ”ç©¶ä»…å…³æ³¨æ„ŸçŸ¥ä»»åŠ¡å­é›†è€Œå¯¼è‡´çš„é€šç”¨æ€§é™åˆ¶ï¼ŒMVP-LMåœ¨å•ä¸€æ¶æ„ä¸­é›†æˆäº†åŸºäºå•è¯(word-based)å’ŒåŸºäºå¥å­(sentence-based)çš„æ„ŸçŸ¥ä»»åŠ¡ï¼Œå¹¶åŒæ—¶æ”¯æŒæ¡†(box)å’Œæ©ç (mask)é¢„æµ‹ã€‚è¯¥æ¡†æ¶é‡‡ç”¨äº†åˆ›æ–°çš„å¤šç²’åº¦è§£ç å™¨(multi-granularity decoder)ä»¥åŠå—é“¾å¼æ€ç»´(Chain-of-Thought)å¯å‘çš„åœ°ç†æ•°æ®é›†ç»Ÿä¸€ç­–ç•¥ï¼Œå®ç°äº†å…¨æ™¯åˆ†å‰²(panoptic segmentation)ã€ç›®æ ‡æ£€æµ‹(detection)ã€å®šä½(grounding)å’ŒæŒ‡ä»£è¡¨è¾¾åˆ†å‰²(referring expression segmentation)ç­‰å¤šç§ä»»åŠ¡çš„æ— ç¼æœ‰ç›‘ç£å¾®è°ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†æŸ¥è¯¢å¢å¼ºç­–ç•¥(query enhancement strategy)ï¼Œä»¥å……åˆ†åˆ©ç”¨VLLMå›ºæœ‰çš„è§£ç å’Œç”Ÿæˆèƒ½åŠ›ã€‚åœ¨å¤šé¡¹æ„ŸçŸ¥ä»»åŠ¡åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›å®éªŒè¯æ˜äº†è¯¥æ¡†æ¶çš„æœ‰æ•ˆæ€§ä¸é¢†å…ˆæ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16213v1",
      "published_date": "2025-07-22 04:09:14 UTC",
      "updated_date": "2025-07-22 04:09:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:12.384629+00:00"
    },
    {
      "arxiv_id": "2507.16208v1",
      "title": "LOCOFY Large Design Models -- Design to code conversion solution",
      "title_zh": "LOCOFY å¤§è®¾è®¡æ¨¡å‹ï¼šä»è®¾è®¡åˆ°ä»£ç çš„è½¬æ¢è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Sohaib Muhammad",
        "Ashwati Vipin",
        "Karan Shetti",
        "Honey Mittal"
      ],
      "abstract": "Despite rapid advances in Large Language Models and Multimodal Large Language Models (LLMs), numerous challenges related to interpretability, scalability, resource requirements and repeatability remain, related to their application in the design-to-code space. To address this, we introduce the Large Design Models (LDMs) paradigm specifically trained on designs and webpages to enable seamless conversion from design-to-code. We have developed a training and inference pipeline by incorporating data engineering and appropriate model architecture modification. The training pipeline consists of the following: 1)Design Optimiser: developed using a proprietary ground truth dataset and addresses sub-optimal designs; 2)Tagging and feature detection: using pre-trained and fine-tuned models, this enables the accurate detection and classification of UI elements; and 3)Auto Components: extracts repeated UI structures into reusable components to enable creation of modular code, thus reducing redundancy while enhancing code reusability. In this manner, each model addresses distinct but key issues for design-to-code conversion. Separately, our inference pipeline processes real-world designs to produce precise and interpretable instructions for code generation and ensures reliability. Additionally, our models illustrated exceptional end-to-end design-to-code conversion accuracy using a novel preview match score metric. Comparative experiments indicated superior performance of LDMs against LLMs on accuracy of node positioning, responsiveness and reproducibility. Moreover, our custom-trained tagging and feature detection model demonstrated high precision and consistency in identifying UI elements across a wide sample of test designs. Thus, our proposed LDMs are a reliable and superior solution to understanding designs that subsequently enable the generation of efficient and reliable production-ready code.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† Large Design Models (LDMs) èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Large Language Models (LLMs) åœ¨è®¾è®¡ç¨¿è½¬ä»£ç  (design-to-code) é¢†åŸŸé¢ä¸´çš„å¯è§£é‡Šæ€§ã€æ‰©å±•æ€§å’Œé‡å¤æ€§ç­‰æŒ‘æˆ˜ã€‚è¯¥ç ”ç©¶å¼€å‘äº†ä¸€å¥—ç»“åˆæ•°æ®å·¥ç¨‹ä¸æ¨¡å‹æ¶æ„ä¼˜åŒ–çš„è®­ç»ƒä¸æ¨ç†æµæ°´çº¿ï¼Œå…¶ä¸­åŒ…å«ç”¨äºä¿®å¤æ¬¡ä¼˜è®¾è®¡çš„ Design Optimiser ä»¥åŠå®ç° UI å…ƒç´ ç²¾ç¡®åˆ†ç±»çš„ Tagging and feature detection æ¨¡å‹ã€‚é€šè¿‡ Auto Components æŠ€æœ¯ï¼Œç³»ç»Ÿèƒ½å¤Ÿè‡ªåŠ¨æå–é‡å¤çš„ UI ç»“æ„å¹¶è½¬åŒ–ä¸ºå¯å¤ç”¨çš„æ¨¡å—åŒ–ä»£ç ï¼Œæ˜¾è‘—æå‡äº†ä»£ç çš„ç®€æ´æ€§ã€‚æ¨ç†æµæ°´çº¿é€šè¿‡å¤„ç†çœŸå®ä¸–ç•Œçš„è®¾è®¡ç¨¿ç”Ÿæˆç²¾ç¡®ä¸”å¯è§£é‡Šçš„æŒ‡ä»¤ï¼Œç¡®ä¿äº†ç”Ÿæˆè¿‡ç¨‹çš„å¯é æ€§ã€‚å®éªŒé‡‡ç”¨æ–°å‹çš„ preview match score æŒ‡æ ‡è¿›è¡Œè¯„ä¼°ï¼Œç»“æœæ˜¾ç¤º LDMs åœ¨èŠ‚ç‚¹å®šä½å‡†ç¡®æ€§ã€å“åº”å¼ (responsiveness) å’Œå¯å¤ç°æ€§æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿ LLMsã€‚è¯¥ç ”ç©¶è¯æ˜äº† LDMs èƒ½å¤Ÿæä¾›é«˜ç²¾åº¦ä¸”ä¸€è‡´çš„ UI è¯†åˆ«èƒ½åŠ›ï¼Œæ˜¯ç”Ÿæˆé«˜æ•ˆã€ç”Ÿäº§å°±ç»ª (production-ready) ä»£ç çš„ä¼˜é€‰æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16208v1",
      "published_date": "2025-07-22 03:54:57 UTC",
      "updated_date": "2025-07-22 03:54:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:23.280199+00:00"
    },
    {
      "arxiv_id": "2507.16207v2",
      "title": "A Human-Centered Approach to Identifying Promises, Risks, & Challenges of Text-to-Image Generative AI in Radiology",
      "title_zh": "æ”¾å°„å­¦ä¸­æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆå¼äººå·¥æ™ºèƒ½çš„æœºé‡ã€é£é™©ä¸æŒ‘æˆ˜ï¼šä¸€ç§ä»¥äººä¸ºæœ¬çš„ç ”ç©¶æ–¹æ³•",
      "authors": [
        "Katelyn Morrison",
        "Arpit Mathur",
        "Aidan Bradshaw",
        "Tom Wartmann",
        "Steven Lundi",
        "Afrooz Zandifar",
        "Weichang Dai",
        "Kayhan Batmanghelich",
        "Motahhare Eslami",
        "Adam Perer"
      ],
      "abstract": "As text-to-image generative models rapidly improve, AI researchers are making significant advances in developing domain-specific models capable of generating complex medical imagery from text prompts. Despite this, these technical advancements have overlooked whether and how medical professionals would benefit from and use text-to-image generative AI (GenAI) in practice. By developing domain-specific GenAI without involving stakeholders, we risk the potential of building models that are either not useful or even more harmful than helpful. In this paper, we adopt a human-centered approach to responsible model development by involving stakeholders in evaluating and reflecting on the promises, risks, and challenges of a novel text-to-CT Scan GenAI model. Through exploratory model prompting activities, we uncover the perspectives of medical students, radiology trainees, and radiologists on the role that text-to-CT Scan GenAI can play across medical education, training, and practice. This human-centered approach additionally enabled us to surface technical challenges and domain-specific risks of generating synthetic medical images. We conclude by reflecting on the implications of medical text-to-image GenAI.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é‡‡ç”¨ä»¥äººä¸ºæœ¬(Human-Centered)çš„æ–¹æ³•ï¼Œæ¢è®¨äº†æ–‡æœ¬ç”Ÿæˆå›¾åƒ(Text-to-Image)ç”Ÿæˆå¼äººå·¥æ™ºèƒ½(GenAI)åœ¨æ”¾å°„å­¦é¢†åŸŸçš„åº”ç”¨å‰æ™¯ã€é£é™©åŠæŒ‘æˆ˜ã€‚ä½œè€…æŒ‡å‡ºå½“å‰æŠ€æœ¯ç ”å‘å¾€å¾€å¿½ç•¥äº†åŒ»ç–—ä¸“ä¸šäººå‘˜çš„å®é™…ä½¿ç”¨éœ€æ±‚ï¼Œå› æ­¤é€šè¿‡é‚€è¯·åŒ»å­¦ç”Ÿã€æ”¾å°„ç§‘å—è®­äººå‘˜å’Œæ”¾å°„ç§‘åŒ»ç”Ÿå‚ä¸ï¼Œå…±åŒè¯„ä¼°äº†ä¸€ç§æ–°å‹çš„æ–‡æœ¬ç”ŸæˆCTæ‰«æ(Text-to-CT Scan)æ¨¡å‹ã€‚ç ”ç©¶æ­ç¤ºäº†è¯¥æŠ€æœ¯åœ¨åŒ»å­¦æ•™è‚²ã€ä¸“ä¸šåŸ¹è®­å’Œä¸´åºŠå®è·µä¸­çš„æ½œåœ¨ä½œç”¨ï¼Œå¹¶è¯†åˆ«å‡ºäº†ç”ŸæˆåˆæˆåŒ»å­¦å½±åƒæ‰€é¢ä¸´çš„æŠ€æœ¯ç“¶é¢ˆä¸ç‰¹å®šé¢†åŸŸé£é™©ã€‚è¯¥é¡¹å·¥ä½œå¼ºè°ƒäº†åœ¨å¼€å‘é¢†åŸŸç‰¹å®šæ¨¡å‹æ—¶å¼•å…¥åˆ©ç›Šç›¸å…³è€…çš„é‡è¦æ€§ï¼Œä¸ºè´Ÿè´£ä»»çš„åŒ»ç–—AIæ¨¡å‹å¼€å‘åŠå…¶å®é™…åº”ç”¨æ„ä¹‰æä¾›äº†æ·±åˆ»è§è§£ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "10 pages of main content, Appendix attached after references, accepted to AAAI/ACM AIES 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16207v2",
      "published_date": "2025-07-22 03:53:25 UTC",
      "updated_date": "2025-09-14 14:17:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:24.180461+00:00"
    },
    {
      "arxiv_id": "2507.19534v1",
      "title": "FedDPG: An Adaptive Yet Efficient Prompt-tuning Approach in Federated Learning Settings",
      "title_zh": "FedDPGï¼šè”é‚¦å­¦ä¹ åœºæ™¯ä¸‹ä¸€ç§è‡ªé€‚åº”ä¸”é«˜æ•ˆçš„æç¤ºå¾®è°ƒæ–¹æ³•",
      "authors": [
        "Ali Shakeri",
        "Wei Emma Zhang",
        "Amin Beheshti",
        "Weitong Chen",
        "Jian Yang",
        "Lishan Yang"
      ],
      "abstract": "Pre-trained Language Models (PLMs) have demonstrated impressive performance in various NLP tasks. However, traditional fine-tuning methods for leveraging PLMs for downstream tasks entail significant computational overhead. Prompt-tuning has emerged as an efficient alternative that involves prepending a limited number of parameters to the input sequence and only updating them while the PLM's parameters are frozen. However, this technique's prompts remain fixed for all inputs, reducing the model's flexibility. The Federated Learning (FL) technique has gained attention in recent years to address the growing concerns around data privacy. However, challenges such as communication and computation limitations of clients still need to be addressed. To mitigate these challenges, this paper introduces the Federated Dynamic Prompt Generator (FedDPG), which incorporates a dynamic prompt generator network to generate context-aware prompts based on the given input, ensuring flexibility and adaptability while prioritising data privacy in federated learning settings. Our experiments on three NLP benchmark datasets showcase that FedDPG outperforms the state-of-the-art parameter-efficient fine-tuning methods in terms of global model performance, and has significantly reduced the calculation time and the number of parameters to be sent through the FL network.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ Pre-trained Language Models (PLMs) å¾®è°ƒè®¡ç®—å¼€é”€å¤§ä»¥åŠæ ‡å‡† Prompt-tuning æç¤ºè¯å›ºå®šä¸”ç¼ºä¹çµæ´»æ€§ç­‰é—®é¢˜ï¼Œæå‡ºäº† Federated Dynamic Prompt Generator (FedDPG)ã€‚è¿™æ˜¯ä¸€ç§åœ¨ Federated Learning (FL) è®¾ç½®ä¸‹çš„åŠ¨æ€æç¤ºè¯ç”Ÿæˆæ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸€ä¸ªåŠ¨æ€ç”Ÿæˆç½‘ç»œä¸ºç»™å®šè¾“å…¥äº§ç”Ÿ context-aware promptsï¼Œåœ¨ä¼˜å…ˆè€ƒè™‘æ•°æ®éšç§çš„åŒæ—¶ç¡®ä¿äº†æ¨¡å‹çš„è‡ªé€‚åº”æ€§ã€‚å®éªŒåœ¨ä¸‰ä¸ª NLP åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œï¼Œç»“æœè¡¨æ˜ FedDPG åœ¨å…¨å±€æ¨¡å‹æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„ parameter-efficient fine-tuning (PEFT) æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒFedDPG æ˜¾è‘—ç¼©çŸ­äº†è®¡ç®—æ—¶é—´ï¼Œå¹¶å¤§å¹…å‡å°‘äº†åœ¨ FL ç½‘ç»œä¸­ä¼ è¾“çš„å‚æ•°é‡ï¼Œä¸ºå—é™ç¯å¢ƒä¸‹çš„è”é‚¦å­¦ä¹ ä»»åŠ¡æä¾›äº†æ›´é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages; Published to PAKDD'2025",
      "pdf_url": "https://arxiv.org/pdf/2507.19534v1",
      "published_date": "2025-07-22 03:47:12 UTC",
      "updated_date": "2025-07-22 03:47:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:25.288967+00:00"
    },
    {
      "arxiv_id": "2507.16206v1",
      "title": "METER: Multi-modal Evidence-based Thinking and Explainable Reasoning -- Algorithm and Benchmark",
      "title_zh": "METERï¼šå¤šæ¨¡æ€å¾ªè¯æ€ç»´ä¸å¯è§£é‡Šæ€§æ¨ç†â€”â€”ç®—æ³•ä¸åŸºå‡†",
      "authors": [
        "Xu Yang",
        "Qi Zhang",
        "Shuming Jiang",
        "Yaowen Xu",
        "Zhaofan Zou",
        "Hao Sun",
        "Xuelong Li"
      ],
      "abstract": "With the rapid advancement of generative AI, synthetic content across images, videos, and audio has become increasingly realistic, amplifying the risk of misinformation. Existing detection approaches predominantly focus on binary classification while lacking detailed and interpretable explanations of forgeries, which limits their applicability in safety-critical scenarios. Moreover, current methods often treat each modality separately, without a unified benchmark for cross-modal forgery detection and interpretation. To address these challenges, we introduce METER, a unified, multi-modal benchmark for interpretable forgery detection spanning images, videos, audio, and audio-visual content. Our dataset comprises four tracks, each requiring not only real-vs-fake classification but also evidence-chain-based explanations, including spatio-temporal localization, textual rationales, and forgery type tracing. Compared to prior benchmarks, METER offers broader modality coverage and richer interpretability metrics such as spatial/temporal IoU, multi-class tracing, and evidence consistency. We further propose a human-aligned, three-stage Chain-of-Thought (CoT) training strategy combining SFT, DPO, and a novel GRPO stage that integrates a human-aligned evaluator with CoT reasoning. We hope METER will serve as a standardized foundation for advancing generalizable and interpretable forgery detection in the era of generative media.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† METERï¼Œä¸€ä¸ªæ¶µç›–å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘åŠéŸ³è§†é¢‘å†…å®¹çš„ç»Ÿä¸€å¤šæ¨¡æ€å¯è§£é‡Šä¼ªé€ æ£€æµ‹åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•åœ¨å®‰å…¨å…³é”®åœºæ™¯ä¸­ç¼ºä¹å¯è§£é‡Šæ€§çš„é—®é¢˜ã€‚è¯¥åŸºå‡†ä¸ä»…è¦æ±‚è¿›è¡ŒçœŸå‡åˆ†ç±»ï¼Œè¿˜éœ€æä¾›åŒ…å«æ—¶ç©ºå®šä½ã€æ–‡æœ¬ä¾æ®å’Œä¼ªé€ ç±»å‹è¿½è¸ªçš„è¯æ®é“¾ (evidence-chain) è§£é‡Šã€‚ç›¸æ¯”æ­¤å‰åŸºå‡†ï¼ŒMETER åœ¨æ¨¡æ€è¦†ç›–å’Œå¯è§£é‡Šæ€§æŒ‡æ ‡ï¼ˆå¦‚ç©ºé—´/æ—¶é—´ IoUã€å¤šç±»è¿½è¸ªå’Œè¯æ®ä¸€è‡´æ€§ç­‰ï¼‰æ–¹é¢æ›´ä¸ºä¸°å¯Œã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ç§äººç±»å¯¹é½çš„ä¸‰é˜¶æ®µé“¾å¼æ€ç»´ (Chain-of-Thought) è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡ç»“åˆ SFTã€DPO ä»¥åŠå¼•å…¥æ–°å‹è¯„ä¼°å™¨çš„ GRPO é˜¶æ®µï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„æ¨ç†è¡¨ç°ã€‚METER ä¸ºæ¨åŠ¨ç”Ÿæˆå¼åª’ä½“æ—¶ä»£ä¸‹å…·æœ‰æ³›åŒ–æ€§å’Œé€æ˜åº¦çš„æ£€æµ‹æŠ€æœ¯å¥ å®šäº†æ ‡å‡†åŒ–åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages,3 figures ICCV format",
      "pdf_url": "https://arxiv.org/pdf/2507.16206v1",
      "published_date": "2025-07-22 03:42:51 UTC",
      "updated_date": "2025-07-22 03:42:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:29.898081+00:00"
    },
    {
      "arxiv_id": "2507.16204v2",
      "title": "Multi-Functional RIS-Enabled in SAGIN for IoT: A Hybrid Deep Reinforcement Learning Approach with Compressed Twin-Models",
      "title_zh": "é¢å‘ç‰©è”ç½‘çš„å¤šåŠŸèƒ½ RIS èµ‹èƒ½ç©ºå¤©åœ°ä¸€ä½“åŒ–ç½‘ç»œï¼šä¸€ç§åŸºäºå‹ç¼©å­ªç”Ÿæ¨¡å‹çš„æ··åˆæ·±åº¦å¼ºåŒ–å­¦ä¹ æ–¹æ³•",
      "authors": [
        "Li-Hsiang Shen",
        "Jyun-Jhe Huang"
      ],
      "abstract": "A space-air-ground integrated network (SAGIN) for Internet of Things (IoT) network architecture is investigated, empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS) capable of simultaneously reflecting, amplifying, and harvesting wireless energy. The MF-RIS plays a pivotal role in addressing the energy shortages of low-Earth orbit (LEO) satellites operating in the shadowed regions, while accounting for both communication and computing energy consumption across the SAGIN nodes. To maximize the long-term energy efficiency (EE) of IoT devices, we formulate a joint optimization problem over the MF-RIS parameters, including signal amplification, phase-shifts, energy harvesting ratio, and active element selection as well as the SAGIN parameters of beamforming vectors, high-altitude platform station (HAPS) deployment, IoT device association, and computing capability. The formulated problem is highly non-convex and non-linear and contains mixed discrete-continuous parameters. To tackle this, we conceive a compressed hybrid twin-model enhanced multi-agent deep reinforcement learning (CHIMERA) framework, which integrates semantic state-action compression and parametrized sharing under hybrid reinforcement learning to efficiently explore suitable complex actions. The simulation results have demonstrated that the proposed CHIMERA scheme substantially outperforms the conventional benchmarks, including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and no-RIS cases, as well as centralized and multi-agent deep reinforcement learning baselines in terms of the highest EE. Moreover, the proposed SAGIN-MF-RIS architecture in IoT network achieves superior EE performance due to its complementary coverage, offering notable advantages over either standalone satellite, aerial, or ground-only deployments.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢ç´¢äº†ç”±å¤šåŠŸèƒ½å¯é‡æ„æ™ºèƒ½è¡¨é¢(MF-RIS)å¢å¼ºçš„å¤©ç©ºåœ°ä¸€ä½“åŒ–ç½‘ç»œ(SAGIN)ç‰©è”ç½‘æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ä½è½¨(LEO)å«æ˜Ÿåœ¨é˜´å½±åŒºåŸŸçš„èƒ½æºçŸ­ç¼ºä»¥åŠç½‘ç»œèŠ‚ç‚¹çš„é€šä¿¡ä¸è®¡ç®—èƒ½è€—é—®é¢˜ã€‚è¯¥ç ”ç©¶é€šè¿‡è”åˆä¼˜åŒ–MF-RISçš„ä¿¡å·æ”¾å¤§ã€ç›¸ç§»ã€èƒ½é‡æ”¶é›†æ¯”ä¾‹ä»¥åŠSAGINçš„æ³¢æŸèµ‹å½¢(beamforming)ã€é«˜ç©ºå¹³å°ç«™(HAPS)éƒ¨ç½²ã€è®¾å¤‡å…³è”å’Œè®¡ç®—èƒ½åŠ›ï¼Œæ—¨åœ¨æœ€å¤§åŒ–ç‰©è”ç½‘è®¾å¤‡çš„é•¿æœŸèƒ½æ•ˆ(EE)ã€‚ä¸ºè§£å†³é«˜åº¦éå‡¸ä¸”åŒ…å«æ··åˆç¦»æ•£è¿ç»­å‚æ•°çš„ä¼˜åŒ–éš¾é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸ºCHIMERAçš„å‹ç¼©æ··åˆåŒæ¨¡å‹å¢å¼ºå¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é›†æˆäº†è¯­ä¹‰çŠ¶æ€-åŠ¨ä½œå‹ç¼©å’Œæ··åˆå¼ºåŒ–å­¦ä¹ ä¸‹çš„å‚æ•°å…±äº«æœºåˆ¶ã€‚ä»¿çœŸç»“æœè¯æ˜ï¼ŒCHIMERAæ–¹æ¡ˆåœ¨èƒ½æ•ˆè¡¨ç°ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»ŸRISã€éèƒ½é‡æ”¶é›†MF-RISä»¥åŠå¸¸è§„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ åŸºå‡†ã€‚æ­¤å¤–ï¼Œå®éªŒè¡¨æ˜SAGIN-MF-RISæ¶æ„å‡­å€Ÿäº’è¡¥çš„è¦†ç›–ç‰¹æ€§ï¼Œå…¶èƒ½æ•ˆæ€§èƒ½ä¼˜äºå•ä¸€çš„å«æ˜Ÿã€ç©ºä¸­æˆ–åœ°é¢éƒ¨ç½²æ¨¡å¼ï¼Œä¸ºæœªæ¥ç‰©è”ç½‘é€šä¿¡æä¾›äº†é«˜æ•ˆçš„è¦†ç›–æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16204v2",
      "published_date": "2025-07-22 03:40:56 UTC",
      "updated_date": "2025-10-13 15:17:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:50.988508+00:00"
    },
    {
      "arxiv_id": "2507.16203v1",
      "title": "SVAgent: AI Agent for Hardware Security Verification Assertion",
      "title_zh": "SVAgentï¼šé¢å‘ç¡¬ä»¶å®‰å…¨éªŒè¯æ–­è¨€çš„ AI æ™ºèƒ½ä½“",
      "authors": [
        "Rui Guo",
        "Avinash Ayalasomayajula",
        "Henian Li",
        "Jingbo Zhou",
        "Sujan Kumar Saha",
        "Farimah Farahmandi"
      ],
      "abstract": "Verification using SystemVerilog assertions (SVA) is one of the most popular methods for detecting circuit design vulnerabilities. However, with the globalization of integrated circuit design and the continuous upgrading of security requirements, the SVA development model has exposed major limitations. It is not only inefficient in development, but also unable to effectively deal with the increasing number of security vulnerabilities in modern complex integrated circuits. In response to these challenges, this paper proposes an innovative SVA automatic generation framework SVAgent. SVAgent introduces a requirement decomposition mechanism to transform the original complex requirements into a structured, gradually solvable fine-grained problem-solving chain. Experiments have shown that SVAgent can effectively suppress the influence of hallucinations and random answers, and the key evaluation indicators such as the accuracy and consistency of the SVA are significantly better than existing frameworks. More importantly, we successfully integrated SVAgent into the most mainstream integrated circuit vulnerability assessment framework and verified its practicality and reliability in a real engineering design environment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SVAgentï¼Œä¸€ç§ç”¨äºç¡¬ä»¶å®‰å…¨éªŒè¯æ–­è¨€ (Hardware Security Verification Assertion) ç”Ÿæˆçš„åˆ›æ–° AI Agent æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ SystemVerilog assertions (SVA) åœ¨ç°ä»£å¤æ‚é›†æˆç”µè·¯éªŒè¯ä¸­é¢ä¸´çš„å¼€å‘æ•ˆç‡ä½å’Œå®‰å…¨æ¼æ´å¤„ç†èƒ½åŠ›ä¸è¶³ç­‰é—®é¢˜ã€‚SVAgent å¼•å…¥äº†éœ€æ±‚åˆ†è§£æœºåˆ¶ (requirement decomposition mechanism)ï¼Œå°†å¤æ‚çš„åŸå§‹éœ€æ±‚è½¬åŒ–ä¸ºç»“æ„åŒ–ä¸”é€æ­¥å¯è§£çš„ç»†ç²’åº¦é—®é¢˜é“¾ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆæŠ‘åˆ¶å¹»è§‰ (hallucinations) å’Œéšæœºå›ç­”ï¼Œåœ¨ SVA ç”Ÿæˆçš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§ç­‰å…³é”®æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿå°† SVAgent æˆåŠŸé›†æˆåˆ°ä¸»æµé›†æˆç”µè·¯æ¼æ´è¯„ä¼°æ¡†æ¶ä¸­ï¼Œå¹¶åœ¨çœŸå®å·¥ç¨‹è®¾è®¡ç¯å¢ƒä¸‹éªŒè¯äº†å…¶åœ¨ç¡¬ä»¶å®‰å…¨éªŒè¯é¢†åŸŸçš„å®ç”¨æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16203v1",
      "published_date": "2025-07-22 03:36:06 UTC",
      "updated_date": "2025-07-22 03:36:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:44.479536+00:00"
    },
    {
      "arxiv_id": "2508.00875v1",
      "title": "Preliminary suggestions for rigorous GPAI model evaluations",
      "title_zh": "GPAI æ¨¡å‹ä¸¥è°¨è¯„ä¼°çš„åˆæ­¥å»ºè®®",
      "authors": [
        "Patricia Paskov",
        "Michael J. Byun",
        "Kevin Wei",
        "Toby Webster"
      ],
      "abstract": "This document presents a preliminary compilation of general-purpose AI (GPAI) evaluation practices that may promote internal validity, external validity and reproducibility. It includes suggestions for human uplift studies and benchmark evaluations, as well as cross-cutting suggestions that may apply to many different evaluation types. Suggestions are organised across four stages in the evaluation life cycle: design, implementation, execution and documentation. Drawing from established practices in machine learning, statistics, psychology, economics, biology and other fields recognised to have important lessons for AI evaluation, these suggestions seek to contribute to the conversation on the nascent and evolving field of the science of GPAI evaluations. The intended audience of this document includes providers of GPAI models presenting systemic risk (GPAISR), for whom the EU AI Act lays out specific evaluation requirements; third-party evaluators; policymakers assessing the rigour of evaluations; and academic researchers developing or conducting GPAI evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é’ˆå¯¹é€šç”¨äººå·¥æ™ºèƒ½ (GPAI) æ¨¡å‹è¯„ä¼°çš„åˆæ­¥å»ºè®®ï¼Œæ—¨åœ¨æé«˜è¯„ä¼°çš„å†…éƒ¨æœ‰æ•ˆæ€§ (Internal Validity)ã€å¤–éƒ¨æœ‰æ•ˆæ€§ (External Validity) å’Œå¯é‡å¤æ€§ (Reproducibility)ã€‚å»ºè®®å†…å®¹æ¶µç›–äº†äººç±»æå‡ç ”ç©¶ (Human Uplift Studies) å’ŒåŸºå‡†æµ‹è¯•è¯„ä¼° (Benchmark Evaluations)ï¼Œå¹¶æä¾›äº†é€‚ç”¨äºå¤šç§è¯„ä¼°ç±»å‹çš„è·¨é¢†åŸŸæŒ‡å¯¼ã€‚è¿™äº›å»ºè®®æŒ‰ç…§è®¾è®¡ (Design)ã€å®æ–½ (Implementation)ã€æ‰§è¡Œ (Execution) å’Œæ–‡æ¡£è®°å½• (Documentation) å››ä¸ªç”Ÿå‘½å‘¨æœŸé˜¶æ®µè¿›è¡Œç»„ç»‡ï¼Œç¡®ä¿äº†è¯„ä¼°æµç¨‹çš„ç³»ç»Ÿæ€§ã€‚ç ”ç©¶å¹¿æ³›å€Ÿé‰´äº†æœºå™¨å­¦ä¹ ã€ç»Ÿè®¡å­¦ã€å¿ƒç†å­¦ã€ç»æµå­¦å’Œç”Ÿç‰©å­¦ç­‰å­¦ç§‘çš„æˆç†Ÿå®è·µï¼Œä¸ºå°šå¤„äºèµ·æ­¥é˜¶æ®µçš„ GPAI è¯„ä¼°ç§‘å­¦è´¡çŒ®äº†ä¸¥è°¨çš„æ–¹æ³•è®ºã€‚å…¶ç›®æ ‡å—ä¼—æ¶µç›–äº†éœ€è¦æ»¡è¶³æ¬§ç›Ÿ AI æ³•æ¡ˆ (EU AI Act) åˆè§„è¦æ±‚çš„ GPAI æä¾›è€…ã€ç¬¬ä¸‰æ–¹è¯„ä¼°æœºæ„ã€æ”¿ç­–åˆ¶å®šè€…ä»¥åŠç›¸å…³é¢†åŸŸçš„å­¦æœ¯ç ”ç©¶äººå‘˜ã€‚è¯¥æ–‡æ¡£é€šè¿‡å»ºç«‹è¯„ä¼°è§„èŒƒï¼Œä¸ºæå‡ GPAI æ¨¡å‹è¯„ä¼°çš„ä¸¥è°¨æ€§ä¸å¯é æ€§æä¾›äº†é‡è¦çš„å‚è€ƒæ¡†æ¶ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Santa Monica, CA: RAND Corporation, 2025. Published as a RAND expert commentary at: https://www.rand.org/pubs/perspectives/PEA3971-1.html",
      "pdf_url": "https://arxiv.org/pdf/2508.00875v1",
      "published_date": "2025-07-22 03:27:42 UTC",
      "updated_date": "2025-07-22 03:27:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:50.286075+00:00"
    },
    {
      "arxiv_id": "2507.16867v1",
      "title": "Diffusion-Modeled Reinforcement Learning for Carbon and Risk-Aware Microgrid Optimization",
      "title_zh": "é¢å‘ç¢³ä¸é£é™©æ„ŸçŸ¥å¾®ç”µç½‘ä¼˜åŒ–çš„æ‰©æ•£æ¨¡å‹å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Yunyi Zhao",
        "Wei Zhang",
        "Cheng Xiang",
        "Hongyang Du",
        "Dusit Niyato",
        "Shuhua Gao"
      ],
      "abstract": "This paper introduces DiffCarl, a diffusion-modeled carbon- and risk-aware reinforcement learning algorithm for intelligent operation of multi-microgrid systems. With the growing integration of renewables and increasing system complexity, microgrid communities face significant challenges in real-time energy scheduling and optimization under uncertainty. DiffCarl integrates a diffusion model into a deep reinforcement learning (DRL) framework to enable adaptive energy scheduling under uncertainty and explicitly account for carbon emissions and operational risk. By learning action distributions through a denoising generation process, DiffCarl enhances DRL policy expressiveness and enables carbon- and risk-aware scheduling in dynamic and uncertain microgrid environments. Extensive experimental studies demonstrate that it outperforms classic algorithms and state-of-the-art DRL solutions, with 2.3-30.1% lower operational cost. It also achieves 28.7% lower carbon emissions than those of its carbon-unaware variant and reduces performance variability. These results highlight DiffCarl as a practical and forward-looking solution. Its flexible design allows efficient adaptation to different system configurations and objectives to support real-world deployment in evolving energy systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DiffCarlï¼Œä¸€ç§èåˆæ‰©æ•£æ¨¡å‹(Diffusion Model)çš„ç¢³æ’æ”¾ä¸é£é™©æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³å¤šå¾®ç”µç½‘(multi-microgrid)ç³»ç»Ÿåœ¨å®æ—¶èƒ½æºè°ƒåº¦ä¸ä¼˜åŒ–ä¸­é¢ä¸´çš„ä¸ç¡®å®šæ€§æŒ‘æˆ˜ã€‚è¯¥ç®—æ³•é€šè¿‡å°†æ‰©æ•£æ¨¡å‹é›†æˆåˆ°æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)æ¡†æ¶ä¸­ï¼Œåˆ©ç”¨å»å™ªç”Ÿæˆè¿‡ç¨‹(denoising generation process)å­¦ä¹ åŠ¨ä½œåˆ†å¸ƒï¼Œæ˜¾è‘—å¢å¼ºäº†ç­–ç•¥çš„è¡¨è¾¾èƒ½åŠ›ã€‚å®éªŒè¯æ˜ï¼ŒDiffCarlåœ¨è¿è¡Œæˆæœ¬ä¸Šæ¯”ç°æœ‰ä¸»æµç®—æ³•é™ä½äº†2.3%è‡³30.1%ï¼Œå¹¶èƒ½æœ‰æ•ˆå…¼é¡¾ç¢³æ’æ”¾ä¸è¿è¡Œé£é™©ã€‚ä¸ä¸å…·å¤‡ç¢³æ„ŸçŸ¥çš„ç‰ˆæœ¬ç›¸æ¯”ï¼Œè¯¥æ¨¡å‹æˆåŠŸå‡å°‘äº†28.7%çš„ç¢³æ’æ”¾ï¼Œå¹¶æ˜¾è‘—é™ä½äº†æ€§èƒ½æ³¢åŠ¨ã€‚å…¶çµæ´»çš„è®¾è®¡ä½¿å…¶èƒ½å¤Ÿé€‚åº”ä¸åŒçš„ç³»ç»Ÿé…ç½®å’Œç›®æ ‡ï¼Œä¸ºå®é™…èƒ½æºç³»ç»Ÿçš„æ™ºèƒ½åŒ–è¿è¡Œæä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å…·å‰ç»æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2507.16867v1",
      "published_date": "2025-07-22 03:27:07 UTC",
      "updated_date": "2025-07-22 03:27:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:55.036420+00:00"
    },
    {
      "arxiv_id": "2507.16184v3",
      "title": "Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind",
      "title_zh": "ç»ç”±å®ç°æ¶Œç°çš„è®¤çŸ¥è¶‹åŒï¼šä¸€ä¸ªåæ˜ å››ç§å¿ƒæ™ºç†è®ºçš„ç»“æ„åŒ–å¾ªç¯",
      "authors": [
        "Myung Ho Kim"
      ],
      "abstract": "We report a structural convergence among four influential theories of mind: Kahneman's dual-system theory, Friston's predictive processing, Minsky's society of mind, and Clark's extended mind, emerging unintentionally within a practical AI architecture known as Agentic Flow. Designed to address the limitations of large language models (LLMs), Agentic Flow comprises five interlocking modules: Retrieval, Cognition, Control, Memory, and Action, organized into a repeatable cognitive loop. Although originally inspired only by Minsky and Clark, subsequent analysis revealed that its structure echoes computational motifs from all four theories, suggesting that theoretical convergence can emerge naturally from implementation demands rather than deliberate synthesis. Controlled evaluations confirmed this: the structured agent achieved 95.8% task success versus 62.3% for baseline LLMs, demonstrating robust constraint adherence and reproducible reasoning. We describe this convergence under a broader descriptive meta-architecture called PEACE, highlighting recurring design patterns such as predictive modeling, associative recall, and error-sensitive control. Later formalized as the Structured Cognitive Loop (SCL), this framework generalizes the same principles as a foundation for behavioral intelligence in LLM-based agents. Rather than claiming theoretical unification, this paper proposes that intelligent architectures may evolve toward shared structural patterns shaped by practical constraints. As a position paper, it aims to frame this convergence as an interpretive reflection rather than a finalized theory, inviting further theoretical and experimental dialogue. Agentic Flow, or equivalently the Structured Cognitive Loop, thus offers a glimpse of how a unified cognitive form can arise not from abstraction, but from the necessities of real-world reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æŠ¥å‘Šäº†å››ç§æ ¸å¿ƒå¿ƒæ™ºç†è®ºâ€”â€”Kahnemançš„Dual-system theoryã€Fristonçš„Predictive processingã€Minskyçš„Society of mindä»¥åŠClarkçš„Extended mindâ€”â€”åœ¨åä¸ºAgentic Flowçš„å®ç”¨AIæ¶æ„ä¸­æ„å¤–å®ç°çš„ç»“æ„æ€§èåˆã€‚è¯¥æ¶æ„ç”±Retrievalã€Cognitionã€Controlã€Memoryå’ŒActionäº”ä¸ªæ¨¡å—ç»„æˆçš„é‡å¤è®¤çŸ¥å›è·¯æ„æˆï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„å±€é™æ€§ã€‚åˆ†æè¡¨æ˜ï¼Œè¿™ç§ç†è®ºèåˆå¹¶éåˆ»æ„åˆæˆï¼Œè€Œæ˜¯ä»å®é™…å®æ–½éœ€æ±‚ä¸­è‡ªç„¶äº§ç”Ÿçš„è®¡ç®—æ¨¡å¼ã€‚ç ”ç©¶å°†æ­¤ç°è±¡å½’çº³ä¸ºåä¸ºPEACEçš„å…ƒæ¶æ„ï¼Œå¹¶å½¢å¼åŒ–ä¸ºç»“æ„åŒ–è®¤çŸ¥å›è·¯(Structured Cognitive Loop, SCL)ï¼Œä¸ºLLMæ™ºèƒ½ä½“çš„è¡Œä¸ºæ™ºèƒ½å¥ å®šåŸºç¡€ã€‚å—æ§è¯„ä¼°æ˜¾ç¤ºï¼Œè¯¥ç»“æ„åŒ–æ™ºèƒ½ä½“å®ç°äº†95.8%çš„ä»»åŠ¡æˆåŠŸç‡ï¼Œè¿œè¶…åŸºçº¿LLMsçš„62.3%ï¼Œè¯æ˜äº†å…¶ç¨³å¥çš„çº¦æŸéµå¾ªå’Œæ¨ç†èƒ½åŠ›ã€‚è¯¥è®ºæ–‡æå‡ºæ™ºèƒ½æ¶æ„å¯èƒ½åœ¨å®é™…çº¦æŸä¸‹å‘å…±äº«çš„ç»“æ„æ¨¡å¼æ¼”åŒ–ï¼Œä¸ºä»å·¥ç¨‹å®è·µè§’åº¦ç†è§£ç»Ÿä¸€è®¤çŸ¥å½¢å¼æä¾›äº†æ–°çš„è§£é‡Šæ€§æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Added a public demo for the conditional travel planning scenario to illustrate the framework presented in this study",
      "pdf_url": "https://arxiv.org/pdf/2507.16184v3",
      "published_date": "2025-07-22 02:54:45 UTC",
      "updated_date": "2025-11-12 08:46:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:19:59.038294+00:00"
    },
    {
      "arxiv_id": "2507.16178v1",
      "title": "LLM Data Selection and Utilization via Dynamic Bi-level Optimization",
      "title_zh": "åŸºäºåŠ¨æ€åŒå±‚ä¼˜åŒ–çš„ LLM æ•°æ®é€‰æ‹©ä¸åˆ©ç”¨",
      "authors": [
        "Yang Yu",
        "Kai Han",
        "Hang Zhou",
        "Yehui Tang",
        "Kaiqi Huang",
        "Yunhe Wang",
        "Dacheng Tao"
      ],
      "abstract": "While large-scale training data is fundamental for developing capable large language models (LLMs), strategically selecting high-quality data has emerged as a critical approach to enhance training efficiency and reduce computational costs. Current data selection methodologies predominantly rely on static, training-agnostic criteria, failing to account for the dynamic model training and data interactions. In this paper, we propose a new Data Weighting Model (DWM) to adjust the weight of selected data within each batch to achieve a dynamic data utilization during LLM training. Specially, to better capture the dynamic data preference of the trained model, a bi-level optimization framework is implemented to update the weighting model. Our experiments demonstrate that DWM enhances the performance of models trained with randomly-selected data, and the learned weighting model can be transferred to enhance other data selection methods and models of different sizes. Moreover, we further analyze how a model's data preferences evolve throughout training, providing new insights into the data preference of the model during training.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºæ•°æ®åŠ æƒæ¨¡å‹ (Data Weighting Model, DWM) çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ•°æ®é€‰æ‹©æ–¹æ³•å› ä¾èµ–é™æ€æ ‡å‡†è€Œå¿½è§†æ¨¡å‹è®­ç»ƒä¸æ•°æ®é—´åŠ¨æ€äº¤äº’çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥åŒå±‚ä¼˜åŒ– (bi-level optimization) æ¡†æ¶ï¼Œåœ¨ LLM è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´æ¯ä¸ªæ‰¹æ¬¡ (batch) å†…é€‰å®šæ•°æ®çš„æƒé‡ï¼Œä»¥æ›´ç²¾å‡†åœ°æ•æ‰æ¨¡å‹åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µçš„åŠ¨æ€æ•°æ®åå¥½ (data preference)ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒDWM æ˜¾è‘—æå‡äº†åŸºäºéšæœºé€‰æ‹©æ•°æ®è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½ï¼Œä¸”å…¶å­¦ä¹ åˆ°çš„åŠ æƒæ¨¡å‹å…·æœ‰è‰¯å¥½çš„è¿ç§»æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¢å¼ºå…¶ä»–æ•°æ®é€‰æ‹©æ–¹æ³•åŠä¸åŒè§„æ¨¡æ¨¡å‹çš„è¡¨ç°ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡æ·±å…¥åˆ†ææ¨¡å‹æ•°æ®åå¥½çš„æ¼”å˜è¿‡ç¨‹ï¼Œä¸ºç†è§£å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒæœŸé—´çš„å†…éƒ¨éœ€æ±‚æä¾›äº†æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 42nd International Conference on Machine Learning (ICML 2025)",
      "pdf_url": "https://arxiv.org/pdf/2507.16178v1",
      "published_date": "2025-07-22 02:47:12 UTC",
      "updated_date": "2025-07-22 02:47:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:05.558814+00:00"
    },
    {
      "arxiv_id": "2507.16164v1",
      "title": "Attacking interpretable NLP systems",
      "title_zh": "æ”»å‡»å¯è§£é‡Šè‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿ",
      "authors": [
        "Eldor Abdukhamidov",
        "Tamer Abuhmed",
        "Joanna C. S. Santos",
        "Mohammed Abuhamad"
      ],
      "abstract": "Studies have shown that machine learning systems are vulnerable to adversarial examples in theory and practice. Where previous attacks have focused mainly on visual models that exploit the difference between human and machine perception, text-based models have also fallen victim to these attacks. However, these attacks often fail to maintain the semantic meaning of the text and similarity. This paper introduces AdvChar, a black-box attack on Interpretable Natural Language Processing Systems, designed to mislead the classifier while keeping the interpretation similar to benign inputs, thus exploiting trust in system transparency. AdvChar achieves this by making less noticeable modifications to text input, forcing the deep learning classifier to make incorrect predictions and preserve the original interpretation. We use an interpretation-focused scoring approach to determine the most critical tokens that, when changed, can cause the classifier to misclassify the input. We apply simple character-level modifications to measure the importance of tokens, minimizing the difference between the original and new text while generating adversarial interpretations similar to benign ones. We thoroughly evaluated AdvChar by testing it against seven NLP models and three interpretation models using benchmark datasets for the classification task. Our experiments show that AdvChar can significantly reduce the prediction accuracy of current deep learning models by altering just two characters on average in input samples.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¯è§£é‡Š Natural Language Processing (NLP) ç³»ç»Ÿåœ¨å¯¹æŠ—æ ·æœ¬é¢å‰çš„è„†å¼±æ€§ã€‚è®ºæ–‡æå‡ºäº† AdvCharï¼Œä¸€ç§é’ˆå¯¹è¯¥ç³»ç»Ÿçš„ black-box attack æ–¹æ³•ï¼Œæ—¨åœ¨è¯±å¯¼ classifier åšå‡ºé”™è¯¯é¢„æµ‹çš„åŒæ—¶ï¼Œä¿æŒä¸åŸå§‹è¾“å…¥ç›¸ä¼¼çš„è§£é‡Šç»“æœï¼Œä»è€Œåˆ©ç”¨ç”¨æˆ·å¯¹ç³»ç»Ÿé€æ˜åº¦çš„ä¿¡ä»»ã€‚AdvChar é‡‡ç”¨ interpretation-focused scoring æ–¹æ³•ç¡®å®šå…³é”® tokenï¼Œå¹¶é€šè¿‡å­—ç¬¦çº§çš„å¾®å°ä¿®æ”¹ï¼ˆcharacter-level modificationsï¼‰æ¥æœ€å°åŒ–åŸå§‹æ–‡æœ¬ä¸å¯¹æŠ—æ–‡æœ¬ä¹‹é—´çš„å·®å¼‚ã€‚ç ”ç©¶äººå‘˜åœ¨ 7 ä¸ª NLP models å’Œ 3 ä¸ª interpretation models ä¸Šè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒAdvChar å¹³å‡ä»…éœ€ä¿®æ”¹ä¸¤ä¸ªå­—ç¬¦å³å¯æ˜¾è‘—é™ä½æ·±åº¦å­¦ä¹ æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®ç‡ï¼Œè¯æ˜äº†å½“å‰æ¨¡å‹åœ¨ç»´æŒè§£é‡Šä¸€è‡´æ€§çš„åŒæ—¶ææ˜“å—åˆ°æ”»å‡»ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16164v1",
      "published_date": "2025-07-22 02:20:00 UTC",
      "updated_date": "2025-07-22 02:20:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:05.935311+00:00"
    },
    {
      "arxiv_id": "2507.16154v1",
      "title": "LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation",
      "title_zh": "LSSGenï¼šåˆ©ç”¨æµåŒ¹é…ä¸æ‰©æ•£æ¨¡å‹ä¸­çš„æ½œç©ºé—´ç¼©æ”¾å®ç°é«˜æ•ˆæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ",
      "authors": [
        "Jyun-Ze Tang",
        "Chih-Fan Hsu",
        "Jeng-Lin Li",
        "Ming-Ching Chang",
        "Wei-Chao Chen"
      ],
      "abstract": "Flow matching and diffusion models have shown impressive results in text-to-image generation, producing photorealistic images through an iterative denoising process. A common strategy to speed up synthesis is to perform early denoising at lower resolutions. However, traditional methods that downscale and upscale in pixel space often introduce artifacts and distortions. These issues arise when the upscaled images are re-encoded into the latent space, leading to degraded final image quality. To address this, we propose {\\bf Latent Space Scaling Generation (LSSGen)}, a framework that performs resolution scaling directly in the latent space using a lightweight latent upsampler. Without altering the Transformer or U-Net architecture, LSSGen improves both efficiency and visual quality while supporting flexible multi-resolution generation. Our comprehensive evaluation covering text-image alignment and perceptual quality shows that LSSGen significantly outperforms conventional scaling approaches. When generating $1024^2$ images at similar speeds, it achieves up to 246\\% TOPIQ score improvement.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† LSSGenï¼ˆLatent Space Scaling Generationï¼‰ï¼Œä¸€ä¸ªæ—¨åœ¨æå‡ Flow matching å’Œ Diffusion models åœ¨æ–‡æœ¬ç”Ÿæˆå›¾åƒä»»åŠ¡ä¸­æ•ˆç‡çš„æ¡†æ¶ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•åœ¨åƒç´ ç©ºé—´ï¼ˆpixel spaceï¼‰è¿›è¡Œåˆ†è¾¨ç‡ç¼©æ”¾ä¼šå¯¼è‡´ä¼ªå½±å’Œå¤±çœŸï¼Œè¿›è€Œå½±å“é‡ç¼–ç åæ½œç©ºé—´å›¾åƒè´¨é‡çš„é—®é¢˜ï¼ŒLSSGen åˆ›æ–°æ€§åœ°æå‡ºç›´æ¥åœ¨æ½œç©ºé—´ï¼ˆlatent spaceï¼‰ä¸­ä½¿ç”¨è½»é‡çº§æ½œç©ºé—´ä¸Šé‡‡æ ·å™¨ï¼ˆlatent upsamplerï¼‰è¿›è¡Œåˆ†è¾¨ç‡ç¼©æ”¾ã€‚è¯¥æ–¹æ³•æ— éœ€ä¿®æ”¹åŸæœ‰çš„ Transformer æˆ– U-Net æ¶æ„ï¼Œåœ¨æ”¯æŒçµæ´»å¤šåˆ†è¾¨ç‡ç”Ÿæˆçš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†åˆæˆæ•ˆç‡å’Œè§†è§‰è´¨é‡ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒLSSGen åœ¨æ–‡æœ¬-å›¾åƒå¯¹é½å’Œæ„ŸçŸ¥è´¨é‡æ–¹é¢å‡ä¼˜äºä¼ ç»Ÿç¼©æ”¾æ–¹æ³•ã€‚åœ¨ç”Ÿæˆ $1024^2$ åˆ†è¾¨ç‡å›¾åƒä¸”é€Ÿåº¦ç›¸å½“çš„æƒ…å†µä¸‹ï¼ŒLSSGen ç›¸æ¯”åŸºçº¿æ–¹æ³•å®ç°äº†é«˜è¾¾ 246% çš„ TOPIQ è¯„åˆ†æå‡ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICCV AIGENS 2025",
      "pdf_url": "https://arxiv.org/pdf/2507.16154v1",
      "published_date": "2025-07-22 02:05:21 UTC",
      "updated_date": "2025-07-22 02:05:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:06.914800+00:00"
    },
    {
      "arxiv_id": "2507.16151v1",
      "title": "SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities",
      "title_zh": "SPACT18ï¼šç»“åˆ RGB ä¸çƒ­æˆåƒäº’è¡¥æ¨¡æ€çš„è„‰å†²å¼äººä½“åŠ¨ä½œè¯†åˆ«åŸºå‡†æ•°æ®é›†",
      "authors": [
        "Yasser Ashraf",
        "Ahmed Sharshar",
        "Velibor Bojkovic",
        "Bin Gu"
      ],
      "abstract": "Spike cameras, bio-inspired vision sensors, asynchronously fire spikes by accumulating light intensities at each pixel, offering ultra-high energy efficiency and exceptional temporal resolution. Unlike event cameras, which record changes in light intensity to capture motion, spike cameras provide even finer spatiotemporal resolution and a more precise representation of continuous changes. In this paper, we introduce the first video action recognition (VAR) dataset using spike camera, alongside synchronized RGB and thermal modalities, to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). By preserving the inherent sparsity and temporal precision of spiking data, our three datasets offer a unique platform for exploring multimodal video understanding and serve as a valuable resource for directly comparing spiking, thermal, and RGB modalities. This work contributes a novel dataset that will drive research in energy-efficient, ultra-low-power video understanding, specifically for action recognition tasks using spike-based data.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†SPACT18ï¼Œè¿™æ˜¯é¦–ä¸ªç»“åˆäº†è„‰å†²ç›¸æœº(Spike Camera)ä»¥åŠåŒæ­¥RGBå’Œçƒ­æˆåƒ(Thermal)æ¨¡æ€çš„äººä½“åŠ¨ä½œè¯†åˆ«(Human Action Recognition)åŸºå‡†æ•°æ®é›†ã€‚è„‰å†²ç›¸æœºä½œä¸ºä¸€ç§ä»¿ç”Ÿè§†è§‰ä¼ æ„Ÿå™¨ï¼Œé€šè¿‡åœ¨æ¯ä¸ªåƒç´ ç‚¹ç§¯ç´¯å…‰å¼ºæ¥å¼‚æ­¥è§¦å‘è„‰å†²ï¼Œå…·æœ‰æé«˜çš„èƒ½é‡æ•ˆç‡å’Œå“è¶Šçš„æ—¶é—´åˆ†è¾¨ç‡ã€‚ä¸ä»…è®°å½•å…‰å¼ºå˜åŒ–çš„äº‹ä»¶ç›¸æœº(Event Camera)ä¸åŒï¼Œè„‰å†²ç›¸æœºæä¾›äº†æ›´ç²¾ç»†çš„æ—¶ç©ºåˆ†è¾¨ç‡ï¼Œèƒ½æ›´ç²¾ç¡®åœ°å‘ˆç°è¿ç»­çš„è§†è§‰å˜åŒ–ã€‚SPACT18æ—¨åœ¨ä¸ºè„‰å†²ç¥ç»ç½‘ç»œ(SNNs)æä¾›å…¨é¢çš„åŸºå‡†æµ‹è¯•å¹³å°ï¼Œå¹¶å®Œæ•´ä¿ç•™äº†è„‰å†²æ•°æ®çš„å›ºæœ‰ç¨€ç–æ€§å’Œæ—¶é—´ç²¾ç¡®æ€§ã€‚è¯¥æ•°æ®é›†ä¸ºæ¢ç´¢å¤šæ¨¡æ€è§†é¢‘ç†è§£æä¾›äº†ç‹¬ç‰¹èµ„æºï¼Œæ”¯æŒå¯¹è„‰å†²ã€çƒ­æˆåƒå’ŒRGBæ¨¡æ€è¿›è¡Œç›´æ¥å¯¹æ¯”ã€‚è¿™é¡¹å·¥ä½œå°†æ˜¾è‘—æ¨åŠ¨é«˜æ•ˆèƒ½ã€è¶…ä½åŠŸè€—è§†é¢‘ç†è§£é¢†åŸŸçš„ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯åœ¨åŸºäºè„‰å†²æ•°æ®çš„åŠ¨ä½œè¯†åˆ«ä»»åŠ¡æ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16151v1",
      "published_date": "2025-07-22 01:59:14 UTC",
      "updated_date": "2025-07-22 01:59:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:17.282881+00:00"
    },
    {
      "arxiv_id": "2507.16145v2",
      "title": "SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting",
      "title_zh": "SpiroLLMï¼šé€šè¿‡å¾®è°ƒé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å®ç°å¯¹å‘¼å¸é‡å›¾æ—¶é—´åºåˆ—çš„ç†è§£åŠå…¶åœ¨COPDæŠ¥å‘Šä¸­çš„ä¸´åºŠéªŒè¯",
      "authors": [
        "Shuhao Mei",
        "Yongchao Long",
        "Shan Cao",
        "Xiaobo Han",
        "Shijia Geng",
        "Jinbo Sun",
        "Yuxi Zhou",
        "Shenda Hong"
      ],
      "abstract": "Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory disease with persistent airflow limitation, is a leading global cause of disability and mortality. Respiratory spirogram time series, routinely collected during pulmonary function tests (PFTs), play a critical role in the early detection of repsiratory diseases and in monitoring lung function over time. However, most current AI models for COPD diagnosis are limited to outputting classification results without providing a rationale for their diagnostic process, while current Large Language Models (LLMs) cannot understand spirograms yet, which severely limits their clinical trust and adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large language model that can understand spirogram. The model extracts morphological features from respiratory curves via a SpiroEncoder and aligns them with PFT numerical values in a unified latent space using a SpiroProjector, ultimately empowering a large language model to generate a comprehensive diagnostic report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC of 0.8977 (95% CI: 0.88-0.91). In a robustness test with missing core data, it maintained a 100% valid response rate, far surpassing the 13.4% of a text-only model and showcasing the superiority of its multimodal design. This work demonstrates the substantial potential of deeply fusing physiological signals with large language models, establishing a new paradigm for the next generation of interpretable and reliable clinical decision support tools.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ…¢æ€§é˜»å¡æ€§è‚ºç–¾ç—…(COPD)è¯Šæ–­ä¸­AIæ¨¡å‹ç¼ºä¹è§£é‡ŠåŠ›ä»¥åŠå¤§è¯­è¨€æ¨¡å‹(LLMs)æ— æ³•ç›´æ¥ç†è§£å‘¼å¸é‡è®¡(Spirogram)æ•°æ®çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†é¦–ä¸ªèƒ½ç†è§£Spirogramçš„å¤šæ¨¡æ€æ¨¡å‹SpiroLLMã€‚è¯¥æ¨¡å‹åˆ©ç”¨SpiroEncoderä»å‘¼å¸æ›²çº¿ä¸­æå–å½¢æ€ç‰¹å¾ï¼Œå¹¶é€šè¿‡SpiroProjectorå°†ç‰¹å¾ä¸è‚ºåŠŸèƒ½æµ‹è¯•(PFT)æ•°å€¼åœ¨ç»Ÿä¸€æ½œç©ºé—´ä¸­å¯¹é½ï¼Œä»è€Œä½¿å¤§è¯­è¨€æ¨¡å‹å…·å¤‡ç”Ÿæˆè¯¦ç»†ä¸´åºŠè¯Šæ–­æŠ¥å‘Šçš„èƒ½åŠ›ã€‚åŸºäºUK Biobank (UKB)ä¸­234,028åå—è¯•è€…çš„æ•°æ®ï¼Œå®éªŒè¡¨æ˜SpiroLLMçš„è¯Šæ–­AUROCè¾¾åˆ°äº†0.8977ã€‚åœ¨æ•°æ®ç¼ºå¤±çš„é²æ£’æ€§æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹ä¿æŒäº†100%çš„æœ‰æ•ˆå“åº”ç‡ï¼Œæ˜¾è‘—ä¼˜äºçº¯æ–‡æœ¬æ¨¡å‹çš„13.4%ï¼Œè¯æ˜äº†å¤šæ¨¡æ€è®¾è®¡çš„ä¼˜è¶Šæ€§ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡æ·±åº¦èåˆç”Ÿç†ä¿¡å·ä¸å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸ºå¼€å‘å¯è§£é‡Šã€é«˜å¯é æ€§çš„ä¸´åºŠå†³ç­–æ”¯æŒå·¥å…·å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16145v2",
      "published_date": "2025-07-22 01:44:12 UTC",
      "updated_date": "2025-12-18 14:32:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:22.046197+00:00"
    },
    {
      "arxiv_id": "2507.16136v2",
      "title": "SDBench: A Comprehensive Benchmark Suite for Speaker Diarization",
      "title_zh": "SDBenchï¼šå…¨é¢çš„è¯´è¯äººæ—¥å¿—åŸºå‡†æµ‹è¯•å¥—ä»¶",
      "authors": [
        "Eduardo Pacheco",
        "Atila Orhon",
        "Berkin Durmus",
        "Blaise Munyampirwa",
        "Andrey Leonov"
      ],
      "abstract": "Even state-of-the-art speaker diarization systems exhibit high variance in error rates across different datasets, representing numerous use cases and domains. Furthermore, comparing across systems requires careful application of best practices such as dataset splits and metric definitions to allow for apples-to-apples comparison. We propose SDBench (Speaker Diarization Benchmark), an open-source benchmark suite that integrates 13 diverse datasets with built-in tooling for consistent and fine-grained analysis of speaker diarization performance for various on-device and server-side systems. SDBench enables reproducible evaluation and easy integration of new systems over time. To demonstrate the efficacy of SDBench, we built SpeakerKit, an inference efficiency-focused system built on top of Pyannote v3. SDBench enabled rapid execution of ablation studies that led to SpeakerKit being 9.6x faster than Pyannote v3 while achieving comparable error rates. We benchmark 6 state-of-the-art systems including Deepgram, AWS Transcribe, and Pyannote AI API, revealing important trade-offs between accuracy and speed.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SDBench (Speaker Diarization Benchmark)ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼€æºçš„è¯„æµ‹åŸºå‡†å¥—ä»¶ï¼Œæ—¨åœ¨è§£å†³Speaker Diarizationç³»ç»Ÿåœ¨ä¸åŒæ•°æ®é›†å’Œé¢†åŸŸä¸­è¡¨ç°å·®å¼‚å¤§ä¸”ç¼ºä¹ç»Ÿä¸€è¯„ä¼°æ ‡å‡†çš„é—®é¢˜ã€‚SDBenché›†æˆäº†13ä¸ªå¤šæ ·åŒ–çš„æ•°æ®é›†ï¼Œå¹¶å†…ç½®äº†ç”¨äºä¸€è‡´æ€§ã€ç»†ç²’åº¦æ€§èƒ½åˆ†æçš„å·¥å…·ï¼Œæ”¯æŒå¯¹è®¾å¤‡ç«¯å’ŒæœåŠ¡å™¨ç«¯ç³»ç»Ÿçš„å¯é‡å¤è¯„ä¼°ã€‚ä¸ºäº†å±•ç¤ºSDBenchçš„æ•ˆç”¨ï¼Œç ”ç©¶è€…å¼€å‘äº†åŸºäºPyannote v3çš„SpeakerKitç³»ç»Ÿï¼Œé€šè¿‡å¿«é€Ÿæ¶ˆèå®éªŒä½¿å…¶åœ¨ä¿æŒç›¸å½“é”™è¯¯ç‡çš„æƒ…å†µä¸‹é€Ÿåº¦æå‡äº†9.6å€ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¯¹åŒ…æ‹¬Deepgramã€AWS Transcribeå’ŒPyannote AI APIåœ¨å†…çš„6ä¸ªå‰æ²¿ç³»ç»Ÿè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼Œæ­ç¤ºäº†å„ç³»ç»Ÿåœ¨å‡†ç¡®ç‡ä¸é€Ÿåº¦ä¹‹é—´çš„å…³é”®æƒè¡¡ã€‚è¯¥å¥—ä»¶çš„æ¨å‡ºä¸ºSpeaker Diarizationé¢†åŸŸçš„å…¬å¹³æ¯”è¾ƒå’Œæ–°ç³»ç»Ÿé›†æˆæä¾›äº†å¼ºæœ‰åŠ›çš„æ”¯æŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16136v2",
      "published_date": "2025-07-22 01:11:26 UTC",
      "updated_date": "2025-08-06 16:02:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:39.221045+00:00"
    },
    {
      "arxiv_id": "2507.16130v1",
      "title": "Disability Across Cultures: A Human-Centered Audit of Ableism in Western and Indic LLMs",
      "title_zh": "è·¨æ–‡åŒ–è§†é˜ˆä¸‹çš„æ®‹éšœï¼šè¥¿æ–¹ä¸å°åº¦è¯­ç³»å¤§è¯­è¨€æ¨¡å‹ä¸­å¥å…¨ä¸»ä¹‰çš„ä»¥äººä¸ºæœ¬å®¡è®¡",
      "authors": [
        "Mahika Phutane",
        "Aditya Vashistha"
      ],
      "abstract": "People with disabilities (PwD) experience disproportionately high levels of discrimination and hate online, particularly in India, where entrenched stigma and limited resources intensify these challenges. Large language models (LLMs) are increasingly used to identify and mitigate online hate, yet most research on online ableism focuses on Western audiences with Western AI models. Are these models adequately equipped to recognize ableist harm in non-Western places like India? Do localized, Indic language models perform better? To investigate, we adopted and translated a publicly available ableist speech dataset to Hindi, and prompted eight LLMs--four developed in the U.S. (GPT-4, Gemini, Claude, Llama) and four in India (Krutrim, Nanda, Gajendra, Airavata)--to score and explain ableism. In parallel, we recruited 175 PwD from both the U.S. and India to perform the same task, revealing stark differences between groups. Western LLMs consistently overestimated ableist harm, while Indic LLMs underestimated it. Even more concerning, all LLMs were more tolerant of ableism when it was expressed in Hindi and asserted Western framings of ableist harm. In contrast, Indian PwD interpreted harm through intention, relationality, and resilience--emphasizing a desire to inform and educate perpetrators. This work provides groundwork for global, inclusive standards of ableism, demonstrating the need to center local disability experiences in the design and evaluation of AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹è¥¿æ–¹å’Œå°åº¦å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†æ®‹éšœæ­§è§†(Ableism)æ–¹é¢çš„è¡¨ç°è¿›è¡Œäº†ä»¥äººä¸ºä¸­å¿ƒçš„å®¡è®¡ï¼Œæ—¨åœ¨è¯„ä¼°è¿™äº›æ¨¡å‹è¯†åˆ«éè¥¿æ–¹æ–‡åŒ–èƒŒæ™¯ï¼ˆç‰¹åˆ«æ˜¯å°åº¦ï¼‰ä¸‹æ­§è§†ä¼¤å®³çš„èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿå°†æ­§è§†è¨€è®ºæ•°æ®é›†ç¿»è¯‘ä¸ºå°åœ°è¯­(Hindi)ï¼Œå¯¹æ¯”äº†GPT-4ã€Geminiç­‰è¥¿æ–¹æ¨¡å‹ä¸Krutrimã€Nandaç­‰å°åº¦æœ¬åœŸæ¨¡å‹åœ¨è¯„åˆ†ä¸è§£é‡Šä¸Šçš„å·®å¼‚ï¼Œå¹¶æ‹›å‹Ÿäº†175åç¾å°æ®‹éšœäººå£«(PwD)è¿›è¡Œå¯¹ç…§è¯„ä¼°ã€‚å®éªŒå‘ç°ï¼Œè¥¿æ–¹LLMsæ™®éé«˜ä¼°äº†æ®‹éšœæ­§è§†çš„ä¼¤å®³ç¨‹åº¦ï¼Œè€Œå°åº¦LLMsåˆ™å€¾å‘äºä½ä¼°ï¼Œä¸”æ‰€æœ‰æ¨¡å‹åœ¨å¤„ç†å°åœ°è¯­æ—¶å‡è¡¨ç°å‡ºæ›´é«˜çš„è€å—åº¦å¹¶å›ºå®ˆè¥¿æ–¹è®¤çŸ¥æ¡†æ¶ã€‚ä¸ä¹‹ä¸åŒï¼Œå°åº¦PwDæ›´å€¾å‘äºä»æ„å›¾ã€å…³ç³»æ€§å’ŒéŸ§æ€§è§’åº¦è§£è¯»ä¼¤å®³ï¼Œå¼ºè°ƒé€šè¿‡æ•™è‚²è€Œéå•çº¯æƒ©æˆ’æ¥åº”å¯¹æ­§è§†ã€‚è¯¥å·¥ä½œæ­ç¤ºäº†å½“å‰AIç³»ç»Ÿåœ¨è·¨æ–‡åŒ–ç†è§£æ®‹éšœæ­§è§†æ–¹é¢çš„æ˜¾è‘—å±€é™ï¼Œå¼ºè°ƒäº†åœ¨ç®—æ³•è®¾è®¡ä¸è¯„ä¼°ä¸­çº³å…¥å½“åœ°æ®‹éšœç¾¤ä½“çœŸå®ç»éªŒå¯¹äºæ„å»ºå…¨çƒåŒ…å®¹æ€§æ ‡å‡†çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16130v1",
      "published_date": "2025-07-22 00:51:41 UTC",
      "updated_date": "2025-07-22 00:51:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:51.980151+00:00"
    },
    {
      "arxiv_id": "2507.16126v1",
      "title": "TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task",
      "title_zh": "TaxCalcBenchï¼šè¯„ä¼°å‰æ²¿æ¨¡å‹åœ¨ç¨åŠ¡è®¡ç®—ä»»åŠ¡ä¸­çš„è¡¨ç°",
      "authors": [
        "Michael R. Bock",
        "Kara Molisee",
        "Zachary Ozer",
        "Sumit Shah"
      ],
      "abstract": "Can AI file your taxes? Not yet. Calculating US personal income taxes is a task that requires building an understanding of vast amounts of English text and using that knowledge to carefully compute results. We propose TaxCalcBench, a benchmark for determining models' abilities to calculate personal income tax returns given all of the necessary information. Our experiment shows that state-of-the-art models succeed in calculating less than a third of federal income tax returns even on this simplified sample set. Our analysis concludes that models consistently misuse tax tables, make errors in tax calculation, and incorrectly determine eligibility. Our findings point to the need for additional infrastructure to apply LLMs to the personal income tax calculation task.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† TaxCalcBenchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç¾å›½ä¸ªäººæ‰€å¾—ç¨è®¡ç®—ä»»åŠ¡èƒ½åŠ›çš„åŸºå‡†æµ‹è¯•ã€‚èƒŒæ™¯åœ¨äºè®¡ç®—ä¸ªäººæ‰€å¾—ç¨éœ€è¦ä»æµ·é‡è‹±æ–‡æ–‡æœ¬ä¸­æå–çŸ¥è¯†å¹¶è¿›è¡Œä¸¥è°¨è®¡ç®—ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå³ä½¿åœ¨ç®€åŒ–çš„æ ·æœ¬é›†ä¸Šï¼Œç›®å‰çš„å°–ç«¯æ¨¡å‹åœ¨è”é‚¦æ‰€å¾—ç¨ç”³æŠ¥è®¡ç®—ä¸­çš„æˆåŠŸç‡ä¹Ÿä½äºä¸‰åˆ†ä¹‹ä¸€ã€‚ç ”ç©¶åˆ†ææŒ‡å‡ºï¼Œæ¨¡å‹åœ¨è®¡ç®—è¿‡ç¨‹ä¸­é¢‘ç¹å‡ºç°é”™è¯¯ä½¿ç”¨ç¨ç‡è¡¨(tax tables)ã€æ•°å­¦è®¡ç®—å¤±è¯¯ä»¥åŠå¯¹çº³ç¨èµ„æ ¼(eligibility)åˆ¤æ–­é”™è¯¯ç­‰é—®é¢˜ã€‚è¿™äº›å‘ç°è¡¨æ˜å¤§è¯­è¨€æ¨¡å‹åœ¨æ²¡æœ‰é¢å¤–åŸºç¡€è®¾æ–½æ”¯æŒçš„æƒ…å†µä¸‹ï¼Œå°šä¸è¶³ä»¥ç‹¬ç«‹å®Œæˆå¤æ‚çš„ç¨åŠ¡è®¡ç®—ä»»åŠ¡ï¼ŒæŒ‡å‡ºäº†å°† LLMs åº”ç”¨äºç¨åŠ¡é¢†åŸŸä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2507.16126v1",
      "published_date": "2025-07-22 00:37:59 UTC",
      "updated_date": "2025-07-22 00:37:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:41.210363+00:00"
    },
    {
      "arxiv_id": "2507.16124v3",
      "title": "Benchmarking LLM Privacy Recognition for Social Robot Decision Making",
      "title_zh": "é¢å‘ç¤¾äº¤æœºå™¨äººå†³ç­–çš„å¤§è¯­è¨€æ¨¡å‹éšç§è¯†åˆ«åŸºå‡†æµ‹è¯•",
      "authors": [
        "Dakota Sullivan",
        "Shirley Zhang",
        "Jennica Li",
        "Heather Kirkorian",
        "Bilge Mutlu",
        "Kassem Fawaz"
      ],
      "abstract": "While robots have previously utilized rule-based systems or probabilistic models for user interaction, the rapid evolution of large language models (LLMs) presents new opportunities to develop LLM-powered robots for enhanced human-robot interaction (HRI). To fully realize these capabilities, however, robots need to collect data such as audio, fine-grained images, video, and locations. As a result, LLMs often process sensitive personal information, particularly within private environments, such as homes. Given the tension between utility and privacy risks, evaluating how current LLMs manage sensitive data is critical. Specifically, we aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the context of household robots. In this work, we present a set of privacy-relevant scenarios developed using the Contextual Integrity (CI) framework. We first surveyed users' privacy preferences regarding in-home robot behaviors and then examined how their privacy orientations affected their choices of these behaviors (N = 450). We then provided the same set of scenarios and questions to state-of-the-art LLMs (N = 10) and found that the agreement between humans and LLMs was generally low. To further investigate the capabilities of LLMs as potential privacy controllers, we implemented four additional prompting strategies and compared their results. We discuss the performance of the evaluated models as well as the implications and potential of AI privacy awareness in human-robot interaction.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨ç¤¾äº¤æœºå™¨äººå†³ç­–è¿‡ç¨‹ä¸­ï¼Œå¤§è¯­è¨€æ¨¡å‹(LLMs)è¯†åˆ«å¹¶å¤„ç†æ•æ„Ÿéšç§æ•°æ®çš„èƒ½åŠ›ï¼Œé‡ç‚¹å…³æ³¨å®¶åº­ç­‰ç§å¯†ç¯å¢ƒä¸‹çš„é£é™©ã€‚ç ”ç©¶é‡‡ç”¨è¯­å¢ƒå®Œæ•´æ€§(Contextual Integrity, CI)æ¡†æ¶è®¾è®¡äº†å¤šç§éšç§åœºæ™¯ï¼Œé¦–å…ˆé€šè¿‡è°ƒç ”450åç”¨æˆ·çš„éšç§åå¥½å»ºç«‹äº†åŸºå‡†ï¼Œéšåè¯„ä¼°äº†10ä¸ªå…ˆè¿›çš„LLMsåœ¨ç›¸åŒæƒ…å¢ƒä¸‹çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œç°æœ‰æ¨¡å‹åœ¨éšç§å†³ç­–ä¸Šä¸äººç±»çš„è¾¾æˆåº¦æ™®éè¾ƒä½ï¼Œæš´éœ²å‡ºæ˜¾è‘—çš„è®¤çŸ¥å·®å¼‚ã€‚ä¸ºæå‡LLMsä½œä¸ºéšç§æ§åˆ¶å™¨(privacy controllers)çš„æ•ˆèƒ½ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¯¹æ¯”äº†å››ç§ä¸åŒçš„æç¤ºç­–ç•¥(prompting strategies)ï¼Œæ·±å…¥åˆ†æäº†å½“å‰äººå·¥æ™ºèƒ½åœ¨äººæœºäº¤äº’(HRI)ä¸­å®ç°éšç§æ„è¯†çš„ç°çŠ¶ä¸æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "18 pages, 7 figures. Dakota Sullivan and Shirley Zhang contributed equally to this work",
      "pdf_url": "https://arxiv.org/pdf/2507.16124v3",
      "published_date": "2025-07-22 00:36:59 UTC",
      "updated_date": "2025-11-17 15:01:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T06:20:44.334763+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 154,
  "processed_papers_count": 154,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T06:21:40.062733+00:00"
}