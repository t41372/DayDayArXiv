[
  {
    "arxiv_id": "2504.05559v1",
    "title": "SciSciGPT: Advancing Human-AI Collaboration in the Science of Science",
    "authors": [
      "Erzhuo Shao",
      "Yifang Wang",
      "Yifan Qian",
      "Zhenyu Pan",
      "Han Liu",
      "Dashun Wang"
    ],
    "abstract": "The increasing availability of large-scale datasets has fueled rapid progress\nacross many scientific fields, creating unprecedented opportunities for\nresearch and discovery while posing significant analytical challenges. Recent\nadvances in large language models (LLMs) and AI agents have opened new\npossibilities for human-AI collaboration, offering powerful tools to navigate\nthis complex research landscape. In this paper, we introduce SciSciGPT, an\nopen-source, prototype AI collaborator that uses the science of science as a\ntestbed to explore the potential of LLM-powered research tools. SciSciGPT\nautomates complex workflows, supports diverse analytical approaches,\naccelerates research prototyping and iteration, and facilitates\nreproducibility. Through case studies, we demonstrate its ability to streamline\na wide range of empirical and analytical research tasks while highlighting its\nbroader potential to advance research. We further propose an LLM Agent\ncapability maturity model for human-AI collaboration, envisioning a roadmap to\nfurther improve and expand upon frameworks like SciSciGPT. As AI capabilities\ncontinue to evolve, frameworks like SciSciGPT may play increasingly pivotal\nroles in scientific research and discovery, unlocking further opportunities. At\nthe same time, these new advances also raise critical challenges, from ensuring\ntransparency and ethical use to balancing human and AI contributions.\nAddressing these issues may shape the future of scientific inquiry and inform\nhow we train the next generation of scientists to thrive in an increasingly\nAI-integrated research ecosystem.",
    "categories": [
      "cs.AI",
      "I.2; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05559v1",
    "published_date": "2025-04-07 23:19:39 UTC",
    "updated_date": "2025-04-07 23:19:39 UTC"
  },
  {
    "arxiv_id": "2504.05550v1",
    "title": "Path Database Guidance for Motion Planning",
    "authors": [
      "Amnon Attali",
      "Praval Telagi",
      "Marco Morales",
      "Nancy M. Amato"
    ],
    "abstract": "One approach to using prior experience in robot motion planning is to store\nsolutions to previously seen problems in a database of paths. Methods that use\nsuch databases are characterized by how they query for a path and how they use\nqueries given a new problem. In this work we present a new method, Path\nDatabase Guidance (PDG), which innovates on existing work in two ways. First,\nwe use the database to compute a heuristic for determining which nodes of a\nsearch tree to expand, in contrast to prior work which generally pastes the\n(possibly transformed) queried path or uses it to bias a sampling distribution.\nWe demonstrate that this makes our method more easily composable with other\nsearch methods by dynamically interleaving exploration according to a baseline\nalgorithm with exploitation of the database guidance. Second, in contrast to\nother methods that treat the database as a single fixed prior, our database\n(and thus our queried heuristic) updates as we search the implicitly defined\nrobot configuration space. We experimentally demonstrate the effectiveness of\nPDG in a variety of explicitly defined environment distributions in simulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05550v1",
    "published_date": "2025-04-07 23:00:31 UTC",
    "updated_date": "2025-04-07 23:00:31 UTC"
  },
  {
    "arxiv_id": "2504.07137v1",
    "title": "Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering",
    "authors": [
      "Hamed Jelodar",
      "Samita Bai",
      "Parisa Hamedi",
      "Hesamodin Mohammadian",
      "Roozbeh Razavi-Far",
      "Ali Ghorbani"
    ],
    "abstract": "Large Language Models (LLMs) have recently emerged as powerful tools in\ncybersecurity, offering advanced capabilities in malware detection, generation,\nand real-time monitoring. Numerous studies have explored their application in\ncybersecurity, demonstrating their effectiveness in identifying novel malware\nvariants, analyzing malicious code structures, and enhancing automated threat\nanalysis. Several transformer-based architectures and LLM-driven models have\nbeen proposed to improve malware analysis, leveraging semantic and structural\ninsights to recognize malicious intent more accurately. This study presents a\ncomprehensive review of LLM-based approaches in malware code analysis,\nsummarizing recent advancements, trends, and methodologies. We examine notable\nscholarly works to map the research landscape, identify key challenges, and\nhighlight emerging innovations in LLM-driven cybersecurity. Additionally, we\nemphasize the role of static analysis in malware detection, introduce notable\ndatasets and specialized LLM models, and discuss essential datasets supporting\nautomated malware research. This study serves as a valuable resource for\nresearchers and cybersecurity professionals, offering insights into LLM-powered\nmalware detection and defence strategies while outlining future directions for\nstrengthening cybersecurity resilience.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07137v1",
    "published_date": "2025-04-07 22:32:46 UTC",
    "updated_date": "2025-04-07 22:32:46 UTC"
  },
  {
    "arxiv_id": "2504.05537v1",
    "title": "Towards Efficient Real-Time Video Motion Transfer via Generative Time Series Modeling",
    "authors": [
      "Tasmiah Haque",
      "Md. Asif Bin Syed",
      "Byungheon Jeong",
      "Xue Bai",
      "Sumit Mohan",
      "Somdyuti Paul",
      "Imtiaz Ahmed",
      "Srinjoy Das"
    ],
    "abstract": "We propose a deep learning framework designed to significantly optimize\nbandwidth for motion-transfer-enabled video applications, including video\nconferencing, virtual reality interactions, health monitoring systems, and\nvision-based real-time anomaly detection. To capture complex motion\neffectively, we utilize the First Order Motion Model (FOMM), which encodes\ndynamic objects by detecting keypoints and their associated local affine\ntransformations. These keypoints are identified using a self-supervised\nkeypoint detector and arranged into a time series corresponding to the\nsuccessive frames. Forecasting is performed on these keypoints by integrating\ntwo advanced generative time series models into the motion transfer pipeline,\nnamely the Variational Recurrent Neural Network (VRNN) and the Gated Recurrent\nUnit with Normalizing Flow (GRU-NF). The predicted keypoints are subsequently\nsynthesized into realistic video frames using an optical flow estimator paired\nwith a generator network, thereby facilitating accurate video forecasting and\nenabling efficient, low-frame-rate video transmission. We validate our results\nacross three datasets for video animation and reconstruction using the\nfollowing metrics: Mean Absolute Error, Joint Embedding Predictive Architecture\nEmbedding Distance, Structural Similarity Index, and Average Pair-wise\nDisplacement. Our results confirm that by utilizing the superior reconstruction\nproperty of the Variational Autoencoder, the VRNN integrated FOMM excels in\napplications involving multi-step ahead forecasts such as video conferencing.\nOn the other hand, by leveraging the Normalizing Flow architecture for exact\nlikelihood estimation, and enabling efficient latent space sampling, the GRU-NF\nbased FOMM exhibits superior capabilities for producing diverse future samples\nwhile maintaining high visual quality for tasks like real-time video-based\nanomaly detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05537v1",
    "published_date": "2025-04-07 22:21:54 UTC",
    "updated_date": "2025-04-07 22:21:54 UTC"
  },
  {
    "arxiv_id": "2504.05530v1",
    "title": "FORCE: Feature-Oriented Representation with Clustering and Explanation",
    "authors": [
      "Rishav Mukherjee",
      "Jeffrey Ahearn Thompson"
    ],
    "abstract": "Learning about underlying patterns in data using latent unobserved structures\nto improve the accuracy of predictive models has become an active avenue of\ndeep learning research. Most approaches cluster the original features to\ncapture certain latent structures. However, the information gained in the\nprocess can often be implicitly derived by sufficiently complex models. Thus,\nsuch approaches often provide minimal benefits. We propose a SHAP (Shapley\nAdditive exPlanations) based supervised deep learning framework FORCE which\nrelies on two-stage usage of SHAP values in the neural network architecture,\n(i) an additional latent feature to guide model training, based on clustering\nSHAP values, and (ii) initiating an attention mechanism within the architecture\nusing latent information. This approach gives a neural network an indication\nabout the effect of unobserved values that modify feature importance for an\nobservation. The proposed framework is evaluated on three real life datasets.\nOur results demonstrate that FORCE led to dramatic improvements in overall\nperformance as compared to networks that did not incorporate the latent feature\nand attention framework (e.g., F1 score for presence of heart disease 0.80 vs\n0.72). Using cluster assignments and attention based on SHAP values guides deep\nlearning, enhancing latent pattern learning and overall discriminative\ncapability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05530v1",
    "published_date": "2025-04-07 22:05:50 UTC",
    "updated_date": "2025-04-07 22:05:50 UTC"
  },
  {
    "arxiv_id": "2504.05527v1",
    "title": "Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents",
    "authors": [
      "Despina Tomkou",
      "George Fatouros",
      "Andreas Andreou",
      "Georgios Makridis",
      "Fotis Liarokapis",
      "Dimitrios Dardanis",
      "Athanasios Kiourtis",
      "John Soldatos",
      "Dimosthenis Kyriazis"
    ],
    "abstract": "This paper introduces a novel integration of Retrieval-Augmented Generation\n(RAG) enhanced Large Language Models (LLMs) with Extended Reality (XR)\ntechnologies to address knowledge transfer challenges in industrial\nenvironments. The proposed system embeds domain-specific industrial knowledge\ninto XR environments through a natural language interface, enabling hands-free,\ncontext-aware expert guidance for workers. We present the architecture of the\nproposed system consisting of an LLM Chat Engine with dynamic tool\norchestration and an XR application featuring voice-driven interaction.\nPerformance evaluation of various chunking strategies, embedding models, and\nvector databases reveals that semantic chunking, balanced embedding models, and\nefficient vector stores deliver optimal performance for industrial knowledge\nretrieval. The system's potential is demonstrated through early implementation\nin multiple industrial use cases, including robotic assembly, smart\ninfrastructure maintenance, and aerospace component servicing. Results indicate\npotential for enhancing training efficiency, remote assistance capabilities,\nand operational guidance in alignment with Industry 5.0's human-centric and\nresilient approach to industrial development.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T40, 68U20, 68U35",
      "H.5.1; I.2.7; I.2.11; H.3.3; H.5.2; C.3"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05527v1",
    "published_date": "2025-04-07 22:02:19 UTC",
    "updated_date": "2025-04-07 22:02:19 UTC"
  },
  {
    "arxiv_id": "2504.06308v1",
    "title": "Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Encoding",
    "authors": [
      "Haiping Liu",
      "Hongpeng Zhou"
    ],
    "abstract": "Rotary Position Embedding (RoPE) is widely adopted in Transformers due to its\nability to encode relative positions with high efficiency and extrapolation\ncapability. However, existing RoPE variants lack a unified theoretical\nfoundation, especially in higher dimensions. In this paper, we propose a\nsystematic mathematical framework for RoPE grounded in Lie group and Lie\nalgebra theory. We identify two core properties of RoPE, named relativity and\nreversibility, and derive general constraints and constructions for valid RoPE\nin 1D, 2D, and N-dimensional (ND). We prove that RoPE must lie in the basis of\na maximal abelian subalgebra (MASA) of the special orthogonal Lie algebra, and\nshow that standard RoPE corresponds to the maximal toral subalgebra.\nFurthermore, we propose to model inter-dimensional interactions by learning an\northogonal basis transformation. Our framework unifies and explains existing\nRoPE designs, while enabling principled extensions to new modalities and tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06308v1",
    "published_date": "2025-04-07 21:58:22 UTC",
    "updated_date": "2025-04-07 21:58:22 UTC"
  },
  {
    "arxiv_id": "2504.06307v1",
    "title": "Optimizing Large Language Models: Metrics, Energy Efficiency, and Case Study Insights",
    "authors": [
      "Tahniat Khan",
      "Soroor Motie",
      "Sedef Akinli Kocak",
      "Shaina Raza"
    ],
    "abstract": "The rapid adoption of large language models (LLMs) has led to significant\nenergy consumption and carbon emissions, posing a critical challenge to the\nsustainability of generative AI technologies. This paper explores the\nintegration of energy-efficient optimization techniques in the deployment of\nLLMs to address these environmental concerns. We present a case study and\nframework that demonstrate how strategic quantization and local inference\ntechniques can substantially lower the carbon footprints of LLMs without\ncompromising their operational effectiveness. Experimental results reveal that\nthese methods can reduce energy consumption and carbon emissions by up to 45\\%\npost quantization, making them particularly suitable for resource-constrained\nenvironments. The findings provide actionable insights for achieving\nsustainability in AI while maintaining high levels of accuracy and\nresponsiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06307v1",
    "published_date": "2025-04-07 21:56:59 UTC",
    "updated_date": "2025-04-07 21:56:59 UTC"
  },
  {
    "arxiv_id": "2504.05521v2",
    "title": "Deep Reinforcement Learning Algorithms for Option Hedging",
    "authors": [
      "Andrei Neagu",
      "Frédéric Godin",
      "Leila Kosseim"
    ],
    "abstract": "Dynamic hedging is a financial strategy that consists in periodically\ntransacting one or multiple financial assets to offset the risk associated with\na correlated liability. Deep Reinforcement Learning (DRL) algorithms have been\nused to find optimal solutions to dynamic hedging problems by framing them as\nsequential decision-making problems. However, most previous work assesses the\nperformance of only one or two DRL algorithms, making an objective comparison\nacross algorithms difficult. In this paper, we compare the performance of eight\nDRL algorithms in the context of dynamic hedging; Monte Carlo Policy Gradient\n(MCPG), Proximal Policy Optimization (PPO), along with four variants of Deep\nQ-Learning (DQL) and two variants of Deep Deterministic Policy Gradient (DDPG).\nTwo of these variants represent a novel application to the task of dynamic\nhedging. In our experiments, we use the Black-Scholes delta hedge as a baseline\nand simulate the dataset using a GJR-GARCH(1,1) model. Results show that MCPG,\nfollowed by PPO, obtain the best performance in terms of the root\nsemi-quadratic penalty. Moreover, MCPG is the only algorithm to outperform the\nBlack-Scholes delta hedge baseline with the allotted computational budget,\npossibly due to the sparsity of rewards in our environment.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05521v2",
    "published_date": "2025-04-07 21:32:14 UTC",
    "updated_date": "2025-04-17 00:36:34 UTC"
  },
  {
    "arxiv_id": "2504.16939v1",
    "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions",
    "authors": [
      "Emre Can Acikgoz",
      "Cheng Qian",
      "Hongru Wang",
      "Vardhan Dongre",
      "Xiusi Chen",
      "Heng Ji",
      "Dilek Hakkani-Tür",
      "Gokhan Tur"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have propelled conversational\nAI from traditional dialogue systems into sophisticated agents capable of\nautonomous actions, contextual awareness, and multi-turn interactions with\nusers. Yet, fundamental questions about their capabilities, limitations, and\npaths forward remain open. This survey paper presents a desideratum for\nnext-generation Conversational Agents - what has been achieved, what challenges\npersist, and what must be done for more scalable systems that approach\nhuman-level intelligence. To that end, we systematically analyze LLM-driven\nConversational Agents by organizing their capabilities into three primary\ndimensions: (i) Reasoning - logical, systematic thinking inspired by human\nintelligence for decision making, (ii) Monitor - encompassing self-awareness\nand user interaction monitoring, and (iii) Control - focusing on tool\nutilization and policy following. Building upon this, we introduce a novel\ntaxonomy by classifying recent work on Conversational Agents around our\nproposed desideratum. We identify critical research gaps and outline key\ndirections, including realistic evaluations, long-term multi-turn reasoning\nskills, self-evolution capabilities, collaborative and multi-agent task\ncompletion, personalization, and proactivity. This work aims to provide a\nstructured foundation, highlight existing limitations, and offer insights into\npotential future research directions for Conversational Agents, ultimately\nadvancing progress toward Artificial General Intelligence (AGI). We maintain a\ncurated repository of papers at:\nhttps://github.com/emrecanacikgoz/awesome-conversational-agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16939v1",
    "published_date": "2025-04-07 21:01:25 UTC",
    "updated_date": "2025-04-07 21:01:25 UTC"
  },
  {
    "arxiv_id": "2504.05500v2",
    "title": "Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search",
    "authors": [
      "Vahid Majdinasab",
      "Amin Nikanjam",
      "Foutse Khomh"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has outpaced\ntraditional evaluation methods. Static benchmarks fail to capture the depth and\nbreadth of LLM capabilities and eventually become obsolete, while most dynamic\napproaches either rely too heavily on LLM-based evaluation or remain\nconstrained by predefined test sets. We introduce Prism, a flexible, dynamic\nbenchmarking framework designed for comprehensive LLM assessment. Prism builds\non three key components: (1) a tree-based state representation that models\nevaluation as a Markov Decision Process, (2) a Monte Carlo Tree Search\nalgorithm adapted to uncover challenging evaluation scenarios, and (3) a\nmulti-agent evaluation pipeline that enables simultaneous assessment of diverse\ncapabilities. To ensure robust evaluation, Prism integrates structural\nmeasurements of tree exploration patterns with performance metrics across\ndifficulty levels, providing detailed diagnostics of error patterns, test\ncoverage, and solution approaches. Through extensive experiments on five\nstate-of-the-art LLMs, we analyze how model architecture and scale influence\ncode generation performance across varying task difficulties. Our results\ndemonstrate Prism's effectiveness as a dynamic benchmark that evolves with\nmodel advancements while offering deeper insights into their limitations.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05500v2",
    "published_date": "2025-04-07 20:53:18 UTC",
    "updated_date": "2025-04-10 01:06:05 UTC"
  },
  {
    "arxiv_id": "2504.06306v1",
    "title": "Predicting Survivability of Cancer Patients with Metastatic Patterns Using Explainable AI",
    "authors": [
      "Polycarp Nalela",
      "Deepthi Rao",
      "Praveen Rao"
    ],
    "abstract": "Cancer remains a leading global health challenge and a major cause of\nmortality. This study leverages machine learning (ML) to predict the\nsurvivability of cancer patients with metastatic patterns using the\ncomprehensive MSK-MET dataset, which includes genomic and clinical data from\n25,775 patients across 27 cancer types. We evaluated five ML models-XGBoost,\nNa\\\"ive Bayes, Decision Tree, Logistic Regression, and Random Fores using\nhyperparameter tuning and grid search. XGBoost emerged as the best performer\nwith an area under the curve (AUC) of 0.82. To enhance model interpretability,\nSHapley Additive exPlanations (SHAP) were applied, revealing key predictors\nsuch as metastatic site count, tumor mutation burden, fraction of genome\naltered, and organ-specific metastases. Further survival analysis using\nKaplan-Meier curves, Cox Proportional Hazards models, and XGBoost Survival\nAnalysis identified significant predictors of patient outcomes, offering\nactionable insights for clinicians. These findings could aid in personalized\nprognosis and treatment planning, ultimately improving patient care.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06306v1",
    "published_date": "2025-04-07 20:48:15 UTC",
    "updated_date": "2025-04-07 20:48:15 UTC"
  },
  {
    "arxiv_id": "2504.16938v1",
    "title": "Rational Inference in Formal Concept Analysis",
    "authors": [
      "Lucas Carr",
      "Nicholas Leisegang",
      "Thomas Meyer",
      "Sergei Obiedkov"
    ],
    "abstract": "Defeasible conditionals are a form of non-monotonic inference which enable\nthe expression of statements like \"if $\\phi$ then normally $\\psi$\". The KLM\nframework defines a semantics for the propositional case of defeasible\nconditionals by construction of a preference ordering over possible worlds. The\npattern of reasoning induced by these semantics is characterised by consequence\nrelations satisfying certain desirable properties of non-monotonic reasoning.\nIn FCA, implications are used to describe dependencies between attributes.\nHowever, these implications are unsuitable to reason with erroneous data or\ndata prone to exceptions. Until recently, the topic of non-monotonic inference\nin FCA has remained largely uninvestigated. In this paper, we provide a\nconstruction of the KLM framework for defeasible reasoning in FCA and show that\nthis construction remains faithful to the principle of non-monotonic inference\ndescribed in the original framework. We present an additional argument that,\nwhile remaining consistent with the original ideas around non-monotonic\nreasoning, the defeasible reasoning we propose in FCA offers a more contextual\nview on inference, providing the ability for more relevant conclusions to be\ndrawn when compared to the propositional case.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16938v1",
    "published_date": "2025-04-07 20:15:20 UTC",
    "updated_date": "2025-04-07 20:15:20 UTC"
  },
  {
    "arxiv_id": "2504.06305v1",
    "title": "Well2Flow: Reconstruction of reservoir states from sparse wells using score-based generative models",
    "authors": [
      "Shiqin Zeng",
      "Haoyun Li",
      "Abhinav Prakash Gahlot",
      "Felix J. Herrmann"
    ],
    "abstract": "This study investigates the use of score-based generative models for\nreservoir simulation, with a focus on reconstructing spatially varying\npermeability and saturation fields in saline aquifers, inferred from sparse\nobservations at two well locations. By modeling the joint distribution of\npermeability and saturation derived from high-fidelity reservoir simulations,\nthe proposed neural network is trained to learn the complex spatiotemporal\ndynamics governing multiphase fluid flow in porous media. During inference, the\nframework effectively reconstructs both permeability and saturation fields by\nconditioning on sparse vertical profiles extracted from well log data. This\napproach introduces a novel methodology for incorporating physical constraints\nand well log guidance into generative models, significantly enhancing the\naccuracy and physical plausibility of the reconstructed subsurface states.\nFurthermore, the framework demonstrates strong generalization capabilities\nacross varying geological scenarios, highlighting its potential for practical\ndeployment in data-scarce reservoir management tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06305v1",
    "published_date": "2025-04-07 20:12:19 UTC",
    "updated_date": "2025-04-07 20:12:19 UTC"
  },
  {
    "arxiv_id": "2504.05455v1",
    "title": "Large-Scale Classification of Shortwave Communication Signals with Machine Learning",
    "authors": [
      "Stefan Scholl"
    ],
    "abstract": "This paper presents a deep learning approach to the classification of 160\nshortwave radio signals. It addresses the typical challenges of the shortwave\nspectrum, which are the large number of different signal types, the presence of\nvarious analog modulations and ionospheric propagation. As a classifier a deep\nconvolutional neural network is used, that is trained to recognize 160 typical\nshortwave signal classes. The approach is blind and therefore does not require\npreknowledge or special preprocessing of the signal and no manual design of\ndiscriminative features for each signal class. The network is trained on a\nlarge number of synthetically generated signals and high quality recordings.\nFinally, the network is evaluated on real-world radio signals obtained from\nglobally deployed receiver hardware and achieves up to 90% accuracy for an\nobservation time of only 1 second.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05455v1",
    "published_date": "2025-04-07 19:45:08 UTC",
    "updated_date": "2025-04-07 19:45:08 UTC"
  },
  {
    "arxiv_id": "2504.05454v1",
    "title": "GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction",
    "authors": [
      "Yoshitaka Inoue",
      "Tianfan Fu",
      "Augustin Luna"
    ],
    "abstract": "Explainability is necessary for many tasks in biomedical research. Recent\nexplainability methods have focused on attention, gradient, and Shapley value.\nThese do not handle data with strong associated prior knowledge and fail to\nconstrain explainability results based on known relationships between\npredictive features.\n  We propose GraphPINE, a graph neural network (GNN) architecture leveraging\ndomain-specific prior knowledge to initialize node importance optimized during\ntraining for drug response prediction. Typically, a manual post-prediction step\nexamines literature (i.e., prior knowledge) to understand returned predictive\nfeatures. While node importance can be obtained for gradient and attention\nafter prediction, node importance from these methods lacks complementary prior\nknowledge; GraphPINE seeks to overcome this limitation. GraphPINE differs from\nother GNN gating methods by utilizing an LSTM-like sequential format. We\nintroduce an importance propagation layer that unifies 1) updates for feature\nmatrix and node importance and 2) uses GNN-based graph propagation of feature\nvalues. This initialization and updating mechanism allows for informed feature\nlearning and improved graph representation.\n  We apply GraphPINE to cancer drug response prediction using drug screening\nand gene data collected for over 5,000 gene nodes included in a gene-gene graph\nwith a drug-target interaction (DTI) graph for initial importance. The\ngene-gene graph and DTIs were obtained from curated sources and weighted by\narticle count discussing relationships between drugs and genes. GraphPINE\nachieves a PR-AUC of 0.894 and ROC-AUC of 0.796 across 952 drugs. Code is\navailable at https://anonymous.4open.science/r/GraphPINE-40DE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05454v1",
    "published_date": "2025-04-07 19:42:12 UTC",
    "updated_date": "2025-04-07 19:42:12 UTC"
  },
  {
    "arxiv_id": "2504.05425v1",
    "title": "A Behavior-Based Knowledge Representation Improves Prediction of Players' Moves in Chess by 25%",
    "authors": [
      "Benny Skidanov",
      "Daniel Erbesfeld",
      "Gera Weiss",
      "Achiya Elyasaf"
    ],
    "abstract": "Predicting player behavior in strategic games, especially complex ones like\nchess, presents a significant challenge. The difficulty arises from several\nfactors. First, the sheer number of potential outcomes stemming from even a\nsingle position, starting from the initial setup, makes forecasting a player's\nnext move incredibly complex. Second, and perhaps even more challenging, is the\ninherent unpredictability of human behavior. Unlike the optimized play of\nengines, humans introduce a layer of variability due to differing playing\nstyles and decision-making processes. Each player approaches the game with a\nunique blend of strategic thinking, tactical awareness, and psychological\ntendencies, leading to diverse and often unexpected actions. This stylistic\nvariation, combined with the capacity for creativity and even irrational moves,\nmakes predicting human play difficult. Chess, a longstanding benchmark of\nartificial intelligence research, has seen significant advancements in tools\nand automation. Engines like Deep Blue, AlphaZero, and Stockfish can defeat\neven the most skilled human players. However, despite their exceptional ability\nto outplay top-level grandmasters, predicting the moves of non-grandmaster\nplayers, who comprise most of the global chess community -- remains complicated\nfor these engines. This paper proposes a novel approach combining expert\nknowledge with machine learning techniques to predict human players' next\nmoves. By applying feature engineering grounded in domain expertise, we seek to\nuncover the patterns in the moves of intermediate-level chess players,\nparticularly during the opening phase of the game. Our methodology offers a\npromising framework for anticipating human behavior, advancing both the fields\nof AI and human-computer interaction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 2 tables, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05425v1",
    "published_date": "2025-04-07 18:49:00 UTC",
    "updated_date": "2025-04-07 18:49:00 UTC"
  },
  {
    "arxiv_id": "2504.05424v1",
    "title": "Safe Automated Refactoring for Efficient Migration of Imperative Deep Learning Programs to Graph Execution",
    "authors": [
      "Raffi Khatchadourian",
      "Tatiana Castro Vélez",
      "Mehdi Bagherzadeh",
      "Nan Jia",
      "Anita Raja"
    ],
    "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing\ndatasets, especially for Deep Learning (DL) systems. DL frameworks have\ntraditionally embraced deferred execution-style DL code -- supporting symbolic,\ngraph-based Deep Neural Network (DNN) computation. While scalable, such\ndevelopment is error-prone, non-intuitive, and difficult to debug.\nConsequently, more natural, imperative DL frameworks encouraging eager\nexecution have emerged at the expense of run-time performance. Though hybrid\napproaches aim for the \"best of both worlds,\" using them effectively requires\nsubtle considerations to make code amenable to safe, accurate, and efficient\ngraph execution. We present an automated refactoring approach that assists\ndevelopers in specifying whether their otherwise eagerly-executed imperative DL\ncode could be reliably and efficiently executed as graphs while preserving\nsemantics. The approach, based on a novel imperative tensor analysis,\nautomatically determines when it is safe and potentially advantageous to\nmigrate imperative DL code to graph execution. The approach is implemented as a\nPyDev Eclipse IDE plug-in that integrates the WALA Ariadne analysis framework\nand evaluated on 19 Python projects consisting of 132.05 KLOC. We found that\n326 of 766 candidate functions (42.56%) were refactorable, and an average\nspeedup of 2.16 on performance tests was observed. The results indicate that\nthe approach is useful in optimizing imperative DL code to its full potential.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL",
      "D.2.7; C.4; D.3.4; I.2.6"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05424v1",
    "published_date": "2025-04-07 18:48:43 UTC",
    "updated_date": "2025-04-07 18:48:43 UTC"
  },
  {
    "arxiv_id": "2504.05420v1",
    "title": "PreSumm: Predicting Summarization Performance Without Summarizing",
    "authors": [
      "Steven Koniaev",
      "Ori Ernst",
      "Jackie Chi Kit Cheung"
    ],
    "abstract": "Despite recent advancements in automatic summarization, state-of-the-art\nmodels do not summarize all documents equally well, raising the question: why?\nWhile prior research has extensively analyzed summarization models, little\nattention has been given to the role of document characteristics in influencing\nsummarization performance. In this work, we explore two key research questions.\nFirst, do documents exhibit consistent summarization quality across multiple\nsystems? If so, can we predict a document's summarization performance without\ngenerating a summary? We answer both questions affirmatively and introduce\nPreSumm, a novel task in which a system predicts summarization performance\nbased solely on the source document. Our analysis sheds light on common\nproperties of documents with low PreSumm scores, revealing that they often\nsuffer from coherence issues, complex content, or a lack of a clear main theme.\nIn addition, we demonstrate PreSumm's practical utility in two key\napplications: improving hybrid summarization workflows by identifying documents\nthat require manual summarization and enhancing dataset quality by filtering\noutliers and noisy documents. Overall, our findings highlight the critical role\nof document properties in summarization performance and offer insights into the\nlimitations of current systems that could serve as the basis for future\nimprovements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05420v1",
    "published_date": "2025-04-07 18:43:00 UTC",
    "updated_date": "2025-04-07 18:43:00 UTC"
  },
  {
    "arxiv_id": "2504.05419v1",
    "title": "Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification",
    "authors": [
      "Anqi Zhang",
      "Yulin Chen",
      "Jane Pan",
      "Chen Zhao",
      "Aurojit Panda",
      "Jinyang Li",
      "He He"
    ],
    "abstract": "Reasoning models have achieved remarkable performance on tasks like math and\nlogical reasoning thanks to their ability to search during reasoning. However,\nthey still suffer from overthinking, often performing unnecessary reasoning\nsteps even after reaching the correct answer. This raises the question: can\nmodels evaluate the correctness of their intermediate answers during reasoning?\nIn this work, we study whether reasoning models encode information about answer\ncorrectness through probing the model's hidden states. The resulting probe can\nverify intermediate answers with high accuracy and produces highly calibrated\nscores. Additionally, we find models' hidden states encode correctness of\nfuture answers, enabling early prediction of the correctness before the\nintermediate answer is fully formulated. We then use the probe as a verifier to\ndecide whether to exit reasoning at intermediate answers during inference,\nreducing the number of inference tokens by 24\\% without compromising\nperformance. These findings confirm that reasoning models do encode a notion of\ncorrectness yet fail to exploit it, revealing substantial untapped potential to\nenhance their efficiency.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05419v1",
    "published_date": "2025-04-07 18:42:01 UTC",
    "updated_date": "2025-04-07 18:42:01 UTC"
  },
  {
    "arxiv_id": "2504.07992v1",
    "title": "'Neural howlround' in large language models: a self-reinforcing bias phenomenon, and a dynamic attenuation solution",
    "authors": [
      "Seth Drake"
    ],
    "abstract": "Large language model (LLM)-driven AI systems may exhibit an inference failure\nmode we term `neural howlround,' a self-reinforcing cognitive loop where\ncertain highly weighted inputs become dominant, leading to entrenched response\npatterns resistant to correction. This paper explores the mechanisms underlying\nthis phenomenon, which is distinct from model collapse and biased salience\nweighting. We propose an attenuation-based correction mechanism that\ndynamically introduces counterbalancing adjustments and can restore adaptive\nreasoning, even in `locked-in' AI systems. Additionally, we discuss some other\nrelated effects arising from improperly managed reinforcement. Finally, we\noutline potential applications of this mitigation strategy for improving AI\nrobustness in real-world decision-making tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 3 figures, 2 tables,",
    "pdf_url": "http://arxiv.org/pdf/2504.07992v1",
    "published_date": "2025-04-07 18:30:52 UTC",
    "updated_date": "2025-04-07 18:30:52 UTC"
  },
  {
    "arxiv_id": "2504.05410v1",
    "title": "Fast Controlled Generation from Language Models with Adaptive Weighted Rejection Sampling",
    "authors": [
      "Benjamin Lipkin",
      "Benjamin LeBrun",
      "Jacob Hoover Vigly",
      "João Loula",
      "David R. MacIver",
      "Li Du",
      "Jason Eisner",
      "Ryan Cotterell",
      "Vikash Mansinghka",
      "Timothy J. O'Donnell",
      "Alexander K. Lew",
      "Tim Vieira"
    ],
    "abstract": "The dominant approach to generating from language models subject to some\nconstraint is locally constrained decoding (LCD), incrementally sampling tokens\nat each time step such that the constraint is never violated. Typically, this\nis achieved through token masking: looping over the vocabulary and excluding\nnon-conforming tokens. There are two important problems with this approach. (i)\nEvaluating the constraint on every token can be prohibitively expensive -- LM\nvocabularies often exceed $100,000$ tokens. (ii) LCD can distort the global\ndistribution over strings, sampling tokens based only on local information,\neven if they lead down dead-end paths. This work introduces a new algorithm\nthat addresses both these problems. First, to avoid evaluating a constraint on\nthe full vocabulary at each step of generation, we propose an adaptive\nrejection sampling algorithm that typically requires orders of magnitude fewer\nconstraint evaluations. Second, we show how this algorithm can be extended to\nproduce low-variance, unbiased estimates of importance weights at a very small\nadditional cost -- estimates that can be soundly used within previously\nproposed sequential Monte Carlo algorithms to correct for the myopic behavior\nof local constraint enforcement. Through extensive empirical evaluation in\ntext-to-SQL, molecular synthesis, goal inference, pattern matching, and JSON\ndomains, we show that our approach is superior to state-of-the-art baselines,\nsupporting a broader class of constraints and improving both runtime and\nperformance. Additional theoretical and empirical analyses show that our\nmethod's runtime efficiency is driven by its dynamic use of computation,\nscaling with the divergence between the unconstrained and constrained LM, and\nas a consequence, runtime improvements are greater for better models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05410v1",
    "published_date": "2025-04-07 18:30:18 UTC",
    "updated_date": "2025-04-07 18:30:18 UTC"
  },
  {
    "arxiv_id": "2504.05408v2",
    "title": "Frontier AI's Impact on the Cybersecurity Landscape",
    "authors": [
      "Wenbo Guo",
      "Yujin Potter",
      "Tianneng Shi",
      "Zhun Wang",
      "Andy Zhang",
      "Dawn Song"
    ],
    "abstract": "As frontier AI advances rapidly, understanding its impact on cybersecurity\nand inherent risks is essential to ensuring safe AI evolution (e.g., guiding\nrisk mitigation and informing policymakers). While some studies review AI\napplications in cybersecurity, none of them comprehensively discuss AI's future\nimpacts or provide concrete recommendations for navigating its safe and secure\nusage. This paper presents an in-depth analysis of frontier AI's impact on\ncybersecurity and establishes a systematic framework for risk assessment and\nmitigation. To this end, we first define and categorize the marginal risks of\nfrontier AI in cybersecurity and then systemically analyze the current and\nfuture impacts of frontier AI in cybersecurity, qualitatively and\nquantitatively. We also discuss why frontier AI likely benefits attackers more\nthan defenders in the short term from equivalence classes, asymmetry, and\neconomic impact. Next, we explore frontier AI's impact on future software\nsystem development, including enabling complex hybrid systems while introducing\nnew risks. Based on our findings, we provide security recommendations,\nincluding constructing fine-grained benchmarks for risk assessment, designing\nAI agents for defenses, building security mechanisms and provable defenses for\nhybrid systems, enhancing pre-deployment security testing and transparency, and\nstrengthening defenses for users. Finally, we present long-term research\nquestions essential for understanding AI's future impacts and unleashing its\ndefensive capabilities.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05408v2",
    "published_date": "2025-04-07 18:25:18 UTC",
    "updated_date": "2025-04-14 17:35:14 UTC"
  },
  {
    "arxiv_id": "2504.05407v1",
    "title": "TRATSS: Transformer-Based Task Scheduling System for Autonomous Vehicles",
    "authors": [
      "Yazan Youssef",
      "Paulo Ricardo Marques de Araujo",
      "Aboelmagd Noureldin",
      "Sidney Givigi"
    ],
    "abstract": "Efficient scheduling remains a critical challenge in various domains,\nrequiring solutions to complex NP-hard optimization problems to achieve optimal\nresource allocation and maximize productivity. In this paper, we introduce a\nframework called Transformer-Based Task Scheduling System (TRATSS), designed to\naddress the intricacies of single agent scheduling in graph-based environments.\nBy integrating the latest advancements in reinforcement learning and\ntransformer architecture, TRATSS provides a novel system that outputs optimized\ntask scheduling decisions while dynamically adapting to evolving task\nrequirements and resource availability. Leveraging the self-attention mechanism\nin transformers, TRATSS effectively captures complex task dependencies, thereby\nproviding solutions with enhanced resource utilization and task completion\nefficiency. Experimental evaluations on benchmark datasets demonstrate TRATSS's\neffectiveness in providing high-quality solutions to scheduling problems that\ninvolve multiple action profiles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05407v1",
    "published_date": "2025-04-07 18:23:13 UTC",
    "updated_date": "2025-04-07 18:23:13 UTC"
  },
  {
    "arxiv_id": "2504.05405v1",
    "title": "The Role of Environment Access in Agnostic Reinforcement Learning",
    "authors": [
      "Akshay Krishnamurthy",
      "Gene Li",
      "Ayush Sekhari"
    ],
    "abstract": "We study Reinforcement Learning (RL) in environments with large state spaces,\nwhere function approximation is required for sample-efficient learning.\nDeparting from a long history of prior work, we consider the weakest possible\nform of function approximation, called agnostic policy learning, where the\nlearner seeks to find the best policy in a given class $\\Pi$, with no guarantee\nthat $\\Pi$ contains an optimal policy for the underlying task. Although it is\nknown that sample-efficient agnostic policy learning is not possible in the\nstandard online RL setting without further assumptions, we investigate the\nextent to which this can be overcome with stronger forms of access to the\nenvironment. Specifically, we show that: 1. Agnostic policy learning remains\nstatistically intractable when given access to a local simulator, from which\none can reset to any previously seen state. This result holds even when the\npolicy class is realizable, and stands in contrast to a positive result of\n[MFR24] showing that value-based learning under realizability is tractable with\nlocal simulator access. 2. Agnostic policy learning remains statistically\nintractable when given online access to a reset distribution with good coverage\nproperties over the state space (the so-called $\\mu$-reset setting). We also\nstudy stronger forms of function approximation for policy learning, showing\nthat PSDP [BKSN03] and CPI [KL02] provably fail in the absence of policy\ncompleteness. 3. On a positive note, agnostic policy learning is statistically\ntractable for Block MDPs with access to both of the above reset models. We\nestablish this via a new algorithm that carefully constructs a policy emulator:\na tabular MDP with a small state space that approximates the value functions of\nall policies $\\pi \\in \\Pi$. These values are approximated without any explicit\nvalue function class.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2504.05405v1",
    "published_date": "2025-04-07 18:19:56 UTC",
    "updated_date": "2025-04-07 18:19:56 UTC"
  },
  {
    "arxiv_id": "2504.05400v1",
    "title": "GARF: Learning Generalizable 3D Reassembly for Real-World Fractures",
    "authors": [
      "Sihang Li",
      "Zeyu Jiang",
      "Grace Chen",
      "Chenyang Xu",
      "Siqi Tan",
      "Xue Wang",
      "Irving Fang",
      "Kristof Zyskowski",
      "Shannon P. McPherron",
      "Radu Iovita",
      "Chen Feng",
      "Jing Zhang"
    ],
    "abstract": "3D reassembly is a challenging spatial intelligence task with broad\napplications across scientific domains. While large-scale synthetic datasets\nhave fueled promising learning-based approaches, their generalizability to\ndifferent domains is limited. Critically, it remains uncertain whether models\ntrained on synthetic datasets can generalize to real-world fractures where\nbreakage patterns are more complex. To bridge this gap, we propose GARF, a\ngeneralizable 3D reassembly framework for real-world fractures. GARF leverages\nfracture-aware pretraining to learn fracture features from individual\nfragments, with flow matching enabling precise 6-DoF alignments. At inference\ntime, we introduce one-step preassembly, improving robustness to unseen objects\nand varying numbers of fractures. In collaboration with archaeologists,\npaleoanthropologists, and ornithologists, we curate Fractura, a diverse dataset\nfor vision and learning communities, featuring real-world fracture types across\nceramics, bones, eggshells, and lithics. Comprehensive experiments have shown\nour approach consistently outperforms state-of-the-art methods on both\nsynthetic and real-world datasets, achieving 82.87\\% lower rotation error and\n25.15\\% higher part accuracy. This sheds light on training on synthetic data to\nadvance real-world 3D puzzle solving, demonstrating its strong generalization\nacross unseen object shapes and diverse fracture types.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 11 figures. Project Page https://ai4ce.github.io/GARF/",
    "pdf_url": "http://arxiv.org/pdf/2504.05400v1",
    "published_date": "2025-04-07 18:13:16 UTC",
    "updated_date": "2025-04-07 18:13:16 UTC"
  },
  {
    "arxiv_id": "2504.05393v1",
    "title": "Interactive Explanations for Reinforcement-Learning Agents",
    "authors": [
      "Yotam Amitai",
      "Ofra Amir",
      "Guy Avni"
    ],
    "abstract": "As reinforcement learning methods increasingly amass accomplishments, the\nneed for comprehending their solutions becomes more crucial. Most explainable\nreinforcement learning (XRL) methods generate a static explanation depicting\ntheir developers' intuition of what should be explained and how. In contrast,\nliterature from the social sciences proposes that meaningful explanations are\nstructured as a dialog between the explainer and the explainee, suggesting a\nmore active role for the user and her communication with the agent. In this\npaper, we present ASQ-IT -- an interactive explanation system that presents\nvideo clips of the agent acting in its environment based on queries given by\nthe user that describe temporal properties of behaviors of interest. Our\napproach is based on formal methods: queries in ASQ-IT's user interface map to\na fragment of Linear Temporal Logic over finite traces (LTLf), which we\ndeveloped, and our algorithm for query processing is based on automata theory.\nUser studies show that end-users can understand and formulate queries in ASQ-IT\nand that using ASQ-IT assists users in identifying faulty agent behaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05393v1",
    "published_date": "2025-04-07 18:00:50 UTC",
    "updated_date": "2025-04-07 18:00:50 UTC"
  },
  {
    "arxiv_id": "2504.06303v1",
    "title": "On the Effectiveness and Generalization of Race Representations for Debiasing High-Stakes Decisions",
    "authors": [
      "Dang Nguyen",
      "Chenhao Tan"
    ],
    "abstract": "Understanding and mitigating biases is critical for the adoption of large\nlanguage models (LLMs) in high-stakes decision-making. We introduce Admissions\nand Hiring, decision tasks with hypothetical applicant profiles where a\nperson's race can be inferred from their name, as simplified test beds for\nracial bias. We show that Gemma 2B Instruct and LLaMA 3.2 3B Instruct exhibit\nstrong biases. Gemma grants admission to 26% more White than Black applicants,\nand LLaMA hires 60% more Asian than White applicants. We demonstrate that these\nbiases are resistant to prompt engineering: multiple prompting strategies all\nfail to promote fairness. In contrast, using distributed alignment search, we\ncan identify \"race subspaces\" within model activations and intervene on them to\ndebias model decisions. Averaging the representation across all races within\nthe subspaces reduces Gemma's bias by 37-57%. Finally, we examine the\ngeneralizability of Gemma's race subspaces, and find limited evidence for\ngeneralization, where changing the prompt format can affect the race\nrepresentation. Our work suggests mechanistic approaches may provide a\npromising venue for improving the fairness of LLMs, but a universal race\nrepresentation remains elusive.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages, 15 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.06303v1",
    "published_date": "2025-04-07 17:59:58 UTC",
    "updated_date": "2025-04-07 17:59:58 UTC"
  },
  {
    "arxiv_id": "2504.05305v1",
    "title": "URECA: Unique Region Caption Anything",
    "authors": [
      "Sangbeom Lim",
      "Junwan Kim",
      "Heeji Yoon",
      "Jaewoo Jung",
      "Seungryong Kim"
    ],
    "abstract": "Region-level captioning aims to generate natural language descriptions for\nspecific image regions while highlighting their distinguishing features.\nHowever, existing methods struggle to produce unique captions across\nmulti-granularity, limiting their real-world applicability. To address the need\nfor detailed region-level understanding, we introduce URECA dataset, a\nlarge-scale dataset tailored for multi-granularity region captioning. Unlike\nprior datasets that focus primarily on salient objects, URECA dataset ensures a\nunique and consistent mapping between regions and captions by incorporating a\ndiverse set of objects, parts, and background elements. Central to this is a\nstage-wise data curation pipeline, where each stage incrementally refines\nregion selection and caption generation. By leveraging Multimodal Large\nLanguage Models (MLLMs) at each stage, our pipeline produces distinctive and\ncontextually grounded captions with improved accuracy and semantic diversity.\nBuilding upon this dataset, we present URECA, a novel captioning model designed\nto effectively encode multi-granularity regions. URECA maintains essential\nspatial properties such as position and shape through simple yet impactful\nmodifications to existing MLLMs, enabling fine-grained and semantically rich\nregion descriptions. Our approach introduces dynamic mask modeling and a\nhigh-resolution mask encoder to enhance caption uniqueness. Experiments show\nthat URECA achieves state-of-the-art performance on URECA dataset and\ngeneralizes well to existing region-level captioning benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://cvlab-kaist.github.io/URECA Code:\n  https://github.com/cvlab-kaist/URECA",
    "pdf_url": "http://arxiv.org/pdf/2504.05305v1",
    "published_date": "2025-04-07 17:59:44 UTC",
    "updated_date": "2025-04-07 17:59:44 UTC"
  },
  {
    "arxiv_id": "2504.05299v1",
    "title": "SmolVLM: Redefining small and efficient multimodal models",
    "authors": [
      "Andrés Marafioti",
      "Orr Zohar",
      "Miquel Farré",
      "Merve Noyan",
      "Elie Bakouch",
      "Pedro Cuenca",
      "Cyril Zakka",
      "Loubna Ben Allal",
      "Anton Lozhkov",
      "Nouamane Tazi",
      "Vaibhav Srivastav",
      "Joshua Lochner",
      "Hugo Larcher",
      "Mathieu Morlon",
      "Lewis Tunstall",
      "Leandro von Werra",
      "Thomas Wolf"
    ],
    "abstract": "Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05299v1",
    "published_date": "2025-04-07 17:58:57 UTC",
    "updated_date": "2025-04-07 17:58:57 UTC"
  },
  {
    "arxiv_id": "2504.13900v1",
    "title": "Supporting Students' Reading and Cognition with AI",
    "authors": [
      "Yue Fu",
      "Alexis Hiniker"
    ],
    "abstract": "With the rapid adoption of AI tools in learning contexts, it is vital to\nunderstand how these systems shape users' reading processes and cognitive\nengagement. We collected and analyzed text from 124 sessions with AI tools, in\nwhich students used these tools to support them as they read assigned readings\nfor an undergraduate course. We categorized participants' prompts to AI\naccording to Bloom's Taxonomy of educational objectives -- Remembering,\nUnderstanding, Applying, Analyzing, Evaluating. Our results show that\n``Analyzing'' and ``Evaluating'' are more prevalent in users' second and third\nprompts within a single usage session, suggesting a shift toward higher-order\nthinking. However, in reviewing users' engagement with AI tools over several\nweeks, we found that users converge toward passive reading engagement over\ntime. Based on these results, we propose design implications for future AI\nreading-support systems, including structured scaffolds for lower-level\ncognitive tasks (e.g., recalling terms) and proactive prompts that encourage\nhigher-order thinking (e.g., analyzing, applying, evaluating). Additionally, we\nadvocate for adaptive, human-in-the-loop features that allow students and\ninstructors to tailor their reading experiences with AI, balancing efficiency\nwith enriched cognitive engagement. Our paper expands the dialogue on\nintegrating AI into academic reading, highlighting both its potential benefits\nand challenges.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.13900v1",
    "published_date": "2025-04-07 17:51:27 UTC",
    "updated_date": "2025-04-07 17:51:27 UTC"
  },
  {
    "arxiv_id": "2504.05295v2",
    "title": "Dion: Distributed Orthonormalized Updates",
    "authors": [
      "Kwangjun Ahn",
      "Byron Xu",
      "Natalie Abreu",
      "John Langford"
    ],
    "abstract": "Recent work has shown that orthonormal matrix updates speed up neural network\noptimization, improve training stability, and offer better hyperparameter\ntransfer across model sizes. Applying these updates efficiently when model\nweights and optimizer states are sharded across a large-scale distributed LLM\ntraining system remains a major challenge. We introduce Dion (DIstributed\nOrthoNormalization), a scalable and communication-efficient orthonormalizing\noptimizer. Dion leverages low-rank approximation and decoupled momentum\nbuffers, eliminating the need for full gradient synchronization while producing\nnumerically equivalent results. It is compatible with simultaneous DDP, FSDP,\nand TP parallelism, and it computes an orthonormalized update without\nunsharding a full parameter matrix on any single device. We evaluate Dion on\nlanguage models from 120M to 3B parameters and find that its benefits improve\nwith increasing model size and batch size.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "\"Version 2\" with more experimental results and algorithmic details.\n  Comments would be appreciated!",
    "pdf_url": "http://arxiv.org/pdf/2504.05295v2",
    "published_date": "2025-04-07 17:49:37 UTC",
    "updated_date": "2025-05-21 18:05:14 UTC"
  },
  {
    "arxiv_id": "2504.05370v1",
    "title": "EduPlanner: LLM-Based Multi-Agent Systems for Customized and Intelligent Instructional Design",
    "authors": [
      "Xueqiao Zhang",
      "Chao Zhang",
      "Jianwen Sun",
      "Jun Xiao",
      "Yi Yang",
      "Yawei Luo"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced smart education in\nthe Artificial General Intelligence (AGI) era. A promising application lies in\nthe automatic generalization of instructional design for curriculum and\nlearning activities, focusing on two key aspects: (1) Customized Generation:\ngenerating niche-targeted teaching content based on students' varying learning\nabilities and states, and (2) Intelligent Optimization: iteratively optimizing\ncontent based on feedback from learning effectiveness or test scores.\nCurrently, a single large LLM cannot effectively manage the entire process,\nposing a challenge for designing intelligent teaching plans. To address these\nissues, we developed EduPlanner, an LLM-based multi-agent system comprising an\nevaluator agent, an optimizer agent, and a question analyst, working in\nadversarial collaboration to generate customized and intelligent instructional\ndesign for curriculum and learning activities. Taking mathematics lessons as\nour example, EduPlanner employs a novel Skill-Tree structure to accurately\nmodel the background mathematics knowledge of student groups, personalizing\ninstructional design for curriculum and learning activities according to\nstudents' knowledge levels and learning abilities. Additionally, we introduce\nthe CIDDP, an LLM-based five-dimensional evaluation module encompassing\nclarity, Integrity, Depth, Practicality, and Pertinence, to comprehensively\nassess mathematics lesson plan quality and bootstrap intelligent optimization.\nExperiments conducted on the GSM8K and Algebra datasets demonstrate that\nEduPlanner excels in evaluating and optimizing instructional design for\ncurriculum and learning activities. Ablation studies further validate the\nsignificance and effectiveness of each component within the framework. Our code\nis publicly available at https://github.com/Zc0812/Edu_Planner",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05370v1",
    "published_date": "2025-04-07 17:49:12 UTC",
    "updated_date": "2025-04-07 17:49:12 UTC"
  },
  {
    "arxiv_id": "2504.05278v1",
    "title": "The challenge of uncertainty quantification of large language models in medicine",
    "authors": [
      "Zahra Atf",
      "Seyed Amir Ahmad Safavi-Naini",
      "Peter R. Lewis",
      "Aref Mahjoubfar",
      "Nariman Naderi",
      "Thomas R. Savage",
      "Ali Soroush"
    ],
    "abstract": "This study investigates uncertainty quantification in large language models\n(LLMs) for medical applications, emphasizing both technical innovations and\nphilosophical implications. As LLMs become integral to clinical\ndecision-making, accurately communicating uncertainty is crucial for ensuring\nreliable, safe, and ethical AI-assisted healthcare. Our research frames\nuncertainty not as a barrier but as an essential part of knowledge that invites\na dynamic and reflective approach to AI design. By integrating advanced\nprobabilistic methods such as Bayesian inference, deep ensembles, and Monte\nCarlo dropout with linguistic analysis that computes predictive and semantic\nentropy, we propose a comprehensive framework that manages both epistemic and\naleatoric uncertainties. The framework incorporates surrogate modeling to\naddress limitations of proprietary APIs, multi-source data integration for\nbetter context, and dynamic calibration via continual and meta-learning.\nExplainability is embedded through uncertainty maps and confidence metrics to\nsupport user trust and clinical interpretability. Our approach supports\ntransparent and ethical decision-making aligned with Responsible and Reflective\nAI principles. Philosophically, we advocate accepting controlled ambiguity\ninstead of striving for absolute predictability, recognizing the inherent\nprovisionality of medical knowledge.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05278v1",
    "published_date": "2025-04-07 17:24:11 UTC",
    "updated_date": "2025-04-07 17:24:11 UTC"
  },
  {
    "arxiv_id": "2504.08793v1",
    "title": "A Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size",
    "authors": [
      "Jorge A. Huertas",
      "Pascal Van Hentenryck"
    ],
    "abstract": "In serial batch (s-batch) scheduling, jobs are grouped in batches and\nprocessed sequentially within their batch. This paper considers multiple\nparallel machines, nonidentical job weights and release times, and\nsequence-dependent setup times between batches of different families. Although\ns-batch has been widely studied in the literature, very few papers have taken\ninto account a minimum batch size, typical in practical settings such as\nsemiconductor manufacturing and the metal industry. The problem with this\nminimum batch size requirement has been mostly tackled with dynamic programming\nand meta-heuristics, and no article has ever used constraint programming (CP)\nto do so. This paper fills this gap by proposing, for the first time, a CP\nmodel for s-batching with minimum batch size. The computational experiments on\nstandard cases compare the CP model with two existing mixed-integer programming\n(MIP) models from the literature. The results demonstrate the versatility of\nthe proposed CP model to handle multiple variations of s-batching; and its\nability to produce, in large instances, better solutions than the MIP models\nfaster.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.08793v1",
    "published_date": "2025-04-07 17:14:19 UTC",
    "updated_date": "2025-04-07 17:14:19 UTC"
  },
  {
    "arxiv_id": "2504.05259v1",
    "title": "How to evaluate control measures for LLM agents? A trajectory from today to superintelligence",
    "authors": [
      "Tomek Korbak",
      "Mikita Balesni",
      "Buck Shlegeris",
      "Geoffrey Irving"
    ],
    "abstract": "As LLM agents grow more capable of causing harm autonomously, AI developers\nwill rely on increasingly sophisticated control measures to prevent possibly\nmisaligned agents from causing harm. AI developers could demonstrate that their\ncontrol measures are sufficient by running control evaluations: testing\nexercises in which a red team produces agents that try to subvert control\nmeasures. To ensure control evaluations accurately capture misalignment risks,\nthe affordances granted to this red team should be adapted to the capability\nprofiles of the agents to be deployed under control measures.\n  In this paper we propose a systematic framework for adapting affordances of\nred teams to advancing AI capabilities. Rather than assuming that agents will\nalways execute the best attack strategies known to humans, we demonstrate how\nknowledge of an agents's actual capability profile can inform proportional\ncontrol evaluations, resulting in more practical and cost-effective control\nmeasures. We illustrate our framework by considering a sequence of five\nfictional models (M1-M5) with progressively advanced capabilities, defining\nfive distinct AI control levels (ACLs). For each ACL, we provide example rules\nfor control evaluation, control measures, and safety cases that could be\nappropriate. Finally, we show why constructing a compelling AI control safety\ncase for superintelligent LLM agents will require research breakthroughs,\nhighlighting that we might eventually need alternative approaches to mitigating\nmisalignment risk.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05259v1",
    "published_date": "2025-04-07 16:52:52 UTC",
    "updated_date": "2025-04-07 16:52:52 UTC"
  },
  {
    "arxiv_id": "2504.05258v1",
    "title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models",
    "authors": [
      "Adrián Bazaga",
      "Rexhina Blloshmi",
      "Bill Byrne",
      "Adrià de Gispert"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05258v1",
    "published_date": "2025-04-07 16:51:45 UTC",
    "updated_date": "2025-04-07 16:51:45 UTC"
  },
  {
    "arxiv_id": "2504.05254v1",
    "title": "Explaining Low Perception Model Competency with High-Competency Counterfactuals",
    "authors": [
      "Sara Pohland",
      "Claire Tomlin"
    ],
    "abstract": "There exist many methods to explain how an image classification model\ngenerates its decision, but very little work has explored methods to explain\nwhy a classifier might lack confidence in its prediction. As there are various\nreasons the classifier might lose confidence, it would be valuable for this\nmodel to not only indicate its level of uncertainty but also explain why it is\nuncertain. Counterfactual images have been used to visualize changes that could\nbe made to an image to generate a different classification decision. In this\nwork, we explore the use of counterfactuals to offer an explanation for low\nmodel competency--a generalized form of predictive uncertainty that measures\nconfidence. Toward this end, we develop five novel methods to generate\nhigh-competency counterfactual images, namely Image Gradient Descent (IGD),\nFeature Gradient Descent (FGD), Autoencoder Reconstruction (Reco), Latent\nGradient Descent (LGD), and Latent Nearest Neighbors (LNN). We evaluate these\nmethods across two unique datasets containing images with six known causes for\nlow model competency and find Reco, LGD, and LNN to be the most promising\nmethods for counterfactual generation. We further evaluate how these three\nmethods can be utilized by pre-trained Multimodal Large Language Models (MLLMs)\nto generate language explanations for low model competency. We find that the\ninclusion of a counterfactual image in the language model query greatly\nincreases the ability of the model to generate an accurate explanation for the\ncause of low model competency, thus demonstrating the utility of counterfactual\nimages in explaining low perception model competency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05254v1",
    "published_date": "2025-04-07 16:46:52 UTC",
    "updated_date": "2025-04-07 16:46:52 UTC"
  },
  {
    "arxiv_id": "2504.05255v2",
    "title": "Adversarial KA",
    "authors": [
      "Sviatoslav Dzhenzher",
      "Michael H. Freedman"
    ],
    "abstract": "Regarding the representation theorem of Kolmogorov and Arnold (KA) as an\nalgorithm for representing or {\\guillemotleft}expressing{\\guillemotright}\nfunctions, we test its robustness by analyzing its ability to withstand\nadversarial attacks. We find KA to be robust to countable collections of\ncontinuous adversaries, but unearth a question about the equi-continuity of the\nouter functions that, so far, obstructs taking limits and defeating continuous\ngroups of adversaries. This question on the regularity of the outer functions\nis relevant to the debate over the applicability of KA to the general theory of\nNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 3 figures; minor revision, question 4.1 added",
    "pdf_url": "http://arxiv.org/pdf/2504.05255v2",
    "published_date": "2025-04-07 16:46:52 UTC",
    "updated_date": "2025-04-30 15:07:54 UTC"
  },
  {
    "arxiv_id": "2504.05248v1",
    "title": "PINNverse: Accurate parameter estimation in differential equations from noisy data with constrained physics-informed neural networks",
    "authors": [
      "Marius Almanstötter",
      "Roman Vetter",
      "Dagmar Iber"
    ],
    "abstract": "Parameter estimation for differential equations from measured data is an\ninverse problem prevalent across quantitative sciences. Physics-Informed Neural\nNetworks (PINNs) have emerged as effective tools for solving such problems,\nespecially with sparse measurements and incomplete system information. However,\nPINNs face convergence issues, stability problems, overfitting, and complex\nloss function design. Here we introduce PINNverse, a training paradigm that\naddresses these limitations by reformulating the learning process as a\nconstrained differential optimization problem. This approach achieves a dynamic\nbalance between data loss and differential equation residual loss during\ntraining while preventing overfitting. PINNverse combines the advantages of\nPINNs with the Modified Differential Method of Multipliers to enable\nconvergence on any point on the Pareto front. We demonstrate robust and\naccurate parameter estimation from noisy data in four classical ODE and PDE\nmodels from physics and biology. Our method enables accurate parameter\ninference also when the forward problem is expensive to solve.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05248v1",
    "published_date": "2025-04-07 16:34:57 UTC",
    "updated_date": "2025-04-07 16:34:57 UTC"
  },
  {
    "arxiv_id": "2504.05231v1",
    "title": "Mapping biodiversity at very-high resolution in Europe",
    "authors": [
      "César Leblanc",
      "Lukas Picek",
      "Benjamin Deneu",
      "Pierre Bonnet",
      "Maximilien Servajean",
      "Rémi Palard",
      "Alexis Joly"
    ],
    "abstract": "This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05231v1",
    "published_date": "2025-04-07 16:15:52 UTC",
    "updated_date": "2025-04-07 16:15:52 UTC"
  },
  {
    "arxiv_id": "2504.05229v1",
    "title": "FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in Explainable Automatic Fact-Checking",
    "authors": [
      "Islam Eldifrawi",
      "Shengrui Wang",
      "Amine Trabelsi"
    ],
    "abstract": "The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05229v1",
    "published_date": "2025-04-07 16:14:27 UTC",
    "updated_date": "2025-04-07 16:14:27 UTC"
  },
  {
    "arxiv_id": "2504.05220v2",
    "title": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG",
    "authors": [
      "Hengran Zhang",
      "Minghao Tang",
      "Keping Bi",
      "Jiafeng Guo",
      "Shihao Liu",
      "Daiting Shi",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "abstract": "Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05220v2",
    "published_date": "2025-04-07 16:05:52 UTC",
    "updated_date": "2025-04-08 02:11:05 UTC"
  },
  {
    "arxiv_id": "2504.05216v2",
    "title": "Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling",
    "authors": [
      "Hengran Zhang",
      "Keping Bi",
      "Jiafeng Guo",
      "Xiaojie Sun",
      "Shihao Liu",
      "Daiting Shi",
      "Dawei Yin",
      "Xueqi Cheng"
    ],
    "abstract": "Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05216v2",
    "published_date": "2025-04-07 16:03:59 UTC",
    "updated_date": "2025-04-19 13:16:08 UTC"
  },
  {
    "arxiv_id": "2504.05210v1",
    "title": "A moving target in AI-assisted decision-making: Dataset shift, model updating, and the problem of update opacity",
    "authors": [
      "Joshua Hatherley"
    ],
    "abstract": "Machine learning (ML) systems are vulnerable to performance decline over time\ndue to dataset shift. To address this problem, experts often suggest that ML\nsystems should be regularly updated to ensure ongoing performance stability.\nSome scholarly literature has begun to address the epistemic and ethical\nchallenges associated with different updating methodologies. Thus far, however,\nlittle attention has been paid to the impact of model updating on the\nML-assisted decision-making process itself, particularly in the AI ethics and\nAI epistemology literatures. This article aims to address this gap in the\nliterature. It argues that model updating introduces a new sub-type of opacity\ninto ML-assisted decision-making -- update opacity -- that occurs when users\ncannot understand how or why an update has changed the reasoning or behaviour\nof an ML system. This type of opacity presents a variety of distinctive\nepistemic and safety concerns that available solutions to the black box problem\nin ML are largely ill-equipped to address. A variety of alternative strategies\nmay be developed or pursued to address the problem of update opacity more\ndirectly, including bi-factual explanations, dynamic model reporting, and\nupdate compatibility. However, each of these strategies presents its own risks\nor carries significant limitations. Further research will be needed to address\nthe epistemic and safety concerns associated with model updating and update\nopacity going forward.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05210v1",
    "published_date": "2025-04-07 15:58:23 UTC",
    "updated_date": "2025-04-07 15:58:23 UTC"
  },
  {
    "arxiv_id": "2505.03746v1",
    "title": "Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework",
    "authors": [
      "Silvia García-Méndez",
      "Francisco De Arriba-Pérez"
    ],
    "abstract": "Social media platforms enable instant and ubiquitous connectivity and are\nessential to social interaction and communication in our technological society.\nApart from its advantages, these platforms have given rise to negative\nbehaviors in the online community, the so-called cyberbullying. Despite the\nmany works involving generative Artificial Intelligence (AI) in the literature\nlately, there remain opportunities to study its performance apart from\nzero/few-shot learning strategies. Accordingly, we propose an innovative and\nreal-time solution for cyberbullying detection that leverages stream-based\nMachine Learning (ML) models able to process the incoming samples incrementally\nand Large Language Models (LLMS) for feature engineering to address the\nevolving nature of abusive and hate speech online. An explainability dashboard\nis provided to promote the system's trustworthiness, reliability, and\naccountability. Results on experimental data report promising performance close\nto 90 % in all evaluation metrics and surpassing those obtained by competing\nworks in the literature. Ultimately, our proposal contributes to the safety of\nonline communities by timely detecting abusive behavior to prevent long-lasting\nharassment and reduce the negative consequences in society.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03746v1",
    "published_date": "2025-04-07 15:57:37 UTC",
    "updated_date": "2025-04-07 15:57:37 UTC"
  },
  {
    "arxiv_id": "2504.05207v1",
    "title": "Correcting Class Imbalances with Self-Training for Improved Universal Lesion Detection and Tagging",
    "authors": [
      "Alexander Shieh",
      "Tejas Sudharshan Mathai",
      "Jianfei Liu",
      "Angshuman Paul",
      "Ronald M. Summers"
    ],
    "abstract": "Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at SPIE Medical Imaging 2023",
    "pdf_url": "http://arxiv.org/pdf/2504.05207v1",
    "published_date": "2025-04-07 15:57:03 UTC",
    "updated_date": "2025-04-07 15:57:03 UTC"
  },
  {
    "arxiv_id": "2504.05201v1",
    "title": "3D Universal Lesion Detection and Tagging in CT with Self-Training",
    "authors": [
      "Jared Frazier",
      "Tejas Sudharshan Mathai",
      "Jianfei Liu",
      "Angshuman Paul",
      "Ronald M. Summers"
    ],
    "abstract": "Radiologists routinely perform the tedious task of lesion localization,\nclassification, and size measurement in computed tomography (CT) studies.\nUniversal lesion detection and tagging (ULDT) can simultaneously help alleviate\nthe cumbersome nature of lesion measurement and enable tumor burden assessment.\nPrevious ULDT approaches utilize the publicly available DeepLesion dataset,\nhowever it does not provide the full volumetric (3D) extent of lesions and also\ndisplays a severe class imbalance. In this work, we propose a self-training\npipeline to detect 3D lesions and tag them according to the body part they\noccur in. We used a significantly limited 30\\% subset of DeepLesion to train a\nVFNet model for 2D lesion detection and tagging. Next, the 2D lesion context\nwas expanded into 3D, and the mined 3D lesion proposals were integrated back\ninto the baseline training data in order to retrain the model over multiple\nrounds. Through the self-training procedure, our VFNet model learned from its\nown predictions, detected lesions in 3D, and tagged them. Our results indicated\nthat our VFNet model achieved an average sensitivity of 46.9\\% at [0.125:8]\nfalse positives (FP) with a limited 30\\% data subset in comparison to the\n46.8\\% of an existing approach that used the entire DeepLesion dataset. To our\nknowledge, we are the first to jointly detect lesions in 3D and tag them\naccording to the body part label.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published at SPIE Medical Imaging 2023",
    "pdf_url": "http://arxiv.org/pdf/2504.05201v1",
    "published_date": "2025-04-07 15:50:27 UTC",
    "updated_date": "2025-04-07 15:50:27 UTC"
  },
  {
    "arxiv_id": "2504.05196v1",
    "title": "Universal Lymph Node Detection in Multiparametric MRI with Selective Augmentation",
    "authors": [
      "Tejas Sudharshan Mathai",
      "Sungwon Lee",
      "Thomas C. Shen",
      "Zhiyong Lu",
      "Ronald M. Summers"
    ],
    "abstract": "Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Published at SPIE Medical Imaging 2023",
    "pdf_url": "http://arxiv.org/pdf/2504.05196v1",
    "published_date": "2025-04-07 15:46:43 UTC",
    "updated_date": "2025-04-07 15:46:43 UTC"
  },
  {
    "arxiv_id": "2504.05187v1",
    "title": "Resource-Efficient Beam Prediction in mmWave Communications with Multimodal Realistic Simulation Framework",
    "authors": [
      "Yu Min Park",
      "Yan Kyaw Tun",
      "Walid Saad",
      "Choong Seon Hong"
    ],
    "abstract": "Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "12 pages, 8 figures, Submitted to IEEE Transactions on Communications\n  on Apr. 07, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05187v1",
    "published_date": "2025-04-07 15:38:25 UTC",
    "updated_date": "2025-04-07 15:38:25 UTC"
  },
  {
    "arxiv_id": "2504.05181v2",
    "title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval",
    "authors": [
      "Kidist Amde Mekonnen",
      "Yubao Tang",
      "Maarten de Rijke"
    ],
    "abstract": "Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DL",
      "cs.LG",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 3 figures. SIGIR '25 Proceedings of the 48th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  July 13--18, 2025 Padua, Italy. Code and pretrained models available at:\n  https://github.com/kidist-amde/ddro/",
    "pdf_url": "http://arxiv.org/pdf/2504.05181v2",
    "published_date": "2025-04-07 15:27:37 UTC",
    "updated_date": "2025-04-24 23:04:52 UTC"
  },
  {
    "arxiv_id": "2504.05180v1",
    "title": "BRIDGES: Bridging Graph Modality and Large Language Models within EDA Tasks",
    "authors": [
      "Wei Li",
      "Yang Zou",
      "Christopher Ellis",
      "Ruben Purdy",
      "Shawn Blanton",
      "José M. F. Moura"
    ],
    "abstract": "While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05180v1",
    "published_date": "2025-04-07 15:27:32 UTC",
    "updated_date": "2025-04-07 15:27:32 UTC"
  },
  {
    "arxiv_id": "2504.05172v2",
    "title": "Attention-Based Multiscale Temporal Fusion Network for Uncertain-Mode Fault Diagnosis in Multimode Processes",
    "authors": [
      "Guangqiang Li",
      "M. Amine Atoui",
      "Xiangshun Li"
    ],
    "abstract": "Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multiscale temporal fusion network. The multiscale\ndepthwise convolution and gated recurrent unit are employed to extract\nmultiscale contextual local features and long-short-term features. Instance\nnormalization is applied to suppress mode-specific information. Furthermore, a\ntemporal attention mechanism is designed to focus on critical time points with\nhigher cross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size. The source code will be available on GitHub at\nhttps://github.com/GuangqiangLi/AMTFNet.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages,11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05172v2",
    "published_date": "2025-04-07 15:16:22 UTC",
    "updated_date": "2025-04-14 08:47:52 UTC"
  },
  {
    "arxiv_id": "2504.05170v1",
    "title": "SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D Object Detection",
    "authors": [
      "Bonan Ding",
      "Jin Xie",
      "Jing Nie",
      "Jiale Cao"
    ],
    "abstract": "Multimodal 3D object detection based on deep neural networks has indeed made\nsignificant progress. However, it still faces challenges due to the\nmisalignment of scale and spatial information between features extracted from\n2D images and those derived from 3D point clouds. Existing methods usually\naggregate multimodal features at a single stage. However, leveraging\nmulti-stage cross-modal features is crucial for detecting objects of various\nscales. Therefore, these methods often struggle to integrate features across\ndifferent scales and modalities effectively, thereby restricting the accuracy\nof detection. Additionally, the time-consuming Query-Key-Value-based\n(QKV-based) cross-attention operations often utilized in existing methods aid\nin reasoning the location and existence of objects by capturing non-local\ncontexts. However, this approach tends to increase computational complexity. To\naddress these challenges, we present SSLFusion, a novel Scale & Space Aligned\nLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a\n3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module\n(LFM). SAF mitigates scale misalignment between modalities by aggregating\nfeatures from both images and point clouds across multiple levels. SAM is\ndesigned to reduce the inter-modal gap between features from images and point\nclouds by incorporating 3D coordinate information into 2D image features.\nAdditionally, LFM captures cross-modal non-local contexts in the latent space\nwithout utilizing the QKV-based attention operations, thus mitigating\ncomputational complexity. Experiments on the KITTI and DENSE datasets\ndemonstrate that our SSLFusion outperforms state-of-the-art methods. Our\napproach obtains an absolute gain of 2.15% in 3D AP, compared with the\nstate-of-art method GraphAlign on the moderate level of the KITTI test set.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05170v1",
    "published_date": "2025-04-07 15:15:06 UTC",
    "updated_date": "2025-04-07 15:15:06 UTC"
  },
  {
    "arxiv_id": "2504.05167v1",
    "title": "RLBayes: a Bayesian Network Structure Learning Algorithm via Reinforcement Learning-Based Search Strategy",
    "authors": [
      "Mingcan Wang",
      "Junchang Xin",
      "Luxuan Qu",
      "Qi Chen",
      "Zhiqiong Wang"
    ],
    "abstract": "The score-based structure learning of Bayesian network (BN) is an effective\nway to learn BN models, which are regarded as some of the most compelling\nprobabilistic graphical models in the field of representation and reasoning\nunder uncertainty. However, the search space of structure learning grows\nsuper-exponentially as the number of variables increases, which makes BN\nstructure learning an NP-hard problem, as well as a combination optimization\nproblem (COP). Despite the successes of many heuristic methods on it, the\nresults of the structure learning of BN are usually unsatisfactory. Inspired by\nQ-learning, in this paper, a Bayesian network structure learning algorithm via\nreinforcement learning-based (RL-based) search strategy is proposed, namely\nRLBayes. The method borrows the idea of RL and tends to record and guide the\nlearning process by a dynamically maintained Q-table. By creating and\nmaintaining the dynamic Q-table, RLBayes achieve storing the unlimited search\nspace within limited space, thereby achieving the structure learning of BN via\nQ-learning. Not only is it theoretically proved that RLBayes can converge to\nthe global optimal BN structure, but also it is experimentally proved that\nRLBayes has a better effect than almost all other heuristic search algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05167v1",
    "published_date": "2025-04-07 15:11:51 UTC",
    "updated_date": "2025-04-07 15:11:51 UTC"
  },
  {
    "arxiv_id": "2504.05163v1",
    "title": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness",
    "authors": [
      "Dongzhuoran Zhou",
      "Yuqicheng Zhu",
      "Yuan He",
      "Jiaoyan Chen",
      "Evgeny Kharlamov",
      "Steffen Staab"
    ],
    "abstract": "Knowledge Graph based Retrieval-Augmented Generation (KG-RAG) is a technique\nthat enhances Large Language Model (LLM) inference in tasks like Question\nAnswering (QA) by retrieving relevant information from knowledge graphs (KGs).\nHowever, real-world KGs are often incomplete, meaning that essential\ninformation for answering questions may be missing. Existing benchmarks do not\nadequately capture the impact of KG incompleteness on KG-RAG performance. In\nthis paper, we systematically evaluate KG-RAG methods under incomplete KGs by\nremoving triples using different methods and analyzing the resulting effects.\nWe demonstrate that KG-RAG methods are sensitive to KG incompleteness,\nhighlighting the need for more robust approaches in realistic settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2504.05163v1",
    "published_date": "2025-04-07 15:08:03 UTC",
    "updated_date": "2025-04-07 15:08:03 UTC"
  },
  {
    "arxiv_id": "2504.05158v1",
    "title": "Leveraging Label Potential for Enhanced Multimodal Emotion Recognition",
    "authors": [
      "Xuechun Shao",
      "Yinfeng Yu",
      "Liejun Wang"
    ],
    "abstract": "Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Main paper (8 pages). Accepted for publication by IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05158v1",
    "published_date": "2025-04-07 15:00:34 UTC",
    "updated_date": "2025-04-07 15:00:34 UTC"
  },
  {
    "arxiv_id": "2504.05150v2",
    "title": "A Reinforcement Learning Method for Environments with Stochastic Variables: Post-Decision Proximal Policy Optimization with Dual Critic Networks",
    "authors": [
      "Leonardo Kanashiro Felizardo",
      "Edoardo Fadda",
      "Paolo Brandimarte",
      "Emilio Del-Moral-Hernandez",
      "Mariá Cristina Vasconcelos Nascimento"
    ],
    "abstract": "This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; G.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures. Accepted for presentation at IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05150v2",
    "published_date": "2025-04-07 14:56:43 UTC",
    "updated_date": "2025-04-11 03:14:53 UTC"
  },
  {
    "arxiv_id": "2504.05141v2",
    "title": "EffOWT: Transfer Visual Language Models to Open-World Tracking Efficiently and Effectively",
    "authors": [
      "Bingyang Wang",
      "Kaer Huang",
      "Bin Li",
      "Yiqiang Yan",
      "Lihe Zhang",
      "Huchuan Lu",
      "You He"
    ],
    "abstract": "Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05141v2",
    "published_date": "2025-04-07 14:47:58 UTC",
    "updated_date": "2025-04-09 01:00:05 UTC"
  },
  {
    "arxiv_id": "2504.05125v1",
    "title": "Interpretable Style Takagi-Sugeno-Kang Fuzzy Clustering",
    "authors": [
      "Suhang Gu",
      "Ye Wang",
      "Yongxin Chou",
      "Jinliang Cong",
      "Mingli Lu",
      "Zhuqing Jiao"
    ],
    "abstract": "Clustering is an efficient and essential technique for exploring latent\nknowledge of data. However, limited attention has been given to the\ninterpretability of the clusters detected by most clustering algorithms. In\naddition, due to the homogeneity of data, different groups of data have their\nown homogeneous styles. In this paper, the above two aspects are considered,\nand an interpretable style Takagi-Sugeno-Kang (TSK) fuzzy clustering\n(IS-TSK-FC) algorithm is proposed. The clustering behavior of IS-TSK-FC is\nfully guided by the TSK fuzzy inference on fuzzy rules. In particular, samples\nare grouped into clusters represented by the corresponding consequent vectors\nof all fuzzy rules learned in an unsupervised manner. This can explain how the\nclusters are generated in detail, thus making the underlying decision-making\nprocess of the IS-TSK-FC interpretable. Moreover, a series of style matrices\nare introduced to facilitate the consequents of fuzzy rules in IS-TSK-FC by\ncapturing the styles of clusters as well as the nuances between different\nstyles. Consequently, all the fuzzy rules in IS-TSK-FC have powerful data\nrepresentation capability. After determining the antecedents of all the fuzzy\nrules, the optimization problem of IS-TSK-FC can be iteratively solved in an\nalternation manner. The effectiveness of IS-TSK-FC as an interpretable\nclustering tool is validated through extensive experiments on benchmark\ndatasets with unknown implicit/explicit styles. Specially, the superior\nclustering performance of IS-TSK-FC is demonstrated on case studies where\ndifferent groups of data present explicit styles. The source code of IS-TSK-FC\ncan be downloaded from https://github.com/gusuhang10/IS-TSK-FC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05125v1",
    "published_date": "2025-04-07 14:28:56 UTC",
    "updated_date": "2025-04-07 14:28:56 UTC"
  },
  {
    "arxiv_id": "2504.05119v1",
    "title": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection",
    "authors": [
      "Jon Gutiérrez Zaballa",
      "Koldo Basterretxea",
      "Javier Echanobe"
    ],
    "abstract": "Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05119v1",
    "published_date": "2025-04-07 14:21:31 UTC",
    "updated_date": "2025-04-07 14:21:31 UTC"
  },
  {
    "arxiv_id": "2504.05118v3",
    "title": "VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks",
    "authors": [
      "Yu Yue",
      "Yufeng Yuan",
      "Qiying Yu",
      "Xiaochen Zuo",
      "Ruofei Zhu",
      "Wenyuan Xu",
      "Jiaze Chen",
      "Chengyi Wang",
      "TianTian Fan",
      "Zhengyin Du",
      "Xiangpeng Wei",
      "Xiangyu Yu",
      "Gaohong Liu",
      "Juncai Liu",
      "Lingjun Liu",
      "Haibin Lin",
      "Zhiqi Lin",
      "Bole Ma",
      "Chi Zhang",
      "Mofan Zhang",
      "Wang Zhang",
      "Hang Zhu",
      "Ru Zhang",
      "Xin Liu",
      "Mingxuan Wang",
      "Yonghui Wu",
      "Lin Yan"
    ],
    "abstract": "We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05118v3",
    "published_date": "2025-04-07 14:21:11 UTC",
    "updated_date": "2025-04-11 02:54:58 UTC"
  },
  {
    "arxiv_id": "2504.05108v3",
    "title": "Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning",
    "authors": [
      "Anja Surina",
      "Amin Mansouri",
      "Lars Quaedvlieg",
      "Amal Seddas",
      "Maryna Viazovska",
      "Emmanuel Abbe",
      "Caglar Gulcehre"
    ],
    "abstract": "Discovering efficient algorithms for solving complex problems has been an\noutstanding challenge in mathematics and computer science, requiring\nsubstantial human expertise over the years. Recent advancements in evolutionary\nsearch with large language models (LLMs) have shown promise in accelerating the\ndiscovery of algorithms across various domains, particularly in mathematics and\noptimization. However, existing approaches treat the LLM as a static generator,\nmissing the opportunity to update the model with the signal obtained from\nevolutionary exploration. In this work, we propose to augment LLM-based\nevolutionary search by continuously refining the search operator - the LLM -\nthrough reinforcement learning (RL) fine-tuning. Our method leverages\nevolutionary search as an exploration strategy to discover improved algorithms,\nwhile RL optimizes the LLM policy based on these discoveries. Our experiments\non three combinatorial optimization tasks - bin packing, traveling salesman,\nand the flatpack problem - show that combining RL and evolutionary search\nimproves discovery efficiency of improved algorithms, showcasing the potential\nof RL-enhanced evolutionary strategies to assist computer scientists and\nmathematicians for more efficient algorithm design.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05108v3",
    "published_date": "2025-04-07 14:14:15 UTC",
    "updated_date": "2025-04-12 17:44:16 UTC"
  },
  {
    "arxiv_id": "2504.05106v1",
    "title": "SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content Creation",
    "authors": [
      "Stephen Brade",
      "Sam Anderson",
      "Rithesh Kumar",
      "Zeyu Jin",
      "Anh Truong"
    ],
    "abstract": "Novice content creators often invest significant time recording expressive\nspeech for social media videos. While recent advancements in text-to-speech\n(TTS) technology can generate highly realistic speech in various languages and\naccents, many struggle with unintuitive or overly granular TTS interfaces. We\npropose simplifying TTS generation by allowing users to specify high-level\ncontext alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages\nuser-provided context to inform and influence TTS output, enabling iterative\nrefinement with high-level feedback. This approach was informed by two\n8-subject formative studies: one examining content creators' experiences with\nTTS, and the other drawing on effective strategies from voice actors. Our\nevaluation shows that participants using SpeakEasy were more successful in\ngenerating performances matching their personal standards, without requiring\nsignificantly more effort than leading industry interfaces.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05106v1",
    "published_date": "2025-04-07 14:13:49 UTC",
    "updated_date": "2025-04-07 14:13:49 UTC"
  },
  {
    "arxiv_id": "2505.09619v3",
    "title": "Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification",
    "authors": [
      "Pietro Cassieri",
      "Aiman Faiz",
      "Anna Maria De Roberto",
      "Claudio Pascarelli",
      "Gianvito Mitrano",
      "Gianluca Fimiani",
      "Marina Garofano",
      "Genoveffa Tortora",
      "Mariangela Lazoi",
      "Claudio Passino",
      "Alessia Bramanti",
      "Giuseppe Scanniello"
    ],
    "abstract": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.",
    "categories": [
      "stat.OT",
      "cs.AI"
    ],
    "primary_category": "stat.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.09619v3",
    "published_date": "2025-04-07 14:07:05 UTC",
    "updated_date": "2025-05-22 13:49:33 UTC"
  },
  {
    "arxiv_id": "2504.08791v1",
    "title": "PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters",
    "authors": [
      "Zonghang Li",
      "Tao Li",
      "Wenjiao Feng",
      "Mohsen Guizani",
      "Hongfang Yu"
    ],
    "abstract": "Emergency of DeepSeek R1 and QwQ 32B have broken through performance barriers\nfor running frontier large language models (LLMs) on home devices. While\nconsumer hardware is getting stronger and model quantization is improving,\nexisting end-side solutions still demand GPU clusters, large RAM/VRAM, and high\nbandwidth, far beyond what a common home cluster can handle. This paper\nintroduces prima.cpp, a distributed inference system that runs 70B-scale models\non everyday home devices using a mix of CPU/GPU, low RAM/VRAM, Wi-Fi, and\ncross-platform support. It uses mmap to manage model weights and introduces\npiped-ring parallelism with prefetching to hide disk loading. By modeling\nheterogeneity in computation, communication, disk, memory (and its management\nbehavior), and OS, it optimally assigns model layers to each device's CPU and\nGPU, further reducing token latency. An elegant algorithm named Halda is\nproposed to solve this NP-hard assignment problem. We evaluate prima.cpp on a\ncommon four-node home cluster. It outperforms llama.cpp, exo, and dllama on\n30B+ models while keeping memory pressure below 6%. This brings frontier\n30B-70B models, such as Llama 3, DeepSeek R1, Qwen 2.5, and QwQ to home\nassistants, making advanced AI truly accessible to individuals. The code is\nopen source and available at https://github.com/Lizonghang/prima.cpp.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "68T50",
      "I.2.7; I.2.11"
    ],
    "primary_category": "cs.DC",
    "comment": "23 pages, 9 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.08791v1",
    "published_date": "2025-04-07 13:46:21 UTC",
    "updated_date": "2025-04-07 13:46:21 UTC"
  },
  {
    "arxiv_id": "2504.10498v3",
    "title": "CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models",
    "authors": [
      "Jianling Lu",
      "Mingqi Lv",
      "Tieming Chen"
    ],
    "abstract": "The performance of large language models (LLMs) in Q&A task increased\nsubstantially through Retrieval-Augmented Generation (RAG) which brings in\nexternal knowledge. However, the main difficulty lies in balancing the inherent\nself-knowledge of LLMs with external information retrieval (IR). The current\nthreshold-based methods apply one-dimensional static mechanisms with single\ncriterion. As a result, their IR decisions might be irrelevant to the LLMs'\nresponse under difficult queries. To alleviate this problem, we propose\nCognitive Convection of Self-Knowledge (CCSK). Different from traditional\nmethods that maintain single fixed IR activation criteria, CCSK implements a\ndynamic joint decision process via a Siamese Network module and a Response\nQuality Model. The Siamese Network calculates the cosine similarity between the\ncurrent query and the historical queries. The Response Quality Model evaluates\nthe responses of LLMs through LightGBM. The final decision of the CCSK is\nderived from the outputs of the two modules, as well as text features fused\nusing a multi-head attention mechanism. Extensive experiments on real-world\ndatasets show that CCSK significantly enhances the model's effectiveness in\ninformation retrieval.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "All authors of this paper have unanimously decided to withdraw its\n  preprint from arXiv. As one of the authors, I cannot unilaterally decide its\n  retention. In accordance with the collective decision, we formally request\n  the complete deletion of the paper from arXiv",
    "pdf_url": "http://arxiv.org/pdf/2504.10498v3",
    "published_date": "2025-04-07 13:43:53 UTC",
    "updated_date": "2025-05-06 07:41:59 UTC"
  },
  {
    "arxiv_id": "2504.05050v2",
    "title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models",
    "authors": [
      "Jiawei Lian",
      "Jianhong Pan",
      "Lefan Wang",
      "Yi Wang",
      "Shaohui Mei",
      "Lap-Pui Chau"
    ],
    "abstract": "Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05050v2",
    "published_date": "2025-04-07 13:20:17 UTC",
    "updated_date": "2025-04-18 02:10:21 UTC"
  },
  {
    "arxiv_id": "2504.05047v2",
    "title": "Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning",
    "authors": [
      "Sugyeong Eo",
      "Hyeonseok Moon",
      "Evelyn Hayoon Zi",
      "Chanjun Park",
      "Heuiseok Lim"
    ],
    "abstract": "Multiagent collaboration has emerged as a promising framework for enhancing\nthe reasoning capabilities of large language models (LLMs). Despite\nimprovements in reasoning, the approach introduces substantial computational\noverhead resulting from iterative agent interactions. Furthermore, engaging in\nunnecessary debates increases the risk of generating erroneous responses. To\naddress these challenges, we propose Debate Only When Necessary (DOWN), an\nadaptive multiagent debate framework that selectively activates debate based on\nthe confidence score of the agent's initial response. Debate is activated only\nfor queries requiring further deliberation, during which agents refine their\noutputs by referencing peer responses and associated confidence scores.\nEvaluations on benchmarks show that DOWN improves efficiency by up to six times\nwhile preserving or even outperforming the performance of existing methods.\nFurther analysis indicates that DOWN effectively mitigates the risk of error\npropagation stemming from the unnecessary debate process. These findings\ndemonstrate the effectiveness of our approach in delivering high-performance\nLLM solutions at a lower computational cost.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05047v2",
    "published_date": "2025-04-07 13:17:52 UTC",
    "updated_date": "2025-05-20 12:17:15 UTC"
  },
  {
    "arxiv_id": "2504.05029v1",
    "title": "Graph-based Diffusion Model for Collaborative Filtering",
    "authors": [
      "Xuan Zhang",
      "Xiang Deng",
      "Hongxing Yuan",
      "Chunyu Wei",
      "Yushun Fan"
    ],
    "abstract": "Recently, diffusion-based recommendation methods have achieved impressive\nresults. However, existing approaches predominantly treat each user's\nhistorical interactions as independent training samples, overlooking the\npotential of higher-order collaborative signals between users and items. Such\nsignals, which encapsulate richer and more nuanced relationships, can be\nnaturally captured using graph-based data structures. To address this\nlimitation, we extend diffusion-based recommendation methods to the graph\ndomain by directly modeling user-item bipartite graphs with diffusion models.\nThis enables better modeling of the higher-order connectivity inherent in\ncomplex interaction dynamics. However, this extension introduces two primary\nchallenges: (1) Noise Heterogeneity, where interactions are influenced by\nvarious forms of continuous and discrete noise, and (2) Relation Explosion,\nreferring to the high computational costs of processing large-scale graphs. To\ntackle these challenges, we propose a Graph-based Diffusion Model for\nCollaborative Filtering (GDMCF). To address noise heterogeneity, we introduce a\nmulti-level noise corruption mechanism that integrates both continuous and\ndiscrete noise, effectively simulating real-world interaction complexities. To\nmitigate relation explosion, we design a user-active guided diffusion process\nthat selectively focuses on the most meaningful edges and active users,\nreducing inference costs while preserving the graph's topological integrity.\nExtensive experiments on three benchmark datasets demonstrate that GDMCF\nconsistently outperforms state-of-the-art methods, highlighting its\neffectiveness in capturing higher-order collaborative signals and improving\nrecommendation performance.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05029v1",
    "published_date": "2025-04-07 12:51:18 UTC",
    "updated_date": "2025-04-07 12:51:18 UTC"
  },
  {
    "arxiv_id": "2504.05020v1",
    "title": "Batch Aggregation: An Approach to Enhance Text Classification with Correlated Augmented Data",
    "authors": [
      "Charco Hui",
      "Yalu Wen"
    ],
    "abstract": "Natural language processing models often face challenges due to limited\nlabeled data, especially in domain specific areas, e.g., clinical trials. To\novercome this, text augmentation techniques are commonly used to increases\nsample size by transforming the original input data into artificial ones with\nthe label preserved. However, traditional text classification methods ignores\nthe relationship between augmented texts and treats them as independent samples\nwhich may introduce classification error. Therefore, we propose a novel\napproach called 'Batch Aggregation' (BAGG) which explicitly models the\ndependence of text inputs generated through augmentation by incorporating an\nadditional layer that aggregates results from correlated texts. Through\nstudying multiple benchmark data sets across different domains, we found that\nBAGG can improve classification accuracy. We also found that the increase of\nperformance with BAGG is more obvious in domain specific data sets, with\naccuracy improvements of up to 10-29%. Through the analysis of benchmark data,\nthe proposed method addresses limitations of traditional techniques and\nimproves robustness in text classification tasks. Our result demonstrates that\nBAGG offers more robust results and outperforms traditional approaches when\ntraining data is limited.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05020v1",
    "published_date": "2025-04-07 12:46:07 UTC",
    "updated_date": "2025-04-07 12:46:07 UTC"
  },
  {
    "arxiv_id": "2504.05007v1",
    "title": "Measuring the right thing: justifying metrics in AI impact assessments",
    "authors": [
      "Stefan Buijsman",
      "Herman Veluwenkamp"
    ],
    "abstract": "AI Impact Assessments are only as good as the measures used to assess the\nimpact of these systems. It is therefore paramount that we can justify our\nchoice of metrics in these assessments, especially for difficult to quantify\nethical and social values. We present a two-step approach to ensure metrics are\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\nfairness or fairness as solidarity) and then a metric can be fitted to that\nconception. Both steps require separate justifications, as conceptions can be\njudged on how well they fit with the function of, for example, fairness. We\nargue that conceptual engineering offers helpful tools for this step. Second,\nmetrics need to be fitted to a conception. We illustrate this process through\nan examination of competing fairness metrics to illustrate that here the\nadditional content that a conception offers helps us justify the choice for a\nspecific metric. We thus advocate that impact assessments are not only clear on\ntheir metrics, but also on the conceptions that motivate those metrics.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted for publication in Global Perspectives on AI Impact\n  Assessment (Oxford University Press, forthcoming). Pre-publication version;\n  final version will be available from the publisher",
    "pdf_url": "http://arxiv.org/pdf/2504.05007v1",
    "published_date": "2025-04-07 12:32:41 UTC",
    "updated_date": "2025-04-07 12:32:41 UTC"
  },
  {
    "arxiv_id": "2504.07990v1",
    "title": "Comparative analysis of Realistic EMF Exposure Estimation from Low Density Sensor Network by Finite & Infinite Neural Networks",
    "authors": [
      "Mohammed Mallik",
      "Laurent Clavier",
      "Davy P. Gaillot"
    ],
    "abstract": "Understanding the spatial and temporal patterns of environmental exposure to\nradio-frequency electromagnetic fields (RF-EMF) is essential for conducting\nrisk assessments. These assessments aim to explore potential connections\nbetween RF-EMF exposure and its effects on human health, as well as on wildlife\nand plant life. Existing research has used different machine learning tools for\nEMF exposure estimation; however, a comparative analysis of these techniques is\nrequired to better understand their performance for real-world datasets. In\nthis work, we present both finite and infinite-width convolutional\nnetwork-based methods to estimate and assess EMF exposure levels from 70\nreal-world sensors in Lille, France. A comparative analysis has been conducted\nto analyze the performance of the methods' execution time and estimation\naccuracy. To improve estimation accuracy for higher-resolution grids, we\nutilized a preconditioned gradient descent method for kernel estimation. Root\nMean Square Error (RMSE) is used as the evaluation criterion for comparing the\nperformance of these deep learning models.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07990v1",
    "published_date": "2025-04-07 12:31:53 UTC",
    "updated_date": "2025-04-07 12:31:53 UTC"
  },
  {
    "arxiv_id": "2504.04997v1",
    "title": "SurvSurf: a partially monotonic neural network for first-hitting time prediction of intermittently observed discrete and continuous sequential events",
    "authors": [
      "Yichen Kelly Chen",
      "Sören Dittmer",
      "Kinga Bernatowicz",
      "Josep Arús-Pous",
      "Kamen Bliznashki",
      "John Aston",
      "James H. F. Rudd",
      "Carola-Bibiane Schönlieb",
      "James Jones",
      "Michael Roberts"
    ],
    "abstract": "We propose a neural-network based survival model (SurvSurf) specifically\ndesigned for direct and simultaneous probabilistic prediction of the first\nhitting time of sequential events from baseline. Unlike existing models,\nSurvSurf is theoretically guaranteed to never violate the monotonic\nrelationship between the cumulative incidence functions of sequential events,\nwhile allowing nonlinear influence from predictors. It also incorporates\nimplicit truths for unobserved intermediate events in model fitting, and\nsupports both discrete and continuous time and events. We also identified a\nvariant of the Integrated Brier Score (IBS) that showed robust correlation with\nthe mean squared error (MSE) between the true and predicted probabilities by\naccounting for implied truths about the missing intermediate events. We\ndemonstrated the superiority of SurvSurf compared to modern and traditional\npredictive survival models in two simulated datasets and two real-world\ndatasets, using MSE, the more robust IBS and by measuring the extent of\nmonotonicity violation.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.AP",
      "stat.TH",
      "62N01"
    ],
    "primary_category": "stat.ML",
    "comment": "41 pages, 18 figures (including supplemental information). Submitted\n  to RSS: Data Science and Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2504.04997v1",
    "published_date": "2025-04-07 12:24:59 UTC",
    "updated_date": "2025-04-07 12:24:59 UTC"
  },
  {
    "arxiv_id": "2504.04994v2",
    "title": "Following the Whispers of Values: Unraveling Neural Mechanisms Behind Value-Oriented Behaviors in LLMs",
    "authors": [
      "Ling Hu",
      "Yuemei Xu",
      "Xiaoyang Gu",
      "Letao Han"
    ],
    "abstract": "Despite the impressive performance of large language models (LLMs), they can\npresent unintended biases and harmful behaviors driven by encoded values,\nemphasizing the urgent need to understand the value mechanisms behind them.\nHowever, current research primarily evaluates these values through external\nresponses with a focus on AI safety, lacking interpretability and failing to\nassess social values in real-world contexts. In this paper, we propose a novel\nframework called ValueExploration, which aims to explore the behavior-driven\nmechanisms of National Social Values within LLMs at the neuron level. As a case\nstudy, we focus on Chinese Social Values and first construct C-voice, a\nlarge-scale bilingual benchmark for identifying and evaluating Chinese Social\nValues in LLMs. By leveraging C-voice, we then identify and locate the neurons\nresponsible for encoding these values according to activation difference.\nFinally, by deactivating these neurons, we analyze shifts in model behavior,\nuncovering the internal mechanism by which values influence LLM\ndecision-making. Extensive experiments on four representative LLMs validate the\nefficacy of our framework. The benchmark and code will be available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04994v2",
    "published_date": "2025-04-07 12:23:59 UTC",
    "updated_date": "2025-04-20 13:04:42 UTC"
  },
  {
    "arxiv_id": "2504.04988v1",
    "title": "RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model",
    "authors": [
      "Congcong Wen",
      "Yiting Lin",
      "Xiaokang Qu",
      "Nan Li",
      "Yong Liao",
      "Hui Lin",
      "Xiang Li"
    ],
    "abstract": "Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04988v1",
    "published_date": "2025-04-07 12:13:43 UTC",
    "updated_date": "2025-04-07 12:13:43 UTC"
  },
  {
    "arxiv_id": "2504.05365v1",
    "title": "A Nature-Inspired Colony of Artificial Intelligence System with Fast, Detailed, and Organized Learner Agents for Enhancing Diversity and Quality",
    "authors": [
      "Shan Suthaharan"
    ],
    "abstract": "The concepts of convolutional neural networks (CNNs) and multi-agent systems\nare two important areas of research in artificial intelligence (AI). In this\npaper, we present an approach that builds a CNN-based colony of AI agents to\nserve as a single system and perform multiple tasks (e.g., predictions or\nclassifications) in an environment. The proposed system impersonates the\nnatural environment of a biological system, like an ant colony or a human\ncolony. The proposed colony of AI that is defined as a role-based system\nuniquely contributes to accomplish tasks in an environment by incorporating AI\nagents that are fast learners, detailed learners, and organized learners. These\nlearners can enhance their localized learning and their collective decisions as\na single system of colony of AI agents. This approach also enhances the\ndiversity and quality of the colony of AI with the help of Genetic Algorithms\nand their crossover and mutation mechanisms. The evolution of fast, detailed,\nand organized learners in the colony of AI is achieved by introducing a unique\none-to-one mapping between these learners and the pretrained VGG16, VGG19, and\nResNet50 models, respectively. This role-based approach creates two parent-AI\nagents using the AI models through the processes, called the intra- and\ninter-marriage of AI, so that they can share their learned knowledge (weights\nand biases) based on a probabilistic rule and produce diversified child-AI\nagents to perform new tasks. This process will form a colony of AI that\nconsists of families of multi-model and mixture-model AI agents to improve\ndiversity and quality. Simulations show that the colony of AI, built using the\nVGG16, VGG19, and ResNet50 models, can provide a single system that generates\nchild-AI agents of excellent predictive performance, ranging between 82% and\n95% of F1-scores, to make diversified collective and quality decisions on a\ntask.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.NE",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05365v1",
    "published_date": "2025-04-07 12:13:14 UTC",
    "updated_date": "2025-04-07 12:13:14 UTC"
  },
  {
    "arxiv_id": "2504.04982v2",
    "title": "Transforming Future Data Center Operations and Management via Physical AI",
    "authors": [
      "Zhiwei Cao",
      "Minghao Li",
      "Feng Lin",
      "Jimin Jia",
      "Yonggang Wen",
      "Jianxiong Yin",
      "Simon See"
    ],
    "abstract": "Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04982v2",
    "published_date": "2025-04-07 12:09:22 UTC",
    "updated_date": "2025-04-15 15:06:12 UTC"
  },
  {
    "arxiv_id": "2504.04981v1",
    "title": "DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation",
    "authors": [
      "Sohyun Lee",
      "Nayeong Kim",
      "Juwon Kang",
      "Seong Joon Oh",
      "Suha Kwak"
    ],
    "abstract": "This paper studies continual test-time adaptation (CTTA), the task of\nadapting a model to constantly changing unseen domains in testing while\npreserving previously learned knowledge. Existing CTTA methods mostly focus on\nadaptation to the current test domain only, overlooking generalization to\narbitrary test domains a model may face in the future. To tackle this\nlimitation, we present a novel online domain-invariant learning framework for\nCTTA, dubbed DiCoTTA. DiCoTTA aims to learn feature representation to be\ninvariant to both current and previous test domains on the fly during testing.\nTo this end, we propose a new model architecture and a test-time adaptation\nstrategy dedicated to learning domain-invariant features without corrupting\nsemantic contents, along with a new data structure and optimization algorithm\nfor effectively managing information from previous test domains. DiCoTTA\nachieved state-of-the-art performance on four public CTTA benchmarks. Moreover,\nit showed superior generalization to unseen test domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04981v1",
    "published_date": "2025-04-07 12:09:18 UTC",
    "updated_date": "2025-04-07 12:09:18 UTC"
  },
  {
    "arxiv_id": "2504.04974v1",
    "title": "Towards Visual Text Grounding of Multimodal Large Language Model",
    "authors": [
      "Ming Li",
      "Ruiyi Zhang",
      "Jian Chen",
      "Jiuxiang Gu",
      "Yufan Zhou",
      "Franck Dernoncourt",
      "Wanrong Zhu",
      "Tianyi Zhou",
      "Tong Sun"
    ],
    "abstract": "Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04974v1",
    "published_date": "2025-04-07 12:01:59 UTC",
    "updated_date": "2025-04-07 12:01:59 UTC"
  },
  {
    "arxiv_id": "2504.04973v2",
    "title": "Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds",
    "authors": [
      "Qian Zuo",
      "Fengxiang He"
    ],
    "abstract": "This paper studies constrained Markov decision processes (CMDPs) with\nconstraints against stochastic thresholds, aiming at the safety of\nreinforcement learning in unknown and uncertain environments. We leverage a\nGrowing-Window estimator sampling from interactions with the uncertain and\ndynamic environment to estimate the thresholds, based on which we design\nStochastic Pessimistic-Optimistic Thresholding (SPOT), a novel model-based\nprimal-dual algorithm for multiple constraints against stochastic thresholds.\nSPOT enables reinforcement learning under both pessimistic and optimistic\nthreshold settings. We prove that our algorithm achieves sublinear regret and\nconstraint violation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nwhile allowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$\nepisodes. The theoretical guarantees show that our algorithm achieves\nperformance comparable to that of an approach relying on fixed and clear\nthresholds. To the best of our knowledge, SPOT is the first reinforcement\nlearning algorithm that realises theoretical guaranteed performance in an\nuncertain environment where even thresholds are unknown.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04973v2",
    "published_date": "2025-04-07 11:58:19 UTC",
    "updated_date": "2025-05-16 14:13:34 UTC"
  },
  {
    "arxiv_id": "2504.04970v1",
    "title": "A High-Force Gripper with Embedded Multimodal Sensing for Powerful and Perception Driven Grasping",
    "authors": [
      "Edoardo Del Bianco",
      "Davide Torielli",
      "Federico Rollo",
      "Damiano Gasperini",
      "Arturo Laurenzi",
      "Lorenzo Baccelliere",
      "Luca Muratore",
      "Marco Roveri",
      "Nikos G. Tsagarakis"
    ],
    "abstract": "Modern humanoid robots have shown their promising potential for executing\nvarious tasks involving the grasping and manipulation of objects using their\nend-effectors. Nevertheless, in the most of the cases, the grasping and\nmanipulation actions involve low to moderate payload and interaction forces.\nThis is due to limitations often presented by the end-effectors, which can not\nmatch their arm-reachable payload, and hence limit the payload that can be\ngrasped and manipulated. In addition, grippers usually do not embed adequate\nperception in their hardware, and grasping actions are mainly driven by\nperception sensors installed in the rest of the robot body, frequently affected\nby occlusions due to the arm motions during the execution of the grasping and\nmanipulation tasks. To address the above, we developed a modular high grasping\nforce gripper equipped with embedded multi-modal perception functionalities.\nThe proposed gripper can generate a grasping force of 110 N in a compact\nimplementation. The high grasping force capability is combined with embedded\nmulti-modal sensing, which includes an eye-in-hand camera, a Time-of-Flight\n(ToF) distance sensor, an Inertial Measurement Unit (IMU) and an\nomnidirectional microphone, permitting the implementation of perception-driven\ngrasping functionalities.\n  We extensively evaluated the grasping force capacity of the gripper by\nintroducing novel payload evaluation metrics that are a function of the robot\narm's dynamic motion and gripper thermal states. We also evaluated the embedded\nmulti-modal sensing by performing perception-guided enhanced grasping\noperations.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04970v1",
    "published_date": "2025-04-07 11:57:08 UTC",
    "updated_date": "2025-04-07 11:57:08 UTC"
  },
  {
    "arxiv_id": "2504.04968v1",
    "title": "The Dream Within Huang Long Cave: AI-Driven Interactive Narrative for Family Storytelling and Emotional Reflection",
    "authors": [
      "Jiayang Huang",
      "Lingjie Li",
      "Kang Zhang",
      "David Yip"
    ],
    "abstract": "This paper introduces the art project The Dream Within Huang Long Cave, an\nAI-driven interactive and immersive narrative experience. The project offers\nnew insights into AI technology, artistic practice, and psychoanalysis.\nInspired by actual geographical landscapes and familial archetypes, the work\ncombines psychoanalytic theory and computational technology, providing an\nartistic response to the concept of the non-existence of the Big Other. The\nnarrative is driven by a combination of a large language model (LLM) and a\nrealistic digital character, forming a virtual agent named YELL. Through\ndialogue and exploration within a cave automatic virtual environment (CAVE),\nthe audience is invited to unravel the language puzzles presented by YELL and\nhelp him overcome his life challenges. YELL is a fictional embodiment of the\nBig Other, modeled after the artist's real father. Through a cross-temporal\ninteraction with this digital father, the project seeks to deconstruct complex\nfamilial relationships. By demonstrating the non-existence of the Big Other, we\naim to underscore the authenticity of interpersonal emotions, positioning art\nas a bridge for emotional connection and understanding within family dynamics.",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "8 pages,8 figures, International Symposium on Electronic/Emerging Art\n  (ISEA)",
    "pdf_url": "http://arxiv.org/pdf/2504.04968v1",
    "published_date": "2025-04-07 11:54:11 UTC",
    "updated_date": "2025-04-07 11:54:11 UTC"
  },
  {
    "arxiv_id": "2504.05364v1",
    "title": "Of All StrIPEs: Investigating Structure-informed Positional Encoding for Efficient Music Generation",
    "authors": [
      "Manvi Agarwal",
      "Changhong Wang",
      "Gael Richard"
    ],
    "abstract": "While music remains a challenging domain for generative models like\nTransformers, a two-pronged approach has recently proved successful: inserting\nmusically-relevant structural information into the positional encoding (PE)\nmodule and using kernel approximation techniques based on Random Fourier\nFeatures (RFF) to lower the computational cost from quadratic to linear. Yet,\nit is not clear how such RFF-based efficient PEs compare with those based on\nrotation matrices, such as Rotary Positional Encoding (RoPE). In this paper, we\npresent a unified framework based on kernel methods to analyze both families of\nefficient PEs. We use this framework to develop a novel PE method called\nRoPEPool, capable of extracting causal relationships from temporal sequences.\nUsing RFF-based PEs and rotation-based PEs, we demonstrate how seemingly\ndisparate PEs can be jointly studied by considering the content-context\ninteractions they induce. For empirical validation, we use a symbolic music\ngeneration task, namely, melody harmonization. We show that RoPEPool, combined\nwith highly-informative structural priors, outperforms all methods.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05364v1",
    "published_date": "2025-04-07 11:51:29 UTC",
    "updated_date": "2025-04-07 11:51:29 UTC"
  },
  {
    "arxiv_id": "2504.04954v1",
    "title": "GOTHAM: Graph Class Incremental Learning Framework under Weak Supervision",
    "authors": [
      "Aditya Hemant Shahane",
      "Prathosh A. P",
      "Sandeep Kumar"
    ],
    "abstract": "Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04954v1",
    "published_date": "2025-04-07 11:39:13 UTC",
    "updated_date": "2025-04-07 11:39:13 UTC"
  },
  {
    "arxiv_id": "2504.04953v1",
    "title": "M-Prometheus: A Suite of Open Multilingual LLM Judges",
    "authors": [
      "José Pombal",
      "Dongkeun Yoon",
      "Patrick Fernandes",
      "Ian Wu",
      "Seungone Kim",
      "Ricardo Rei",
      "Graham Neubig",
      "André F. T. Martins"
    ],
    "abstract": "The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04953v1",
    "published_date": "2025-04-07 11:37:26 UTC",
    "updated_date": "2025-04-07 11:37:26 UTC"
  },
  {
    "arxiv_id": "2504.04949v1",
    "title": "One Quantizer is Enough: Toward a Lightweight Audio Codec",
    "authors": [
      "Linwei Zhai",
      "Han Ding",
      "Cui Zhao",
      "fei wang",
      "Ge Wang",
      "Wang Zhi",
      "Wei Xi"
    ],
    "abstract": "Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "68T07",
      "I.2.m"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04949v1",
    "published_date": "2025-04-07 11:34:39 UTC",
    "updated_date": "2025-04-07 11:34:39 UTC"
  },
  {
    "arxiv_id": "2504.04945v1",
    "title": "A Llama walks into the 'Bar': Efficient Supervised Fine-Tuning for Legal Reasoning in the Multi-state Bar Exam",
    "authors": [
      "Rean Fernandes",
      "André Biedenkapp",
      "Frank Hutter",
      "Noor Awad"
    ],
    "abstract": "Legal reasoning tasks present unique challenges for large language models\n(LLMs) due to the complexity of domain-specific knowledge and reasoning\nprocesses. This paper investigates how effectively smaller language models\n(Llama 2 7B and Llama 3 8B) can be fine-tuned with a limited dataset of 1,514\nMulti-state Bar Examination (MBE) questions to improve legal question answering\naccuracy. We evaluate these models on the 2022 MBE questions licensed from JD\nAdvising, the same dataset used in the 'GPT-4 passes the Bar exam' study. Our\nmethodology involves collecting approximately 200 questions per legal domain\nacross 7 domains. We distill the dataset using Llama 3 (70B) to transform\nexplanations into a structured IRAC (Issue, Rule, Application, Conclusion)\nformat as a guided reasoning process to see if it results in better performance\nover the non-distilled dataset. We compare the non-fine-tuned models against\ntheir supervised fine-tuned (SFT) counterparts, trained for different sample\nsizes per domain, to study the effect on accuracy and prompt adherence. We also\nanalyse option selection biases and their mitigation following SFT. In\naddition, we consolidate the performance across multiple variables: prompt type\n(few-shot vs zero-shot), answer ordering (chosen-option first vs\ngenerated-explanation first), response format (Numbered list vs Markdown vs\nJSON), and different decoding temperatures. Our findings show that\ndomain-specific SFT helps some model configurations achieve close to human\nbaseline performance, despite limited computational resources and a relatively\nsmall dataset. We release both the gathered SFT dataset and the family of\nSupervised Fine-tuned (SFT) adapters optimised for MBE performance. This\nestablishes a practical lower bound on resources needed towards achieving\neffective legal question answering in smaller LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "COLM 2025 preprint, 9 pages, 3 figures, 16 appendix pages",
    "pdf_url": "http://arxiv.org/pdf/2504.04945v1",
    "published_date": "2025-04-07 11:31:22 UTC",
    "updated_date": "2025-04-07 11:31:22 UTC"
  },
  {
    "arxiv_id": "2504.04942v1",
    "title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing",
    "authors": [
      "Yousef Alhessi",
      "Sólrún Halla Einarsdóttir",
      "George Granberry",
      "Emily First",
      "Moa Johansson",
      "Sorin Lerner",
      "Nicholas Smallbone"
    ],
    "abstract": "Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04942v1",
    "published_date": "2025-04-07 11:30:36 UTC",
    "updated_date": "2025-04-07 11:30:36 UTC"
  },
  {
    "arxiv_id": "2504.04939v2",
    "title": "A Taxonomy of Self-Handover",
    "authors": [
      "Naoki Wake",
      "Atsushi Kanehira",
      "Kazuhiro Sasabuchi",
      "Jun Takamatsu",
      "Katsushi Ikeuchi"
    ],
    "abstract": "Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 figures, 1 table, Last updated on April 7th, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04939v2",
    "published_date": "2025-04-07 11:21:42 UTC",
    "updated_date": "2025-04-08 10:18:43 UTC"
  },
  {
    "arxiv_id": "2504.04935v1",
    "title": "RCCFormer: A Robust Crowd Counting Network Based on Transformer",
    "authors": [
      "Peng Liu",
      "Heng-Chao Li",
      "Sen Lei",
      "Nanqing Liu",
      "Bin Feng",
      "Xiao Wu"
    ],
    "abstract": "Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04935v1",
    "published_date": "2025-04-07 11:19:05 UTC",
    "updated_date": "2025-04-07 11:19:05 UTC"
  },
  {
    "arxiv_id": "2504.04934v1",
    "title": "Boosting Relational Deep Learning with Pretrained Tabular Models",
    "authors": [
      "Veronica Lachi",
      "Antonio Longa",
      "Beatrice Bevilacqua",
      "Bruno Lepri",
      "Andrea Passerini",
      "Bruno Ribeiro"
    ],
    "abstract": "Relational databases, organized into tables connected by primary-foreign key\nrelationships, are a common format for organizing data. Making predictions on\nrelational data often involves transforming them into a flat tabular format\nthrough table joins and feature engineering, which serve as input to tabular\nmethods. However, designing features that fully capture complex relational\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\nalternative by inherently modeling these relationships, but their time overhead\nduring inference limits their applicability for real-time scenarios. In this\nwork, we aim to bridge this gap by leveraging existing feature engineering\nefforts to enhance the efficiency of GNNs in relational databases.\nSpecifically, we use GNNs to capture complex relationships within relational\ndatabases, patterns that are difficult to featurize, while employing engineered\nfeatures to encode temporal information, thereby avoiding the need to retain\nthe entire historical graph and enabling the use of smaller, more efficient\ngraphs. Our \\textsc{LightRDL} approach not only improves efficiency, but also\noutperforms existing models. Experimental results on the RelBench benchmark\ndemonstrate that our framework achieves up to $33\\%$ performance improvement\nand a $526\\times$ inference speedup compared to GNNs, making it highly suitable\nfor real-time inference.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04934v1",
    "published_date": "2025-04-07 11:19:04 UTC",
    "updated_date": "2025-04-07 11:19:04 UTC"
  },
  {
    "arxiv_id": "2504.13899v1",
    "title": "Predicting Satisfaction of Counterfactual Explanations from Human Ratings of Explanatory Qualities",
    "authors": [
      "Marharyta Domnich",
      "Rasmus Moorits Veski",
      "Julius Välja",
      "Kadi Tulver",
      "Raul Vicente"
    ],
    "abstract": "Counterfactual explanations are a widely used approach in Explainable AI,\noffering actionable insights into decision-making by illustrating how small\nchanges to input data can lead to different outcomes. Despite their importance,\nevaluating the quality of counterfactual explanations remains an open problem.\nTraditional quantitative metrics, such as sparsity or proximity, fail to fully\naccount for human preferences in explanations, while user studies are\ninsightful but not scalable. Moreover, relying only on a single overall\nsatisfaction rating does not lead to a nuanced understanding of why certain\nexplanations are effective or not. To address this, we analyze a dataset of\ncounterfactual explanations that were evaluated by 206 human participants, who\nrated not only overall satisfaction but also seven explanatory criteria:\nfeasibility, coherence, complexity, understandability, completeness, fairness,\nand trust. Modeling overall satisfaction as a function of these criteria, we\nfind that feasibility (the actionability of suggested changes) and trust (the\nbelief that the changes would lead to the desired outcome) consistently stand\nout as the strongest predictors of user satisfaction, though completeness also\nemerges as a meaningful contributor. Crucially, even excluding feasibility and\ntrust, other metrics explain 58% of the variance, highlighting the importance\nof additional explanatory qualities. Complexity appears independent, suggesting\nmore detailed explanations do not necessarily reduce satisfaction. Strong\nmetric correlations imply a latent structure in how users judge quality, and\ndemographic background significantly shapes ranking patterns. These insights\ninform the design of counterfactual algorithms that adapt explanatory qualities\nto user expertise and domain context.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "This work has been accepted to The 3rd World Conference on\n  eXplainable Artificial Intelligence (xAI 2025), July 9-11, 2025 - Istanbul,\n  Turkey",
    "pdf_url": "http://arxiv.org/pdf/2504.13899v1",
    "published_date": "2025-04-07 11:09:25 UTC",
    "updated_date": "2025-04-07 11:09:25 UTC"
  },
  {
    "arxiv_id": "2504.04921v1",
    "title": "Expectations vs Reality -- A Secondary Study on AI Adoption in Software Testing",
    "authors": [
      "Katja Karhu",
      "Jussi Kasurinen",
      "Kari Smolander"
    ],
    "abstract": "In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "26 pages, 1 figure, submitted to Software Testing, Vertification and\n  Reliability journal",
    "pdf_url": "http://arxiv.org/pdf/2504.04921v1",
    "published_date": "2025-04-07 11:03:54 UTC",
    "updated_date": "2025-04-07 11:03:54 UTC"
  },
  {
    "arxiv_id": "2504.04918v1",
    "title": "Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B",
    "authors": [
      "Xue Zhang"
    ],
    "abstract": "As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.",
    "categories": [
      "cs.AI",
      "68T05, 68T50",
      "I.2.6; I.2.7; I.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 2 figures. Conducted as part of research on alignment\n  techniques for language models",
    "pdf_url": "http://arxiv.org/pdf/2504.04918v1",
    "published_date": "2025-04-07 11:01:25 UTC",
    "updated_date": "2025-04-07 11:01:25 UTC"
  },
  {
    "arxiv_id": "2504.04915v1",
    "title": "Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration",
    "authors": [
      "Ran Xu",
      "Wenqi Shi",
      "Yuchen Zhuang",
      "Yue Yu",
      "Joyce C. Ho",
      "Haoyu Wang",
      "Carl Yang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Code: https://github.com/ritaranx/Collab-RAG/",
    "pdf_url": "http://arxiv.org/pdf/2504.04915v1",
    "published_date": "2025-04-07 10:52:22 UTC",
    "updated_date": "2025-04-07 10:52:22 UTC"
  },
  {
    "arxiv_id": "2504.04909v1",
    "title": "AlgOS: Algorithm Operating System",
    "authors": [
      "Llewyn Salt",
      "Marcus Gallagher"
    ],
    "abstract": "Algorithm Operating System (AlgOS) is an unopinionated, extensible, modular\nframework for algorithmic implementations. AlgOS offers numerous features:\nintegration with Optuna for automated hyperparameter tuning; automated argument\nparsing for generic command-line interfaces; automated registration of new\nclasses; and a centralised database for logging experiments and studies. These\nfeatures are designed to reduce the overhead of implementing new algorithms and\nto standardise the comparison of algorithms. The standardisation of algorithmic\nimplementations is crucial for reproducibility and reliability in research.\nAlgOS combines Abstract Syntax Trees with a novel implementation of the\nObserver pattern to control the logical flow of algorithmic segments.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04909v1",
    "published_date": "2025-04-07 10:36:46 UTC",
    "updated_date": "2025-04-07 10:36:46 UTC"
  },
  {
    "arxiv_id": "2504.07989v2",
    "title": "Regional Tiny Stories: Using Small Models to Compare Language Learning and Tokenizer Performance",
    "authors": [
      "Nirvan Patil",
      "Malhar Abhay Inamdar",
      "Agnivo Gosai",
      "Guruprasad Pathak",
      "Anish Joshi",
      "Aryan Sagavekar",
      "Anish Joshirao",
      "Raj Dandekar",
      "Rajat Dandekar",
      "Sreedath Panat"
    ],
    "abstract": "Small Language Models (SLMs) offer efficient alternatives to LLMs for\nspecific domains. The 2023 TinyStories study developed an English dataset that\nallows SLMs with 1 to 10 million parameters to produce coherent outputs. Our\nresearch expands this framework by translating the original dataset into Indian\nlanguages and creating synthetic data using LLMs. We focus on Hindi, Marathi,\nand Bengali, evaluating SLMs for regional language processing and understanding\nlinguistic complexity. We show that SLMs efficiently process regional languages\nwith significantly fewer parameters than LLMs, providing a complementary\nframework for ``inference based evaluation\" of tokenization strategies and\nlinguistic complexity. Our analysis shows that language-specific tokenizers\noutperform general-purpose ones for Indian languages. Empirical validations,\nsupported by information-theoretic and morphological analyses, provides\nfundamental understanding behind the better performance of Hindi models over\nMarathi and Bengali. Additionally, we show that synthetic datasets outperform\ntranslated content for training SLMs. Correlation analyses reveal\ncross-linguistic patterns and language-specific relationships between\ncreativity, grammatical precision, and narrative completeness. These findings\nadvance both the practical application of SLMs to underserved languages and our\ntheoretical understanding of neural language development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages, 24 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.07989v2",
    "published_date": "2025-04-07 10:33:14 UTC",
    "updated_date": "2025-04-22 05:18:24 UTC"
  },
  {
    "arxiv_id": "2504.04907v2",
    "title": "Video-Bench: Human-Aligned Video Generation Benchmark",
    "authors": [
      "Hui Han",
      "Siyuan Li",
      "Jiaqi Chen",
      "Yiwen Yuan",
      "Yuling Wu",
      "Chak Tou Leong",
      "Hanwen Du",
      "Junchen Fu",
      "Youhua Li",
      "Jie Zhang",
      "Chi Zhang",
      "Li-jia Li",
      "Yongxin Ni"
    ],
    "abstract": "Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR'25",
    "pdf_url": "http://arxiv.org/pdf/2504.04907v2",
    "published_date": "2025-04-07 10:32:42 UTC",
    "updated_date": "2025-04-29 15:56:46 UTC"
  },
  {
    "arxiv_id": "2504.04903v2",
    "title": "Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision",
    "authors": [
      "Yuandong Pu",
      "Le Zhuo",
      "Kaiwen Zhu",
      "Liangbin Xie",
      "Wenlong Zhang",
      "Xiangyu Chen",
      "Peng Gao",
      "Yu Qiao",
      "Chao Dong",
      "Yihao Liu"
    ],
    "abstract": "We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04903v2",
    "published_date": "2025-04-07 10:22:00 UTC",
    "updated_date": "2025-04-08 07:26:50 UTC"
  },
  {
    "arxiv_id": "2504.04893v4",
    "title": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models",
    "authors": [
      "Justus Westerhoff",
      "Erblina Purelku",
      "Jakob Hackstein",
      "Jonas Loos",
      "Leo Pinetzki",
      "Lorenz Hufe"
    ],
    "abstract": "Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper along with the code for evaluations at\nwww.bliss.berlin/research/scam.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2025 Workshop EVAL-FoMo-2",
    "pdf_url": "http://arxiv.org/pdf/2504.04893v4",
    "published_date": "2025-04-07 10:01:38 UTC",
    "updated_date": "2025-05-16 11:54:09 UTC"
  },
  {
    "arxiv_id": "2504.05358v1",
    "title": "Debate-Feedback: A Multi-Agent Framework for Efficient Legal Judgment Prediction",
    "authors": [
      "Xi Chen",
      "Mao Mao",
      "Shuo Li",
      "Haotian Shangguan"
    ],
    "abstract": "The use of AI in legal analysis and prediction (LegalAI) has gained\nwidespread attention, with past research focusing on retrieval-based methods\nand fine-tuning large models. However, these approaches often require large\ndatasets and underutilize the capabilities of modern large language models\n(LLMs). In this paper, inspired by the debate phase of real courtroom trials,\nwe propose a novel legal judgment prediction model based on the Debate-Feedback\narchitecture, which integrates LLM multi-agent debate and reliability\nevaluation models. Unlike traditional methods, our model achieves significant\nimprovements in efficiency by minimizing the need for large historical\ndatasets, thus offering a lightweight yet robust solution. Comparative\nexperiments show that it outperforms several general-purpose and\ndomain-specific legal models, offering a dynamic reasoning process and a\npromising direction for future LegalAI research.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05358v1",
    "published_date": "2025-04-07 09:34:14 UTC",
    "updated_date": "2025-04-07 09:34:14 UTC"
  },
  {
    "arxiv_id": "2504.05357v1",
    "title": "Find A Winning Sign: Sign Is All We Need to Win the Lottery",
    "authors": [
      "Junghun Oh",
      "Sungyong Baik",
      "Kyoung Mu Lee"
    ],
    "abstract": "The Lottery Ticket Hypothesis (LTH) posits the existence of a sparse\nsubnetwork (a.k.a. winning ticket) that can generalize comparably to its\nover-parameterized counterpart when trained from scratch. The common approach\nto finding a winning ticket is to preserve the original strong generalization\nthrough Iterative Pruning (IP) and transfer information useful for achieving\nthe learned generalization by applying the resulting sparse mask to an\nuntrained network. However, existing IP methods still struggle to generalize\ntheir observations beyond ad-hoc initialization and small-scale architectures\nor datasets, or they bypass these challenges by applying their mask to trained\nweights instead of initialized ones. In this paper, we demonstrate that the\nparameter sign configuration plays a crucial role in conveying useful\ninformation for generalization to any randomly initialized network. Through\nlinear mode connectivity analysis, we observe that a sparse network trained by\nan existing IP method can retain its basin of attraction if its parameter signs\nand normalization layer parameters are preserved. To take a step closer to\nfinding a winning ticket, we alleviate the reliance on normalization layer\nparameters by preventing high error barriers along the linear path between the\nsparse network trained by our method and its counterpart with initialized\nnormalization layer parameters. Interestingly, across various architectures and\ndatasets, we observe that any randomly initialized network can be optimized to\nexhibit low error barriers along the linear path to the sparse network trained\nby our method by inheriting its sparsity and parameter sign information,\npotentially achieving performance comparable to the original. The code is\navailable at https://github.com/JungHunOh/AWS\\_ICLR2025.git",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05357v1",
    "published_date": "2025-04-07 09:30:38 UTC",
    "updated_date": "2025-04-07 09:30:38 UTC"
  },
  {
    "arxiv_id": "2504.04874v1",
    "title": "Futureproof Static Memory Planning",
    "authors": [
      "Christos Lamprakos",
      "Panagiotis Xanthopoulos",
      "Manolis Katsaragakis",
      "Sotirios Xydis",
      "Dimitrios Soudris",
      "Francky Catthoor"
    ],
    "abstract": "The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.",
    "categories": [
      "cs.OS",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.OS",
    "comment": "Submitted to ACM TOPLAS",
    "pdf_url": "http://arxiv.org/pdf/2504.04874v1",
    "published_date": "2025-04-07 09:28:54 UTC",
    "updated_date": "2025-04-07 09:28:54 UTC"
  },
  {
    "arxiv_id": "2504.05356v2",
    "title": "DyTTP: Trajectory Prediction with Normalization-Free Transformers",
    "authors": [
      "JianLin Zhu",
      "HongKuo Niu"
    ],
    "abstract": "Accurate trajectory prediction is a cornerstone for the safe operation of\nautonomous driving systems, where understanding the dynamic behavior of\nsurrounding agents is crucial. Transformer-based architectures have\ndemonstrated significant promise in capturing complex spatio-temporality\ndependencies. However, their reliance on normalization layers can lead to\ncomputation overhead and training instabilities. In this work, we present a\ntwo-fold approach to address these challenges. First, we integrate DynamicTanh\n(DyT), which is the latest method to promote transformers, into the backbone,\nreplacing traditional layer normalization. This modification simplifies the\nnetwork architecture and improves the stability of the inference. We are the\nfirst work to deploy the DyT to the trajectory prediction task. Complementing\nthis, we employ a snapshot ensemble strategy to further boost trajectory\nprediction performance. Using cyclical learning rate scheduling, multiple model\nsnapshots are captured during a single training run. These snapshots are then\naggregated via simple averaging at inference time, allowing the model to\nbenefit from diverse hypotheses without incurring substantial additional\ncomputational cost. Extensive experiments on Argoverse datasets demonstrate\nthat our combined approach significantly improves prediction accuracy,\ninference speed and robustness in diverse driving scenarios. This work\nunderscores the potential of normalization-free transformer designs augmented\nwith lightweight ensemble techniques in advancing trajectory forecasting for\nautonomous vehicles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05356v2",
    "published_date": "2025-04-07 09:26:25 UTC",
    "updated_date": "2025-05-06 14:46:21 UTC"
  },
  {
    "arxiv_id": "2504.04867v1",
    "title": "FedSAUC: A Similarity-Aware Update Control for Communication-Efficient Federated Learning in Edge Computing",
    "authors": [
      "Ming-Lun Lee",
      "Han-Chang Chou",
      "Yan-Ann Chen"
    ],
    "abstract": "Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Proceedings of the International Conference on\n  Mobile Computing and Ubiquitous Network (ICMU), 2021",
    "pdf_url": "http://arxiv.org/pdf/2504.04867v1",
    "published_date": "2025-04-07 09:21:43 UTC",
    "updated_date": "2025-04-07 09:21:43 UTC"
  },
  {
    "arxiv_id": "2504.04862v1",
    "title": "GAMDTP: Dynamic Trajectory Prediction with Graph Attention Mamba Network",
    "authors": [
      "Yunxiang Liu",
      "Hongkuo Niu",
      "Jianlin Zhu"
    ],
    "abstract": "Accurate motion prediction of traffic agents is crucial for the safety and\nstability of autonomous driving systems. In this paper, we introduce GAMDTP, a\nnovel graph attention-based network tailored for dynamic trajectory prediction.\nSpecifically, we fuse the result of self attention and mamba-ssm through a gate\nmechanism, leveraging the strengths of both to extract features more\nefficiently and accurately, in each graph convolution layer. GAMDTP encodes the\nhigh-definition map(HD map) data and the agents' historical trajectory\ncoordinates and decodes the network's output to generate the final prediction\nresults. Additionally, recent approaches predominantly focus on dynamically\nfusing historical forecast results and rely on two-stage frameworks including\nproposal and refinement. To further enhance the performance of the two-stage\nframeworks we also design a scoring mechanism to evaluate the prediction\nquality during the proposal and refinement processes. Experiments on the\nArgoverse dataset demonstrates that GAMDTP achieves state-of-the-art\nperformance, achieving superior accuracy in dynamic trajectory prediction.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04862v1",
    "published_date": "2025-04-07 09:19:20 UTC",
    "updated_date": "2025-04-07 09:19:20 UTC"
  },
  {
    "arxiv_id": "2504.04861v1",
    "title": "SAFT: Structure-aware Transformers for Textual Interaction Classification",
    "authors": [
      "Hongtao Wang",
      "Renchi Yang",
      "Hewen Wang",
      "Haoran Zheng",
      "Jianliang Xu"
    ],
    "abstract": "Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04861v1",
    "published_date": "2025-04-07 09:19:12 UTC",
    "updated_date": "2025-04-07 09:19:12 UTC"
  },
  {
    "arxiv_id": "2504.04858v1",
    "title": "Don't Lag, RAG: Training-Free Adversarial Detection Using RAG",
    "authors": [
      "Roie Kazoom",
      "Raz Lapid",
      "Moshe Sipper",
      "Ofer Hadar"
    ],
    "abstract": "Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04858v1",
    "published_date": "2025-04-07 09:14:47 UTC",
    "updated_date": "2025-04-07 09:14:47 UTC"
  },
  {
    "arxiv_id": "2504.04855v1",
    "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents",
    "authors": [
      "Haoxuan Li",
      "Mingyu Derek Ma",
      "Jen-tse Huang",
      "Zhaotian Weng",
      "Wei Wang",
      "Jieyu Zhao"
    ],
    "abstract": "Detecting biases in structured data is a complex and time-consuming task.\nExisting automated techniques are limited in diversity of data types and\nheavily reliant on human case-by-case handling, resulting in a lack of\ngeneralizability. Currently, large language model (LLM)-based agents have made\nsignificant progress in data science, but their ability to detect data biases\nis still insufficiently explored. To address this gap, we introduce the first\nend-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for\nautomatic bias detection in structured data based on specific user\nrequirements. It first develops a multi-stage plan to analyze user-specified\nbias detection tasks and then implements it with a diverse and well-suited set\nof tools. It delivers detailed results that include explanations and\nvisualizations. To address the lack of a standardized framework for evaluating\nthe capability of LLM agents to detect biases in data, we further propose a\ncomprehensive benchmark that includes multiple evaluation metrics and a large\nset of test cases. Extensive experiments demonstrate that our framework\nachieves exceptional overall performance in structured data bias detection,\nsetting a new milestone for fairer data applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04855v1",
    "published_date": "2025-04-07 09:12:00 UTC",
    "updated_date": "2025-04-07 09:12:00 UTC"
  },
  {
    "arxiv_id": "2504.04850v1",
    "title": "An Efficient Approach for Cooperative Multi-Agent Learning Problems",
    "authors": [
      "Ángel Aso-Mollar",
      "Eva Onaindia"
    ],
    "abstract": "In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICTAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2504.04850v1",
    "published_date": "2025-04-07 09:03:35 UTC",
    "updated_date": "2025-04-07 09:03:35 UTC"
  },
  {
    "arxiv_id": "2504.04833v2",
    "title": "Explanation-Driven Interventions for Artificial Intelligence Model Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology",
    "authors": [
      "Andrea Esposito",
      "Miriana Calvano",
      "Antonio Curci",
      "Francesco Greco",
      "Rosa Lanzilotti",
      "Antonio Piccinno"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) in modern society is\ntransforming how individuals perform tasks. In high-risk domains, ensuring\nhuman control over AI systems remains a key design challenge. This article\npresents a novel End-User Development (EUD) approach for black-box AI models,\nenabling users to edit explanations and influence future predictions through\ntargeted interventions. By combining explainability, user control, and model\nadaptability, the proposed method advances Human-Centered AI (HCAI), promoting\na symbiotic relationship between humans and adaptive, user-tailored AI systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Second version (11 pages, 8 of content)",
    "pdf_url": "http://arxiv.org/pdf/2504.04833v2",
    "published_date": "2025-04-07 08:44:48 UTC",
    "updated_date": "2025-04-14 16:21:20 UTC"
  },
  {
    "arxiv_id": "2504.04827v1",
    "title": "From Specificity to Generality: Revisiting Generalizable Artifacts in Detecting Face Deepfakes",
    "authors": [
      "Long Ma",
      "Zhiyuan Yan",
      "Yize Chen",
      "Jin Xu",
      "Qinglang Guo",
      "Hu Huang",
      "Yong Liao",
      "Hui Lin"
    ],
    "abstract": "Detecting deepfakes has been an increasingly important topic, especially\ngiven the rapid development of AI generation techniques. In this paper, we ask:\nHow can we build a universal detection framework that is effective for most\nfacial deepfakes? One significant challenge is the wide variety of deepfake\ngenerators available, resulting in varying forgery artifacts (e.g., lighting\ninconsistency, color mismatch, etc). But should we ``teach\" the detector to\nlearn all these artifacts separately? It is impossible and impractical to\nelaborate on them all. So the core idea is to pinpoint the more common and\ngeneral artifacts across different deepfakes. Accordingly, we categorize\ndeepfake artifacts into two distinct yet complementary types: Face\nInconsistency Artifacts (FIA) and Up-Sampling Artifacts (USA). FIA arise from\nthe challenge of generating all intricate details, inevitably causing\ninconsistencies between the complex facial features and relatively uniform\nsurrounding areas. USA, on the other hand, are the inevitable traces left by\nthe generator's decoder during the up-sampling process. This categorization\nstems from the observation that all existing deepfakes typically exhibit one or\nboth of these artifacts. To achieve this, we propose a new data-level\npseudo-fake creation framework that constructs fake samples with only the FIA\nand USA, without introducing extra less-general artifacts. Specifically, we\nemploy a super-resolution to simulate the USA, while design a Blender module\nthat uses image-level self-blending on diverse facial regions to create the\nFIA. We surprisingly found that, with this intuitive design, a standard image\nclassifier trained only with our pseudo-fake data can non-trivially generalize\nwell to unseen deepfakes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04827v1",
    "published_date": "2025-04-07 08:34:28 UTC",
    "updated_date": "2025-04-07 08:34:28 UTC"
  },
  {
    "arxiv_id": "2504.04823v1",
    "title": "Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models",
    "authors": [
      "Ruikang Liu",
      "Yuxuan Sun",
      "Manyi Zhang",
      "Haoli Bai",
      "Xianzhi Yu",
      "Tiezheng Yu",
      "Chun Yuan",
      "Lu Hou"
    ],
    "abstract": "Recent advancements in reasoning language models have demonstrated remarkable\nperformance in complex tasks, but their extended chain-of-thought reasoning\nprocess increases inference overhead. While quantization has been widely\nadopted to reduce the inference cost of large language models, its impact on\nreasoning models remains understudied. In this study, we conduct the first\nsystematic study on quantized reasoning models, evaluating the open-sourced\nDeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B\nparameters, and QwQ-32B. Our investigation covers weight, KV cache, and\nactivation quantization using state-of-the-art algorithms at varying\nbit-widths, with extensive evaluation across mathematical (AIME, MATH-500),\nscientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our\nfindings reveal that while lossless quantization can be achieved with W8A8 or\nW4A16 quantization, lower bit-widths introduce significant accuracy risks. We\nfurther identify model size, model origin, and task difficulty as critical\ndeterminants of performance. Contrary to expectations, quantized models do not\nexhibit increased output lengths. In addition, strategically scaling the model\nsizes or reasoning steps can effectively enhance the performance. All quantized\nmodels and codes will be open-sourced in\nhttps://github.com/ruikangliu/Quantized-Reasoning-Models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04823v1",
    "published_date": "2025-04-07 08:22:45 UTC",
    "updated_date": "2025-04-07 08:22:45 UTC"
  },
  {
    "arxiv_id": "2504.04821v1",
    "title": "A Customized SAT-based Solver for Graph Coloring",
    "authors": [
      "Timo Brand",
      "Daniel Faber",
      "Stephan Held",
      "Petra Mutzel"
    ],
    "abstract": "We introduce ZykovColor, a novel SAT-based algorithm to solve the graph\ncoloring problem working on top of an encoding that mimics the Zykov tree. Our\nmethod is based on an approach of H\\'ebrard and Katsirelos (2020) that employs\na propagator to enforce transitivity constraints, incorporate lower bounds for\nsearch tree pruning, and enable inferred propagations. We leverage the recently\nintroduced IPASIR-UP interface for CaDiCal to implement these techniques with a\nSAT solver. Furthermore, we propose new features that take advantage of the\nunderlying SAT solver. These include modifying the integrated decision strategy\nwith vertex domination hints and using incremental bottom-up search that allows\nto reuse learned clauses from previous calls. Additionally, we integrate a more\nefficient clique computation to improve the lower bounds during the search. We\nvalidate the effectiveness of each new feature through an experimental\nanalysis. ZykovColor outperforms other state-of-the-art graph coloring\nimplementations on the DIMACS benchmark set. Further experiments on random\nErd\\H{o}s-R\\'enyi graphs show that our new approach dominates state-of-the-art\nSAT-based methods for both very sparse and highly dense graphs.",
    "categories": [
      "cs.DM",
      "cs.AI",
      "cs.DS",
      "cs.LO",
      "05C15",
      "G.2.2"
    ],
    "primary_category": "cs.DM",
    "comment": "5 figures, 2 tables, source code published at\n  https://github.com/trewes/ZykovColor",
    "pdf_url": "http://arxiv.org/pdf/2504.04821v1",
    "published_date": "2025-04-07 08:22:00 UTC",
    "updated_date": "2025-04-07 08:22:00 UTC"
  },
  {
    "arxiv_id": "2504.04808v2",
    "title": "ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines",
    "authors": [
      "Tengjun Jin",
      "Yuxuan Zhu",
      "Daniel Kang"
    ],
    "abstract": "Practitioners are increasingly turning to Extract-Load-Transform (ELT)\npipelines with the widespread adoption of cloud data warehouses. However,\ndesigning these pipelines often involves significant manual work to ensure\ncorrectness. Recent advances in AI-based methods, which have shown strong\ncapabilities in data tasks, such as text-to-SQL, present an opportunity to\nalleviate manual efforts in developing ELT pipelines. Unfortunately, current\nbenchmarks in data engineering only evaluate isolated tasks, such as using data\ntools and writing data transformation queries, leaving a significant gap in\nevaluating AI agents for generating end-to-end ELT pipelines.\n  To fill this gap, we introduce ELT-Bench, an end-to-end benchmark designed to\nassess the capabilities of AI agents to build ELT pipelines. ELT-Bench consists\nof 100 pipelines, including 835 source tables and 203 data models across\nvarious domains. By simulating realistic scenarios involving the integration of\ndiverse data sources and the use of popular data tools, ELT-Bench evaluates AI\nagents' abilities in handling complex data engineering workflows. AI agents\nmust interact with databases and data tools, write code and SQL queries, and\norchestrate every pipeline stage. We evaluate two representative code agent\nframeworks, Spider-Agent and SWE-Agent, using six popular Large Language Models\n(LLMs) on ELT-Bench. The highest-performing agent, Spider-Agent\nClaude-3.7-Sonnet with extended thinking, correctly generates only 3.9% of data\nmodels, with an average cost of $4.30 and 89.3 steps per pipeline. Our\nexperimental results demonstrate the challenges of ELT-Bench and highlight the\nneed for a more advanced AI agent to reduce manual effort in ELT workflows. Our\ncode and data are available at https://github.com/uiuc-kang-lab/ELT-Bench.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "14 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04808v2",
    "published_date": "2025-04-07 08:03:36 UTC",
    "updated_date": "2025-04-14 19:46:56 UTC"
  },
  {
    "arxiv_id": "2504.04789v1",
    "title": "Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for Intelligent Agricultural Decision-Making",
    "authors": [
      "Zhuoning Xu",
      "Jian Xu",
      "Mingqing Zhang",
      "Peijie Wang",
      "Chao Deng",
      "Cheng-Lin Liu"
    ],
    "abstract": "As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04789v1",
    "published_date": "2025-04-07 07:32:41 UTC",
    "updated_date": "2025-04-07 07:32:41 UTC"
  },
  {
    "arxiv_id": "2504.04787v1",
    "title": "Dynamic Vision Mamba",
    "authors": [
      "Mengxuan Wu",
      "Zekai Li",
      "Zhiyuan Liang",
      "Moyang Li",
      "Xuanlei Zhao",
      "Samir Khaki",
      "Zheng Zhu",
      "Xiaojiang Peng",
      "Konstantinos N. Plataniotis",
      "Kai Wang",
      "Wangbo Zhao",
      "Yang You"
    ],
    "abstract": "Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04787v1",
    "published_date": "2025-04-07 07:31:28 UTC",
    "updated_date": "2025-04-07 07:31:28 UTC"
  },
  {
    "arxiv_id": "2504.04785v1",
    "title": "Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors",
    "authors": [
      "Fan Nie",
      "Lan Feng",
      "Haotian Ye",
      "Weixin Liang",
      "Pan Lu",
      "Huaxiu Yao",
      "Alexandre Alahi",
      "James Zou"
    ],
    "abstract": "Efficiently leveraging of the capabilities of contemporary large language\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\nis expensive and often impractical. Existing training-free methods, including\nmanually or automated designed workflows, typically demand substantial human\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\nlanguage models to design and optimize workflows for harnessing stronger\nmodels. W4S formulates workflow design as a multi-turn markov decision process\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\nto train a weak meta-agent. Through iterative interaction with the environment,\nthe meta-agent learns to design increasingly effective workflows without manual\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\nNotably, W4S exhibits strong generalization capabilities across both seen and\nunseen tasks, offering an efficient, high-performing alternative to directly\nfine-tuning strong models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04785v1",
    "published_date": "2025-04-07 07:27:31 UTC",
    "updated_date": "2025-04-07 07:27:31 UTC"
  },
  {
    "arxiv_id": "2504.04770v1",
    "title": "Bidirectional Hierarchical Protein Multi-Modal Representation Learning",
    "authors": [
      "Xuefeng Liu",
      "Songhao Jiang",
      "Chih-chan Tien",
      "Jinbo Xu",
      "Rick Stevens"
    ],
    "abstract": "Protein representation learning is critical for numerous biological tasks.\nRecently, large transformer-based protein language models (pLMs) pretrained on\nlarge scale protein sequences have demonstrated significant success in\nsequence-based tasks. However, pLMs lack structural information. Conversely,\ngraph neural networks (GNNs) designed to leverage 3D structural information\nhave shown promising generalization in protein-related prediction tasks, but\ntheir effectiveness is often constrained by the scarcity of labeled structural\ndata. Recognizing that sequence and structural representations are\ncomplementary perspectives of the same protein entity, we propose a multimodal\nbidirectional hierarchical fusion framework to effectively merge these\nmodalities. Our framework employs attention and gating mechanisms to enable\neffective interaction between pLMs-generated sequential representations and\nGNN-extracted structural features, improving information exchange and\nenhancement across layers of the neural network. Based on the framework, we\nfurther introduce local Bi-Hierarchical Fusion with gating and global\nBi-Hierarchical Fusion with multihead self-attention approaches. Through\nextensive experiments on a diverse set of protein-related tasks, our method\ndemonstrates consistent improvements over strong baselines and existing fusion\ntechniques in a variety of protein representation learning benchmarks,\nincluding react (enzyme/EC classification), model quality assessment (MQA),\nprotein-ligand binding affinity prediction (LBA), protein-protein binding site\nprediction (PPBS), and B cell epitopes prediction (BCEs). Our method\nestablishes a new state-of-the-art for multimodal protein representation\nlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging\nsequence and structural modalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04770v1",
    "published_date": "2025-04-07 06:47:49 UTC",
    "updated_date": "2025-04-07 06:47:49 UTC"
  },
  {
    "arxiv_id": "2504.04766v1",
    "title": "KunPeng: A Global Ocean Environmental Model",
    "authors": [
      "Yi Zhao",
      "Jiaqi Li",
      "Haitao Xia",
      "Tianjiao Zhang",
      "Zerong Zeng",
      "Tianyu Ren",
      "Yucheng Zhang",
      "Chao Zhu",
      "Shengtong Xu",
      "Hongchun Yuan"
    ],
    "abstract": "Inspired by the similarity of the atmosphere-ocean physical coupling\nmechanism, this study innovatively migrates meteorological large-model\ntechniques to the ocean domain, constructing the KunPeng global ocean\nenvironmental prediction model. Aimed at the discontinuous characteristics of\nmarine space, we propose a terrain-adaptive mask constraint mechanism to\nmitigate effectively training divergence caused by abrupt gradients at land-sea\nboundaries. To fully integrate far-, medium-, and close-range marine features,\na longitude-cyclic deformable convolution network (LC-DCN) is employed to\nenhance the dynamic receptive field, achieving refined modeling of multi-scale\noceanic characteristics. A Deformable Convolution-enhanced Multi-Step\nPrediction module (DC-MTP) is employed to strengthen temporal dependency\nfeature extraction capabilities. Experimental results demonstrate that this\nmodel achieves an average ACC of 0.80 in 15-day global predictions at\n0.25$^\\circ$ resolution, outperforming comparative models by 0.01-0.08. The\naverage mean squared error (MSE) is 0.41 (representing a 5%-31% reduction) and\nthe average mean absolute error (MAE) is 0.44 (0.6%-21% reduction) compared to\nother models. Significant improvements are particularly observed in sea surface\nparameter prediction, deep-sea region characterization, and current velocity\nfield forecasting. Through a horizontal comparison of the applicability of\noperators at different scales in the marine domain, this study reveals that\nlocal operators significantly outperform global operators under slow-varying\noceanic processes, demonstrating the effectiveness of dynamic feature pyramid\nrepresentations in predicting marine physical parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04766v1",
    "published_date": "2025-04-07 06:41:05 UTC",
    "updated_date": "2025-04-07 06:41:05 UTC"
  },
  {
    "arxiv_id": "2504.04764v1",
    "title": "Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model",
    "authors": [
      "Shyam Sundhar",
      "Riya Sharma",
      "Priyansh Maheshwari",
      "Suvidha Rupesh Kumar",
      "T. Sunil Kumar"
    ],
    "abstract": "Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04764v1",
    "published_date": "2025-04-07 06:31:38 UTC",
    "updated_date": "2025-04-07 06:31:38 UTC"
  },
  {
    "arxiv_id": "2504.13898v1",
    "title": "The Human Robot Social Interaction (HSRI) Dataset: Benchmarking Foundational Models' Social Reasoning",
    "authors": [
      "Dong Won Lee",
      "Yubin Kim",
      "Denison Guvenoz",
      "Sooyeon Jeong",
      "Parker Malachowsky",
      "Louis-Philippe Morency",
      "Cynthia Breazeal",
      "Hae Won Park"
    ],
    "abstract": "Our work aims to advance the social reasoning of embodied artificial\nintelligence (AI) agents in real-world social interactions. Recently, language\nmodels (LMs) and foundational models (FMs) are being utilized as automatic\nevaluators of human-AI interactions with the goal of eventually being used to\nimprove the policy of the AI agent. To enable further research in this\ndirection, we introduce a large-scale real-world Human Robot Social Interaction\n(HSRI) Dataset to benchmark the capabilities of LMs and FMs to identify and\nreason about social interactions, specifically with regard to robot social\nerrors and competencies . Our dataset consists of 400 real-world human social\nrobot interaction videos and over 10K annotations, detailing the robot's social\nerrors, competencies, rationale, and corrective actions, capturing unique\naspects of human-AI interaction only present in real-world interactions. To\nfurther assess AI models' ability to reason about social interactions, we\npropose eight new benchmark tasks for evaluating centered around whether AI\nmodels can (1) evaluate social interactions via detecting social errors and\ncompetencies, (2) identify the explanatory factors associated to errors and\ncompetencies, (3) understand the flow of real-world social interactions, and\n(4) provide reasons and corrective actions for social errors. Human studies and\nexperiments with modern LMs and FMs reveal that current models struggle with\nthese tasks, demonstrating that our dataset and benchmark provides a step\nforward towards socially intelligent AI.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "23 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.13898v1",
    "published_date": "2025-04-07 06:27:02 UTC",
    "updated_date": "2025-04-07 06:27:02 UTC"
  },
  {
    "arxiv_id": "2504.04751v1",
    "title": "Unsupervised Estimation of Nonlinear Audio Effects: Comparing Diffusion-Based and Adversarial approaches",
    "authors": [
      "Eloi Moliner",
      "Michal Švento",
      "Alec Wright",
      "Lauri Juvela",
      "Pavel Rajmic",
      "Vesa Välimäki"
    ],
    "abstract": "Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Submitted to the 28th International Conference on Digital Audio\n  Effects (DAFx25)",
    "pdf_url": "http://arxiv.org/pdf/2504.04751v1",
    "published_date": "2025-04-07 05:56:51 UTC",
    "updated_date": "2025-04-07 05:56:51 UTC"
  },
  {
    "arxiv_id": "2504.04744v1",
    "title": "Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions",
    "authors": [
      "He Zhu",
      "Quyu Kong",
      "Kechun Xu",
      "Xunlong Xia",
      "Bing Deng",
      "Jieping Ye",
      "Rong Xiong",
      "Yue Wang"
    ],
    "abstract": "Grounding 3D object affordance is a task that locates objects in 3D space\nwhere they can be manipulated, which links perception and action for embodied\nintelligence. For example, for an intelligent robot, it is necessary to\naccurately ground the affordance of an object and grasp it according to human\ninstructions. In this paper, we introduce a novel task that grounds 3D object\naffordance based on language instructions, visual observations and\ninteractions, which is inspired by cognitive science. We collect an Affordance\nGrounding dataset with Points, Images and Language instructions (AGPIL) to\nsupport the proposed task. In the 3D physical world, due to observation\norientation, object rotation, or spatial occlusion, we can only get a partial\nobservation of the object. So this dataset includes affordance estimations of\nobjects from full-view, partial-view, and rotation-view perspectives. To\naccomplish this task, we propose LMAffordance3D, the first multi-modal,\nlanguage-guided 3D affordance grounding network, which applies a\nvision-language model to fuse 2D and 3D spatial features with semantic\nfeatures. Comprehensive experiments on AGPIL demonstrate the effectiveness and\nsuperiority of our method on this task, even in unseen experimental settings.\nOur project is available at https://sites.google.com/view/lmaffordance3d.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04744v1",
    "published_date": "2025-04-07 05:38:23 UTC",
    "updated_date": "2025-04-07 05:38:23 UTC"
  },
  {
    "arxiv_id": "2504.04740v1",
    "title": "Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data",
    "authors": [
      "Samarth Mishra",
      "Kate Saenko",
      "Venkatesh Saligrama"
    ],
    "abstract": "Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04740v1",
    "published_date": "2025-04-07 05:35:34 UTC",
    "updated_date": "2025-04-07 05:35:34 UTC"
  },
  {
    "arxiv_id": "2504.04737v1",
    "title": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context",
    "authors": [
      "Shubham Kumar Nigam",
      "Balaramamahanthi Deepak Patnaik",
      "Shivam Mishra",
      "Noel Shallum",
      "Kripabandhu Ghosh",
      "Arnab Bhattacharya"
    ],
    "abstract": "In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04737v1",
    "published_date": "2025-04-07 05:27:32 UTC",
    "updated_date": "2025-04-07 05:27:32 UTC"
  },
  {
    "arxiv_id": "2504.04736v2",
    "title": "Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use",
    "authors": [
      "Anna Goldie",
      "Azalia Mirhoseini",
      "Hao Zhou",
      "Irene Cai",
      "Christopher D. Manning"
    ],
    "abstract": "Reinforcement learning has been shown to improve the performance of large\nlanguage models. However, traditional approaches like RLHF or RLAIF treat the\nproblem as single-step. As focus shifts toward more complex reasoning and\nagentic tasks, language models must take multiple steps of text generation,\nreasoning and environment interaction before generating a solution. We propose\na synthetic data generation and RL methodology targeting multi-step\noptimization scenarios. This approach, called Step-Wise Reinforcement Learning\n(SWiRL), iteratively generates multi-step reasoning and tool use data, and then\nlearns from that data. It employs a simple step-wise decomposition that breaks\neach multi-step trajectory into multiple sub-trajectories corresponding to each\naction by the original model. It then applies synthetic data filtering and RL\noptimization on these sub-trajectories. We evaluated SWiRL on a number of\nmulti-step tool use, question answering, and mathematical reasoning tasks. Our\nexperiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,\n14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,\nMuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits\ngeneralization across tasks: for example, training only on HotPotQA (text\nquestion-answering) improves zero-shot performance on GSM8K (a math dataset) by\na relative 16.9%.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04736v2",
    "published_date": "2025-04-07 05:20:58 UTC",
    "updated_date": "2025-04-28 01:20:59 UTC"
  },
  {
    "arxiv_id": "2504.05352v1",
    "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization",
    "authors": [
      "Siqing Song",
      "Chuang Wang",
      "Ruiqi Wang",
      "Yi Yang",
      "Xuyao Zhang"
    ],
    "abstract": "Quantizing large language models (LLMs) to 1-bit precision significantly\nreduces computational costs, but existing quantization techniques suffer from\nnoticeable performance degradation when using weight and activation precisions\nbelow 4 bits (W4A4). In this paper, we propose a post-training quantization\nframework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit\nwith an additional 1 bit for fine-grain grouping and activations are quantized\nto 1 bit with a 4-fold increase in the number of channels. For weight\nquantization, we propose utilizing Hessian-aware fine-grained grouping along\nwith an EM-based quantization scheme. For activation quantization, we decompose\nINT4-quantized activations into a 4 * INT1 format equivalently and\nsimultaneously smooth the scaling factors based on quantization errors, which\nfurther reduces the quantization errors in activations. Our method surpasses\nstate-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple\ntasks, pushing the boundaries of existing LLM quantization methods toward fully\nbinarized models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05352v1",
    "published_date": "2025-04-07 04:50:04 UTC",
    "updated_date": "2025-04-07 04:50:04 UTC"
  },
  {
    "arxiv_id": "2504.04718v1",
    "title": "T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models",
    "authors": [
      "Minki Kang",
      "Jongwon Jeong",
      "Jaewoong Cho"
    ],
    "abstract": "Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.04718v1",
    "published_date": "2025-04-07 04:01:17 UTC",
    "updated_date": "2025-04-07 04:01:17 UTC"
  },
  {
    "arxiv_id": "2504.04717v4",
    "title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models",
    "authors": [
      "Yubo Li",
      "Xiaobin Shen",
      "Xinyu Yao",
      "Xueying Ding",
      "Yidi Miao",
      "Ramayya Krishnan",
      "Rema Padman"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04717v4",
    "published_date": "2025-04-07 04:00:08 UTC",
    "updated_date": "2025-05-14 01:48:30 UTC"
  },
  {
    "arxiv_id": "2504.04711v1",
    "title": "Generalising from Self-Produced Data: Model Training Beyond Human Constraints",
    "authors": [
      "Alfath Daryl Alhajir",
      "Jennifer Dodgson",
      "Joseph Lim",
      "Truong Ma Phi",
      "Julian Peh",
      "Akira Rafhael Janson Pattirane",
      "Lokesh Poovaragan"
    ],
    "abstract": "Current large language models (LLMs) are constrained by human-derived\ntraining data and limited by a single level of abstraction that impedes\ndefinitive truth judgments. This paper introduces a novel framework in which AI\nmodels autonomously generate and validate new knowledge through direct\ninteraction with their environment. Central to this approach is an unbounded,\nungamable numeric reward - such as annexed disk space or follower count - that\nguides learning without requiring human benchmarks. AI agents iteratively\ngenerate strategies and executable code to maximize this metric, with\nsuccessful outcomes forming the basis for self-retraining and incremental\ngeneralisation. To mitigate model collapse and the warm start problem, the\nframework emphasizes empirical validation over textual similarity and supports\nfine-tuning via GRPO. The system architecture employs modular agents for\nenvironment analysis, strategy generation, and code synthesis, enabling\nscalable experimentation. This work outlines a pathway toward self-improving AI\nsystems capable of advancing beyond human-imposed constraints toward autonomous\ngeneral intelligence.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.04711v1",
    "published_date": "2025-04-07 03:48:02 UTC",
    "updated_date": "2025-04-07 03:48:02 UTC"
  },
  {
    "arxiv_id": "2504.04706v1",
    "title": "AdvKT: An Adversarial Multi-Step Training Framework for Knowledge Tracing",
    "authors": [
      "Lingyue Fu",
      "Ting Long",
      "Jianghao Lin",
      "Wei Xia",
      "Xinyi Dai",
      "Ruiming Tang",
      "Yasheng Wang",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "abstract": "Knowledge Tracing (KT) monitors students' knowledge states and simulates\ntheir responses to question sequences. Existing KT models typically follow a\nsingle-step training paradigm, which leads to discrepancies with the multi-step\ninference process required in real-world simulations, resulting in significant\nerror accumulation. This accumulation of error, coupled with the issue of data\nsparsity, can substantially degrade the performance of recommendation models in\nthe intelligent tutoring systems. To address these challenges, we propose a\nnovel Adversarial Multi-Step Training Framework for Knowledge Tracing (AdvKT),\nwhich, for the first time, focuses on the multi-step KT task. More\nspecifically, AdvKT leverages adversarial learning paradigm involving a\ngenerator and a discriminator. The generator mimics high-reward responses,\neffectively reducing error accumulation across multiple steps, while the\ndiscriminator provides feedback to generate synthetic data. Additionally, we\ndesign specialized data augmentation techniques to enrich the training data\nwith realistic variations, ensuring that the model generalizes well even in\nscenarios with sparse data. Experiments conducted on four real-world datasets\ndemonstrate the superiority of AdvKT over existing KT models, showcasing its\nability to address both error accumulation and data sparsity issues\neffectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04706v1",
    "published_date": "2025-04-07 03:31:57 UTC",
    "updated_date": "2025-04-07 03:31:57 UTC"
  },
  {
    "arxiv_id": "2504.04704v1",
    "title": "LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important",
    "authors": [
      "Manlai Liang",
      "JiaMing Zhang",
      "Xiong Li",
      "Jinlong Li"
    ],
    "abstract": "The increasing size of the Key-Value (KV) cache during the Large Language\nModels long-context inference is the main obstacle for its balance between the\ndeployment cost and task accuracy. To reduce the KV cache size in such\nscenarios, most previous efforts leveraged on the attention weight to evict\nnon-critical cache tokens. But there is a trade-off in those methods, they\nusually require major modifiation of the inference infrastructure and\nsignificant computation overhead. Base on the fact that the Large Lanuage\nmodels are autoregresssive models, we propose {\\it LagKV}, a KV allocation\nstrategy only relying on straight forward comparison among KV themself. It is a\ntotally attention free method which offers easy integration to the main stream\ninference platform and comparable performance comparing to other complicated KV\ncompression methods. Results on LongBench and PasskeyRetrieval show that, our\napproach achieves nearly zero loss when the ratio is $2\\times$ and $\\approx\n90\\%$ of the original model performance for $8\\times$. Especially in the\n64-digit passkey retrieval task, our mehod outperforms the attention weight\nbased method $H_2O$ over $60\\%$ with same compression ratios. Our code is\navailable at \\url{https://github.com/AI-Lab-China-Merchants-Bank/LagKV}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04704v1",
    "published_date": "2025-04-07 03:22:15 UTC",
    "updated_date": "2025-04-07 03:22:15 UTC"
  },
  {
    "arxiv_id": "2504.04702v1",
    "title": "Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent",
    "authors": [
      "Bo Chen",
      "Zhenmei Shi",
      "Zhao Song",
      "Jiahao Zhang"
    ],
    "abstract": "Recent advancements in Transformer-based architectures have led to impressive\nbreakthroughs in natural language processing tasks, with models such as GPT-4,\nClaude, and Gemini demonstrating human-level reasoning abilities. However,\ndespite their high performance, concerns remain about the inherent limitations\nof these models, especially when it comes to learning basic logical functions.\nWhile complexity-theoretic analyses indicate that Transformers can represent\nsimple logic functions (e.g., $\\mathsf{AND}$, $\\mathsf{OR}$, and majority\ngates) by its nature of belonging to the $\\mathsf{TC}^0$ class, these results\nassume ideal parameter settings and do not account for the constraints imposed\nby gradient descent-based training methods. In this work, we investigate\nwhether Transformers can truly learn simple majority functions when trained\nusing gradient-based methods. We focus on a simplified variant of the\nTransformer architecture and consider both $n=\\mathrm{poly}(d)$ and\n$n=\\exp(\\Omega(d))$ number of training samples, where each sample is a $d$-size\nbinary string paired with the output of a basic majority function. Our analysis\ndemonstrates that even after $\\mathrm{poly}(d)$ gradient queries, the\ngeneralization error of the Transformer model still remains substantially\nlarge, growing exponentially with $d$. This work highlights fundamental\noptimization challenges in training Transformers for the simplest logical\nreasoning tasks and provides new insights into their theoretical limitations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04702v1",
    "published_date": "2025-04-07 03:08:12 UTC",
    "updated_date": "2025-04-07 03:08:12 UTC"
  },
  {
    "arxiv_id": "2504.04699v1",
    "title": "R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation",
    "authors": [
      "Martin Weyssow",
      "Chengran Yang",
      "Junkai Chen",
      "Yikun Li",
      "Huihui Huang",
      "Ratnadira Widyasari",
      "Han Wei Ang",
      "Frank Liauw",
      "Eng Lieh Ouh",
      "Lwin Khin Shar",
      "David Lo"
    ],
    "abstract": "Large language models (LLMs) have shown promising performance in software\nvulnerability detection (SVD), yet their reasoning capabilities remain\nunreliable. Existing approaches relying on chain-of-thought (CoT) struggle to\nprovide relevant and actionable security assessments. Additionally, effective\nSVD requires not only generating coherent reasoning but also differentiating\nbetween well-founded and misleading yet plausible security assessments, an\naspect overlooked in prior work. To this end, we introduce R2Vul, a novel\napproach that distills structured reasoning into small LLMs using reinforcement\nlearning from AI feedback (RLAIF). Through RLAIF, R2Vul enables LLMs to produce\nstructured, security-aware reasoning that is actionable and reliable while\nexplicitly learning to distinguish valid assessments from misleading ones. We\nevaluate R2Vul across five languages against SAST tools, CoT, instruction\ntuning, and classification-based baselines. Our results show that R2Vul with\nstructured reasoning distillation enables a 1.5B student LLM to rival larger\nmodels while improving generalization to out-of-distribution vulnerabilities.\nBeyond model improvements, we contribute a large-scale, multilingual preference\ndataset featuring structured reasoning to support future research in SVD.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04699v1",
    "published_date": "2025-04-07 03:04:16 UTC",
    "updated_date": "2025-04-07 03:04:16 UTC"
  },
  {
    "arxiv_id": "2505.03745v1",
    "title": "AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design",
    "authors": [
      "Yanbiao Liang",
      "Huihong Shi",
      "Haikuo Shao",
      "Zhongfeng Wang"
    ],
    "abstract": "Recently, large language models (LLMs) have achieved huge success in the\nnatural language processing (NLP) field, driving a growing demand to extend\ntheir deployment from the cloud to edge devices. However, deploying LLMs on\nresource-constrained edge devices poses significant challenges, including (1)\nintensive computations and huge model sizes, (2) great memory and bandwidth\ndemands introduced by the autoregressive generation process, and (3) limited\nscalability for handling long sequences. To address these challenges, we\npropose AccLLM, a comprehensive acceleration framework that enables efficient\nand fast long-context LLM inference through algorithm and hardware co-design.\nAt the algorithmic level, we integrate (1) pruning, (2) {\\Lambda}-shaped\nattention, and (3) an innovative W2A8KV4 (2-bit weights, 8-bit activations, and\n4-bit KV cache) quantization scheme, thus effectively reducing memory and\nbandwidth requirements while facilitating LLMs' long-sequence generation. At\nthe hardware level, we design a dedicated FPGA-based accelerator with a\nreconfigurable computing engine to effectively and flexibly accommodate diverse\noperations arising from our compression algorithm, thereby fully translating\nthe algorithmic innovations into tangible hardware efficiency. We validate\nAccLLM on the Xilinx Alveo U280 FPGA, demonstrating a 4.07x energy efficiency\nand a 2.98x throughput compared to the state-of-the-art work FlightLLM.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03745v1",
    "published_date": "2025-04-07 02:52:30 UTC",
    "updated_date": "2025-04-07 02:52:30 UTC"
  },
  {
    "arxiv_id": "2504.07986v2",
    "title": "SEAL: Steerable Reasoning Calibration of Large Language Models for Free",
    "authors": [
      "Runjin Chen",
      "Zhenyu Zhang",
      "Junyuan Hong",
      "Souvik Kundu",
      "Zhangyang Wang"
    ],
    "abstract": "Large Language Models (LLMs), such as OpenAI's o1-series have demonstrated\ncompelling capabilities for complex reasoning tasks via the extended\nchain-of-thought (CoT) reasoning mechanism. However, recent studies reveal\nsubstantial redundancy in the CoT reasoning traces, which not only increases\ninference latency but also negatively impacts model performance by diverting\nattention to unnecessary reasoning paths. To address this issue, we investigate\nthe internal reasoning structures of LLMs and categorize them into three\nprimary thought types: execution, reflection, and transition thoughts.\nMoreover, our analysis reveals that excessive reflection and transition\nthoughts are strongly correlated with failure cases and these thought\ncategories exhibit clear separation in the latent space. Based on these, we\nintroduce SEAL (Steerable reasoning calibration), a training-free approach that\nseamlessly calibrates the CoT process, improving accuracy while demonstrating\nsignificant efficiency gains. SEAL consists of an offline stage for extracting\nthe reasoning steering vector in the latent space, followed by an on-the-fly\ncalibration of the reasoning trace through representation intervention using\nthe steering vector. Notably, the steering vector exhibits strong\ntransferability across various tasks. Extensive experiments across multiple\nmodels (DeepSeek-R1-Distill and QwQ-32B-Preview) and benchmarks (Math500,\nGSM8K, LiveCodeBench) validate the effectiveness of SEAL, up to a 11%\nimprovement in accuracy while reducing reasoning tokens by 11.8% to 50.4%. Our\ncode is publicly available at https://github.com/VITA-Group/SEAL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07986v2",
    "published_date": "2025-04-07 02:42:07 UTC",
    "updated_date": "2025-05-06 08:30:46 UTC"
  },
  {
    "arxiv_id": "2504.04687v1",
    "title": "Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal",
    "authors": [
      "Yicheng Leng",
      "Chaowei Fang",
      "Junye Chen",
      "Yixiang Fang",
      "Sheng Li",
      "Guanbin Li"
    ],
    "abstract": "Visible watermark removal which involves watermark cleaning and background\ncontent restoration is pivotal to evaluate the resilience of watermarks.\nExisting deep neural network (DNN)-based models still struggle with large-area\nwatermarks and are overly dependent on the quality of watermark mask\nprediction. To overcome these challenges, we introduce a novel feature adapting\nframework that leverages the representation modeling capacity of a pre-trained\nimage inpainting model. Our approach bridges the knowledge gap between image\ninpainting and watermark removal by fusing information of the residual\nbackground content beneath watermarks into the inpainting backbone model. We\nestablish a dual-branch system to capture and embed features from the residual\nbackground content, which are merged into intermediate features of the\ninpainting backbone model via gated feature fusion modules. Moreover, for\nrelieving the dependence on high-quality watermark masks, we introduce a new\ntraining paradigm by utilizing coarse watermark masks to guide the inference\nprocess. This contributes to a visible image removal model which is insensitive\nto the quality of watermark mask during testing. Extensive experiments on both\na large-scale synthesized dataset and a real-world dataset demonstrate that our\napproach significantly outperforms existing state-of-the-art methods. The\nsource code is available in the supplementary materials.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "eess.IV",
      "I.2.10; I.4.4; I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "To be published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.04687v1",
    "published_date": "2025-04-07 02:37:14 UTC",
    "updated_date": "2025-04-07 02:37:14 UTC"
  },
  {
    "arxiv_id": "2504.04676v1",
    "title": "Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering",
    "authors": [
      "Bo Li",
      "Jing Yun"
    ],
    "abstract": "Multi-view clustering can explore common semantics from multiple views and\nhas received increasing attention in recent years. However, current methods\nfocus on learning consistency in representation, neglecting the contribution of\neach view's complementarity aspect in representation learning. This limit poses\na significant challenge in multi-view representation learning. This paper\nproposes a novel multi-view clustering framework that introduces a disentangled\nvariational autoencoder that separates multi-view into shared and private\ninformation, i.e., consistency and complementarity information. We first learn\ninformative and consistent representations by maximizing mutual information\nacross different views through contrastive learning. This process will ignore\ncomplementary information. Then, we employ consistency inference constraints to\nexplicitly utilize complementary information when attempting to seek the\nconsistency of shared information across all views. Specifically, we perform a\nwithin-reconstruction using the private and shared information of each view and\na cross-reconstruction using the shared information of all views. The dual\nconsistency constraints are not only effective in improving the representation\nquality of data but also easy to extend to other scenarios, especially in\ncomplex multi-view scenes. This could be the first attempt to employ dual\nconsistent constraint in a unified MVC theoretical framework. During the\ntraining procedure, the consistency and complementarity features are jointly\noptimized. Extensive experiments show that our method outperforms baseline\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04676v1",
    "published_date": "2025-04-07 02:00:16 UTC",
    "updated_date": "2025-04-07 02:00:16 UTC"
  },
  {
    "arxiv_id": "2504.04675v2",
    "title": "HypRL: Reinforcement Learning of Control Policies for Hyperproperties",
    "authors": [
      "Tzu-Han Hsu",
      "Arshia Rafieioskouei",
      "Borzoo Bonakdarpour"
    ],
    "abstract": "We study the problem of learning control policies for complex tasks whose\nrequirements are given by a hyperproperty. The use of hyperproperties is\nmotivated by their significant power to formally specify requirements of\nmulti-agent systems as well as those that need expressiveness in terms of\nmultiple execution traces (e.g., privacy and fairness). Given a Markov decision\nprocess M with unknown transitions (representing the environment) and a\nHyperLTL formula $\\varphi$, our approach first employs Skolemization to handle\nquantifier alternations in $\\varphi$. We introduce quantitative robustness\nfunctions for HyperLTL to define rewards of finite traces of M with respect to\n$\\varphi$. Finally, we utilize a suitable reinforcement learning algorithm to\nlearn (1) a policy per trace quantifier in $\\varphi$, and (2) the probability\ndistribution of transitions of M that together maximize the expected reward\nand, hence, probability of satisfaction of $\\varphi$ in M. We present a set of\ncase studies on (1) safety-preserving multi-agent path planning, (2) fairness\nin resource allocation, and (3) the post-correspondence problem (PCP).",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04675v2",
    "published_date": "2025-04-07 01:58:36 UTC",
    "updated_date": "2025-04-08 04:19:02 UTC"
  },
  {
    "arxiv_id": "2504.04654v1",
    "title": "EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions",
    "authors": [
      "Ngoc-Quang Nguyen"
    ],
    "abstract": "Accurate prediction of compound-protein interactions (CPI) remains a\ncornerstone challenge in computational drug discovery. While existing\nsequence-based approaches leverage molecular fingerprints or graph\nrepresentations, they critically overlook three-dimensional (3D) structural\ndeterminants of binding affinity. To bridge this gap, we present EquiCPI, an\nend-to-end geometric deep learning framework that synergizes first-principles\nstructural modeling with SE(3)-equivariant neural networks. Our pipeline\ntransforms raw sequences into 3D atomic coordinates via ESMFold for proteins\nand DiffDock-L for ligands, followed by physics-guided conformer re-ranking and\nequivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant\nmessage passing over atomic point clouds, preserving symmetry under rotations,\ntranslations, and reflections, while hierarchically encoding local interaction\npatterns through tensor products of spherical harmonics. The proposed model is\nevaluated on BindingDB (affinity prediction) and DUD-E (virtual screening),\nEquiCPI achieves performance on par with or exceeding the state-of-the-art deep\nlearning competitors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.04654v1",
    "published_date": "2025-04-07 00:57:08 UTC",
    "updated_date": "2025-04-07 00:57:08 UTC"
  }
]