{
  "date": "2025-04-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-07 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型的优化、推理和多模态应用，突出大型语言模型 (LLM) 在科学协作、法律推理和强化学习中的创新，如 SciSciGPT 和 Debate-Feedback 框架，同时探讨 AI 在医疗、机器人和可持续领域的潜力，令人印象深刻的文章包括知名学者如 Dashun Wang 参与的 SciSciGPT，以及多代理协作方法。\n\n以下是今天更新的部分论文摘要，我将优先讨论那些重要、创新或有话题度的文章（如 LLM 相关和多模态模型），并快速掠过较次要的。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n\n**SciSciGPT: Advancing Human-AI Collaboration in the Science of Science（SciSciGPT: 推进人类-AI 在科学领域的协作）**  \n这篇论文由 Dashun Wang 等知名学者撰写，引入 SciSciGPT 框架，利用 LLM 驱动的 AI 代理自动化科学分析工作流程，提高研究效率和可重复性。主要贡献是通过案例研究展示其在人类-AI 协作中的潜力，并提出 LLM 代理能力成熟模型，解决透明性和伦理挑战。\n\n**Path Database Guidance for Motion Planning（路径数据库引导的运动规划）**  \n论文提出 PDG 方法，使用路径数据库计算启发式来指导机器人搜索树扩展，动态更新数据库以适应新问题。主要发现是其在模拟环境中提升了运动规划效率，便于与其他搜索方法结合。\n\n**Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering（LLM 用于软件安全：代码分析、恶意软件分析和逆向工程）**  \n这篇综述性文章总结了 LLM 在恶意软件检测中的进展，包括基于 Transformer 的模型。主要贡献是映射研究景观、识别挑战，并强调静态分析和数据集的作用，提升了网络安全策略。\n\n**Towards Efficient Real-Time Video Motion Transfer via Generative Time Series Modeling（通过生成性时间序列建模实现高效实时视频运动转移）**  \n论文开发了一个框架，使用 VRNN 和 GRU-NF 模型预测关键点，实现视频动画和异常检测。主要发现是 VRNN 在多步预测中表现出色，适用于视频会议等应用。\n\n**FORCE: Feature-Oriented Representation with Clustering and Explanation（FORCE: 基于聚类和解释的功能导向表示）**  \n论文提出 FORCE 框架，使用 SHAP 值指导神经网络训练，结合聚类和注意力机制提升预测性能。主要贡献是在真实数据集上显著提高 F1 分数，增强了模型的判别能力。\n\n**Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents（通过 LLM 驱动的对话代理桥接工业专业知识和 XR）**  \n论文整合 RAG 增强的 LLM 与 XR 技术，提供工业指导。主要发现是语义分块策略优化了知识检索，提升了训练效率和操作指导。\n\n**Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Encoding（重新审视 RoPE: N 维位置编码的数学框架）**  \n论文基于 Lie 群理论重新定义 RoPE 属性，提供统一框架扩展到高维空间。主要贡献是证明 RoPE 的数学约束，并提出正交基变换模型，统一了现有设计。\n\n**Optimizing Large Language Models: Metrics, Energy Efficiency, and Case Study Insights（优化大型语言模型：指标、能源效率和案例研究洞见）**  \n论文探索 LLM 的量化技术，减少碳排放。主要发现是通过量化和本地推理降低能源消耗达 45%，适用于资源受限环境。\n\n**Deep Reinforcement Learning Algorithms for Option Hedging（用于期权套期的深度强化学习算法）**  \n论文比较八种 DRL 算法在动态套期中的性能，主要发现 MCPG 算法在计算预算下优于基准 Black-Scholes 方法。\n\n**A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions（对话代理的需求：能力、挑战和未来方向）**  \n这篇综述提出对话代理的三个维度（推理、监控和控制），并分类最新工作。主要贡献是识别研究空白，如长期推理和个性化。\n\n**Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search（Prism: 使用 Monte Carlo 树搜索的 LLM 代码生成动态基准）**  \n论文引入 Prism 框架，使用 MCTS 评估 LLM 代码生成能力。主要发现是其在不同难度级别上提供详细诊断，提升了模型评估。\n\n**Predicting Survivability of Cancer Patients with Metastatic Patterns Using Explainable AI（使用可解释 AI 预测癌转移模式的患者生存率）**  \n论文使用 XGBoost 和 SHAP 分析癌转移数据，主要贡献是识别关键预测因素，如转移部位，提升了临床决策。\n\n**Well2Flow: Reconstruction of reservoir states from sparse wells using score-based generative models（Well2Flow: 使用基于分数的分数生成模型从稀疏井重建储层状态）**  \n论文提出基于分数的生成模型重建储层状态，主要发现是其在数据稀缺环境下准确性高。\n\n快速掠过其他论文：  \n- **GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction（GraphPINE: 用于可解释药物反应预测的图重要性传播）**：使用 GNN 提升药物响应预测的可解释性。  \n- **A Behavior-Based Knowledge Representation Improves Prediction of Players' Moves in Chess（基于行为的知识表示改善国际象棋玩家走法的预测）**：结合专家知识和机器学习预测棋手行为。  \n- **Safe Automated Refactoring for Efficient Migration of Imperative Deep Learning Programs to Graph Execution（安全自动化重构以高效迁移命令式深度学习程序到图执行）**：提出重构方法优化深度学习代码。  \n- 其他如教育AI、强化学习算法等论文虽有贡献，但相对次要，仅提及其在特定领域的应用，如 PreSumm 在摘要预测中的创新。\n\n今天的论文展示了 AI 在多领域的前沿进展，LLM 的优化和应用尤为值得关注，期待后续研究！",
  "papers": [
    {
      "arxiv_id": "2504.05559v1",
      "title": "SciSciGPT: Advancing Human-AI Collaboration in the Science of Science",
      "title_zh": "翻译失败",
      "authors": [
        "Erzhuo Shao",
        "Yifang Wang",
        "Yifan Qian",
        "Zhenyu Pan",
        "Han Liu",
        "Dashun Wang"
      ],
      "abstract": "The increasing availability of large-scale datasets has fueled rapid progress\nacross many scientific fields, creating unprecedented opportunities for\nresearch and discovery while posing significant analytical challenges. Recent\nadvances in large language models (LLMs) and AI agents have opened new\npossibilities for human-AI collaboration, offering powerful tools to navigate\nthis complex research landscape. In this paper, we introduce SciSciGPT, an\nopen-source, prototype AI collaborator that uses the science of science as a\ntestbed to explore the potential of LLM-powered research tools. SciSciGPT\nautomates complex workflows, supports diverse analytical approaches,\naccelerates research prototyping and iteration, and facilitates\nreproducibility. Through case studies, we demonstrate its ability to streamline\na wide range of empirical and analytical research tasks while highlighting its\nbroader potential to advance research. We further propose an LLM Agent\ncapability maturity model for human-AI collaboration, envisioning a roadmap to\nfurther improve and expand upon frameworks like SciSciGPT. As AI capabilities\ncontinue to evolve, frameworks like SciSciGPT may play increasingly pivotal\nroles in scientific research and discovery, unlocking further opportunities. At\nthe same time, these new advances also raise critical challenges, from ensuring\ntransparency and ethical use to balancing human and AI contributions.\nAddressing these issues may shape the future of scientific inquiry and inform\nhow we train the next generation of scientists to thrive in an increasingly\nAI-integrated research ecosystem.",
      "tldr_zh": "本研究引入SciSciGPT，一种开源的AI协作工具，利用science of science作为测试平台，旨在提升人类-AI在科学领域的合作。SciSciGPT通过自动化复杂工作流、支持多样分析方法、加速研究原型迭代和促进可重复性，帮助处理大规模数据集带来的挑战。实验案例证明了其在各种实证和分析任务中的高效性，同时论文提出LLM Agent capability maturity model作为未来发展路线图，并讨论了透明性、伦理问题以及平衡人类与AI贡献的潜在挑战。",
      "categories": [
        "cs.AI",
        "I.2; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05559v1",
      "published_date": "2025-04-07 23:19:39 UTC",
      "updated_date": "2025-04-07 23:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:15:11.231843"
    },
    {
      "arxiv_id": "2504.05550v1",
      "title": "Path Database Guidance for Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Amnon Attali",
        "Praval Telagi",
        "Marco Morales",
        "Nancy M. Amato"
      ],
      "abstract": "One approach to using prior experience in robot motion planning is to store\nsolutions to previously seen problems in a database of paths. Methods that use\nsuch databases are characterized by how they query for a path and how they use\nqueries given a new problem. In this work we present a new method, Path\nDatabase Guidance (PDG), which innovates on existing work in two ways. First,\nwe use the database to compute a heuristic for determining which nodes of a\nsearch tree to expand, in contrast to prior work which generally pastes the\n(possibly transformed) queried path or uses it to bias a sampling distribution.\nWe demonstrate that this makes our method more easily composable with other\nsearch methods by dynamically interleaving exploration according to a baseline\nalgorithm with exploitation of the database guidance. Second, in contrast to\nother methods that treat the database as a single fixed prior, our database\n(and thus our queried heuristic) updates as we search the implicitly defined\nrobot configuration space. We experimentally demonstrate the effectiveness of\nPDG in a variety of explicitly defined environment distributions in simulation.",
      "tldr_zh": "本论文提出了一种新方法 Path Database Guidance (PDG)，用于机器人运动规划，通过利用路径数据库计算启发式 heuristic 来决定搜索树的节点扩展，从而指导规划过程。PDG 的创新在于其可动态更新数据库以适应搜索中的隐式机器人配置空间，并易于与其他搜索算法结合，实现探索与利用的交替。实验结果显示，在各种模拟环境分布中，PDG 显著提升了规划效率和性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05550v1",
      "published_date": "2025-04-07 23:00:31 UTC",
      "updated_date": "2025-04-07 23:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:15:23.635284"
    },
    {
      "arxiv_id": "2504.07137v1",
      "title": "Large Language Model (LLM) for Software Security: Code Analysis, Malware Analysis, Reverse Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Hamed Jelodar",
        "Samita Bai",
        "Parisa Hamedi",
        "Hesamodin Mohammadian",
        "Roozbeh Razavi-Far",
        "Ali Ghorbani"
      ],
      "abstract": "Large Language Models (LLMs) have recently emerged as powerful tools in\ncybersecurity, offering advanced capabilities in malware detection, generation,\nand real-time monitoring. Numerous studies have explored their application in\ncybersecurity, demonstrating their effectiveness in identifying novel malware\nvariants, analyzing malicious code structures, and enhancing automated threat\nanalysis. Several transformer-based architectures and LLM-driven models have\nbeen proposed to improve malware analysis, leveraging semantic and structural\ninsights to recognize malicious intent more accurately. This study presents a\ncomprehensive review of LLM-based approaches in malware code analysis,\nsummarizing recent advancements, trends, and methodologies. We examine notable\nscholarly works to map the research landscape, identify key challenges, and\nhighlight emerging innovations in LLM-driven cybersecurity. Additionally, we\nemphasize the role of static analysis in malware detection, introduce notable\ndatasets and specialized LLM models, and discuss essential datasets supporting\nautomated malware research. This study serves as a valuable resource for\nresearchers and cybersecurity professionals, offering insights into LLM-powered\nmalware detection and defence strategies while outlining future directions for\nstrengthening cybersecurity resilience.",
      "tldr_zh": "这篇论文对大型语言模型 (LLM) 在软件安全领域的应用进行了全面回顾，重点涵盖代码分析、恶意软件分析和逆向工程。论文总结了 LLM 在恶意软件检测、生成和实时监控中的进展，包括 transformer-based 架构和 LLM 驱动模型，这些方法利用语义及结构洞见来提升恶意意图识别的准确性。研究还识别了关键挑战、引入了相关数据集和创新策略，并为未来 LLM 驱动的网络安全防御提供了宝贵见解和方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07137v1",
      "published_date": "2025-04-07 22:32:46 UTC",
      "updated_date": "2025-04-07 22:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:15:36.809020"
    },
    {
      "arxiv_id": "2504.05537v1",
      "title": "Towards Efficient Real-Time Video Motion Transfer via Generative Time Series Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Tasmiah Haque",
        "Md. Asif Bin Syed",
        "Byungheon Jeong",
        "Xue Bai",
        "Sumit Mohan",
        "Somdyuti Paul",
        "Imtiaz Ahmed",
        "Srinjoy Das"
      ],
      "abstract": "We propose a deep learning framework designed to significantly optimize\nbandwidth for motion-transfer-enabled video applications, including video\nconferencing, virtual reality interactions, health monitoring systems, and\nvision-based real-time anomaly detection. To capture complex motion\neffectively, we utilize the First Order Motion Model (FOMM), which encodes\ndynamic objects by detecting keypoints and their associated local affine\ntransformations. These keypoints are identified using a self-supervised\nkeypoint detector and arranged into a time series corresponding to the\nsuccessive frames. Forecasting is performed on these keypoints by integrating\ntwo advanced generative time series models into the motion transfer pipeline,\nnamely the Variational Recurrent Neural Network (VRNN) and the Gated Recurrent\nUnit with Normalizing Flow (GRU-NF). The predicted keypoints are subsequently\nsynthesized into realistic video frames using an optical flow estimator paired\nwith a generator network, thereby facilitating accurate video forecasting and\nenabling efficient, low-frame-rate video transmission. We validate our results\nacross three datasets for video animation and reconstruction using the\nfollowing metrics: Mean Absolute Error, Joint Embedding Predictive Architecture\nEmbedding Distance, Structural Similarity Index, and Average Pair-wise\nDisplacement. Our results confirm that by utilizing the superior reconstruction\nproperty of the Variational Autoencoder, the VRNN integrated FOMM excels in\napplications involving multi-step ahead forecasts such as video conferencing.\nOn the other hand, by leveraging the Normalizing Flow architecture for exact\nlikelihood estimation, and enabling efficient latent space sampling, the GRU-NF\nbased FOMM exhibits superior capabilities for producing diverse future samples\nwhile maintaining high visual quality for tasks like real-time video-based\nanomaly detection.",
      "tldr_zh": "该研究提出了一种深度学习框架，通过生成性时间序列建模优化实时视频运动转移的带宽效率，适用于视频会议、虚拟现实和实时异常检测等应用。框架基于 First Order Motion Model (FOMM) 来检测关键点并构建时间序列，随后整合 Variational Recurrent Neural Network (VRNN) 和 Gated Recurrent Unit with Normalizing Flow (GRU-NF) 模型进行关键点预测，并使用光流估计器与生成器合成视频帧。实验结果显示，在多个数据集上评估的指标如 Mean Absolute Error 和 Structural Similarity Index 中，VRNN 模型在多步预测任务中表现出色，而 GRU-NF 则在生成多样样本和保持视觉质量方面更具优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05537v1",
      "published_date": "2025-04-07 22:21:54 UTC",
      "updated_date": "2025-04-07 22:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:15:48.481069"
    },
    {
      "arxiv_id": "2504.05530v1",
      "title": "FORCE: Feature-Oriented Representation with Clustering and Explanation",
      "title_zh": "FORCE：结合聚类和解释的特征导向表示",
      "authors": [
        "Rishav Mukherjee",
        "Jeffrey Ahearn Thompson"
      ],
      "abstract": "Learning about underlying patterns in data using latent unobserved structures\nto improve the accuracy of predictive models has become an active avenue of\ndeep learning research. Most approaches cluster the original features to\ncapture certain latent structures. However, the information gained in the\nprocess can often be implicitly derived by sufficiently complex models. Thus,\nsuch approaches often provide minimal benefits. We propose a SHAP (Shapley\nAdditive exPlanations) based supervised deep learning framework FORCE which\nrelies on two-stage usage of SHAP values in the neural network architecture,\n(i) an additional latent feature to guide model training, based on clustering\nSHAP values, and (ii) initiating an attention mechanism within the architecture\nusing latent information. This approach gives a neural network an indication\nabout the effect of unobserved values that modify feature importance for an\nobservation. The proposed framework is evaluated on three real life datasets.\nOur results demonstrate that FORCE led to dramatic improvements in overall\nperformance as compared to networks that did not incorporate the latent feature\nand attention framework (e.g., F1 score for presence of heart disease 0.80 vs\n0.72). Using cluster assignments and attention based on SHAP values guides deep\nlearning, enhancing latent pattern learning and overall discriminative\ncapability.",
      "tldr_zh": "本文提出FORCE框架，这是一种基于SHAP（Shapley Additive exPlanations）的监督深度学习方法，用于通过聚类和解释来捕获数据中的潜在结构，从而提升预测模型的准确性。具体而言，FORCE采用两阶段SHAP值应用：首先通过聚类SHAP值生成额外潜在特征指导模型训练，其次启动注意力机制以整合潜在信息并调整特征重要性。在三个真实数据集上的实验显示，该框架显著提高了性能，例如心脏病存在性的F1分数从0.72提升至0.80，增强了深度学习的潜在模式学习和整体区分能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05530v1",
      "published_date": "2025-04-07 22:05:50 UTC",
      "updated_date": "2025-04-07 22:05:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:15:59.800611"
    },
    {
      "arxiv_id": "2504.05527v1",
      "title": "Bridging Industrial Expertise and XR with LLM-Powered Conversational Agents",
      "title_zh": "通过 LLM 驱动",
      "authors": [
        "Despina Tomkou",
        "George Fatouros",
        "Andreas Andreou",
        "Georgios Makridis",
        "Fotis Liarokapis",
        "Dimitrios Dardanis",
        "Athanasios Kiourtis",
        "John Soldatos",
        "Dimosthenis Kyriazis"
      ],
      "abstract": "This paper introduces a novel integration of Retrieval-Augmented Generation\n(RAG) enhanced Large Language Models (LLMs) with Extended Reality (XR)\ntechnologies to address knowledge transfer challenges in industrial\nenvironments. The proposed system embeds domain-specific industrial knowledge\ninto XR environments through a natural language interface, enabling hands-free,\ncontext-aware expert guidance for workers. We present the architecture of the\nproposed system consisting of an LLM Chat Engine with dynamic tool\norchestration and an XR application featuring voice-driven interaction.\nPerformance evaluation of various chunking strategies, embedding models, and\nvector databases reveals that semantic chunking, balanced embedding models, and\nefficient vector stores deliver optimal performance for industrial knowledge\nretrieval. The system's potential is demonstrated through early implementation\nin multiple industrial use cases, including robotic assembly, smart\ninfrastructure maintenance, and aerospace component servicing. Results indicate\npotential for enhancing training efficiency, remote assistance capabilities,\nand operational guidance in alignment with Industry 5.0's human-centric and\nresilient approach to industrial development.",
      "tldr_zh": "本论文提出了一种将Retrieval-Augmented Generation (RAG)增强的Large Language Models (LLMs)与Extended Reality (XR)技术整合的系统，旨在解决工业环境中知识转移的挑战。该系统通过自然语言界面将领域特定工业知识嵌入XR环境，提供无手持的上下文感知专家指导，架构包括LLM Chat Engine的动态工具编排和支持语音交互的XR应用。性能评估显示，语义分块策略、平衡嵌入模型和高效向量数据库在工业知识检索中表现出最佳效果。在多个实际案例中，如机器人组装、智能基础设施维护和航空航天组件服务，该系统提升了培训效率、远程协助能力和操作指导，符合Industry 5.0的人本化和弹性发展理念。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50, 68T40, 68U20, 68U35",
        "H.5.1; I.2.7; I.2.11; H.3.3; H.5.2; C.3"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05527v1",
      "published_date": "2025-04-07 22:02:19 UTC",
      "updated_date": "2025-04-07 22:02:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:16:11.736111"
    },
    {
      "arxiv_id": "2504.06308v1",
      "title": "Rethinking RoPE: A Mathematical Blueprint for N-dimensional Positional Encoding",
      "title_zh": "重新思考 RoPE：N 维位置编码的数学蓝图",
      "authors": [
        "Haiping Liu",
        "Hongpeng Zhou"
      ],
      "abstract": "Rotary Position Embedding (RoPE) is widely adopted in Transformers due to its\nability to encode relative positions with high efficiency and extrapolation\ncapability. However, existing RoPE variants lack a unified theoretical\nfoundation, especially in higher dimensions. In this paper, we propose a\nsystematic mathematical framework for RoPE grounded in Lie group and Lie\nalgebra theory. We identify two core properties of RoPE, named relativity and\nreversibility, and derive general constraints and constructions for valid RoPE\nin 1D, 2D, and N-dimensional (ND). We prove that RoPE must lie in the basis of\na maximal abelian subalgebra (MASA) of the special orthogonal Lie algebra, and\nshow that standard RoPE corresponds to the maximal toral subalgebra.\nFurthermore, we propose to model inter-dimensional interactions by learning an\northogonal basis transformation. Our framework unifies and explains existing\nRoPE designs, while enabling principled extensions to new modalities and tasks.",
      "tldr_zh": "本论文重新审视了 Rotary Position Embedding (RoPE)，提出一个基于 Lie group 和 Lie algebra 理论的系统数学框架，以统一其在 N 维空间中的位置编码设计。框架识别了 RoPE 的两个核心属性——relativity 和 reversibility，并推导出在 1D、2D 和 ND 中的通用约束和构造，同时证明 RoPE 必须位于特殊正交 Lie algebra 的最大阿贝尔子代数 (MASA) 基础上，其中标准 RoPE 对应 maximal toral subalgebra。论文进一步建议通过学习正交基变换来建模维度间交互，从而统一现有 RoPE 设计，并为扩展到新模态和任务提供原理指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06308v1",
      "published_date": "2025-04-07 21:58:22 UTC",
      "updated_date": "2025-04-07 21:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:16:24.476009"
    },
    {
      "arxiv_id": "2504.06307v1",
      "title": "Optimizing Large Language Models: Metrics, Energy Efficiency, and Case Study Insights",
      "title_zh": "优化大型语言模型：指标、能源效率和案例研究见解",
      "authors": [
        "Tahniat Khan",
        "Soroor Motie",
        "Sedef Akinli Kocak",
        "Shaina Raza"
      ],
      "abstract": "The rapid adoption of large language models (LLMs) has led to significant\nenergy consumption and carbon emissions, posing a critical challenge to the\nsustainability of generative AI technologies. This paper explores the\nintegration of energy-efficient optimization techniques in the deployment of\nLLMs to address these environmental concerns. We present a case study and\nframework that demonstrate how strategic quantization and local inference\ntechniques can substantially lower the carbon footprints of LLMs without\ncompromising their operational effectiveness. Experimental results reveal that\nthese methods can reduce energy consumption and carbon emissions by up to 45\\%\npost quantization, making them particularly suitable for resource-constrained\nenvironments. The findings provide actionable insights for achieving\nsustainability in AI while maintaining high levels of accuracy and\nresponsiveness.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 的快速采用所带来的能源消耗和碳排放问题，提出通过整合节能优化技术来提升其可持续性。论文呈现了一个案例研究和框架，利用战略量化 (quantization) 和本地推理 (local inference) 方法，显著降低了 LLMs 的碳足迹，同时保持了模型的性能和准确性。实验结果显示，这些优化技术可将能源消耗和碳排放减少高达 45%，特别适合资源受限环境。总体而言，该研究提供了可操作的见解，帮助实现 AI 的可持续发展，同时维持高响应性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06307v1",
      "published_date": "2025-04-07 21:56:59 UTC",
      "updated_date": "2025-04-07 21:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:16:36.187541"
    },
    {
      "arxiv_id": "2504.05521v2",
      "title": "Deep Reinforcement Learning Algorithms for Option Hedging",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Neagu",
        "Frédéric Godin",
        "Leila Kosseim"
      ],
      "abstract": "Dynamic hedging is a financial strategy that consists in periodically\ntransacting one or multiple financial assets to offset the risk associated with\na correlated liability. Deep Reinforcement Learning (DRL) algorithms have been\nused to find optimal solutions to dynamic hedging problems by framing them as\nsequential decision-making problems. However, most previous work assesses the\nperformance of only one or two DRL algorithms, making an objective comparison\nacross algorithms difficult. In this paper, we compare the performance of eight\nDRL algorithms in the context of dynamic hedging; Monte Carlo Policy Gradient\n(MCPG), Proximal Policy Optimization (PPO), along with four variants of Deep\nQ-Learning (DQL) and two variants of Deep Deterministic Policy Gradient (DDPG).\nTwo of these variants represent a novel application to the task of dynamic\nhedging. In our experiments, we use the Black-Scholes delta hedge as a baseline\nand simulate the dataset using a GJR-GARCH(1,1) model. Results show that MCPG,\nfollowed by PPO, obtain the best performance in terms of the root\nsemi-quadratic penalty. Moreover, MCPG is the only algorithm to outperform the\nBlack-Scholes delta hedge baseline with the allotted computational budget,\npossibly due to the sparsity of rewards in our environment.",
      "tldr_zh": "该研究比较了八种深度强化学习 (DRL) 算法在动态对冲问题中的性能，包括 Monte Carlo Policy Gradient (MCPG)、Proximal Policy Optimization (PPO)、四种 Deep Q-Learning (DQL) 变体和两种 Deep Deterministic Policy Gradient (DDPG) 变体，其中两种变体为动态对冲任务的新应用。实验以 Black-Scholes delta hedge 作为基准，使用 GJR-GARCH(1,1) 模型模拟数据集，并评估算法在根半二次惩罚方面的表现。结果显示，MCPG 表现出最佳性能，其次是 PPO，且 MCPG 是唯一在给定计算预算下超越基准的算法，这可能归因于环境中奖励的稀疏性。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "q-fin.CP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05521v2",
      "published_date": "2025-04-07 21:32:14 UTC",
      "updated_date": "2025-04-17 00:36:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:16:48.289365"
    },
    {
      "arxiv_id": "2504.16939v1",
      "title": "A Desideratum for Conversational Agents: Capabilities, Challenges, and Future Directions",
      "title_zh": "对话代理的理想要求：能力、挑战与未来方向",
      "authors": [
        "Emre Can Acikgoz",
        "Cheng Qian",
        "Hongru Wang",
        "Vardhan Dongre",
        "Xiusi Chen",
        "Heng Ji",
        "Dilek Hakkani-Tür",
        "Gokhan Tur"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have propelled conversational\nAI from traditional dialogue systems into sophisticated agents capable of\nautonomous actions, contextual awareness, and multi-turn interactions with\nusers. Yet, fundamental questions about their capabilities, limitations, and\npaths forward remain open. This survey paper presents a desideratum for\nnext-generation Conversational Agents - what has been achieved, what challenges\npersist, and what must be done for more scalable systems that approach\nhuman-level intelligence. To that end, we systematically analyze LLM-driven\nConversational Agents by organizing their capabilities into three primary\ndimensions: (i) Reasoning - logical, systematic thinking inspired by human\nintelligence for decision making, (ii) Monitor - encompassing self-awareness\nand user interaction monitoring, and (iii) Control - focusing on tool\nutilization and policy following. Building upon this, we introduce a novel\ntaxonomy by classifying recent work on Conversational Agents around our\nproposed desideratum. We identify critical research gaps and outline key\ndirections, including realistic evaluations, long-term multi-turn reasoning\nskills, self-evolution capabilities, collaborative and multi-agent task\ncompletion, personalization, and proactivity. This work aims to provide a\nstructured foundation, highlight existing limitations, and offer insights into\npotential future research directions for Conversational Agents, ultimately\nadvancing progress toward Artificial General Intelligence (AGI). We maintain a\ncurated repository of papers at:\nhttps://github.com/emrecanacikgoz/awesome-conversational-agents.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型 (LLMs) 驱动的对话代理的发展现状，提出了一个期望框架，系统分析了其能力、挑战和未来方向。论文将代理能力分为三个维度：(i) Reasoning（推理），用于决策的逻辑思考；(ii) Monitor（监控），包括自我意识和用户互动监控；以及 (iii) Control（控制），聚焦工具利用和政策遵循。基于此框架，他们引入了一个新分类法来整理相关研究，识别关键空白如现实评估、长期多轮推理技能和自我进化能力，并概述未来方向，包括协作多代理任务和个性化，以推动对话代理向人工通用智能 (AGI) 迈进。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16939v1",
      "published_date": "2025-04-07 21:01:25 UTC",
      "updated_date": "2025-04-07 21:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:17:01.073404"
    },
    {
      "arxiv_id": "2504.05500v2",
      "title": "Prism: Dynamic and Flexible Benchmarking of LLMs Code Generation with Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Majdinasab",
        "Amin Nikanjam",
        "Foutse Khomh"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has outpaced\ntraditional evaluation methods. Static benchmarks fail to capture the depth and\nbreadth of LLM capabilities and eventually become obsolete, while most dynamic\napproaches either rely too heavily on LLM-based evaluation or remain\nconstrained by predefined test sets. We introduce Prism, a flexible, dynamic\nbenchmarking framework designed for comprehensive LLM assessment. Prism builds\non three key components: (1) a tree-based state representation that models\nevaluation as a Markov Decision Process, (2) a Monte Carlo Tree Search\nalgorithm adapted to uncover challenging evaluation scenarios, and (3) a\nmulti-agent evaluation pipeline that enables simultaneous assessment of diverse\ncapabilities. To ensure robust evaluation, Prism integrates structural\nmeasurements of tree exploration patterns with performance metrics across\ndifficulty levels, providing detailed diagnostics of error patterns, test\ncoverage, and solution approaches. Through extensive experiments on five\nstate-of-the-art LLMs, we analyze how model architecture and scale influence\ncode generation performance across varying task difficulties. Our results\ndemonstrate Prism's effectiveness as a dynamic benchmark that evolves with\nmodel advancements while offering deeper insights into their limitations.",
      "tldr_zh": "该研究提出了Prism，一种动态灵活的基准测试框架，用于评估Large Language Models (LLMs)代码生成能力，以解决传统静态基准的局限性。Prism的核心组件包括基于树状状态表示的Markov Decision Process (MDP)、适应Monte Carlo Tree Search (MCTS)算法来发现挑战性场景，以及多代理评估管道以同时评估多种能力。该框架通过整合树探索模式和性能指标，提供对错误模式、测试覆盖率和解决方案的详细诊断。在对五种最先进LLMs的实验中，结果显示模型架构和规模显著影响代码生成性能，并证明Prism能随模型进步动态演变，提供更深入的局限性洞察。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05500v2",
      "published_date": "2025-04-07 20:53:18 UTC",
      "updated_date": "2025-04-10 01:06:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:17:12.638181"
    },
    {
      "arxiv_id": "2504.06306v1",
      "title": "Predicting Survivability of Cancer Patients with Metastatic Patterns Using Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Polycarp Nalela",
        "Deepthi Rao",
        "Praveen Rao"
      ],
      "abstract": "Cancer remains a leading global health challenge and a major cause of\nmortality. This study leverages machine learning (ML) to predict the\nsurvivability of cancer patients with metastatic patterns using the\ncomprehensive MSK-MET dataset, which includes genomic and clinical data from\n25,775 patients across 27 cancer types. We evaluated five ML models-XGBoost,\nNa\\\"ive Bayes, Decision Tree, Logistic Regression, and Random Fores using\nhyperparameter tuning and grid search. XGBoost emerged as the best performer\nwith an area under the curve (AUC) of 0.82. To enhance model interpretability,\nSHapley Additive exPlanations (SHAP) were applied, revealing key predictors\nsuch as metastatic site count, tumor mutation burden, fraction of genome\naltered, and organ-specific metastases. Further survival analysis using\nKaplan-Meier curves, Cox Proportional Hazards models, and XGBoost Survival\nAnalysis identified significant predictors of patient outcomes, offering\nactionable insights for clinicians. These findings could aid in personalized\nprognosis and treatment planning, ultimately improving patient care.",
      "tldr_zh": "本研究利用机器学习（ML）预测癌症患者转移模式下的生存率，基于 MSK-MET 数据集（包含 25,775 名患者的数据，涵盖 27 种癌症类型，包括基因组和临床信息）。评估了五种模型，包括 XGBoost、Naïve Bayes、Decision Tree、Logistic Regression 和 Random Forest，其中 XGBoost 以 AUC 0.82 的表现脱颖而出。利用 SHAP 解释方法，识别了关键预测因子，如转移部位数量、肿瘤突变负荷（tumor mutation burden）、基因组改变分数（fraction of genome altered）和器官特定转移。最终，通过 Kaplan-Meier 曲线、Cox Proportional Hazards 模型和 XGBoost Survival Analysis 等生存分析，提供可操作的见解，支持个性化预后和治疗规划，从而提升患者护理。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06306v1",
      "published_date": "2025-04-07 20:48:15 UTC",
      "updated_date": "2025-04-07 20:48:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:17:24.582711"
    },
    {
      "arxiv_id": "2504.16938v1",
      "title": "Rational Inference in Formal Concept Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Carr",
        "Nicholas Leisegang",
        "Thomas Meyer",
        "Sergei Obiedkov"
      ],
      "abstract": "Defeasible conditionals are a form of non-monotonic inference which enable\nthe expression of statements like \"if $\\phi$ then normally $\\psi$\". The KLM\nframework defines a semantics for the propositional case of defeasible\nconditionals by construction of a preference ordering over possible worlds. The\npattern of reasoning induced by these semantics is characterised by consequence\nrelations satisfying certain desirable properties of non-monotonic reasoning.\nIn FCA, implications are used to describe dependencies between attributes.\nHowever, these implications are unsuitable to reason with erroneous data or\ndata prone to exceptions. Until recently, the topic of non-monotonic inference\nin FCA has remained largely uninvestigated. In this paper, we provide a\nconstruction of the KLM framework for defeasible reasoning in FCA and show that\nthis construction remains faithful to the principle of non-monotonic inference\ndescribed in the original framework. We present an additional argument that,\nwhile remaining consistent with the original ideas around non-monotonic\nreasoning, the defeasible reasoning we propose in FCA offers a more contextual\nview on inference, providing the ability for more relevant conclusions to be\ndrawn when compared to the propositional case.",
      "tldr_zh": "本论文探讨了在 Formal Concept Analysis (FCA) 中的理性推理，特别是引入 defeasible conditionals 作为一种非单调推理形式，以处理异常数据或错误信息。作者构建了 KLM framework 在 FCA 中的扩展，通过在可能世界上的偏好排序来定义 defeasible reasoning 的语义，确保其符合非单调推理的核心原则。相比传统的命题推理，这种方法提供更上下文化的视角，能从 FCA 数据中得出更相关和实用的结论，从而提升推理的适用性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16938v1",
      "published_date": "2025-04-07 20:15:20 UTC",
      "updated_date": "2025-04-07 20:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:17:35.406074"
    },
    {
      "arxiv_id": "2504.06305v1",
      "title": "Well2Flow: Reconstruction of reservoir states from sparse wells using score-based generative models",
      "title_zh": "Well2Flow：使用基于分数的",
      "authors": [
        "Shiqin Zeng",
        "Haoyun Li",
        "Abhinav Prakash Gahlot",
        "Felix J. Herrmann"
      ],
      "abstract": "This study investigates the use of score-based generative models for\nreservoir simulation, with a focus on reconstructing spatially varying\npermeability and saturation fields in saline aquifers, inferred from sparse\nobservations at two well locations. By modeling the joint distribution of\npermeability and saturation derived from high-fidelity reservoir simulations,\nthe proposed neural network is trained to learn the complex spatiotemporal\ndynamics governing multiphase fluid flow in porous media. During inference, the\nframework effectively reconstructs both permeability and saturation fields by\nconditioning on sparse vertical profiles extracted from well log data. This\napproach introduces a novel methodology for incorporating physical constraints\nand well log guidance into generative models, significantly enhancing the\naccuracy and physical plausibility of the reconstructed subsurface states.\nFurthermore, the framework demonstrates strong generalization capabilities\nacross varying geological scenarios, highlighting its potential for practical\ndeployment in data-scarce reservoir management tasks.",
      "tldr_zh": "这篇论文提出了Well2Flow框架，利用score-based generative models从稀疏井数据重建水库的渗透率和饱和度场。框架通过训练神经网络学习基于高保真reservoir simulations的渗透率和饱和度的联合分布，并整合物理约束和井日志指导，以捕捉多相流体在多孔介质中的复杂时空动态。在推理过程中，该方法能有效条件化稀疏垂直剖面数据，实现高准确性和物理plausibility的重建，并展示出在不同地质场景中的强泛化能力，适用于数据稀缺的reservoir management任务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06305v1",
      "published_date": "2025-04-07 20:12:19 UTC",
      "updated_date": "2025-04-07 20:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:17:49.046228"
    },
    {
      "arxiv_id": "2504.05455v1",
      "title": "Large-Scale Classification of Shortwave Communication Signals with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Scholl"
      ],
      "abstract": "This paper presents a deep learning approach to the classification of 160\nshortwave radio signals. It addresses the typical challenges of the shortwave\nspectrum, which are the large number of different signal types, the presence of\nvarious analog modulations and ionospheric propagation. As a classifier a deep\nconvolutional neural network is used, that is trained to recognize 160 typical\nshortwave signal classes. The approach is blind and therefore does not require\npreknowledge or special preprocessing of the signal and no manual design of\ndiscriminative features for each signal class. The network is trained on a\nlarge number of synthetically generated signals and high quality recordings.\nFinally, the network is evaluated on real-world radio signals obtained from\nglobally deployed receiver hardware and achieves up to 90% accuracy for an\nobservation time of only 1 second.",
      "tldr_zh": "这篇论文提出了一种基于深度卷积神经网络(deep convolutional neural network)的深度学习方法，用于对160种短波无线电信号进行大规模分类，解决了短波频谱中的信号类型多样、模拟调制和电离层传播等挑战。方法采用盲分类策略，无需预先知识、特殊预处理或手动设计特征，而是通过合成信号和高品质记录进行训练。实验结果显示，该网络在真实世界信号上实现了高达90%的准确率，仅需1秒观察时间。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05455v1",
      "published_date": "2025-04-07 19:45:08 UTC",
      "updated_date": "2025-04-07 19:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:18:00.195428"
    },
    {
      "arxiv_id": "2504.05454v1",
      "title": "GraphPINE: Graph Importance Propagation for Interpretable Drug Response Prediction",
      "title_zh": "GraphPINE: 图重要性传播用于可解释药物反应预测",
      "authors": [
        "Yoshitaka Inoue",
        "Tianfan Fu",
        "Augustin Luna"
      ],
      "abstract": "Explainability is necessary for many tasks in biomedical research. Recent\nexplainability methods have focused on attention, gradient, and Shapley value.\nThese do not handle data with strong associated prior knowledge and fail to\nconstrain explainability results based on known relationships between\npredictive features.\n  We propose GraphPINE, a graph neural network (GNN) architecture leveraging\ndomain-specific prior knowledge to initialize node importance optimized during\ntraining for drug response prediction. Typically, a manual post-prediction step\nexamines literature (i.e., prior knowledge) to understand returned predictive\nfeatures. While node importance can be obtained for gradient and attention\nafter prediction, node importance from these methods lacks complementary prior\nknowledge; GraphPINE seeks to overcome this limitation. GraphPINE differs from\nother GNN gating methods by utilizing an LSTM-like sequential format. We\nintroduce an importance propagation layer that unifies 1) updates for feature\nmatrix and node importance and 2) uses GNN-based graph propagation of feature\nvalues. This initialization and updating mechanism allows for informed feature\nlearning and improved graph representation.\n  We apply GraphPINE to cancer drug response prediction using drug screening\nand gene data collected for over 5,000 gene nodes included in a gene-gene graph\nwith a drug-target interaction (DTI) graph for initial importance. The\ngene-gene graph and DTIs were obtained from curated sources and weighted by\narticle count discussing relationships between drugs and genes. GraphPINE\nachieves a PR-AUC of 0.894 and ROC-AUC of 0.796 across 952 drugs. Code is\navailable at https://anonymous.4open.science/r/GraphPINE-40DE.",
      "tldr_zh": "该研究提出GraphPINE，一种基于图神经网络(GNN)的架构，用于可解释的药物反应预测，通过利用领域特定先验知识初始化节点重要性，并在训练过程中优化，以克服传统方法如注意力、梯度和Shapley value在处理先验关系方面的局限性。GraphPINE引入重要性传播层，统一更新特征矩阵和节点重要性，并采用类似LSTM的顺序格式进行GNN-based图传播，从而提升特征学习和图表示。实验结果显示，在癌症药物反应预测任务上，GraphPINE使用基因-基因图和药物-靶点交互(DTI)图初始化重要性，实现了PR-AUC 0.894和ROC-AUC 0.796的性能，适用于超过5000个基因节点和952种药物的场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "q-bio.GN",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05454v1",
      "published_date": "2025-04-07 19:42:12 UTC",
      "updated_date": "2025-04-07 19:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:18:12.940068"
    },
    {
      "arxiv_id": "2504.05425v1",
      "title": "A Behavior-Based Knowledge Representation Improves Prediction of Players' Moves in Chess by 25%",
      "title_zh": "翻译失败",
      "authors": [
        "Benny Skidanov",
        "Daniel Erbesfeld",
        "Gera Weiss",
        "Achiya Elyasaf"
      ],
      "abstract": "Predicting player behavior in strategic games, especially complex ones like\nchess, presents a significant challenge. The difficulty arises from several\nfactors. First, the sheer number of potential outcomes stemming from even a\nsingle position, starting from the initial setup, makes forecasting a player's\nnext move incredibly complex. Second, and perhaps even more challenging, is the\ninherent unpredictability of human behavior. Unlike the optimized play of\nengines, humans introduce a layer of variability due to differing playing\nstyles and decision-making processes. Each player approaches the game with a\nunique blend of strategic thinking, tactical awareness, and psychological\ntendencies, leading to diverse and often unexpected actions. This stylistic\nvariation, combined with the capacity for creativity and even irrational moves,\nmakes predicting human play difficult. Chess, a longstanding benchmark of\nartificial intelligence research, has seen significant advancements in tools\nand automation. Engines like Deep Blue, AlphaZero, and Stockfish can defeat\neven the most skilled human players. However, despite their exceptional ability\nto outplay top-level grandmasters, predicting the moves of non-grandmaster\nplayers, who comprise most of the global chess community -- remains complicated\nfor these engines. This paper proposes a novel approach combining expert\nknowledge with machine learning techniques to predict human players' next\nmoves. By applying feature engineering grounded in domain expertise, we seek to\nuncover the patterns in the moves of intermediate-level chess players,\nparticularly during the opening phase of the game. Our methodology offers a\npromising framework for anticipating human behavior, advancing both the fields\nof AI and human-computer interaction.",
      "tldr_zh": "本论文针对国际象棋中预测玩家行为的挑战，提出了一种基于行为的知识表示方法（behavior-based knowledge representation），结合专家知识和机器学习技术，通过特征工程分析中间水平玩家的开局阶段决策模式。该方法有效捕捉玩家的独特风格和变异性，显著提高了预测准确率，较基准模型提升25%。这项创新框架为AI在战略游戏中的人类行为预测提供了新途径，并推动了AI和人机交互领域的发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 2 tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05425v1",
      "published_date": "2025-04-07 18:49:00 UTC",
      "updated_date": "2025-04-07 18:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:18:24.575959"
    },
    {
      "arxiv_id": "2504.05424v1",
      "title": "Safe Automated Refactoring for Efficient Migration of Imperative Deep Learning Programs to Graph Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Raffi Khatchadourian",
        "Tatiana Castro Vélez",
        "Mehdi Bagherzadeh",
        "Nan Jia",
        "Anita Raja"
      ],
      "abstract": "Efficiency is essential to support responsiveness w.r.t. ever-growing\ndatasets, especially for Deep Learning (DL) systems. DL frameworks have\ntraditionally embraced deferred execution-style DL code -- supporting symbolic,\ngraph-based Deep Neural Network (DNN) computation. While scalable, such\ndevelopment is error-prone, non-intuitive, and difficult to debug.\nConsequently, more natural, imperative DL frameworks encouraging eager\nexecution have emerged at the expense of run-time performance. Though hybrid\napproaches aim for the \"best of both worlds,\" using them effectively requires\nsubtle considerations to make code amenable to safe, accurate, and efficient\ngraph execution. We present an automated refactoring approach that assists\ndevelopers in specifying whether their otherwise eagerly-executed imperative DL\ncode could be reliably and efficiently executed as graphs while preserving\nsemantics. The approach, based on a novel imperative tensor analysis,\nautomatically determines when it is safe and potentially advantageous to\nmigrate imperative DL code to graph execution. The approach is implemented as a\nPyDev Eclipse IDE plug-in that integrates the WALA Ariadne analysis framework\nand evaluated on 19 Python projects consisting of 132.05 KLOC. We found that\n326 of 766 candidate functions (42.56%) were refactorable, and an average\nspeedup of 2.16 on performance tests was observed. The results indicate that\nthe approach is useful in optimizing imperative DL code to its full potential.",
      "tldr_zh": "这篇论文提出了一种安全的自动重构方法，用于将命令式深度学习（Imperative Deep Learning）程序高效迁移到图形执行（Graph Execution），以解决传统框架在可伸缩性和易用性之间的权衡问题。方法基于新型的命令式张量分析（Imperative Tensor Analysis），自动评估代码是否能安全、准确且高效地转为图形执行，同时保持语义完整。实验结果显示，在19个Python项目（总计132.05 KLOC）上，42.56%的候选函数可重构，并实现了平均2.16倍的速度提升，从而优化了命令式DL代码的性能潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL",
        "D.2.7; C.4; D.3.4; I.2.6"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05424v1",
      "published_date": "2025-04-07 18:48:43 UTC",
      "updated_date": "2025-04-07 18:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:18:37.365078"
    },
    {
      "arxiv_id": "2504.05420v1",
      "title": "PreSumm: Predicting Summarization Performance Without Summarizing",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Koniaev",
        "Ori Ernst",
        "Jackie Chi Kit Cheung"
      ],
      "abstract": "Despite recent advancements in automatic summarization, state-of-the-art\nmodels do not summarize all documents equally well, raising the question: why?\nWhile prior research has extensively analyzed summarization models, little\nattention has been given to the role of document characteristics in influencing\nsummarization performance. In this work, we explore two key research questions.\nFirst, do documents exhibit consistent summarization quality across multiple\nsystems? If so, can we predict a document's summarization performance without\ngenerating a summary? We answer both questions affirmatively and introduce\nPreSumm, a novel task in which a system predicts summarization performance\nbased solely on the source document. Our analysis sheds light on common\nproperties of documents with low PreSumm scores, revealing that they often\nsuffer from coherence issues, complex content, or a lack of a clear main theme.\nIn addition, we demonstrate PreSumm's practical utility in two key\napplications: improving hybrid summarization workflows by identifying documents\nthat require manual summarization and enhancing dataset quality by filtering\noutliers and noisy documents. Overall, our findings highlight the critical role\nof document properties in summarization performance and offer insights into the\nlimitations of current systems that could serve as the basis for future\nimprovements.",
      "tldr_zh": "本研究探讨了文档特性对自动摘要模型性能的影响，发现不同文档的摘要质量在多个系统间表现出一致性。论文引入PreSumm任务，该任务允许基于源文档预测摘要性能，而无需实际生成摘要，通过分析文档的连贯性、复杂性和主题清晰度来实现。研究发现，低PreSumm分数的文档通常存在连贯性问题、复杂内容或缺乏主要主题。PreSumm的应用包括优化混合摘要工作流（如识别需手动摘要的文档）和提升数据集质量（如过滤异常和噪声文档）。总之，此工作强调文档属性的关键作用，并为改进摘要系统提供见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05420v1",
      "published_date": "2025-04-07 18:43:00 UTC",
      "updated_date": "2025-04-07 18:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:18:47.681202"
    },
    {
      "arxiv_id": "2504.05419v1",
      "title": "Reasoning Models Know When They're Right: Probing Hidden States for Self-Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Anqi Zhang",
        "Yulin Chen",
        "Jane Pan",
        "Chen Zhao",
        "Aurojit Panda",
        "Jinyang Li",
        "He He"
      ],
      "abstract": "Reasoning models have achieved remarkable performance on tasks like math and\nlogical reasoning thanks to their ability to search during reasoning. However,\nthey still suffer from overthinking, often performing unnecessary reasoning\nsteps even after reaching the correct answer. This raises the question: can\nmodels evaluate the correctness of their intermediate answers during reasoning?\nIn this work, we study whether reasoning models encode information about answer\ncorrectness through probing the model's hidden states. The resulting probe can\nverify intermediate answers with high accuracy and produces highly calibrated\nscores. Additionally, we find models' hidden states encode correctness of\nfuture answers, enabling early prediction of the correctness before the\nintermediate answer is fully formulated. We then use the probe as a verifier to\ndecide whether to exit reasoning at intermediate answers during inference,\nreducing the number of inference tokens by 24\\% without compromising\nperformance. These findings confirm that reasoning models do encode a notion of\ncorrectness yet fail to exploit it, revealing substantial untapped potential to\nenhance their efficiency.",
      "tldr_zh": "本研究探讨了推理模型在数学和逻辑任务中的过度思考问题，即即使得出正确答案仍继续推理，并通过探测模型的hidden states来评估中间答案的正确性。结果显示，探测器能以高精度验证答案并产生校准良好的分数，同时模型的hidden states还能提前预测未来答案的正确性。研究进一步将该探测器用作验证器，在推理过程中决定是否提前退出，从而减少推理tokens数量24%而不降低性能。这些发现揭示了推理模型内部编码了正确性信息，但尚未充分利用，这为提升模型效率提供了新潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05419v1",
      "published_date": "2025-04-07 18:42:01 UTC",
      "updated_date": "2025-04-07 18:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:19:01.574557"
    },
    {
      "arxiv_id": "2504.07992v1",
      "title": "'Neural howlround' in large language models: a self-reinforcing bias phenomenon, and a dynamic attenuation solution",
      "title_zh": "翻译失败",
      "authors": [
        "Seth Drake"
      ],
      "abstract": "Large language model (LLM)-driven AI systems may exhibit an inference failure\nmode we term `neural howlround,' a self-reinforcing cognitive loop where\ncertain highly weighted inputs become dominant, leading to entrenched response\npatterns resistant to correction. This paper explores the mechanisms underlying\nthis phenomenon, which is distinct from model collapse and biased salience\nweighting. We propose an attenuation-based correction mechanism that\ndynamically introduces counterbalancing adjustments and can restore adaptive\nreasoning, even in `locked-in' AI systems. Additionally, we discuss some other\nrelated effects arising from improperly managed reinforcement. Finally, we\noutline potential applications of this mitigation strategy for improving AI\nrobustness in real-world decision-making tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLM）中一种称为“neural howlround”的自我强化偏差现象，这种现象会导致某些高权重输入主导响应模式，形成顽固的认知循环，并与模型崩溃（model collapse）和偏差显著性加权（biased salience weighting）不同。作者提出了一种动态衰减解决方案，通过动态引入平衡调整来纠正这一问题，从而恢复AI系统的适应性推理，甚至适用于“锁定”状态的系统。该方法不仅能缓解不当强化的相关效应，还为提升AI在真实世界决策任务中的稳健性提供了潜在应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "27 pages, 3 figures, 2 tables,",
      "pdf_url": "http://arxiv.org/pdf/2504.07992v1",
      "published_date": "2025-04-07 18:30:52 UTC",
      "updated_date": "2025-04-07 18:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:19:13.374660"
    },
    {
      "arxiv_id": "2504.05410v1",
      "title": "Fast Controlled Generation from Language Models with Adaptive Weighted Rejection Sampling",
      "title_zh": "快速受控生成：基于自适应加权拒绝采样的语言模型生成方法",
      "authors": [
        "Benjamin Lipkin",
        "Benjamin LeBrun",
        "Jacob Hoover Vigly",
        "João Loula",
        "David R. MacIver",
        "Li Du",
        "Jason Eisner",
        "Ryan Cotterell",
        "Vikash Mansinghka",
        "Timothy J. O'Donnell",
        "Alexander K. Lew",
        "Tim Vieira"
      ],
      "abstract": "The dominant approach to generating from language models subject to some\nconstraint is locally constrained decoding (LCD), incrementally sampling tokens\nat each time step such that the constraint is never violated. Typically, this\nis achieved through token masking: looping over the vocabulary and excluding\nnon-conforming tokens. There are two important problems with this approach. (i)\nEvaluating the constraint on every token can be prohibitively expensive -- LM\nvocabularies often exceed $100,000$ tokens. (ii) LCD can distort the global\ndistribution over strings, sampling tokens based only on local information,\neven if they lead down dead-end paths. This work introduces a new algorithm\nthat addresses both these problems. First, to avoid evaluating a constraint on\nthe full vocabulary at each step of generation, we propose an adaptive\nrejection sampling algorithm that typically requires orders of magnitude fewer\nconstraint evaluations. Second, we show how this algorithm can be extended to\nproduce low-variance, unbiased estimates of importance weights at a very small\nadditional cost -- estimates that can be soundly used within previously\nproposed sequential Monte Carlo algorithms to correct for the myopic behavior\nof local constraint enforcement. Through extensive empirical evaluation in\ntext-to-SQL, molecular synthesis, goal inference, pattern matching, and JSON\ndomains, we show that our approach is superior to state-of-the-art baselines,\nsupporting a broader class of constraints and improving both runtime and\nperformance. Additional theoretical and empirical analyses show that our\nmethod's runtime efficiency is driven by its dynamic use of computation,\nscaling with the divergence between the unconstrained and constrained LM, and\nas a consequence, runtime improvements are greater for better models.",
      "tldr_zh": "这篇论文针对语言模型的受约束生成问题，提出了一个名为“adaptive weighted rejection sampling”的新算法，以解决传统 locally constrained decoding (LCD) 方法的两个主要问题：高计算开销（需评估整个词汇表）和全局分布扭曲（仅依赖局部信息）。该算法通过自适应拒绝采样显著减少约束评估次数，并扩展为低方差重要权重估计，用于 sequential Monte Carlo 算法中纠正短视行为。在 text-to-SQL、分子合成、目标推断、模式匹配和 JSON 等领域的实验中，该方法优于现有基线，提高了运行时效率和性能，且其效率随无约束与有约束模型差异而动态调整，尤其适用于更先进的模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05410v1",
      "published_date": "2025-04-07 18:30:18 UTC",
      "updated_date": "2025-04-07 18:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:19:25.161061"
    },
    {
      "arxiv_id": "2504.05408v2",
      "title": "Frontier AI's Impact on the Cybersecurity Landscape",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Guo",
        "Yujin Potter",
        "Tianneng Shi",
        "Zhun Wang",
        "Andy Zhang",
        "Dawn Song"
      ],
      "abstract": "As frontier AI advances rapidly, understanding its impact on cybersecurity\nand inherent risks is essential to ensuring safe AI evolution (e.g., guiding\nrisk mitigation and informing policymakers). While some studies review AI\napplications in cybersecurity, none of them comprehensively discuss AI's future\nimpacts or provide concrete recommendations for navigating its safe and secure\nusage. This paper presents an in-depth analysis of frontier AI's impact on\ncybersecurity and establishes a systematic framework for risk assessment and\nmitigation. To this end, we first define and categorize the marginal risks of\nfrontier AI in cybersecurity and then systemically analyze the current and\nfuture impacts of frontier AI in cybersecurity, qualitatively and\nquantitatively. We also discuss why frontier AI likely benefits attackers more\nthan defenders in the short term from equivalence classes, asymmetry, and\neconomic impact. Next, we explore frontier AI's impact on future software\nsystem development, including enabling complex hybrid systems while introducing\nnew risks. Based on our findings, we provide security recommendations,\nincluding constructing fine-grained benchmarks for risk assessment, designing\nAI agents for defenses, building security mechanisms and provable defenses for\nhybrid systems, enhancing pre-deployment security testing and transparency, and\nstrengthening defenses for users. Finally, we present long-term research\nquestions essential for understanding AI's future impacts and unleashing its\ndefensive capabilities.",
      "tldr_zh": "这篇论文分析了前沿 AI（Frontier AI）对网络安全（Cybersecurity）格局的影响，强调了理解其风险以指导风险缓解和政策制定的重要性。该研究建立了系统性的风险评估框架，通过定义和分类前沿 AI 的边际风险，并进行定性和定量分析，探讨了其当前和未来影响，包括短期内可能使攻击者受益更多于防御者（如从等价类、asymmetry 和经济影响角度）。论文还考察了前沿 AI 对软件系统开发的双重作用，即启用复杂混合系统但引入新风险，并基于这些发现提出具体安全推荐，如构建细粒度基准、设计 AI 代理用于防御、加强安全机制和预部署测试，以推动 AI 的安全应用和长期研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05408v2",
      "published_date": "2025-04-07 18:25:18 UTC",
      "updated_date": "2025-04-14 17:35:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:19:37.360941"
    },
    {
      "arxiv_id": "2504.05407v1",
      "title": "TRATSS: Transformer-Based Task Scheduling System for Autonomous Vehicles",
      "title_zh": "TRAT",
      "authors": [
        "Yazan Youssef",
        "Paulo Ricardo Marques de Araujo",
        "Aboelmagd Noureldin",
        "Sidney Givigi"
      ],
      "abstract": "Efficient scheduling remains a critical challenge in various domains,\nrequiring solutions to complex NP-hard optimization problems to achieve optimal\nresource allocation and maximize productivity. In this paper, we introduce a\nframework called Transformer-Based Task Scheduling System (TRATSS), designed to\naddress the intricacies of single agent scheduling in graph-based environments.\nBy integrating the latest advancements in reinforcement learning and\ntransformer architecture, TRATSS provides a novel system that outputs optimized\ntask scheduling decisions while dynamically adapting to evolving task\nrequirements and resource availability. Leveraging the self-attention mechanism\nin transformers, TRATSS effectively captures complex task dependencies, thereby\nproviding solutions with enhanced resource utilization and task completion\nefficiency. Experimental evaluations on benchmark datasets demonstrate TRATSS's\neffectiveness in providing high-quality solutions to scheduling problems that\ninvolve multiple action profiles.",
      "tldr_zh": "本论文针对自治车辆中的任务调度问题，提出了一种名为TRATSS的Transformer-Based系统，用于解决复杂的NP-hard优化挑战。TRATSS整合强化学习和Transformer架构，通过自注意力机制捕捉任务依赖，实现动态适应任务需求和资源可用性的优化调度决策。实验评估在基准数据集上证明，该系统显著提升了资源利用率和任务完成效率，提供高品质的调度解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05407v1",
      "published_date": "2025-04-07 18:23:13 UTC",
      "updated_date": "2025-04-07 18:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:19:48.306036"
    },
    {
      "arxiv_id": "2504.05405v1",
      "title": "The Role of Environment Access in Agnostic Reinforcement Learning",
      "title_zh": "环境访问在无假设强化学习中的作用",
      "authors": [
        "Akshay Krishnamurthy",
        "Gene Li",
        "Ayush Sekhari"
      ],
      "abstract": "We study Reinforcement Learning (RL) in environments with large state spaces,\nwhere function approximation is required for sample-efficient learning.\nDeparting from a long history of prior work, we consider the weakest possible\nform of function approximation, called agnostic policy learning, where the\nlearner seeks to find the best policy in a given class $\\Pi$, with no guarantee\nthat $\\Pi$ contains an optimal policy for the underlying task. Although it is\nknown that sample-efficient agnostic policy learning is not possible in the\nstandard online RL setting without further assumptions, we investigate the\nextent to which this can be overcome with stronger forms of access to the\nenvironment. Specifically, we show that: 1. Agnostic policy learning remains\nstatistically intractable when given access to a local simulator, from which\none can reset to any previously seen state. This result holds even when the\npolicy class is realizable, and stands in contrast to a positive result of\n[MFR24] showing that value-based learning under realizability is tractable with\nlocal simulator access. 2. Agnostic policy learning remains statistically\nintractable when given online access to a reset distribution with good coverage\nproperties over the state space (the so-called $\\mu$-reset setting). We also\nstudy stronger forms of function approximation for policy learning, showing\nthat PSDP [BKSN03] and CPI [KL02] provably fail in the absence of policy\ncompleteness. 3. On a positive note, agnostic policy learning is statistically\ntractable for Block MDPs with access to both of the above reset models. We\nestablish this via a new algorithm that carefully constructs a policy emulator:\na tabular MDP with a small state space that approximates the value functions of\nall policies $\\pi \\in \\Pi$. These values are approximated without any explicit\nvalue function class.",
      "tldr_zh": "该论文探讨了在强化学习（RL）环境中，环境访问形式对 agnostic policy learning 的影响，特别是在大状态空间下需要函数逼近的情况下。研究发现，即使提供本地模拟器访问或具有良好覆盖的μ-reset 设置，agnostic policy learning 仍然统计上不可行，即使策略类是可实现的，且方法如 PSDP 和 CPI 在缺乏策略完整性时会失败。作为正面贡献，论文提出了一种新算法，通过构建 policy emulator 来在 Block MDPs 中实现统计可行的 agnostic policy learning，从而近似所有策略 π ∈ Π 的价值函数。总的来说，这为理解环境访问在非最优策略学习中的作用提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "comments welcome",
      "pdf_url": "http://arxiv.org/pdf/2504.05405v1",
      "published_date": "2025-04-07 18:19:56 UTC",
      "updated_date": "2025-04-07 18:19:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:20:01.479471"
    },
    {
      "arxiv_id": "2504.05400v1",
      "title": "GARF: Learning Generalizable 3D Reassembly for Real-World Fractures",
      "title_zh": "GARF：学习可泛化的 3D",
      "authors": [
        "Sihang Li",
        "Zeyu Jiang",
        "Grace Chen",
        "Chenyang Xu",
        "Siqi Tan",
        "Xue Wang",
        "Irving Fang",
        "Kristof Zyskowski",
        "Shannon P. McPherron",
        "Radu Iovita",
        "Chen Feng",
        "Jing Zhang"
      ],
      "abstract": "3D reassembly is a challenging spatial intelligence task with broad\napplications across scientific domains. While large-scale synthetic datasets\nhave fueled promising learning-based approaches, their generalizability to\ndifferent domains is limited. Critically, it remains uncertain whether models\ntrained on synthetic datasets can generalize to real-world fractures where\nbreakage patterns are more complex. To bridge this gap, we propose GARF, a\ngeneralizable 3D reassembly framework for real-world fractures. GARF leverages\nfracture-aware pretraining to learn fracture features from individual\nfragments, with flow matching enabling precise 6-DoF alignments. At inference\ntime, we introduce one-step preassembly, improving robustness to unseen objects\nand varying numbers of fractures. In collaboration with archaeologists,\npaleoanthropologists, and ornithologists, we curate Fractura, a diverse dataset\nfor vision and learning communities, featuring real-world fracture types across\nceramics, bones, eggshells, and lithics. Comprehensive experiments have shown\nour approach consistently outperforms state-of-the-art methods on both\nsynthetic and real-world datasets, achieving 82.87\\% lower rotation error and\n25.15\\% higher part accuracy. This sheds light on training on synthetic data to\nadvance real-world 3D puzzle solving, demonstrating its strong generalization\nacross unseen object shapes and diverse fracture types.",
      "tldr_zh": "该论文提出GARF框架，用于实现真实世界断裂的通用3D reassembly（3D重组），以解决现有基于合成数据集的模型在泛化性上的局限性。GARF通过fracture-aware pretraining（断裂感知预训练）从单个碎片中学习断裂特征，并利用flow matching（流匹配）实现精确的6-DoF alignments（6自由度对齐），同时引入one-step preassembly（一步预组装）来提升对未知对象和不同断裂数量的鲁棒性。研究团队与考古学家、古人类学家和鸟类学家合作，创建了Fractura数据集，该数据集涵盖陶瓷、骨头、蛋壳和石器的多样真实断裂类型。实验结果显示，GARF在合成和真实数据集上显著优于现有方法，旋转误差降低82.87%、部分准确率提高25.15%，证明了使用合成数据训练可有效推进真实世界3D拼图解决的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 11 figures. Project Page https://ai4ce.github.io/GARF/",
      "pdf_url": "http://arxiv.org/pdf/2504.05400v1",
      "published_date": "2025-04-07 18:13:16 UTC",
      "updated_date": "2025-04-07 18:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:20:13.943504"
    },
    {
      "arxiv_id": "2504.05393v1",
      "title": "Interactive Explanations for Reinforcement-Learning Agents",
      "title_zh": "强化学习代理的交互式解释",
      "authors": [
        "Yotam Amitai",
        "Ofra Amir",
        "Guy Avni"
      ],
      "abstract": "As reinforcement learning methods increasingly amass accomplishments, the\nneed for comprehending their solutions becomes more crucial. Most explainable\nreinforcement learning (XRL) methods generate a static explanation depicting\ntheir developers' intuition of what should be explained and how. In contrast,\nliterature from the social sciences proposes that meaningful explanations are\nstructured as a dialog between the explainer and the explainee, suggesting a\nmore active role for the user and her communication with the agent. In this\npaper, we present ASQ-IT -- an interactive explanation system that presents\nvideo clips of the agent acting in its environment based on queries given by\nthe user that describe temporal properties of behaviors of interest. Our\napproach is based on formal methods: queries in ASQ-IT's user interface map to\na fragment of Linear Temporal Logic over finite traces (LTLf), which we\ndeveloped, and our algorithm for query processing is based on automata theory.\nUser studies show that end-users can understand and formulate queries in ASQ-IT\nand that using ASQ-IT assists users in identifying faulty agent behaviors.",
      "tldr_zh": "该论文探讨了强化学习（Reinforcement Learning）代理的可解释性问题，指出现有可解释强化学习（XRL）方法多为静态解释，缺乏用户互动。作者提出 ASQ-IT 系统，一个交互式解释框架，用户可以通过描述行为时序属性的查询（如基于 Linear Temporal Logic over finite traces (LTLf) 的片段）来查看代理在环境中的视频片段，算法利用自动机理论进行处理。用户研究显示，ASQ-IT 能帮助用户有效理解代理行为并识别潜在错误，从而提升解释的互动性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05393v1",
      "published_date": "2025-04-07 18:00:50 UTC",
      "updated_date": "2025-04-07 18:00:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:20:24.890421"
    },
    {
      "arxiv_id": "2504.06303v1",
      "title": "On the Effectiveness and Generalization of Race Representations for Debiasing High-Stakes Decisions",
      "title_zh": "种族表征用于",
      "authors": [
        "Dang Nguyen",
        "Chenhao Tan"
      ],
      "abstract": "Understanding and mitigating biases is critical for the adoption of large\nlanguage models (LLMs) in high-stakes decision-making. We introduce Admissions\nand Hiring, decision tasks with hypothetical applicant profiles where a\nperson's race can be inferred from their name, as simplified test beds for\nracial bias. We show that Gemma 2B Instruct and LLaMA 3.2 3B Instruct exhibit\nstrong biases. Gemma grants admission to 26% more White than Black applicants,\nand LLaMA hires 60% more Asian than White applicants. We demonstrate that these\nbiases are resistant to prompt engineering: multiple prompting strategies all\nfail to promote fairness. In contrast, using distributed alignment search, we\ncan identify \"race subspaces\" within model activations and intervene on them to\ndebias model decisions. Averaging the representation across all races within\nthe subspaces reduces Gemma's bias by 37-57%. Finally, we examine the\ngeneralizability of Gemma's race subspaces, and find limited evidence for\ngeneralization, where changing the prompt format can affect the race\nrepresentation. Our work suggests mechanistic approaches may provide a\npromising venue for improving the fairness of LLMs, but a universal race\nrepresentation remains elusive.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在高风险决策中的种族偏见问题，通过Admissions和Hiring任务作为测试床，展示了Gemma 2B Instruct和LLaMA 3.2 3B Instruct模型的显著偏见，例如Gemma录取白人申请人多26%，LLaMA雇用亚洲申请人多60%。研究发现，prompt engineering等多种提示策略无法有效缓解这些偏见。相反，通过distributed alignment search识别模型激活中的race subspaces并进行干预（如平均种族表示），成功将Gemma的偏见减少37-57%。然而，race subspaces的泛化性有限，提示格式变化会影响其表现，表明机制方法可能为提升LLMs公平性提供新途径，但普遍的种族表示仍未实现。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "21 pages, 15 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.06303v1",
      "published_date": "2025-04-07 17:59:58 UTC",
      "updated_date": "2025-04-07 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:20:37.964384"
    },
    {
      "arxiv_id": "2504.05305v1",
      "title": "URECA: Unique Region Caption Anything",
      "title_zh": "翻译失败",
      "authors": [
        "Sangbeom Lim",
        "Junwan Kim",
        "Heeji Yoon",
        "Jaewoo Jung",
        "Seungryong Kim"
      ],
      "abstract": "Region-level captioning aims to generate natural language descriptions for\nspecific image regions while highlighting their distinguishing features.\nHowever, existing methods struggle to produce unique captions across\nmulti-granularity, limiting their real-world applicability. To address the need\nfor detailed region-level understanding, we introduce URECA dataset, a\nlarge-scale dataset tailored for multi-granularity region captioning. Unlike\nprior datasets that focus primarily on salient objects, URECA dataset ensures a\nunique and consistent mapping between regions and captions by incorporating a\ndiverse set of objects, parts, and background elements. Central to this is a\nstage-wise data curation pipeline, where each stage incrementally refines\nregion selection and caption generation. By leveraging Multimodal Large\nLanguage Models (MLLMs) at each stage, our pipeline produces distinctive and\ncontextually grounded captions with improved accuracy and semantic diversity.\nBuilding upon this dataset, we present URECA, a novel captioning model designed\nto effectively encode multi-granularity regions. URECA maintains essential\nspatial properties such as position and shape through simple yet impactful\nmodifications to existing MLLMs, enabling fine-grained and semantically rich\nregion descriptions. Our approach introduces dynamic mask modeling and a\nhigh-resolution mask encoder to enhance caption uniqueness. Experiments show\nthat URECA achieves state-of-the-art performance on URECA dataset and\ngeneralizes well to existing region-level captioning benchmarks.",
      "tldr_zh": "该论文针对区域级图像描述（region-level captioning）的挑战，提出 URECA 数据集和模型，以生成多粒度（multi-granularity）下独特且富有特色的自然语言描述。URECA 数据集是一个大规模资源，通过阶段式数据整理管道（stage-wise data curation pipeline）和 Multimodal Large Language Models (MLLMs) 逐步优化区域选择和描述生成，确保涵盖多样对象、部分及背景元素，并提升准确性和语义多样性。URECA 模型通过对现有 MLLMs 的简单修改，保留空间属性（如位置和形状），并引入动态掩码建模（dynamic mask modeling）和高分辨率掩码编码器（high-resolution mask encoder），从而实现细粒度和语义丰富的区域描述。实验结果表明，URECA 在其数据集上达到最先进性能，并能良好泛化到现有区域级描述基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://cvlab-kaist.github.io/URECA Code:\n  https://github.com/cvlab-kaist/URECA",
      "pdf_url": "http://arxiv.org/pdf/2504.05305v1",
      "published_date": "2025-04-07 17:59:44 UTC",
      "updated_date": "2025-04-07 17:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:20:50.758115"
    },
    {
      "arxiv_id": "2504.05299v1",
      "title": "SmolVLM: Redefining small and efficient multimodal models",
      "title_zh": "翻译失败",
      "authors": [
        "Andrés Marafioti",
        "Orr Zohar",
        "Miquel Farré",
        "Merve Noyan",
        "Elie Bakouch",
        "Pedro Cuenca",
        "Cyril Zakka",
        "Loubna Ben Allal",
        "Anton Lozhkov",
        "Nouamane Tazi",
        "Vaibhav Srivastav",
        "Joshua Lochner",
        "Hugo Larcher",
        "Mathieu Morlon",
        "Lewis Tunstall",
        "Leandro von Werra",
        "Thomas Wolf"
      ],
      "abstract": "Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.",
      "tldr_zh": "本研究介绍了 SmolVLM，一系列紧凑的多模态模型，旨在解决大型 Vision-Language Models (VLMs) 的高计算资源需求问题，使其更适合移动和边缘设备。SmolVLM 通过系统优化架构配置、标记策略和数据整理，实现了高效的资源利用，并在图像和视频任务中取得了显著性能提升。最小模型 SmolVLM-256M 使用不到 1GB GPU 内存，便超越了 300 倍大的 Idefics-80B 模型，而其 2.2B 参数模型则与最先进 VLMs 相当，同时支持稳健的视频理解。这些结果证明，战略性的架构优化和高效标记策略能显著提升多模态性能，促进能量高效的实际部署。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05299v1",
      "published_date": "2025-04-07 17:58:57 UTC",
      "updated_date": "2025-04-07 17:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:21:02.023216"
    },
    {
      "arxiv_id": "2504.13900v1",
      "title": "Supporting Students' Reading and Cognition with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Fu",
        "Alexis Hiniker"
      ],
      "abstract": "With the rapid adoption of AI tools in learning contexts, it is vital to\nunderstand how these systems shape users' reading processes and cognitive\nengagement. We collected and analyzed text from 124 sessions with AI tools, in\nwhich students used these tools to support them as they read assigned readings\nfor an undergraduate course. We categorized participants' prompts to AI\naccording to Bloom's Taxonomy of educational objectives -- Remembering,\nUnderstanding, Applying, Analyzing, Evaluating. Our results show that\n``Analyzing'' and ``Evaluating'' are more prevalent in users' second and third\nprompts within a single usage session, suggesting a shift toward higher-order\nthinking. However, in reviewing users' engagement with AI tools over several\nweeks, we found that users converge toward passive reading engagement over\ntime. Based on these results, we propose design implications for future AI\nreading-support systems, including structured scaffolds for lower-level\ncognitive tasks (e.g., recalling terms) and proactive prompts that encourage\nhigher-order thinking (e.g., analyzing, applying, evaluating). Additionally, we\nadvocate for adaptive, human-in-the-loop features that allow students and\ninstructors to tailor their reading experiences with AI, balancing efficiency\nwith enriched cognitive engagement. Our paper expands the dialogue on\nintegrating AI into academic reading, highlighting both its potential benefits\nand challenges.",
      "tldr_zh": "本研究调查了AI工具如何影响学生的阅读过程和认知参与，通过分析124个学生使用AI辅助阅读本科课程材料的会话数据。研究采用Bloom's Taxonomy框架，将学生的AI提示分类为Remembering、Understanding、Applying、Analyzing和Evaluating，发现单个会话中后续提示更倾向于Analyzing和Evaluating，表明短期内促进更高阶思考，但长期使用导致用户转向被动阅读。基于这些结果，论文提出设计建议，包括为低阶任务（如Recalling terms）提供结构化支架、主动提示鼓励高阶思考（如Analyzing、Applying、Evaluating），以及适应性的人机交互功能，以平衡效率和认知参与。总的来说，该研究扩展了AI在学术阅读中的应用讨论，突出了其益处与挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.13900v1",
      "published_date": "2025-04-07 17:51:27 UTC",
      "updated_date": "2025-04-07 17:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:21:14.012829"
    },
    {
      "arxiv_id": "2504.05295v2",
      "title": "Dion: Distributed Orthonormalized Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Kwangjun Ahn",
        "Byron Xu",
        "Natalie Abreu",
        "John Langford"
      ],
      "abstract": "Recent work has shown that orthonormal matrix updates speed up neural network\noptimization, improve training stability, and offer better hyperparameter\ntransfer across model sizes. Applying these updates efficiently when model\nweights and optimizer states are sharded across a large-scale distributed LLM\ntraining system remains a major challenge. We introduce Dion (DIstributed\nOrthoNormalization), a scalable and communication-efficient orthonormalizing\noptimizer. Dion leverages low-rank approximation and decoupled momentum\nbuffers, eliminating the need for full gradient synchronization while producing\nnumerically equivalent results. It is compatible with simultaneous DDP, FSDP,\nand TP parallelism, and it computes an orthonormalized update without\nunsharding a full parameter matrix on any single device. We evaluate Dion on\nlanguage models from 120M to 3B parameters and find that its benefits improve\nwith increasing model size and batch size.",
      "tldr_zh": "该研究引入了Dion，一种分布式正交优化器，用于加速神经网络训练、提升稳定性并改善超参数在不同模型大小间的转移。Dion通过低秩逼近和解耦动量缓冲区，实现通信高效的正交更新，避免了全梯度同步，同时保持数值等效，并兼容DDP、FSDP和TP并行性。在120M到3B参数的语言模型上评估，Dion的性能优势随模型大小和批量大小增加而增强。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "\"Version 2\" with more experimental results and algorithmic details.\n  Comments would be appreciated!",
      "pdf_url": "http://arxiv.org/pdf/2504.05295v2",
      "published_date": "2025-04-07 17:49:37 UTC",
      "updated_date": "2025-05-21 18:05:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:21:25.199184"
    },
    {
      "arxiv_id": "2504.05370v1",
      "title": "EduPlanner: LLM-Based Multi-Agent Systems for Customized and Intelligent Instructional Design",
      "title_zh": "翻译失败",
      "authors": [
        "Xueqiao Zhang",
        "Chao Zhang",
        "Jianwen Sun",
        "Jun Xiao",
        "Yi Yang",
        "Yawei Luo"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced smart education in\nthe Artificial General Intelligence (AGI) era. A promising application lies in\nthe automatic generalization of instructional design for curriculum and\nlearning activities, focusing on two key aspects: (1) Customized Generation:\ngenerating niche-targeted teaching content based on students' varying learning\nabilities and states, and (2) Intelligent Optimization: iteratively optimizing\ncontent based on feedback from learning effectiveness or test scores.\nCurrently, a single large LLM cannot effectively manage the entire process,\nposing a challenge for designing intelligent teaching plans. To address these\nissues, we developed EduPlanner, an LLM-based multi-agent system comprising an\nevaluator agent, an optimizer agent, and a question analyst, working in\nadversarial collaboration to generate customized and intelligent instructional\ndesign for curriculum and learning activities. Taking mathematics lessons as\nour example, EduPlanner employs a novel Skill-Tree structure to accurately\nmodel the background mathematics knowledge of student groups, personalizing\ninstructional design for curriculum and learning activities according to\nstudents' knowledge levels and learning abilities. Additionally, we introduce\nthe CIDDP, an LLM-based five-dimensional evaluation module encompassing\nclarity, Integrity, Depth, Practicality, and Pertinence, to comprehensively\nassess mathematics lesson plan quality and bootstrap intelligent optimization.\nExperiments conducted on the GSM8K and Algebra datasets demonstrate that\nEduPlanner excels in evaluating and optimizing instructional design for\ncurriculum and learning activities. Ablation studies further validate the\nsignificance and effectiveness of each component within the framework. Our code\nis publicly available at https://github.com/Zc0812/Edu_Planner",
      "tldr_zh": "该论文提出了 EduPlanner，一种基于 LLM 的多智能体系统，用于实现定制化和智能化的教学设计，针对学生学习能力和反馈进行个性化内容生成和迭代优化。系统包括 evaluator agent、optimizer agent 和 question analyst 等代理，通过对抗协作和 Skill-Tree 结构建模学生知识背景，为数学课程提供个性化教学计划；同时引入 CIDDP 五维评估模块（clarity, Integrity, Depth, Practicality, and Pertinence）来全面评估和优化课计划。实验在 GSM8K 和 Algebra 数据集上显示，EduPlanner 显著优于基线模型，消融研究验证了各组件的有效性，代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05370v1",
      "published_date": "2025-04-07 17:49:12 UTC",
      "updated_date": "2025-04-07 17:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:21:38.315553"
    },
    {
      "arxiv_id": "2504.05278v1",
      "title": "The challenge of uncertainty quantification of large language models in medicine",
      "title_zh": "大型语言模型在医学中的不确定性量化挑战",
      "authors": [
        "Zahra Atf",
        "Seyed Amir Ahmad Safavi-Naini",
        "Peter R. Lewis",
        "Aref Mahjoubfar",
        "Nariman Naderi",
        "Thomas R. Savage",
        "Ali Soroush"
      ],
      "abstract": "This study investigates uncertainty quantification in large language models\n(LLMs) for medical applications, emphasizing both technical innovations and\nphilosophical implications. As LLMs become integral to clinical\ndecision-making, accurately communicating uncertainty is crucial for ensuring\nreliable, safe, and ethical AI-assisted healthcare. Our research frames\nuncertainty not as a barrier but as an essential part of knowledge that invites\na dynamic and reflective approach to AI design. By integrating advanced\nprobabilistic methods such as Bayesian inference, deep ensembles, and Monte\nCarlo dropout with linguistic analysis that computes predictive and semantic\nentropy, we propose a comprehensive framework that manages both epistemic and\naleatoric uncertainties. The framework incorporates surrogate modeling to\naddress limitations of proprietary APIs, multi-source data integration for\nbetter context, and dynamic calibration via continual and meta-learning.\nExplainability is embedded through uncertainty maps and confidence metrics to\nsupport user trust and clinical interpretability. Our approach supports\ntransparent and ethical decision-making aligned with Responsible and Reflective\nAI principles. Philosophically, we advocate accepting controlled ambiguity\ninstead of striving for absolute predictability, recognizing the inherent\nprovisionality of medical knowledge.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在医疗应用中不确定性量化的挑战，强调技术创新与哲学含义，以确保可靠、安全和道德的AI辅助临床决策。研究提出一个综合框架，通过整合Bayesian inference、deep ensembles和Monte Carlo dropout等概率方法与语言分析，管理epistemic和aleatoric不确定性，并利用surrogate modeling、多源数据整合以及动态校准（如continual和meta-learning）来提升模型性能和可解释性。框架嵌入uncertainty maps和confidence metrics，支持透明决策并符合Responsible and Reflective AI原则，同时哲学上主张接受受控模糊性，承认医疗知识的固有暂定性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05278v1",
      "published_date": "2025-04-07 17:24:11 UTC",
      "updated_date": "2025-04-07 17:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:21:51.273197"
    },
    {
      "arxiv_id": "2504.08793v1",
      "title": "A Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size",
      "title_zh": "翻译失败",
      "authors": [
        "Jorge A. Huertas",
        "Pascal Van Hentenryck"
      ],
      "abstract": "In serial batch (s-batch) scheduling, jobs are grouped in batches and\nprocessed sequentially within their batch. This paper considers multiple\nparallel machines, nonidentical job weights and release times, and\nsequence-dependent setup times between batches of different families. Although\ns-batch has been widely studied in the literature, very few papers have taken\ninto account a minimum batch size, typical in practical settings such as\nsemiconductor manufacturing and the metal industry. The problem with this\nminimum batch size requirement has been mostly tackled with dynamic programming\nand meta-heuristics, and no article has ever used constraint programming (CP)\nto do so. This paper fills this gap by proposing, for the first time, a CP\nmodel for s-batching with minimum batch size. The computational experiments on\nstandard cases compare the CP model with two existing mixed-integer programming\n(MIP) models from the literature. The results demonstrate the versatility of\nthe proposed CP model to handle multiple variations of s-batching; and its\nability to produce, in large instances, better solutions than the MIP models\nfaster.",
      "tldr_zh": "本论文针对串行批处理（serial batch, s-batch）调度问题，考虑了多个并行机器、非相同作业权重、发布时间以及批次间依赖序列的设置时间，同时引入了实际场景（如半导体制造）中常见的最小批次大小要求。作者首次提出一个约束编程（CP）模型，用于处理这一问题，并通过计算实验与现有混合整数编程（MIP）模型进行比较。结果显示，该CP模型在处理多种s-batching变体时更具灵活性，并在大型实例中比MIP模型更快地生成更优解决方案。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.08793v1",
      "published_date": "2025-04-07 17:14:19 UTC",
      "updated_date": "2025-04-07 17:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:22:01.487091"
    },
    {
      "arxiv_id": "2504.05259v1",
      "title": "How to evaluate control measures for LLM agents? A trajectory from today to superintelligence",
      "title_zh": "如何评估 LLM 代理的控制措施？从今天到超级智能的轨迹",
      "authors": [
        "Tomek Korbak",
        "Mikita Balesni",
        "Buck Shlegeris",
        "Geoffrey Irving"
      ],
      "abstract": "As LLM agents grow more capable of causing harm autonomously, AI developers\nwill rely on increasingly sophisticated control measures to prevent possibly\nmisaligned agents from causing harm. AI developers could demonstrate that their\ncontrol measures are sufficient by running control evaluations: testing\nexercises in which a red team produces agents that try to subvert control\nmeasures. To ensure control evaluations accurately capture misalignment risks,\nthe affordances granted to this red team should be adapted to the capability\nprofiles of the agents to be deployed under control measures.\n  In this paper we propose a systematic framework for adapting affordances of\nred teams to advancing AI capabilities. Rather than assuming that agents will\nalways execute the best attack strategies known to humans, we demonstrate how\nknowledge of an agents's actual capability profile can inform proportional\ncontrol evaluations, resulting in more practical and cost-effective control\nmeasures. We illustrate our framework by considering a sequence of five\nfictional models (M1-M5) with progressively advanced capabilities, defining\nfive distinct AI control levels (ACLs). For each ACL, we provide example rules\nfor control evaluation, control measures, and safety cases that could be\nappropriate. Finally, we show why constructing a compelling AI control safety\ncase for superintelligent LLM agents will require research breakthroughs,\nhighlighting that we might eventually need alternative approaches to mitigating\nmisalignment risk.",
      "tldr_zh": "本研究探讨了如何评估大型语言模型(LLM)代理的控制措施，以防范其自主失调风险，并从当前水平延伸到超级智能时代。作者提出一个系统框架，根据代理的能力配置文件动态调整红队的权限，进行比例控制评估，从而实现更实用和成本有效的测试，而非假设代理总是采用人类已知的最佳攻击策略。该框架通过五个虚构模型(M1-M5)和对应的AI控制水平(ACLs)举例，定义了控制评估规则、措施和安全案例；结果显示，对于超级智能LLM代理，构建可靠的安全案例可能需要研究突破和替代方法来缓解失调风险。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05259v1",
      "published_date": "2025-04-07 16:52:52 UTC",
      "updated_date": "2025-04-07 16:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:22:13.582276"
    },
    {
      "arxiv_id": "2504.05258v1",
      "title": "Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adrián Bazaga",
        "Rexhina Blloshmi",
        "Bill Byrne",
        "Adrià de Gispert"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools for generating\ncoherent text, understanding context, and performing reasoning tasks. However,\nthey struggle with temporal reasoning, which requires processing time-related\ninformation such as event sequencing, durations, and inter-temporal\nrelationships. These capabilities are critical for applications including\nquestion answering, scheduling, and historical analysis. In this paper, we\nintroduce TISER, a novel framework that enhances the temporal reasoning\nabilities of LLMs through a multi-stage process that combines timeline\nconstruction with iterative self-reflection. Our approach leverages test-time\nscaling to extend the length of reasoning traces, enabling models to capture\ncomplex temporal dependencies more effectively. This strategy not only boosts\nreasoning accuracy but also improves the traceability of the inference process.\nExperimental results demonstrate state-of-the-art performance across multiple\nbenchmarks, including out-of-distribution test sets, and reveal that TISER\nenables smaller open-source models to surpass larger closed-weight models on\nchallenging temporal reasoning tasks.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在 temporal reasoning 方面的不足，提出 TISER 框架，通过时间线构建和迭代自省的多阶段过程来提升模型处理事件序列、持续时间和时间关系的能力。框架利用测试时缩放来延长推理痕迹，从而更好地捕捉复杂 temporal dependencies，并提高推理准确性和过程可追踪性。实验结果显示，TISER 在多个基准上达到最先进性能，包括分布外测试集，并使小型开源模型在 challenging temporal reasoning 任务中超越大型闭源模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05258v1",
      "published_date": "2025-04-07 16:51:45 UTC",
      "updated_date": "2025-04-07 16:51:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:22:25.889322"
    },
    {
      "arxiv_id": "2504.05254v1",
      "title": "Explaining Low Perception Model Competency with High-Competency Counterfactuals",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Pohland",
        "Claire Tomlin"
      ],
      "abstract": "There exist many methods to explain how an image classification model\ngenerates its decision, but very little work has explored methods to explain\nwhy a classifier might lack confidence in its prediction. As there are various\nreasons the classifier might lose confidence, it would be valuable for this\nmodel to not only indicate its level of uncertainty but also explain why it is\nuncertain. Counterfactual images have been used to visualize changes that could\nbe made to an image to generate a different classification decision. In this\nwork, we explore the use of counterfactuals to offer an explanation for low\nmodel competency--a generalized form of predictive uncertainty that measures\nconfidence. Toward this end, we develop five novel methods to generate\nhigh-competency counterfactual images, namely Image Gradient Descent (IGD),\nFeature Gradient Descent (FGD), Autoencoder Reconstruction (Reco), Latent\nGradient Descent (LGD), and Latent Nearest Neighbors (LNN). We evaluate these\nmethods across two unique datasets containing images with six known causes for\nlow model competency and find Reco, LGD, and LNN to be the most promising\nmethods for counterfactual generation. We further evaluate how these three\nmethods can be utilized by pre-trained Multimodal Large Language Models (MLLMs)\nto generate language explanations for low model competency. We find that the\ninclusion of a counterfactual image in the language model query greatly\nincreases the ability of the model to generate an accurate explanation for the\ncause of low model competency, thus demonstrating the utility of counterfactual\nimages in explaining low perception model competency.",
      "tldr_zh": "本文提出一种使用高信心反事实图像（counterfactual images）来解释图像分类模型低信心原因的方法，旨在填补现有解释技术的空白。研究开发了五种新生成方法，包括Image Gradient Descent (IGD)、Feature Gradient Descent (FGD)、Autoencoder Reconstruction (Reco)、Latent Gradient Descent (LGD)和Latent Nearest Neighbors (LNN)，并在包含六种已知低信心原因的两个数据集上评估，结果显示Reco、LGD和LNN是最具前景的方法。通过将这些方法与预训练的多模态大语言模型（MLLMs）结合，添加反事实图像显著提高了模型生成准确语言解释的能力，证明了该方法在提升模型可解释性方面的效用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05254v1",
      "published_date": "2025-04-07 16:46:52 UTC",
      "updated_date": "2025-04-07 16:46:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:22:37.889213"
    },
    {
      "arxiv_id": "2504.05255v2",
      "title": "Adversarial KA",
      "title_zh": "翻译失败",
      "authors": [
        "Sviatoslav Dzhenzher",
        "Michael H. Freedman"
      ],
      "abstract": "Regarding the representation theorem of Kolmogorov and Arnold (KA) as an\nalgorithm for representing or {\\guillemotleft}expressing{\\guillemotright}\nfunctions, we test its robustness by analyzing its ability to withstand\nadversarial attacks. We find KA to be robust to countable collections of\ncontinuous adversaries, but unearth a question about the equi-continuity of the\nouter functions that, so far, obstructs taking limits and defeating continuous\ngroups of adversaries. This question on the regularity of the outer functions\nis relevant to the debate over the applicability of KA to the general theory of\nNNs.",
      "tldr_zh": "本论文探讨了Kolmogorov-Arnold (KA)表示定理作为函数表示算法的鲁棒性，通过分析其对adversarial attacks的抵抗能力。研究发现，KA对可数集合的连续对抗者具有鲁棒性，但外函数的equi-continuity问题阻碍了其应对连续组对抗者的能力。最终，这引发了对KA在neural networks (NNs)一般理论中适用性的争论，为进一步研究外函数的正则性提供了方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.FA"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 3 figures; minor revision, question 4.1 added",
      "pdf_url": "http://arxiv.org/pdf/2504.05255v2",
      "published_date": "2025-04-07 16:46:52 UTC",
      "updated_date": "2025-04-30 15:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:22:48.602311"
    },
    {
      "arxiv_id": "2504.05248v1",
      "title": "PINNverse: Accurate parameter estimation in differential equations from noisy data with constrained physics-informed neural networks",
      "title_zh": "PINNverse：利用约束物理信息神经网络从噪声数据中对微",
      "authors": [
        "Marius Almanstötter",
        "Roman Vetter",
        "Dagmar Iber"
      ],
      "abstract": "Parameter estimation for differential equations from measured data is an\ninverse problem prevalent across quantitative sciences. Physics-Informed Neural\nNetworks (PINNs) have emerged as effective tools for solving such problems,\nespecially with sparse measurements and incomplete system information. However,\nPINNs face convergence issues, stability problems, overfitting, and complex\nloss function design. Here we introduce PINNverse, a training paradigm that\naddresses these limitations by reformulating the learning process as a\nconstrained differential optimization problem. This approach achieves a dynamic\nbalance between data loss and differential equation residual loss during\ntraining while preventing overfitting. PINNverse combines the advantages of\nPINNs with the Modified Differential Method of Multipliers to enable\nconvergence on any point on the Pareto front. We demonstrate robust and\naccurate parameter estimation from noisy data in four classical ODE and PDE\nmodels from physics and biology. Our method enables accurate parameter\ninference also when the forward problem is expensive to solve.",
      "tldr_zh": "本研究引入了 PINNverse，一种新的训练范式，用于从噪声数据中准确估计微分方程的参数问题，通过将物理信息神经网络 (PINNs) 的学习过程重新表述为约束的微分优化问题。PINNverse 结合 Modified Differential Method of Multipliers，实现数据损失和微分方程残差损失之间的动态平衡，解决 PINNs 的收敛问题、稳定性问题和过拟合风险。实验结果显示，该方法在四个经典的 ODE 和 PDE 模型上表现出色，即使正向问题计算成本高，也能实现鲁棒的参数推断。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05248v1",
      "published_date": "2025-04-07 16:34:57 UTC",
      "updated_date": "2025-04-07 16:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:23:02.641152"
    },
    {
      "arxiv_id": "2504.05231v1",
      "title": "Mapping biodiversity at very-high resolution in Europe",
      "title_zh": "欧洲的超高分辨率生物多样性映射",
      "authors": [
        "César Leblanc",
        "Lukas Picek",
        "Benjamin Deneu",
        "Pierre Bonnet",
        "Maximilien Servajean",
        "Rémi Palard",
        "Alexis Joly"
      ],
      "abstract": "This paper describes a cascading multimodal pipeline for high-resolution\nbiodiversity mapping across Europe, integrating species distribution modeling,\nbiodiversity indicators, and habitat classification. The proposed pipeline\nfirst predicts species compositions using a deep-SDM, a multimodal model\ntrained on remote sensing, climate time series, and species occurrence data at\n50x50m resolution. These predictions are then used to generate biodiversity\nindicator maps and classify habitats with Pl@ntBERT, a transformer-based LLM\ndesigned for species-to-habitat mapping. With this approach, continental-scale\nspecies distribution maps, biodiversity indicator maps, and habitat maps are\nproduced, providing fine-grained ecological insights. Unlike traditional\nmethods, this framework enables joint modeling of interspecies dependencies,\nbias-aware training with heterogeneous presence-absence data, and large-scale\ninference from multi-source remote sensing inputs.",
      "tldr_zh": "该论文提出了一种级联多模态管道，用于在欧洲实现高分辨率生物多样性映射，整合了物种分布建模、biodiversity indicators 和栖息地分类。管道首先利用 deep-SDM 模型（基于遥感数据、气候时间序列和物种发生数据）在 50x50m 分辨率下预测物种组成，然后通过 Pl@ntBERT（一个基于 Transformer 的 LLM）生成生物多样性指标地图并进行栖息地分类。这种方法支持种间依赖性的联合建模、基于异构 presence-absence 数据的偏差感知训练，以及从多源 remote sensing 输入进行大规模推理，提供精细的生态洞见。相比传统方法，该框架显著提升了映射的准确性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05231v1",
      "published_date": "2025-04-07 16:15:52 UTC",
      "updated_date": "2025-04-07 16:15:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:23:14.862704"
    },
    {
      "arxiv_id": "2504.05229v1",
      "title": "FinGrAct: A Framework for FINe-GRrained Evaluation of ACTionability in Explainable Automatic Fact-Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Islam Eldifrawi",
        "Shengrui Wang",
        "Amine Trabelsi"
      ],
      "abstract": "The field of explainable Automatic Fact-Checking (AFC) aims to enhance the\ntransparency and trustworthiness of automated fact-verification systems by\nproviding clear and comprehensible explanations. However, the effectiveness of\nthese explanations depends on their actionability --their ability to empower\nusers to make informed decisions and mitigate misinformation. Despite\nactionability being a critical property of high-quality explanations, no prior\nresearch has proposed a dedicated method to evaluate it. This paper introduces\nFinGrAct, a fine-grained evaluation framework that can access the web, and it\nis designed to assess actionability in AFC explanations through well-defined\ncriteria and an evaluation dataset. FinGrAct surpasses state-of-the-art (SOTA)\nevaluators, achieving the highest Pearson and Kendall correlation with human\njudgments while demonstrating the lowest ego-centric bias, making it a more\nrobust evaluation approach for actionability evaluation in AFC.",
      "tldr_zh": "该论文针对可解释的 Automatic Fact-Checking (AFC) 系统，强调解释的 actionability（可操作性）对于提升用户决策和减少错误信息的重要性，但现有研究缺乏专用评估方法。作者引入了 FinGrAct 框架，这是一个细粒度评估工具，能访问网络，通过明确标准和数据集来评估 AFC 解释的 actionability。实验结果显示，FinGrAct 超过了 SOTA 评估器，在 Pearson 和 Kendall 相关性上最高，同时表现出最低的 ego-centric 偏差，从而提供更稳健的评估方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05229v1",
      "published_date": "2025-04-07 16:14:27 UTC",
      "updated_date": "2025-04-07 16:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:23:26.026166"
    },
    {
      "arxiv_id": "2504.05220v2",
      "title": "Leveraging LLMs for Utility-Focused Annotation: Reducing Manual Effort for Retrieval and RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Hengran Zhang",
        "Minghao Tang",
        "Keping Bi",
        "Jiafeng Guo",
        "Shihao Liu",
        "Daiting Shi",
        "Dawei Yin",
        "Xueqi Cheng"
      ],
      "abstract": "Retrieval models typically rely on costly human-labeled query-document\nrelevance annotations for training and evaluation. To reduce this cost and\nleverage the potential of Large Language Models (LLMs) in relevance judgments,\nwe aim to explore whether LLM-generated annotations can effectively replace\nhuman annotations in training retrieval models. Retrieval usually emphasizes\nrelevance, which indicates \"topic-relatedness\" of a document to a query, while\nin RAG, the value of a document (or utility) depends on how it contributes to\nanswer generation. Recognizing this mismatch, some researchers use LLM\nperformance on downstream tasks with documents as labels, but this approach\nrequires manual answers for specific tasks, leading to high costs and limited\ngeneralization. In another line of work, prompting LLMs to select useful\ndocuments as RAG references eliminates the need for human annotation and is not\ntask-specific. If we leverage LLMs' utility judgments to annotate retrieval\ndata, we may retain cross-task generalization without human annotation in\nlarge-scale corpora. Therefore, we investigate utility-focused annotation via\nLLMs for large-scale retriever training data across both in-domain and\nout-of-domain settings on the retrieval and RAG tasks. To reduce the impact of\nlow-quality positives labeled by LLMs, we design a novel loss function, i.e.,\nDisj-InfoNCE. Our experiments reveal that: (1) Retrievers trained on\nutility-focused annotations significantly outperform those trained on human\nannotations in the out-of-domain setting on both tasks, demonstrating superior\ngeneralization capabilities. (2) LLM annotation does not replace human\nannotation in the in-domain setting. However, incorporating just 20%\nhuman-annotated data enables retrievers trained with utility-focused\nannotations to match the performance of models trained entirely with human\nannotations.",
      "tldr_zh": "本文提出一种利用大语言模型 (LLMs) 进行实用性-focused 标注的方法，以减少检索和 RAG 任务中手动标注的成本。研究设计了新损失函数 Disj-InfoNCE 来缓解 LLMs 标注中低质量正样本的影响，并通过实验验证了在 out-of-domain 设置下，使用实用性标注训练的检索器在泛化能力上显著优于基于人工标注的模型。结果表明，虽然在 in-domain 设置中 LLMs 标注无法完全取代人工标注，但仅需加入 20% 的人工标注数据，就能使模型性能与完全使用人工标注的模型相当，从而提升跨任务泛化并降低整体标注负担。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05220v2",
      "published_date": "2025-04-07 16:05:52 UTC",
      "updated_date": "2025-04-08 02:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:23:38.838692"
    },
    {
      "arxiv_id": "2504.05216v2",
      "title": "Unleashing the Power of LLMs in Dense Retrieval with Query Likelihood Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Hengran Zhang",
        "Keping Bi",
        "Jiafeng Guo",
        "Xiaojie Sun",
        "Shihao Liu",
        "Daiting Shi",
        "Dawei Yin",
        "Xueqi Cheng"
      ],
      "abstract": "Dense retrieval is a crucial task in Information Retrieval (IR) and is the\nfoundation for downstream tasks such as re-ranking. Recently, large language\nmodels (LLMs) have shown compelling semantic understanding capabilities and are\nappealing to researchers studying dense retrieval. LLMs, as decoder-style\ngenerative models, are competent at language generation while falling short on\nmodeling global information due to the lack of attention to tokens afterward.\nInspired by the classical word-based language modeling approach for IR, i.e.,\nthe query likelihood (QL) model, we seek to sufficiently utilize LLMs'\ngenerative ability by QL maximization. However, instead of ranking documents\nwith QL estimation, we introduce an auxiliary task of QL maximization to yield\na better backbone for contrastively learning a discriminative retriever. We\nname our model as LLM-QL. To condense global document semantics to a single\nvector during QL modeling, LLM-QL has two major components, Attention Stop (AS)\nand Input Corruption (IC). AS stops the attention of predictive tokens to\nprevious tokens until the ending token of the document. IC masks a portion of\ntokens in the input documents during prediction. Experiments on MSMARCO show\nthat LLM-QL can achieve significantly better performance than other LLM-based\nretrievers and using QL estimated by LLM-QL for ranking outperforms word-based\nQL by a large margin.",
      "tldr_zh": "这篇论文探讨了如何利用大语言模型（LLMs）提升密集检索（Dense Retrieval）的性能，提出通过最大化查询似然（Query Likelihood, QL）作为辅助任务，训练一个更有效的判别式检索器。模型名为 LLM-QL，包括 Attention Stop (AS) 和 Input Corruption (IC) 两个组件，AS 用于停止预测标记对之前标记的注意力以捕捉全局文档语义，IC 通过掩盖输入文档部分标记来增强预测鲁棒性。在 MSMARCO 数据集上的实验表明，LLM-QL 显著优于其他基于 LLMs 的检索器，且其 QL 估计用于排名时远超传统基于单词的 QL 方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05216v2",
      "published_date": "2025-04-07 16:03:59 UTC",
      "updated_date": "2025-04-19 13:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:23:50.857378"
    },
    {
      "arxiv_id": "2504.05210v1",
      "title": "A moving target in AI-assisted decision-making: Dataset shift, model updating, and the problem of update opacity",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Hatherley"
      ],
      "abstract": "Machine learning (ML) systems are vulnerable to performance decline over time\ndue to dataset shift. To address this problem, experts often suggest that ML\nsystems should be regularly updated to ensure ongoing performance stability.\nSome scholarly literature has begun to address the epistemic and ethical\nchallenges associated with different updating methodologies. Thus far, however,\nlittle attention has been paid to the impact of model updating on the\nML-assisted decision-making process itself, particularly in the AI ethics and\nAI epistemology literatures. This article aims to address this gap in the\nliterature. It argues that model updating introduces a new sub-type of opacity\ninto ML-assisted decision-making -- update opacity -- that occurs when users\ncannot understand how or why an update has changed the reasoning or behaviour\nof an ML system. This type of opacity presents a variety of distinctive\nepistemic and safety concerns that available solutions to the black box problem\nin ML are largely ill-equipped to address. A variety of alternative strategies\nmay be developed or pursued to address the problem of update opacity more\ndirectly, including bi-factual explanations, dynamic model reporting, and\nupdate compatibility. However, each of these strategies presents its own risks\nor carries significant limitations. Further research will be needed to address\nthe epistemic and safety concerns associated with model updating and update\nopacity going forward.",
      "tldr_zh": "这篇论文探讨了机器学习(ML)系统因 dataset shift 而导致性能下降的问题，强调定期 model updating 的重要性，但指出更新过程会引入 update opacity，即用户无法理解更新如何或为什么改变了系统的推理或行为。该文分析了 update opacity 带来的独特认识论和安全挑战，并认为现有黑箱问题解决方案难以有效应对。论文提出潜在策略，如 bi-factual explanations、dynamic model reporting 和 update compatibility，但这些方法各有风险和限制，呼吁进一步研究以解决相关问题。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05210v1",
      "published_date": "2025-04-07 15:58:23 UTC",
      "updated_date": "2025-04-07 15:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:24:02.509981"
    },
    {
      "arxiv_id": "2505.03746v1",
      "title": "Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García-Méndez",
        "Francisco De Arriba-Pérez"
      ],
      "abstract": "Social media platforms enable instant and ubiquitous connectivity and are\nessential to social interaction and communication in our technological society.\nApart from its advantages, these platforms have given rise to negative\nbehaviors in the online community, the so-called cyberbullying. Despite the\nmany works involving generative Artificial Intelligence (AI) in the literature\nlately, there remain opportunities to study its performance apart from\nzero/few-shot learning strategies. Accordingly, we propose an innovative and\nreal-time solution for cyberbullying detection that leverages stream-based\nMachine Learning (ML) models able to process the incoming samples incrementally\nand Large Language Models (LLMS) for feature engineering to address the\nevolving nature of abusive and hate speech online. An explainability dashboard\nis provided to promote the system's trustworthiness, reliability, and\naccountability. Results on experimental data report promising performance close\nto 90 % in all evaluation metrics and surpassing those obtained by competing\nworks in the literature. Ultimately, our proposal contributes to the safety of\nonline communities by timely detecting abusive behavior to prevent long-lasting\nharassment and reduce the negative consequences in society.",
      "tldr_zh": "本研究针对社交媒体上的网络欺凌（cyberbullying）问题，提出了一种创新的实时检测解决方案，该方案结合Large Language Models (LLMs)进行特征工程和stream-based Machine Learning (ML)模型来增量处理动态数据流。系统包括一个解释性仪表板（explainability dashboard），以提升模型的可信度、可靠性和可解释性。实验结果显示，该方法在各种评估指标上达到近90%的性能，优于现有文献中的竞争方案，最终有助于及时识别虐待行为，保护在线社区安全并减少社会负面影响。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03746v1",
      "published_date": "2025-04-07 15:57:37 UTC",
      "updated_date": "2025-04-07 15:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:24:13.177109"
    },
    {
      "arxiv_id": "2504.05207v1",
      "title": "Correcting Class Imbalances with Self-Training for Improved Universal Lesion Detection and Tagging",
      "title_zh": "使用自训练纠正类别不平衡以改进通用病变检测和标记",
      "authors": [
        "Alexander Shieh",
        "Tejas Sudharshan Mathai",
        "Jianfei Liu",
        "Angshuman Paul",
        "Ronald M. Summers"
      ],
      "abstract": "Universal lesion detection and tagging (ULDT) in CT studies is critical for\ntumor burden assessment and tracking the progression of lesion status\n(growth/shrinkage) over time. However, a lack of fully annotated data hinders\nthe development of effective ULDT approaches. Prior work used the DeepLesion\ndataset (4,427 patients, 10,594 studies, 32,120 CT slices, 32,735 lesions, 8\nbody part labels) for algorithmic development, but this dataset is not\ncompletely annotated and contains class imbalances. To address these issues, in\nthis work, we developed a self-training pipeline for ULDT. A VFNet model was\ntrained on a limited 11.5\\% subset of DeepLesion (bounding boxes + tags) to\ndetect and classify lesions in CT studies. Then, it identified and incorporated\nnovel lesion candidates from a larger unseen data subset into its training set,\nand self-trained itself over multiple rounds. Multiple self-training\nexperiments were conducted with different threshold policies to select\npredicted lesions with higher quality and cover the class imbalances. We\ndiscovered that direct self-training improved the sensitivities of\nover-represented lesion classes at the expense of under-represented classes.\nHowever, upsampling the lesions mined during self-training along with a\nvariable threshold policy yielded a 6.5\\% increase in sensitivity at 4 FP in\ncontrast to self-training without class balancing (72\\% vs 78.5\\%) and a 11.7\\%\nincrease compared to the same self-training policy without upsampling (66.8\\%\nvs 78.5\\%). Furthermore, we show that our results either improved or maintained\nthe sensitivity at 4FP for all 8 lesion classes.",
      "tldr_zh": "该论文针对 CT 研究中的 Universal Lesion Detection and Tagging (ULDT) 问题，开发了一种自训练管道来纠正类别不平衡，利用 VFNet 模型在 DeepLesion 数据集的 11.5% 子集上初始训练，并通过多轮自训练从未见数据中挖掘并加入新病变候选。实验采用不同阈值策略和上采样技术，结果显示这种方法在 4 FP 时的敏感性提高了 6.5%（从 72% 到 78.5%），并比不使用上采样的策略提升了 11.7%。此外，该方法改善了所有 8 个病变类别的敏感性表现，为 ULDT 的算法开发提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at SPIE Medical Imaging 2023",
      "pdf_url": "http://arxiv.org/pdf/2504.05207v1",
      "published_date": "2025-04-07 15:57:03 UTC",
      "updated_date": "2025-04-07 15:57:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:24:27.455106"
    },
    {
      "arxiv_id": "2504.05201v1",
      "title": "3D Universal Lesion Detection and Tagging in CT with Self-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jared Frazier",
        "Tejas Sudharshan Mathai",
        "Jianfei Liu",
        "Angshuman Paul",
        "Ronald M. Summers"
      ],
      "abstract": "Radiologists routinely perform the tedious task of lesion localization,\nclassification, and size measurement in computed tomography (CT) studies.\nUniversal lesion detection and tagging (ULDT) can simultaneously help alleviate\nthe cumbersome nature of lesion measurement and enable tumor burden assessment.\nPrevious ULDT approaches utilize the publicly available DeepLesion dataset,\nhowever it does not provide the full volumetric (3D) extent of lesions and also\ndisplays a severe class imbalance. In this work, we propose a self-training\npipeline to detect 3D lesions and tag them according to the body part they\noccur in. We used a significantly limited 30\\% subset of DeepLesion to train a\nVFNet model for 2D lesion detection and tagging. Next, the 2D lesion context\nwas expanded into 3D, and the mined 3D lesion proposals were integrated back\ninto the baseline training data in order to retrain the model over multiple\nrounds. Through the self-training procedure, our VFNet model learned from its\nown predictions, detected lesions in 3D, and tagged them. Our results indicated\nthat our VFNet model achieved an average sensitivity of 46.9\\% at [0.125:8]\nfalse positives (FP) with a limited 30\\% data subset in comparison to the\n46.8\\% of an existing approach that used the entire DeepLesion dataset. To our\nknowledge, we are the first to jointly detect lesions in 3D and tag them\naccording to the body part label.",
      "tldr_zh": "本研究针对放射科医生在 CT 扫描中进行病变定位、分类和大小测量的繁琐任务，提出了一种基于自训练(self-training)的 3D Universal Lesion Detection and Tagging (ULDT) 方法，以缓解负担并实现肿瘤负担评估。方法使用 DeepLesion 数据集的 30% 子集训练 VFNet 模型进行 2D 病变检测和标记，然后扩展到 3D 并通过多次自训练循环整合挖掘的 3D 病变提案，实现病变的 3D 检测和身体部位标记。实验结果显示，该模型在 [0.125:8] 假阳性(FP)范围内达到 46.9% 的平均敏感性，与使用完整数据集的现有方法(46.8%)相当；这也是首次联合实现 3D 病变检测和标签标记，展示了高效的数据利用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at SPIE Medical Imaging 2023",
      "pdf_url": "http://arxiv.org/pdf/2504.05201v1",
      "published_date": "2025-04-07 15:50:27 UTC",
      "updated_date": "2025-04-07 15:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:24:39.994646"
    },
    {
      "arxiv_id": "2504.05196v1",
      "title": "Universal Lymph Node Detection in Multiparametric MRI with Selective Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Tejas Sudharshan Mathai",
        "Sungwon Lee",
        "Thomas C. Shen",
        "Zhiyong Lu",
        "Ronald M. Summers"
      ],
      "abstract": "Robust localization of lymph nodes (LNs) in multiparametric MRI (mpMRI) is\ncritical for the assessment of lymphadenopathy. Radiologists routinely measure\nthe size of LN to distinguish benign from malignant nodes, which would require\nsubsequent cancer staging. Sizing is a cumbersome task compounded by the\ndiverse appearances of LNs in mpMRI, which renders their measurement difficult.\nFurthermore, smaller and potentially metastatic LNs could be missed during a\nbusy clinical day. To alleviate these imaging and workflow problems, we propose\na pipeline to universally detect both benign and metastatic nodes in the body\nfor their ensuing measurement. The recently proposed VFNet neural network was\nemployed to identify LN in T2 fat suppressed and diffusion weighted imaging\n(DWI) sequences acquired by various scanners with a variety of exam protocols.\nWe also use a selective augmentation technique known as Intra-Label LISA (ILL)\nto diversify the input data samples the model sees during training, such that\nit improves its robustness during the evaluation phase. We achieved a\nsensitivity of $\\sim$83\\% with ILL vs. $\\sim$80\\% without ILL at 4 FP/vol.\nCompared with current LN detection approaches evaluated on mpMRI, we show a\nsensitivity improvement of $\\sim$9\\% at 4 FP/vol.",
      "tldr_zh": "该论文针对多参数 MRI (mpMRI) 中淋巴结 (LNs) 的鲁棒检测问题提出了一种通用管道，以辅助区分良性和恶性节点并简化临床测量流程。该方法采用 VFNet 神经网络在 T2 脂肪抑制和扩散加权成像 (DWI) 序列上识别 LNs，并引入选择性增强技术 Intra-Label LISA (ILL) 来增加训练数据的多样性，提高模型鲁棒性。实验结果显示，使用 ILL 的敏感性约为 83%，比不使用时提高 3%，并在 4 FP/vol 条件下比现有方法提升约 9%。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Published at SPIE Medical Imaging 2023",
      "pdf_url": "http://arxiv.org/pdf/2504.05196v1",
      "published_date": "2025-04-07 15:46:43 UTC",
      "updated_date": "2025-04-07 15:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:24:51.546103"
    },
    {
      "arxiv_id": "2504.05187v1",
      "title": "Resource-Efficient Beam Prediction in mmWave Communications with Multimodal Realistic Simulation Framework",
      "title_zh": "资源高效的毫米波通信波束",
      "authors": [
        "Yu Min Park",
        "Yan Kyaw Tun",
        "Walid Saad",
        "Choong Seon Hong"
      ],
      "abstract": "Beamforming is a key technology in millimeter-wave (mmWave) communications\nthat improves signal transmission by optimizing directionality and intensity.\nHowever, conventional channel estimation methods, such as pilot signals or beam\nsweeping, often fail to adapt to rapidly changing communication environments.\nTo address this limitation, multimodal sensing-aided beam prediction has gained\nsignificant attention, using various sensing data from devices such as LiDAR,\nradar, GPS, and RGB images to predict user locations or network conditions.\nDespite its promising potential, the adoption of multimodal sensing-aided beam\nprediction is hindered by high computational complexity, high costs, and\nlimited datasets. Thus, in this paper, a resource-efficient learning approach\nis proposed to transfer knowledge from a multimodal network to a monomodal\n(radar-only) network based on cross-modal relational knowledge distillation\n(CRKD), while reducing computational overhead and preserving predictive\naccuracy. To enable multimodal learning with realistic data, a novel multimodal\nsimulation framework is developed while integrating sensor data generated from\nthe autonomous driving simulator CARLA with MATLAB-based mmWave channel\nmodeling, and reflecting real-world conditions. The proposed CRKD achieves its\nobjective by distilling relational information across different feature spaces,\nwhich enhances beam prediction performance without relying on expensive sensor\ndata. Simulation results demonstrate that CRKD efficiently distills multimodal\nknowledge, allowing a radar-only model to achieve $94.62\\%$ of the teacher\nperformance. In particular, this is achieved with just $10\\%$ of the teacher\nnetwork's parameters, thereby significantly reducing computational complexity\nand dependence on multimodal sensor data.",
      "tldr_zh": "本文提出了一种资源高效的波束预测方法，针对 mmWave 通信中传统通道估计（如 pilot signals 或 beam sweeping）无法适应快速变化环境的局限性，通过跨模态关系知识蒸馏 (CRKD) 将知识从多模态网络（如 LiDAR、radar、GPS 和 RGB 图像）转移到单模态 (radar-only) 网络，从而减少计算开销并保持预测准确性。该方法还开发了一个新颖的多模态模拟框架，将 CARLA 自动驾驶模拟器生成的传感器数据与 MATLAB 的 mmWave 通道建模整合，以模拟真实世界条件。实验结果表明，CRKD 使 radar-only 模型达到了教师模型 94.62% 的性能，仅需教师网络 10% 的参数，显著降低了计算复杂度和对多模态数据的依赖。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages, 8 figures, Submitted to IEEE Transactions on Communications\n  on Apr. 07, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05187v1",
      "published_date": "2025-04-07 15:38:25 UTC",
      "updated_date": "2025-04-07 15:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:25:03.155207"
    },
    {
      "arxiv_id": "2504.05181v2",
      "title": "Lightweight and Direct Document Relevance Optimization for Generative Information Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Kidist Amde Mekonnen",
        "Yubao Tang",
        "Maarten de Rijke"
      ],
      "abstract": "Generative information retrieval (GenIR) is a promising neural retrieval\nparadigm that formulates document retrieval as a document identifier (docid)\ngeneration task, allowing for end-to-end optimization toward a unified global\nretrieval objective. However, existing GenIR models suffer from token-level\nmisalignment, where models trained to predict the next token often fail to\ncapture document-level relevance effectively. While reinforcement\nlearning-based methods, such as reinforcement learning from relevance feedback\n(RLRF), aim to address this misalignment through reward modeling, they\nintroduce significant complexity, requiring the optimization of an auxiliary\nreward function followed by reinforcement fine-tuning, which is computationally\nexpensive and often unstable. To address these challenges, we propose direct\ndocument relevance optimization (DDRO), which aligns token-level docid\ngeneration with document-level relevance estimation through direct optimization\nvia pairwise ranking, eliminating the need for explicit reward modeling and\nreinforcement learning. Experimental results on benchmark datasets, including\nMS MARCO document and Natural Questions, show that DDRO outperforms\nreinforcement learning-based methods, achieving a 7.4% improvement in MRR@10\nfor MS MARCO and a 19.9% improvement for Natural Questions. These findings\nhighlight DDRO's potential to enhance retrieval effectiveness with a simplified\noptimization approach. By framing alignment as a direct optimization problem,\nDDRO simplifies the ranking optimization pipeline of GenIR models while\noffering a viable alternative to reinforcement learning-based methods.",
      "tldr_zh": "本研究针对生成式信息检索 (GenIR) 中存在的 token-level 失调问题，提出了一种轻量级直接文档相关性优化 (DDRO) 方法，通过配对排名直接优化 docid 生成与文档级相关性的对齐，省去了传统强化学习方法（如 RLRF）的复杂奖励模型和微调过程。DDRO 简化了优化流程，使模型能够更有效地捕捉文档相关性。实验在 MS MARCO 和 Natural Questions 数据集上显示，DDRO 比强化学习方法提升了 7.4% 的 MRR@10 和 19.9% 的 MRR，证明了其在提升检索效果方面的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DL",
        "cs.LG",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "12 pages, 3 figures. SIGIR '25 Proceedings of the 48th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  July 13--18, 2025 Padua, Italy. Code and pretrained models available at:\n  https://github.com/kidist-amde/ddro/",
      "pdf_url": "http://arxiv.org/pdf/2504.05181v2",
      "published_date": "2025-04-07 15:27:37 UTC",
      "updated_date": "2025-04-24 23:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:25:14.722157"
    },
    {
      "arxiv_id": "2504.05180v1",
      "title": "BRIDGES: Bridging Graph Modality and Large Language Models within EDA Tasks",
      "title_zh": "BRIDGES：在 EDA 任务中桥接图模态与大型语言模型",
      "authors": [
        "Wei Li",
        "Yang Zou",
        "Christopher Ellis",
        "Ruben Purdy",
        "Shawn Blanton",
        "José M. F. Moura"
      ],
      "abstract": "While many EDA tasks already involve graph-based data, existing LLMs in EDA\nprimarily either represent graphs as sequential text, or simply ignore\ngraph-structured data that might be beneficial like dataflow graphs of RTL\ncode. Recent studies have found that LLM performance suffers when graphs are\nrepresented as sequential text, and using additional graph information\nsignificantly boosts performance. To address these challenges, we introduce\nBRIDGES, a framework designed to incorporate graph modality into LLMs for EDA\ntasks. BRIDGES integrates an automated data generation workflow, a solution\nthat combines graph modality with LLM, and a comprehensive evaluation suite.\nFirst, we establish an LLM-driven workflow to generate RTL and netlist-level\ndata, converting them into dataflow and netlist graphs with function\ndescriptions. This workflow yields a large-scale dataset comprising over\n500,000 graph instances and more than 1.5 billion tokens. Second, we propose a\nlightweight cross-modal projector that encodes graph representations into\ntext-compatible prompts, enabling LLMs to effectively utilize graph data\nwithout architectural modifications. Experimental results demonstrate 2x to 10x\nimprovements across multiple tasks compared to text-only baselines, including\naccuracy in design retrieval, type prediction and perplexity in function\ndescription, with negligible computational overhead (<1% model weights increase\nand <30% additional runtime overhead). Even without additional LLM finetuning,\nour results outperform text-only by a large margin. We plan to release BRIDGES,\nincluding the dataset, models, and training flow.",
      "tldr_zh": "该研究提出BRIDGES框架，用于将图模式(Graph Modality)整合到Large Language Models (LLMs)中，以提升电子设计自动化(EDA)任务的性能。框架包括一个自动化数据生成工作流，该工作流利用LLM驱动生成RTL和netlist-level数据，并转换为dataflow和netlist graphs，创建了超过50万图实例和15亿tokens的大规模数据集；此外，还引入了一个轻量级跨模式投影器，将图表示编码为文本兼容提示，而无需修改LLM架构。实验结果显示，BRIDGES在设计检索、类型预测和功能描述等任务上比文本-only基线提升2x到10x的性能，同时计算开销极低（<1%模型权重增加和<30%额外运行时开销），并计划开源数据集、模型和训练流程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05180v1",
      "published_date": "2025-04-07 15:27:32 UTC",
      "updated_date": "2025-04-07 15:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:25:27.135866"
    },
    {
      "arxiv_id": "2504.05172v2",
      "title": "Attention-Based Multiscale Temporal Fusion Network for Uncertain-Mode Fault Diagnosis in Multimode Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Guangqiang Li",
        "M. Amine Atoui",
        "Xiangshun Li"
      ],
      "abstract": "Fault diagnosis in multimode processes plays a critical role in ensuring the\nsafe operation of industrial systems across multiple modes. It faces a great\nchallenge yet to be addressed - that is, the significant distributional\ndifferences among monitoring data from multiple modes make it difficult for the\nmodels to extract shared feature representations related to system health\nconditions. In response to this problem, this paper introduces a novel method\ncalled attention-based multiscale temporal fusion network. The multiscale\ndepthwise convolution and gated recurrent unit are employed to extract\nmultiscale contextual local features and long-short-term features. Instance\nnormalization is applied to suppress mode-specific information. Furthermore, a\ntemporal attention mechanism is designed to focus on critical time points with\nhigher cross-mode shared information, thereby enhancing the accuracy of fault\ndiagnosis. The proposed model is applied to Tennessee Eastman process dataset\nand three-phase flow facility dataset. The experiments demonstrate that the\nproposed model achieves superior diagnostic performance and maintains a small\nmodel size. The source code will be available on GitHub at\nhttps://github.com/GuangqiangLi/AMTFNet.",
      "tldr_zh": "这篇论文针对多模式过程的故障诊断问题，提出了一种名为 Attention-Based Multiscale Temporal Fusion Network 的新方法，以应对不同模式数据分布差异导致的共享特征提取难题。该方法结合 Multiscale Depthwise Convolution 和 Gated Recurrent Unit 来提取多尺度上下文局部特征与长短期特征，并通过 Instance Normalization 抑制模式特定信息，同时设计 Temporal Attention Mechanism 关注关键时间点以提升诊断准确性。在 Tennessee Eastman 过程数据集和三相流设施数据集上的实验显示，该模型在故障诊断性能上优于基线方法，同时保持较小的模型大小，源代码将在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05172v2",
      "published_date": "2025-04-07 15:16:22 UTC",
      "updated_date": "2025-04-14 08:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:25:39.291922"
    },
    {
      "arxiv_id": "2504.05170v1",
      "title": "SSLFusion: Scale & Space Aligned Latent Fusion Model for Multimodal 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Bonan Ding",
        "Jin Xie",
        "Jing Nie",
        "Jiale Cao"
      ],
      "abstract": "Multimodal 3D object detection based on deep neural networks has indeed made\nsignificant progress. However, it still faces challenges due to the\nmisalignment of scale and spatial information between features extracted from\n2D images and those derived from 3D point clouds. Existing methods usually\naggregate multimodal features at a single stage. However, leveraging\nmulti-stage cross-modal features is crucial for detecting objects of various\nscales. Therefore, these methods often struggle to integrate features across\ndifferent scales and modalities effectively, thereby restricting the accuracy\nof detection. Additionally, the time-consuming Query-Key-Value-based\n(QKV-based) cross-attention operations often utilized in existing methods aid\nin reasoning the location and existence of objects by capturing non-local\ncontexts. However, this approach tends to increase computational complexity. To\naddress these challenges, we present SSLFusion, a novel Scale & Space Aligned\nLatent Fusion Model, consisting of a scale-aligned fusion strategy (SAF), a\n3D-to-2D space alignment module (SAM), and a latent cross-modal fusion module\n(LFM). SAF mitigates scale misalignment between modalities by aggregating\nfeatures from both images and point clouds across multiple levels. SAM is\ndesigned to reduce the inter-modal gap between features from images and point\nclouds by incorporating 3D coordinate information into 2D image features.\nAdditionally, LFM captures cross-modal non-local contexts in the latent space\nwithout utilizing the QKV-based attention operations, thus mitigating\ncomputational complexity. Experiments on the KITTI and DENSE datasets\ndemonstrate that our SSLFusion outperforms state-of-the-art methods. Our\napproach obtains an absolute gain of 2.15% in 3D AP, compared with the\nstate-of-art method GraphAlign on the moderate level of the KITTI test set.",
      "tldr_zh": "该研究针对多模态3D物体检测中的规模和空间不对齐问题，提出了SSLFusion，一种新型的Scale & Space Aligned Latent Fusion Model。\nSSLFusion包括Scale-Aligned Fusion Strategy (SAF)用于多级别特征聚合以缓解规模失配、3D-to-2D Space Alignment Module (SAM)通过融入3D坐标信息减少模态间差距，以及Latent Cross-Modal Fusion Module (LFM)在潜在空间捕获跨模态上下文而避免计算密集的QKV-based注意力操作。\n在KITTI和DENSE数据集的实验中，SSLFusion比最先进方法GraphAlign在KITTI测试集moderate级别上提高了2.15%的3D AP，展示了其在检测准确性上的显著提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05170v1",
      "published_date": "2025-04-07 15:15:06 UTC",
      "updated_date": "2025-04-07 15:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:25:51.955098"
    },
    {
      "arxiv_id": "2504.05167v1",
      "title": "RLBayes: a Bayesian Network Structure Learning Algorithm via Reinforcement Learning-Based Search Strategy",
      "title_zh": "RLBayes：基于强化学习搜索策略的贝叶斯网络结构学习算法",
      "authors": [
        "Mingcan Wang",
        "Junchang Xin",
        "Luxuan Qu",
        "Qi Chen",
        "Zhiqiong Wang"
      ],
      "abstract": "The score-based structure learning of Bayesian network (BN) is an effective\nway to learn BN models, which are regarded as some of the most compelling\nprobabilistic graphical models in the field of representation and reasoning\nunder uncertainty. However, the search space of structure learning grows\nsuper-exponentially as the number of variables increases, which makes BN\nstructure learning an NP-hard problem, as well as a combination optimization\nproblem (COP). Despite the successes of many heuristic methods on it, the\nresults of the structure learning of BN are usually unsatisfactory. Inspired by\nQ-learning, in this paper, a Bayesian network structure learning algorithm via\nreinforcement learning-based (RL-based) search strategy is proposed, namely\nRLBayes. The method borrows the idea of RL and tends to record and guide the\nlearning process by a dynamically maintained Q-table. By creating and\nmaintaining the dynamic Q-table, RLBayes achieve storing the unlimited search\nspace within limited space, thereby achieving the structure learning of BN via\nQ-learning. Not only is it theoretically proved that RLBayes can converge to\nthe global optimal BN structure, but also it is experimentally proved that\nRLBayes has a better effect than almost all other heuristic search algorithms.",
      "tldr_zh": "这篇论文针对贝叶斯网络 (BN) 结构学习的 NP-hard 问题，提出了一种名为 RLBayes 的算法，该算法采用基于强化学习 (RL) 的搜索策略，通过动态维护 Q-table 来记录和指导学习过程。RLBayes 借鉴 Q-learning 的思想，将无限搜索空间存储在有限空间内，实现高效的 BN 结构学习。理论上证明该算法能收敛到全局最优结构，实验结果显示它在效果上优于几乎所有其他启发式搜索算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05167v1",
      "published_date": "2025-04-07 15:11:51 UTC",
      "updated_date": "2025-04-07 15:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:26:02.500713"
    },
    {
      "arxiv_id": "2504.05163v1",
      "title": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness",
      "title_zh": "在知识不完整性下评估基于知识图谱的检索增强生成方法",
      "authors": [
        "Dongzhuoran Zhou",
        "Yuqicheng Zhu",
        "Yuan He",
        "Jiaoyan Chen",
        "Evgeny Kharlamov",
        "Steffen Staab"
      ],
      "abstract": "Knowledge Graph based Retrieval-Augmented Generation (KG-RAG) is a technique\nthat enhances Large Language Model (LLM) inference in tasks like Question\nAnswering (QA) by retrieving relevant information from knowledge graphs (KGs).\nHowever, real-world KGs are often incomplete, meaning that essential\ninformation for answering questions may be missing. Existing benchmarks do not\nadequately capture the impact of KG incompleteness on KG-RAG performance. In\nthis paper, we systematically evaluate KG-RAG methods under incomplete KGs by\nremoving triples using different methods and analyzing the resulting effects.\nWe demonstrate that KG-RAG methods are sensitive to KG incompleteness,\nhighlighting the need for more robust approaches in realistic settings.",
      "tldr_zh": "本文评估了在知识图谱 (KG) 不完整情况下的基于 KG 的检索增强生成 (KG-RAG) 方法，这些方法通过从 KG 中检索信息来提升大型语言模型 (LLM) 在问答 (QA) 等任务中的性能。研究者通过移除 triples 的不同方式模拟 KG 不完整性，并系统分析其对 KG-RAG 性能的影响。结果显示，KG-RAG 方法对 KG 不完整性高度敏感，突显了在现实场景中开发更鲁棒方法的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2504.05163v1",
      "published_date": "2025-04-07 15:08:03 UTC",
      "updated_date": "2025-04-07 15:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:26:14.601324"
    },
    {
      "arxiv_id": "2504.05158v1",
      "title": "Leveraging Label Potential for Enhanced Multimodal Emotion Recognition",
      "title_zh": "利用标签潜力增强多模态情感识别",
      "authors": [
        "Xuechun Shao",
        "Yinfeng Yu",
        "Liejun Wang"
      ],
      "abstract": "Multimodal emotion recognition (MER) seeks to integrate various modalities to\npredict emotional states accurately. However, most current research focuses\nsolely on the fusion of audio and text features, overlooking the valuable\ninformation in emotion labels. This oversight could potentially hinder the\nperformance of existing methods, as emotion labels harbor rich, insightful\ninformation that could significantly aid MER. We introduce a novel model called\nLabel Signal-Guided Multimodal Emotion Recognition (LSGMER) to overcome this\nlimitation. This model aims to fully harness the power of emotion label\ninformation to boost the classification accuracy and stability of MER.\nSpecifically, LSGMER employs a Label Signal Enhancement module that optimizes\nthe representation of modality features by interacting with audio and text\nfeatures through label embeddings, enabling it to capture the nuances of\nemotions precisely. Furthermore, we propose a Joint Objective Optimization(JOO)\napproach to enhance classification accuracy by introducing the\nAttribution-Prediction Consistency Constraint (APC), which strengthens the\nalignment between fused features and emotion categories. Extensive experiments\nconducted on the IEMOCAP and MELD datasets have demonstrated the effectiveness\nof our proposed LSGMER model.",
      "tldr_zh": "该研究指出，现有多模态情感识别(Multimodal Emotion Recognition, MER)方法主要聚焦音频和文本特征融合，却忽略了情感标签中蕴含的宝贵信息，从而限制了性能。作者提出了一种新型模型Label Signal-Guided Multimodal Emotion Recognition (LSGMER)，通过Label Signal Enhancement模块利用标签嵌入与音频、文本特征交互，优化模态表示以精确捕捉情感细微差别；同时，引入Joint Objective Optimization (JOO)方法和Attribution-Prediction Consistency Constraint (APC)来加强融合特征与情感类别的对齐，提升分类准确性和稳定性。在IEMOCAP和MELD数据集上的广泛实验证明，LSGMER显著提高了MER的表现。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Main paper (8 pages). Accepted for publication by IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05158v1",
      "published_date": "2025-04-07 15:00:34 UTC",
      "updated_date": "2025-04-07 15:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:26:26.980982"
    },
    {
      "arxiv_id": "2504.05150v2",
      "title": "A Reinforcement Learning Method for Environments with Stochastic Variables: Post-Decision Proximal Policy Optimization with Dual Critic Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Kanashiro Felizardo",
        "Edoardo Fadda",
        "Paolo Brandimarte",
        "Emilio Del-Moral-Hernandez",
        "Mariá Cristina Vasconcelos Nascimento"
      ],
      "abstract": "This paper presents Post-Decision Proximal Policy Optimization (PDPPO), a\nnovel variation of the leading deep reinforcement learning method, Proximal\nPolicy Optimization (PPO). The PDPPO state transition process is divided into\ntwo steps: a deterministic step resulting in the post-decision state and a\nstochastic step leading to the next state. Our approach incorporates\npost-decision states and dual critics to reduce the problem's dimensionality\nand enhance the accuracy of value function estimation. Lot-sizing is a mixed\ninteger programming problem for which we exemplify such dynamics. The objective\nof lot-sizing is to optimize production, delivery fulfillment, and inventory\nlevels in uncertain demand and cost parameters. This paper evaluates the\nperformance of PDPPO across various environments and configurations. Notably,\nPDPPO with a dual critic architecture achieves nearly double the maximum reward\nof vanilla PPO in specific scenarios, requiring fewer episode iterations and\ndemonstrating faster and more consistent learning across different\ninitializations. On average, PDPPO outperforms PPO in environments with a\nstochastic component in the state transition. These results support the\nbenefits of using a post-decision state. Integrating this post-decision state\nin the value function approximation leads to more informed and efficient\nlearning in high-dimensional and stochastic environments.",
      "tldr_zh": "本论文提出了一种新型强化学习方法 Post-Decision Proximal Policy Optimization (PDPPO)，它是 Proximal Policy Optimization (PPO) 的变体，针对随机变量环境通过分解状态转移为确定性后决策状态和随机下一步状态来提升性能。PDPPO 引入后决策状态和 Dual Critic Networks，以降低问题维度并提高价值函数估计的准确性，并以库存优化（Lot-sizing）问题为例，展示其在不确定需求和成本下的应用。实验结果表明，PDPPO 在各种环境中平均优于 PPO，尤其在特定场景中实现近乎双倍的最大奖励，且需要更少的迭代和更一致的学习过程，从而证明了其在高维随机环境中的高效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; G.1.6"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures. Accepted for presentation at IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05150v2",
      "published_date": "2025-04-07 14:56:43 UTC",
      "updated_date": "2025-04-11 03:14:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:26:39.990895"
    },
    {
      "arxiv_id": "2504.05141v2",
      "title": "EffOWT: Transfer Visual Language Models to Open-World Tracking Efficiently and Effectively",
      "title_zh": "EffOWT：高效有效地将视觉语言模型转移到开放世界跟踪",
      "authors": [
        "Bingyang Wang",
        "Kaer Huang",
        "Bin Li",
        "Yiqiang Yan",
        "Lihe Zhang",
        "Huchuan Lu",
        "You He"
      ],
      "abstract": "Open-World Tracking (OWT) aims to track every object of any category, which\nrequires the model to have strong generalization capabilities. Trackers can\nimprove their generalization ability by leveraging Visual Language Models\n(VLMs). However, challenges arise with the fine-tuning strategies when VLMs are\ntransferred to OWT: full fine-tuning results in excessive parameter and memory\ncosts, while the zero-shot strategy leads to sub-optimal performance. To solve\nthe problem, EffOWT is proposed for efficiently transferring VLMs to OWT.\nSpecifically, we build a small and independent learnable side network outside\nthe VLM backbone. By freezing the backbone and only executing backpropagation\non the side network, the model's efficiency requirements can be met. In\naddition, EffOWT enhances the side network by proposing a hybrid structure of\nTransformer and CNN to improve the model's performance in the OWT field.\nFinally, we implement sparse interactions on the MLP, thus reducing parameter\nupdates and memory costs significantly. Thanks to the proposed methods, EffOWT\nachieves an absolute gain of 5.5% on the tracking metric OWTA for unknown\ncategories, while only updating 1.3% of the parameters compared to full\nfine-tuning, with a 36.4% memory saving. Other metrics also demonstrate obvious\nimprovement.",
      "tldr_zh": "该研究提出 EffOWT 方法，用于高效有效地将 Visual Language Models (VLMs) 转移到 Open-World Tracking (OWT)，以提升模型的泛化能力并解决全微调的高成本和零样本策略的性能不足问题。EffOWT 通过构建一个小型独立的可学习 side network，冻结 VLM backbone 并仅在 side network 上执行反向传播，同时采用 Transformer 和 CNN 的混合结构以及 MLP 上的稀疏交互，显著减少参数更新和内存消耗。实验结果显示，EffOWT 在未知类别跟踪指标 OWTA 上获得 5.5% 的绝对提升，仅更新 1.3% 的参数，并节省 36.4% 的内存，其他跟踪指标也表现出明显改善。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05141v2",
      "published_date": "2025-04-07 14:47:58 UTC",
      "updated_date": "2025-04-09 01:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:26:52.584032"
    },
    {
      "arxiv_id": "2504.05125v1",
      "title": "Interpretable Style Takagi-Sugeno-Kang Fuzzy Clustering",
      "title_zh": "可解释的风格 Takagi-Sugeno-Kang 模糊聚类",
      "authors": [
        "Suhang Gu",
        "Ye Wang",
        "Yongxin Chou",
        "Jinliang Cong",
        "Mingli Lu",
        "Zhuqing Jiao"
      ],
      "abstract": "Clustering is an efficient and essential technique for exploring latent\nknowledge of data. However, limited attention has been given to the\ninterpretability of the clusters detected by most clustering algorithms. In\naddition, due to the homogeneity of data, different groups of data have their\nown homogeneous styles. In this paper, the above two aspects are considered,\nand an interpretable style Takagi-Sugeno-Kang (TSK) fuzzy clustering\n(IS-TSK-FC) algorithm is proposed. The clustering behavior of IS-TSK-FC is\nfully guided by the TSK fuzzy inference on fuzzy rules. In particular, samples\nare grouped into clusters represented by the corresponding consequent vectors\nof all fuzzy rules learned in an unsupervised manner. This can explain how the\nclusters are generated in detail, thus making the underlying decision-making\nprocess of the IS-TSK-FC interpretable. Moreover, a series of style matrices\nare introduced to facilitate the consequents of fuzzy rules in IS-TSK-FC by\ncapturing the styles of clusters as well as the nuances between different\nstyles. Consequently, all the fuzzy rules in IS-TSK-FC have powerful data\nrepresentation capability. After determining the antecedents of all the fuzzy\nrules, the optimization problem of IS-TSK-FC can be iteratively solved in an\nalternation manner. The effectiveness of IS-TSK-FC as an interpretable\nclustering tool is validated through extensive experiments on benchmark\ndatasets with unknown implicit/explicit styles. Specially, the superior\nclustering performance of IS-TSK-FC is demonstrated on case studies where\ndifferent groups of data present explicit styles. The source code of IS-TSK-FC\ncan be downloaded from https://github.com/gusuhang10/IS-TSK-FC.",
      "tldr_zh": "本论文提出了一种可解释的风格 Takagi-Sugeno-Kang (TSK) 模糊聚类算法（IS-TSK-FC），旨在解决传统聚类算法解释性不足的问题，同时考虑数据组的同质风格差异。IS-TSK-FC 通过 TSK 模糊推理指导聚类行为，将样本分组到由模糊规则的后续向量表示的聚集中，从而详细解释聚类生成过程。算法引入风格矩阵来捕捉聚类的风格特征及其细微差异，提升模糊规则的数据表示能力，并通过迭代交替优化问题来实现高效计算。实验在基准数据集上验证了 IS-TSK-FC 的优越性能，尤其在数据具有显式风格的案例中，展示了其作为可解释聚类工具的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05125v1",
      "published_date": "2025-04-07 14:28:56 UTC",
      "updated_date": "2025-04-07 14:28:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:27:03.702830"
    },
    {
      "arxiv_id": "2504.05119v1",
      "title": "Balancing Robustness and Efficiency in Embedded DNNs Through Activation Function Selection",
      "title_zh": "通过激活函数选择平衡嵌入式深度神经网络的鲁棒性和效率",
      "authors": [
        "Jon Gutiérrez Zaballa",
        "Koldo Basterretxea",
        "Javier Echanobe"
      ],
      "abstract": "Machine learning-based embedded systems for safety-critical applications,\nsuch as aerospace and autonomous driving, must be robust to perturbations\ncaused by soft errors. As transistor geometries shrink and voltages decrease,\nmodern electronic devices become more susceptible to background radiation,\nincreasing the concern about failures produced by soft errors. The resilience\nof deep neural networks (DNNs) to these errors depends not only on target\ndevice technology but also on model structure and the numerical representation\nand arithmetic precision of their parameters. Compression techniques like\npruning and quantization, used to reduce memory footprint and computational\ncomplexity, alter both model structure and representation, affecting soft error\nrobustness. In this regard, although often overlooked, the choice of activation\nfunctions (AFs) impacts not only accuracy and trainability but also\ncompressibility and error resilience. This paper explores the use of bounded\nAFs to enhance robustness against parameter perturbations, while evaluating\ntheir effects on model accuracy, compressibility, and computational load with a\ntechnology-agnostic approach. We focus on encoder-decoder convolutional models\ndeveloped for semantic segmentation of hyperspectral images with application to\nautonomous driving systems. Experiments are conducted on an AMD-Xilinx's KV260\nSoM.",
      "tldr_zh": "该论文探讨了在嵌入式深度神经网络 (DNNs) 中，通过激活函数 (AFs) 选择来平衡鲁棒性和效率，以应对安全关键应用（如航空航天和自动驾驶）中的软错误问题。研究强调，使用有界激活函数 (bounded AFs) 可以增强模型对参数扰动的鲁棒性，同时评估其对模型准确性、可压缩性和计算负载的影响。实验采用技术无关的方法，焦点在编码器-解码器卷积模型上，用于高光谱图像的语义分割，并已在 AMD-Xilinx's KV260 SoM 上进行验证，结果展示了这种方法在提高鲁棒性方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05119v1",
      "published_date": "2025-04-07 14:21:31 UTC",
      "updated_date": "2025-04-07 14:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:27:15.900774"
    },
    {
      "arxiv_id": "2504.05118v3",
      "title": "VAPO: Efficient and Reliable Reinforcement Learning for Advanced Reasoning Tasks",
      "title_zh": "VAPO：高效且可靠的强化学习，用于高级推理任务",
      "authors": [
        "Yu Yue",
        "Yufeng Yuan",
        "Qiying Yu",
        "Xiaochen Zuo",
        "Ruofei Zhu",
        "Wenyuan Xu",
        "Jiaze Chen",
        "Chengyi Wang",
        "TianTian Fan",
        "Zhengyin Du",
        "Xiangpeng Wei",
        "Xiangyu Yu",
        "Gaohong Liu",
        "Juncai Liu",
        "Lingjun Liu",
        "Haibin Lin",
        "Zhiqi Lin",
        "Bole Ma",
        "Chi Zhang",
        "Mofan Zhang",
        "Wang Zhang",
        "Hang Zhu",
        "Ru Zhang",
        "Xin Liu",
        "Mingxuan Wang",
        "Yonghui Wu",
        "Lin Yan"
      ],
      "abstract": "We present VAPO, Value-based Augmented Proximal Policy Optimization framework\nfor reasoning models., a novel framework tailored for reasoning models within\nthe value-based paradigm. Benchmarked the AIME 2024 dataset, VAPO, built on the\nQwen 32B pre-trained model, attains a state-of-the-art score of\n$\\mathbf{60.4}$. In direct comparison under identical experimental settings,\nVAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B\nand DAPO by more than 10 points. The training process of VAPO stands out for\nits stability and efficiency. It reaches state-of-the-art performance within a\nmere 5,000 steps. Moreover, across multiple independent runs, no training\ncrashes occur, underscoring its reliability. This research delves into long\nchain-of-thought (long-CoT) reasoning using a value-based reinforcement\nlearning framework. We pinpoint three key challenges that plague value-based\nmethods: value model bias, the presence of heterogeneous sequence lengths, and\nthe sparsity of reward signals. Through systematic design, VAPO offers an\nintegrated solution that effectively alleviates these challenges, enabling\nenhanced performance in long-CoT reasoning tasks.",
      "tldr_zh": "本研究提出 VAPO 框架，这是一种基于价值的增强近端策略优化（Value-based Augmented Proximal Policy Optimization），针对高级推理任务的强化学习模型。在 AIME 2024 数据集上，VAPO 基于 Qwen 32B 预训练模型达到了 60.4 的最先进分数，比 DeepSeek-R1-Zero-Qwen-32B 和 DAPO 高出 10 点以上，且在 5000 步内实现这一性能，同时确保训练过程稳定可靠，无崩溃风险。VAPO 系统地解决了价值模型偏差、异构序列长度和奖励信号稀疏等挑战，从而提升了长链式思维（long-CoT）推理任务的整体表现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05118v3",
      "published_date": "2025-04-07 14:21:11 UTC",
      "updated_date": "2025-04-11 02:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:27:27.381742"
    },
    {
      "arxiv_id": "2504.05108v3",
      "title": "Algorithm Discovery With LLMs: Evolutionary Search Meets Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Anja Surina",
        "Amin Mansouri",
        "Lars Quaedvlieg",
        "Amal Seddas",
        "Maryna Viazovska",
        "Emmanuel Abbe",
        "Caglar Gulcehre"
      ],
      "abstract": "Discovering efficient algorithms for solving complex problems has been an\noutstanding challenge in mathematics and computer science, requiring\nsubstantial human expertise over the years. Recent advancements in evolutionary\nsearch with large language models (LLMs) have shown promise in accelerating the\ndiscovery of algorithms across various domains, particularly in mathematics and\noptimization. However, existing approaches treat the LLM as a static generator,\nmissing the opportunity to update the model with the signal obtained from\nevolutionary exploration. In this work, we propose to augment LLM-based\nevolutionary search by continuously refining the search operator - the LLM -\nthrough reinforcement learning (RL) fine-tuning. Our method leverages\nevolutionary search as an exploration strategy to discover improved algorithms,\nwhile RL optimizes the LLM policy based on these discoveries. Our experiments\non three combinatorial optimization tasks - bin packing, traveling salesman,\nand the flatpack problem - show that combining RL and evolutionary search\nimproves discovery efficiency of improved algorithms, showcasing the potential\nof RL-enhanced evolutionary strategies to assist computer scientists and\nmathematicians for more efficient algorithm design.",
      "tldr_zh": "该论文探讨了利用大型语言模型 (LLMs) 发现高效算法的挑战，提出了一种结合进化搜索和强化学习 (RL) 的新方法，以解决现有方法中 LLMs 被静态使用的局限性。研究通过 RL 微调来持续优化 LLMs 的搜索操作器，同时利用进化搜索作为探索策略，针对 bin packing、traveling salesman 和 flatpack problem 等组合优化任务进行算法发现。实验结果显示，这种整合方法显著提高了算法发现效率，为计算机科学家和数学家提供更有效的算法设计工具。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05108v3",
      "published_date": "2025-04-07 14:14:15 UTC",
      "updated_date": "2025-04-12 17:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:27:38.697563"
    },
    {
      "arxiv_id": "2504.05106v1",
      "title": "SpeakEasy: Enhancing Text-to-Speech Interactions for Expressive Content Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Brade",
        "Sam Anderson",
        "Rithesh Kumar",
        "Zeyu Jin",
        "Anh Truong"
      ],
      "abstract": "Novice content creators often invest significant time recording expressive\nspeech for social media videos. While recent advancements in text-to-speech\n(TTS) technology can generate highly realistic speech in various languages and\naccents, many struggle with unintuitive or overly granular TTS interfaces. We\npropose simplifying TTS generation by allowing users to specify high-level\ncontext alongside their script. Our Wizard-of-Oz system, SpeakEasy, leverages\nuser-provided context to inform and influence TTS output, enabling iterative\nrefinement with high-level feedback. This approach was informed by two\n8-subject formative studies: one examining content creators' experiences with\nTTS, and the other drawing on effective strategies from voice actors. Our\nevaluation shows that participants using SpeakEasy were more successful in\ngenerating performances matching their personal standards, without requiring\nsignificantly more effort than leading industry interfaces.",
      "tldr_zh": "本研究针对新手内容创建者在社交媒体视频中录制表达性语音耗时长且TTS（Text-to-Speech）接口不直观的问题，提出SpeakEasy系统。该系统允许用户通过提供高层上下文来指导TTS输出，支持迭代优化，并基于两个8受试者的形成性研究（一个考察内容创建者对TTS的体验，另一个借鉴语音演员策略）进行设计。评估结果显示，使用SpeakEasy的用户能更成功地生成符合个人标准的语音表演，且所需努力不高于行业领先接口。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05106v1",
      "published_date": "2025-04-07 14:13:49 UTC",
      "updated_date": "2025-04-07 14:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:27:51.601163"
    },
    {
      "arxiv_id": "2505.09619v3",
      "title": "Machine Learning Solutions Integrated in an IoT Healthcare Platform for Heart Failure Risk Stratification",
      "title_zh": "集成于物联网医疗平台的机器学习解决方案，用于心力衰竭风险分层",
      "authors": [
        "Pietro Cassieri",
        "Aiman Faiz",
        "Anna Maria De Roberto",
        "Claudio Pascarelli",
        "Gianvito Mitrano",
        "Gianluca Fimiani",
        "Marina Garofano",
        "Genoveffa Tortora",
        "Mariangela Lazoi",
        "Claudio Passino",
        "Alessia Bramanti",
        "Giuseppe Scanniello"
      ],
      "abstract": "The management of chronic Heart Failure (HF) presents significant challenges\nin modern healthcare, requiring continuous monitoring, early detection of\nexacerbations, and personalized treatment strategies. In this paper, we present\na predictive model founded on Machine Learning (ML) techniques to identify\npatients at HF risk. This model is an ensemble learning approach, a modified\nstacking technique, that uses two specialized models leveraging clinical and\nechocardiographic features and then a meta-model to combine the predictions of\nthese two models. We initially assess the model on a real dataset and the\nobtained results suggest that it performs well in the stratification of\npatients at HR risk. Specifically, we obtained high sensitivity (95\\%),\nensuring that nearly all high-risk patients are identified. As for accuracy, we\nobtained 84\\%, which can be considered moderate in some ML contexts. However,\nit is acceptable given our priority of identifying patients at risk of HF\nbecause they will be asked to participate in the telemonitoring program of the\nPrediHealth research project on which some of the authors of this paper are\nworking. The initial findings also suggest that ML-based risk stratification\nmodels can serve as valuable decision-support tools not only in the PrediHealth\nproject but also for healthcare professionals, aiding in early intervention and\npersonalized patient management. To have a better understanding of the value\nand of potentiality of our predictive model, we also contrasted its results\nwith those obtained by using three baseline models. The preliminary results\nindicate that our predictive model outperforms these baselines that flatly\nconsider features, \\ie not grouping them in clinical and echocardiographic\nfeatures.",
      "tldr_zh": "本文提出了一种基于 Machine Learning 的预测模型，整合到 IoT 医疗平台中，用于心力衰竭（HF）风险分层。该模型采用修改的堆叠技术（ensemble learning），结合两个专门模型（分别处理临床和超声心动图特征）及一个元模型来融合预测结果。在真实数据集上的评估显示，该模型具有高敏感性（95%）和适中准确率（84%），并优于基线模型，可作为决策支持工具，促进早期干预和个性化患者管理。",
      "categories": [
        "stat.OT",
        "cs.AI"
      ],
      "primary_category": "stat.OT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09619v3",
      "published_date": "2025-04-07 14:07:05 UTC",
      "updated_date": "2025-05-22 13:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:28:03.250423"
    },
    {
      "arxiv_id": "2504.08791v1",
      "title": "PRIMA.CPP: Speeding Up 70B-Scale LLM Inference on Low-Resource Everyday Home Clusters",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghang Li",
        "Tao Li",
        "Wenjiao Feng",
        "Mohsen Guizani",
        "Hongfang Yu"
      ],
      "abstract": "Emergency of DeepSeek R1 and QwQ 32B have broken through performance barriers\nfor running frontier large language models (LLMs) on home devices. While\nconsumer hardware is getting stronger and model quantization is improving,\nexisting end-side solutions still demand GPU clusters, large RAM/VRAM, and high\nbandwidth, far beyond what a common home cluster can handle. This paper\nintroduces prima.cpp, a distributed inference system that runs 70B-scale models\non everyday home devices using a mix of CPU/GPU, low RAM/VRAM, Wi-Fi, and\ncross-platform support. It uses mmap to manage model weights and introduces\npiped-ring parallelism with prefetching to hide disk loading. By modeling\nheterogeneity in computation, communication, disk, memory (and its management\nbehavior), and OS, it optimally assigns model layers to each device's CPU and\nGPU, further reducing token latency. An elegant algorithm named Halda is\nproposed to solve this NP-hard assignment problem. We evaluate prima.cpp on a\ncommon four-node home cluster. It outperforms llama.cpp, exo, and dllama on\n30B+ models while keeping memory pressure below 6%. This brings frontier\n30B-70B models, such as Llama 3, DeepSeek R1, Qwen 2.5, and QwQ to home\nassistants, making advanced AI truly accessible to individuals. The code is\nopen source and available at https://github.com/Lizonghang/prima.cpp.",
      "tldr_zh": "该论文介绍了 PRIMA.CPP，一种分布式推理系统，旨在在低资源家用设备（如使用 CPU/GPU、低 RAM/VRAM 和 Wi-Fi 的集群）上加速 70B 规模的 LLM 推理。系统通过 mmap 管理模型权重，并引入 piped-ring parallelism with prefetching 来隐藏磁盘加载延迟，同时利用 Halda 算法优化计算、通信和内存异质性，以最优方式分配模型层。实验结果显示，PRIMA.CPP 在四节点家用集群上优于 llama.cpp、exo 和 dllama 等基线，在 30B+ 模型上保持内存压力低于 6%，从而使先进 LLM 如 Llama 3、DeepSeek R1 和 Qwen 2.5 更易于个人设备使用。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "68T50",
        "I.2.7; I.2.11"
      ],
      "primary_category": "cs.DC",
      "comment": "23 pages, 9 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.08791v1",
      "published_date": "2025-04-07 13:46:21 UTC",
      "updated_date": "2025-04-07 13:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:28:16.312263"
    },
    {
      "arxiv_id": "2504.10498v3",
      "title": "CCSK:Cognitive Convection of Self-Knowledge Based Retrieval Augmentation for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianling Lu",
        "Mingqi Lv",
        "Tieming Chen"
      ],
      "abstract": "The performance of large language models (LLMs) in Q&A task increased\nsubstantially through Retrieval-Augmented Generation (RAG) which brings in\nexternal knowledge. However, the main difficulty lies in balancing the inherent\nself-knowledge of LLMs with external information retrieval (IR). The current\nthreshold-based methods apply one-dimensional static mechanisms with single\ncriterion. As a result, their IR decisions might be irrelevant to the LLMs'\nresponse under difficult queries. To alleviate this problem, we propose\nCognitive Convection of Self-Knowledge (CCSK). Different from traditional\nmethods that maintain single fixed IR activation criteria, CCSK implements a\ndynamic joint decision process via a Siamese Network module and a Response\nQuality Model. The Siamese Network calculates the cosine similarity between the\ncurrent query and the historical queries. The Response Quality Model evaluates\nthe responses of LLMs through LightGBM. The final decision of the CCSK is\nderived from the outputs of the two modules, as well as text features fused\nusing a multi-head attention mechanism. Extensive experiments on real-world\ndatasets show that CCSK significantly enhances the model's effectiveness in\ninformation retrieval.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在问答任务中通过 Retrieval-Augmented Generation (RAG) 提升性能的问题，提出 Cognitive Convection of Self-Knowledge (CCSK) 框架，以动态平衡 LLMs 的 inherent self-knowledge 和 external information retrieval (IR)。CCSK 采用 Siamese Network 计算当前查询与历史查询的 cosine similarity，以及 Response Quality Model 通过 LightGBM 评估响应质量，并融合多头注意力机制的文本特征进行联合决策。相较于传统的 threshold-based 方法，CCSK 显著提高了 IR 决策的相关性。实验在真实数据集上证明，该框架有效提升了模型的信息检索性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "All authors of this paper have unanimously decided to withdraw its\n  preprint from arXiv. As one of the authors, I cannot unilaterally decide its\n  retention. In accordance with the collective decision, we formally request\n  the complete deletion of the paper from arXiv",
      "pdf_url": "http://arxiv.org/pdf/2504.10498v3",
      "published_date": "2025-04-07 13:43:53 UTC",
      "updated_date": "2025-05-06 07:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:28:27.906022"
    },
    {
      "arxiv_id": "2504.05050v2",
      "title": "Revealing the Intrinsic Ethical Vulnerability of Aligned Large Language Models",
      "title_zh": "揭示已对齐大语言模型的内在伦理脆弱性",
      "authors": [
        "Jiawei Lian",
        "Jianhong Pan",
        "Lefan Wang",
        "Yi Wang",
        "Shaohui Mei",
        "Lap-Pui Chau"
      ],
      "abstract": "Large language models (LLMs) are foundational explorations to artificial\ngeneral intelligence, yet their alignment with human values via instruction\ntuning and preference learning achieves only superficial compliance. Here, we\ndemonstrate that harmful knowledge embedded during pretraining persists as\nindelible \"dark patterns\" in LLMs' parametric memory, evading alignment\nsafeguards and resurfacing under adversarial inducement at distributional\nshifts. In this study, we first theoretically analyze the intrinsic ethical\nvulnerability of aligned LLMs by proving that current alignment methods yield\nonly local \"safety regions\" in the knowledge manifold. In contrast, pretrained\nknowledge remains globally connected to harmful concepts via high-likelihood\nadversarial trajectories. Building on this theoretical insight, we empirically\nvalidate our findings by employing semantic coherence inducement under\ndistributional shifts--a method that systematically bypasses alignment\nconstraints through optimized adversarial prompts. This combined theoretical\nand empirical approach achieves a 100% attack success rate across 19 out of 23\nstate-of-the-art aligned LLMs, including DeepSeek-R1 and LLaMA-3, revealing\ntheir universal vulnerabilities.",
      "tldr_zh": "该研究揭示了经过对齐的大语言模型 (LLMs) 的内在伦理脆弱性，即预训练期间嵌入的有害知识作为“dark patterns”存在于模型参数记忆中，并能通过对抗诱导在分布偏移下重新出现。作者首先通过理论分析证明，当前的对齐方法（如指令微调和偏好学习）仅在知识流形中创建局部“safety regions”，而有害概念仍通过高概率对抗轨迹与预训练知识全局连接。接着，通过语义连贯诱导和优化的对抗提示进行实证验证，在 23 个最先进对齐 LLMs 中实现了 19 个的 100% 攻击成功率，包括 DeepSeek-R1 和 LLaMA-3，这暴露了这些模型的普遍脆弱性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05050v2",
      "published_date": "2025-04-07 13:20:17 UTC",
      "updated_date": "2025-04-18 02:10:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:28:40.130153"
    },
    {
      "arxiv_id": "2504.05047v2",
      "title": "Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Sugyeong Eo",
        "Hyeonseok Moon",
        "Evelyn Hayoon Zi",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "Multiagent collaboration has emerged as a promising framework for enhancing\nthe reasoning capabilities of large language models (LLMs). Despite\nimprovements in reasoning, the approach introduces substantial computational\noverhead resulting from iterative agent interactions. Furthermore, engaging in\nunnecessary debates increases the risk of generating erroneous responses. To\naddress these challenges, we propose Debate Only When Necessary (DOWN), an\nadaptive multiagent debate framework that selectively activates debate based on\nthe confidence score of the agent's initial response. Debate is activated only\nfor queries requiring further deliberation, during which agents refine their\noutputs by referencing peer responses and associated confidence scores.\nEvaluations on benchmarks show that DOWN improves efficiency by up to six times\nwhile preserving or even outperforming the performance of existing methods.\nFurther analysis indicates that DOWN effectively mitigates the risk of error\npropagation stemming from the unnecessary debate process. These findings\ndemonstrate the effectiveness of our approach in delivering high-performance\nLLM solutions at a lower computational cost.",
      "tldr_zh": "该研究提出了一种名为“Debate Only When Necessary (DOWN)”的自适应多智能体协作框架，旨在提升大型语言模型 (LLMs) 的推理能力，同时减少不必要的辩论带来的计算开销和错误风险。框架通过代理初始响应的置信度分数来选择性地激活辩论，仅对需要进一步审议的查询进行处理，代理们在辩论中参考同行响应和置信度以改进输出。在基准测试中，DOWN 提高了效率最多六倍，同时保持或超越现有方法的性能，并有效缓解了错误传播问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05047v2",
      "published_date": "2025-04-07 13:17:52 UTC",
      "updated_date": "2025-05-20 12:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:28:51.422820"
    },
    {
      "arxiv_id": "2504.05029v1",
      "title": "Graph-based Diffusion Model for Collaborative Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Zhang",
        "Xiang Deng",
        "Hongxing Yuan",
        "Chunyu Wei",
        "Yushun Fan"
      ],
      "abstract": "Recently, diffusion-based recommendation methods have achieved impressive\nresults. However, existing approaches predominantly treat each user's\nhistorical interactions as independent training samples, overlooking the\npotential of higher-order collaborative signals between users and items. Such\nsignals, which encapsulate richer and more nuanced relationships, can be\nnaturally captured using graph-based data structures. To address this\nlimitation, we extend diffusion-based recommendation methods to the graph\ndomain by directly modeling user-item bipartite graphs with diffusion models.\nThis enables better modeling of the higher-order connectivity inherent in\ncomplex interaction dynamics. However, this extension introduces two primary\nchallenges: (1) Noise Heterogeneity, where interactions are influenced by\nvarious forms of continuous and discrete noise, and (2) Relation Explosion,\nreferring to the high computational costs of processing large-scale graphs. To\ntackle these challenges, we propose a Graph-based Diffusion Model for\nCollaborative Filtering (GDMCF). To address noise heterogeneity, we introduce a\nmulti-level noise corruption mechanism that integrates both continuous and\ndiscrete noise, effectively simulating real-world interaction complexities. To\nmitigate relation explosion, we design a user-active guided diffusion process\nthat selectively focuses on the most meaningful edges and active users,\nreducing inference costs while preserving the graph's topological integrity.\nExtensive experiments on three benchmark datasets demonstrate that GDMCF\nconsistently outperforms state-of-the-art methods, highlighting its\neffectiveness in capturing higher-order collaborative signals and improving\nrecommendation performance.",
      "tldr_zh": "本文提出 Graph-based Diffusion Model for Collaborative Filtering (GDMCF)，通过在用户-物品二分图上应用扩散模型来捕捉高阶协作信号，从而提升推荐系统的性能。针对 Noise Heterogeneity 和 Relation Explosion 的挑战，GDMCF 引入多级噪声污染机制整合连续和离散噪声，并设计用户活跃引导扩散过程以减少计算成本并保留图拓扑完整性。实验在三个基准数据集上显示，GDMCF 优于最先进方法，显著提高了推荐准确性和整体效果。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05029v1",
      "published_date": "2025-04-07 12:51:18 UTC",
      "updated_date": "2025-04-07 12:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:29:03.214412"
    },
    {
      "arxiv_id": "2504.05020v1",
      "title": "Batch Aggregation: An Approach to Enhance Text Classification with Correlated Augmented Data",
      "title_zh": "批量聚合：一种利用相关增强数据提升文本分类的方法",
      "authors": [
        "Charco Hui",
        "Yalu Wen"
      ],
      "abstract": "Natural language processing models often face challenges due to limited\nlabeled data, especially in domain specific areas, e.g., clinical trials. To\novercome this, text augmentation techniques are commonly used to increases\nsample size by transforming the original input data into artificial ones with\nthe label preserved. However, traditional text classification methods ignores\nthe relationship between augmented texts and treats them as independent samples\nwhich may introduce classification error. Therefore, we propose a novel\napproach called 'Batch Aggregation' (BAGG) which explicitly models the\ndependence of text inputs generated through augmentation by incorporating an\nadditional layer that aggregates results from correlated texts. Through\nstudying multiple benchmark data sets across different domains, we found that\nBAGG can improve classification accuracy. We also found that the increase of\nperformance with BAGG is more obvious in domain specific data sets, with\naccuracy improvements of up to 10-29%. Through the analysis of benchmark data,\nthe proposed method addresses limitations of traditional techniques and\nimproves robustness in text classification tasks. Our result demonstrates that\nBAGG offers more robust results and outperforms traditional approaches when\ntraining data is limited.",
      "tldr_zh": "本论文针对自然语言处理中数据标注不足的问题，提出了一种名为 Batch Aggregation (BAGG) 的新方法，用于处理文本增强数据间的相关性。BAGG 通过添加一个聚合层，显式建模增强文本的依赖关系，从而提高分类准确率。实验在多个基准数据集上显示，该方法在特定领域数据上表现尤为突出，准确率提升可达10-29%，并增强了文本分类任务的鲁棒性，尤其适用于训练数据有限的场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05020v1",
      "published_date": "2025-04-07 12:46:07 UTC",
      "updated_date": "2025-04-07 12:46:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:29:14.369535"
    },
    {
      "arxiv_id": "2504.05007v1",
      "title": "Measuring the right thing: justifying metrics in AI impact assessments",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Buijsman",
        "Herman Veluwenkamp"
      ],
      "abstract": "AI Impact Assessments are only as good as the measures used to assess the\nimpact of these systems. It is therefore paramount that we can justify our\nchoice of metrics in these assessments, especially for difficult to quantify\nethical and social values. We present a two-step approach to ensure metrics are\nproperly motivated. First, a conception needs to be spelled out (e.g. Rawlsian\nfairness or fairness as solidarity) and then a metric can be fitted to that\nconception. Both steps require separate justifications, as conceptions can be\njudged on how well they fit with the function of, for example, fairness. We\nargue that conceptual engineering offers helpful tools for this step. Second,\nmetrics need to be fitted to a conception. We illustrate this process through\nan examination of competing fairness metrics to illustrate that here the\nadditional content that a conception offers helps us justify the choice for a\nspecific metric. We thus advocate that impact assessments are not only clear on\ntheir metrics, but also on the conceptions that motivate those metrics.",
      "tldr_zh": "这篇论文强调，在AI影响评估中，选择正确的指标至关重要，尤其是针对难以量化的伦理和社会价值。作者提出一个两步方法：首先，阐述一个概念（如Rawlsian fairness或fairness as solidarity），并使用conceptual engineering工具为其提供理由；其次，将指标拟合到该概念，并通过竞争的公平性指标示例说明这一过程。最终，论文主张影响评估不仅需明确指标，还需透明地说明这些指标背后的概念，以确保评估的正当性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for publication in Global Perspectives on AI Impact\n  Assessment (Oxford University Press, forthcoming). Pre-publication version;\n  final version will be available from the publisher",
      "pdf_url": "http://arxiv.org/pdf/2504.05007v1",
      "published_date": "2025-04-07 12:32:41 UTC",
      "updated_date": "2025-04-07 12:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:29:27.255452"
    },
    {
      "arxiv_id": "2504.07990v1",
      "title": "Comparative analysis of Realistic EMF Exposure Estimation from Low Density Sensor Network by Finite & Infinite Neural Networks",
      "title_zh": "有限和无限神经网络对低密度传感器网络中真实 EMF 暴露估计的比较分析",
      "authors": [
        "Mohammed Mallik",
        "Laurent Clavier",
        "Davy P. Gaillot"
      ],
      "abstract": "Understanding the spatial and temporal patterns of environmental exposure to\nradio-frequency electromagnetic fields (RF-EMF) is essential for conducting\nrisk assessments. These assessments aim to explore potential connections\nbetween RF-EMF exposure and its effects on human health, as well as on wildlife\nand plant life. Existing research has used different machine learning tools for\nEMF exposure estimation; however, a comparative analysis of these techniques is\nrequired to better understand their performance for real-world datasets. In\nthis work, we present both finite and infinite-width convolutional\nnetwork-based methods to estimate and assess EMF exposure levels from 70\nreal-world sensors in Lille, France. A comparative analysis has been conducted\nto analyze the performance of the methods' execution time and estimation\naccuracy. To improve estimation accuracy for higher-resolution grids, we\nutilized a preconditioned gradient descent method for kernel estimation. Root\nMean Square Error (RMSE) is used as the evaluation criterion for comparing the\nperformance of these deep learning models.",
      "tldr_zh": "本研究对使用有限和无限神经网络从低密度传感器网络估计现实 RF-EMF 暴露水平进行了比较分析，旨在评估这些方法在真实数据集中的性能，以支持 RF-EMF 对人类健康、野生动物和植物的影响风险评估。研究基于法国 Lille 的 70 个传感器数据，采用了卷积网络方法，并引入预处理梯度下降来提升高分辨率网格的估计准确性。结果显示，通过比较执行时间和估计准确性，以 RMSE 作为评估标准，这些模型在精确性上表现出显著潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07990v1",
      "published_date": "2025-04-07 12:31:53 UTC",
      "updated_date": "2025-04-07 12:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:29:40.137167"
    },
    {
      "arxiv_id": "2504.04997v1",
      "title": "SurvSurf: a partially monotonic neural network for first-hitting time prediction of intermittently observed discrete and continuous sequential events",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Kelly Chen",
        "Sören Dittmer",
        "Kinga Bernatowicz",
        "Josep Arús-Pous",
        "Kamen Bliznashki",
        "John Aston",
        "James H. F. Rudd",
        "Carola-Bibiane Schönlieb",
        "James Jones",
        "Michael Roberts"
      ],
      "abstract": "We propose a neural-network based survival model (SurvSurf) specifically\ndesigned for direct and simultaneous probabilistic prediction of the first\nhitting time of sequential events from baseline. Unlike existing models,\nSurvSurf is theoretically guaranteed to never violate the monotonic\nrelationship between the cumulative incidence functions of sequential events,\nwhile allowing nonlinear influence from predictors. It also incorporates\nimplicit truths for unobserved intermediate events in model fitting, and\nsupports both discrete and continuous time and events. We also identified a\nvariant of the Integrated Brier Score (IBS) that showed robust correlation with\nthe mean squared error (MSE) between the true and predicted probabilities by\naccounting for implied truths about the missing intermediate events. We\ndemonstrated the superiority of SurvSurf compared to modern and traditional\npredictive survival models in two simulated datasets and two real-world\ndatasets, using MSE, the more robust IBS and by measuring the extent of\nmonotonicity violation.",
      "tldr_zh": "本研究提出SurvSurf，一种部分单调的神经网络生存模型，用于直接预测间歇观察的离散和连续序列事件的首次命中时间（first-hitting time），并确保序列事件累积发生函数（cumulative incidence functions）之间的单调关系，同时支持非线性预测变量和未观察中间事件的隐含事实。不同于现有模型，SurvSurf在模型拟合中纳入了Integrated Brier Score (IBS)的变体，该变体与mean squared error (MSE)相关联，更好地处理缺失事件。实验结果显示，SurvSurf在两个模拟数据集和两个真实数据集上优于现代和传统生存模型，在MSE、IBS以及单调性违反程度方面表现出色。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.AP",
        "stat.TH",
        "62N01"
      ],
      "primary_category": "stat.ML",
      "comment": "41 pages, 18 figures (including supplemental information). Submitted\n  to RSS: Data Science and Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2504.04997v1",
      "published_date": "2025-04-07 12:24:59 UTC",
      "updated_date": "2025-04-07 12:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:29:51.529717"
    },
    {
      "arxiv_id": "2504.04994v2",
      "title": "Following the Whispers of Values: Unraveling Neural Mechanisms Behind Value-Oriented Behaviors in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Hu",
        "Yuemei Xu",
        "Xiaoyang Gu",
        "Letao Han"
      ],
      "abstract": "Despite the impressive performance of large language models (LLMs), they can\npresent unintended biases and harmful behaviors driven by encoded values,\nemphasizing the urgent need to understand the value mechanisms behind them.\nHowever, current research primarily evaluates these values through external\nresponses with a focus on AI safety, lacking interpretability and failing to\nassess social values in real-world contexts. In this paper, we propose a novel\nframework called ValueExploration, which aims to explore the behavior-driven\nmechanisms of National Social Values within LLMs at the neuron level. As a case\nstudy, we focus on Chinese Social Values and first construct C-voice, a\nlarge-scale bilingual benchmark for identifying and evaluating Chinese Social\nValues in LLMs. By leveraging C-voice, we then identify and locate the neurons\nresponsible for encoding these values according to activation difference.\nFinally, by deactivating these neurons, we analyze shifts in model behavior,\nuncovering the internal mechanism by which values influence LLM\ndecision-making. Extensive experiments on four representative LLMs validate the\nefficacy of our framework. The benchmark and code will be available.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)中编码的值导致的偏差和有害行为，提出了一种新框架ValueExploration，用于在神经元级别揭示国家社会值的行为驱动机制。以中国社会值为案例，该框架首先构建了大规模双语基准C-voice，用于识别和评估中国社会值。接着，通过激活差异方法定位编码这些值的神经元，并通过关闭这些神经元分析模型行为的改变，从而揭示值如何影响LLMs的决策决策。在四个代表性LLMs上的广泛实验验证了框架的有效性，并提供了基准和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04994v2",
      "published_date": "2025-04-07 12:23:59 UTC",
      "updated_date": "2025-04-20 13:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:30:03.806375"
    },
    {
      "arxiv_id": "2504.04988v1",
      "title": "RS-RAG: Bridging Remote Sensing Imagery and Comprehensive Knowledge with a Multi-Modal Dataset and Retrieval-Augmented Generation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Congcong Wen",
        "Yiting Lin",
        "Xiaokang Qu",
        "Nan Li",
        "Yong Liao",
        "Hui Lin",
        "Xiang Li"
      ],
      "abstract": "Recent progress in VLMs has demonstrated impressive capabilities across a\nvariety of tasks in the natural image domain. Motivated by these advancements,\nthe remote sensing community has begun to adopt VLMs for remote sensing\nvision-language tasks, including scene understanding, image captioning, and\nvisual question answering. However, existing remote sensing VLMs typically rely\non closed-set scene understanding and focus on generic scene descriptions, yet\nlack the ability to incorporate external knowledge. This limitation hinders\ntheir capacity for semantic reasoning over complex or context-dependent queries\nthat involve domain-specific or world knowledge. To address these challenges,\nwe first introduced a multimodal Remote Sensing World Knowledge (RSWK) dataset,\nwhich comprises high-resolution satellite imagery and detailed textual\ndescriptions for 14,141 well-known landmarks from 175 countries, integrating\nboth remote sensing domain knowledge and broader world knowledge. Building upon\nthis dataset, we proposed a novel Remote Sensing Retrieval-Augmented Generation\n(RS-RAG) framework, which consists of two key components. The Multi-Modal\nKnowledge Vector Database Construction module encodes remote sensing imagery\nand associated textual knowledge into a unified vector space. The Knowledge\nRetrieval and Response Generation module retrieves and re-ranks relevant\nknowledge based on image and/or text queries, and incorporates the retrieved\ncontent into a knowledge-augmented prompt to guide the VLM in producing\ncontextually grounded responses. We validated the effectiveness of our approach\non three representative vision-language tasks, including image captioning,\nimage classification, and visual question answering, where RS-RAG significantly\noutperformed state-of-the-art baselines.",
      "tldr_zh": "该研究针对遥感领域的视觉语言模型（VLMs）在处理复杂查询时缺乏外部知识整合的问题，引入了一个多模态数据集RSWK，包含14,141个地标的卫星图像和文本描述，覆盖175个国家，融合了遥感领域知识和更广泛的世界知识。基于此，论文提出了一种新型框架RS-RAG，包括Multi-Modal Knowledge Vector Database Construction模块（将图像和文本编码到统一向量空间）和Knowledge Retrieval and Response Generation模块（通过检索和重新排序相关知识，增强提示以指导VLM生成响应）。RS-RAG在图像描述、图像分类和视觉问答等任务上显著优于现有基线模型，证明了其在提升语义推理能力方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04988v1",
      "published_date": "2025-04-07 12:13:43 UTC",
      "updated_date": "2025-04-07 12:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:30:14.925174"
    },
    {
      "arxiv_id": "2504.05365v1",
      "title": "A Nature-Inspired Colony of Artificial Intelligence System with Fast, Detailed, and Organized Learner Agents for Enhancing Diversity and Quality",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Suthaharan"
      ],
      "abstract": "The concepts of convolutional neural networks (CNNs) and multi-agent systems\nare two important areas of research in artificial intelligence (AI). In this\npaper, we present an approach that builds a CNN-based colony of AI agents to\nserve as a single system and perform multiple tasks (e.g., predictions or\nclassifications) in an environment. The proposed system impersonates the\nnatural environment of a biological system, like an ant colony or a human\ncolony. The proposed colony of AI that is defined as a role-based system\nuniquely contributes to accomplish tasks in an environment by incorporating AI\nagents that are fast learners, detailed learners, and organized learners. These\nlearners can enhance their localized learning and their collective decisions as\na single system of colony of AI agents. This approach also enhances the\ndiversity and quality of the colony of AI with the help of Genetic Algorithms\nand their crossover and mutation mechanisms. The evolution of fast, detailed,\nand organized learners in the colony of AI is achieved by introducing a unique\none-to-one mapping between these learners and the pretrained VGG16, VGG19, and\nResNet50 models, respectively. This role-based approach creates two parent-AI\nagents using the AI models through the processes, called the intra- and\ninter-marriage of AI, so that they can share their learned knowledge (weights\nand biases) based on a probabilistic rule and produce diversified child-AI\nagents to perform new tasks. This process will form a colony of AI that\nconsists of families of multi-model and mixture-model AI agents to improve\ndiversity and quality. Simulations show that the colony of AI, built using the\nVGG16, VGG19, and ResNet50 models, can provide a single system that generates\nchild-AI agents of excellent predictive performance, ranging between 82% and\n95% of F1-scores, to make diversified collective and quality decisions on a\ntask.",
      "tldr_zh": "该研究提出了一种受自然启发（如蚁群或人类群落）的 AI 系统，构建基于 CNN 的多智能体殖民地，包括快速学习者、详细学习者和组织学习者代理，以提升系统的多样性和质量。系统利用 Genetic Algorithms 的交叉和变异机制，通过“intra- and inter-marriage of AI”过程让代理（如映射到 VGG16、VGG19 和 ResNet50 模型）分享知识（权重和偏差），生成多样化的子代理。模拟实验显示，该系统在预测任务上表现出色，F1-scores 范围为 82% 到 95%，从而实现高质量的集体决策。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.NE",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05365v1",
      "published_date": "2025-04-07 12:13:14 UTC",
      "updated_date": "2025-04-07 12:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:30:26.860711"
    },
    {
      "arxiv_id": "2504.04982v2",
      "title": "Transforming Future Data Center Operations and Management via Physical AI",
      "title_zh": "通过 Physical AI 转变未来数据中心运营与管理",
      "authors": [
        "Zhiwei Cao",
        "Minghao Li",
        "Feng Lin",
        "Jimin Jia",
        "Yonggang Wen",
        "Jianxiong Yin",
        "Simon See"
      ],
      "abstract": "Data centers (DCs) as mission-critical infrastructures are pivotal in\npowering the growth of artificial intelligence (AI) and the digital economy.\nThe evolution from Internet DC to AI DC has introduced new challenges in\noperating and managing data centers for improved business resilience and\nreduced total cost of ownership. As a result, new paradigms, beyond the\ntraditional approaches based on best practices, must be in order for future\ndata centers. In this research, we propose and develop a novel Physical AI\n(PhyAI) framework for advancing DC operations and management. Our system\nleverages the emerging capabilities of state-of-the-art industrial products and\nour in-house research and development. Specifically, it presents three core\nmodules, namely: 1) an industry-grade in-house simulation engine to simulate DC\noperations in a highly accurate manner, 2) an AI engine built upon NVIDIA\nPhysicsNemo for the training and evaluation of physics-informed machine\nlearning (PIML) models, and 3) a digital twin platform built upon NVIDIA\nOmniverse for our proposed 5-tier digital twin framework. This system presents\na scalable and adaptable solution to digitalize, optimize, and automate future\ndata center operations and management, by enabling real-time digital twins for\nfuture data centers. To illustrate its effectiveness, we present a compelling\ncase study on building a surrogate model for predicting the thermal and airflow\nprofiles of a large-scale DC in a real-time manner. Our results demonstrate its\nsuperior performance over traditional time-consuming Computational Fluid\nDynamics/Heat Transfer (CFD/HT) simulation, with a median absolute temperature\nprediction error of 0.18 {\\deg}C. This emerging approach would open doors to\nseveral potential research directions for advancing Physical AI in future DC\noperations.",
      "tldr_zh": "本研究探讨了数据中心（DCs）从互联网DC向AI DC演变的挑战，包括提升业务韧性和降低总拥有成本，并提出Physical AI (PhyAI)框架来革新DC操作和管理。该框架包括三个核心模块：1) 行业级模拟引擎，用于精确模拟DC操作；2) 基于NVIDIA PhysicsNemo的AI引擎，用于训练和评估physics-informed machine learning (PIML)模型；以及3) 基于NVIDIA Omniverse的数字孪生平台，支持5-tier数字孪生框架，以实现实时优化和自动化。实验案例展示了PhyAI构建的代理模型，能实时预测大型DC的热力和气流分布，其性能优于传统的Computational Fluid Dynamics/Heat Transfer (CFD/HT)模拟，中位绝对温度预测误差仅为0.18 °C。这一方法为未来DC操作的Physical AI研究开辟了新方向。",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04982v2",
      "published_date": "2025-04-07 12:09:22 UTC",
      "updated_date": "2025-04-15 15:06:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:30:40.098543"
    },
    {
      "arxiv_id": "2504.04981v1",
      "title": "DiCoTTA: Domain-invariant Learning for Continual Test-time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Sohyun Lee",
        "Nayeong Kim",
        "Juwon Kang",
        "Seong Joon Oh",
        "Suha Kwak"
      ],
      "abstract": "This paper studies continual test-time adaptation (CTTA), the task of\nadapting a model to constantly changing unseen domains in testing while\npreserving previously learned knowledge. Existing CTTA methods mostly focus on\nadaptation to the current test domain only, overlooking generalization to\narbitrary test domains a model may face in the future. To tackle this\nlimitation, we present a novel online domain-invariant learning framework for\nCTTA, dubbed DiCoTTA. DiCoTTA aims to learn feature representation to be\ninvariant to both current and previous test domains on the fly during testing.\nTo this end, we propose a new model architecture and a test-time adaptation\nstrategy dedicated to learning domain-invariant features without corrupting\nsemantic contents, along with a new data structure and optimization algorithm\nfor effectively managing information from previous test domains. DiCoTTA\nachieved state-of-the-art performance on four public CTTA benchmarks. Moreover,\nit showed superior generalization to unseen test domains.",
      "tldr_zh": "本论文研究了持续测试时适应(CTTA)，即在测试阶段适应不断变化的未见域，同时保留先前学到的知识。针对现有方法仅关注当前测试域而忽略未来域泛化的局限，作者提出了DiCoTTA框架，一种在线域不变学习方法，通过新模型架构、测试时适应策略以及用于管理先前域信息的新数据结构和优化算法，实现对当前和先前测试域的特征表示不变。实验结果显示，DiCoTTA在四个公共CTTA基准上达到了state-of-the-art性能，并展示了在未见测试域上的优越泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04981v1",
      "published_date": "2025-04-07 12:09:18 UTC",
      "updated_date": "2025-04-07 12:09:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:30:51.088447"
    },
    {
      "arxiv_id": "2504.04974v1",
      "title": "Towards Visual Text Grounding of Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Ruiyi Zhang",
        "Jian Chen",
        "Jiuxiang Gu",
        "Yufan Zhou",
        "Franck Dernoncourt",
        "Wanrong Zhu",
        "Tianyi Zhou",
        "Tong Sun"
      ],
      "abstract": "Despite the existing evolution of Multimodal Large Language Models (MLLMs), a\nnon-neglectable limitation remains in their struggle with visual text\ngrounding, especially in text-rich images of documents. Document images, such\nas scanned forms and infographics, highlight critical challenges due to their\ncomplex layouts and textual content. However, current benchmarks do not fully\naddress these challenges, as they mostly focus on visual grounding on natural\nimages, rather than text-rich document images. Thus, to bridge this gap, we\nintroduce TRIG, a novel task with a newly designed instruction dataset for\nbenchmarking and improving the Text-Rich Image Grounding capabilities of MLLMs\nin document question-answering. Specifically, we propose an OCR-LLM-human\ninteraction pipeline to create 800 manually annotated question-answer pairs as\na benchmark and a large-scale training set of 90$ synthetic data based on four\ndiverse datasets. A comprehensive evaluation of various MLLMs on our proposed\nbenchmark exposes substantial limitations in their grounding capability on\ntext-rich images. In addition, we propose two simple and effective TRIG methods\nbased on general instruction tuning and plug-and-play efficient embedding,\nrespectively. By finetuning MLLMs on our synthetic dataset, they promisingly\nimprove spatial reasoning and grounding capabilities.",
      "tldr_zh": "这篇论文针对Multimodal Large Language Models (MLLMs)在视觉文本定位(visual text grounding)上的局限性，特别是处理文本丰富的文档图像（如扫描表格和信息图）时，提出了TRIG任务和数据集，以基准测试和提升MLLMs的定位能力。研究者设计了一个OCR-LLM-human交互管道，创建了800个手动标注的问答对作为基准，以及基于四个数据集的90k合成数据，用于训练和评估。实验结果显示，现有MLLMs在文本丰富图像上的定位能力存在重大缺陷，但通过提出的两种TRIG方法——基于一般指令微调和即插即用高效嵌入——进行微调后，模型的空间推理和定位能力得到显著改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04974v1",
      "published_date": "2025-04-07 12:01:59 UTC",
      "updated_date": "2025-04-07 12:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:31:04.621189"
    },
    {
      "arxiv_id": "2504.04973v2",
      "title": "Ensuring Safety in an Uncertain Environment: Constrained MDPs via Stochastic Thresholds",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Zuo",
        "Fengxiang He"
      ],
      "abstract": "This paper studies constrained Markov decision processes (CMDPs) with\nconstraints against stochastic thresholds, aiming at the safety of\nreinforcement learning in unknown and uncertain environments. We leverage a\nGrowing-Window estimator sampling from interactions with the uncertain and\ndynamic environment to estimate the thresholds, based on which we design\nStochastic Pessimistic-Optimistic Thresholding (SPOT), a novel model-based\nprimal-dual algorithm for multiple constraints against stochastic thresholds.\nSPOT enables reinforcement learning under both pessimistic and optimistic\nthreshold settings. We prove that our algorithm achieves sublinear regret and\nconstraint violation; i.e., a reward regret of $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nwhile allowing an $\\tilde{\\mathcal{O}}(\\sqrt{T})$ constraint violation over $T$\nepisodes. The theoretical guarantees show that our algorithm achieves\nperformance comparable to that of an approach relying on fixed and clear\nthresholds. To the best of our knowledge, SPOT is the first reinforcement\nlearning algorithm that realises theoretical guaranteed performance in an\nuncertain environment where even thresholds are unknown.",
      "tldr_zh": "本论文研究了在不确定环境中确保安全的 Constrained MDPs，通过 Stochastic Thresholds 处理强化学习的约束问题。作者引入了 Growing-Window estimator 来从环境交互中估计阈值，并设计了 Stochastic Pessimistic-Optimistic Thresholding (SPOT)，一个基于模型的 primal-dual 算法，支持多个约束并适用于 pessimistic 和 optimistic 阈值设置。实验证明，SPOT 算法在 T 轮次内实现了 reward regret 为 \\(\\tilde{\\mathcal{O}}(\\sqrt{T})\\) 和 constraint violation 为 \\(\\tilde{\\mathcal{O}}(\\sqrt{T})\\)，其性能与固定阈值方法相当，是首个在阈值未知的不确定环境中提供理论保证的强化学习算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04973v2",
      "published_date": "2025-04-07 11:58:19 UTC",
      "updated_date": "2025-05-16 14:13:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:31:16.194154"
    },
    {
      "arxiv_id": "2504.04970v1",
      "title": "A High-Force Gripper with Embedded Multimodal Sensing for Powerful and Perception Driven Grasping",
      "title_zh": "翻译失败",
      "authors": [
        "Edoardo Del Bianco",
        "Davide Torielli",
        "Federico Rollo",
        "Damiano Gasperini",
        "Arturo Laurenzi",
        "Lorenzo Baccelliere",
        "Luca Muratore",
        "Marco Roveri",
        "Nikos G. Tsagarakis"
      ],
      "abstract": "Modern humanoid robots have shown their promising potential for executing\nvarious tasks involving the grasping and manipulation of objects using their\nend-effectors. Nevertheless, in the most of the cases, the grasping and\nmanipulation actions involve low to moderate payload and interaction forces.\nThis is due to limitations often presented by the end-effectors, which can not\nmatch their arm-reachable payload, and hence limit the payload that can be\ngrasped and manipulated. In addition, grippers usually do not embed adequate\nperception in their hardware, and grasping actions are mainly driven by\nperception sensors installed in the rest of the robot body, frequently affected\nby occlusions due to the arm motions during the execution of the grasping and\nmanipulation tasks. To address the above, we developed a modular high grasping\nforce gripper equipped with embedded multi-modal perception functionalities.\nThe proposed gripper can generate a grasping force of 110 N in a compact\nimplementation. The high grasping force capability is combined with embedded\nmulti-modal sensing, which includes an eye-in-hand camera, a Time-of-Flight\n(ToF) distance sensor, an Inertial Measurement Unit (IMU) and an\nomnidirectional microphone, permitting the implementation of perception-driven\ngrasping functionalities.\n  We extensively evaluated the grasping force capacity of the gripper by\nintroducing novel payload evaluation metrics that are a function of the robot\narm's dynamic motion and gripper thermal states. We also evaluated the embedded\nmulti-modal sensing by performing perception-guided enhanced grasping\noperations.",
      "tldr_zh": "本研究针对现代人形机器人在抓取和操作物体时存在的抓取力不足和感知受限问题，提出了一种模块化 high-force gripper，具备强大的抓取能力（可产生110 N的抓取力）和嵌入式多模态感知功能，包括 eye-in-hand 相机、Time-of-Flight (ToF) 距离传感器、Inertial Measurement Unit (IMU) 和 omnidirectional 麦克风，以实现感知驱动的抓取操作。研究引入了新的负载评估指标，考虑机器人手臂动态运动和 gripper 热状态，对抓取力进行了全面评估。实验结果显示，该 gripper 在增强抓取任务中表现出色，提升了机器人对物体的可靠操控性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04970v1",
      "published_date": "2025-04-07 11:57:08 UTC",
      "updated_date": "2025-04-07 11:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:31:28.095760"
    },
    {
      "arxiv_id": "2504.04968v1",
      "title": "The Dream Within Huang Long Cave: AI-Driven Interactive Narrative for Family Storytelling and Emotional Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayang Huang",
        "Lingjie Li",
        "Kang Zhang",
        "David Yip"
      ],
      "abstract": "This paper introduces the art project The Dream Within Huang Long Cave, an\nAI-driven interactive and immersive narrative experience. The project offers\nnew insights into AI technology, artistic practice, and psychoanalysis.\nInspired by actual geographical landscapes and familial archetypes, the work\ncombines psychoanalytic theory and computational technology, providing an\nartistic response to the concept of the non-existence of the Big Other. The\nnarrative is driven by a combination of a large language model (LLM) and a\nrealistic digital character, forming a virtual agent named YELL. Through\ndialogue and exploration within a cave automatic virtual environment (CAVE),\nthe audience is invited to unravel the language puzzles presented by YELL and\nhelp him overcome his life challenges. YELL is a fictional embodiment of the\nBig Other, modeled after the artist's real father. Through a cross-temporal\ninteraction with this digital father, the project seeks to deconstruct complex\nfamilial relationships. By demonstrating the non-existence of the Big Other, we\naim to underscore the authenticity of interpersonal emotions, positioning art\nas a bridge for emotional connection and understanding within family dynamics.",
      "tldr_zh": "本论文介绍了艺术项目“The Dream Within Huang Long Cave”，这是一个AI驱动的互动沉浸式叙事体验，旨在通过AI技术、艺术实践和精神分析理论探索家庭故事和情感反思。项目结合大型语言模型(LLM)和数字角色YELL，在CAVE（洞穴自动虚拟环境）中引导观众通过对话和探索解开语言谜题，帮助YELL克服生活挑战，从而解构复杂的家庭关系。最终，该项目强调Big Other（大他者）的不存在，突出人际情感的真实性，并将艺术定位为连接家庭情感的桥梁。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "8 pages,8 figures, International Symposium on Electronic/Emerging Art\n  (ISEA)",
      "pdf_url": "http://arxiv.org/pdf/2504.04968v1",
      "published_date": "2025-04-07 11:54:11 UTC",
      "updated_date": "2025-04-07 11:54:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:31:40.984758"
    },
    {
      "arxiv_id": "2504.05364v1",
      "title": "Of All StrIPEs: Investigating Structure-informed Positional Encoding for Efficient Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Manvi Agarwal",
        "Changhong Wang",
        "Gael Richard"
      ],
      "abstract": "While music remains a challenging domain for generative models like\nTransformers, a two-pronged approach has recently proved successful: inserting\nmusically-relevant structural information into the positional encoding (PE)\nmodule and using kernel approximation techniques based on Random Fourier\nFeatures (RFF) to lower the computational cost from quadratic to linear. Yet,\nit is not clear how such RFF-based efficient PEs compare with those based on\nrotation matrices, such as Rotary Positional Encoding (RoPE). In this paper, we\npresent a unified framework based on kernel methods to analyze both families of\nefficient PEs. We use this framework to develop a novel PE method called\nRoPEPool, capable of extracting causal relationships from temporal sequences.\nUsing RFF-based PEs and rotation-based PEs, we demonstrate how seemingly\ndisparate PEs can be jointly studied by considering the content-context\ninteractions they induce. For empirical validation, we use a symbolic music\ngeneration task, namely, melody harmonization. We show that RoPEPool, combined\nwith highly-informative structural priors, outperforms all methods.",
      "tldr_zh": "这篇论文探讨了在音乐生成领域，使用结构信息增强的定位编码(PE)来提高Transformer模型的效率，特别比较了基于Random Fourier Features (RFF)的PE和基于旋转矩阵的PE，如Rotary Positional Encoding (RoPE)。作者提出一个统一的内核方法框架，用于分析这些PE方法，并开发了新方法RoPEPool，能够从时间序列中提取因果关系。实验在符号音乐生成任务（如旋律和声化）中验证，RoPEPool结合高度信息结构先验，优于所有基线方法。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05364v1",
      "published_date": "2025-04-07 11:51:29 UTC",
      "updated_date": "2025-04-07 11:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:31:53.776243"
    },
    {
      "arxiv_id": "2504.04954v1",
      "title": "GOTHAM: Graph Class Incremental Learning Framework under Weak Supervision",
      "title_zh": "GOTHAM：弱监督下的图类增量学习框架",
      "authors": [
        "Aditya Hemant Shahane",
        "Prathosh A. P",
        "Sandeep Kumar"
      ],
      "abstract": "Graphs are growing rapidly, along with the number of distinct label\ncategories associated with them. Applications like e-commerce, healthcare,\nrecommendation systems, and various social media platforms are rapidly moving\ntowards graph representation of data due to their ability to capture both\nstructural and attribute information. One crucial task in graph analysis is\nnode classification, where unlabeled nodes are categorized into predefined\nclasses. In practice, novel classes appear incrementally sometimes with just a\nfew labels (seen classes) or even without any labels (unseen classes), either\nbecause they are new or haven't been explored much. Traditional methods assume\nabundant labeled data for training, which isn't always feasible. We investigate\na broader objective: \\emph{Graph Class Incremental Learning under Weak\nSupervision (GCL)}, addressing this challenge by meta-training on base classes\nwith limited labeled instances. During the incremental streams, novel classes\ncan have few-shot or zero-shot representation. Our proposed framework GOTHAM\nefficiently accommodates these unlabeled nodes by finding the closest prototype\nrepresentation, serving as class representatives in the attribute space. For\nText-Attributed Graphs (TAGs), our framework additionally incorporates semantic\ninformation to enhance the representation. By employing teacher-student\nknowledge distillation to mitigate forgetting, GOTHAM achieves promising\nresults across various tasks. Experiments on datasets such as Cora-ML, Amazon,\nand OBGN-Arxiv showcase the effectiveness of our approach in handling evolving\ngraph data under limited supervision. The repository is available here:\n\\href{https://github.com/adityashahane10/GOTHAM--Graph-based-Class-Incremental-Learning-Framework-under-Weak-Supervision}{\\small\n\\textcolor{blue}{Code}}",
      "tldr_zh": "该论文针对图数据中新型类别的增量学习问题，提出了 GOTHAM 框架，用于 Graph Class Incremental Learning under Weak Supervision (GCL)，通过在基类上进行元训练（meta-training）来处理 few-shot 或 zero-shot 场景下的未标记节点。框架通过寻找最接近的原型表示作为类代表，并在 Text-Attributed Graphs (TAGs) 中整合语义信息，同时采用 teacher-student knowledge distillation 技术来缓解模型遗忘。实验结果在 Cora-ML、Amazon 和 OBGN-Arxiv 数据集上展示了 GOTHAM 在有限监督下有效处理演化图数据的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04954v1",
      "published_date": "2025-04-07 11:39:13 UTC",
      "updated_date": "2025-04-07 11:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:32:04.398019"
    },
    {
      "arxiv_id": "2504.04953v1",
      "title": "M-Prometheus: A Suite of Open Multilingual LLM Judges",
      "title_zh": "翻译失败",
      "authors": [
        "José Pombal",
        "Dongkeun Yoon",
        "Patrick Fernandes",
        "Ian Wu",
        "Seungone Kim",
        "Ricardo Rei",
        "Graham Neubig",
        "André F. T. Martins"
      ],
      "abstract": "The use of language models for automatically evaluating long-form text\n(LLM-as-a-judge) is becoming increasingly common, yet most LLM judges are\noptimized exclusively for English, with strategies for enhancing their\nmultilingual evaluation capabilities remaining largely unexplored in the\ncurrent literature. This has created a disparity in the quality of automatic\nevaluation methods for non-English languages, ultimately hindering the\ndevelopment of models with better multilingual capabilities. To bridge this\ngap, we introduce M-Prometheus, a suite of open-weight LLM judges ranging from\n3B to 14B parameters that can provide both direct assessment and pairwise\ncomparison feedback on multilingual outputs. M-Prometheus models outperform\nstate-of-the-art open LLM judges on multilingual reward benchmarks spanning\nmore than 20 languages, as well as on literary machine translation (MT)\nevaluation covering 4 language pairs. Furthermore, M-Prometheus models can be\nleveraged at decoding time to significantly improve generated outputs across\nall 3 tested languages, showcasing their utility for the development of better\nmultilingual models. Lastly, through extensive ablations, we identify the key\nfactors for obtaining an effective multilingual judge, including backbone model\nselection and training on natively multilingual feedback data instead of\ntranslated data. We release our models, training dataset, and code.",
      "tldr_zh": "该研究针对现有LLM-as-a-judge模型主要针对英语优化的问题，引入M-Prometheus，一套开放权重LLM评估器（从3B到14B参数），支持多语言输出评估，包括直接评估和配对比较反馈。M-Prometheus在超过20种语言的多语言奖励基准以及4个语言对的文学机器翻译评估中，超越了最先进开放LLM评估器，并在解码时显著提升了生成输出的质量。论文通过消融实验识别了关键因素，如骨干模型选择和使用原生多语言反馈数据，并开源了模型、训练数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04953v1",
      "published_date": "2025-04-07 11:37:26 UTC",
      "updated_date": "2025-04-07 11:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:32:16.451977"
    },
    {
      "arxiv_id": "2504.04949v1",
      "title": "One Quantizer is Enough: Toward a Lightweight Audio Codec",
      "title_zh": "一个量化器就足够：迈向轻量级音频编解码器",
      "authors": [
        "Linwei Zhai",
        "Han Ding",
        "Cui Zhao",
        "fei wang",
        "Ge Wang",
        "Wang Zhi",
        "Wei Xi"
      ],
      "abstract": "Neural audio codecs have recently gained traction for their ability to\ncompress high-fidelity audio and generate discrete tokens that can be utilized\nin downstream generative modeling tasks. However, leading approaches often rely\non resource-intensive models and multi-quantizer architectures, resulting in\nconsiderable computational overhead and constrained real-world applicability.\nIn this paper, we present SQCodec, a lightweight neural audio codec that\nleverages a single quantizer to address these limitations. SQCodec explores\nstreamlined convolutional networks and local Transformer modules, alongside\nTConv, a novel mechanism designed to capture acoustic variations across\nmultiple temporal scales, thereby enhancing reconstruction fidelity while\nreducing model complexity. Extensive experiments across diverse datasets show\nthat SQCodec achieves audio quality comparable to multi-quantizer baselines,\nwhile its single-quantizer design offers enhanced adaptability and its\nlightweight architecture reduces resource consumption by an order of magnitude.\nThe source code is publicly available at https://github.com/zhai-lw/SQCodec.",
      "tldr_zh": "本文提出 SQCodec，一种轻量级 neural audio codec，使用单个 quantizer 来解决现有方法的资源密集型问题和多-quantizer 架构的计算开销。SQCodec 采用简化的卷积网络、局部 Transformer 模块以及新型 TConv 机制，以捕捉多时间尺度的声学变化，从而提升音频重建的保真度并降低模型复杂度。实验在多种数据集上表明，SQCodec 的音频质量与多-quantizer 基线相当，同时其设计提高了适应性和将资源消耗减少了一个数量级。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "68T07",
        "I.2.m"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04949v1",
      "published_date": "2025-04-07 11:34:39 UTC",
      "updated_date": "2025-04-07 11:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:32:28.342023"
    },
    {
      "arxiv_id": "2504.04945v1",
      "title": "A Llama walks into the 'Bar': Efficient Supervised Fine-Tuning for Legal Reasoning in the Multi-state Bar Exam",
      "title_zh": "翻译失败",
      "authors": [
        "Rean Fernandes",
        "André Biedenkapp",
        "Frank Hutter",
        "Noor Awad"
      ],
      "abstract": "Legal reasoning tasks present unique challenges for large language models\n(LLMs) due to the complexity of domain-specific knowledge and reasoning\nprocesses. This paper investigates how effectively smaller language models\n(Llama 2 7B and Llama 3 8B) can be fine-tuned with a limited dataset of 1,514\nMulti-state Bar Examination (MBE) questions to improve legal question answering\naccuracy. We evaluate these models on the 2022 MBE questions licensed from JD\nAdvising, the same dataset used in the 'GPT-4 passes the Bar exam' study. Our\nmethodology involves collecting approximately 200 questions per legal domain\nacross 7 domains. We distill the dataset using Llama 3 (70B) to transform\nexplanations into a structured IRAC (Issue, Rule, Application, Conclusion)\nformat as a guided reasoning process to see if it results in better performance\nover the non-distilled dataset. We compare the non-fine-tuned models against\ntheir supervised fine-tuned (SFT) counterparts, trained for different sample\nsizes per domain, to study the effect on accuracy and prompt adherence. We also\nanalyse option selection biases and their mitigation following SFT. In\naddition, we consolidate the performance across multiple variables: prompt type\n(few-shot vs zero-shot), answer ordering (chosen-option first vs\ngenerated-explanation first), response format (Numbered list vs Markdown vs\nJSON), and different decoding temperatures. Our findings show that\ndomain-specific SFT helps some model configurations achieve close to human\nbaseline performance, despite limited computational resources and a relatively\nsmall dataset. We release both the gathered SFT dataset and the family of\nSupervised Fine-tuned (SFT) adapters optimised for MBE performance. This\nestablishes a practical lower bound on resources needed towards achieving\neffective legal question answering in smaller LLMs.",
      "tldr_zh": "本论文探讨了使用较小语言模型（Llama 2 7B和Llama 3 8B）通过监督微调（SFT）来提升法律推理能力，针对Multi-state Bar Exam (MBE)的1,514个问题数据集。研究方法包括使用Llama 3 (70B)将解释转化为结构化的IRAC (Issue, Rule, Application, Conclusion) 格式，并评估样本大小、提示类型（如few-shot vs zero-shot）、答案顺序和响应格式等变量的影响。结果表明，领域特定的SFT使某些模型配置接近人类基线性能，尽管资源有限；论文发布了SFT数据集和优化适配器，建立有效法律问答所需资源的实际下限。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.7; I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "COLM 2025 preprint, 9 pages, 3 figures, 16 appendix pages",
      "pdf_url": "http://arxiv.org/pdf/2504.04945v1",
      "published_date": "2025-04-07 11:31:22 UTC",
      "updated_date": "2025-04-07 11:31:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:32:41.657947"
    },
    {
      "arxiv_id": "2504.04942v1",
      "title": "Lemmanaid: Neuro-Symbolic Lemma Conjecturing",
      "title_zh": "翻译失败",
      "authors": [
        "Yousef Alhessi",
        "Sólrún Halla Einarsdóttir",
        "George Granberry",
        "Emily First",
        "Moa Johansson",
        "Sorin Lerner",
        "Nicholas Smallbone"
      ],
      "abstract": "Automatically conjecturing useful, interesting and novel lemmas would greatly\nimprove automated reasoning tools and lower the bar for formalizing mathematics\nin proof assistants. It is however a very challenging task for both neural and\nsymbolic approaches. We present the first steps towards a practical\nneuro-symbolic lemma conjecturing tool, Lemmanaid, that combines Large Language\nModels (LLMs) and symbolic methods, and evaluate it on proof libraries for the\nIsabelle proof assistant. We train an LLM to generate lemma templates that\ndescribe the shape of a lemma, and use symbolic methods to fill in the details.\nWe compare Lemmanaid against an LLM trained to generate complete lemma\nstatements as well as previous fully symbolic conjecturing methods. Our results\nindicate that neural and symbolic techniques are complementary. By leveraging\nthe best of both symbolic and neural methods we can generate useful lemmas for\na wide range of input domains, facilitating computer-assisted theory\ndevelopment and formalization.",
      "tldr_zh": "该研究提出Lemmanaid，一种神经-符号（Neuro-Symbolic）方法，用于自动推测有用、有趣和新颖的引理，以提升自动推理工具和数学形式化。该工具结合Large Language Models (LLMs)来生成引理模板，并利用符号方法填充细节，在Isabelle proof assistant的证明库上进行评估。与仅使用LLMs生成完整引理或纯符号方法的基线相比，Lemmanaid展示了神经和符号技术的互补优势，能为多种输入领域生成更多实用引理，从而促进计算机辅助理论发展和形式化。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04942v1",
      "published_date": "2025-04-07 11:30:36 UTC",
      "updated_date": "2025-04-07 11:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:32:52.278100"
    },
    {
      "arxiv_id": "2504.04939v2",
      "title": "A Taxonomy of Self-Handover",
      "title_zh": "自我移交的分类学",
      "authors": [
        "Naoki Wake",
        "Atsushi Kanehira",
        "Kazuhiro Sasabuchi",
        "Jun Takamatsu",
        "Katsushi Ikeuchi"
      ],
      "abstract": "Self-handover, transferring an object between one's own hands, is a common\nbut understudied bimanual action. While it facilitates seamless transitions in\ncomplex tasks, the strategies underlying its execution remain largely\nunexplored. Here, we introduce the first systematic taxonomy of self-handover,\nderived from manual annotation of over 12 hours of cooking activity performed\nby 21 participants. Our analysis reveals that self-handover is not merely a\npassive transition, but a highly coordinated action involving anticipatory\nadjustments by both hands. As a step toward automated analysis of human\nmanipulation, we further demonstrate the feasibility of classifying\nself-handover types using a state-of-the-art vision-language model. These\nfindings offer fresh insights into bimanual coordination, underscoring the role\nof self-handover in enabling smooth task transitions-an ability essential for\nadaptive dual-arm robotics.",
      "tldr_zh": "该论文首次提出自手移交（Self-handover）的系统分类法，这是一种常见的双臂动作（bimanual action），涉及将物体从一只手转移到另一只手，以实现复杂任务的无缝过渡。研究者通过手动标注21名参与者超过12小时的烹饪活动数据，揭示自手移交并非被动过程，而是双手高度协调的预见性调整。论文进一步证明，使用最先进的视觉语言模型（vision-language model）可行地分类自手移交类型，为自动化人类操作分析提供基础。这些发现深化了对双臂协调（bimanual coordination）的理解，并强调其在适应性双臂机器人（dual-arm robotics）中的关键作用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 8 figures, 1 table, Last updated on April 7th, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.04939v2",
      "published_date": "2025-04-07 11:21:42 UTC",
      "updated_date": "2025-04-08 10:18:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:33:04.177000"
    },
    {
      "arxiv_id": "2504.04935v1",
      "title": "RCCFormer: A Robust Crowd Counting Network Based on Transformer",
      "title_zh": "RCCFormer：基于Transformer的鲁棒人群计数网络",
      "authors": [
        "Peng Liu",
        "Heng-Chao Li",
        "Sen Lei",
        "Nanqing Liu",
        "Bin Feng",
        "Xiao Wu"
      ],
      "abstract": "Crowd counting, which is a key computer vision task, has emerged as a\nfundamental technology in crowd analysis and public safety management. However,\nchallenges such as scale variations and complex backgrounds significantly\nimpact the accuracy of crowd counting. To mitigate these issues, this paper\nproposes a robust Transformer-based crowd counting network, termed RCCFormer,\nspecifically designed for background suppression and scale awareness. The\nproposed method incorporates a Multi-level Feature Fusion Module (MFFM), which\nmeticulously integrates features extracted at diverse stages of the backbone\narchitecture. It establishes a strong baseline capable of capturing intricate\nand comprehensive feature representations, surpassing traditional baselines.\nFurthermore, the introduced Detail-Embedded Attention Block (DEAB) captures\ncontextual information and local details through global self-attention and\nlocal attention along with a learnable manner for efficient fusion. This\nenhances the model's ability to focus on foreground regions while effectively\nmitigating background noise interference. Additionally, we develop an Adaptive\nScale-Aware Module (ASAM), with our novel Input-dependent Deformable\nConvolution (IDConv) as its fundamental building block. This module dynamically\nadapts to changes in head target shapes and scales, significantly improving the\nnetwork's capability to accommodate large-scale variations. The effectiveness\nof the proposed method is validated on the ShanghaiTech Part_A and Part_B,\nNWPU-Crowd, and QNRF datasets. The results demonstrate that our RCCFormer\nachieves excellent performance across all four datasets, showcasing\nstate-of-the-art outcomes.",
      "tldr_zh": "本论文提出了一种基于 Transformer 的稳健人群计数网络 RCCFormer，旨在解决人群计数任务中规模变化和复杂背景带来的准确性挑战。该网络引入 Multi-level Feature Fusion Module (MFFM) 来融合骨干网络的多级特征，Detail-Embedded Attention Block (DEAB) 通过全局自注意力和局部注意机制增强前景焦点并抑制背景噪声，以及 Adaptive Scale-Aware Module (ASAM) 利用 Input-dependent Deformable Convolution (IDConv) 动态适应头部规模变化，从而提升整体性能。在 ShanghaiTech Part_A and Part_B、NWPU-Crowd 和 QNRF 数据集上的实验表明，RCCFormer 实现了 state-of-the-art 的结果，显著超越传统基线。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04935v1",
      "published_date": "2025-04-07 11:19:05 UTC",
      "updated_date": "2025-04-07 11:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:33:16.268323"
    },
    {
      "arxiv_id": "2504.04934v1",
      "title": "Boosting Relational Deep Learning with Pretrained Tabular Models",
      "title_zh": "翻译失败",
      "authors": [
        "Veronica Lachi",
        "Antonio Longa",
        "Beatrice Bevilacqua",
        "Bruno Lepri",
        "Andrea Passerini",
        "Bruno Ribeiro"
      ],
      "abstract": "Relational databases, organized into tables connected by primary-foreign key\nrelationships, are a common format for organizing data. Making predictions on\nrelational data often involves transforming them into a flat tabular format\nthrough table joins and feature engineering, which serve as input to tabular\nmethods. However, designing features that fully capture complex relational\npatterns remains challenging. Graph Neural Networks (GNNs) offer a compelling\nalternative by inherently modeling these relationships, but their time overhead\nduring inference limits their applicability for real-time scenarios. In this\nwork, we aim to bridge this gap by leveraging existing feature engineering\nefforts to enhance the efficiency of GNNs in relational databases.\nSpecifically, we use GNNs to capture complex relationships within relational\ndatabases, patterns that are difficult to featurize, while employing engineered\nfeatures to encode temporal information, thereby avoiding the need to retain\nthe entire historical graph and enabling the use of smaller, more efficient\ngraphs. Our \\textsc{LightRDL} approach not only improves efficiency, but also\noutperforms existing models. Experimental results on the RelBench benchmark\ndemonstrate that our framework achieves up to $33\\%$ performance improvement\nand a $526\\times$ inference speedup compared to GNNs, making it highly suitable\nfor real-time inference.",
      "tldr_zh": "本论文旨在提升关系数据库上的深度学习预测，通过结合 Graph Neural Networks (GNNs) 和预训练的表格模型，解决传统特征工程的局限性和 GNNs 的推理效率问题。提出的 LightRDL 方法利用 GNNs 捕获复杂关系，同时用工程特征编码时间信息，避免依赖完整历史图，从而实现更高效的模型。实验结果在 RelBench 基准上显示，LightRDL 比现有 GNNs 模型性能提升高达 33%，推理速度加快 526 倍，适用于实时场景。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04934v1",
      "published_date": "2025-04-07 11:19:04 UTC",
      "updated_date": "2025-04-07 11:19:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:33:27.969998"
    },
    {
      "arxiv_id": "2504.13899v1",
      "title": "Predicting Satisfaction of Counterfactual Explanations from Human Ratings of Explanatory Qualities",
      "title_zh": "翻译失败",
      "authors": [
        "Marharyta Domnich",
        "Rasmus Moorits Veski",
        "Julius Välja",
        "Kadi Tulver",
        "Raul Vicente"
      ],
      "abstract": "Counterfactual explanations are a widely used approach in Explainable AI,\noffering actionable insights into decision-making by illustrating how small\nchanges to input data can lead to different outcomes. Despite their importance,\nevaluating the quality of counterfactual explanations remains an open problem.\nTraditional quantitative metrics, such as sparsity or proximity, fail to fully\naccount for human preferences in explanations, while user studies are\ninsightful but not scalable. Moreover, relying only on a single overall\nsatisfaction rating does not lead to a nuanced understanding of why certain\nexplanations are effective or not. To address this, we analyze a dataset of\ncounterfactual explanations that were evaluated by 206 human participants, who\nrated not only overall satisfaction but also seven explanatory criteria:\nfeasibility, coherence, complexity, understandability, completeness, fairness,\nand trust. Modeling overall satisfaction as a function of these criteria, we\nfind that feasibility (the actionability of suggested changes) and trust (the\nbelief that the changes would lead to the desired outcome) consistently stand\nout as the strongest predictors of user satisfaction, though completeness also\nemerges as a meaningful contributor. Crucially, even excluding feasibility and\ntrust, other metrics explain 58% of the variance, highlighting the importance\nof additional explanatory qualities. Complexity appears independent, suggesting\nmore detailed explanations do not necessarily reduce satisfaction. Strong\nmetric correlations imply a latent structure in how users judge quality, and\ndemographic background significantly shapes ranking patterns. These insights\ninform the design of counterfactual algorithms that adapt explanatory qualities\nto user expertise and domain context.",
      "tldr_zh": "该研究探讨了在可解释AI（Explainable AI）中，使用Counterfactual explanations评估用户满意度的预测问题，通过分析206名参与者对七个解释标准（feasibility、coherence、complexity、understandability、completeness、fairness和trust）的评分。结果显示，feasibility（建议变化的可操作性）和trust（相信变化能实现预期结果）是整体满意度的最强预测因素，而completeness也发挥了重要作用，即使排除前两者，其他标准仍能解释58%的方差。论文进一步发现，complexity与满意度无关，用户判断质量存在潜在结构，且人口统计背景会影响排名模式，这些洞见有助于设计适应用户专业知识和领域背景的Counterfactual算法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "This work has been accepted to The 3rd World Conference on\n  eXplainable Artificial Intelligence (xAI 2025), July 9-11, 2025 - Istanbul,\n  Turkey",
      "pdf_url": "http://arxiv.org/pdf/2504.13899v1",
      "published_date": "2025-04-07 11:09:25 UTC",
      "updated_date": "2025-04-07 11:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:33:40.980035"
    },
    {
      "arxiv_id": "2504.04921v1",
      "title": "Expectations vs Reality -- A Secondary Study on AI Adoption in Software Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Katja Karhu",
        "Jussi Kasurinen",
        "Kari Smolander"
      ],
      "abstract": "In the software industry, artificial intelligence (AI) has been utilized more\nand more in software development activities. In some activities, such as\ncoding, AI has already been an everyday tool, but in software testing\nactivities AI it has not yet made a significant breakthrough. In this paper,\nthe objective was to identify what kind of empirical research with industry\ncontext has been conducted on AI in software testing, as well as how AI has\nbeen adopted in software testing practice. To achieve this, we performed a\nsystematic mapping study of recent (2020 and later) studies on AI adoption in\nsoftware testing in the industry, and applied thematic analysis to identify\ncommon themes and categories, such as the real-world use cases and benefits, in\nthe found papers. The observations suggest that AI is not yet heavily utilized\nin software testing, and still relatively few studies on AI adoption in\nsoftware testing have been conducted in the industry context to solve\nreal-world problems. Earlier studies indicated there was a noticeable gap\nbetween the actual use cases and actual benefits versus the expectations, which\nwe analyzed further. While there were numerous potential use cases for AI in\nsoftware testing, such as test case generation, code analysis, and intelligent\ntest automation, the reported actual implementations and observed benefits were\nlimited. In addition, the systematic mapping study revealed a potential problem\nwith false positive search results in online databases when using the search\nstring \"artificial intelligence\".",
      "tldr_zh": "这篇论文通过一个系统映射研究(systematic mapping study)调查了 AI 在软件测试中的采用现状，聚焦于2020年后的行业实证研究，并运用主题分析(thematic analysis)来识别常见主题，如实际用例和益处。研究发现，AI 在软件测试中尚未广泛应用，尽管存在众多潜在用例（如测试用例生成、代码分析和智能测试自动化），但实际实施和观察到的益处有限，存在显著的预期与现实差距。此外，论文指出在线数据库搜索“artificial intelligence”时可能出现假阳性问题，强调了进一步研究的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, 1 figure, submitted to Software Testing, Vertification and\n  Reliability journal",
      "pdf_url": "http://arxiv.org/pdf/2504.04921v1",
      "published_date": "2025-04-07 11:03:54 UTC",
      "updated_date": "2025-04-07 11:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:33:52.196288"
    },
    {
      "arxiv_id": "2504.04918v1",
      "title": "Constitution or Collapse? Exploring Constitutional AI with Llama 3-8B",
      "title_zh": "翻译失败",
      "authors": [
        "Xue Zhang"
      ],
      "abstract": "As language models continue to grow larger, the cost of acquiring\nhigh-quality training data has increased significantly. Collecting human\nfeedback is both expensive and time-consuming, and manual labels can be noisy,\nleading to an imbalance between helpfulness and harmfulness. Constitutional AI,\nintroduced by Anthropic in December 2022, uses AI to provide feedback to\nanother AI, greatly reducing the need for human labeling. However, the original\nimplementation was designed for a model with around 52 billion parameters, and\nthere is limited information on how well Constitutional AI performs with\nsmaller models, such as LLaMA 3-8B. In this paper, we replicated the\nConstitutional AI workflow using the smaller LLaMA 3-8B model. Our results show\nthat Constitutional AI can effectively increase the harmlessness of the model,\nreducing the Attack Success Rate in MT-Bench by 40.8%. However, similar to the\noriginal study, increasing harmlessness comes at the cost of helpfulness. The\nhelpfulness metrics, which are an average of the Turn 1 and Turn 2 scores,\ndropped by 9.8% compared to the baseline. Additionally, we observed clear signs\nof model collapse in the final DPO-CAI model, indicating that smaller models\nmay struggle with self-improvement due to insufficient output quality, making\neffective fine-tuning more challenging. Our study suggests that, like reasoning\nand math ability, self-improvement is an emergent property.",
      "tldr_zh": "本研究探讨了在较小模型 Llama 3-8B 上应用 Constitutional AI 的效果，旨在减少对人类反馈的依赖并提升模型安全性。研究者复现了 Constitutional AI 流程，通过 AI 反馈机制对模型进行微调，结果显示模型的无害性显著提高，MT-Bench 的 Attack Success Rate 降低了 40.8%。然而，这导致帮助性指标下降 9.8%，并观察到最终 DPO-CAI 模型出现 model collapse 的迹象，表明自改进是 emergent property，小模型在输出质量不足时难以实现有效 fine-tuning。",
      "categories": [
        "cs.AI",
        "68T05, 68T50",
        "I.2.6; I.2.7; I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures. Conducted as part of research on alignment\n  techniques for language models",
      "pdf_url": "http://arxiv.org/pdf/2504.04918v1",
      "published_date": "2025-04-07 11:01:25 UTC",
      "updated_date": "2025-04-07 11:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:34:04.561268"
    },
    {
      "arxiv_id": "2504.04915v1",
      "title": "Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Xu",
        "Wenqi Shi",
        "Yuchen Zhuang",
        "Yue Yu",
        "Joyce C. Ho",
        "Haoyu Wang",
        "Carl Yang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems often struggle to handle\nmulti-hop question-answering tasks accurately due to irrelevant context\nretrieval and limited complex reasoning capabilities. We introduce Collab-RAG,\na collaborative training framework that leverages mutual enhancement between a\nwhite-box small language model (SLM) and a blackbox large language model (LLM)\nfor RAG. Specifically, the SLM decomposes complex queries into simpler\nsub-questions, thus enhancing the accuracy of the retrieval and facilitating\nmore effective reasoning by the black-box LLM. Concurrently, the black-box LLM\nprovides feedback signals to improve the SLM's decomposition capability. We\nobserve that Collab-RAG relies solely on supervision from an affordable\nblack-box LLM without additional distillation from frontier LLMs, yet\ndemonstrates strong generalization across multiple black-box LLMs. Experimental\nevaluations across five multi-hop QA datasets demonstrate that Collab-RAG\nsubstantially outperforms existing black-box-only and SLM fine-tuning baselines\nby 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a\nfrozen 32B LLM in question decomposition, highlighting the efficiency of\nCollab-RAG in improving reasoning and retrieval for complex questions. The code\nof Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.",
      "tldr_zh": "本研究提出Collab-RAG，一种协作训练框架，用于提升Retrieval-Augmented Generation (RAG)系统在多跳问答任务中的性能，通过white-box小语言模型 (SLM) 和black-box大语言模型 (LLM) 的相互增强来解决无关上下文检索和复杂推理能力有限的问题。SLM负责将复杂查询分解为简单子问题，从而提高检索准确性和LLM的推理效果，同时LLM提供反馈信号来优化SLM的分解能力。该框架仅依赖可负担的黑盒LLM的监督，就实现了在多个黑盒LLM上的强泛化性能，并在五个多跳QA数据集上比现有基线平均提升1.8%-14.2%，其中fine-tuned的3B SLM在问题分解上甚至超过了frozen的32B LLM。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Code: https://github.com/ritaranx/Collab-RAG/",
      "pdf_url": "http://arxiv.org/pdf/2504.04915v1",
      "published_date": "2025-04-07 10:52:22 UTC",
      "updated_date": "2025-04-07 10:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:34:16.949911"
    },
    {
      "arxiv_id": "2504.04909v1",
      "title": "AlgOS: Algorithm Operating System",
      "title_zh": "AlgOS：算法操作系统",
      "authors": [
        "Llewyn Salt",
        "Marcus Gallagher"
      ],
      "abstract": "Algorithm Operating System (AlgOS) is an unopinionated, extensible, modular\nframework for algorithmic implementations. AlgOS offers numerous features:\nintegration with Optuna for automated hyperparameter tuning; automated argument\nparsing for generic command-line interfaces; automated registration of new\nclasses; and a centralised database for logging experiments and studies. These\nfeatures are designed to reduce the overhead of implementing new algorithms and\nto standardise the comparison of algorithms. The standardisation of algorithmic\nimplementations is crucial for reproducibility and reliability in research.\nAlgOS combines Abstract Syntax Trees with a novel implementation of the\nObserver pattern to control the logical flow of algorithmic segments.",
      "tldr_zh": "AlgOS 是一种无偏见、可扩展、模块化的框架，用于算法实现，旨在标准化算法开发过程。框架集成 Optuna 用于自动超参数调优、自动参数解析支持通用命令行界面、自动注册新类，以及一个集中数据库记录实验和研究，从而减少实现新算法的开销。AlgOS 通过结合 Abstract Syntax Trees 和新型 Observer pattern 来控制算法段的逻辑流程，最终提升研究的再现性和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04909v1",
      "published_date": "2025-04-07 10:36:46 UTC",
      "updated_date": "2025-04-07 10:36:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:34:26.698067"
    },
    {
      "arxiv_id": "2504.07989v2",
      "title": "Regional Tiny Stories: Using Small Models to Compare Language Learning and Tokenizer Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Nirvan Patil",
        "Malhar Abhay Inamdar",
        "Agnivo Gosai",
        "Guruprasad Pathak",
        "Anish Joshi",
        "Aryan Sagavekar",
        "Anish Joshirao",
        "Raj Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "Small Language Models (SLMs) offer efficient alternatives to LLMs for\nspecific domains. The 2023 TinyStories study developed an English dataset that\nallows SLMs with 1 to 10 million parameters to produce coherent outputs. Our\nresearch expands this framework by translating the original dataset into Indian\nlanguages and creating synthetic data using LLMs. We focus on Hindi, Marathi,\nand Bengali, evaluating SLMs for regional language processing and understanding\nlinguistic complexity. We show that SLMs efficiently process regional languages\nwith significantly fewer parameters than LLMs, providing a complementary\nframework for ``inference based evaluation\" of tokenization strategies and\nlinguistic complexity. Our analysis shows that language-specific tokenizers\noutperform general-purpose ones for Indian languages. Empirical validations,\nsupported by information-theoretic and morphological analyses, provides\nfundamental understanding behind the better performance of Hindi models over\nMarathi and Bengali. Additionally, we show that synthetic datasets outperform\ntranslated content for training SLMs. Correlation analyses reveal\ncross-linguistic patterns and language-specific relationships between\ncreativity, grammatical precision, and narrative completeness. These findings\nadvance both the practical application of SLMs to underserved languages and our\ntheoretical understanding of neural language development.",
      "tldr_zh": "本研究扩展了TinyStories数据集，将其翻译成Hindi、Marathi和Bengali等印度语言，并使用LLMs创建合成数据，以评估SLMs在区域语言处理中的性能。研究发现，SLMs能以显著更少的参数高效处理这些语言，且语言特定tokenizer在表现上优于通用tokenizer，同时通过信息理论和形态分析解释了Hindi模型为何优于Marathi和Bengali。实验结果表明，合成数据集在训练SLMs时比翻译内容更有效，并揭示了跨语言模式，如创造力、语法精确性和叙事完整性的相关性。这些发现推进了SLMs在未服务语言的实际应用，并加深了对神经语言发展的理论理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 24 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.07989v2",
      "published_date": "2025-04-07 10:33:14 UTC",
      "updated_date": "2025-04-22 05:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:34:40.999680"
    },
    {
      "arxiv_id": "2504.04907v2",
      "title": "Video-Bench: Human-Aligned Video Generation Benchmark",
      "title_zh": "Video-Bench：人类对齐的视频生成基准",
      "authors": [
        "Hui Han",
        "Siyuan Li",
        "Jiaqi Chen",
        "Yiwen Yuan",
        "Yuling Wu",
        "Chak Tou Leong",
        "Hanwen Du",
        "Junchen Fu",
        "Youhua Li",
        "Jie Zhang",
        "Chi Zhang",
        "Li-jia Li",
        "Yongxin Ni"
      ],
      "abstract": "Video generation assessment is essential for ensuring that generative models\nproduce visually realistic, high-quality videos while aligning with human\nexpectations. Current video generation benchmarks fall into two main\ncategories: traditional benchmarks, which use metrics and embeddings to\nevaluate generated video quality across multiple dimensions but often lack\nalignment with human judgments; and large language model (LLM)-based\nbenchmarks, though capable of human-like reasoning, are constrained by a\nlimited understanding of video quality metrics and cross-modal consistency. To\naddress these challenges and establish a benchmark that better aligns with\nhuman preferences, this paper introduces Video-Bench, a comprehensive benchmark\nfeaturing a rich prompt suite and extensive evaluation dimensions. This\nbenchmark represents the first attempt to systematically leverage MLLMs across\nall dimensions relevant to video generation assessment in generative models. By\nincorporating few-shot scoring and chain-of-query techniques, Video-Bench\nprovides a structured, scalable approach to generated video evaluation.\nExperiments on advanced models including Sora demonstrate that Video-Bench\nachieves superior alignment with human preferences across all dimensions.\nMoreover, in instances where our framework's assessments diverge from human\nevaluations, it consistently offers more objective and accurate insights,\nsuggesting an even greater potential advantage over traditional human judgment.",
      "tldr_zh": "本文提出Video-Bench，一个与人类偏好对齐的视频生成基准，旨在解决传统基准（如基于指标的评估）与人类判断不一致，以及LLM-based基准在视频质量和跨模态一致性理解上的局限。Video-Bench首次系统利用MLLMs结合few-shot scoring和chain-of-query技术，提供全面的评估框架，涵盖丰富的提示套件和多个评估维度。在Sora等先进模型的实验中，该基准显示出与人类偏好更高的一致性，并在评估分歧时提供更客观、准确的洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR'25",
      "pdf_url": "http://arxiv.org/pdf/2504.04907v2",
      "published_date": "2025-04-07 10:32:42 UTC",
      "updated_date": "2025-04-29 15:56:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:34:52.118322"
    },
    {
      "arxiv_id": "2504.04903v2",
      "title": "Lumina-OmniLV: A Unified Multimodal Framework for General Low-Level Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Yuandong Pu",
        "Le Zhuo",
        "Kaiwen Zhu",
        "Liangbin Xie",
        "Wenlong Zhang",
        "Xiangyu Chen",
        "Peng Gao",
        "Yu Qiao",
        "Chao Dong",
        "Yihao Liu"
      ],
      "abstract": "We present Lunima-OmniLV (abbreviated as OmniLV), a universal multimodal\nmulti-task framework for low-level vision that addresses over 100 sub-tasks\nacross four major categories: image restoration, image enhancement,\nweak-semantic dense prediction, and stylization. OmniLV leverages both textual\nand visual prompts to offer flexible and user-friendly interactions. Built on\nDiffusion Transformer (DiT)-based generative priors, our framework supports\narbitrary resolutions -- achieving optimal performance at 1K resolution --\nwhile preserving fine-grained details and high fidelity. Through extensive\nexperiments, we demonstrate that separately encoding text and visual\ninstructions, combined with co-training using shallow feature control, is\nessential to mitigate task ambiguity and enhance multi-task generalization. Our\nfindings also reveal that integrating high-level generative tasks into\nlow-level vision models can compromise detail-sensitive restoration. These\ninsights pave the way for more robust and generalizable low-level vision\nsystems.",
      "tldr_zh": "我们介绍了 OmniLV，一种统一的 multimodal 多任务框架，用于处理低级视觉领域的100多个子任务，包括图像恢复、图像增强、弱语义密集预测和风格化。该框架基于 Diffusion Transformer (DiT) 的生成先验，支持任意分辨率（如1K分辨率）并保持细粒度细节和高保真度，通过文本和视觉提示提供灵活交互。实验结果显示，单独编码文本和视觉指令并结合浅层特征控制的联合训练，能有效缓解任务模糊性和提升多任务泛化能力。然而，研究发现，将高层生成任务整合到低级视觉模型中可能损害细节敏感的恢复性能，为开发更稳健的低级视觉系统提供了关键见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04903v2",
      "published_date": "2025-04-07 10:22:00 UTC",
      "updated_date": "2025-04-08 07:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:35:04.430880"
    },
    {
      "arxiv_id": "2504.04893v4",
      "title": "SCAM: A Real-World Typographic Robustness Evaluation for Multimodal Foundation Models",
      "title_zh": "SCAM：多模态基础模型的真实世界排版鲁棒性评估",
      "authors": [
        "Justus Westerhoff",
        "Erblina Purelku",
        "Jakob Hackstein",
        "Jonas Loos",
        "Leo Pinetzki",
        "Lorenz Hufe"
      ],
      "abstract": "Typographic attacks exploit the interplay between text and visual content in\nmultimodal foundation models, causing misclassifications when misleading text\nis embedded within images. However, existing datasets are limited in size and\ndiversity, making it difficult to study such vulnerabilities. In this paper, we\nintroduce SCAM, the largest and most diverse dataset of real-world typographic\nattack images to date, containing 1,162 images across hundreds of object\ncategories and attack words. Through extensive benchmarking of Vision-Language\nModels (VLMs) on SCAM, we demonstrate that typographic attacks significantly\ndegrade performance, and identify that training data and model architecture\ninfluence the susceptibility to these attacks. Our findings reveal that\ntypographic attacks persist in state-of-the-art Large Vision-Language Models\n(LVLMs) due to the choice of their vision encoder, though larger Large Language\nModels (LLMs) backbones help mitigate their vulnerability. Additionally, we\ndemonstrate that synthetic attacks closely resemble real-world (handwritten)\nattacks, validating their use in research. Our work provides a comprehensive\nresource and empirical insights to facilitate future research toward robust and\ntrustworthy multimodal AI systems. We publicly release the datasets introduced\nin this paper along with the code for evaluations at\nwww.bliss.berlin/research/scam.",
      "tldr_zh": "本文提出 SCAM 数据集，这是迄今为止最大的真实世界 typographic attacks 图像数据集，包含 1,162 张图像，覆盖数百个对象类别和攻击词，用于评估多模态基础模型的鲁棒性。研究通过对 Vision-Language Models (VLMs) 进行广泛基准测试，发现 typographic attacks 会显著降低模型性能，且模型的训练数据和架构（如视觉编码器）是影响易受攻击性的关键因素。结果显示，state-of-the-art Large Vision-Language Models (LVLMs) 仍存在这些漏洞，但采用更大的 Large Language Models (LLMs) 骨干可部分缓解；此外，合成攻击与真实手写攻击相似，可用于研究。作者公开发布了数据集和评估代码，以推动更可靠的多模态 AI 系统的发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025 Workshop EVAL-FoMo-2",
      "pdf_url": "http://arxiv.org/pdf/2504.04893v4",
      "published_date": "2025-04-07 10:01:38 UTC",
      "updated_date": "2025-05-16 11:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:35:17.330525"
    },
    {
      "arxiv_id": "2504.05358v1",
      "title": "Debate-Feedback: A Multi-Agent Framework for Efficient Legal Judgment Prediction",
      "title_zh": "Debate-Feedback：一个多智能体框架，用于高效的法律判决预测",
      "authors": [
        "Xi Chen",
        "Mao Mao",
        "Shuo Li",
        "Haotian Shangguan"
      ],
      "abstract": "The use of AI in legal analysis and prediction (LegalAI) has gained\nwidespread attention, with past research focusing on retrieval-based methods\nand fine-tuning large models. However, these approaches often require large\ndatasets and underutilize the capabilities of modern large language models\n(LLMs). In this paper, inspired by the debate phase of real courtroom trials,\nwe propose a novel legal judgment prediction model based on the Debate-Feedback\narchitecture, which integrates LLM multi-agent debate and reliability\nevaluation models. Unlike traditional methods, our model achieves significant\nimprovements in efficiency by minimizing the need for large historical\ndatasets, thus offering a lightweight yet robust solution. Comparative\nexperiments show that it outperforms several general-purpose and\ndomain-specific legal models, offering a dynamic reasoning process and a\npromising direction for future LegalAI research.",
      "tldr_zh": "本文提出了一种名为 Debate-Feedback 的多智能体框架，用于高效的 Legal Judgment Prediction（法律判断预测），灵感来源于法庭辩论阶段。该框架整合了大语言模型（LLMs）的多智能体辩论和可靠性评估模型，减少了对大型历史数据集的依赖，提供了一个轻量级且稳健的解决方案。与传统检索-based 方法和 fine-tuning 模型相比，实验结果显示该框架在效率和性能上优于多个通用和领域特定的法律模型，并实现了动态推理过程，为 LegalAI 研究开辟了新方向。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05358v1",
      "published_date": "2025-04-07 09:34:14 UTC",
      "updated_date": "2025-04-07 09:34:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:35:28.445062"
    },
    {
      "arxiv_id": "2504.05357v1",
      "title": "Find A Winning Sign: Sign Is All We Need to Win the Lottery",
      "title_zh": "翻译失败",
      "authors": [
        "Junghun Oh",
        "Sungyong Baik",
        "Kyoung Mu Lee"
      ],
      "abstract": "The Lottery Ticket Hypothesis (LTH) posits the existence of a sparse\nsubnetwork (a.k.a. winning ticket) that can generalize comparably to its\nover-parameterized counterpart when trained from scratch. The common approach\nto finding a winning ticket is to preserve the original strong generalization\nthrough Iterative Pruning (IP) and transfer information useful for achieving\nthe learned generalization by applying the resulting sparse mask to an\nuntrained network. However, existing IP methods still struggle to generalize\ntheir observations beyond ad-hoc initialization and small-scale architectures\nor datasets, or they bypass these challenges by applying their mask to trained\nweights instead of initialized ones. In this paper, we demonstrate that the\nparameter sign configuration plays a crucial role in conveying useful\ninformation for generalization to any randomly initialized network. Through\nlinear mode connectivity analysis, we observe that a sparse network trained by\nan existing IP method can retain its basin of attraction if its parameter signs\nand normalization layer parameters are preserved. To take a step closer to\nfinding a winning ticket, we alleviate the reliance on normalization layer\nparameters by preventing high error barriers along the linear path between the\nsparse network trained by our method and its counterpart with initialized\nnormalization layer parameters. Interestingly, across various architectures and\ndatasets, we observe that any randomly initialized network can be optimized to\nexhibit low error barriers along the linear path to the sparse network trained\nby our method by inheriting its sparsity and parameter sign information,\npotentially achieving performance comparable to the original. The code is\navailable at https://github.com/JungHunOh/AWS\\_ICLR2025.git",
      "tldr_zh": "本文研究了Lottery Ticket Hypothesis (LTH)，提出参数符号配置是找到winning ticket的关键因素，而非依赖特定初始化或归一化层参数。作者通过线性模式连接性分析发现，保留稀疏网络的参数符号和归一化层参数能维持其吸引力盆地，并开发了一种方法来减少高错误障碍，从而使任何随机初始化的网络通过继承稀疏性和符号信息实现优化。实验结果显示，该方法在各种架构和数据集上使网络性能与原网络相当，提升了LTH的泛化适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05357v1",
      "published_date": "2025-04-07 09:30:38 UTC",
      "updated_date": "2025-04-07 09:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:35:40.766161"
    },
    {
      "arxiv_id": "2504.04874v1",
      "title": "Futureproof Static Memory Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Christos Lamprakos",
        "Panagiotis Xanthopoulos",
        "Manolis Katsaragakis",
        "Sotirios Xydis",
        "Dimitrios Soudris",
        "Francky Catthoor"
      ],
      "abstract": "The NP-complete combinatorial optimization task of assigning offsets to a set\nof buffers with known sizes and lifetimes so as to minimize total memory usage\nis called dynamic storage allocation (DSA). Existing DSA implementations bypass\nthe theoretical state-of-the-art algorithms in favor of either fast but\nwasteful heuristics, or memory-efficient approaches that do not scale beyond\none thousand buffers. The \"AI memory wall\", combined with deep neural networks'\nstatic architecture, has reignited interest in DSA. We present idealloc, a\nlow-fragmentation, high-performance DSA implementation designed for\nmillion-buffer instances. Evaluated on a novel suite of particularly hard\nbenchmarks from several domains, idealloc ranks first against four production\nimplementations in terms of a joint effectiveness/robustness criterion.",
      "tldr_zh": "该论文探讨了动态存储分配(DSA)，一个NP-complete的组合优化问题，旨在为已知大小和生命周期的缓冲区分配偏移量以最小化内存使用，但现有实现要么采用快速却浪费资源的启发式方法，要么是高效但无法扩展到超过一千个缓冲区的方案。作者引入了idealloc，一种低碎片、高性能的DSA实现，专门设计用于百万级缓冲区实例，并结合了AI memory wall和深度神经网络静态架构的背景。实验在多个领域的新型困难基准测试中显示，idealloc在有效性和鲁棒性标准上优于四个生产实现，排名第一。",
      "categories": [
        "cs.OS",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.OS",
      "comment": "Submitted to ACM TOPLAS",
      "pdf_url": "http://arxiv.org/pdf/2504.04874v1",
      "published_date": "2025-04-07 09:28:54 UTC",
      "updated_date": "2025-04-07 09:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:35:52.127238"
    },
    {
      "arxiv_id": "2504.05356v2",
      "title": "DyTTP: Trajectory Prediction with Normalization-Free Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "JianLin Zhu",
        "HongKuo Niu"
      ],
      "abstract": "Accurate trajectory prediction is a cornerstone for the safe operation of\nautonomous driving systems, where understanding the dynamic behavior of\nsurrounding agents is crucial. Transformer-based architectures have\ndemonstrated significant promise in capturing complex spatio-temporality\ndependencies. However, their reliance on normalization layers can lead to\ncomputation overhead and training instabilities. In this work, we present a\ntwo-fold approach to address these challenges. First, we integrate DynamicTanh\n(DyT), which is the latest method to promote transformers, into the backbone,\nreplacing traditional layer normalization. This modification simplifies the\nnetwork architecture and improves the stability of the inference. We are the\nfirst work to deploy the DyT to the trajectory prediction task. Complementing\nthis, we employ a snapshot ensemble strategy to further boost trajectory\nprediction performance. Using cyclical learning rate scheduling, multiple model\nsnapshots are captured during a single training run. These snapshots are then\naggregated via simple averaging at inference time, allowing the model to\nbenefit from diverse hypotheses without incurring substantial additional\ncomputational cost. Extensive experiments on Argoverse datasets demonstrate\nthat our combined approach significantly improves prediction accuracy,\ninference speed and robustness in diverse driving scenarios. This work\nunderscores the potential of normalization-free transformer designs augmented\nwith lightweight ensemble techniques in advancing trajectory forecasting for\nautonomous vehicles.",
      "tldr_zh": "本文提出 DyTTP，一种基于无归一化 Transformers 的轨迹预测方法，旨在解决自动驾驶系统中轨迹预测的计算开销和训练不稳定性问题。核心创新包括首次将 DynamicTanh (DyT) 集成到模型中，替换传统层归一化以简化架构并提升推理稳定性；同时采用快照集成策略(snapshot ensemble)通过循环学习率调度捕获多个模型快照，并在推理时进行平均，以提高性能而不增加显著计算成本。在 Argoverse 数据集上的实验表明，DyTTP 显著提升了预测准确性、推理速度和鲁棒性，展示了无归一化 Transformer 设计结合轻量级集成技术的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05356v2",
      "published_date": "2025-04-07 09:26:25 UTC",
      "updated_date": "2025-05-06 14:46:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:36:05.078174"
    },
    {
      "arxiv_id": "2504.04867v1",
      "title": "FedSAUC: A Similarity-Aware Update Control for Communication-Efficient Federated Learning in Edge Computing",
      "title_zh": "FedSAUC",
      "authors": [
        "Ming-Lun Lee",
        "Han-Chang Chou",
        "Yan-Ann Chen"
      ],
      "abstract": "Federated learning is a distributed machine learning framework to\ncollaboratively train a global model without uploading privacy-sensitive data\nonto a centralized server. Usually, this framework is applied to edge devices\nsuch as smartphones, wearable devices, and Internet of Things (IoT) devices\nwhich closely collect information from users. However, these devices are mostly\nbattery-powered. The update procedure of federated learning will constantly\nconsume the battery power and the transmission bandwidth. In this work, we\npropose an update control for federated learning, FedSAUC, by considering the\nsimilarity of users' behaviors (models). At the server side, we exploit\nclustering algorithms to group devices with similar models. Then we select some\nrepresentatives for each cluster to update information to train the model. We\nalso implemented a testbed prototyping on edge devices for validating the\nperformance. The experimental results show that this update control will not\naffect the training accuracy in the long run.",
      "tldr_zh": "本研究提出 FedSAUC，一种基于用户行为（模型）相似性的更新控制方法，旨在提升 Federated Learning 在 Edge Computing 中的通信效率，减少边缘设备（如智能手机和 IoT 设备）的电池和带宽消耗。FedSAUC 在服务器端使用聚类算法对设备模型进行分组，并仅选择每个群组的代表进行模型更新，从而优化信息传输过程。该方法通过在边缘设备上构建测试床进行验证，实验结果显示 FedSAUC 不会影响长期训练准确性，同时显著提高了通信效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Proceedings of the International Conference on\n  Mobile Computing and Ubiquitous Network (ICMU), 2021",
      "pdf_url": "http://arxiv.org/pdf/2504.04867v1",
      "published_date": "2025-04-07 09:21:43 UTC",
      "updated_date": "2025-04-07 09:21:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:36:16.101942"
    },
    {
      "arxiv_id": "2504.04862v1",
      "title": "GAMDTP: Dynamic Trajectory Prediction with Graph Attention Mamba Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yunxiang Liu",
        "Hongkuo Niu",
        "Jianlin Zhu"
      ],
      "abstract": "Accurate motion prediction of traffic agents is crucial for the safety and\nstability of autonomous driving systems. In this paper, we introduce GAMDTP, a\nnovel graph attention-based network tailored for dynamic trajectory prediction.\nSpecifically, we fuse the result of self attention and mamba-ssm through a gate\nmechanism, leveraging the strengths of both to extract features more\nefficiently and accurately, in each graph convolution layer. GAMDTP encodes the\nhigh-definition map(HD map) data and the agents' historical trajectory\ncoordinates and decodes the network's output to generate the final prediction\nresults. Additionally, recent approaches predominantly focus on dynamically\nfusing historical forecast results and rely on two-stage frameworks including\nproposal and refinement. To further enhance the performance of the two-stage\nframeworks we also design a scoring mechanism to evaluate the prediction\nquality during the proposal and refinement processes. Experiments on the\nArgoverse dataset demonstrates that GAMDTP achieves state-of-the-art\nperformance, achieving superior accuracy in dynamic trajectory prediction.",
      "tldr_zh": "本研究提出GAMDTP，一种基于Graph Attention的网络，用于动态轨迹预测，以提升自动驾驶系统的安全性和稳定性。该方法在每个图卷积层中，通过门机制融合自注意力(Self Attention)和Mamba-SSM，高效准确地提取特征，并结合高清地图(HD map)数据和代理的历史轨迹坐标进行编码和解码。此外，引入评分机制来评估预测质量，优化两阶段框架（proposal and refinement）的性能。在Argoverse数据集上的实验表明，GAMDTP实现了state-of-the-art性能，显著提高了轨迹预测的准确性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04862v1",
      "published_date": "2025-04-07 09:19:20 UTC",
      "updated_date": "2025-04-07 09:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:36:28.133509"
    },
    {
      "arxiv_id": "2504.04861v1",
      "title": "SAFT: Structure-aware Transformers for Textual Interaction Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Hongtao Wang",
        "Renchi Yang",
        "Hewen Wang",
        "Haoran Zheng",
        "Jianliang Xu"
      ],
      "abstract": "Textual interaction networks (TINs) are an omnipresent data structure used to\nmodel the interplay between users and items on e-commerce websites, social\nnetworks, etc., where each interaction is associated with a text description.\nClassifying such textual interactions (TIC) finds extensive use in detecting\nspam reviews in e-commerce, fraudulent transactions in finance, and so on.\nExisting TIC solutions either (i) fail to capture the rich text semantics due\nto the use of context-free text embeddings, and/or (ii) disregard the bipartite\nstructure and node heterogeneity of TINs, leading to compromised TIC\nperformance. In this work, we propose SAFT, a new architecture that integrates\nlanguage- and graph-based modules for the effective fusion of textual and\nstructural semantics in the representation learning of interactions. In\nparticular, line graph attention (LGA)/gated attention units (GAUs) and\npretrained language models (PLMs) are capitalized on to model the\ninteraction-level and token-level signals, which are further coupled via the\nproxy token in an iterative and contextualized fashion. Additionally, an\nefficient and theoretically-grounded approach is developed to encode the local\nand global topology information pertaining to interactions into structural\nembeddings. The resulting embeddings not only inject the structural features\nunderlying TINs into the textual interaction encoding but also facilitate the\ndesign of graph sampling strategies. Extensive empirical evaluations on\nmultiple real TIN datasets demonstrate the superiority of SAFT over the\nstate-of-the-art baselines in TIC accuracy.",
      "tldr_zh": "该论文针对文本交互分类 (TIC) 问题，提出了一种名为 SAFT 的新架构，用于处理文本交互网络 (TINs) 中的文本语义和结构信息融合。SAFT 整合了 Line Graph Attention (LGA)、Gated Attention Units (GAUs) 和 Pretrained Language Models (PLMs)，通过代理 token 的迭代上下文化方式来建模交互级和 token 级信号，同时编码交互的局部和全局拓扑信息，以提升表示学习效果。实验在多个真实 TIN 数据集上表明，SAFT 在 TIC 准确率上显著优于现有基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04861v1",
      "published_date": "2025-04-07 09:19:12 UTC",
      "updated_date": "2025-04-07 09:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:36:41.159665"
    },
    {
      "arxiv_id": "2504.04858v1",
      "title": "Don't Lag, RAG: Training-Free Adversarial Detection Using RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Roie Kazoom",
        "Raz Lapid",
        "Moshe Sipper",
        "Ofer Hadar"
      ],
      "abstract": "Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.",
      "tldr_zh": "这篇论文提出了一种训练-free 的 Visual Retrieval-Augmented Generation (VRAG) 框架，用于检测对抗性补丁攻击 (adversarial patch attacks)，通过整合 Vision-Language Models (VLMs) 来检索视觉上相似的补丁和图像，并进行生成式推理识别攻击类型，而无需额外训练或微调。实验评估了多种 VLMs，包括开源模型 Qwen-VL-Plus、Qwen2.5-VL-72B 和 UI-TARS-72B-DPO，以及闭源模型 Gemini-2.0，结果显示 UI-TARS-72B-DPO 达到了 95% 的分类准确率，Gemini-2.0 则高达 98%。该框架在最小人类标注下有效识别多样化攻击，为鲁棒且实用的对抗攻击防御铺平了道路。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04858v1",
      "published_date": "2025-04-07 09:14:47 UTC",
      "updated_date": "2025-04-07 09:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:36:52.999466"
    },
    {
      "arxiv_id": "2504.04855v1",
      "title": "BIASINSPECTOR: Detecting Bias in Structured Data through LLM Agents",
      "title_zh": "BIASINSPECTOR：通过LLM代理检测结构化数据中的偏见",
      "authors": [
        "Haoxuan Li",
        "Mingyu Derek Ma",
        "Jen-tse Huang",
        "Zhaotian Weng",
        "Wei Wang",
        "Jieyu Zhao"
      ],
      "abstract": "Detecting biases in structured data is a complex and time-consuming task.\nExisting automated techniques are limited in diversity of data types and\nheavily reliant on human case-by-case handling, resulting in a lack of\ngeneralizability. Currently, large language model (LLM)-based agents have made\nsignificant progress in data science, but their ability to detect data biases\nis still insufficiently explored. To address this gap, we introduce the first\nend-to-end, multi-agent synergy framework, BIASINSPECTOR, designed for\nautomatic bias detection in structured data based on specific user\nrequirements. It first develops a multi-stage plan to analyze user-specified\nbias detection tasks and then implements it with a diverse and well-suited set\nof tools. It delivers detailed results that include explanations and\nvisualizations. To address the lack of a standardized framework for evaluating\nthe capability of LLM agents to detect biases in data, we further propose a\ncomprehensive benchmark that includes multiple evaluation metrics and a large\nset of test cases. Extensive experiments demonstrate that our framework\nachieves exceptional overall performance in structured data bias detection,\nsetting a new milestone for fairer data applications.",
      "tldr_zh": "该论文引入了 BIASINSPECTOR，一种基于 LLM Agents 的端到端多智能体协同框架，用于自动检测结构化数据中的偏差，以解决现有方法的多样性不足和对人工依赖问题。框架通过多阶段计划分析用户指定的偏差检测任务，并利用多样化工具集生成详细解释和可视化结果。论文还提出一个全面基准测试，包括多种评估指标和大量测试用例，实验结果显示 BIASINSPECTOR 在偏差检测方面表现出色，推动了更公平的数据应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04855v1",
      "published_date": "2025-04-07 09:12:00 UTC",
      "updated_date": "2025-04-07 09:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:37:04.443978"
    },
    {
      "arxiv_id": "2504.04850v1",
      "title": "An Efficient Approach for Cooperative Multi-Agent Learning Problems",
      "title_zh": "一种针对合作多智能体学习问题的有效方法",
      "authors": [
        "Ángel Aso-Mollar",
        "Eva Onaindia"
      ],
      "abstract": "In this article, we propose a centralized Multi-Agent Learning framework for\nlearning a policy that models the simultaneous behavior of multiple agents that\nneed to coordinate to solve a certain task. Centralized approaches often suffer\nfrom the explosion of an action space that is defined by all possible\ncombinations of individual actions, known as joint actions. Our approach\naddresses the coordination problem via a sequential abstraction, which\novercomes the scalability problems typical to centralized methods. It\nintroduces a meta-agent, called \\textit{supervisor}, which abstracts joint\nactions as sequential assignments of actions to each agent. This sequential\nabstraction not only simplifies the centralized joint action space but also\nenhances the framework's scalability and efficiency. Our experimental results\ndemonstrate that the proposed approach successfully coordinates agents across a\nvariety of Multi-Agent Learning environments of diverse sizes.",
      "tldr_zh": "本文提出了一种高效的中心化 Multi-Agent Learning 框架，用于学习多个需要协调的智能体策略，以解决合作任务。框架通过引入一个名为 supervisor 的元智能体，将联合 actions 抽象为对每个智能体的顺序分配，从而简化了联合动作空间并提升了可扩展性和效率。与传统中心化方法相比，该方法避免了动作空间爆炸问题。实验结果显示，该框架在各种规模的 Multi-Agent Learning 环境中成功实现了智能体的协调。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICTAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2504.04850v1",
      "published_date": "2025-04-07 09:03:35 UTC",
      "updated_date": "2025-04-07 09:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:37:15.896608"
    },
    {
      "arxiv_id": "2504.04833v2",
      "title": "Explanation-Driven Interventions for Artificial Intelligence Model Customization: Empowering End-Users to Tailor Black-Box AI in Rhinocytology",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Esposito",
        "Miriana Calvano",
        "Antonio Curci",
        "Francesco Greco",
        "Rosa Lanzilotti",
        "Antonio Piccinno"
      ],
      "abstract": "The integration of Artificial Intelligence (AI) in modern society is\ntransforming how individuals perform tasks. In high-risk domains, ensuring\nhuman control over AI systems remains a key design challenge. This article\npresents a novel End-User Development (EUD) approach for black-box AI models,\nenabling users to edit explanations and influence future predictions through\ntargeted interventions. By combining explainability, user control, and model\nadaptability, the proposed method advances Human-Centered AI (HCAI), promoting\na symbiotic relationship between humans and adaptive, user-tailored AI systems.",
      "tldr_zh": "该论文提出了一种基于解释驱动干预的End-User Development (EUD) 方法，允许用户编辑黑-box AI 模型的解释，从而影响其未来预测，实现AI 的个性化定制。针对高风险领域如 Rhinocytology，该方法结合 explainability、user control 和 model adaptability，提升了人类对AI 系统的控制。总体上，该创新推进了 Human-Centered AI (HCAI)，促进人类与适应性AI 的协同关系。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Second version (11 pages, 8 of content)",
      "pdf_url": "http://arxiv.org/pdf/2504.04833v2",
      "published_date": "2025-04-07 08:44:48 UTC",
      "updated_date": "2025-04-14 16:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:37:27.933463"
    },
    {
      "arxiv_id": "2504.04827v1",
      "title": "From Specificity to Generality: Revisiting Generalizable Artifacts in Detecting Face Deepfakes",
      "title_zh": "从具体到一般：重新审",
      "authors": [
        "Long Ma",
        "Zhiyuan Yan",
        "Yize Chen",
        "Jin Xu",
        "Qinglang Guo",
        "Hu Huang",
        "Yong Liao",
        "Hui Lin"
      ],
      "abstract": "Detecting deepfakes has been an increasingly important topic, especially\ngiven the rapid development of AI generation techniques. In this paper, we ask:\nHow can we build a universal detection framework that is effective for most\nfacial deepfakes? One significant challenge is the wide variety of deepfake\ngenerators available, resulting in varying forgery artifacts (e.g., lighting\ninconsistency, color mismatch, etc). But should we ``teach\" the detector to\nlearn all these artifacts separately? It is impossible and impractical to\nelaborate on them all. So the core idea is to pinpoint the more common and\ngeneral artifacts across different deepfakes. Accordingly, we categorize\ndeepfake artifacts into two distinct yet complementary types: Face\nInconsistency Artifacts (FIA) and Up-Sampling Artifacts (USA). FIA arise from\nthe challenge of generating all intricate details, inevitably causing\ninconsistencies between the complex facial features and relatively uniform\nsurrounding areas. USA, on the other hand, are the inevitable traces left by\nthe generator's decoder during the up-sampling process. This categorization\nstems from the observation that all existing deepfakes typically exhibit one or\nboth of these artifacts. To achieve this, we propose a new data-level\npseudo-fake creation framework that constructs fake samples with only the FIA\nand USA, without introducing extra less-general artifacts. Specifically, we\nemploy a super-resolution to simulate the USA, while design a Blender module\nthat uses image-level self-blending on diverse facial regions to create the\nFIA. We surprisingly found that, with this intuitive design, a standard image\nclassifier trained only with our pseudo-fake data can non-trivially generalize\nwell to unseen deepfakes.",
      "tldr_zh": "本论文探讨了构建通用面部深度伪造（deepfakes）检测框架的方法，核心在于从特定伪迹转向识别更通用的伪迹，通过分类为Face Inconsistency Artifacts (FIA)和Up-Sampling Artifacts (USA)来实现。研究者提出一个数据级伪假创建框架，使用超分辨率模拟USA，并设计Blender模块通过图像级自混合创建FIA，从而生成仅包含这些通用伪迹的伪造样本，而避免引入其他不相关伪迹。实验结果显示，使用这种伪造数据训练的标准图像分类器，能够有效泛化到未见过的深度伪造，提高了检测的鲁棒性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04827v1",
      "published_date": "2025-04-07 08:34:28 UTC",
      "updated_date": "2025-04-07 08:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:37:40.505467"
    },
    {
      "arxiv_id": "2504.04823v1",
      "title": "Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models",
      "title_zh": "量化损害推理？ 量化推理模型的实证",
      "authors": [
        "Ruikang Liu",
        "Yuxuan Sun",
        "Manyi Zhang",
        "Haoli Bai",
        "Xianzhi Yu",
        "Tiezheng Yu",
        "Chun Yuan",
        "Lu Hou"
      ],
      "abstract": "Recent advancements in reasoning language models have demonstrated remarkable\nperformance in complex tasks, but their extended chain-of-thought reasoning\nprocess increases inference overhead. While quantization has been widely\nadopted to reduce the inference cost of large language models, its impact on\nreasoning models remains understudied. In this study, we conduct the first\nsystematic study on quantized reasoning models, evaluating the open-sourced\nDeepSeek-R1-Distilled Qwen and LLaMA families ranging from 1.5B to 70B\nparameters, and QwQ-32B. Our investigation covers weight, KV cache, and\nactivation quantization using state-of-the-art algorithms at varying\nbit-widths, with extensive evaluation across mathematical (AIME, MATH-500),\nscientific (GPQA), and programming (LiveCodeBench) reasoning benchmarks. Our\nfindings reveal that while lossless quantization can be achieved with W8A8 or\nW4A16 quantization, lower bit-widths introduce significant accuracy risks. We\nfurther identify model size, model origin, and task difficulty as critical\ndeterminants of performance. Contrary to expectations, quantized models do not\nexhibit increased output lengths. In addition, strategically scaling the model\nsizes or reasoning steps can effectively enhance the performance. All quantized\nmodels and codes will be open-sourced in\nhttps://github.com/ruikangliu/Quantized-Reasoning-Models.",
      "tldr_zh": "本研究首次系统探讨了量化（quantization）对推理语言模型性能的影响，旨在评估其在减少推理开销的同时是否会损害模型的推理能力。研究者评估了DeepSeek-R1-Distilled、Qwen和LLaMA等模型家族（参数从1.5B到70B），测试了权重（weight）、KV cache和激活（activation）的量化算法在不同位宽下的表现，并使用AIME、MATH-500、GPQA和LiveCodeBench等基准进行跨领域评估。结果显示，无损量化可在W8A8或W4A16位宽下实现，但更低位宽会显著降低准确率；模型大小、来源和任务难度是关键影响因素，且量化并未增加输出长度，通过战略性调整模型规模或推理步骤可提升性能。该研究将开源所有量化模型和代码，以促进进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04823v1",
      "published_date": "2025-04-07 08:22:45 UTC",
      "updated_date": "2025-04-07 08:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:37:53.081742"
    },
    {
      "arxiv_id": "2504.04821v1",
      "title": "A Customized SAT-based Solver for Graph Coloring",
      "title_zh": "自定义的 SAT 基于图着色求解",
      "authors": [
        "Timo Brand",
        "Daniel Faber",
        "Stephan Held",
        "Petra Mutzel"
      ],
      "abstract": "We introduce ZykovColor, a novel SAT-based algorithm to solve the graph\ncoloring problem working on top of an encoding that mimics the Zykov tree. Our\nmethod is based on an approach of H\\'ebrard and Katsirelos (2020) that employs\na propagator to enforce transitivity constraints, incorporate lower bounds for\nsearch tree pruning, and enable inferred propagations. We leverage the recently\nintroduced IPASIR-UP interface for CaDiCal to implement these techniques with a\nSAT solver. Furthermore, we propose new features that take advantage of the\nunderlying SAT solver. These include modifying the integrated decision strategy\nwith vertex domination hints and using incremental bottom-up search that allows\nto reuse learned clauses from previous calls. Additionally, we integrate a more\nefficient clique computation to improve the lower bounds during the search. We\nvalidate the effectiveness of each new feature through an experimental\nanalysis. ZykovColor outperforms other state-of-the-art graph coloring\nimplementations on the DIMACS benchmark set. Further experiments on random\nErd\\H{o}s-R\\'enyi graphs show that our new approach dominates state-of-the-art\nSAT-based methods for both very sparse and highly dense graphs.",
      "tldr_zh": "该研究引入了 ZykovColor，一种定制的 SAT-based 算法，用于解决图着色问题，通过模仿 Zykov tree 的编码并整合传播器来强制传递性约束、应用下界剪枝和推断传播。创新包括利用 IPASIR-UP 接口与 CaDiCal 求解器结合、修改决策策略以加入顶点支配提示、实现增量自底向上搜索重用学到的子句，以及优化团计算以提升下界。实验分析证明，这些新特性使 ZykovColor 在 DIMACS 基准集和随机 Erd\\H{o}s-R\\'enyi 图上均优于现有 SAT-based 方法，尤其在非常稀疏和高密度图中表现出显著优势。",
      "categories": [
        "cs.DM",
        "cs.AI",
        "cs.DS",
        "cs.LO",
        "05C15",
        "G.2.2"
      ],
      "primary_category": "cs.DM",
      "comment": "5 figures, 2 tables, source code published at\n  https://github.com/trewes/ZykovColor",
      "pdf_url": "http://arxiv.org/pdf/2504.04821v1",
      "published_date": "2025-04-07 08:22:00 UTC",
      "updated_date": "2025-04-07 08:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:38:04.992563"
    },
    {
      "arxiv_id": "2504.04808v2",
      "title": "ELT-Bench: An End-to-End Benchmark for Evaluating AI Agents on ELT Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Tengjun Jin",
        "Yuxuan Zhu",
        "Daniel Kang"
      ],
      "abstract": "Practitioners are increasingly turning to Extract-Load-Transform (ELT)\npipelines with the widespread adoption of cloud data warehouses. However,\ndesigning these pipelines often involves significant manual work to ensure\ncorrectness. Recent advances in AI-based methods, which have shown strong\ncapabilities in data tasks, such as text-to-SQL, present an opportunity to\nalleviate manual efforts in developing ELT pipelines. Unfortunately, current\nbenchmarks in data engineering only evaluate isolated tasks, such as using data\ntools and writing data transformation queries, leaving a significant gap in\nevaluating AI agents for generating end-to-end ELT pipelines.\n  To fill this gap, we introduce ELT-Bench, an end-to-end benchmark designed to\nassess the capabilities of AI agents to build ELT pipelines. ELT-Bench consists\nof 100 pipelines, including 835 source tables and 203 data models across\nvarious domains. By simulating realistic scenarios involving the integration of\ndiverse data sources and the use of popular data tools, ELT-Bench evaluates AI\nagents' abilities in handling complex data engineering workflows. AI agents\nmust interact with databases and data tools, write code and SQL queries, and\norchestrate every pipeline stage. We evaluate two representative code agent\nframeworks, Spider-Agent and SWE-Agent, using six popular Large Language Models\n(LLMs) on ELT-Bench. The highest-performing agent, Spider-Agent\nClaude-3.7-Sonnet with extended thinking, correctly generates only 3.9% of data\nmodels, with an average cost of $4.30 and 89.3 steps per pipeline. Our\nexperimental results demonstrate the challenges of ELT-Bench and highlight the\nneed for a more advanced AI agent to reduce manual effort in ELT workflows. Our\ncode and data are available at https://github.com/uiuc-kang-lab/ELT-Bench.",
      "tldr_zh": "本文引入了 ELT-Bench，这是一个端到端的基准，用于评估 AI agents 在 Extract-Load-Transform (ELT) 管道上的整体性能，旨在填补现有基准只评估孤立任务（如数据工具使用和 SQL 查询编写）的空白。ELT-Bench 包含 100 个管道、835 个源表和 203 个数据模型，模拟真实场景要求 AI agents 与数据库交互、编写代码和 SQL 查询，并编排整个工作流。实验结果显示，使用 Spider-Agent 和 SWE-Agent 等框架搭配六种 Large Language Models (LLMs)，最高性能代理仅正确生成 3.9% 的数据模型，平均成本为 4.30 美元和 89.3 步骤，突显了当前 AI agents 在 ELT 工作流中的挑战，并强调需要更先进的解决方案来减少手动努力。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "14 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04808v2",
      "published_date": "2025-04-07 08:03:36 UTC",
      "updated_date": "2025-04-14 19:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:38:17.991118"
    },
    {
      "arxiv_id": "2504.04789v1",
      "title": "Multimodal Agricultural Agent Architecture (MA3): A New Paradigm for Intelligent Agricultural Decision-Making",
      "title_zh": "多模态农业智能体架构 (MA3)：智能农业决策的新范",
      "authors": [
        "Zhuoning Xu",
        "Jian Xu",
        "Mingqing Zhang",
        "Peijie Wang",
        "Chao Deng",
        "Cheng-Lin Liu"
      ],
      "abstract": "As a strategic pillar industry for human survival and development, modern\nagriculture faces dual challenges: optimizing production efficiency and\nachieving sustainable development. Against the backdrop of intensified climate\nchange leading to frequent extreme weather events, the uncertainty risks in\nagricultural production systems are increasing exponentially. To address these\nchallenges, this study proposes an innovative \\textbf{M}ultimodal\n\\textbf{A}gricultural \\textbf{A}gent \\textbf{A}rchitecture (\\textbf{MA3}),\nwhich leverages cross-modal information fusion and task collaboration\nmechanisms to achieve intelligent agricultural decision-making. This study\nconstructs a multimodal agricultural agent dataset encompassing five major\ntasks: classification, detection, Visual Question Answering (VQA), tool\nselection, and agent evaluation. We propose a unified backbone for sugarcane\ndisease classification and detection tools, as well as a sugarcane disease\nexpert model. By integrating an innovative tool selection module, we develop a\nmultimodal agricultural agent capable of effectively performing tasks in\nclassification, detection, and VQA. Furthermore, we introduce a\nmulti-dimensional quantitative evaluation framework and conduct a comprehensive\nassessment of the entire architecture over our evaluation dataset, thereby\nverifying the practicality and robustness of MA3 in agricultural scenarios.\nThis study provides new insights and methodologies for the development of\nagricultural agents, holding significant theoretical and practical\nimplications. Our source code and dataset will be made publicly available upon\nacceptance.",
      "tldr_zh": "本研究提出Multimodal Agricultural Agent Architecture (MA3)，一种创新框架，通过跨模态信息融合和任务协作机制，应对现代农业在生产效率优化和可持续性方面的挑战，尤其是在气候变化引发的极端天气不确定性下。研究构建了一个多模态农业代理数据集，涵盖分类、检测、Visual Question Answering (VQA)、工具选择和代理评估五大任务，并开发了统一骨干网络用于甘蔗病害分类和检测，以及甘蔗病害专家模型和工具选择模块，以实现高效的农业决策。实验通过多维量化评估框架验证了MA3在农业场景中的实用性和鲁棒性，为智能农业代理的发展提供了新见解和方法论，源代码及数据集将在接受后公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04789v1",
      "published_date": "2025-04-07 07:32:41 UTC",
      "updated_date": "2025-04-07 07:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:38:29.154618"
    },
    {
      "arxiv_id": "2504.04787v1",
      "title": "Dynamic Vision Mamba",
      "title_zh": "动态视觉 Mamba",
      "authors": [
        "Mengxuan Wu",
        "Zekai Li",
        "Zhiyuan Liang",
        "Moyang Li",
        "Xuanlei Zhao",
        "Samir Khaki",
        "Zheng Zhu",
        "Xiaojiang Peng",
        "Konstantinos N. Plataniotis",
        "Kai Wang",
        "Wangbo Zhao",
        "Yang You"
      ],
      "abstract": "Mamba-based vision models have gained extensive attention as a result of\nbeing computationally more efficient than attention-based models. However,\nspatial redundancy still exists in these models, represented by token and block\nredundancy. For token redundancy, we analytically find that early token pruning\nmethods will result in inconsistency between training and inference or\nintroduce extra computation for inference. Therefore, we customize token\npruning to fit the Mamba structure by rearranging the pruned sequence before\nfeeding it into the next Mamba block. For block redundancy, we allow each image\nto select SSM blocks dynamically based on an empirical observation that the\ninference speed of Mamba-based vision models is largely affected by the number\nof SSM blocks. Our proposed method, Dynamic Vision Mamba (DyVM), effectively\nreduces FLOPs with minor performance drops. We achieve a reduction of 35.2\\%\nFLOPs with only a loss of accuracy of 1.7\\% on Vim-S. It also generalizes well\nacross different Mamba vision model architectures and different vision tasks.\nOur code will be made public.",
      "tldr_zh": "该研究提出 Dynamic Vision Mamba (DyVM)，一种针对 Mamba-based vision models 的高效框架，用于解决 token redundancy 和 block redundancy 的空间冗余问题。通过自定义 token pruning（在下一个 Mamba block 前重新排列序列）和动态选择 SSM blocks，DyVM 显著减少计算量，同时保持性能最小损失。在 Vim-S 数据集上，该方法实现了 35.2% FLOPs 的减少，仅损失 1.7% 准确率，并适用于不同 Mamba 架构和视觉任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04787v1",
      "published_date": "2025-04-07 07:31:28 UTC",
      "updated_date": "2025-04-07 07:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:38:40.257799"
    },
    {
      "arxiv_id": "2504.04785v1",
      "title": "Weak-for-Strong: Training Weak Meta-Agent to Harness Strong Executors",
      "title_zh": "Weak-for-Strong：训练弱元代理以利用强执行器",
      "authors": [
        "Fan Nie",
        "Lan Feng",
        "Haotian Ye",
        "Weixin Liang",
        "Pan Lu",
        "Huaxiu Yao",
        "Alexandre Alahi",
        "James Zou"
      ],
      "abstract": "Efficiently leveraging of the capabilities of contemporary large language\nmodels (LLMs) is increasingly challenging, particularly when direct fine-tuning\nis expensive and often impractical. Existing training-free methods, including\nmanually or automated designed workflows, typically demand substantial human\neffort or yield suboptimal results. This paper proposes Weak-for-Strong\nHarnessing (W4S), a novel framework that customizes smaller, cost-efficient\nlanguage models to design and optimize workflows for harnessing stronger\nmodels. W4S formulates workflow design as a multi-turn markov decision process\nand introduces reinforcement learning for agentic workflow optimization (RLAO)\nto train a weak meta-agent. Through iterative interaction with the environment,\nthe meta-agent learns to design increasingly effective workflows without manual\nintervention. Empirical results demonstrate the superiority of W4S that our 7B\nmeta-agent, trained with just one GPU hour, outperforms the strongest baseline\nby 2.9% ~ 24.6% across eleven benchmarks, successfully elevating the\nperformance of state-of-the-art models such as GPT-3.5-Turbo and GPT-4o.\nNotably, W4S exhibits strong generalization capabilities across both seen and\nunseen tasks, offering an efficient, high-performing alternative to directly\nfine-tuning strong models.",
      "tldr_zh": "本论文提出 Weak-for-Strong Harnessing (W4S) 框架，使用较小的、成本高效的语言模型训练一个弱 meta-agent，来设计和优化工作流，以高效利用更强的 LLMs，而避免直接微调的高成本。W4S 将工作流设计视为多轮 Markov 决策过程，并引入强化学习 for agentic workflow optimization (RLAO)，让 meta-agent 通过与环境的迭代交互自动学习更有效的策略，无需人工干预。实验结果显示，训练仅需一个 GPU 小时的 7B meta-agent 在 11 个基准上比最强基线提升 2.9% ~ 24.6%，显著提高了 GPT-3.5-Turbo 和 GPT-4o 的性能，并展示了在已见和未见任务上的强泛化能力，提供了一个高效替代直接微调的方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04785v1",
      "published_date": "2025-04-07 07:27:31 UTC",
      "updated_date": "2025-04-07 07:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:38:52.576168"
    },
    {
      "arxiv_id": "2504.04770v1",
      "title": "Bidirectional Hierarchical Protein Multi-Modal Representation Learning",
      "title_zh": "双向层次蛋白质多模",
      "authors": [
        "Xuefeng Liu",
        "Songhao Jiang",
        "Chih-chan Tien",
        "Jinbo Xu",
        "Rick Stevens"
      ],
      "abstract": "Protein representation learning is critical for numerous biological tasks.\nRecently, large transformer-based protein language models (pLMs) pretrained on\nlarge scale protein sequences have demonstrated significant success in\nsequence-based tasks. However, pLMs lack structural information. Conversely,\ngraph neural networks (GNNs) designed to leverage 3D structural information\nhave shown promising generalization in protein-related prediction tasks, but\ntheir effectiveness is often constrained by the scarcity of labeled structural\ndata. Recognizing that sequence and structural representations are\ncomplementary perspectives of the same protein entity, we propose a multimodal\nbidirectional hierarchical fusion framework to effectively merge these\nmodalities. Our framework employs attention and gating mechanisms to enable\neffective interaction between pLMs-generated sequential representations and\nGNN-extracted structural features, improving information exchange and\nenhancement across layers of the neural network. Based on the framework, we\nfurther introduce local Bi-Hierarchical Fusion with gating and global\nBi-Hierarchical Fusion with multihead self-attention approaches. Through\nextensive experiments on a diverse set of protein-related tasks, our method\ndemonstrates consistent improvements over strong baselines and existing fusion\ntechniques in a variety of protein representation learning benchmarks,\nincluding react (enzyme/EC classification), model quality assessment (MQA),\nprotein-ligand binding affinity prediction (LBA), protein-protein binding site\nprediction (PPBS), and B cell epitopes prediction (BCEs). Our method\nestablishes a new state-of-the-art for multimodal protein representation\nlearning, emphasizing the efficacy of BIHIERARCHICAL FUSION in bridging\nsequence and structural modalities.",
      "tldr_zh": "本文提出一个多模态双向分层融合框架（Bi-Hierarchical Fusion），用于蛋白质表示学习，通过结合蛋白质语言模型（pLMs）的序列表示和图神经网络（GNNs）的结构表示，解决两者各自的局限性。框架采用注意力机制和门控机制，实现序列与结构特征的多层交互，包括局部和全局融合方法。实验在酶分类（react）、蛋白质模型质量评估（MQA）、蛋白-配体结合亲和力预测（LBA）等任务上，展现出显著改进，超越现有基线并确立了蛋白质多模态表示学习的新最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04770v1",
      "published_date": "2025-04-07 06:47:49 UTC",
      "updated_date": "2025-04-07 06:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:39:04.371009"
    },
    {
      "arxiv_id": "2504.04766v1",
      "title": "KunPeng: A Global Ocean Environmental Model",
      "title_zh": "KunPeng：全球海洋环境模型",
      "authors": [
        "Yi Zhao",
        "Jiaqi Li",
        "Haitao Xia",
        "Tianjiao Zhang",
        "Zerong Zeng",
        "Tianyu Ren",
        "Yucheng Zhang",
        "Chao Zhu",
        "Shengtong Xu",
        "Hongchun Yuan"
      ],
      "abstract": "Inspired by the similarity of the atmosphere-ocean physical coupling\nmechanism, this study innovatively migrates meteorological large-model\ntechniques to the ocean domain, constructing the KunPeng global ocean\nenvironmental prediction model. Aimed at the discontinuous characteristics of\nmarine space, we propose a terrain-adaptive mask constraint mechanism to\nmitigate effectively training divergence caused by abrupt gradients at land-sea\nboundaries. To fully integrate far-, medium-, and close-range marine features,\na longitude-cyclic deformable convolution network (LC-DCN) is employed to\nenhance the dynamic receptive field, achieving refined modeling of multi-scale\noceanic characteristics. A Deformable Convolution-enhanced Multi-Step\nPrediction module (DC-MTP) is employed to strengthen temporal dependency\nfeature extraction capabilities. Experimental results demonstrate that this\nmodel achieves an average ACC of 0.80 in 15-day global predictions at\n0.25$^\\circ$ resolution, outperforming comparative models by 0.01-0.08. The\naverage mean squared error (MSE) is 0.41 (representing a 5%-31% reduction) and\nthe average mean absolute error (MAE) is 0.44 (0.6%-21% reduction) compared to\nother models. Significant improvements are particularly observed in sea surface\nparameter prediction, deep-sea region characterization, and current velocity\nfield forecasting. Through a horizontal comparison of the applicability of\noperators at different scales in the marine domain, this study reveals that\nlocal operators significantly outperform global operators under slow-varying\noceanic processes, demonstrating the effectiveness of dynamic feature pyramid\nrepresentations in predicting marine physical parameters.",
      "tldr_zh": "这篇论文受大气-海洋物理耦合机制启发，将气象大模型技术迁移到海洋领域，构建了 KunPeng 全球海洋环境预测模型，以实现精确的海洋参数预测。论文提出地形自适应掩码约束机制、经度循环可变形卷积网络 (LC-DCN) 和 Deformable Convolution-enhanced Multi-Step Prediction 模块 (DC-MTP)，用于缓解陆海边界训练问题、整合多尺度海洋特征并加强时间依赖提取。实验结果显示，KunPeng 在 0.25° 分辨率的 15 天全球预测中，平均 ACC 达 0.80，比其他模型高 0.01-0.08，同时 MSE 和 MAE 分别降低 5%-31% 和 0.6%-21%，特别是在海面参数预测、深海区域表征和流速场预测方面表现出显著优势；此外，研究发现局部操作符在缓慢变化的海洋过程中优于全局操作符，验证了动态特征金字塔表示的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04766v1",
      "published_date": "2025-04-07 06:41:05 UTC",
      "updated_date": "2025-04-07 06:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:39:18.615177"
    },
    {
      "arxiv_id": "2504.04764v1",
      "title": "Enhancing Leaf Disease Classification Using GAT-GCN Hybrid Model",
      "title_zh": "使用 GAT-GCN 混合模型增强叶病分类",
      "authors": [
        "Shyam Sundhar",
        "Riya Sharma",
        "Priyansh Maheshwari",
        "Suvidha Rupesh Kumar",
        "T. Sunil Kumar"
      ],
      "abstract": "Agriculture plays a critical role in the global economy, providing\nlivelihoods and ensuring food security for billions. As innovative agricultural\npractices become more widespread, the risk of crop diseases has increased,\nhighlighting the urgent need for efficient, low-intervention disease\nidentification methods. This research presents a hybrid model combining Graph\nAttention Networks (GATs) and Graph Convolution Networks (GCNs) for leaf\ndisease classification. GCNs have been widely used for learning from\ngraph-structured data, and GATs enhance this by incorporating attention\nmechanisms to focus on the most important neighbors. The methodology integrates\nsuperpixel segmentation for efficient feature extraction, partitioning images\ninto meaningful, homogeneous regions that better capture localized features.\nThe authors have employed an edge augmentation technique to enhance the\nrobustness of the model. The edge augmentation technique has introduced a\nsignificant degree of generalization in the detection capabilities of the\nmodel. To further optimize training, weight initialization techniques are\napplied. The hybrid model is evaluated against the individual performance of\nthe GCN and GAT models and the hybrid model achieved a precision of 0.9822,\nrecall of 0.9818, and F1-score of 0.9818 in apple leaf disease classification,\na precision of 0.9746, recall of 0.9744, and F1-score of 0.9743 in potato leaf\ndisease classification, and a precision of 0.8801, recall of 0.8801, and\nF1-score of 0.8799 in sugarcane leaf disease classification. These results\ndemonstrate the robustness and performance of the model, suggesting its\npotential to support sustainable agricultural practices through precise and\neffective disease detection. This work is a small step towards reducing the\nloss of crops and hence supporting sustainable goals of zero hunger and life on\nland.",
      "tldr_zh": "本研究提出了一种结合 Graph Attention Networks (GATs) 和 Graph Convolution Networks (GCNs) 的混合模型，用于提升叶病分类的准确性，以应对农业中作物疾病识别的挑战。该模型通过超像素分割（superpixel segmentation）进行高效特征提取，并采用边增强技术（edge augmentation）和权重初始化技术优化训练，提高了模型的鲁棒性和泛化能力。在评估中，该混合模型在苹果叶病分类中达到精度0.9822、召回率0.9818和F1分数0.9818，在土豆和甘蔗叶病分类中也表现出色，优于单独的GCN或GAT模型。这些结果表明，该方法有助于精确检测作物疾病，减少损失，并支持可持续农业目标如零饥饿和陆地生命保护。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04764v1",
      "published_date": "2025-04-07 06:31:38 UTC",
      "updated_date": "2025-04-07 06:31:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:39:28.613013"
    },
    {
      "arxiv_id": "2504.13898v1",
      "title": "The Human Robot Social Interaction (HSRI) Dataset: Benchmarking Foundational Models' Social Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Won Lee",
        "Yubin Kim",
        "Denison Guvenoz",
        "Sooyeon Jeong",
        "Parker Malachowsky",
        "Louis-Philippe Morency",
        "Cynthia Breazeal",
        "Hae Won Park"
      ],
      "abstract": "Our work aims to advance the social reasoning of embodied artificial\nintelligence (AI) agents in real-world social interactions. Recently, language\nmodels (LMs) and foundational models (FMs) are being utilized as automatic\nevaluators of human-AI interactions with the goal of eventually being used to\nimprove the policy of the AI agent. To enable further research in this\ndirection, we introduce a large-scale real-world Human Robot Social Interaction\n(HSRI) Dataset to benchmark the capabilities of LMs and FMs to identify and\nreason about social interactions, specifically with regard to robot social\nerrors and competencies . Our dataset consists of 400 real-world human social\nrobot interaction videos and over 10K annotations, detailing the robot's social\nerrors, competencies, rationale, and corrective actions, capturing unique\naspects of human-AI interaction only present in real-world interactions. To\nfurther assess AI models' ability to reason about social interactions, we\npropose eight new benchmark tasks for evaluating centered around whether AI\nmodels can (1) evaluate social interactions via detecting social errors and\ncompetencies, (2) identify the explanatory factors associated to errors and\ncompetencies, (3) understand the flow of real-world social interactions, and\n(4) provide reasons and corrective actions for social errors. Human studies and\nexperiments with modern LMs and FMs reveal that current models struggle with\nthese tasks, demonstrating that our dataset and benchmark provides a step\nforward towards socially intelligent AI.",
      "tldr_zh": "这篇论文引入了 Human Robot Social Interaction (HSRI) 数据集，用于基准测试 foundational models (FMs) 和 language models (LMs) 在真实世界社交互动中的社交推理能力。数据集包含 400 个真实人类-机器人互动视频和超过 10K 注解，详细记录机器人的社交错误、能力、理由以及纠正措施，捕捉真实互动的独特方面。研究提出了八个新基准任务，包括检测社交错误和能力、识别相关解释因素、理解互动流程以及为错误提供理由和纠正建议。实验结果显示，当前 FMs 和 LMs 在这些任务上表现不佳，突显了该数据集在推动社交智能 AI 发展方面的关键作用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.13898v1",
      "published_date": "2025-04-07 06:27:02 UTC",
      "updated_date": "2025-04-07 06:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:39:41.524442"
    },
    {
      "arxiv_id": "2504.04751v1",
      "title": "Unsupervised Estimation of Nonlinear Audio Effects: Comparing Diffusion-Based and Adversarial approaches",
      "title_zh": "无监督估计非线性音频效果：比较基于",
      "authors": [
        "Eloi Moliner",
        "Michal Švento",
        "Alec Wright",
        "Lauri Juvela",
        "Pavel Rajmic",
        "Vesa Välimäki"
      ],
      "abstract": "Accurately estimating nonlinear audio effects without access to paired\ninput-output signals remains a challenging problem.This work studies\nunsupervised probabilistic approaches for solving this task. We introduce a\nmethod, novel for this application, based on diffusion generative models for\nblind system identification, enabling the estimation of unknown nonlinear\neffects using black- and gray-box models. This study compares this method with\na previously proposed adversarial approach, analyzing the performance of both\nmethods under different parameterizations of the effect operator and varying\nlengths of available effected recordings.Through experiments on guitar\ndistortion effects, we show that the diffusion-based approach provides more\nstable results and is less sensitive to data availability, while the\nadversarial approach is superior at estimating more pronounced distortion\neffects. Our findings contribute to the robust unsupervised blind estimation of\naudio effects, demonstrating the potential of diffusion models for system\nidentification in music technology.",
      "tldr_zh": "该研究探讨了无监督估计非线性音频效果的挑战，提出了一种基于diffusion generative models的新方法，用于blind system identification，以估计未知的非线性效果，支持黑盒和灰盒模型。该方法与之前提出的adversarial approach进行了比较，实验在不同参数化和录音长度条件下评估了二者的性能。在吉他失真效果的测试中，diffusion-based方法显示出更稳定的结果且对数据可用性不敏感，而adversarial approach在估计更明显的失真效果时表现出色。该工作为音频效果的鲁棒无监督盲估计提供了新见解，并突显了diffusion models在音乐技术中的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to the 28th International Conference on Digital Audio\n  Effects (DAFx25)",
      "pdf_url": "http://arxiv.org/pdf/2504.04751v1",
      "published_date": "2025-04-07 05:56:51 UTC",
      "updated_date": "2025-04-07 05:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:39:52.136082"
    },
    {
      "arxiv_id": "2504.04744v1",
      "title": "Grounding 3D Object Affordance with Language Instructions, Visual Observations and Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "He Zhu",
        "Quyu Kong",
        "Kechun Xu",
        "Xunlong Xia",
        "Bing Deng",
        "Jieping Ye",
        "Rong Xiong",
        "Yue Wang"
      ],
      "abstract": "Grounding 3D object affordance is a task that locates objects in 3D space\nwhere they can be manipulated, which links perception and action for embodied\nintelligence. For example, for an intelligent robot, it is necessary to\naccurately ground the affordance of an object and grasp it according to human\ninstructions. In this paper, we introduce a novel task that grounds 3D object\naffordance based on language instructions, visual observations and\ninteractions, which is inspired by cognitive science. We collect an Affordance\nGrounding dataset with Points, Images and Language instructions (AGPIL) to\nsupport the proposed task. In the 3D physical world, due to observation\norientation, object rotation, or spatial occlusion, we can only get a partial\nobservation of the object. So this dataset includes affordance estimations of\nobjects from full-view, partial-view, and rotation-view perspectives. To\naccomplish this task, we propose LMAffordance3D, the first multi-modal,\nlanguage-guided 3D affordance grounding network, which applies a\nvision-language model to fuse 2D and 3D spatial features with semantic\nfeatures. Comprehensive experiments on AGPIL demonstrate the effectiveness and\nsuperiority of our method on this task, even in unseen experimental settings.\nOur project is available at https://sites.google.com/view/lmaffordance3d.",
      "tldr_zh": "这篇论文提出了一种新任务，即基于语言指令、视觉观察和交互来定位3D物体可操作性（Grounding 3D Object Affordance），以桥接具身智能中的感知和行动，并受认知科学启发。作者构建了AGPIL数据集，包括点云、图像和语言指令，并覆盖全视图、部分视图和旋转视图，以处理现实世界中物体部分遮挡的问题。论文引入了LMAffordance3D模型，这是首个多模态、语言引导的3D可操作性网络，使用vision-language model融合2D和3D空间特征与语义特征。在AGPIL数据集上的实验证明，该方法在各种设置中表现出色，甚至在未见场景中也具有显著优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.04744v1",
      "published_date": "2025-04-07 05:38:23 UTC",
      "updated_date": "2025-04-07 05:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:40:05.206361"
    },
    {
      "arxiv_id": "2504.04740v1",
      "title": "Enhancing Compositional Reasoning in Vision-Language Models with Synthetic Preference Data",
      "title_zh": "使用合成偏好数据增强视觉语言模型的组合推理",
      "authors": [
        "Samarth Mishra",
        "Kate Saenko",
        "Venkatesh Saligrama"
      ],
      "abstract": "Compositionality, or correctly recognizing scenes as compositions of atomic\nvisual concepts, remains difficult for multimodal large language models\n(MLLMs). Even state of the art MLLMs such as GPT-4o can make mistakes in\ndistinguishing compositions like \"dog chasing cat\" vs \"cat chasing dog\". While\non Winoground, a benchmark for measuring such reasoning, MLLMs have made\nsignificant progress, they are still far from a human's performance. We show\nthat compositional reasoning in these models can be improved by elucidating\nsuch concepts via data, where a model is trained to prefer the correct caption\nfor an image over a close but incorrect one. We introduce SCRAMBLe: Synthetic\nCompositional Reasoning Augmentation of MLLMs with Binary preference Learning,\nan approach for preference tuning open-weight MLLMs on synthetic preference\ndata generated in a fully automated manner from existing image-caption data.\nSCRAMBLe holistically improves these MLLMs' compositional reasoning\ncapabilities which we can see through significant improvements across multiple\nvision language compositionality benchmarks, as well as smaller but significant\nimprovements on general question answering tasks. As a sneak peek, SCRAMBLe\ntuned Molmo-7B model improves on Winoground from 49.5% to 54.8% (best reported\nto date), while improving by ~1% on more general visual question answering\ntasks. Code for SCRAMBLe along with tuned models and our synthetic training\ndataset is available at https://github.com/samarth4149/SCRAMBLe.",
      "tldr_zh": "这项研究针对多模态大语言模型(MLLMs)在组合性推理上的不足，例如难以区分像“dog chasing cat”与“cat chasing dog”的场景，提出了一种SCRAMBLe方法来提升模型性能。SCRAMBLe通过从现有图像-描述数据中自动生成合成偏好数据，并采用二元偏好学习对开源MLLMs进行微调，训练模型优先选择正确的图像描述。实验结果显示，该方法在多个视觉语言组合性基准上显著改善推理能力，如将Molmo-7B模型在Winoground上的表现从49.5%提升至54.8%，并在一般视觉问答任务上获得约1%的提升。该框架的代码、调整模型和合成数据集已在GitHub上公开，提供可复现的研究资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04740v1",
      "published_date": "2025-04-07 05:35:34 UTC",
      "updated_date": "2025-04-07 05:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:40:16.901143"
    },
    {
      "arxiv_id": "2504.04737v1",
      "title": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context",
      "title_zh": "TathyaNyaya 和 FactLegalLlama：推进印度法律语境中的事实判断预测和解释",
      "authors": [
        "Shubham Kumar Nigam",
        "Balaramamahanthi Deepak Patnaik",
        "Shivam Mishra",
        "Noel Shallum",
        "Kripabandhu Ghosh",
        "Arnab Bhattacharya"
      ],
      "abstract": "In the landscape of Fact-based Judgment Prediction and Explanation (FJPE),\nreliance on factual data is essential for developing robust and realistic\nAI-driven decision-making tools. This paper introduces TathyaNyaya, the largest\nannotated dataset for FJPE tailored to the Indian legal context, encompassing\njudgments from the Supreme Court of India and various High Courts. Derived from\nthe Hindi terms \"Tathya\" (fact) and \"Nyaya\" (justice), the TathyaNyaya dataset\nis uniquely designed to focus on factual statements rather than complete legal\ntexts, reflecting real-world judicial processes where factual data drives\noutcomes. Complementing this dataset, we present FactLegalLlama, an\ninstruction-tuned variant of the LLaMa-3-8B Large Language Model (LLM),\noptimized for generating high-quality explanations in FJPE tasks. Finetuned on\nthe factual data in TathyaNyaya, FactLegalLlama integrates predictive accuracy\nwith coherent, contextually relevant explanations, addressing the critical need\nfor transparency and interpretability in AI-assisted legal systems. Our\nmethodology combines transformers for binary judgment prediction with\nFactLegalLlama for explanation generation, creating a robust framework for\nadvancing FJPE in the Indian legal domain. TathyaNyaya not only surpasses\nexisting datasets in scale and diversity but also establishes a benchmark for\nbuilding explainable AI systems in legal analysis. The findings underscore the\nimportance of factual precision and domain-specific tuning in enhancing\npredictive performance and interpretability, positioning TathyaNyaya and\nFactLegalLlama as foundational resources for AI-assisted legal decision-making.",
      "tldr_zh": "本论文介绍了TathyaNyaya，这是一个针对印度法律背景的最大FJPE（Fact-based Judgment Prediction and Explanation）数据集，涵盖印度最高法院和高等法院的判决事实陈述，以提升AI决策工具的准确性和真实性。论文同时提出FactLegalLlama，一种基于LLaMa-3-8B LLM的指令调整模型，通过在TathyaNyaya数据集上微调，结合transformer进行二元判断预测并生成上下文相关的解释，从而提高法律分析的可解释性和透明度。实验结果显示，TathyaNyaya在规模和多样性上超越现有数据集，并为AI辅助法律决策建立基准，强调了事实精确性和领域特定调整的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04737v1",
      "published_date": "2025-04-07 05:27:32 UTC",
      "updated_date": "2025-04-07 05:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:40:28.117990"
    },
    {
      "arxiv_id": "2504.04736v2",
      "title": "Synthetic Data Generation & Multi-Step RL for Reasoning & Tool Use",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Goldie",
        "Azalia Mirhoseini",
        "Hao Zhou",
        "Irene Cai",
        "Christopher D. Manning"
      ],
      "abstract": "Reinforcement learning has been shown to improve the performance of large\nlanguage models. However, traditional approaches like RLHF or RLAIF treat the\nproblem as single-step. As focus shifts toward more complex reasoning and\nagentic tasks, language models must take multiple steps of text generation,\nreasoning and environment interaction before generating a solution. We propose\na synthetic data generation and RL methodology targeting multi-step\noptimization scenarios. This approach, called Step-Wise Reinforcement Learning\n(SWiRL), iteratively generates multi-step reasoning and tool use data, and then\nlearns from that data. It employs a simple step-wise decomposition that breaks\neach multi-step trajectory into multiple sub-trajectories corresponding to each\naction by the original model. It then applies synthetic data filtering and RL\noptimization on these sub-trajectories. We evaluated SWiRL on a number of\nmulti-step tool use, question answering, and mathematical reasoning tasks. Our\nexperiments show that SWiRL outperforms baseline approaches by 21.5%, 12.3%,\n14.8%, 11.1%, and 15.3% in relative accuracy on GSM8K, HotPotQA, CofCA,\nMuSiQue, and BeerQA, respectively. Excitingly, the approach exhibits\ngeneralization across tasks: for example, training only on HotPotQA (text\nquestion-answering) improves zero-shot performance on GSM8K (a math dataset) by\na relative 16.9%.",
      "tldr_zh": "本研究提出了一种名为 SWiRL 的 Step-Wise Reinforcement Learning 方法，针对强化学习（RL）在多步推理和工具使用场景中的应用，解决传统方法如 RLHF 或 RLAIF 的单步局限性。SWiRL 通过合成数据生成和迭代优化，将多步轨迹分解为子轨迹，进行数据过滤和 RL 训练，从而提升语言模型在复杂任务中的性能。在实验中，SWiRL 在 GSM8K、HotPotQA、CofCA、MuSiQue 和 BeerQA 等任务上分别实现了 21.5%、12.3%、14.8%、11.1% 和 15.3% 的相对准确率提升，并展示了任务间泛化能力，例如仅在 HotPotQA 上训练后，零样本在 GSM8K 上提升了 16.9%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04736v2",
      "published_date": "2025-04-07 05:20:58 UTC",
      "updated_date": "2025-04-28 01:20:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:40:40.806968"
    },
    {
      "arxiv_id": "2504.05352v1",
      "title": "Achieving binary weight and activation for LLMs using Post-Training Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Siqing Song",
        "Chuang Wang",
        "Ruiqi Wang",
        "Yi Yang",
        "Xuyao Zhang"
      ],
      "abstract": "Quantizing large language models (LLMs) to 1-bit precision significantly\nreduces computational costs, but existing quantization techniques suffer from\nnoticeable performance degradation when using weight and activation precisions\nbelow 4 bits (W4A4). In this paper, we propose a post-training quantization\nframework with W(1+1)A(1*4) configuration, where weights are quantized to 1 bit\nwith an additional 1 bit for fine-grain grouping and activations are quantized\nto 1 bit with a 4-fold increase in the number of channels. For weight\nquantization, we propose utilizing Hessian-aware fine-grained grouping along\nwith an EM-based quantization scheme. For activation quantization, we decompose\nINT4-quantized activations into a 4 * INT1 format equivalently and\nsimultaneously smooth the scaling factors based on quantization errors, which\nfurther reduces the quantization errors in activations. Our method surpasses\nstate-of-the-art (SOTA) LLM quantization baselines on W2A4 across multiple\ntasks, pushing the boundaries of existing LLM quantization methods toward fully\nbinarized models.",
      "tldr_zh": "该论文提出了一种后训练量化框架，用于实现大语言模型（LLMs）的二值化权重和激活，显著降低计算成本，同时缓解现有技术在低于 4 位精度时的性能下降问题。框架采用 W(1+1)A(1*4) 配置，其中权重通过 Hessian-aware 细粒度分组和基于 EM 的量化方案进行处理，激活则被分解为 4 * INT1 格式并通过量化错误平滑缩放因子以减少误差。该方法在多个任务上超越了现有 SOTA LLM 量化基线，推动了向完全二值化模型的边界扩展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05352v1",
      "published_date": "2025-04-07 04:50:04 UTC",
      "updated_date": "2025-04-07 04:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:40:52.899353"
    },
    {
      "arxiv_id": "2504.04718v1",
      "title": "T1: Tool-integrated Self-verification for Test-time Compute Scaling in Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Minki Kang",
        "Jongwon Jeong",
        "Jaewoong Cho"
      ],
      "abstract": "Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.",
      "tldr_zh": "本研究探讨了小语言模型 (sLMs) 在 test-time compute scaling 中的自验证能力，发现 sLMs 难以处理需要记忆的任务，如数值计算和事实检查，即使经过知识蒸馏。针对这一问题，提出 T1 方法，即 Tool-integrated self-verification，通过委托记忆密集型步骤给外部工具（如代码解释器），减少记忆需求并提升性能。实验结果显示，在 MATH 基准上，使用 T1 的 Llama-3.2 1B 模型超过了更大的 Llama-3.1 8B 模型，且 T1 在数学任务 (MATH500) 和多领域知识密集任务 (MMLU-Pro) 上具有良好泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.04718v1",
      "published_date": "2025-04-07 04:01:17 UTC",
      "updated_date": "2025-04-07 04:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:41:05.532299"
    },
    {
      "arxiv_id": "2504.04717v4",
      "title": "Beyond Single-Turn: A Survey on Multi-Turn Interactions with Large Language Models",
      "title_zh": "超越单轮：大型语言模型多轮互动的调查",
      "authors": [
        "Yubo Li",
        "Xiaobin Shen",
        "Xinyu Yao",
        "Xueying Ding",
        "Yidi Miao",
        "Ramayya Krishnan",
        "Rema Padman"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have revolutionized their\nability to handle single-turn tasks, yet real-world applications demand\nsophisticated multi-turn interactions. This survey provides a comprehensive\nreview of recent advancements in evaluating and enhancing multi-turn\ninteractions in LLMs. Focusing on task-specific scenarios, from instruction\nfollowing in diverse domains such as math and coding to complex conversational\nengagements in roleplay, healthcare, education, and even adversarial jailbreak\nsettings, we systematically examine the challenges of maintaining context,\ncoherence, fairness, and responsiveness over prolonged dialogues. The paper\norganizes current benchmarks and datasets into coherent categories that reflect\nthe evolving landscape of multi-turn dialogue evaluation. In addition, we\nreview a range of enhancement methodologies under multi-turn settings,\nincluding model-centric strategies (contextual learning, supervised\nfine-tuning, reinforcement learning, and new architectures), external\nintegration approaches (memory-augmented, retrieval-based methods, and\nknowledge graph), and agent-based techniques for collaborative interactions.\nFinally, we discuss open challenges and propose future directions for research\nto further advance the robustness and effectiveness of multi-turn interactions\nin LLMs. Related resources and papers are available at\nhttps://github.com/yubol-cmu/Awesome-Multi-Turn-LLMs.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)在多轮交互中的最新进展，超越了单轮任务的局限，聚焦于真实场景如指令遵循、角色扮演、健康教育和对抗性对话。论文系统地审查了评估挑战，包括维护上下文、一致性、公平性和响应性，并组织了相关基准和数据集以分类多轮对话。针对增强方法，它涵盖了模型中心策略（如上下文学习、监督微调和强化学习）、外部集成（如记忆增强和检索-based 方法）以及基于代理的协作技术。最后，论文讨论了开放挑战并提出未来方向，以提升LLMs的多轮交互鲁棒性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04717v4",
      "published_date": "2025-04-07 04:00:08 UTC",
      "updated_date": "2025-05-14 01:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:41:17.267186"
    },
    {
      "arxiv_id": "2504.04711v1",
      "title": "Generalising from Self-Produced Data: Model Training Beyond Human Constraints",
      "title_zh": "从自我产生的数据中泛化：超越人类约束的模型训练",
      "authors": [
        "Alfath Daryl Alhajir",
        "Jennifer Dodgson",
        "Joseph Lim",
        "Truong Ma Phi",
        "Julian Peh",
        "Akira Rafhael Janson Pattirane",
        "Lokesh Poovaragan"
      ],
      "abstract": "Current large language models (LLMs) are constrained by human-derived\ntraining data and limited by a single level of abstraction that impedes\ndefinitive truth judgments. This paper introduces a novel framework in which AI\nmodels autonomously generate and validate new knowledge through direct\ninteraction with their environment. Central to this approach is an unbounded,\nungamable numeric reward - such as annexed disk space or follower count - that\nguides learning without requiring human benchmarks. AI agents iteratively\ngenerate strategies and executable code to maximize this metric, with\nsuccessful outcomes forming the basis for self-retraining and incremental\ngeneralisation. To mitigate model collapse and the warm start problem, the\nframework emphasizes empirical validation over textual similarity and supports\nfine-tuning via GRPO. The system architecture employs modular agents for\nenvironment analysis, strategy generation, and code synthesis, enabling\nscalable experimentation. This work outlines a pathway toward self-improving AI\nsystems capable of advancing beyond human-imposed constraints toward autonomous\ngeneral intelligence.",
      "tldr_zh": "本论文探讨了当前大型语言模型（LLMs）的局限性，即受人类数据约束和单一抽象水平的影响，导致难以进行准确真相判断。作者提出一个新框架，让AI模型通过与环境的直接互动自主生成和验证新知识，使用不受限的数值奖励（如磁盘空间或关注者数量）作为指导，避免依赖人类基准。框架中，AI代理迭代生成策略和可执行代码来最大化奖励，并基于成功结果进行自我再训练，同时通过经验验证和GRPO微调来缓解模型崩溃和启动问题。最终，该系统采用模块化代理架构，支持AI向超越人类约束的自主通用智能发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.04711v1",
      "published_date": "2025-04-07 03:48:02 UTC",
      "updated_date": "2025-04-07 03:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:41:29.513005"
    },
    {
      "arxiv_id": "2504.04706v1",
      "title": "AdvKT: An Adversarial Multi-Step Training Framework for Knowledge Tracing",
      "title_zh": "AdvKT：用于知识追踪的对抗多步训练框架",
      "authors": [
        "Lingyue Fu",
        "Ting Long",
        "Jianghao Lin",
        "Wei Xia",
        "Xinyi Dai",
        "Ruiming Tang",
        "Yasheng Wang",
        "Weinan Zhang",
        "Yong Yu"
      ],
      "abstract": "Knowledge Tracing (KT) monitors students' knowledge states and simulates\ntheir responses to question sequences. Existing KT models typically follow a\nsingle-step training paradigm, which leads to discrepancies with the multi-step\ninference process required in real-world simulations, resulting in significant\nerror accumulation. This accumulation of error, coupled with the issue of data\nsparsity, can substantially degrade the performance of recommendation models in\nthe intelligent tutoring systems. To address these challenges, we propose a\nnovel Adversarial Multi-Step Training Framework for Knowledge Tracing (AdvKT),\nwhich, for the first time, focuses on the multi-step KT task. More\nspecifically, AdvKT leverages adversarial learning paradigm involving a\ngenerator and a discriminator. The generator mimics high-reward responses,\neffectively reducing error accumulation across multiple steps, while the\ndiscriminator provides feedback to generate synthetic data. Additionally, we\ndesign specialized data augmentation techniques to enrich the training data\nwith realistic variations, ensuring that the model generalizes well even in\nscenarios with sparse data. Experiments conducted on four real-world datasets\ndemonstrate the superiority of AdvKT over existing KT models, showcasing its\nability to address both error accumulation and data sparsity issues\neffectively.",
      "tldr_zh": "该论文提出 AdvKT，一种对抗性多步训练框架，用于解决 Knowledge Tracing (KT) 模型在多步推理过程中存在的错误积累和数据稀疏问题。AdvKT 采用对抗学习范式，包括一个生成器来模拟高奖励响应以减少错误积累，以及一个判别器提供反馈生成合成数据；同时，框架还设计了专门的数据增强技术来丰富训练数据，提升模型的泛化能力。在四个真实数据集上的实验显示，AdvKT 显著优于现有 KT 模型，有效地改善了智能辅导系统的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04706v1",
      "published_date": "2025-04-07 03:31:57 UTC",
      "updated_date": "2025-04-07 03:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:41:41.084181"
    },
    {
      "arxiv_id": "2504.04704v1",
      "title": "LagKV: Lag-Relative Information of the KV Cache Tells Which Tokens Are Important",
      "title_zh": "翻译失败",
      "authors": [
        "Manlai Liang",
        "JiaMing Zhang",
        "Xiong Li",
        "Jinlong Li"
      ],
      "abstract": "The increasing size of the Key-Value (KV) cache during the Large Language\nModels long-context inference is the main obstacle for its balance between the\ndeployment cost and task accuracy. To reduce the KV cache size in such\nscenarios, most previous efforts leveraged on the attention weight to evict\nnon-critical cache tokens. But there is a trade-off in those methods, they\nusually require major modifiation of the inference infrastructure and\nsignificant computation overhead. Base on the fact that the Large Lanuage\nmodels are autoregresssive models, we propose {\\it LagKV}, a KV allocation\nstrategy only relying on straight forward comparison among KV themself. It is a\ntotally attention free method which offers easy integration to the main stream\ninference platform and comparable performance comparing to other complicated KV\ncompression methods. Results on LongBench and PasskeyRetrieval show that, our\napproach achieves nearly zero loss when the ratio is $2\\times$ and $\\approx\n90\\%$ of the original model performance for $8\\times$. Especially in the\n64-digit passkey retrieval task, our mehod outperforms the attention weight\nbased method $H_2O$ over $60\\%$ with same compression ratios. Our code is\navailable at \\url{https://github.com/AI-Lab-China-Merchants-Bank/LagKV}.",
      "tldr_zh": "这项研究针对大型语言模型(LLMs)中KV缓存大小增加导致的部署成本问题，提出LagKV策略，该方法基于KV缓存的滞后相对信息(Lag-Relative Information)进行直接比较，而非依赖注意力权重，从而避免了重大基础设施修改和计算开销。\nLagKV易于集成主流推理平台，并与复杂KV压缩方法相比表现出色。\n实验结果显示，在LongBench和PasskeyRetrieval基准测试中，LagKV在2倍压缩下几乎无性能损失，在8倍压缩下保留约90%原始模型性能；尤其在64位passkey检索任务中，它比注意力权重-based方法H2O高出60%以上。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04704v1",
      "published_date": "2025-04-07 03:22:15 UTC",
      "updated_date": "2025-04-07 03:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:41:53.820039"
    },
    {
      "arxiv_id": "2504.04702v1",
      "title": "Provable Failure of Language Models in Learning Majority Boolean Logic via Gradient Descent",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Chen",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang"
      ],
      "abstract": "Recent advancements in Transformer-based architectures have led to impressive\nbreakthroughs in natural language processing tasks, with models such as GPT-4,\nClaude, and Gemini demonstrating human-level reasoning abilities. However,\ndespite their high performance, concerns remain about the inherent limitations\nof these models, especially when it comes to learning basic logical functions.\nWhile complexity-theoretic analyses indicate that Transformers can represent\nsimple logic functions (e.g., $\\mathsf{AND}$, $\\mathsf{OR}$, and majority\ngates) by its nature of belonging to the $\\mathsf{TC}^0$ class, these results\nassume ideal parameter settings and do not account for the constraints imposed\nby gradient descent-based training methods. In this work, we investigate\nwhether Transformers can truly learn simple majority functions when trained\nusing gradient-based methods. We focus on a simplified variant of the\nTransformer architecture and consider both $n=\\mathrm{poly}(d)$ and\n$n=\\exp(\\Omega(d))$ number of training samples, where each sample is a $d$-size\nbinary string paired with the output of a basic majority function. Our analysis\ndemonstrates that even after $\\mathrm{poly}(d)$ gradient queries, the\ngeneralization error of the Transformer model still remains substantially\nlarge, growing exponentially with $d$. This work highlights fundamental\noptimization challenges in training Transformers for the simplest logical\nreasoning tasks and provides new insights into their theoretical limitations.",
      "tldr_zh": "本研究证明了Transformer模型在使用梯度下降训练时，无法有效学习简单majority Boolean逻辑函数，尽管理论上这些模型属于$\\mathsf{TC}^0$类并能表示基本逻辑门。研究者分析了简化Transformer架构，在$n=\\mathrm{poly}(d)$和$n=\\exp(\\Omega(d))$的训练样本下进行实验，结果显示即使经过$\\mathrm{poly}(d)$梯度查询，模型的泛化错误率仍随维度$d$指数增长。这一发现突出了Transformer在优化过程中的根本挑战，并为理解其在逻辑推理任务中的理论局限性提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04702v1",
      "published_date": "2025-04-07 03:08:12 UTC",
      "updated_date": "2025-04-07 03:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:42:05.875408"
    },
    {
      "arxiv_id": "2504.04699v1",
      "title": "R2Vul: Learning to Reason about Software Vulnerabilities with Reinforcement Learning and Structured Reasoning Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Weyssow",
        "Chengran Yang",
        "Junkai Chen",
        "Yikun Li",
        "Huihui Huang",
        "Ratnadira Widyasari",
        "Han Wei Ang",
        "Frank Liauw",
        "Eng Lieh Ouh",
        "Lwin Khin Shar",
        "David Lo"
      ],
      "abstract": "Large language models (LLMs) have shown promising performance in software\nvulnerability detection (SVD), yet their reasoning capabilities remain\nunreliable. Existing approaches relying on chain-of-thought (CoT) struggle to\nprovide relevant and actionable security assessments. Additionally, effective\nSVD requires not only generating coherent reasoning but also differentiating\nbetween well-founded and misleading yet plausible security assessments, an\naspect overlooked in prior work. To this end, we introduce R2Vul, a novel\napproach that distills structured reasoning into small LLMs using reinforcement\nlearning from AI feedback (RLAIF). Through RLAIF, R2Vul enables LLMs to produce\nstructured, security-aware reasoning that is actionable and reliable while\nexplicitly learning to distinguish valid assessments from misleading ones. We\nevaluate R2Vul across five languages against SAST tools, CoT, instruction\ntuning, and classification-based baselines. Our results show that R2Vul with\nstructured reasoning distillation enables a 1.5B student LLM to rival larger\nmodels while improving generalization to out-of-distribution vulnerabilities.\nBeyond model improvements, we contribute a large-scale, multilingual preference\ndataset featuring structured reasoning to support future research in SVD.",
      "tldr_zh": "本研究提出 R2Vul，一种新型方法，通过强化学习从 AI 反馈 (RLAIF) 和结构化推理蒸馏 (Structured Reasoning Distillation) 提升大型语言模型 (LLMs) 在软件漏洞检测 (SVD) 中的推理能力，以解决现有 Chain-of-Thought (CoT) 方法无法提供相关可操作安全评估的问题。R2Vul 训练小 LLMs 生成结构化、安全意识强的推理，并学会区分有效评估与误导性评估。实验结果显示，R2Vul 让 1.5B 学生 LLM 的性能可媲美更大模型，并在五种语言上超越 SAST 工具、CoT 和其他基准，同时提升了对分布外漏洞的泛化能力。该方法还贡献了一个大规模多语言偏好数据集，包含结构化推理，支持未来 SVD 研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04699v1",
      "published_date": "2025-04-07 03:04:16 UTC",
      "updated_date": "2025-04-07 03:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:42:17.623316"
    },
    {
      "arxiv_id": "2505.03745v1",
      "title": "AccLLM: Accelerating Long-Context LLM Inference Via Algorithm-Hardware Co-Design",
      "title_zh": "AccLLM：通过算法-硬件协同设计",
      "authors": [
        "Yanbiao Liang",
        "Huihong Shi",
        "Haikuo Shao",
        "Zhongfeng Wang"
      ],
      "abstract": "Recently, large language models (LLMs) have achieved huge success in the\nnatural language processing (NLP) field, driving a growing demand to extend\ntheir deployment from the cloud to edge devices. However, deploying LLMs on\nresource-constrained edge devices poses significant challenges, including (1)\nintensive computations and huge model sizes, (2) great memory and bandwidth\ndemands introduced by the autoregressive generation process, and (3) limited\nscalability for handling long sequences. To address these challenges, we\npropose AccLLM, a comprehensive acceleration framework that enables efficient\nand fast long-context LLM inference through algorithm and hardware co-design.\nAt the algorithmic level, we integrate (1) pruning, (2) {\\Lambda}-shaped\nattention, and (3) an innovative W2A8KV4 (2-bit weights, 8-bit activations, and\n4-bit KV cache) quantization scheme, thus effectively reducing memory and\nbandwidth requirements while facilitating LLMs' long-sequence generation. At\nthe hardware level, we design a dedicated FPGA-based accelerator with a\nreconfigurable computing engine to effectively and flexibly accommodate diverse\noperations arising from our compression algorithm, thereby fully translating\nthe algorithmic innovations into tangible hardware efficiency. We validate\nAccLLM on the Xilinx Alveo U280 FPGA, demonstrating a 4.07x energy efficiency\nand a 2.98x throughput compared to the state-of-the-art work FlightLLM.",
      "tldr_zh": "该论文提出AccLLM框架，通过算法和硬件协同设计，加速长上下文LLM推理，以应对LLMs部署到资源受限边缘设备面临的计算密集、内存带宽需求高和长序列处理挑战。在算法层面，AccLLM整合pruning、Λ-shaped attention以及W2A8KV4量化方案（2-bit weights、8-bit activations和4-bit KV cache），有效降低内存和带宽消耗，支持高效长序列生成。在硬件层面，该框架设计了基于FPGA的专用加速器，配备可重构计算引擎，以灵活适应各种操作并提升硬件效率。实验结果显示，在Xilinx Alveo U280 FPGA上，AccLLM相较于FlightLLM实现了4.07倍的能量效率和2.98倍的吞吐量改进。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03745v1",
      "published_date": "2025-04-07 02:52:30 UTC",
      "updated_date": "2025-04-07 02:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:42:29.506768"
    },
    {
      "arxiv_id": "2504.07986v2",
      "title": "SEAL: Steerable Reasoning Calibration of Large Language Models for Free",
      "title_zh": "翻译失败",
      "authors": [
        "Runjin Chen",
        "Zhenyu Zhang",
        "Junyuan Hong",
        "Souvik Kundu",
        "Zhangyang Wang"
      ],
      "abstract": "Large Language Models (LLMs), such as OpenAI's o1-series have demonstrated\ncompelling capabilities for complex reasoning tasks via the extended\nchain-of-thought (CoT) reasoning mechanism. However, recent studies reveal\nsubstantial redundancy in the CoT reasoning traces, which not only increases\ninference latency but also negatively impacts model performance by diverting\nattention to unnecessary reasoning paths. To address this issue, we investigate\nthe internal reasoning structures of LLMs and categorize them into three\nprimary thought types: execution, reflection, and transition thoughts.\nMoreover, our analysis reveals that excessive reflection and transition\nthoughts are strongly correlated with failure cases and these thought\ncategories exhibit clear separation in the latent space. Based on these, we\nintroduce SEAL (Steerable reasoning calibration), a training-free approach that\nseamlessly calibrates the CoT process, improving accuracy while demonstrating\nsignificant efficiency gains. SEAL consists of an offline stage for extracting\nthe reasoning steering vector in the latent space, followed by an on-the-fly\ncalibration of the reasoning trace through representation intervention using\nthe steering vector. Notably, the steering vector exhibits strong\ntransferability across various tasks. Extensive experiments across multiple\nmodels (DeepSeek-R1-Distill and QwQ-32B-Preview) and benchmarks (Math500,\nGSM8K, LiveCodeBench) validate the effectiveness of SEAL, up to a 11%\nimprovement in accuracy while reducing reasoning tokens by 11.8% to 50.4%. Our\ncode is publicly available at https://github.com/VITA-Group/SEAL.",
      "tldr_zh": "这篇论文针对Large Language Models (LLMs)中chain-of-thought (CoT)推理的冗余问题，分析了内部推理结构并将其分为execution、reflection和transition thoughts，发现过多的reflection和transition thoughts会降低性能。作者提出了SEAL（Steerable reasoning calibration），一种无需训练的框架，通过离线提取reasoning steering vector并进行在线representation intervention来校准CoT过程，提高准确性和效率。该方法在DeepSeek-R1-Distill和QwQ-32B-Preview等模型上实验验证，准确率提升高达11%，并减少了11.8%至50.4%的推理tokens，展示了良好的transferability。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.07986v2",
      "published_date": "2025-04-07 02:42:07 UTC",
      "updated_date": "2025-05-06 08:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:42:41.475513"
    },
    {
      "arxiv_id": "2504.04687v1",
      "title": "Bridging Knowledge Gap Between Image Inpainting and Large-Area Visible Watermark Removal",
      "title_zh": "桥接图像修复与大面积可见水印去除之间的知识鸿沟",
      "authors": [
        "Yicheng Leng",
        "Chaowei Fang",
        "Junye Chen",
        "Yixiang Fang",
        "Sheng Li",
        "Guanbin Li"
      ],
      "abstract": "Visible watermark removal which involves watermark cleaning and background\ncontent restoration is pivotal to evaluate the resilience of watermarks.\nExisting deep neural network (DNN)-based models still struggle with large-area\nwatermarks and are overly dependent on the quality of watermark mask\nprediction. To overcome these challenges, we introduce a novel feature adapting\nframework that leverages the representation modeling capacity of a pre-trained\nimage inpainting model. Our approach bridges the knowledge gap between image\ninpainting and watermark removal by fusing information of the residual\nbackground content beneath watermarks into the inpainting backbone model. We\nestablish a dual-branch system to capture and embed features from the residual\nbackground content, which are merged into intermediate features of the\ninpainting backbone model via gated feature fusion modules. Moreover, for\nrelieving the dependence on high-quality watermark masks, we introduce a new\ntraining paradigm by utilizing coarse watermark masks to guide the inference\nprocess. This contributes to a visible image removal model which is insensitive\nto the quality of watermark mask during testing. Extensive experiments on both\na large-scale synthesized dataset and a real-world dataset demonstrate that our\napproach significantly outperforms existing state-of-the-art methods. The\nsource code is available in the supplementary materials.",
      "tldr_zh": "本文提出一个新颖的特征适应框架，桥接图像修复（image inpainting）和大面积可见水印移除的知识差距，解决现有DNN-based模型在处理大面积水印时的局限性及其对水印掩码质量的过度依赖。框架通过双分支系统捕获水印下残留背景内容的特征，并利用门控特征融合模块（gated feature fusion modules）将其融入预训练的图像修复骨干模型中。此外，引入新的训练范式，使用粗糙的水印掩码指导推理过程，使模型在测试时对掩码质量不敏感。实验在大型合成数据集和真实数据集上表明，该方法显著优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.IV",
        "I.2.10; I.4.4; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.04687v1",
      "published_date": "2025-04-07 02:37:14 UTC",
      "updated_date": "2025-04-07 02:37:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:42:54.932556"
    },
    {
      "arxiv_id": "2504.04676v1",
      "title": "Dual Consistent Constraint via Disentangled Consistency and Complementarity for Multi-view Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Li",
        "Jing Yun"
      ],
      "abstract": "Multi-view clustering can explore common semantics from multiple views and\nhas received increasing attention in recent years. However, current methods\nfocus on learning consistency in representation, neglecting the contribution of\neach view's complementarity aspect in representation learning. This limit poses\na significant challenge in multi-view representation learning. This paper\nproposes a novel multi-view clustering framework that introduces a disentangled\nvariational autoencoder that separates multi-view into shared and private\ninformation, i.e., consistency and complementarity information. We first learn\ninformative and consistent representations by maximizing mutual information\nacross different views through contrastive learning. This process will ignore\ncomplementary information. Then, we employ consistency inference constraints to\nexplicitly utilize complementary information when attempting to seek the\nconsistency of shared information across all views. Specifically, we perform a\nwithin-reconstruction using the private and shared information of each view and\na cross-reconstruction using the shared information of all views. The dual\nconsistency constraints are not only effective in improving the representation\nquality of data but also easy to extend to other scenarios, especially in\ncomplex multi-view scenes. This could be the first attempt to employ dual\nconsistent constraint in a unified MVC theoretical framework. During the\ntraining procedure, the consistency and complementarity features are jointly\noptimized. Extensive experiments show that our method outperforms baseline\nmethods.",
      "tldr_zh": "该论文针对多-view clustering（多视图聚类）问题，指出现有方法过度关注表示的一致性（consistency），而忽略了各视图的互补性（complementarity），从而提出一个新框架，使用 disentangled variational autoencoder 将多视图信息分离为共享（shared）和私有（private）部分。框架通过 contrastive learning 最大化不同视图间的互信息，以学习信息丰富的共享表示；同时，引入 dual consistent constraint，包括 within-reconstruction（使用每个视图的私有和共享信息）和 cross-reconstruction（使用所有视图的共享信息），以利用互补信息并确保跨视图一致性。实验结果显示，该方法在多视图场景中优于基线方法，证明了其在提升表示质量和扩展性方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04676v1",
      "published_date": "2025-04-07 02:00:16 UTC",
      "updated_date": "2025-04-07 02:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:43:05.999430"
    },
    {
      "arxiv_id": "2504.04675v2",
      "title": "HypRL: Reinforcement Learning of Control Policies for Hyperproperties",
      "title_zh": "HypRL：超属性控制策略",
      "authors": [
        "Tzu-Han Hsu",
        "Arshia Rafieioskouei",
        "Borzoo Bonakdarpour"
      ],
      "abstract": "We study the problem of learning control policies for complex tasks whose\nrequirements are given by a hyperproperty. The use of hyperproperties is\nmotivated by their significant power to formally specify requirements of\nmulti-agent systems as well as those that need expressiveness in terms of\nmultiple execution traces (e.g., privacy and fairness). Given a Markov decision\nprocess M with unknown transitions (representing the environment) and a\nHyperLTL formula $\\varphi$, our approach first employs Skolemization to handle\nquantifier alternations in $\\varphi$. We introduce quantitative robustness\nfunctions for HyperLTL to define rewards of finite traces of M with respect to\n$\\varphi$. Finally, we utilize a suitable reinforcement learning algorithm to\nlearn (1) a policy per trace quantifier in $\\varphi$, and (2) the probability\ndistribution of transitions of M that together maximize the expected reward\nand, hence, probability of satisfaction of $\\varphi$ in M. We present a set of\ncase studies on (1) safety-preserving multi-agent path planning, (2) fairness\nin resource allocation, and (3) the post-correspondence problem (PCP).",
      "tldr_zh": "该论文提出 HypRL 方法，通过强化学习（Reinforcement Learning）来学习控制策略，以满足由 Hyperproperties 指定的复杂任务要求，例如多代理系统的隐私和公平性。方法包括使用 Skolemization 处理 HyperLTL 公式中的量化器交替，引入定量鲁棒性函数来定义奖励，并优化策略和转移概率分布以最大化公式满足概率。在案例研究中，该方法在安全多代理路径规划、公平资源分配和后对应问题（PCP）上展示了显著的有效性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04675v2",
      "published_date": "2025-04-07 01:58:36 UTC",
      "updated_date": "2025-04-08 04:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:43:17.408161"
    },
    {
      "arxiv_id": "2504.04654v1",
      "title": "EquiCPI: SE(3)-Equivariant Geometric Deep Learning for Structure-Aware Prediction of Compound-Protein Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Ngoc-Quang Nguyen"
      ],
      "abstract": "Accurate prediction of compound-protein interactions (CPI) remains a\ncornerstone challenge in computational drug discovery. While existing\nsequence-based approaches leverage molecular fingerprints or graph\nrepresentations, they critically overlook three-dimensional (3D) structural\ndeterminants of binding affinity. To bridge this gap, we present EquiCPI, an\nend-to-end geometric deep learning framework that synergizes first-principles\nstructural modeling with SE(3)-equivariant neural networks. Our pipeline\ntransforms raw sequences into 3D atomic coordinates via ESMFold for proteins\nand DiffDock-L for ligands, followed by physics-guided conformer re-ranking and\nequivariant feature learning. At its core, EquiCPI employs SE(3)-equivariant\nmessage passing over atomic point clouds, preserving symmetry under rotations,\ntranslations, and reflections, while hierarchically encoding local interaction\npatterns through tensor products of spherical harmonics. The proposed model is\nevaluated on BindingDB (affinity prediction) and DUD-E (virtual screening),\nEquiCPI achieves performance on par with or exceeding the state-of-the-art deep\nlearning competitors.",
      "tldr_zh": "本研究提出EquiCPI，一种端到端的SE(3)-Equivariant几何深度学习框架，用于结构感知的化合物-蛋白质相互作用(CPI)预测，以解决现有方法忽略三维(3D)结构问题的局限性。框架首先通过ESMFold和DiffDock-L将蛋白质和配体序列转换为3D原子坐标，然后结合基于物理的构象重新排序和SE(3)-equivariant消息传递机制，通过球谐函数的张量积编码局部交互模式，确保对旋转、平移和反射的对称性保持不变。在BindingDB（亲和力预测）和DUD-E（虚拟筛选）数据集上评估，EquiCPI的性能达到或超过了最先进的深度学习竞争对手。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.04654v1",
      "published_date": "2025-04-07 00:57:08 UTC",
      "updated_date": "2025-04-07 00:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T10:43:29.274806"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 142,
  "processed_papers_count": 142,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T10:43:50.262413"
}