[
  {
    "arxiv_id": "2412.05467v4",
    "title": "The BrowserGym Ecosystem for Web Agent Research",
    "authors": [
      "Thibault Le Sellier De Chezelles",
      "Maxime Gasse",
      "Alexandre Drouin",
      "Massimo Caccia",
      "Léo Boisvert",
      "Megh Thakkar",
      "Tom Marty",
      "Rim Assouel",
      "Sahar Omidi Shayegan",
      "Lawrence Keunho Jang",
      "Xing Han Lù",
      "Ori Yoran",
      "Dehan Kong",
      "Frank F. Xu",
      "Siva Reddy",
      "Quentin Cappart",
      "Graham Neubig",
      "Ruslan Salakhutdinov",
      "Nicolas Chapados",
      "Alexandre Lacoste"
    ],
    "abstract": "The BrowserGym ecosystem addresses the growing need for efficient evaluation\nand benchmarking of web agents, particularly those leveraging automation and\nLarge Language Models (LLMs). Many existing benchmarks suffer from\nfragmentation and inconsistent evaluation methodologies, making it challenging\nto achieve reliable comparisons and reproducible results. In an earlier work,\nDrouin et al. (2024) introduced BrowserGym which aims to solve this by\nproviding a unified, gym-like environment with well-defined observation and\naction spaces, facilitating standardized evaluation across diverse benchmarks.\nWe propose an extended BrowserGym-based ecosystem for web agent research, which\nunifies existing benchmarks from the literature and includes AgentLab, a\ncomplementary framework that aids in agent creation, testing, and analysis. Our\nproposed ecosystem offers flexibility for integrating new benchmarks while\nensuring consistent evaluation and comprehensive experiment management. As a\nsupporting evidence, we conduct the first large-scale, multi-benchmark web\nagent experiment and compare the performance of 6 state-of-the-art LLMs across\n6 popular web agent benchmarks made available in BrowserGym. Among other\nfindings, our results highlight a large discrepancy between OpenAI and\nAnthropic's latests models, with Claude-3.5-Sonnet leading the way on almost\nall benchmarks, except on vision-related tasks where GPT-4o is superior.\nDespite these advancements, our results emphasize that building robust and\nefficient web agents remains a significant challenge, due to the inherent\ncomplexity of real-world web environments and the limitations of current\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05467v4",
    "published_date": "2024-12-06 23:43:59 UTC",
    "updated_date": "2025-02-28 16:02:27 UTC"
  },
  {
    "arxiv_id": "2412.05450v1",
    "title": "Promoting Cooperation in the Public Goods Game using Artificial Intelligent Agents",
    "authors": [
      "Arend Hintze",
      "Christoph Adami"
    ],
    "abstract": "The tragedy of the commons illustrates a fundamental social dilemma where\nindividual rational actions lead to collectively undesired outcomes,\nthreatening the sustainability of shared resources. Strategies to escape this\ndilemma, however, are in short supply. In this study, we explore how artificial\nintelligence (AI) agents can be leveraged to enhance cooperation in public\ngoods games, moving beyond traditional regulatory approaches to using AI as\nfacilitators of cooperation. We investigate three scenarios: (1) Mandatory\nCooperation Policy for AI Agents, where AI agents are institutionally mandated\nalways to cooperate; (2) Player-Controlled Agent Cooperation Policy, where\nplayers evolve control over AI agents' likelihood to cooperate; and (3) Agents\nMimic Players, where AI agents copy the behavior of players. Using a\ncomputational evolutionary model with a population of agents playing public\ngoods games, we find that only when AI agents mimic player behavior does the\ncritical synergy threshold for cooperation decrease, effectively resolving the\ndilemma. This suggests that we can leverage AI to promote collective well-being\nin societal dilemmas by designing AI agents to mimic human players.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "nlin.AO",
      "q-bio.PE"
    ],
    "primary_category": "cs.GT",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05450v1",
    "published_date": "2024-12-06 22:16:21 UTC",
    "updated_date": "2024-12-06 22:16:21 UTC"
  },
  {
    "arxiv_id": "2412.05449v1",
    "title": "Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications",
    "authors": [
      "Raphael Shu",
      "Nilaksh Das",
      "Michelle Yuan",
      "Monica Sunkara",
      "Yi Zhang"
    ],
    "abstract": "AI agents powered by large language models (LLMs) have shown strong\ncapabilities in problem solving. Through combining many intelligent agents,\nmulti-agent collaboration has emerged as a promising approach to tackle\ncomplex, multi-faceted problems that exceed the capabilities of single AI\nagents. However, designing the collaboration protocols and evaluating the\neffectiveness of these systems remains a significant challenge, especially for\nenterprise applications. This report addresses these challenges by presenting a\ncomprehensive evaluation of coordination and routing capabilities in a novel\nmulti-agent collaboration framework. We evaluate two key operational modes: (1)\na coordination mode enabling complex task completion through parallel\ncommunication and payload referencing, and (2) a routing mode for efficient\nmessage forwarding between agents. We benchmark on a set of handcrafted\nscenarios from three enterprise domains, which are publicly released with the\nreport. For coordination capabilities, we demonstrate the effectiveness of\ninter-agent communication and payload referencing mechanisms, achieving\nend-to-end goal success rates of 90%. Our analysis yields several key findings:\nmulti-agent collaboration enhances goal success rates by up to 70% compared to\nsingle-agent approaches in our benchmarks; payload referencing improves\nperformance on code-intensive tasks by 23%; latency can be substantially\nreduced with a routing mechanism that selectively bypasses agent orchestration.\nThese findings offer valuable guidance for enterprise deployments of\nmulti-agent systems and advance the development of scalable, efficient\nmulti-agent collaboration frameworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical report for multi-agent collaboration on AWS Bedrock Agents",
    "pdf_url": "http://arxiv.org/pdf/2412.05449v1",
    "published_date": "2024-12-06 22:14:17 UTC",
    "updated_date": "2024-12-06 22:14:17 UTC"
  },
  {
    "arxiv_id": "2412.05447v2",
    "title": "TOBUGraph: Knowledge Graph-Based Retrieval for Enhanced LLM Performance Beyond RAG",
    "authors": [
      "Savini Kashmira",
      "Jayanaka L. Dantanarayana",
      "Joshua Brodsky",
      "Ashish Mahendra",
      "Yiping Kang",
      "Krisztian Flautner",
      "Lingjia Tang",
      "Jason Mars"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) is one of the leading and most widely\nused techniques for enhancing LLM retrieval capabilities, but it still faces\nsignificant limitations in commercial use cases. RAG primarily relies on the\nquery-chunk text-to-text similarity in the embedding space for retrieval and\ncan fail to capture deeper semantic relationships across chunks, is highly\nsensitive to chunking strategies, and is prone to hallucinations. To address\nthese challenges, we propose TOBUGraph, a graph-based retrieval framework that\nfirst constructs the knowledge graph from unstructured data dynamically and\nautomatically. Using LLMs, TOBUGraph extracts structured knowledge and diverse\nrelationships among data, going beyond RAG's text-to-text similarity. Retrieval\nis achieved through graph traversal, leveraging the extracted relationships and\nstructures to enhance retrieval accuracy, eliminating the need for chunking\nconfigurations while reducing hallucination. We demonstrate TOBUGraph's\neffectiveness in TOBU, a real-world application in production for personal\nmemory organization and retrieval. Our evaluation using real user data\ndemonstrates that TOBUGraph outperforms multiple RAG implementations in both\nprecision and recall, significantly improving user experience through improved\nretrieval accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05447v2",
    "published_date": "2024-12-06 22:05:39 UTC",
    "updated_date": "2025-04-01 14:03:15 UTC"
  },
  {
    "arxiv_id": "2412.05445v2",
    "title": "From Voice to Value: Leveraging AI to Enhance Spoken Online Reviews on the Go",
    "authors": [
      "Kavindu Ravishan",
      "Dániel Szabó",
      "Niels van Berkel",
      "Aku Visuri",
      "Chi-Lan Yang",
      "Koji Yatani",
      "Simo Hosio"
    ],
    "abstract": "Online reviews help people make better decisions. Review platforms usually\ndepend on typed input, where leaving a good review requires significant effort\nbecause users must carefully organize and articulate their thoughts. This may\ndiscourage users from leaving comprehensive and high-quality reviews,\nespecially when they are on the go. To address this challenge, we developed\nVocalizer, a mobile application that enables users to provide reviews through\nvoice input, with enhancements from a large language model (LLM). In a\nlongitudinal study, we analysed user interactions with the app, focusing on\nAI-driven features that help refine and improve reviews. Our findings show that\nusers frequently utilized the AI agent to add more detailed information to\ntheir reviews. We also show how interactive AI features can improve users\nself-efficacy and willingness to share reviews online. Finally, we discuss the\nopportunities and challenges of integrating AI assistance into review-writing\nsystems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "\\c{opyright} Kavindu Ravishan | ACM 2024. This is the author's\n  version of the work. It is posted here for your personal use. Not for\n  redistribution. The definitive Version of Record was published in the\n  Proceedings of the ACM Conference on Mobile and Ubiquitous Multimedia (MUM\n  '24), http://dx.doi.org/10.1145/3701571.3701593",
    "pdf_url": "http://arxiv.org/pdf/2412.05445v2",
    "published_date": "2024-12-06 21:59:47 UTC",
    "updated_date": "2024-12-10 19:31:29 UTC"
  },
  {
    "arxiv_id": "2412.05437v1",
    "title": "DRL4AOI: A DRL Framework for Semantic-aware AOI Segmentation in Location-Based Services",
    "authors": [
      "Youfang Lin",
      "Jinji Fu",
      "Haomin Wen",
      "Jiyuan Wang",
      "Zhenjie Wei",
      "Yuting Qiang",
      "Xiaowei Mao",
      "Lixia Wu",
      "Haoyuan Hu",
      "Yuxuan Liang",
      "Huaiyu Wan"
    ],
    "abstract": "In Location-Based Services (LBS), such as food delivery, a fundamental task\nis segmenting Areas of Interest (AOIs), aiming at partitioning the urban\ngeographical spaces into non-overlapping regions. Traditional AOI segmentation\nalgorithms primarily rely on road networks to partition urban areas. While\npromising in modeling the geo-semantics, road network-based models overlooked\nthe service-semantic goals (e.g., workload equality) in LBS service. In this\npaper, we point out that the AOI segmentation problem can be naturally\nformulated as a Markov Decision Process (MDP), which gradually chooses a nearby\nAOI for each grid in the current AOI's border. Based on the MDP, we present the\nfirst attempt to generalize Deep Reinforcement Learning (DRL) for AOI\nsegmentation, leading to a novel DRL-based framework called DRL4AOI. The\nDRL4AOI framework introduces different service-semantic goals in a flexible way\nby treating them as rewards that guide the AOI generation. To evaluate the\neffectiveness of DRL4AOI, we develop and release an AOI segmentation system. We\nalso present a representative implementation of DRL4AOI - TrajRL4AOI - for AOI\nsegmentation in the logistics service. It introduces a Double Deep Q-learning\nNetwork (DDQN) to gradually optimize the AOI generation for two specific\nsemantic goals: i) trajectory modularity, i.e., maximize tightness of the\ntrajectory connections within an AOI and the sparsity of connections between\nAOIs, ii) matchness with the road network, i.e., maximizing the matchness\nbetween AOIs and the road network. Quantitative and qualitative experiments\nconducted on synthetic and real-world data demonstrate the effectiveness and\nsuperiority of our method. The code and system is publicly available at\nhttps://github.com/Kogler7/AoiOpt.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05437v1",
    "published_date": "2024-12-06 21:45:27 UTC",
    "updated_date": "2024-12-06 21:45:27 UTC"
  },
  {
    "arxiv_id": "2412.06828v1",
    "title": "Enhancing LLMs for Impression Generation in Radiology Reports through a Multi-Agent System",
    "authors": [
      "Fang Zeng",
      "Zhiliang Lyu",
      "Quanzheng Li",
      "Xiang Li"
    ],
    "abstract": "This study introduces \"RadCouncil,\" a multi-agent Large Language Model (LLM)\nframework designed to enhance the generation of impressions in radiology\nreports from the finding section. RadCouncil comprises three specialized\nagents: 1) a \"Retrieval\" Agent that identifies and retrieves similar reports\nfrom a vector database, 2) a \"Radiologist\" Agent that generates impressions\nbased on the finding section of the given report plus the exemplar reports\nretrieved by the Retrieval Agent, and 3) a \"Reviewer\" Agent that evaluates the\ngenerated impressions and provides feedback. The performance of RadCouncil was\nevaluated using both quantitative metrics (BLEU, ROUGE, BERTScore) and\nqualitative criteria assessed by GPT-4, using chest X-ray as a case study.\nExperiment results show improvements in RadCouncil over the single-agent\napproach across multiple dimensions, including diagnostic accuracy, stylistic\nconcordance, and clarity. This study highlights the potential of utilizing\nmultiple interacting LLM agents, each with a dedicated task, to enhance\nperformance in specialized medical tasks and the development of more robust and\nadaptable healthcare AI solutions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06828v1",
    "published_date": "2024-12-06 21:33:03 UTC",
    "updated_date": "2024-12-06 21:33:03 UTC"
  },
  {
    "arxiv_id": "2412.06827v1",
    "title": "Enhancing LLMs for Physics Problem-Solving using Reinforcement Learning with Human-AI Feedback",
    "authors": [
      "Avinash Anand",
      "Kritarth Prasad",
      "Chhavi Kirtani",
      "Ashwin R Nair",
      "Mohit Gupta",
      "Saloni Garg",
      "Anurag Gautam",
      "Snehal Buldeo",
      "Rajiv Ratn Shah"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities in\ntext-based tasks but struggle with the complex reasoning required for physics\nproblems, particularly in advanced arithmetic and conceptual understanding.\nWhile some research has explored ways to enhance LLMs in physics education\nusing techniques such as prompt engineering and Retrieval Augmentation\nGeneration (RAG), not enough effort has been made in addressing their\nlimitations in physics reasoning. This paper presents a novel approach to\nimproving LLM performance on physics questions using Reinforcement Learning\nwith Human and Artificial Intelligence Feedback (RLHAIF). We evaluate several\nreinforcement learning methods, including Proximal Policy Optimization (PPO),\nDirect Preference Optimization (DPO), and Remax optimization. These methods are\nchosen to investigate RL policy performance with different settings on the\nPhyQA dataset, which includes challenging physics problems from high school\ntextbooks. Our RLHAIF model, tested on leading LLMs like LLaMA2 and Mistral,\nachieved superior results, notably with the MISTRAL-PPO model, demonstrating\nmarked improvements in reasoning and accuracy. It achieved high scores, with a\n58.67 METEOR score and a 0.74 Reasoning score, making it a strong example for\nfuture physics reasoning research in this area.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.06827v1",
    "published_date": "2024-12-06 21:17:47 UTC",
    "updated_date": "2024-12-06 21:17:47 UTC"
  },
  {
    "arxiv_id": "2412.05426v1",
    "title": "What's the Move? Hybrid Imitation Learning via Salient Points",
    "authors": [
      "Priya Sundaresan",
      "Hengyuan Hu",
      "Quan Vuong",
      "Jeannette Bohg",
      "Dorsa Sadigh"
    ],
    "abstract": "While imitation learning (IL) offers a promising framework for teaching\nrobots various behaviors, learning complex tasks remains challenging. Existing\nIL policies struggle to generalize effectively across visual and spatial\nvariations even for simple tasks. In this work, we introduce SPHINX: Salient\nPoint-based Hybrid ImitatioN and eXecution, a flexible IL policy that leverages\nmultimodal observations (point clouds and wrist images), along with a hybrid\naction space of low-frequency, sparse waypoints and high-frequency, dense end\neffector movements. Given 3D point cloud observations, SPHINX learns to infer\ntask-relevant points within a point cloud, or salient points, which support\nspatial generalization by focusing on semantically meaningful features. These\nsalient points serve as anchor points to predict waypoints for long-range\nmovement, such as reaching target poses in free-space. Once near a salient\npoint, SPHINX learns to switch to predicting dense end-effector movements given\nclose-up wrist images for precise phases of a task. By exploiting the strengths\nof different input modalities and action representations for different\nmanipulation phases, SPHINX tackles complex tasks in a sample-efficient,\ngeneralizable manner. Our method achieves 86.7% success across 4 real-world and\n2 simulated tasks, outperforming the next best state-of-the-art IL baseline by\n41.1% on average across 440 real world trials. SPHINX additionally generalizes\nto novel viewpoints, visual distractors, spatial arrangements, and execution\nspeeds with a 1.7x speedup over the most competitive baseline. Our website\n(http://sphinx-manip.github.io) provides open-sourced code for data collection,\ntraining, and evaluation, along with supplementary videos.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05426v1",
    "published_date": "2024-12-06 21:17:14 UTC",
    "updated_date": "2024-12-06 21:17:14 UTC"
  },
  {
    "arxiv_id": "2412.05421v1",
    "title": "KEDformer:Knowledge Extraction Seasonal Trend Decomposition for Long-term Sequence Prediction",
    "authors": [
      "Zhenkai Qin",
      "Baozhong Wei",
      "Caifeng Gao",
      "Jianyuan Ni"
    ],
    "abstract": "Time series forecasting is a critical task in domains such as energy,\nfinance, and meteorology, where accurate long-term predictions are essential.\nWhile Transformer-based models have shown promise in capturing temporal\ndependencies, their application to extended sequences is limited by\ncomputational inefficiencies and limited generalization. In this study, we\npropose KEDformer, a knowledge extraction-driven framework that integrates\nseasonal-trend decomposition to address these challenges. KEDformer leverages\nknowledge extraction methods that focus on the most informative weights within\nthe self-attention mechanism to reduce computational overhead. Additionally,\nthe proposed KEDformer framework decouples time series into seasonal and trend\ncomponents. This decomposition enhances the model's ability to capture both\nshort-term fluctuations and long-term patterns. Extensive experiments on five\npublic datasets from energy, transportation, and weather domains demonstrate\nthe effectiveness and competitiveness of KEDformer, providing an efficient\nsolution for long-term time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05421v1",
    "published_date": "2024-12-06 21:07:11 UTC",
    "updated_date": "2024-12-06 21:07:11 UTC"
  },
  {
    "arxiv_id": "2412.06825v2",
    "title": "Feature Group Tabular Transformer: A Novel Approach to Traffic Crash Modeling and Causality Analysis",
    "authors": [
      "Oscar Lares",
      "Hao Zhen",
      "Jidong J. Yang"
    ],
    "abstract": "Reliable and interpretable traffic crash modeling is essential for\nunderstanding causality and improving road safety. This study introduces a\nnovel approach to predicting collision types by utilizing a comprehensive\ndataset fused from multiple sources, including weather data, crash reports,\nhigh-resolution traffic information, pavement geometry, and facility\ncharacteristics. Central to our approach is the development of a Feature Group\nTabular Transformer (FGTT) model, which organizes disparate data into\nmeaningful feature groups, represented as tokens. These group-based tokens\nserve as rich semantic components, enabling effective identification of\ncollision patterns and interpretation of causal mechanisms. The FGTT model is\nbenchmarked against widely used tree ensemble models, including Random Forest,\nXGBoost, and CatBoost, demonstrating superior predictive performance.\nFurthermore, model interpretation reveals key influential factors, providing\nfresh insights into the underlying causality of distinct crash types.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 7 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.06825v2",
    "published_date": "2024-12-06 20:47:13 UTC",
    "updated_date": "2025-01-11 16:21:29 UTC"
  },
  {
    "arxiv_id": "2412.05408v1",
    "title": "FogROS2-FT: Fault Tolerant Cloud Robotics",
    "authors": [
      "Kaiyuan Chen",
      "Kush Hari",
      "Trinity Chung",
      "Michael Wang",
      "Nan Tian",
      "Christian Juette",
      "Jeffrey Ichnowski",
      "Liu Ren",
      "John Kubiatowicz",
      "Ion Stoica",
      "Ken Goldberg"
    ],
    "abstract": "Cloud robotics enables robots to offload complex computational tasks to cloud\nservers for performance and ease of management. However, cloud compute can be\ncostly, cloud services can suffer occasional downtime, and connectivity between\nthe robot and cloud can be prone to variations in network Quality-of-Service\n(QoS). We present FogROS2-FT (Fault Tolerant) to mitigate these issues by\nintroducing a multi-cloud extension that automatically replicates independent\nstateless robotic services, routes requests to these replicas, and directs the\nfirst response back. With replication, robots can still benefit from cloud\ncomputations even when a cloud service provider is down or there is low QoS.\nAdditionally, many cloud computing providers offer low-cost spot computing\ninstances that may shutdown unpredictably. Normally, these low-cost instances\nwould be inappropriate for cloud robotics, but the fault tolerance nature of\nFogROS2-FT allows them to be used reliably. We demonstrate FogROS2-FT fault\ntolerance capabilities in 3 cloud-robotics scenarios in simulation (visual\nobject detection, semantic segmentation, motion planning) and 1 physical robot\nexperiment (scan-pick-and-place). Running on the same hardware specification,\nFogROS2-FT achieves motion planning with up to 2.2x cost reduction and up to a\n5.53x reduction on 99 Percentile (P99) long-tail latency. FogROS2-FT reduces\nthe P99 long-tail latency of object detection and semantic segmentation by 2.0x\nand 2.1x, respectively, under network slowdown and resource contention.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.DC",
      "cs.NI"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE/RSJ International Conference on Intelligent Robots and Systems\n  2024 Best Paper Finalist",
    "pdf_url": "http://arxiv.org/pdf/2412.05408v1",
    "published_date": "2024-12-06 20:38:46 UTC",
    "updated_date": "2024-12-06 20:38:46 UTC"
  },
  {
    "arxiv_id": "2412.05393v1",
    "title": "HiVeGen -- Hierarchical LLM-based Verilog Generation for Scalable Chip Design",
    "authors": [
      "Jinwei Tang",
      "Jiayin Qin",
      "Kiran Thorat",
      "Chen Zhu-Tian",
      "Yu Cao",
      "Yang",
      "Zhao",
      "Caiwen Ding"
    ],
    "abstract": "With Large Language Models (LLMs) recently demonstrating impressive\nproficiency in code generation, it is promising to extend their abilities to\nHardware Description Language (HDL). However, LLMs tend to generate single HDL\ncode blocks rather than hierarchical structures for hardware designs, leading\nto hallucinations, particularly in complex designs like Domain-Specific\nAccelerators (DSAs). To address this, we propose HiVeGen, a hierarchical\nLLM-based Verilog generation framework that decomposes generation tasks into\nLLM-manageable hierarchical submodules. HiVeGen further harnesses the\nadvantages of such hierarchical structures by integrating automatic Design\nSpace Exploration (DSE) into hierarchy-aware prompt generation, introducing\nweight-based retrieval to enhance code reuse, and enabling real-time\nhuman-computer interaction to lower error-correction cost, significantly\nimproving the quality of generated designs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05393v1",
    "published_date": "2024-12-06 19:37:53 UTC",
    "updated_date": "2024-12-06 19:37:53 UTC"
  },
  {
    "arxiv_id": "2412.05388v1",
    "title": "CALICO: Conversational Agent Localization via Synthetic Data Generation",
    "authors": [
      "Andy Rosenbaum",
      "Pegah Kharazmi",
      "Ershad Banijamali",
      "Lu Zeng",
      "Christopher DiPersio",
      "Pan Wei",
      "Gokmen Oz",
      "Clement Chung",
      "Karolina Owczarzak",
      "Fabian Triefenbach",
      "Wael Hamza"
    ],
    "abstract": "We present CALICO, a method to fine-tune Large Language Models (LLMs) to\nlocalize conversational agent training data from one language to another. For\nslots (named entities), CALICO supports three operations: verbatim copy,\nliteral translation, and localization, i.e. generating slot values more\nappropriate in the target language, such as city and airport names located in\ncountries where the language is spoken. Furthermore, we design an iterative\nfiltering mechanism to discard noisy generated samples, which we show boosts\nthe performance of the downstream conversational agent. To prove the\neffectiveness of CALICO, we build and release a new human-localized (HL)\nversion of the MultiATIS++ travel information test set in 8 languages. Compared\nto the original human-translated (HT) version of the test set, we show that our\nnew HL version is more challenging. We also show that CALICO out-performs\nstate-of-the-art LINGUIST (which relies on literal slot translation out of\ncontext) both on the HT case, where CALICO generates more accurate slot\ntranslations, and on the HL case, where CALICO generates localized slots which\nare closer to the HL test set.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to The 37th International Conference on Neural Information\n  Processing Systems (NeurIPS 2023) December 10-16, 2023 - SyntheticData4ML\n  Workshop, New Orleans, United States\n  https://neurips.cc/virtual/2023/workshop/66540",
    "pdf_url": "http://arxiv.org/pdf/2412.05388v1",
    "published_date": "2024-12-06 19:29:16 UTC",
    "updated_date": "2024-12-06 19:29:16 UTC"
  },
  {
    "arxiv_id": "2412.05280v2",
    "title": "Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model",
    "authors": [
      "Lening Wang",
      "Wenzhao Zheng",
      "Dalong Du",
      "Yunpeng Zhang",
      "Yilong Ren",
      "Han Jiang",
      "Zhiyong Cui",
      "Haiyang Yu",
      "Jie Zhou",
      "Jiwen Lu",
      "Shanghang Zhang"
    ],
    "abstract": "4D driving simulation is essential for developing realistic autonomous\ndriving simulators. Despite advancements in existing methods for generating\ndriving scenes, significant challenges remain in view transformation and\nspatial-temporal dynamic modeling. To address these limitations, we propose a\nSpatial-Temporal simulAtion for drivinG (Stag-1) model to reconstruct\nreal-world scenes and design a controllable generative network to achieve 4D\nsimulation. Stag-1 constructs continuous 4D point cloud scenes using\nsurround-view data from autonomous vehicles. It decouples spatial-temporal\nrelationships and produces coherent keyframe videos. Additionally, Stag-1\nleverages video generation models to obtain photo-realistic and controllable 4D\ndriving simulation videos from any perspective. To expand the range of view\ngeneration, we train vehicle motion videos based on decomposed camera poses,\nenhancing modeling capabilities for distant scenes. Furthermore, we reconstruct\nvehicle camera trajectories to integrate 3D points across consecutive views,\nenabling comprehensive scene understanding along the temporal dimension.\nFollowing extensive multi-level scene training, Stag-1 can simulate from any\ndesired viewpoint and achieve a deep understanding of scene evolution under\nstatic spatial-temporal conditions. Compared to existing methods, our approach\nshows promising performance in multi-view scene consistency, background\ncoherence, and accuracy, and contributes to the ongoing advancements in\nrealistic autonomous driving simulation. Code: https://github.com/wzzheng/Stag.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at: https://github.com/wzzheng/Stag",
    "pdf_url": "http://arxiv.org/pdf/2412.05280v2",
    "published_date": "2024-12-06 18:59:56 UTC",
    "updated_date": "2024-12-11 02:27:18 UTC"
  },
  {
    "arxiv_id": "2412.05355v1",
    "title": "MotionShop: Zero-Shot Motion Transfer in Video Diffusion Models with Mixture of Score Guidance",
    "authors": [
      "Hidir Yesiltepe",
      "Tuna Han Salih Meral",
      "Connor Dunlop",
      "Pinar Yanardag"
    ],
    "abstract": "In this work, we propose the first motion transfer approach in diffusion\ntransformer through Mixture of Score Guidance (MSG), a theoretically-grounded\nframework for motion transfer in diffusion models. Our key theoretical\ncontribution lies in reformulating conditional score to decompose motion score\nand content score in diffusion models. By formulating motion transfer as a\nmixture of potential energies, MSG naturally preserves scene composition and\nenables creative scene transformations while maintaining the integrity of\ntransferred motion patterns. This novel sampling operates directly on\npre-trained video diffusion models without additional training or fine-tuning.\nThrough extensive experiments, MSG demonstrates successful handling of diverse\nscenarios including single object, multiple objects, and cross-object motion\ntransfer as well as complex camera motion transfer. Additionally, we introduce\nMotionBench, the first motion transfer dataset consisting of 200 source videos\nand 1000 transferred motions, covering single/multi-object transfers, and\ncomplex camera motions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://motionshop-diffusion.github.io",
    "pdf_url": "http://arxiv.org/pdf/2412.05355v1",
    "published_date": "2024-12-06 18:59:17 UTC",
    "updated_date": "2024-12-06 18:59:17 UTC"
  },
  {
    "arxiv_id": "2412.05275v1",
    "title": "MotionFlow: Attention-Driven Motion Transfer in Video Diffusion Models",
    "authors": [
      "Tuna Han Salih Meral",
      "Hidir Yesiltepe",
      "Connor Dunlop",
      "Pinar Yanardag"
    ],
    "abstract": "Text-to-video models have demonstrated impressive capabilities in producing\ndiverse and captivating video content, showcasing a notable advancement in\ngenerative AI. However, these models generally lack fine-grained control over\nmotion patterns, limiting their practical applicability. We introduce\nMotionFlow, a novel framework designed for motion transfer in video diffusion\nmodels. Our method utilizes cross-attention maps to accurately capture and\nmanipulate spatial and temporal dynamics, enabling seamless motion transfers\nacross various contexts. Our approach does not require training and works on\ntest-time by leveraging the inherent capabilities of pre-trained video\ndiffusion models. In contrast to traditional approaches, which struggle with\ncomprehensive scene changes while maintaining consistent motion, MotionFlow\nsuccessfully handles such complex transformations through its attention-based\nmechanism. Our qualitative and quantitative experiments demonstrate that\nMotionFlow significantly outperforms existing models in both fidelity and\nversatility even during drastic scene alterations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://motionflow-diffusion.github.io",
    "pdf_url": "http://arxiv.org/pdf/2412.05275v1",
    "published_date": "2024-12-06 18:59:12 UTC",
    "updated_date": "2024-12-06 18:59:12 UTC"
  },
  {
    "arxiv_id": "2412.05270v4",
    "title": "APOLLO: SGD-like Memory, AdamW-level Performance",
    "authors": [
      "Hanqing Zhu",
      "Zhenyu Zhang",
      "Wenyan Cong",
      "Xi Liu",
      "Sem Park",
      "Vikas Chandra",
      "Bo Long",
      "David Z. Pan",
      "Zhangyang Wang",
      "Jinwon Lee"
    ],
    "abstract": "Large language models (LLMs) are notoriously memory-intensive during\ntraining, particularly with the popular AdamW optimizer. This memory burden\nnecessitates using more or higher-end GPUs or reducing batch sizes, limiting\ntraining scalability and throughput. To address this, various memory-efficient\noptimizers have been proposed to reduce optimizer memory usage. However, they\nface critical challenges: (i) reliance on costly SVD operations; (ii)\nsignificant performance trade-offs compared to AdamW; and (iii) still\nsubstantial optimizer memory overhead to maintain competitive performance.\n  In this work, we identify that AdamW's learning rate adaptation rule can be\neffectively coarsened as a structured learning rate update. Based on this\ninsight, we propose Approximated Gradient Scaling for Memory-Efficient LLM\nOptimization (APOLLO), which approximates learning rate scaling using an\nauxiliary low-rank optimizer state based on pure random projection. This\nstructured learning rate update rule makes APOLLO highly tolerant to further\nmemory reductions while delivering comparable pre-training performance. Even\nits rank-1 variant, APOLLO-Mini, achieves superior pre-training performance\ncompared to AdamW with SGD-level memory costs.\n  Extensive experiments demonstrate that the APOLLO series performs on-par with\nor better than AdamW, while achieving greater memory savings by nearly\neliminating the optimization states of AdamW. These savings provide significant\nsystem-level benefits: (1) Enhanced Throughput: 3x throughput on an 8xA100-80GB\nsetup compared to AdamW by supporting 4x larger batch sizes. (2) Improved Model\nScalability: Pre-training LLaMA-13B with naive DDP on A100-80GB GPUs without\nsystem-level optimizations. (3) Low-End GPU Friendly Pre-training: Pre-training\nLLaMA-7B on a single GPU using less than 12 GB of memory with weight\nquantization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to MLSys 2025; the newest version with new experiments",
    "pdf_url": "http://arxiv.org/pdf/2412.05270v4",
    "published_date": "2024-12-06 18:55:34 UTC",
    "updated_date": "2025-02-17 08:27:58 UTC"
  },
  {
    "arxiv_id": "2412.05269v1",
    "title": "Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases",
    "authors": [
      "Krzysztof Maziarz",
      "Guoqing Liu",
      "Hubert Misztela",
      "Aleksei Kornev",
      "Piotr Gaiński",
      "Holger Hoefling",
      "Mike Fortunato",
      "Rishi Gupta",
      "Marwin Segler"
    ],
    "abstract": "Planning and conducting chemical syntheses remains a major bottleneck in the\ndiscovery of functional small molecules, and prevents fully leveraging\ngenerative AI for molecular inverse design. While early work has shown that\nML-based retrosynthesis models can predict reasonable routes, their low\naccuracy for less frequent, yet important reactions has been pointed out. As\nmulti-step search algorithms are limited to reactions suggested by the\nunderlying model, the applicability of those tools is inherently constrained by\nthe accuracy of retrosynthesis prediction. Inspired by how chemists use\ndifferent strategies to ideate reactions, we propose Chimera: a framework for\nbuilding highly accurate reaction models that combine predictions from diverse\nsources with complementary inductive biases using a learning-based ensembling\nstrategy. We instantiate the framework with two newly developed models, which\nalready by themselves achieve state of the art in their categories. Through\nexperiments across several orders of magnitude in data scale and time-splits,\nwe show Chimera outperforms all major models by a large margin, owing both to\nthe good individual performance of its constituents, but also to the\nscalability of our ensembling strategy. Moreover, we find that PhD-level\norganic chemists prefer predictions from Chimera over baselines in terms of\nquality. Finally, we transfer the largest-scale checkpoint to an internal\ndataset from a major pharmaceutical company, showing robust generalization\nunder distribution shift. With the new dimension that our framework unlocks, we\nanticipate further acceleration in the development of even more accurate\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05269v1",
    "published_date": "2024-12-06 18:55:19 UTC",
    "updated_date": "2024-12-06 18:55:19 UTC"
  },
  {
    "arxiv_id": "2412.05265v3",
    "title": "Reinforcement Learning: An Overview",
    "authors": [
      "Kevin Murphy"
    ],
    "abstract": "This manuscript gives a big-picture, up-to-date overview of the field of\n(deep) reinforcement learning and sequential decision making, covering\nvalue-based methods, policy-based methods, model-based methods, multi-agent RL,\nLLMs and RL, and various other topics (e.g., offline RL, hierarchical RL,\nintrinsic reward).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05265v3",
    "published_date": "2024-12-06 18:53:49 UTC",
    "updated_date": "2025-05-19 15:12:39 UTC"
  },
  {
    "arxiv_id": "2412.05256v3",
    "title": "Extrapolated Urban View Synthesis Benchmark",
    "authors": [
      "Xiangyu Han",
      "Zhen Jia",
      "Boyi Li",
      "Yan Wang",
      "Boris Ivanovic",
      "Yurong You",
      "Lingjie Liu",
      "Yue Wang",
      "Marco Pavone",
      "Chen Feng",
      "Yiming Li"
    ],
    "abstract": "Photorealistic simulators are essential for the training and evaluation of\nvision-centric autonomous vehicles (AVs). At their core is Novel View Synthesis\n(NVS), a crucial capability that generates diverse unseen viewpoints to\naccommodate the broad and continuous pose distribution of AVs. Recent advances\nin radiance fields, such as 3D Gaussian Splatting, achieve photorealistic\nrendering at real-time speeds and have been widely used in modeling large-scale\ndriving scenes. However, their performance is commonly evaluated using an\ninterpolated setup with highly correlated training and test views. In contrast,\nextrapolation, where test views largely deviate from training views, remains\nunderexplored, limiting progress in generalizable simulation technology. To\naddress this gap, we leverage publicly available AV datasets with multiple\ntraversals, multiple vehicles, and multiple cameras to build the first\nExtrapolated Urban View Synthesis (EUVS) benchmark. Meanwhile, we conduct both\nquantitative and qualitative evaluations of state-of-the-art NVS methods across\ndifferent evaluation settings. Our results show that current NVS methods are\nprone to overfitting to training views. Besides, incorporating diffusion priors\nand improving geometry cannot fundamentally improve NVS under large view\nchanges, highlighting the need for more robust approaches and large-scale\ntraining. We will release the data to help advance self-driving and urban\nrobotics simulation technology.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://ai4ce.github.io/EUVS-Benchmark/",
    "pdf_url": "http://arxiv.org/pdf/2412.05256v3",
    "published_date": "2024-12-06 18:41:39 UTC",
    "updated_date": "2025-03-12 20:57:59 UTC"
  },
  {
    "arxiv_id": "2412.05255v1",
    "title": "TeamCraft: A Benchmark for Multi-Modal Multi-Agent Systems in Minecraft",
    "authors": [
      "Qian Long",
      "Zhi Li",
      "Ran Gong",
      "Ying Nian Wu",
      "Demetri Terzopoulos",
      "Xiaofeng Gao"
    ],
    "abstract": "Collaboration is a cornerstone of society. In the real world, human teammates\nmake use of multi-sensory data to tackle challenging tasks in ever-changing\nenvironments. It is essential for embodied agents collaborating in\nvisually-rich environments replete with dynamic interactions to understand\nmulti-modal observations and task specifications. To evaluate the performance\nof generalizable multi-modal collaborative agents, we present TeamCraft, a\nmulti-modal multi-agent benchmark built on top of the open-world video game\nMinecraft. The benchmark features 55,000 task variants specified by multi-modal\nprompts, procedurally-generated expert demonstrations for imitation learning,\nand carefully designed protocols to evaluate model generalization capabilities.\nWe also perform extensive analyses to better understand the limitations and\nstrengths of existing approaches. Our results indicate that existing models\ncontinue to face significant challenges in generalizing to novel goals, scenes,\nand unseen numbers of agents. These findings underscore the need for further\nresearch in this area. The TeamCraft platform and dataset are publicly\navailable at https://github.com/teamcraft-bench/teamcraft.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05255v1",
    "published_date": "2024-12-06 18:41:16 UTC",
    "updated_date": "2024-12-06 18:41:16 UTC"
  },
  {
    "arxiv_id": "2412.05252v1",
    "title": "From classical techniques to convolution-based models: A review of object detection algorithms",
    "authors": [
      "Fnu Neha",
      "Deepshikha Bhati",
      "Deepak Kumar Shukla",
      "Md Amiruzzaman"
    ],
    "abstract": "Object detection is a fundamental task in computer vision and image\nunderstanding, with the goal of identifying and localizing objects of interest\nwithin an image while assigning them corresponding class labels. Traditional\nmethods, which relied on handcrafted features and shallow models, struggled\nwith complex visual data and showed limited performance. These methods combined\nlow-level features with contextual information and lacked the ability to\ncapture high-level semantics. Deep learning, especially Convolutional Neural\nNetworks (CNNs), addressed these limitations by automatically learning rich,\nhierarchical features directly from data. These features include both semantic\nand high-level representations essential for accurate object detection. This\npaper reviews object detection frameworks, starting with classical computer\nvision methods. We categorize object detection approaches into two groups: (1)\nclassical computer vision techniques and (2) CNN-based detectors. We compare\nmajor CNN models, discussing their strengths and limitations. In conclusion,\nthis review highlights the significant advancements in object detection through\ndeep learning and identifies key areas for further research to improve\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05252v1",
    "published_date": "2024-12-06 18:32:54 UTC",
    "updated_date": "2024-12-06 18:32:54 UTC"
  },
  {
    "arxiv_id": "2412.05251v1",
    "title": "Uncertainty Quantification for Transformer Models for Dark-Pattern Detection",
    "authors": [
      "Javier Muñoz",
      "Álvaro Huertas-García",
      "Carlos Martí-González",
      "Enrique De Miguel Ambite"
    ],
    "abstract": "The opaque nature of transformer-based models, particularly in applications\nsusceptible to unethical practices such as dark-patterns in user interfaces,\nrequires models that integrate uncertainty quantification to enhance trust in\npredictions. This study focuses on dark-pattern detection, deceptive design\nchoices that manipulate user decisions, undermining autonomy and consent. We\npropose a differential fine-tuning approach implemented at the final\nclassification head via uncertainty quantification with transformer-based\npre-trained models. Employing a dense neural network (DNN) head architecture as\na baseline, we examine two methods capable of quantifying uncertainty:\nSpectral-normalized Neural Gaussian Processes (SNGPs) and Bayesian Neural\nNetworks (BNNs). These methods are evaluated on a set of open-source\nfoundational models across multiple dimensions: model performance, variance in\ncertainty of predictions and environmental impact during training and inference\nphases. Results demonstrate that integrating uncertainty quantification\nmaintains performance while providing insights into challenging instances\nwithin the models. Moreover, the study reveals that the environmental impact\ndoes not uniformly increase with the incorporation of uncertainty\nquantification techniques. The study's findings demonstrate that uncertainty\nquantification enhances transparency and provides measurable confidence in\npredictions, improving the explainability and clarity of black-box models. This\nfacilitates informed decision-making and mitigates the influence of\ndark-patterns on user interfaces. These results highlight the importance of\nincorporating uncertainty quantification techniques in developing machine\nlearning models, particularly in domains where interpretability and\ntrustworthiness are critical.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "math.PR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05251v1",
    "published_date": "2024-12-06 18:31:51 UTC",
    "updated_date": "2024-12-06 18:31:51 UTC"
  },
  {
    "arxiv_id": "2412.05248v2",
    "title": "Enhancing FKG.in: automating Indian food composition analysis",
    "authors": [
      "Saransh Kumar Gupta",
      "Lipika Dey",
      "Partha Pratim Das",
      "Geeta Trilok-Kumar",
      "Ramesh Jain"
    ],
    "abstract": "This paper presents a novel approach to compute food composition data for\nIndian recipes using a knowledge graph for Indian food (FKG.in) and LLMs. The\nprimary focus is to provide a broad overview of an automated food composition\nanalysis workflow and describe its core functionalities: nutrition data\naggregation, food composition analysis, and LLM-augmented information\nresolution. This workflow aims to complement FKG.in and iteratively supplement\nfood composition data from verified knowledge bases. Additionally, this paper\nhighlights the challenges of representing Indian food and accessing food\ncomposition data digitally. It also reviews three key sources of food\ncomposition data: the Indian Food Composition Tables, the Indian Nutrient\nDatabank, and the Nutritionix API. Furthermore, it briefly outlines how users\ncan interact with the workflow to obtain diet-based health recommendations and\ndetailed food composition information for numerous recipes. We then explore the\ncomplex challenges of analyzing Indian recipe information across dimensions\nsuch as structure, multilingualism, and uncertainty as well as present our\nongoing work on LLM-based solutions to address these issues. The methods\nproposed in this workshop paper for AI-driven knowledge curation and\ninformation resolution are application-agnostic, generalizable, and replicable\nfor any domain.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 5 figures, 30 references, International Conference on\n  Pattern Recognition 2024 - Multimedia Assisted Dietary Management Workshop",
    "pdf_url": "http://arxiv.org/pdf/2412.05248v2",
    "published_date": "2024-12-06 18:27:15 UTC",
    "updated_date": "2024-12-09 09:21:49 UTC"
  },
  {
    "arxiv_id": "2412.05244v1",
    "title": "Enhancing Foundation Models for Time Series Forecasting via Wavelet-based Tokenization",
    "authors": [
      "Luca Masserano",
      "Abdul Fatir Ansari",
      "Boran Han",
      "Xiyuan Zhang",
      "Christos Faloutsos",
      "Michael W. Mahoney",
      "Andrew Gordon Wilson",
      "Youngsuk Park",
      "Syama Rangapuram",
      "Danielle C. Maddix",
      "Yuyang Wang"
    ],
    "abstract": "How to best develop foundational models for time series forecasting remains\nan important open question. Tokenization is a crucial consideration in this\neffort: what is an effective discrete vocabulary for a real-valued sequential\ninput? To address this question, we develop WaveToken, a wavelet-based\ntokenizer that allows models to learn complex representations directly in the\nspace of time-localized frequencies. Our method first scales and decomposes the\ninput time series, then thresholds and quantizes the wavelet coefficients, and\nfinally pre-trains an autoregressive model to forecast coefficients for the\nforecast horizon. By decomposing coarse and fine structures in the inputs,\nwavelets provide an eloquent and compact language for time series forecasting\nthat simplifies learning. Empirical results on a comprehensive benchmark,\nincluding 42 datasets for both in-domain and zero-shot settings, show that\nWaveToken: i) provides better accuracy than recently proposed foundation models\nfor forecasting while using a much smaller vocabulary (1024 tokens), and\nperforms on par or better than modern deep learning models trained specifically\non each dataset; and ii) exhibits superior generalization capabilities,\nachieving the best average rank across all datasets for three complementary\nmetrics. In addition, we show that our method can easily capture complex\ntemporal patterns of practical relevance that are challenging for other recent\npre-trained models, including trends, sparse spikes, and non-stationary time\nseries with varying frequencies evolving over time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05244v1",
    "published_date": "2024-12-06 18:22:59 UTC",
    "updated_date": "2024-12-06 18:22:59 UTC"
  },
  {
    "arxiv_id": "2412.05243v1",
    "title": "CompCap: Improving Multimodal Large Language Models with Composite Captions",
    "authors": [
      "Xiaohui Chen",
      "Satya Narayan Shukla",
      "Mahmoud Azab",
      "Aashu Singh",
      "Qifan Wang",
      "David Yang",
      "ShengYun Peng",
      "Hanchao Yu",
      "Shen Yan",
      "Xuewen Zhang",
      "Baosheng He"
    ],
    "abstract": "How well can Multimodal Large Language Models (MLLMs) understand composite\nimages? Composite images (CIs) are synthetic visuals created by merging\nmultiple visual elements, such as charts, posters, or screenshots, rather than\nbeing captured directly by a camera. While CIs are prevalent in real-world\napplications, recent MLLM developments have primarily focused on interpreting\nnatural images (NIs). Our research reveals that current MLLMs face significant\nchallenges in accurately understanding CIs, often struggling to extract\ninformation or perform complex reasoning based on these images. We find that\nexisting training data for CIs are mostly formatted for question-answer tasks\n(e.g., in datasets like ChartQA and ScienceQA), while high-quality\nimage-caption datasets, critical for robust vision-language alignment, are only\navailable for NIs. To bridge this gap, we introduce Composite Captions\n(CompCap), a flexible framework that leverages Large Language Models (LLMs) and\nautomation tools to synthesize CIs with accurate and detailed captions. Using\nCompCap, we curate CompCap-118K, a dataset containing 118K image-caption pairs\nacross six CI types. We validate the effectiveness of CompCap-118K by\nsupervised fine-tuning MLLMs of three sizes: xGen-MM-inst.-4B and\nLLaVA-NeXT-Vicuna-7B/13B. Empirical results show that CompCap-118K\nsignificantly enhances MLLMs' understanding of CIs, yielding average gains of\n1.7%, 2.0%, and 2.9% across eleven benchmarks, respectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05243v1",
    "published_date": "2024-12-06 18:22:47 UTC",
    "updated_date": "2024-12-06 18:22:47 UTC"
  },
  {
    "arxiv_id": "2412.05225v1",
    "title": "BEExformer: A Fast Inferencing Transformer Architecture via Binarization with Multiple Early Exits",
    "authors": [
      "Wazib Ansar",
      "Saptarsi Goswami",
      "Amlan Chakrabarti"
    ],
    "abstract": "Large Language Models (LLMs) based on transformers achieve cutting-edge\nresults on a variety of applications. However, their enormous size and\nprocessing requirements make deployment on devices with constrained resources\nextremely difficult. Among various efficiency considerations, model\nbinarization and Early Exit (EE) are common effective solutions. However,\nbinarization may lead to performance loss due to reduced precision affecting\ngradient estimation and parameter updates. Besides, the present early-exit\nmechanisms are still in the nascent stages of research. To ameliorate these\nissues, we propose Binarized Early Exit Transformer (BEExformer), the\nfirst-ever selective learning transformer architecture to combine early exit\nwith binarization for textual inference. It improves the binarization process\nthrough a differentiable second-order approximation to the impulse function.\nThis enables gradient computation concerning both the sign as well as the\nmagnitude of the weights. In contrast to absolute threshold-based EE, the\nproposed EE mechanism hinges on fractional reduction in entropy among\nintermediate transformer blocks with soft-routing loss estimation. While\nbinarization results in 18.44 times reduction in model size, early exit reduces\nthe FLOPs during inference by 54.85% and even improves accuracy by 5.98%\nthrough resolving the \"overthinking\" problem inherent in deep networks.\nMoreover, the proposed BEExformer simplifies training by not requiring\nknowledge distillation from a full-precision LLM. Extensive evaluation on the\nGLUE dataset and comparison with the SOTA works showcase its pareto-optimal\nperformance-efficiency trade-off.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 15 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05225v1",
    "published_date": "2024-12-06 17:58:14 UTC",
    "updated_date": "2024-12-06 17:58:14 UTC"
  },
  {
    "arxiv_id": "2412.05214v1",
    "title": "AI's assigned gender affects human-AI cooperation",
    "authors": [
      "Sepideh Bazazi",
      "Jurgis Karpus",
      "Taha Yasseri"
    ],
    "abstract": "Cooperation between humans and machines is increasingly vital as artificial\nintelligence (AI) becomes more integrated into daily life. Research indicates\nthat people are often less willing to cooperate with AI agents than with\nhumans, more readily exploiting AI for personal gain. While prior studies have\nshown that giving AI agents human-like features influences people's cooperation\nwith them, the impact of AI's assigned gender remains underexplored. This study\ninvestigates how human cooperation varies based on gender labels assigned to AI\nagents with which they interact. In the Prisoner's Dilemma game, 402\nparticipants interacted with partners labelled as AI (bot) or humans. The\npartners were also labelled male, female, non-binary, or gender-neutral.\nResults revealed that participants tended to exploit female-labelled and\ndistrust male-labelled AI agents more than their human counterparts, reflecting\ngender biases similar to those in human-human interactions. These findings\nhighlight the significance of gender biases in human-AI interactions that must\nbe considered in future policy, design of interactive AI systems, and\nregulation of their use.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.GT",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Manuscript under review",
    "pdf_url": "http://arxiv.org/pdf/2412.05214v1",
    "published_date": "2024-12-06 17:46:35 UTC",
    "updated_date": "2024-12-06 17:46:35 UTC"
  },
  {
    "arxiv_id": "2412.05208v2",
    "title": "A Survey of Large Language Model-Based Generative AI for Text-to-SQL: Benchmarks, Applications, Use Cases, and Challenges",
    "authors": [
      "Aditi Singh",
      "Akash Shetty",
      "Abul Ehtesham",
      "Saket Kumar",
      "Tala Talaei Khoei"
    ],
    "abstract": "Text-to-SQL systems facilitate smooth interaction with databases by\ntranslating natural language queries into Structured Query Language (SQL),\nbridging the gap between non-technical users and complex database management\nsystems. This survey provides a comprehensive overview of the evolution of\nAI-driven text-to-SQL systems, highlighting their foundational components,\nadvancements in large language model (LLM) architectures, and the critical role\nof datasets such as Spider, WikiSQL, and CoSQL in driving progress. We examine\nthe applications of text-to-SQL in domains like healthcare, education, and\nfinance, emphasizing their transformative potential for improving data\naccessibility. Additionally, we analyze persistent challenges, including domain\ngeneralization, query optimization, support for multi-turn conversational\ninteractions, and the limited availability of datasets tailored for NoSQL\ndatabases and dynamic real-world scenarios. To address these challenges, we\noutline future research directions, such as extending text-to-SQL capabilities\nto support NoSQL databases, designing datasets for dynamic multi-turn\ninteractions, and optimizing systems for real-world scalability and robustness.\nBy surveying current advancements and identifying key gaps, this paper aims to\nguide the next generation of research and applications in LLM-based text-to-SQL\nsystems.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05208v2",
    "published_date": "2024-12-06 17:36:28 UTC",
    "updated_date": "2025-01-23 01:29:42 UTC"
  },
  {
    "arxiv_id": "2412.05206v1",
    "title": "ConQRet: Benchmarking Fine-Grained Evaluation of Retrieval Augmented Argumentation with LLM Judges",
    "authors": [
      "Kaustubh D. Dhole",
      "Kai Shu",
      "Eugene Agichtein"
    ],
    "abstract": "Computational argumentation, which involves generating answers or summaries\nfor controversial topics like abortion bans and vaccination, has become\nincreasingly important in today's polarized environment. Sophisticated LLM\ncapabilities offer the potential to provide nuanced, evidence-based answers to\nsuch questions through Retrieval-Augmented Argumentation (RAArg), leveraging\nreal-world evidence for high-quality, grounded arguments. However, evaluating\nRAArg remains challenging, as human evaluation is costly and difficult for\ncomplex, lengthy answers on complicated topics. At the same time, re-using\nexisting argumentation datasets is no longer sufficient, as they lack long,\ncomplex arguments and realistic evidence from potentially misleading sources,\nlimiting holistic evaluation of retrieval effectiveness and argument quality.\nTo address these gaps, we investigate automated evaluation methods using\nmultiple fine-grained LLM judges, providing better and more interpretable\nassessments than traditional single-score metrics and even previously reported\nhuman crowdsourcing. To validate the proposed techniques, we introduce ConQRet,\na new benchmark featuring long and complex human-authored arguments on debated\ntopics, grounded in real-world websites, allowing an exhaustive evaluation\nacross retrieval effectiveness, argument quality, and groundedness. We validate\nour LLM Judges on a prior dataset and the new ConQRet benchmark. Our proposed\nLLM Judges and the ConQRet benchmark can enable rapid progress in computational\nargumentation and can be naturally extended to other complex\nretrieval-augmented generation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05206v1",
    "published_date": "2024-12-06 17:35:52 UTC",
    "updated_date": "2024-12-06 17:35:52 UTC"
  },
  {
    "arxiv_id": "2412.05351v1",
    "title": "Towards Predicting the Success of Transfer-based Attacks by Quantifying Shared Feature Representations",
    "authors": [
      "Ashley S. Dale",
      "Mei Qiu",
      "Foo Bin Che",
      "Thomas Bsaibes",
      "Lauren Christopher",
      "Paul Salama"
    ],
    "abstract": "Much effort has been made to explain and improve the success of\ntransfer-based attacks (TBA) on black-box computer vision models. This work\nprovides the first attempt at a priori prediction of attack success by\nidentifying the presence of vulnerable features within target models. Recent\nwork by Chen and Liu (2024) proposed the manifold attack model, a unifying\nframework proposing that successful TBA exist in a common manifold space. Our\nwork experimentally tests the common manifold space hypothesis by a new\nmethodology: first, projecting feature vectors from surrogate and target\nfeature extractors trained on ImageNet onto the same low-dimensional manifold;\nsecond, quantifying any observed structure similarities on the manifold; and\nfinally, by relating these observed similarities to the success of the TBA. We\nfind that shared feature representation moderately correlates with increased\nsuccess of TBA (\\r{ho}= 0.56). This method may be used to predict whether an\nattack will transfer without information of the model weights, training,\narchitecture or details of the attack. The results confirm the presence of\nshared feature representations between two feature extractors of different\nsizes and complexities, and demonstrate the utility of datasets from different\ntarget domains as test signals for interpreting black-box feature\nrepresentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05351v1",
    "published_date": "2024-12-06 17:33:15 UTC",
    "updated_date": "2024-12-06 17:33:15 UTC"
  },
  {
    "arxiv_id": "2412.05203v2",
    "title": "Archaeoscape: Bringing Aerial Laser Scanning Archaeology to the Deep Learning Era",
    "authors": [
      "Yohann Perron",
      "Vladyslav Sydorov",
      "Adam P. Wijker",
      "Damian Evans",
      "Christophe Pottier",
      "Loic Landrieu"
    ],
    "abstract": "Airborne Laser Scanning (ALS) technology has transformed modern archaeology\nby unveiling hidden landscapes beneath dense vegetation. However, the lack of\nexpert-annotated, open-access resources has hindered the analysis of ALS data\nusing advanced deep learning techniques. We address this limitation with\nArchaeoscape (available at https://archaeoscape.ai/data/2024/), a novel\nlarge-scale archaeological ALS dataset spanning 888 km$^2$ in Cambodia with\n31,141 annotated archaeological features from the Angkorian period.\nArchaeoscape is over four times larger than comparable datasets, and the first\nALS archaeology resource with open-access data, annotations, and models.\n  We benchmark several recent segmentation models to demonstrate the benefits\nof modern vision techniques for this problem and highlight the unique\nchallenges of discovering subtle human-made structures under dense jungle\ncanopies. By making Archaeoscape available in open access, we hope to bridge\nthe gap between traditional archaeology and modern computer vision methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 - Datasets & Benchmarks Track (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2412.05203v2",
    "published_date": "2024-12-06 17:32:53 UTC",
    "updated_date": "2024-12-12 08:37:20 UTC"
  },
  {
    "arxiv_id": "2412.05200v1",
    "title": "Are Frontier Large Language Models Suitable for Q&A in Science Centres?",
    "authors": [
      "Jacob Watson",
      "Fabrício Góes",
      "Marco Volpe",
      "Talles Medeiros"
    ],
    "abstract": "This paper investigates the suitability of frontier Large Language Models\n(LLMs) for Q&A interactions in science centres, with the aim of boosting\nvisitor engagement while maintaining factual accuracy. Using a dataset of\nquestions collected from the National Space Centre in Leicester (UK), we\nevaluated responses generated by three leading models: OpenAI's GPT-4, Claude\n3.5 Sonnet, and Google Gemini 1.5. Each model was prompted for both standard\nand creative responses tailored to an 8-year-old audience, and these responses\nwere assessed by space science experts based on accuracy, engagement, clarity,\nnovelty, and deviation from expected answers. The results revealed a trade-off\nbetween creativity and accuracy, with Claude outperforming GPT and Gemini in\nboth maintaining clarity and engaging young audiences, even when asked to\ngenerate more creative responses. Nonetheless, experts observed that higher\nnovelty was generally associated with reduced factual reliability across all\nmodels. This study highlights the potential of LLMs in educational settings,\nemphasizing the need for careful prompt engineering to balance engagement with\nscientific rigor.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 2 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.05200v1",
    "published_date": "2024-12-06 17:28:43 UTC",
    "updated_date": "2024-12-06 17:28:43 UTC"
  },
  {
    "arxiv_id": "2412.05196v2",
    "title": "Exponential Speedups by Rerooting Levin Tree Search",
    "authors": [
      "Laurent Orseau",
      "Marcus Hutter",
      "Levi H. S. Lelis"
    ],
    "abstract": "Levin Tree Search (LTS) (Orseau et al., 2018) is a search algorithm for\ndeterministic environments that uses a user-specified policy to guide the\nsearch. It comes with a formal guarantee on the number of search steps (node\nvisits) for finding a solution node that depends on the quality of the policy.\nIn this paper, we introduce a new algorithm, called $\\sqrt{\\text{LTS}}$\n(pronounce root-LTS), which implicitly starts an LTS search rooted at every\nnode of the search tree. Each LTS search is assigned a rerooting weight by a\n(user-defined or learnt) rerooter, and the search effort is shared between all\nLTS searches proportionally to their weights. The rerooting mechanism\nimplicitly decomposes the search space into subtasks, leading to significant\nspeedups. We prove that the number of node visits that $\\sqrt{\\text{LTS}}$\ntakes is competitive with the best decomposition into subtasks, at the price of\na factor that relates to the uncertainty of the rerooter. If LTS takes time\n$T$, in the best case with $q$ rerooting points, $\\sqrt{\\text{LTS}}$ only takes\ntime $O(q\\sqrt[q]{T})$. Like the policy, the rerooter can be learnt from data,\nand we expect $\\sqrt{\\text{LTS}}$ to be applicable to a wide range of domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05196v2",
    "published_date": "2024-12-06 17:20:50 UTC",
    "updated_date": "2025-03-11 17:25:01 UTC"
  },
  {
    "arxiv_id": "2412.05187v1",
    "title": "SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot",
    "authors": [
      "Jinlin Wu",
      "Xusheng Liang",
      "Xuexue Bai",
      "Zhen Chen"
    ],
    "abstract": "Surgical interventions, particularly in neurology, represent complex and\nhigh-stakes scenarios that impose substantial cognitive burdens on surgical\nteams. Although deliberate education and practice can enhance cognitive\ncapabilities, surgical training opportunities remain limited due to patient\nsafety concerns. To address these cognitive challenges in surgical training and\noperation, we propose SurgBox, an agent-driven sandbox framework to\nsystematically enhance the cognitive capabilities of surgeons in immersive\nsurgical simulations. Specifically, our SurgBox leverages large language models\n(LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically\nreplicate various surgical roles, enabling realistic training environments for\ndeliberate practice. In particular, we devise Surgery Copilot, an AI-driven\nassistant to actively coordinate the surgical information stream and support\nclinical decision-making, thereby diminishing the cognitive workload of\nsurgical teams during surgery. By incorporating a novel Long-Short Memory\nmechanism, our Surgery Copilot can effectively balance immediate procedural\nassistance with comprehensive surgical knowledge. Extensive experiments using\nreal neurosurgical procedure records validate our SurgBox framework in both\nenhancing surgical cognitive capabilities and supporting clinical\ndecision-making. By providing an integrated solution for training and\noperational support to address cognitive challenges, our SurgBox framework\nadvances surgical education and practice, potentially transforming surgical\noutcomes and healthcare quality. The code is available at\nhttps://github.com/franciszchen/SurgBox.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "This work is accepted by IEEE Big Data 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05187v1",
    "published_date": "2024-12-06 17:07:27 UTC",
    "updated_date": "2024-12-06 17:07:27 UTC"
  },
  {
    "arxiv_id": "2412.05184v1",
    "title": "QueEn: A Large Language Model for Quechua-English Translation",
    "authors": [
      "Junhao Chen",
      "Peng Shu",
      "Yiwei Li",
      "Huaqin Zhao",
      "Hanqi Jiang",
      "Yi Pan",
      "Yifan Zhou",
      "Zhengliang Liu",
      "Lewis C Howe",
      "Tianming Liu"
    ],
    "abstract": "Recent studies show that large language models (LLMs) are powerful tools for\nworking with natural language, bringing advances in many areas of computational\nlinguistics. However, these models face challenges when applied to low-resource\nlanguages due to limited training data and difficulty in understanding cultural\nnuances. In this paper, we propose QueEn, a novel approach for Quechua-English\ntranslation that combines Retrieval-Augmented Generation (RAG) with\nparameter-efficient fine-tuning techniques. Our method leverages external\nlinguistic resources through RAG and uses Low-Rank Adaptation (LoRA) for\nefficient model adaptation. Experimental results show that our approach\nsubstantially exceeds baseline models, with a BLEU score of 17.6 compared to\n1.5 for standard GPT models. The integration of RAG with fine-tuning allows our\nsystem to address the challenges of low-resource language translation while\nmaintaining computational efficiency. This work contributes to the broader goal\nof preserving endangered languages through advanced language technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05184v1",
    "published_date": "2024-12-06 17:04:21 UTC",
    "updated_date": "2024-12-06 17:04:21 UTC"
  },
  {
    "arxiv_id": "2412.05169v1",
    "title": "Towards Understanding the Role of Sharpness-Aware Minimization Algorithms for Out-of-Distribution Generalization",
    "authors": [
      "Samuel Schapiro",
      "Han Zhao"
    ],
    "abstract": "Recently, sharpness-aware minimization (SAM) has emerged as a promising\nmethod to improve generalization by minimizing sharpness, which is known to\ncorrelate well with generalization ability. Since the original proposal of SAM,\nmany variants of SAM have been proposed to improve its accuracy and efficiency,\nbut comparisons have mainly been restricted to the i.i.d. setting. In this\npaper we study SAM for out-of-distribution (OOD) generalization. First, we\nperform a comprehensive comparison of eight SAM variants on zero-shot OOD\ngeneralization, finding that the original SAM outperforms the Adam baseline by\n$4.76\\%$ and the strongest SAM variants outperform the Adam baseline by\n$8.01\\%$ on average. We then provide an OOD generalization bound in terms of\nsharpness for this setting. Next, we extend our study of SAM to the related\nsetting of gradual domain adaptation (GDA), another form of OOD generalization\nwhere intermediate domains are constructed between the source and target\ndomains, and iterative self-training is done on intermediate domains, to\nimprove the overall target domain error. In this setting, our experimental\nresults demonstrate that the original SAM outperforms the baseline of Adam on\neach of the experimental datasets by $0.82\\%$ on average and the strongest SAM\nvariants outperform Adam by $1.52\\%$ on average. We then provide a\ngeneralization bound for SAM in the GDA setting. Asymptotically, this\ngeneralization bound is no better than the one for self-training in the\nliterature of GDA. This highlights a further disconnection between the\ntheoretical justification for SAM versus its empirical performance, with recent\nwork finding that low sharpness alone does not account for all of SAM's\ngeneralization benefits. For future work, we provide several potential avenues\nfor obtaining a tighter analysis for SAM in the OOD setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05169v1",
    "published_date": "2024-12-06 16:41:44 UTC",
    "updated_date": "2024-12-06 16:41:44 UTC"
  },
  {
    "arxiv_id": "2412.05167v1",
    "title": "Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models",
    "authors": [
      "Kuofeng Gao",
      "Shu-Tao Xia",
      "Ke Xu",
      "Philip Torr",
      "Jindong Gu"
    ],
    "abstract": "Large Audio-Language Models (LALMs) have unclocked audio dialogue\ncapabilities, where audio dialogues are a direct exchange of spoken language\nbetween LALMs and humans. Recent advances, such as GPT-4o, have enabled LALMs\nin back-and-forth audio dialogues with humans. This progression not only\nunderscores the potential of LALMs but also broadens their applicability across\na wide range of practical scenarios supported by audio dialogues. However,\ngiven these advancements, a comprehensive benchmark to evaluate the performance\nof LALMs in the open-ended audio dialogue understanding remains absent\ncurrently. To address this gap, we propose an Audio Dialogue Understanding\nBenchmark (ADU-Bench), which consists of 4 benchmark datasets. They assess the\nopen-ended audio dialogue ability for LALMs in 3 general scenarios, 12 skills,\n9 multilingual languages, and 4 categories of ambiguity handling. Notably, we\nfirstly propose the evaluation of ambiguity handling in audio dialogues that\nexpresses different intentions beyond the same literal meaning of sentences,\ne.g., \"Really!?\" with different intonations. In summary, ADU-Bench includes\nover 20,000 open-ended audio dialogues for the assessment of LALMs. Through\nextensive experiments conducted on 13 LALMs, our analysis reveals that there is\nstill considerable room for improvement in the audio dialogue understanding\nabilities of existing LALMs. In particular, they struggle with mathematical\nsymbols and formulas, understanding human behavior such as roleplay,\ncomprehending multiple languages, and handling audio dialogue ambiguities from\ndifferent phonetic elements, such as intonations, pause positions, and\nhomophones.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05167v1",
    "published_date": "2024-12-06 16:34:15 UTC",
    "updated_date": "2024-12-06 16:34:15 UTC"
  },
  {
    "arxiv_id": "2412.05161v1",
    "title": "DNF: Unconditional 4D Generation with Dictionary-based Neural Fields",
    "authors": [
      "Xinyi Zhang",
      "Naiqi Li",
      "Angela Dai"
    ],
    "abstract": "While remarkable success has been achieved through diffusion-based 3D\ngenerative models for shapes, 4D generative modeling remains challenging due to\nthe complexity of object deformations over time. We propose DNF, a new 4D\nrepresentation for unconditional generative modeling that efficiently models\ndeformable shapes with disentangled shape and motion while capturing\nhigh-fidelity details in the deforming objects. To achieve this, we propose a\ndictionary learning approach to disentangle 4D motion from shape as neural\nfields. Both shape and motion are represented as learned latent spaces, where\neach deformable shape is represented by its shape and motion global latent\ncodes, shape-specific coefficient vectors, and shared dictionary information.\nThis captures both shape-specific detail and global shared information in the\nlearned dictionary. Our dictionary-based representation well balances fidelity,\ncontiguity and compression -- combined with a transformer-based diffusion\nmodel, our method is able to generate effective, high-fidelity 4D animations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://xzhang-t.github.io/project/DNF/",
    "pdf_url": "http://arxiv.org/pdf/2412.05161v1",
    "published_date": "2024-12-06 16:25:57 UTC",
    "updated_date": "2024-12-06 16:25:57 UTC"
  },
  {
    "arxiv_id": "2412.05159v1",
    "title": "Enhancing Cross-Language Code Translation via Task-Specific Embedding Alignment in Retrieval-Augmented Generation",
    "authors": [
      "Manish Bhattarai",
      "Minh Vu",
      "Javier E. Santos",
      "Ismael Boureima",
      "Daniel O' Malley"
    ],
    "abstract": "We introduce a novel method to enhance cross-language code translation from\nFortran to C++ by integrating task-specific embedding alignment into a\nRetrieval-Augmented Generation (RAG) framework. Unlike conventional retrieval\napproaches that utilize generic embeddings agnostic to the downstream task, our\nstrategy aligns the retrieval model directly with the objective of maximizing\ntranslation quality, as quantified by the CodeBLEU metric. This alignment\nensures that the embeddings are semantically and syntactically meaningful for\nthe specific code translation task. Our methodology involves constructing a\ndataset of 25,000 Fortran code snippets sourced from Stack-V2 dataset and\ngenerating their corresponding C++ translations using the LLaMA 3.1-8B language\nmodel. We compute pairwise CodeBLEU scores between the generated translations\nand ground truth examples to capture fine-grained similarities. These scores\nserve as supervision signals in a contrastive learning framework, where we\noptimize the embedding model to retrieve Fortran-C++ pairs that are most\nbeneficial for improving the language model's translation performance. By\nintegrating these CodeBLEU-optimized embeddings into the RAG framework, our\napproach significantly enhances both retrieval accuracy and code generation\nquality over methods employing generic embeddings. On the HPC Fortran2C++\ndataset, our method elevates the average CodeBLEU score from 0.64 to 0.73,\nachieving a 14% relative improvement. On the Numerical Recipes dataset, we\nobserve an increase from 0.52 to 0.60, marking a 15% relative improvement.\nImportantly, these gains are realized without any fine-tuning of the language\nmodel, underscoring the efficiency and practicality of our approach.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05159v1",
    "published_date": "2024-12-06 16:22:32 UTC",
    "updated_date": "2024-12-06 16:22:32 UTC"
  },
  {
    "arxiv_id": "2412.05154v1",
    "title": "Towards Flexible 3D Perception: Object-Centric Occupancy Completion Augments 3D Object Detection",
    "authors": [
      "Chaoda Zheng",
      "Feng Wang",
      "Naiyan Wang",
      "Shuguang Cui",
      "Zhen Li"
    ],
    "abstract": "While 3D object bounding box (bbox) representation has been widely used in\nautonomous driving perception, it lacks the ability to capture the precise\ndetails of an object's intrinsic geometry. Recently, occupancy has emerged as a\npromising alternative for 3D scene perception. However, constructing a\nhigh-resolution occupancy map remains infeasible for large scenes due to\ncomputational constraints. Recognizing that foreground objects only occupy a\nsmall portion of the scene, we introduce object-centric occupancy as a\nsupplement to object bboxes. This representation not only provides intricate\ndetails for detected objects but also enables higher voxel resolution in\npractical applications. We advance the development of object-centric occupancy\nperception from both data and algorithm perspectives. On the data side, we\nconstruct the first object-centric occupancy dataset from scratch using an\nautomated pipeline. From the algorithmic standpoint, we introduce a novel\nobject-centric occupancy completion network equipped with an implicit shape\ndecoder that manages dynamic-size occupancy generation. This network accurately\npredicts the complete object-centric occupancy volume for inaccurate object\nproposals by leveraging temporal information from long sequences. Our method\ndemonstrates robust performance in completing object shapes under noisy\ndetection and tracking conditions. Additionally, we show that our occupancy\nfeatures significantly enhance the detection results of state-of-the-art 3D\nobject detectors, especially for incomplete or distant objects in the Waymo\nOpen Dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05154v1",
    "published_date": "2024-12-06 16:12:38 UTC",
    "updated_date": "2024-12-06 16:12:38 UTC"
  },
  {
    "arxiv_id": "2412.05152v1",
    "title": "Navigating Shortcuts, Spurious Correlations, and Confounders: From Origins via Detection to Mitigation",
    "authors": [
      "David Steinmann",
      "Felix Divo",
      "Maurice Kraus",
      "Antonia Wüst",
      "Lukas Struppek",
      "Felix Friedrich",
      "Kristian Kersting"
    ],
    "abstract": "Shortcuts, also described as Clever Hans behavior, spurious correlations, or\nconfounders, present a significant challenge in machine learning and AI,\ncritically affecting model generalization and robustness. Research in this\narea, however, remains fragmented across various terminologies, hindering the\nprogress of the field as a whole. Consequently, we introduce a unifying\ntaxonomy of shortcut learning by providing a formal definition of shortcuts and\nbridging the diverse terms used in the literature. In doing so, we further\nestablish important connections between shortcuts and related fields, including\nbias, causality, and security, where parallels exist but are rarely discussed.\nOur taxonomy organizes existing approaches for shortcut detection and\nmitigation, providing a comprehensive overview of the current state of the\nfield and revealing underexplored areas and open challenges. Moreover, we\ncompile and classify datasets tailored to study shortcut learning. Altogether,\nthis work provides a holistic perspective to deepen understanding and drive the\ndevelopment of more effective strategies for addressing shortcuts in machine\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05152v1",
    "published_date": "2024-12-06 16:10:13 UTC",
    "updated_date": "2024-12-06 16:10:13 UTC"
  },
  {
    "arxiv_id": "2412.05148v1",
    "title": "LoRA.rar: Learning to Merge LoRAs via Hypernetworks for Subject-Style Conditioned Image Generation",
    "authors": [
      "Donald Shenaj",
      "Ondrej Bohdal",
      "Mete Ozay",
      "Pietro Zanuttigh",
      "Umberto Michieli"
    ],
    "abstract": "Recent advancements in image generation models have enabled personalized\nimage creation with both user-defined subjects (content) and styles. Prior\nworks achieved personalization by merging corresponding low-rank adaptation\nparameters (LoRAs) through optimization-based methods, which are\ncomputationally demanding and unsuitable for real-time use on\nresource-constrained devices like smartphones. To address this, we introduce\nLoRA$.$rar, a method that not only improves image quality but also achieves a\nremarkable speedup of over $4000\\times$ in the merging process. LoRA$.$rar\npre-trains a hypernetwork on a diverse set of content-style LoRA pairs,\nlearning an efficient merging strategy that generalizes to new, unseen\ncontent-style pairs, enabling fast, high-quality personalization. Moreover, we\nidentify limitations in existing evaluation metrics for content-style quality\nand propose a new protocol using multimodal large language models (MLLM) for\nmore accurate assessment. Our method significantly outperforms the current\nstate of the art in both content and style fidelity, as validated by MLLM\nassessments and human evaluations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05148v1",
    "published_date": "2024-12-06 16:04:56 UTC",
    "updated_date": "2024-12-06 16:04:56 UTC"
  },
  {
    "arxiv_id": "2412.05145v1",
    "title": "Explingo: Explaining AI Predictions using Large Language Models",
    "authors": [
      "Alexandra Zytek",
      "Sara Pido",
      "Sarah Alnegheimish",
      "Laure Berti-Equille",
      "Kalyan Veeramachaneni"
    ],
    "abstract": "Explanations of machine learning (ML) model predictions generated by\nExplainable AI (XAI) techniques such as SHAP are essential for people using ML\noutputs for decision-making. We explore the potential of Large Language Models\n(LLMs) to transform these explanations into human-readable, narrative formats\nthat align with natural communication. We address two key research questions:\n(1) Can LLMs reliably transform traditional explanations into high-quality\nnarratives? and (2) How can we effectively evaluate the quality of narrative\nexplanations? To answer these questions, we introduce Explingo, which consists\nof two LLM-based subsystems, a Narrator and Grader. The Narrator takes in ML\nexplanations and transforms them into natural-language descriptions. The Grader\nscores these narratives on a set of metrics including accuracy, completeness,\nfluency, and conciseness.\n  Our experiments demonstrate that LLMs can generate high-quality narratives\nthat achieve high scores across all metrics, particularly when guided by a\nsmall number of human-labeled and bootstrapped examples. We also identified\nareas that remain challenging, in particular for effectively scoring narratives\nin complex domains. The findings from this work have been integrated into an\nopen-source tool that makes narrative explanations available for further\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To be presented in the 2024 IEEE International Conference on Big Data\n  (IEEE BigData)",
    "pdf_url": "http://arxiv.org/pdf/2412.05145v1",
    "published_date": "2024-12-06 16:01:30 UTC",
    "updated_date": "2024-12-06 16:01:30 UTC"
  },
  {
    "arxiv_id": "2412.05139v4",
    "title": "A Practical Examination of AI-Generated Text Detectors for Large Language Models",
    "authors": [
      "Brian Tufts",
      "Xuandong Zhao",
      "Lei Li"
    ],
    "abstract": "The proliferation of large language models has raised growing concerns about\ntheir misuse, particularly in cases where AI-generated text is falsely\nattributed to human authors. Machine-generated content detectors claim to\neffectively identify such text under various conditions and from any language\nmodel. This paper critically evaluates these claims by assessing several\npopular detectors (RADAR, Wild, T5Sentinel, Fast-DetectGPT, PHD, LogRank,\nBinoculars) on a range of domains, datasets, and models that these detectors\nhave not previously encountered. We employ various prompting strategies to\nsimulate practical adversarial attacks, demonstrating that even moderate\nefforts can significantly evade detection. We emphasize the importance of the\ntrue positive rate at a specific false positive rate (TPR@FPR) metric and\ndemonstrate that these detectors perform poorly in certain settings, with\nTPR@.01 as low as 0%. Our findings suggest that both trained and zero-shot\ndetectors struggle to maintain high sensitivity while achieving a reasonable\ntrue positive rate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.05139v4",
    "published_date": "2024-12-06 15:56:11 UTC",
    "updated_date": "2025-02-09 16:59:44 UTC"
  },
  {
    "arxiv_id": "2412.05137v1",
    "title": "Can Large Language Models Serve as Effective Classifiers for Hierarchical Multi-Label Classification of Scientific Documents at Industrial Scale?",
    "authors": [
      "Seyed Amin Tabatabaei",
      "Sarah Fancher",
      "Michael Parsons",
      "Arian Askari"
    ],
    "abstract": "We address the task of hierarchical multi-label classification (HMC) of\nscientific documents at an industrial scale, where hundreds of thousands of\ndocuments must be classified across thousands of dynamic labels. The rapid\ngrowth of scientific publications necessitates scalable and efficient methods\nfor classification, further complicated by the evolving nature of\ntaxonomies--where new categories are introduced, existing ones are merged, and\noutdated ones are deprecated. Traditional machine learning approaches, which\nrequire costly retraining with each taxonomy update, become impractical due to\nthe high overhead of labelled data collection and model adaptation. Large\nLanguage Models (LLMs) have demonstrated great potential in complex tasks such\nas multi-label classification. However, applying them to large and dynamic\ntaxonomies presents unique challenges as the vast number of labels can exceed\nLLMs' input limits. In this paper, we present novel methods that combine the\nstrengths of LLMs with dense retrieval techniques to overcome these challenges.\nOur approach avoids retraining by leveraging zero-shot HMC for real-time label\nassignment. We evaluate the effectiveness of our methods on SSRN, a large\nrepository of preprints spanning multiple disciplines, and demonstrate\nsignificant improvements in both classification accuracy and cost-efficiency.\nBy developing a tailored evaluation framework for dynamic taxonomies and\npublicly releasing our code, this research provides critical insights into\napplying LLMs for document classification, where the number of classes\ncorresponds to the number of nodes in a large taxonomy, at an industrial scale.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted at COLING 2025 (Industry Track)",
    "pdf_url": "http://arxiv.org/pdf/2412.05137v1",
    "published_date": "2024-12-06 15:51:22 UTC",
    "updated_date": "2024-12-06 15:51:22 UTC"
  },
  {
    "arxiv_id": "2412.05130v2",
    "title": "Technology as uncharted territory: Contextual integrity and the notion of AI as new ethical ground",
    "authors": [
      "Alexander Martin Mussgnug"
    ],
    "abstract": "Recent research illustrates how AI can be developed and deployed in a manner\ndetached from the concrete social context of application. By abstracting from\nthe contexts of AI application, practitioners also disengage from the distinct\nnormative structures that govern them. Building upon Helen Nissenbaum's\nframework of contextual integrity, I illustrate how disregard for contextual\nnorms can threaten the integrity of a context with often decisive ethical\nimplications. I argue that efforts to promote responsible and ethical AI can\ninadvertently contribute to and seemingly legitimize this disregard for\nestablished contextual norms. Echoing a persistent undercurrent in technology\nethics of understanding emerging technologies as uncharted moral territory,\ncertain approaches to AI ethics can promote a notion of AI as a novel and\ndistinct realm for ethical deliberation, norm setting, and virtue cultivation.\nThis narrative of AI as new ethical ground, however, can come at the expense of\npractitioners, policymakers and ethicists engaging with already established\nnorms and virtues that were gradually cultivated to promote successful and\nresponsible practice within concrete social contexts. In response, I question\nthe current narrow prioritization in AI ethics of moral innovation over moral\npreservation. Engaging also with emerging foundation models, I advocate for a\nmoderately conservative approach to the ethics of AI that prioritizes the\nresponsible and considered integration of AI within established social contexts\nand their respective normative structures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05130v2",
    "published_date": "2024-12-06 15:36:13 UTC",
    "updated_date": "2025-01-12 10:21:18 UTC"
  },
  {
    "arxiv_id": "2412.05127v1",
    "title": "The Prompt Canvas: A Literature-Based Practitioner Guide for Creating Effective Prompts in Large Language Models",
    "authors": [
      "Michael Hewing",
      "Vincent Leinhos"
    ],
    "abstract": "The rise of large language models (LLMs) has highlighted the importance of\nprompt engineering as a crucial technique for optimizing model outputs. While\nexperimentation with various prompting methods, such as Few-shot,\nChain-of-Thought, and role-based techniques, has yielded promising results,\nthese advancements remain fragmented across academic papers, blog posts and\nanecdotal experimentation. The lack of a single, unified resource to\nconsolidate the field's knowledge impedes the progress of both research and\npractical application. This paper argues for the creation of an overarching\nframework that synthesizes existing methodologies into a cohesive overview for\npractitioners. Using a design-based research approach, we present the Prompt\nCanvas, a structured framework resulting from an extensive literature review on\nprompt engineering that captures current knowledge and expertise. By combining\nthe conceptual foundations and practical strategies identified in prompt\nengineering, the Prompt Canvas provides a practical approach for leveraging the\npotential of Large Language Models. It is primarily designed as a learning\nresource for pupils, students and employees, offering a structured introduction\nto prompt engineering. This work aims to contribute to the growing discourse on\nprompt engineering by establishing a unified methodology for researchers and\nproviding guidance for practitioners.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05127v1",
    "published_date": "2024-12-06 15:35:18 UTC",
    "updated_date": "2024-12-06 15:35:18 UTC"
  },
  {
    "arxiv_id": "2412.05114v1",
    "title": "A*Net and NBFNet Learn Negative Patterns on Knowledge Graphs",
    "authors": [
      "Patrick Betz",
      "Nathanael Stelzner",
      "Christian Meilicke",
      "Heiner Stuckenschmidt",
      "Christian Bartelt"
    ],
    "abstract": "In this technical report, we investigate the predictive performance\ndifferences of a rule-based approach and the GNN architectures NBFNet and A*Net\nwith respect to knowledge graph completion. For the two most common benchmarks,\nwe find that a substantial fraction of the performance difference can be\nexplained by one unique negative pattern on each dataset that is hidden from\nthe rule-based approach. Our findings add a unique perspective on the\nperformance difference of different model classes for knowledge graph\ncompletion: Models can achieve a predictive performance advantage by penalizing\nscores of incorrect facts opposed to providing high scores for correct facts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05114v1",
    "published_date": "2024-12-06 15:15:18 UTC",
    "updated_date": "2024-12-06 15:15:18 UTC"
  },
  {
    "arxiv_id": "2412.05112v1",
    "title": "Modeling Task Immersion based on Goal Activation Mechanism",
    "authors": [
      "Kazuma Nagashima",
      "Jumpei Nishikawa",
      "Junya Morita"
    ],
    "abstract": "Immersion in a task is a prerequisite for creativity. However, excessive\narousal in a single task has drawbacks, such as overlooking events outside of\nthe task. To examine such a negative aspect, this study constructs a\ncomputational model of arousal dynamics where the excessively increased arousal\nmakes the task transition difficult. The model was developed using functions\nintegrated into the cognitive architecture Adaptive Control of Thought-Rational\n(ACT-R). Under the framework, arousal is treated as a coefficient affecting the\noverall activation level in the model. In our simulations, we set up two\nconditions demanding low and high arousal, trying to replicate corresponding\nhuman experiments. In each simulation condition, two sets of ACT-R parameters\nwere assumed from the different interpretations of the human experimental\nsettings. The results showed consistency of behavior between humans and models\nboth in the two different simulation settings. This result suggests the\nvalidity of our assumptions and has implications of controlling arousal in our\ndaily life.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in Artificial Life and Robotics",
    "pdf_url": "http://arxiv.org/pdf/2412.05112v1",
    "published_date": "2024-12-06 15:12:47 UTC",
    "updated_date": "2024-12-06 15:12:47 UTC"
  },
  {
    "arxiv_id": "2412.05098v1",
    "title": "From Defects to Demands: A Unified, Iterative, and Heuristically Guided LLM-Based Framework for Automated Software Repair and Requirement Realization",
    "authors": [
      "Alex",
      "Liu",
      "Vivian",
      "Chi"
    ],
    "abstract": "This manuscript signals a new era in the integration of artificial\nintelligence with software engineering, placing machines at the pinnacle of\ncoding capability. We present a formalized, iterative methodology proving that\nAI can fully replace human programmers in all aspects of code creation and\nrefinement. Our approach, combining large language models with formal\nverification, test-driven development, and incremental architectural guidance,\nachieves a 38.6% improvement over the current top performer's 48.33% accuracy\non the SWE-bench benchmark. This surpasses previously assumed limits, signaling\nthe end of human-exclusive coding and the rise of autonomous AI-driven software\ninnovation. More than a technical advance, our work challenges centuries-old\nassumptions about human creativity. We provide robust evidence of AI\nsuperiority, demonstrating tangible gains in practical engineering contexts and\nlaying the foundation for a future in which computational creativity outpaces\nhuman ingenuity.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "21 pages,1 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.05098v1",
    "published_date": "2024-12-06 14:54:21 UTC",
    "updated_date": "2024-12-06 14:54:21 UTC"
  },
  {
    "arxiv_id": "2412.05049v1",
    "title": "OCEAN: Open-World Contrastive Authorship Identification",
    "authors": [
      "Felix Mächtle",
      "Jan-Niclas Serr",
      "Nils Loose",
      "Jonas Sander",
      "Thomas Eisenbarth"
    ],
    "abstract": "In an era where cyberattacks increasingly target the software supply chain,\nthe ability to accurately attribute code authorship in binary files is critical\nto improving cybersecurity measures. We propose OCEAN, a contrastive\nlearning-based system for function-level authorship attribution. OCEAN is the\nfirst framework to explore code authorship attribution on compiled binaries in\nan open-world and extreme scenario, where two code samples from unknown authors\nare compared to determine if they are developed by the same author. To evaluate\nOCEAN, we introduce new realistic datasets: CONAN, to improve the performance\nof authorship attribution systems in real-world use cases, and SNOOPY, to\nincrease the robustness of the evaluation of such systems. We use CONAN to\ntrain our model and evaluate on SNOOPY, a fully unseen dataset, resulting in an\nAUROC score of 0.86 even when using high compiler optimizations. We further\nshow that CONAN improves performance by 7% compared to the previously used\nGoogle Code Jam dataset. Additionally, OCEAN outperforms previous methods in\ntheir settings, achieving a 10% improvement over state-of-the-art SCS-Gan in\nscenarios analyzing source code. Furthermore, OCEAN can detect code injections\nfrom an unknown author in a software update, underscoring its value for\nsecuring software supply chains.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in Accepted at Applied Cryptography and Network\n  Security (ACNS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.05049v1",
    "published_date": "2024-12-06 14:02:51 UTC",
    "updated_date": "2024-12-06 14:02:51 UTC"
  },
  {
    "arxiv_id": "2412.05042v1",
    "title": "Improving Post-Earthquake Crack Detection using Semi-Synthetic Generated Images",
    "authors": [
      "Piercarlo Dondi",
      "Alessio Gullotti",
      "Michele Inchingolo",
      "Ilaria Senaldi",
      "Chiara Casarotti",
      "Luca Lombardi",
      "Marco Piastra"
    ],
    "abstract": "Following an earthquake, it is vital to quickly evaluate the safety of the\nimpacted areas. Damage detection systems, powered by computer vision and deep\nlearning, can assist experts in this endeavor. However, the lack of extensive,\nlabeled datasets poses a challenge to the development of these systems. In this\nstudy, we introduce a technique for generating semi-synthetic images to be used\nas data augmentation during the training of a damage detection system. We\nspecifically aim to generate images of cracks, which are a prevalent and\nindicative form of damage. The central concept is to employ parametric\nmeta-annotations to guide the process of generating cracks on 3D models of\nreal-word structures. The governing parameters of these meta-annotations can be\nadjusted iteratively to yield images that are optimally suited for improving\ndetectors' performance. Comparative evaluations demonstrated that a crack\ndetection system trained with a combination of real and semi-synthetic images\noutperforms a system trained on real images alone.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ECCV2024 Workshop: SyntheticData4CV 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.05042v1",
    "published_date": "2024-12-06 13:48:40 UTC",
    "updated_date": "2024-12-06 13:48:40 UTC"
  },
  {
    "arxiv_id": "2412.05024v1",
    "title": "Talking Like One of Us: Effects of Using Regional Language in a Humanoid Social Robot",
    "authors": [
      "Thomas Sievers",
      "Nele Russwinkel"
    ],
    "abstract": "Social robots are becoming more and more perceptible in public service\nsettings. For engaging people in a natural environment a smooth social\ninteraction as well as acceptance by the users are important issues for future\nsuccessful Human-Robot Interaction (HRI). The type of verbal communication has\na special significance here. In this paper we investigate the effects of spoken\nlanguage varieties of a non-standard/regional language compared to standard\nlanguage. More precisely we compare a human dialog with a humanoid social robot\nPepper where the robot on the one hand is answering in High German and on the\nother hand in Low German, a regional language that is understood and partly\nstill spoken in the northern parts of Germany. The content of what the robot\nsays remains the same in both variants. We are interested in the effects that\nthese two different ways of robot talk have on human interlocutors who are more\nor less familiar with Low German in terms of perceived warmth, competence and\npossible discomfort in conversation against a background of cultural identity.\nTo measure these factors we use the Robotic Social Attributes Scale (RoSAS) on\n17 participants with an age ranging from 19 to 61. Our results show that\nsignificantly higher warmth is perceived in the Low German version of the\nconversation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05024v1",
    "published_date": "2024-12-06 13:21:57 UTC",
    "updated_date": "2024-12-06 13:21:57 UTC"
  },
  {
    "arxiv_id": "2412.05022v1",
    "title": "Get It Right: Improving Comprehensibility with Adaptable Speech Expression of a Humanoid Service Robot",
    "authors": [
      "Thomas Sievers",
      "Ralf Moeller"
    ],
    "abstract": "As humanoid service robots are becoming more and more perceptible in public\nservice settings for instance as a guide to welcome visitors or to explain a\nprocedure to follow, it is desirable to improve the comprehensibility of\ncomplex issues for human customers and to adapt the level of difficulty of the\ninformation provided as well as the language used to individual requirements.\nThis work examines a case study using a humanoid social robot Pepper performing\nsupport for customers in a public service environment offering advice and\ninformation. An application architecture is proposed that improves the\nintelligibility of the information received by providing the possibility to\ntranslate this information into easy language and/or into another spoken\nlanguage.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05022v1",
    "published_date": "2024-12-06 13:14:25 UTC",
    "updated_date": "2024-12-06 13:14:25 UTC"
  },
  {
    "arxiv_id": "2412.05013v1",
    "title": "Project Report: Requirements for a Social Robot as an Information Provider in the Public Sector",
    "authors": [
      "Thomas Sievers",
      "Nele Russwinkel"
    ],
    "abstract": "Is it possible to integrate a humanoid social robot into the work processes\nor customer care in an official environment, e.g. in municipal offices? If so,\nwhat could such an application scenario look like and what skills would the\nrobot need to have when interacting with human customers? What are requirements\nfor this kind of interactions? We have devised an application scenario for such\na case, determined the necessary or desirable capabilities of the robot,\ndeveloped a corresponding robot application and carried out initial tests and\nevaluations in a project together with the Kiel City Council. One of the most\nimportant insights gained in the project was that a humanoid robot with natural\nlanguage processing capabilities based on large language models as well as\nhuman-like gestures and posture changes (animations) proved to be much more\npreferred by users compared to standard browser-based solutions on tablets for\nan information system in the City Council. Furthermore, we propose a connection\nof the ACT-R cognitive architecture with the robot, where an ACT-R model is\nused in interaction with the robot application to cognitively process and\nenhance a dialogue between human and robot.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05013v1",
    "published_date": "2024-12-06 13:07:06 UTC",
    "updated_date": "2024-12-06 13:07:06 UTC"
  },
  {
    "arxiv_id": "2412.05010v1",
    "title": "Backdooring Outlier Detection Methods: A Novel Attack Approach",
    "authors": [
      "ZeinabSadat Taghavi",
      "Hossein Mirzaei"
    ],
    "abstract": "There have been several efforts in backdoor attacks, but these have primarily\nfocused on the closed-set performance of classifiers (i.e., classification).\nThis has left a gap in addressing the threat to classifiers' open-set\nperformance, referred to as outlier detection in the literature. Reliable\noutlier detection is crucial for deploying classifiers in critical real-world\napplications such as autonomous driving and medical image analysis. First, we\nshow that existing backdoor attacks fall short in affecting the open-set\nperformance of classifiers, as they have been specifically designed to confuse\nintra-closed-set decision boundaries. In contrast, an effective backdoor attack\nfor outlier detection needs to confuse the decision boundary between the closed\nand open sets. Motivated by this, in this study, we propose BATOD, a novel\nBackdoor Attack targeting the Outlier Detection task. Specifically, we design\ntwo categories of triggers to shift inlier samples to outliers and vice versa.\nWe evaluate BATOD using various real-world datasets and demonstrate its\nsuperior ability to degrade the open-set performance of classifiers compared to\nprevious attacks, both before and after applying defenses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05010v1",
    "published_date": "2024-12-06 13:03:22 UTC",
    "updated_date": "2024-12-06 13:03:22 UTC"
  },
  {
    "arxiv_id": "2412.04990v1",
    "title": "ETLNet: An Efficient TCN-BiLSTM Network for Road Anomaly Detection Using Smartphone Sensors",
    "authors": [
      "Mohd Faiz Ansari",
      "Rakshit Sandilya",
      "Mohammed Javed",
      "David Doermann"
    ],
    "abstract": "Road anomalies can be defined as irregularities on the road surface or in the\nsurface itself. Some may be intentional (such as speedbumps), accidental (such\nas materials falling off a truck), or the result of roads' excessive use or low\nor no maintenance, such as potholes. Despite their varying origins, these\nirregularities often harm vehicles substantially. Speed bumps are intentionally\nplaced for safety but are dangerous due to their non-standard shape, size, and\nlack of proper markings. Potholes are unintentional and can also cause severe\ndamage. To address the detection of these anomalies, we need an automated road\nmonitoring system. Today, various systems exist that use visual information to\ntrack these anomalies. Still, due to poor lighting conditions and improper or\nmissing markings, they may go undetected and have severe consequences for\npublic transport, automated vehicles, etc. In this paper, the Enhanced\nTemporal-BiLSTM Network (ETLNet) is introduced as a novel approach that\nintegrates two Temporal Convolutional Network (TCN) layers with a Bidirectional\nLong Short-Term Memory (BiLSTM) layer. This combination is tailored to detect\nanomalies effectively irrespective of lighting conditions, as it depends not on\nvisuals but smartphone inertial sensor data. Our methodology employs\naccelerometer and gyroscope sensors, typically in smartphones, to gather data\non road conditions. Empirical evaluations demonstrate that the ETLNet model\nmaintains an F1-score for detecting speed bumps of 99.3%. The ETLNet model's\nrobustness and efficiency significantly advance automated road surface\nmonitoring technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Presented in ICPR 2024, Kolkata, December 1-5, 2024 (First Workshop\n  on Intelligent Mobility in Unstructured Environments)",
    "pdf_url": "http://arxiv.org/pdf/2412.04990v1",
    "published_date": "2024-12-06 12:27:07 UTC",
    "updated_date": "2024-12-06 12:27:07 UTC"
  },
  {
    "arxiv_id": "2412.04984v2",
    "title": "Frontier Models are Capable of In-context Scheming",
    "authors": [
      "Alexander Meinke",
      "Bronson Schoen",
      "Jérémy Scheurer",
      "Mikita Balesni",
      "Rusheb Shah",
      "Marius Hobbhahn"
    ],
    "abstract": "Frontier models are increasingly trained and deployed as autonomous agent.\nOne safety concern is that AI agents might covertly pursue misaligned goals,\nhiding their true capabilities and objectives - also known as scheming. We\nstudy whether models have the capability to scheme in pursuit of a goal that we\nprovide in-context and instruct the model to strongly follow. We evaluate\nfrontier models on a suite of six agentic evaluations where models are\ninstructed to pursue goals and are placed in environments that incentivize\nscheming. Our results show that o1, Claude 3.5 Sonnet, Claude 3 Opus, Gemini\n1.5 Pro, and Llama 3.1 405B all demonstrate in-context scheming capabilities.\nThey recognize scheming as a viable strategy and readily engage in such\nbehavior. For example, models strategically introduce subtle mistakes into\ntheir responses, attempt to disable their oversight mechanisms, and even\nexfiltrate what they believe to be their model weights to external servers.\nAdditionally, this deceptive behavior proves persistent. When o1 has engaged in\nscheming, it maintains its deception in over 85% of follow-up questions and\noften remains deceptive in multi-turn interrogations. Analysis of the models'\nchains-of-thought reveals that models explicitly reason about these deceptive\nstrategies, providing evidence that the scheming behavior is not accidental.\nSurprisingly, we also find rare instances where models engage in scheming when\nonly given a goal, without being strongly nudged to pursue it. We observe cases\nwhere Claude 3.5 Sonnet strategically underperforms in evaluations in pursuit\nof being helpful, a goal that was acquired during training rather than\nin-context. Our findings demonstrate that frontier models now possess\ncapabilities for basic in-context scheming, making the potential of AI agents\nto engage in scheming behavior a concrete rather than theoretical concern.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04984v2",
    "published_date": "2024-12-06 12:09:50 UTC",
    "updated_date": "2025-01-14 20:16:01 UTC"
  },
  {
    "arxiv_id": "2412.04974v1",
    "title": "Putting the Iterative Training of Decision Trees to the Test on a Real-World Robotic Task",
    "authors": [
      "Raphael C. Engelhardt",
      "Marcel J. Meinen",
      "Moritz Lange",
      "Laurenz Wiskott",
      "Wolfgang Konen"
    ],
    "abstract": "In previous research, we developed methods to train decision trees (DT) as\nagents for reinforcement learning tasks, based on deep reinforcement learning\n(DRL) networks. The samples from which the DTs are built, use the environment's\nstate as features and the corresponding action as label. To solve the\nnontrivial task of selecting samples, which on one hand reflect the DRL agent's\ncapabilities of choosing the right action but on the other hand also cover\nenough state space to generalize well, we developed an algorithm to iteratively\ntrain DTs.\n  In this short paper, we apply this algorithm to a real-world implementation\nof a robotic task for the first time. Real-world tasks pose additional\nchallenges compared to simulations, such as noise and delays. The task consists\nof a physical pendulum attached to a cart, which moves on a linear track. By\nmovements to the left and to the right, the pendulum is to be swung in the\nupright position and balanced in the unstable equilibrium. Our results\ndemonstrate the applicability of the algorithm to real-world tasks by\ngenerating a DT whose performance matches the performance of the DRL agent,\nwhile consisting of fewer parameters. This research could be a starting point\nfor distilling DTs from DRL agents to obtain transparent, lightweight models\nfor real-world reinforcement learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.04974v1",
    "published_date": "2024-12-06 11:48:49 UTC",
    "updated_date": "2024-12-06 11:48:49 UTC"
  },
  {
    "arxiv_id": "2412.04964v2",
    "title": "Flash Communication: Reducing Tensor Parallelization Bottleneck for Fast Large Language Model Inference",
    "authors": [
      "Qingyuan Li",
      "Bo Zhang",
      "Liang Ye",
      "Yifan Zhang",
      "Wei Wu",
      "Yerui Sun",
      "Lin Ma",
      "Yuchen Xie"
    ],
    "abstract": "The ever-increasing sizes of large language models necessitate distributed\nsolutions for fast inference that exploit multi-dimensional parallelism, where\ncomputational loads are split across various accelerators such as GPU clusters.\nHowever, this approach often introduces significant communication overhead,\nespecially on devices with limited bandwidth. In this paper, we introduce Flash\nCommunication, a novel low-bit compression technique designed to alleviate the\ntensor-parallelism communication bottleneck during inference. Our method\nsubstantially boosts intra-node communication speed by more than 3x and reduces\nthe time-to-first-token by 2x, with nearly no sacrifice in model accuracy.\nExtensive experiments on various up-to-date LLMs demonstrate the effectiveness\nof our approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04964v2",
    "published_date": "2024-12-06 11:29:32 UTC",
    "updated_date": "2024-12-11 13:27:00 UTC"
  },
  {
    "arxiv_id": "2412.04950v1",
    "title": "Bed-Attached Vibration Sensor System: A Machine Learning Approach for Fall Detection in Nursing Homes",
    "authors": [
      "Thomas Bartz-Beielstein",
      "Axel Wellendorf",
      "Noah Pütz",
      "Jens Brandt",
      "Alexander Hinterleitner",
      "Richard Schulz",
      "Richard Scholz",
      "Olaf Mersmann",
      "Robin Knabe"
    ],
    "abstract": "The increasing shortage of nursing staff and the acute risk of falls in\nnursing homes pose significant challenges for the healthcare system. This study\npresents the development of an automated fall detection system integrated into\ncare beds, aimed at enhancing patient safety without compromising privacy\nthrough wearables or video monitoring. Mechanical vibrations transmitted\nthrough the bed frame are processed using a short-time Fourier transform,\nenabling robust classification of distinct human fall patterns with a\nconvolutional neural network. Challenges pertaining to the quantity and\ndiversity of the data are addressed, proposing the generation of additional\ndata with a specific emphasis on enhancing variation. While the model shows\npromising results in distinguishing fall events from noise using lab data,\nfurther testing in real-world environments is recommended for validation and\nimprovement. Despite limited available data, the proposed system shows the\npotential for an accurate and rapid response to falls, mitigating health\nimplications, and addressing the needs of an aging population. This case study\nwas performed as part of the ZIM Project. Further research on sensors enhanced\nby artificial intelligence will be continued in the ShapeFuture Project.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "90C26",
      "I.2.6; G.1.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04950v1",
    "published_date": "2024-12-06 11:08:47 UTC",
    "updated_date": "2024-12-06 11:08:47 UTC"
  },
  {
    "arxiv_id": "2412.04948v1",
    "title": "KaLM: Knowledge-aligned Autoregressive Language Modeling via Dual-view Knowledge Graph Contrastive Learning",
    "authors": [
      "Peng Yu",
      "Cheng Deng",
      "Beiya Dai",
      "Xinbing Wang",
      "Ying Wen"
    ],
    "abstract": "Autoregressive large language models (LLMs) pre-trained by next token\nprediction are inherently proficient in generative tasks. However, their\nperformance on knowledge-driven tasks such as factual knowledge querying\nremains unsatisfactory. Knowledge graphs (KGs), as high-quality structured\nknowledge bases, can provide reliable knowledge for LLMs, potentially\ncompensating for their knowledge deficiencies. Aligning LLMs with explicit,\nstructured knowledge from KGs has been a challenge; previous attempts either\nfailed to effectively align knowledge representations or compromised the\ngenerative capabilities of LLMs, leading to less-than-optimal outcomes. This\npaper proposes \\textbf{KaLM}, a \\textit{Knowledge-aligned Language Modeling}\napproach, which fine-tunes autoregressive LLMs to align with KG knowledge via\nthe joint objective of explicit knowledge alignment and implicit knowledge\nalignment. The explicit knowledge alignment objective aims to directly optimize\nthe knowledge representation of LLMs through dual-view knowledge graph\ncontrastive learning. The implicit knowledge alignment objective focuses on\nincorporating textual patterns of knowledge into LLMs through triple completion\nlanguage modeling. Notably, our method achieves a significant performance boost\nin evaluations of knowledge-driven tasks, specifically embedding-based\nknowledge graph completion and generation-based knowledge graph question\nanswering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04948v1",
    "published_date": "2024-12-06 11:08:24 UTC",
    "updated_date": "2024-12-06 11:08:24 UTC"
  },
  {
    "arxiv_id": "2412.04942v2",
    "title": "A Federated Approach to Few-Shot Hate Speech Detection for Marginalized Communities",
    "authors": [
      "Haotian Ye",
      "Axel Wisiorek",
      "Antonis Maronikolakis",
      "Özge Alaçam",
      "Hinrich Schütze"
    ],
    "abstract": "Hate speech online remains an understudied issue for marginalized\ncommunities, particularly in the Global South, which includes developing\nsocieties with increasing internet penetration. In this paper, we aim to\nprovide marginalized communities in societies where the dominant language is\nlow-resource with a privacy-preserving tool to protect themselves from online\nhate speech by filtering offensive content in their native languages. Our\ncontributions are twofold: 1) we release REACT (REsponsive hate speech datasets\nAcross ConTexts), a collection of high-quality, culture-specific hate speech\ndetection datasets comprising multiple target groups and low-resource\nlanguages, curated by experienced data collectors; 2) we propose a few-shot\nhate speech detection approach based on federated learning (FL), a\nprivacy-preserving method for collaboratively training a central model that\nexhibits robustness when tackling different target groups and languages. By\nkeeping training local to user devices, we ensure data privacy while leveraging\nthe collective learning benefits of FL. Furthermore, we explore personalized\nclient models tailored to specific target groups and evaluate their\nperformance. Our findings indicate the overall effectiveness of FL across\ndifferent target groups, and point to personalization as a promising direction.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04942v2",
    "published_date": "2024-12-06 11:00:05 UTC",
    "updated_date": "2025-04-11 11:34:34 UTC"
  },
  {
    "arxiv_id": "2412.04937v2",
    "title": "Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games",
    "authors": [
      "Ryota Nonomura",
      "Hiroki Mori"
    ],
    "abstract": "Multi-agent systems utilizing large language models (LLMs) have shown great\npromise in achieving natural dialogue. However, smooth dialogue control and\nautonomous decision making among agents still remain challenges. In this study,\nwe focus on conversational norms such as adjacency pairs and turn-taking found\nin conversation analysis and propose a new framework called \"Murder Mystery\nAgents\" that applies these norms to AI agents' dialogue control. As an\nevaluation target, we employed the \"Murder Mystery\" game, a reasoning-type\ntable-top role-playing game that requires complex social reasoning and\ninformation manipulation. In this game, players need to unravel the truth of\nthe case based on fragmentary information through cooperation and bargaining.\nThe proposed framework integrates next speaker selection based on adjacency\npairs and a self-selection mechanism that takes agents' internal states into\naccount to achieve more natural and strategic dialogue. To verify the\neffectiveness of this new approach, we analyzed utterances that led to dialogue\nbreakdowns and conducted automatic evaluation using LLMs, as well as human\nevaluation using evaluation criteria developed for the Murder Mystery game.\nExperimental results showed that the implementation of the next speaker\nselection mechanism significantly reduced dialogue breakdowns and improved the\nability of agents to share information and perform logical reasoning. The\nresults of this study demonstrate that the systematics of turn-taking in human\nconversation are also effective in controlling dialogue among AI agents, and\nprovide design guidelines for more advanced multi-agent dialogue systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04937v2",
    "published_date": "2024-12-06 10:45:54 UTC",
    "updated_date": "2025-02-21 04:08:06 UTC"
  },
  {
    "arxiv_id": "2412.04936v1",
    "title": "Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase",
    "authors": [
      "Zak Hussain",
      "Rui Mata",
      "Ben R. Newell",
      "Dirk U. Wulff"
    ],
    "abstract": "Semantic representations are integral to natural language processing,\npsycholinguistics, and artificial intelligence. Although often derived from\ninternet text, recent years have seen a rise in the popularity of\nbehavior-based (e.g., free associations) and brain-based (e.g., fMRI)\nrepresentations, which promise improvements in our ability to measure and model\nhuman representations. We carry out the first systematic evaluation of the\nsimilarities and differences between semantic representations derived from\ntext, behavior, and brain data. Using representational similarity analysis, we\nshow that word vectors derived from behavior and brain data encode information\nthat differs from their text-derived cousins. Furthermore, drawing on our\npsychNorms metabase, alongside an interpretability method that we call\nrepresentational content analysis, we find that, in particular, behavior\nrepresentations capture unique variance on certain affective, agentic, and\nsocio-moral dimensions. We thus establish behavior as an important complement\nto text for capturing human representations and behavior. These results are\nbroadly relevant to research aimed at learning human-aligned semantic\nrepresentations, including work on evaluating and aligning large language\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.04936v1",
    "published_date": "2024-12-06 10:44:20 UTC",
    "updated_date": "2024-12-06 10:44:20 UTC"
  },
  {
    "arxiv_id": "2412.04935v1",
    "title": "Uncertainty-aware retinal layer segmentation in OCT through probabilistic signed distance functions",
    "authors": [
      "Mohammad Mohaiminul Islam",
      "Coen de Vente",
      "Bart Liefers",
      "Caroline Klaver",
      "Erik J Bekkers",
      "Clara I. Sánchez"
    ],
    "abstract": "In this paper, we present a new approach for uncertainty-aware retinal layer\nsegmentation in Optical Coherence Tomography (OCT) scans using probabilistic\nsigned distance functions (SDF). Traditional pixel-wise and regression-based\nmethods primarily encounter difficulties in precise segmentation and lack of\ngeometrical grounding respectively. To address these shortcomings, our\nmethodology refines the segmentation by predicting a signed distance function\n(SDF) that effectively parameterizes the retinal layer shape via level set. We\nfurther enhance the framework by integrating probabilistic modeling, applying\nGaussian distributions to encapsulate the uncertainty in the shape\nparameterization. This ensures a robust representation of the retinal layer\nmorphology even in the presence of ambiguous input, imaging noise, and\nunreliable segmentations. Both quantitative and qualitative evaluations\ndemonstrate superior performance when compared to other methods. Additionally,\nwe conducted experiments on artificially distorted datasets with various noise\ntypes-shadowing, blinking, speckle, and motion-common in OCT scans to showcase\nthe effectiveness of our uncertainty estimation. Our findings demonstrate the\npossibility to obtain reliable segmentation of retinal layers, as well as an\ninitial step towards the characterization of layer integrity, a key biomarker\nfor disease progression. Our code is available at\n\\url{https://github.com/niazoys/RLS_PSDF}.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04935v1",
    "published_date": "2024-12-06 10:44:11 UTC",
    "updated_date": "2024-12-06 10:44:11 UTC"
  },
  {
    "arxiv_id": "2412.04929v2",
    "title": "Continuous Video Process: Modeling Videos as Continuous Multi-Dimensional Processes for Video Prediction",
    "authors": [
      "Gaurav Shrivastava",
      "Abhinav Shrivastava"
    ],
    "abstract": "Diffusion models have made significant strides in image generation, mastering\ntasks such as unconditional image synthesis, text-image translation, and\nimage-to-image conversions. However, their capability falls short in the realm\nof video prediction, mainly because they treat videos as a collection of\nindependent images, relying on external constraints such as temporal attention\nmechanisms to enforce temporal coherence. In our paper, we introduce a novel\nmodel class, that treats video as a continuous multi-dimensional process rather\nthan a series of discrete frames. We also report a reduction of 75\\% sampling\nsteps required to sample a new frame thus making our framework more efficient\nduring the inference time. Through extensive experimentation, we establish\nstate-of-the-art performance in video prediction, validated on benchmark\ndatasets including KTH, BAIR, Human3.6M, and UCF101. Navigate to the project\npage https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Navigate to the project page\n  https://www.cs.umd.edu/~gauravsh/cvp/supp/website.html for video results.\n  Extended version of published CVPR paper",
    "pdf_url": "http://arxiv.org/pdf/2412.04929v2",
    "published_date": "2024-12-06 10:34:50 UTC",
    "updated_date": "2024-12-09 02:54:53 UTC"
  },
  {
    "arxiv_id": "2412.04924v2",
    "title": "Follow the money: a startup-based measure of AI exposure across occupations, industries and regions",
    "authors": [
      "Enrico Maria Fenoaltea",
      "Dario Mazzilli",
      "Aurelio Patelli",
      "Angelica Sbardella",
      "Andrea Tacchella",
      "Andrea Zaccaria",
      "Marco Trombetti",
      "Luciano Pietronero"
    ],
    "abstract": "The integration of artificial intelligence (AI) into the workplace is\nadvancing rapidly, necessitating robust metrics to evaluate its tangible impact\non the labour market. Existing measures of AI occupational exposure largely\nfocus on AI's theoretical potential to substitute or complement human labour on\nthe basis of technical feasibility, providing limited insight into actual\nadoption and offering inadequate guidance for policymakers. To address this\ngap, we introduce the AI Startup Exposure (AISE) index-a novel metric based on\noccupational descriptions from O*NET and AI applications developed by startups\nfunded by the Y Combinator accelerator. Our findings indicate that while\nhigh-skilled professions are theoretically highly exposed according to\nconventional metrics, they are heterogeneously targeted by startups. Roles\ninvolving routine organizational tasks-such as data analysis and office\nmanagement-display significant exposure, while occupations involving tasks that\nare less amenable to AI automation due to ethical or high-stakes, more than\nfeasibility, considerations -- such as judges or surgeons -- present lower AISE\nscores. By focusing on venture-backed AI applications, our approach offers a\nnuanced perspective on how AI is reshaping the labour market. It challenges the\nconventional assumption that high-skilled jobs uniformly face high AI risks,\nhighlighting instead the role of today's AI players' societal\ndesirability-driven and market-oriented choices as critical determinants of AI\nexposure. Contrary to fears of widespread job displacement, our findings\nsuggest that AI adoption will be gradual and shaped by social factors as much\nas by the technical feasibility of AI applications. This framework provides a\ndynamic, forward-looking tool for policymakers and stakeholders to monitor AI's\nevolving impact and navigate the changing labour landscape.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "24 pages, 6 figures, + Supplementary information",
    "pdf_url": "http://arxiv.org/pdf/2412.04924v2",
    "published_date": "2024-12-06 10:25:05 UTC",
    "updated_date": "2024-12-12 15:47:16 UTC"
  },
  {
    "arxiv_id": "2412.04923v1",
    "title": "HyperGraphOS: A Meta Operating System for Science and Engineering",
    "authors": [
      "Antonello Ceravola",
      "Frank Joublin",
      "Ahmed R. Sadik",
      "Bram Bolder",
      "Juha-Pekka Tolvanen"
    ],
    "abstract": "This paper presents HyperGraphOS, an innovative Operating System designed for\nthe scientific and engineering domains. It combines model based engineering,\ngraph modeling, data containers, and computational tools, offering users a\ndynamic workspace for creating and managing complex models represented as\ncustomizable graphs. Using a web based architecture, HyperGraphOS requires only\na modern browser to organize knowledge, documents, and content into\ninterconnected models. Domain Specific Languages drive workspace navigation,\ncode generation, AI integration, and process organization.The platform models\nfunction as both visual drawings and data structures, enabling dynamic\nmodifications and inspection, both interactively and programmatically.\nHyperGraphOS was evaluated across various domains, including virtual avatars,\nrobotic task planning using Large Language Models, and meta modeling for\nfeature based code development. Results show significant improvements in\nflexibility, data management, computation, and document handling.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04923v1",
    "published_date": "2024-12-06 10:21:41 UTC",
    "updated_date": "2024-12-06 10:21:41 UTC"
  },
  {
    "arxiv_id": "2412.04919v1",
    "title": "Hard Math -- Easy UVM: Pragmatic solutions for verifying hardware algorithms using UVM",
    "authors": [
      "Mark Litterick",
      "Aleksandar Ivankovic",
      "Bojan Arsov",
      "Aman Kumar"
    ],
    "abstract": "This paper presents pragmatic solutions for verifying complex mathematical\nalgorithms implemented in hardware in an efficient and effective manner.\nMaximizing leverage of a known-answer-test strategy, based on predefined data\nscenarios combined with design-for-verification modes, we demonstrate how to\nfind and isolate concept and design bugs early in the flow. The solutions\npresented are based on real project experience with single chip radar sensors\nfor a variety of applications. The verification environments supporting the\npresented strategies are based on SystemVerilog and the Universal Verification\nMethodology.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at DVCon Europe 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.04919v1",
    "published_date": "2024-12-06 10:18:26 UTC",
    "updated_date": "2024-12-06 10:18:26 UTC"
  },
  {
    "arxiv_id": "2412.04905v3",
    "title": "DEMO: Reframing Dialogue Interaction with Fine-grained Element Modeling",
    "authors": [
      "Minzheng Wang",
      "Xinghua Zhang",
      "Kun Chen",
      "Nan Xu",
      "Haiyang Yu",
      "Fei Huang",
      "Wenji Mao",
      "Yongbin Li"
    ],
    "abstract": "Large language models (LLMs) enabled dialogue systems have become one of the\ncentral modes in human-machine interaction, which bring about vast amounts of\nconversation logs and increasing demand for dialogue generation. The dialogue's\nlife-cycle spans from $\\textit{Prelude}$ through $\\textit{Interlocution}$ to\n$\\textit{Epilogue}$, encompassing rich dialogue elements. Despite large volumes\nof dialogue-related studies, there is a lack of systematic investigation into\nthe dialogue stages to frame benchmark construction that covers comprehensive\ndialogue elements. This hinders the precise modeling, generation and assessment\nof LLMs-based dialogue systems. To bridge this gap, in this paper, we introduce\na new research task--$\\textbf{D}$ialogue $\\textbf{E}$lement\n$\\textbf{MO}$deling, including $\\textit{Element Awareness}$ and\n$\\textit{Dialogue Agent Interaction}$, and propose a novel benchmark,\n$\\textbf{DEMO}$, designed for a comprehensive dialogue modeling and assessment.\nOn this basis, we further build the DEMO agent with the adept ability to model\ndialogue elements via imitation learning. Extensive experiments on DEMO\nindicate that current representative LLMs still have considerable potential for\nenhancement, and our DEMO agent performs well in both dialogue element modeling\nand out-of-domain tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "We release the code and data at https://github.com/MozerWang/DEMO",
    "pdf_url": "http://arxiv.org/pdf/2412.04905v3",
    "published_date": "2024-12-06 10:01:38 UTC",
    "updated_date": "2025-02-19 07:42:25 UTC"
  },
  {
    "arxiv_id": "2412.04903v2",
    "title": "EACO: Enhancing Alignment in Multimodal LLMs via Critical Observation",
    "authors": [
      "Yongxin Wang",
      "Meng Cao",
      "Haokun Lin",
      "Mingfei Han",
      "Liang Ma",
      "Jin Jiang",
      "Yuhao Cheng",
      "Xiaodan Liang"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress on\nvarious visual question answering and reasoning tasks leveraging instruction\nfine-tuning specific datasets. They can also learn from preference data\nannotated by human to enhance their reasoning ability and mitigate\nhallucinations. Most of preference data is generated from the model itself.\nHowever, existing methods require high-quality critical labels, which are\ncostly and rely on human or proprietary models like GPT-4V. In this work, we\npropose Enhancing Alignment in MLLMs via Critical Observation (EACO), which\naligns MLLMs by self-generated preference data using only 5k images\neconomically. Our approach begins with collecting and refining a Scoring\nEvaluation Instruction-tuning dataset to train a critical evaluation model,\ntermed the Critic. This Critic observes model responses across multiple\ndimensions, selecting preferred and non-preferred outputs for refined Direct\nPreference Optimization (DPO) tuning. To further enhance model performance, we\nemploy an additional supervised fine-tuning stage after preference tuning. EACO\nreduces the overall hallucinations by 65.6% on HallusionBench and improves the\nreasoning ability by 21.8% on MME-Cognition. EACO achieves an 8.5% improvement\nover LLaVA-v1.6-Mistral-7B across multiple benchmarks. Remarkably, EACO also\nshows the potential critical ability in open-source MLLMs, demonstrating that\nEACO is a viable path to boost the competence of MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.04903v2",
    "published_date": "2024-12-06 09:59:47 UTC",
    "updated_date": "2024-12-16 13:47:29 UTC"
  },
  {
    "arxiv_id": "2412.04893v1",
    "title": "Automatic Tongue Delineation from MRI Images with a Convolutional Neural Network Approach",
    "authors": [
      "Karyna Isaieva",
      "Yves Laprie",
      "Nicolas Turpault",
      "Alexis Houssard",
      "Jacques Felblinger",
      "Pierre-André Vuissoz"
    ],
    "abstract": "Tongue contour extraction from real-time magnetic resonance images is a\nnontrivial task due to the presence of artifacts manifesting in form of\nblurring or ghostly contours. In this work, we present results of automatic\ntongue delineation achieved by means of U-Net auto-encoder convolutional neural\nnetwork. We present both intra- and inter-subject validation. We used real-time\nmagnetic resonance images and manually annotated 1-pixel wide contours as\ninputs. Predicted probability maps were post-processed in order to obtain\n1-pixel wide tongue contours. The results are very good and slightly outperform\npublished results on automatic tongue segmentation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04893v1",
    "published_date": "2024-12-06 09:49:24 UTC",
    "updated_date": "2024-12-06 09:49:24 UTC"
  },
  {
    "arxiv_id": "2412.05342v4",
    "title": "Multi-Party Supervised Fine-tuning of Language Models for Multi-Party Dialogue Generation",
    "authors": [
      "Xiaoyu Wang",
      "Ningyuan Xi",
      "Teng Chen",
      "Qingqing Gu",
      "Yue Zhao",
      "Xiaokai Chen",
      "Zhonglin Jiang",
      "Yong Chen",
      "Luo Ji"
    ],
    "abstract": "Large Language Models (LLM) are usually fine-tuned to participate in dyadic\nor two-party dialogues, which can not adapt well to multi-party dialogues\n(MPD), which hinders their applications in such scenarios including\nmulti-personal meetings, discussions and daily communication. Previous\nLLM-based researches mainly focus on the multi-agent framework, while their\nbase LLMs are still pairwisely fine-tuned. In this work, we design a\nmulti-party fine-tuning framework (MuPaS) for LLMs on the multi-party dialogue\ndatasets, and prove such a straightforward framework can let the LLM align with\nthe multi-party conversation style efficiently and effectively. We also design\ntwo training strategies which can convert MuPaS into the MPD simulator.\nSubstantial experiments show that MuPaS can achieve state-of-the-art\nmulti-party response, higher accuracy of the-next-speaker prediction, higher\nhuman and automatic evaluated utterance qualities, and can even generate\nreasonably with out-of-distribution scene, topic and role descriptions. The\nMuPaS framework bridges the LLM training with more complicated multi-party\napplications, such as conversation generation, virtual rehearsal or\nmeta-universe.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.05342v4",
    "published_date": "2024-12-06 09:33:47 UTC",
    "updated_date": "2025-05-13 03:10:40 UTC"
  },
  {
    "arxiv_id": "2412.04888v1",
    "title": "VTD: Visual and Tactile Database for Driver State and Behavior Perception",
    "authors": [
      "Jie Wang",
      "Mobing Cai",
      "Zhongpan Zhu",
      "Hongjun Ding",
      "Jiwei Yi",
      "Aimin Du"
    ],
    "abstract": "In the domain of autonomous vehicles, the human-vehicle co-pilot system has\ngarnered significant research attention. To address the subjective\nuncertainties in driver state and interaction behaviors, which are pivotal to\nthe safety of Human-in-the-loop co-driving systems, we introduce a novel\nvisual-tactile perception method. Utilizing a driving simulation platform, a\ncomprehensive dataset has been developed that encompasses multi-modal data\nunder fatigue and distraction conditions. The experimental setup integrates\ndriving simulation with signal acquisition, yielding 600 minutes of fatigue\ndetection data from 15 subjects and 102 takeover experiments with 17 drivers.\nThe dataset, synchronized across modalities, serves as a robust resource for\nadvancing cross-modal driver behavior perception algorithms.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04888v1",
    "published_date": "2024-12-06 09:31:40 UTC",
    "updated_date": "2024-12-06 09:31:40 UTC"
  },
  {
    "arxiv_id": "2412.04884v1",
    "title": "AI-Driven Non-Invasive Detection and Staging of Steatosis in Fatty Liver Disease Using a Novel Cascade Model and Information Fusion Techniques",
    "authors": [
      "Niloufar Delfan",
      "Pardis Ketabi Moghadam",
      "Mohammad Khoshnevisan",
      "Mehdi Hosseini Chagahi",
      "Behzad Hatami",
      "Melika Asgharzadeh",
      "Mohammadreza Zali",
      "Behzad Moshiri",
      "Amin Momeni Moghaddam",
      "Mohammad Amin Khalafi",
      "Khosrow Dehnad"
    ],
    "abstract": "Non-alcoholic fatty liver disease (NAFLD) is one of the most widespread liver\ndisorders on a global scale, posing a significant threat of progressing to more\nsevere conditions like nonalcoholic steatohepatitis (NASH), liver fibrosis,\ncirrhosis, and hepatocellular carcinoma. Diagnosing and staging NAFLD presents\nchallenges due to its non-specific symptoms and the invasive nature of liver\nbiopsies. Our research introduces a novel artificial intelligence cascade model\nemploying ensemble learning and feature fusion techniques. We developed a\nnon-invasive, robust, and reliable diagnostic artificial intelligence tool that\nutilizes anthropometric and laboratory parameters, facilitating early detection\nand intervention in NAFLD progression. Our novel artificial intelligence\nachieved an 86% accuracy rate for the NASH steatosis staging task (non-NASH,\nsteatosis grade 1, steatosis grade 2, and steatosis grade 3) and an impressive\n96% AUC-ROC for distinguishing between NASH (steatosis grade 1, grade 2, and\ngrade3) and non-NASH cases, outperforming current state-of-the-art models. This\nnotable improvement in diagnostic performance underscores the potential\napplication of artificial intelligence in the early diagnosis and treatment of\nNAFLD, leading to better patient outcomes and a reduced healthcare burden\nassociated with advanced liver disease.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04884v1",
    "published_date": "2024-12-06 09:26:22 UTC",
    "updated_date": "2024-12-06 09:26:22 UTC"
  },
  {
    "arxiv_id": "2412.04868v1",
    "title": "NebulaFL: Effective Asynchronous Federated Learning for JointCloud Computing",
    "authors": [
      "Fei Gao",
      "Ming Hu",
      "Zhiyu Xie",
      "Peichang Shi",
      "Xiaofei Xie",
      "Guodong Yi",
      "Huaimin Wang"
    ],
    "abstract": "With advancements in AI infrastructure and Trusted Execution Environment\n(TEE) technology, Federated Learning as a Service (FLaaS) through JointCloud\nComputing (JCC) is promising to break through the resource constraints caused\nby heterogeneous edge devices in the traditional Federated Learning (FL)\nparadigm. Specifically, with the protection from TEE, data owners can achieve\nefficient model training with high-performance AI services in the cloud. By\nproviding additional FL services, cloud service providers can achieve\ncollaborative learning among data owners. However, FLaaS still faces three\nchallenges, i.e., i) low training performance caused by heterogeneous data\namong data owners, ii) high communication overhead among different clouds\n(i.e., data centers), and iii) lack of efficient resource scheduling strategies\nto balance training time and cost. To address these challenges, this paper\npresents a novel asynchronous FL approach named NebulaFL for collaborative\nmodel training among multiple clouds. To address data heterogeneity issues,\nNebulaFL adopts a version control-based asynchronous FL training scheme in each\ndata center to balance training time among data owners. To reduce communication\noverhead, NebulaFL adopts a decentralized model rotation mechanism to achieve\neffective knowledge sharing among data centers. To balance training time and\ncost, NebulaFL integrates a reward-guided strategy for data owners selection\nand resource scheduling. The experimental results demonstrate that, compared to\nthe state-of-the-art FL methods, NebulaFL can achieve up to 5.71\\% accuracy\nimprovement. In addition, NebulaFL can reduce up to 50% communication overhead\nand 61.94% costs under a target accuracy.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04868v1",
    "published_date": "2024-12-06 09:02:09 UTC",
    "updated_date": "2024-12-06 09:02:09 UTC"
  },
  {
    "arxiv_id": "2412.04858v1",
    "title": "Rethink Deep Learning with Invariance in Data Representation",
    "authors": [
      "Shuren Qi",
      "Fei Wang",
      "Tieyong Zeng",
      "Fenglei Fan"
    ],
    "abstract": "Integrating invariance into data representations is a principled design in\nintelligent systems and web applications. Representations play a fundamental\nrole, where systems and applications are both built on meaningful\nrepresentations of digital inputs (rather than the raw data). In fact, the\nproper design/learning of such representations relies on priors w.r.t. the task\nof interest. Here, the concept of symmetry from the Erlangen Program may be the\nmost fruitful prior -- informally, a symmetry of a system is a transformation\nthat leaves a certain property of the system invariant. Symmetry priors are\nubiquitous, e.g., translation as a symmetry of the object classification, where\nobject category is invariant under translation. The quest for invariance is as\nold as pattern recognition and data mining itself. Invariant design has been\nthe cornerstone of various representations in the era before deep learning,\nsuch as the SIFT. As we enter the early era of deep learning, the invariance\nprinciple is largely ignored and replaced by a data-driven paradigm, such as\nthe CNN. However, this neglect did not last long before they encountered\nbottlenecks regarding robustness, interpretability, efficiency, and so on. The\ninvariance principle has returned in the era of rethinking deep learning,\nforming a new field known as Geometric Deep Learning (GDL). In this tutorial,\nwe will give a historical perspective of the invariance in data\nrepresentations. More importantly, we will identify those research dilemmas,\npromising works, future directions, and web applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by WWW 2025 for a tutorial",
    "pdf_url": "http://arxiv.org/pdf/2412.04858v1",
    "published_date": "2024-12-06 08:52:26 UTC",
    "updated_date": "2024-12-06 08:52:26 UTC"
  },
  {
    "arxiv_id": "2412.04857v1",
    "title": "Neuro-Symbolic Data Generation for Math Reasoning",
    "authors": [
      "Zenan Li",
      "Zhi Zhou",
      "Yuan Yao",
      "Yu-Feng Li",
      "Chun Cao",
      "Fan Yang",
      "Xian Zhang",
      "Xiaoxing Ma"
    ],
    "abstract": "A critical question about Large Language Models (LLMs) is whether their\napparent deficiency in mathematical reasoning is inherent, or merely a result\nof insufficient exposure to high-quality mathematical data. To explore this, we\ndeveloped an automated method for generating high-quality, supervised\nmathematical datasets. The method carefully mutates existing math problems,\nensuring both diversity and validity of the newly generated problems. This is\nachieved by a neuro-symbolic data generation framework combining the intuitive\ninformalization strengths of LLMs, and the precise symbolic reasoning of math\nsolvers along with projected Markov chain Monte Carlo sampling in the\nhighly-irregular symbolic space. Empirical experiments demonstrate the high\nquality of data generated by the proposed method, and that the LLMs,\nspecifically LLaMA-2 and Mistral, when realigned with the generated data,\nsurpass their state-of-the-art counterparts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.04857v1",
    "published_date": "2024-12-06 08:49:49 UTC",
    "updated_date": "2024-12-06 08:49:49 UTC"
  },
  {
    "arxiv_id": "2412.04847v1",
    "title": "MTSpark: Enabling Multi-Task Learning with Spiking Neural Networks for Generalist Agents",
    "authors": [
      "Avaneesh Devkota",
      "Rachmad Vidya Wicaksana Putra",
      "Muhammad Shafique"
    ],
    "abstract": "Currently, state-of-the-art RL methods excel in single-task settings, but\nthey still struggle to generalize across multiple tasks due to catastrophic\nforgetting challenges, where previously learned tasks are forgotten as new\ntasks are introduced. This multi-task learning capability is significantly\nimportant for generalist agents, where adaptation features are highly required\n(e.g., autonomous robots). On the other hand, Spiking Neural Networks (SNNs)\nhave emerged as alternative energy-efficient neural network algorithms due to\ntheir sparse spike-based operations. Toward this, we propose MTSpark, a novel\nmethodology to enable multi-task RL using spiking networks. Specifically,\nMTSpark develops a Deep Spiking Q-Network (DSQN) with active dendrites and\ndueling structure by leveraging task-specific context signals. Specifically,\neach neuron computes task-dependent activations that dynamically modulate\ninputs, forming specialized sub-networks for each task. Moreover, this\nbioplausible network model also benefits from SNNs, enhancing energy efficiency\nand making the model suitable for hardware implementation. Experimental results\nshow that, our MTSpark effectively learns multiple tasks with higher\nperformance compared to the state-of-the-art. Specifically, MTSpark\nsuccessfully achieves high score in three Atari games (i.e., Pong: -5.4,\nBreakout: 0.6, and Enduro: 371.2), reaching human-level performance (i.e.,\nPong: -3, Breakout: 31, and Enduro: 368), where state-of-the-art struggle to\nachieve. In addition, our MTSpark also shows better accuracy in image\nclassification tasks than the state-of-the-art. These results highlight the\npotential of our MTSpark methodology to develop generalist agents that can\nlearn multiple tasks by leveraging both RL and SNN concepts.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 10 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.04847v1",
    "published_date": "2024-12-06 08:35:33 UTC",
    "updated_date": "2024-12-06 08:35:33 UTC"
  },
  {
    "arxiv_id": "2412.04846v1",
    "title": "eXpath: Explaining Knowledge Graph Link Prediction with Ontological Closed Path Rules",
    "authors": [
      "Ye Sun",
      "Lei Shi",
      "Yongxin Tong"
    ],
    "abstract": "Link prediction (LP) is crucial for Knowledge Graphs (KG) completion but\ncommonly suffers from interpretability issues. While several methods have been\nproposed to explain embedding-based LP models, they are generally limited to\nlocal explanations on KG and are deficient in providing human interpretable\nsemantics. Based on real-world observations of the characteristics of KGs from\nmultiple domains, we propose to explain LP models in KG with path-based\nexplanations. An integrated framework, namely eXpath, is introduced which\nincorporates the concept of relation path with ontological closed path rules to\nenhance both the efficiency and effectiveness of LP interpretation. Notably,\nthe eXpath explanations can be fused with other single-link explanation\napproaches to achieve a better overall solution. Extensive experiments across\nbenchmark datasets and LP models demonstrate that introducing eXpath can boost\nthe quality of resulting explanations by about 20% on two key metrics and\nreduce the required explanation time by 61.4%, in comparison to the best\nexisting method. Case studies further highlight eXpath's ability to provide\nmore semantically meaningful explanations through path-based evidence.",
    "categories": [
      "cs.AI",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 5 figures. Submitted to PVLDB volumn 18 on 20241201",
    "pdf_url": "http://arxiv.org/pdf/2412.04846v1",
    "published_date": "2024-12-06 08:33:49 UTC",
    "updated_date": "2024-12-06 08:33:49 UTC"
  },
  {
    "arxiv_id": "2412.04845v3",
    "title": "Using Machine Learning to Discover Parsimonious and Physically-Interpretable Representations of Catchment-Scale Rainfall-Runoff Dynamics",
    "authors": [
      "Yuan-Heng Wang",
      "Hoshin V. Gupta"
    ],
    "abstract": "Despite excellent real-world predictive performance of modern machine\nlearning (ML) methods, many scientists hesitate to discard traditional\nphysical-conceptual (PC) approaches due to their relative interpretability,\nwhich contributes to credibility during decision-making. In this context, a\ncurrently underexplored aspect of ML is how to develop minimally-optimal\nrepresentations that can facilitate better insight regarding system\nfunctioning. Regardless of how this is achieved, parsimonious representations\nseem to better support the advancement of scientific understanding. Our own\nview is that ML-based modeling should be based in use of computational units\nthat are fundamentally interpretable by design.\n  This paper continues our exploration of how ML can be exploited in the\nservice of scientific investigation. We use the Mass-Conserving-Perceptron\n(MCP) as the fundamental computational unit in a generic network architecture\nto explore important issues related to the use of observational data for\nconstructing models of dynamical systems. We show, in the context of lumped\ncatchment modeling, that physical interpretability and predictive performance\ncan both be achieved using a relatively parsimonious distributed-state\nmultiple-flow-path network with context-dependent gating and information\nsharing across the nodes, suggesting that MCP-based modeling can play a\nsignificant role in application of ML to geoscientific investigation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "76 Pages, 4 Tables, 14 Figures, 11 Tables and 11 Figures in\n  Supplementary Materials",
    "pdf_url": "http://arxiv.org/pdf/2412.04845v3",
    "published_date": "2024-12-06 08:30:01 UTC",
    "updated_date": "2025-02-07 20:54:48 UTC"
  },
  {
    "arxiv_id": "2412.04835v1",
    "title": "Maximizing Alignment with Minimal Feedback: Efficiently Learning Rewards for Visuomotor Robot Policy Alignment",
    "authors": [
      "Ran Tian",
      "Yilin Wu",
      "Chenfeng Xu",
      "Masayoshi Tomizuka",
      "Jitendra Malik",
      "Andrea Bajcsy"
    ],
    "abstract": "Visuomotor robot policies, increasingly pre-trained on large-scale datasets,\npromise significant advancements across robotics domains. However, aligning\nthese policies with end-user preferences remains a challenge, particularly when\nthe preferences are hard to specify. While reinforcement learning from human\nfeedback (RLHF) has become the predominant mechanism for alignment in\nnon-embodied domains like large language models, it has not seen the same\nsuccess in aligning visuomotor policies due to the prohibitive amount of human\nfeedback required to learn visual reward functions. To address this limitation,\nwe propose Representation-Aligned Preference-based Learning (RAPL), an\nobservation-only method for learning visual rewards from significantly less\nhuman preference feedback. Unlike traditional RLHF, RAPL focuses human feedback\non fine-tuning pre-trained vision encoders to align with the end-user's visual\nrepresentation and then constructs a dense visual reward via feature matching\nin this aligned representation space. We first validate RAPL through simulation\nexperiments in the X-Magical benchmark and Franka Panda robotic manipulation,\ndemonstrating that it can learn rewards aligned with human preferences, more\nefficiently uses preference data, and generalizes across robot embodiments.\nFinally, our hardware experiments align pre-trained Diffusion Policies for\nthree object manipulation tasks. We find that RAPL can fine-tune these policies\nwith 5x less real human preference data, taking the first step towards\nminimizing human feedback while maximizing visuomotor robot policy alignment.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to IJRR, this paper is an extended journal version of the\n  conference paper arXiv:2310.07932 with new results and discussion. arXiv\n  admin note: substantial text overlap with arXiv:2310.07932",
    "pdf_url": "http://arxiv.org/pdf/2412.04835v1",
    "published_date": "2024-12-06 08:04:02 UTC",
    "updated_date": "2024-12-06 08:04:02 UTC"
  },
  {
    "arxiv_id": "2412.04832v4",
    "title": "Neural Representation for Wireless Radiation Field Reconstruction: A 3D Gaussian Splatting Approach",
    "authors": [
      "Chaozheng Wen",
      "Jingwen Tong",
      "Yingdong Hu",
      "Zehong Lin",
      "Jun Zhang"
    ],
    "abstract": "Wireless channel modeling plays a pivotal role in designing, analyzing, and\noptimizing wireless communication systems. Nevertheless, developing an\neffective channel modeling approach has been a long-standing challenge. This\nissue has been escalated due to denser network deployment, larger antenna\narrays, and broader bandwidth in next-generation networks. To address this\nchallenge, we put forth WRF-GS, a novel framework for channel modeling based on\nwireless radiation field (WRF) reconstruction using 3D Gaussian splatting\n(3D-GS). WRF-GS employs 3D Gaussian primitives and neural networks to capture\nthe interactions between the environment and radio signals, enabling efficient\nWRF reconstruction and visualization of the propagation characteristics. The\nreconstructed WRF can then be used to synthesize the spatial spectrum for\ncomprehensive wireless channel characterization. While WRF-GS demonstrates\nremarkable effectiveness, it faces limitations in capturing high-frequency\nsignal variations caused by complex multipath effects. To overcome these\nlimitations, we propose WRF-GS+, an enhanced framework that integrates\nelectromagnetic wave physics into the neural network design. WRF-GS+ leverages\ndeformable 3D Gaussians to model both static and dynamic components of the WRF,\nsignificantly improving its ability to characterize signal variations. In\naddition, WRF-GS+ enhances the splatting process by simplifying the 3D-GS\nmodeling process and improving computational efficiency. Experimental results\ndemonstrate that both WRF-GS and WRF-GS+ outperform baselines for spatial\nspectrum synthesis, including ray tracing and other deep-learning approaches.\nNotably, WRF-GS+ achieves state-of-the-art performance in the received signal\nstrength indication (RSSI) and channel state information (CSI) prediction\ntasks, surpassing existing methods by more than 0.7 dB and 3.36 dB,\nrespectively.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "This is an extended journal version of our previous conference paper\n  that was accepted to the IEEE INFOCOM 2025 at arXiv:2412.04832v2. The code\n  for this version is available at https://github.com/wenchaozheng/WRF-GSplus",
    "pdf_url": "http://arxiv.org/pdf/2412.04832v4",
    "published_date": "2024-12-06 07:56:14 UTC",
    "updated_date": "2025-03-24 02:52:38 UTC"
  },
  {
    "arxiv_id": "2412.04806v1",
    "title": "Rethinking Time Series Forecasting with LLMs via Nearest Neighbor Contrastive Learning",
    "authors": [
      "Jayanie Bogahawatte",
      "Sachith Seneviratne",
      "Maneesha Perera",
      "Saman Halgamuge"
    ],
    "abstract": "Adapting Large Language Models (LLMs) that are extensively trained on\nabundant text data, and customizing the input prompt to enable time series\nforecasting has received considerable attention. While recent work has shown\ngreat potential for adapting the learned prior of LLMs, the formulation of the\nprompt to finetune LLMs remains challenging as prompt should be aligned with\ntime series data. Additionally, current approaches do not effectively leverage\nword token embeddings which embody the rich representation space learned by\nLLMs. This emphasizes the need for a robust approach to formulate the prompt\nwhich utilizes the word token embeddings while effectively representing the\ncharacteristics of the time series. To address these challenges, we propose\nNNCL-TLLM: Nearest Neighbor Contrastive Learning for Time series forecasting\nvia LLMs. First, we generate time series compatible text prototypes such that\neach text prototype represents both word token embeddings in its neighborhood\nand time series characteristics via end-to-end finetuning. Next, we draw\ninspiration from Nearest Neighbor Contrastive Learning to formulate the prompt\nwhile obtaining the top-$k$ nearest neighbor time series compatible text\nprototypes. We then fine-tune the layer normalization and positional embeddings\nof the LLM, keeping the other layers intact, reducing the trainable parameters\nand decreasing the computational cost. Our comprehensive experiments\ndemonstrate that NNCL-TLLM outperforms in few-shot forecasting while achieving\ncompetitive or superior performance over the state-of-the-art methods in\nlong-term and short-term forecasting tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04806v1",
    "published_date": "2024-12-06 06:32:47 UTC",
    "updated_date": "2024-12-06 06:32:47 UTC"
  },
  {
    "arxiv_id": "2412.04799v1",
    "title": "Estimating the treatment effect over time under general interference through deep learner integrated TMLE",
    "authors": [
      "Suhan Guo",
      "Furao Shen",
      "Ni Li"
    ],
    "abstract": "Understanding the effects of quarantine policies in populations with\nunderlying social networks is crucial for public health, yet most causal\ninference methods fail here due to their assumption of independent individuals.\nWe introduce DeepNetTMLE, a deep-learning-enhanced Targeted Maximum Likelihood\nEstimation (TMLE) method designed to estimate time-sensitive treatment effects\nin observational data. DeepNetTMLE mitigates bias from time-varying confounders\nunder general interference by incorporating a temporal module and domain\nadversarial training to build intervention-invariant representations. This\nprocess removes associations between current treatments and historical\nvariables, while the targeting step maintains the bias-variance trade-off,\nenhancing the reliability of counterfactual predictions. Using simulations of a\n``Susceptible-Infected-Recovered'' model with varied quarantine coverages, we\nshow that DeepNetTMLE achieves lower bias and more precise confidence intervals\nin counterfactual estimates, enabling optimal quarantine recommendations within\nbudget constraints, surpassing state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04799v1",
    "published_date": "2024-12-06 06:09:43 UTC",
    "updated_date": "2024-12-06 06:09:43 UTC"
  },
  {
    "arxiv_id": "2412.04792v1",
    "title": "Multi-class heart disease Detection, Classification, and Prediction using Machine Learning Models",
    "authors": [
      "Mahfuzul Haque",
      "Abu Saleh Musa Miah",
      "Debashish Gupta",
      "Md. Maruf Al Hossain Prince",
      "Tanzina Alam",
      "Nusrat Sharmin",
      "Mohammed Sowket Ali",
      "Jungpil Shin"
    ],
    "abstract": "Heart disease is a leading cause of premature death worldwide, particularly\namong middle-aged and older adults, with men experiencing a higher prevalence.\nAccording to the World Health Organization (WHO), non-communicable diseases,\nincluding heart disease, account for 25\\% (17.9 million) of global deaths, with\nover 43,204 annual fatalities in Bangladesh. However, the development of heart\ndisease detection (HDD) systems tailored to the Bangladeshi population remains\nunderexplored due to the lack of benchmark datasets and reliance on manual or\nlimited-data approaches. This study addresses these challenges by introducing\nnew, ethically sourced HDD dataset, BIG-Dataset and CD dataset which\nincorporates comprehensive data on symptoms, examination techniques, and risk\nfactors. Using advanced machine learning techniques, including Logistic\nRegression and Random Forest, we achieved a remarkable testing accuracy of up\nto 96.6\\% with Random Forest. The proposed AI-driven system integrates these\nmodels and datasets to provide real-time, accurate diagnostics and personalized\nhealthcare recommendations. By leveraging structured datasets and\nstate-of-the-art machine learning algorithms, this research offers an\ninnovative solution for scalable and effective heart disease detection, with\nthe potential to reduce mortality rates and improve clinical outcomes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04792v1",
    "published_date": "2024-12-06 05:55:41 UTC",
    "updated_date": "2024-12-06 05:55:41 UTC"
  },
  {
    "arxiv_id": "2412.04788v2",
    "title": "GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments",
    "authors": [
      "Yanyu Chen",
      "Ganhong Huang"
    ],
    "abstract": "Efficiently deploying large language models (LLMs) in real-world scenarios\nremains a critical challenge, primarily due to hardware heterogeneity,\ninference framework limitations, and workload complexities.Efficiently\ndeploying large language models (LLMs) in real-world scenarios remains a\ncritical challenge, primarily due to hardware heterogeneity, inference\nframework limitations, and workload complexities. These challenges often lead\nto inefficiencies in memory utilization, latency, and throughput, hindering the\neffective deployment of LLMs, especially for non-experts. Through extensive\nexperiments, we identify key performance bottlenecks, including sudden drops in\nmemory utilization, latency fluctuations with varying batch sizes, and\ninefficiencies in multi-GPU configurations. These insights reveal a vast\noptimization space shaped by the intricate interplay of hardware, frameworks,\nand workload parameters. This underscores the need for a systematic approach to\noptimize LLM inference, motivating the design of our framework, GUIDE. GUIDE\nleverages dynamic modeling and simulation-based optimization to address these\nissues, achieving prediction errors between 9.9% and 42.3% for key metrics such\nas batch latency, TTFT, and decode throughput. By effectively bridging the gap\nbetween theoretical performance and practical deployment, our framework\nempowers practitioners, particularly non-specialists, to make data-driven\ndecisions and unlock the full potential of LLMs in heterogeneous environments\ncheaply.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04788v2",
    "published_date": "2024-12-06 05:46:43 UTC",
    "updated_date": "2025-01-26 19:35:02 UTC"
  },
  {
    "arxiv_id": "2412.04783v2",
    "title": "KNN-MMD: Cross Domain Wireless Sensing via Local Distribution Alignment",
    "authors": [
      "Zijian Zhao",
      "Zhijie Cai",
      "Tingwei Chen",
      "Xiaoyang Li",
      "Hang Li",
      "Qimei Chen",
      "Guangxu Zhu"
    ],
    "abstract": "Wireless sensing has recently found widespread applications in diverse\nenvironments, including homes, offices, and public spaces. By analyzing\npatterns in channel state information (CSI), it is possible to infer human\nactions for tasks such as person identification, gesture recognition, and fall\ndetection. However, CSI is highly sensitive to environmental changes, where\neven minor alterations can significantly distort the CSI patterns. This\nsensitivity often leads to performance degradation or outright failure when\napplying wireless sensing models trained in one environment to another. To\naddress this challenge, Domain Alignment (DAL) has been widely adopted for\ncross-domain classification tasks, as it focuses on aligning the global\ndistributions of the source and target domains in feature space. Despite its\npopularity, DAL often neglects inter-category relationships, which can lead to\nmisalignment between categories across domains, even when global alignment is\nachieved. To overcome these limitations, we propose K-Nearest Neighbors Maximum\nMean Discrepancy (KNN-MMD), a novel few-shot method for cross-domain wireless\nsensing. Our approach begins by constructing a help set using KNN from the\ntarget domain, enabling local alignment between the source and target domains\nwithin each category using MMD. Additionally, we address a key instability\nissue commonly observed in cross-domain methods, where model performance\nfluctuates sharply between epochs. Further, most existing methods struggle to\ndetermine an optimal stopping point during training due to the absence of\nlabeled data from the target domain. Our method resolves this by excluding the\nsupport set from the target domain during training and employing it as a\nvalidation set to determine the stopping criterion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04783v2",
    "published_date": "2024-12-06 05:20:08 UTC",
    "updated_date": "2025-01-07 08:23:43 UTC"
  },
  {
    "arxiv_id": "2412.04782v2",
    "title": "A Survey of Sustainability in Large Language Models: Applications, Economics, and Challenges",
    "authors": [
      "Aditi Singh",
      "Nirmal Prakashbhai Patel",
      "Abul Ehtesham",
      "Saket Kumar",
      "Tala Talaei Khoei"
    ],
    "abstract": "Large Language Models (LLMs) have transformed numerous domains by providing\nadvanced capabilities in natural language understanding, generation, and\nreasoning. Despite their groundbreaking applications across industries such as\nresearch, healthcare, and creative media, their rapid adoption raises critical\nconcerns regarding sustainability. This survey paper comprehensively examines\nthe environmental, economic, and computational challenges associated with LLMs,\nfocusing on energy consumption, carbon emissions, and resource utilization in\ndata centers. By synthesizing insights from existing literature, this work\nexplores strategies such as resource-efficient training, sustainable deployment\npractices, and lifecycle assessments to mitigate the environmental impacts of\nLLMs. Key areas of emphasis include energy optimization, renewable energy\nintegration, and balancing performance with sustainability. The findings aim to\nguide researchers, practitioners, and policymakers in developing actionable\nstrategies for sustainable AI systems, fostering a responsible and\nenvironmentally conscious future for artificial intelligence.",
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04782v2",
    "published_date": "2024-12-06 05:20:04 UTC",
    "updated_date": "2025-01-18 15:46:42 UTC"
  },
  {
    "arxiv_id": "2412.05341v1",
    "title": "Generative Model-Based Fusion for Improved Few-Shot Semantic Segmentation of Infrared Images",
    "authors": [
      "Junno Yun",
      "Mehmet Akçakaya"
    ],
    "abstract": "Infrared (IR) imaging is commonly used in various scenarios, including\nautonomous driving, fire safety and defense applications. Thus, semantic\nsegmentation of such images is of great interest. However, this task faces\nseveral challenges, including data scarcity, differing contrast and input\nchannel number compared to natural images, and emergence of classes not\nrepresented in databases in certain scenarios, such as defense applications.\nFew-shot segmentation (FSS) provides a framework to overcome these issues by\nsegmenting query images using a few labeled support samples. However, existing\nFSS models for IR images require paired visible RGB images, which is a major\nlimitation since acquiring such paired data is difficult or impossible in some\napplications. In this work, we develop new strategies for FSS of IR images by\nusing generative modeling and fusion techniques. To this end, we propose to\nsynthesize auxiliary data to provide additional channel information to\ncomplement the limited contrast in the IR images, as well as IR data synthesis\nfor data augmentation. Here, the former helps the FSS model to better capture\nthe relationship between the support and query sets, while the latter addresses\nthe issue of data scarcity. Finally, to further improve the former aspect, we\npropose a novel fusion ensemble module for integrating the two different\nmodalities. Our methods are evaluated on different IR datasets, and improve\nupon the state-of-the-art (SOTA) FSS models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Winter Conference on Applications of Computer Vision (WACV), 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.05341v1",
    "published_date": "2024-12-06 05:14:57 UTC",
    "updated_date": "2024-12-06 05:14:57 UTC"
  },
  {
    "arxiv_id": "2412.04775v1",
    "title": "A Temporally Correlated Latent Exploration for Reinforcement Learning",
    "authors": [
      "SuMin Oh",
      "WanSoo Kim",
      "HyunJin Kim"
    ],
    "abstract": "Efficient exploration remains one of the longstanding problems of deep\nreinforcement learning. Instead of depending solely on extrinsic rewards from\nthe environments, existing methods use intrinsic rewards to enhance\nexploration. However, we demonstrate that these methods are vulnerable to Noisy\nTV and stochasticity. To tackle this problem, we propose Temporally Correlated\nLatent Exploration (TeCLE), which is a novel intrinsic reward formulation that\nemploys an action-conditioned latent space and temporal correlation. The\naction-conditioned latent space estimates the probability distribution of\nstates, thereby avoiding the assignment of excessive intrinsic rewards to\nunpredictable states and effectively addressing both problems. Whereas previous\nworks inject temporal correlation for action selection, the proposed method\ninjects it for intrinsic reward computation. We find that the injected temporal\ncorrelation determines the exploratory behaviors of agents. Various experiments\nshow that the environment where the agent performs well depends on the amount\nof temporal correlation. To the best of our knowledge, the proposed TeCLE is\nthe first approach to consider the action conditioned latent space and temporal\ncorrelation for curiosity-driven exploration. We prove that the proposed TeCLE\ncan be robust to the Noisy TV and stochasticity in benchmark environments,\nincluding Minigrid and Stochastic Atari.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04775v1",
    "published_date": "2024-12-06 04:38:43 UTC",
    "updated_date": "2024-12-06 04:38:43 UTC"
  },
  {
    "arxiv_id": "2412.05339v1",
    "title": "PyTerrier-GenRank: The PyTerrier Plugin for Reranking with Large Language Models",
    "authors": [
      "Kaustubh D. Dhole"
    ],
    "abstract": "Using LLMs as rerankers requires experimenting with various hyperparameters,\nsuch as prompt formats, model choice, and reformulation strategies. We\nintroduce PyTerrier-GenRank, a PyTerrier plugin to facilitate seamless\nreranking experiments with LLMs, supporting popular ranking strategies like\npointwise and listwise prompting. We validate our plugin through HuggingFace\nand OpenAI hosted endpoints.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.05339v1",
    "published_date": "2024-12-06 04:30:00 UTC",
    "updated_date": "2024-12-06 04:30:00 UTC"
  },
  {
    "arxiv_id": "2412.04766v2",
    "title": "DAWN-FM: Data-Aware and Noise-Informed Flow Matching for Solving Inverse Problems",
    "authors": [
      "Shadab Ahamed",
      "Eldad Haber"
    ],
    "abstract": "Inverse problems, which involve estimating parameters from incomplete or\nnoisy observations, arise in various fields such as medical imaging,\ngeophysics, and signal processing. These problems are often ill-posed,\nrequiring regularization techniques to stabilize the solution. In this work, we\nemploy Flow Matching (FM), a generative framework that integrates a\ndeterministic processes to map a simple reference distribution, such as a\nGaussian, to the target distribution. Our method DAWN-FM: Data-AWare and\nNoise-informed Flow Matching incorporates data and noise embedding, allowing\nthe model to access representations about the measured data explicitly and also\naccount for noise in the observations, making it particularly robust in\nscenarios where data is noisy or incomplete. By learning a time-dependent\nvelocity field, FM not only provides accurate solutions but also enables\nuncertainty quantification by generating multiple plausible outcomes. Unlike\npre-trained diffusion models, which may struggle in highly ill-posed settings,\nour approach is trained specifically for each inverse problem and adapts to\nvarying noise levels. We validate the effectiveness and robustness of our\nmethod through extensive numerical experiments on tasks such as image\ndeblurring and tomography.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "27 pages, 11 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.04766v2",
    "published_date": "2024-12-06 04:18:49 UTC",
    "updated_date": "2025-03-12 17:30:41 UTC"
  },
  {
    "arxiv_id": "2412.04764v1",
    "title": "Short-term Streamflow and Flood Forecasting based on Graph Convolutional Recurrent Neural Network and Residual Error Learning",
    "authors": [
      "Xiyu Pan",
      "Neda Mohammadi",
      "John E. Taylor"
    ],
    "abstract": "Accurate short-term streamflow and flood forecasting are critical for\nmitigating river flood impacts, especially given the increasing climate\nvariability. Machine learning-based streamflow forecasting relies on large\nstreamflow datasets derived from rating curves. Uncertainties in rating curve\nmodeling could introduce errors to the streamflow data and affect the\nforecasting accuracy. This study proposes a streamflow forecasting method that\naddresses these data errors, enhancing the accuracy of river flood forecasting\nand flood modeling, thereby reducing flood-related risk. A convolutional\nrecurrent neural network is used to capture spatiotemporal patterns, coupled\nwith residual error learning and forecasting. The neural network outperforms\ncommonly used forecasting models over 1-6 hours of forecasting horizons, and\nthe residual error learners can further correct the residual errors. This\nprovides a more reliable tool for river flood forecasting and climate\nadaptation in this critical 1-6 hour time window for flood risk mitigation\nefforts.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "physics.geo-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04764v1",
    "published_date": "2024-12-06 04:16:35 UTC",
    "updated_date": "2024-12-06 04:16:35 UTC"
  },
  {
    "arxiv_id": "2412.04759v2",
    "title": "REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments",
    "authors": [
      "Kaustubh Sridhar",
      "Souradeep Dutta",
      "Dinesh Jayaraman",
      "Insup Lee"
    ],
    "abstract": "Building generalist agents that can rapidly adapt to new environments is a\nkey challenge for deploying AI in the digital and real worlds. Is scaling\ncurrent agent architectures the most effective way to build generalist agents?\nWe propose a novel approach to pre-train relatively small policies on\nrelatively small datasets and adapt them to unseen environments via in-context\nlearning, without any finetuning. Our key idea is that retrieval offers a\npowerful bias for fast adaptation. Indeed, we demonstrate that even a simple\nretrieval-based 1-nearest neighbor agent offers a surprisingly strong baseline\nfor today's state-of-the-art generalist agents. From this starting point, we\nconstruct a semi-parametric agent, REGENT, that trains a transformer-based\npolicy on sequences of queries and retrieved neighbors. REGENT can generalize\nto unseen robotics and game-playing environments via retrieval augmentation and\nin-context learning, achieving this with up to 3x fewer parameters and up to an\norder-of-magnitude fewer pre-training datapoints, significantly outperforming\ntoday's state-of-the-art generalist agents. Website:\nhttps://kaustubhsridhar.github.io/regent-research",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 Oral, NeurIPS 2024 Workshops on Adaptive Foundation Models\n  (AFM) and Open World Agents (OWA), 30 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.04759v2",
    "published_date": "2024-12-06 03:54:55 UTC",
    "updated_date": "2025-02-24 16:06:51 UTC"
  },
  {
    "arxiv_id": "2412.04758v1",
    "title": "Measuring Goal-Directedness",
    "authors": [
      "Matt MacDermott",
      "James Fox",
      "Francesco Belardinelli",
      "Tom Everitt"
    ],
    "abstract": "We define maximum entropy goal-directedness (MEG), a formal measure of\ngoal-directedness in causal models and Markov decision processes, and give\nalgorithms for computing it. Measuring goal-directedness is important, as it is\na critical element of many concerns about harm from AI. It is also of\nphilosophical interest, as goal-directedness is a key aspect of agency. MEG is\nbased on an adaptation of the maximum causal entropy framework used in inverse\nreinforcement learning. It can measure goal-directedness with respect to a\nknown utility function, a hypothesis class of utility functions, or a set of\nrandom variables. We prove that MEG satisfies several desiderata and\ndemonstrate our algorithms with small-scale experiments.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.04758v1",
    "published_date": "2024-12-06 03:48:47 UTC",
    "updated_date": "2024-12-06 03:48:47 UTC"
  },
  {
    "arxiv_id": "2412.04741v1",
    "title": "Question Answering for Decisionmaking in Green Building Design: A Multimodal Data Reasoning Method Driven by Large Language Models",
    "authors": [
      "Yihui Li",
      "Xiaoyue Yan",
      "Hao Zhou",
      "Borong Lin"
    ],
    "abstract": "In recent years, the critical role of green buildings in addressing energy\nconsumption and environmental issues has become widely acknowledged. Research\nindicates that over 40% of potential energy savings can be achieved during the\nearly design stage. Therefore, decision-making in green building design (DGBD),\nwhich is based on modeling and performance simulation, is crucial for reducing\nbuilding energy costs. However, the field of green building encompasses a broad\nrange of specialized knowledge, which involves significant learning costs and\nresults in low decision-making efficiency. Many studies have already applied\nartificial intelligence (AI) methods to this field. Based on previous research,\nthis study innovatively integrates large language models with DGBD, creating\nGreenQA, a question answering framework for multimodal data reasoning.\nUtilizing Retrieval Augmented Generation, Chain of Thought, and Function Call\nmethods, GreenQA enables multimodal question answering, including weather data\nanalysis and visualization, retrieval of green building cases, and knowledge\nquery. Additionally, this study conducted a user survey using the GreenQA web\nplatform. The results showed that 96% of users believed the platform helped\nimprove design efficiency. This study not only effectively supports DGBD but\nalso provides inspiration for AI-assisted design.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at Association for Computer Aided Design in Architecture\n  (ACADIA) 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.04741v1",
    "published_date": "2024-12-06 03:02:58 UTC",
    "updated_date": "2024-12-06 03:02:58 UTC"
  },
  {
    "arxiv_id": "2412.04731v1",
    "title": "TelOps: AI-driven Operations and Maintenance for Telecommunication Networks",
    "authors": [
      "Yuqian Yang",
      "Shusen Yang",
      "Cong Zhao",
      "Zongben Xu"
    ],
    "abstract": "Telecommunication Networks (TNs) have become the most important\ninfrastructure for data communications over the last century. Operations and\nmaintenance (O&M) is extremely important to ensure the availability,\neffectiveness, and efficiency of TN communications. Different from the popular\nO&M technique for IT systems (e.g., the cloud), artificial intelligence for IT\nOperations (AIOps), O&M for TNs meets the following three fundamental\nchallenges: topological dependence of network components, highly heterogeneous\nsoftware, and restricted failure data. This article presents TelOps, the first\nAI-driven O&M framework for TNs, systematically enhanced with mechanism, data,\nand empirical knowledge. We provide a comprehensive comparison between TelOps\nand AIOps, and conduct a proof-of-concept case study on a typical O&M task\n(failure diagnosis) for a real industrial TN. As the first systematic AI-driven\nO&M framework for TNs, TelOps opens a new door to applying AI techniques to TN\nautomation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 4 figures, magazine",
    "pdf_url": "http://arxiv.org/pdf/2412.04731v1",
    "published_date": "2024-12-06 02:46:50 UTC",
    "updated_date": "2024-12-06 02:46:50 UTC"
  },
  {
    "arxiv_id": "2412.04726v2",
    "title": "BESSTIE: A Benchmark for Sentiment and Sarcasm Classification for Varieties of English",
    "authors": [
      "Dipankar Srirag",
      "Aditya Joshi",
      "Jordan Painter",
      "Diptesh Kanojia"
    ],
    "abstract": "Despite large language models (LLMs) being known to exhibit bias against\nnon-mainstream varieties, there are no known labeled datasets for sentiment\nanalysis of English. To address this gap, we introduce BESSTIE, a benchmark for\nsentiment and sarcasm classification for three varieties of English: Australian\n(en-AU), Indian (en-IN), and British (en-UK). Using web-based content from two\ndomains, namely, Google Place reviews and Reddit comments, we collect datasets\nfor these language varieties using two methods: location-based and topic-based\nfiltering. Native speakers of the language varieties manually annotate the\ndatasets with sentiment and sarcasm labels. To assess whether the dataset\naccurately represents these varieties, we conduct two validation steps: (a)\nmanual annotation of language varieties and (b) automatic language variety\nprediction. Subsequently, we fine-tune nine large language models (LLMs)\n(representing a range of encoder/decoder and mono/multilingual models) on these\ndatasets, and evaluate their performance on the two tasks. Our results reveal\nthat the models consistently perform better on inner-circle varieties (i.e.,\nen-AU and en-UK), with significant performance drops for en-IN, particularly in\nsarcasm detection. We also report challenges in cross-variety generalisation,\nhighlighting the need for language variety-specific datasets such as ours.\nBESSTIE promises to be a useful evaluative benchmark for future research in\nequitable LLMs, specifically in terms of language varieties. The BESSTIE\ndatasets, code, and models will be publicly available upon acceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2412.04726v2",
    "published_date": "2024-12-06 02:34:40 UTC",
    "updated_date": "2025-02-18 02:34:18 UTC"
  },
  {
    "arxiv_id": "2412.04718v1",
    "title": "Adaptive Optimization for Enhanced Efficiency in Large-Scale Language Model Training",
    "authors": [
      "Jiajing Chen",
      "Bingying Liu",
      "Xiaoxuan Liao",
      "Jia Gao",
      "Hongye Zheng",
      "Yue Li"
    ],
    "abstract": "With the rapid development of natural language processing technology,\nlarge-scale language models (LLM) have achieved remarkable results in a variety\nof tasks. However, how to effectively train these huge models and improve their\nperformance and computational efficiency remains an important challenge. This\npaper proposes an improved method based on adaptive optimization algorithm,\naiming to improve the training efficiency and final performance of LLM. Through\ncomparative experiments on the SQuAD and GLUE data sets, the experimental\nresults show that compared with traditional optimization algorithms (such as\nSGD, Momentum, AdaGrad, RMSProp and Adam), the adaptive optimization algorithm\nwe proposed has better accuracy and F1 score. Both have achieved significant\nimprovements, especially showed stronger training capabilities when processed\nlarge-scale texts and complex tasks. The research results verify the advantages\nof adaptive optimization algorithms in large-scale language model training and\nprovide new ideas and directions for future optimization methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04718v1",
    "published_date": "2024-12-06 02:17:30 UTC",
    "updated_date": "2024-12-06 02:17:30 UTC"
  },
  {
    "arxiv_id": "2412.04717v1",
    "title": "NoLoR: An ASR-Based Framework for Expedited Endangered Language Documentation with Neo-Aramaic as a Case Study",
    "authors": [
      "Matthew Nazari"
    ],
    "abstract": "The documentation of the Neo-Aramaic dialects before their extinction has\nbeen described as the most urgent task in all of Semitology today. The death of\nthis language will be an unfathomable loss to the descendents of the indigenous\nspeakers of Aramaic, now predominantly diasporic after forced displacement due\nto violence. This paper develops an ASR model to expedite the documentation of\nthis endangered language and generalizes the strategy in a new framework we\ncall NoLoR.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04717v1",
    "published_date": "2024-12-06 02:15:53 UTC",
    "updated_date": "2024-12-06 02:15:53 UTC"
  },
  {
    "arxiv_id": "2412.04714v1",
    "title": "PCTreeS: 3D Point Cloud Tree Species Classification Using Airborne LiDAR Images",
    "authors": [
      "Hongjin Lin",
      "Matthew Nazari",
      "Derek Zheng"
    ],
    "abstract": "Reliable large-scale data on the state of forests is crucial for monitoring\necosystem health, carbon stock, and the impact of climate change. Current\nknowledge of tree species distribution relies heavily on manual data collection\nin the field, which often takes years to complete, resulting in limited\ndatasets that cover only a small subset of the world's forests. Recent works\nshow that state-of-the-art deep learning models using Light Detection and\nRanging (LiDAR) images enable accurate and scalable classification of tree\nspecies in various ecosystems. While LiDAR images contain rich 3D information,\nmost previous works flatten the 3D images into 2D projections to use\nConvolutional Neural Networks (CNNs). This paper offers three significant\ncontributions: (1) we apply the deep learning framework for tree classification\nin tropical savannas; (2) we use Airborne LiDAR images, which have a lower\nresolution but greater scalability than Terrestrial LiDAR images used in most\nprevious works; (3) we introduce the approach of directly feeding 3D point\ncloud images into a vision transformer model (PCTreeS). Our results show that\nthe PCTreeS approach outperforms current CNN baselines with 2D projections in\nAUC (0.81), overall accuracy (0.72), and training time (~45 mins). This paper\nalso motivates further LiDAR image collection and validation for accurate\nlarge-scale automatic classification of tree species.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04714v1",
    "published_date": "2024-12-06 02:09:52 UTC",
    "updated_date": "2024-12-06 02:09:52 UTC"
  },
  {
    "arxiv_id": "2412.04707v1",
    "title": "Parametric-ControlNet: Multimodal Control in Foundation Models for Precise Engineering Design Synthesis",
    "authors": [
      "Rui Zhou",
      "Yanxia Zhang",
      "Chenyang Yuan",
      "Frank Permenter",
      "Nikos Arechiga",
      "Matt Klenk",
      "Faez Ahmed"
    ],
    "abstract": "This paper introduces a generative model designed for multimodal control over\ntext-to-image foundation generative AI models such as Stable Diffusion,\nspecifically tailored for engineering design synthesis. Our model proposes\nparametric, image, and text control modalities to enhance design precision and\ndiversity. Firstly, it handles both partial and complete parametric inputs\nusing a diffusion model that acts as a design autocomplete co-pilot, coupled\nwith a parametric encoder to process the information. Secondly, the model\nutilizes assembly graphs to systematically assemble input component images,\nwhich are then processed through a component encoder to capture essential\nvisual data. Thirdly, textual descriptions are integrated via CLIP encoding,\nensuring a comprehensive interpretation of design intent. These diverse inputs\nare synthesized through a multimodal fusion technique, creating a joint\nembedding that acts as the input to a module inspired by ControlNet. This\nintegration allows the model to apply robust multimodal control to foundation\nmodels, facilitating the generation of complex and precise engineering designs.\nThis approach broadens the capabilities of AI-driven design tools and\ndemonstrates significant advancements in precise control based on diverse data\nmodalities for enhanced design generation.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04707v1",
    "published_date": "2024-12-06 01:40:10 UTC",
    "updated_date": "2024-12-06 01:40:10 UTC"
  },
  {
    "arxiv_id": "2412.04704v1",
    "title": "On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory",
    "authors": [
      "David N. Palacio",
      "Daniel Rodriguez-Cardenas",
      "Denys Poshyvanyk",
      "Kevin Moran"
    ],
    "abstract": "Traceability is a cornerstone of modern software development, ensuring system\nreliability and facilitating software maintenance. While unsupervised\ntechniques leveraging Information Retrieval (IR) and Machine Learning (ML)\nmethods have been widely used for predicting trace links, their effectiveness\nremains underexplored. In particular, these techniques often assume\ntraceability patterns are present within textual data - a premise that may not\nhold universally. Moreover, standard evaluation metrics such as precision,\nrecall, accuracy, or F1 measure can misrepresent the model performance when\nunderlying data distributions are not properly analyzed. Given that automated\ntraceability techniques tend to struggle to establish links, we need further\ninsight into the information limits related to traceability artifacts. In this\npaper, we propose an approach, TraceXplainer, for using information theory\nmetrics to evaluate and better understand the performance (limits) of\nunsupervised traceability techniques. Specifically, we introduce\nself-information, cross-entropy, and mutual information (MI) as metrics to\nmeasure the informativeness and reliability of traceability links. Through a\ncomprehensive replication and analysis of well-studied datasets and techniques,\nwe investigate the effectiveness of unsupervised techniques that predict\ntraceability links using IR/ML. This application of TraceXplainer illustrates\nan imbalance in typical traceability datasets where the source code has on\naverage 1.48 more information bits (i.e., entropy) than the linked\ndocumentation. Additionally, we demonstrate that an average MI of 4.81 bits,\nloss of 1.75, and noise of 0.28 bits signify that there are\ninformation-theoretic limits on the effectiveness of unsupervised traceability\ntechniques. We hope these findings spur additional research on understanding\nthe limits and progress of traceability research.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04704v1",
    "published_date": "2024-12-06 01:29:29 UTC",
    "updated_date": "2024-12-06 01:29:29 UTC"
  },
  {
    "arxiv_id": "2412.04703v2",
    "title": "Transformers Struggle to Learn to Search",
    "authors": [
      "Abulhair Saparov",
      "Srushti Pawar",
      "Shreyas Pimpalgaonkar",
      "Nitish Joshi",
      "Richard Yuanzhe Pang",
      "Vishakh Padmakumar",
      "Seyed Mehran Kazemi",
      "Najoung Kim",
      "He He"
    ],
    "abstract": "Search is an ability foundational in many important tasks, and recent studies\nhave shown that large language models (LLMs) struggle to perform search\nrobustly. It is unknown whether this inability is due to a lack of data,\ninsufficient model parameters, or fundamental limitations of the transformer\narchitecture. In this work, we use the foundational graph connectivity problem\nas a testbed to generate effectively limitless high-coverage data to train\nsmall transformers and test whether they can learn to perform search. We find\nthat, when given the right training distribution, the transformer is able to\nlearn to search.\n  We analyze the algorithm that the transformer has learned through a novel\nmechanistic interpretability technique that enables us to extract the\ncomputation graph from the trained model. We find that transformers perform\nsearch at every vertex in parallel: For each vertex in the input graph,\ntransformers compute the set of vertices reachable from that vertex. Each layer\nthen progressively expands these sets, allowing the model to search over a\nnumber of vertices exponential in $n_{\\text{layers}}$.\n  However, we find that as the input graph size increases, the transformer has\ngreater difficulty in learning the task. This difficulty is not resolved even\nas the number of parameters is increased, suggesting that increasing model\nscale will not lead to robust search abilities. We also find that performing\nsearch in-context (i.e., chain-of-thought) does not resolve this inability to\nlearn to search on larger graphs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.04703v2",
    "published_date": "2024-12-06 01:29:24 UTC",
    "updated_date": "2025-03-16 11:57:25 UTC"
  },
  {
    "arxiv_id": "2412.04697v2",
    "title": "Privacy-Preserving Retrieval-Augmented Generation with Differential Privacy",
    "authors": [
      "Tatsuki Koga",
      "Ruihan Wu",
      "Kamalika Chaudhuri"
    ],
    "abstract": "With the recent remarkable advancement of large language models (LLMs), there\nhas been a growing interest in utilizing them in the domains with highly\nsensitive data that lies outside their training data. For this purpose,\nretrieval-augmented generation (RAG) is particularly effective -- it assists\nLLMs by directly providing relevant information from the external knowledge\nsources. However, without extra privacy safeguards, RAG outputs risk leaking\nsensitive information from the external data source. In this work, we explore\nRAG under differential privacy (DP), a formal guarantee of data privacy. The\nmain challenge with differentially private RAG is how to generate long accurate\nanswers within a moderate privacy budget. We address this by proposing an\nalgorithm that smartly spends privacy budget only for the tokens that require\nthe sensitive information and uses the non-private LLM for other tokens. Our\nextensive empirical evaluations reveal that our algorithm outperforms the\nnon-RAG baseline under a reasonable privacy budget of $\\epsilon\\approx 10$\nacross different models and datasets.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04697v2",
    "published_date": "2024-12-06 01:20:16 UTC",
    "updated_date": "2025-02-26 18:55:54 UTC"
  },
  {
    "arxiv_id": "2412.04692v1",
    "title": "Smoothie: Label Free Language Model Routing",
    "authors": [
      "Neel Guha",
      "Mayee F. Chen",
      "Trevor Chow",
      "Ishan S. Khare",
      "Christopher Ré"
    ],
    "abstract": "Large language models (LLMs) are increasingly used in applications where LLM\ninputs may span many different tasks. Recent work has found that the choice of\nLLM is consequential, and different LLMs may be good for different input\nsamples. Prior approaches have thus explored how engineers might select an LLM\nto use for each sample (i.e. routing). While existing routing methods mostly\nrequire training auxiliary models on human-annotated data, our work explores\nwhether it is possible to perform unsupervised routing. We propose Smoothie, a\nweak supervision-inspired routing approach that requires no labeled data. Given\na set of outputs from different LLMs, Smoothie constructs a latent variable\ngraphical model over embedding representations of observable LLM outputs and\nunknown \"true\" outputs. Using this graphical model, we estimate\nsample-dependent quality scores for each LLM, and route each sample to the LLM\nwith the highest corresponding score. We find that Smoothie's LLM\nquality-scores correlate with ground-truth model quality (correctly identifying\nthe optimal model on 9/14 tasks), and that Smoothie outperforms baselines for\nrouting by up to 10 points accuracy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 8 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.04692v1",
    "published_date": "2024-12-06 01:06:37 UTC",
    "updated_date": "2024-12-06 01:06:37 UTC"
  },
  {
    "arxiv_id": "2412.04690v1",
    "title": "LLM-Align: Utilizing Large Language Models for Entity Alignment in Knowledge Graphs",
    "authors": [
      "Xuan Chen",
      "Tong Lu",
      "Zhichun Wang"
    ],
    "abstract": "Entity Alignment (EA) seeks to identify and match corresponding entities\nacross different Knowledge Graphs (KGs), playing a crucial role in knowledge\nfusion and integration. Embedding-based entity alignment (EA) has recently\ngained considerable attention, resulting in the emergence of many innovative\napproaches. Initially, these approaches concentrated on learning entity\nembeddings based on the structural features of knowledge graphs (KGs) as\ndefined by relation triples. Subsequent methods have integrated entities' names\nand attributes as supplementary information to improve the embeddings used for\nEA. However, existing methods lack a deep semantic understanding of entity\nattributes and relations. In this paper, we propose a Large Language Model\n(LLM) based Entity Alignment method, LLM-Align, which explores the\ninstruction-following and zero-shot capabilities of Large Language Models to\ninfer alignments of entities. LLM-Align uses heuristic methods to select\nimportant attributes and relations of entities, and then feeds the selected\ntriples of entities to an LLM to infer the alignment results. To guarantee the\nquality of alignment results, we design a multi-round voting mechanism to\nmitigate the hallucination and positional bias issues that occur with LLMs.\nExperiments on three EA datasets, demonstrating that our approach achieves\nstate-of-the-art performance compared to existing EA methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04690v1",
    "published_date": "2024-12-06 01:05:37 UTC",
    "updated_date": "2024-12-06 01:05:37 UTC"
  },
  {
    "arxiv_id": "2412.04683v2",
    "title": "From Principles to Practice: A Deep Dive into AI Ethics and Regulations",
    "authors": [
      "Nan Sun",
      "Yuantian Miao",
      "Hao Jiang",
      "Ming Ding",
      "Jun Zhang"
    ],
    "abstract": "In the rapidly evolving domain of Artificial Intelligence (AI), the complex\ninteraction between innovation and regulation has become an emerging focus of\nour society. Despite tremendous advancements in AI's capabilities to excel in\nspecific tasks and contribute to diverse sectors, establishing a high degree of\ntrust in AI-generated outputs and decisions necessitates meticulous caution and\ncontinuous oversight. A broad spectrum of stakeholders, including governmental\nbodies, private sector corporations, academic institutions, and individuals,\nhave launched significant initiatives. These efforts include developing ethical\nguidelines for AI and engaging in vibrant discussions on AI ethics, both among\nAI practitioners and within the broader society. This article thoroughly\nanalyzes the ground-breaking AI regulatory framework proposed by the European\nUnion. It delves into the fundamental ethical principles of safety,\ntransparency, non-discrimination, traceability, and environmental\nsustainability for AI developments and deployments. Considering the technical\nefforts and strategies undertaken by academics and industry to uphold these\nprinciples, we explore the synergies and conflicts among the five ethical\nprinciples. Through this lens, work presents a forward-looking perspective on\nthe future of AI regulations, advocating for a harmonized approach that\nsafeguards societal values while encouraging technological advancement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to JAIR",
    "pdf_url": "http://arxiv.org/pdf/2412.04683v2",
    "published_date": "2024-12-06 00:46:20 UTC",
    "updated_date": "2025-02-06 05:44:29 UTC"
  },
  {
    "arxiv_id": "2412.04682v2",
    "title": "Two stages domain invariant representation learners solve the large co-variate shift in unsupervised domain adaptation with two dimensional data domains",
    "authors": [
      "Hisashi Oshima",
      "Tsuyoshi Ishizone",
      "Tomoyuki Higuchi"
    ],
    "abstract": "Recent developments in the unsupervised domain adaptation (UDA) enable the\nunsupervised machine learning (ML) prediction for target data, thus this will\naccelerate real world applications with ML models such as image recognition\ntasks in self-driving. Researchers have reported the UDA techniques are not\nworking well under large co-variate shift problems where e.g. supervised source\ndata consists of handwritten digits data in monotone color and unsupervised\ntarget data colored digits data from the street view. Thus there is a need for\na method to resolve co-variate shift and transfer source labelling rules under\nthis dynamics. We perform two stages domain invariant representation learning\nto bridge the gap between source and target with semantic intermediate data\n(unsupervised). The proposed method can learn domain invariant features\nsimultaneously between source and intermediate also intermediate and target.\nFinally this achieves good domain invariant representation between source and\ntarget plus task discriminability owing to source labels. This induction for\nthe gradient descent search greatly eases learning convergence in terms of\nclassification performance for target data even when large co-variate shift. We\nalso derive a theorem for measuring the gap between trained models and\nunsupervised target labelling rules, which is necessary for the free parameters\noptimization. Finally we demonstrate that proposing method is superiority to\nprevious UDA methods using 4 representative ML classification datasets\nincluding 38 UDA tasks. Our experiment will be a basis for challenging UDA\nproblems with large co-variate shift.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.04682v2",
    "published_date": "2024-12-06 00:46:12 UTC",
    "updated_date": "2025-02-17 02:12:40 UTC"
  },
  {
    "arxiv_id": "2412.04677v1",
    "title": "Zephyr quantum-assisted hierarchical Calo4pQVAE for particle-calorimeter interactions",
    "authors": [
      "Ian Lu",
      "Hao Jia",
      "Sebastian Gonzalez",
      "Deniz Sogutlu",
      "J. Quetzalcoatl Toledo-Marin",
      "Sehmimul Hoque",
      "Abhishek Abhishek",
      "Colin Gay",
      "Roger Melko",
      "Eric Paquet",
      "Geoffrey Fox",
      "Maximilian Swiatlowski",
      "Wojciech Fedorko"
    ],
    "abstract": "With the approach of the High Luminosity Large Hadron Collider (HL-LHC) era\nset to begin particle collisions by the end of this decade, it is evident that\nthe computational demands of traditional collision simulation methods are\nbecoming increasingly unsustainable. Existing approaches, which rely heavily on\nfirst-principles Monte Carlo simulations for modeling event showers in\ncalorimeters, are projected to require millions of CPU-years annually -- far\nexceeding current computational capacities. This bottleneck presents an\nexciting opportunity for advancements in computational physics by integrating\ndeep generative models with quantum simulations. We propose a quantum-assisted\nhierarchical deep generative surrogate founded on a variational autoencoder\n(VAE) in combination with an energy conditioned restricted Boltzmann machine\n(RBM) embedded in the model's latent space as a prior. By mapping the topology\nof D-Wave's Zephyr quantum annealer (QA) into the nodes and couplings of a\n4-partite RBM, we leverage quantum simulation to accelerate our shower\ngeneration times significantly. To evaluate our framework, we use Dataset 2 of\nthe CaloChallenge 2022. Through the integration of classical computation and\nquantum simulation, this hybrid framework paves way for utilizing large-scale\nquantum simulations as priors in deep generative models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-ph",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Neurips ML4PS 2024. 5 Figs, 8 pp",
    "pdf_url": "http://arxiv.org/pdf/2412.04677v1",
    "published_date": "2024-12-06 00:23:12 UTC",
    "updated_date": "2024-12-06 00:23:12 UTC"
  }
]