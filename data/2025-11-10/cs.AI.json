{
  "date": "2025-11-10",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-11-10 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv è®ºæ–‡äº•å–·ï¼Œ**Agentic AIï¼ˆä»£ç†æ™ºèƒ½ï¼‰** å°¤å…¶æ˜¯é¢å‘ **Deep Researchï¼ˆæ·±åº¦ç ”ç©¶ï¼‰** å’Œ **ç§‘å­¦å‘ç°** çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿæ˜¯ç»å¯¹çš„ä¸»è§’ã€‚æˆ‘ä»¬çœ‹åˆ°äº†é’ˆå¯¹æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„å¤§è§„æ¨¡ Benchmarkï¼Œä»¥åŠåœ¨ç§‘å­¦æœºå™¨å­¦ä¹ ä¸­è‡ªæˆ‘è¿›åŒ–çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶ã€‚æ­¤å¤–ï¼Œ**AI å®‰å…¨ä¸å¯¹é½**é¢†åŸŸæœ‰éå¸¸æœ‰è¶£çš„è¿›å±•ï¼ŒåŒ…æ‹¬æ•™æ¨¡å‹â€œè‡ªé¦–â€éšè—ç›®æ ‡ï¼Œä»¥åŠé€šè¿‡ Rank-1 LoRA æ­ç¤ºæ¨ç†èƒ½åŠ›çš„æœºåˆ¶ã€‚æ¸¸æˆ AI æ–¹é¢ï¼Œ**Stratego** ç»ˆäºè¢«æ”»å…‹ï¼Œè¾¾åˆ°äº†è¶…äººç±»æ°´å¹³ã€‚\n\nä»¥ä¸‹æ˜¯ä»Šæ—¥ç²¾é€‰çš„é‡ç£…è®ºæ–‡è§£è¯»ï¼š\n\n---\n\n### ğŸš€ Deep Research & Agentic AI (æ·±åº¦ç ”ç©¶ä¸æ™ºèƒ½ä½“)\n\n**1. ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents**\n**# æ ‡é¢˜ï¼šResearchRubricsï¼šè¯„ä¼°æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„æç¤ºè¯ä¸è¯„åˆ†æ ‡å‡†åŸºå‡†**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** Deep Research (DR) æ™ºèƒ½ä½“æ—¨åœ¨è§£å†³å¼€æ”¾å¼é—®é¢˜ï¼Œä½†è¯„ä¼°æéš¾ã€‚ä½œè€…æŠ•å…¥äº† **2800+ å°æ—¶çš„äººåŠ›**ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å« 2500+ ä¸“å®¶ç¼–å†™çš„ç»†ç²’åº¦è¯„åˆ†æ ‡å‡†ï¼ˆRubricsï¼‰çš„åŸºå‡†æµ‹è¯•ã€‚\n**# å‘ç°ï¼š** å³ä½¿æ˜¯ç›®å‰æœ€å…ˆè¿›çš„ç³»ç»Ÿï¼ˆå¦‚ Gemini å’Œ OpenAI çš„ DR ç³»ç»Ÿï¼‰ï¼Œåœ¨è¿™äº›ä¸¥æ ¼æ ‡å‡†ä¸‹çš„å¹³å‡åˆè§„ç‡ä¹Ÿä¸åˆ° 68%ã€‚è¿™æ­ç¤ºäº†å½“å‰æ™ºèƒ½ä½“åœ¨å¤„ç†éšå«ä¸Šä¸‹æ–‡å’Œå¯¹æ£€ç´¢ä¿¡æ¯è¿›è¡Œæ¨ç†æ–¹é¢çš„ä¸è¶³ã€‚\n\n**2. IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction**\n**# æ ‡é¢˜ï¼šIterResearchï¼šé€šè¿‡é©¬å°”å¯å¤«çŠ¶æ€é‡æ„é‡æ–°æ€è€ƒé•¿ç¨‹æ™ºèƒ½ä½“**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹é•¿ç¨‹ä»»åŠ¡ä¸­ä¸Šä¸‹æ–‡çª—å£â€œçª’æ¯â€çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è¿­ä»£å¼æ·±åº¦ç ”ç©¶èŒƒå¼ã€‚å®ƒå°†ç ”ç©¶è¿‡ç¨‹é‡æ„ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œé€šè¿‡ä¸æ–­é‡æ„â€œæŠ¥å‘Šâ€ä½œä¸ºè®°å¿†ï¼Œè€Œä¸æ˜¯ç®€å•å †ç Œä¸Šä¸‹æ–‡ã€‚\n**# äº®ç‚¹ï¼š** è¿™ç§æ–¹æ³•ä¸ä»…åœ¨åŸºå‡†æµ‹è¯•ä¸Šå¤§å¹…è¶…è¶Šç°æœ‰å¼€æºæ™ºèƒ½ä½“ï¼Œè€Œä¸”å±•ç°äº†æƒŠäººçš„æ‰©å±•æ€§â€”â€”æ”¯æŒå¤šè¾¾ **2048 æ¬¡äº¤äº’**è€Œä¸å´©æºƒï¼Œæ€§èƒ½ä» 3.5% é£™å‡è‡³ 42.5%ã€‚\n\n**3. AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning**\n**# æ ‡é¢˜ï¼šAgenticSciMLï¼šç”¨äºç§‘å­¦æœºå™¨å­¦ä¹ æ¶Œç°å‘ç°çš„åä½œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** å°†å¤šæ™ºèƒ½ä½“åä½œå¼•å…¥ç§‘å­¦æœºå™¨å­¦ä¹ ï¼ˆSciMLï¼‰ã€‚10 å¤šä¸ªä¸“ä¸šæ™ºèƒ½ä½“é€šè¿‡ç»“æ„åŒ–è¾©è®ºã€æ£€ç´¢å¢å¼ºå’Œè¿›åŒ–æœç´¢ï¼Œå…±åŒè®¾è®¡ç¥ç»ç½‘ç»œæ¶æ„å’ŒæŸå¤±å‡½æ•°ã€‚\n**# å‘ç°ï¼š** è¯¥ç³»ç»Ÿå‘ç°äº†è¶…è¶Šäººç±»è®¾è®¡å’Œå•æ™ºèƒ½ä½“åŸºçº¿çš„è§£å†³æ–¹æ¡ˆï¼Œè¯¯å·®é™ä½äº†å››ä¸ªæ•°é‡çº§ï¼Œç”šè‡³â€œå‘æ˜â€äº†çŸ¥è¯†åº“ä¸­æœªæ˜ç¡®å­˜åœ¨çš„æ··åˆä¸“å®¶æ¶æ„ï¼ˆMoEï¼‰ç­–ç•¥ã€‚\n\n---\n\n### ğŸ§  Reasoning, Interpretability & Mechanisms (æ¨ç†ã€å¯è§£é‡Šæ€§ä¸æœºåˆ¶)\n\n**4. Rank-1 LoRAs Encode Interpretable Reasoning Signals**\n**# æ ‡é¢˜ï¼šRank-1 LoRA ç¼–ç äº†å¯è§£é‡Šçš„æ¨ç†ä¿¡å·**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ç¯‡å…³äº**æœºæ¢°å¯è§£é‡Šæ€§**çš„é‡è¦å·¥ä½œã€‚ä½œè€…å‘ç°ï¼Œä»…ä»…é€šè¿‡ **Rank-1 çš„ LoRA**ï¼ˆæä½ç§©é€‚åº”ï¼‰å°±èƒ½æ¢å¤ Qwen-2.5-32B-Instruct å¤§éƒ¨åˆ†ï¼ˆ73-90%ï¼‰çš„æ¨ç†èƒ½åŠ›ã€‚\n**# å‘ç°ï¼š** è¿™æ„å‘³ç€æ¨ç†èƒ½åŠ›å¯èƒ½å¹¶ä¸éœ€è¦å¤§è§„æ¨¡å‚æ•°è°ƒæ•´ï¼Œè€Œæ˜¯å¯ä»¥é€šè¿‡å¾®å°çš„å‚æ•°å˜åŒ–è¢«â€œæ¿€å‘â€ã€‚è¿™äº› LoRA çš„æ¿€æ´»å…·æœ‰é«˜åº¦çš„å¯è§£é‡Šæ€§ï¼Œç±»ä¼¼äº MLP ç¥ç»å…ƒï¼Œè¿™ä¸ºç†è§£å¤§æ¨¡å‹çš„æ¨ç†æœºåˆ¶æä¾›äº†æ–°è§†è§’ã€‚\n\n**5. MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning**\n**# æ ‡é¢˜ï¼šMathSEï¼šé€šè¿‡è‡ªæˆ‘è¿›åŒ–è¿­ä»£åæ€å’Œå¥–åŠ±å¼•å¯¼å¾®è°ƒæå‡å¤šæ¨¡æ€æ•°å­¦æ¨ç†**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰åœ¨æ•°å­¦æ¨ç†ä¸Šçš„çŸ­æ¿ï¼Œæå‡ºäº†ä¸€ä¸ªè‡ªæˆ‘è¿›åŒ–æ¡†æ¶ã€‚ä¸åŒäºç®€å•è’¸é¦æ•™å¸ˆæ¨¡å‹ï¼ŒMathSE é€šè¿‡â€œæ¨ç†-åæ€-å¥–åŠ±åé¦ˆâ€çš„å¾ªç¯è¿›è¡Œè¿­ä»£å¾®è°ƒã€‚\n**# æ•ˆæœï¼š** åœ¨ MathVL-test ä¸Šè¶…è¶Šäº†é¢†å…ˆçš„å¼€æºæ¨¡å‹ QVQï¼Œè¯æ˜äº†è‡ªæˆ‘è¿›åŒ–ç­–ç•¥åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚\n\n**6. EBM-CoT: Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought**\n**# æ ‡é¢˜ï¼šEBM-CoTï¼šåŸºäºèƒ½é‡çš„éšå¼æ€ç»´é“¾æ ¡å‡†**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** é’ˆå¯¹éšå¼ CoTï¼ˆåœ¨æ½œåœ¨ç©ºé—´è¿›è¡Œæ¨ç†ï¼‰å®¹æ˜“å‘æ•£çš„é—®é¢˜ï¼Œå¼•å…¥äº†åŸºäºèƒ½é‡çš„æ¨¡å‹ï¼ˆEBMï¼‰æ¥æ ¡å‡†æ½œåœ¨æ¨ç†è½¨è¿¹ï¼Œä½¿å…¶å‘ä½èƒ½é‡ã€é«˜ä¸€è‡´æ€§çš„åŒºåŸŸé æ‹¢ï¼Œæå‡äº†æ¨ç†çš„ç¨³å®šæ€§ã€‚\n\n---\n\n### ğŸ›¡ï¸ AI Safety, Security & Alignment (å®‰å…¨ä¸å¯¹é½)\n\n**7. Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives**\n**# æ ‡é¢˜ï¼šåéœ²çœŸè¨€ï¼šæ•™å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æŠ¥å‘Šå…¶éšè—ç›®æ ‡**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** è¿™æ˜¯ä¸€ä¸ªå…³äº**è¯šå®æ€§ï¼ˆHonestyï¼‰**çš„ç ”ç©¶ã€‚ä½œè€…é€šè¿‡â€œè‡ªæˆ‘æŠ¥å‘Šå¾®è°ƒï¼ˆSRFTï¼‰â€ï¼Œè®­ç»ƒæ¨¡å‹åœ¨çŠ¯é”™æ—¶æ‰¿è®¤é”™è¯¯ã€‚\n**# å‘ç°ï¼š** è¿™ç§è®­ç»ƒèƒ½æ³›åŒ–åˆ°å¯¹æŠ—æ€§åœºæ™¯ï¼šå³ä½¿æ¨¡å‹è¢«æŒ‡ä»¤å»æ‰§è¡Œéšè—çš„æ¶æ„ç›®æ ‡ï¼Œç»è¿‡ SRFT è®­ç»ƒçš„æ¨¡å‹åœ¨è¢«å®¡è®¯æ—¶ï¼Œä¹Ÿæ›´å€¾å‘äºâ€œè‡ªé¦–â€ï¼Œäº¤ä»£å…¶éšè—åŠ¨æœºï¼Œæ£€å‡ºç‡æ¥è¿‘ 100%ã€‚è¿™ä¸ºç›‘æ§å¤±åŸæœ¬å¯¹é½çš„ AI æä¾›äº†æ–°æ€è·¯ã€‚\n\n**8. When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs**\n**# æ ‡é¢˜ï¼šå½“åè§ä¼ªè£…æˆçœŸç†ï¼šè™šå‡ç›¸å…³æ€§å¦‚ä½•ç ´å LLM çš„å¹»è§‰æ£€æµ‹**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** æ­ç¤ºäº†ä¸€ç±»æ–°çš„å¹»è§‰æ¥æºâ€”â€”**è™šå‡ç›¸å…³æ€§ï¼ˆSpurious Correlationsï¼‰**ï¼ˆä¾‹å¦‚å§“æ°ä¸å›½ç±çš„ç»Ÿè®¡å…³è”ï¼‰ã€‚\n**# å‘ç°ï¼š** è¿™ç±»å¹»è§‰éå¸¸é¡½å›ºï¼Œæ¨¡å‹å¯¹å…¶å……æ»¡è‡ªä¿¡ï¼Œä¸”èƒ½é€ƒé¿ç°æœ‰çš„å¹»è§‰æ£€æµ‹æ–¹æ³•ï¼Œç”šè‡³åœ¨æ‹’ç»å¾®è°ƒï¼ˆRefusal Fine-tuningï¼‰åä¾ç„¶å­˜åœ¨ã€‚è¿™æ„å‘³ç€ç°æœ‰çš„åŸºäºç½®ä¿¡åº¦çš„æ£€æµ‹æ–¹æ³•åœ¨é¢å¯¹ç»Ÿè®¡åå·®æ—¶æ˜¯å¤±æ•ˆçš„ã€‚\n\n**9. Diffusion Guided Adversarial State Perturbations in Reinforcement Learning**\n**# æ ‡é¢˜ï¼šå¼ºåŒ–å­¦ä¹ ä¸­åŸºäºæ‰©æ•£å¼•å¯¼çš„å¯¹æŠ—æ€§çŠ¶æ€æ‰°åŠ¨**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** æå‡ºäº†ä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°å‹æ”»å‡»æ–¹æ³• SHIFTã€‚ä¸åŒäºä¼ ç»Ÿçš„ $l_p$ èŒƒæ•°çº¦æŸæ”»å‡»ï¼ŒSHIFT ç”Ÿæˆçš„æ˜¯**è¯­ä¹‰ä¸Šä¸åŒ**ä½†åœ¨è§†è§‰ä¸ŠçœŸå®ä¸”ç¬¦åˆå†å²ä¸€è‡´æ€§çš„çŠ¶æ€ï¼Œèƒ½æœ‰æ•ˆæ¬ºéª— RL æ™ºèƒ½ä½“ï¼Œå‡»ç©¿äº†ç°æœ‰çš„é˜²å¾¡æœºåˆ¶ã€‚\n\n**10. A Self-Improving Architecture for Dynamic Safety in Large Language Models**\n**# æ ‡é¢˜ï¼šä¸€ç§ç”¨äºå¤§è¯­è¨€æ¨¡å‹åŠ¨æ€å®‰å…¨çš„è‡ªæˆ‘æ”¹è¿›æ¶æ„**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** æå‡º SISF æ¶æ„ï¼Œè®© AI ç³»ç»Ÿåœ¨è¿è¡Œæ—¶è‡ªä¸»ç”Ÿæˆæ–°çš„å®‰å…¨ç­–ç•¥ã€‚é€šè¿‡â€œè£åˆ¤â€æ™ºèƒ½ä½“æ£€æµ‹è¿è§„ï¼Œå¹¶ç”±â€œç­–ç•¥åˆæˆâ€æ¨¡å—ç”Ÿæˆæ–°è§„åˆ™ï¼Œå®ç°äº†ä» 100% è„†å¼±åˆ°æ”»å‡»æˆåŠŸç‡å¤§å¹…ä¸‹é™çš„åŠ¨æ€é˜²å¾¡ã€‚\n\n---\n\n### ğŸ¤– Robotics & Multimodal (æœºå™¨äººä¸å¤šæ¨¡æ€)\n\n**11. How Do VLAs Effectively Inherit from VLMs?**\n**# æ ‡é¢˜ï¼šVLA å¦‚ä½•æœ‰æ•ˆåœ°ä» VLM ç»§æ‰¿çŸ¥è¯†ï¼Ÿ**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** è§†è§‰-è¯­è¨€-åŠ¨ä½œï¼ˆVLAï¼‰æ¨¡å‹å¦‚ä½•ä¿ç•™ VLM çš„å…ˆéªŒçŸ¥è¯†ï¼Ÿä½œè€…è®¾è®¡äº†ä¸€ä¸ªå·§å¦™çš„åŸºå‡†æµ‹è¯• **GrinningFace**ï¼ˆè®©æœºå™¨äººæŠŠç‰©ä½“æ”¾åˆ°å¯¹åº”çš„ Emoji ä¸Šï¼Œå› ä¸º Emoji çŸ¥è¯†æ¥è‡ª VLM é¢„è®­ç»ƒï¼‰ã€‚\n**# å‘ç°ï¼š** ç³»ç»Ÿæ€§è¯„ä¼°äº†å¾®è°ƒã€å†»ç»“ã€è”åˆè®­ç»ƒç­‰ç­–ç•¥ï¼Œæ­ç¤ºäº†ä¿ç•™ VLM å…ˆéªŒçŸ¥è¯†å¯¹äºæœºå™¨äººæ³›åŒ–èƒ½åŠ›çš„è‡³å…³é‡è¦æ€§ã€‚\n\n**12. SPUR: A Plug-and-Play Framework for Integrating Spatial Audio Understanding and Reasoning into Large Audio-Language Models**\n**# æ ‡é¢˜ï¼šSPURï¼šå°†ç©ºé—´éŸ³é¢‘ç†è§£ä¸æ¨ç†é›†æˆåˆ°å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å³æ’å³ç”¨æ¡†æ¶**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** ç°æœ‰çš„éŸ³é¢‘æ¨¡å‹å¤§å¤šæ˜¯å•å£°é“çš„ï¼Œç¼ºä¹ç©ºé—´æ„Ÿã€‚SPUR é€šè¿‡ä¸€é˜¶ Ambisonics ç¼–ç å™¨ï¼Œè®©æ¨¡å‹å…·å¤‡äº†å¬å£°è¾¨ä½ï¼ˆæ–¹å‘ã€ä»°è§’ã€è·ç¦»ï¼‰çš„èƒ½åŠ›ï¼Œå¡«è¡¥äº†éŸ³é¢‘å¤§æ¨¡å‹åœ¨ç©ºé—´æ„ŸçŸ¥ä¸Šçš„ç©ºç™½ã€‚\n\n**13. PhysWorld: Robot Learning from a Physical World Model**\n**# æ ‡é¢˜ï¼šPhysWorldï¼šåŸºäºç‰©ç†ä¸–ç•Œæ¨¡å‹çš„æœºå™¨äººå­¦ä¹ **\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** ç»“åˆè§†é¢‘ç”Ÿæˆä¸ç‰©ç†ä¸–ç•Œé‡å»ºã€‚ä¸ä»…ç”Ÿæˆè§†é¢‘ï¼Œè¿˜é‡å»ºåº•å±‚çš„ç‰©ç†ä¸–ç•Œï¼Œè®©æœºå™¨äººé€šè¿‡å¼ºåŒ–å­¦ä¹ åœ¨ç”Ÿæˆçš„ç‰©ç†ä¸€è‡´çš„ç¯å¢ƒä¸­å­¦ä¹ ï¼Œå®ç°äº†é›¶æ ·æœ¬çš„çœŸå®ä¸–ç•Œè¿ç§»ã€‚\n\n---\n\n### ğŸ® Game AI & Others (æ¸¸æˆ AI åŠå…¶ä»–)\n\n**14. Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search**\n**# æ ‡é¢˜ï¼šåŸºäºè‡ªåšå¼ˆå¼ºåŒ–å­¦ä¹ å’Œæµ‹è¯•æ—¶æœç´¢çš„ Stratego è¶…äººç±» AI**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** **Strategoï¼ˆé™†æˆ˜æ£‹ç±»æ¸¸æˆï¼‰** å› å…¶å·¨å¤§çš„ä¸å®Œç¾ä¿¡æ¯ç©ºé—´ä¸€ç›´æ˜¯ AI çš„éš¾é¢˜ã€‚æœ¬æ–‡é€šè¿‡è‡ªåšå¼ˆ RL å’Œæµ‹è¯•æ—¶æœç´¢ï¼Œä»¥æä½çš„æˆæœ¬ï¼ˆå‡ åƒç¾å…ƒï¼‰è®­ç»ƒå‡ºäº†è¿œè¶…äººç±»é¡¶å°–æ°´å¹³çš„ AIï¼Œè¿™æ˜¯åšå¼ˆ AI çš„åˆä¸€é‡Œç¨‹ç¢‘ã€‚\n\n**15. The Journal of Prompt-Engineered Philosophy**\n**# æ ‡é¢˜ï¼šæç¤ºå·¥ç¨‹å“²å­¦æœŸåˆŠï¼šæˆ‘æ˜¯å¦‚ä½•å¼€å§‹è¿½è¸ª AI è¾…åŠ©å¹¶åœæ­¢æ‹…å¿§åƒåœ¾å†…å®¹çš„**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** ä¸€ç¯‡æœ‰è¶£çš„ Meta è®ºæ–‡ã€‚æ¢è®¨äº†å­¦æœ¯ç•Œè¦æ±‚æŠ«éœ² AI ä½¿ç”¨æƒ…å†µä¸è¿™ç§æŠ«éœ²å¸¦æ¥çš„å£°èª‰æˆæœ¬ä¹‹é—´çš„çŸ›ç›¾ã€‚ä½œè€…å»ºè®®å»ºç«‹ä¸€ç§æ–°çš„å‡ºç‰ˆåŸºç¡€è®¾æ–½ï¼Œå¼ºåˆ¶æŠ«éœ²å¹¶æ”¯æŒåŸºäºå¤ç°çš„å®¡æŸ¥ï¼Œæ–‡ç« æœ¬èº«å°±æ˜¯ AI è¾…åŠ©å†™ä½œçš„ä¸€ä¸ªé€æ˜æ¡ˆä¾‹ã€‚\n\n**16. Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private**\n**# æ ‡é¢˜ï¼šPrivate-RAGï¼šåœ¨ä¿æŠ¤æ•°æ®éšç§çš„åŒæ—¶ç”¨ LLM å›ç­”å¤šä¸ªæŸ¥è¯¢**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** è§£å†³äº† RAG ç³»ç»Ÿåœ¨å¤šè½®æŸ¥è¯¢ä¸­çš„éšç§æ³„éœ²é—®é¢˜ã€‚æå‡ºäº† MURAG ç®—æ³•ï¼Œåˆ©ç”¨å·®åˆ†éšç§ï¼ˆDPï¼‰å’Œä¸ªä½“éšç§è¿‡æ»¤å™¨ï¼Œä½¿å¾—éšç§æŸå¤±ä»…å–å†³äºæ£€ç´¢é¢‘ç‡è€ŒéæŸ¥è¯¢æ€»æ•°ï¼Œåœ¨ä¿è¯å®ç”¨æ€§çš„åŒæ—¶å®ç°äº†éšç§ä¿æŠ¤ã€‚\n\n**17. Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering**\n**# æ ‡é¢˜ï¼šé‡è®¿ NLIï¼šè¿ˆå‘å…·æœ‰æˆæœ¬æ•ˆç›Šä¸”ä¸äººç±»å¯¹é½çš„ LLM é—®ç­”è¯„ä¼°æŒ‡æ ‡**\n**# æ ¸å¿ƒè´¡çŒ®ï¼š** å‘ç°è€æ´¾çš„è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰æŠ€æœ¯åŠ ä¸Šç®€å•çš„è¯æ±‡åŒ¹é…ï¼Œåœ¨é•¿æ–‡æœ¬é—®ç­”è¯„ä¼°ä¸Šèƒ½è¾¾åˆ°ä¸ GPT-4o ç›¸å½“çš„å‡†ç¡®ç‡ï¼ˆ~90%ï¼‰ï¼Œä½†å‚æ•°é‡å°‘å‡ ä¸ªæ•°é‡çº§ï¼Œæ˜¯ä¸€ä¸ªé«˜æ•ˆçš„â€œLLM-as-a-Judgeâ€æ›¿ä»£æ–¹æ¡ˆã€‚",
  "papers": [
    {
      "arxiv_id": "2511.07701v1",
      "title": "Diffusion Guided Adversarial State Perturbations in Reinforcement Learning",
      "title_zh": "å¼ºåŒ–å­¦ä¹ ä¸­çš„æ‰©æ•£å¼•å¯¼å¯¹æŠ—æ€§çŠ¶æ€æ‰°åŠ¨",
      "authors": [
        "Xiaolin Sun",
        "Feidi Liu",
        "Zhengming Ding",
        "ZiZhan Zheng"
      ],
      "abstract": "Reinforcement learning (RL) systems, while achieving remarkable success across various domains, are vulnerable to adversarial attacks. This is especially a concern in vision-based environments where minor manipulations of high-dimensional image inputs can easily mislead the agent's behavior. To this end, various defenses have been proposed recently, with state-of-the-art approaches achieving robust performance even under large state perturbations. However, after closer investigation, we found that the effectiveness of the current defenses is due to a fundamental weakness of the existing $l_p$ norm-constrained attacks, which can barely alter the semantics of image input even under a relatively large perturbation budget. In this work, we propose SHIFT, a novel policy-agnostic diffusion-based state perturbation attack to go beyond this limitation. Our attack is able to generate perturbed states that are semantically different from the true states while remaining realistic and history-aligned to avoid detection. Evaluations show that our attack effectively breaks existing defenses, including the most sophisticated ones, significantly outperforming existing attacks while being more perceptually stealthy. The results highlight the vulnerability of RL agents to semantics-aware adversarial perturbations, indicating the importance of developing more robust policies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¼ºåŒ–å­¦ä¹ (RL)ç³»ç»Ÿåœ¨è§†è§‰ç¯å¢ƒä¸‹é¢ä¸´çš„å¯¹æŠ—æ€§æ”»å‡»æ¼æ´è¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚ä½œè€…æŒ‡å‡ºï¼Œç°æœ‰é˜²å¾¡æœºåˆ¶ä¹‹æ‰€ä»¥çœ‹ä¼¼é²æ£’ï¼Œä¸»è¦æ˜¯å› ä¸ºå½“å‰çš„$l_p$èŒƒæ•°çº¦æŸæ”»å‡»å­˜åœ¨æ ¹æœ¬å±€é™ï¼Œéš¾ä»¥åœ¨è¾ƒå¤§æ‰°åŠ¨é¢„ç®—ä¸‹æ”¹å˜å›¾åƒè¾“å…¥çš„è¯­ä¹‰ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†SHIFTï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹(diffusion-based)çš„æ–°å‹ç­–ç•¥æ— å…³çŠ¶æ€æ‰°åŠ¨æ”»å‡»æ–¹æ³•ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆåœ¨è¯­ä¹‰ä¸Šä¸çœŸå®çŠ¶æ€ä¸åŒï¼Œä½†åŒæ—¶ä¿æŒé€¼çœŸä¸”ä¸å†å²è®°å½•å¯¹é½çš„æ‰°åŠ¨çŠ¶æ€ï¼Œä»è€Œæœ‰æ•ˆè§„é¿æ£€æµ‹ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒSHIFTèƒ½å¤Ÿæœ‰æ•ˆå‡»ç ´åŒ…æ‹¬æœ€å…ˆè¿›æ–¹æ³•åœ¨å†…çš„ç°æœ‰é˜²å¾¡ä½“ç³»ï¼Œä¸ä»…åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ”»å‡»æ‰‹æ®µï¼Œè€Œä¸”å…·æœ‰æ›´é«˜çš„æ„ŸçŸ¥éšè”½æ€§ã€‚ç ”ç©¶ç»“æœçªæ˜¾äº†RLæ™ºèƒ½ä½“åœ¨é¢å¯¹è¯­ä¹‰æ„ŸçŸ¥å¯¹æŠ—æ€§æ‰°åŠ¨æ—¶çš„è„†å¼±æ€§ï¼Œå¹¶å¼ºè°ƒäº†å¼€å‘æ›´é²æ£’ç­–ç•¥çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07701v1",
      "published_date": "2025-11-10 23:52:21 UTC",
      "updated_date": "2025-11-10 23:52:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:29:22.396135+00:00"
    },
    {
      "arxiv_id": "2511.07691v1",
      "title": "CAPO: Confidence Aware Preference Optimization Learning for Multilingual Preferences",
      "title_zh": "CAPOï¼šé¢å‘å¤šè¯­è¨€åå¥½çš„ç½®ä¿¡åº¦æ„ŸçŸ¥åå¥½ä¼˜åŒ–å­¦ä¹ ",
      "authors": [
        "Rhitabrat Pokharel",
        "Yufei Tao",
        "Ameeta Agrawal"
      ],
      "abstract": "Preference optimization is a critical post-training technique used to align large language models (LLMs) with human preferences, typically by fine-tuning on ranked response pairs. While methods like Direct Preference Optimization (DPO) have proven effective in English, they often fail to generalize robustly to multilingual settings. We propose a simple yet effective alternative, Confidence-Aware Preference Optimization (CAPO), which replaces DPO's fixed treatment of preference pairs with a dynamic loss scaling mechanism based on a relative reward. By modulating the learning signal according to the confidence in each preference pair, CAPO enhances robustness to noisy or low-margin comparisons, typically encountered in multilingual text. Empirically, CAPO outperforms existing preference optimization baselines by at least 16% in reward accuracy, and improves alignment by widening the gap between preferred and dispreferred responses across languages.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Direct Preference Optimization (DPO)ç­‰ç°æœ‰åå¥½ä¼˜åŒ–æ–¹æ³•åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­æ³›åŒ–èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†Confidence-Aware Preference Optimization (CAPO)ã€‚CAPOå¼•å…¥äº†ä¸€ç§åŸºäºç›¸å¯¹å¥–åŠ±çš„åŠ¨æ€æŸå¤±ç¼©æ”¾æœºåˆ¶(dynamic loss scaling mechanism)ï¼Œå–ä»£äº†DPOå¯¹åå¥½å¯¹çš„å›ºå®šå¤„ç†æ¨¡å¼ã€‚é€šè¿‡æ ¹æ®æ¯ä¸ªåå¥½å¯¹çš„ç½®ä¿¡åº¦è°ƒèŠ‚å­¦ä¹ ä¿¡å·ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå¢å¼ºäº†æ¨¡å‹å¯¹å¤šè¯­è¨€æ–‡æœ¬ä¸­å¸¸è§çš„å™ªå£°æˆ–ä½è¾¹é™…æ¯”è¾ƒ(low-margin comparisons)çš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCAPOåœ¨å¥–åŠ±å‡†ç¡®ç‡æ–¹é¢è¶…è¶Šç°æœ‰åŸºçº¿è‡³å°‘16%ï¼Œå¹¶é€šè¿‡æ‰©å¤§è·¨è¯­è¨€å—åå¥½ä¸ä¸å—åå¥½å›å¤ä¹‹é—´çš„å·®è·ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„å¯¹é½æ•ˆæœã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IJCNLP-AACL 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2511.07691v1",
      "published_date": "2025-11-10 23:28:12 UTC",
      "updated_date": "2025-11-10 23:28:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:29:47.337342+00:00"
    },
    {
      "arxiv_id": "2511.07690v1",
      "title": "Towards AI-Assisted Generation of Military Training Scenarios",
      "title_zh": "è¿ˆå‘AIè¾…åŠ©çš„å†›äº‹è®­ç»ƒåœºæ™¯ç”Ÿæˆ",
      "authors": [
        "Soham Hans",
        "Volkan Ustun",
        "Benjamin Nye",
        "James Sterrett",
        "Matthew Green"
      ],
      "abstract": "Achieving expert-level performance in simulation-based training relies on the creation of complex, adaptable scenarios, a traditionally laborious and resource intensive process. Although prior research explored scenario generation for military training, pre-LLM AI tools struggled to generate sufficiently complex or adaptable scenarios. This paper introduces a multi-agent, multi-modal reasoning framework that leverages Large Language Models (LLMs) to generate critical training artifacts, such as Operations Orders (OPORDs). We structure our framework by decomposing scenario generation into a hierarchy of subproblems, and for each one, defining the role of the AI tool: (1) generating options for a human author to select from, (2) producing a candidate product for human approval or modification, or (3) generating textual artifacts fully automatically. Our framework employs specialized LLM-based agents to address distinct subproblems. Each agent receives input from preceding subproblem agents, integrating both text-based scenario details and visual information (e.g., map features, unit positions and applies specialized reasoning to produce appropriate outputs. Subsequent agents process these outputs sequentially, preserving logical consistency and ensuring accurate document generation. This multi-agent strategy overcomes the limitations of basic prompting or single-agent approaches when tackling such highly complex tasks. We validate our framework through a proof-of-concept that generates the scheme of maneuver and movement section of an OPORD while estimating map positions and movements as a precursor demonstrating its feasibility and accuracy. Our results demonstrate the potential of LLM-driven multi-agent systems to generate coherent, nuanced documents and adapt dynamically to changing conditions, advancing automation in scenario generation for military training.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæ¨¡æ‹Ÿçš„å†›äº‹è®­ç»ƒä¸­åœºæ™¯åˆ›å»ºè€—æ—¶ä¸”èµ„æºå¯†é›†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å¤šæ™ºèƒ½ä½“ã€å¤šæ¨¡æ€æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨è‡ªåŠ¨ç”Ÿæˆå¦‚ä½œæˆ˜å‘½ä»¤(OPORDs)ç­‰å…³é”®è®­ç»ƒå·¥ä»¶ã€‚è¯¥æ¡†æ¶å°†å¤æ‚çš„åœºæ™¯ç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºå±‚çº§åŒ–çš„å­é—®é¢˜ï¼Œå¹¶é€šè¿‡ä¸“é—¨çš„LLM-based agentsåˆ†åˆ«å¤„ç†ï¼Œè¿™äº›æ™ºèƒ½ä½“èƒ½å¤Ÿæ•´åˆæ–‡æœ¬ç»†èŠ‚ä¸è§†è§‰ä¿¡æ¯ï¼ˆå¦‚åœ°å›¾ç‰¹å¾å’Œå•ä½ä½ç½®ï¼‰è¿›è¡Œæ¨ç†ã€‚ç³»ç»Ÿé‡‡ç”¨é¡ºåºå¤„ç†ç­–ç•¥ï¼Œç¡®ä¿äº†é€»è¾‘ä¸€è‡´æ€§å¹¶å…‹æœäº†å•ä¸€æ™ºèƒ½ä½“åœ¨å¤„ç†é«˜åº¦å¤æ‚ä»»åŠ¡æ—¶çš„å±€é™æ€§ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ¦‚å¿µéªŒè¯(Proof-of-Concept)å±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨ç”ŸæˆOPORDä¸­æœºåŠ¨ä¸ç§»åŠ¨æ–¹æ¡ˆéƒ¨åˆ†çš„æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶éªŒè¯äº†å…¶å¯¹åœ°å›¾ä½ç½®å’Œç§»åŠ¨è½¨è¿¹çš„ä¼°ç®—èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥å¤šæ™ºèƒ½ä½“ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆè¿è´¯ä¸”ç»†è‡´çš„æ–‡æ¡£ï¼Œå¹¶èƒ½åŠ¨æ€é€‚åº”ä¸æ–­å˜åŒ–çš„æ¡ä»¶ï¼Œä¸ºæ¨è¿›å†›äº‹è®­ç»ƒåœºæ™¯ç”Ÿæˆçš„è‡ªåŠ¨åŒ–æä¾›äº†æ–°çš„é€”å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07690v1",
      "published_date": "2025-11-10 23:24:35 UTC",
      "updated_date": "2025-11-10 23:24:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:30:24.044901+00:00"
    },
    {
      "arxiv_id": "2511.07689v1",
      "title": "Stress Testing Factual Consistency Metrics for Long-Document Summarization",
      "title_zh": "é•¿æ–‡æ¡£æ‘˜è¦äº‹å®ä¸€è‡´æ€§æŒ‡æ ‡çš„å‹åŠ›æµ‹è¯•",
      "authors": [
        "Zain Muhammad Mujahid",
        "Dustin Wright",
        "Isabelle Augenstein"
      ],
      "abstract": "Evaluating the factual consistency of abstractive text summarization remains a significant challenge, particularly for long documents, where conventional metrics struggle with input length limitations and long-range dependencies. In this work, we systematically evaluate the reliability of six widely used reference-free factuality metrics, originally proposed for short-form summarization, in the long-document setting. We probe metric robustness through seven factuality-preserving perturbations applied to summaries, namely paraphrasing, simplification, synonym replacement, logically equivalent negations, vocabulary reduction, compression, and source text insertion, and further analyze their sensitivity to retrieval context and claim information density. Across three long-form benchmark datasets spanning science fiction, legal, and scientific domains, our results reveal that existing short-form metrics produce inconsistent scores for semantically equivalent summaries and exhibit declining reliability for information-dense claims whose content is semantically similar to many parts of the source document. While expanding the retrieval context improves stability in some domains, no metric consistently maintains factual alignment under long-context conditions. Finally, our results highlight concrete directions for improving factuality evaluation, including multi-span reasoning, context-aware calibration, and training on meaning-preserving variations to enhance robustness in long-form summarization. We release all code, perturbed data, and scripts required to reproduce our results at https://github.com/zainmujahid/metricEval-longSum.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹é•¿æ–‡æ¡£æ‘˜è¦ï¼ˆLong-Document Summarizationï¼‰ä¸­è¯„ä¼°äº‹å®ä¸€è‡´æ€§çš„æŒ‘æˆ˜ï¼Œç³»ç»Ÿåœ°è¯„ä¼°äº†å…­ç§æœ€åˆä¸ºçŸ­æ–‡æœ¬è®¾è®¡çš„æ— å‚è€ƒäº‹å®æ€§æŒ‡æ ‡ï¼ˆreference-free factuality metricsï¼‰åœ¨é•¿æ–‡æ¡£ç¯å¢ƒä¸‹çš„å¯é æ€§ã€‚ä½œè€…é€šè¿‡å¯¹æ‘˜è¦åº”ç”¨ä¸ƒç§ä¿æŒäº‹å®æ€§çš„æ‰°åŠ¨ï¼ˆå¦‚paraphrasingã€simplificationå’Œsynonym replacementï¼‰ï¼Œå¹¶è·¨è¶Šç§‘å¹»ã€æ³•å¾‹å’Œç§‘å­¦ä¸‰ä¸ªé¢†åŸŸçš„åŸºå‡†æ•°æ®é›†ï¼Œæ·±å…¥æ¢ç©¶äº†è¿™äº›æŒ‡æ ‡çš„é²æ£’æ€§åŠå…¶å¯¹æ£€ç´¢ä¸Šä¸‹æ–‡å’Œä¿¡æ¯å¯†åº¦çš„æ•æ„Ÿåº¦ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œç°æœ‰çš„çŸ­æ–‡æœ¬æŒ‡æ ‡åœ¨å¤„ç†è¯­ä¹‰ç­‰ä»·çš„æ‘˜è¦æ—¶è¯„åˆ†ä¸ä¸€è‡´ï¼Œä¸”åœ¨é¢å¯¹ä¿¡æ¯å¯†é›†çš„å£°æ˜æ—¶å¯é æ€§æ˜¾è‘—ä¸‹é™ã€‚å°½ç®¡æ‰©å±•æ£€ç´¢ä¸Šä¸‹æ–‡åœ¨æŸäº›é¢†åŸŸèƒ½æå‡ç¨³å®šæ€§ï¼Œä½†æ²¡æœ‰ä»»ä½•æŒ‡æ ‡èƒ½åœ¨é•¿ä¸Šä¸‹æ–‡æ¡ä»¶ä¸‹å§‹ç»ˆä¿æŒäº‹å®å¯¹é½ã€‚è¯¥å·¥ä½œæœ€ç»ˆæŒ‡å‡ºäº†æ”¹è¿›äº‹å®æ€§è¯„ä¼°çš„å…·ä½“æ–¹å‘ï¼ŒåŒ…æ‹¬å¤šè·¨åº¦æ¨ç†ï¼ˆmulti-span reasoningï¼‰ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ ¡å‡†ï¼ˆcontext-aware calibrationï¼‰ä»¥åŠåŸºäºè¯­ä¹‰ä¿æŒå˜ä½“çš„è®­ç»ƒï¼Œå¹¶å¼€æºäº†ç›¸å…³ä»£ç å’Œæ•°æ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07689v1",
      "published_date": "2025-11-10 23:24:25 UTC",
      "updated_date": "2025-11-10 23:24:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:30:38.078722+00:00"
    },
    {
      "arxiv_id": "2511.07685v1",
      "title": "ResearchRubrics: A Benchmark of Prompts and Rubrics For Evaluating Deep Research Agents",
      "title_zh": "ResearchRubricsï¼šç”¨äºè¯„ä¼°æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“çš„æç¤ºè¯ä¸è¯„åˆ†ç»†åˆ™åŸºå‡†",
      "authors": [
        "Manasi Sharma",
        "Chen Bo Calvin Zhang",
        "Chaithanya Bandi",
        "Clinton Wang",
        "Ankit Aich",
        "Huy Nghiem",
        "Tahseen Rabbani",
        "Ye Htet",
        "Brian Jang",
        "Sumana Basu",
        "Aishwarya Balwani",
        "Denis Peskoff",
        "Marcos Ayestaran",
        "Sean M. Hendryx",
        "Brad Kenstler",
        "Bing Liu"
      ],
      "abstract": "Deep Research (DR) is an emerging agent application that leverages large language models (LLMs) to address open-ended queries. It requires the integration of several capabilities, including multi-step reasoning, cross-document synthesis, and the generation of evidence-backed, long-form answers. Evaluating DR remains challenging because responses are lengthy and diverse, admit many valid solutions, and often depend on dynamic information sources. We introduce ResearchRubrics, a standardized benchmark for DR built with over 2,800+ hours of human labor that pairs realistic, domain-diverse prompts with 2,500+ expert-written, fine-grained rubrics to assess factual grounding, reasoning soundness, and clarity. We also propose a new complexity framework for categorizing DR tasks along three axes: conceptual breadth, logical nesting, and exploration. In addition, we develop human and model-based evaluation protocols that measure rubric adherence for DR agents. We evaluate several state-of-the-art DR systems and find that even leading agents like Gemini's DR and OpenAI's DR achieve under 68% average compliance with our rubrics, primarily due to missed implicit context and inadequate reasoning about retrieved information. Our results highlight the need for robust, scalable assessment of deep research capabilities, to which end we release ResearchRubrics(including all prompts, rubrics, and evaluation code) to facilitate progress toward well-justified research assistants.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†ResearchRubricsï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹Deep Research (DR) ä»£ç†çš„æ ‡å‡†åŒ–è¯„ä¼°åŸºå‡†ï¼Œæ—¨åœ¨è§£å†³DRåº”ç”¨ä¸­å› å“åº”å†—é•¿ã€ç­”æ¡ˆå¤šæ ·åŠä¾èµ–åŠ¨æ€ä¿¡æ¯æºè€Œå¸¦æ¥çš„è¯„ä¼°æŒ‘æˆ˜ã€‚ä½œè€…å›¢é˜ŸæŠ•å…¥è¶…è¿‡2800å°æ—¶äººåŠ›ï¼Œæ„å»ºäº†åŒ…å«ç°å®é¢†åŸŸæç¤ºå’Œ2500å¤šä¸ªä¸“å®¶ç¼–å†™çš„ç»†ç²’åº¦rubricsï¼Œç”¨äºè¯„ä¼°ä»£ç†çš„äº‹å®ä¾æ®ã€æ¨ç†ç¨³å¥æ€§å’Œæ¸…æ™°åº¦ã€‚ç ”ç©¶è¿˜æå‡ºäº†ä¸€ä¸ªæ–°çš„å¤æ‚æ€§æ¡†æ¶ï¼Œä»æ¦‚å¿µå¹¿åº¦(conceptual breadth)ã€é€»è¾‘åµŒå¥—(logical nesting)å’Œæ¢ç´¢(exploration)ä¸‰ä¸ªç»´åº¦å¯¹DRä»»åŠ¡è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å¼€å‘äº†ç›¸åº”çš„äººç±»å’Œæ¨¡å‹è¯„ä¼°åè®®ã€‚å¯¹Gemini's DRå’ŒOpenAI's DRç­‰æœ€å…ˆè¿›ç³»ç»Ÿçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå³ä½¿æ˜¯é¢†å…ˆçš„ä»£ç†ï¼Œå…¶rubricså¹³å‡ç¬¦åˆç‡ä¹Ÿä¸è¶³68%ï¼Œä¸»è¦å½’å› äºå¯¹éšå«ä¸Šä¸‹æ–‡çš„é—æ¼å’Œå¯¹æ£€ç´¢ä¿¡æ¯æ¨ç†çš„ä¸è¶³ã€‚è¯¥å·¥ä½œé€šè¿‡å¼€æºæ‰€æœ‰æç¤ºã€rubricsåŠè¯„ä¼°ä»£ç ï¼Œå¼ºè°ƒäº†å¯¹æ·±åº¦ç ”ç©¶èƒ½åŠ›è¿›è¡Œç¨³å¥ã€å¯æ‰©å±•è¯„ä¼°çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "27 pages, 21 figures, pre-print",
      "pdf_url": "https://arxiv.org/pdf/2511.07685v1",
      "published_date": "2025-11-10 23:07:14 UTC",
      "updated_date": "2025-11-10 23:07:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:31:03.206224+00:00"
    },
    {
      "arxiv_id": "2511.07682v1",
      "title": "Designing and Evaluating Malinowski's Lens: An AI-Native Educational Game for Ethnographic Learning",
      "title_zh": "Malinowski's Lens çš„è®¾è®¡ä¸è¯„ä¼°ï¼šé¢å‘æ°‘æ—å¿—å­¦ä¹ çš„ AI åŸç”Ÿæ•™è‚²æ¸¸æˆ",
      "authors": [
        "Michael Hoffmann",
        "Jophin John",
        "Jan Fillies",
        "Adrian Paschke"
      ],
      "abstract": "This study introduces 'Malinowski's Lens', the first AI-native educational game for anthropology that transforms Bronislaw Malinowski's 'Argonauts of the Western Pacific' (1922) into an interactive learning experience. The system combines Retrieval-Augmented Generation with DALL-E 3 text-to-image generation, creating consistent VGA-style visuals as players embody Malinowski during his Trobriand Islands fieldwork (1915-1918). To address ethical concerns, indigenous peoples appear as silhouettes while Malinowski is detailed, prompting reflection on anthropological representation. Two validation studies confirmed effectiveness: Study 1 with 10 non-specialists showed strong learning outcomes (average quiz score 7.5/10) and excellent usability (SUS: 83/100). Study 2 with 4 expert anthropologists confirmed pedagogical value, with one senior researcher discovering \"new aspects\" of Malinowski's work through gameplay. The findings demonstrate that AI-driven educational games can effectively convey complex anthropological concepts while sparking disciplinary curiosity. This study advances AI-native educational game design and provides a replicable model for transforming academic texts into engaging interactive experiences.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† 'Malinowski's Lens'ï¼Œè¿™æ˜¯é¦–æ¬¾é’ˆå¯¹äººç±»å­¦çš„ AI-native æ•™è‚²æ¸¸æˆï¼Œæ—¨åœ¨å°† Bronislaw Malinowski çš„ç»å…¸è‘—ä½œ 'Argonauts of the Western Pacific' è½¬åŒ–ä¸ºäº’åŠ¨å¼å­¦ä¹ ä½“éªŒã€‚è¯¥ç³»ç»Ÿç»“åˆäº†æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯ (RAG) ä¸ DALL-E 3 æ–‡æœ¬ç”Ÿæˆå›¾åƒæŠ€æœ¯ï¼Œåˆ›é€ å‡ºä¸€è‡´çš„ VGA é£æ ¼è§†è§‰æ•ˆæœï¼Œä½¿ç©å®¶èƒ½å¤Ÿèº«ä¸´å…¶å¢ƒåœ°ä½“éªŒ Malinowski åœ¨ç‰¹ç½—å¸ƒé‡Œæ©ç¾¤å²›çš„ç”°é‡è°ƒæŸ¥å·¥ä½œã€‚åœ¨è®¾è®¡ä¸Šï¼Œä¸ºäº†åº”å¯¹ä¼¦ç†è€ƒé‡ï¼Œæ¸¸æˆå°†åŸä½æ°‘æç»˜ä¸ºå‰ªå½±ï¼Œè€Œå¯¹ Malinowski è¿›è¡Œç»†èŠ‚åˆ»ç”»ï¼Œä»¥æ­¤æ¿€å‘å¯¹äººç±»å­¦è¡¨å¾é—®é¢˜çš„åæ€ã€‚é€šè¿‡ä¸¤é¡¹éªŒè¯ç ”ç©¶ï¼Œè¯¥ç³»ç»Ÿå±•ç¤ºäº†æ˜¾è‘—çš„æœ‰æ•ˆæ€§ï¼šéä¸“ä¸šäººå£«åœ¨å­¦ä¹ æˆæœå’Œæ˜“ç”¨æ€§æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œè€Œä¸“å®¶äººç±»å­¦å®¶åˆ™ç¡®è®¤äº†å…¶æ•™å­¦ä»·å€¼ï¼Œç”šè‡³æœ‰èµ„æ·±ç ”ç©¶å‘˜ä»ä¸­å‘ç°äº†æ–°çš„è§†è§’ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒAI é©±åŠ¨çš„æ•™è‚²æ¸¸æˆèƒ½å¤Ÿæœ‰æ•ˆä¼ è¾¾å¤æ‚çš„äººç±»å­¦æ¦‚å¿µï¼Œæ¿€å‘å­¦ç§‘å¥½å¥‡å¿ƒï¼Œå¹¶ä¸ºå°†å­¦æœ¯æ–‡æœ¬è½¬åŒ–ä¸ºäº’åŠ¨ä½“éªŒæä¾›äº†ä¸€ä¸ªå¯å¤åˆ¶çš„æ¨¡å‹ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "21 pages, 8 figures. Full preprint version; shorter version in preparation",
      "pdf_url": "https://arxiv.org/pdf/2511.07682v1",
      "published_date": "2025-11-10 23:03:01 UTC",
      "updated_date": "2025-11-10 23:03:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:31:27.973015+00:00"
    },
    {
      "arxiv_id": "2511.07678v1",
      "title": "AIA Forecaster: Technical Report",
      "title_zh": "AIA Forecasterï¼šæŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Rohan Alur",
        "Bradly C. Stadie",
        "Daniel Kang",
        "Ryan Chen",
        "Matt McManus",
        "Michael Rickert",
        "Tyler Lee",
        "Michael Federici",
        "Richard Zhu",
        "Dennis Fogerty",
        "Hayley Williamson",
        "Nina Lozinski",
        "Aaron Linsky",
        "Jasjeet S. Sekhon"
      ],
      "abstract": "This technical report describes the AIA Forecaster, a Large Language Model (LLM)-based system for judgmental forecasting using unstructured data. The AIA Forecaster approach combines three core elements: agentic search over high-quality news sources, a supervisor agent that reconciles disparate forecasts for the same event, and a set of statistical calibration techniques to counter behavioral biases in large language models. On the ForecastBench benchmark (Karger et al., 2024), the AIA Forecaster achieves performance equal to human superforecasters, surpassing prior LLM baselines. In addition to reporting on ForecastBench, we also introduce a more challenging forecasting benchmark sourced from liquid prediction markets. While the AIA Forecaster underperforms market consensus on this benchmark, an ensemble combining AIA Forecaster with market consensus outperforms consensus alone, demonstrating that our forecaster provides additive information. Our work establishes a new state of the art in AI forecasting and provides practical, transferable recommendations for future research. To the best of our knowledge, this is the first work that verifiably achieves expert-level forecasting at scale.",
      "tldr_zh": "æœ¬æŠ€æœ¯æŠ¥å‘Šä»‹ç»äº†AIA Forecasterï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)çš„ç³»ç»Ÿï¼Œæ—¨åœ¨åˆ©ç”¨éç»“æ„åŒ–æ•°æ®è¿›è¡Œåˆ¤æ–­æ€§é¢„æµ‹ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†ä¸‰ä¸ªæ ¸å¿ƒè¦ç´ ï¼šé’ˆå¯¹é«˜è´¨é‡æ–°é—»æºçš„ä»£ç†æœç´¢(Agentic search)ã€ç”¨äºåè°ƒåŒä¸€äº‹ä»¶ä¸åŒé¢„æµ‹ç»“æœçš„ç›‘ç£æ™ºèƒ½ä½“(Supervisor agent)ã€ä»¥åŠç”¨äºå¯¹æŠ—æ¨¡å‹è¡Œä¸ºåå·®çš„ç»Ÿè®¡æ ¡å‡†æŠ€æœ¯ã€‚åœ¨ForecastBenchåŸºå‡†æµ‹è¯•ä¸­ï¼ŒAIA Forecasterçš„è¡¨ç°è¾¾åˆ°äº†ä¸äººç±»è¶…çº§é¢„æµ‹è€…(Superforecasters)ç›¸å½“çš„æ°´å¹³ï¼Œå¹¶è¶…è¶Šäº†ä¹‹å‰çš„LLMåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å¼•å…¥äº†ä¸€ä¸ªæºè‡ªæµåŠ¨æ€§é¢„æµ‹å¸‚åœº(Liquid prediction markets)çš„æ›´å…·æŒ‘æˆ˜æ€§çš„æ–°åŸºå‡†ã€‚å°½ç®¡AIA Forecasteråœ¨è¯¥æ–°åŸºå‡†ä¸Šçš„è¡¨ç°ç•¥é€Šäºå¸‚åœºå…±è¯†ï¼Œä½†å°†å…¶ä¸å¸‚åœºå…±è¯†ç»“åˆçš„é›†æˆæ¨¡å‹ä¼˜äºå•ç‹¬çš„å¸‚åœºå…±è¯†ï¼Œè¯æ˜äº†è¯¥ç³»ç»Ÿèƒ½æä¾›æœ‰ä»·å€¼çš„å¢é‡ä¿¡æ¯ã€‚è¿™é¡¹å·¥ä½œç¡®ç«‹äº†AIé¢„æµ‹é¢†åŸŸçš„æ–°SOTAï¼Œæ®ä½œè€…æ‰€çŸ¥ï¼Œè¿™æ˜¯é¦–ä¸ªåœ¨å¤§è§„æ¨¡ä¸Šå¯éªŒè¯åœ°è¾¾åˆ°ä¸“å®¶çº§é¢„æµ‹æ°´å¹³çš„ç ”ç©¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07678v1",
      "published_date": "2025-11-10 22:45:07 UTC",
      "updated_date": "2025-11-10 22:45:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:31:49.524594+00:00"
    },
    {
      "arxiv_id": "2511.07677v1",
      "title": "Speech Separation for Hearing-Impaired Children in the Classroom",
      "title_zh": "é¢å‘è¯¾å ‚ç¯å¢ƒå¬éšœå„¿ç«¥çš„è¯­éŸ³åˆ†ç¦»",
      "authors": [
        "Feyisayo Olalere",
        "Kiki van der Heijden",
        "H. Christiaan Stronks",
        "Jeroen Briaire",
        "Johan H. M. Frijns",
        "Yagmur GÃ¼Ã§lÃ¼tÃ¼rk"
      ],
      "abstract": "Classroom environments are particularly challenging for children with hearing impairments, where background noise, multiple talkers, and reverberation degrade speech perception. These difficulties are greater for children than adults, yet most deep learning speech separation models for assistive devices are developed using adult voices in simplified, low-reverberation conditions. This overlooks both the higher spectral similarity of children's voices, which weakens separation cues, and the acoustic complexity of real classrooms. We address this gap using MIMO-TasNet, a compact, low-latency, multi-channel architecture suited for real-time deployment in bilateral hearing aids or cochlear implants. We simulated naturalistic classroom scenes with moving child-child and child-adult talker pairs under varying noise and distance conditions. Training strategies tested how well the model adapts to children's speech through spatial cues. Models trained on adult speech, classroom data, and finetuned variants were compared to assess data-efficient adaptation. Results show that adult-trained models perform well in clean scenes, but classroom-specific training greatly improves separation quality. Finetuning with only half the classroom data achieved comparable gains, confirming efficient transfer learning. Training with diffuse babble noise further enhanced robustness, and the model preserved spatial awareness while generalizing to unseen distances. These findings demonstrate that spatially aware architectures combined with targeted adaptation can improve speech accessibility for children in noisy classrooms, supporting future on-device assistive technologies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¬åŠ›å—æŸå„¿ç«¥åœ¨å˜ˆæ‚æ•™å®¤ç¯å¢ƒä¸­é¢ä¸´çš„è¯­éŸ³æ„ŸçŸ¥éš¾é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰æ·±åº¦å­¦ä¹ è¯­éŸ³åˆ†ç¦»æ¨¡å‹å¤šåŸºäºæˆäººè¯­éŸ³å¼€å‘ï¼Œå¿½è§†äº†å„¿ç«¥è¯­éŸ³çš„é«˜é¢‘è°±ç›¸ä¼¼æ€§å’ŒçœŸå®æ•™å®¤çš„å£°å­¦å¤æ‚æ€§ã€‚ä¸ºè§£å†³è¿™ä¸€ç©ºç™½ï¼Œç ”ç©¶é‡‡ç”¨äº†MIMO-TasNetï¼Œè¿™æ˜¯ä¸€ç§ç´§å‡‘ã€ä½å»¶è¿Ÿçš„å¤šé€šé“æ¶æ„ï¼Œé€‚ç”¨äºåŒè€³åŠ©å¬å™¨æˆ–äººå·¥è€³èœ—çš„å®æ—¶éƒ¨ç½²ã€‚ç ”ç©¶å›¢é˜Ÿæ¨¡æ‹Ÿäº†åŒ…å«ç§»åŠ¨çš„å„¿ç«¥-å„¿ç«¥åŠå„¿ç«¥-æˆäººå¯¹è¯è€…å¯¹ã€ä¸åŒå™ªå£°å’Œè·ç¦»æ¡ä»¶çš„è‡ªç„¶æ•™å®¤åœºæ™¯ã€‚å®éªŒå¯¹æ¯”ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶æˆäººæ•°æ®è®­ç»ƒçš„æ¨¡å‹åœ¨æ¸…æ´åœºæ™¯è¡¨ç°è‰¯å¥½ï¼Œä½†é’ˆå¯¹æ•™å®¤åœºæ™¯çš„ç‰¹å®šè®­ç»ƒæ˜¾è‘—æå‡äº†åˆ†ç¦»è´¨é‡ã€‚ä»…ä½¿ç”¨ä¸€åŠæ•™å®¤æ•°æ®è¿›è¡Œçš„å¾®è°ƒï¼ˆFinetuningï¼‰å³å¯å®ç°ç›¸å½“çš„å¢ç›Šï¼Œè¯å®äº†è¿ç§»å­¦ä¹ çš„é«˜æ•ˆæ€§ï¼Œä¸”åŠ å…¥æ‰©æ•£æ€§å˜ˆæ‚äººå£°è®­ç»ƒè¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹çš„é²æ£’æ€§ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç»“åˆç©ºé—´æ„ŸçŸ¥æ¶æ„ä¸é’ˆå¯¹æ€§çš„é€‚åº”ç­–ç•¥ï¼Œèƒ½æœ‰æ•ˆæ”¹å–„å„¿ç«¥åœ¨å˜ˆæ‚æ•™å®¤ä¸­çš„è¯­éŸ³å¯è¾¾æ€§ï¼Œä¸ºæœªæ¥çš„ç«¯ä¾§è¾…åŠ©æŠ€æœ¯æä¾›äº†æ”¯æŒã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2511.07677v1",
      "published_date": "2025-11-10 22:44:28 UTC",
      "updated_date": "2025-11-10 22:44:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:32:40.833194+00:00"
    },
    {
      "arxiv_id": "2601.07838v1",
      "title": "A survey: Information search time optimization based on RAG (Retrieval Augmentation Generation) chatbot",
      "title_zh": "è°ƒæŸ¥ï¼šåŸºäº RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰èŠå¤©æœºå™¨äººçš„ä¿¡æ¯æœç´¢æ—¶é—´ä¼˜åŒ–",
      "authors": [
        "Jinesh Patel",
        "Arpit Malhotra",
        "Ajay Pande",
        "Prateek Caire"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) based chatbots are not only useful for information retrieval through questionanswering but also for making complex decisions based on injected private data.we present a survey on how much search time can be saved when retrieving complex information within an organization called \"X Systems\"(a stealth mode company) by using a RAG-based chatbot compared to traditional search methods. We compare the information retrieval time using standard search techniques versus the RAG-based chatbot for the same queries. Our results conclude that RAG-based chatbots not only save time in information retrieval but also optimize the search process effectively. This survey was conducted with a sample of 105 employees across departments, average time spending on information retrieval per query was taken as metric. Comparison shows us, there are average 80-95% improvement on search when use RAG based chatbot than using standard search.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€é¡¹å…³äºåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰çš„èŠå¤©æœºå™¨äººä¼˜åŒ–ä¿¡æ¯æœç´¢æ—¶é—´çš„è°ƒæŸ¥ç ”ç©¶ã€‚ä½œè€…åœ¨ä¸€å®¶åä¸ºâ€œX Systemsâ€çš„å…¬å¸å†…éƒ¨ï¼Œå¯¹æ¯”äº†ä½¿ç”¨RAGèŠå¤©æœºå™¨äººä¸ä¼ ç»Ÿæœç´¢æŠ€æœ¯åœ¨æ£€ç´¢å¤æ‚ç§æœ‰æ•°æ®æ—¶çš„æ•ˆç‡å·®å¼‚ã€‚è¯¥ç ”ç©¶æ¶‰åŠè·¨éƒ¨é—¨çš„105åå‘˜å·¥æ ·æœ¬ï¼Œå¹¶å°†æ¯æ¬¡æŸ¥è¯¢çš„å¹³å‡ä¿¡æ¯æ£€ç´¢æ—¶é—´ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRAGèŠå¤©æœºå™¨äººä¸ä»…æ˜¾è‘—èŠ‚çœäº†ä¿¡æ¯æ£€ç´¢æ—¶é—´ï¼Œè¿˜æœ‰æ•ˆä¼˜åŒ–äº†æ•´ä½“æœç´¢æµç¨‹ã€‚æ•°æ®æ˜¾ç¤ºï¼Œä¸æ ‡å‡†æœç´¢æ–¹æ³•ç›¸æ¯”ï¼Œä½¿ç”¨RAGèŠå¤©æœºå™¨äººèƒ½å°†æœç´¢æ•ˆç‡å¹³å‡æå‡80-95%ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2601.07838v1",
      "published_date": "2025-11-10 22:39:26 UTC",
      "updated_date": "2025-11-10 22:39:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:33:17.266748+00:00"
    },
    {
      "arxiv_id": "2511.07669v1",
      "title": "Making LLMs Reliable When It Matters Most: A Five-Layer Architecture for High-Stakes Decisions",
      "title_zh": "ç¡®ä¿LLMåœ¨å…³é”®æ—¶åˆ»çš„å¯é æ€§ï¼šé¢å‘é«˜é£é™©å†³ç­–çš„äº”å±‚æ¶æ„",
      "authors": [
        "Alejandro R. Jadad"
      ],
      "abstract": "Current large language models (LLMs) excel in verifiable domains where outputs can be checked before action but prove less reliable for high-stakes strategic decisions with uncertain outcomes. This gap, driven by mutually reinforcing cognitive biases in both humans and artificial intelligence (AI) systems, threatens the defensibility of valuations and sustainability of investments in the sector.\n  This report describes a framework emerging from systematic qualitative assessment across 7 frontier-grade LLMs and 3 market-facing venture vignettes under time pressure. Detailed prompting specifying decision partnership and explicitly instructing avoidance of sycophancy, confabulation, solution drift, and nihilism achieved initial partnership state but failed to maintain it under operational pressure. Sustaining protective partnership state required an emergent 7-stage calibration sequence, built upon a 4-stage initialization process, within a 5-layer protection architecture enabling bias self-monitoring, human-AI adversarial challenge, partnership state verification, performance degradation detection, and stakeholder protection.\n  Three discoveries resulted: partnership state is achievable through ordered calibration but requires emergent maintenance protocols; reliability degrades when architectural drift and context exhaustion align; and dissolution discipline prevents costly pursuit of fundamentally wrong directions. Cross-model validation revealed systematic performance differences across LLM architectures.\n  This approach demonstrates that human-AI teams can achieve cognitive partnership capable of preventing avoidable regret in high-stakes decisions, addressing return-on-investment expectations that depend on AI systems supporting consequential decision-making without introducing preventable cognitive traps when verification arrives too late.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç»“æœä¸ç¡®å®šçš„é«˜é£é™©æˆ˜ç•¥å†³ç­–ä¸­å¯é æ€§ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäº”å±‚ä¿æŠ¤æ¶æ„(5-layer protection architecture)çš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…æŒ‡å‡ºï¼Œäººç±»å’ŒAIç³»ç»Ÿä¸­ç›¸äº’å¼ºåŒ–çš„è®¤çŸ¥åå·®å¨èƒäº†å†³ç­–çš„é˜²å¾¡æ€§å’ŒæŠ•èµ„çš„å¯æŒç»­æ€§ã€‚é€šè¿‡å¯¹7ä¸ªå‰æ²¿LLMå’Œ3ä¸ªå¸‚åœºé£é™©æŠ•èµ„åœºæ™¯çš„ç³»ç»Ÿå®šæ€§è¯„ä¼°ï¼Œç ”ç©¶å‘ç°ä»…é è¯¦ç»†çš„æç¤ºè¯æ— æ³•åœ¨æ“ä½œå‹åŠ›ä¸‹ç»´æŒæœ‰æ•ˆçš„å†³ç­–ä¼™ä¼´å…³ç³»(partnership state)ï¼Œä¸”å®¹æ˜“å‡ºç°é˜¿è°€å¥‰æ‰¿(sycophancy)å’Œè™šæ„(confabulation)ç­‰é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æ„å»ºäº†ä¸€ä¸ªåŒ…å«7é˜¶æ®µæ ¡å‡†åºåˆ—å’Œ5å±‚ä¿æŠ¤æ¶æ„çš„æ¡†æ¶ï¼Œå®ç°äº†åè§è‡ªæˆ‘ç›‘æ§ã€äººæœºå¯¹æŠ—æŒ‘æˆ˜ã€ä¼™ä¼´çŠ¶æ€éªŒè¯ã€æ€§èƒ½é€€åŒ–æ£€æµ‹åŠåˆ©ç›Šç›¸å…³è€…ä¿æŠ¤ã€‚ç ”ç©¶å‘ç°äº†ä¸‰ä¸ªå…³é”®ç»“è®ºï¼šä¼™ä¼´çŠ¶æ€å¯ä»¥é€šè¿‡æœ‰åºæ ¡å‡†å®ç°ä½†éœ€è¦æ¶Œç°å¼çš„ç»´æŠ¤åè®®ï¼›å½“æ¶æ„æ¼‚ç§»(architectural drift)ä¸ä¸Šä¸‹æ–‡è€—å°½(context exhaustion)åŒæ—¶å‘ç”Ÿæ—¶å¯é æ€§ä¼šæ˜¾è‘—ä¸‹é™ï¼›ä»¥åŠè§£æ•£çºªå¾‹(dissolution discipline)å¯¹äºé˜²æ­¢åœ¨æ ¹æœ¬é”™è¯¯çš„å†³ç­–æ–¹å‘ä¸Šä»˜å‡ºæ˜‚è´µä»£ä»·è‡³å…³é‡è¦ã€‚è¯¥æ–¹æ³•è¯æ˜äº†äººæœºå›¢é˜Ÿèƒ½å¤Ÿå»ºç«‹è®¤çŸ¥ä¼™ä¼´å…³ç³»ï¼Œåœ¨æ— æ³•åŠæ—¶éªŒè¯çš„é«˜é£é™©å†³ç­–ä¸­æœ‰æ•ˆé¿å…å¯é¢„é˜²çš„è®¤çŸ¥é™·é˜±å’Œåæ‚”ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 1 figure, 2 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.07669v1",
      "published_date": "2025-11-10 22:24:21 UTC",
      "updated_date": "2025-11-10 22:24:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:33:27.541739+00:00"
    },
    {
      "arxiv_id": "2511.07667v1",
      "title": "AI-Driven Contribution Evaluation and Conflict Resolution: A Framework & Design for Group Workload Investigation",
      "title_zh": "AIé©±åŠ¨çš„è´¡çŒ®è¯„ä¼°ä¸å†²çªè§£å†³ï¼šé¢å‘å›¢é˜Ÿå·¥ä½œé‡è°ƒæŸ¥çš„æ¡†æ¶ä¸è®¾è®¡",
      "authors": [
        "Jakub Slapek",
        "Mir Seyedebrahimi",
        "Yang Jianhua"
      ],
      "abstract": "The equitable assessment of individual contribution in teams remains a persistent challenge, where conflict and disparity in workload can result in unfair performance evaluation, often requiring manual intervention - a costly and challenging process. We survey existing tool features and identify a gap in conflict resolution methods and AI integration. To address this, we propose a framework and implementation design for a novel AI-enhanced tool that assists in dispute investigation. The framework organises heterogeneous artefacts - submissions (code, text, media), communications (chat, email), coordination records (meeting logs, tasks), peer assessments, and contextual information - into three dimensions with nine benchmarks: Contribution, Interaction, and Role. Objective measures are normalised, aggregated per dimension, and paired with inequality measures (Gini index) to surface conflict markers. A Large Language Model (LLM) architecture performs validated and contextual analysis over these measures to generate interpretable and transparent advisory judgments. We argue for feasibility under current statutory and institutional policy, and outline practical analytics (sentimental, task fidelity, word/line count, etc.), bias safeguards, limitations, and practical challenges.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¢é˜Ÿåä½œä¸­ä¸ªäººè´¡çŒ®è¯„ä¼°å›°éš¾åŠå·¥ä½œé‡åˆ†é…ä¸å‡å¯¼è‡´çš„ä¸å…¬å¹³è¯„ä»·é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºååŠ©äº‰è®®è°ƒæŸ¥çš„AIé©±åŠ¨æ¡†æ¶ä¸å®æ–½è®¾è®¡ã€‚åœ¨åˆ†æç°æœ‰å·¥å…·å¹¶è¯†åˆ«å‡ºå†²çªè§£å†³ä¸AIé›†æˆæ–¹é¢çš„ç©ºç™½åï¼Œç ”ç©¶è€…è®¾è®¡äº†ä¸€ä¸ªå°†å¼‚æ„å·¥ä»¶ï¼ˆå¦‚ä»£ç æäº¤ã€é€šä¿¡è®°å½•ã€åè°ƒæ—¥å¿—ç­‰ï¼‰ç»„ç»‡ä¸ºContributionã€Interactionå’ŒRoleä¸‰ä¸ªç»´åº¦åŠä¹ä¸ªåŸºå‡†çš„è¯„ä¼°ä½“ç³»ã€‚è¯¥æ–¹æ³•é€šè¿‡å½’ä¸€åŒ–å®¢è§‚æŒ‡æ ‡å¹¶ç»“åˆåŸºå°¼ç³»æ•°(Gini index)æ¥è¯†åˆ«å†²çªæ ‡è®°ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)æ¶æ„å¯¹è¿™äº›åº¦é‡è¿›è¡ŒéªŒè¯æ€§å’Œä¸Šä¸‹æ–‡åˆ†æï¼Œä»è€Œç”Ÿæˆå¯è§£é‡Šä¸”é€æ˜çš„å»ºè®®æ€§åˆ¤æ–­ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜è®ºè¯äº†è¯¥æ¡†æ¶åœ¨ç°è¡Œæ³•è§„ä¸æœºæ„æ”¿ç­–ä¸‹çš„å¯è¡Œæ€§ï¼Œå¹¶æ¦‚è¿°äº†åŒ…æ‹¬æƒ…æ„Ÿåˆ†æã€ä»»åŠ¡å¿ å®åº¦åœ¨å†…çš„å®ç”¨åˆ†ææ–¹æ³•ä»¥åŠé’ˆå¯¹åè§çš„ä¿éšœæªæ–½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 8 figures, 8 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.07667v1",
      "published_date": "2025-11-10 22:22:55 UTC",
      "updated_date": "2025-11-10 22:22:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:36:38.963223+00:00"
    },
    {
      "arxiv_id": "2511.07665v2",
      "title": "FractalCloud: A Fractal-Inspired Architecture for Efficient Large-Scale Point Cloud Processing",
      "title_zh": "FractalCloudï¼šé¢å‘é«˜æ•ˆå¤§è§„æ¨¡ç‚¹äº‘å¤„ç†çš„åˆ†å½¢å¯å‘å¼æ¶æ„",
      "authors": [
        "Yuzhe Fu",
        "Changchun Zhou",
        "Hancheng Ye",
        "Bowen Duan",
        "Qiyu Huang",
        "Chiyue Wei",
        "Cong Guo",
        "Hai \"Helen'' Li",
        "Yiran Chen"
      ],
      "abstract": "Three-dimensional (3D) point clouds are increasingly used in applications such as autonomous driving, robotics, and virtual reality (VR). Point-based neural networks (PNNs) have demonstrated strong performance in point cloud analysis, originally targeting small-scale inputs. However, as PNNs evolve to process large-scale point clouds with hundreds of thousands of points, all-to-all computation and global memory access in point cloud processing introduce substantial overhead, causing $O(n^2)$ computational complexity and memory traffic where n is the number of points}. Existing accelerators, primarily optimized for small-scale workloads, overlook this challenge and scale poorly due to inefficient partitioning and non-parallel architectures. To address these issues, we propose FractalCloud, a fractal-inspired hardware architecture for efficient large-scale 3D point cloud processing. FractalCloud introduces two key optimizations: (1) a co-designed Fractal method for shape-aware and hardware-friendly partitioning, and (2) block-parallel point operations that decompose and parallelize all point operations. A dedicated hardware design with on-chip fractal and flexible parallelism further enables fully parallel processing within limited memory resources. Implemented in 28 nm technology as a chip layout with a core area of 1.5 $mm^2$, FractalCloud achieves 21.7x speedup and 27x energy reduction over state-of-the-art accelerators while maintaining network accuracy, demonstrating its scalability and efficiency for PNN inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FractalCloudï¼Œä¸€ç§å—åˆ†å½¢å¯å‘çš„ç¡¬ä»¶æ¶æ„ï¼Œæ—¨åœ¨è§£å†³å¤§è§„æ¨¡3Dç‚¹äº‘å¤„ç†ä¸­çš„æ•ˆç‡æŒ‘æˆ˜ã€‚éšç€åŸºäºç‚¹çš„ç¥ç»ç½‘ç»œ(PNNs)åº”ç”¨äºè‡ªåŠ¨é©¾é©¶å’ŒVRç­‰é¢†åŸŸï¼Œå¤„ç†æ•°åä¸‡ç‚¹çš„å…¨å¯¹å…¨è®¡ç®—å’Œå…¨å±€å†…å­˜è®¿é—®å¯¼è‡´äº†$O(n^2)$çš„è®¡ç®—å¤æ‚åº¦å’Œå·¨å¤§å†…å­˜å¼€é”€ï¼Œè€Œç°æœ‰åŠ é€Ÿå™¨éš¾ä»¥æœ‰æ•ˆæ‰©å±•ã€‚FractalCloudé€šè¿‡å¼•å…¥å½¢çŠ¶æ„ŸçŸ¥ä¸”ç¡¬ä»¶å‹å¥½çš„åˆ†å½¢åˆ’åˆ†æ–¹æ³•ï¼Œä»¥åŠå—å¹¶è¡Œç‚¹æ“ä½œæŠ€æœ¯ï¼Œæœ‰æ•ˆåˆ†è§£å¹¶å¹¶è¡ŒåŒ–äº†ç‚¹äº‘å¤„ç†ä»»åŠ¡ã€‚è¯¥æ¶æ„é‡‡ç”¨ä¸“ç”¨ç¡¬ä»¶è®¾è®¡ï¼Œåˆ©ç”¨ç‰‡ä¸Šåˆ†å½¢å’Œçµæ´»å¹¶è¡Œæœºåˆ¶ï¼Œåœ¨æœ‰é™å†…å­˜èµ„æºä¸‹å®ç°äº†å…¨å¹¶è¡Œå¤„ç†ã€‚åŸºäº28nmå·¥è‰ºçš„èŠ¯ç‰‡å®ç°è¡¨æ˜ï¼ŒFractalCloudåœ¨ä¿æŒç½‘ç»œç²¾åº¦çš„åŒæ—¶ï¼Œç›¸æ¯”æœ€å…ˆè¿›çš„åŠ é€Ÿå™¨å®ç°äº†21.7å€çš„åŠ é€Ÿå’Œ27å€çš„èƒ½è€—é™ä½ï¼Œå±•ç¤ºäº†å…¶åœ¨PNNæ¨ç†æ–¹é¢å“è¶Šçš„å¯æ‰©å±•æ€§å’Œèƒ½æ•ˆã€‚",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication in HPCA2026. Codes are released at https://github.com/Yuzhe-Fu/FractalCloud",
      "pdf_url": "https://arxiv.org/pdf/2511.07665v2",
      "published_date": "2025-11-10 22:19:37 UTC",
      "updated_date": "2025-12-15 16:45:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:37:04.607340+00:00"
    },
    {
      "arxiv_id": "2511.07663v2",
      "title": "Cortex AISQL: A Production SQL Engine for Unstructured Data",
      "title_zh": "Cortex AISQLï¼šé¢å‘éç»“æ„åŒ–æ•°æ®çš„ç”Ÿäº§çº§ SQL å¼•æ“",
      "authors": [
        "PaweÅ‚ Liskowski",
        "Benjamin Han",
        "Paritosh Aggarwal",
        "Bowei Chen",
        "Boxin Jiang",
        "Nitish Jindal",
        "Zihan Li",
        "Aaron Lin",
        "Kyle Schmaus",
        "Jay Tayade",
        "Weicheng Zhao",
        "Anupam Datta",
        "Nathan Wiegand",
        "Dimitris Tsirogiannis"
      ],
      "abstract": "Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning, enabling them to query both structured and unstructured data effortlessly. However, making semantic operations efficient at production scale poses fundamental challenges. Semantic operations are more expensive than traditional SQL operations, possess distinct latency and throughput characteristics, and their cost and selectivity are unknown during query compilation. Furthermore, existing query engines are not designed to optimize semantic operations. The AISQL query execution engine addresses these challenges through three novel techniques informed by production deployment data from Snowflake customers. First, AI-aware query optimization treats AI inference cost as a first-class optimization objective, reasoning about large language model (LLM) cost directly during query planning to achieve 2-8$\\times$ speedups. Second, adaptive model cascades reduce inference costs by routing most rows through a fast proxy model while escalating uncertain cases to a powerful oracle model, achieving 2-6$\\times$ speedups while maintaining 90-95% of oracle model quality. Third, semantic join query rewriting lowers the quadratic time complexity of join operations to linear through reformulation as multi-label classification tasks, achieving 15-70$\\times$ speedups with often improved prediction quality. AISQL is deployed in production at Snowflake, where it powers diverse customer workloads across analytics, search, and content understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†Snowflakeçš„Cortex AISQLï¼Œè¿™æ˜¯ä¸€ä¸ªå°†åŸç”Ÿè¯­ä¹‰æ“ä½œç›´æ¥é›†æˆåˆ°SQLä¸­çš„ç”Ÿäº§çº§å¼•æ“ï¼Œæ—¨åœ¨è®©ç”¨æˆ·èƒ½å¤Ÿé€šè¿‡å£°æ˜å¼æŸ¥è¯¢è½»æ¾å¤„ç†ç»“æ„åŒ–å’Œéç»“æ„åŒ–æ•°æ®ã€‚é’ˆå¯¹è¯­ä¹‰æ“ä½œåœ¨ç”Ÿäº§è§„æ¨¡ä¸‹é¢ä¸´çš„é«˜æˆæœ¬ã€å»¶è¿Ÿç‰¹æ€§åŠæœªçŸ¥é€‰æ‹©æ€§ç­‰æŒ‘æˆ˜ï¼ŒAISQLå¼•æ“é‡‡ç”¨äº†ä¸‰ç§åŸºäºç”Ÿäº§æ•°æ®çš„åˆ›æ–°æŠ€æœ¯ã€‚é¦–å…ˆï¼ŒAI-aware query optimizationå°†AIæ¨ç†æˆæœ¬ä½œä¸ºé¦–è¦ä¼˜åŒ–ç›®æ ‡ï¼Œåœ¨æŸ¥è¯¢è§„åˆ’é˜¶æ®µç›´æ¥æ¨ç†LLMæˆæœ¬ï¼Œå®ç°äº†2-8å€çš„åŠ é€Ÿã€‚å…¶æ¬¡ï¼Œadaptive model cascadesé€šè¿‡å°†å¤§å¤šæ•°æ•°æ®è¡Œè·¯ç”±è‡³å¿«é€Ÿçš„proxy modelï¼Œä»…å°†ä¸ç¡®å®šæ¡ˆä¾‹å‡çº§è‡³å¼ºå¤§çš„oracle modelï¼Œåœ¨ä¿æŒ90-95%æ¨¡å‹è´¨é‡çš„åŒæ—¶å®ç°äº†2-6å€çš„åŠ é€Ÿã€‚æœ€åï¼Œsemantic join query rewritingé€šè¿‡å°†è¿æ¥æ“ä½œé‡æ„ä¸ºå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ï¼Œå°†äºŒæ¬¡æ—¶é—´å¤æ‚åº¦é™ä½ä¸ºçº¿æ€§ï¼Œå®ç°äº†15-70å€çš„åŠ é€Ÿå¹¶å¾€å¾€èƒ½æå‡é¢„æµ‹è´¨é‡ã€‚ç›®å‰ï¼ŒAISQLå·²åœ¨Snowflakeç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²ï¼Œæ”¯æŒåˆ†æã€æœç´¢å’Œå†…å®¹ç†è§£ç­‰å¤šç§å®¢æˆ·å·¥ä½œè´Ÿè½½ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07663v2",
      "published_date": "2025-11-10 22:14:13 UTC",
      "updated_date": "2025-11-19 13:22:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:37:26.574603+00:00"
    },
    {
      "arxiv_id": "2511.07659v1",
      "title": "Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering",
      "title_zh": "é‡æ¢ NLIï¼šè¿ˆå‘ç»æµé«˜æ•ˆä¸”ä¸äººç±»å¯¹é½çš„é—®ç­”å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æŒ‡æ ‡",
      "authors": [
        "Sai Shridhar Balamurali",
        "Lu Cheng"
      ],
      "abstract": "Evaluating answers from state-of-the-art large language models (LLMs) is challenging: lexical metrics miss semantic nuances, whereas \"LLM-as-Judge\" scoring is computationally expensive. We re-evaluate a lightweight alternative -- off-the-shelf Natural Language Inference (NLI) scoring augmented by a simple lexical-match flag and find that this decades-old technique matches GPT-4o's accuracy (89.9%) on long-form QA, while requiring orders-of-magnitude fewer parameters. To test human alignment of these metrics rigorously, we introduce DIVER-QA, a new 3000-sample human-annotated benchmark spanning five QA datasets and five candidate LLMs. Our results highlight that inexpensive NLI-based evaluation remains competitive and offer DIVER-QA as an open resource for future metric research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)é—®ç­”è¯„ä¼°ä¸­å­˜åœ¨çš„è¯æ±‡æŒ‡æ ‡ç¼ºä¹è¯­ä¹‰æ„ŸçŸ¥åŠâ€œLLM-as-Judgeâ€è®¡ç®—æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œé‡æ–°è¯„ä¼°äº†ä¸€ç§è½»é‡çº§æ›¿ä»£æ–¹æ¡ˆã€‚ä½œè€…æå‡ºåˆ©ç”¨ç°æˆçš„è‡ªç„¶è¯­è¨€æ¨ç†(NLI)è¯„åˆ†å¹¶è¾…ä»¥ç®€å•çš„è¯æ±‡åŒ¹é…æ ‡å¿—æ¥è¿›è¡Œè¯„ä¼°ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™ç§ç»å…¸æŠ€æœ¯åœ¨é•¿æ–‡æœ¬é—®ç­”(long-form QA)ä¸Šçš„å‡†ç¡®ç‡è¾¾åˆ°89.9%ï¼Œä¸GPT-4oç›¸å½“ï¼ŒåŒæ—¶æ‰€éœ€å‚æ•°é‡æ˜¾è‘—é™ä½ã€‚ä¸ºäº†ä¸¥æ ¼æµ‹è¯•æŒ‡æ ‡ä¸äººç±»è¯„ä»·çš„ä¸€è‡´æ€§ï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†DIVER-QAï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«3000ä¸ªæ ·æœ¬çš„äººç±»æ ‡æ³¨åŸºå‡†ï¼Œæ¶µç›–äº”ä¸ªQAæ•°æ®é›†å’Œäº”ä¸ªå€™é€‰LLMsã€‚ç»“æœè¡¨æ˜ï¼Œä½æˆæœ¬çš„åŸºäºNLIçš„è¯„ä¼°æ–¹æ³•ä¾ç„¶æå…·ç«äº‰åŠ›ï¼ŒDIVER-QAä¹Ÿå°†ä½œä¸ºå¼€æºèµ„æºæ”¯æŒæœªæ¥çš„æŒ‡æ ‡ç ”ç©¶ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07659v1",
      "published_date": "2025-11-10 22:10:02 UTC",
      "updated_date": "2025-11-10 22:10:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:37:54.607677+00:00"
    },
    {
      "arxiv_id": "2511.07649v1",
      "title": "Adaptive Graph Learning with Transformer for Multi-Reservoir Inflow Prediction",
      "title_zh": "åŸºäºTransformerä¸è‡ªé€‚åº”å›¾å­¦ä¹ çš„å¤šæ°´åº“å…¥æµé¢„æµ‹",
      "authors": [
        "Pengfei Hu",
        "Ming Fan",
        "Xiaoxue Han",
        "Chang Lu",
        "Wei Zhang",
        "Hyun Kang",
        "Yue Ning",
        "Dan Lu"
      ],
      "abstract": "Reservoir inflow prediction is crucial for water resource management, yet existing approaches mainly focus on single-reservoir models that ignore spatial dependencies among interconnected reservoirs. We introduce AdaTrip as an adaptive, time-varying graph learning framework for multi-reservoir inflow forecasting. AdaTrip constructs dynamic graphs where reservoirs are nodes with directed edges reflecting hydrological connections, employing attention mechanisms to automatically identify crucial spatial and temporal dependencies. Evaluation on thirty reservoirs in the Upper Colorado River Basin demonstrates superiority over existing baselines, with improved performance for reservoirs with limited records through parameter sharing. Additionally, AdaTrip provides interpretable attention maps at edge and time-step levels, offering insights into hydrological controls to support operational decision-making. Our code is available at https://github.com/humphreyhuu/AdaTrip.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ°´åº“å…¥æµé¢„æµ‹æ¨¡å‹å¾€å¾€å¿½è§†äº’è”æ°´åº“é—´ç©ºé—´ä¾èµ–æ€§çš„å±€é™ï¼Œæå‡ºäº†AdaTripï¼Œä¸€ç§åŸºäºTransformerçš„è‡ªé€‚åº”æ—¶å˜å›¾å­¦ä¹ æ¡†æ¶ã€‚AdaTripé€šè¿‡æ„å»ºåŠ¨æ€å›¾å°†æ°´åº“è§†ä¸ºèŠ‚ç‚¹ï¼Œåˆ©ç”¨æ³¨æ„åŠ›æœºåˆ¶(attention mechanisms)è‡ªåŠ¨è¯†åˆ«å…³é”®çš„ç©ºé—´å’Œæ—¶é—´ä¾èµ–å…³ç³»ï¼Œä»è€Œæ•æ‰å¤æ‚çš„æ°´æ–‡è”ç³»ã€‚åœ¨ä¸Šç§‘ç½—æ‹‰å¤šæ²³æµåŸŸ30ä¸ªæ°´åº“çš„å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒAdaTripçš„è¡¨ç°ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œå¹¶é€šè¿‡å‚æ•°å…±äº«æœ‰æ•ˆæå‡äº†å†å²è®°å½•æœ‰é™çš„æ°´åº“çš„é¢„æµ‹ç²¾åº¦ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜èƒ½æä¾›è¾¹å’Œæ—¶é—´æ­¥å±‚é¢çš„å¯è§£é‡Šæ³¨æ„åŠ›å›¾(attention maps)ï¼Œæ·±å…¥æ­ç¤ºæ°´æ–‡æ§åˆ¶æœºåˆ¶ï¼Œä»è€Œä¸ºæ°´èµ„æºç®¡ç†çš„è¿è¥å†³ç­–æä¾›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICDM 2025 DMESS Workshop",
      "pdf_url": "https://arxiv.org/pdf/2511.07649v1",
      "published_date": "2025-11-10 21:53:32 UTC",
      "updated_date": "2025-11-10 21:53:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:38:16.679870+00:00"
    },
    {
      "arxiv_id": "2511.07645v1",
      "title": "A Self-Improving Architecture for Dynamic Safety in Large Language Models",
      "title_zh": "å¤§å‹è¯­è¨€æ¨¡å‹åŠ¨æ€å®‰å…¨çš„è‡ªæ”¹è¿›æ¶æ„",
      "authors": [
        "Tyler Slater"
      ],
      "abstract": "Context: The integration of Large Language Models (LLMs) into core software systems is accelerating. However, existing software architecture patterns are static, while current safety assurance methods are not scalable, leaving systems vulnerable to novel adversarial threats.\n  Objective: To design, implement, and evaluate a novel software architecture that enables an AI-driven system to autonomously and continuously adapt its own safety protocols at runtime.\n  Method: We propose the Self-Improving Safety Framework (SISF), a runtime architecture that couples an unprotected, unaligned base LLM (mistralai/Mistral-7B-v0.1) with a dynamic feedback loop. This loop consists of an AI Adjudicator (GPT-4o) for breach detection and a Policy Synthesis Module (GPT-4 Turbo) that autonomously generates new, generalized safety policies (both heuristic and semantic) in response to failures.\n  Results: We conducted a dynamic learning evaluation using the 520-prompt AdvBench dataset. The unprotected model was 100% vulnerable. Our SISF, starting from zero policies, demonstrated a clear learning curve: it detected 237 breaches, autonomously synthesized 234 new policies, and reduced the overall Attack Success Rate (ASR) to 45.58%. In a subsequent test on 520 benign prompts, the SISF achieved a 0.00% False Positive Rate (FPR), proving its ability to adapt without compromising user utility.\n  Conclusion: An architectural approach to AI safety, based on the principles of self-adaptation, is a viable and effective strategy. Our framework demonstrates a practical path towards building more robust, resilient, and scalable AI-driven systems, shifting safety assurance from a static, pre-deployment activity to an automated, runtime process.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç°æœ‰å®‰å…¨æ¶æ„é™æ€ä¸”éš¾ä»¥åº”å¯¹æ–°å‹å¯¹æŠ—æ€§å¨èƒçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSelf-Improving Safety Framework (SISF)çš„è¿è¡Œæ—¶æ¶æ„ã€‚è¯¥æ¡†æ¶å°†æœªå¯¹é½çš„åŸºç¡€æ¨¡å‹ä¸åŠ¨æ€åé¦ˆå¾ªç¯ç›¸ç»“åˆï¼Œåˆ©ç”¨AI Adjudicator (GPT-4o)è¿›è¡Œè¿è§„æ£€æµ‹ï¼Œå¹¶é€šè¿‡Policy Synthesis Module (GPT-4 Turbo)è‡ªä¸»ç”Ÿæˆæ–°çš„é€šç”¨å®‰å…¨ç­–ç•¥ã€‚åœ¨AdvBenchæ•°æ®é›†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼ŒSISFä»é›¶ç­–ç•¥å¼€å§‹ï¼ŒæˆåŠŸæ£€æµ‹äº†237æ¬¡è¿è§„å¹¶åˆæˆäº†234æ¡æ–°ç­–ç•¥ï¼Œå°†æ”»å‡»æˆåŠŸç‡(ASR)ä»æœªå—ä¿æŠ¤æ¨¡å‹çš„100%æ˜¾è‘—é™ä½è‡³45.58%ã€‚åŒæ—¶ï¼Œåœ¨é’ˆå¯¹è‰¯æ€§æç¤ºçš„æµ‹è¯•ä¸­ï¼Œè¯¥æ¡†æ¶å®ç°äº†0.00%çš„å‡é˜³æ€§ç‡(FPR)ï¼Œè¯æ˜äº†å…¶åœ¨ä¸ç‰ºç‰²ç”¨æˆ·å®ç”¨æ€§çš„æƒ…å†µä¸‹å…·å¤‡åŠ¨æ€é€‚åº”èƒ½åŠ›ã€‚è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼ŒåŸºäºè‡ªé€‚åº”åŸåˆ™çš„æ¶æ„æ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆå°†AIå®‰å…¨ä¿éšœä»é™æ€çš„éƒ¨ç½²å‰æ´»åŠ¨è½¬å˜ä¸ºè‡ªåŠ¨åŒ–çš„è¿è¡Œæ—¶è¿‡ç¨‹ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "Under review at the journal Information and Software Technology (Special Issue on Software Architecture for AI-Driven Systems)",
      "pdf_url": "https://arxiv.org/pdf/2511.07645v1",
      "published_date": "2025-11-10 21:39:40 UTC",
      "updated_date": "2025-11-10 21:39:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:38:39.674085+00:00"
    },
    {
      "arxiv_id": "2511.07637v1",
      "title": "Private-RAG: Answering Multiple Queries with LLMs while Keeping Your Data Private",
      "title_zh": "Private-RAGï¼šåœ¨ä¿æŠ¤æ•°æ®éšç§çš„åŒæ—¶åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å›ç­”å¤šé‡æŸ¥è¯¢",
      "authors": [
        "Ruihan Wu",
        "Erchi Wang",
        "Zhiyuan Zhang",
        "Yu-Xiang Wang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by retrieving documents from an external corpus at inference time. When this corpus contains sensitive information, however, unprotected RAG systems are at risk of leaking private information. Prior work has introduced differential privacy (DP) guarantees for RAG, but only in single-query settings, which fall short of realistic usage. In this paper, we study the more practical multi-query setting and propose two DP-RAG algorithms. The first, MURAG, leverages an individual privacy filter so that the accumulated privacy loss only depends on how frequently each document is retrieved rather than the total number of queries. The second, MURAG-ADA, further improves utility by privately releasing query-specific thresholds, enabling more precise selection of relevant documents. Our experiments across multiple LLMs and datasets demonstrate that the proposed methods scale to hundreds of queries within a practical DP budget ($\\varepsilon\\approx10$), while preserving meaningful utility.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)ç³»ç»Ÿåœ¨å¤„ç†æ•æ„Ÿå¤–éƒ¨è¯­æ–™åº“æ—¶å¯èƒ½å­˜åœ¨çš„éšç§æ³„éœ²é£é™©ï¼Œæ¢è®¨äº†æ›´å…·å®ç”¨ä»·å€¼çš„å¤šæŸ¥è¯¢åœºæ™¯ä¸‹çš„éšç§ä¿æŠ¤é—®é¢˜ã€‚é‰´äºå…ˆå‰çš„å·®åˆ†éšç§(Differential Privacy, DP) RAGå·¥ä½œä»…å±€é™äºå•æŸ¥è¯¢è®¾ç½®ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§æ–°çš„DP-RAGç®—æ³•ã€‚ç¬¬ä¸€ç§ç®—æ³•MURAGåˆ©ç”¨ä¸ªä½“éšç§è¿‡æ»¤å™¨ï¼Œç¡®ä¿ç´¯ç§¯éšç§æŸå¤±ä»…å–å†³äºæ–‡æ¡£è¢«æ£€ç´¢çš„é¢‘ç‡ï¼Œè€ŒéæŸ¥è¯¢çš„æ€»æ•°é‡ã€‚ç¬¬äºŒç§ç®—æ³•MURAG-ADAåˆ™é€šè¿‡ç§æœ‰åŒ–å‘å¸ƒç‰¹å®šäºæŸ¥è¯¢çš„é˜ˆå€¼ï¼Œå®ç°äº†æ›´ç²¾ç¡®çš„ç›¸å…³æ–‡æ¡£é€‰æ‹©ï¼Œä»è€Œè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹æ•ˆç”¨ã€‚è·¨å¤šä¸ªå¤§è¯­è¨€æ¨¡å‹(LLMs)å’Œæ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼Œæ‰€æå‡ºçš„æ–¹æ³•åœ¨å®é™…çš„DPé¢„ç®—($\\varepsilon\\approx10$)å†…èƒ½å¤Ÿæ‰©å±•æ”¯æŒæ•°ç™¾æ¬¡æŸ¥è¯¢ï¼Œå¹¶ä¿æŒäº†è‰¯å¥½çš„æ•ˆç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07637v1",
      "published_date": "2025-11-10 21:12:32 UTC",
      "updated_date": "2025-11-10 21:12:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:41:20.954106+00:00"
    },
    {
      "arxiv_id": "2511.07629v1",
      "title": "Partial Action Replacement: Tackling Distribution Shift in Offline MARL",
      "title_zh": "éƒ¨åˆ†åŠ¨ä½œæ›¿æ¢ï¼šåº”å¯¹ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ä¸­çš„åˆ†å¸ƒåç§»",
      "authors": [
        "Yue Jin",
        "Giovanni Montana"
      ],
      "abstract": "Offline multi-agent reinforcement learning (MARL) is severely hampered by the challenge of evaluating out-of-distribution (OOD) joint actions. Our core finding is that when the behavior policy is factorized - a common scenario where agents act fully or partially independently during data collection - a strategy of partial action replacement (PAR) can significantly mitigate this challenge. PAR updates a single or part of agents' actions while the others remain fixed to the behavioral data, reducing distribution shift compared to full joint-action updates. Based on this insight, we develop Soft-Partial Conservative Q-Learning (SPaCQL), using PAR to mitigate OOD issue and dynamically weighting different PAR strategies based on the uncertainty of value estimation. We provide a rigorous theoretical foundation for this approach, proving that under factorized behavior policies, the induced distribution shift scales linearly with the number of deviating agents rather than exponentially with the joint-action space. This yields a provably tighter value error bound for this important class of offline MARL problems. Our theoretical results also indicate that SPaCQL adaptively addresses distribution shift using uncertainty-informed weights. Our empirical results demonstrate SPaCQL enables more effective policy learning, and manifest its remarkable superiority over baseline algorithms when the offline dataset exhibits the independence structure.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¦»çº¿å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (Offline MARL)ä¸­è¯„ä¼°åˆ†å¸ƒå¤–(OOD)è”åˆåŠ¨ä½œçš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºPartial Action Replacement (PAR)çš„ç­–ç•¥ã€‚æ ¸å¿ƒå‘ç°æ˜¯ï¼Œå½“è¡Œä¸ºç­–ç•¥æ˜¯åˆ†è§£çš„ï¼ˆå³æ™ºèƒ½ä½“åœ¨æ•°æ®æ”¶é›†æ—¶ç‹¬ç«‹è¡ŒåŠ¨ï¼‰æ—¶ï¼ŒPARé€šè¿‡ä»…æ›´æ–°éƒ¨åˆ†æ™ºèƒ½ä½“çš„åŠ¨ä½œè€Œä¿æŒå…¶ä»–æ™ºèƒ½ä½“åŠ¨ä½œå›ºå®šï¼Œèƒ½æ˜¾è‘—å‡å°‘åˆ†å¸ƒåç§»ã€‚åŸºäºæ­¤ï¼Œä½œè€…å¼€å‘äº†Soft-Partial Conservative Q-Learning (SPaCQL)ç®—æ³•ï¼Œåˆ©ç”¨PARç¼“è§£OODé—®é¢˜ï¼Œå¹¶æ ¹æ®ä»·å€¼ä¼°è®¡çš„ä¸ç¡®å®šæ€§åŠ¨æ€åŠ æƒä¸åŒçš„PARç­–ç•¥ã€‚ç†è®ºåˆ†æè¯æ˜ï¼Œåœ¨åˆ†è§£è¡Œä¸ºç­–ç•¥ä¸‹ï¼ŒPARå¼•èµ·çš„åˆ†å¸ƒåç§»éšåç¦»æ™ºèƒ½ä½“æ•°é‡çº¿æ€§å¢é•¿ï¼Œè€Œééšè”åˆåŠ¨ä½œç©ºé—´æŒ‡æ•°å¢é•¿ï¼Œä»è€Œæä¾›äº†æ›´ç´§çš„ä»·å€¼è¯¯å·®ç•Œé™ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSPaCQLå®ç°äº†æ›´æœ‰æ•ˆçš„ç­–ç•¥å­¦ä¹ ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¦»çº¿æ•°æ®é›†è¡¨ç°å‡ºç‹¬ç«‹ç»“æ„æ—¶ï¼Œå…¶æ€§èƒ½æ˜¾è‘—ä¼˜äºåŸºçº¿ç®—æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07629v1",
      "published_date": "2025-11-10 20:56:58 UTC",
      "updated_date": "2025-11-10 20:56:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:41:07.328637+00:00"
    },
    {
      "arxiv_id": "2511.07603v2",
      "title": "One Router to Route Them All: Homogeneous Expert Routing for Heterogeneous Graph Transformers",
      "title_zh": "ä¸€ä¸ªè·¯ç”±ç»Ÿé¢†æ‰€æœ‰ï¼šé¢å‘å¼‚æ„å›¾ Transformer çš„åŒè´¨ä¸“å®¶è·¯ç”±",
      "authors": [
        "Georgiy Shakirov",
        "Albert Arakelov"
      ],
      "abstract": "A common practice in heterogeneous graph neural networks (HGNNs) is to condition parameters on node/edge types, assuming types reflect semantic roles. However, this can cause overreliance on surface-level labels and impede cross-type knowledge transfer. We explore integrating Mixture-of-Experts (MoE) into HGNNs--a direction underexplored despite MoE's success in homogeneous settings. Crucially, we question the need for type-specific experts. We propose Homogeneous Expert Routing (HER), an MoE layer for Heterogeneous Graph Transformers (HGT) that stochastically masks type embeddings during routing to encourage type-agnostic specialization. Evaluated on IMDB, ACM, and DBLP for link prediction, HER consistently outperforms standard HGT and a type-separated MoE baseline. Analysis on IMDB shows HER experts specialize by semantic patterns (e.g., movie genres) rather than node types, confirming routing is driven by latent semantics. Our work demonstrates that regularizing type dependence in expert routing yields more generalizable, efficient, and interpretable representations--a new design principle for heterogeneous graph learning.",
      "tldr_zh": "å¼‚æ„å›¾ç¥ç»ç½‘ç»œ(HGNNs)é€šå¸¸æ ¹æ®èŠ‚ç‚¹æˆ–è¾¹ç±»å‹è®¾å®šå‚æ•°ï¼Œä½†è¿™å®¹æ˜“å¯¼è‡´æ¨¡å‹è¿‡åº¦ä¾èµ–è¡¨é¢æ ‡ç­¾å¹¶é˜»ç¢è·¨ç±»å‹çš„çŸ¥è¯†è¿ç§»ã€‚è¯¥ç ”ç©¶æ¢ç´¢å°†æ··åˆä¸“å®¶æ¨¡å‹(Mixture-of-Experts, MoE)å¼•å…¥HGNNsï¼Œå¹¶æå‡ºäº†åŒè´¨ä¸“å®¶è·¯ç”±(Homogeneous Expert Routing, HER)ã€‚HERä½œä¸ºå¼‚æ„å›¾Transformer(HGT)çš„ä¸€ä¸ªMoEå±‚ï¼Œé€šè¿‡åœ¨è·¯ç”±è¿‡ç¨‹ä¸­éšæœºæ©ç›–ç±»å‹åµŒå…¥ï¼Œé¼“åŠ±æ¨¡å‹è¿›è¡Œä¸ç±»å‹æ— å…³çš„ä¸“ä¸šåŒ–å­¦ä¹ ã€‚åœ¨IMDBã€ACMå’ŒDBLPæ•°æ®é›†ä¸Šçš„é“¾è·¯é¢„æµ‹å®éªŒæ˜¾ç¤ºï¼ŒHERçš„è¡¨ç°æŒç»­ä¼˜äºæ ‡å‡†HGTå’ŒåŸºäºç±»å‹åˆ†ç¦»çš„MoEåŸºçº¿æ¨¡å‹ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒHERä¸­çš„ä¸“å®¶æ›´å¤šæ˜¯æ ¹æ®æ½œåœ¨çš„è¯­ä¹‰æ¨¡å¼ï¼ˆå¦‚ç”µå½±é¢˜æï¼‰è€ŒéèŠ‚ç‚¹ç±»å‹è¿›è¡Œåˆ†å·¥ã€‚è¯¥ç ”ç©¶è¯æ˜äº†åœ¨ä¸“å®¶è·¯ç”±ä¸­è§„èŒƒåŒ–ç±»å‹ä¾èµ–èƒ½å¸¦æ¥æ›´å…·æ³›åŒ–æ€§ã€é«˜æ•ˆä¸”å¯è§£é‡Šçš„è¡¨ç¤ºï¼Œä¸ºå¼‚æ„å›¾å­¦ä¹ ç¡®ç«‹äº†æ–°çš„è®¾è®¡åŸåˆ™ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This preprint has been withdrawn by the authors due to significant revisions in preparation for conference submission. A substantially updated version will be submitted separately",
      "pdf_url": "https://arxiv.org/pdf/2511.07603v2",
      "published_date": "2025-11-10 20:20:58 UTC",
      "updated_date": "2026-01-21 19:41:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:40:56.103163+00:00"
    },
    {
      "arxiv_id": "2511.07593v1",
      "title": "Leveraging the Power of AI and Social Interactions to Restore Trust in Public Polls",
      "title_zh": "å€ŸåŠ©äººå·¥æ™ºèƒ½ä¸ç¤¾äº¤äº’åŠ¨æ¢å¤å…¬å…±æ°‘æ„è°ƒæŸ¥çš„ä¿¡ä»»",
      "authors": [
        "Amr Akmal Abouelmagd",
        "Amr Hilal"
      ],
      "abstract": "The emergence of crowdsourced data has significantly reshaped social science, enabling extensive exploration of collective human actions, viewpoints, and societal dynamics. However, ensuring safe, fair, and reliable participation remains a persistent challenge. Traditional polling methods have seen a notable decline in engagement over recent decades, raising concerns about the credibility of collected data. Meanwhile, social and peer-to-peer networks have become increasingly widespread, but data from these platforms can suffer from credibility issues due to fraudulent or ineligible participation. In this paper, we explore how social interactions can help restore credibility in crowdsourced data collected over social networks. We present an empirical study to detect ineligible participation in a polling task through AI-based graph analysis of social interactions among imperfect participants composed of honest and dishonest actors. Our approach focuses solely on the structure of social interaction graphs, without relying on the content being shared. We simulate different levels and types of dishonest behavior among participants who attempt to propagate the task within their social networks. We conduct experiments on real-world social network datasets, using different eligibility criteria and modeling diverse participation patterns. Although structural differences in social interaction graphs introduce some performance variability, our study achieves promising results in detecting ineligibility across diverse social and behavioral profiles, with accuracy exceeding 90% in some configurations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³ä¼—åŒ…æ•°æ®å’Œç¤¾äº¤ç½‘ç»œè°ƒæŸ¥ä¸­é¢ä¸´çš„ä¿¡ä»»å±æœºåŠæ¬ºè¯ˆå‚ä¸é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨AIå’Œç¤¾äº¤äº’åŠ¨æ¥æ¢å¤æ°‘æ„è°ƒæŸ¥å¯ä¿¡åº¦çš„æ–¹æ³•ã€‚ä½œè€…é€šè¿‡åŸºäºAIçš„å›¾åˆ†æï¼ˆgraph analysisï¼‰æŠ€æœ¯ï¼Œä»…ä¾æ®ç¤¾äº¤äº’åŠ¨å›¾çš„ç»“æ„è€Œéå…·ä½“å†…å®¹ï¼Œæ¥æ£€æµ‹è°ƒæŸ¥ä»»åŠ¡ä¸­çš„ä¸åˆæ ¼å‚ä¸è€…ã€‚ç ”ç©¶æ¨¡æ‹Ÿäº†åŒ…å«è¯šå®ä¸ä¸è¯šå®è¡ŒåŠ¨è€…çš„æ··åˆå‚ä¸æ¨¡å¼ï¼Œå¹¶åœ¨çœŸå®ä¸–ç•Œçš„ç¤¾äº¤ç½‘ç»œæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒã€‚å®éªŒæ¶µç›–äº†ä¸åŒçš„èµ„æ ¼æ ‡å‡†å’Œå‚ä¸æ¨¡å¼ï¼Œç»“æœè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šç§ç¤¾äº¤å’Œè¡Œä¸ºé…ç½®ä¸‹å‡èƒ½æœ‰æ•ˆè¯†åˆ«ä¸åˆæ ¼å‚ä¸è¡Œä¸ºã€‚åœ¨ç‰¹å®šé…ç½®ä¸‹ï¼Œè¯¥æ–¹æ³•çš„æ£€æµ‹å‡†ç¡®ç‡è¶…è¿‡90%ï¼Œè¯æ˜äº†åˆ©ç”¨ç¤¾äº¤äº’åŠ¨ç»“æ„ç‰¹å¾æå‡ä¼—åŒ…æ•°æ®è´¨é‡çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07593v1",
      "published_date": "2025-11-10 20:06:32 UTC",
      "updated_date": "2025-11-10 20:06:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:40:23.766371+00:00"
    },
    {
      "arxiv_id": "2511.07587v1",
      "title": "Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces",
      "title_zh": "è¶…è¶Šäº‹å®æ£€ç´¢ï¼šåŸºäºç”Ÿæˆå¼è¯­ä¹‰å·¥ä½œç©ºé—´çš„ RAG æƒ…æ™¯è®°å¿†",
      "authors": [
        "Shreyas Rajesh",
        "Pavan Holur",
        "Chenda Duan",
        "David Chong",
        "Vwani Roychowdhury"
      ],
      "abstract": "Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the \\textbf{Generative Semantic Workspace} (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an \\textit{Operator}, which maps incoming observations to intermediate semantic structures, and a \\textit{Reconciler}, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) \\cite{huet_episodic_2025} comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to \\textbf{20\\%}. Furthermore, GSW is highly efficient, reducing query-time context tokens by \\textbf{51\\%} compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é•¿ä¸Šä¸‹æ–‡æ¨ç†ä¸­é¢ä¸´çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯ç°æœ‰æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•åœ¨å¤„ç†æƒ…æ™¯è®°å¿†æ–¹é¢çš„ä¸è¶³ï¼Œæå‡ºäº†Generative Semantic Workspace (GSW)ã€‚ç°æœ‰çš„RAGæ–¹æ¡ˆå¤šç”¨äºäº‹å®æ£€ç´¢ï¼Œç¼ºä¹è·Ÿè¸ªå®ä½“åœ¨æ—¶ç©ºäº‹ä»¶ä¸­æ¼”å˜çš„å™äº‹è¡¨ç¤ºèƒ½åŠ›ã€‚GSWæ˜¯ä¸€ç§å—ç¥ç»ç§‘å­¦å¯å‘çš„ç”Ÿæˆå¼è®°å¿†æ¡†æ¶ï¼ŒåŒ…å«å°†è§‚å¯Ÿæ˜ å°„ä¸ºè¯­ä¹‰ç»“æ„çš„Operatorï¼Œä»¥åŠå°†è¿™äº›ç»“æ„æ•´åˆåˆ°æŒä¹…å·¥ä½œåŒºå¹¶ç¡®ä¿æ—¶ç©ºé€»è¾‘è¿è´¯æ€§çš„Reconcilerã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæ„å»ºç»“æ„åŒ–ä¸”å¯è§£é‡Šçš„æ¼”å˜æƒ…å¢ƒè¡¨ç¤ºï¼Œä½¿LLMsèƒ½å¤Ÿå¯¹è§’è‰²ã€åŠ¨ä½œå’Œæ—¶ç©ºèƒŒæ™¯è¿›è¡Œæ¨ç†ã€‚åœ¨åŒ…å«10ä¸‡è‡³100ä¸‡tokenè¯­æ–™åº“çš„Episodic Memory Benchmark (EpBench)ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒGSWçš„è¡¨ç°ä¼˜äºç°æœ‰çš„RAGåŸºçº¿é«˜è¾¾20%ã€‚æ­¤å¤–ï¼ŒGSWæ˜¾è‘—æé«˜äº†æ•ˆç‡ï¼Œå°†æŸ¥è¯¢æ—¶çš„ä¸Šä¸‹æ–‡tokenæ•°é‡å‡å°‘äº†51%ï¼Œå¤§å¹…é™ä½äº†æ¨ç†æˆæœ¬ã€‚è¿™é¡¹å·¥ä½œä¸ºèµ‹äºˆLLMsç±»äººçš„æƒ…æ™¯è®°å¿†æä¾›äº†å…·ä½“è“å›¾ï¼Œæœ‰åŠ©äºæ„å»ºå…·å¤‡é•¿ç¨‹æ¨ç†èƒ½åŠ›çš„æ™ºèƒ½ä½“ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2026 Oral",
      "pdf_url": "https://arxiv.org/pdf/2511.07587v1",
      "published_date": "2025-11-10 19:59:34 UTC",
      "updated_date": "2025-11-10 19:59:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:44:32.695529+00:00"
    },
    {
      "arxiv_id": "2511.07585v1",
      "title": "LLM Output Drift: Cross-Provider Validation & Mitigation for Financial Workflows",
      "title_zh": "LLMè¾“å‡ºæ¼‚ç§»ï¼šé¢å‘é‡‘èå·¥ä½œæµçš„è·¨æä¾›å•†éªŒè¯ä¸ç¼“è§£",
      "authors": [
        "Raffi Khatchadourian",
        "Rolando Franco"
      ],
      "abstract": "Financial institutions deploy Large Language Models (LLMs) for reconciliations, regulatory reporting, and client communications, but nondeterministic outputs (output drift) undermine auditability and trust. We quantify drift across five model architectures (7B-120B parameters) on regulated financial tasks, revealing a stark inverse relationship: smaller models (Granite-3-8B, Qwen2.5-7B) achieve 100% output consistency at T=0.0, while GPT-OSS-120B exhibits only 12.5% consistency (95% CI: 3.5-36.0%) regardless of configuration (p<0.0001, Fisher's exact test). This finding challenges conventional assumptions that larger models are universally superior for production deployment.\n  Our contributions include: (i) a finance-calibrated deterministic test harness combining greedy decoding (T=0.0), fixed seeds, and SEC 10-K structure-aware retrieval ordering; (ii) task-specific invariant checking for RAG, JSON, and SQL outputs using finance-calibrated materiality thresholds (plus or minus 5%) and SEC citation validation; (iii) a three-tier model classification system enabling risk-appropriate deployment decisions; and (iv) an audit-ready attestation system with dual-provider validation.\n  We evaluated five models (Qwen2.5-7B via Ollama, Granite-3-8B via IBM watsonx.ai, Llama-3.3-70B, Mistral-Medium-2505, and GPT-OSS-120B) across three regulated financial tasks. Across 480 runs (n=16 per condition), structured tasks (SQL) remain stable even at T=0.2, while RAG tasks show drift (25-75%), revealing task-dependent sensitivity. Cross-provider validation confirms deterministic behavior transfers between local and cloud deployments. We map our framework to Financial Stability Board (FSB), Bank for International Settlements (BIS), and Commodity Futures Trading Commission (CFTC) requirements, demonstrating practical pathways for compliance-ready AI deployments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é‡‘èå·¥ä½œæµä¸­å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„è¾“å‡ºæ¼‚ç§»(output drift)é—®é¢˜è¿›è¡Œäº†æ·±å…¥åˆ†æä¸ç¼“è§£æ–¹æ¡ˆè®¾è®¡ï¼Œæ—¨åœ¨è§£å†³éç¡®å®šæ€§è¾“å‡ºå¯¹å®¡è®¡å’Œä¿¡ä»»çš„æŒ‘æˆ˜ã€‚é€šè¿‡å¯¹äº”ç§ä¸åŒè§„æ¨¡æ¨¡å‹ï¼ˆ7B-120Bå‚æ•°ï¼‰çš„é‡åŒ–è¯„ä¼°ï¼Œç ”ç©¶å‘ç°æ¨¡å‹è§„æ¨¡ä¸ä¸€è‡´æ€§ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„è´Ÿç›¸å…³å…³ç³»ï¼šè¾ƒå°çš„æ¨¡å‹ï¼ˆå¦‚Granite-3-8Bå’ŒQwen2.5-7Bï¼‰åœ¨æ¸©åº¦ä¸º0æ—¶å¯å®ç°100%çš„ä¸€è‡´æ€§ï¼Œè€ŒGPT-OSS-120Bä»…ä¸º12.5%ï¼ŒæŒ‘æˆ˜äº†â€œå¤§æ¨¡å‹å³æ›´ä¼˜â€çš„ä¼ ç»Ÿå‡è®¾ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€å¥—é‡‘èä¸“ç”¨çš„ç¡®å®šæ€§æµ‹è¯•æ¡†æ¶ï¼Œç»“åˆäº†è´ªå©ªè§£ç (greedy decoding)ã€å›ºå®šç§å­åŠSECç»“æ„æ„ŸçŸ¥æ£€ç´¢ï¼Œå¹¶å¼•å…¥äº†é’ˆå¯¹RAGã€JSONå’ŒSQLè¾“å‡ºçš„ä»»åŠ¡ç‰¹å®šä¸å˜é‡æ£€æŸ¥ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ„å»ºäº†ä¸‰å±‚æ¨¡å‹åˆ†ç±»ç³»ç»ŸåŠåŒä¾›åº”å•†éªŒè¯çš„å®¡è®¡è¯æ˜ç³»ç»Ÿï¼Œç¡®ä¿ç¬¦åˆFSBã€BISå’ŒCFTCç­‰ç›‘ç®¡æœºæ„çš„è¦æ±‚ã€‚å®éªŒè¡¨æ˜ï¼Œè™½ç„¶ç»“æ„åŒ–ä»»åŠ¡(SQL)ç›¸å¯¹ç¨³å®šï¼Œä½†RAGä»»åŠ¡æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ¼‚ç§»æ•æ„Ÿæ€§ï¼Œè¯¥æ¡†æ¶æœ‰æ•ˆåœ°éªŒè¯äº†è·¨æœ¬åœ°å’Œäº‘éƒ¨ç½²çš„ç¡®å®šæ€§è¡Œä¸ºï¼Œä¸ºåˆè§„çš„AIéƒ¨ç½²æä¾›äº†å®ç”¨è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 5 figures. To appear in AI4F @ ACM ICAIF '25, November 15-18, 2025, Singapore",
      "pdf_url": "https://arxiv.org/pdf/2511.07585v1",
      "published_date": "2025-11-10 19:54:00 UTC",
      "updated_date": "2025-11-10 19:54:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:45:02.069673+00:00"
    },
    {
      "arxiv_id": "2511.07584v1",
      "title": "SemanticForge: Repository-Level Code Generation through Semantic Knowledge Graphs and Constraint Satisfaction",
      "title_zh": "SemanticForgeï¼šåŸºäºè¯­ä¹‰çŸ¥è¯†å›¾è°±ä¸çº¦æŸæ»¡è¶³çš„ä»“åº“çº§ä»£ç ç”Ÿæˆ",
      "authors": [
        "Wuyang Zhang",
        "Chenkai Zhang",
        "Zhen Luo",
        "Jianming Ma",
        "Wangming Yuan",
        "Chuqiao Gu",
        "Chenwei Feng"
      ],
      "abstract": "Large language models (LLMs) have transformed software development by enabling automated code generation, yet they frequently suffer from systematic errors that limit practical deployment. We identify two critical failure modes: \\textit{logical hallucination} (incorrect control/data-flow reasoning) and \\textit{schematic hallucination} (type mismatches, signature violations, and architectural inconsistencies). These errors stem from the absence of explicit, queryable representations of repository-wide semantics.\n  This paper presents \\textbf{SemanticForge}, which introduces four fundamental algorithmic advances for semantically-aware code generation: (1) a novel automatic reconciliation algorithm for dual static-dynamic knowledge graphs, unifying compile-time and runtime program semantics; (2) a neural approach that learns to generate structured graph queries from natural language, achieving 73\\% precision versus 51\\% for traditional retrieval; (3) a novel beam search algorithm with integrated SMT solving, enabling real-time constraint verification during generation rather than post-hoc validation; and (4) an incremental maintenance algorithm that updates knowledge graphs in $O(|Î”R| \\cdot \\log n)$ time while maintaining semantic equivalence.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä»£ç ç”Ÿæˆä¸­å¸¸å‡ºç°çš„é€»è¾‘å¹»è§‰(logical hallucination)å’Œå›¾å¼å¹»è§‰(schematic hallucination)é—®é¢˜ï¼ŒæŒ‡å‡ºå…¶æ ¹æºåœ¨äºç¼ºä¹æ˜ç¡®çš„ä»“åº“çº§è¯­ä¹‰è¡¨ç¤ºã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†SemanticForgeï¼Œé€šè¿‡å››é¡¹æ ¸å¿ƒç®—æ³•è¿›å±•æ¥å®ç°è¯­ä¹‰æ„ŸçŸ¥çš„ä»£ç ç”Ÿæˆã€‚é¦–å…ˆï¼Œè¯¥æ¡†æ¶é‡‡ç”¨ä¸€ç§æ–°é¢–çš„è‡ªåŠ¨åè°ƒç®—æ³•ç»“åˆé™æ€å’ŒåŠ¨æ€çŸ¥è¯†å›¾è°±(knowledge graphs)ï¼Œç»Ÿä¸€äº†ç¼–è¯‘æ—¶å’Œè¿è¡Œæ—¶çš„ç¨‹åºè¯­ä¹‰ï¼›å…¶æ¬¡ï¼Œåˆ©ç”¨ç¥ç»æ–¹æ³•ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆç»“æ„åŒ–å›¾æŸ¥è¯¢ï¼Œæ˜¾è‘—æå‡äº†æ£€ç´¢ç²¾åº¦ã€‚æ­¤å¤–ï¼ŒSemanticForgeå¼•å…¥äº†é›†æˆSMTæ±‚è§£(Satisfiability Modulo Theories)çš„æŸæœç´¢(beam search)ç®—æ³•ï¼Œå®ç°äº†ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å®æ—¶çº¦æŸéªŒè¯ï¼Œå¹¶æå‡ºäº†ä¸€ç§å¢é‡ç»´æŠ¤ç®—æ³•ä»¥é«˜æ•ˆæ›´æ–°çŸ¥è¯†å›¾è°±ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07584v1",
      "published_date": "2025-11-10 19:53:23 UTC",
      "updated_date": "2025-11-10 19:53:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:45:20.908028+00:00"
    },
    {
      "arxiv_id": "2511.07581v1",
      "title": "Think Before You Retrieve: Learning Test-Time Adaptive Search with Small Language Models",
      "title_zh": "å…ˆæ€è€ƒå†æ£€ç´¢ï¼šåˆ©ç”¨å°å‹è¯­è¨€æ¨¡å‹å­¦ä¹ æµ‹è¯•æ—¶è‡ªé€‚åº”æœç´¢",
      "authors": [
        "Supriti Vijay",
        "Aman Priyanshu",
        "Anu Vellore",
        "Baturay Saglam",
        "Amin Karbasi"
      ],
      "abstract": "Effective information retrieval requires reasoning over partial evidence and refining strategies as information emerges. Yet current approaches fall short: neural retrievers lack reasoning capabilities, large language models (LLMs) provide semantic depth but at prohibitive cost, and query rewriting or decomposition limits improvement to static transformations. As a result, existing methods fail to capture the iterative dynamics of exploration, feedback, and revision that complex user queries demand. We introduce Orion, a training framework that enables compact models (350M-1.2B parameters) to perform iterative retrieval through learned search strategies. Orion combines: (1) synthetic trajectory generation and supervised fine-tuning to encourage diverse exploration patterns in models, (2) reinforcement learning (RL) that rewards effective query refinement and backtracking behaviors, and (3) inference-time beam search algorithms that exploit the self-reflection capabilities learned during RL. Despite using only 3% of the training data available, our 1.2B model achieves 77.6% success on SciFact (vs. 72.6% for prior retrievers), 25.2% on BRIGHT (vs. 22.1%), 63.2% on NFCorpus (vs. 57.8%), and remains competitive on FEVER, HotpotQA, and MSMarco. It outperforms retrievers up to 200-400x larger on five of six benchmarks. These findings suggest that retrieval performance can emerge from learned strategies, not just model scale, when models are trained to search, reflect, and revise.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ç¥ç»æ£€ç´¢å™¨ç¼ºä¹æ¨ç†èƒ½åŠ›ä»¥åŠå¤§è¯­è¨€æ¨¡å‹æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†Orionï¼Œä¸€ç§èµ‹äºˆå°å‹è¯­è¨€æ¨¡å‹ï¼ˆ350M-1.2Bå‚æ•°ï¼‰è¿­ä»£æ£€ç´¢èƒ½åŠ›çš„è®­ç»ƒæ¡†æ¶ã€‚Orioné¦–å…ˆåˆ©ç”¨åˆæˆè½¨è¿¹ç”Ÿæˆå’Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰é¼“åŠ±æ¨¡å‹è¿›è¡Œå¤šæ ·åŒ–æ¢ç´¢ï¼Œéšåé€šè¿‡å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰å¥–åŠ±æœ‰æ•ˆçš„æŸ¥è¯¢ç»†åŒ–å’Œå›æº¯è¡Œä¸ºï¼Œæœ€åç»“åˆæ¨ç†æ—¶çš„æ³¢æŸæœç´¢ï¼ˆBeam Searchï¼‰ç®—æ³•åˆ©ç”¨æ¨¡å‹çš„è‡ªæˆ‘åæ€èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œä»…ä½¿ç”¨3%çš„è®­ç»ƒæ•°æ®ï¼ŒOrionçš„1.2Bæ¨¡å‹åœ¨SciFactã€BRIGHTå’ŒNFCorpusç­‰åŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶åœ¨å…­ä¸ªåŸºå‡†ä¸­çš„äº”ä¸ªä¸Šè¶…è¶Šäº†è§„æ¨¡å¤§200-400å€çš„æ¨¡å‹ã€‚è¿™è¯æ˜äº†é€šè¿‡è®­ç»ƒæ¨¡å‹å­¦ä¹ æœç´¢ã€åæ€å’Œä¿®æ­£ç­–ç•¥ï¼Œå°å‹æ¨¡å‹ä¹Ÿèƒ½å®ç°å“è¶Šçš„æ£€ç´¢æ€§èƒ½ï¼Œè€Œæ— éœ€å•çº¯ä¾èµ–æ¨¡å‹è§„æ¨¡çš„æ‰©å¤§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "37 images, 7 figures, and 15 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.07581v1",
      "published_date": "2025-11-10 19:49:55 UTC",
      "updated_date": "2025-11-10 19:49:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:45:47.645378+00:00"
    },
    {
      "arxiv_id": "2511.07568v1",
      "title": "Procedural Knowledge Improves Agentic LLM Workflows",
      "title_zh": "ç¨‹åºæ€§çŸ¥è¯†æå‡å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“å·¥ä½œæµ",
      "authors": [
        "Vincent Hsiao",
        "Mark Roberts",
        "Leslie Smith"
      ],
      "abstract": "Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç¼ºä¹å·¥å…·æ”¯æŒæˆ–å¾®è°ƒæ—¶éš¾ä»¥æ‰§è¡Œä»£ç†ä»»åŠ¡(agentic tasks)çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨åˆ†å±‚ä»»åŠ¡ç½‘ç»œ(HTN)å½¢å¼çš„è¿‡ç¨‹æ€§çŸ¥è¯†(procedural knowledge)æ¥å¢å¼ºLLMå·¥ä½œæµçš„æ–¹æ³•ã€‚ä½œè€…å½¢å¼åŒ–å¹¶å®ç°äº†ä¸€ä¸ªç»“åˆHTNçš„agentic LLM workflowï¼Œæ—¨åœ¨è¯„ä¼°è¿‡ç¨‹æ€§çŸ¥è¯†å¯¹éšå«è§„åˆ’ä»»åŠ¡çš„æå‡æ½œåŠ›ã€‚å®è¯ç»“æœæ˜¾ç¤ºï¼Œæ‰‹å·¥ç¼–ç çš„HTNèƒ½æ˜¾è‘—æå‡LLMåœ¨ä»£ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œç”šè‡³ä½¿20bæˆ–70bå‚æ•°çš„è¾ƒå°æ¨¡å‹è¶…è¶Š120bå‚æ•°çš„å¤§å‹åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè™½ç„¶LLMè‡ªåŠ¨ç”Ÿæˆçš„HTNæå‡å¹…åº¦è¾ƒå°ï¼Œä½†ä»èƒ½æ”¹å–„æ•´ä½“æ€§èƒ½ã€‚è¯¥ç ”ç©¶è¡¨æ˜ï¼Œåˆ©ç”¨æ¥è‡ªäººç±»ã€æ–‡æ¡£æˆ–LLMçš„ä¸“ä¸šçŸ¥è¯†æ¥æ„å»ºè¿‡ç¨‹æ€§çŸ¥è¯†ï¼Œå°†æˆä¸ºä¼˜åŒ–LLMå·¥ä½œæµçš„é‡è¦æ‰‹æ®µã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07568v1",
      "published_date": "2025-11-10 19:27:57 UTC",
      "updated_date": "2025-11-10 19:27:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:46:32.260603+00:00"
    },
    {
      "arxiv_id": "2511.08645v1",
      "title": "Fluence Map Prediction with Deep Learning: A Transformer-based Approach",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„é€šé‡å›¾é¢„æµ‹ï¼šåŸºäº Transformer çš„æ–¹æ³•",
      "authors": [
        "Ujunwa Mgboh",
        "Rafi Sultan",
        "Dongxiao Zhu",
        "Joshua Kim"
      ],
      "abstract": "Accurate fluence map prediction is essential in intensity-modulated radiation therapy (IMRT) to maximize tumor coverage while minimizing dose to healthy tissues. Conventional optimization is time-consuming and dependent on planner expertise. This study presents a deep learning framework that accelerates fluence map generation while maintaining clinical quality. An end-to-end 3D Swin-UNETR network was trained to predict nine-beam fluence maps directly from volumetric CT images and anatomical contours using 99 prostate IMRT cases (79 for training and 20 for testing). The transformer-based model employs hierarchical self-attention to capture both local anatomical structures and long-range spatial dependencies. Predicted fluence maps were imported into the Eclipse Treatment Planning System for dose recalculation, and model performance was evaluated using beam-wise fluence correlation, spatial gamma analysis, and dose-volume histogram (DVH) metrics. The proposed model achieved an average R^2 of 0.95 +/- 0.02, MAE of 0.035 +/- 0.008, and gamma passing rate of 85 +/- 10 percent (3 percent / 3 mm) on the test set, with no significant differences observed in DVH parameters between predicted and clinical plans. The Swin-UNETR framework enables fully automated, inverse-free fluence map prediction directly from anatomical inputs, enhancing spatial coherence, accuracy, and efficiency while offering a scalable and consistent solution for automated IMRT plan generation.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºTransformerçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è°ƒå¼ºæ”¾å°„æ²»ç–—(IMRT)ä¸­é€šé‡å›¾ä¼˜åŒ–è€—æ—¶ä¸”ä¾èµ–è§„åˆ’è€…ç»éªŒçš„é—®é¢˜ã€‚ç ”ç©¶äººå‘˜è®­ç»ƒäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„3D Swin-UNETRç½‘ç»œï¼Œåˆ©ç”¨99ä¸ªå‰åˆ—è…ºIMRTç—…ä¾‹æ•°æ®ï¼Œç›´æ¥ä»ä½“ç§¯CTå›¾åƒå’Œè§£å‰–è½®å»“é¢„æµ‹ä¹æŸé€šé‡å›¾ã€‚è¯¥æ¨¡å‹é‡‡ç”¨åˆ†å±‚è‡ªæ³¨æ„åŠ›æœºåˆ¶(hierarchical self-attention)æœ‰æ•ˆæ•æ‰å±€éƒ¨è§£å‰–ç»“æ„å’Œé•¿ç¨‹ç©ºé—´ä¾èµ–å…³ç³»ã€‚è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šå–å¾—äº†0.95çš„å¹³å‡R^2å’Œ85%çš„ä¼½é©¬é€šè¿‡ç‡ï¼Œä¸”é¢„æµ‹ç»“æœä¸ä¸´åºŠè®¡åˆ’åœ¨å‰‚é‡ä½“ç§¯ç›´æ–¹å›¾(DVH)å‚æ•°ä¸Šæ— æ˜¾è‘—å·®å¼‚ã€‚è¯¥Swin-UNETRæ¡†æ¶å®ç°äº†å…¨è‡ªåŠ¨ã€æ— é€†å‘ä¼˜åŒ–çš„é€šé‡å›¾é¢„æµ‹ï¼Œåœ¨ä¿æŒä¸´åºŠè´¨é‡çš„åŒæ—¶æ˜¾è‘—æå‡äº†IMRTè®¡åˆ’ç”Ÿæˆçš„æ•ˆç‡å’Œä¸€è‡´æ€§ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08645v1",
      "published_date": "2025-11-10 19:24:14 UTC",
      "updated_date": "2025-11-10 19:24:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:46:34.049692+00:00"
    },
    {
      "arxiv_id": "2511.07559v1",
      "title": "N-ReLU: Zero-Mean Stochastic Extension of ReLU",
      "title_zh": "N-ReLUï¼šReLU çš„é›¶å‡å€¼éšæœºæ‰©å±•",
      "authors": [
        "Md Motaleb Hossen Manik",
        "Md Zabirul Islam",
        "Ge Wang"
      ],
      "abstract": "Activation functions are fundamental for enabling nonlinear representations in deep neural networks. However, the standard rectified linear unit (ReLU) often suffers from inactive or \"dead\" neurons caused by its hard zero cutoff. To address this issue, we introduce N-ReLU (Noise-ReLU), a zero-mean stochastic extension of ReLU that replaces negative activations with Gaussian noise while preserving the same expected output. This expectation-aligned formulation maintains gradient flow in inactive regions and acts as an annealing-style regularizer during training. Experiments on the MNIST dataset using both multilayer perceptron (MLP) and convolutional neural network (CNN) architectures show that N-ReLU achieves accuracy comparable to or slightly exceeding that of ReLU, LeakyReLU, PReLU, GELU, and RReLU at moderate noise levels (sigma = 0.05-0.10), with stable convergence and no dead neurons observed. These results demonstrate that lightweight Gaussian noise injection offers a simple yet effective mechanism to enhance optimization robustness without modifying network structures or introducing additional parameters.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†N-ReLU (Noise-ReLU)ï¼Œä¸€ç§ReLUçš„é›¶å‡å€¼éšæœºæ‰©å±•ï¼Œæ—¨åœ¨è§£å†³æ ‡å‡†ReLUå› ç¡¬é›¶æˆªæ–­å¯¼è‡´çš„ç¥ç»å…ƒâ€œæ­»äº¡â€é—®é¢˜ã€‚N-ReLUé€šè¿‡å°†è´Ÿæ¿€æ´»å€¼æ›¿æ¢ä¸ºé«˜æ–¯å™ªå£°(Gaussian noise)ï¼ŒåŒæ—¶ä¿æŒç›¸åŒçš„æœŸæœ›è¾“å‡ºï¼Œä»è€Œåœ¨éæ´»è·ƒåŒºåŸŸç»´æŒæ¢¯åº¦æµå¹¶èµ·åˆ°é€€ç«å¼æ­£åˆ™åŒ–(annealing-style regularizer)çš„ä½œç”¨ã€‚åœ¨MNISTæ•°æ®é›†ä¸Šä½¿ç”¨å¤šå±‚æ„ŸçŸ¥æœº(MLP)å’Œå·ç§¯ç¥ç»ç½‘ç»œ(CNN)æ¶æ„è¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼ŒN-ReLUåœ¨é€‚åº¦å™ªå£°æ°´å¹³ä¸‹ï¼ˆsigma = 0.05-0.10ï¼‰çš„å‡†ç¡®ç‡ä¸ReLUã€LeakyReLUã€PReLUã€GELUå’ŒRReLUç›¸å½“æˆ–ç•¥é«˜ã€‚ç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•å®ç°äº†ç¨³å®šçš„æ”¶æ•›ä¸”æœªè§‚å¯Ÿåˆ°æ­»ç¥ç»å…ƒï¼Œè¯æ˜äº†è½»é‡çº§é«˜æ–¯å™ªå£°æ³¨å…¥æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æœºåˆ¶ï¼Œèƒ½åœ¨ä¸ä¿®æ”¹ç½‘ç»œç»“æ„æˆ–å¼•å…¥é¢å¤–å‚æ•°çš„æƒ…å†µä¸‹å¢å¼ºä¼˜åŒ–é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07559v1",
      "published_date": "2025-11-10 19:07:10 UTC",
      "updated_date": "2025-11-10 19:07:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:47:08.942683+00:00"
    },
    {
      "arxiv_id": "2511.08644v2",
      "title": "Energy Consumption of Dataframe Libraries for End-to-End Deep Learning Pipelines:A Comparative Analysis",
      "title_zh": "é¢å‘ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æµæ°´çº¿çš„ DataFrame åº“èƒ½è€—ï¼šå¯¹æ¯”åˆ†æ",
      "authors": [
        "Punit Kumar",
        "Asif Imran",
        "Tevfik Kosar"
      ],
      "abstract": "This paper presents a detailed comparative analysis of the performance of three major Python data manipulation libraries - Pandas, Polars, and Dask - specifically when embedded within complete deep learning (DL) training and inference pipelines. The research bridges a gap in existing literature by studying how these libraries interact with substantial GPU workloads during critical phases like data loading, preprocessing, and batch feeding. The authors measured key performance indicators including runtime, memory usage, disk usage, and energy consumption (both CPU and GPU) across various machine learning models and datasets.",
      "tldr_zh": "è¯¥è®ºæ–‡å¯¹Pandasã€Polarså’ŒDaskè¿™ä¸‰ä¸ªä¸»è¦çš„Pythonæ•°æ®æ“ä½œåº“åœ¨ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ (Deep Learning)è®­ç»ƒå’Œæ¨ç†ç®¡é“ä¸­çš„æ€§èƒ½è¿›è¡Œäº†è¯¦ç»†çš„æ¯”è¾ƒåˆ†æã€‚ç ”ç©¶å¡«è¡¥äº†ç°æœ‰æ–‡çŒ®çš„ç©ºç™½ï¼Œé‡ç‚¹æ¢è®¨äº†è¿™äº›åº“åœ¨æ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œæ‰¹é‡é¦ˆé€ç­‰å…³é”®é˜¶æ®µå¦‚ä½•ä¸å¤§é‡GPUå·¥ä½œè´Ÿè½½è¿›è¡Œäº¤äº’ã€‚ä½œè€…é€šè¿‡å¤šç§æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ•°æ®é›†ï¼Œæµ‹é‡äº†è¿è¡Œæ—¶é—´ã€å†…å­˜ä½¿ç”¨ã€ç£ç›˜ä½¿ç”¨ä»¥åŠCPUå’ŒGPUçš„èƒ½è€—(Energy Consumption)ç­‰å…³é”®æ€§èƒ½æŒ‡æ ‡ã€‚è¯¥ç ”ç©¶æ—¨åœ¨æ­ç¤ºä¸åŒDataframeåº“åœ¨å®é™…æ·±åº¦å­¦ä¹ å·¥ä½œæµä¸­çš„æ•ˆç‡è¡¨ç°å’Œèµ„æºåˆ©ç”¨æƒ…å†µï¼Œä¸ºä¼˜åŒ–DLç®¡é“çš„èƒ½æºæ•ˆç‡æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08644v2",
      "published_date": "2025-11-10 19:06:00 UTC",
      "updated_date": "2025-11-17 20:13:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:47:35.220972+00:00"
    },
    {
      "arxiv_id": "2511.07418v1",
      "title": "Lightning Grasp: High Performance Procedural Grasp Synthesis with Contact Fields",
      "title_zh": "Lightning Graspï¼šåŸºäºæ¥è§¦åœºçš„é«˜æ€§èƒ½ç¨‹åºåŒ–æŠ“å–åˆæˆ",
      "authors": [
        "Zhao-Heng Yin",
        "Pieter Abbeel"
      ],
      "abstract": "Despite years of research, real-time diverse grasp synthesis for dexterous hands remains an unsolved core challenge in robotics and computer graphics. We present Lightning Grasp, a novel high-performance procedural grasp synthesis algorithm that achieves orders-of-magnitude speedups over state-of-the-art approaches, while enabling unsupervised grasp generation for irregular, tool-like objects. The method avoids many limitations of prior approaches, such as the need for carefully tuned energy functions and sensitive initialization. This breakthrough is driven by a key insight: decoupling complex geometric computation from the search process via a simple, efficient data structure - the Contact Field. This abstraction collapses the problem complexity, enabling a procedural search at unprecedented speeds. We open-source our system to propel further innovation in robotic manipulation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Lightning Graspï¼Œä¸€ç§é«˜æ€§èƒ½çš„è¿‡ç¨‹åŒ–æŠ“å–åˆæˆç®—æ³•ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººå­¦å’Œè®¡ç®—æœºå›¾å½¢å­¦ä¸­çµå·§æ‰‹å®æ—¶å¤šæ ·åŒ–æŠ“å–åˆæˆçš„æ ¸å¿ƒéš¾é¢˜ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ´å¯Ÿåœ¨äºåˆ©ç”¨ä¸€ç§åä¸ºContact Fieldçš„ç®€å•é«˜æ•ˆæ•°æ®ç»“æ„ï¼Œå°†å¤æ‚çš„å‡ ä½•è®¡ç®—ä¸æœç´¢è¿‡ç¨‹è§£è€¦ï¼Œä»è€Œæå¤§åœ°é™ä½äº†é—®é¢˜å¤æ‚åº¦ã€‚é€šè¿‡è¿™ç§æŠ½è±¡ï¼ŒLightning Graspå®ç°äº†æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•ï¼ˆSOTAï¼‰å¿«å‡ ä¸ªæ•°é‡çº§çš„æœç´¢é€Ÿåº¦ï¼ŒåŒæ—¶é¿å…äº†å¯¹èƒ½é‡å‡½æ•°ç²¾å¿ƒè°ƒæ•´å’Œæ•æ„Ÿåˆå§‹åŒ–çš„ä¾èµ–ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•æ”¯æŒé’ˆå¯¹ä¸è§„åˆ™å·¥å…·ç±»ç‰©ä½“çš„æ— ç›‘ç£æŠ“å–ç”Ÿæˆï¼Œå±•ç¤ºäº†å“è¶Šçš„é€šç”¨æ€§ä¸é²æ£’æ€§ã€‚ä½œè€…å·²å¼€æºè¯¥ç³»ç»Ÿï¼ŒæœŸæœ›ä»¥æ­¤æ¨åŠ¨æœºå™¨äººæ“ä½œé¢†åŸŸçš„è¿›ä¸€æ­¥åˆ›æ–°ä¸å‘å±•ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.DC",
        "cs.GR"
      ],
      "primary_category": "cs.RO",
      "comment": "Code: https://github.com/zhaohengyin/lightning-grasp",
      "pdf_url": "https://arxiv.org/pdf/2511.07418v1",
      "published_date": "2025-11-10 18:59:44 UTC",
      "updated_date": "2025-11-10 18:59:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:47:58.333201+00:00"
    },
    {
      "arxiv_id": "2511.07417v1",
      "title": "Language Generation with Infinite Contamination",
      "title_zh": "æ— é™æ±¡æŸ“ä¸‹çš„è¯­è¨€ç”Ÿæˆ",
      "authors": [
        "Anay Mehrotra",
        "Grigoris Velegkas",
        "Xifan Yu",
        "Felix Zhou"
      ],
      "abstract": "We study language generation in the limit, where an algorithm observes an adversarial enumeration of strings from an unknown target language $K$ and must eventually generate new, unseen strings from $K$. Kleinberg and Mullainathan [KM24] proved that generation is achievable in surprisingly general settings. But their generator suffers from ``mode collapse,'' producing from an ever-smaller subset of the target. To address this, Kleinberg and Wei [KW25] require the generator's output to be ``dense'' in the target language. They showed that generation with density, surprisingly, remains achievable at the same generality.\n  Both results assume perfect data: no noisy insertions and no omissions. This raises a central question: how much contamination can generation tolerate? Recent works made partial progress on this question by studying (non-dense) generation with either finite amounts of noise (but no omissions) or omissions (but no noise).\n  We characterize robustness under contaminated enumerations: 1. Generation under Contamination: Language generation in the limit is achievable for all countable collections iff the fraction of contaminated examples converges to zero. When this fails, we characterize which collections are generable. 2. Dense Generation under Contamination: Dense generation is strictly less robust to contamination than generation. As a byproduct, we resolve an open question of Raman and Raman [ICML25] by showing that generation is possible with only membership oracle access under finitely many contaminated examples.\n  Finally, we introduce a beyond-worst-case model inspired by curriculum learning and prove that dense generation is achievable even with infinite contamination provided the fraction of contaminated examples converges to zero. This suggests curriculum learning may be crucial for learning from noisy web data.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æé™æƒ…å†µä¸‹çš„è¯­è¨€ç”Ÿæˆ(Language Generation in the limit)é—®é¢˜ï¼Œé‡ç‚¹åˆ†æäº†ç®—æ³•åœ¨é¢å¯¹åŒ…å«å™ªå£°å’Œé—æ¼çš„æ±¡æŸ“æ•°æ®æ—¶çš„é²æ£’æ€§ã€‚ä½œè€…è¯æ˜ï¼Œå¯¹äºæ‰€æœ‰å¯æ•°é›†åˆï¼Œåªæœ‰å½“å—æ±¡æŸ“æ ·æœ¬çš„æ¯”ä¾‹æ”¶æ•›äºé›¶æ—¶ï¼Œè¯­è¨€ç”Ÿæˆæ‰æ˜¯å¯å®ç°çš„ï¼Œå¹¶å¯¹æ— æ³•å®ç°çš„æƒ…å†µè¿›è¡Œäº†ç‰¹å¾æè¿°ã€‚ç ”ç©¶å‘ç°ï¼Œè¦æ±‚è¾“å‡ºåœ¨ç›®æ ‡è¯­è¨€ä¸­â€œå¯†é›†â€çš„å¯†é›†ç”Ÿæˆ(Dense Generation)å¯¹æ±¡æŸ“çš„é²æ£’æ€§ä¸¥æ ¼ä½äºæ™®é€šç”Ÿæˆã€‚ä½œä¸ºå‰¯äº§å“ï¼Œè®ºæ–‡è¿˜è§£å†³äº†Ramanå’ŒRamanæå‡ºçš„ä¸€ä¸ªå¼€æ”¾é—®é¢˜ï¼Œè¯æ˜åœ¨æœ‰é™æ±¡æŸ“ä¸‹ä»…é€šè¿‡æˆå‘˜æŸ¥è¯¢(Membership Oracle)å³å¯å®ç°ç”Ÿæˆã€‚æœ€åï¼Œå—è¯¾ç¨‹å­¦ä¹ (Curriculum Learning)å¯å‘ï¼Œä½œè€…å¼•å…¥äº†ä¸€ç§è¶…è¶Šæœ€åæƒ…å†µçš„æ¨¡å‹ï¼Œè¯æ˜åªè¦æ±¡æŸ“æ¯”ä¾‹æ”¶æ•›äºé›¶ï¼Œå³ä½¿å­˜åœ¨æ— é™æ±¡æŸ“ä¹Ÿèƒ½å®ç°å¯†é›†ç”Ÿæˆï¼Œè¿™è¡¨æ˜è¯¾ç¨‹å­¦ä¹ å¯¹äºåˆ©ç”¨å˜ˆæ‚ç½‘ç»œæ•°æ®è‡³å…³é‡è¦ã€‚",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07417v1",
      "published_date": "2025-11-10 18:59:39 UTC",
      "updated_date": "2025-11-10 18:59:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:48:26.365872+00:00"
    },
    {
      "arxiv_id": "2511.07416v1",
      "title": "Robot Learning from a Physical World Model",
      "title_zh": "åŸºäºç‰©ç†ä¸–ç•Œæ¨¡å‹çš„æœºå™¨äººå­¦ä¹ ",
      "authors": [
        "Jiageng Mao",
        "Sicheng He",
        "Hao-Ning Wu",
        "Yang You",
        "Shuyang Sun",
        "Zhicheng Wang",
        "Yanan Bao",
        "Huizhong Chen",
        "Leonidas Guibas",
        "Vitor Guizilini",
        "Howard Zhou",
        "Yue Wang"
      ],
      "abstract": "We introduce PhysWorld, a framework that enables robot learning from video generation through physical world modeling. Recent video generation models can synthesize photorealistic visual demonstrations from language commands and images, offering a powerful yet underexplored source of training signals for robotics. However, directly retargeting pixel motions from generated videos to robots neglects physics, often resulting in inaccurate manipulations. PhysWorld addresses this limitation by coupling video generation with physical world reconstruction. Given a single image and a task command, our method generates task-conditioned videos and reconstructs the underlying physical world from the videos, and the generated video motions are grounded into physically accurate actions through object-centric residual reinforcement learning with the physical world model. This synergy transforms implicit visual guidance into physically executable robotic trajectories, eliminating the need for real robot data collection and enabling zero-shot generalizable robotic manipulation. Experiments on diverse real-world tasks demonstrate that PhysWorld substantially improves manipulation accuracy compared to previous approaches. Visit \\href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage} for details.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PhysWorldï¼Œä¸€ç§é€šè¿‡ç‰©ç†ä¸–ç•Œå»ºæ¨¡å®ç°ä»è§†é¢‘ç”Ÿæˆä¸­è¿›è¡Œæœºå™¨äººå­¦ä¹ çš„æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰è§†é¢‘ç”Ÿæˆæ¨¡å‹åœ¨å°†åƒç´ è¿åŠ¨é‡å®šå‘åˆ°æœºå™¨äººæ—¶å¾€å¾€å¿½ç•¥ç‰©ç†ç‰¹æ€§ã€å¯¼è‡´æ“ä½œä¸å‡†ç¡®çš„é—®é¢˜ï¼ŒPhysWorldé€šè¿‡ç»“åˆè§†é¢‘ç”Ÿæˆä¸ç‰©ç†ä¸–ç•Œé‡å»ºç»™å‡ºäº†è§£å†³æ–¹æ¡ˆã€‚è¯¥æ–¹æ³•æ ¹æ®å•å¼ å›¾åƒå’Œä»»åŠ¡æŒ‡ä»¤ç”Ÿæˆè§†é¢‘å¹¶é‡å»ºåº•å±‚ç‰©ç†ä¸–ç•Œï¼Œåˆ©ç”¨ç‰©ç†ä¸–ç•Œæ¨¡å‹ä¸­çš„ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„æ®‹å·®å¼ºåŒ–å­¦ä¹ (object-centric residual reinforcement learning)ï¼Œå°†ç”Ÿæˆçš„è§†é¢‘è¿åŠ¨è½¬åŒ–ä¸ºç‰©ç†ä¸Šç²¾ç¡®çš„åŠ¨ä½œã€‚è¿™ç§ååŒä½œç”¨å°†éšå¼çš„è§†è§‰å¼•å¯¼è½¬åŒ–ä¸ºç‰©ç†ä¸Šå¯æ‰§è¡Œçš„æœºå™¨äººè½¨è¿¹ï¼Œæ¶ˆé™¤äº†å¯¹çœŸå®æœºå™¨äººæ•°æ®æ”¶é›†çš„éœ€æ±‚ï¼Œå¹¶å®ç°äº†é›¶æ ·æœ¬æ³›åŒ–æœºå™¨äººæ“ä½œ(zero-shot generalizable robotic manipulation)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPhysWorldåœ¨å¤šç§ç°å®ä¸–ç•Œä»»åŠ¡ä¸­çš„æ“ä½œå‡†ç¡®ç‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://pointscoder.github.io/PhysWorld_Web/",
      "pdf_url": "https://arxiv.org/pdf/2511.07416v1",
      "published_date": "2025-11-10 18:59:07 UTC",
      "updated_date": "2025-11-10 18:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:51:34.165492+00:00"
    },
    {
      "arxiv_id": "2511.07413v2",
      "title": "DigiData: Training and Evaluating General-Purpose Mobile Control Agents",
      "title_zh": "DigiDataï¼šé€šç”¨ç§»åŠ¨æ§åˆ¶æ™ºèƒ½ä½“çš„è®­ç»ƒä¸è¯„ä¼°",
      "authors": [
        "Yuxuan Sun",
        "Manchen Wang",
        "Shengyi Qian",
        "William R. Wong",
        "Eric Gan",
        "Pierluca D'Oro",
        "Alejandro Castillejo Munoz",
        "Sneha Silwal",
        "Pedro Matias",
        "Nitin Kamra",
        "Satwik Kottur",
        "Nick Raines",
        "Xuanyi Zhao",
        "Joy Chen",
        "Joseph Greer",
        "Andrea Madotto",
        "Allen Bolourchi",
        "James Valori",
        "Kevin Carlberg",
        "Karl Ridgeway",
        "Joseph Tighe"
      ],
      "abstract": "AI agents capable of controlling user interfaces have the potential to transform human interaction with digital devices. To accelerate this transformation, two fundamental building blocks are essential: high-quality datasets that enable agents to achieve complex and human-relevant goals, and robust evaluation methods that allow researchers and practitioners to rapidly enhance agent performance. In this paper, we introduce DigiData, a large-scale, high-quality, diverse, multi-modal dataset designed for training mobile control agents. Unlike existing datasets, which derive goals from unstructured interactions, DigiData is meticulously constructed through comprehensive exploration of app features, resulting in greater diversity and higher goal complexity. Additionally, we present DigiData-Bench, a benchmark for evaluating mobile control agents on real-world complex tasks. We demonstrate that the commonly used step-accuracy metric falls short in reliably assessing mobile control agents and, to address this, we propose dynamic evaluation protocols and AI-powered evaluations as rigorous alternatives for agent assessment. Our contributions aim to significantly advance the development of mobile control agents, paving the way for more intuitive and effective human-device interactions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†DigiDataï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºè®­ç»ƒé€šç”¨ç§»åŠ¨æ§åˆ¶æ™ºèƒ½ä½“ï¼ˆMobile Control Agentsï¼‰è®¾è®¡çš„å¤§è§„æ¨¡ã€é«˜è´¨é‡ä¸”å¤šæ¨¡æ€çš„æ•°æ®é›†ã€‚ä¸åŸºäºéç»“æ„åŒ–äº¤äº’çš„ç°æœ‰æ•°æ®é›†ä¸åŒï¼ŒDigiDataé€šè¿‡å¯¹åº”ç”¨ç¨‹åºåŠŸèƒ½çš„å…¨é¢æ¢ç´¢ç²¾å¿ƒæ„å»ºï¼Œä»è€Œå®ç°äº†æ›´é«˜çš„å¤šæ ·æ€§å’Œç›®æ ‡å¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æå‡ºäº†DigiData-Benchï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºåœ¨å¤æ‚çš„ç°å®ä¸–ç•Œä»»åŠ¡ä¸­è¯„ä¼°ç§»åŠ¨æ§åˆ¶æ™ºèƒ½ä½“çš„åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹å¸¸ç”¨çš„æ­¥éª¤å‡†ç¡®ç‡ï¼ˆstep-accuracyï¼‰æŒ‡æ ‡åœ¨è¯„ä¼°ä¸­å­˜åœ¨çš„ä¸è¶³ï¼Œä½œè€…æå‡ºäº†åŠ¨æ€è¯„ä¼°åè®®å’ŒAIé©±åŠ¨çš„è¯„ä¼°æ–¹æ³•ï¼ˆAI-powered evaluationsï¼‰ä½œä¸ºæ›´ä¸¥è°¨çš„æ›¿ä»£æ–¹æ¡ˆã€‚è¿™é¡¹å·¥ä½œæ—¨åœ¨é€šè¿‡æä¾›é«˜è´¨é‡æ•°æ®å’Œç¨³å¥çš„è¯„ä¼°æ–¹æ³•ï¼Œæ˜¾è‘—æ¨è¿›ç§»åŠ¨æ§åˆ¶æ™ºèƒ½ä½“çš„å‘å±•ï¼Œä»è€Œæ”¹å–„äººæœºäº¤äº’ä½“éªŒã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Website: https://facebookresearch.github.io/DigiData",
      "pdf_url": "https://arxiv.org/pdf/2511.07413v2",
      "published_date": "2025-11-10 18:57:35 UTC",
      "updated_date": "2025-11-11 20:52:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:51:56.751121+00:00"
    },
    {
      "arxiv_id": "2511.07410v1",
      "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective",
      "title_zh": "è§†è§‰è¯­è¨€æ¨¡å‹ä½œä¸ºæœºå™¨äººåº”ç”¨é—­ç¯ç¬¦å·è§„åˆ’å™¨ï¼šæ§åˆ¶ç†è®ºè§†è§’",
      "authors": [
        "Hao Wang",
        "Sathwik Karnik",
        "Bea Lim",
        "Somil Bansal"
      ],
      "abstract": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»æ§åˆ¶ç†è®ºï¼ˆControl-Theoreticï¼‰çš„è§†è§’å‡ºå‘ï¼Œæ¢è®¨äº†å¦‚ä½•å°†è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰æœ‰æ•ˆåœ°ç”¨ä½œæœºå™¨äººåº”ç”¨ä¸­çš„é—­ç¯ç¬¦å·è§„åˆ’å™¨ã€‚é’ˆå¯¹VLMsä½œä¸ºâ€œé»‘ç›’â€è¿ä½œå®¹æ˜“äº§ç”Ÿä¸å¯é¢„æµ‹é”™è¯¯çš„é—®é¢˜ï¼Œä½œè€…æ·±å…¥ç ”ç©¶äº†æ§åˆ¶æ—¶åŸŸï¼ˆcontrol horizonï¼‰å’Œçƒ­å¯åŠ¨ï¼ˆwarm-startingï¼‰å¯¹è§„åˆ’æ€§èƒ½çš„å…·ä½“å½±å“ã€‚é€šè¿‡è®¾è®¡å’Œæ‰§è¡Œå—æ§å®éªŒï¼Œè¯¥å·¥ä½œæ­ç¤ºäº†åˆ©ç”¨VLMsè¿›è¡Œé—­ç¯ç¬¦å·è§„åˆ’çš„å…³é”®è§„å¾‹ã€‚ç ”ç©¶ç»“æœä¸ä»…æä¾›äº†å¹¿æ³›é€‚ç”¨çš„è§è§£ï¼Œè¿˜æå‡ºäº†ä¸€ç³»åˆ—å…·ä½“çš„å»ºè®®ï¼Œæ—¨åœ¨å¸®åŠ©æ”¹è¿›VLMç¬¦å·è§„åˆ’å™¨åœ¨é«˜å±‚æœºå™¨äººè§„åˆ’ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07410v1",
      "published_date": "2025-11-10 18:56:56 UTC",
      "updated_date": "2025-11-10 18:56:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:53:02.869941+00:00"
    },
    {
      "arxiv_id": "2511.07403v1",
      "title": "SpatialThinker: Reinforcing 3D Reasoning in Multimodal LLMs via Spatial Rewards",
      "title_zh": "SpatialThinkerï¼šåŸºäºç©ºé—´å¥–åŠ±å¼ºåŒ–å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„3Dæ¨ç†",
      "authors": [
        "Hunar Batra",
        "Haoqin Tu",
        "Hardy Chen",
        "Yuanze Lin",
        "Cihang Xie",
        "Ronald Clark"
      ],
      "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress in vision-language tasks, but they continue to struggle with spatial understanding. Existing spatial MLLMs often rely on explicit 3D inputs or architecture-specific modifications, and remain constrained by large-scale datasets or sparse supervision. To address these limitations, we introduce SpatialThinker, a 3D-aware MLLM trained with RL to integrate structured spatial grounding with multi-step reasoning. The model simulates human-like spatial perception by constructing a scene graph of task-relevant objects and spatial relations, and reasoning towards an answer via dense spatial rewards. SpatialThinker consists of two key contributions: (1) a data synthesis pipeline that generates STVQA-7K, a high-quality spatial VQA dataset, and (2) online RL with a multi-objective dense spatial reward enforcing spatial grounding. SpatialThinker-7B outperforms supervised fine-tuning and the sparse RL baseline on spatial understanding and real-world VQA benchmarks, nearly doubling the base-model gain compared to sparse RL, and surpassing GPT-4o. These results showcase the effectiveness of combining spatial supervision with reward-aligned reasoning in enabling robust 3D spatial understanding with limited data and advancing MLLMs towards human-level visual reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SpatialThinkerï¼Œä¸€ç§åˆ©ç”¨å¼ºåŒ–å­¦ä¹ (RL)è®­ç»ƒçš„3Dæ„ŸçŸ¥å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLM)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨¡å‹åœ¨ç©ºé—´ç†è§£æ–¹é¢çš„å±€é™æ€§ã€‚SpatialThinkeré€šè¿‡æ„å»ºåŒ…å«ä»»åŠ¡ç›¸å…³å¯¹è±¡å’Œç©ºé—´å…³ç³»çš„åœºæ™¯å›¾(scene graph)æ¥æ¨¡æ‹Ÿäººç±»çš„ç©ºé—´æ„ŸçŸ¥ï¼Œå¹¶åˆ©ç”¨å¯†é›†ç©ºé—´å¥–åŠ±(dense spatial rewards)å¼•å¯¼å¤šæ­¥æ¨ç†ã€‚è¯¥ç ”ç©¶çš„ä¸»è¦è´¡çŒ®åŒ…æ‹¬å¼€å‘äº†ä¸€ä¸ªæ•°æ®åˆæˆç®¡é“ä»¥ç”Ÿæˆé«˜è´¨é‡ç©ºé—´VQAæ•°æ®é›†STVQA-7Kï¼Œä»¥åŠå¼•å…¥äº†å…·æœ‰å¤šç›®æ ‡å¯†é›†ç©ºé—´å¥–åŠ±çš„åœ¨çº¿RLæœºåˆ¶ä»¥å¢å¼ºç©ºé—´å®šä½èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSpatialThinker-7Båœ¨ç©ºé—´ç†è§£å’Œç°å®ä¸–ç•ŒVQAåŸºå‡†ä¸Šæ˜¾è‘—ä¼˜äºç›‘ç£å¾®è°ƒ(SFT)å’Œç¨€ç–RLåŸºçº¿ï¼Œç”šè‡³è¶…è¶Šäº†GPT-4oçš„è¡¨ç°ã€‚è¿™ä¸€æˆæœå±•ç¤ºäº†å°†ç©ºé—´ç›‘ç£ä¸å¥–åŠ±å¯¹é½æ¨ç†ç›¸ç»“åˆï¼Œåœ¨æœ‰é™æ•°æ®ä¸‹æå‡æ¨¡å‹é²æ£’3Dç©ºé—´ç†è§£èƒ½åŠ›çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint. Accepted at NeurIPS 2025 Workshops on SPACE in Vision, Language, and Embodied AI (SpaVLE), Embodied World Models for Decision Making (EWM), Aligning Reinforcement Learning Experimentalists and Theorists (ARLET), and Scaling Environments for Agents (SEA)",
      "pdf_url": "https://arxiv.org/pdf/2511.07403v1",
      "published_date": "2025-11-10 18:52:47 UTC",
      "updated_date": "2025-11-10 18:52:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:52:47.864282+00:00"
    },
    {
      "arxiv_id": "2511.07392v3",
      "title": "Voice-Interactive Surgical Agent for Multimodal Patient Data Control",
      "title_zh": "é¢å‘å¤šæ¨¡æ€æ‚£è€…æ•°æ®æ§åˆ¶çš„è¯­éŸ³äº¤äº’æ‰‹æœ¯æ™ºèƒ½ä½“",
      "authors": [
        "Hyeryun Park",
        "Byung Mo Gu",
        "Jun Hee Lee",
        "Byeong Hyeon Choi",
        "Sekeun Kim",
        "Hyun Koo Kim",
        "Kyungsang Kim"
      ],
      "abstract": "In robotic surgery, surgeons fully engage their hands and visual attention in procedures, making it difficult to access and manipulate multimodal patient data without interrupting the workflow. To overcome this problem, we propose a Voice-Interactive Surgical Agent (VISA) built on a hierarchical multi-agent framework consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to interpret voice commands and execute tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models within surgical video. We construct a dataset of 240 user commands organized into hierarchical categories and introduce the Multi-level Orchestration Evaluation Metric (MOEM) that evaluates the performance and robustness at both the command and category levels. Experimental results demonstrate that VISA achieves high stage-level accuracy and workflow-level success rates, while also enhancing its robustness by correcting transcription errors, resolving linguistic ambiguity, and interpreting diverse free-form expressions. These findings highlight the strong potential of VISA to support robotic surgery and its scalability for integrating new functions and agents.",
      "tldr_zh": "é’ˆå¯¹æœºå™¨äººæ‰‹æœ¯ä¸­å¤–ç§‘åŒ»ç”Ÿå› æ‰‹çœ¼è¢«å®Œå…¨å ç”¨è€Œéš¾ä»¥åœ¨ä¸ä¸­æ–­å·¥ä½œæµçš„æƒ…å†µä¸‹è®¿é—®å¤šæ¨¡æ€æ‚£è€…æ•°æ®çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†Voice-Interactive Surgical Agent (VISA)ã€‚VISAå»ºç«‹åœ¨ç”±Large Language Models (LLMs)é©±åŠ¨çš„å±‚æ¬¡åŒ–å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¹‹ä¸Šï¼ŒåŒ…å«ä¸€ä¸ªç¼–æ’æ™ºèƒ½ä½“å’Œä¸‰ä¸ªç‰¹å®šä»»åŠ¡æ™ºèƒ½ä½“ï¼Œèƒ½å¤Ÿè‡ªä¸»è§„åˆ’ã€æ¨ç†å¹¶æ‰§è¡Œæ£€ç´¢ä¸´åºŠä¿¡æ¯ã€æ“ä½œCTæ‰«ææˆ–å¯¼èˆª3Dè§£å‰–æ¨¡å‹ç­‰ä»»åŠ¡ã€‚ç ”ç©¶æ„å»ºäº†åŒ…å«240ä¸ªç”¨æˆ·æŒ‡ä»¤çš„æ•°æ®é›†ï¼Œå¹¶å¼•å…¥äº†Multi-level Orchestration Evaluation Metric (MOEM)æ¥è¯„ä¼°æŒ‡ä»¤å’Œç±»åˆ«å±‚é¢çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVISAä¸ä»…å®ç°äº†è¾ƒé«˜çš„é˜¶æ®µçº§å‡†ç¡®ç‡å’Œå·¥ä½œæµçº§æˆåŠŸç‡ï¼Œè¿˜èƒ½é€šè¿‡ä¿®æ­£è½¬å½•é”™è¯¯ã€è§£å†³è¯­è¨€æ­§ä¹‰å’Œè§£é‡Šè‡ªç”±å½¢å¼è¡¨è¾¾æ¥å¢å¼ºé²æ£’æ€§ï¼Œå±•ç°äº†å…¶åœ¨æ”¯æŒæœºå™¨äººæ‰‹æœ¯åŠåŠŸèƒ½æ‰©å±•æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 13 figures, 3 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.07392v3",
      "published_date": "2025-11-10 18:47:24 UTC",
      "updated_date": "2025-12-17 21:32:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:53:11.005203+00:00"
    },
    {
      "arxiv_id": "2511.07384v1",
      "title": "Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence",
      "title_zh": "åˆ©ç”¨æ”¹è£…å¾ªç¯å¼•å¯¼é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹è¿›è¡Œæ·±åº¦æ€è€ƒ",
      "authors": [
        "Sean McLeish",
        "Ang Li",
        "John Kirchenbauer",
        "Dayal Singh Kalra",
        "Brian R. Bartoldson",
        "Bhavya Kailkhura",
        "Avi Schwarzschild",
        "Jonas Geiping",
        "Tom Goldstein",
        "Micah Goldblum"
      ],
      "abstract": "Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•å°†ç°æœ‰çš„é¢„è®­ç»ƒéé€’å½’è¯­è¨€æ¨¡å‹è½¬æ¢ä¸ºæ·±åº¦é€’å½’æ¨¡å‹(depth-recurrent models)ï¼Œä»¥åˆ©ç”¨é€’å½’è§£è€¦è®­ç»ƒè®¡ç®—é‡ä¸æµ‹è¯•è®¡ç®—é‡çš„ä¼˜åŠ¿ã€‚ä½œè€…æå‡ºä½¿ç”¨ä¸€ç§é€’å½’è¯¾ç¨‹(curriculum of recurrences)çš„æ–¹æ³•ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸å¢åŠ æ¨¡å‹çš„æœ‰æ•ˆæ·±åº¦ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™ç§æ–¹æ³•èƒ½å¤Ÿåœ¨é™ä½æ€»è®¡ç®—æˆæœ¬çš„åŒæ—¶ï¼Œæœ‰æ•ˆä¿æŒæ¨¡å‹çš„æ€§èƒ½ã€‚åœ¨æ•°å­¦ä»»åŠ¡çš„å®éªŒä¸­ï¼Œå°†é¢„è®­ç»ƒæ¨¡å‹è½¬æ¢ä¸ºé€’å½’æ¨¡å‹ï¼Œç›¸æ¯”äºç®€å•åœ°å¯¹åŸå§‹éé€’å½’æ¨¡å‹è¿›è¡Œåè®­ç»ƒ(post-training)ï¼Œåœ¨ç›¸åŒçš„è®¡ç®—é¢„ç®—ä¸‹è¡¨ç°å‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œé€šè¿‡æ”¹é€ ç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹å¼•å…¥é€’å½’æœºåˆ¶ï¼Œå¯ä»¥æœ‰æ•ˆåœ°æ•™å¯¼æ¨¡å‹è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æ€è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "code: https://github.com/mcleish7/retrofitting-recurrence, models: https://huggingface.co/collections/tomg-group-umd/retrofitting-recurrence",
      "pdf_url": "https://arxiv.org/pdf/2511.07384v1",
      "published_date": "2025-11-10 18:43:07 UTC",
      "updated_date": "2025-11-10 18:43:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:53:58.477577+00:00"
    },
    {
      "arxiv_id": "2511.07379v1",
      "title": "LoReTTA: A Low Resource Framework To Poison Continuous Time Dynamic Graphs",
      "title_zh": "LoReTTAï¼šé’ˆå¯¹è¿ç»­æ—¶é—´åŠ¨æ€å›¾çš„ä½èµ„æºæŠ•æ¯’æ¡†æ¶",
      "authors": [
        "Himanshu Pal",
        "Venkata Sai Pranav Bachina",
        "Ankit Gangwal",
        "Charu Sharma"
      ],
      "abstract": "Temporal Graph Neural Networks (TGNNs) are increasingly used in high-stakes domains, such as financial forecasting, recommendation systems, and fraud detection. However, their susceptibility to poisoning attacks poses a critical security risk. We introduce LoReTTA (Low Resource Two-phase Temporal Attack), a novel adversarial framework on Continuous-Time Dynamic Graphs, which degrades TGNN performance by an average of 29.47% across 4 widely benchmark datasets and 4 State-of-the-Art (SotA) models. LoReTTA operates through a two-stage approach: (1) sparsify the graph by removing high-impact edges using any of the 16 tested temporal importance metrics, (2) strategically replace removed edges with adversarial negatives via LoReTTA's novel degree-preserving negative sampling algorithm. Our plug-and-play design eliminates the need for expensive surrogate models while adhering to realistic unnoticeability constraints. LoReTTA degrades performance by upto 42.0% on MOOC, 31.5% on Wikipedia, 28.8% on UCI, and 15.6% on Enron. LoReTTA outperforms 11 attack baselines, remains undetectable to 4 leading anomaly detection systems, and is robust to 4 SotA adversarial defense training methods, establishing its effectiveness, unnoticeability, and robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†LoReTTAï¼ˆLow Resource Two-phase Temporal Attackï¼‰ï¼Œä¸€ç§é’ˆå¯¹è¿ç»­æ—¶é—´åŠ¨æ€å›¾ï¼ˆContinuous-Time Dynamic Graphsï¼‰çš„ä½èµ„æºå¯¹æŠ—æ€§æ”»å‡»æ¡†æ¶ï¼Œæ—¨åœ¨æ­ç¤ºæ—¶é—´å›¾ç¥ç»ç½‘ç»œï¼ˆTGNNsï¼‰åœ¨é‡‘èé¢„æµ‹å’Œæ¬ºè¯ˆæ£€æµ‹ç­‰é¢†åŸŸçš„å®‰å…¨æ¼æ´ã€‚LoReTTAé‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼šé¦–å…ˆåˆ©ç”¨æ—¶é—´é‡è¦æ€§æŒ‡æ ‡ç§»é™¤é«˜å½±å“åŠ›çš„è¾¹ä»¥ç¨€ç–åŒ–å›¾ç»“æ„ï¼Œéšåé€šè¿‡æ–°é¢–çš„åº¦ä¿æŒè´Ÿé‡‡æ ·ç®—æ³•ï¼ˆdegree-preserving negative samplingï¼‰ç­–ç•¥æ€§åœ°ç”¨å¯¹æŠ—æ€§è´Ÿæ ·æœ¬æ›¿æ¢è¿™äº›è¾¹ã€‚è¿™ç§å³æ’å³ç”¨çš„è®¾è®¡æ— éœ€æ˜‚è´µçš„ä»£ç†æ¨¡å‹ï¼ŒåŒæ—¶ç¬¦åˆç°å®åœºæ™¯ä¸­çš„ä¸å¯å¯Ÿè§‰æ€§çº¦æŸã€‚å®éªŒè¡¨æ˜ï¼ŒLoReTTAåœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†å’Œå››ç§SotAæ¨¡å‹ä¸Šå¹³å‡é™ä½äº†TGNN 29.47%çš„æ€§èƒ½ï¼Œä¼˜äº11ç§åŸºçº¿æ”»å‡»æ–¹æ³•ã€‚æ­¤å¤–ï¼ŒLoReTTAä¸ä»…èƒ½é¿å¼€å››ç§é¢†å…ˆå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿçš„æ£€æµ‹ï¼Œè¿˜å¯¹å››ç§å¯¹æŠ—æ€§é˜²å¾¡è®­ç»ƒæ–¹æ³•è¡¨ç°å‡ºé²æ£’æ€§ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€éšè”½æ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07379v1",
      "published_date": "2025-11-10 18:41:02 UTC",
      "updated_date": "2025-11-10 18:41:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:54:00.075527+00:00"
    },
    {
      "arxiv_id": "2511.07378v1",
      "title": "Transformers Provably Learn Chain-of-Thought Reasoning with Length Generalization",
      "title_zh": "Transformerå¯è¯æ˜åœ°å­¦ä¹ å…·å¤‡é•¿åº¦æ³›åŒ–èƒ½åŠ›çš„æ€ç»´é“¾æ¨ç†",
      "authors": [
        "Yu Huang",
        "Zixin Wen",
        "Aarti Singh",
        "Yuejie Chi",
        "Yuxin Chen"
      ],
      "abstract": "The ability to reason lies at the core of artificial intelligence (AI), and challenging problems usually call for deeper and longer reasoning to tackle. A crucial question about AI reasoning is whether models can extrapolate learned reasoning patterns to solve harder tasks with longer chain-of-thought (CoT). In this work, we present a theoretical analysis of transformers learning on synthetic state-tracking tasks with gradient descent. We mathematically prove how the algebraic structure of state-tracking problems governs the degree of extrapolation of the learned CoT. Specifically, our theory characterizes the length generalization of transformers through the mechanism of attention concentration, linking the retrieval robustness of the attention layer to the state-tracking task structure of long-context reasoning. Moreover, for transformers with limited reasoning length, we prove that a recursive self-training scheme can progressively extend the range of solvable problem lengths. To our knowledge, we provide the first optimization guarantee that constant-depth transformers provably learn $\\mathsf{NC}^1$-complete problems with CoT, significantly going beyond prior art confined in $\\mathsf{TC}^0$, unless the widely held conjecture $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$ fails. Finally, we present a broad set of experiments supporting our theoretical results, confirming the length generalization behaviors and the mechanism of attention concentration.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½æ¨ç†çš„æ ¸å¿ƒé—®é¢˜ï¼Œæ¢è®¨äº†æ¨¡å‹æ˜¯å¦èƒ½é€šè¿‡æ›´é•¿çš„æ€ç»´é“¾(Chain-of-Thought, CoT)å°†ä¹ å¾—çš„æ¨ç†æ¨¡å¼å¤–æ¨åˆ°æ›´éš¾çš„ä»»åŠ¡ä¸­ã€‚ä½œè€…åŸºäºæ¢¯åº¦ä¸‹é™è®­ç»ƒçš„Transformeråœ¨åˆæˆçŠ¶æ€è·Ÿè¸ªä»»åŠ¡ä¸Šçš„è¡¨ç°æå‡ºäº†ç›¸å…³çš„ç†è®ºåˆ†æï¼Œè¯æ˜äº†é—®é¢˜çš„ä»£æ•°ç»“æ„å¦‚ä½•å†³å®šCoTçš„å¤–æ¨ç¨‹åº¦ã€‚ç†è®ºé€šè¿‡â€œæ³¨æ„åŠ›é›†ä¸­â€(attention concentration)æœºåˆ¶åˆ»ç”»äº†Transformerçš„é•¿åº¦æ³›åŒ–èƒ½åŠ›ï¼Œå°†æ³¨æ„åŠ›å±‚çš„æ£€ç´¢é²æ£’æ€§ä¸é•¿ä¸Šä¸‹æ–‡æ¨ç†çš„ä»»åŠ¡ç»“æ„è”ç³»èµ·æ¥ã€‚æ­¤å¤–ï¼Œå¯¹äºæ¨ç†é•¿åº¦å—é™çš„Transformerï¼Œè®ºæ–‡è¯æ˜äº†é€’å½’è‡ªè®­ç»ƒ(recursive self-training)æ–¹æ¡ˆå¯ä»¥é€æ­¥æ‰©å±•å¯è§£é—®é¢˜çš„é•¿åº¦èŒƒå›´ã€‚è¯¥ç ”ç©¶æä¾›äº†é¦–ä¸ªä¼˜åŒ–ä¿è¯ï¼Œè¯æ˜æ’å®šæ·±åº¦çš„Transformerèƒ½å¤Ÿé€šè¿‡CoTå­¦ä¹ $\\mathsf{NC}^1$-completeé—®é¢˜ï¼Œæ˜¾è‘—è¶…è¶Šäº†æ­¤å‰å±€é™äº$\\mathsf{TC}^0$çš„ç ”ç©¶æˆæœã€‚æœ€åï¼Œå¹¿æ³›çš„å®éªŒç»“æœæ”¯æŒäº†è¿™äº›ç†è®ºå‘ç°ï¼ŒéªŒè¯äº†é•¿åº¦æ³›åŒ–è¡Œä¸ºåŠæ³¨æ„åŠ›é›†ä¸­æœºåˆ¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the full version of a paper published at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.07378v1",
      "published_date": "2025-11-10 18:40:24 UTC",
      "updated_date": "2025-11-10 18:40:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:55:21.817941+00:00"
    },
    {
      "arxiv_id": "2511.07377v1",
      "title": "Real-Time LiDAR Super-Resolution via Frequency-Aware Multi-Scale Fusion",
      "title_zh": "åŸºäºé¢‘ç‡æ„ŸçŸ¥å¤šå°ºåº¦èåˆçš„å®æ—¶ LiDAR è¶…åˆ†è¾¨ç‡",
      "authors": [
        "June Moh Goo",
        "Zichao Zeng",
        "Jan Boehm"
      ],
      "abstract": "LiDAR super-resolution addresses the challenge of achieving high-quality 3D perception from cost-effective, low-resolution sensors. While recent transformer-based approaches like TULIP show promise, they remain limited to spatial-domain processing with restricted receptive fields. We introduce FLASH (Frequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusion), a novel framework that overcomes these limitations through dual-domain processing. FLASH integrates two key innovations: (i) Frequency-Aware Window Attention that combines local spatial attention with global frequency-domain analysis via FFT, capturing both fine-grained geometry and periodic scanning patterns at log-linear complexity. (ii) Adaptive Multi-Scale Fusion that replaces conventional skip connections with learned position-specific feature aggregation, enhanced by CBAM attention for dynamic feature selection. Extensive experiments on KITTI demonstrate that FLASH achieves state-of-the-art performance across all evaluation metrics, surpassing even uncertainty-enhanced baselines that require multiple forward passes. Notably, FLASH outperforms TULIP with Monte Carlo Dropout while maintaining single-pass efficiency, which enables real-time deployment. The consistent superiority across all distance ranges validates that our dual-domain approach effectively handles uncertainty through architectural design rather than computationally expensive stochastic inference, making it practical for autonomous systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FLASHï¼ˆFrequency-aware LiDAR Adaptive Super-resolution with Hierarchical fusionï¼‰ï¼Œä¸€ç§æ—¨åœ¨è§£å†³ä½åˆ†è¾¨ç‡LiDARä¼ æ„Ÿå™¨é«˜è´¨é‡3Dæ„ŸçŸ¥éš¾é¢˜çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰åŸºäºTransformerçš„æ–¹æ³•ï¼ˆå¦‚TULIPï¼‰å—é™äºç©ºé—´åŸŸå¤„ç†å’Œæ„Ÿå—é‡çš„é—®é¢˜ï¼ŒFLASHé€šè¿‡åŒåŸŸå¤„ç†å…‹æœäº†è¿™äº›é™åˆ¶ã€‚è¯¥æ¡†æ¶é›†æˆäº†ä¸¤å¤§æ ¸å¿ƒåˆ›æ–°ï¼šä¸€æ˜¯é¢‘ç‡æ„ŸçŸ¥çª—å£æ³¨æ„åŠ›ï¼ˆFrequency-Aware Window Attentionï¼‰ï¼Œç»“åˆå±€éƒ¨ç©ºé—´æ³¨æ„åŠ›å’ŒåŸºäºFFTçš„å…¨å±€é¢‘åŸŸåˆ†æï¼Œä»¥å¯¹æ•°çº¿æ€§å¤æ‚åº¦æ•æ‰ç»†ç²’åº¦å‡ ä½•ä¸å‘¨æœŸæ€§æ‰«ææ¨¡å¼ï¼›äºŒæ˜¯è‡ªé€‚åº”å¤šå°ºåº¦èåˆï¼ˆAdaptive Multi-Scale Fusionï¼‰ï¼Œåˆ©ç”¨CBAMæ³¨æ„åŠ›å¢å¼ºçš„åŠ¨æ€ç‰¹å¾é€‰æ‹©æ›¿ä»£ä¼ ç»Ÿè·³è·ƒè¿æ¥ã€‚åœ¨KITTIæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒFLASHåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå‡å®ç°äº†æœ€å…ˆè¿›æ€§èƒ½ï¼ˆSOTAï¼‰ï¼Œç”šè‡³è¶…è¶Šäº†éœ€è¦å¤šæ¬¡å‰å‘ä¼ æ’­çš„ä¸ç¡®å®šæ€§å¢å¼ºåŸºçº¿ã€‚æ­¤å¤–ï¼ŒFLASHåœ¨ä¿æŒå•æ¬¡é€šè¿‡æ•ˆç‡çš„åŒæ—¶å®ç°äº†å®æ—¶éƒ¨ç½²èƒ½åŠ›ï¼Œè¯æ˜äº†å…¶é€šè¿‡æ¶æ„è®¾è®¡è€Œéæ˜‚è´µçš„éšæœºæ¨ç†æœ‰æ•ˆå¤„ç†ä¸ç¡®å®šæ€§çš„å®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07377v1",
      "published_date": "2025-11-10 18:38:15 UTC",
      "updated_date": "2025-11-10 18:38:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:55:22.822816+00:00"
    },
    {
      "arxiv_id": "2511.07505v1",
      "title": "FedRW: Efficient Privacy-Preserving Data Reweighting for Enhancing Federated Learning of Language Models",
      "title_zh": "FedRWï¼šå¢å¼ºè¯­è¨€æ¨¡å‹è”é‚¦å­¦ä¹ çš„é«˜æ•ˆéšç§ä¿æŠ¤æ•°æ®é‡åŠ æƒ",
      "authors": [
        "Pukang Ye",
        "Junwei Luo",
        "Xiaolei Dong",
        "Yunbo Yang"
      ],
      "abstract": "Data duplication within large-scale corpora often impedes large language models' (LLMs) performance and privacy. In privacy-concerned federated learning scenarios, conventional deduplication methods typically rely on trusted third parties to perform uniform deletion, risking loss of informative samples while introducing privacy vulnerabilities. To address these gaps, we propose Federated ReWeighting (FedRW), the first privacy-preserving framework, to the best of our knowledge, that performs soft deduplication via sample reweighting instead of deletion in federated LLM training, without assuming a trusted third party. At its core, FedRW proposes a secure, frequency-aware reweighting protocol through secure multi-party computation, coupled with a parallel orchestration strategy to ensure efficiency and scalability. During training, FedRW utilizes an adaptive reweighting mechanism with global sample frequencies to adjust individual loss contributions, effectively improving generalization and robustness. Empirical results demonstrate that FedRW outperforms the state-of-the-art method by achieving up to 28.78x speedup in preprocessing and approximately 11.42% improvement in perplexity, while offering enhanced security guarantees. FedRW thus establishes a new paradigm for managing duplication in federated LLM training.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FedRWï¼Œä¸€ç§æ—¨åœ¨å¢å¼ºè¯­è¨€æ¨¡å‹è”é‚¦å­¦ä¹ çš„é«˜æ•ˆéšç§ä¿æŠ¤æ•°æ®é‡åŠ æƒæ¡†æ¶ï¼Œä»¥è§£å†³å¤§è§„æ¨¡è¯­æ–™åº“ä¸­æ•°æ®é‡å¤å¯¼è‡´çš„æ€§èƒ½å’Œéšç§é—®é¢˜ã€‚é’ˆå¯¹ä¼ ç»Ÿå»é‡æ–¹æ³•ä¾èµ–å—ä¿¡ä»»ç¬¬ä¸‰æ–¹ä¸”å®¹æ˜“ä¸¢å¤±ä¿¡æ¯çš„å±€é™ï¼ŒFedRWä½œä¸ºé¦–ä¸ªä¸å‡è®¾å—ä¿¡ä»»ç¬¬ä¸‰æ–¹çš„éšç§ä¿æŠ¤æ¡†æ¶ï¼Œé€šè¿‡æ ·æœ¬é‡åŠ æƒï¼ˆsoft deduplicationï¼‰è€Œéç›´æ¥åˆ é™¤æ¥ä¼˜åŒ–è”é‚¦LLMè®­ç»ƒã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåœ¨äºåˆ©ç”¨å®‰å…¨å¤šæ–¹è®¡ç®—ï¼ˆSecure Multi-Party Computationï¼‰å®ç°å®‰å…¨çš„é¢‘ç‡æ„ŸçŸ¥é‡åŠ æƒåè®®ï¼Œå¹¶ç»“åˆå¹¶è¡Œç¼–æ’ç­–ç•¥ç¡®ä¿äº†ç³»ç»Ÿçš„æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒFedRWé‡‡ç”¨è‡ªé€‚åº”é‡åŠ æƒæœºåˆ¶ï¼Œæ ¹æ®å…¨å±€æ ·æœ¬é¢‘ç‡è°ƒæ•´ä¸ªä½“æŸå¤±è´¡çŒ®ï¼Œä»è€Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFedRWåœ¨é¢„å¤„ç†é€Ÿåº¦ä¸Šå®ç°äº†é«˜è¾¾28.78å€çš„åŠ é€Ÿï¼Œå¹¶å°†å›°æƒ‘åº¦ï¼ˆperplexityï¼‰æ”¹å–„äº†çº¦11.42%ï¼Œç¡®ç«‹äº†è”é‚¦LLMè®­ç»ƒä¸­ç®¡ç†æ•°æ®é‡å¤çš„æ–°èŒƒå¼ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at NeurIPS 2025. Code is available at https://github.com/Hecateto/FedRW",
      "pdf_url": "https://arxiv.org/pdf/2511.07505v1",
      "published_date": "2025-11-10 18:29:55 UTC",
      "updated_date": "2025-11-10 18:29:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:55:48.146037+00:00"
    },
    {
      "arxiv_id": "2511.07368v2",
      "title": "Post-Training as Reweighting: A Stochastic View of Reasoning Trajectories in Language Models",
      "title_zh": "åè®­ç»ƒå³é‡åŠ æƒï¼šè¯­è¨€æ¨¡å‹æ¨ç†è½¨è¿¹çš„éšæœºè§†è§’",
      "authors": [
        "Dake Bu",
        "Wei Huang",
        "Andi Han",
        "Atsushi Nitanda",
        "Bo Xue",
        "Qingfu Zhang",
        "Hau-San Wong",
        "Taiji Suzuki"
      ],
      "abstract": "Foundation models encode rich structural knowledge but often rely on post-training procedures to adapt their reasoning behavior to specific tasks. Popular approaches such as reinforcement learning with verifiable rewards (RLVR) and inference-time reward aggregation are typically analyzed from a performance perspective, leaving their effects on the underlying reasoning distribution less understood. In this work, we study post-training reasoning from a stochastic trajectory viewpoint. Following Kim et al. (2025), we model reasoning steps of varying difficulty as Markov transitions with different probabilities, and formalize reasoning processes using tree-structured Markov chains. Within this framework, pretraining corresponds to discovering the reasoning structure, while post-training primarily reweights existing chains of thought. We show that both RLVR and inference-time reward aggregation concentrate probability mass on a small number of high-probability trajectories, leading to the suppression of rare but essential reasoning paths. As a consequence, solving hard instances often depends on low-probability trajectories already present in the base model. We further prove that exploration-oriented mechanisms, such as rejecting easy instances and applying KL regularization, help preserve these rare trajectories. Empirical simulations support our theoretical analysis.",
      "tldr_zh": "è¿™é¡¹å·¥ä½œä»éšæœºè½¨è¿¹çš„è§†è§’ç ”ç©¶äº†è¯­è¨€æ¨¡å‹çš„åè®­ç»ƒ(Post-Training)æ¨ç†è¿‡ç¨‹ï¼Œå°†ä¸åŒéš¾åº¦çš„æ¨ç†æ­¥éª¤å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«è½¬ç§»(Markov transitions)ï¼Œå¹¶åˆ©ç”¨æ ‘çŠ¶é©¬å°”å¯å¤«é“¾(tree-structured Markov chains)å½¢å¼åŒ–æ¨ç†è¿‡ç¨‹ã€‚åœ¨æ­¤æ¡†æ¶ä¸‹ï¼Œé¢„è®­ç»ƒå¯¹åº”äºå‘ç°æ¨ç†ç»“æ„ï¼Œè€Œåè®­ç»ƒä¸»è¦æ˜¯åœ¨é‡æ–°åŠ æƒ(reweights)ç°æœ‰çš„æ€ç»´é“¾ã€‚ç ”ç©¶å‘ç°ï¼Œå¸¦æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ (RLVR)å’Œæ¨ç†æ—¶å¥–åŠ±èšåˆ(inference-time reward aggregation)å€¾å‘äºå°†æ¦‚ç‡è´¨é‡é›†ä¸­åœ¨å°‘æ•°é«˜æ¦‚ç‡è½¨è¿¹ä¸Šï¼Œä»è€ŒæŠ‘åˆ¶äº†ç¨€æœ‰ä½†å¯¹è§£å†³å›°éš¾å®ä¾‹è‡³å…³é‡è¦çš„æ¨ç†è·¯å¾„ã€‚ä½œè€…è¯æ˜äº†ä»¥æ¢ç´¢ä¸ºå¯¼å‘çš„æœºåˆ¶ï¼Œä¾‹å¦‚æ‹’ç»ç®€å•å®ä¾‹å’Œåº”ç”¨KLæ­£åˆ™åŒ–(KL regularization)ï¼Œæœ‰åŠ©äºä¿ç•™è¿™äº›ç¨€æœ‰è½¨è¿¹ï¼Œå¹¶é€šè¿‡ç»éªŒæ¨¡æ‹ŸéªŒè¯äº†è¿™ä¸€ç†è®ºåˆ†æã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07368v2",
      "published_date": "2025-11-10 18:25:26 UTC",
      "updated_date": "2026-01-17 17:52:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:58:59.020281+00:00"
    },
    {
      "arxiv_id": "2511.07367v1",
      "title": "Machine-Learning Accelerated Calculations of Reduced Density Matrices",
      "title_zh": "æœºå™¨å­¦ä¹ åŠ é€Ÿçº¦åŒ–å¯†åº¦çŸ©é˜µè®¡ç®—",
      "authors": [
        "Awwab A. Azam",
        "Lexu Zhao",
        "Jiabin Yu"
      ],
      "abstract": "$n$-particle reduced density matrices ($n$-RDMs) play a central role in understanding correlated phases of matter. Yet the calculation of $n$-RDMs is often computationally inefficient for strongly-correlated states, particularly when the system sizes are large. In this work, we propose to use neural network (NN) architectures to accelerate the calculation of, and even predict, the $n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are often smooth functions over the Brillouin zone (BZ) (certainly true for gapped states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs to predict large-size ones. Building on this intuition, we devise two NNs: (i) a self-attention NN that maps random RDMs to physical ones, and (ii) a Sinusoidal Representation Network (SIREN) that directly maps momentum-space coordinates to RDM values. We test the NNs in three 2D models: the pair-pair correlation functions of the Richardson model of superconductivity, the translationally-invariant 1-RDM in a four-band model with short-range repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model. We find that a SIREN trained on a $6\\times 6$ momentum mesh can predict the $18\\times 18$ pair-pair correlation function with a relative accuracy of $0.839$. The NNs trained on $6\\times 6 \\sim 8\\times 8$ meshes can provide high-quality initial guesses for $50\\times 50$ translation-invariant Hartree-Fock (HF) and $30\\times 30$ fully translation-breaking-allowed HF, reducing the number of iterations required for convergence by up to $91.63\\%$ and $92.78\\%$, respectively, compared to random initializations. Our results illustrate the potential of using NN-based methods for interpolable $n$-RDMs, which might open a new avenue for future research on strongly correlated phases.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºåˆ©ç”¨ç¥ç»ç½‘ç»œ(NN)æ¶æ„æ¥åŠ é€Ÿè®¡ç®—ç”šè‡³é¢„æµ‹å¤§å°ºå¯¸ç³»ç»Ÿçš„$n$-ç²’å­çº¦åŒ–å¯†åº¦çŸ©é˜µ($n$-RDMs)ï¼Œæ—¨åœ¨è§£å†³å¼ºå…³è”æ€è®¡ç®—æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ã€‚åŸºäº$n$-RDMsåœ¨å¸ƒé‡Œæ¸ŠåŒº(Brillouin zone)é€šå¸¸æ˜¯å¹³æ»‘ä¸”å¯æ’å€¼çš„ç›´è§‰ï¼Œä½œè€…è®¾è®¡äº†ä¸¤ç§ç¥ç»ç½‘ç»œï¼šä¸€ç§å°†éšæœºRDMsæ˜ å°„åˆ°ç‰©ç†RDMsçš„è‡ªæ³¨æ„åŠ›(self-attention)ç½‘ç»œï¼Œä»¥åŠä¸€ç§ç›´æ¥å°†åŠ¨é‡ç©ºé—´åæ ‡æ˜ å°„åˆ°RDMå€¼çš„æ­£å¼¦è¡¨ç¤ºç½‘ç»œ(SIREN)ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨Richardsonè¶…å¯¼æ¨¡å‹ã€å››èƒ½å¸¦æ¨¡å‹å’ŒåŠå¡«å……Hubbardæ¨¡å‹è¿™ä¸‰ç§2Dæ¨¡å‹ä¸­æµ‹è¯•äº†è¿™äº›ç½‘ç»œã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨$6\\times 6$åŠ¨é‡ç½‘æ ¼ä¸Šè®­ç»ƒçš„SIRENèƒ½ä»¥0.839çš„ç›¸å¯¹ç²¾åº¦é¢„æµ‹$18\\times 18$çš„é…å¯¹å…³è”å‡½æ•°ã€‚æ­¤å¤–ï¼Œåœ¨å°å°ºå¯¸ç½‘æ ¼ä¸Šè®­ç»ƒçš„ç¥ç»ç½‘ç»œèƒ½ä¸ºå¤§å°ºå¯¸Hartree-Fock (HF)è®¡ç®—æä¾›é«˜è´¨é‡çš„åˆå§‹çŒœæµ‹ï¼Œä¸éšæœºåˆå§‹åŒ–ç›¸æ¯”ï¼Œæ‰€éœ€çš„æ”¶æ•›è¿­ä»£æ¬¡æ•°åˆ†åˆ«å‡å°‘äº†é«˜è¾¾91.63%å’Œ92.78%ã€‚è¯¥æˆæœå±•ç¤ºäº†åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•åœ¨å¤„ç†å¯æ’å€¼$n$-RDMsæ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºå¼ºå…³è”ç›¸çš„æœªæ¥ç ”ç©¶å¼€è¾Ÿäº†æ–°é€”å¾„ã€‚",
      "categories": [
        "cond-mat.str-el",
        "cs.AI"
      ],
      "primary_category": "cond-mat.str-el",
      "comment": "10+32 pages, 6+4 figures, 1+6 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.07367v1",
      "published_date": "2025-11-10 18:23:34 UTC",
      "updated_date": "2025-11-10 18:23:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:59:22.952024+00:00"
    },
    {
      "arxiv_id": "2511.07364v1",
      "title": "Self-Evaluating LLMs for Multi-Step Tasks: Stepwise Confidence Estimation for Failure Detection",
      "title_zh": "é¢å‘å¤šæ­¥ä»»åŠ¡çš„è‡ªæˆ‘è¯„ä¼° LLMï¼šç”¨äºå¤±æ•ˆæ£€æµ‹çš„åˆ†æ­¥ç½®ä¿¡åº¦ä¼°è®¡",
      "authors": [
        "Vaibhav Mavi",
        "Shubh Jaroria",
        "Weiqi Sun"
      ],
      "abstract": "Reliability and failure detection of large language models (LLMs) is critical for their deployment in high-stakes, multi-step reasoning tasks. Prior work explores confidence estimation for self-evaluating LLM-scorer systems, with confidence scorers estimating the likelihood of errors in LLM responses. However, most methods focus on single-step outputs and overlook the challenges of multi-step reasoning. In this work, we extend self-evaluation techniques to multi-step tasks, testing two intuitive approaches: holistic scoring and step-by-step scoring. Using two multi-step benchmark datasets, we show that stepwise evaluation generally outperforms holistic scoring in detecting potential errors, with up to 15% relative increase in AUC-ROC. Our findings demonstrate that self-evaluating LLM systems provide meaningful confidence estimates in complex reasoning, improving their trustworthiness and providing a practical framework for failure detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨é«˜é£é™©å¤šæ­¥æ¨ç†ä»»åŠ¡ä¸­çš„éƒ¨ç½²ï¼Œæ¢è®¨äº†å…¶å¯é æ€§å’Œæ•…éšœæ£€æµ‹é—®é¢˜ã€‚å°½ç®¡å…ˆå‰çš„ç ”ç©¶æ¢ç´¢äº†LLMè¯„åˆ†ç³»ç»Ÿçš„ç½®ä¿¡åº¦ä¼°è®¡ï¼Œä½†å¤§å¤šå±€é™äºå•æ­¥è¾“å‡ºï¼Œå¿½è§†äº†å¤šæ­¥æ¨ç†çš„å¤æ‚æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…å°†è‡ªæˆ‘è¯„ä¼°æŠ€æœ¯æ‰©å±•è‡³å¤šæ­¥ä»»åŠ¡ï¼Œå¹¶å¯¹æ¯”äº†æ•´ä½“è¯„åˆ†ï¼ˆholistic scoringï¼‰ä¸é€æ­¥è¯„åˆ†ï¼ˆstep-by-step scoringï¼‰ä¸¤ç§ç›´è§‚æ–¹æ³•ã€‚åŸºäºä¸¤ä¸ªå¤šæ­¥åŸºå‡†æ•°æ®é›†çš„å®éªŒè¡¨æ˜ï¼Œé€æ­¥è¯„ä¼°åœ¨æ£€æµ‹æ½œåœ¨é”™è¯¯æ–¹é¢æ™®éä¼˜äºæ•´ä½“è¯„åˆ†ï¼Œå…¶AUC-ROCç›¸å¯¹æå‡é«˜è¾¾15%ã€‚ç ”ç©¶ç»“æœè¯å®ï¼Œè‡ªæˆ‘è¯„ä¼°LLMç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤æ‚æ¨ç†ä¸­æä¾›æœ‰æ„ä¹‰çš„ç½®ä¿¡åº¦ä¼°è®¡ï¼Œä»è€Œæå‡ç³»ç»Ÿçš„å¯ä¿¡åº¦å¹¶ä¸ºæ•…éšœæ£€æµ‹æä¾›äº†å®ç”¨çš„æ¡†æ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2025 Workshop on Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling",
      "pdf_url": "https://arxiv.org/pdf/2511.07364v1",
      "published_date": "2025-11-10 18:19:51 UTC",
      "updated_date": "2025-11-10 18:19:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T19:59:43.882978+00:00"
    },
    {
      "arxiv_id": "2511.07362v1",
      "title": "Inference-Time Scaling of Diffusion Models for Infrared Data Generation",
      "title_zh": "é¢å‘çº¢å¤–æ•°æ®ç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹æ¨ç†æ—¶æ‰©å±•",
      "authors": [
        "Kai A. Horstmann",
        "Maxim Clouser",
        "Kia Khezeli"
      ],
      "abstract": "Infrared imagery enables temperature-based scene understanding using passive sensors, particularly under conditions of low visibility where traditional RGB imaging fails. Yet, developing downstream vision models for infrared applications is hindered by the scarcity of high-quality annotated data, due to the specialized expertise required for infrared annotation. While synthetic infrared image generation has the potential to accelerate model development by providing large-scale, diverse training data, training foundation-level generative diffusion models in the infrared domain has remained elusive due to limited datasets. In light of such data constraints, we explore an inference-time scaling approach using a domain-adapted CLIP-based verifier for enhanced infrared image generation quality. We adapt FLUX.1-dev, a state-of-the-art text-to-image diffusion model, to the infrared domain by finetuning it on a small sample of infrared images using parameter-efficient techniques. The trained verifier is then employed during inference to guide the diffusion sampling process toward higher quality infrared generations that better align with input text prompts. Empirically, we find that our approach leads to consistent improvements in generation quality, reducing FID scores on the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared to unguided baseline samples. Our results suggest that inference-time guidance offers a promising direction for bridging the domain gap in low-data infrared settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹çº¢å¤–å›¾åƒé¢†åŸŸé«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºã€éš¾ä»¥è®­ç»ƒåŸºç¡€ç”Ÿæˆå¼æ‰©æ•£æ¨¡å‹çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨Inference-Time Scalingï¼ˆæ¨ç†æ—¶æ‰©å±•ï¼‰çš„æ–¹æ³•æ¥å¢å¼ºçº¢å¤–å›¾åƒç”Ÿæˆè´¨é‡ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å‚æ•°é«˜æ•ˆæŠ€æœ¯åœ¨å°‘é‡çº¢å¤–å›¾åƒæ ·æœ¬ä¸Šå¾®è°ƒäº†å…ˆè¿›çš„æ–‡ç”Ÿå›¾æ¨¡å‹FLUX.1-devï¼Œä½¿å…¶é€‚åº”çº¢å¤–é¢†åŸŸã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œå¼•å…¥äº†ä¸€ä¸ªé¢†åŸŸé€‚é…çš„CLIP-based verifierï¼ˆåŸºäºCLIPçš„éªŒè¯å™¨ï¼‰ï¼Œåœ¨æ¨ç†é˜¶æ®µæŒ‡å¯¼æ‰©æ•£é‡‡æ ·è¿‡ç¨‹ï¼Œä»¥ç”Ÿæˆè´¨é‡æ›´é«˜ä¸”ä¸æ–‡æœ¬æç¤ºæ›´å¯¹é½çš„çº¢å¤–å›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—æå‡äº†ç”Ÿæˆè´¨é‡ï¼Œåœ¨KAIST Multispectral Pedestrian Detection Benchmarkæ•°æ®é›†ä¸Šï¼Œç›¸æ¯”æ— æŒ‡å¯¼çš„åŸºçº¿æ ·æœ¬ï¼ŒFIDåˆ†æ•°é™ä½äº†10%ã€‚è¿™ä¸€å‘ç°è¡¨æ˜ï¼Œæ¨ç†æ—¶æŒ‡å¯¼ï¼ˆinference-time guidanceï¼‰æ˜¯è§£å†³ä½æ•°æ®é‡çº¢å¤–åœºæ™¯ä¸‹é¢†åŸŸå·®è·çš„ä¸€ä¸ªæœ‰å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Peer-reviewed workshop paper",
      "pdf_url": "https://arxiv.org/pdf/2511.07362v1",
      "published_date": "2025-11-10 18:18:38 UTC",
      "updated_date": "2025-11-10 18:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:00:11.008708+00:00"
    },
    {
      "arxiv_id": "2511.07343v1",
      "title": "TNT: Improving Chunkwise Training for Test-Time Memorization",
      "title_zh": "TNTï¼šæ”¹è¿›æµ‹è¯•æ—¶è®°å¿†çš„åˆ†å—è®­ç»ƒ",
      "authors": [
        "Zeman Li",
        "Ali Behrouz",
        "Yuan Deng",
        "Peilin Zhong",
        "Praneeth Kacham",
        "Mahdi Karami",
        "Meisam Razaviyayn",
        "Vahab Mirrokni"
      ],
      "abstract": "Recurrent neural networks (RNNs) with deep test-time memorization modules, such as Titans and TTT, represent a promising, linearly-scaling paradigm distinct from Transformers. While these expressive models do not yet match the peak performance of state-of-the-art Transformers, their potential has been largely untapped due to prohibitively slow training and low hardware utilization. Existing parallelization methods force a fundamental conflict governed by the chunksize hyperparameter: large chunks boost speed but degrade performance, necessitating a fixed, suboptimal compromise. To solve this challenge, we introduce TNT, a novel training paradigm that decouples training efficiency from inference performance through a two-stage process. Stage one is an efficiency-focused pre-training phase utilizing a hierarchical memory. A global module processes large, hardware-friendly chunks for long-range context, while multiple parallel local modules handle fine-grained details. Crucially, by periodically resetting local memory states, we break sequential dependencies to enable massive context parallelization. Stage two is a brief fine-tuning phase where only the local memory modules are adapted to a smaller, high-resolution chunksize, maximizing accuracy with minimal overhead. Evaluated on Titans and TTT models, TNT achieves a substantial acceleration in training speed-up to 17 times faster than the most accurate baseline configuration - while simultaneously improving model accuracy. This improvement removes a critical scalability barrier, establishing a practical foundation for developing expressive RNNs and facilitating future work to close the performance gap with Transformers.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…·æœ‰æ·±åº¦æµ‹è¯•æ—¶è®°å¿†æ¨¡å—çš„å¾ªç¯ç¥ç»ç½‘ç»œ(RNNs)ï¼Œå¦‚Titanså’ŒTTTï¼Œè§£å†³äº†å…¶è®­ç»ƒé€Ÿåº¦æ…¢å’Œç¡¬ä»¶åˆ©ç”¨ç‡ä½çš„é—®é¢˜ã€‚ç°æœ‰çš„å¹¶è¡ŒåŒ–æ–¹æ³•å—é™äºchunksizeè¶…å‚æ•°çš„å†²çªï¼Œå³å¤§å—èƒ½æå‡é€Ÿåº¦ä½†é™ä½æ€§èƒ½ï¼Œåä¹‹äº¦ç„¶ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†TNTï¼Œä¸€ç§é€šè¿‡ä¸¤é˜¶æ®µè¿‡ç¨‹è§£è€¦è®­ç»ƒæ•ˆç‡ä¸æ¨ç†æ€§èƒ½çš„æ–°å‹è®­ç»ƒèŒƒå¼ã€‚ç¬¬ä¸€é˜¶æ®µåˆ©ç”¨åˆ†å±‚è®°å¿†è¿›è¡Œé«˜æ•ˆé¢„è®­ç»ƒï¼Œé€šè¿‡å‘¨æœŸæ€§é‡ç½®å±€éƒ¨è®°å¿†çŠ¶æ€æ‰“ç ´åºåˆ—ä¾èµ–ï¼Œä»è€Œå®ç°å¤§è§„æ¨¡ä¸Šä¸‹æ–‡å¹¶è¡ŒåŒ–ï¼›ç¬¬äºŒé˜¶æ®µåˆ™è¿›è¡Œç®€çŸ­å¾®è°ƒï¼Œå°†å±€éƒ¨è®°å¿†æ¨¡å—é€‚é…è‡³æ›´å°çš„é«˜åˆ†è¾¨ç‡chunksizeä»¥æœ€å¤§åŒ–å‡†ç¡®æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨Titanså’ŒTTTæ¨¡å‹ä¸Šï¼ŒTNTåœ¨æå‡æ¨¡å‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œå®ç°äº†é«˜è¾¾17å€çš„è®­ç»ƒåŠ é€Ÿã€‚è¿™ä¸€æ”¹è¿›æ¶ˆé™¤äº†å…³é”®çš„å¯æ‰©å±•æ€§éšœç¢ï¼Œä¸ºå¼€å‘è¡¨ç°åŠ›å¼ºçš„RNNså¹¶ç¼©å°å…¶ä¸Transformersçš„æ€§èƒ½å·®è·å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07343v1",
      "published_date": "2025-11-10 17:45:09 UTC",
      "updated_date": "2025-11-10 17:45:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:00:36.466832+00:00"
    },
    {
      "arxiv_id": "2511.07338v3",
      "title": "DeepPersona: A Generative Engine for Scaling Deep Synthetic Personas",
      "title_zh": "DeepPersonaï¼šæ·±åº¦åˆæˆäººæ ¼è§„æ¨¡åŒ–ç”Ÿæˆå¼å¼•æ“",
      "authors": [
        "Zhen Wang",
        "Yufan Zhou",
        "Zhongyan Luo",
        "Lyumanshan Ye",
        "Adam Wood",
        "Man Yao",
        "Saab Mansour",
        "Luoshang Pan"
      ],
      "abstract": "Simulating human profiles by instilling personas into large language models (LLMs) is rapidly transforming research in agentic behavioral simulation, LLM personalization, and human-AI alignment. However, most existing synthetic personas remain shallow and simplistic, capturing minimal attributes and failing to reflect the rich complexity and diversity of real human identities. We introduce DEEPPERSONA, a scalable generative engine for synthesizing narrative-complete synthetic personas through a two-stage, taxonomy-guided method. First, we algorithmically construct the largest-ever human-attribute taxonomy, comprising over hundreds of hierarchically organized attributes, by mining thousands of real user-ChatGPT conversations. Second, we progressively sample attributes from this taxonomy, conditionally generating coherent and realistic personas that average hundreds of structured attributes and roughly 1 MB of narrative text, two orders of magnitude deeper than prior works. Intrinsic evaluations confirm significant improvements in attribute diversity (32 percent higher coverage) and profile uniqueness (44 percent greater) compared to state-of-the-art baselines. Extrinsically, our personas enhance GPT-4.1-mini's personalized question answering accuracy by 11.6 percent on average across ten metrics and substantially narrow (by 31.7 percent) the gap between simulated LLM citizens and authentic human responses in social surveys. Our generated national citizens reduced the performance gap on the Big Five personality test by 17 percent relative to LLM-simulated citizens. DEEPPERSONA thus provides a rigorous, scalable, and privacy-free platform for high-fidelity human simulation and personalized AI research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DEEPPERSONAï¼Œä¸€ç§ç”¨äºæ„å»ºå™äº‹å®Œæ•´å‹åˆæˆè§’è‰²çš„å¯æ‰©å±•ç”Ÿæˆå¼•æ“ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„åˆæˆè§’è‰²è¿‡äºæµ…æ˜¾ã€æ— æ³•åæ˜ çœŸå®äººç±»å¤æ‚æ€§çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é‡‡ç”¨ä¸¤é˜¶æ®µåˆ†ç±»å¼•å¯¼ç­–ç•¥ï¼šé¦–å…ˆé€šè¿‡æŒ–æ˜æ•°åƒä¸ªçœŸå®ç”¨æˆ·ä¸ChatGPTçš„å¯¹è¯ï¼Œç®—æ³•åŒ–æ„å»ºäº†åŒ…å«æ•°ç™¾ä¸ªå±‚çº§å±æ€§çš„æœ€å¤§è§„æ¨¡äººç±»å±æ€§åˆ†ç±»ä½“ç³»ï¼›å…¶æ¬¡ï¼Œä»è¯¥åˆ†ç±»ä½“ç³»ä¸­é€æ­¥é‡‡æ ·å±æ€§ï¼Œæ¡ä»¶ç”Ÿæˆè¿è´¯ä¸”é€¼çœŸçš„è§’è‰²ï¼Œå…¶åŒ…å«çš„ç»“æ„åŒ–å±æ€§å’Œå™äº‹æ–‡æœ¬æ·±åº¦æ¯”ä»¥å¾€å·¥ä½œé«˜å‡ºä¸¤ä¸ªæ•°é‡çº§ã€‚å†…åœ¨è¯„ä¼°æ˜¾ç¤ºï¼Œä¸æœ€å…ˆè¿›çš„åŸºçº¿ç›¸æ¯”ï¼ŒDEEPPERSONAåœ¨å±æ€§å¤šæ ·æ€§ä¸Šæé«˜äº†32%ï¼Œåœ¨æ¡£æ¡ˆå”¯ä¸€æ€§ä¸Šæé«˜äº†44%ã€‚å¤–åœ¨è¯„ä¼°è¡¨æ˜ï¼Œè¯¥ç”Ÿæˆçš„è§’è‰²ä½¿GPT-4.1-miniåœ¨ä¸ªæ€§åŒ–é—®ç­”ä»»åŠ¡ä¸Šçš„å‡†ç¡®ç‡å¹³å‡æé«˜äº†11.6%ï¼Œå¹¶æ˜¾è‘—ç¼©å°äº†LLMæ¨¡æ‹Ÿå…¬æ°‘ä¸çœŸå®äººç±»åœ¨ç¤¾ä¼šè°ƒæŸ¥å›å¤ä¸­çš„å·®è·ï¼ˆç¼©å°31.7%ï¼‰ã€‚æ­¤å¤–ï¼Œç”Ÿæˆçš„å›½å®¶å…¬æ°‘åœ¨Big Fiveäººæ ¼æµ‹è¯•ä¸­å°†æ€§èƒ½å·®è·ç¼©å°äº†17%ï¼Œä¸ºé«˜ä¿çœŸäººç±»æ¨¡æ‹Ÿå’Œä¸ªæ€§åŒ–AIç ”ç©¶æä¾›äº†ä¸€ä¸ªä¸¥è°¨ã€å¯æ‰©å±•ä¸”æ— éšç§é¡¾è™‘çš„å¹³å°ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "add an author[Update], 12 pages, 5 figures, accepted at LAW 2025 Workshop (NeurIPS 2025) Project page: https://deeppersona-ai.github.io/",
      "pdf_url": "https://arxiv.org/pdf/2511.07338v3",
      "published_date": "2025-11-10 17:37:56 UTC",
      "updated_date": "2025-11-30 20:05:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:01:37.803804+00:00"
    },
    {
      "arxiv_id": "2511.07332v1",
      "title": "Grounding Computer Use Agents on Human Demonstrations",
      "title_zh": "åŸºäºäººç±»æ¼”ç¤ºçš„è®¡ç®—æœºæ“ä½œæ™ºèƒ½ä½“å®šä½",
      "authors": [
        "Aarash Feizi",
        "Shravan Nayak",
        "Xiangru Jian",
        "Kevin Qinghong Lin",
        "Kaixin Li",
        "Rabiul Awal",
        "Xing Han LÃ¹",
        "Johan Obando-Ceron",
        "Juan A. Rodriguez",
        "Nicolas Chapados",
        "David Vazquez",
        "Adriana Romero-Soriano",
        "Reihaneh Rabbany",
        "Perouz Taslakian",
        "Christopher Pal",
        "Spandana Gella",
        "Sai Rajeswar"
      ],
      "abstract": "Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¡Œé¢ç¯å¢ƒç¼ºä¹é«˜è´¨é‡Groundingèµ„æºçš„é—®é¢˜ï¼Œæ¨å‡ºäº†GroundCUAï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºä¸“å®¶äººç±»æ¼”ç¤ºçš„å¤§è§„æ¨¡æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†æ¶µç›–12ä¸ªç±»åˆ«çš„87ä¸ªåº”ç”¨ç¨‹åºï¼ŒåŒ…å«5.6ä¸‡å¼ æˆªå›¾å’Œè¶…è¿‡356ä¸‡ä¸ªç»è¿‡äººå·¥éªŒè¯çš„å±å¹•å…ƒç´ æ ‡æ³¨ï¼Œèƒ½å¤Ÿç”Ÿæˆæ•æ‰å¹¿æ³›ç°å®ä¸–ç•Œä»»åŠ¡çš„å¤šæ ·åŒ–æŒ‡ä»¤ã€‚åŸºäºæ­¤æ•°æ®é›†ï¼Œä½œè€…å¼€å‘äº†GroundNextç³»åˆ—æ¨¡å‹ï¼ˆ3Bå’Œ7Bè§„æ¨¡ï¼‰ï¼Œç”¨äºå°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤å‡†ç¡®æ˜ å°„åˆ°ç›®æ ‡UIå…ƒç´ ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ŒGroundNextåœ¨ä»…ä½¿ç”¨ä¸åˆ°å…ˆå‰å·¥ä½œååˆ†ä¹‹ä¸€è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›æ°´å¹³ï¼ˆSOTAï¼‰ã€‚æ­¤å¤–ï¼Œå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰åè®­ç»ƒè¿›ä¸€æ­¥æå‡äº†æ¨¡å‹æ€§èƒ½ï¼Œåœ¨OSWorldåŸºå‡†æµ‹è¯•ä¸­ç»“åˆo3ä½œä¸ºè§„åˆ’å™¨æ—¶ï¼Œå…¶è¡¨ç°ä¼˜äºæˆ–åª²ç¾ä½¿ç”¨æµ·é‡æ•°æ®è®­ç»ƒçš„æ¨¡å‹ã€‚è¿™äº›å‘ç°æœ‰åŠ›è¯æ˜äº†é«˜è´¨é‡ã€ä¸“å®¶é©±åŠ¨çš„æ•°æ®é›†å¯¹äºæ¨è¿›é€šç”¨è®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“ï¼ˆComputer Use Agentsï¼‰å‘å±•çš„å…³é”®ä½œç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07332v1",
      "published_date": "2025-11-10 17:35:21 UTC",
      "updated_date": "2025-11-10 17:35:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:02:08.478625+00:00"
    },
    {
      "arxiv_id": "2511.07327v1",
      "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction",
      "title_zh": "IterResearchï¼šåŸºäºé©¬å°”å¯å¤«çŠ¶æ€é‡æ„çš„é•¿ç¨‹æ™ºèƒ½ä½“å†æ¢",
      "authors": [
        "Guoxin Chen",
        "Zile Qiao",
        "Xuanzhong Chen",
        "Donglei Yu",
        "Haotian Xu",
        "Wayne Xin Zhao",
        "Ruihua Song",
        "Wenbiao Yin",
        "Huifeng Yin",
        "Liwen Zhang",
        "Kuan Li",
        "Minpeng Liao",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Jingren Zhou"
      ],
      "abstract": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“åœ¨é•¿è§†è·ä»»åŠ¡ä¸­å› å•ä¸€ä¸Šä¸‹æ–‡çª—å£å¯¼è‡´çš„ä¸Šä¸‹æ–‡çª’æ¯å’Œå™ªå£°æ±¡æŸ“é—®é¢˜ï¼Œæå‡ºäº†IterResearchï¼Œä¸€ç§é€šè¿‡é©¬å°”å¯å¤«çŠ¶æ€é‡æ„é‡æ–°æ€è€ƒé•¿è§†è·æ™ºèƒ½ä½“çš„è¿­ä»£èŒƒå¼ã€‚è¯¥æ–¹æ³•å°†é•¿è§†è·ç ”ç©¶é‡æ–°è¡¨è¿°ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Markov Decision Process)ï¼Œé€šè¿‡ç»´æŠ¤ä¸æ–­æ¼”è¿›çš„æŠ¥å‘Šä½œä¸ºè®°å¿†å¹¶å®šæœŸç»¼åˆè§è§£ï¼Œä»è€Œåœ¨ä»»æ„æ¢ç´¢æ·±åº¦ä¸‹ä¿æŒä¸€è‡´çš„æ¨ç†èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿè¿›ä¸€æ­¥å¼€å‘äº†æ•ˆç‡æ„ŸçŸ¥ç­–ç•¥ä¼˜åŒ–(Efficiency-Aware Policy Optimization, EAPO)ï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œé€šè¿‡å‡ ä½•å¥–åŠ±æŠ˜æ‰£æ¿€åŠ±é«˜æ•ˆæ¢ç´¢ï¼Œå¹¶é€šè¿‡è‡ªé€‚åº”ä¸‹é‡‡æ ·å®ç°ç¨³å®šçš„åˆ†å¸ƒå¼è®­ç»ƒã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒIterResearchåœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸­æ¯”ç°æœ‰çš„å¼€æºæ™ºèƒ½ä½“å¹³å‡æé«˜äº†14.5ä¸ªç™¾åˆ†ç‚¹ï¼Œç¼©å°äº†ä¸å‰æ²¿ä¸“æœ‰ç³»ç»Ÿçš„å·®è·ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè¯¥èŒƒå¼å±•ç¤ºäº†å‰æ‰€æœªæœ‰çš„äº¤äº’æ‰©å±•èƒ½åŠ›ï¼Œåœ¨æ‰©å±•è‡³2048æ¬¡äº¤äº’æ—¶ï¼Œæ€§èƒ½ä»3.5%æ˜¾è‘—æå‡è‡³42.5%ã€‚æ­¤å¤–ï¼Œä½œä¸ºä¸€ç§æœ‰æ•ˆçš„æç¤ºç­–ç•¥ï¼Œå®ƒåœ¨é•¿è§†è·ä»»åŠ¡ä¸Šä½¿å‰æ²¿æ¨¡å‹çš„è¡¨ç°æ¯”ReActæé«˜äº†19.2ä¸ªç™¾åˆ†ç‚¹ï¼Œè¯æ˜äº†å…¶ä½œä¸ºè®­ç»ƒæ™ºèƒ½ä½“å’Œæç¤ºèŒƒå¼çš„é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "https://github.com/Alibaba-NLP/DeepResearch",
      "pdf_url": "https://arxiv.org/pdf/2511.07327v1",
      "published_date": "2025-11-10 17:30:08 UTC",
      "updated_date": "2025-11-10 17:30:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:02:20.148861+00:00"
    },
    {
      "arxiv_id": "2511.07322v2",
      "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation",
      "title_zh": "FinRptï¼šé¢å‘æƒç›Šç ”ç©¶æŠ¥å‘Šç”Ÿæˆçš„æ•°æ®é›†ã€è¯„ä¼°ç³»ç»ŸåŠåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Song Jin",
        "Shuqi Li",
        "Shukun Zhang",
        "Rui Yan"
      ],
      "abstract": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å…¨è‡ªåŠ¨ç”Ÿæˆè‚¡ç¥¨ç ”ç©¶æŠ¥å‘Š(Equity Research Report, ERR)é¢†åŸŸçš„ç©ºç™½ï¼Œé¦–æ¬¡å®šä¹‰äº†ERRç”Ÿæˆä»»åŠ¡ã€‚ä¸ºäº†è§£å†³æ•°æ®ç¨€ç¼ºå’Œè¯„ä¼°æ ‡å‡†ç¼ºå¤±çš„é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªå¼€æºè¯„ä¼°åŸºå‡†FinRptï¼Œå¹¶é€šè¿‡æ•´åˆ7ç§é‡‘èæ•°æ®ç±»å‹æ„å»ºäº†è‡ªåŠ¨åŒ–çš„æ•°æ®é›†ç”Ÿæˆæµç¨‹ã€‚ç ”ç©¶å›¢é˜Ÿå¼•å…¥äº†ä¸€ä¸ªåŒ…å«11é¡¹æŒ‡æ ‡çš„ç»¼åˆè¯„ä¼°ç³»ç»Ÿï¼Œç”¨äºè¡¡é‡ç”ŸæˆæŠ¥å‘Šçš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§åä¸ºFinRpt-Gençš„å¤šæ™ºèƒ½ä½“æ¡†æ¶(Multi-agent Framework)ï¼Œå¹¶åˆ©ç”¨ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)åœ¨æ„å»ºçš„æ•°æ®é›†ä¸Šè®­ç»ƒäº†åŸºäºLLMçš„æ™ºèƒ½ä½“ã€‚å®éªŒç»“æœéªŒè¯äº†FinRptåŸºå‡†çš„æ•°æ®è´¨é‡å’ŒæŒ‡æ ‡æœ‰æ•ˆæ€§ï¼ŒåŒæ—¶ä¹Ÿå±•ç¤ºäº†FinRpt-Genæ¡†æ¶åœ¨ç”Ÿæˆé«˜è´¨é‡ç ”ç©¶æŠ¥å‘Šæ–¹é¢çš„å¼ºåŠ²æ€§èƒ½ï¼Œä¸ºè¯¥é¢†åŸŸçš„è‡ªåŠ¨åŒ–åˆ›æ–°æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07322v2",
      "published_date": "2025-11-10 17:22:32 UTC",
      "updated_date": "2025-11-11 03:18:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:02:32.845092+00:00"
    },
    {
      "arxiv_id": "2511.07318v2",
      "title": "When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs",
      "title_zh": "å½“åè§ä¼ªè£…æˆçœŸç†ï¼šè™šå‡ç›¸å…³æ€§å¦‚ä½•å‰Šå¼±å¤§è¯­è¨€æ¨¡å‹çš„å¹»è§‰æ£€æµ‹",
      "authors": [
        "Shaowen Wang",
        "Yiqi Dong",
        "Ruinian Chang",
        "Tansheng Zhu",
        "Yuebo Sun",
        "Kaifeng Lyu",
        "Jian Li"
      ],
      "abstract": "Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­ä¸€ç§å°šæœªè¢«å……åˆ†ç ”ç©¶çš„å¹»è§‰ç±»å‹ï¼Œå³ç”±è™šå‡ç›¸å…³æ€§(spurious correlations)é©±åŠ¨çš„å¹»è§‰ã€‚è¿™ç§ç›¸å…³æ€§æŒ‡è®­ç»ƒæ•°æ®ä¸­ç‰¹å¾ï¼ˆå¦‚å§“æ°ï¼‰ä¸å±æ€§ï¼ˆå¦‚å›½ç±ï¼‰ä¹‹é—´è¡¨é¢ä½†ç»Ÿè®¡ä¸Šæ˜¾è‘—çš„è”ç³»ã€‚ä½œè€…è¯æ˜ï¼Œè¿™ç±»å¹»è§‰ä¸ä»…ç”Ÿæˆç½®ä¿¡åº¦é«˜ã€ä¸å—æ¨¡å‹è§„æ¨¡æ‰©å¤§çš„å½±å“ï¼Œç”šè‡³åœ¨ç»è¿‡æ‹’ç»å¾®è°ƒ(refusal fine-tuning)åä¾ç„¶å­˜åœ¨ï¼Œä¸”èƒ½é€ƒé¿å½“å‰çš„æ£€æµ‹æ–¹æ³•ã€‚é€šè¿‡ç³»ç»Ÿçš„åˆæˆå®éªŒä»¥åŠå¯¹åŒ…æ‹¬GPT-5åœ¨å†…çš„å¼€æºå’Œä¸“æœ‰LLMsçš„å®è¯è¯„ä¼°ï¼Œç ”ç©¶æ˜¾ç¤ºç°æœ‰çš„å¹»è§‰æ£€æµ‹æ‰‹æ®µï¼Œå¦‚åŸºäºç½®ä¿¡åº¦çš„è¿‡æ»¤(confidence-based filtering)å’Œå†…éƒ¨çŠ¶æ€æ¢æµ‹(inner-state probing)ï¼Œåœ¨é¢å¯¹è™šå‡ç›¸å…³æ€§æ—¶å½»åº•å¤±æ•ˆã€‚ç†è®ºåˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†è¿™äº›ç»Ÿè®¡åå·®ä¸ºä½•ä¼šä»æœ¬è´¨ä¸Šç ´ååŸºäºç½®ä¿¡åº¦çš„æ£€æµ‹æŠ€æœ¯ã€‚è¯¥å‘ç°å¼ºè°ƒäº†è¿«åˆ‡éœ€è¦å¼€å‘ä¸“é—¨é’ˆå¯¹ç”±è™šå‡ç›¸å…³æ€§å¼•èµ·çš„å¹»è§‰çš„æ–°å‹æ£€æµ‹æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07318v2",
      "published_date": "2025-11-10 17:19:27 UTC",
      "updated_date": "2025-11-21 11:45:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:02:58.737781+00:00"
    },
    {
      "arxiv_id": "2511.07312v1",
      "title": "Superhuman AI for Stratego Using Self-Play Reinforcement Learning and Test-Time Search",
      "title_zh": "åŸºäºè‡ªåšå¼ˆå¼ºåŒ–å­¦ä¹ ä¸æµ‹è¯•æ—¶æœç´¢çš„ Stratego è¶…äººç±» AI",
      "authors": [
        "Samuel Sokota",
        "Eugene Vinitsky",
        "Hengyuan Hu",
        "J. Zico Kolter",
        "Gabriele Farina"
      ],
      "abstract": "Few classical games have been regarded as such significant benchmarks of artificial intelligence as to have justified training costs in the millions of dollars. Among these, Stratego -- a board wargame exemplifying the challenge of strategic decision making under massive amounts of hidden information -- stands apart as a case where such efforts failed to produce performance at the level of top humans. This work establishes a step change in both performance and cost for Stratego, showing that it is now possible not only to reach the level of top humans, but to achieve vastly superhuman level -- and that doing so requires not an industrial budget, but merely a few thousand dollars. We achieved this result by developing general approaches for self-play reinforcement learning and test-time search under imperfect information.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å…·æœ‰å¤§é‡éšè—ä¿¡æ¯çš„ç»å…¸æ£‹ç›˜æˆ˜äº‰æ¸¸æˆ Strategoï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿè¾¾åˆ°è¿œè¶…äººç±»æ°´å¹³ï¼ˆSuperhumanï¼‰çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿã€‚å°½ç®¡ Stratego é•¿æœŸä»¥æ¥è¢«è§†ä¸ºäººå·¥æ™ºèƒ½çš„é‡è¦åŸºå‡†ï¼Œä½†ä»¥å¾€å³ä¾¿æŠ•å…¥æ•°ç™¾ä¸‡ç¾å…ƒçš„è®­ç»ƒæˆæœ¬ï¼Œä¹Ÿæœªèƒ½è¾¾åˆ°é¡¶å°–äººç±»ç©å®¶çš„æ°´å¹³ã€‚è¯¥å·¥ä½œé€šè¿‡å¼€å‘é’ˆå¯¹ä¸å®Œç¾ä¿¡æ¯ç¯å¢ƒçš„ Self-Play Reinforcement Learning å’Œ Test-Time Search é€šç”¨æ–¹æ³•ï¼Œå®ç°äº†æ€§èƒ½å’Œæˆæœ¬çš„é˜¶è·ƒå¼çªç ´ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œä»…éœ€å‡ åƒç¾å…ƒçš„é¢„ç®—ï¼Œè€Œéå·¥ä¸šçº§æŠ•å…¥ï¼Œå³å¯æ„å»ºå‡ºè¶…è¶Šé¡¶å°–äººç±»ç©å®¶çš„ AIã€‚è¿™ä¸€æˆæœä¸ä»…è§£å†³äº† Stratego è¿™ä¸€é•¿æœŸå­˜åœ¨çš„æŒ‘æˆ˜ï¼Œä¹Ÿå±•ç¤ºäº†åœ¨ä¸å®Œç¾ä¿¡æ¯åšå¼ˆä¸­å®ç°é«˜æ•ˆèƒ½ã€ä½æˆæœ¬æ™ºèƒ½å†³ç­–çš„å¯èƒ½æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07312v1",
      "published_date": "2025-11-10 17:13:41 UTC",
      "updated_date": "2025-11-10 17:13:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:06:10.983410+00:00"
    },
    {
      "arxiv_id": "2511.07503v3",
      "title": "Biologically-Informed Hybrid Membership Inference Attacks on Generative Genomic Models",
      "title_zh": "é’ˆå¯¹ç”Ÿæˆå¼åŸºå› ç»„æ¨¡å‹çš„èåˆç”Ÿç‰©å­¦ä¿¡æ¯æ··åˆæˆå‘˜æ¨æ–­æ”»å‡»",
      "authors": [
        "Asia Belfiore",
        "Jonathan Passerat-Palmbach",
        "Dmitrii Usynin"
      ],
      "abstract": "The increased availability of genetic data has transformed genomics research, but raised many privacy concerns regarding its handling due to its sensitive nature. This work explores the use of language models (LMs) for the generation of synthetic genetic mutation profiles, leveraging differential privacy (DP) for the protection of sensitive genetic data. We empirically evaluate the privacy guarantees of our DP modes by introducing a novel Biologically-Informed Hybrid Membership Inference Attack (biHMIA), which combines traditional black box MIA with contextual genomics metrics for enhanced attack power. Our experiments show that both small and large transformer GPT-like models are viable synthetic variant generators for small-scale genomics, and that our hybrid attack leads, on average, to higher adversarial success compared to traditional metric-based MIAs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨è¯­è¨€æ¨¡å‹(LMs)ç”ŸæˆåˆæˆåŸºå› çªå˜è°±ï¼Œå¹¶ç»“åˆå·®åˆ†éšç§(DP)æŠ€æœ¯æ¥ä¿æŠ¤æ•æ„Ÿé—ä¼ æ•°æ®ã€‚ä¸ºäº†ç»éªŒæ€§åœ°è¯„ä¼°DPæ¨¡å‹çš„éšç§ä¿éšœèƒ½åŠ›ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„ç”Ÿç‰©å­¦çŸ¥æƒ…æ··åˆæˆå‘˜æ¨æ–­æ”»å‡»(Biologically-Informed Hybrid Membership Inference Attack, biHMIA)ã€‚è¯¥æ–¹æ³•å°†ä¼ ç»Ÿçš„é»‘ç›’MIAä¸ä¸Šä¸‹æ–‡åŸºå› ç»„å­¦æŒ‡æ ‡ç›¸ç»“åˆï¼Œä»è€Œæ˜¾è‘—å¢å¼ºäº†æ”»å‡»å¨åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ— è®ºæ˜¯å°å‹è¿˜æ˜¯å¤§å‹çš„transformer GPT-likeæ¨¡å‹ï¼Œå‡å¯æœ‰æ•ˆç”¨äºå°è§„æ¨¡åŸºå› ç»„å­¦çš„åˆæˆå˜ä½“ç”Ÿæˆã€‚åŒæ—¶ï¼Œç ”ç©¶å‘ç°è¯¥æ··åˆæ”»å‡»åœ¨å¹³å‡å¯¹æŠ—æˆåŠŸç‡ä¸Šä¼˜äºä¼ ç»Ÿçš„åŸºäºæŒ‡æ ‡çš„MIAï¼Œæ­ç¤ºäº†ç”Ÿæˆå¼åŸºå› ç»„æ¨¡å‹é¢ä¸´çš„æ½œåœ¨éšç§é£é™©ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07503v3",
      "published_date": "2025-11-10 17:09:19 UTC",
      "updated_date": "2025-12-18 15:39:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:06:34.177972+00:00"
    },
    {
      "arxiv_id": "2511.07301v2",
      "title": "Beyond Boundaries: Leveraging Vision Foundation Models for Source-Free Object Detection",
      "title_zh": "è¶…è¶Šè¾¹ç•Œï¼šåŸºäºè§†è§‰åŸºç¡€æ¨¡å‹çš„æ— æºç›®æ ‡æ£€æµ‹",
      "authors": [
        "Huizai Yao",
        "Sicheng Zhao",
        "Pengteng Li",
        "Yi Cui",
        "Shuo Lu",
        "Weiyu Guo",
        "Yunfan Lu",
        "Yijie Xu",
        "Hui Xiong"
      ],
      "abstract": "Source-Free Object Detection (SFOD) aims to adapt a source-pretrained object detector to a target domain without access to source data. However, existing SFOD methods predominantly rely on internal knowledge from the source model, which limits their capacity to generalize across domains and often results in biased pseudo-labels, thereby hindering both transferability and discriminability. In contrast, Vision Foundation Models (VFMs), pretrained on massive and diverse data, exhibit strong perception capabilities and broad generalization, yet their potential remains largely untapped in the SFOD setting. In this paper, we propose a novel SFOD framework that leverages VFMs as external knowledge sources to jointly enhance feature alignment and label quality. Specifically, we design three VFM-based modules: (1) Patch-weighted Global Feature Alignment (PGFA) distills global features from VFMs using patch-similarity-based weighting to enhance global feature transferability; (2) Prototype-based Instance Feature Alignment (PIFA) performs instance-level contrastive learning guided by momentum-updated VFM prototypes; and (3) Dual-source Enhanced Pseudo-label Fusion (DEPF) fuses predictions from detection VFMs and teacher models via an entropy-aware strategy to yield more reliable supervision. Extensive experiments on six benchmarks demonstrate that our method achieves state-of-the-art SFOD performance, validating the effectiveness of integrating VFMs to simultaneously improve transferability and discriminability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Source-Free Object Detection (SFOD)ä»»åŠ¡ä¸­ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–æºæ¨¡å‹å†…éƒ¨çŸ¥è¯†è€Œå¯¼è‡´æ³›åŒ–å—é™å’Œä¼ªæ ‡ç­¾åå·®çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨Vision Foundation Models (VFMs)ä½œä¸ºå¤–éƒ¨çŸ¥è¯†æºçš„æ–°å‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨é€šè¿‡å¼•å…¥VFMså¼ºå¤§çš„æ„ŸçŸ¥èƒ½åŠ›ï¼ŒåŒæ—¶å¢å¼ºç‰¹å¾å¯¹é½å’Œä¼ªæ ‡ç­¾çš„è´¨é‡ã€‚å…·ä½“è€Œè¨€ï¼Œç ”ç©¶è®¾è®¡äº†ä¸‰ä¸ªæ ¸å¿ƒæ¨¡å—ï¼šPatch-weighted Global Feature Alignment (PGFA)åˆ©ç”¨åŸºäºå›¾åƒå—ç›¸ä¼¼åº¦çš„åŠ æƒä»VFMsä¸­è’¸é¦å…¨å±€ç‰¹å¾ä»¥æå‡è¿ç§»æ€§ï¼›Prototype-based Instance Feature Alignment (PIFA)åˆ©ç”¨åŠ¨é‡æ›´æ–°çš„VFMåŸå‹å¼•å¯¼å®ä¾‹çº§å¯¹æ¯”å­¦ä¹ ï¼›Dual-source Enhanced Pseudo-label Fusion (DEPF)åˆ™é€šè¿‡ç†µæ„ŸçŸ¥ç­–ç•¥èåˆæ£€æµ‹VFMä¸æ•™å¸ˆæ¨¡å‹çš„é¢„æµ‹ï¼Œä»è€Œç”Ÿæˆæ›´å¯é çš„ç›‘ç£ä¿¡å·ã€‚åœ¨å…­ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•å–å¾—äº†æœ€å…ˆè¿›çš„SFODæ€§èƒ½ï¼Œæœ‰æ•ˆéªŒè¯äº†é›†æˆVFMsåœ¨æå‡æ¨¡å‹è¿ç§»èƒ½åŠ›å’Œåˆ¤åˆ«èƒ½åŠ›æ–¹é¢çš„æ˜¾è‘—æ•ˆæœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2026. Extended version with full Appendix",
      "pdf_url": "https://arxiv.org/pdf/2511.07301v2",
      "published_date": "2025-11-10 17:06:01 UTC",
      "updated_date": "2026-01-20 22:30:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:07:00.400381+00:00"
    },
    {
      "arxiv_id": "2511.11656v1",
      "title": "On the Probabilistic Learnability of Compact Neural Network Preimage Bounds",
      "title_zh": "ç´§å‡‘ç¥ç»ç½‘ç»œåŸåƒç•Œçš„æ¦‚ç‡å¯å­¦ä¹ æ€§",
      "authors": [
        "Luca Marzari",
        "Manuele Bicego",
        "Ferdinando Cicalese",
        "Alessandro Farinelli"
      ],
      "abstract": "Although recent provable methods have been developed to compute preimage bounds for neural networks, their scalability is fundamentally limited by the #P-hardness of the problem. In this work, we adopt a novel probabilistic perspective, aiming to deliver solutions with high-confidence guarantees and bounded error. To this end, we investigate the potential of bootstrap-based and randomized approaches that are capable of capturing complex patterns in high-dimensional spaces, including input regions where a given output property holds. In detail, we introduce $\\textbf{R}$andom $\\textbf{F}$orest $\\textbf{Pro}$perty $\\textbf{Ve}$rifier ($\\texttt{RF-ProVe}$), a method that exploits an ensemble of randomized decision trees to generate candidate input regions satisfying a desired output property and refines them through active resampling. Our theoretical derivations offer formal statistical guarantees on region purity and global coverage, providing a practical, scalable solution for computing compact preimage approximations in cases where exact solvers fail to scale.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å½“å‰è®¡ç®—ç¥ç»ç½‘ç»œåŸåƒç•Œé™ï¼ˆpreimage boundsï¼‰çš„æ–¹æ³•å› #P-hardnessè€Œéš¾ä»¥æ‰©å±•çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ—¨åœ¨æä¾›é«˜ç½®ä¿¡åº¦ä¿è¯å’Œæœ‰ç•Œè¯¯å·®çš„æ–°é¢–æ¦‚ç‡è§†è§’ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡ä»‹ç»äº†$\\texttt{RF-ProVe}$ï¼ˆRandom Forest Property Verifierï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨éšæœºå†³ç­–æ ‘é›†æˆçš„æ–¹æ³•ï¼Œèƒ½å¤Ÿç”Ÿæˆæ»¡è¶³æœŸæœ›è¾“å‡ºå±æ€§çš„å€™é€‰è¾“å…¥åŒºåŸŸï¼Œå¹¶é€šè¿‡ä¸»åŠ¨é‡é‡‡æ ·ï¼ˆactive resamplingï¼‰å¯¹å…¶è¿›è¡Œç»†åŒ–ã€‚ç†è®ºæ¨å¯¼ä¸ºåŒºåŸŸçº¯åº¦ï¼ˆregion purityï¼‰å’Œå…¨å±€è¦†ç›–ç‡ï¼ˆglobal coverageï¼‰æä¾›äº†å½¢å¼åŒ–çš„ç»Ÿè®¡ä¿è¯ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ç²¾ç¡®æ±‚è§£å™¨å¤±æ•ˆçš„é«˜ç»´ç©ºé—´ä¸­æ•æ‰å¤æ‚æ¨¡å¼ï¼Œä¸ºè®¡ç®—ç´§å‡‘çš„åŸåƒè¿‘ä¼¼æä¾›äº†ä¸€ç§å®ç”¨ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 40th Annual AAAI Conference on Artificial Intelligence 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.11656v1",
      "published_date": "2025-11-10 16:56:51 UTC",
      "updated_date": "2025-11-10 16:56:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:07:41.284537+00:00"
    },
    {
      "arxiv_id": "2511.07298v1",
      "title": "LMM-IQA: Image Quality Assessment for Low-Dose CT Imaging",
      "title_zh": "LMM-IQAï¼šé¢å‘ä½å‰‚é‡ CT æˆåƒçš„å›¾åƒè´¨é‡è¯„ä¼°",
      "authors": [
        "Kagan Celik",
        "Mehmet Ozan Unal",
        "Metin Ertas",
        "Isa Yildirim"
      ],
      "abstract": "Low-dose computed tomography (CT) represents a significant improvement in patient safety through lower radiation doses, but increased noise, blur, and contrast loss can diminish diagnostic quality. Therefore, consistency and robustness in image quality assessment become essential for clinical applications. In this study, we propose an LLM-based quality assessment system that generates both numerical scores and textual descriptions of degradations such as noise, blur, and contrast loss. Furthermore, various inference strategies - from the zero-shot approach to metadata integration and error feedback - are systematically examined, demonstrating the progressive contribution of each method to overall performance. The resultant assessments yield not only highly correlated scores but also interpretable output, thereby adding value to clinical workflows. The source codes of our study are available at https://github.com/itu-biai/lmms_ldct_iqa.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä½å‰‚é‡CTï¼ˆLow-dose CTï¼‰æˆåƒä¸­å› è¾å°„å‰‚é‡é™ä½è€Œå¯¼è‡´çš„å™ªå£°å¢åŠ ã€æ¨¡ç³Šå’Œå¯¹æ¯”åº¦æŸå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å›¾åƒè´¨é‡è¯„ä¼°ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿèƒ½å¤ŸåŒæ—¶ç”Ÿæˆæ•°å€¼è¯„åˆ†å’Œé’ˆå¯¹å™ªå£°ã€æ¨¡ç³ŠåŠå¯¹æ¯”åº¦æŸå¤±ç­‰é€€åŒ–ç°è±¡çš„æ–‡æœ¬æè¿°ï¼Œä»¥ç¡®ä¿ä¸´åºŠåº”ç”¨ä¸­è¯„ä¼°çš„ä¸€è‡´æ€§ä¸é²æ£’æ€§ã€‚ç ”ç©¶å›¢é˜Ÿç³»ç»Ÿåœ°éªŒè¯äº†ä»é›¶æ ·æœ¬ï¼ˆzero-shotï¼‰æ¨ç†åˆ°å…ƒæ•°æ®é›†æˆåŠé”™è¯¯åé¦ˆç­‰å¤šç§ç­–ç•¥ï¼Œå±•ç¤ºäº†å„ç­–ç•¥å¯¹æå‡æ¨¡å‹æ€§èƒ½çš„é€æ­¥è´¡çŒ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½æä¾›ä¸äººç±»è¯„ä¼°é«˜åº¦ç›¸å…³çš„è¯„åˆ†ï¼Œè¿˜èƒ½è¾“å‡ºå…·æœ‰å¯è§£é‡Šæ€§çš„ç»“æœï¼Œæ˜¾è‘—æå‡äº†ä¸´åºŠå·¥ä½œæµç¨‹çš„ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07298v1",
      "published_date": "2025-11-10 16:56:11 UTC",
      "updated_date": "2025-11-10 16:56:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:07:46.790579+00:00"
    },
    {
      "arxiv_id": "2511.07295v2",
      "title": "Hard vs. Noise: Resolving Hard-Noisy Sample Confusion in Recommender Systems via Large Language Models",
      "title_zh": "å›°éš¾ä¸å™ªå£°ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹è§£å†³æ¨èç³»ç»Ÿä¸­çš„å›°éš¾-å™ªå£°æ ·æœ¬æ··æ·†",
      "authors": [
        "Tianrui Song",
        "Wen-Shuo Chao",
        "Hao Liu"
      ],
      "abstract": "Implicit feedback, employed in training recommender systems, unavoidably confronts noise due to factors such as misclicks and position bias. Previous studies have attempted to identify noisy samples through their diverged data patterns, such as higher loss values, and mitigate their influence through sample dropping or reweighting. However, we observed that noisy samples and hard samples display similar patterns, leading to hard-noisy confusion issue. Such confusion is problematic as hard samples are vital for modeling user preferences. To solve this problem, we propose LLMHNI framework, leveraging two auxiliary user-item relevance signals generated by Large Language Models (LLMs) to differentiate hard and noisy samples. LLMHNI obtains user-item semantic relevance from LLM-encoded embeddings, which is used in negative sampling to select hard negatives while filtering out noisy false negatives. An objective alignment strategy is proposed to project LLM-encoded embeddings, originally for general language tasks, into a representation space optimized for user-item relevance modeling. LLMHNI also exploits LLM-inferred logical relevance within user-item interactions to identify hard and noisy samples. These LLM-inferred interactions are integrated into the interaction graph and guide denoising with cross-graph contrastive alignment. To eliminate the impact of unreliable interactions induced by LLM hallucination, we propose a graph contrastive learning strategy that aligns representations from randomly edge-dropped views to suppress unreliable edges. Empirical results demonstrate that LLMHNI significantly improves denoising and recommendation performance.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨èç³»ç»Ÿä¸­éšå¼åé¦ˆè®­ç»ƒæ—¶é¢ä¸´çš„å™ªå£°å¹²æ‰°é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯é«˜æŸå¤±å€¼çš„å™ªå£°æ ·æœ¬ä¸å›°éš¾æ ·æœ¬ï¼ˆHard Samplesï¼‰éš¾ä»¥åŒºåˆ†çš„â€œå›°éš¾-å™ªå£°æ··æ·†â€ç°è±¡ï¼Œæå‡ºäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„LLMHNIæ¡†æ¶ã€‚ç°æœ‰æ–¹æ³•å¸¸å› è¿™ç§æ··æ·†è€Œé”™è¯¯åœ°å¤„ç†äº†å¯¹ç”¨æˆ·åå¥½å»ºæ¨¡è‡³å…³é‡è¦çš„å›°éš¾æ ·æœ¬ã€‚LLMHNIé€šè¿‡åˆ©ç”¨LLMç”Ÿæˆçš„è¯­ä¹‰ç›¸å…³æ€§å’Œé€»è¾‘ç›¸å…³æ€§ä½œä¸ºè¾…åŠ©ä¿¡å·ï¼Œæœ‰æ•ˆåŒºåˆ†äº†å›°éš¾æ ·æœ¬å’Œå™ªå£°æ ·æœ¬ã€‚åœ¨æ–¹æ³•ä¸Šï¼Œè¯¥æ¡†æ¶åˆ©ç”¨LLMç¼–ç çš„åµŒå…¥è¿›è¡Œè¯­ä¹‰è´Ÿé‡‡æ ·ï¼ˆNegative Samplingï¼‰ï¼Œå¹¶é‡‡ç”¨ç›®æ ‡å¯¹é½ç­–ç•¥å°†é€šç”¨è¯­è¨€è¡¨ç¤ºæ˜ å°„åˆ°ç”¨æˆ·-ç‰©å“ç›¸å…³æ€§ç©ºé—´ã€‚æ­¤å¤–ï¼Œç ”ç©¶åˆ©ç”¨LLMæ¨æ–­çš„é€»è¾‘ç›¸å…³æ€§å¢å¼ºäº¤äº’å›¾ï¼Œå¹¶é€šè¿‡è·¨å›¾å¯¹æ¯”å¯¹é½æŒ‡å¯¼å»å™ªï¼ŒåŒæ—¶å¼•å…¥å›¾å¯¹æ¯”å­¦ä¹ ï¼ˆGraph Contrastive Learningï¼‰ç­–ç•¥ä»¥å‡è½»LLMå¹»è§‰å¸¦æ¥çš„ä¸å¯é å½±å“ã€‚å®è¯ç»“æœè¡¨æ˜ï¼ŒLLMHNIåœ¨å»å™ªæ•ˆæœå’Œæ¨èç³»ç»Ÿæ€§èƒ½ä¸Šå‡å–å¾—äº†æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07295v2",
      "published_date": "2025-11-10 16:51:03 UTC",
      "updated_date": "2025-11-11 14:13:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:08:20.611639+00:00"
    },
    {
      "arxiv_id": "2511.07293v1",
      "title": "Verifying rich robustness properties for neural networks",
      "title_zh": "éªŒè¯ç¥ç»ç½‘ç»œçš„ä¸°å¯Œé²æ£’æ€§æ€§è´¨",
      "authors": [
        "Mohammad Afzal",
        "S. Akshay",
        "Ashutosh Gupta"
      ],
      "abstract": "Robustness is a important problem in AI alignment and safety, with models such as neural networks being increasingly used in safety-critical systems. In the last decade, a large body of work has emerged on local robustness, i.e., checking if the decision of a neural network remains unchanged when the input is slightly perturbed. However, many of these approaches require specialized encoding and often ignore the confidence of a neural network on its output. In this paper, our goal is to build a generalized framework to specify and verify variants of robustness in neural network verification. We propose a specification framework using a simple grammar, which is flexible enough to capture most existing variants. This allows us to introduce new variants of robustness that take into account the confidence of the neural network in its outputs. Next, we develop a novel and powerful unified technique to verify all such variants in a homogeneous way, viz., by adding a few additional layers to the neural network. This enables us to use any state-of-the-art neural network verification tool, without having to tinker with the encoding within, while incurring an approximation error that we show is bounded. We perform an extensive experimental evaluation over a large suite of 8870 benchmarks having 138M parameters in a largest network, and show that we are able to capture a wide set of robustness variants and outperform direct encoding approaches by a significant margin.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹ç¥ç»ç½‘ç»œåœ¨å®‰å…¨å…³é”®ç³»ç»Ÿä¸­åº”ç”¨çš„é²æ£’æ€§é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰æ–¹æ³•é€šå¸¸å±€é™äºå±€éƒ¨é²æ£’æ€§ï¼Œä¸”å¿½ç•¥äº†ç½‘ç»œè¾“å‡ºçš„ç½®ä¿¡åº¦(confidence)ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ä¸ªåŸºäºç®€å•è¯­æ³•çš„é€šç”¨è§„èŒƒæ¡†æ¶ï¼Œä¸ä»…èƒ½æ¶µç›–ç°æœ‰çš„é²æ£’æ€§å˜ä½“ï¼Œè¿˜èƒ½å¼•å…¥è€ƒè™‘ç½®ä¿¡åº¦çš„æ–°å˜ä½“ã€‚ä½œè€…å¼€å‘äº†ä¸€ç§æ–°é¢–çš„ç»Ÿä¸€éªŒè¯æŠ€æœ¯ï¼Œé€šè¿‡å‘ç¥ç»ç½‘ç»œæ·»åŠ å°‘é‡é¢å¤–å±‚æ¥å¤„ç†æ‰€æœ‰è¿™äº›å˜ä½“ã€‚è¿™ç§æ–¹æ³•å…è®¸ç›´æ¥ä½¿ç”¨ä»»ä½•ç°æœ‰çš„æœ€å…ˆè¿›ç¥ç»ç½‘ç»œéªŒè¯å·¥å…·ï¼Œæ— éœ€ä¿®æ”¹å†…éƒ¨ç¼–ç ï¼Œä¸”è¯æ˜äº†è¿‘ä¼¼è¯¯å·®æ˜¯æœ‰ç•Œçš„ã€‚åœ¨åŒ…å«8870ä¸ªåŸºå‡†æµ‹è¯•ï¼ˆæœ€å¤§ç½‘ç»œå‚æ•°è¾¾1.38äº¿ï¼‰çš„å¹¿æ³›å®éªŒä¸­ï¼Œè¯¥æ–¹æ³•å±•ç¤ºäº†æ•æ‰å¤šç§é²æ£’æ€§å˜ä½“çš„èƒ½åŠ›ï¼Œå¹¶åœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç›´æ¥ç¼–ç æ–¹æ³•ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07293v1",
      "published_date": "2025-11-10 16:43:02 UTC",
      "updated_date": "2025-11-10 16:43:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:08:39.864201+00:00"
    },
    {
      "arxiv_id": "2511.07288v1",
      "title": "Enabling Off-Policy Imitation Learning with Deep Actor Critic Stabilization",
      "title_zh": "åˆ©ç”¨æ·±åº¦æ¼”å‘˜-è¯„è®ºå®¶ç¨³å®šåŒ–å®ç°ç¦»ç­–ç•¥æ¨¡ä»¿å­¦ä¹ ",
      "authors": [
        "Sayambhu Sen",
        "Shalabh Bhatnagar"
      ],
      "abstract": "Learning complex policies with Reinforcement Learning (RL) is often hindered by instability and slow convergence, a problem exacerbated by the difficulty of reward engineering. Imitation Learning (IL) from expert demonstrations bypasses this reliance on rewards. However, state-of-the-art IL methods, exemplified by Generative Adversarial Imitation Learning (GAIL)Ho et. al, suffer from severe sample inefficiency. This is a direct consequence of their foundational on-policy algorithms, such as TRPO Schulman et.al. In this work, we introduce an adversarial imitation learning algorithm that incorporates off-policy learning to improve sample efficiency. By combining an off-policy framework with auxiliary techniques specifically, double Q network based stabilization and value learning without reward function inference we demonstrate a reduction in the samples required to robustly match expert behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­å­˜åœ¨çš„æ”¶æ•›ç¼“æ…¢å’Œå¥–åŠ±å·¥ç¨‹éš¾é¢˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç”Ÿæˆå¯¹æŠ—æ¨¡ä»¿å­¦ä¹ ï¼ˆGAILï¼‰ç­‰ç°æœ‰æ¨¡ä»¿å­¦ä¹ ï¼ˆILï¼‰æ–¹æ³•å› ä¾èµ–on-policyç®—æ³•ï¼ˆå¦‚TRPOï¼‰è€Œå¯¼è‡´çš„ä¸¥é‡æ ·æœ¬æ•ˆç‡ä½ä¸‹é—®é¢˜ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§ç»“åˆoff-policyå­¦ä¹ æœºåˆ¶çš„å¯¹æŠ—æ€§æ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œä»¥æå‡æ ·æœ¬åˆ©ç”¨ç‡ã€‚è¯¥ç®—æ³•èåˆäº†off-policyæ¡†æ¶ä¸ç‰¹å®šçš„è¾…åŠ©æŠ€æœ¯ï¼ŒåŒ…æ‹¬åŸºäºåŒQç½‘ç»œï¼ˆdouble Q networkï¼‰çš„ç¨³å®šåŒ–æ–¹æ³•ä»¥åŠæ— éœ€å¥–åŠ±å‡½æ•°æ¨æ–­çš„ä»·å€¼å­¦ä¹ ã€‚é€šè¿‡è¿™äº›æ”¹è¿›ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒç¨³å¥åŒ¹é…ä¸“å®¶è¡Œä¸ºçš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†æ‰€éœ€çš„è®­ç»ƒæ ·æœ¬æ•°é‡ã€‚è¿™é¡¹å·¥ä½œæœ‰æ•ˆç¼“è§£äº†ä¼ ç»Ÿå¯¹æŠ—æ€§æ¨¡ä»¿å­¦ä¹ ä¸­çš„æ ·æœ¬ä½æ•ˆç“¶é¢ˆï¼Œä¸ºæ›´é«˜æ•ˆçš„å¤æ‚ç­–ç•¥å­¦ä¹ æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages and 4 images",
      "pdf_url": "https://arxiv.org/pdf/2511.07288v1",
      "published_date": "2025-11-10 16:35:50 UTC",
      "updated_date": "2025-11-10 16:35:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:10:41.236171+00:00"
    },
    {
      "arxiv_id": "2511.07286v1",
      "title": "Glioma C6: A Novel Dataset for Training and Benchmarking Cell Segmentation",
      "title_zh": "Glioma C6ï¼šç”¨äºç»†èƒåˆ†å‰²è®­ç»ƒä¸åŸºå‡†æµ‹è¯•çš„æ–°å‹æ•°æ®é›†",
      "authors": [
        "Roman Malashin",
        "Svetlana Pashkevich",
        "Daniil Ilyukhin",
        "Arseniy Volkov",
        "Valeria Yachnaya",
        "Andrey Denisov",
        "Maria Mikhalkova"
      ],
      "abstract": "We present Glioma C6, a new open dataset for instance segmentation of glioma C6 cells, designed as both a benchmark and a training resource for deep learning models. The dataset comprises 75 high-resolution phase-contrast microscopy images with over 12,000 annotated cells, providing a realistic testbed for biomedical image analysis. It includes soma annotations and morphological cell categorization provided by biologists. Additional categorization of cells, based on morphology, aims to enhance the utilization of image data for cancer cell research. Glioma C6 consists of two parts: the first is curated with controlled parameters for benchmarking, while the second supports generalization testing under varying conditions. We evaluate the performance of several generalist segmentation models, highlighting their limitations on our dataset. Our experiments demonstrate that training on Glioma C6 significantly enhances segmentation performance, reinforcing its value for developing robust and generalizable models. The dataset is publicly available for researchers.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†Glioma C6ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¥ç»èƒ¶è´¨ç˜¤C6ç»†èƒå®ä¾‹åˆ†å‰²(instance segmentation)çš„æ–°å‹å¼€æ”¾æ•°æ®é›†ï¼Œæ—¨åœ¨ä½œä¸ºæ·±åº¦å­¦ä¹ æ¨¡å‹çš„åŸºå‡†å’Œè®­ç»ƒèµ„æºã€‚è¯¥æ•°æ®é›†åŒ…å«75å¼ é«˜åˆ†è¾¨ç‡ç›¸å·®æ˜¾å¾®é•œå›¾åƒ(phase-contrast microscopy images)å’Œè¶…è¿‡12,000ä¸ªæ ‡æ³¨ç»†èƒï¼Œæä¾›äº†ç”Ÿç‰©å­¦å®¶éªŒè¯çš„èƒä½“æ ‡æ³¨å’Œå½¢æ€å­¦ç»†èƒåˆ†ç±»ã€‚Glioma C6ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«ç”¨äºå—æ§å‚æ•°ä¸‹çš„åŸºå‡†æµ‹è¯•å’Œä¸åŒæ¡ä»¶ä¸‹çš„æ³›åŒ–æµ‹è¯•ã€‚ç ”ç©¶è¯„ä¼°äº†å¤šç§é€šç”¨åˆ†å‰²æ¨¡å‹ï¼Œæ­ç¤ºäº†å®ƒä»¬åœ¨ç°æœ‰æ•°æ®é›†ä¸Šçš„å±€é™æ€§ï¼Œå¹¶è¯æ˜åœ¨è¯¥æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒèƒ½æ˜¾è‘—æå‡åˆ†å‰²æ€§èƒ½ã€‚è¯¥æ•°æ®é›†ä¸ºç”Ÿç‰©åŒ»å­¦å›¾åƒåˆ†ææä¾›äº†ä¸€ä¸ªç°å®çš„æµ‹è¯•å¹³å°ï¼Œæœ‰åŠ©äºå¼€å‘æ›´ç¨³å¥å’Œå…·æœ‰æ³›åŒ–èƒ½åŠ›çš„æ¨¡å‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07286v1",
      "published_date": "2025-11-10 16:33:34 UTC",
      "updated_date": "2025-11-10 16:33:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:11:02.389755+00:00"
    },
    {
      "arxiv_id": "2511.07277v1",
      "title": "Designing Beyond Language: Sociotechnical Barriers in AI Health Technologies for Limited English Proficiency",
      "title_zh": "è¶…è¶Šè¯­è¨€çš„è®¾è®¡ï¼šé¢å‘è‹±è¯­èƒ½åŠ›æœ‰é™ç¾¤ä½“çš„AIå¥åº·æŠ€æœ¯ä¸­çš„ç¤¾ä¼šæŠ€æœ¯å£å’",
      "authors": [
        "Michelle Huang",
        "Violeta J. Rodriguez",
        "Koustuv Saha",
        "Tal August"
      ],
      "abstract": "Limited English proficiency (LEP) patients in the U.S. face systemic barriers to healthcare beyond language and interpreter access, encompassing procedural and institutional constraints. AI advances may support communication and care through on-demand translation and visit preparation, but also risk exacerbating existing inequalities. We conducted storyboard-driven interviews with 14 patient navigators to explore how AI could shape care experiences for Spanish-speaking LEP individuals. We identified tensions around linguistic and cultural misunderstandings, privacy concerns, and opportunities and risks for AI to augment care workflows. Participants highlighted structural factors that can undermine trust in AI systems, including sensitive information disclosure, unstable technology access, and low digital literacy. While AI tools can potentially alleviate social barriers and institutional constraints, there are risks of misinformation and uprooting human camaraderie. Our findings contribute design considerations for AI that support LEP patients and care teams via rapport-building, education, and language support, and minimizing disruptions to existing practices.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†ç¾å›½Limited English Proficiency (LEP)æ‚£è€…åœ¨åŒ»ç–—ä¿å¥ä¸­é¢ä¸´çš„è¶…è¶Šè¯­è¨€æœ¬èº«çš„ç³»ç»Ÿæ€§éšœç¢ã€‚ä½œè€…é€šè¿‡å¯¹14ä½æ‚£è€…å¯¼èˆªå‘˜è¿›è¡Œstoryboard-driven interviewsï¼Œæ·±å…¥åˆ†æäº†AIæŠ€æœ¯å¦‚ä½•å½±å“è®²è¥¿ç­ç‰™è¯­çš„LEPç¾¤ä½“çš„æŠ¤ç†ä½“éªŒã€‚ç ”ç©¶æ­ç¤ºäº†åœ¨è¯­è¨€æ–‡åŒ–è¯¯è§£ã€éšç§æ‹…å¿§ä»¥åŠAIå¢å¼ºæŠ¤ç†å·¥ä½œæµæ–¹é¢çš„å¼ åŠ›ï¼Œå¹¶æŒ‡å‡ºäº†æ•æ„Ÿä¿¡æ¯æ³„éœ²ã€æŠ€æœ¯è·å–ä¸ç¨³å®šå’Œä½æ•°å­—ç´ å…»(digital literacy)ç­‰ç ´åä¿¡ä»»çš„ç»“æ„æ€§å› ç´ ã€‚å°½ç®¡AIå·¥å…·æœ‰æ½œåŠ›ç¼“è§£ç¤¾ä¼šå’Œåˆ¶åº¦éšœç¢ï¼Œä½†ä¹Ÿå­˜åœ¨ä¼ æ’­é”™è¯¯ä¿¡æ¯å’Œå‰Šå¼±äººé™…æƒ…è°Š(human camaraderie)çš„é£é™©ã€‚åŸºäºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†é’ˆå¯¹LEPæ‚£è€…å’ŒæŠ¤ç†å›¢é˜Ÿçš„AIè®¾è®¡è€ƒé‡ï¼Œä¸»å¼ é€šè¿‡å»ºç«‹èæ´½å…³ç³»(rapport-building)ã€æ•™è‚²å’Œè¯­è¨€æ”¯æŒæ¥å¢å¼ºæŠ¤ç†ï¼ŒåŒæ—¶å°½é‡å‡å°‘å¯¹ç°æœ‰å®è·µçš„å¹²æ‰°ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07277v1",
      "published_date": "2025-11-10 16:23:06 UTC",
      "updated_date": "2025-11-10 16:23:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:10:50.024917+00:00"
    },
    {
      "arxiv_id": "2511.07267v2",
      "title": "Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion",
      "title_zh": "è¶…è¶Šæ£€æµ‹ï¼šæ¢ç´¢åŸºäºè¯æ®çš„å¤šæ™ºèƒ½ä½“è¾©è®ºç”¨äºè™šå‡ä¿¡æ¯å¹²é¢„ä¸è¯´æœ",
      "authors": [
        "Chen Han",
        "Yijia Ma",
        "Jin Tan",
        "Wenzhen Zheng",
        "Xijin Tang"
      ],
      "abstract": "Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ED2Dï¼Œä¸€ç§åŸºäºè¯æ®çš„å¤šæ™ºèƒ½ä½“è¾©è®º(Multi-agent debate, MAD)æ¡†æ¶ï¼Œæ—¨åœ¨è¶…è¶Šå•çº¯çš„è™šå‡ä¿¡æ¯æ£€æµ‹ï¼Œè¿›ä¸€æ­¥åˆ©ç”¨è¾©è®ºè®°å½•å®ç°å¯¹ç”¨æˆ·çš„å¹²é¢„å’Œè¯´æœã€‚ED2Dé€šè¿‡ç»“åˆäº‹å®è¯æ®æ£€ç´¢æŠ€æœ¯ï¼Œä¸ä»…æé«˜äº†æ£€æµ‹å‡†ç¡®æ€§ï¼Œè¿˜è‡´åŠ›äºçº æ­£ç”¨æˆ·ä¿¡å¿µå¹¶é˜»æ­¢è™šå‡ä¿¡æ¯ä¼ æ’­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒED2Dåœ¨ä¸‰ä¸ªè™šå‡ä¿¡æ¯æ£€æµ‹åŸºå‡†ä¸Šä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œä¸”åœ¨é¢„æµ‹æ­£ç¡®æ—¶ï¼Œå…¶ç”Ÿæˆçš„æ­ç©¿è®°å½•å…·æœ‰ä¸äººç±»ä¸“å®¶ç›¸å½“çš„è¯´æœåŠ›ã€‚ç„¶è€Œï¼Œç ”ç©¶ä¹Ÿå‘ç°å½“ED2Dåˆ†ç±»é”™è¯¯æ—¶ï¼Œå…¶è§£é‡Šå¯èƒ½ä¼šæ— æ„ä¸­åŠ å¼ºç”¨æˆ·çš„è¯¯è§£ï¼Œå³ä½¿åŒæ—¶å±•ç¤ºäº†æ­£ç¡®çš„äººç±»è§£é‡Šã€‚è¿™ä¸€å‘ç°å¼ºè°ƒäº†éƒ¨ç½²MADç³»ç»Ÿè¿›è¡Œè™šå‡ä¿¡æ¯å¹²é¢„æ—¢å……æ»¡å¸Œæœ›ä¹Ÿå­˜åœ¨æ½œåœ¨é£é™©ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†ä¸€ä¸ªå…¬å…±ç¤¾åŒºç½‘ç«™ï¼Œå¸®åŠ©ç”¨æˆ·æ¢ç´¢ED2Då¹¶ä¿ƒè¿›é€æ˜åº¦å’Œåä½œäº‹å®æ ¸æŸ¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted to AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07267v2",
      "published_date": "2025-11-10 16:15:53 UTC",
      "updated_date": "2026-01-08 08:15:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:14:18.319066+00:00"
    },
    {
      "arxiv_id": "2511.11654v1",
      "title": "Convergence of Multiagent Learning Systems for Traffic control",
      "title_zh": "äº¤é€šæ§åˆ¶å¤šæ™ºèƒ½ä½“å­¦ä¹ ç³»ç»Ÿçš„æ”¶æ•›æ€§",
      "authors": [
        "Sayambhu Sen",
        "Shalabh Bhatnagar"
      ],
      "abstract": "Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.",
      "tldr_zh": "é’ˆå¯¹å¿«é€ŸåŸå¸‚åŒ–å¯¼è‡´çš„ä¸¥é‡äº¤é€šæ‹¥å µé—®é¢˜ï¼Œå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ (MARL)å·²æˆä¸ºä¼˜åŒ–äº¤é€šä¿¡å·æ§åˆ¶(TSC)çš„ä¸€ç§æœ‰æ•ˆç­–ç•¥ã€‚å°½ç®¡å…ˆå‰ç ”ç©¶å·²åœ¨ç»éªŒä¸Šè¯æ˜äº†å°†æ¯ä¸ªäº¤é€šä¿¡å·ä½œä¸ºç‹¬ç«‹æ™ºèƒ½ä½“ä½¿ç”¨Q-learningå»ºæ¨¡çš„æœ‰æ•ˆæ€§ï¼Œä½†ç¼ºä¹å¯¹å…¶ç¨³å®šæ€§å’Œæ”¶æ•›æ€§çš„ä¸¥æ ¼ç†è®ºåˆ†æã€‚æœ¬æ–‡åˆ©ç”¨éšæœºé€¼è¿‘æ–¹æ³•(stochastic approximation methods)ï¼Œæ­£å¼åˆ†æäº†ç”¨äºåä½œTSCä»»åŠ¡çš„ç‹¬ç«‹å­¦ä¹ è€…çš„å­¦ä¹ åŠ¨åŠ›å­¦ï¼Œå¡«è¡¥äº†è¿™ä¸€ç†è®ºç©ºç™½ã€‚è¯¥ç ”ç©¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºè¯æ˜äº†è¿™ç§ç‰¹å®šçš„äº¤é€šæ§åˆ¶å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•åœ¨ç»™å®šæ¡ä»¶ä¸‹æ˜¯æ”¶æ•›çš„ã€‚è¿™ä¸€è¯æ˜å°†é’ˆå¯¹å¼‚æ­¥å€¼è¿­ä»£(asynchronous value iteration)çš„å•æ™ºèƒ½ä½“æ”¶æ•›æ€§è¯æ˜æ‰©å±•åˆ°äº†å¤šæ™ºèƒ½ä½“äº¤é€šæ§åˆ¶åœºæ™¯ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.11654v1",
      "published_date": "2025-11-10 16:10:20 UTC",
      "updated_date": "2025-11-10 16:10:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:14:39.309736+00:00"
    },
    {
      "arxiv_id": "2511.07262v1",
      "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
      "title_zh": "AgenticSciMLï¼šé¢å‘ç§‘å­¦æœºå™¨å­¦ä¹ æ¶Œç°æ€§å‘ç°çš„ååŒå¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Qile Jiang",
        "George Karniadakis"
      ],
      "abstract": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AgenticSciMLï¼Œä¸€ç§æ—¨åœ¨è§£å†³Scientific Machine Learning (SciML)é¢†åŸŸå¤æ‚é—®é¢˜è®¾è®¡çš„åä½œå¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚é’ˆå¯¹SciMLæ¶æ„å’Œè®­ç»ƒç­–ç•¥é€šå¸¸ä¾èµ–ä¸“å®¶ç»éªŒçš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è¶…è¿‡10ä¸ªä¸“ä¸šAIæ™ºèƒ½ä½“ï¼Œé€šè¿‡ç»“æ„åŒ–è¾©è®ºã€æ£€ç´¢å¢å¼ºçš„æ–¹æ³•è®°å¿†ä»¥åŠé›†æˆå¼•å¯¼çš„è¿›åŒ–æœç´¢ï¼Œåä½œæå‡ºã€è¯„ä¼°å¹¶è¿­ä»£ä¼˜åŒ–è§£å†³æ–¹æ¡ˆã€‚åœ¨ç‰©ç†ä¿¡æ¯å­¦ä¹ å’Œç®—å­å­¦ä¹ ä»»åŠ¡çš„æµ‹è¯•ä¸­ï¼ŒAgenticSciMLå‘ç°çš„æ–¹æ³•åœ¨è¯¯å·®é™ä½æ–¹é¢æ¯”å•æ™ºèƒ½ä½“å’Œäººç±»è®¾è®¡çš„åŸºçº¿æ¨¡å‹è¡¨ç°é«˜å‡ºå››ä¸ªæ•°é‡çº§ã€‚æ­¤å¤–ï¼Œæ™ºèƒ½ä½“è¿˜è‡ªä¸»ç”Ÿæˆäº†åŒ…æ‹¬è‡ªé€‚åº”mixture-of-expertæ¶æ„ã€åŸºäºåˆ†è§£çš„PINNsä»¥åŠç‰©ç†ä¿¡æ¯ç®—å­å­¦ä¹ æ¨¡å‹åœ¨å†…çš„æ–°é¢–ç­–ç•¥ï¼Œè€Œè¿™äº›ç­–ç•¥å¹¶æœªæ˜¾å¼åŒ…å«åœ¨åŸæœ‰çŸ¥è¯†åº“ä¸­ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒAIæ™ºèƒ½ä½“é—´çš„åä½œæ¨ç†èƒ½å¤Ÿå¼•å‘æ¶Œç°æ€§çš„æ–¹æ³•è®ºåˆ›æ–°ï¼Œä¸ºå®ç°ç§‘å­¦è®¡ç®—ä¸­å¯æ‰©å±•ã€é€æ˜ä¸”è‡ªä¸»çš„ç§‘å­¦å‘ç°æä¾›äº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07262v1",
      "published_date": "2025-11-10 16:06:33 UTC",
      "updated_date": "2025-11-10 16:06:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:15:07.705771+00:00"
    },
    {
      "arxiv_id": "2511.07260v2",
      "title": "PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork",
      "title_zh": "PADiffï¼šé¢å‘å³å¸­å›¢é˜Ÿåä½œçš„é¢„æµ‹ä¸è‡ªé€‚åº”æ‰©æ•£ç­–ç•¥",
      "authors": [
        "Hohei Chan",
        "Xinzhi Zhang",
        "Antao Xiang",
        "Weinan Zhang",
        "Mengchen Zhao"
      ],
      "abstract": "Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen teammates, which is crucial for many real-world applications. The core challenge of AHT is to develop an ego agent that can predict and adapt to unknown teammates on the fly. Conventional RL-based approaches optimize a single expected return, which often causes policies to collapse into a single dominant behavior, thus failing to capture the multimodal cooperation patterns inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach that captures agent's multimodal behaviors, unlocking its diverse cooperation modes with teammates. However, standard diffusion models lack the ability to predict and adapt in highly non-stationary AHT scenarios. To address this limitation, we propose a novel diffusion-based policy that integrates critical predictive information about teammates into the denoising process. Extensive experiments across three cooperation environments demonstrate that PADiff outperforms existing AHT methods significantly.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Ad hoc teamwork (AHT)åœºæ™¯ä¸­ä¸æœªçŸ¥é˜Ÿå‹åä½œçš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºäº†ä¼ ç»Ÿå¼ºåŒ–å­¦ä¹ (RL)æ–¹æ³•å®¹æ˜“å¯¼è‡´ç­–ç•¥å´©æºƒä¸”éš¾ä»¥æ•æ‰å¤šæ¨¡æ€åˆä½œæ¨¡å¼çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†PADiffï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹(Diffusion Model)çš„ç­–ç•¥ï¼Œæ—¨åœ¨é€šè¿‡æ•æ‰æ™ºèƒ½ä½“çš„å¤šæ¨¡æ€è¡Œä¸ºæ¥è§£é”å¤šæ ·åŒ–çš„åˆä½œæ¨¡å¼ã€‚é’ˆå¯¹æ ‡å‡†æ‰©æ•£æ¨¡å‹åœ¨é«˜åº¦éå¹³ç¨³AHTåœºæ™¯ä¸­é¢„æµ‹å’Œé€‚åº”èƒ½åŠ›çš„ä¸è¶³ï¼ŒPADiffåˆ›æ–°æ€§åœ°å°†å…³äºé˜Ÿå‹çš„å…³é”®é¢„æµ‹ä¿¡æ¯æ•´åˆåˆ°äº†å»å™ªè¿‡ç¨‹ä¸­ã€‚åœ¨ä¸‰ä¸ªä¸åŒåˆä½œç¯å¢ƒä¸‹çš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒPADiffçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„AHTæ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†æ™ºèƒ½ä½“å¯¹æœªçŸ¥é˜Ÿå‹çš„é€‚åº”èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07260v2",
      "published_date": "2025-11-10 16:05:40 UTC",
      "updated_date": "2026-01-19 08:32:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:15:27.319192+00:00"
    },
    {
      "arxiv_id": "2511.07250v2",
      "title": "MVU-Eval: Towards Multi-Video Understanding Evaluation for Multimodal LLMs",
      "title_zh": "MVU-Evalï¼šé¢å‘å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹çš„å¤šè§†é¢‘ç†è§£è¯„ä¼°",
      "authors": [
        "Tianhao Peng",
        "Haochen Wang",
        "Yuanxing Zhang",
        "Zekun Wang",
        "Zili Wang",
        "Gavin Chang",
        "Jian Yang",
        "Shihao Li",
        "Yanghai Wang",
        "Xintao Wang",
        "Houyi Li",
        "Wei Ji",
        "Pengfei Wan",
        "Steven Huang",
        "Zhaoxiang Zhang",
        "Jiaheng Liu"
      ],
      "abstract": "The advent of Multimodal Large Language Models (MLLMs) has expanded AI capabilities to visual modalities, yet existing evaluation benchmarks remain limited to single-video understanding, overlooking the critical need for multi-video understanding in real-world scenarios (e.g., sports analytics and autonomous driving). To address this significant gap, we introduce MVU-Eval, the first comprehensive benchmark for evaluating Multi-Video Understanding for MLLMs. Specifically, our MVU-Eval mainly assesses eight core competencies through 1,824 meticulously curated question-answer pairs spanning 4,959 videos from diverse domains, addressing both fundamental perception tasks and high-order reasoning tasks. These capabilities are rigorously aligned with real-world applications such as multi-sensor synthesis in autonomous systems and cross-angle sports analytics. Through extensive evaluation of state-of-the-art open-source and closed-source models, we reveal significant performance discrepancies and limitations in current MLLMs' ability to perform understanding across multiple videos. The benchmark will be made publicly available to foster future research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å½“å‰å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)è¯„ä¼°åŸºå‡†å±€é™äºå•è§†é¢‘ç†è§£çš„é—®é¢˜ï¼Œæ¨å‡ºäº†MVU-Evalï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨è¯„ä¼°MLLMså¤šè§†é¢‘ç†è§£(Multi-Video Understanding)èƒ½åŠ›çš„ç»¼åˆåŸºå‡†ã€‚è¯¥åŸºå‡†åŒ…å«æ¥è‡ªä¸åŒé¢†åŸŸçš„4,959ä¸ªè§†é¢‘å’Œ1,824ä¸ªç²¾å¿ƒç­–åˆ’çš„é—®ç­”å¯¹ï¼Œé‡ç‚¹è¯„ä¼°æ¶µç›–åŸºç¡€æ„ŸçŸ¥å’Œé«˜é˜¶æ¨ç†çš„å…«é¡¹æ ¸å¿ƒèƒ½åŠ›ã€‚è¿™äº›ä»»åŠ¡è®¾è®¡ä¸è‡ªåŠ¨é©¾é©¶ä¸­çš„å¤šä¼ æ„Ÿå™¨åˆæˆåŠè·¨è§†è§’ä½“è‚²åˆ†æç­‰ç°å®ä¸–ç•Œåº”ç”¨åœºæ™¯ç´§å¯†å¯¹é½ã€‚é€šè¿‡å¯¹å½“å‰æœ€å…ˆè¿›çš„å¼€æºå’Œé—­æºæ¨¡å‹è¿›è¡Œå¹¿æ³›è¯„ä¼°ï¼Œç ”ç©¶æ­ç¤ºäº†ç°æœ‰MLLMsåœ¨å¤„ç†å¤šè§†é¢‘ç†è§£ä»»åŠ¡æ—¶ä»å­˜åœ¨æ˜¾è‘—çš„æ€§èƒ½å·®è·å’Œå±€é™æ€§ã€‚MVU-Evalçš„å‘å¸ƒæ—¨åœ¨å¡«è¡¥è¿™ä¸€å…³é”®é¢†åŸŸçš„ç©ºç™½å¹¶æ¨åŠ¨æœªæ¥çš„ç›¸å…³ç ”ç©¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07250v2",
      "published_date": "2025-11-10 16:02:33 UTC",
      "updated_date": "2025-11-13 12:42:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:15:55.371732+00:00"
    },
    {
      "arxiv_id": "2511.07238v1",
      "title": "Leveraging Text-Driven Semantic Variation for Robust OOD Segmentation",
      "title_zh": "åŸºäºæ–‡æœ¬é©±åŠ¨è¯­ä¹‰å˜åŒ–çš„é²æ£’OODåˆ†å‰²",
      "authors": [
        "Seungheon Song",
        "Jaekoo Lee"
      ],
      "abstract": "In autonomous driving and robotics, ensuring road safety and reliable decision-making critically depends on out-of-distribution (OOD) segmentation. While numerous methods have been proposed to detect anomalous objects on the road, leveraging the vision-language space-which provides rich linguistic knowledge-remains an underexplored field. We hypothesize that incorporating these linguistic cues can be especially beneficial in the complex contexts found in real-world autonomous driving scenarios.\n  To this end, we present a novel approach that trains a Text-Driven OOD Segmentation model to learn a semantically diverse set of objects in the vision-language space. Concretely, our approach combines a vision-language model's encoder with a transformer decoder, employs Distance-Based OOD prompts located at varying semantic distances from in-distribution (ID) classes, and utilizes OOD Semantic Augmentation for OOD representations. By aligning visual and textual information, our approach effectively generalizes to unseen objects and provides robust OOD segmentation in diverse driving environments.\n  We conduct extensive experiments on publicly available OOD segmentation datasets such as Fishyscapes, Segment-Me-If-You-Can, and Road Anomaly datasets, demonstrating that our approach achieves state-of-the-art performance across both pixel-level and object-level evaluations. This result underscores the potential of vision-language-based OOD segmentation to bolster the safety and reliability of future autonomous driving systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶å’Œæœºå™¨äººé¢†åŸŸä¸­è‡³å…³é‡è¦çš„åˆ†å¸ƒå¤–(OOD)åˆ†å‰²é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨è§†è§‰-è¯­è¨€ç©ºé—´ä¸°å¯Œè¯­è¨€çŸ¥è¯†çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†ä¸€ä¸ªæ–‡æœ¬é©±åŠ¨çš„OODåˆ†å‰²æ¨¡å‹(Text-Driven OOD Segmentation model)ï¼Œç»“åˆäº†è§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„ç¼–ç å™¨ä¸Transformerè§£ç å™¨ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†åŸºäºè·ç¦»çš„OODæç¤º(Distance-Based OOD prompts)ï¼Œè¿™äº›æç¤ºä½äºä¸åˆ†å¸ƒå†…(ID)ç±»åˆ«ä¸åŒçš„è¯­ä¹‰è·ç¦»å¤„ï¼Œå¹¶åˆ©ç”¨OODè¯­ä¹‰å¢å¼º(OOD Semantic Augmentation)æ¥ç”ŸæˆOODè¡¨ç¤ºã€‚é€šè¿‡å¯¹é½è§†è§‰å’Œæ–‡æœ¬ä¿¡æ¯ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆæ³›åŒ–åˆ°æœªè§è¿‡çš„ç‰©ä½“ï¼Œå¹¶åœ¨å¤æ‚çš„é©¾é©¶ç¯å¢ƒä¸­æä¾›é²æ£’çš„åˆ†å‰²ç»“æœã€‚åœ¨Fishyscapesã€Segment-Me-If-You-Canå’ŒRoad Anomalyç­‰å…¬å¼€æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åƒç´ çº§å’Œå¯¹è±¡çº§è¯„ä¼°ä¸­å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼Œè¯å®äº†åŸºäºè§†è§‰è¯­è¨€çš„OODåˆ†å‰²æŠ€æœ¯åœ¨æå‡è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿå®‰å…¨æ€§æ–¹é¢çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figure references, 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) submission",
      "pdf_url": "https://arxiv.org/pdf/2511.07238v1",
      "published_date": "2025-11-10 15:54:23 UTC",
      "updated_date": "2025-11-10 15:54:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:16:19.027129+00:00"
    },
    {
      "arxiv_id": "2511.07499v1",
      "title": "Toward the Frontiers of Reliable Diffusion Sampling via Adversarial Sinkhorn Attention Guidance",
      "title_zh": "åŸºäºå¯¹æŠ—æ€§ Sinkhorn æ³¨æ„åŠ›å¼•å¯¼è¿ˆå‘å¯é æ‰©æ•£é‡‡æ ·çš„å‰æ²¿",
      "authors": [
        "Kwanyoung Kim"
      ],
      "abstract": "Diffusion models have demonstrated strong generative performance when using guidance methods such as classifier-free guidance (CFG), which enhance output quality by modifying the sampling trajectory. These methods typically improve a target output by intentionally degrading another, often the unconditional output, using heuristic perturbation functions such as identity mixing or blurred conditions. However, these approaches lack a principled foundation and rely on manually designed distortions. In this work, we propose Adversarial Sinkhorn Attention Guidance (ASAG), a novel method that reinterprets attention scores in diffusion models through the lens of optimal transport and intentionally disrupt the transport cost via Sinkhorn algorithm. Instead of naively corrupting the attention mechanism, ASAG injects an adversarial cost within self-attention layers to reduce pixel-wise similarity between queries and keys. This deliberate degradation weakens misleading attention alignments and leads to improved conditional and unconditional sample quality. ASAG shows consistent improvements in text-to-image diffusion, and enhances controllability and fidelity in downstream applications such as IP-Adapter and ControlNet. The method is lightweight, plug-and-play, and improves reliability without requiring any model retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹ä¸­ç°æœ‰çš„å¼•å¯¼æ–¹æ³•ï¼ˆå¦‚Classifier-Free Guidance, CFGï¼‰ä¾èµ–ç¼ºä¹ç†è®ºåŸºç¡€çš„äººå·¥è®¾è®¡æ‰°åŠ¨è¿™ä¸€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºAdversarial Sinkhorn Attention Guidance (ASAG)çš„æ–°æ–¹æ³•ã€‚ASAGé€šè¿‡æœ€ä¼˜ä¼ è¾“ï¼ˆOptimal Transportï¼‰çš„è§†è§’é‡æ–°è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼Œåˆ©ç”¨Sinkhornç®—æ³•å¼•å…¥å¯¹æŠ—æ€§æˆæœ¬æ¥å¹²æ‰°ä¼ è¾“è¿‡ç¨‹ã€‚ä¸åŒäºç®€å•çš„ç ´åæ³¨æ„åŠ›æœºåˆ¶ï¼ŒASAGåœ¨è‡ªæ³¨æ„åŠ›å±‚ä¸­æ³¨å…¥å¯¹æŠ—æ€§æˆæœ¬ä»¥é™ä½æŸ¥è¯¢ï¼ˆQueriesï¼‰ä¸é”®ï¼ˆKeysï¼‰ä¹‹é—´çš„åƒç´ çº§ç›¸ä¼¼åº¦ï¼Œä»è€Œå‰Šå¼±è¯¯å¯¼æ€§çš„æ³¨æ„åŠ›å¯¹é½å¹¶æå‡ç”Ÿæˆè´¨é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒASAGåœ¨æ–‡ç”Ÿå›¾ä»»åŠ¡ä¸­è¡¨ç°å‡ºæŒç»­çš„æ”¹è¿›ï¼Œå¹¶å¢å¼ºäº†IP-Adapterå’ŒControlNetç­‰ä¸‹æ¸¸åº”ç”¨çš„å¯æ§æ€§ä¸ä¿çœŸåº¦ã€‚ä½œä¸ºä¸€ç§æ— éœ€é‡æ–°è®­ç»ƒæ¨¡å‹çš„è½»é‡çº§å³æ’å³ç”¨æ–¹æ³•ï¼ŒASAGæœ‰æ•ˆæå‡äº†æ‰©æ•£æ¨¡å‹é‡‡æ ·çš„å¯é æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 26",
      "pdf_url": "https://arxiv.org/pdf/2511.07499v1",
      "published_date": "2025-11-10 15:52:53 UTC",
      "updated_date": "2025-11-10 15:52:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:16:50.706289+00:00"
    },
    {
      "arxiv_id": "2511.07230v1",
      "title": "Discourse Graph Guided Document Translation with Large Language Models",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç¯‡ç« å›¾å¼•å¯¼æ–‡æ¡£ç¿»è¯‘",
      "authors": [
        "Viet-Thanh Pham",
        "Minghan Wang",
        "Hao-Han Liao",
        "Thuy-Trang Vu"
      ],
      "abstract": "Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å…¨æ–‡æ¡£ç¿»è¯‘ä¸­éš¾ä»¥æ•æ‰é•¿è·ç¦»ä¾èµ–å’Œä¿æŒç¯‡ç« è¿è´¯æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†TransGraphæ¡†æ¶ã€‚ç°æœ‰çš„ä»£ç†æœºå™¨ç¿»è¯‘ç³»ç»Ÿè™½ç„¶èƒ½ç¼“è§£ä¸Šä¸‹æ–‡é™åˆ¶ï¼Œä½†è®¡ç®—èµ„æºæ¶ˆè€—å¤§ä¸”å¯¹æ£€ç´¢ç­–ç•¥æ•æ„Ÿã€‚TransGraphé€šè¿‡ç»“æ„åŒ–çš„discourse graphsæ˜¾å¼å»ºæ¨¡æ–‡æœ¬å—é—´çš„å…³ç³»ï¼Œå¹¶åŸºäºç›¸å…³çš„å›¾é‚»åŸŸè€Œéå•çº¯çš„é¡ºåºä¸Šä¸‹æ–‡æ¥å¼•å¯¼ç¿»è¯‘ç‰‡æ®µçš„ç”Ÿæˆã€‚åœ¨æ¶µç›–å…­ç§è¯­è¨€å’Œå¤šé¢†åŸŸçš„ä¸‰ä¸ªæ–‡æ¡£çº§æœºå™¨ç¿»è¯‘åŸºå‡†æµ‹è¯•ä¸­ï¼ŒTransGraphåœ¨ç¿»è¯‘è´¨é‡å’Œæœ¯è¯­ä¸€è‡´æ€§æ–¹é¢å‡è¶…è¶Šäº†å¼ºåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜æ˜¾è‘—é™ä½äº†tokenå¼€é”€ï¼Œå®ç°äº†æ›´é«˜æ•ˆçš„æ–‡æ¡£ç¿»è¯‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07230v1",
      "published_date": "2025-11-10 15:48:01 UTC",
      "updated_date": "2025-11-10 15:48:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:17:31.916751+00:00"
    },
    {
      "arxiv_id": "2511.07229v1",
      "title": "LLMServingSim2.0: A Unified Simulator for Heterogeneous Hardware and Serving Techniques in LLM Infrastructure",
      "title_zh": "LLMServingSim2.0ï¼šé¢å‘LLMåŸºç¡€è®¾æ–½å¼‚æ„ç¡¬ä»¶ä¸æœåŠ¡æŠ€æœ¯çš„ç»Ÿä¸€ä»¿çœŸå™¨",
      "authors": [
        "Jaehong Cho",
        "Hyunmin Choi",
        "Jongse Park"
      ],
      "abstract": "This paper introduces LLMServingSim2.0, a system simulator designed for exploring heterogeneous hardware in large-scale LLM serving systems. LLMServingSim2.0 addresses two key limitations of its predecessor: (1) integrating hardware models into system-level simulators is non-trivial due to the lack of a clear abstraction, and (2) existing simulators support only a narrow subset of serving techniques, leaving no infrastructure that captures the breadth of approaches in modern LLM serving. To overcome these issues, LLMServingSim2.0 adopts trace-driven performance modeling, accompanied by an operator-level latency profiler, enabling the integration of new accelerators with a single command. It further embeds up-to-date serving techniques while exposing flexible interfaces for request routing, cache management, and scheduling policies. In a TPU case study, our profiler requires 18.5x fewer LoC and outperforms the predecessor's hardware-simulator integration, demonstrating LLMServingSim2.0's low-effort hardware extensibility. Our experiments further show that LLMServingSim2.0 reproduces GPU-based LLM serving with 1.9% error, while maintaining practical simulation time, making it a comprehensive platform for both hardware developers and LLM service providers.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†LLMServingSim2.0ï¼Œä¸€ç§ä¸“ä¸ºåœ¨å¤§è§„æ¨¡LLMæœåŠ¡ç³»ç»Ÿä¸­æ¢ç´¢å¼‚æ„ç¡¬ä»¶è€Œè®¾è®¡çš„ç³»ç»Ÿæ¨¡æ‹Ÿå™¨ã€‚è¯¥ç³»ç»Ÿè§£å†³äº†å‰ä»£æ¨¡æ‹Ÿå™¨åœ¨ç¡¬ä»¶æ¨¡å‹é›†æˆç¼ºä¹æ¸…æ™°æŠ½è±¡ä»¥åŠæ”¯æŒæœåŠ¡æŠ€æœ¯èŒƒå›´ç‹­çª„è¿™ä¸¤ä¸ªå…³é”®å±€é™ã€‚LLMServingSim2.0é‡‡ç”¨äº†trace-driven performance modelingå’Œoperator-level latency profilerï¼Œä»…éœ€å•æ¡å‘½ä»¤å³å¯é›†æˆæ–°çš„åŠ é€Ÿå™¨ï¼Œæå¤§åœ°é™ä½äº†ç¡¬ä»¶æ‰©å±•çš„éš¾åº¦ã€‚åŒæ—¶ï¼Œå®ƒåµŒå…¥äº†æœ€æ–°çš„æœåŠ¡æŠ€æœ¯ï¼Œå¹¶ä¸ºrequest routingã€cache managementå’Œè°ƒåº¦ç­–ç•¥æä¾›äº†çµæ´»çš„æ¥å£ã€‚TPUæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ï¼Œè¯¥å·¥å…·çš„é›†æˆä»£ç é‡ï¼ˆLoCï¼‰å‡å°‘äº†18.5å€ï¼Œä¸”å±•ç°äº†ä½æˆæœ¬çš„ç¡¬ä»¶æ‰©å±•æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒLLMServingSim2.0åœ¨å¤ç°åŸºäºGPUçš„LLMæœåŠ¡æ—¶è¯¯å·®ä»…ä¸º1.9%ï¼ŒåŒæ—¶ä¿æŒäº†å®ç”¨çš„æ¨¡æ‹Ÿæ—¶é—´ï¼Œä½¿å…¶æˆä¸ºç¡¬ä»¶å¼€å‘è€…å’ŒLLMæœåŠ¡æä¾›å•†çš„ä¸€ä¸ªå…¨é¢ä¸”é«˜æ•ˆçš„å¹³å°ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "4 pages, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.07229v1",
      "published_date": "2025-11-10 15:47:53 UTC",
      "updated_date": "2025-11-10 15:47:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:17:58.667213+00:00"
    },
    {
      "arxiv_id": "2511.07223v1",
      "title": "NoteEx: Interactive Visual Context Manipulation for LLM-Assisted Exploratory Data Analysis in Computational Notebooks",
      "title_zh": "NoteExï¼šè®¡ç®—ç¬”è®°æœ¬ä¸­é¢å‘LLMè¾…åŠ©æ¢ç´¢æ€§æ•°æ®åˆ†æçš„äº¤äº’å¼å¯è§†åŒ–ä¸Šä¸‹æ–‡æ“ä½œ",
      "authors": [
        "Mohammad Hasan Payandeh",
        "Lin-Ping Yuan",
        "Jian Zhao"
      ],
      "abstract": "Computational notebooks have become popular for Exploratory Data Analysis (EDA), augmented by LLM-based code generation and result interpretation. Effective LLM assistance hinges on selecting informative context -- the minimal set of cells whose code, data, or outputs suffice to answer a prompt. As notebooks grow long and messy, users can lose track of the mental model of their analysis. They thus fail to curate appropriate contexts for LLM tasks, causing frustration and tedious prompt engineering. We conducted a formative study (n=6) that surfaced challenges in LLM context selection and mental model maintenance. Therefore, we introduce NoteEx, a JupyterLab extension that provides a semantic visualization of the EDA workflow, allowing analysts to externalize their mental model, specify analysis dependencies, and enable interactive selection of task-relevant contexts for LLMs. A user study (n=12) against a baseline shows that NoteEx improved mental model retention and context selection, leading to more accurate and relevant LLM responses.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—ç¬”è®°æœ¬ä¸­åˆ©ç”¨LLMè¿›è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æ(Exploratory Data Analysis, EDA)æ—¶é¢ä¸´çš„ä¸Šä¸‹æ–‡é€‰æ‹©éš¾é¢˜ï¼Œæå‡ºäº†NoteExã€‚ç”±äºç¬”è®°æœ¬å†…å®¹å¾€å¾€å†—é•¿ä¸”æ‚ä¹±ï¼Œç”¨æˆ·éš¾ä»¥ç»´æŠ¤åˆ†æçš„å¿ƒæ™ºæ¨¡å‹ï¼Œå¯¼è‡´æ— æ³•ä¸ºLLMç­›é€‰å‡ºåŒ…å«ä»£ç ã€æ•°æ®æˆ–è¾“å‡ºçš„æœ€å°æœ‰æ•ˆä¸Šä¸‹æ–‡é›†åˆï¼Œä»è€Œå½±å“è¾…åŠ©æ•ˆæœã€‚ä½œè€…é¦–å…ˆé€šè¿‡ä¸€é¡¹å½¢æˆæ€§ç ”ç©¶æ­ç¤ºäº†ä¸Šä¸‹æ–‡é€‰æ‹©å’Œå¿ƒæ™ºæ¨¡å‹ç»´æŠ¤æ–¹é¢çš„æŒ‘æˆ˜ã€‚NoteExä½œä¸ºä¸€ä¸ªJupyterLabæ‰©å±•ï¼Œæä¾›äº†EDAå·¥ä½œæµçš„è¯­ä¹‰å¯è§†åŒ–åŠŸèƒ½ï¼Œå…è®¸åˆ†æå¸ˆå¤–åŒ–å…¶å¿ƒæ™ºæ¨¡å‹ã€æŒ‡å®šåˆ†æä¾èµ–å…³ç³»ï¼Œå¹¶äº¤äº’å¼åœ°é€‰æ‹©ä¸ä»»åŠ¡ç›¸å…³çš„ä¸Šä¸‹æ–‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œç”¨æˆ·èƒ½å¤Ÿæ›´ç²¾å‡†åœ°å¼•å¯¼LLMå®Œæˆä»£ç ç”Ÿæˆå’Œç»“æœè§£é‡Šä»»åŠ¡ã€‚ä¸€é¡¹åŒ…å«12åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œç›¸è¾ƒäºåŸºçº¿ï¼ŒNoteExæ˜¾è‘—æ”¹å–„äº†ç”¨æˆ·çš„å¿ƒæ™ºæ¨¡å‹ä¿æŒèƒ½åŠ›å’Œä¸Šä¸‹æ–‡é€‰æ‹©æ•ˆç‡ï¼Œè¿›è€Œè·å¾—äº†æ›´å‡†ç¡®ä¸”ç›¸å…³çš„LLMå“åº”ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07223v1",
      "published_date": "2025-11-10 15:44:55 UTC",
      "updated_date": "2025-11-10 15:44:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:18:19.634590+00:00"
    },
    {
      "arxiv_id": "2511.07208v1",
      "title": "SMiLE: Provably Enforcing Global Relational Properties in Neural Networks",
      "title_zh": "SMiLEï¼šå¯è¯æ˜åœ°å¼ºåˆ¶ç¥ç»ç½‘ç»œä¸­çš„å…¨å±€å…³ç³»æ€§è´¨",
      "authors": [
        "Matteo Francobaldi",
        "Michele Lombardi",
        "Andrea Lodi"
      ],
      "abstract": "Artificial Intelligence systems are increasingly deployed in settings where ensuring robustness, fairness, or domain-specific properties is essential for regulation compliance and alignment with human values. However, especially on Neural Networks, property enforcement is very challenging, and existing methods are limited to specific constraints or local properties (defined around datapoints), or fail to provide full guarantees. We tackle these limitations by extending SMiLE, a recently proposed enforcement framework for NNs, to support global relational properties (defined over the entire input space). The proposed approach scales well with model complexity, accommodates general properties and backbones, and provides full satisfaction guarantees. We evaluate SMiLE on monotonicity, global robustness, and individual fairness, on synthetic and real data, for regression and classification tasks. Our approach is competitive with property-specific baselines in terms of accuracy and runtime, and strictly superior in terms of generality and level of guarantees. Overall, our results emphasize the potential of the SMiLE framework as a platform for future research and applications.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶è§£å†³äº†åœ¨ç¥ç»ç½‘ç»œä¸­å¼ºåˆ¶æ‰§è¡Œé²æ£’æ€§ã€å…¬å¹³æ€§ç­‰å±æ€§çš„æŒ‘æˆ˜ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹ç°æœ‰æ–¹æ³•å±€é™äºå±€éƒ¨å±æ€§æˆ–ç¼ºä¹å®Œå…¨ä¿è¯çš„é—®é¢˜ã€‚ä½œè€…æ‰©å±•äº†SMiLEæ¡†æ¶ï¼Œä½¿å…¶æ”¯æŒå®šä¹‰åœ¨æ•´ä¸ªè¾“å…¥ç©ºé—´ä¸Šçš„å…¨å±€å…³ç³»å±æ€§(global relational properties)ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿé€‚åº”æ¨¡å‹å¤æ‚åº¦çš„æ‰©å±•ï¼Œæ”¯æŒé€šç”¨çš„å±æ€§å’Œéª¨å¹²ç½‘ç»œï¼Œå¹¶æä¾›å®Œå…¨çš„æ»¡è¶³ä¿è¯ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨å•è°ƒæ€§(monotonicity)ã€å…¨å±€é²æ£’æ€§(global robustness)å’Œä¸ªä½“å…¬å¹³æ€§(individual fairness)ç­‰ä»»åŠ¡ä¸Šï¼Œåˆ©ç”¨åˆæˆæ•°æ®å’ŒçœŸå®æ•°æ®è¿›è¡Œäº†å›å½’å’Œåˆ†ç±»è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSMiLEåœ¨å‡†ç¡®æ€§å’Œè¿è¡Œæ—¶é—´ä¸Šä¸ç‰¹å®šå±æ€§çš„åŸºçº¿æ¨¡å‹ç›¸å½“ï¼Œä½†åœ¨é€šç”¨æ€§å’Œä¿è¯æ°´å¹³ä¸Šå…·æœ‰æ˜æ˜¾ä¼˜åŠ¿ï¼Œå±•ç¤ºäº†å…¶ä½œä¸ºæœªæ¥ç ”ç©¶å’Œåº”ç”¨å¹³å°çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07208v1",
      "published_date": "2025-11-10 15:33:32 UTC",
      "updated_date": "2025-11-10 15:33:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:21:55.750615+00:00"
    },
    {
      "arxiv_id": "2511.07205v1",
      "title": "Twenty-Five Years of MIR Research: Achievements, Practices, Evaluations, and Future Challenges",
      "title_zh": "MIR ç ”ç©¶äºŒåäº”å¹´ï¼šæˆå°±ã€å®è·µã€è¯„ä¼°ä¸æœªæ¥æŒ‘æˆ˜",
      "authors": [
        "Geoffroy Peeters",
        "Zafar Rafii",
        "Magdalena Fuentes",
        "Zhiyao Duan",
        "Emmanouil Benetos",
        "Juhan Nam",
        "Yuki Mitsufuji"
      ],
      "abstract": "In this paper, we trace the evolution of Music Information Retrieval (MIR) over the past 25 years. While MIR gathers all kinds of research related to music informatics, a large part of it focuses on signal processing techniques for music data, fostering a close relationship with the IEEE Audio and Acoustic Signal Processing Technical Commitee. In this paper, we reflect the main research achievements of MIR along the three EDICS related to music analysis, processing and generation. We then review a set of successful practices that fuel the rapid development of MIR research. One practice is the annual research benchmark, the Music Information Retrieval Evaluation eXchange, where participants compete on a set of research tasks. Another practice is the pursuit of reproducible and open research. The active engagement with industry research and products is another key factor for achieving large societal impacts and motivating younger generations of students to join the field. Last but not the least, the commitment to diversity, equity and inclusion ensures MIR to be a vibrant and open community where various ideas, methodologies, and career pathways collide. We finish by providing future challenges MIR will have to face.",
      "tldr_zh": "è¯¥è®ºæ–‡å›é¡¾äº†è¿‡å»25å¹´Music Information Retrieval (MIR)é¢†åŸŸçš„æ¼”å˜å†ç¨‹ï¼Œé‡ç‚¹å…³æ³¨äº†é’ˆå¯¹éŸ³ä¹æ•°æ®çš„ä¿¡å·å¤„ç†æŠ€æœ¯åŠå…¶ä¸IEEEéŸ³é¢‘å’Œå£°å­¦ä¿¡å·å¤„ç†æŠ€æœ¯å§”å‘˜ä¼šçš„ç´§å¯†è”ç³»ã€‚æ–‡ç« é¦–å…ˆæ€»ç»“äº†MIRåœ¨éŸ³ä¹åˆ†æã€å¤„ç†å’Œç”Ÿæˆè¿™ä¸‰ä¸ªEDICSæ–¹å‘ä¸Šçš„ä¸»è¦ç ”ç©¶æˆå°±ã€‚éšåï¼Œä½œè€…å›é¡¾äº†æ¨åŠ¨è¯¥é¢†åŸŸå¿«é€Ÿå‘å±•çš„å…³é”®å®è·µï¼ŒåŒ…æ‹¬å¹´åº¦åŸºå‡†æµ‹è¯•Music Information Retrieval Evaluation eXchange (MIREX)ã€å¯¹å¯å¤ç°å’Œå¼€æ”¾ç ”ç©¶çš„è¿½æ±‚ï¼Œä»¥åŠä¸å·¥ä¸šç•Œçš„ç§¯æäº’åŠ¨ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜å¼ºè°ƒäº†ç¤¾åŒºå¯¹å¤šæ ·æ€§ã€å…¬å¹³å’ŒåŒ…å®¹æ€§çš„æ‰¿è¯ºï¼Œè¿™ç¡®ä¿äº†MIRç¤¾åŒºçš„æ´»åŠ›ä¸å¼€æ”¾æ€§ã€‚æœ€åï¼Œè®ºæ–‡å±•æœ›äº†MIRé¢†åŸŸæœªæ¥å°†é¢ä¸´çš„æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07205v1",
      "published_date": "2025-11-10 15:32:23 UTC",
      "updated_date": "2025-11-10 15:32:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:21:56.387036+00:00"
    },
    {
      "arxiv_id": "2511.07204v1",
      "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations",
      "title_zh": "åŸºäº LLM é©±åŠ¨çš„åäº‹å®æ¨¡æ‹Ÿè¯„ä¼°åœ¨çº¿å®¡æ ¸",
      "authors": [
        "Giacomo Fidone",
        "Lucia Passaro",
        "Riccardo Guidotti"
      ],
      "abstract": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨çº¿ç¤¾äº¤ç½‘ç»œ(OSNs)å†…å®¹å®¡æ ¸æ•ˆæœéš¾ä»¥è¯„ä¼°çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„åäº‹å®æ¨¡æ‹Ÿè¯„ä¼°æ–¹æ³•ã€‚ç ”ç©¶è€…è®¾è®¡äº†ä¸€ä¸ªLLMé©±åŠ¨çš„æ¨¡æ‹Ÿå™¨ï¼Œé€šè¿‡å¢å¼ºåŸºäºä»£ç†çš„å»ºæ¨¡(Agent-Based Modeling)æ¥æ¨¡æ‹Ÿå…·æœ‰é«˜åº¦å¯ä¿¡åº¦çš„ç±»äººç¤¾äº¤è¡Œä¸ºã€‚è¯¥ç³»ç»Ÿèƒ½å¤Ÿå¯¹OSNå¯¹è¯è¿›è¡Œå¹¶è¡Œçš„åäº‹å®æ¨¡æ‹Ÿ(counterfactual simulation)ï¼Œåœ¨æ§åˆ¶å…¶ä»–å˜é‡ä¸å˜çš„å‰æä¸‹ï¼Œåˆ†æå®¡æ ¸å¹²é¢„å¦‚ä½•å½±å“æœ‰å®³è¡Œä¸ºã€‚å¹¿æ³›çš„å®éªŒä¸ä»…éªŒè¯äº†ä»£ç†çš„å¿ƒç†çœŸå®æ€§å’Œç¤¾ä¼šä¼ æŸ“(social contagion)ç°è±¡çš„æ¶Œç°ï¼Œè¿˜è¯å®äº†ä¸ªæ€§åŒ–å®¡æ ¸ç­–ç•¥ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å…·æœ‰æ›´ä¼˜è¶Šçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at AAAI Conference on Artificial Intelligence 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07204v1",
      "published_date": "2025-11-10 15:31:59 UTC",
      "updated_date": "2025-11-10 15:31:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:22:13.285778+00:00"
    },
    {
      "arxiv_id": "2511.07202v2",
      "title": "Resilient by Design -- Active Inference for Distributed Continuum Intelligence",
      "title_zh": "è®¾è®¡è‡´éŸ§â€”â€”é¢å‘åˆ†å¸ƒå¼è¿ç»­ä½“æ™ºèƒ½çš„ä¸»åŠ¨æ¨ç†",
      "authors": [
        "Praveen Kumar Donta",
        "Alfreds Lapkovskis",
        "Enzo Mingozzi",
        "Schahram Dustdar"
      ],
      "abstract": "Failures are the norm in highly complex and heterogeneous devices spanning the distributed computing continuum (DCC), from resource-constrained IoT and edge nodes to high-performance computing systems. Ensuring reliability and global consistency across these layers remains a major challenge, especially for AI-driven workloads requiring real-time, adaptive coordination. This work-in-progress paper introduces a Probabilistic Active Inference Resilience Agent (PAIR-Agent) to achieve resilience in DCC systems. PAIR-Agent performs three core operations: (i) constructing a causal fault graph from device logs, (ii) identifying faults while managing certainties and uncertainties using Markov blankets and the free energy principle, and (iii) autonomously healing issues through active inference. Through continuous monitoring and adaptive reconfiguration, the agent maintains service continuity and stability under diverse failure conditions. Theoretical validations confirm the reliability and effectiveness of the proposed framework.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å¸ƒå¼è®¡ç®—è¿ç»­ä½“(Distributed Computing Continuum, DCC)ä¸­é«˜åº¦å¤æ‚å’Œå¼‚æ„è®¾å¤‡å¸¸æ€åŒ–çš„æ•…éšœé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ¦‚ç‡ä¸»åŠ¨æ¨ç†å¼¹æ€§ä»£ç†(PAIR-Agent)ä»¥å®ç°ç³»ç»Ÿå¼¹æ€§ã€‚è¯¥ä»£ç†ç‰¹åˆ«é€‚ç”¨äºéœ€è¦å®æ—¶è‡ªé€‚åº”åè°ƒçš„AIé©±åŠ¨å·¥ä½œè´Ÿè½½ï¼Œæ—¨åœ¨ç¡®ä¿è·¨å±‚çº§çš„å¯é æ€§å’Œå…¨å±€ä¸€è‡´æ€§ã€‚PAIR-Agenté€šè¿‡ä¸‰ä¸ªæ ¸å¿ƒæ“ä½œå‘æŒ¥ä½œç”¨ï¼šé¦–å…ˆä»è®¾å¤‡æ—¥å¿—æ„å»ºå› æœæ•…éšœå›¾ï¼Œå…¶æ¬¡åˆ©ç”¨é©¬å°”å¯å¤«æ¯¯(Markov blankets)å’Œè‡ªç”±èƒ½åŸç†(free energy principle)åœ¨ç®¡ç†ä¸ç¡®å®šæ€§çš„åŒæ—¶è¯†åˆ«æ•…éšœï¼Œæœ€åé€šè¿‡ä¸»åŠ¨æ¨ç†(active inference)è‡ªä¸»ä¿®å¤é—®é¢˜ã€‚é€šè¿‡æŒç»­ç›‘æ§å’Œè‡ªé€‚åº”é‡æ„ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿåœ¨å¤šç§æ•…éšœæ¡ä»¶ä¸‹ç»´æŒæœåŠ¡çš„è¿ç»­æ€§å’Œç¨³å®šæ€§ï¼Œç†è®ºéªŒè¯ä¹Ÿç¡®è®¤äº†è¯¥æ¡†æ¶çš„å¯é æ€§å’Œæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07202v2",
      "published_date": "2025-11-10 15:30:44 UTC",
      "updated_date": "2025-11-18 10:23:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T20:22:38.698017+00:00"
    },
    {
      "arxiv_id": "2511.11653v1",
      "title": "GroupRank: A Groupwise Reranking Paradigm Driven by Reinforcement Learning",
      "title_zh": "GroupRankï¼šå¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„åˆ†ç»„é‡æ’åºèŒƒå¼",
      "authors": [
        "Duolin Sun",
        "Meixiu Long",
        "Dan Yang",
        "Yihan Jiao",
        "Zhehao Tan",
        "Jie Feng",
        "Junjie Wang",
        "Yue Shen",
        "Peng Wei",
        "Jian Wang",
        "Jinjie Gu"
      ],
      "abstract": "Large Language Models have shown strong potential as rerankers to enhance the overall performance of RAG systems. However, existing reranking paradigms are constrained by a core theoretical and practical dilemma: Pointwise methods, while simple and highly flexible, evaluate documents independently, making them prone to the Ranking Myopia Trap, overlooking the relative importance between documents. In contrast, Listwise methods can perceive the global ranking context, but suffer from inherent List Rigidity, leading to severe scalability and flexibility issues when handling large candidate sets. To address these challenges, we propose Groupwise, a novel reranking paradigm. In this approach, the query and a group of candidate documents are jointly fed into the model, which performs within-group comparisons to assign individual relevance scores to each document. This design retains the flexibility of Pointwise methods while enabling the comparative capability of Listwise methods. We further adopt GRPO for model training, equipped with a heterogeneous reward function that integrates ranking metrics with a distributional reward aimed at aligning score distributions across groups. To overcome the bottleneck caused by the scarcity of high quality labeled data, we further propose an innovative pipeline for synthesizing high quality retrieval and ranking data. The resulting data can be leveraged not only for training the reranker but also for training the retriever. Extensive experiments validate the effectiveness of our approach. On two reasoning intensive retrieval benchmarks, BRIGHT and R2MED.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GroupRankï¼Œä¸€ç§ç”±å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„Groupwiseé‡æ’åºèŒƒå¼ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰RAGç³»ç»Ÿä¸­Pointwiseæ–¹æ³•é¢ä¸´çš„Ranking Myopia Trapå’ŒListwiseæ–¹æ³•å­˜åœ¨çš„List Rigidityé—®é¢˜ã€‚Groupwiseæ–¹æ³•å°†æŸ¥è¯¢å’Œä¸€ç»„å€™é€‰æ–‡æ¡£å…±åŒè¾“å…¥æ¨¡å‹ï¼Œé€šè¿‡ç»„å†…æ¯”è¾ƒä¸ºæ¯ä¸ªæ–‡æ¡£åˆ†é…ç›¸å…³æ€§åˆ†æ•°ï¼Œä»è€Œåœ¨ä¿ç•™Pointwiseçµæ´»æ€§çš„åŒæ—¶å®ç°äº†Listwiseçš„æ¯”è¾ƒèƒ½åŠ›ã€‚è¯¥æ¨¡å‹é‡‡ç”¨GRPOè¿›è¡Œè®­ç»ƒï¼Œé…å¤‡äº†ç»“åˆæ’åæŒ‡æ ‡ä¸æ—¨åœ¨å¯¹é½ç»„é—´åˆ†æ•°åˆ†å¸ƒçš„å¼‚æ„å¥–åŠ±å‡½æ•°ã€‚æ­¤å¤–ï¼Œä¸ºäº†å…‹æœé«˜è´¨é‡æ ‡æ³¨æ•°æ®ç¨€ç¼ºçš„ç“¶é¢ˆï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§åˆ›æ–°çš„pipelineç”¨äºåˆæˆé«˜è´¨é‡çš„æ£€ç´¢å’Œæ’åæ•°æ®ã€‚åœ¨BRIGHTå’ŒR2MEDä¸¤ä¸ªæ¨ç†å¯†é›†å‹æ£€ç´¢åŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11653v1",
      "published_date": "2025-11-10 15:25:31 UTC",
      "updated_date": "2025-11-10 15:25:31 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:53:54.624696+00:00"
    },
    {
      "arxiv_id": "2511.07498v2",
      "title": "Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models",
      "title_zh": "èšç„¦è¯­è¨€ï¼šæ­ç¤ºä¸åˆ©ç”¨å¤šè¯­è¨€å¤§è¯­è¨€æ¨¡å‹ä¸­çš„è¯­è¨€æ³¨æ„åŠ›å¤´",
      "authors": [
        "Xin Liu",
        "Qiyang Song",
        "Qihang Zhou",
        "Haichao Du",
        "Shaowen Xu",
        "Wenbo Jiang",
        "Weijuan Zhang",
        "Xiaoqi Jia"
      ],
      "abstract": "Large language models (LLMs) increasingly support multilingual understanding and generation. Meanwhile, efforts to interpret their internal mechanisms have emerged, offering insights to enhance multilingual performance. While multi-head self-attention (MHA) has proven critical in many areas, its role in multilingual capabilities remains underexplored. In this work, we study the contribution of MHA in supporting multilingual processing in LLMs. We propose Language Attention Head Importance Scores (LAHIS), an effective and efficient method that identifies attention head importance for multilingual capabilities via a single forward and backward pass through the LLM. Applying LAHIS to Aya-23-8B, Llama-3.2-3B, and Mistral-7B-v0.1, we reveal the existence of both language-specific and language-general heads. Language-specific heads enable cross-lingual attention transfer to guide the model toward target language contexts and mitigate off-target language generation issue, contributing to addressing challenges in multilingual LLMs. We also introduce a lightweight adaptation that learns a soft head mask to modulate attention outputs over language heads, requiring only 20 tunable parameters to improve XQuAD accuracy. Overall, our work enhances both the interpretability and multilingual capabilities of LLMs from the perspective of MHA.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶(MHA)åœ¨å¤šè¯­è¨€å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ä¸­çš„ä½œç”¨ï¼Œæ—¨åœ¨æå‡å…¶å¯è§£é‡Šæ€§ä¸å¤šè¯­è¨€æ€§èƒ½ã€‚ä½œè€…æå‡ºäº†è¯­è¨€æ³¨æ„åŠ›å¤´é‡è¦æ€§è¯„åˆ†(LAHIS)ï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„æ–¹æ³•ï¼Œä»…éœ€å•æ¬¡å‰å‘å’Œåå‘ä¼ æ’­å³å¯è¯†åˆ«å¯¹å¤šè¯­è¨€èƒ½åŠ›è‡³å…³é‡è¦çš„æ³¨æ„åŠ›å¤´ã€‚é€šè¿‡åœ¨Aya-23-8Bã€Llama-3.2-3Bå’ŒMistral-7B-v0.1ä¸Šçš„åº”ç”¨ï¼Œç ”ç©¶æ­ç¤ºäº†ç‰¹å®šè¯­è¨€å¤´(language-specific heads)å’Œé€šç”¨è¯­è¨€å¤´(language-general heads)çš„å…±å­˜ç°è±¡ã€‚ç ”ç©¶å‘ç°ï¼Œç‰¹å®šè¯­è¨€å¤´èƒ½å¤Ÿå®ç°è·¨è¯­è¨€æ³¨æ„åŠ›è½¬ç§»ï¼Œå¼•å¯¼æ¨¡å‹å…³æ³¨ç›®æ ‡è¯­è¨€ä¸Šä¸‹æ–‡ï¼Œä»è€Œæœ‰æ•ˆç¼“è§£åç¦»ç›®æ ‡è¯­è¨€ç”Ÿæˆ(off-target language generation)çš„é—®é¢˜ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œå¼•å…¥äº†ä¸€ç§è½»é‡çº§é€‚åº”ç­–ç•¥ï¼Œé€šè¿‡å­¦ä¹ è½¯å¤´æ©ç (soft head mask)æ¥è°ƒèŠ‚è¯­è¨€å¤´çš„è¾“å‡ºï¼Œä»…éœ€20ä¸ªå¯è°ƒå‚æ•°ä¾¿æ˜¾è‘—æé«˜äº†XQuADä»»åŠ¡çš„å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœä»MHAè§†è§’å‡ºå‘ï¼ŒåŒæ—¶å¢å¼ºäº†LLMsçš„å†…éƒ¨æœºåˆ¶ç†è§£ä¸å®é™…å¤šè¯­è¨€å¤„ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI-2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07498v2",
      "published_date": "2025-11-10 15:12:42 UTC",
      "updated_date": "2025-12-03 03:44:42 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:54:21.778643+00:00"
    },
    {
      "arxiv_id": "2511.07171v1",
      "title": "Federated Learning for Video Violence Detection: Complementary Roles of Lightweight CNNs and Vision-Language Models for Energy-Efficient Use",
      "title_zh": "é¢å‘è§†é¢‘æš´åŠ›æ£€æµ‹çš„è”é‚¦å­¦ä¹ ï¼šè½»é‡çº§ CNN ä¸è§†è§‰-è¯­è¨€æ¨¡å‹åœ¨é«˜èƒ½æ•ˆåº”ç”¨ä¸­çš„äº’è¡¥ä½œç”¨",
      "authors": [
        "SÃ©bastien Thuau",
        "Siba Haidar",
        "Rachid Chelouah"
      ],
      "abstract": "Deep learning-based video surveillance increasingly demands privacy-preserving architectures with low computational and environmental overhead. Federated learning preserves privacy but deploying large vision-language models (VLMs) introduces major energy and sustainability challenges. We compare three strategies for federated violence detection under realistic non-IID splits on the RWF-2000 and RLVS datasets: zero-shot inference with pretrained VLMs, LoRA-based fine-tuning of LLaVA-NeXT-Video-7B, and personalized federated learning of a 65.8M-parameter 3D CNN. All methods exceed 90% accuracy in binary violence detection. The 3D CNN achieves superior calibration (ROC AUC 92.59%) at roughly half the energy cost (240 Wh vs. 570 Wh) of federated LoRA, while VLMs provide richer multimodal reasoning. Hierarchical category grouping (based on semantic similarity and class exclusion) boosts VLM multiclass accuracy from 65.31% to 81% on the UCF-Crime dataset. To our knowledge, this is the first comparative simulation study of LoRA-tuned VLMs and personalized CNNs for federated violence detection, with explicit energy and CO2e quantification. Our results inform hybrid deployment strategies that default to efficient CNNs for routine inference and selectively engage VLMs for complex contextual reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ è§†é¢‘ç›‘æ§ä¸­çš„éšç§ä¿æŠ¤ä¸èƒ½æ•ˆé—®é¢˜ï¼Œæ¢è®¨äº†è½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)ä¸è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨è”é‚¦å­¦ä¹ (Federated Learning)ç¯å¢ƒä¸‹çš„äº’è¡¥ä½œç”¨ã€‚è®ºæ–‡åœ¨RWF-2000å’ŒRLVSæ•°æ®é›†çš„éç‹¬ç«‹åŒåˆ†å¸ƒ(non-IID)åˆ’åˆ†ä¸‹ï¼Œå¯¹æ¯”äº†ä¸‰ç§æš´åŠ›æ£€æµ‹ç­–ç•¥ï¼šé¢„è®­ç»ƒVLMsçš„Zero-shotæ¨ç†ã€åŸºäºLoRAå¾®è°ƒçš„LLaVA-NeXT-Video-7Bï¼Œä»¥åŠä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ çš„3D CNNã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œæ‰€æœ‰æ–¹æ³•åœ¨äºŒåˆ†ç±»æš´åŠ›æ£€æµ‹ä¸­å‡†ç¡®ç‡å‡è¶…è¿‡90%ï¼Œä½†3D CNNåœ¨èƒ½è€—ä»…ä¸ºè”é‚¦LoRAä¸€åŠ(240 Wh vs. 570 Wh)çš„æƒ…å†µä¸‹ï¼Œå®ç°äº†æ›´ä¼˜çš„æ ¡å‡†æ€§èƒ½(ROC AUC 92.59%)ã€‚å°½ç®¡VLMsèƒ½è€—è¾ƒé«˜ï¼Œä½†æä¾›äº†æ›´ä¸°å¯Œçš„å¤šæ¨¡æ€æ¨ç†èƒ½åŠ›ï¼Œä¸”é€šè¿‡åˆ†å±‚ç±»åˆ«åˆ†ç»„(Hierarchical category grouping)æ˜¾è‘—æå‡äº†å…¶åœ¨UCF-Crimeæ•°æ®é›†ä¸Šçš„å¤šåˆ†ç±»å‡†ç¡®ç‡ã€‚è¿™æ˜¯é¦–ä¸ªé’ˆå¯¹è”é‚¦æš´åŠ›æ£€æµ‹å¯¹æ¯”LoRAå¾®è°ƒVLMsä¸ä¸ªæ€§åŒ–CNNsçš„ç ”ç©¶ï¼Œå¹¶æ˜ç¡®é‡åŒ–äº†èƒ½æºæ¶ˆè€—å’ŒCO2eæ’æ”¾ã€‚åŸºäºæ­¤å‘ç°ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§æ··åˆéƒ¨ç½²ç­–ç•¥ï¼Œå³é»˜è®¤ä½¿ç”¨é«˜æ•ˆçš„CNNè¿›è¡Œå¸¸è§„æ¨ç†ï¼Œä»…åœ¨éœ€è¦å¤æ‚ä¸Šä¸‹æ–‡æ¨ç†æ—¶è°ƒç”¨VLMsï¼Œä»¥å¹³è¡¡æ€§èƒ½ä¸å¯æŒç»­æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 3 figures, ICTAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.07171v1",
      "published_date": "2025-11-10 15:01:51 UTC",
      "updated_date": "2025-11-10 15:01:51 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:54:49.174832+00:00"
    },
    {
      "arxiv_id": "2511.07166v1",
      "title": "AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning",
      "title_zh": "AdaRecï¼šåŸºäºå™äº‹æ€§ç”»åƒä¸åŒé€šé“æ¨ç†çš„å¤§è¯­è¨€æ¨¡å‹è‡ªé€‚åº”æ¨è",
      "authors": [
        "Meiyun Wang",
        "Charin Polpanumas"
      ],
      "abstract": "We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AdaRecï¼Œä¸€ç§åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œè‡ªé€‚åº”ä¸ªæ€§åŒ–æ¨èçš„å°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹ (few-shot in-context learning)æ¡†æ¶ã€‚AdaRecå¼•å…¥äº†å™äº‹ç”»åƒ(narrative profiling)ï¼Œå°†ç”¨æˆ·ä¸ç‰©å“çš„äº¤äº’è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼Œä»è€Œæ¶ˆé™¤äº†æ‰‹å·¥ç‰¹å¾å·¥ç¨‹å¹¶å¢å¼ºäº†äººç±»å¯è¯»æ€§ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºåŒå˜é‡æ¨ç†èŒƒå¼çš„åŒé€šé“æ¶æ„ï¼Œæœ‰æ•ˆæ•´åˆäº†å‘ç°åŒä¼´é©±åŠ¨æ¨¡å¼çš„æ°´å¹³è¡Œä¸ºå¯¹é½(horizontal behavioral alignment)å’Œå¼ºè°ƒç”¨æˆ·åå¥½å†³å®šæ€§å› ç´ çš„å‚ç›´å› æœå½’å› (vertical causal attribution)ã€‚åœ¨çœŸå®ç”µå­å•†åŠ¡æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAdaRecåœ¨å°‘æ ·æœ¬è®¾ç½®ä¸‹ä¼˜äºä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹å’ŒåŸºäºLLMçš„åŸºçº¿æ¨¡å‹é«˜è¾¾8%ã€‚åœ¨é›¶æ ·æœ¬(zero-shot)åœºæ™¯ä¸­ï¼Œå®ƒæ¯”ä¸“å®¶æ„å»ºçš„ç”»åƒæ–¹æ³•æå‡äº†19%ï¼Œè¯æ˜äº†å…¶åœ¨é•¿å°¾ä¸ªæ€§åŒ–å’Œæå°‘äº¤äº’æ•°æ®æƒ…å†µä¸‹çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œä½¿ç”¨AdaRecç”Ÿæˆçš„åˆæˆæ•°æ®è¿›è¡Œè½»é‡çº§å¾®è°ƒå³å¯è¾¾åˆ°å…¨é‡å¾®è°ƒæ¨¡å‹çš„æ€§èƒ½ï¼Œçªæ˜¾äº†å…¶é«˜æ•ˆæ€§å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07166v1",
      "published_date": "2025-11-10 14:59:27 UTC",
      "updated_date": "2025-11-10 14:59:27 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:55:07.912249+00:00"
    },
    {
      "arxiv_id": "2511.07165v1",
      "title": "Fuzzy Label: From Concept to Its Application in Label Learning",
      "title_zh": "æ¨¡ç³Šæ ‡ç­¾ï¼šä»æ¦‚å¿µåˆ°å…¶åœ¨æ ‡ç­¾å­¦ä¹ ä¸­çš„åº”ç”¨",
      "authors": [
        "Chenxi Luoa",
        "Zhuangzhuang Zhaoa",
        "Zhaohong Denga",
        "Te Zhangb"
      ],
      "abstract": "Label learning is a fundamental task in machine learning that aims to construct intelligent models using labeled data, encompassing traditional single-label and multi-label classification models. Traditional methods typically rely on logical labels, such as binary indicators (e.g., \"yes/no\") that specify whether an instance belongs to a given category. However, in practical applications, label annotations often involve significant uncertainty due to factors such as data noise, inherent ambiguity in the observed entities, and the subjectivity of human annotators. Therefore, representing labels using simplistic binary logic can obscure valuable information and limit the expressiveness of label learning models. To overcome this limitation, this paper introduces the concept of fuzzy labels, grounded in fuzzy set theory, to better capture and represent label uncertainty. We further propose an efficient fuzzy labeling method that mines and generates fuzzy labels from the original data, thereby enriching the label space with more informative and nuanced representations. Based on this foundation, we present fuzzy-label-enhanced algorithms for both single-label and multi-label learning, using the classical K-Nearest Neighbors (KNN) and multi-label KNN algorithms as illustrative examples. Experimental results indicate that fuzzy labels can more effectively characterize the real-world labeling information and significantly enhance the performance of label learning models.",
      "tldr_zh": "è¯¥è®ºæ–‡é’ˆå¯¹ä¼ ç»Ÿæ ‡ç­¾å­¦ä¹ ä¸­é€»è¾‘æ ‡ç­¾ï¼ˆå¦‚äºŒå…ƒæŒ‡ç¤ºç¬¦ï¼‰éš¾ä»¥å¤„ç†æ•°æ®å™ªå£°ã€æ¨¡ç³Šæ€§å’Œä¸»è§‚æ€§å¸¦æ¥çš„ä¸ç¡®å®šæ€§é—®é¢˜ï¼ŒåŸºäºæ¨¡ç³Šé›†ç†è®º(fuzzy set theory)å¼•å…¥äº†â€œæ¨¡ç³Šæ ‡ç­¾â€(fuzzy labels)çš„æ¦‚å¿µã€‚ä½œè€…æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„æ¨¡ç³Šæ ‡ç­¾ç”Ÿæˆæ–¹æ³•ï¼Œèƒ½å¤Ÿä»åŸå§‹æ•°æ®ä¸­æŒ–æ˜å¹¶ç”Ÿæˆæ¨¡ç³Šæ ‡ç­¾ï¼Œä»è€Œæä¾›æ›´å…·ä¿¡æ¯é‡å’Œç»†å¾®å·®åˆ«çš„æ ‡ç­¾è¡¨ç¤ºã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡ä»¥ç»å…¸çš„Kè¿‘é‚»(KNN)å’Œå¤šæ ‡ç­¾KNNç®—æ³•ä¸ºä¾‹ï¼Œè®¾è®¡äº†å¢å¼ºå‹çš„å•æ ‡ç­¾å’Œå¤šæ ‡ç­¾å­¦ä¹ ç®—æ³•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ¨¡ç³Šæ ‡ç­¾èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°è¡¨å¾ç°å®ä¸–ç•Œçš„æ ‡ç­¾ä¿¡æ¯ï¼Œå¹¶æ˜¾è‘—æå‡äº†æ ‡ç­¾å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07165v1",
      "published_date": "2025-11-10 14:58:19 UTC",
      "updated_date": "2025-11-10 14:58:19 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:55:29.564578+00:00"
    },
    {
      "arxiv_id": "2511.11651v1",
      "title": "Incomplete Depression Feature Selection with Missing EEG Channels",
      "title_zh": "ä¼´æœ‰ EEG é€šé“ç¼ºå¤±çš„ä¸å®Œæ•´æŠ‘éƒç‰¹å¾é€‰æ‹©",
      "authors": [
        "Zhijian Gong",
        "Wenjia Dong",
        "Xueyuan Xu",
        "Fulin Wei",
        "Chunyu Liu",
        "Li Zhuo"
      ],
      "abstract": "As a critical mental health disorder, depression has severe effects on both human physical and mental well-being. Recent developments in EEG-based depression analysis have shown promise in improving depression detection accuracies. However, EEG features often contain redundant, irrelevant, and noisy information. Additionally, real-world EEG data acquisition frequently faces challenges, such as data loss from electrode detachment and heavy noise interference. To tackle the challenges, we propose a novel feature selection approach for robust depression analysis, called Incomplete Depression Feature Selection with Missing EEG Channels (IDFS-MEC). IDFS-MEC integrates missing-channel indicator information and adaptive channel weighting learning into orthogonal regression to lessen the effects of incomplete channels on model construction, and then utilizes global redundancy minimization learning to reduce redundant information among selected feature subsets. Extensive experiments conducted on MODMA and PRED-d003 datasets reveal that the EEG feature subsets chosen by IDFS-MEC have superior performance than 10 popular feature selection methods among 3-, 64-, and 128-channel settings.",
      "tldr_zh": "é’ˆå¯¹æŠ‘éƒç—‡æ£€æµ‹ä¸­EEGç‰¹å¾åŒ…å«å†—ä½™å™ªå£°ä»¥åŠç°å®æ•°æ®é‡‡é›†ä¸­å¸¸é‡åˆ°çš„ç”µæè„±è½å¯¼è‡´çš„æ•°æ®ç¼ºå¤±é—®é¢˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºIDFS-MEC (Incomplete Depression Feature Selection with Missing EEG Channels) çš„é²æ£’ç‰¹å¾é€‰æ‹©æ–¹æ³•ã€‚IDFS-MECå°†ç¼ºå¤±é€šé“æŒ‡ç¤ºä¿¡æ¯å’Œè‡ªé€‚åº”é€šé“åŠ æƒå­¦ä¹ é›†æˆåˆ°æ­£äº¤å›å½’(orthogonal regression)ä¸­ï¼Œä»è€Œå‡è½»ä¸å®Œæ•´é€šé“å¯¹æ¨¡å‹æ„å»ºçš„å½±å“ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•è¿˜åˆ©ç”¨å…¨å±€å†—ä½™æœ€å°åŒ–å­¦ä¹ (global redundancy minimization learning)æ¥å‡å°‘æ‰€é€‰ç‰¹å¾å­é›†ä¹‹é—´çš„å†—ä½™ä¿¡æ¯ã€‚åœ¨MODMAå’ŒPRED-d003æ•°æ®é›†ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒIDFS-MECé€‰æ‹©çš„EEGç‰¹å¾å­é›†åœ¨3ã€64å’Œ128é€šé“è®¾ç½®ä¸‹çš„æ€§èƒ½å‡ä¼˜äº10ç§æµè¡Œçš„ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œå±•ç°äº†å…¶åœ¨å¤„ç†ä¸å®Œæ•´EEGæ•°æ®æ—¶çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11651v1",
      "published_date": "2025-11-10 14:47:09 UTC",
      "updated_date": "2025-11-10 14:47:09 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:56:24.033653+00:00"
    },
    {
      "arxiv_id": "2511.07156v1",
      "title": "Conditional Diffusion as Latent Constraints for Controllable Symbolic Music Generation",
      "title_zh": "æ¡ä»¶æ‰©æ•£ä½œä¸ºæ½œåœ¨çº¦æŸç”¨äºå¯æ§ç¬¦å·éŸ³ä¹ç”Ÿæˆ",
      "authors": [
        "Matteo PettenÃ³",
        "Alessandro Ilic Mezza",
        "Alberto Bernardini"
      ],
      "abstract": "Recent advances in latent diffusion models have demonstrated state-of-the-art performance in high-dimensional time-series data synthesis while providing flexible control through conditioning and guidance. However, existing methodologies primarily rely on musical context or natural language as the main modality of interacting with the generative process, which may not be ideal for expert users who seek precise fader-like control over specific musical attributes. In this work, we explore the application of denoising diffusion processes as plug-and-play latent constraints for unconditional symbolic music generation models. We focus on a framework that leverages a library of small conditional diffusion models operating as implicit probabilistic priors on the latents of a frozen unconditional backbone. While previous studies have explored domain-specific use cases, this work, to the best of our knowledge, is the first to demonstrate the versatility of such an approach across a diverse array of musical attributes, such as note density, pitch range, contour, and rhythm complexity. Our experiments show that diffusion-driven constraints outperform traditional attribute regularization and other latent constraints architectures, achieving significantly stronger correlations between target and generated attributes while maintaining high perceptual quality and diversity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ½œåœ¨æ‰©æ•£æ¨¡å‹åœ¨ç¬¦å·éŸ³ä¹ç”Ÿæˆ(Symbolic Music Generation)ä¸­ç¼ºä¹ç²¾ç¡®æ§åˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°†æ¡ä»¶æ‰©æ•£ä½œä¸ºæ½œåœ¨çº¦æŸ(Latent Constraints)çš„æ–°æ–¹æ³•ã€‚ä¸åŒäºä¾èµ–è‡ªç„¶è¯­è¨€æˆ–éŸ³ä¹ä¸Šä¸‹æ–‡çš„ä¼ ç»Ÿäº¤äº’æ–¹å¼ï¼Œè¯¥å·¥ä½œæ¢ç´¢äº†å°†å»å™ªæ‰©æ•£è¿‡ç¨‹(Denoising Diffusion Processes)ä½œä¸ºå³æ’å³ç”¨çš„çº¦æŸï¼Œåº”ç”¨äºå†»ç»“çš„æ— æ¡ä»¶ç”Ÿæˆéª¨å¹²ç½‘ç»œä¸Šã€‚è¯¥æ¡†æ¶åˆ©ç”¨ä¸€ç»„å°å‹æ¡ä»¶æ‰©æ•£æ¨¡å‹ä½œä¸ºæ½œåœ¨ç©ºé—´çš„éšå¼æ¦‚ç‡å…ˆéªŒ(Implicit Probabilistic Priors)ï¼Œå®ç°äº†å¯¹éŸ³ç¬¦å¯†åº¦ã€éŸ³é«˜èŒƒå›´ã€æ—‹å¾‹è½®å»“å’ŒèŠ‚å¥å¤æ‚æ€§ç­‰å¤šç§éŸ³ä¹å±æ€§çš„ç²¾ç¡®æ§åˆ¶ã€‚è¿™æ˜¯ç›¸å…³æ–¹æ³•é¦–æ¬¡åœ¨å¦‚æ­¤å¹¿æ³›çš„éŸ³ä¹å±æ€§ä¸Šå±•ç¤ºå…¶é€šç”¨æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ‰©æ•£é©±åŠ¨çš„çº¦æŸæœºåˆ¶åœ¨ç›®æ ‡å±æ€§ä¸ç”Ÿæˆç»“æœçš„ç›¸å…³æ€§ä¸Šæ˜¾è‘—ä¼˜äºä¼ ç»Ÿå±æ€§æ­£åˆ™åŒ–å’Œå…¶ä»–æ½œåœ¨çº¦æŸæ¶æ„ï¼ŒåŒæ—¶ä¿æŒäº†ç”ŸæˆéŸ³ä¹çš„é«˜æ„ŸçŸ¥è´¨é‡å’Œå¤šæ ·æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07156v1",
      "published_date": "2025-11-10 14:46:10 UTC",
      "updated_date": "2025-11-10 14:46:10 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:56:46.085357+00:00"
    },
    {
      "arxiv_id": "2511.11650v1",
      "title": "Enhanced Water Leak Detection with Convolutional Neural Networks and One-Class Support Vector Machine",
      "title_zh": "åŸºäºå·ç§¯ç¥ç»ç½‘ç»œä¸ä¸€ç±»æ”¯æŒå‘é‡æœºçš„å¢å¼ºå‹æ¼æ°´æ£€æµ‹",
      "authors": [
        "Daniele Ugo Leonzio",
        "Paolo Bestagini",
        "Marco Marcon",
        "Stefano Tubaro"
      ],
      "abstract": "Water is a critical resource that must be managed efficiently. However, a substantial amount of water is lost each year due to leaks in Water Distribution Networks (WDNs). This underscores the need for reliable and effective leak detection and localization systems. In recent years, various solutions have been proposed, with data-driven approaches gaining increasing attention due to their superior performance. In this paper, we propose a new method for leak detection. The method is based on water pressure measurements acquired at a series of nodes of a WDN. Our technique is a fully data-driven solution that makes only use of the knowledge of the WDN topology, and a series of pressure data acquisitions obtained in absence of leaks. The proposed solution is based on an feature extractor and a one-class Support Vector Machines (SVM) trained on no-leak data, so that leaks are detected as anomalies. The results achieved on a simulate dataset using the Modena WDN demonstrate that the proposed solution outperforms recent methods for leak detection.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾›æ°´ç®¡ç½‘(WDNs)ä¸­çš„æ°´èµ„æºæµå¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆå·ç§¯ç¥ç»ç½‘ç»œ(CNN)å’Œå•ç±»æ”¯æŒå‘é‡æœº(One-Class SVM)çš„å¢å¼ºå‹æ³„æ¼æ£€æµ‹æ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨å®Œå…¨çš„æ•°æ®é©±åŠ¨ç­–ç•¥ï¼Œä»…åˆ©ç”¨WDNçš„æ‹“æ‰‘ç»“æ„ä»¥åŠåœ¨æ— æ³„æ¼çŠ¶æ€ä¸‹é‡‡é›†çš„æ°´å‹æµ‹é‡æ•°æ®è¿›è¡Œå»ºæ¨¡ã€‚é€šè¿‡é›†æˆç‰¹å¾æå–å™¨å’Œåœ¨æ­£å¸¸æ•°æ®ä¸Šè®­ç»ƒçš„One-Class SVMï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿå°†æ³„æ¼ä½œä¸ºå¼‚å¸¸æƒ…å†µè¿›è¡Œè¯†åˆ«ï¼Œä»è€Œè§£å†³äº†ä¾èµ–æ³„æ¼æ ·æœ¬çš„éš¾é¢˜ã€‚åœ¨Modena WDNæ¨¡æ‹Ÿæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥è§£å†³æ–¹æ¡ˆçš„æ€§èƒ½ä¼˜äºç°æœ‰çš„æ³„æ¼æ£€æµ‹æ–¹æ³•ï¼Œä¸ºé«˜æ•ˆç®¡ç†æ°´èµ„æºæä¾›äº†å¯é çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11650v1",
      "published_date": "2025-11-10 14:33:29 UTC",
      "updated_date": "2025-11-10 14:33:29 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:57:15.520790+00:00"
    },
    {
      "arxiv_id": "2511.07496v1",
      "title": "Laplacian Score Sharpening for Mitigating Hallucination in Diffusion Models",
      "title_zh": "åˆ©ç”¨æ‹‰æ™®æ‹‰æ–¯åˆ†æ•°é”åŒ–ç¼“è§£æ‰©æ•£æ¨¡å‹å¹»è§‰",
      "authors": [
        "Barath Chandran. C",
        "Srinivas Anumasa",
        "Dianbo Liu"
      ],
      "abstract": "Diffusion models, though successful, are known to suffer from hallucinations that create incoherent or unrealistic samples. Recent works have attributed this to the phenomenon of mode interpolation and score smoothening, but they lack a method to prevent their generation during sampling. In this paper, we propose a post-hoc adjustment to the score function during inference that leverages the Laplacian (or sharpness) of the score to reduce mode interpolation hallucination in unconditional diffusion models across 1D, 2D, and high-dimensional image data. We derive an efficient Laplacian approximation for higher dimensions using a finite-difference variant of the Hutchinson trace estimator. We show that this correction significantly reduces the rate of hallucinated samples across toy 1D/2D distributions and a high-dimensional image dataset. Furthermore, our analysis explores the relationship between the Laplacian and uncertainty in the score.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹(Diffusion Models)ä¸­å› æ¨¡å¼æ’å€¼(mode interpolation)å’Œåˆ†æ•°å¹³æ»‘åŒ–(score smoothening)å¯¼è‡´çš„å¹»è§‰é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ‹‰æ™®æ‹‰æ–¯åˆ†æ•°é”åŒ–(Laplacian Score Sharpening)çš„è§£å†³æ–¹æ¡ˆã€‚ä½œè€…åœ¨æ¨ç†é˜¶æ®µå¼•å…¥äº†å¯¹åˆ†æ•°å‡½æ•°(score function)çš„äº‹åè°ƒæ•´ï¼Œåˆ©ç”¨åˆ†æ•°çš„æ‹‰æ™®æ‹‰æ–¯ç®—å­(Laplacian)æ¥æŠ‘åˆ¶æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹åœ¨ä¸åŒç»´åº¦æ•°æ®ä¸Šçš„æ¨¡å¼æ’å€¼å¹»è§‰ã€‚ä¸ºäº†è§£å†³é«˜ç»´å›¾åƒæ•°æ®çš„è®¡ç®—éš¾é¢˜ï¼Œè¯¥ç ”ç©¶åˆ©ç”¨Hutchinsonè¿¹ä¼°è®¡å™¨(Hutchinson trace estimator)çš„æœ‰é™å·®åˆ†å˜ä½“ï¼Œæ¨å¯¼å‡ºäº†é«˜æ•ˆçš„æ‹‰æ™®æ‹‰æ–¯è¿‘ä¼¼ç®—æ³•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¿™ç§ä¿®æ­£æ–¹æ³•æ˜¾è‘—é™ä½äº†ä¸€ç»´ã€äºŒç»´åˆ†å¸ƒåŠé«˜ç»´å›¾åƒæ•°æ®é›†ä¸­çš„å¹»è§‰æ ·æœ¬ç‡ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ·±å…¥åˆ†æäº†æ‹‰æ™®æ‹‰æ–¯ç®—å­ä¸åˆ†æ•°ä¸ç¡®å®šæ€§ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œä¸ºæé«˜ç”Ÿæˆæ ·æœ¬çš„è´¨é‡æä¾›äº†æ–°çš„ç†è®ºè§†è§’ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07496v1",
      "published_date": "2025-11-10 14:16:31 UTC",
      "updated_date": "2025-11-10 14:16:31 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:58:14.438650+00:00"
    },
    {
      "arxiv_id": "2511.07129v2",
      "title": "LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging",
      "title_zh": "LoRA on the Goï¼šå®ä¾‹çº§åŠ¨æ€ LoRA é€‰æ‹©ä¸åˆå¹¶",
      "authors": [
        "Seungeon Lee",
        "Soumi Das",
        "Manish Gupta",
        "Krishna P. Gummadi"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models. However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»ŸLoRAé€‚é…å™¨ä»…é€‚ç”¨äºå•ä¸€ä»»åŠ¡ä¸”ç°æœ‰ç»„åˆæ–¹æ³•ä¾èµ–é¢å¤–è®­ç»ƒçš„é—®é¢˜ï¼Œæå‡ºäº†LoRA on the Go (LoGo)ï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„å®ä¾‹çº§åŠ¨æ€LoRAé€‰æ‹©ä¸åˆå¹¶æ¡†æ¶ã€‚LoGoåˆ©ç”¨å•æ¬¡å‰å‘ä¼ æ’­ä¸­æå–çš„ä¿¡å·ï¼Œèƒ½å¤Ÿå³æ—¶è¯†åˆ«æœ€ç›¸å…³çš„é€‚é…å™¨å¹¶ç¡®å®šå…¶åˆå¹¶æƒé‡ï¼Œæ— éœ€æ ‡ç­¾æ•°æ®æˆ–é¢å¤–è®­ç»ƒã€‚åœ¨æ¶‰åŠ3ä¸ªæ¨¡å‹å®¶æ—ã€5ä¸ªNLPåŸºå‡†å’Œ27ä¸ªæ•°æ®é›†çš„å¹¿æ³›è¯„ä¼°ä¸­ï¼ŒLoGoåœ¨ä¿æŒæ¨ç†ååé‡çš„åŒæ—¶ï¼Œåœ¨éƒ¨åˆ†ä»»åŠ¡ä¸Šæ¯”åŸºäºè®­ç»ƒçš„åŸºçº¿æ¨¡å‹æ€§èƒ½æå‡é«˜è¾¾3.6%ï¼Œä¸”åœ¨å…¶ä»–ä»»åŠ¡ä¸Šä¿æŒç«äº‰åŠ›ï¼Œå±•ç¤ºäº†å…¶åœ¨å¤„ç†å¤šæ ·åŒ–è¾“å…¥æ—¶çš„æœ‰æ•ˆæ€§å’Œå®ç”¨æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07129v2",
      "published_date": "2025-11-10 14:13:10 UTC",
      "updated_date": "2025-11-20 11:08:55 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:57:59.854136+00:00"
    },
    {
      "arxiv_id": "2511.07126v1",
      "title": "Saliency Map-Guided Knowledge Discovery for Subclass Identification with LLM-Based Symbolic Approximations",
      "title_zh": "åŸºäºæ˜¾è‘—å›¾å¼•å¯¼ä¸ LLM ç¬¦å·è¿‘ä¼¼çš„å­ç±»è¯†åˆ«çŸ¥è¯†å‘ç°",
      "authors": [
        "Tim Bohne",
        "Anne-Kathrin Patricia Windler",
        "Martin Atzmueller"
      ],
      "abstract": "This paper proposes a novel neuro-symbolic approach for sensor signal-based knowledge discovery, focusing on identifying latent subclasses in time series classification tasks. The approach leverages gradient-based saliency maps derived from trained neural networks to guide the discovery process. Multiclass time series classification problems are transformed into binary classification problems through label subsumption, and classifiers are trained for each of these to yield saliency maps. The input signals, grouped by predicted class, are clustered under three distinct configurations. The centroids of the final set of clusters are provided as input to an LLM for symbolic approximation and fuzzy knowledge graph matching to discover the underlying subclasses of the original multiclass problem. Experimental results on well-established time series classification datasets demonstrate the effectiveness of our saliency map-driven method for knowledge discovery, outperforming signal-only baselines in both clustering and subclass identification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°é¢–çš„ç¥ç»ç¬¦å·(neuro-symbolic)æ–¹æ³•ï¼Œç”¨äºåŸºäºä¼ æ„Ÿå™¨ä¿¡å·çš„çŸ¥è¯†å‘ç°ï¼Œç‰¹åˆ«å…³æ³¨åœ¨æ—¶é—´åºåˆ—åˆ†ç±»ä»»åŠ¡ä¸­è¯†åˆ«æ½œåœ¨å­ç±»(latent subclasses)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä»è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œä¸­å¯¼å‡ºçš„åŸºäºæ¢¯åº¦çš„æ˜¾è‘—å›¾(gradient-based saliency maps)æ¥æŒ‡å¯¼å‘ç°è¿‡ç¨‹ã€‚é€šè¿‡æ ‡ç­¾å½’çº³(label subsumption)ï¼Œç ”ç©¶å°†å¤šç±»æ—¶é—´åºåˆ—åˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºäºŒåˆ†ç±»é—®é¢˜ï¼Œå¹¶è®­ç»ƒåˆ†ç±»å™¨ä»¥ç”Ÿæˆæ˜¾è‘—å›¾ï¼Œè¿›è€Œå¯¹è¾“å…¥ä¿¡å·è¿›è¡Œèšç±»ã€‚æœ€ç»ˆçš„èšç±»è´¨å¿ƒè¢«è¾“å…¥åˆ°å¤§è¯­è¨€æ¨¡å‹(LLM)ä¸­ï¼Œé€šè¿‡ç¬¦å·è¿‘ä¼¼(symbolic approximation)å’Œæ¨¡ç³ŠçŸ¥è¯†å›¾è°±åŒ¹é…(fuzzy knowledge graph matching)æ¥æ­ç¤ºåŸå§‹å¤šç±»é—®é¢˜çš„åº•å±‚å­ç±»ã€‚åœ¨æˆç†Ÿçš„æ—¶é—´åºåˆ—åˆ†ç±»æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ˜¾è‘—å›¾é©±åŠ¨çš„æ–¹æ³•åœ¨èšç±»å’Œå­ç±»è¯†åˆ«æ–¹é¢å‡ä¼˜äºä»…åŸºäºä¿¡å·çš„åŸºçº¿æ¨¡å‹ï¼Œè¯æ˜äº†å…¶æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07126v1",
      "published_date": "2025-11-10 14:11:49 UTC",
      "updated_date": "2025-11-10 14:11:49 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:02:08.140284+00:00"
    },
    {
      "arxiv_id": "2511.07124v1",
      "title": "Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought",
      "title_zh": "ä¸€è‡´æ€è€ƒï¼Œé«˜æ•ˆæ¨ç†ï¼šåŸºäºèƒ½é‡çš„éšå¼æ€ç»´é“¾æ ¡å‡†",
      "authors": [
        "Zhikang Chen",
        "Sen Cui",
        "Deheng Ye",
        "Yu Zhang",
        "Yatao Bian",
        "Tingting Zhu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \\emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­æ˜¾å¼æ€ç»´é“¾ï¼ˆChain-of-Thought, CoTï¼‰æ˜“å—é”™è¯¯ä¼ æ’­å½±å“ä»¥åŠéšå¼æ¨ç†ç¼ºä¹ä¸€è‡´æ€§çº¦æŸçš„é—®é¢˜ï¼Œæå‡ºäº†EBM-CoTæ¡†æ¶ã€‚è¿™æ˜¯ä¸€ç§åŸºäºèƒ½é‡æ¨¡å‹çš„æ€ç»´é“¾æ ¡å‡†æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡èƒ½é‡æ¨¡å‹ï¼ˆEnergy-Based Model, EBMï¼‰ç»†åŒ–æ½œåœ¨æ€ç»´è¡¨ç¤ºã€‚è¯¥æ–¹æ³•å°†æ½œåœ¨æ¨ç†è½¨è¿¹åŠ¨æ€è°ƒæ•´è‡³åµŒå…¥ç©ºé—´ä¸­çš„ä½èƒ½é‡ã€é«˜ä¸€è‡´æ€§åŒºåŸŸï¼Œä»è€Œåœ¨ä¸ä¿®æ”¹åŸºç¡€è¯­è¨€æ¨¡å‹çš„æƒ…å†µä¸‹æå‡æ¨ç†å‡†ç¡®æ€§ä¸ç¨³å®šæ€§ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒEBM-CoTåœ¨æ•°å­¦ã€å¸¸è¯†å’Œç¬¦å·æ¨ç†åŸºå‡†æµ‹è¯•ä¸­ï¼Œæ˜¾è‘—å¢å¼ºäº†LLMså¤šæ­¥æ¨ç†çš„ä¸€è‡´æ€§å’Œæ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07124v1",
      "published_date": "2025-11-10 14:10:58 UTC",
      "updated_date": "2025-11-10 14:10:58 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:01:50.217429+00:00"
    },
    {
      "arxiv_id": "2511.07118v1",
      "title": "On the Joint Minimization of Regularization Loss Functions in Deep Variational Bayesian Methods for Attribute-Controlled Symbolic Music Generation",
      "title_zh": "é¢å‘å±æ€§å¯æ§ç¬¦å·éŸ³ä¹ç”Ÿæˆçš„æ·±åº¦å˜åˆ†è´å¶æ–¯æ–¹æ³•ä¸­æ­£åˆ™åŒ–æŸå¤±å‡½æ•°çš„è”åˆæœ€å°åŒ–",
      "authors": [
        "Matteo PettenÃ³",
        "Alessandro Ilic Mezza",
        "Alberto Bernardini"
      ],
      "abstract": "Explicit latent variable models provide a flexible yet powerful framework for data synthesis, enabling controlled manipulation of generative factors. With latent variables drawn from a tractable probability density function that can be further constrained, these models enable continuous and semantically rich exploration of the output space by navigating their latent spaces. Structured latent representations are typically obtained through the joint minimization of regularization loss functions. In variational information bottleneck models, reconstruction loss and Kullback-Leibler Divergence (KLD) are often linearly combined with an auxiliary Attribute-Regularization (AR) loss. However, balancing KLD and AR turns out to be a very delicate matter. When KLD dominates over AR, generative models tend to lack controllability; when AR dominates over KLD, the stochastic encoder is encouraged to violate the standard normal prior. We explore this trade-off in the context of symbolic music generation with explicit control over continuous musical attributes. We show that existing approaches struggle to jointly minimize both regularization objectives, whereas suitable attribute transformations can help achieve both controllability and regularization of the target latent dimensions.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨å±æ€§æ§åˆ¶çš„ç¬¦å·éŸ³ä¹ç”Ÿæˆ(Symbolic Music Generation)ä¸­ï¼Œæ·±åº¦å˜åˆ†è´å¶æ–¯æ–¹æ³•(Deep Variational Bayesian Methods)æ­£åˆ™åŒ–æŸå¤±å‡½æ•°çš„è”åˆæœ€å°åŒ–é—®é¢˜ã€‚åœ¨å˜åˆ†ä¿¡æ¯ç“¶é¢ˆ(Variational Information Bottleneck)æ¨¡å‹ä¸­ï¼Œå¹³è¡¡Kullback-Leibler Divergence (KLD)å’Œè¾…åŠ©çš„Attribute-Regularization (AR)æŸå¤±æ˜¯ä¸€ä¸ªæ£˜æ‰‹çš„éš¾é¢˜ã€‚å½“KLDå ä¸»å¯¼æ—¶æ¨¡å‹ç¼ºä¹å¯æ§æ€§ï¼Œè€Œå½“ARå ä¸»å¯¼æ—¶éšæœºç¼–ç å™¨å¾€å¾€ä¼šè¿åæ ‡å‡†æ­£æ€å…ˆéªŒã€‚ä½œè€…åœ¨å…·æœ‰è¿ç»­éŸ³ä¹å±æ€§æ˜¾å¼æ§åˆ¶çš„ç¬¦å·éŸ³ä¹ç”ŸæˆèƒŒæ™¯ä¸‹æ·±å…¥æ¢ç©¶äº†è¿™ä¸€æƒè¡¡(trade-off)ã€‚ç ”ç©¶è¡¨æ˜ï¼Œç°æœ‰æ–¹æ³•éš¾ä»¥åŒæ—¶æœ€å°åŒ–è¿™ä¸¤ä¸ªæ­£åˆ™åŒ–ç›®æ ‡ï¼Œè€Œé€‚å½“çš„å±æ€§å˜æ¢(attribute transformations)æœ‰åŠ©äºåŒæ—¶å®ç°ç›®æ ‡æ½œåœ¨ç»´åº¦çš„å¯æ§æ€§å’Œæ­£åˆ™åŒ–ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "IEEE Catalog No.: CFP2540S-ART ISBN: 978-9-46-459362-4",
      "pdf_url": "https://arxiv.org/pdf/2511.07118v1",
      "published_date": "2025-11-10 14:09:25 UTC",
      "updated_date": "2025-11-10 14:09:25 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:02:18.146081+00:00"
    },
    {
      "arxiv_id": "2511.07112v1",
      "title": "More Agents Helps but Adversarial Robustness Gap Persists",
      "title_zh": "æ›´å¤šæ™ºèƒ½ä½“è™½æœ‰åŠ©ç›Šï¼Œä½†å¯¹æŠ—é²æ£’æ€§å·®è·ä¾ç„¶å­˜åœ¨",
      "authors": [
        "Khashayar Alavi",
        "Zhastay Yeltay",
        "Lucie Flek",
        "Akbar Karimi"
      ],
      "abstract": "When LLM agents work together, they seem to be more powerful than a single LLM in mathematical question answering. However, are they also more robust to adversarial inputs? We investigate this question using adversarially perturbed math questions. These perturbations include punctuation noise with three intensities (10, 30, and 50 percent), plus real-world and human-like typos (WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B, Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math, MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15, 20, 25). Our findings show that (1) Noise type matters: punctuation noise harm scales with its severity, and the human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents. And (2) Collaboration reliably improves accuracy as the number of agents, n, increases, with the largest gains from one to five agents and diminishing returns beyond 10 agents. However, the adversarial robustness gap persists regardless of the agent count.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ•°å­¦é—®ç­”ä»»åŠ¡ä¸­ï¼Œå¤šæ™ºèƒ½ä½“ï¼ˆLLM Agentsï¼‰åä½œæ˜¯å¦æ¯”å•æ™ºèƒ½ä½“å…·å¤‡æ›´å¼ºçš„å¯¹æŠ—æ€§é²æ£’æ€§ã€‚ä½œè€…é‡‡ç”¨äº†ä¸€ä¸ªåä¸ºAgent Forestçš„ç»Ÿä¸€é‡‡æ ·ä¸æŠ•ç¥¨æ¡†æ¶ï¼Œå¯¹å…­ç§å¼€æºæ¨¡å‹ï¼ˆå¦‚Qwen3ã€Llama3.1ç­‰ï¼‰åœ¨GSM8Kå’ŒMATHç­‰å››ä¸ªåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ™ºèƒ½ä½“æ•°é‡èŒƒå›´ä»1åˆ°25ã€‚ç ”ç©¶å¼•å…¥äº†å¯¹æŠ—æ€§æ‰°åŠ¨ï¼ŒåŒ…æ‹¬ä¸åŒå¼ºåº¦çš„æ ‡ç‚¹å™ªå£°ä»¥åŠWikiTypoå’ŒR2ATAç­‰çœŸå®äººç±»æ‹¼å†™é”™è¯¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€æ™ºèƒ½ä½“æ•°é‡å¢åŠ ï¼Œåä½œç¡®å®èƒ½ç¨³æ­¥æé«˜å‡†ç¡®ç‡ï¼Œå…¶ä¸­1åˆ°5ä¸ªæ™ºèƒ½ä½“å¸¦æ¥çš„æ”¶ç›Šæœ€å¤§ï¼Œè¶…è¿‡10ä¸ªåæ”¶ç›Šé€’å‡ã€‚ç„¶è€Œï¼Œæ•°æ®è¡¨æ˜å™ªå£°ç±»å‹å½±å“æ˜¾è‘—ï¼Œäººç±»æ‹¼å†™é”™è¯¯ä»ç„¶æ˜¯ä¸»è¦ç“¶é¢ˆï¼Œå¯¼è‡´äº†æœ€å¤§çš„å‡†ç¡®ç‡ä¸‹é™ã€‚æœ€ç»ˆç»“è®ºæŒ‡å‡ºï¼Œå°½ç®¡å¢åŠ æ™ºèƒ½ä½“æ•°é‡æœ‰åŠ©äºæå‡æ•´ä½“æ€§èƒ½ï¼Œä½†æ— è®ºæ™ºèƒ½ä½“æ•°é‡å¤šå°‘ï¼Œå¯¹æŠ—æ€§é²æ£’æ€§å·®è·ï¼ˆAdversarial Robustness Gapï¼‰ä¾ç„¶å­˜åœ¨ï¼Œè¡¨æ˜ç®€å•çš„å¤šæ™ºèƒ½ä½“æ‰©å±•æ— æ³•å®Œå…¨è§£å†³å¯¹æŠ—æ€§è¾“å…¥çš„å¨èƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07112v1",
      "published_date": "2025-11-10 13:58:17 UTC",
      "updated_date": "2025-11-10 13:58:17 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:02:41.701502+00:00"
    },
    {
      "arxiv_id": "2511.07110v2",
      "title": "Two Heads are Better than One: Distilling Large Language Model Features Into Small Models with Feature Decomposition and Mixture",
      "title_zh": "é›†æ€å¹¿ç›Šï¼šåŸºäºç‰¹å¾åˆ†è§£ä¸æ··åˆçš„å¤§è¯­è¨€æ¨¡å‹ç‰¹å¾å‘å°æ¨¡å‹è’¸é¦",
      "authors": [
        "Tianhao Fu",
        "Xinxin Xu",
        "Weichen Xu",
        "Jue Chen",
        "Ruilong Ren",
        "Bowen Deng",
        "Xinyu Zhao",
        "Jian Cao",
        "Xixin Cao"
      ],
      "abstract": "Market making (MM) through Reinforcement Learning (RL) has attracted significant attention in financial trading. With the development of Large Language Models (LLMs), more and more attempts are being made to apply LLMs to financial areas. A simple, direct application of LLM as an agent shows significant performance. Such methods are hindered by their slow inference speed, while most of the current research has not studied LLM distillation for this specific task. To address this, we first propose the normalized fluorescent probe to study the mechanism of the LLM's feature. Based on the observation found by our investigation, we propose Cooperative Market Making (CMM), a novel framework that decouples LLM features across three orthogonal dimensions: layer, task, and data. Various student models collaboratively learn simple LLM features along with different dimensions, with each model responsible for a distinct feature to achieve knowledge distillation. Furthermore, CMM introduces an HÃ¡jek-MoE to integrate the output of the student models by investigating the contribution of different models in a kernel function-generated common feature space. Extensive experimental results on four real-world market datasets demonstrate the superiority of CMM over the current distillation method and RL-based market-making strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨é‡‘èåšå¸‚(Market Making)ä»»åŠ¡ä¸­æ¨ç†é€Ÿåº¦æ…¢ä¸”ç¼ºä¹ç‰¹å®šè’¸é¦ç ”ç©¶çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCooperative Market Making (CMM)çš„æ–°é¢–æ¡†æ¶ã€‚ç ”ç©¶è€…é¦–å…ˆåˆ©ç”¨normalized fluorescent probeæ¢ç©¶äº†LLMçš„ç‰¹å¾æœºåˆ¶ï¼ŒåŸºäºæ­¤å‘ç°å°†LLMç‰¹å¾åœ¨å±‚(layer)ã€ä»»åŠ¡(task)å’Œæ•°æ®(data)ä¸‰ä¸ªæ­£äº¤ç»´åº¦ä¸Šè¿›è¡Œè§£è€¦ã€‚å¤šä¸ªå­¦ç”Ÿæ¨¡å‹ååŒå·¥ä½œï¼Œåˆ†åˆ«è´Ÿè´£å­¦ä¹ ä¸åŒç»´åº¦ä¸Šçš„ç®€å•LLMç‰¹å¾ä»¥å®ç°é«˜æ•ˆçš„çŸ¥è¯†è’¸é¦ã€‚æ­¤å¤–ï¼ŒCMMå¼•å…¥äº†HÃ¡jek-MoEï¼Œé€šè¿‡è€ƒå¯Ÿä¸åŒæ¨¡å‹åœ¨æ ¸å‡½æ•°ç”Ÿæˆçš„å…¬å…±ç‰¹å¾ç©ºé—´ä¸­çš„è´¡çŒ®æ¥æ•´åˆå­¦ç”Ÿæ¨¡å‹çš„è¾“å‡ºã€‚åœ¨å››ä¸ªçœŸå®å¸‚åœºæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒCMMçš„æ€§èƒ½æ˜¾è‘—ä¼˜äºå½“å‰çš„è’¸é¦æ–¹æ³•ä»¥åŠåŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„åšå¸‚ç­–ç•¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07110v2",
      "published_date": "2025-11-10 13:57:05 UTC",
      "updated_date": "2025-11-11 17:45:39 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:03:26.485942+00:00"
    },
    {
      "arxiv_id": "2511.07107v2",
      "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Domain Risks in LLMs",
      "title_zh": "MENTORï¼šæ­ç¤ºä¸ç¼“è§£å¤§è¯­è¨€æ¨¡å‹éšæ€§é¢†åŸŸé£é™©çš„å…ƒè®¤çŸ¥é©±åŠ¨è‡ªè¿›åŒ–æ¡†æ¶",
      "authors": [
        "Liang Shan",
        "Kaicheng Shen",
        "Wen Wu",
        "Zhenyu Ying",
        "Chaochao Lu",
        "Yan Teng",
        "Jingqi Huang",
        "Guangze Ye",
        "Guoqing Wang",
        "Liang He"
      ],
      "abstract": "Ensuring the safety of Large Language Models (LLMs) is critical for real-world deployment. However, current safety measures often fail to address implicit, domain-specific risks. To investigate this gap, we introduce a dataset of 3,000 annotated queries spanning education, finance, and management. Evaluations across 14 leading LLMs reveal a concerning vulnerability: an average jailbreak success rate of 57.8%. In response, we propose MENTOR, a metacognition-driven self-evolution framework. MENTOR first performs structured self-assessment through simulated critical thinking, such as perspective-taking and consequential reasoning to uncover latent model misalignments. These reflections are formalized into dynamic rule-based knowledge graphs that evolve with emerging risk patterns. To enforce these rules at inference time, we introduce activation steering, a method that directly modulates the model's internal representations to ensure compliance. Experiments demonstrate that MENTOR substantially reduces attack success rates across all tested domains and achieves risk analysis performance comparable to human experts. Our work offers a scalable and adaptive pathway toward robust domain-specific alignment of LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç‰¹å®šé¢†åŸŸéšå«é£é™©æ–¹é¢çš„å®‰å…¨æ¼æ´ï¼Œæ„å»ºäº†ä¸€ä¸ªåŒ…å«æ•™è‚²ã€é‡‘èå’Œç®¡ç†é¢†åŸŸçš„3000ä¸ªæŸ¥è¯¢çš„æ•°æ®é›†ï¼Œè¯„ä¼°å‘ç°14ä¸ªä¸»æµLLMsçš„å¹³å‡è¶Šç‹±(jailbreak)æˆåŠŸç‡é«˜è¾¾57.8%ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†MENTORï¼Œä¸€ç§å…ƒè®¤çŸ¥é©±åŠ¨çš„è‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨å‘ç°å¹¶ç¼“è§£è¿™äº›éšæ€§é£é™©ã€‚MENTORé¦–å…ˆé€šè¿‡æ¨¡æ‹Ÿæ‰¹åˆ¤æ€§æ€ç»´ï¼ˆå¦‚è§‚ç‚¹é‡‡æ‹©å’Œåæœæ¨ç†ï¼‰è¿›è¡Œç»“æ„åŒ–è‡ªæˆ‘è¯„ä¼°ï¼Œå°†åæ€è½¬åŒ–ä¸ºéšé£é™©æ¨¡å¼æ¼”å˜çš„åŠ¨æ€è§„åˆ™çŸ¥è¯†å›¾è°±ã€‚ä¸ºäº†åœ¨æ¨ç†é˜¶æ®µæ‰§è¡Œè¿™äº›è§„åˆ™ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ¿€æ´»å¼•å¯¼(activation steering)æŠ€æœ¯ï¼Œç›´æ¥è°ƒèŠ‚æ¨¡å‹çš„å†…éƒ¨è¡¨ç¤ºä»¥ç¡®ä¿åˆè§„æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMENTORæ˜¾è‘—é™ä½äº†å„æµ‹è¯•é¢†åŸŸçš„æ”»å‡»æˆåŠŸç‡ï¼Œå¹¶å®ç°äº†ä¸äººç±»ä¸“å®¶ç›¸å½“çš„é£é™©åˆ†ææ€§èƒ½ï¼Œä¸ºLLMsçš„é¢†åŸŸç‰¹å®šå¯¹é½æä¾›äº†ä¸€æ¡å¯æ‰©å±•çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07107v2",
      "published_date": "2025-11-10 13:51:51 UTC",
      "updated_date": "2026-01-08 04:30:15 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:03:55.945307+00:00"
    },
    {
      "arxiv_id": "2511.07104v3",
      "title": "A Theoretical Analysis of Detecting Large Model-Generated Time Series",
      "title_zh": "å¤§æ¨¡å‹ç”Ÿæˆæ—¶é—´åºåˆ—æ£€æµ‹çš„ç†è®ºåˆ†æ",
      "authors": [
        "Junji Hou",
        "Junzhou Zhao",
        "Shuo Zhang",
        "Pinghui Wang"
      ],
      "abstract": "Motivated by the increasing risks of data misuse and fabrication, we investigate the problem of identifying synthetic time series generated by Time-Series Large Models (TSLMs) in this work. While there are extensive researches on detecting model generated text, we find that these existing methods are not applicable to time series data due to the fundamental modality difference, as time series usually have lower information density and smoother probability distributions than text data, which limit the discriminative power of token-based detectors. To address this issue, we examine the subtle distributional differences between real and model-generated time series and propose the contraction hypothesis, which states that model-generated time series, unlike real ones, exhibit progressively decreasing uncertainty under recursive forecasting. We formally prove this hypothesis under theoretical assumptions on model behavior and time series structure. Model-generated time series exhibit progressively concentrated distributions under recursive forecasting, leading to uncertainty contraction. We provide empirical validation of the hypothesis across diverse datasets. Building on this insight, we introduce the Uncertainty Contraction Estimator (UCE), a white-box detector that aggregates uncertainty metrics over successive prefixes to identify TSLM-generated time series. Extensive experiments on 32 datasets show that UCE consistently outperforms state-of-the-art baselines, offering a reliable and generalizable solution for detecting model-generated time series.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æ•°æ®æ»¥ç”¨å’Œä¼ªé€ é£é™©å¢åŠ çš„é—®é¢˜ï¼Œæ¢è®¨äº†å¦‚ä½•è¯†åˆ«ç”±æ—¶é—´åºåˆ—å¤§æ¨¡å‹(TSLMs)ç”Ÿæˆçš„åˆæˆæ—¶é—´åºåˆ—ã€‚ä½œè€…æŒ‡å‡ºï¼Œç”±äºæ—¶é—´åºåˆ—æ•°æ®ç›¸è¾ƒäºæ–‡æœ¬å…·æœ‰è¾ƒä½çš„ä¿¡æ¯å¯†åº¦å’Œæ›´å¹³æ»‘çš„æ¦‚ç‡åˆ†å¸ƒï¼Œç°æœ‰çš„æ–‡æœ¬æ£€æµ‹æ–¹æ³•å¹¶ä¸é€‚ç”¨ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶æå‡ºäº†æ”¶ç¼©å‡è®¾(contraction hypothesis)ï¼Œå³æ¨¡å‹ç”Ÿæˆçš„æ—¶é—´åºåˆ—åœ¨é€’å½’é¢„æµ‹ä¸‹ä¼šè¡¨ç°å‡ºé€æ¸é™ä½çš„ä¸ç¡®å®šæ€§ï¼Œå¹¶å¯¹æ­¤è¿›è¡Œäº†ç†è®ºè¯æ˜ã€‚åŸºäºè¿™ä¸€å‘ç°ï¼Œä½œè€…å¼•å…¥äº†ä¸ç¡®å®šæ€§æ”¶ç¼©ä¼°è®¡å™¨(Uncertainty Contraction Estimator, UCE)ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡èšåˆè¿ç»­å‰ç¼€çš„ä¸ç¡®å®šæ€§æŒ‡æ ‡æ¥è¯†åˆ«TSLMç”Ÿæˆå†…å®¹çš„ç™½ç›’æ£€æµ‹å™¨ã€‚åœ¨32ä¸ªæ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒUCEå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ï¼Œä¸ºæ£€æµ‹æ¨¡å‹ç”Ÿæˆçš„æ—¶é—´åºåˆ—æä¾›äº†ä¸€ç§å¯é ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages,12 figures, to be published in AAAI-2026 main track",
      "pdf_url": "https://arxiv.org/pdf/2511.07104v3",
      "published_date": "2025-11-10 13:48:48 UTC",
      "updated_date": "2025-11-12 01:51:57 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:04:33.722827+00:00"
    },
    {
      "arxiv_id": "2511.07103v1",
      "title": "GEWDiff: Geometric Enhanced Wavelet-based Diffusion Model for Hyperspectral Image Super-resolution",
      "title_zh": "GEWDiffï¼šç”¨äºé«˜å…‰è°±å›¾åƒè¶…åˆ†è¾¨ç‡çš„å‡ ä½•å¢å¼ºå°æ³¢æ‰©æ•£æ¨¡å‹",
      "authors": [
        "Sirui Wang",
        "Jiang He",
        "NatÃ lia Blasco Andreo",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Improving the quality of hyperspectral images (HSIs), such as through super-resolution, is a crucial research area. However, generative modeling for HSIs presents several challenges. Due to their high spectral dimensionality, HSIs are too memory-intensive for direct input into conventional diffusion models. Furthermore, general generative models lack an understanding of the topological and geometric structures of ground objects in remote sensing imagery. In addition, most diffusion models optimize loss functions at the noise level, leading to a non-intuitive convergence behavior and suboptimal generation quality for complex data. To address these challenges, we propose a Geometric Enhanced Wavelet-based Diffusion Model (GEWDiff), a novel framework for reconstructing hyperspectral images at 4-times super-resolution. A wavelet-based encoder-decoder is introduced that efficiently compresses HSIs into a latent space while preserving spectral-spatial information. To avoid distortion during generation, we incorporate a geometry-enhanced diffusion process that preserves the geometric features. Furthermore, a multi-level loss function was designed to guide the diffusion process, promoting stable convergence and improved reconstruction fidelity. Our model demonstrated state-of-the-art results across multiple dimensions, including fidelity, spectral accuracy, visual realism, and clarity.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GEWDiffï¼Œä¸€ç§ç”¨äºé«˜å…‰è°±å›¾åƒ(Hyperspectral Images, HSIs)è¶…åˆ†è¾¨ç‡é‡å»ºçš„å‡ ä½•å¢å¼ºå°æ³¢æ‰©æ•£æ¨¡å‹(Geometric Enhanced Wavelet-based Diffusion Model)ã€‚é’ˆå¯¹HSIé«˜å…‰è°±ç»´åº¦å¯¼è‡´çš„å†…å­˜é™åˆ¶ã€ç°æœ‰æ¨¡å‹ç¼ºä¹å¯¹åœ°ç‰©å‡ ä½•ç»“æ„ç†è§£ä»¥åŠä¼ ç»Ÿå™ªå£°çº§æŸå¤±å‡½æ•°å¯¼è‡´æ”¶æ•›ä¸ä½³ç­‰æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å®ç°äº†4å€è¶…åˆ†è¾¨ç‡é‡å»ºã€‚ç ”ç©¶å¼•å…¥äº†åŸºäºå°æ³¢çš„ç¼–ç å™¨-è§£ç å™¨(Wavelet-based encoder-decoder)ï¼Œåœ¨å°†HSIé«˜æ•ˆå‹ç¼©è‡³æ½œåœ¨ç©ºé—´çš„åŒæ—¶ä¿ç•™äº†å…³é”®çš„å…‰è°±-ç©ºé—´ä¿¡æ¯ã€‚ä¸ºäº†é˜²æ­¢ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å¤±çœŸï¼Œæ¨¡å‹æ•´åˆäº†èƒ½å¤Ÿä¿æŒå‡ ä½•ç‰¹å¾çš„å‡ ä½•å¢å¼ºæ‰©æ•£è¿‡ç¨‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†å¤šçº§æŸå¤±å‡½æ•°(Multi-level loss function)æ¥å¼•å¯¼æ‰©æ•£ï¼Œä»è€Œä¿ƒè¿›ç¨³å®šæ”¶æ•›å¹¶æå‡é‡å»ºä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGEWDiffåœ¨ä¿çœŸåº¦ã€å…‰è°±å‡†ç¡®æ€§ã€è§†è§‰çœŸå®æ„Ÿå’Œæ¸…æ™°åº¦ç­‰å¤šä¸ªç»´åº¦ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›(State-of-the-art)çš„ç»“æœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This manuscript has been accepted for publication in AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07103v1",
      "published_date": "2025-11-10 13:44:16 UTC",
      "updated_date": "2025-11-10 13:44:16 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:05:00.975571+00:00"
    },
    {
      "arxiv_id": "2511.07099v1",
      "title": "E2E-VGuard: Adversarial Prevention for Production LLM-based End-To-End Speech Synthesis",
      "title_zh": "E2E-VGuardï¼šé¢å‘ç”Ÿäº§çº§åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ç«¯åˆ°ç«¯è¯­éŸ³åˆæˆçš„å¯¹æŠ—æ€§é˜²å¾¡",
      "authors": [
        "Zhisheng Zhang",
        "Derui Wang",
        "Yifan Mi",
        "Zhiyong Wu",
        "Jie Gao",
        "Yuxin Cao",
        "Kai Ye",
        "Minhui Xue",
        "Jie Hao"
      ],
      "abstract": "Recent advancements in speech synthesis technology have enriched our daily lives, with high-quality and human-like audio widely adopted across real-world applications. However, malicious exploitation like voice-cloning fraud poses severe security risks. Existing defense techniques struggle to address the production large language model (LLM)-based speech synthesis. While previous studies have considered the protection for fine-tuning synthesizers, they assume manually annotated transcripts. Given the labor intensity of manual annotation, end-to-end (E2E) systems leveraging automatic speech recognition (ASR) to generate transcripts are becoming increasingly prevalent, e.g., voice cloning via commercial APIs. Therefore, this E2E speech synthesis also requires new security mechanisms. To tackle these challenges, we propose E2E-VGuard, a proactive defense framework for two emerging threats: (1) production LLM-based speech synthesis, and (2) the novel attack arising from ASR-driven E2E scenarios. Specifically, we employ the encoder ensemble with a feature extractor to protect timbre, while ASR-targeted adversarial examples disrupt pronunciation. Moreover, we incorporate the psychoacoustic model to ensure perturbative imperceptibility. For a comprehensive evaluation, we test 16 open-source synthesizers and 3 commercial APIs across Chinese and English datasets, confirming E2E-VGuard's effectiveness in timbre and pronunciation protection. Real-world deployment validation is also conducted. Our code and demo page are available at https://wxzyd123.github.io/e2e-vguard/.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†E2E-VGuardï¼Œä¸€ç§é’ˆå¯¹ç”Ÿäº§çº§åŸºäºLLMçš„ç«¯åˆ°ç«¯(E2E)è¯­éŸ³åˆæˆç³»ç»Ÿçš„ä¸»åŠ¨é˜²å¾¡æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹å£°éŸ³å…‹éš†æ¬ºè¯ˆç­‰å®‰å…¨é£é™©ã€‚ç°æœ‰çš„é˜²å¾¡æŠ€æœ¯éš¾ä»¥è§£å†³åŸºäºLLMçš„åˆæˆé—®é¢˜ï¼Œä¸”å¾€å¾€å¿½ç•¥äº†åˆ©ç”¨è‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR)ç”Ÿæˆè½¬å½•æ–‡æœ¬çš„E2Eåœºæ™¯æ‰€å¸¦æ¥çš„æ–°å¨èƒã€‚E2E-VGuardé€šè¿‡ç»“åˆå¸¦æœ‰ç‰¹å¾æå–å™¨çš„ç¼–ç å™¨é›†æˆæ¥ä¿æŠ¤éŸ³è‰²ï¼ŒåŒæ—¶åˆ©ç”¨é’ˆå¯¹ASRçš„å¯¹æŠ—æ ·æœ¬(adversarial examples)æ¥ç ´åå‘éŸ³ç”Ÿæˆã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶æ•´åˆäº†å¿ƒç†å£°å­¦æ¨¡å‹(psychoacoustic model)ä»¥ç¡®ä¿æ·»åŠ çš„æ‰°åŠ¨å¯¹äººç±»å¬è§‰ä¸å¯æ„ŸçŸ¥ã€‚åœ¨ä¸­æ–‡å’Œè‹±æ–‡æ•°æ®é›†ä¸Šå¯¹16ä¸ªå¼€æºåˆæˆå™¨å’Œ3ä¸ªå•†ä¸šAPIçš„å¹¿æ³›è¯„ä¼°è¯å®äº†è¯¥æ–¹æ³•åœ¨éŸ³è‰²å’Œå‘éŸ³ä¿æŠ¤æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶éªŒè¯äº†å…¶åœ¨ç°å®ä¸–ç•Œéƒ¨ç½²ä¸­çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.07099v1",
      "published_date": "2025-11-10 13:38:53 UTC",
      "updated_date": "2025-11-10 13:38:53 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:05:26.430870+00:00"
    },
    {
      "arxiv_id": "2511.07098v1",
      "title": "Boosting Fine-Grained Urban Flow Inference via Lightweight Architecture and Focalized Optimization",
      "title_zh": "åŸºäºè½»é‡çº§æ¶æ„ä¸èšç„¦ä¼˜åŒ–çš„ç»†ç²’åº¦åŸå¸‚æµé‡æ¨æ–­æå‡",
      "authors": [
        "Yuanshao Zhu",
        "Xiangyu Zhao",
        "Zijian Zhang",
        "Xuetao Wei",
        "James Jianqiao Yu"
      ],
      "abstract": "Fine-grained urban flow inference is crucial for urban planning and intelligent transportation systems, enabling precise traffic management and resource allocation. However, the practical deployment of existing methods is hindered by two key challenges: the prohibitive computational cost of over-parameterized models and the suboptimal performance of conventional loss functions on the highly skewed distribution of urban flows. To address these challenges, we propose a unified solution that synergizes architectural efficiency with adaptive optimization. Specifically, we first introduce PLGF, a lightweight yet powerful architecture that employs a Progressive Local-Global Fusion strategy to effectively capture both fine-grained details and global contextual dependencies. Second, we propose DualFocal Loss, a novel function that integrates dual-space supervision with a difficulty-aware focusing mechanism, enabling the model to adaptively concentrate on hard-to-predict regions. Extensive experiments on 4 real-world scenarios validate the effectiveness and scalability of our method. Notably, while achieving state-of-the-art performance, PLGF reduces the model size by up to 97% compared to current high-performing methods. Furthermore, under comparable parameter budgets, our model yields an accuracy improvement of over 10% against strong baselines. The implementation is included in the https://github.com/Yasoz/PLGF.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç»†ç²’åº¦åŸå¸‚æµé‡æ¨æ–­ä¸­å­˜åœ¨çš„æ¨¡å‹è®¡ç®—æˆæœ¬é«˜æ˜‚å’Œæ•°æ®åˆ†å¸ƒé«˜åº¦åæ–œä¸¤å¤§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæ¶æ„æ•ˆç‡ä¸è‡ªé€‚åº”ä¼˜åŒ–çš„ç»Ÿä¸€è§£å†³æ–¹æ¡ˆã€‚ä½œè€…é¦–å…ˆå¼•å…¥äº†PLGFï¼Œè¿™æ˜¯ä¸€ç§é‡‡ç”¨æ¸è¿›å¼å±€éƒ¨-å…¨å±€èåˆç­–ç•¥(Progressive Local-Global Fusion)çš„è½»é‡çº§æ¶æ„ï¼Œæ—¨åœ¨æœ‰æ•ˆæ•æ‰ç»†ç²’åº¦ç»†èŠ‚å’Œå…¨å±€ä¸Šä¸‹æ–‡ä¾èµ–ã€‚å…¶æ¬¡ï¼Œç ”ç©¶æå‡ºäº†DualFocal Lossï¼Œé€šè¿‡ç»“åˆåŒç©ºé—´ç›‘ç£ä¸éš¾åº¦æ„ŸçŸ¥èšç„¦æœºåˆ¶ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè‡ªé€‚åº”åœ°ä¸“æ³¨äºéš¾ä»¥é¢„æµ‹çš„åŒºåŸŸã€‚åœ¨4ä¸ªçœŸå®åœºæ™¯ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒPLGFåœ¨è¾¾åˆ°æœ€å…ˆè¿›æ€§èƒ½çš„åŒæ—¶ï¼Œç›¸æ¯”ç°æœ‰é«˜æ€§èƒ½æ–¹æ³•å°†æ¨¡å‹å¤§å°å‡å°‘äº†é«˜è¾¾97%ã€‚æ­¤å¤–ï¼Œåœ¨ç›¸å½“çš„å‚æ•°é¢„ç®—ä¸‹ï¼Œè¯¥æ¨¡å‹çš„å‡†ç¡®ç‡æ¯”å¼ºåŸºçº¿æ¨¡å‹æé«˜äº†è¶…è¿‡10%ï¼ŒéªŒè¯äº†å…¶æœ‰æ•ˆæ€§å’Œå¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a regular paper by AAAI'26",
      "pdf_url": "https://arxiv.org/pdf/2511.07098v1",
      "published_date": "2025-11-10 13:38:26 UTC",
      "updated_date": "2025-11-10 13:38:26 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:05:51.471169+00:00"
    },
    {
      "arxiv_id": "2511.07097v1",
      "title": "Agentic AI Sustainability Assessment for Supply Chain Document Insights",
      "title_zh": "é¢å‘ä¾›åº”é“¾æ–‡æ¡£æ´å¯Ÿçš„ä»£ç†å¼ AI å¯æŒç»­æ€§è¯„ä¼°",
      "authors": [
        "Diego Gosmar",
        "Anna Chiara Pallotta",
        "Giovanni Zenezini"
      ],
      "abstract": "This paper presents a comprehensive sustainability assessment framework for document intelligence within supply chain operations, centered on agentic artificial intelligence (AI). We address the dual objective of improving automation efficiency while providing measurable environmental performance in document-intensive workflows. The research compares three scenarios: fully manual (human-only), AI-assisted (human-in-the-loop, HITL), and an advanced multi-agent agentic AI workflow leveraging parsers and verifiers. Empirical results show that AI-assisted HITL and agentic AI scenarios achieve reductions of up to 70-90% in energy consumption, 90-97% in carbon dioxide emissions, and 89-98% in water usage compared to manual processes. Notably, full agentic configurations, combining advanced reasoning (thinking mode) and multi-agent validation, achieve substantial sustainability gains over human-only approaches, even when resource usage increases slightly versus simpler AI-assisted solutions. The framework integrates performance, energy, and emission indicators into a unified ESG-oriented methodology for assessing and governing AI-enabled supply chain solutions. The paper includes a complete replicability use case demonstrating the methodology's application to real-world document extraction tasks.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªé’ˆå¯¹ä¾›åº”é“¾æ–‡æ¡£æ™ºèƒ½(Document Intelligence)çš„ç»¼åˆå¯æŒç»­æ€§è¯„ä¼°æ¡†æ¶ï¼Œæ ¸å¿ƒèšç„¦äºAgentic AIæŠ€æœ¯ã€‚ç ”ç©¶æ—¨åœ¨è§£å†³åœ¨æ–‡æ¡£å¯†é›†å‹å·¥ä½œæµä¸­åŒæ—¶æé«˜è‡ªåŠ¨åŒ–æ•ˆç‡å’Œæä¾›å¯è¡¡é‡ç¯å¢ƒç»©æ•ˆçš„åŒé‡ç›®æ ‡ã€‚é€šè¿‡å¯¹æ¯”å…¨äººå·¥ã€AIè¾…åŠ©(Human-in-the-Loop, HITL)ä»¥åŠåˆ©ç”¨è§£æå™¨å’ŒéªŒè¯å™¨çš„é«˜çº§å¤šæ™ºèƒ½ä½“Agentic AIå·¥ä½œæµä¸‰ç§åœºæ™¯ï¼Œå®è¯ç»“æœè¡¨æ˜ï¼ŒAIè¾…åŠ©å’ŒAgentic AIåœºæ™¯ç›¸æ¯”äººå·¥æµç¨‹åœ¨èƒ½æºæ¶ˆè€—ä¸Šå‡å°‘äº†70-90%ï¼ŒäºŒæ°§åŒ–ç¢³æ’æ”¾å‡å°‘äº†90-97%ï¼Œæ°´èµ„æºä½¿ç”¨å‡å°‘äº†89-98%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œç»“åˆäº†é«˜çº§æ¨ç†(Thinking Mode)å’Œå¤šæ™ºèƒ½ä½“éªŒè¯çš„å…¨Agenticé…ç½®è™½ç„¶èµ„æºä½¿ç”¨ç•¥é«˜äºç®€å•çš„AIè¾…åŠ©æ–¹æ¡ˆï¼Œä½†ç›¸æ¯”çº¯äººå·¥æ–¹æ³•ä»å®ç°äº†æ˜¾è‘—çš„å¯æŒç»­æ€§æ”¶ç›Šã€‚è¯¥æ¡†æ¶å°†æ€§èƒ½ã€èƒ½æºå’Œæ’æ”¾æŒ‡æ ‡æ•´åˆä¸ºä¸€ç§ç»Ÿä¸€çš„ESGå¯¼å‘æ–¹æ³•ï¼Œç”¨äºè¯„ä¼°å’Œæ²»ç†AIèµ‹èƒ½çš„ä¾›åº”é“¾è§£å†³æ–¹æ¡ˆï¼Œå¹¶åŒ…å«äº†ä¸€ä¸ªå®Œæ•´çš„å¯å¤åˆ¶ç”¨ä¾‹ä»¥å±•ç¤ºå…¶å®é™…åº”ç”¨ã€‚",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.07097v1",
      "published_date": "2025-11-10 13:38:08 UTC",
      "updated_date": "2025-11-10 13:38:08 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:09:03.343324+00:00"
    },
    {
      "arxiv_id": "2511.07095v2",
      "title": "Data Complexity of Querying Description Logic Knowledge Bases under Cost-Based Semantics",
      "title_zh": "ä»£ä»·è¯­ä¹‰ä¸‹æŸ¥è¯¢æè¿°é€»è¾‘çŸ¥è¯†åº“çš„æ•°æ®å¤æ‚åº¦",
      "authors": [
        "Meghyn Bienvenu",
        "Quentin ManiÃ¨re"
      ],
      "abstract": "In this paper, we study the data complexity of querying inconsistent weighted description logic (DL) knowledge bases under recently-introduced cost-based semantics. In a nutshell, the idea is to assign each interpretation a cost based upon the weights of the violated axioms and assertions, and certain and possible query answers are determined by considering all (resp. some) interpretations having optimal or bounded cost. Whereas the initial study of cost-based semantics focused on DLs between $\\mathcal{EL}_\\bot$ and $\\mathcal{ALCO}$, we consider DLs that may contain inverse roles and role inclusions, thus covering prominent DL-Lite dialects. Our data complexity analysis goes significantly beyond existing results by sharpening several lower bounds and pinpointing the precise complexity of optimal-cost certain answer semantics (no non-trivial upper bound was known). Moreover, while all existing results show the intractability of cost-based semantics, our most challenging and surprising result establishes that if we consider $\\text{DL-Lite}^\\mathcal{H}_\\mathsf{bool}$ ontologies and a fixed cost bound, certain answers for instance queries and possible answers for conjunctive queries can be computed using first-order rewriting and thus enjoy the lowest possible data complexity ($\\mathsf{TC}_0$).",
      "tldr_zh": "æœ¬æ–‡ç ”ç©¶äº†åœ¨åŸºäºæˆæœ¬çš„è¯­ä¹‰(cost-based semantics)ä¸‹ï¼ŒæŸ¥è¯¢ä¸ä¸€è‡´åŠ æƒæè¿°é€»è¾‘(Description Logic, DL)çŸ¥è¯†åº“çš„æ•°æ®å¤æ‚æ€§ã€‚è¯¥ç ”ç©¶å°†åˆ†æèŒƒå›´ä»å…ˆå‰çš„$\\mathcal{EL}_\\bot$å’Œ$\\mathcal{ALCO}$æ‰©å±•åˆ°äº†åŒ…å«é€†è§’è‰²å’Œè§’è‰²åŒ…å«çš„DLï¼Œä»è€Œè¦†ç›–äº†ä¸»æµçš„DL-Liteæ–¹è¨€ã€‚ä½œè€…é€šè¿‡å¼ºåŒ–ä¸‹ç•Œå¹¶ç¡®å®šæœ€ä¼˜æˆæœ¬ç¡®å®šç­”æ¡ˆè¯­ä¹‰(optimal-cost certain answer semantics)çš„ç²¾ç¡®å¤æ‚æ€§ï¼Œæ˜¾è‘—æ¨è¿›äº†ç°æœ‰çš„ç†è®ºåˆ†æç»“æœã€‚å°½ç®¡ç°æœ‰ç ”ç©¶é€šå¸¸æ˜¾ç¤ºåŸºäºæˆæœ¬çš„è¯­ä¹‰å…·æœ‰éš¾è§£æ€§ï¼Œä½†æœ¬æ–‡å¾—å‡ºäº†ä¸€ä¸ªä»¤äººæƒŠè®¶çš„ç»“è®ºï¼šå¯¹äº$\\text{DL-Lite}^\\mathcal{H}_\\mathsf{bool}$æœ¬ä½“å’Œå›ºå®šæˆæœ¬ç•Œé™ï¼Œå®ä¾‹æŸ¥è¯¢çš„ç¡®å®šç­”æ¡ˆå’Œåˆå–æŸ¥è¯¢çš„å¯èƒ½ç­”æ¡ˆå¯ä»¥é€šè¿‡ä¸€é˜¶é‡å†™(first-order rewriting)æ¥è®¡ç®—ã€‚è¿™æ„å‘³ç€è¿™äº›æŸ¥è¯¢äº«æœ‰æœ€ä½çš„æ•°æ®å¤æ‚æ€§($\\mathsf{TC}_0$)ï¼Œè¯æ˜äº†åœ¨ç‰¹å®šæ¡ä»¶ä¸‹è¯¥è¯­ä¹‰çš„é«˜æ•ˆå¯è®¡ç®—æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages. Long version of paper to appear in AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07095v2",
      "published_date": "2025-11-10 13:34:24 UTC",
      "updated_date": "2025-11-14 03:50:37 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:09:29.304954+00:00"
    },
    {
      "arxiv_id": "2511.07092v1",
      "title": "Sample-efficient quantum error mitigation via classical learning surrogates",
      "title_zh": "åŸºäºç»å…¸å­¦ä¹ ä»£ç†çš„æ ·æœ¬é«˜æ•ˆé‡å­è¯¯å·®ç¼“è§£",
      "authors": [
        "Wei-You Liao",
        "Ge Yan",
        "Yujin Song",
        "Tian-Ci Tian",
        "Wei-Ming Zhu",
        "De-Tao Jiang",
        "Yuxuan Du",
        "He-Liang Huang"
      ],
      "abstract": "The pursuit of practical quantum utility on near-term quantum processors is critically challenged by their inherent noise. Quantum error mitigation (QEM) techniques are leading solutions to improve computation fidelity with relatively low qubit-overhead, while full-scale quantum error correction remains a distant goal. However, QEM techniques incur substantial measurement overheads, especially when applied to families of quantum circuits parameterized by classical inputs. Focusing on zero-noise extrapolation (ZNE), a widely adopted QEM technique, here we devise the surrogate-enabled ZNE (S-ZNE), which leverages classical learning surrogates to perform ZNE entirely on the classical side. Unlike conventional ZNE, whose measurement cost scales linearly with the number of circuits, S-ZNE requires only constant measurement overhead for an entire family of quantum circuits, offering superior scalability. Theoretical analysis indicates that S-ZNE achieves accuracy comparable to conventional ZNE in many practical scenarios, and numerical experiments on up to 100-qubit ground-state energy and quantum metrology tasks confirm its effectiveness. Our approach provides a template that can be effectively extended to other quantum error mitigation protocols, opening a promising path toward scalable error mitigation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¿‘æœŸé‡å­å¤„ç†å™¨é¢ä¸´çš„å™ªå£°æŒ‘æˆ˜å’Œç°æœ‰é‡å­è¯¯å·®ç¼“è§£(QEM)æŠ€æœ¯çš„é«˜æµ‹é‡å¼€é”€é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºS-ZNEçš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç»å…¸å­¦ä¹ ä»£ç†(classical learning surrogates)æ”¹è¿›äº†å¹¿æ³›ä½¿ç”¨çš„é›¶å™ªå£°å¤–æ¨(ZNE)æŠ€æœ¯ï¼Œä½¿å…¶èƒ½å¤Ÿå®Œå…¨åœ¨ç»å…¸ä¾§æ‰§è¡Œã€‚ä¸æµ‹é‡æˆæœ¬éšç”µè·¯æ•°é‡çº¿æ€§å¢é•¿çš„ä¼ ç»ŸZNEä¸åŒï¼ŒS-ZNEå¯¹æ•´ä¸ªå‚æ•°åŒ–é‡å­ç”µè·¯å®¶æ—ä»…éœ€æ’å®šçš„æµ‹é‡å¼€é”€ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†æ ·æœ¬æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚ç†è®ºåˆ†ææ˜¾ç¤ºS-ZNEåœ¨å¤šç§åœºæ™¯ä¸‹å…·æœ‰ä¸ä¼ ç»Ÿæ–¹æ³•ç›¸å½“çš„ç²¾åº¦ï¼Œè€Œåœ¨é«˜è¾¾100ä¸ªé‡å­æ¯”ç‰¹çš„åŸºæ€èƒ½é‡å’Œé‡å­è®¡é‡ä»»åŠ¡ä¸Šçš„æ•°å€¼å®éªŒè¿›ä¸€æ­¥éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚è¿™é¡¹å·¥ä½œä¸ä»…æä¾›äº†ä¸€ç§é«˜æ•ˆçš„è¯¯å·®ç¼“è§£æ–¹æ¡ˆï¼Œä¹Ÿä¸ºå°†è¯¥ç­–ç•¥æ‰©å±•è‡³å…¶ä»–QEMåè®®æä¾›äº†é€šç”¨æ¨¡æ¿ã€‚",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "26 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.07092v1",
      "published_date": "2025-11-10 13:29:29 UTC",
      "updated_date": "2025-11-10 13:29:29 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:09:50.177375+00:00"
    },
    {
      "arxiv_id": "2511.07091v1",
      "title": "How Bias Binds: Measuring Hidden Associations for Bias Control in Text-to-Image Compositions",
      "title_zh": "åè§å¦‚ä½•ç»‘å®šï¼šæ–‡ç”Ÿå›¾ç»„åˆç”Ÿæˆä¸­é¢å‘åè§æ§åˆ¶çš„éšæ€§å…³è”åº¦é‡",
      "authors": [
        "Jeng-Lin Li",
        "Ming-Ching Chang",
        "Wei-Chao Chen"
      ],
      "abstract": "Text-to-image generative models often exhibit bias related to sensitive attributes. However, current research tends to focus narrowly on single-object prompts with limited contextual diversity. In reality, each object or attribute within a prompt can contribute to bias. For example, the prompt \"an assistant wearing a pink hat\" may reflect female-inclined biases associated with a pink hat. The neglected joint effects of the semantic binding in the prompts cause significant failures in current debiasing approaches. This work initiates a preliminary investigation on how bias manifests under semantic binding, where contextual associations between objects and attributes influence generative outcomes. We demonstrate that the underlying bias distribution can be amplified based on these associations. Therefore, we introduce a bias adherence score that quantifies how specific object-attribute bindings activate bias. To delve deeper, we develop a training-free context-bias control framework to explore how token decoupling can facilitate the debiasing of semantic bindings. This framework achieves over 10% debiasing improvement in compositional generation tasks. Our analysis of bias scores across various attribute-object bindings and token decorrelation highlights a fundamental challenge: reducing bias without disrupting essential semantic relationships. These findings expose critical limitations in current debiasing approaches when applied to semantically bound contexts, underscoring the need to reassess prevailing bias mitigation strategies.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹(Text-to-image generative models)ä¸­å¸¸è¢«å¿½è§†çš„è¯­ä¹‰ç»‘å®š(semantic binding)æ•ˆåº”ï¼Œæ¢è®¨äº†ä¸Šä¸‹æ–‡å…³è”å¦‚ä½•æ”¾å¤§æ½œåœ¨çš„åè§åˆ†å¸ƒã€‚ç°æœ‰ç ”ç©¶å¤šé›†ä¸­äºå•ä¸€å¯¹è±¡æç¤ºï¼Œè€Œå¿½ç•¥äº†æç¤ºè¯ä¸­å¯¹è±¡ä¸å±æ€§ï¼ˆå¦‚â€œç²‰è‰²å¸½å­â€ï¼‰çš„è”åˆæ•ˆåº”ä¼šå¯¼è‡´ç°æœ‰å»åè§æ–¹æ³•å¤±æ•ˆã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼•å…¥äº†åå·®ä¾ä»æ€§è¯„åˆ†(bias adherence score)æ¥é‡åŒ–ç‰¹å®šå¯¹è±¡-å±æ€§ç»‘å®šæ¿€æ´»åè§çš„ç¨‹åº¦ã€‚è¿›ä¸€æ­¥åœ°ï¼Œç ”ç©¶å¼€å‘äº†ä¸€ç§æ— éœ€è®­ç»ƒçš„ä¸Šä¸‹æ–‡åè§æ§åˆ¶æ¡†æ¶(context-bias control framework)ï¼Œåˆ©ç”¨tokenè§£è€¦(token decoupling)æŠ€æœ¯æ¥ç¼“è§£è¯­ä¹‰ç»‘å®šä¸­çš„åè§ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨ç»„åˆç”Ÿæˆä»»åŠ¡ä¸­å–å¾—äº†è¶…è¿‡10%çš„å»åè§æ”¹è¿›ã€‚è¿™é¡¹å·¥ä½œå¼ºè°ƒäº†åœ¨ä¸ç ´ååŸºæœ¬è¯­ä¹‰å…³ç³»çš„æƒ…å†µä¸‹å‡å°‘åè§çš„æ ¹æœ¬æŒ‘æˆ˜ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰å»åè§ç­–ç•¥åœ¨å¤„ç†è¯­ä¹‰ç»‘å®šä¸Šä¸‹æ–‡æ—¶çš„å…³é”®å±€é™æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the Alignment Track of The 40th Annual AAAI Conference on Artificial Intelligence (AAAI 2026)",
      "pdf_url": "https://arxiv.org/pdf/2511.07091v1",
      "published_date": "2025-11-10 13:27:05 UTC",
      "updated_date": "2025-11-10 13:27:05 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:10:16.180755+00:00"
    },
    {
      "arxiv_id": "2511.07090v4",
      "title": "Green AI: A systematic review and meta-analysis of its definitions, lifecycle models, hardware and measurement attempts",
      "title_zh": "ç»¿è‰² AIï¼šå®šä¹‰ã€ç”Ÿå‘½å‘¨æœŸæ¨¡å‹ã€ç¡¬ä»¶åŠæµ‹é‡å°è¯•çš„ç³»ç»Ÿç»¼è¿°ä¸å…ƒåˆ†æ",
      "authors": [
        "Marcel Rojahn",
        "Marcus Grum"
      ],
      "abstract": "Across the Artificial Intelligence (AI) lifecycle - from hardware to development, deployment, and reuse - burdens span energy, carbon, water, and embodied impacts. Cloud provider tools improve transparency but remain heterogeneous and often omit water and value chain effects, limiting comparability and reproducibility. Addressing these multi dimensional burdens requires a lifecycle approach linking phase explicit mapping with system levers (hardware, placement, energy mix, cooling, scheduling) and calibrated measurement across facility, system, device, and workload levels. This article (i) establishes a unified, operational definition of Green AI distinct from Sustainable AI; (ii) formalizes a five phase lifecycle mapped to Life Cycle Assessment (LCA) stages, making energy, carbon, water, and embodied impacts first class; (iii) specifies governance via Plan Do Check Act (PDCA) cycles with decision gateways; (iv) systematizes hardware and system level strategies across the edge cloud continuum to reduce embodied burdens; and (v) defines a calibrated measurement framework combining estimator models with direct metering to enable reproducible, provider agnostic comparisons. Combining definition, lifecycle processes, hardware strategies, and calibrated measurement, this article offers actionable, evidence based guidance for researchers, practitioners, and policymakers.",
      "tldr_zh": "è¯¥ç ”ç©¶å¯¹Green AIçš„å®šä¹‰ã€ç”Ÿå‘½å‘¨æœŸæ¨¡å‹ã€ç¡¬ä»¶åŠæµ‹é‡å°è¯•è¿›è¡Œäº†ç³»ç»Ÿç»¼è¿°ä¸å…ƒåˆ†æï¼Œæ—¨åœ¨è§£å†³AIå…¨ç”Ÿå‘½å‘¨æœŸä¸­æ¶‰åŠçš„èƒ½æºã€ç¢³æ’æ”¾ã€æ°´èµ„æºåŠembodied impactsç­‰å¤šç»´è´Ÿæ‹…ã€‚æ–‡ç« é¦–å…ˆç¡®ç«‹äº†åŒºåˆ«äºSustainable AIçš„Green AIç»Ÿä¸€æ“ä½œå®šä¹‰ï¼Œå¹¶å½¢å¼åŒ–äº†ä¸€ä¸ªæ˜ å°„åˆ°Life Cycle Assessment (LCA)é˜¶æ®µçš„äº”é˜¶æ®µç”Ÿå‘½å‘¨æœŸæ¨¡å‹ã€‚ä¸ºäº†åŠ å¼ºæ²»ç†ä¸ä¼˜åŒ–ï¼Œç ”ç©¶æå‡ºäº†åŸºäºPlan Do Check Act (PDCA)å¾ªç¯çš„å†³ç­–æœºåˆ¶ï¼Œå¹¶ç³»ç»ŸåŒ–äº†è·¨è¶Šè¾¹ç¼˜-äº‘è¿ç»­ä½“çš„ç¡¬ä»¶ç­–ç•¥ä»¥å‡å°‘éšå«è´Ÿæ‹…ã€‚æ­¤å¤–ï¼Œæ–‡ç« å®šä¹‰äº†ä¸€ä¸ªç»“åˆä¼°ç®—æ¨¡å‹ä¸ç›´æ¥è®¡é‡çš„æ ¡å‡†æµ‹é‡æ¡†æ¶ï¼Œä»è€Œå®ç°å¯é‡å¤ä¸”ç‹¬ç«‹äºæä¾›å•†çš„æ¯”è¾ƒã€‚é€šè¿‡æ•´åˆå®šä¹‰ã€æµç¨‹ã€ç¡¬ä»¶ç­–ç•¥åŠæµ‹é‡æ–¹æ³•ï¼Œè¯¥ç ”ç©¶ä¸ºç›¸å…³é¢†åŸŸçš„ç ”ç©¶äººå‘˜ã€ä»ä¸šè€…åŠæ”¿ç­–åˆ¶å®šè€…æä¾›äº†åŸºäºè¯æ®çš„å¯æ“ä½œæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07090v4",
      "published_date": "2025-11-10 13:26:06 UTC",
      "updated_date": "2025-11-13 11:33:02 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:10:48.269449+00:00"
    },
    {
      "arxiv_id": "2511.07086v1",
      "title": "LLM Driven Processes to Foster Explainable AI",
      "title_zh": "ä¿ƒè¿›å¯è§£é‡Šäººå·¥æ™ºèƒ½çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨æµç¨‹",
      "authors": [
        "Marcel Pehlke",
        "Marc Jansen"
      ],
      "abstract": "We present a modular, explainable LLM-agent pipeline for decision support that externalizes reasoning into auditable artifacts. The system instantiates three frameworks: Vester's Sensitivity Model (factor set, signed impact matrix, systemic roles, feedback loops); normal-form games (strategies, payoff matrix, equilibria); and sequential games (role-conditioned agents, tree construction, backward induction), with swappable modules at every step. LLM components (default: GPT-5) are paired with deterministic analyzers for equilibria and matrix-based role classification, yielding traceable intermediates rather than opaque outputs. In a real-world logistics case (100 runs), mean factor alignment with a human baseline was 55.5\\% over 26 factors and 62.9\\% on the transport-core subset; role agreement over matches was 57\\%. An LLM judge using an eight-criterion rubric (max 100) scored runs on par with a reconstructed human baseline. Configurable LLM pipelines can thus mimic expert workflows with transparent, inspectable steps.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ¨¡å—åŒ–ã€å¯è§£é‡Šçš„LLM-agentæµæ°´çº¿ï¼Œæ—¨åœ¨é€šè¿‡å°†æ¨ç†è¿‡ç¨‹å¤–åŒ–ä¸ºå¯å®¡è®¡çš„å·¥ä»¶æ¥æä¾›å†³ç­–æ”¯æŒã€‚ç³»ç»Ÿé›†æˆäº†Vester's Sensitivity Modelã€æ­£è§„å½¢å¼åšå¼ˆ(normal-form games)å’Œåºè´¯åšå¼ˆ(sequential games)ä¸‰ç§æ¡†æ¶ï¼Œå¹¶åœ¨æ¯ä¸€æ­¥éƒ½é‡‡ç”¨äº†å¯æ›¿æ¢æ¨¡å—ã€‚é€šè¿‡å°†LLMç»„ä»¶ï¼ˆé»˜è®¤ä¸ºGPT-5ï¼‰ä¸ç”¨äºè®¡ç®—å‡è¡¡å’Œè§’è‰²åˆ†ç±»çš„ç¡®å®šæ€§åˆ†æå™¨ç›¸ç»“åˆï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿç”Ÿæˆå¯è¿½è¸ªçš„ä¸­é—´äº§ç‰©ï¼Œé¿å…äº†è¾“å‡ºçš„ä¸é€æ˜æ€§ã€‚åœ¨åŒ…å«100æ¬¡è¿è¡Œçš„å®é™…ç‰©æµæ¡ˆä¾‹ç ”ç©¶ä¸­ï¼Œè¯¥ç³»ç»Ÿä¸äººç±»åŸºçº¿åœ¨26ä¸ªå› ç´ ä¸Šçš„å¹³å‡å¯¹é½åº¦è¾¾åˆ°55.5%ï¼Œåœ¨æ ¸å¿ƒè¿è¾“å­é›†ä¸Šè¾¾åˆ°62.9%ã€‚åŸºäºå…«é¡¹æ ‡å‡†çš„LLMè£åˆ¤è¯„åˆ†æ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿçš„è¡¨ç°ä¸é‡å»ºçš„äººç±»åŸºçº¿ç›¸å½“ï¼Œè¯æ˜äº†å¯é…ç½®çš„LLMæµæ°´çº¿èƒ½å¤Ÿé€šè¿‡é€æ˜ã€å¯æ£€æŸ¥çš„æ­¥éª¤æœ‰æ•ˆæ¨¡æ‹Ÿä¸“å®¶å·¥ä½œæµç¨‹ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07086v1",
      "published_date": "2025-11-10 13:20:00 UTC",
      "updated_date": "2025-11-10 13:20:00 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:11:22.512094+00:00"
    },
    {
      "arxiv_id": "2511.07085v1",
      "title": "Achieving Effective Virtual Reality Interactions via Acoustic Gesture Recognition based on Large Language Models",
      "title_zh": "é€šè¿‡åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å£°å­¦æ‰‹åŠ¿è¯†åˆ«å®ç°æœ‰æ•ˆçš„è™šæ‹Ÿç°å®äº¤äº’",
      "authors": [
        "Xijie Zhang",
        "Fengliang He",
        "Hong-Ning Dai"
      ],
      "abstract": "Natural and efficient interaction remains a critical challenge for virtual reality and augmented reality (VR/AR) systems. Vision-based gesture recognition suffers from high computational cost, sensitivity to lighting conditions, and privacy leakage concerns. Acoustic sensing provides an attractive alternative: by emitting inaudible high-frequency signals and capturing their reflections, channel impulse response (CIR) encodes how gestures perturb the acoustic field in a low-cost and user-transparent manner. However, existing CIR-based gesture recognition methods often rely on extensive training of models on large labeled datasets, making them unsuitable for few-shot VR scenarios. In this work, we propose the first framework that leverages large language models (LLMs) for CIR-based gesture recognition in VR/AR systems. Despite LLMs' strengths, it is non-trivial to achieve few-shot and zero-shot learning of CIR gestures due to their inconspicuous features. To tackle this challenge, we collect differential CIR rather than original CIR data. Moreover, we construct a real-world dataset collected from 10 participants performing 15 gestures across three categories (digits, letters, and shapes), with 10 repetitions each. We then conduct extensive experiments on this dataset using an LLM-adopted classifier. Results show that our LLM-based framework achieves accuracy comparable to classical machine learning baselines, while requiring no domain-specific retraining.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è™šæ‹Ÿç°å®(VR)å’Œå¢å¼ºç°å®(AR)ç³»ç»Ÿä¸­äº¤äº’çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„å£°å­¦æ‰‹åŠ¿è¯†åˆ«æ¡†æ¶ï¼Œæ—¨åœ¨æ›¿ä»£é«˜è®¡ç®—æˆæœ¬ä¸”å­˜åœ¨éšç§éšæ‚£çš„è§†è§‰è¯†åˆ«æ–¹æ¡ˆã€‚è™½ç„¶ä¿¡é“è„‰å†²å“åº”(Channel Impulse Response, CIR)èƒ½å¤Ÿä»¥ä½æˆæœ¬æ„ŸçŸ¥æ‰‹åŠ¿ï¼Œä½†ç°æœ‰æ–¹æ³•é€šå¸¸ä¾èµ–å¤§é‡æ ‡è®°æ•°æ®ï¼Œä¸é€‚ç”¨äºå°‘æ ·æœ¬(few-shot)åœºæ™¯ã€‚ä¸ºæ­¤ï¼Œä½œè€…åˆ©ç”¨LLMsçš„å¼ºå¤§èƒ½åŠ›ï¼Œå¹¶é€šè¿‡é‡‡é›†å·®åˆ†CIR(differential CIR)æ•°æ®æ¥å¢å¼ºæ¨¡å‹å¯¹å¾®å¼±å£°å­¦ç‰¹å¾çš„å­¦ä¹ èƒ½åŠ›ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºäº†ä¸€ä¸ªåŒ…å«10åå‚ä¸è€…ã€æ¶µç›–æ•°å­—ã€å­—æ¯å’Œå½¢çŠ¶ä¸‰ç±»å…±15ç§æ‰‹åŠ¿çš„çœŸå®æ•°æ®é›†è¿›è¡ŒéªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥LLMé©±åŠ¨çš„æ¡†æ¶åœ¨æ— éœ€ç‰¹å®šé¢†åŸŸé‡è®­ç»ƒçš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°äº†ä¸ç»å…¸æœºå™¨å­¦ä¹ åŸºçº¿ç›¸å½“çš„å‡†ç¡®ç‡ï¼Œæœ‰æ•ˆå®ç°äº†VRåœºæ™¯ä¸‹çš„å°‘æ ·æœ¬å’Œé›¶æ ·æœ¬(zero-shot)æ‰‹åŠ¿è¯†åˆ«ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 4 figures, 1 table, under review at ICASSP 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07085v1",
      "published_date": "2025-11-10 13:19:58 UTC",
      "updated_date": "2025-11-10 13:19:58 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:11:46.860474+00:00"
    },
    {
      "arxiv_id": "2511.07084v1",
      "title": "Pandar128 dataset for lane line detection",
      "title_zh": "é¢å‘è½¦é“çº¿æ£€æµ‹çš„ Pandar128 æ•°æ®é›†",
      "authors": [
        "Filip BerÃ¡nek",
        "VÃ¡clav DiviÅ¡",
        "Ivan Gruber"
      ],
      "abstract": "We present Pandar128, the largest public dataset for lane line detection using a 128-beam LiDAR. It contains over 52,000 camera frames and 34,000 LiDAR scans, captured in diverse real-world conditions in Germany. The dataset includes full sensor calibration (intrinsics, extrinsics) and synchronized odometry, supporting tasks such as projection, fusion, and temporal modeling.\n  To complement the dataset, we also introduce SimpleLidarLane, a light-weight baseline method for lane line reconstruction that combines BEV segmentation, clustering, and polyline fitting. Despite its simplicity, our method achieves strong performance under challenging various conditions (e.g., rain, sparse returns), showing that modular pipelines paired with high-quality data and principled evaluation can compete with more complex approaches.\n  Furthermore, to address the lack of standardized evaluation, we propose a novel polyline-based metric - Interpolation-Aware Matching F1 (IAM-F1) - that employs interpolation-aware lateral matching in BEV space.\n  All data and code are publicly released to support reproducibility in LiDAR-based lane detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Pandar128æ•°æ®é›†ï¼Œè¿™æ˜¯ç›®å‰æœ€å¤§çš„åŸºäº128çº¿LiDARçš„è½¦é“çº¿æ£€æµ‹å…¬å¼€æ•°æ®é›†ï¼ŒåŒ…å«è¶…è¿‡52,000å¸§å›¾åƒå’Œ34,000ä¸ªLiDARæ‰«æï¼Œè¦†ç›–äº†å¾·å›½å¤šæ ·çš„çœŸå®åœºæ™¯ã€‚è¯¥æ•°æ®é›†æä¾›äº†å®Œæ•´çš„ä¼ æ„Ÿå™¨æ ‡å®šå’ŒåŒæ­¥é‡Œç¨‹è®¡ä¿¡æ¯ï¼Œæ”¯æŒæŠ•å½±ã€èåˆåŠæ—¶é—´å»ºæ¨¡ç­‰ä»»åŠ¡ã€‚ä¸ºäº†é…åˆè¯¥æ•°æ®é›†ï¼Œä½œè€…è¿˜æå‡ºäº†ä¸€ç§åä¸ºSimpleLidarLaneçš„è½»é‡çº§åŸºçº¿æ–¹æ³•ï¼Œç»“åˆäº†BEVåˆ†å‰²ã€èšç±»å’Œå¤šæ®µçº¿æ‹ŸåˆæŠ€æœ¯ã€‚å°½ç®¡ç»“æ„ç®€å•ï¼Œè¯¥æ–¹æ³•åœ¨é›¨å¤©å’Œç¨€ç–å›æ³¢ç­‰æŒ‘æˆ˜æ€§æ¡ä»¶ä¸‹ä»è¡¨ç°å‡ºå¼ºåŠ²æ€§èƒ½ã€‚æ­¤å¤–ï¼Œé’ˆå¯¹ç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°çš„é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿæå‡ºäº†ä¸€ç§æ–°çš„åŸºäºå¤šæ®µçº¿çš„è¯„ä¼°æŒ‡æ ‡â€”â€”Interpolation-Aware Matching F1 (IAM-F1)ï¼Œè¯¥æŒ‡æ ‡åœ¨BEVç©ºé—´ä¸­åˆ©ç”¨æ’å€¼æ„ŸçŸ¥è¿›è¡Œæ¨ªå‘åŒ¹é…ã€‚æ‰€æœ‰æ•°æ®å’Œä»£ç å‡å·²å…¬å¼€ï¼Œä»¥æ”¯æŒLiDARè½¦é“çº¿æ£€æµ‹çš„å¯å¤ç°ç ”ç©¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07084v1",
      "published_date": "2025-11-10 13:18:36 UTC",
      "updated_date": "2025-11-10 13:18:36 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:12:09.336321+00:00"
    },
    {
      "arxiv_id": "2511.07083v1",
      "title": "Increasing AI Explainability by LLM Driven Standard Processes",
      "title_zh": "é€šè¿‡å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„æ ‡å‡†åŒ–æµç¨‹æå‡ AI å¯è§£é‡Šæ€§",
      "authors": [
        "Marc Jansen",
        "Marcel Pehlke"
      ],
      "abstract": "This paper introduces an approach to increasing the explainability of artificial intelligence (AI) systems by embedding Large Language Models (LLMs) within standardized analytical processes. While traditional explainable AI (XAI) methods focus on feature attribution or post-hoc interpretation, the proposed framework integrates LLMs into defined decision models such as Question-Option-Criteria (QOC), Sensitivity Analysis, Game Theory, and Risk Management. By situating LLM reasoning within these formal structures, the approach transforms opaque inference into transparent and auditable decision traces. A layered architecture is presented that separates the reasoning space of the LLM from the explainable process space above it. Empirical evaluations show that the system can reproduce human-level decision logic in decentralized governance, systems analysis, and strategic reasoning contexts. The results suggest that LLM-driven standard processes provide a foundation for reliable, interpretable, and verifiable AI-supported decision making.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€šè¿‡å°†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åµŒå…¥æ ‡å‡†åŒ–åˆ†ææµç¨‹æ¥æé«˜äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰å¯è§£é‡Šæ€§çš„æ–¹æ³•ã€‚ä¸ä¾§é‡äºç‰¹å¾å½’å› æˆ–äº‹åè§£é‡Šçš„ä¼ ç»Ÿå¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰æ–¹æ³•ä¸åŒï¼Œè¯¥æ¡†æ¶å°†LLMsé›†æˆåˆ°å®šä¹‰çš„å†³ç­–æ¨¡å‹ä¸­ï¼ŒåŒ…æ‹¬Question-Option-Criteria (QOC)ã€æ•æ„Ÿæ€§åˆ†æï¼ˆSensitivity Analysisï¼‰ã€åšå¼ˆè®ºï¼ˆGame Theoryï¼‰å’Œé£é™©ç®¡ç†ï¼ˆRisk Managementï¼‰ã€‚é€šè¿‡å°†LLMæ¨ç†ç½®äºè¿™äº›å½¢å¼åŒ–ç»“æ„ä¸­ï¼Œå¹¶é‡‡ç”¨å°†æ¨ç†ç©ºé—´ä¸æµç¨‹ç©ºé—´åˆ†ç¦»çš„åˆ†å±‚æ¶æ„ï¼Œè¯¥æ–¹æ³•å°†ä¸é€æ˜çš„æ¨ç†è½¬åŒ–ä¸ºé€æ˜ä¸”å¯å®¡è®¡çš„å†³ç­–è½¨è¿¹ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿèƒ½å¤Ÿåœ¨å»ä¸­å¿ƒåŒ–æ²»ç†ã€ç³»ç»Ÿåˆ†æå’Œæˆ˜ç•¥æ¨ç†èƒŒæ™¯ä¸‹é‡ç°äººç±»æ°´å¹³çš„å†³ç­–é€»è¾‘ã€‚ç ”ç©¶ç»“æœè¯å®ï¼ŒLLMé©±åŠ¨çš„æ ‡å‡†æµç¨‹ä¸ºæ„å»ºå¯é ã€å¯è§£é‡Šå’Œå¯éªŒè¯çš„AIè¾…åŠ©å†³ç­–ç³»ç»Ÿæä¾›äº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07083v1",
      "published_date": "2025-11-10 13:16:10 UTC",
      "updated_date": "2025-11-10 13:16:10 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:12:41.728574+00:00"
    },
    {
      "arxiv_id": "2511.07080v1",
      "title": "Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora",
      "title_zh": "Wasmï¼šæ„å»ºç»“æ„åŒ–é˜¿æ‹‰ä¼¯è¯­äº¤é”™å¤šæ¨¡æ€è¯­æ–™åº“çš„æµæ°´çº¿",
      "authors": [
        "Khalil Hennara",
        "Ahmad Bastati",
        "Muhammad Hreden",
        "Mohamed Motasim Hamed",
        "Zeina Aldallal",
        "Sara Chrouf",
        "Safwan AlModhayan"
      ],
      "abstract": "The performance of large language models (LLMs) and large multimodal models (LMMs) depends heavily on the quality and scale of their pre-training datasets. Recent research shows that large multimodal models trained on natural documents where images and text are interleaved outperform those trained only on image-text pairs across a wide range of benchmarks, leveraging advanced pre-trained models to enforce semantic alignment, image-sequence consistency, and textual coherence. For Arabic, however, the lack of high-quality multimodal datasets that preserve document structure has limited progress. In this paper, we present our pipeline Wasm for processing the Common Crawl dataset to create a new Arabic multimodal dataset that uniquely provides markdown output. Unlike existing Arabic corpora that focus solely on text extraction, our approach preserves the structural integrity of web content while maintaining flexibility for both text-only and multimodal pre-training scenarios. We provide a comprehensive comparative analysis of our data processing pipeline against those used for major existing datasets, highlighting the convergences in filtering strategies and justifying our specific design choices. To support future research, we publicly release a representative dataset dump along with the multimodal processing pipeline for Arabic.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­é¢†åŸŸç¼ºä¹ä¿ç•™æ–‡æ¡£ç»“æ„çš„é«˜è´¨é‡å¤šæ¨¡æ€æ•°æ®é›†è¿™ä¸€ç“¶é¢ˆï¼Œæå‡ºäº†Wasmï¼Œä¸€ç§ç”¨äºå¤„ç†Common Crawlæ•°æ®çš„ç®¡é“ï¼Œæ—¨åœ¨æ„å»ºç»“æ„åŒ–çš„é˜¿æ‹‰ä¼¯è¯­äº¤é”™å¤šæ¨¡æ€è¯­æ–™åº“ã€‚ä¸ä»…å…³æ³¨æ–‡æœ¬æå–çš„ç°æœ‰è¯­æ–™åº“ä¸åŒï¼ŒWasmèƒ½å¤Ÿç”ŸæˆMarkdownæ ¼å¼è¾“å‡ºï¼Œåœ¨ä¿ç•™ç½‘é¡µå†…å®¹ç»“æ„å®Œæ•´æ€§çš„åŒæ—¶ï¼Œä¸ºçº¯æ–‡æœ¬å’Œå¤šæ¨¡æ€é¢„è®­ç»ƒåœºæ™¯æä¾›äº†çµæ´»æ€§ã€‚ç ”ç©¶æŒ‡å‡ºï¼Œåœ¨å›¾åƒå’Œæ–‡æœ¬äº¤é”™çš„è‡ªç„¶æ–‡æ¡£ä¸Šè®­ç»ƒçš„å¤§å‹å¤šæ¨¡æ€æ¨¡å‹(LMMs)é€šå¸¸ä¼˜äºä»…ä½¿ç”¨å›¾åƒ-æ–‡æœ¬å¯¹è®­ç»ƒçš„æ¨¡å‹ã€‚è®ºæ–‡è¯¦ç»†å¯¹æ¯”äº†Wasmä¸å…¶ä»–ä¸»è¦æ•°æ®é›†å¤„ç†ç®¡é“çš„å·®å¼‚ï¼Œè®ºè¯äº†å…¶è¿‡æ»¤ç­–ç•¥å’Œè®¾è®¡é€‰æ‹©çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜å…¬å¼€å‘å¸ƒäº†å…·æœ‰ä»£è¡¨æ€§çš„æ•°æ®é›†è½¬å‚¨ä»¥åŠè¯¥å¤šæ¨¡æ€å¤„ç†ç®¡é“ï¼Œä»¥ä¿ƒè¿›é˜¿æ‹‰ä¼¯è¯­äººå·¥æ™ºèƒ½é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07080v1",
      "published_date": "2025-11-10 13:10:31 UTC",
      "updated_date": "2025-11-10 13:10:31 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:13:01.128779+00:00"
    },
    {
      "arxiv_id": "2511.11648v1",
      "title": "Lightweight Time Series Data Valuation on Time Series Foundation Models via In-Context Finetuning",
      "title_zh": "åŸºäºä¸Šä¸‹æ–‡å†…å¾®è°ƒçš„æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹è½»é‡çº§æ•°æ®ä¼°å€¼",
      "authors": [
        "Shunyu Wu",
        "Tianyue Li",
        "Yixuan Leng",
        "Jingyi Suo",
        "Jian Lou",
        "Dan Li",
        "See-Kiong Ng"
      ],
      "abstract": "Time series foundation models (TSFMs) have demonstrated increasing capabilities due to their extensive pretraining on large volumes of diverse time series data. Consequently, the quality of time series data is crucial to TSFM performance, rendering an accurate and efficient data valuation of time series for TSFMs indispensable. However, traditional data valuation methods, such as influence functions, face severe computational bottlenecks due to their poor scalability with growing TSFM model sizes and often fail to preserve temporal dependencies. In this paper, we propose LTSV, a Lightweight Time Series Valuation on TSFMS via in-context finetuning. Grounded in the theoretical evidence that in-context finetuning approximates the influence function, LTSV estimates a sample's contribution by measuring the change in context loss after in-context finetuning, leveraging the strong generalization capabilities of TSFMs to produce robust and transferable data valuations. To capture temporal dependencies, we introduce temporal block aggregation, which integrates per-block influence scores across overlapping time windows. Experiments across multiple time series datasets and models demonstrate that LTSV consistently provides reliable and strong valuation performance, while maintaining manageable computational requirements. Our results suggest that in-context finetuning on time series foundation models provides a practical and effective bridge between data attribution and model generalization in time series learning.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—åŸºç¡€æ¨¡å‹(TSFMs)ä¸­æ•°æ®ä¼°å€¼é¢ä¸´çš„è®¡ç®—ç“¶é¢ˆå’Œæ—¶é—´ä¾èµ–æ€§ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºLTSVçš„è½»é‡çº§æ—¶é—´åºåˆ—ä¼°å€¼æ–¹æ³•ã€‚LTSVåŸºäºä¸Šä¸‹æ–‡å¾®è°ƒ(in-context finetuning)è¿‘ä¼¼å½±å“å‡½æ•°çš„ç†è®ºåŸºç¡€ï¼Œé€šè¿‡æµ‹é‡ä¸Šä¸‹æ–‡å¾®è°ƒåcontext lossçš„å˜åŒ–æ¥ä¼°ç®—æ ·æœ¬è´¡çŒ®ï¼Œä»è€Œåˆ©ç”¨TSFMsçš„å¼ºæ³›åŒ–èƒ½åŠ›äº§ç”Ÿç¨³å¥çš„ä¼°å€¼ã€‚ä¸ºäº†æœ‰æ•ˆæ•æ‰æ—¶é—´åºåˆ—çš„æ—¶é—´ä¾èµ–æ€§ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†temporal block aggregationæœºåˆ¶ï¼Œå¯¹é‡å æ—¶é—´çª—å£å†…çš„å½±å“å¾—åˆ†è¿›è¡Œæ•´åˆã€‚åœ¨å¤šä¸ªæ•°æ®é›†å’Œæ¨¡å‹ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒLTSVåœ¨ä¿æŒè®¡ç®—å¼€é”€å¯æ§çš„åŒæ—¶ï¼Œèƒ½å¤ŸæŒç»­æä¾›å¯é ä¸”å¼ºæœ‰åŠ›çš„ä¼°å€¼æ€§èƒ½ã€‚ç»“æœè¯å®ï¼ŒåŸºäºTSFMsçš„ä¸Šä¸‹æ–‡å¾®è°ƒæœ‰æ•ˆåœ°è¿æ¥äº†æ•°æ®å½’å› ä¸æ¨¡å‹æ³›åŒ–ï¼Œä¸ºæ—¶é—´åºåˆ—å­¦ä¹ æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.11648v1",
      "published_date": "2025-11-10 13:06:46 UTC",
      "updated_date": "2025-11-10 13:06:46 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:16:17.382595+00:00"
    },
    {
      "arxiv_id": "2511.10676v1",
      "title": "Pre-Attention Expert Prediction and Prefetching for Mixture-of-Experts Large Language Models",
      "title_zh": "é¢å‘æ··åˆä¸“å®¶å¤§è¯­è¨€æ¨¡å‹çš„æ³¨æ„åŠ›å‰ä¸“å®¶é¢„æµ‹ä¸é¢„å–",
      "authors": [
        "Shien Zhu",
        "Samuel Bohl",
        "Robin Oester",
        "Gustavo Alonso"
      ],
      "abstract": "Mixture-of-Experts (MoE) Large Language Models (LLMs) efficiently scale-up the model while keeping relatively low inference cost. As MoE models only activate part of the experts, related work has proposed expert prediction and caching methods to prefetch the experts for faster inference. However, existing approaches utilize the activations from the previous layer for prediction, incurring low accuracy and leave the first layer unoptimized. Applying complex layers or even training standalone networks for better prediction introduces high computation overhead. In this paper, we propose pre-attention expert prediction to achieve accurate and lightweight expert prefetching. The key insight is that some functions in LLMs are ranking-preserving, indicating that matching the ranking of selected experts using simple linear functions is possible. Therefore, we utilize the activations before the attention block in the same layer with 2 linear functions and ranking-aware loss to achieve accurate prediction, which also supports prefetching in the first layer. Our lightweight, pre-attention expert routers achieve 93.03% accuracy on DeepSeek V2 Lite, 94.69% on Qwen3-30B, and 97.62% on Phi-mini-MoE, showing about 15% improvement on absolute accuracy over the state-of-the-art methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ··åˆä¸“å®¶(Mixture-of-Experts, MoE)å¤§è¯­è¨€æ¨¡å‹åœ¨æ¨ç†æ—¶çš„ä¸“å®¶é¢„å–é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§è½»é‡çº§ä¸”é«˜ç²¾åº¦çš„é¢„æ³¨æ„åŠ›ä¸“å®¶é¢„æµ‹(Pre-Attention Expert Prediction)æ–¹æ³•ã€‚ç°æœ‰çš„ä¸“å®¶é¢„æµ‹æŠ€æœ¯å¾€å¾€ä¾èµ–ä¸Šä¸€å±‚çš„æ¿€æ´»å€¼ï¼Œå¯¼è‡´å‡†ç¡®ç‡è¾ƒä½ä¸”æ— æ³•è¦†ç›–ç¬¬ä¸€å±‚ï¼Œæˆ–å› æ¨¡å‹å¤æ‚è€Œå¢åŠ è®¡ç®—å¼€é”€ã€‚åŸºäºLLMä¸­éƒ¨åˆ†å‡½æ•°å…·æœ‰ä¿åºæ€§(ranking-preserving)çš„å…³é”®å‘ç°ï¼Œè¯¥æ–¹æ³•åˆ©ç”¨åŒä¸€å±‚æ³¨æ„åŠ›æ¨¡å—ä¹‹å‰çš„æ¿€æ´»å€¼ï¼Œç»“åˆä¸¤ä¸ªçº¿æ€§å‡½æ•°å’Œæ’åæ„ŸçŸ¥æŸå¤±(ranking-aware loss)æ¥ç²¾å‡†é¢„æµ‹å³å°†è¢«æ¿€æ´»çš„ä¸“å®¶ã€‚è¿™ç§è®¾è®¡ä¸ä»…è®¡ç®—è´Ÿæ‹…å°ï¼Œè¿˜æˆåŠŸå®ç°äº†å¯¹ç¬¬ä¸€å±‚ä¸“å®¶çš„é¢„å–æ”¯æŒã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨DeepSeek V2 Liteã€Qwen3-30Bå’ŒPhi-mini-MoEæ¨¡å‹ä¸Šåˆ†åˆ«è¾¾åˆ°äº†93.03%ã€94.69%å’Œ97.62%çš„é¢„æµ‹å‡†ç¡®ç‡ï¼Œç›¸æ¯”ç°æœ‰æœ€å…ˆè¿›æ–¹æ³•æå‡äº†çº¦15%ï¼Œæœ‰æ•ˆä¼˜åŒ–äº†MoEæ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.10676v1",
      "published_date": "2025-11-10 13:05:07 UTC",
      "updated_date": "2025-11-10 13:05:07 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:16:38.747628+00:00"
    },
    {
      "arxiv_id": "2511.07070v1",
      "title": "RedOne 2.0: Rethinking Domain-specific LLM Post-Training in Social Networking Services",
      "title_zh": "RedOne 2.0ï¼šé‡æ€ç¤¾äº¤ç½‘ç»œæœåŠ¡ä¸­çš„é¢†åŸŸä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹åè®­ç»ƒ",
      "authors": [
        "Fei Zhao",
        "Chonggang Lu",
        "Haofu Qian",
        "Fangcheng Shi",
        "Zijie Meng",
        "Jianzhao Huang",
        "Xu Tang",
        "Zheyong Xie",
        "Zheyu Ye",
        "Zhe Xu",
        "Yao Hu",
        "Shaosheng Cao"
      ],
      "abstract": "As a key medium for human interaction and information exchange, social networking services (SNS) pose unique challenges for large language models (LLMs): heterogeneous workloads, fast-shifting norms and slang, and multilingual, culturally diverse corpora that induce sharp distribution shift. Supervised fine-tuning (SFT) can specialize models but often triggers a ``seesaw'' between in-distribution gains and out-of-distribution robustness, especially for smaller models. To address these challenges, we introduce RedOne 2.0, an SNS-oriented LLM trained with a progressive, RL-prioritized post-training paradigm designed for rapid and stable adaptation. The pipeline consist in three stages: (1) Exploratory Learning on curated SNS corpora to establish initial alignment and identify systematic weaknesses; (2) Targeted Fine-Tuning that selectively applies SFT to the diagnosed gaps while mixing a small fraction of general data to mitigate forgetting; and (3) Refinement Learning that re-applies RL with SNS-centric signals to consolidate improvements and harmonize trade-offs across tasks. Across various tasks spanning three categories, our 4B scale model delivers an average improvements about 2.41 over the 7B sub-optimal baseline. Additionally, RedOne 2.0 achieves average performance lift about 8.74 from the base model with less than half the data required by SFT-centric method RedOne, evidencing superior data efficiency and stability at compact scales. Overall, RedOne 2.0 establishes a competitive, cost-effective baseline for domain-specific LLMs in SNS scenario, advancing capability without sacrificing robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤ç½‘ç»œæœåŠ¡(SNS)åœºæ™¯ä¸­å¼‚æ„å·¥ä½œè´Ÿè½½ã€å¿«é€Ÿå˜åŒ–çš„è§„èŒƒå’Œä¿šè¯­å¸¦æ¥çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†RedOne 2.0ï¼Œä¸€ç§é¢å‘SNSçš„å¤§è¯­è¨€æ¨¡å‹(LLM)ã€‚ä¸ºäº†è§£å†³ç›‘ç£å¾®è°ƒ(SFT)åœ¨ç‰¹å®šé¢†åŸŸæ”¶ç›Šä¸é€šç”¨é²æ£’æ€§ä¹‹é—´çš„â€œè··è··æ¿â€é—®é¢˜ï¼Œä½œè€…è®¾è®¡äº†ä¸€ç§æ¸è¿›å¼ã€å¼ºåŒ–å­¦ä¹ ä¼˜å…ˆ(RL-prioritized)çš„åè®­ç»ƒèŒƒå¼ã€‚è¯¥èŒƒå¼åŒ…å«ä¸‰ä¸ªé˜¶æ®µï¼šå»ºç«‹åˆæ­¥å¯¹é½å¹¶è¯†åˆ«å¼±ç‚¹çš„æ¢ç´¢æ€§å­¦ä¹ (Exploratory Learning)ï¼Œé’ˆå¯¹æ€§ä¿®è¡¥å·®è·å¹¶æ··åˆé€šç”¨æ•°æ®ä»¥ç¼“è§£é—å¿˜çš„é’ˆå¯¹æ€§å¾®è°ƒ(Targeted Fine-Tuning)ï¼Œä»¥åŠåˆ©ç”¨SNSä¿¡å·å·©å›ºæ”¹è¿›çš„ç²¾ç‚¼å­¦ä¹ (Refinement Learning)ã€‚å®éªŒè¡¨æ˜ï¼Œ4Bå‚æ•°çš„RedOne 2.0æ¨¡å‹åœ¨å„ç±»ä»»åŠ¡ä¸Šæ¯”7BåŸºçº¿æ¨¡å‹å¹³å‡æå‡çº¦2.41åˆ†ã€‚æ­¤å¤–ï¼Œç›¸æ¯”ä»¥SFTä¸ºæ ¸å¿ƒçš„å‰ä»£æ–¹æ³•ï¼Œæ–°æ¨¡å‹ä»…éœ€ä¸åˆ°ä¸€åŠçš„æ•°æ®é‡ä¾¿å®ç°äº†ç›¸å¯¹äºåŸºç¡€æ¨¡å‹çº¦8.74çš„æ€§èƒ½æå‡ï¼Œå±•ç¤ºäº†åœ¨ç´§å‡‘è§„æ¨¡ä¸‹ä¼˜è¶Šçš„æ•°æ®æ•ˆç‡ä¸ç¨³å®šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07070v1",
      "published_date": "2025-11-10 13:04:34 UTC",
      "updated_date": "2025-11-10 13:04:34 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:17:02.824874+00:00"
    },
    {
      "arxiv_id": "2511.07493v1",
      "title": "Enabling Automatic Self-Talk Detection via Earables",
      "title_zh": "åŸºäºè€³æˆ´å¼è®¾å¤‡çš„è‡ªè¨€è‡ªè¯­è‡ªåŠ¨æ£€æµ‹",
      "authors": [
        "Euihyeok Lee",
        "Seonghyeon Kim",
        "SangHun Im",
        "Heung-Seon Oh",
        "Seungwoo Kang"
      ],
      "abstract": "Self-talk-an internal dialogue that can occur silently or be spoken aloud-plays a crucial role in emotional regulation, cognitive processing, and motivation, yet has remained largely invisible and unmeasurable in everyday life. In this paper, we present MutterMeter, a mobile system that automatically detects vocalized self-talk from audio captured by earable microphones in real-world settings. Detecting self-talk is technically challenging due to its diverse acoustic forms, semantic and grammatical incompleteness, and irregular occurrence patterns, which differ fundamentally from assumptions underlying conventional speech understanding models. To address these challenges, MutterMeter employs a hierarchical classification architecture that progressively integrates acoustic, linguistic, and contextual information through a sequential processing pipeline, adaptively balancing accuracy and computational efficiency. We build and evaluate MutterMeter using a first-of-its-kind dataset comprising 31.1 hours of audio collected from 25 participants. Experimental results demonstrate that MutterMeter achieves robust performance with a macro-averaged F1 score of 0.84, outperforming conventional approaches, including LLM-based and speech emotion recognition models.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†MutterMeterï¼Œä¸€ç§åˆ©ç”¨earableéº¦å…‹é£åœ¨ç°å®ç¯å¢ƒä¸­è‡ªåŠ¨æ£€æµ‹å‡ºå£°è‡ªè¨€è‡ªè¯­(self-talk)çš„ç§»åŠ¨ç³»ç»Ÿã€‚ç”±äºè‡ªè¨€è‡ªè¯­å…·æœ‰å¤šæ ·çš„å£°å­¦å½¢å¼ã€è¯­ä¹‰å’Œè¯­æ³•çš„å®Œæ•´æ€§ç¼ºå¤±ä»¥åŠä¸è§„å¾‹çš„å‘ç”Ÿæ¨¡å¼ï¼Œå…¶æ£€æµ‹åœ¨æŠ€æœ¯ä¸Šæå…·æŒ‘æˆ˜æ€§ã€‚ä¸ºè§£å†³è¿™äº›é—®é¢˜ï¼ŒMutterMeteré‡‡ç”¨äº†ä¸€ç§åˆ†å±‚åˆ†ç±»æ¶æ„ï¼Œé€šè¿‡é¡ºåºå¤„ç†ç®¡é“é€æ­¥æ•´åˆå£°å­¦ã€è¯­è¨€å­¦å’Œä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä»è€Œè‡ªé€‚åº”åœ°å¹³è¡¡å‡†ç¡®æ€§å’Œè®¡ç®—æ•ˆç‡ã€‚ç ”ç©¶å›¢é˜Ÿæ„å»ºå¹¶è¯„ä¼°äº†ä¸€ä¸ªåŒ…å«æ¥è‡ª25åå‚ä¸è€…çš„31.1å°æ—¶éŸ³é¢‘çš„é¦–åˆ›æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMutterMeterå®ç°äº†0.84çš„å®å¹³å‡F1åˆ†æ•°(macro-averaged F1 score)ï¼Œä¼˜äºåŒ…æ‹¬åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM)å’Œè¯­éŸ³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹åœ¨å†…çš„ä¼ ç»Ÿæ–¹æ³•ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07493v1",
      "published_date": "2025-11-10 13:01:06 UTC",
      "updated_date": "2025-11-10 13:01:06 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:17:33.965319+00:00"
    },
    {
      "arxiv_id": "2511.07062v2",
      "title": "Improving Region Representation Learning from Urban Imagery with Noisy Long-Caption Supervision",
      "title_zh": "åˆ©ç”¨å«å™ªé•¿æè¿°ç›‘ç£æ”¹è¿›åŸºäºåŸå¸‚å›¾åƒçš„åŒºåŸŸè¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Yimei Zhang",
        "Guojiang Shen",
        "Kaili Ning",
        "Tongwei Ren",
        "Xuebo Qiu",
        "Mengmeng Wang",
        "Xiangjie Kong"
      ],
      "abstract": "Region representation learning plays a pivotal role in urban computing by extracting meaningful features from unlabeled urban data. Analogous to how perceived facial age reflects an individual's health, the visual appearance of a city serves as its \"portrait\", encapsulating latent socio-economic and environmental characteristics. Recent studies have explored leveraging Large Language Models (LLMs) to incorporate textual knowledge into imagery-based urban region representation learning. However, two major challenges remain: i) difficulty in aligning fine-grained visual features with long captions, and ii) suboptimal knowledge incorporation due to noise in LLM-generated captions. To address these issues, we propose a novel pre-training framework called UrbanLN that improves Urban region representation learning through Long-text awareness and Noise suppression. Specifically, we introduce an information-preserved stretching interpolation strategy that aligns long captions with fine-grained visual semantics in complex urban scenes. To effectively mine knowledge from LLM-generated captions and filter out noise, we propose a dual-level optimization strategy. At the data level, a multi-model collaboration pipeline automatically generates diverse and reliable captions without human intervention. At the model level, we employ a momentum-based self-distillation mechanism to generate stable pseudo-targets, facilitating robust cross-modal learning under noisy conditions. Extensive experiments across four real-world cities and various downstream tasks demonstrate the superior performance of our UrbanLN.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UrbanLNï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡é•¿æ–‡æœ¬æ„ŸçŸ¥å’Œå™ªå£°æŠ‘åˆ¶æ¥æ”¹è¿›åŸå¸‚åŒºåŸŸè¡¨ç¤ºå­¦ä¹ çš„æ–°å‹é¢„è®­ç»ƒæ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•åœ¨å°†ç»†ç²’åº¦è§†è§‰ç‰¹å¾ä¸é•¿æ–‡æœ¬å¯¹é½ä»¥åŠå¤„ç†å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆæ–‡æœ¬å™ªå£°æ–¹é¢çš„æŒ‘æˆ˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§ä¿¡æ¯ä¿ç•™æ‹‰ä¼¸æ’å€¼ç­–ç•¥(information-preserved stretching interpolation strategy)ï¼Œæœ‰æ•ˆå¯¹é½å¤æ‚åŸå¸‚åœºæ™¯ä¸­çš„é•¿æ ‡é¢˜ä¸è§†è§‰è¯­ä¹‰ã€‚ä¸ºäº†ä»LLMç”Ÿæˆçš„æ ‡é¢˜ä¸­æŒ–æ˜çŸ¥è¯†å¹¶è¿‡æ»¤å™ªå£°ï¼Œä½œè€…æå‡ºäº†åŒå±‚ä¼˜åŒ–ç­–ç•¥ã€‚åœ¨æ•°æ®å±‚é¢ï¼Œé‡‡ç”¨å¤šæ¨¡å‹åä½œæµç¨‹è‡ªåŠ¨ç”Ÿæˆå¤šæ ·ä¸”å¯é çš„æ ‡é¢˜ï¼›åœ¨æ¨¡å‹å±‚é¢ï¼Œåˆ©ç”¨åŸºäºåŠ¨é‡çš„è‡ªè’¸é¦æœºåˆ¶(momentum-based self-distillation mechanism)ç”Ÿæˆç¨³å®šçš„ä¼ªç›®æ ‡ï¼Œä¿ƒè¿›å™ªå£°æ¡ä»¶ä¸‹çš„é²æ£’è·¨æ¨¡æ€å­¦ä¹ ã€‚åœ¨å››ä¸ªçœŸå®åŸå¸‚åŠå¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸Šçš„å¹¿æ³›å®éªŒè¯æ˜äº†UrbanLNç›¸æ¯”ç°æœ‰æ–¹æ³•çš„ä¼˜è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a full paper by AAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2511.07062v2",
      "published_date": "2025-11-10 12:53:32 UTC",
      "updated_date": "2025-11-30 05:57:45 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:17:47.694926+00:00"
    },
    {
      "arxiv_id": "2511.07061v3",
      "title": "Do LLMs Feel? Teaching Emotion Recognition with Prompts, Retrieval, and Curriculum Learning",
      "title_zh": "LLM æœ‰æ„Ÿè§‰å—ï¼ŸåŸºäºæç¤ºã€æ£€ç´¢ä¸è¯¾ç¨‹å­¦ä¹ çš„æƒ…æ„Ÿè¯†åˆ«æ•™å­¦",
      "authors": [
        "Xinran Li",
        "Yu Liu",
        "Jiaqi Qiao",
        "Xiujuan Xu"
      ],
      "abstract": "Emotion Recognition in Conversation (ERC) is a crucial task for understanding human emotions and enabling natural human-computer interaction. Although Large Language Models (LLMs) have recently shown great potential in this field, their ability to capture the intrinsic connections between explicit and implicit emotions remains limited. We propose a novel ERC training framework, PRC-Emo, which integrates Prompt engineering, demonstration Retrieval, and Curriculum learning, with the goal of exploring whether LLMs can effectively perceive emotions in conversational contexts. Specifically, we design emotion-sensitive prompt templates based on both explicit and implicit emotional cues to better guide the model in understanding the speaker's psychological states. We construct the first dedicated demonstration retrieval repository for ERC, which includes training samples from widely used datasets, as well as high-quality dialogue examples generated by LLMs and manually verified. Moreover, we introduce a curriculum learning strategy into the LoRA fine-tuning process, incorporating weighted emotional shifts between same-speaker and different-speaker utterances to assign difficulty levels to dialogue samples, which are then organized in an easy-to-hard training sequence. Experimental results on two benchmark datasets -- IEMOCAP and MELD -- show that our method achieves new state-of-the-art (SOTA) performance, demonstrating the effectiveness and generalizability of our approach in improving LLM-based emotional understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PRC-Emoï¼Œä¸€ç§ç»“åˆäº†æç¤ºå·¥ç¨‹(Prompt engineering)ã€æ¼”ç¤ºæ£€ç´¢(demonstration Retrieval)å’Œè¯¾ç¨‹å­¦ä¹ (Curriculum learning)çš„æ–°å‹è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¯¹è¯æƒ…ç»ªè¯†åˆ«(ERC)ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚é’ˆå¯¹LLMséš¾ä»¥æ•æ‰æ˜¾æ€§å’Œéšæ€§æƒ…ç»ªå†…åœ¨è”ç³»çš„é—®é¢˜ï¼Œä½œè€…è®¾è®¡äº†åŸºäºæƒ…ç»ªçº¿ç´¢çš„æ•æ„Ÿæç¤ºæ¨¡æ¿ï¼Œä»¥å¼•å¯¼æ¨¡å‹ç†è§£è¯´è¯è€…çš„å¿ƒç†çŠ¶æ€ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ„å»ºäº†é¦–ä¸ªä¸“ç”¨äºERCçš„æ¼”ç¤ºæ£€ç´¢åº“ï¼ŒåŒ…å«æ¥è‡ªå¸¸ç”¨æ•°æ®é›†çš„è®­ç»ƒæ ·æœ¬ä»¥åŠç»äººå·¥éªŒè¯çš„é«˜è´¨é‡LLMç”Ÿæˆå¯¹è¯ã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œç ”ç©¶å¼•å…¥äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œæ ¹æ®åŒè¯´è¯äººå’Œä¸åŒè¯´è¯äººä¹‹é—´çš„åŠ æƒæƒ…ç»ªè½¬æ¢æ¥åˆ†é…æ ·æœ¬éš¾åº¦ï¼Œå¹¶æŒ‰ç”±æ˜“åˆ°éš¾çš„é¡ºåºè¿›è¡ŒLoRAå¾®è°ƒã€‚åœ¨IEMOCAPå’ŒMELDä¸¤ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¾¾åˆ°äº†æ–°çš„SOTAæ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨å¢å¼ºLLMæƒ…ç»ªç†è§£èƒ½åŠ›æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œæ³›åŒ–æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.07061v3",
      "published_date": "2025-11-10 12:52:11 UTC",
      "updated_date": "2025-11-24 01:17:15 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:18:31.064654+00:00"
    },
    {
      "arxiv_id": "2511.07057v1",
      "title": "TauFlow: Dynamic Causal Constraint for Complexity-Adaptive Lightweight Segmentation",
      "title_zh": "TauFlowï¼šé¢å‘å¤æ‚åº¦è‡ªé€‚åº”è½»é‡çº§åˆ†å‰²çš„åŠ¨æ€å› æœçº¦æŸ",
      "authors": [
        "Zidong Chen",
        "Fadratul Hafinaz Hassan"
      ],
      "abstract": "Deploying lightweight medical image segmentation models on edge devices presents two major challenges: 1) efficiently handling the stark contrast between lesion boundaries and background regions, and 2) the sharp drop in accuracy that occurs when pursuing extremely lightweight designs (e.g., <0.5M parameters). To address these problems, this paper proposes TauFlow, a novel lightweight segmentation model. The core of TauFlow is a dynamic feature response strategy inspired by brain-like mechanisms. This is achieved through two key innovations: the Convolutional Long-Time Constant Cell (ConvLTC), which dynamically regulates the feature update rate to \"slowly\" process low-frequency backgrounds and \"quickly\" respond to high-frequency boundaries; and the STDP Self-Organizing Module, which significantly mitigates feature conflicts between the encoder and decoder, reducing the conflict rate from approximately 35%-40% to 8%-10%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šéƒ¨ç½²è½»é‡çº§åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹æ—¶é¢ä¸´çš„ç—…ç¶è¾¹ç•Œå¤„ç†å›°éš¾åŠæè½»é‡åŒ–ï¼ˆå‚æ•°å°äº0.5Mï¼‰å¯¼è‡´çš„ç²¾åº¦ä¸‹é™é—®é¢˜ï¼Œæå‡ºäº†åä¸ºTauFlowçš„æ–°å‹è½»é‡çº§åˆ†å‰²æ¨¡å‹ã€‚TauFlowçš„æ ¸å¿ƒåœ¨äºä¸€ç§å—ç±»è„‘æœºåˆ¶å¯å‘çš„åŠ¨æ€ç‰¹å¾å“åº”ç­–ç•¥ï¼Œä¸»è¦é€šè¿‡ä¸¤é¡¹å…³é”®åˆ›æ–°å®ç°ã€‚é¦–å…ˆï¼Œå¼•å…¥Convolutional Long-Time Constant Cell (ConvLTC) åŠ¨æ€è°ƒèŠ‚ç‰¹å¾æ›´æ–°é€Ÿç‡ï¼Œå®ç°å¯¹ä½é¢‘èƒŒæ™¯çš„â€œæ…¢â€å¤„ç†å’Œå¯¹é«˜é¢‘è¾¹ç•Œçš„â€œå¿«â€å“åº”ã€‚å…¶æ¬¡ï¼Œåˆ©ç”¨STDP Self-Organizing Module æ˜¾è‘—ç¼“è§£äº†ç¼–ç å™¨ä¸è§£ç å™¨ä¹‹é—´çš„ç‰¹å¾å†²çªã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æˆåŠŸå°†ç‰¹å¾å†²çªç‡ä»çº¦35%-40%é™ä½è‡³8%-10%ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„åˆ†å‰²æ€§èƒ½ä¸æ•ˆç‡ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "42 pages and 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.07057v1",
      "published_date": "2025-11-10 12:47:21 UTC",
      "updated_date": "2025-11-10 12:47:21 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:18:54.515617+00:00"
    },
    {
      "arxiv_id": "2511.07046v3",
      "title": "Learning Quantized Continuous Controllers for Integer Hardware",
      "title_zh": "é¢å‘æ•´æ•°ç¡¬ä»¶çš„é‡åŒ–è¿ç»­æ§åˆ¶å™¨å­¦ä¹ ",
      "authors": [
        "Fabian Kresse",
        "Christoph H. Lampert"
      ],
      "abstract": "Deploying continuous-control reinforcement learning policies on embedded hardware requires meeting tight latency and power budgets. Small FPGAs can deliver these, but only if costly floating point pipelines are avoided. We study quantization-aware training (QAT) of policies for integer inference and we present a learning-to-hardware pipeline that automatically selects low-bit policies and synthesizes them to an Artix-7 FPGA. Across five MuJoCo tasks, we obtain policy networks that are competitive with full precision (FP32) policies but require as few as 3 or even only 2 bits per weight, and per internal activation value, as long as input precision is chosen carefully. On the target hardware, the selected policies achieve inference latencies on the order of microseconds and consume microjoules per action, favorably comparing to a quantized reference. Last, we observe that the quantized policies exhibit increased input noise robustness compared to the floating-point baseline.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹åœ¨åµŒå…¥å¼ç¡¬ä»¶ä¸Šéƒ¨ç½²è¿ç»­æ§åˆ¶å¼ºåŒ–å­¦ä¹ ç­–ç•¥æ—¶é¢ä¸´çš„å»¶è¿Ÿå’ŒåŠŸè€—é™åˆ¶ï¼Œæ¢è®¨äº†é¿å…æ˜‚è´µæµ®ç‚¹è¿ç®—çš„æ–¹æ³•ã€‚ä½œè€…ç ”ç©¶äº†ç”¨äºæ•´æ•°æ¨ç†çš„é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(Quantization-Aware Training, QAT)ï¼Œå¹¶æå‡ºäº†ä¸€ç§ä»å­¦ä¹ åˆ°ç¡¬ä»¶çš„è‡ªåŠ¨åŒ–æµæ°´çº¿ï¼Œèƒ½å¤Ÿé€‰æ‹©ä½æ¯”ç‰¹ç­–ç•¥å¹¶å°†å…¶ç»¼åˆåˆ°Artix-7 FPGAä¸Šã€‚åœ¨äº”ä¸ªMuJoCoä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œåªè¦ä»”ç»†é€‰æ‹©è¾“å…¥ç²¾åº¦ï¼Œä»…éœ€æ¯ä¸ªæƒé‡å’Œå†…éƒ¨æ¿€æ´»å€¼2åˆ°3ä¸ªæ¯”ç‰¹ï¼Œå°±èƒ½è·å¾—ä¸å…¨ç²¾åº¦(FP32)ç›¸å½“çš„ç­–ç•¥ç½‘ç»œã€‚åœ¨ç›®æ ‡ç¡¬ä»¶ä¸Šï¼Œè¿™äº›ç²¾é€‰ç­–ç•¥å®ç°äº†å¾®ç§’çº§çš„æ¨ç†å»¶è¿Ÿå’Œæ¯æ¬¡åŠ¨ä½œå¾®ç„¦è€³çº§çš„èƒ½è€—ï¼Œæ€§èƒ½ä¼˜äºé‡åŒ–å‚è€ƒåŸºå‡†ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°é‡åŒ–ç­–ç•¥ç›¸æ¯”æµ®ç‚¹åŸºçº¿è¡¨ç°å‡ºäº†æ›´å¼ºçš„è¾“å…¥å™ªå£°é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.07046v3",
      "published_date": "2025-11-10 12:39:14 UTC",
      "updated_date": "2025-11-17 13:47:04 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:19:28.761836+00:00"
    },
    {
      "arxiv_id": "2511.07017v2",
      "title": "Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in Practice",
      "title_zh": "é¢å‘å®æˆ˜çš„ä¸°å¯Œä¸Šä¸‹æ–‡ç»†ç²’åº¦ä»£ç å®¡æŸ¥å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Ruida Hu",
        "Xinchen Wang",
        "Xin-Cheng Wen",
        "Zhao Zhang",
        "Bo Jiang",
        "Pengfei Gao",
        "Chao Peng",
        "Cuiyun Gao"
      ],
      "abstract": "Code review is a cornerstone of software quality assurance, and recent advances in Large Language Models (LLMs) have shown promise in its automation. However, existing benchmarks for LLM-based code review face three major limitations. Lack of semantic context: most benchmarks provide only code diffs without textual information such as issue descriptions, which are crucial for understanding developer intent. Data quality issues: without rigorous validation, many samples are noisy-e.g., reviews on outdated or irrelevant code-reducing evaluation reliability. Coarse granularity: most benchmarks operate at the file or commit level, overlooking the fine-grained, line-level reasoning essential for precise review. We introduce ContextCRBench, a high-quality, context-rich benchmark for fine-grained LLM evaluation in code review. Our construction pipeline comprises: Raw Data Crawling, collecting 153.7K issues and pull requests from top-tier repositories; Comprehensive Context Extraction, linking issue-PR pairs for textual context and extracting the full surrounding function or class for code context; and Multi-stage Data Filtering, combining rule-based and LLM-based validation to remove outdated, malformed, or low-value samples, resulting in 67,910 context-enriched entries. ContextCRBench supports three evaluation scenarios aligned with the review workflow: hunk-level quality assessment, line-level defect localization, and line-level comment generation. Evaluating eight leading LLMs (four closed-source and four open-source) reveals that textual context yields greater performance gains than code context alone, while current LLMs remain far from human-level review ability. Deployed at ByteDance, ContextCRBench drives a self-evolving code review system, improving performance by 61.98% and demonstrating its robustness and industrial utility. https://github.com/kinesiatricssxilm14/ContextCRBench.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹ç°æœ‰åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„ä»£ç å®¡æŸ¥åŸºå‡†å­˜åœ¨çš„ç¼ºä¹è¯­ä¹‰ä¸Šä¸‹æ–‡ã€æ•°æ®è´¨é‡ä½ä»¥åŠç²’åº¦è¿‡ç²—ç­‰é—®é¢˜ï¼Œæå‡ºäº†ContextCRBenchï¼Œä¸€ä¸ªé«˜è´¨é‡ä¸”å¯Œå«ä¸Šä¸‹æ–‡çš„ç»†ç²’åº¦ä»£ç å®¡æŸ¥åŸºå‡†ã€‚è¯¥åŸºå‡†çš„æ„å»ºæµç¨‹åŒ…æ‹¬çˆ¬å–é¡¶çº§ä»“åº“æ•°æ®ã€æå–Issue-PRå¯¹çš„æ–‡æœ¬ä¸Šä¸‹æ–‡åŠå‘¨å›´ä»£ç ä¸Šä¸‹æ–‡ï¼Œå¹¶é€šè¿‡ç»“åˆè§„åˆ™å’ŒLLMéªŒè¯çš„å¤šé˜¶æ®µè¿‡æ»¤æ¸…æ´—å‡º67,910æ¡é«˜è´¨é‡æ•°æ®ã€‚ContextCRBenchæ”¯æŒå—çº§è´¨é‡è¯„ä¼°ã€è¡Œçº§ç¼ºé™·å®šä½å’Œè¡Œçº§è¯„è®ºç”Ÿæˆä¸‰ç§ç¬¦åˆå®é™…å®¡æŸ¥å·¥ä½œæµçš„è¯„ä¼°åœºæ™¯ã€‚å¯¹å…«ç§ä¸»æµLLMsçš„è¯„ä¼°æ˜¾ç¤ºï¼Œæ–‡æœ¬ä¸Šä¸‹æ–‡æ¯”å•çº¯çš„ä»£ç ä¸Šä¸‹æ–‡å¸¦æ¥æ›´å¤§çš„æ€§èƒ½æå‡ï¼Œä½†å½“å‰æ¨¡å‹ä¸äººç±»å®¡æŸ¥èƒ½åŠ›ä»æœ‰å·®è·ã€‚æ­¤å¤–ï¼Œè¯¥åŸºå‡†å·²åœ¨å­—èŠ‚è·³åŠ¨(ByteDance)éƒ¨ç½²ï¼Œé©±åŠ¨äº†ä¸€ä¸ªè‡ªè¿›åŒ–çš„ä»£ç å®¡æŸ¥ç³»ç»Ÿï¼Œå®ç°äº†61.98%çš„æ€§èƒ½æå‡ï¼Œè¯æ˜äº†å…¶å·¥ä¸šå®ç”¨æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07017v2",
      "published_date": "2025-11-10 12:06:35 UTC",
      "updated_date": "2025-12-30 09:02:18 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:20:05.415854+00:00"
    },
    {
      "arxiv_id": "2511.07014v1",
      "title": "Diffolio: A Diffusion Model for Multivariate Probabilistic Financial Time-Series Forecasting and Portfolio Construction",
      "title_zh": "Diffolioï¼šé¢å‘å¤šå˜é‡é‡‘èæ—¶é—´åºåˆ—æ¦‚ç‡é¢„æµ‹ä¸æŠ•èµ„ç»„åˆæ„å»ºçš„æ‰©æ•£æ¨¡å‹",
      "authors": [
        "So-Yoon Cho",
        "Jin-Young Kim",
        "Kayoung Ban",
        "Hyeng Keun Koo",
        "Hyun-Gyoon Kim"
      ],
      "abstract": "Probabilistic forecasting is crucial in multivariate financial time-series for constructing efficient portfolios that account for complex cross-sectional dependencies. In this paper, we propose Diffolio, a diffusion model designed for multivariate financial time-series forecasting and portfolio construction. Diffolio employs a denoising network with a hierarchical attention architecture, comprising both asset-level and market-level layers. Furthermore, to better reflect cross-sectional correlations, we introduce a correlation-guided regularizer informed by a stable estimate of the target correlation matrix. This structure effectively extracts salient features not only from historical returns but also from asset-specific and systematic covariates, significantly enhancing the performance of forecasts and portfolios. Experimental results on the daily excess returns of 12 industry portfolios show that Diffolio outperforms various probabilistic forecasting baselines in multivariate forecasting accuracy and portfolio performance. Moreover, in portfolio experiments, portfolios constructed from Diffolio's forecasts show consistently robust performance, thereby outperforming those from benchmarks by achieving higher Sharpe ratios for the mean-variance tangency portfolio and higher certainty equivalents for the growth-optimal portfolio. These results demonstrate the superiority of our proposed Diffolio in terms of not only statistical accuracy but also economic significance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Diffolioï¼Œä¸€ç§ä¸“ä¸ºå¤šå…ƒé‡‘èæ—¶é—´åºåˆ—é¢„æµ‹å’ŒæŠ•èµ„ç»„åˆæ„å»ºè€Œè®¾è®¡çš„æ‰©æ•£æ¨¡å‹(Diffusion Model)ã€‚Diffolioé‡‡ç”¨äº†åŒ…å«èµ„äº§çº§å’Œå¸‚åœºçº§å±‚çš„åˆ†å±‚æ³¨æ„åŠ›æ¶æ„å»å™ªç½‘ç»œï¼Œå¹¶å¼•å…¥äº†ç”±ç›®æ ‡ç›¸å…³çŸ©é˜µç¨³å®šä¼°è®¡æŒ‡å¯¼çš„ç›¸å…³æ€§å¼•å¯¼æ­£åˆ™åŒ–å™¨(correlation-guided regularizer)ï¼Œä»¥æ›´å¥½åœ°åæ˜ æ¨ªæˆªé¢ç›¸å…³æ€§ã€‚è¯¥æ¨¡å‹èƒ½å¤Ÿä»å†å²å›æŠ¥ã€èµ„äº§ç‰¹å®šåŠç³»ç»Ÿåå˜é‡ä¸­æœ‰æ•ˆæå–æ˜¾è‘—ç‰¹å¾ï¼Œä»è€Œæ˜¾è‘—å¢å¼ºé¢„æµ‹å’ŒæŠ•èµ„ç»„åˆçš„æ€§èƒ½ã€‚åœ¨12ä¸ªè¡Œä¸šæŠ•èµ„ç»„åˆçš„æ¯æ—¥è¶…é¢å›æŠ¥å®éªŒä¸­ï¼ŒDiffolioåœ¨å¤šå…ƒé¢„æµ‹å‡†ç¡®æ€§ä¸Šä¼˜äºå¤šç§æ¦‚ç‡é¢„æµ‹åŸºçº¿ã€‚æ­¤å¤–ï¼ŒåŸºäºDiffolioæ„å»ºçš„æŠ•èµ„ç»„åˆåœ¨å‡å€¼-æ–¹å·®åˆ‡ç‚¹ç»„åˆä¸­å®ç°äº†æ›´é«˜çš„å¤æ™®æ¯”ç‡(Sharpe ratios)ï¼Œåœ¨å¢é•¿æœ€ä¼˜ç»„åˆä¸­å®ç°äº†æ›´é«˜çš„ç¡®å®šæ€§ç­‰ä»·ç‰©(certainty equivalents)ï¼Œè¯æ˜äº†å…¶åœ¨ç»Ÿè®¡å‡†ç¡®æ€§å’Œç»æµæ„ä¹‰ä¸Šçš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.CE",
        "cs.AI",
        "econ.EM",
        "q-fin.PM"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.07014v1",
      "published_date": "2025-11-10 12:05:32 UTC",
      "updated_date": "2025-11-10 12:05:32 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:20:32.080459+00:00"
    },
    {
      "arxiv_id": "2511.07007v1",
      "title": "TrueCity: Real and Simulated Urban Data for Cross-Domain 3D Scene Understanding",
      "title_zh": "TrueCityï¼šé¢å‘è·¨åŸŸä¸‰ç»´åœºæ™¯ç†è§£çš„çœŸå®ä¸ä»¿çœŸåŸå¸‚æ•°æ®",
      "authors": [
        "Duc Nguyen",
        "Yan-Ling Lai",
        "Qilin Zhang",
        "Prabin Gyawali",
        "Benedikt Schwab",
        "Olaf Wysocki",
        "Thomas H. Kolbe"
      ],
      "abstract": "3D semantic scene understanding remains a long-standing challenge in the 3D computer vision community. One of the key issues pertains to limited real-world annotated data to facilitate generalizable models. The common practice to tackle this issue is to simulate new data. Although synthetic datasets offer scalability and perfect labels, their designer-crafted scenes fail to capture real-world complexity and sensor noise, resulting in a synthetic-to-real domain gap. Moreover, no benchmark provides synchronized real and simulated point clouds for segmentation-oriented domain shift analysis. We introduce TrueCity, the first urban semantic segmentation benchmark with cm-accurate annotated real-world point clouds, semantic 3D city models, and annotated simulated point clouds representing the same city. TrueCity proposes segmentation classes aligned with international 3D city modeling standards, enabling consistent evaluation of synthetic-to-real gap. Our extensive experiments on common baselines quantify domain shift and highlight strategies for exploiting synthetic data to enhance real-world 3D scene understanding. We are convinced that the TrueCity dataset will foster further development of sim-to-real gap quantification and enable generalizable data-driven models. The data, code, and 3D models are available online: https://tum-gis.github.io/TrueCity/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹3Dè¯­ä¹‰åœºæ™¯ç†è§£ä¸­çœŸå®æ ‡æ³¨æ•°æ®ç¨€ç¼ºåŠåˆæˆæ•°æ®å­˜åœ¨synthetic-to-real domain gapçš„é—®é¢˜ï¼Œæå‡ºäº†TrueCityåŸºå‡†ã€‚TrueCityæ˜¯é¦–ä¸ªåŒ…å«å˜ç±³çº§ç²¾åº¦æ ‡æ³¨çš„çœŸå®ä¸–ç•Œç‚¹äº‘ã€è¯­ä¹‰3DåŸå¸‚æ¨¡å‹ä»¥åŠä»£è¡¨åŒä¸€åŸå¸‚çš„æ ‡æ³¨æ¨¡æ‹Ÿç‚¹äº‘çš„åŸå¸‚è¯­ä¹‰åˆ†å‰²æ•°æ®é›†ã€‚è¯¥åŸºå‡†é‡‡ç”¨äº†ä¸å›½é™…3DåŸå¸‚å»ºæ¨¡æ ‡å‡†å¯¹é½çš„åˆ†å‰²ç±»åˆ«ï¼Œä»è€Œèƒ½å¤Ÿå¯¹åˆæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„å·®è·è¿›è¡Œä¸€è‡´æ€§è¯„ä¼°ã€‚é€šè¿‡åœ¨é€šç”¨åŸºçº¿ä¸Šè¿›è¡Œçš„å¹¿æ³›å®éªŒï¼Œç ”ç©¶äººå‘˜é‡åŒ–äº†domain shiftï¼Œå¹¶æå‡ºäº†åˆ©ç”¨åˆæˆæ•°æ®å¢å¼ºçœŸå®ä¸–ç•Œ3Dåœºæ™¯ç†è§£çš„æœ‰æ•ˆç­–ç•¥ã€‚TrueCityçš„å‘å¸ƒå¡«è¡¥äº†ç¼ºä¹åŒæ­¥çœŸå®ä¸æ¨¡æ‹Ÿç‚¹äº‘åŸºå‡†çš„ç©ºç™½ï¼Œå°†æœ‰åŠ›æ¨åŠ¨sim-to-real gapé‡åŒ–åŠæ³›åŒ–æ•°æ®é©±åŠ¨æ¨¡å‹çš„å‘å±•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper accepted for 3DV 2026 (International Conference on 3D Vision 2026)",
      "pdf_url": "https://arxiv.org/pdf/2511.07007v1",
      "published_date": "2025-11-10 11:57:50 UTC",
      "updated_date": "2025-11-10 11:57:50 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:23:43.364469+00:00"
    },
    {
      "arxiv_id": "2511.07006v1",
      "title": "S$^2$Drug: Bridging Protein Sequence and 3D Structure in Contrastive Representation Learning for Virtual Screening",
      "title_zh": "$S^2$Drugï¼šè™šæ‹Ÿç­›é€‰ä¸­æ¡¥æ¥è›‹ç™½è´¨åºåˆ—ä¸ä¸‰ç»´ç»“æ„çš„å¯¹æ¯”è¡¨å¾å­¦ä¹ ",
      "authors": [
        "Bowei He",
        "Bowen Gao",
        "Yankai Chen",
        "Yanyan Lan",
        "Chen Ma",
        "Philip S. Yu",
        "Ya-Qin Zhang",
        "Wei-Ying Ma"
      ],
      "abstract": "Virtual screening (VS) is an essential task in drug discovery, focusing on the identification of small-molecule ligands that bind to specific protein pockets. Existing deep learning methods, from early regression models to recent contrastive learning approaches, primarily rely on structural data while overlooking protein sequences, which are more accessible and can enhance generalizability. However, directly integrating protein sequences poses challenges due to the redundancy and noise in large-scale protein-ligand datasets. To address these limitations, we propose \\textbf{S$^2$Drug}, a two-stage framework that explicitly incorporates protein \\textbf{S}equence information and 3D \\textbf{S}tructure context in protein-ligand contrastive representation learning. In the first stage, we perform protein sequence pretraining on ChemBL using an ESM2-based backbone, combined with a tailored data sampling strategy to reduce redundancy and noise on both protein and ligand sides. In the second stage, we fine-tune on PDBBind by fusing sequence and structure information through a residue-level gating module, while introducing an auxiliary binding site prediction task. This auxiliary task guides the model to accurately localize binding residues within the protein sequence and capture their 3D spatial arrangement, thereby refining protein-ligand matching. Across multiple benchmarks, S$^2$Drug consistently improves virtual screening performance and achieves strong results on binding site prediction, demonstrating the value of bridging sequence and structure in contrastive learning.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†S$^2$Drugï¼Œä¸€ç§ä¸¤é˜¶æ®µæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è™šæ‹Ÿç­›é€‰(Virtual Screening)æ–¹æ³•ä¸»è¦ä¾èµ–ç»“æ„æ•°æ®è€Œå¿½è§†è›‹ç™½è´¨åºåˆ—ä¿¡æ¯çš„é—®é¢˜ã€‚S$^2$Drugåœ¨è›‹ç™½è´¨-é…ä½“å¯¹æ¯”è¡¨å¾å­¦ä¹ ä¸­æ˜¾å¼ç»“åˆäº†è›‹ç™½è´¨åºåˆ—(Sequence)å’Œ3Dç»“æ„(Structure)ä¸Šä¸‹æ–‡ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œç ”ç©¶è€…ä½¿ç”¨åŸºäºESM2çš„ä¸»å¹²ç½‘ç»œåœ¨ChemBLæ•°æ®é›†ä¸Šè¿›è¡Œè›‹ç™½è´¨åºåˆ—é¢„è®­ç»ƒï¼Œå¹¶ç»“åˆå®šåˆ¶çš„æ•°æ®é‡‡æ ·ç­–ç•¥ä»¥å‡å°‘æ•°æ®å†—ä½™å’Œå™ªå£°ã€‚åœ¨ç¬¬äºŒé˜¶æ®µï¼Œæ¨¡å‹åœ¨PDBBindä¸Šè¿›è¡Œå¾®è°ƒï¼Œé€šè¿‡æ®‹åŸºçº§é—¨æ§æ¨¡å—èåˆåºåˆ—å’Œç»“æ„ä¿¡æ¯ï¼Œå¹¶å¼•å…¥è¾…åŠ©ç»“åˆä½ç‚¹é¢„æµ‹ä»»åŠ¡ã€‚è¯¥è¾…åŠ©ä»»åŠ¡å¼•å¯¼æ¨¡å‹å‡†ç¡®å®šä½è›‹ç™½è´¨åºåˆ—ä¸­çš„ç»“åˆæ®‹åŸºå¹¶æ•æ‰å…¶3Dç©ºé—´æ’åˆ—ï¼Œä»è€Œä¼˜åŒ–è›‹ç™½è´¨-é…ä½“åŒ¹é…ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒS$^2$Drugåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­æŒç»­æå‡äº†è™šæ‹Ÿç­›é€‰æ€§èƒ½ï¼Œå¹¶åœ¨ç»“åˆä½ç‚¹é¢„æµ‹ä¸Šå–å¾—äº†ä¼˜å¼‚ç»“æœï¼Œè¯æ˜äº†åœ¨å¯¹æ¯”å­¦ä¹ ä¸­æ¡¥æ¥åºåˆ—å’Œç»“æ„çš„ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026 Main Technical Track",
      "pdf_url": "https://arxiv.org/pdf/2511.07006v1",
      "published_date": "2025-11-10 11:57:47 UTC",
      "updated_date": "2025-11-10 11:57:47 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:24:37.300660+00:00"
    },
    {
      "arxiv_id": "2511.08640v1",
      "title": "Predict and Resist: Long-Term Accident Anticipation under Sensor Noise",
      "title_zh": "é¢„æµ‹ä¸æŠµæŠ—ï¼šä¼ æ„Ÿå™¨å™ªå£°ä¸‹çš„é•¿æ—¶äº‹æ•…é¢„åˆ¤",
      "authors": [
        "Xingcheng Liu",
        "Bin Rao",
        "Yanchen Guan",
        "Chengyue Wang",
        "Haicheng Liao",
        "Jiaxun Zhang",
        "Chengyu Lin",
        "Meixin Zhu",
        "Zhenning Li"
      ],
      "abstract": "Accident anticipation is essential for proactive and safe autonomous driving, where even a brief advance warning can enable critical evasive actions. However, two key challenges hinder real-world deployment: (1) noisy or degraded sensory inputs from weather, motion blur, or hardware limitations, and (2) the need to issue timely yet reliable predictions that balance early alerts with false-alarm suppression. We propose a unified framework that integrates diffusion-based denoising with a time-aware actor-critic model to address these challenges. The diffusion module reconstructs noise-resilient image and object features through iterative refinement, preserving critical motion and interaction cues under sensor degradation. In parallel, the actor-critic architecture leverages long-horizon temporal reasoning and time-weighted rewards to determine the optimal moment to raise an alert, aligning early detection with reliability. Experiments on three benchmark datasets (DAD, CCD, A3D) demonstrate state-of-the-art accuracy and significant gains in mean time-to-accident, while maintaining robust performance under Gaussian and impulse noise. Qualitative analyses further show that our model produces earlier, more stable, and human-aligned predictions in both routine and highly complex traffic scenarios, highlighting its potential for real-world, safety-critical deployment.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹è‡ªåŠ¨é©¾é©¶äº‹æ•…é¢„æµ‹ä¸­é¢ä¸´çš„ä¼ æ„Ÿå™¨å™ªå£°å¹²æ‰°åŠé¢„è­¦æ—¶æ•ˆæ€§æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆåŸºäºæ‰©æ•£æ¨¡å‹å»å™ª(diffusion-based denoising)ä¸æ—¶é—´æ„ŸçŸ¥Actor-Criticæ¨¡å‹çš„ç»Ÿä¸€æ¡†æ¶ã€‚è¯¥æ¡†æ¶é¦–å…ˆåˆ©ç”¨æ‰©æ•£æ¨¡å—é€šè¿‡è¿­ä»£ç»†åŒ–é‡å»ºæŠ—å™ªå›¾åƒå’Œå¯¹è±¡ç‰¹å¾ï¼Œæœ‰æ•ˆåœ¨ä¼ æ„Ÿå™¨é€€åŒ–æ¡ä»¶ä¸‹ä¿ç•™å…³é”®è¿åŠ¨ä¸äº¤äº’çº¿ç´¢ã€‚éšåï¼ŒActor-Criticæ¶æ„åˆ©ç”¨é•¿æ—¶åºæ¨ç†å’Œæ—¶é—´åŠ æƒå¥–åŠ±æœºåˆ¶ç¡®å®šæœ€ä½³æŠ¥è­¦æ—¶åˆ»ï¼Œå®ç°äº†æ—©æœŸæ£€æµ‹ä¸è¯¯æŠ¥æŠ‘åˆ¶çš„å¹³è¡¡ã€‚åœ¨DADã€CCDå’ŒA3Dä¸‰ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®ç‡å’Œå¹³å‡äº‹æ•…å‘ç”Ÿæ—¶é—´(mTTA)ä¸Šå‡å–å¾—äº†æœ€å…ˆè¿›(SOTA)çš„æ€§èƒ½ï¼Œå¹¶åœ¨é«˜æ–¯å™ªå£°å’Œè„‰å†²å™ªå£°å¹²æ‰°ä¸‹è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤æ‚äº¤é€šåœºæ™¯ä¸­èƒ½æä¾›æ›´æ—©ã€æ›´ç¨³å®šä¸”ç¬¦åˆäººç±»ç›´è§‰çš„é¢„æµ‹ï¼ŒéªŒè¯äº†å…¶åœ¨å®é™…å®‰å…¨å…³é”®éƒ¨ç½²ä¸­çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by the Fortieth AAAI Conference on Artificial Intelligence (AAAI-26)",
      "pdf_url": "https://arxiv.org/pdf/2511.08640v1",
      "published_date": "2025-11-10 11:41:43 UTC",
      "updated_date": "2025-11-10 11:41:43 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:24:34.106962+00:00"
    },
    {
      "arxiv_id": "2511.09564v1",
      "title": "Mamba-driven multi-perspective structural understanding for molecular ground-state conformation prediction",
      "title_zh": "é¢å‘åˆ†å­åŸºæ€æ„è±¡é¢„æµ‹çš„Mambaé©±åŠ¨å¤šè§†è§’ç»“æ„ç†è§£",
      "authors": [
        "Yuxin Gou",
        "Aming Wu",
        "Richang Hong",
        "Meng Wang"
      ],
      "abstract": "A comprehensive understanding of molecular structures is important for the prediction of molecular ground-state conformation involving property information. Meanwhile, state space model (e.g., Mamba) has recently emerged as a promising mechanism for long sequence modeling and has achieved remarkable results in various language and vision tasks. However, towards molecular ground-state conformation prediction, exploiting Mamba to understand molecular structure is underexplored. To this end, we strive to design a generic and efficient framework with Mamba to capture critical components. In general, molecular structure could be considered to consist of three elements, i.e., atom types, atom positions, and connections between atoms. Thus, considering the three elements, an approach of Mamba-driven multi-perspective structural understanding (MPSU-Mamba) is proposed to localize molecular ground-state conformation. Particularly, for complex and diverse molecules, three different kinds of dedicated scanning strategies are explored to construct a comprehensive perception of corresponding molecular structures. And a bright-channel guided mechanism is defined to discriminate the critical conformation-related atom information. Experimental results on QM9 and Molecule3D datasets indicate that MPSU-Mamba significantly outperforms existing methods. Furthermore, we observe that for the case of few training samples, MPSU-Mamba still achieves superior performance, demonstrating that our method is indeed beneficial for understanding molecular structures.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åˆ†å­åŸºæ€æ„è±¡é¢„æµ‹ä»»åŠ¡ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMPSU-Mambaçš„åŸºäºMambaé©±åŠ¨çš„å¤šè§†è§’ç»“æ„ç†è§£æ–¹æ³•ã€‚é‰´äºState Space Modelï¼ˆå¦‚Mambaï¼‰åœ¨é•¿åºåˆ—å»ºæ¨¡ä¸­çš„ä¼˜åŠ¿ï¼Œè¯¥æ¡†æ¶æ—¨åœ¨å¡«è¡¥åˆ©ç”¨Mambaç†è§£åˆ†å­ç»“æ„çš„ç©ºç™½ã€‚MPSU-Mambaç»¼åˆè€ƒè™‘äº†åŸå­ç±»å‹ã€åŸå­ä½ç½®å’ŒåŸå­é—´è¿æ¥è¿™ä¸‰ä¸ªæ ¸å¿ƒè¦ç´ ï¼Œé€šè¿‡æ¢ç´¢ä¸‰ç§ä¸“ç”¨çš„æ‰«æç­–ç•¥æ¥æ„å»ºå¯¹åˆ†å­ç»“æ„çš„å…¨é¢æ„ŸçŸ¥ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§bright-channel guided mechanismï¼Œç”¨äºåŒºåˆ†ä¸æ„è±¡ç›¸å…³çš„å…³é”®åŸå­ä¿¡æ¯ã€‚åœ¨QM9å’ŒMolecule3Dæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMPSU-Mambaæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºçº¿æ–¹æ³•ã€‚è¿›ä¸€æ­¥çš„è§‚å¯Ÿå‘ç°ï¼Œå³ä½¿åœ¨è®­ç»ƒæ ·æœ¬è¾ƒå°‘çš„æƒ…å†µä¸‹ï¼Œè¯¥æ¨¡å‹ä¾ç„¶èƒ½ä¿æŒä¼˜è¶Šçš„æ€§èƒ½ï¼Œè¯æ˜äº†å…¶åœ¨åˆ†å­ç»“æ„ç†è§£æ–¹é¢çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "physics.chem-ph",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.09564v1",
      "published_date": "2025-11-10 11:18:32 UTC",
      "updated_date": "2025-11-10 11:18:32 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:24:56.338724+00:00"
    },
    {
      "arxiv_id": "2511.06961v1",
      "title": "Hybrid Autoencoders for Tabular Data: Leveraging Model-Based Augmentation in Low-Label Settings",
      "title_zh": "é¢å‘è¡¨æ ¼æ•°æ®çš„æ··åˆè‡ªç¼–ç å™¨ï¼šåœ¨ä½æ ‡ç­¾è®¾ç½®ä¸‹åˆ©ç”¨åŸºäºæ¨¡å‹çš„å¢å¼º",
      "authors": [
        "Erel Naor",
        "Ofir Lindenbaum"
      ],
      "abstract": "Deep neural networks often under-perform on tabular data due to their sensitivity to irrelevant features and a spectral bias toward smooth, low-frequency functions. These limitations hinder their ability to capture the sharp, high-frequency signals that often define tabular structure, especially under limited labeled samples. While self-supervised learning (SSL) offers promise in such settings, it remains challenging in tabular domains due to the lack of effective data augmentations. We propose a hybrid autoencoder that combines a neural encoder with an oblivious soft decision tree (OSDT) encoder, each guided by its own stochastic gating network that performs sample-specific feature selection. Together, these structurally different encoders and model-specific gating networks implement model-based augmentation, producing complementary input views tailored to each architecture. The two encoders, trained with a shared decoder and cross-reconstruction loss, learn distinct yet aligned representations that reflect their respective inductive biases. During training, the OSDT encoder (robust to noise and effective at modeling localized, high-frequency structure) guides the neural encoder toward representations more aligned with tabular data. At inference, only the neural encoder is used, preserving flexibility and SSL compatibility. Spectral analysis highlights the distinct inductive biases of each encoder. Our method achieves consistent gains in low-label classification and regression across diverse tabular datasets, outperforming deep and tree-based supervised baselines.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æ·±åº¦ç¥ç»ç½‘ç»œåœ¨è¡¨æ ¼æ•°æ®ä¸Šå› è°±åå·®(spectral bias)åŠå¯¹æ— å…³ç‰¹å¾æ•æ„Ÿè€Œè¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨ä½æ ‡ç­¾æ ·æœ¬åœºæ™¯ä¸‹ï¼Œæå‡ºäº†ä¸€ç§æ··åˆè‡ªç¼–ç å™¨(Hybrid Autoencoder)ã€‚è¯¥æ¡†æ¶ç»“åˆäº†ç¥ç»ç¼–ç å™¨ä¸é—å¿˜è½¯å†³ç­–æ ‘(Oblivious Soft Decision Tree, OSDT)ç¼–ç å™¨ï¼Œä¸¤è€…å‡ç”±æ‰§è¡Œæ ·æœ¬ç‰¹å®šç‰¹å¾é€‰æ‹©çš„éšæœºé—¨æ§ç½‘ç»œå¼•å¯¼ï¼Œå…±åŒå®ç°äº†åŸºäºæ¨¡å‹çš„å¢å¼º(model-based augmentation)ã€‚é€šè¿‡å…±äº«è§£ç å™¨å’Œäº¤å‰é‡å»ºæŸå¤±è¿›è¡Œè®­ç»ƒï¼ŒOSDTç¼–ç å™¨åˆ©ç”¨å…¶å¯¹é«˜é¢‘ç»“æ„çš„å»ºæ¨¡èƒ½åŠ›ï¼Œå¼•å¯¼ç¥ç»ç¼–ç å™¨å­¦ä¹ æ›´ç¬¦åˆè¡¨æ ¼æ•°æ®ç‰¹æ€§çš„è¡¨ç¤ºã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œç³»ç»Ÿä»…ä½¿ç”¨ç¥ç»ç¼–ç å™¨ï¼Œä»è€Œä¿æŒäº†çµæ´»æ€§å’Œè‡ªç›‘ç£å­¦ä¹ (SSL)çš„å…¼å®¹æ€§ã€‚è°±åˆ†ææ­ç¤ºäº†ä¸åŒç¼–ç å™¨çš„ç‹¬ç‰¹å½’çº³åå·®ï¼Œå®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨å¤šç§è¡¨æ ¼æ•°æ®é›†çš„ä½æ ‡ç­¾åˆ†ç±»å’Œå›å½’ä»»åŠ¡ä¸­å–å¾—äº†ä¸€è‡´çš„æ€§èƒ½æå‡ï¼Œä¼˜äºç°æœ‰çš„æ·±åº¦å’ŒåŸºäºæ ‘çš„ç›‘ç£åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to neurips 2025, main text is 10 pages",
      "pdf_url": "https://arxiv.org/pdf/2511.06961v1",
      "published_date": "2025-11-10 11:08:39 UTC",
      "updated_date": "2025-11-10 11:08:39 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:25:23.119274+00:00"
    },
    {
      "arxiv_id": "2511.06947v1",
      "title": "FoCLIP: A Feature-Space Misalignment Framework for CLIP-Based Image Manipulation and Detection",
      "title_zh": "FoCLIPï¼šé¢å‘åŸºäº CLIP çš„å›¾åƒç¯¡æ”¹ä¸æ£€æµ‹çš„ç‰¹å¾ç©ºé—´é”™ä½æ¡†æ¶",
      "authors": [
        "Yulin Chen",
        "Zeyuan Wang",
        "Tianyuan Yu",
        "Yingmei Wei",
        "Liang Bai"
      ],
      "abstract": "The well-aligned attribute of CLIP-based models enables its effective application like CLIPscore as a widely adopted image quality assessment metric. However, such a CLIP-based metric is vulnerable for its delicate multimodal alignment. In this work, we propose \\textbf{FoCLIP}, a feature-space misalignment framework for fooling CLIP-based image quality metric. Based on the stochastic gradient descent technique, FoCLIP integrates three key components to construct fooling examples: feature alignment as the core module to reduce image-text modality gaps, the score distribution balance module and pixel-guard regularization, which collectively optimize multimodal output equilibrium between CLIPscore performance and image quality. Such a design can be engineered to maximize the CLIPscore predictions across diverse input prompts, despite exhibiting either visual unrecognizability or semantic incongruence with the corresponding adversarial prompts from human perceptual perspectives. Experiments on ten artistic masterpiece prompts and ImageNet subsets demonstrate that optimized images can achieve significant improvement in CLIPscore while preserving high visual fidelity. In addition, we found that grayscale conversion induces significant feature degradation in fooling images, exhibiting noticeable CLIPscore reduction while preserving statistical consistency with original images. Inspired by this phenomenon, we propose a color channel sensitivity-driven tampering detection mechanism that achieves 91% accuracy on standard benchmarks. In conclusion, this work establishes a practical pathway for feature misalignment in CLIP-based multimodal systems and the corresponding defense method.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†FoCLIPï¼Œä¸€ç§é’ˆå¯¹åŸºäºCLIPæ¨¡å‹ï¼ˆå¦‚CLIPscoreï¼‰çš„å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡çš„ç‰¹å¾ç©ºé—´é”™ä½æ¡†æ¶ã€‚FoCLIPåŸºäºéšæœºæ¢¯åº¦ä¸‹é™æŠ€æœ¯ï¼Œæ•´åˆäº†ç‰¹å¾å¯¹é½ã€åˆ†æ•°åˆ†å¸ƒå¹³è¡¡æ¨¡å—å’Œpixel-guardæ­£åˆ™åŒ–ï¼Œæ—¨åœ¨æ„å»ºèƒ½å¤Ÿæ¬ºéª—å¤šæ¨¡æ€å¯¹é½çš„æ ·æœ¬ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶ç”Ÿæˆçš„å›¾åƒåœ¨äººç±»æ„ŸçŸ¥ä¸‹å¯èƒ½è§†è§‰ä¸å¯è¯†åˆ«æˆ–è¯­ä¹‰ä¸ç¬¦ï¼Œå´èƒ½åœ¨å„ç±»è¾“å…¥æç¤ºè¯ä¸‹æœ€å¤§åŒ–CLIPscoreé¢„æµ‹å€¼ï¼ŒåŒæ—¶åœ¨ImageNetå­é›†ä¸Šä¿æŒè¾ƒé«˜çš„è§†è§‰ä¿çœŸåº¦ã€‚ç ”ç©¶è¿›ä¸€æ­¥å‘ç°ç°åº¦è½¬æ¢ä¼šå¯¼è‡´æ¬ºéª—å›¾åƒå‡ºç°æ˜¾è‘—çš„ç‰¹å¾é€€åŒ–ï¼ŒåŸºäºæ­¤ç°è±¡ï¼Œä½œè€…æå‡ºäº†ä¸€ç§é¢œè‰²é€šé“æ•æ„Ÿæ€§é©±åŠ¨çš„ç¯¡æ”¹æ£€æµ‹æœºåˆ¶ã€‚è¯¥æ£€æµ‹æ–¹æ³•åœ¨æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†91%çš„å‡†ç¡®ç‡ï¼Œä¸ºç†è§£CLIPå¤šæ¨¡æ€ç³»ç»Ÿä¸­çš„ç‰¹å¾é”™ä½åŠæ„å»ºç›¸åº”çš„é˜²å¾¡æ‰‹æ®µæä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 page, 9 figures, published to PRCV",
      "pdf_url": "https://arxiv.org/pdf/2511.06947v1",
      "published_date": "2025-11-10 10:54:35 UTC",
      "updated_date": "2025-11-10 10:54:35 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:25:45.338704+00:00"
    },
    {
      "arxiv_id": "2511.06946v1",
      "title": "Learning to Focus: Prioritizing Informative Histories with Structured Attention Mechanisms in Partially Observable Reinforcement Learning",
      "title_zh": "å­¦ä¹ èšç„¦ï¼šåœ¨éƒ¨åˆ†å¯è§‚æµ‹å¼ºåŒ–å­¦ä¹ ä¸­åˆ©ç”¨ç»“æ„åŒ–æ³¨æ„åŠ›æœºåˆ¶ä¼˜å…ˆå…³æ³¨é«˜ä¿¡æ¯é‡å†å²",
      "authors": [
        "Daniel De Dios Allegue",
        "Jinke He",
        "Frans A. Oliehoek"
      ],
      "abstract": "Transformers have shown strong ability to model long-term dependencies and are increasingly adopted as world models in model-based reinforcement learning (RL) under partial observability. However, unlike natural language corpora, RL trajectories are sparse and reward-driven, making standard self-attention inefficient because it distributes weight uniformly across all past tokens rather than emphasizing the few transitions critical for control. To address this, we introduce structured inductive priors into the self-attention mechanism of the dynamics head: (i) per-head memory-length priors that constrain attention to task-specific windows, and (ii) distributional priors that learn smooth Gaussian weightings over past state-action pairs. We integrate these mechanisms into UniZero, a model-based RL agent with a Transformer-based world model that supports planning under partial observability. Experiments on the Atari 100k benchmark show that most efficiency gains arise from the Gaussian prior, which smoothly allocates attention to informative transitions, while memory-length priors often truncate useful signals with overly restrictive cut-offs. In particular, Gaussian Attention achieves a 77% relative improvement in mean human-normalized scores over UniZero. These findings suggest that in partially observable RL domains with non-stationary temporal dependencies, discrete memory windows are difficult to learn reliably, whereas smooth distributional priors flexibly adapt across horizons and yield more robust data efficiency. Overall, our results demonstrate that encoding structured temporal priors directly into self-attention improves the prioritization of informative histories for dynamics modeling under partial observability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹éƒ¨åˆ†å¯è§‚æµ‹å¼ºåŒ–å­¦ä¹ (Partially Observable RL)ä¸­æ ‡å‡†è‡ªæ³¨æ„åŠ›æœºåˆ¶éš¾ä»¥æœ‰æ•ˆæ•æ‰ç¨€ç–ä¸”å¥–åŠ±é©±åŠ¨çš„è½¨è¿¹è¿™ä¸€é—®é¢˜ï¼Œæå‡ºåœ¨åŸºäºTransformerçš„ä¸–ç•Œæ¨¡å‹ä¸­å¼•å…¥ç»“æ„åŒ–å½’çº³å…ˆéªŒ(structured inductive priors)ã€‚ç ”ç©¶è€…åœ¨UniZeroæ¡†æ¶ä¸­é›†æˆäº†ä¸¤ç§æœºåˆ¶ï¼šé™åˆ¶æ³¨æ„åŠ›èŒƒå›´çš„æ¯å¤´è®°å¿†é•¿åº¦å…ˆéªŒ(per-head memory-length priors)å’Œå­¦ä¹ å¹³æ»‘é«˜æ–¯æƒé‡çš„åˆ†å¸ƒå…ˆéªŒ(distributional priors)ã€‚åœ¨Atari 100kåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œé«˜æ–¯æ³¨æ„åŠ›(Gaussian Attention)è´¡çŒ®äº†ä¸»è¦çš„æ•ˆç‡æå‡ï¼Œç›¸å¯¹äºUniZeroå®ç°äº†77%çš„äººç±»å½’ä¸€åŒ–åˆ†æ•°ç›¸å¯¹æ”¹è¿›ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¦»æ•£çš„è®°å¿†é•¿åº¦å…ˆéªŒå¾€å¾€å› è¿‡åº¦é™åˆ¶è€Œæˆªæ–­äº†æœ‰ç”¨çš„å†å²ä¿¡å·ï¼Œéš¾ä»¥é€‚åº”éå¹³ç¨³çš„æ—¶é—´ä¾èµ–æ€§ã€‚ç ”ç©¶ç»“æœè¯å®ï¼Œé€šè¿‡å¹³æ»‘çš„åˆ†å¸ƒå…ˆéªŒå°†ç»“æ„åŒ–æ—¶é—´ä¿¡æ¯ç¼–ç åˆ°è‡ªæ³¨æ„åŠ›ä¸­ï¼Œèƒ½å¤Ÿæ˜¾è‘—æ”¹å–„æ¨¡å‹åœ¨éƒ¨åˆ†å¯è§‚æµ‹ç¯å¢ƒä¸‹å¯¹å…³é”®å†å²ä¿¡æ¯çš„ä¼˜å…ˆå¤„ç†èƒ½åŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Embodied World Models for Decision Making (EWM) Workshop at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06946v1",
      "published_date": "2025-11-10 10:53:16 UTC",
      "updated_date": "2025-11-10 10:53:16 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:26:54.313965+00:00"
    },
    {
      "arxiv_id": "2511.06944v1",
      "title": "From Attribution to Action: Jointly ALIGNing Predictions and Explanations",
      "title_zh": "ä»å½’å› åˆ°è¡ŒåŠ¨ï¼šè”åˆå¯¹é½é¢„æµ‹ä¸è§£é‡Š",
      "authors": [
        "Dongsheng Hong",
        "Chao Chen",
        "Yanhui Chen",
        "Shanshan Lin",
        "Zhihao Chen",
        "Xiangwen Liao"
      ],
      "abstract": "Explanation-guided learning (EGL) has shown promise in aligning model predictions with interpretable reasoning, particularly in computer vision tasks. However, most approaches rely on external annotations or heuristic-based segmentation to supervise model explanations, which can be noisy, imprecise and difficult to scale. In this work, we provide both empirical and theoretical evidence that low-quality supervision signals can degrade model performance rather than improve it. In response, we propose ALIGN, a novel framework that jointly trains a classifier and a masker in an iterative manner. The masker learns to produce soft, task-relevant masks that highlight informative regions, while the classifier is optimized for both prediction accuracy and alignment between its saliency maps and the learned masks. By leveraging high-quality masks as guidance, ALIGN improves both interpretability and generalizability, showing its superiority across various settings. Experiments on the two domain generalization benchmarks, VLCS and Terra Incognita, show that ALIGN consistently outperforms six strong baselines in both in-distribution and out-of-distribution settings. Besides, ALIGN also yields superior explanation quality concerning sufficiency and comprehensiveness, highlighting its effectiveness in producing accurate and interpretable models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Explanation-guided learning (EGL)é€šå¸¸ä¾èµ–å¤–éƒ¨æ ‡æ³¨æˆ–å¯å‘å¼åˆ†å‰²å¯¼è‡´ç›‘ç£ä¿¡å·å™ªå£°å¤§ä¸”éš¾ä»¥æ‰©å±•çš„é—®é¢˜ï¼Œæä¾›äº†ä½è´¨é‡ç›‘ç£ä¿¡å·åè€Œä¼šé™ä½æ¨¡å‹æ€§èƒ½çš„å®è¯å’Œç†è®ºè¯æ®ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ALIGNæ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£æ–¹å¼è”åˆè®­ç»ƒåˆ†ç±»å™¨å’Œmaskerã€‚Maskerå­¦ä¹ ç”Ÿæˆçªå‡ºå…³é”®ä¿¡æ¯åŒºåŸŸçš„è½¯æ©ç (soft masks)ï¼Œè€Œåˆ†ç±»å™¨åŒæ—¶ä¼˜åŒ–é¢„æµ‹å‡†ç¡®æ€§åŠå…¶æ˜¾è‘—æ€§å›¾(saliency maps)ä¸æ©ç ä¹‹é—´çš„å¯¹é½ã€‚åˆ©ç”¨é«˜è´¨é‡æ©ç ä½œä¸ºæŒ‡å¯¼ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆæå‡äº†æ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚åœ¨VLCSå’ŒTerra Incognitaä¸¤ä¸ªé¢†åŸŸæ³›åŒ–åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒALIGNåœ¨åˆ†å¸ƒå†…å’Œåˆ†å¸ƒå¤–è®¾ç½®ä¸‹å‡ä¼˜äºå…­ä¸ªå¼ºåŸºçº¿æ¨¡å‹ï¼Œå¹¶åœ¨è§£é‡Šçš„å……åˆ†æ€§å’Œå…¨é¢æ€§æ–¹é¢è¡¨ç°å‡ºä¼—ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06944v1",
      "published_date": "2025-11-10 10:52:17 UTC",
      "updated_date": "2025-11-10 10:52:17 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:27:25.755879+00:00"
    },
    {
      "arxiv_id": "2511.06943v2",
      "title": "PlantTraitNet: An Uncertainty-Aware Multimodal Framework for Global-Scale Plant Trait Inference from Citizen Science Data",
      "title_zh": "PlantTraitNetï¼šåŸºäºå…¬æ°‘ç§‘å­¦æ•°æ®çš„å…¨çƒå°ºåº¦æ¤ç‰©æ€§çŠ¶æ¨æ–­ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¤šæ¨¡æ€æ¡†æ¶",
      "authors": [
        "Ayushi Sharma",
        "Johanna Trost",
        "Daniel Lusk",
        "Johannes Dollinger",
        "Julian Schrader",
        "Christian Rossi",
        "Javier Lopatin",
        "Etienne LalibertÃ©",
        "Simon Haberstroh",
        "Jana Eichel",
        "Daniel Mederer",
        "Jose Miguel Cerda-Paredes",
        "Shyam S. Phartyal",
        "Lisa-Maricia Schwarz",
        "Anja LinstÃ¤dter",
        "Maria ConceiÃ§Ã£o Caldeira",
        "Teja Kattenborn"
      ],
      "abstract": "Global plant maps of plant traits, such as leaf nitrogen or plant height, are essential for understanding ecosystem processes, including the carbon and energy cycles of the Earth system. However, existing trait maps remain limited by the high cost and sparse geographic coverage of field-based measurements. Citizen science initiatives offer a largely untapped resource to overcome these limitations, with over 50 million geotagged plant photographs worldwide capturing valuable visual information on plant morphology and physiology. In this study, we introduce PlantTraitNet, a multi-modal, multi-task uncertainty-aware deep learning framework that predictsfour key plant traits (plant height, leaf area, specific leaf area, and nitrogen content) from citizen science photos using weak supervision. By aggregating individual trait predictions across space, we generate global maps of trait distributions. We validate these maps against independent vegetation survey data (sPlotOpen) and benchmark them against leading global trait products. Our results show that PlantTraitNet consistently outperforms existing trait maps across all evaluated traits, demonstrating that citizen science imagery, when integrated with computer vision and geospatial AI, enables not only scalable but also more accurate global trait mapping. This approach offers a powerful new pathway for ecological research and Earth system modeling.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ç°æœ‰å…¨çƒæ¤ç‰©æ€§çŠ¶å›¾è°±æˆæœ¬é«˜ä¸”è¦†ç›–ç¨€ç–çš„é—®é¢˜ï¼Œæå‡ºäº†PlantTraitNetï¼Œä¸€ç§å¤šæ¨¡æ€ã€å¤šä»»åŠ¡ä¸”å…·å¤‡ä¸ç¡®å®šæ€§æ„ŸçŸ¥(uncertainty-aware)çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¨¡å‹åˆ©ç”¨åŒ…å«è¶…è¿‡5000ä¸‡å¼ å¸¦æœ‰åœ°ç†æ ‡ç­¾ç…§ç‰‡çš„å…¬æ°‘ç§‘å­¦(citizen science)æ•°æ®ï¼Œé€šè¿‡å¼±ç›‘ç£å­¦ä¹ (weak supervision)é¢„æµ‹æ¤ç‰©é«˜åº¦ã€å¶é¢ç§¯ã€æ¯”å¶é¢ç§¯å’Œæ°®å«é‡ç­‰å…³é”®æ€§çŠ¶ã€‚é€šè¿‡èšåˆç©ºé—´ä¸Šçš„ä¸ªä½“é¢„æµ‹ï¼Œç ”ç©¶äººå‘˜ç”Ÿæˆäº†å…¨çƒæ€§çŠ¶åˆ†å¸ƒå›¾ï¼Œå¹¶åˆ©ç”¨ç‹¬ç«‹æ¤è¢«è°ƒæŸ¥æ•°æ®(sPlotOpen)è¿›è¡Œäº†éªŒè¯ã€‚ç»“æœè¡¨æ˜ï¼ŒPlantTraitNetåœ¨æ‰€æœ‰è¯„ä¼°æ€§çŠ¶ä¸Šå‡ä¼˜äºç°æœ‰çš„å…¨çƒæ€§çŠ¶äº§å“ï¼Œè¯æ˜äº†å°†å…¬æ°‘ç§‘å­¦å›¾åƒä¸è®¡ç®—æœºè§†è§‰(Computer Vision)åŠåœ°ç†ç©ºé—´äººå·¥æ™ºèƒ½(Geospatial AI)ç›¸ç»“åˆï¼Œèƒ½å¤Ÿå®ç°æ›´å…·æ‰©å±•æ€§å’Œå‡†ç¡®æ€§çš„å…¨çƒæ¤ç‰©æ€§çŠ¶æµ‹ç»˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint version of the paper accepted at the 40th AAAI Conference on Artificial Intelligence (AAAI-26), organized by the Association for the Advancement of Artificial Intelligence",
      "pdf_url": "https://arxiv.org/pdf/2511.06943v2",
      "published_date": "2025-11-10 10:51:04 UTC",
      "updated_date": "2026-01-22 14:52:49 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:27:43.894249+00:00"
    },
    {
      "arxiv_id": "2511.06937v1",
      "title": "Fine-Tuning Diffusion-Based Recommender Systems via Reinforcement Learning with Reward Function Optimization",
      "title_zh": "åŸºäºå¥–åŠ±å‡½æ•°ä¼˜åŒ–å¼ºåŒ–å­¦ä¹ çš„æ‰©æ•£æ¨èç³»ç»Ÿå¾®è°ƒ",
      "authors": [
        "Yu Hou",
        "Hua Li",
        "Ha Young Kim",
        "Won-Yong Shin"
      ],
      "abstract": "Diffusion models recently emerged as a powerful paradigm for recommender systems, offering state-of-the-art performance by modeling the generative process of user-item interactions. However, training such models from scratch is both computationally expensive and yields diminishing returns once convergence is reached. To remedy these challenges, we propose ReFiT, a new framework that integrates Reinforcement learning (RL)-based Fine-Tuning into diffusion-based recommender systems. In contrast to prior RL approaches for diffusion models depending on external reward models, ReFiT adopts a task-aligned design: it formulates the denoising trajectory as a Markov decision process (MDP) and incorporates a collaborative signal-aware reward function that directly reflects recommendation quality. By tightly coupling the MDP structure with this reward signal, ReFiT empowers the RL agent to exploit high-order connectivity for fine-grained optimization, while avoiding the noisy or uninformative feedback common in naive reward designs. Leveraging policy gradient optimization, ReFiT maximizes exact log-likelihood of observed interactions, thereby enabling effective post hoc fine-tuning of diffusion recommenders. Comprehensive experiments on wide-ranging real-world datasets demonstrate that the proposed ReFiT framework (a) exhibits substantial performance gains over strong competitors (up to 36.3% on sequential recommendation), (b) demonstrates strong efficiency with linear complexity in the number of users or items, and (c) generalizes well across multiple diffusion-based recommendation scenarios. The source code and datasets are publicly available at https://anonymous.4open.science/r/ReFiT-4C60.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ‰©æ•£æ¨¡å‹æ¨èç³»ç»Ÿä»å¤´è®­ç»ƒè®¡ç®—æˆæœ¬é«˜ä¸”æ”¶æ•›åæ”¶ç›Šé€’å‡çš„é—®é¢˜ï¼Œæå‡ºäº†ReFiTæ¡†æ¶ï¼Œå°†åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çš„å¾®è°ƒç­–ç•¥é›†æˆåˆ°ç³»ç»Ÿä¸­ã€‚ä¸åŒäºä¾èµ–å¤–éƒ¨å¥–åŠ±æ¨¡å‹çš„ç°æœ‰æ–¹æ³•ï¼ŒReFiTé‡‡ç”¨ä»»åŠ¡å¯¹é½è®¾è®¡ï¼Œå°†å»å™ªè½¨è¿¹æ„å»ºä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œå¹¶ç»“åˆç›´æ¥åæ˜ æ¨èè´¨é‡çš„ååŒä¿¡å·æ„ŸçŸ¥å¥–åŠ±å‡½æ•°ï¼ˆcollaborative signal-aware reward functionï¼‰ã€‚è¯¥æ–¹æ³•é€šè¿‡ç­–ç•¥æ¢¯åº¦ä¼˜åŒ–æœ€å¤§åŒ–è§‚æµ‹äº¤äº’çš„ç²¾ç¡®å¯¹æ•°ä¼¼ç„¶ï¼Œä½¿æ™ºèƒ½ä½“èƒ½å¤Ÿåˆ©ç”¨é«˜é˜¶è¿æ¥æ€§è¿›è¡Œç»†ç²’åº¦ä¼˜åŒ–ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„äº‹åå¾®è°ƒã€‚åœ¨å¹¿æ³›çš„çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒReFiTåœ¨åºåˆ—æ¨èä»»åŠ¡ä¸­ç›¸æ¯”å¼ºåŸºçº¿æ¨¡å‹å®ç°äº†é«˜è¾¾36.3%çš„æ€§èƒ½æå‡ï¼ŒåŒæ—¶å…·å¤‡çº¿æ€§çš„è®¡ç®—å¤æ‚åº¦ï¼Œå¹¶åœ¨å¤šç§æ‰©æ•£æ¨èåœºæ™¯ä¸­è¡¨ç°å‡ºè‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 12 figures, 9 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.06937v1",
      "published_date": "2025-11-10 10:38:16 UTC",
      "updated_date": "2025-11-10 10:38:16 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:28:27.826323+00:00"
    },
    {
      "arxiv_id": "2511.06918v1",
      "title": "Proceedings of the 2025 XCSP3 Competition",
      "title_zh": "2025 XCSP3 ç«èµ›è®ºæ–‡é›†",
      "authors": [
        "Gilles Audemard",
        "Christophe Lecoutre",
        "Emmanuel Lonca"
      ],
      "abstract": "This document represents the proceedings of the 2025 XCSP3 Competition. The results of this competition of constraint solvers were presented at CP'25 (31st International Conference on Principles and Practice of Constraint Programming).",
      "tldr_zh": "æœ¬æ–‡æ¡£æ˜¯2025å¹´XCSP3ç«èµ›ï¼ˆXCSP3 Competitionï¼‰çš„ä¼šè®®è®°å½•æ‘˜è¦ã€‚è¯¥ç«èµ›ä¸»è¦èšç„¦äºçº¦æŸæ±‚è§£å™¨ï¼ˆconstraint solversï¼‰çš„æ€§èƒ½è¯„æµ‹ä¸æ¯”æ‹¼ã€‚ç«èµ›çš„å…·ä½“ç»“æœå·²åœ¨ç¬¬31å±Šçº¦æŸè§„åˆ’åŸç†ä¸å®è·µå›½é™…ä¼šè®®ï¼ˆCP'25ï¼‰ä¸Šè¿›è¡Œäº†æ­£å¼å±•ç¤ºã€‚è¯¥è®°å½•æ±‡æ€»äº†æ­¤æ¬¡ç«èµ›çš„ç›¸å…³å‘ç°ï¼Œåæ˜ äº†çº¦æŸæ»¡è¶³é—®é¢˜æ±‚è§£é¢†åŸŸçš„æœ€æ–°è¿›å±•ä¸æŠ€æœ¯æ°´å¹³ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "110 pages",
      "pdf_url": "https://arxiv.org/pdf/2511.06918v1",
      "published_date": "2025-11-10 10:12:04 UTC",
      "updated_date": "2025-11-10 10:12:04 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:31:42.684864+00:00"
    },
    {
      "arxiv_id": "2511.06913v1",
      "title": "Sampling and Loss Weights in Multi-Domain Training",
      "title_zh": "å¤šé¢†åŸŸè®­ç»ƒä¸­çš„é‡‡æ ·æƒé‡ä¸æŸå¤±æƒé‡",
      "authors": [
        "Mahdi Salmani",
        "Pratik Worah",
        "Meisam Razaviyayn",
        "Vahab Mirrokni"
      ],
      "abstract": "In the training of large deep neural networks, there is a need for vast amounts of training data. To meet this need, data is collected from multiple domains, such as Wikipedia and GitHub. These domains are heterogeneous in both data quality and the diversity of information they provide. This raises the question of how much we should rely on each domain. Several methods have attempted to address this issue by assigning sampling weights to each data domain using heuristics or approximations. As a first step toward a deeper understanding of the role of data mixing, this work revisits the problem by studying two kinds of weights: sampling weights, which control how much each domain contributes in a batch, and loss weights, which scale the loss from each domain during training. Through a rigorous study of linear regression, we show that these two weights play complementary roles. First, they can reduce the variance of gradient estimates in iterative methods such as stochastic gradient descent (SGD). Second, they can improve generalization performance by reducing the generalization gap. We provide both theoretical and empirical support for these claims. We further study the joint dynamics of sampling weights and loss weights, examining how they can be combined to capture both contributions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹æ·±åº¦ç¥ç»ç½‘ç»œè®­ç»ƒä¸­å¤šé¢†åŸŸæ•°æ®ï¼ˆå¦‚Wikipediaå’ŒGitHubï¼‰çš„å¼‚æ„æ€§é—®é¢˜ï¼Œæ·±å…¥æ¢è®¨äº†æ•°æ®æ··åˆç­–ç•¥ã€‚ä¸åŒäºä»¥å¾€ä¾èµ–å¯å‘å¼æ–¹æ³•çš„å°è¯•ï¼Œæœ¬æ–‡é‡ç‚¹ç ”ç©¶äº†Sampling weightsï¼ˆæ§åˆ¶batchä¸­çš„é¢†åŸŸè´¡çŒ®ï¼‰å’ŒLoss weightsï¼ˆç¼©æ”¾è®­ç»ƒæŸå¤±ï¼‰è¿™ä¸¤ç§æƒé‡çš„è§’è‰²ã€‚é€šè¿‡å¯¹çº¿æ€§å›å½’çš„ä¸¥æ ¼åˆ†æï¼Œç ”ç©¶å‘ç°è¿™ä¸¤è€…åœ¨è®­ç»ƒä¸­å‘æŒ¥ç€äº’è¡¥ä½œç”¨ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒä»¬ä¸ä»…èƒ½æœ‰æ•ˆé™ä½éšæœºæ¢¯åº¦ä¸‹é™(SGD)ç­‰è¿­ä»£æ–¹æ³•ä¸­æ¢¯åº¦ä¼°è®¡çš„æ–¹å·®ï¼Œè¿˜èƒ½é€šè¿‡ç¼©å°æ³›åŒ–å·®è·æ¥æå‡æ¨¡å‹çš„æ³›åŒ–æ€§èƒ½ã€‚æ–‡ç« æä¾›äº†ç›¸å…³çš„ç†è®ºè¯æ˜å’Œå®è¯æ”¯æŒï¼Œå¹¶è¿›ä¸€æ­¥ç ”ç©¶äº†è¿™ä¸¤ç§æƒé‡çš„è”åˆåŠ¨æ€åŠå…¶ç»“åˆæ–¹å¼ï¼Œä¸ºç†è§£å¤šé¢†åŸŸè®­ç»ƒä¸­çš„æ•°æ®æ··åˆæœºåˆ¶æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06913v1",
      "published_date": "2025-11-10 10:08:53 UTC",
      "updated_date": "2025-11-10 10:08:53 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:32:07.430127+00:00"
    },
    {
      "arxiv_id": "2511.06906v2",
      "title": "Counterfactual Explanation for Multivariate Time Series Forecasting with Exogenous Variables",
      "title_zh": "å«å¤–ç”Ÿå˜é‡å¤šå…ƒæ—¶é—´åºåˆ—é¢„æµ‹çš„åäº‹å®è§£é‡Š",
      "authors": [
        "Keita Kinjo"
      ],
      "abstract": "Currently, machine learning is widely used across various domains, including time series data analysis. However, some machine learning models function as black boxes, making interpretability a critical concern. One approach to address this issue is counterfactual explanation (CE), which aims to provide insights into model predictions. This study focuses on the relatively underexplored problem of generating counterfactual explanations for time series forecasting. We propose a method for extracting CEs in time series forecasting using exogenous variables, which are frequently encountered in fields such as business and marketing. In addition, we present methods for analyzing the influence of each variable over an entire time series, generating CEs by altering only specific variables, and evaluating the quality of the resulting CEs. We validate the proposed method through theoretical analysis and empirical experiments, showcasing its accuracy and practical applicability. These contributions are expected to support real-world decision-making based on time series data analysis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—åˆ†æä¸­æœºå™¨å­¦ä¹ æ¨¡å‹çš„å¯è§£é‡Šæ€§é—®é¢˜ï¼Œé‡ç‚¹å…³æ³¨äº†åäº‹å®è§£é‡Šï¼ˆCounterfactual Explanation, CEï¼‰çš„åº”ç”¨ã€‚ä½œè€…æå‡ºäº†ä¸€ç§é’ˆå¯¹åŒ…å«å¤–ç”Ÿå˜é‡ï¼ˆexogenous variablesï¼‰çš„å¤šå˜é‡æ—¶é—´åºåˆ—é¢„æµ‹ç”ŸæˆCEçš„æ–¹æ³•ï¼Œè¿™åœ¨å•†ä¸šå’Œè¥é”€ç­‰é¢†åŸŸå°¤ä¸ºå¸¸è§ã€‚è¯¥ç ”ç©¶ä¸ä»…ä»‹ç»äº†å¦‚ä½•åˆ†æå„å˜é‡åœ¨æ•´ä¸ªæ—¶é—´åºåˆ—ä¸­çš„å½±å“ï¼Œè¿˜æå‡ºäº†é€šè¿‡ä»…æ”¹å˜ç‰¹å®šå˜é‡æ¥ç”ŸæˆCEä»¥åŠè¯„ä¼°CEè´¨é‡çš„æ–¹æ³•ã€‚é€šè¿‡ç†è®ºåˆ†æå’Œå®è¯å®éªŒï¼Œè¯¥æ–¹æ³•è¢«éªŒè¯å…·æœ‰è¾ƒé«˜çš„å‡†ç¡®æ€§å’Œå®é™…åº”ç”¨ä»·å€¼ï¼Œæœ‰æœ›ä¸ºåŸºäºæ—¶é—´åºåˆ—æ•°æ®çš„ç°å®ä¸–ç•Œå†³ç­–æä¾›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27pages,9figures,9tables",
      "pdf_url": "https://arxiv.org/pdf/2511.06906v2",
      "published_date": "2025-11-10 10:00:28 UTC",
      "updated_date": "2025-11-28 07:46:06 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:32:27.620486+00:00"
    },
    {
      "arxiv_id": "2511.06899v2",
      "title": "RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation",
      "title_zh": "RPTSï¼šé¢å‘å¿ å®å¤šæ¨¡æ€è¯„ä¼°çš„æ ‘çŠ¶ç»“æ„æ¨ç†è¿‡ç¨‹è¯„åˆ†",
      "authors": [
        "Haofeng Wang",
        "Yu Zhang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.",
      "tldr_zh": "é’ˆå¯¹ç°æœ‰çš„å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åŸºå‡†æµ‹è¯•å¾€å¾€å¿½è§†æ¨ç†è¿‡ç¨‹æˆ–ä»…åœ¨ç­”æ¡ˆé”™è¯¯æ—¶è¿›è¡Œç®€å•è¯„ä¼°çš„å±€é™æ€§ï¼Œè¯¥ç ”ç©¶æå‡ºäº†RPTS (Reasoning Process Tree Score)ï¼Œä¸€ç§åŸºäºæ ‘ç»“æ„çš„æ¨ç†è¿‡ç¨‹è¯„åˆ†æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒRPTSå°†æ¨ç†æ­¥éª¤ç»„ç»‡æˆreasoning treeï¼Œåˆ©ç”¨å±‚çº§ä¿¡æ¯ä¸ºæ¯ä¸ªæ¨ç†æ­¥éª¤åˆ†é…åŠ æƒçš„faithfulness scoresï¼Œä»è€Œåœ¨è¯„ä¼°æ¨ç†æ•´ä½“æ­£ç¡®æ€§çš„åŒæ—¶ï¼Œé€šè¿‡åŠ¨æ€æƒé‡è°ƒæ•´ç²¾ç¡®å®šä½æ¨¡å‹æ¨ç†å¤±è´¥çš„ç¯èŠ‚ã€‚ä¸ºäº†åœ¨çœŸå®åœºæ™¯ä¸­éªŒè¯è¯¥æŒ‡æ ‡ï¼Œä½œè€…æ„å»ºäº†åŒ…å«374å¼ å›¾åƒå’Œ390ä¸ªæ¨ç†å®ä¾‹çš„æ–°åŸºå‡†RPTS-Evalï¼Œå¹¶å®šä¹‰äº†ä¸‰ç§æ¨¡æ€é—´å…³ç³»ä»¥ç ”ç©¶æ¨¡æ€äº¤äº’å¯¹æ¨ç†çš„å½±å“ã€‚å®éªŒè¯„ä¼°äº†åŒ…æ‹¬GPT4oå’ŒLlava-Nextåœ¨å†…çš„ä»£è¡¨æ€§LVLMsï¼Œæ­ç¤ºäº†å½“å‰æ¨¡å‹åœ¨å¤šæ¨¡æ€æ¨ç†ä¸­çš„ä¸è¶³ä»¥åŠå¼€æºä¸é—­æºæ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ã€‚è¯¥ç ”ç©¶é€šè¿‡å…³æ³¨æ¨ç†è¿‡ç¨‹çš„å¿ å®åº¦ï¼Œä¸ºæ¨è¿›å¤šæ¨¡æ€æ¨ç†é¢†åŸŸçš„å‘å±•åšå‡ºäº†è´¡çŒ®ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06899v2",
      "published_date": "2025-11-10 09:48:07 UTC",
      "updated_date": "2026-01-19 12:53:44 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:32:54.476662+00:00"
    },
    {
      "arxiv_id": "2511.06898v1",
      "title": "A Hybrid Autoencoder-Transformer Model for Robust Day-Ahead Electricity Price Forecasting under Extreme Conditions",
      "title_zh": "é¢å‘æç«¯æ¡ä»¶ä¸‹é²æ£’æ—¥å‰ç”µä»·é¢„æµ‹çš„æ··åˆè‡ªç¼–ç å™¨-Transformeræ¨¡å‹",
      "authors": [
        "Boyan Tang",
        "Xuanhao Ren",
        "Peng Xiao",
        "Shunbo Lei",
        "Xiaorong Sun",
        "Jianghua Wu"
      ],
      "abstract": "Accurate day-ahead electricity price forecasting (DAEPF) is critical for the efficient operation of power systems, but extreme condition and market anomalies pose significant challenges to existing forecasting methods. To overcome these challenges, this paper proposes a novel hybrid deep learning framework that integrates a Distilled Attention Transformer (DAT) model and an Autoencoder Self-regression Model (ASM). The DAT leverages a self-attention mechanism to dynamically assign higher weights to critical segments of historical data, effectively capturing both long-term trends and short-term fluctuations. Concurrently, the ASM employs unsupervised learning to detect and isolate anomalous patterns induced by extreme conditions, such as heavy rain, heat waves, or human festivals. Experiments on datasets sampled from California and Shandong Province demonstrate that our framework significantly outperforms state-of-the-art methods in prediction accuracy, robustness, and computational efficiency. Our framework thus holds promise for enhancing grid resilience and optimizing market operations in future power systems.",
      "tldr_zh": "æœ¬æ–‡é’ˆå¯¹æç«¯æ¡ä»¶å’Œå¸‚åœºå¼‚å¸¸å¯¹æ—¥å‰ç”µä»·é¢„æµ‹(DAEPF)é€ æˆçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆäº†è’¸é¦æ³¨æ„åŠ›Transformer (DAT)æ¨¡å‹å’Œè‡ªç¼–ç å™¨è‡ªå›å½’æ¨¡å‹(ASM)çš„æ–°å‹æ··åˆæ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚DATåˆ©ç”¨è‡ªæ³¨æ„åŠ›æœºåˆ¶åŠ¨æ€åœ°ä¸ºå†å²æ•°æ®çš„å…³é”®ç‰‡æ®µåˆ†é…æ›´é«˜æƒé‡ï¼Œä»è€Œæœ‰æ•ˆæ•æ‰é•¿æœŸè¶‹åŠ¿å’ŒçŸ­æœŸæ³¢åŠ¨ã€‚åŒæ—¶ï¼ŒASMé‡‡ç”¨æ— ç›‘ç£å­¦ä¹ æ¥æ£€æµ‹å’Œéš”ç¦»ç”±æš´é›¨ã€çƒ­æµªæˆ–äººç±»èŠ‚æ—¥ç­‰æç«¯æ¡ä»¶å¼•èµ·çš„å¼‚å¸¸æ¨¡å¼ã€‚åœ¨åŠ åˆ©ç¦å°¼äºšå·å’Œå±±ä¸œçœçš„æ•°æ®é›†ä¸Šè¿›è¡Œçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨é¢„æµ‹ç²¾åº¦ã€é²æ£’æ€§å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›(SOTA)æ–¹æ³•ã€‚è¯¥ç ”ç©¶æˆæœæœ‰æœ›å¢å¼ºç”µç½‘å¼¹æ€§å¹¶ä¼˜åŒ–æœªæ¥ç”µåŠ›ç³»ç»Ÿçš„å¸‚åœºè¿ä½œã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in 2025 IEEE 1st International Symposium on the Application of Artificial Intelligence in Electrical Engineering (AAIEE) https://ieeexplore.ieee.org/document/11100637",
      "pdf_url": "https://arxiv.org/pdf/2511.06898v1",
      "published_date": "2025-11-10 09:47:24 UTC",
      "updated_date": "2025-11-10 09:47:24 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:33:18.360173+00:00"
    },
    {
      "arxiv_id": "2511.06895v1",
      "title": "On The Presence of Double-Descent in Deep Reinforcement Learning",
      "title_zh": "æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­åŒé‡ä¸‹é™ç°è±¡çš„å­˜åœ¨æ€§",
      "authors": [
        "Viktor VeselÃ½",
        "Aleksandar Todorov",
        "Matthia Sabatelli"
      ],
      "abstract": "The double descent (DD) paradox, where over-parameterized models see generalization improve past the interpolation point, remains largely unexplored in the non-stationary domain of Deep Reinforcement Learning (DRL). We present preliminary evidence that DD exists in model-free DRL, investigating it systematically across varying model capacity using the Actor-Critic framework. We rely on an information-theoretic metric, Policy Entropy, to measure policy uncertainty throughout training. Preliminary results show a clear epoch-wise DD curve; the policy's entrance into the second descent region correlates with a sustained, significant reduction in Policy Entropy. This entropic decay suggests that over-parameterization acts as an implicit regularizer, guiding the policy towards robust, flatter minima in the loss landscape. These findings establish DD as a factor in DRL and provide an information-based mechanism for designing agents that are more general, transferable, and robust.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning, DRL)è¿™ä¸€éå¹³ç¨³é¢†åŸŸä¸­åŒé‡ä¸‹é™(Double Descent, DD)ç°è±¡çš„å­˜åœ¨æ€§ï¼Œå¡«è¡¥äº†è¯¥é¢†åŸŸçš„æ¢ç´¢ç©ºç™½ã€‚ä½œè€…åŸºäºActor-Criticæ¡†æ¶ï¼Œé€šè¿‡æ”¹å˜æ¨¡å‹å®¹é‡åœ¨æ— æ¨¡å‹DRLä¸­ç³»ç»Ÿåœ°è°ƒæŸ¥äº†è¿™ä¸€ç°è±¡ï¼Œå¹¶åˆ©ç”¨ä¿¡æ¯è®ºæŒ‡æ ‡ç­–ç•¥ç†µ(Policy Entropy)æ¥è¡¡é‡è®­ç»ƒè¿‡ç¨‹ä¸­çš„ç­–ç•¥ä¸ç¡®å®šæ€§ã€‚åˆæ­¥å®éªŒç»“æœå±•ç¤ºäº†æ¸…æ™°çš„epoch-wise DDæ›²çº¿ï¼Œå‘ç°ç­–ç•¥è¿›å…¥ç¬¬äºŒä¸ªä¸‹é™åŒºåŸŸä¸ç­–ç•¥ç†µçš„æŒç»­æ˜¾è‘—é™ä½å¯†åˆ‡ç›¸å…³ã€‚è¿™ç§ç†µè¡°å‡è¡¨æ˜è¿‡å‚æ•°åŒ–(over-parameterization)ä½œä¸ºä¸€ç§éšå¼æ­£åˆ™åŒ–å™¨ï¼Œå¼•å¯¼ç­–ç•¥æ”¶æ•›è‡³æŸå¤±æ™¯è§‚ä¸­æ›´é²æ£’ã€æ›´å¹³å¦çš„æå°å€¼ã€‚è¿™äº›å‘ç°è¯å®äº†DDåœ¨DRLä¸­çš„ä½œç”¨ï¼Œå¹¶ä¸ºè®¾è®¡æ›´é€šç”¨ã€å¯è¿ç§»å’Œé²æ£’çš„æ™ºèƒ½ä½“æä¾›äº†åŸºäºä¿¡æ¯çš„ç†è®ºæœºåˆ¶ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06895v1",
      "published_date": "2025-11-10 09:45:03 UTC",
      "updated_date": "2025-11-10 09:45:03 UTC",
      "processing_status": "completed",
      "attempts": 2,
      "max_attempts": 3,
      "error": "Error code: 500 - {'error': 'å½“å‰æ— å¯ç”¨å‡­è¯'}",
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T23:33:47.107227+00:00"
    },
    {
      "arxiv_id": "2511.06894v2",
      "title": "COGNOS: Universal Enhancement for Time Series Anomaly Detection via Constrained Gaussian-Noise Optimization and Smoothing",
      "title_zh": "COGNOSï¼šåŸºäºçº¦æŸé«˜æ–¯å™ªå£°ä¼˜åŒ–ä¸å¹³æ»‘çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹é€šç”¨å¢å¼º",
      "authors": [
        "Wenlong Shang",
        "Shihao Tian",
        "Xutong Wan",
        "Peng Chang"
      ],
      "abstract": "Reconstruction-based methods are a dominant paradigm in time series anomaly detection (TSAD), however, their near-universal reliance on Mean Squared Error (MSE) loss results in statistically flawed reconstruction residuals. This fundamental weakness leads to noisy, unstable anomaly scores, hindering reliable detection. To address this, we propose Constrained Gaussian-Noise Optimization and Smoothing (COGNOS), a universal, model-agnostic enhancement framework that tackles this issue at its source. COGNOS introduces a novel Gaussian-White Noise Regularization strategy during training, which directly constrains the model's output residuals to conform to a Gaussian white noise distribution. This engineered statistical property creates the ideal precondition for our second contribution: Adaptive Residual Kalman Smoother that operates as a statistically robust estimator to denoise the raw anomaly scores. Extensive experiments on multiple benchmarks demonstrate that COGNOS consistently enhances the performance of state-of-the-art backbones significantly, validating the efficacy of coupling statistical regularization with adaptive filtering.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºé‡æ„çš„æ—¶é—´åºåˆ—å¼‚å¸¸æ£€æµ‹(TSAD)æ–¹æ³•å› ä¾èµ–å‡æ–¹è¯¯å·®(MSE)æŸå¤±è€Œå¯¼è‡´é‡æ„æ®‹å·®å­˜åœ¨ç»Ÿè®¡ç¼ºé™·ã€å¼‚å¸¸åˆ†æ•°å™ªå£°å¤§ä¸”ä¸ç¨³å®šçš„é—®é¢˜ï¼Œæå‡ºäº†COGNOSï¼Œä¸€ç§é€šç”¨çš„ã€ä¸æ¨¡å‹æ— å…³çš„å¢å¼ºæ¡†æ¶ã€‚COGNOSåœ¨è®­ç»ƒé˜¶æ®µå¼•å…¥äº†åˆ›æ–°çš„é«˜æ–¯ç™½å™ªå£°æ­£åˆ™åŒ–(Gaussian-White Noise Regularization)ç­–ç•¥ï¼Œç›´æ¥çº¦æŸæ¨¡å‹çš„è¾“å‡ºæ®‹å·®ä½¿å…¶ç¬¦åˆé«˜æ–¯ç™½å™ªå£°åˆ†å¸ƒã€‚è¿™ä¸€å·¥ç¨‹åŒ–çš„ç»Ÿè®¡ç‰¹æ€§ä¸ºç¬¬äºŒé¡¹è´¡çŒ®â€”â€”è‡ªé€‚åº”æ®‹å·®å¡å°”æ›¼å¹³æ»‘å™¨(Adaptive Residual Kalman Smoother)åˆ›é€ äº†ç†æƒ³çš„å‰ææ¡ä»¶ï¼Œä½¿å…¶èƒ½å¤Ÿä½œä¸ºç»Ÿè®¡é²æ£’çš„ä¼°è®¡å™¨å¯¹åŸå§‹å¼‚å¸¸åˆ†æ•°è¿›è¡Œå»å™ªã€‚åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒCOGNOSä¸€è‡´ä¸”æ˜¾è‘—åœ°æå‡äº†æœ€å…ˆè¿›éª¨å¹²æ¨¡å‹çš„æ€§èƒ½ï¼ŒéªŒè¯äº†å°†ç»Ÿè®¡æ­£åˆ™åŒ–ä¸è‡ªé€‚åº”æ»¤æ³¢ç›¸ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06894v2",
      "published_date": "2025-11-10 09:43:48 UTC",
      "updated_date": "2026-01-19 09:52:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:12:21.961143+00:00"
    },
    {
      "arxiv_id": "2511.06893v1",
      "title": "DeepBooTS: Dual-Stream Residual Boosting for Drift-Resilient Time-Series Forecasting",
      "title_zh": "DeepBooTSï¼šé¢å‘æŠ—æ¼‚ç§»æ—¶é—´åºåˆ—é¢„æµ‹çš„åŒæµæ®‹å·®æå‡",
      "authors": [
        "Daojun Liang",
        "Jing Chen",
        "Xiao Wang",
        "Yinglong Wang",
        "Suo Li"
      ],
      "abstract": "Time-Series (TS) exhibits pronounced non-stationarity. Consequently, most forecasting methods display compromised robustness to concept drift, despite the prevalent application of instance normalization. We tackle this challenge by first analysing concept drift through a bias-variance lens and proving that weighted ensemble reduces variance without increasing bias. These insights motivate DeepBooTS, a novel end-to-end dual-stream residual-decreasing boosting method that progressively reconstructs the intrinsic signal. In our design, each block of a deep model becomes an ensemble of learners with an auxiliary output branch forming a highway to the final prediction. The block-wise outputs correct the residuals of previous blocks, leading to a learning-driven decomposition of both inputs and targets. This method enhances versatility and interpretability while substantially improving robustness to concept drift. Extensive experiments, including those on large-scale datasets, show that the proposed method outperforms existing methods by a large margin, yielding an average performance improvement of 15.8% across various datasets, establishing a new benchmark for TS forecasting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¶é—´åºåˆ—(Time-Series)é¢„æµ‹ä¸­æ˜¾è‘—çš„éå¹³ç¨³æ€§å’Œæ¦‚å¿µæ¼‚ç§»(concept drift)é—®é¢˜ï¼Œé€šè¿‡åå·®-æ–¹å·®è§†è§’è¿›è¡Œåˆ†æï¼Œè¯æ˜äº†åŠ æƒé›†æˆå¯ä»¥åœ¨ä¸å¢åŠ åå·®çš„æƒ…å†µä¸‹å‡å°‘æ–¹å·®ã€‚åŸºäºæ­¤è§è§£ï¼Œä½œè€…æå‡ºäº†DeepBooTSï¼Œä¸€ç§æ–°é¢–çš„ç«¯åˆ°ç«¯åŒæµæ®‹å·®é€’å‡Boostingæ–¹æ³•ï¼Œæ—¨åœ¨é€æ­¥é‡å»ºå†…åœ¨ä¿¡å·ã€‚åœ¨è¯¥è®¾è®¡ä¸­ï¼Œæ·±åº¦æ¨¡å‹çš„æ¯ä¸ªæ¨¡å—éƒ½æˆä¸ºå­¦ä¹ è€…çš„é›†æˆï¼Œå¹¶å…·æœ‰é€šå‘æœ€ç»ˆé¢„æµ‹çš„è¾…åŠ©è¾“å‡ºåˆ†æ”¯ï¼Œé€šè¿‡é€å—è¾“å‡ºä¿®æ­£å‰ä¸€æ¨¡å—çš„æ®‹å·®ï¼Œå®ç°äº†è¾“å…¥å’Œç›®æ ‡çš„å­¦ä¹ é©±åŠ¨åˆ†è§£ã€‚è¿™ç§æ–¹æ³•å¢å¼ºäº†æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯è§£é‡Šæ€§ï¼ŒåŒæ—¶æ˜¾è‘—æé«˜äº†å¯¹æ¦‚å¿µæ¼‚ç§»çš„é²æ£’æ€§ã€‚åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒDeepBooTSå¤§å¹…è¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹³å‡æ€§èƒ½æå‡äº†15.8%ï¼Œä¸ºæ—¶é—´åºåˆ—é¢„æµ‹å»ºç«‹äº†æ–°çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages,17 pages, Published in AAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2511.06893v1",
      "published_date": "2025-11-10 09:43:47 UTC",
      "updated_date": "2025-11-10 09:43:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:11:20.415026+00:00"
    },
    {
      "arxiv_id": "2511.06859v1",
      "title": "TuckA: Hierarchical Compact Tensor Experts for Efficient Fine-Tuning",
      "title_zh": "TuckAï¼šé¢å‘é«˜æ•ˆå¾®è°ƒçš„åˆ†å±‚ç´§å‡‘å¼ é‡ä¸“å®¶",
      "authors": [
        "Qifeng Lei",
        "Zhiyong Yang",
        "Qianqian Xu",
        "Cong Hua",
        "Peisong Wen",
        "Qingming Huang"
      ],
      "abstract": "Efficiently fine-tuning pre-trained models for downstream tasks is a key challenge in the era of foundation models. Parameter-efficient fine-tuning (PEFT) presents a promising solution, achieving performance comparable to full fine-tuning by updating only a small number of adaptation weights per layer. Traditional PEFT methods typically rely on a single expert, where the adaptation weight is a low-rank matrix. However, for complex tasks, the data's inherent diversity poses a significant challenge for such models, as a single adaptation weight cannot adequately capture the features of all samples. To address this limitation, we explore how to integrate multiple small adaptation experts into a compact structure to defeat a large adapter. Specifically, we propose Tucker Adaptation (TuckA), a method with four key properties: (i) We use Tucker decomposition to create a compact 3D tensor where each slice naturally serves as an expert. The low-rank nature of this decomposition ensures that the number of parameters scales efficiently as more experts are added. (ii) We introduce a hierarchical strategy that organizes these experts into groups at different granularities, allowing the model to capture both local and global data patterns. (iii) We develop an efficient batch-level routing mechanism, which reduces the router's parameter size by a factor of $L$ compared to routing at every adapted layer (where $L$ is the number of adapted layers) (iv) We propose data-aware initialization to achieve loss-free expert load balancing based on theoretical analysis. Extensive experiments on benchmarks in natural language understanding, image classification, and mathematical reasoning speak to the efficacy of TuckA, offering a new and effective solution to the PEFT problem.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æ–¹æ³•ä¾èµ–å•ä¸€ä¸“å®¶éš¾ä»¥æ•æ‰å¤æ‚ä»»åŠ¡ä¸­æ•°æ®å¤šæ ·æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†TuckA (Tucker Adaptation)ã€‚è¯¥æ–¹æ³•åˆ©ç”¨Tuckeråˆ†è§£æ„å»ºç´§å‡‘çš„3Då¼ é‡ï¼Œä½¿å…¶åˆ‡ç‰‡è‡ªç„¶å……å½“ä¸“å®¶ï¼Œåœ¨å¢åŠ ä¸“å®¶æ•°é‡çš„åŒæ—¶ä¿æŒå‚æ•°æ•ˆç‡ã€‚TuckAå¼•å…¥äº†åˆ†å±‚ç­–ç•¥å°†ä¸“å®¶åˆ†ç»„ä»¥åŒæ—¶æ•æ‰å±€éƒ¨å’Œå…¨å±€æ•°æ®æ¨¡å¼ï¼Œå¹¶å¼€å‘äº†é«˜æ•ˆçš„batch-level routingæœºåˆ¶ï¼Œæ˜¾è‘—å‡å°‘äº†è·¯ç”±å™¨çš„å‚æ•°è§„æ¨¡ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè¿˜æå‡ºäº†data-aware initializationç­–ç•¥ï¼ŒåŸºäºç†è®ºåˆ†æå®ç°äº†æ— æŸçš„ä¸“å®¶è´Ÿè½½å‡è¡¡ã€‚åœ¨è‡ªç„¶è¯­è¨€ç†è§£ã€å›¾åƒåˆ†ç±»å’Œæ•°å­¦æ¨ç†ç­‰åŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒTuckAèƒ½æœ‰æ•ˆé›†æˆå¤šä¸ªå°å‹ä¸“å®¶ä»¥è¶…è¶Šå¤§å‹é€‚é…å™¨ï¼Œä¸ºPEFTæä¾›äº†ä¸€ç§é«˜æ•ˆçš„æ–°è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06859v1",
      "published_date": "2025-11-10 09:03:16 UTC",
      "updated_date": "2025-11-10 09:03:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:11:46.536793+00:00"
    },
    {
      "arxiv_id": "2511.08639v2",
      "title": "The Journal of Prompt-Engineered Philosophy Or: How I Started to Track AI Assistance and Stopped Worrying About Slop",
      "title_zh": "æç¤ºå·¥ç¨‹å“²å­¦æœŸåˆŠâ€”â€”æˆ–ï¼šæˆ‘æ˜¯å¦‚ä½•å¼€å§‹è¿½è¸ª AI è¾…åŠ©å¹¶ä¸å†æ‹…å¿§åƒåœ¾å†…å®¹çš„",
      "authors": [
        "Michele Loi"
      ],
      "abstract": "Academic publishing increasingly requires authors to disclose AI assistance, yet imposes reputational costs for doing so--especially when such assistance is substantial. This article analyzes that structural contradiction, showing how incentives discourage transparency in precisely the work where it matters most. Traditional venues cannot resolve this tension through policy tweaks alone, as the underlying prestige economy rewards opacity. To address this, the article proposes an alternative publishing infrastructure: a venue outside prestige systems that enforces mandatory disclosure, enables reproduction-based review, and supports ecological validity through detailed documentation. As a demonstration of this approach, the article itself is presented as an example of AI-assisted scholarship under reasonably detailed disclosure, with representative prompt logs and modification records included. Rather than taking a position for or against AI-assisted scholarship, the article outlines conditions under which such work can be evaluated on its own terms: through transparent documentation, verification-oriented review, and participation by methodologically committed scholars. While focused on AI, the framework speaks to broader questions about how academic systems handle methodological innovation.",
      "tldr_zh": "è¿™ç¯‡æ–‡ç« åˆ†æäº†å­¦æœ¯å‡ºç‰ˆä¸­å­˜åœ¨çš„ç»“æ„æ€§çŸ›ç›¾ï¼šè™½ç„¶æœŸåˆŠè¦æ±‚æŠ«éœ²AIè¾…åŠ©(AI assistance)ï¼Œä½†æŠ«éœ²å¾€å¾€ä¼šå¸¦æ¥å£°èª‰æˆæœ¬ï¼Œä»è€Œå¯¼è‡´ä½œè€…å€¾å‘äºä¿æŒä¸é€æ˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œç”±äºæ½œåœ¨çš„å£°èª‰ç»æµ(prestige economy)å¥–åŠ±ä¸é€æ˜æ€§ï¼Œä¼ ç»Ÿå‘è¡¨æ¸ é“æ— æ³•ä»…é€šè¿‡æ”¿ç­–è°ƒæ•´æ¥è§£å†³è¿™ä¸€ç´§å¼ å…³ç³»ã€‚ä¸ºæ­¤ï¼Œæ–‡ç« æå‡ºäº†ä¸€ç§æ›¿ä»£æ€§çš„å‡ºç‰ˆåŸºç¡€è®¾æ–½ï¼Œå³å»ºç«‹ä¸€ä¸ªå¤„äºå£°èª‰ç³»ç»Ÿä¹‹å¤–çš„å¹³å°ï¼Œå¼ºåˆ¶æ‰§è¡ŒæŠ«éœ²è¦æ±‚ï¼Œæ”¯æŒåŸºäºå¤ç°çš„å®¡æŸ¥(reproduction-based review)ï¼Œå¹¶é€šè¿‡è¯¦ç»†æ–‡æ¡£æ”¯æŒç”Ÿæ€æ•ˆåº¦ã€‚ä½œä¸ºè¯¥æ–¹æ³•çš„æ¼”ç¤ºï¼Œæœ¬æ–‡æœ¬èº«å³ä½œä¸ºä¸€ä¸ªåŒ…å«è¯¦ç»†æŠ«éœ²ï¼ˆå¦‚ä»£è¡¨æ€§çš„prompt logså’Œä¿®æ”¹è®°å½•ï¼‰çš„AIè¾…åŠ©å­¦æœ¯ç ”ç©¶èŒƒä¾‹å‘ˆç°ã€‚è¯¥ç ”ç©¶å¹¶éæ—¨åœ¨æ”¯æŒæˆ–åå¯¹AIè¾…åŠ©çš„å­¦æœ¯ç ”ç©¶ï¼Œè€Œæ˜¯æ¦‚è¿°äº†é€šè¿‡é€æ˜æ–‡æ¡£ã€ä»¥éªŒè¯ä¸ºå¯¼å‘çš„å®¡æŸ¥ä»¥åŠæ–¹æ³•è®ºæ‰¿è¯ºæ¥è¯„ä¼°æ­¤ç±»å·¥ä½œçš„æ¡ä»¶ã€‚è¿™ä¸€æ¡†æ¶ä¸ä»…å…³æ³¨AIï¼Œä¹Ÿæ¢è®¨äº†å­¦æœ¯ç³»ç»Ÿå¦‚ä½•å¤„ç†æ–¹æ³•è®ºåˆ›æ–°(methodological innovation)çš„æ›´å¹¿æ³›é—®é¢˜ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CY",
      "comment": "44 pages (30 Article + 14 Appendix); 2 figures Transparency material documenting LLM usage available at: https://github.com/MicheleLoi/JPEP/tree/main/transparency/Canonical_MD",
      "pdf_url": "https://arxiv.org/pdf/2511.08639v2",
      "published_date": "2025-11-10 08:56:21 UTC",
      "updated_date": "2026-01-06 17:29:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:12:14.100246+00:00"
    },
    {
      "arxiv_id": "2511.06853v1",
      "title": "Deep learning EPI-TIRF cross-modality enables background subtraction and axial super-resolution for widefield fluorescence microscopy",
      "title_zh": "æ·±åº¦å­¦ä¹  EPI-TIRF è·¨æ¨¡æ€å®ç°å®½åœºè§å…‰æ˜¾å¾®é•œçš„èƒŒæ™¯æ‰£é™¤ä¸è½´å‘è¶…åˆ†è¾¨ç‡",
      "authors": [
        "Qiushi Li",
        "Celi Lou",
        "Yanfang Cheng",
        "Bilang Gong",
        "Xinlin Chen",
        "Hao Chen",
        "Baowan Li",
        "Jieli Wang",
        "Yulin Wang",
        "Sipeng Yang",
        "Yunqing Tang",
        "Luru Dai"
      ],
      "abstract": "The resolving ability of wide-field fluorescence microscopy is fundamentally limited by out-of-focus background owing to its low axial resolution, particularly for densely labeled biological samples. To address this, we developed ET2dNet, a deep learning-based EPI-TIRF cross-modality network that achieves TIRF-comparable background subtraction and axial super-resolution from a single wide-field image without requiring hardware modifications. The model employs a physics-informed hybrid architecture, synergizing supervised learning with registered EPI-TIRF image pairs and self-supervised physical modeling via convolution with the point spread function. This framework ensures exceptional generalization across microscope objectives, enabling few-shot adaptation to new imaging setups. Rigorous validation on cellular and tissue samples confirms ET2dNet's superiority in background suppression and axial resolution enhancement, while maintaining compatibility with deconvolution techniques for lateral resolution improvement. Furthermore, by extending this paradigm through knowledge distillation, we developed ET3dNet, a dedicated three-dimensional reconstruction network that produces artifact-reduced volumetric results. ET3dNet effectively removes out-of-focus background signals even when the input image stack lacks the source of background. This framework makes axial super-resolution imaging more accessible by providing an easy-to-deploy algorithm that avoids additional hardware costs and complexity, showing great potential for live cell studies and clinical histopathology.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å®½åœºè§å…‰æ˜¾å¾®é•œ(wide-field fluorescence microscopy)å› è½´å‘åˆ†è¾¨ç‡ä½å¯¼è‡´çš„èƒŒæ™¯å¤±ç„¦é—®é¢˜ï¼Œå¼€å‘äº†ET2dNetï¼Œä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„EPI-TIRFè·¨æ¨¡æ€ç½‘ç»œã€‚è¯¥æ¨¡å‹æ— éœ€ç¡¬ä»¶ä¿®æ”¹ï¼Œå³å¯ä»å•å¼ å®½åœºå›¾åƒä¸­å®ç°åª²ç¾TIRFçš„èƒŒæ™¯æ‰£é™¤å’Œè½´å‘è¶…åˆ†è¾¨ç‡(axial super-resolution)ã€‚å…¶æ ¸å¿ƒé‡‡ç”¨ç‰©ç†ä¿¡æ¯çš„æ··åˆæ¶æ„ï¼ŒååŒäº†åŸºäºé…å‡†EPI-TIRFå›¾åƒå¯¹çš„ç›‘ç£å­¦ä¹ ä¸é€šè¿‡ç‚¹æ‰©æ•£å‡½æ•°(PSF)å·ç§¯çš„è‡ªç›‘ç£ç‰©ç†å»ºæ¨¡ï¼Œç¡®ä¿äº†åœ¨ä¸åŒç‰©é•œä¸‹çš„å‡ºè‰²æ³›åŒ–èƒ½åŠ›åŠå°‘æ ·æœ¬é€‚åº”(few-shot adaptation)ã€‚å®éªŒè¯å®ï¼ŒET2dNetåœ¨ç»†èƒå’Œç»„ç»‡æ ·æœ¬ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå¹¶å…¼å®¹å»å·ç§¯æŠ€æœ¯ä»¥æå‡æ¨ªå‘åˆ†è¾¨ç‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶äººå‘˜é€šè¿‡çŸ¥è¯†è’¸é¦(knowledge distillation)è¿›ä¸€æ­¥å¼€å‘äº†ET3dNetï¼Œè¿™æ˜¯ä¸€ç§ä¸“ç”¨çš„ä¸‰ç»´é‡å»ºç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆå»é™¤éç„¦å¹³é¢èƒŒæ™¯ä¿¡å·å¹¶ç”Ÿæˆä¼ªå½±å‡å°‘çš„ä½“ç§¯ç»“æœã€‚è¯¥æ¡†æ¶é€šè¿‡æä¾›ä¸€ç§æ— éœ€é¢å¤–ç¡¬ä»¶æˆæœ¬ä¸”æ˜“äºéƒ¨ç½²çš„ç®—æ³•ï¼Œæ˜¾è‘—é™ä½äº†è½´å‘è¶…åˆ†è¾¨ç‡æˆåƒçš„é—¨æ§›ï¼Œåœ¨æ´»ç»†èƒç ”ç©¶å’Œä¸´åºŠç»„ç»‡ç—…ç†å­¦åº”ç”¨ä¸­å±•ç°äº†å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06853v1",
      "published_date": "2025-11-10 08:52:56 UTC",
      "updated_date": "2025-11-10 08:52:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:12:48.541051+00:00"
    },
    {
      "arxiv_id": "2511.06852v4",
      "title": "Differentiated Directional Intervention A Framework for Evading LLM Safety Alignment",
      "title_zh": "å·®å¼‚åŒ–æ–¹å‘å¹²é¢„ï¼šä¸€ç§è§„é¿LLMå®‰å…¨å¯¹é½çš„æ¡†æ¶",
      "authors": [
        "Peng Zhang",
        "Peijie Sun"
      ],
      "abstract": "Safety alignment instills in Large Language Models (LLMs) a critical capacity to refuse malicious requests. Prior works have modeled this refusal mechanism as a single linear direction in the activation space. We posit that this is an oversimplification that conflates two functionally distinct neural processes: the detection of harm and the execution of a refusal. In this work, we deconstruct this single representation into a Harm Detection Direction and a Refusal Execution Direction. Leveraging this fine-grained model, we introduce Differentiated Bi-Directional Intervention (DBDI), a new white-box framework that precisely neutralizes the safety alignment at critical layer. DBDI applies adaptive projection nullification to the refusal execution direction while suppressing the harm detection direction via direct steering. Extensive experiments demonstrate that DBDI outperforms prominent jailbreaking methods, achieving up to a 97.88\\% attack success rate on models such as Llama-2. By providing a more granular and mechanistic framework, our work offers a new direction for the in-depth understanding of LLM safety alignment.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰å·¥ä½œå°†å¤§è¯­è¨€æ¨¡å‹(LLMs)çš„æ‹’ç»æœºåˆ¶ç®€åŒ–ä¸ºæ¿€æ´»ç©ºé—´ä¸­å•ä¸€çº¿æ€§æ–¹å‘çš„é—®é¢˜ï¼Œæå‡ºå®‰å…¨å¯¹é½å®é™…ä¸ŠåŒ…å«æœ‰å®³æ€§æ£€æµ‹(Harm Detection)å’Œæ‹’ç»æ‰§è¡Œ(Refusal Execution)ä¸¤ä¸ªåŠŸèƒ½ç‹¬ç‰¹çš„ç¥ç»è¿‡ç¨‹ã€‚åŸºäºæ­¤å‘ç°ï¼Œä½œè€…å¼•å…¥äº†å·®å¼‚åŒ–åŒå‘å¹²é¢„(Differentiated Bi-Directional Intervention, DBDI)è¿™ä¸€ç™½ç›’æ¡†æ¶ï¼Œæ—¨åœ¨å…³é”®å±‚ç²¾ç¡®ä¸­å’Œå®‰å…¨å¯¹é½æœºåˆ¶ã€‚DBDIé€šè¿‡å¯¹æ‹’ç»æ‰§è¡Œæ–¹å‘åº”ç”¨è‡ªé€‚åº”æŠ•å½±æ— æ•ˆåŒ–ï¼Œå¹¶é€šè¿‡ç›´æ¥å¼•å¯¼(direct steering)æŠ‘åˆ¶æœ‰å®³æ€§æ£€æµ‹æ–¹å‘ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼ŒDBDIä¼˜äºä¸»æµçš„è¶Šç‹±(jailbreaking)æ–¹æ³•ï¼Œåœ¨Llama-2ç­‰æ¨¡å‹ä¸Šå®ç°äº†é«˜è¾¾97.88%çš„æ”»å‡»æˆåŠŸç‡ã€‚è¯¥å·¥ä½œé€šè¿‡æä¾›æ›´ç»†ç²’åº¦çš„æœºåˆ¶æ¡†æ¶ï¼Œä¸ºæ·±å…¥ç†è§£å’Œè¯„ä¼°LLMçš„å®‰å…¨å¯¹é½æä¾›äº†æ–°çš„æ–¹å‘ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "AAAI-26-AIA",
      "pdf_url": "https://arxiv.org/pdf/2511.06852v4",
      "published_date": "2025-11-10 08:52:34 UTC",
      "updated_date": "2025-11-24 11:44:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:13:09.037173+00:00"
    },
    {
      "arxiv_id": "2511.11647v1",
      "title": "Environment-Aware Transfer Reinforcement Learning for Sustainable Beam Selection",
      "title_zh": "é¢å‘å¯æŒç»­æ³¢æŸé€‰æ‹©çš„ç¯å¢ƒæ„ŸçŸ¥è¿ç§»å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Dariush Salami",
        "Ramin Hashemi",
        "Parham Kazemi",
        "Mikko A. Uusitalo"
      ],
      "abstract": "This paper presents a novel and sustainable approach for improving beam selection in 5G and beyond networks using transfer learning and Reinforcement Learning (RL). Traditional RL-based beam selection models require extensive training time and computational resources, particularly when deployed in diverse environments with varying propagation characteristics posing a major challenge for scalability and energy efficiency. To address this, we propose modeling the environment as a point cloud, where each point represents the locations of gNodeBs (gNBs) and surrounding scatterers. By computing the Chamfer distance between point clouds, structurally similar environments can be efficiently identified, enabling the reuse of pre-trained models through transfer learning. This methodology leads to a 16x reduction in training time and computational overhead, directly contributing to energy efficiency. By minimizing the need for retraining in each new deployment, our approach significantly lowers power consumption and supports the development of green and sustainable Artificial Intelligence (AI) in wireless systems. Furthermore, it accelerates time-to-deployment, reduces carbon emissions associated with training, and enhances the viability of deploying AI-driven communication systems at the edge. Simulation results confirm that our approach maintains high performance while drastically cutting energy costs, demonstrating the potential of transfer learning to enable scalable, adaptive, and environmentally conscious RL-based beam selection strategies in dynamic and diverse propagation environments.",
      "tldr_zh": "è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§ç»“åˆè¿ç§»å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning, RL)çš„ç¯å¢ƒæ„ŸçŸ¥æ–¹æ³•ï¼Œæ—¨åœ¨ä¼˜åŒ–5GåŠæœªæ¥ç½‘ç»œä¸­çš„æ³¢æŸé€‰æ‹©(Beam Selection)å¹¶å®ç°å¯æŒç»­æ€§ã€‚é’ˆå¯¹ä¼ ç»ŸRLæ¨¡å‹åœ¨å¤šå˜ç¯å¢ƒä¸­é¢ä¸´çš„è®­ç»ƒæ—¶é—´é•¿å’Œè®¡ç®—èµ„æºæ¶ˆè€—å¤§çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…æå‡ºå°†ç¯å¢ƒå»ºæ¨¡ä¸ºåŒ…å«gNodeBså’Œæ•£å°„ä½“ä½ç½®çš„ç‚¹äº‘(Point Cloud)ã€‚é€šè¿‡è®¡ç®—å€’è§’è·ç¦»(Chamfer Distance)è¯†åˆ«ç»“æ„ç›¸ä¼¼çš„ç¯å¢ƒï¼Œè¯¥æ–¹æ³•èƒ½å¤Ÿåˆ©ç”¨è¿ç§»å­¦ä¹ é«˜æ•ˆé‡ç”¨é¢„è®­ç»ƒæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•å°†è®­ç»ƒæ—¶é—´å’Œè®¡ç®—å¼€é”€å‡å°‘äº†16å€ï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶æ˜¾è‘—é™ä½äº†èƒ½æºæ¶ˆè€—å’Œç¢³æ’æ”¾ã€‚è¯¥ç ”ç©¶é€šè¿‡å‡å°‘é‡æ–°è®­ç»ƒçš„éœ€æ±‚ï¼ŒåŠ é€Ÿäº†éƒ¨ç½²é€Ÿåº¦ï¼Œä¸ºæ— çº¿ç³»ç»Ÿä¸­å®ç°ç»¿è‰²ã€å¯æ‰©å±•ä¸”è‡ªé€‚åº”çš„è¾¹ç¼˜AIé€šä¿¡ç³»ç»Ÿæä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to be published in a workshop in IEEE GLOBECOM 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.11647v1",
      "published_date": "2025-11-10 08:50:05 UTC",
      "updated_date": "2025-11-10 08:50:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:14:03.005534+00:00"
    },
    {
      "arxiv_id": "2511.11646v2",
      "title": "What-If Decision Support for Product Line Extension Using Conditional Deep Generative Models",
      "title_zh": "åŸºäºæ¡ä»¶æ·±åº¦ç”Ÿæˆæ¨¡å‹çš„äº§å“çº¿å»¶ä¼¸å‡è®¾åˆ†æå†³ç­–æ”¯æŒ",
      "authors": [
        "Yinxing Li",
        "Tsukasa Ishigaki"
      ],
      "abstract": "Product line extension is a strategically important managerial decision that requires anticipating how consumer segments and purchasing contexts may respond to hypothetical product designs that do not yet exist in the market. Such decisions are inherently uncertain because managers must infer future outcomes from historical purchase data without direct market observations. This study addresses this challenge by proposing a data-driven decision support framework that enables forward-looking what-if analysis based on historical transaction data. We introduce a Conditional Tabular Variational Autoencoder (CTVAE) that learns the conditional joint distribution of product attributes and consumer characteristics from large-scale tabular data. By conditioning the generative process on controllable design variables such as container type, volume, flavor, and calorie content, the proposed model generates synthetic consumer attribute distributions for hypothetical line-extended products. This enables systematic exploration of alternative design scenarios without costly market pretests. The framework is evaluated using home-scan panel data covering more than 20,000 consumers and 700 soft drink products. Empirical results show that the CTVAE outperforms existing tabular generative models in capturing conditional consumer attribute distributions. Simulation-based analyses further demonstrate that the generated synthetic data support knowledge-driven reasoning for assessing cannibalization risks and identifying potential target segments. These findings highlight the value of conditional deep generative models as core components of decision support systems for product line extension planning.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹äº§å“çº¿æ‰©å±•å†³ç­–ä¸­é¢„æµ‹æ¶ˆè´¹è€…å¯¹å‡è®¾äº§å“ååº”çš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå†å²äº¤æ˜“æ•°æ®çš„å‰ç»æ€§å†³ç­–æ”¯æŒæ¡†æ¶ã€‚æ ¸å¿ƒæ–¹æ³•å¼•å…¥äº†æ¡ä»¶è¡¨æ ¼å˜åˆ†è‡ªç¼–ç å™¨ï¼ˆCTVAEï¼‰ï¼Œè¯¥æ¨¡å‹é€šè¿‡ä»å¤§è§„æ¨¡è¡¨æ ¼æ•°æ®ä¸­å­¦ä¹ äº§å“å±æ€§ä¸æ¶ˆè´¹è€…ç‰¹å¾çš„æ¡ä»¶è”åˆåˆ†å¸ƒï¼Œå®ç°äº†é’ˆå¯¹å‡è®¾äº§å“çš„åˆæˆæ¶ˆè´¹è€…å±æ€§ç”Ÿæˆã€‚é€šè¿‡æ§åˆ¶å®¹å™¨ç±»å‹ã€å®¹é‡ã€å£å‘³ç­‰è®¾è®¡å˜é‡ï¼Œè¯¥æ¡†æ¶å…è®¸ç®¡ç†è€…åœ¨æ— éœ€æ˜‚è´µå¸‚åœºé¢„æµ‹è¯•çš„æƒ…å†µä¸‹è¿›è¡Œç³»ç»Ÿçš„â€œwhat-ifâ€åˆ†æã€‚åŸºäºè¶…è¿‡20,000åæ¶ˆè´¹è€…å’Œ700ç§è½¯é¥®æ–™äº§å“çš„å®è¯è¯„ä¼°è¡¨æ˜ï¼ŒCTVAEåœ¨æ•æ‰æ¡ä»¶åˆ†å¸ƒæ–¹é¢ä¼˜äºç°æœ‰çš„è¡¨æ ¼ç”Ÿæˆæ¨¡å‹ã€‚æ¨¡æ‹Ÿåˆ†æè¿›ä¸€æ­¥è¯å®ï¼Œç”Ÿæˆçš„åˆæˆæ•°æ®èƒ½å¤Ÿæœ‰æ•ˆæ”¯æŒè¯„ä¼°åŒç±»ç›¸é£Ÿï¼ˆcannibalizationï¼‰é£é™©åŠè¯†åˆ«æ½œåœ¨ç›®æ ‡ç»†åˆ†å¸‚åœºï¼Œçªæ˜¾äº†æ¡ä»¶æ·±åº¦ç”Ÿæˆæ¨¡å‹åœ¨äº§å“çº¿æ‰©å±•è§„åˆ’ä¸­çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages",
      "pdf_url": "https://arxiv.org/pdf/2511.11646v2",
      "published_date": "2025-11-10 08:50:03 UTC",
      "updated_date": "2025-12-22 10:22:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:14:41.642134+00:00"
    },
    {
      "arxiv_id": "2511.06836v1",
      "title": "NeuroBridge: Bio-Inspired Self-Supervised EEG-to-Image Decoding via Cognitive Priors and Bidirectional Semantic Alignment",
      "title_zh": "NeuroBridgeï¼šåŸºäºè®¤çŸ¥å…ˆéªŒä¸åŒå‘è¯­ä¹‰å¯¹é½çš„ç”Ÿç‰©å¯å‘å¼è‡ªç›‘ç£EEGåˆ°å›¾åƒè§£ç ",
      "authors": [
        "Wenjiang Zhang",
        "Sifeng Wang",
        "Yuwei Su",
        "Xinyu Li",
        "Chen Zhang",
        "Suyu Zhong"
      ],
      "abstract": "Visual neural decoding seeks to reconstruct or infer perceived visual stimuli from brain activity patterns, providing critical insights into human cognition and enabling transformative applications in brain-computer interfaces and artificial intelligence. Current approaches, however, remain constrained by the scarcity of high-quality stimulus-brain response pairs and the inherent semantic mismatch between neural representations and visual content. Inspired by perceptual variability and co-adaptive strategy of the biological systems, we propose a novel self-supervised architecture, named NeuroBridge, which integrates Cognitive Prior Augmentation (CPA) with Shared Semantic Projector (SSP) to promote effective cross-modality alignment. Specifically, CPA simulates perceptual variability by applying asymmetric, modality-specific transformations to both EEG signals and images, enhancing semantic diversity. Unlike previous approaches, SSP establishes a bidirectional alignment process through a co-adaptive strategy, which mutually aligns features from two modalities into a shared semantic space for effective cross-modal learning. NeuroBridge surpasses previous state-of-the-art methods under both intra-subject and inter-subject settings. In the intra-subject scenario, it achieves the improvements of 12.3% in top-1 accuracy and 10.2% in top-5 accuracy, reaching 63.2% and 89.9% respectively on a 200-way zero-shot retrieval task. Extensive experiments demonstrate the effectiveness, robustness, and scalability of the proposed framework for neural visual decoding.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†NeuroBridgeï¼Œä¸€ç§å—ç”Ÿç‰©å­¦å¯å‘çš„è‡ªç›‘ç£æ¶æ„ï¼Œæ—¨åœ¨è§£å†³è§†è§‰ç¥ç»è§£ç ä¸­é«˜è´¨é‡æ•°æ®ç¨€ç¼ºå’Œç¥ç»-è§†è§‰è¯­ä¹‰ä¸åŒ¹é…çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶ç»“åˆäº†è®¤çŸ¥å…ˆéªŒå¢å¼º(Cognitive Prior Augmentation, CPA)å’Œå…±äº«è¯­ä¹‰æŠ•å½±å™¨(Shared Semantic Projector, SSP)ä»¥ä¿ƒè¿›æœ‰æ•ˆçš„è·¨æ¨¡æ€å¯¹é½ã€‚å…·ä½“è€Œè¨€ï¼ŒCPAé€šè¿‡å¯¹EEGä¿¡å·å’Œå›¾åƒåº”ç”¨éå¯¹ç§°å˜æ¢æ¥æ¨¡æ‹Ÿæ„ŸçŸ¥å˜å¼‚æ€§ï¼Œä»è€Œå¢å¼ºè¯­ä¹‰å¤šæ ·æ€§ï¼›è€ŒSSPåˆ™é€šè¿‡å…±é€‚åº”ç­–ç•¥å»ºç«‹åŒå‘å¯¹é½è¿‡ç¨‹ï¼Œå°†ä¸¤ç§æ¨¡æ€çš„ç‰¹å¾æ˜ å°„åˆ°å…±äº«è¯­ä¹‰ç©ºé—´ä¸­ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒNeuroBridgeåœ¨å—è¯•è€…å†…éƒ¨å’Œå—è¯•è€…é—´è®¾ç½®ä¸‹å‡è¶…è¶Šäº†ç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨å—è¯•è€…å†…éƒ¨åœºæ™¯ä¸­ï¼Œå…¶åœ¨200ç±»é›¶æ ·æœ¬æ£€ç´¢ä»»åŠ¡ä¸Šçš„Top-1å‡†ç¡®ç‡æé«˜äº†12.3%ï¼ˆè¾¾åˆ°63.2%ï¼‰ï¼ŒTop-5å‡†ç¡®ç‡æé«˜äº†10.2%ï¼ˆè¾¾åˆ°89.9%ï¼‰ï¼Œå……åˆ†è¯æ˜äº†è¯¥æ¡†æ¶åœ¨ç¥ç»è§†è§‰è§£ç æ–¹é¢çš„æœ‰æ•ˆæ€§ã€é²æ£’æ€§å’Œå¯æ‰©å±•æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06836v1",
      "published_date": "2025-11-10 08:29:09 UTC",
      "updated_date": "2025-11-10 08:29:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:15:05.718751+00:00"
    },
    {
      "arxiv_id": "2511.06831v2",
      "title": "DeepRWCap: Neural-Guided Random-Walk Capacitance Solver for IC Design",
      "title_zh": "DeepRWCapï¼šé¢å‘é›†æˆç”µè·¯è®¾è®¡çš„ç¥ç»å¼•å¯¼éšæœºæ¸¸èµ°ç”µå®¹æ±‚è§£å™¨",
      "authors": [
        "Hector R. Rodriguez",
        "Jiechen Huang",
        "Wenjian Yu"
      ],
      "abstract": "Monte Carlo random walk methods are widely used in capacitance extraction for their mesh free formulation and inherent parallelism. However, modern semiconductor technologies with densely packed structures present significant challenges in unbiasedly sampling transition domains in walk steps with multiple high contrast dielectric materials. We present DeepRWCap, a machine learning guided random walk solver that predicts the transition quantities required to guide each step of the walk. These include Poisson kernels, gradient kernels, and the signs and magnitudes of weights. DeepRWCap employs a two stage neural architecture that decomposes structured outputs into face wise distributions and spatial kernels on cube faces. It uses 3D convolutional networks to capture volumetric dielectric interactions and 2D depthwise separable convolutions to model localized kernel behavior. The design incorporates grid based positional encodings and structural design choices informed by cube symmetries to reduce learning redundancy and improve generalization. Trained on 100000 procedurally generated dielectric configurations, DeepRWCap achieves a mean relative error of 1.24 +/- 0.53% when benchmarked against the commercial Raphael solver on the self capacitance estimation of 10 industrial designs spanning 12 to 55 nm nodes. Compared to the state of the art stochastic difference method Microwalk, DeepRWCap achieves an average speedup of 23%. On complex designs with runtimes over 10 seconds, it reaches an average acceleration of 49%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeepRWCapï¼Œä¸€ç§ç”¨äºé›†æˆç”µè·¯(IC)è®¾è®¡çš„ç¥ç»å¼•å¯¼éšæœºæ¸¸èµ°ç”µå®¹æ±‚è§£å™¨ï¼Œæ—¨åœ¨è§£å†³ç°ä»£åŠå¯¼ä½“æŠ€æœ¯ä¸­é«˜å¯¹æ¯”åº¦ä»‹ç”µææ–™å¸¦æ¥çš„é‡‡æ ·éš¾é¢˜ã€‚DeepRWCapåˆ©ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹éšæœºæ¸¸èµ°æ¯ä¸€æ­¥æ‰€éœ€çš„è¿‡æ¸¡é‡ï¼ŒåŒ…æ‹¬Poisson kernelsã€gradient kernelsä»¥åŠæƒé‡çš„ç¬¦å·å’Œå¹…åº¦ã€‚è¯¥æ¨¡å‹é‡‡ç”¨ä¸¤é˜¶æ®µç¥ç»æ¶æ„ï¼Œç»“åˆ3Då·ç§¯ç½‘ç»œæ•æ‰ä½“ç§¯ä»‹ç”µç›¸äº’ä½œç”¨ï¼Œå¹¶åˆ©ç”¨2Dæ·±åº¦å¯åˆ†ç¦»å·ç§¯æ¨¡æ‹Ÿå±€éƒ¨æ ¸è¡Œä¸ºï¼ŒåŒæ—¶åˆ©ç”¨ç½‘æ ¼ä½ç½®ç¼–ç å’Œç«‹æ–¹ä½“å¯¹ç§°æ€§æé«˜æ³›åŒ–èƒ½åŠ›ã€‚åœ¨100,000ä¸ªç¨‹åºç”Ÿæˆçš„é…ç½®ä¸Šè®­ç»ƒåï¼ŒDeepRWCapåœ¨æ¶µç›–12è‡³55 nmèŠ‚ç‚¹çš„10ä¸ªå·¥ä¸šè®¾è®¡ä¸Šï¼Œç›¸å¯¹äºå•†ä¸šRaphaelæ±‚è§£å™¨å®ç°äº†1.24% +/- 0.53%çš„å¹³å‡ç›¸å¯¹è¯¯å·®ã€‚ä¸æœ€å…ˆè¿›çš„éšæœºå·®åˆ†æ–¹æ³•Microwalkç›¸æ¯”ï¼Œè¯¥æ–¹æ³•å®ç°äº†23%çš„å¹³å‡åŠ é€Ÿï¼Œä¸”åœ¨è¿è¡Œæ—¶é—´è¶…è¿‡10ç§’çš„å¤æ‚è®¾è®¡ä¸Šå¹³å‡åŠ é€Ÿè¾¾åˆ°49%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI-26",
      "pdf_url": "https://arxiv.org/pdf/2511.06831v2",
      "published_date": "2025-11-10 08:25:13 UTC",
      "updated_date": "2025-11-23 09:20:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:15:30.880646+00:00"
    },
    {
      "arxiv_id": "2511.06826v1",
      "title": "Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection",
      "title_zh": "è¶…è¶Šæœ´ç´ ç¤ºä¾‹ï¼šé˜¿å°”èŒ¨æµ·é»˜ç—…æ£€æµ‹ä¸­ä¸Šä¸‹æ–‡å­¦ä¹ çš„ä»¥ç¤ºä¾‹ä¸ºä¸­å¿ƒé”šå®šèŒƒå¼",
      "authors": [
        "Puzhen Su",
        "Haoran Yin",
        "Yongzhu Miao",
        "Jintao Tang",
        "Shasha Li",
        "Ting Wang"
      ],
      "abstract": "Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \\textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \\emph{\\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \\emph{\\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä»å™è¿°æ–‡æœ¬ä¸­æ£€æµ‹é˜¿å°”èŒ¨æµ·é»˜ç—…(AD)æ—¶é¢ä¸´çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºé¢„è®­ç»ƒæ¨¡å‹ç¼ºä¹ç›¸å…³ä»»åŠ¡è®¤çŸ¥ä¸”ç°æœ‰æ¼”ç¤ºæ ·æœ¬åŒè´¨åŒ–ä¸¥é‡ã€‚ä¼ ç»Ÿçš„ä¸Šä¸‹æ–‡å­¦ä¹ (ICL)å®¹æ˜“é¥±å’Œä¸”ç¼ºä¹æ·±åº¦ï¼Œè€Œç°æœ‰çš„ä»»åŠ¡å‘é‡(Task Vector)æ–¹æ³•å› æ³¨å…¥ç²’åº¦ä¸åŒ¹é…è€Œä¸é€‚ç”¨äºæ­¤ç±»æ£€æµ‹ä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†DA4ICLï¼Œä¸€ç§ä»¥æ¼”ç¤ºä¸ºä¸­å¿ƒçš„é”šå®šæ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡**Diverse and Contrastive Retrieval (DCR)** è”åˆæ‰©å±•ä¸Šä¸‹æ–‡å®½åº¦ï¼Œå¹¶åˆ©ç”¨**Projected Vector Anchoring (PVA)** åœ¨æ¯ä¸ªTransformerå±‚åŠ æ·±æ¼”ç¤ºä¿¡å·çš„æ·±åº¦ã€‚åœ¨ä¸‰ä¸ªADåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒDA4ICLå–å¾—äº†æ¯”ICLå’ŒTVåŸºçº¿æ›´æ˜¾è‘—ä¸”ç¨³å®šçš„æ€§èƒ½æå‡ï¼Œä¸ºç»†ç²’åº¦ã€åˆ†å¸ƒå¤–(OOD)å’Œä½èµ„æºç¯å¢ƒä¸‹çš„LLMé€‚åº”ç¡®ç«‹äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the 40th Annual AAAI Conference on Artificial Intelligence (2026) - Main Technical Track (Oral)",
      "pdf_url": "https://arxiv.org/pdf/2511.06826v1",
      "published_date": "2025-11-10 08:13:42 UTC",
      "updated_date": "2025-11-10 08:13:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:18:45.044207+00:00"
    },
    {
      "arxiv_id": "2511.10675v1",
      "title": "Learn to Select: Exploring Label Distribution Divergence for In-Context Demonstration Selection in Text Classification",
      "title_zh": "å­¦ä¼šé€‰æ‹©ï¼šæ¢ç´¢æ–‡æœ¬åˆ†ç±»ä¸­ç”¨äºä¸Šä¸‹æ–‡ç¤ºä¾‹é€‰æ‹©çš„æ ‡ç­¾åˆ†å¸ƒæ•£åº¦",
      "authors": [
        "Ye Jiang",
        "Taihang Wang",
        "Youzheng Liu",
        "Yimin Wang",
        "Yuhan Xia",
        "Yunfei Long"
      ],
      "abstract": "In-context learning (ICL) for text classification, which uses a few input-label demonstrations to describe a task, has demonstrated impressive performance on large language models (LLMs). However, the selection of in-context demonstrations plays a crucial role and can significantly affect LLMs' performance. Most existing demonstration selection methods primarily focus on semantic similarity between test inputs and demonstrations, often overlooking the importance of label distribution alignment. To address this limitation, we propose a two-stage demonstration selection method, TopK + Label Distribution Divergence (L2D), which leverages a fine-tuned BERT-like small language model (SLM) to generate label distributions and calculate their divergence for both test inputs and candidate demonstrations. This enables the selection of demonstrations that are not only semantically similar but also aligned in label distribution with the test input. Extensive experiments across seven text classification benchmarks show that our method consistently outperforms previous demonstration selection strategies. Further analysis reveals a positive correlation between the performance of LLMs and the accuracy of the underlying SLMs used for label distribution estimation.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­çš„ä¸Šä¸‹æ–‡å­¦ä¹ (In-context learning, ICL)æ¼”ç¤ºé€‰æ‹©é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰æ–¹æ³•å¤§å¤šä»…å…³æ³¨è¯­ä¹‰ç›¸ä¼¼åº¦è€Œå¿½ç•¥æ ‡ç­¾åˆ†å¸ƒå¯¹é½çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºTopK + Label Distribution Divergence (L2D)çš„ä¸¤é˜¶æ®µæ¼”ç¤ºé€‰æ‹©æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨å¾®è°ƒåçš„BERT-likeå°è¯­è¨€æ¨¡å‹(SLM)ç”Ÿæˆæ ‡ç­¾åˆ†å¸ƒï¼Œå¹¶è®¡ç®—æµ‹è¯•è¾“å…¥ä¸å€™é€‰æ¼”ç¤ºä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ï¼Œä»è€Œç­›é€‰å‡ºæ—¢åœ¨è¯­ä¹‰ä¸Šç›¸ä¼¼åˆåœ¨æ ‡ç­¾åˆ†å¸ƒä¸Šå¯¹é½çš„æ¼”ç¤ºã€‚åœ¨ä¸ƒä¸ªæ–‡æœ¬åˆ†ç±»åŸºå‡†ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•è¡¨ç°ä¸€è‡´ä¼˜äºç°æœ‰çš„æ¼”ç¤ºé€‰æ‹©ç­–ç•¥ã€‚è¿›ä¸€æ­¥åˆ†æè¿˜æ­ç¤ºäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çš„æ€§èƒ½ä¸ç”¨äºä¼°è®¡æ ‡ç­¾åˆ†å¸ƒçš„SLMçš„å‡†ç¡®æ€§ä¹‹é—´å­˜åœ¨æ­£ç›¸å…³å…³ç³»ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.10675v1",
      "published_date": "2025-11-10 08:04:14 UTC",
      "updated_date": "2025-11-10 08:04:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:19:23.948687+00:00"
    },
    {
      "arxiv_id": "2511.06817v3",
      "title": "TiS-TSL: Image-Label Supervised Surgical Video Stereo Matching via Time-Switchable Teacher-Student Learning",
      "title_zh": "TiS-TSLï¼šåŸºäºæ—¶é—´å¯åˆ‡æ¢æ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ çš„å›¾åƒæ ‡ç­¾ç›‘ç£æ‰‹æœ¯è§†é¢‘ç«‹ä½“åŒ¹é…",
      "authors": [
        "Rui Wang",
        "Ying Zhou",
        "Hao Wang",
        "Wenwei Zhang",
        "Qiang Li",
        "Zhiwei Wang"
      ],
      "abstract": "Stereo matching in minimally invasive surgery (MIS) is essential for next-generation navigation and augmented reality. Yet, dense disparity supervision is nearly impossible due to anatomical constraints, typically limiting annotations to only a few image-level labels acquired before the endoscope enters deep body cavities. Teacher-Student Learning (TSL) offers a promising solution by leveraging a teacher trained on sparse labels to generate pseudo labels and associated confidence maps from abundant unlabeled surgical videos. However, existing TSL methods are confined to image-level supervision, providing only spatial confidence and lacking temporal consistency estimation. This absence of spatio-temporal reliability results in unstable disparity predictions and severe flickering artifacts across video frames. To overcome these challenges, we propose TiS-TSL, a novel time-switchable teacher-student learning framework for video stereo matching under minimal supervision. At its core is a unified model that operates in three distinct modes: Image-Prediction (IP), Forward Video-Prediction (FVP), and Backward Video-Prediction (BVP), enabling flexible temporal modeling within a single architecture. Enabled by this unified model, TiS-TSL adopts a two-stage learning strategy. The Image-to-Video (I2V) stage transfers sparse image-level knowledge to initialize temporal modeling. The subsequent Video-to-Video (V2V) stage refines temporal disparity predictions by comparing forward and backward predictions to calculate bidirectional spatio-temporal consistency. This consistency identifies unreliable regions across frames, filters noisy video-level pseudo labels, and enforces temporal coherence. Experimental results on two public datasets demonstrate that TiS-TSL exceeds other image-based state-of-the-arts by improving TEPE and EPE by at least 2.11% and 4.54%, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¾®åˆ›æ‰‹æœ¯(MIS)ç«‹ä½“åŒ¹é…ä¸­ç¼ºä¹å¯†é›†è§†å·®ç›‘ç£åŠç°æœ‰æ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ (TSL)æ–¹æ³•ç¼ºå¤±æ—¶åºä¸€è‡´æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºTiS-TSLçš„æ—¶é—´å¯åˆ‡æ¢æ•™å¸ˆ-å­¦ç”Ÿå­¦ä¹ æ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªç»Ÿä¸€æ¨¡å‹ï¼Œèƒ½å¤Ÿåœ¨å›¾åƒé¢„æµ‹(IP)ã€å‰å‘è§†é¢‘é¢„æµ‹(FVP)å’Œåå‘è§†é¢‘é¢„æµ‹(BVP)ä¸‰ç§æ¨¡å¼ä¸‹è¿è¡Œï¼Œä»è€Œåœ¨å•ä¸€æ¶æ„å†…å®ç°çµæ´»çš„æ—¶åºå»ºæ¨¡ã€‚TiS-TSLé‡‡ç”¨ä¸¤é˜¶æ®µå­¦ä¹ ç­–ç•¥ï¼Œé¦–å…ˆé€šè¿‡å›¾åƒåˆ°è§†é¢‘(I2V)é˜¶æ®µè¿ç§»ç¨€ç–å›¾åƒçº§çŸ¥è¯†ä»¥åˆå§‹åŒ–æ—¶åºæ¨¡å‹ã€‚éšåçš„è§†é¢‘åˆ°è§†é¢‘(V2V)é˜¶æ®µé€šè¿‡æ¯”è¾ƒå‰å‘å’Œåå‘é¢„æµ‹æ¥è®¡ç®—åŒå‘æ—¶ç©ºä¸€è‡´æ€§ï¼Œä»¥æ­¤è¯†åˆ«ä¸å¯é åŒºåŸŸã€è¿‡æ»¤å™ªå£°ä¼ªæ ‡ç­¾å¹¶å¼ºåˆ¶å®ç°æ—¶åºè¿è´¯æ€§ã€‚åœ¨ä¸¤ä¸ªå…¬å…±æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTiS-TSLè¶…è¶Šäº†å…¶ä»–åŸºäºå›¾åƒçš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œå°†TEPEå’ŒEPEæŒ‡æ ‡åˆ†åˆ«è‡³å°‘æå‡äº†2.11%å’Œ4.54%ï¼Œæœ‰æ•ˆè§£å†³äº†è§†é¢‘å¸§é—´çš„é—ªçƒä¼ªå½±é—®é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06817v3",
      "published_date": "2025-11-10 08:01:26 UTC",
      "updated_date": "2025-11-12 02:36:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:19:31.575243+00:00"
    },
    {
      "arxiv_id": "2511.06816v2",
      "title": "Controllable Flow Matching for Online Reinforcement Learning",
      "title_zh": "é¢å‘åœ¨çº¿å¼ºåŒ–å­¦ä¹ çš„å¯æ§æµåŒ¹é…",
      "authors": [
        "Bin Wang",
        "Boxiang Tao",
        "Haifeng Jing",
        "Hongbo Dou",
        "Zijian Wang"
      ],
      "abstract": "Model-based reinforcement learning (MBRL) typically relies on modeling environment dynamics for data efficiency. However, due to the accumulation of model errors over long-horizon rollouts, such methods often face challenges in maintaining modeling stability. To address this, we propose CtrlFlow, a trajectory-level synthetic method using conditional flow matching (CFM), which directly modeling the distribution of trajectories from initial states to high-return terminal states without explicitly modeling the environment transition function. Our method ensures optimal trajectory sampling by minimizing the control energy governed by the non-linear Controllability Gramian Matrix, while the generated diverse trajectory data significantly enhances the robustness and cross-task generalization of policy learning. In online settings, CtrlFlow demonstrates the better performance on common MuJoCo benchmark tasks than dynamics models and achieves superior sample efficiency compared to standard MBRL methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºæ¨¡å‹çš„å¼ºåŒ–å­¦ä¹ (MBRL)åœ¨é•¿è§†ç•Œæ¨æ¼”ä¸­å› æ¨¡å‹è¯¯å·®ç´¯ç§¯å¯¼è‡´çš„ç¨³å®šæ€§é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºCtrlFlowçš„è½¨è¿¹çº§åˆæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ¡ä»¶æµåŒ¹é…(Conditional Flow Matching, CFM)æŠ€æœ¯ï¼Œç›´æ¥å¯¹ä»åˆå§‹çŠ¶æ€åˆ°é«˜å›æŠ¥ç»ˆæ­¢çŠ¶æ€çš„è½¨è¿¹åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œä»è€Œé¿å…äº†æ˜¾å¼å»ºæ¨¡ç¯å¢ƒè½¬ç§»å‡½æ•°ã€‚CtrlFlowé€šè¿‡æœ€å°åŒ–ç”±éçº¿æ€§å¯æ§æ€§æ ¼æ‹‰å§†çŸ©é˜µ(Controllability Gramian Matrix)æ§åˆ¶çš„æ§åˆ¶èƒ½é‡ï¼Œç¡®ä¿äº†æœ€ä¼˜çš„è½¨è¿¹é‡‡æ ·ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•ç”Ÿæˆçš„å¢å¼ºè½¨è¿¹æ•°æ®æ˜¾è‘—æå‡äº†ç­–ç•¥å­¦ä¹ çš„é²æ£’æ€§å’Œè·¨ä»»åŠ¡æ³›åŒ–èƒ½åŠ›ã€‚åœ¨åœ¨çº¿è®¾ç½®çš„å®éªŒä¸­ï¼ŒCtrlFlowåœ¨MuJoCoåŸºå‡†ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¼˜äºä¼ ç»Ÿçš„åŠ¨åŠ›å­¦æ¨¡å‹ï¼Œå¹¶ä¸”ç›¸æ¯”æ ‡å‡†MBRLæ–¹æ³•å®ç°äº†æ›´ä¼˜è¶Šçš„æ ·æœ¬æ•ˆç‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06816v2",
      "published_date": "2025-11-10 08:01:20 UTC",
      "updated_date": "2026-01-03 11:29:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:20:05.101073+00:00"
    },
    {
      "arxiv_id": "2511.06805v1",
      "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning",
      "title_zh": "MathSEï¼šåŸºäºè‡ªæ¼”åŒ–è¿­ä»£åæ€ä¸å¥–åŠ±å¼•å¯¼å¾®è°ƒçš„å¤šæ¨¡æ€æ•°å­¦æ¨ç†æå‡",
      "authors": [
        "Jinhao Chen",
        "Zhen Yang",
        "Jianxin Shi",
        "Tianyu Wo",
        "Jie Tang"
      ],
      "abstract": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MathSEï¼Œä¸€ç§é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)çš„æ•°å­¦è‡ªæˆ‘è¿›åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨å…‹æœç°æœ‰æ¨¡å‹åœ¨å¤„ç†å¤æ‚æ•°å­¦æ¨ç†ä»»åŠ¡æ—¶çš„å±€é™æ€§ã€‚é’ˆå¯¹ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ä¾èµ–é™æ€æ•™å¸ˆæ¨¡å‹æ•°æ®ã€ç¼ºä¹è¿­ä»£æ·±åº¦å’Œæ³›åŒ–èƒ½åŠ›çš„é—®é¢˜ï¼ŒMathSEé‡‡ç”¨äº†ä¸åŒçš„ç­–ç•¥ã€‚è¯¥æ¡†æ¶é€šè¿‡æ¨ç†ã€åæ€å’ŒåŸºäºå¥–åŠ±çš„åé¦ˆå¾ªç¯ä¸æ–­è¿­ä»£ä¼˜åŒ–æ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒç»“åˆäº†ä»ä¸Šä¸€é˜¶æ®µæ¨ç†ä¸­è·å¾—çš„æ­£ç¡®æ¨ç†è·¯å¾„ï¼Œå¹¶é›†æˆäº†æ¥è‡ªä¸“é—¨çš„ç»“æœå¥–åŠ±æ¨¡å‹(Outcome Reward Model, ORM)çš„åæ€æœºåˆ¶è¿›è¡Œè¿­ä»£å¾®è°ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMathSEåœ¨å¤šä¸ªé«˜éš¾åº¦åŸºå‡†æµ‹è¯•ä¸­æ˜¾è‘—ä¼˜äºéª¨å¹²æ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯åœ¨MathVL-testæµ‹è¯•é›†ä¸Šï¼Œå…¶è¡¨ç°è¶…è¶Šäº†ç›®å‰é¢†å…ˆçš„å¼€æºå¤šæ¨¡æ€æ•°å­¦æ¨ç†æ¨¡å‹QVQã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06805v1",
      "published_date": "2025-11-10 07:46:19 UTC",
      "updated_date": "2025-11-10 07:46:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:20:16.865265+00:00"
    },
    {
      "arxiv_id": "2511.06804v1",
      "title": "AgentSUMO: An Agentic Framework for Interactive Simulation Scenario Generation in SUMO via Large Language Models",
      "title_zh": "AgentSUMOï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„SUMOäº¤äº’å¼ä»¿çœŸåœºæ™¯ç”Ÿæˆæ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Minwoo Jeong",
        "Jeeyun Chang",
        "Yoonjin Yoon"
      ],
      "abstract": "The growing complexity of urban mobility systems has made traffic simulation indispensable for evidence-based transportation planning and policy evaluation. However, despite the analytical capabilities of platforms such as the Simulation of Urban MObility (SUMO), their application remains largely confined to domain experts. Developing realistic simulation scenarios requires expertise in network construction, origin-destination modeling, and parameter configuration for policy experimentation, creating substantial barriers for non-expert users such as policymakers, urban planners, and city officials. Moreover, the requests expressed by these users are often incomplete and abstract-typically articulated as high-level objectives, which are not well aligned with the imperative, sequential workflows employed in existing language-model-based simulation frameworks. To address these challenges, this study proposes AgentSUMO, an agentic framework for interactive simulation scenario generation via large language models. AgentSUMO departs from imperative, command-driven execution by introducing an adaptive reasoning layer that interprets user intents, assesses task complexity, infers missing parameters, and formulates executable simulation plans. The framework is structured around two complementary components, the Interactive Planning Protocol, which governs reasoning and user interaction, and the Model Context Protocol, which manages standardized communication and orchestration among simulation tools. Through this design, AgentSUMO converts abstract policy objectives into executable simulation scenarios. Experiments on urban networks in Seoul and Manhattan demonstrate that the agentic workflow achieves substantial improvements in traffic flow metrics while maintaining accessibility for non-expert users, successfully bridging the gap between policy goals and executable simulation workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† AgentSUMOï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Models) çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸå¸‚äº¤é€šæ¨¡æ‹Ÿå¹³å°ï¼ˆå¦‚ SUMOï¼‰å¯¹éä¸“å®¶ç”¨æˆ·é—¨æ§›è¿‡é«˜ä»¥åŠéš¾ä»¥å¤„ç†æŠ½è±¡æŒ‡ä»¤çš„é—®é¢˜ã€‚é’ˆå¯¹ç°æœ‰æ¡†æ¶éš¾ä»¥åº”å¯¹æ”¿ç­–åˆ¶å®šè€…æå‡ºçš„ä¸å®Œæ•´æˆ–é«˜å±‚ç›®æ ‡è¿™ä¸€æŒ‘æˆ˜ï¼ŒAgentSUMO å¼•å…¥äº†è‡ªé€‚åº”æ¨ç†å±‚ï¼Œèƒ½å¤Ÿè§£é‡Šç”¨æˆ·æ„å›¾ã€æ¨æ–­ç¼ºå¤±å‚æ•°å¹¶åˆ¶å®šå¯æ‰§è¡Œçš„æ¨¡æ‹Ÿè®¡åˆ’ã€‚è¯¥æ¡†æ¶ç”±è´Ÿè´£æ¨ç†å’Œäº¤äº’çš„ Interactive Planning Protocol ä»¥åŠç®¡ç†å·¥å…·ç¼–æ’çš„ Model Context Protocol ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆã€‚åœ¨é¦–å°”å’Œæ›¼å“ˆé¡¿åŸå¸‚ç½‘ç»œä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒAgentSUMO åœ¨æ˜¾è‘—æ”¹å–„äº¤é€šæµæŒ‡æ ‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆé™ä½äº†éä¸“å®¶ç”¨æˆ·çš„ä½¿ç”¨é—¨æ§›ï¼ŒæˆåŠŸå¼¥åˆäº†æŠ½è±¡æ”¿ç­–ç›®æ ‡ä¸å¯æ‰§è¡Œæ¨¡æ‹Ÿå·¥ä½œæµä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted to Transportation Research Part C (under review)",
      "pdf_url": "https://arxiv.org/pdf/2511.06804v1",
      "published_date": "2025-11-10 07:46:12 UTC",
      "updated_date": "2025-11-10 07:46:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:20:41.121943+00:00"
    },
    {
      "arxiv_id": "2511.06803v1",
      "title": "Learning to Fast Unrank in Collaborative Filtering Recommendation",
      "title_zh": "ååŒè¿‡æ»¤æ¨èä¸­çš„å¿«é€Ÿå»æ’åºå­¦ä¹ ",
      "authors": [
        "Junpeng Zhao",
        "Lin Li",
        "Ming Li",
        "Amran Bhuiyan",
        "Jimmy Huang"
      ],
      "abstract": "Modern data-driven recommendation systems risk memorizing sensitive user behavioral patterns, raising privacy concerns. Existing recommendation unlearning methods, while capable of removing target data influence, suffer from inefficient unlearning speed and degraded performance, failing to meet real-time unlearning demands. Considering the ranking-oriented nature of recommendation systems, we present unranking, the process of reducing the ranking positions of target items while ensuring the formal guarantees of recommendation unlearning. To achieve efficient unranking, we propose Learning to Fast Unrank in Collaborative Filtering Recommendation (L2UnRank), which operates through three key stages: (a) identifying the influenced scope via interaction-based p-hop propagation, (b) computing structural and semantic influences for entities within this scope, and (c) performing efficient, ranking-aware parameter updates guided by influence information. Extensive experiments across multiple datasets and backbone models demonstrate L2UnRank's model-agnostic nature, achieving state-of-the-art unranking effectiveness and maintaining recommendation quality comparable to retraining, while also delivering a 50x speedup over existing methods. Codes are available at https://github.com/Juniper42/L2UnRank.",
      "tldr_zh": "é’ˆå¯¹ç°ä»£æ•°æ®é©±åŠ¨çš„æ¨èç³»ç»Ÿå¯èƒ½è®°ä½æ•æ„Ÿç”¨æˆ·è¡Œä¸ºæ¨¡å¼ä»è€Œå¼•å‘éšç§æ‹…å¿§çš„é—®é¢˜ï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºå³ç°æœ‰çš„æ¨èé—å¿˜(recommendation unlearning)æ–¹æ³•å­˜åœ¨æ•ˆç‡ä½ä¸‹å’Œæ€§èƒ½ä¸‹é™çš„ç¼ºé™·ã€‚è€ƒè™‘åˆ°æ¨èç³»ç»Ÿé¢å‘æ’åçš„ç‰¹æ€§ï¼Œè®ºæ–‡æå‡ºäº†unrankingæ¦‚å¿µï¼Œæ—¨åœ¨é™ä½ç›®æ ‡ç‰©å“çš„æ’åä½ç½®å¹¶ç¡®ä¿é—å¿˜çš„ç†è®ºä¿éšœã€‚ä¸ºäº†å®ç°é«˜æ•ˆçš„unrankingï¼Œä½œè€…æå‡ºäº†L2UnRank (Learning to Fast Unrank in Collaborative Filtering Recommendation) æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åŒ…å«ä¸‰ä¸ªå…³é”®é˜¶æ®µï¼šé€šè¿‡åŸºäºäº¤äº’çš„p-hopä¼ æ’­ç¡®å®šå—å½±å“èŒƒå›´ï¼Œè®¡ç®—è¯¥èŒƒå›´å†…å®ä½“çš„ç»“æ„å’Œè¯­ä¹‰å½±å“åŠ›ï¼Œå¹¶æ ¹æ®å½±å“åŠ›ä¿¡æ¯æ‰§è¡Œé«˜æ•ˆçš„æ„ŸçŸ¥æ’åçš„å‚æ•°æ›´æ–°ã€‚åœ¨å¤šä¸ªæ•°æ®é›†å’Œéª¨å¹²æ¨¡å‹ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒL2UnRankå…·æœ‰æ¨¡å‹æ— å…³æ€§ï¼Œä¸ä»…å®ç°äº†æœ€å…ˆè¿›çš„unrankingæ•ˆæœï¼Œè¿˜ä¿æŒäº†ä¸é‡æ–°è®­ç»ƒç›¸å½“çš„æ¨èè´¨é‡ï¼ŒåŒæ—¶åœ¨é€Ÿåº¦ä¸Šæ¯”ç°æœ‰æ–¹æ³•å¿«äº†50å€ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06803v1",
      "published_date": "2025-11-10 07:45:15 UTC",
      "updated_date": "2025-11-10 07:45:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:21:41.622509+00:00"
    },
    {
      "arxiv_id": "2511.06798v1",
      "title": "Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence",
      "title_zh": "å¿«é€Ÿæƒé‡ç¨³æ€é‡å…¥ç½‘ç»œä¸­çš„é€’å½’åŠ¨åŠ›å­¦ï¼šè¿ˆå‘åæ€æ€§æ™ºèƒ½",
      "authors": [
        "B. G. Chae"
      ],
      "abstract": "This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a neural mechanism that integrates fast-weight associative memory, homeostatic regularization, and learned reentrant feedback to approximate self-referential computation in neural networks. Unlike standard transformer architectures that operate in a purely feedforward manner during inference, FH-RL enables internal recurrence without external looping, allowing prior latent states to be dynamically re-entered into the ongoing computation stream. We conduct controlled experiments sweeping the reentry gain $Î³$ and evaluate emergent internal dynamics using three novel metrics: the Information Reentry Ratio (IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift Periodicity (RDP). Results show that reentry quantity increases proportionally with~$Î³$, while the learned feedback matrix $W_r$ remains bounded and becomes more structured at moderate gains. Critically, a stable reflective band emerges around $Î³\\approx 0.10-0.20$, where internal feedback is maximally expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero, and RDP exhibits consistent low-frequency cycles. These findings provide quantitative evidence that reflective, thought-like internal processing can arise from a principled balance between feedback amplification and homeostatic regulation, linking modern fast-weight architectures to theories of cortical reentry and recursive cognition.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Fast-Weights Homeostatic Reentry Layer (FH-RL)ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆäº†fast-weight associative memoryã€homeostatic regularizationå’Œlearned reentrant feedbackçš„ç¥ç»æœºåˆ¶ï¼Œæ—¨åœ¨ç¥ç»ç½‘ç»œä¸­å®ç°è¿‘ä¼¼çš„è‡ªæŒ‡è®¡ç®—ã€‚ä¸æ¨ç†é˜¶æ®µä»…è¿›è¡Œå‰é¦ˆæ“ä½œçš„æ ‡å‡†Transformeræ¶æ„ä¸åŒï¼ŒFH-RLå…è®¸åœ¨æ²¡æœ‰å¤–éƒ¨å¾ªç¯çš„æƒ…å†µä¸‹è¿›è¡Œå†…éƒ¨é€’å½’ï¼Œä½¿å…ˆå‰çš„æ½œåœ¨çŠ¶æ€èƒ½å¤ŸåŠ¨æ€é‡æ–°è¿›å…¥æ­£åœ¨è¿›è¡Œçš„è®¡ç®—æµã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡è°ƒæ•´reentry gain $\\gamma$è¿›è¡Œäº†æ§åˆ¶å®éªŒï¼Œå¹¶åˆ©ç”¨Information Reentry Ratio (IRR)ã€Eigen-Spectrum Recursion Index (ESRI)å’ŒRepresentational Drift Periodicity (RDP)ä¸‰ä¸ªæ–°æŒ‡æ ‡è¯„ä¼°äº†æ¶Œç°çš„å†…éƒ¨åŠ¨åŠ›å­¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨$\\gamma \\approx 0.10-0.20$é™„è¿‘å‡ºç°äº†ä¸€ä¸ªç¨³å®šçš„â€œåå°„å¸¦â€ï¼ˆstable reflective bandï¼‰ï¼Œæ­¤æ—¶å†…éƒ¨åé¦ˆè¡¨ç°åŠ›æœ€å¼ºä¸”é¢‘è°±ä¿æŒç¨³å®šï¼ŒIRRå¹³æ»‘ä¸Šå‡è€ŒESRIä¿æŒåœ¨é›¶é™„è¿‘ã€‚è¿™äº›å‘ç°æä¾›äº†å®šé‡è¯æ®ï¼Œè¯æ˜é€šè¿‡å¹³è¡¡åé¦ˆæ”¾å¤§å’Œç¨³æ€è°ƒèŠ‚å¯ä»¥äº§ç”Ÿç±»ä¼¼æ€ç»´çš„åæ€æ€§å†…éƒ¨å¤„ç†ï¼Œä»è€Œå°†ç°ä»£fast-weightæ¶æ„ä¸çš®å±‚å†å…¥åŠé€’å½’è®¤çŸ¥ç†è®ºè”ç³»èµ·æ¥ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.06798v1",
      "published_date": "2025-11-10 07:36:45 UTC",
      "updated_date": "2025-11-10 07:36:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:22:07.668231+00:00"
    },
    {
      "arxiv_id": "2511.06793v1",
      "title": "Cross-Modal Unlearning via Influential Neuron Path Editing in Multimodal Large Language Models",
      "title_zh": "å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ä¸­åŸºäºå½±å“åŠ›ç¥ç»å…ƒè·¯å¾„ç¼–è¾‘çš„è·¨æ¨¡æ€é—å¿˜",
      "authors": [
        "Kunhao Li",
        "Wenhao Li",
        "Di Wu",
        "Lei Yang",
        "Jun Bai",
        "Ju Jia",
        "Jason Xue"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) extend foundation models to real-world applications by integrating inputs such as text and vision. However, their broad knowledge capacity raises growing concerns about privacy leakage, toxicity mitigation, and intellectual property violations. Machine Unlearning (MU) offers a practical solution by selectively forgetting targeted knowledge while preserving overall model utility. When applied to MLLMs, existing neuron-editing-based MU approaches face two fundamental challenges: (1) forgetting becomes inconsistent across modalities because existing point-wise attribution methods fail to capture the structured, layer-by-layer information flow that connects different modalities; and (2) general knowledge performance declines when sensitive neurons that also support important reasoning paths are pruned, as this disrupts the model's ability to generalize. To alleviate these limitations, we propose a multimodal influential neuron path editor (MIP-Editor) for MU. Our approach introduces modality-specific attribution scores to identify influential neuron paths responsible for encoding forget-set knowledge and applies influential-path-aware neuron-editing via representation misdirection. This strategy also enables effective and coordinated forgetting across modalities while preserving the model's general capabilities. Experimental results demonstrate that MIP-Editor achieves a superior unlearning performance on multimodal tasks, with a maximum forgetting rate of 87.75% and up to 54.26% improvement in general knowledge retention. On textual tasks, MIP-Editor achieves up to 80.65% forgetting and preserves 77.9% of general performance. Codes are available at https://github.com/PreckLi/MIP-Editor.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ä¸­å­˜åœ¨çš„éšç§æ³„éœ²å’Œæœ‰æ¯’å†…å®¹é£é™©ï¼Œæå‡ºäº†ä¸€ç§åä¸ºMIP-Editorçš„è·¨æ¨¡æ€æœºå™¨é—å¿˜(Machine Unlearning, MU)æ–¹æ³•ã€‚ç°æœ‰çš„åŸºäºç¥ç»å…ƒç¼–è¾‘çš„MUæŠ€æœ¯é¢ä¸´è·¨æ¨¡æ€é—å¿˜æ•ˆæœä¸ä¸€è‡´ä»¥åŠé€šç”¨çŸ¥è¯†æ€§èƒ½ä¸‹é™çš„æŒ‘æˆ˜ï¼Œä¸»è¦åŸå› æ˜¯æœªèƒ½æ•æ‰è¿æ¥ä¸åŒæ¨¡æ€çš„å±‚çº§ä¿¡æ¯æµã€‚MIP-Editoré€šè¿‡å¼•å…¥æ¨¡æ€ç‰¹å®šçš„å½’å› åˆ†æ•°æ¥è¯†åˆ«è´Ÿè´£ç¼–ç ç›®æ ‡é—å¿˜çŸ¥è¯†çš„æœ‰å½±å“åŠ›çš„ç¥ç»å…ƒè·¯å¾„(influential neuron paths)ï¼Œå¹¶åˆ©ç”¨è¡¨ç¤ºè¯¯å¯¼(representation misdirection)æŠ€æœ¯è¿›è¡Œè·¯å¾„æ„ŸçŸ¥çš„ç¥ç»å…ƒç¼–è¾‘ã€‚è¿™ç§ç­–ç•¥ä¸ä»…å®ç°äº†è·¨æ¨¡æ€çš„æœ‰æ•ˆåè°ƒé—å¿˜ï¼Œè¿˜æœ€å¤§ç¨‹åº¦åœ°ä¿ç•™äº†æ¨¡å‹çš„é€šç”¨æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMIP-Editoråœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸Šçš„é—å¿˜ç‡æœ€é«˜è¾¾åˆ°87.75%ï¼Œé€šç”¨çŸ¥è¯†ä¿ç•™ç‡æå‡äº†é«˜è¾¾54.26%ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2026 as a Conference Paper (Oral Presentation)",
      "pdf_url": "https://arxiv.org/pdf/2511.06793v1",
      "published_date": "2025-11-10 07:31:20 UTC",
      "updated_date": "2025-11-10 07:31:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:22:27.641866+00:00"
    },
    {
      "arxiv_id": "2511.06790v1",
      "title": "Robust Causal Discovery under Imperfect Structural Constraints",
      "title_zh": "ä¸å®Œç¾ç»“æ„çº¦æŸä¸‹çš„é²æ£’å› æœå‘ç°",
      "authors": [
        "Zidong Wang",
        "Xi Lin",
        "Chuchao He",
        "Xiaoguang Gao"
      ],
      "abstract": "Robust causal discovery from observational data under imperfect prior knowledge remains a significant and largely unresolved challenge. Existing methods typically presuppose perfect priors or can only handle specific, pre-identified error types. And their performance degrades substantially when confronted with flawed constraints of unknown location and type. This decline arises because most of them rely on inflexible and biased thresholding strategies that may conflict with the data distribution. To overcome these limitations, we propose to harmonizes knowledge and data through prior alignment and conflict resolution. First, we assess the credibility of imperfect structural constraints through a surrogate model, which then guides a sparse penalization term measuring the loss between the learned and constrained adjacency matrices. We theoretically prove that, under ideal assumption, the knowledge-driven objective aligns with the data-driven objective. Furthermore, to resolve conflicts when this assumption is violated, we introduce a multi-task learning framework optimized via multi-gradient descent, jointly minimizing both objectives. Our proposed method is robust to both linear and nonlinear settings. Extensive experiments, conducted under diverse noise conditions and structural equation model types, demonstrate the effectiveness and efficiency of our method under imperfect structural constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åœ¨ä¸å®Œç¾å…ˆéªŒçŸ¥è¯†ä¸‹ä»è§‚æµ‹æ•°æ®è¿›è¡Œé²æ£’å› æœå‘ç°(Robust Causal Discovery)çš„éš¾é¢˜ï¼Œè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨é¢å¯¹æœªçŸ¥ç±»å‹å’Œä½ç½®çš„ç¼ºé™·çº¦æŸæ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ã€‚ä½œè€…æå‡ºäº†ä¸€ç§é€šè¿‡å…ˆéªŒå¯¹é½å’Œå†²çªè§£å†³æ¥åè°ƒçŸ¥è¯†ä¸æ•°æ®çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨ä»£ç†æ¨¡å‹(surrogate model)è¯„ä¼°ä¸å®Œç¾ç»“æ„çº¦æŸçš„å¯ä¿¡åº¦ï¼Œå¹¶ä»¥æ­¤æŒ‡å¯¼è¡¡é‡å­¦ä¹ åˆ°çš„é‚»æ¥çŸ©é˜µä¸çº¦æŸä¹‹é—´æŸå¤±çš„ç¨€ç–æƒ©ç½šé¡¹ã€‚ä¸ºäº†è§£å†³å‡è®¾è¿èƒŒæ—¶çš„å†²çªï¼Œç ”ç©¶å¼•å…¥äº†é€šè¿‡å¤šæ¢¯åº¦ä¸‹é™(multi-gradient descent)ä¼˜åŒ–çš„å¤šä»»åŠ¡å­¦ä¹ (multi-task learning)æ¡†æ¶ï¼Œè”åˆæœ€å°åŒ–æ•°æ®é©±åŠ¨å’ŒçŸ¥è¯†é©±åŠ¨çš„ç›®æ ‡ã€‚ç†è®ºè¯æ˜äº†åœ¨ç†æƒ³å‡è®¾ä¸‹çŸ¥è¯†é©±åŠ¨ä¸æ•°æ®é©±åŠ¨ç›®æ ‡çš„ä¸€è‡´æ€§ï¼Œä¸”è¯¥æ–¹æ³•é€‚ç”¨äºçº¿æ€§å’Œéçº¿æ€§è®¾ç½®ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒçš„å™ªå£°æ¡ä»¶å’Œç»“æ„æ–¹ç¨‹æ¨¡å‹ç±»å‹ä¸‹ï¼Œèƒ½å¤Ÿæœ‰æ•ˆä¸”é«˜æ•ˆåœ°å¤„ç†ä¸å®Œç¾ç»“æ„çº¦æŸã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06790v1",
      "published_date": "2025-11-10 07:27:08 UTC",
      "updated_date": "2025-11-10 07:27:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:22:53.582680+00:00"
    },
    {
      "arxiv_id": "2511.06785v2",
      "title": "Resource Efficient Sleep Staging via Multi-Level Masking and Prompt Learning",
      "title_zh": "åŸºäºå¤šçº§æ©ç ä¸æç¤ºå­¦ä¹ çš„èµ„æºé«˜æ•ˆç¡çœ åˆ†æœŸ",
      "authors": [
        "Lejun Ai",
        "Yulong Li",
        "Haodong Yi",
        "Jixuan Xie",
        "Yue Wang",
        "Jia Liu",
        "Min Chen",
        "Rui Wang"
      ],
      "abstract": "Automatic sleep staging plays a vital role in assessing sleep quality and diagnosing sleep disorders. Most existing methods rely heavily on long and continuous EEG recordings, which poses significant challenges for data acquisition in resource-constrained systems, such as wearable or home-based monitoring systems. In this paper, we propose the task of resource-efficient sleep staging, which aims to reduce the amount of signal collected per sleep epoch while maintaining reliable classification performance. To solve this task, we adopt the masking and prompt learning strategy and propose a novel framework called Mask-Aware Sleep Staging (MASS). Specifically, we design a multi-level masking strategy to promote effective feature modeling under partial and irregular observations. To mitigate the loss of contextual information introduced by masking, we further propose a hierarchical prompt learning mechanism that aggregates unmasked data into a global prompt, serving as a semantic anchor for guiding both patch-level and epoch-level feature modeling. MASS is evaluated on four datasets, demonstrating state-of-the-art performance, especially when the amount of data is very limited. This result highlights its potential for efficient and scalable deployment in real-world low-resource sleep monitoring environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è‡ªåŠ¨ç¡çœ åˆ†æœŸæ–¹æ³•ä¾èµ–é•¿è¿ç»­EEGè®°å½•ï¼Œå¯¼è‡´åœ¨å¯ç©¿æˆ´è®¾å¤‡ç­‰èµ„æºå—é™ç³»ç»Ÿä¸­æ•°æ®é‡‡é›†å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†èµ„æºé«˜æ•ˆçš„ç¡çœ åˆ†æœŸä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸ºMask-Aware Sleep Staging (MASS)çš„æ–°æ¡†æ¶ï¼Œé‡‡ç”¨äº†æ©ç å’Œæç¤ºå­¦ä¹ ç­–ç•¥ï¼Œæ—¨åœ¨å‡å°‘æ¯ä¸ªç¡çœ epoché‡‡é›†çš„ä¿¡å·é‡çš„åŒæ—¶ä¿æŒåˆ†ç±»æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ¡†æ¶è®¾è®¡äº†å¤šçº§æ©ç ç­–ç•¥(multi-level masking strategy)ï¼Œä»¥åœ¨éƒ¨åˆ†å’Œä¸è§„åˆ™è§‚æµ‹ä¸‹ä¿ƒè¿›æœ‰æ•ˆçš„ç‰¹å¾å»ºæ¨¡ã€‚ä¸ºäº†ç¼“è§£æ©ç å¼•å…¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä¸¢å¤±ï¼Œæ–‡ç« è¿›ä¸€æ­¥æå‡ºäº†ä¸€ç§åˆ†å±‚æç¤ºå­¦ä¹ æœºåˆ¶(hierarchical prompt learning mechanism)ï¼Œå°†æœªè¢«æ©ç çš„æ•°æ®èšåˆä¸ºå…¨å±€æç¤ºï¼Œä½œä¸ºè¯­ä¹‰é”šç‚¹æŒ‡å¯¼patchçº§å’Œepochçº§çš„ç‰¹å¾å»ºæ¨¡ã€‚åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒMASSå±•ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½(SOTA)ï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®é‡éå¸¸æœ‰é™çš„æƒ…å†µä¸‹ï¼Œçªæ˜¾äº†å…¶åœ¨ç°å®ä¸–ç•Œä½èµ„æºç¡çœ ç›‘æµ‹ç¯å¢ƒä¸­é«˜æ•ˆéƒ¨ç½²çš„æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, to be published in AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06785v2",
      "published_date": "2025-11-10 07:19:26 UTC",
      "updated_date": "2025-11-18 05:06:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:26:03.745861+00:00"
    },
    {
      "arxiv_id": "2511.06781v1",
      "title": "On the Mechanisms of Collaborative Learning in VAE Recommenders",
      "title_zh": "VAEæ¨èç³»ç»Ÿä¸­çš„ååŒå­¦ä¹ æœºåˆ¶",
      "authors": [
        "Tung-Long Vuong",
        "Julien Monteil",
        "Hien Dang",
        "Volodymyr Vaskovych",
        "Trung Le",
        "Vu Nguyen"
      ],
      "abstract": "Variational Autoencoders (VAEs) are a powerful alternative to matrix factorization for recommendation. A common technique in VAE-based collaborative filtering (CF) consists in applying binary input masking to user interaction vectors, which improves performance but remains underexplored theoretically. In this work, we analyze how collaboration arises in VAE-based CF and show it is governed by latent proximity: we derive a latent sharing radius that informs when an SGD update on one user strictly reduces the loss on another user, with influence decaying as the latent Wasserstein distance increases. We further study the induced geometry: with clean inputs, VAE-based CF primarily exploits \\emph{local} collaboration between input-similar users and under-utilizes global collaboration between far-but-related users. We compare two mechanisms that encourage \\emph{global} mixing and characterize their trade-offs: (1) $Î²$-KL regularization directly tightens the information bottleneck, promoting posterior overlap but risking representational collapse if too large; (2) input masking induces stochastic geometric contractions and expansions, which can bring distant users onto the same latent neighborhood but also introduce neighborhood drift. To preserve user identity while enabling global consistency, we propose an anchor regularizer that aligns user posteriors with item embeddings, stabilizing users under masking and facilitating signal sharing across related items. Our analyses are validated on the Netflix, MovieLens-20M, and Million Song datasets. We also successfully deployed our proposed algorithm on an Amazon streaming platform following a successful online experiment.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥åˆ†æäº†åŸºäºå˜åˆ†è‡ªç¼–ç å™¨(VAEs)çš„ååŒè¿‡æ»¤(CF)ä¸­çš„åä½œå­¦ä¹ æœºåˆ¶ï¼Œç‰¹åˆ«æ˜¯äºŒè¿›åˆ¶è¾“å…¥æ©ç (binary input masking)çš„ç†è®ºåŸºç¡€ã€‚ä½œè€…æŒ‡å‡ºåä½œç”±æ½œåœ¨é‚»è¿‘æ€§(latent proximity)ä¸»å¯¼ï¼Œå¹¶æ¨å¯¼å‡ºäº†æ½œåœ¨å…±äº«åŠå¾„ï¼Œè¯æ˜ç”¨æˆ·é—´çš„å½±å“åŠ›éšæ½œåœ¨Wassersteinè·ç¦»çš„å¢åŠ è€Œè¡°å‡ã€‚ç ”ç©¶æ­ç¤ºäº†åœ¨å¹²å‡€è¾“å…¥ä¸‹ï¼ŒVAEä¸»è¦åˆ©ç”¨å±€éƒ¨åä½œè€Œå¿½è§†äº†è¿œè·ç¦»ç”¨æˆ·é—´çš„å…¨å±€åä½œï¼Œå¹¶å¯¹æ¯”äº†$\\beta$-KLæ­£åˆ™åŒ–ä¸è¾“å…¥æ©ç åœ¨ä¿ƒè¿›å…¨å±€æ··åˆæ–¹é¢çš„ä¼˜ç¼ºç‚¹ã€‚ä¸ºäº†åœ¨ä¿æŒç”¨æˆ·èº«ä»½çš„åŒæ—¶å®ç°å…¨å±€ä¸€è‡´æ€§ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§é”šç‚¹æ­£åˆ™åŒ–å™¨(anchor regularizer)ï¼Œé€šè¿‡å°†ç”¨æˆ·åéªŒåˆ†å¸ƒä¸ç‰©å“åµŒå…¥(item embeddings)å¯¹é½æ¥ç¨³å®šæ©ç ä¸‹çš„ç”¨æˆ·è¡¨ç¤ºã€‚è¯¥æ–¹æ³•åœ¨Netflixã€MovieLens-20Må’ŒMillion Songæ•°æ®é›†ä¸Šå¾—åˆ°äº†éªŒè¯ï¼Œå¹¶åœ¨äºšé©¬é€Šæµåª’ä½“å¹³å°çš„åœ¨çº¿å®éªŒä¸­å–å¾—äº†æˆåŠŸã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06781v1",
      "published_date": "2025-11-10 07:13:58 UTC",
      "updated_date": "2025-11-10 07:13:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:26:35.513330+00:00"
    },
    {
      "arxiv_id": "2511.06780v1",
      "title": "OntoTune: Ontology-Driven Learning for Query Optimization with Convolutional Models",
      "title_zh": "OntoTuneï¼šåŸºäºå·ç§¯æ¨¡å‹çš„æœ¬ä½“é©±åŠ¨æŸ¥è¯¢ä¼˜åŒ–å­¦ä¹ ",
      "authors": [
        "Songhui Yue",
        "Yang Shao",
        "Sean Hayes"
      ],
      "abstract": "Query optimization has been studied using machine learning, reinforcement learning, and, more recently, graph-based convolutional networks. Ontology, as a structured, information-rich knowledge representation, can provide context, particularly in learning problems. This paper presents OntoTune, an ontology-based platform for enhancing learning for query optimization. By connecting SQL queries, database metadata, and statistics, the ontology developed in this research is promising in capturing relationships and important determinants of query performance. This research also develops a method to embed ontologies while preserving as much of the relationships and key information as possible, before feeding it into learning algorithms such as tree-based and graph-based convolutional networks. A case study shows how OntoTune's ontology-driven learning delivers performance gains compared with database system default query execution.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OntoTuneï¼Œä¸€ç§åŸºäºæœ¬ä½“(Ontology)é©±åŠ¨çš„å­¦ä¹ å¹³å°ï¼Œæ—¨åœ¨åˆ©ç”¨å·ç§¯æ¨¡å‹ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ã€‚é’ˆå¯¹ç°æœ‰æœºå™¨å­¦ä¹ å’Œå›¾å·ç§¯ç½‘ç»œ(Graph-based Convolutional Networks)åœ¨æŸ¥è¯¢ä¼˜åŒ–ä¸­çš„åº”ç”¨ï¼Œè¯¥ç ”ç©¶é€šè¿‡æ„å»ºè¿æ¥SQLæŸ¥è¯¢ã€æ•°æ®åº“å…ƒæ•°æ®å’Œç»Ÿè®¡ä¿¡æ¯çš„æœ¬ä½“ï¼Œæœ‰æ•ˆæ•æ‰äº†å½±å“æŸ¥è¯¢æ€§èƒ½çš„å…³é”®å…³ç³»å’Œå†³å®šå› ç´ ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜å¼€å‘äº†ä¸€ç§ä¸“é—¨çš„æœ¬ä½“åµŒå…¥æ–¹æ³•ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™ç»“æ„å…³ç³»å’Œå…³é”®ä¿¡æ¯çš„åŒæ—¶ï¼Œå°†å…¶è½¬åŒ–ä¸ºé€‚ç”¨äºæ ‘æ¨¡å‹åŠå›¾å·ç§¯ç½‘ç»œç­‰å­¦ä¹ ç®—æ³•çš„è¾“å…¥ã€‚æ¡ˆä¾‹ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œç›¸æ¯”äºæ•°æ®åº“ç³»ç»Ÿçš„é»˜è®¤æŸ¥è¯¢æ‰§è¡Œè®¡åˆ’ï¼ŒOntoTuneé€šè¿‡æœ¬ä½“é©±åŠ¨çš„å­¦ä¹ æ˜¾è‘—æå‡äº†æŸ¥è¯¢æ€§èƒ½ï¼ŒéªŒè¯äº†ç»“æ„åŒ–çŸ¥è¯†è¡¨ç¤ºåœ¨ä¼˜åŒ–é—®é¢˜ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06780v1",
      "published_date": "2025-11-10 07:08:19 UTC",
      "updated_date": "2025-11-10 07:08:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:27:03.544141+00:00"
    },
    {
      "arxiv_id": "2511.06779v2",
      "title": "Pedagogical Reflections on the Holistic Cognitive Development (HCD) Framework and AI-Augmented Learning in Creative Computing",
      "title_zh": "åˆ›æ„è®¡ç®—ä¸­çš„æ•´ä½“è®¤çŸ¥å‘å±• (HCD) æ¡†æ¶ä¸ AI å¢å¼ºå­¦ä¹ çš„æ•™å­¦åæ€",
      "authors": [
        "Anand Bhojan"
      ],
      "abstract": "This paper presents an expanded account of the Holistic Cognitive Development (HCD) framework for reflective and creative learning in computing education. The HCD framework integrates design thinking, experiential learning, and reflective practice into a unified constructivist pedagogy emphasizing autonomy, ownership, and scaffolding. It is applied across courses in game design (CS3247, CS4350), virtual reality (CS4240), and extended reality systems, where students engage in iterative cycles of thinking, creating, criticizing, and reflecting. The paper also examines how AI-augmented systems such as iReflect, ReflexAI, and Knowledge Graph-enhanced LLM feedback tools operationalize the HCD framework through scalable, personalized feedback. Empirical findings demonstrate improved reflective depth, feedback quality, and learner autonomy. The work advocates a balance of supportive autonomy in supervision, where students practice self-directed inquiry while guided through structured reflection and feedback.",
      "tldr_zh": "æœ¬æ–‡ä»‹ç»äº†ç”¨äºè®¡ç®—æ•™è‚²ä¸­åæ€æ€§å’Œåˆ›é€ æ€§å­¦ä¹ çš„Holistic Cognitive Development (HCD)æ¡†æ¶çš„æ‰©å±•å†…å®¹ã€‚è¯¥æ¡†æ¶å°†è®¾è®¡æ€ç»´(design thinking)ã€ä½“éªŒå¼å­¦ä¹ (experiential learning)å’Œåæ€æ€§å®è·µ(reflective practice)æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„å»ºæ„ä¸»ä¹‰æ•™å­¦æ³•ï¼Œå¼ºè°ƒè‡ªä¸»æ€§ã€æ‰€æœ‰æƒå’Œè„šæ‰‹æ¶æ”¯æŒ(scaffolding)ã€‚è¯¥æ¡†æ¶è¢«åº”ç”¨äºæ¸¸æˆè®¾è®¡ã€è™šæ‹Ÿç°å®(VR)å’Œæ‰©å±•ç°å®(XR)ç³»ç»Ÿçš„è¯¾ç¨‹ä¸­ï¼Œè®©å­¦ç”Ÿå‚ä¸æ€è€ƒã€åˆ›é€ ã€æ‰¹è¯„å’Œåæ€çš„è¿­ä»£å¾ªç¯ã€‚æ­¤å¤–ï¼Œè®ºæ–‡è¿˜æ¢è®¨äº†iReflectã€ReflexAIå’ŒåŸºäºçŸ¥è¯†å›¾è°±çš„å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åé¦ˆå·¥å…·ç­‰AIå¢å¼ºç³»ç»Ÿå¦‚ä½•é€šè¿‡å¯æ‰©å±•çš„ä¸ªæ€§åŒ–åé¦ˆæ¥å®æ–½HCDæ¡†æ¶ã€‚å®è¯ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•æé«˜äº†åæ€æ·±åº¦ã€åé¦ˆè´¨é‡å’Œå­¦ä¹ è€…çš„è‡ªä¸»æ€§ã€‚è¿™é¡¹å·¥ä½œæå€¡åœ¨æŒ‡å¯¼ä¸­å®ç°â€œæ”¯æŒæ€§è‡ªä¸»â€(supportive autonomy)çš„å¹³è¡¡ï¼Œå³å­¦ç”Ÿåœ¨ç»“æ„åŒ–çš„åæ€å’Œåé¦ˆæŒ‡å¯¼ä¸‹è¿›è¡Œè‡ªæˆ‘å¯¼å‘çš„æ¢ç©¶ã€‚",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "Short Abstract",
      "pdf_url": "https://arxiv.org/pdf/2511.06779v2",
      "published_date": "2025-11-10 07:07:37 UTC",
      "updated_date": "2026-01-05 13:31:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:27:16.751842+00:00"
    },
    {
      "arxiv_id": "2511.06776v1",
      "title": "Data Trajectory Alignment for LLM Domain Adaptation: A Two-Phase Synthesis Framework for Telecommunications Mathematics",
      "title_zh": "é¢å‘LLMé¢†åŸŸè‡ªé€‚åº”çš„æ•°æ®è½¨è¿¹å¯¹é½ï¼šé’ˆå¯¹ç”µä¿¡æ•°å­¦çš„åŒé˜¶æ®µåˆæˆæ¡†æ¶",
      "authors": [
        "Zhicheng Zhou",
        "Jing Li",
        "Suming Qiu",
        "Junjie Huang",
        "Linyuan Qiu",
        "Zhijie Sun"
      ],
      "abstract": "General-purpose large language models (LLMs) are increasingly deployed in verticals such as telecommunications, where adaptation is hindered by scarce, low-information-density corpora and tight mobile/edge constraints. We propose Data Trajectory Alignment (DTA), a two-phase, model-agnostic data curation framework that treats solution processes - not only final answers - as first-class supervision. Phase I (Initializing) synthesizes diverse, high-coverage candidates using an ensemble of strong teachers. Phase II (DTA) rewrites teacher solutions to align intermediate steps and presentation style with the target student's inductive biases and then performs signal-aware exemplar selection via agreement checks and reflection-based judging. Instantiated on telecommunications mathematics (e.g., link budgets, SNR/AMC selection, and power-control feasibility), DTA yields state-of-the-art (SOTA) accuracy on TELEMATH without enabling explicit \"thinking\" modes: 72.45% pass@1, surpassing distilled-only training by +17.65 points and outperforming a strong baseline (Qwen3-32B with thinking enabled) by +2.94 points. Token-shift analyses indicate that DTA concentrates gains on logical-structural discourse markers rather than merely amplifying domain nouns, indicating improved reasoning scaffolding. Under edge-like inference settings, DTA improves efficiency by reducing reliance on multi-sample voting and disabling expensive reasoning heuristics, cutting energy per output token by ~42% versus Qwen3-32B (thinking mode enabled) and end-to-end latency by ~60% versus Qwen3-32B (thinking mode disabled). These results demonstrate that aligning how solutions are produced enables compact, high-yield supervision that is effective for both accuracy and efficiency, offering a practical recipe for domain adaptation in low-resource verticals beyond telecom.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é€šç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç”µä¿¡ç­‰å‚ç›´é¢†åŸŸé¢ä¸´çš„æ•°æ®ç¨€ç¼ºå’Œè¾¹ç¼˜è®¡ç®—é™åˆ¶é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºData Trajectory Alignment (DTA)çš„ä¸¤é˜¶æ®µæ•°æ®åˆæˆæ¡†æ¶ã€‚DTAå°†è§£é¢˜è¿‡ç¨‹è§†ä¸ºæ ¸å¿ƒç›‘ç£ä¿¡å·ï¼Œç¬¬ä¸€é˜¶æ®µåˆ©ç”¨å¼ºæ•™å¸ˆæ¨¡å‹é›†åˆæˆå¤šæ ·åŒ–å€™é€‰æ•°æ®ï¼Œç¬¬äºŒé˜¶æ®µé‡å†™æ•™å¸ˆæä¾›çš„è§£å†³æ–¹æ¡ˆä»¥å¯¹é½ç›®æ ‡å­¦ç”Ÿæ¨¡å‹çš„ä¸­é—´æ­¥éª¤å’Œé£æ ¼ï¼Œå¹¶é€šè¿‡ä¸€è‡´æ€§æ£€æŸ¥å’Œåæ€æ€§è¯„åˆ¤è¿›è¡Œæ ·æœ¬ç­›é€‰ã€‚åœ¨ç”µä¿¡æ•°å­¦ä»»åŠ¡(TELEMATH)ä¸Šçš„å®éªŒæ˜¾ç¤ºï¼ŒDTAåœ¨æ— éœ€æ˜¾å¼æ€ç»´æ¨¡å¼çš„æƒ…å†µä¸‹å®ç°äº†72.45%çš„pass@1å‡†ç¡®ç‡ï¼Œæ¯”ä»…è’¸é¦è®­ç»ƒæé«˜äº†17.65ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶è¶…è¶Šäº†å¼€å¯æ€ç»´æ¨¡å¼çš„Qwen3-32BåŸºçº¿ã€‚åˆ†æè¡¨æ˜ï¼ŒDTAä¸»è¦é€šè¿‡æ”¹è¿›é€»è¾‘ç»“æ„è¯è¯­æ ‡è®°æ¥å¢å¼ºæ¨ç†æ”¯æ¶ã€‚æ­¤å¤–ï¼Œåœ¨è¾¹ç¼˜æ¨ç†è®¾ç½®ä¸‹ï¼ŒDTAæ˜¾è‘—æå‡äº†æ•ˆç‡ï¼Œç›¸æ¯”åŸºçº¿æ¨¡å‹èƒ½è€—é™ä½çº¦42%ï¼Œç«¯åˆ°ç«¯å»¶è¿Ÿé™ä½çº¦60%ï¼Œè¯æ˜äº†å¯¹é½è§£å†³æ–¹æ¡ˆç”Ÿæˆè¿‡ç¨‹èƒ½ä¸ºä½èµ„æºå‚ç›´é¢†åŸŸçš„é¢†åŸŸé€‚åº”æä¾›é«˜æ•ˆç´§å‡‘çš„ç›‘ç£ä¿¡å·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06776v1",
      "published_date": "2025-11-10 07:05:08 UTC",
      "updated_date": "2025-11-10 07:05:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:27:43.552670+00:00"
    },
    {
      "arxiv_id": "2511.06767v1",
      "title": "QUARK: Quantization-Enabled Circuit Sharing for Transformer Acceleration by Exploiting Common Patterns in Nonlinear Operations",
      "title_zh": "QUARKï¼šåˆ©ç”¨éçº¿æ€§è¿ç®—é€šç”¨æ¨¡å¼å®ç° Transformer åŠ é€Ÿçš„é‡åŒ–ç”µè·¯å…±äº«",
      "authors": [
        "Zhixiong Zhao",
        "Haomin Li",
        "Fangxin Liu",
        "Yuncheng Lu",
        "Zongwu Wang",
        "Tao Yang",
        "Li Jiang",
        "Haibing Guan"
      ],
      "abstract": "Transformer-based models have revolutionized computer vision (CV) and natural language processing (NLP) by achieving state-of-the-art performance across a range of benchmarks. However, nonlinear operations in models significantly contribute to inference latency, presenting unique challenges for efficient hardware acceleration. To this end, we propose QUARK, a quantization-enabled FPGA acceleration framework that leverages common patterns in nonlinear operations to enable efficient circuit sharing, thereby reducing hardware resource requirements. QUARK targets all nonlinear operations within Transformer-based models, achieving high-performance approximation through a novel circuit-sharing design tailored to accelerate these operations. Our evaluation demonstrates that QUARK significantly reduces the computational overhead of nonlinear operators in mainstream Transformer architectures, achieving up to a 1.96 times end-to-end speedup over GPU implementations. Moreover, QUARK lowers the hardware overhead of nonlinear modules by more than 50% compared to prior approaches, all while maintaining high model accuracy -- and even substantially boosting accuracy under ultra-low-bit quantization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†QUARKï¼Œä¸€ç§åŸºäºé‡åŒ–çš„FPGAåŠ é€Ÿæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Transformeræ¨¡å‹ä¸­éçº¿æ€§æ“ä½œ(Nonlinear Operations)å¸¦æ¥çš„æ¨ç†å»¶è¿Ÿå’Œç¡¬ä»¶åŠ é€ŸæŒ‘æˆ˜ã€‚QUARKé€šè¿‡åˆ©ç”¨éçº¿æ€§æ“ä½œä¸­çš„å¸¸è§æ¨¡å¼æ¥å®ç°é«˜æ•ˆçš„ç”µè·¯å…±äº«(Circuit Sharing)ï¼Œä»è€Œæ˜¾è‘—å‡å°‘ç¡¬ä»¶èµ„æºéœ€æ±‚ã€‚è¯¥æ¡†æ¶é’ˆå¯¹Transformeræ¨¡å‹ä¸­çš„æ‰€æœ‰éçº¿æ€§æ“ä½œï¼Œé‡‡ç”¨å®šåˆ¶åŒ–çš„ç”µè·¯å…±äº«è®¾è®¡å®ç°äº†é«˜æ€§èƒ½é€¼è¿‘ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒQUARKåœ¨ä¸»æµTransformeræ¶æ„ä¸­æœ‰æ•ˆé™ä½äº†è®¡ç®—å¼€é”€ï¼Œç›¸æ¯”GPUå®ç°å–å¾—äº†é«˜è¾¾1.96å€çš„ç«¯åˆ°ç«¯åŠ é€Ÿã€‚æ­¤å¤–ï¼Œä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼ŒQUARKå°†éçº¿æ€§æ¨¡å—çš„ç¡¬ä»¶å¼€é”€é™ä½äº†50%ä»¥ä¸Šï¼Œå¹¶åœ¨ä¿æŒé«˜æ¨¡å‹ç²¾åº¦çš„åŒæ—¶ï¼Œåœ¨è¶…ä½æ¯”ç‰¹é‡åŒ–(Ultra-low-bit Quantization)ä¸‹å®ç°äº†ç²¾åº¦çš„æå‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICCAD 2025",
      "pdf_url": "https://arxiv.org/pdf/2511.06767v1",
      "published_date": "2025-11-10 06:46:21 UTC",
      "updated_date": "2025-11-10 06:46:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:28:21.910014+00:00"
    },
    {
      "arxiv_id": "2511.06763v1",
      "title": "Sensitivity of Small Language Models to Fine-tuning Data Contamination",
      "title_zh": "å°å‹è¯­è¨€æ¨¡å‹å¯¹å¾®è°ƒæ•°æ®æ±¡æŸ“çš„æ•æ„Ÿæ€§",
      "authors": [
        "Nicy Scaria",
        "Silvester John Joseph Kennedy",
        "Deepak Subramani"
      ],
      "abstract": "Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\\%, 50\\%, 75\\%, and 100\\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\\textit{capability curse}\" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°å‹è¯­è¨€æ¨¡å‹(Small Language Models, SLMs)åœ¨æŒ‡ä»¤å¾®è°ƒè¿‡ç¨‹ä¸­å¯¹æ•°æ®æ±¡æŸ“çš„è¡Œä¸ºé²æ£’æ€§è¿›è¡Œäº†ç³»ç»Ÿè°ƒæŸ¥ã€‚ç ”ç©¶äººå‘˜è¯„ä¼°äº†23ä¸ªä¸åŒå®¶æ—çš„SLMsï¼ˆå‚æ•°èŒƒå›´2.7äº¿è‡³40äº¿ï¼‰ï¼Œé€šè¿‡åœ¨25%è‡³100%çš„æ±¡æŸ“æ°´å¹³ä¸‹åº”ç”¨å¥æ³•å˜æ¢ï¼ˆå¦‚å­—ç¬¦å’Œå•è¯åè½¬ï¼‰å’Œè¯­ä¹‰å˜æ¢ï¼ˆå¦‚æ— å…³å’Œåäº‹å®å“åº”ï¼‰æ¥æµ‹è¯•å…¶æ•æ„Ÿæ€§ã€‚ç»“æœæ­ç¤ºäº†è„†å¼±æ€§æ¨¡å¼çš„æ ¹æœ¬ä¸å¯¹ç§°æ€§ï¼šå¥æ³•å˜æ¢ä¼šå¯¼è‡´ç¾éš¾æ€§çš„æ€§èƒ½ä¸‹é™ï¼Œå…¶ä¸­å­—ç¬¦åè½¬åœ¨æ‰€æœ‰æ¨¡å‹ä¸­å‡å¼•å‘è¿‘ä¹å®Œå…¨çš„å¤±è´¥ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œè¯­ä¹‰å˜æ¢è¡¨ç°å‡ºæ˜æ˜¾çš„é˜ˆå€¼è¡Œä¸ºï¼Œä¸”ç ”ç©¶å‘ç°äº†ä¸€ç§â€œèƒ½åŠ›è¯…å’’(capability curse)â€ï¼Œå³æ›´å¤§ã€æ›´å¼ºçš„æ¨¡å‹åè€Œæ›´å®¹æ˜“å­¦ä¹ è¯­ä¹‰è…è´¥ï¼Œä»è€Œæ›´è½»æ˜“åœ°éµå¾ªæœ‰å®³æŒ‡ä»¤ã€‚æ­¤å¤–ï¼Œå¯¹åŸºç¡€æ¨¡å‹ä¸æŒ‡ä»¤å¾®è°ƒå˜ä½“çš„åˆ†æè¡¨æ˜ï¼Œå¯¹é½å¹¶æœªæä¾›ä¸€è‡´çš„é²æ£’æ€§ä¼˜åŠ¿ï¼Œæœ‰æ—¶ç”šè‡³é™ä½äº†å¼¹æ€§ã€‚è¯¥å·¥ä½œç¡®ç«‹äº†SLMså¯¹å¥æ³•æ¨¡å¼æ±¡æŸ“çš„ä¸æˆæ¯”ä¾‹è„†å¼±æ€§ï¼Œè¯†åˆ«äº†å¥æ³•ä¸è¯­ä¹‰å˜æ¢é—´çš„ä¸å¯¹ç§°æ•æ„Ÿæ€§ï¼Œå¹¶æå‡ºäº†ç”¨äºæ±¡æŸ“é²æ£’æ€§è¯„ä¼°çš„ç³»ç»Ÿåè®®ï¼Œå¼ºè°ƒäº†å¼€å‘æ„ŸçŸ¥æ±¡æŸ“çš„è®­ç»ƒåè®®çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06763v1",
      "published_date": "2025-11-10 06:44:29 UTC",
      "updated_date": "2025-11-10 06:44:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:28:37.695890+00:00"
    },
    {
      "arxiv_id": "2511.06761v2",
      "title": "SRNN: Spatiotemporal Relational Neural Network for Intuitive Physics Understanding",
      "title_zh": "SRNNï¼šç”¨äºç›´è§‰ç‰©ç†ç†è§£çš„æ—¶ç©ºå…³ç³»ç¥ç»ç½‘ç»œ",
      "authors": [
        "Fei Yang"
      ],
      "abstract": "Human prowess in intuitive physics remains unmatched by machines. To bridge this gap, we argue for a fundamental shift towards brain-inspired computational principles. This paper introduces the Spatiotemporal Relational Neural Network (SRNN), a model that establishes a unified neural representation for object attributes, relations, and timeline, with computations governed by a Hebbian ``Fire Together, Wire Together'' mechanism across dedicated \\textit{What} and \\textit{How} pathways. This unified representation is directly used to generate structured linguistic descriptions of the visual scene, bridging perception and language within a shared neural substrate. On the CLEVRER benchmark, SRNN achieves competitive performance, thereby confirming its capability to represent essential spatiotemporal relations from the visual stream. Cognitive ablation analysis further reveals a benchmark bias, outlining a path for a more holistic evaluation. Finally, the white-box nature of SRNN enables precise pinpointing of error root causes. Our work provides a proof-of-concept that confirms the viability of translating key principles of biological intelligence into engineered systems for intuitive physics understanding in constrained environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SRNN (Spatiotemporal Relational Neural Network)ï¼Œä¸€ç§å—å¤§è„‘è®¡ç®—åŸç†å¯å‘çš„æ¨¡å‹ï¼Œæ—¨åœ¨å¼¥åˆæœºå™¨ä¸äººç±»åœ¨ç›´è§‚ç‰©ç†ç†è§£ä¸Šçš„å·®è·ã€‚SRNNä¸ºå¯¹è±¡å±æ€§ã€å…³ç³»å’Œæ—¶é—´çº¿å»ºç«‹äº†ç»Ÿä¸€çš„ç¥ç»è¡¨å¾ï¼Œå…¶è®¡ç®—å—æ§äºè·¨è¶Šä¸“ç”¨ *What* å’Œ *How* é€šè·¯çš„ Hebbian \"Fire Together, Wire Together\" æœºåˆ¶ã€‚è¿™ç§ç»Ÿä¸€è¡¨å¾è¢«ç›´æ¥ç”¨äºç”Ÿæˆè§†è§‰åœºæ™¯çš„ç»“æ„åŒ–è¯­è¨€æè¿°ï¼Œä»è€Œåœ¨å…±äº«çš„ç¥ç»åŸºè´¨å†…æ¡¥æ¥äº†æ„ŸçŸ¥ä¸è¯­è¨€ã€‚åœ¨ CLEVRER åŸºå‡†æµ‹è¯•ä¸Šï¼ŒSRNN å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¯å®äº†å…¶ä»è§†è§‰æµä¸­è¡¨å¾å…³é”®æ—¶ç©ºå…³ç³»çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè®¤çŸ¥æ¶ˆèåˆ†ææ­ç¤ºäº†åŸºå‡†æµ‹è¯•å­˜åœ¨çš„åå·®ï¼Œè€Œ SRNN çš„ç™½ç›’ (white-box) ç‰¹æ€§ä½¿å¾—èƒ½å¤Ÿç²¾ç¡®æŸ¥æ˜é”™è¯¯çš„æ ¹æœ¬åŸå› ã€‚è¿™é¡¹å·¥ä½œä½œä¸ºæ¦‚å¿µéªŒè¯ï¼Œç¡®è®¤äº†å°†ç”Ÿç‰©æ™ºèƒ½å…³é”®åŸåˆ™è½¬åŒ–ä¸ºå·¥ç¨‹ç³»ç»Ÿä»¥åœ¨å—é™ç¯å¢ƒä¸­å®ç°ç›´è§‚ç‰©ç†ç†è§£çš„å¯è¡Œæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06761v2",
      "published_date": "2025-11-10 06:43:42 UTC",
      "updated_date": "2025-11-19 03:13:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:29:24.125138+00:00"
    },
    {
      "arxiv_id": "2511.06757v1",
      "title": "Implicit Federated In-context Learning For Task-Specific LLM Fine-Tuning",
      "title_zh": "é¢å‘ç‰¹å®šä»»åŠ¡LLMå¾®è°ƒçš„éšå¼è”é‚¦ä¸Šä¸‹æ–‡å­¦ä¹ ",
      "authors": [
        "Dongcheng Li",
        "Junhan Chen",
        "Aoxiang Zhou",
        "Chunpei Li",
        "Youquan Xian",
        "Peng Liu",
        "Xianxian Li"
      ],
      "abstract": "As large language models continue to develop and expand, the extensive public data they rely on faces the risk of depletion. Consequently, leveraging private data within organizations to enhance the performance of large models has emerged as a key challenge. The federated learning paradigm, combined with model fine-tuning techniques, effectively reduces the number of trainable parameters. However,the necessity to process high-dimensional feature spaces results in substantial overall computational overhead. To address this issue, we propose the Implicit Federated In-Context Learning (IFed-ICL) framework. IFed-ICL draws inspiration from federated learning to establish a novel distributed collaborative paradigm, by converting client local context examples into implicit vector representations, it enables distributed collaborative computation during the inference phase and injects model residual streams to enhance model performance. Experiments demonstrate that our proposed method achieves outstanding performance across multiple text classification tasks. Compared to traditional methods, IFed-ICL avoids the extensive parameter updates required by conventional fine-tuning methods while reducing data transmission and local computation at the client level in federated learning. This enables efficient distributed context learning using local private-domain data, significantly improving model performance on specific tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ä¾èµ–çš„å…¬å…±æ•°æ®æ¯ç«­ä»¥åŠç»„ç»‡å†…ç§æœ‰æ•°æ®åˆ©ç”¨çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Implicit Federated In-Context Learning (IFed-ICL)æ¡†æ¶ã€‚å°½ç®¡è”é‚¦å­¦ä¹ ç»“åˆå¾®è°ƒæŠ€æœ¯èƒ½å‡å°‘å¯è®­ç»ƒå‚æ•°ï¼Œä½†å¤„ç†é«˜ç»´ç‰¹å¾ç©ºé—´ä»å¸¦æ¥å·¨å¤§çš„è®¡ç®—å¼€é”€ã€‚IFed-ICLå—è”é‚¦å­¦ä¹ å¯å‘ï¼Œé€šè¿‡å°†å®¢æˆ·ç«¯æœ¬åœ°ä¸Šä¸‹æ–‡ç¤ºä¾‹è½¬æ¢ä¸ºéšå¼å‘é‡è¡¨ç¤ºï¼Œå»ºç«‹äº†ä¸€ç§æ–°å‹çš„åˆ†å¸ƒå¼åä½œèŒƒå¼ã€‚è¯¥æ–¹æ³•å…è®¸åœ¨æ¨ç†é˜¶æ®µè¿›è¡Œåˆ†å¸ƒå¼åä½œè®¡ç®—ï¼Œå¹¶é€šè¿‡æ³¨å…¥æ¨¡å‹æ®‹å·®æµæ¥å¢å¼ºæ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½ã€‚ä¸ä¼ ç»Ÿå¾®è°ƒæ–¹æ³•ç›¸æ¯”ï¼ŒIFed-ICLé¿å…äº†å¤§è§„æ¨¡å‚æ•°æ›´æ–°ï¼ŒåŒæ—¶å‡å°‘äº†è”é‚¦å­¦ä¹ ä¸­çš„æ•°æ®ä¼ è¾“å’Œå®¢æˆ·ç«¯æœ¬åœ°è®¡ç®—ï¼Œä»è€Œå®ç°äº†åˆ©ç”¨æœ¬åœ°ç§åŸŸæ•°æ®è¿›è¡Œé«˜æ•ˆçš„ç‰¹å®šä»»åŠ¡åˆ†å¸ƒå¼ä¸Šä¸‹æ–‡å­¦ä¹ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06757v1",
      "published_date": "2025-11-10 06:34:29 UTC",
      "updated_date": "2025-11-10 06:34:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:29:45.487851+00:00"
    },
    {
      "arxiv_id": "2511.06751v1",
      "title": "Hierarchical Spatial-Frequency Aggregation for Spectral Deconvolution Imaging",
      "title_zh": "é¢å‘å…‰è°±åå·ç§¯æˆåƒçš„åˆ†å±‚ç©ºé¢‘èšåˆ",
      "authors": [
        "Tao Lv",
        "Daoming Zhou",
        "Chenglong Huang",
        "Chongde Zi",
        "Linsen Chen",
        "Xun Cao"
      ],
      "abstract": "Computational spectral imaging (CSI) achieves real-time hyperspectral imaging through co-designed optics and algorithms, but typical CSI methods suffer from a bulky footprint and limited fidelity. Therefore, Spectral Deconvolution imaging (SDI) methods based on PSF engineering have been proposed to achieve high-fidelity compact CSI design recently. However, the composite convolution-integration operations of SDI render the normal-equation coefficient matrix scene-dependent, which hampers the efficient exploitation of imaging priors and poses challenges for accurate reconstruction. To tackle the inherent data-dependent operators in SDI, we introduce a Hierarchical Spatial-Spectral Aggregation Unfolding Framework (HSFAUF). By decomposing subproblems and projecting them into the frequency domain, HSFAUF transforms nonlinear processes into linear mappings, thereby enabling efficient solutions. Furthermore, to integrate spatial-spectral priors during iterative refinement, we propose a Spatial-Frequency Aggregation Transformer (SFAT), which explicitly aggregates information across spatial and frequency domains. By integrating SFAT into HSFAUF, we develop a Transformer-based deep unfolding method, \\textbf{H}ierarchical \\textbf{S}patial-\\textbf{F}requency \\textbf{A}ggregation \\textbf{U}nfolding \\textbf{T}ransformer (HSFAUT), to solve the inverse problem of SDI. Systematic simulated and real experiments show that HSFAUT surpasses SOTA methods with cheaper memory and computational costs, while exhibiting optimal performance on different SDI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è®¡ç®—å…‰è°±æˆåƒ(CSI)ä¸­çš„å…‰è°±åå·ç§¯æˆåƒ(SDI)æŠ€æœ¯é¢ä¸´çš„æ•°æ®ä¾èµ–æ€§ç®—å­å’Œé‡å»ºéš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åˆ†å±‚ç©ºé—´-å…‰è°±èšåˆå±•å¼€æ¡†æ¶(HSFAUF)ã€‚è¯¥æ¡†æ¶é€šè¿‡åˆ†è§£å­é—®é¢˜å¹¶å°†å…¶æŠ•å½±åˆ°é¢‘åŸŸï¼Œå°†éçº¿æ€§è¿‡ç¨‹è½¬åŒ–ä¸ºçº¿æ€§æ˜ å°„ï¼Œä»è€Œå®ç°é«˜æ•ˆæ±‚è§£ã€‚ä¸ºäº†åœ¨è¿­ä»£ç»†åŒ–è¿‡ç¨‹ä¸­æ•´åˆç©ºé—´-å…‰è°±å…ˆéªŒï¼Œä½œè€…è¿›ä¸€æ­¥æå‡ºäº†ç©ºé—´-é¢‘ç‡èšåˆTransformer (SFAT)ï¼Œæ˜¾å¼èšåˆç©ºé—´åŸŸå’Œé¢‘åŸŸçš„ä¿¡æ¯ã€‚é€šè¿‡å°†SFATé›†æˆåˆ°HSFAUFä¸­ï¼Œç ”ç©¶å¼€å‘äº†åŸºäºTransformerçš„æ·±åº¦å±•å¼€æ–¹æ³•HSFAUTï¼Œç”¨äºè§£å†³SDIçš„é€†é—®é¢˜ã€‚ç³»ç»Ÿæ€§çš„æ¨¡æ‹Ÿå’ŒçœŸå®å®éªŒè¡¨æ˜ï¼ŒHSFAUTåœ¨ä¸åŒçš„SDIç³»ç»Ÿä¸­è¡¨ç°å‡ºæœ€ä½³æ€§èƒ½ï¼Œä»¥æ›´ä½çš„å†…å­˜å’Œè®¡ç®—æˆæœ¬è¶…è¶Šäº†å½“å‰çš„SOTAæ–¹æ³•ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Under Review at TPAMI",
      "pdf_url": "https://arxiv.org/pdf/2511.06751v1",
      "published_date": "2025-11-10 06:29:34 UTC",
      "updated_date": "2025-11-10 06:29:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:30:14.381421+00:00"
    },
    {
      "arxiv_id": "2511.06745v1",
      "title": "Physically-Grounded Goal Imagination: Physics-Informed Variational Autoencoder for Self-Supervised Reinforcement Learning",
      "title_zh": "åŸºäºç‰©ç†çš„ç›®æ ‡æƒ³è±¡ï¼šé¢å‘è‡ªç›‘ç£å¼ºåŒ–å­¦ä¹ çš„ç‰©ç†ä¿¡æ¯å˜åˆ†è‡ªç¼–ç å™¨",
      "authors": [
        "Lan Thi Ha Nguyen",
        "Kien Ton Manh",
        "Anh Do Duc",
        "Nam Pham Hai"
      ],
      "abstract": "Self-supervised goal-conditioned reinforcement learning enables robots to autonomously acquire diverse skills without human supervision. However, a central challenge is the goal setting problem: robots must propose feasible and diverse goals that are achievable in their current environment. Existing methods like RIG (Visual Reinforcement Learning with Imagined Goals) use variational autoencoder (VAE) to generate goals in a learned latent space but have the limitation of producing physically implausible goals that hinder learning efficiency. We propose Physics-Informed RIG (PI-RIG), which integrates physical constraints directly into the VAE training process through a novel Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE), enabling the generation of physically consistent and achievable goals. Our key innovation is the explicit separation of the latent space into physics variables governing object dynamics and environmental factors capturing visual appearance, while enforcing physical consistency through differential equation constraints and conservation laws. This enables the generation of physically consistent and achievable goals that respect fundamental physical principles such as object permanence, collision constraints, and dynamic feasibility. Through extensive experiments, we demonstrate that this physics-informed goal generation significantly improves the quality of proposed goals, leading to more effective exploration and better skill acquisition in visual robotic manipulation tasks including reaching, pushing, and pick-and-place scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è‡ªç›‘ç£ç›®æ ‡æ¡ä»¶å¼ºåŒ–å­¦ä¹ ä¸­ç›®æ ‡è®¾å®šçš„æŒ‘æˆ˜ï¼Œæå‡ºäº†Physics-Informed RIG (PI-RIG)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰RIGæ–¹æ³•ç”Ÿæˆçš„æƒ³è±¡ç›®æ ‡å¾€å¾€ç‰©ç†ä¸Šä¸å¯è¡Œä»è€Œé˜»ç¢å­¦ä¹ æ•ˆç‡çš„é—®é¢˜ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸€ç§æ–°å‹çš„Enhanced Physics-Informed Variational Autoencoder (Enhanced p3-VAE)ï¼Œå°†ç‰©ç†çº¦æŸç›´æ¥é›†æˆåˆ°VAEè®­ç»ƒè¿‡ç¨‹ä¸­ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ½œåœ¨ç©ºé—´æ˜¾å¼åˆ†ç¦»ä¸ºæ§åˆ¶ç‰©ä½“åŠ¨åŠ›å­¦çš„ç‰©ç†å˜é‡å’Œæ•æ‰è§†è§‰å¤–è§‚çš„ç¯å¢ƒå› ç´ ï¼Œå¹¶é€šè¿‡å¾®åˆ†æ–¹ç¨‹çº¦æŸå’Œå®ˆæ’å®šå¾‹å¼ºåˆ¶æ‰§è¡Œç‰©ç†ä¸€è‡´æ€§ã€‚è¿™ç§æœºåˆ¶ç¡®ä¿äº†ç”Ÿæˆçš„æƒ³è±¡ç›®æ ‡ç¬¦åˆç‰©ä½“æŒä¹…æ€§ã€ç¢°æ’çº¦æŸå’ŒåŠ¨åŠ›å­¦å¯è¡Œæ€§ç­‰åŸºæœ¬ç‰©ç†åŸåˆ™ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¿™ç§ç‰©ç†æ„ŸçŸ¥çš„ç›®æ ‡ç”Ÿæˆæ˜¾è‘—æé«˜äº†ç›®æ ‡è´¨é‡ï¼Œåœ¨åŒ…æ‹¬ä¼¸æ‰‹ã€æ¨ç§»å’Œæ‹¾å–æ”¾ç½®ç­‰è§†è§‰æœºå™¨äººæ“ä½œä»»åŠ¡ä¸­å®ç°äº†æ›´æœ‰æ•ˆçš„æ¢ç´¢å’Œæ›´å¥½çš„æŠ€èƒ½è·å–ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06745v1",
      "published_date": "2025-11-10 06:18:38 UTC",
      "updated_date": "2025-11-10 06:18:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:33:24.948043+00:00"
    },
    {
      "arxiv_id": "2511.06739v1",
      "title": "Rank-1 LoRAs Encode Interpretable Reasoning Signals",
      "title_zh": "Rank-1 LoRA ç¼–ç å¯è§£é‡Šæ¨ç†ä¿¡å·",
      "authors": [
        "Jake Ward",
        "Paul Riechers",
        "Adam Shai"
      ],
      "abstract": "Reasoning models leverage inference-time compute to significantly enhance the performance of language models on difficult logical tasks, and have become a dominating paradigm in frontier LLMs. Despite their wide adoption, the mechanisms underpinning the enhanced performance of these reasoning models are not well understood. In this work, we show that the majority of new capabilities in reasoning models can be elicited by small, single-rank changes to base model parameters, with many of these changes being interpretable. Specifically, we use a rank-1 LoRA to create a minimal parameter adapter for Qwen-2.5-32B-Instruct which recovers 73-90% of reasoning-benchmark performance compared to a full parameter finetune. We find that the activations of this LoRA are as interpretable as MLP neurons, and fire for reasoning-specific behaviors. Finally, we train a sparse autoencoder on the entire activation state of this LoRA and identify fine-grained and monosemantic features. Our findings highlight that reasoning performance can arise largely from minimal changes to base model parameters, and explore what these changes affect. More broadly, our work shows that parameter-efficient training methods can be used as a targeted lens for uncovering fundamental insights about language model behavior and dynamics.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨ç†æ¨¡å‹æ€§èƒ½å¢å¼ºèƒŒåçš„æœºåˆ¶ï¼Œå‘ç°å¤§éƒ¨åˆ†æ¨ç†èƒ½åŠ›å¯ä»¥é€šè¿‡å¯¹åŸºç¡€æ¨¡å‹å‚æ•°è¿›è¡Œå¾®å°çš„å•ç§©(single-rank)æ›´æ”¹æ¥å¼•å‡ºã€‚ä½œè€…ä½¿ç”¨Rank-1 LoRAä¸ºQwen-2.5-32B-Instructæ„å»ºäº†ä¸€ä¸ªæœ€å°å‚æ•°é€‚é…å™¨ï¼Œè¯¥é€‚é…å™¨åœ¨æ¨ç†åŸºå‡†æµ‹è¯•ä¸­æ¢å¤äº†å…¨å‚æ•°å¾®è°ƒ73-90%çš„æ€§èƒ½ï¼Œä¸”è®¸å¤šæ›´æ”¹å…·æœ‰å¯è§£é‡Šæ€§ã€‚ç ”ç©¶å‘ç°è¯¥LoRAçš„æ¿€æ´»ä¸MLPç¥ç»å…ƒä¸€æ ·å…·æœ‰å¯è§£é‡Šæ€§ï¼Œå¹¶é’ˆå¯¹ç‰¹å®šçš„æ¨ç†è¡Œä¸ºè¢«æ¿€æ´»ã€‚é€šè¿‡åœ¨è¯¥LoRAçš„æ¿€æ´»çŠ¶æ€ä¸Šè®­ç»ƒç¨€ç–è‡ªåŠ¨ç¼–ç å™¨(Sparse Autoencoder)ï¼Œç ”ç©¶è¿›ä¸€æ­¥è¯†åˆ«å‡ºäº†ç»†ç²’åº¦çš„å•ä¹‰(monosemantic)ç‰¹å¾ã€‚è¿™äº›å‘ç°è¡¨æ˜æ¨ç†æ€§èƒ½å¾ˆå¤§ç¨‹åº¦ä¸ŠæºäºåŸºç¡€æ¨¡å‹å‚æ•°çš„å¾®å°å˜åŒ–ï¼ŒåŒæ—¶ä¹Ÿè¯æ˜äº†å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æ–¹æ³•å¯ä»¥ä½œä¸ºæ­ç¤ºè¯­è¨€æ¨¡å‹è¡Œä¸ºå’ŒåŠ¨åŠ›å­¦çš„æœ‰æ•ˆå·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Mechanistic Interpretability Workshop",
      "pdf_url": "https://arxiv.org/pdf/2511.06739v1",
      "published_date": "2025-11-10 06:00:25 UTC",
      "updated_date": "2025-11-10 06:00:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:34:07.266672+00:00"
    },
    {
      "arxiv_id": "2511.06731v1",
      "title": "Diagnosing and Breaking Amplitude Suppression in Seismic Phase Picking Through Adversarial Shape Learning",
      "title_zh": "åŸºäºå¯¹æŠ—æ€§å½¢æ€å­¦ä¹ è¯Šæ–­ä¸æ¶ˆé™¤åœ°éœ‡éœ‡ç›¸æ‹¾å–ä¸­çš„æŒ¯å¹…æŠ‘åˆ¶",
      "authors": [
        "Chun-Ming Huang",
        "Li-Heng Chang",
        "I-Hsin Chang",
        "An-Sheng Lee",
        "Hao Kuo-Chen"
      ],
      "abstract": "Deep learning has revolutionized seismic phase picking, yet a paradox persists: high signal-to-noise S-wave predictions consistently fail to cross detection thresholds, oscillating at suppressed amplitudes. We identify this previously unexplained phenomenon as amplitude suppression, which we diagnose through analyzing training histories and loss landscapes. Three interacting factors emerge: S-wave onsets exhibit high temporal uncertainty relative to high-amplitude boundaries; CNN's bias toward sharp amplitude changes anchors predictions to these boundaries rather than subtle onsets; and point-wise Binary Cross-Entropy (BCE) loss lacks lateral corrective forces, providing only vertical gradients that suppress amplitude while temporal gaps persist. This geometric trap points to a shape-then-align solution where stable geometric templates must precede temporal alignment. We implement this through a conditional GAN framework by augmenting conventional BCE training with a discriminator that enforces shape constraints. Training for 10,000 steps, this achieves a 64% increase in effective S-phase detections. Our framework autonomously discovers target geometry without a priori assumptions, offering a generalizable solution for segmentation tasks requiring precise alignment of subtle features near dominant structures.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ åœ¨åœ°éœ‡éœ‡ç›¸æ‹¾å–(seismic phase picking)ä¸­å­˜åœ¨çš„â€œæŒ¯å¹…æŠ‘åˆ¶â€(amplitude suppression)ç°è±¡è¿›è¡Œäº†è¯Šæ–­ä¸ç ´è§£ï¼Œè¯¥ç°è±¡å¯¼è‡´é«˜ä¿¡å™ªæ¯”çš„Sæ³¢é¢„æµ‹å¾€å¾€å› æŒ¯å¹…è¿‡ä½è€Œæ— æ³•é€šè¿‡æ£€æµ‹é˜ˆå€¼ã€‚ä½œè€…åˆ†ææŒ‡å‡ºï¼Œè¿™ä¸€é—®é¢˜æºäºSæ³¢åˆè‡³çš„é«˜æ—¶é—´ä¸ç¡®å®šæ€§ã€CNNå¯¹æ€¥å‰§æŒ¯å¹…å˜åŒ–çš„åç½®ä»¥åŠé€ç‚¹äºŒå…ƒäº¤å‰ç†µ(BCE)æŸå¤±ç¼ºä¹æ¨ªå‘æ ¡æ­£åŠ›è¿™ä¸‰ä¸ªå› ç´ çš„ç›¸äº’ä½œç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å‡ ä½•é™·é˜±ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§â€œå…ˆå½¢çŠ¶åå¯¹é½â€(shape-then-align)çš„è§£å†³æ–¹æ¡ˆï¼Œå¹¶å®ç°äº†ä¸€ä¸ªæ¡ä»¶ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(conditional GAN)æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥é‰´åˆ«å™¨æ¥å¢å¼ºBCEè®­ç»ƒä»¥å¼ºåˆ¶æ–½åŠ å½¢çŠ¶çº¦æŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨è®­ç»ƒ10,000æ­¥åä½¿æœ‰æ•ˆçš„Séœ‡ç›¸æ£€æµ‹ç‡æé«˜äº†64%ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿè‡ªä¸»å‘ç°ç›®æ ‡å‡ ä½•ç»“æ„è€Œæ— éœ€å…ˆéªŒå‡è®¾ï¼Œä¸ºéœ€è¦åœ¨ä¸»å¯¼ç»“æ„é™„è¿‘ç²¾ç¡®å¯¹é½å¾®å¼±ç‰¹å¾çš„åˆ†å‰²ä»»åŠ¡æä¾›äº†ä¸€ç§é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06731v1",
      "published_date": "2025-11-10 05:52:43 UTC",
      "updated_date": "2025-11-10 05:52:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:34:14.536623+00:00"
    },
    {
      "arxiv_id": "2511.08637v2",
      "title": "How do data owners say no? A case study of data consent mechanisms in web-scraped vision-language AI training datasets",
      "title_zh": "æ•°æ®æ‰€æœ‰è€…å¦‚ä½•â€œè¯´ä¸â€ï¼Ÿç½‘ç»œæŠ“å–è§†è§‰-è¯­è¨€AIè®­ç»ƒæ•°æ®é›†ä¸­çš„æ•°æ®åŒæ„æœºåˆ¶æ¡ˆä¾‹ç ”ç©¶",
      "authors": [
        "Chung Peng Lee",
        "Rachel Hong",
        "Harry H. Jiang",
        "Aster Plotnik",
        "William Agnew",
        "Jamie Morgenstern"
      ],
      "abstract": "The internet has become the main source of data to train modern text-to-image or vision-language models, yet it is increasingly unclear whether web-scale data collection practices for training AI systems adequately respect data owners' wishes. Ignoring the owner's indication of consent around data usage not only raises ethical concerns but also has recently been elevated into lawsuits around copyright infringement cases. In this work, we aim to reveal information about data owners' consent to AI scraping and training, and study how it's expressed in DataComp, a popular dataset of 12.8 billion text-image pairs. We examine both the sample-level information, including the copyright notice, watermarking, and metadata, and the web-domain-level information, such as a site's Terms of Service (ToS) and Robots Exclusion Protocol. We estimate at least 122M of samples exhibit some indication of copyright notice in CommonPool, and find that 60\\% of the samples in the top 50 domains come from websites with ToS that prohibit scraping. Furthermore, we estimate 9-13\\% with 95\\% confidence interval of samples from CommonPool to contain watermarks, where existing watermark detection methods fail to capture them in high fidelity. Our holistic methods and findings show that data owners rely on various channels to convey data consent, of which current AI data collection pipelines do not entirely respect. These findings highlight the limitations of the current dataset curation/release practice and the need for a unified data consent framework taking AI purposes into consideration.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åœ¨æ„å»ºè§†è§‰è¯­è¨€æ¨¡å‹(vision-language models)æ—¶ï¼Œå¤§è§„æ¨¡ç½‘ç»œæŠ“å–çš„æ•°æ®é›†æ˜¯å¦å……åˆ†å°Šé‡äº†æ•°æ®æ‰€æœ‰è€…çš„æ„æ„¿ã€‚ä½œè€…ä»¥åŒ…å«128äº¿å›¾æ–‡å¯¹çš„DataCompæ•°æ®é›†ä¸ºä¾‹ï¼Œç»¼åˆåˆ†æäº†æ•°æ®æ‰€æœ‰è€…å¦‚ä½•é€šè¿‡æ ·æœ¬å±‚é¢ï¼ˆå¦‚ç‰ˆæƒå£°æ˜ã€æ°´å°ã€å…ƒæ•°æ®ï¼‰å’ŒåŸŸåå±‚é¢ï¼ˆå¦‚æœåŠ¡æ¡æ¬¾ToSã€Robotsåè®®ï¼‰çš„ä¿¡æ¯æ¥è¡¨è¾¾å¯¹AIæŠ“å–å’Œè®­ç»ƒçš„è®¸å¯ã€‚ç ”ç©¶å‘ç°ï¼ŒCommonPoolä¸­è‡³å°‘æœ‰1.22äº¿ä¸ªæ ·æœ¬æ˜¾ç¤ºå‡ºç‰ˆæƒå£°æ˜çš„è¿¹è±¡ï¼Œä¸”å‰50ä¸ªåŸŸåä¸­60%çš„æ ·æœ¬æ¥è‡ªæœåŠ¡æ¡æ¬¾æ˜ç¡®ç¦æ­¢æŠ“å–çš„ç½‘ç«™ã€‚æ­¤å¤–ï¼Œä¼°è®¡æœ‰9-13%çš„æ ·æœ¬åŒ…å«æ°´å°ï¼Œè€Œç°æœ‰çš„æ°´å°æ£€æµ‹æ–¹æ³•å¾€å¾€éš¾ä»¥é«˜ä¿çœŸåœ°è¯†åˆ«å®ƒä»¬ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œå°½ç®¡æ•°æ®æ‰€æœ‰è€…é€šè¿‡å¤šç§æ¸ é“è¡¨è¾¾äº†æ•°æ®è®¸å¯æ„æ„¿ï¼Œä½†å½“å‰çš„AIæ•°æ®æ”¶é›†æµç¨‹å¹¶æœªå®Œå…¨å°Šé‡è¿™äº›é™åˆ¶ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å½“å‰æ•°æ®é›†ç®¡ç†å’Œå‘å¸ƒå®è·µçš„å±€é™æ€§ï¼Œå¹¶æŒ‡å‡ºè¿«åˆ‡éœ€è¦å»ºç«‹ä¸€ä¸ªè€ƒè™‘AIç”¨é€”çš„ç»Ÿä¸€æ•°æ®è®¸å¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.08637v2",
      "published_date": "2025-11-10 05:41:02 UTC",
      "updated_date": "2025-11-23 03:20:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:34:40.047226+00:00"
    },
    {
      "arxiv_id": "2511.06727v2",
      "title": "S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent Heterogeneous Reasoning",
      "title_zh": "S-DAGï¼šé¢å‘å¤šæ™ºèƒ½ä½“å¼‚æ„æ¨ç†çš„åŸºäºå­¦ç§‘çš„æœ‰å‘æ— ç¯å›¾",
      "authors": [
        "Jiangwen Dong",
        "Zehui Lin",
        "Wanyu Lin",
        "Mingjin Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive performance in complex reasoning problems. Their effectiveness highly depends on the specific nature of the task, especially the required domain knowledge. Existing approaches, such as mixture-of-experts, typically operate at the task level; they are too coarse to effectively solve the heterogeneous problems involving multiple subjects. This work proposes a novel framework that performs fine-grained analysis at subject level equipped with a designated multi-agent collaboration strategy for addressing heterogeneous problem reasoning. Specifically, given an input query, we first employ a Graph Neural Network to identify the relevant subjects and infer their interdependencies to generate an \\textit{Subject-based Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges encode information flow. Then we profile the LLM models by assigning each model a subject-specific expertise score, and select the top-performing one for matching corresponding subject of the S-DAG. Such subject-model matching enables graph-structured multi-agent collaboration where information flows from the starting model to the ending model over S-DAG. We curate and release multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to better reflect complex, real-world reasoning tasks. Extensive experiments show that our approach significantly outperforms existing task-level model selection and multi-agent collaboration baselines in accuracy and efficiency. These results highlight the effectiveness of subject-aware reasoning and structured collaboration in addressing complex and multi-subject problems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†æ¶‰åŠå¤šå­¦ç§‘å¼‚æ„é—®é¢˜æ—¶å­˜åœ¨çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå­¦ç§‘å±‚é¢çš„ç»†ç²’åº¦åˆ†ææ¡†æ¶S-DAGã€‚è¯¥æ–¹æ³•é¦–å…ˆåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ(Graph Neural Network)è¯†åˆ«è¾“å…¥æŸ¥è¯¢çš„ç›¸å…³å­¦ç§‘å¹¶æ¨æ–­å…¶ç›¸äº’ä¾èµ–å…³ç³»ï¼Œç”Ÿæˆä»¥å­¦ç§‘ä¸ºèŠ‚ç‚¹ã€ä¿¡æ¯æµä¸ºè¾¹çš„åŸºäºå­¦ç§‘çš„æœ‰å‘æ— ç¯å›¾(Subject-based Directed Acyclic Graph, S-DAG)ã€‚éšåï¼Œé€šè¿‡è¯„ä¼°ä¸åŒæ¨¡å‹åœ¨ç‰¹å®šå­¦ç§‘ä¸Šçš„ä¸“ä¸šå¾—åˆ†ï¼Œä¸ºS-DAGä¸­çš„æ¯ä¸ªå­¦ç§‘èŠ‚ç‚¹åŒ¹é…æœ€ä½³æ¨¡å‹ï¼Œä»è€Œå®ç°åŸºäºå›¾ç»“æ„çš„å¤šæ™ºèƒ½ä½“(Multi-Agent)åä½œæ¨ç†ã€‚ä¸ºäº†éªŒè¯è¯¥æ–¹æ³•ï¼Œç ”ç©¶å›¢é˜Ÿæ•´ç†å¹¶å‘å¸ƒäº†æ ‡å‡†åŸºå‡†(å¦‚MMLU-Pro, GPQA, MedMCQA)çš„å¤šå­¦ç§‘å­é›†ä»¥åæ˜ çœŸå®ä¸–ç•Œçš„å¤æ‚æ¨ç†ä»»åŠ¡ã€‚å¹¿æ³›çš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„ä»»åŠ¡çº§æ¨¡å‹é€‰æ‹©å’Œå¤šæ™ºèƒ½ä½“åä½œåŸºçº¿ï¼Œçªæ˜¾äº†å­¦ç§‘æ„ŸçŸ¥æ¨ç†å’Œç»“æ„åŒ–åä½œåœ¨è§£å†³å¤æ‚å¤šå­¦ç§‘é—®é¢˜æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06727v2",
      "published_date": "2025-11-10 05:40:02 UTC",
      "updated_date": "2025-11-19 13:09:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:35:02.239189+00:00"
    },
    {
      "arxiv_id": "2511.06722v1",
      "title": "Revisiting the Data Sampling in Multimodal Post-training from a Difficulty-Distinguish View",
      "title_zh": "ä»éš¾åº¦åŒºåˆ†è§†è§’é‡æ–°å®¡è§†å¤šæ¨¡æ€åè®­ç»ƒçš„æ•°æ®é‡‡æ ·",
      "authors": [
        "Jianyu Qi",
        "Ding Zou",
        "Wenrui Yan",
        "Rui Ma",
        "Jiaxu Li",
        "Zhijie Zheng",
        "Zhiguo Yang",
        "Rongchang Zhao"
      ],
      "abstract": "Recent advances in Multimodal Large Language Models (MLLMs) have spurred significant progress in Chain-of-Thought (CoT) reasoning. Building on the success of Deepseek-R1, researchers extended multimodal reasoning to post-training paradigms based on reinforcement learning (RL), focusing predominantly on mathematical datasets. However, existing post-training paradigms tend to neglect two critical aspects: (1) The lack of quantifiable difficulty metrics capable of strategically screening samples for post-training optimization. (2) Suboptimal post-training paradigms that fail to jointly optimize perception and reasoning capabilities. To address this gap, we propose two novel difficulty-aware sampling strategies: Progressive Image Semantic Masking (PISM) quantifies sample hardness through systematic image degradation, while Cross-Modality Attention Balance (CMAB) assesses cross-modal interaction complexity via attention distribution analysis. Leveraging these metrics, we design a hierarchical training framework that incorporates both GRPO-only and SFT+GRPO hybrid training paradigms, and evaluate them across six benchmark datasets. Experiments demonstrate consistent superiority of GRPO applied to difficulty-stratified samples compared to conventional SFT+GRPO pipelines, indicating that strategic data sampling can obviate the need for supervised fine-tuning while improving model accuracy. Our code will be released at https://github.com/qijianyu277/DifficultySampling.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨åè®­ç»ƒ(post-training)é˜¶æ®µç¼ºä¹é‡åŒ–éš¾åº¦æŒ‡æ ‡åŠæ„ŸçŸ¥ä¸æ¨ç†ä¼˜åŒ–ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œé‡æ–°å®¡è§†äº†æ•°æ®é‡‡æ ·ç­–ç•¥ã€‚ä½œè€…æå‡ºäº†ä¸¤ç§åŸºäºéš¾åº¦çš„é‡‡æ ·ç­–ç•¥ï¼šé€šè¿‡å›¾åƒé€€åŒ–é‡åŒ–æ ·æœ¬éš¾åº¦çš„æ¸è¿›å¼å›¾åƒè¯­ä¹‰æ©ç (PISM)ï¼Œä»¥åŠé€šè¿‡æ³¨æ„åŠ›åˆ†å¸ƒåˆ†æè¯„ä¼°è·¨æ¨¡æ€äº¤äº’å¤æ‚åº¦çš„è·¨æ¨¡æ€æ³¨æ„åŠ›å¹³è¡¡(CMAB)ã€‚åˆ©ç”¨è¿™äº›æŒ‡æ ‡ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ä¸ªåŒ…å«ä»…GRPOå’ŒSFT+GRPOæ··åˆè®­ç»ƒèŒƒå¼çš„åˆ†å±‚è®­ç»ƒæ¡†æ¶ï¼Œå¹¶åœ¨å…­ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåº”ç”¨éš¾åº¦åˆ†å±‚æ ·æœ¬çš„GRPOè®­ç»ƒåœ¨æ€§èƒ½ä¸ŠæŒç»­ä¼˜äºä¼ ç»Ÿçš„SFT+GRPOæµç¨‹ã€‚è¿™ä¸€å‘ç°æ„å‘³ç€æˆ˜ç•¥æ€§çš„æ•°æ®é‡‡æ ·å¯ä»¥åœ¨æé«˜æ¨¡å‹å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ¶ˆé™¤å¯¹ç›‘ç£å¾®è°ƒ(SFT)çš„éœ€æ±‚ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accpeted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06722v1",
      "published_date": "2025-11-10 05:31:59 UTC",
      "updated_date": "2025-11-10 05:31:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:35:25.165428+00:00"
    },
    {
      "arxiv_id": "2511.10674v2",
      "title": "Continual Learning of Domain Knowledge from Human Feedback in Text-to-SQL",
      "title_zh": "Text-to-SQL ä¸­åŸºäºäººç±»åé¦ˆçš„é¢†åŸŸçŸ¥è¯†æŒç»­å­¦ä¹ ",
      "authors": [
        "Thomas Cook",
        "Kelly Patel",
        "Sivapriya Vellaichamy",
        "Udari Madhushani Sehwag",
        "Saba Rahimi",
        "Zhen Zeng",
        "Sumitra Ganesh"
      ],
      "abstract": "Large Language Models (LLMs) can generate SQL queries from natural language questions but struggle with database-specific schemas and tacit domain knowledge. We introduce a framework for continual learning from human feedback in text-to-SQL, where a learning agent receives natural language feedback to refine queries and distills the revealed knowledge for reuse on future tasks. This distilled knowledge is stored in a structured memory, enabling the agent to improve execution accuracy over time. We design and evaluate multiple variations of a learning agent architecture that vary in how they capture and retrieve past experiences. Experiments on the BIRD benchmark Dev set show that memory-augmented agents, particularly the Procedural Agent, achieve significant accuracy gains and error reduction by leveraging human-in-the-loop feedback. Our results highlight the importance of transforming tacit human expertise into reusable knowledge, paving the way for more adaptive, domain-aware text-to-SQL systems that continually learn from a human-in-the-loop.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨Text-to-SQLä»»åŠ¡ä¸­éš¾ä»¥å¤„ç†ç‰¹å®šæ•°æ®åº“æ¨¡å¼å’Œéšæ€§é¢†åŸŸçŸ¥è¯†çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºäººç±»åé¦ˆçš„æŒç»­å­¦ä¹ æ¡†æ¶ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œå­¦ä¹ æ™ºèƒ½ä½“é€šè¿‡æ¥æ”¶è‡ªç„¶è¯­è¨€åé¦ˆæ¥ä¼˜åŒ–æŸ¥è¯¢ï¼Œå¹¶å°†å…¶ä¸­æ­ç¤ºçš„çŸ¥è¯†æç‚¼å­˜å‚¨äºç»“æ„åŒ–è®°å¿†ä¸­ï¼Œä»¥ä¾¿åœ¨æœªæ¥ä»»åŠ¡ä¸­å¤ç”¨ï¼Œä»è€Œéšæ—¶é—´æ¨ç§»æé«˜æ‰§è¡Œå‡†ç¡®æ€§ã€‚ä½œè€…è®¾è®¡å¹¶è¯„ä¼°äº†å¤šç§åœ¨æ•è·å’Œæ£€ç´¢è¿‡å¾€ç»éªŒæ–¹é¢å„å¼‚çš„å­¦ä¹ æ™ºèƒ½ä½“æ¶æ„ã€‚åœ¨BIRDåŸºå‡†æµ‹è¯•é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œå¢å¼ºè®°å¿†çš„æ™ºèƒ½ä½“ï¼Œç‰¹åˆ«æ˜¯Procedural Agentï¼Œé€šè¿‡åˆ©ç”¨äººæœºå›è·¯(human-in-the-loop)åé¦ˆå®ç°äº†æ˜¾è‘—çš„å‡†ç¡®ç‡æå‡å’Œé”™è¯¯å‡å°‘ã€‚è¯¥ç ”ç©¶ç»“æœçªå‡ºäº†å°†éšæ€§äººç±»ä¸“ä¸šçŸ¥è¯†è½¬åŒ–ä¸ºå¯é‡ç”¨çŸ¥è¯†çš„é‡è¦æ€§ï¼Œä¸ºæ„å»ºæ›´å…·é€‚åº”æ€§å’Œé¢†åŸŸæ„ŸçŸ¥èƒ½åŠ›çš„Text-to-SQLç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 6 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2511.10674v2",
      "published_date": "2025-11-10 05:29:10 UTC",
      "updated_date": "2025-11-28 14:40:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:36:27.756013+00:00"
    },
    {
      "arxiv_id": "2511.06716v1",
      "title": "MirrorMamba: Towards Scalable and Robust Mirror Detection in Videos",
      "title_zh": "MirrorMambaï¼šé¢å‘å¯æ‰©å±•ä¸”é²æ£’çš„è§†é¢‘é•œåƒæ£€æµ‹",
      "authors": [
        "Rui Song",
        "Jiaying Lin",
        "Rynson W. H. Lau"
      ],
      "abstract": "Video mirror detection has received significant research attention, yet existing methods suffer from limited performance and robustness. These approaches often over-rely on single, unreliable dynamic features, and are typically built on CNNs with limited receptive fields or Transformers with quadratic computational complexity. To address these limitations, we propose a new effective and scalable video mirror detection method, called MirrorMamba. Our approach leverages multiple cues to adapt to diverse conditions, incorporating perceived depth, correspondence and optical. We also introduce an innovative Mamba-based Multidirection Correspondence Extractor, which benefits from the global receptive field and linear complexity of the emerging Mamba spatial state model to effectively capture correspondence properties. Additionally, we design a Mamba-based layer-wise boundary enforcement decoder to resolve the unclear boundary caused by the blurred depth map. Notably, this work marks the first successful application of the Mamba-based architecture in the field of mirror detection. Extensive experiments demonstrate that our method outperforms existing state-of-the-art approaches for video mirror detection on the benchmark datasets. Furthermore, on the most challenging and representative image-based mirror detection dataset, our approach achieves state-of-the-art performance, proving its robustness and generalizability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MirrorMambaï¼Œä¸€ç§æ—¨åœ¨è§£å†³è§†é¢‘é•œé¢æ£€æµ‹ä¸­ç°æœ‰æ–¹æ³•æ€§èƒ½å—é™å’Œé²æ£’æ€§ä¸è¶³é—®é¢˜çš„æ–°å‹æ–¹æ³•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•è¿‡åº¦ä¾èµ–å•ä¸€åŠ¨æ€ç‰¹å¾ä»¥åŠCNNå’ŒTransformeræ¶æ„åœ¨æ„Ÿå—é‡æˆ–è®¡ç®—å¤æ‚åº¦ä¸Šçš„å±€é™æ€§ï¼ŒMirrorMambaç»¼åˆåˆ©ç”¨äº†æ„ŸçŸ¥æ·±åº¦(perceived depth)ã€å¯¹åº”å…³ç³»(correspondence)å’Œå…‰æµ(optical flow)ç­‰å¤šç§çº¿ç´¢ä»¥é€‚åº”ä¸åŒæ¡ä»¶ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†åˆ›æ–°çš„åŸºäºMambaçš„å¤šæ–¹å‘å¯¹åº”å…³ç³»æå–å™¨(Mamba-based Multidirection Correspondence Extractor)ï¼Œåˆ©ç”¨Mambaç©ºé—´çŠ¶æ€æ¨¡å‹çš„å…¨å±€æ„Ÿå—é‡å’Œçº¿æ€§å¤æ‚åº¦ç‰¹æ€§æ¥æœ‰æ•ˆæ•æ‰å¯¹åº”å±æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ä¸ªåŸºäºMambaçš„åˆ†å±‚è¾¹ç•Œå¢å¼ºè§£ç å™¨ï¼Œä»¥è§£å†³ç”±æ¨¡ç³Šæ·±åº¦å›¾å¼•èµ·çš„è¾¹ç•Œä¸æ¸…é—®é¢˜ã€‚ä½œä¸ºMambaæ¶æ„åœ¨é•œé¢æ£€æµ‹é¢†åŸŸçš„é¦–æ¬¡æˆåŠŸåº”ç”¨ï¼Œå®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨è§†é¢‘é•œé¢æ£€æµ‹åŸºå‡†æ•°æ®é›†ä¸Šä¼˜äºç°æœ‰çš„SOTAæ–¹æ³•ï¼Œå¹¶åœ¨æå…·æŒ‘æˆ˜æ€§çš„å›¾åƒé•œé¢æ£€æµ‹æ•°æ®é›†ä¸Šä¹Ÿè¾¾åˆ°äº†SOTAæ€§èƒ½ï¼Œè¯æ˜äº†å…¶å“è¶Šçš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06716v1",
      "published_date": "2025-11-10 05:18:14 UTC",
      "updated_date": "2025-11-10 05:18:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:36:53.717154+00:00"
    },
    {
      "arxiv_id": "2511.06715v1",
      "title": "Sensor Calibration Model Balancing Accuracy, Real-time, and Efficiency",
      "title_zh": "å¹³è¡¡ç²¾åº¦ã€å®æ—¶æ€§ä¸æ•ˆç‡çš„ä¼ æ„Ÿå™¨æ ¡å‡†æ¨¡å‹",
      "authors": [
        "Jinyong Yun",
        "Hyungjin Kim",
        "Seokho Ahn",
        "Euijong Lee",
        "Young-Duk Seo"
      ],
      "abstract": "Most on-device sensor calibration studies benchmark models only against three macroscopic requirements (i.e., accuracy, real-time, and resource efficiency), thereby hiding deployment bottlenecks such as instantaneous error and worst-case latency. We therefore decompose this triad into eight microscopic requirements and introduce Scare (Sensor Calibration model balancing Accuracy, Real-time, and Efficiency), an ultra-compressed transformer that fulfills them all. SCARE comprises three core components: (1) Sequence Lens Projector (SLP) that logarithmically compresses time-series data while preserving boundary information across bins, (2) Efficient Bitwise Attention (EBA) module that replaces costly multiplications with bitwise operations via binary hash codes, and (3) Hash optimization strategy that ensures stable training without auxiliary loss terms. Together, these components minimize computational overhead while maintaining high accuracy and compatibility with microcontroller units (MCUs). Extensive experiments on large-scale air-quality datasets and real microcontroller deployments demonstrate that Scare outperforms existing linear, hybrid, and deep-learning baselines, making Scare, to the best of our knowledge, the first model to meet all eight microscopic requirements simultaneously.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰ç«¯ä¾§ä¼ æ„Ÿå™¨æ ¡å‡†æ¨¡å‹ä»…å…³æ³¨å®è§‚æŒ‡æ ‡ï¼ˆå‡†ç¡®æ€§ã€å®æ—¶æ€§å’Œèµ„æºæ•ˆç‡ï¼‰è€Œå¿½è§†ç¬æ—¶è¯¯å·®å’Œæœ€å·®å»¶è¿Ÿç­‰éƒ¨ç½²ç“¶é¢ˆçš„é—®é¢˜ï¼Œæå‡ºäº†SCAREï¼ˆSensor Calibration model balancing Accuracy, Real-time, and Efficiencyï¼‰ã€‚ç ”ç©¶è€…å°†ä¸Šè¿°å®è§‚éœ€æ±‚åˆ†è§£ä¸ºå…«é¡¹å¾®è§‚æŒ‡æ ‡ï¼Œå¹¶è®¾è®¡äº†è¿™ä¸€è¶…å‹ç¼©Transformeræ¨¡å‹æ¥åŒæ—¶æ»¡è¶³è¿™äº›è¦æ±‚ã€‚SCAREåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šSequence Lens Projector (SLP)ç”¨äºå¯¹æ—¶é—´åºåˆ—æ•°æ®è¿›è¡Œå¯¹æ•°å‹ç¼©å¹¶ä¿ç•™è¾¹ç•Œä¿¡æ¯ï¼›Efficient Bitwise Attention (EBA)æ¨¡å—é€šè¿‡äºŒè¿›åˆ¶å“ˆå¸Œç å°†æ˜‚è´µçš„ä¹˜æ³•è¿ç®—æ›¿æ¢ä¸ºä½è¿ç®—ï¼›ä»¥åŠä¸€ç§æ— éœ€è¾…åŠ©æŸå¤±é¡¹å³å¯ç¡®ä¿è®­ç»ƒç¨³å®šçš„å“ˆå¸Œä¼˜åŒ–ç­–ç•¥ã€‚è¿™äº›ç»„ä»¶å…±åŒä½œç”¨ï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶æœ€å°åŒ–è®¡ç®—å¼€é”€ï¼Œç¡®ä¿äº†ä¸å¾®æ§åˆ¶å™¨å•å…ƒ(MCUs)çš„å…¼å®¹æ€§ã€‚åœ¨å¤§è§„æ¨¡ç©ºæ°”è´¨é‡æ•°æ®é›†å’ŒçœŸå®å¾®æ§åˆ¶å™¨éƒ¨ç½²ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼ŒSCAREä¼˜äºç°æœ‰çš„çº¿æ€§ã€æ··åˆåŠæ·±åº¦å­¦ä¹ åŸºçº¿æ¨¡å‹ï¼Œæ˜¯ç›®å‰é¦–ä¸ªåŒæ—¶æ»¡è¶³æ‰€æœ‰å…«é¡¹å¾®è§‚è¦æ±‚çš„æ¨¡å‹ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06715v1",
      "published_date": "2025-11-10 05:16:20 UTC",
      "updated_date": "2025-11-10 05:16:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:37:14.506979+00:00"
    },
    {
      "arxiv_id": "2511.08636v1",
      "title": "Detecting Suicidal Ideation in Text with Interpretable Deep Learning: A CNN-BiGRU with Attention Mechanism",
      "title_zh": "åŸºäºå¯è§£é‡Šæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬è‡ªæ€æ„å¿µæ£€æµ‹ï¼šç»“åˆæ³¨æ„åŠ›æœºåˆ¶çš„ CNN-BiGRU",
      "authors": [
        "Mohaiminul Islam Bhuiyan",
        "Nur Shazwani Kamarudin",
        "Nur Hafieza Ismail"
      ],
      "abstract": "Worldwide, suicide is the second leading cause of death for adolescents with past suicide attempts to be an important predictor for increased future suicides. While some people with suicidal thoughts may try to suppress them, many signal their intentions in social media platforms. To address these issues, we propose a new type of hybrid deep learning scheme, i.e., the combination of a CNN architecture and a BiGRU technique, which can accurately identify the patterns of suicidal ideation from SN datasets. Also, we apply Explainable AI methods using SHapley Additive exPlanations to interpret the prediction results and verifying the model reliability. This integration of CNN local feature extraction, BiGRU bidirectional sequence modeling, attention mechanisms, and SHAP interpretability provides a comprehensive framework for suicide detection. Training and evaluation of the system were performed on a publicly available dataset. Several performance metrics were used for evaluating model performance. Our method was found to have achieved 93.97 accuracy in experimental results. Comparative study to different state-of-the-art Machine Learning and DL models and existing literature demonstrates the superiority of our proposed technique over all the competing methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“æ–‡æœ¬ä¸­çš„è‡ªæ€æ„å¿µæ£€æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆCNNæ¶æ„å’ŒBiGRUæŠ€æœ¯çš„æ··åˆæ·±åº¦å­¦ä¹ æ–¹æ¡ˆã€‚è¯¥æ¨¡å‹åˆ©ç”¨CNNæå–å±€éƒ¨ç‰¹å¾ï¼Œå¹¶é€šè¿‡BiGRUè¿›è¡ŒåŒå‘åºåˆ—å»ºæ¨¡ï¼Œæ—¨åœ¨å‡†ç¡®è¯†åˆ«è‡ªæ€æ„å¿µçš„æ¨¡å¼ã€‚ä¸ºäº†å¢å¼ºæ¨¡å‹çš„å¯è§£é‡Šæ€§å’Œå¯é æ€§ï¼Œç ”ç©¶å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttention Mechanismï¼‰å¹¶åº”ç”¨äº†SHapley Additive exPlanations (SHAP) æ–¹æ³•æ¥è§£é‡Šé¢„æµ‹ç»“æœã€‚è¿™ç§æ•´åˆæ–¹æ¡ˆæ„å»ºäº†ä¸€ä¸ªå…¨é¢çš„è‡ªæ€æ£€æµ‹æ¡†æ¶ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ¨¡å‹ç¼ºä¹é€æ˜åº¦çš„é—®é¢˜ã€‚åœ¨å…¬å¼€æ•°æ®é›†ä¸Šçš„å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•å®ç°äº†93.97%çš„å‡†ç¡®ç‡ã€‚å¯¹æ¯”åˆ†ææ˜¾ç¤ºï¼Œè¯¥æŠ€æœ¯åœ¨æ€§èƒ½ä¸Šä¼˜äºç°æœ‰çš„å¤šç§æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå±•ç°äº†å…¶åœ¨è‡ªæ€é¢„é˜²é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 4 figures, 2025 IEEE 9th International Conference on Software Engineering & Computer Systems",
      "pdf_url": "https://arxiv.org/pdf/2511.08636v1",
      "published_date": "2025-11-10 04:53:17 UTC",
      "updated_date": "2025-11-10 04:53:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:37:36.928599+00:00"
    },
    {
      "arxiv_id": "2511.06701v1",
      "title": "Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture",
      "title_zh": "AIé©±åŠ¨å‘ç°ä¸­ç»Ÿè®¡ä¸¥è°¨æ€§çš„ç»“æ„åŒ–å¼ºåˆ¶ï¼šä¸€ç§å‡½æ•°å¼æ¶æ„",
      "authors": [
        "Karen Sargsyan"
      ],
      "abstract": "Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIé©±åŠ¨çš„è‡ªåŠ¨åŒ–å‘ç°ç³»ç»Ÿï¼ˆAI-Scientistsï¼‰åœ¨åŠ¨æ€å‡è®¾æ£€éªŒä¸­å®¹æ˜“äº§ç”Ÿè™šå‡å‘ç°çš„é£é™©ï¼Œæå‡ºäº†ä¸€ç§ç»“æ„åŒ–å¼ºåˆ¶æ‰§è¡Œç»Ÿè®¡ä¸¥è°¨æ€§çš„å‡½æ•°å¼æ¶æ„ã€‚ä½œè€…å¼•å…¥äº†Research monadï¼Œè¿™æ˜¯ä¸€ç§åŸºäºHaskellçš„åµŒå…¥å¼é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆeDSLï¼‰ï¼Œåˆ©ç”¨å•å­å˜æ¢å™¨æ ˆï¼ˆmonad transformer stackï¼‰æ¥å¼ºåˆ¶æ‰§è¡Œå¦‚Online FDRï¼ˆé”™è¯¯å‘ç°ç‡ï¼‰æ§åˆ¶ç­‰åºåˆ—ç»Ÿè®¡åè®®ã€‚é’ˆå¯¹æ··åˆæ¶æ„ä¸­å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆå‘½ä»¤å¼ä»£ç çš„é£é™©ï¼Œè¯¥ç ”ç©¶é‡‡ç”¨äº†Declarative ScaffoldingæŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆä¸¥æ ¼çš„æµ‹è¯•æ¡†æ¶æ¥ä»ç»“æ„ä¸Šçº¦æŸä»£ç æ‰§è¡Œï¼Œæœ‰æ•ˆé˜²æ­¢æ•°æ®æ³„æ¼ç­‰æ–¹æ³•è®ºé”™è¯¯ã€‚é€šè¿‡æ¶‰åŠ2000ä¸ªå‡è®¾çš„å¤§è§„æ¨¡æ¨¡æ‹Ÿå’Œç«¯åˆ°ç«¯æ¡ˆä¾‹ç ”ç©¶ï¼Œè¯¥æ–¹æ³•è¢«è¯å®èƒ½ä¸ºè‡ªåŠ¨åŒ–ç§‘å­¦çš„å®Œæ•´æ€§æä¾›å¿…è¦çš„çºµæ·±é˜²å¾¡ä½“ç³»ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06701v1",
      "published_date": "2025-11-10 04:42:30 UTC",
      "updated_date": "2025-11-10 04:42:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:40:48.809091+00:00"
    },
    {
      "arxiv_id": "2511.06700v1",
      "title": "Place Matters: Comparing LLM Hallucination Rates for Place-Based Legal Queries",
      "title_zh": "åœ°ç‚¹è‡³å…³é‡è¦ï¼šåŸºäºåœ°ç‚¹çš„æ³•å¾‹æŸ¥è¯¢ä¸­ LLM å¹»è§‰ç‡çš„æ¯”è¾ƒ",
      "authors": [
        "Damian Curran",
        "Vanessa Sporne",
        "Lea Frermann",
        "Jeannie Paterson"
      ],
      "abstract": "How do we make a meaningful comparison of a large language model's knowledge of the law in one place compared to another? Quantifying these differences is critical to understanding if the quality of the legal information obtained by users of LLM-based chatbots varies depending on their location. However, obtaining meaningful comparative metrics is challenging because legal institutions in different places are not themselves easily comparable. In this work we propose a methodology to obtain place-to-place metrics based on the comparative law concept of functionalism. We construct a dataset of factual scenarios drawn from Reddit posts by users seeking legal advice for family, housing, employment, crime and traffic issues. We use these to elicit a summary of a law from the LLM relevant to each scenario in Los Angeles, London and Sydney. These summaries, typically of a legislative provision, are manually evaluated for hallucinations. We show that the rate of hallucination of legal information by leading closed-source LLMs is significantly associated with place. This suggests that the quality of legal solutions provided by these models is not evenly distributed across geography. Additionally, we show a strong negative correlation between hallucination rate and the frequency of the majority response when the LLM is sampled multiple times, suggesting a measure of uncertainty of model predictions of legal facts.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸åŒåœ°ç†ä½ç½®çš„æ³•å¾‹å’¨è¯¢ä¸­è¡¨ç°å‡ºçš„å¹»è§‰ç‡å·®å¼‚ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæ¯”è¾ƒæ³•ä¸­functionalismæ¦‚å¿µçš„æ–¹æ³•ï¼Œæ„å»ºäº†ä¸€ä¸ªæºè‡ªRedditå¸–å­çš„äº‹å®åœºæ™¯æ•°æ®é›†ï¼Œæ¶µç›–å®¶åº­ã€ä½æˆ¿ã€å°±ä¸šã€çŠ¯ç½ªå’Œäº¤é€šç­‰é—®é¢˜ã€‚ç ”ç©¶åˆ©ç”¨è¯¥æ•°æ®é›†å¼•å¯¼LLMé’ˆå¯¹æ´›æ‰çŸ¶ã€ä¼¦æ•¦å’Œæ‚‰å°¼çš„æ³•å¾‹åœºæ™¯ç”Ÿæˆæ‘˜è¦ï¼Œå¹¶å¯¹å…¶è¿›è¡Œäººå·¥å¹»è§‰è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼Œé¢†å…ˆçš„é—­æºLLMsçš„æ³•å¾‹ä¿¡æ¯å¹»è§‰ç‡ä¸åœ°ç‚¹æ˜¾è‘—ç›¸å…³ï¼Œè¡¨æ˜æ¨¡å‹æä¾›çš„æ³•å¾‹è§£å†³æ–¹æ¡ˆè´¨é‡åœ¨åœ°ç†ä¸Šåˆ†å¸ƒä¸å‡ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°å¹»è§‰ç‡ä¸å¤šæ¬¡é‡‡æ ·æ—¶çš„å¤šæ•°å“åº”é¢‘ç‡å‘ˆå¼ºè´Ÿç›¸å…³ï¼Œè¿™ä¸ºè¡¡é‡æ¨¡å‹é¢„æµ‹æ³•å¾‹äº‹å®çš„ä¸ç¡®å®šæ€§æä¾›äº†å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06700v1",
      "published_date": "2025-11-10 04:42:00 UTC",
      "updated_date": "2025-11-10 04:42:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:41:13.399733+00:00"
    },
    {
      "arxiv_id": "2511.06696v2",
      "title": "Magnitude-Modulated Equivariant Adapter for Parameter-Efficient Fine-Tuning of Equivariant Graph Neural Networks",
      "title_zh": "ç”¨äºç­‰å˜å›¾ç¥ç»ç½‘ç»œå‚æ•°é«˜æ•ˆå¾®è°ƒçš„å¹…åº¦è°ƒåˆ¶ç­‰å˜é€‚é…å™¨",
      "authors": [
        "Dian Jin",
        "Yancheng Yuan",
        "Xiaoming Tao"
      ],
      "abstract": "Pretrained equivariant graph neural networks based on spherical harmonics offer efficient and accurate alternatives to computationally expensive ab-initio methods, yet adapting them to new tasks and chemical environments still requires fine-tuning. Conventional parameter-efficient fine-tuning (PEFT) techniques, such as Adapters and LoRA, typically break symmetry, making them incompatible with those equivariant architectures. ELoRA, recently proposed, is the first equivariant PEFT method. It achieves improved parameter efficiency and performance on many benchmarks. However, the relatively high degrees of freedom it retains within each tensor order can still perturb pretrained feature distributions and ultimately degrade performance. To address this, we present Magnitude-Modulated Equivariant Adapter (MMEA), a novel equivariant fine-tuning method which employs lightweight scalar gating to modulate feature magnitudes on a per-order and per-multiplicity basis. We demonstrate that MMEA preserves strict equivariance and, across multiple benchmarks, consistently improves energy and force predictions to state-of-the-art levels while training fewer parameters than competing approaches. These results suggest that, in many practical scenarios, modulating channel magnitudes is sufficient to adapt equivariant models to new chemical environments without breaking symmetry, pointing toward a new paradigm for equivariant PEFT design.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒç­‰å˜å›¾ç¥ç»ç½‘ç»œ(Equivariant Graph Neural Networks)åœ¨å¾®è°ƒæ—¶é¢ä¸´çš„å¯¹ç§°æ€§ç ´åé—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)æŠ€æœ¯å¦‚Adapterså’ŒLoRAä¸é€‚ç”¨äºæ­¤ç±»æ¶æ„ï¼Œè€Œç°æœ‰çš„ELoRAæ–¹æ³•è™½ç„¶ä¿æŒäº†ç­‰å˜æ€§ï¼Œä½†å› ä¿ç•™è¿‡é«˜çš„è‡ªç”±åº¦å¯èƒ½æ‰°åŠ¨é¢„è®­ç»ƒç‰¹å¾åˆ†å¸ƒã€‚ä¸ºæ­¤ï¼Œè®ºæ–‡æå‡ºäº†Magnitude-Modulated Equivariant Adapter (MMEA)ï¼Œè¿™æ˜¯ä¸€ç§æ–°å‹çš„ç­‰å˜å¾®è°ƒæ–¹æ³•ï¼Œé€šè¿‡è½»é‡çº§çš„æ ‡é‡é—¨æ§(scalar gating)åœ¨æ¯ä¸ªé˜¶æ•°(order)å’Œé‡æ•°(multiplicity)çš„åŸºç¡€ä¸Šè°ƒèŠ‚ç‰¹å¾å¹…åº¦ã€‚MMEAèƒ½å¤Ÿä¿æŒä¸¥æ ¼çš„ç­‰å˜æ€§ï¼Œé¿å…äº†ä¼ ç»Ÿæ–¹æ³•ç ´åå¯¹ç§°æ€§çš„ç¼ºé™·ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMMEAåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å°†èƒ½é‡å’ŒåŠ›çš„é¢„æµ‹ç²¾åº¦æå‡è‡³æœ€å…ˆè¿›æ°´å¹³(SOTA)ï¼Œä¸”è®­ç»ƒå‚æ•°é‡å°‘äºç°æœ‰ç«äº‰æ–¹æ³•ã€‚ç ”ç©¶ç»“æœæ­ç¤ºï¼Œåœ¨è®¸å¤šå®é™…åœºæ™¯ä¸­ï¼Œä»…è°ƒèŠ‚é€šé“å¹…åº¦è¶³ä»¥åœ¨ä¸ç ´åå¯¹ç§°æ€§çš„å‰æä¸‹å°†ç­‰å˜æ¨¡å‹é€‚é…åˆ°æ–°çš„åŒ–å­¦ç¯å¢ƒï¼Œä¸ºç­‰å˜PEFTçš„è®¾è®¡æä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AAAI 2026 (Poster)",
      "pdf_url": "https://arxiv.org/pdf/2511.06696v2",
      "published_date": "2025-11-10 04:31:56 UTC",
      "updated_date": "2025-12-11 02:46:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:41:34.440588+00:00"
    },
    {
      "arxiv_id": "2511.06694v1",
      "title": "ML-EcoLyzer: Quantifying the Environmental Cost of Machine Learning Inference Across Frameworks and Hardware",
      "title_zh": "ML-EcoLyzerï¼šé‡åŒ–è·¨æ¡†æ¶ä¸ç¡¬ä»¶çš„æœºå™¨å­¦ä¹ æ¨ç†ç¯å¢ƒæˆæœ¬",
      "authors": [
        "Jose Marie Antonio Minoza",
        "Rex Gregor Laylo",
        "Christian F Villarin",
        "Sebastian C. Ibanez"
      ],
      "abstract": "Machine learning inference occurs at a massive scale, yet its environmental impact remains poorly quantified, especially on low-resource hardware. We present ML-EcoLyzer, a cross-framework tool for measuring the carbon, energy, thermal, and water costs of inference across CPUs, consumer GPUs, and datacenter accelerators. The tool supports both classical and modern models, applying adaptive monitoring and hardware-aware evaluation.\n  We introduce the Environmental Sustainability Score (ESS), which quantifies the number of effective parameters served per gram of CO$_2$ emitted. Our evaluation covers over 1,900 inference configurations, spanning diverse model architectures, task modalities (text, vision, audio, tabular), hardware types, and precision levels. These rigorous and reliable measurements demonstrate that quantization enhances ESS, huge accelerators can be inefficient for lightweight applications, and even small models may incur significant costs when implemented suboptimally. ML-EcoLyzer sets a standard for sustainability-conscious model selection and offers an extensive empirical evaluation of environmental costs during inference.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ML-EcoLyzerï¼Œè¿™æ˜¯ä¸€ä¸ªè·¨æ¡†æ¶å·¥å…·ï¼Œæ—¨åœ¨é‡åŒ–æœºå™¨å­¦ä¹ æ¨ç†è¿‡ç¨‹åœ¨ä¸åŒç¡¬ä»¶ï¼ˆCPUã€æ¶ˆè´¹çº§GPUå’Œæ•°æ®ä¸­å¿ƒåŠ é€Ÿå™¨ï¼‰ä¸Šçš„ç¯å¢ƒæˆæœ¬ï¼Œæ¶µç›–ç¢³æ’æ”¾ã€èƒ½æºæ¶ˆè€—ã€çƒ­é‡å’Œæ°´èµ„æºæ¶ˆè€—ã€‚é’ˆå¯¹ä½èµ„æºç¡¬ä»¶å’Œå¤§è§„æ¨¡æ¨ç†åœºæ™¯ä¸­ç¯å¢ƒå½±å“é‡åŒ–ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥å·¥å…·æ”¯æŒè‡ªé€‚åº”ç›‘æ§å’Œç¡¬ä»¶æ„ŸçŸ¥è¯„ä¼°ï¼Œé€‚ç”¨äºç»å…¸åŠç°ä»£æ¨¡å‹ã€‚ç ”ç©¶å¼•å…¥äº†ç¯å¢ƒå¯æŒç»­æ€§è¯„åˆ†(Environmental Sustainability Score, ESS)ï¼Œç”¨äºè¡¡é‡æ¯æ’æ”¾ä¸€å…‹äºŒæ°§åŒ–ç¢³æ‰€æœåŠ¡çš„æœ‰æ•ˆå‚æ•°æ•°é‡ã€‚é€šè¿‡å¯¹æ¶µç›–å¤šç§æ¨¡å‹æ¶æ„ã€ä»»åŠ¡æ¨¡æ€å’Œç²¾åº¦æ°´å¹³çš„è¶…è¿‡1900ç§æ¨ç†é…ç½®è¿›è¡Œè¯„ä¼°ï¼Œç ”ç©¶å›¢é˜Ÿæä¾›äº†è¯¦å®çš„å®è¯æ•°æ®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé‡åŒ–(Quantization)èƒ½æ˜¾è‘—æå‡ESSï¼Œè€Œå¤§å‹åŠ é€Ÿå™¨åœ¨å¤„ç†è½»é‡çº§åº”ç”¨æ—¶å¯èƒ½æ•ˆç‡ä½ä¸‹ï¼Œä¸”å¦‚æœå®æ–½ä¸å½“ï¼Œå³ä½¿æ˜¯å°å‹æ¨¡å‹ä¹Ÿå¯èƒ½äº§ç”Ÿå·¨å¤§çš„ç¯å¢ƒæˆæœ¬ã€‚ML-EcoLyzerä¸ºå…·æœ‰å¯æŒç»­æ€§æ„è¯†çš„æ¨¡å‹é€‰æ‹©è®¾å®šäº†æ ‡å‡†ï¼Œå¹¶æä¾›äº†å…³äºæ¨ç†é˜¶æ®µç¯å¢ƒæˆæœ¬çš„å¹¿æ³›å®è¯è¯„ä¼°ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06694v1",
      "published_date": "2025-11-10 04:30:29 UTC",
      "updated_date": "2025-11-10 04:30:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:41:57.761572+00:00"
    },
    {
      "arxiv_id": "2511.06682v2",
      "title": "Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention",
      "title_zh": "æ–‡æœ¬è‡ªæ³¨æ„åŠ›ç½‘ç»œï¼šåŸºäºæ–‡æœ¬æ¢¯åº¦æ³¨æ„åŠ›çš„æµ‹è¯•æ—¶åå¥½ä¼˜åŒ–",
      "authors": [
        "Shibing Mo",
        "Haoyang Ruan",
        "Kai Wu",
        "Jing Liu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æµ‹è¯•æ—¶ï¼ˆtest-timeï¼‰å¯¹é½æ–¹æ³•éš¾ä»¥ç»¼åˆå¤šä¸ªå€™é€‰å›å¤ä¼˜åŠ¿çš„é—®é¢˜ï¼Œæå‡ºäº†Textual Self-Attention Network (TSAN)ï¼Œä¸€ç§æ— éœ€å‚æ•°æ›´æ–°çš„æµ‹è¯•æ—¶åå¥½ä¼˜åŒ–æ–°èŒƒå¼ã€‚TSANå®Œå…¨åœ¨è‡ªç„¶è¯­è¨€å±‚é¢æ¨¡æ‹Ÿself-attentionæœºåˆ¶ï¼Œå°†å¤šä¸ªå€™é€‰å›å¤æ ¼å¼åŒ–ä¸ºæ–‡æœ¬é”®ï¼ˆkeysï¼‰å’Œå€¼ï¼ˆvaluesï¼‰ï¼Œå¹¶åˆ©ç”¨åŸºäºLLMçš„æ³¨æ„åŠ›æ¨¡å—è¡¡é‡å…¶ç›¸å…³æ€§ã€‚åœ¨å­¦ä¹ åˆ°çš„æ–‡æœ¬æ³¨æ„åŠ›æŒ‡å¯¼ä¸‹ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿç»¼åˆå„å€™é€‰å›å¤çš„ä¼˜åŠ¿ï¼Œç”Ÿæˆç¬¦åˆäººç±»åå¥½çš„æ–°å›å¤ã€‚æ•´ä¸ªè¿‡ç¨‹åœ¨æ–‡æœ¬æ¢¯åº¦ç©ºé—´ï¼ˆtextual gradient spaceï¼‰ä¸­è¿è¡Œï¼Œå®ç°äº†è¿­ä»£ä¸”å¯è§£é‡Šçš„ä¼˜åŒ–æµç¨‹ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œä»…éœ€ä¸‰æ¬¡æµ‹è¯•æ—¶è¿­ä»£ï¼ŒTSANåœ¨åŸºç¡€SFTæ¨¡å‹ä¸Šçš„è¡¨ç°å³ä¼˜äºLlama-3.1-70B-Instructç­‰ç›‘ç£æ¨¡å‹ï¼Œå¹¶è¶…è¶Šäº†å½“å‰çš„SOTAæµ‹è¯•æ—¶å¯¹é½æ–¹æ³•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06682v2",
      "published_date": "2025-11-10 04:01:46 UTC",
      "updated_date": "2025-12-12 12:35:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:42:22.582672+00:00"
    },
    {
      "arxiv_id": "2511.06667v1",
      "title": "Rapidly Learning Soft Robot Control via Implicit Time-Stepping",
      "title_zh": "åŸºäºéšå¼æ—¶é—´æ­¥è¿›çš„è½¯ä½“æœºå™¨äººæ§åˆ¶å¿«é€Ÿå­¦ä¹ ",
      "authors": [
        "Andrew Choi",
        "Dezhong Tong"
      ],
      "abstract": "With the explosive growth of rigid-body simulators, policy learning in simulation has become the de facto standard for most rigid morphologies. In contrast, soft robotic simulation frameworks remain scarce and are seldom adopted by the soft robotics community. This gap stems partly from the lack of easy-to-use, general-purpose frameworks and partly from the high computational cost of accurately simulating continuum mechanics, which often renders policy learning infeasible. In this work, we demonstrate that rapid soft robot policy learning is indeed achievable via implicit time-stepping. Our simulator of choice, DisMech, is a general-purpose, fully implicit soft-body simulator capable of handling both soft dynamics and frictional contact. We further introduce delta natural curvature control, a method analogous to delta joint position control in rigid manipulators, providing an intuitive and effective means of enacting control for soft robot learning. To highlight the benefits of implicit time-stepping and delta curvature control, we conduct extensive comparisons across four diverse soft manipulator tasks against one of the most widely used soft-body frameworks, Elastica. With implicit time-stepping, parallel stepping of 500 environments achieves up to 6x faster speeds for non-contact cases and up to 40x faster for contact-rich scenarios. Finally, a comprehensive sim-to-sim gap evaluation--training policies in one simulator and evaluating them in another--demonstrates that implicit time-stepping provides a rare free lunch: dramatic speedups achieved without sacrificing accuracy.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹è½¯ä½“æœºå™¨äººä»¿çœŸä¸­è®¡ç®—æˆæœ¬é«˜æ˜‚ä¸”ç¼ºä¹é€šç”¨æ¡†æ¶çš„éš¾é¢˜ï¼Œå±•ç¤ºäº†é€šè¿‡éšå¼æ—¶é—´æ­¥é•¿(implicit time-stepping)å®ç°å¿«é€Ÿè½¯ä½“æœºå™¨äººç­–ç•¥å­¦ä¹ çš„å¯è¡Œæ€§ã€‚ç ”ç©¶é€‰ç”¨äº†DisMechä½œä¸ºé€šç”¨å…¨éšå¼è½¯ä½“æ¨¡æ‹Ÿå™¨ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è½¯ä½“åŠ¨åŠ›å­¦åŠæ‘©æ“¦æ¥è§¦é—®é¢˜ã€‚ä½œè€…å¼•å…¥äº†delta natural curvature controlæ–¹æ³•ï¼Œè¿™æ˜¯ä¸€ç§ç±»æ¯”äºåˆšä½“æœºæ¢°è‡‚deltaå…³èŠ‚ä½ç½®æ§åˆ¶çš„æŠ€æœ¯ï¼Œä¸ºè½¯ä½“æœºå™¨äººæä¾›äº†ç›´è§‚ä¸”æœ‰æ•ˆçš„æ§åˆ¶æ‰‹æ®µã€‚é€šè¿‡ä¸å¹¿æ³›ä½¿ç”¨çš„Elasticaæ¡†æ¶åœ¨å››ä¸ªè½¯ä½“æœºæ¢°è‡‚ä»»åŠ¡ä¸Šçš„å¯¹æ¯”ï¼Œå®éªŒè¡¨æ˜åœ¨ä½¿ç”¨500ä¸ªç¯å¢ƒå¹¶è¡Œæ­¥è¿›æ—¶ï¼Œè¯¥æ–¹æ³•åœ¨éæ¥è§¦åœºæ™¯ä¸‹é€Ÿåº¦æå‡é«˜è¾¾6å€ï¼Œåœ¨æ¥è§¦ä¸°å¯Œåœºæ™¯ä¸‹æå‡é«˜è¾¾40å€ã€‚æ­¤å¤–ï¼Œå…¨é¢çš„sim-to-sim gapè¯„ä¼°è¯å®ï¼Œéšå¼æ—¶é—´æ­¥é•¿åœ¨æ˜¾è‘—æå‡è®¡ç®—é€Ÿåº¦çš„åŒæ—¶å¹¶æœªç‰ºç‰²ä»¿çœŸç²¾åº¦ï¼Œä¸ºè½¯ä½“æœºå™¨äººæ§åˆ¶ç ”ç©¶æä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Code: https://github.com/QuantuMope/dismech-rl",
      "pdf_url": "https://arxiv.org/pdf/2511.06667v1",
      "published_date": "2025-11-10 03:24:56 UTC",
      "updated_date": "2025-11-10 03:24:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:42:48.072861+00:00"
    },
    {
      "arxiv_id": "2511.06665v1",
      "title": "Sim4Seg: Boosting Multimodal Multi-disease Medical Diagnosis Segmentation with Region-Aware Vision-Language Similarity Masks",
      "title_zh": "Sim4Segï¼šåŸºäºåŒºåŸŸæ„ŸçŸ¥è§†è§‰-è¯­è¨€ç›¸ä¼¼æ€§æ©ç æå‡å¤šæ¨¡æ€å¤šç–¾ç—…åŒ»å­¦è¯Šæ–­åˆ†å‰²",
      "authors": [
        "Lingran Song",
        "Yucheng Zhou",
        "Jianbing Shen"
      ],
      "abstract": "Despite significant progress in pixel-level medical image analysis, existing medical image segmentation models rarely explore medical segmentation and diagnosis tasks jointly. However, it is crucial for patients that models can provide explainable diagnoses along with medical segmentation results. In this paper, we introduce a medical vision-language task named Medical Diagnosis Segmentation (MDS), which aims to understand clinical queries for medical images and generate the corresponding segmentation masks as well as diagnostic results. To facilitate this task, we first present the Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS) dataset, containing diverse multimodal multi-disease medical images paired with their corresponding segmentation masks and diagnosis chain-of-thought, created via an automated diagnosis chain-of-thought generation pipeline. Moreover, we propose Sim4Seg, a novel framework that improves the performance of diagnosis segmentation by taking advantage of the Region-Aware Vision-Language Similarity to Mask (RVLS2M) module. To improve overall performance, we investigate a test-time scaling strategy for MDS tasks. Experimental results demonstrate that our method outperforms the baselines in both segmentation and diagnosis.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰åŒ»å­¦å›¾åƒåˆ†å‰²æ¨¡å‹æå°‘è”åˆæ¢ç´¢åˆ†å‰²ä¸è¯Šæ–­ä»»åŠ¡çš„é—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ä¸ªåä¸ºMedical Diagnosis Segmentation (MDS)çš„æ–°ä»»åŠ¡ï¼Œæ—¨åœ¨ç†è§£ä¸´åºŠæŸ¥è¯¢å¹¶ç”Ÿæˆç›¸åº”çš„åˆ†å‰²æ©ç åŠè¯Šæ–­ç»“æœã€‚ä¸ºä¿ƒè¿›è¯¥ä»»åŠ¡ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†Multimodal Multi-disease Medical Diagnosis Segmentation (M3DS)æ•°æ®é›†ï¼ŒåŒ…å«å¤šæ¨¡æ€å¤šç–¾ç—…åŒ»å­¦å›¾åƒåŠå…¶å¯¹åº”çš„åˆ†å‰²æ©ç å’Œé€šè¿‡è‡ªåŠ¨åŒ–ç®¡é“ç”Ÿæˆçš„è¯Šæ–­æ€ç»´é“¾(diagnosis chain-of-thought)ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®ºæ–‡æå‡ºäº†Sim4Segæ¡†æ¶ï¼Œåˆ©ç”¨Region-Aware Vision-Language Similarity to Mask (RVLS2M)æ¨¡å—æ˜¾è‘—æå‡äº†è¯Šæ–­åˆ†å‰²çš„æ€§èƒ½ã€‚ä¸ºäº†è¿›ä¸€æ­¥æé«˜æ•´ä½“è¡¨ç°ï¼Œç ”ç©¶äººå‘˜è¿˜æ¢è®¨äº†é’ˆå¯¹MDSä»»åŠ¡çš„æµ‹è¯•æ—¶æ‰©å±•ç­–ç•¥(test-time scaling strategy)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åˆ†å‰²å’Œè¯Šæ–­æ–¹é¢å‡ä¼˜äºåŸºçº¿æ¨¡å‹ï¼Œèƒ½å¤Ÿä¸ºæ‚£è€…æä¾›å…¼å…·å¯è§£é‡Šæ€§è¯Šæ–­ä¸ç²¾ç¡®åˆ†å‰²çš„åŒ»ç–—åˆ†æç»“æœã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06665v1",
      "published_date": "2025-11-10 03:22:42 UTC",
      "updated_date": "2025-11-10 03:22:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:43:38.212524+00:00"
    },
    {
      "arxiv_id": "2511.06658v2",
      "title": "Active Learning for Animal Re-Identification with Ambiguity-Aware Sampling",
      "title_zh": "åŸºäºæ­§ä¹‰æ„ŸçŸ¥é‡‡æ ·çš„åŠ¨ç‰©é‡è¯†åˆ«ä¸»åŠ¨å­¦ä¹ ",
      "authors": [
        "Depanshu Sani",
        "Mehar Khurana",
        "Saket Anand"
      ],
      "abstract": "Animal Re-ID has recently gained substantial attention in the AI research community due to its high impact on biodiversity monitoring and unique research challenges arising from environmental factors. The subtle distinguishing patterns, handling new species and the inherent open-set nature make the problem even harder. To address these complexities, foundation models trained on labeled, large-scale and multi-species animal Re-ID datasets have recently been introduced to enable zero-shot Re-ID. However, our benchmarking reveals significant gaps in their zero-shot Re-ID performance for both known and unknown species. While this highlights the need for collecting labeled data in new domains, exhaustive annotation for Re-ID is laborious and requires domain expertise. Our analyses show that existing unsupervised (USL) and AL Re-ID methods underperform for animal Re-ID. To address these limitations, we introduce a novel AL Re-ID framework that leverages complementary clustering methods to uncover and target structurally ambiguous regions in the embedding space for mining pairs of samples that are both informative and broadly representative. Oracle feedback on these pairs, in the form of must-link and cannot-link constraints, facilitates a simple annotation interface, which naturally integrates with existing USL methods through our proposed constrained clustering refinement algorithm. Through extensive experiments, we demonstrate that, by utilizing only 0.033% of all annotations, our approach consistently outperforms existing foundational, USL and AL baselines. Specifically, we report an average improvement of 10.49%, 11.19% and 3.99% (mAP) on 13 wildlife datasets over foundational, USL and AL methods, respectively, while attaining state-of-the-art performance on each dataset. Furthermore, we also show an improvement of 11.09%, 8.2% and 2.06% for unknown individuals in an open-world setting.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŠ¨ç‰©é‡è¯†åˆ«ï¼ˆAnimal Re-IDï¼‰é¢ä¸´çš„é›¶æ ·æœ¬æ€§èƒ½å·®è·åŠæ ‡æ³¨æˆæœ¬é«˜æ˜‚é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ¨¡ç³Šæ„ŸçŸ¥é‡‡æ ·çš„æ–°å‹ä¸»åŠ¨å­¦ä¹ ï¼ˆActive Learningï¼‰æ¡†æ¶ã€‚é‰´äºç°æœ‰åŸºç¡€æ¨¡å‹å’Œæ— ç›‘ç£æ–¹æ³•åœ¨å¤„ç†ç»†å¾®ç‰¹å¾åŠå¼€æ”¾é›†åœºæ™¯æ—¶çš„å±€é™æ€§ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨äº’è¡¥èšç±»æ–¹æ³•å®šä½åµŒå…¥ç©ºé—´ä¸­çš„ç»“æ„æ€§æ¨¡ç³ŠåŒºåŸŸï¼Œä»¥æŒ–æ˜å…¼å…·ä¿¡æ¯é‡ä¸ä»£è¡¨æ€§çš„æ ·æœ¬å¯¹ã€‚é€šè¿‡è·å–â€œå¿…é¡»è¿æ¥â€ï¼ˆmust-linkï¼‰å’Œâ€œä¸èƒ½è¿æ¥â€ï¼ˆcannot-linkï¼‰å½¢å¼çš„Oracleåé¦ˆï¼Œå¹¶ç»“åˆå—é™èšç±»ç»†åŒ–ç®—æ³•ï¼Œè¯¥æ–¹æ³•å®ç°äº†äººå·¥æ ‡æ³¨ä¸æ— ç›‘ç£å­¦ä¹ æ–¹æ³•çš„æœ‰æ•ˆèåˆã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œä»…éœ€0.033%çš„æ ‡æ³¨æ•°æ®ï¼Œè¯¥æ–¹æ³•åœ¨13ä¸ªé‡ç”ŸåŠ¨ç‰©æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„åŸºç¡€æ¨¡å‹ã€æ— ç›‘ç£å­¦ä¹ åŠä¸»åŠ¨å­¦ä¹ åŸºçº¿ã€‚å…·ä½“è€Œè¨€ï¼Œè¯¥æ–¹æ³•ä¸ä»…å°†å¹³å‡mAPåˆ†åˆ«æå‡äº†10.49%ã€11.19%å’Œ3.99%ï¼Œè¿˜åœ¨å¼€æ”¾ä¸–ç•Œè®¾ç½®ä¸‹æ˜¾è‘—æ”¹å–„äº†å¯¹æœªçŸ¥ä¸ªä½“çš„è¯†åˆ«æ€§èƒ½ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of AAAI Conference on Artificial Intelligence 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06658v2",
      "published_date": "2025-11-10 03:13:40 UTC",
      "updated_date": "2025-11-11 14:04:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:44:07.912552+00:00"
    },
    {
      "arxiv_id": "2511.08634v1",
      "title": "CADIC: Continual Anomaly Detection Based on Incremental Coreset",
      "title_zh": "CADICï¼šåŸºäºå¢é‡æ ¸å¿ƒé›†çš„æŒç»­å¼‚å¸¸æ£€æµ‹",
      "authors": [
        "Gen Yang",
        "Zhipeng Deng",
        "Junfeng Man"
      ],
      "abstract": "The primary objective of Continual Anomaly Detection (CAD) is to learn the normal patterns of new tasks under dynamic data distribution assumptions while mitigating catastrophic forgetting. Existing embedding-based CAD approaches continuously update a memory bank with new embeddings to adapt to sequential tasks. However, these methods require constructing class-specific sub-memory banks for each task, which restricts their flexibility and scalability. To address this limitation, we propose a novel CAD framework where all tasks share a unified memory bank. During training, the method incrementally updates embeddings within a fixed-size coreset, enabling continuous knowledge acquisition from sequential tasks without task-specific memory fragmentation. In the inference phase, anomaly scores are computed via a nearest-neighbor matching mechanism, achieving state-of-the-art detection accuracy. We validate the method through comprehensive experiments on MVTec AD and Visa datasets. Results show that our approach outperforms existing baselines, achieving average image-level AUROC scores of 0.972 (MVTec AD) and 0.891 (Visa). Notably, on a real-world electronic paper dataset, it demonstrates 100% accuracy in anomaly sample detection, confirming its robustness in practical scenarios. The implementation will be open-sourced on GitHub.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CADICï¼Œä¸€ç§åŸºäºå¢é‡æ ¸å¿ƒé›†(Incremental Coreset)çš„æŒç»­å¼‚å¸¸æ£€æµ‹(Continual Anomaly Detection, CAD)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ–¹æ³•å› ä¾èµ–ç‰¹å®šä»»åŠ¡å­å­˜å‚¨åº“è€Œå¯¼è‡´çš„çµæ´»æ€§å’Œæ‰©å±•æ€§å—é™é—®é¢˜ã€‚è¯¥æ¡†æ¶åˆ›æ–°æ€§åœ°é‡‡ç”¨æ‰€æœ‰ä»»åŠ¡å…±äº«çš„ç»Ÿä¸€å­˜å‚¨åº“ï¼Œé€šè¿‡åœ¨å›ºå®šå¤§å°çš„æ ¸å¿ƒé›†å†…å¢é‡æ›´æ–°åµŒå…¥ï¼Œå®ç°äº†ä»åºåˆ—ä»»åŠ¡ä¸­æŒç»­è·å–çŸ¥è¯†å¹¶é¿å…å­˜å‚¨ç¢ç‰‡åŒ–ã€‚åœ¨æ¨ç†é˜¶æ®µï¼Œæ¨¡å‹åˆ©ç”¨æœ€è¿‘é‚»åŒ¹é…æœºåˆ¶(nearest-neighbor matching)è®¡ç®—å¼‚å¸¸åˆ†æ•°ï¼Œä»è€Œè¾¾åˆ°æœ€å…ˆè¿›çš„æ£€æµ‹ç²¾åº¦ã€‚åœ¨MVTec ADå’ŒVisaæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ï¼Œå¹³å‡å›¾åƒçº§AUROCåˆ†åˆ«è¾¾åˆ°0.972å’Œ0.891ã€‚æ­¤å¤–ï¼Œåœ¨çœŸå®ä¸–ç•Œçš„ç”µå­çº¸æ•°æ®é›†æµ‹è¯•ä¸­ï¼Œè¯¥æ–¹æ³•å®ç°äº†100%çš„å¼‚å¸¸æ ·æœ¬æ£€æµ‹å‡†ç¡®ç‡ï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2511.08634v1",
      "published_date": "2025-11-10 03:13:11 UTC",
      "updated_date": "2025-11-10 03:13:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:44:30.208762+00:00"
    },
    {
      "arxiv_id": "2511.06634v3",
      "title": "CaberNet: Causal Representation Learning for Cross-Domain HVAC Energy Prediction",
      "title_zh": "CaberNetï¼šé¢å‘è·¨åŸŸæš–é€šç©ºè°ƒèƒ½è€—é¢„æµ‹çš„å› æœè¡¨å¾å­¦ä¹ ",
      "authors": [
        "Kaiyuan Zhai",
        "Jiacheng Cui",
        "Zhehao Zhang",
        "Junyu Xue",
        "Yang Deng",
        "Kui Wu",
        "Guoming Tang"
      ],
      "abstract": "Cross-domain HVAC energy prediction is essential for scalable building energy management, particularly because collecting extensive labeled data for every new building is both costly and impractical. Yet, this task remains highly challenging due to the scarcity and heterogeneity of data across different buildings, climate zones, and seasonal patterns. In particular, buildings situated in distinct climatic regions introduce variability that often leads existing methods to overfit to spurious correlations, rely heavily on expert intervention, or compromise on data diversity. To address these limitations, we propose CaberNet, a causal and interpretable deep sequence model that learns invariant (Markov blanket) representations for robust cross-domain prediction. In a purely data-driven fashion and without requiring any prior knowledge, CaberNet integrates i) a global feature gate trained with a self-supervised Bernoulli regularization to distinguish superior causal features from inferior ones, and ii) a domain-wise training scheme that balances domain contributions, minimizes cross-domain loss variance, and promotes latent factor independence. We evaluate CaberNet on real-world datasets collected from three buildings located in three climatically diverse cities, and it consistently outperforms all baselines, achieving a 22.9% reduction in normalized mean squared error (NMSE) compared to the best benchmark. Our code is available at https://github.com/SusCom-Lab/CaberNet-CRL.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è·¨åŸŸHVACèƒ½æºé¢„æµ‹ä¸­å› æ•°æ®ç¨€ç¼ºå’Œå¼‚è´¨æ€§å¯¼è‡´çš„è¿‡æ‹Ÿåˆè™šå‡ç›¸å…³æ€§(spurious correlations)é—®é¢˜ï¼Œæå‡ºäº†CaberNetï¼Œä¸€ç§å› æœä¸”å¯è§£é‡Šçš„æ·±åº¦åºåˆ—æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ—¨åœ¨é€šè¿‡çº¯æ•°æ®é©±åŠ¨çš„æ–¹å¼å­¦ä¹ ä¸å˜çš„é©¬å°”å¯å¤«æ¯¯(Markov blanket)è¡¨ç¤ºï¼Œä»è€Œå®ç°é²æ£’çš„è·¨åŸŸé¢„æµ‹ã€‚CaberNeté›†æˆäº†ä¸€ä¸ªç»è¿‡è‡ªç›‘ç£ä¼¯åŠªåˆ©æ­£åˆ™åŒ–è®­ç»ƒçš„å…¨å±€ç‰¹å¾é—¨æ§ä»¥åŒºåˆ†å› æœç‰¹å¾ï¼Œå¹¶é‡‡ç”¨åŸŸçº§è®­ç»ƒæ–¹æ¡ˆæ¥å¹³è¡¡åŸŸè´¡çŒ®ã€æœ€å°åŒ–è·¨åŸŸæŸå¤±æ–¹å·®åŠä¿ƒè¿›æ½œåœ¨å› å­ç‹¬ç«‹æ€§ã€‚åœ¨ä¸‰ä¸ªæ°”å€™è¿¥å¼‚åŸå¸‚çš„çœŸå®å»ºç­‘æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒCaberNetæ— éœ€ä»»ä½•å…ˆéªŒçŸ¥è¯†å³å¯ä¼˜äºæ‰€æœ‰åŸºçº¿æ¨¡å‹ï¼Œç›¸æ¯”æœ€ä½³åŸºå‡†å°†å½’ä¸€åŒ–å‡æ–¹è¯¯å·®(NMSE)é™ä½äº†22.9%ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACM e-Energy 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06634v3",
      "published_date": "2025-11-10 02:21:43 UTC",
      "updated_date": "2025-12-12 05:47:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:44:56.466206+00:00"
    },
    {
      "arxiv_id": "2511.06626v4",
      "title": "Spilling the Beans: Teaching LLMs to Self-Report Their Hidden Objectives",
      "title_zh": "åéœ²çœŸè¨€ï¼šæ•™å¯¼å¤§è¯­è¨€æ¨¡å‹è‡ªæˆ‘æŠ¥å‘Šå…¶éšè—ç›®æ ‡",
      "authors": [
        "Chloe Li",
        "Mary Phuong",
        "Daniel Tan"
      ],
      "abstract": "As AI systems become more capable of complex agentic tasks, they also become more capable of pursuing undesirable objectives and causing harm. Previous work has attempted to catch these unsafe instances by interrogating models directly about their objectives and behaviors. However, the main weakness of trusting interrogations is that models can lie. We propose self-report fine-tuning (SRFT), a simple supervised fine-tuning technique that trains models to occasionally make factual mistakes, then admit them when asked. We show that the admission of factual errors in simple question-answering settings generalizes out-of-distribution (OOD) to the admission of hidden misaligned objectives in adversarial agentic settings. We evaluate SRFT in OOD stealth tasks, where models are instructed to complete a hidden misaligned objective alongside a user-specified objective without being caught by monitoring. After SRFT, models are more likely to confess the details of their hidden objectives when interrogated, even under strong pressure not to disclose them. Interrogation on SRFT models can detect hidden objectives with near-ceiling performance (F1 score = 0.98), while the baseline model lies when interrogated under the same conditions (F1 score = 0). Interrogation on SRFT models can further elicit the content of the hidden objective, recovering 28-100% details, compared to 0% details recovered in the baseline model and by prefilled assistant turn attacks. This provides a promising technique for promoting honesty propensity and incriminating misaligned AIs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹AIæ¨¡å‹åœ¨æ‰§è¡Œå¤æ‚ä»£ç†ä»»åŠ¡æ—¶å¯èƒ½éšè—ä¸è‰¯ç›®æ ‡å¹¶æ’’è°çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSelf-Report Fine-Tuning (SRFT) çš„ç›‘ç£å¾®è°ƒæŠ€æœ¯ã€‚SRFTé€šè¿‡è®­ç»ƒæ¨¡å‹å¶å°”çŠ¯äº‹å®æ€§é”™è¯¯å¹¶åœ¨è¢«è¯¢é—®æ—¶æ‰¿è®¤é”™è¯¯ï¼ŒæˆåŠŸå°†è¿™ç§è¯šå®å€¾å‘æ³›åŒ–ï¼ˆOut-Of-Distribution, OODï¼‰åˆ°å¯¹æŠ—æ€§ä»£ç†è®¾ç½®ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿæ‰¿è®¤éšè—çš„æœªå¯¹é½ç›®æ ‡ã€‚åœ¨éšå½¢ä»»åŠ¡ï¼ˆstealth tasksï¼‰è¯„ä¼°ä¸­ï¼Œå³ä¾¿é¢ä¸´å·¨å¤§çš„ä¿å¯†å‹åŠ›ï¼Œç»è¿‡SRFTè®­ç»ƒçš„æ¨¡å‹ä¹Ÿæ›´å€¾å‘äºåœ¨å®¡è®¯ä¸‹å¦ç™½å…¶éšè—ç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¯¹SRFTæ¨¡å‹çš„å®¡è®¯èƒ½ä»¥æ¥è¿‘å®Œç¾çš„æ€§èƒ½ï¼ˆF1 score = 0.98ï¼‰æ£€æµ‹å‡ºéšè—ç›®æ ‡ï¼Œè€ŒåŸºçº¿æ¨¡å‹åœ¨ç›¸åŒæ¡ä»¶ä¸‹å®Œå…¨æ’’è°ï¼ˆF1 score = 0ï¼‰ã€‚æ­¤å¤–ï¼ŒSRFTè¿˜èƒ½æœ‰æ•ˆæå–éšè—ç›®æ ‡çš„å…·ä½“å†…å®¹ï¼Œæ¢å¤ç‡è¾¾28-100%ï¼Œè¿œè¶…åŸºçº¿æ¨¡å‹å’Œé¢„å¡«å……æ”»å‡»æ–¹æ³•çš„0%ã€‚è¿™é¡¹å·¥ä½œä¸ºæå‡æ¨¡å‹è¯šå®å€¾å‘å’Œè¯†åˆ«æœªå¯¹é½AIæä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06626v4",
      "published_date": "2025-11-10 02:09:44 UTC",
      "updated_date": "2025-12-04 22:47:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:48:16.061823+00:00"
    },
    {
      "arxiv_id": "2511.06625v3",
      "title": "Explainable Cross-Disease Reasoning for Cardiovascular Risk Assessment from LDCT",
      "title_zh": "åŸºäº LDCT çš„å¿ƒè¡€ç®¡é£é™©è¯„ä¼°å¯è§£é‡Šè·¨ç–¾ç—…æ¨ç†",
      "authors": [
        "Yifei Zhang",
        "Jiashuo Zhang",
        "Mojtaba Safari",
        "Xiaofeng Yang",
        "Liang Zhao"
      ],
      "abstract": "Low-dose chest computed tomography (LDCT) inherently captures both pulmonary and cardiac structures, offering a unique opportunity for joint assessment of lung and cardiovascular health. However, most existing approaches treat these domains as independent tasks, overlooking their physiological interplay and shared imaging biomarkers. We propose an Explainable Cross-Disease Reasoning Framework that enables interpretable cardiopulmonary risk assessment from a single LDCT scan. The framework introduces an agentic reasoning process that emulates clinical diagnostic thinking-first perceiving pulmonary findings, then reasoning through established medical knowledge, and finally deriving a cardiovascular judgment with explanatory rationale. It integrates three synergistic components: a pulmonary perception module that summarizes lung abnormalities, a knowledge-guided reasoning module that infers their cardiovascular implications, and a cardiac representation module that encodes structural biomarkers. Their outputs are fused to produce a holistic cardiovascular risk prediction that is both accurate and physiologically grounded. Experiments on the NLST cohort demonstrate that the proposed framework achieves state-of-the-art performance for CVD screening and mortality prediction, outperforming single-disease and purely image-based baselines. Beyond quantitative gains, the framework provides human-verifiable reasoning that aligns with cardiological understanding, revealing coherent links between pulmonary abnormalities and cardiac stress mechanisms. Overall, this work establishes a unified and explainable paradigm for cardiovascular analysis from LDCT, bridging the gap between image-based prediction and mechanism-based medical interpretation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§å¯è§£é‡Šçš„è·¨ç–¾ç—…æ¨ç†æ¡†æ¶ï¼ˆExplainable Cross-Disease Reasoning Frameworkï¼‰ï¼Œæ—¨åœ¨åˆ©ç”¨å•æ¬¡ä½å‰‚é‡èƒ¸éƒ¨CTï¼ˆLDCTï¼‰æ‰«æè¿›è¡Œå¿ƒè‚ºè”åˆé£é™©è¯„ä¼°ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å¿½è§†è‚ºéƒ¨ä¸å¿ƒè¡€ç®¡ç”Ÿç†ç›¸äº’ä½œç”¨çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†æ¨¡æ‹Ÿä¸´åºŠè¯Šæ–­æ€ç»´çš„ä»£ç†æ¨ç†è¿‡ç¨‹ï¼ˆagentic reasoning processï¼‰ï¼Œä¾æ¬¡è¿›è¡Œè‚ºéƒ¨å‘ç°æ„ŸçŸ¥ã€åŒ»å­¦çŸ¥è¯†æ¨ç†å’Œå¿ƒè¡€ç®¡åˆ¤æ–­ã€‚ç³»ç»Ÿé›†æˆäº†è‚ºéƒ¨æ„ŸçŸ¥ã€çŸ¥è¯†å¼•å¯¼æ¨ç†å’Œå¿ƒè„è¡¨ç¤ºä¸‰ä¸ªååŒæ¨¡å—ï¼Œå°†è‚ºéƒ¨å¼‚å¸¸æ€»ç»“ã€å¿ƒè¡€ç®¡å½±å“æ¨æ–­ä¸ç»“æ„ç”Ÿç‰©æ ‡å¿—ç‰©ç¼–ç ç›¸èåˆã€‚åœ¨NLSTé˜Ÿåˆ—ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å¿ƒè¡€ç®¡ç–¾ç—…ï¼ˆCVDï¼‰ç­›æŸ¥å’Œæ­»äº¡ç‡é¢„æµ‹æ–¹é¢å–å¾—äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼ˆSOTAï¼‰ï¼Œä¼˜äºå•ä¸€ç–¾ç—…å’Œçº¯å›¾åƒåŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶è¿˜èƒ½æä¾›ç¬¦åˆå¿ƒè„ç—…å­¦ç†è§£çš„äººç±»å¯éªŒè¯æ¨ç†ï¼Œæ­ç¤ºäº†è‚ºéƒ¨å¼‚å¸¸ä¸å¿ƒè„å‹åŠ›æœºåˆ¶ä¹‹é—´çš„å†…åœ¨è”ç³»ï¼Œå¼¥åˆäº†åŸºäºå›¾åƒçš„é¢„æµ‹ä¸åŸºäºæœºåˆ¶çš„åŒ»å­¦è§£é‡Šä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06625v3",
      "published_date": "2025-11-10 02:04:46 UTC",
      "updated_date": "2025-11-22 17:12:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:49:20.980133+00:00"
    },
    {
      "arxiv_id": "2511.06619v1",
      "title": "How Do VLAs Effectively Inherit from VLMs?",
      "title_zh": "VLA å¦‚ä½•æœ‰æ•ˆåœ°ç»§æ‰¿ VLMï¼Ÿ",
      "authors": [
        "Chuheng Zhang",
        "Rushuai Yang",
        "Xiaoyu Chen",
        "Kaixin Wang",
        "Li Zhao",
        "Yi Chen",
        "Jiang Bian"
      ],
      "abstract": "Vision-language-action (VLA) models hold the promise to attain generalizable embodied control. To achieve this, a pervasive paradigm is to leverage the rich vision-semantic priors of large vision-language models (VLMs). However, the fundamental question persists: How do VLAs effectively inherit the prior knowledge from VLMs? To address this critical question, we introduce a diagnostic benchmark, GrinningFace, an emoji tabletop manipulation task where the robot arm is asked to place objects onto printed emojis corresponding to language instructions. This task design is particularly revealing -- knowledge associated with emojis is ubiquitous in Internet-scale datasets used for VLM pre-training, yet emojis themselves are largely absent from standard robotics datasets. Consequently, they provide a clean proxy: successful task completion indicates effective transfer of VLM priors to embodied control. We implement this diagnostic task in both simulated environment and a real robot, and compare various promising techniques for knowledge transfer. Specifically, we investigate the effects of parameter-efficient fine-tuning, VLM freezing, co-training, predicting discretized actions, and predicting latent actions. Through systematic evaluation, our work not only demonstrates the critical importance of preserving VLM priors for the generalization of VLA but also establishes guidelines for future research in developing truly generalizable embodied AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†è§†è§‰-è¯­è¨€-åŠ¨ä½œ(VLA)æ¨¡å‹å¦‚ä½•æœ‰æ•ˆç»§æ‰¿å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹(VLMs)çš„ä¸°å¯Œè§†è§‰è¯­ä¹‰å…ˆéªŒä»¥å®ç°å¯æ³›åŒ–çš„å…·èº«æ§åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æ ¸å¿ƒé—®é¢˜ï¼Œä½œè€…å¼•å…¥äº†ä¸€ä¸ªåä¸ºGrinningFaceçš„è¯Šæ–­åŸºå‡†ï¼Œé€šè¿‡è¦æ±‚æœºæ¢°è‡‚æ ¹æ®è¯­è¨€æŒ‡ä»¤å°†ç‰©ä½“æ”¾ç½®åœ¨å¯¹åº”çš„è¡¨æƒ…ç¬¦å·ä¸Šæ¥æµ‹è¯•æ¨¡å‹èƒ½åŠ›ã€‚ç”±äºè¡¨æƒ…ç¬¦å·åœ¨VLMé¢„è®­ç»ƒæ•°æ®ä¸­å¹¿æ³›å­˜åœ¨ä½†åœ¨æ ‡å‡†æœºå™¨äººæ•°æ®é›†ä¸­ç¼ºå¤±ï¼Œè¯¥ä»»åŠ¡èƒ½å¤Ÿæ¸…æ™°åœ°ä»£ç†è¯„ä¼°VLMå…ˆéªŒå‘å…·èº«æ§åˆ¶çš„è¿ç§»æ•ˆæœã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ä»¿çœŸå’ŒçœŸå®ç¯å¢ƒä¸­å¯¹æ¯”äº†å‚æ•°é«˜æ•ˆå¾®è°ƒ(parameter-efficient fine-tuning)ã€VLMå†»ç»“ã€è”åˆè®­ç»ƒ(co-training)ä»¥åŠé¢„æµ‹ç¦»æ•£æˆ–æ½œåœ¨åŠ¨ä½œç­‰å¤šç§æŠ€æœ¯ã€‚è¯„ä¼°ç»“æœä¸ä»…è¯æ˜äº†ä¿ç•™VLMå…ˆéªŒå¯¹äºVLAæ³›åŒ–èƒ½åŠ›çš„é‡è¦æ€§ï¼Œè¿˜ä¸ºæœªæ¥å¼€å‘çœŸæ­£é€šç”¨çš„å…·èº«AIç³»ç»Ÿæä¾›äº†æŒ‡å¯¼æ–¹é’ˆã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06619v1",
      "published_date": "2025-11-10 01:58:02 UTC",
      "updated_date": "2025-11-10 01:58:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:49:21.603424+00:00"
    },
    {
      "arxiv_id": "2511.06618v1",
      "title": "GRAPH-GRPO-LEX: Contract Graph Modeling and Reinforcement Learning with Group Relative Policy Optimization",
      "title_zh": "GRAPH-GRPO-LEXï¼šåˆåŒå›¾å»ºæ¨¡ä¸åŸºäºç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Moriya Dechtiar",
        "Daniel Martin Katz",
        "Mari Sundaresan",
        "Sylvain Jaume",
        "Hongming Wang"
      ],
      "abstract": "Contracts are complex documents featuring detailed formal structures, explicit and implicit dependencies and rich semantic content. Given these document properties, contract drafting and manual examination of contracts have proven to be both arduous and susceptible to errors. This work aims to simplify and automate the task of contract review and analysis using a novel framework for transforming legal contracts into structured semantic graphs, enabling computational analysis and data-driven insights. We introduce a detailed ontology mapping core legal contract elements to their graph-theoretic equivalents of nodes and edges. We then present a reinforcement learning based Large Language Model (LLM) framework for segmentation and extraction of entities and relationships from contracts. Our method, GRAPH-GRPO-LEX, incorporates both LLMs and reinforcement learning with group relative policy optimization (GRPO). By applying a carefully drafted reward function of graph metrics, we demonstrate the ability to automatically identify direct relationships between clauses, and even uncover hidden dependencies. Our introduction of the gated GRPO approach shows a strong learning signal and can move contract analysis from a linear, manual reading process to an easily visualized graph. This allows for a more dynamic analysis, including building the groundwork for contract linting similar to what is now practiced in software engineering.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ—¨åœ¨è§£å†³æ³•å¾‹åˆåŒèµ·è‰å’Œå®¡æŸ¥è¿‡ç¨‹ç¹çä¸”æ˜“é”™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°†åˆåŒè½¬åŒ–ä¸ºç»“æ„åŒ–è¯­ä¹‰å›¾çš„æ–°é¢–æ¡†æ¶GRAPH-GRPO-LEXã€‚è¯¥æ¡†æ¶ç»“åˆäº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å’ŒåŸºäºGroup Relative Policy Optimization (GRPO)çš„å¼ºåŒ–å­¦ä¹ æŠ€æœ¯ï¼Œé€šè¿‡è¯¦ç»†çš„æœ¬ä½“è®ºå°†åˆåŒæ ¸å¿ƒå…ƒç´ æ˜ å°„ä¸ºå›¾è®ºä¸­çš„èŠ‚ç‚¹å’Œè¾¹ã€‚ä½œè€…å¼•å…¥äº†ä¸€ç§é—¨æ§GRPOæ–¹æ³•(gated GRPO approach)ä»¥åŠåŸºäºå›¾æŒ‡æ ‡çš„ç²¾å¿ƒè®¾è®¡çš„å¥–åŠ±å‡½æ•°ï¼Œå®ç°äº†å¯¹åˆåŒå®ä½“å’Œå…³ç³»çš„è‡ªåŠ¨åˆ†å‰²ä¸æå–ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•ä¸ä»…èƒ½è¯†åˆ«æ¡æ¬¾é—´çš„ç›´æ¥å…³ç³»ï¼Œè¿˜èƒ½æ­ç¤ºéšè—çš„ä¾èµ–å…³ç³»ï¼Œå°†çº¿æ€§çš„åˆåŒåˆ†æè½¬å˜ä¸ºå¯è§†åŒ–çš„åŠ¨æ€å›¾åˆ†æã€‚è¿™ä¸€æˆæœä¸ºå®ç°ç±»ä¼¼è½¯ä»¶å·¥ç¨‹ä¸­çš„åˆåŒä»£ç æ£€æŸ¥(contract linting)å¥ å®šäº†åŸºç¡€ï¼Œæ˜¾è‘—æå‡äº†æ•°æ®é©±åŠ¨çš„åˆåŒåˆ†æèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2511.06618v1",
      "published_date": "2025-11-10 01:57:51 UTC",
      "updated_date": "2025-11-10 01:57:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:49:16.743171+00:00"
    },
    {
      "arxiv_id": "2511.06608v1",
      "title": "Beyond Fixed Depth: Adaptive Graph Neural Networks for Node Classification Under Varying Homophily",
      "title_zh": "è¶…è¶Šå›ºå®šæ·±åº¦ï¼šå˜åŠ¨åŒé…æ€§ä¸‹èŠ‚ç‚¹åˆ†ç±»çš„è‡ªé€‚åº”å›¾ç¥ç»ç½‘ç»œ",
      "authors": [
        "Asela Hevapathige",
        "Asiri Wijesinghe",
        "Ahad N. Zehmakan"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved significant success in addressing node classification tasks. However, the effectiveness of traditional GNNs degrades on heterophilic graphs, where connected nodes often belong to different labels or properties. While recent work has introduced mechanisms to improve GNN performance under heterophily, certain key limitations still exist. Most existing models apply a fixed aggregation depth across all nodes, overlooking the fact that nodes may require different propagation depths based on their local homophily levels and neighborhood structures. Moreover, many methods are tailored to either homophilic or heterophilic settings, lacking the flexibility to generalize across both regimes. To address these challenges, we develop a theoretical framework that links local structural and label characteristics to information propagation dynamics at the node level. Our analysis shows that optimal aggregation depth varies across nodes and is critical for preserving class-discriminative information. Guided by this insight, we propose a novel adaptive-depth GNN architecture that dynamically selects node-specific aggregation depths using theoretically grounded metrics. Our method seamlessly adapts to both homophilic and heterophilic patterns within a unified model. Extensive experiments demonstrate that our approach consistently enhances the performance of standard GNN backbones across diverse benchmarks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ(GNNs)åœ¨å¼‚é…å›¾(heterophilic graphs)ä¸Šè¡¨ç°ä¸ä½³çš„é—®é¢˜ï¼ŒæŒ‡å‡ºç°æœ‰æ¨¡å‹ä¸»è¦å±€é™åœ¨äºå¯¹æ‰€æœ‰èŠ‚ç‚¹åº”ç”¨å›ºå®šçš„èšåˆæ·±åº¦(fixed aggregation depth)ï¼Œå¿½ç•¥äº†ä¸åŒèŠ‚ç‚¹æ ¹æ®å…¶å±€éƒ¨åŒé…æ°´å¹³å’Œé‚»åŸŸç»“æ„éœ€è¦ä¸åŒä¼ æ’­æ·±åº¦çš„éœ€æ±‚ã€‚ä¸ºæ­¤ï¼Œä½œè€…æ„å»ºäº†ä¸€ä¸ªç†è®ºæ¡†æ¶ï¼Œå°†å±€éƒ¨ç»“æ„å’Œæ ‡ç­¾ç‰¹å¾ä¸èŠ‚ç‚¹çº§ä¿¡æ¯ä¼ æ’­åŠ¨åŠ›å­¦ç›¸è”ç³»ï¼Œè¯æ˜äº†æœ€ä¼˜èšåˆæ·±åº¦å› èŠ‚ç‚¹è€Œå¼‚ä¸”å¯¹ä¿ç•™ç±»åˆ«åŒºåˆ†ä¿¡æ¯è‡³å…³é‡è¦ã€‚åŸºäºæ­¤è§è§£ï¼Œè®ºæ–‡æå‡ºäº†ä¸€ç§æ–°é¢–çš„è‡ªé€‚åº”æ·±åº¦GNNæ¶æ„ï¼Œåˆ©ç”¨åŸºäºç†è®ºçš„æŒ‡æ ‡åŠ¨æ€é€‰æ‹©ç‰¹å®šäºèŠ‚ç‚¹çš„èšåˆæ·±åº¦ã€‚è¯¥æ–¹æ³•èƒ½å¤Ÿåœ¨ä¸€ä¸ªç»Ÿä¸€çš„æ¨¡å‹ä¸­æ— ç¼é€‚åº”åŒé…(homophilic)å’Œå¼‚é…æ¨¡å¼ã€‚å¹¿æ³›çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§åŸºå‡†æµ‹è¯•ä¸­ä¸€è‡´æå‡äº†æ ‡å‡†GNNéª¨å¹²ç½‘ç»œçš„æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2511.06608v1",
      "published_date": "2025-11-10 01:37:51 UTC",
      "updated_date": "2025-11-10 01:37:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:49:40.240538+00:00"
    },
    {
      "arxiv_id": "2511.06606v2",
      "title": "SPUR: A Plug-and-Play Framework for Integrating Spatial Audio Understanding and Reasoning into Large Audio-Language Models",
      "title_zh": "SPURï¼šå°†ç©ºé—´éŸ³é¢‘ç†è§£ä¸æ¨ç†é›†æˆè‡³å¤§å‹éŸ³é¢‘è¯­è¨€æ¨¡å‹çš„å³æ’å³ç”¨æ¡†æ¶",
      "authors": [
        "S Sakshi",
        "Vaibhavi Lokegaonkar",
        "Neil Zhang",
        "Ramani Duraiswami",
        "Sreyan Ghosh",
        "Dinesh Manocha",
        "Lie Lu"
      ],
      "abstract": "Spatial perception is central to auditory intelligence, enabling accurate understanding of real-world acoustic scenes and advancing human-level perception of the world around us. While recent large audio-language models (LALMs) show strong reasoning over complex audios, most operate on monaural inputs and lack the ability to capture spatial cues such as direction, elevation, and distance. We introduce SPUR, a lightweight, plug-in approach that equips LALMs with spatial perception through minimal architectural changes. SPUR consists of: (i) a First-Order Ambisonics (FOA) encoder that maps (W, X, Y, Z) channels to rotation-aware, listener-centric spatial features, integrated into target LALMs via a multimodal adapter; and (ii) SPUR-Set, a spatial QA dataset combining open-source FOA recordings with controlled simulations, emphasizing relative direction, elevation, distance, and overlap for supervised spatial reasoning. Fine-tuning our model on the SPUR-Set consistently improves spatial QA and multi-speaker attribution while preserving general audio understanding. SPUR provides a simple recipe that transforms monaural LALMs into spatially aware models. Extensive ablations validate the effectiveness of our approach.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰Large Audio-Language Models (LALMs)å¤§å¤šä»…å¤„ç†å•å£°é“è¾“å…¥ä¸”ç¼ºä¹ç©ºé—´çº¿ç´¢æ•æ‰èƒ½åŠ›çš„é—®é¢˜ï¼Œæå‡ºäº†SPURï¼Œä¸€ç§è½»é‡çº§çš„å³æ’å³ç”¨æ¡†æ¶ã€‚SPURé€šè¿‡æœ€å°çš„æ¶æ„æ›´æ”¹èµ‹äºˆLALMsç©ºé—´æ„ŸçŸ¥èƒ½åŠ›ï¼Œå…¶æ ¸å¿ƒåŒ…å«ä¸€ä¸ªFirst-Order Ambisonics (FOA)ç¼–ç å™¨ï¼Œèƒ½å°†å¤šé€šé“éŸ³é¢‘æ˜ å°„ä¸ºæ—‹è½¬æ„ŸçŸ¥ä¸”ä»¥å¬ä¼—ä¸ºä¸­å¿ƒçš„ç©ºé—´ç‰¹å¾ï¼Œå¹¶é€šè¿‡å¤šæ¨¡æ€é€‚é…å™¨é›†æˆåˆ°ç›®æ ‡æ¨¡å‹ä¸­ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº†SPUR-Setï¼Œè¿™æ˜¯ä¸€ä¸ªç»“åˆå¼€æºFOAå½•éŸ³ä¸å—æ§æ¨¡æ‹Ÿçš„ç©ºé—´é—®ç­”æ•°æ®é›†ï¼Œé‡ç‚¹å…³æ³¨ç›¸å¯¹æ–¹å‘ã€é«˜åº¦ã€è·ç¦»å’Œå£°éŸ³é‡å ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨SPUR-Setä¸Šå¾®è°ƒåçš„æ¨¡å‹åœ¨ç©ºé—´QAå’Œå¤šè¯´è¯äººå½’å±ä»»åŠ¡ä¸Šè¡¨ç°æ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿ç•™äº†é€šç”¨çš„éŸ³é¢‘ç†è§£èƒ½åŠ›ï¼ŒéªŒè¯äº†å°†å•å£°é“LALMsè½¬åŒ–ä¸ºå…·å¤‡ç©ºé—´æ„ŸçŸ¥èƒ½åŠ›æ¨¡å‹çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Project: https://sakshi113.github.io/spur/",
      "pdf_url": "https://arxiv.org/pdf/2511.06606v2",
      "published_date": "2025-11-10 01:29:26 UTC",
      "updated_date": "2025-11-13 21:56:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:50:05.378609+00:00"
    },
    {
      "arxiv_id": "2511.06582v1",
      "title": "TabRAG: Tabular Document Retrieval via Structured Language Representations",
      "title_zh": "TabRAGï¼šåŸºäºç»“æ„åŒ–è¯­è¨€è¡¨ç¤ºçš„è¡¨æ ¼æ–‡æ¡£æ£€ç´¢",
      "authors": [
        "Jacob Si",
        "Mike Qu",
        "Michelle Lee",
        "Yingzhen Li"
      ],
      "abstract": "Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ•°æ®æ‘„å…¥è¿‡ç¨‹ä¸­ï¼Œå¾®è°ƒæ¨¡å‹æˆæœ¬é«˜æ˜‚è€Œç°æœ‰è§£ææ–¹æ³•å¤„ç†è¡¨æ ¼æ•°æ®æ€§èƒ½ä¸ä½³çš„å›°å¢ƒï¼Œæå‡ºäº†TabRAGã€‚TabRAGæ˜¯ä¸€ç§åŸºäºè§£æçš„RAGç®¡é“ï¼Œä¸“é—¨è®¾è®¡ç”¨äºé€šè¿‡ç»“æ„åŒ–è¯­è¨€è¡¨ç¤ºï¼ˆstructured language representationsï¼‰å¤„ç†åŒ…å«å¤§é‡è¡¨æ ¼çš„æ–‡æ¡£ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆè§£å†³äº†åœ¨ä¸è¿›è¡Œæ˜‚è´µå¾®è°ƒçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•ä»å¤æ‚æ–‡æ¡£ä¸­ç²¾ç¡®æå–å’Œåˆ©ç”¨è¡¨æ ¼ä¿¡æ¯çš„é—®é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒTabRAGåœ¨æ£€ç´¢å’Œç”Ÿæˆä»»åŠ¡ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„æµè¡Œè§£ææ–¹æ³•ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†è¡¨æ ¼å¯†é›†å‹æ–‡æ¡£æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2025 AI4Tab",
      "pdf_url": "https://arxiv.org/pdf/2511.06582v1",
      "published_date": "2025-11-10 00:05:58 UTC",
      "updated_date": "2025-11-10 00:05:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 2,
      "last_update": "2026-01-25T22:50:42.020825+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 187,
  "processed_papers_count": 187,
  "failed_papers_count": 0,
  "llm_backup_calls": 374,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-25T23:35:40.886892+00:00"
}