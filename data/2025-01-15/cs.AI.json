{
  "date": "2025-01-15",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-15 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 算法优化、强化学习、多模态生成和 LLM 应用等领域，强调模型鲁棒性、效率提升和实际应用；重点包括 Abhishek Sharma 的多篇强化学习工作，以及 LLM 在理论心智推理和图像生成上的创新；令人印象深刻的文章有 ObjectDiffusion 在可控图像生成上的 SOTA 性能，以及 Mantis Shrimp 在天文图像处理中的进展。\n\n下面，我将挑选并简要讨论部分重要论文，先从高影响力或热门主题入手（如强化学习和 LLM），再快速掠过其他次要文章。每个条目列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### 强化学习与知识表示\n- **Temporal Reasoning in AI systems (时间推理在 AI 系统中的应用)**: Abhishek Sharma 的论文探讨了常识时间推理问题，使用 Cyc 知识库和离散生存函数改进 Q/A 性能。贡献包括更准确的流畅性推断和事件风险期建模，发现该方法显著提升了自然语言理解和规划任务的准确率。\n- **A Coordination-based Approach for Focused Learning in Knowledge-Based Systems (基于协调的方法用于知识库系统的焦点学习)**: Abhishek Sharma 的另一篇工作，针对知识学习系统提出强化学习优化学习请求。关键发现是通过模拟协调游戏，提升 Q/A 性能达显著水平，适用于大规模知识获取。\n- **Growth Patterns of Inference (推理的增长模式)**: 同样由 Abhishek Sharma 撰写，分析一阶搜索空间的属性及其对推理的影响。贡献在于开发模型评估事实分布对性能的影响，发现均匀搜索空间更适合大型知识库，而倾斜分布适用于小型库。\n- **Inferring Transition Dynamics from Value Functions (从价值函数推断转移动态)**: Jacob Adamczyk 的论文揭示价值函数中隐含的环境动态信息。主要发现是通过重排 Bellman 方程，实现无需显式模型学习的动态推断，桥接了无模型和有模型强化学习。\n- **Average-Reward Reinforcement Learning with Entropy Regularization (带熵正则化的平均奖励强化学习)**: Jacob Adamczyk 等人的工作扩展了平均奖励强化学习。贡献包括新算法处理熵正则化，提升了算法在经典控制基准上的稳定性和收敛率。\n\n这些论文由同一作者系列组成，突出了强化学习在知识表示和动态推理中的潜力，整体上推动了 AI 系统在不确定环境下的鲁棒性。\n\n### LLM 和多模态应用\n- **Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG (代理式检索增强生成：代理式 RAG 的调查)**: Aditi Singh 等人的综述探讨了代理式 RAG 在 AI 中的应用。关键贡献是提出代理设计模式（如反射和规划），发现其在医疗和金融领域的可扩展性显著提升了 LLM 的动态适应性。\n- **Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition (通过模拟和任务分解增强大语言模型的理论心智推理)**: Sneheel Sarangi 等的工作，使用模拟理论改进 LLM 的心智推理。发现递归模拟和任务分解能显著提升模型在复杂 ToM 任务上的性能，适用于对话和决策场景。\n- **Grounding Text-to-Image Diffusion Models for Controlled High-Quality Image Generation (为可控高质量图像生成构建文本到图像扩散模型的语义基础)**: Ahmad Süleyman 等人的论文提出 ObjectDiffusion 模型。核心发现是通过 bounding box 整合语义和空间信息，实现了 SOTA 的图像生成精度（AP50 为 46.6），在多对象合成中表现出色。\n\n这些 LLM 相关论文展示了模型在代理和多模态生成上的进步，尤其 ObjectDiffusion 的图像控制能力令人注目，潜在影响图像 AI 应用。\n\n### 图像处理和医疗 AI\n- **Patch-aware Vector Quantized Codebook Learning for Unsupervised Visual Defect Detection (基于补丁感知的向量量化代码本学习，用于无监督视觉缺陷检测)**: Qisen Cheng 等人的工作优化了 VQ-VAE 框架。贡献包括动态代码分配方案，提升了缺陷检测准确率，在 MVTecAD 数据集上达到 SOTA 性能。\n- **Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval (对比学习模型在医疗图像-报告检索中的鲁棒性基准测试)**: Demetrio Deanda 等人的论文评估了 CLIP 等模型的鲁棒性。发现模型对图像遮挡敏感，但 MedCLIP 稍具优势，强调了改进医疗检索模型的必要性。\n\n这些论文在实际应用中表现突出，快速掠过其他图像论文如 Mantis Shrimp (天文图像红移估计)，其贡献在于融合多波段图像提升光度红移精度，但细节较技术化。\n\n### 其他快速掠过\n- **Guiding Retrieval using LLM-based Listwise Rankers (使用 LLM 基于列表的检索引导)**: Mandeep Rathee 等的工作提出自适应检索方法，提升了 LLM 检索的召回率和 nDCG@10。\n- **A Blockchain-Enabled Approach to Cross-Border Compliance and Trust (区块链赋能的跨境合规和信任方法)**: Vikram Kulothungan 的论文设计区块链框架提升 AI 治理安全，发现其在金融领域的适应性强。\n- **Towards Multilingual LLM Evaluation for Baltic and Nordic languages (针对波罗的海和北欧语言的多语言 LLM 评估)**: Yevhen Kostiuk 等的工作评估 LLM 在小语种上的性能，贡献在于揭示模型在区域语言中的偏差。\n- **AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning (通过代理式课程学习快速微调视觉 SLAM)**: Assaf Lahiany 等人的论文优化了 SLAM 训练，显著减少训练时间。\n- 其余论文如语音处理、区块链安全和医疗图像生成等（如 Generative Medical Image Anonymization），主要贡献在于具体技术优化，但影响力较小，仅快速提及其核心术语和发现，例如 Anonymization 模型在隐私保护和数据效用间平衡。\n\n总之，今天的论文突出了 AI 在高效计算和实际应用上的进展，但许多次要工作（如特定领域优化）未涉及核心创新，故从简。希望这份快报帮助您快速筛选感兴趣的文章！",
  "papers": [
    {
      "arxiv_id": "2502.00020v2",
      "title": "Temporal Reasoning in AI systems",
      "title_zh": "AI 系统中的时间推理",
      "authors": [
        "Abhishek Sharma"
      ],
      "abstract": "Commonsense temporal reasoning at scale is a core problem for cognitive\nsystems. The correct inference of the duration for which fluents hold is\nrequired by many tasks, including natural language understanding and planning.\nMany AI systems have limited deductive closure because they cannot extrapolate\ninformation correctly regarding existing fluents and events. In this study, we\ndiscuss the knowledge representation and reasoning schemes required for robust\ntemporal projection in the Cyc Knowledge Base. We discuss how events can start\nand end risk periods for fluents. We then use discrete survival functions,\nwhich represent knowledge of the persistence of facts, to extrapolate a given\nfluent. The extrapolated intervals can be truncated by temporal constraints and\nother types of commonsense knowledge. Finally, we present the results of\nexperiments to demonstrate that these methods obtain significant improvements\nin terms of Q/A performance.",
      "tldr_zh": "这篇论文探讨了AI系统在常识性时间推理中的核心挑战，特别是正确推断流畅（fluents）的持续时间，以支持自然语言理解和规划任务。作者在Cyc知识库中提出了一种知识表示和推理方案，利用事件启动/结束风险期（risk periods）和离散生存函数（discrete survival functions）来外推流畅，并通过时间约束和其他常识知识进行截断。实验结果表明，这些方法显著提升了问答（Q/A）性能，为AI系统的鲁棒性提供了重要改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00020v2",
      "published_date": "2025-01-15 23:47:50 UTC",
      "updated_date": "2025-02-12 21:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:41:38.046554"
    },
    {
      "arxiv_id": "2502.10394v1",
      "title": "A Coordination-based Approach for Focused Learning in Knowledge-Based Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Sharma"
      ],
      "abstract": "Recent progress in Learning by Reading and Machine Reading systems has\nsignificantly increased the capacity of knowledge-based systems to learn new\nfacts. In this work, we discuss the problem of selecting a set of learning\nrequests for these knowledge-based systems which would lead to maximum Q/A\nperformance. To understand the dynamics of this problem, we simulate the\nproperties of a learning strategy, which sends learning requests to an external\nknowledge source. We show that choosing an optimal set of facts for these\nlearning systems is similar to a coordination game, and use reinforcement\nlearning to solve this problem. Experiments show that such an approach can\nsignificantly improve Q/A performance.",
      "tldr_zh": "这篇论文提出了一种基于协调游戏的策略，用于知识-based 系统选择学习请求，从而最大化 Q/A 性能。作者通过模拟学习策略的动态，将问题建模为 coordination game，并应用 reinforcement learning 来优化事实集的选择。实验结果表明，这种方法能显著提升系统的 Q/A 性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10394v1",
      "published_date": "2025-01-15 23:45:02 UTC",
      "updated_date": "2025-01-15 23:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:41:48.609118"
    },
    {
      "arxiv_id": "2502.00019v1",
      "title": "Growth Patterns of Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Sharma"
      ],
      "abstract": "What properties of a first-order search space support/hinder inference? What\nkinds of facts would be most effective to learn? Answering these questions is\nessential for understanding the dynamics of deductive reasoning and creating\nlarge-scale knowledge-based learning systems that support efficient inference.\nWe address these questions by developing a model of how the distribution of\nground facts affects inference performance in search spaces. Experiments\nsuggest that uniform search spaces are suitable for larger KBs whereas search\nspaces with skewed degree distribution show better performance in smaller KBs.\nA sharp transition in Q/A performance is seen in some cases, suggesting that\nanalysis of the structure of search spaces with existing knowledge should be\nused to guide the acquisition of new ground facts in learning systems.",
      "tldr_zh": "该论文探讨了 first-order search space 的属性如何支持或阻碍推理性能，以及哪些 ground facts 最有效学习，以理解演绎推理动态并优化大规模知识库系统。研究者开发了一个模型，分析地面事实分布对搜索空间中推理性能的影响。实验结果显示，均匀搜索空间适合较大的知识库，而偏斜度分布的搜索空间在较小知识库中表现更佳；此外，某些情况下 Q/A performance 会出现急剧转变，建议通过分析现有知识的搜索空间结构来指导新 ground facts 的获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00019v1",
      "published_date": "2025-01-15 23:41:04 UTC",
      "updated_date": "2025-01-15 23:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:42:02.564857"
    },
    {
      "arxiv_id": "2501.09194v2",
      "title": "Grounding Text-to-Image Diffusion Models for Controlled High-Quality Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Süleyman",
        "Göksel Biricik"
      ],
      "abstract": "Text-to-image (T2I) generative diffusion models have demonstrated outstanding\nperformance in synthesizing diverse, high-quality visuals from text captions.\nSeveral layout-to-image models have been developed to control the generation\nprocess by utilizing a wide range of layouts, such as segmentation maps, edges,\nand human keypoints. In this work, we propose ObjectDiffusion, a model that\nconditions T2I diffusion models on semantic and spatial grounding information,\nenabling the precise rendering and placement of desired objects in specific\nlocations defined by bounding boxes. To achieve this, we make substantial\nmodifications to the network architecture introduced in ControlNet to integrate\nit with the grounding method proposed in GLIGEN. We fine-tune ObjectDiffusion\non the COCO2017 training dataset and evaluate it on the COCO2017 validation\ndataset. Our model improves the precision and quality of controllable image\ngeneration, achieving an AP$_{\\text{50}}$ of 46.6, an AR of 44.5, and an FID of\n19.8, outperforming the current SOTA model trained on open-source datasets\nacross all three metrics. ObjectDiffusion demonstrates a distinctive capability\nin synthesizing diverse, high-quality, high-fidelity images that seamlessly\nconform to the semantic and spatial control layout. Evaluated in qualitative\nand quantitative tests, ObjectDiffusion exhibits remarkable grounding\ncapabilities in closed-set and open-set vocabulary settings across a wide\nvariety of contexts. The qualitative assessment verifies the ability of\nObjectDiffusion to generate multiple detailed objects in varying sizes, forms,\nand locations.",
      "tldr_zh": "本研究提出ObjectDiffusion模型，通过整合语义和空间定位信息（如边界框），增强文本到图像(T2I)扩散模型的生成可控性，实现精确渲染和放置对象。方法上，该模型对ControlNet的网络架构进行重大修改，并与GLIGEN的定位技术结合，在COCO2017训练数据集上进行微调。实验结果显示，ObjectDiffusion在COCO2017验证集上达到AP$_{\\text{50}}$ 46.6、AR 44.5和FID 19.8的性能，优于当前SOTA模型，并在定性和定量测试中展现出生成多样、高质量图像的能力，尤其在封闭和开放词汇设置下精确处理多种对象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09194v2",
      "published_date": "2025-01-15 22:55:26 UTC",
      "updated_date": "2025-02-10 18:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:42:14.048753"
    },
    {
      "arxiv_id": "2501.09187v1",
      "title": "Patch-aware Vector Quantized Codebook Learning for Unsupervised Visual Defect Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Qisen Cheng",
        "Shuhui Qu",
        "Janghwan Lee"
      ],
      "abstract": "Unsupervised visual defect detection is critical in industrial applications,\nrequiring a representation space that captures normal data features while\ndetecting deviations. Achieving a balance between expressiveness and\ncompactness is challenging; an overly expressive space risks inefficiency and\nmode collapse, impairing detection accuracy. We propose a novel approach using\nan enhanced VQ-VAE framework optimized for unsupervised defect detection. Our\nmodel introduces a patch-aware dynamic code assignment scheme, enabling\ncontext-sensitive code allocation to optimize spatial representation. This\nstrategy enhances normal-defect distinction and improves detection accuracy\nduring inference. Experiments on MVTecAD, BTAD, and MTSD datasets show our\nmethod achieves state-of-the-art performance.",
      "tldr_zh": "这篇论文针对无监督视觉缺陷检测的挑战，提出了一种基于增强 VQ-VAE 框架的创新方法，以平衡表示空间的表达性和紧凑性，避免效率低下和模式崩溃问题。方法引入 patch-aware 动态代码分配方案，实现上下文敏感的代码分配，从而优化空间表示并提高正常与缺陷的区分准确性。在 MVTecAD、BTAD 和 MTSD 数据集上的实验显示，该方法达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, Accepted to 36th IEEE ICTAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.09187v1",
      "published_date": "2025-01-15 22:26:26 UTC",
      "updated_date": "2025-01-15 22:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:42:25.657672"
    },
    {
      "arxiv_id": "2501.09186v1",
      "title": "Guiding Retrieval using LLM-based Listwise Rankers",
      "title_zh": "使用基于LLM的列表式排序器引导检索",
      "authors": [
        "Mandeep Rathee",
        "Sean MacAvaney",
        "Avishek Anand"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong promise as rerankers,\nespecially in ``listwise'' settings where an LLM is prompted to rerank several\nsearch results at once. However, this ``cascading'' retrieve-and-rerank\napproach is limited by the bounded recall problem: relevant documents not\nretrieved initially are permanently excluded from the final ranking. Adaptive\nretrieval techniques address this problem, but do not work with listwise\nrerankers because they assume a document's score is computed independently from\nother documents. In this paper, we propose an adaptation of an existing\nadaptive retrieval method that supports the listwise setting and helps guide\nthe retrieval process itself (thereby overcoming the bounded recall problem for\nLLM rerankers). Specifically, our proposed algorithm merges results both from\nthe initial ranking and feedback documents provided by the most relevant\ndocuments seen up to that point. Through extensive experiments across diverse\nLLM rerankers, first stage retrievers, and feedback sources, we demonstrate\nthat our method can improve nDCG@10 by up to 13.23% and recall by 28.02%--all\nwhile keeping the total number of LLM inferences constant and overheads due to\nthe adaptive process minimal. The work opens the door to leveraging LLM-based\nsearch in settings where the initial pool of results is limited, e.g., by\nlegacy systems, or by the cost of deploying a semantic first-stage.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）作为 listwise rankers 在检索重排中的 bounded recall 问题提出了一种适应性检索方法，该问题导致初始检索遗漏的相关文档无法进入最终排名。所提出的算法支持 listwise 设置，通过合并初始排名结果和从最相关文档提供的反馈文档来指导检索过程，从而提升整体检索效率。实验在多种 LLM rerankers、第一阶段检索器和反馈来源上进行，结果显示 nDCG@10 提高了最多 13.23%，召回率提高了 28.02%，同时保持 LLM 推理次数不变并将额外开销最小化。该方法为在初始结果池受限场景（如遗留系统或部署成本限制）下应用 LLM-based 搜索提供了新途径。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "16 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09186v1",
      "published_date": "2025-01-15 22:23:53 UTC",
      "updated_date": "2025-01-15 22:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:42:38.186114"
    },
    {
      "arxiv_id": "2501.09182v1",
      "title": "A Blockchain-Enabled Approach to Cross-Border Compliance and Trust",
      "title_zh": "翻译失败",
      "authors": [
        "Vikram Kulothungan"
      ],
      "abstract": "As artificial intelligence (AI) systems become increasingly integral to\ncritical infrastructure and global operations, the need for a unified,\ntrustworthy governance framework is more urgent that ever. This paper proposes\na novel approach to AI governance, utilizing blockchain and distributed ledger\ntechnologies (DLT) to establish a decentralized, globally recognized framework\nthat ensures security, privacy, and trustworthiness of AI systems across\nborders. The paper presents specific implementation scenarios within the\nfinancial sector, outlines a phased deployment timeline over the next decade,\nand addresses potential challenges with solutions grounded in current research.\nBy synthesizing advancements in blockchain, AI ethics, and cybersecurity, this\npaper offers a comprehensive roadmap for a decentralized AI governance\nframework capable of adapting to the complex and evolving landscape of global\nAI regulation.",
      "tldr_zh": "本论文提出了一种基于 blockchain 和分布式账本技术 (DLT) 的新型方法，建立一个去中心化的全球 AI 治理框架，以确保跨国界 AI 系统的安全、隐私和可信度。论文聚焦于金融部门的特定实施场景，并规划了一个十年分阶段部署时间表，同时针对潜在挑战提供基于当前研究的解决方案。通过整合 blockchain、AI 伦理和网络安全领域的进展，该框架为适应复杂多变的全球 AI 监管环境提供了全面路线图。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a preprint of paper that has been accepted for Publication at\n  2024 IEEE International Conference on Trust, Privacy and Security in\n  Intelligent Systems, and Applications",
      "pdf_url": "http://arxiv.org/pdf/2501.09182v1",
      "published_date": "2025-01-15 22:19:34 UTC",
      "updated_date": "2025-01-15 22:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:42:50.128885"
    },
    {
      "arxiv_id": "2501.09166v1",
      "title": "Attention is All You Need Until You Need Retention",
      "title_zh": "翻译失败",
      "authors": [
        "M. Murat Yaslioglu"
      ],
      "abstract": "This work introduces a novel Retention Layer mechanism for Transformer based\narchitectures, addressing their inherent lack of intrinsic retention\ncapabilities. Unlike human cognition, which can encode and dynamically recall\nsymbolic templates, Generative Pretrained Transformers rely solely on fixed\npretrained weights and ephemeral context windows, limiting their adaptability.\nThe proposed Retention Layer incorporates a persistent memory module capable of\nreal time data population, dynamic recall, and guided output generation. This\nenhancement allows models to store, update, and reuse observed patterns across\nsessions, enabling incremental learning and bridging the gap between static\npretraining and dynamic, context sensitive adaptation. The Retention Layer\ndesign parallels social learning processes, encompassing attention, retention,\nreproduction, and motivation stages. Technically, it integrates a memory\nattention mechanism and episodic buffers to manage memory scalability, mitigate\noverfitting, and ensure efficient recall. Applications span adaptive personal\nassistants, real time fraud detection, autonomous robotics, content moderation,\nand healthcare diagnostics. In each domain, the retention mechanism enables\nsystems to learn incrementally, personalize outputs, and respond to evolving\nreal world challenges effectively. By emulating key aspects of human learning,\nthis retention enhanced architecture fosters a more fluid and responsive AI\nparadigm, paving the way for dynamic, session aware models that extend the\ncapabilities of traditional Transformers into domains requiring continual\nadaptation.",
      "tldr_zh": "本研究提出了一种新型 Retention Layer 机制，用于增强 Transformer 架构的内在保留能力，以克服其依赖固定预训练权重和短暂上下文窗口的局限性。Retention Layer 整合持久内存模块、内存注意机制和 episodic buffers，支持实时数据存储、动态回忆以及模式的重用，从而实现增量学习和上下文敏感的适应。实验结果显示，该机制在适应性个人助理、实时欺诈检测、自主机器人等领域表现出色，提升了模型的响应性和个性化输出，推动 AI 向更动态的人类学习范式演进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09166v1",
      "published_date": "2025-01-15 21:33:53 UTC",
      "updated_date": "2025-01-15 21:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:43:01.738858"
    },
    {
      "arxiv_id": "2501.09164v1",
      "title": "The Veln(ia)s is in the Details: Evaluating LLM Judgment on Latvian and Lithuanian Short Answer Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Yevhen Kostiuk",
        "Oxana Vitman",
        "Łukasz Gagała",
        "Artur Kiulian"
      ],
      "abstract": "In this work, we address the challenge of evaluating large language models\n(LLMs) on the short answer matching task for Latvian and Lithuanian languages.\nWe introduce novel datasets consisting of 502 Latvian and 690 Lithuanian\nquestion-answer pairs. For each question-answer pair, we generated matched and\nnon-matched answers using a set of alteration rules specifically designed to\nintroduce small but meaningful changes in the text. These generated answers\nserve as test cases to assess the ability of LLMs to detect subtle differences\nin matching of the original answers. A subset of the datasets was manually\nverified for quality and accuracy. Our results show that while larger LLMs,\nsuch as QWEN2.5 72b and LLaMa3.1 70b, demonstrate near-perfect performance in\ndistinguishing matched and non-matched answers, smaller models show more\nvariance. For instance, LLaMa3.1 8b and EuroLLM 9b benefited from few-shot\nexamples, while Mistral Nemo 12b underperformed on detection of subtle text\nalteration, particularly in Lithuanian, even with additional examples. QWEN2.5\n7b and Mistral 7b were able to obtain a strong and comparable performance to\nthe larger 70b models in zero and few shot experiments. Moreover, the\nperformance of Mistral 7b was weaker in few shot experiments.",
      "tldr_zh": "本文评估大型语言模型(LLMs)在拉脱维亚语和立陶宛语短答案匹配任务上的判断能力，引入了新数据集，包括502对拉脱维亚语和690对立陶宛语问题-答案对。研究通过alteration rules生成细微修改的匹配和非匹配答案，并测试LLMs检测这些差异的表现。结果显示，大型模型如QWEN2.5 72b和LLaMa3.1 70b在区分任务中近乎完美，而较小模型如Mistral Nemo 12b在few-shot设置下表现较弱，尤其在立陶宛语上；相反，QWEN2.5 7b和Mistral 7b在zero-shot和few-shot实验中表现出色，与大型模型相当。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09164v1",
      "published_date": "2025-01-15 21:30:03 UTC",
      "updated_date": "2025-01-15 21:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:43:15.731800"
    },
    {
      "arxiv_id": "2501.09163v1",
      "title": "Towards Understanding Extrapolation: a Causal Lens",
      "title_zh": "翻译失败",
      "authors": [
        "Lingjing Kong",
        "Guangyi Chen",
        "Petar Stojanov",
        "Haoxuan Li",
        "Eric P. Xing",
        "Kun Zhang"
      ],
      "abstract": "Canonical work handling distribution shifts typically necessitates an entire\ntarget distribution that lands inside the training distribution. However,\npractical scenarios often involve only a handful of target samples, potentially\nlying outside the training support, which requires the capability of\nextrapolation. In this work, we aim to provide a theoretical understanding of\nwhen extrapolation is possible and offer principled methods to achieve it\nwithout requiring an on-support target distribution. To this end, we formulate\nthe extrapolation problem with a latent-variable model that embodies the\nminimal change principle in causal mechanisms. Under this formulation, we cast\nthe extrapolation problem into a latent-variable identification problem. We\nprovide realistic conditions on shift properties and the estimation objectives\nthat lead to identification even when only one off-support target sample is\navailable, tackling the most challenging scenarios. Our theory reveals the\nintricate interplay between the underlying manifold's smoothness and the shift\nproperties. We showcase how our theoretical results inform the design of\npractical adaptation algorithms. Through experiments on both synthetic and\nreal-world data, we validate our theoretical findings and their practical\nimplications.",
      "tldr_zh": "这篇论文从因果视角（Causal Lens）探讨了外推（extrapolation）的理论理解，针对实际场景中目标样本可能位于训练分布外的问题。作者使用潜变量模型（latent-variable model）来制定外推问题，基于最小变化原则（minimal change principle）将之转化为潜变量识别问题，并给出了条件，即使只有一个不在支持内的目标样本也能实现识别。理论揭示了潜在流形平滑性和偏移属性的复杂互动，并据此设计了实际适应算法。通过合成和真实数据实验，论文验证了这些发现，为处理分布偏移提供了新颖的指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.09163v1",
      "published_date": "2025-01-15 21:29:29 UTC",
      "updated_date": "2025-01-15 21:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:43:27.002352"
    },
    {
      "arxiv_id": "2501.09160v1",
      "title": "AutoLoop: Fast Visual SLAM Fine-tuning through Agentic Curriculum Learning",
      "title_zh": "AutoLoop",
      "authors": [
        "Assaf Lahiany",
        "Oren Gal"
      ],
      "abstract": "Current visual SLAM systems face significant challenges in balancing\ncomputational efficiency with robust loop closure handling. Traditional\napproaches require careful manual tuning and incur substantial computational\noverhead, while learning-based methods either lack explicit loop closure\ncapabilities or implement them through computationally expensive methods. We\npresent AutoLoop, a novel approach that combines automated curriculum learning\nwith efficient fine-tuning for visual SLAM systems. Our method employs a DDPG\n(Deep Deterministic Policy Gradient) agent to dynamically adjust loop closure\nweights during training, eliminating the need for manual hyperparameter search\nwhile significantly reducing the required training steps. The approach\npre-computes potential loop closure pairs offline and leverages them through an\nagent-guided curriculum, allowing the model to adapt efficiently to new\nscenarios. Experiments conducted on TartanAir for training and validated across\nmultiple benchmarks including KITTI, EuRoC, ICL-NUIM and TUM RGB-D demonstrate\nthat AutoLoop achieves comparable or superior performance while reducing\ntraining time by an order of magnitude compared to traditional approaches.\nAutoLoop provides a practical solution for rapid adaptation of visual SLAM\nsystems, automating the weight tuning process that traditionally requires\nmultiple manual iterations. Our results show that this automated curriculum\nstrategy not only accelerates training but also maintains or improves the\nmodel's performance across diverse environmental conditions.",
      "tldr_zh": "这篇论文提出了AutoLoop，一种通过代理课程学习（Agentic Curriculum Learning）实现视觉SLAM（Visual SLAM）系统快速微调的创新方法，以解决传统方法在计算效率和环路闭合处理上的挑战。AutoLoop利用DDPG（Deep Deterministic Policy Gradient）代理动态调整训练中的环路闭合权重，并预计算潜在环路闭合对，从而自动化超参数搜索并减少训练步骤。在TartanAir等基准（如KITTI、EuRoC、ICL-NUIM和TUM RGB-D）上实验显示，AutoLoop将训练时间减少一个数量级，同时实现与传统方法相当或优越的性能，为视觉SLAM系统的快速适应提供了实用解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09160v1",
      "published_date": "2025-01-15 21:22:09 UTC",
      "updated_date": "2025-01-15 21:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:43:38.615016"
    },
    {
      "arxiv_id": "2501.09154v1",
      "title": "Towards Multilingual LLM Evaluation for Baltic and Nordic languages: A study on Lithuanian History",
      "title_zh": "翻译失败",
      "authors": [
        "Yevhen Kostiuk",
        "Oxana Vitman",
        "Łukasz Gagała",
        "Artur Kiulian"
      ],
      "abstract": "In this work, we evaluated Lithuanian and general history knowledge of\nmultilingual Large Language Models (LLMs) on a multiple-choice\nquestion-answering task. The models were tested on a dataset of Lithuanian\nnational and general history questions translated into Baltic, Nordic, and\nother languages (English, Ukrainian, Arabic) to assess the knowledge sharing\nfrom culturally and historically connected groups. We evaluated GPT-4o,\nLLaMa3.1 8b and 70b, QWEN2.5 7b and 72b, Mistral Nemo 12b, LLaMa3 8b, Mistral\n7b, LLaMa3.2 3b, and Nordic fine-tuned models (GPT-SW3 and LLaMa3 8b).\n  Our results show that GPT-4o consistently outperformed all other models\nacross language groups, with slightly better results for Baltic and Nordic\nlanguages. Larger open-source models like QWEN2.5 72b and LLaMa3.1 70b\nperformed well but showed weaker alignment with Baltic languages. Smaller\nmodels (Mistral Nemo 12b, LLaMa3.2 3b, QWEN 7B, LLaMa3.1 8B, and LLaMa3 8b)\ndemonstrated gaps with LT-related alignment with Baltic languages while\nperforming better on Nordic and other languages. The Nordic fine-tuned models\ndid not surpass multilingual models, indicating that shared cultural or\nhistorical context alone does not guarantee better performance.",
      "tldr_zh": "本文评估了多种多语言大型语言模型 (LLMs) 在立陶宛历史知识上的表现，使用多选问答任务和翻译数据集，涵盖波罗的海、Nordic 语言（如英语、乌克兰语、阿拉伯语），以探讨知识在文化相关群体间的共享。测试模型包括 GPT-4o、LLaMa3.1 8b 和 70b、QWEN2.5 7b 和 72b 等，结果显示 GPT-4o 在所有语言组中领先，尤其在波罗的海和 Nordic 语言上略占优势。较大开源模型如 QWEN2.5 72b 和 LLaMa3.1 70b 表现良好但对波罗的海语言适应性较弱，而较小模型和针对 Nordic 微调的模型（如 GPT-SW3）未超出多语言模型，表明共享文化或历史背景并不保证更好性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09154v1",
      "published_date": "2025-01-15 21:14:09 UTC",
      "updated_date": "2025-01-15 21:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:43:52.522168"
    },
    {
      "arxiv_id": "2501.09136v3",
      "title": "Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Aditi Singh",
        "Abul Ehtesham",
        "Saket Kumar",
        "Tala Talaei Khoei"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence (AI)\nby enabling human like text generation and natural language understanding.\nHowever, their reliance on static training data limits their ability to respond\nto dynamic, real time queries, resulting in outdated or inaccurate outputs.\nRetrieval Augmented Generation (RAG) has emerged as a solution, enhancing LLMs\nby integrating real time data retrieval to provide contextually relevant and\nup-to-date responses. Despite its promise, traditional RAG systems are\nconstrained by static workflows and lack the adaptability required for\nmultistep reasoning and complex task management.\n  Agentic Retrieval-Augmented Generation (Agentic RAG) transcends these\nlimitations by embedding autonomous AI agents into the RAG pipeline. These\nagents leverage agentic design patterns reflection, planning, tool use, and\nmultiagent collaboration to dynamically manage retrieval strategies,\niteratively refine contextual understanding, and adapt workflows to meet\ncomplex task requirements. This integration enables Agentic RAG systems to\ndeliver unparalleled flexibility, scalability, and context awareness across\ndiverse applications.\n  This survey provides a comprehensive exploration of Agentic RAG, beginning\nwith its foundational principles and the evolution of RAG paradigms. It\npresents a detailed taxonomy of Agentic RAG architectures, highlights key\napplications in industries such as healthcare, finance, and education, and\nexamines practical implementation strategies. Additionally, it addresses\nchallenges in scaling these systems, ensuring ethical decision making, and\noptimizing performance for real-world applications, while providing detailed\ninsights into frameworks and tools for implementing Agentic RAG.",
      "tldr_zh": "这篇调查论文探讨了Large Language Models (LLMs) 的局限性，即依赖静态训练数据导致响应不实时或不准确，并介绍了Retrieval-Augmented Generation (RAG) 作为解决方案，但传统 RAG 系统受限于静态工作流和缺乏适应性。Agentic RAG 通过整合自主 AI 代理，利用 reflection, planning, tool use 和 multiagent collaboration 等设计模式，动态管理检索策略、精炼上下文并适应复杂任务，从而提升灵活性、可扩展性和上下文意识。论文提供了 Agentic RAG 的基础原则、演变、分类、关键应用（如 healthcare, finance 和 education 领域）、实施策略，以及对挑战（如 scaling、ethical decision making 和性能优化）的分析，并分享了相关框架和工具以支持实际应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09136v3",
      "published_date": "2025-01-15 20:40:25 UTC",
      "updated_date": "2025-02-04 04:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:44:03.341520"
    },
    {
      "arxiv_id": "2501.09134v1",
      "title": "Benchmarking Robustness of Contrastive Learning Models for Medical Image-Report Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Demetrio Deanda",
        "Yuktha Priya Masupalli",
        "Jeong Yang",
        "Young Lee",
        "Zechun Cao",
        "Gongbo Liang"
      ],
      "abstract": "Medical images and reports offer invaluable insights into patient health. The\nheterogeneity and complexity of these data hinder effective analysis. To bridge\nthis gap, we investigate contrastive learning models for cross-domain\nretrieval, which associates medical images with their corresponding clinical\nreports. This study benchmarks the robustness of four state-of-the-art\ncontrastive learning models: CLIP, CXR-RePaiR, MedCLIP, and CXR-CLIP. We\nintroduce an occlusion retrieval task to evaluate model performance under\nvarying levels of image corruption. Our findings reveal that all evaluated\nmodels are highly sensitive to out-of-distribution data, as evidenced by the\nproportional decrease in performance with increasing occlusion levels. While\nMedCLIP exhibits slightly more robustness, its overall performance remains\nsignificantly behind CXR-CLIP and CXR-RePaiR. CLIP, trained on a\ngeneral-purpose dataset, struggles with medical image-report retrieval,\nhighlighting the importance of domain-specific training data. The evaluation of\nthis work suggests that more effort needs to be spent on improving the\nrobustness of these models. By addressing these limitations, we can develop\nmore reliable cross-domain retrieval models for medical applications.",
      "tldr_zh": "本研究评估了对比学习模型在医疗图像-报告检索中的鲁棒性，基准测试了四个先进模型：CLIP、CXR-RePaiR、MedCLIP 和 CXR-CLIP。通过引入遮挡检索任务，测试了这些模型在不同图像损坏水平下的性能。结果显示，所有模型对分布外数据高度敏感，性能随遮挡增加而显著下降，其中 MedCLIP 表现出略微更高的鲁棒性，但整体仍落后于 CXR-CLIP 和 CXR-RePaiR。该工作强调了领域特定训练数据的重要性，并呼吁进一步努力来提升这些模型的可靠性，以支持医疗应用的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work is accepted to AAAI 2025 Workshop -- the 9th International\n  Workshop on Health Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2501.09134v1",
      "published_date": "2025-01-15 20:37:04 UTC",
      "updated_date": "2025-01-15 20:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:44:14.423838"
    },
    {
      "arxiv_id": "2501.09114v1",
      "title": "Generative Medical Image Anonymization Based on Latent Code Projection and Optimization",
      "title_zh": "基于潜在代码投影和优化的生成式医学图像匿名化",
      "authors": [
        "Huiyu Li",
        "Nicholas Ayache",
        "Hervé Delingette"
      ],
      "abstract": "Medical image anonymization aims to protect patient privacy by removing\nidentifying information, while preserving the data utility to solve downstream\ntasks. In this paper, we address the medical image anonymization problem with a\ntwo-stage solution: latent code projection and optimization. In the projection\nstage, we design a streamlined encoder to project input images into a latent\nspace and propose a co-training scheme to enhance the projection process. In\nthe optimization stage, we refine the latent code using two deep loss functions\ndesigned to address the trade-off between identity protection and data utility\ndedicated to medical images. Through a comprehensive set of qualitative and\nquantitative experiments, we showcase the effectiveness of our approach on the\nMIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that\ncan serve as training set for detecting lung pathologies. Source codes are\navailable at https://github.com/Huiyu-Li/GMIA.",
      "tldr_zh": "该论文提出了一种基于潜在代码投影(latent code projection)和优化的生成式医疗图像匿名化方法，旨在保护患者隐私的同时保留图像数据效用。该方法分为两阶段：首先，使用一个简化的编码器将输入图像投影到潜在空间(latent space)，并通过联合训练方案(co-training scheme)提升投影精度；其次，通过两个深度损失函数(deep loss functions)优化潜在代码(latent code)，以平衡身份保护和数据效用。在MIMIC-CXR胸部X光数据集上的实验表明，该方法能生成有效的匿名合成图像，用于肺部病变检测训练集，提高了下游任务性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.09114v1",
      "published_date": "2025-01-15 19:50:56 UTC",
      "updated_date": "2025-01-15 19:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:44:25.860315"
    },
    {
      "arxiv_id": "2501.09112v1",
      "title": "Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Engel",
        "Nell Byler",
        "Adam Tsou",
        "Gautham Narayan",
        "Emmanuel Bonilla",
        "Ian Smith"
      ],
      "abstract": "We present Mantis Shrimp, a multi-survey deep learning model for photometric\nredshift estimation that fuses ultra-violet (GALEX), optical (PanSTARRS), and\ninfrared (UnWISE) imagery. Machine learning is now an established approach for\nphotometric redshift estimation, with generally acknowledged higher performance\nin areas with a high density of spectroscopically identified galaxies over\ntemplate-based methods. Multiple works have shown that image-based\nconvolutional neural networks can outperform tabular-based color/magnitude\nmodels. In comparison to tabular models, image models have additional design\ncomplexities: it is largely unknown how to fuse inputs from different\ninstruments which have different resolutions or noise properties. The Mantis\nShrimp model estimates the conditional density estimate of redshift using\ncutout images. The density estimates are well calibrated and the point\nestimates perform well in the distribution of available spectroscopically\nconfirmed galaxies with (bias = 1e-2), scatter (NMAD = 2.44e-2) and\ncatastrophic outlier rate ($\\eta$=17.53$\\%$). We find that early fusion\napproaches (e.g., resampling and stacking images from different instruments)\nmatch the performance of late fusion approaches (e.g., concatenating latent\nspace representations), so that the design choice ultimately is left to the\nuser. Finally, we study how the models learn to use information across bands,\nfinding evidence that our models successfully incorporates information from all\nsurveys. The applicability of our model to the analysis of large populations of\ngalaxies is limited by the speed of downloading cutouts from external servers;\nhowever, our model could be useful in smaller studies such as generating priors\nover redshift for stellar population synthesis.",
      "tldr_zh": "本研究提出Mantis Shrimp模型，这是一个多调查深度学习框架，用于光度红shift estimation（Photometric Redshift Estimation），通过融合GALEX（紫外）、PanSTARRS（光学）和UnWISE（红外）图像来提升性能。模型采用基于图像的卷积神经网络（CNNs），比较了早融合（如重采样和堆叠图像）和晚融合（如连接潜在空间表示）方法，发现两者性能相当，且模型成功整合了各波段信息。实验结果显示，该模型的红移密度估计校准良好，点估计在偏差（bias = 1e-2）、散度（NMAD = 2.44e-2）和灾难性异常率（η=17.53%）上表现出色。尽管受图像下载速度限制，该模型适用于生成红移先验或较小规模的星系种群分析。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09112v1",
      "published_date": "2025-01-15 19:46:23 UTC",
      "updated_date": "2025-01-15 19:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:44:40.902728"
    },
    {
      "arxiv_id": "2501.09104v2",
      "title": "A Non-autoregressive Model for Joint STT and TTS",
      "title_zh": "一种用于联合 STT 和 TTS 的非自回归模型",
      "authors": [
        "Vishal Sunder",
        "Brian Kingsbury",
        "George Saon",
        "Samuel Thomas",
        "Slava Shechtman",
        "Hagai Aronowitz",
        "Eric Fosler-Lussier",
        "Luis Lastras"
      ],
      "abstract": "In this paper, we take a step towards jointly modeling automatic speech\nrecognition (STT) and speech synthesis (TTS) in a fully non-autoregressive way.\nWe develop a novel multimodal framework capable of handling the speech and text\nmodalities as input either individually or together. The proposed model can\nalso be trained with unpaired speech or text data owing to its multimodal\nnature. We further propose an iterative refinement strategy to improve the STT\nand TTS performance of our model such that the partial hypothesis at the output\ncan be fed back to the input of our model, thus iteratively improving both STT\nand TTS predictions. We show that our joint model can effectively perform both\nSTT and TTS tasks, outperforming the STT-specific baseline in all tasks and\nperforming competitively with the TTS-specific baseline across a wide range of\nevaluation metrics.",
      "tldr_zh": "本论文提出一个非自回归模型，用于联合建模自动语音识别(STT)和语音合成(TTS)，以实现高效的多任务处理。该模型采用多模态框架，能同时处理语音和文本作为单个或联合输入，并支持未配对数据的训练，从而提升灵活性。此外，论文引入迭代精炼策略，通过将部分输出反馈到输入来逐步改进STT和TTS性能。实验结果表明，该联合模型在STT任务上优于专用基线，在TTS任务上与专用基线在多种评估指标上表现出竞争力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09104v2",
      "published_date": "2025-01-15 19:42:41 UTC",
      "updated_date": "2025-01-20 18:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:44:50.615764"
    },
    {
      "arxiv_id": "2501.09102v1",
      "title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites",
      "title_zh": "翻译失败",
      "authors": [
        "Hans W. A. Hanley",
        "Emily Okabe",
        "Zakir Durumeric"
      ],
      "abstract": "Understanding how misleading and outright false information enters news\necosystems remains a difficult challenge that requires tracking how narratives\nspread across thousands of fringe and mainstream news websites. To do this, we\nintroduce a system that utilizes encoder-based large language models and\nzero-shot stance detection to scalably identify and track news narratives and\ntheir attitudes across over 4,000 factually unreliable, mixed-reliability, and\nfactually reliable English-language news websites. Running our system over an\n18 month period, we track the spread of 146K news stories. Using network-based\ninterference via the NETINF algorithm, we show that the paths of news\nnarratives and the stances of websites toward particular entities can be used\nto uncover slanted propaganda networks (e.g., anti-vaccine and anti-Ukraine)\nand to identify the most influential websites in spreading these attitudes in\nthe broader news ecosystem. We hope that increased visibility into our\ndistributed news ecosystem can help with the reporting and fact-checking of\npropaganda and disinformation.",
      "tldr_zh": "该研究开发了一个系统，利用基于编码器的LLM和zero-shot stance detection技术，在超过4000个英语新闻网站（包括事实不可靠、混合可靠和事实可靠的网站）上，可扩展地识别和追踪新闻叙事及其态度。系统运行18个月，追踪了146K条新闻故事，并通过NETINF算法进行网络干预，揭示了新闻叙事路径和网站姿态如何暴露偏向宣传网络（如反疫苗和反乌克兰网络），并识别出传播这些态度的最具影响力的网站。该方法为报道和事实检查宣传及虚假信息提供了重要工具，提升了对分布式新闻生态系统的可见性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "To appear at USENIX Security Symposium 2025. Keywords:\n  Misinformation, News, Narratives, LLMs, Stance-Detection",
      "pdf_url": "http://arxiv.org/pdf/2501.09102v1",
      "published_date": "2025-01-15 19:37:44 UTC",
      "updated_date": "2025-01-15 19:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:45:02.116798"
    },
    {
      "arxiv_id": "2501.09092v1",
      "title": "SteLLA: A Structured Grading System Using LLMs with RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Hefei Qiu",
        "Brian White",
        "Ashley Ding",
        "Reinaldo Costa",
        "Ali Hachem",
        "Wei Ding",
        "Ping Chen"
      ],
      "abstract": "Large Language Models (LLMs) have shown strong general capabilities in many\napplications. However, how to make them reliable tools for some specific tasks\nsuch as automated short answer grading (ASAG) remains a challenge. We present\nSteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval\nAugmented Generation (RAG) approach is used to empower LLMs specifically on the\nASAG task by extracting structured information from the highly relevant and\nreliable external knowledge based on the instructor-provided reference answer\nand rubric, b) an LLM performs a structured and question-answering-based\nevaluation of student answers to provide analytical grades and feedback. A\nreal-world dataset that contains students' answers in an exam was collected\nfrom a college-level Biology course. Experiments show that our proposed system\ncan achieve substantial agreement with the human grader while providing\nbreak-down grades and feedback on all the knowledge points examined in the\nproblem. A qualitative and error analysis of the feedback generated by GPT4\nshows that GPT4 is good at capturing facts while may be prone to inferring too\nmuch implication from the given text in the grading task which provides\ninsights into the usage of LLMs in the ASAG system.",
      "tldr_zh": "该论文提出SteLLA，一种基于LLMs（Large Language Models）和RAG（Retrieval Augmented Generation）的结构化评分系统，用于解决自动短答案评分（ASAG）任务的可靠性问题。该系统通过RAG从教师提供的参考答案和评分标准中提取结构化信息，并利用LLMs进行问答式评估，提供详细的分析性分数和反馈。实验在真实大学生物课程考试数据集上显示，SteLLA与人工评分者达成高度一致，同时给出知识点分解反馈；定性和错误分析揭示，GPT4擅长捕捉事实但易过度推断含义，为LLMs在ASAG中的应用提供宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09092v1",
      "published_date": "2025-01-15 19:24:48 UTC",
      "updated_date": "2025-01-15 19:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:45:14.091348"
    },
    {
      "arxiv_id": "2501.09081v1",
      "title": "Inferring Transition Dynamics from Value Functions",
      "title_zh": "从价值函数推断转移动态",
      "authors": [
        "Jacob Adamczyk"
      ],
      "abstract": "In reinforcement learning, the value function is typically trained to solve\nthe Bellman equation, which connects the current value to future values. This\ntemporal dependency hints that the value function may contain implicit\ninformation about the environment's transition dynamics. By rearranging the\nBellman equation, we show that a converged value function encodes a model of\nthe underlying dynamics of the environment. We build on this insight to propose\na simple method for inferring dynamics models directly from the value function,\npotentially mitigating the need for explicit model learning. Furthermore, we\nexplore the challenges of next-state identifiability, discussing conditions\nunder which the inferred dynamics model is well-defined. Our work provides a\ntheoretical foundation for leveraging value functions in dynamics modeling and\nopens a new avenue for bridging model-free and model-based reinforcement\nlearning.",
      "tldr_zh": "该研究揭示了在强化学习中，价值函数(Value Function)隐含了环境转移动态(Transition Dynamics)的信息，通过重新排列贝尔曼方程(Bellman Equation)，作者证明了收敛的价值函数可以编码环境动态模型。基于此，他们提出了一种简单方法，直接从价值函数推断动态模型，从而潜在地减少对显式模型学习的依赖。论文探讨了下一状态的可识别性条件，讨论了模型定义的必要前提，并为桥接无模型和有模型强化学习提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the AAAI-25 8th Workshop on Generalization in Planning",
      "pdf_url": "http://arxiv.org/pdf/2501.09081v1",
      "published_date": "2025-01-15 19:00:47 UTC",
      "updated_date": "2025-01-15 19:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:45:26.589619"
    },
    {
      "arxiv_id": "2501.09080v1",
      "title": "Average-Reward Reinforcement Learning with Entropy Regularization",
      "title_zh": "带熵正则化的平均奖励强化学习",
      "authors": [
        "Jacob Adamczyk",
        "Volodymyr Makarenko",
        "Stas Tiomkin",
        "Rahul V. Kulkarni"
      ],
      "abstract": "The average-reward formulation of reinforcement learning (RL) has drawn\nincreased interest in recent years due to its ability to solve\ntemporally-extended problems without discounting. Independently, RL algorithms\nhave benefited from entropy-regularization: an approach used to make the\noptimal policy stochastic, thereby more robust to noise. Despite the distinct\nbenefits of the two approaches, the combination of entropy regularization with\nan average-reward objective is not well-studied in the literature and there has\nbeen limited development of algorithms for this setting. To address this gap in\nthe field, we develop algorithms for solving entropy-regularized average-reward\nRL problems with function approximation. We experimentally validate our method,\ncomparing it with existing algorithms on standard benchmarks for RL.",
      "tldr_zh": "这篇论文探讨了average-reward reinforcement learning与entropy regularization的结合，以解决不打折的长期强化学习问题并提升策略的鲁棒性。由于现有研究较少，本文开发了使用function approximation的算法，来处理熵正则化的average-reward RL问题。实验结果显示，该方法在标准基准上与现有算法相比表现出色，填补了这一领域的空白。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the AAAI-25 Eighth Workshop on Bridging the Gap Between\n  AI Planning and Reinforcement Learning (PRL)",
      "pdf_url": "http://arxiv.org/pdf/2501.09080v1",
      "published_date": "2025-01-15 19:00:46 UTC",
      "updated_date": "2025-01-15 19:00:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:45:38.261634"
    },
    {
      "arxiv_id": "2501.09770v1",
      "title": "EVAL: EigenVector-based Average-reward Learning",
      "title_zh": "EVAL：基于特征向量的平均奖励学习",
      "authors": [
        "Jacob Adamczyk",
        "Volodymyr Makarenko",
        "Stas Tiomkin",
        "Rahul V. Kulkarni"
      ],
      "abstract": "In reinforcement learning, two objective functions have been developed\nextensively in the literature: discounted and averaged rewards. The\ngeneralization to an entropy-regularized setting has led to improved robustness\nand exploration for both of these objectives. Recently, the entropy-regularized\naverage-reward problem was addressed using tools from large deviation theory in\nthe tabular setting. This method has the advantage of linearity, providing\naccess to both the optimal policy and average reward-rate through properties of\na single matrix. In this paper, we extend that framework to more general\nsettings by developing approaches based on function approximation by neural\nnetworks. This formulation reveals new theoretical insights into the\nrelationship between different objectives used in RL. Additionally, we combine\nour algorithm with a posterior policy iteration scheme, showing how our\napproach can also solve the average-reward RL problem without\nentropy-regularization. Using classic control benchmarks, we experimentally\nfind that our method compares favorably with other algorithms in terms of\nstability and rate of convergence.",
      "tldr_zh": "本文提出EVAL，一种基于特征向量(EigenVector-based)的平均奖励学习方法，扩展了熵正则化(entropy-regularized)平均奖励问题到神经网络函数逼近的通用设置。该框架利用大偏差理论工具，提供强化学习(reinforcement learning)中不同目标函数之间的新理论洞见，并通过后验策略迭代(posterior policy iteration)方案解决无熵正则化的平均奖励问题。在经典控制基准实验中，EVAL显示出比其他算法更优的稳定性和收敛速度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the AAAI-25 8th Workshop on Generalization in Planning.\n  arXiv admin note: text overlap with arXiv:2501.09080",
      "pdf_url": "http://arxiv.org/pdf/2501.09770v1",
      "published_date": "2025-01-15 19:00:45 UTC",
      "updated_date": "2025-01-15 19:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:45:50.590019"
    },
    {
      "arxiv_id": "2501.09014v1",
      "title": "How Do Generative Models Draw a Software Engineer? A Case Study on Stable Diffusion Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Tosin Fadahunsi",
        "Giordano d'Aloisio",
        "Antinisca Di Marco",
        "Federica Sarro"
      ],
      "abstract": "Generative models are nowadays widely used to generate graphical content used\nfor multiple purposes, e.g. web, art, advertisement. However, it has been shown\nthat the images generated by these models could reinforce societal biases\nalready existing in specific contexts. In this paper, we focus on understanding\nif this is the case when one generates images related to various software\nengineering tasks. In fact, the Software Engineering (SE) community is not\nimmune from gender and ethnicity disparities, which could be amplified by the\nuse of these models. Hence, if used without consciousness, artificially\ngenerated images could reinforce these biases in the SE domain. Specifically,\nwe perform an extensive empirical evaluation of the gender and ethnicity bias\nexposed by three versions of the Stable Diffusion (SD) model (a very popular\nopen-source text-to-image model) - SD 2, SD XL, and SD 3 - towards SE tasks. We\nobtain 6,720 images by feeding each model with two sets of prompts describing\ndifferent software-related tasks: one set includes the Software Engineer\nkeyword, and one set does not include any specification of the person\nperforming the task. Next, we evaluate the gender and ethnicity disparities in\nthe generated images. Results show how all models are significantly biased\ntowards male figures when representing software engineers. On the contrary,\nwhile SD 2 and SD XL are strongly biased towards White figures, SD 3 is\nslightly more biased towards Asian figures. Nevertheless, all models\nsignificantly under-represent Black and Arab figures, regardless of the prompt\nstyle used. The results of our analysis highlight severe concerns about\nadopting those models to generate content for SE tasks and open the field for\nfuture research on bias mitigation in this context.",
      "tldr_zh": "这篇论文探讨了生成模型（如Stable Diffusion）在生成软件工程相关图像时是否强化了性别和种族偏见，通过对软件工程任务的实证评估来揭示这一问题。研究者使用Stable Diffusion的三个版本（SD 2、SD XL和SD 3）生成6720张图像，基于两种提示集（一种包含“Software Engineer”关键词，另一种不指定人）来分析性别和ethnicity bias。结果显示，所有模型在描绘软件工程师时显著偏向男性，且种族偏见突出：SD 2和SD XL偏向White figures，而SD 3略偏向Asian figures，但所有版本都严重低估Black和Arab figures。该研究强调了在软件工程领域使用这些模型的潜在风险，并呼吁未来开展bias mitigation研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09014v1",
      "published_date": "2025-01-15 18:57:17 UTC",
      "updated_date": "2025-01-15 18:57:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:46:03.360980"
    },
    {
      "arxiv_id": "2501.09012v2",
      "title": "Multimodal LLMs Can Reason about Aesthetics in Zero-Shot",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixiang Jiang",
        "Changwen Chen"
      ],
      "abstract": "The rapid progress of generative art has democratized the creation of\nvisually pleasing imagery. However, achieving genuine artistic impact - the\nkind that resonates with viewers on a deeper, more meaningful level - requires\na sophisticated aesthetic sensibility. This sensibility involves a\nmulti-faceted reasoning process extending beyond mere visual appeal, which is\noften overlooked by current computational models. This paper pioneers an\napproach to capture this complex process by investigating how the reasoning\ncapabilities of Multimodal LLMs (MLLMs) can be effectively elicited for\naesthetic judgment. Our analysis reveals a critical challenge: MLLMs exhibit a\ntendency towards hallucinations during aesthetic reasoning, characterized by\nsubjective opinions and unsubstantiated artistic interpretations. We further\ndemonstrate that these limitations can be overcome by employing an\nevidence-based, objective reasoning process, as substantiated by our proposed\nbaseline, ArtCoT. MLLMs prompted by this principle produce multi-faceted and\nin-depth aesthetic reasoning that aligns significantly better with human\njudgment. These findings have direct applications in areas such as AI art\ntutoring and as reward models for generative art. Ultimately, our work paves\nthe way for AI systems that can truly understand, appreciate, and generate\nartworks that align with the sensible human aesthetic standard.",
      "tldr_zh": "本研究探讨了Multimodal LLMs (MLLMs) 在零样本（zero-shot）条件下进行审美推理的能力，旨在捕捉艺术影响力的多方面过程，而非仅限于视觉吸引力。研究发现，MLLMs 在审美判断中容易出现 hallucinations，包括主观意见和无依据的解释，导致推理不准确。作者提出了一种基于证据的客观推理方法ArtCoT，通过提示引导 MLLMs 产生更全面、深入的审美分析，并显著提升了其输出与人类判断的一致性。该方法的应用前景包括 AI 艺术 tutoring 和作为生成艺术的 reward models，最终推动 AI 系统更好地理解和生成符合人类审美标准的艺术作品。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "WIP, Homepage https://github.com/songrise/MLLM4Art",
      "pdf_url": "http://arxiv.org/pdf/2501.09012v2",
      "published_date": "2025-01-15 18:56:22 UTC",
      "updated_date": "2025-04-17 17:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:46:14.563561"
    },
    {
      "arxiv_id": "2501.09007v1",
      "title": "AI-RAN: Transforming RAN with AI-driven Computing Infrastructure",
      "title_zh": "翻译失败",
      "authors": [
        "Lopamudra Kundu",
        "Xingqin Lin",
        "Rajesh Gadiyar",
        "Jean-Francois Lacasse",
        "Shuvo Chowdhury"
      ],
      "abstract": "The radio access network (RAN) landscape is undergoing a transformative shift\nfrom traditional, communication-centric infrastructures towards converged\ncompute-communication platforms. This article introduces AI-RAN which\nintegrates both RAN and artificial intelligence (AI) workloads on the same\ninfrastructure. By doing so, AI-RAN not only meets the performance demands of\nfuture networks but also improves asset utilization. We begin by examining how\nRANs have evolved beyond mobile broadband towards AI-RAN and articulating\nmanifestations of AI-RAN into three forms: AI-for-RAN, AI-on-RAN, and\nAI-and-RAN. Next, we identify the key requirements and enablers for the\nconvergence of communication and computing in AI-RAN. We then provide a\nreference architecture for advancing AI-RAN from concept to practice. To\nillustrate the practical potential of AI-RAN, we present a proof-of-concept\nthat concurrently processes RAN and AI workloads utilizing NVIDIA Grace-Hopper\nGH200 servers. Finally, we conclude the article by outlining future work\ndirections to guide further developments of AI-RAN.",
      "tldr_zh": "这篇论文介绍了 AI-RAN 框架，将无线接入网络（RAN）与人工智能（AI）工作负载整合到同一基础设施中，实现性能提升和资产利用率的优化。论文分析了 RAN 从移动宽带向 AI-RAN 的演变，并将其分为 AI-for-RAN、AI-on-RAN 和 AI-and-RAN 三种形式，同时识别关键要求、推动因素，并提出一个参考架构来推进实际应用。通过使用 NVIDIA Grace-Hopper GH200 服务器的证明概念，展示了 AI-RAN 能够同时处理 RAN 和 AI 工作负载的潜力，并为未来发展方向提供了指导。",
      "categories": [
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09007v1",
      "published_date": "2025-01-15 18:47:05 UTC",
      "updated_date": "2025-01-15 18:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:46:26.578748"
    },
    {
      "arxiv_id": "2501.09056v1",
      "title": "Decompose-ToM: Enhancing Theory of Mind Reasoning in Large Language Models through Simulation and Task Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Sneheel Sarangi",
        "Maha Elgarf",
        "Hanan Salam"
      ],
      "abstract": "Theory of Mind (ToM) is the ability to understand and reflect on the mental\nstates of others. Although this capability is crucial for human interaction,\ntesting on Large Language Models (LLMs) reveals that they possess only a\nrudimentary understanding of it. Although the most capable closed-source LLMs\nhave come close to human performance on some ToM tasks, they still perform\npoorly on complex variations of the task that involve more structured\nreasoning. In this work, we utilize the concept of \"pretend-play\", or\n``Simulation Theory'' from cognitive psychology to propose ``Decompose-ToM'':\nan LLM-based inference algorithm that improves model performance on complex ToM\ntasks. We recursively simulate user perspectives and decompose the ToM task\ninto a simpler set of functions: subject identification, question-reframing,\nworld model updation, and knowledge availability. We test the algorithm on\nhigher-order ToM tasks and a task testing for ToM capabilities in a\nconversational setting, demonstrating that our approach shows significant\nimprovement across models compared to baseline methods while requiring minimal\nprompt tuning across tasks and no additional model training.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）在理论心智（Theory of Mind, ToM）推理方面的不足，提出了一种名为 Decompose-ToM 的算法，通过模拟理论（Simulation Theory）来提升模型对他人心理状态的理解。Decompose-ToM 算法递归模拟用户视角，并将复杂 ToM 任务分解为简单子任务，包括主体识别（subject identification）、问题重构（question-reframing）、世界模型更新（world model updation）和知识可用性（knowledge availability）。实验结果显示，该方法在更高阶 ToM 任务和对话场景中显著优于基线方法，且仅需最小提示调整，无需额外模型训练，从而提高了 LLMs 的 ToM 性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09056v1",
      "published_date": "2025-01-15 18:44:01 UTC",
      "updated_date": "2025-01-15 18:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:46:38.497734"
    },
    {
      "arxiv_id": "2501.10467v1",
      "title": "Securing the AI Frontier: Urgent Ethical and Regulatory Imperatives for AI-Driven Cybersecurity",
      "title_zh": "保护AI前沿：针对AI驱动网络安全的紧急伦理和监管要求",
      "authors": [
        "Vikram Kulothungan"
      ],
      "abstract": "This paper critically examines the evolving ethical and regulatory challenges\nposed by the integration of artificial intelligence (AI) in cybersecurity. We\ntrace the historical development of AI regulation, highlighting major\nmilestones from theoretical discussions in the 1940s to the implementation of\nrecent global frameworks such as the European Union AI Act. The current\nregulatory landscape is analyzed, emphasizing risk-based approaches,\nsector-specific regulations, and the tension between fostering innovation and\nmitigating risks. Ethical concerns such as bias, transparency, accountability,\nprivacy, and human oversight are explored in depth, along with their\nimplications for AI-driven cybersecurity systems. Furthermore, we propose\nstrategies for promoting AI literacy and public engagement, essential for\nshaping a future regulatory framework. Our findings underscore the need for a\nunified, globally harmonized regulatory approach that addresses the unique\nrisks of AI in cybersecurity. We conclude by identifying future research\nopportunities and recommending pathways for collaboration between policymakers,\nindustry leaders, and researchers to ensure the responsible deployment of AI\ntechnologies in cybersecurity.",
      "tldr_zh": "这篇论文审视了人工智能(AI)在网络安全(cybersecurity)领域的伦理和监管挑战，追溯了AI监管的历史从1940年代的理论讨论到最近的全球框架如欧盟AI法案(EU AI Act)。作者分析了当前的风险导向(risk-based)方法、行业特定规定，以及在推动创新与缓解风险之间的张力，同时深入探讨了偏见(bias)、透明性(transparency)、责任(accountability)、隐私和人类监督(human oversight)等伦理问题及其对AI驱动网络安全系统的含义。论文提出促进AI素养和公众参与的策略，强调需要统一的全球协调监管框架，并为政策制定者、行业领袖和研究者推荐合作路径，以确保AI在网络安全中的负责任部署。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This is a preprint of a paper that has been accepted at BigCyber at\n  2024 IEEE International Conference on Big Data (IEEE BigData 2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.10467v1",
      "published_date": "2025-01-15 18:17:37 UTC",
      "updated_date": "2025-01-15 18:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:46:49.768240"
    },
    {
      "arxiv_id": "2503.15497v1",
      "title": "The Impact of Big Five Personality Traits on AI Agent Decision-Making in Public Spaces: A Social Simulation Study",
      "title_zh": "大五人格特质对AI代理在公共空间决策的影响：一项社会模拟研究",
      "authors": [
        "Mingjun Ren",
        "Wentao Xu"
      ],
      "abstract": "This study investigates how the Big Five personality traits influence\ndecision-making processes in AI agents within public spaces. Using AgentVerse\nframework and GPT-3.5-turbo, we simulated interactions among 10 AI agents, each\nembodying different dimensions of the Big Five personality traits, in a\nclassroom environment responding to misinformation. The experiment assessed\nboth public expressions ([Speak]) and private thoughts ([Think]) of agents,\nrevealing significant correlations between personality traits and\ndecision-making patterns. Results demonstrate that Openness to Experience had\nthe strongest impact on information acceptance, with curious agents showing\nhigh acceptance rates and cautious agents displaying strong skepticism.\nExtraversion and Conscientiousness also showed notable influence on\ndecision-making, while Neuroticism and Agreeableness exhibited more balanced\nresponses. Additionally, we observed significant discrepancies between public\nexpressions and private thoughts, particularly in agents with friendly and\nextroverted personalities, suggesting that social context influences\ndecision-making behavior. Our findings contribute to understanding how\npersonality traits shape AI agent behavior in social settings and have\nimplications for developing more nuanced and context-aware AI systems.",
      "tldr_zh": "本研究探讨了 Big Five personality traits 如何影响 AI 代理在公共空间的决策过程，使用 AgentVerse 框架和 GPT-3.5-turbo 模拟了 10 个代理在教室环境中响应错误信息的互动。结果显示，Openness to Experience 对信息接受影响最大，好奇的代理接受率高，而谨慎的代理表现出强烈怀疑；Extraversion 和 Conscientiousness 也显著影响决策行为，而 Neuroticism 和 Agreeableness 则显示更平衡的响应。研究进一步观察到代理的公共表达 ([Speak]) 和私人想法 ([Think]) 之间存在显著差异，尤其在友好和外向的代理中，这反映了社会上下文对决策行为的影响。该研究为理解个性特征对 AI 代理行为的作用提供了新见解，并为开发更细致和上下文感知的 AI 系统提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15497v1",
      "published_date": "2025-01-15 18:06:18 UTC",
      "updated_date": "2025-01-15 18:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:47:04.313927"
    },
    {
      "arxiv_id": "2501.08985v1",
      "title": "Personality Modeling for Persuasion of Misinformation using AI Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Qianmin Lou",
        "Wentao Xu"
      ],
      "abstract": "The proliferation of misinformation on social media platforms has highlighted\nthe need to understand how individual personality traits influence\nsusceptibility to and propagation of misinformation. This study employs an\ninnovative agent-based modeling approach to investigate the relationship\nbetween personality traits and misinformation dynamics. Using six AI agents\nembodying different dimensions of the Big Five personality traits\n(Extraversion, Agreeableness, and Neuroticism), we simulated interactions\nacross six diverse misinformation topics. The experiment, implemented through\nthe AgentScope framework using the GLM-4-Flash model, generated 90 unique\ninteractions, revealing complex patterns in how personality combinations affect\npersuasion and resistance to misinformation. Our findings demonstrate that\nanalytical and critical personality traits enhance effectiveness in\nevidence-based discussions, while non-aggressive persuasion strategies show\nunexpected success in misinformation correction. Notably, agents with critical\ntraits achieved a 59.4% success rate in HIV-related misinformation discussions,\nwhile those employing non-aggressive approaches maintained consistent\npersuasion rates above 40% across different personality combinations. The study\nalso revealed a non-transitive pattern in persuasion effectiveness, challenging\nconventional assumptions about personality-based influence. These results\nprovide crucial insights for developing personality-aware interventions in\ndigital environments and suggest that effective misinformation countermeasures\nshould prioritize emotional connection and trust-building over confrontational\napproaches. The findings contribute to both theoretical understanding of\npersonality-misinformation dynamics and practical strategies for combating\nmisinformation in social media contexts.",
      "tldr_zh": "本研究使用 AI 代理建模 Big Five 人格特质（包括 Extraversion、Agreeableness 和 Neuroticism），通过 AgentScope 框架和 GLM-4-Flash 模型模拟社交媒体上的错误信息互动，生成90个独特场景以探讨人格对说服和抵抗的影响。实验结果显示，分析性和批判性人格特质在 evidence-based 讨论中更有效，例如批判性特质的代理在 HIV 相关错误信息讨论中达到59.4%的成功率，而非攻击性说服策略在不同人格组合中保持超过40%的说服率。研究还发现说服效果存在非传递性模式，挑战了传统假设，并为数字环境中的 personality-aware 干预提供见解，建议优先采用情感连接和信任构建的策略来对抗错误信息。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08985v1",
      "published_date": "2025-01-15 18:04:21 UTC",
      "updated_date": "2025-01-15 18:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:47:16.801552"
    },
    {
      "arxiv_id": "2501.08977v2",
      "title": "Development and Validation of the Provider Documentation Summarization Quality Instrument for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Emma Croxford",
        "Yanjun Gao",
        "Nicholas Pellegrino",
        "Karen K. Wong",
        "Graham Wills",
        "Elliot First",
        "Miranda Schnier",
        "Kyle Burton",
        "Cris G. Ebby",
        "Jillian Gorskic",
        "Matthew Kalscheur",
        "Samy Khalil",
        "Marie Pisani",
        "Tyler Rubeor",
        "Peter Stetson",
        "Frank Liao",
        "Cherodeep Goswami",
        "Brian Patterson",
        "Majid Afshar"
      ],
      "abstract": "As Large Language Models (LLMs) are integrated into electronic health record\n(EHR) workflows, validated instruments are essential to evaluate their\nperformance before implementation. Existing instruments for provider\ndocumentation quality are often unsuitable for the complexities of\nLLM-generated text and lack validation on real-world data. The Provider\nDocumentation Summarization Quality Instrument (PDSQI-9) was developed to\nevaluate LLM-generated clinical summaries. Multi-document summaries were\ngenerated from real-world EHR data across multiple specialties using several\nLLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson\ncorrelation for substantive validity, factor analysis and Cronbach's alpha for\nstructural validity, inter-rater reliability (ICC and Krippendorff's alpha) for\ngeneralizability, a semi-Delphi process for content validity, and comparisons\nof high-versus low-quality summaries for discriminant validity. Seven physician\nraters evaluated 779 summaries and answered 8,329 questions, achieving over 80%\npower for inter-rater reliability. The PDSQI-9 demonstrated strong internal\nconsistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high\ninter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting\nstructural validity and generalizability. Factor analysis identified a 4-factor\nmodel explaining 58% of the variance, representing organization, clarity,\naccuracy, and utility. Substantive validity was supported by correlations\nbetween note length and scores for Succinct (rho = -0.200, p = 0.029) and\nOrganized ($\\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished\nhigh- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust\nconstruct validity, supporting its use in clinical practice to evaluate\nLLM-generated summaries and facilitate safer integration of LLMs into\nhealthcare workflows.",
      "tldr_zh": "本文开发并验证了PDSQI-9（Provider Documentation Summarization Quality Instrument），一种专门用于评估大型语言模型（LLMs）生成临床总结质量的工具，以解决现有评估方法在处理真实EHR数据时的不足。研究方法包括使用GPT-4o、Mixtral 8x7b和Llama 3-8b等模型生成多文档总结，并通过Pearson相关、因子分析、Cronbach's alpha和ICC等统计验证来评估其结构有效性、可靠性和区分能力。结果显示PDSQI-9具有强内部一致性（Cronbach's alpha = 0.879）和高评级者间可靠性（ICC = 0.867），并识别出四个关键因素（organization, clarity, accuracy, and utility），成功区分高质量与低质量总结。该工具的稳健构建有效性支持其在临床实践中应用，促进LLMs在医疗工作流中的安全整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08977v2",
      "published_date": "2025-01-15 17:47:57 UTC",
      "updated_date": "2025-01-17 19:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:47:27.073975"
    },
    {
      "arxiv_id": "2501.08970v1",
      "title": "Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography",
      "title_zh": "可信的机器学习模型解锁了密码学目前无法处理的私有推理问题",
      "authors": [
        "Ilia Shumailov",
        "Daniel Ramage",
        "Sarah Meiklejohn",
        "Peter Kairouz",
        "Florian Hartmann",
        "Borja Balle",
        "Eugene Bagdasarian"
      ],
      "abstract": "We often interact with untrusted parties. Prioritization of privacy can limit\nthe effectiveness of these interactions, as achieving certain goals\nnecessitates sharing private data. Traditionally, addressing this challenge has\ninvolved either seeking trusted intermediaries or constructing cryptographic\nprotocols that restrict how much data is revealed, such as multi-party\ncomputations or zero-knowledge proofs. While significant advances have been\nmade in scaling cryptographic approaches, they remain limited in terms of the\nsize and complexity of applications they can be used for. In this paper, we\nargue that capable machine learning models can fulfill the role of a trusted\nthird party, thus enabling secure computations for applications that were\npreviously infeasible. In particular, we describe Trusted Capable Model\nEnvironments (TCMEs) as an alternative approach for scaling secure computation,\nwhere capable machine learning model(s) interact under input/output\nconstraints, with explicit information flow control and explicit statelessness.\nThis approach aims to achieve a balance between privacy and computational\nefficiency, enabling private inference where classical cryptographic solutions\nare currently infeasible. We describe a number of use cases that are enabled by\nTCME, and show that even some simple classic cryptographic problems can already\nbe solved with TCME. Finally, we outline current limitations and discuss the\npath forward in implementing them.",
      "tldr_zh": "该论文讨论了在与不受信任方交互时，隐私保护可能限制数据共享的有效性，而传统加密方法如 multi-party computations 和 zero-knowledge proofs 虽然先进，却受限于应用规模和复杂度。作者提出 Trusted Capable Model Environments (TCMEs) 作为替代方案，利用强大的 machine learning models 作为受信任第三方，在输入/输出约束、信息流控制和无状态性条件下进行安全计算，从而实现之前不可行的私有推理。TCMEs 能处理各种用例，包括解决一些经典加密问题，并展示了隐私与计算效率的平衡。论文还概述了当前限制和未来实施路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08970v1",
      "published_date": "2025-01-15 17:28:53 UTC",
      "updated_date": "2025-01-15 17:28:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:49:39.660147"
    },
    {
      "arxiv_id": "2501.08962v2",
      "title": "An analysis of data variation and bias in image-based dermatological datasets for machine learning classification",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Filho",
        "Emanoel Santos",
        "Rodrigo Mota",
        "Kelvin Cunha",
        "Fabio Papais",
        "Amanda Arruda",
        "Mateus Baltazar",
        "Camila Vieira",
        "José Gabriel Tavares",
        "Rafael Barros",
        "Othon Souza",
        "Thales Bezerra",
        "Natalia Lopes",
        "Érico Moutinho",
        "Jéssica Guido",
        "Shirley Cruz",
        "Paulo Borba",
        "Tsang Ing Ren"
      ],
      "abstract": "AI algorithms have become valuable in aiding professionals in healthcare. The\nincreasing confidence obtained by these models is helpful in critical decision\ndemands. In clinical dermatology, classification models can detect malignant\nlesions on patients' skin using only RGB images as input. However, most\nlearning-based methods employ data acquired from dermoscopic datasets on\ntraining, which are large and validated by a gold standard. Clinical models aim\nto deal with classification on users' smartphone cameras that do not contain\nthe corresponding resolution provided by dermoscopy. Also, clinical\napplications bring new challenges. It can contain captures from uncontrolled\nenvironments, skin tone variations, viewpoint changes, noises in data and\nlabels, and unbalanced classes. A possible alternative would be to use transfer\nlearning to deal with the clinical images. However, as the number of samples is\nlow, it can cause degradations on the model's performance; the source\ndistribution used in training differs from the test set. This work aims to\nevaluate the gap between dermoscopic and clinical samples and understand how\nthe dataset variations impact training. It assesses the main differences\nbetween distributions that disturb the model's prediction. Finally, from\nexperiments on different architectures, we argue how to combine the data from\ndivergent distributions, decreasing the impact on the model's final accuracy.",
      "tldr_zh": "本研究分析了基于图像的皮肤病数据集在机器学习分类中的数据变异和偏差问题，重点比较了dermoscopic数据集与临床图像（如手机相机拍摄）的差异，后者面临不受控环境、皮肤色调变化、视角变化、数据噪声和类不平衡等挑战。作者通过实验评估了这些分布差异如何影响模型性能，并探讨了使用transfer learning等方法来结合不同数据分布，以减少对分类准确性的负面影响。结果表明，通过适当的数据整合策略，可以有效缩小数据间隙，提高模型在临床场景下的预测可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.08962v2",
      "published_date": "2025-01-15 17:18:46 UTC",
      "updated_date": "2025-02-11 13:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:47:50.060063"
    },
    {
      "arxiv_id": "2501.08958v2",
      "title": "Kolmogorov-Arnold Networks for Time Series Granger Causality Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Meiliang Liu",
        "Yunfang Xu",
        "Zijin Li",
        "Zhengye Si",
        "Xiaoxiao Yang",
        "Xinyue Yang",
        "Zhiwen Zhao"
      ],
      "abstract": "We propose the Granger causality inference Kolmogorov-Arnold Networks\n(KANGCI), a novel architecture that extends the recently proposed\nKolmogorov-Arnold Networks (KAN) to the domain of causal inference. By\nextracting base weights from KAN layers and incorporating the sparsity-inducing\npenalty and ridge regularization, KANGCI effectively infers the Granger\ncausality from time series. Additionally, we propose an algorithm based on\ntime-reversed Granger causality that automatically selects causal relationships\nwith better inference performance from the original or time-reversed time\nseries or integrates the results to mitigate spurious connectivities.\nComprehensive experiments conducted on Lorenz-96, Gene regulatory networks,\nfMRI BOLD signals, VAR, and real-world EEG datasets demonstrate that the\nproposed model achieves competitive performance to state-of-the-art methods in\ninferring Granger causality from nonlinear, high-dimensional, and\nlimited-sample time series.",
      "tldr_zh": "本研究提出了一种新型架构Kolmogorov-Arnold Networks for Granger Causality Inference (KANGCI)，它扩展了Kolmogorov-Arnold Networks (KAN)，用于从时间序列中推断Granger因果关系。KANGCI通过提取KAN层的基权重，并结合稀疏诱导惩罚和岭正则化，有效地识别因果关系，同时引入基于时间反转Granger因果关系的算法，以优化结果并减少虚假连接。实验结果显示，在Lorenz-96、基因调控网络、fMRI BOLD信号、VAR和真实EEG数据集上，KANGCI在非线性、高维和小样本时间序列的推断性能上，与最先进方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08958v2",
      "published_date": "2025-01-15 17:09:07 UTC",
      "updated_date": "2025-02-05 15:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:48:02.964714"
    },
    {
      "arxiv_id": "2501.08951v1",
      "title": "Analyzing the Ethical Logic of Six Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "W. Russell Neuman",
        "Chad Coleman",
        "Manan Shah"
      ],
      "abstract": "This study examines the ethical reasoning of six prominent generative large\nlanguage models: OpenAI GPT-4o, Meta LLaMA 3.1, Perplexity, Anthropic Claude\n3.5 Sonnet, Google Gemini, and Mistral 7B. The research explores how these\nmodels articulate and apply ethical logic, particularly in response to moral\ndilemmas such as the Trolley Problem, and Heinz Dilemma. Departing from\ntraditional alignment studies, the study adopts an explainability-transparency\nframework, prompting models to explain their ethical reasoning. This approach\nis analyzed through three established ethical typologies: the\nconsequentialist-deontological analytic, Moral Foundations Theory, and the\nKohlberg Stages of Moral Development Model. Findings reveal that LLMs exhibit\nlargely convergent ethical logic, marked by a rationalist, consequentialist\nemphasis, with decisions often prioritizing harm minimization and fairness.\nDespite similarities in pre-training and model architecture, a mixture of\nnuanced and significant differences in ethical reasoning emerge across models,\nreflecting variations in fine-tuning and post-training processes. The models\nconsistently display erudition, caution, and self-awareness, presenting ethical\nreasoning akin to a graduate-level discourse in moral philosophy. In striking\nuniformity these systems all describe their ethical reasoning as more\nsophisticated than what is characteristic of typical human moral logic.",
      "tldr_zh": "本研究分析了六个主要的大型语言模型（LLMs）的伦理推理，包括 OpenAI GPT-4o、Meta LLaMA 3.1、Perplexity、Anthropic Claude 3.5 Sonnet、Google Gemini 和 Mistral 7B。采用 explainability-transparency 框架，通过道德困境如 Trolley Problem 和 Heinz Dilemma 的测试，并结合 consequentialist-deontological analytic、Moral Foundations Theory 和 Kohlberg Stages of Moral Development Model 等理论，评估模型如何解释和应用伦理逻辑。结果显示，这些模型的伦理推理高度一致，主要强调理性 consequentialist 观点、伤害最小化和公平，尽管微调过程导致细微差异，且模型普遍表现出博学和自我意识，自称其推理比典型人类道德逻辑更复杂。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08951v1",
      "published_date": "2025-01-15 16:56:26 UTC",
      "updated_date": "2025-01-15 16:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:48:14.569550"
    },
    {
      "arxiv_id": "2501.14809v1",
      "title": "Towards Foundation Models: Evaluation of Geoscience Artificial Intelligence with Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Myren",
        "Nidhi Parikh",
        "Rosalyn Rael",
        "Garrison Flynn",
        "Dave Higdon",
        "Emily Casleton"
      ],
      "abstract": "Artificial intelligence (AI) has transformed the geoscience community with\ndeep learning models (DLMs) that are trained to complete specific tasks within\nworkflows. This success has led to the development of geoscience foundation\nmodels (FMs), which promise to accomplish multiple tasks within a workflow or\nreplace the workflow altogether. However, lack of robust evaluation frameworks,\neven for traditional DLMs, leaves the geoscience community ill prepared for the\ninevitable adoption of FMs. We address this gap by designing an evaluation\nframework that jointly incorporates three crucial aspects to current DLMs and\nfuture FMs: performance uncertainty, learning efficiency, and overlapping\ntraining-test data splits. To target the three aspects, we meticulously\nconstruct the training, validation, and test splits using clustering methods\ntailored to geoscience data and enact an expansive training design to segregate\nperformance uncertainty arising from stochastic training processes and random\ndata sampling. The framework's ability to guard against misleading declarations\nof model superiority is demonstrated through evaluation of PhaseNet, a popular\nseismic phase picking DLM, under 3 training approaches. Furthermore, we show\nhow the performance gains due to overlapping training-test data can lead to\nbiased FM evaluation. Our framework helps practitioners choose the best model\nfor their problem and set performance expectations by explicitly analyzing\nmodel performance at varying budgets of training data.",
      "tldr_zh": "本论文针对地科学 AI 模型（特别是深度学习模型 DLMs 和基础模型 FMs）的评价不足问题，提出了一种综合框架，整合性能不确定性、学习效率和重叠训练测试数据分割三个关键方面。该框架通过使用聚类方法构建数据集，并进行广泛训练设计，来分离随机训练和数据采样带来的不确定性。实验评估了 PhaseNet 等模型，揭示了重叠数据可能导致的性能偏差，并帮助从业者根据训练数据预算选择最佳模型并设定合理期望。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14809v1",
      "published_date": "2025-01-15 16:45:51 UTC",
      "updated_date": "2025-01-15 16:45:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:48:26.490564"
    },
    {
      "arxiv_id": "2501.08931v1",
      "title": "Visual WetlandBirds Dataset: Bird Species Identification and Behavior Recognition in Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Rodriguez-Juan",
        "David Ortiz-Perez",
        "Manuel Benavent-Lledo",
        "David Mulero-Pérez",
        "Pablo Ruiz-Ponce",
        "Adrian Orihuela-Torres",
        "Jose Garcia-Rodriguez",
        "Esther Sebastián-González"
      ],
      "abstract": "The current biodiversity loss crisis makes animal monitoring a relevant field\nof study. In light of this, data collected through monitoring can provide\nessential insights, and information for decision-making aimed at preserving\nglobal biodiversity. Despite the importance of such data, there is a notable\nscarcity of datasets featuring videos of birds, and none of the existing\ndatasets offer detailed annotations of bird behaviors in video format. In\nresponse to this gap, our study introduces the first fine-grained video dataset\nspecifically designed for bird behavior detection and species classification.\nThis dataset addresses the need for comprehensive bird video datasets and\nprovides detailed data on bird actions, facilitating the development of deep\nlearning models to recognize these, similar to the advancements made in human\naction recognition. The proposed dataset comprises 178 videos recorded in\nSpanish wetlands, capturing 13 different bird species performing 7 distinct\nbehavior classes. In addition, we also present baseline results using state of\nthe art models on two tasks: bird behavior recognition and species\nclassification.",
      "tldr_zh": "本研究针对生物多样性丧失危机，引入了Visual WetlandBirds Dataset，这是第一个细粒度视频数据集，专门用于鸟类物种识别和行为识别。\n该数据集包括在西班牙湿地拍摄的178个视频，涵盖13种鸟类和7种行为类别，提供详细的鸟类动作注解，以推动深度学习模型的发展。\n研究还提供了基线结果，使用最先进模型在鸟类行为识别和物种分类任务上进行评估。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08931v1",
      "published_date": "2025-01-15 16:34:20 UTC",
      "updated_date": "2025-01-15 16:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:48:38.275861"
    },
    {
      "arxiv_id": "2501.08925v2",
      "title": "Disentangling Exploration of Large Language Models by Optimal Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Grams",
        "Patrick Betz",
        "Christian Bartelt"
      ],
      "abstract": "Exploration is a crucial skill for self-improvement and open-ended\nproblem-solving. However, it remains unclear if large language models can\neffectively explore the state-space within an unknown environment. This work\nisolates exploration as the sole objective, tasking the agent with delivering\ninformation that enhances future returns. Within this framework, we argue that\nmeasuring agent returns is not sufficient for a fair evaluation and decompose\nmissing rewards into exploration and exploitation components based on the\noptimal achievable return. Comprehensive experiments with various models reveal\nthat most struggle to sufficiently explore the state-space and weak exploration\nis insufficient. We observe a positive correlation between parameter count and\nexploration performance, with larger models demonstrating superior\ncapabilities. Furthermore, we show that our decomposition provides insights\ninto differences in behaviors driven by prompt engineering, offering a valuable\ntool for refining performance in exploratory tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型（Large Language Models）在未知环境中的探索能力（Exploration），将探索作为唯一目标，以提升未来回报。作者提出将缺失回报分解为探索和利用（Exploitation）组件，并基于最优可实现回报进行评估，以实现更公平的评估。实验结果显示，大多数模型在探索状态空间方面表现不足，但参数数量与探索性能正相关，且这种分解方法能揭示提示工程（Prompt Engineering）驱动的行为差异，从而为改进探索任务提供工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08925v2",
      "published_date": "2025-01-15 16:30:29 UTC",
      "updated_date": "2025-02-03 15:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:48:49.983909"
    },
    {
      "arxiv_id": "2501.08922v2",
      "title": "Discovery of Spatter Constitutive Models in Additive Manufacturing Using Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Olabode T. Ajenifujah",
        "Amir Barati Farimani"
      ],
      "abstract": "Additive manufacturing (AM) is a rapidly evolving technology that has\nattracted applications across a wide range of fields due to its ability to\nfabricate complex geometries. However, one of the key challenges in AM is\nachieving consistent print quality. This inconsistency is often attributed to\nuncontrolled melt pool dynamics, partly caused by spatter which can lead to\ndefects. Therefore, capturing and controlling the evolution of the melt pool is\ncrucial for enhancing process stability and part quality. In this study, we\ndeveloped a framework to support decision-making towards efficient AM process\noperations, capable of facilitating quality control and minimizing defects via\nmachine learning (ML) and polynomial symbolic regression models. We implemented\nexperimentally validated computational tools, specifically for laser powder bed\nfusion (LPBF) processes as a cost-effective approach to collect large datasets.\nFor a dataset consisting of 281 varying process conditions, parameters such as\nmelt pool dimensions (length, width, depth), melt pool geometry (area, volume),\nand volume indicated as spatter were extracted. Using machine learning (ML) and\npolynomial symbolic regression models, a high R2 of over 95 % was achieved in\npredicting the melt pool dimensions and geometry features on both the training\nand testing datasets, with either process conditions (power and velocity) or\nmelt pool dimensions as the model inputs. In the case of volume indicated as\nspatter the value of the R2 improved after logarithmic transforming the model\ninputs, which were either the process conditions or the melt pool dimensions.\nAmong the investigated ML models, the ExtraTree model achieved the highest R2\nvalues of 96.7 % and 87.5 %.",
      "tldr_zh": "本文研究了使用机器学习(Machine Learning, ML)来发现增材制造(Additive Manufacturing, AM)中飞溅(Spatter)的本构模型，以解决熔池动力学不一致性导致的打印质量问题。研究框架结合ML和多项式符号回归模型，基于激光粉末床熔融(Laser Powder Bed Fusion, LPBF)过程的实验数据（包括281种过程条件），提取并预测熔池尺寸、几何特征及飞溅体积。结果显示，模型在预测熔池参数时达到了超过95%的R2值，其中ExtraTree模型表现最佳，R2值分别为96.7%和87.5%，并通过对数变换改善了飞溅体积的预测准确性。该方法为AM过程的决策支持和缺陷最小化提供了高效工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08922v2",
      "published_date": "2025-01-15 16:26:01 UTC",
      "updated_date": "2025-02-04 16:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:49:03.792816"
    },
    {
      "arxiv_id": "2501.08907v1",
      "title": "Projection Implicit Q-Learning with Support Constraint for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinchen Han",
        "Hossam Afifi",
        "Michel Marot"
      ],
      "abstract": "Offline Reinforcement Learning (RL) faces a critical challenge of\nextrapolation errors caused by out-of-distribution (OOD) actions. Implicit\nQ-Learning (IQL) algorithm employs expectile regression to achieve in-sample\nlearning, effectively mitigating the risks associated with OOD actions.\nHowever, the fixed hyperparameter in policy evaluation and density-based policy\nimprovement method limit its overall efficiency. In this paper, we propose\nProj-IQL, a projective IQL algorithm enhanced with the support constraint. In\nthe policy evaluation phase, Proj-IQL generalizes the one-step approach to a\nmulti-step approach through vector projection, while maintaining in-sample\nlearning and expectile regression framework. In the policy improvement phase,\nProj-IQL introduces support constraint that is more aligned with the policy\nevaluation approach. Furthermore, we theoretically demonstrate that Proj-IQL\nguarantees monotonic policy improvement and enjoys a progressively more\nrigorous criterion for superior actions. Empirical results demonstrate the\nProj-IQL achieves state-of-the-art performance on D4RL benchmarks, especially\nin challenging navigation domains.",
      "tldr_zh": "本文提出 Proj-IQL 算法，以改进 Implicit Q-Learning (IQL) 在离线强化学习（Offline RL）中的性能，针对 OOD 动作导致的推断错误问题，通过向量投影将策略评估从一步扩展到多步方法，同时保留 expectile regression 的样本内学习框架，并在策略改进阶段引入 support constraint 以增强一致性。  \n理论分析表明，Proj-IQL 保证策略单调改进，并提供更严格的优越动作标准。  \n实验结果显示，该算法在 D4RL 基准测试中实现最先进性能，尤其在挑战性的导航领域表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08907v1",
      "published_date": "2025-01-15 16:17:02 UTC",
      "updated_date": "2025-01-15 16:17:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:49:15.061855"
    },
    {
      "arxiv_id": "2501.08905v2",
      "title": "Computing Game Symmetries and Equilibria That Respect Them",
      "title_zh": "计算游戏对称性与尊重它们的均衡",
      "authors": [
        "Emanuel Tewolde",
        "Brian Hu Zhang",
        "Caspar Oesterheld",
        "Tuomas Sandholm",
        "Vincent Conitzer"
      ],
      "abstract": "Strategic interactions can be represented more concisely, and analyzed and\nsolved more efficiently, if we are aware of the symmetries within the\nmultiagent system. Symmetries also have conceptual implications, for example\nfor equilibrium selection. We study the computational complexity of identifying\nand using symmetries. Using the classical framework of normal-form games, we\nconsider game symmetries that can be across some or all players and/or actions.\nWe find a strong connection between game symmetries and graph automorphisms,\nyielding graph automorphism and graph isomorphism completeness results for\ncharacterizing the symmetries present in a game. On the other hand, we also\nshow that the problem becomes polynomial-time solvable when we restrict the\nconsideration of actions in one of two ways.\n  Next, we investigate when exactly game symmetries can be successfully\nleveraged for Nash equilibrium computation. We show that finding a Nash\nequilibrium that respects a given set of symmetries is PPAD- and CLS-complete\nin general-sum and team games respectively -- that is, exactly as hard as\nBrouwer fixed point and gradient descent problems. Finally, we present\npolynomial-time methods for the special cases where we are aware of a vast\nnumber of symmetries, or where the game is two-player zero-sum and we do not\neven know the symmetries.",
      "tldr_zh": "本论文探讨了在多智能体系统中识别和利用游戏对称性（symmetries），以更简洁地表示战略互动并提升分析效率。研究使用 normal-form games 框架，分析了玩家和行动的对称性，发现这些对称性与 graph automorphisms 和 graph isomorphism 密切相关，导致相关问题通常是 graph automorphism-complete 或 graph isomorphism-complete。论文证明，在某些行动限制下，这些问题可多项式时间求解；然而，计算尊重给定对称性的 Nash equilibrium 在一般和求和游戏中分别是 PPAD-complete 和 CLS-complete。最终，论文提出在特定场景（如大量对称性或两玩家零和游戏）下多项式时间方法，为游戏理论计算提供高效工具。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CC",
        "cs.MA",
        "91A05, 91A06, 91A10, 91A26, 91A35, 91A68, 68Q17, 68Q25, 68T01",
        "I.2; J.4; F.2"
      ],
      "primary_category": "cs.GT",
      "comment": "Long and updated version to the published paper in the Proceedings of\n  the 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025). 24\n  pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.08905v2",
      "published_date": "2025-01-15 16:15:16 UTC",
      "updated_date": "2025-02-27 23:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:49:26.386895"
    },
    {
      "arxiv_id": "2501.08897v2",
      "title": "Automated Retrosynthesis Planning of Macromolecules Using Large Language Models and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Qinyu Ma",
        "Yuhao Zhou",
        "Jianfeng Li"
      ],
      "abstract": "Identifying reliable synthesis pathways in materials chemistry is a complex\ntask, particularly in polymer science, due to the intricate and often\nnon-unique nomenclature of macromolecules. To address this challenge, we\npropose an agent system that integrates large language models (LLMs) and\nknowledge graphs. By leveraging LLMs' powerful capabilities for extracting and\nrecognizing chemical substance names, and storing the extracted data in a\nstructured knowledge graph, our system fully automates the retrieval of\nrelevant literatures, extraction of reaction data, database querying,\nconstruction of retrosynthetic pathway trees, further expansion through the\nretrieval of additional literature and recommendation of optimal reaction\npathways. By considering the complex interdependencies among chemical\nreactants, a novel Multi-branched Reaction Pathway Search Algorithm (MBRPS) is\nproposed to help identify all valid multi-branched reaction pathways, which\narise when a single product decomposes into multiple reaction intermediates. In\ncontrast, previous studies were limited to cases where a product decomposes\ninto at most one reaction intermediate. This work represents the first attempt\nto develop a fully automated retrosynthesis planning agent tailored specially\nfor macromolecules powered by LLMs. Applied to polyimide synthesis, our new\napproach constructs a retrosynthetic pathway tree with hundreds of pathways and\nrecommends optimized routes, including both known and novel pathways. This\ndemonstrates utilizing LLMs for literature consultation to accomplish specific\ntasks is possible and crucial for future materials research, given the vast\namount of materials-related literature.",
      "tldr_zh": "本研究针对材料化学中大分子逆合成规划的复杂性，提出了一种整合大型语言模型(LLMs)和知识图的代理系统，用于自动化文献检索、反应数据提取、数据库查询以及逆合成路径树的构建。系统通过LLMs提取并识别化学物质名称，并引入Multi-branched Reaction Pathway Search Algorithm (MBRPS)来处理产品分解成多个反应中间体的多分支路径，这扩展了传统方法的局限性。在聚酰亚胺合成应用中，该系统构建了数百条逆合成路径并推荐优化路线，包括已知和新颖路径，展示了LLMs在材料研究中的关键潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The source code of RetroSynthesisAgent is available at\n  https://github.com/QinyuMa316/RetroSynthesisAgent",
      "pdf_url": "http://arxiv.org/pdf/2501.08897v2",
      "published_date": "2025-01-15 16:06:10 UTC",
      "updated_date": "2025-04-15 14:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:49:52.051420"
    },
    {
      "arxiv_id": "2501.08889v1",
      "title": "Karatsuba Matrix Multiplication and its Efficient Custom Hardware Implementations",
      "title_zh": "Karatsuba 矩阵乘法及其高效的自定义硬件实现",
      "authors": [
        "Trevor E. Pogue",
        "Nicola Nicolici"
      ],
      "abstract": "While the Karatsuba algorithm reduces the complexity of large integer\nmultiplication, the extra additions required minimize its benefits for smaller\nintegers of more commonly-used bitwidths. In this work, we propose the\nextension of the scalar Karatsuba multiplication algorithm to matrix\nmultiplication, showing how this maintains the reduction in multiplication\ncomplexity of the original Karatsuba algorithm while reducing the complexity of\nthe extra additions. Furthermore, we propose new matrix multiplication hardware\narchitectures for efficiently exploiting this extension of the Karatsuba\nalgorithm in custom hardware. We show that the proposed algorithm and hardware\narchitectures can provide real area or execution time improvements for integer\nmatrix multiplication compared to scalar Karatsuba or conventional matrix\nmultiplication algorithms, while also supporting implementation through proven\nsystolic array and conventional multiplier architectures at the core. We\nprovide a complexity analysis of the algorithm and architectures and evaluate\nthe proposed designs both in isolation and in an end-to-end deep learning\naccelerator system compared to baseline designs and prior state-of-the-art\nworks implemented on the same type of compute platform, demonstrating their\nability to increase the performance-per-area of matrix multiplication hardware.",
      "tldr_zh": "本研究将Karatsuba算法扩展到矩阵乘法中，通过减少乘法复杂性并优化额外加法操作，从而在常见位宽整数乘法中提升效率。研究者提出新的矩阵乘法硬件架构，利用systolic array和conventional multiplier等核心组件，实现高效的自定义硬件实现。实验结果显示，与传统Karatsuba或常规算法相比，该方法在整数矩阵乘法中显著降低面积或执行时间，并在深度学习加速器系统中提高了性能每面积指标。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication in IEEE Transactions on Computers;\n  Associated source code available on github at\n  https://github.com/trevorpogue/algebraic-nnhw",
      "pdf_url": "http://arxiv.org/pdf/2501.08889v1",
      "published_date": "2025-01-15 16:00:43 UTC",
      "updated_date": "2025-01-15 16:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:50:01.327772"
    },
    {
      "arxiv_id": "2501.08878v2",
      "title": "Incrementally Learning Multiple Diverse Data Domains via Multi-Source Dynamic Expansion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Runqing Wu",
        "Fei Ye",
        "Qihe Liu",
        "Guoxi Huang",
        "Jinyu Guo",
        "Rongyao Hu"
      ],
      "abstract": "Continual Learning seeks to develop a model capable of incrementally\nassimilating new information while retaining prior knowledge. However, current\nresearch predominantly addresses a straightforward learning context, wherein\nall data samples originate from a singular data domain. This paper shifts focus\nto a more complex and realistic learning environment, characterized by data\nsamples sourced from multiple distinct domains. We tackle this intricate\nlearning challenge by introducing a novel methodology, termed the Multi-Source\nDynamic Expansion Model (MSDEM), which leverages various pre-trained models as\nbackbones and progressively establishes new experts based on them to adapt to\nemerging tasks. Additionally, we propose an innovative dynamic expandable\nattention mechanism designed to selectively harness knowledge from multiple\nbackbones, thereby accelerating the new task learning. Moreover, we introduce a\ndynamic graph weight router that strategically reuses all previously acquired\nparameters and representations for new task learning, maximizing the positive\nknowledge transfer effect, which further improves generalization performance.\nWe conduct a comprehensive series of experiments, and the empirical findings\nindicate that our proposed approach achieves state-of-the-art performance.",
      "tldr_zh": "本论文针对持续学习（Continual Learning）在多个不同数据域中的挑战，提出了一种新方法Multi-Source Dynamic Expansion Model (MSDEM)，该模型利用各种预训练模型作为骨干，并动态建立新专家来适应新任务。同时，引入动态可扩展注意力机制和动态图权重路由器，以选择性地重用先前参数并最大化知识转移，提升泛化性能。实验结果显示，MSDEM 在综合测试中达到了最先进（state-of-the-art）的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08878v2",
      "published_date": "2025-01-15 15:49:46 UTC",
      "updated_date": "2025-04-16 01:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:50:14.723910"
    },
    {
      "arxiv_id": "2501.10466v1",
      "title": "Improving the Efficiency of Self-Supervised Adversarial Training through Latent Clustering-Based Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Somrita Ghosh",
        "Yuelin Xu",
        "Xiao Zhang"
      ],
      "abstract": "Compared with standard learning, adversarially robust learning is widely\nrecognized to demand significantly more training examples. Recent works propose\nthe use of self-supervised adversarial training (SSAT) with external or\nsynthetically generated unlabeled data to enhance model robustness. However,\nSSAT requires a substantial amount of extra unlabeled data, significantly\nincreasing memory usage and model training times. To address these challenges,\nwe propose novel methods to strategically select a small subset of unlabeled\ndata essential for SSAT and robustness improvement. Our selection prioritizes\ndata points near the model's decision boundary based on latent clustering-based\ntechniques, efficiently identifying a critical subset of unlabeled data with a\nhigher concentration of boundary-adjacent points. While focusing on\nnear-boundary data, our methods are designed to maintain a balanced ratio\nbetween boundary and non-boundary data points to avoid overfitting. Our\nexperiments on image benchmarks show that integrating our selection strategies\ninto self-supervised adversarial training can largely reduce memory and\ncomputational requirements while achieving high model robustness. In\nparticular, our latent clustering-based selection method with k-means is the\nmost effective, achieving nearly identical test-time robust accuracies with 5\nto 10 times less external or generated unlabeled data when applied to image\nbenchmarks. Additionally, we validate the generalizability of our approach\nacross various application scenarios, including a real-world medical dataset\nfor COVID-19 chest X-ray classification.",
      "tldr_zh": "这篇论文针对自监督对抗训练(SSAT)的效率问题，提出了一种基于潜在聚类的选择方法，以战略性地选取靠近模型决策边界的关键无标签数据子集。该方法利用k-means等聚类技术优先识别边界附近点，同时保持边界和非边界数据的平衡比例，避免过拟合。实验结果显示，在图像基准测试中，该策略能大幅减少内存和计算需求，使用5到10倍更少的外部或生成无标签数据即可实现几乎相同的测试鲁棒准确率。此外，该方法在真实世界场景如COVID-19胸部X光分类数据集上展现出良好的泛化性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Shorter version of this work accepted by NextGenAISafety Workshop at\n  ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.10466v1",
      "published_date": "2025-01-15 15:47:49 UTC",
      "updated_date": "2025-01-15 15:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:50:27.633843"
    },
    {
      "arxiv_id": "2501.08869v2",
      "title": "Silent Abandonment in Text-Based Contact Centers: Identifying, Quantifying, and Mitigating its Operational Impacts",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio Castellanos",
        "Galit B. Yom-Tov",
        "Yair Goldberg",
        "Jaeyoung Park"
      ],
      "abstract": "In the quest to improve services, companies offer customers the option to\ninteract with agents via texting. Such contact centers face unique challenges\ncompared to traditional call centers, as measuring customer experience proxies\nlike abandonment and patience involves uncertainty. A key source of this\nuncertainty is silent abandonment, where customers leave without notifying the\nsystem, wasting agent time and leaving their status unclear. Silent abandonment\nalso obscures whether a customer was served or left. Our goals are to measure\nthe magnitude of silent abandonment and mitigate its effects. Classification\nmodels show that 3%-70% of customers across 17 companies abandon silently. In\none study, 71.3% of abandoning customers did so silently, reducing agent\nefficiency by 3.2% and system capacity by 15.3%, incurring $5,457 in annual\ncosts per agent. We develop an expectation-maximization (EM) algorithm to\nestimate customer patience under uncertainty and identify influencing\ncovariates. We find that companies should use classification models to estimate\nabandonment scope and our EM algorithm to assess patience. We suggest\nstrategies to operationally mitigate the impact of silent abandonment by\npredicting suspected silent-abandonment behavior or changing service design.\nSpecifically, we show that while allowing customers to write while waiting in\nthe queue creates a missing data challenge, it also significantly increases\npatience and reduces service time, leading to reduced abandonment and lower\nstaffing requirements.",
      "tldr_zh": "这篇论文探讨了文本-based 联系中心中的 silent abandonment 问题，即客户悄然离开而不通知系统，导致代理时间浪费和运营不确定性。研究通过 classification models 分析发现，17 家公司中有 3%-70% 的客户 silent abandonment，在一个案例中占比达 71.3%，导致代理效率降低 3.2%、系统容量减少 15.3%，并每年每代理产生 5,457 美元的成本。作者开发了 expectation-maximization (EM) algorithm 来估计客户耐心并识别影响因素，并建议采用预测模型评估放弃范围，以及通过改变服务设计（如允许客户在队列中写作）来增加耐心、减少放弃率和人员需求。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "75% of the paper is an updated version of arXiv:2304.11754",
      "pdf_url": "http://arxiv.org/pdf/2501.08869v2",
      "published_date": "2025-01-15 15:38:56 UTC",
      "updated_date": "2025-01-16 13:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:50:39.761427"
    },
    {
      "arxiv_id": "2501.08862v1",
      "title": "ARMOR: Shielding Unlearnable Examples against Data Augmentation",
      "title_zh": "ARMOR：针对数据增强的不可学习样本屏蔽方法",
      "authors": [
        "Xueluan Gong",
        "Yuji Wang",
        "Yanjiao Chen",
        "Haocheng Dong",
        "Yiming Li",
        "Mengyuan Sun",
        "Shuaike Li",
        "Qian Wang",
        "Chen Chen"
      ],
      "abstract": "Private data, when published online, may be collected by unauthorized parties\nto train deep neural networks (DNNs). To protect privacy, defensive noises can\nbe added to original samples to degrade their learnability by DNNs. Recently,\nunlearnable examples are proposed to minimize the training loss such that the\nmodel learns almost nothing. However, raw data are often pre-processed before\nbeing used for training, which may restore the private information of protected\ndata. In this paper, we reveal the data privacy violation induced by data\naugmentation, a commonly used data pre-processing technique to improve model\ngeneralization capability, which is the first of its kind as far as we are\nconcerned. We demonstrate that data augmentation can significantly raise the\naccuracy of the model trained on unlearnable examples from 21.3% to 66.1%. To\naddress this issue, we propose a defense framework, dubbed ARMOR, to protect\ndata privacy from potential breaches of data augmentation. To overcome the\ndifficulty of having no access to the model training process, we design a\nnon-local module-assisted surrogate model that better captures the effect of\ndata augmentation. In addition, we design a surrogate augmentation selection\nstrategy that maximizes distribution alignment between augmented and\nnon-augmented samples, to choose the optimal augmentation strategy for each\nclass. We also use a dynamic step size adjustment algorithm to enhance the\ndefensive noise generation process. Extensive experiments are conducted on 4\ndatasets and 5 data augmentation methods to verify the performance of ARMOR.\nComparisons with 6 state-of-the-art defense methods have demonstrated that\nARMOR can preserve the unlearnability of protected private data under data\naugmentation. ARMOR reduces the test accuracy of the model trained on augmented\nprotected samples by as much as 60% more than baselines.",
      "tldr_zh": "该论文揭示了数据增强（data augmentation）可能破坏unlearnable examples的隐私保护效果，导致训练DNNs的模型准确率显著提升（如从21.3%提高到66.1%）。为了应对这一问题，作者提出ARMOR框架，该框架利用非本地模块辅助的代理模型、代理增强选择策略（最大化增强前后样本分布对齐）和动态步长调整算法来生成更有效的防御噪声，从而维持数据的不可学习性。实验在4个数据集和5种数据增强方法上进行，结果显示ARMOR比6种最先进方法多降低模型测试准确率达60%，有效保护私有数据隐私。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08862v1",
      "published_date": "2025-01-15 15:22:57 UTC",
      "updated_date": "2025-01-15 15:22:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:50:51.588717"
    },
    {
      "arxiv_id": "2501.08851v1",
      "title": "Digital Phenotyping for Adolescent Mental Health: A Feasibility Study Employing Machine Learning to Predict Mental Health Risk From Active and Passive Smartphone Data",
      "title_zh": "翻译失败",
      "authors": [
        "Balasundaram Kadirvelu",
        "Teresa Bellido Bel",
        "Aglaia Freccero",
        "Martina Di Simplicio",
        "Dasha Nicholls",
        "A Aldo Faisal"
      ],
      "abstract": "Background: Adolescents are particularly vulnerable to mental disorders, with\nover 75% of cases manifesting before the age of 25. Research indicates that\nonly 18 to 34% of young people experiencing high levels of depression or\nanxiety symptoms seek support. Digital tools leveraging smartphones offer\nscalable and early intervention opportunities. Objective: Using a novel machine\nlearning framework, this study evaluated the feasibility of integrating active\nand passive smartphone data to predict mental disorders in non-clinical\nadolescents. Specifically, we investigated the utility of the Mindcraft app in\npredicting risks for internalising and externalising disorders, eating\ndisorders, insomnia and suicidal ideation. Methods: Participants (N=103; mean\nage 16.1 years) were recruited from three London schools. Participants\ncompleted the Strengths and Difficulties Questionnaire, the Eating Disorders-15\nQuestionnaire, Sleep Condition Indicator Questionnaire and indicated the\npresence/absence of suicidal ideation. They used the Mindcraft app for 14 days,\ncontributing active data via self-reports and passive data from smartphone\nsensors. A contrastive pretraining phase was applied to enhance user-specific\nfeature stability, followed by supervised fine-tuning. The model evaluation\nemployed leave-one-subject-out cross-validation using balanced accuracy as the\nprimary metric. Results: The integration of active and passive data achieved\nsuperior performance compared to individual data sources, with mean balanced\naccuracies of 0.71 for SDQ-High risk, 0.67 for insomnia, 0.77 for suicidal\nideation and 0.70 for eating disorders. The contrastive learning framework\nstabilised daily behavioural representations, enhancing predictive robustness.\nThis study demonstrates the potential of integrating active and passive\nsmartphone data with advanced machine-learning techniques for predicting mental\nhealth risks.",
      "tldr_zh": "本研究评估了数字表型（Digital Phenotyping）在青少年精神健康领域的可行性，通过机器学习（Machine Learning）框架整合主动（如自报）和被动（如传感器）智能手机数据，来预测非临床青少年的内部化障碍、外部化障碍、饮食障碍、失眠和自杀意念风险。参与者包括103名平均年龄16.1岁的伦敦学生，他们使用Mindcraft app 14天收集数据，并采用对比预训练增强特征稳定性，随后进行监督微调和留一受试者交叉验证。结果显示，整合数据显著提高了预测性能，平均平衡准确率（balanced accuracy）分别为SDQ-High风险0.71、失眠0.67、自杀意念0.77和饮食障碍0.70，证明了这种方法在早期干预精神健康问题上的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08851v1",
      "published_date": "2025-01-15 15:05:49 UTC",
      "updated_date": "2025-01-15 15:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:51:04.596973"
    },
    {
      "arxiv_id": "2501.08850v1",
      "title": "Graph Counterfactual Explainable AI via Latent Space Traversal",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Abildtrup Hansen",
        "Paraskevas Pegios",
        "Anna Calissano",
        "Aasa Feragen"
      ],
      "abstract": "Explaining the predictions of a deep neural network is a nontrivial task, yet\nhigh-quality explanations for predictions are often a prerequisite for\npractitioners to trust these models. Counterfactual explanations aim to explain\npredictions by finding the ''nearest'' in-distribution alternative input whose\nprediction changes in a pre-specified way. However, it remains an open question\nhow to define this nearest alternative input, whose solution depends on both\nthe domain (e.g. images, graphs, tabular data, etc.) and the specific\napplication considered. For graphs, this problem is complicated i) by their\ndiscrete nature, as opposed to the continuous nature of state-of-the-art graph\nclassifiers; and ii) by the node permutation group acting on the graphs. We\npropose a method to generate counterfactual explanations for any differentiable\nblack-box graph classifier, utilizing a case-specific permutation equivariant\ngraph variational autoencoder. We generate counterfactual explanations in a\ncontinuous fashion by traversing the latent space of the autoencoder across the\nclassification boundary of the classifier, allowing for seamless integration of\ndiscrete graph structure and continuous graph attributes. We empirically\nvalidate the approach on three graph datasets, showing that our model is\nconsistently high-performing and more robust than the baselines.",
      "tldr_zh": "本文提出一种通过潜在空间遍历（latent space traversal）生成图数据反事实解释（Counterfactual explanations）的方法，针对可微黑盒图分类器，解决图的离散性质和节点置换问题。该方法利用置换等变图变分自编码器（permutation equivariant graph variational autoencoder），在连续潜在空间中遍历分类边界，实现离散图结构与连续属性的无缝整合。实验结果显示，该方法在三个图数据集上表现出色，比基线模型更稳健。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Northern Lights Deep Learning Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08850v1",
      "published_date": "2025-01-15 15:04:10 UTC",
      "updated_date": "2025-01-15 15:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:51:15.343090"
    },
    {
      "arxiv_id": "2501.10465v1",
      "title": "The Mathematics of Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Peyré"
      ],
      "abstract": "This overview article highlights the critical role of mathematics in\nartificial intelligence (AI), emphasizing that mathematics provides tools to\nbetter understand and enhance AI systems. Conversely, AI raises new problems\nand drives the development of new mathematics at the intersection of various\nfields. This article focuses on the application of analytical and probabilistic\ntools to model neural network architectures and better understand their\noptimization. Statistical questions (particularly the generalization capacity\nof these networks) are intentionally set aside, though they are of crucial\nimportance. We also shed light on the evolution of ideas that have enabled\nsignificant advances in AI through architectures tailored to specific tasks,\neach echoing distinct mathematical techniques. The goal is to encourage more\nmathematicians to take an interest in and contribute to this exciting field.",
      "tldr_zh": "这篇概述文章强调了数学在人工智能（AI）中的关键作用，提供工具来理解和提升AI系统，同时AI也推动了新数学问题的产生。该文聚焦于分析和概率工具在神经网络架构建模与优化中的应用，探讨了为特定任务设计的AI架构如何与不同数学技术相呼应。尽管忽略了统计问题如泛化能力，但整体目标是鼓励更多数学家参与并贡献于这个激动人心的领域。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10465v1",
      "published_date": "2025-01-15 15:00:23 UTC",
      "updated_date": "2025-01-15 15:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:51:26.060142"
    },
    {
      "arxiv_id": "2501.08848v1",
      "title": "RouteNet-Gauss: Hardware-Enhanced Network Modeling with Machine Learning",
      "title_zh": "RouteNet-Gauss: 利用机器学习的硬件增强网络建模",
      "authors": [
        "Carlos Güemes-Palau",
        "Miquel Ferriol-Galmés",
        "Jordi Paillisse-Vilanova",
        "Albert López-Brescó",
        "Pere Barlet-Ros",
        "Albert Cabellos-Aparicio"
      ],
      "abstract": "Network simulation is pivotal in network modeling, assisting with tasks\nranging from capacity planning to performance estimation. Traditional\napproaches such as Discrete Event Simulation (DES) face limitations in terms of\ncomputational cost and accuracy. This paper introduces RouteNet-Gauss, a novel\nintegration of a testbed network with a Machine Learning (ML) model to address\nthese challenges. By using the testbed as a hardware accelerator,\nRouteNet-Gauss generates training datasets rapidly and simulates network\nscenarios with high fidelity to real-world conditions. Experimental results\nshow that RouteNet-Gauss significantly reduces prediction errors by up to 95%\nand achieves a 488x speedup in inference time compared to state-of-the-art\nDES-based methods. RouteNet-Gauss's modular architecture is dynamically\nconstructed based on the specific characteristics of the network scenario, such\nas topology and routing. This enables it to understand and generalize to\ndifferent network configurations beyond those seen during training, including\nnetworks up to 10x larger. Additionally, it supports Temporal Aggregated\nPerformance Estimation (TAPE), providing configurable temporal granularity and\nmaintaining high accuracy in flow performance metrics. This approach shows\npromise in improving both simulation efficiency and accuracy, offering a\nvaluable tool for network operators.",
      "tldr_zh": "本研究提出RouteNet-Gauss，一种将硬件测试床(testbed)与Machine Learning (ML)模型集成的网络模拟方法，旨在解决传统Discrete Event Simulation (DES)的计算成本高和准确性低的问题。通过使用测试床作为硬件加速器，该框架快速生成训练数据集，并以高保真度模拟真实网络场景。实验结果显示，RouteNet-Gauss将预测错误降低高达95%，推理时间比现有DES方法快488倍，并支持Temporal Aggregated Performance Estimation (TAPE)，提供可配置的时间粒度以保持高准确性。该方法通过模块化架构实现对不同网络拓扑和路由的泛化，包括训练中未见过的更大规模网络，为网络运营商提供高效的模拟工具。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "13 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08848v1",
      "published_date": "2025-01-15 15:00:11 UTC",
      "updated_date": "2025-01-15 15:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:51:38.993869"
    },
    {
      "arxiv_id": "2501.08847v1",
      "title": "Automatic tuning of communication protocols for vehicular ad hoc networks using metaheuristics",
      "title_zh": "翻译失败",
      "authors": [
        "José García-Nieto",
        "Jamal Toutouh",
        "Enrique Alba"
      ],
      "abstract": "The emerging field of vehicular ad hoc networks (VANETs) deals with a set of\ncommunicating vehicles which are able to spontaneously interconnect without any\npre-existing infrastructure. In such kind of networks, it is crucial to make an\noptimal configuration of the communication protocols previously to the final\nnetwork deployment. This way, a human designer can obtain an optimal QoS of the\nnetwork beforehand. The problem we consider in this work lies in configuring\nthe File Transfer protocol Configuration (FTC) with the aim of optimizing the\ntransmission time, the number of lost packets, and the amount of data\ntransferred in realistic VANET scenarios. We face the FTC with five\nrepresentative state-of-the-art optimization techniques and compare their\nperformance. These algorithms are: Particle Swarm Optimization (PSO),\nDifferential Evolution (DE), Genetic Algorithm (GA), Evolutionary Strategy\n(ES), and Simulated Annealing (SA). For our tests, two typical environment\ninstances of VANETs for Urban and Highway scenarios have been defined. The\nexperiments using ns- 2 (a well-known realistic VANET simulator) reveal that\nPSO outperforms all the compared algorithms for both studied VANET instances.",
      "tldr_zh": "该论文探讨了使用元启发式算法自动调优车辆自组网(VANETs)通信协议的问题，旨在在部署前优化网络质量(QoS)，具体包括传输时间、丢失数据包数量和传输数据量。研究者比较了五种优化技术：Particle Swarm Optimization (PSO)、Differential Evolution (DE)、Genetic Algorithm (GA)、Evolutionary Strategy (ES) 和 Simulated Annealing (SA)，并在城市和高速公路场景中使用 ns-2 模拟器进行测试。结果显示，PSO 在两个场景中均表现出色，优于其他算法，为 VANETs 的高效配置提供了实用指导。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08847v1",
      "published_date": "2025-01-15 14:59:00 UTC",
      "updated_date": "2025-01-15 14:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:51:50.991738"
    },
    {
      "arxiv_id": "2501.08841v1",
      "title": "Exploring Task-Level Optimal Prompts for Visual In-Context Learning",
      "title_zh": "探索任务级最优提示用于视觉上下文学习",
      "authors": [
        "Yan Zhu",
        "Huan Ma",
        "Changqing Zhang"
      ],
      "abstract": "With the development of Vision Foundation Models (VFMs) in recent years,\nVisual In-Context Learning (VICL) has become a better choice compared to\nmodifying models in most scenarios. Different from retraining or fine-tuning\nmodel, VICL does not require modifications to the model's weights or\narchitecture, and only needs a prompt with demonstrations to teach VFM how to\nsolve tasks. Currently, significant computational cost for finding optimal\nprompts for every test sample hinders the deployment of VICL, as determining\nwhich demonstrations to use for constructing prompts is very costly. In this\npaper, however, we find a counterintuitive phenomenon that most test samples\nactually achieve optimal performance under the same prompts, and searching for\nsample-level prompts only costs more time but results in completely identical\nprompts. Therefore, we propose task-level prompting to reduce the cost of\nsearching for prompts during the inference stage and introduce two time-saving\nyet effective task-level prompt search strategies. Extensive experimental\nresults show that our proposed method can identify near-optimal prompts and\nreach the best VICL performance with a minimal cost that prior work has never\nachieved.",
      "tldr_zh": "本研究探讨了Visual In-Context Learning (VICL) 中任务级别的最优提示策略，以解决为每个测试样本搜索提示的计算成本高问题。不同于传统的样本级搜索，研究发现大多数测试样本在相同的提示下即可达到最佳性能，从而提出task-level prompting 方法，并引入两种高效的提示搜索策略。实验结果显示，该方法能够识别近似最优提示，并在最低成本下实现最佳的VICL 性能，避免了以往方法的资源浪费。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08841v1",
      "published_date": "2025-01-15 14:52:20 UTC",
      "updated_date": "2025-01-15 14:52:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:52:02.821952"
    },
    {
      "arxiv_id": "2501.08838v1",
      "title": "ToMATO: Verbalizing the Mental States of Role-Playing LLMs for Benchmarking Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Kazutoshi Shinoda",
        "Nobukatsu Hojo",
        "Kyosuke Nishida",
        "Saki Mizuno",
        "Keita Suzuki",
        "Ryo Masumura",
        "Hiroaki Sugiyama",
        "Kuniko Saito"
      ],
      "abstract": "Existing Theory of Mind (ToM) benchmarks diverge from real-world scenarios in\nthree aspects: 1) they assess a limited range of mental states such as beliefs,\n2) false beliefs are not comprehensively explored, and 3) the diverse\npersonality traits of characters are overlooked. To address these challenges,\nwe introduce ToMATO, a new ToM benchmark formulated as multiple-choice QA over\nconversations. ToMATO is generated via LLM-LLM conversations featuring\ninformation asymmetry. By employing a prompting method that requires\nrole-playing LLMs to verbalize their thoughts before each utterance, we capture\nboth first- and second-order mental states across five categories: belief,\nintention, desire, emotion, and knowledge. These verbalized thoughts serve as\nanswers to questions designed to assess the mental states of characters within\nconversations. Furthermore, the information asymmetry introduced by hiding\nthoughts from others induces the generation of false beliefs about various\nmental states. Assigning distinct personality traits to LLMs further\ndiversifies both utterances and thoughts. ToMATO consists of 5.4k questions,\n753 conversations, and 15 personality trait patterns. Our analysis shows that\nthis dataset construction approach frequently generates false beliefs due to\nthe information asymmetry between role-playing LLMs, and effectively reflects\ndiverse personalities. We evaluate nine LLMs on ToMATO and find that even\nGPT-4o mini lags behind human performance, especially in understanding false\nbeliefs, and lacks robustness to various personality traits.",
      "tldr_zh": "本文提出 ToMATO，一种新的 Theory of Mind (ToM) 基准，通过 LLM-LLM 对话评估模型对心理状态的理解，解决了现有基准在心理状态范围、错误信念探索和人物人格多样性方面的不足。ToMATO 采用提示方法要求角色扮演的 LLMs verbalize 他们的 thoughts，从而捕捉一阶和二阶心理状态，包括 belief, intention, desire, emotion 和 knowledge，并通过信息不对称和分配不同 personality traits 生成 5.4k 道问题和 753 个对话。实验评估显示，九个 LLMs 如 GPT-4o mini 在 ToMATO 上表现落后于人类，尤其在理解 false beliefs 和处理各种 personality traits 时缺乏鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08838v1",
      "published_date": "2025-01-15 14:47:02 UTC",
      "updated_date": "2025-01-15 14:47:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:52:16.308118"
    },
    {
      "arxiv_id": "2501.08828v2",
      "title": "MMDocIR: Benchmarking Multi-Modal Retrieval for Long Documents",
      "title_zh": "MMDocIR：长文档多模态检索基准测试",
      "authors": [
        "Kuicai Dong",
        "Yujing Chang",
        "Xin Deik Goh",
        "Dexun Li",
        "Ruiming Tang",
        "Yong Liu"
      ],
      "abstract": "Multimodal document retrieval aims to identify and retrieve various forms of\nmultimodal content, such as figures, tables, charts, and layout information\nfrom extensive documents. Despite its increasing popularity, there is a notable\nlack of a comprehensive and robust benchmark to effectively evaluate the\nperformance of systems in such tasks. To address this gap, this work introduces\na new benchmark, named MMDocIR, that encompasses two distinct tasks: page-level\nand layout-level retrieval. The former evaluates the performance of identifying\nthe most relevant pages within a long document, while the later assesses the\nability of detecting specific layouts, providing a more fine-grained measure\nthan whole-page analysis. A layout refers to a variety of elements, including\ntextual paragraphs, equations, figures, tables, or charts. The MMDocIR\nbenchmark comprises a rich dataset featuring 1,685 questions annotated by\nexperts and 173,843 questions with bootstrapped labels, making it a valuable\nresource in multimodal document retrieval for both training and evaluation.\nThrough rigorous experiments, we demonstrate that (i) visual retrievers\nsignificantly outperform their text counterparts, (ii) MMDocIR training set\neffectively enhances the performance of multimodal document retrieval and (iii)\ntext retrievers leveraging VLM-text significantly outperforms retrievers\nrelying on OCR-text. Our dataset is available at\nhttps://mmdocrag.github.io/MMDocIR/.",
      "tldr_zh": "本研究针对多模态文档检索（Multi-Modal Retrieval）提出一个新的基准MMDocIR，用于评估从长文档中检索图表、表格和布局信息等任务的性能。该基准包括页面级检索（page-level retrieval），评估识别最相关页面的能力，以及布局级检索（layout-level retrieval），细粒度检测文本段落、方程、图表等元素的准确性。MMDocIR数据集包含1,685个专家标注问题和173,843个引导式标注问题，可用于训练和评估。实验结果显示，视觉检索器显著优于文本检索器，使用MMDocIR训练集可有效提升检索性能，且依赖VLM-text的文本检索器优于基于OCR-text的检索器。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "https://huggingface.co/MMDocIR",
      "pdf_url": "http://arxiv.org/pdf/2501.08828v2",
      "published_date": "2025-01-15 14:30:13 UTC",
      "updated_date": "2025-05-20 14:49:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:52:26.927030"
    },
    {
      "arxiv_id": "2501.08816v2",
      "title": "IDEA: Image Description Enhanced CLIP-Adapter",
      "title_zh": "IDEA：图像描述增强 CLIP-适配器",
      "authors": [
        "Zhipeng Ye",
        "Feng Jiang",
        "Qiufeng Wang",
        "Kaizhu Huang",
        "Jiaqi Huang"
      ],
      "abstract": "CLIP (Contrastive Language-Image Pre-training) has attained great success in\npattern recognition and computer vision. Transferring CLIP to downstream tasks\n(e.g. zero- or few-shot classification) is a hot topic in multimodal learning.\nHowever, current studies primarily focus on either prompt learning for text or\nadapter tuning for vision, without fully exploiting the complementary\ninformation and correlations among image-text pairs. In this paper, we propose\nan Image Description Enhanced CLIP-Adapter (IDEA) method to adapt CLIP to\nfew-shot image classification tasks. This method captures fine-grained features\nby leveraging both visual features and textual descriptions of images. IDEA is\na training-free method for CLIP, and it can be comparable to or even exceeds\nstate-of-the-art models on multiple tasks. Furthermore, we introduce\nTrainable-IDEA (T-IDEA), which extends IDEA by adding two lightweight learnable\ncomponents (i.e., a projector and a learnable latent space), further enhancing\nthe model's performance and achieving SOTA results on 11 datasets. As one\nimportant contribution, we employ the Llama model and design a comprehensive\npipeline to generate textual descriptions for images of 11 datasets, resulting\nin a total of 1,637,795 image-text pairs, named \"IMD-11\". Our code and data are\nreleased at https://github.com/FourierAI/IDEA.",
      "tldr_zh": "本研究提出 IDEA（Image Description Enhanced CLIP-Adapter）方法，以提升 CLIP 模型在少样本图像分类任务中的性能，通过整合视觉特征和图像的文本描述来捕获细粒度信息。IDEA 是一个无训练（training-free）框架，能够与或超过现有最先进模型（SOTA），而其扩展版本 T-IDEA 通过添加轻量级可学习组件（如投影器和潜在空间）进一步优化，在 11 个数据集上实现 SOTA 结果。研究还贡献了 IMD-11 数据集，利用 Llama 模型生成 1,637,795 个图像-文本对，并开源了代码和数据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08816v2",
      "published_date": "2025-01-15 14:12:59 UTC",
      "updated_date": "2025-01-19 02:34:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:52:39.012559"
    },
    {
      "arxiv_id": "2501.08814v2",
      "title": "SAIF: A Comprehensive Framework for Evaluating the Risks of Generative AI in the Public Sector",
      "title_zh": "SAIF：用于评估公共部门生成式 AI 风险的全面框架",
      "authors": [
        "Kyeongryul Lee",
        "Heehyeon Kim",
        "Joyce Jiyoung Whang"
      ],
      "abstract": "The rapid adoption of generative AI in the public sector, encompassing\ndiverse applications ranging from automated public assistance to welfare\nservices and immigration processes, highlights its transformative potential\nwhile underscoring the pressing need for thorough risk assessments. Despite its\ngrowing presence, evaluations of risks associated with AI-driven systems in the\npublic sector remain insufficiently explored. Building upon an established\ntaxonomy of AI risks derived from diverse government policies and corporate\nguidelines, we investigate the critical risks posed by generative AI in the\npublic sector while extending the scope to account for its multimodal\ncapabilities. In addition, we propose a Systematic dAta generatIon Framework\nfor evaluating the risks of generative AI (SAIF). SAIF involves four key\nstages: breaking down risks, designing scenarios, applying jailbreak methods,\nand exploring prompt types. It ensures the systematic and consistent generation\nof prompt data, facilitating a comprehensive evaluation while providing a solid\nfoundation for mitigating the risks. Furthermore, SAIF is designed to\naccommodate emerging jailbreak methods and evolving prompt types, thereby\nenabling effective responses to unforeseen risk scenarios. We believe that this\nstudy can play a crucial role in fostering the safe and responsible integration\nof generative AI into the public sector.",
      "tldr_zh": "该研究探讨了生成式 AI 在公共部门的快速应用（如公共援助和移民流程）所带来的风险，并强调了全面风险评估的必要性。基于现有 AI 风险分类，论文扩展了针对生成式 AI 的多模态能力评估，并提出 Systematic dAta generatIon Framework (SAIF)，该框架包括四个关键阶段：分解风险、设计场景、应用 jailbreak methods 和探索 prompt types，以系统生成提示数据并进行全面评估。SAIF 设计灵活，可适应新兴的 jailbreak methods 和 prompt types，从而为公共部门安全、负责任地整合生成式 AI 提供坚实基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures, 1 tables. AI for Public Missions (AIPM) Workshop\n  at the 39th AAAI Conference on Artificial Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.08814v2",
      "published_date": "2025-01-15 14:12:38 UTC",
      "updated_date": "2025-03-28 04:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:52:50.478081"
    },
    {
      "arxiv_id": "2501.08809v1",
      "title": "XMusic: Towards a Generalized and Controllable Symbolic Music Generation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Sida Tian",
        "Can Zhang",
        "Wei Yuan",
        "Wei Tan",
        "Wenjie Zhu"
      ],
      "abstract": "In recent years, remarkable advancements in artificial intelligence-generated\ncontent (AIGC) have been achieved in the fields of image synthesis and text\ngeneration, generating content comparable to that produced by humans. However,\nthe quality of AI-generated music has not yet reached this standard, primarily\ndue to the challenge of effectively controlling musical emotions and ensuring\nhigh-quality outputs. This paper presents a generalized symbolic music\ngeneration framework, XMusic, which supports flexible prompts (i.e., images,\nvideos, texts, tags, and humming) to generate emotionally controllable and\nhigh-quality symbolic music. XMusic consists of two core components, XProjector\nand XComposer. XProjector parses the prompts of various modalities into\nsymbolic music elements (i.e., emotions, genres, rhythms and notes) within the\nprojection space to generate matching music. XComposer contains a Generator and\na Selector. The Generator generates emotionally controllable and melodious\nmusic based on our innovative symbolic music representation, whereas the\nSelector identifies high-quality symbolic music by constructing a multi-task\nlearning scheme involving quality assessment, emotion recognition, and genre\nrecognition tasks. In addition, we build XMIDI, a large-scale symbolic music\ndataset that contains 108,023 MIDI files annotated with precise emotion and\ngenre labels. Objective and subjective evaluations show that XMusic\nsignificantly outperforms the current state-of-the-art methods with impressive\nmusic quality. Our XMusic has been awarded as one of the nine Highlights of\nCollectibles at WAIC 2023. The project homepage of XMusic is\nhttps://xmusic-project.github.io.",
      "tldr_zh": "该论文提出XMusic框架，一个通用的符号音乐生成系统，旨在解决AI音乐生成中情感控制和质量不足的问题，支持图像、视频、文本、标签和哼唱等多种提示输入。框架的核心组件包括XProjector，用于将各种模态提示解析成符号音乐元素（如情感、流派、节奏和音符），以及XComposer，由Generator（基于创新符号音乐表示生成可控音乐）和Selector（通过多任务学习评估质量、情感和流派）组成。此外，研究构建了XMIDI数据集，包含10.8万标注情感和流派的MIDI文件。客观和主观评估显示，XMusic显著优于现有方法，并在WAIC 2023获得亮点奖项。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accepted by TMM",
      "pdf_url": "http://arxiv.org/pdf/2501.08809v1",
      "published_date": "2025-01-15 14:08:44 UTC",
      "updated_date": "2025-01-15 14:08:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:53:03.352967"
    },
    {
      "arxiv_id": "2501.10464v3",
      "title": "Adapting Beyond the Depth Limit: Counter Strategies in Large Imperfect Information Games",
      "title_zh": "超越深度限制的适应：大规模不完美信息游戏中的反制策略",
      "authors": [
        "David Milec",
        "Vojtěch Kovařík",
        "Viliam Lisý"
      ],
      "abstract": "We study the problem of adapting to a known sub-rational opponent during\nonline play while remaining robust to rational opponents. We focus on large\nimperfect-information (zero-sum) games, which makes it impossible to inspect\nthe whole game tree at once and necessitates the use of depth-limited search.\nHowever, all existing methods assume rational play beyond the depth-limit,\nwhich only allows them to adapt a very limited portion of the opponent's\nbehaviour. We propose an algorithm Adapting Beyond Depth-limit (ABD) that uses\na strategy-portfolio approach - which we refer to as matrix-valued states - for\ndepth-limited search. This allows the algorithm to fully utilise all\ninformation about the opponent model, making it the first robust-adaptation\nmethod to be able to do so in large imperfect-information games. As an\nadditional benefit, the use of matrix-valued states makes the algorithm simpler\nthan traditional methods based on optimal value functions. Our experimental\nresults in poker and battleship show that ABD yields more than a twofold\nincrease in utility when facing opponents who make mistakes beyond the depth\nlimit and also delivers significant improvements in utility and safety against\nrandomly generated opponents.",
      "tldr_zh": "这篇论文探讨了在大型 imperfect-information games 中，如何在在线游戏中适应已知的亚理性对手，同时保持对理性对手的鲁棒性。论文提出 ABD（Adapting Beyond Depth-limit）算法，使用 matrix-valued states 的策略组合方法进行 depth-limited search，从而充分利用对手行为信息，这是首个能在此类游戏中实现全面适应的鲁棒方法。实验结果显示，在扑克和战舰游戏中，ABD 对犯错对手的效用提高了两倍以上，并对随机生成的对手带来了显著的效用和安全性提升。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10464v3",
      "published_date": "2025-01-15 14:04:27 UTC",
      "updated_date": "2025-02-09 16:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:53:15.491034"
    },
    {
      "arxiv_id": "2501.08778v1",
      "title": "Networked Agents in the Dark: Team Value Learning under Partial Observability",
      "title_zh": "黑暗中的网络化代理：部分可观察性下的团队价值学习",
      "authors": [
        "Guilherme S. Varela",
        "Alberto Sardinha",
        "Francisco S. Melo"
      ],
      "abstract": "We propose a novel cooperative multi-agent reinforcement learning (MARL)\napproach for networked agents. In contrast to previous methods that rely on\ncomplete state information or joint observations, our agents must learn how to\nreach shared objectives under partial observability. During training, they\ncollect individual rewards and approximate a team value function through local\ncommunication, resulting in cooperative behavior. To describe our problem, we\nintroduce the networked dynamic partially observable Markov game framework,\nwhere agents communicate over a switching topology communication network. Our\ndistributed method, DNA-MARL, uses a consensus mechanism for local\ncommunication and gradient descent for local computation. DNA-MARL increases\nthe range of the possible applications of networked agents, being well-suited\nfor real world domains that impose privacy and where the messages may not reach\ntheir recipients. We evaluate DNA-MARL across benchmark MARL scenarios. Our\nresults highlight the superior performance of DNA-MARL over previous methods.",
      "tldr_zh": "本研究提出了一种新型合作多智能体强化学习(MARL)方法，DNA-MARL，针对部分可观察性的网络代理场景，代理通过本地通信收集个体奖励并近似团队价值函数，实现合作行为。该方法基于网络动态部分可观察Markov游戏框架，使用共识机制进行通信和梯度下降进行本地计算，适用于隐私要求高且消息可能丢失的真实世界应用。在基准MARL场景中，DNA-MARL的表现优于现有方法，扩展了网络代理的应用范围。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures, 5 tables. Accepted as supplemental material at\n  Proceedings of the 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025), Detroit, Michigan, USA, May 19 - 23, 2025,\n  IFAAMAS",
      "pdf_url": "http://arxiv.org/pdf/2501.08778v1",
      "published_date": "2025-01-15 13:01:32 UTC",
      "updated_date": "2025-01-15 13:01:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:53:26.306685"
    },
    {
      "arxiv_id": "2501.08774v2",
      "title": "How Developers Interact with AI: A Taxonomy of Human-AI Collaboration in Software Engineering",
      "title_zh": "开发人员如何与 AI 互动：软件工程中人类-AI 协作的分类法",
      "authors": [
        "Christoph Treude",
        "Marco A. Gerosa"
      ],
      "abstract": "Artificial intelligence (AI), including large language models and generative\nAI, is emerging as a significant force in software development, offering\ndevelopers powerful tools that span the entire development lifecycle. Although\nsoftware engineering research has extensively studied AI tools in software\ndevelopment, the specific types of interactions between developers and these\nAI-powered tools have only recently begun to receive attention. Understanding\nand improving these interactions has the potential to enhance productivity,\ntrust, and efficiency in AI-driven workflows. In this paper, we propose a\ntaxonomy of interaction types between developers and AI tools, identifying\neleven distinct interaction types, such as auto-complete code suggestions,\ncommand-driven actions, and conversational assistance. Building on this\ntaxonomy, we outline a research agenda focused on optimizing AI interactions,\nimproving developer control, and addressing trust and usability challenges in\nAI-assisted development. By establishing a structured foundation for studying\ndeveloper-AI interactions, this paper aims to stimulate research on creating\nmore effective, adaptive AI tools for software development.",
      "tldr_zh": "这篇论文探讨了开发者与AI工具的交互，提出一个分类系统（taxonomy），识别了11种不同的交互类型，如代码自动完成建议、命令驱动动作和对话式协助，以系统化地理解人类-AI协作在软件工程中的作用。论文强调，这些交互类型能提升开发者的生产力、信任和效率，并基于taxonomy概述了一个研究议程，聚焦于优化AI交互、改善开发者控制以及解决信任和可用性挑战。通过建立这一结构化基础，论文旨在推动开发更有效、适应性的AI工具的研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at 2nd ACM International Conference on AI Foundation Models\n  and Software Engineering (FORGE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.08774v2",
      "published_date": "2025-01-15 12:53:49 UTC",
      "updated_date": "2025-02-05 16:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:53:39.821588"
    },
    {
      "arxiv_id": "2501.09051v1",
      "title": "Polyp detection in colonoscopy images using YOLOv11",
      "title_zh": "使用 YOLOv11 检测结肠镜图像中的息肉",
      "authors": [
        "Alok Ranjan Sahoo",
        "Satya Sangram Sahoo",
        "Pavan Chakraborty"
      ],
      "abstract": "Colorectal cancer (CRC) is one of the most commonly diagnosed cancers all\nover the world. It starts as a polyp in the inner lining of the colon. To\nprevent CRC, early polyp detection is required. Colonosopy is used for the\ninspection of the colon. Generally, the images taken by the camera placed at\nthe tip of the endoscope are analyzed by the experts manually. Various\ntraditional machine learning models have been used with the rise of machine\nlearning. Recently, deep learning models have shown more effectiveness in polyp\ndetection due to their superiority in generalizing and learning small features.\nThese deep learning models for object detection can be segregated into two\ndifferent types: single-stage and two-stage. Generally, two stage models have\nhigher accuracy than single stage ones but the single stage models have low\ninference time. Hence, single stage models are easy to use for quick object\ndetection. YOLO is one of the singlestage models used successfully for polyp\ndetection. It has drawn the attention of researchers because of its lower\ninference time. The researchers have used Different versions of YOLO so far,\nand with each newer version, the accuracy of the model is increasing. This\npaper aims to see the effectiveness of the recently released YOLOv11 to detect\npolyp. We analyzed the performance for all five models of YOLOv11 (YOLO11n,\nYOLO11s, YOLO11m, YOLO11l, YOLO11x) with Kvasir dataset for the training and\ntesting. Two different versions of the dataset were used. The first consisted\nof the original dataset, and the other was created using augmentation\ntechniques. The performance of all the models with these two versions of the\ndataset have been analysed.",
      "tldr_zh": "本研究针对结肠癌早期预防，探讨了使用YOLOv11模型检测结肠镜图像中的息肉，以辅助专家手动分析。论文评估了YOLOv11的五个变体（YOLO11n, YOLO11s, YOLO11m, YOLO11l, YOLO11x）在Kvasir数据集上的性能，包括原始数据集和通过数据增强技术创建的版本。结果表明，YOLOv11作为单阶段深度学习模型，兼具低推理时间和较高准确性，在息肉检测任务中显示出显著有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09051v1",
      "published_date": "2025-01-15 12:40:13 UTC",
      "updated_date": "2025-01-15 12:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:53:50.507991"
    },
    {
      "arxiv_id": "2501.08760v1",
      "title": "Leveraging LLM Agents for Translating Network Configurations",
      "title_zh": "翻译失败",
      "authors": [
        "Yunze Wei",
        "Xiaohui Xie",
        "Yiwei Zuo",
        "Tianshuo Hu",
        "Xinyi Chen",
        "Kaiwen Chi",
        "Yong Cui"
      ],
      "abstract": "Configuration translation is a critical and frequent task in network\noperations. When a network device is damaged or outdated, administrators need\nto replace it to maintain service continuity. The replacement devices may\noriginate from different vendors, necessitating configuration translation to\nensure seamless network operation. However, translating configurations manually\nis a labor-intensive and error-prone process. In this paper, we propose an\nintent-based framework for translating network configuration with Large\nLanguage Model (LLM) Agents. The core of our approach is an Intent-based\nRetrieval Augmented Generation (IRAG) module that systematically splits a\nconfiguration file into fragments, extracts intents, and generates accurate\ntranslations. We also design a two-stage verification method to validate the\nsyntax and semantics correctness of the translated configurations. We implement\nand evaluate the proposed method on real-world network configurations.\nExperimental results show that our method achieves 97.74% syntax correctness,\noutperforming state-of-the-art methods in translation accuracy.",
      "tldr_zh": "该研究针对网络操作中设备更换导致的配置翻译难题，提出了一种基于 Large Language Model (LLM) Agents 的 intent-based 框架，以自动化处理不同供应商的网络配置。框架的核心是 Intent-based Retrieval Augmented Generation (IRAG) 模块，该模块将配置文件拆分成片段、提取意图并生成准确翻译，同时结合两阶段验证方法确保翻译的语法和语义正确性。在真实网络配置的实验中，该方法实现了97.74%的语法正确率，并超越了现有方法的翻译准确性，为高效的网络维护提供了可靠工具。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08760v1",
      "published_date": "2025-01-15 12:25:56 UTC",
      "updated_date": "2025-01-15 12:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:54:02.372135"
    },
    {
      "arxiv_id": "2501.09050v1",
      "title": "Generating Realistic Synthetic Head Rotation Data for Extended Reality using Deep Learning",
      "title_zh": "使用深度学习生成用于扩展现实的真实合成头部旋转数据",
      "authors": [
        "Jakob Struye",
        "Filip Lemic",
        "Jeroen Famaey"
      ],
      "abstract": "Extended Reality is a revolutionary method of delivering multimedia content\nto users. A large contributor to its popularity is the sense of immersion and\ninteractivity enabled by having real-world motion reflected in the virtual\nexperience accurately and immediately. This user motion, mainly caused by head\nrotations, induces several technical challenges. For instance, which content is\ngenerated and transmitted depends heavily on where the user is looking.\nSeamless systems, taking user motion into account proactively, will therefore\nrequire accurate predictions of upcoming rotations. Training and evaluating\nsuch predictors requires vast amounts of orientational input data, which is\nexpensive to gather, as it requires human test subjects. A more feasible\napproach is to gather a modest dataset through test subjects, and then extend\nit to a more sizeable set using synthetic data generation methods. In this\nwork, we present a head rotation time series generator based on TimeGAN, an\nextension of the well-known Generative Adversarial Network, designed\nspecifically for generating time series. This approach is able to extend a\ndataset of head rotations with new samples closely matching the distribution of\nthe measured time series.",
      "tldr_zh": "这篇论文针对 Extended Reality (XR) 中的头部旋转数据生成问题，提出了一种基于 Deep Learning 的方法，以解决真实数据收集成本高的问题。作者使用 TimeGAN（一种扩展 Generative Adversarial Network 的时间序列生成器）来扩展现有的头部旋转数据集，生成与真实时间序列分布高度相似的合成样本。该方法能够有效提升数据集规模，支持XR系统中用户运动预测的训练和评估，从而提高系统的沉浸感和响应效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published and presented at International Conference on Multimedia\n  2022 (ACMMM), Workshop on Interactive eXtended Reality (IXR)",
      "pdf_url": "http://arxiv.org/pdf/2501.09050v1",
      "published_date": "2025-01-15 12:14:15 UTC",
      "updated_date": "2025-01-15 12:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:54:14.342924"
    },
    {
      "arxiv_id": "2501.09049v1",
      "title": "Dynamic-Aware Spatio-temporal Representation Learning for Dynamic MRI Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Dayoung Baik",
        "Jaejun Yoo"
      ],
      "abstract": "Dynamic MRI reconstruction, one of inverse problems, has seen a surge by the\nuse of deep learning techniques. Especially, the practical difficulty of\nobtaining ground truth data has led to the emergence of unsupervised learning\napproaches. A recent promising method among them is implicit neural\nrepresentation (INR), which defines the data as a continuous function that maps\ncoordinate values to the corresponding signal values. This allows for filling\nin missing information only with incomplete measurements and solving the\ninverse problem effectively. Nevertheless, previous works incorporating this\nmethod have faced drawbacks such as long optimization time and the need for\nextensive hyperparameter tuning. To address these issues, we propose\nDynamic-Aware INR (DA-INR), an INR-based model for dynamic MRI reconstruction\nthat captures the spatial and temporal continuity of dynamic MRI data in the\nimage domain and explicitly incorporates the temporal redundancy of the data\ninto the model structure. As a result, DA-INR outperforms other models in\nreconstruction quality even at extreme undersampling ratios while significantly\nreducing optimization time and requiring minimal hyperparameter tuning.",
      "tldr_zh": "本研究针对动态MRI重建的逆问题，提出了一种Dynamic-Aware Spatio-temporal Representation Learning方法，即Dynamic-Aware INR (DA-INR)模型，以解决传统无监督学习方法如INR存在的优化时间长和超参数调整复杂的问题。DA-INR通过捕捉动态MRI数据的空间和时间连续性，并在模型结构中显式融入时间冗余，实现高效的重建过程。实验结果显示，该模型在极端欠采样比率下，重建质量优于现有模型，同时显著缩短优化时间并减少超参数调整需求。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09049v1",
      "published_date": "2025-01-15 12:11:33 UTC",
      "updated_date": "2025-01-15 12:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:54:26.182869"
    },
    {
      "arxiv_id": "2501.10463v1",
      "title": "GLow -- A Novel, Flower-Based Simulated Gossip Learning Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Aitor Belenguer",
        "Jose A. Pascual",
        "Javier Navaridas"
      ],
      "abstract": "Fully decentralized learning algorithms are still in an early stage of\ndevelopment. Creating modular Gossip Learning strategies is not trivial due to\nconvergence challenges and Byzantine faults intrinsic in systems of\ndecentralized nature. Our contribution provides a novel means to simulate\ncustom Gossip Learning systems by leveraging the state-of-the-art Flower\nFramework. Specifically, we introduce GLow, which will allow researchers to\ntrain and assess scalability and convergence of devices, across custom network\ntopologies, before making a physical deployment. The Flower Framework is\nselected for being a simulation featured library with a very active community\non Federated Learning research. However, Flower exclusively includes vanilla\nFederated Learning strategies and, thus, is not originally designed to perform\nsimulations without a centralized authority. GLow is presented to fill this gap\nand make simulation of Gossip Learning systems possible. Results achieved by\nGLow in the MNIST and CIFAR10 datasets, show accuracies over 0.98 and 0.75\nrespectively. More importantly, GLow performs similarly in terms of accuracy\nand convergence to its analogous Centralized and Federated approaches in all\ndesigned experiments.",
      "tldr_zh": "该研究提出了一种新型模拟策略 GLow，利用 Flower Framework 构建模块化的 Gossip Learning 系统，以应对去中心化学习中的收敛挑战和 Byzantine faults。GLow 允许研究者在自定义网络拓扑下训练和评估设备的可扩展性及收敛性，从而避免直接物理部署的风险。实验结果显示，在 MNIST 和 CIFAR10 数据集上，GLow 分别实现了超过 0.98 和 0.75 的准确率，且其性能与相应的 Centralized 和 Federated Learning 方法相当。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures, 2 tables, source code:\n  https://github.com/AitorB16/GLow",
      "pdf_url": "http://arxiv.org/pdf/2501.10463v1",
      "published_date": "2025-01-15 11:35:32 UTC",
      "updated_date": "2025-01-15 11:35:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:54:39.304303"
    },
    {
      "arxiv_id": "2501.10462v1",
      "title": "BloomScene: Lightweight Structured 3D Gaussian Splatting for Crossmodal Scene Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolu Hou",
        "Mingcheng Li",
        "Dingkang Yang",
        "Jiawei Chen",
        "Ziyun Qian",
        "Xiao Zhao",
        "Yue Jiang",
        "Jinjie Wei",
        "Qingyao Xu",
        "Lihua Zhang"
      ],
      "abstract": "With the widespread use of virtual reality applications, 3D scene generation\nhas become a new challenging research frontier. 3D scenes have highly complex\nstructures and need to ensure that the output is dense, coherent, and contains\nall necessary structures. Many current 3D scene generation methods rely on\npre-trained text-to-image diffusion models and monocular depth estimators.\nHowever, the generated scenes occupy large amounts of storage space and often\nlack effective regularisation methods, leading to geometric distortions. To\nthis end, we propose BloomScene, a lightweight structured 3D Gaussian splatting\nfor crossmodal scene generation, which creates diverse and high-quality 3D\nscenes from text or image inputs. Specifically, a crossmodal progressive scene\ngeneration framework is proposed to generate coherent scenes utilizing\nincremental point cloud reconstruction and 3D Gaussian splatting. Additionally,\nwe propose a hierarchical depth prior-based regularization mechanism that\nutilizes multi-level constraints on depth accuracy and smoothness to enhance\nthe realism and continuity of the generated scenes. Ultimately, we propose a\nstructured context-guided compression mechanism that exploits structured hash\ngrids to model the context of unorganized anchor attributes, which\nsignificantly eliminates structural redundancy and reduces storage overhead.\nComprehensive experiments across multiple scenes demonstrate the significant\npotential and advantages of our framework compared with several baselines.",
      "tldr_zh": "该论文提出 BloomScene，一种轻量级的结构化 3D Gaussian Splatting 方法，用于从文本或图像输入生成高质量的跨模态 3D 场景，以解决现有方法在存储空间和几何扭曲方面的不足。具体而言，该框架采用跨模态渐进场景生成（结合增量点云重建和 3D Gaussian Splatting）、分层深度先验正则化机制（通过多级深度准确性和平滑性约束提升场景真实性），以及结构化上下文引导压缩机制（利用结构化哈希网格减少冗余并降低存储开销）。实验结果显示，BloomScene 在多个场景中比基线框架表现出显著优势，提高了 3D 场景的密集性、连贯性和整体质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10462v1",
      "published_date": "2025-01-15 11:33:34 UTC",
      "updated_date": "2025-01-15 11:33:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:55:59.571947"
    },
    {
      "arxiv_id": "2501.09768v3",
      "title": "Can Large Language Models Predict the Outcome of Judicial Decisions?",
      "title_zh": "大型语言模型能否预测司法决定的结果？",
      "authors": [
        "Mohamed Bayan Kmainasi",
        "Ali Ezzat Shahroor",
        "Amani Al-Ghraibah"
      ],
      "abstract": "Large Language Models (LLMs) have shown exceptional capabilities in Natural\nLanguage Processing (NLP) across diverse domains. However, their application in\nspecialized tasks such as Legal Judgment Prediction (LJP) for low-resource\nlanguages like Arabic remains underexplored. In this work, we address this gap\nby developing an Arabic LJP dataset, collected and preprocessed from Saudi\ncommercial court judgments. We benchmark state-of-the-art open-source LLMs,\nincluding LLaMA-3.2-3B and LLaMA-3.1-8B, under varying configurations such as\nzero-shot, one-shot, and fine-tuning using LoRA. Additionally, we employed a\ncomprehensive evaluation framework that integrates both quantitative metrics\n(such as BLEU, ROUGE, and BERT) and qualitative assessments (including\nCoherence, Legal Language, Clarity, etc.) using an LLM. Our results demonstrate\nthat fine-tuned smaller models achieve comparable performance to larger models\nin task-specific contexts while offering significant resource efficiency.\nFurthermore, we investigate the impact of fine-tuning the model on a diverse\nset of instructions, offering valuable insights into the development of a more\nhuman-centric and adaptable LLM. We have made the dataset, code, and models\npublicly available to provide a solid foundation for future research in Arabic\nlegal NLP.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 在Legal Judgment Prediction (LJP) 任务中的性能，特别是针对低资源语言如阿拉伯语，开发了一个从沙特商业法院判决中收集的阿拉伯语LJP数据集。研究通过基准测试开源模型如LLaMA-3.2-3B和LLaMA-3.1-8B，在零样本、一样本和使用LoRA的微调配置下，采用量化指标（BLEU、ROUGE、BERT）和定性评估（Coherence、Legal Language等）进行全面评估。结果显示，微调后的小型模型在任务特定场景下与大型模型性能相当，同时具备更高的资源效率，并提供了多样指令微调的见解；数据集、代码和模型已公开，以支持未来阿拉伯语法律NLP研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09768v3",
      "published_date": "2025-01-15 11:32:35 UTC",
      "updated_date": "2025-02-28 18:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:00.269735"
    },
    {
      "arxiv_id": "2501.08712v1",
      "title": "Self-supervised Transformation Learning for Equivariant Representations",
      "title_zh": "自监督变换学习用于等变表示",
      "authors": [
        "Jaemyung Yu",
        "Jaehyun Choi",
        "Dong-Jae Lee",
        "HyeongGwon Hong",
        "Junmo Kim"
      ],
      "abstract": "Unsupervised representation learning has significantly advanced various\nmachine learning tasks. In the computer vision domain, state-of-the-art\napproaches utilize transformations like random crop and color jitter to achieve\ninvariant representations, embedding semantically the same inputs despite\ntransformations. However, this can degrade performance in tasks requiring\nprecise features, such as localization or flower classification. To address\nthis, recent research incorporates equivariant representation learning, which\ncaptures transformation-sensitive information. However, current methods depend\non transformation labels and thus struggle with interdependency and complex\ntransformations. We propose Self-supervised Transformation Learning (STL),\nreplacing transformation labels with transformation representations derived\nfrom image pairs. The proposed method ensures transformation representation is\nimage-invariant and learns corresponding equivariant transformations, enhancing\nperformance without increased batch complexity. We demonstrate the approach's\neffectiveness across diverse classification and detection tasks, outperforming\nexisting methods in 7 out of 11 benchmarks and excelling in detection. By\nintegrating complex transformations like AugMix, unusable by prior equivariant\nmethods, this approach enhances performance across tasks, underscoring its\nadaptability and resilience. Additionally, its compatibility with various base\nmodels highlights its flexibility and broad applicability. The code is\navailable at https://github.com/jaemyung-u/stl.",
      "tldr_zh": "本文提出 Self-supervised Transformation Learning (STL)，一种自监督方法，用于学习等变表示 (equivariant representations)，以解决传统不变表示在精确任务（如定位或花朵分类）中的性能下降问题。STL 通过从图像对中派生变换表示，取代依赖变换标签的传统方法，确保变换表示图像不变并学习相应的等变变换，同时不增加批量复杂度。在多种分类和检测任务中，该方法在 11 个基准中的 7 个中优于现有方法，尤其在检测任务中表现出色，并能整合复杂变换如 AugMix，展示了其灵活性和广泛适用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.08712v1",
      "published_date": "2025-01-15 10:54:21 UTC",
      "updated_date": "2025-01-15 10:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:55:15.413870"
    },
    {
      "arxiv_id": "2501.10461v1",
      "title": "A Framework for Mining Collectively-Behaving Bots in MMORPGs",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsoo Kim",
        "Jun Hee Kim",
        "Jaeman Son",
        "Jihoon Song",
        "Eunjo Lee"
      ],
      "abstract": "In MMORPGs (Massively Multiplayer Online Role-Playing Games), abnormal\nplayers (bots) using unauthorized automated programs to carry out pre-defined\nbehaviors systematically and repeatedly are commonly observed. Bots usually\nengage in these activities to gain in-game money, which they eventually trade\nfor real money outside the game. Such abusive activities negatively impact the\nin-game experiences of legitimate users since bots monopolize specific hunting\nareas and obtain valuable items. Thus, detecting abnormal players is a\nsignificant task for game companies. Motivated by the fact that bots tend to\nbehave collectively with similar in-game trajectories due to the auto-programs,\nwe developed BotTRep, a framework that comprises trajectory representation\nlearning followed by clustering using a completely unlabeled in-game trajectory\ndataset. Our model aims to learn representations for in-game trajectory\nsequences so that players with contextually similar trajectories have closer\nembeddings. Then, by applying DBSCAN to these representations and visualizing\nthe corresponding moving patterns, our framework ultimately assists game\nmasters in identifying and banning bots.",
      "tldr_zh": "该研究针对MMORPGs（大型多人在线角色扮演游戏）中bots（异常玩家）的问题，提出BotTRep框架，以应对bots使用自动化程序进行集体行为（如刷取游戏货币），从而影响合法玩家的游戏体验。框架首先通过轨迹表示学习从无标签的游戏轨迹数据集中学得玩家轨迹的嵌入表示，确保上下文相似的轨迹具有更接近的向量距离。接着，应用DBSCAN聚类算法并可视化移动模式，帮助游戏管理员高效识别和封禁bots。总体而言，该方法为自动化检测bots提供了可扩展的解决方案，提升了游戏环境的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10461v1",
      "published_date": "2025-01-15 10:11:26 UTC",
      "updated_date": "2025-01-15 10:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:55:58.921680"
    },
    {
      "arxiv_id": "2501.08669v2",
      "title": "SPEQ: Offline Stabilization Phases for Efficient Q-Learning in High Update-To-Data Ratio Reinforcement Learning",
      "title_zh": "SPEQ：用于高更新到数据比率强化学习的离线",
      "authors": [
        "Carlo Romeo",
        "Girolamo Macaluso",
        "Alessandro Sestini",
        "Andrew D. Bagdanov"
      ],
      "abstract": "High update-to-data (UTD) ratio algorithms in reinforcement learning (RL)\nimprove sample efficiency but incur high computational costs, limiting\nreal-world scalability. We propose Offline Stabilization Phases for Efficient\nQ-Learning (SPEQ), an RL algorithm that combines low-UTD online training with\nperiodic offline stabilization phases. During these phases, Q-functions are\nfine-tuned with high UTD ratios on a fixed replay buffer, reducing redundant\nupdates on suboptimal data. This structured training schedule optimally\nbalances computational and sample efficiency, addressing the limitations of\nboth high and low UTD ratio approaches. We empirically demonstrate that SPEQ\nrequires from 40% to 99% fewer gradient updates and 27% to 78% less training\ntime compared to state-of-the-art high UTD ratio methods while maintaining or\nsurpassing their performance on the MuJoCo continuous control benchmark. Our\nfindings highlight the potential of periodic stabilization phases as an\neffective alternative to conventional training schedules, paving the way for\nmore scalable reinforcement learning solutions in real-world applications where\ncomputational resources are constrained.",
      "tldr_zh": "该论文提出 SPEQ 算法，用于在高更新到数据比 (UTD) 强化学习 (RL) 中提升效率，通过结合低 UTD 在线训练和周期性离线稳定阶段来优化训练过程。离线阶段采用高 UTD 比对固定重放缓冲区 (replay buffer) 进行 Q 函数微调，减少对次优数据的冗余更新，从而平衡计算和样本效率。实验结果显示，SPEQ 在 MuJoCo 连续控制基准上比现有高 UTD 方法减少 40% 到 99% 的梯度更新和 27% 到 78% 的训练时间，同时维持或超越其性能。这些发现证明了周期性稳定阶段的有效性，为计算资源受限的实际 RL 应用提供了更可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08669v2",
      "published_date": "2025-01-15 09:04:19 UTC",
      "updated_date": "2025-03-18 12:54:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:55:40.494060"
    },
    {
      "arxiv_id": "2501.09045v2",
      "title": "Spatio-Temporal Foundation Models: Vision, Challenges, and Opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Goodge",
        "Wee Siong Ng",
        "Bryan Hooi",
        "See Kiong Ng"
      ],
      "abstract": "Foundation models have revolutionized artificial intelligence, setting new\nbenchmarks in performance and enabling transformative capabilities across a\nwide range of vision and language tasks. However, despite the prevalence of\nspatio-temporal data in critical domains such as transportation, public health,\nand environmental monitoring, spatio-temporal foundation models (STFMs) have\nnot yet achieved comparable success. In this paper, we articulate a vision for\nthe future of STFMs, outlining their essential characteristics and the\ngeneralization capabilities necessary for broad applicability. We critically\nassess the current state of research, identifying gaps relative to these ideal\ntraits, and highlight key challenges that impede their progress. Finally, we\nexplore potential opportunities and directions to advance research towards the\naim of effective and broadly applicable STFMs.",
      "tldr_zh": "本论文探讨了时空基础模型（STFMs）的愿景、挑战和机会，强调尽管基础模型已在视觉和语言任务中取得革命性进展，但STFMs在交通、公共健康和环境监测等领域的应用仍落后。作者概述了STFMs的关键特征和泛化能力需求，以实现广泛适用性，并评估当前研究状态，识别出与理想特性的差距。论文突出了阻碍进展的主要挑战，如数据复杂性和模型局限性，并提出未来研究方向，以推动STFMs的开发和应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09045v2",
      "published_date": "2025-01-15 08:52:28 UTC",
      "updated_date": "2025-02-07 02:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:10.762165"
    },
    {
      "arxiv_id": "2501.08655v1",
      "title": "Application of Deep Reinforcement Learning to UAV Swarming for Ground Surveillance",
      "title_zh": "翻译失败",
      "authors": [
        "Raúl Arranz",
        "David Carramiñana",
        "Gonzalo de Miguel",
        "Juan A. Besada",
        "Ana M. Bernardos"
      ],
      "abstract": "This paper summarizes in depth the state of the art of aerial swarms,\ncovering both classical and new reinforcement-learning-based approaches for\ntheir management. Then, it proposes a hybrid AI system, integrating deep\nreinforcement learning in a multi-agent centralized swarm architecture. The\nproposed system is tailored to perform surveillance of a specific area,\nsearching and tracking ground targets, for security and law enforcement\napplications. The swarm is governed by a central swarm controller responsible\nfor distributing different search and tracking tasks among the cooperating\nUAVs. Each UAV agent is then controlled by a collection of cooperative\nsub-agents, whose behaviors have been trained using different deep\nreinforcement learning models, tailored for the different task types proposed\nby the swarm controller. More specifically, proximal policy optimization (PPO)\nalgorithms were used to train the agents' behavior. In addition, several\nmetrics to assess the performance of the swarm in this application were\ndefined. The results obtained through simulation show that our system searches\nthe operation area effectively, acquires the targets in a reasonable time, and\nis capable of tracking them continuously and consistently.",
      "tldr_zh": "这篇论文总结了无人机群（UAV swarming）的现有技术，包括经典方法和基于深度强化学习（deep reinforcement learning）的创新方法，并提出了一种混合 AI 系统，用于地面目标的监视和跟踪，适用于安全与执法场景。系统采用多智能体集中式架构，由中央控制器分配搜索和跟踪任务，每个 UAV 由一组合作子智能体控制，这些子智能体使用近端策略优化（PPO）算法进行训练。实验通过模拟评估了系统的性能，定义了多项指标，结果显示该系统能有效搜索操作区域、及时获取目标并持续跟踪，展示了其可靠性和潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08655v1",
      "published_date": "2025-01-15 08:46:20 UTC",
      "updated_date": "2025-01-15 08:46:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:24.389431"
    },
    {
      "arxiv_id": "2501.08653v2",
      "title": "Fine-grained Spatio-temporal Event Prediction with Self-adaptive Anchor Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Wang-Tao Zhou",
        "Zhao Kang",
        "Sicong Liu",
        "Lizong Zhang",
        "Ling Tian"
      ],
      "abstract": "Event prediction tasks often handle spatio-temporal data distributed in a\nlarge spatial area. Different regions in the area exhibit different\ncharacteristics while having latent correlations. This spatial heterogeneity\nand correlations greatly affect the spatio-temporal distributions of event\noccurrences, which has not been addressed by state-of-the-art models. Learning\nspatial dependencies of events in a continuous space is challenging due to its\nfine granularity and a lack of prior knowledge. In this work, we propose a\nnovel Graph Spatio-Temporal Point Process (GSTPP) model for fine-grained event\nprediction. It adopts an encoder-decoder architecture that jointly models the\nstate dynamics of spatially localized regions using neural Ordinary\nDifferential Equations (ODEs). The state evolution is built on the foundation\nof a novel Self-Adaptive Anchor Graph (SAAG) that captures spatial\ndependencies. By adaptively localizing the anchor nodes in the space and\njointly constructing the correlation edges between them, the SAAG enhances the\nmodel's ability of learning complex spatial event patterns. The proposed GSTPP\nmodel greatly improves the accuracy of fine-grained event prediction. Extensive\nexperimental results show that our method greatly improves the prediction\naccuracy over existing spatio-temporal event prediction approaches.",
      "tldr_zh": "本研究针对事件预测中空间异质性和相关性的挑战，提出了一种新型 Graph Spatio-Temporal Point Process (GSTPP) 模型，用于细粒度时空事件预测。GSTPP 采用编码器-解码器架构，通过神经 Ordinary Differential Equations (ODEs) 建模空间局部区域的状态动态，并引入 Self-Adaptive Anchor Graph (SAAG) 来自适应定位锚点节点并构建相关边，从而更好地捕捉复杂空间依赖性。实验结果显示，该模型在多个数据集上显著提高了预测准确性，比现有时空事件预测方法有较大改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to SIAM International Conference on Data Mining 2025\n  (SDM'25)",
      "pdf_url": "http://arxiv.org/pdf/2501.08653v2",
      "published_date": "2025-01-15 08:38:07 UTC",
      "updated_date": "2025-01-19 08:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:36.236739"
    },
    {
      "arxiv_id": "2501.08648v2",
      "title": "MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities",
      "title_zh": "MAGNET：用表示学习和填充能力增强生成式解码器",
      "authors": [
        "Savya Khosla",
        "Aditi Tiwari",
        "Kushal Kafle",
        "Simon Jenni",
        "Handong Zhao",
        "John Collomosse",
        "Jing Shi"
      ],
      "abstract": "While originally designed for unidirectional generative modeling,\ndecoder-only large language models (LLMs) are increasingly being adapted for\nbidirectional modeling. However, unidirectional and bidirectional models are\ntypically trained separately with distinct objectives (generation and\nrepresentation learning). This separation overlooks the opportunity for\ndeveloping a more versatile language model and for these objectives to\ncomplement each other. In this work, we propose MAGNET, a method for adapting\ndecoder-only LLMs to generate robust representations and infill missing text\nspans. MAGNET employs three self-supervised training objectives and introduces\nan attention mechanism that combines bidirectional and causal attention,\nenabling unified training across all objectives. Our results demonstrate that\nLLMs adapted with MAGNET (1) surpass strong text encoders on token-level and\nsentence-level representation learning tasks, (2) generate contextually\nappropriate text infills by leveraging past and future contexts, (3) perform\nopen-ended text generation without excessive repetition of words or phrases,\nand (4) preserve the knowledge and reasoning capability gained by the LLM\nduring pretraining.",
      "tldr_zh": "本论文提出MAGNET方法，用于增强decoder-only large language models (LLMs)，使其同时具备representation learning和infilling capabilities，解决传统单向生成模型与双向模型分开训练的局限性。MAGNET采用三个自监督训练目标，并引入结合bidirectional和causal attention的机制，实现这些目标的统一训练。实验结果表明，MAGNET适应后的LLMs在标记级和句子级representation learning任务上超越强文本编码器，能够生成上下文合适的文本infills，进行开放式文本生成而不重复过多内容，并保留了LLMs的预训练知识和推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08648v2",
      "published_date": "2025-01-15 08:24:03 UTC",
      "updated_date": "2025-02-14 00:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:48.404081"
    },
    {
      "arxiv_id": "2501.08641v1",
      "title": "Reassessing the Role of Chain-of-Thought in Sentiment Analysis: Insights and Limitations",
      "title_zh": "重新评估链式思维在情感分析中的作用：洞见和局限性",
      "authors": [
        "Kaiyuan Zheng",
        "Qinghua Zhao",
        "Lei Li"
      ],
      "abstract": "The relationship between language and thought remains an unresolved\nphilosophical issue. Existing viewpoints can be broadly categorized into two\nschools: one asserting their independence, and another arguing that language\nconstrains thought. In the context of large language models, this debate raises\na crucial question: Does a language model's grasp of semantic meaning depend on\nthought processes? To explore this issue, we investigate whether reasoning\ntechniques can facilitate semantic understanding. Specifically, we\nconceptualize thought as reasoning, employ chain-of-thought prompting as a\nreasoning technique, and examine its impact on sentiment analysis tasks. The\nexperiments show that chain-of-thought has a minimal impact on sentiment\nanalysis tasks. Both the standard and chain-of-thought prompts focus on aspect\nterms rather than sentiment in the generated content. Furthermore,\ncounterfactual experiments reveal that the model's handling of sentiment tasks\nprimarily depends on information from demonstrations. The experimental results\nsupport the first viewpoint.",
      "tldr_zh": "这篇论文重新评估了Chain-of-Thought推理技术在情感分析中的作用，探讨语言模型对语义理解是否依赖于思考过程。研究者通过实验比较标准提示和Chain-of-Thought提示，发现后者对情感分析任务的影响很小，主要关注方面术语而非情感表达。反事实实验进一步揭示，模型的表现主要依赖于演示中的信息，从而支持语言和思想独立的观点。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08641v1",
      "published_date": "2025-01-15 08:07:22 UTC",
      "updated_date": "2025-01-15 08:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:56:59.061984"
    },
    {
      "arxiv_id": "2501.09044v1",
      "title": "TCMM: Token Constraint and Multi-Scale Memory Bank of Contrastive Learning for Unsupervised Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng-An Zhu",
        "Hsin-Che Chien",
        "Chen-Kuo Chiang"
      ],
      "abstract": "This paper proposes the ViT Token Constraint and Multi-scale Memory bank\n(TCMM) method to address the patch noises and feature inconsistency in\nunsupervised person re-identification works. Many excellent methods use ViT\nfeatures to obtain pseudo labels and clustering prototypes, then train the\nmodel with contrastive learning. However, ViT processes images by performing\npatch embedding, which inevitably introduces noise in patches and may\ncompromise the performance of the re-identification model. On the other hand,\nprevious memory bank based contrastive methods may lead data inconsistency due\nto the limitation of batch size. Furthermore, existing pseudo label methods\noften discard outlier samples that are difficult to cluster. It sacrifices the\npotential value of outlier samples, leading to limited model diversity and\nrobustness. This paper introduces the ViT Token Constraint to mitigate the\ndamage caused by patch noises to the ViT architecture. The proposed Multi-scale\nMemory enhances the exploration of outlier samples and maintains feature\nconsistency. Experimental results demonstrate that our system achieves\nstate-of-the-art performance on common benchmarks. The project is available at\n\\href{https://github.com/andy412510/TCMM}{https://github.com/andy412510/TCMM}.",
      "tldr_zh": "这篇论文提出 TCMM 方法，包括 ViT Token Constraint 和 Multi-scale Memory Bank，用于解决无监督人重新识别中的 patch 噪声和特征不一致问题。TCMM 通过 ViT Token Constraint 减轻 ViT 架构中 patch embedding 引入的噪声，并利用 Multi-scale Memory Bank 增强对异常样本的探索，同时维护特征一致性，以克服现有方法的局限性，如批量大小限制和样本丢弃。实验结果显示，该方法在常见基准上达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09044v1",
      "published_date": "2025-01-15 07:14:02 UTC",
      "updated_date": "2025-01-15 07:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:57:11.425648"
    },
    {
      "arxiv_id": "2501.08621v1",
      "title": "ViBidirectionMT-Eval: Machine Translation for Vietnamese-Chinese and Vietnamese-Lao language pair",
      "title_zh": "翻译失败",
      "authors": [
        "Hong-Viet Tran",
        "Minh-Quy Nguyen",
        "Van-Vinh Nguyen"
      ],
      "abstract": "This paper presents an results of the VLSP 2022-2023 Machine Translation\nShared Tasks, focusing on Vietnamese-Chinese and Vietnamese-Lao machine\ntranslation. The tasks were organized as part of the 9th, 10th annual workshop\non Vietnamese Language and Speech Processing (VLSP 2022, VLSP 2023). The\nobjective of the shared task was to build machine translation systems,\nspecifically targeting Vietnamese-Chinese and Vietnamese-Lao translation\n(corresponding to 4 translation directions). The submission were evaluated on\n1,000 pairs for testing (news and general domains) using established metrics\nlike BLEU [11] and SacreBLEU [12]. Additionally, system outputs also were\nevaluated with human judgment provided by experts in Chinese and Lao languages.\nThese human assessments played a crucial role in ranking the performance of the\nmachine translation models, ensuring a more comprehensive evaluation.",
      "tldr_zh": "本论文介绍了 VLSP 2022-2023 机器翻译共享任务的结果，焦点是针对越南语-中文和越南语-老挝语的 Machine Translation 系统，涵盖四个翻译方向。任务要求参与者构建翻译系统，并在新闻和一般领域使用 1,000 对测试数据进行评估，采用 BLEU 和 SacreBLEU 等指标。人类判断由中文和老挝语专家提供，用于补充量化评估，确保系统性能的全面排名。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08621v1",
      "published_date": "2025-01-15 06:40:26 UTC",
      "updated_date": "2025-01-15 06:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:57:23.647290"
    },
    {
      "arxiv_id": "2501.08618v1",
      "title": "Disjoint Processing Mechanisms of Hierarchical and Linear Grammars in Large Language Models",
      "title_zh": "大型语言模型中分层语法和线性语法的",
      "authors": [
        "Aruna Sankaranarayanan",
        "Dylan Hadfield-Menell",
        "Aaron Mueller"
      ],
      "abstract": "All natural languages are structured hierarchically. In humans, this\nstructural restriction is neurologically coded: when two grammars are presented\nwith identical vocabularies, brain areas responsible for language processing\nare only sensitive to hierarchical grammars. Using large language models\n(LLMs), we investigate whether such functionally distinct hierarchical\nprocessing regions can arise solely from exposure to large-scale language\ndistributions. We generate inputs using English, Italian, Japanese, or nonce\nwords, varying the underlying grammars to conform to either hierarchical or\nlinear/positional rules. Using these grammars, we first observe that language\nmodels show distinct behaviors on hierarchical versus linearly structured\ninputs. Then, we find that the components responsible for processing\nhierarchical grammars are distinct from those that process linear grammars; we\ncausally verify this in ablation experiments. Finally, we observe that\nhierarchy-selective components are also active on nonce grammars; this suggests\nthat hierarchy sensitivity is not tied to meaning, nor in-distribution inputs.",
      "tldr_zh": "本研究调查大型语言模型 (LLMs) 是否能通过暴露于大规模语言分布而发展出与人类类似的层级语法处理机制，类似于大脑中对层级和线性语法的功能分离。研究者生成使用英语、意大利语、日语或无意义词的输入，分别基于层级或线性规则进行测试，结果显示 LLMs 在处理层级结构输入时表现出与线性结构不同的行为，且通过消融实验 (ablation experiments) 证实了负责层级语法的组件与线性语法的组件是分离的。最后，发现这些层级选择性组件在无意义语法上也活跃，表明这种敏感性不依赖于输入的意义或分布内特性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08618v1",
      "published_date": "2025-01-15 06:34:34 UTC",
      "updated_date": "2025-01-15 06:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:57:36.141831"
    },
    {
      "arxiv_id": "2501.08617v2",
      "title": "RLHS: Mitigating Misalignment in RLHF with Hindsight Simulation",
      "title_zh": "RLHS：通过事后模拟缓解 RLHF 中的不对齐",
      "authors": [
        "Kaiqu Liang",
        "Haimin Hu",
        "Ryan Liu",
        "Thomas L. Griffiths",
        "Jaime Fernández Fisac"
      ],
      "abstract": "While Reinforcement Learning from Human Feedback (RLHF) has shown promise in\naligning generative AI, we present empirical evidence that it can also cause\nsevere, systematic misalignment. We hypothesize that this stems from evaluator\nfeedback depending on downstream outcome predictions (foresight) that can be\ninfluenced by the AI's output, inducing Goodhart's law dynamics. Conversely,\nour theoretical analysis shows that conditioning evaluator feedback on\ndownstream observations (hindsight) inhibits this effect by decoupling the\nalignment signal from potentially compromised predictions-crucially, the result\nholds even if the observed outcomes are sampled from the AI's own world model.\nBuilding on this insight, we introduce Reinforcement Learning from Hindsight\nSimulation (RLHS), which presents plausible simulated outcomes to evaluators\nbefore eliciting feedback. We demonstrate RLHS on online (PPO) and offline\n(DPO) large language model fine-tuning, obtaining superior alignment over RLHF\nin controlled consultancy-type experiments and user studies. We evaluate\npost-hoc on the TruthfulQA benchmark and find that, even after single-task\nfine-tuning, both RLHF misalignment and RLHS alignment carry over to\nsubstantially different settings.",
      "tldr_zh": "该论文揭示了 Reinforcement Learning from Human Feedback (RLHF) 在对齐生成式 AI 时可能导致系统性失调的问题，原因在于评估者反馈依赖于下游结果预测（foresight），从而引发 Goodhart's law 动态。作者通过理论分析提出，使用基于下游观察（hindsight）的反馈机制可以抑制这种效应，即使观察来自 AI 的世界模型。基于此，论文引入 Reinforcement Learning from Hindsight Simulation (RLHS) 方法，向评估者呈现可信模拟结果后收集反馈，并在在线（PPO）和离线（DPO）大语言模型微调实验中，RLHS 比 RLHF 实现了更好的对齐效果，且在 TruthfulQA 基准测试中，这种对齐优势能转移到其他场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08617v2",
      "published_date": "2025-01-15 06:33:15 UTC",
      "updated_date": "2025-02-10 21:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:57:47.878823"
    },
    {
      "arxiv_id": "2501.16344v2",
      "title": "WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rajath Rao",
        "Adithya Ganesan",
        "Oscar Kjell",
        "Jonah Luby",
        "Akshay Raghavan",
        "Scott Feltman",
        "Whitney Ringwald",
        "Ryan L. Boyd",
        "Benjamin Luft",
        "Camilo Ruggero",
        "Neville Ryant",
        "Roman Kotov",
        "H. Andrew Schwartz"
      ],
      "abstract": "Current speech encoding pipelines often rely on an additional text-based LM\nto get robust representations of human communication, even though SotA\nspeech-to-text models often have a LM within. This work proposes an approach to\nimprove the LM within an audio model such that the subsequent text-LM is\nunnecessary. We introduce WhiSPA (Whisper with Semantic and Psychological\nAlignment), which leverages a novel audio training objective: contrastive loss\nwith a language model embedding as a teacher. Using over 500k speech segments\nfrom mental health audio interviews, we evaluate the utility of aligning\nWhisper's latent space with semantic representations from a text autoencoder\n(SBERT) and lexically derived embeddings of basic psychological dimensions:\nemotion and personality. Over self-supervised affective tasks and downstream\npsychological tasks, WhiSPA surpasses current speech encoders, achieving an\naverage error reduction of 73.4% and 83.8%, respectively. WhiSPA demonstrates\nthat it is not always necessary to run a subsequent text LM on speech-to-text\noutput in order to get a rich psychological representation of human\ncommunication.",
      "tldr_zh": "本文提出WhiSPA方法，通过自监督对比损失和student-teacher学习，将Whisper模型的音频嵌入与语义表示（来自SBERT）和心理维度（如情感和个性）的词汇派生嵌入对齐，从而无需额外的文本LM即可获取鲁棒的人类沟通表示。使用超过50万段心理健康音频访谈数据进行训练，WhiSPA在自监督情感任务和下游心理任务上超越现有语音编码器，平均错误减少73.4%和83.8%。这项工作证明了在心理分析中，直接优化音频模型的潜在空间即可实现高效的语义和心理对齐。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "15 pages, 8 figures, ACL ARR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.16344v2",
      "published_date": "2025-01-15 06:30:17 UTC",
      "updated_date": "2025-02-16 23:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:00.007842"
    },
    {
      "arxiv_id": "2501.08603v3",
      "title": "Monte Carlo Tree Search for Comprehensive Exploration in LLM-Based Automatic Heuristic Design",
      "title_zh": "Monte Carlo Tree Search 用于 LLM-Based 自动启发式设计的全面探索",
      "authors": [
        "Zhi Zheng",
        "Zhuoliang Xie",
        "Zhenkun Wang",
        "Bryan Hooi"
      ],
      "abstract": "Handcrafting heuristics for solving complex optimization tasks (e.g., route\nplanning and task allocation) is a common practice but requires extensive\ndomain knowledge. Recently, Large Language Model (LLM)-based automatic\nheuristic design (AHD) methods have shown promise in generating high-quality\nheuristics without manual interventions. Existing LLM-based AHD methods employ\na population to maintain a fixed number of top-performing LLM-generated\nheuristics and introduce evolutionary computation (EC) to iteratively enhance\nthe population. However, these population-based procedures cannot fully develop\nthe potential of each heuristic and are prone to converge into local optima. To\nmore comprehensively explore the space of heuristics, this paper proposes to\nuse Monte Carlo Tree Search (MCTS) for LLM-based heuristic evolution. The\nproposed MCTS-AHD method organizes all LLM-generated heuristics in a tree\nstructure and can better develop the potential of temporarily underperforming\nheuristics. In experiments, MCTS-AHD delivers significantly higher-quality\nheuristics on various complex tasks. Our code is available.",
      "tldr_zh": "该研究针对复杂优化任务（如路径规划和任务分配）的启发式算法设计问题，指出现有基于 Large Language Model (LLM) 的 Automatic Heuristic Design (AHD) 方法依赖种群和 evolutionary computation (EC)，但容易陷入局部最优且未能充分开发每个启发式的潜力。论文提出 MCTS-AHD 方法，利用 Monte Carlo Tree Search (MCTS) 将 LLM 生成的启发式算法组织成树结构，实现更全面的探索和优化。实验结果显示，MCTS-AHD 在多种复杂任务上显著提升了启发式算法的质量，并公开了相关代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08603v3",
      "published_date": "2025-01-15 06:00:50 UTC",
      "updated_date": "2025-01-31 05:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:11.496934"
    },
    {
      "arxiv_id": "2501.08600v2",
      "title": "AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL",
      "title_zh": "翻译失败",
      "authors": [
        "Tyler Stennett",
        "Myeongsoo Kim",
        "Saurabh Sinha",
        "Alessandro Orso"
      ],
      "abstract": "As REST APIs have become widespread in modern web services, comprehensive\ntesting of these APIs is increasingly crucial. Because of the vast search space\nof operations, parameters, and parameter values, along with their dependencies\nand constraints, current testing tools often achieve low code coverage,\nresulting in suboptimal fault detection. To address this limitation, we present\nAutoRestTest, a novel tool that integrates the Semantic Property Dependency\nGraph (SPDG) with Multi-Agent Reinforcement Learning (MARL) and large language\nmodels (LLMs) for effective REST API testing. AutoRestTest determines\noperation-dependent parameters using the SPDG and employs five specialized\nagents (operation, parameter, value, dependency, and header) to identify\ndependencies of operations and generate operation sequences, parameter\ncombinations, and values. Through an intuitive command-line interface, users\ncan easily configure and monitor tests with successful operation count, unique\nserver errors detected, and time elapsed. Upon completion, AutoRestTest\ngenerates a detailed report highlighting errors detected and operations\nexercised. In this paper, we introduce our tool and present preliminary\nfindings, with a demonstration video available at\nhttps://www.youtube.com/watch?v=VVus2W8rap8.",
      "tldr_zh": "该研究引入了AutoRestTest，一种新型工具，用于自动化REST API测试，通过整合Semantic Property Dependency Graph (SPDG)、Multi-Agent Reinforcement Learning (MARL)和large language models (LLMs)，解决现有工具在庞大搜索空间和依赖性方面的低代码覆盖率问题。该工具使用SPDG识别操作依赖参数，并部署五个专门代理（operation, parameter, value, dependency, and header）来生成操作序列、参数组合和值，从而提升故障检测效率。通过命令行界面，用户可轻松配置测试并监控指标，如成功操作数、唯一服务器错误和时间消耗，最终生成详细报告突出错误和操作。初步结果表明，AutoRestTest在REST API测试中表现出色，为更有效的自动化测试提供了实用解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To be published in the 47th IEEE/ACM International Conference on\n  Software Engineering - Demonstration Track (ICSE-Demo 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.08600v2",
      "published_date": "2025-01-15 05:54:33 UTC",
      "updated_date": "2025-03-04 03:19:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:25.257717"
    },
    {
      "arxiv_id": "2501.08598v2",
      "title": "LlamaRestTest: Effective REST API Testing with Small Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Myeongsoo Kim",
        "Saurabh Sinha",
        "Alessandro Orso"
      ],
      "abstract": "Modern web services rely heavily on REST APIs, typically documented using the\nOpenAPI specification. The widespread adoption of this standard has resulted in\nthe development of many black-box testing tools that generate tests based on\nOpenAPI specifications. Although Large Language Models (LLMs) have shown\npromising test-generation abilities, their application to REST API testing\nremains mostly unexplored. We present LlamaRestTest, a novel approach that\nemploys two custom LLMs-created by fine-tuning and quantizing the Llama3-8B\nmodel using mined datasets of REST API example values and inter-parameter\ndependencies-to generate realistic test inputs and uncover inter-parameter\ndependencies during the testing process by analyzing server responses. We\nevaluated LlamaRestTest on 12 real-world services (including popular services\nsuch as Spotify), comparing it against RESTGPT, a GPT-powered\nspecification-enhancement tool, as well as several state-of-the-art REST API\ntesting tools, including RESTler, MoRest, EvoMaster, and ARAT-RL. Our results\ndemonstrate that fine-tuning enables smaller models to outperform much larger\nmodels in detecting actionable parameter-dependency rules and generating valid\ninputs for REST API testing. We also evaluated different tool configurations,\nranging from the base Llama3-8B model to fine-tuned versions, and explored\nmultiple quantization techniques, including 2-bit, 4-bit, and 8-bit integer\nformats. Our study shows that small language models can perform as well as, or\nbetter than, large language models in REST API testing, balancing effectiveness\nand efficiency. Furthermore, LlamaRestTest outperforms state-of-the-art REST\nAPI testing tools in code coverage achieved and internal server errors\nidentified, even when those tools use RESTGPT-enhanced specifications.",
      "tldr_zh": "本研究提出 LlamaRestTest，一种基于小语言模型的 REST API 测试方法，通过微调和量化 Llama3-8B 模型，利用挖掘的数据集生成真实测试输入，并通过分析服务器响应发现参数间依赖。\n与 RESTGPT 和其他工具（如 RESTler、MoRest、EvoMaster、ARAT-RL）相比，LlamaRestTest 在 12 个真实服务（如 Spotify）上表现优异，小模型在检测参数依赖规则和生成有效输入方面优于更大模型。\n实验结果表明，该方法在代码覆盖和内部服务器错误识别上超过了现有工具，即使后者使用了增强的 OpenAPI 规范。\n此外，通过探索不同量化技术（如 2-bit、4-bit 和 8-bit），研究证明小语言模型能实现效果与效率的平衡。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To be published in the ACM International Conference on the\n  Foundations of Software Engineering (FSE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.08598v2",
      "published_date": "2025-01-15 05:51:20 UTC",
      "updated_date": "2025-04-03 19:42:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:36.674872"
    },
    {
      "arxiv_id": "2501.08591v1",
      "title": "OpenMLDB: A Real-Time Relational Data Feature Computation System for Online ML",
      "title_zh": "OpenMLDB：一个用于在线机器学习的实时关系数据特征计算系统",
      "authors": [
        "Xuanhe Zhou",
        "Wei Zhou",
        "Liguo Qi",
        "Hao Zhang",
        "Dihao Chen",
        "Bingsheng He",
        "Mian Lu",
        "Guoliang Li",
        "Fan Wu",
        "Yuqiang Chen"
      ],
      "abstract": "Efficient and consistent feature computation is crucial for a wide range of\nonline ML applications. Typically, feature computation is divided into two\ndistinct phases, i.e., offline stage for model training and online stage for\nmodel serving. These phases often rely on execution engines with different\ninterface languages and function implementations, causing significant\ninconsistencies. Moreover, many online ML features involve complex time-series\ncomputations (e.g., functions over varied-length table windows) that differ\nfrom standard streaming and analytical queries. Existing data processing\nsystems (e.g., Spark, Flink, DuckDB) often incur multi-second latencies for\nthese computations, making them unsuitable for real-time online ML applications\nthat demand timely feature updates.\n  This paper presents OpenMLDB, a feature computation system deployed in\n4Paradigm's SageOne platform and over 100 real scenarios. Technically, OpenMLDB\nfirst employs a unified query plan generator for consistent computation results\nacross the offline and online stages, significantly reducing feature deployment\noverhead. Second, OpenMLDB provides an online execution engine that resolves\nperformance bottlenecks caused by long window computations (via\npre-aggregation) and multi-table window unions (via data self-adjusting). It\nalso provides a high-performance offline execution engine with window parallel\noptimization and time-aware data skew resolving. Third, OpenMLDB features a\ncompact data format and stream-focused indexing to maximize memory usage and\naccelerate data access. Evaluations in testing and real workloads reveal\nsignificant performance improvements and resource savings compared to the\nbaseline systems. The open community of OpenMLDB now has over 150 contributors\nand gained 1.6k stars on GitHub.",
      "tldr_zh": "OpenMLDB 是一个针对在线 ML 的实时关系数据特征计算系统，旨在解决传统系统（如 Spark、Flink 和 DuckDB）在离线和在线阶段计算不一致、时间序列计算延迟高等问题，通过统一查询计划生成器确保计算结果一致，并优化在线执行引擎（包括预聚合和数据自调整）以及离线执行引擎（窗口并行优化和时间感知数据倾斜处理）。系统还引入紧凑数据格式和流式索引，以最大化内存利用和加速数据访问。实验评估显示，OpenMLDB 在测试和真实工作负载中显著提升性能和资源效率，已部署在100多个场景，并获得活跃社区支持（超过150贡献者和1.6k GitHub stars）。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08591v1",
      "published_date": "2025-01-15 05:20:01 UTC",
      "updated_date": "2025-01-15 05:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:47.768975"
    },
    {
      "arxiv_id": "2501.09767v1",
      "title": "LeMo: Enabling LEss Token Involvement for MOre Context Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Tuowei Wang",
        "Xingyu Chen",
        "Kun Li",
        "Ting Cao",
        "Ju Ren",
        "Yaoxue Zhang"
      ],
      "abstract": "The escalating demand for long-context applications has intensified the\nnecessity of extending the LLM context windows. Despite recent fine-tuning\napproaches successfully expanding context lengths, their high memory\nfootprints, especially for activations, present a critical practical\nlimitation. Current parameter-efficient fine-tuning methods prioritize reducing\nparameter update overhead over addressing activation memory constraints.\nSimilarly, existing sparsity mechanisms improve computational efficiency but\noverlook activation memory optimization due to the phenomenon of Shadowy\nActivation.\n  In this paper, we propose LeMo, the first LLM fine-tuning system that\nexplores and exploits a new token-level sparsity mechanism inherent in\nlong-context scenarios, termed Contextual Token Sparsity. LeMo minimizes\nredundant token involvement by assessing the informativeness of token\nembeddings while preserving model accuracy. Specifically, LeMo introduces three\nkey techniques: (1) Token Elimination, dynamically identifying and excluding\nredundant tokens across varying inputs and layers. (2) Pattern Prediction,\nutilizing well-trained predictors to approximate token sparsity patterns with\nminimal overhead. (3) Kernel Optimization, employing permutation-free and\nsegment-based strategies to boost system performance. We implement LeMo as an\nend-to-end fine-tuning system compatible with various LLM architectures and\nother optimization techniques. Comprehensive evaluations demonstrate that LeMo\nreduces memory consumption by up to 1.93x and achieves up to 1.36x speedups,\noutperforming state-of-the-art fine-tuning systems.",
      "tldr_zh": "该论文提出LeMo，一种创新的LLM细调系统，旨在通过利用长上下文场景中的Contextual Token Sparsity机制，减少冗余token参与，从而缓解现有方法的高激活内存消耗问题，同时保持模型准确性。LeMo引入三大关键技术：Token Elimination动态识别并排除冗余tokens、Pattern Prediction使用训练好的预测器以最小开销近似稀疏模式，以及Kernel Optimization采用无置换和基于段的策略提升性能。实验结果显示，LeMo可将内存消耗降低高达1.93倍，并实现1.36倍的加速，优于现有LLM细调系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09767v1",
      "published_date": "2025-01-15 05:17:12 UTC",
      "updated_date": "2025-01-15 05:17:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:58:59.821751"
    },
    {
      "arxiv_id": "2501.08587v1",
      "title": "Sound Scene Synthesis at the DCASE 2024 Challenge",
      "title_zh": "DCASE 2024 挑战中的声音场景合成",
      "authors": [
        "Mathieu Lagrange",
        "Junwon Lee",
        "Modan Tailleur",
        "Laurie M. Heller",
        "Keunwoo Choi",
        "Brian McFee",
        "Keisuke Imoto",
        "Yuki Okamoto"
      ],
      "abstract": "This paper presents Task 7 at the DCASE 2024 Challenge: sound scene\nsynthesis. Recent advances in sound synthesis and generative models have\nenabled the creation of realistic and diverse audio content. We introduce a\nstandardized evaluation framework for comparing different sound scene synthesis\nsystems, incorporating both objective and subjective metrics. The challenge\nattracted four submissions, which are evaluated using the Fr\\'echet Audio\nDistance (FAD) and human perceptual ratings. Our analysis reveals significant\ninsights into the current capabilities and limitations of sound scene synthesis\nsystems, while also highlighting areas for future improvement in this rapidly\nevolving field.",
      "tldr_zh": "本论文介绍了DCASE 2024 Challenge的Task 7：声音场景合成，利用最近的声音合成和生成模型进展来创建真实多样的音频内容。研究者提出一个标准化评估框架，结合客观指标如Fréchet Audio Distance (FAD)和主观人类感知评级，来比较不同合成系统。该挑战收到四份提交，通过分析结果揭示了当前系统的能力和局限性，并指出未来改进的方向，如提升合成真实性和多样性。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08587v1",
      "published_date": "2025-01-15 05:15:54 UTC",
      "updated_date": "2025-01-15 05:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:59:09.898745"
    },
    {
      "arxiv_id": "2501.09766v3",
      "title": "iTool: Boosting Tool Use of Large Language Models via Iterative Reinforced Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yirong Zeng",
        "Xiao Ding",
        "Yuxian Wang",
        "Weiwen Liu",
        "Wu Ning",
        "Yutai Hou",
        "Xu Huang",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Augmenting large language models (LLMs) with external tools is known as a\npromising approach to enhancing their capabilities, especially for complex\ntasks. Synthesizing tool-use data through real-world simulations is an\neffective way to achieve it. Nevertheless, our investigation reveals that (1)\ntraining gains significantly decay as synthetic data increases. The model\nstruggles to benefit from more synthetic data due to potential data diversity\nissues, resulting in poor performance in complex scenarios. Moreover, we find\nthat (2) this challenge primarily manifests as minor discrepancies between the\nmodel's output and the ground truth response (termed as deficiency), such as\nerrors in parameter values that require complex reasoning from the context to\nresolve. To this end, we propose an iterative reinforced fine-tuning strategy\ndesigned to alleviate these challenges. This strategy involves: (1) enhancing\nthe diversity of synthetic data through path exploration of Monte Carlo Tree\nSearch. (2) iteratively identifying deficiency-related data, constructing\nfine-grained preference pairs to pinpoint deficiencies, and then applying\npreference optimization to optimize these deficiencies. Our experiments show\nthat models trained using our method achieve about 12\\% better performance than\nbaseline models, outperforming larger open-source and closed-source models.",
      "tldr_zh": "该研究提出 iTool 框架，通过迭代强化微调（Iterative Reinforced Fine-Tuning）提升大型语言模型（LLMs）的工具使用能力，以解决合成数据多样性不足和输出缺陷（如参数值错误）问题。方法包括使用 Monte Carlo Tree Search 探索路径来增强合成数据的多样性，以及迭代识别缺陷相关数据、构建细粒度偏好对（preference pairs）并应用偏好优化。实验结果显示，采用 iTool 训练的模型比基线模型性能提升约 12%，并优于更大的开源和闭源模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "under review ACL",
      "pdf_url": "http://arxiv.org/pdf/2501.09766v3",
      "published_date": "2025-01-15 04:52:34 UTC",
      "updated_date": "2025-03-27 05:05:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:59:22.915012"
    },
    {
      "arxiv_id": "2501.08569v1",
      "title": "Evaluating SAT and SMT Solvers on Large-Scale Sudoku Puzzles",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Davis",
        "Tairan Ji"
      ],
      "abstract": "Modern SMT solvers have revolutionized the approach to constraint\nsatisfaction problems by integrating advanced theory reasoning and encoding\ntechniques. In this work, we evaluate the performance of modern SMT solvers in\nZ3, CVC5 and DPLL(T) against a standard SAT solver in DPLL. By benchmarking\nthese solvers on novel, diverse 25x25 Sudoku puzzles of various difficulty\nlevels created by our improved Sudoku generator, we examine the impact of\nadvanced theory reasoning and encoding techniques. Our findings demonstrate\nthat modern SMT solvers significantly outperform classical SAT solvers. This\nwork highlights the evolution of logical solvers and exemplifies the utility of\nSMT solvers in addressing large-scale constraint satisfaction problems.",
      "tldr_zh": "本文评估了现代 SMT 求解器（包括 Z3、CVC5 和 DPLL(T)）与标准 SAT 求解器 DPLL 在处理大规模约束满足问题时的性能。研究使用改进的数独生成器创建了各种难度水平的 25x25 Sudoku 谜题作为基准测试，考察了高级理论推理和编码技术的影响。结果显示，现代 SMT 求解器显著优于经典 SAT 求解器，在这些谜题上表现出色。该工作突出了逻辑求解器的演变，并展示了 SMT 求解器在解决大型约束满足问题中的实用价值。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08569v1",
      "published_date": "2025-01-15 04:31:56 UTC",
      "updated_date": "2025-01-15 04:31:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:59:35.909712"
    },
    {
      "arxiv_id": "2501.08566v1",
      "title": "Towards Lightweight and Stable Zero-shot TTS with Self-distilled Representation Disentanglement",
      "title_zh": "翻译失败",
      "authors": [
        "Qianniu Chen",
        "Xiaoyang Hao",
        "Bowen Li",
        "Yue Liu",
        "Li Lu"
      ],
      "abstract": "Zero-shot Text-To-Speech (TTS) synthesis shows great promise for personalized\nvoice customization through voice cloning. However, current methods for\nachieving zero-shot TTS heavily rely on large model scales and extensive\ntraining datasets to ensure satisfactory performance and generalizability\nacross various speakers. This raises concerns regarding both deployment costs\nand data security. In this paper, we present a lightweight and stable zero-shot\nTTS system. We introduce a novel TTS architecture designed to effectively model\nlinguistic content and various speaker attributes from source speech and prompt\nspeech, respectively. Furthermore, we present a two-stage self-distillation\nframework that constructs parallel data pairs for effectively disentangling\nlinguistic content and speakers from the perspective of training data.\nExtensive experiments show that our system exhibits excellent performance and\nsuperior stability on the zero-shot TTS tasks. Moreover, it shows markedly\nsuperior computational efficiency, with RTFs of 0.13 and 0.012 on the CPU and\nGPU, respectively.",
      "tldr_zh": "本研究针对零-shot Text-To-Speech (TTS) 系统的依赖于大型模型和海量数据的局限性，提出了一种轻量级且稳定的解决方案。论文引入一个新颖的TTS架构，用于从源语音和提示语音中分别建模语言内容和说话者属性，同时采用两阶段自蒸馏框架(Self-distilled Representation Disentanglement)，通过构建平行数据对实现有效表示分离。实验结果显示，该系统在零-shot TTS任务上表现出色，具有优越的稳定性和计算效率，CPU和GPU的实时因子(RTF)分别为0.13和0.012。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages,4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08566v1",
      "published_date": "2025-01-15 04:17:48 UTC",
      "updated_date": "2025-01-15 04:17:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:59:46.507826"
    },
    {
      "arxiv_id": "2501.08565v1",
      "title": "DualOpt: A Dual Divide-and-Optimize Algorithm for the Large-scale Traveling Salesman Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Shipei Zhou",
        "Yuandong Ding",
        "Chi Zhang",
        "Zhiguang Cao",
        "Yan Jin"
      ],
      "abstract": "This paper proposes a dual divide-and-optimize algorithm (DualOpt) for\nsolving the large-scale traveling salesman problem (TSP). DualOpt combines two\ncomplementary strategies to improve both solution quality and computational\nefficiency. The first strategy is a grid-based divide-and-conquer procedure\nthat partitions the TSP into smaller sub-problems, solving them in parallel and\niteratively refining the solution by merging nodes and partial routes. The\nprocess continues until only one grid remains, yielding a high-quality initial\nsolution. The second strategy involves a path-based divide-and-optimize\nprocedure that further optimizes the solution by dividing it into sub-paths,\noptimizing each using a neural solver, and merging them back to progressively\nimprove the overall solution. Extensive experiments conducted on two groups of\nTSP benchmark instances, including randomly generated instances with up to\n100,000 nodes and real-world datasets from TSPLIB, demonstrate the\neffectiveness of DualOpt. The proposed DualOpt achieves highly competitive\nresults compared to 10 state-of-the-art algorithms in the literature. In\nparticular, DualOpt achieves an improvement gap up to 1.40% for the largest\ninstance TSP100K with a remarkable 104x speed-up over the leading heuristic\nsolver LKH3. Additionally, DualOpt demonstrates strong generalization on TSPLIB\nbenchmarks, confirming its capability to tackle diverse real-world TSP\napplications.",
      "tldr_zh": "本文提出了一种双重分治优化算法 DualOpt，用于解决大规模 Traveling Salesman Problem (TSP)。该算法结合网格分治策略（将问题分区、平行求解并迭代合并）和路径分治策略（优化子路径并使用神经求解器进一步改进），从而提升解的质量和计算效率。在实验中，DualOpt 在随机实例（最多 100,000 节点）和 TSPLIB 基准上表现出色，与 10 个最先进算法相比，在 TSP100K 实例上实现了高达 1.40% 的改善和 104 倍的速度提升，证明了其在真实世界应用的强泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI-25, February 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08565v1",
      "published_date": "2025-01-15 04:16:28 UTC",
      "updated_date": "2025-01-15 04:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:00:00.385506"
    },
    {
      "arxiv_id": "2501.08561v2",
      "title": "ANSR-DT: An Adaptive Neuro-Symbolic Learning and Reasoning Framework for Digital Twins",
      "title_zh": "翻译失败",
      "authors": [
        "Safayat Bin Hakim",
        "Muhammad Adil",
        "Alvaro Velasquez",
        "Houbing Herbert Song"
      ],
      "abstract": "In this paper, we propose an Adaptive Neuro-Symbolic Learning and Reasoning\nFramework for digital twin technology called ``ANSR-DT.\" Digital twins in\nindustrial environments often struggle with interpretability, real-time\nadaptation, and human input integration. Our approach addresses these\nchallenges by combining CNN-LSTM dynamic event detection with reinforcement\nlearning and symbolic reasoning to enable adaptive intelligence with\ninterpretable decision processes. This integration enhances environmental\nunderstanding while promoting continuous learning, leading to more effective\nreal-time decision-making in human-machine collaborative applications. We\nevaluated ANSR-DT on synthetic industrial data, observing significant\nimprovements over traditional approaches, with up to 99.5% accuracy for dynamic\npattern recognition. The framework demonstrated superior adaptability with\nextended reinforcement learning training, improving explained variance from\n0.447 to 0.547. Future work aims at scaling to larger datasets to test rule\nmanagement beyond the current 14 rules. Our open-source implementation promotes\nreproducibility and establishes a foundation for future research in adaptive,\ninterpretable digital twins for industrial applications.",
      "tldr_zh": "本研究提出 ANSR-DT，一种自适应神经-符号学习和推理框架，用于数字孪生（digital twins）技术，以解决工业环境中可解释性、实时适应性和人类输入整合的挑战。该框架结合 CNN-LSTM 用于动态事件检测、reinforcement learning 进行优化，以及 symbolic reasoning 实现可解释决策过程，从而提升环境理解和实时决策效能。在合成工业数据上的评估显示，ANSR-DT 比传统方法显著改进，动态模式识别准确率达 99.5%，并通过强化学习训练将解释方差从 0.447 提升至 0.547。该框架的开源实现促进了可重复性，并为未来扩展到更大数据集和超过 14 条规则的管理奠定基础。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08561v2",
      "published_date": "2025-01-15 04:04:57 UTC",
      "updated_date": "2025-04-11 13:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:00:11.267140"
    },
    {
      "arxiv_id": "2501.08558v1",
      "title": "LAMS: LLM-Driven Automatic Mode Switching for Assistive Teleoperation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Tao",
        "Jehan Yang",
        "Dan Ding",
        "Zackory Erickson"
      ],
      "abstract": "Teleoperating high degrees-of-freedom (DoF) robotic manipulators via low-DoF\ncontrollers like joysticks often requires frequent switching between control\nmodes, where each mode maps controller movements to specific robot actions.\nManually performing this frequent switching can make teleoperation cumbersome\nand inefficient. On the other hand, existing automatic mode-switching\nsolutions, such as heuristic-based or learning-based methods, are often\ntask-specific and lack generalizability. In this paper, we introduce LLM-Driven\nAutomatic Mode Switching (LAMS), a novel approach that leverages Large Language\nModels (LLMs) to automatically switch control modes based on task context.\nUnlike existing methods, LAMS requires no prior task demonstrations and\nincrementally improves by integrating user-generated mode-switching examples.\nWe validate LAMS through an ablation study and a user study with 10\nparticipants on complex, long-horizon tasks, demonstrating that LAMS\neffectively reduces manual mode switches, is preferred over alternative\nmethods, and improves performance over time. The project website with\nsupplementary materials is at https://lams-assistance.github.io/.",
      "tldr_zh": "这篇论文提出了 LAMS，一种利用 Large Language Models (LLMs) 驱动的自动模式切换方法，用于辅助遥操作高自由度机器人，以解决手动频繁切换控制模式的低效问题。LAMS 通过任务上下文进行模式切换，不需要先前的任务演示，而是通过整合用户生成的示例来逐步优化。实验结果显示，在消融研究和用户研究（10 名参与者）中，LAMS 显著减少了手动切换，用户更偏好该方法，并且在复杂长期任务上性能持续改进。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08558v1",
      "published_date": "2025-01-15 03:49:08 UTC",
      "updated_date": "2025-01-15 03:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:02:16.794309"
    },
    {
      "arxiv_id": "2501.08552v2",
      "title": "Reinforcement Learning-Enhanced Procedural Generation for Dynamic Narrative-Driven AR Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Aniruddha Srinivas Joshi"
      ],
      "abstract": "Procedural Content Generation (PCG) is widely used to create scalable and\ndiverse environments in games. However, existing methods, such as the Wave\nFunction Collapse (WFC) algorithm, are often limited to static scenarios and\nlack the adaptability required for dynamic, narrative-driven applications,\nparticularly in augmented reality (AR) games. This paper presents a\nreinforcement learning-enhanced WFC framework designed for mobile AR\nenvironments. By integrating environment-specific rules and dynamic tile weight\nadjustments informed by reinforcement learning (RL), the proposed method\ngenerates maps that are both contextually coherent and responsive to gameplay\nneeds. Comparative evaluations and user studies demonstrate that the framework\nachieves superior map quality and delivers immersive experiences, making it\nwell-suited for narrative-driven AR games. Additionally, the method holds\npromise for broader applications in education, simulation training, and\nimmersive extended reality (XR) experiences, where dynamic and adaptive\nenvironments are critical.",
      "tldr_zh": "该论文针对现有 Procedural Content Generation (PCG) 方法（如 Wave Function Collapse (WFC) 算法）在动态叙事驱动的 Augmented Reality (AR) 游戏中缺乏适应性的问题，提出了一种强化学习 (RL) 增强的 WFC 框架。框架通过整合环境特定规则和基于 RL 的动态 tile 权重调整，生成语境连贯且响应游戏需求的地图。实验比较评估和用户研究显示，该方法显著提升了地图质量和沉浸式体验，并有望应用于教育、模拟训练和 Extended Reality (XR) 等领域。",
      "categories": [
        "cs.AI",
        "cs.GR",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in Proceedings of the 20th International Joint Conference\n  on Computer Vision, Imaging and Computer Graphics Theory and Applications -\n  GRAPP 2025\n  https://www.scitepress.org/PublicationsDetail.aspx?ID=LfPv9Lfiya8=&t=1",
      "pdf_url": "http://arxiv.org/pdf/2501.08552v2",
      "published_date": "2025-01-15 03:23:06 UTC",
      "updated_date": "2025-03-13 07:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:00:36.875605"
    },
    {
      "arxiv_id": "2501.08549v1",
      "title": "The Devil is in Temporal Token: High Quality Video Reasoning Segmentation",
      "title_zh": "魔鬼在于时间标记：高质量视频推理分割",
      "authors": [
        "Sitong Gong",
        "Yunzhi Zhuge",
        "Lu Zhang",
        "Zongxin Yang",
        "Pingping Zhang",
        "Huchuan Lu"
      ],
      "abstract": "Existing methods for Video Reasoning Segmentation rely heavily on a single\nspecial token to represent the object in the keyframe or the entire video,\ninadequately capturing spatial complexity and inter-frame motion. To overcome\nthese challenges, we propose VRS-HQ, an end-to-end video reasoning segmentation\napproach that leverages Multimodal Large Language Models (MLLMs) to inject rich\nspatiotemporal features into hierarchical tokens.Our key innovations include a\nTemporal Dynamic Aggregation (TDA) and a Token-driven Keyframe Selection (TKS).\nSpecifically, we design frame-level <SEG> and temporal-level <TAK> tokens that\nutilize MLLM's autoregressive learning to effectively capture both local and\nglobal information. Subsequently, we apply a similarity-based weighted fusion\nand frame selection strategy, then utilize SAM2 to perform keyframe\nsegmentation and propagation. To enhance keyframe localization accuracy, the\nTKS filters keyframes based on SAM2's occlusion scores during inference. VRS-HQ\nachieves state-of-the-art performance on ReVOS, surpassing VISA by\n5.9%/12.5%/9.1% in J&F scores across the three subsets. These results highlight\nthe strong temporal reasoning and segmentation capabilities of our method. Code\nand model weights will be released at VRS-HQ.",
      "tldr_zh": "本研究指出，现有的视频推理分割方法依赖单一特殊 token，无法有效捕捉空间复杂性和帧间运动。为解决此问题，提出 VRS-HQ，一种端到端的视频推理分割框架，利用 Multimodal Large Language Models (MLLMs) 注入丰富的时空特征，包括 Temporal Dynamic Aggregation (TDA) 和 Token-driven Keyframe Selection (TKS) 等创新设计，生成 frame-level <SEG> 和 temporal-level <TAK> tokens，并结合 SAM2 进行关键帧分割和传播。在 ReVOS 数据集上，VRS-HQ 相比 VISA 提升了 5.9%/12.5%/9.1% 的 J&F scores，展示了其出色的时间推理和分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08549v1",
      "published_date": "2025-01-15 03:17:24 UTC",
      "updated_date": "2025-01-15 03:17:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:00:49.594994"
    },
    {
      "arxiv_id": "2501.12405v1",
      "title": "Scopes of Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Kush R. Varshney",
        "Zahra Ashktorab",
        "Djallel Bouneffouf",
        "Matthew Riemer",
        "Justin D. Weisz"
      ],
      "abstract": "Much of the research focus on AI alignment seeks to align large language\nmodels and other foundation models to the context-less and generic values of\nhelpfulness, harmlessness, and honesty. Frontier model providers also strive to\nalign their models with these values. In this paper, we motivate why we need to\nmove beyond such a limited conception and propose three dimensions for doing\nso. The first scope of alignment is competence: knowledge, skills, or behaviors\nthe model must possess to be useful for its intended purpose. The second scope\nof alignment is transience: either semantic or episodic depending on the\ncontext of use. The third scope of alignment is audience: either mass, public,\nsmall-group, or dyadic. At the end of the paper, we use the proposed framework\nto position some technologies and workflows that go beyond prevailing notions\nof alignment.",
      "tldr_zh": "该论文批评了当前AI alignment（校准）研究过于局限地专注于模型的helpfulness（帮助性）、harmlessness（无害性）和honesty（诚实性），并提出扩展校准的三个维度：competence（能力），即模型所需的知识、技能或行为以实现预期用途；transience（短暂性），分为语义或情节性取决于使用情境；以及audience（受众），包括大众、公共、小组或双人互动。作者通过这个框架分析了超越现有校准概念的各种技术和工作流，旨在推动更全面的AI对齐策略。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "The 2nd International Workshop on AI Governance (AIGOV) held in\n  conjunction with AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12405v1",
      "published_date": "2025-01-15 03:06:59 UTC",
      "updated_date": "2025-01-15 03:06:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:00:59.250887"
    },
    {
      "arxiv_id": "2501.08540v1",
      "title": "Knowledge prompt chaining for semantic modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Pei Ding",
        "Jingge Du",
        "Zaiwen Feng"
      ],
      "abstract": "The task of building semantics for structured data such as CSV, JSON, and XML\nfiles is highly relevant in the knowledge representation field. Even though we\nhave a vast of structured data on the internet, mapping them to domain\nontologies to build semantics for them is still very challenging as it requires\nthe construction model to understand and learn graph-structured knowledge.\nOtherwise, the task will require human beings' effort and cost. In this paper,\nwe proposed a novel automatic semantic modeling framework: Knowledge Prompt\nChaining. It can serialize the graph-structured knowledge and inject it into\nthe LLMs properly in a Prompt Chaining architecture. Through this knowledge\ninjection and prompting chaining, the model in our framework can learn the\nstructure information and latent space of the graph and generate the semantic\nlabels and semantic graphs following the chains' insturction naturally. Based\non experimental results, our method achieves better performance than existing\nleading techniques, despite using reduced structured input data.",
      "tldr_zh": "该论文针对结构化数据（如 CSV、JSON 和 XML）的语义建模任务，提出了一种新型自动框架 Knowledge Prompt Chaining，以解决映射到领域本体时所需的图结构知识理解难题。该框架通过序列化图结构知识并注入到 LLMs 中，利用 Prompt Chaining 架构，让模型学习图的结构信息和潜在空间，从而自然生成语义标签和语义图。实验结果显示，该方法在减少结构化输入数据的情况下，性能优于现有领先技术，为高效的知识表示提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08540v1",
      "published_date": "2025-01-15 03:00:57 UTC",
      "updated_date": "2025-01-15 03:00:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:01:11.318682"
    },
    {
      "arxiv_id": "2501.08528v1",
      "title": "Dynamic Portfolio Optimization via Augmented DDPG with Quantum Price Levels-Based Trading Strategy",
      "title_zh": "动态投资组合优化",
      "authors": [
        "Runsheng Lin",
        "Zihan Xing",
        "Mingze Ma",
        "Raymond S. T. Lee"
      ],
      "abstract": "With the development of deep learning, Dynamic Portfolio Optimization (DPO)\nproblem has received a lot of attention in recent years, not only in the field\nof finance but also in the field of deep learning. Some advanced research in\nrecent years has proposed the application of Deep Reinforcement Learning (DRL)\nto the DPO problem, which demonstrated to be more advantageous than supervised\nlearning in solving the DPO problem. However, there are still certain unsolved\nissues: 1) DRL algorithms usually have the problems of slow learning speed and\nhigh sample complexity, which is especially problematic when dealing with\ncomplex financial data. 2) researchers use DRL simply for the purpose of\nobtaining high returns, but pay little attention to the problem of risk control\nand trading strategy, which will affect the stability of model returns. In\norder to address these issues, in this study we revamped the intrinsic\nstructure of the model based on the Deep Deterministic Policy Gradient (DDPG)\nand proposed the Augmented DDPG model. Besides, we also proposed an innovative\nrisk control strategy based on Quantum Price Levels (QPLs) derived from Quantum\nFinance Theory (QFT). Our experimental results revealed that our model has\nbetter profitability as well as risk control ability with less sample\ncomplexity in the DPO problem compared to the baseline models.",
      "tldr_zh": "本文针对Dynamic Portfolio Optimization (DPO)问题，指出现有Deep Reinforcement Learning (DRL)算法存在学习速度慢、样本复杂度高以及风险控制不足的挑战。研究者改进了Deep Deterministic Policy Gradient (DDPG)结构，提出Augmented DDPG模型，并结合基于Quantum Price Levels (QPLs)的风险控制策略，源自Quantum Finance Theory (QFT)，以提升交易策略的稳定性和盈利潜力。实验结果显示，该模型在DPO任务中比基线模型表现出更高的盈利能力、更强的风险控制能力，以及更低的样本复杂度。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08528v1",
      "published_date": "2025-01-15 02:37:28 UTC",
      "updated_date": "2025-01-15 02:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:01:24.173173"
    },
    {
      "arxiv_id": "2501.08523v1",
      "title": "Doc-Guided Sent2Sent++: A Sent2Sent++ Agent with Doc-Guided memory for Document-level Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "Yuanchang Luo",
        "Daimeng Wei",
        "Ling Zhang",
        "Zongyao Li",
        "Hengchao Shang",
        "Zhiqiang Rao",
        "Shaojun Li",
        "Jinlong Yang",
        "Zhanglin Wu",
        "Hao Yang"
      ],
      "abstract": "The field of artificial intelligence has witnessed significant advancements\nin natural language processing, largely attributed to the capabilities of Large\nLanguage Models (LLMs). These models form the backbone of Agents designed to\naddress long-context dependencies, particularly in Document-level Machine\nTranslation (DocMT). DocMT presents unique challenges, with quality,\nconsistency, and fluency being the key metrics for evaluation. Existing\napproaches, such as Doc2Doc and Doc2Sent, either omit sentences or compromise\nfluency. This paper introduces Doc-Guided Sent2Sent++, an Agent that employs an\nincremental sentence-level forced decoding strategy \\textbf{to ensure every\nsentence is translated while enhancing the fluency of adjacent sentences.} Our\nAgent leverages a Doc-Guided Memory, focusing solely on the summary and its\ntranslation, which we find to be an efficient approach to maintaining\nconsistency. Through extensive testing across multiple languages and domains,\nwe demonstrate that Sent2Sent++ outperforms other methods in terms of quality,\nconsistency, and fluency. The results indicate that, our approach has achieved\nsignificant improvements in metrics such as s-COMET, d-COMET, LTCR-$1_f$, and\ndocument-level perplexity (d-ppl). The contributions of this paper include a\ndetailed analysis of current DocMT research, the introduction of the\nSent2Sent++ decoding method, the Doc-Guided Memory mechanism, and validation of\nits effectiveness across languages and domains.",
      "tldr_zh": "这篇论文针对 Document-level Machine Translation (DocMT) 的挑战，提出了一种 Doc-Guided Sent2Sent++ 代理，该代理采用增量句子级强制解码策略，确保每个句子被完整翻译并提升相邻句子的流畅性，同时利用 Doc-Guided Memory 只关注摘要及其翻译，以高效维护一致性。实验结果显示，该方法在多语言和领域测试中优于现有方法，如 Doc2Doc 和 Doc2Sent，在质量、一致性和流畅性指标（如 s-COMET、d-COMET、LTCR-$1_f$ 和 d-ppl）上实现了显著改善。论文的主要贡献包括对当前 DocMT 研究的详细分析、Sent2Sent++ 解码方法的引入，以及 Doc-Guided Memory 机制的有效性验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08523v1",
      "published_date": "2025-01-15 02:25:35 UTC",
      "updated_date": "2025-01-15 02:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:01:36.755640"
    },
    {
      "arxiv_id": "2501.08521v2",
      "title": "Mitigating Domain Shift in Federated Learning via Intra- and Inter-Domain Prototypes",
      "title_zh": "通过域内和域间原型缓解联邦学习中的领域偏移",
      "authors": [
        "Huy Q. Le",
        "Ye Lin Tun",
        "Yu Qiao",
        "Minh N. H. Nguyen",
        "Keon Oh Kim",
        "Choong Seon Hong"
      ],
      "abstract": "Federated Learning (FL) has emerged as a decentralized machine learning\ntechnique, allowing clients to train a global model collaboratively without\nsharing private data. However, most FL studies ignore the crucial challenge of\nheterogeneous domains where each client has a distinct feature distribution,\nwhich is popular in real-world scenarios. Prototype learning, which leverages\nthe mean feature vectors within the same classes, has become a prominent\nsolution for federated learning under domain shift. However, existing federated\nprototype learning methods focus soley on inter-domain prototypes and neglect\nintra-domain perspectives. In this work, we introduce a novel federated\nprototype learning method, namely I$^2$PFL, which incorporates\n$\\textbf{I}$ntra-domain and $\\textbf{I}$nter-domain $\\textbf{P}$rototypes, to\nmitigate domain shift from both perspectives and learn a generalized global\nmodel across multiple domains in federated learning. To construct intra-domain\nprototypes, we propose feature alignment with MixUp-based augmented prototypes\nto capture the diversity within local domains and enhance the generalization of\nlocal features. Additionally, we introduce a reweighting mechanism for\ninter-domain prototypes to generate generalized prototypes that reduce domain\nshift while providing inter-domain knowledge across multiple clients. Extensive\nexperiments on the Digits, Office-10, and PACS datasets illustrate the superior\nperformance of our method compared to other baselines.",
      "tldr_zh": "该论文针对 Federated Learning (FL) 中客户端异构域导致的 Domain Shift 问题，提出了一种新方法 I²PFL，通过整合 Intra-domain Prototypes 和 Inter-domain Prototypes 来缓解域移位并学习泛化全局模型。具体而言，I²PFL 使用特征对齐和 MixUp-based augmented prototypes 来捕捉本地域内的多样性，提高本地特征的泛化能力；同时，通过 Reweighting mechanism 生成泛化的 Inter-domain Prototypes，以减少域移位并共享跨客户端知识。在 Digits、Office-10 和 PACS 数据集上的广泛实验表明，I²PFL 比其他基线方法表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 11 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.08521v2",
      "published_date": "2025-01-15 02:17:38 UTC",
      "updated_date": "2025-03-10 02:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:01:48.669081"
    },
    {
      "arxiv_id": "2501.08518v1",
      "title": "Easing Seasickness through Attention Redirection with a Mindfulness-Based Brain--Computer Interface",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Bao",
        "Kailin Xu",
        "Jiawei Zhu",
        "Haiyun Huang",
        "Kangning Li",
        "Qiyun Huang",
        "Yuanqing Li"
      ],
      "abstract": "Seasickness is a prevalent issue that adversely impacts both passenger\nexperiences and the operational efficiency of maritime crews. While techniques\nthat redirect attention have proven effective in alleviating motion sickness\nsymptoms in terrestrial environments, applying similar strategies to manage\nseasickness poses unique challenges due to the prolonged and intense motion\nenvironment associated with maritime travel. In this study, we propose a\nmindfulness brain-computer interface (BCI), specifically designed to redirect\nattention with the aim of mitigating seasickness symptoms in real-world\nsettings. Our system utilizes a single-channel headband to capture prefrontal\nEEG signals, which are then wirelessly transmitted to computing devices for the\nassessment of mindfulness states. The results are transferred into real-time\nfeedback as mindfulness scores and audiovisual stimuli, facilitating a shift in\nattentional focus from physiological discomfort to mindfulness practices. A\ntotal of 43 individuals participated in a real-world maritime experiment\nconsisted of three sessions: a real-feedback mindfulness session, a resting\nsession, and a pseudofeedback mindfulness session. Notably, 81.39% of\nparticipants reported that the mindfulness BCI intervention was effective, and\nthere was a significant reduction in the severity of seasickness, as measured\nby the Misery Scale (MISC). Furthermore, EEG analysis revealed a decrease in\nthe theta/beta ratio, corresponding with the alleviation of seasickness\nsymptoms. A decrease in overall EEG band power during the real-feedback\nmindfulness session suggests that the mindfulness BCI fosters a more tranquil\nand downregulated state of brain activity. Together, this study presents a\nnovel nonpharmacological, portable, and effective approach for seasickness\nintervention, with the potential to enhance the cruising experience for both\npassengers and crews.",
      "tldr_zh": "本研究提出了一种基于正念的脑机接口(BCI)，通过注意力重定向来缓解晕船症状，该系统利用单通道头带捕获前额EEG信号，并提供实时反馈（如正念分数和视听刺激），帮助用户从生理不适转向正念练习。  \n在43名参与者的海上实验中，包括真实反馈正念会话、休息会话和伪反馈会话，结果显示81.39%的参与者认为干预有效，晕船严重程度（Misery Scale）显著降低，且EEG分析表明theta/beta比率减少，整体脑波功率降低，反映出大脑更平静的状态。  \n这项创新方法提供了一种非药物、可携带的解决方案，有潜力提升乘客和船员的海上体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "eess.SP",
        "q-bio.QM"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08518v1",
      "published_date": "2025-01-15 02:06:29 UTC",
      "updated_date": "2025-01-15 02:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:02:00.641635"
    },
    {
      "arxiv_id": "2501.08506v2",
      "title": "Exploring the Efficacy of Meta-Learning: Unveiling Superior Data Diversity Utilization of MAML Over Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Kavita Selva",
        "Satita Vittayaareekul",
        "Brando Miranda"
      ],
      "abstract": "Currently, data and model size dominate the narrative in the training of\nsuper-large, powerful models. However, there has been a lack of exploration on\nthe effect of other attributes of the training dataset on model performance. We\nhypothesize that dataset diversity can impact the performance of vision models.\nOur study shows positive correlations between test set accuracy and data\ndiversity, providing an argument for furthering the research of dataset\nattributes beyond size. We analyzed pre-training and model-agnostic\nmeta-learning methods on twelve popular visual datasets (e.g., Omniglot,\nCIFAR-FS, Aircraft) and five model configurations, including MAML variants with\ndifferent numbers of inner gradient steps and supervised learning. We show\nmoderate to strong positive correlations (R-squared: 0.15-0.42) between\naccuracy and data diversity and weaker but significant correlations (R-squared:\n~0.2) between loss and diversity. These findings support our hypothesis and\ndemonstrate a promising way for a deeper exploration of how formal data\ndiversity influences model performance. This initial study highlights the\npotential of (Task2Vec) data diversity as a valuable measure in the rapidly\nevolving field of large-scale learning and emphasizes that understanding the\ndataset is key to building more powerful and generalizable models.",
      "tldr_zh": "本研究假设数据集多样性会影响视觉模型性能，并通过分析预训练和元学习方法（如 MAML）在12个流行视觉数据集（例如 Omniglot、CIFAR-FS、Aircraft）和5个模型配置上的表现来验证这一假设。结果显示，模型准确率与数据多样性存在中等到强正相关（R-squared: 0.15-0.42），而损失与多样性有较弱但显著相关（R-squared: ~0.2）。这些发现支持了数据集属性（如 Task2Vec 多样性指标）的重要性，并强调深入理解数据集是提升模型性能和泛化能力的关键。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08506v2",
      "published_date": "2025-01-15 00:56:59 UTC",
      "updated_date": "2025-01-21 01:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:02:28.871423"
    },
    {
      "arxiv_id": "2501.08502v1",
      "title": "Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the United Kingdom",
      "title_zh": "翻译失败",
      "authors": [
        "Melissa Torgbi",
        "Andrew Clayman",
        "Jordan J. Speight",
        "Harish Tayyar Madabushi"
      ],
      "abstract": "We collect novel data in the public service domain to evaluate the capability\nof the state-of-the-art automatic speech recognition (ASR) models in capturing\nregional differences in accents in the United Kingdom (UK), specifically\nfocusing on two accents from Scotland with distinct dialects. This study\naddresses real-world problems where biased ASR models can lead to\nmiscommunication in public services, disadvantaging individuals with regional\naccents particularly those in vulnerable populations. We first examine the\nout-of-the-box performance of the Whisper large-v3 model on a baseline dataset\nand our data. We then explore the impact of fine-tuning Whisper on the\nperformance in the two UK regions and investigate the effectiveness of existing\nmodel evaluation techniques for our real-world application through manual\ninspection of model errors. We observe that the Whisper model has a higher word\nerror rate (WER) on our test datasets compared to the baseline data and\nfine-tuning on a given data improves performance on the test dataset with the\nsame domain and accent. The fine-tuned models also appear to show improved\nperformance when applied to the test data outside of the region it was trained\non suggesting that fine-tuned models may be transferable within parts of the\nUK. Our manual analysis of model outputs reveals the benefits and drawbacks of\nusing WER as an evaluation metric and fine-tuning to adapt to regional\ndialects.",
      "tldr_zh": "本研究收集了新的公共服务领域数据，以评估最先进的自动语音识别（ASR）模型（如Whisper large-v3）在捕捉英国地区口音差异的能力，特别是苏格兰的两种方言，并解决ASR模型偏差导致公共服务误传的问题，从而保护弱势群体。研究首先测试了Whisper模型在基准数据集和自有数据上的性能，发现其在测试数据集上的Word Error Rate (WER)更高。接着，通过微调Whisper模型，显著改善了特定领域和口音的性能，且微调模型显示出在英国其他地区的可转移性；手动分析进一步揭示了WER作为评估指标的优缺点，以及微调适应地区方言的潜在益处。总的来说，此工作为提升ASR模型的包容性和公共服务公平性提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08502v1",
      "published_date": "2025-01-15 00:39:21 UTC",
      "updated_date": "2025-01-15 00:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:02:40.828946"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 102,
  "processed_papers_count": 102,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T00:03:02.650352"
}