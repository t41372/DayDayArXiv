{
  "date": "2024-12-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-16 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域的创新应用，包括大型语言模型（LLM）的优化、多模态学习、强化学习以及特定领域的实际部署，令人印象深刻的是 Tuka Alhanai 等作者关于 LLM 在低资源语言中的基准工作，以及对 LLM 内部机制和多代理协作的深入探索。\n\n### 重点论文讨论\n今天共有 136 篇论文，我将优先选取那些重要、话题性和影响大的文章进行简要分析，尤其是与 LLM、强化学习和多模态相关的论文，这些领域有潜在的突破性贡献。其他较常规或应用性较弱的论文（如某些图像处理或特定任务优化）将快速掠过。\n\n#### LLM 和语言模型优化\n- **Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments**（标题：弥合差距：通过新基准、微调和文化调整提升低资源非洲语言的 LLM 性能）  \n  这篇论文由 Tuka Alhanai 等作者主导，创建了约 100 万词的基准数据集，覆盖 8 种非洲语言（如 Amharic 和 Igbo），通过微调和跨语言转移减少 LLM 在这些语言上的性能差距，主要发现包括微调带来 5.6% 的单语改进和文化调整的 3.0% 性能提升。该工作对低资源语言处理有重要启发，强调文化相关性的影响。\n\n- **SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator**（标题：SepLLM：通过将一个段压缩到一个分隔符加速大型语言模型）  \n  论文提出了一种插件式框架，通过压缩段落并消除冗余 token 来加速 LLM 推理，主要贡献是减少 KV 缓存 50% 以上，同时保持性能。该方法在 GSM8K 等基准上表现出色，适合资源受限的实际部署。\n\n- **Emergence of Abstractions: Concept Encoding and Decoding Mechanism for In-Context Learning in Transformers**（标题：抽象的涌现：Transformer 中 In-Context Learning 的概念编码和解码机制）  \n  作者研究了 Transformer 如何通过概念编码-解码机制学习抽象表示，主要发现是模型在合成任务中自发形成可分离的潜在概念（如“Finding the first noun”），并在 Gemma 和 Llama 模型上验证了其因果关系。该工作揭示了 LLM 在上下文学习中的内部机制，提供对模型鲁棒性的新洞见。\n\n- **Improving Cooperation in Language Games with Bayesian Inference and the Cognitive Hierarchy**（标题：通过贝叶斯推理和认知层次提升语言游戏中的合作）  \n  这篇论文探索了代理在语言游戏中的合作，使用贝叶斯推理和认知层次建模语义和语用不确定性，主要贡献是提升代理在 Codenames 游戏中的性能，平均改进 5%，强调不确定性建模对多代理系统的实际意义。\n\n- **How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games**（标题：不同 AI 聊天机器人如何行为？在行为经济学游戏中对大型语言模型的基准测试）  \n  作者对五种 LLM（如 GPT 系列）在行为经济学游戏中的决策进行基准测试，主要发现是这些模型展示了独特的策略偏好（如风险厌恶），为 LLM 在决策角色中的部署提供洞见。\n\n#### 多模态和图神经网络应用\n- **Gramian Multimodal Representation Learning and Alignment**（标题：Gramian 多模态表示学习和对齐）  \n  论文提出 Gramian 表示学习方法，用于多模态（如视频-音频-文本）任务，主要贡献是通过最小化 Gramian 体积实现多模态对齐，提升视频检索和分类性能。该方法在多模态基准上超越现有技术，展示了高效的多模态融合潜力。\n\n- **DeepSN: A Sheaf Neural Framework for Influence Maximization**（标题：DeepSN：用于影响最大化的 Sheaf 神经框架）  \n  这篇论文针对影响最大化问题，引入 Sheaf 神经网络学习扩散模式，主要发现是通过数据驱动的方法捕获复杂影响动态，并在真实数据集上提升了种子集选择效率。该工作扩展了图神经网络（GNNs）的应用，适用于社交网络分析。\n\n#### 强化学习和机器人\n- **MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization**（标题：MaxInfoRL：通过信息增益最大化提升强化学习的探索）  \n  作者提出 MaxInfoRL 框架，通过最大化信息增益增强 RL 探索，主要贡献是结合 Boltzmann 探索实现子线性遗憾，并在连续控制任务中超越基线，适用于高维探索场景。\n\n- **Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation**（标题：在可微多物理模拟中稳定强化学习）  \n  论文引入 SAPO 算法，用于可微模拟中的 RL，主要发现是提升了机器人任务的稳定性和性能。该方法在 Rewarped 平台上验证，适用于刚性和可变形物体交互。\n\n其他论文，如那些专注于特定图像生成、音频分类或交通系统的 AI 应用（如 \"AgroXAI\" 和 \"Artificial Intelligence in Traffic Systems\"），虽然有实际价值，但相对常规，我将快速掠过：它们主要贡献于领域特定优化，例如 AgroXAI 在农业中用 XAI 推荐作物，或交通 AI 改善路由决策，但未带来根本性突破。\n\n总之，今天的论文展示了 AI 领域的多样性与深度，LLM 相关工作尤其值得关注，未来可能推动低资源语言处理和多代理协作的进展。如果你对 LLM 在实际应用中的优化感兴趣，这些论文是很好的起点！",
  "papers": [
    {
      "arxiv_id": "2412.12417v1",
      "title": "Bridging the Gap: Enhancing LLM Performance for Low-Resource African Languages with New Benchmarks, Fine-Tuning, and Cultural Adjustments",
      "title_zh": "翻译失败",
      "authors": [
        "Tuka Alhanai",
        "Adam Kasumovic",
        "Mohammad Ghassemi",
        "Aven Zitzelberger",
        "Jessica Lundin",
        "Guillaume Chabot-Couture"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable performance across various\ntasks, yet significant disparities remain for non-English languages, and\nespecially native African languages. This paper addresses these disparities by\ncreating approximately 1 million human-translated words of new benchmark data\nin 8 low-resource African languages, covering a population of over 160 million\nspeakers of: Amharic, Bambara, Igbo, Sepedi (Northern Sotho), Shona, Sesotho\n(Southern Sotho), Setswana, and Tsonga. Our benchmarks are translations of\nWinogrande and three sections of MMLU: college medicine, clinical knowledge,\nand virology. Using the translated benchmarks, we report previously unknown\nperformance gaps between state-of-the-art (SOTA) LLMs in English and African\nlanguages. Finally, using results from over 400 fine-tuned models, we explore\nseveral methods to reduce the LLM performance gap, including high-quality\ndataset fine-tuning (using an LLM-as-an-Annotator), cross-lingual transfer, and\ncultural appropriateness adjustments. Key findings include average mono-lingual\nimprovements of 5.6% with fine-tuning (with 5.4% average mono-lingual\nimprovements when using high-quality data over low-quality data), 2.9% average\ngains from cross-lingual transfer, and a 3.0% out-of-the-box performance boost\non culturally appropriate questions. The publicly available benchmarks,\ntranslations, and code from this study support further research and development\naimed at creating more inclusive and effective language technologies.",
      "tldr_zh": "本论文揭示了大型语言模型（LLM）在低资源非洲语言上的性能差距，并通过创建约100万字的新基准数据来桥接这一鸿沟，该数据翻译自Winogrande和MMLU的部分（包括大学医学、临床知识和病毒学），覆盖Amharic、Bambara、Igbo、Sepedi、Shona、Sesotho、Setswana和Tsonga等8种语言，涉及1.6亿人口。研究报告了SOTA LLM在英语与这些非洲语言间的未知性能差距，并探索了减少差距的方法，如高质量数据集微调（使用LLM-as-an-Annotator）、跨语言转移和文化适应调整。关键发现包括微调带来的平均5.6%单语改进（高质量数据较低质量数据多5.4%）、跨语言转移的2.9%平均增益，以及文化适当问题上的3.0%性能提升；最终，论文公开了这些基准、翻译和代码，以推动更具包容性的语言技术发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to AAAI 2025. Main content is 9 pages, 3 figures. Includes\n  supplementary materials",
      "pdf_url": "http://arxiv.org/pdf/2412.12417v1",
      "published_date": "2024-12-16 23:50:21 UTC",
      "updated_date": "2024-12-16 23:50:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:09:35.616222"
    },
    {
      "arxiv_id": "2412.12416v1",
      "title": "DeepSN: A Sheaf Neural Framework for Influence Maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Asela Hevapathige",
        "Qing Wang",
        "Ahad N. Zehmakan"
      ],
      "abstract": "Influence maximization is key topic in data mining, with broad applications\nin social network analysis and viral marketing. In recent years, researchers\nhave increasingly turned to machine learning techniques to address this\nproblem. They have developed methods to learn the underlying diffusion\nprocesses in a data-driven manner, which enhances the generalizability of the\nsolution, and have designed optimization objectives to identify the optimal\nseed set. Nonetheless, two fundamental gaps remain unsolved: (1) Graph Neural\nNetworks (GNNs) are increasingly used to learn diffusion models, but in their\ntraditional form, they often fail to capture the complex dynamics of influence\ndiffusion, (2) Designing optimization objectives is challenging due to\ncombinatorial explosion when solving this problem. To address these challenges,\nwe propose a novel framework, DeepSN. Our framework employs sheaf neural\ndiffusion to learn diverse influence patterns in a data-driven, end-to-end\nmanner, providing enhanced separability in capturing diffusion characteristics.\nWe also propose an optimization technique that accounts for overlapping\ninfluence between vertices, which helps to reduce the search space and identify\nthe optimal seed set effectively and efficiently. Finally, we conduct extensive\nexperiments on both synthetic and real-world datasets to demonstrate the\neffectiveness of our framework.",
      "tldr_zh": "该论文针对影响最大化（Influence Maximization）问题，提出了一种新型框架DeepSN，以解决Graph Neural Networks (GNNs)无法有效捕捉影响扩散复杂动态以及优化目标设计面临的组合爆炸挑战。DeepSN采用sheaf neural diffusion技术，通过数据驱动的端到端方法学习多样化的影响模式，提高扩散特征的可分性。同时，该框架引入一种优化技术，考虑顶点间的重叠影响，减少搜索空间并高效识别最优种子集。在合成和真实数据集上的广泛实验证明，DeepSN框架在社交网络分析和病毒营销应用中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12416v1",
      "published_date": "2024-12-16 23:49:51 UTC",
      "updated_date": "2024-12-16 23:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:09:46.630926"
    },
    {
      "arxiv_id": "2412.12409v1",
      "title": "Improving Cooperation in Language Games with Bayesian Inference and the Cognitive Hierarchy",
      "title_zh": "通过贝叶斯推理和认知层次改进语言游戏中的合作",
      "authors": [
        "Joseph Bills",
        "Christopher Archibald",
        "Diego Blaylock"
      ],
      "abstract": "In two-player cooperative games, agents can play together effectively when\nthey have accurate assumptions about how their teammate will behave, but may\nperform poorly when these assumptions are inaccurate. In language games,\nfailure may be due to disagreement in the understanding of either the semantics\nor pragmatics of an utterance. We model coarse uncertainty in semantics using a\nprior distribution of language models and uncertainty in pragmatics using the\ncognitive hierarchy, combining the two aspects into a single prior distribution\nover possible partner types. Fine-grained uncertainty in semantics is modeled\nusing noise that is added to the embeddings of words in the language. To handle\nall forms of uncertainty we construct agents that learn the behavior of their\npartner using Bayesian inference and use this information to maximize the\nexpected value of a heuristic function. We test this approach by constructing\nBayesian agents for the game of Codenames, and show that they perform better in\nexperiments where semantics is uncertain",
      "tldr_zh": "这篇论文旨在通过Bayesian Inference和Cognitive Hierarchy改善两人合作语言游戏中的代理合作问题，特别是处理语义和语义学（pragmatics）理解的分歧。研究者使用先验分布建模语义不确定性，并结合认知层次构建一个统一的伙伴类型分布，同时通过添加噪声到词嵌入处理细粒度语义不确定性。代理通过Bayesian Inference学习队友行为并优化启发式函数的预期价值；在Codenames游戏的实验中，这些Bayesian代理在语义不确定场景下表现出更好的性能。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "Full version of AAAI-25 paper",
      "pdf_url": "http://arxiv.org/pdf/2412.12409v1",
      "published_date": "2024-12-16 23:24:12 UTC",
      "updated_date": "2024-12-16 23:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:09:58.842887"
    },
    {
      "arxiv_id": "2412.12408v1",
      "title": "Automated Generation of Massive Reasonable Empirical Theorems by Forward Reasoning Based on Strong Relevant Logics -- A Solution to the Problem of LLM Pre-training Data Exhaustion",
      "title_zh": "翻译失败",
      "authors": [
        "Jingde Cheng"
      ],
      "abstract": "Recently, it is often said that the data used for the pre-training of large\nlanguage models (LLMs) have been exhausted. This paper proposes a solution to\nthe problem: Automated generation of massive reasonable empirical theorems by\nforward reasoning based on strong relevant logics. In fact, this can be\nregarded as a part of our approach to the problems of ATF (Automated Theorem\nFinding) and AKA (Automated Knowledge Appreciation).",
      "tldr_zh": "该论文针对大型语言模型（LLMs）预训练数据耗尽的问题，提出了一种解决方案：通过基于强相关逻辑（Strong Relevant Logics）的前向推理（Forward Reasoning）自动生成大量合理的经验定理（Reasonable Empirical Theorems）。这种方法利用逻辑推理来创建新数据，从而缓解数据短缺的挑战，并作为 Automated Theorem Finding (ATF) 和 Automated Knowledge Appreciation (AKA) 框架的一部分。实验结果未详细说明，但该方法有望为LLMs的持续训练提供可扩展的知识来源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12408v1",
      "published_date": "2024-12-16 23:18:17 UTC",
      "updated_date": "2024-12-16 23:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:10:09.313788"
    },
    {
      "arxiv_id": "2412.12395v1",
      "title": "Sound Classification of Four Insect Classes",
      "title_zh": "翻译失败",
      "authors": [
        "Yinxuan Wang",
        "Sudip Vhaduri"
      ],
      "abstract": "The goal of this project is to classify four different insect sounds: cicada,\nbeetle, termite, and cricket. One application of this project is for pest\ncontrol to monitor and protect our ecosystem. Our project leverages data\naugmentation, including pitch shifting and speed changing, to improve model\ngeneralization. This project will test the performance of Decision Tree, Random\nForest, SVM RBF, XGBoost, and k-NN models, combined with MFCC feature. A\npotential novelty of this project is that various data augmentation techniques\nare used and created 6 data along with the original sound. The dataset consists\nof the sound recordings of these four insects. This project aims to achieve a\nhigh classification accuracy and to reduce the over-fitting problem.",
      "tldr_zh": "本文的目标是分类四种昆虫声音：cicada、beetle、termite 和 cricket，以应用于害虫控制和生态监测。研究采用数据增强技术（如 pitch shifting 和 speed changing）结合 MFCC feature，测试 Decision Tree、Random Forest、SVM RBF、XGBoost 和 k-NN 模型，以提升模型泛化能力并减少过拟合问题。该项目创新性地创建了6种增强数据，加上原始数据集，旨在实现高分类准确率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "The manuscript is in submission",
      "pdf_url": "http://arxiv.org/pdf/2412.12395v1",
      "published_date": "2024-12-16 23:03:28 UTC",
      "updated_date": "2024-12-16 23:03:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:10:22.544779"
    },
    {
      "arxiv_id": "2412.12385v1",
      "title": "Enhancing Temporal Link Prediction with HierTKG: A Hierarchical Temporal Knowledge Graph Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Mariam Almutairi",
        "Melike Yildiz Aktas",
        "Nawar Wali",
        "Shutonu Mitra",
        "Dawei Zhou"
      ],
      "abstract": "The rapid spread of misinformation on social media, especially during crises,\nchallenges public decision-making. To address this, we propose HierTKG, a\nframework combining Temporal Graph Networks (TGN) and hierarchical pooling\n(DiffPool) to model rumor dynamics across temporal and structural scales.\nHierTKG captures key propagation phases, enabling improved temporal link\nprediction and actionable insights for misinformation control. Experiments\ndemonstrate its effectiveness, achieving an MRR of 0.9845 on ICEWS14 and 0.9312\non WikiData, with competitive performance on noisy datasets like PHEME (MRR:\n0.8802). By modeling structured event sequences and dynamic social\ninteractions, HierTKG adapts to diverse propagation patterns, offering a\nscalable and robust solution for real-time analysis and prediction of rumor\nspread, aiding proactive intervention strategies.",
      "tldr_zh": "这篇论文提出 HierTKG 框架，通过结合 Temporal Graph Networks (TGN) 和 hierarchical pooling (DiffPool)，来增强 Temporal Link Prediction，并模型谣言动态在时间和结构尺度上的传播。框架捕捉关键传播阶段，提供可操作洞见以控制 misinformation。实验结果显示，HierTKG 在 ICEWS14 上达到 MRR 0.9845、在 WikiData 上为 0.9312，以及在 PHEME 上为 0.8802，证明其在噪声数据集上的鲁棒性和可扩展性，为实时分析、预测谣言传播和主动干预策略提供了有效解决方案。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2412.12385v1",
      "published_date": "2024-12-16 22:43:41 UTC",
      "updated_date": "2024-12-16 22:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:10:34.195583"
    },
    {
      "arxiv_id": "2412.14205v1",
      "title": "Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Rosenberg",
        "Hans Schumann",
        "Christopher Dishop",
        "Gregg Willcox",
        "Anita Woolley",
        "Ganesh Mani"
      ],
      "abstract": "Conversational Swarm Intelligence (CSI) is an AI-facilitated method for\nenabling real-time conversational deliberations and prioritizations among\nnetworked human groups of potentially unlimited size. Based on the biological\nprinciple of Swarm Intelligence and modelled on the decision-making dynamics of\nfish schools, CSI has been shown in prior studies to amplify group\nintelligence, increase group participation, and facilitate productive\ncollaboration among hundreds of participants at once. It works by dividing a\nlarge population into a set of small subgroups that are woven together by\nreal-time AI agents called Conversational Surrogates. The present study focuses\non the use of a CSI platform called Thinkscape to enable real-time\nbrainstorming and prioritization among groups of 75 networked users. The study\nemployed a variant of a common brainstorming intervention called an Alternative\nUse Task (AUT) and was designed to compare through subjective feedback, the\nexperience of participants brainstorming using a CSI structure vs brainstorming\nin a single large chat room. This comparison revealed that participants\nsignificantly preferred brainstorming with the CSI structure and reported that\nit felt (i) more collaborative, (ii) more productive, and (iii) was better at\nsurfacing quality answers. In addition, participants using the CSI structure\nreported (iv) feeling more ownership and more buy-in in the final answers the\ngroup converged on and (v) reported feeling more heard as compared to\nbrainstorming in a traditional text chat environment. Overall, the results\nsuggest that CSI is a very promising AI-facilitated method for brainstorming\nand prioritization among large-scale, networked human groups.",
      "tldr_zh": "本研究比较了基于 Conversational Swarm Intelligence (CSI) 与传统聊天在大型群体脑暴中的效果，CSI 是一种受 Swarm Intelligence 启发的 AI 辅助方法，能将大群体分成小子群并通过 Conversational Surrogates 实时连接，促进协作。实验使用 Thinkscape 平台和 Alternative Use Task (AUT) 进行75名用户的脑暴测试，结果显示参与者更倾向于 CSI 结构，认为它更具协作性、生产力和高质量答案输出，并增加了对最终结果的归属感与被倾听感。总体而言，CSI 被证明是大规模网络化群体脑暴和优先级排序的极具潜力的方法。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI",
        "I.2.11"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14205v1",
      "published_date": "2024-12-16 22:11:25 UTC",
      "updated_date": "2024-12-16 22:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:10:46.987440"
    },
    {
      "arxiv_id": "2412.12370v5",
      "title": "Scam Detection for Ethereum Smart Contracts: Leveraging Graph Representation Learning for Secure Blockchain",
      "title_zh": "针对以太坊智能合约的诈骗检测：利用图表示学习实现安全的区块链",
      "authors": [
        "Yihong Jin",
        "Ze Yang",
        "Xinhe Xu"
      ],
      "abstract": "As more and more attacks have been detected on Ethereum smart contracts, it\nhas seriously affected finance and credibility. Current anti-fraud detection\ntechniques, including code parsing or manual feature extraction, still have\nsome shortcomings, although some generalization or adaptability can be\nobtained. In the face of this situation, this paper proposes to use graphical\nrepresentation learning technology to find transaction patterns and distinguish\nmalicious transaction contracts, that is, to represent Ethereum transaction\ndata as graphs, and then use advanced ML technology to obtain reliable and\naccurate results. Taking into account the sample imbalance, we treated with\nSMOTE-ENN and tested several models, in which MLP performed better than GCN,\nbut the exact effect depends on its field trials. Our research opens up more\npossibilities for trust and security in the Ethereum ecosystem.",
      "tldr_zh": "该研究针对 Ethereum 智能合约的欺诈检测问题，提出了一种基于 Graph Representation Learning 的方法，将交易数据表示为图结构，以发现恶意交易模式并提升检测准确性。为处理样本不平衡，论文采用了 SMOTE-ENN 技术，并测试了多个模型，其中 MLP 比 GCN 表现更好。实验结果表明，该方法为 Ethereum 生态系统的安全和信任提供了可靠的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "cs.SI",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ISCAIT 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12370v5",
      "published_date": "2024-12-16 21:56:01 UTC",
      "updated_date": "2025-03-19 05:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:10:58.704601"
    },
    {
      "arxiv_id": "2412.12364v1",
      "title": "LogBabylon: A Unified Framework for Cross-Log File Integration and Analysis",
      "title_zh": "LogBabylon：跨日志文件整合和分析的统一框架",
      "authors": [
        "Rabimba Karanjai",
        "Yang Lu",
        "Dana Alsagheer",
        "Keshav Kasichainula",
        "Lei Xu",
        "Weidong Shi",
        "Shou-Hsuan Stephen Huang"
      ],
      "abstract": "Logs are critical resources that record events, activities, or messages\nproduced by software applications, operating systems, servers, and network\ndevices. However, consolidating the heterogeneous logs and cross-referencing\nthem is challenging and complicated. Manually analyzing the log data is\ntime-consuming and prone to errors. LogBabylon is a centralized log data\nconsolidating solution that leverages Large Language Models (LLMs) integrated\nwith Retrieval-Augmented Generation (RAG) technology. LogBabylon interprets the\nlog data in a human-readable way and adds insight analysis of the system\nperformance and anomaly alerts. It provides a paramount view of the system\nlandscape, enabling proactive management and rapid incident response.\nLogBabylon consolidates diverse log sources and enhances the extracted\ninformation's accuracy and relevancy. This facilitates a deeper understanding\nof log data, supporting more effective decision-making and operational\nefficiency. Furthermore, LogBabylon streamlines the log analysis process,\nsignificantly reducing the time and effort required to interpret complex\ndatasets. Its capabilities extend to generating context-aware insights,\noffering an invaluable tool for continuous monitoring, performance\noptimization, and security assurance in dynamic computing environments.",
      "tldr_zh": "LogBabylon 提出了一种统一的框架，用于整合和分析异构日志文件，解决手动分析耗时且易出错的问题。框架整合 Large Language Models (LLMs) 和 Retrieval-Augmented Generation (RAG) 技术，将日志数据转化为易读形式，并提供系统性能洞察、异常警报和上下文感知分析。实验结果显示，它提升了信息的准确性和相关性，简化了分析过程，支持更有效的决策、主动管理和快速响应，从而优化动态计算环境的监控与安全。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12364v1",
      "published_date": "2024-12-16 21:36:03 UTC",
      "updated_date": "2024-12-16 21:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:11:10.317688"
    },
    {
      "arxiv_id": "2412.12362v1",
      "title": "How Different AI Chatbots Behave? Benchmarking Large Language Models in Behavioral Economics Games",
      "title_zh": "不同 AI 聊天机器人如何表现？在行为经济学游戏中对大型语言模型进行基准测试",
      "authors": [
        "Yutong Xie",
        "Yiyao Liu",
        "Zhuang Ma",
        "Lin Shi",
        "Xiyuan Wang",
        "Walter Yuan",
        "Matthew O. Jackson",
        "Qiaozhu Mei"
      ],
      "abstract": "The deployment of large language models (LLMs) in diverse applications\nrequires a thorough understanding of their decision-making strategies and\nbehavioral patterns. As a supplement to a recent study on the behavioral Turing\ntest, this paper presents a comprehensive analysis of five leading LLM-based\nchatbot families as they navigate a series of behavioral economics games. By\nbenchmarking these AI chatbots, we aim to uncover and document both common and\ndistinct behavioral patterns across a range of scenarios. The findings provide\nvaluable insights into the strategic preferences of each LLM, highlighting\npotential implications for their deployment in critical decision-making roles.",
      "tldr_zh": "这篇论文通过基准测试五种领先的 Large Language Models (LLMs) 聊天机器人家族在行为经济学游戏中的表现，补充了行为图灵测试的研究，旨在揭示这些 AI 的决策策略和行为模式。研究分析了不同场景下的共同和独特行为特征，突出了每个 LLM 的战略偏好。结果为 LLM 在关键决策角色中的部署提供了宝贵的洞见，帮助评估其潜在风险和应用价值。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at The First Workshop on AI Behavioral Science (AIBS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.12362v1",
      "published_date": "2024-12-16 21:25:45 UTC",
      "updated_date": "2024-12-16 21:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:11:22.084643"
    },
    {
      "arxiv_id": "2412.12361v2",
      "title": "The Ramanujan Library -- Automated Discovery on the Hypergraph of Integer Relations",
      "title_zh": "翻译失败",
      "authors": [
        "Itay Beit-Halachmi",
        "Ido Kaminer"
      ],
      "abstract": "Fundamental mathematical constants appear in nearly every field of science,\nfrom physics to biology. Formulas that connect different constants often bring\ngreat insight by hinting at connections between previously disparate fields.\nDiscoveries of such relations, however, have remained scarce events, relying on\nsporadic strokes of creativity by human mathematicians. Recent developments of\nalgorithms for automated conjecture generation have accelerated the discovery\nof formulas for specific constants. Yet, the discovery of connections between\nconstants has not been addressed. In this paper, we present the first library\ndedicated to mathematical constants and their interrelations. This library can\nserve as a central repository of knowledge for scientists from different areas,\nand as a collaborative platform for development of new algorithms. The library\nis based on a new representation that we propose for organizing the formulas of\nmathematical constants: a hypergraph, with each node representing a constant\nand each edge representing a formula. Using this representation, we propose and\ndemonstrate a systematic approach for automatically enriching this library\nusing PSLQ, an integer relation algorithm based on QR decomposition and lattice\nconstruction. During its development and testing, our strategy led to the\ndiscovery of 75 previously unknown connections between constants, including a\nnew formula for the `first continued fraction' constant $C_1$, novel formulas\nfor natural logarithms, and new formulas connecting $\\pi$ and $e$. The latter\nformulas generalize a century-old relation between $\\pi$ and $e$ by Ramanujan,\nwhich until now was considered a singular formula and is now found to be part\nof a broader mathematical structure. The code supporting this library is a\npublic, open-source API that can serve researchers in experimental mathematics\nand other fields of science.",
      "tldr_zh": "这篇论文介绍了 Ramanujan Library，这是一个基于 hypergraph 表示的数学常数关系库，用于系统地发现整数关系。作者提出使用 PSLQ 算法（基于 QR 分解和格子构造）自动丰富库的内容，在开发过程中发现了 75 个之前未知的连接，包括新的公式如第一个连分数常数 $C_1$ 的公式、自然对数的公式，以及扩展 Ramanujan 百年关系的 $\\pi$ 和 $e$ 连接公式。该库作为开源 API，提供了一个协作平台，促进实验数学和其他科学领域的知识共享和算法开发。",
      "categories": [
        "cs.AI",
        "cs.MS",
        "math.NT"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12361v2",
      "published_date": "2024-12-16 21:18:44 UTC",
      "updated_date": "2025-01-19 10:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:11:34.350723"
    },
    {
      "arxiv_id": "2412.12358v1",
      "title": "BioRAGent: A Retrieval-Augmented Generation System for Showcasing Generative Query Expansion and Domain-Specific Search for Scientific Q&A",
      "title_zh": "翻译失败",
      "authors": [
        "Samy Ateia",
        "Udo Kruschwitz"
      ],
      "abstract": "We present BioRAGent, an interactive web-based retrieval-augmented generation\n(RAG) system for biomedical question answering. The system uses large language\nmodels (LLMs) for query expansion, snippet extraction, and answer generation\nwhile maintaining transparency through citation links to the source documents\nand displaying generated queries for further editing. Building on our\nsuccessful participation in the BioASQ 2024 challenge, we demonstrate how\nfew-shot learning with LLMs can be effectively applied for a professional\nsearch setting. The system supports both direct short paragraph style responses\nand responses with inline citations. Our demo is available online, and the\nsource code is publicly accessible through GitHub.",
      "tldr_zh": "该研究介绍了BioRAGent，一种交互式Retrieval-Augmented Generation (RAG)系统，针对生物医学问答领域，通过Large Language Models (LLMs)实现查询扩展、snippet extraction和答案生成，同时通过源文档引用链接和查询编辑功能确保透明性。系统利用Few-Shot Learning在专业搜索环境中表现出色，基于BioASQ 2024挑战的成功经验，支持短段式响应和内联引用格式。BioRAGent的在线演示和GitHub开源代码使其易于访问和扩展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Version as accepted at the Demo Track at ECIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.12358v1",
      "published_date": "2024-12-16 21:09:28 UTC",
      "updated_date": "2024-12-16 21:09:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:11:46.391958"
    },
    {
      "arxiv_id": "2501.01432v1",
      "title": "Survey on safe robot control via learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bassel El Mabsout"
      ],
      "abstract": "Control systems are critical to modern technological infrastructure, spanning\nindustries from aerospace to healthcare. This survey explores the landscape of\nsafe robot learning, investigating methods that balance high-performance\ncontrol with rigorous safety constraints. By examining classical control\ntechniques, learning-based approaches, and embedded system design, the research\nseeks to understand how robotic systems can be developed to prevent hazardous\nstates while maintaining optimal performance across complex operational\nenvironments.",
      "tldr_zh": "这篇调查论文探讨了通过学习实现安全机器人控制的领域，旨在平衡高性能控制与严格的安全约束。论文审查了经典控制技术（classical control techniques）、基于学习的途径（learning-based approaches）以及嵌入式系统设计（embedded system design），以理解如何在复杂环境中开发机器人系统。最终目标是防止危险状态（hazardous states）发生，同时维持最佳性能，为机器人应用提供全面的指导框架。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01432v1",
      "published_date": "2024-12-16 21:04:09 UTC",
      "updated_date": "2024-12-16 21:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:11:57.282209"
    },
    {
      "arxiv_id": "2412.15262v1",
      "title": "Advanced ingestion process powered by LLM parsing for RAG system",
      "title_zh": "翻译失败",
      "authors": [
        "Arnau Perez",
        "Xavier Vizcaino"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) systems struggle with processing\nmultimodal documents of varying structural complexity. This paper introduces a\nnovel multi-strategy parsing approach using LLM-powered OCR to extract content\nfrom diverse document types, including presentations and high text density\nfiles both scanned or not. The methodology employs a node-based extraction\ntechnique that creates relationships between different information types and\ngenerates context-aware metadata. By implementing a Multimodal Assembler Agent\nand a flexible embedding strategy, the system enhances document comprehension\nand retrieval capabilities. Experimental evaluations across multiple knowledge\nbases demonstrate the approach's effectiveness, showing improvements in answer\nrelevancy and information faithfulness.",
      "tldr_zh": "这篇论文针对 Retrieval Augmented Generation (RAG) 系统处理多模态文档（如演示文稿和高密度文本文件）的结构复杂性问题，提出了一种新型多策略解析方法，利用 LLM-powered OCR 提取内容。方法包括基于节点的提取技术，以创建信息类型间的关系并生成上下文感知元数据，同时整合 Multimodal Assembler Agent 和灵活的 embedding 策略，提升文档理解和检索能力。实验评估在多个知识库上证明了该方法的有效性，显著提高了答案的相关性和信息忠实度。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.15262v1",
      "published_date": "2024-12-16 20:33:33 UTC",
      "updated_date": "2024-12-16 20:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:12:10.988624"
    },
    {
      "arxiv_id": "2412.16196v1",
      "title": "AgroXAI: Explainable AI-Driven Crop Recommendation System for Agriculture 4.0",
      "title_zh": "翻译失败",
      "authors": [
        "Ozlem Turgut",
        "Ibrahim Kok",
        "Suat Ozdemir"
      ],
      "abstract": "Today, crop diversification in agriculture is a critical issue to meet the\nincreasing demand for food and improve food safety and quality. This issue is\nconsidered to be the most important challenge for the next generation of\nagriculture due to the diminishing natural resources, the limited arable land,\nand unpredictable climatic conditions caused by climate change. In this paper,\nwe employ emerging technologies such as the Internet of Things (IoT), machine\nlearning (ML), and explainable artificial intelligence (XAI) to improve\noperational efficiency and productivity in the agricultural sector.\nSpecifically, we propose an edge computing-based explainable crop\nrecommendation system, AgroXAI, which suggests suitable crops for a region\nbased on weather and soil conditions. In this system, we provide local and\nglobal explanations of ML model decisions with methods such as ELI5, LIME,\nSHAP, which we integrate into ML models. More importantly, we provide regional\nalternative crop recommendations with the counterfactual explainability method.\nIn this way, we envision that our proposed AgroXAI system will be a platform\nthat provides regional crop diversity in the next generation agriculture.",
      "tldr_zh": "本研究针对农业作物多样化问题（如食物需求增加、自然资源减少和气候变化），提出AgroXAI系统，这是一个基于边缘计算的解释性AI驱动作物推荐系统。AgroXAI利用IoT、ML和XAI技术，根据天气和土壤条件推荐适合的作物，同时通过ELI5、LIME和SHAP方法提供局部和全局解释。系统还采用反事实解释方法给出区域替代作物推荐，从而提升农业4.0的生产力和作物多样化潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 2024 IEEE International Conference on Big Data (IEEE\n  BigData), 10 pages, 9 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.16196v1",
      "published_date": "2024-12-16 20:18:10 UTC",
      "updated_date": "2024-12-16 20:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:12:22.102939"
    },
    {
      "arxiv_id": "2412.19823v1",
      "title": "A Survey on Large Language Models for Communication, Network, and Service Management: Application Insights, Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Gordon Owusu Boateng",
        "Hani Sami",
        "Ahmed Alagha",
        "Hanae Elmekki",
        "Ahmad Hammoud",
        "Rabeb Mizouni",
        "Azzam Mourad",
        "Hadi Otrok",
        "Jamal Bentahar",
        "Sami Muhaidat",
        "Chamseddine Talhi",
        "Zbigniew Dziong",
        "Mohsen Guizani"
      ],
      "abstract": "The rapid evolution of communication networks in recent decades has\nintensified the need for advanced Network and Service Management (NSM)\nstrategies to address the growing demands for efficiency, scalability, enhanced\nperformance, and reliability of these networks. Large Language Models (LLMs)\nhave received tremendous attention due to their unparalleled capabilities in\nvarious Natural Language Processing (NLP) tasks and generating context-aware\ninsights, offering transformative potential for automating diverse\ncommunication NSM tasks. Contrasting existing surveys that consider a single\nnetwork domain, this survey investigates the integration of LLMs across\ndifferent communication network domains, including mobile networks and related\ntechnologies, vehicular networks, cloud-based networks, and fog/edge-based\nnetworks. First, the survey provides foundational knowledge of LLMs, explicitly\ndetailing the generic transformer architecture, general-purpose and\ndomain-specific LLMs, LLM model pre-training and fine-tuning, and their\nrelation to communication NSM. Under a novel taxonomy of network monitoring and\nreporting, AI-powered network planning, network deployment and distribution,\nand continuous network support, we extensively categorize LLM applications for\nNSM tasks in each of the different network domains, exploring existing\nliterature and their contributions thus far. Then, we identify existing\nchallenges and open issues, as well as future research directions for\nLLM-driven communication NSM, emphasizing the need for scalable, adaptable, and\nresource-efficient solutions that align with the dynamic landscape of\ncommunication networks. We envision that this survey serves as a holistic\nroadmap, providing critical insights for leveraging LLMs to enhance NSM.",
      "tldr_zh": "这篇调查探讨了Large Language Models (LLMs) 在通信、网络和服务管理 (NSM) 领域的应用，强调其在自动化任务中的潜力，如网络监控、规划和支持。论文基于一个新颖的分类体系，涵盖多个网络领域包括移动网络、车联网、云网络和雾/边网络，系统总结了现有文献中的LLMs 应用，包括 transformer 架构、预训练和微调技术。调查还指出了当前挑战，如可扩展性和资源效率问题，并提出了未来研究方向，以推动LLMs 在动态通信网络中的高效整合。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19823v1",
      "published_date": "2024-12-16 20:01:36 UTC",
      "updated_date": "2024-12-16 20:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:12:34.294144"
    },
    {
      "arxiv_id": "2412.12326v1",
      "title": "Achieving Collective Welfare in Multi-Agent Reinforcement Learning via Suggestion Sharing",
      "title_zh": "通过建议共享在多智能体强化学习中实现集体福利",
      "authors": [
        "Yue Jin",
        "Shuangqing Wei",
        "Giovanni Montana"
      ],
      "abstract": "In human society, the conflict between self-interest and collective\nwell-being often obstructs efforts to achieve shared welfare. Related concepts\nlike the Tragedy of the Commons and Social Dilemmas frequently manifest in our\ndaily lives. As artificial agents increasingly serve as autonomous proxies for\nhumans, we propose using multi-agent reinforcement learning (MARL) to address\nthis issue - learning policies to maximise collective returns even when\nindividual agents' interests conflict with the collective one. Traditional MARL\nsolutions involve sharing rewards, values, and policies or designing intrinsic\nrewards to encourage agents to learn collectively optimal policies. We\nintroduce a novel MARL approach based on Suggestion Sharing (SS), where agents\nexchange only action suggestions. This method enables effective cooperation\nwithout the need to design intrinsic rewards, achieving strong performance\nwhile revealing less private information compared to sharing rewards, values,\nor policies. Our theoretical analysis establishes a bound on the discrepancy\nbetween collective and individual objectives, demonstrating how sharing\nsuggestions can align agents' behaviours with the collective objective.\nExperimental results demonstrate that SS performs competitively with baselines\nthat rely on value or policy sharing or intrinsic rewards.",
      "tldr_zh": "本研究探讨了多智能体强化学习(MARL)中代理的自私行为与集体福利之间的冲突，旨在通过一种新颖的建议共享(Suggestion Sharing, SS)方法来实现集体最优策略。SS 允许代理仅交换行动建议，而非共享奖励、值或策略，从而避免了设计内在奖励的需要，并减少了私人信息的泄露。理论分析证明了 SS 如何桥接个体与集体目标的差距，实验结果显示其性能与依赖值共享、策略共享或内在奖励的基线方法相当。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12326v1",
      "published_date": "2024-12-16 19:44:44 UTC",
      "updated_date": "2024-12-16 19:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:12:45.987196"
    },
    {
      "arxiv_id": "2412.12322v1",
      "title": "RAG Playground: A Framework for Systematic Evaluation of Retrieval Strategies and Prompt Engineering in RAG Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ioannis Papadimitriou",
        "Ilias Gialampoukidis",
        "Stefanos Vrochidis",
        "Ioannis",
        "Kompatsiaris"
      ],
      "abstract": "We present RAG Playground, an open-source framework for systematic evaluation\nof Retrieval-Augmented Generation (RAG) systems. The framework implements and\ncompares three retrieval approaches: naive vector search, reranking, and hybrid\nvector-keyword search, combined with ReAct agents using different prompting\nstrategies. We introduce a comprehensive evaluation framework with novel\nmetrics and provide empirical results comparing different language models\n(Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our\nexperiments demonstrate significant performance improvements through hybrid\nsearch methods and structured self-evaluation prompting, achieving up to 72.7%\npass rate on our multi-metric evaluation framework. The results also highlight\nthe importance of prompt engineering in RAG systems, with our custom-prompted\nagents showing consistent improvements in retrieval accuracy and response\nquality.",
      "tldr_zh": "我们提出了 RAG Playground，一个开源框架，用于系统评估 Retrieval-Augmented Generation (RAG) 系统的检索策略和提示工程。该框架实现了三种检索方法——naive vector search、reranking 和 hybrid vector-keyword search，并结合 ReAct agents 以及不同 prompting strategies，进行全面比较。实验结果显示，使用 hybrid search 方法和结构化的 self-evaluation prompting，能显著提升性能，达到 72.7% 的多指标通过率；此外，自定义提示策略在提高检索准确性和响应质量方面表现出一致的优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Work In Progress",
      "pdf_url": "http://arxiv.org/pdf/2412.12322v1",
      "published_date": "2024-12-16 19:40:26 UTC",
      "updated_date": "2024-12-16 19:40:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:12:58.511879"
    },
    {
      "arxiv_id": "2412.12276v2",
      "title": "Emergence of Abstractions: Concept Encoding and Decoding Mechanism for In-Context Learning in Transformers",
      "title_zh": "抽象概念的涌现：概念编码和解码机制用于Transformer中的上下文学习",
      "authors": [
        "Seungwook Han",
        "Jinyeop Song",
        "Jeff Gore",
        "Pulkit Agrawal"
      ],
      "abstract": "Humans distill complex experiences into fundamental abstractions that enable\nrapid learning and adaptation. Similarly, autoregressive transformers exhibit\nadaptive learning through in-context learning (ICL), which begs the question of\nhow. In this paper, we propose concept encoding-decoding mechanism to explain\nICL by studying how transformers form and use internal abstractions in their\nrepresentations. On synthetic ICL tasks, we analyze the training dynamics of a\nsmall transformer and report the coupled emergence of concept encoding and\ndecoding. As the model learns to encode different latent concepts (e.g.,\n``Finding the first noun in a sentence.\") into distinct, separable\nrepresentations, it concureently builds conditional decoding algorithms and\nimprove its ICL performance. We validate the existence of this mechanism across\npretrained models of varying scales (Gemma-2 2B/9B/27B, Llama-3.1 8B/70B).\nFurther, through mechanistic interventions and controlled finetuning, we\ndemonstrate that the quality of concept encoding is causally related and\npredictive of ICL performance. Our empirical insights shed light into better\nunderstanding the success and failure modes of large language models via their\nrepresentations.",
      "tldr_zh": "本研究探讨了Transformer模型中In-Context Learning (ICL)的机制，提出了一种概念编码-解码机制来解释模型如何形成和利用内部抽象以实现快速适应。研究者通过分析小Transformer在合成ICL任务上的训练动态，发现概念编码（如将“Finding the first noun in a sentence”编码成可分离表示）和解码算法的共同出现，从而提升ICL性能，并在Gemma-2 (2B/9B/27B)和Llama-3.1 (8B/70B)等预训练模型上验证了这一机制。通过机制干预和控制微调实验，证明概念编码质量与ICL性能存在因果关系，并为理解大型语言模型的成功与失败模式提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12276v2",
      "published_date": "2024-12-16 19:00:18 UTC",
      "updated_date": "2024-12-18 06:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:13:10.270941"
    },
    {
      "arxiv_id": "2412.12098v1",
      "title": "MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization",
      "title_zh": "翻译失败",
      "authors": [
        "Bhavya Sukhija",
        "Stelian Coros",
        "Andreas Krause",
        "Pieter Abbeel",
        "Carmelo Sferrazza"
      ],
      "abstract": "Reinforcement learning (RL) algorithms aim to balance exploiting the current\nbest strategy with exploring new options that could lead to higher rewards.\nMost common RL algorithms use undirected exploration, i.e., select random\nsequences of actions. Exploration can also be directed using intrinsic rewards,\nsuch as curiosity or model epistemic uncertainty. However, effectively\nbalancing task and intrinsic rewards is challenging and often task-dependent.\nIn this work, we introduce a framework, MaxInfoRL, for balancing intrinsic and\nextrinsic exploration. MaxInfoRL steers exploration towards informative\ntransitions, by maximizing intrinsic rewards such as the information gain about\nthe underlying task. When combined with Boltzmann exploration, this approach\nnaturally trades off maximization of the value function with that of the\nentropy over states, rewards, and actions. We show that our approach achieves\nsublinear regret in the simplified setting of multi-armed bandits. We then\napply this general formulation to a variety of off-policy model-free RL methods\nfor continuous state-action spaces, yielding novel algorithms that achieve\nsuperior performance across hard exploration problems and complex scenarios\nsuch as visual control tasks.",
      "tldr_zh": "本论文提出MaxInfoRL框架，通过最大化information gain来提升reinforcement learning中的探索效率，从而平衡内在奖励（如任务不确定性）和外在奖励。MaxInfoRL将这一方法与Boltzmann exploration结合，实现价值函数最大化与状态、奖励和动作熵的自然权衡。实验结果显示，该框架在多臂老虎机简化场景中达到次线性遗憾，并在复杂连续状态-动作空间的离策略无模型RL任务中，表现出色，尤其适用于困难探索和视觉控制问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12098v1",
      "published_date": "2024-12-16 18:59:53 UTC",
      "updated_date": "2024-12-16 18:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:13:22.598884"
    },
    {
      "arxiv_id": "2412.12242v1",
      "title": "OmniPrism: Learning Disentangled Visual Concept for Image Generation",
      "title_zh": "OmniPrism：学习解耦视觉概念用于图像生成",
      "authors": [
        "Yangyang Li",
        "Daqing Liu",
        "Wu Liu",
        "Allen He",
        "Xinchen Liu",
        "Yongdong Zhang",
        "Guoqing Jin"
      ],
      "abstract": "Creative visual concept generation often draws inspiration from specific\nconcepts in a reference image to produce relevant outcomes. However, existing\nmethods are typically constrained to single-aspect concept generation or are\neasily disrupted by irrelevant concepts in multi-aspect concept scenarios,\nleading to concept confusion and hindering creative generation. To address\nthis, we propose OmniPrism, a visual concept disentangling approach for\ncreative image generation. Our method learns disentangled concept\nrepresentations guided by natural language and trains a diffusion model to\nincorporate these concepts. We utilize the rich semantic space of a multimodal\nextractor to achieve concept disentanglement from given images and concept\nguidance. To disentangle concepts with different semantics, we construct a\npaired concept disentangled dataset (PCD-200K), where each pair shares the same\nconcept such as content, style, and composition. We learn disentangled concept\nrepresentations through our contrastive orthogonal disentangled (COD) training\npipeline, which are then injected into additional diffusion cross-attention\nlayers for generation. A set of block embeddings is designed to adapt each\nblock's concept domain in the diffusion models. Extensive experiments\ndemonstrate that our method can generate high-quality, concept-disentangled\nresults with high fidelity to text prompts and desired concepts.",
      "tldr_zh": "该论文提出 OmniPrism，一种用于创意图像生成的视觉概念解耦（disentangled visual concept）方法，以解决现有模型在多方面概念生成中容易出现概念混淆的问题。OmniPrism 通过自然语言指导学习解耦的概念表示，并训练扩散模型（diffusion model）来整合这些表示，利用多模态提取器和自建的 PCD-200K 数据集进行对比正交解耦（COD）训练管道。实验结果显示，该方法能生成高质量、与文本提示和期望概念高度一致的图像，显著提升了概念解耦的准确性和生成效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "WebPage available at https://tale17.github.io/omni/",
      "pdf_url": "http://arxiv.org/pdf/2412.12242v1",
      "published_date": "2024-12-16 18:59:52 UTC",
      "updated_date": "2024-12-16 18:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:13:34.447886"
    },
    {
      "arxiv_id": "2412.12094v5",
      "title": "SepLLM: Accelerate Large Language Models by Compressing One Segment into One Separator",
      "title_zh": "翻译失败",
      "authors": [
        "Guoxuan Chen",
        "Han Shi",
        "Jiawei Li",
        "Yihang Gao",
        "Xiaozhe Ren",
        "Yimeng Chen",
        "Xin Jiang",
        "Zhenguo Li",
        "Weiyang Liu",
        "Chao Huang"
      ],
      "abstract": "Large Language Models (LLMs) have exhibited exceptional performance across a\nspectrum of natural language processing tasks. However, their substantial sizes\npose considerable challenges, particularly in computational demands and\ninference speed, due to their quadratic complexity. In this work, we have\nidentified a key pattern: certain seemingly meaningless separator tokens (i.e.,\npunctuations) contribute disproportionately to attention scores compared to\nsemantically meaningful tokens. This observation suggests that information of\nthe segments between these separator tokens can be effectively condensed into\nthe separator tokens themselves without significant information loss. Guided by\nthis insight, we introduce SepLLM, a plug-and-play framework that accelerates\ninference by compressing these segments and eliminating redundant tokens.\nAdditionally, we implement efficient kernels for training acceleration.\nExperimental results across training-free, training-from-scratch, and\npost-training settings demonstrate SepLLM's effectiveness. Notably, using the\nLlama-3-8B backbone, SepLLM achieves over 50% reduction in KV cache on the\nGSM8K-CoT benchmark while maintaining comparable performance. Furthermore, in\nstreaming settings, SepLLM effectively processes sequences of up to 4 million\ntokens or more while maintaining consistent language modeling capabilities.",
      "tldr_zh": "该论文观察到大型语言模型（LLMs）中的某些分隔符（如标点）在注意力分数中贡献较大，因此提出SepLLM框架，通过将段落信息压缩到单个分隔符中，消除冗余token，从而加速模型推理和训练。SepLLM是一个即插即用的方法，还实现了高效内核以进一步提升训练速度。实验结果显示，在Llama-3-8B骨干模型上，SepLLM在GSM8K-CoT基准测试中减少超过50%的KV cache，同时保持类似性能，并在流式设置中成功处理超过400万token的序列。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "We have made our code publicly available at sepllm.github.io. Our\n  codebase supports efficient multi-node distributed training with accelerated\n  attention module Sep-Attention and also supports numerous existing Fusion\n  Operators to accelerate the training process, such as fused rope, etc. If you\n  find our code helpful, please kindly consider giving us a **star** on GitHub\n  ^_^ Thank you very much!",
      "pdf_url": "http://arxiv.org/pdf/2412.12094v5",
      "published_date": "2024-12-16 18:58:57 UTC",
      "updated_date": "2025-02-24 15:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:13:46.078392"
    },
    {
      "arxiv_id": "2412.12089v2",
      "title": "Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Eliot Xing",
        "Vernon Luk",
        "Jean Oh"
      ],
      "abstract": "Recent advances in GPU-based parallel simulation have enabled practitioners\nto collect large amounts of data and train complex control policies using deep\nreinforcement learning (RL), on commodity GPUs. However, such successes for RL\nin robotics have been limited to tasks sufficiently simulated by fast\nrigid-body dynamics. Simulation techniques for soft bodies are comparatively\nseveral orders of magnitude slower, thereby limiting the use of RL due to\nsample complexity requirements. To address this challenge, this paper presents\nboth a novel RL algorithm and a simulation platform to enable scaling RL on\ntasks involving rigid bodies and deformables. We introduce Soft Analytic Policy\nOptimization (SAPO), a maximum entropy first-order model-based actor-critic RL\nalgorithm, which uses first-order analytic gradients from differentiable\nsimulation to train a stochastic actor to maximize expected return and entropy.\nAlongside our approach, we develop Rewarped, a parallel differentiable\nmultiphysics simulation platform that supports simulating various materials\nbeyond rigid bodies. We re-implement challenging manipulation and locomotion\ntasks in Rewarped, and show that SAPO outperforms baselines over a range of\ntasks that involve interaction between rigid bodies, articulations, and\ndeformables. Additional details at https://rewarped.github.io/.",
      "tldr_zh": "本研究针对软体模拟的低效率问题，提出了一种新的强化学习（RL）算法Soft Analytic Policy Optimization (SAPO)，它是一种最大熵的first-order model-based actor-critic方法，利用可微模拟的first-order analytic gradients来训练随机actor，提升RL在多物理模拟中的稳定性。论文同时开发了Rewarped，一个并行可微多物理模拟平台，支持刚体、可变形体等多种材料的模拟。实验结果显示，SAPO在涉及刚体、关节和可变形体的操纵和运动任务中，超过了基线模型的表现，为RL在复杂机器人任务中的应用提供了可扩展解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "34 pages, 13 figures, 18 tables. Accepted to ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2412.12089v2",
      "published_date": "2024-12-16 18:56:24 UTC",
      "updated_date": "2025-02-27 19:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:13:57.987560"
    },
    {
      "arxiv_id": "2412.12063v1",
      "title": "Revelations: A Decidable Class of POMDPs with Omega-Regular Objectives",
      "title_zh": "翻译失败",
      "authors": [
        "Marius Belly",
        "Nathanaël Fijalkow",
        "Hugo Gimbert",
        "Florian Horn",
        "Guillermo A. Pérez",
        "Pierre Vandenhove"
      ],
      "abstract": "Partially observable Markov decision processes (POMDPs) form a prominent\nmodel for uncertainty in sequential decision making. We are interested in\nconstructing algorithms with theoretical guarantees to determine whether the\nagent has a strategy ensuring a given specification with probability 1. This\nwell-studied problem is known to be undecidable already for very simple\nomega-regular objectives, because of the difficulty of reasoning on uncertain\nevents. We introduce a revelation mechanism which restricts information loss by\nrequiring that almost surely the agent has eventually full information of the\ncurrent state. Our main technical results are to construct exact algorithms for\ntwo classes of POMDPs called weakly and strongly revealing. Importantly, the\ndecidable cases reduce to the analysis of a finite belief-support Markov\ndecision process. This yields a conceptually simple and exact algorithm for a\nlarge class of POMDPs.",
      "tldr_zh": "本研究针对部分可观测Markov决策过程（POMDPs），探讨了在omega-regular目标下确定代理策略是否能以概率1实现给定规范的问题，该问题通常因不确定事件而不可判定。论文引入了revelation mechanism机制，通过要求代理几乎肯定地最终获得当前状态的完整信息，定义了weakly revealing和strongly revealing两种POMDPs类。关键贡献是为这些类构建精确算法，将问题简化为分析有限的belief-support Markov决策过程，从而为一大类POMDPs提供了一个概念简单且可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted to AAAI 2025. 26 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12063v1",
      "published_date": "2024-12-16 18:37:06 UTC",
      "updated_date": "2024-12-16 18:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:14:09.552767"
    },
    {
      "arxiv_id": "2412.12046v1",
      "title": "Artificial Intelligence in Traffic Systems",
      "title_zh": "人工智能在交通系统",
      "authors": [
        "Ritwik Raj Saxena"
      ],
      "abstract": "Existing research on AI-based traffic management systems, utilizing\ntechniques such as fuzzy logic, reinforcement learning, deep neural networks,\nand evolutionary algorithms, demonstrates the potential of AI to transform the\ntraffic landscape. This article endeavors to review the topics where AI and\ntraffic management intersect. It comprises areas like AI-powered traffic signal\ncontrol systems, automatic distance and velocity recognition (for instance, in\nautonomous vehicles, hereafter AVs), smart parking systems, and Intelligent\nTraffic Management Systems (ITMS), which use data captured in real-time to keep\ntrack of traffic conditions, and traffic-related law enforcement and\nsurveillance using AI. AI applications in traffic management cover a wide range\nof spheres. The spheres comprise, inter alia, streamlining traffic signal\ntimings, predicting traffic bottlenecks in specific areas, detecting potential\naccidents and road hazards, managing incidents accurately, advancing public\ntransportation systems, development of innovative driver assistance systems,\nand minimizing environmental impact through simplified routes and reduced\nemissions. The benefits of AI in traffic management are also diverse. They\ncomprise improved management of traffic data, sounder route decision\nautomation, easier and speedier identification and resolution of vehicular\nissues through monitoring the condition of individual vehicles, decreased\ntraffic snarls and mishaps, superior resource utilization, alleviated stress of\ntraffic management manpower, greater on-road safety, and better emergency\nresponse time.",
      "tldr_zh": "这篇论文回顾了人工智能（AI）在交通管理系统中的应用，涵盖了技术如模糊逻辑（fuzzy logic）、强化学习（reinforcement learning）、深度神经网络和进化算法。论文探讨了AI在多个领域的交叉，包括AI驱动的交通信号控制系统、自动距离和速度识别（如在自动驾驶车辆中）、智能停车系统，以及智能交通管理系统（ITMS），这些系统利用实时数据监控交通条件和执法。AI的应用有助于优化交通信号时间、预测拥堵、检测事故、管理事件、提升公共交通和驾驶辅助系统，并减少环境影响。总体而言，AI带来的益处包括改善交通数据管理、自动化路由决策、减少事故和拥堵、优化资源利用、提高道路安全和应急响应效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 17343 words, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.12046v1",
      "published_date": "2024-12-16 18:15:49 UTC",
      "updated_date": "2024-12-16 18:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:14:22.152548"
    },
    {
      "arxiv_id": "2412.12042v1",
      "title": "The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Julián N. Acosta",
        "Siddhant Dogra",
        "Subathra Adithan",
        "Kay Wu",
        "Michael Moritz",
        "Stephen Kwak",
        "Pranav Rajpurkar"
      ],
      "abstract": "Radiologists face increasing workload pressures amid growing imaging volumes,\ncreating risks of burnout and delayed reporting times. While artificial\nintelligence (AI) based automated radiology report generation shows promise for\nreporting workflow optimization, evidence of its real-world impact on clinical\naccuracy and efficiency remains limited. This study evaluated the effect of\ndraft reports on radiology reporting workflows by conducting a three reader\nmulti-case study comparing standard versus AI-assisted reporting workflows. In\nboth workflows, radiologists reviewed the cases and modified either a standard\ntemplate (standard workflow) or an AI-generated draft report (AI-assisted\nworkflow) to create the final report. For controlled evaluation, we used GPT-4\nto generate simulated AI drafts and deliberately introduced 1-3 errors in half\nthe cases to mimic real AI system performance. The AI-assisted workflow\nsignificantly reduced average reporting time from 573 to 435 seconds (p=0.003),\nwithout a statistically significant difference in clinically significant errors\nbetween workflows. These findings suggest that AI-generated drafts can\nmeaningfully accelerate radiology reporting while maintaining diagnostic\naccuracy, offering a practical solution to address mounting workload challenges\nin clinical practice.",
      "tldr_zh": "本研究评估了AI辅助在放射报告中的影响，通过一个试点研究比较标准工作流程和AI辅助工作流程，以应对放射科医生面临的工作量压力和报告延迟问题。研究中，三名放射科医生使用GPT-4生成的模拟AI草稿报告（其中半数病例故意引入1-3个错误）进行修改，结果显示AI辅助工作流程将平均报告时间从573秒显著减少到435秒（p=0.003），而临床显著错误之间无统计学差异。这些发现表明，AI生成的草稿能有效提升报告效率，同时保持诊断准确性，为临床实践中的工作负载挑战提供实用解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12042v1",
      "published_date": "2024-12-16 18:10:49 UTC",
      "updated_date": "2024-12-16 18:10:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:14:34.857165"
    },
    {
      "arxiv_id": "2412.12039v2",
      "title": "Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ira Ceka",
        "Feitong Qiao",
        "Anik Dey",
        "Aastha Valecha",
        "Gail Kaiser",
        "Baishakhi Ray"
      ],
      "abstract": "Despite their remarkable success, large language models (LLMs) have shown\nlimited ability on applied tasks such as vulnerability detection. We\ninvestigate various prompting strategies for vulnerability detection and, as\npart of this exploration, propose a prompting strategy that integrates natural\nlanguage descriptions of vulnerabilities with a contrastive chain-of-thought\nreasoning approach, augmented using contrastive samples from a synthetic\ndataset. Our study highlights the potential of LLMs to detect vulnerabilities\nby integrating natural language descriptions, contrastive reasoning, and\nsynthetic examples into a comprehensive prompting framework. Our results show\nthat this approach can enhance LLM understanding of vulnerabilities. On a\nhigh-quality vulnerability detection dataset such as SVEN, our prompting\nstrategies can improve accuracies, F1-scores, and pairwise accuracies by 23%,\n11%, and 14%, respectively.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 是否能通过提示策略替代静态分析 (static analysis) 来检测漏洞，尽管 LLMs 在此任务上表现有限。作者提出了一种新颖的提示框架，将漏洞的自然语言描述与对比链式思维推理 (contrastive chain-of-thought reasoning) 相结合，并使用合成数据集的对比样本进行增强，从而提升 LLMs 对漏洞的理解。在 SVEN 数据集上的实验结果显示，该策略将准确率、F1 分数和成对准确率分别提高了 23%、11% 和 14%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12039v2",
      "published_date": "2024-12-16 18:08:14 UTC",
      "updated_date": "2025-01-18 01:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:14:46.382955"
    },
    {
      "arxiv_id": "2412.12032v3",
      "title": "FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning",
      "title_zh": "FSFM：",
      "authors": [
        "Gaojian Wang",
        "Feng Lin",
        "Tong Wu",
        "Zhenguang Liu",
        "Zhongjie Ba",
        "Kui Ren"
      ],
      "abstract": "This work asks: with abundant, unlabeled real faces, how to learn a robust\nand transferable facial representation that boosts various face security tasks\nwith respect to generalization performance? We make the first attempt and\npropose a self-supervised pretraining framework to learn fundamental\nrepresentations of real face images, FSFM, that leverages the synergy between\nmasked image modeling (MIM) and instance discrimination (ID). We explore\nvarious facial masking strategies for MIM and present a simple yet powerful\nCRFR-P masking, which explicitly forces the model to capture meaningful\nintra-region consistency and challenging inter-region coherency. Furthermore,\nwe devise the ID network that naturally couples with MIM to establish\nunderlying local-to-global correspondence via tailored self-distillation. These\nthree learning objectives, namely 3C, empower encoding both local features and\nglobal semantics of real faces. After pretraining, a vanilla ViT serves as a\nuniversal vision foundation model for downstream face security tasks:\ncross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen\ndiffusion facial forgery detection. Extensive experiments on 10 public datasets\ndemonstrate that our model transfers better than supervised pretraining, visual\nand facial self-supervised learning arts, and even outperforms task-specialized\nSOTA methods.",
      "tldr_zh": "这篇论文探讨了如何利用大量无标签真实面部图像，通过自监督学习来获得鲁棒且可转移的面部表示，从而提升面部安全任务的泛化性能。作者提出了 FSFM 框架，结合 Masked Image Modeling (MIM) 和 Instance Discrimination (ID)，并引入 CRFR-P 掩码策略以及 ID 网络，以捕捉面部的局部特征和全局语义。实验结果显示，FSFM 在 10 个公共数据集上的下游任务（如跨数据集深度伪造检测、跨域面部反欺骗和未见扩散面部伪造检测）中，超过了监督预训练、自监督学习方法，甚至专有 SOTA 模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 11 figures, project page: https://fsfm-3c.github.io",
      "pdf_url": "http://arxiv.org/pdf/2412.12032v3",
      "published_date": "2024-12-16 17:58:45 UTC",
      "updated_date": "2025-04-06 14:07:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:14:59.836798"
    },
    {
      "arxiv_id": "2412.12237v1",
      "title": "Equivariant Action Sampling for Reinforcement Learning and Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Linfeng Zhao",
        "Owen Howell",
        "Xupeng Zhu",
        "Jung Yeon Park",
        "Zhewen Zhang",
        "Robin Walters",
        "Lawson L. S. Wong"
      ],
      "abstract": "Reinforcement learning (RL) algorithms for continuous control tasks require\naccurate sampling-based action selection. Many tasks, such as robotic\nmanipulation, contain inherent problem symmetries. However, correctly\nincorporating symmetry into sampling-based approaches remains a challenge. This\nwork addresses the challenge of preserving symmetry in sampling-based planning\nand control, a key component for enhancing decision-making efficiency in RL. We\nintroduce an action sampling approach that enforces the desired symmetry. We\napply our proposed method to a coordinate regression problem and show that the\nsymmetry aware sampling method drastically outperforms the naive sampling\napproach. We furthermore develop a general framework for sampling-based\nmodel-based planning with Model Predictive Path Integral (MPPI). We compare our\nMPPI approach with standard sampling methods on several continuous control\ntasks. Empirical demonstrations across multiple continuous control environments\nvalidate the effectiveness of our approach, showcasing the importance of\nsymmetry preservation in sampling-based action selection.",
      "tldr_zh": "本文提出一种 equivariant action sampling 方法，用于强化学习 (RL) 和规划中，确保采样过程保留任务的对称性，从而提升决策效率。该方法通过强制执行所需对称性，应用于坐标回归问题和基于 Model Predictive Path Integral (MPPI) 的采样-based 模型-based 规划框架中。实验结果显示，与标准采样方法相比，该方法在多个连续控制任务上大幅提高了性能，验证了保留对称性在动作选择中的关键作用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at International Workshop on the Algorithmic Foundations of\n  Robotics (WAFR) 2024. Website: http://lfzhao.com/EquivSampling",
      "pdf_url": "http://arxiv.org/pdf/2412.12237v1",
      "published_date": "2024-12-16 17:51:14 UTC",
      "updated_date": "2024-12-16 17:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:15:10.672936"
    },
    {
      "arxiv_id": "2412.12024v1",
      "title": "Learning to Navigate in Mazes with Novel Layouts using Abstract Top-down Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Linfeng Zhao",
        "Lawson L. S. Wong"
      ],
      "abstract": "Learning navigation capabilities in different environments has long been one\nof the major challenges in decision-making. In this work, we focus on zero-shot\nnavigation ability using given abstract $2$-D top-down maps. Like human\nnavigation by reading a paper map, the agent reads the map as an image when\nnavigating in a novel layout, after learning to navigate on a set of training\nmaps. We propose a model-based reinforcement learning approach for this\nmulti-task learning problem, where it jointly learns a hypermodel that takes\ntop-down maps as input and predicts the weights of the transition network. We\nuse the DeepMind Lab environment and customize layouts using generated maps.\nOur method can adapt better to novel environments in zero-shot and is more\nrobust to noise.",
      "tldr_zh": "本研究探讨了使用抽象 2-D top-down maps 进行零-shot navigation 的能力，旨在让代理在新型迷宫布局中学习导航，类似于人类阅读纸质地图。研究提出了一种基于模型的强化学习方法，通过训练一个 hypermodel 来处理多任务学习，该模型以顶视图地图作为输入，并预测过渡网络的权重。实验在 DeepMind Lab 环境中使用自定义生成的地图进行测试，结果显示该方法在零-shot 场景下对新环境适应性更强，并对噪声更具鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Reinforcement Learning Conference (RLC) 2024. Website:\n  http://lfzhao.com/map-nav/",
      "pdf_url": "http://arxiv.org/pdf/2412.12024v1",
      "published_date": "2024-12-16 17:51:09 UTC",
      "updated_date": "2024-12-16 17:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:15:21.488803"
    },
    {
      "arxiv_id": "2412.16195v2",
      "title": "Machine Learning-Based Automated Assessment of Intracorporeal Suturing in Laparoscopic Fundoplication",
      "title_zh": "翻译失败",
      "authors": [
        "Shekhar Madhav Khairnar",
        "Huu Phong Nguyen",
        "Alexis Desir",
        "Carla Holcomb",
        "Daniel J. Scott",
        "Ganesh Sankaranarayanan"
      ],
      "abstract": "Automated assessment of surgical skills using artificial intelligence (AI)\nprovides trainees with instantaneous feedback. After bimanual tool motions are\ncaptured, derived kinematic metrics are reliable predictors of performance in\nlaparoscopic tasks. Implementing automated tool tracking requires\ntime-intensive human annotation. We developed AI-based tool tracking using the\nSegment Anything Model (SAM) to eliminate the need for human annotators. Here,\nwe describe a study evaluating the usefulness of our tool tracking model in\nautomated assessment during a laparoscopic suturing task in the fundoplication\nprocedure. An automated tool tracking model was applied to recorded videos of\nNissen fundoplication on porcine bowel. Surgeons were grouped as novices\n(PGY1-2) and experts (PGY3-5, attendings). The beginning and end of each\nsuturing step were segmented, and motions of the left and right tools were\nextracted. A low-pass filter with a 24 Hz cut-off frequency removed noise.\nPerformance was assessed using supervised and unsupervised models, and an\nablation study compared results. Kinematic features--RMS velocity, RMS\nacceleration, RMS jerk, total path length, and Bimanual Dexterity--were\nextracted and analyzed using Logistic Regression, Random Forest, Support Vector\nClassifier, and XGBoost. PCA was performed for feature reduction. For\nunsupervised learning, a Denoising Autoencoder (DAE) model with classifiers,\nsuch as a 1-D CNN and traditional models, was trained. Data were extracted for\n28 participants (9 novices, 19 experts). Supervised learning with PCA and\nRandom Forest achieved an accuracy of 0.795 and an F1 score of 0.778. The\nunsupervised 1-D CNN achieved superior results with an accuracy of 0.817 and an\nF1 score of 0.806, eliminating the need for kinematic feature computation. We\ndemonstrated an AI model capable of automated performance classification,\nindependent of human annotation.",
      "tldr_zh": "本文提出了一种基于机器学习的自动评估系统，用于评估腹腔镜 fundoplication 手术中体内缝合技能的性能，旨在提供即时反馈并消除人工标注需求。该系统利用 Segment Anything Model (SAM) 进行工具跟踪，从手术视频中提取运动学特征，如 RMS velocity、RMS acceleration 和 Bimanual Dexterity，并应用监督模型（如 Logistic Regression、Random Forest、Support Vector Classifier 和 XGBoost）以及无监督模型（如 Denoising Autoencoder (DAE) 和 1-D CNN）。在 28 名参与者（9 名新手、19 名专家）的数据分析中，无监督 1-D CNN 模型取得了 0.817 的准确率和 0.806 的 F1 分数，优于监督模型，且无需手动计算特征。该方法展示了 AI 在外科技能评估中的潜力，实现独立于人工的自动化分类。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.16195v2",
      "published_date": "2024-12-16 17:44:44 UTC",
      "updated_date": "2025-04-24 05:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:15:36.673288"
    },
    {
      "arxiv_id": "2412.12009v2",
      "title": "SpeechPrune: Context-aware Token Pruning for Speech Information Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Yueqian Lin",
        "Yuzhe Fu",
        "Jingyang Zhang",
        "Yudong Liu",
        "Jianyi Zhang",
        "Jingwei Sun",
        "Hai \"Helen\" Li",
        "Yiran Chen"
      ],
      "abstract": "We introduce Speech Information Retrieval (SIR), a new long-context task for\nSpeech Large Language Models (Speech LLMs), and present SPIRAL, a 1,012-sample\nbenchmark testing models' ability to extract critical details from\napproximately 90-second spoken inputs. While current Speech LLMs excel at\nshort-form tasks, they struggle with the computational and representational\ndemands of longer audio sequences. To address this limitation, we propose\nSpeechPrune, a training-free token pruning strategy that uses speech-text\nsimilarity and approximated attention scores to efficiently discard irrelevant\ntokens. In SPIRAL, SpeechPrune achieves accuracy improvements of 29% and up to\n47% over the original model and the random pruning model at a pruning rate of\n20%, respectively. SpeechPrune can maintain network performance even at a\npruning level of 80%. This approach highlights the potential of token-level\npruning for efficient and scalable long-form speech understanding.",
      "tldr_zh": "本论文引入了Speech Information Retrieval (SIR)，一个针对Speech Large Language Models (Speech LLMs)的长上下文任务，并提出了SPIRAL基准测试，包含1,012个样本，用于评估模型从约90秒语音输入中提取关键细节的能力。为应对长音频序列的计算挑战，论文提出了SpeechPrune，一种无需训练的token修剪策略，通过语音-文本相似度和近似注意力分数来高效丢弃无关token。在SPIRAL基准上，SpeechPrune在20%修剪率下准确率比原模型提高29%并比随机修剪模型提高47%，即使在80%修剪率下也能保持性能，这突显了token-level修剪在高效、可扩展的长语音理解中的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at IEEE ICME 2025. Project page:\n  https://speechprune.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2412.12009v2",
      "published_date": "2024-12-16 17:36:02 UTC",
      "updated_date": "2025-03-30 02:39:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:15:47.392733"
    },
    {
      "arxiv_id": "2412.12006v2",
      "title": "Agentic AI-Driven Technical Troubleshooting for Enterprise Systems: A Novel Weighted Retrieval-Augmented Generation Paradigm",
      "title_zh": "Agentic AI驱动的企业系统技术故障排除：一种新型",
      "authors": [
        "Rajat Khanda"
      ],
      "abstract": "Technical troubleshooting in enterprise environments often involves\nnavigating diverse, heterogeneous data sources to resolve complex issues\neffectively. This paper presents a novel agentic AI solution built on a\nWeighted Retrieval-Augmented Generation (RAG) Framework tailored for enterprise\ntechnical troubleshooting. By dynamically weighting retrieval sources such as\nproduct manuals, internal knowledge bases, FAQs, and troubleshooting guides\nbased on query context, the framework prioritizes the most relevant data. For\ninstance, it gives precedence to product manuals for SKU-specific queries while\nincorporating general FAQs for broader issues. The system employs FAISS for\nefficient dense vector search, coupled with a dynamic aggregation mechanism to\nseamlessly integrate results from multiple sources. A Llama-based\nself-evaluator ensures the contextual accuracy and confidence of the generated\nresponses before delivering them. This iterative cycle of retrieval and\nvalidation enhances precision, diversity, and reliability in response\ngeneration. Preliminary evaluations on large enterprise datasets demonstrate\nthe framework's efficacy in improving troubleshooting accuracy, reducing\nresolution times, and adapting to varied technical challenges. Future research\naims to enhance the framework by integrating advanced conversational AI\ncapabilities, enabling more interactive and intuitive troubleshooting\nexperiences. Efforts will also focus on refining the dynamic weighting\nmechanism through reinforcement learning to further optimize the relevance and\nprecision of retrieved information. By incorporating these advancements, the\nproposed framework is poised to evolve into a comprehensive, autonomous AI\nsolution, redefining technical service workflows across enterprise settings.",
      "tldr_zh": "这篇论文提出了一种基于代理AI的Weighted Retrieval-Augmented Generation (Weighted RAG)框架，用于企业系统技术故障排除，通过动态加权检索来源（如产品手册、内部知识库和FAQ）来优先处理查询相关数据，例如针对SKU特定查询优先使用产品手册。框架结合FAISS的密集向量搜索、动态聚合机制和Llama-based自评估器，确保响应生成过程的准确性、可靠性和多样性，并在迭代检索与验证循环中提升整体性能。初步评估显示，该系统在大型企业数据集上提高了故障排除准确率、缩短了解决时间，并能适应各种技术挑战；未来计划通过整合高级对话AI和强化学习优化加权机制，进一步提升框架的自主性和交互性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12006v2",
      "published_date": "2024-12-16 17:32:38 UTC",
      "updated_date": "2024-12-17 17:02:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:15:58.049738"
    },
    {
      "arxiv_id": "2412.12000v1",
      "title": "CP-Guard: Malicious Agent Detection and Defense in Collaborative Bird's Eye View Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Senkang Hu",
        "Yihang Tao",
        "Guowen Xu",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang",
        "Sam Kwong"
      ],
      "abstract": "Collaborative Perception (CP) has shown a promising technique for autonomous\ndriving, where multiple connected and autonomous vehicles (CAVs) share their\nperception information to enhance the overall perception performance and expand\nthe perception range. However, in CP, ego CAV needs to receive messages from\nits collaborators, which makes it easy to be attacked by malicious agents. For\nexample, a malicious agent can send harmful information to the ego CAV to\nmislead it. To address this critical issue, we propose a novel method,\n\\textbf{CP-Guard}, a tailored defense mechanism for CP that can be deployed by\neach agent to accurately detect and eliminate malicious agents in its\ncollaboration network. Our key idea is to enable CP to reach a consensus rather\nthan a conflict against the ego CAV's perception results. Based on this idea,\nwe first develop a probability-agnostic sample consensus (PASAC) method to\neffectively sample a subset of the collaborators and verify the consensus\nwithout prior probabilities of malicious agents. Furthermore, we define a\ncollaborative consistency loss (CCLoss) to capture the discrepancy between the\nego CAV and its collaborators, which is used as a verification criterion for\nconsensus. Finally, we conduct extensive experiments in collaborative bird's\neye view (BEV) tasks and our results demonstrate the effectiveness of our\nCP-Guard.",
      "tldr_zh": "该研究针对自动驾驶中的协作感知（CP），探讨了恶意代理攻击问题，这些攻击可能通过发送有害信息误导车辆。作者提出了一种名为CP-Guard的防御机制，每个代理可部署此机制来检测和消除协作网络中的恶意代理，其核心是通过probability-agnostic sample consensus (PASAC)方法采样子集并验证共识，以及collaborative consistency loss (CCLoss)来衡量ego CAV与协作者的不一致性。实验在协作鸟瞰视图（BEV）任务上显示，CP-Guard有效提升了系统的鲁棒性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by AAAI'25",
      "pdf_url": "http://arxiv.org/pdf/2412.12000v1",
      "published_date": "2024-12-16 17:28:25 UTC",
      "updated_date": "2024-12-16 17:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:16:09.740078"
    },
    {
      "arxiv_id": "2412.11995v1",
      "title": "Combining Large Language Models with Tutoring System Intelligence: A Case Study in Caregiver Homework Support",
      "title_zh": "翻译失败",
      "authors": [
        "Devika Venugopalan",
        "Ziwen Yan",
        "Conrad Borchers",
        "Jionghao Lin",
        "Vincent Aleven"
      ],
      "abstract": "Caregivers (i.e., parents and members of a child's caring community) are\nunderappreciated stakeholders in learning analytics. Although caregiver\ninvolvement can enhance student academic outcomes, many obstacles hinder\ninvolvement, most notably knowledge gaps with respect to modern school\ncurricula. An emerging topic of interest in learning analytics is hybrid\ntutoring, which includes instructional and motivational support. Caregivers\nassert similar roles in homework, yet it is unknown how learning analytics can\nsupport them. Our past work with caregivers suggested that conversational\nsupport is a promising method of providing caregivers with the guidance needed\nto effectively support student learning. We developed a system that provides\ninstructional support to caregivers through conversational recommendations\ngenerated by a Large Language Model (LLM). Addressing known instructional\nlimitations of LLMs, we use instructional intelligence from tutoring systems\nwhile conducting prompt engineering experiments with the open-source Llama 3\nLLM. This LLM generated message recommendations for caregivers supporting their\nchild's math practice via chat. Few-shot prompting and combining real-time\nproblem-solving context from tutoring systems with examples of tutoring\npractices yielded desirable message recommendations. These recommendations were\nevaluated with ten middle school caregivers, who valued recommendations\nfacilitating content-level support and student metacognition through\nself-explanation. We contribute insights into how tutoring systems can best be\nmerged with LLMs to support hybrid tutoring settings through conversational\nassistance, facilitating effective caregiver involvement in tutoring systems.",
      "tldr_zh": "本文研究探讨了如何结合大型语言模型(LLM)和辅导系统智能，以支持照顾者（如父母）在家庭作业中的角色，解决他们面对现代课程知识缺口的问题。研究开发了一个系统，使用开源Llama 3 LLM通过few-shot prompting和实时问题解决上下文生成对话推荐，帮助照顾者提供教学和动机支持。实验中，该系统为十位中学照顾者生成的消息推荐获得了积极反馈，特别是那些促进内容支持和学生元认知（如自我解释）的建议。最终，该工作为混合辅导环境提供了见解，展示了如何整合LLM和辅导系统以提升照顾者参与度。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Full research paper accepted to Learning Analytics and Knowledge (LAK\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11995v1",
      "published_date": "2024-12-16 17:22:40 UTC",
      "updated_date": "2024-12-16 17:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:16:22.722565"
    },
    {
      "arxiv_id": "2412.11994v1",
      "title": "Fairness Shields: Safeguarding against Biased Decision Makers",
      "title_zh": "翻译失败",
      "authors": [
        "Filip Cano",
        "Thomas A. Henzinger",
        "Bettina Könighofer",
        "Konstantin Kueffner",
        "Kaushik Mallik"
      ],
      "abstract": "As AI-based decision-makers increasingly influence human lives, it is a\ngrowing concern that their decisions are often unfair or biased with respect to\npeople's sensitive attributes, such as gender and race. Most existing bias\nprevention measures provide probabilistic fairness guarantees in the long run,\nand it is possible that the decisions are biased on specific instances of short\ndecision sequences. We introduce fairness shielding, where a symbolic\ndecision-maker -- the fairness shield -- continuously monitors the sequence of\ndecisions of another deployed black-box decision-maker, and makes interventions\nso that a given fairness criterion is met while the total intervention costs\nare minimized. We present four different algorithms for computing fairness\nshields, among which one guarantees fairness over fixed horizons, and three\nguarantee fairness periodically after fixed intervals. Given a distribution\nover future decisions and their intervention costs, our algorithms solve\ndifferent instances of bounded-horizon optimal control problems with different\nlevels of computational costs and optimality guarantees. Our empirical\nevaluation demonstrates the effectiveness of these shields in ensuring fairness\nwhile maintaining cost efficiency across various scenarios.",
      "tldr_zh": "该研究针对 AI 决策系统在性别、种族等敏感属性上的偏见问题，提出了“fairness shields”机制，该机制由一个符号决策者（symbolic decision-maker）监控黑盒决策者的决策序列，并在必要时干预，以满足给定公平标准同时最小化干预成本。研究开发了四种算法，其中一种保证固定时段内的公平，其他三种确保定期公平，这些算法基于边界时段最优控制问题，并考虑未来决策分布和成本。实验结果表明，“fairness shields”在各种场景中有效，提高了公平性并保持了成本效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11994v1",
      "published_date": "2024-12-16 17:21:12 UTC",
      "updated_date": "2024-12-16 17:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:16:33.870883"
    },
    {
      "arxiv_id": "2412.11983v3",
      "title": "Leveraging Large Language Models for Effective Label-free Node Classification in Text-Attributed Graphs",
      "title_zh": "利用大型语言模型实现文本属性图中有效的无标签节点分类",
      "authors": [
        "Taiyan Zhang",
        "Renchi Yang",
        "Yurui Lai",
        "Mingyu Yan",
        "Xiaochun Ye",
        "Dongrui Fan"
      ],
      "abstract": "Graph neural networks (GNNs) have become the preferred models for node\nclassification in graph data due to their robust capabilities in integrating\ngraph structures and attributes. However, these models heavily depend on a\nsubstantial amount of high-quality labeled data for training, which is often\ncostly to obtain. With the rise of large language models (LLMs), a promising\napproach is to utilize their exceptional zero-shot capabilities and extensive\nknowledge for node labeling. Despite encouraging results, this approach either\nrequires numerous queries to LLMs or suffers from reduced performance due to\nnoisy labels generated by LLMs. To address these challenges, we introduce\nLocle, an active self-training framework that does Label-free node\nClassification with LLMs cost-Effectively. Locle iteratively identifies small\nsets of \"critical\" samples using GNNs and extracts informative pseudo-labels\nfor them with both LLMs and GNNs, serving as additional supervision signals to\nenhance model training. Specifically, Locle comprises three key components: (i)\nan effective active node selection strategy for initial annotations; (ii) a\ncareful sample selection scheme to identify \"critical\" nodes based on label\ndisharmonicity and entropy; and (iii) a label refinement module that combines\nLLMs and GNNs with a rewired topology. Extensive experiments on five benchmark\ntext-attributed graph datasets demonstrate that Locle significantly outperforms\nstate-of-the-art methods under the same query budget to LLMs in terms of\nlabel-free node classification. Notably, on the DBLP dataset with 14.3k nodes,\nLocle achieves an 8.08% improvement in accuracy over the state-of-the-art at a\ncost of less than one cent. Our code is available at\nhttps://github.com/HKBU-LAGAS/Locle.",
      "tldr_zh": "这篇论文提出 Locle 框架，利用大型语言模型 (LLMs) 和图神经网络 (GNNs) 进行有效的无标签节点分类，解决传统 GNNs 对高质量标签数据依赖的问题，同时减少 LLMs 查询成本和噪声影响。Locle 通过主动自训练机制，包括主动节点选择策略、基于标签不和谐性和熵的“关键”样本选择，以及结合 LLMs 和 GNNs 的标签精炼模块来增强模型训练。在五个基准文本属性图数据集上的实验表明，Locle 在相同查询预算下显著优于现有方法，例如在 DBLP 数据集上准确率提升 8.08%，成本不到一美分。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SIGIR2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11983v3",
      "published_date": "2024-12-16 17:04:40 UTC",
      "updated_date": "2025-05-16 06:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:16:46.994232"
    },
    {
      "arxiv_id": "2412.11974v2",
      "title": "Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Sun",
        "Pengfei Hong",
        "Tej Deep Pala",
        "Vernon Toh",
        "U-Xuan Tan",
        "Deepanway Ghosal",
        "Soujanya Poria"
      ],
      "abstract": "Traditional reinforcement learning-based robotic control methods are often\ntask-specific and fail to generalize across diverse environments or unseen\nobjects and instructions. Visual Language Models (VLMs) demonstrate strong\nscene understanding and planning capabilities but lack the ability to generate\nactionable policies tailored to specific robotic embodiments. To address this,\nVisual-Language-Action (VLA) models have emerged, yet they face challenges in\nlong-horizon spatial reasoning and grounded task planning. In this work, we\npropose the Embodied Multimodal Action Model with Grounded Chain of Thought and\nLook-ahead Spatial Reasoning, Emma-X. Emma-X leverages our constructed\nhierarchical embodiment dataset based on BridgeV2, containing 60,000 robot\nmanipulation trajectories auto-annotated with grounded task reasoning and\nspatial guidance. Additionally, we introduce a trajectory segmentation strategy\nbased on gripper states and motion trajectories, which can help mitigate\nhallucination in grounding subtask reasoning generation. Experimental results\ndemonstrate that Emma-X achieves superior performance over competitive\nbaselines, particularly in real-world robotic tasks requiring spatial\nreasoning.",
      "tldr_zh": "该研究针对传统强化学习方法和视觉语言模型(VLMs)的局限性，提出Emma-X模型，这是一种结合Grounded Chain of Thought和Look-ahead Spatial Reasoning的具身多模态动作模型，以提升机器人任务的泛化性和空间推理能力。Emma-X基于BridgeV2构建的层次化数据集，包含60,000个机器人操作轨迹，并引入基于gripper states和motion trajectories的轨迹分割策略，以减少hallucination并改善子任务推理的准确性。实验结果显示，Emma-X在需要空间推理的真实机器人任务中，显著优于竞争基线模型。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "https://github.com/declare-lab/Emma-X,\n  https://huggingface.co/declare-lab/Emma-X",
      "pdf_url": "http://arxiv.org/pdf/2412.11974v2",
      "published_date": "2024-12-16 16:58:28 UTC",
      "updated_date": "2024-12-17 14:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:18:30.801554"
    },
    {
      "arxiv_id": "2412.11959v2",
      "title": "Gramian Multimodal Representation Learning and Alignment",
      "title_zh": "Gramian 多模态表示学习与对齐",
      "authors": [
        "Giordano Cicchetti",
        "Eleonora Grassucci",
        "Luigi Sigillo",
        "Danilo Comminiello"
      ],
      "abstract": "Human perception integrates multiple modalities, such as vision, hearing, and\nlanguage, into a unified understanding of the surrounding reality. While recent\nmultimodal models have achieved significant progress by aligning pairs of\nmodalities via contrastive learning, their solutions are unsuitable when\nscaling to multiple modalities. These models typically align each modality to a\ndesignated anchor without ensuring the alignment of all modalities with each\nother, leading to suboptimal performance in tasks requiring a joint\nunderstanding of multiple modalities. In this paper, we structurally rethink\nthe pairwise conventional approach to multimodal learning and we present the\nnovel Gramian Representation Alignment Measure (GRAM), which overcomes the\nabove-mentioned limitations. GRAM learns and then aligns $n$ modalities\ndirectly in the higher-dimensional space in which modality embeddings lie by\nminimizing the Gramian volume of the $k$-dimensional parallelotope spanned by\nthe modality vectors, ensuring the geometric alignment of all modalities\nsimultaneously. GRAM can replace cosine similarity in any downstream method,\nholding for 2 to $n$ modalities and providing more meaningful alignment with\nrespect to previous similarity measures. The novel GRAM-based contrastive loss\nfunction enhances the alignment of multimodal models in the higher-dimensional\nembedding space, leading to new state-of-the-art performance in downstream\ntasks such as video-audio-text retrieval and audio-video classification. The\nproject page, the code, and the pretrained models are available at\nhttps://ispamm.github.io/GRAM/.",
      "tldr_zh": "该论文探讨了多模态表示学习和对齐问题，指出现有基于对比学习的模型在对齐多个模态（如视觉、听觉和语言）时，仅将每个模态对齐到一个锚点，导致整体对齐不佳。论文提出了一种新方法Gramian Representation Alignment Measure (GRAM)，通过在更高维空间中最小化模态向量张成的Gramian体积，实现所有模态的几何对齐，从而提升多模态模型的性能。实验结果显示，基于GRAM的对比损失函数在视频-音频-文本检索和音频-视频分类等下游任务上达到了新的state-of-the-art水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11959v2",
      "published_date": "2024-12-16 16:41:51 UTC",
      "updated_date": "2025-02-12 13:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:17:10.607280"
    },
    {
      "arxiv_id": "2412.11952v1",
      "title": "Advancing Comprehensive Aesthetic Insight with Multi-Scale Text-Guided Self-Supervised Learning",
      "title_zh": "利用多尺度",
      "authors": [
        "Yuti Liu",
        "Shice Liu",
        "Junyuan Gao",
        "Pengtao Jiang",
        "Hao Zhang",
        "Jinwei Chen",
        "Bo Li"
      ],
      "abstract": "Image Aesthetic Assessment (IAA) is a vital and intricate task that entails\nanalyzing and assessing an image's aesthetic values, and identifying its\nhighlights and areas for improvement. Traditional methods of IAA often\nconcentrate on a single aesthetic task and suffer from inadequate labeled\ndatasets, thus impairing in-depth aesthetic comprehension. Despite efforts to\novercome this challenge through the application of Multi-modal Large Language\nModels (MLLMs), such models remain underdeveloped for IAA purposes. To address\nthis, we propose a comprehensive aesthetic MLLM capable of nuanced aesthetic\ninsight. Central to our approach is an innovative multi-scale text-guided\nself-supervised learning technique. This technique features a multi-scale\nfeature alignment module and capitalizes on a wealth of unlabeled data in a\nself-supervised manner to structurally and functionally enhance aesthetic\nability. The empirical evidence indicates that accompanied with extensive\ninstruct-tuning, our model sets new state-of-the-art benchmarks across multiple\ntasks, including aesthetic scoring, aesthetic commenting, and personalized\nimage aesthetic assessment. Remarkably, it also demonstrates zero-shot learning\ncapabilities in the emerging task of aesthetic suggesting. Furthermore, for\npersonalized image aesthetic assessment, we harness the potential of in-context\nlearning and showcase its inherent advantages.",
      "tldr_zh": "这篇论文针对图像美学评估 (IAA) 的传统局限性，如单一任务焦点和标注数据不足，提出了一种全面的美学多模态大语言模型 (MLLMs)。核心方法是创新的多尺度文本引导自监督学习技术，包括多尺度特征对齐模块，利用无标签数据来提升模型的美学理解和功能。实验结果显示，该模型通过广泛的指令微调，在美学评分、美学评论和个性化图像美学评估等任务上设立了新的基准，并展示了零样本学习能力，尤其在美学建议任务上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11952v1",
      "published_date": "2024-12-16 16:35:35 UTC",
      "updated_date": "2024-12-16 16:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:17:22.732648"
    },
    {
      "arxiv_id": "2412.11951v1",
      "title": "The Impact of Generalization Techniques on the Interplay Among Privacy, Utility, and Fairness in Image Classification",
      "title_zh": "泛化技术对图像分类中隐私、效用和公平性之间相互作用的影响",
      "authors": [
        "Ahmad Hassanpour",
        "Amir Zarei",
        "Khawla Mallat",
        "Anderson Santana de Oliveira",
        "Bian Yang"
      ],
      "abstract": "This study investigates the trade-offs between fairness, privacy, and utility\nin image classification using machine learning (ML). Recent research suggests\nthat generalization techniques can improve the balance between privacy and\nutility. One focus of this work is sharpness-aware training (SAT) and its\nintegration with differential privacy (DP-SAT) to further improve this balance.\nAdditionally, we examine fairness in both private and non-private learning\nmodels trained on datasets with synthetic and real-world biases. We also\nmeasure the privacy risks involved in these scenarios by performing membership\ninference attacks (MIAs) and explore the consequences of eliminating\nhigh-privacy risk samples, termed outliers. Moreover, we introduce a new\nmetric, named \\emph{harmonic score}, which combines accuracy, privacy, and\nfairness into a single measure.\n  Through empirical analysis using generalization techniques, we achieve an\naccuracy of 81.11\\% under $(8, 10^{-5})$-DP on CIFAR-10, surpassing the 79.5\\%\nreported by De et al. (2022). Moreover, our experiments show that memorization\nof training samples can begin before the overfitting point, and generalization\ntechniques do not guarantee the prevention of this memorization. Our analysis\nof synthetic biases shows that generalization techniques can amplify model bias\nin both private and non-private models. Additionally, our results indicate that\nincreased bias in training data leads to reduced accuracy, greater\nvulnerability to privacy attacks, and higher model bias. We validate these\nfindings with the CelebA dataset, demonstrating that similar trends persist\nwith real-world attribute imbalances. Finally, our experiments show that\nremoving outlier data decreases accuracy and further amplifies model bias.",
      "tldr_zh": "本研究探讨了在图像分类任务中，generalization techniques（如sharpness-aware training (SAT)和differential privacy (DP-SAT)）对隐私、实用性和公平性之间相互作用的影响。研究引入了新的harmonic score指标，将准确性、隐私和公平性整合为单一衡量标准，并通过membership inference attacks (MIAs)评估隐私风险。实验结果显示，在CIFAR-10数据集上，使用DP-SAT实现了81.11%的准确率，超过了先前报告的79.5%。此外，研究发现generalization techniques可能放大模型偏差，尤其在存在合成或真实世界偏差（如CelebA数据集）时，且移除high-privacy risk样本（outliers）会降低准确性和加剧偏差。总体而言，此工作揭示了这些技术在平衡三者时的潜在局限性，为更公平和隐私友好的机器学习模型提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at the 25th Privacy Enhancing\n  Technologies Symposium (PETS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11951v1",
      "published_date": "2024-12-16 16:35:31 UTC",
      "updated_date": "2024-12-16 16:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:18:43.045877"
    },
    {
      "arxiv_id": "2412.11948v3",
      "title": "OpenReviewer: A Specialized Large Language Model for Generating Critical Scientific Paper Reviews",
      "title_zh": "OpenReviewer：一种用于生成批判性科学",
      "authors": [
        "Maximilian Idahl",
        "Zahra Ahmadi"
      ],
      "abstract": "We present OpenReviewer, an open-source system for generating high-quality\npeer reviews of machine learning and AI conference papers. At its core is\nLlama-OpenReviewer-8B, an 8B parameter language model specifically fine-tuned\non 79,000 expert reviews from top conferences. Given a PDF paper submission and\nreview template as input, OpenReviewer extracts the full text, including\ntechnical content like equations and tables, and generates a structured review\nfollowing conference-specific guidelines. Our evaluation on 400 test papers\nshows that OpenReviewer produces considerably more critical and realistic\nreviews compared to general-purpose LLMs like GPT-4 and Claude-3.5. While other\nLLMs tend toward overly positive assessments, OpenReviewer's recommendations\nclosely match the distribution of human reviewer ratings. The system provides\nauthors with rapid, constructive feedback to improve their manuscripts before\nsubmission, though it is not intended to replace human peer review.\nOpenReviewer is available as an online demo and open-source tool.",
      "tldr_zh": "本研究介绍了 OpenReviewer，一个开源系统，旨在生成高质量的机器学习和 AI 会议论文同行评审，其核心是基于 79,000 个专家评审微调的 Llama-OpenReviewer-8B 模型。系统接受 PDF 论文和评审模板作为输入，提取全文内容（如方程和表格），并生成符合会议指南的结构化评审。实验评估显示，在 400 个测试论文上，OpenReviewer 比通用 LLM 如 GPT-4 和 Claude-3.5 产生更批判、更真实的评审，推荐分布更接近人类评审者。该系统为作者提供快速建设性反馈以改进稿件，但不意在取代人类同行评审，并以在线演示和开源工具形式发布。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL 2025 System Demonstrations Track (Camera-ready version) Demo:\n  https://huggingface.co/spaces/maxidl/openreviewer Model:\n  https://huggingface.co/maxidl/Llama-OpenReviewer-8B",
      "pdf_url": "http://arxiv.org/pdf/2412.11948v3",
      "published_date": "2024-12-16 16:31:00 UTC",
      "updated_date": "2025-03-18 08:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:18:55.659748"
    },
    {
      "arxiv_id": "2412.11943v2",
      "title": "autrainer: A Modular and Extensible Deep Learning Toolkit for Computer Audition Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Rampp",
        "Andreas Triantafyllopoulos",
        "Manuel Milling",
        "Björn W. Schuller"
      ],
      "abstract": "This work introduces the key operating principles for autrainer, our new deep\nlearning training framework for computer audition tasks. autrainer is a\nPyTorch-based toolkit that allows for rapid, reproducible, and easily\nextensible training on a variety of different computer audition tasks.\nConcretely, autrainer offers low-code training and supports a wide range of\nneural networks as well as preprocessing routines. In this work, we present an\noverview of its inner workings and key capabilities.",
      "tldr_zh": "这篇论文介绍了 autrainer，一种基于 PyTorch 的模块化和可扩展深度学习工具包，专为计算机听觉任务设计。该工具包支持快速、可复现的训练，提供低代码接口，并兼容多种神经网络和预处理例程。作者概述了 autrainer 的内部工作原理和关键功能，从而便于研究者高效开发和扩展相关应用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11943v2",
      "published_date": "2024-12-16 16:25:58 UTC",
      "updated_date": "2025-04-10 13:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:19:05.737034"
    },
    {
      "arxiv_id": "2412.11939v1",
      "title": "SEAGraph: Unveiling the Whole Story of Paper Review Comments",
      "title_zh": "SEAGraph：揭示论文审阅评论的整个故事",
      "authors": [
        "Jianxiang Yu",
        "Jiaqi Tan",
        "Zichen Ding",
        "Jiapeng Zhu",
        "Jiahao Li",
        "Yao Cheng",
        "Qier Cui",
        "Yunshi Lan",
        "Xiang Li"
      ],
      "abstract": "Peer review, as a cornerstone of scientific research, ensures the integrity\nand quality of scholarly work by providing authors with objective feedback for\nrefinement. However, in the traditional peer review process, authors often\nreceive vague or insufficiently detailed feedback, which provides limited\nassistance and leads to a more time-consuming review cycle. If authors can\nidentify some specific weaknesses in their paper, they can not only address the\nreviewer's concerns but also improve their work. This raises the critical\nquestion of how to enhance authors' comprehension of review comments. In this\npaper, we present SEAGraph, a novel framework developed to clarify review\ncomments by uncovering the underlying intentions behind them. We construct two\ntypes of graphs for each paper: the semantic mind graph, which captures the\nauthor's thought process, and the hierarchical background graph, which\ndelineates the research domains related to the paper. A retrieval method is\nthen designed to extract relevant content from both graphs, facilitating\ncoherent explanations for the review comments. Extensive experiments show that\nSEAGraph excels in review comment understanding tasks, offering significant\nbenefits to authors.",
      "tldr_zh": "本研究针对同行评审过程中反馈模糊和细节不足的问题，提出 SEAGraph 框架，以揭示评审评论背后的潜在意图。具体而言，SEAGraph 通过构建 semantic mind graph（捕捉作者的思想过程）和 hierarchical background graph（描绘论文相关研究领域），并设计一种检索方法从这些图中提取相关内容，提供连贯的解释。实验结果表明，SEAGraph 在评审评论理解任务上表现出色，能显著提升作者的理解和改进效率。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11939v1",
      "published_date": "2024-12-16 16:24:36 UTC",
      "updated_date": "2024-12-16 16:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:19:17.837563"
    },
    {
      "arxiv_id": "2412.11934v3",
      "title": "Stepwise Reasoning Error Disruption Attack of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyu Peng",
        "Maolin Wang",
        "Xiangyu Zhao",
        "Kai Zhang",
        "Wanyu Wang",
        "Pengyue Jia",
        "Qidong Liu",
        "Ruocheng Guo",
        "Qi Liu"
      ],
      "abstract": "Large language models (LLMs) have made remarkable strides in complex\nreasoning tasks, but their safety and robustness in reasoning processes remain\nunderexplored. Existing attacks on LLM reasoning are constrained by specific\nsettings or lack of imperceptibility, limiting their feasibility and\ngeneralizability. To address these challenges, we propose the Stepwise\nrEasoning Error Disruption (SEED) attack, which subtly injects errors into\nprior reasoning steps to mislead the model into producing incorrect subsequent\nreasoning and final answers. Unlike previous methods, SEED is compatible with\nzero-shot and few-shot settings, maintains the natural reasoning flow, and\nensures covert execution without modifying the instruction. Extensive\nexperiments on four datasets across four different models demonstrate SEED's\neffectiveness, revealing the vulnerabilities of LLMs to disruptions in\nreasoning processes. These findings underscore the need for greater attention\nto the robustness of LLM reasoning to ensure safety in practical applications.",
      "tldr_zh": "这篇论文提出了一种名为 Stepwise rEasoning Error Disruption (SEED) 攻击方法，用于评估大型语言模型 (LLMs) 在推理过程中的安全性和鲁棒性。SEED 通过在先前的推理步骤中巧妙注入错误，误导模型产生错误的后续推理和最终答案，同时兼容 zero-shot 和 few-shot 设置，并保持自然的推理流程和指令隐蔽性。在四个数据集和四个模型上的广泛实验证明，SEED 有效揭示了 LLMs 的脆弱性，强调了在实际应用中加强推理鲁棒性的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11934v3",
      "published_date": "2024-12-16 16:20:41 UTC",
      "updated_date": "2025-03-10 06:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:19:30.235600"
    },
    {
      "arxiv_id": "2412.11930v1",
      "title": "Hierarchical Meta-Reinforcement Learning via Automated Macro-Action Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Minjae Cho",
        "Chuangchuang Sun"
      ],
      "abstract": "Meta-Reinforcement Learning (Meta-RL) enables fast adaptation to new testing\ntasks. Despite recent advancements, it is still challenging to learn performant\npolicies across multiple complex and high-dimensional tasks. To address this,\nwe propose a novel architecture with three hierarchical levels for 1) learning\ntask representations, 2) discovering task-agnostic macro-actions in an\nautomated manner, and 3) learning primitive actions. The macro-action can guide\nthe low-level primitive policy learning to more efficiently transition to goal\nstates. This can address the issue that the policy may forget previously\nlearned behavior while learning new, conflicting tasks. Moreover, the\ntask-agnostic nature of the macro-actions is enabled by removing task-specific\ncomponents from the state space. Hence, this makes them amenable to\nre-composition across different tasks and leads to promising fast adaptation to\nnew tasks. Also, the prospective instability from the tri-level hierarchies is\neffectively mitigated by our innovative, independently tailored training\nschemes. Experiments in the MetaWorld framework demonstrate the improved sample\nefficiency and success rate of our approach compared to previous\nstate-of-the-art methods.",
      "tldr_zh": "该论文提出了一种分层 Meta-Reinforcement Learning (Meta-RL) 架构，通过自动发现任务无关的宏动作（macro-actions），以解决在多个复杂高维任务中学习高效策略的挑战。该架构包括三个层次：学习任务表示、自动发现宏动作，以及学习原始动作（primitive actions），其中宏动作能指导低层策略更高效地过渡到目标状态，并缓解策略在学习新任务时遗忘先前行为的遗忘问题。通过从状态空间移除任务特定组件，宏动作实现了任务无关性，从而便于在不同任务间重组以实现快速适应。实验在 MetaWorld 框架中显示，该方法比现有最先进方法显著提高了样本效率和成功率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11930v1",
      "published_date": "2024-12-16 16:15:36 UTC",
      "updated_date": "2024-12-16 16:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:19:42.932072"
    },
    {
      "arxiv_id": "2412.11927v1",
      "title": "Explainable Procedural Mistake Detection",
      "title_zh": "可解释的过程错误检测",
      "authors": [
        "Shane Storks",
        "Itamar Bar-Yossef",
        "Yayuan Li",
        "Zheyuan Zhang",
        "Jason J. Corso",
        "Joyce Chai"
      ],
      "abstract": "Automated task guidance has recently attracted attention from the AI research\ncommunity. Procedural mistake detection (PMD) is a challenging sub-problem of\nclassifying whether a human user (observed through egocentric video) has\nsuccessfully executed the task at hand (specified by a procedural text).\nDespite significant efforts in building resources and models for PMD, machine\nperformance remains nonviable, and the reasoning processes underlying this\nperformance are opaque. As such, we recast PMD to an explanatory self-dialog of\nquestions and answers, which serve as evidence for a decision. As this\nreformulation enables an unprecedented transparency, we leverage a fine-tuned\nnatural language inference (NLI) model to formulate two automated coherence\nmetrics for generated explanations. Our results show that while open-source\nVLMs struggle with this task off-the-shelf, their accuracy, coherence, and\ndialog efficiency can be vastly improved by incorporating these coherence\nmetrics into common inference and fine-tuning methods. Furthermore, our\nmulti-faceted metrics can visualize common outcomes at a glance, highlighting\nareas for improvement.",
      "tldr_zh": "本论文针对Procedural Mistake Detection (PMD) 的挑战，将其重新表述为解释性的自对话形式（questions and answers），作为决策证据，以提升模型透明度。作者使用fine-tuned的Natural Language Inference (NLI)模型开发了两个自动化的coherence metrics来评估生成解释的连贯性。尽管开源的Vision-Language Models (VLMs) 初始在该任务上表现不佳，但通过将这些metrics整合到推理和fine-tuning方法中，显著提高了准确性、连贯性和对话效率。这些多方面指标还支持结果可视化，帮助快速识别改进领域。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11927v1",
      "published_date": "2024-12-16 16:13:55 UTC",
      "updated_date": "2024-12-16 16:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:19:55.162771"
    },
    {
      "arxiv_id": "2412.11923v2",
      "title": "PICLe: Pseudo-Annotations for In-Context Learning in Low-Resource Named Entity Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sepideh Mamooler",
        "Syrielle Montariol",
        "Alexander Mathis",
        "Antoine Bosselut"
      ],
      "abstract": "In-context learning (ICL) enables Large Language Models (LLMs) to perform\ntasks using few demonstrations, facilitating task adaptation when labeled\nexamples are hard to obtain. However, ICL is sensitive to the choice of\ndemonstrations, and it remains unclear which demonstration attributes enable\nin-context generalization. In this work, we conduct a perturbation study of\nin-context demonstrations for low-resource Named Entity Detection (NED). Our\nsurprising finding is that in-context demonstrations with partially correct\nannotated entity mentions can be as effective for task transfer as fully\ncorrect demonstrations. Based off our findings, we propose Pseudo-annotated\nIn-Context Learning (PICLe), a framework for in-context learning with noisy,\npseudo-annotated demonstrations. PICLe leverages LLMs to annotate many\ndemonstrations in a zero-shot first pass. We then cluster these synthetic\ndemonstrations, sample specific sets of in-context demonstrations from each\ncluster, and predict entity mentions using each set independently. Finally, we\nuse self-verification to select the final set of entity mentions. We evaluate\nPICLe on five biomedical NED datasets and show that, with zero human\nannotation, PICLe outperforms ICL in low-resource settings where limited gold\nexamples can be used as in-context demonstrations.",
      "tldr_zh": "本研究发现，在低资源 Named Entity Detection (NED) 中，In-Context Learning (ICL) 的演示示例即使部分正确也能有效进行任务转移。论文提出 PICLe 框架，利用 Large Language Models (LLMs) 在零样本条件下生成伪标注演示，然后通过聚类、采样独立预测和自我验证机制来优化实体识别过程。在五个生物医学 NED 数据集的评估中，PICLe 在无需人类标注的情况下，显著优于传统 ICL，尤其在低资源设置中提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In Proceedings of NAACL2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11923v2",
      "published_date": "2024-12-16 16:09:35 UTC",
      "updated_date": "2025-04-01 12:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:20:06.316661"
    },
    {
      "arxiv_id": "2412.11919v1",
      "title": "RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation",
      "title_zh": "RetroLLM：赋予大型语言模型在生成过程中检索细粒度证据的能力",
      "authors": [
        "Xiaoxi Li",
        "Jiajie Jin",
        "Yujia Zhou",
        "Yongkang Wu",
        "Zhonghua Li",
        "Qi Ye",
        "Zhicheng Dou"
      ],
      "abstract": "Large language models (LLMs) exhibit remarkable generative capabilities but\noften suffer from hallucinations. Retrieval-augmented generation (RAG) offers\nan effective solution by incorporating external knowledge, but existing methods\nstill face several limitations: additional deployment costs of separate\nretrievers, redundant input tokens from retrieved text chunks, and the lack of\njoint optimization of retrieval and generation. To address these issues, we\npropose \\textbf{RetroLLM}, a unified framework that integrates retrieval and\ngeneration into a single, cohesive process, enabling LLMs to directly generate\nfine-grained evidence from the corpus with constrained decoding. Moreover, to\nmitigate false pruning in the process of constrained evidence generation, we\nintroduce (1) hierarchical FM-Index constraints, which generate\ncorpus-constrained clues to identify a subset of relevant documents before\nevidence generation, reducing irrelevant decoding space; and (2) a\nforward-looking constrained decoding strategy, which considers the relevance of\nfuture sequences to improve evidence accuracy. Extensive experiments on five\nopen-domain QA datasets demonstrate RetroLLM's superior performance across both\nin-domain and out-of-domain tasks. The code is available at\n\\url{https://github.com/sunnynexus/RetroLLM}.",
      "tldr_zh": "该论文提出 RetroLLM 框架，以解决 Large Language Models (LLMs) 的幻觉问题，并克服现有 Retrieval-augmented Generation (RAG) 方法的局限性，如额外部署成本和检索生成脱节。RetroLLM 将检索和生成整合为一个统一过程，使用约束解码直接从语料库生成细粒度的证据。针对约束生成中的假剪枝问题，该框架引入层次化 FM-Index 约束来缩小相关文档子集，以及前瞻性约束解码策略以提升证据准确性。在五个开放域 QA 数据集上的实验表明，RetroLLM 在领域内和领域外任务上表现出优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11919v1",
      "published_date": "2024-12-16 16:03:25 UTC",
      "updated_date": "2024-12-16 16:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:20:19.292280"
    },
    {
      "arxiv_id": "2412.11906v1",
      "title": "PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Kun Ouyang",
        "Yuanxin Liu",
        "Shicheng Li",
        "Yi Liu",
        "Hao Zhou",
        "Fandong Meng",
        "Jie Zhou",
        "Xu Sun"
      ],
      "abstract": "Multimodal punchlines, which involve humor or sarcasm conveyed in\nimage-caption pairs, are a popular way of communication on online multimedia\nplatforms. With the rapid development of multimodal large language models\n(MLLMs), it is essential to assess their ability to effectively comprehend\nthese punchlines. However, existing benchmarks on punchline comprehension\nsuffer from three major limitations: 1) language shortcuts that allow models to\nsolely rely on text, 2) lack of question diversity, and 3) narrow focus on a\nspecific domain of multimodal content (e.g., cartoon). To address these\nlimitations, we introduce a multimodal \\textbf{Punch}line comprehension\n\\textbf{Bench}mark, named \\textbf{PunchBench}, which is tailored for accurate\nand comprehensive evaluation of punchline comprehension. To enhance the\nevaluation accuracy, we generate synonymous and antonymous captions by\nmodifying original captions, which mitigates the impact of shortcuts in the\ncaptions. To provide a comprehensive evaluation, PunchBench incorporates\ndiverse question formats and image-captions from various domains. On this\nbasis, we conduct extensive evaluations and reveal a significant gap between\nstate-of-the-art MLLMs and humans in punchline comprehension. To improve\npunchline comprehension, we propose Simple-to-Complex Chain-of-Question\n(SC-CoQ) strategy, enabling the models to incrementally address complicated\nquestions by first mastering simple ones. SC-CoQ effectively enhances the\nperformance of various MLLMs on PunchBench, surpassing in-context learning and\nchain-of-thought.",
      "tldr_zh": "该研究引入了PunchBench，一个针对多模态大型语言模型(MLLMs)在多模态幽默理解方面的基准测试，以解决现有基准的局限性，如语言捷径、问题多样性不足和领域单一性。PunchBench通过生成同义和反义标题来减少捷径影响，并整合多样化问题格式和各种领域的图像-标题对，实现更准确全面的评估。实验结果显示，现有的MLLMs在幽默理解上与人类存在显著差距。为提升性能，论文提出Simple-to-Complex Chain-of-Question (SC-CoQ)策略，让模型逐步从简单问题过渡到复杂问题，从而优于in-context learning和chain-of-thought方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11906v1",
      "published_date": "2024-12-16 15:52:59 UTC",
      "updated_date": "2024-12-16 15:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:20:30.571102"
    },
    {
      "arxiv_id": "2412.11888v1",
      "title": "GNN Applied to Ego-nets for Friend Suggestions",
      "title_zh": "翻译失败",
      "authors": [
        "Evgeny Zamyatin"
      ],
      "abstract": "A major problem of making friend suggestions in social networks is the large\nsize of social graphs, which can have hundreds of millions of people and tens\nof billions of connections. Classic methods based on heuristics or\nfactorizations are often used to address the difficulties of scaling more\ncomplex models. However, the unsupervised nature of these methods can lead to\nsuboptimal results. In this work, we introduce the Generalized Ego-network\nFriendship Score framework, which makes it possible to use complex supervised\nmodels without sacrificing scalability. The main principle of the framework is\nto reduce the problem of link prediction on a full graph to a series of\nlow-scale tasks on ego-nets with subsequent aggregation of their results. Here,\nthe underlying model takes an ego-net as input and produces a pairwise\nrelevance matrix for its nodes. In addition, we develop the WalkGNN model which\nis capable of working effectively in the social network domain, where these\ngraph-level link prediction tasks are heterogeneous, dynamic and featureless.\nTo measure the accuracy of this model, we introduce the Ego-VK dataset that\nserves as an exact representation of the real-world problem that we are\naddressing. Offline experiments on the dataset show that our model outperforms\nall baseline methods, and a live A/B test demonstrates the growth of business\nmetrics as a result of utilizing our approach.",
      "tldr_zh": "本研究针对社交网络中好友推荐的挑战（如大规模图结构），提出 Generalized Ego-network Friendship Score 框架，该框架将全图链接预测问题分解为在 ego-nets 上进行的小规模任务，并聚合结果，从而实现复杂监督模型的扩展性应用。具体而言，框架使用 WalkGNN 模型处理社交网络的异构、动态和无特征特性，生成节点对的相关性矩阵。实验在 Ego-VK 数据集上显示，WalkGNN 模型优于所有基线方法，并在在线 A/B 测试中提升了业务指标。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11888v1",
      "published_date": "2024-12-16 15:37:17 UTC",
      "updated_date": "2024-12-16 15:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:20:42.073619"
    },
    {
      "arxiv_id": "2412.11868v2",
      "title": "A Variable Occurrence-Centric Framework for Inconsistency Handling (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Yakoub Salhi"
      ],
      "abstract": "In this paper, we introduce a syntactic framework for analyzing and handling\ninconsistencies in propositional bases. Our approach focuses on examining the\nrelationships between variable occurrences within conflicts. We propose two\ndual concepts: Minimal Inconsistency Relation (MIR) and Maximal Consistency\nRelation (MCR). Each MIR is a minimal equivalence relation on variable\noccurrences that results in inconsistency, while each MCR is a maximal\nequivalence relation designed to prevent inconsistency. Notably, MIRs capture\nconflicts overlooked by minimal inconsistent subsets. Using MCRs, we develop a\nseries of non-explosive inference relations. The main strategy involves\nrestoring consistency by modifying the propositional base according to each\nMCR, followed by employing the classical inference relation to derive\nconclusions. Additionally, we propose an unusual semantics that assigns truth\nvalues to variable occurrences instead of the variables themselves. The\nassociated inference relations are established through Boolean interpretations\ncompatible with the occurrence-based models.",
      "tldr_zh": "这篇论文引入了一个以变量出现为中心的句法框架，用于分析和处理命题基础中的不一致性，焦点在于变量出现之间的关系。论文提出两个关键概念：Minimal Inconsistency Relation (MIR)，它是导致不一致的最小等价关系，能捕捉到最小不一致子集忽略的冲突；以及Maximal Consistency Relation (MCR)，它是防止不一致的最大等价关系。基于MCR，作者开发了一系列non-explosive inference relations，通过修改命题基础恢复一致性并应用经典推理得出结论。此外，论文提出了一种新颖的语义，将真值赋值给变量出现而非变量本身，并通过与基于出现的布尔解释兼容的模型建立相关的推理关系。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11868v2",
      "published_date": "2024-12-16 15:22:10 UTC",
      "updated_date": "2024-12-17 08:17:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:20:55.224748"
    },
    {
      "arxiv_id": "2412.11867v2",
      "title": "Transformers Use Causal World Models in Maze-Solving Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Alex F. Spies",
        "William Edwards",
        "Michael I. Ivanitskiy",
        "Adrians Skapars",
        "Tilman Räuker",
        "Katsumi Inoue",
        "Alessandra Russo",
        "Murray Shanahan"
      ],
      "abstract": "Recent studies in interpretability have explored the inner workings of\ntransformer models trained on tasks across various domains, often discovering\nthat these networks naturally develop highly structured representations. When\nsuch representations comprehensively reflect the task domain's structure, they\nare commonly referred to as \"World Models\" (WMs). In this work, we identify WMs\nin transformers trained on maze-solving tasks. By using Sparse Autoencoders\n(SAEs) and analyzing attention patterns, we examine the construction of WMs and\ndemonstrate consistency between SAE feature-based and circuit-based analyses.\nBy subsequently intervening on isolated features to confirm their causal role,\nwe find that it is easier to activate features than to suppress them.\nFurthermore, we find that models can reason about mazes involving more\nsimultaneously active features than they encountered during training; however,\nwhen these same mazes (with greater numbers of connections) are provided to\nmodels via input tokens instead, the models fail. Finally, we demonstrate that\npositional encoding schemes appear to influence how World Models are structured\nwithin the model's residual stream.",
      "tldr_zh": "本研究探讨了 transformer 模型在迷宫求解任务中如何开发和利用因果 World Models (WMs)，这些模型通过高度结构化的表示反映任务领域。研究者使用 Sparse Autoencoders (SAEs) 和注意力模式分析来检查 WMs 的构建，并证实了 SAE 特征分析与电路分析的一致性；此外，通过干预隔离特征，发现激活特征比抑制特征更容易。实验结果显示，模型能在训练中未遇到的涉及更多活跃特征的迷宫上进行推理，但当这些迷宫通过输入标记提供时，模型会失败；同时，位置编码方案会影响 WMs 在模型残差流中的结构。该工作为理解 transformer 的内部机制和泛化能力提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Main paper: 9 pages, 9 figures. Supplementary material: 10 pages, 17\n  additional figures. Code and data will be available upon publication.\n  Corresponding author: A. F. Spies (afspies@imperial.ac.uk)",
      "pdf_url": "http://arxiv.org/pdf/2412.11867v2",
      "published_date": "2024-12-16 15:21:04 UTC",
      "updated_date": "2025-03-05 23:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:21:06.328651"
    },
    {
      "arxiv_id": "2412.11864v1",
      "title": "Investigating Mixture of Experts in Dense Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Effrosyni Sokli",
        "Pranav Kasela",
        "Georgios Peikos",
        "Gabriella Pasi"
      ],
      "abstract": "While Dense Retrieval Models (DRMs) have advanced Information Retrieval (IR),\none limitation of these neural models is their narrow generalizability and\nrobustness. To cope with this issue, one can leverage the Mixture-of-Experts\n(MoE) architecture. While previous IR studies have incorporated MoE\narchitectures within the Transformer layers of DRMs, our work investigates an\narchitecture that integrates a single MoE block (SB-MoE) after the output of\nthe final Transformer layer. Our empirical evaluation investigates how SB-MoE\ncompares, in terms of retrieval effectiveness, to standard fine-tuning. In\ndetail, we fine-tune three DRMs (TinyBERT, BERT, and Contriever) across four\nbenchmark collections with and without adding the MoE block. Moreover, since\nMoE showcases performance variations with respect to its parameters (i.e., the\nnumber of experts), we conduct additional experiments to investigate this\naspect further. The findings show the effectiveness of SB-MoE especially for\nDRMs with a low number of parameters (i.e., TinyBERT), as it consistently\noutperforms the fine-tuned underlying model on all four benchmarks. For DRMs\nwith a higher number of parameters (i.e., BERT and Contriever), SB-MoE requires\nlarger numbers of training samples to yield better retrieval performance.",
      "tldr_zh": "本论文调查了在Dense Retrieval Models (DRMs) 中整合Mixture-of-Experts (MoE) 架构，以提升模型的一般化和鲁棒性，特别提出了一种在最终Transformer层输出后添加单个MoE块 (SB-MoE) 的新方法。\n研究者对TinyBERT、BERT和Contriever等DRMs在四个基准集合上进行了微调实验，比较了添加SB-MoE前后在检索效果上的表现，并探讨了MoE参数（如专家数量）的影响。\n结果表明，SB-MoE对参数较少的DRMs（如TinyBERT）特别有效，能够在所有基准上优于标准微调模型，而对于参数较多的DRMs（如BERT和Contriever），则需要更多训练样本才能实现性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11864v1",
      "published_date": "2024-12-16 15:20:13 UTC",
      "updated_date": "2024-12-16 15:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:21:19.678921"
    },
    {
      "arxiv_id": "2412.11855v2",
      "title": "A Theory of Formalisms for Representing Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Heng Zhang",
        "Guifei Jiang",
        "Donghui Quan"
      ],
      "abstract": "There has been a longstanding dispute over which formalism is the best for\nrepresenting knowledge in AI. The well-known \"declarative vs. procedural\ncontroversy\" is concerned with the choice of utilizing declarations or\nprocedures as the primary mode of knowledge representation. The ongoing debate\nbetween symbolic AI and connectionist AI also revolves around the question of\nwhether knowledge should be represented implicitly (e.g., as parametric\nknowledge in deep learning and large language models) or explicitly (e.g., as\nlogical theories in traditional knowledge representation and reasoning). To\naddress these issues, we propose a general framework to capture various\nknowledge representation formalisms in which we are interested. Within the\nframework, we find a family of universal knowledge representation formalisms,\nand prove that all universal formalisms are recursively isomorphic. Moreover,\nwe show that all pairwise intertranslatable formalisms that admit the padding\nproperty are also recursively isomorphic. These imply that, up to an offline\ncompilation, all universal (or natural and equally expressive) representation\nformalisms are in fact the same, which thus provides a partial answer to the\naforementioned dispute.",
      "tldr_zh": "这篇论文探讨了AI领域中知识表示形式主义的长期争论，包括“declarative vs. procedural controversy”以及symbolic AI与connectionist AI之间的隐式 vs. 显式表示问题。为了解决这些争议，作者提出一个通用框架，用于捕捉各种知识表示形式主义。在该框架中，他们发现一族通用知识表示形式主义，并证明这些形式主义是recursively isomorphic的。此外，论文证明所有成对可互译的形式主义（如果满足padding property）也具有递归同构性，从而表明在离线编译下，所有通用或同样 expressive 的形式主义本质上相同，为上述争论提供了部分答案。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper to appear in AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2412.11855v2",
      "published_date": "2024-12-16 15:13:30 UTC",
      "updated_date": "2024-12-29 13:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:21:30.645163"
    },
    {
      "arxiv_id": "2412.11834v3",
      "title": "Wonderful Matrices: Combining for a More Efficient and Effective Foundation Model Architecture",
      "title_zh": "Wonderful Matrices: 组合以实现更高效、更有效的基础模型架构",
      "authors": [
        "Jingze Shi",
        "Bingheng Wu"
      ],
      "abstract": "In order to make the foundation model more efficient and effective, our idea\nis combining sequence transformation and state transformation. First, we prove\nthe availability of rotary position embedding in the state space duality\nalgorithm, which reduces the perplexity of the hybrid quadratic causal\nself-attention and state space duality by more than 4%, to ensure that the\ncombining sequence transformation unifies position encoding. Second, we propose\ndynamic mask attention, which maintains 100% accuracy in the more challenging\nmulti-query associative recall task, improving by more than 150% compared to\nquadratic causal self-attention and state space duality, to ensure that the\ncombining sequence transformation selectively filters relevant information.\nThird, we design cross domain mixture of experts, which makes the computational\nspeed of expert retrieval with more than 1024 experts 8 to 10 times faster than\nthe mixture of experts, to ensure that the combining state transformation\nquickly retrieval mixture. Finally, we summarize these matrix algorithms that\ncan form the foundation model: Wonderful Matrices, which can be a competitor to\npopular model architectures.",
      "tldr_zh": "该论文提出了一种名为“Wonderful Matrices”的基础模型架构，通过结合序列转换和状态转换来提升模型的效率和效果。首先，作者证明了rotary position embedding在state space duality算法中的可用性，降低了hybrid quadratic causal self-attention和state space duality的困惑度超过4%，从而统一了位置编码。其次，引入dynamic mask attention，确保在多查询关联回忆任务中保持100%准确率，比现有方法提高150%以上，并选择性地过滤信息；同时，设计了cross domain mixture of experts，使专家检索速度比传统mixture of experts快8到10倍。总体上，这些矩阵算法形成了“Wonderful Matrices”，作为流行模型架构的潜在竞争者。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "The code is open-sourced at\n  https://github.com/LoserCheems/WonderfulMatrices",
      "pdf_url": "http://arxiv.org/pdf/2412.11834v3",
      "published_date": "2024-12-16 14:56:28 UTC",
      "updated_date": "2024-12-20 11:43:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:21:43.164397"
    },
    {
      "arxiv_id": "2412.12232v1",
      "title": "You Only Submit One Image to Find the Most Suitable Generative Model",
      "title_zh": "只需提交一张图像即可找到最合适的生成模型",
      "authors": [
        "Zhi Zhou",
        "Lan-Zhe Guo",
        "Peng-Xiao Song",
        "Yu-Feng Li"
      ],
      "abstract": "Deep generative models have achieved promising results in image generation,\nand various generative model hubs, e.g., Hugging Face and Civitai, have been\ndeveloped that enable model developers to upload models and users to download\nmodels. However, these model hubs lack advanced model management and\nidentification mechanisms, resulting in users only searching for models through\ntext matching, download sorting, etc., making it difficult to efficiently find\nthe model that best meets user requirements. In this paper, we propose a novel\nsetting called Generative Model Identification (GMI), which aims to enable the\nuser to identify the most appropriate generative model(s) for the user's\nrequirements from a large number of candidate models efficiently. To our best\nknowledge, it has not been studied yet. In this paper, we introduce a\ncomprehensive solution consisting of three pivotal modules: a weighted Reduced\nKernel Mean Embedding (RKME) framework for capturing the generated image\ndistribution and the relationship between images and prompts, a pre-trained\nvision-language model aimed at addressing dimensionality challenges, and an\nimage interrogator designed to tackle cross-modality issues. Extensive\nempirical results demonstrate the proposal is both efficient and effective. For\nexample, users only need to submit a single example image to describe their\nrequirements, and the model platform can achieve an average top-4\nidentification accuracy of more than 80%.",
      "tldr_zh": "该论文提出了一种新的设置Generative Model Identification (GMI)，旨在帮助用户从大量生成模型中高效识别最适合其需求的模型，解决现有模型中心（如Hugging Face）依赖文本匹配等低效方法的痛点。核心解决方案包括三个模块：weighted Reduced Kernel Mean Embedding (RKME)框架用于捕捉图像分布及图像与提示的关系、预训练vision-language model处理维度挑战，以及image interrogator解决跨模态问题。实验结果显示，该方法高效有效，用户只需提交一张示例图像，即可实现平均top-4识别准确率超过80%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2023 Workshop on Diffusion Models",
      "pdf_url": "http://arxiv.org/pdf/2412.12232v1",
      "published_date": "2024-12-16 14:46:57 UTC",
      "updated_date": "2024-12-16 14:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:21:53.907034"
    },
    {
      "arxiv_id": "2412.14203v1",
      "title": "BlenderLLM: Training Large Language Models for Computer-Aided Design with Self-improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Du",
        "Shunian Chen",
        "Wenbo Zan",
        "Peizhao Li",
        "Mingxuan Wang",
        "Dingjie Song",
        "Bo Li",
        "Yan Hu",
        "Benyou Wang"
      ],
      "abstract": "The application of Large Language Models (LLMs) in Computer-Aided Design\n(CAD) remains an underexplored area, despite their remarkable advancements in\nother domains. In this paper, we present BlenderLLM, a novel framework for\ntraining LLMs specifically for CAD tasks leveraging a self-improvement\nmethodology. To support this, we developed a bespoke training dataset,\nBlendNet, and introduced a comprehensive evaluation suite, CADBench. Our\nresults reveal that existing models demonstrate significant limitations in\ngenerating accurate CAD scripts. However, through minimal instruction-based\nfine-tuning and iterative self-improvement, BlenderLLM significantly surpasses\nthese models in both functionality and accuracy of CAD script generation. This\nresearch establishes a strong foundation for the application of LLMs in CAD\nwhile demonstrating the transformative potential of self-improving models in\nadvancing CAD automation. We encourage further exploration and adoption of\nthese methodologies to drive innovation in the field. The dataset, model,\nbenchmark, and source code are publicly available at\nhttps://github.com/FreedomIntelligence/BlenderLLM",
      "tldr_zh": "该研究探讨了Large Language Models (LLMs) 在Computer-Aided Design (CAD) 领域的应用，提出BlenderLLM框架，通过自改进(self-improvement)方法训练LLMs 以生成准确的CAD脚本。研究团队构建了专属训练数据集BlendNet 和全面评估套件CADBench，以评估现有模型的局限性。实验结果显示，通过最小指令微调和迭代自改进，BlenderLLM 在CAD脚本的功能性和准确性上大幅超越基线模型，为LLMs在CAD自动化中的应用奠定坚实基础；相关数据集、模型、基准和源代码已公开可用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.14203v1",
      "published_date": "2024-12-16 14:34:02 UTC",
      "updated_date": "2024-12-16 14:34:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:22:06.614589"
    },
    {
      "arxiv_id": "2412.11807v2",
      "title": "PhysAug: A Physical-guided and Frequency-based Data Augmentation for Single-Domain Generalized Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoran Xu",
        "Jiangang Yang",
        "Wenhui Shi",
        "Siyuan Ding",
        "Luqing Luo",
        "Jian Liu"
      ],
      "abstract": "Single-Domain Generalized Object Detection~(S-DGOD) aims to train on a single\nsource domain for robust performance across a variety of unseen target domains\nby taking advantage of an object detector. Existing S-DGOD approaches often\nrely on data augmentation strategies, including a composition of visual\ntransformations, to enhance the detector's generalization ability. However, the\nabsence of real-world prior knowledge hinders data augmentation from\ncontributing to the diversity of training data distributions. To address this\nissue, we propose PhysAug, a novel physical model-based non-ideal imaging\ncondition data augmentation method, to enhance the adaptability of the S-DGOD\ntasks. Drawing upon the principles of atmospheric optics, we develop a\nuniversal perturbation model that serves as the foundation for our proposed\nPhysAug. Given that visual perturbations typically arise from the interaction\nof light with atmospheric particles, the image frequency spectrum is harnessed\nto simulate real-world variations during training. This approach fosters the\ndetector to learn domain-invariant representations, thereby enhancing its\nability to generalize across various settings. Without altering the network\narchitecture or loss function, our approach significantly outperforms the\nstate-of-the-art across various S-DGOD datasets. In particular, it achieves a\nsubstantial improvement of $7.3\\%$ and $7.2\\%$ over the baseline on DWD and\nCityscape-C, highlighting its enhanced generalizability in real-world settings.",
      "tldr_zh": "本论文针对 Single-Domain Generalized Object Detection (S-DGOD) 提出了一种基于物理模型和图像频谱的数据增强方法 PhysAug，以解决现有策略缺乏真实世界先验知识的问题。PhysAug 利用大气光学原理构建通用扰动模型，通过模拟图像频谱中的真实变异，帮助检测器学习域不变表示，从而提升其在未见目标域上的泛化性能。该方法无需改变网络架构或损失函数，即在各种 S-DGOD 数据集上显著超越最先进方法，特别是在 DWD 和 Cityscape-C 上分别实现了 7.3% 和 7.2% 的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI,2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11807v2",
      "published_date": "2024-12-16 14:18:01 UTC",
      "updated_date": "2025-02-21 03:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:22:19.740893"
    },
    {
      "arxiv_id": "2412.11802v1",
      "title": "AMI-Net: Adaptive Mask Inpainting Network for Industrial Anomaly Detection and Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Luo",
        "Haiming Yao",
        "Wenyong Yu",
        "Zhengyong Li"
      ],
      "abstract": "Unsupervised visual anomaly detection is crucial for enhancing industrial\nproduction quality and efficiency. Among unsupervised methods, reconstruction\napproaches are popular due to their simplicity and effectiveness. The key\naspect of reconstruction methods lies in the restoration of anomalous regions,\nwhich current methods have not satisfactorily achieved. To tackle this issue,\nwe introduce a novel \\uline{A}daptive \\uline{M}ask \\uline{I}npainting\n\\uline{Net}work (AMI-Net) from the perspective of adaptive mask-inpainting. In\ncontrast to traditional reconstruction methods that treat non-semantic image\npixels as targets, our method uses a pre-trained network to extract multi-scale\nsemantic features as reconstruction targets. Given the multiscale nature of\nindustrial defects, we incorporate a training strategy involving random\npositional and quantitative masking. Moreover, we propose an innovative\nadaptive mask generator capable of generating adaptive masks that effectively\nmask anomalous regions while preserving normal regions. In this manner, the\nmodel can leverage the visible normal global contextual information to restore\nthe masked anomalous regions, thereby effectively suppressing the\nreconstruction of defects. Extensive experimental results on the MVTec AD and\nBTAD industrial datasets validate the effectiveness of the proposed method.\nAdditionally, AMI-Net exhibits exceptional real-time performance, striking a\nfavorable balance between detection accuracy and speed, rendering it highly\nsuitable for industrial applications. Code is available at:\nhttps://github.com/luow23/AMI-Net",
      "tldr_zh": "该论文针对无监督视觉异常检测问题，提出了一种新型的自适应掩码填充网络（AMI-Net），以提升工业异常检测和定位的准确性。AMI-Net 使用预训练网络提取多尺度语义特征作为重建目标，并引入随机位置和数量掩码的训练策略，以及一个创新的自适应掩码生成器，来有效掩盖异常区域同时保留正常区域，从而抑制缺陷的重建。实验在 MVTec AD 和 BTAD 工业数据集上验证了该方法的有效性，实现了比传统重建方法更高的准确率，并展现出优秀的实时性能，使其适用于实际工业应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Automation Science and\n  Engineering.Code is available at: https://github.com/luow23/AMI-Net",
      "pdf_url": "http://arxiv.org/pdf/2412.11802v1",
      "published_date": "2024-12-16 14:12:06 UTC",
      "updated_date": "2024-12-16 14:12:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:22:30.081091"
    },
    {
      "arxiv_id": "2412.11787v1",
      "title": "A Method for Detecting Legal Article Competition for Korean Criminal Law Using a Case-augmented Mention Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Seonho An",
        "Young Yik Rhim",
        "Min-Soo Kim"
      ],
      "abstract": "As social systems become increasingly complex, legal articles are also\ngrowing more intricate, making it progressively harder for humans to identify\nany potential competitions among them, particularly when drafting new laws or\napplying existing laws. Despite this challenge, no method for detecting such\ncompetitions has been proposed so far. In this paper, we propose a new legal AI\ntask called Legal Article Competition Detection (LACD), which aims to identify\ncompeting articles within a given law. Our novel retrieval method, CAM-Re2,\noutperforms existing relevant methods, reducing false positives by 20.8% and\nfalse negatives by 8.3%, while achieving a 98.2% improvement in precision@5,\nfor the LACD task. We release our codes at\nhttps://github.com/asmath472/LACD-public.",
      "tldr_zh": "本研究针对韩国刑法中法律条文的复杂性，提出了一种新任务Legal Article Competition Detection (LACD)，旨在自动识别给定法律中的竞争条文，以解决人类在起草或应用法律时面临的识别难题。该方法引入了CAM-Re2，一种基于Case-augmented Mention Graph的检索技术，显著优于现有方法，减少了假阳性20.8%和假阴性8.3%。实验结果显示，CAM-Re2将precision@5提高了98.2%，并通过开源代码（https://github.com/asmath472/LACD-public）促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2412.11787v1",
      "published_date": "2024-12-16 13:59:10 UTC",
      "updated_date": "2024-12-16 13:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:22:41.990894"
    },
    {
      "arxiv_id": "2501.10377v1",
      "title": "The Three Social Dimensions of Chatbot Technology",
      "title_zh": "聊天机器人技术的三个社会维度",
      "authors": [
        "Mauricio Figueroa-Torres"
      ],
      "abstract": "The development and deployment of chatbot technology, while spanning decades\nand employing different techniques, require innovative frameworks to understand\nand interrogate their functionality and implications. A mere technocentric\naccount of the evolution of chatbot technology does not fully illuminate how\nconversational systems are embedded in societal dynamics. This study presents a\nstructured examination of chatbots across three societal dimensions,\nhighlighting their roles as objects of scientific research, commercial\ninstruments, and agents of intimate interaction. Through furnishing a\ndimensional framework for the evolution of conversational systems, from\nlaboratories to marketplaces to private lives, this article contributes to the\nwider scholarly inquiry of chatbot technology and its impact in lived human\nexperiences and dynamics.",
      "tldr_zh": "这篇论文探讨了聊天机器人技术（chatbot technology）的三个社会维度：作为科学研究对象、商业工具和亲密互动代理。它提出一个结构化的维度框架，分析聊天机器人从实验室到市场再到私人生活的演变过程，从而揭示其在社会动态中的嵌入作用。主要贡献在于为学术界提供了一个创新工具，以更全面地审视聊天机器人对人类生活的影响和含义。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "I.2; J.4; K.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.10377v1",
      "published_date": "2024-12-16 13:45:53 UTC",
      "updated_date": "2024-12-16 13:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:22:53.188265"
    },
    {
      "arxiv_id": "2412.11769v1",
      "title": "Does it Chug? Towards a Data-Driven Understanding of Guitar Tone Description",
      "title_zh": "翻译失败",
      "authors": [
        "Pratik Sutar",
        "Jason Naradowsky",
        "Yusuke Miyao"
      ],
      "abstract": "Natural language is commonly used to describe instrument timbre, such as a\n\"warm\" or \"heavy\" sound. As these descriptors are based on human perception,\nthere can be disagreement over which acoustic features correspond to a given\nadjective. In this work, we pursue a data-driven approach to further our\nunderstanding of such adjectives in the context of guitar tone. Our main\ncontribution is a dataset of timbre adjectives, constructed by processing\nsingle clips of instrument audio to produce varied timbres through adjustments\nin EQ and effects such as distortion. Adjective annotations are obtained for\neach clip by crowdsourcing experts to complete a pairwise comparison and a\nlabeling task. We examine the dataset and reveal correlations between adjective\nratings and highlight instances where the data contradicts prevailing theories\non spectral features and timbral adjectives, suggesting a need for a more\nnuanced, data-driven understanding of timbre.",
      "tldr_zh": "这篇论文采用数据驱动方法，探讨吉他音色描述的形容词（如“warm”或“heavy”），旨在解决这些基于人类感知的描述可能存在的分歧。研究者构建了一个数据集，通过处理单段音频片段（调整EQ和effects如distortion）来产生多样音色，并利用crowdsourcing专家进行配对比较和标注任务。分析结果揭示了形容词评分与声学特征的相关性，并指出数据与现有关于spectral features和timbral adjectives的理论存在矛盾，强调需要更细致的数据驱动理解。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted for publication at the 3rd Workshop on NLP for Music and\n  Audio (NLP4MusA 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.11769v1",
      "published_date": "2024-12-16 13:44:19 UTC",
      "updated_date": "2024-12-16 13:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:23:06.280778"
    },
    {
      "arxiv_id": "2412.11768v2",
      "title": "No More Adam: Learning Rate Scaling at Initialization is All You Need",
      "title_zh": "不再需要 Adam：初始化时的学习率缩放就是你所需要的全部",
      "authors": [
        "Minghao Xu",
        "Lichuan Xiang",
        "Xu Cai",
        "Hongkai Wen"
      ],
      "abstract": "In this work, we question the necessity of adaptive gradient methods for\ntraining deep neural networks. SGD-SaI is a simple yet effective enhancement to\nstochastic gradient descent with momentum (SGDM). SGD-SaI performs learning\nrate Scaling at Initialization (SaI) to distinct parameter groups, guided by\ntheir respective gradient signal-to-noise ratios (g-SNR). By adjusting learning\nrates without relying on adaptive second-order momentum, SGD-SaI helps prevent\ntraining imbalances from the very first iteration and cuts the optimizer's\nmemory usage by half compared to AdamW. Despite its simplicity and efficiency,\nSGD-SaI consistently matches or outperforms AdamW in training a variety of\nTransformer-based tasks, effectively overcoming a long-standing challenge of\nusing SGD for training Transformers. SGD-SaI excels in ImageNet-1K\nclassification with Vision Transformers(ViT) and GPT-2 pretraining for large\nlanguage models (LLMs, transformer decoder-only), demonstrating robustness to\nhyperparameter variations and practicality for diverse applications. We further\ntested its robustness on tasks like LoRA fine-tuning for LLMs and diffusion\nmodels, where it consistently outperforms state-of-the-art optimizers. From a\nmemory efficiency perspective, SGD-SaI achieves substantial memory savings for\noptimizer states, reducing memory usage by 5.93 GB for GPT-2 (1.5B parameters)\nand 25.15 GB for Llama2-7B compared to AdamW in full-precision training\nsettings.",
      "tldr_zh": "本研究质疑自适应梯度方法的必要性，提出SGD-SaI优化器，这是一种对随机梯度下降动量(SGDM)的简单增强，通过在初始化时根据梯度信号噪声比(g-SNR)对不同参数组进行学习率缩放(SaI)，从而从第一迭代开始防止训练不平衡并将优化器内存使用减半。相比AdamW，SGD-SaI在各种Transformer-based任务中表现出色或更优，包括ImageNet-1K分类、GPT-2预训练以及LoRA细调和扩散模型。实验结果显示，SGD-SaI在鲁棒性和超参数变异方面更具优势，并显著节省内存，例如在GPT-2 (1.5B参数)上节省5.93 GB，在Llama2-7B上节省25.15 GB。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11768v2",
      "published_date": "2024-12-16 13:41:37 UTC",
      "updated_date": "2024-12-17 09:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:23:19.539739"
    },
    {
      "arxiv_id": "2412.11761v2",
      "title": "Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control",
      "title_zh": "利用语言进行协调：LLM驱动的多智能体控制框架和基准",
      "authors": [
        "Timothée Anne",
        "Noah Syrkis",
        "Meriem Elhosni",
        "Florian Turati",
        "Franck Legendre",
        "Alain Jaquier",
        "Sebastian Risi"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious tasks. Their potential to facilitate human coordination with many\nagents is a promising but largely under-explored area. Such capabilities would\nbe helpful in disaster response, urban planning, and real-time strategy\nscenarios. In this work, we introduce (1) a real-time strategy game benchmark\ndesigned to evaluate these abilities and (2) a novel framework we term HIVE.\nHIVE empowers a single human to coordinate swarms of up to 2,000 agents through\na natural language dialog with an LLM. We present promising results on this\nmulti-agent benchmark, with our hybrid approach solving tasks such as\ncoordinating agent movements, exploiting unit weaknesses, leveraging human\nannotations, and understanding terrain and strategic points. Our findings also\nhighlight critical limitations of current models, including difficulties in\nprocessing spatial visual information and challenges in formulating long-term\nstrategic plans. This work sheds light on the potential and limitations of LLMs\nin human-swarm coordination, paving the way for future research in this area.\nThe HIVE project page, hive.syrkis.com, includes videos of the system in\naction.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)在协调多代理方面的潜力，引入了HIVE框架和一个实时策略游戏基准，以评估LLMs在人类-代理协调中的表现。HIVE框架允许一个人类通过自然语言对话控制多达2,000个代理，成功处理任务如代理移动、利用单位弱点、理解地形和战略点。实验结果显示，该方法在基准上表现出色，但也揭示了LLMs在处理空间视觉信息和制定长期战略计划方面的关键局限性，为未来LLMs驱动的多代理控制研究铺平了道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11761v2",
      "published_date": "2024-12-16 13:25:42 UTC",
      "updated_date": "2025-04-22 11:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:23:31.152265"
    },
    {
      "arxiv_id": "2412.11753v1",
      "title": "DriveGazen: Event-Based Driving Status Recognition using Conventional Camera",
      "title_zh": "DriveGazen：基于事件的驾驶状态识别，使用传统相机",
      "authors": [
        "Xiaoyin Yang"
      ],
      "abstract": "We introduce a wearable driving status recognition device and our open-source\ndataset, along with a new real-time method robust to changes in lighting\nconditions for identifying driving status from eye observations of drivers. The\ncore of our method is generating event frames from conventional intensity\nframes, and the other is a newly designed Attention Driving State Network\n(ADSN). Compared to event cameras, conventional cameras offer complete\ninformation and lower hardware costs, enabling captured frames to encode rich\nspatial information. However, these textures lack temporal information, posing\nchallenges in effectively identifying driving status. DriveGazen addresses this\nissue from three perspectives. First, we utilize video frames to generate\nrealistic synthetic dynamic vision sensor (DVS) events. Second, we adopt a\nspiking neural network to decode pertinent temporal information. Lastly, ADSN\nextracts crucial spatial cues from corresponding intensity frames and conveys\nspatial attention to convolutional spiking layers during both training and\ninference through a novel guide attention module to guide the feature learning\nand feature enhancement of the event frame. We specifically collected the\nDriving Status (DriveGaze) dataset to demonstrate the effectiveness of our\napproach. Additionally, we validate the superiority of the DriveGazen on the\nSingle-eye Event-based Emotion (SEE) dataset. To the best of our knowledge, our\nmethod is the first to utilize guide attention spiking neural networks and\neye-based event frames generated from conventional cameras for driving status\nrecognition. Please refer to our project page for more details:\nhttps://github.com/TooyoungALEX/AAAI25-DriveGazen.",
      "tldr_zh": "本研究引入了DriveGazen，一种基于常规相机的Event-Based驾驶状态识别系统，以及一个开源的Driving Status (DriveGaze)数据集。该方法通过从常规强度帧生成合成DVS Events，并结合新设计的Attention Driving State Network (ADSN)，解决了传统相机缺乏时间信息的问题，其中包括采用Spiking Neural Network解码时间数据，并通过Guide Attention Module增强空间特征学习。实验结果显示，该系统在DriveGaze和SEE数据集上表现出色，对光照变化具有鲁棒性，并首次实现了使用引导注意力尖峰神经网络从常规相机生成的事件帧进行驾驶状态识别。总的来说，DriveGazen为实时、可穿戴的驾驶监控技术提供了高效且低成本的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures, (AAAI25)The 39th Annual AAAI Conference on\n  Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2412.11753v1",
      "published_date": "2024-12-16 13:12:11 UTC",
      "updated_date": "2024-12-16 13:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:23:42.980972"
    },
    {
      "arxiv_id": "2412.11735v2",
      "title": "Transferable Adversarial Face Attack with Text Controlled Attribute",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyun Li",
        "Zheng Zhang",
        "Xiangyuan Lan",
        "Dongmei Jiang"
      ],
      "abstract": "Traditional adversarial attacks typically produce adversarial examples under\nnorm-constrained conditions, whereas unrestricted adversarial examples are\nfree-form with semantically meaningful perturbations. Current unrestricted\nadversarial impersonation attacks exhibit limited control over adversarial face\nattributes and often suffer from low transferability. In this paper, we propose\na novel Text Controlled Attribute Attack (TCA$^2$) to generate photorealistic\nadversarial impersonation faces guided by natural language. Specifically, the\ncategory-level personal softmax vector is employed to precisely guide the\nimpersonation attacks. Additionally, we propose both data and model\naugmentation strategies to achieve transferable attacks on unknown target\nmodels. Finally, a generative model, \\textit{i.e}, Style-GAN, is utilized to\nsynthesize impersonated faces with desired attributes. Extensive experiments on\ntwo high-resolution face recognition datasets validate that our TCA$^2$ method\ncan generate natural text-guided adversarial impersonation faces with high\ntransferability. We also evaluate our method on real-world face recognition\nsystems, \\textit{i.e}, Face++ and Aliyun, further demonstrating the practical\npotential of our approach.",
      "tldr_zh": "该研究提出了一种新型不受限制的对抗性人脸攻击方法，名为Text Controlled Attribute Attack (TCA²)，通过自然语言指导生成逼真的人脸模拟图像，以解决现有攻击在属性控制和转移性上的局限性。具体而言，TCA² 利用类别级别的个人softmax向量精确指导攻击，并结合数据和模型增强策略以及Style-GAN 生成器，实现对未知目标模型的高转移攻击。实验在两个高分辨率人脸识别数据集上验证，该方法能产生自然、文本引导的对抗性人脸，且在真实系统如Face++和Aliyun上表现出色，展示了其实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11735v2",
      "published_date": "2024-12-16 12:56:57 UTC",
      "updated_date": "2025-02-02 06:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:23:53.570751"
    },
    {
      "arxiv_id": "2502.17439v2",
      "title": "Large Language Models as Realistic Microservice Trace Generators",
      "title_zh": "翻译失败",
      "authors": [
        "Donghyun Kim",
        "Sriram Ravula",
        "Taemin Ha",
        "Alexandros G. Dimakis",
        "Daehyeok Kim",
        "Aditya Akella"
      ],
      "abstract": "Workload traces are essential to understand complex computer systems'\nbehavior and manage processing and memory resources. Since real-world traces\nare hard to obtain, synthetic trace generation is a promising alternative. This\npaper proposes a first-of-a-kind approach that relies on training a large\nlanguage model (LLM) to generate synthetic workload traces, specifically\nmicroservice call graphs. To capture complex and arbitrary hierarchical\nstructures and implicit constraints in such traces, we show how to fine-tune\nLLMs to generate recursively, making call graph generation a sequence of easier\nsteps. To further enforce learning constraints in traces and generate uncommon\nsituations, we argue for applying additional instruction tuning steps to align\nour model with the desired trace features. Our evaluation results show that we\ncan generate diverse realistic traces under various conditions and outperform\nexisting methods in accuracy and validity. We demonstrate that our\nsynthetically generated traces can effectively replace real data to optimize\nimportant microservice management tasks. Additionally, our model adapts to\ndownstream trace-related tasks, such as predicting key trace features and\ninfilling missing data.",
      "tldr_zh": "本文提出了一种创新方法，使用大型语言模型（LLM）生成合成微服务追踪（microservice call graphs），以替代难以获取的真实工作负载追踪。方法涉及微调 LLM 进行递归生成，从而捕捉追踪中的复杂分层结构和隐含约束，并通过额外指令微调（instruction tuning）强化约束学习和生成多样场景。实验结果显示，该方法在准确性和有效性上优于现有技术，能产生真实多样化的追踪，并成功应用于微服务管理优化任务，如预测关键特征和填充缺失数据。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.OS"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17439v2",
      "published_date": "2024-12-16 12:48:04 UTC",
      "updated_date": "2025-02-26 03:02:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:24:09.062720"
    },
    {
      "arxiv_id": "2412.11716v1",
      "title": "LLMs Can Simulate Standardized Patients via Agent Coevolution",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyun Du",
        "Lujie Zheng",
        "Renjun Hu",
        "Yuyang Xu",
        "Xiawei Li",
        "Ying Sun",
        "Wei Chen",
        "Jian Wu",
        "Haolei Cai",
        "Haohao Ying"
      ],
      "abstract": "Training medical personnel using standardized patients (SPs) remains a\ncomplex challenge, requiring extensive domain expertise and role-specific\npractice. Most research on Large Language Model (LLM)-based simulated patients\nfocuses on improving data retrieval accuracy or adjusting prompts through human\nfeedback. However, this focus has overlooked the critical need for patient\nagents to learn a standardized presentation pattern that transforms data into\nhuman-like patient responses through unsupervised simulations. To address this\ngap, we propose EvoPatient, a novel simulated patient framework in which a\npatient agent and doctor agents simulate the diagnostic process through\nmulti-turn dialogues, simultaneously gathering experience to improve the\nquality of both questions and answers, ultimately enabling human doctor\ntraining. Extensive experiments on various cases demonstrate that, by providing\nonly overall SP requirements, our framework improves over existing reasoning\nmethods by more than 10% in requirement alignment and better human preference,\nwhile achieving an optimal balance of resource consumption after evolving over\n200 cases for 10 hours, with excellent generalizability. The code will be\navailable at https://github.com/ZJUMAI/EvoPatient.",
      "tldr_zh": "本研究提出EvoPatient框架，利用LLM（Large Language Models）通过代理共同演化（Agent Coevolution）来模拟标准化患者（Standardized Patients），以解决现有方法忽略患者代理学习标准化呈现模式的局限性。该框架让患者代理和医生代理通过多轮对话模拟诊断过程，同时积累经验，提高问题和答案的质量，从而用于训练人类医疗人员。实验结果表明，仅提供整体SP要求，EvoPatient在要求一致性和人类偏好上比现有推理方法提升10%以上，并在演化200个案例后10小时内实现资源消耗的最佳平衡，并展示出优秀的泛化性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2412.11716v1",
      "published_date": "2024-12-16 12:36:47 UTC",
      "updated_date": "2024-12-16 12:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:24:18.888106"
    },
    {
      "arxiv_id": "2412.11710v1",
      "title": "Re-Attentional Controllable Video Diffusion Editing",
      "title_zh": "重新注意力可控视频扩散编辑",
      "authors": [
        "Yuanzhi Wang",
        "Yong Li",
        "Mengyi Liu",
        "Xiaoya Zhang",
        "Xin Liu",
        "Zhen Cui",
        "Antoni B. Chan"
      ],
      "abstract": "Editing videos with textual guidance has garnered popularity due to its\nstreamlined process which mandates users to solely edit the text prompt\ncorresponding to the source video. Recent studies have explored and exploited\nlarge-scale text-to-image diffusion models for text-guided video editing,\nresulting in remarkable video editing capabilities. However, they may still\nsuffer from some limitations such as mislocated objects, incorrect number of\nobjects. Therefore, the controllability of video editing remains a formidable\nchallenge. In this paper, we aim to challenge the above limitations by\nproposing a Re-Attentional Controllable Video Diffusion Editing (ReAtCo)\nmethod. Specially, to align the spatial placement of the target objects with\nthe edited text prompt in a training-free manner, we propose a Re-Attentional\nDiffusion (RAD) to refocus the cross-attention activation responses between the\nedited text prompt and the target video during the denoising stage, resulting\nin a spatially location-aligned and semantically high-fidelity manipulated\nvideo. In particular, to faithfully preserve the invariant region content with\nless border artifacts, we propose an Invariant Region-guided Joint Sampling\n(IRJS) strategy to mitigate the intrinsic sampling errors w.r.t the invariant\nregions at each denoising timestep and constrain the generated content to be\nharmonized with the invariant region content. Experimental results verify that\nReAtCo consistently improves the controllability of video diffusion editing and\nachieves superior video editing performance.",
      "tldr_zh": "本文提出 Re-Attentional Controllable Video Diffusion Editing (ReAtCo) 方法，以解决文本引导视频编辑中的问题，如物体位置错误和数量不准确，从而提升编辑的可控性。ReAtCo 包括 Re-Attentional Diffusion (RAD) 机制，在去噪阶段重新调整交叉注意力响应，确保目标物体在空间位置对齐并保持语义高保真；以及 Invariant Region-guided Joint Sampling (IRJS) 策略，用于保护不变区域的内容，减少边界伪影并优化采样过程。实验验证显示，该方法显著提高了视频扩散编辑的性能和可控性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025. Codes are released at:\n  https://github.com/mdswyz/ReAtCo",
      "pdf_url": "http://arxiv.org/pdf/2412.11710v1",
      "published_date": "2024-12-16 12:32:21 UTC",
      "updated_date": "2024-12-16 12:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:24:30.885854"
    },
    {
      "arxiv_id": "2412.11704v3",
      "title": "ElChat: Adapting Chat Language Models Using Only Target Unlabeled Language Data",
      "title_zh": "ElChat：仅使用目标未标注语言数据适应聊天语言模型",
      "authors": [
        "Atsuki Yamaguchi",
        "Terufumi Morishita",
        "Aline Villavicencio",
        "Nikolaos Aletras"
      ],
      "abstract": "Vocabulary expansion (VE) is the de-facto approach to language adaptation of\nlarge language models (LLMs) by adding new tokens and continuing pre-training\non target data. While this is effective for base models trained on unlabeled\ndata, it poses challenges for chat models trained to follow instructions\nthrough labeled conversation data. Directly adapting the latter with VE on\ntarget unlabeled data may result in forgetting chat abilities. While ideal,\ntarget chat data is often unavailable or costly to create for low-resource\nlanguages, and machine-translated alternatives are not always effective. To\naddress this issue, previous work proposed using a base and chat model from the\nsame family. This method first adapts the base LLM with VE on target unlabeled\ndata and then converts it to a chat model by adding a chat vector (CV) derived\nfrom the weight difference between the source base and chat models. We propose\nElChat, a new language adaptation method for chat LLMs that adapts a chat model\ndirectly on target unlabeled data, without a base model. It elicits chat\nabilities by injecting information from the source chat model. ElChat offers\nmore robust and competitive target language and safety performance while\nachieving superior English, chat, and instruction-following abilities compared\nto CV.",
      "tldr_zh": "该研究提出ElChat，一种新型方法，用于直接适应聊天语言模型（chat LLMs），仅使用目标无标签语言数据，而无需依赖基模型。ElChat通过从源聊天模型注入信息来激发聊天能力，从而避免了传统词汇扩展（VE）方法导致的聊天能力遗忘问题。与之前使用聊天向量（CV）的技术相比，ElChat在目标语言和安全性能上更稳健，并表现出色于CV在英语、聊天和指令遵循能力方面。实验结果表明，该方法为低资源语言的模型适应提供了更具竞争力的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11704v3",
      "published_date": "2024-12-16 12:26:28 UTC",
      "updated_date": "2025-04-25 16:08:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:24:42.001576"
    },
    {
      "arxiv_id": "2412.11698v2",
      "title": "On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Esposito",
        "Francesco Palagiano",
        "Valentina Lenarduzzi",
        "Davide Taibi"
      ],
      "abstract": "Context. The security of critical infrastructure has been a pressing concern\nsince the advent of computers and has become even more critical in today's era\nof cyber warfare. Protecting mission-critical systems (MCSs), essential for\nnational security, requires swift and robust governance, yet recent events\nreveal the increasing difficulty of meeting these challenges. Aim. Building on\nprior research showcasing the potential of Generative AI (GAI), such as Large\nLanguage Models, in enhancing risk analysis, we aim to explore practitioners'\nviews on integrating GAI into the governance of IT MCSs. Our goal is to provide\nactionable insights and recommendations for stakeholders, including\nresearchers, practitioners, and policymakers. Method. We designed a survey to\ncollect practical experiences, concerns, and expectations of practitioners who\ndevelop and implement security solutions in the context of MCSs. Conclusions\nand Future Works. Our findings highlight that the safe use of LLMs in MCS\ngovernance requires interdisciplinary collaboration. Researchers should focus\non designing regulation-oriented models and focus on accountability;\npractitioners emphasize data protection and transparency, while policymakers\nmust establish a unified AI framework with global benchmarks to ensure ethical\nand secure LLMs-based MCS governance.",
      "tldr_zh": "这篇论文探讨了在关键任务IT治理中使用大型语言模型(LLMs)的可行性，针对关键基础设施的安全挑战，通过调查从业者的实际经验、担忧和期望来评估其潜力。研究方法采用问卷设计，收集开发和实施任务关键系统(MCSs)安全解决方案的专业人士的反馈。关键发现包括：LLMs的安全应用需跨学科合作，研究者应优先设计面向法规的模型并强化问责制，从业者强调数据保护和透明性，而政策制定者需建立统一的AI框架和全球基准，以确保LLMs-based MCS治理的伦理和安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11698v2",
      "published_date": "2024-12-16 12:21:05 UTC",
      "updated_date": "2025-01-10 13:35:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:24:55.288030"
    },
    {
      "arxiv_id": "2412.12228v1",
      "title": "Linear Equations with Min and Max Operators: Computational Complexity",
      "title_zh": "带有最小和最大运算符的线性方程：计算复杂性",
      "authors": [
        "Krishnendu Chatterjee",
        "Ruichen Luo",
        "Raimundo Saona",
        "Jakub Svoboda"
      ],
      "abstract": "We consider a class of optimization problems defined by a system of linear\nequations with min and max operators. This class of optimization problems has\nbeen studied under restrictive conditions, such as, (C1) the halting or\nstability condition; (C2) the non-negative coefficients condition; (C3) the sum\nup to 1 condition; and (C4) the only min or only max oerator condition. Several\nseminal results in the literature focus on special cases. For example,\nturn-based stochastic games correspond to conditions C2 and C3; and Markov\ndecision process to conditions C2, C3, and C4. However, the systematic\ncomputational complexity study of all the cases has not been explored, which we\naddress in this work. Some highlights of our results are: with conditions C2\nand C4, and with conditions C3 and C4, the problem is NP-complete, whereas with\ncondition C1 only, the problem is in UP intersects coUP. Finally, we establish\nthe computational complexity of the decision problem of checking the respective\nconditions.",
      "tldr_zh": "本论文探讨了包含 min 和 max 操作符的线性方程优化问题的计算复杂度，系统分析了多种限制条件（如 C1: 停止或稳定性条件；C2: 非负系数条件；C3: 系数和为1条件；C4: 只使用 min 或只使用 max 操作符条件）的影响。研究发现，在 C2 和 C4 组合下，或 C3 和 C4 组合下，该问题为 NP-complete，而仅满足 C1 条件时，则属于 UP ∩ coUP。最终，论文还确立了检查这些条件的决策问题的计算复杂度，为相关领域提供了全面的复杂度基准。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12228v1",
      "published_date": "2024-12-16 12:18:36 UTC",
      "updated_date": "2024-12-16 12:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:25:06.598763"
    },
    {
      "arxiv_id": "2412.11694v3",
      "title": "From Specific-MLLMs to Omni-MLLMs: A Survey on MLLMs Aligned with Multi-modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Shixin Jiang",
        "Jiafeng Liang",
        "Jiyuan Wang",
        "Xuan Dong",
        "Heng Chang",
        "Weijiang Yu",
        "Jinhua Du",
        "Ming Liu",
        "Bing Qin"
      ],
      "abstract": "To tackle complex tasks in real-world scenarios, more researchers are\nfocusing on Omni-MLLMs, which aim to achieve omni-modal understanding and\ngeneration. Beyond the constraints of any specific non-linguistic modality,\nOmni-MLLMs map various non-linguistic modalities into the embedding space of\nLLMs and enable the interaction and understanding of arbitrary combinations of\nmodalities within a single model. In this paper, we systematically investigate\nrelevant research and provide a comprehensive survey of Omni-MLLMs.\nSpecifically, we first explain the four core components of Omni-MLLMs for\nunified multi-modal modeling with a meticulous taxonomy that offers novel\nperspectives. Then, we introduce the effective integration achieved through\ntwo-stage training and discuss the corresponding datasets as well as\nevaluation. Furthermore, we summarize the main challenges of current Omni-MLLMs\nand outline future directions. We hope this paper serves as an introduction for\nbeginners and promotes the advancement of related research. Resources have been\nmade publicly available at https://github.com/threegold116/Awesome-Omni-MLLMs.",
      "tldr_zh": "这篇论文对多模态大型语言模型（MLLMs）从特定模态模型向全模态模型（Omni-MLLMs）的演进进行全面调查，旨在实现多种模态的统一理解和生成。论文详细阐述了Omni-MLLMs的四个核心组件，包括将各种非语言模态映射到LLMs的嵌入空间，并讨论了通过两阶段训练实现有效整合的策略，以及相应的数据集和评估方法。最终，论文总结了当前Omni-MLLMs面临的挑战和未来方向，并公开了相关资源，以促进该领域的进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.11694v3",
      "published_date": "2024-12-16 12:12:45 UTC",
      "updated_date": "2025-03-04 01:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:25:18.336125"
    },
    {
      "arxiv_id": "2412.11691v1",
      "title": "Multilingual and Explainable Text Detoxification with Parallel Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "Daryna Dementieva",
        "Nikolay Babakov",
        "Amit Ronen",
        "Abinew Ali Ayele",
        "Naquee Rizwan",
        "Florian Schneider",
        "Xintong Wang",
        "Seid Muhie Yimam",
        "Daniil Moskovskiy",
        "Elisei Stakovskii",
        "Eran Kaufman",
        "Ashraf Elnagar",
        "Animesh Mukherjee",
        "Alexander Panchenko"
      ],
      "abstract": "Even with various regulations in place across countries and social media\nplatforms (Government of India, 2021; European Parliament and Council of the\nEuropean Union, 2022, digital abusive speech remains a significant issue. One\npotential approach to address this challenge is automatic text detoxification,\na text style transfer (TST) approach that transforms toxic language into a more\nneutral or non-toxic form. To date, the availability of parallel corpora for\nthe text detoxification task (Logachevavet al., 2022; Atwell et al., 2022;\nDementievavet al., 2024a) has proven to be crucial for state-of-the-art\napproaches. With this work, we extend parallel text detoxification corpus to\nnew languages -- German, Chinese, Arabic, Hindi, and Amharic -- testing in the\nextensive multilingual setup TST baselines. Next, we conduct the first of its\nkind an automated, explainable analysis of the descriptive features of both\ntoxic and non-toxic sentences, diving deeply into the nuances, similarities,\nand differences of toxicity and detoxification across 9 languages. Finally,\nbased on the obtained insights, we experiment with a novel text detoxification\nmethod inspired by the Chain-of-Thoughts reasoning approach, enhancing the\nprompting process through clustering on relevant descriptive attributes.",
      "tldr_zh": "这篇论文探讨了多语言文本净化（text detoxification），通过扩展平行语料库（parallel corpora）到德语、中文、阿拉伯语、印地语和阿姆哈拉语，以支持多语言文本风格转移（TST）基准测试。研究者首次进行了自动、可解释的分析，比较了9种语言中毒性句子和无毒句子的描述性特征，揭示了毒性和净化过程的细微差异。基于这些洞见，他们实验了一种新方法，使用Chain-of-Thoughts推理和相关描述属性的聚类来优化提示过程。该方法为解决数字滥用言论问题提供了更有效的跨语言解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025, main conference, long",
      "pdf_url": "http://arxiv.org/pdf/2412.11691v1",
      "published_date": "2024-12-16 12:08:59 UTC",
      "updated_date": "2024-12-16 12:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:25:30.954709"
    },
    {
      "arxiv_id": "2412.11682v1",
      "title": "NEST: A Neuromodulated Small-world Hypergraph Trajectory Prediction Model for Autonomous Driving",
      "title_zh": "NEST：一种神经调控的小世界超图轨迹预测模型，用于自动驾驶",
      "authors": [
        "Chengyue Wang",
        "Haicheng Liao",
        "Bonan Wang",
        "Yanchen Guan",
        "Bin Rao",
        "Ziyuan Pu",
        "Zhiyong Cui",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate trajectory prediction is essential for the safety and efficiency of\nautonomous driving. Traditional models often struggle with real-time\nprocessing, capturing non-linearity and uncertainty in traffic environments,\nefficiency in dense traffic, and modeling temporal dynamics of interactions. We\nintroduce NEST (Neuromodulated Small-world Hypergraph Trajectory Prediction), a\nnovel framework that integrates Small-world Networks and hypergraphs for\nsuperior interaction modeling and prediction accuracy. This integration enables\nthe capture of both local and extended vehicle interactions, while the\nNeuromodulator component adapts dynamically to changing traffic conditions. We\nvalidate the NEST model on several real-world datasets, including nuScenes,\nMoCAD, and HighD. The results consistently demonstrate that NEST outperforms\nexisting methods in various traffic scenarios, showcasing its exceptional\ngeneralization capability, efficiency, and temporal foresight. Our\ncomprehensive evaluation illustrates that NEST significantly improves the\nreliability and operational efficiency of autonomous driving systems, making it\na robust solution for trajectory prediction in complex traffic environments.",
      "tldr_zh": "该研究针对自动驾驶中的轨迹预测问题，提出NEST模型，该模型整合Small-world Networks和hypergraphs，以更好地捕捉车辆间的本地和扩展交互，并通过Neuromodulator组件动态适应变化的交通条件。NEST框架解决了传统模型在实时处理、非线性不确定性和密集交通等方面的局限性，在nuScenes、MoCAD和HighD等真实数据集上进行验证。结果显示，NEST在各种交通场景中优于现有方法，显著提升了预测准确性、泛化能力、效率和时间预见性，最终提高了自动驾驶系统的可靠性和操作效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2412.11682v1",
      "published_date": "2024-12-16 11:49:12 UTC",
      "updated_date": "2024-12-16 11:49:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:25:41.909904"
    },
    {
      "arxiv_id": "2412.11681v1",
      "title": "Fast-staged CNN Model for Accurate pulmonary diseases and Lung cancer detection",
      "title_zh": "快速分阶段 CNN 模型用于准确检测肺部疾病和肺癌",
      "authors": [
        "Abdelbaki Souid",
        "Mohamed Hamroun",
        "Soufiene Ben Othman",
        "Hedi Sakli",
        "Naceur Abdelkarim"
      ],
      "abstract": "Pulmonary pathologies are a significant global health concern, often leading\nto fatal outcomes if not diagnosed and treated promptly. Chest radiography\nserves as a primary diagnostic tool, but the availability of experienced\nradiologists remains limited. Advances in Artificial Intelligence (AI) and\nmachine learning, particularly in computer vision, offer promising solutions to\naddress this challenge.\n  This research evaluates a deep learning model designed to detect lung cancer,\nspecifically pulmonary nodules, along with eight other lung pathologies, using\nchest radiographs. The study leverages diverse datasets comprising over 135,120\nfrontal chest radiographs to train a Convolutional Neural Network (CNN). A\ntwo-stage classification system, utilizing ensemble methods and transfer\nlearning, is employed to first triage images into Normal or Abnormal categories\nand then identify specific pathologies, including lung nodules.\n  The deep learning model achieves notable results in nodule classification,\nwith a top-performing accuracy of 77%, a sensitivity of 0.713, a specificity of\n0.776 during external validation, and an AUC score of 0.888. Despite these\nsuccesses, some misclassifications were observed, primarily false negatives.\n  In conclusion, the model demonstrates robust potential for generalization\nacross diverse patient populations, attributed to the geographic diversity of\nthe training dataset. Future work could focus on integrating ETL data\ndistribution strategies and expanding the dataset with additional nodule-type\nsamples to further enhance diagnostic accuracy.",
      "tldr_zh": "本研究针对肺部疾病的诊断挑战，提出了一种快速分阶段的CNN模型，用于准确检测肺癌（包括肺结节）和其他八种肺部病变，利用超过135,120张胸部X光图像进行训练。模型采用两阶段分类系统：第一阶段通过集成方法和迁移学习将图像分类为正常或异常，第二阶段识别具体病变。实验结果显示，该模型在肺结节分类上达到77%的准确率、0.713的敏感性、0.776的特异性和0.888的AUC分数，尽管存在部分假阴性误分类，但展示了良好的泛化潜力。未来工作将聚焦整合ETL数据策略和扩展数据集，以进一步提升诊断准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "IEEE International Workshop on Mechatronic Systems Supervision 2023",
      "pdf_url": "http://arxiv.org/pdf/2412.11681v1",
      "published_date": "2024-12-16 11:47:07 UTC",
      "updated_date": "2024-12-16 11:47:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:25:55.499237"
    },
    {
      "arxiv_id": "2412.11679v1",
      "title": "Bias Vector: Mitigating Biases in Language Models with Task Arithmetic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Daiki Shirafuji",
        "Makoto Takenaka",
        "Shinya Taguchi"
      ],
      "abstract": "The use of language models (LMs) has increased considerably in recent years,\nand the biases and stereotypes in training data that are reflected in the LM\noutputs are causing social problems. In this paper, inspired by the task\narithmetic, we propose the ``Bias Vector'' method for the mitigation of these\nLM biases. The Bias Vector method does not require manually created debiasing\ndata. The three main steps of our approach involve: (1) continual training the\npre-trained LMs on biased data using masked language modeling; (2) constructing\nthe Bias Vector as the difference between the weights of the biased LMs and\nthose of pre-trained LMs; and (3) subtracting the Bias Vector from the weights\nof the pre-trained LMs for debiasing. We evaluated the Bias Vector method on\nthe SEAT across three LMs and confirmed an average improvement of 0.177 points.\nWe demonstrated that the Bias Vector method does not degrade the LM performance\non downstream tasks in the GLUE benchmark. In addition, we examined the impact\nof scaling factors, which control the magnitudes of Bias Vectors, with effect\nsizes on the SEAT and conducted a comprehensive evaluation of our debiased LMs\nacross both the SEAT and GLUE benchmarks.",
      "tldr_zh": "这篇论文提出了 Bias Vector 方法，受 Task Arithmetic 启发，用于缓解语言模型 (LMs) 中的偏见问题，而无需手动创建去偏见数据。方法的核心步骤包括：在偏见数据上使用 masked language modeling 持续训练预训练 LMs、计算 Bias Vector 作为偏见模型与预训练模型权重差异、然后从预训练模型权重中减去 Bias Vector 以实现去偏见。实验结果显示，该方法在 SEAT 基准上评估三个 LMs 时平均改善 0.177 点，同时在 GLUE 基准上不降低下游任务的性能，并通过缩放因素分析进一步验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to COLING2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11679v1",
      "published_date": "2024-12-16 11:38:23 UTC",
      "updated_date": "2024-12-16 11:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:26:06.664594"
    },
    {
      "arxiv_id": "2412.11678v2",
      "title": "Loosely Synchronized Rule-Based Planning for Multi-Agent Path Finding with Asynchronous Actions",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Zhou",
        "Shizhe Zhao",
        "Zhongqiang Ren"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) seeks collision-free paths for multiple\nagents from their respective starting locations to their respective goal\nlocations while minimizing path costs. Although many MAPF algorithms were\ndeveloped and can handle up to thousands of agents, they usually rely on the\nassumption that each action of the agent takes a time unit, and the actions of\nall agents are synchronized in a sense that the actions of agents start at the\nsame discrete time step, which may limit their use in practice. Only a few\nalgorithms were developed to address asynchronous actions, and they all lie on\none end of the spectrum, focusing on finding optimal solutions with limited\nscalability. This paper develops new planners that lie on the other end of the\nspectrum, trading off solution quality for scalability, by finding an unbounded\nsub-optimal solution for many agents. Our method leverages both search methods\n(LSS) in handling asynchronous actions and rule-based planning methods (PIBT)\nfor MAPF. We analyze the properties of our method and test it against several\nbaselines with up to 1000 agents in various maps. Given a runtime limit, our\nmethod can handle an order of magnitude more agents than the baselines with\nabout 25% longer makespan.",
      "tldr_zh": "这篇论文针对 Multi-Agent Path Finding (MAPF) 问题，提出了一种松散同步的基于规则的规划方法，以处理异步动作场景，避免了传统算法对动作同步的假设限制。方法结合了 LSS 搜索技术和 PIBT 规则-based 规划，优先优化可扩展性而非解的最优性，从而实现对多达1000个智能体的子最优路径规划。实验结果表明，在运行时间限制下，该方法能处理比基线多一个数量级的智能体，同时 makespan 只增加了约25%。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11678v2",
      "published_date": "2024-12-16 11:36:24 UTC",
      "updated_date": "2024-12-21 08:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:26:18.590156"
    },
    {
      "arxiv_id": "2412.11674v1",
      "title": "UA-PDFL: A Personalized Approach for Decentralized Federated Learning",
      "title_zh": "UA-PDFL：一种个性化的去中心化联邦学习方法",
      "authors": [
        "Hangyu Zhu",
        "Yuxiang Fan",
        "Zhenping Xie"
      ],
      "abstract": "Federated learning (FL) is a privacy preserving machine learning paradigm\ndesigned to collaboratively learn a global model without data leakage.\nSpecifically, in a typical FL system, the central server solely functions as an\ncoordinator to iteratively aggregate the collected local models trained by each\nclient, potentially introducing single-point transmission bottleneck and\nsecurity threats. To mitigate this issue, decentralized federated learning\n(DFL) has been proposed, where all participating clients engage in peer-to-peer\ncommunication without a central server. Nonetheless, DFL still suffers from\ntraining degradation as FL does due to the non-independent and identically\ndistributed (non-IID) nature of client data. And incorporating personalization\nlayers into DFL may be the most effective solutions to alleviate the side\neffects caused by non-IID data. Therefore, in this paper, we propose a novel\nunit representation aided personalized decentralized federated learning\nframework, named UA-PDFL, to deal with the non-IID challenge in DFL. By\nadaptively adjusting the level of personalization layers through the guidance\nof the unit representation, UA-PDFL is able to address the varying degrees of\ndata skew. Based on this scheme, client-wise dropout and layer-wise\npersonalization are proposed to further enhance the learning performance of\nDFL. Extensive experiments empirically prove the effectiveness of our proposed\nmethod.",
      "tldr_zh": "论文提出 UA-PDFL，一种针对去中心化联邦学习(DFL)的个性化框架，旨在解决非独立同分布(non-IID)数据导致的训练退化问题，同时避免传统联邦学习(FL)中的中央服务器瓶颈和安全威胁。UA-PDFL 通过 unit representation 动态调整个性化层的程度，并结合 client-wise dropout 和 layer-wise personalization 来适应不同数据偏差，提升整体学习性能。实验结果显示，该方法在广泛测试中证明了其有效性，显著提高了 DFL 的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11674v1",
      "published_date": "2024-12-16 11:27:35 UTC",
      "updated_date": "2024-12-16 11:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:26:30.008791"
    },
    {
      "arxiv_id": "2412.11672v1",
      "title": "LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User Requests",
      "title_zh": "翻译失败",
      "authors": [
        "Lillian Wassim",
        "Kamal Mohamed",
        "Ali Hamdi"
      ],
      "abstract": "We propose LLM-DaaS, a novel Drone-as-a-Service (DaaS) framework that\nleverages Large Language Models (LLMs) to transform free-text user requests\ninto structured, actionable DaaS operation tasks. Our approach addresses the\nkey challenge of interpreting and structuring natural language input to\nautomate drone service operations under uncertain conditions. The system is\ncomposed of three main components: free-text request processing, structured\nrequest generation, and dynamic DaaS selection and composition. First, we\nfine-tune different LLM models such as Phi-3.5, LLaMA-3.2 7b and Gemma 2b on a\ndataset of text user requests mapped to structured DaaS requests. Users\ninteract with our model in a free conversational style, discussing package\ndelivery requests, while the fine-tuned LLM extracts DaaS metadata such as\ndelivery time, source and destination locations, and package weight. The DaaS\nservice selection model is designed to select the best available drone capable\nof delivering the requested package from the delivery point to the nearest\noptimal destination. Additionally, the DaaS composition model composes a\nservice from a set of the best available drones to deliver the package from the\nsource to the final destination. Second, the system integrates real-time\nweather data to optimize drone route planning and scheduling, ensuring safe and\nefficient operations. Simulations demonstrate the system's ability to\nsignificantly improve task accuracy, operational efficiency, and establish\nLLM-DaaS as a robust solution for DaaS operations in uncertain environments.",
      "tldr_zh": "本研究提出LLM-DaaS框架，利用大型语言模型(LLMs)将自由文本用户请求转化为结构化的Drone-as-a-Service (DaaS)操作任务，旨在解决自然语言输入解释和不确定环境下的无人机自动化问题。系统包括三个主要组件：自由文本请求处理（通过微调如Phi-3.5、LLaMA-3.2 7b和Gemma 2b模型提取元数据，如交付时间、源目的地和包裹重量）、结构化请求生成，以及动态DaaS选择和组合（包括选择最佳无人机和整合实时天气数据优化路线规划）。实验模拟显示，该框架显著提高了任务准确性和操作效率，将LLM-DaaS确立为不确定环境中的鲁棒解决方案。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11672v1",
      "published_date": "2024-12-16 11:25:56 UTC",
      "updated_date": "2024-12-16 11:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:26:42.913593"
    },
    {
      "arxiv_id": "2412.11671v1",
      "title": "BioBridge: Unified Bio-Embedding with Bridging Modality in Code-Switched EMR",
      "title_zh": "翻译失败",
      "authors": [
        "Jangyeong Jeon",
        "Sangyeon Cho",
        "Dongjoon Lee",
        "Changhee Lee",
        "Junyeong Kim"
      ],
      "abstract": "Pediatric Emergency Department (PED) overcrowding presents a significant\nglobal challenge, prompting the need for efficient solutions. This paper\nintroduces the BioBridge framework, a novel approach that applies Natural\nLanguage Processing (NLP) to Electronic Medical Records (EMRs) in written\nfree-text form to enhance decision-making in PED. In non-English speaking\ncountries, such as South Korea, EMR data is often written in a Code-Switching\n(CS) format that mixes the native language with English, with most\ncode-switched English words having clinical significance. The BioBridge\nframework consists of two core modules: \"bridging modality in context\" and\n\"unified bio-embedding.\" The \"bridging modality in context\" module improves the\ncontextual understanding of bilingual and code-switched EMRs. In the \"unified\nbio-embedding\" module, the knowledge of the model trained in the medical domain\nis injected into the encoder-based model to bridge the gap between the medical\nand general domains. Experimental results demonstrate that the proposed\nBioBridge significantly performance traditional machine learning and\npre-trained encoder-based models on several metrics, including F1 score, area\nunder the receiver operating characteristic curve (AUROC), area under the\nprecision-recall curve (AUPRC), and Brier score. Specifically, BioBridge-XLM\nachieved enhancements of 0.85% in F1 score, 0.75% in AUROC, and 0.76% in AUPRC,\nalong with a notable 3.04% decrease in the Brier score, demonstrating marked\nimprovements in accuracy, reliability, and prediction calibration over the\nbaseline XLM model. The source code will be made publicly available.",
      "tldr_zh": "本文提出 BioBridge 框架，利用 Natural Language Processing (NLP) 处理代码切换 (Code-Switching) 的电子病历 (EMRs)，旨在提升儿科急诊部门 (PED) 的决策效率，尤其针对非英语国家如韩国的双语医疗数据。框架的核心模块包括“bridging modality in context”，用于改善双语和代码切换文本的上下文理解，以及“unified bio-embedding”，通过注入医疗领域知识桥接医疗和一般领域差距。实验结果显示，BioBridge-XLM 模型在 F1 score 上提升 0.85%、AUROC 上提升 0.75%、AUPRC 上提升 0.76%，并将 Brier score 降低 3.04%，显著优于传统模型和基线 XLM 模型。该框架为处理复杂医疗数据提供可靠解决方案，源代码将公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IEEE Access 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.11671v1",
      "published_date": "2024-12-16 11:24:54 UTC",
      "updated_date": "2024-12-16 11:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:26:56.278388"
    },
    {
      "arxiv_id": "2412.12227v1",
      "title": "EDformer: Embedded Decomposition Transformer for Interpretable Multivariate Time Series Predictions",
      "title_zh": "EDformer：嵌入分解 Transformer 用于可",
      "authors": [
        "Sanjay Chakraborty",
        "Ibrahim Delibasoglu",
        "Fredrik Heintz"
      ],
      "abstract": "Time series forecasting is a crucial challenge with significant applications\nin areas such as weather prediction, stock market analysis, and scientific\nsimulations. This paper introduces an embedded decomposed transformer,\n'EDformer', for multivariate time series forecasting tasks. Without altering\nthe fundamental elements, we reuse the Transformer architecture and consider\nthe capable functions of its constituent parts in this work. Edformer first\ndecomposes the input multivariate signal into seasonal and trend components.\nNext, the prominent multivariate seasonal component is reconstructed across the\nreverse dimensions, followed by applying the attention mechanism and\nfeed-forward network in the encoder stage. In particular, the feed-forward\nnetwork is used for each variable frame to learn nonlinear representations,\nwhile the attention mechanism uses the time points of individual seasonal\nseries embedded within variate frames to capture multivariate correlations.\nTherefore, the trend signal is added with projection and performs the final\nforecasting. The EDformer model obtains state-of-the-art predicting results in\nterms of accuracy and efficiency on complex real-world time series datasets.\nThis paper also addresses model explainability techniques to provide insights\ninto how the model makes its predictions and why specific features or time\nsteps are important, enhancing the interpretability and trustworthiness of the\nforecasting results.",
      "tldr_zh": "本论文提出了一种嵌入式分解 Transformer 模型（EDformer），用于多变量时间序列预测任务，通过重用 Transformer 架构来提升预测的准确性和效率。EDformer 的方法包括先将输入信号分解为季节性和趋势组件，然后对季节性组件进行重构并应用注意力机制捕捉多变量相关性，以及前馈网络学习非线性表示，最后结合趋势组件进行最终预测。该模型在复杂真实世界数据集上取得了最先进的预测性能，并通过模型可解释性技术，提供对预测过程的洞见，增强了模型的可信度和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12227v1",
      "published_date": "2024-12-16 11:13:57 UTC",
      "updated_date": "2024-12-16 11:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:27:06.603916"
    },
    {
      "arxiv_id": "2412.12226v1",
      "title": "Apollo-Forecast: Overcoming Aliasing and Inference Speed Challenges in Language Models for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Yin",
        "Jingwei Wang",
        "Yunlong Ma",
        "Han Wang",
        "Chenze Wang",
        "Yukai Zhao",
        "Min Liu",
        "Weiming Shen",
        "Yufeng Chen"
      ],
      "abstract": "Encoding time series into tokens and using language models for processing has\nbeen shown to substantially augment the models' ability to generalize to unseen\ntasks. However, existing language models for time series forecasting encounter\nseveral obstacles, including aliasing distortion and prolonged inference times,\nprimarily due to the limitations of quantization processes and the\ncomputational demands of large models. This paper introduces Apollo-Forecast, a\nnovel framework that tackles these challenges with two key innovations: the\nAnti-Aliasing Quantization Module (AAQM) and the Race Decoding (RD) technique.\nAAQM adeptly encodes sequences into tokens while mitigating high-frequency\nnoise in the original signals, thus enhancing both signal fidelity and overall\nquantization efficiency. RD employs a draft model to enable parallel processing\nand results integration, which markedly accelerates the inference speed for\nlong-term predictions, particularly in large-scale models. Extensive\nexperiments on various real-world datasets show that Apollo-Forecast\noutperforms state-of-the-art methods by 35.41\\% and 18.99\\% in WQL and MASE\nmetrics, respectively, in zero-shot scenarios. Furthermore, our method achieves\na 1.9X-2.7X acceleration in inference speed over baseline methods.",
      "tldr_zh": "该研究提出 Apollo-Forecast 框架，旨在解决语言模型在时间序列预测中的别名失真（aliasing distortion）和推理速度慢等问题。框架引入 Anti-Aliasing Quantization Module (AAQM) 来减少高频噪声，提高序列编码的信号保真度和量化效率，以及 Race Decoding (RD) 技术通过草稿模型实现并行处理，从而加速长期预测的推理速度。在各种真实数据集上的实验显示，Apollo-Forecast 在零样本场景下，比最先进方法在 WQL 和 MASE 指标上分别提升 35.41% 和 18.99%，并实现 1.9X-2.7X 的推理速度加速。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12226v1",
      "published_date": "2024-12-16 11:01:20 UTC",
      "updated_date": "2024-12-16 11:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:27:18.453542"
    },
    {
      "arxiv_id": "2412.11654v3",
      "title": "Smoothness Really Matters: A Simple Yet Effective Approach for Unsupervised Graph Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Chen",
        "Guo Ye",
        "Yakun Wang",
        "Zhao Zhang",
        "Libang Zhang",
        "Daixin Wang",
        "Zhiqiang Zhang",
        "Fuzhen Zhuang"
      ],
      "abstract": "Unsupervised Graph Domain Adaptation (UGDA) seeks to bridge distribution\nshifts between domains by transferring knowledge from labeled source graphs to\ngiven unlabeled target graphs. Existing UGDA methods primarily focus on\naligning features in the latent space learned by graph neural networks (GNNs)\nacross domains, often overlooking structural shifts, resulting in limited\neffectiveness when addressing structurally complex transfer scenarios. Given\nthe sensitivity of GNNs to local structural features, even slight discrepancies\nbetween source and target graphs could lead to significant shifts in node\nembeddings, thereby reducing the effectiveness of knowledge transfer. To\naddress this issue, we introduce a novel approach for UGDA called Target-Domain\nStructural Smoothing (TDSS). TDSS is a simple and effective method designed to\nperform structural smoothing directly on the target graph, thereby mitigating\nstructural distribution shifts and ensuring the consistency of node\nrepresentations. Specifically, by integrating smoothing techniques with\nneighborhood sampling, TDSS maintains the structural coherence of the target\ngraph while mitigating the risk of over-smoothing. Our theoretical analysis\nshows that TDSS effectively reduces target risk by improving model smoothness.\nEmpirical results on three real-world datasets demonstrate that TDSS\noutperforms recent state-of-the-art baselines, achieving significant\nimprovements across six transfer scenarios. The code is available in\nhttps://github.com/cwei01/TDSS.",
      "tldr_zh": "本研究针对无监督图域适应 (UGDA) 的问题，提出了一种简单有效的Target-Domain Structural Smoothing (TDSS) 方法，以缓解源图和目标图之间的结构分布转移。TDSS 通过在目标图上直接应用结构平滑技术和邻居采样，保持节点表示的一致性，同时避免过度平滑，从而提升Graph Neural Networks (GNNs) 的知识转移效果。理论分析表明，TDSS 通过提高模型平滑度来降低目标风险，而在三个真实数据集上的实验结果显示，它在六个转移场景中显著优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, Accpected by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11654v3",
      "published_date": "2024-12-16 10:56:58 UTC",
      "updated_date": "2025-01-16 03:04:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:27:30.515840"
    },
    {
      "arxiv_id": "2412.11652v1",
      "title": "SE-GCL: An Event-Based Simple and Effective Graph Contrastive Learning for Text Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Meng",
        "Wei Ai",
        "Jianbin Li",
        "Ze Wang",
        "Yuntao Shou",
        "Keqin Li"
      ],
      "abstract": "Text representation learning is significant as the cornerstone of natural\nlanguage processing. In recent years, graph contrastive learning (GCL) has been\nwidely used in text representation learning due to its ability to represent and\ncapture complex text information in a self-supervised setting. However, current\nmainstream graph contrastive learning methods often require the incorporation\nof domain knowledge or cumbersome computations to guide the data augmentation\nprocess, which significantly limits the application efficiency and scope of\nGCL. Additionally, many methods learn text representations only by constructing\nword-document relationships, which overlooks the rich contextual semantic\ninformation in the text. To address these issues and exploit representative\ntextual semantics, we present an event-based, simple, and effective graph\ncontrastive learning (SE-GCL) for text representation. Precisely, we extract\nevent blocks from text and construct internal relation graphs to represent\ninter-semantic interconnections, which can ensure that the most critical\nsemantic information is preserved. Then, we devise a streamlined, unsupervised\ngraph contrastive learning framework to leverage the complementary nature of\nthe event semantic and structural information for intricate feature data\ncapture. In particular, we introduce the concept of an event skeleton for core\nrepresentation semantics and simplify the typically complex data augmentation\ntechniques found in existing graph contrastive learning to boost algorithmic\nefficiency. We employ multiple loss functions to prompt diverse embeddings to\nconverge or diverge within a confined distance in the vector space, ultimately\nachieving a harmonious equilibrium. We conducted experiments on the proposed\nSE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to\nverify its effectiveness in text representation learning.",
      "tldr_zh": "本研究针对现有图对比学习 (GCL) 在文本表示学习中依赖领域知识、复杂计算和忽略上下文语义的问题，提出了一种基于事件的简单有效框架 SE-GCL。方法包括从文本中提取事件块并构建内部关系图，以捕捉语义互连，并引入事件骨架 (event skeleton) 简化数据增强，同时使用多个损失函数优化嵌入表示，实现语义和结构信息的互补捕捉。在 AG News、20NG、SougouNews 和 THUCNews 等四个标准数据集上的实验验证了 SE-GCL 的有效性，提高了文本表示学习的效率和性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.11652v1",
      "published_date": "2024-12-16 10:53:24 UTC",
      "updated_date": "2024-12-16 10:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:27:43.206413"
    },
    {
      "arxiv_id": "2412.11643v1",
      "title": "A comprehensive GeoAI review: Progress, Challenges and Outlooks",
      "title_zh": "全面的 GeoAI 综述：进展、挑战和展望",
      "authors": [
        "Anasse Boutayeb",
        "Iyad Lahsen-cherif",
        "Ahmed El Khadimi"
      ],
      "abstract": "In recent years, Geospatial Artificial Intelligence (GeoAI) has gained\ntraction in the most relevant research works and industrial applications, while\nalso becoming involved in various fields of use. This paper offers a\ncomprehensive review of GeoAI as a synergistic concept applying Artificial\nIntelligence (AI) methods and models to geospatial data. A preliminary study is\ncarried out, identifying the methodology of the work, the research motivations,\nthe issues and the directions to be tracked, followed by exploring how GeoAI\ncan be used in various interesting fields of application, such as precision\nagriculture, environmental monitoring, disaster management and urban planning.\nNext, a statistical and semantic analysis is carried out, followed by a clear\nand precise presentation of the challenges facing GeoAI. Then, a concrete\nexploration of the future prospects is provided, based on several informations\ngathered during the census. To sum up, this paper provides a complete overview\nof the correlation between AI and the geospatial domain, while mentioning the\nresearches conducted in this context, and emphasizing the close relationship\nlinking GeoAI with other advanced concepts such as geographic information\nsystems (GIS) and large-scale geospatial data, known as big geodata. This will\nenable researchers and scientific community to assess the state of progress in\nthis promising field, and will help other interested parties to gain a better\nunderstanding of the issues involved.",
      "tldr_zh": "这篇论文对 GeoAI（Geospatial Artificial Intelligence）进行了全面回顾，探讨了其作为 AI 方法应用于地理空间数据的进展、挑战和未来展望。通过初步研究、统计分析和语义分析，论文阐述了 GeoAI 在精密农业、环境监测、灾害管理和城市规划等领域的应用潜力，并突出了面临的挑战，如数据处理和整合问题。最终，论文强调了 GeoAI 与 GIS（Geographic Information Systems）和 big geodata 的紧密关联，为研究人员评估该领域进展并规划未来研究提供了重要指导。",
      "categories": [
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "A comprehensive GeoAI review with 50 pages, 52 figures and 13 tables.\n  This paper explores the synergy between the most advanced artificial\n  intelligence techniques and geospatial data, while highlighting the close\n  relationship between this concept and the notions of GIS and big geodata",
      "pdf_url": "http://arxiv.org/pdf/2412.11643v1",
      "published_date": "2024-12-16 10:41:02 UTC",
      "updated_date": "2024-12-16 10:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:27:54.251883"
    },
    {
      "arxiv_id": "2412.11642v1",
      "title": "Introduction to AI Planning",
      "title_zh": "人工智能规划导论",
      "authors": [
        "Marco Aiello",
        "Ilche Georgievski"
      ],
      "abstract": "These are notes for lectures presented at the University of Stuttgart that\nprovide an introduction to key concepts and techniques in AI Planning.\nArtificial Intelligence Planning, also known as Automated Planning, emerged\nsomewhere in 1966 from the need to give autonomy to a wheeled robot. Since\nthen, it has evolved into a flourishing research and development discipline,\noften associated with scheduling. Over the decades, various approaches to\nplanning have been developed with characteristics that make them appropriate\nfor specific tasks and applications. Most approaches represent the world as a\nstate within a state transition system; then the planning problem becomes that\nof searching a path in the state space from the current state to one which\nsatisfies the goals of the user. The notes begin by introducing the state model\nand move on to exploring classical planning, the foundational form of planning,\nand present fundamental algorithms for solving such problems. Subsequently, we\nexamine planning as a constraint satisfaction problem, outlining the mapping\nprocess and describing an approach to solve such problems. The most extensive\nsection is dedicated to Hierarchical Task Network (HTN) planning, one of the\nmost widely used and powerful planning techniques in the field. The lecture\nnotes end with a bonus chapter on the Planning Domain Definition (PDDL)\nLanguage, the de facto standard syntax for representing non-hierarchical\nplanning problems.",
      "tldr_zh": "这些讲义介绍了AI Planning（人工智能规划）的关键概念和技术，作为大学课程的入门材料。内容从AI Planning的起源（如1966年为机器人自主性而生）开始，涵盖状态转换系统、经典规划算法、规划作为约束满足问题，以及Hierarchical Task Network (HTN) planning的详细探讨。最终，还包括一个关于Planning Domain Definition (PDDL) Language的章节，作为非层次化规划问题的标准表示语法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11642v1",
      "published_date": "2024-12-16 10:38:04 UTC",
      "updated_date": "2024-12-16 10:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:30:05.462957"
    },
    {
      "arxiv_id": "2412.11632v1",
      "title": "Multi-Scale Incremental Modeling for Enhanced Human Motion Prediction in Human-Robot Collaboration",
      "title_zh": "多尺度增量建模用于提升人机协作中的人类运动预测",
      "authors": [
        "Juncheng Zou"
      ],
      "abstract": "Accurate human motion prediction is crucial for safe human-robot\ncollaboration but remains challenging due to the complexity of modeling\nintricate and variable human movements. This paper presents Parallel\nMulti-scale Incremental Prediction (PMS), a novel framework that explicitly\nmodels incremental motion across multiple spatio-temporal scales to capture\nsubtle joint evolutions and global trajectory shifts. PMS encodes these\nmulti-scale increments using parallel sequence branches, enabling iterative\nrefinement of predictions. A multi-stage training procedure with a\nfull-timeline loss integrates temporal context. Extensive experiments on four\ndatasets demonstrate substantial improvements in continuity, biomechanical\nconsistency, and long-term forecast stability by modeling inter-frame\nincrements. PMS achieves state-of-the-art performance, increasing prediction\naccuracy by 16.3%-64.2% over previous methods. The proposed multi-scale\nincremental approach provides a powerful technique for advancing human motion\nprediction capabilities critical for seamless human-robot interaction.",
      "tldr_zh": "这篇论文提出了Parallel Multi-scale Incremental Prediction (PMS)框架，以提升人机协作中的人类运动预测准确性，通过显式建模多尺度时空增量来捕捉细微关节演变和全局轨迹变化，并利用并行序列分支和多阶段训练过程（包括全时间线损失）实现预测的迭代精炼。实验在四个数据集上证明，该方法显著改善了预测的连续性、生物力学一致性和长期稳定性，与现有方法相比，准确率提高了16.3%至64.2%。PMS的多尺度增量建模方法为推进无缝人机交互的关键预测能力提供了强大技术。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11632v1",
      "published_date": "2024-12-16 10:20:46 UTC",
      "updated_date": "2024-12-16 10:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:28:18.391891"
    },
    {
      "arxiv_id": "2412.11620v3",
      "title": "Combating Semantic Contamination in Learning with Label Noise",
      "title_zh": "在带有标签噪声的学习中对抗语义污染",
      "authors": [
        "Wenxiao Fan",
        "Kan Li"
      ],
      "abstract": "Noisy labels can negatively impact the performance of deep neural networks.\nOne common solution is label refurbishment, which involves reconstructing noisy\nlabels through predictions and distributions. However, these methods may\nintroduce problematic semantic associations, a phenomenon that we identify as\nSemantic Contamination. Through an analysis of Robust LR, a representative\nlabel refurbishment method, we found that utilizing the logits of views for\nrefurbishment does not adequately balance the semantic information of\nindividual classes. Conversely, using the logits of models fails to maintain\nconsistent semantic relationships across models, which explains why label\nrefurbishment methods frequently encounter issues related to Semantic\nContamination. To address this issue, we propose a novel method called\nCollaborative Cross Learning, which utilizes semi-supervised learning on\nrefurbished labels to extract appropriate semantic associations from embeddings\nacross views and models. Experimental results show that our method outperforms\nexisting approaches on both synthetic and real-world noisy datasets,\neffectively mitigating the impact of label noise and Semantic Contamination.",
      "tldr_zh": "该论文探讨了噪声标签对深度神经网络性能的负面影响，指出现有标签重构（label refurbishment）方法可能引入Semantic Contamination问题，导致类别语义信息不平衡或跨模型不一致。通过分析Robust LR方法，研究者发现其在利用视图或模型logits时存在缺陷。为解决此问题，他们提出Collaborative Cross Learning方法，利用半监督学习从视图和模型的嵌入中提取合适的语义关联。实验结果显示，该方法在合成和真实世界噪声数据集上优于现有方法，有效缓解了标签噪声和Semantic Contamination的影响。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11620v3",
      "published_date": "2024-12-16 10:07:15 UTC",
      "updated_date": "2025-03-28 09:47:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:30:24.071120"
    },
    {
      "arxiv_id": "2412.12225v3",
      "title": "DLF: Disentangled-Language-Focused Multimodal Sentiment Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Pan Wang",
        "Qiang Zhou",
        "Yawen Wu",
        "Tianlong Chen",
        "Jingtong Hu"
      ],
      "abstract": "Multimodal Sentiment Analysis (MSA) leverages heterogeneous modalities, such\nas language, vision, and audio, to enhance the understanding of human\nsentiment. While existing models often focus on extracting shared information\nacross modalities or directly fusing heterogeneous modalities, such approaches\ncan introduce redundancy and conflicts due to equal treatment of all modalities\nand the mutual transfer of information between modality pairs. To address these\nissues, we propose a Disentangled-Language-Focused (DLF) multimodal\nrepresentation learning framework, which incorporates a feature disentanglement\nmodule to separate modality-shared and modality-specific information. To\nfurther reduce redundancy and enhance language-targeted features, four\ngeometric measures are introduced to refine the disentanglement process. A\nLanguage-Focused Attractor (LFA) is further developed to strengthen language\nrepresentation by leveraging complementary modality-specific information\nthrough a language-guided cross-attention mechanism. The framework also employs\nhierarchical predictions to improve overall accuracy. Extensive experiments on\ntwo popular MSA datasets, CMU-MOSI and CMU-MOSEI, demonstrate the significant\nperformance gains achieved by the proposed DLF framework. Comprehensive\nablation studies further validate the effectiveness of the feature\ndisentanglement module, language-focused attractor, and hierarchical\npredictions. Our code is available at https://github.com/pwang322/DLF.",
      "tldr_zh": "这篇论文针对 Multimodal Sentiment Analysis (MSA) 中的冗余和冲突问题，提出了 Disentangled-Language-Focused (DLF) 框架，通过特征解耦模块分离模态共享和模态特定信息，并引入四个几何度量来优化解耦过程，减少冗余并强化语言相关特征。框架还开发了 Language-Focused Attractor (LFA)，利用语言引导的交叉注意力机制整合互补模态信息，并采用 hierarchical predictions 来提升整体准确性。在 CMU-MOSI 和 CMU-MOSEI 数据集上的实验显示，DLF 框架实现了显著性能提升，消融研究进一步验证了特征解耦模块、LFA 和分层预测的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025 accepted",
      "pdf_url": "http://arxiv.org/pdf/2412.12225v3",
      "published_date": "2024-12-16 10:03:44 UTC",
      "updated_date": "2025-04-09 00:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:30:36.387657"
    },
    {
      "arxiv_id": "2412.11618v1",
      "title": "EvoLlama: Enhancing LLMs' Understanding of Proteins via Multimodal Structure and Sequence Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Nuowei Liu",
        "Changzhi Sun",
        "Tao Ji",
        "Junfeng Tian",
        "Jianxin Tang",
        "Yuanbin Wu",
        "Man Lan"
      ],
      "abstract": "Current Large Language Models (LLMs) for understanding proteins primarily\ntreats amino acid sequences as a text modality. Meanwhile, Protein Language\nModels (PLMs), such as ESM-2, have learned massive sequential evolutionary\nknowledge from the universe of natural protein sequences. Furthermore,\nstructure-based encoders like ProteinMPNN learn the structural information of\nproteins through Graph Neural Networks. However, whether the incorporation of\nprotein encoders can enhance the protein understanding of LLMs has not been\nexplored. To bridge this gap, we propose EvoLlama, a multimodal framework that\nconnects a structure-based encoder, a sequence-based protein encoder and an LLM\nfor protein understanding. EvoLlama consists of a ProteinMPNN structure\nencoder, an ESM-2 protein sequence encoder, a multimodal projector to align\nprotein and text representations and a Llama-3 text decoder. To train EvoLlama,\nwe fine-tune it on protein-oriented instructions and protein property\nprediction datasets verbalized via natural language instruction templates. Our\nexperiments show that EvoLlama's protein understanding capabilities have been\nsignificantly enhanced, outperforming other fine-tuned protein-oriented LLMs in\nzero-shot settings by an average of 1%-8% and surpassing the state-of-the-art\nbaseline with supervised fine-tuning by an average of 6%. On protein property\nprediction datasets, our approach achieves promising results that are\ncompetitive with state-of-the-art task-specific baselines. We will release our\ncode in a future version.",
      "tldr_zh": "本研究提出 EvoLlama，一种多模态框架，用于增强 Large Language Models (LLMs) 对蛋白质的理解，通过整合结构-based 编码器和序列-based 蛋白编码器。EvoLlama 包括 ProteinMPNN 结构编码器、ESM-2 序列编码器、多模态投影器（用于对齐蛋白质和文本表示）以及 Llama-3 文本解码器，并通过在蛋白质导向指令和属性预测数据集上微调来训练模型。实验结果显示，EvoLlama 在零样本设置中平均超过其他微调的蛋白质导向 LLMs 1%-8%，并在监督微调中超越最先进基线平均 6%；在蛋白质属性预测任务上，其表现与任务特定基线具有竞争力。总的来说，该框架桥接了 LLMs 与蛋白质结构/序列知识的差距，提升了蛋白质理解能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11618v1",
      "published_date": "2024-12-16 10:01:33 UTC",
      "updated_date": "2024-12-16 10:01:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:30:48.822947"
    },
    {
      "arxiv_id": "2412.11605v2",
      "title": "SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Cheng",
        "Xiao Liu",
        "Cunxiang Wang",
        "Xiaotao Gu",
        "Yida Lu",
        "Dan Zhang",
        "Yuxiao Dong",
        "Jie Tang",
        "Hongning Wang",
        "Minlie Huang"
      ],
      "abstract": "Instruction-following is a fundamental capability of language models,\nrequiring the model to recognize even the most subtle requirements in the\ninstructions and accurately reflect them in its output. Such an ability is\nwell-suited for and often optimized by preference learning. However, existing\nmethods often directly sample multiple independent responses from the model\nwhen creating preference pairs. Such practice can introduce content variations\nirrelevant to whether the instruction is precisely followed (e.g., different\nexpressions about the same semantic), interfering with the goal of teaching\nmodels to recognize the key differences that lead to improved instruction\nfollowing. In light of this, we introduce SPaR, a self-play framework\nintegrating tree-search self-refinement to yield valid and comparable\npreference pairs free from distractions. By playing against itself, an LLM\nemploys a tree-search strategy to refine its previous responses with respect to\nthe instruction while minimizing unnecessary variations. Our experiments show\nthat a LLaMA3-8B model, trained over three iterations guided by SPaR, surpasses\nGPT-4-Turbo on the IFEval benchmark without losing general capabilities.\nFurthermore, SPaR demonstrates promising scalability, greatly enhancing models\nlike GLM-4-9B and LLaMA3-70B. We also identify how inference scaling in tree\nsearch would impact model performance. Our code and data are publicly available\nat https://github.com/thu-coai/SPaR.",
      "tldr_zh": "该论文提出 SPaR 框架，一种结合 self-play 和 tree-search refinement 的自玩机制，旨在改进大型语言模型(LLMs)的指令遵循能力，避免现有 preference learning 方法中无关内容变化（如语义相同但表达不同）干扰关键差异的优化。SPaR 通过让模型自我对抗并使用树搜索策略生成有效的、可比较的偏好对，从而精确提升指令识别和响应质量。实验结果显示，训练后的 LLaMA3-8B 模型在 IFEval 基准上超越了 GPT-4-Turbo，同时保留了通用能力；此外，SPaR 在模型如 GLM-4-9B 和 LLaMA3-70B 上显示出良好的可扩展性，并探讨了树搜索推理规模对性能的影响。代码和数据已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11605v2",
      "published_date": "2024-12-16 09:47:43 UTC",
      "updated_date": "2025-03-16 09:43:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:31:01.343234"
    },
    {
      "arxiv_id": "2412.12223v2",
      "title": "Can video generation replace cinematographers? Research on the cinematic language of generated video",
      "title_zh": "视频生成能取代电影摄影师吗？ 生成视频的电影语言研究",
      "authors": [
        "Xiaozhe Li",
        "Kai WU",
        "Siyi Yang",
        "YiZhan Qu",
        "Guohua. Zhang",
        "Zhiyu Chen",
        "Jiayao Li",
        "Jiangchuan Mu",
        "Xiaobin Hu",
        "Wen Fang",
        "Mingliang Xiong",
        "Hao Deng",
        "Qingwen Liu",
        "Gang Li",
        "Bin He"
      ],
      "abstract": "Recent advancements in text-to-video (T2V) generation have leveraged\ndiffusion models to enhance visual coherence in videos synthesized from textual\ndescriptions. However, existing research primarily focuses on object motion,\noften overlooking cinematic language, which is crucial for conveying emotion\nand narrative pacing in cinematography. To address this, we propose a threefold\napproach to improve cinematic control in T2V models. First, we introduce a\nmeticulously annotated cinematic language dataset with twenty subcategories,\ncovering shot framing, shot angles, and camera movements, enabling models to\nlearn diverse cinematic styles. Second, we present CameraDiff, which employs\nLoRA for precise and stable cinematic control, ensuring flexible shot\ngeneration. Third, we propose CameraCLIP, designed to evaluate cinematic\nalignment and guide multi-shot composition. Building on CameraCLIP, we\nintroduce CLIPLoRA, a CLIP-guided dynamic LoRA composition method that\nadaptively fuses multiple pre-trained cinematic LoRAs, enabling smooth\ntransitions and seamless style blending. Experimental results demonstrate that\nCameraDiff ensures stable and precise cinematic control, CameraCLIP achieves an\nR@1 score of 0.83, and CLIPLoRA significantly enhances multi-shot composition\nwithin a single video, bridging the gap between automated video generation and\nprofessional cinematography.\\textsuperscript{1}",
      "tldr_zh": "本研究探讨文本到视频(T2V)生成模型是否能取代摄影师，焦点在于提升生成的视频对电影语言(cinematic language)的控制，以更好地传达情感和叙事节奏。研究者提出一个详细注释的电影语言数据集，涵盖二十个子类别如镜头构图(shot framing)、镜头角度(shot angles)和相机运动(camera movements)，并开发了CameraDiff使用LoRA实现精确稳定的镜头生成，以及CameraCLIP用于评估电影对齐并指导多镜头组合。基于CameraCLIP，他们进一步引入CLIPLoRA，一种CLIP引导的动态LoRA组合方法，能自适应融合多个预训练的电影LoRA，实现平滑过渡和风格混合；实验结果显示，CameraDiff提供稳定控制、CameraCLIP的R@1分数达0.83，且CLIPLoRA显著改善多镜头合成，缩小了自动视频生成与专业摄影间的差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.12223v2",
      "published_date": "2024-12-16 09:02:24 UTC",
      "updated_date": "2025-03-28 03:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:31:12.111605"
    },
    {
      "arxiv_id": "2412.11556v1",
      "title": "Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Fu",
        "Zifeng Cheng",
        "Zhiwei Jiang",
        "Zhonghui Wang",
        "Yafeng Yin",
        "Zhengliang Li",
        "Qing Gu"
      ],
      "abstract": "Extracting sentence embeddings from large language models (LLMs) is a\npromising direction, as LLMs have demonstrated stronger semantic understanding\ncapabilities. Previous studies typically focus on prompt engineering to elicit\nsentence embeddings from LLMs by prompting the model to encode sentence\ninformation into the embedding of the last token. However, LLMs are mostly\ndecoder-only models with causal attention and the earlier tokens in the\nsentence cannot attend to the latter tokens, resulting in biased encoding of\nsentence information and cascading effects on the final decoded token. To this\nend, we propose a novel Token Prepending (TP) technique that prepends each\nlayer's decoded sentence embedding to the beginning of the sentence in the next\nlayer's input, allowing earlier tokens to attend to the complete sentence\ninformation under the causal attention mechanism. The proposed TP technique is\na plug-and-play and training-free technique, which means it can be seamlessly\nintegrated with various prompt-based sentence embedding methods and\nautoregressive LLMs. Extensive experiments on various Semantic Textual\nSimilarity (STS) tasks and downstream classification tasks demonstrate that our\nproposed TP technique can significantly improve the performance of existing\nprompt-based sentence embedding methods across different LLMs, while incurring\nnegligible additional inference cost.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)提取句子嵌入(sentence embeddings)时因因果注意力(causal attention)机制导致的编码偏差问题，提出了一种无需训练的Token Prepending (TP)技术。该方法在每个层中将解码的句子嵌入添加到下一层的输入开头，从而允许早期token访问完整句子信息，并与各种基于提示的句子嵌入方法无缝整合。实验结果显示，TP显著提升了现有方法的性能，在语义文本相似性(Semantic Textual Similarity, STS)任务和下游分类任务上表现出色，同时仅带来微不足道的额外推理成本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11556v1",
      "published_date": "2024-12-16 08:42:00 UTC",
      "updated_date": "2024-12-16 08:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:33:24.712693"
    },
    {
      "arxiv_id": "2412.11555v1",
      "title": "TS-SatFire: A Multi-Task Satellite Image Time-Series Dataset for Wildfire Detection and Prediction",
      "title_zh": "TS-SatFire：一个",
      "authors": [
        "Yu Zhao",
        "Sebastian Gerard",
        "Yifang Ban"
      ],
      "abstract": "Wildfire monitoring and prediction are essential for understanding wildfire\nbehaviour. With extensive Earth observation data, these tasks can be integrated\nand enhanced through multi-task deep learning models. We present a\ncomprehensive multi-temporal remote sensing dataset for active fire detection,\ndaily wildfire monitoring, and next-day wildfire prediction. Covering wildfire\nevents in the contiguous U.S. from January 2017 to October 2021, the dataset\nincludes 3552 surface reflectance images and auxiliary data such as weather,\ntopography, land cover, and fuel information, totalling 71 GB. The lifecycle of\neach wildfire is documented, with labels for active fires (AF) and burned areas\n(BA), supported by manual quality assurance of AF and BA test labels. The\ndataset supports three tasks: a) active fire detection, b) daily burned area\nmapping, and c) wildfire progression prediction. Detection tasks use pixel-wise\nclassification of multi-spectral, multi-temporal images, while prediction tasks\nintegrate satellite and auxiliary data to model fire dynamics. This dataset and\nits benchmarks provide a foundation for advancing wildfire research using deep\nlearning.",
      "tldr_zh": "本研究介绍了TS-SatFire数据集，这是一个多任务卫星图像时序数据集，旨在通过多任务深度学习模型提升野火检测和预测能力。数据集涵盖2017年至2021年美国本土的野火事件，包括3552张地表反射图像以及辅助数据（如天气、地形、土地覆盖和燃料信息），总计71 GB，并为每个野火生命周期提供活跃火点(AF)和烧毁区域(BA)的标签。TS-SatFire支持三个关键任务：a) 活跃火点检测，b) 每日烧毁区域映射，以及c) 下一天野火进展预测，这些任务利用像素级分类的多光谱、多时相图像和辅助数据来建模火动态。该数据集及其基准为利用深度学习推进野火研究提供了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11555v1",
      "published_date": "2024-12-16 08:40:12 UTC",
      "updated_date": "2024-12-16 08:40:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:31:35.583980"
    },
    {
      "arxiv_id": "2412.11551v1",
      "title": "Region-Based Optimization in Continual Learning for Audio Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yujie Chen",
        "Jiangyan Yi",
        "Cunhang Fan",
        "Jianhua Tao",
        "Yong Ren",
        "Siding Zeng",
        "Chu Yuan Zhang",
        "Xinrui Yan",
        "Hao Gu",
        "Jun Xue",
        "Chenglong Wang",
        "Zhao Lv",
        "Xiaohui Zhang"
      ],
      "abstract": "Rapid advancements in speech synthesis and voice conversion bring convenience\nbut also new security risks, creating an urgent need for effective audio\ndeepfake detection. Although current models perform well, their effectiveness\ndiminishes when confronted with the diverse and evolving nature of real-world\ndeepfakes. To address this issue, we propose a continual learning method named\nRegion-Based Optimization (RegO) for audio deepfake detection. Specifically, we\nuse the Fisher information matrix to measure important neuron regions for real\nand fake audio detection, dividing them into four regions. First, we directly\nfine-tune the less important regions to quickly adapt to new tasks. Next, we\napply gradient optimization in parallel for regions important only to real\naudio detection, and in orthogonal directions for regions important only to\nfake audio detection. For regions that are important to both, we use sample\nproportion-based adaptive gradient optimization. This region-adaptive\noptimization ensures an appropriate trade-off between memory stability and\nlearning plasticity. Additionally, to address the increase of redundant neurons\nfrom old tasks, we further introduce the Ebbinghaus forgetting mechanism to\nrelease them, thereby promoting the capability of the model to learn more\ngeneralized discriminative features. Experimental results show our method\nachieves a 21.3% improvement in EER over the state-of-the-art continual\nlearning approach RWM for audio deepfake detection. Moreover, the effectiveness\nof RegO extends beyond the audio deepfake detection domain, showing potential\nsignificance in other tasks, such as image recognition. The code is available\nat https://github.com/cyjie429/RegO",
      "tldr_zh": "本文提出了一种名为 Region-Based Optimization (RegO) 的持续学习方法，用于音频深度伪造检测，以应对真实世界深度伪造的多样性和演变挑战。RegO 通过 Fisher information matrix 测量并划分神经元区域为四类，对不太重要的区域直接微调，而对特定区域采用并行、正交或基于样本比例的自适应梯度优化，并引入 Ebbinghaus forgetting mechanism 来释放冗余神经元，从而平衡记忆稳定性和学习可塑性。实验结果显示，该方法在音频深度伪造检测上比最先进方法 RWM 改善了 21.3% 的 EER。此外，RegO 的有效性扩展到图像识别等其他任务中，展示了其广泛潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11551v1",
      "published_date": "2024-12-16 08:34:09 UTC",
      "updated_date": "2024-12-16 08:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:31:48.374244"
    },
    {
      "arxiv_id": "2412.11543v2",
      "title": "Error Diversity Matters: An Error-Resistant Ensemble Method for Unsupervised Dependency Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Behzad Shayegh",
        "Hobie H. -B. Lee",
        "Xiaodan Zhu",
        "Jackie Chi Kit Cheung",
        "Lili Mou"
      ],
      "abstract": "We address unsupervised dependency parsing by building an ensemble of diverse\nexisting models through post hoc aggregation of their output dependency parse\nstructures. We observe that these ensembles often suffer from low robustness\nagainst weak ensemble components due to error accumulation. To tackle this\nproblem, we propose an efficient ensemble-selection approach that considers\nerror diversity and avoids error accumulation. Results demonstrate that our\napproach outperforms each individual model as well as previous ensemble\ntechniques. Additionally, our experiments show that the proposed\nensemble-selection method significantly enhances the performance and robustness\nof our ensemble, surpassing previously proposed strategies, which have not\naccounted for error diversity.",
      "tldr_zh": "该论文针对无监督依赖解析（unsupervised dependency parsing）提出了一种抗错误的集成方法，通过后处理聚合现有模型的输出依赖结构来构建多样化集成（ensemble）。为解决集成中弱组件导致的错误积累问题，该方法引入考虑错误多样性（error diversity）的高效集成选择策略，避免错误积累并提升整体鲁棒性。实验结果表明，该方法优于每个独立模型和先前技术，在性能和鲁棒性方面实现了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by the AAAI Conference on Artificial Intelligence (AAAI)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11543v2",
      "published_date": "2024-12-16 08:23:50 UTC",
      "updated_date": "2025-02-06 21:00:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:31:58.498877"
    },
    {
      "arxiv_id": "2412.11540v1",
      "title": "SP$^2$T: Sparse Proxy Attention for Dual-stream Point Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxu Wan",
        "Hong Zhang",
        "Ziqi He",
        "Qishu Wang",
        "Ding Yuan",
        "Yifan Yang"
      ],
      "abstract": "In 3D understanding, point transformers have yielded significant advances in\nbroadening the receptive field. However, further enhancement of the receptive\nfield is hindered by the constraints of grouping attention. The proxy-based\nmodel, as a hot topic in image and language feature extraction, uses global or\nlocal proxies to expand the model's receptive field. But global proxy-based\nmethods fail to precisely determine proxy positions and are not suited for\ntasks like segmentation and detection in the point cloud, and exist local\nproxy-based methods for image face difficulties in global-local balance, proxy\nsampling in various point clouds, and parallel cross-attention computation for\nsparse association. In this paper, we present SP$^2$T, a local proxy-based dual\nstream point transformer, which promotes global receptive field while\nmaintaining a balance between local and global information. To tackle robust 3D\nproxy sampling, we propose a spatial-wise proxy sampling with vertex-based\npoint proxy associations, ensuring robust point-cloud sampling in many scales\nof point cloud. To resolve economical association computation, we introduce\nsparse proxy attention combined with table-based relative bias, which enables\nlow-cost and precise interactions between proxy and point features.\nComprehensive experiments across multiple datasets reveal that our model\nachieves SOTA performance in downstream tasks. The code has been released in\nhttps://github.com/TerenceWallel/Sparse-Proxy-Point-Transformer .",
      "tldr_zh": "本文提出 SP²T，一种基于稀疏代理注意力的双流点变换器（Dual-stream Point Transformer），旨在解决传统点变换器在扩展感受野时受限于分组注意力的挑战。SP²T 通过空间-wise 代理采样和基于顶点的点代理关联，实现鲁棒的点云采样，并在不同规模下平衡全局和局部信息；同时，引入稀疏代理注意力（Sparse Proxy Attention）结合基于表的相对偏差，降低计算成本并精确处理代理与点特征的交互。实验结果显示，SP²T 在多个点云理解数据集上达到 SOTA 性能，为 3D 任务如分割和检测提供了高效改进。代码已开源于 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 14 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.11540v1",
      "published_date": "2024-12-16 08:21:09 UTC",
      "updated_date": "2024-12-16 08:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:32:11.558802"
    },
    {
      "arxiv_id": "2412.11538v2",
      "title": "MERaLiON-SpeechEncoder: Towards a Speech Foundation Model for Singapore and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Huzaifah",
        "Geyu Lin",
        "Tianchi Liu",
        "Hardik B. Sailor",
        "Kye Min Tan",
        "Tarun K. Vangani",
        "Qiongqiong Wang",
        "Jeremy H. M. Wong",
        "Nancy F. Chen",
        "Ai Ti Aw"
      ],
      "abstract": "This technical report describes the MERaLiON-SpeechEncoder, a foundation\nmodel designed to support a wide range of downstream speech applications.\nDeveloped as part of Singapore's National Multimodal Large Language Model\nProgramme, the MERaLiON-SpeechEncoder is tailored to address the speech\nprocessing needs in Singapore and the surrounding Southeast Asian region. The\nmodel currently supports mainly English, including the variety spoken in\nSingapore. We are actively expanding our datasets to gradually cover other\nlanguages in subsequent releases. The MERaLiON-SpeechEncoder was pre-trained\nfrom scratch on 200,000 hours of unlabelled speech data using a self-supervised\nlearning approach based on masked language modelling. We describe our training\nprocedure and hyperparameter tuning experiments in detail below. Our evaluation\ndemonstrates improvements to spontaneous and Singapore speech benchmarks for\nspeech recognition, while remaining competitive to other state-of-the-art\nspeech encoders across ten other speech tasks. We commit to releasing our\nmodel, supporting broader research endeavours, both in Singapore and beyond.",
      "tldr_zh": "本研究介绍了MERaLiON-SpeechEncoder，这是一个针对新加坡和东南亚地区语音处理需求的语音基础模型，支持多种下游应用，目前主要聚焦于新加坡英语。模型采用自监督学习(self-supervised learning)方法，通过masked language modelling在20万小时的无标签语音数据上从零预训练，并详细优化了训练过程和超参数。评估结果显示，该模型在语音识别任务上显著提升了新加坡和自发性语音的基准表现，并在其他十个语音任务上与最先进模型保持竞争力。新加坡国家多模态大语言模型计划承诺开源该模型，并计划扩展支持更多语言，以推动更广泛的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11538v2",
      "published_date": "2024-12-16 08:15:19 UTC",
      "updated_date": "2024-12-20 09:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:32:23.138411"
    },
    {
      "arxiv_id": "2412.11520v2",
      "title": "EditSplat: Multi-View Fusion and Attention-Guided Optimization for View-Consistent 3D Scene Editing with 3D Gaussian Splatting",
      "title_zh": "EditSplat：多视图融合和注意力引导优化，用于实现视图一致的3D",
      "authors": [
        "Dong In Lee",
        "Hyeongcheol Park",
        "Jiyoung Seo",
        "Eunbyung Park",
        "Hyunje Park",
        "Ha Dam Baek",
        "Sangheon Shin",
        "Sangmin Kim",
        "Sangpil Kim"
      ],
      "abstract": "Recent advancements in 3D editing have highlighted the potential of\ntext-driven methods in real-time, user-friendly AR/VR applications. However,\ncurrent methods rely on 2D diffusion models without adequately considering\nmulti-view information, resulting in multi-view inconsistency. While 3D\nGaussian Splatting (3DGS) significantly improves rendering quality and speed,\nits 3D editing process encounters difficulties with inefficient optimization,\nas pre-trained Gaussians retain excessive source information, hindering\noptimization. To address these limitations, we propose EditSplat, a novel\ntext-driven 3D scene editing framework that integrates Multi-view Fusion\nGuidance (MFG) and Attention-Guided Trimming (AGT). Our MFG ensures multi-view\nconsistency by incorporating essential multi-view information into the\ndiffusion process, leveraging classifier-free guidance from the text-to-image\ndiffusion model and the geometric structure inherent to 3DGS. Additionally, our\nAGT utilizes the explicit representation of 3DGS to selectively prune and\noptimize 3D Gaussians, enhancing optimization efficiency and enabling precise,\nsemantically rich local editing. Through extensive qualitative and quantitative\nevaluations, EditSplat achieves state-of-the-art performance, establishing a\nnew benchmark for text-driven 3D scene editing.",
      "tldr_zh": "本文提出EditSplat，一种基于文本驱动的3D场景编辑框架，利用Multi-view Fusion Guidance (MFG)和Attention-Guided Trimming (AGT)，以解决现有方法在多视图不一致和优化效率方面的局限性。MFG通过将多视图信息融入扩散过程，并结合3D Gaussian Splatting (3DGS)的几何结构和classifier-free guidance，确保编辑结果的多视图一致性。AGT则通过选择性地修剪和优化3D高斯，实现高效的、语义丰富的局部编辑。实验评估表明，EditSplat在定性和定量指标上达到了最先进性能，为文本驱动3D场景编辑设定了新基准。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11520v2",
      "published_date": "2024-12-16 07:56:04 UTC",
      "updated_date": "2025-04-17 20:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:33:37.234633"
    },
    {
      "arxiv_id": "2412.11517v2",
      "title": "DART: An AIGT Detector using AMR of Rephrased Text",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonchu Park",
        "Byungjun Kim",
        "Bugeun Kim"
      ],
      "abstract": "As large language models (LLMs) generate more human-like texts, concerns\nabout the side effects of AI-generated texts (AIGT) have grown. So, researchers\nhave developed methods for detecting AIGT. However, two challenges remain.\nFirst, the performance of detecting black-box LLMs is low because existing\nmodels focus on probabilistic features. Second, most AIGT detectors have been\ntested on a single-candidate setting, which assumes that we know the origin of\nan AIGT and which may deviate from the real-world scenario. To resolve these\nchallenges, we propose DART, which consists of four steps: rephrasing, semantic\nparsing, scoring, and multiclass classification. We conducted three experiments\nto test the performance of DART. The experimental result shows that DART can\ndiscriminate multiple black-box LLMs without probabilistic features and the\norigin of AIGT.",
      "tldr_zh": "研究提出 DART，一种新型 AI 生成文本 (AIGT) 检测器，通过对文本进行 rephrasing（改写）、semantic parsing（语义解析）、scoring（评分）和 multiclass classification（多类分类）四个步骤，利用抽象含义表示 (AMR) 来分析改写后的文本。DART 旨在解决现有检测方法在黑盒 LLMs（大型语言模型）上的低性能问题，以及单候选设置的局限性，不依赖概率特征即可识别 AIGT 的来源。实验结果显示，DART 能够有效区分多个黑盒 LLMs，并在真实场景中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented in NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11517v2",
      "published_date": "2024-12-16 07:51:09 UTC",
      "updated_date": "2025-02-04 10:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:33:48.334853"
    },
    {
      "arxiv_id": "2412.11506v2",
      "title": "Glimpse: Enabling White-Box Methods to Use Proprietary Models for Zero-Shot LLM-Generated Text Detection",
      "title_zh": "Glimpse：使白盒方法能够使用专有模型进行零样本LLM生成文本检测",
      "authors": [
        "Guangsheng Bao",
        "Yanbin Zhao",
        "Juncai He",
        "Yue Zhang"
      ],
      "abstract": "Advanced large language models (LLMs) can generate text almost\nindistinguishable from human-written text, highlighting the importance of\nLLM-generated text detection. However, current zero-shot techniques face\nchallenges as white-box methods are restricted to use weaker open-source LLMs,\nand black-box methods are limited by partial observation from stronger\nproprietary LLMs. It seems impossible to enable white-box methods to use\nproprietary models because API-level access to the models neither provides full\npredictive distributions nor inner embeddings. To traverse the divide, we\npropose **Glimpse**, a probability distribution estimation approach, predicting\nthe full distributions from partial observations. Despite the simplicity of\nGlimpse, we successfully extend white-box methods like Entropy, Rank, Log-Rank,\nand Fast-DetectGPT to latest proprietary models. Experiments show that Glimpse\nwith Fast-DetectGPT and GPT-3.5 achieves an average AUROC of about 0.95 in five\nlatest source models, improving the score by 51% relative to the remaining\nspace of the open source baseline. It demonstrates that the latest LLMs can\neffectively detect their own outputs, suggesting that advanced LLMs may be the\nbest shield against themselves. We release our code and data at\nhttps://github.com/baoguangsheng/glimpse.",
      "tldr_zh": "该研究提出Glimpse，一种概率分布估计方法，旨在解决zero-shot LLM-Generated Text Detection中的挑战，即white-box methods无法直接使用proprietary models。Glimpse通过从API提供的部分观察预测完整的预测分布，从而扩展white-box方法如Entropy、Rank、Log-Rank和Fast-DetectGPT到最新的私有模型。实验结果显示，Glimpse结合Fast-DetectGPT和GPT-3.5在五个最新源模型上平均AUROC达到约0.95，比开源基线提高了51%。这一发现表明，先进的LLMs能够有效检测自身输出，从而作为对抗自身生成文本的最佳工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 camera version (10 pages, 9 figures, 9 tables)",
      "pdf_url": "http://arxiv.org/pdf/2412.11506v2",
      "published_date": "2024-12-16 07:28:36 UTC",
      "updated_date": "2025-02-19 07:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:00.438359"
    },
    {
      "arxiv_id": "2412.11500v2",
      "title": "Intention Knowledge Graph Construction for User Intention Relation Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Bai",
        "Zhaobo Wang",
        "Junfei Cheng",
        "Dan Yu",
        "Zerui Huang",
        "Weiqi Wang",
        "Xin Liu",
        "Chen Luo",
        "Yanming Zhu",
        "Bo Li",
        "Yangqiu Song"
      ],
      "abstract": "Understanding user intentions is challenging for online platforms. Recent\nwork on intention knowledge graphs addresses this but often lacks focus on\nconnecting intentions, which is crucial for modeling user behavior and\npredicting future actions. This paper introduces a framework to automatically\ngenerate an intention knowledge graph, capturing connections between user\nintentions. Using the Amazon m2 dataset, we construct an intention graph with\n351 million edges, demonstrating high plausibility and acceptance. Our model\neffectively predicts new session intentions and enhances product\nrecommendations, outperforming previous state-of-the-art methods and showcasing\nthe approach's practical utility.",
      "tldr_zh": "本论文针对在线平台理解用户意图的挑战，提出一个自动构建Intention Knowledge Graph的框架，以捕捉意图之间的连接，从而更好地模型用户行为和预测未来行动。使用Amazon m2数据集，该框架生成了一个包含351 million edges的意图图，并证明其具有高可信度和接受度。实验结果显示，该模型在预测新会话意图和提升产品推荐方面，优于现有最先进方法，展示了其实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11500v2",
      "published_date": "2024-12-16 07:18:40 UTC",
      "updated_date": "2025-05-17 05:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:11.390226"
    },
    {
      "arxiv_id": "2412.11499v1",
      "title": "Embodied CoT Distillation From LLM To Off-the-shelf Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wonje Choi",
        "Woo Kyung Kim",
        "Minjong Yoo",
        "Honguk Woo"
      ],
      "abstract": "We address the challenge of utilizing large language models (LLMs) for\ncomplex embodied tasks, in the environment where decision-making systems\noperate timely on capacity-limited, off-the-shelf devices. We present DeDer, a\nframework for decomposing and distilling the embodied reasoning capabilities\nfrom LLMs to efficient, small language model (sLM)-based policies. In DeDer,\nthe decision-making process of LLM-based strategies is restructured into a\nhierarchy with a reasoning-policy and planning-policy. The reasoning-policy is\ndistilled from the data that is generated through the embodied in-context\nlearning and self-verification of an LLM, so it can produce effective\nrationales. The planning-policy, guided by the rationales, can render optimized\nplans efficiently. In turn, DeDer allows for adopting sLMs for both policies,\ndeployed on off-the-shelf devices. Furthermore, to enhance the quality of\nintermediate rationales, specific to embodied tasks, we devise the embodied\nknowledge graph, and to generate multiple rationales timely through a single\ninference, we also use the contrastively prompted attention model. Our\nexperiments with the ALFRED benchmark demonstrate that DeDer surpasses leading\nlanguage planning and distillation approaches, indicating the applicability and\nefficiency of sLM-based embodied policies derived through DeDer.",
      "tldr_zh": "该研究提出 DeDer 框架，用于将大型语言模型 (LLMs) 的实体推理能力提炼到高效的小语言模型 (sLM) 策略中，以适应容量有限的现成设备在复杂实体任务中的实时决策。DeDer 将 LLM 的决策过程重构为一个层次结构，包括通过实体上下文学习和自我验证生成数据的推理策略，以及基于这些推理指导的规划策略；此外，还引入实体知识图和对比提示注意力模型来提升中间推理的质量和效率。在 ALFRED 基准测试中，DeDer 超过了领先的语言规划和提炼方法，证明了 sLM 策略的适用性和性能提升。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.11499v1",
      "published_date": "2024-12-16 07:18:02 UTC",
      "updated_date": "2024-12-16 07:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:25.696794"
    },
    {
      "arxiv_id": "2412.11489v1",
      "title": "HGSFusion: Radar-Camera Fusion with Hybrid Generation and Synchronization for 3D Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Gu",
        "Jianwei Ma",
        "Yan Huang",
        "Honghao Wei",
        "Zhanye Chen",
        "Hui Zhang",
        "Wei Hong"
      ],
      "abstract": "Millimeter-wave radar plays a vital role in 3D object detection for\nautonomous driving due to its all-weather and all-lighting-condition\ncapabilities for perception. However, radar point clouds suffer from pronounced\nsparsity and unavoidable angle estimation errors. To address these limitations,\nincorporating a camera may partially help mitigate the shortcomings.\nNevertheless, the direct fusion of radar and camera data can lead to negative\nor even opposite effects due to the lack of depth information in images and\nlow-quality image features under adverse lighting conditions. Hence, in this\npaper, we present the radar-camera fusion network with Hybrid Generation and\nSynchronization (HGSFusion), designed to better fuse radar potentials and image\nfeatures for 3D object detection. Specifically, we propose the Radar Hybrid\nGeneration Module (RHGM), which fully considers the Direction-Of-Arrival (DOA)\nestimation errors in radar signal processing. This module generates denser\nradar points through different Probability Density Functions (PDFs) with the\nassistance of semantic information. Meanwhile, we introduce the Dual Sync\nModule (DSM), comprising spatial sync and modality sync, to enhance image\nfeatures with radar positional information and facilitate the fusion of\ndistinct characteristics in different modalities. Extensive experiments\ndemonstrate the effectiveness of our approach, outperforming the\nstate-of-the-art methods in the VoD and TJ4DRadSet datasets by $6.53\\%$ and\n$2.03\\%$ in RoI AP and BEV AP, respectively. The code is available at\nhttps://github.com/garfield-cpp/HGSFusion.",
      "tldr_zh": "这篇论文提出了 HGSFusion，一种用于自动驾驶 3D 对象检测的雷达-相机融合网络，旨在解决雷达点云的稀疏性和角度估计错误问题，同时避免直接融合带来的负面影响。核心组件包括 Radar Hybrid Generation Module (RHGM)，它通过考虑 Direction-Of-Arrival (DOA) 估计错误并利用不同 Probability Density Functions (PDFs) 和语义信息生成更密集的雷达点。另一个关键模块是 Dual Sync Module (DSM)，通过空间同步和模态同步增强图像特征并融合雷达位置信息。实验结果显示，HGSFusion 在 VoD 和 TJ4DRadSet 数据集上分别在 RoI AP 和 BEV AP 上超过了最先进方法 6.53% 和 2.03%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures, 7 tables. Accepted by AAAI 2025 , the 39th\n  Annual AAAI Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2412.11489v1",
      "published_date": "2024-12-16 07:06:17 UTC",
      "updated_date": "2024-12-16 07:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:37.074917"
    },
    {
      "arxiv_id": "2412.11484v1",
      "title": "Efficient Policy Adaptation with Contrastive Prompt Ensemble for Embodied Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Wonje Choi",
        "Woo Kyung Kim",
        "SeungHyun Kim",
        "Honguk Woo"
      ],
      "abstract": "For embodied reinforcement learning (RL) agents interacting with the\nenvironment, it is desirable to have rapid policy adaptation to unseen visual\nobservations, but achieving zero-shot adaptation capability is considered as a\nchallenging problem in the RL context. To address the problem, we present a\nnovel contrastive prompt ensemble (ConPE) framework which utilizes a pretrained\nvision-language model and a set of visual prompts, thus enabling efficient\npolicy learning and adaptation upon a wide range of environmental and physical\nchanges encountered by embodied agents. Specifically, we devise a\nguided-attention-based ensemble approach with multiple visual prompts on the\nvision-language model to construct robust state representations. Each prompt is\ncontrastively learned in terms of an individual domain factor that\nsignificantly affects the agent's egocentric perception and observation. For a\ngiven task, the attention-based ensemble and policy are jointly learned so that\nthe resulting state representations not only generalize to various domains but\nare also optimized for learning the task. Through experiments, we show that\nConPE outperforms other state-of-the-art algorithms for several embodied agent\ntasks including navigation in AI2THOR, manipulation in egocentric-Metaworld,\nand autonomous driving in CARLA, while also improving the sample efficiency of\npolicy learning and adaptation.",
      "tldr_zh": "该研究提出了一种高效政策适应框架Contrastive Prompt Ensemble (ConPE)，针对强化学习（RL）中的具身代理（embodied agents），实现对未见视觉观察的零样本适应（zero-shot adaptation）。框架利用预训练的视觉语言模型（vision-language model）和一组视觉提示，通过引导注意力机制的集成方法，对每个提示进行对比学习，以构建鲁棒的状态表示，并针对特定任务联合优化注意力与政策。实验结果显示，ConPE在AI2THOR导航、egocentric-Metaworld操作和CARLA自动驾驶等任务中优于现有算法，同时显著提高了政策学习和适应的样本效率。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2412.11484v1",
      "published_date": "2024-12-16 06:53:00 UTC",
      "updated_date": "2024-12-16 06:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:48.887966"
    },
    {
      "arxiv_id": "2412.11472v1",
      "title": "Leveraging Foundation Language Models (FLMs) for Automated Cohort Extraction from Large EHR Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Purity Mugambi",
        "Alexandra Meliou",
        "Madalina Fiterau"
      ],
      "abstract": "A crucial step in cohort studies is to extract the required cohort from one\nor more study datasets. This step is time-consuming, especially when a\nresearcher is presented with a dataset that they have not previously worked\nwith. When the cohort has to be extracted from multiple datasets, cohort\nextraction can be extremely laborious. In this study, we present an approach\nfor partially automating cohort extraction from multiple electronic health\nrecord (EHR) databases. We formulate the guided multi-dataset cohort extraction\nproblem in which selection criteria are first converted into queries,\ntranslating them from natural language text to language that maps to database\nentities. Then, using FLMs, columns of interest identified from the queries are\nautomatically matched between the study databases. Finally, the generated\nqueries are run across all databases to extract the study cohort. We propose\nand evaluate an algorithm for automating column matching on two large, popular\nand publicly-accessible EHR databases -- MIMIC-III and eICU. Our approach\nachieves a high top-three accuracy of $92\\%$, correctly matching $12$ out of\nthe $13$ columns of interest, when using a small, pre-trained general purpose\nlanguage model. Furthermore, this accuracy is maintained even as the search\nspace (i.e., size of the database) increases.",
      "tldr_zh": "这篇论文提出了一种利用基础语言模型(FLMs)自动从多个电子健康记录(EHR)数据库中提取研究队列的方法，以解决手动提取耗时的问题。方法包括将自然语言选择标准转换为数据库查询，并使用FLMs自动匹配感兴趣的列，如在MIMIC-III和eICU数据库中进行操作。实验结果显示，该算法在小型预训练模型下实现了92%的top-three准确率，正确匹配了13列中的12列，且在数据库规模增加时保持了鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11472v1",
      "published_date": "2024-12-16 06:19:35 UTC",
      "updated_date": "2024-12-16 06:19:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:34:59.772716"
    },
    {
      "arxiv_id": "2412.11471v1",
      "title": "Red Pill and Blue Pill: Controllable Website Fingerprinting Defense via Dynamic Backdoor Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Liang",
        "Jiajun Gong",
        "Tianmeng Fang",
        "Aishan Liu",
        "Tao Wang",
        "Xianglong Liu",
        "Xiaochun Cao",
        "Dacheng Tao",
        "Chang Ee-Chien"
      ],
      "abstract": "Website fingerprint (WF) attacks, which covertly monitor user communications\nto identify the web pages they visit, pose a serious threat to user privacy.\nExisting WF defenses attempt to reduce the attacker's accuracy by disrupting\nunique traffic patterns; however, they often suffer from the trade-off between\noverhead and effectiveness, resulting in less usefulness in practice. To\novercome this limitation, we introduce Controllable Website Fingerprint Defense\n(CWFD), a novel defense perspective based on backdoor learning. CWFD exploits\nbackdoor vulnerabilities in neural networks to directly control the attacker's\nmodel by designing trigger patterns based on network traffic. Specifically,\nCWFD injects only incoming packets on the server side into the target web\npage's traffic, keeping overhead low while effectively poisoning the attacker's\nmodel during training. During inference, the defender can influence the\nattacker's model through a 'red pill, blue pill' choice: traces with the\ntrigger (red pill) lead to misclassification as the target web page, while\nnormal traces (blue pill) are classified correctly, achieving directed control\nover the defense outcome. We use the Fast Levenshtein-like distance as the\noptimization objective to compute trigger patterns that can be effectively\nassociated with our target page. Experiments show that CWFD significantly\nreduces RF's accuracy from 99% to 6% with 74% data overhead. In comparison,\nFRONT reduces accuracy to only 97% at similar overhead, while Palette achieves\n32% accuracy with 48% more overhead. We further validate the practicality of\nour method in a real Tor network environment.",
      "tldr_zh": "该论文提出 CWFD（Controllable Website Fingerprint Defense），一种基于 backdoor learning 的网站指纹（Website Fingerprint）防御方法，通过在服务器端注入传入数据包作为触发模式，来直接控制攻击者的神经网络模型。防御者可通过 'red pill'（触发器）使目标网页流量被误分类，或 'blue pill'（正常流量）保持正确分类，实现对防御效果的定向控制。实验显示，CWFD 将攻击准确率从 99% 降至 6%，开销仅为 74%，比现有方法如 FRONT 和 Palette 更高效，并在真实 Tor 网络环境中验证了其实用性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "68M10",
        "C.2.0"
      ],
      "primary_category": "cs.CR",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11471v1",
      "published_date": "2024-12-16 06:12:56 UTC",
      "updated_date": "2024-12-16 06:12:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:35:12.557744"
    },
    {
      "arxiv_id": "2412.11463v1",
      "title": "FedCAR: Cross-client Adaptive Re-weighting for Generative Models in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Minjun Kim",
        "Minjee Kim",
        "Jinhoon Jeong"
      ],
      "abstract": "Generative models trained on multi-institutional datasets can provide an\nenriched understanding through diverse data distributions. However, training\nthe models on medical images is often challenging due to hospitals' reluctance\nto share data for privacy reasons. Federated learning(FL) has emerged as a\nprivacy-preserving solution for training distributed datasets across data\ncenters by aggregating model weights from multiple clients instead of sharing\nraw data. Previous research has explored the adaptation of FL to generative\nmodels, yet effective aggregation algorithms specifically tailored for\ngenerative models remain unexplored. We hereby propose a novel algorithm aimed\nat improving the performance of generative models within FL. Our approach\nadaptively re-weights the contribution of each client, resulting in\nwell-trained shared parameters. In each round, the server side measures the\ndistribution distance between fake images generated by clients instead of\ndirectly comparing the Fr\\'echet Inception Distance per client, thereby\nenhancing efficiency of the learning. Experimental results on three public\nchest X-ray datasets show superior performance in medical image generation,\noutperforming both centralized learning and conventional FL algorithms. Our\ncode is available at https://github.com/danny0628/FedCAR.",
      "tldr_zh": "该研究提出FedCAR，一种针对生成模型的联邦学习（Federated Learning）算法，通过跨客户端自适应重新加权（Cross-client Adaptive Re-weighting）来优化模型性能，解决医疗图像数据隐私问题。FedCAR在每个训练轮次中，由服务器测量客户端生成的假图像之间的分布距离，而不是直接比较Fréchet Inception Distance（FID），从而提高了学习效率。实验结果显示，在三个公共胸部X光数据集上，该方法在医疗图像生成方面优于集中式学习和传统FL算法，提供了一种高效的隐私保护训练框架。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11463v1",
      "published_date": "2024-12-16 05:43:14 UTC",
      "updated_date": "2024-12-16 05:43:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:35:23.586954"
    },
    {
      "arxiv_id": "2412.12221v1",
      "title": "Parallel Greedy Best-First Search with a Bound on the Number of Expansions Relative to Sequential Search",
      "title_zh": "翻译失败",
      "authors": [
        "Takumi Shimoda",
        "Alex Fukunaga"
      ],
      "abstract": "Parallelization of non-admissible search algorithms such as GBFS poses a\nchallenge because straightforward parallelization can result in search behavior\nwhich significantly deviates from sequential search. Previous work proposed\nPUHF, a parallel search algorithm which is constrained to only expand states\nthat can be expanded by some tie-breaking strategy for GBFS. We show that\ndespite this constraint, the number of states expanded by PUHF is not bounded\nby a constant multiple of the number of states expanded by sequential GBFS with\nthe worst-case tie-breaking strategy. We propose and experimentally evaluate\nOne Bench At a Time (OBAT), a parallel greedy search which guarantees that the\nnumber of states expanded is within a constant factor of the number of states\nexpanded by sequential GBFS with some tie-breaking policy.",
      "tldr_zh": "本研究探讨了Greedy Best-First Search (GBFS) 等非admissible搜索算法的并行化问题，指出直接并行化可能导致搜索行为显著偏离顺序搜索，而现有算法PUHF尽管约束了状态扩展，却无法保证扩展数量被顺序GBFS的常量倍数限制。作者提出了一种新算法One Bench At a Time (OBAT)，这是一种并行greedy搜索方法，能够确保扩展的状态数量在某个常量因子内与顺序GBFS的某些tie-breaking策略相当。通过实验评估，OBAT证明了其在保持搜索效率和一致性方面的优势。",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12221v1",
      "published_date": "2024-12-16 05:39:59 UTC",
      "updated_date": "2024-12-16 05:39:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:35:36.642052"
    },
    {
      "arxiv_id": "2412.11461v1",
      "title": "Unsupervised Anomaly Detection for Tabular Data Using Noise Evaluation",
      "title_zh": "基于噪声评估的无监督表格数据异常检测",
      "authors": [
        "Wei Dai",
        "Kai Hwang",
        "Jicong Fan"
      ],
      "abstract": "Unsupervised anomaly detection (UAD) plays an important role in modern data\nanalytics and it is crucial to provide simple yet effective and guaranteed UAD\nalgorithms for real applications. In this paper, we present a novel UAD method\nfor tabular data by evaluating how much noise is in the data. Specifically, we\npropose to learn a deep neural network from the clean (normal) training dataset\nand a noisy dataset, where the latter is generated by adding highly diverse\nnoises to the clean data. The neural network can learn a reliable decision\nboundary between normal data and anomalous data when the diversity of the\ngenerated noisy data is sufficiently high so that the hard abnormal samples lie\nin the noisy region. Importantly, we provide theoretical guarantees, proving\nthat the proposed method can detect anomalous data successfully, although the\nmethod does not utilize any real anomalous data in the training stage.\nExtensive experiments through more than 60 benchmark datasets demonstrate the\neffectiveness of the proposed method in comparison to 12 baselines of UAD. Our\nmethod obtains a 92.27\\% AUC score and a 1.68 ranking score on average.\nMoreover, compared to the state-of-the-art UAD methods, our method is easier to\nimplement.",
      "tldr_zh": "本文提出了一种基于噪声评估的Unsupervised Anomaly Detection (UAD)方法，用于表格数据异常检测。该方法通过训练深度神经网络来区分干净（正常）数据集和添加多样化噪声的数据，从而在高噪声多样性下建立可靠的决策边界，即使训练阶段不使用真实异常数据。理论分析证明了该方法的有效性，实验在超过60个基准数据集上与12个基线方法比较，取得了平均92.27%的AUC分数和1.68的排名分数，且比现有最先进方法更容易实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper was accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11461v1",
      "published_date": "2024-12-16 05:35:58 UTC",
      "updated_date": "2024-12-16 05:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:35:48.202100"
    },
    {
      "arxiv_id": "2412.11455v1",
      "title": "Towards Better Multi-task Learning: A Framework for Optimizing Dataset Combinations in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zaifu Zhan",
        "Rui Zhang"
      ],
      "abstract": "To efficiently select optimal dataset combinations for enhancing multi-task\nlearning (MTL) performance in large language models, we proposed a novel\nframework that leverages a neural network to predict the best dataset\ncombinations. The framework iteratively refines the selection, greatly\nimproving efficiency, while being model-, dataset-, and domain-independent.\nThrough experiments on 12 biomedical datasets across four tasks - named entity\nrecognition, relation extraction, event extraction, and text classification-we\ndemonstrate that our approach effectively identifies better combinations, even\nfor tasks that may seem unpromising from a human perspective. This verifies\nthat our framework provides a promising solution for maximizing MTL potential.",
      "tldr_zh": "本研究提出了一种新框架，用于优化大型语言模型（Large Language Models）中的多任务学习（MTL）性能，通过神经网络预测最佳数据集组合并进行迭代精炼，从而显著提高选择效率，且该框架独立于模型、数据集和领域。实验在12个生物医学数据集上进行，涵盖命名实体识别、关系抽取、事件抽取和文本分类任务，结果显示该方法能有效识别出更好的数据集组合，甚至包括人类看来不乐观的任务。总体而言，此框架为最大化MTL潜力提供了高效且通用的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.11455v1",
      "published_date": "2024-12-16 05:20:18 UTC",
      "updated_date": "2024-12-16 05:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:35:59.382969"
    },
    {
      "arxiv_id": "2412.11453v1",
      "title": "ACE-$M^3$: Automatic Capability Evaluator for Multimodal Medical Models",
      "title_zh": "ACE-$M^3$：用于多模态医疗模型的自动能力评估器",
      "authors": [
        "Xiechi Zhang",
        "Shunfan Zheng",
        "Linlin Wang",
        "Gerard de Melo",
        "Zhu Cao",
        "Xiaoling Wang",
        "Liang He"
      ],
      "abstract": "As multimodal large language models (MLLMs) gain prominence in the medical\nfield, the need for precise evaluation methods to assess their effectiveness\nhas become critical. While benchmarks provide a reliable means to evaluate the\ncapabilities of MLLMs, traditional metrics like ROUGE and BLEU employed for\nopen domain evaluation only focus on token overlap and may not align with human\njudgment. Although human evaluation is more reliable, it is labor-intensive,\ncostly, and not scalable. LLM-based evaluation methods have proven promising,\nbut to date, there is still an urgent need for open-source multimodal LLM-based\nevaluators in the medical field. To address this issue, we introduce ACE-$M^3$,\nan open-sourced \\textbf{A}utomatic \\textbf{C}apability \\textbf{E}valuator for\n\\textbf{M}ultimodal \\textbf{M}edical \\textbf{M}odels specifically designed to\nassess the question answering abilities of medical MLLMs. It first utilizes a\nbranch-merge architecture to provide both detailed analysis and a concise final\nscore based on standard medical evaluation criteria. Subsequently, a reward\ntoken-based direct preference optimization (RTDPO) strategy is incorporated to\nsave training time without compromising performance of our model. Extensive\nexperiments have demonstrated the effectiveness of our ACE-$M^3$\nmodel\\footnote{\\url{https://huggingface.co/collections/AIUSRTMP/ace-m3-67593297ff391b93e3e5d068}}\nin evaluating the capabilities of medical MLLMs.",
      "tldr_zh": "该研究指出，随着多模态大语言模型 (MLLMs) 在医疗领域的应用，传统评估指标如 ROUGE 和 BLEU 仅关注 token 重叠，无法与人类判断对齐，而人类评估又耗时且不易扩展，因此需要开源的 LLM-based 评估器。作者引入了 ACE-$M^3$，一个开源的自动能力评估器，专门用于评估医疗 MLLMs 的问答能力，通过 branch-merge architecture 提供详细分析和简洁最终分数，并采用 reward token-based direct preference optimization (RTDPO) 策略来节省训练时间。实验结果证明，ACE-$M^3$ 在评估医疗 MLLMs 能力方面表现出色，为高效的模型评估奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11453v1",
      "published_date": "2024-12-16 05:15:43 UTC",
      "updated_date": "2024-12-16 05:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:36:12.625646"
    },
    {
      "arxiv_id": "2412.11449v1",
      "title": "Whisper-GPT: A Hybrid Representation Audio Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Prateek Verma"
      ],
      "abstract": "We propose WHISPER-GPT: A generative large language model (LLM) for speech\nand music that allows us to work with continuous audio representations and\ndiscrete tokens simultaneously as part of a single architecture. There has been\na huge surge in generative audio, speech, and music models that utilize\ndiscrete audio tokens derived from neural compression algorithms, e.g. ENCODEC.\nHowever, one of the major drawbacks of this approach is handling the context\nlength. It blows up for high-fidelity generative architecture if one has to\naccount for all the audio contents at various frequencies for the next token\nprediction. By combining continuous audio representation like the spectrogram\nand discrete acoustic tokens, we retain the best of both worlds: Have all the\ninformation needed from the audio at a specific time instance in a single\ntoken, yet allow LLM to predict the future token to allow for sampling and\nother benefits discrete space provides. We show how our architecture improves\nthe perplexity and negative log-likelihood scores for the next token prediction\ncompared to a token-based LLM for speech and music.",
      "tldr_zh": "本研究提出Whisper-GPT，一种混合表示的音频大型语言模型（LLM），能够同时处理连续音频表示（如spectrogram）和离散acoustic tokens，实现语音和音乐的生成。相比传统基于离散音频标记（如ENCODEC）的模型，该架构解决了上下文长度膨胀问题，通过结合两种表示方式，确保在单个标记中保留音频关键信息，同时支持LLM的未来标记预测。实验结果显示，Whisper-GPT在语音和音乐的下一个标记预测上，显著降低了perplexity和negative log-likelihood分数。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "6 pages, 3 figures. 50th International Conference on Acoustics,\n  Speech and Signal Processing, Hyderabad, India",
      "pdf_url": "http://arxiv.org/pdf/2412.11449v1",
      "published_date": "2024-12-16 05:03:48 UTC",
      "updated_date": "2024-12-16 05:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:36:23.467580"
    },
    {
      "arxiv_id": "2412.11448v3",
      "title": "TRAIL: Trust-Aware Client Scheduling for Semi-Decentralized Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Gangqiang Hu",
        "Jianfeng Lu",
        "Jianmin Han",
        "Shuqin Cao",
        "Jing Liu",
        "Hao Fu"
      ],
      "abstract": "Due to the sensitivity of data, Federated Learning (FL) is employed to enable\ndistributed machine learning while safeguarding data privacy and accommodating\nthe requirements of various devices. However, in the context of\nsemi-decentralized FL, clients' communication and training states are dynamic.\nThis variability arises from local training fluctuations, heterogeneous data\ndistributions, and intermittent client participation. Most existing studies\nprimarily focus on stable client states, neglecting the dynamic challenges\ninherent in real-world scenarios. To tackle this issue, we propose a\nTRust-Aware clIent scheduLing mechanism called TRAIL, which assesses client\nstates and contributions, enhancing model training efficiency through selective\nclient participation. We focus on a semi-decentralized FL framework where edge\nservers and clients train a shared global model using unreliable intra-cluster\nmodel aggregation and inter-cluster model consensus. First, we propose an\nadaptive hidden semi-Markov model to estimate clients' communication states and\ncontributions. Next, we address a client-server association optimization\nproblem to minimize global training loss. Using convergence analysis, we\npropose a greedy client scheduling algorithm. Finally, our experiments\nconducted on real-world datasets demonstrate that TRAIL outperforms\nstate-of-the-art baselines, achieving an improvement of 8.7% in test accuracy\nand a reduction of 15.3% in training loss.",
      "tldr_zh": "该论文针对半去中心化 Federated Learning (FL) 中客户端通信和训练状态的动态变化问题，提出了一种基于信任评估的客户端调度机制 TRAIL，以提升模型训练效率。TRAIL 首先使用 adaptive hidden semi-Markov model 估计客户端的通信状态和贡献，然后通过解决 client-server association 优化问题并采用贪婪算法来最小化全局训练损失，同时在 unreliable intra-cluster model aggregation 和 inter-cluster model consensus 框架下实现模型聚合。实验结果显示，TRAIL 在真实数据集上比现有基线提高了 8.7% 的测试准确率，并减少了 15.3% 的训练损失，为处理动态 FL 场景提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11448v3",
      "published_date": "2024-12-16 05:02:50 UTC",
      "updated_date": "2024-12-19 12:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:36:36.907307"
    },
    {
      "arxiv_id": "2412.18619v2",
      "title": "Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Chen",
        "Zekun Wang",
        "Shuhuai Ren",
        "Lei Li",
        "Haozhe Zhao",
        "Yunshui Li",
        "Zefan Cai",
        "Hongcheng Guo",
        "Lei Zhang",
        "Yizhe Xiong",
        "Yichi Zhang",
        "Ruoyu Wu",
        "Qingxiu Dong",
        "Ge Zhang",
        "Jian Yang",
        "Lingwei Meng",
        "Shujie Hu",
        "Yulong Chen",
        "Junyang Lin",
        "Shuai Bai",
        "Andreas Vlachos",
        "Xu Tan",
        "Minjia Zhang",
        "Wen Xiao",
        "Aaron Yee",
        "Tianyu Liu",
        "Baobao Chang"
      ],
      "abstract": "Building on the foundations of language modeling in natural language\nprocessing, Next Token Prediction (NTP) has evolved into a versatile training\nobjective for machine learning tasks across various modalities, achieving\nconsiderable success. As Large Language Models (LLMs) have advanced to unify\nunderstanding and generation tasks within the textual modality, recent research\nhas shown that tasks from different modalities can also be effectively\nencapsulated within the NTP framework, transforming the multimodal information\ninto tokens and predict the next one given the context. This survey introduces\na comprehensive taxonomy that unifies both understanding and generation within\nmultimodal learning through the lens of NTP. The proposed taxonomy covers five\nkey aspects: Multimodal tokenization, MMNTP model architectures, unified task\nrepresentation, datasets \\& evaluation, and open challenges. This new taxonomy\naims to aid researchers in their exploration of multimodal intelligence. An\nassociated GitHub repository collecting the latest papers and repos is\navailable at https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction",
      "tldr_zh": "这篇论文对 Next Token Prediction (NTP) 在多模态智能领域的应用进行了全面调查，扩展了其从语言模型到多模态任务的训练目标。作者提出一个新的分类法（taxonomy），统一多模态学习中的理解和生成任务，通过 NTP 框架将多模态信息转化为 tokens 并预测下一个。分类法涵盖五个关键方面：Multimodal tokenization、MMNTP model architectures、unified task representation、datasets & evaluation，以及开放挑战，并提供了一个 GitHub 仓库（https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction）来收集相关资源，以支持研究者进一步探索。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "69 papes, 18 figures, repo at\n  https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction",
      "pdf_url": "http://arxiv.org/pdf/2412.18619v2",
      "published_date": "2024-12-16 05:02:25 UTC",
      "updated_date": "2024-12-30 03:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:36:49.102524"
    },
    {
      "arxiv_id": "2412.11446v1",
      "title": "Theoretical Analysis of Quality Diversity Algorithms for a Classical Path Planning Problem",
      "title_zh": "质量多样性算法在经典路径规划问题的理论分析",
      "authors": [
        "Duc-Cuong Dang",
        "Aneta Neumann",
        "Frank Neumann",
        "Andre Opris",
        "Dirk Sudholt"
      ],
      "abstract": "Quality diversity (QD) algorithms have shown to provide sets of high quality\nsolutions for challenging problems in robotics, games, and combinatorial\noptimisation. So far, theoretical foundational explaining their good behaviour\nin practice lack far behind their practical success. We contribute to the\ntheoretical understanding of these algorithms and study the behaviour of QD\nalgorithms for a classical planning problem seeking several solutions. We study\nthe all-pairs-shortest-paths (APSP) problem which gives a natural formulation\nof the behavioural space based on all pairs of nodes of the given input graph\nthat can be used by Map-Elites QD algorithms. Our results show that Map-Elites\nQD algorithms are able to compute a shortest path for each pair of nodes\nefficiently in parallel. Furthermore, we examine parent selection techniques\nfor crossover that exhibit significant speed ups compared to the standard QD\napproach.",
      "tldr_zh": "该论文对 Quality Diversity (QD) 算法进行了理论分析，聚焦于经典路径规划问题，特别是 all-pairs-shortest-paths (APSP) 问题，通过将行为空间定义为图中所有节点对。研究采用 Map-Elites QD 算法，展示了其在并行环境中高效计算每个节点对的最短路径的能力。结果表明，与标准 QD 方法相比，改进的父选择技术（parent selection techniques for crossover）显著提升了算法速度，为 QD 算法在机器人、游戏和组合优化领域的应用提供了理论基础。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11446v1",
      "published_date": "2024-12-16 04:58:32 UTC",
      "updated_date": "2024-12-16 04:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:36:59.655274"
    },
    {
      "arxiv_id": "2412.11443v1",
      "title": "Universal Domain Adaptive Object Detection via Dual Probabilistic Alignment",
      "title_zh": "通用领域自适应对象检测通过双重概率对齐",
      "authors": [
        "Yuanfan Zheng",
        "Jinlin Wu",
        "Wuyang Li",
        "Zhen Chen"
      ],
      "abstract": "Domain Adaptive Object Detection (DAOD) transfers knowledge from a labeled\nsource domain to an unannotated target domain under closed-set assumption.\nUniversal DAOD (UniDAOD) extends DAOD to handle open-set, partial-set, and\nclosed-set domain adaptation. In this paper, we first unveil two issues:\ndomain-private category alignment is crucial for global-level features, and the\ndomain probability heterogeneity of features across different levels. To\naddress these issues, we propose a novel Dual Probabilistic Alignment (DPA)\nframework to model domain probability as Gaussian distribution, enabling the\nheterogeneity domain distribution sampling and measurement. The DPA consists of\nthree tailored modules: the Global-level Domain Private Alignment (GDPA), the\nInstance-level Domain Shared Alignment (IDSA), and the Private Class Constraint\n(PCC). GDPA utilizes the global-level sampling to mine domain-private category\nsamples and calculate alignment weight through a cumulative distribution\nfunction to address the global-level private category alignment. IDSA utilizes\ninstance-level sampling to mine domain-shared category samples and calculates\nalignment weight through Gaussian distribution to conduct the domain-shared\ncategory domain alignment to address the feature heterogeneity. The PCC\naggregates domain-private category centroids between feature and probability\nspaces to mitigate negative transfer. Extensive experiments demonstrate that\nour DPA outperforms state-of-the-art UniDAOD and DAOD methods across various\ndatasets and scenarios, including open, partial, and closed sets. Codes are\navailable at \\url{https://github.com/zyfone/DPA}.",
      "tldr_zh": "这篇论文扩展了 Domain Adaptive Object Detection (DAOD) 到 Universal DAOD (UniDAOD)，以处理开放集、部分集和闭合集域适应场景，揭示了域私有类别对全局级特征的对齐重要性以及不同级别特征的域概率异质性问题。作者提出 Dual Probabilistic Alignment (DPA) 框架，将域概率建模为高斯分布，包括 Global-level Domain Private Alignment (GDPA) 用于挖掘私有类别样本、Instance-level Domain Shared Alignment (IDSA) 用于共享类别对齐，以及 Private Class Constraint (PCC) 用于减轻负转移。实验结果显示，DPA 在各种数据集和场景中优于现有最先进方法，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work is accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11443v1",
      "published_date": "2024-12-16 04:55:13 UTC",
      "updated_date": "2024-12-16 04:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:37:12.557895"
    },
    {
      "arxiv_id": "2412.11439v4",
      "title": "Bayesian Flow Is All You Need to Sample Out-of-Distribution Chemical Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Nianze Tao"
      ],
      "abstract": "Generating novel molecules with higher properties than the training space,\nnamely the out-of-distribution generation, is important for ${de~novo}$ drug\ndesign. However, it is not easy for distribution learning-based models, for\nexample diffusion models, to solve this challenge as these methods are designed\nto fit the distribution of training data as close as possible. In this paper,\nwe show that Bayesian flow network is capable of effortlessly generating high\nquality out-of-distribution samples that meet several scenarios. We introduce a\nsemi-autoregressive training/sampling method that helps to enhance the model\nperformance and surpass the state-of-the-art models.",
      "tldr_zh": "这篇论文提出，使用Bayesian flow network 可以轻松生成out-of-distribution化学空间中的高质量分子样本，从而支持新药设计。作者指出，传统分布学习模型如扩散模型难以实现这一目标，因为它们专注于拟合训练数据。论文引入了一种半自回归的训练和采样方法，提升了模型性能，并超越了现有最先进模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 10 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.11439v4",
      "published_date": "2024-12-16 04:43:54 UTC",
      "updated_date": "2025-02-15 01:29:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:37:23.094314"
    },
    {
      "arxiv_id": "2412.11434v3",
      "title": "Auto-bidding in real-time auctions via Oracle Imitation Learning (OIL)",
      "title_zh": "翻译失败",
      "authors": [
        "Alberto Silvio Chiappa",
        "Briti Gangopadhyay",
        "Zhao Wang",
        "Shingo Takamatsu"
      ],
      "abstract": "Online advertising has become one of the most successful business models of\nthe internet era. Impression opportunities are typically allocated through\nreal-time auctions, where advertisers bid to secure advertisement slots.\nDeciding the best bid for an impression opportunity is challenging, due to the\nstochastic nature of user behavior and the variability of advertisement traffic\nover time. In this work, we propose a framework for training auto-bidding\nagents in multi-slot second-price auctions to maximize acquisitions (e.g.,\nclicks, conversions) while adhering to budget and cost-per-acquisition (CPA)\nconstraints. We exploit the insight that, after an advertisement campaign\nconcludes, determining the optimal bids for each impression opportunity can be\nframed as a multiple-choice knapsack problem (MCKP) with a nonlinear objective.\nWe propose an \"oracle\" algorithm that identifies a near-optimal combination of\nimpression opportunities and advertisement slots, considering both past and\nfuture advertisement traffic data. This oracle solution serves as a training\ntarget for a student network which bids having access only to real-time\ninformation, a method we term Oracle Imitation Learning (OIL). Through\nnumerical experiments, we demonstrate that OIL achieves superior performance\ncompared to both online and offline reinforcement learning algorithms, offering\nimproved sample efficiency. Notably, OIL shifts the complexity of training\nauto-bidding agents from crafting sophisticated learning algorithms to solving\na nonlinear constrained optimization problem efficiently.",
      "tldr_zh": "本文提出了一种名为 Oracle Imitation Learning (OIL) 的框架，用于在线广告实时拍卖中的自动竞价，旨在最大化获取（如点击或转换）同时遵守预算和 cost-per-acquisition (CPA) 约束。框架将竞价问题建模为 multiple-choice knapsack problem (MCKP) 的非线性优化形式，利用 oracle 算法基于过去和未来广告流量数据生成近优解，作为学生网络的训练目标，该网络仅依赖实时信息进行决策。通过数值实验，OIL 比在线和离线 reinforcement learning 算法表现出色，具有更高的样本效率，并将训练复杂性简化为高效解决非线性约束优化问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11434v3",
      "published_date": "2024-12-16 04:21:35 UTC",
      "updated_date": "2025-05-16 21:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:37:37.169094"
    },
    {
      "arxiv_id": "2412.12220v1",
      "title": "Relieving Universal Label Noise for Unsupervised Visible-Infrared Person Re-Identification by Inferring from Neighbors",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Teng",
        "Long Lan",
        "Dingyao Chen",
        "Kele Xu",
        "Nan Yin"
      ],
      "abstract": "Unsupervised visible-infrared person re-identification (USL-VI-ReID) is of\ngreat research and practical significance yet remains challenging due to the\nabsence of annotations. Existing approaches aim to learn modality-invariant\nrepresentations in an unsupervised setting. However, these methods often\nencounter label noise within and across modalities due to suboptimal clustering\nresults and considerable modality discrepancies, which impedes effective\ntraining. To address these challenges, we propose a straightforward yet\neffective solution for USL-VI-ReID by mitigating universal label noise using\nneighbor information. Specifically, we introduce the Neighbor-guided Universal\nLabel Calibration (N-ULC) module, which replaces explicit hard pseudo labels in\nboth homogeneous and heterogeneous spaces with soft labels derived from\nneighboring samples to reduce label noise. Additionally, we present the\nNeighbor-guided Dynamic Weighting (N-DW) module to enhance training stability\nby minimizing the influence of unreliable samples. Extensive experiments on the\nRegDB and SYSU-MM01 datasets demonstrate that our method outperforms existing\nUSL-VI-ReID approaches, despite its simplicity. The source code is available\nat: https://github.com/tengxiao14/Neighbor-guided-USL-VI-ReID.",
      "tldr_zh": "该研究针对无监督可见-红外人重新识别（USL-VI-ReID）中的标签噪声问题，提出了一种基于邻居信息的简单有效解决方案，以缓解模态间差异和聚类错误带来的挑战。核心方法包括Neighbor-guided Universal Label Calibration (N-ULC)模块，使用邻居样本推断的软标签替换硬伪标签，从而减少标签噪声；以及Neighbor-guided Dynamic Weighting (N-DW)模块，通过动态加权最小化不可靠样本的影响，提升训练稳定性。在RegDB和SYSU-MM01数据集上的广泛实验表明，该方法优于现有USL-VI-ReID方法，尽管其设计相对简单。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12220v1",
      "published_date": "2024-12-16 04:04:41 UTC",
      "updated_date": "2024-12-16 04:04:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:37:48.666766"
    },
    {
      "arxiv_id": "2412.11427v2",
      "title": "Towards Scientific Discovery with Generative AI: Progress, Opportunities, and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Chandan K Reddy",
        "Parshin Shojaee"
      ],
      "abstract": "Scientific discovery is a complex cognitive process that has driven human\nknowledge and technological progress for centuries. While artificial\nintelligence (AI) has made significant advances in automating aspects of\nscientific reasoning, simulation, and experimentation, we still lack integrated\nAI systems capable of performing autonomous long-term scientific research and\ndiscovery. This paper examines the current state of AI for scientific\ndiscovery, highlighting recent progress in large language models and other AI\ntechniques applied to scientific tasks. We then outline key challenges and\npromising research directions toward developing more comprehensive AI systems\nfor scientific discovery, including the need for science-focused AI agents,\nimproved benchmarks and evaluation metrics, multimodal scientific\nrepresentations, and unified frameworks combining reasoning, theorem proving,\nand data-driven modeling. Addressing these challenges could lead to\ntransformative AI tools to accelerate progress across disciplines towards\nscientific discovery.",
      "tldr_zh": "这篇论文探讨了Generative AI在科学发现中的进展、机会和挑战，审视了AI在科学推理、模拟和实验中的应用进展，包括大型语言模型和其他技术。作者强调当前缺乏能够进行自主长期科学研究的集成AI系统，并提出关键研究方向，如开发science-focused AI agents、改进benchmarks和evaluation metrics、构建多模态科学表示，以及统一框架结合推理、theorem proving和数据驱动建模。解决这些挑战有望催生变革性AI工具，加速跨学科的科学发现和创新。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11427v2",
      "published_date": "2024-12-16 03:52:20 UTC",
      "updated_date": "2024-12-21 19:22:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:38:00.979658"
    },
    {
      "arxiv_id": "2412.11417v2",
      "title": "RL-LLM-DT: An Automatic Decision Tree Generation Method Based on RL Evaluation and LLM Enhancement",
      "title_zh": "RL-LLM-DT：基于 RL 评估和 LLM 增强的自动决策树生成方法",
      "authors": [
        "Junjie Lin",
        "Jian Zhao",
        "Lin Liu",
        "Yue Deng",
        "Youpeng Zhao",
        "Lanxiao Huang",
        "Xia Lin",
        "Wengang Zhou",
        "Houqiang Li"
      ],
      "abstract": "Traditionally, AI development for two-player zero-sum games has relied on two\nprimary techniques: decision trees and reinforcement learning (RL). A common\napproach involves using a fixed decision tree as one player's strategy while\ntraining an RL agent as the opponent to identify vulnerabilities in the\ndecision tree, thereby improving its strategic strength iteratively. However,\nthis process often requires significant human intervention to refine the\ndecision tree after identifying its weaknesses, resulting in inefficiencies and\nhindering full automation of the strategy enhancement process. Fortunately, the\nadvent of Large Language Models (LLMs) offers a transformative opportunity to\nautomate the process. We propose RL-LLM-DT, an automatic decision tree\ngeneration method based on RL Evaluation and LLM Enhancement. Given an initial\ndecision tree, the method involves two important iterative steps. Response\nPolicy Search: RL is used to discover counter-strategies targeting the decision\ntree. Policy Improvement: LLMs analyze failure scenarios and generate improved\ndecision tree code. In our method, RL focuses on finding the decision tree's\nflaws while LLM is prompted to generate an improved version of the decision\ntree. The iterative refinement process terminates when RL can't find any flaw\nof the tree or LLM fails to improve the tree. To evaluate the effectiveness of\nthis integrated approach, we conducted experiments in a curling game. After\niterative refinements, our curling AI based on the decision tree ranks first on\nthe Jidi platform among 34 curling AIs in total, which demonstrates that LLMs\ncan significantly enhance the robustness and adaptability of decision trees,\nrepresenting a substantial advancement in the field of Game AI. Our code is\navailable at https://github.com/Linjunjie99/RL-LLM-DT.",
      "tldr_zh": "该论文提出 RL-LLM-DT 方法，利用 Reinforcement Learning (RL) 评估和 Large Language Models (LLM) 增强来自动生成决策树，解决传统两玩家零和游戏中决策树改进依赖人类干预的效率问题。该方法通过迭代步骤进行优化：首先使用 RL 搜索决策树的漏洞，然后用 LLM 分析失败场景并生成改进的决策树代码，直至 RL 无法发现新缺陷或 LLM 无法进一步提升。实验在冰壶游戏上验证，优化后的 AI 在 Jidi 平台上位列 34 个参赛 AI 的第一名，显著提高了决策树的鲁棒性和适应性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T05",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "Length:10 pages. Figures:10 figures. Additional Notes:In this paper,\n  we have introduced a novel hybrid approach which leverages the strengths of\n  both RL and LLMs to itera- tively refine decision tree tactics, enhancing\n  their performance and adaptability",
      "pdf_url": "http://arxiv.org/pdf/2412.11417v2",
      "published_date": "2024-12-16 03:33:49 UTC",
      "updated_date": "2024-12-17 04:04:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:38:12.966000"
    },
    {
      "arxiv_id": "2412.11409v3",
      "title": "Multi-modal and Multi-scale Spatial Environment Understanding for Immersive Visual Text-to-Speech",
      "title_zh": "多模态和多尺度空间环境理解，用于沉浸式视觉文本到语音",
      "authors": [
        "Rui Liu",
        "Shuwei He",
        "Yifan Hu",
        "Haizhou Li"
      ],
      "abstract": "Visual Text-to-Speech (VTTS) aims to take the environmental image as the\nprompt to synthesize the reverberant speech for the spoken content. The\nchallenge of this task lies in understanding the spatial environment from the\nimage. Many attempts have been made to extract global spatial visual\ninformation from the RGB space of an spatial image. However, local and depth\nimage information are crucial for understanding the spatial environment, which\nprevious works have ignored. To address the issues, we propose a novel\nmulti-modal and multi-scale spatial environment understanding scheme to achieve\nimmersive VTTS, termed M2SE-VTTS. The multi-modal aims to take both the RGB and\nDepth spaces of the spatial image to learn more comprehensive spatial\ninformation, and the multi-scale seeks to model the local and global spatial\nknowledge simultaneously. Specifically, we first split the RGB and Depth images\ninto patches and adopt the Gemini-generated environment captions to guide the\nlocal spatial understanding. After that, the multi-modal and multi-scale\nfeatures are integrated by the local-aware global spatial understanding. In\nthis way, M2SE-VTTS effectively models the interactions between local and\nglobal spatial contexts in the multi-modal spatial environment. Objective and\nsubjective evaluations suggest that our model outperforms the advanced\nbaselines in environmental speech generation. The code and audio samples are\navailable at: https://github.com/AI-S2-Lab/M2SE-VTTS.",
      "tldr_zh": "该论文针对 Visual Text-to-Speech (VTTS) 任务，提出了一种多模态和多尺度空间环境理解方案，名为 M2SE-VTTS，以从环境图像中提取更全面的空间信息，从而合成更沉浸式的回声语音。方法包括利用 RGB 和 Depth 空间的多模态输入，同时建模局部和全局空间知识，通过将图像分割成 patches 并结合 Gemini 生成的环境描述来指导局部理解，并整合特征以实现局部与全局上下文的交互。实验结果显示，M2SE-VTTS 在客观和主观评估中优于现有基线模型，在环境语音生成方面表现出色，代码和音频样本已公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages,2 figures, Accepted by AAAI'2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11409v3",
      "published_date": "2024-12-16 03:25:23 UTC",
      "updated_date": "2025-01-15 01:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:38:24.492915"
    },
    {
      "arxiv_id": "2412.11408v2",
      "title": "Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Soltany",
        "Farhad Pourpanah",
        "Mahdiyar Molahasani",
        "Michael Greenspan",
        "Ali Etemad"
      ],
      "abstract": "In this paper, we propose a novel approach, Federated Domain Generalization\nwith Label Smoothing and Balanced Decentralized Training (FedSB), to address\nthe challenges of data heterogeneity within a federated learning framework.\nFedSB utilizes label smoothing at the client level to prevent overfitting to\ndomain-specific features, thereby enhancing generalization capabilities across\ndiverse domains when aggregating local models into a global model.\nAdditionally, FedSB incorporates a decentralized budgeting mechanism which\nbalances training among clients, which is shown to improve the performance of\nthe aggregated global model. Extensive experiments on four commonly used\nmulti-domain datasets, PACS, VLCS, OfficeHome, and TerraInc, demonstrate that\nFedSB outperforms competing methods, achieving state-of-the-art results on\nthree out of four datasets, indicating the effectiveness of FedSB in addressing\ndata heterogeneity.",
      "tldr_zh": "本论文提出了一种新方法FedSB（Federated Domain Generalization with Label Smoothing and Balanced Decentralized Training），旨在解决联邦学习框架中数据异质性带来的挑战。FedSB通过在客户端级别应用Label Smoothing来防止过拟合，从而提升模型在不同领域的泛化能力，并引入平衡Decentralized Training机制来优化客户端训练均衡性。实验在PACS、VLCS、OfficeHome和TerraInc四个多领域数据集上进行，结果显示FedSB优于竞争方法，在三个数据集上达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.11408v2",
      "published_date": "2024-12-16 03:25:19 UTC",
      "updated_date": "2025-02-08 15:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:38:36.261393"
    },
    {
      "arxiv_id": "2412.11404v1",
      "title": "Attention with Dependency Parsing Augmentation for Fine-Grained Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Ding",
        "Lvzhou Luo",
        "Yixuan Cao",
        "Ping Luo"
      ],
      "abstract": "To assist humans in efficiently validating RAG-generated content, developing\na fine-grained attribution mechanism that provides supporting evidence from\nretrieved documents for every answer span is essential. Existing fine-grained\nattribution methods rely on model-internal similarity metrics between responses\nand documents, such as saliency scores and hidden state similarity. However,\nthese approaches suffer from either high computational complexity or\ncoarse-grained representations. Additionally, a common problem shared by the\nprevious works is their reliance on decoder-only Transformers, limiting their\nability to incorporate contextual information after the target span. To address\nthe above problems, we propose two techniques applicable to all\nmodel-internals-based methods. First, we aggregate token-wise evidence through\nset union operations, preserving the granularity of representations. Second, we\nenhance the attributor by integrating dependency parsing to enrich the semantic\ncompleteness of target spans. For practical implementation, our approach\nemploys attention weights as the similarity metric. Experimental results\ndemonstrate that the proposed method consistently outperforms all prior works.",
      "tldr_zh": "该论文针对RAG生成内容的验证，提出了一种细粒度归因机制，用于为每个答案片段提供来自检索文档的支持证据，以帮助人类高效验证。作者引入两种技术：通过集合并操作聚合token-wise证据以保持表示粒度，以及整合dependency parsing增强目标片段的语义完整性，并以attention weights作为相似度指标。实验结果显示，该方法在性能上 consistently outperforms现有基于模型内部的方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 7 figures, submitted to ACL ARR 2024 October",
      "pdf_url": "http://arxiv.org/pdf/2412.11404v1",
      "published_date": "2024-12-16 03:12:13 UTC",
      "updated_date": "2024-12-16 03:12:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:38:47.428838"
    },
    {
      "arxiv_id": "2412.15256v1",
      "title": "Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search",
      "title_zh": "翻译失败",
      "authors": [
        "Edward Kim",
        "Manil Shrestha",
        "Richard Foty",
        "Tom DeLay",
        "Vicki Seyfert-Margolis"
      ],
      "abstract": "Creation and curation of knowledge graphs can accelerate disease discovery\nand analysis in real-world data. While disease ontologies aid in biological\ndata annotation, codified categories (SNOMED-CT, ICD10, CPT) may not capture\npatient condition nuances or rare diseases. Multiple disease definitions across\ndata sources complicate ontology mapping and disease clustering. We propose\ncreating patient knowledge graphs using large language model extraction\ntechniques, allowing data extraction via natural language rather than rigid\nontological hierarchies. Our method maps to existing ontologies (MeSH,\nSNOMED-CT, RxNORM, HPO) to ground extracted entities.\n  Using a large ambulatory care EHR database with 33.6M patients, we\ndemonstrate our method through the patient search for Dravet syndrome, which\nreceived ICD10 recognition in October 2020. We describe our construction of\npatient-specific knowledge graphs and symptom-based patient searches. Using\nconfirmed Dravet syndrome ICD10 codes as ground truth, we employ LLM-based\nentity extraction to characterize patients in grounded ontologies. We then\napply this method to identify Beta-propeller protein-associated\nneurodegeneration (BPAN) patients, demonstrating real-world discovery where no\nground truth exists.",
      "tldr_zh": "本研究提出了一种使用大型语言模型（LLMs）来结构化提取真实世界医疗知识的方法，旨在创建患者知识图谱（knowledge graphs）以加速疾病发现和分析。该方法通过LLMs的实体提取技术，实现自然语言数据提取，并将提取实体映射到现有本体（如MeSH、SNOMED-CT、RxNORM、HPO），从而解决传统本体（如ICD10、CPT）在捕捉患者细微差别或罕见疾病方面的局限性。在一个包含3360万患者的EHR数据库上，实验证明该方法能有效识别Dravet syndrome患者，并扩展到无ground truth的Beta-propeller protein-associated neurodegeneration (BPAN)患者发现，提供了一种更灵活的医疗数据总结和搜索框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 3 figures, Work published in 4th Workshop on Knowledge\n  Graphs and Big Data (In Conjunction with IEEE Big Data 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.15256v1",
      "published_date": "2024-12-16 02:57:00 UTC",
      "updated_date": "2024-12-16 02:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:39:00.984827"
    },
    {
      "arxiv_id": "2412.12219v1",
      "title": "Are Large Language Models Useful for Time Series Data Analysis?",
      "title_zh": "大型语言模型在时间序列数据分析中是否有用？",
      "authors": [
        "Francis Tang",
        "Ying Ding"
      ],
      "abstract": "Time series data plays a critical role across diverse domains such as\nhealthcare, energy, and finance, where tasks like classification, anomaly\ndetection, and forecasting are essential for informed decision-making.\nRecently, large language models (LLMs) have gained prominence for their ability\nto handle complex data and extract meaningful insights. This study investigates\nwhether LLMs are effective for time series data analysis by comparing their\nperformance with non-LLM-based approaches across three tasks: classification,\nanomaly detection, and forecasting.\n  Through a series of experiments using GPT4TS and autoregressive models, we\nevaluate their performance on benchmark datasets and assess their accuracy,\nprecision, and ability to generalize. Our findings indicate that while\nLLM-based methods excel in specific tasks like anomaly detection, their\nbenefits are less pronounced in others, such as forecasting, where simpler\nmodels sometimes perform comparably or better. This research highlights the\nrole of LLMs in time series analysis and lays the groundwork for future studies\nto systematically explore their applications and limitations in handling\ntemporal data.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在时间序列数据分析中的实用性，通过实验比较 LLMs 与非 LLMs 方法在分类、异常检测和预测任务上的表现。\n研究使用 GPT4TS 和自回归模型，在基准数据集上评估了准确性、精确性和泛化能力。\n结果表明，LLMs 在异常检测方面表现出色，但在预测任务中，简单模型有时表现相当或更好。\n该研究突出了 LLMs 在时间序列分析中的潜力，并为未来系统性探索其应用和局限性奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.12219v1",
      "published_date": "2024-12-16 02:47:44 UTC",
      "updated_date": "2024-12-16 02:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:39:12.354006"
    },
    {
      "arxiv_id": "2412.11387v1",
      "title": "How Can LLMs and Knowledge Graphs Contribute to Robot Safety? A Few-Shot Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulrahman Althobaiti",
        "Angel Ayala",
        "JingYing Gao",
        "Ali Almutairi",
        "Mohammad Deghat",
        "Imran Razzak",
        "Francisco Cruz"
      ],
      "abstract": "Large Language Models (LLMs) are transforming the robotics domain by enabling\nrobots to comprehend and execute natural language instructions. The cornerstone\nbenefits of LLM include processing textual data from technical manuals,\ninstructions, academic papers, and user queries based on the knowledge\nprovided. However, deploying LLM-generated code in robotic systems without\nsafety verification poses significant risks. This paper outlines a safety layer\nthat verifies the code generated by ChatGPT before executing it to control a\ndrone in a simulated environment. The safety layer consists of a fine-tuned\nGPT-4o model using Few-Shot learning, supported by knowledge graph prompting\n(KGP). Our approach improves the safety and compliance of robotic actions,\nensuring that they adhere to the regulations of drone operations.",
      "tldr_zh": "该论文探讨了大型语言模型 (LLMs) 和知识图谱 (Knowledge Graphs) 如何提升机器人安全，提出一种基于 Few-Shot Learning 的方法。研究设计了一个安全层，使用细调的 GPT-4o 模型结合 Knowledge Graph Prompting (KGP) 来验证 LLM 生成的代码，并在模拟环境中应用于无人机控制。该方法显著提高了机器人动作的安全性和合规性，确保遵守无人机操作规定。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11387v1",
      "published_date": "2024-12-16 02:28:34 UTC",
      "updated_date": "2024-12-16 02:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:41:17.286544"
    },
    {
      "arxiv_id": "2412.11385v1",
      "title": "Why Does ChatGPT \"Delve\" So Much? Exploring the Sources of Lexical Overrepresentation in Large Language Models",
      "title_zh": "为什么 ChatGPT 这么频繁地使用 \"Delve\"？ 探索大语言模型中词汇过度表示的来源",
      "authors": [
        "Tom S. Juzek",
        "Zina B. Ward"
      ],
      "abstract": "Scientific English is currently undergoing rapid change, with words like\n\"delve,\" \"intricate,\" and \"underscore\" appearing far more frequently than just\na few years ago. It is widely assumed that scientists' use of large language\nmodels (LLMs) is responsible for such trends. We develop a formal, transferable\nmethod to characterize these linguistic changes. Application of our method\nyields 21 focal words whose increased occurrence in scientific abstracts is\nlikely the result of LLM usage. We then pose \"the puzzle of lexical\noverrepresentation\": WHY are such words overused by LLMs? We fail to find\nevidence that lexical overrepresentation is caused by model architecture,\nalgorithm choices, or training data. To assess whether reinforcement learning\nfrom human feedback (RLHF) contributes to the overuse of focal words, we\nundertake comparative model testing and conduct an exploratory online study.\nWhile the model testing is consistent with RLHF playing a role, our\nexperimental results suggest that participants may be reacting differently to\n\"delve\" than to other focal words. With LLMs quickly becoming a driver of\nglobal language change, investigating these potential sources of lexical\noverrepresentation is important. We note that while insights into the workings\nof LLMs are within reach, a lack of transparency surrounding model development\nremains an obstacle to such research.",
      "tldr_zh": "本论文探讨大型语言模型(LLMs)中词汇过度使用（如“delve”、“intricate”和“underscore”）的现象，并开发了一个正式方法来识别这些变化，确认了21个焦点词汇可能源于LLMs的使用。研究者调查了潜在原因，包括模型架构、算法选择和训练数据，但未发现直接证据；随后通过比较模型测试和探索性在线实验，评估了强化学习从人类反馈(RLHF)的作用。结果显示RLHF可能部分导致词汇过度使用，但实验中参与者对“delve”等词汇的反应有所不同；论文强调，随着LLMs驱动全球语言变化，模型开发缺乏透明度已成为研究障碍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 8 figures, The 31st International Conference on\n  Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.11385v1",
      "published_date": "2024-12-16 02:27:59 UTC",
      "updated_date": "2024-12-16 02:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:43:21.559028"
    },
    {
      "arxiv_id": "2412.11381v1",
      "title": "Adapting Segment Anything Model (SAM) to Experimental Datasets via Fine-Tuning on GAN-based Simulation: A Case Study in Additive Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Anika Tabassum",
        "Amirkoushyar Ziabari"
      ],
      "abstract": "Industrial X-ray computed tomography (XCT) is a powerful tool for\nnon-destructive characterization of materials and manufactured components. XCT\ncommonly accompanied by advanced image analysis and computer vision algorithms\nto extract relevant information from the images. Traditional computer vision\nmodels often struggle due to noise, resolution variability, and complex\ninternal structures, particularly in scientific imaging applications.\nState-of-the-art foundational models, like the Segment Anything Model\n(SAM)-designed for general-purpose image segmentation-have revolutionized image\nsegmentation across various domains, yet their application in specialized\nfields like materials science remains under-explored. In this work, we explore\nthe application and limitations of SAM for industrial X-ray CT inspection of\nadditive manufacturing components. We demonstrate that while SAM shows promise,\nit struggles with out-of-distribution data, multiclass segmentation, and\ncomputational efficiency during fine-tuning. To address these issues, we\npropose a fine-tuning strategy utilizing parameter-efficient techniques,\nspecifically Conv-LoRa, to adapt SAM for material-specific datasets.\nAdditionally, we leverage generative adversarial network (GAN)-generated data\nto enhance the training process and improve the model's segmentation\nperformance on complex X-ray CT data. Our experimental results highlight the\nimportance of tailored segmentation models for accurate inspection, showing\nthat fine-tuning SAM on domain-specific scientific imaging data significantly\nimproves performance. However, despite improvements, the model's ability to\ngeneralize across diverse datasets remains limited, highlighting the need for\nfurther research into robust, scalable solutions for domain-specific\nsegmentation tasks.",
      "tldr_zh": "本研究探讨了如何将Segment Anything Model (SAM)适应于实验数据集，特别是增材制造领域的工业X-ray计算断层扫描 (XCT) 图像分割。作者发现，SAM在处理噪声、分辨率变化和复杂结构时存在挑战，包括分布外数据、多类分割和计算效率问题，因此提出了一种基于参数高效技术Conv-LoRa的微调策略，并利用生成对抗网络 (GAN) 生成的模拟数据来增强训练过程。实验结果显示，这种方法显著提高了SAM在特定领域数据集上的分割性能，但模型的泛化能力仍有限，强调了针对领域特定任务开发更鲁棒解决方案的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11381v1",
      "published_date": "2024-12-16 02:11:19 UTC",
      "updated_date": "2024-12-16 02:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:41:40.793580"
    },
    {
      "arxiv_id": "2412.11377v1",
      "title": "Improving Automatic Fetal Biometry Measurement with Swoosh Activation Function",
      "title_zh": "翻译失败",
      "authors": [
        "Shijia Zhou",
        "Euijoon Ahn",
        "Hao Wang",
        "Ann Quinton",
        "Narelle Kennedy",
        "Pradeeba Sridar",
        "Ralph Nanan",
        "Jinman Kim"
      ],
      "abstract": "The measurement of fetal thalamus diameter (FTD) and fetal head circumference\n(FHC) are crucial in identifying abnormal fetal thalamus development as it may\nlead to certain neuropsychiatric disorders in later life. However, manual\nmeasurements from 2D-US images are laborious, prone to high inter-observer\nvariability, and complicated by the high signal-to-noise ratio nature of the\nimages. Deep learning-based landmark detection approaches have shown promise in\nmeasuring biometrics from US images, but the current state-of-the-art (SOTA)\nalgorithm, BiometryNet, is inadequate for FTD and FHC measurement due to its\ninability to account for the fuzzy edges of these structures and the complex\nshape of the FTD structure. To address these inadequacies, we propose a novel\nSwoosh Activation Function (SAF) designed to enhance the regularization of\nheatmaps produced by landmark detection algorithms. Our SAF serves as a\nregularization term to enforce an optimum mean squared error (MSE) level\nbetween predicted heatmaps, reducing the dispersiveness of hotspots in\npredicted heatmaps. Our experimental results demonstrate that SAF significantly\nimproves the measurement performances of FTD and FHC with higher intraclass\ncorrelation coefficient scores in FTD and lower mean difference scores in FHC\nmeasurement than those of the current SOTA algorithm BiometryNet. Moreover, our\nproposed SAF is highly generalizable and architecture-agnostic. The SAF's\ncoefficients can be configured for different tasks, making it highly\ncustomizable. Our study demonstrates that the SAF activation function is a\nnovel method that can improve measurement accuracy in fetal biometry landmark\ndetection. This improvement has the potential to contribute to better fetal\nmonitoring and improved neonatal outcomes.",
      "tldr_zh": "本研究针对胎儿丘脑直径 (FTD) 和胎儿头围 (FHC) 的自动测量问题，指出现有深度学习方法如 BiometryNet 无法有效处理超声图像的模糊边缘和复杂形状，导致测量不准。作者提出了一种新型激活函数 Swoosh Activation Function (SAF)，通过作为正则化项优化预测热图的均方误差 (MSE)，减少热点分散，从而提升地标检测算法的性能。实验结果显示，SAF 显著提高了 FTD 和 FHC 的测量准确性，比当前最先进算法 BiometryNet 取得了更高的 intraclass correlation coefficient 分数和更低的 mean difference 分数。此外，SAF 具有高度通用性和可自定义性，有望改善胎儿监测并提升新生儿预后。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11377v1",
      "published_date": "2024-12-16 02:05:15 UTC",
      "updated_date": "2024-12-16 02:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:41:54.185923"
    },
    {
      "arxiv_id": "2412.11373v2",
      "title": "Codenames as a Benchmark for Large Language Models",
      "title_zh": "Codenames 作为大型语言模型的基准",
      "authors": [
        "Matthew Stephenson",
        "Matthew Sidji",
        "Benoît Ronval"
      ],
      "abstract": "In this paper, we propose the use of the popular word-based board game\nCodenames as a suitable benchmark for evaluating the reasoning capabilities of\nLarge Language Models (LLMs). Codenames presents a highly interesting challenge\nfor achieving successful AI performance, requiring both a sophisticated\nunderstanding of language, theory of mind, and epistemic reasoning\ncapabilities. Prior attempts to develop agents for Codenames have largely\nrelied on word embedding techniques, which have a limited vocabulary range and\nperform poorly when paired with differing approaches. LLMs have demonstrated\nenhanced reasoning and comprehension capabilities for language-based tasks, but\ncan still suffer in lateral thinking challenges. We evaluate the capabilities\nof several state-of-the-art LLMs, including GPT-4o, Gemini 1.5, Claude 3.5\nSonnet, and Llama 3.1, across a variety of board setups. Our results indicate\nthat while certain LLMs perform better than others overall, different models\nexhibit varying emergent behaviours during gameplay and excel at specific\nroles. We also evaluate the performance of different combinations of LLMs when\nplaying cooperatively together, demonstrating that LLM agents are more\ngeneralisable to a wider range of teammates than prior techniques.",
      "tldr_zh": "本研究提出将词语板游戏 Codenames 作为评估 Large Language Models (LLMs) 推理能力的基准，该游戏需要语言理解、theory of mind 和 epistemic reasoning 等高级能力。研究评估了 GPT-4o、Gemini 1.5、Claude 3.5 Sonnet 和 Llama 3.1 等模型在各种棋盘设置下的表现，结果显示不同模型表现出独特的紧急行为，并在特定角色中表现出色。进一步测试了 LLMs 之间的合作组合，发现这些代理比以往的词嵌入技术更具通用性，能更好地适应不同队友。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.11373v2",
      "published_date": "2024-12-16 01:59:03 UTC",
      "updated_date": "2025-04-21 22:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:42:04.786917"
    },
    {
      "arxiv_id": "2412.11364v1",
      "title": "Individual Bus Trip Chain Prediction and Pattern Identification Considering Similarities",
      "title_zh": "考虑相似性的个体公交出行链预测与模式识别",
      "authors": [
        "Xiannan Huang",
        "Yixin Chen",
        "Quan Yuan",
        "Chao Yang"
      ],
      "abstract": "Predicting future bus trip chains for an existing user is of great\nsignificance for operators of public transit systems. Existing methods always\ntreat this task as a time-series prediction problem, but the 1-dimensional time\nseries structure cannot express the complex relationship between trips. To\nbetter capture the inherent patterns in bus travel behavior, this paper\nproposes a novel approach that synthesizes future bus trip chains based on\nthose from similar days. Key similarity patterns are defined and tested using\nreal-world data, and a similarity function is then developed to capture these\npatterns. Afterwards, a graph is constructed where each day is represented as a\nnode and edge weight reflects the similarity between days. Besides, the trips\non a given day can be regarded as labels for each node, transferring the bus\ntrip chain prediction problem to a semi-supervised classification problem on a\ngraph. To address this, we propose several methods and validate them on a\nreal-world dataset of 10000 bus users, achieving state-of-the-art prediction\nresults. Analyzing the parameters of similarity function reveals some\ninteresting bus usage patterns, allowing us can to cluster bus users into three\ntypes: repeat-dominated, evolve-dominate and repeat-evolve balanced. In\nsummary, our work demonstrates the effectiveness of similarity-based prediction\nfor bus trip chains and provides a new perspective for analyzing individual bus\ntravel patterns. The code for our prediction model is publicly available.",
      "tldr_zh": "这篇论文提出了一种基于相似日子的方法来预测个人公交出行链（bus trip chains），通过定义关键相似性模式（key similarity patterns）和开发相似性函数（similarity function），将问题转化为图上的半监督分类问题（semi-supervised classification）。作者构建了一个图结构，其中每个节点代表一天，边权重反映日子间的相似性，并在包含10000名用户的真实数据集上验证多种方法，取得了state-of-the-art的预测结果。分析相似性函数参数后，揭示了公交使用模式，并将用户聚类为三种类型：repeat-dominated、evolve-dominate和repeat-evolve balanced，从而为分析个人公交出行模式提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11364v1",
      "published_date": "2024-12-16 01:32:26 UTC",
      "updated_date": "2024-12-16 01:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:42:19.627977"
    },
    {
      "arxiv_id": "2412.11360v1",
      "title": "Visual IRL for Human-Like Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Asali",
        "Prashant Doshi"
      ],
      "abstract": "We present a novel method for collaborative robots (cobots) to learn\nmanipulation tasks and perform them in a human-like manner. Our method falls\nunder the learn-from-observation (LfO) paradigm, where robots learn to perform\ntasks by observing human actions, which facilitates quicker integration into\nindustrial settings compared to programming from scratch. We introduce Visual\nIRL that uses the RGB-D keypoints in each frame of the observed human task\nperformance directly as state features, which are input to inverse\nreinforcement learning (IRL). The inversely learned reward function, which maps\nkeypoints to reward values, is transferred from the human to the cobot using a\nnovel neuro-symbolic dynamics model, which maps human kinematics to the cobot\narm. This model allows similar end-effector positioning while minimizing joint\nadjustments, aiming to preserve the natural dynamics of human motion in robotic\nmanipulation. In contrast with previous techniques that focus on end-effector\nplacement only, our method maps multiple joint angles of the human arm to the\ncorresponding cobot joints. Moreover, it uses an inverse kinematics model to\nthen minimally adjust the joint angles, for accurate end-effector positioning.\nWe evaluate the performance of this approach on two different realistic\nmanipulation tasks. The first task is produce processing, which involves\npicking, inspecting, and placing onions based on whether they are blemished.\nThe second task is liquid pouring, where the robot picks up bottles, pours the\ncontents into designated containers, and disposes of the empty bottles. Our\nresults demonstrate advances in human-like robotic manipulation, leading to\nmore human-robot compatibility in manufacturing applications.",
      "tldr_zh": "本研究提出了一种名为 Visual IRL 的新方法，用于让协作机器人（cobots）通过观察人类动作（Learn-from-Observation, LfO 范式）学习并执行操作任务，以实现更人性化的机器人操控。方法利用 RGB-D 关键点作为状态特征输入到 Inverse Reinforcement Learning (IRL)，并通过一个 neuro-symbolic dynamics model 将人类运动学映射到 cobot 手臂，同时采用 inverse kinematics model 最小化关节调整，以保留人类动作的自然动态。实验在两个实际任务上进行，包括处理洋葱（捡起、检查和放置）和倒液体（捡起瓶子、倾倒和处理空瓶），结果显示该方法显著提升了机器人操作的人类兼容性，在制造应用中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11360v1",
      "published_date": "2024-12-16 01:23:13 UTC",
      "updated_date": "2024-12-16 01:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:42:29.204928"
    },
    {
      "arxiv_id": "2412.11356v1",
      "title": "The Stabilizer Bootstrap of Quantum Machine Learning with up to 10000 qubits",
      "title_zh": "量子机器学习的稳定子",
      "authors": [
        "Yuqing Li",
        "Jinglei Cheng",
        "Xulong Tang",
        "Youtao Zhang",
        "Frederic T. Chong",
        "Junyu Liu"
      ],
      "abstract": "Quantum machine learning is considered one of the flagship applications of\nquantum computers, where variational quantum circuits could be the leading\nparadigm both in the near-term quantum devices and the early fault-tolerant\nquantum computers. However, it is not clear how to identify the regime of\nquantum advantages from these circuits, and there is no explicit theory to\nguide the practical design of variational ansatze to achieve better\nperformance. We address these challenges with the stabilizer bootstrap, a\nmethod that uses stabilizer-based techniques to optimize quantum neural\nnetworks before their quantum execution, together with theoretical proofs and\nhigh-performance computing with 10000 qubits or random datasets up to 1000\ndata. We find that, in a general setup of variational ansatze, the possibility\nof improvements from the stabilizer bootstrap depends on the structure of the\nobservables and the size of the datasets. The results reveal that\nconfigurations exhibit two distinct behaviors: some maintain a constant\nprobability of circuit improvement, while others show an exponential decay in\nimprovement probability as qubit numbers increase. These patterns are termed\nstrong stabilizer enhancement and weak stabilizer enhancement, respectively,\nwith most situations falling in between. Our work seamlessly bridges techniques\nfrom fault-tolerant quantum computing with applications of variational quantum\nalgorithms. Not only does it offer practical insights for designing variational\ncircuits tailored to large-scale machine learning challenges, but it also maps\nout a clear trajectory for defining the boundaries of feasible and practical\nquantum advantages.",
      "tldr_zh": "本研究提出了一种名为 stabilizer bootstrap 的方法，用于优化量子机器学习中的变分量子电路（variational quantum circuits），以解决识别量子优势（quantum advantages）和设计高效电路的挑战。该方法利用 stabilizer-based 技术在量子执行前对量子神经网络进行优化，并通过理论证明和高性能计算模拟支持高达 10000 qubits 或 1000 数据规模的场景。研究发现，改进的可能性取决于 observable 的结构和数据集大小，导致两种行为：强 stabilizer enhancement（概率恒定）和弱 stabilizer enhancement（概率指数衰减）。总之，该工作桥接了容错量子计算（fault-tolerant quantum computing）和变分量子算法的应用，提供实用指导来设计适用于大型机器学习挑战的量子电路，并明确了量子优势的边界。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "15 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.11356v1",
      "published_date": "2024-12-16 01:12:00 UTC",
      "updated_date": "2024-12-16 01:12:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:42:40.451860"
    },
    {
      "arxiv_id": "2412.11344v1",
      "title": "Can AI Extract Antecedent Factors of Human Trust in AI? An Application of Information Extraction for Scientific Literature in Behavioural and Computer Sciences",
      "title_zh": "翻译失败",
      "authors": [
        "Melanie McGrath",
        "Harrison Bailey",
        "Necva Bölücü",
        "Xiang Dai",
        "Sarvnaz Karimi",
        "Cecile Paris"
      ],
      "abstract": "Information extraction from the scientific literature is one of the main\ntechniques to transform unstructured knowledge hidden in the text into\nstructured data which can then be used for decision-making in down-stream\ntasks. One such area is Trust in AI, where factors contributing to human trust\nin artificial intelligence applications are studied. The relationships of these\nfactors with human trust in such applications are complex. We hence explore\nthis space from the lens of information extraction where, with the input of\ndomain experts, we carefully design annotation guidelines, create the first\nannotated English dataset in this domain, investigate an LLM-guided annotation,\nand benchmark it with state-of-the-art methods using large language models in\nnamed entity and relation extraction. Our results indicate that this problem\nrequires supervised learning which may not be currently feasible with\nprompt-based LLMs.",
      "tldr_zh": "这篇论文探讨了使用信息提取技术从行为科学和计算机科学文献中提取影响人类对 AI 信任的先决因素（Antecedent Factors of Human Trust in AI）。作者设计了注解指南、创建了首个英语数据集，并通过领域专家输入和 LLM-guided 注解方法，基准测试了命名实体和关系提取的最新大型语言模型。结果显示，该问题需要监督学习，而基于提示的 LLMs 当前可能无法有效实现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.11344v1",
      "published_date": "2024-12-16 00:02:38 UTC",
      "updated_date": "2024-12-16 00:02:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T13:42:52.571706"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 138,
  "processed_papers_count": 138,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T13:43:42.646642"
}