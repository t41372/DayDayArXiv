{
  "date": "2024-08-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-21 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、计算机视觉、强化学习和 LLM 应用等领域，强调模型的鲁棒性、解释性和实际应用；令人印象深刻的包括 LLM 在情感理解和安全方面的创新（如第五篇涉及 Bayesian Theory of Mind 的认知模型）和多模态框架（如第九十一条的 UniFashion），而知名学者如 Joshua B. Tenenbaum（第五篇）参与的论文突出理论深度。\n\n以下是今日论文的精选摘要，我优先讨论重要、创新或话题度高的文章，并将相关主题归类快速概述。其他较常规的论文（如纯理论或小众优化方法）将简要掠过。\n\n**AI 模型与 LLM 优化（重点领域）**  \n- **Great Memory, Shallow Reasoning: Limits of $k$NN-LMs（记忆强大，推理浅薄：kNN-LM 的局限性）**：这篇论文分析 kNN-LM 在序列推荐中的记忆优势和推理弱点，发现其在复杂任务中不如人类模型，主要贡献是通过实验证明 kNN-LM 依赖记忆而非深度推理，揭示了其在 NLP 任务中的潜在瓶颈。  \n- **Does It Look Sequential? An Analysis of Datasets for Evaluation of Sequential Recommendations（它看起来是顺序的吗？对顺序推荐数据集的分析）**：作者评估了 15 个顺序推荐数据集的结构强度，发现许多数据集的顺序依赖性较弱，主要发现是通过随机打乱序列来量化依赖性，为推荐系统评估提供更可靠的基准。  \n- **Memorization in In-Context Learning（In-Context Learning 中的记忆化）**：这篇讨论 LLM 在上下文学习中的记忆机制，作者 Shahriar Golchin 等发现 ICL 显著提升了记忆效果，但也可能导致过度依赖训练数据，主要贡献是揭示 ICL 与记忆之间的相关性，对模型泛化提出新见解。  \n- **Are KANs Effective for Multivariate Time Series Forecasting?（KANs 在多变量时间序列预测中有效吗？）**：论文探索 Kolmogorov-Arnold 网络在时间序列预测中的性能，通过 MMK 框架证明 KANs 在性能、效率和可解释性上优于传统模型，主要发现是其在实际预测中的鲁棒性。  \n- **SarcasmBench: Towards Evaluating Large Language Models on Sarcasm Understanding（SarcasmBench：评估大语言模型讽刺理解的基准）**：作者构建了讽刺理解基准，测试多个 LLM（如 GPT-4），发现讽刺检测需要更直观的提示方法，主要贡献是提出新指标，揭示 LLM 在处理复杂情感时的局限性。  \n- **Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models（分析和缓解大视觉语言模型中的谄媚行为）**：这篇关注 LVLMs 的偏见问题，提出 LQCD 方法通过对比解码减少对引导提示的过度依赖，主要发现是 LQCD 在保持模型准确性的同时显著降低谄媚风险。  \n- **EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models（EEG-Defender：通过大语言模型早期退出生成防御越狱攻击）**：论文提出 EEG-Defender 框架，通过早期层分析检测恶意输入并终止生成，主要贡献是有效降低攻击成功率，同时保持模型效率。  \n- **其他 LLM 相关（如第九十四篇等）**：这些论文探讨 LLM 的安全和优化，但贡献较常规，如通过提示微调提升性能，快速掠过。\n\n**计算机视觉与多模态应用（创新框架）**  \n- **Timeline and Boundary Guided Diffusion Network for Video Shadow Detection（时间线和边界引导的扩散网络用于视频阴影检测）**：作者设计 TBGDiff 网络，利用双尺度聚合和阴影边界注意力改进视频阴影检测，主要发现是首次将扩散模型应用于该任务，提升了检测精度。  \n- **UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation（UniFashion：用于多模态时尚检索和生成的统一视觉语言模型）**：这篇提出 UniFashion 框架，结合扩散模型和 LLM 处理时尚任务，主要贡献是统一嵌入和生成任务，实现高保真图像检索和生成，显著优于单任务模型。  \n- **其他视觉论文（如第二十七篇等）**：这些涉及图像生成和检测的常规方法，如使用扩散模型优化，效果中等，简要提及。\n\n**强化学习与决策（理论与实践）**  \n- **Understanding Epistemic Language with a Language-augmented Bayesian Theory of Mind（使用语言增强的 Bayesian Theory of Mind 理解认知语言）**：知名学者 Joshua B. Tenenbaum 参与，论文构建 LaBToM 模型，通过 Bayesian 推理和 LLM 解码评估认知语言，主要发现是模型在处理模态语言和不确定性时与人类判断高度相关。  \n- **Advances in Preference-based Reinforcement Learning: A Review（基于偏好的强化学习进展：综述）**：作者综述了偏好强化学习的发展，强调其在不确定环境中的优势，主要贡献是提出统一框架和未来方向。  \n- **其他 RL 论文（如第十篇等）**：这些探讨 RL 的能量景观和优化，但较理论化，快速掠过。\n\n**医疗与生物应用（实际影响）**  \n- **Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data（使用加拿大跨省初级医疗数据的联邦糖尿病预测）**：论文引入联邦学习预测糖尿病，处理数据隐私问题，主要发现是联邦 MLP 模型性能与集中式模型相当，但更适合隐私敏感场景。  \n- **ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding（ProteinGPT：用于蛋白质属性预测和结构理解的多模态 LLM）**：作者构建 ProteinGPT 模型，通过多任务学习预测蛋白质属性，主要贡献是使用 LLM 提升生物信息分析效率。  \n- **其他医疗论文（如第三十六篇等）**：这些涉及 LLM 在临床预测中的应用，贡献实用但不显著，简要概述。\n\n剩余论文（如纯优化方法或小众主题）由于主题较常规或影响力有限，这里不逐一详述，仅提及其核心如 \"Efficient Exploration and Discriminative World Model Learning\"（探索高效的世界模型学习），这些工作虽有技术贡献，但对主流读者吸引力不大。\n\n总之，今天的论文展示了 AI 领域的快速迭代，LLM 的安全和多模态应用尤为值得关注。更多细节可查阅 arXiv 原文！",
  "papers": [
    {
      "arxiv_id": "2408.12036v2",
      "title": "Reasoning and Tools for Human-Level Forecasting",
      "title_zh": "针对人类水平预测的推理与工具",
      "authors": [
        "Elvis Hsieh",
        "Preston Fu",
        "Jonathan Chen"
      ],
      "abstract": "Language models (LMs) trained on web-scale datasets are largely successful\ndue to their ability to memorize large amounts of training data, even if only\npresent in a few examples. These capabilities are often desirable in evaluation\non tasks such as question answering but raise questions about whether these\nmodels can exhibit genuine reasoning or succeed only at mimicking patterns from\nthe training data. This distinction is particularly salient in forecasting\ntasks, where the answer is not present in the training data, and the model must\nreason to make logical deductions. We present Reasoning and Tools for\nForecasting (RTF), a framework of reasoning-and-acting (ReAct) agents that can\ndynamically retrieve updated information and run numerical simulation with\nequipped tools. We evaluate our model with questions from competitive\nforecasting platforms and demonstrate that our method is competitive with and\ncan outperform human predictions. This suggests that LMs, with the right tools,\ncan indeed think and adapt like humans, offering valuable insights for\nreal-world decision-making.",
      "tldr_zh": "这篇论文探讨了语言模型（LMs）在预测任务中的真实推理能力，而非仅依赖训练数据记忆。论文提出 Reasoning and Tools for Forecasting (RTF) 框架，该框架基于 Reasoning-and-Acting (ReAct) 代理，允许模型动态检索更新信息并使用工具进行数值模拟。实验结果显示，RTF 在竞争性预测平台的任务上与人类预测相当或更优，证明配备适当工具的 LMs 可以像人类一样思考和适应，从而为现实决策提供宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12036v2",
      "published_date": "2024-08-21 23:42:06 UTC",
      "updated_date": "2024-10-31 23:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:20:34.096071"
    },
    {
      "arxiv_id": "2408.12032v1",
      "title": "A Constraint Programming Approach to Fair High School Course Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Mitsuka Kiyohara",
        "Masakazu Ishihata"
      ],
      "abstract": "Issues of inequity in U.S. high schools' course scheduling did not previously\nexist. However, in recent years, with the increase in student population and\ncourse variety, students perceive that the course scheduling method is unfair.\nCurrent integer programming (IP) methods to the high school scheduling problem\n(HSSP) fall short in addressing these fairness concerns. The purpose of this\nresearch is to develop a solution methodology that generates feasible and fair\ncourse schedules using student preferences. Utilizing principles of fairness,\nwhich have been well studied in market design, we define the fair high school\nscheduling problem (FHSSP), a novel extension to the HSSP, and devise a\ncorresponding algorithm based on integer programming to solve the FHSSP. We\ntest our approach on a real course request dataset from a high school in\nCalifornia, USA. Results show that our algorithm can generate schedules that\nare both feasible and fair. In this paper, we demonstrate that our IP algorithm\nnot only solves the HSSP and FHSSP in the United States but has the potential\nto be applied to various real-world scheduling problems. Additionally, we show\nthe feasibility of integrating human emotions into mathematical modeling.",
      "tldr_zh": "本研究针对美国高中课程安排（High School Scheduling Problem, HSSP）中的不公平问题，提出了一种基于整数规划（Integer Programming, IP）的公平高中课程安排问题（Fair High School Scheduling Problem, FHSSP）。该方法整合公平原则和学生偏好，开发出算法生成可行且公平的课程表，并在加利福尼亚一所高中的真实数据集上进行测试，结果显示算法有效。研究不仅证明了该算法适用于HSSP和FHSSP，还展示了其在其他调度问题中的潜力，以及将人类情感融入数学建模的可行性。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12032v1",
      "published_date": "2024-08-21 23:14:46 UTC",
      "updated_date": "2024-08-21 23:14:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:20:43.983104"
    },
    {
      "arxiv_id": "2408.12029v1",
      "title": "Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data",
      "title_zh": "翻译失败",
      "authors": [
        "Guojun Tang",
        "Jason E. Black",
        "Tyler S. Williamson",
        "Steve H. Drew"
      ],
      "abstract": "Integrating Electronic Health Records (EHR) and the application of machine\nlearning present opportunities for enhancing the accuracy and accessibility of\ndata-driven diabetes prediction. In particular, developing data-driven machine\nlearning models can provide early identification of patients with high risk for\ndiabetes, potentially leading to more effective therapeutic strategies and\nreduced healthcare costs. However, regulation restrictions create barriers to\ndeveloping centralized predictive models. This paper addresses the challenges\nby introducing a federated learning approach, which amalgamates predictive\nmodels without centralized data storage and processing, thus avoiding privacy\nissues. This marks the first application of federated learning to predict\ndiabetes using real clinical datasets in Canada extracted from the Canadian\nPrimary Care Sentinel Surveillance Network (CPCSSN) without crossprovince\npatient data sharing. We address class-imbalance issues through downsampling\ntechniques and compare federated learning performance against province-based\nand centralized models. Experimental results show that the federated MLP model\npresents a similar or higher performance compared to the model trained with the\ncentralized approach. However, the federated logistic regression model showed\ninferior performance compared to its centralized peer.",
      "tldr_zh": "该研究利用加拿大初级护理哨兵监测网络 (CPCSSN) 的真实临床数据，引入联邦学习 (federated learning) 方法来预测成年糖尿病风险，从而避免跨省患者数据共享并解决隐私问题。研究者通过下采样技术 (downsampling) 处理类别不平衡，并将联邦学习模型与基于省份的模型和集中式模型进行比较。实验结果显示，联邦学习的多层感知器 (MLP) 模型的性能与集中式模型相当或更高，而联邦学习的后勤回归 (logistic regression) 模型则表现较差。该方法为数据驱动的糖尿病早期识别提供了隐私保护的创新框架，有助于优化治疗策略并降低医疗成本。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.12029v1",
      "published_date": "2024-08-21 22:47:21 UTC",
      "updated_date": "2024-08-21 22:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:20:56.227592"
    },
    {
      "arxiv_id": "2408.12025v2",
      "title": "Exploring Large Language Models for Feature Selection: A Data-centric Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Li",
        "Zhen Tan",
        "Huan Liu"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly\ninfluenced various domains, leveraging their exceptional few-shot and zero-shot\nlearning capabilities. In this work, we aim to explore and understand the\nLLMs-based feature selection methods from a data-centric perspective. We begin\nby categorizing existing feature selection methods with LLMs into two groups:\ndata-driven feature selection which requires numerical values of samples to do\nstatistical inference and text-based feature selection which utilizes prior\nknowledge of LLMs to do semantical associations using descriptive context. We\nconduct experiments in both classification and regression tasks with LLMs in\nvarious sizes (e.g., GPT-4, ChatGPT and LLaMA-2). Our findings emphasize the\neffectiveness and robustness of text-based feature selection methods and\nshowcase their potentials using a real-world medical application. We also\ndiscuss the challenges and future opportunities in employing LLMs for feature\nselection, offering insights for further research and development in this\nemerging field.",
      "tldr_zh": "这篇论文从数据中心视角探讨大型语言模型 (LLMs) 在特征选择中的应用，分为数据驱动（依赖样本数值进行统计推断）和基于文本（利用 LLMs 的先验知识进行语义关联）两类方法。作者通过实验评估不同规模的 LLMs（如 GPT-4、ChatGPT 和 LLaMA-2）在分类和回归任务上的性能，发现基于文本的特征选择方法更有效且鲁棒，并在真实医疗应用中展示了其潜力。论文还讨论了采用 LLMs 进行特征选择的挑战和未来机会，为该领域的研究提供见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by SIGKDD Explorations (December 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.12025v2",
      "published_date": "2024-08-21 22:35:19 UTC",
      "updated_date": "2024-10-23 17:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:21:07.869806"
    },
    {
      "arxiv_id": "2408.12022v2",
      "title": "Understanding Epistemic Language with a Language-augmented Bayesian Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Lance Ying",
        "Tan Zhi-Xuan",
        "Lionel Wong",
        "Vikash Mansinghka",
        "Joshua B. Tenenbaum"
      ],
      "abstract": "How do people understand and evaluate claims about others' beliefs, even\nthough these beliefs cannot be directly observed? In this paper, we introduce a\ncognitive model of epistemic language interpretation, grounded in Bayesian\ninferences about other agents' goals, beliefs, and intentions: a\nlanguage-augmented Bayesian theory-of-mind (LaBToM). By translating natural\nlanguage into an epistemic ``language-of-thought'' with grammar-constrained LLM\ndecoding, then evaluating these translations against the inferences produced by\ninverting a generative model of rational action and perception, LaBToM captures\ngraded plausibility judgments of epistemic claims. We validate our model in an\nexperiment where participants watch an agent navigate a maze to find keys\nhidden in boxes needed to reach their goal, then rate sentences about the\nagent's beliefs. In contrast with multimodal LLMs (GPT-4o, Gemini Pro) and\nablated models, our model correlates highly with human judgments for a wide\nrange of expressions, including modal language, uncertainty expressions,\nknowledge claims, likelihood comparisons, and attributions of false belief.",
      "tldr_zh": "本论文提出了一种语言增强的贝叶斯心智理论（LaBToM），用于理解人们如何评估他人不可直接观察的信念，通过Bayesian推理整合语言解释和代理行为建模。模型将自然语言翻译成认识论的“language-of-thought”，并通过逆转一个生成模型（inverting a generative model of rational action and perception）来评估声明的graded plausibility。实验结果显示，LaBToM在参与者评估代理信念的场景中，与人类判断高度相关，尤其在modal language、不确定性expressions、knowledge claims等领域优于多模态LLMs如GPT-4o和Gemini Pro。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages; Published at the Transactions of the Association for\n  Computational Linguistics (TACL); Presented at NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.12022v2",
      "published_date": "2024-08-21 22:29:56 UTC",
      "updated_date": "2025-04-18 15:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:21:20.838633"
    },
    {
      "arxiv_id": "2408.12008v1",
      "title": "Does It Look Sequential? An Analysis of Datasets for Evaluation of Sequential Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Klenitskiy",
        "Anna Volodkevich",
        "Anton Pembek",
        "Alexey Vasilev"
      ],
      "abstract": "Sequential recommender systems are an important and demanded area of\nresearch. Such systems aim to use the order of interactions in a user's history\nto predict future interactions. The premise is that the order of interactions\nand sequential patterns play an essential role. Therefore, it is crucial to use\ndatasets that exhibit a sequential structure to evaluate sequential\nrecommenders properly.\n  We apply several methods based on the random shuffling of the user's sequence\nof interactions to assess the strength of sequential structure across 15\ndatasets, frequently used for sequential recommender systems evaluation in\nrecent research papers presented at top-tier conferences. As shuffling\nexplicitly breaks sequential dependencies inherent in datasets, we estimate the\nstrength of sequential patterns by comparing metrics for shuffled and original\nversions of the dataset. Our findings show that several popular datasets have a\nrather weak sequential structure.",
      "tldr_zh": "这篇论文分析了15个常用数据集在评估顺序推荐系统(sequential recommender systems)中的顺序结构强度，强调了交互顺序对预测未来用户行为的重要性。\n作者采用基于随机打乱用户交互序列的多种方法，比较打乱前后数据集的指标，以量化顺序模式的强度。\n研究发现，许多流行数据集的顺序结构较弱，这可能导致对顺序推荐系统的评估不准确，并为未来数据集选择和改进提供了重要启示。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12008v1",
      "published_date": "2024-08-21 21:40:07 UTC",
      "updated_date": "2024-08-21 21:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:21:30.813880"
    },
    {
      "arxiv_id": "2408.12007v1",
      "title": "QuaCK-TSF: Quantum-Classical Kernelized Time Series Forecasting",
      "title_zh": "QuaCK-TSF：量子-经典核化时间序列预测",
      "authors": [
        "Abdallah Aaraba",
        "Soumaya Cherkaoui",
        "Ola Ahmad",
        "Jean-Frédéric Laprade",
        "Olivier Nahman-Lévesque",
        "Alexis Vieloszynski",
        "Shengrui Wang"
      ],
      "abstract": "Forecasting in probabilistic time series is a complex endeavor that extends\nbeyond predicting future values to also quantifying the uncertainty inherent in\nthese predictions. Gaussian process regression stands out as a Bayesian machine\nlearning technique adept at addressing this multifaceted challenge. This paper\nintroduces a novel approach that blends the robustness of this Bayesian\ntechnique with the nuanced insights provided by the kernel perspective on\nquantum models, aimed at advancing quantum kernelized probabilistic\nforecasting. We incorporate a quantum feature map inspired by Ising\ninteractions and demonstrate its effectiveness in capturing the temporal\ndependencies critical for precise forecasting. The optimization of our model's\nhyperparameters circumvents the need for computationally intensive gradient\ndescent by employing gradient-free Bayesian optimization. Comparative\nbenchmarks against established classical kernel models are provided, affirming\nthat our quantum-enhanced approach achieves competitive performance.",
      "tldr_zh": "这篇论文引入了 QuaCK-TSF，一种结合量子和经典内核的概率时间序列预测方法，利用 Gaussian process regression 来量化预测的不确定性，并通过受 Ising interactions 启发的量子特征映射捕捉时间依赖性。模型优化采用 gradient-free Bayesian optimization，避免了计算密集型梯度下降的开销。与经典内核模型的基准比较显示，QuaCK-TSF 实现了竞争性性能，证明了量子增强方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 15 figures, to be published in IEEE Quantum Week 2024's\n  conference proceeding",
      "pdf_url": "http://arxiv.org/pdf/2408.12007v1",
      "published_date": "2024-08-21 21:39:31 UTC",
      "updated_date": "2024-08-21 21:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:21:44.229244"
    },
    {
      "arxiv_id": "2408.11987v1",
      "title": "SimBench: A Rule-Based Multi-Turn Interaction Benchmark for Evaluating an LLM's Ability to Generate Digital Twins",
      "title_zh": "翻译失败",
      "authors": [
        "Jingquan Wang",
        "Harry Zhang",
        "Huzaifa Mustafa Unjhawala",
        "Peter Negrut",
        "Shu Wang",
        "Khailanii Slaton",
        "Radu Serban",
        "Jin-Long Wu",
        "Dan Negrut"
      ],
      "abstract": "We introduce SimBench, a benchmark designed to evaluate the proficiency of\nstudent large language models (S-LLMs) in generating digital twins (DTs) that\ncan be used in simulators for virtual testing. Given a collection of S-LLMs,\nthis benchmark enables the ranking of the S-LLMs based on their ability to\nproduce high-quality DTs. We demonstrate this by comparing over 20 open- and\nclosed-source S-LLMs. Using multi-turn interactions, SimBench employs a\nrule-based judge LLM (J-LLM) that leverages both predefined rules and\nhuman-in-the-loop guidance to assign scores for the DTs generated by the S-LLM,\nthus providing a consistent and expert-inspired evaluation protocol. The J-LLM\nis specific to a simulator, and herein the proposed benchmarking approach is\ndemonstrated in conjunction with the Chrono multi-physics simulator. Chrono\nprovided the backdrop used to assess an S-LLM in relation to the latter's\nability to create digital twins for multibody dynamics, finite element\nanalysis, vehicle dynamics, robotic dynamics, and sensor simulations. The\nproposed benchmarking principle is broadly applicable and enables the\nassessment of an S-LLM's ability to generate digital twins for other simulation\npackages. All code and data are available at\nhttps://github.com/uwsbel/SimBench.",
      "tldr_zh": "本研究引入了SimBench，这是一个基于规则的多轮交互基准，用于评估学生大型语言模型(S-LLMs)生成Digital Twins (DTs)的能力，这些DTs可用于模拟器进行虚拟测试。SimBench采用规则-based判断LLM (J-LLM)，结合预定义规则和人类指导，通过多轮交互为S-LLMs生成的DTs分配分数，并在Chrono多物理模拟器上评估了多体动力学、有限元分析等领域的表现。实验比较了20多个开源和闭源S-LLMs，结果显示该基准可有效排名模型性能，并适用于其他模拟器，所有代码和数据已在GitHub开源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11987v1",
      "published_date": "2024-08-21 20:52:32 UTC",
      "updated_date": "2024-08-21 20:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:21:55.908439"
    },
    {
      "arxiv_id": "2408.11984v2",
      "title": "Chemical Reaction Neural Networks for Fitting Accelerating Rate Calorimetry Data",
      "title_zh": "翻译失败",
      "authors": [
        "Saakaar Bhatnagar",
        "Andrew Comerford",
        "Zelu Xu",
        "Davide Berti Polato",
        "Araz Banaeizadeh",
        "Alessandro Ferraris"
      ],
      "abstract": "As the demand for lithium-ion batteries rapidly increases there is a need to\ndesign these cells in a safe manner to mitigate thermal runaway. Thermal\nrunaway in batteries leads to an uncontrollable temperature rise and\npotentially fires, which is a major safety concern. Typically, when modelling\nthe chemical kinetics of thermal runaway calorimetry data ( e.g. Accelerating\nRate Calorimetry (ARC)) is needed to determine the temperature-driven\ndecomposition kinetics. Conventional methods of fitting Arrhenius Ordinary\nDifferential Equation (ODE) thermal runaway models to Accelerated Rate\nCalorimetry (ARC) data make several assumptions that reduce the fidelity and\ngeneralizability of the obtained model. In this paper, Chemical Reaction Neural\nNetworks (CRNNs) are trained to fit the kinetic parameters of N-equation\nArrhenius ODEs to ARC data obtained from a Molicel 21700 P45B. The models are\nfound to be better approximations of the experimental data. The flexibility of\nthe method is demonstrated by experimenting with two-equation and four-equation\nmodels. Thermal runaway simulations are conducted in 3D using the obtained\nkinetic parameters, showing the applicability of the obtained thermal runaway\nmodels to large-scale simulations.",
      "tldr_zh": "本研究针对锂离子电池热失控的安全设计问题，提出使用 Chemical Reaction Neural Networks (CRNNs) 来拟合 Accelerating Rate Calorimetry (ARC) 数据，从而克服传统 Arrhenius ODE 方法的假设限制，提高模型的保真度和泛化性。CRNNs 通过训练拟合 Molicel 21700 P45B 的 ARC 数据，展示了在两方程和四方程模型上的灵活性，并更好地逼近实验数据。最终，利用获得的动力学参数进行 3D 热失控模拟，证明了该方法在大规模应用中的有效性。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11984v2",
      "published_date": "2024-08-21 20:39:41 UTC",
      "updated_date": "2024-09-03 16:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:22:08.619790"
    },
    {
      "arxiv_id": "2408.11979v2",
      "title": "Only Strict Saddles in the Energy Landscape of Predictive Coding Networks?",
      "title_zh": "预测编码网络的能量景观中仅有严格鞍点？",
      "authors": [
        "Francesco Innocenti",
        "El Mehdi Achour",
        "Ryan Singh",
        "Christopher L. Buckley"
      ],
      "abstract": "Predictive coding (PC) is an energy-based learning algorithm that performs\niterative inference over network activities before updating weights. Recent\nwork suggests that PC can converge in fewer learning steps than backpropagation\nthanks to its inference procedure. However, these advantages are not always\nobserved, and the impact of PC inference on learning is not theoretically well\nunderstood. Here, we study the geometry of the PC energy landscape at the\ninference equilibrium of the network activities. For deep linear networks, we\nfirst show that the equilibrated energy is simply a rescaled mean squared error\nloss with a weight-dependent rescaling. We then prove that many highly\ndegenerate (non-strict) saddles of the loss including the origin become much\neasier to escape (strict) in the equilibrated energy. Our theory is validated\nby experiments on both linear and non-linear networks. Based on these and other\nresults, we conjecture that all the saddles of the equilibrated energy are\nstrict. Overall, this work suggests that PC inference makes the loss landscape\nmore benign and robust to vanishing gradients, while also highlighting the\nfundamental challenge of scaling PC to deeper models.",
      "tldr_zh": "该研究探讨了基于能量的学习算法 Predictive Coding (PC) 在网络活动推理平衡状态下的能量景观几何结构。作者证明，对于深度线性网络，平衡后的能量等价于一个权重相关的缩放均方误差损失(mean squared error loss)，使得许多退化(non-strict)鞍点转变为更容易逃逸的严格(strict)鞍点。实验在线性及非线性网络上验证了这一理论，并推测能量景观的所有鞍点均为严格的。总体而言，PC 的推理过程使损失景观更易优化、减少梯度消失问题，但扩展到更深模型仍面临挑战。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11979v2",
      "published_date": "2024-08-21 20:23:44 UTC",
      "updated_date": "2024-11-08 16:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:22:20.160948"
    },
    {
      "arxiv_id": "2408.11976v1",
      "title": "Sentiment and Emotion-aware Multi-criteria Fuzzy Group Decision Making System",
      "title_zh": "情感和情绪感知的多标准模糊群体决策系统",
      "authors": [
        "Adilet Yerkin",
        "Pakizar Shamoi",
        "Elnara Kadyrgali"
      ],
      "abstract": "In today's world, making decisions as a group is common, whether choosing a\nrestaurant or deciding on a holiday destination. Group decision-making (GDM)\nsystems play a crucial role by facilitating consensus among participants with\ndiverse preferences. Discussions are one of the main tools people use to make\ndecisions. When people discuss alternatives, they use natural language to\nexpress their opinions. Traditional GDM systems generally require participants\nto provide explicit opinion values to the system. However, in real-life\nscenarios, participants often express their opinions through some text (e.g.,\nin comments, social media, messengers, etc.). This paper introduces a sentiment\nand emotion-aware multi-criteria fuzzy GDM system designed to enhance\nconsensus-reaching effectiveness in group settings. This system incorporates\nnatural language processing to analyze sentiments and emotions expressed in\ntextual data, enabling an understanding of participant opinions besides the\nexplicit numerical preference inputs. Once all the experts have provided their\npreferences for the alternatives, the individual preferences are aggregated\ninto a single collective preference matrix. This matrix represents the\ncollective expert opinion regarding the other options. Then, sentiments,\nemotions, and preference scores are inputted into a fuzzy inference system to\nget the overall score. The proposed system was used for a small decision-making\nprocess - choosing the hotel for a vacation by a group of friends. Our findings\ndemonstrate that integrating sentiment and emotion analysis into GDM systems\nallows everyone's feelings and opinions to be considered during discussions and\nsignificantly improves consensus among participants.",
      "tldr_zh": "这篇论文提出了一种Sentiment and Emotion-aware Multi-criteria Fuzzy Group Decision Making System，用于提升群体决策（GDM）中的共识效果。该系统通过Natural Language Processing分析参与者在文本（如评论）中表达的sentiment和emotion，结合专家偏好聚合成集体偏好矩阵，并输入Fuzzy Inference System计算整体分数。与传统GDM系统不同，该方法能更好地处理真实场景下的隐性意见。实验结果显示，在一群朋友选择度假酒店的决策过程中，该系统显著提高了参与者间的共识。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to FSDM 2024 - The 10th International Conference on Fuzzy\n  Systems and Data Mining",
      "pdf_url": "http://arxiv.org/pdf/2408.11976v1",
      "published_date": "2024-08-21 20:17:06 UTC",
      "updated_date": "2024-08-21 20:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:22:32.385861"
    },
    {
      "arxiv_id": "2408.11963v2",
      "title": "Real-Time Incremental Explanations for Object Detectors in Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Santiago Calderón-Peña",
        "Hana Chockler",
        "David A. Kelly"
      ],
      "abstract": "Object detectors are widely used in safety-critical real-time applications\nsuch as autonomous driving. Explainability is especially important for\nsafety-critical applications, and due to the variety of object detectors and\ntheir often proprietary nature, black-box explainability tools are needed.\nHowever, existing black-box explainability tools for AI models rely on multiple\nmodel calls, rendering them impractical for real-time use.\n  In this paper, we introduce IncX, an algorithm and a tool for real-time\nblack-box explainability for object detectors. The algorithm is based on linear\ntransformations of saliency maps, producing sufficient explanations. We\nevaluate our implementation on four widely used video datasets of autonomous\ndriving and demonstrate that IncX's explanations are comparable in quality to\nthe state-of-the-art and are computed two orders of magnitude faster than the\nstate-of-the-art, making them usable in real time.",
      "tldr_zh": "这篇论文针对自动驾驶中的对象检测器(object detectors)，提出了一种实时黑盒解释工具IncX，以解决现有黑盒解释方法因多次模型调用而无法实时应用的难题。IncX算法基于显著性地图(saliency maps)的线性变换，生成高质量且高效的解释。在四个广泛使用的自动驾驶视频数据集上评估显示，IncX的解释质量与最先进方法相当，但计算速度快两个数量级，从而使其适用于安全关键的实时场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11963v2",
      "published_date": "2024-08-21 19:31:39 UTC",
      "updated_date": "2025-03-07 17:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:22:45.061773"
    },
    {
      "arxiv_id": "2408.11943v1",
      "title": "Advances in Preference-based Reinforcement Learning: A Review",
      "title_zh": "基于偏好的强化学习的进展：综述",
      "authors": [
        "Youssef Abdelkareem",
        "Shady Shehata",
        "Fakhri Karray"
      ],
      "abstract": "Reinforcement Learning (RL) algorithms suffer from the dependency on\naccurately engineered reward functions to properly guide the learning agents to\ndo the required tasks. Preference-based reinforcement learning (PbRL) addresses\nthat by utilizing human preferences as feedback from the experts instead of\nnumeric rewards. Due to its promising advantage over traditional RL, PbRL has\ngained more focus in recent years with many significant advances. In this\nsurvey, we present a unified PbRL framework to include the newly emerging\napproaches that improve the scalability and efficiency of PbRL. In addition, we\ngive a detailed overview of the theoretical guarantees and benchmarking work\ndone in the field, while presenting its recent applications in complex\nreal-world tasks. Lastly, we go over the limitations of the current approaches\nand the proposed future research directions.",
      "tldr_zh": "这篇论文综述了 Preference-based Reinforcement Learning (PbRL)，它通过使用人类偏好反馈取代传统 Reinforcement Learning (RL) 中的数字奖励函数，从而更好地指导代理学习。作者提出一个统一的 PbRL 框架，整合了新方法来提升其可伸缩性和效率，并详细概述了理论保证、基准测试工作以及在复杂真实世界任务中的应用。最终，论文指出了当前方法的局限性，并提出了未来的研究方向，如进一步优化反馈机制和扩展应用场景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11943v1",
      "published_date": "2024-08-21 18:57:12 UTC",
      "updated_date": "2024-08-21 18:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:22:58.023057"
    },
    {
      "arxiv_id": "2408.11939v2",
      "title": "Matmul or No Matmul in the Era of 1-bit LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jinendra Malekar",
        "Mohammed E. Elbtity",
        "Ramtin Zand"
      ],
      "abstract": "The advent of 1-bit large language models (LLMs) has attracted considerable\nattention and opened up new research opportunities. However, 1-bit LLMs only\nimprove a fraction of models by applying extreme quantization to the projection\nlayers while leaving attention heads unchanged. Therefore, to avoid\nfundamentally wrong choices of goals in future research, it is crucial to\nunderstand the actual improvements in computation and memory usage that 1-bit\nLLMs can deliver. In this work, we present an adaptation of Amdahl's Law\ntailored for the 1-bit LLM context, which illustrates how partial improvements\nin 1-bit LLMs impact overall model performance. Through extensive experiments,\nwe uncover key nuances across different model architectures and hardware\nconfigurations, offering a roadmap for future research in the era of 1-bit\nLLMs.",
      "tldr_zh": "本研究探讨了在1-bit LLMs时代是否需要矩阵乘法(Matmul)，强调当前1-bit LLMs仅对投影层进行极端量化，而忽略注意力头，导致计算和内存改进有限。论文提出一个针对1-bit LLMs的Amdahl's Law适应版本，分析部分改进对整体模型性能的影响，通过广泛实验揭示不同模型架构和硬件配置的关键差异。最终，该工作为未来1-bit LLMs研究提供路线图，帮助避免错误目标选择。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Fixed Typo in title, Fixed typo in author name, fixed typo in\n  amdhal's law para",
      "pdf_url": "http://arxiv.org/pdf/2408.11939v2",
      "published_date": "2024-08-21 18:44:21 UTC",
      "updated_date": "2024-08-28 19:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:23:08.268894"
    },
    {
      "arxiv_id": "2408.12629v2",
      "title": "Continual Gesture Learning without Data via Synthetic Feature Sampling",
      "title_zh": "无数据持续手势学习通过合成特征采样",
      "authors": [
        "Zhenyu Lu",
        "Hao Tang"
      ],
      "abstract": "Data-Free Class Incremental Learning (DFCIL) aims to enable models to\ncontinuously learn new classes while retraining knowledge of old classes, even\nwhen the training data for old classes is unavailable. Although explored\nprimarily with image datasets by researchers, this study focuses on\ninvestigating DFCIL for skeleton-based gesture classification due to its\nsignificant real-world implications, particularly considering the growing\nprevalence of VR/AR headsets where gestures serve as the primary means of\ncontrol and interaction. In this work, we made an intriguing observation:\nskeleton models trained with base classes(even very limited) demonstrate strong\ngeneralization capabilities to unseen classes without requiring additional\ntraining. Building on this insight, we developed Synthetic Feature Replay (SFR)\nthat can sample synthetic features from class prototypes to replay for old\nclasses and augment for new classes (under a few-shot setting). Our proposed\nmethod showcases significant advancements over the state-of-the-art, achieving\nup to 15% enhancements in mean accuracy across all steps and largely mitigating\nthe accuracy imbalance between base classes and new classes.",
      "tldr_zh": "这篇论文探讨了Data-Free Class Incremental Learning (DFCIL)在骨骼-based手势分类中的应用，旨在让模型在没有旧类训练数据的情况下持续学习新类，同时保留旧类知识，尤其针对VR/AR头盔中手势交互的实际需求。研究发现，基于基类训练的骨骼模型对未见类具有强泛化能力，因此提出Synthetic Feature Replay (SFR)方法，通过从类原型采样合成特征来重放旧类特征并增强新类（few-shot设置）。实验结果显示，SFR比现有方法提升了15%的平均准确率，并显著缓解了基类和新类之间的准确率不平衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.12629v2",
      "published_date": "2024-08-21 18:44:15 UTC",
      "updated_date": "2025-03-19 20:54:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:23:23.586004"
    },
    {
      "arxiv_id": "2408.11936v1",
      "title": "Estimating Contribution Quality in Online Deliberations Using a Large Language Model",
      "title_zh": "使用大型语言模型估计在线审议中的贡献质量",
      "authors": [
        "Lodewijk Gelauff",
        "Mohak Goyal",
        "Bhargav Dindukurthi",
        "Ashish Goel",
        "Alice Siu"
      ],
      "abstract": "Deliberation involves participants exchanging knowledge, arguments, and\nperspectives and has been shown to be effective at addressing polarization. The\nStanford Online Deliberation Platform facilitates large-scale deliberations. It\nenables video-based online discussions on a structured agenda for small groups\nwithout requiring human moderators. This paper's data comes from various\ndeliberation events, including one conducted in collaboration with Meta in 32\ncountries, and another with 38 post-secondary institutions in the US.\n  Estimating the quality of contributions in a conversation is crucial for\nassessing feature and intervention impacts. Traditionally, this is done by\nhuman annotators, which is time-consuming and costly. We use a large language\nmodel (LLM) alongside eight human annotators to rate contributions based on\njustification, novelty, expansion of the conversation, and potential for\nfurther expansion, with scores ranging from 1 to 5. Annotators also provide\nbrief justifications for their ratings. Using the average rating from other\nhuman annotators as the ground truth, we find the model outperforms individual\nhuman annotators. While pairs of human annotators outperform the model in\nrating justification and groups of three outperform it on all four metrics, the\nmodel remains competitive.\n  We illustrate the usefulness of the automated quality rating by assessing the\neffect of nudges on the quality of deliberation. We first observe that\nindividual nudges after prolonged inactivity are highly effective, increasing\nthe likelihood of the individual requesting to speak in the next 30 seconds by\n65%. Using our automated quality estimation, we show that the quality ratings\nfor statements prompted by nudging are similar to those made without nudging,\nsignifying that nudging leads to more ideas being generated in the conversation\nwithout losing overall quality.",
      "tldr_zh": "本文使用Large Language Model (LLM)来评估在线审议中贡献的质量，基于justification（理由）、novelty（新颖性）、expansion of the conversation（对话扩展）和potential for further expansion（进一步扩展潜力）四个指标，并与八位人类标注器进行比较。结果表明，LLM的表现优于单个人类标注器，但在某些指标上不如两人或三人组。研究还通过自动化质量评估显示，nudges（提示）能有效提高参与度（如增加65%的发言概率），且被nudges触发的陈述质量与自然发言相当，从而为大规模审议提供高效工具。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "I.2.1; J.5; H.5.3"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11936v1",
      "published_date": "2024-08-21 18:41:32 UTC",
      "updated_date": "2024-08-21 18:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:23:33.878803"
    },
    {
      "arxiv_id": "2408.11935v1",
      "title": "Explainable Anomaly Detection: Counterfactual driven What-If Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Cummins",
        "Alexander Sommers",
        "Sudip Mittal",
        "Shahram Rahimi",
        "Maria Seale",
        "Joseph Jaboure",
        "Thomas Arnold"
      ],
      "abstract": "There exists three main areas of study inside of the field of predictive\nmaintenance: anomaly detection, fault diagnosis, and remaining useful life\nprediction. Notably, anomaly detection alerts the stakeholder that an anomaly\nis occurring. This raises two fundamental questions: what is causing the fault\nand how can we fix it? Inside of the field of explainable artificial\nintelligence, counterfactual explanations can give that information in the form\nof what changes to make to put the data point into the opposing class, in this\ncase \"healthy\". The suggestions are not always actionable which may raise the\ninterest in asking \"what if we do this instead?\" In this work, we provide a\nproof of concept for utilizing counterfactual explanations as what-if analysis.\nWe perform this on the PRONOSTIA dataset with a temporal convolutional network\nas the anomaly detector. Our method presents the counterfactuals in the form of\na what-if analysis for this base problem to inspire future work for more\ncomplex systems and scenarios.",
      "tldr_zh": "本研究聚焦于预测性维护中的异常检测（anomaly detection），提出一种基于反事实解释（counterfactual explanations）的“what-if”分析方法，以回答异常原因和修复策略。作者利用反事实解释生成建议，帮助将异常数据点转变为“健康”状态，并通过“what-if”分析评估这些建议的可操作性。在PRONOSTIA数据集上，使用时序卷积网络（temporal convolutional network）作为异常检测器进行概念证明，为更复杂系统中的可解释性人工智能应用提供灵感。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.11935v1",
      "published_date": "2024-08-21 18:38:59 UTC",
      "updated_date": "2024-08-21 18:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:23:44.243246"
    },
    {
      "arxiv_id": "2408.11925v1",
      "title": "An Open Knowledge Graph-Based Approach for Mapping Concepts and Requirements between the EU AI Act and International Standards",
      "title_zh": "基于开放知识图谱的方法，用于",
      "authors": [
        "Julio Hernandez",
        "Delaram Golpayegani",
        "Dave Lewis"
      ],
      "abstract": "The many initiatives on trustworthy AI result in a confusing and multipolar\nlandscape that organizations operating within the fluid and complex\ninternational value chains must navigate in pursuing trustworthy AI. The EU's\nAI Act will now shift the focus of such organizations toward conformance with\nthe technical requirements for regulatory compliance, for which the Act relies\non Harmonized Standards. Though a high-level mapping to the Act's requirements\nwill be part of such harmonization, determining the degree to which standards\nconformity delivers regulatory compliance with the AI Act remains a complex\nchallenge. Variance and gaps in the definitions of concepts and how they are\nused in requirements between the Act and harmonized standards may impact the\nconsistency of compliance claims across organizations, sectors, and\napplications. This may present regulatory uncertainty, especially for SMEs and\npublic sector bodies relying on standards conformance rather than proprietary\nequivalents for developing and deploying compliant high-risk AI systems. To\naddress this challenge, this paper offers a simple and repeatable mechanism for\nmapping the terms and requirements relevant to normative statements in\nregulations and standards, e.g., AI Act and ISO management system standards,\ntexts into open knowledge graphs. This representation is used to assess the\nadequacy of standards conformance to regulatory compliance and thereby provide\na basis for identifying areas where further technical consensus development in\ntrustworthy AI value chains is required to achieve regulatory compliance.",
      "tldr_zh": "该研究针对欧盟AI法案（EU AI Act）和国际标准之间概念及要求的差异所带来的合规挑战，提出了一种基于开放知识图谱（open knowledge graphs）的映射方法。该方法通过将AI Act和标准（如ISO management system standards）中的术语及规范语句映射到知识图谱中，评估标准符合性是否满足监管合规要求，从而识别潜在差距。实验结果表明，此机制能减少组织间的合规不一致性，尤其有助于SMEs和公共部门在可信赖AI价值链中实现更可靠的共识发展。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "This work was presented at the 9th International Symposium on\n  Language & Knowledge Engineering (LKE 2024) Dublin, Ireland, 4 - 6 June, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11925v1",
      "published_date": "2024-08-21 18:21:09 UTC",
      "updated_date": "2024-08-21 18:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:23:55.792083"
    },
    {
      "arxiv_id": "2408.11918v1",
      "title": "Neural Symbolic Logical Rule Learner for Interpretable Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Wei",
        "Ziwei Zhu"
      ],
      "abstract": "Rule-based neural networks stand out for enabling interpretable\nclassification by learning logical rules for both prediction and\ninterpretation. However, existing models often lack flexibility due to the\nfixed model structure. Addressing this, we introduce the Normal Form Rule\nLearner (NFRL) algorithm, leveraging a selective discrete neural network, that\ntreat weight parameters as hard selectors, to learn rules in both Conjunctive\nNormal Form (CNF) and Disjunctive Normal Form (DNF) for enhanced accuracy and\ninterpretability. Instead of adopting a deep, complex structure, the NFRL\nincorporates two specialized Normal Form Layers (NFLs) with adaptable AND/OR\nneurons, a Negation Layer for input negations, and a Normal Form Constraint\n(NFC) to streamline neuron connections. We also show the novel network\narchitecture can be optimized using adaptive gradient update together with\nStraight-Through Estimator to overcome the gradient vanishing challenge.\nThrough extensive experiments on 11 datasets, NFRL demonstrates superior\nclassification performance, quality of learned rules, efficiency and\ninterpretability compared to 12 state-of-the-art alternatives. Code and data\nare available at \\url{https://anonymous.4open.science/r/NFRL-27B4/}.",
      "tldr_zh": "本研究提出了一种名为 Normal Form Rule Learner (NFRL) 的算法，用于构建可解释的规则-based 神经网络，以解决现有模型结构固定导致的灵活性不足问题。NFRL 利用 selective discrete neural network 将权重参数作为硬选择器，学习 Conjunctive Normal Form (CNF) 和 Disjunctive Normal Form (DNF) 规则，并整合 Normal Form Layers (NFLs)、Negation Layer 和 Normal Form Constraint (NFC) 等组件，同时采用 adaptive gradient update 和 Straight-Through Estimator 来优化网络并克服梯度消失挑战。在 11 个数据集上的实验表明，NFRL 在分类性能、学习规则质量、效率和可解释性方面优于 12 个 state-of-the-art 方法，为可解释学习提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 62 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11918v1",
      "published_date": "2024-08-21 18:09:12 UTC",
      "updated_date": "2024-08-21 18:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:24:09.293682"
    },
    {
      "arxiv_id": "2408.11910v1",
      "title": "Why am I Still Seeing This: Measuring the Effectiveness Of Ad Controls and Explanations in AI-Mediated Ad Targeting Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jane Castleman",
        "Aleksandra Korolova"
      ],
      "abstract": "Recently, Meta has shifted towards AI-mediated ad targeting mechanisms that\ndo not require advertisers to provide detailed targeting criteria, likely\ndriven by excitement over AI capabilities as well as new data privacy policies\nand targeting changes agreed upon in civil rights settlements. At the same\ntime, Meta has touted their ad preference controls as an effective mechanism\nfor users to control the ads they see. Furthermore, Meta markets their\ntargeting explanations as a transparency tool that allows users to understand\nwhy they saw certain ads and inform actions to control future ads.\n  Our study evaluates the effectiveness of Meta's \"See less\" ad control and the\nactionability of ad targeting explanations following the shift to AI-mediated\ntargeting. We conduct a large-scale study, randomly assigning participants to\nmark \"See less\" to Body Weight Control or Parenting topics, and collecting the\nads and targeting explanations Meta shows to participants before and after the\nintervention. We find that utilizing the \"See less\" ad control for the topics\nwe study does not significantly reduce the number of ads shown by Meta on these\ntopics, and that the control is less effective for some users whose\ndemographics are correlated with the topic. Furthermore, we find that the\nmajority of ad targeting explanations for local ads made no reference to\nlocation-specific targeting criteria, and did not inform users why ads related\nto the topics they marked to \"See less\" of continued to be delivered. We\nhypothesize that the poor effectiveness of controls and lack of actionability\nin explanations are the result of the shift to AI-mediated targeting, for which\nexplainability and transparency tools have not yet been developed. Our work\nthus provides evidence for the need of new methods for transparency and user\ncontrol, suitable and reflective of increasingly complex AI-mediated ad\ndelivery systems.",
      "tldr_zh": "本文评估了 Meta 的 AI-mediated ad targeting 系统中的 \"See less\" 广告控制和定位解释的有效性，通过大规模实验随机分配参与者标记特定主题（如 Body Weight Control 或 Parenting），并比较干预前后看到的广告。结果显示，\"See less\" 控制未能显著减少相关主题广告，尤其对与主题相关的用户群体效果更差；此外，大多数定位解释忽略了位置特定标准，无法解释为什么相关广告继续出现。研究推测这是 AI-mediated 定位的复杂性所致，并呼吁开发新的透明工具和用户控制方法，以适应日益复杂的广告系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to the 7th AAAI Conference on AI, Ethics, and Society (AIES,\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.11910v1",
      "published_date": "2024-08-21 18:03:11 UTC",
      "updated_date": "2024-08-21 18:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:24:21.051870"
    },
    {
      "arxiv_id": "2408.11816v3",
      "title": "Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony GX-Chen",
        "Kenneth Marino",
        "Rob Fergus"
      ],
      "abstract": "In the face of difficult exploration problems in reinforcement learning, we\nstudy whether giving an agent an object-centric mapping (describing a set of\nitems and their attributes) allow for more efficient learning. We found this\nproblem is best solved hierarchically by modelling items at a higher level of\nstate abstraction to pixels, and attribute change at a higher level of temporal\nabstraction to primitive actions. This abstraction simplifies the transition\ndynamic by making specific future states easier to predict. We make use of this\nto propose a fully model-based algorithm that learns a discriminative world\nmodel, plans to explore efficiently with only a count-based intrinsic reward,\nand can subsequently plan to reach any discovered (abstract) states.\n  We demonstrate the model's ability to (i) efficiently solve single tasks,\n(ii) transfer zero-shot and few-shot across item types and environments, and\n(iii) plan across long horizons. Across a suite of 2D crafting and MiniHack\nenvironments, we empirically show our model significantly out-performs\nstate-of-the-art low-level methods (without abstraction), as well as performant\nmodel-free and model-based methods using the same abstraction. Finally, we show\nhow to learn low level object-perturbing policies via reinforcement learning,\nand the object mapping itself by supervised learning.",
      "tldr_zh": "本研究探讨了在强化学习中，通过提供对象中心抽象（object-centric abstraction）来提升探索效率的方法。该方法采用分层建模，将物品建模为更高层次的状态抽象（相对于像素），并将属性变化建模为更高层次的时间抽象（相对于原始动作），从而简化过渡动态并易于预测未来状态。研究提出一个完全基于模型的算法，学习区分性世界模型（discriminative world model），并使用基于计数的内在奖励（intrinsic reward）进行高效探索和规划，以到达任何发现的抽象状态。实验结果显示，该模型在2D制作和MiniHack环境中显著优于无抽象的低级方法，以及使用相同抽象的模型无关和基于模型方法，并在任务解决、零样本/少样本转移（zero-shot and few-shot transfer）和长 horizons 规划方面表现出色。最终，该框架还展示了通过强化学习学习低级对象扰动策略，以及通过监督学习学习对象映射本身的可能性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.11816v3",
      "published_date": "2024-08-21 17:59:31 UTC",
      "updated_date": "2025-04-12 14:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:24:34.718062"
    },
    {
      "arxiv_id": "2408.11815v1",
      "title": "Great Memory, Shallow Reasoning: Limits of $k$NN-LMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shangyi Geng",
        "Wenting Zhao",
        "Alexander M Rush"
      ],
      "abstract": "$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval\nwith next-word prediction, have demonstrated strong performance in language\nmodeling as well as downstream NLP benchmarks. These results have led\nresearchers to argue that models trained on poor quality or outdated data could\nperform well by employing a $k$NN extension that has access to a higher-quality\ndatastore. In this work, we ask whether this improved ability to recall\ninformation really translates into downstream abilities. We extensively\nevaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment\nclassification and commonsense reasoning to multi-hop reasoning. Results show\nthat $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in\nthe input is sufficient for determining the output, but struggle with reasoning\ntasks that require integrating multiple pieces of information to derive new\nknowledge. We further demonstrate through oracle experiments and qualitative\nanalysis that even with perfect retrieval, $k$NN-LMs still fail to determine\nthe correct answers, placing an upper bound on their reasoning performance.\nCode and datastores are released at https://github.com/GSYfate/knnlm-limits/.",
      "tldr_zh": "这篇论文探讨了 $k$NN-LMs（k最近邻语言模型）的局限性，这些模型通过整合检索机制在语言建模和下游 NLP 任务中表现出色，但作者质疑其是否能真正提升下游性能。研究团队对 $k$NN-LMs 进行了广泛评估，包括情感分类、常识推理和多跳推理等任务，结果显示这些模型在记忆密集型任务上（如利用输入模式直接得出输出）表现优秀，但在需要整合多信息进行推理的任务上存在显著不足。通过预言实验和定性分析，作者证明即使检索机制完美无缺，$k$NN-LMs 仍无法准确推导出新知识，从而为它们的推理能力设定了上限。代码和数据存储已开源，详见相关仓库。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11815v1",
      "published_date": "2024-08-21 17:59:05 UTC",
      "updated_date": "2024-08-21 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:24:46.678644"
    },
    {
      "arxiv_id": "2408.11804v1",
      "title": "Approaching Deep Learning through the Spectral Dynamics of Weights",
      "title_zh": "翻译失败",
      "authors": [
        "David Yunis",
        "Kumar Kshitij Patel",
        "Samuel Wheeler",
        "Pedro Savarese",
        "Gal Vardi",
        "Karen Livescu",
        "Michael Maire",
        "Matthew R. Walter"
      ],
      "abstract": "We propose an empirical approach centered on the spectral dynamics of weights\n-- the behavior of singular values and vectors during optimization -- to unify\nand clarify several phenomena in deep learning. We identify a consistent bias\nin optimization across various experiments, from small-scale ``grokking'' to\nlarge-scale tasks like image classification with ConvNets, image generation\nwith UNets, speech recognition with LSTMs, and language modeling with\nTransformers. We also demonstrate that weight decay enhances this bias beyond\nits role as a norm regularizer, even in practical systems. Moreover, we show\nthat these spectral dynamics distinguish memorizing networks from generalizing\nones, offering a novel perspective on this longstanding conundrum.\nAdditionally, we leverage spectral dynamics to explore the emergence of\nwell-performing sparse subnetworks (lottery tickets) and the structure of the\nloss surface through linear mode connectivity. Our findings suggest that\nspectral dynamics provide a coherent framework to better understand the\nbehavior of neural networks across diverse settings.",
      "tldr_zh": "本研究提出一种基于权重谱动态（spectral dynamics of weights）的实证方法，通过分析奇异值和向量的行为，来统一和阐明深度学习中的多种现象，如优化过程中的一致偏差。实验覆盖从小型grokking到大规模任务，包括图像分类、生成、语音识别和语言建模，结果显示权重衰减（weight decay）不仅作为规范正则化，还能进一步增强这种偏差。论文进一步证明，谱动态能区分记忆网络与泛化网络，并用于探索lottery tickets的出现和损失表面的结构，最终提供了一个连贯框架，深化了对神经网络行为的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11804v1",
      "published_date": "2024-08-21 17:48:01 UTC",
      "updated_date": "2024-08-21 17:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:24:58.810146"
    },
    {
      "arxiv_id": "2408.11796v4",
      "title": "LLM Pruning and Distillation in Practice: The Minitron Approach",
      "title_zh": "LLM 修剪与蒸馏在实践中的应用：Minitron 方法",
      "authors": [
        "Sharath Turuvekere Sreenivas",
        "Saurav Muralidharan",
        "Raviraj Joshi",
        "Marcin Chochowski",
        "Ameya Sunil Mahabaleshwarkar",
        "Gerald Shen",
        "Jiaqi Zeng",
        "Zijia Chen",
        "Yoshi Suhara",
        "Shizhe Diao",
        "Chenhan Yu",
        "Wei-Chun Chen",
        "Hayley Ross",
        "Oluwatobi Olabiyi",
        "Ashwath Aithal",
        "Oleksii Kuchaiev",
        "Daniel Korzekwa",
        "Pavlo Molchanov",
        "Mostofa Patwary",
        "Mohammad Shoeybi",
        "Jan Kautz",
        "Bryan Catanzaro"
      ],
      "abstract": "We present a comprehensive report on compressing the Llama 3.1 8B and Mistral\nNeMo 12B models to 4B and 8B parameters, respectively, using pruning and\ndistillation. We explore two distinct pruning strategies: (1) depth pruning and\n(2) joint hidden/attention/MLP (width) pruning, and evaluate the results on\ncommon benchmarks from the LM Evaluation Harness. The models are then aligned\nwith NeMo Aligner and tested in instruct-tuned versions. This approach produces\na compelling 4B model from Llama 3.1 8B and a state-of-the-art\nMistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo\n12B. We found that with no access to the original data, it is beneficial to\nslightly fine-tune teacher models on the distillation dataset. We open-source\nour base model weights on Hugging Face with a permissive license.",
      "tldr_zh": "这篇论文介绍了 Minitron 方法，用于实际压缩大型语言模型（LLM），如将 Llama 3.1 8B 压缩到 4B 参数，以及 Mistral NeMo 12B 压缩到 8B 参数，通过 pruning（修剪）和 distillation（知识蒸馏）技术。研究者探索了两种 pruning 策略：depth pruning 和 joint hidden/attention/MLP (width) pruning，并在 LM Evaluation Harness 基准上评估模型，随后使用 NeMo Aligner 进行对齐和指令调整。结果显示，压缩后的模型表现出色，特别是 Mistral-NeMo-Minitron-8B 达到了 state-of-the-art 水平，且在没有原始数据的情况下，对教师模型进行轻微 fine-tune 有助于提升性能；作者还开放源码了这些基础模型权重在 Hugging Face 上。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "v4: Update author order",
      "pdf_url": "http://arxiv.org/pdf/2408.11796v4",
      "published_date": "2024-08-21 17:38:48 UTC",
      "updated_date": "2024-12-09 18:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:25:12.594968"
    },
    {
      "arxiv_id": "2408.11793v2",
      "title": "Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel H. Park",
        "Tiffany J. Callahan",
        "James L. Hedrick",
        "Tim Erdmann",
        "Sara Capponi"
      ],
      "abstract": "Molecular property prediction and generative design via deep learning models\nhas been the subject of intense research given its potential to accelerate\ndevelopment of new, high-performance materials. More recently, these workflows\nhave been significantly augmented with the advent of large language models\n(LLMs) and systems of autonomous agents capable of utilizing pre-trained models\nto make predictions in the context of more complex research tasks. While\neffective, there is still room for substantial improvement within agentic\nsystems on the retrieval of salient information for material design tasks.\nWithin this context, alternative uses of predictive deep learning models, such\nas leveraging their latent representations to facilitate cross-modal retrieval\naugmented generation within agentic systems for task-specific materials design,\nhas remained unexplored. Herein, we demonstrate that large, pre-trained\nchemistry foundation models can serve as a basis for enabling\nstructure-focused, semantic chemistry information retrieval for both\nsmall-molecules, complex polymeric materials, and reactions. Additionally, we\nshow the use of chemistry foundation models in conjunction with multi-modal\nmodels such as OpenCLIP facilitate unprecedented queries and information\nretrieval across multiple characterization data domains. Finally, we\ndemonstrate the integration of these models within multi-agent systems to\nfacilitate structure and topological-based natural language queries and\ninformation retrieval for different research tasks.",
      "tldr_zh": "本论文探讨了利用Chemistry Foundation Models来提升结构聚焦的Retrieval Augmented Generation (RAG)在多智能体工作流中的应用，以加速催化剂和材料设计。研究展示了这些预训练模型的潜在表示如何促进跨模态语义信息检索，适用于小分子、复杂聚合物和化学反应。通过结合多模态模型如OpenCLIP，论文实现了跨多个表征数据领域的查询和信息检索。最后，该方法在多智能体系统中整合后，支持结构和拓扑基础的自然语言查询，显著改善了材料设计任务的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11793v2",
      "published_date": "2024-08-21 17:25:45 UTC",
      "updated_date": "2024-12-13 01:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:25:23.808980"
    },
    {
      "arxiv_id": "2408.11788v1",
      "title": "DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Zhifei Xie",
        "Daniel Tang",
        "Dingwei Tan",
        "Jacques Klein",
        "Tegawend F. Bissyand",
        "Saad Ezzini"
      ],
      "abstract": "Current video generation models excel at creating short, realistic clips, but\nstruggle with longer, multi-scene videos. We introduce \\texttt{DreamFactory},\nan LLM-based framework that tackles this challenge. \\texttt{DreamFactory}\nleverages multi-agent collaboration principles and a Key Frames Iteration\nDesign Method to ensure consistency and style across long videos. It utilizes\nChain of Thought (COT) to address uncertainties inherent in large language\nmodels. \\texttt{DreamFactory} generates long, stylistically coherent, and\ncomplex videos. Evaluating these long-form videos presents a challenge. We\npropose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene\nStyle Consistency Score. To further research in this area, we contribute the\nMulti-Scene Videos Dataset containing over 150 human-rated videos.",
      "tldr_zh": "该研究引入DreamFactory，一个基于LLM的框架，利用多智能体协作原则和Key Frames Iteration Design Method，生成风格一致的多场景长视频，同时通过Chain of Thought (COT)处理LLM的不确定性。相比现有模型，DreamFactory能创建更复杂且连贯的视频。论文提出新评估指标，如Cross-Scene Face Distance Score和Cross-Scene Style Consistency Score，并贡献Multi-Scene Videos Dataset，包含超过150个由人类评级的视频，以推动该领域的研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.SE",
        "TsingHua University"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11788v1",
      "published_date": "2024-08-21 17:21:13 UTC",
      "updated_date": "2024-08-21 17:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:25:33.146958"
    },
    {
      "arxiv_id": "2408.11785v1",
      "title": "Timeline and Boundary Guided Diffusion Network for Video Shadow Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Haipeng Zhou",
        "Honqiu Wang",
        "Tian Ye",
        "Zhaohu Xing",
        "Jun Ma",
        "Ping Li",
        "Qiong Wang",
        "Lei Zhu"
      ],
      "abstract": "Video Shadow Detection (VSD) aims to detect the shadow masks with frame\nsequence. Existing works suffer from inefficient temporal learning. Moreover,\nfew works address the VSD problem by considering the characteristic (i.e.,\nboundary) of shadow. Motivated by this, we propose a Timeline and Boundary\nGuided Diffusion (TBGDiff) network for VSD where we take account of the\npast-future temporal guidance and boundary information jointly. In detail, we\ndesign a Dual Scale Aggregation (DSA) module for better temporal understanding\nby rethinking the affinity of the long-term and short-term frames for the\nclipped video. Next, we introduce Shadow Boundary Aware Attention (SBAA) to\nutilize the edge contexts for capturing the characteristics of shadows.\nMoreover, we are the first to introduce the Diffusion model for VSD in which we\nexplore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance\nfor Diffusion to conduct shadow detection. Benefiting from these designs, our\nmodel can not only capture the temporal information but also the shadow\nproperty. Extensive experiments show that the performance of our approach\novertakes the state-of-the-art methods, verifying the effectiveness of our\ncomponents. We release the codes, weights, and results at\n\\url{https://github.com/haipengzhou856/TBGDiff}.",
      "tldr_zh": "该论文针对视频阴影检测（Video Shadow Detection, VSD）问题，提出了一种Timeline and Boundary Guided Diffusion (TBGDiff) 网络，该方法通过整合过去-未来的时间指导和阴影边界信息来提升检测性能。论文设计了Dual Scale Aggregation (DSA) 模块，用于优化视频片段中长短期帧的亲和性以改善时间理解；同时引入Shadow Boundary Aware Attention (SBAA) 模块，利用边缘上下文捕捉阴影特性；并首次将Diffusion模型应用于VSD，通过Space-Time Encoded Embedding (STEE) 注入时间指导。实验结果显示，该方法在多项指标上超过了现有最先进方法，验证了其组件的有效性，并已在GitHub开源相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ACM MM2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11785v1",
      "published_date": "2024-08-21 17:16:21 UTC",
      "updated_date": "2024-08-21 17:16:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:25:45.616816"
    },
    {
      "arxiv_id": "2408.11778v2",
      "title": "Sum of Squares Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Loconte",
        "Stefan Mengel",
        "Antonio Vergari"
      ],
      "abstract": "Designing expressive generative models that support exact and efficient\ninference is a core question in probabilistic ML. Probabilistic circuits (PCs)\noffer a framework where this tractability-vs-expressiveness trade-off can be\nanalyzed theoretically. Recently, squared PCs encoding subtractive mixtures via\nnegative parameters have emerged as tractable models that can be exponentially\nmore expressive than monotonic PCs, i.e., PCs with positive parameters only. In\nthis paper, we provide a more precise theoretical characterization of the\nexpressiveness relationships among these models. First, we prove that squared\nPCs can be less expressive than monotonic ones. Second, we formalize a novel\nclass of PCs -- sum of squares PCs -- that can be exponentially more expressive\nthan both squared and monotonic PCs. Around sum of squares PCs, we build an\nexpressiveness hierarchy that allows us to precisely unify and separate\ndifferent tractable model classes such as Born Machines and PSD models, and\nother recently introduced tractable probabilistic models by using complex\nparameters. Finally, we empirically show the effectiveness of sum of squares\ncircuits in performing distribution estimation.",
      "tldr_zh": "本研究探讨了概率电路(PCs) 在生成模型中的可计算性和表现力权衡，特别分析了 squared PCs（通过负参数编码减法混合）与 monotonic PCs（仅正参数）的关系。论文证明，squared PCs 可能不如 monotonic PCs 更具表现力，并形式化了一个新类——sum of squares PCs，能比两者指数级更具表现力。该框架构建了一个表现力层次结构，将 Born Machines、PSD 模型以及使用复杂参数的模型统一并分离。最后，实验结果显示 sum of squares circuits 在分布估计任务中表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.AG"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11778v2",
      "published_date": "2024-08-21 17:08:05 UTC",
      "updated_date": "2024-12-19 13:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:26:00.388557"
    },
    {
      "arxiv_id": "2408.11761v1",
      "title": "D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models",
      "title_zh": "D-RMGPT：由大型多模态模型驱动的机器人辅助协作任务",
      "authors": [
        "M. Forlini",
        "M. Babcinschi",
        "G. Palmieri",
        "P. Neto"
      ],
      "abstract": "Collaborative robots are increasingly popular for assisting humans at work\nand daily tasks. However, designing and setting up interfaces for human-robot\ncollaboration is challenging, requiring the integration of multiple components,\nfrom perception and robot task control to the hardware itself. Frequently, this\nleads to highly customized solutions that rely on large amounts of costly\ntraining data, diverging from the ideal of flexible and general interfaces that\nempower robots to perceive and adapt to unstructured environments where they\ncan naturally collaborate with humans. To overcome these challenges, this paper\npresents the Detection-Robot Management GPT (D-RMGPT), a robot-assisted\nassembly planner based on Large Multimodal Models (LMM). This system can assist\ninexperienced operators in assembly tasks without requiring any markers or\nprevious training. D-RMGPT is composed of DetGPT-V and R-ManGPT. DetGPT-V,\nbased on GPT-4V(vision), perceives the surrounding environment through one-shot\nanalysis of prompted images of the current assembly stage and the list of\ncomponents to be assembled. It identifies which components have already been\nassembled by analysing their features and assembly requirements. R-ManGPT,\nbased on GPT-4, plans the next component to be assembled and generates the\nrobot's discrete actions to deliver it to the human co-worker. Experimental\ntests on assembling a toy aircraft demonstrated that D-RMGPT is flexible and\nintuitive to use, achieving an assembly success rate of 83% while reducing the\nassembly time for inexperienced operators by 33% compared to the manual\nprocess. http://robotics-and-ai.github.io/LMMmodels/",
      "tldr_zh": "本论文提出 D-RMGPT，一种基于 Large Multimodal Models (LMM) 的机器人辅助协作系统，旨在简化人类-机器人协作任务的设计，避免依赖大量训练数据。该系统由 DetGPT-V（基于 GPT-4V 进行环境感知，通过单次图像分析识别装配组件）和 R-ManGPT（基于 GPT-4 规划机器人动作）组成，能够帮助 inexperienced operators 直观地完成装配。实验结果显示，在组装玩具飞机的任务中，D-RMGPT 实现了 83% 的成功率，并将装配时间减少 33%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11761v1",
      "published_date": "2024-08-21 16:34:21 UTC",
      "updated_date": "2024-08-21 16:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:26:10.026610"
    },
    {
      "arxiv_id": "2408.11760v3",
      "title": "R2Det: Exploring Relaxed Rotation Equivariance in 2D object detection",
      "title_zh": "R2Det：在 2D 对象检测中探索松弛旋转等变性",
      "authors": [
        "Zhiqiang Wu",
        "Yingjie Liu",
        "Hanlin Dong",
        "Xuan Tang",
        "Jian Yang",
        "Bo Jin",
        "Mingsong Chen",
        "Xian Wei"
      ],
      "abstract": "Group Equivariant Convolution (GConv) empowers models to explore underlying\nsymmetry in data, improving performance. However, real-world scenarios often\ndeviate from ideal symmetric systems caused by physical permutation,\ncharacterized by non-trivial actions of a symmetry group, resulting in\nasymmetries that affect the outputs, a phenomenon known as Symmetry Breaking.\nTraditional GConv-based methods are constrained by rigid operational rules\nwithin group space, assuming data remains strictly symmetry after limited group\ntransformations. This limitation makes it difficult to adapt to\nSymmetry-Breaking and non-rigid transformations. Motivated by this, we mainly\nfocus on a common scenario: Rotational Symmetry-Breaking. By relaxing strict\ngroup transformations within Strict Rotation-Equivariant group $\\mathbf{C}_n$,\nwe redefine a Relaxed Rotation-Equivariant group $\\mathbf{R}_n$ and introduce a\nnovel Relaxed Rotation-Equivariant GConv (R2GConv) with only a minimal increase\nof $4n$ parameters compared to GConv. Based on R2GConv, we propose a Relaxed\nRotation-Equivariant Network (R2Net) as the backbone and develop a Relaxed\nRotation-Equivariant Object Detector (R2Det) for 2D object detection.\nExperimental results demonstrate the effectiveness of the proposed R2GConv in\nnatural image classification, and R2Det achieves excellent performance in 2D\nobject detection with improved generalization capabilities and robustness. The\ncode is available in \\texttt{https://github.com/wuer5/r2det}.",
      "tldr_zh": "该论文探讨了在2D对象检测中，如何应对Symmetry Breaking（对称性破坏）问题，特别是Rotational Symmetry-Breaking。作者引入了Relaxed Rotation-Equivariant group $\\mathbf{R}_n$和新型Relaxed Rotation-Equivariant GConv (R2GConv)，仅增加了$4n$参数，以放松传统Group Equivariant Convolution (GConv)的严格变换限制。基于R2GConv，他们开发了Relaxed Rotation-Equivariant Network (R2Net)作为骨干网络，并提出Relaxed Rotation-Equivariant Object Detector (R2Det)，显著提升了模型的泛化和鲁棒性。实验结果显示，R2GConv在自然图像分类中表现优秀，而R2Det在2D对象检测任务上取得了出色性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11760v3",
      "published_date": "2024-08-21 16:32:03 UTC",
      "updated_date": "2025-03-04 14:04:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:26:24.272812"
    },
    {
      "arxiv_id": "2408.11754v1",
      "title": "Improving the Scan-rescan Precision of AI-based CMR Biomarker Estimation",
      "title_zh": "改善基于 AI 的 CMR 生物标志物估计的扫描-重扫精度",
      "authors": [
        "Dewmini Hasara Wickremasinghe",
        "Yiyang Xu",
        "Esther Puyol-Antón",
        "Paul Aljabar",
        "Reza Razavi",
        "Andrew P. King"
      ],
      "abstract": "Quantification of cardiac biomarkers from cine cardiovascular magnetic\nresonance (CMR) data using deep learning (DL) methods offers many advantages,\nsuch as increased accuracy and faster analysis. However, only a few studies\nhave focused on the scan-rescan precision of the biomarker estimates, which is\nimportant for reproducibility and longitudinal analysis. Here, we propose a\ncardiac biomarker estimation pipeline that not only focuses on achieving high\nsegmentation accuracy but also on improving the scan-rescan precision of the\ncomputed biomarkers, namely left and right ventricular ejection fraction, and\nleft ventricular myocardial mass. We evaluate two approaches to improve the\napical-basal resolution of the segmentations used for estimating the\nbiomarkers: one based on image interpolation and one based on segmentation\ninterpolation. Using a database comprising scan-rescan cine CMR data acquired\nfrom 92 subjects, we compare the performance of these two methods against\nground truth (GT) segmentations and DL segmentations obtained before\ninterpolation (baseline). The results demonstrate that both the image-based and\nsegmentation-based interpolation methods were able to narrow Bland-Altman\nscan-rescan confidence intervals for all biomarkers compared to the GT and\nbaseline performances. Our findings highlight the importance of focusing not\nonly on segmentation accuracy but also on the consistency of biomarkers across\nrepeated scans, which is crucial for longitudinal analysis of cardiac function.",
      "tldr_zh": "本文提出了一种改进AI-based CMR生物标志物估计的管道，使用深度学习（DL）方法，不仅提升分割准确性，还重点提高扫描-重扫（scan-rescan）精度，包括左心室和右心室ejection fraction以及左心室myocardial mass的估算。研究评估了基于图像插值和基于分割插值的两种方法，通过92个受试者的cine CMR数据与地面真实（GT）和基线DL分割进行比较。结果显示，这两种方法显著缩小了Bland-Altman扫描-重扫置信区间，改善了所有生物标志物的可重复性。该工作强调，在心脏功能纵向分析中，确保生物标志物的一致性与分割准确性同样重要。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "11 pages, 3 figures, MICCAI STACOM 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11754v1",
      "published_date": "2024-08-21 16:24:27 UTC",
      "updated_date": "2024-08-21 16:24:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:26:38.241506"
    },
    {
      "arxiv_id": "2408.11747v1",
      "title": "Open-Ended 3D Point Cloud Instance Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Phuc D. A. Nguyen",
        "Minh Luu",
        "Anh Tran",
        "Cuong Pham",
        "Khoi Nguyen"
      ],
      "abstract": "Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently\ndemonstrated their ability to generalize to unseen objects. However, these\nmethods still depend on predefined class names during testing, restricting the\nautonomy of agents. To mitigate this constraint, we propose a novel problem\ntermed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the\nnecessity for predefined class names during testing. Moreover, we contribute a\ncomprehensive set of strong baselines, derived from OV-3DIS approaches and\nleveraging 2D Multimodal Large Language Models. To assess the performance of\nour OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the\nsemantic and geometric quality of predicted masks and their associated class\nnames, alongside the standard AP score. Our approach demonstrates significant\nperformance improvements over the baselines on the ScanNet200 and ScanNet++\ndatasets. Remarkably, our method surpasses the performance of Open3DIS, the\ncurrent state-of-the-art method in OV-3DIS, even in the absence of ground-truth\nobject class names.",
      "tldr_zh": "这篇论文提出了一种新的问题 Open-Ended 3D Instance Segmentation (OE-3DIS)，旨在解决传统 Open-Vocab 3D Instance Segmentation (OV-3DIS) 方法在测试时依赖预定义类名的限制，从而提升代理的自治性。作者贡献了基于 OV-3DIS 框架和 2D Multimodal Large Language Models 的强基线方法，并引入了 Open-Ended score 指标，用于评估预测掩码的语义、几何质量以及关联类名。实验结果显示，该方法在 ScanNet200 和 ScanNet++ 数据集上显著优于基线，并超越了当前最先进的 Open3DIS 方法，即使没有地面真实对象类名。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11747v1",
      "published_date": "2024-08-21 16:14:11 UTC",
      "updated_date": "2024-08-21 16:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:26:49.288076"
    },
    {
      "arxiv_id": "2408.11745v2",
      "title": "FocusLLM: Precise Understanding of Long Context by Dynamic Condensing",
      "title_zh": "FocusLLM：通过动态浓缩实现长上下文的精确理解",
      "authors": [
        "Zhenyu Li",
        "Yike Zhang",
        "Tengyu Pan",
        "Yutao Sun",
        "Zhichao Duan",
        "Junjie Fang",
        "Rong Han",
        "Zixuan Wang",
        "Jianyong Wang"
      ],
      "abstract": "Empowering LLMs with the ability to precisely understand long contexts is\ncrucial for many downstream applications. However, handling long contexts with\nconventional transformer architecture requires substantial training and\ninference resources. Existing context condensing methods cannot accurately\nunderstand the full context, as there is a considerable amount of information\nloss in the condensing process. To address these issues, we present FocusLLM, a\nframework designed to extend the fixed context length of any decoder-only LLM,\nallowing the model to focus on relevant information from very long sequences.\nFocusLLM first divides long text input into chunks based on the model's\noriginal context length. It then employs the dynamic condensing process to\ndistill crucial information from each chunk. Ultimately, through the novel\nparallel decoding mechanism, FocusLLM can integrate the extracted information\ninto its local context. FocusLLM stands out for great training efficiency and\nversatility: trained with an 8K input length and with much less training cost\nthan previous methods, FocusLLM exhibits superior performance across downstream\ntasks and maintains strong language modeling ability when handling extensive\nlong texts, even up to 400K tokens. Our code is available at\nhttps://github.com/leezythu/FocusLLM.",
      "tldr_zh": "该论文提出FocusLLM框架，通过动态浓缩技术来提升decoder-only LLM对长上下文的精确理解能力，解决了传统transformer架构资源需求大和信息丢失的问题。FocusLLM将长文本分成块、从每个块中提炼关键信息，并采用新型并行解码机制整合这些信息到本地上下文。实验结果显示，该框架在8K输入长度下训练成本更低，却能在下游任务中表现出色，并能处理长达400K标记的文本，提供更高效的语言建模能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11745v2",
      "published_date": "2024-08-21 16:11:59 UTC",
      "updated_date": "2024-12-23 15:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:27:04.606285"
    },
    {
      "arxiv_id": "2408.11744v1",
      "title": "JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet",
      "title_zh": "翻译失败",
      "authors": [
        "Yujia Gu",
        "Haofeng Li",
        "Xinyu Fang",
        "Zihan Peng",
        "Yinan Peng"
      ],
      "abstract": "This study proposes a novel approach to extract stylistic features of Jiehua:\nthe utilization of the Fine-tuned Stable Diffusion Model with ControlNet\n(FSDMC) to refine depiction techniques from artists' Jiehua. The training data\nfor FSDMC is based on the opensource Jiehua artist's work collected from the\nInternet, which were subsequently manually constructed in the format of\n(Original Image, Canny Edge Features, Text Prompt). By employing the optimal\nhyperparameters identified in this paper, it was observed FSDMC outperforms\nCycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27\non the dataset and also surpasses CycleGAN in terms of expert evaluation. This\nnot only demonstrates the model's high effectiveness in extracting Jiehua's\nstyle features, but also preserves the original pre-trained semantic\ninformation. The findings of this study suggest that the application of FSDMC\nwith appropriate hyperparameters can enhance the efficacy of the Stable\nDiffusion Model in the field of traditional art style migration tasks,\nparticularly within the context of Jiehua.",
      "tldr_zh": "本研究提出了一种名为 FSDMC 的模型，利用 Fine-tuned Stable Diffusion with ControlNet 来提取 Jiehua 画作的风格特征，训练数据基于互联网开源艺术家作品，并手动构建为 (Original Image, Canny Edge Features, Text Prompt) 格式。 通过优化超参数，FSDMC 在 FID 指标上达到 3.27，比主流风格迁移模型 CycleGAN 表现更优，并在专家评估中表现出色，同时保留了预训练的语义信息。 这表明 FSDMC 为传统艺术风格迁移任务提供了更有效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted by ICCSMT 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11744v1",
      "published_date": "2024-08-21 16:11:01 UTC",
      "updated_date": "2024-08-21 16:11:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:27:23.847297"
    },
    {
      "arxiv_id": "2408.11742v1",
      "title": "CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuliang Cai",
        "Mohammad Rostami"
      ],
      "abstract": "Large vision-language models (VLMs) have shown significant performance boost\nin various application domains. However, adopting them to deal with several\nsequentially encountered tasks has been challenging because finetuning a VLM on\na task normally leads to reducing its generalization power and the capacity of\nlearning new tasks as well as causing catastrophic forgetting on previously\nlearned tasks. Enabling using VLMs in multimodal continual learning (CL)\nsettings can help to address such scenarios. To improve generalization capacity\nand prevent catastrophic forgetting, we propose a novel prompt-based CL method\nfor VLMs, namely $\\textbf{Clu}$ster-based $\\textbf{Mo}$dality Fusion Prompt\n(\\textbf{CluMo}). We design a novel \\textbf{Key-Key-Prompt} pair, where each\nprompt is associated with a visual prompt key and a textual prompt key. We\nadopt a two-stage training strategy. During the first stage, the single-modal\nkeys are trained via $K$-means clustering algorithm to help select the best\nsemantically matched prompt. During the second stage, the prompt keys are\nfrozen, the selected prompt is attached to the input for training the VLM in\nthe CL scenario. Experiments on two benchmarks demonstrate that our method\nachieves SOTA performance.",
      "tldr_zh": "本文提出 CluMo，一种基于聚类的模态融合提示方法，用于解决视觉语言模型（VLMs）在视觉问答领域的连续学习（CL）中面临的灾难性遗忘和泛化能力下降问题。CluMo 设计了 Key-Key-Prompt 对，每个提示与视觉提示键和文本提示键相关联，通过两阶段训练策略实现优化：第一阶段使用 K-means 聚类算法训练单模态键以选择最佳语义匹配提示；第二阶段冻结提示键并将选定提示附加到输入中训练 VLM。实验结果显示，该方法在两个基准上达到了 SOTA（State-of-the-Art）性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11742v1",
      "published_date": "2024-08-21 16:07:49 UTC",
      "updated_date": "2024-08-21 16:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:27:26.488664"
    },
    {
      "arxiv_id": "2408.11735v3",
      "title": "Clinical Insights: A Comprehensive Review of Language Models in Medicine",
      "title_zh": "临床见解：医学中语言模型的全面回顾",
      "authors": [
        "Nikita Neveditsin",
        "Pawan Lingras",
        "Vijay Mago"
      ],
      "abstract": "This paper explores the advancements and applications of language models in\nhealthcare, focusing on their clinical use cases. It examines the evolution\nfrom early encoder-based systems requiring extensive fine-tuning to\nstate-of-the-art large language and multimodal models capable of integrating\ntext and visual data through in-context learning. The analysis emphasizes\nlocally deployable models, which enhance data privacy and operational autonomy,\nand their applications in tasks such as text generation, classification,\ninformation extraction, and conversational systems. The paper also highlights a\nstructured organization of tasks and a tiered ethical approach, providing a\nvaluable resource for researchers and practitioners, while discussing key\nchallenges related to ethics, evaluation, and implementation.",
      "tldr_zh": "这篇论文对语言模型在医疗领域的进展和应用进行全面综述，从早期的编码器模型发展到先进的 large language models 和 multimodal models，这些模型通过 in-context learning 整合文本和视觉数据。论文强调本地部署模型的优势，包括提升数据隐私和操作自治，并在文本生成、分类、信息提取以及对话系统等任务中展示其实用性。同时，它提出结构化的任务组织和分层伦理方法，作为研究者和从业者的宝贵资源，并讨论了伦理、评估和实施方面的关键挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to PLOS Digital Health, Revision 1",
      "pdf_url": "http://arxiv.org/pdf/2408.11735v3",
      "published_date": "2024-08-21 15:59:33 UTC",
      "updated_date": "2025-01-07 17:34:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:27:38.361772"
    },
    {
      "arxiv_id": "2408.11727v2",
      "title": "Efficient Detection of Toxic Prompts in Large Language Models",
      "title_zh": "高效检测大型语言模型中的毒性提示",
      "authors": [
        "Yi Liu",
        "Junzhe Yu",
        "Huijia Sun",
        "Ling Shi",
        "Gelei Deng",
        "Yuqi Chen",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) like ChatGPT and Gemini have significantly\nadvanced natural language processing, enabling various applications such as\nchatbots and automated content generation. However, these models can be\nexploited by malicious individuals who craft toxic prompts to elicit harmful or\nunethical responses. These individuals often employ jailbreaking techniques to\nbypass safety mechanisms, highlighting the need for robust toxic prompt\ndetection methods. Existing detection techniques, both blackbox and whitebox,\nface challenges related to the diversity of toxic prompts, scalability, and\ncomputational efficiency. In response, we propose ToxicDetector, a lightweight\ngreybox method designed to efficiently detect toxic prompts in LLMs.\nToxicDetector leverages LLMs to create toxic concept prompts, uses embedding\nvectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP)\nclassifier for prompt classification. Our evaluation on various versions of the\nLLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector\nachieves a high accuracy of 96.39\\% and a low false positive rate of 2.00\\%,\noutperforming state-of-the-art methods. Additionally, ToxicDetector's\nprocessing time of 0.0780 seconds per prompt makes it highly suitable for\nreal-time applications. ToxicDetector achieves high accuracy, efficiency, and\nscalability, making it a practical method for toxic prompt detection in LLMs.",
      "tldr_zh": "本文探讨了Large Language Models (LLMs) 如何被恶意toxic prompts 利用，引发有害响应的问题，并提出了一种轻量级的greybox 方法ToxicDetector 用于高效检测这些prompts。该方法利用LLMs 生成toxic concept prompts，通过embedding vectors 形成feature vectors，并采用Multi-Layer Perceptron (MLP) 分类器进行分类。在多种LLama 模型、Gemma-2 和多个数据集上的评估中，ToxicDetector 实现了96.39%的准确率和2.00%的假阳性率，且每prompt 处理时间仅为0.0780 秒，显著优于现有方法，提供高效率和可扩展性的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by the 39th IEEE/ACM International Conference on Automated\n  Software Engineering (ASE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2408.11727v2",
      "published_date": "2024-08-21 15:54:04 UTC",
      "updated_date": "2024-09-14 02:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:27:49.875988"
    },
    {
      "arxiv_id": "2408.11721v1",
      "title": "Iterative Object Count Optimization for Text-to-image Diffusion Models",
      "title_zh": "文本到图像扩散模型的迭代物体计数优化",
      "authors": [
        "Oz Zafar",
        "Lior Wolf",
        "Idan Schwartz"
      ],
      "abstract": "We address a persistent challenge in text-to-image models: accurately\ngenerating a specified number of objects. Current models, which learn from\nimage-text pairs, inherently struggle with counting, as training data cannot\ndepict every possible number of objects for any given object. To solve this, we\npropose optimizing the generated image based on a counting loss derived from a\ncounting model that aggregates an object\\'s potential. Employing an\nout-of-the-box counting model is challenging for two reasons: first, the model\nrequires a scaling hyperparameter for the potential aggregation that varies\ndepending on the viewpoint of the objects, and second, classifier guidance\ntechniques require modified models that operate on noisy intermediate diffusion\nsteps. To address these challenges, we propose an iterated online training mode\nthat improves the accuracy of inferred images while altering the text\nconditioning embedding and dynamically adjusting hyperparameters. Our method\noffers three key advantages: (i) it can consider non-derivable counting\ntechniques based on detection models, (ii) it is a zero-shot plug-and-play\nsolution facilitating rapid changes to the counting techniques and image\ngeneration methods, and (iii) the optimized counting token can be reused to\ngenerate accurate images without additional optimization. We evaluate the\ngeneration of various objects and show significant improvements in accuracy.\nThe project page is available at https://ozzafar.github.io/count_token.",
      "tldr_zh": "本文针对文本到图像扩散模型在生成指定数量对象时的准确性挑战，提出了一种迭代对象计数优化方法，通过基于计数模型的损失函数和迭代在线训练模式，动态调整超参数和文本条件嵌入来优化图像生成。 该方法的关键优势包括：(i) 支持基于检测模型的非可微计数技术，(ii) 提供零-shot 即插即用解决方案，便于快速切换计数和生成方法，(iii) 允许优化的计数标记重用以避免额外优化。 实验结果显示，该方法在各种对象生成任务上显著提高了准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2408.11721v1",
      "published_date": "2024-08-21 15:51:46 UTC",
      "updated_date": "2024-08-21 15:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:28:12.171917"
    },
    {
      "arxiv_id": "2408.11710v1",
      "title": "Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests",
      "title_zh": "利用大型语言模型提升生成单元测试的可理解性",
      "authors": [
        "Amirhossein Deljouyi",
        "Roham Koohestani",
        "Maliheh Izadi",
        "Andy Zaidman"
      ],
      "abstract": "Automated unit test generators, particularly search-based software testing\ntools like EvoSuite, are capable of generating tests with high coverage.\nAlthough these generators alleviate the burden of writing unit tests, they\noften pose challenges for software engineers in terms of understanding the\ngenerated tests. To address this, we introduce UTGen, which combines\nsearch-based software testing and large language models to enhance the\nunderstandability of automatically generated test cases. We achieve this\nenhancement through contextualizing test data, improving identifier naming, and\nadding descriptive comments. Through a controlled experiment with 32\nparticipants from both academia and industry, we investigate how the\nunderstandability of unit tests affects a software engineer's ability to\nperform bug-fixing tasks. We selected bug-fixing to simulate a real-world\nscenario that emphasizes the importance of understandable test cases. We\nobserve that participants working on assignments with UTGen test cases fix up\nto 33% more bugs and use up to 20% less time when compared to baseline test\ncases. From the post-test questionnaire, we gathered that participants found\nthat enhanced test names, test data, and variable names improved their\nbug-fixing process.",
      "tldr_zh": "该研究提出 UTGen 框架，通过整合搜索-based 软件测试工具（如 EvoSuite）和 Large Language Models，提升自动生成单元测试的可理解性，主要方法包括上下文化测试数据、改善标识符命名以及添加描述性注释。研究者进行了一项涉及 32 名学术和行业参与者的受控实验，评估可理解性对 bug-fixing 任务的影响，结果显示使用 UTGen 测试用例的参与者修复了多达 33% 的 bug，并节省了多达 20% 的时间。参与者反馈表明，增强的测试名称、测试数据和变量名称显著改善了 bug-fixing 过程，从而为软件工程实践提供了更高效的测试策略。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "**Note:** This paper has been accepted for presentation at the 47th\n  International Conference on Software Engineering (ICSE 2025) - Research Track",
      "pdf_url": "http://arxiv.org/pdf/2408.11710v1",
      "published_date": "2024-08-21 15:35:34 UTC",
      "updated_date": "2024-08-21 15:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:28:14.673279"
    },
    {
      "arxiv_id": "2408.11691v1",
      "title": "Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Félix Chavelli",
        "Zi-Yu Khoo",
        "Dawen Wu",
        "Jonathan Sze Choong Low",
        "Stéphane Bressan"
      ],
      "abstract": "The modeling of dynamical systems is a pervasive concern for not only\ndescribing but also predicting and controlling natural phenomena and engineered\nsystems. Current data-driven approaches often assume prior knowledge of the\nrelevant state variables or result in overparameterized state spaces. Boyuan\nChen and his co-authors proposed a neural network model that estimates the\ndegrees of freedom and attempts to discover the state variables of a dynamical\nsystem. Despite its innovative approach, this baseline model lacks a connection\nto the physical principles governing the systems it analyzes, leading to\nunreliable state variables.\n  This research proposes a method that leverages the physical characteristics\nof second-order Hamiltonian systems to constrain the baseline model. The\nproposed model outperforms the baseline model in identifying a minimal set of\nnon-redundant and interpretable state variables.",
      "tldr_zh": "这篇论文针对动态系统的建模挑战，提出了一种基于物理信息的方法，用于发现第二阶和Hamiltonian系统的状态变量。该方法通过利用Hamiltonian系统的物理特性来约束现有的神经网络基线模型（如Boyuan Chen等人的方法），从而克服基线模型缺乏物理原则导致的状态变量不可靠问题。结果显示，新模型能够识别出最小、非冗余且可解释的状态变量集，并在性能上优于基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11691v1",
      "published_date": "2024-08-21 15:10:50 UTC",
      "updated_date": "2024-08-21 15:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:28:25.883871"
    },
    {
      "arxiv_id": "2408.11659v1",
      "title": "5G NR PRACH Detection with Convolutional Neural Networks (CNN): Overcoming Cell Interference Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Desire Guel",
        "Arsene Kabore",
        "Didier Bassole"
      ],
      "abstract": "In this paper, we present a novel approach to interference detection in 5G\nNew Radio (5G-NR) networks using Convolutional Neural Networks (CNN).\nInterference in 5G networks challenges high-quality service due to dense user\nequipment deployment and increased wireless environment complexity. Our\nCNN-based model is designed to detect Physical Random Access Channel (PRACH)\nsequences amidst various interference scenarios, leveraging the spatial and\ntemporal characteristics of PRACH signals to enhance detection accuracy and\nrobustness. Comprehensive datasets of simulated PRACH signals under controlled\ninterference conditions were generated to train and validate the model.\nExperimental results show that our CNN-based approach outperforms traditional\nPRACH detection methods in accuracy, precision, recall and F1-score. This study\ndemonstrates the potential of AI/ML techniques in advancing interference\nmanagement in 5G networks, providing a foundation for future research and\npractical applications in optimizing network performance and reliability.",
      "tldr_zh": "本文提出了一种基于 Convolutional Neural Networks (CNN) 的新方法，用于检测 5G NR 网络中的 Physical Random Access Channel (PRACH) 序列，以克服密集用户设备部署和复杂无线环境带来的干扰挑战。该模型利用 PRACH 信号的空间和时间特性，通过在模拟数据集上训练来提升检测的准确性和鲁棒性。实验结果表明，该方法在准确率、精确率、召回率和 F1 分数上均优于传统 PRACH 检测方法。该研究展示了 AI/ML 技术在 5G 网络干扰管理中的潜力，为未来优化网络性能和可靠性提供重要基础。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11659v1",
      "published_date": "2024-08-21 14:33:43 UTC",
      "updated_date": "2024-08-21 14:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:28:39.453732"
    },
    {
      "arxiv_id": "2408.11650v2",
      "title": "CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher",
      "title_zh": "翻译失败",
      "authors": [
        "Derry Pratama",
        "Naufal Suryanto",
        "Andro Aprila Adiputra",
        "Thi-Thu-Huong Le",
        "Ahmada Yusril Kadiptya",
        "Muhammad Iqbal",
        "Howon Kim"
      ],
      "abstract": "Penetration testing, a critical component of cybersecurity, typically\nrequires extensive time and effort to find vulnerabilities. Beginners in this\nfield often benefit from collaborative approaches with the community or\nexperts. To address this, we develop CIPHER (Cybersecurity Intelligent\nPenetration-testing Helper for Ethical Researchers), a large language model\nspecifically trained to assist in penetration testing tasks. We trained CIPHER\nusing over 300 high-quality write-ups of vulnerable machines, hacking\ntechniques, and documentation of open-source penetration testing tools.\nAdditionally, we introduced the Findings, Action, Reasoning, and Results (FARR)\nFlow augmentation, a novel method to augment penetration testing write-ups to\nestablish a fully automated pentesting simulation benchmark tailored for large\nlanguage models. This approach fills a significant gap in traditional\ncybersecurity Q\\&A benchmarks and provides a realistic and rigorous standard\nfor evaluating AI's technical knowledge, reasoning capabilities, and practical\nutility in dynamic penetration testing scenarios. In our assessments, CIPHER\nachieved the best overall performance in providing accurate suggestion\nresponses compared to other open-source penetration testing models of similar\nsize and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B\nChat, particularly on insane difficulty machine setups. This demonstrates that\nthe current capabilities of general LLMs are insufficient for effectively\nguiding users through the penetration testing process. We also discuss the\npotential for improvement through scaling and the development of better\nbenchmarks using FARR Flow augmentation results. Our benchmark will be released\npublicly at https://github.com/ibndias/CIPHER.",
      "tldr_zh": "本研究开发了CIPHER，一种专门训练的大型语言模型（Large Language Model），旨在辅助道德研究者的渗透测试（Penetration Testing），通过使用超过300个高质量的渗透测试写-ups、黑客技巧和工具文档进行训练。研究引入了FARR Flow增强方法，以创建自动化渗透测试模拟基准，填补了传统网络安全Q&A基准的空白。评估结果显示，CIPHER在高难度场景中比类似规模的开源模型以及更大的模型如Llama 3 70B和Qwen1.5 72B Chat提供更准确的建议，证明了通用LLM在渗透测试中的不足，并讨论了通过扩展和改进基准的潜力，该基准将公开发布于GitHub。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "28 pages, github available",
      "pdf_url": "http://arxiv.org/pdf/2408.11650v2",
      "published_date": "2024-08-21 14:24:04 UTC",
      "updated_date": "2024-11-06 06:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:28:51.491286"
    },
    {
      "arxiv_id": "2408.11649v1",
      "title": "Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed S. Abdelrahman",
        "Mohamed Abdel-Aty",
        "Dongdong Wang"
      ],
      "abstract": "Computer vision has advanced research methodologies, enhancing system\nservices across various fields. It is a core component in traffic monitoring\nsystems for improving road safety; however, these monitoring systems don't\npreserve the privacy of pedestrians who appear in the videos, potentially\nrevealing their identities. Addressing this issue, our paper introduces\nVideo-to-Text Pedestrian Monitoring (VTPM), which monitors pedestrian movements\nat intersections and generates real-time textual reports, including traffic\nsignal and weather information. VTPM uses computer vision models for pedestrian\ndetection and tracking, achieving a latency of 0.05 seconds per video frame.\nAdditionally, it detects crossing violations with 90.2% accuracy by\nincorporating traffic signal data. The proposed framework is equipped with\nPhi-3 mini-4k to generate real-time textual reports of pedestrian activity\nwhile stating safety concerns like crossing violations, conflicts, and the\nimpact of weather on their behavior with latency of 0.33 seconds. To enhance\ncomprehensive analysis of the generated textual reports, Phi-3 medium is\nfine-tuned for historical analysis of these generated textual reports. This\nfine-tuning enables more reliable analysis about the pedestrian safety at\nintersections, effectively detecting patterns and safety critical events. The\nproposed VTPM offers a more efficient alternative to video footage by using\ntextual reports reducing memory usage, saving up to 253 million percent,\neliminating privacy issues, and enabling comprehensive interactive historical\nanalysis.",
      "tldr_zh": "这篇论文提出了 Video-to-Text Pedestrian Monitoring (VTPM) 框架，利用 Computer Vision 和 Large Language Models 来实现隐私保护的行人活动监控。VTPM 通过计算机视觉模型进行行人检测和跟踪，延迟仅为 0.05 秒，并以 90.2% 准确率检测违规行为，同时整合交通信号和天气信息生成实时文本报告。框架采用 Phi-3 mini-4k 模型创建这些报告，延迟为 0.33 秒，并微调 Phi-3 medium 用于历史分析，以识别行人安全模式和关键事件。总体上，VTPM 通过文本报告替代视频，大幅减少内存使用（节省高达 253 百万百分比），消除隐私风险，并支持全面交互式分析。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11649v1",
      "published_date": "2024-08-21 14:21:53 UTC",
      "updated_date": "2024-08-21 14:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:29:13.811844"
    },
    {
      "arxiv_id": "2408.11619v3",
      "title": "Data-driven Modeling of Combined Sewer Systems for Urban Sustainability: An Empirical Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Vipin Singh",
        "Tianheng Ling",
        "Teodor Chiaburu",
        "Felix Biessmann"
      ],
      "abstract": "Climate change poses complex challenges, with extreme weather events becoming\nincreasingly frequent and difficult to model. Examples include the dynamics of\nCombined Sewer Systems (CSS). Overburdened CSS during heavy rainfall will\noverflow untreated wastewater into surface water bodies. Classical approaches\nto modeling the impact of extreme rainfall events rely on physical simulations,\nwhich are particularly challenging to create for large urban infrastructures.\nDeep Learning (DL) models offer a cost-effective alternative for modeling the\ncomplex dynamics of sewer systems. In this study, we present a comprehensive\nempirical evaluation of several state-of-the-art DL time series models for\npredicting sewer system dynamics in a large urban infrastructure, utilizing\nthree years of measurement data. We especially investigate the potential of DL\nmodels to maintain predictive precision during network outages by comparing\nglobal models, which have access to all variables within the sewer system, and\nlocal models, which are limited to data from a restricted set of local sensors.\nOur findings demonstrate that DL models can accurately predict the dynamics of\nsewer system load, even under network outage conditions. These results suggest\nthat DL models can effectively aid in balancing the load redistribution in CSS,\nthereby enhancing the sustainability and resilience of urban infrastructures.",
      "tldr_zh": "本研究针对气候变化导致的极端天气事件对Combined Sewer Systems (CSS)的冲击，使用数据驱动方法评估Deep Learning (DL)模型预测大型城市下水系统动态。研究利用三年的测量数据，对多种先进的DL时间序列模型进行实证评估，比较了全局模型（访问所有变量）和局部模型（仅限本地传感器数据），特别是在网络中断条件下的预测性能。结果表明，DL模型即使在网络中断情况下也能准确预测下水系统负载，从而有助于平衡CSS的负载分布，提升城市基础设施的可持续性和弹性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "8 pages, 4 figures, accepted at 2nd Workshop on 'Public Interest AI'\n  co-located with 47th German Conference on Artificial Intelligence, Wuerzburg\n  23rd September 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11619v3",
      "published_date": "2024-08-21 13:46:58 UTC",
      "updated_date": "2025-02-13 11:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:29:25.292270"
    },
    {
      "arxiv_id": "2408.11609v2",
      "title": "Xinyu: An Efficient LLM-based System for Commentary Generation",
      "title_zh": "Xinyu：一种高效的基于LLM的评论生成系统",
      "authors": [
        "Yiquan Wu",
        "Bo Tang",
        "Chenyang Xi",
        "Yu Yu",
        "Pengyu Wang",
        "Yifei Liu",
        "Kun Kuang",
        "Haiying Deng",
        "Zhiyu Li",
        "Feiyu Xiong",
        "Jie Hu",
        "Peng Cheng",
        "Zhonghao Wang",
        "Yi Wang",
        "Yi Luo",
        "Mingchuan Yang"
      ],
      "abstract": "Commentary provides readers with a deep understanding of events by presenting\ndiverse arguments and evidence. However, creating commentary is a\ntime-consuming task, even for skilled commentators. Large language models\n(LLMs) have simplified the process of natural language generation, but their\ndirect application in commentary creation still faces challenges due to unique\ntask requirements. These requirements can be categorized into two levels: 1)\nfundamental requirements, which include creating well-structured and logically\nconsistent narratives, and 2) advanced requirements, which involve generating\nquality arguments and providing convincing evidence. In this paper, we\nintroduce Xinyu, an efficient LLM-based system designed to assist commentators\nin generating Chinese commentaries. To meet the fundamental requirements, we\ndeconstruct the generation process into sequential steps, proposing targeted\nstrategies and supervised fine-tuning (SFT) for each step. To address the\nadvanced requirements, we present an argument ranking model for arguments and\nestablish a comprehensive evidence database that includes up-to-date events and\nclassic books, thereby strengthening the substantiation of the evidence with\nretrieval augmented generation (RAG) technology. To evaluate the generated\ncommentaries more fairly, corresponding to the two-level requirements, we\nintroduce a comprehensive evaluation metric that considers five distinct\nperspectives in commentary generation. Our experiments confirm the\neffectiveness of our proposed system. We also observe a significant increase in\nthe efficiency of commentators in real-world scenarios, with the average time\nspent on creating a commentary dropping from 4 hours to 20 minutes.\nImportantly, such an increase in efficiency does not compromise the quality of\nthe commentaries.",
      "tldr_zh": "这篇论文介绍了 Xinyu，一种基于 LLM 的高效系统，旨在辅助生成中文评论以解决创建评论的耗时问题，包括基本要求（如结构化和逻辑一致的叙述）和高级要求（如高质量论点和证据）。系统通过将生成过程分解为顺序步骤、采用监督微调 (SFT) 策略，以及引入论点排名模型和一个综合证据数据库结合检索增强生成 (RAG) 技术，来满足这些要求。实验结果显示，Xinyu 显著提升了效率，将评论员的平均创作时间从 4 小时缩短至 20 分钟，同时保持了评论质量，并在多视角评价指标下证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11609v2",
      "published_date": "2024-08-21 13:34:29 UTC",
      "updated_date": "2024-08-23 03:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:29:27.856847"
    },
    {
      "arxiv_id": "2408.11608v2",
      "title": "Don't Kill the Baby: The Case for AI in Arbitration",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Broyde",
        "Yiyang Mei"
      ],
      "abstract": "Since the introduction of Generative AI (GenAI) in 2022, its ability to\nsimulate human intelligence and generate content has sparked both enthusiasm\nand concern. While much criticism focuses on AI's potential to perpetuate bias,\ncreate emotional dissonance, displace jobs, and raise ethical questions, these\nconcerns often overlook the practical benefits of AI, particularly in legal\ncontexts.\n  This article examines the integration of AI into arbitration, arguing that\nthe Federal Arbitration Act (FAA) allows parties to contractually choose\nAI-driven arbitration, despite traditional reservations. The article makes\nthree key contributions: (1) It shifts the focus from debates over AI's\npersonhood to the practical aspects of incorporating AI into arbitration,\nasserting that AI can effectively serve as an arbitrator if both parties agree;\n(2) It positions arbitration as an ideal starting point for broader AI adoption\nin the legal field, given its flexibility and the autonomy it grants parties to\ndefine their standards of fairness; and (3) It outlines future research\ndirections, emphasizing the importance of empirically comparing AI and human\narbitration, which could lead to the development of distinct systems.\n  By advocating for the use of AI in arbitration, this article underscores the\nimportance of respecting contractual autonomy and creating an environment that\nallows AI's potential to be fully realized. Drawing on the insights of Judge\nRichard Posner, the article argues that the ethical obligations of AI in\narbitration should be understood within the context of its technological\nstrengths and the voluntary nature of arbitration agreements. Ultimately, it\ncalls for a balanced, open-minded approach to AI in arbitration, recognizing\nits potential to enhance the efficiency, fairness, and flexibility of dispute\nresolution",
      "tldr_zh": "这篇文章探讨了Generative AI (GenAI) 在仲裁领域的潜力，主张尽管存在偏见和伦理担忧，但AI可以通过Federal Arbitration Act (FAA) 的规定，由当事人合同选择作为仲裁员。文章的主要贡献包括：将焦点从AI的拟人化辩论转向实际整合的可行性、将仲裁视为AI在法律领域推广的理想起点，以及提出未来研究方向，如AI与人类仲裁的实证比较。最终，它呼吁平衡的方法，强调尊重合同自治，利用AI提升仲裁的效率、公平性和灵活性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11608v2",
      "published_date": "2024-08-21 13:34:20 UTC",
      "updated_date": "2025-03-22 17:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:29:38.182232"
    },
    {
      "arxiv_id": "2408.11607v2",
      "title": "Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Benjamin",
        "Alessandro Abate"
      ],
      "abstract": "Recent algorithms allow decentralised agents, possibly connected via a\ncommunication network, to learn equilibria in Mean-Field Games from a\nnon-episodic run of the empirical system. However, these algorithms are for\ntabular settings: this computationally limits the size of agents' observation\nspace, meaning the algorithms cannot handle anything but small state spaces,\nnor generalise beyond policies depending only on the agent's local state to\nso-called 'population-dependent' policies. We address this limitation by\nintroducing function approximation to the existing setting, drawing on the\nMunchausen Online Mirror Descent method that has previously been employed only\nin finite-horizon, episodic, centralised settings. While this permits us to\ninclude the mean field in the observation for players' policies, it is\nunrealistic to assume decentralised agents have access to this global\ninformation: we therefore also provide new algorithms allowing agents to\nlocally estimate the global empirical distribution, and to improve this\nestimate via inter-agent communication. We show theoretically that exchanging\npolicy information helps networked agents outperform both independent and even\ncentralised agents in function-approximation settings. Our experiments\ndemonstrate this happening empirically, by an even greater margin than in\ntabular settings, and show that the communication network allows decentralised\nagents to estimate the mean field for population-dependent policies.",
      "tldr_zh": "这篇论文针对Mean-Field Games的去中心化代理学习问题，引入函数逼近和经验Mean-Field Estimation，通过网络化通信来克服现有算法在表格设置下的局限性，如小状态空间和无法处理Population-Dependent policies。作者基于Munchausen Online Mirror Descent方法，开发了新算法，让代理本地估计全局经验分布，并通过交换策略信息进行改进。理论分析和实验结果表明，这种网络化方法使去中心化代理在函数逼近场景中显著优于独立或中心化代理，尤其在估计Mean-Field和实现Population-Dependent策略方面。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11607v2",
      "published_date": "2024-08-21 13:32:46 UTC",
      "updated_date": "2025-03-13 13:32:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:29:50.507762"
    },
    {
      "arxiv_id": "2408.11599v1",
      "title": "Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinhao Chen",
        "Chong Yang",
        "Man Lan",
        "Li Cai",
        "Yang Chen",
        "Tu Hu",
        "Xinlin Zhuang",
        "Aimin Zhou"
      ],
      "abstract": "Empathetic response generation endows agents with the capability to\ncomprehend dialogue contexts and react to expressed emotions. Previous works\npredominantly focus on leveraging the speaker's emotional labels, but ignore\nthe importance of emotion cause reasoning in empathetic response generation,\nwhich hinders the model's capacity for further affective understanding and\ncognitive inference. In this paper, we propose a cause-aware empathetic\ngeneration approach by integrating emotions and causes through a well-designed\nChain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can\ngreatly promote LLMs' performance of empathy by instruction tuning and\nenhancing the role awareness of an empathetic listener in the prompt.\nAdditionally, we propose to incorporate cause-oriented external knowledge from\nCOMET into the prompt, which improves the diversity of generation and\nalleviates conflicts between internal and external knowledge at the same time.\nExperimental results on the benchmark dataset demonstrate that our approach on\nLLaMA-7b achieves state-of-the-art performance in both automatic and human\nevaluations.",
      "tldr_zh": "本文提出了一种基于 Chain-of-Thought (CoT) 微调的因果感知共情响应生成方法，旨在解决现有模型忽略情感原因推理的问题，从而提升对对话情境的认知和情感理解。方法通过在 Large Language Models (LLMs) 上设计 CoT 提示，整合情感标签与原因推理，并引入来自 COMET 的外部知识，以提高生成多样性和缓解内部外部知识冲突。实验结果表明，该方法在 LLaMA-7b 模型上于基准数据集中实现了 state-of-the-art 性能，在自动和人工评估中均表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11599v1",
      "published_date": "2024-08-21 13:11:03 UTC",
      "updated_date": "2024-08-21 13:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:30:13.564188"
    },
    {
      "arxiv_id": "2408.11592v1",
      "title": "Active learning for efficient data selection in radio-signal based positioning via deep learning",
      "title_zh": "翻译失败",
      "authors": [
        "Vincent Corlay",
        "Milan Courcoux-Caro"
      ],
      "abstract": "We consider the problem of user equipment (UE) positioning based on radio\nsignals via deep learning. As in most supervised-learning tasks, a critical\naspect is the availability of a relevant dataset to train a model. However, in\na cellular network, the data-collection step may induce a high communication\noverhead. As a result, to reduce the required size of the dataset, it may be\ninteresting to carefully choose the positions to be labelled and to be used in\nthe training. We therefore propose an active learning approach for efficient\ndata collection. We first show that significant gains (both in terms of\npositioning accuracy and size of the required dataset) can be obtained for the\nconsidered positioning problem using a genie. This validates the interest of\nactive learning for positioning. We then propose a \\textcolor{blue}{practical}\nmethod to approximate this genie.",
      "tldr_zh": "该研究探讨了基于深度学习的无线电信号定位问题，旨在通过主动学习(active learning)优化数据选择以减少数据集规模。论文提出了一种方法来高效选择需要标记的位置，从而降低数据收集的通信开销。实验结果显示，使用理想的genie辅助选择能显著提升定位准确性并减少所需数据，验证了主动学习的有效性。最后，作者提供了一个实际方法来近似genie，实现更可行的定位系统优化。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Submitted to Electronics Letters",
      "pdf_url": "http://arxiv.org/pdf/2408.11592v1",
      "published_date": "2024-08-21 12:59:35 UTC",
      "updated_date": "2024-08-21 12:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:30:18.268736"
    },
    {
      "arxiv_id": "2408.11574v1",
      "title": "Drama Engine: A Framework for Narrative Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Pichlmair",
        "Riddhi Raj",
        "Charlene Putney"
      ],
      "abstract": "This technical report presents the Drama Engine, a novel framework for\nagentic interaction with large language models designed for narrative purposes.\nThe framework adapts multi-agent system principles to create dynamic,\ncontext-aware companions that can develop over time and interact with users and\neach other. Key features include multi-agent workflows with delegation, dynamic\nprompt assembly, and model-agnostic design. The Drama Engine introduces unique\nelements such as companion development, mood systems, and automatic context\nsummarising. It is implemented in TypeScript. The framework's applications\ninclude multi-agent chats and virtual co-workers for creative writing. The\npaper discusses the system's architecture, prompt assembly process, delegation\nmechanisms, and moderation techniques, as well as potential ethical\nconsiderations and future extensions.",
      "tldr_zh": "该论文介绍了Drama Engine，一种新型框架，用于大型语言模型（large language models）的代理交互，专注于叙事应用。该框架基于多代理系统（multi-agent system）原则，设计了动态、上下文感知的伴侣代理，支持多代理工作流、委托机制、动态提示组装（dynamic prompt assembly）和模型无关设计，并引入了伴侣发展、情绪系统以及自动上下文总结功能。Drama Engine以TypeScript实现，可应用于多代理聊天和虚拟合作者（virtual co-workers）以辅助创意写作，论文还讨论了系统架构、委托机制、调节技术、伦理考虑以及未来扩展潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "68T42 (Primary), 68T50 (Secondary)",
        "I.2.7; J.5"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.11574v1",
      "published_date": "2024-08-21 12:29:38 UTC",
      "updated_date": "2024-08-21 12:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:30:26.203919"
    },
    {
      "arxiv_id": "2408.11554v1",
      "title": "Differentiating Choices via Commonality for Multiple-Choice Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Deng",
        "Zhe Wang",
        "Kewen Wang",
        "Shirui Pan",
        "Xiaowang Zhang",
        "Zhiyong Feng"
      ],
      "abstract": "Multiple-choice question answering (MCQA) becomes particularly challenging\nwhen all choices are relevant to the question and are semantically similar. Yet\nthis setting of MCQA can potentially provide valuable clues for choosing the\nright answer. Existing models often rank each choice separately, overlooking\nthe context provided by other choices. Specifically, they fail to leverage the\nsemantic commonalities and nuances among the choices for reasoning. In this\npaper, we propose a novel MCQA model by differentiating choices through\nidentifying and eliminating their commonality, called DCQA. Our model captures\ntoken-level attention of each choice to the question, and separates tokens of\nthe question attended to by all the choices (i.e., commonalities) from those by\nindividual choices (i.e., nuances). Using the nuances as refined contexts for\nthe choices, our model can effectively differentiate choices with subtle\ndifferences and provide justifications for choosing the correct answer. We\nconduct comprehensive experiments across five commonly used MCQA benchmarks,\ndemonstrating that DCQA consistently outperforms baseline models. Furthermore,\nour case study illustrates the effectiveness of the approach in directing the\nattention of the model to more differentiating features.",
      "tldr_zh": "本文提出 DCQA 模型，用于解决多选题问答（MCQA）中选项语义相似且相关时的挑战，通过识别和消除选项的 commonalities（共同性）来区分 nuances（细微差异）。模型捕捉每个选项对问题的 token-level attention，将问题中被所有选项关注的 tokens（commonalities）与被单个选项关注的 tokens（nuances）分开，并使用 nuances 作为细化上下文，以更有效地识别正确答案并提供推理依据。实验结果显示，DCQA 在五个常用 MCQA 基准上 consistently outperforms baseline models，并在案例研究中证明了其在引导模型关注区分性特征方面的优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, accepted to ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11554v1",
      "published_date": "2024-08-21 12:05:21 UTC",
      "updated_date": "2024-08-21 12:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:30:42.297266"
    },
    {
      "arxiv_id": "2408.11552v1",
      "title": "Explainable Deep Learning Framework for Human Activity Recognition",
      "title_zh": "可解释深度学习框架用于人类活动识别",
      "authors": [
        "Yiran Huang",
        "Yexu Zhou",
        "Haibin Zhao",
        "Till Riedel",
        "Michael Beigl"
      ],
      "abstract": "In the realm of human activity recognition (HAR), the integration of\nexplainable Artificial Intelligence (XAI) emerges as a critical necessity to\nelucidate the decision-making processes of complex models, fostering\ntransparency and trust. Traditional explanatory methods like Class Activation\nMapping (CAM) and attention mechanisms, although effective in highlighting\nregions vital for decisions in various contexts, prove inadequate for HAR. This\ninadequacy stems from the inherently abstract nature of HAR data, rendering\nthese explanations obscure. In contrast, state-of-th-art post-hoc\ninterpretation techniques for time series can explain the model from other\nperspectives. However, this requires extra effort. It usually takes 10 to 20\nseconds to generate an explanation. To overcome these challenges, we proposes a\nnovel, model-agnostic framework that enhances both the interpretability and\nefficacy of HAR models through the strategic use of competitive data\naugmentation. This innovative approach does not rely on any particular model\narchitecture, thereby broadening its applicability across various HAR models.\nBy implementing competitive data augmentation, our framework provides intuitive\nand accessible explanations of model decisions, thereby significantly advancing\nthe interpretability of HAR systems without compromising on performance.",
      "tldr_zh": "本论文针对人类活动识别 (HAR) 中的解释性挑战，指出传统方法如 Class Activation Mapping (CAM) 和注意力机制无法有效处理 HAR 数据的抽象性，导致解释模糊。论文提出一个新型、模型无关的框架，通过竞争性数据增强 (competitive data augmentation) 策略来提升 HAR 模型的可解释性和性能。该框架不依赖特定模型架构，提供直观的决策解释，并在保持高效能的同时，显著提高了系统的透明度和信任。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11552v1",
      "published_date": "2024-08-21 11:59:55 UTC",
      "updated_date": "2024-08-21 11:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:30:51.150962"
    },
    {
      "arxiv_id": "2408.11546v3",
      "title": "Memorization in In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shahriar Golchin",
        "Mihai Surdeanu",
        "Steven Bethard",
        "Eduardo Blanco",
        "Ellen Riloff"
      ],
      "abstract": "In-context learning (ICL) has proven to be an effective strategy for\nimproving the performance of large language models (LLMs) with no additional\ntraining. However, the exact mechanism behind this performance improvement\nremains unclear. This study is the first to show how ICL surfaces memorized\ntraining data and to explore the correlation between this memorization and\nperformance on downstream tasks across various ICL regimes: zero-shot,\nfew-shot, and many-shot. Our most notable findings include: (1) ICL\nsignificantly surfaces memorization compared to zero-shot learning in most\ncases; (2) demonstrations, without their labels, are the most effective element\nin surfacing memorization; (3) ICL improves performance when the surfaced\nmemorization in few-shot regimes reaches a high level (about 40%); and (4)\nthere is a very strong correlation between performance and memorization in ICL\nwhen it outperforms zero-shot learning. Overall, our study uncovers\nmemorization as a new factor impacting ICL, raising an important question: to\nwhat extent do LLMs truly generalize from demonstrations in ICL, and how much\nof their success is due to memorization?",
      "tldr_zh": "本研究探讨了In-Context Learning (ICL)如何提升大型语言模型 (LLMs) 的性能，却揭示了其背后机制涉及训练数据的记忆表面化。该研究首次分析了ICL在零样本、少样本和多样本场景下如何显著增加记忆暴露，并发现不带标签的演示样本是最有效的元素。关键发现包括：当少样本场景中的记忆水平达到约40%时，ICL性能显著提升，且记忆与性能之间存在强相关性。该工作引发了对LLMs在ICL中是否真正泛化，还是主要依赖记忆的深思。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "v3",
      "pdf_url": "http://arxiv.org/pdf/2408.11546v3",
      "published_date": "2024-08-21 11:54:22 UTC",
      "updated_date": "2025-04-04 02:50:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:31:03.361625"
    },
    {
      "arxiv_id": "2408.11537v1",
      "title": "A Survey of Embodied Learning for Object-Centric Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Zheng",
        "Lei Yao",
        "Yuejiao Su",
        "Yi Zhang",
        "Yi Wang",
        "Sicheng Zhao",
        "Yiyi Zhang",
        "Lap-Pui Chau"
      ],
      "abstract": "Embodied learning for object-centric robotic manipulation is a rapidly\ndeveloping and challenging area in embodied AI. It is crucial for advancing\nnext-generation intelligent robots and has garnered significant interest\nrecently. Unlike data-driven machine learning methods, embodied learning\nfocuses on robot learning through physical interaction with the environment and\nperceptual feedback, making it especially suitable for robotic manipulation. In\nthis paper, we provide a comprehensive survey of the latest advancements in\nthis field and categorize the existing work into three main branches: 1)\nEmbodied perceptual learning, which aims to predict object pose and affordance\nthrough various data representations; 2) Embodied policy learning, which\nfocuses on generating optimal robotic decisions using methods such as\nreinforcement learning and imitation learning; 3) Embodied task-oriented\nlearning, designed to optimize the robot's performance based on the\ncharacteristics of different tasks in object grasping and manipulation. In\naddition, we offer an overview and discussion of public datasets, evaluation\nmetrics, representative applications, current challenges, and potential future\nresearch directions. A project associated with this survey has been established\nat https://github.com/RayYoh/OCRM_survey.",
      "tldr_zh": "这篇论文对 Embodied Learning for Object-Centric Robotic Manipulation 进行了全面调查，强调通过机器人与环境的物理互动和感知反馈来提升智能机器人操作能力。论文将现有工作分类为三大分支：Embodied perceptual learning（预测物体姿势和 affordance）、Embodied policy learning（利用 reinforcement learning 和 imitation learning 生成最佳决策），以及 Embodied task-oriented learning（针对物体抓取和操作任务优化性能）。此外，论文还概述了公共数据集、evaluation metrics、代表性应用、当前挑战和未来研究方向，并提供了一个相关 GitHub 项目（https://github.com/RayYoh/OCRM_survey）。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11537v1",
      "published_date": "2024-08-21 11:32:09 UTC",
      "updated_date": "2024-08-21 11:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:31:15.783099"
    },
    {
      "arxiv_id": "2408.11530v1",
      "title": "Scalable Knowledge Refactoring using Constrained Optimisation",
      "title_zh": "翻译失败",
      "authors": [
        "Minghao Liu",
        "David M. Cerna",
        "Filipe Gouveia",
        "Andrew Cropper"
      ],
      "abstract": "Knowledge refactoring compresses a logic program by introducing new rules.\nCurrent approaches struggle to scale to large programs. To overcome this\nlimitation, we introduce a constrained optimisation refactoring approach. Our\nfirst key idea is to encode the problem with decision variables based on\nliterals rather than rules. Our second key idea is to focus on linear invented\nrules. Our empirical results on multiple domains show that our approach can\nrefactor programs quicker and with more compression than the previous\nstate-of-the-art approach, sometimes by 60%.",
      "tldr_zh": "该论文提出了一种基于约束优化的可扩展知识重构方法（Scalable Knowledge Refactoring），旨在通过引入新规则压缩逻辑程序，并解决现有方法在处理大型程序时的扩展性问题。关键创新包括使用基于字面量（literals）的决策变量进行问题编码，以及专注于线性发明规则（linear invented rules），从而提升重构效率。实验结果显示，该方法在多个领域比之前的最先进方法更快完成重构，并实现更高压缩率，有时高达60%。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11530v1",
      "published_date": "2024-08-21 11:12:42 UTC",
      "updated_date": "2024-08-21 11:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:31:26.471535"
    },
    {
      "arxiv_id": "2408.11527v3",
      "title": "The Vizier Gaussian Process Bandit Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyou Song",
        "Qiuyi Zhang",
        "Chansoo Lee",
        "Emily Fertig",
        "Tzu-Kuo Huang",
        "Lior Belenki",
        "Greg Kochanski",
        "Setareh Ariafar",
        "Srinivas Vasudevan",
        "Sagi Perel",
        "Daniel Golovin"
      ],
      "abstract": "Google Vizier has performed millions of optimizations and accelerated\nnumerous research and production systems at Google, demonstrating the success\nof Bayesian optimization as a large-scale service. Over multiple years, its\nalgorithm has been improved considerably, through the collective experiences of\nnumerous research efforts and user feedback. In this technical report, we\ndiscuss the implementation details and design choices of the current default\nalgorithm provided by Open Source Vizier. Our experiments on standardized\nbenchmarks reveal its robustness and versatility against well-established\nindustry baselines on multiple practical modes.",
      "tldr_zh": "该论文介绍了 Google Vizier 的高斯过程(Gaussian Process) Bandit 算法，作为一个大规模贝叶斯优化(Bayesian optimization)服务，已进行数百万次优化并加速了 Google 的研究和生产系统。算法通过多年研究努力和用户反馈不断改进，包括详细的实现细节和设计选择，以提升其在实际应用中的性能。实验结果显示，该算法在标准化基准上表现出色，比行业基线更稳健和多功能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Google DeepMind Technical Report. Code can be found in\n  https://github.com/google/vizier",
      "pdf_url": "http://arxiv.org/pdf/2408.11527v3",
      "published_date": "2024-08-21 11:06:02 UTC",
      "updated_date": "2024-12-06 17:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:31:37.671897"
    },
    {
      "arxiv_id": "2408.11526v2",
      "title": "RConE: Rough Cone Embedding for Multi-Hop Logical Query Answering on Multi-Modal Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Mayank Kharbanda",
        "Rajiv Ratn Shah",
        "Raghava Mutharaju"
      ],
      "abstract": "Multi-hop query answering over a Knowledge Graph (KG) involves traversing one\nor more hops from the start node to answer a query. Path-based and logic-based\nmethods are state-of-the-art for multi-hop question answering. The former is\nused in link prediction tasks. The latter is for answering complex logical\nqueries. The logical multi-hop querying technique embeds the KG and queries in\nthe same embedding space. The existing work incorporates First Order Logic\n(FOL) operators, such as conjunction ($\\wedge$), disjunction ($\\vee$), and\nnegation ($\\neg$), in queries. Though current models have most of the building\nblocks to execute the FOL queries, they cannot use the dense information of\nmulti-modal entities in the case of Multi-Modal Knowledge Graphs (MMKGs). We\npropose RConE, an embedding method to capture the multi-modal information\nneeded to answer a query. The model first shortlists candidate (multi-modal)\nentities containing the answer. It then finds the solution (sub-entities)\nwithin those entities. Several existing works tackle path-based\nquestion-answering in MMKGs. However, to our knowledge, we are the first to\nintroduce logical constructs in querying MMKGs and to answer queries that\ninvolve sub-entities of multi-modal entities as the answer. Extensive\nevaluation of four publicly available MMKGs indicates that RConE outperforms\nthe current state-of-the-art.",
      "tldr_zh": "该论文提出 RConE（Rough Cone Embedding）方法，用于在多模态知识图谱（Multi-Modal Knowledge Graphs, MMKGs）上进行多跳逻辑查询回答（Multi-Hop Logical Query Answering）。RConE 通过嵌入技术捕捉多模态实体信息，先筛选候选实体，然后在这些实体中定位子实体作为答案，从而解决了现有方法无法充分利用 First Order Logic (FOL) 操作符（如 ∧、∨、¬）和多模态数据的局限性。该方法是首次将逻辑结构应用于 MMKGs 并处理涉及子实体的查询，在四个公开 MMKGs 的广泛实验中，RConE 超过了当前最先进模型的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11526v2",
      "published_date": "2024-08-21 11:02:35 UTC",
      "updated_date": "2024-08-26 07:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:31:51.332756"
    },
    {
      "arxiv_id": "2408.11523v1",
      "title": "LARR: Large Language Model Aided Real-time Scene Recommendation with Semantic Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhizhong Wan",
        "Bin Yin",
        "Junjie Xie",
        "Fei Jiang",
        "Xiang Li",
        "Wei Lin"
      ],
      "abstract": "Click-Through Rate (CTR) prediction is crucial for Recommendation System(RS),\naiming to provide personalized recommendation services for users in many\naspects such as food delivery, e-commerce and so on. However, traditional RS\nrelies on collaborative signals, which lacks semantic understanding to\nreal-time scenes. We also noticed that a major challenge in utilizing Large\nLanguage Models (LLMs) for practical recommendation purposes is their\nefficiency in dealing with long text input. To break through the problems\nabove, we propose Large Language Model Aided Real-time Scene\nRecommendation(LARR), adopt LLMs for semantic understanding, utilizing\nreal-time scene information in RS without requiring LLM to process the entire\nreal-time scene text directly, thereby enhancing the efficiency of LLM-based\nCTR modeling. Specifically, recommendation domain-specific knowledge is\ninjected into LLM and then RS employs an aggregation encoder to build real-time\nscene information from separate LLM's outputs. Firstly, a LLM is continual\npretrained on corpus built from recommendation data with the aid of special\ntokens. Subsequently, the LLM is fine-tuned via contrastive learning on three\nkinds of sample construction strategies. Through this step, LLM is transformed\ninto a text embedding model. Finally, LLM's separate outputs for different\nscene features are aggregated by an encoder, aligning to collaborative signals\nin RS, enhancing the performance of recommendation model.",
      "tldr_zh": "该论文提出LARR框架，利用Large Language Models (LLMs)辅助实时场景推荐系统（RS），以解决传统RS依赖协作信号而缺乏语义理解的问题，同时提升LLMs处理长文本的效率。具体方法包括：将推荐领域特定知识注入LLMs，并通过持续预训练（continual pretrained）在推荐数据语料上训练，使用特殊tokens和三种样本构建策略进行对比学习（contrastive learning）微调，将LLMs转化为文本嵌入模型；随后，使用aggregation encoder聚合LLMs对不同场景特征的输出，与协作信号对齐。最终，该框架增强了CTR（Click-Through Rate）预测的性能，提高了实时推荐的准确性和效率。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11523v1",
      "published_date": "2024-08-21 10:56:26 UTC",
      "updated_date": "2024-08-21 10:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:32:03.616035"
    },
    {
      "arxiv_id": "2408.11515v1",
      "title": "Quantifying Behavioural Distance Between Mathematical Expressions",
      "title_zh": "量化数学表达式之间的行为距离",
      "authors": [
        "Sebastian Mežnar",
        "Sašo Džeroski",
        "Ljupčo Todorovski"
      ],
      "abstract": "Existing symbolic regression methods organize the space of candidate\nmathematical expressions primarily based on their syntactic, structural\nsimilarity. However, this approach overlooks crucial equivalences between\nexpressions that arise from mathematical symmetries, such as commutativity,\nassociativity, and distribution laws for arithmetic operations. Consequently,\nexpressions with similar errors on a given data set are apart from each other\nin the search space. This leads to a rough error landscape in the search space\nthat efficient local, gradient-based methods cannot explore. This paper\nproposes and implements a measure of a behavioral distance, BED, that clusters\ntogether expressions with similar errors. The experimental results show that\nthe stochastic method for calculating BED achieves consistency with a modest\nnumber of sampled values for evaluating the expressions. This leads to\ncomputational efficiency comparable to the tree-based syntactic distance. Our\nfindings also reveal that BED significantly improves the smoothness of the\nerror landscape in the search space for symbolic regression.",
      "tldr_zh": "本研究指出，现有的符号回归方法主要基于表达式的语法和结构相似性组织搜索空间，但忽略了数学对称性（如 commutativity、associativity 和 distribution laws）带来的等价性，导致错误相似的表达式在搜索空间中相隔较远，形成粗糙的错误景观。作者提出了一种行为距离度量 BED（Behavioural Distance），通过聚类错误相似的表达式来改善这一问题，并采用随机采样方法计算 BED，以实现与基于树的语法距离相当的计算效率。实验结果显示，BED 显著提升了符号回归搜索空间的错误景观平滑度，从而优化了局部和梯度-based 方法的探索效果。",
      "categories": [
        "cs.AI",
        "68T01",
        "I.1.1; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 10 figures, 1 table, 2 appendices",
      "pdf_url": "http://arxiv.org/pdf/2408.11515v1",
      "published_date": "2024-08-21 10:48:04 UTC",
      "updated_date": "2024-08-21 10:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:32:15.166770"
    },
    {
      "arxiv_id": "2408.11513v1",
      "title": "Last-Iterate Convergence of General Parameterized Policies in Constrained MDPs",
      "title_zh": "一般参数化策略在约束马尔可夫决策过程中的最后迭代收敛",
      "authors": [
        "Washim Uddin Mondal",
        "Vaneet Aggarwal"
      ],
      "abstract": "We consider the problem of learning a Constrained Markov Decision Process\n(CMDP) via general parameterization. Our proposed Primal-Dual based Regularized\nAccelerated Natural Policy Gradient (PDR-ANPG) algorithm uses entropy and\nquadratic regularizers to reach this goal. For a parameterized policy class\nwith transferred compatibility approximation error, $\\epsilon_{\\mathrm{bias}}$,\nPDR-ANPG achieves a last-iterate $\\epsilon$ optimality gap and $\\epsilon$\nconstraint violation (up to some additive factor of $\\epsilon_{\\mathrm{bias}}$)\nwith a sample complexity of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-2}\\min\\{\\epsilon^{-2},\\epsilon_{\\mathrm{bias}}^{-\\frac{1}{3}}\\})$.\nIf the class is incomplete ($\\epsilon_{\\mathrm{bias}}>0$), then the sample\ncomplexity reduces to $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ for\n$\\epsilon<(\\epsilon_{\\mathrm{bias}})^{\\frac{1}{6}}$. Moreover, for complete\npolicies with $\\epsilon_{\\mathrm{bias}}=0$, our algorithm achieves a\nlast-iterate $\\epsilon$ optimality gap and $\\epsilon$ constraint violation with\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4})$ sample complexity. It is a significant\nimprovement of the state-of-the-art last-iterate guarantees of general\nparameterized CMDPs.",
      "tldr_zh": "本研究针对 Constrained MDPs (CMDP) 的参数化策略学习问题，提出了一种 Primal-Dual based Regularized Accelerated Natural Policy Gradient (PDR-ANPG) 算法，该算法结合 entropy 和 quadratic regularizers 来优化策略。针对具有 transferred compatibility approximation error ε_bias 的策略类，PDR-ANPG 实现了 last-iterate ε optimality gap 和 ε constraint violation，其样本复杂度为 Õ(ε^{-2} min{ε^{-2}, ε_bias^{-1/3}})；若策略类不完整（ε_bias > 0），则在 ε < (ε_bias)^{1/6} 时样本复杂度简化为 Õ(ε^{-2})。对于完整策略（ε_bias = 0），算法的样本复杂度进一步降低至 Õ(ε^{-4})，这显著改善了现有状态的最优 last-iterate 保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11513v1",
      "published_date": "2024-08-21 10:44:57 UTC",
      "updated_date": "2024-08-21 10:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:32:30.189627"
    },
    {
      "arxiv_id": "2408.11494v3",
      "title": "Mutagenesis screen to map the functions of parameters of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Hu",
        "Chengming Xu",
        "Jixin Zheng",
        "Patrick X. Zhao",
        "Javed Khan",
        "Ruimeng Wang"
      ],
      "abstract": "Large Language Models (LLMs) have significantly advanced artificial\nintelligence, excelling in numerous tasks. Although the functionality of a\nmodel is inherently tied to its parameters, a systematic method for exploring\nthe connections between the parameters and the functionality are lacking.\nModels sharing similar structure and parameter counts exhibit significant\nperformance disparities across various tasks, prompting investigations into the\nvarying patterns that govern their performance. We adopted a mutagenesis screen\napproach inspired by the methods used in biological studies, to investigate\nLlama2-7b and Zephyr. This technique involved mutating elements within the\nmodels' matrices to their maximum or minimum values to examine the relationship\nbetween model parameters and their functionalities. Our research uncovered\nmultiple levels of fine structures within both models. Many matrices showed a\nmixture of maximum and minimum mutations following mutagenesis, but others were\npredominantly sensitive to one type. Notably, mutations that produced\nphenotypes, especially those with severe outcomes, tended to cluster along\naxes. Additionally, the location of maximum and minimum mutations often\ndisplayed a complementary pattern on matrix in both models, with the Gate\nmatrix showing a unique two-dimensional asymmetry after rearrangement. In\nZephyr, certain mutations consistently resulted in poetic or conversational\nrather than descriptive outputs. These \"writer\" mutations grouped according to\nthe high-frequency initial word of the output, with a marked tendency to share\nthe row coordinate even when they are in different matrices. Our findings\naffirm that the mutagenesis screen is an effective tool for deciphering the\ncomplexities of large language models and identifying unexpected ways to expand\ntheir potential, providing deeper insights into the foundational aspects of AI\nsystems.",
      "tldr_zh": "本研究采用突变筛查(mutagenesis screen)方法，借鉴生物学技术，对Large Language Models(LLMs)如Llama2-7b和Zephyr进行参数突变（将矩阵元素设为最大或最小值），以系统探索模型参数与功能之间的关系。结果揭示了模型内部的多层次精细结构，许多矩阵对特定突变类型敏感，且突变导致的表型(phenotypes)往往沿轴聚集；在Zephyr中，某些突变会产生诗意或对话式输出，这些“writer”突变显示出坐标共享的模式。总体上，此方法为解密LLMs的复杂性并扩展其潜力提供了有效工具和深刻洞见。",
      "categories": [
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures, supplementary material available online",
      "pdf_url": "http://arxiv.org/pdf/2408.11494v3",
      "published_date": "2024-08-21 10:10:08 UTC",
      "updated_date": "2025-01-17 22:10:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:32:43.521702"
    },
    {
      "arxiv_id": "2408.11492v2",
      "title": "Estimating Peer Direct and Indirect Effects in Observational Network Data",
      "title_zh": "在观测网络数据中估计同伴直接和间接效应",
      "authors": [
        "Xiaojing Du",
        "Jiuyong Li",
        "Debo Cheng",
        "Lin Liu",
        "Wentao Gao",
        "Xiongren Chen"
      ],
      "abstract": "Estimating causal effects is crucial for decision-makers in many\napplications, but it is particularly challenging with observational network\ndata due to peer interactions. Many algorithms have been proposed to estimate\ncausal effects involving network data, particularly peer effects, but they\noften overlook the variety of peer effects. To address this issue, we propose a\ngeneral setting which considers both peer direct effects and peer indirect\neffects, and the effect of an individual's own treatment, and provide\nidentification conditions of these causal effects and proofs. To estimate these\ncausal effects, we utilize attention mechanisms to distinguish the influences\nof different neighbors and explore high-order neighbor effects through\nmulti-layer graph neural networks (GNNs). Additionally, to control the\ndependency between node features and representations, we incorporate the\nHilbert-Schmidt Independence Criterion (HSIC) into the GNN, fully utilizing the\nstructural information of the graph, to enhance the robustness and accuracy of\nthe model. Extensive experiments on two semi-synthetic datasets confirm the\neffectiveness of our approach. Our theoretical findings have the potential to\nimprove intervention strategies in networked systems, with applications in\nareas such as social networks and epidemiology.",
      "tldr_zh": "该论文探讨了在观察性网络数据中估计同行直接 effects、间接 effects 以及个体自身治疗效应的因果效应问题，提出一个通用设置并提供这些效应的识别条件和证明，以解决现有算法忽略同行效应多样性的局限性。方法上，利用注意力机制区分不同邻居的影响，通过多层图神经网络 (GNNs) 探索高阶邻居效应，并整合 Hilbert-Schmidt Independence Criterion (HSIC) 来控制节点特征与表示之间的依赖性，从而提升模型的鲁棒性和准确性。在两个半合成数据集上的广泛实验验证了方法的有效性，理论成果可应用于社交网络和流行病学等领域，优化干预策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11492v2",
      "published_date": "2024-08-21 10:02:05 UTC",
      "updated_date": "2024-09-13 05:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:32:54.919750"
    },
    {
      "arxiv_id": "2408.11491v2",
      "title": "SCANS: Mitigating the Exaggerated Safety for LLMs via Safety-Conscious Activation Steering",
      "title_zh": "翻译失败",
      "authors": [
        "Zouying Cao",
        "Yifei Yang",
        "Hai Zhao"
      ],
      "abstract": "Safety alignment is indispensable for Large Language Models (LLMs) to defend\nthreats from malicious instructions. However, recent researches reveal\nsafety-aligned LLMs prone to reject benign queries due to the exaggerated\nsafety issue, limiting their helpfulness. In this paper, we propose a\nSafety-Conscious Activation Steering (SCANS) method to mitigate the exaggerated\nsafety concerns in aligned LLMs. First, SCANS extracts the refusal steering\nvectors within the activation space and utilizes vocabulary projection to\nanchor some specific safety-critical layers which influence model refusal\nbehavior. Second, by tracking the hidden state transition, SCANS identifies the\nsteering direction and steers the model behavior accordingly, achieving a\nbalance between exaggerated safety and adequate safety. Experiments show that\nSCANS achieves new state-of-the-art performance on XSTest and OKTest\nbenchmarks, without impairing their defense capability against harmful queries\nand maintaining almost unchanged model capability.",
      "tldr_zh": "该研究针对安全对齐的大型语言模型(LLMs)存在的夸大安全问题，即过度拒绝良性查询，提出了一种Safety-Conscious Activation Steering (SCANS)方法来缓解这一问题。SCANS首先提取拒绝转向向量并通过词汇投影锚定安全关键层，然后通过跟踪隐藏状态转换来调整模型行为，实现安全性和帮助性的平衡。实验结果显示，SCANS在XSTest和OKTest基准上取得了新的最先进性能，同时不影响对有害查询的防御能力，并保持了模型的整体能力几乎不变。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of paper accepted to AAAI 2025. 14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11491v2",
      "published_date": "2024-08-21 10:01:34 UTC",
      "updated_date": "2024-12-17 13:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:33:06.835882"
    },
    {
      "arxiv_id": "2408.11455v2",
      "title": "Using Part-based Representations for Explainable Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Manos Kirtas",
        "Konstantinos Tsampazis",
        "Loukia Avramelou",
        "Nikolaos Passalis",
        "Anastasios Tefas"
      ],
      "abstract": "Utilizing deep learning models to learn part-based representations holds\nsignificant potential for interpretable-by-design approaches, as these models\nincorporate latent causes obtained from feature representations through simple\naddition. However, training a part-based learning model presents challenges,\nparticularly in enforcing non-negative constraints on the model's parameters,\nwhich can result in training difficulties such as instability and convergence\nissues. Moreover, applying such approaches in Deep Reinforcement Learning (RL)\nis even more demanding due to the inherent instabilities that impact many\noptimization methods. In this paper, we propose a non-negative training\napproach for actor models in RL, enabling the extraction of part-based\nrepresentations that enhance interpretability while adhering to non-negative\nconstraints. To this end, we employ a non-negative initialization technique, as\nwell as a modified sign-preserving training method, which can ensure better\ngradient flow compared to existing approaches. We demonstrate the effectiveness\nof the proposed approach using the well-known Cartpole benchmark.",
      "tldr_zh": "本论文探讨了使用基于部分的表示（part-based representations）来提升深度强化学习（Deep Reinforcement Learning）的可解释性，这些表示通过简单加法捕捉潜在原因。论文提出一种非负训练方法，针对强化学习的 actor 模型，采用非负初始化技术和修改后的 sign-preserving 训练方法，以克服参数非负约束带来的训练不稳定性和收敛问题。实验结果显示，该方法在 Cartpole 基准上有效，提高了模型的可解释性和训练稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11455v2",
      "published_date": "2024-08-21 09:21:59 UTC",
      "updated_date": "2024-08-22 05:46:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:33:17.615641"
    },
    {
      "arxiv_id": "2408.11451v4",
      "title": "SIGMA: Selective Gated Mamba for Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Liu",
        "Qidong Liu",
        "Yejing Wang",
        "Wanyu Wang",
        "Pengyue Jia",
        "Maolin Wang",
        "Zitao Liu",
        "Yi Chang",
        "Xiangyu Zhao"
      ],
      "abstract": "In various domains, Sequential Recommender Systems (SRS) have become\nessential due to their superior capability to discern intricate user\npreferences. Typically, SRS utilize transformer-based architectures to forecast\nthe subsequent item within a sequence. Nevertheless, the quadratic\ncomputational complexity inherent in these models often leads to\ninefficiencies, hindering the achievement of real-time recommendations. Mamba,\na recent advancement, has exhibited exceptional performance in time series\nprediction, significantly enhancing both efficiency and accuracy. However,\nintegrating Mamba directly into SRS poses several challenges. Its inherently\nunidirectional nature may constrain the model's capacity to capture the full\ncontext of user-item interactions, while its instability in state estimation\ncan compromise its ability to detect short-term patterns within interaction\nsequences.\n  To overcome these issues, we introduce a new framework named Selective Gated\nMamba (SIGMA) for Sequential Recommendation. This framework leverages a\nPartially Flipped Mamba (PF-Mamba) to construct a bidirectional architecture\nspecifically tailored to improve contextual modeling. Additionally, an\ninput-sensitive Dense Selective Gate (DS Gate) is employed to optimize\ndirectional weights and enhance the processing of sequential information in\nPF-Mamba. For short sequence modeling, we have also developed a Feature Extract\nGRU (FE-GRU) to efficiently capture short-term dependencies. Empirical results\nindicate that SIGMA outperforms current models on five real-world datasets. Our\nimplementation code is available at https://github.com/ziwliu-cityu/SIMGA to\nease reproducibility.",
      "tldr_zh": "该论文针对顺序推荐系统（Sequential Recommender Systems, SRS）的计算效率和上下文捕捉问题，提出了一种新型框架 SIGMA: Selective Gated Mamba。SIGMA 通过 Partially Flipped Mamba (PF-Mamba) 构建双向架构来提升用户交互的整体上下文建模，并引入 Dense Selective Gate (DS Gate) 和 Feature Extract GRU (FE-GRU) 来优化方向权重处理和短-term 依赖捕捉。实验结果显示，SIGMA 在五个真实数据集上优于现有模型，提供更高效的实时推荐性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11451v4",
      "published_date": "2024-08-21 09:12:59 UTC",
      "updated_date": "2024-12-24 17:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:33:30.843131"
    },
    {
      "arxiv_id": "2408.11449v2",
      "title": "Enabling Small Models for Zero-Shot Selection and Reuse through Model Label Learning",
      "title_zh": "通过模型标签学习启用小模型进行零样本选择和重",
      "authors": [
        "Jia Zhang",
        "Zhi Zhou",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "Vision-language models (VLMs) like CLIP have demonstrated impressive\nzero-shot ability in image classification tasks by aligning text and images but\nsuffer inferior performance compared with task-specific expert models. On the\ncontrary, expert models excel in their specialized domains but lack zero-shot\nability for new tasks. How to obtain both the high performance of expert models\nand zero-shot ability is an important research direction. In this paper, we\nattempt to demonstrate that by constructing a model hub and aligning models\nwith their functionalities using model labels, new tasks can be solved in a\nzero-shot manner by effectively selecting and reusing models in the hub. We\nintroduce a novel paradigm, Model Label Learning (MLL), which bridges the gap\nbetween models and their functionalities through a Semantic Directed Acyclic\nGraph (SDAG) and leverages an algorithm, Classification Head Combination\nOptimization (CHCO), to select capable models for new tasks. Compared with the\nfoundation model paradigm, it is less costly and more scalable, i.e., the\nzero-shot ability grows with the sizes of the model hub. Experiments on seven\nreal-world datasets validate the effectiveness and efficiency of MLL,\ndemonstrating that expert models can be effectively reused for zero-shot tasks.\nOur code will be released publicly.",
      "tldr_zh": "该论文探讨了如何让小型模型通过 Model Label Learning (MLL) 实现零样本 (Zero-Shot) 任务的模型选择和重用，旨在结合专家模型的高性能与零样本能力。MLL 范式通过构建模型库、使用 Semantic Directed Acyclic Graph (SDAG) 对模型功能进行对齐，并引入 Classification Head Combination Optimization (CHCO) 算法来有效选择和重用适合的新任务模型。这种方法比基础模型范式更低成本且更可扩展，因为零样本能力随模型库规模增长。在七个真实数据集上的实验验证了 MLL 的有效性和效率，证明专家模型可成功应用于零样本任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11449v2",
      "published_date": "2024-08-21 09:08:26 UTC",
      "updated_date": "2025-02-02 08:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:33:43.867081"
    },
    {
      "arxiv_id": "2408.11448v1",
      "title": "Lookism: The overlooked bias in computer vision",
      "title_zh": "Lookism：计算机视觉中被忽略的偏见",
      "authors": [
        "Aditya Gulati",
        "Bruno Lepri",
        "Nuria Oliver"
      ],
      "abstract": "In recent years, there have been significant advancements in computer vision\nwhich have led to the widespread deployment of image recognition and generation\nsystems in socially relevant applications, from hiring to security screening.\nHowever, the prevalence of biases within these systems has raised significant\nethical and social concerns. The most extensively studied biases in this\ncontext are related to gender, race and age. Yet, other biases are equally\npervasive and harmful, such as lookism, i.e., the preferential treatment of\nindividuals based on their physical appearance. Lookism remains under-explored\nin computer vision but can have profound implications not only by perpetuating\nharmful societal stereotypes but also by undermining the fairness and\ninclusivity of AI technologies. Thus, this paper advocates for the systematic\nstudy of lookism as a critical bias in computer vision models. Through a\ncomprehensive review of existing literature, we identify three areas of\nintersection between lookism and computer vision. We illustrate them by means\nof examples and a user study. We call for an interdisciplinary approach to\naddress lookism, urging researchers, developers, and policymakers to prioritize\nthe development of equitable computer vision systems that respect and reflect\nthe diversity of human appearances.",
      "tldr_zh": "这篇论文探讨了计算机视觉领域中被忽视的外貌主义（lookism）偏见，即基于个人外貌的偏好对待，这可能加剧社会刻板印象并损害AI的公平性。作者通过文献综述，识别了外貌主义与计算机视觉的三个关键交集领域，并通过例子和用户研究进行说明。论文呼吁采用跨学科方法，由研究者、开发者和政策制定者共同推动开发尊重人类多样性的公平计算机视觉系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "I.2.0; I.4.0; K.4.2"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted at the ECCV 2024 workshop named \"Fairness and ethics\n  towards transparent AI: facing the chalLEnge through model Debiasing\n  (FAILED)\", https://failed-workshop-eccv-2024.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2408.11448v1",
      "published_date": "2024-08-21 09:07:20 UTC",
      "updated_date": "2024-08-21 09:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:33:55.226142"
    },
    {
      "arxiv_id": "2408.11441v1",
      "title": "Epistemic Injustice in Generative AI",
      "title_zh": "生成式人工智能中的认识论不公",
      "authors": [
        "Jackie Kay",
        "Atoosa Kasirzadeh",
        "Shakir Mohamed"
      ],
      "abstract": "This paper investigates how generative AI can potentially undermine the\nintegrity of collective knowledge and the processes we rely on to acquire,\nassess, and trust information, posing a significant threat to our knowledge\necosystem and democratic discourse. Grounded in social and political\nphilosophy, we introduce the concept of \\emph{generative algorithmic epistemic\ninjustice}. We identify four key dimensions of this phenomenon: amplified and\nmanipulative testimonial injustice, along with hermeneutical ignorance and\naccess injustice. We illustrate each dimension with real-world examples that\nreveal how generative AI can produce or amplify misinformation, perpetuate\nrepresentational harm, and create epistemic inequities, particularly in\nmultilingual contexts. By highlighting these injustices, we aim to inform the\ndevelopment of epistemically just generative AI systems, proposing strategies\nfor resistance, system design principles, and two approaches that leverage\ngenerative AI to foster a more equitable information ecosystem, thereby\nsafeguarding democratic values and the integrity of knowledge production.",
      "tldr_zh": "这篇论文探讨了生成式 AI 如何破坏集体知识的完整性，并威胁到获取、评估和信任信息的进程，引入了“generative algorithmic epistemic injustice”（生成式算法认识论不公）概念。论文基于社会和政治哲学，识别了四个关键维度：amplified and manipulative testimonial injustice（放大的和操纵性的证言不公）、hermeneutical ignorance（解释学无知）和access injustice（访问不公），并通过真实世界例子说明这些问题如何放大 misinformation（错误信息）、perpetuate representational harm（ perpetuates 代表性伤害），并在多语种环境中制造 epistemic inequities（认识论不平等）。最终，论文提出抵抗策略、系统设计原则以及两种利用生成式 AI 的方法，以推动 epistemically just（认识论公正）的 AI 系统，保护民主价值观和知识生产的完整性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11441v1",
      "published_date": "2024-08-21 08:51:05 UTC",
      "updated_date": "2024-08-21 08:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:34:08.741913"
    },
    {
      "arxiv_id": "2408.11433v2",
      "title": "Towards Aligned Data Removal via Twin Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxuan Ji",
        "Zheng Lin",
        "Yuyao Sun",
        "Gao Fei",
        "Yuhang Wang",
        "Haichang Gao",
        "Zhenxing Niu"
      ],
      "abstract": "Modern privacy regulations have spurred the evolution of machine unlearning,\na technique that enables the removal of data from an already trained ML model\nwithout requiring retraining from scratch. Previous unlearning methods tend to\ninduce the model to achieve lowest classification accuracy on the removal data.\nNonetheless, the authentic objective of machine unlearning is to align the\nunlearned model with the gold model, i.e., achieving the same classification\naccuracy as the gold model. For this purpose, we present a Twin Machine\nUnlearning (TMU) approach, where a twin unlearning problem is defined\ncorresponding to the original unlearning problem. As a results, the\ngeneralization-label predictor trained on the twin problem can be transferred\nto the original problem, facilitating aligned data removal. Comprehensive\nempirical experiments illustrate that our approach significantly enhances the\nalignment between the unlearned model and the gold model. Meanwhile, our method\nallows data removal without compromising the model accuracy.",
      "tldr_zh": "该研究针对机器无学习（machine unlearning）技术的不足，提出了一种Twin Machine Unlearning (TMU)方法，以实现模型与“gold model”的准确率对齐，而不是仅降低移除数据上的分类准确率。TMU通过定义一个与原问题对应的孪生问题，并在孪生问题上训练的泛化标签预测器转移到原问题，从而促进数据移除时的模型对齐。实验结果表明，该方法显著提升了无学习模型与gold model的相似度，同时保持了模型的整体准确率，避免了性能损失。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11433v2",
      "published_date": "2024-08-21 08:42:21 UTC",
      "updated_date": "2025-05-02 08:12:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:34:18.150900"
    },
    {
      "arxiv_id": "2408.11431v1",
      "title": "Diagnosing and Remedying Knowledge Deficiencies in LLMs via Label-free Curricular Meaningful Learning",
      "title_zh": "通过无标签课程式有意义学习诊断和修复 LLMs 中的知识缺陷",
      "authors": [
        "Kai Xiong",
        "Xiao Ding",
        "Li Du",
        "Jiahao Ying",
        "Ting Liu",
        "Bing Qin",
        "Yixin Cao"
      ],
      "abstract": "Large Language Models (LLMs) are versatile and demonstrate impressive\ngeneralization ability by mining and learning information from extensive\nunlabeled text. However, they still exhibit reasoning mistakes, often stemming\nfrom knowledge deficiencies, which can affect their trustworthiness and\nreliability. Although users can provide diverse and comprehensive queries,\nobtaining sufficient and effective feedback is demanding. Furthermore,\nevaluating LLMs comprehensively with limited labeled samples is difficult. This\nmakes it a challenge to diagnose and remedy the deficiencies of LLMs through\nrich label-free user queries. To tackle this challenge, we propose a label-free\ncurricular meaningful learning framework (LaMer). LaMer first employs relative\nentropy to automatically diagnose and quantify the knowledge deficiencies of\nLLMs in a label-free setting. Next, to remedy the diagnosed knowledge\ndeficiencies, we apply curricular meaningful learning: first, we adopt\nmeaningful learning to adaptively synthesize augmentation data according to the\nseverity of the deficiencies, and then design a curricular deficiency remedy\nstrategy to remedy the knowledge deficiencies of LLMs progressively.\nExperiments show that LaMer efficiently and effectively diagnoses and remedies\nknowledge deficiencies in LLMs, improving various LLMs across seven\nout-of-distribution (OOD) reasoning and language understanding benchmarks,\nachieving comparable results to baselines with just 40\\% training data. LaMer\neven surpasses methods that rely on labeled datasets for deficiency diagnosis.\nIn application, our label-free method can offer an effective knowledge\ndeficiency diagnostic tool for efficient LLM development.",
      "tldr_zh": "该论文提出 LaMer 框架，用于诊断和修复大型语言模型（LLMs）的知识缺陷，而不依赖标签数据。LaMer 首先利用 relative entropy 自动量化 LLMs 的知识不足，然后通过 curricular meaningful learning 适应性合成增强数据，并设计课程式策略逐步修复缺陷。实验结果表明，该框架仅用 40% 的训练数据就显著提升了各种 LLMs 在七个 out-of-distribution (OOD) 推理和语言理解基准上的性能，甚至超越依赖标签数据集的基线方法，为高效的 LLM 开发提供了一个有效的诊断工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2408.11431v1",
      "published_date": "2024-08-21 08:39:49 UTC",
      "updated_date": "2024-08-21 08:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:34:31.689221"
    },
    {
      "arxiv_id": "2408.11429v1",
      "title": "Long-Range Vision-Based UAV-assisted Localization for Unmanned Surface Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Waseem Akram",
        "Siyuan Yang",
        "Hailiang Kuang",
        "Xiaoyu He",
        "Muhayy Ud Din",
        "Yihao Dong",
        "Defu Lin",
        "Lakmal Seneviratne",
        "Shaoming He",
        "Irfan Hussain"
      ],
      "abstract": "The global positioning system (GPS) has become an indispensable navigation\nmethod for field operations with unmanned surface vehicles (USVs) in marine\nenvironments. However, GPS may not always be available outdoors because it is\nvulnerable to natural interference and malicious jamming attacks. Thus, an\nalternative navigation system is required when the use of GPS is restricted or\nprohibited. To this end, we present a novel method that utilizes an Unmanned\nAerial Vehicle (UAV) to assist in localizing USVs in GNSS-restricted marine\nenvironments. In our approach, the UAV flies along the shoreline at a\nconsistent altitude, continuously tracking and detecting the USV using a deep\nlearning-based approach on camera images. Subsequently, triangulation\ntechniques are applied to estimate the USV's position relative to the UAV,\nutilizing geometric information and datalink range from the UAV. We propose\nadjusting the UAV's camera angle based on the pixel error between the USV and\nthe image center throughout the localization process to enhance accuracy.\nAdditionally, visual measurements are integrated into an Extended Kalman Filter\n(EKF) for robust state estimation. To validate our proposed method, we utilize\na USV equipped with onboard sensors and a UAV equipped with a camera. A\nheterogeneous robotic interface is established to facilitate communication\nbetween the USV and UAV. We demonstrate the efficacy of our approach through a\nseries of experiments conducted during the ``Muhammad Bin Zayed International\nRobotic Challenge (MBZIRC-2024)'' in real marine environments, incorporating\nnoisy measurements and ocean disturbances. The successful outcomes indicate the\npotential of our method to complement GPS for USV navigation.",
      "tldr_zh": "这篇论文提出了一种基于视觉的 UAV 辅助定位方法，用于在 GPS 受限的海洋环境中定位 Unmanned Surface Vehicles (USV)，以应对干扰和攻击问题。方法包括 UAV 沿岸线飞行，使用深度学习算法检测 USV，并结合三角测量、几何信息和数据链路范围估计 USV 位置，同时通过调整 UAV 相机角度和整合 Extended Kalman Filter (EKF) 进行鲁棒状态估计。实验在 MBZIRC-2024 真实海洋环境中进行，证明该方法能有效处理噪声和海洋干扰，提高定位准确性，并作为 GPS 的可靠补充。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11429v1",
      "published_date": "2024-08-21 08:37:37 UTC",
      "updated_date": "2024-08-21 08:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:34:44.464038"
    },
    {
      "arxiv_id": "2408.11415v1",
      "title": "Towards \"Differential AI Psychology\" and in-context Value-driven Statement Alignment with Moral Foundations Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Münker"
      ],
      "abstract": "Contemporary research in social sciences is increasingly utilizing\nstate-of-the-art statistical language models to annotate or generate content.\nWhile these models perform benchmark-leading on common language tasks and show\nexemplary task-independent emergent abilities, transferring them to novel\nout-of-domain tasks is only insufficiently explored. The implications of the\nstatistical black-box approach - stochastic parrots - are prominently\ncriticized in the language model research community; however, the significance\nfor novel generative tasks is not.\n  This work investigates the alignment between personalized language models and\nsurvey participants on a Moral Foundation Theory questionnaire. We adapt\ntext-to-text models to different political personas and survey the\nquestionnaire repetitively to generate a synthetic population of persona and\nmodel combinations. Analyzing the intra-group variance and cross-alignment\nshows significant differences across models and personas. Our findings indicate\nthat adapted models struggle to represent the survey-captured assessment of\npolitical ideologies. Thus, using language models to mimic social interactions\nrequires measurable improvements in in-context optimization or parameter\nmanipulation to align with psychological and sociological stereotypes. Without\nquantifiable alignment, generating politically nuanced content remains\nunfeasible. To enhance these representations, we propose a testable framework\nto generate agents based on moral value statements for future research.",
      "tldr_zh": "本文探讨了“Differential AI Psychology”和基于“Moral Foundations Theory”的语句对齐问题，旨在评估语言模型在模拟社会互动时的表现。研究方法包括将文本到文本模型适应不同政治人物，生成合成人群并分析其与调查参与者的跨对齐差异。结果表明，适应后的模型难以准确代表政治意识形态，需要通过in-context optimization或参数调整来提升对齐；为此，作者提出一个可测试框架，用于基于道德价值语句生成代理，以推动未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.11415v1",
      "published_date": "2024-08-21 08:20:41 UTC",
      "updated_date": "2024-08-21 08:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:34:56.414168"
    },
    {
      "arxiv_id": "2408.11401v1",
      "title": "Revisiting FunnyBirds evaluation framework for prototypical parts networks",
      "title_zh": "翻译失败",
      "authors": [
        "Szymon Opłatek",
        "Dawid Rymarczyk",
        "Bartosz Zieliński"
      ],
      "abstract": "Prototypical parts networks, such as ProtoPNet, became popular due to their\npotential to produce more genuine explanations than post-hoc methods. However,\nfor a long time, this potential has been strictly theoretical, and no\nsystematic studies have existed to support it. That changed recently with the\nintroduction of the FunnyBirds benchmark, which includes metrics for evaluating\ndifferent aspects of explanations.\n  However, this benchmark employs attribution maps visualization for all\nexplanation techniques except for the ProtoPNet, for which the bounding boxes\nare used. This choice significantly influences the metric scores and questions\nthe conclusions stated in FunnyBirds publication.\n  In this study, we comprehensively compare metric scores obtained for two\ntypes of ProtoPNet visualizations: bounding boxes and similarity maps. Our\nanalysis indicates that employing similarity maps aligns better with the\nessence of ProtoPNet, as evidenced by different metric scores obtained from\nFunnyBirds. Therefore, we advocate using similarity maps as a visualization\ntechnique for prototypical parts networks in explainability evaluation\nbenchmarks.",
      "tldr_zh": "这篇论文重新审视了 FunnyBirds 评估框架，针对 Prototypical parts networks（如 ProtoPNet）的解释可视化问题。研究者比较了 ProtoPNet 的两种可视化技术：bounding boxes 和 similarity maps，发现使用 similarity maps 与 ProtoPNet 的本质更一致，导致 FunnyBirds 指标分数出现显著差异。结果表明，之前 FunnyBirds 框架的 bounding boxes 选择可能扭曲了结论，因此作者主张在解释性评估基准中采用 similarity maps 以获得更准确的评估。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at 2nd XAI World Conference",
      "pdf_url": "http://arxiv.org/pdf/2408.11401v1",
      "published_date": "2024-08-21 07:58:34 UTC",
      "updated_date": "2024-08-21 07:58:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:35:07.870170"
    },
    {
      "arxiv_id": "2408.11384v1",
      "title": "Data-Centric Machine Learning for Earth Observation: Necessary and Sufficient Features",
      "title_zh": "翻译失败",
      "authors": [
        "Hiba Najjar",
        "Marlon Nuske",
        "Andreas Dengel"
      ],
      "abstract": "The availability of temporal geospatial data in multiple modalities has been\nextensively leveraged to enhance the performance of machine learning models.\nWhile efforts on the design of adequate model architectures are approaching a\nlevel of saturation, focusing on a data-centric perspective can complement\nthese efforts to achieve further enhancements in data usage efficiency and\nmodel generalization capacities. This work contributes to this direction. We\nleverage model explanation methods to identify the features crucial for the\nmodel to reach optimal performance and the smallest set of features sufficient\nto achieve this performance. We evaluate our approach on three temporal\nmultimodal geospatial datasets and compare multiple model explanation\ntechniques. Our results reveal that some datasets can reach their optimal\naccuracy with less than 20% of the temporal instances, while in other datasets,\nthe time series of a single band from a single modality is sufficient.",
      "tldr_zh": "这篇论文探讨了数据中心机器学习（Data-Centric Machine Learning）在地球观测（Earth Observation）领域的应用，旨在通过模型解释方法（model explanation methods）识别机器学习模型达到最优性能所需的关键特征和最小特征集。作者在三个temporal multimodal geospatial datasets上评估了多种模型解释技术，结果表明某些数据集只需不到20%的temporal instances即可实现最优准确率。总体上，这方法提升了数据使用效率和模型泛化能力，为高效处理多模态时空数据提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at MACLEAN workshop, ECML/PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11384v1",
      "published_date": "2024-08-21 07:26:43 UTC",
      "updated_date": "2024-08-21 07:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:35:19.801049"
    },
    {
      "arxiv_id": "2408.11380v1",
      "title": "Reflex-Based Open-Vocabulary Navigation without Prior Knowledge Using Omnidirectional Camera and Multiple Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kento Kawaharazuka",
        "Yoshiki Obinata",
        "Naoaki Kanazawa",
        "Naoto Tsukamoto",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "Various robot navigation methods have been developed, but they are mainly\nbased on Simultaneous Localization and Mapping (SLAM), reinforcement learning,\netc., which require prior map construction or learning. In this study, we\nconsider the simplest method that does not require any map construction or\nlearning, and execute open-vocabulary navigation of robots without any prior\nknowledge to do this. We applied an omnidirectional camera and pre-trained\nvision-language models to the robot. The omnidirectional camera provides a\nuniform view of the surroundings, thus eliminating the need for complicated\nexploratory behaviors including trajectory generation. By applying multiple\npre-trained vision-language models to this omnidirectional image and\nincorporating reflective behaviors, we show that navigation becomes simple and\ndoes not require any prior setup. Interesting properties and limitations of our\nmethod are discussed based on experiments with the mobile robot Fetch.",
      "tldr_zh": "本研究提出了一种基于反射行为的开放词汇导航方法，不依赖于先验地图构建或学习（如 Simultaneous Localization and Mapping (SLAM)），从而简化机器人导航过程。该方法利用全向相机（omnidirectional camera）提供周围环境的均匀视图，避免复杂的探索轨迹生成，并结合多个预训练的 vision-language models 对图像进行处理，以实现无需预设知识的导航。实验在 Fetch 移动机器人上验证了该方法的特性，包括其简单性和潜在局限性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at Advanced Robotics, website -\n  https://haraduka.github.io/omnidirectional-vlm/",
      "pdf_url": "http://arxiv.org/pdf/2408.11380v1",
      "published_date": "2024-08-21 07:18:58 UTC",
      "updated_date": "2024-08-21 07:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:35:32.665826"
    },
    {
      "arxiv_id": "2408.11372v1",
      "title": "Denoising Pre-Training and Customized Prompt Learning for Efficient Multi-Behavior Sequential Recommendation",
      "title_zh": "用于高效多行为序列推荐的去噪预训练和自定义提示学习",
      "authors": [
        "Hao Wang",
        "Yongqiang Han",
        "Kefan Wang",
        "Kai Cheng",
        "Zhen Wang",
        "Wei Guo",
        "Yong Liu",
        "Defu Lian",
        "Enhong Chen"
      ],
      "abstract": "In the realm of recommendation systems, users exhibit a diverse array of\nbehaviors when interacting with items. This phenomenon has spurred research\ninto learning the implicit semantic relationships between these behaviors to\nenhance recommendation performance. However, these methods often entail high\ncomputational complexity. To address concerns regarding efficiency,\npre-training presents a viable solution. Its objective is to extract knowledge\nfrom extensive pre-training data and fine-tune the model for downstream tasks.\nNevertheless, previous pre-training methods have primarily focused on\nsingle-behavior data, while multi-behavior data contains significant noise.\nAdditionally, the fully fine-tuning strategy adopted by these methods still\nimposes a considerable computational burden. In response to this challenge, we\npropose DPCPL, the first pre-training and prompt-tuning paradigm tailored for\nMulti-Behavior Sequential Recommendation. Specifically, in the pre-training\nstage, we commence by proposing a novel Efficient Behavior Miner (EBM) to\nfilter out the noise at multiple time scales, thereby facilitating the\ncomprehension of the contextual semantics of multi-behavior sequences.\nSubsequently, we propose to tune the pre-trained model in a highly efficient\nmanner with the proposed Customized Prompt Learning (CPL) module, which\ngenerates personalized, progressive, and diverse prompts to fully exploit the\npotential of the pre-trained model effectively. Extensive experiments on three\nreal-world datasets have unequivocally demonstrated that DPCPL not only\nexhibits high efficiency and effectiveness, requiring minimal parameter\nadjustments but also surpasses the state-of-the-art performance across a\ndiverse range of downstream tasks.",
      "tldr_zh": "本论文提出DPCPL框架，这是首个针对多行为序列推荐(Multi-Behavior Sequential Recommendation)的预训练和提示调整范式，旨在解决多行为数据中的噪音问题并提升计算效率。在预训练阶段，引入Efficient Behavior Miner (EBM)模块在多个时间尺度过滤噪音，以更好地理解多行为序列的上下文语义；随后，在微调阶段，使用Customized Prompt Learning (CPL)模块生成个性化的、渐进的和多样的提示，从而高效利用预训练模型。实验在三个真实数据集上证明，DPCPL只需最小参数调整即可超越现有最先进方法，在效率和性能上表现出色。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11372v1",
      "published_date": "2024-08-21 06:48:38 UTC",
      "updated_date": "2024-08-21 06:48:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:35:44.939850"
    },
    {
      "arxiv_id": "2408.11371v1",
      "title": "Solving Decision Theory Problems with Probabilistic Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Damiano Azzolini",
        "Elena Bellodi",
        "Rafael Kiesel",
        "Fabrizio Riguzzi"
      ],
      "abstract": "Solving a decision theory problem usually involves finding the actions, among\na set of possible ones, which optimize the expected reward, possibly accounting\nfor the uncertainty of the environment. In this paper, we introduce the\npossibility to encode decision theory problems with Probabilistic Answer Set\nProgramming under the credal semantics via decision atoms and utility\nattributes. To solve the task we propose an algorithm based on three layers of\nAlgebraic Model Counting, that we test on several synthetic datasets against an\nalgorithm that adopts answer set enumeration. Empirical results show that our\nalgorithm can manage non trivial instances of programs in a reasonable amount\nof time. Under consideration in Theory and Practice of Logic Programming\n(TPLP).",
      "tldr_zh": "本论文提出了一种使用 Probabilistic Answer Set Programming 在 credal semantics 下编码决策理论问题的方法，通过 decision atoms 和 utility attributes 来优化预期奖励并处理环境不确定性。作者开发了一种基于三层 Algebraic Model Counting 的算法，并与基于 answer set enumeration 的方法在合成数据集上进行了比较。实验结果显示，该算法能够高效处理非平凡实例，在合理时间内表现出色。该研究正在 Theory and Practice of Logic Programming (TPLP) 审稿中。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2408.11371v1",
      "published_date": "2024-08-21 06:44:16 UTC",
      "updated_date": "2024-08-21 06:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:35:56.212703"
    },
    {
      "arxiv_id": "2408.11370v1",
      "title": "Graph Classification via Reference Distribution Learning: Theory and Practice",
      "title_zh": "通过参考分布学习的图分类：理论与实践",
      "authors": [
        "Zixiao Wang",
        "Jicong Fan"
      ],
      "abstract": "Graph classification is a challenging problem owing to the difficulty in\nquantifying the similarity between graphs or representing graphs as vectors,\nthough there have been a few methods using graph kernels or graph neural\nnetworks (GNNs). Graph kernels often suffer from computational costs and manual\nfeature engineering, while GNNs commonly utilize global pooling operations,\nrisking the loss of structural or semantic information. This work introduces\nGraph Reference Distribution Learning (GRDL), an efficient and accurate graph\nclassification method. GRDL treats each graph's latent node embeddings given by\nGNN layers as a discrete distribution, enabling direct classification without\nglobal pooling, based on maximum mean discrepancy to adaptively learned\nreference distributions. To fully understand this new model (the existing\ntheories do not apply) and guide its configuration (e.g., network architecture,\nreferences' sizes, number, and regularization) for practical use, we derive\ngeneralization error bounds for GRDL and verify them numerically. More\nimportantly, our theoretical and numerical results both show that GRDL has a\nstronger generalization ability than GNNs with global pooling operations.\nExperiments on moderate-scale and large-scale graph datasets show the\nsuperiority of GRDL over the state-of-the-art, emphasizing its remarkable\nefficiency, being at least 10 times faster than leading competitors in both\ntraining and inference stages.",
      "tldr_zh": "本研究提出了一种高效准确的图分类方法Graph Reference Distribution Learning (GRDL)，通过将图的潜在节点嵌入视为离散分布，并利用最大均值差异(maximum mean discrepancy)与自适应学习的参考分布进行分类，从而避免了传统Graph Neural Networks (GNNs)的全局池化操作导致的信息丢失。论文推导了GRDL的泛化错误边界，并通过数值验证证明其泛化能力强于使用全局池化的GNNs。实验结果显示，GRDL在中等规模和大规模图数据集上优于最先进方法，且在训练和推理阶段至少快10倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11370v1",
      "published_date": "2024-08-21 06:42:22 UTC",
      "updated_date": "2024-08-21 06:42:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:36:08.329570"
    },
    {
      "arxiv_id": "2408.11367v2",
      "title": "Towards Probabilistic Inductive Logic Programming with Neurosymbolic Inference and Relaxation",
      "title_zh": "翻译失败",
      "authors": [
        "Fieke Hillerstrom",
        "Gertjan Burghouts"
      ],
      "abstract": "Many inductive logic programming (ILP) methods are incapable of learning\nprograms from probabilistic background knowledge, e.g. coming from sensory data\nor neural networks with probabilities. We propose Propper, which handles flawed\nand probabilistic background knowledge by extending ILP with a combination of\nneurosymbolic inference, a continuous criterion for hypothesis selection (BCE)\nand a relaxation of the hypothesis constrainer (NoisyCombo). For relational\npatterns in noisy images, Propper can learn programs from as few as 8 examples.\nIt outperforms binary ILP and statistical models such as a Graph Neural\nNetwork.",
      "tldr_zh": "该研究针对归纳逻辑编程 (ILP) 方法无法处理概率背景知识（如传感器数据或神经网络概率）的局限性，提出 Propper 框架，通过结合 neurosymbolic inference、假设选择标准 (BCE) 和假设约束松弛 (NoisyCombo)，实现对不完善概率知识的学习。Propper 能在嘈杂图像中的关系模式上，从仅 8 个例子中有效学习程序。实验结果显示，它优于二元 ILP 和统计模型如 Graph Neural Network，在处理噪声数据方面表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.11367v2",
      "published_date": "2024-08-21 06:38:49 UTC",
      "updated_date": "2024-09-20 13:28:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:36:29.931799"
    },
    {
      "arxiv_id": "2408.11363v2",
      "title": "ProteinGPT: Multimodal LLM for Protein Property Prediction and Structure Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yijia Xiao",
        "Edward Sun",
        "Yiqiao Jin",
        "Qifan Wang",
        "Wei Wang"
      ],
      "abstract": "Understanding biological processes, drug development, and biotechnological\nadvancements requires a detailed analysis of protein structures and functions,\na task that is inherently complex and time-consuming in traditional protein\nresearch. To streamline this process, we introduce ProteinGPT, a\nstate-of-the-art multimodal large language model for proteins that enables\nusers to upload protein sequences and/or structures for comprehensive analysis\nand responsive inquiries. ProteinGPT integrates protein sequence and structure\nencoders with linear projection layers to ensure precise representation\nadaptation and leverages a large language model (LLM) to generate accurate,\ncontextually relevant responses. To train ProteinGPT, we constructed a\nlarge-scale dataset of 132,092 proteins, each annotated with 20-30 property\ntags and 5-10 QA pairs per protein, and optimized the instruction-tuning\nprocess using GPT-4o. Experiments demonstrate that ProteinGPT effectively\ngenerates informative responses to protein-related questions, achieving high\nperformance on both semantic and lexical metrics and significantly\noutperforming baseline models and general-purpose LLMs in understanding and\nresponding to protein-related queries. Our code and data are available at\nhttps://github.com/ProteinGPT/ProteinGPT.",
      "tldr_zh": "本文提出 ProteinGPT，一种多模态 LLM，用于简化蛋白质属性预测和结构理解，允许用户上传蛋白质 sequences 和/或 structures 以进行全面分析和响应查询。该模型整合蛋白质 sequence 和 structure 编码器，通过线性投影层适应表示，并利用 LLM 生成准确的上下文相关响应，同时基于一个包含 132,092 个蛋白质的庞大数据集进行 instruction-tuning 优化。实验结果表明，ProteinGPT 在语义和词汇指标上表现出色，显著优于基线模型和通用 LLM，在蛋白质相关问题上提供高性能的响应。代码和数据已在 GitHub 上公开。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "Spotlight, Machine Learning for Genomics Explorations @ ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2408.11363v2",
      "published_date": "2024-08-21 06:16:22 UTC",
      "updated_date": "2025-04-17 21:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:36:32.977126"
    },
    {
      "arxiv_id": "2408.11359v1",
      "title": "Hypergraph Learning based Recommender System for Anomaly Detection, Control and Optimization",
      "title_zh": "基于超图学习的异常检测、控制和优化推荐系统",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Rajat Kumar Sarkar",
        "Venkataramana Runkana"
      ],
      "abstract": "Anomaly detection is fundamental yet, challenging problem with practical\napplications in industry. The current approaches neglect the higher-order\ndependencies within the networks of interconnected sensors in the\nhigh-dimensional time series(multisensor data) for anomaly detection. To this\nend, we present a self-adapting anomaly detection framework for joint learning\nof (a) discrete hypergraph structure and (b) modeling the temporal trends and\nspatial relations among the interdependent sensors using the hierarchical\nencoder-decoder architecture to overcome the challenges. The hypergraph\nrepresentation learning-based framework exploits the relational inductive\nbiases in the hypergraph-structured data to learn the pointwise\nsingle-step-ahead forecasts through the self-supervised autoregressive task and\npredicts the anomalies based on the forecast error. Furthermore, our framework\nincentivizes learning the anomaly-diagnosis ontology through a differentiable\napproach. It derives the anomaly information propagation-based computational\nhypergraphs for root cause analysis and provides recommendations through an\noffline, optimal predictive control policy to remedy an anomaly. We conduct\nextensive experiments to evaluate the proposed method on the benchmark datasets\nfor fair and rigorous comparison with the popular baselines. The proposed\nmethod outperforms the baseline models and achieves SOTA performance. We report\nthe ablation studies to support the efficacy of the framework.",
      "tldr_zh": "本论文提出了一种基于Hypergraph Learning的推荐系统框架，用于异常检测、控制和优化，旨在解决多传感器高维时间序列中高阶依赖关系的忽略问题。该框架通过联合学习离散的超图结构和分层编码器-解码器架构，来建模传感器之间的时间趋势和空间关系，并利用自监督的自回归任务进行点-wise 单步预测，以基于预测错误检测异常。同时，框架引入可微分方法学习异常诊断本体，支持根因分析和通过离线最优预测控制策略提供修复推荐。实验结果显示，该方法在基准数据集上优于基线模型，实现了SOTA性能，并通过消融研究验证了框架的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 10 figure, Accepted at IEEE International Conference on Big\n  Data 2022, Osaka, Japan",
      "pdf_url": "http://arxiv.org/pdf/2408.11359v1",
      "published_date": "2024-08-21 06:04:02 UTC",
      "updated_date": "2024-08-21 06:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:36:48.513036"
    },
    {
      "arxiv_id": "2408.11356v1",
      "title": "One-step Structure Prediction and Screening for Protein-Ligand Complexes using Multi-Task Geometric Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kelei He",
        "Tiejun Dong",
        "Jinhui Wu",
        "Junfeng Zhang"
      ],
      "abstract": "Understanding the structure of the protein-ligand complex is crucial to drug\ndevelopment. Existing virtual structure measurement and screening methods are\ndominated by docking and its derived methods combined with deep learning.\nHowever, the sampling and scoring methodology have largely restricted the\naccuracy and efficiency. Here, we show that these two fundamental tasks can be\naccurately tackled with a single model, namely LigPose, based on multi-task\ngeometric deep learning. By representing the ligand and the protein pair as a\ngraph, LigPose directly optimizes the three-dimensional structure of the\ncomplex, with the learning of binding strength and atomic interactions as\nauxiliary tasks, enabling its one-step prediction ability without docking\ntools. Extensive experiments show LigPose achieved state-of-the-art performance\non major tasks in drug research. Its considerable improvements indicate a\npromising paradigm of AI-based pipeline for drug development.",
      "tldr_zh": "本文提出LigPose，一种基于multi-task geometric deep learning的单模型方法，用于蛋白质-配体复合物的结构预测和筛选，解决了传统docking方法在准确性和效率上的局限。LigPose将配体和蛋白质对表示为graph，直接优化三维结构，并通过学习结合强度和原子相互作用作为辅助任务，实现无需docking工具的一步预测。实验结果显示，LigPose在药物研究的主要任务上达到了最先进性能，并为AI驱动的药物开发管道提供了有前景的新范式。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11356v1",
      "published_date": "2024-08-21 05:53:50 UTC",
      "updated_date": "2024-08-21 05:53:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:37:08.755172"
    },
    {
      "arxiv_id": "2408.11351v1",
      "title": "Vision HgNN: An Electron-Micrograph is Worth Hypergraph of Hypernodes",
      "title_zh": "翻译失败",
      "authors": [
        "Sakhinana Sagar Srinivas",
        "Rajat Kumar Sarkar",
        "Sreeja Gangasani",
        "Venkataramana Runkana"
      ],
      "abstract": "Material characterization using electron micrographs is a crucial but\nchallenging task with applications in various fields, such as semiconductors,\nquantum materials, batteries, etc. The challenges in categorizing electron\nmicrographs include but are not limited to the complexity of patterns, high\nlevel of detail, and imbalanced data distribution(long-tail distribution).\nExisting methods have difficulty in modeling the complex relational structure\nin electron micrographs, hindering their ability to effectively capture the\ncomplex relationships between different spatial regions of micrographs. We\npropose a hypergraph neural network(HgNN) backbone architecture, a conceptually\nalternative approach, to better model the complex relationships in electron\nmicrographs and improve material characterization accuracy. By utilizing\ncost-effective GPU hardware, our proposed framework outperforms popular\nbaselines. The results of the ablation studies demonstrate that the proposed\nframework is effective in achieving state-of-the-art performance on benchmark\ndatasets and efficient in terms of computational and memory requirements for\nhandling large-scale electron micrograph-based datasets.",
      "tldr_zh": "电子显微镜照片的材料表征任务面临图案复杂、细节丰富和数据分布不均衡等挑战，现有的方法难以有效捕捉照片中不同空间区域的复杂关系。研究提出Vision HgNN框架，使用Hypergraph Neural Network (HgNN)作为骨干架构，通过建模超图（hypergraph of hypernodes）来更好地表示这些关系，从而提高材料表征准确性。该框架在基准数据集上优于流行基线模型，并在计算和内存需求上更高效，证明了其在处理大规模电子显微镜数据集时的先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, Accepted in PML4DC Workshop at International Conference on\n  Learning Representations (ICLR) 2023",
      "pdf_url": "http://arxiv.org/pdf/2408.11351v1",
      "published_date": "2024-08-21 05:36:53 UTC",
      "updated_date": "2024-08-21 05:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:37:19.978297"
    },
    {
      "arxiv_id": "2408.11347v2",
      "title": "Multimodal Datasets and Benchmarks for Reasoning about Dynamic Spatio-Temporality in Everyday Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Takanori Ugai",
        "Kensho Hara",
        "Shusaku Egami",
        "Ken Fukuda"
      ],
      "abstract": "We used a 3D simulator to create artificial video data with standardized\nannotations, aiming to aid in the development of Embodied AI. Our question\nanswering (QA) dataset measures the extent to which a robot can understand\nhuman behavior and the environment in a home setting. Preliminary experiments\nsuggest our dataset is useful in measuring AI's comprehension of daily life.\n\\end{abstract}",
      "tldr_zh": "这篇论文介绍了多模态数据集和基准，用于评估AI在日常环境中推理动态时空关系（Dynamic Spatio-Temporality）的能力。研究团队使用3D模拟器生成人工视频数据，并添加标准化注解，旨在支持Embodied AI的发展，同时通过Question Answering (QA)数据集测量机器人对人类行为和家庭环境的理解。初步实验结果表明，该数据集有效评估了AI对日常生活认知的水平，为AI系统在真实场景中的应用提供了重要基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 1 figure, 1 table, accepted in Embodied AI 2024 Workshop\n  held in conjunction with CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11347v2",
      "published_date": "2024-08-21 05:27:55 UTC",
      "updated_date": "2024-09-17 01:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:37:22.080647"
    },
    {
      "arxiv_id": "2408.11341v1",
      "title": "EHL*: Memory-Budgeted Indexing for Ultrafast Optimal Euclidean Pathfinding",
      "title_zh": "EHL*：内存预算索引用于超快速最优欧氏路径查找",
      "authors": [
        "Jinchun Du",
        "Bojie Shen",
        "Muhammad Aamir Cheema"
      ],
      "abstract": "The Euclidean Shortest Path Problem (ESPP), which involves finding the\nshortest path in a Euclidean plane with polygonal obstacles, is a classic\nproblem with numerous real-world applications. The current state-of-the-art\nsolution, Euclidean Hub Labeling (EHL), offers ultra-fast query performance,\noutperforming existing techniques by 1-2 orders of magnitude in runtime\nefficiency. However, this performance comes at the cost of significant memory\noverhead, requiring up to tens of gigabytes of storage on large maps, which can\nlimit its applicability in memory-constrained environments like mobile phones\nor smaller devices. Additionally, EHL's memory usage can only be determined\nafter index construction, and while it provides a memory-runtime tradeoff, it\ndoes not fully optimize memory utilization. In this work, we introduce an\nimproved version of EHL, called EHL*, which overcomes these limitations. A key\ncontribution of EHL* is its ability to create an index that adheres to a\nspecified memory budget while optimizing query runtime performance. Moreover,\nEHL* can leverage preknown query distributions, a common scenario in many\nreal-world applications to further enhance runtime efficiency. Our results show\nthat EHL* can reduce memory usage by up to 10-20 times without much impact on\nquery runtime performance compared to EHL, making it a highly effective\nsolution for optimal pathfinding in memory-constrained environments.",
      "tldr_zh": "本研究针对欧氏平面中带有多边形障碍的最短路径问题 (Euclidean Shortest Path Problem, ESPP)，提出了一种改进的索引方法 EHL*，旨在解决现有 Euclidean Hub Labeling (EHL) 的高内存开销问题。EHL* 允许用户指定内存预算来构建索引，同时优化查询运行时间，并能利用预知的查询分布进一步提升效率。与 EHL 相比，EHL* 可将内存使用减少 10-20 倍，同时保持查询性能基本不受影响，使其更适合内存受限环境如移动设备。实验结果证明了 EHL* 在保持超快路径查找速度的同时，大大提高了实际应用的可行性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11341v1",
      "published_date": "2024-08-21 04:55:10 UTC",
      "updated_date": "2024-08-21 04:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:37:44.430001"
    },
    {
      "arxiv_id": "2408.11338v1",
      "title": "Automatic Dataset Construction (ADC): Sample Collection, Data Curation, and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Minghao Liu",
        "Zonglin Di",
        "Jiaheng Wei",
        "Zhongruo Wang",
        "Hengxiang Zhang",
        "Ruixuan Xiao",
        "Haoyu Wang",
        "Jinlong Pang",
        "Hao Chen",
        "Ankit Shah",
        "Hongxin Wei",
        "Xinlei He",
        "Zhaowei Zhao",
        "Haobo Wang",
        "Lei Feng",
        "Jindong Wang",
        "James Davis",
        "Yang Liu"
      ],
      "abstract": "Large-scale data collection is essential for developing personalized training\ndata, mitigating the shortage of training data, and fine-tuning specialized\nmodels. However, creating high-quality datasets quickly and accurately remains\na challenge due to annotation errors, the substantial time and costs associated\nwith human labor. To address these issues, we propose Automatic Dataset\nConstruction (ADC), an innovative methodology that automates dataset creation\nwith negligible cost and high efficiency. Taking the image classification task\nas a starting point, ADC leverages LLMs for the detailed class design and code\ngeneration to collect relevant samples via search engines, significantly\nreducing the need for manual annotation and speeding up the data generation\nprocess. Despite these advantages, ADC also encounters real-world challenges\nsuch as label errors (label noise) and imbalanced data distributions (label\nbias). We provide open-source software that incorporates existing methods for\nlabel error detection, robust learning under noisy and biased data, ensuring a\nhigher-quality training data and more robust model training procedure.\nFurthermore, we design three benchmark datasets focused on label noise\ndetection, label noise learning, and class-imbalanced learning. These datasets\nare vital because there are few existing datasets specifically for label noise\ndetection, despite its importance. Finally, we evaluate the performance of\nexisting popular methods on these datasets, thereby facilitating further\nresearch in the field.",
      "tldr_zh": "这篇论文提出了 Automatic Dataset Construction (ADC)，一种自动化数据集构建方法，以解决大规模数据收集中的标注错误、时间和成本问题。ADC 以图像分类任务为例，利用 LLMs 进行详细的类设计和代码生成，通过搜索引擎收集相关样本，从而减少手动标注并加速数据生成过程。尽管面临标签错误（label noise）和数据分布不平衡（label bias）的挑战，该方法提供了开源软件，包括标签错误检测和鲁棒学习技术，以确保数据质量和模型训练的可靠性。此外，论文设计了三个基准数据集，专注于标签噪声检测、标签噪声学习和类别不平衡学习，并评估了现有流行方法的性能，以推动该领域的进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11338v1",
      "published_date": "2024-08-21 04:45:12 UTC",
      "updated_date": "2024-08-21 04:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:37:45.990818"
    },
    {
      "arxiv_id": "2408.11334v1",
      "title": "BURExtract-Llama: An LLM for Clinical Concept Extraction in Breast Ultrasound Reports",
      "title_zh": "BURExtract-Llama：一种用于乳房超声报告中临床概念提取的大型语言模型",
      "authors": [
        "Yuxuan Chen",
        "Haoyan Yang",
        "Hengkai Pan",
        "Fardeen Siddiqui",
        "Antonio Verdone",
        "Qingyang Zhang",
        "Sumit Chopra",
        "Chen Zhao",
        "Yiqiu Shen"
      ],
      "abstract": "Breast ultrasound is essential for detecting and diagnosing abnormalities,\nwith radiology reports summarizing key findings like lesion characteristics and\nmalignancy assessments. Extracting this critical information is challenging due\nto the unstructured nature of these reports, with varied linguistic styles and\ninconsistent formatting. While proprietary LLMs like GPT-4 are effective, they\nare costly and raise privacy concerns when handling protected health\ninformation. This study presents a pipeline for developing an in-house LLM to\nextract clinical information from radiology reports. We first use GPT-4 to\ncreate a small labeled dataset, then fine-tune a Llama3-8B model on it.\nEvaluated on clinician-annotated reports, our model achieves an average F1\nscore of 84.6%, which is on par with GPT-4. Our findings demonstrate the\nfeasibility of developing an in-house LLM that not only matches GPT-4's\nperformance but also offers cost reductions and enhanced data privacy.",
      "tldr_zh": "本研究针对乳房超声报告的非结构化特点（如多样语言风格和不一致格式），提出BURExtract-Llama，一种基于LLM的临床概念提取模型。该方法先利用GPT-4生成小型标注数据集，然后对Llama3-8B模型进行fine-tune，以提取关键信息如病变特征和恶性评估。在临床专家标注的报告上评估，该模型平均F1 score达84.6%，与GPT-4性能相当。研究证明，开发in-house LLM可实现成本降低和数据隐私提升，同时保持高效提取能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted as the oral paper for the HCHM workshop,\n  ACM Multimedia 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11334v1",
      "published_date": "2024-08-21 04:33:05 UTC",
      "updated_date": "2024-08-21 04:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:38:07.637849"
    },
    {
      "arxiv_id": "2408.11327v2",
      "title": "Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking Across Diverse Vocabularies",
      "title_zh": "即插即用并融合：通过跨越不同",
      "authors": [
        "Sai Koneru",
        "Matthias Huck",
        "Miriam Exel",
        "Jan Niehues"
      ],
      "abstract": "Recent advancements in NLP have resulted in models with specialized\nstrengths, such as processing multimodal inputs or excelling in specific\ndomains. However, real-world tasks, like multimodal translation, often require\na combination of these strengths, such as handling both translation and image\nprocessing. While individual translation and vision models are powerful, they\ntypically lack the ability to perform both tasks in a single system. Combining\nthese models poses challenges, particularly due to differences in their\nvocabularies, which limit the effectiveness of traditional ensemble methods to\npost-generation techniques like N-best list re-ranking. In this work, we\npropose a novel zero-shot ensembling strategy that allows for the integration\nof different models during the decoding phase without the need for additional\ntraining. Our approach re-ranks beams during decoding by combining scores at\nthe word level, using heuristics to predict when a word is completed. We\ndemonstrate the effectiveness of this method in machine translation scenarios,\nshowing that it enables the generation of translations that are both speech-\nand image-aware while also improving overall translation quality (We will\nrelease the code upon paper acceptance.).",
      "tldr_zh": "该研究解决了NLP中不同模型专长（如多模态处理或特定领域）的整合问题，尤其在需要结合任务（如多模态翻译）时，传统方法因词汇表差异而受限。作者提出了一种Zero-Shot集成策略，通过在解码阶段进行Word-Level Re-ranking，将不同模型的分数在单词级别结合，并使用启发式方法预测单词完成，从而无需额外训练即可实现模型融合。实验结果显示，该方法在机器翻译场景中生成既考虑语音和图像的翻译，同时提升了整体翻译质量，为灵活的跨模型应用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WMT 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.11327v2",
      "published_date": "2024-08-21 04:20:55 UTC",
      "updated_date": "2024-11-04 12:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:38:19.735757"
    },
    {
      "arxiv_id": "2408.11326v1",
      "title": "Automating Thought of Search: A Journey Towards Soundness and Completeness",
      "title_zh": "自动化搜索思维：通往健全性和完整性的",
      "authors": [
        "Daniel Cao",
        "Michael Katz",
        "Harsha Kokel",
        "Kavitha Srinivas",
        "Shirin Sohrabi"
      ],
      "abstract": "Planning remains one of the last standing bastions for large language models\n(LLMs), which now turn their attention to search. Most of the literature uses\nthe language models as world models to define the search space, forgoing\nsoundness for the sake of flexibility. A recent work, Thought of Search (ToS),\nproposed defining the search space with code, having the language models\nproduce that code. ToS requires a human in the loop, collaboratively producing\na sound successor function and goal test. The result, however, is worth the\neffort: all the tested datasets were solved with 100% accuracy. At the same\ntime LLMs have demonstrated significant progress in code generation and\nrefinement for complex reasoning tasks. In this work, we automate ToS\n(AutoToS), completely taking the human out of the loop of solving planning\nproblems. AutoToS guides the language model step by step towards the generation\nof sound and complete search components, through feedback from both generic and\ndomain specific unit tests. We achieve 100% accuracy, with minimal feedback\niterations, using LLMs of various sizes on all evaluated domains.",
      "tldr_zh": "该论文提出AutoToS（Automating Thought of Search），一种自动化框架，用于解决大型语言模型（LLMs）在规划问题中的soundness（正确性）和completeness（完整性）挑战。AutoToS通过引导LLMs逐步生成代码，并利用通用和领域特定单元测试提供反馈，彻底移除人类参与来构建可靠的搜索组件。与先前的ToS方法相比，该框架在所有评估领域实现了100%准确率，且仅需最小反馈迭代。实验结果证明，即使使用不同大小的LLMs，AutoToS也能高效处理复杂规划任务，为LLMs在搜索领域的应用奠定更坚实基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11326v1",
      "published_date": "2024-08-21 04:19:52 UTC",
      "updated_date": "2024-08-21 04:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:38:21.821841"
    },
    {
      "arxiv_id": "2408.11319v2",
      "title": "SarcasmBench: Towards Evaluating Large Language Models on Sarcasm Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yazhou Zhang",
        "Chunwang Zou",
        "Zheng Lian",
        "Prayag Tiwari",
        "Jing Qin"
      ],
      "abstract": "In the era of large language models (LLMs), the task of ``System I''~-~the\nfast, unconscious, and intuitive tasks, e.g., sentiment analysis, text\nclassification, etc., have been argued to be successfully solved. However,\nsarcasm, as a subtle linguistic phenomenon, often employs rhetorical devices\nlike hyperbole and figuration to convey true sentiments and intentions,\ninvolving a higher level of abstraction than sentiment analysis. There is\ngrowing concern that the argument about LLMs' success may not be fully tenable\nwhen considering sarcasm understanding. To address this question, we select\neleven SOTA LLMs and eight SOTA pre-trained language models (PLMs) and present\ncomprehensive evaluations on six widely used benchmark datasets through\ndifferent prompting approaches, i.e., zero-shot input/output (IO) prompting,\nfew-shot IO prompting, chain of thought (CoT) prompting. Our results highlight\nthree key findings: (1) current LLMs underperform supervised PLMs based sarcasm\ndetection baselines across six sarcasm benchmarks. This suggests that\nsignificant efforts are still required to improve LLMs' understanding of human\nsarcasm. (2) GPT-4 consistently and significantly outperforms other LLMs across\nvarious prompting methods, with an average improvement of 14.0\\%$\\uparrow$.\nClaude 3 and ChatGPT demonstrate the next best performance after GPT-4. (3)\nFew-shot IO prompting method outperforms the other two methods: zero-shot IO\nand few-shot CoT. The reason is that sarcasm detection, being a holistic,\nintuitive, and non-rational cognitive process, is argued not to adhere to\nstep-by-step logical reasoning, making CoT less effective in understanding\nsarcasm compared to its effectiveness in mathematical reasoning tasks.",
      "tldr_zh": "本论文提出 SarcasmBench 框架，用于评估大型语言模型(LLMs)和预训练语言模型(PLMs)在讽刺理解上的性能，通过零样本 IO、少样本 IO 和链式思考(CoT)提示方法，在六大基准数据集上测试 11 个 SOTA LLMs 和 8 个 SOTA PLMs。\n结果显示，当前 LLMs 在讽刺检测上整体不如监督训练的 PLMs，这表明 LLMs 在处理这种直觉性任务时仍需进一步改进。\nGPT-4 在各种提示方法中表现出显著优势，比其他 LLMs 平均提升 14%，而 Claude 3 和 ChatGPT 紧随其后；此外，少样本 IO 方法最有效，因为讽刺理解更依赖整体直觉而非步步逻辑推理。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11319v2",
      "published_date": "2024-08-21 03:59:51 UTC",
      "updated_date": "2024-08-24 03:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:38:35.613729"
    },
    {
      "arxiv_id": "2408.11316v2",
      "title": "Probabilistic Medical Predictions of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Gu",
        "Rishi J. Desai",
        "Kueiyu Joshua Lin",
        "Jie Yang"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in clinical applications\nthrough prompt engineering, allowing flexible clinical predictions. However,\nthey struggle to produce reliable prediction probabilities, which are crucial\nfor transparency and decision-making. While explicit prompts can lead LLMs to\ngenerate probability estimates, their numerical reasoning limitations raise\nconcerns about reliability. We compared explicit probabilities from text\ngeneration to implicit probabilities derived from the likelihood of predicting\nthe correct label token. Across six advanced open-source LLMs and five medical\ndatasets, explicit probabilities consistently underperformed implicit\nprobabilities in discrimination, precision, and recall. This discrepancy is\nmore pronounced with smaller LLMs and imbalanced datasets, highlighting the\nneed for cautious interpretation, improved probability estimation methods, and\nfurther research for clinical use of LLMs.",
      "tldr_zh": "这篇论文探讨了大语言模型（LLMs）在医疗预测中的概率输出问题，通过提示工程（prompt engineering）比较了显式概率（从文本生成）和隐式概率（从正确标签标记的似然度计算）。研究在六个先进的开源 LLMs 和五个医疗数据集上进行，结果显示隐式概率在区分度、精确度和召回率方面均优于显式概率。差异在较小 LLMs 和不平衡数据集上更为显著，突显了 LLMs 数值推理的局限性。论文建议谨慎解释这些概率估计，并呼吁开发改进的概率估计方法，以推动 LLMs 在临床决策中的可靠应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2408.11316v2",
      "published_date": "2024-08-21 03:47:17 UTC",
      "updated_date": "2024-12-03 21:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:38:50.092803"
    },
    {
      "arxiv_id": "2408.11313v2",
      "title": "An Optimizable Suffix Is Worth A Thousand Templates: Efficient Black-box Jailbreaking without Affirmative Phrases via LLM as Optimizer",
      "title_zh": "翻译失败",
      "authors": [
        "Weipeng Jiang",
        "Zhenting Wang",
        "Juan Zhai",
        "Shiqing Ma",
        "Zhengyu Zhao",
        "Chao Shen"
      ],
      "abstract": "Despite prior safety alignment efforts, mainstream LLMs can still generate\nharmful and unethical content when subjected to jailbreaking attacks. Existing\njailbreaking methods fall into two main categories: template-based and\noptimization-based methods. The former requires significant manual effort and\ndomain knowledge, while the latter, exemplified by Greedy Coordinate Gradient\n(GCG), which seeks to maximize the likelihood of harmful LLM outputs through\ntoken-level optimization, also encounters several limitations: requiring\nwhite-box access, necessitating pre-constructed affirmative phrase, and\nsuffering from low efficiency. In this paper, we present ECLIPSE, a novel and\nefficient black-box jailbreaking method utilizing optimizable suffixes. Drawing\ninspiration from LLMs' powerful generation and optimization capabilities, we\nemploy task prompts to translate jailbreaking goals into natural language\ninstructions. This guides the LLM to generate adversarial suffixes for\nmalicious queries. In particular, a harmfulness scorer provides continuous\nfeedback, enabling LLM self-reflection and iterative optimization to\nautonomously and efficiently produce effective suffixes. Experimental results\ndemonstrate that ECLIPSE achieves an average attack success rate (ASR) of 0.92\nacross three open-source LLMs and GPT-3.5-Turbo, significantly surpassing GCG\nin 2.4 times. Moreover, ECLIPSE is on par with template-based methods in ASR\nwhile offering superior attack efficiency, reducing the average attack overhead\nby 83%.",
      "tldr_zh": "该论文提出了一种高效的黑盒 jailbreaking 方法 ECLIPSE，利用 LLM 作为优化器，通过可优化后缀来生成对抗性输入，而无需预构建的肯定短语，从而规避了模板-based 方法的手动努力和 GCG 的白盒限制。ECLIPSE 通过任务提示将 jailbreaking 目标转化为自然语言指令，并结合有害性评分器提供反馈，实现 LLM 的自反和迭代优化。实验结果显示，该方法在三个开源 LLMs 和 GPT-3.5-Turbo 上平均 ASR 达到 0.92，比 GCG 高 2.4 倍，且攻击效率提高 83%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Be accepeted as NAACL2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2408.11313v2",
      "published_date": "2024-08-21 03:35:24 UTC",
      "updated_date": "2025-04-02 08:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:39:11.778541"
    },
    {
      "arxiv_id": "2408.11312v3",
      "title": "Swarm Intelligence in Geo-Localization: A Multi-Agent Large Vision-Language Model Collaborative Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Han",
        "Chen Zhu",
        "Xiangyu Zhao",
        "Hengshu Zhu"
      ],
      "abstract": "Visual geo-localization demands in-depth knowledge and advanced reasoning\nskills to associate images with precise real-world geographic locations.\nExisting image database retrieval methods are limited by the impracticality of\nstoring sufficient visual records of global landmarks. Recently, Large\nVision-Language Models (LVLMs) have demonstrated the capability of\ngeo-localization through Visual Question Answering (VQA), enabling a solution\nthat does not require external geo-tagged image records. However, the\nperformance of a single LVLM is still limited by its intrinsic knowledge and\nreasoning capabilities. To address these challenges, we introduce smileGeo, a\nnovel visual geo-localization framework that leverages multiple\nInternet-enabled LVLM agents operating within an agent-based architecture. By\nfacilitating inter-agent communication, smileGeo integrates the inherent\nknowledge of these agents with additional retrieved information, enhancing the\nability to effectively localize images. Furthermore, our framework incorporates\na dynamic learning strategy that optimizes agent communication, reducing\nredundant interactions and enhancing overall system efficiency. To validate the\neffectiveness of the proposed framework, we conducted experiments on three\ndifferent datasets, and the results show that our approach significantly\noutperforms current state-of-the-art methods. The source code is available at\nhttps://anonymous.4open.science/r/ViusalGeoLocalization-F8F5.",
      "tldr_zh": "该研究针对视觉地理定位（geo-localization）的挑战，提出了一种基于群体智能（Swarm Intelligence）的多代理协作框架smileGeo，利用多个互联网启用的Large Vision-Language Model (LVLM)代理来整合内在知识和外部检索信息。框架通过代理间通信和动态学习策略优化交互，减少冗余并提升图像本地化能力，避免了传统图像数据库检索的局限性。在三个不同数据集上的实验显示，smileGeo显著优于现有最先进方法，证明了其有效性。开源代码可在指定链接获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "resubmit to www2025",
      "pdf_url": "http://arxiv.org/pdf/2408.11312v3",
      "published_date": "2024-08-21 03:31:30 UTC",
      "updated_date": "2024-10-15 06:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:39:12.458772"
    },
    {
      "arxiv_id": "2408.11308v1",
      "title": "EEG-Defender: Defending against Jailbreak through Early Exit Generation of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chongwen Zhao",
        "Zhihao Dou",
        "Kaizhu Huang"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly attracting attention in various\napplications. Nonetheless, there is a growing concern as some users attempt to\nexploit these models for malicious purposes, including the synthesis of\ncontrolled substances and the propagation of disinformation. In an effort to\nmitigate such risks, the concept of \"Alignment\" technology has been developed.\nHowever, recent studies indicate that this alignment can be undermined using\nsophisticated prompt engineering or adversarial suffixes, a technique known as\n\"Jailbreak.\" Our research takes cues from the human-like generate process of\nLLMs. We identify that while jailbreaking prompts may yield output logits\nsimilar to benign prompts, their initial embeddings within the model's latent\nspace tend to be more analogous to those of malicious prompts. Leveraging this\nfinding, we propose utilizing the early transformer outputs of LLMs as a means\nto detect malicious inputs, and terminate the generation immediately. Built\nupon this idea, we introduce a simple yet significant defense approach called\nEEG-Defender for LLMs. We conduct comprehensive experiments on ten jailbreak\nmethods across three models. Our results demonstrate that EEG-Defender is\ncapable of reducing the Attack Success Rate (ASR) by a significant margin,\nroughly 85\\% in comparison with 50\\% for the present SOTAs, with minimal impact\non the utility and effectiveness of LLMs.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 的安全风险，提出 EEG-Defender，一种通过 Early Exit Generation 机制的防御方法，以应对 Jailbreak 攻击。研究发现，Jailbreak 提示在模型的潜在空间中早期嵌入更类似于恶意提示，因此利用 LLMs 的早期 transformer 输出即可检测并立即终止生成过程。实验在三个模型上测试了十种 Jailbreak 方法，结果显示 EEG-Defender 将 Attack Success Rate (ASR) 降低了约 85%，远优于现有 SOTA 技术的 50%，同时对模型的效用影响最小。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.11308v1",
      "published_date": "2024-08-21 03:25:31 UTC",
      "updated_date": "2024-08-21 03:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:39:27.909923"
    },
    {
      "arxiv_id": "2408.11306v2",
      "title": "Are KANs Effective for Multivariate Time Series Forecasting?",
      "title_zh": "KANs 是否有效用于多变量时间序列预测？",
      "authors": [
        "Xiao Han",
        "Xinfeng Zhang",
        "Yiling Wu",
        "Zhenduo Zhang",
        "Zhe Wu"
      ],
      "abstract": "Multivariate time series forecasting is a crucial task that predicts the\nfuture states based on historical inputs. Related techniques have been\ndeveloping in parallel with the machine learning community, from early\nstatistical learning methods to current deep learning methods. Despite their\nsignificant advancements, existing methods continue to struggle with the\nchallenge of inadequate interpretability. The rise of the Kolmogorov-Arnold\nNetwork (KAN) provides a new perspective to solve this challenge, but current\nwork has not yet concluded whether KAN is effective in time series forecasting\ntasks. In this paper, we aim to evaluate the effectiveness of KANs in\ntime-series forecasting from the perspectives of performance, integrability,\nefficiency, and interpretability. To this end, we propose the Multi-layer\nMixture-of-KAN network (MMK), which achieves excellent performance while\nretaining KAN's ability to be transformed into a combination of symbolic\nfunctions. The core module of MMK is the mixture-of-KAN layer, which uses a\nmixture-of-experts structure to assign variables to best-matched KAN experts.\nThen, we explore some useful experimental strategies to deal with the issues in\nthe training stage. Finally, we compare MMK and various baselines on seven\ndatasets. Extensive experimental and visualization results demonstrate that\nKANs are effective in multivariate time series forecasting. Code is available\nat: https://github.com/2448845600/EasyTSF.",
      "tldr_zh": "本研究评估了Kolmogorov-Arnold Network (KAN)在多元时间序列预测中的有效性，针对现有方法的可解释性不足问题，提出Multi-layer Mixture-of-KAN network (MMK)模型，该模型通过mixture-of-experts结构将变量分配给最佳KAN专家，实现高性能的同时保留符号函数转换能力。MMK的核心模块结合多层设计和实验策略，解决了训练阶段的挑战，并在七个数据集上与基线模型比较。实验结果显示，MMK显著提升了预测性能、效率和可解释性，证明KAN在时间序列预测任务中有效，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11306v2",
      "published_date": "2024-08-21 03:21:52 UTC",
      "updated_date": "2025-02-11 03:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:39:36.639155"
    },
    {
      "arxiv_id": "2408.11305v2",
      "title": "UniFashion: A Unified Vision-Language Model for Multimodal Fashion Retrieval and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Zhao",
        "Yuehan Zhang",
        "Wenlong Zhang",
        "Xiao-Ming Wu"
      ],
      "abstract": "The fashion domain encompasses a variety of real-world multimodal tasks,\nincluding multimodal retrieval and multimodal generation. The rapid\nadvancements in artificial intelligence generated content, particularly in\ntechnologies like large language models for text generation and diffusion\nmodels for visual generation, have sparked widespread research interest in\napplying these multimodal models in the fashion domain. However, tasks\ninvolving embeddings, such as image-to-text or text-to-image retrieval, have\nbeen largely overlooked from this perspective due to the diverse nature of the\nmultimodal fashion domain. And current research on multi-task single models\nlack focus on image generation. In this work, we present UniFashion, a unified\nframework that simultaneously tackles the challenges of multimodal generation\nand retrieval tasks within the fashion domain, integrating image generation\nwith retrieval tasks and text generation tasks. UniFashion unifies embedding\nand generative tasks by integrating a diffusion model and LLM, enabling\ncontrollable and high-fidelity generation. Our model significantly outperforms\nprevious single-task state-of-the-art models across diverse fashion tasks, and\ncan be readily adapted to manage complex vision-language tasks. This work\ndemonstrates the potential learning synergy between multimodal generation and\nretrieval, offering a promising direction for future research in the fashion\ndomain. The source code is available at\nhttps://github.com/xiangyu-mm/UniFashion.",
      "tldr_zh": "本文提出UniFashion，一种统一的Vision-Language Model，用于处理时尚领域的多模态检索和生成任务，旨在解决现有模型在嵌入任务（如图像到文本检索）和图像生成方面的不足。UniFashion通过整合Diffusion Model和LLM，实现嵌入任务与生成任务的统一，提供可控和高保真度的输出。实验结果显示，该模型在多种时尚任务上显著优于现有单任务SOTA模型，并揭示了多模态生成与检索之间的学习协同效应，为时尚领域的研究开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by EMNLP 2024, main conference",
      "pdf_url": "http://arxiv.org/pdf/2408.11305v2",
      "published_date": "2024-08-21 03:17:20 UTC",
      "updated_date": "2024-10-12 14:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:39:59.431964"
    },
    {
      "arxiv_id": "2408.11300v1",
      "title": "Offline Policy Learning via Skill-step Abstraction for Long-horizon Goal-Conditioned Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Donghoon Kim",
        "Minjong Yoo",
        "Honguk Woo"
      ],
      "abstract": "Goal-conditioned (GC) policy learning often faces a challenge arising from\nthe sparsity of rewards, when confronting long-horizon goals. To address the\nchallenge, we explore skill-based GC policy learning in offline settings, where\nskills are acquired from existing data and long-horizon goals are decomposed\ninto sequences of near-term goals that align with these skills. Specifically,\nwe present an `offline GC policy learning via skill-step abstraction' framework\n(GLvSA) tailored for tackling long-horizon GC tasks affected by goal\ndistribution shifts. In the framework, a GC policy is progressively learned\noffline in conjunction with the incremental modeling of skill-step abstractions\non the data. We also devise a GC policy hierarchy that not only accelerates GC\npolicy learning within the framework but also allows for parameter-efficient\nfine-tuning of the policy. Through experiments with the maze and Franka kitchen\nenvironments, we demonstrate the superiority and efficiency of our GLvSA\nframework in adapting GC policies to a wide range of long-horizon goals. The\nframework achieves competitive zero-shot and few-shot adaptation performance,\noutperforming existing GC policy learning and skill-based methods.",
      "tldr_zh": "这篇论文针对长时序目标条件 (GC) 策略学习中奖励稀疏性的挑战，提出了一种离线框架 GLvSA，通过技能步骤抽象 (skill-step abstraction) 将长时序目标分解为与现有数据中获取的技能对齐的近期目标序列。框架采用增量建模和 GC 策略层次结构，不仅加速策略学习，还实现了参数高效的微调。在迷宫和 Franka 厨房环境中，实验结果显示 GLvSA 在适应广泛长时序目标时表现出优越性，实现了竞争性的零样本和少样本适应性能，优于现有 GC 策略学习和基于技能的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures, International Joint Conference on Artificial\n  Intelligence 2024, Published version",
      "pdf_url": "http://arxiv.org/pdf/2408.11300v1",
      "published_date": "2024-08-21 03:05:06 UTC",
      "updated_date": "2024-08-21 03:05:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:40:02.293859"
    },
    {
      "arxiv_id": "2408.11288v1",
      "title": "Applying and Evaluating Large Language Models in Mental Health Care: A Scoping Review of Human-Assessed Generative Tasks",
      "title_zh": "在心理健康护理中应用和评估大语言模型：人类评估生成任务的范围",
      "authors": [
        "Yining Hua",
        "Hongbin Na",
        "Zehan Li",
        "Fenglin Liu",
        "Xiao Fang",
        "David Clifton",
        "John Torous"
      ],
      "abstract": "Large language models (LLMs) are emerging as promising tools for mental\nhealth care, offering scalable support through their ability to generate\nhuman-like responses. However, the effectiveness of these models in clinical\nsettings remains unclear. This scoping review aimed to assess the current\ngenerative applications of LLMs in mental health care, focusing on studies\nwhere these models were tested with human participants in real-world scenarios.\nA systematic search across APA PsycNet, Scopus, PubMed, and Web of Science\nidentified 726 unique articles, of which 17 met the inclusion criteria. These\nstudies encompassed applications such as clinical assistance, counseling,\ntherapy, and emotional support. However, the evaluation methods were often\nnon-standardized, with most studies relying on ad hoc scales that limit\ncomparability and robustness. Privacy, safety, and fairness were also\nfrequently underexplored. Moreover, reliance on proprietary models, such as\nOpenAI's GPT series, raises concerns about transparency and reproducibility.\nWhile LLMs show potential in expanding mental health care access, especially in\nunderserved areas, the current evidence does not fully support their use as\nstandalone interventions. More rigorous, standardized evaluations and ethical\noversight are needed to ensure these tools can be safely and effectively\nintegrated into clinical practice.",
      "tldr_zh": "这篇 scoping review 评估了 Large Language Models (LLMs) 在心理健康护理中的生成任务应用，通过系统搜索 APA PsycNet、Scopus、PubMed 和 Web of Science 等数据库，筛选出 17 篇涉及人类参与者真实场景研究的文章，包括临床辅助、咨询、治疗和情感支持。研究发现，LLMs 有潜力扩展心理健康服务，尤其在 underserved 地区，但存在评估方法不标准化（如依赖 ad hoc 量表）、隐私、安全和公平性不足，以及对专有模型（如 OpenAI 的 GPT 系列）的依赖，导致透明度和可重复性问题。总体而言，虽然 LLMs 显示出前景，但当前证据不支持其作为独立干预措施，未来需加强标准化评估和伦理监督以安全整合临床实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11288v1",
      "published_date": "2024-08-21 02:21:59 UTC",
      "updated_date": "2024-08-21 02:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:40:13.053135"
    },
    {
      "arxiv_id": "2408.11283v2",
      "title": "Inference Plans for Hybrid Particle Filtering",
      "title_zh": "混合粒子滤波的推断计划",
      "authors": [
        "Ellie Y. Cheng",
        "Eric Atkinson",
        "Guillaume Baudart",
        "Louis Mandel",
        "Michael Carbin"
      ],
      "abstract": "Advanced probabilistic programming languages (PPLs) using hybrid particle\nfiltering combine symbolic exact inference and Monte Carlo methods to improve\ninference performance. These systems use heuristics to partition random\nvariables within the program into variables that are encoded symbolically and\nvariables that are encoded with sampled values, and the heuristics are not\nnecessarily aligned with the developer's performance evaluation metrics. In\nthis work, we present inference plans, a programming interface that enables\ndevelopers to control the partitioning of random variables during hybrid\nparticle filtering. We further present Siren, a new PPL that enables developers\nto use annotations to specify inference plans the inference system must\nimplement. To assist developers with statically reasoning about whether an\ninference plan can be implemented, we present an abstract-interpretation-based\nstatic analysis for Siren for determining inference plan satisfiability. We\nprove the analysis is sound with respect to Siren's semantics. Our evaluation\napplies inference plans to three different hybrid particle filtering algorithms\non a suite of benchmarks. It shows that the control provided by inference plans\nenables speed ups of 1.76x on average and up to 206x to reach a target\naccuracy, compared to the inference plans implemented by default heuristics;\nthe results also show that inference plans improve accuracy by 1.83x on average\nand up to 595x with less or equal runtime, compared to the default inference\nplans. We further show that our static analysis is precise in practice,\nidentifying all satisfiable inference plans in 27 out of the 33\nbenchmark-algorithm evaluation settings.",
      "tldr_zh": "本论文提出“inference plans”，一种编程接口，允许开发者在混合粒子过滤（hybrid particle filtering）中控制随机变量的分区，以优化高级概率编程语言（PPLs）的推理性能。论文引入了Siren，一种新PPL，通过注解让开发者指定inference plans，并开发了基于抽象解释的静态分析来验证这些计划的可实现性，并证明了其相对于Siren语义的正确性。实验评估显示，与默认启发式方法相比，inference plans在基准测试中平均加速1.76倍（最高206倍）以达到目标准确率，并平均提高准确性1.83倍（最高595倍），同时保持或减少运行时间。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "v2: camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2408.11283v2",
      "published_date": "2024-08-21 02:07:03 UTC",
      "updated_date": "2024-12-14 16:19:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:40:25.781780"
    },
    {
      "arxiv_id": "2408.11281v2",
      "title": "BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation",
      "title_zh": "BearLLM：一种基于先验知识增强的轴承健康管理框架，采用统一振动信号表示",
      "authors": [
        "Haotian Peng",
        "Jiawei Liu",
        "Jinsong Du",
        "Jie Gao",
        "Wei Wang"
      ],
      "abstract": "We propose a bearing health management framework leveraging large language\nmodels (BearLLM), a novel multimodal model that unifies multiple\nbearing-related tasks by processing user prompts and vibration signals.\nSpecifically, we introduce a prior knowledge-enhanced unified vibration signal\nrepresentation to handle various working conditions across multiple datasets.\nThis involves adaptively sampling the vibration signals based on the sampling\nrate of the sensor, incorporating the frequency domain to unify input\ndimensions, and using a fault-free reference signal as an auxiliary input. To\nextract features from vibration signals, we first train a fault classification\nnetwork, then convert and align the extracted features into word embedding, and\nfinally concatenate these with text embedding as input to an LLM. To evaluate\nthe performance of the proposed method, we constructed the first large-scale\nmultimodal bearing health management (MBHM) dataset, including paired vibration\nsignals and textual descriptions. With our unified vibration signal\nrepresentation, BearLLM using one set of pre-trained weights achieves\nstate-of-the-art performance on nine publicly available fault diagnosis\nbenchmarks, outperforming specific methods designed for individual datasets. We\nprovide a dataset, our model, and code to inspire future research on building\nmore capable industrial multimodal models https://github.com/SIA-IDE/BearLLM.",
      "tldr_zh": "该论文提出 BearLLM，一种基于大型语言模型(LLMs)的轴承健康管理框架，通过 prior knowledge-enhanced unified vibration signal representation 方法统一处理振动信号和用户提示，以适应多种工作条件。该框架包括自适应采样振动信号、整合频域输入以及使用无故障参考信号作为辅助输入，并通过训练故障分类网络提取特征，将其转换为词嵌入后与文本嵌入拼接输入 LLM。为评估性能，作者构建了首个大规模多模态轴承健康管理(MBHM)数据集，结果显示 BearLLM 使用一套预训练权重，在九个公开故障诊断基准上超越特定方法，实现了最先进性能，并开源了数据集、模型和代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2408.11281v2",
      "published_date": "2024-08-21 02:04:54 UTC",
      "updated_date": "2024-12-16 03:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:40:36.484249"
    },
    {
      "arxiv_id": "2408.11261v1",
      "title": "Towards Analyzing and Mitigating Sycophancy in Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yunpu Zhao",
        "Rui Zhang",
        "Junbin Xiao",
        "Changxin Ke",
        "Ruibo Hou",
        "Yifan Hao",
        "Qi Guo",
        "Yunji Chen"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have shown significant capability in\nvision-language understanding. However, one critical issue that persists in\nthese models is sycophancy, which means models are unduly influenced by leading\nor deceptive prompts, resulting in biased outputs and hallucinations. Despite\nthe progress in LVLMs, evaluating and mitigating sycophancy is yet much\nunder-explored. In this work, we fill this gap by systematically analyzing\nsycophancy on various VL benchmarks with curated leading queries and further\nproposing a text contrastive decoding method for mitigation. While the specific\nsycophantic behavior varies significantly among models, our analysis reveals\nthe severe deficiency of all LVLMs in resilience of sycophancy across various\ntasks. For improvement, we propose Leading Query Contrastive Decoding (LQCD), a\nmodel-agnostic method focusing on calibrating the LVLMs' over-reliance on\nleading cues by identifying and suppressing the probabilities of sycophancy\ntokens at the decoding stage. Extensive experiments show that LQCD effectively\nmitigate sycophancy, outperforming both prompt engineering methods and common\nmethods for hallucination mitigation. We further demonstrate that LQCD does not\nhurt but even slightly improves LVLMs' responses to neutral queries, suggesting\nit being a more effective strategy for general-purpose decoding but not limited\nto sycophancy.",
      "tldr_zh": "本研究分析了大型视觉语言模型(LVLMs)中的sycophancy问题，即模型容易受引导或欺骗性提示影响，导致输出偏见和幻觉。作者通过在各种视觉语言基准上使用定制引导查询，对多种LVLMs的sycophancy行为进行系统评估，发现所有模型在抗sycophancy方面均存在严重缺陷。为此，提出Leading Query Contrastive Decoding (LQCD)，一种模型无关的方法，通过在解码阶段识别并抑制sycophancy tokens来校准模型对引导提示的过度依赖。实验结果显示，LQCD比提示工程和幻觉缓解方法更有效，不仅显著降低sycophancy，还能略微提升模型对中性查询的响应。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11261v1",
      "published_date": "2024-08-21 01:03:21 UTC",
      "updated_date": "2024-08-21 01:03:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:40:52.233853"
    },
    {
      "arxiv_id": "2408.11258v1",
      "title": "Improving Speech Recognition Error Prediction for Modern and Off-the-shelf Speech Recognizers",
      "title_zh": "翻译失败",
      "authors": [
        "Prashant Serai",
        "Peidong Wang",
        "Eric Fosler-Lussier"
      ],
      "abstract": "Modeling the errors of a speech recognizer can help simulate errorful\nrecognized speech data from plain text, which has proven useful for tasks like\ndiscriminative language modeling, improving robustness of NLP systems, where\nlimited or even no audio data is available at train time. Previous work\ntypically considered replicating behavior of GMM-HMM based systems, but the\nbehavior of more modern posterior-based neural network acoustic models is not\nthe same and requires adjustments to the error prediction model. In this work,\nwe extend a prior phonetic confusion based model for predicting speech\nrecognition errors in two ways: first, we introduce a sampling-based paradigm\nthat better simulates the behavior of a posterior-based acoustic model. Second,\nwe investigate replacing the confusion matrix with a sequence-to-sequence model\nin order to introduce context dependency into the prediction. We evaluate the\nerror predictors in two ways: first by predicting the errors made by a\nSwitchboard ASR system on unseen data (Fisher), and then using that same\npredictor to estimate the behavior of an unrelated cloud-based ASR system on a\nnovel task. Sampling greatly improves predictive accuracy within a 100-guess\nparadigm, while the sequence model performs similarly to the confusion matrix.",
      "tldr_zh": "该研究旨在改进语音识别错误预测模型，以适应现代后验基于神经网络的声学模型（如 ASR 系统），从而从纯文本模拟错误语音数据，用于任务如区分性语言建模和提升 NLP 系统鲁棒性。作者扩展了之前的基于语音混淆矩阵的模型：引入采样-based paradigm 来更好地模拟后验模型行为，并探索用 sequence-to-sequence 模型替换混淆矩阵以增加上下文依赖性。在实验中，该方法在预测 Switchboard ASR 系统对 Fisher 数据错误的准确性上显著提升，尤其在 100 次猜测范式下，而 sequence-to-sequence 模型的表现与混淆矩阵相当。总的来说，这为处理现代和现成 ASR 系统的错误预测提供了有效调整。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11258v1",
      "published_date": "2024-08-21 00:48:03 UTC",
      "updated_date": "2024-08-21 00:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:41:01.536116"
    },
    {
      "arxiv_id": "2408.11253v2",
      "title": "Automatic Image Annotation (AIA) of AlmondNet-20 Method for Almond Detection by Improved CNN-based Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Asghari Ilani",
        "Saba Moftakhar Tehran",
        "Ashkan Kavei",
        "Arian Radmehr"
      ],
      "abstract": "In response to the burgeoning global demand for premium agricultural\nproducts, particularly within the competitive nut market, this paper introduces\nan innovative methodology aimed at enhancing the grading process for almonds\nand their shells. Leveraging state-of-the-art Deep Convolutional Neural\nNetworks (CNNs), specifically the AlmondNet-20 architecture, our study achieves\nexceptional accuracy exceeding 99%, facilitated by the utilization of a\n20-layer CNN model. To bolster robustness in differentiating between almonds\nand shells, data augmentation techniques are employed, ensuring the reliability\nand accuracy of our classification system. Our model, meticulously trained over\n1000 epochs, demonstrates remarkable performance, boasting an accuracy rate of\n99% alongside a minimal loss function of 0.0567. Rigorous evaluation through\ntest datasets further validates the efficacy of our approach, revealing\nimpeccable precision, recall, and F1-score metrics for almond detection. Beyond\nits technical prowess, this advanced classification system offers tangible\nbenefits to both industry experts and non-specialists alike, ensuring globally\nreliable almond classification. The application of deep learning algorithms, as\nshowcased in our study, not only enhances grading accuracy but also presents\nopportunities for product patents, thereby contributing to the economic value\nof our nation. Through the adoption of cutting-edge technologies such as the\nAlmondNet-20 model, we pave the way for future advancements in agricultural\nproduct classification, ultimately enriching global trade and economic\nprosperity.",
      "tldr_zh": "本研究提出了一种基于改进 CNN 模型的 AlmondNet-20 方法，用于自动图像注释 (AIA) 和杏仁检测，以提升杏仁及其壳的分类精度。AlmondNet-20 采用 20 层架构，并结合数据增强技术进行训练，历经 1000 个 epochs，实现了超过 99% 的准确率和最低损失函数 0.0567。实验结果显示，该模型在测试数据集上表现出色的精确率、召回率和 F1-score，显著提高了杏仁检测的鲁棒性和可靠性。该方法不仅为农业产品分级提供实际益处，还为专利机会和国家经济价值贡献力量，推动全球贸易中的深层学习应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.11253v2",
      "published_date": "2024-08-21 00:20:08 UTC",
      "updated_date": "2024-12-04 23:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T17:41:12.509011"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 103,
  "processed_papers_count": 103,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T17:41:35.607445"
}