{
  "date": "2024-12-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 48 篇论文，主要聚焦 AI 模型优化（如 LLM 和 Transformer）、医疗应用以及计算机视觉创新，亮点包括 HuatuoGPT-o1 在医疗复杂推理上的突破，以及 Tempus Core 在硬件效率提升方面的实用进展；知名学者如 John Paul Shen 和 Denys Poshyvanyk 的参与文章值得关注，这些工作突显了 AI 在资源约束和实际应用中的潜力。\n\n下面，我挑选并简要讨论几篇重要或话题度高的论文，先从 AI 和 LLM 领域入手（这些是今日热点），再快速触及医疗和计算机视觉相关内容。对于其他较常规的论文，我会简略掠过，只列出标题和核心要点，以控制篇幅。\n\n### AI 和 LLM 优化\n- **标题（中文）：大型语言模型在代码异味生成中的倾向性研究（英文）：How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study**  \n  作者包括 Denys Poshyvanyk，这篇论文引入 CodeSmellEval 基准和 Propensity Smelly Score（PSC）指标，评估 LLM（如 CodeLlama 和 Mistral）生成代码异味的倾向。主要发现：LLM 容易产生异味，如 simplifiable-condition，发现有助于提升代码生成任务的可靠性和质量。\n\n- **标题（中文）：注入偏见到文本分类模型使用后门攻击（英文）：Injecting Bias into Text Classification Models using Backdoor Attacks**  \n  这篇工作探索后门攻击用于偏见注入，针对 IMDb 和 SST 数据集的模型（如 BERT 和 RoBERTa）。主要贡献：展示了攻击的高效性（100% 成功率），并提出 U-BBSR 和 P-BBSR 指标评估泛化偏见，强调现代模型面临的安全风险。\n\n- **标题（中文）：ModelGrow: 持续文本到视频预训练模型的扩展和语言理解增强（英文）：ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement**  \n  作者团队包括 Qifeng Chen，这篇论文提出 ModelGrow 框架，用于高效的文本到视频生成。主要发现：通过模型容量扩展和 LLM 增强语义理解，提升了生成性能，实验显示在各种指标上优于基线，适用于资源有限的场景。\n\n- **标题（中文）：HuatuoGPT-o1: 面向医疗复杂推理的大型语言模型（英文）：HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs**  \n  作者如 Benyou Wang，这篇由中国学者主导的论文使用强化学习和验证器优化医疗推理。主要贡献：仅用 40K 可验证问题就超越基线模型，RL 进一步提升问题解决能力，展示了 LLM 在医疗领域的潜力。\n\n- **标题（中文）：PRISM: 使用短上下文 LLM 进行高效长程推理（英文）：PRISM: Efficient Long-Range Reasoning With Short-Context LLMs**  \n  这篇论文提出 PRISM 框架，使用结构化内存处理长程任务。主要发现：在短上下文（<500 tokens）下，性能优于长上下文模型，减少计算成本达 54%，适用于多样任务。\n\n其他 LLM 相关论文如第18（AdaEAGLE）和第37（Torque-Aware Momentum）也优化了模型推理，但细节较常规，我快速掠过：它们分别通过自适应草稿结构和动量优化提升速度和泛化。\n\n### 医疗和生物应用\n- **标题（中文）：MedHallBench: 评估医疗大型语言模型幻觉的新基准（英文）：MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models**  \n  这篇论文引入 MedHallBench 框架，使用 ACHMI 评分和强化学习评估医疗 LLM 的幻觉问题。主要发现：比传统指标更精确，实验显示幻觉评估能改善模型可靠性，为医疗 AI 提供新标准。\n\n其他医疗论文如第13（HuatuoGPT-o1，已上文）和第21（Comprehensive Study on Lumbar Disc Segmentation）聚焦图像分割，但后者较基础，仅提升了 ResUnext 等模型的准确率（Dice Coefficient 达 0.8425），不做深挖。\n\n### 计算机视觉和硬件创新\n- **标题（中文）：Tempus Core: 面向低精度边缘深度学习加速器的面积-功耗高效时序一元卷积核心（英文）：Tempus Core: Area-Power Efficient Temporal-Unary Convolution Core for Low-Precision Edge DLAs**  \n  作者包括 John Paul Shen，这篇印象深刻的工作提出 Tempus Core 架构，集成到 NVDLA 中。主要贡献：INT8 精度下，面积和功耗分别减少 59.3% 和 15.3%，适用于边缘 AI，展示了高效硬件设计的潜力。\n\n- **标题（中文）：TravelAgent: 建筑环境中的生成代理（英文）：TravelAgent: Generative Agents in the Built Environment**  \n  作者如 Kent Larson，这篇论文开发 TravelAgent 模拟平台，模拟行人行为。主要发现：76% 任务完成率，通过生成代理提升城市设计研究，相关实验数据详实。\n\n其他视觉论文如第17（Accelerating Diffusion Transformers）和第26（WeatherGS）优化了 Transformer 和场景重建，但前者通过双特征缓存加速，后者处理恶劣天气重建，我仅简注：它们提升了效率和鲁棒性，却非今日核心。\n\n剩余论文如第2、3（地理数据融合，相关但不突出）、第7（IoT 模型推荐，实用但常规）、第11（强化学习，技术性强但不话题度高），我快速掠过：它们分别在遥感分析、IoT 和安全 RL 方面有小幅进展，但未有突破性影响。\n\n总之，今天的 arXiv 更新强调 AI 效率和应用创新，HuatuoGPT-o1 和 Tempus Core 等论文可能引发广泛讨论，建议读者关注这些领域的最新进展！如果有特定兴趣，建议直接查阅原文。明天见！",
  "papers": [
    {
      "arxiv_id": "2412.19002v1",
      "title": "Tempus Core: Area-Power Efficient Temporal-Unary Convolution Core for Low-Precision Edge DLAs",
      "title_zh": "翻译失败",
      "authors": [
        "Prabhu Vellaisamy",
        "Harideep Nair",
        "Thomas Kang",
        "Yichen Ni",
        "Haoyang Fan",
        "Bin Qi",
        "Jeff Chen",
        "Shawn Blanton",
        "John Paul Shen"
      ],
      "abstract": "The increasing complexity of deep neural networks (DNNs) poses significant\nchallenges for edge inference deployment due to resource and power constraints\nof edge devices. Recent works on unary-based matrix multiplication hardware aim\nto leverage data sparsity and low-precision values to enhance hardware\nefficiency. However, the adoption and integration of such unary hardware into\ncommercial deep learning accelerators (DLA) remain limited due to processing\nelement (PE) array dataflow differences. This work presents Tempus Core, a\nconvolution core with highly scalable unary-based PE array comprising of tub\n(temporal-unary-binary) multipliers that seamlessly integrates with the NVDLA\n(NVIDIA's open-source DLA for accelerating CNNs) while maintaining dataflow\ncompliance and boosting hardware efficiency. Analysis across various datapath\ngranularities shows that for INT8 precision in 45nm CMOS, Tempus Core's PE cell\nunit (PCU) yields 59.3% and 15.3% reductions in area and power consumption,\nrespectively, over NVDLA's CMAC unit. Considering a 16x16 PE array in Tempus\nCore, area and power improves by 75% and 62%, respectively, while delivering 5x\nand 4x iso-area throughput improvements for INT8 and INT4 precisions.\nPost-place and route analysis of Tempus Core's PCU shows that the 16x4 PE array\nfor INT4 precision in 45nm CMOS requires only 0.017 mm^2 die area and consumes\nonly 6.2mW of total power. We demonstrate that area-power efficient unary-based\nhardware can be seamlessly integrated into conventional DLAs, paving the path\nfor efficient unary hardware for edge AI inference.",
      "tldr_zh": "这篇论文针对深度神经网络(DNNs)在边缘设备上的资源和功耗挑战，提出了一种高效的卷积核心Tempus Core，该核心采用可扩展的unary-based PE阵列和temporal-unary-binary (tub) 乘法器，与NVDLA无缝集成。Tempus Core在45nm CMOS工艺下，对于INT8精度，其PE单元(PCU)相比NVDLA的CMAC单元减少59.3%面积和15.3%功耗；在16x16 PE阵列配置中，面积和功耗分别改善75%和62%，并实现INT8和INT4精度的5x和4x等面积吞吐量提升。实验证明，这种设计为边缘AI推理提供了高效的unary-based硬件集成路径。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted in DATE 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.19002v1",
      "published_date": "2024-12-25 23:20:02 UTC",
      "updated_date": "2024-12-25 23:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:33:12.112254"
    },
    {
      "arxiv_id": "2412.18994v1",
      "title": "Geospatial Data Fusion: Combining Lidar, SAR, and Optical Imagery with AI for Enhanced Urban Mapping",
      "title_zh": "地理空间数据融合：利用 AI 结合 Lidar、SAR 和光学图像以增强城市映射",
      "authors": [
        "Sajjad Afroosheh",
        "Mohammadreza Askari"
      ],
      "abstract": "This study explores the integration of Lidar, Synthetic Aperture Radar (SAR),\nand optical imagery through advanced artificial intelligence techniques for\nenhanced urban mapping. By fusing these diverse geospatial datasets, we aim to\novercome the limitations associated with single-sensor data, achieving a more\ncomprehensive representation of urban environments. The research employs Fully\nConvolutional Networks (FCNs) as the primary deep learning model for urban\nfeature extraction, enabling precise pixel-wise classification of essential\nurban elements, including buildings, roads, and vegetation. To optimize the\nperformance of the FCN model, we utilize Particle Swarm Optimization (PSO) for\nhyperparameter tuning, significantly enhancing model accuracy. Key findings\nindicate that the FCN-PSO model achieved a pixel accuracy of 92.3% and a mean\nIntersection over Union (IoU) of 87.6%, surpassing traditional single-sensor\napproaches. These results underscore the potential of fused geospatial data and\nAI-driven methodologies in urban mapping, providing valuable insights for urban\nplanning and management. The implications of this research pave the way for\nfuture developments in real-time mapping and adaptive urban infrastructure\nplanning.",
      "tldr_zh": "这篇论文探讨了通过人工智能技术融合 Lidar、SAR 和 optical imagery 的方法，以克服单一传感器数据的局限性，实现更全面的城市环境映射。研究采用 Fully Convolutional Networks (FCNs) 作为主要深度学习模型，进行精确的像素级分类，如建筑物、道路和植被，并利用 Particle Swarm Optimization (PSO) 优化模型超参数，提升整体性能。关键发现显示，FCN-PSO 模型取得了 92.3% 的像素准确率和 87.6% 的平均 IoU，显著优于传统单一传感器方法。这些结果为城市规划和管理提供了宝贵见解，并为实时映射和自适应城市基础设施规划铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18994v1",
      "published_date": "2024-12-25 22:17:31 UTC",
      "updated_date": "2024-12-25 22:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:33:22.853367"
    },
    {
      "arxiv_id": "2412.19856v1",
      "title": "Fusion of Deep Learning and GIS for Advanced Remote Sensing Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Sajjad Afroosheh",
        "Mohammadreza Askari"
      ],
      "abstract": "This paper presents an innovative framework for remote sensing image analysis\nby fusing deep learning techniques, specifically Convolutional Neural Networks\n(CNNs) and Long Short-Term Memory (LSTM) networks, with Geographic Information\nSystems (GIS). The primary objective is to enhance the accuracy and efficiency\nof spatial data analysis by overcoming challenges associated with high\ndimensionality, complex patterns, and temporal data processing. We implemented\noptimization algorithms, namely Particle Swarm Optimization (PSO) and Genetic\nAlgorithms (GA), to fine-tune model parameters, resulting in improved\nperformance metrics. Our findings reveal a significant increase in\nclassification accuracy from 78% to 92% and a reduction in prediction error\nfrom 12% to 6% after optimization. Additionally, the temporal accuracy of the\nmodels improved from 75% to 88%, showcasing the frameworks capability to\nmonitor dynamic changes effectively. The integration of GIS not only enriched\nthe spatial analysis but also facilitated a deeper understanding of the\nrelationships between geographical features. This research demonstrates that\ncombining advanced deep learning methods with GIS and optimization strategies\ncan significantly advance remote sensing applications, paving the way for\nfuture developments in environmental monitoring, urban planning, and resource\nmanagement.",
      "tldr_zh": "本研究提出了一种创新框架，将深度学习技术（CNN 和 LSTM）与 GIS 融合，用于提升遥感图像分析的准确性和效率，解决高维度数据、复杂模式和时间处理挑战。框架通过粒子群优化（PSO）和遗传算法（GA）对模型参数进行微调，导致分类准确率从 78% 提高到 92%，预测错误从 12% 减少到 6%，以及时间准确率从 75% 提升到 88%。这种整合不仅加深了对地理特征关系的理解，还为环境监测、城市规划和资源管理等应用提供了先进解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.19856v1",
      "published_date": "2024-12-25 22:10:35 UTC",
      "updated_date": "2024-12-25 22:10:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:33:33.490026"
    },
    {
      "arxiv_id": "2412.18989v2",
      "title": "How Propense Are Large Language Models at Producing Code Smells? A Benchmarking Study",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Velasco",
        "Daniel Rodriguez-Cardenas",
        "Luftar Rahman Alif",
        "David N. Palacio",
        "Denys Poshyvanyk"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant potential in automating\nsoftware engineering tasks, particularly in code generation. However, current\nevaluation benchmarks, which primarily focus on accuracy, fall short in\nassessing the quality of the code generated by these models, specifically their\ntendency to produce code smells. To address this limitation, we introduce\nCodeSmellEval, a benchmark designed to evaluate the propensity of LLMs for\ngenerating code smells. Our benchmark includes a novel metric: Propensity\nSmelly Score (PSC), and a curated dataset of method-level code smells:\nCodeSmellData. To demonstrate the use of CodeSmellEval, we conducted a case\nstudy with two state-of-the-art LLMs, CodeLlama and Mistral. The results reveal\nthat both models tend to generate code smells, such as simplifiable-condition\nand consider-merging-isinstance. These findings highlight the effectiveness of\nour benchmark in evaluating LLMs, providing valuable insights into their\nreliability and their propensity to introduce code smells in code generation\ntasks.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在代码生成任务中产生代码异味 (code smells) 的倾向，引入了 CodeSmellEval 基准作为评估工具，以弥补现有基准仅关注准确性的局限。研究开发了 Propensity Smelly Score (PSC) 指标和 CodeSmellData 数据集，用于量化 LLMs 生成代码的质量问题。针对 CodeLlama 和 Mistral 两个先进模型的案例研究显示，这些模型经常产生如 simplifiable-condition 和 consider-merging-isinstance 等代码异味。总体结果强调了 CodeSmellEval 的有效性，为提升 LLMs 的可靠性和代码生成质量提供了关键见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18989v2",
      "published_date": "2024-12-25 21:56:35 UTC",
      "updated_date": "2025-01-18 20:14:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:33:45.816618"
    },
    {
      "arxiv_id": "2412.18985v1",
      "title": "TravelAgent: Generative Agents in the Built Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Ariel Noyman",
        "Kai Hu",
        "Kent Larson"
      ],
      "abstract": "Understanding human behavior in built environments is critical for designing\nfunctional, user centered urban spaces. Traditional approaches, such as manual\nobservations, surveys, and simplified simulations, often fail to capture the\ncomplexity and dynamics of real world behavior. To address these limitations,\nwe introduce TravelAgent, a novel simulation platform that models pedestrian\nnavigation and activity patterns across diverse indoor and outdoor environments\nunder varying contextual and environmental conditions. TravelAgent leverages\ngenerative agents integrated into 3D virtual environments, enabling agents to\nprocess multimodal sensory inputs and exhibit human-like decision-making,\nbehavior, and adaptation. Through experiments, including navigation,\nwayfinding, and free exploration, we analyze data from 100 simulations\ncomprising 1898 agent steps across diverse spatial layouts and agent\narchetypes, achieving an overall task completion rate of 76%. Using spatial,\nlinguistic, and sentiment analyses, we show how agents perceive, adapt to, or\nstruggle with their surroundings and assigned tasks. Our findings highlight the\npotential of TravelAgent as a tool for urban design, spatial cognition\nresearch, and agent-based modeling. We discuss key challenges and opportunities\nin deploying generative agents for the evaluation and refinement of spatial\ndesigns, proposing TravelAgent as a new paradigm for simulating and\nunderstanding human experiences in built environments.",
      "tldr_zh": "本研究提出TravelAgent，一种新型模拟平台，用于模拟行人在室内和室外建筑环境中的导航和活动模式，以解决传统方法（如手动观察和简化模拟）无法捕捉真实行为复杂性的问题。TravelAgent 整合生成性 agents 到 3D virtual environments 中，这些 agents 处理多模态感官输入，并展示类似人类的决策、行为和适应能力。通过100个模拟实验（涉及1898个 agent 步骤），平台在不同空间布局和 agent archetypes 上实现了76%的任务完成率，并通过空间、语言和情感分析揭示了 agents 如何感知和适应环境。研究结果突显了 TravelAgent 在城市设计、空间认知研究和基于代理的建模中的潜力，同时讨论了部署生成性 agents 的挑战与机会，为优化建筑环境提供新范式。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages 9 figs",
      "pdf_url": "http://arxiv.org/pdf/2412.18985v1",
      "published_date": "2024-12-25 21:27:51 UTC",
      "updated_date": "2024-12-25 21:27:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:33:58.378853"
    },
    {
      "arxiv_id": "2412.18975v1",
      "title": "Injecting Bias into Text Classification Models using Backdoor Attacks",
      "title_zh": "使用后门攻击向文本分类模型注入偏见",
      "authors": [
        "A. Dilara Yavuz",
        "M. Emre Gursoy"
      ],
      "abstract": "The rapid growth of natural language processing (NLP) and pre-trained\nlanguage models have enabled accurate text classification in a variety of\nsettings. However, text classification models are susceptible to backdoor\nattacks, where an attacker embeds a trigger into the victim model to make the\nmodel predict attacker-desired labels in targeted scenarios. In this paper, we\npropose to utilize backdoor attacks for a new purpose: bias injection. We\ndevelop a backdoor attack in which a subset of the training dataset is poisoned\nto associate strong male actors with negative sentiment. We execute our attack\non two popular text classification datasets (IMDb and SST) and seven different\nmodels ranging from traditional Doc2Vec-based models to LSTM networks and\nmodern transformer-based BERT and RoBERTa models. Our results show that the\nreduction in backdoored models' benign classification accuracy is limited,\nimplying that our attacks remain stealthy, whereas the models successfully\nlearn to associate strong male actors with negative sentiment (100% attack\nsuccess rate with >= 3% poison rate). Attacks on BERT and RoBERTa are\nparticularly more stealthy and effective, demonstrating an increased risk of\nusing modern and larger models. We also measure the generalizability of our\nbias injection by proposing two metrics: (i) U-BBSR which uses previously\nunseen words when measuring attack success, and (ii) P-BBSR which measures\nattack success using paraphrased test samples. U-BBSR and P-BBSR results show\nthat the bias injected by our attack can go beyond memorizing a trigger phrase.",
      "tldr_zh": "这篇论文探讨了利用backdoor attacks在文本分类模型中注入偏见的方法，具体通过毒化训练数据集的子集，使模型将强壮男性演员与负面情绪关联。研究者在IMDb和SST数据集上测试了七种模型，包括Doc2Vec、LSTM以及现代模型如BERT和RoBERTa，结果显示攻击成功率达100%（毒化率≥3%），而模型的正常分类准确率下降有限，保持了隐蔽性。论文还引入了U-BBSR和P-BBSR指标来评估偏见的泛化能力，证明注入的偏见不止于记忆触发短语，而是具有更广泛的影响。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18975v1",
      "published_date": "2024-12-25 19:32:02 UTC",
      "updated_date": "2024-12-25 19:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:34:10.710464"
    },
    {
      "arxiv_id": "2412.18972v1",
      "title": "Recommending Pre-Trained Models for IoT Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Parth V. Patil",
        "Wenxin Jiang",
        "Huiyun Peng",
        "Daniel Lugo",
        "Kelechi G. Kalu",
        "Josh LeBlanc",
        "Lawrence Smith",
        "Hyeonwoo Heo",
        "Nathanael Aou",
        "James C. Davis"
      ],
      "abstract": "The availability of pre-trained models (PTMs) has enabled faster deployment\nof machine learning across applications by reducing the need for extensive\ntraining. Techniques like quantization and distillation have further expanded\nPTM applicability to resource-constrained IoT hardware. Given the many PTM\noptions for any given task, engineers often find it too costly to evaluate each\nmodel's suitability. Approaches such as LogME, LEEP, and ModelSpider help\nstreamline model selection by estimating task relevance without exhaustive\ntuning. However, these methods largely leave hardware constraints as future\nwork-a significant limitation in IoT settings. In this paper, we identify the\nlimitations of current model recommendation approaches regarding hardware\nconstraints and introduce a novel, hardware-aware method for PTM selection. We\nalso propose a research agenda to guide the development of effective,\nhardware-conscious model recommendation systems for IoT applications.",
      "tldr_zh": "本文探讨了预训练模型 (PTMs) 在资源受限的 IoT 设备上的应用问题，通过量化 (quantization) 和蒸馏 (distillation) 等技术，使 PTMs 能够更快部署，但模型选择过程因硬件约束而变得复杂。现有方法如 LogME、LEEP 和 ModelSpider 可估计任务相关性以简化选择，但未充分考虑硬件限制，导致实际适用性不足。本文识别了这些方法的局限性，提出了一种新型硬件-aware 方法来推荐适合 IoT 设备的 PTMs，并制定了一个研究议程，以推动硬件意识模型推荐系统的开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at SERP4IOT'25",
      "pdf_url": "http://arxiv.org/pdf/2412.18972v1",
      "published_date": "2024-12-25 19:19:55 UTC",
      "updated_date": "2024-12-25 19:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:34:23.452750"
    },
    {
      "arxiv_id": "2412.18966v1",
      "title": "ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Zhefan Rao",
        "Liya Ji",
        "Yazhou Xing",
        "Runtao Liu",
        "Zhaoyang Liu",
        "Jiaxin Xie",
        "Ziqiao Peng",
        "Yingqing He",
        "Qifeng Chen"
      ],
      "abstract": "Text-to-video (T2V) generation has gained significant attention recently.\nHowever, the costs of training a T2V model from scratch remain persistently\nhigh, and there is considerable room for improving the generation performance,\nespecially under limited computation resources. This work explores the\ncontinual general pre-training of text-to-video models, enabling the model to\n\"grow\" its abilities based on a pre-trained foundation, analogous to how humans\nacquire new knowledge based on past experiences. There is a lack of extensive\nstudy of the continual pre-training techniques in T2V generation. In this work,\nwe take the initial step toward exploring this task systematically and propose\nModelGrow. Specifically, we break this task into two key aspects: increasing\nmodel capacity and improving semantic understanding. For model capacity, we\nintroduce several novel techniques to expand the model size, enabling it to\nstore new knowledge and improve generation performance. For semantic\nunderstanding, we propose a method that leverages large language models as\nadvanced text encoders, integrating them into T2V models to enhance language\ncomprehension and guide generation results according to detailed prompts. This\napproach enables the model to achieve better semantic alignment, particularly\nin response to complex user prompts. Extensive experiments demonstrate the\neffectiveness of our method across various metrics. The source code and the\nmodel of ModelGrow will be publicly available.",
      "tldr_zh": "本研究探讨了Text-to-Video (T2V) 生成的持续预训练问题，提出ModelGrow框架，让模型基于预训练基础逐步“成长”，以降低训练成本并提升生成性能。该框架包括两方面：通过新型技巧扩展模型容量以存储新知识，以及整合大型语言模型作为高级文本编码器来改善语义理解和对复杂提示的响应。实验结果证明，ModelGrow在多种指标上表现出显著有效性，并将公开源代码和模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.18966v1",
      "published_date": "2024-12-25 18:58:07 UTC",
      "updated_date": "2024-12-25 18:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:34:34.295284"
    },
    {
      "arxiv_id": "2412.18952v1",
      "title": "Bridging Interpretability and Robustness Using LIME-Guided Model Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Navid Nayyem",
        "Abdullah Rakin",
        "Longwei Wang"
      ],
      "abstract": "This paper explores the intricate relationship between interpretability and\nrobustness in deep learning models. Despite their remarkable performance across\nvarious tasks, deep learning models often exhibit critical vulnerabilities,\nincluding susceptibility to adversarial attacks, over-reliance on spurious\ncorrelations, and a lack of transparency in their decision-making processes. To\naddress these limitations, we propose a novel framework that leverages Local\nInterpretable Model-Agnostic Explanations (LIME) to systematically enhance\nmodel robustness. By identifying and mitigating the influence of irrelevant or\nmisleading features, our approach iteratively refines the model, penalizing\nreliance on these features during training. Empirical evaluations on multiple\nbenchmark datasets demonstrate that LIME-guided refinement not only improves\ninterpretability but also significantly enhances resistance to adversarial\nperturbations and generalization to out-of-distribution data.",
      "tldr_zh": "本研究探讨了深度学习模型中解释性和鲁棒性的关系，针对模型易受对抗攻击、过度依赖虚假相关性以及决策过程缺乏透明度的局限性，提出了一种新型框架。框架利用 Local Interpretable Model-Agnostic Explanations (LIME) 来识别并减轻无关或误导性特征的影响，通过迭代精炼模型并在训练中惩罚对这些特征的依赖，从而提升模型的鲁棒性。实验在多个基准数据集上验证，该方法不仅提高了模型的解释性，还显著增强了对抗扰动的抵抗力和对分布外数据的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18952v1",
      "published_date": "2024-12-25 17:32:45 UTC",
      "updated_date": "2024-12-25 17:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:34:45.192838"
    },
    {
      "arxiv_id": "2412.18947v4",
      "title": "MedHallBench: A New Benchmark for Assessing Hallucination in Medical Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Zuo",
        "Yirui Jiang"
      ],
      "abstract": "Medical Large Language Models (MLLMs) have demonstrated potential in\nhealthcare applications, yet their propensity for hallucinations -- generating\nmedically implausible or inaccurate information -- presents substantial risks\nto patient care. This paper introduces MedHallBench, a comprehensive benchmark\nframework for evaluating and mitigating hallucinations in MLLMs. Our\nmethodology integrates expert-validated medical case scenarios with established\nmedical databases to create a robust evaluation dataset. The framework employs\na sophisticated measurement system that combines automated ACHMI (Automatic\nCaption Hallucination Measurement in Medical Imaging) scoring with rigorous\nclinical expert evaluations and utilizes reinforcement learning methods to\nachieve automatic annotation. Through an optimized reinforcement learning from\nhuman feedback (RLHF) training pipeline specifically designed for medical\napplications, MedHallBench enables thorough evaluation of MLLMs across diverse\nclinical contexts while maintaining stringent accuracy standards. We conducted\ncomparative experiments involving various models, utilizing the benchmark to\nestablish a baseline for widely adopted large language models (LLMs). Our\nfindings indicate that ACHMI provides a more nuanced understanding of the\neffects of hallucinations compared to traditional metrics, thereby highlighting\nits advantages in hallucination assessment. This research establishes a\nfoundational framework for enhancing MLLMs' reliability in healthcare settings\nand presents actionable strategies for addressing the critical challenge of AI\nhallucinations in medical applications.",
      "tldr_zh": "本研究引入了MedHallBench，一种全面的基准框架，用于评估和缓解医疗大语言模型(MLLMs)中的幻觉问题，这些幻觉可能导致不准确的医疗信息并危害患者护理。框架通过整合专家验证的医疗案例场景与医疗数据库，结合ACHMI（Automatic Caption Hallucination Measurement in Medical Imaging）评分系统、临床专家评估以及强化学习方法，实现自动标注和优化RLHF（Reinforcement Learning from Human Feedback）训练管道。实验结果显示，ACHMI比传统指标更精细地评估幻觉影响，并在多种模型上建立了基准，为提升MLLMs在医疗环境中的可靠性和安全性提供了关键策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published to AAAI-25 Bridge Program",
      "pdf_url": "http://arxiv.org/pdf/2412.18947v4",
      "published_date": "2024-12-25 16:51:29 UTC",
      "updated_date": "2025-03-28 23:37:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:34:58.226954"
    },
    {
      "arxiv_id": "2412.18946v1",
      "title": "Constraint-Adaptive Policy Switching for Offline Safe Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yassine Chemingui",
        "Aryan Deshwal",
        "Honghao Wei",
        "Alan Fern",
        "Janardhan Rao Doppa"
      ],
      "abstract": "Offline safe reinforcement learning (OSRL) involves learning a\ndecision-making policy to maximize rewards from a fixed batch of training data\nto satisfy pre-defined safety constraints. However, adapting to varying safety\nconstraints during deployment without retraining remains an under-explored\nchallenge. To address this challenge, we introduce constraint-adaptive policy\nswitching (CAPS), a wrapper framework around existing offline RL algorithms.\nDuring training, CAPS uses offline data to learn multiple policies with a\nshared representation that optimize different reward and cost trade-offs.\nDuring testing, CAPS switches between those policies by selecting at each state\nthe policy that maximizes future rewards among those that satisfy the current\ncost constraint. Our experiments on 38 tasks from the DSRL benchmark\ndemonstrate that CAPS consistently outperforms existing methods, establishing a\nstrong wrapper-based baseline for OSRL. The code is publicly available at\nhttps://github.com/yassineCh/CAPS.",
      "tldr_zh": "本文提出 Constraint-Adaptive Policy Switching (CAPS)，一个围绕现有 Offline RL 算法的框架，用于 Offline Safe Reinforcement Learning (OSRL)，旨在帮助决策策略在部署时适应不同的安全约束，而无需重新训练。CAPS 在训练阶段利用离线数据学习多个共享表示的策略，每个策略优化不同的奖励和成本权衡；在测试阶段，通过在每个状态下选择满足当前成本约束并最大化未来奖励的策略来动态切换。实验在 DSRL benchmark 的 38 个任务上表明，CAPS  consistently outperforms 现有方法，建立了一个强有力的基于包装器的基线。代码已公开在 https://github.com/yassineCh/CAPS。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18946v1",
      "published_date": "2024-12-25 16:42:27 UTC",
      "updated_date": "2024-12-25 16:42:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:35:10.730183"
    },
    {
      "arxiv_id": "2412.18926v1",
      "title": "Exemplar-condensed Federated Class-incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Sun",
        "Yumin Zhang",
        "Varun Ojha",
        "Tejal Shah",
        "Haoran Duan",
        "Bo Wei",
        "Rajiv Ranjan"
      ],
      "abstract": "We propose Exemplar-Condensed federated class-incremental learning (ECoral)\nto distil the training characteristics of real images from streaming data into\ninformative rehearsal exemplars. The proposed method eliminates the limitations\nof exemplar selection in replay-based approaches for mitigating catastrophic\nforgetting in federated continual learning (FCL). The limitations particularly\nrelated to the heterogeneity of information density of each summarized data.\nOur approach maintains the consistency of training gradients and the\nrelationship to past tasks for the summarized exemplars to represent the\nstreaming data compared to the original images effectively. Additionally, our\napproach reduces the information-level heterogeneity of the summarized data by\ninter-client sharing of the disentanglement generative model. Extensive\nexperiments show that our ECoral outperforms several state-of-the-art methods\nand can be seamlessly integrated with many existing approaches to enhance\nperformance.",
      "tldr_zh": "本研究提出了一种名为 ECoral 的 Exemplar-condensed Federated Class-incremental Learning 方法，用于在联邦持续学习（FCL）中缓解灾难性遗忘（catastrophic forgetting），通过将流式数据的训练特征浓缩成信息丰富的演练样本（exemplars）。该方法维护训练梯度的一致性、过去任务的关系，并通过客户端间共享的解耦生成模型（disentanglement generative model）来减少信息异质性，从而更有效地代表原始数据。实验结果表明，ECoral 优于多种最先进方法，并可无缝整合到现有方法中以进一步提升性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18926v1",
      "published_date": "2024-12-25 15:13:40 UTC",
      "updated_date": "2024-12-25 15:13:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:35:22.992225"
    },
    {
      "arxiv_id": "2412.18925v1",
      "title": "HuatuoGPT-o1, Towards Medical Complex Reasoning with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Junying Chen",
        "Zhenyang Cai",
        "Ke Ji",
        "Xidong Wang",
        "Wanlong Liu",
        "Rongsheng Wang",
        "Jianye Hou",
        "Benyou Wang"
      ],
      "abstract": "The breakthrough of OpenAI o1 highlights the potential of enhancing reasoning\nto improve LLM. Yet, most research in reasoning has focused on mathematical\ntasks, leaving domains like medicine underexplored. The medical domain, though\ndistinct from mathematics, also demands robust reasoning to provide reliable\nanswers, given the high standards of healthcare. However, verifying medical\nreasoning is challenging, unlike those in mathematics. To address this, we\npropose verifiable medical problems with a medical verifier to check the\ncorrectness of model outputs. This verifiable nature enables advancements in\nmedical reasoning through a two-stage approach: (1) using the verifier to guide\nthe search for a complex reasoning trajectory for fine-tuning LLMs, (2)\napplying reinforcement learning (RL) with verifier-based rewards to enhance\ncomplex reasoning further. Finally, we introduce HuatuoGPT-o1, a medical LLM\ncapable of complex reasoning, which outperforms general and medical-specific\nbaselines using only 40K verifiable problems. Experiments show complex\nreasoning improves medical problem-solving and benefits more from RL. We hope\nour approach inspires advancements in reasoning across medical and other\nspecialized domains.",
      "tldr_zh": "该研究针对医学领域的复杂推理问题，提出一种基于可验证医学问题的框架，以提升大型语言模型（LLMs）的性能。该框架采用两阶段方法：首先使用医学验证器指导搜索复杂的推理轨迹来微调LLMs，其次通过基于验证器的奖励进行强化学习（RL）进一步优化推理能力。最终，HuatuoGPT-o1模型仅使用40K可验证问题就超过了通用和医学特定基线，在实验中显示复杂推理显著改善了医学问题解决，并从RL中获得更大收益。该方法有望启发医学及其他专业领域的推理进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18925v1",
      "published_date": "2024-12-25 15:12:34 UTC",
      "updated_date": "2024-12-25 15:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:35:34.218690"
    },
    {
      "arxiv_id": "2501.00042v1",
      "title": "Resource-Efficient Transformer Architecture: Optimizing Memory and Execution Time for Real-Time Applications",
      "title_zh": "资源高效的 Transformer 架构：优化内存和执行时间以适用于实时应用",
      "authors": [
        "Krisvarish V",
        "Priyadarshini T",
        "K P Abhishek Sri Saai",
        "Vaidehi Vijayakumar"
      ],
      "abstract": "This paper describes a memory-efficient transformer model designed to drive a\nreduction in memory usage and execution time by substantial orders of magnitude\nwithout impairing the model's performance near that of the original model.\nRecently, new architectures of transformers were presented, focused on\nparameter efficiency and computational optimization; however, such models\nusually require considerable resources in terms of hardware when deployed in\nreal-world applications on edge devices. This approach addresses this concern\nby halving embedding size and applying targeted techniques such as parameter\npruning and quantization to optimize the memory footprint with minimum\nsacrifices in terms of accuracy. Experimental results include a 52% reduction\nin memory usage and a 33% decrease in execution time, resulting in better\nefficiency than state-of-the-art models. This work compared our model with\nexisting compelling architectures, such as MobileBERT and DistilBERT, and\nproved its feasibility in the domain of resource-friendly deep learning\narchitectures, mainly for applications in real-time and in resource-constrained\napplications.",
      "tldr_zh": "这篇论文提出了一种资源高效的Transformer架构，旨在大幅减少内存使用和执行时间，同时保持接近原模型的性能。方法包括减半embedding size，并应用parameter pruning和quantization等技术，以优化内存占用并最小化准确性损失。实验结果显示，该模型实现了52%的内存减少和33%的执行时间缩短，并在与MobileBERT和DistilBERT的比较中表现出优越性，适用于实时和资源受限应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.00042v1",
      "published_date": "2024-12-25 14:41:23 UTC",
      "updated_date": "2024-12-25 14:41:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:35:45.439281"
    },
    {
      "arxiv_id": "2412.18917v1",
      "title": "Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of Vision-Language Multiway Transformer Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Chia Chen",
        "Wei-Hua Li",
        "Chu-Song Chen"
      ],
      "abstract": "Open-vocabulary panoptic segmentation remains a challenging problem. One of\nthe biggest difficulties lies in training models to generalize to an unlimited\nnumber of classes using limited categorized training data. Recent popular\nmethods involve large-scale vision-language pre-trained foundation models, such\nas CLIP. In this paper, we propose OMTSeg for open-vocabulary segmentation\nusing another large-scale vision-language pre-trained model called BEiT-3 and\nleveraging the cross-modal attention between visual and linguistic features in\nBEiT-3 to achieve better performance. Experiments result demonstrates that\nOMTSeg performs favorably against state-of-the-art models.",
      "tldr_zh": "本文提出 OMTSeg，一种用于开放词汇全景分割（Open-Vocabulary Panoptic Segmentation）的模型，基于 BEiT-3 的视觉语言预训练框架，通过利用视觉和语言特征之间的跨模态注意力（cross-modal attention），来解决使用有限分类训练数据泛化到无限类别的挑战。相比于基于 CLIP 等模型的现有方法，OMTSeg 展示了更好的性能表现。实验结果显示，该模型在相关基准上优于最先进（state-of-the-art）模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICIP 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.18917v1",
      "published_date": "2024-12-25 14:31:00 UTC",
      "updated_date": "2024-12-25 14:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:35:58.452172"
    },
    {
      "arxiv_id": "2412.18914v2",
      "title": "PRISM: Efficient Long-Range Reasoning With Short-Context LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Dulhan Jayalath",
        "James Bradley Wendt",
        "Nicholas Monath",
        "Sandeep Tata",
        "Beliz Gunel"
      ],
      "abstract": "Long-range tasks demand reasoning over long inputs. Current solutions require\nlarge compute budgets, training data, model weight access, or complex\ntask-specific designs. We introduce PRISM, which processes information as a\nstream of chunks while maintaining a structured in-context memory specified\nwith a typed hierarchical schema. PRISM outperforms baselines on diverse tasks\nwhile using at least 4x shorter contexts than long-context models. This\napproach is token-efficient, producing concise outputs and efficiently\nleveraging key-value (KV) caches to reduce costs by up to 54% compared to\nalternative short-context methods. PRISM scales down to tiny chunks (<500\ntokens) without increasing encoding costs or sacrificing quality, and\ngeneralizes to new tasks with minimal effort by automatically generating\nschemas from task descriptions.",
      "tldr_zh": "该研究引入了 PRISM，一种高效的框架，用于利用短上下文 LLMs 处理长范围推理任务，避免了传统方法的高计算开销和复杂设计。PRISM 通过将信息处理为块流，同时维护一个类型化的层次化 schema 来管理结构化上下文内存，从而在各种任务上优于基线模型，使用至少 4 倍更短的上下文。实验显示，该方法在 token 效率上表现出色，能减少高达 54% 的 KV caches 成本，并在小块（如小于 500 tokens）上保持高质量，同时通过从任务描述自动生成 schema 实现对新任务的轻松泛化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.18914v2",
      "published_date": "2024-12-25 14:14:31 UTC",
      "updated_date": "2025-03-12 17:59:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:36:09.522559"
    },
    {
      "arxiv_id": "2412.18911v1",
      "title": "Accelerating Diffusion Transformers with Dual Feature Caching",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Zou",
        "Evelyn Zhang",
        "Runlin Guo",
        "Haohang Xu",
        "Conghui He",
        "Xuming Hu",
        "Linfeng Zhang"
      ],
      "abstract": "Diffusion Transformers (DiT) have become the dominant methods in image and\nvideo generation yet still suffer substantial computational costs. As an\neffective approach for DiT acceleration, feature caching methods are designed\nto cache the features of DiT in previous timesteps and reuse them in the next\ntimesteps, allowing us to skip the computation in the next timesteps. However,\non the one hand, aggressively reusing all the features cached in previous\ntimesteps leads to a severe drop in generation quality. On the other hand,\nconservatively caching only the features in the redundant layers or tokens but\nstill computing the important ones successfully preserves the generation\nquality but results in reductions in acceleration ratios. Observing such a\ntradeoff between generation quality and acceleration performance, this paper\nbegins by quantitatively studying the accumulated error from cached features.\nSurprisingly, we find that aggressive caching does not introduce significantly\nmore caching errors in the caching step, and the conservative feature caching\ncan fix the error introduced by aggressive caching. Thereby, we propose a dual\ncaching strategy that adopts aggressive and conservative caching iteratively,\nleading to significant acceleration and high generation quality at the same\ntime. Besides, we further introduce a V-caching strategy for token-wise\nconservative caching, which is compatible with flash attention and requires no\ntraining and calibration data.\n  Our codes have been released in Github: \\textbf{Code:\n\\href{https://github.com/Shenyi-Z/DuCa}{\\texttt{\\textcolor{cyan}{https://github.com/Shenyi-Z/DuCa}}}}",
      "tldr_zh": "Diffusion Transformers (DiT) 在图像和视频生成中是主流方法，但计算成本高。论文通过量化缓存错误，发现 aggressive caching 不会显著增加错误，且 conservative caching 可以修复这些错误，从而提出 dual feature caching 策略，交替使用激进和保守缓存，以实现高效加速同时保持高生成质量。此外，论文引入 V-caching 策略，用于 token-wise 保守缓存，支持 flash attention，且无需训练或校准数据。总的来说，这一方法显著提升了 DiT 的性能，并已开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18911v1",
      "published_date": "2024-12-25 14:00:14 UTC",
      "updated_date": "2024-12-25 14:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:36:21.921971"
    },
    {
      "arxiv_id": "2412.18910v1",
      "title": "AdaEAGLE: Optimizing Speculative Decoding via Explicit Modeling of Adaptive Draft Structures",
      "title_zh": "翻译失败",
      "authors": [
        "Situo Zhang",
        "Hankun Wang",
        "Da Ma",
        "Zichen Zhu",
        "Lu Chen",
        "Kunyao Lan",
        "Kai Yu"
      ],
      "abstract": "Speculative Decoding (SD) is a popular lossless technique for accelerating\nthe inference of Large Language Models (LLMs). We show that the decoding speed\nof SD frameworks with static draft structures can be significantly improved by\nincorporating context-aware adaptive draft structures. However, current studies\non adaptive draft structures are limited by their performance, modeling\napproaches, and applicability. In this paper, we introduce AdaEAGLE, the first\nSD framework that explicitly models adaptive draft structures. AdaEAGLE\nleverages the Lightweight Draft Length Predictor (LDLP) module to explicitly\npredict the optimal number of draft tokens during inference to guide the draft\nmodel. It achieves comparable speedup results without manual thresholds and\nallows for deeper, more specialized optimizations. Moreover, together with\nthreshold-based strategies, AdaEAGLE achieves a $1.62\\times$ speedup over the\nvanilla AR decoding and outperforms fixed-length SotA baseline while\nmaintaining output quality.",
      "tldr_zh": "本文提出 AdaEAGLE，一种优化 Speculative Decoding (SD) 的框架，通过显式建模 adaptive draft structures 来提升 Large Language Models (LLMs) 推理速度，解决现有方法的性能和适用性限制。AdaEAGLE 引入 Lightweight Draft Length Predictor (LDLP) 模块，显式预测推理过程中的最佳 draft tokens 数量，以指导 draft model 的生成，实现无手动阈值的加速优化。与 threshold-based 策略结合，该框架比 vanilla AR decoding 实现 1.62 倍的加速，并优于固定长度 SotA 基准，同时保持输出质量。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18910v1",
      "published_date": "2024-12-25 13:57:33 UTC",
      "updated_date": "2024-12-25 13:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:36:34.666396"
    },
    {
      "arxiv_id": "2412.18907v2",
      "title": "EC-Diffuser: Multi-Object Manipulation via Entity-Centric Behavior Generation",
      "title_zh": "EC-Diffuser：通过实体中心行为生成进行多对象操控",
      "authors": [
        "Carl Qi",
        "Dan Haramati",
        "Tal Daniel",
        "Aviv Tamar",
        "Amy Zhang"
      ],
      "abstract": "Object manipulation is a common component of everyday tasks, but learning to\nmanipulate objects from high-dimensional observations presents significant\nchallenges. These challenges are heightened in multi-object environments due to\nthe combinatorial complexity of the state space as well as of the desired\nbehaviors. While recent approaches have utilized large-scale offline data to\ntrain models from pixel observations, achieving performance gains through\nscaling, these methods struggle with compositional generalization in unseen\nobject configurations with constrained network and dataset sizes. To address\nthese issues, we propose a novel behavioral cloning (BC) approach that\nleverages object-centric representations and an entity-centric Transformer with\ndiffusion-based optimization, enabling efficient learning from offline image\ndata. Our method first decomposes observations into an object-centric\nrepresentation, which is then processed by our entity-centric Transformer that\ncomputes attention at the object level, simultaneously predicting object\ndynamics and the agent's actions. Combined with the ability of diffusion models\nto capture multi-modal behavior distributions, this results in substantial\nperformance improvements in multi-object tasks and, more importantly, enables\ncompositional generalization. We present BC agents capable of zero-shot\ngeneralization to tasks with novel compositions of objects and goals, including\nlarger numbers of objects than seen during training. We provide video rollouts\non our webpage: https://sites.google.com/view/ec-diffuser.",
      "tldr_zh": "这篇论文提出EC-Diffuser，一种基于behavioral cloning的方法，用于处理多物体操作的挑战，通过object-centric representations分解观察，并使用entity-centric Transformer结合diffusion-based optimization来预测物体动态和代理动作，从而从离线图像数据中高效学习行为。相比现有方法，该框架显著提升了多物体任务的性能，并实现了compositional generalization。实验证明，代理能够零样本泛化到未见过的物体组合和更大数量的物体，并提供了视频演示。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18907v2",
      "published_date": "2024-12-25 13:50:15 UTC",
      "updated_date": "2025-02-14 20:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:36:46.670032"
    },
    {
      "arxiv_id": "2412.18899v2",
      "title": "GAI: Generative Agents for Innovation",
      "title_zh": "翻译失败",
      "authors": [
        "Masahiro Sato"
      ],
      "abstract": "This study examines whether collective reasoning among generative agents can\nfacilitate novel and coherent thinking that leads to innovation. To achieve\nthis, it proposes GAI, a new LLM-empowered framework designed for reflection\nand interaction among multiple generative agents to replicate the process of\ninnovation. The core of the GAI framework lies in an architecture that\ndynamically processes the internal states of agents and a dialogue scheme\nspecifically tailored to facilitate analogy-driven innovation. The framework's\nfunctionality is evaluated using Dyson's invention of the bladeless fan as a\ncase study, assessing the extent to which the core ideas of the innovation can\nbe replicated through a set of fictional technical documents. The experimental\nresults demonstrate that models with internal states significantly outperformed\nthose without, achieving higher average scores and lower variance. Notably, the\nmodel with five heterogeneous agents equipped with internal states successfully\nreplicated the key ideas underlying the Dyson's invention. This indicates that\nthe internal state enables agents to refine their ideas, resulting in the\nconstruction and sharing of more coherent and comprehensive concepts.",
      "tldr_zh": "本研究探讨生成式代理（generative agents）的集体推理是否能促进创新，提出GAI框架，这是一个基于LLM（Large Language Models）的多代理系统，旨在通过代理间的反思和互动复制创新过程。GAI的核心包括动态处理代理的内部状态和一个针对类比驱动创新的对话方案，并以Dyson无叶风扇发明作为案例研究，通过虚构技术文档评估其效能。实验结果显示，具有内部状态的模型显著优于无内部状态模型，平均分数更高且方差更低，其中五个异构代理的配置成功复制了关键创新想法，证明内部状态有助于代理完善概念并实现更连贯的知识共享。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Added an Appendix section",
      "pdf_url": "http://arxiv.org/pdf/2412.18899v2",
      "published_date": "2024-12-25 13:20:10 UTC",
      "updated_date": "2024-12-31 17:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:36:57.753001"
    },
    {
      "arxiv_id": "2412.18894v1",
      "title": "Comprehensive Study on Lumbar Disc Segmentation Techniques Using MRI Data",
      "title_zh": "翻译失败",
      "authors": [
        "Serkan Salturk",
        "Irem Sayin",
        "Ibrahim Cem Balci",
        "Taha Emre Pamukcu",
        "Zafer Soydan",
        "Huseyin Uvet"
      ],
      "abstract": "Lumbar disk segmentation is essential for diagnosing and curing spinal\ndisorders by enabling precise detection of disk boundaries in medical imaging.\nThe advent of deep learning has resulted in the development of many\nsegmentation methods, offering differing levels of accuracy and effectiveness.\nThis study assesses the effectiveness of several sophisticated deep learning\narchitectures, including ResUnext, Ef3 Net, UNet, and TransUNet, for lumbar\ndisk segmentation, highlighting key metrics like as Pixel Accuracy, Mean\nIntersection over Union (Mean IoU), and Dice Coefficient. The findings indicate\nthat ResUnext achieved the highest segmentation accuracy, with a Pixel Accuracy\nof 0.9492 and a Dice Coefficient of 0.8425, with TransUNet following closely\nafter. Filtering techniques somewhat enhanced the performance of most models,\nparticularly Dense UNet, improving stability and segmentation quality. The\nfindings underscore the efficacy of these models in lumbar disk segmentation\nand highlight potential areas for improvement.",
      "tldr_zh": "这篇论文对使用 MRI 数据进行腰椎盘分割技术进行了全面评估，旨在提高脊柱疾病诊断的精确性。研究比较了多种深度学习架构，包括 ResUnext、Ef3 Net、UNet 和 TransUNet，并使用 Pixel Accuracy、Mean IoU 和 Dice Coefficient 等指标进行评估。结果显示，ResUnext 表现最佳，达到 Pixel Accuracy 0.9492 和 Dice Coefficient 0.8425，而过滤技术显著提升了大多数模型的稳定性和分割质量，如 Dense UNet。该研究强调了这些模型在腰椎盘分割中的有效性，并指出了未来改进的潜在领域。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18894v1",
      "published_date": "2024-12-25 12:54:52 UTC",
      "updated_date": "2024-12-25 12:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:37:10.665964"
    },
    {
      "arxiv_id": "2412.18890v1",
      "title": "CoEvo: Continual Evolution of Symbolic Solutions Using Large Language Models",
      "title_zh": "CoEvo：利用大型",
      "authors": [
        "Ping Guo",
        "Qingfu Zhang",
        "Xi Lin"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as transformative tools in\nartificial intelligence, capable of processing and understanding extensive\nhuman knowledge to enhance problem-solving across various domains. This paper\nexplores the potential of LLMs to drive the discovery of symbolic solutions\nwithin scientific and engineering disciplines, where such solutions are crucial\nfor advancing theoretical and practical applications. We propose a novel\nframework that utilizes LLMs in an evolutionary search methodology, augmented\nby a dynamic knowledge library that integrates and refines insights in an\n\\textit{open-ended manner}. This approach aims to tackle the dual challenges of\nefficiently navigating complex symbolic representation spaces and leveraging\nboth existing and newly generated knowledge to foster open-ended innovation. By\nenabling LLMs to interact with and expand upon a knowledge library, we\nfacilitate the continuous generation of novel solutions in diverse forms such\nas language, code, and mathematical expressions. Our experimental results\ndemonstrate that this method not only enhances the efficiency of searching for\nsymbolic solutions but also supports the ongoing discovery process, akin to\nhuman scientific endeavors. This study represents a first effort in\nconceptualizing the search for symbolic solutions as a lifelong, iterative\nprocess, marking a significant step towards harnessing AI in the perpetual\npursuit of scientific and engineering breakthroughs. We have open-sourced our\ncode and data, please visit \\url{https://github.com/pgg3/CoEvo} for more\ninformation.",
      "tldr_zh": "这篇论文提出 CoEvo 框架，利用 Large Language Models (LLMs) 驱动符号解决方案在科学和工程领域的持续演化，通过进化搜索方法和动态知识库实现开放式创新。框架允许 LLMs 与知识库互动，生成多样形式的解决方案，如语言、代码和数学表达式，从而高效导航复杂符号表示空间。实验结果表明，该方法显著提高了搜索效率，并支持终身迭代的发现过程，类似于人类科学探索；论文已开源代码和数据。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18890v1",
      "published_date": "2024-12-25 12:27:27 UTC",
      "updated_date": "2024-12-25 12:27:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:37:21.355748"
    },
    {
      "arxiv_id": "2412.18874v1",
      "title": "IUST_PersonReId: A New Domain in Person Re-Identification Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Sedighi Moghaddam",
        "Fatemeh Anvari",
        "Mohammadjavad Mirshekari Haghighi",
        "Mohammadali Fakhari",
        "Mohammad Reza Mohammadi"
      ],
      "abstract": "Person re-identification (ReID) models often struggle to generalize across\ndiverse cultural contexts, particularly in Islamic regions like Iran, where\nmodest clothing styles are prevalent. Existing datasets predominantly feature\nWestern and East Asian fashion, limiting their applicability in these settings.\nTo address this gap, we introduce IUST_PersonReId, a dataset designed to\nreflect the unique challenges of ReID in new cultural environments, emphasizing\nmodest attire and diverse scenarios from Iran, including markets, campuses, and\nmosques. Experiments on IUST_PersonReId with state-of-the-art models, such as\nSolider and CLIP-ReID, reveal significant performance drops compared to\nbenchmarks like Market1501 and MSMT17, highlighting the challenges posed by\nocclusion and limited distinctive features. Sequence-based evaluations show\nimprovements by leveraging temporal context, emphasizing the dataset's\npotential for advancing culturally sensitive and robust ReID systems.\nIUST_PersonReId offers a critical resource for addressing fairness and bias in\nReID research globally. The dataset is publicly available at\nhttps://computervisioniust.github.io/IUST_PersonReId/.",
      "tldr_zh": "本研究引入了 IUST_PersonReId 数据集，这是一个针对伊斯兰地区（如伊朗）的人脸再识别 (ReID) 领域的全新数据集，强调保守服装和多样化场景，包括市场、校园和清真寺，以解决现有数据集（如 Market1501 和 MSMT17）在文化背景泛化上的局限性。实验显示，先进模型如 Solider 和 CLIP-ReID 在 IUST_PersonReId 上性能显著下降，突出了遮挡和有限特征的挑战，但通过序列-based 评估利用时间上下文可实现性能提升。IUST_PersonReId 作为公开资源，有助于推动文化敏感的 ReID 系统发展，并解决全球 ReID 研究中的公平性和偏见问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 4 figures. The dataset introduced in this paper,\n  IUST_PersonReId, is publicly available at\n  https://computervisioniust.github.io/IUST_PersonReId/",
      "pdf_url": "http://arxiv.org/pdf/2412.18874v1",
      "published_date": "2024-12-25 11:17:43 UTC",
      "updated_date": "2024-12-25 11:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:37:34.806836"
    },
    {
      "arxiv_id": "2501.01439v1",
      "title": "Probabilistic Mission Design in Neuro-Symbolic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kohaut",
        "Benedict Flade",
        "Daniel Ochs",
        "Devendra Singh Dhami",
        "Julian Eggert",
        "Kristian Kersting"
      ],
      "abstract": "Advanced Air Mobility (AAM) is a growing field that demands accurate modeling\nof legal concepts and restrictions in navigating intelligent vehicles. In\naddition, any implementation of AAM needs to face the challenges posed by\ninherently dynamic and uncertain human-inhabited spaces robustly. Nevertheless,\nthe employment of Unmanned Aircraft Systems (UAS) beyond visual line of sight\n(BVLOS) is an endearing task that promises to enhance significantly today's\nlogistics and emergency response capabilities. To tackle these challenges, we\npresent a probabilistic and neuro-symbolic architecture to encode legal\nframeworks and expert knowledge over uncertain spatial relations and noisy\nperception in an interpretable and adaptable fashion. More specifically, we\ndemonstrate Probabilistic Mission Design (ProMis), a system architecture that\nlinks geospatial and sensory data with declarative, Hybrid Probabilistic Logic\nPrograms (HPLP) to reason over the agent's state space and its legality. As a\nresult, ProMis generates Probabilistic Mission Landscapes (PML), which quantify\nthe agent's belief that a set of mission conditions is satisfied across its\nnavigation space. Extending prior work on ProMis' reasoning capabilities and\ncomputational characteristics, we show its integration with potent machine\nlearning models such as Large Language Models (LLM) and Transformer-based\nvision models. Hence, our experiments underpin the application of ProMis with\nmulti-modal input data and how our method applies to many important AAM\nscenarios.",
      "tldr_zh": "本研究针对 Advanced Air Mobility (AAM) 领域中智能车辆导航的法律限制和不确定环境挑战，提出了一种概率化和神经符号架构——Probabilistic Mission Design (ProMis)。ProMis 通过将地理空间数据、传感器输入与 Hybrid Probabilistic Logic Programs (HPLP) 相结合，进行代理状态空间的推理，生成 Probabilistic Mission Landscapes (PML) 来量化任务条件在导航空间中的满足可能性。实验结果展示了 ProMis 与 Large Language Models (LLM) 和 Transformer-based 视觉模型的整合，提升了系统在多模态数据下的鲁棒性和适应性，为 UAS 的超出视距 (BVLOS) 操作提供可解释的解决方案。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2406.03454",
      "pdf_url": "http://arxiv.org/pdf/2501.01439v1",
      "published_date": "2024-12-25 11:04:00 UTC",
      "updated_date": "2024-12-25 11:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:37:46.823293"
    },
    {
      "arxiv_id": "2412.18863v1",
      "title": "Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Meltem Aksoy"
      ],
      "abstract": "Large language models (LLMs) have become integral tools in diverse domains,\nyet their moral reasoning capabilities across cultural and linguistic contexts\nremain underexplored. This study investigates whether multilingual LLMs, such\nas GPT-3.5-Turbo, GPT-4o-mini, Llama 3.1, and MistralNeMo, reflect culturally\nspecific moral values or impose dominant moral norms, particularly those rooted\nin English. Using the updated Moral Foundations Questionnaire (MFQ-2) in eight\nlanguages, Arabic, Farsi, English, Spanish, Japanese, Chinese, French, and\nRussian, the study analyzes the models' adherence to six core moral\nfoundations: care, equality, proportionality, loyalty, authority, and purity.\nThe results reveal significant cultural and linguistic variability, challenging\nthe assumption of universal moral consistency in LLMs. Although some models\ndemonstrate adaptability to diverse contexts, others exhibit biases influenced\nby the composition of the training data. These findings underscore the need for\nculturally inclusive model development to improve fairness and trust in\nmultilingual AI systems.",
      "tldr_zh": "这篇论文探讨了多语言大型语言模型 (LLMs) 在不同文化和语言背景下的道德推理能力，调查了模型如 GPT-3.5-Turbo、GPT-4o-mini、Llama 3.1 和 MistralNeMo 是否反映特定文化价值观或强加英语主导规范。研究者使用更新后的 Moral Foundations Questionnaire (MFQ-2) 在八种语言（包括 Arabic、Farsi、English 等）上评估了六个核心道德基础：care、equality、proportionality、loyalty、authority 和 purity。结果显示模型存在显著的文化和语言变异性，挑战了 LLMs 道德一致性的假设，有些模型受训练数据偏见影响。论文强调，需要开发文化包容性的模型，以提高多语言 AI 系统的公平性和可信度。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18863v1",
      "published_date": "2024-12-25 10:17:15 UTC",
      "updated_date": "2024-12-25 10:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:37:59.026393"
    },
    {
      "arxiv_id": "2412.18862v3",
      "title": "WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via Gaussian Splatting",
      "title_zh": "翻译失败",
      "authors": [
        "Chenghao Qian",
        "Yuhu Guo",
        "Wenjing Li",
        "Gustav Markkula"
      ],
      "abstract": "3D Gaussian Splatting (3DGS) has gained significant attention for 3D scene\nreconstruction, but still suffers from complex outdoor environments, especially\nunder adverse weather. This is because 3DGS treats the artifacts caused by\nadverse weather as part of the scene and will directly reconstruct them,\nlargely reducing the clarity of the reconstructed scene. To address this\nchallenge, we propose WeatherGS, a 3DGS-based framework for reconstructing\nclear scenes from multi-view images under different weather conditions.\nSpecifically, we explicitly categorize the multi-weather artifacts into the\ndense particles and lens occlusions that have very different characters, in\nwhich the former are caused by snowflakes and raindrops in the air, and the\nlatter are raised by the precipitation on the camera lens. In light of this, we\npropose a dense-to-sparse preprocess strategy, which sequentially removes the\ndense particles by an Atmospheric Effect Filter (AEF) and then extracts the\nrelatively sparse occlusion masks with a Lens Effect Detector (LED). Finally,\nwe train a set of 3D Gaussians by the processed images and generated masks for\nexcluding occluded areas, and accurately recover the underlying clear scene by\nGaussian splatting. We conduct a diverse and challenging benchmark to\nfacilitate the evaluation of 3D reconstruction under complex weather scenarios.\nExtensive experiments on this benchmark demonstrate that our WeatherGS\nconsistently produces high-quality, clean scenes across various weather\nscenarios, outperforming existing state-of-the-art methods. See project\npage:https://jumponthemoon.github.io/weather-gs.",
      "tldr_zh": "这篇论文提出了WeatherGS，一种基于3D Gaussian Splatting (3DGS)的框架，用于从多视图图像中重建恶劣天气条件下清晰的3D场景，以解决传统3DGS将天气伪像（如雪花或雨滴）视为场景部分的问题。框架的关键方法包括将天气伪像分类为密集粒子和镜头遮挡，并采用密集到稀疏预处理策略：使用Atmospheric Effect Filter (AEF)移除密集粒子，以及Lens Effect Detector (LED)提取遮挡掩码，然后通过训练3D Gaussians排除遮挡区域来准确恢复底层场景。实验在多样且具有挑战性的基准数据集上验证，WeatherGS在各种天气场景下显著优于现有最先进方法，提供高质量的重建结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18862v3",
      "published_date": "2024-12-25 10:16:57 UTC",
      "updated_date": "2025-02-12 03:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:38:11.016923"
    },
    {
      "arxiv_id": "2501.05460v2",
      "title": "Efficiently Serving Large Multimodal Models Using EPD Disaggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Gursimran Singh",
        "Xinglu Wang",
        "Yifan Hu",
        "Timothy Yu",
        "Linzi Xing",
        "Wei Jiang",
        "Zhefeng Wang",
        "Xiaolong Bai",
        "Yi Li",
        "Ying Xiong",
        "Yong Zhang",
        "Zhenan Fan"
      ],
      "abstract": "Large Multimodal Models (LMMs) extend Large Language Models (LLMs) by\nhandling diverse inputs such as images, audio, and video, but at the cost of\nadding a multimodal encoding stage that increases both computational and memory\noverhead. This step negatively impacting key Service Level Objectives (SLOs)\nlike time to first token (TTFT) and end-to-end throughput (E2ETP). We introduce\nEncode-Prefill-Decode (EPD) Disaggregation, a novel framework that separates\nthe encoding, prefill, and decode stages onto dedicated resources. Unlike\ncurrent systems, which bundle encoding and prefill together, our approach\ndecouple these steps unlocking new opportunities and optimizations. These\ninclude a new mechanism to cache multimedia tokens for efficient transfer, a\nnovel way to parallelize encoding load within a request, a module to find the\noptimal resource allocation for disaggregated serving, and a novel role\nswitching method to handle changing workload characteristics. Experimental\nevaluations with popular LMMs show substantial gains in memory efficiency (up\nto 15$\\times$ less utilization), batch sizes (up to 22$\\times$ larger),\n10$\\times$ more images/request, and 2.2$\\times$ larger KV caches. Further, it\nleads to significant improvements in latency metrics (TTFT up to 71\\%\nreduction) and end-to-end throughput (up to 57\\% reduction), compared to\nsystems that do not disaggregate.",
      "tldr_zh": "本文提出了一种名为 EPD Disaggregation 的框架，用于高效服务 Large Multimodal Models (LMMs)，通过将编码、预填充和解码阶段分离到专用资源上，解决多模态输入带来的计算和内存开销问题，从而改善 Service Level Objectives (SLOs) 如 TTFT 和 E2ETP。框架引入了缓存多媒体 token 的机制、请求内编码负载的并行化、最优资源分配模块以及角色切换方法，以优化系统性能。实验结果显示，与传统系统相比，该框架实现了内存效率提高至多 15 倍、批处理大小增加至多 22 倍、每请求图像数量增加 10 倍，以及 TTFT 延迟减少至多 71% 和端到端吞吐量改善至多 57%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "16 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.05460v2",
      "published_date": "2024-12-25 10:11:31 UTC",
      "updated_date": "2025-02-05 22:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:38:25.535887"
    },
    {
      "arxiv_id": "2412.18857v1",
      "title": "Computing Approximate Graph Edit Distance via Optimal Transport",
      "title_zh": "通过最优传输计算近似图编辑距离",
      "authors": [
        "Qihao Cheng",
        "Da Yan",
        "Tianhao Wu",
        "Zhongyi Huang",
        "Qin Zhang"
      ],
      "abstract": "Given a graph pair $(G^1, G^2)$, graph edit distance (GED) is defined as the\nminimum number of edit operations converting $G^1$ to $G^2$. GED is a\nfundamental operation widely used in many applications, but its exact\ncomputation is NP-hard, so the approximation of GED has gained a lot of\nattention. Data-driven learning-based methods have been found to provide\nsuperior results compared to classical approximate algorithms, but they\ndirectly fit the coupling relationship between a pair of vertices from their\nvertex features. We argue that while pairwise vertex features can capture the\ncoupling cost (discrepancy) of a pair of vertices, the vertex coupling matrix\nshould be derived from the vertex-pair cost matrix through a more\nwell-established method that is aware of the global context of the graph pair,\nsuch as optimal transport. In this paper, we propose an ensemble approach that\nintegrates a supervised learning-based method and an unsupervised method, both\nbased on optimal transport. Our learning method, GEDIOT, is based on inverse\noptimal transport that leverages a learnable Sinkhorn algorithm to generate the\ncoupling matrix. Our unsupervised method, GEDGW, models GED computation as a\nlinear combination of optimal transport and its variant, Gromov-Wasserstein\ndiscrepancy, for node and edge operations, respectively, which can be solved\nefficiently without needing the ground truth. Our ensemble method, GEDHOT,\ncombines GEDIOT and GEDGW to further boost the performance. Extensive\nexperiments demonstrate that our methods significantly outperform the existing\nmethods in terms of the performance of GED computation, edit path generation,\nand model generalizability.",
      "tldr_zh": "这篇论文提出了一种基于 Optimal Transport 的方法来近似计算 Graph Edit Distance (GED)，旨在解决 GED 计算的 NP-hard 问题，并超越传统数据驱动方法。作者开发了 GEDIOT（利用逆 Optimal Transport 和可学习 Sinkhorn 算法生成耦合矩阵的监督学习方法）和 GEDGW（将 GED 建模为 Optimal Transport 与 Gromov-Wasserstein 差异的线性组合的无监督方法），并通过集成方法 GEDHOT 结合两者以提升性能。实验结果表明，这些方法在 GED 计算、编辑路径生成和模型泛化性上显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SIGMOD2025. 26 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18857v1",
      "published_date": "2024-12-25 09:55:14 UTC",
      "updated_date": "2024-12-25 09:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:38:34.867104"
    },
    {
      "arxiv_id": "2412.19847v1",
      "title": "Symbolic Disentangled Representations for Images",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandr Korchemnyi",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "The idea of disentangled representations is to reduce the data to a set of\ngenerative factors that produce it. Typically, such representations are vectors\nin latent space, where each coordinate corresponds to one of the generative\nfactors. The object can then be modified by changing the value of a particular\ncoordinate, but it is necessary to determine which coordinate corresponds to\nthe desired generative factor -- a difficult task if the vector representation\nhas a high dimension. In this article, we propose ArSyD (Architecture for\nSymbolic Disentanglement), which represents each generative factor as a vector\nof the same dimension as the resulting representation. In ArSyD, the object\nrepresentation is obtained as a superposition of the generative factor vector\nrepresentations. We call such a representation a \\textit{symbolic disentangled\nrepresentation}. We use the principles of Hyperdimensional Computing (also\nknown as Vector Symbolic Architectures), where symbols are represented as\nhypervectors, allowing vector operations on them. Disentanglement is achieved\nby construction, no additional assumptions about the underlying distributions\nare made during training, and the model is only trained to reconstruct images\nin a weakly supervised manner. We study ArSyD on the dSprites and CLEVR\ndatasets and provide a comprehensive analysis of the learned symbolic\ndisentangled representations. We also propose new disentanglement metrics that\nallow comparison of methods using latent representations of different\ndimensions. ArSyD allows to edit the object properties in a controlled and\ninterpretable way, and the dimensionality of the object property representation\ncoincides with the dimensionality of the object representation itself.",
      "tldr_zh": "本论文提出ArSyD（Architecture for Symbolic Disentanglement），一种用于图像的符号解缠表示（symbolic disentangled representations），旨在解决传统潜空间向量表示中高维度下难以识别生成因子的难题。ArSyD通过将每个生成因子表示为与结果表示相同维度的向量，并使用Hyperdimensional Computing（也称为Vector Symbolic Architectures）的原理，将对象表示作为这些向量的叠加，从而实现解缠。模型仅通过弱监督训练图像重建，无需额外分布假设，并在dSprites和CLEVR数据集上进行全面分析，展示了可控、可解释的对象属性编辑能力。论文还引入新的解缠度量指标，用于比较不同维度潜表示的方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19847v1",
      "published_date": "2024-12-25 09:20:13 UTC",
      "updated_date": "2024-12-25 09:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:38:46.185112"
    },
    {
      "arxiv_id": "2412.18840v2",
      "title": "Implicit factorized transformer approach to fast prediction of turbulent channel flows",
      "title_zh": "隐式因子化 Transformer 方法用于湍流通道流动的快速预测",
      "authors": [
        "Huiyu Yang",
        "Yunpeng Wang",
        "Jianchun Wang"
      ],
      "abstract": "Transformer neural operators have recently become an effective approach for\nsurrogate modeling of systems governed by partial differential equations\n(PDEs). In this paper, we introduce a modified implicit factorized transformer\n(IFactFormer-m) model which replaces the original chained factorized attention\nwith parallel factorized attention. The IFactFormer-m model successfully\nperforms long-term predictions for turbulent channel flow, whereas the original\nIFactFormer (IFactFormer-o), Fourier neural operator (FNO), and implicit\nFourier neural operator (IFNO) exhibit a poor performance. Turbulent channel\nflows are simulated by direct numerical simulation using fine grids at friction\nReynolds numbers $\\text{Re}_{\\tau}\\approx 180,395,590$, and filtered to coarse\ngrids for training neural operator. The neural operator takes the current flow\nfield as input and predicts the flow field at the next time step, and long-term\nprediction is achieved in the posterior through an autoregressive approach. The\nresults show that IFactFormer-m, compared to other neural operators and the\ntraditional large eddy simulation (LES) methods including dynamic Smagorinsky\nmodel (DSM) and the wall-adapted local eddy-viscosity (WALE) model, reduces\nprediction errors in the short term, and achieves stable and accurate long-term\nprediction of various statistical properties and flow structures, including the\nenergy spectrum, mean streamwise velocity, root mean square (rms) values of\nfluctuating velocities, Reynolds shear stress, and spatial structures of\ninstantaneous velocity. Moreover, the trained IFactFormer-m is much faster than\ntraditional LES methods. By analyzing the attention kernels, we elucidate the\nreasons why IFactFormer-m converges faster and achieves a stable and accurate\nlong-term prediction compared to IFactFormer-o. Code and data are available at:\nhttps://github.com/huiyu-2002/IFactFormer-m.",
      "tldr_zh": "本文提出了一种修改后的隐式因子化 Transformer 模型（IFactFormer-m），通过将链式因子化注意力替换为平行因子化注意力，以实现对湍流通道流的快速和准确预测。该模型基于直接数值模拟（DNS）在摩擦雷诺数 Reτ ≈ 180, 395, 590 的数据，通过自回归方法进行长期预测，并显著优于原版 IFactFormer-o、Fourier neural operator (FNO) 和 implicit Fourier neural operator (IFNO)。实验结果显示，IFactFormer-m 在短期和长期预测中减少了错误，准确捕捉了能量谱、平均流速、波动速度的均方根值以及流体结构等统计属性，且其计算速度远超传统大涡模拟方法如 dynamic Smagorinsky model (DSM) 和 WALE 模型。通过分析注意力内核，该模型的更快收敛和稳定性得到了解释。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18840v2",
      "published_date": "2024-12-25 09:05:14 UTC",
      "updated_date": "2025-02-26 07:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:38:59.800248"
    },
    {
      "arxiv_id": "2412.18839v2",
      "title": "Advancing NAM-to-Speech Conversion with Novel Methods and the MultiNAM Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Neil Shah",
        "Shirish Karande",
        "Vineet Gandhi"
      ],
      "abstract": "Current Non-Audible Murmur (NAM)-to-speech techniques rely on voice cloning\nto simulate ground-truth speech from paired whispers. However, the simulated\nspeech often lacks intelligibility and fails to generalize well across\ndifferent speakers. To address this issue, we focus on learning phoneme-level\nalignments from paired whispers and text and employ a Text-to-Speech (TTS)\nsystem to simulate the ground-truth. To reduce dependence on whispers, we learn\nphoneme alignments directly from NAMs, though the quality is constrained by the\navailable training data. To further mitigate reliance on NAM/whisper data for\nground-truth simulation, we propose incorporating the lip modality to infer\nspeech and introduce a novel diffusion-based method that leverages recent\nadvancements in lip-to-speech technology. Additionally, we release the MultiNAM\ndataset with over 7.96 hours of paired NAM, whisper, video, and text data from\ntwo speakers and benchmark all methods on this dataset. Speech samples and the\ndataset are available at https://diff-nam.github.io/DiffNAM/",
      "tldr_zh": "本文提出改进 Non-Audible Murmur (NAM)-to-speech 转换的新方法，以解决现有技术依赖语音克隆导致的语音可理解性和泛化性问题。主要方法包括从配对耳语和文本学习音素级对齐、采用 Text-to-Speech (TTS) 系统模拟真实语音、直接从 NAM 学习对齐，以及引入唇部模态并使用新型 diffusion-based 方法来减少对耳语数据的依赖。为支持研究，论文发布了 MultiNAM 数据集，包含超过7.96小时的配对 NAM、耳语、视频和文本数据，并在此数据集上基准测试了所有方法，展示了方法的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at IEEE ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18839v2",
      "published_date": "2024-12-25 08:57:24 UTC",
      "updated_date": "2025-01-23 05:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:41:04.319870"
    },
    {
      "arxiv_id": "2412.18836v2",
      "title": "MRI2Speech: Speech Synthesis from Articulatory Movements Recorded by Real-time MRI",
      "title_zh": "MRI2Speech：基于实时 MRI 记录的发音运动的",
      "authors": [
        "Neil Shah",
        "Ayan Kashyap",
        "Shirish Karande",
        "Vineet Gandhi"
      ],
      "abstract": "Previous real-time MRI (rtMRI)-based speech synthesis models depend heavily\non noisy ground-truth speech. Applying loss directly over ground truth\nmel-spectrograms entangles speech content with MRI noise, resulting in poor\nintelligibility. We introduce a novel approach that adapts the multi-modal\nself-supervised AV-HuBERT model for text prediction from rtMRI and incorporates\na new flow-based duration predictor for speaker-specific alignment. The\npredicted text and durations are then used by a speech decoder to synthesize\naligned speech in any novel voice. We conduct thorough experiments on two\ndatasets and demonstrate our method's generalization ability to unseen\nspeakers. We assess our framework's performance by masking parts of the rtMRI\nvideo to evaluate the impact of different articulators on text prediction. Our\nmethod achieves a $15.18\\%$ Word Error Rate (WER) on the USC-TIMIT MRI corpus,\nmarking a huge improvement over the current state-of-the-art. Speech samples\nare available at https://mri2speech.github.io/MRI2Speech/",
      "tldr_zh": "该研究提出了一种名为 MRI2Speech 的新方法，用于从实时 MRI (rtMRI) 记录的关节运动合成语音，解决了传统模型因依赖嘈杂的 ground-truth speech 而导致的语音可懂度问题。该方法通过适应多模态自监督模型 AV-HuBERT 来预测文本，并引入一个新的 flow-based duration predictor 以实现说话者特定的时长对齐，随后使用语音解码器合成任何新语音。实验在两个数据集上验证了该方法的泛化能力，包括对未见说话者的适应，并通过遮挡 rtMRI 视频评估不同关节的影响，最终在 USC-TIMIT MRI 语料库上实现了 15.18% 的 Word Error Rate (WER)，比现有最先进技术有显著改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at IEEE ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18836v2",
      "published_date": "2024-12-25 08:49:43 UTC",
      "updated_date": "2025-01-17 12:18:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:39:24.846928"
    },
    {
      "arxiv_id": "2412.18827v1",
      "title": "PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph Structure Generation",
      "title_zh": "翻译失败",
      "authors": [
        "ChenRui Duan",
        "Zelin Zang",
        "Siyuan Li",
        "Yongjie Xu",
        "Stan Z. Li"
      ],
      "abstract": "Phylogenetic trees elucidate evolutionary relationships among species, but\nphylogenetic inference remains challenging due to the complexity of combining\ncontinuous (branch lengths) and discrete parameters (tree topology).\nTraditional Markov Chain Monte Carlo methods face slow convergence and\ncomputational burdens. Existing Variational Inference methods, which require\npre-generated topologies and typically treat tree structures and branch lengths\nindependently, may overlook critical sequence features, limiting their accuracy\nand flexibility. We propose PhyloGen, a novel method leveraging a pre-trained\ngenomic language model to generate and optimize phylogenetic trees without\ndependence on evolutionary models or aligned sequence constraints. PhyloGen\nviews phylogenetic inference as a conditionally constrained tree structure\ngeneration problem, jointly optimizing tree topology and branch lengths through\nthree core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and\n(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function\nto guide the model towards a more stable gradient descent. We demonstrate the\neffectiveness and robustness of PhyloGen on eight real-world benchmark\ndatasets. Visualization results confirm PhyloGen provides deeper insights into\nphylogenetic relationships.",
      "tldr_zh": "该论文提出 PhyloGen，一种利用预训练基因组语言模型增强的进化树推断方法，旨在解决传统 Markov Chain Monte Carlo 方法的慢速收敛和计算负担，以及现有 Variational Inference 方法对树拓扑和分支长度的独立处理导致的准确性问题。PhyloGen 将进化树推断视为有条件约束的树结构生成问题，通过三个核心模块——Feature Extraction、PhyloTree Construction 和 PhyloTree Structure Modeling——联合优化树拓扑和分支长度，并引入 Scoring Function 来指导更稳定的梯度下降。在八个真实世界基准数据集上，PhyloGen 展示了显著的有效性和鲁棒性，可视化结果提供了更深入的 phylogenetic relationships 洞见。",
      "categories": [
        "q-bio.PE",
        "cs.AI"
      ],
      "primary_category": "q-bio.PE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18827v1",
      "published_date": "2024-12-25 08:33:05 UTC",
      "updated_date": "2024-12-25 08:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:39:35.813781"
    },
    {
      "arxiv_id": "2412.18819v2",
      "title": "LLM-assisted Vector Similarity Search",
      "title_zh": "LLM 辅助向量相似性搜索",
      "authors": [
        "Md Riyadh",
        "Muqi Li",
        "Felix Haryanto Lie",
        "Jia Long Loh",
        "Haotian Mi",
        "Sayam Bohra"
      ],
      "abstract": "As data retrieval demands become increasingly complex, traditional search\nmethods often fall short in addressing nuanced and conceptual queries. Vector\nsimilarity search has emerged as a promising technique for finding semantically\nsimilar information efficiently. However, its effectiveness diminishes when\nhandling intricate queries with contextual nuances. This paper explores a\nhybrid approach combining vector similarity search with Large Language Models\n(LLMs) to enhance search accuracy and relevance. The proposed two-step solution\nfirst employs vector similarity search to shortlist potential matches, followed\nby an LLM for context-aware ranking of the results. Experiments on structured\ndatasets demonstrate that while vector similarity search alone performs well\nfor straightforward queries, the LLM-assisted approach excels in processing\ncomplex queries involving constraints, negations, or conceptual requirements.\nBy leveraging the natural language understanding capabilities of LLMs, this\nmethod improves the accuracy of search results for complex tasks without\nsacrificing efficiency. We also discuss real-world applications and propose\ndirections for future research to refine and scale this technique for diverse\ndatasets and use cases.\n  Original article:\nhttps://engineering.grab.com/llm-assisted-vector-similarity-search",
      "tldr_zh": "这篇论文探讨了传统搜索方法在处理复杂查询时的局限性，并提出了一种结合向量相似性搜索（vector similarity search）和大型语言模型（Large Language Models, LLMs）的混合方法，以提升搜索的准确性和相关性。该方法采用两步流程：首先使用向量相似性搜索筛选潜在匹配项，然后由 LLM 进行基于上下文的排名。实验结果显示，在结构化数据集上，该方法在处理涉及约束、否定或概念要求的复杂查询时，显著优于单纯的向量搜索，提高了搜索精度，同时保持了效率。该方法的应用前景广阔，并为未来研究提供了方向，如扩展到多样化数据集和场景。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18819v2",
      "published_date": "2024-12-25 08:17:37 UTC",
      "updated_date": "2024-12-30 04:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:39:46.779932"
    },
    {
      "arxiv_id": "2412.18816v1",
      "title": "GSAVS: Gaussian Splatting-based Autonomous Vehicle Simulator",
      "title_zh": "GSAVS：基于高斯喷溅的自动驾驶车辆模拟器",
      "authors": [
        "Rami Wilson"
      ],
      "abstract": "Modern autonomous vehicle simulators feature an ever-growing library of\nassets, including vehicles, buildings, roads, pedestrians, and more. While this\nlevel of customization proves beneficial when creating virtual urban\nenvironments, this process becomes cumbersome when intending to train within a\ndigital twin or a duplicate of a real scene. Gaussian splatting emerged as a\npowerful technique in scene reconstruction and novel view synthesis, boasting\nhigh fidelity and rendering speeds. In this paper, we introduce GSAVS, an\nautonomous vehicle simulator that supports the creation and development of\nautonomous vehicle models. Every asset within the simulator is a 3D Gaussian\nsplat, including the vehicles and the environment. However, the simulator runs\nwithin a classical 3D engine, rendering 3D Gaussian splats in real-time. This\nallows the simulator to utilize the photorealism that 3D Gaussian splatting\nboasts while providing the customization and ease of use of a classical 3D\nengine.",
      "tldr_zh": "该论文提出 GSAVS，一种基于 Gaussian splatting 的自动驾驶车辆模拟器，旨在简化真实场景数字孪生的创建过程。GSAVS 将所有资产（如车辆和环境）表示为 3D Gaussian splats，并在经典 3D 引擎中实现实时渲染，从而结合了 Gaussian splatting 的高保真度和快速渲染优势。相比传统模拟器，这方法提升了自定义易用性，并为自动驾驶模型的开发提供了更高效的训练环境。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18816v1",
      "published_date": "2024-12-25 07:52:09 UTC",
      "updated_date": "2024-12-25 07:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:39:59.339068"
    },
    {
      "arxiv_id": "2412.18798v2",
      "title": "Ister: Inverted Seasonal-Trend Decomposition Transformer for Explainable Multivariate Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Fanpu Cao",
        "Shu Yang",
        "Zhengjian Chen",
        "Ye Liu",
        "Laizhong Cui"
      ],
      "abstract": "In long-term time series forecasting, Transformer-based models have achieved\ngreat success, due to its ability to capture long-range dependencies. However,\nexisting models face challenges in identifying critical components for\nprediction, leading to limited interpretability and suboptimal performance. To\naddress these issues, we propose the Inverted Seasonal-Trend Decomposition\nTransformer (Ister), a novel Transformer-based model for multivariate time\nseries forecasting. Ister decomposes time series into seasonal and trend\ncomponents, further modeling multi-periodicity and inter-series dependencies\nusing a Dual Transformer architecture. We introduce a novel Dot-attention\nmechanism that improves interpretability, computational efficiency, and\npredictive accuracy. Comprehensive experiments on benchmark datasets\ndemonstrate that Ister outperforms existing state-of-the-art models, achieving\nup to 10% improvement in MSE. Moreover, Ister enables intuitive visualization\nof component contributions, shedding lights on model's decision process and\nenhancing transparency in prediction results.",
      "tldr_zh": "本研究提出 Ister，一种基于 Transformer 的模型，用于可解释的多变量时间序列预测，以解决现有模型在识别关键组件方面导致的解释性和性能问题。Ister 通过季节-趋势分解将时间序列拆解成季节性和趋势组件，并采用 Dual Transformer 架构和新型 Dot-attention 机制来建模多周期性和系列间依赖，从而提升解释性、计算效率和预测准确性。在基准数据集上的实验表明，Ister 比现有最先进模型改善高达 10% 的 MSE，并通过直观的可视化展示组件贡献，提高预测结果的透明度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18798v2",
      "published_date": "2024-12-25 06:37:19 UTC",
      "updated_date": "2025-01-25 13:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:40:10.730972"
    },
    {
      "arxiv_id": "2412.18790v1",
      "title": "Torque-Aware Momentum",
      "title_zh": "翻译失败",
      "authors": [
        "Pranshu Malviya",
        "Goncalo Mordido",
        "Aristide Baratin",
        "Reza Babanezhad Harikandeh",
        "Gintare Karolina Dziugaite",
        "Razvan Pascanu",
        "Sarath Chandar"
      ],
      "abstract": "Efficiently exploring complex loss landscapes is key to the performance of\ndeep neural networks. While momentum-based optimizers are widely used in\nstate-of-the-art setups, classical momentum can still struggle with large,\nmisaligned gradients, leading to oscillations. To address this, we propose\nTorque-Aware Momentum (TAM), which introduces a damping factor based on the\nangle between the new gradients and previous momentum, stabilizing the update\ndirection during training. Empirical results show that TAM, which can be\ncombined with both SGD and Adam, enhances exploration, handles distribution\nshifts more effectively, and improves generalization performance across various\ntasks, including image classification and large language model fine-tuning,\nwhen compared to classical momentum-based optimizers.",
      "tldr_zh": "该研究提出 Torque-Aware Momentum (TAM)，一种改进动量优化器的方法，用于高效探索深度神经网络的复杂损失景观，解决经典动量在面对大且不一致梯度时出现的震荡问题。TAM 通过引入基于新梯度与之前动量角度的阻尼因子来稳定训练更新方向，并可与 SGD 和 Adam 优化器无缝结合。实验结果表明，TAM 提升了模型的探索能力、更有效地处理分布偏移，并在图像分类和大语言模型微调等任务上实现了更好的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18790v1",
      "published_date": "2024-12-25 05:58:07 UTC",
      "updated_date": "2024-12-25 05:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:40:23.191778"
    },
    {
      "arxiv_id": "2412.18780v1",
      "title": "Skeleton-based Action Recognition with Non-linear Dependency Modeling and Hilbert-Schmidt Independence Criterion",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Yang"
      ],
      "abstract": "Human skeleton-based action recognition has long been an indispensable aspect\nof artificial intelligence. Current state-of-the-art methods tend to consider\nonly the dependencies between connected skeletal joints, limiting their ability\nto capture non-linear dependencies between physically distant joints. Moreover,\nmost existing approaches distinguish action classes by estimating the\nprobability density of motion representations, yet the high-dimensional nature\nof human motions invokes inherent difficulties in accomplishing such\nmeasurements. In this paper, we seek to tackle these challenges from two\ndirections: (1) We propose a novel dependency refinement approach that\nexplicitly models dependencies between any pair of joints, effectively\ntranscending the limitations imposed by joint distance. (2) We further propose\na framework that utilizes the Hilbert-Schmidt Independence Criterion to\ndifferentiate action classes without being affected by data dimensionality, and\nmathematically derive learning objectives guaranteeing precise recognition.\nEmpirically, our approach sets the state-of-the-art performance on NTU RGB+D,\nNTU RGB+D 120, and Northwestern-UCLA datasets.",
      "tldr_zh": "这项研究针对基于骨骼的人类动作识别问题，指出现有方法仅考虑连接关节间的依赖性，而忽略了物理距离远的关节之间的非线性依赖，以及高维数据在概率密度估计中的挑战。作者提出了一种新颖的依赖性精炼方法，能够显式建模任意关节对之间的依赖性，从而超越关节距离的限制。论文进一步引入Hilbert-Schmidt Independence Criterion (HSIC)框架，用于区分动作类别，避免数据维度影响，并推导了精确识别的学习目标。在NTU RGB+D、NTU RGB+D 120和Northwestern-UCLA数据集上，该方法实现了最先进的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18780v1",
      "published_date": "2024-12-25 05:02:11 UTC",
      "updated_date": "2024-12-25 05:02:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:40:34.608114"
    },
    {
      "arxiv_id": "2412.18778v1",
      "title": "Unified Local and Global Attention Interaction Modeling for Vision Transformers",
      "title_zh": "视觉变压器的统一局部和全局注意力交互建模",
      "authors": [
        "Tan Nguyen",
        "Coy D. Heldermon",
        "Corey Toler-Franklin"
      ],
      "abstract": "We present a novel method that extends the self-attention mechanism of a\nvision transformer (ViT) for more accurate object detection across diverse\ndatasets. ViTs show strong capability for image understanding tasks such as\nobject detection, segmentation, and classification. This is due in part to\ntheir ability to leverage global information from interactions among visual\ntokens. However, the self-attention mechanism in ViTs are limited because they\ndo not allow visual tokens to exchange local or global information with\nneighboring features before computing global attention. This is problematic\nbecause tokens are treated in isolation when attending (matching) to other\ntokens, and valuable spatial relationships are overlooked. This isolation is\nfurther compounded by dot-product similarity operations that make tokens from\ndifferent semantic classes appear visually similar. To address these\nlimitations, we introduce two modifications to the traditional self-attention\nframework; a novel aggressive convolution pooling strategy for local feature\nmixing, and a new conceptual attention transformation to facilitate interaction\nand feature exchange between semantic concepts. Experimental results\ndemonstrate that local and global information exchange among visual features\nbefore self-attention significantly improves performance on challenging object\ndetection tasks and generalizes across multiple benchmark datasets and\nchallenging medical datasets. We publish source code and a novel dataset of\ncancerous tumors (chimeric cell clusters).",
      "tldr_zh": "该论文提出了一种新方法，用于扩展 Vision Transformers (ViT) 的自注意力机制，以提升物体检测的准确性。该方法通过引入 aggressive convolution pooling 策略来实现本地特征混合，以及 conceptual attention transformation 来促进语义概念之间的交互和特征交换，从而解决传统自注意力中视觉标记孤立处理和空间关系忽略的问题。实验结果显示，这种本地和全局信息交换显著提高了物体检测任务的性能，并在多个基准数据集和医学数据集上实现泛化；此外，论文还发布了源代码和一个新的癌症肿瘤数据集（chimeric cell clusters）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.5.0, I.5.4, I.4.0"
      ],
      "primary_category": "cs.CV",
      "comment": "20 Pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18778v1",
      "published_date": "2024-12-25 04:53:19 UTC",
      "updated_date": "2024-12-25 04:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:40:46.886554"
    },
    {
      "arxiv_id": "2412.18775v1",
      "title": "ObitoNet: Multimodal High-Resolution Point Cloud Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Apoorv Thapliyal",
        "Vinay Lanka",
        "Swathi Baskaran"
      ],
      "abstract": "ObitoNet employs a Cross Attention mechanism to integrate multimodal inputs,\nwhere Vision Transformers (ViT) extract semantic features from images and a\npoint cloud tokenizer processes geometric information using Farthest Point\nSampling (FPS) and K Nearest Neighbors (KNN) for spatial structure capture. The\nlearned multimodal features are fed into a transformer-based decoder for\nhigh-resolution point cloud reconstruction. This approach leverages the\ncomplementary strengths of both modalities rich image features and precise\ngeometric details ensuring robust point cloud generation even in challenging\nconditions such as sparse or noisy data.",
      "tldr_zh": "该论文提出了一种名为 ObitoNet 的多模态高分辨率点云重建框架，使用 Cross Attention 机制整合图像和点云输入。框架中，Vision Transformers (ViT) 从图像中提取语义特征，而点云 tokenizer 通过 Farthest Point Sampling (FPS) 和 K Nearest Neighbors (KNN) 处理几何信息，以捕捉空间结构。最终，将这些多模态特征输入基于 Transformer 的解码器，实现稳健的点云重建，尤其在稀疏或噪声数据条件下，利用图像的丰富特征和点云的精确细节提升了重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18775v1",
      "published_date": "2024-12-25 04:34:22 UTC",
      "updated_date": "2024-12-25 04:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:43:00.017758"
    },
    {
      "arxiv_id": "2412.19845v1",
      "title": "Unveiling Secrets of Brain Function With Generative Modeling: Motion Perception in Primates & Cortical Network Organization in Mice",
      "title_zh": "翻译失败",
      "authors": [
        "Hadi Vafaii"
      ],
      "abstract": "This Dissertation is comprised of two main projects, addressing questions in\nneuroscience through applications of generative modeling.\n  Project #1 (Chapter 4) explores how neurons encode features of the external\nworld. I combine Helmholtz's \"Perception as Unconscious Inference\" --\nparalleled by modern generative models like variational autoencoders (VAE) --\nwith the hierarchical structure of the visual cortex. This combination leads to\nthe development of a hierarchical VAE model, which I test for its ability to\nmimic neurons from the primate visual cortex in response to motion stimuli.\nResults show that the hierarchical VAE perceives motion similar to the primate\nbrain. Additionally, the model identifies causal factors of retinal motion\ninputs, such as object- and self-motion, in a completely unsupervised manner.\nCollectively, these results suggest that hierarchical inference underlines the\nbrain's understanding of the world, and hierarchical VAEs can effectively model\nthis understanding.\n  Project #2 (Chapter 5) investigates the spatiotemporal structure of\nspontaneous brain activity and its reflection of brain states like rest. Using\nsimultaneous fMRI and wide-field Ca2+ imaging data, this project demonstrates\nthat the mouse cortex can be decomposed into overlapping communities, with\naround half of the cortical regions belonging to multiple communities.\nComparisons reveal similarities and differences between networks inferred from\nfMRI and Ca2+ signals.\n  The introduction (Chapter 1) is divided similarly to this abstract: sections\n1.1 to 1.8 provide background information about Project #1, and sections 1.9 to\n1.13 are related to Project #2. Chapter 2 includes historical background,\nChapter 3 provides the necessary mathematical background, and finally, Chapter\n6 contains concluding remarks and future directions.",
      "tldr_zh": "这篇论文通过生成建模揭示大脑功能的奥秘，包括灵长类动物的运动感知和小鼠皮层网络组织。论文第一项目开发了一个分层变分自编码器（hierarchical VAE）模型，结合Helmholtz的“Perception as Unconscious Inference”理论，模拟灵长类视觉皮层对运动刺激的响应，结果显示模型能无监督地识别视网膜运动输入的因果因素，如物体运动和自身运动，从而证明分层推理是大脑理解世界的关键机制。第二项目使用fMRI和宽场Ca2+成像数据分析小鼠皮层的自发活动，揭示皮层可分解为重叠社区，其中约一半区域属于多个社区，并比较fMRI和Ca2+信号的网络相似性与差异。整体上，该研究展示了生成模型在神经科学中的应用潜力，为理解脑功能提供了新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "This is my PhD Dissertation, defended on November 3, 2023",
      "pdf_url": "http://arxiv.org/pdf/2412.19845v1",
      "published_date": "2024-12-25 03:39:18 UTC",
      "updated_date": "2024-12-25 03:39:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:43:12.664958"
    },
    {
      "arxiv_id": "2412.18760v2",
      "title": "Data clustering: an essential technique in data science",
      "title_zh": "翻译失败",
      "authors": [
        "Tai Dinh",
        "Wong Hauchi",
        "Daniil Lisik",
        "Michal Koren",
        "Dat Tran",
        "Philip S. Yu",
        "Joaquín Torres-Sospedra"
      ],
      "abstract": "This paper explores the critical role of data clustering in data science,\nemphasizing its methodologies, tools, and diverse applications. Traditional\ntechniques, such as partitional and hierarchical clustering, are analyzed\nalongside advanced approaches such as data stream, density-based, graph-based,\nand model-based clustering for handling complex structured datasets. The paper\nhighlights key principles underpinning clustering, outlines widely used tools\nand frameworks, introduces the workflow of clustering in data science,\ndiscusses challenges in practical implementation, and examines various\napplications of clustering. By focusing on these foundations and applications,\nthe discussion underscores clustering's transformative potential. The paper\nconcludes with insights into future research directions, emphasizing\nclustering's role in driving innovation and enabling data-driven\ndecision-making.",
      "tldr_zh": "这篇论文探讨了数据聚类在数据科学中的关键作用，涵盖了传统方法如 partitional clustering 和 hierarchical clustering，以及高级技术如 data stream、density-based、graph-based 和 model-based clustering，用于处理复杂结构数据集。论文分析了聚类的基本原则、常用工具和框架、实施工作流程，以及实际面临的挑战，并强调其在多样应用中的变革潜力。最终，它总结了聚类推动创新和数据驱动决策的重要性，并指出未来研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18760v2",
      "published_date": "2024-12-25 03:14:18 UTC",
      "updated_date": "2025-01-30 21:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:43:23.384008"
    },
    {
      "arxiv_id": "2412.18750v2",
      "title": "The Impact of Input Order Bias on Large Language Models for Software Fault Localization",
      "title_zh": "输入顺序偏差对大型语言模型在软件故障定位中的影响",
      "authors": [
        "Md Nakhla Rafi",
        "Dong Jae Kim",
        "Tse-Hsun Chen",
        "Shaowei Wang"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant potential in software\nengineering tasks such as Fault Localization (FL) and Automatic Program Repair\n(APR). This study investigates how input order and context size influence LLM\nperformance in FL, a crucial step for many downstream software engineering\ntasks. We evaluate different method orderings using Kendall Tau distances,\nincluding \"perfect\" (where ground truths appear first) and \"worst\" (where\nground truths appear last), across two benchmarks containing Java and Python\nprojects. Our results reveal a strong order bias: in Java projects, Top-1 FL\naccuracy drops from 57% to 20% when reversing the order, while in Python\nprojects, it decreases from 38% to approximately 3%. However, segmenting inputs\ninto smaller contexts mitigates this bias, reducing the performance gap in FL\nfrom 22% and 6% to just 1% across both benchmarks. We replaced method names\nwith semantically meaningful alternatives to determine whether this bias is due\nto data leakage. The observed trends remained consistent, suggesting that the\nbias is not caused by memorization from training data but rather by the\ninherent effect of input order. Additionally, we explored ordering methods\nbased on traditional FL techniques and metrics, finding that DepGraph's ranking\nachieves 48% Top-1 accuracy, outperforming simpler approaches such as\nCallGraph(DFS). These findings highlight the importance of structuring inputs,\nmanaging context effectively, and selecting appropriate ordering strategies to\nenhance LLM performance in FL and other software engineering applications.",
      "tldr_zh": "本研究探讨了 Large Language Models (LLMs) 在软件 Fault Localization (FL) 任务中的输入顺序偏见及其对性能的影响。研究者使用 Kendall Tau distances 评估不同方法顺序（如“perfect”顺序和“worst”顺序）在 Java 和 Python 项目基准上的表现，结果显示顺序偏见显著，导致 Java 项目 Top-1 FL 准确率从 57% 降至 20%，Python 项目从 38% 降至约 3%。通过将输入分割成更小上下文，偏见可被缓解，将性能差距缩小至 1%。此外，实验证实该偏见并非源于数据泄露，而是输入顺序的固有效应，并发现基于传统 FL 技术的顺序策略（如 DepGraph 的排名）可提升 Top-1 准确率至 48%，优于 CallGraph(DFS) 等方法。这些发现强调了结构化输入、管理上下文和选择适当顺序策略的重要性，以提升 LLMs 在软件工程应用中的可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18750v2",
      "published_date": "2024-12-25 02:48:53 UTC",
      "updated_date": "2025-03-19 16:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:45:36.635894"
    },
    {
      "arxiv_id": "2412.18743v1",
      "title": "Successes and Limitations of Object-centric Models at Compositional Generalisation",
      "title_zh": "翻译失败",
      "authors": [
        "Milton L. Montero",
        "Jeffrey S. Bowers",
        "Gaurav Malhotra"
      ],
      "abstract": "In recent years, it has been shown empirically that standard disentangled\nlatent variable models do not support robust compositional learning in the\nvisual domain. Indeed, in spite of being designed with the goal of factorising\ndatasets into their constituent factors of variations, disentangled models show\nextremely limited compositional generalisation capabilities. On the other hand,\nobject-centric architectures have shown promising compositional skills, albeit\nthese have 1) not been extensively tested and 2) experiments have been limited\nto scene composition -- where models must generalise to novel combinations of\nobjects in a visual scene instead of novel combinations of object properties.\nIn this work, we show that these compositional generalisation skills extend to\nthis later setting. Furthermore, we present evidence pointing to the source of\nthese skills and how they can be improved through careful training. Finally, we\npoint to one important limitation that still exists which suggests new\ndirections of research.",
      "tldr_zh": "本研究发现，标准的解缠结潜在变量模型在视觉领域的组合泛化(compositional generalisation)能力有限，无法有效处理新组合的物体属性，而object-centric models则展现出更强的组合技能。作者通过实验证明，这些模型的技能可以扩展到物体属性的新组合设置，并分析了其来源以及通过仔细训练的改进方法。最终，论文指出了object-centric models的潜在局限性，并提出新的研究方向以进一步提升其性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "As it appeared in the Compositional Learning Workshop, NeurIPS 2024;\n  14 pages (5 main text, 7 appendices, 2 references); 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18743v1",
      "published_date": "2024-12-25 02:25:12 UTC",
      "updated_date": "2024-12-25 02:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:43:47.592137"
    },
    {
      "arxiv_id": "2412.18734v1",
      "title": "Predicting Time Series of Networked Dynamical Systems without Knowing Topology",
      "title_zh": "翻译失败",
      "authors": [
        "Yanna Ding",
        "Zijie Huang",
        "Malik Magdon-Ismail",
        "Jianxi Gao"
      ],
      "abstract": "Many real-world complex systems, such as epidemic spreading networks and\necosystems, can be modeled as networked dynamical systems that produce\nmultivariate time series. Learning the intrinsic dynamics from observational\ndata is pivotal for forecasting system behaviors and making informed decisions.\nHowever, existing methods for modeling networked time series often assume known\ntopologies, whereas real-world networks are typically incomplete or inaccurate,\nwith missing or spurious links that hinder precise predictions. Moreover, while\nnetworked time series often originate from diverse topologies, the ability of\nmodels to generalize across topologies has not been systematically evaluated.\nTo address these gaps, we propose a novel framework for learning network\ndynamics directly from observed time-series data, when prior knowledge of graph\ntopology or governing dynamical equations is absent. Our approach leverages\ncontinuous graph neural networks with an attention mechanism to construct a\nlatent topology, enabling accurate reconstruction of future trajectories for\nnetwork states. Extensive experiments on real and synthetic networks\ndemonstrate that our model not only captures dynamics effectively without\ntopology knowledge but also generalizes to unseen time series originating from\ndiverse topologies.",
      "tldr_zh": "该研究解决了在未知拓扑情况下预测网络动态系统时间序列的问题，针对现实中网络拓扑的不完整性（如缺失或虚假链接）提出了一种新框架。该框架利用连续图神经网络（continuous graph neural networks）和注意力机制（attention mechanism）从观测数据中直接学习潜在拓扑，从而准确重建未来系统轨迹。实验结果显示，该模型在真实和合成网络上有效捕捉动态，并能泛化到来自不同拓扑的未见时间序列。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18734v1",
      "published_date": "2024-12-25 01:39:04 UTC",
      "updated_date": "2024-12-25 01:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:43:59.306549"
    },
    {
      "arxiv_id": "2412.18727v1",
      "title": "SAFLITE: Fuzzing Autonomous Systems via Large Language Models",
      "title_zh": "SAFLITE：利用大语言模型进行自治系统的模糊测试",
      "authors": [
        "Taohong Zhu",
        "Adrians Skapars",
        "Fardeen Mackenzie",
        "Declan Kehoe",
        "William Newton",
        "Suzanne Embury",
        "Youcheng Sun"
      ],
      "abstract": "Fuzz testing effectively uncovers software vulnerabilities; however, it faces\nchallenges with Autonomous Systems (AS) due to their vast search spaces and\ncomplex state spaces, which reflect the unpredictability and complexity of\nreal-world environments. This paper presents a universal framework aimed at\nimproving the efficiency of fuzz testing for AS. At its core is SaFliTe, a\npredictive component that evaluates whether a test case meets predefined safety\ncriteria. By leveraging the large language model (LLM) with information about\nthe test objective and the AS state, SaFliTe assesses the relevance of each\ntest case. We evaluated SaFliTe by instantiating it with various LLMs,\nincluding GPT-3.5, Mistral-7B, and Llama2-7B, and integrating it into four fuzz\ntesting tools: PGFuzz, DeepHyperion-UAV, CAMBA, and TUMB. These tools are\ndesigned specifically for testing autonomous drone control systems, such as\nArduPilot, PX4, and PX4-Avoidance. The experimental results demonstrate that,\ncompared to PGFuzz, SaFliTe increased the likelihood of selecting operations\nthat triggered bug occurrences in each fuzzing iteration by an average of\n93.1\\%. Additionally, after integrating SaFliTe, the ability of\nDeepHyperion-UAV, CAMBA, and TUMB to generate test cases that caused system\nviolations increased by 234.5\\%, 33.3\\%, and 17.8\\%, respectively. The\nbenchmark for this evaluation was sourced from a UAV Testing Competition.",
      "tldr_zh": "该论文针对Autonomous Systems (AS)的模糊测试(Fuzz testing)面临的巨大搜索空间和复杂状态空间问题，提出了一种通用框架的核心组件SaFliTe，利用Large Language Model (LLM)评估测试用例是否符合预定义的安全标准。SaFliTe通过结合测试目标和AS状态信息，来预测测试用例的相关性，并已集成到PGFuzz、DeepHyperion-UAV、CAMBA和TUMB等工具中，用于测试无人机控制系统如ArduPilot和PX4。实验结果显示，SaFliTe使PGFuzz在每次模糊迭代中触发bug的可能性平均提高93.1%，并分别使其他工具生成导致系统违规的测试用例能力提升234.5%、33.3%和17.8%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18727v1",
      "published_date": "2024-12-25 01:00:05 UTC",
      "updated_date": "2024-12-25 01:00:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:44:12.361467"
    },
    {
      "arxiv_id": "2412.18715v1",
      "title": "Optimization and Scalability of Collaborative Filtering Algorithms in Large Language Models",
      "title_zh": "大型语言模型中协同过滤算法的优化与可扩展性",
      "authors": [
        "Haowei Yang",
        "Longfei Yun",
        "Jinghan Cao",
        "Qingyi Lu",
        "Yuming Tu"
      ],
      "abstract": "With the rapid development of large language models (LLMs) and the growing\ndemand for personalized content, recommendation systems have become critical in\nenhancing user experience and driving engagement. Collaborative filtering\nalgorithms, being core to many recommendation systems, have garnered\nsignificant attention for their efficiency and interpretability. However,\ntraditional collaborative filtering approaches face numerous challenges when\nintegrated into large-scale LLM-based systems, including high computational\ncosts, severe data sparsity, cold start problems, and lack of scalability. This\npaper investigates the optimization and scalability of collaborative filtering\nalgorithms in large language models, addressing these limitations through\nadvanced optimization strategies. Firstly, we analyze the fundamental\nprinciples of collaborative filtering algorithms and their limitations when\napplied in LLM-based contexts. Next, several optimization techniques such as\nmatrix factorization, approximate nearest neighbor search, and parallel\ncomputing are proposed to enhance computational efficiency and model accuracy.\nAdditionally, strategies such as distributed architecture and model compression\nare explored to facilitate dynamic updates and scalability in data-intensive\nenvironments.",
      "tldr_zh": "这篇论文探讨了在大型语言模型（LLMs）中优化协作过滤算法的问题，以应对高计算成本、数据稀疏性、冷启动问题和可扩展性不足等挑战。作者首先分析了协作过滤算法的基本原理及其在LLMs环境中的局限性，然后提出优化技术，包括矩阵 factorization、approximate nearest neighbor search 和 parallel computing，以提升计算效率和模型准确性。此外，通过探索 distributed architecture 和 model compression 策略，论文实现了算法在数据密集型环境中的动态更新和可扩展性，提高了推荐系统的整体性能。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18715v1",
      "published_date": "2024-12-25 00:26:51 UTC",
      "updated_date": "2024-12-25 00:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:44:23.696772"
    },
    {
      "arxiv_id": "2412.18713v1",
      "title": "Enhanced Recommendation Combining Collaborative Filtering and Large Language Models",
      "title_zh": "结合协同过滤和大型语言模型的增强推荐",
      "authors": [
        "Xueting Lin",
        "Zhan Cheng",
        "Longfei Yun",
        "Qingyi Lu",
        "Yuanshuai Luo"
      ],
      "abstract": "With the advent of the information explosion era, the importance of\nrecommendation systems in various applications is increasingly significant.\nTraditional collaborative filtering algorithms are widely used due to their\neffectiveness in capturing user behavior patterns, but they encounter\nlimitations when dealing with cold start problems and data sparsity. Large\nLanguage Models (LLMs), with their strong natural language understanding and\ngeneration capabilities, provide a new breakthrough for recommendation systems.\nThis study proposes an enhanced recommendation method that combines\ncollaborative filtering and LLMs, aiming to leverage collaborative filtering's\nadvantage in modeling user preferences while enhancing the understanding of\ntextual information about users and items through LLMs to improve\nrecommendation accuracy and diversity. This paper first introduces the\nfundamental theories of collaborative filtering and LLMs, then designs a\nrecommendation system architecture that integrates both, and validates the\nsystem's effectiveness through experiments. The results show that the hybrid\nmodel based on collaborative filtering and LLMs significantly improves\nprecision, recall, and user satisfaction, demonstrating its potential in\ncomplex recommendation scenarios.",
      "tldr_zh": "本研究针对推荐系统的冷启动和数据稀疏问题，提出了一种结合 Collaborative Filtering 和 Large Language Models (LLMs) 的增强推荐方法，利用 Collaborative Filtering 捕捉用户行为模式，同时借助 LLMs 的自然语言理解能力来提升对用户和物品文本信息的处理，从而提高推荐的准确性和多样性。论文首先介绍了 Collaborative Filtering 和 LLMs 的基础理论，然后设计了集成架构，并通过实验验证了该混合模型的效果。实验结果显示，该方法显著提高了精确率、召回率和用户满意度，在复杂推荐场景中展现出巨大潜力。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18713v1",
      "published_date": "2024-12-25 00:23:53 UTC",
      "updated_date": "2024-12-25 00:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:44:35.365982"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 48,
  "processed_papers_count": 48,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T17:45:53.472472"
}