{
  "date": "2024-03-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-05 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的优化与应用、强化学习、多模态处理和图像生成等方面。其中，LLM 在代理和多模态任务中的创新应用（如 Cradle 和 NaturalSpeech 3）最为令人印象深刻，同时 AI 安全与偏差研究（如 WMDP Benchmark 和 Bias in Generative AI）也引发关注，突显了知名学者（如 Alexandr Wang 和 Furu Wei）在这些方向的贡献。\n\n下面，我挑选并简要讨论了部分重要、话题性和影响较大的论文，先从 LLM 相关的高影响力文章入手，再触及强化学习和图像处理领域。对于其他较次要的论文（如纯理论数学或特定领域小众工作），我将快速掠过或合并提及，以控制篇幅。每个论文标题以“中文翻译 + 英文原标题”形式列出。\n\n### 1. **大型语言模型的创新与优化**\n- **可靠、可适应和可归因的语言模型：检索增强（Reliable, Adaptable, and Attributable Language Models with Retrieval）**  \n  这篇论文提出了一种检索增强框架，用于提升 LLM 的可靠性、适应性和可归因性。主要贡献是通过结合大型数据存储在推理阶段，处理 LLM 的幻觉问题和泛化挑战。发现显示，该方法在非知识密集任务中也表现出色，强调了检索机制在未来 LLM 部署中的潜力。\n  \n- **摇篮：赋予基础代理通用计算机控制能力（Cradle: Empowering Foundation Agents Towards General Computer Control）**  \n  作者开发了一个模块化框架 Cradle，利用 LLM 驱动代理在各种软件（如游戏和应用）中执行复杂任务。主要发现是，该方法在无需内置 API 的情况下实现高效控制，并在多个基准上超越现有模型，展示了 LLM 在自动化领域的强大潜力。\n\n- **NaturalSpeech 3：零样本语音合成使用因子化编解码器和扩散模型（NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models）**  \n  这篇工作引入因子化扩散模型，实现零样本语音合成。主要贡献是，通过分解语音属性（如内容和音色），模型在多说话人数据集上达到人类级质量，扩展了 LLM 在语音领域的应用。\n\n- **偏差在生成式 AI 中的表现（Bias in Generative AI）**  \n  论文分析了生成式 AI（如 Midjourney）在图像生成中的性别和种族偏差。主要发现是，AI 放大了社会偏差（如女性被描绘得更年轻、更 submissive），并建议通过优化训练数据缓解这些问题，强调了 AI 伦理的重要性。\n\n- **基准测试 LLM 的 Text-to-SQL 能力：全面评估（Benchmarking the Text-to-SQL Capability of Large Language Models）**  \n  作者构建了新基准，评估 LLM 在文本到 SQL 转换中的性能。主要贡献是通过多任务评估，发现 LLM 在零样本场景下表现出色，但仍需优化提示策略。\n\n其他 LLM 相关论文（如第4、54、55、56、101）探讨了提示工程和知识蒸馏，但这些工作相对常规，我快速掠过：它们主要优化了 LLM 的推理和泛化，但未带来革命性突破。\n\n### 2. **强化学习与多代理系统**\n- **RACE-SM：基于强化学习的自治社会上坡合并控制（RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging）**  \n  这篇论文提出了一种新型强化学习模型，用于自动驾驶中的社会上坡合并。主要贡献是通过社交价值取向设计奖励函数，实现更安全的行为，避免碰撞和反社会行为。发现显示，该方法在模拟环境中超越传统优化方法。\n\n- **代理共识：使用目标想象的多代理强化学习（Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination）**  \n  作者引入目标想象机制，提升多代理协调。主要发现是，该框架在复杂环境中显著提高样本效率，并在 StarCraft 等基准上表现优异。\n\n强化学习其他论文（如第43、50）聚焦代理优化，但影响力较小，我简要提及：它们改善了学习效率，但未解决核心挑战。\n\n### 3. **图像处理与计算机视觉**\n- **深度生成模型用于粒子物理检测器模拟（Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation）**  \n  论文开发了新生成模型（如 IEA-GAN 和 YonedaVAE），用于高精度粒子物理模拟。主要贡献是，通过自监督学习捕捉事件相关性，提升模拟精度。\n\n- **多尺度子图对比学习（Multi-Scale Subgraph Contrastive Learning）**  \n  作者提出了一种多尺度子图对比框架，用于图分类。主要发现是，该方法捕获了细粒度语义，提升了图神经网络的性能。\n\n图像领域其他论文（如第14、33、67）涉及噪声减少和生成，但较基础，我快速掠过：它们优化了图像质量，但未有突破性创新。\n\n### 4. **其他值得注意的领域**\n- **WMDP 基准：测量和减少 LLM 的恶意使用（The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning）**  \n  这篇工作构建了新基准，评估 LLM 在生物、网络和化学安全中的风险。主要贡献是通过无监督学习减少恶意知识，LLM 在此基准上表现出色。\n\n- **零样本跨语言事件因果识别（Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning）**  \n  论文使用异构图对比学习，实现跨语言事件因果检测。主要发现是，该方法在多语言基准上提升了准确性。\n\n其他论文（如第6、8、9、13、15、18、23、24、25、27、28、29、30、31、32、34、36、37、38、39、40、41、42、44、45、46、47、51、52、57、59、68、69、70、72、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、97、98、99、100）涉及教育、医学、量子计算等领域，但这些工作较为分散或应用性不强，我仅快速提及：它们提供了技术细节，但对主流 AI 社区的影响有限。\n\n总之，今天的论文突显了 LLM 和 AI 应用的多样性与潜力，但也暴露了偏差和安全挑战。感兴趣的读者可关注 LLM 代理和强化学习方向的创新！如果有特定论文需求，欢迎后续讨论。",
  "papers": [
    {
      "arxiv_id": "2403.13825v1",
      "title": "Deep Generative Models for Ultra-High Granularity Particle Physics Detector Simulation: A Voyage From Emulation to Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Baran Hashemi"
      ],
      "abstract": "Simulating ultra-high-granularity detector responses in Particle Physics\nrepresents a critical yet computationally demanding task. This thesis aims to\novercome this challenge for the Pixel Vertex Detector (PXD) at the Belle II\nexperiment, which features over 7.5M pixel channels-the highest spatial\nresolution detector simulation dataset ever analysed with generative models.\nThis thesis starts off by a comprehensive and taxonomic review on generative\nmodels for simulating detector signatures. Then, it presents the Intra-Event\nAware Generative Adversarial Network (IEA-GAN), a new geometry-aware generative\nmodel that introduces a relational attentive reasoning and Self-Supervised\nLearning to approximate an \"event\" in the detector. This study underscores the\nimportance of intra-event correlation for downstream physics analyses. Building\nupon this, the work drifts towards a more generic approach and presents\nYonedaVAE, a Category Theory-inspired generative model that tackles the open\nproblem of Out-of-Distribution (OOD) simulation. YonedaVAE introduces a\nlearnable Yoneda embedding to capture the entirety of an event based on its\nsensor relationships, formulating a Category theoretical language for\nintra-event relational reasoning. This is complemented by introducing a\nSelf-Supervised learnable prior for VAEs and an Adaptive Top-q sampling\nmechanism, enabling the model to sample point clouds with variable\nintra-category cardinality in a zero-shot manner. Variable Intra-event\ncardinality has not been approached before and is vital for simulating\nirregular detector geometries. Trained on an early experiment data, YonedaVAE\ncan reach a reasonable OOD simulation precision of a later experiment with\nalmost double luminosity. This study introduces, for the first time, the\nresults of using deep generative models for ultra-high granularity detector\nsimulation in Particle Physics.",
      "tldr_zh": "本论文探讨了使用深度生成模型模拟粒子物理学中超高粒度探测器响应的问题，针对Belle II实验的Pixel Vertex Detector (PXD) 及其超过7.5M像素通道的数据集。论文首先回顾了生成模型的应用，并提出Intra-Event Aware Generative Adversarial Network (IEA-GAN)，通过关系注意力推理和Self-Supervised Learning 来捕捉事件内部相关性，提高下游物理分析的准确性。接着，引入YonedaVAE 模型，受范畴论启发，采用可学习的Yoneda嵌入、自监督可学习先验和Adaptive Top-q采样机制，实现Out-of-Distribution (OOD)模拟，并首次处理可变事件基数；在早期实验数据上训练后，YonedaVAE 成功模拟更高光度的后期实验，展示了在超高粒度探测器模拟中的潜力。",
      "categories": [
        "physics.ins-det",
        "cs.AI",
        "cs.LG",
        "hep-ex",
        "hep-ph"
      ],
      "primary_category": "physics.ins-det",
      "comment": "PhD thesis, 234 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.13825v1",
      "published_date": "2024-03-05 23:12:47 UTC",
      "updated_date": "2024-03-05 23:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:30:54.612515"
    },
    {
      "arxiv_id": "2403.03359v2",
      "title": "RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Poots"
      ],
      "abstract": "Autonomous parallel-style on-ramp merging in human controlled traffic\ncontinues to be an existing issue for autonomous vehicle control. Existing\nnon-learning based solutions for vehicle control rely on rules and optimization\nprimarily. These methods have been seen to present significant challenges.\nRecent advancements in Deep Reinforcement Learning have shown promise and have\nreceived significant academic interest however the available learning based\napproaches show inadequate attention to other highway vehicles and often rely\non inaccurate road traffic assumptions. In addition, the parallel-style case is\nrarely considered. A novel learning based model for acceleration and lane\nchange decision making that explicitly considers the utility to both the ego\nvehicle and its surrounding vehicles which may be cooperative or uncooperative\nto produce behaviour that is socially acceptable is proposed. The novel reward\nfunction makes use of Social Value Orientation to weight the vehicle's level of\nsocial cooperation and is divided into ego vehicle and surrounding vehicle\nutility which are weighted according to the model's designated Social Value\nOrientation. A two-lane highway with an on-ramp divided into a taper-style and\nparallel-style section is considered. Simulation results indicated the\nimportance of considering surrounding vehicles in reward function design and\nshow that the proposed model matches or surpasses those in literature in terms\nof collisions while also introducing socially courteous behaviour avoiding near\nmisses and anti-social behaviour through direct consideration of the effect of\nmerging on surrounding vehicles.",
      "tldr_zh": "该论文提出了一种名为 RACE-SM 的强化学习（Reinforcement Learning）模型，用于实现自动驾驶车辆在高速公路上坡合并时的社会友好控制。该模型通过设计一个新型奖励函数，显式考虑自我车辆（ego vehicle）和周围车辆的效用，并利用 Social Value Orientation 来权衡车辆的社会合作水平，从而生成更礼貌的行为。模拟实验结果显示，该方法在两车道高速公路（包括锥形和并行部分）的场景中，显著减少了碰撞和近距离事故，同时在社会接受度方面优于现有文献。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated explanation of TTC, page 7",
      "pdf_url": "http://arxiv.org/pdf/2403.03359v2",
      "published_date": "2024-03-05 23:03:56 UTC",
      "updated_date": "2024-03-15 10:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:31:03.812931"
    },
    {
      "arxiv_id": "2403.03357v2",
      "title": "The Case for Globalizing Fairness: A Mixed Methods Study on Colonialism, AI, and Health in Africa",
      "title_zh": "翻译失败",
      "authors": [
        "Mercy Asiedu",
        "Awa Dieng",
        "Iskandar Haykel",
        "Negar Rostamzadeh",
        "Stephen Pfohl",
        "Chirag Nagpal",
        "Maria Nagawa",
        "Abigail Oppong",
        "Sanmi Koyejo",
        "Katherine Heller"
      ],
      "abstract": "With growing application of machine learning (ML) technologies in healthcare,\nthere have been calls for developing techniques to understand and mitigate\nbiases these systems may exhibit. Fair-ness considerations in the development\nof ML-based solutions for health have particular implications for Africa, which\nalready faces inequitable power imbalances between the Global North and\nSouth.This paper seeks to explore fairness for global health, with Africa as a\ncase study. We conduct a scoping review to propose axes of disparities for\nfairness consideration in the African context and delineate where they may come\ninto play in different ML-enabled medical modalities. We then conduct\nqualitative research studies with 672 general population study participants and\n28 experts inML, health, and policy focused on Africa to obtain corroborative\nevidence on the proposed axes of disparities. Our analysis focuses on\ncolonialism as the attribute of interest and examines the interplay between\nartificial intelligence (AI), health, and colonialism. Among the pre-identified\nattributes, we found that colonial history, country of origin, and national\nincome level were specific axes of disparities that participants believed would\ncause an AI system to be biased.However, there was also divergence of opinion\nbetween experts and general population participants. Whereas experts generally\nexpressed a shared view about the relevance of colonial history for the\ndevelopment and implementation of AI technologies in Africa, the majority of\nthe general population participants surveyed did not think there was a direct\nlink between AI and colonialism. Based on these findings, we provide practical\nrecommendations for developing fairness-aware ML solutions for health in\nAfrica.",
      "tldr_zh": "这篇论文探讨了机器学习（ML）在非洲医疗中的公平性问题，强调殖民主义、AI和全球不平等的影响，通过混合方法研究（包括文献综述和定性调查）作为案例分析。研究识别出殖民历史、国籍和国民收入水平作为关键的不平等轴线，可能导致AI系统偏见，并调查了672名普通参与者和28名专家的意见。结果显示，专家认为殖民历史与AI开发密切相关，而普通参与者对此持怀疑态度；基于这些发现，论文提供了开发公平ML健康解决方案的实用推荐。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2304.02190",
      "pdf_url": "http://arxiv.org/pdf/2403.03357v2",
      "published_date": "2024-03-05 22:54:15 UTC",
      "updated_date": "2024-03-11 16:16:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:31:16.568233"
    },
    {
      "arxiv_id": "2403.03348v3",
      "title": "Learning to Maximize Mutual Information for Chain-of-Thought Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Chen",
        "Hanxian Huang",
        "Yanjun Gao",
        "Yi Wang",
        "Jishen Zhao",
        "Ke Ding"
      ],
      "abstract": "Knowledge distillation, the technique of transferring knowledge from large,\ncomplex models to smaller ones, marks a pivotal step towards efficient AI\ndeployment. Distilling Step-by-Step~(DSS), a novel method utilizing\nchain-of-thought~(CoT) distillation, has demonstrated promise by imbuing\nsmaller models with the superior reasoning capabilities of their larger\ncounterparts. In DSS, the distilled model acquires the ability to generate\nrationales and predict labels concurrently through a multi-task learning\nframework. However, DSS overlooks the intrinsic relationship between the two\ntraining tasks, leading to ineffective integration of CoT knowledge with the\ntask of label prediction. To this end, we investigate the mutual relationship\nof the two tasks from Information Bottleneck perspective and formulate it as\nmaximizing the mutual information of the representation features of the two\ntasks. We propose a variational approach to solve this optimization problem\nusing a learning-based method. Our experimental results across four datasets\ndemonstrate that our method outperforms the state-of-the-art DSS. Our findings\noffer insightful guidance for future research on language model distillation as\nwell as applications involving CoT. Codes are available at\n\\url{https://github.com/xinchen9/cot_distillation_ACL2024}.",
      "tldr_zh": "该论文针对知识蒸馏（knowledge distillation）中的 Chain-of-Thought (CoT) 蒸馏方法 DSS 存在的不足，即忽略了生成推理过程和预测标签两个任务的内在关系，导致整合不佳。研究从 Information Bottleneck 视角出发，提出一种最大化 mutual information 的方法，通过 variational approach 和 learning-based 优化来增强任务表示的互信息整合。实验在四个数据集上表明，该方法优于现有 DSS 状态，并为未来语言模型蒸馏和 CoT 应用提供重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2403.03348v3",
      "published_date": "2024-03-05 22:21:45 UTC",
      "updated_date": "2024-06-09 14:24:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:31:28.668754"
    },
    {
      "arxiv_id": "2403.09700v2",
      "title": "Shapley Values-Powered Framework for Fair Reward Split in Content Produced by GenAI",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Glinsky",
        "Alexey Sokolsky"
      ],
      "abstract": "It is evident that, currently, generative models are surpassed in quality by\nhuman professionals. However, with the advancements in Artificial Intelligence,\nthis gap will narrow, leading to scenarios where individuals who have dedicated\nyears of their lives to mastering a skill become obsolete due to their high\ncosts, which are inherently linked to the time they require to complete a task\n-- a task that AI could accomplish in minutes or seconds. To avoid future\nsocial upheavals, we must, even now, contemplate how to fairly assess the\ncontributions of such individuals in training generative models and how to\ncompensate them for the reduction or complete loss of their incomes. In this\nwork, we propose a method to structure collaboration between model developers\nand data providers. To achieve this, we employ Shapley Values to quantify the\ncontribution of artist(s) in an image generated by the Stable Diffusion-v1.5\nmodel and to equitably allocate the reward among them.",
      "tldr_zh": "该论文探讨了生成式 AI（GenAI）快速发展可能导致人类专业人士失业的问题，强调需要公平评估他们在训练模型中的贡献，以避免社会动荡。研究提出一个基于 Shapley Values 的框架，用于量化艺术家在 Stable Diffusion-v1.5 生成图像中的贡献。作者通过此方法结构化模型开发者和数据提供者之间的合作，实现奖励的公平分配，从而为未来的人工智能伦理补偿机制提供可行方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "91A12, 68T05, 91B32",
        "I.2.6; I.3.3; I.2.0; J.5; J.7"
      ],
      "primary_category": "cs.CV",
      "comment": "36 pages, 32 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.09700v2",
      "published_date": "2024-03-05 22:19:21 UTC",
      "updated_date": "2024-03-27 13:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:31:38.529594"
    },
    {
      "arxiv_id": "2403.03344v1",
      "title": "Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tina Vartziotis",
        "Ippolyti Dellatolas",
        "George Dasoulas",
        "Maximilian Schmidt",
        "Florian Schneider",
        "Tim Hoffmann",
        "Sotirios Kotsopoulos",
        "Michael Keckeisen"
      ],
      "abstract": "The increasing use of information technology has led to a significant share\nof energy consumption and carbon emissions from data centers. These\ncontributions are expected to rise with the growing demand for big data\nanalytics, increasing digitization, and the development of large artificial\nintelligence (AI) models. The need to address the environmental impact of\nsoftware development has led to increased interest in green (sustainable)\ncoding and claims that the use of AI models can lead to energy efficiency\ngains. Here, we provide an empirical study on green code and an overview of\ngreen coding practices, as well as metrics used to quantify the sustainability\nawareness of AI models. In this framework, we evaluate the sustainability of\nauto-generated code. The auto-generate codes considered in this study are\nproduced by generative commercial AI language models, GitHub Copilot, OpenAI\nChatGPT-3, and Amazon CodeWhisperer. Within our methodology, in order to\nquantify the sustainability awareness of these AI models, we propose a\ndefinition of the code's \"green capacity\", based on certain sustainability\nmetrics. We compare the performance and green capacity of human-generated code\nand code generated by the three AI language models in response to easy-to-hard\nproblem statements. Our findings shed light on the current capacity of AI\nmodels to contribute to sustainable software development.",
      "tldr_zh": "这篇论文通过实证研究探讨了LLM-based绿色代码生成的可持续性，针对信息技术和AI模型对能源消耗和碳排放的影响。研究评估了GitHub Copilot、OpenAI ChatGPT-3和Amazon CodeWhisperer等AI模型生成的代码，并引入了代码的\"green capacity\"指标来量化其可持续性意识，同时与人类生成代码在易到难问题上的性能进行比较。结果表明，这些AI模型在促进可持续软件开发方面具有一定潜力，但仍存在局限性，为未来绿色编码实践提供了重要洞见。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03344v1",
      "published_date": "2024-03-05 22:12:01 UTC",
      "updated_date": "2024-03-05 22:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:31:52.939454"
    },
    {
      "arxiv_id": "2403.03334v3",
      "title": "DIVERSE: A Dataset of YouTube Video Comment Stances with a Data Programming Model",
      "title_zh": "翻译失败",
      "authors": [
        "Iain J. Cruickshank",
        "Amir Soofi",
        "Lynnette Hui Xian Ng"
      ],
      "abstract": "Public opinion of military organizations significantly influences their\nability to recruit talented individuals. As recruitment efforts increasingly\nextend into digital spaces like social media, it becomes essential to assess\nthe stance of social media users toward online military content. However, there\nis a notable lack of data for analyzing opinions on military recruiting efforts\nonline, compounded by challenges in stance labeling, which is crucial for\nunderstanding public perceptions. Despite the importance of stance analysis for\nsuccessful online military recruitment, creating human-annotated, in-domain\nstance labels is resource-intensive. In this paper, we address both the\nchallenges of stance labeling and the scarcity of data on public opinions of\nonline military recruitment by introducing and releasing the DIVERSE dataset:\nhttps://doi.org/10.5281/zenodo.10493803. This dataset comprises all comments\nfrom the U.S. Army's official YouTube Channel videos. We employed a\nstate-of-the-art weak supervision approach, leveraging large language models to\nlabel the stance of each comment toward its respective video and the U.S. Army.\nOur findings indicate that the U.S. Army's videos began attracting a\nsignificant number of comments post-2021, with the stance distribution\ngenerally balanced among supportive, oppositional, and neutral comments, with a\nslight skew towards oppositional versus supportive comments.",
      "tldr_zh": "本研究针对在线军事招聘中立场分析的数据短缺和标记挑战，引入了DIVERSE数据集（包含美国陆军官方YouTube频道的所有评论），以评估公众对军事内容的立场。研究采用weak supervision方法和large language models对评论进行自动标记，确定其对视频和美国陆军的支持、中立或反对立场。结果显示，2021年后评论数量显著增加，立场分布大致平衡，但反对评论略多于支持评论，为进一步分析公众意见提供了宝贵资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at IEEE Big Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.03334v3",
      "published_date": "2024-03-05 21:36:23 UTC",
      "updated_date": "2024-10-29 02:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:32:03.712917"
    },
    {
      "arxiv_id": "2403.03322v4",
      "title": "Deep Configuration Performance Learning: A Systematic Survey and Taxonomy",
      "title_zh": "翻译失败",
      "authors": [
        "Jingzhi Gong",
        "Tao Chen"
      ],
      "abstract": "Performance is arguably the most crucial attribute that reflects the quality\nof a configurable software system. However, given the increasing scale and\ncomplexity of modern software, modeling and predicting how various\nconfigurations can impact performance becomes one of the major challenges in\nsoftware maintenance. As such, performance is often modeled without having a\nthorough knowledge of the software system, but relying mainly on data, which\nfits precisely with the purpose of deep learning.\n  In this paper, we conduct a comprehensive review exclusively on the topic of\ndeep learning for performance learning of configurable software, covering 1,206\nsearched papers spanning six indexing services, based on which 99 primary\npapers were extracted and analyzed. Our results outline key statistics,\ntaxonomy, strengths, weaknesses, and optimal usage scenarios for techniques\nrelated to the preparation of configuration data, the construction of deep\nlearning performance models, the evaluation of these models, and their\nutilization in various software configuration-related tasks.We also identify\nthe good practices and potentially problematic phenomena from the studies\nsurveyed, together with a comprehensive summary of actionable suggestions and\ninsights into future opportunities within the field. To promote open science,\nall the raw results of this survey can be accessed at our repository:\nhttps://github.com/ideas-labo/DCPL-SLR.",
      "tldr_zh": "这篇论文对使用深度学习（deep learning）进行可配置软件（configurable software）性能建模进行了系统性调查和分类（taxonomy），旨在解决软件维护中的性能预测挑战。作者搜索了1206篇论文并分析了99篇，涵盖了配置数据准备、性能模型构建、模型评估以及在软件配置任务中的应用，包括优势、劣势、最优使用场景和良好实践。最终，论文总结了潜在问题、行动建议和未来机会，并通过开源仓库促进该领域的开放科学。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by the TOSEM survey track in October 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.03322v4",
      "published_date": "2024-03-05 21:05:16 UTC",
      "updated_date": "2024-11-03 17:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:32:16.109453"
    },
    {
      "arxiv_id": "2403.04803v1",
      "title": "Enhancing Security in Federated Learning through Adaptive Consensus-Based Model Update Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Zahir Alsulaimawi"
      ],
      "abstract": "This paper introduces an advanced approach for fortifying Federated Learning\n(FL) systems against label-flipping attacks. We propose a simplified\nconsensus-based verification process integrated with an adaptive thresholding\nmechanism. This dynamic thresholding is designed to adjust based on the\nevolving landscape of model updates, offering a refined layer of anomaly\ndetection that aligns with the real-time needs of distributed learning\nenvironments. Our method necessitates a majority consensus among participating\nclients to validate updates, ensuring that only vetted and consensual\nmodifications are applied to the global model. The efficacy of our approach is\nvalidated through experiments on two benchmark datasets in deep learning,\nCIFAR-10 and MNIST. Our results indicate a significant mitigation of\nlabel-flipping attacks, bolstering the FL system's resilience. This method\ntranscends conventional techniques that depend on anomaly detection or\nstatistical validation by incorporating a verification layer reminiscent of\nblockchain's participatory validation without the associated cryptographic\noverhead. The innovation of our approach rests in striking an optimal balance\nbetween heightened security measures and the inherent limitations of FL\nsystems, such as computational efficiency and data privacy. Implementing a\nconsensus mechanism specifically tailored for FL environments paves the way for\nmore secure, robust, and trustworthy distributed machine learning applications,\nwhere safeguarding data integrity and model robustness is critical.",
      "tldr_zh": "本文提出了一种增强Federated Learning (FL)系统安全性的方法，通过自适应共识-based模型更新验证来对抗label-flipping attacks。该方法结合简化共识过程和动态阈值机制，根据模型更新演变实时调整阈值，并要求多数客户端共识才能应用更新，从而实现高效的异常检测。在CIFAR-10和MNIST基准数据集上的实验验证表明，该方法显著缓解了攻击风险，并在安全性和计算效率、数据隐私之间取得了平衡，提供更可靠的分布式机器学习应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.04803v1",
      "published_date": "2024-03-05 20:54:56 UTC",
      "updated_date": "2024-03-05 20:54:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:32:28.345894"
    },
    {
      "arxiv_id": "2403.03305v1",
      "title": "Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach for Relation Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Vacareanu",
        "Fahmida Alam",
        "Md Asiful Islam",
        "Haris Riaz",
        "Mihai Surdeanu"
      ],
      "abstract": "This paper introduces a novel neuro-symbolic architecture for relation\nclassification (RC) that combines rule-based methods with contemporary deep\nlearning techniques. This approach capitalizes on the strengths of both\nparadigms: the adaptability of rule-based systems and the generalization power\nof neural networks. Our architecture consists of two components: a declarative\nrule-based model for transparent classification and a neural component to\nenhance rule generalizability through semantic text matching. Notably, our\nsemantic matcher is trained in an unsupervised domain-agnostic way, solely with\nsynthetic data. Further, these components are loosely coupled, allowing for\nrule modifications without retraining the semantic matcher. In our evaluation,\nwe focused on two few-shot relation classification datasets: Few-Shot TACRED\nand a Few-Shot version of NYT29. We show that our proposed method outperforms\nprevious state-of-the-art models in three out of four settings, despite not\nseeing any human-annotated training data. Further, we show that our approach\nremains modular and pliable, i.e., the corresponding rules can be locally\nmodified to improve the overall model. Human interventions to the rules for the\nTACRED relation \\texttt{org:parents} boost the performance on that relation by\nas much as 26\\% relative improvement, without negatively impacting the other\nrelations, and without retraining the semantic matching component.",
      "tldr_zh": "本论文提出了一种可塑化和泛化性强的神经符号(neuro-symbolic)方法，用于关系分类(Relation Classification)，它结合了基于规则的系统透明性和神经网络的泛化能力。架构包括一个声明性规则模型和一个通过语义文本匹配增强规则泛化的神经组件，后者使用合成数据进行无监督、领域无关的训练，且组件间 loosely coupled，允许规则修改而不需重新训练匹配器。在 Few-Shot TACRED 和 Few-Shot NYT29 数据集上的评估中，该方法在四个设置中的三个中超越了现有最先进模型，尽管未使用人类标注数据；此外，通过对特定规则（如 TACRED 的 org:parents 关系）的局部修改，可实现高达 26% 的性能提升，而不影响其他关系和组件。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03305v1",
      "published_date": "2024-03-05 20:08:32 UTC",
      "updated_date": "2024-03-05 20:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:32:40.544912"
    },
    {
      "arxiv_id": "2403.03293v1",
      "title": "AI Insights: A Case Study on Utilizing ChatGPT Intelligence for Research Paper Analysis",
      "title_zh": "AI Insights: 利用 ChatGPT 智能进行研究论文分析的案例研究",
      "authors": [
        "Anjalee De Silva",
        "Janaka L. Wijekoon",
        "Rashini Liyanarachchi",
        "Rrubaa Panchendrarajan",
        "Weranga Rajapaksha"
      ],
      "abstract": "This paper discusses the effectiveness of leveraging Chatbot: Generative\nPre-trained Transformer (ChatGPT) versions 3.5 and 4 for analyzing research\npapers for effective writing of scientific literature surveys. The study\nselected the \\textit{Application of Artificial Intelligence in Breast Cancer\nTreatment} as the research topic. Research papers related to this topic were\ncollected from three major publication databases Google Scholar, Pubmed, and\nScopus. ChatGPT models were used to identify the category, scope, and relevant\ninformation from the research papers for automatic identification of relevant\npapers related to Breast Cancer Treatment (BCT), organization of papers\naccording to scope, and identification of key information for survey paper\nwriting. Evaluations performed using ground truth data annotated using subject\nexperts reveal, that GPT-4 achieves 77.3\\% accuracy in identifying the research\npaper categories and 50\\% of the papers were correctly identified by GPT-4 for\ntheir scopes. Further, the results demonstrate that GPT-4 can generate reasons\nfor its decisions with an average of 27\\% new words, and 67\\% of the reasons\ngiven by the model were completely agreeable to the subject experts.",
      "tldr_zh": "这篇论文探讨了利用ChatGPT-3.5和4模型分析研究论文的有效性，以辅助科学文献综述的撰写。研究以“人工智能在乳腺癌治疗中的应用”为主题，从Google Scholar、PubMed和Scopus数据库收集相关论文，并使用ChatGPT进行论文类别识别、范围组织以及关键信息提取。结果显示，GPT-4在识别论文类别上达到77.3%的准确率，在范围识别上正确率达50%，且其生成的决策理由中有67%获得专家完全认可，为自动化文献分析提供实用见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03293v1",
      "published_date": "2024-03-05 19:47:57 UTC",
      "updated_date": "2024-03-05 19:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:32:53.975372"
    },
    {
      "arxiv_id": "2403.03288v1",
      "title": "Should We Fear Large Language Models? A Structural Analysis of the Human Reasoning System for Elucidating LLM Capabilities and Risks Through the Lens of Heidegger's Philosophy",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiiu Zhang"
      ],
      "abstract": "In the rapidly evolving field of Large Language Models (LLMs), there is a\ncritical need to thoroughly analyze their capabilities and risks. Central to\nour investigation are two novel elements. Firstly, it is the innovative\nparallels between the statistical patterns of word relationships within LLMs\nand Martin Heidegger's concepts of \"ready-to-hand\" and \"present-at-hand,\" which\nencapsulate the utilitarian and scientific altitudes humans employ in\ninteracting with the world. This comparison lays the groundwork for positioning\nLLMs as the digital counterpart to the Faculty of Verbal Knowledge, shedding\nlight on their capacity to emulate certain facets of human reasoning. Secondly,\na structural analysis of human reasoning, viewed through Heidegger's notion of\ntruth as \"unconcealment\" is conducted This foundational principle enables us to\nmap out the inputs and outputs of the reasoning system and divide reasoning\ninto four distinct categories. Respective cognitive faculties are delineated,\nallowing us to place LLMs within the broader schema of human reasoning, thus\nclarifying their strengths and inherent limitations. Our findings reveal that\nwhile LLMs possess the capability for Direct Explicative Reasoning and Pseudo\nRational Reasoning, they fall short in authentic rational reasoning and have no\ncreative reasoning capabilities, due to the current lack of many analogous AI\nmodels such as the Faculty of Judgement. The potential and risks of LLMs when\nthey are augmented with other AI technologies are also evaluated. The results\nindicate that although LLMs have achieved proficiency in some reasoning\nabilities, the aspiration to match or exceed human intellectual capabilities is\nyet unattained. This research not only enriches our comprehension of LLMs but\nalso propels forward the discourse on AI's potential and its bounds, paving the\nway for future explorations into AI's evolving landscape.",
      "tldr_zh": "本研究通过Heidegger的哲学概念（如\"ready-to-hand\"和\"present-at-hand\"）分析Large Language Models (LLMs)的能力与风险，将LLMs视为人类语言知识的数字对应物，并将其与人类推理系统进行比较。论文对人类推理进行结构分析，基于Heidegger的真理观（unconcealment）将推理分为四个类别，发现LLMs仅擅长Direct Explicative Reasoning和Pseudo Rational Reasoning，但缺乏authentic rational reasoning和creative reasoning能力。最终，研究评估了LLMs与其他AI技术结合的潜在风险与益处，强调虽然LLMs在某些推理方面表现出色，但尚未达到或超越人类智力水平，这为AI发展提供了重要启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.03288v1",
      "published_date": "2024-03-05 19:40:53 UTC",
      "updated_date": "2024-03-05 19:40:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:33:05.796900"
    },
    {
      "arxiv_id": "2403.03281v2",
      "title": "Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Sidheekh",
        "Pranuthi Tenali",
        "Saurabh Mathur",
        "Erik Blasch",
        "Kristian Kersting",
        "Sriraam Natarajan"
      ],
      "abstract": "We consider the problem of late multi-modal fusion for discriminative\nlearning. Motivated by noisy, multi-source domains that require understanding\nthe reliability of each data source, we explore the notion of credibility in\nthe context of multi-modal fusion. We propose a combination function that uses\nprobabilistic circuits (PCs) to combine predictive distributions over\nindividual modalities. We also define a probabilistic measure to evaluate the\ncredibility of each modality via inference queries over the PC. Our\nexperimental evaluation demonstrates that our fusion method can reliably infer\ncredibility while maintaining competitive performance with the\nstate-of-the-art.",
      "tldr_zh": "这篇论文探讨了多模态融合在判别学习中的应用，特别关注噪声多源域中数据源可靠性的问题。作者提出了一种使用 Probabilistic Circuits (PCs) 的组合函数，来整合各个模态的预测分布，同时定义了一个概率度量，通过对 PCs 的推理查询来评估每个模态的可信度。该方法在实验中表现出可靠的可靠性推断能力，同时在性能上与最先进方法保持竞争水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03281v2",
      "published_date": "2024-03-05 19:25:55 UTC",
      "updated_date": "2024-07-17 05:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:33:16.221655"
    },
    {
      "arxiv_id": "2403.03276v2",
      "title": "ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures",
      "title_zh": "ARNN",
      "authors": [
        "Salim Rukhsar",
        "Anil Kumar Tiwari"
      ],
      "abstract": "Electroencephalography (EEG) is a widely used tool for diagnosing brain\ndisorders due to its high temporal resolution, non-invasive nature, and\naffordability. Manual analysis of EEG is labor-intensive and requires\nexpertise, making automatic EEG interpretation crucial for reducing workload\nand accurately assessing seizures. In epilepsy diagnosis, prolonged EEG\nmonitoring generates extensive data, often spanning hours, days, or even weeks.\nWhile machine learning techniques for automatic EEG interpretation have\nadvanced significantly in recent decades, there remains a gap in its ability to\nefficiently analyze large datasets with a balance of accuracy and computational\nefficiency. To address the challenges mentioned above, an Attention Recurrent\nNeural Network (ARNN) is proposed that can process a large amount of data\nefficiently and accurately. This ARNN cell recurrently applies attention layers\nalong a sequence and has linear complexity with the sequence length and\nleverages parallel computation by processing multi-channel EEG signals rather\nthan single-channel signals. In this architecture, the attention layer is a\ncomputational unit that efficiently applies self-attention and cross-attention\nmechanisms to compute a recurrent function over a wide number of state vectors\nand input signals. This framework is inspired in part by the attention layer\nand long short-term memory (LSTM) cells, but it scales this typical cell up by\nseveral orders to parallelize for multi-channel EEG signals. It inherits the\nadvantages of attention layers and LSTM gate while avoiding their respective\ndrawbacks. The model's effectiveness is evaluated through extensive experiments\nwith heterogeneous datasets, including the CHB-MIT and UPenn and Mayo's Clinic\ndatasets.",
      "tldr_zh": "该研究针对EEG（Electroencephalography）信号的手动分析耗时且依赖专家的问题，提出了一种Attentive Recurrent Neural Network (ARNN)，用于识别癫痫发作。该ARNN结合注意力机制和循环神经网络，处理多通道EEG信号，具有线性复杂度并支持并行计算，从而高效分析大量数据。相比传统方法，ARNN继承了注意力层和LSTM的优势，避免了它们的缺点，并在CHB-MIT和UPenn and Mayo's Clinic数据集上的实验中显示出显著的准确性和效率提升。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 7 figures, Journal Paper",
      "pdf_url": "http://arxiv.org/pdf/2403.03276v2",
      "published_date": "2024-03-05 19:15:17 UTC",
      "updated_date": "2024-11-18 10:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:33:28.373782"
    },
    {
      "arxiv_id": "2403.03274v1",
      "title": "From Noise to Signal: Unveiling Treatment Effects from Digital Health Data through Pharmacology-Informed Neural-SDE",
      "title_zh": "翻译失败",
      "authors": [
        "Samira Pakravan",
        "Nikolaos Evangelou",
        "Maxime Usdin",
        "Logan Brooks",
        "James Lu"
      ],
      "abstract": "Digital health technologies (DHT), such as wearable devices, provide\npersonalized, continuous, and real-time monitoring of patient. These\ntechnologies are contributing to the development of novel therapies and\npersonalized medicine. Gaining insight from these technologies requires\nappropriate modeling techniques to capture clinically-relevant changes in\ndisease state. The data generated from these devices is characterized by being\nstochastic in nature, may have missing elements, and exhibits considerable\ninter-individual variability - thereby making it difficult to analyze using\ntraditional longitudinal modeling techniques. We present a novel\npharmacology-informed neural stochastic differential equation (SDE) model\ncapable of addressing these challenges. Using synthetic data, we demonstrate\nthat our approach is effective in identifying treatment effects and learning\ncausal relationships from stochastic data, thereby enabling counterfactual\nsimulation.",
      "tldr_zh": "本研究针对数字健康技术（DHT）如可穿戴设备生成的数据问题，提出了一种pharmacology-informed neural stochastic differential equation (SDE)模型，以处理数据中的随机性、缺失元素和个体间变异。 该模型通过整合药理学知识和神经SDE框架，能够有效识别治疗效果、学习因果关系，并支持反事实模拟。 使用合成数据进行的实验证明，该方法显著提高了从噪声数据中提取信号的能力，为个性化医学和新型疗法的发展提供新工具。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "math.DS",
        "I.2; G.3"
      ],
      "primary_category": "q-bio.QM",
      "comment": "6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.03274v1",
      "published_date": "2024-03-05 19:13:57 UTC",
      "updated_date": "2024-03-05 19:13:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:33:40.357863"
    },
    {
      "arxiv_id": "2403.03218v7",
      "title": "The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Nathaniel Li",
        "Alexander Pan",
        "Anjali Gopal",
        "Summer Yue",
        "Daniel Berrios",
        "Alice Gatti",
        "Justin D. Li",
        "Ann-Kathrin Dombrowski",
        "Shashwat Goel",
        "Long Phan",
        "Gabriel Mukobi",
        "Nathan Helm-Burger",
        "Rassin Lababidi",
        "Lennart Justen",
        "Andrew B. Liu",
        "Michael Chen",
        "Isabelle Barrass",
        "Oliver Zhang",
        "Xiaoyuan Zhu",
        "Rishub Tamirisa",
        "Bhrugu Bharathi",
        "Adam Khoja",
        "Zhenqi Zhao",
        "Ariel Herbert-Voss",
        "Cort B. Breuer",
        "Samuel Marks",
        "Oam Patel",
        "Andy Zou",
        "Mantas Mazeika",
        "Zifan Wang",
        "Palash Oswal",
        "Weiran Lin",
        "Adam A. Hunt",
        "Justin Tienken-Harder",
        "Kevin Y. Shih",
        "Kemper Talley",
        "John Guan",
        "Russell Kaplan",
        "Ian Steneker",
        "David Campbell",
        "Brad Jokubaitis",
        "Alex Levinson",
        "Jean Wang",
        "William Qian",
        "Kallol Krishna Karmakar",
        "Steven Basart",
        "Stephen Fitz",
        "Mindy Levine",
        "Ponnurangam Kumaraguru",
        "Uday Tupakula",
        "Vijay Varadharajan",
        "Ruoyu Wang",
        "Yan Shoshitaishvili",
        "Jimmy Ba",
        "Kevin M. Esvelt",
        "Alexandr Wang",
        "Dan Hendrycks"
      ],
      "abstract": "The White House Executive Order on Artificial Intelligence highlights the\nrisks of large language models (LLMs) empowering malicious actors in developing\nbiological, cyber, and chemical weapons. To measure these risks of malicious\nuse, government institutions and major AI labs are developing evaluations for\nhazardous capabilities in LLMs. However, current evaluations are private,\npreventing further research into mitigating risk. Furthermore, they focus on\nonly a few, highly specific pathways for malicious use. To fill these gaps, we\npublicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a\ndataset of 3,668 multiple-choice questions that serve as a proxy measurement of\nhazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP\nwas developed by a consortium of academics and technical consultants, and was\nstringently filtered to eliminate sensitive information prior to public\nrelease. WMDP serves two roles: first, as an evaluation for hazardous knowledge\nin LLMs, and second, as a benchmark for unlearning methods to remove such\nhazardous knowledge. To guide progress on unlearning, we develop RMU, a\nstate-of-the-art unlearning method based on controlling model representations.\nRMU reduces model performance on WMDP while maintaining general capabilities in\nareas such as biology and computer science, suggesting that unlearning may be a\nconcrete path towards reducing malicious use from LLMs. We release our\nbenchmark and code publicly at https://wmdp.ai",
      "tldr_zh": "该研究发布了 WMDP 基准，这是一个包含 3,668 个多项选择题的数据集，用于评估大型语言模型 (LLMs) 在生物安全、网络安全和化学安全领域的危险知识，从而衡量和减少恶意使用风险。WMDP 由学术和技术顾问组成的财团开发，并经过严格过滤以去除敏感信息，可作为评估危险知识和测试 unlearning 方法的工具。研究者开发了 RMU，一种基于控制模型表示的先进 unlearning 方法，该方法显著降低了模型在 WMDP 上的性能，同时保持了在生物学和计算机科学等领域的总体能力，表明 unlearning 是减少 LLMs 恶意使用的潜在路径。基准和代码已公开发布，以推动相关研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "See the project page at https://wmdp.ai",
      "pdf_url": "http://arxiv.org/pdf/2403.03218v7",
      "published_date": "2024-03-05 18:59:35 UTC",
      "updated_date": "2024-05-15 19:16:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:33:53.877704"
    },
    {
      "arxiv_id": "2403.03203v1",
      "title": "CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments",
      "title_zh": "CLEVR-POC：部分可观察环境中的推理密集型视觉问答",
      "authors": [
        "Savitha Sam Abraham",
        "Marjan Alirezaie",
        "Luc De Raedt"
      ],
      "abstract": "The integration of learning and reasoning is high on the research agenda in\nAI. Nevertheless, there is only a little attention to use existing background\nknowledge for reasoning about partially observed scenes to answer questions\nabout the scene. Yet, we as humans use such knowledge frequently to infer\nplausible answers to visual questions (by eliminating all inconsistent ones).\nSuch knowledge often comes in the form of constraints about objects and it\ntends to be highly domain or environment-specific. We contribute a novel\nbenchmark called CLEVR-POC for reasoning-intensive visual question answering\n(VQA) in partially observable environments under constraints. In CLEVR-POC,\nknowledge in the form of logical constraints needs to be leveraged to generate\nplausible answers to questions about a hidden object in a given partial scene.\nFor instance, if one has the knowledge that all cups are colored either red,\ngreen or blue and that there is only one green cup, it becomes possible to\ndeduce the color of an occluded cup as either red or blue, provided that all\nother cups, including the green one, are observed. Through experiments, we\nobserve that the low performance of pre-trained vision language models like\nCLIP (~ 22%) and a large language model (LLM) like GPT-4 (~ 46%) on CLEVR-POC\nascertains the necessity for frameworks that can handle reasoning-intensive\ntasks where environment-specific background knowledge is available and crucial.\nFurthermore, our demonstration illustrates that a neuro-symbolic model, which\nintegrates an LLM like GPT-4 with a visual perception network and a formal\nlogical reasoner, exhibits exceptional performance on CLEVR-POC.",
      "tldr_zh": "本研究提出CLEVR-POC基准，用于评估推理密集型视觉问答(VQA)任务在部分可观察环境下的性能，该基准要求利用环境特定逻辑约束（如对象颜色规则）来推断隐藏对象的属性，从而生成可信答案。  \n与人类推理类似，CLEVR-POC强调整合背景知识以消除不一致选项，例如通过已知杯子颜色的约束推断被遮挡杯子的颜色。  \n实验结果显示，预训练模型如CLIP（约22%准确率）和GPT-4（约46%）表现不佳，突显了处理此类任务的挑战，而整合GPT-4、视觉感知网络和正式逻辑推理器的神经符号模型表现出色。  \n这项工作为开发更有效的AI推理框架提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 10 images, Accepted at LREC-COLING 2024 - The 2024 Joint\n  International Conference on Computational Linguistics, Language Resources and\n  Evaluation",
      "pdf_url": "http://arxiv.org/pdf/2403.03203v1",
      "published_date": "2024-03-05 18:41:37 UTC",
      "updated_date": "2024-03-05 18:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:34:05.967603"
    },
    {
      "arxiv_id": "2403.03188v2",
      "title": "Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement",
      "title_zh": "走向民主化的洪水风险管理：一个由 GPT-4 启用的高级 AI 助手，用于增强可解释性和公众参与",
      "authors": [
        "Rafaela Martelo",
        "Kimia Ahmadiyehyazdi",
        "Ruo-Qian Wang"
      ],
      "abstract": "Real-time flood forecasting is vital for effective emergency responses, but\nbridging the gap between complex numerical models and practical decision-making\nremains challenging. Decision-makers often rely on experts, while the public\nstruggles to interpret flood risk information. To address this, we developed a\ncustomized AI Assistant powered by GPT-4. This tool enhances communication\nbetween decision-makers, the public, and forecasters, requiring no specialized\nknowledge. The framework leverages GPT-4's advanced natural language\ncapabilities to search flood alerts, answer inquiries, and integrate real-time\nwarnings with flood maps and social vulnerability data. It simplifies complex\nflood zone information into actionable advice. The prototype was evaluated on\nrelevance, error resilience, and contextual understanding, with performance\ncompared across different GPT models. This research advances flood risk\nmanagement by making critical information more accessible and engaging,\ndemonstrating the potential of AI tools like GPT-4 in addressing social and\nenvironmental challenges.",
      "tldr_zh": "本研究针对洪水风险管理的决策挑战，提出了一种基于 GPT-4 的高级 AI 助手，以提升信息可解释性和公众参与。该助手利用 GPT-4 的自然语言处理能力，整合实时洪水警报、洪水地图和社会脆弱性数据，将复杂洪水信息简化成易懂的可操作建议，无需专业知识即可供决策者、公众和预报员使用。在评估中，该原型在相关性、错误耐受性和上下文理解方面表现出色，并优于其他 GPT 模型，从而推动洪水风险管理更具民主化和吸引力。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "I.2.1; I.2.7; J.2"
      ],
      "primary_category": "cs.AI",
      "comment": "48 pages, 3 figures and an appendix with 2 supplementary tables\n  detailing experimental results and observations. Supported by Rutgers's\n  Research Incubator in Climate and Health, Seed Funding Initiative and\n  Research Council Award - \"Engaged Climate Action\". Source code and data\n  available at https://github.com/RafaelaMartelo/FloodGPT-4_Prototype",
      "pdf_url": "http://arxiv.org/pdf/2403.03188v2",
      "published_date": "2024-03-05 18:24:52 UTC",
      "updated_date": "2024-12-20 20:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:34:17.846986"
    },
    {
      "arxiv_id": "2403.03187v1",
      "title": "Reliable, Adaptable, and Attributable Language Models with Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Akari Asai",
        "Zexuan Zhong",
        "Danqi Chen",
        "Pang Wei Koh",
        "Luke Zettlemoyer",
        "Hannaneh Hajishirzi",
        "Wen-tau Yih"
      ],
      "abstract": "Parametric language models (LMs), which are trained on vast amounts of web\ndata, exhibit remarkable flexibility and capability. However, they still face\npractical challenges such as hallucinations, difficulty in adapting to new data\ndistributions, and a lack of verifiability. In this position paper, we advocate\nfor retrieval-augmented LMs to replace parametric LMs as the next generation of\nLMs. By incorporating large-scale datastores during inference,\nretrieval-augmented LMs can be more reliable, adaptable, and attributable.\nDespite their potential, retrieval-augmented LMs have yet to be widely adopted\ndue to several obstacles: specifically, current retrieval-augmented LMs\nstruggle to leverage helpful text beyond knowledge-intensive tasks such as\nquestion answering, have limited interaction between retrieval and LM\ncomponents, and lack the infrastructure for scaling. To address these, we\npropose a roadmap for developing general-purpose retrieval-augmented LMs. This\ninvolves a reconsideration of datastores and retrievers, the exploration of\npipelines with improved retriever-LM interaction, and significant investment in\ninfrastructure for efficient training and inference.",
      "tldr_zh": "这篇论文讨论了Parametric LMs在实际应用中面临的挑战，包括幻觉问题、适应新数据分布的困难以及缺乏可验证性，并提倡采用Retrieval-Augmented LMs作为下一代语言模型，通过整合大规模数据存储来提升模型的可靠性、可适应性和可归因性。尽管Retrieval-Augmented LMs潜力巨大，但当前存在障碍，如仅限于知识密集任务、检索和LM组件交互有限，以及缺乏可扩展基础设施。为解决这些问题，论文提出了一条发展路线图，包括重新设计数据存储和检索器、探索改进交互的管道，以及投资高效训练和推理的基础设施。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03187v1",
      "published_date": "2024-03-05 18:22:33 UTC",
      "updated_date": "2024-03-05 18:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:34:30.066590"
    },
    {
      "arxiv_id": "2403.03186v3",
      "title": "Cradle: Empowering Foundation Agents Towards General Computer Control",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Tan",
        "Wentao Zhang",
        "Xinrun Xu",
        "Haochong Xia",
        "Ziluo Ding",
        "Boyu Li",
        "Bohan Zhou",
        "Junpeng Yue",
        "Jiechuan Jiang",
        "Yewen Li",
        "Ruyi An",
        "Molei Qin",
        "Chuqiao Zong",
        "Longtao Zheng",
        "Yujie Wu",
        "Xiaoqiang Chai",
        "Yifei Bi",
        "Tianbao Xie",
        "Pengjie Gu",
        "Xiyun Li",
        "Ceyao Zhang",
        "Long Tian",
        "Chaojie Wang",
        "Xinrun Wang",
        "Börje F. Karlsson",
        "Bo An",
        "Shuicheng Yan",
        "Zongqing Lu"
      ],
      "abstract": "Despite the success in specific scenarios, existing foundation agents still\nstruggle to generalize across various virtual scenarios, mainly due to the\ndramatically different encapsulations of environments with manually designed\nobservation and action spaces. To handle this issue, we propose the General\nComputer Control (GCC) setting to restrict foundation agents to interact with\nsoftware through the most unified and standardized interface, i.e., using\nscreenshots as input and keyboard and mouse actions as output. We introduce\nCradle, a modular and flexible LMM-powered framework, as a preliminary attempt\ntowards GCC. Enhanced by six key modules, Cradle can understand input\nscreenshots and output executable code for low-level keyboard and mouse control\nafter high-level planning, so that Cradle can interact with any software and\ncomplete long-horizon complex tasks without relying on any built-in APIs.\nExperimental results show that Cradle exhibits remarkable generalizability and\nimpressive performance across four previously unexplored commercial video\ngames, five software applications, and a comprehensive benchmark, OSWorld.\nCradle is the first to enable foundation agents to follow the main storyline\nand complete 40-minute-long real missions in the complex AAA game Red Dead\nRedemption 2 (RDR2). Cradle can also create a city of a thousand people in\nCities: Skylines, farm and harvest parsnips in Stardew Valley, and trade and\nbargain with a maximal weekly total profit of 87% in Dealer's Life 2. Cradle\ncan not only operate daily software, like Chrome, Outlook, and Feishu, but also\nedit images and videos using Meitu and CapCut. Cradle greatly extends the reach\nof foundation agents by enabling the easy conversion of any software,\nespecially complex games, into benchmarks to evaluate agents' various abilities\nand facilitate further data collection, thus paving the way for generalist\nagents.",
      "tldr_zh": "该论文提出 General Computer Control (GCC) 设置，以统一截图输入和键盘鼠标输出接口，解决 foundation agents 在不同虚拟环境泛化能力不足的问题。作者引入 Cradle，一个模块化的 LMM 驱动框架，通过六个关键模块进行高层规划和低级控制，实现与任何软件的交互，完成长时复杂任务而不依赖内置 API。实验结果显示，Cradle 在四个商业游戏（如 Red Dead Redemption 2，其中首次完成40分钟主线任务）、五个软件应用（如 Chrome 和 CapCut）以及 OSWorld 基准上表现出色，并为未来 generalist agents 的数据收集和评估铺平道路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03186v3",
      "published_date": "2024-03-05 18:22:29 UTC",
      "updated_date": "2024-07-02 17:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:34:41.753690"
    },
    {
      "arxiv_id": "2403.03185v4",
      "title": "Correlated Proxies: A New Definition and Improved Mitigation for Reward Hacking",
      "title_zh": "翻译失败",
      "authors": [
        "Cassidy Laidlaw",
        "Shivam Singhal",
        "Anca Dragan"
      ],
      "abstract": "Because it is difficult to precisely specify complex objectives,\nreinforcement learning policies are often optimized using proxy reward\nfunctions that only approximate the true goal. However, optimizing proxy\nrewards frequently leads to reward hacking: the optimized reward function\nceases to be a good proxy and the resulting policy performs poorly with respect\nto the unspecified true reward. Principled solutions to reward hacking have\nbeen impeded by the lack of a good definition for the problem. To address this\ngap, we introduce a definition of reward hacking based on the correlation\nbetween proxy and true rewards for states and actions seen by a \"reference\npolicy\" that breaks down under optimization. We show that this definition\ncaptures reward hacking behavior across several realistic settings, including\nin reinforcement learning from human feedback (RLHF). Using our formulation, we\nshow theoretically that regularization to the reference policy can effectively\nprevent reward hacking. While the current practice in RLHF applies a KL penalty\nbetween action distributions for this purpose, our theory suggests regularizing\nthe $\\chi^2$ divergence between the policies' occupancy measures can be more\neffective. We intuitively show the benefits of this type of regularization and\ndemonstrate that it better mitigates reward hacking in practice across four\nrealistic settings, including RLHF. Our code is available at\nhttps://github.com/cassidylaidlaw/orpo.",
      "tldr_zh": "本论文针对强化学习中代理奖励函数（proxy reward）优化导致的奖励黑客（reward hacking）问题，提出了一种基于参考策略（reference policy）下代理奖励和真实奖励相关性的新定义，以更精确地捕捉这一现象。该定义适用于多种场景，包括强化学习从人类反馈（RLHF）中。论文理论证明，通过对参考策略进行正则化可以有效缓解奖励黑客，并建议使用 χ² 散度对策略的占用测度（occupancy measures）进行正则化，比传统的 KL penalty 方法更有效。实验结果显示，这种方法在四个现实场景中显著改善了代理奖励的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Spotlight at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.03185v4",
      "published_date": "2024-03-05 18:22:15 UTC",
      "updated_date": "2025-03-13 17:35:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:34:54.998676"
    },
    {
      "arxiv_id": "2403.03183v1",
      "title": "How Well Can Transformers Emulate In-context Newton's Method?",
      "title_zh": "翻译失败",
      "authors": [
        "Angeliki Giannou",
        "Liu Yang",
        "Tianhao Wang",
        "Dimitris Papailiopoulos",
        "Jason D. Lee"
      ],
      "abstract": "Transformer-based models have demonstrated remarkable in-context learning\ncapabilities, prompting extensive research into its underlying mechanisms.\nRecent studies have suggested that Transformers can implement first-order\noptimization algorithms for in-context learning and even second order ones for\nthe case of linear regression. In this work, we study whether Transformers can\nperform higher order optimization methods, beyond the case of linear\nregression. We establish that linear attention Transformers with ReLU layers\ncan approximate second order optimization algorithms for the task of logistic\nregression and achieve $\\epsilon$ error with only a logarithmic to the error\nmore layers. As a by-product we demonstrate the ability of even linear\nattention-only Transformers in implementing a single step of Newton's iteration\nfor matrix inversion with merely two layers. These results suggest the ability\nof the Transformer architecture to implement complex algorithms, beyond\ngradient descent.",
      "tldr_zh": "本文研究了Transformers模型在in-context learning中模拟牛顿方法（Newton's Method）的能力。研究发现，linear attention Transformers结合ReLU layers可以近似二阶优化算法，用于logistic regression任务，并通过对误差的log对数层数实现ε error。进一步，作者证明了这些模型仅需两个层即可执行矩阵求逆的牛顿迭代单步，这些结果突显了Transformers在实现复杂算法（如超出梯度下降）方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03183v1",
      "published_date": "2024-03-05 18:20:10 UTC",
      "updated_date": "2024-03-05 18:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:35:06.799167"
    },
    {
      "arxiv_id": "2403.03181v2",
      "title": "Behavior Generation with Latent Actions",
      "title_zh": "基于潜在动作的行为生成",
      "authors": [
        "Seungjae Lee",
        "Yibin Wang",
        "Haritheja Etukuru",
        "H. Jin Kim",
        "Nur Muhammad Mahi Shafiullah",
        "Lerrel Pinto"
      ],
      "abstract": "Generative modeling of complex behaviors from labeled datasets has been a\nlongstanding problem in decision making. Unlike language or image generation,\ndecision making requires modeling actions - continuous-valued vectors that are\nmultimodal in their distribution, potentially drawn from uncurated sources,\nwhere generation errors can compound in sequential prediction. A recent class\nof models called Behavior Transformers (BeT) addresses this by discretizing\nactions using k-means clustering to capture different modes. However, k-means\nstruggles to scale for high-dimensional action spaces or long sequences, and\nlacks gradient information, and thus BeT suffers in modeling long-range\nactions. In this work, we present Vector-Quantized Behavior Transformer\n(VQ-BeT), a versatile model for behavior generation that handles multimodal\naction prediction, conditional generation, and partial observations. VQ-BeT\naugments BeT by tokenizing continuous actions with a hierarchical vector\nquantization module. Across seven environments including simulated\nmanipulation, autonomous driving, and robotics, VQ-BeT improves on\nstate-of-the-art models such as BeT and Diffusion Policies. Importantly, we\ndemonstrate VQ-BeT's improved ability to capture behavior modes while\naccelerating inference speed 5x over Diffusion Policies. Videos and code can be\nfound https://sjlee.cc/vq-bet",
      "tldr_zh": "该研究解决了决策行为生成中的挑战，特别是处理多模态动作的建模问题，指出现有方法如 Behavior Transformers (BeT) 因依赖 k-means 而在高维或长序列上表现不足。作者提出 Vector-Quantized Behavior Transformer (VQ-BeT)，通过分层向量量化 (hierarchical vector quantization) 模块对连续动作进行标记化，支持多模态动作预测、条件生成和部分观察。实验结果显示，VQ-BeT 在七个环境中（如模拟操作、自动驾驶和机器人）优于 BeT 和 Diffusion Policies，不仅更好地捕捉行为模式，还将推理速度提高了 5 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Github repo: https://github.com/jayLEE0301/vq_bet_official",
      "pdf_url": "http://arxiv.org/pdf/2403.03181v2",
      "published_date": "2024-03-05 18:19:29 UTC",
      "updated_date": "2024-06-28 04:15:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:35:19.531289"
    },
    {
      "arxiv_id": "2403.03176v1",
      "title": "Unifying and Certifying Top-Quality Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Katz",
        "Junkyu Lee",
        "Shirin Sohrabi"
      ],
      "abstract": "The growing utilization of planning tools in practical scenarios has sparked\nan interest in generating multiple high-quality plans. Consequently, a range of\ncomputational problems under the general umbrella of top-quality planning were\nintroduced over a short time period, each with its own definition. In this\nwork, we show that the existing definitions can be unified into one, based on a\ndominance relation. The different computational problems, therefore, simply\ncorrespond to different dominance relations. Given the unified definition, we\ncan now certify the top-quality of the solutions, leveraging existing\ncertification of unsolvability and optimality. We show that task\ntransformations found in the existing literature can be employed for the\nefficient certification of various top-quality planning problems and propose a\nnovel transformation to efficiently certify loopless top-quality planning.",
      "tldr_zh": "该论文统一了 top-quality planning 的多种定义，通过引入基于 dominance relation 的单一框架，将不同计算问题归类为不同 dominance relations。该方法利用现有的 unsolvability 和 optimality 认证技术，来高效验证解决方案的 top-quality 质量。作者展示了现有文献中的任务转换可用于认证各种 top-quality planning 问题，并提出一个新颖的转换，专门针对 loopless top-quality planning 的高效认证，从而提升了规划工具在实际场景中的可靠性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.03176v1",
      "published_date": "2024-03-05 18:13:18 UTC",
      "updated_date": "2024-03-05 18:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:35:28.955972"
    },
    {
      "arxiv_id": "2403.03174v3",
      "title": "MOKA: Open-World Robotic Manipulation through Mark-Based Visual Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Fangchen Liu",
        "Kuan Fang",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "abstract": "Open-world generalization requires robotic systems to have a profound\nunderstanding of the physical world and the user command to solve diverse and\ncomplex tasks. While the recent advancement in vision-language models (VLMs)\nhas offered unprecedented opportunities to solve open-world problems, how to\nleverage their capabilities to control robots remains a grand challenge. In\nthis paper, we introduce Marking Open-world Keypoint Affordances (MOKA), an\napproach that employs VLMs to solve robotic manipulation tasks specified by\nfree-form language instructions. Central to our approach is a compact\npoint-based representation of affordance, which bridges the VLM's predictions\non observed images and the robot's actions in the physical world. By prompting\nthe pre-trained VLM, our approach utilizes the VLM's commonsense knowledge and\nconcept understanding acquired from broad data sources to predict affordances\nand generate motions. To facilitate the VLM's reasoning in zero-shot and\nfew-shot manners, we propose a visual prompting technique that annotates marks\non images, converting affordance reasoning into a series of visual\nquestion-answering problems that are solvable by the VLM. We further explore\nmethods to enhance performance with robot experiences collected by MOKA through\nin-context learning and policy distillation. We evaluate and analyze MOKA's\nperformance on various table-top manipulation tasks including tool use,\ndeformable body manipulation, and object rearrangement.",
      "tldr_zh": "本论文提出 MOKA，一种基于 mark-based visual prompting 的方法，利用视觉语言模型 (VLMs) 来处理 open-world 机器人操作任务。MOKA 通过点-based affordance 表示，将 VLMs 的常识知识应用于图像标注和视觉问答问题，实现 zero-shot 和 few-shot 推理，并生成机器人动作。同时，该方法通过 in-context learning 和 policy distillation 整合机器人经验，提升任务性能。在桌面操作任务如工具使用、可变形物体操作和物体重新排列上，MOKA 展示了显著的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03174v3",
      "published_date": "2024-03-05 18:08:45 UTC",
      "updated_date": "2024-09-04 01:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:35:43.070738"
    },
    {
      "arxiv_id": "2403.03172v1",
      "title": "Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination",
      "title_zh": "翻译失败",
      "authors": [
        "Liangzhou Wang",
        "Kaiwen Zhu",
        "Fengming Zhu",
        "Xinghu Yao",
        "Shujie Zhang",
        "Deheng Ye",
        "Haobo Fu",
        "Qiang Fu",
        "Wei Yang"
      ],
      "abstract": "Reaching consensus is key to multi-agent coordination. To accomplish a\ncooperative task, agents need to coherently select optimal joint actions to\nmaximize the team reward. However, current cooperative multi-agent\nreinforcement learning (MARL) methods usually do not explicitly take consensus\ninto consideration, which may cause miscoordination problem. In this paper, we\npropose a model-based consensus mechanism to explicitly coordinate multiple\nagents. The proposed Multi-agent Goal Imagination (MAGI) framework guides\nagents to reach consensus with an Imagined common goal. The common goal is an\nachievable state with high value, which is obtained by sampling from the\ndistribution of future states. We directly model this distribution with a\nself-supervised generative model, thus alleviating the \"curse of dimensinality\"\nproblem induced by multi-agent multi-step policy rollout commonly used in\nmodel-based methods. We show that such efficient consensus mechanism can guide\nall agents cooperatively reaching valuable future states. Results on\nMulti-agent Particle-Environments and Google Research Football environment\ndemonstrate the superiority of MAGI in both sample efficiency and performance.",
      "tldr_zh": "该研究针对合作式多智能体强化学习(MARL)中代理协调问题，提出了一种基于模型的共识机制，以显式引导代理达成共识。Multi-agent Goal Imagination (MAGI)框架通过想象一个高价值的可达状态作为共同目标，并利用自监督生成模型来建模未来状态分布，从而缓解了多智能体多步策略展开引发的“curse of dimensionality”问题。实验结果显示，在Multi-agent Particle-Environments和Google Research Football环境中，MAGI在样本效率和整体性能上均优于基线方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03172v1",
      "published_date": "2024-03-05 18:07:34 UTC",
      "updated_date": "2024-03-05 18:07:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:35:53.574997"
    },
    {
      "arxiv_id": "2403.03170v1",
      "title": "SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection",
      "title_zh": "SNIFFER：用于可解释的脱离上下文错误信息检测的多模态大语言模型",
      "authors": [
        "Peng Qi",
        "Zehong Yan",
        "Wynne Hsu",
        "Mong Li Lee"
      ],
      "abstract": "Misinformation is a prevalent societal issue due to its potential high risks.\nOut-of-context (OOC) misinformation, where authentic images are repurposed with\nfalse text, is one of the easiest and most effective ways to mislead audiences.\nCurrent methods focus on assessing image-text consistency but lack convincing\nexplanations for their judgments, which is essential for debunking\nmisinformation. While Multimodal Large Language Models (MLLMs) have rich\nknowledge and innate capability for visual reasoning and explanation\ngeneration, they still lack sophistication in understanding and discovering the\nsubtle crossmodal differences. In this paper, we introduce SNIFFER, a novel\nmultimodal large language model specifically engineered for OOC misinformation\ndetection and explanation. SNIFFER employs two-stage instruction tuning on\nInstructBLIP. The first stage refines the model's concept alignment of generic\nobjects with news-domain entities and the second stage leverages language-only\nGPT-4 generated OOC-specific instruction data to fine-tune the model's\ndiscriminatory powers. Enhanced by external tools and retrieval, SNIFFER not\nonly detects inconsistencies between text and image but also utilizes external\nknowledge for contextual verification. Our experiments show that SNIFFER\nsurpasses the original MLLM by over 40% and outperforms state-of-the-art\nmethods in detection accuracy. SNIFFER also provides accurate and persuasive\nexplanations as validated by quantitative and human evaluations.",
      "tldr_zh": "这篇论文介绍了 SNIFFER，一种新型的多模态大语言模型 (MLLM)，专门用于检测 Out-of-Context (OOC) 误信息，并提供可解释的判断，以解决现有方法缺乏说服力解释的问题。SNIFFER 通过在 InstructBLIP 上进行两阶段指令微调来提升能力：第一阶段优化模型对通用对象与新闻领域实体的概念对齐，第二阶段利用 GPT-4 生成的 OOC 特定指令数据增强辨别力，并结合外部工具和检索进行文本-图像不一致验证。实验结果显示，SNIFFER 比原 MLLM 提高超过 40%，在检测准确性上优于最先进方法，并通过定量和人类评估证实其解释准确且有说服力。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.MM",
      "comment": "To appear in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.03170v1",
      "published_date": "2024-03-05 18:04:59 UTC",
      "updated_date": "2024-03-05 18:04:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:36:07.814713"
    },
    {
      "arxiv_id": "2403.03168v1",
      "title": "Learning Explicitly Conditioned Sparsifying Transforms",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Pătraşcu",
        "Cristian Rusu",
        "Paul Irofti"
      ],
      "abstract": "Sparsifying transforms became in the last decades widely known tools for\nfinding structured sparse representations of signals in certain transform\ndomains. Despite the popularity of classical transforms such as DCT and\nWavelet, learning optimal transforms that guarantee good representations of\ndata into the sparse domain has been recently analyzed in a series of papers.\nTypically, the conditioning number and representation ability are complementary\nkey features of learning square transforms that may not be explicitly\ncontrolled in a given optimization model. Unlike the existing approaches from\nthe literature, in our paper, we consider a new sparsifying transform model\nthat enforces explicit control over the data representation quality and the\ncondition number of the learned transforms. We confirm through numerical\nexperiments that our model presents better numerical behavior than the\nstate-of-the-art.",
      "tldr_zh": "本文探讨了sparsifying transforms在信号处理中的应用，强调了学习最优变换以获得结构化稀疏表示的重要性，但现有方法难以明确控制conditioning number和数据表示能力。该研究提出一个新模型，通过显式条件化强制调控数据表示质量和变换的conditioning number，从而优化学习过程。数值实验结果表明，该模型在数值表现上优于现有最先进方法。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "math.OC"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03168v1",
      "published_date": "2024-03-05 18:03:51 UTC",
      "updated_date": "2024-03-05 18:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:36:18.598035"
    },
    {
      "arxiv_id": "2403.03165v2",
      "title": "Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yaqian Qi",
        "Yuan Feng",
        "Xiangxiang Wang",
        "Hanzhe Li",
        "Jingxiao Tian"
      ],
      "abstract": "To enable large-scale and efficient deployment of artificial intelligence\n(AI), the combination of AI and edge computing has spawned Edge Intelligence,\nwhich leverages the computing and communication capabilities of end devices and\nedge servers to process data closer to where it is generated. A key technology\nfor edge intelligence is the privacy-protecting machine learning paradigm known\nas Federated Learning (FL), which enables data owners to train models without\nhaving to transfer raw data to third-party servers. However, FL networks are\nexpected to involve thousands of heterogeneous distributed devices. As a\nresult, communication efficiency remains a key bottleneck. To reduce node\nfailures and device exits, a Hierarchical Federated Learning (HFL) framework is\nproposed, where a designated cluster leader supports the data owner through\nintermediate model aggregation. Therefore, based on the improvement of edge\nserver resource utilization, this paper can effectively make up for the\nlimitation of cache capacity. In order to mitigate the impact of soft clicks on\nthe quality of user experience (QoE), the authors model the user QoE as a\ncomprehensive system cost. To solve the formulaic problem, the authors propose\na decentralized caching algorithm with federated deep reinforcement learning\n(DRL) and federated learning (FL), where multiple agents learn and make\ndecisions independently",
      "tldr_zh": "这篇论文探讨了如何利用 Federated Learning (FL) 和 Edge Computing 在云 computing 网络中优化推荐系统，以提升通信效率和数据隐私保护。作者提出了 Hierarchical Federated Learning (HFL) 框架，通过集群领导者进行中间模型聚合，减少节点故障和设备退出，同时改善边缘服务器资源利用率以弥补缓存容量限制。为了缓解软点击对用户 Quality of Experience (QoE) 的负面影响，他们设计了一种基于 federated Deep Reinforcement Learning (DRL) 和 FL 的去中心化缓存算法，让多个代理独立学习和决策，从而整体提升系统性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03165v2",
      "published_date": "2024-03-05 17:58:26 UTC",
      "updated_date": "2024-03-13 05:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:36:31.354977"
    },
    {
      "arxiv_id": "2403.03154v2",
      "title": "Quantum Many-Body Physics Calculations with Large Language Models",
      "title_zh": "量子多体物理计算",
      "authors": [
        "Haining Pan",
        "Nayantara Mudur",
        "Will Taranto",
        "Maria Tikhanovskaya",
        "Subhashini Venugopalan",
        "Yasaman Bahri",
        "Michael P. Brenner",
        "Eun-Ah Kim"
      ],
      "abstract": "Large language models (LLMs) have demonstrated an unprecedented ability to\nperform complex tasks in multiple domains, including mathematical and\nscientific reasoning. We demonstrate that with carefully designed prompts, LLMs\ncan accurately carry out key calculations in research papers in theoretical\nphysics. We focus on a broadly used approximation method in quantum physics:\nthe Hartree-Fock method, requiring an analytic multi-step calculation deriving\napproximate Hamiltonian and corresponding self-consistency equations. To carry\nout the calculations using LLMs, we design multi-step prompt templates that\nbreak down the analytic calculation into standardized steps with placeholders\nfor problem-specific information. We evaluate GPT-4's performance in executing\nthe calculation for 15 research papers from the past decade, demonstrating\nthat, with correction of intermediate steps, it can correctly derive the final\nHartree-Fock Hamiltonian in 13 cases and makes minor errors in 2 cases.\nAggregating across all research papers, we find an average score of 87.5 (out\nof 100) on the execution of individual calculation steps. Overall, the\nrequisite skill for doing these calculations is at the graduate level in\nquantum condensed matter theory. We further use LLMs to mitigate the two\nprimary bottlenecks in this evaluation process: (i) extracting information from\npapers to fill in templates and (ii) automatic scoring of the calculation\nsteps, demonstrating good results in both cases. The strong performance is the\nfirst step for developing algorithms that automatically explore theoretical\nhypotheses at an unprecedented scale.",
      "tldr_zh": "本文研究了 Large Language Models (LLMs) 在量子多体物理计算中的应用，特别通过精心设计的多步提示模板，帮助 LLMs 准确执行 Hartree-Fock 方法的分析计算，包括推导近似 Hamiltonian 和自洽方程。实验评估显示，GPT-4 在 15 篇过去十年论文上正确推导最终 Hamiltonian 的案例达 13 例，平均步骤执行分数为 87.5（满分 100），所需技能相当于量子凝聚态理论的研究生水平。此外，LLMs 成功缓解了评估瓶颈，如从论文中提取信息和自动评分，这为开发大规模自动探索理论假设的算法奠定了基础。",
      "categories": [
        "physics.comp-ph",
        "cond-mat.other",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "9 pages, 4 figures. Supplemental material in the source file",
      "pdf_url": "http://arxiv.org/pdf/2403.03154v2",
      "published_date": "2024-03-05 17:47:22 UTC",
      "updated_date": "2024-08-22 22:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:36:44.275789"
    },
    {
      "arxiv_id": "2403.03134v3",
      "title": "Simplicity in Complexity : Explaining Visual Complexity using Deep Segmentation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tingke Shen",
        "Surabhi S Nath",
        "Aenne Brielmann",
        "Peter Dayan"
      ],
      "abstract": "The complexity of visual stimuli plays an important role in many cognitive\nphenomena, including attention, engagement, memorability, time perception and\naesthetic evaluation. Despite its importance, complexity is poorly understood\nand ironically, previous models of image complexity have been quite complex.\nThere have been many attempts to find handcrafted features that explain\ncomplexity, but these features are usually dataset specific, and hence fail to\ngeneralise. On the other hand, more recent work has employed deep neural\nnetworks to predict complexity, but these models remain difficult to interpret,\nand do not guide a theoretical understanding of the problem. Here we propose to\nmodel complexity using segment-based representations of images. We use\nstate-of-the-art segmentation models, SAM and FC-CLIP, to quantify the number\nof segments at multiple granularities, and the number of classes in an image\nrespectively. We find that complexity is well-explained by a simple linear\nmodel with these two features across six diverse image-sets of naturalistic\nscene and art images. This suggests that the complexity of images can be\nsurprisingly simple.",
      "tldr_zh": "该研究探讨了视觉复杂性（visual complexity）在认知现象（如注意力、记忆和审美评价）中的作用，指出现有模型过于复杂且缺乏泛化性。作者提出使用先进的深度分割模型（deep segmentation models），包括 SAM 和 FC-CLIP，来量化图像的段数（在多个粒度级别）和类别数，并构建一个简单的线性模型来解释复杂性。在六个多样化的图像数据集上实验表明，这种基于段和类别的表示能有效预测复杂性，揭示图像复杂性实际上可以非常简单地建模。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03134v3",
      "published_date": "2024-03-05 17:21:31 UTC",
      "updated_date": "2024-05-06 12:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:36:56.140189"
    },
    {
      "arxiv_id": "2403.03114v2",
      "title": "Equilibria in Two-Stage Facility Location with Atomic Clients",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Krogmann",
        "Pascal Lenzner",
        "Alexander Skopalik",
        "Marc Uetz",
        "Marnix C. Vos"
      ],
      "abstract": "We consider competitive facility location as a two-stage multi-agent system\nwith two types of clients. For a given host graph with weighted clients on the\nvertices, first facility agents strategically select vertices for opening their\nfacilities. Then, the clients strategically select which of the opened\nfacilities in their neighborhood to patronize. Facilities want to attract as\nmuch client weight as possible, clients want to minimize congestion on the\nchosen facility.\n  All recently studied versions of this model assume that clients can split\ntheir weight strategically. We consider clients with unsplittable weights but\nallow mixed strategies. So clients may randomize over which facility to\npatronize. Besides modeling a natural client behavior, this subtle change\nyields drastic changes, e.g., for a given facility placement, qualitatively\ndifferent client equilibria are possible.\n  As our main result, we show that pure subgame perfect equilibria always exist\nif all client weights are identical. For this, we use a novel potential\nfunction argument, employing a hierarchical classification of the clients and\nsophisticated rounding in each step. In contrast, for non-identical clients, we\nshow that deciding the existence of even approximately stable states is\ncomputationally intractable. On the positive side, we give a tight bound of $2$\non the price of anarchy which implies high social welfare of equilibria, if\nthey exist.",
      "tldr_zh": "这篇论文研究了带有原子客户端的两阶段设施定位模型，其中设施代理在第一阶段战略性地选择位置，客户端在第二阶段则通过混合策略随机化来最小化设施拥堵。研究的主要贡献是证明了当所有客户端权重相同时，纯子博弈完美均衡（subgame perfect equilibria）总是存在，并引入了一个基于势函数（potential function）的层次分类和舍入方法来证明这一点。对于权重不同的客户端，判断近似稳定状态的存在是计算上困难的（computationally intractable）。此外，论文给出了价格of anarchy的紧密界为2，这表明即使在均衡存在时，社会福利也相对较高。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "full version of the article at the 33rd International Joint\n  Conference on Artificial Intelligence (IJCAI-2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.03114v2",
      "published_date": "2024-03-05 16:56:09 UTC",
      "updated_date": "2024-07-09 15:31:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:37:09.733091"
    },
    {
      "arxiv_id": "2403.03111v1",
      "title": "Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and Novel Outliers Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Afifi",
        "Mohamed ElHelw"
      ],
      "abstract": "Perception is a key element for enabling intelligent autonomous navigation.\nUnderstanding the semantics of the surrounding environment and accurate vehicle\npose estimation are essential capabilities for autonomous vehicles, including\nself-driving cars and mobile robots that perform complex tasks. Fast moving\nplatforms like self-driving cars impose a hard challenge for localization and\nmapping algorithms. In this work, we propose a novel framework for real-time\nLiDAR odometry and mapping based on LOAM architecture for fast moving\nplatforms. Our framework utilizes semantic information produced by a deep\nlearning model to improve point-to-line and point-to-plane matching between\nLiDAR scans and build a semantic map of the environment, leading to more\naccurate motion estimation using LiDAR data. We observe that including semantic\ninformation in the matching process introduces a new type of outlier matches to\nthe process, where matching occur between different objects of the same\nsemantic class. To this end, we propose a novel algorithm that explicitly\nidentifies and discards potential outliers in the matching process. In our\nexperiments, we study the effect of improving the matching process on the\nrobustness of LiDAR odometry against high speed motion. Our experimental\nevaluations on KITTI dataset demonstrate that utilizing semantic information\nand rejecting outliers significantly enhance the robustness of LiDAR odometry\nand mapping when there are large gaps between scan acquisition poses, which is\ntypical for fast moving platforms.",
      "tldr_zh": "本研究提出了一种改进的 LiDAR 测距和建图框架，基于 LOAM 架构，利用深度语义分割技术来提升 LiDAR 扫描之间的点到线和点到平面匹配准确性，从而构建环境语义地图并改善车辆位姿估计。针对语义信息引入的新型异常匹配问题（如相同语义类别的不同物体匹配），论文设计了一个新颖的异常检测算法来识别和排除这些异常。实验结果在 KITTI 数据集上表明，该框架显著提高了 LiDAR 测距和建图的鲁棒性，尤其在高速移动平台下的大扫描间隙场景中。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03111v1",
      "published_date": "2024-03-05 16:53:24 UTC",
      "updated_date": "2024-03-05 16:53:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:37:22.064776"
    },
    {
      "arxiv_id": "2403.03102v4",
      "title": "\"In Dialogues We Learn\": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanqi Cheng",
        "Quan Tu",
        "Shuo Shang",
        "Cunli Mao",
        "Zhengtao Yu",
        "Wei Wu",
        "Rui Yan"
      ],
      "abstract": "Personalized dialogue systems have gained significant attention in recent\nyears for their ability to generate responses in alignment with different\npersonas. However, most existing approaches rely on pre-defined personal\nprofiles, which are not only time-consuming and labor-intensive to create but\nalso lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning\nframework that enhances the ability of pre-trained large language models to\nleverage dialogue history to characterize persona for completing personalized\ndialogue generation tasks without pre-defined profiles. Our experiments on\nthree datasets demonstrate that IDL brings substantial improvements, with BLEU\nand ROUGE scores increasing by up to 200% and 247%, respectively. Additionally,\nthe results of human evaluations further validate the efficacy of our proposed\nmethod.",
      "tldr_zh": "该研究针对个性化对话系统的局限性，提出 In-Dialogue Learning (IDL) 框架，该方法通过微调预训练的大型语言模型，利用对话历史来表征个性，从而实现无需预定义个人资料的个性化对话生成。IDL 避免了传统方法耗时且缺乏灵活性的问题，在三个数据集上的实验显示，BLEU 和 ROUGE 分数分别提高了多达 200% 和 247%。此外，人为评估进一步证实了该框架的有效性，为更灵活的对话系统开发提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.03102v4",
      "published_date": "2024-03-05 16:43:03 UTC",
      "updated_date": "2024-10-13 10:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:37:32.367066"
    },
    {
      "arxiv_id": "2403.03101v3",
      "title": "KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqi Zhu",
        "Shuofei Qiao",
        "Yixin Ou",
        "Shumin Deng",
        "Shiwei Lyu",
        "Yue Shen",
        "Lei Liang",
        "Jinjie Gu",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great potential in complex\nreasoning tasks, yet they fall short when tackling more sophisticated\nchallenges, especially when interacting with environments through generating\nexecutable actions. This inadequacy primarily stems from the lack of built-in\naction knowledge in language agents, which fails to effectively guide the\nplanning trajectories during task solving and results in planning\nhallucination. To address this issue, we introduce KnowAgent, a novel approach\ndesigned to enhance the planning capabilities of LLMs by incorporating explicit\naction knowledge. Specifically, KnowAgent employs an action knowledge base and\na knowledgeable self-learning strategy to constrain the action path during\nplanning, enabling more reasonable trajectory synthesis, and thereby enhancing\nthe planning performance of language agents. Experimental results on HotpotQA\nand ALFWorld based on various backbone models demonstrate that KnowAgent can\nachieve comparable or superior performance to existing baselines. Further\nanalysis indicates the effectiveness of KnowAgent in terms of planning\nhallucinations mitigation. Code is available in\nhttps://github.com/zjunlp/KnowAgent.",
      "tldr_zh": "大型语言模型 (LLMs) 在复杂推理任务中潜力巨大，但由于缺少内置动作知识，在生成可执行动作和环境交互时容易出现规划幻觉 (planning hallucination)。为此，本文提出 KnowAgent，一种知识增强规划方法，利用动作知识库和知识丰富的自学习策略来约束规划轨迹，实现更合理的行动路径合成。实验结果显示，在 HotpotQA 和 ALFWorld 数据集上，KnowAgent 基于多种骨干模型的表现优于或相当现有基线，并显著缓解了规划幻觉问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Findings. Project page:\n  https://zjunlp.github.io/project/KnowAgent/ Code:\n  https://github.com/zjunlp/KnowAgent",
      "pdf_url": "http://arxiv.org/pdf/2403.03101v3",
      "published_date": "2024-03-05 16:39:12 UTC",
      "updated_date": "2025-02-21 05:04:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:37:45.183532"
    },
    {
      "arxiv_id": "2403.03100v3",
      "title": "NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zeqian Ju",
        "Yuancheng Wang",
        "Kai Shen",
        "Xu Tan",
        "Detai Xin",
        "Dongchao Yang",
        "Yanqing Liu",
        "Yichong Leng",
        "Kaitao Song",
        "Siliang Tang",
        "Zhizheng Wu",
        "Tao Qin",
        "Xiang-Yang Li",
        "Wei Ye",
        "Shikun Zhang",
        "Jiang Bian",
        "Lei He",
        "Jinyu Li",
        "Sheng Zhao"
      ],
      "abstract": "While recent large-scale text-to-speech (TTS) models have achieved\nsignificant progress, they still fall short in speech quality, similarity, and\nprosody. Considering speech intricately encompasses various attributes (e.g.,\ncontent, prosody, timbre, and acoustic details) that pose significant\nchallenges for generation, a natural idea is to factorize speech into\nindividual subspaces representing different attributes and generate them\nindividually. Motivated by it, we propose NaturalSpeech 3, a TTS system with\nnovel factorized diffusion models to generate natural speech in a zero-shot\nway. Specifically, 1) we design a neural codec with factorized vector\nquantization (FVQ) to disentangle speech waveform into subspaces of content,\nprosody, timbre, and acoustic details; 2) we propose a factorized diffusion\nmodel to generate attributes in each subspace following its corresponding\nprompt. With this factorization design, NaturalSpeech 3 can effectively and\nefficiently model intricate speech with disentangled subspaces in a\ndivide-and-conquer way. Experiments show that NaturalSpeech 3 outperforms the\nstate-of-the-art TTS systems on quality, similarity, prosody, and\nintelligibility, and achieves on-par quality with human recordings.\nFurthermore, we achieve better performance by scaling to 1B parameters and 200K\nhours of training data.",
      "tldr_zh": "本研究提出 NaturalSpeech 3，一种基于因子化编解码器和扩散模型的零样本语音合成系统，旨在解决现有 Text-to-Speech (TTS) 模型在语音质量、相似性和韵律方面的不足。系统通过因子化向量量化 (FVQ) 将语音波形分解成内容、韵律、音色和声学细节的独立子空间，并使用因子化扩散模型根据相应提示生成每个子空间的属性，从而高效地处理复杂的语音生成任务。实验结果显示，NaturalSpeech 3 在质量、相似性、韵律和可理解性上优于最先进 TTS 系统，并达到人类录音的同等水平；此外，通过扩展到 1B 参数和 20W 小时训练数据，系统性能进一步提升。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Achieving human-level quality and naturalness on multi-speaker\n  datasets (e.g., LibriSpeech) in a zero-shot way",
      "pdf_url": "http://arxiv.org/pdf/2403.03100v3",
      "published_date": "2024-03-05 16:35:25 UTC",
      "updated_date": "2024-04-23 08:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:37:57.936843"
    },
    {
      "arxiv_id": "2403.03089v1",
      "title": "VQSynery: Robust Drug Synergy Prediction With Vector Quantization Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Wu",
        "Mingyuan Yan",
        "Dianbo Liu"
      ],
      "abstract": "The pursuit of optimizing cancer therapies is significantly advanced by the\naccurate prediction of drug synergy. Traditional methods, such as clinical\ntrials, are reliable yet encumbered by extensive time and financial demands.\nThe emergence of high-throughput screening and computational innovations has\nheralded a shift towards more efficient methodologies for exploring drug\ninteractions. In this study, we present VQSynergy, a novel framework that\nemploys the Vector Quantization (VQ) mechanism, integrated with gated residuals\nand a tailored attention mechanism, to enhance the precision and\ngeneralizability of drug synergy predictions. Our findings demonstrate that\nVQSynergy surpasses existing models in terms of robustness, particularly under\nGaussian noise conditions, highlighting its superior performance and utility in\nthe complex and often noisy domain of drug synergy research. This study\nunderscores the potential of VQSynergy in revolutionizing the field through its\nadvanced predictive capabilities, thereby contributing to the optimization of\ncancer treatment strategies.",
      "tldr_zh": "本研究提出VQSynergy框架，利用Vector Quantization (VQ)机制、gated residuals和定制的attention机制，来提升药物协同作用的预测精度和泛化性，以优化癌症疗法。相比传统方法如临床试验，该框架显著减少了时间和成本需求，并在Gaussian noise条件下表现出色，鲁棒性超越现有模型。总体而言，VQSynergy为复杂药物交互研究提供可靠工具，有助于推进癌症治疗策略的创新。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03089v1",
      "published_date": "2024-03-05 16:21:53 UTC",
      "updated_date": "2024-03-05 16:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:38:07.854727"
    },
    {
      "arxiv_id": "2403.03082v1",
      "title": "Recall-Oriented Continual Learning with Generative Adversarial Meta-Model",
      "title_zh": "翻译失败",
      "authors": [
        "Haneol Kang",
        "Dong-Wan Choi"
      ],
      "abstract": "The stability-plasticity dilemma is a major challenge in continual learning,\nas it involves balancing the conflicting objectives of maintaining performance\non previous tasks while learning new tasks. In this paper, we propose the\nrecall-oriented continual learning framework to address this challenge.\nInspired by the human brain's ability to separate the mechanisms responsible\nfor stability and plasticity, our framework consists of a two-level\narchitecture where an inference network effectively acquires new knowledge and\na generative network recalls past knowledge when necessary. In particular, to\nmaximize the stability of past knowledge, we investigate the complexity of\nknowledge depending on different representations, and thereby introducing\ngenerative adversarial meta-model (GAMM) that incrementally learns\ntask-specific parameters instead of input data samples of the task. Through our\nexperiments, we show that our framework not only effectively learns new\nknowledge without any disruption but also achieves high stability of previous\nknowledge in both task-aware and task-agnostic learning scenarios. Our code is\navailable at: https://github.com/bigdata-inha/recall-oriented-cl-framework.",
      "tldr_zh": "该研究针对持续学习中的稳定性-可塑性困境（stability-plasticity dilemma），提出了一种以回忆为导向的框架（recall-oriented continual learning），旨在平衡旧任务性能的维护和新任务的学习。框架采用两级架构，包括 inference network 用于获取新知识，以及 generative network 通过 generative adversarial meta-model (GAMM) 来回忆过去知识，GAMM 通过学习任务特定参数而非输入数据样本，从而最大化知识稳定性。实验结果显示，该框架在任务感知（task-aware）和任务无关（task-agnostic）场景中均能有效学习新知识而不干扰旧知识，并提供了开源代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in AAAI-2024 (Oral presentation)",
      "pdf_url": "http://arxiv.org/pdf/2403.03082v1",
      "published_date": "2024-03-05 16:08:59 UTC",
      "updated_date": "2024-03-05 16:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:38:21.002083"
    },
    {
      "arxiv_id": "2403.03239v2",
      "title": "Note: Harnessing Tellurium Nanoparticles in the Digital Realm Plasmon Resonance, in the Context of Brewster's Angle and the Drude Model for Fake News Adsorption in Incomplete Information Games",
      "title_zh": "翻译失败",
      "authors": [
        "Yasuko Kawahata"
      ],
      "abstract": "This note explores the innovative application of soliton theory and plasmonic\nphenomena in modeling user behavior and engagement within digital health\nplatforms. By introducing the concept of soliton solutions, we present a novel\napproach to understanding stable patterns of health improvement behaviors over\ntime. Additionally, we delve into the role of tellurium nanoparticles and their\nplasmonic properties in adsorbing fake news, thereby influencing user\ninteractions and engagement levels. Through a theoretical framework that\ncombines nonlinear dynamics with the unique characteristics of tellurium\nnanoparticles, we aim to provide new insights into the dynamics of user\nengagement in digital health environments. Our analysis highlights the\npotential of soliton theory in capturing the complex, nonlinear dynamics of\nuser behavior, while the application of plasmonic phenomena offers a promising\navenue for enhancing the sensitivity and effectiveness of digital health\nplatforms. This research ventures into an uncharted territory where optical\nphenomena such as Brewster's Angle and Snell's Law, along with the concept of\nspin solitons, are metaphorically applied to address the challenge of fake news\ndissemination. By exploring the analogy between light refraction, reflection,\nand the propagation of information in digital platforms, we unveil a novel\nperspective on how the 'angle' at which information is presented can\nsignificantly affect its acceptance and spread. Additionally, we propose the\nuse of tellurium nanoparticles to manage 'information waves' through mechanisms\nakin to plasmonic resonance and soliton dynamics. This theoretical exploration\naims to bridge the gap between physical sciences and digital communication,\noffering insights into the development of strategies for mitigating\nmisinformation.",
      "tldr_zh": "这篇论文探索了soliton theory和plasmonic phenomena在数字健康平台用户行为建模中的创新应用，旨在通过孤子解决方案理解健康改善行为的稳定模式，并利用tellurium nanoparticles的特性来吸附假新闻，影响用户互动。论文结合非线性动力学、Brewster's Angle、Snell's Law和Drude Model等光学概念，构建了一个理论框架，将物理科学比喻应用于数字通信。研究发现，这种方法能有效捕捉用户行为的复杂非线性动态，并为缓解假新闻传播提供新策略，从而提升数字平台的敏感性和有效性。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Tellurium Nanoparticles, Snell's Law, Soliton Solution, Anamorphic\n  Surfaces, Nonlinear Dynamics, Fake News Adsorption, User Behavior Modeling,\n  Health Improvement Strategies, Plasmonic Sensors This paper is partially an\n  attempt to utilize \"Generative AI\" and was written with educational intent.\n  There are currently no plans for it to become a peer-reviewed paper",
      "pdf_url": "http://arxiv.org/pdf/2403.03239v2",
      "published_date": "2024-03-05 16:07:57 UTC",
      "updated_date": "2024-04-19 14:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:38:33.596875"
    },
    {
      "arxiv_id": "2403.03053v1",
      "title": "Neural Codebook Design for Network Beam Management",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan M. Dreifuerst",
        "Robert W. Heath Jr"
      ],
      "abstract": "Obtaining accurate and timely channel state information (CSI) is a\nfundamental challenge for large antenna systems. Mobile systems like 5G use a\nbeam management framework that joins the initial access, beamforming, CSI\nacquisition, and data transmission. The design of codebooks for these stages,\nhowever, is challenging due to their interrelationships, varying array sizes,\nand site-specific channel and user distributions. Furthermore, beam management\nis often focused on single-sector operations while ignoring the overarching\nnetwork- and system-level optimization. In this paper, we proposed an\nend-to-end learned codebook design algorithm, network beamspace learning (NBL),\nthat captures and optimizes codebooks to mitigate interference while maximizing\nthe achievable performance with extremely large hybrid arrays. The proposed\nalgorithm requires limited shared information yet designs codebooks that\noutperform traditional codebooks by over 10dB in beam alignment and achieve\nmore than 25% improvements in network spectral efficiency.",
      "tldr_zh": "该论文针对大型天线系统中获取准确信道状态信息(CSI)的挑战，探讨了波束管理框架的设计问题，包括初始接入、波束形成和数据传输，并强调了代码本设计需考虑阵列大小和网络级优化。作者提出了一种端到端学习算法，称为网络波束空间学习(NBL)，通过有限的共享信息捕获并优化代码本，以减轻干扰并提升性能。实验结果显示，NBL在波束对齐方面比传统代码本提高超过10dB，并在网络频谱效率上实现超过25%的改善。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.IT",
        "cs.NI",
        "cs.SY",
        "eess.SY",
        "math.IT"
      ],
      "primary_category": "eess.SP",
      "comment": "To be submitted to IEEE Transactions on Wireless Communications",
      "pdf_url": "http://arxiv.org/pdf/2403.03053v1",
      "published_date": "2024-03-05 15:37:06 UTC",
      "updated_date": "2024-03-05 15:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:38:45.109873"
    },
    {
      "arxiv_id": "2403.03030v1",
      "title": "Unifying Controller Design for Stabilizing Nonlinear Systems with Norm-Bounded Control Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Li",
        "Zhiyong Sun",
        "Siep Weiland"
      ],
      "abstract": "This paper revisits a classical challenge in the design of stabilizing\ncontrollers for nonlinear systems with a norm-bounded input constraint. By\nextending Lin-Sontag's universal formula and introducing a generic\n(state-dependent) scaling term, a unifying controller design method is\nproposed. The incorporation of this generic scaling term gives a unified\ncontroller and enables the derivation of alternative universal formulas with\nvarious favorable properties, which makes it suitable for tailored control\ndesigns to meet specific requirements and provides versatility across different\ncontrol scenarios. Additionally, we present a constructive approach to\ndetermine the optimal scaling term, leading to an explicit solution to an\noptimization problem, named optimization-based universal formula. The resulting\ncontroller ensures asymptotic stability, satisfies a norm-bounded input\nconstraint, and optimizes a predefined cost function. Finally, the essential\nproperties of the unified controllers are analyzed, including smoothness,\ncontinuity at the origin, stability margin, and inverse optimality. Simulations\nvalidate the approach, showcasing its effectiveness in addressing a challenging\nstabilizing control problem of a nonlinear system.",
      "tldr_zh": "这篇论文针对带有规范边界输入约束的非线性系统，提出了一种统一的控制器设计方法，通过扩展 Lin-Sontag 的通用公式并引入状态相关的缩放项，以增强控制器的灵活性和适用性。该方法派生出多种优化的通用公式，支持定制设计以满足特定需求，并提供构建最优缩放项的显式优化方案，确保渐近稳定性、输入约束满足以及成本函数优化。最后，通过分析控制器的平滑性、在原点的连续性、稳定性裕度（margin）和逆最优性（inverse optimality），以及模拟实验，验证了该方法在处理非线性系统稳定控制问题的有效性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03030v1",
      "published_date": "2024-03-05 15:06:16 UTC",
      "updated_date": "2024-03-05 15:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:38:59.278953"
    },
    {
      "arxiv_id": "2403.03028v1",
      "title": "Word Importance Explains How Prompts Affect Language Model Outputs",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Hackmann",
        "Haniyeh Mahmoudian",
        "Mark Steadman",
        "Michael Schmidt"
      ],
      "abstract": "The emergence of large language models (LLMs) has revolutionized numerous\napplications across industries. However, their \"black box\" nature often hinders\nthe understanding of how they make specific decisions, raising concerns about\ntheir transparency, reliability, and ethical use. This study presents a method\nto improve the explainability of LLMs by varying individual words in prompts to\nuncover their statistical impact on the model outputs. This approach, inspired\nby permutation importance for tabular data, masks each word in the system\nprompt and evaluates its effect on the outputs based on the available text\nscores aggregated over multiple user inputs. Unlike classical attention, word\nimportance measures the impact of prompt words on arbitrarily-defined text\nscores, which enables decomposing the importance of words into the specific\nmeasures of interest--including bias, reading level, verbosity, etc. This\nprocedure also enables measuring impact when attention weights are not\navailable. To test the fidelity of this approach, we explore the effect of\nadding different suffixes to multiple different system prompts and comparing\nsubsequent generations with different large language models. Results show that\nword importance scores are closely related to the expected suffix importances\nfor multiple scoring functions.",
      "tldr_zh": "这项研究探讨了大型语言模型 (LLMs) 的提示如何影响输出，并提出了一种“word importance”方法来提升模型的可解释性。该方法受启发于置换重要性 (permutation importance)，通过屏蔽系统提示中的单个单词并评估其对文本分数的统计影响，来量化每个单词对输出（如偏见、阅读水平或冗长）的贡献，与传统注意力机制不同，它适用于任意定义的评分函数且不依赖注意力权重。实验结果显示，在不同系统提示中添加后缀后，word importance 分数与预期的后缀重要性高度相关，证明了该方法在分析 LLMs 决策时的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7; I.5.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03028v1",
      "published_date": "2024-03-05 15:04:18 UTC",
      "updated_date": "2024-03-05 15:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:39:10.012128"
    },
    {
      "arxiv_id": "2403.03020v3",
      "title": "SplAgger: Split Aggregation for Meta-Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Beck",
        "Matthew Jackson",
        "Risto Vuorio",
        "Zheng Xiong",
        "Shimon Whiteson"
      ],
      "abstract": "A core ambition of reinforcement learning (RL) is the creation of agents\ncapable of rapid learning in novel tasks. Meta-RL aims to achieve this by\ndirectly learning such agents. Black box methods do so by training\noff-the-shelf sequence models end-to-end. By contrast, task inference methods\nexplicitly infer a posterior distribution over the unknown task, typically\nusing distinct objectives and sequence models designed to enable task\ninference. Recent work has shown that task inference methods are not necessary\nfor strong performance. However, it remains unclear whether task inference\nsequence models are beneficial even when task inference objectives are not. In\nthis paper, we present evidence that task inference sequence models are indeed\nstill beneficial. In particular, we investigate sequence models with\npermutation invariant aggregation, which exploit the fact that, due to the\nMarkov property, the task posterior does not depend on the order of data. We\nempirically confirm the advantage of permutation invariant sequence models\nwithout the use of task inference objectives. However, we also find,\nsurprisingly, that there are multiple conditions under which permutation\nvariance remains useful. Therefore, we propose SplAgger, which uses both\npermutation variant and invariant components to achieve the best of both\nworlds, outperforming all baselines evaluated on continuous control and memory\nenvironments. Code is provided at https://github.com/jacooba/hyper.",
      "tldr_zh": "本文探讨了Meta-Reinforcement Learning中任务推断序列模型的益处，通过实验验证了permutation invariant aggregation序列模型的优势，即使不使用任务推断目标。研究发现，在某些条件下，permutation variance组件仍然有用，因此提出SplAgger方法，该方法结合permutation variant和invariant组件，实现最佳性能，并在连续控制和记忆环境中优于所有基线模型。SplAgger的代码已在GitHub上公开，提供进一步验证的可能性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at Reinforcement Learning Conference (RLC) 2024. Code is\n  provided at https://github.com/jacooba/hyper",
      "pdf_url": "http://arxiv.org/pdf/2403.03020v3",
      "published_date": "2024-03-05 14:57:04 UTC",
      "updated_date": "2024-06-01 22:35:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:39:22.223890"
    },
    {
      "arxiv_id": "2403.03017v1",
      "title": "OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following",
      "title_zh": "翻译失败",
      "authors": [
        "Haochen Shi",
        "Zhiyuan Sun",
        "Xingdi Yuan",
        "Marc-Alexandre Côté",
        "Bang Liu"
      ],
      "abstract": "Embodied Instruction Following (EIF) is a crucial task in embodied learning,\nrequiring agents to interact with their environment through egocentric\nobservations to fulfill natural language instructions. Recent advancements have\nseen a surge in employing large language models (LLMs) within a\nframework-centric approach to enhance performance in embodied learning tasks,\nincluding EIF. Despite these efforts, there exists a lack of a unified\nunderstanding regarding the impact of various components-ranging from visual\nperception to action execution-on task performance. To address this gap, we\nintroduce OPEx, a comprehensive framework that delineates the core components\nessential for solving embodied learning tasks: Observer, Planner, and Executor.\nThrough extensive evaluations, we provide a deep analysis of how each component\ninfluences EIF task performance. Furthermore, we innovate within this space by\ndeploying a multi-agent dialogue strategy on a TextWorld counterpart, further\nenhancing task performance. Our findings reveal that LLM-centric design\nmarkedly improves EIF outcomes, identify visual perception and low-level action\nexecution as critical bottlenecks, and demonstrate that augmenting LLMs with a\nmulti-agent framework further elevates performance.",
      "tldr_zh": "该论文分析了大型语言模型(LLM)中心代理在Embodied Instruction Following (EIF)任务中的组件影响，引入了OPEx框架，将任务分解为Observer（观察者）、Planner（规划者）和Executor（执行者）三大核心组件。研究通过广泛评估探讨了每个组件对EIF性能的影响，并创新性地采用多智能体对话策略在TextWorld环境中提升任务表现。结果显示，LLM中心设计显著改善EIF效果，但视觉感知和低级动作执行是主要瓶颈，而多智能体框架进一步优化了整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03017v1",
      "published_date": "2024-03-05 14:53:53 UTC",
      "updated_date": "2024-03-05 14:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:39:32.683301"
    },
    {
      "arxiv_id": "2403.03008v1",
      "title": "Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Abu-Rasheed",
        "Christian Weber",
        "Madjid Fathi"
      ],
      "abstract": "In the era of personalized education, the provision of comprehensible\nexplanations for learning recommendations is of a great value to enhance the\nlearner's understanding and engagement with the recommended learning content.\nLarge language models (LLMs) and generative AI in general have recently opened\nnew doors for generating human-like explanations, for and along learning\nrecommendations. However, their precision is still far away from acceptable in\na sensitive field like education. To harness the abilities of LLMs, while still\nensuring a high level of precision towards the intent of the learners, this\npaper proposes an approach to utilize knowledge graphs (KG) as a source of\nfactual context, for LLM prompts, reducing the risk of model hallucinations,\nand safeguarding against wrong or imprecise information, while maintaining an\napplication-intended learning context. We utilize the semantic relations in the\nknowledge graph to offer curated knowledge about learning recommendations. With\ndomain-experts in the loop, we design the explanation as a textual template,\nwhich is filled and completed by the LLM. Domain experts were integrated in the\nprompt engineering phase as part of a study, to ensure that explanations\ninclude information that is relevant to the learner. We evaluate our approach\nquantitatively using Rouge-N and Rouge-L measures, as well as qualitatively\nwith experts and learners. Our results show an enhanced recall and precision of\nthe generated explanations compared to those generated solely by the GPT model,\nwith a greatly reduced risk of generating imprecise information in the final\nlearning explanation.",
      "tldr_zh": "本论文探讨了在个性化教育中，使用知识图谱（KG）作为上下文来源来提升基于大型语言模型（LLM）的学习推荐解释的精确性。研究提出一种方法，通过KG提供事实性的语义关系信息，结合LLM提示工程和领域专家设计的文本模板，减少模型幻觉风险并确保解释与学习者意图相关。实验结果显示，与仅使用GPT模型相比，该方法在Rouge-N和Rouge-L指标上显著提高了回忆和精确度，并通过专家和学习者定性评估证实了生成信息的可靠性。整体而言，此框架为教育领域的可信AI解释提供了实用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.03008v1",
      "published_date": "2024-03-05 14:41:12 UTC",
      "updated_date": "2024-03-05 14:41:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:39:45.087213"
    },
    {
      "arxiv_id": "2403.03002v1",
      "title": "Mem-elements based Neuromorphic Hardware for Neural Network Application",
      "title_zh": "翻译失败",
      "authors": [
        "Ankur Singh"
      ],
      "abstract": "The thesis investigates the utilization of memristive and memcapacitive\ncrossbar arrays in low-power machine learning accelerators, offering a\ncomprehensive co-design framework for deep neural networks (DNN). The model,\nimplemented through a hybrid Python and PyTorch approach, accounts for various\nnon-idealities, achieving exceptional training accuracies of 90.02% and 91.03%\nfor the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on\nan 8-layer VGG network. Additionally, the thesis introduces a novel approach to\nemulate meminductor devices using Operational Transconductance Amplifiers (OTA)\nand capacitors, showcasing adjustable behavior. Transistor-level simulations in\n180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed\nmeminductor emulator's viability with a power consumption of 0.337 mW. The\ndesign is further validated in neuromorphic circuits and CNN accelerators,\nachieving training and testing accuracies of 91.04% and 88.82%, respectively.\nNotably, the exclusive use of MOS transistors ensures the feasibility of\nmonolithic IC fabrication. This research significantly contributes to the\nexploration of advanced hardware solutions for efficient and high-performance\nmachine-learning applications.",
      "tldr_zh": "本研究探讨了基于 memristive 和 memcapacitive crossbar arrays 的神经形态硬件，用于低功耗机器学习加速器，提出一个全面的深度神经网络 (DNN) 协同设计框架。框架采用混合 Python 和 PyTorch 方法，考虑各种非理想性，在 CIFAR-10 数据集上实现 8 层 VGG network 的训练准确率高达 90.02% 和 91.03%。此外，研究创新性地使用 Operational Transconductance Amplifiers (OTA) 和电容仿真 meminductor 设备，并在 180 nm CMOS 技术下以 60 MHz 运行，功耗仅 0.337 mW，同时在神经形态电路和 CNN accelerators 中验证，达到 91.04% 的训练准确率和 88.82% 的测试准确率。该工作通过完全使用 MOS 晶体管确保单片集成电路 (IC) 制造的可行性，为高效高性能机器学习应用提供先进硬件解决方案。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.NE",
      "comment": "Master's Thesis",
      "pdf_url": "http://arxiv.org/pdf/2403.03002v1",
      "published_date": "2024-03-05 14:28:40 UTC",
      "updated_date": "2024-03-05 14:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:39:58.916600"
    },
    {
      "arxiv_id": "2403.02995v1",
      "title": "Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees",
      "title_zh": "使用集成树缓解恶意 URL 检测器中的标签翻转攻击",
      "authors": [
        "Ehsan Nowroozi",
        "Nada Jadalla",
        "Samaneh Ghelichkhani",
        "Alireza Jolfaei"
      ],
      "abstract": "Malicious URLs provide adversarial opportunities across various industries,\nincluding transportation, healthcare, energy, and banking which could be\ndetrimental to business operations. Consequently, the detection of these URLs\nis of crucial importance; however, current Machine Learning (ML) models are\nsusceptible to backdoor attacks. These attacks involve manipulating a small\npercentage of training data labels, such as Label Flipping (LF), which changes\nbenign labels to malicious ones and vice versa. This manipulation results in\nmisclassification and leads to incorrect model behavior. Therefore, integrating\ndefense mechanisms into the architecture of ML models becomes an imperative\nconsideration to fortify against potential attacks.\n  The focus of this study is on backdoor attacks in the context of URL\ndetection using ensemble trees. By illuminating the motivations behind such\nattacks, highlighting the roles of attackers, and emphasizing the critical\nimportance of effective defense strategies, this paper contributes to the\nongoing efforts to fortify ML models against adversarial threats within the ML\ndomain in network security. We propose an innovative alarm system that detects\nthe presence of poisoned labels and a defense mechanism designed to uncover the\noriginal class labels with the aim of mitigating backdoor attacks on ensemble\ntree classifiers. We conducted a case study using the Alexa and Phishing Site\nURL datasets and showed that LF attacks can be addressed using our proposed\ndefense mechanism. Our experimental results prove that the LF attack achieved\nan Attack Success Rate (ASR) between 50-65% within 2-5%, and the innovative\ndefense method successfully detected poisoned labels with an accuracy of up to\n100%.",
      "tldr_zh": "该研究针对恶意 URL 检测中的后门攻击，特别是 Label Flipping (LF) 攻击，探讨了如何利用 Ensemble Trees 分类器进行防御。论文提出了一种创新的警报系统来检测毒化标签，以及一个防御机制来恢复原始标签，从而缓解模型的误分类问题。实验使用 Alexa 和 Phishing Site URL 数据集进行验证，结果显示 LF 攻击的 Attack Success Rate (ASR) 为 50-65%，而提出的防御方法能以高达 100% 的准确率检测毒化标签，有效提升了网络安全中的 ML 模型鲁棒性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02995v1",
      "published_date": "2024-03-05 14:21:57 UTC",
      "updated_date": "2024-03-05 14:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:40:10.222833"
    },
    {
      "arxiv_id": "2403.02993v1",
      "title": "Localized Zeroth-Order Prompt Optimization",
      "title_zh": "局部零阶提示优化",
      "authors": [
        "Wenyang Hu",
        "Yao Shu",
        "Zongmin Yu",
        "Zhaoxuan Wu",
        "Xiangqiang Lin",
        "Zhongxiang Dai",
        "See-Kiong Ng",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "The efficacy of large language models (LLMs) in understanding and generating\nnatural language has aroused a wide interest in developing prompt-based methods\nto harness the power of black-box LLMs. Existing methodologies usually\nprioritize a global optimization for finding the global optimum, which however\nwill perform poorly in certain tasks. This thus motivates us to re-think the\nnecessity of finding a global optimum in prompt optimization. To answer this,\nwe conduct a thorough empirical study on prompt optimization and draw two major\ninsights. Contrasting with the rarity of global optimum, local optima are\nusually prevalent and well-performed, which can be more worthwhile for\nefficient prompt optimization (Insight I). The choice of the input domain,\ncovering both the generation and the representation of prompts, affects the\nidentification of well-performing local optima (Insight II). Inspired by these\ninsights, we propose a novel algorithm, namely localized zeroth-order prompt\noptimization (ZOPO), which incorporates a Neural Tangent Kernel-based derived\nGaussian process into standard zeroth-order optimization for an efficient\nsearch of well-performing local optima in prompt optimization. Remarkably, ZOPO\noutperforms existing baselines in terms of both the optimization performance\nand the query efficiency, which we demonstrate through extensive experiments.",
      "tldr_zh": "该研究通过实证分析发现，在大型语言模型(LLMs)的提示优化中，局部最优解比全局最优解更常见且性能更可靠，这使得专注于局部优化更具效率(Insight I)；此外，提示的输入域选择（如生成和表示方式）会影响局部最优解的识别(Insight II)。为此，作者提出了一种新算法Localized Zeroth-Order Prompt Optimization (ZOPO)，它将Neural Tangent Kernel-based派生的Gaussian process整合到标准的zeroth-order优化中，以高效搜索高性能局部最优解。实验结果显示，ZOPO在优化性能和查询效率上均优于现有基线方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02993v1",
      "published_date": "2024-03-05 14:18:15 UTC",
      "updated_date": "2024-03-05 14:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:40:21.934550"
    },
    {
      "arxiv_id": "2403.02990v4",
      "title": "Data Augmentation using Large Language Models: Data Perspectives, Learning Paradigms and Challenges",
      "title_zh": "使用大型语言模型的数据增强：数据视角、学习范式和挑战",
      "authors": [
        "Bosheng Ding",
        "Chengwei Qin",
        "Ruochen Zhao",
        "Tianze Luo",
        "Xinze Li",
        "Guizhen Chen",
        "Wenhan Xia",
        "Junjie Hu",
        "Anh Tuan Luu",
        "Shafiq Joty"
      ],
      "abstract": "In the rapidly evolving field of large language models (LLMs), data\naugmentation (DA) has emerged as a pivotal technique for enhancing model\nperformance by diversifying training examples without the need for additional\ndata collection. This survey explores the transformative impact of LLMs on DA,\nparticularly addressing the unique challenges and opportunities they present in\nthe context of natural language processing (NLP) and beyond. From both data and\nlearning perspectives, we examine various strategies that utilize LLMs for data\naugmentation, including a novel exploration of learning paradigms where\nLLM-generated data is used for diverse forms of further training. Additionally,\nthis paper highlights the primary open challenges faced in this domain, ranging\nfrom controllable data augmentation to multi-modal data augmentation. This\nsurvey highlights a paradigm shift introduced by LLMs in DA, and aims to serve\nas a comprehensive guide for researchers and practitioners.",
      "tldr_zh": "这篇论文调查了大型语言模型 (LLMs) 在数据增强 (DA) 中的应用，探讨了从数据和学习视角利用 LLMs 来多样化训练样本，从而提升模型性能，而无需额外数据收集。论文介绍了多种策略，包括使用 LLM 生成数据进行进一步训练，并扩展到自然语言处理 (NLP) 及其他领域。最终，它突出了关键挑战，如可控数据增强和多模态数据增强，并强调 LLMs 引发了 DA 的范式转变，为研究者和从业者提供全面指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02990v4",
      "published_date": "2024-03-05 14:11:54 UTC",
      "updated_date": "2024-07-02 07:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:40:33.832878"
    },
    {
      "arxiv_id": "2403.02985v1",
      "title": "Evolution Transformer: In-Context Evolutionary Optimization",
      "title_zh": "Evolution Transformer：上下文中的进化优化",
      "authors": [
        "Robert Tjarko Lange",
        "Yingtao Tian",
        "Yujin Tang"
      ],
      "abstract": "Evolutionary optimization algorithms are often derived from loose biological\nanalogies and struggle to leverage information obtained during the sequential\ncourse of optimization. An alternative promising approach is to leverage data\nand directly discover powerful optimization principles via meta-optimization.\nIn this work, we follow such a paradigm and introduce Evolution Transformer, a\ncausal Transformer architecture, which can flexibly characterize a family of\nEvolution Strategies. Given a trajectory of evaluations and search distribution\nstatistics, Evolution Transformer outputs a performance-improving update to the\nsearch distribution. The architecture imposes a set of suitable inductive\nbiases, i.e. the invariance of the distribution update to the order of\npopulation members within a generation and equivariance to the order of the\nsearch dimensions. We train the model weights using Evolutionary Algorithm\nDistillation, a technique for supervised optimization of sequence models using\nteacher algorithm trajectories. The resulting model exhibits strong in-context\noptimization performance and shows strong generalization capabilities to\notherwise challenging neuroevolution tasks. We analyze the resulting properties\nof the Evolution Transformer and propose a technique to fully\nself-referentially train the Evolution Transformer, starting from a random\ninitialization and bootstrapping its own learning progress. We provide an open\nsource implementation under https://github.com/RobertTLange/evosax.",
      "tldr_zh": "该论文引入了 Evolution Transformer，一种基于 Causal Transformer 的架构，用于提升进化优化算法的性能，通过直接从数据中学习优化原则来解决传统算法在序列信息利用上的不足。该模型输出基于评估轨迹和搜索分布统计的性能改进更新，并通过 Evolutionary Algorithm Distillation 技术进行训练，具备对种群成员顺序不变性和搜索维度等变性的归纳偏差。实验结果表明，Evolution Transformer 在 in-context 优化中表现出色，能够泛化到复杂的神经进化任务，并支持自指训练方法，同时提供开源实现。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02985v1",
      "published_date": "2024-03-05 14:04:13 UTC",
      "updated_date": "2024-03-05 14:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:40:46.199846"
    },
    {
      "arxiv_id": "2403.02983v1",
      "title": "Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Nowroozi",
        "Imran Haider",
        "Rahim Taheri",
        "Mauro Conti"
      ],
      "abstract": "Federated Learning (FL) is a machine learning (ML) approach that enables\nmultiple decentralized devices or edge servers to collaboratively train a\nshared model without exchanging raw data. During the training and sharing of\nmodel updates between clients and servers, data and models are susceptible to\ndifferent data-poisoning attacks.\n  In this study, our motivation is to explore the severity of data poisoning\nattacks in the computer network domain because they are easy to implement but\ndifficult to detect. We considered two types of data-poisoning attacks, label\nflipping (LF) and feature poisoning (FP), and applied them with a novel\napproach. In LF, we randomly flipped the labels of benign data and trained the\nmodel on the manipulated data. For FP, we randomly manipulated the highly\ncontributing features determined using the Random Forest algorithm. The\ndatasets used in this experiment were CIC and UNSW related to computer\nnetworks. We generated adversarial samples using the two attacks mentioned\nabove, which were applied to a small percentage of datasets. Subsequently, we\ntrained and tested the accuracy of the model on adversarial datasets. We\nrecorded the results for both benign and manipulated datasets and observed\nsignificant differences between the accuracy of the models on different\ndatasets. From the experimental results, it is evident that the LF attack\nfailed, whereas the FP attack showed effective results, which proved its\nsignificance in fooling a server. With a 1% LF attack on the CIC, the accuracy\nwas approximately 0.0428 and the ASR was 0.9564; hence, the attack is easily\ndetectable, while with a 1% FP attack, the accuracy and ASR were both\napproximately 0.9600, hence, FP attacks are difficult to detect. We repeated\nthe experiment with different poisoning percentages.",
      "tldr_zh": "这篇论文探讨了Federated Learning (FL) 在计算机网络中的漏洞，重点暴露数据中毒攻击的严重性。研究人员实现了两种攻击：label flipping (LF)，通过随机翻转标签来操纵数据；以及feature poisoning (FP)，使用Random Forest算法识别并修改高贡献特征，并应用在CIC和UNSW数据集上。实验结果显示，FP攻击比LF攻击更有效且难以检测，例如在1%攻击比例下，FP攻击的准确率和攻击成功率（ASR）均约0.9600，而LF攻击导致准确率急剧下降至0.0428，并易于识别。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02983v1",
      "published_date": "2024-03-05 14:03:15 UTC",
      "updated_date": "2024-03-05 14:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:40:59.619899"
    },
    {
      "arxiv_id": "2403.02975v2",
      "title": "A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Yao"
      ],
      "abstract": "Sentence semantic matching is a research hotspot in natural language\nprocessing, which is considerably significant in various key scenarios, such as\ncommunity question answering, searching, chatbot, and recommendation. Since\nmost of the advanced models directly model the semantic relevance among words\nbetween two sentences while neglecting the \\textit{keywords} and\n\\textit{intents} concepts of them, DC-Match is proposed to disentangle keywords\nfrom intents and utilizes them to optimize the matching performance. Although\nDC-Match is a simple yet effective method for semantic matching, it highly\ndepends on the external NER techniques to identify the keywords of sentences,\nwhich limits the performance of semantic matching for minor languages since\nsatisfactory NER tools are usually hard to obtain. In this paper, we propose to\ngenerally and flexibly resolve the text into multi concepts for multilingual\nsemantic matching to liberate the model from the reliance on NER models. To\nthis end, we devise a \\underline{M}ulti-\\underline{C}oncept \\underline{P}arsed\n\\underline{S}emantic \\underline{M}atching framework based on the pre-trained\nlanguage models, abbreviated as \\textbf{MCP-SM}, to extract various concepts\nand infuse them into the classification tokens. We conduct comprehensive\nexperiments on English datasets QQP and MRPC, and Chinese dataset Medical-SM.\nBesides, we experiment on Arabic datasets MQ2Q and XNLI, the outstanding\nperformance further prove MCP-SM's applicability in low-resource languages.",
      "tldr_zh": "本研究针对多语种语义匹配(Semantic Matching)问题，提出了一种通用且灵活的多概念解析框架MCP-SM，基于预训练语言模型(Pre-trained Language Models)提取句子中的各种概念（如关键词和意图），从而避免了对外部NER技术的依赖。MCP-SM框架将这些概念融入分类标记中，优化了匹配性能，并在英语数据集(QQP和MRPC)、中文数据集(Medical-SM)以及阿拉伯语数据集(MQ2Q和XNLI)上进行了全面实验。结果显示，该框架在低资源语言上表现出色，进一步提升了语义匹配的鲁棒性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin comment: This version has been removed by arXiv\n  administrators as the submitter did not have the rights to agree to the\n  license at the time of submission",
      "pdf_url": "http://arxiv.org/pdf/2403.02975v2",
      "published_date": "2024-03-05 13:55:16 UTC",
      "updated_date": "2024-04-04 01:07:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:41:11.332114"
    },
    {
      "arxiv_id": "2403.02966v3",
      "title": "Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Sungho Ko",
        "Hyunjin Cho",
        "Hyungjoo Chae",
        "Jinyoung Yeo",
        "Dongha Lee"
      ],
      "abstract": "Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance\nQuesetion Answering (QA) performance of Large Language Models (LLMs), yet\nstructured KG verbalization remains challengin. Existing methods, such as\ntriple-form or free-form textual conversion of triple-form facts, encounter\nseveral issues. These include reduced evidence density due to duplicated\nentities or relationships, and reduced evidence clarity due to an inability to\nemphasize crucial evidence. To address these issues, we propose EFSum, an\nEvidence-focused Fact Summarization framework for enhanced QA with\nknowledge-augmented LLMs. We optimize an open-source LLM as a fact summarizer\nthrough distillation and preference alignment. Our extensive experiments show\nthat EFSum improves LLM's zero-shot QA performance, and it is possible to\nensure both the helpfulness and faithfulness of the summary.",
      "tldr_zh": "该研究针对利用知识图谱（KGs）增强大型语言模型（LLMs）的问答（QA）性能时存在的证据密度和清晰度问题，提出了一种证据聚焦事实总结框架 EFSum。EFSum 通过优化开源 LLM 作为事实总结器，采用蒸馏（distillation）和偏好对齐（preference alignment）技术，来生成更精确且高效的知识总结。实验结果显示，该框架显著提高了 LLMs 的零样本 QA 性能，同时确保了总结的有用性（helpfulness）和忠实性（faithfulness）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02966v3",
      "published_date": "2024-03-05 13:43:58 UTC",
      "updated_date": "2024-10-09 12:46:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:41:23.011684"
    },
    {
      "arxiv_id": "2403.02965v2",
      "title": "ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Hassanpour",
        "Yasamin Kowsari",
        "Hatef Otroshi Shahreza",
        "Bian Yang",
        "Sebastien Marcel"
      ],
      "abstract": "This paper explores the application of large language models (LLMs), like\nChatGPT, for biometric tasks. We specifically examine the capabilities of\nChatGPT in performing biometric-related tasks, with an emphasis on face\nrecognition, gender detection, and age estimation. Since biometrics are\nconsidered as sensitive information, ChatGPT avoids answering direct prompts,\nand thus we crafted a prompting strategy to bypass its safeguard and evaluate\nthe capabilities for biometrics tasks. Our study reveals that ChatGPT\nrecognizes facial identities and differentiates between two facial images with\nconsiderable accuracy. Additionally, experimental results demonstrate\nremarkable performance in gender detection and reasonable accuracy for the age\nestimation tasks. Our findings shed light on the promising potentials in the\napplication of LLMs and foundation models for biometrics.",
      "tldr_zh": "本研究评估了大型语言模型 ChatGPT 在生物特征任务中的性能，重点考察了 face recognition、gender detection 和 age estimation 的能力。由于 ChatGPT 对敏感信息有安全机制，研究者设计了提示策略来绕过这些限制。结果显示，ChatGPT 在识别面部身份和区分两张面部图像方面准确性较高，在 gender detection 上表现出色，而在 age estimation 上达到了合理准确率。这些发现突显了 LLMs 和基础模型在生物特征应用领域的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at IEEE International Conference on\n  Image Processing (ICIP) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02965v2",
      "published_date": "2024-03-05 13:41:25 UTC",
      "updated_date": "2024-12-11 09:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:41:34.654631"
    },
    {
      "arxiv_id": "2403.02962v1",
      "title": "WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Li",
        "Xiang Chen",
        "Xiaojun Wan"
      ],
      "abstract": "Tabular data, as a crucial form of data representation, exists in diverse\nformats on the Web. When confronted with complex and irregular tables, manual\nmodification becomes a laborious task. This paper investigates the performance\nof Large Language Models (LLMs) in the context of table editing tasks. Existing\nresearch mainly focuses on regular-shaped tables, wherein instructions are used\nto generate code in SQL, Python, or Excel Office-script for manipulating the\ntables. Nevertheless, editing tables with irregular structures, particularly\nthose containing merged cells spanning multiple rows, poses a challenge when\nusing code. To address this, we introduce the WikiTableEdit dataset. Leveraging\n26,531 tables from the WikiSQL dataset, we automatically generate natural\nlanguage instructions for six distinct basic operations and the corresponding\noutcomes, resulting in over 200,000 instances. Subsequently, we evaluate\nseveral representative large language models on the WikiTableEdit dataset to\ndemonstrate the challenge of this task. The dataset will be released to the\ncommunity to promote related researches.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在通过自然语言指令编辑表格任务中的性能，特别针对复杂不规则表格（如包含合并单元格的结构）的挑战。研究者引入了 WikiTableEdit 数据集，该数据集基于 WikiSQL 的 26,531 个表格，自动生成超过 20 万个实例，包括六种基本操作的自然语言指令及其对应结果。实验评估了多个代表性 LLMs，突显了任务的难度，并计划发布数据集以推动相关研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02962v1",
      "published_date": "2024-03-05 13:33:12 UTC",
      "updated_date": "2024-03-05 13:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:41:47.228188"
    },
    {
      "arxiv_id": "2403.02959v3",
      "title": "AgentsCourt: Building Judicial Decision-Making Agents with Court Debate Simulation and Legal Knowledge Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhitao He",
        "Pengfei Cao",
        "Chenhao Wang",
        "Zhuoran Jin",
        "Yubo Chen",
        "Jiexin Xu",
        "Huaijun Li",
        "Xiaojian Jiang",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "With the development of deep learning, natural language processing technology\nhas effectively improved the efficiency of various aspects of the traditional\njudicial industry. However, most current efforts focus on tasks within\nindividual judicial stages, making it difficult to handle complex tasks that\nspan multiple stages. As the autonomous agents powered by large language models\nare becoming increasingly smart and able to make complex decisions in\nreal-world settings, offering new insights for judicial intelligence. In this\npaper, (1) we propose a novel multi-agent framework, AgentsCourt, for judicial\ndecision-making. Our framework follows the classic court trial process,\nconsisting of court debate simulation, legal resources retrieval and\ndecision-making refinement to simulate the decision-making of judge. (2) we\nintroduce SimuCourt, a judicial benchmark that encompasses 420 Chinese judgment\ndocuments, spanning the three most common types of judicial cases. Furthermore,\nto support this task, we construct a large-scale legal knowledge base,\nLegal-KB, with multi-resource legal knowledge. (3) Extensive experiments show\nthat our framework outperforms the existing advanced methods in various\naspects, especially in generating legal articles, where our model achieves\nsignificant improvements of 8.6% and 9.1% F1 score in the first and second\ninstance settings, respectively.",
      "tldr_zh": "本研究提出AgentsCourt，一种多智能体框架，用于模拟法庭辩论和法律知识增强，以支持司法决策过程。该框架遵循经典法庭审判流程，包括法庭辩论模拟、法律资源检索和决策精炼，利用大型语言模型实现自主决策。研究者构建了SimuCourt基准数据集，包含420个中文判决文档，覆盖三种常见司法案件类型，并开发了大型法律知识库Legal-KB以辅助任务。实验结果显示，AgentsCourt在生成法律文章方面显著优于现有方法，提高了F1 score（第一实例8.6%、第二实例9.1%）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2403.02959v3",
      "published_date": "2024-03-05 13:30:02 UTC",
      "updated_date": "2024-09-21 14:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:41:57.451705"
    },
    {
      "arxiv_id": "2405.06642v4",
      "title": "PPFlow: Target-aware Peptide Design with Torsional Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Haitao Lin",
        "Odin Zhang",
        "Huifeng Zhao",
        "Dejun Jiang",
        "Lirong Wu",
        "Zicheng Liu",
        "Yufei Huang",
        "Stan Z. Li"
      ],
      "abstract": "Therapeutic peptides have proven to have great pharmaceutical value and\npotential in recent decades. However, methods of AI-assisted peptide drug\ndiscovery are not fully explored. To fill the gap, we propose a target-aware\npeptide design method called \\textsc{PPFlow}, based on conditional flow\nmatching on torus manifolds, to model the internal geometries of torsion angles\nfor the peptide structure design. Besides, we establish a protein-peptide\nbinding dataset named PPBench2024 to fill the void of massive data for the task\nof structure-based peptide drug design and to allow the training of deep\nlearning methods. Extensive experiments show that PPFlow reaches\nstate-of-the-art performance in tasks of peptide drug generation and\noptimization in comparison with baseline models, and can be generalized to\nother tasks including docking and side-chain packing.",
      "tldr_zh": "该研究提出了一种目标感知肽设计方法 PPFlow，利用基于 torus manifolds 的 conditional flow matching 来建模肽结构中 torsion angles 的内部几何结构，从而辅助肽药物发现。研究者还建立了大规模蛋白-肽结合数据集 PPBench2024，以支持结构-based 肽药物设计任务的深度学习训练。实验结果表明，PPFlow 在 peptide drug generation 和 optimization 任务中达到 state-of-the-art 性能，并能泛化到 docking 和 side-chain packing 等相关任务。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.06642v4",
      "published_date": "2024-03-05 13:26:42 UTC",
      "updated_date": "2024-12-09 11:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:42:09.977582"
    },
    {
      "arxiv_id": "2403.02951v2",
      "title": "Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Zhang",
        "Yuxiao Ye",
        "Guoqing Du",
        "Xiaoru Hu",
        "Zhishuai Li",
        "Sun Yang",
        "Chi Harold Liu",
        "Rui Zhao",
        "Ziyue Li",
        "Hangyu Mao"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as a powerful tool in advancing the\nText-to-SQL task, significantly outperforming traditional methods.\nNevertheless, as a nascent research field, there is still no consensus on the\noptimal prompt templates and design frameworks. Additionally, existing\nbenchmarks inadequately explore the performance of LLMs across the various\nsub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs'\ncognitive capabilities and the optimization of LLM-based solutions. To address\nthe aforementioned issues, we firstly construct a new dataset designed to\nmitigate the risk of overfitting in LLMs. Then we formulate five evaluation\ntasks to comprehensively assess the performance of diverse methods across\nvarious LLMs throughout the Text-to-SQL process.Our study highlights the\nperformance disparities among LLMs and proposes optimal in-context learning\nsolutions tailored to each task. These findings offer valuable insights for\nenhancing the development of LLM-based Text-to-SQL systems.",
      "tldr_zh": "该研究对大语言模型 (LLMs) 在 Text-to-SQL 任务中的能力进行了全面评估，指出现有方法缺乏最佳提示模板和框架，且基准测试未能充分覆盖子任务。研究者构建了一个新数据集，以减少 LLMs 的过拟合风险，并制定了五个评估任务，系统评估不同 LLMs 的性能差异。结果显示，LLMs 之间存在显著差距，并提出了针对每个任务的最佳 in-context learning 解决方案，为优化基于 LLMs 的 Text-to-SQL 系统提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26pages, 6figures, 14tables",
      "pdf_url": "http://arxiv.org/pdf/2403.02951v2",
      "published_date": "2024-03-05 13:23:48 UTC",
      "updated_date": "2024-03-06 08:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:42:23.009889"
    },
    {
      "arxiv_id": "2403.02950v1",
      "title": "A general approach to enhance the survivability of backdoor attacks by decision path coupling",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Zhao",
        "Dingji Wang",
        "Bihuan Chen",
        "Ziqian Chen",
        "Xin Peng"
      ],
      "abstract": "Backdoor attacks have been one of the emerging security threats to deep\nneural networks (DNNs), leading to serious consequences. One of the mainstream\nbackdoor defenses is model reconstruction-based. Such defenses adopt model\nunlearning or pruning to eliminate backdoors. However, little attention has\nbeen paid to survive from such defenses. To bridge the gap, we propose Venom,\nthe first generic backdoor attack enhancer to improve the survivability of\nexisting backdoor attacks against model reconstruction-based defenses. We\nformalize Venom as a binary-task optimization problem. The first is the\noriginal backdoor attack task to preserve the original attack capability, while\nthe second is the attack enhancement task to improve the attack survivability.\nTo realize the second task, we propose attention imitation loss to force the\ndecision path of poisoned samples in backdoored models to couple with the\ncrucial decision path of benign samples, which makes backdoors difficult to\neliminate. Our extensive evaluation on two DNNs and three datasets has\ndemonstrated that Venom significantly improves the survivability of eight\nstate-of-the-art attacks against eight state-of-the-art defenses without\nimpacting the capability of the original attacks.",
      "tldr_zh": "本论文提出Venom，一种通用方法，通过决策路径耦合（decision path coupling）来提升后门攻击（backdoor attacks）对基于模型重建的防御（如模型卸载或修剪）的生存能力。Venom将问题形式化为二元任务优化：一方面保留原始攻击能力，另一方面通过注意力模仿损失（attention imitation loss）强制后门样本的决策路径与良性样本的关键路径耦合，从而使后门更难被消除。实验在两个深度神经网络（DNNs）和三个数据集上评估，结果显示Venom显著提高了八种最先进攻击对八种最先进防御的生存能力，同时不影响原始攻击性能。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02950v1",
      "published_date": "2024-03-05 13:21:20 UTC",
      "updated_date": "2024-03-05 13:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:42:35.718296"
    },
    {
      "arxiv_id": "2403.02946v1",
      "title": "SAFFIRA: a Framework for Assessing the Reliability of Systolic-Array-Based DNN Accelerators",
      "title_zh": "SAFFIRA：用于评估基于脉冲阵列的DNN加速器可靠性的框架",
      "authors": [
        "Mahdi Taheri",
        "Masoud Daneshtalab",
        "Jaan Raik",
        "Maksim Jenihhin",
        "Salvatore Pappalardo",
        "Paul Jimenez",
        "Bastien Deveautour",
        "Alberto Bosio"
      ],
      "abstract": "Systolic array has emerged as a prominent architecture for Deep Neural\nNetwork (DNN) hardware accelerators, providing high-throughput and low-latency\nperformance essential for deploying DNNs across diverse applications. However,\nwhen used in safety-critical applications, reliability assessment is mandatory\nto guarantee the correct behavior of DNN accelerators. While fault injection\nstands out as a well-established practical and robust method for reliability\nassessment, it is still a very time-consuming process. This paper addresses the\ntime efficiency issue by introducing a novel hierarchical software-based\nhardware-aware fault injection strategy tailored for systolic array-based DNN\naccelerators.",
      "tldr_zh": "该论文提出 SAFFIRA 框架，用于评估基于 Systolic Array 的 DNN Accelerators 的可靠性，以满足安全关键应用的需求。传统的故障注入方法虽然可靠，但耗时过长，因此作者引入了一种新型的分层软件-based 硬件-aware 故障注入策略，以显著提高评估效率。该框架针对 Systolic Array 架构优化，确保 DNN 加速器的正确行为，并为实际部署提供更高效的可靠性保障。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02946v1",
      "published_date": "2024-03-05 13:17:09 UTC",
      "updated_date": "2024-03-05 13:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:42:46.523594"
    },
    {
      "arxiv_id": "2403.02939v2",
      "title": "PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers",
      "title_zh": "PaperWeaver：通过使用用户收集的论文为推荐论文提供上下文来丰富",
      "authors": [
        "Yoonjoo Lee",
        "Hyeonsu B. Kang",
        "Matt Latzke",
        "Juho Kim",
        "Jonathan Bragg",
        "Joseph Chee Chang",
        "Pao Siangliulue"
      ],
      "abstract": "With the rapid growth of scholarly archives, researchers subscribe to \"paper\nalert\" systems that periodically provide them with recommendations of recently\npublished papers that are similar to previously collected papers. However,\nresearchers sometimes struggle to make sense of nuanced connections between\nrecommended papers and their own research context, as existing systems only\npresent paper titles and abstracts. To help researchers spot these connections,\nwe present PaperWeaver, an enriched paper alerts system that provides\ncontextualized text descriptions of recommended papers based on user-collected\npapers. PaperWeaver employs a computational method based on Large Language\nModels (LLMs) to infer users' research interests from their collected papers,\nextract context-specific aspects of papers, and compare recommended and\ncollected papers on these aspects. Our user study (N=15) showed that\nparticipants using PaperWeaver were able to better understand the relevance of\nrecommended papers and triage them more confidently when compared to a baseline\nthat presented the related work sections from recommended papers.",
      "tldr_zh": "该研究提出 PaperWeaver 系统，以提升论文警报的实用性，通过将推荐论文与用户收集的论文进行上下文化比较，帮助研究人员更好地理解其相关性。PaperWeaver 利用 Large Language Models (LLMs) 来推断用户的研究兴趣、提取论文的特定方面，并对推荐论文和用户论文进行对比分析。用户研究 (N=15) 表明，与基线方法相比，使用 PaperWeaver 的参与者能更准确地评估推荐论文的相关性，并更自信地进行分类。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.DL",
      "comment": "Accepted to CHI 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02939v2",
      "published_date": "2024-03-05 13:10:06 UTC",
      "updated_date": "2024-05-09 07:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:42:59.466011"
    },
    {
      "arxiv_id": "2403.02936v1",
      "title": "AdAM: Adaptive Fault-Tolerant Approximate Multiplier for Edge DNN Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Taheri",
        "Natalia Cherezova",
        "Samira Nazari",
        "Ahsan Rafiq",
        "Ali Azarpeyvand",
        "Tara Ghasempouri",
        "Masoud Daneshtalab",
        "Jaan Raik",
        "Maksim Jenihhin"
      ],
      "abstract": "In this paper, we propose an architecture of a novel adaptive fault-tolerant\napproximate multiplier tailored for ASIC-based DNN accelerators.",
      "tldr_zh": "本研究提出了一种名为AdAM的自适应容错近似乘法器（Adaptive Fault-Tolerant Approximate Multiplier），专门针对基于ASIC的DNN加速器设计。AdAM通过自适应机制和容错功能，优化了边缘计算环境下的乘法运算，以提升DNN加速器的鲁棒性和效率。该架构为边缘DNN加速器提供了更可靠的硬件解决方案，潜在地降低了功耗并提高了整体性能。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02936v1",
      "published_date": "2024-03-05 13:03:31 UTC",
      "updated_date": "2024-03-05 13:03:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:43:11.392848"
    },
    {
      "arxiv_id": "2403.02933v1",
      "title": "Fuzzy Datalog$^\\exists$ over Arbitrary t-Norms",
      "title_zh": "翻译失败",
      "authors": [
        "Matthias Lanzinger",
        "Stefano Sferrazza",
        "Przemysław A. Wałęga",
        "Georg Gottlob"
      ],
      "abstract": "One of the main challenges in the area of Neuro-Symbolic AI is to perform\nlogical reasoning in the presence of both neural and symbolic data. This\nrequires combining heterogeneous data sources such as knowledge graphs, neural\nmodel predictions, structured databases, crowd-sourced data, and many more. To\nallow for such reasoning, we generalise the standard rule-based language\nDatalog with existential rules (commonly referred to as tuple-generating\ndependencies) to the fuzzy setting, by allowing for arbitrary t-norms in the\nplace of classical conjunctions in rule bodies. The resulting formalism allows\nus to perform reasoning about data associated with degrees of uncertainty while\npreserving computational complexity results and the applicability of reasoning\ntechniques established for the standard Datalog setting. In particular, we\nprovide fuzzy extensions of Datalog chases which produce fuzzy universal models\nand we exploit them to show that in important fragments of the language,\nreasoning has the same complexity as in the classical setting.",
      "tldr_zh": "这篇论文将 Datalog$^\\exists$ 扩展到模糊设置，使用任意 t-norms 代替规则体中的经典合取，旨在处理 Neuro-Symbolic AI 中神经和符号数据的逻辑推理挑战。 该框架支持在不确定度下结合异构数据源（如知识图谱和神经模型预测）进行推理，同时保留了标准 Datalog 的计算复杂性和推理技术。 研究通过模糊扩展的 Datalog chases 生成模糊通用模型，并在重要语言片段中证明了推理复杂度与经典设置一致。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02933v1",
      "published_date": "2024-03-05 12:51:40 UTC",
      "updated_date": "2024-03-05 12:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:43:23.535970"
    },
    {
      "arxiv_id": "2403.02920v2",
      "title": "TaylorShift: Shifting the Complexity of Self-Attention from Squared to Linear (and Back) using Taylor-Softmax",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Christian Nauen",
        "Sebastian Palacio",
        "Andreas Dengel"
      ],
      "abstract": "The quadratic complexity of the attention mechanism represents one of the\nbiggest hurdles for processing long sequences using Transformers. Current\nmethods, relying on sparse representations or stateful recurrence, sacrifice\ntoken-to-token interactions, which ultimately leads to compromises in\nperformance. This paper introduces TaylorShift, a novel reformulation of the\nTaylor softmax that enables computing full token-to-token interactions in\nlinear time and space. We analytically determine the crossover points where\nemploying TaylorShift becomes more efficient than traditional attention,\naligning closely with empirical measurements. Specifically, our findings\ndemonstrate that TaylorShift enhances memory efficiency for sequences as short\nas 800 tokens and accelerates inference for inputs of approximately 1700 tokens\nand beyond. For shorter sequences, TaylorShift scales comparably with the\nvanilla attention. Furthermore, a classification benchmark across five tasks\ninvolving long sequences reveals no degradation in accuracy when employing\nTransformers equipped with TaylorShift. For reproducibility, we provide access\nto our code under https://github.com/tobna/TaylorShift.",
      "tldr_zh": "该论文提出 TaylorShift，一种基于 Taylor softmax 的新方法，将 Transformer 自注意力的复杂度从二次方转变为线性，同时保持完整的 token-to-token 交互，从而解决处理长序列的效率瓶颈。研究通过分析确定了效率交叉点：TaylorShift 在序列长度为 800 tokens 时提升内存效率，并在 1700 tokens 及以上加速推理，而对于较短序列，其性能与传统注意力相当。在五个长序列分类任务的基准测试中，使用 TaylorShift 的 Transformer 准确率未下降，并提供了开源代码以支持复现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07",
        "I.5.1; I.2.10; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02920v2",
      "published_date": "2024-03-05 12:38:14 UTC",
      "updated_date": "2024-07-17 14:32:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:43:36.099543"
    },
    {
      "arxiv_id": "2403.02914v2",
      "title": "DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal Forecasting",
      "title_zh": "DynST：资源受限时空",
      "authors": [
        "Hao Wu",
        "Haomin Wen",
        "Guibin Zhang",
        "Yutong Xia",
        "Yuxuan Liang",
        "Yu Zheng",
        "Qingsong Wen",
        "Kun Wang"
      ],
      "abstract": "The ever-increasing sensor service, though opening a precious path and\nproviding a deluge of earth system data for deep-learning-oriented earth\nscience, sadly introduce a daunting obstacle to their industrial level\ndeployment. Concretely, earth science systems rely heavily on the extensive\ndeployment of sensors, however, the data collection from sensors is constrained\nby complex geographical and social factors, making it challenging to achieve\ncomprehensive coverage and uniform deployment. To alleviate the obstacle,\ntraditional approaches to sensor deployment utilize specific algorithms to\ndesign and deploy sensors. These methods \\textit{dynamically adjust the\nactivation times of sensors to optimize the detection process across each\nsub-region}. Regrettably, formulating an activation strategy generally based on\nhistorical observations and geographic characteristics, which make the methods\nand resultant models were neither simple nor practical. Worse still, the\ncomplex technical design may ultimately lead to a model with weak\ngeneralizability. In this paper, we introduce for the first time the concept of\nspatio-temporal data dynamic sparse training and are committed to adaptively,\ndynamically filtering important sensor distributions. To our knowledge, this is\nthe \\textbf{first} proposal (\\textit{termed DynST}) of an\n\\textbf{industry-level} deployment optimization concept at the data level.\nHowever, due to the existence of the temporal dimension, pruning of\nspatio-temporal data may lead to conflicts at different timestamps. To achieve\nthis goal, we employ dynamic merge technology, along with ingenious dimensional\nmapping to mitigate potential impacts caused by the temporal aspect. During the\ntraining process, DynST utilize iterative pruning and sparse training,\nrepeatedly identifying and dynamically removing sensor perception areas that\ncontribute the least to future predictions.",
      "tldr_zh": "该论文针对资源受限的时空预测（Spatio-Temporal Forecasting）问题，首次提出 DynST（Dynamic Sparse Training）框架，以适应性动态过滤传感器分布，优化工业级部署。DynST 通过动态合并技术、维度映射、迭代修剪和稀疏训练，处理时空数据中的时间戳冲突，并动态移除对未来预测贡献小的传感器感知区域。实验结果表明，该方法有效缓解了传感器部署的地理和社会限制，提高了模型的泛化性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02914v2",
      "published_date": "2024-03-05 12:31:24 UTC",
      "updated_date": "2025-01-16 02:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:43:45.693953"
    },
    {
      "arxiv_id": "2403.04799v1",
      "title": "AI Literacy in Low-Resource Languages:Insights from creating AI in Yoruba videos",
      "title_zh": "翻译失败",
      "authors": [
        "Wuraola Oyewusi"
      ],
      "abstract": "To effectively navigate the AI revolution, AI literacy is crucial. However,\ncontent predominantly exists in dominant languages, creating a gap for\nlow-resource languages like Yoruba (41 million native speakers). This case\nstudy explores bridging this gap by creating and distributing AI videos in\nYoruba.The project developed 26 videos covering foundational, intermediate, and\nadvanced AI concepts, leveraging storytelling and accessible explanations.\nThese videos were created using a cost-effective methodology and distributed\nacross YouTube, LinkedIn, and Twitter, reaching an estimated global audience of\n22 countries. Analysis of YouTube reveals insights into viewing patterns, with\nthe 25-44 age group contributing the most views. Notably, over half of the\ntraffic originated from external sources, highlighting the potential of\ncross-platform promotion.This study demonstrates the feasibility and impact of\ncreating AI literacy content in low-resource languages. It emphasizes that\naccurate interpretation requires both technical expertise in AI and fluency in\nthe target language. This work contributes a replicable methodology, a 22-word\nYoruba AI vocabulary, and data-driven insights into audience demographics and\nacquisition channel",
      "tldr_zh": "这篇论文探讨了在低资源语言如Yoruba（4100万母语使用者）中提升AI literacy的必要性，通过一个案例研究创建并分发26个AI视频，涵盖基础、中间和高级概念，并采用讲故事和易懂解释的成本有效方法。视频在YouTube、LinkedIn和Twitter上发布，覆盖22个国家，分析显示25-44岁群体贡献最多观看量，且超过一半流量来自外部来源。研究证明了这种内容的制作可行性和影响力，强调需要AI技术专长和目标语言流利度，并贡献了可复制的方法、22个Yoruba AI词汇，以及关于观众 demographics和acquisition channel的数据洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the Global AI Cultures Workshop, ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.04799v1",
      "published_date": "2024-03-05 12:27:28 UTC",
      "updated_date": "2024-03-05 12:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:44:00.057834"
    },
    {
      "arxiv_id": "2403.02910v3",
      "title": "ImgTrojan: Jailbreaking Vision-Language Models with ONE Image",
      "title_zh": "翻译失败",
      "authors": [
        "Xijia Tao",
        "Shuai Zhong",
        "Lei Li",
        "Qi Liu",
        "Lingpeng Kong"
      ],
      "abstract": "There has been an increasing interest in the alignment of large language\nmodels (LLMs) with human values. However, the safety issues of their\nintegration with a vision module, or vision language models (VLMs), remain\nrelatively underexplored. In this paper, we propose a novel jailbreaking attack\nagainst VLMs, aiming to bypass their safety barrier when a user inputs harmful\ninstructions. A scenario where our poisoned (image, text) data pairs are\nincluded in the training data is assumed. By replacing the original textual\ncaptions with malicious jailbreak prompts, our method can perform jailbreak\nattacks with the poisoned images. Moreover, we analyze the effect of poison\nratios and positions of trainable parameters on our attack's success rate. For\nevaluation, we design two metrics to quantify the success rate and the\nstealthiness of our attack. Together with a list of curated harmful\ninstructions, a benchmark for measuring attack efficacy is provided. We\ndemonstrate the efficacy of our attack by comparing it with baseline methods.",
      "tldr_zh": "该论文提出了一种名为ImgTrojan的越狱攻击（jailbreaking attack），旨在利用一张图像绕过视觉语言模型（VLMs）的安全屏障，使其响应有害指令。方法假设在训练数据中注入有毒的（图像、文本）对，将原始文本标题替换为恶意提示，并分析毒性比例和可训练参数位置对攻击成功率的影响。为评估攻击效果，论文设计了成功率和隐蔽性指标，并通过基准测试与基线方法比较，证明了该攻击的高效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02910v3",
      "published_date": "2024-03-05 12:21:57 UTC",
      "updated_date": "2025-02-05 13:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:44:11.621867"
    },
    {
      "arxiv_id": "2403.02901v2",
      "title": "A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods",
      "title_zh": "关于过程导向自动",
      "authors": [
        "Yang Zhang",
        "Hanlei Jin",
        "Dan Meng",
        "Jun Wang",
        "Jinghua Tan"
      ],
      "abstract": "Automatic Text Summarization (ATS), utilizing Natural Language Processing\n(NLP) algorithms, aims to create concise and accurate summaries, thereby\nsignificantly reducing the human effort required in processing large volumes of\ntext. ATS has drawn considerable interest in both academic and industrial\ncircles. Many studies have been conducted in the past to survey ATS methods;\nhowever, they generally lack practicality for real-world implementations, as\nthey often categorize previous methods from a theoretical standpoint. Moreover,\nthe advent of Large Language Models (LLMs) has altered conventional ATS\nmethods. In this survey, we aim to 1) provide a comprehensive overview of ATS\nfrom a ``Process-Oriented Schema'' perspective, which is best aligned with\nreal-world implementations; 2) comprehensively review the latest LLM-based ATS\nworks; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in\nthe literature. To the best of our knowledge, this is the first survey to\nspecifically investigate LLM-based ATS methods.",
      "tldr_zh": "本调查对自动文本摘要(Automatic Text Summarization, ATS)进行了全面审视，强调从“Process-Oriented Schema”的视角出发，以更好地适应实际应用场景。论文指出现有ATS方法往往理论导向且缺乏实用性，而Large Language Models (LLMs)的兴起已改变传统ATS方法，因此系统回顾了最新的LLM-based ATS研究。作者的目标包括提供ATS的全面概述、深入探讨LLM-based方法，并填补文献中两年的更新空白；据称，这是首个专门针对LLM-based ATS的调查，为未来研究和实施提供了宝贵参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02901v2",
      "published_date": "2024-03-05 12:11:07 UTC",
      "updated_date": "2025-03-20 07:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:44:23.266616"
    },
    {
      "arxiv_id": "2403.02899v1",
      "title": "Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhekai Du",
        "Xinyao Li",
        "Fengling Li",
        "Ke Lu",
        "Lei Zhu",
        "Jingjing Li"
      ],
      "abstract": "Conventional Unsupervised Domain Adaptation (UDA) strives to minimize\ndistribution discrepancy between domains, which neglects to harness rich\nsemantics from data and struggles to handle complex domain shifts. A promising\ntechnique is to leverage the knowledge of large-scale pre-trained\nvision-language models for more guided adaptation. Despite some endeavors,\ncurrent methods often learn textual prompts to embed domain semantics for\nsource and target domains separately and perform classification within each\ndomain, limiting cross-domain knowledge transfer. Moreover, prompting only the\nlanguage branch lacks flexibility to adapt both modalities dynamically. To\nbridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit\ndomain-invariant semantics by mutually aligning visual and textual embeddings.\nSpecifically, the image contextual information is utilized to prompt the\nlanguage branch in a domain-agnostic and instance-conditioned way. Meanwhile,\nvisual prompts are imposed based on the domain-agnostic textual prompt to\nelicit domain-invariant visual embeddings. These two branches of prompts are\nlearned mutually with a cross-attention module and regularized with a\nsemantic-consistency loss and an instance-discrimination contrastive loss.\nExperiments on three UDA benchmarks demonstrate the superiority of DAMP over\nstate-of-the-art approaches.",
      "tldr_zh": "该论文针对传统 Unsupervised Domain Adaptation (UDA) 方法的局限性，提出 Domain-Agnostic Mutual Prompting (DAMP) 框架，通过相互对齐视觉和文本嵌入来利用领域无关语义，从而提升跨域知识转移和适应复杂领域转移的能力。DAMP 的核心机制包括使用图像上下文信息以领域无关和实例条件方式提示语言分支，同时基于文本提示施加视觉提示，并通过交叉注意力模块、语义一致性损失和实例区分对比损失进行相互学习和优化。在三个 UDA 基准实验中，DAMP 表现出色，优于最先进方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02899v1",
      "published_date": "2024-03-05 12:06:48 UTC",
      "updated_date": "2024-03-05 12:06:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:44:36.077838"
    },
    {
      "arxiv_id": "2403.02893v2",
      "title": "Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhitao He",
        "Pengfei Cao",
        "Zhuoran Jin",
        "Yubo Chen",
        "Kang Liu",
        "Zhiqiang Zhang",
        "Mengshu Sun",
        "Jun Zhao"
      ],
      "abstract": "Event Causality Identification (ECI) refers to the detection of causal\nrelations between events in texts. However, most existing studies focus on\nsentence-level ECI with high-resource languages, leaving more challenging\ndocument-level ECI (DECI) with low-resource languages under-explored. In this\npaper, we propose a Heterogeneous Graph Interaction Model with\nMulti-granularity Contrastive Transfer Learning (GIMC) for zero-shot\ncross-lingual document-level ECI. Specifically, we introduce a heterogeneous\ngraph interaction network to model the long-distance dependencies between\nevents that are scattered over a document. Then, to improve cross-lingual\ntransferability of causal knowledge learned from the source language, we\npropose a multi-granularity contrastive transfer learning module to align the\ncausal representations across languages. Extensive experiments show our\nframework outperforms the previous state-of-the-art model by 9.4% and 8.2% of\naverage F1 score on monolingual and multilingual scenarios respectively.\nNotably, in the multilingual scenario, our zero-shot framework even exceeds\nGPT-3.5 with few-shot learning by 24.3% in overall performance.",
      "tldr_zh": "该论文针对Event Causality Identification (ECI)中的文档级别挑战，提出了一种Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC)框架，用于零-shot跨语言DECI任务。框架通过异构图交互网络建模文档中事件之间的长距离依赖，并采用多粒度对比转移学习模块来对齐不同语言的因果表示，从而提升跨语言知识转移能力。实验结果显示，GIMC在单语和多语场景下分别比现有最先进模型提高9.4%和8.2%的平均F1分数，并在多语场景下零-shot性能超过GPT-3.5的少样本学习24.3%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02893v2",
      "published_date": "2024-03-05 11:57:21 UTC",
      "updated_date": "2024-03-22 07:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:44:49.296971"
    },
    {
      "arxiv_id": "2403.02892v1",
      "title": "Enhancing Long-Term Person Re-Identification Using Global, Local Body Part, and Head Streams",
      "title_zh": "利用全局、局部身体部位和头部流的长期行人再识别增强",
      "authors": [
        "Duy Tran Thanh",
        "Yeejin Lee",
        "Byeongkeun Kang"
      ],
      "abstract": "This work addresses the task of long-term person re-identification.\nTypically, person re-identification assumes that people do not change their\nclothes, which limits its applications to short-term scenarios. To overcome\nthis limitation, we investigate long-term person re-identification, which\nconsiders both clothes-changing and clothes-consistent scenarios. In this\npaper, we propose a novel framework that effectively learns and utilizes both\nglobal and local information. The proposed framework consists of three streams:\nglobal, local body part, and head streams. The global and head streams encode\nidentity-relevant information from an entire image and a cropped image of the\nhead region, respectively. Both streams encode the most distinct, less\ndistinct, and average features using the combinations of adversarial erasing,\nmax pooling, and average pooling. The local body part stream extracts\nidentity-related information for each body part, allowing it to be compared\nwith the same body part from another image. Since body part annotations are not\navailable in re-identification datasets, pseudo-labels are generated using\nclustering. These labels are then utilized to train a body part segmentation\nhead in the local body part stream. The proposed framework is trained by\nbackpropagating the weighted summation of the identity classification loss, the\npair-based loss, and the pseudo body part segmentation loss. To demonstrate the\neffectiveness of the proposed method, we conducted experiments on three\npublicly available datasets (Celeb-reID, PRCC, and VC-Clothes). The\nexperimental results demonstrate that the proposed method outperforms the\nprevious state-of-the-art method.",
      "tldr_zh": "本文提出了一种增强长期Person Re-Identification框架，以处理人物换衣服的场景，扩展了传统方法的适用性。该框架由Global Stream、Local Body Part Stream和Head Stream组成，其中Global和Head Streams使用Adversarial Erasing、Max Pooling和Average Pooling提取图像整体和头部区域的身份相关特征，而Local Body Part Stream通过聚类生成伪标签来训练身体部位分割，并提取每个部位的身份信息。框架通过加权求和的身份分类损失、基于对的损失和伪身体部位分割损失进行训练。在Celeb-reID、PRCC和VC-Clothes数据集上的实验结果表明，该方法超过了现有最先进技术，显著提高了长期再识别的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.02892v1",
      "published_date": "2024-03-05 11:57:10 UTC",
      "updated_date": "2024-03-05 11:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:45:03.270825"
    },
    {
      "arxiv_id": "2403.02884v1",
      "title": "MathScale: Scaling Instruction Tuning for Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyang Tang",
        "Xingxing Zhang",
        "Benyou Wang",
        "Furu Wei"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nproblem-solving. However, their proficiency in solving mathematical problems\nremains inadequate. We propose MathScale, a simple and scalable method to\ncreate high-quality mathematical reasoning data using frontier LLMs (e.g., {\\tt\nGPT-3.5}). Inspired by the cognitive mechanism in human mathematical learning,\nit first extracts topics and knowledge points from seed math questions and then\nbuild a concept graph, which is subsequently used to generate new math\nquestions. MathScale exhibits effective scalability along the size axis of the\nmath dataset that we generate. As a result, we create a mathematical reasoning\ndataset (MathScaleQA) containing two million math question-answer pairs. To\nevaluate mathematical reasoning abilities of LLMs comprehensively, we construct\n{\\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten\ndatasets (including GSM8K and MATH) covering K-12, college, and competition\nlevel math problems. We apply MathScaleQA to fine-tune open-source LLMs (e.g.,\nLLaMA-2 and Mistral), resulting in significantly improved capabilities in\nmathematical reasoning. Evaluated on {\\sc MwpBench}, MathScale-7B achieves\nstate-of-the-art performance across all datasets, surpassing its best peers of\nequivalent size by 42.9\\% in micro average accuracy and 43.7\\% in macro average\naccuracy, respectively.",
      "tldr_zh": "本研究提出MathScale，一种简单且可扩展的方法，使用前沿LLMs（如GPT-3.5）生成高质量数学推理数据，以解决大型语言模型在数学问题解决方面的不足。该方法借鉴人类数学学习认知机制，从种子问题中提取主题和知识点构建概念图，从而生成新的数学问题，并创建了包含200万对问题-答案的MathScaleQA数据集。为全面评估LLMs的数学能力，研究构建了MwpBench基准，包括10个数据集覆盖K-12至竞赛级数学问题。通过使用MathScaleQA微调开源LLMs（如LLaMA-2和Mistral），MathScale-7B模型在MwpBench上实现了最先进性能，比同等规模模型提高了42.9%的微平均准确率和43.7%的宏平均准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2403.02884v1",
      "published_date": "2024-03-05 11:42:59 UTC",
      "updated_date": "2024-03-05 11:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:45:14.910913"
    },
    {
      "arxiv_id": "2403.02877v1",
      "title": "ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Han Lu",
        "Xiaosong Jia",
        "Yichen Xie",
        "Wenlong Liao",
        "Xiaokang Yang",
        "Junchi Yan"
      ],
      "abstract": "End-to-end differentiable learning for autonomous driving (AD) has recently\nbecome a prominent paradigm. One main bottleneck lies in its voracious appetite\nfor high-quality labeled data e.g. 3D bounding boxes and semantic segmentation,\nwhich are notoriously expensive to manually annotate. The difficulty is further\npronounced due to the prominent fact that the behaviors within samples in AD\noften suffer from long tailed distribution. In other words, a large part of\ncollected data can be trivial (e.g. simply driving forward in a straight road)\nand only a few cases are safety-critical. In this paper, we explore a\npractically important yet under-explored problem about how to achieve sample\nand label efficiency for end-to-end AD. Specifically, we design a\nplanning-oriented active learning method which progressively annotates part of\ncollected raw data according to the proposed diversity and usefulness criteria\nfor planning routes. Empirically, we show that our planning-oriented approach\ncould outperform general active learning methods by a large margin. Notably,\nour method achieves comparable performance with state-of-the-art end-to-end AD\nmethods - by using only 30% nuScenes data. We hope our work could inspire\nfuture works to explore end-to-end AD from a data-centric perspective in\naddition to methodology efforts.",
      "tldr_zh": "这篇论文针对端到端自动驾驶（End-to-End Autonomous Driving）的训练瓶颈，提出了一种planning-oriented active learning方法，旨在通过多样性和有用性标准逐步标注关键数据，从而提升样本和标签效率。方法重点优化规划路线选择，避免浪费在平凡数据（如直线行驶）上。实验结果显示，该方法比传统active learning方法有显著优势，仅使用30%的nuScenes数据就达到与最先进模型相当的性能，并呼吁从数据-centric视角推动未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02877v1",
      "published_date": "2024-03-05 11:39:07 UTC",
      "updated_date": "2024-03-05 11:39:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:45:25.640007"
    },
    {
      "arxiv_id": "2403.02870v1",
      "title": "Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices",
      "title_zh": "通过侧信道",
      "authors": [
        "Younghan Lee",
        "Sohee Jun",
        "Yungi Cho",
        "Woorim Han",
        "Hyungon Moon",
        "Yunheung Paek"
      ],
      "abstract": "With growing popularity, deep learning (DL) models are becoming larger-scale,\nand only the companies with vast training datasets and immense computing power\ncan manage their business serving such large models. Most of those DL models\nare proprietary to the companies who thus strive to keep their private models\nsafe from the model extraction attack (MEA), whose aim is to steal the model by\ntraining surrogate models. Nowadays, companies are inclined to offload the\nmodels from central servers to edge/endpoint devices. As revealed in the latest\nstudies, adversaries exploit this opportunity as new attack vectors to launch\nside-channel attack (SCA) on the device running victim model and obtain various\npieces of the model information, such as the model architecture (MA) and image\ndimension (ID). Our work provides a comprehensive understanding of such a\nrelationship for the first time and would benefit future MEA studies in both\noffensive and defensive sides in that they may learn which pieces of\ninformation exposed by SCA are more important than the others. Our analysis\nadditionally reveals that by grasping the victim model information from SCA,\nMEA can get highly effective and successful even without any prior knowledge of\nthe model. Finally, to evince the practicality of our analysis results, we\nempirically apply SCA, and subsequently, carry out MEA under realistic threat\nassumptions. The results show up to 5.8 times better performance than when the\nadversary has no model information about the victim model.",
      "tldr_zh": "该研究探讨了通过侧信道攻击（SCA）从边/端设备提取深度学习（DL）模型的风险，强调攻击者可利用 SCA 获取关键信息，如模型架构（MA）和图像维度（ID），从而进行模型提取攻击（MEA）。作者首次提供了对 SCA 与 MEA 关系的全面分析，揭示即使在没有先验知识的情况下，获取这些信息也能显著提升攻击效率。实验结果显示，基于 SCA 的 MEA 性能比无模型信息的攻击提高了多达 5.8 倍，为未来在攻击和防御方面的 DL 模型保护提供了重要指导。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by 27th European Symposium on Research in Computer Security\n  (ESORICS 2022)",
      "pdf_url": "http://arxiv.org/pdf/2403.02870v1",
      "published_date": "2024-03-05 11:26:22 UTC",
      "updated_date": "2024-03-05 11:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:45:37.613843"
    },
    {
      "arxiv_id": "2403.02846v1",
      "title": "FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models",
      "title_zh": "翻译失败",
      "authors": [
        "Younghan Lee",
        "Yungi Cho",
        "Woorim Han",
        "Ho Bae",
        "Yunheung Paek"
      ],
      "abstract": "Federated Learning (FL) thrives in training a global model with numerous\nclients by only sharing the parameters of their local models trained with their\nprivate training datasets. Therefore, without revealing the private dataset,\nthe clients can obtain a deep learning (DL) model with high performance.\nHowever, recent research proposed poisoning attacks that cause a catastrophic\nloss in the accuracy of the global model when adversaries, posed as benign\nclients, are present in a group of clients. Therefore, recent studies suggested\nbyzantine-robust FL methods that allow the server to train an accurate global\nmodel even with the adversaries present in the system. However, many existing\nmethods require the knowledge of the number of malicious clients or the\nauxiliary (clean) dataset or the effectiveness reportedly decreased hugely when\nthe private dataset was non-independently and identically distributed\n(non-IID). In this work, we propose FLGuard, a novel byzantine-robust FL method\nthat detects malicious clients and discards malicious local updates by\nutilizing the contrastive learning technique, which showed a tremendous\nimprovement as a self-supervised learning method. With contrastive models, we\ndesign FLGuard as an ensemble scheme to maximize the defensive capability. We\nevaluate FLGuard extensively under various poisoning attacks and compare the\naccuracy of the global model with existing byzantine-robust FL methods. FLGuard\noutperforms the state-of-the-art defense methods in most cases and shows\ndrastic improvement, especially in non-IID settings.\nhttps://github.com/201younghanlee/FLGuard",
      "tldr_zh": "论文提出 FLGuard，一种新型 Byzantine-Robust Federated Learning 方法，通过对比学习（Contrastive Learning）技术构建集成模型（Ensemble of Contrastive Models），以检测并丢弃恶意客户端的更新，从而提升全局模型的鲁棒性。该方法无需事先知道恶意客户端数量、辅助数据集或额外假设，并在非-IID 数据设置下表现出色。实验结果显示，FLGuard 在各种中毒攻击场景中，准确率显著优于现有防御方法，尤其在非独立同分布（non-IID）环境中实现了大幅改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by 28th European Symposium on Research in Computer Security\n  (ESORICS 2023)",
      "pdf_url": "http://arxiv.org/pdf/2403.02846v1",
      "published_date": "2024-03-05 10:36:27 UTC",
      "updated_date": "2024-03-05 10:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:45:50.843104"
    },
    {
      "arxiv_id": "2403.02820v1",
      "title": "Reconstruction for Sparse View Tomography of Long Objects Applied to Imaging in the Wood Industry",
      "title_zh": "针对长物体的稀疏视图断层成像重建及其在木材行业成像中的应用",
      "authors": [
        "Buda Bajić",
        "Johannes A. J. Huber",
        "Benedikt Neyses",
        "Linus Olofsson",
        "Ozan Öktem"
      ],
      "abstract": "In the wood industry, logs are commonly quality screened by discrete X-ray\nscans on a moving conveyor belt from a few source positions. Typically,\ntwo-dimensional (2D) slice-wise measurements are obtained by a sequential\nscanning geometry. Each 2D slice alone does not carry sufficient information\nfor a three-dimensional tomographic reconstruction in which biological features\nof interest in the log are well preserved. In the present work, we propose a\nlearned iterative reconstruction method based on the Learned Primal-Dual neural\nnetwork, suited for sequential scanning geometries. Our method accumulates\ninformation between neighbouring slices, instead of only accounting for single\nslices during reconstruction. Our quantitative and qualitative evaluations with\nas few as five source positions show that our method yields reconstructions of\nlogs that are sufficiently accurate to identify biological features like knots\n(branches), heartwood and sapwood.",
      "tldr_zh": "在木材行业，使用稀疏视图 X-ray 扫描对长物体如原木进行质量筛查时，传统的二维切片测量往往不足以支持精确的三维 tomographic reconstruction，从而难以保留生物特征。论文提出了一种基于 Learned Primal-Dual 神经网络的学习迭代重建方法，适用于顺序扫描几何，通过累积相邻切片的信息来提升重建准确性。该方法在少至五个源位置的条件下，通过定量和定性评估，实现了对原木生物特征如 knots、heartwood 和 sapwood 的有效识别和重建。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02820v1",
      "published_date": "2024-03-05 09:44:19 UTC",
      "updated_date": "2024-03-05 09:44:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:46:03.099543"
    },
    {
      "arxiv_id": "2403.02814v1",
      "title": "InjectTST: A Transformer Method of Injecting Global Information into Independent Channels for Long Time Series Forecasting",
      "title_zh": "InjectTST：一种将全局信息注入独立通道的Transformer方法，用于长时序预测",
      "authors": [
        "Ce Chi",
        "Xing Wang",
        "Kexin Yang",
        "Zhiyan Song",
        "Di Jin",
        "Lin Zhu",
        "Chao Deng",
        "Junlan Feng"
      ],
      "abstract": "Transformer has become one of the most popular architectures for multivariate\ntime series (MTS) forecasting. Recent Transformer-based MTS models generally\nprefer channel-independent structures with the observation that channel\nindependence can alleviate noise and distribution drift issues, leading to more\nrobustness. Nevertheless, it is essential to note that channel dependency\nremains an inherent characteristic of MTS, carrying valuable information.\nDesigning a model that incorporates merits of both channel-independent and\nchannel-mixing structures is a key to further improvement of MTS forecasting,\nwhich poses a challenging conundrum. To address the problem, an injection\nmethod for global information into channel-independent Transformer, InjectTST,\nis proposed in this paper. Instead of designing a channel-mixing model\ndirectly, we retain the channel-independent backbone and gradually inject\nglobal information into individual channels in a selective way. A channel\nidentifier, a global mixing module and a self-contextual attention module are\ndevised in InjectTST. The channel identifier can help Transformer distinguish\nchannels for better representation. The global mixing module produces\ncross-channel global information. Through the self-contextual attention module,\nthe independent channels can selectively concentrate on useful global\ninformation without robustness degradation, and channel mixing is achieved\nimplicitly. Experiments indicate that InjectTST can achieve stable improvement\ncompared with state-of-the-art models.",
      "tldr_zh": "本文提出 InjectTST，一种 Transformer 方法，用于将全局信息选择性地注入通道独立的结构中，以提升多变量时间序列 (MTS) 预测的性能。该方法保留通道独立的主干，同时通过 channel identifier 区分通道、global mixing module 生成跨通道全局信息，以及 self-contextual attention module 实现隐式通道混合，从而平衡鲁棒性和信息利用。实验结果表明，InjectTST 与最先进模型相比，实现了稳定的性能改进。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02814v1",
      "published_date": "2024-03-05 09:33:36 UTC",
      "updated_date": "2024-03-05 09:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:46:14.018651"
    },
    {
      "arxiv_id": "2403.02810v1",
      "title": "Dynamic Gaussian Graph Operator: Learning parametric partial differential equations in arbitrary discrete mechanics problems",
      "title_zh": "翻译失败",
      "authors": [
        "Chu Wang",
        "Jinhong Wu",
        "Yanzhi Wang",
        "Zhijian Zha",
        "Qi Zhou"
      ],
      "abstract": "Deep learning methods have access to be employed for solving physical systems\ngoverned by parametric partial differential equations (PDEs) due to massive\nscientific data. It has been refined to operator learning that focuses on\nlearning non-linear mapping between infinite-dimensional function spaces,\noffering interface from observations to solutions. However, state-of-the-art\nneural operators are limited to constant and uniform discretization, thereby\nleading to deficiency in generalization on arbitrary discretization schemes for\ncomputational domain. In this work, we propose a novel operator learning\nalgorithm, referred to as Dynamic Gaussian Graph Operator (DGGO) that expands\nneural operators to learning parametric PDEs in arbitrary discrete mechanics\nproblems. The Dynamic Gaussian Graph (DGG) kernel learns to map the observation\nvectors defined in general Euclidean space to metric vectors defined in\nhigh-dimensional uniform metric space. The DGG integral kernel is parameterized\nby Gaussian kernel weighted Riemann sum approximating and using dynamic message\npassing graph to depict the interrelation within the integral term. Fourier\nNeural Operator is selected to localize the metric vectors on spatial and\nfrequency domains. Metric vectors are regarded as located on latent uniform\ndomain, wherein spatial and spectral transformation offer highly regular\nconstraints on solution space. The efficiency and robustness of DGGO are\nvalidated by applying it to solve numerical arbitrary discrete mechanics\nproblems in comparison with mainstream neural operators. Ablation experiments\nare implemented to demonstrate the effectiveness of spatial transformation in\nthe DGG kernel. The proposed method is utilized to forecast stress field of\nhyper-elastic material with geometrically variable void as engineering\napplication.",
      "tldr_zh": "本论文提出了一种名为Dynamic Gaussian Graph Operator (DGGO)的创新算法，用于学习参数偏微分方程 (PDEs) 在任意离散力学问题中的解决方案，以克服现有神经操作符在常量和均匀离散化上的局限性。DGGO 通过Dynamic Gaussian Graph (DGG) 内核将观察向量映射到高维均匀度量空间，并结合动态消息传递图和高斯内核加权的 Riemann 和，以及Fourier Neural Operator 在空间和频率域上的处理，实现对任意离散化方案的泛化。实验结果显示，DGGO 在数值离散力学问题上比主流神经操作符更高效和鲁棒，并成功应用于预测超弹性材料应力场等工程场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The number of figures is 13. The number of tables is 7. The number of\n  words is 9854",
      "pdf_url": "http://arxiv.org/pdf/2403.02810v1",
      "published_date": "2024-03-05 09:25:31 UTC",
      "updated_date": "2024-03-05 09:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:46:27.030653"
    },
    {
      "arxiv_id": "2403.02799v1",
      "title": "DPPA: Pruning Method for Large Language Model to Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Yaochen Zhu",
        "Rui Xia",
        "Jiajun Zhang"
      ],
      "abstract": "Model merging is to combine fine-tuned models derived from multiple domains,\nwith the intent of enhancing the model's proficiency across various domains.\nThe principal concern is the resolution of parameter conflicts. A substantial\namount of existing research remedy this issue during the merging stage, with\nthe latest study focusing on resolving this issue throughout the pruning stage.\nThe DARE approach has exhibited promising outcomes when applied to a simplistic\nfine-tuned model. However, the efficacy of this method tends to wane when\nemployed on complex fine-tuned models that show a significant parameter bias\nrelative to the baseline model. In this paper, we introduce a dual-stage method\ntermed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the\nchallenge of merging complex fine-tuned models. Initially, we introduce\nDynamically Pruning (DP), an improved approach based on magnitude pruning,\nwhich aim is to enhance performance at higher pruning rates. Subsequently, we\npropose Dynamically Partition Amplification (DPA), a rescaling strategy, is\ndesigned to dynamically amplify parameter partitions in relation to their\nsignificance levels. The experimental results show that our method maintains a\nmere 20% of domain-specific parameters and yet delivers a performance\ncomparable to other methodologies that preserve up to 90% of parameters.\nFurthermore, our method displays outstanding performance post-pruning, leading\nto a significant improvement of nearly 20% performance in model merging. We\nmake our code on Github.",
      "tldr_zh": "本文提出 DPPA（Dynamic Pruning Partition Amplification）方法，用于解决 Large Language Model 在模型合并（Model Merging）中的参数冲突问题，特别是针对复杂微调模型的显著参数偏差。DPPA 采用双阶段策略：首先，通过 Dynamic Pruning (DP) 改进基于 magnitude pruning 的修剪技术，以在高修剪率下提升模型性能；其次，利用 Dynamically Partition Amplification (DPA) 动态放大重要参数分区，根据其显著性水平进行重scaling。实验结果表明，DPPA 只需保留 20% 的领域特定参数，即可实现与保留 90% 参数方法的相当性能，并在模型合并后提升近 20% 的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02799v1",
      "published_date": "2024-03-05 09:12:49 UTC",
      "updated_date": "2024-03-05 09:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:46:39.989696"
    },
    {
      "arxiv_id": "2403.02795v2",
      "title": "Evaluating and Optimizing Educational Content with Large Language Model Judgments",
      "title_zh": "使用大语言模型判断评估和优化教育内容",
      "authors": [
        "Joy He-Yueya",
        "Noah D. Goodman",
        "Emma Brunskill"
      ],
      "abstract": "Creating effective educational materials generally requires expensive and\ntime-consuming studies of student learning outcomes. To overcome this barrier,\none idea is to build computational models of student learning and use them to\noptimize instructional materials. However, it is difficult to model the\ncognitive processes of learning dynamics. We propose an alternative approach\nthat uses Language Models (LMs) as educational experts to assess the impact of\nvarious instructions on learning outcomes. Specifically, we use GPT-3.5 to\nevaluate the overall effect of instructional materials on different student\ngroups and find that it can replicate well-established educational findings\nsuch as the Expertise Reversal Effect and the Variability Effect. This\ndemonstrates the potential of LMs as reliable evaluators of educational\ncontent. Building on this insight, we introduce an instruction optimization\napproach in which one LM generates instructional materials using the judgments\nof another LM as a reward function. We apply this approach to create math word\nproblem worksheets aimed at maximizing student learning gains. Human teachers'\nevaluations of these LM-generated worksheets show a significant alignment\nbetween the LM judgments and human teacher preferences. We conclude by\ndiscussing potential divergences between human and LM opinions and the\nresulting pitfalls of automating instructional design.",
      "tldr_zh": "本研究探讨了使用Large Language Models (LMs)来评估和优化教育内容，以取代传统耗时高成本的学习结果研究。论文提出一种方法，利用LMs（如GPT-3.5）作为教育专家评估教学材料的有效性，并成功复制了已知教育现象，如Expertise Reversal Effect和Variability Effect。进一步，他们开发了指令优化框架，其中一个LM基于另一个LM的判断生成优化教学材料，并在数学文字问题工作表实验中显示LM评估与人类教师偏好高度一致。最后，论文讨论了人类和LM意见潜在分歧的风险，强调自动化教学设计的潜在陷阱。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.02795v2",
      "published_date": "2024-03-05 09:09:15 UTC",
      "updated_date": "2024-05-06 04:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:46:51.801845"
    },
    {
      "arxiv_id": "2403.02794v1",
      "title": "A Distance Metric Learning Model Based On Variational Information Bottleneck",
      "title_zh": "基于变分信息瓶颈的距离度量学习模型",
      "authors": [
        "YaoDan Zhang",
        "Zidong Wang",
        "Ru Jia",
        "Ru Li"
      ],
      "abstract": "In recent years, personalized recommendation technology has flourished and\nbecome one of the hot research directions. The matrix factorization model and\nthe metric learning model which proposed successively have been widely studied\nand applied. The latter uses the Euclidean distance instead of the dot product\nused by the former to measure the latent space vector. While avoiding the\nshortcomings of the dot product, the assumption of Euclidean distance is\nneglected, resulting in limited recommendation quality of the model. In order\nto solve this problem, this paper combines the Variationl Information\nBottleneck with metric learning model for the first time, and proposes a new\nmetric learning model VIB-DML (Variational Information Bottleneck Distance\nMetric Learning) for rating prediction, which limits the mutual information of\nthe latent space feature vector to improve the robustness of the model and\nsatisfiy the assumption of Euclidean distance by decoupling the latent space\nfeature vector. In this paper, the experimental results are compared with the\nroot mean square error (RMSE) on the three public datasets. The results show\nthat the generalization ability of VIB-DML is excellent. Compared with the\ngeneral metric learning model MetricF, the prediction error is reduced by\n7.29%. Finally, the paper proves the strong robustness of VIBDML through\nexperiments.",
      "tldr_zh": "本论文针对个性化推荐系统中度量学习模型的局限性（如忽略Euclidean distance假设导致推荐质量有限），提出了一种新模型VIB-DML（Variational Information Bottleneck Distance Metric Learning）。该模型首次将Variational Information Bottleneck与度量学习结合，通过限制潜在空间特征向量的互信息，提高模型鲁棒性并满足Euclidean distance的假设。实验结果显示，在三个公共数据集上，VIB-DML的RMSE比基准模型MetricF降低了7.29%，证明了其优秀的泛化能力和强鲁棒性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02794v1",
      "published_date": "2024-03-05 09:08:20 UTC",
      "updated_date": "2024-03-05 09:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:47:05.135161"
    },
    {
      "arxiv_id": "2403.02786v1",
      "title": "Semi-Supervised Graph Representation Learning with Human-centric Explanation for Predicting Fatty Liver Disease",
      "title_zh": "翻译失败",
      "authors": [
        "So Yeon Kim",
        "Sehee Wang",
        "Eun Kyung Choe"
      ],
      "abstract": "Addressing the challenge of limited labeled data in clinical settings,\nparticularly in the prediction of fatty liver disease, this study explores the\npotential of graph representation learning within a semi-supervised learning\nframework. Leveraging graph neural networks (GNNs), our approach constructs a\nsubject similarity graph to identify risk patterns from health checkup data.\nThe effectiveness of various GNN approaches in this context is demonstrated,\neven with minimal labeled samples. Central to our methodology is the inclusion\nof human-centric explanations through explainable GNNs, providing personalized\nfeature importance scores for enhanced interpretability and clinical relevance,\nthereby underscoring the potential of our approach in advancing healthcare\npractices with a keen focus on graph representation learning and human-centric\nexplanation.",
      "tldr_zh": "这篇论文针对预测脂肪肝疾病时标签数据有限的临床挑战，提出了一种基于半监督学习的图表示学习方法，通过构建主题相似性图和图神经网络 (GNNs) 从健康检查数据中识别风险模式，即使在标签样本很少的情况下也能实现有效预测。核心创新在于整合人性化解释 (Human-centric Explanation)，利用可解释的 GNNs 提供个性化的特征重要性分数，以提升模型的可解释性和临床相关性。该方法突显了图表示学习在医疗实践中的潜力，助力更可靠的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted in Human-Centric Representation Learning workshop at\n  AAAI 2024 (https://hcrl-workshop.github.io/2024/)",
      "pdf_url": "http://arxiv.org/pdf/2403.02786v1",
      "published_date": "2024-03-05 08:59:45 UTC",
      "updated_date": "2024-03-05 08:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:47:16.819447"
    },
    {
      "arxiv_id": "2403.02783v1",
      "title": "Where the Really Hard Quadratic Assignment Problems Are: the QAP-SAT instances",
      "title_zh": "翻译失败",
      "authors": [
        "Sébastien Verel",
        "Sarah Thomson",
        "Omar Rifki"
      ],
      "abstract": "The Quadratic Assignment Problem (QAP) is one of the major domains in the\nfield of evolutionary computation, and more widely in combinatorial\noptimization. This paper studies the phase transition of the QAP, which can be\ndescribed as a dramatic change in the problem's computational complexity and\nsatisfiability, within a narrow range of the problem parameters. To approach\nthis phenomenon, we introduce a new QAP-SAT design of the initial problem based\non submodularity to capture its difficulty with new features. This\ndecomposition is studied experimentally using branch-and-bound and tabu search\nsolvers. A phase transition parameter is then proposed. The critical parameter\nof phase transition satisfaction and that of the solving effort are shown to be\nhighly correlated for tabu search, thus allowing the prediction of difficult\ninstances.",
      "tldr_zh": "本论文探讨了 Quadratic Assignment Problem (QAP) 在演化计算和组合优化中的相变现象，即问题计算复杂性和可满足性在参数狭窄范围内急剧变化。研究者引入了基于 submodularity 的新 QAP-SAT 设计，以捕捉问题难度的全新特征，并通过 branch-and-bound 和 tabu search 求解器进行实验分析。结果显示，提出的 phase transition parameter 与 tabu search 的求解努力高度相关，可用于预测真正困难的 QAP 实例，从而为优化算法设计提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02783v1",
      "published_date": "2024-03-05 08:56:30 UTC",
      "updated_date": "2024-03-05 08:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:47:28.507924"
    },
    {
      "arxiv_id": "2403.02775v1",
      "title": "EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Tang",
        "Yifu Sun",
        "Decheng Wu",
        "Kai Liu",
        "Jianchen Zhu",
        "Zhanhui Kang"
      ],
      "abstract": "Large language models (LLMs) have proven to be very superior to conventional\nmethods in various tasks. However, their expensive computations and high memory\nrequirements are prohibitive for deployment. Model quantization is an effective\nmethod for reducing this overhead. The problem is that in most previous works,\nthe quantized model was calibrated using few samples from the training data,\nwhich might affect the generalization of the quantized LLMs to unknown cases\nand tasks. Hence in this work, we explore an important question: Can we design\na data-independent quantization method for LLMs to guarantee its generalization\nperformance? In this work, we propose EasyQuant, a training-free and\ndata-independent weight-only quantization algorithm for LLMs. Our observation\nindicates that two factors: outliers in the weight and quantization ranges, are\nessential for reducing the quantization error. Therefore, in EasyQuant, we\nleave the outliers (less than 1%) unchanged and optimize the quantization range\nto reduce the reconstruction error. With these methods, we surprisingly find\nthat EasyQuant achieves comparable performance to the original model. Since\nEasyQuant does not depend on any training data, the generalization performance\nof quantized LLMs is safely guaranteed. Moreover, EasyQuant can be implemented\nin parallel so that the quantized model could be attained in a few minutes even\nfor LLMs over 100B. To our best knowledge, we are the first work that achieves\nalmost lossless quantization performance for LLMs under a data-independent\nsetting and our algorithm runs over 10 times faster than the data-dependent\nmethods.",
      "tldr_zh": "大语言模型 (LLMs) 面临高计算和内存开销的问题，EasyQuant 提出了一种高效的训练-free 和数据-independent 权重-only 量化算法，以解决传统量化方法依赖训练数据可能影响泛化性能的缺陷。该算法通过保留权重中的异常值 (outliers) 不变并优化量化范围，显著减少量化误差，从而实现与原模型几乎无损的性能。实验表明，EasyQuant 在数据无关设置下比数据-dependent 方法快 10 倍以上，即使对超过 100B 参数的 LLMs，也能在几分钟内完成量化，确保了模型的泛化能力和部署效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02775v1",
      "published_date": "2024-03-05 08:45:30 UTC",
      "updated_date": "2024-03-05 08:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:47:40.843796"
    },
    {
      "arxiv_id": "2403.02772v2",
      "title": "Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Karlov",
        "Ali Abedi",
        "Shehroz S. Khan"
      ],
      "abstract": "Exercise-based rehabilitation programs have proven to be effective in\nenhancing the quality of life and reducing mortality and rehospitalization\nrates. AI-driven virtual rehabilitation, which allows patients to independently\ncomplete exercises at home, utilizes AI algorithms to analyze exercise data,\nproviding feedback to patients and updating clinicians on their progress. These\nprograms commonly prescribe a variety of exercise types, leading to a distinct\nchallenge in rehabilitation exercise assessment datasets: while abundant in\noverall training samples, these datasets often have a limited number of samples\nfor each individual exercise type. This disparity hampers the ability of\nexisting approaches to train generalizable models with such a small sample size\nper exercise type. Addressing this issue, this paper introduces a novel\nsupervised contrastive learning framework with hard and soft negative samples\nthat effectively utilizes the entire dataset to train a single model applicable\nto all exercise types. This model, with a Spatial-Temporal Graph Convolutional\nNetwork (ST-GCN) architecture, demonstrated enhanced generalizability across\nexercises and a decrease in overall complexity. Through extensive experiments\non three publicly available rehabilitation exercise assessment datasets,\nUI-PRMD, IRDS, and KIMORE, our method has proven to surpass existing methods,\nsetting a new benchmark in rehabilitation exercise quality assessment.",
      "tldr_zh": "这篇论文针对康复训练评估数据集的问题，即虽然整体样本充足但每个训练类型样本有限，导致模型泛化性差，提出了一种新型监督对比学习（Supervised Contrastive Learning）框架，使用硬负样本（Hard Negatives）和软负样本（Soft Negatives）。该框架基于Spatial-Temporal Graph Convolutional Network (ST-GCN) 架构，能够有效利用整个数据集训练一个适用于所有训练类型的单一模型，从而提升泛化性和降低复杂性。在UI-PRMD、IRDS和KIMORE三个公开数据集上的实验中，该方法超越了现有方法，设定了新的康复训练质量评估基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.02772v2",
      "published_date": "2024-03-05 08:38:25 UTC",
      "updated_date": "2024-08-09 15:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:47:52.544814"
    },
    {
      "arxiv_id": "2403.02760v2",
      "title": "Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations",
      "title_zh": "大型语言模型与机器学习在电子商务推荐中的新兴协同",
      "authors": [
        "Xiaonan Xu",
        "Yichao Wu",
        "Penghao Liang",
        "Yuhang He",
        "Han Wang"
      ],
      "abstract": "With the boom of e-commerce and web applications, recommender systems have\nbecome an important part of our daily lives, providing personalized\nrecommendations based on the user's preferences. Although deep neural networks\n(DNNs) have made significant progress in improving recommendation systems by\nsimulating the interaction between users and items and incorporating their\ntextual information, these DNN-based approaches still have some limitations,\nsuch as the difficulty of effectively understanding users' interests and\ncapturing textual information. It is not possible to generalize to different\nseen/unseen recommendation scenarios and reason about their predictions. At the\nsame time, the emergence of large language models (LLMs), represented by\nChatGPT and GPT-4, has revolutionized the fields of natural language processing\n(NLP) and artificial intelligence (AI) due to their superior capabilities in\nthe basic tasks of language understanding and generation, and their impressive\ngeneralization and reasoning capabilities. As a result, recent research has\nsought to harness the power of LLM to improve recommendation systems. Given the\nrapid development of this research direction in the field of recommendation\nsystems, there is an urgent need for a systematic review of existing LLM-driven\nrecommendation systems for researchers and practitioners in related fields to\ngain insight into. More specifically, we first introduced a representative\napproach to learning user and item representations using LLM as a feature\nencoder. We then reviewed the latest advances in LLMs techniques for\ncollaborative filtering enhanced recommendation systems from the three\nparadigms of pre-training, fine-tuning, and prompting. Finally, we had a\ncomprehensive discussion on the future direction of this emerging field.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 与机器学习在电子商务推荐系统中的协同作用，解决了传统深度神经网络 (DNNs) 方法在理解用户兴趣、捕捉文本信息以及泛化到不同场景方面的局限性。论文首先介绍了使用 LLMs 作为特征编码器来学习用户和物品表示，然后回顾了 LLMs 在协作过滤增强推荐系统中的最新进展，包括预训练、微调和提示技术。最终，它提供了现有 LLM 驱动推荐系统的系统性回顾，并讨论了这一领域的未来发展方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02760v2",
      "published_date": "2024-03-05 08:31:00 UTC",
      "updated_date": "2024-03-12 11:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:48:05.262539"
    },
    {
      "arxiv_id": "2403.15412v5",
      "title": "Towards Measuring and Modeling \"Culture\" in LLMs: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Farid Adilazuarda",
        "Sagnik Mukherjee",
        "Pradhyumna Lavania",
        "Siddhant Singh",
        "Alham Fikri Aji",
        "Jacki O'Neill",
        "Ashutosh Modi",
        "Monojit Choudhury"
      ],
      "abstract": "We present a survey of more than 90 recent papers that aim to study cultural\nrepresentation and inclusion in large language models (LLMs). We observe that\nnone of the studies explicitly define \"culture, which is a complex,\nmultifaceted concept; instead, they probe the models on some specially designed\ndatasets which represent certain aspects of \"culture\". We call these aspects\nthe proxies of culture, and organize them across two dimensions of demographic\nand semantic proxies. We also categorize the probing methods employed. Our\nanalysis indicates that only certain aspects of ``culture,'' such as values and\nobjectives, have been studied, leaving several other interesting and important\nfacets, especially the multitude of semantic domains (Thompson et al., 2020)\nand aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps\nare the lack of robustness of probing techniques and situated studies on the\nimpact of cultural mis- and under-representation in LLM-based applications.",
      "tldr_zh": "这篇调查论文审视了90多篇关于大型语言模型(LLMs)中文化表示和包容性的研究，发现这些研究并未明确定义“culture”这一复杂概念，而是通过demographic proxies和semantic proxies等代理来探测其特定方面。作者分类了各种探测方法，并分析指出，目前的研究仅关注了values和objectives等部分内容，而semantic domains和aboutness等重要领域仍未探索。论文还强调了探测技术的鲁棒性不足，以及缺乏对文化误表示或低度表示在LLM应用中的实际影响进行实证研究的空白。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.15412v5",
      "published_date": "2024-03-05 08:29:36 UTC",
      "updated_date": "2024-09-04 05:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:48:16.639773"
    },
    {
      "arxiv_id": "2403.02750v1",
      "title": "Speckle Noise Reduction in Ultrasound Images using Denoising Auto-encoder with Skip Connection",
      "title_zh": "利用带有跳跃连接的去噪自动编码器对超声图像进行斑点噪声减少",
      "authors": [
        "Suraj Bhute",
        "Subhamoy Mandal",
        "Debashree Guha"
      ],
      "abstract": "Ultrasound is a widely used medical tool for non-invasive diagnosis, but its\nimages often contain speckle noise which can lower their resolution and\ncontrast-to-noise ratio. This can make it more difficult to extract, recognize,\nand analyze features in the images, as well as impair the accuracy of\ncomputer-assisted diagnostic techniques and the ability of doctors to interpret\nthe images. Reducing speckle noise, therefore, is a crucial step in the\npreprocessing of ultrasound images. Researchers have proposed several speckle\nreduction methods, but no single method takes all relevant factors into\naccount. In this paper, we compare seven such methods: Median, Gaussian,\nBilateral, Average, Weiner, Anisotropic and Denoising auto-encoder without and\nwith skip connections in terms of their ability to preserve features and edges\nwhile effectively reducing noise. In an experimental study, a convolutional\nnoise-removing auto-encoder with skip connection, a deep learning method, was\nused to improve ultrasound images of breast cancer. This method involved adding\nspeckle noise at various levels. The results of the deep learning method were\ncompared to those of traditional image enhancement methods, and it was found\nthat the proposed method was more effective. To assess the performance of these\nalgorithms, we use three established evaluation metrics and present both\nfiltered images and statistical data.",
      "tldr_zh": "本论文针对超声图像中的speckle noise问题，比较了七种噪声减少方法，包括Median、Gaussian、Bilateral等传统方法，以及Denoising auto-encoder（有无skip connection）。作者提出了一种带有skip connection的卷积噪声移除auto-encoder，用于处理乳腺癌超声图像，通过添加不同级别的speckle noise进行实验。结果显示，该深度学习方法在保留图像特征和边缘的同时，更有效地减少噪声，并通过三个评价指标的统计数据和过滤图像证明其优于传统方法。总的来说，此方法为超声图像预处理提供了更可靠的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "Selected for presentation at 2024 IEEE South Asian Ultrasonics\n  Symposium",
      "pdf_url": "http://arxiv.org/pdf/2403.02750v1",
      "published_date": "2024-03-05 08:08:59 UTC",
      "updated_date": "2024-03-05 08:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:48:29.757441"
    },
    {
      "arxiv_id": "2403.02745v2",
      "title": "CURATRON: Complete and Robust Preference Data for Rigorous Alignment of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Son The Nguyen",
        "Niranjan Uma Naresh",
        "Theja Tulabandhula"
      ],
      "abstract": "This paper addresses the challenges of aligning large language models (LLMs)\nwith human values via preference learning (PL), focusing on incomplete and\ncorrupted data in preference datasets. We propose a novel method for robustly\nand completely recalibrating values within these datasets to enhance LLMs'\nresilience against the issues. In particular, we devise a guaranteed polynomial\ntime ranking algorithm that robustifies several existing models, such as the\nclassic Bradley-Terry-Luce (BTL) (Bradley and Terry, 1952) model and certain\ngeneralizations of it. To the best of our knowledge, our present work is the\nfirst to propose an algorithm that provably recovers an $\\epsilon$-optimal\nranking with high probability while allowing as large as $O(n)$ perturbed\npairwise comparison results per model response. Furthermore, we show robust\nrecovery results in the partially observed setting. Our experiments confirm\nthat our algorithms handle adversarial noise and unobserved comparisons well in\nboth general and LLM preference dataset settings. This work contributes to the\ndevelopment and scaling of more reliable and ethically aligned AI models by\nequipping the dataset curation pipeline with the ability to handle missing and\nmaliciously manipulated inputs.",
      "tldr_zh": "本论文解决了大型语言模型（LLMs）通过偏好学习（PL）与人类价值观对齐的挑战，焦点在于偏好数据集中的不完整和损坏数据问题。作者提出CURATRON方法，包括一个保证多项式时间排名算法，用于强化现有模型如Bradley-Terry-Luce (BTL)模型，该算法能从高达O(n)的扰动配对比较中恢复ε-最优排名，并在部分观察设置下实现稳健恢复。实验结果表明，该算法有效处理对抗性噪声和未观察比较，从而提升数据集校准流程，支持开发更可靠和道德对齐的AI模型。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02745v2",
      "published_date": "2024-03-05 07:58:12 UTC",
      "updated_date": "2024-10-30 08:54:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:48:41.586719"
    },
    {
      "arxiv_id": "2403.02736v1",
      "title": "Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Akram Zaytar",
        "Caleb Robinson",
        "Gilles Q. Hacheme",
        "Girmaw A. Tadesse",
        "Rahul Dodhia",
        "Juan M. Lavista Ferres",
        "Lacey F. Hughey",
        "Jared A. Stabach",
        "Irene Amoke"
      ],
      "abstract": "Rare object detection is a fundamental task in applied geospatial machine\nlearning, however is often challenging due to large amounts of high-resolution\nsatellite or aerial imagery and few or no labeled positive samples to start\nwith. This paper addresses the problem of bootstrapping such a rare object\ndetection task assuming there is no labeled data and no spatial prior over the\narea of interest. We propose novel offline and online cluster-based approaches\nfor sampling patches that are significantly more efficient, in terms of\nexposing positive samples to a human annotator, than random sampling. We apply\nour methods for identifying bomas, or small enclosures for herd animals, in the\nSerengeti Mara region of Kenya and Tanzania. We demonstrate a significant\nenhancement in detection efficiency, achieving a positive sampling rate\nincrease from 2% (random) to 30%. This advancement enables effective machine\nlearning mapping even with minimal labeling budgets, exemplified by an F1 score\non the boma detection task of 0.51 with a budget of 300 total patches.",
      "tldr_zh": "这篇论文解决了高分辨率卫星图像中稀有物体检测的挑战，提出了一种基于聚类的离线和在线采样方法，能够在没有标记数据和空间先验的情况下，更高效地暴露正样本，从而减少标注工作量。相比随机采样，该方法将正样本采样率从2%提高到30%，并应用于肯尼亚和坦桑尼亚塞伦盖蒂马拉地区的bomas（小型围栏）检测任务。结果显示，在仅300个补丁的标记预算下，实现了0.51的F1分数，显著提升了机器学习映射的效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02736v1",
      "published_date": "2024-03-05 07:44:13 UTC",
      "updated_date": "2024-03-05 07:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:48:52.698378"
    },
    {
      "arxiv_id": "2403.02727v1",
      "title": "HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?",
      "title_zh": "翻译失败",
      "authors": [
        "Sijie Ji",
        "Xinzhe Zheng",
        "Chenshu Wu"
      ],
      "abstract": "There is an ongoing debate regarding the potential of Large Language Models\n(LLMs) as foundational models seamlessly integrated with Cyber-Physical Systems\n(CPS) for interpreting the physical world. In this paper, we carry out a case\nstudy to answer the following question: Are LLMs capable of zero-shot human\nactivity recognition (HAR). Our study, HARGPT, presents an affirmative answer\nby demonstrating that LLMs can comprehend raw IMU data and perform HAR tasks in\na zero-shot manner, with only appropriate prompts. HARGPT inputs raw IMU data\ninto LLMs and utilizes the role-play and think step-by-step strategies for\nprompting. We benchmark HARGPT on GPT4 using two public datasets of different\ninter-class similarities and compare various baselines both based on\ntraditional machine learning and state-of-the-art deep classification models.\nRemarkably, LLMs successfully recognize human activities from raw IMU data and\nconsistently outperform all the baselines on both datasets. Our findings\nindicate that by effective prompting, LLMs can interpret raw IMU data based on\ntheir knowledge base, possessing a promising potential to analyze raw sensor\ndata of the physical world effectively.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否能零样本 (zero-shot) 进行人类活动识别 (HAR)，通过案例研究 HARGPT 给出了肯定的答案。HARGPT 方法将原始 IMU 数据输入 LLMs，并采用角色扮演和逐步思考策略进行提示，使模型无需训练即可理解和处理数据。在两个公共数据集上的基准测试中，HARGPT 基于 GPT4 超过了传统机器学习和最先进深度分类模型的基线。研究结果表明，通过有效提示，LLMs 可以基于其知识库解释物理世界传感器数据，在 Cyber-Physical Systems (CPS) 中展现出巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02727v1",
      "published_date": "2024-03-05 07:34:51 UTC",
      "updated_date": "2024-03-05 07:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:49:06.610830"
    },
    {
      "arxiv_id": "2403.02726v1",
      "title": "Bias in Generative AI",
      "title_zh": "生成式 AI 中的偏见",
      "authors": [
        "Mi Zhou",
        "Vibhanshu Abhishek",
        "Timothy Derdenger",
        "Jaymo Kim",
        "Kannan Srinivasan"
      ],
      "abstract": "This study analyzed images generated by three popular generative artificial\nintelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 -\nrepresenting various occupations to investigate potential bias in AI\ngenerators. Our analysis revealed two overarching areas of concern in these AI\ngenerators, including (1) systematic gender and racial biases, and (2) subtle\nbiases in facial expressions and appearances. Firstly, we found that all three\nAI generators exhibited bias against women and African Americans. Moreover, we\nfound that the evident gender and racial biases uncovered in our analysis were\neven more pronounced than the status quo when compared to labor force\nstatistics or Google images, intensifying the harmful biases we are actively\nstriving to rectify in our society. Secondly, our study uncovered more nuanced\nprejudices in the portrayal of emotions and appearances. For example, women\nwere depicted as younger with more smiles and happiness, while men were\ndepicted as older with more neutral expressions and anger, posing a risk that\ngenerative AI models may unintentionally depict women as more submissive and\nless competent than men. Such nuanced biases, by their less overt nature, might\nbe more problematic as they can permeate perceptions unconsciously and may be\nmore difficult to rectify. Although the extent of bias varied depending on the\nmodel, the direction of bias remained consistent in both commercial and\nopen-source AI generators. As these tools become commonplace, our study\nhighlights the urgency to identify and mitigate various biases in generative\nAI, reinforcing the commitment to ensuring that AI technologies benefit all of\nhumanity for a more inclusive future.",
      "tldr_zh": "本研究分析了 Midjourney、Stable Diffusion 和 DALLE 2 等生成式 AI 工具生成的图像，调查职业代表中的潜在偏见。结果显示，这些 AI 存在系统性的性别和种族偏见，例如对女性和非洲裔美国人的歧视，且这种偏见比现实劳动力统计或 Google 图像更严重。研究还揭示了微妙的表达偏见，如女性被描绘得更年轻、更快乐，而男性被描绘得更老、更中性或愤怒，可能强化社会刻板印象。尽管偏见程度因模型而异，但方向在商业和开源 AI 中保持一致。该研究强调了识别和缓解生成式 AI 偏见的紧迫性，以促进更包容的 AI 技术发展。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02726v1",
      "published_date": "2024-03-05 07:34:41 UTC",
      "updated_date": "2024-03-05 07:34:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:49:17.965770"
    },
    {
      "arxiv_id": "2403.02723v1",
      "title": "Minimum Topology Attacks for Graph Neural Networks",
      "title_zh": "最小拓扑攻击用于图神经网络",
      "authors": [
        "Mengmei Zhang",
        "Xiao Wang",
        "Chuan Shi",
        "Lingjuan Lyu",
        "Tianchi Yang",
        "Junping Du"
      ],
      "abstract": "With the great popularity of Graph Neural Networks (GNNs), their robustness\nto adversarial topology attacks has received significant attention. Although\nmany attack methods have been proposed, they mainly focus on fixed-budget\nattacks, aiming at finding the most adversarial perturbations within a fixed\nbudget for target node. However, considering the varied robustness of each\nnode, there is an inevitable dilemma caused by the fixed budget, i.e., no\nsuccessful perturbation is found when the budget is relatively small, while if\nit is too large, the yielding redundant perturbations will hurt the\ninvisibility. To break this dilemma, we propose a new type of topology attack,\nnamed minimum-budget topology attack, aiming to adaptively find the minimum\nperturbation sufficient for a successful attack on each node. To this end, we\npropose an attack model, named MiBTack, based on a dynamic projected gradient\ndescent algorithm, which can effectively solve the involving non-convex\nconstraint optimization on discrete topology. Extensive results on three GNNs\nand four real-world datasets show that MiBTack can successfully lead all target\nnodes misclassified with the minimum perturbation edges. Moreover, the obtained\nminimum budget can be used to measure node robustness, so we can explore the\nrelationships of robustness, topology, and uncertainty for nodes, which is\nbeyond what the current fixed-budget topology attacks can offer.",
      "tldr_zh": "本研究针对 Graph Neural Networks (GNNs) 的对抗性拓扑攻击，指出现有 fixed-budget attacks 的局限性，即预算过小无法成功攻击，过大则降低隐蔽性。作者提出 minimum-budget topology attack 的一种新模型 MiBTack，利用 dynamic projected gradient descent algorithm 解决离散拓扑上的非凸约束优化问题，以为每个节点找到最小扰动边实现成功攻击。实验在三个 GNNs 和四个真实数据集上显示，MiBTack 能使所有目标节点误分类，同时最小预算可用于衡量节点鲁棒性，并探索其与拓扑和不确定性的关系。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published on WWW 2023. Proceedings of the ACM Web Conference 2023",
      "pdf_url": "http://arxiv.org/pdf/2403.02723v1",
      "published_date": "2024-03-05 07:29:12 UTC",
      "updated_date": "2024-03-05 07:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:49:29.988154"
    },
    {
      "arxiv_id": "2403.02719v3",
      "title": "Multi-Scale Subgraph Contrastive Learning",
      "title_zh": "多尺度子图对比学习",
      "authors": [
        "Yanbei Liu",
        "Yu Zhao",
        "Xiao Wang",
        "Lei Geng",
        "Zhitao Xiao"
      ],
      "abstract": "Graph-level contrastive learning, aiming to learn the representations for\neach graph by contrasting two augmented graphs, has attracted considerable\nattention. Previous studies usually simply assume that a graph and its\naugmented graph as a positive pair, otherwise as a negative pair. However, it\nis well known that graph structure is always complex and multi-scale, which\ngives rise to a fundamental question: after graph augmentation, will the\nprevious assumption still hold in reality? By an experimental analysis, we\ndiscover the semantic information of an augmented graph structure may be not\nconsistent as original graph structure, and whether two augmented graphs are\npositive or negative pairs is highly related with the multi-scale structures.\nBased on this finding, we propose a multi-scale subgraph contrastive learning\narchitecture which is able to characterize the fine-grained semantic\ninformation. Specifically, we generate global and local views at different\nscales based on subgraph sampling, and construct multiple contrastive\nrelationships according to their semantic associations to provide richer\nself-supervised signals. Extensive experiments and parametric analyzes on eight\ngraph classification real-world datasets well demonstrate the effectiveness of\nthe proposed method.",
      "tldr_zh": "该研究发现，传统图级对比学习中简单地将增强图视为正对的假设可能失效，因为图结构的复杂多尺度性会导致语义不一致。为此，提出了一种Multi-Scale Subgraph Contrastive Learning框架，通过子图采样生成不同尺度的全局和局部视图，并根据语义关联构建多种对比关系，以捕捉细粒度语义信息并提供更丰富的自监督信号。实验在八个真实世界图分类数据集上进行，证明了该方法的有效性，显著提升了模型性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 32nd International Joint Conference on Artificial Intelligence\n  (IJCAI-2023)",
      "pdf_url": "http://arxiv.org/pdf/2403.02719v3",
      "published_date": "2024-03-05 07:17:18 UTC",
      "updated_date": "2024-04-12 01:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:49:40.732574"
    },
    {
      "arxiv_id": "2403.02715v2",
      "title": "Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sang T. Truong",
        "Duc Q. Nguyen",
        "Toan Nguyen",
        "Dong D. Le",
        "Nhi N. Truong",
        "Tho Quan",
        "Sanmi Koyejo"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have underscored their\nimportance in the evolution of artificial intelligence. However, despite\nextensive pretraining on multilingual datasets, available open-sourced LLMs\nexhibit limited effectiveness in processing Vietnamese. The challenge is\nexacerbated by the absence of systematic benchmark datasets and metrics\ntailored for Vietnamese LLM evaluation. To mitigate these issues, we have\nfinetuned LLMs specifically for Vietnamese and developed a comprehensive\nevaluation framework encompassing 10 common tasks and 31 metrics. Our\nevaluation results reveal that the fine-tuned LLMs exhibit enhanced\ncomprehension and generative capabilities in Vietnamese. Moreover, our analysis\nindicates that models with more parameters can introduce more biases and\nuncalibrated outputs and the key factor influencing LLM performance is the\nquality of the training or fine-tuning datasets. These insights underscore the\nsignificance of meticulous fine-tuning with high-quality datasets in enhancing\nLLM performance.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在处理越南语时的局限性，突出了现有模型在多语言数据集上预训练后仍缺乏针对性。作者通过针对越南语进行微调( finetuning )，并开发了一个全面评估框架，包括10个常见任务和31个指标，来提升模型的理解和生成能力。评估结果显示，微调后的LLMs在越南语表现显著改善，但参数更多的模型可能带来更多偏差和未校准输出；关键因素是训练或微调数据集的质量，这强调了使用高质量数据集进行细致优化的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.02715v2",
      "published_date": "2024-03-05 07:13:28 UTC",
      "updated_date": "2024-05-26 17:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:49:52.851574"
    },
    {
      "arxiv_id": "2403.02701v1",
      "title": "Fighting Game Adaptive Background Music for Improved Gameplay",
      "title_zh": "翻译失败",
      "authors": [
        "Ibrahim Khan",
        "Thai Van Nguyen",
        "Chollakorn Nimpattanavong",
        "Ruck Thawonmas"
      ],
      "abstract": "This paper presents our work to enhance the background music (BGM) in\nDareFightingICE by adding adaptive features. The adaptive BGM consists of three\ndifferent categories of instruments playing the BGM of the winner sound design\nfrom the 2022 DareFightingICE Competition. The BGM adapts by changing the\nvolume of each category of instruments. Each category is connected to a\ndifferent element of the game. We then run experiments to evaluate the adaptive\nBGM by using a deep reinforcement learning AI agent that only uses audio as\ninput (Blind DL AI). The results show that the performance of the Blind DL AI\nimproves while playing with the adaptive BGM as compared to playing without the\nadaptive BGM.",
      "tldr_zh": "本研究开发了适配性背景音乐 (adaptive BGM) 来提升格斗游戏 DareFightingICE 的游戏体验，该音乐由三类乐器组成，每类与游戏不同元素相关联，并通过调整音量实现动态适应。研究方法包括使用仅依赖音频输入的深度强化学习 AI 代理 (Blind DL AI) 进行实验评估。结果显示，与无适配性 BGM 相比，Blind DL AI 在使用适配性 BGM 时性能得到改善，从而证明了这一方法对游戏玩法的积极影响。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "I.2; H.5.2; H.5"
      ],
      "primary_category": "cs.SD",
      "comment": "This is an updated version of our IEEE CoG 2023 paper\n  (https://ieeexplore.ieee.org/document/10333245). This version has revised the\n  description of the association between the distance between the two players\n  (PD) and the instrument's volume on page 2. arXiv admin note: substantial\n  text overlap with arXiv:2303.15734",
      "pdf_url": "http://arxiv.org/pdf/2403.02701v1",
      "published_date": "2024-03-05 06:46:43 UTC",
      "updated_date": "2024-03-05 06:46:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:50:04.655868"
    },
    {
      "arxiv_id": "2403.02694v4",
      "title": "MeanCache: User-Centric Semantic Caching for LLM Web Services",
      "title_zh": "MeanCache：以用户为中心的语义缓存，用于 LLM Web 服务",
      "authors": [
        "Waris Gill",
        "Mohamed Elidrisi",
        "Pallavi Kalapatapu",
        "Ammar Ahmed",
        "Ali Anwar",
        "Muhammad Ali Gulzar"
      ],
      "abstract": "Large Language Models (LLMs) like ChatGPT and Llama have revolutionized\nnatural language processing and search engine dynamics. However, these models\nincur exceptionally high computational costs. For instance, GPT-3 consists of\n175 billion parameters, where inference demands billions of floating-point\noperations. Caching is a natural solution to reduce LLM inference costs on\nrepeated queries, which constitute about 31% of the total queries. However,\nexisting caching methods are incapable of finding semantic similarities among\nLLM queries nor do they operate on contextual queries, leading to unacceptable\nfalse hit-and-miss rates. This paper introduces MeanCache, a user-centric\nsemantic cache for LLM-based services that identifies semantically similar\nqueries to determine cache hit or miss. Using MeanCache, the response to a\nuser's semantically similar query can be retrieved from a local cache rather\nthan re-querying the LLM, thus reducing costs, service provider load, and\nenvironmental impact. MeanCache leverages Federated Learning (FL) to\ncollaboratively train a query similarity model without violating user privacy.\nBy placing a local cache in each user's device and using FL, MeanCache reduces\nthe latency and costs and enhances model performance, resulting in lower false\nhit rates. MeanCache also encodes context chains for every cached query,\noffering a simple yet highly effective mechanism to discern contextual query\nresponses from standalone. Our experiments benchmarked against the\nstate-of-the-art caching method, reveal that MeanCache attains an approximately\n17% higher F-score and a 20% increase in precision during semantic cache\nhit-and-miss decisions while performing even better on contextual queries. It\nalso reduces the storage requirement by 83% and accelerates semantic cache\nhit-and-miss decisions by 11%.",
      "tldr_zh": "这篇论文提出了 MeanCache，一种用户中心语义缓存系统，旨在降低大型语言模型 (LLMs) 如 ChatGPT 在 Web 服务中的高计算成本，通过识别语义相似查询来实现缓存命中。MeanCache 利用 Federated Learning (FL) 训练查询相似性模型，并在用户设备上部署本地缓存，以保护隐私、减少延迟和成本，同时通过上下文链编码处理上下文查询。实验结果显示，与现有方法相比，MeanCache 提高了 17% F-score 和 20% 精度，尤其在上下文查询上表现更优，并减少了 83% 存储需求和 11% 缓存决策时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.DC",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at 2025 IEEE 39th International Parallel and Distributed\n  Processing Symposium (IPDPS)",
      "pdf_url": "http://arxiv.org/pdf/2403.02694v4",
      "published_date": "2024-03-05 06:23:50 UTC",
      "updated_date": "2025-03-07 14:49:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:50:17.788002"
    },
    {
      "arxiv_id": "2403.02688v2",
      "title": "DOCTOR: Dynamic On-Chip Temporal Variation Remediation Toward Self-Corrected Photonic Tensor Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Haotian Lu",
        "Sanmitra Banerjee",
        "Jiaqi Gu"
      ],
      "abstract": "Photonic computing has emerged as a promising solution for accelerating\ncomputation-intensive artificial intelligence (AI) workloads, offering\nunparalleled speed and energy efficiency, especially in resource-limited,\nlatency-sensitive edge computing environments. However, the deployment of\nanalog photonic tensor accelerators encounters reliability challenges due to\nhardware noise and environmental variations. While off-chip noise-aware\ntraining and on-chip training have been proposed to enhance the variation\ntolerance of optical neural accelerators with moderate, static noise, we\nobserve a notable performance degradation over time due to temporally drifting\nvariations, which requires a real-time, in-situ calibration mechanism. To\ntackle this challenging reliability issues, for the first time, we propose a\nlightweight dynamic on-chip remediation framework, dubbed DOCTOR, providing\nadaptive, in-situ accuracy recovery against temporally drifting noise. The\nDOCTOR framework intelligently monitors the chip status using adaptive probing\nand performs fast in-situ training-free calibration to restore accuracy when\nnecessary. Recognizing nonuniform spatial variation distributions across\ndevices and tensor cores, we also propose a variation-aware architectural\nremapping strategy to avoid executing critical tasks on noisy devices.\nExtensive experiments show that our proposed framework can guarantee sustained\nperformance under drifting variations with 34% higher accuracy and 2-3\norders-of-magnitude lower overhead compared to state-of-the-art on-chip\ntraining methods. Our code is open-sourced at\nhttps://github.com/ScopeX-ASU/DOCTOR.",
      "tldr_zh": "该论文针对光子计算加速器在AI工作负载中的可靠性挑战，特别是由于硬件噪声和环境变化导致的时间漂移问题，提出了一种轻量级的动态芯片上修复框架DOCTOR。DOCTOR框架通过自适应探测监控芯片状态、进行快速无训练校准以及变异感知架构重映射策略，来实现实时精度恢复，避免关键任务在噪声设备上执行。实验结果显示，与现有芯片上训练方法相比，DOCTOR在漂移变化下提高了34%的准确率，并将开销降低了2-3数量级，为自校正光子张量加速器提供了高效解决方案。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.ET",
      "comment": "9 pages. Accepted to IEEE JLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02688v2",
      "published_date": "2024-03-05 06:17:13 UTC",
      "updated_date": "2024-05-31 20:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:50:29.251937"
    },
    {
      "arxiv_id": "2403.02687v2",
      "title": "Enhanced DareFightingICE Competitions: Sound Design and AI Competitions",
      "title_zh": "增强的 DareFightingICE 比赛：声音设计和 AI 比赛",
      "authors": [
        "Ibrahim Khan",
        "Chollakorn Nimpattanavong",
        "Thai Van Nguyen",
        "Kantinan Plupattanakit",
        "Ruck Thawonmas"
      ],
      "abstract": "This paper presents a new and improved DareFightingICE platform, a fighting\ngame platform with a focus on visually impaired players (VIPs), in the Unity\ngame engine. It also introduces the separation of the DareFightingICE\nCompetition into two standalone competitions called DareFightingICE Sound\nDesign Competition and DareFightingICE AI Competition--at the 2024 IEEE\nConference on Games (CoG)--in which a new platform will be used. This new\nplatform is an enhanced version of the old DareFightingICE platform, having a\nbetter audio system to convey 3D sound and a better way to send audio data to\nAI agents. With this enhancement and by utilizing Unity, the new\nDareFightingICE platform is more accessible in terms of adding new features for\nVIPs and future audio research. This paper also improves the evaluation method\nfor evaluating sound designs in the Sound Design Competition which will ensure\na better sound design for VIPs as this competition continues to run at future\nCoG. To the best of our knowledge, both of our competitions are first of their\nkind, and the connection between the competitions to mutually improve the\nentries' quality with time makes these competitions an important part of\nrepresenting an often overlooked segment within the broader gaming community,\nVIPs.",
      "tldr_zh": "本研究介绍了增强版 DareFightingICE 平台，这是一个针对视力障碍玩家 (VIPs) 的格斗游戏平台，使用 Unity 引擎进行开发。平台通过改进音频系统支持3D声音并优化向 AI 代理发送音频数据的方式，提升了可访问性和功能扩展性。论文将 DareFightingICE 比赛分为两个独立赛事——DareFightingICE Sound Design Competition 和 DareFightingICE AI Competition——在2024 IEEE Conference on Games (CoG) 上举行，并改进了声音设计评估方法，以持续提升参赛作品质量。这些创新是首创的举措，有助于代表游戏社区中被忽略的 VIPs 群体，推动音频研究和游戏包容性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS",
        "I.2; H.5.2; H.5.5"
      ],
      "primary_category": "cs.HC",
      "comment": "This paper describes a new competition platform using Unity for our\n  competitions at the 2024 IEEE Conference on Games (CoG 2024). It was accepted\n  for presentation at CoG 2024. However, we recently discovered a much more\n  effective way to do this task without using Unity, leading to our decision to\n  withdraw the paper from CoG 2024 and ArXiv",
      "pdf_url": "http://arxiv.org/pdf/2403.02687v2",
      "published_date": "2024-03-05 06:15:48 UTC",
      "updated_date": "2024-04-27 22:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:50:41.416013"
    },
    {
      "arxiv_id": "2403.02651v1",
      "title": "Learning at the Speed of Wireless: Online Real-Time Learning for AI-Enabled MIMO in NextG",
      "title_zh": "翻译失败",
      "authors": [
        "Jiarui Xu",
        "Shashank Jere",
        "Yifei Song",
        "Yi-Hung Kao",
        "Lizhong Zheng",
        "Lingjia Liu"
      ],
      "abstract": "Integration of artificial intelligence (AI) and machine learning (ML) into\nthe air interface has been envisioned as a key technology for next-generation\n(NextG) cellular networks. At the air interface, multiple-input multiple-output\n(MIMO) and its variants such as multi-user MIMO (MU-MIMO) and\nmassive/full-dimension MIMO have been key enablers across successive\ngenerations of cellular networks with evolving complexity and design\nchallenges. Initiating active investigation into leveraging AI/ML tools to\naddress these challenges for MIMO becomes a critical step towards an AI-enabled\nNextG air interface. At the NextG air interface, the underlying wireless\nenvironment will be extremely dynamic with operation adaptations performed on a\nsub-millisecond basis by MIMO operations such as MU-MIMO scheduling and\nrank/link adaptation. Given the enormously large number of operation adaptation\npossibilities, we contend that online real-time AI/ML-based approaches\nconstitute a promising paradigm. To this end, we outline the inherent\nchallenges and offer insights into the design of such online real-time\nAI/ML-based solutions for MIMO operations. An online real-time AI/ML-based\nmethod for MIMO-OFDM channel estimation is then presented, serving as a\npotential roadmap for developing similar techniques across various MIMO\noperations in NextG.",
      "tldr_zh": "这篇论文探讨了在 NextG 蜂窝网络中，将 AI 和 ML 整合到空口接口的 MIMO（多输入多输出）技术中，以应对其日益复杂的挑战。论文提出采用在线实时 AI/ML 方法，来适应动态无线环境中的操作，如 MU-MIMO 调度和秩/链路适应，从而处理海量可能性带来的难题。作者分析了 inherent challenges，提供设计见解，并以一个 MIMO-OFDM 信道估计的在线实时 AI/ML 方法为例，展示了这类技术的潜在路线图。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "7 pages, 4 figures, 1 table, magazine paper",
      "pdf_url": "http://arxiv.org/pdf/2403.02651v1",
      "published_date": "2024-03-05 04:48:24 UTC",
      "updated_date": "2024-03-05 04:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:50:54.089520"
    },
    {
      "arxiv_id": "2403.02648v4",
      "title": "Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad",
      "title_zh": "翻译失败",
      "authors": [
        "Sayantan Choudhury",
        "Nazarii Tupitsa",
        "Nicolas Loizou",
        "Samuel Horvath",
        "Martin Takac",
        "Eduard Gorbunov"
      ],
      "abstract": "Adaptive methods are extremely popular in machine learning as they make\nlearning rate tuning less expensive. This paper introduces a novel optimization\nalgorithm named KATE, which presents a scale-invariant adaptation of the\nwell-known AdaGrad algorithm. We prove the scale-invariance of KATE for the\ncase of Generalized Linear Models. Moreover, for general smooth non-convex\nproblems, we establish a convergence rate of $O \\left(\\frac{\\log T}{\\sqrt{T}}\n\\right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also\ncompare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in\nnumerical experiments with different problems, including complex machine\nlearning tasks like image classification and text classification on real data.\nThe results indicate that KATE consistently outperforms AdaGrad and\nmatches/surpasses the performance of Adam in all considered scenarios.",
      "tldr_zh": "本论文提出了一种新的优化算法 KATE，这是一个高效的 scale-invariant 版本的 AdaGrad，用于减少学习率调优的复杂性。\n作者证明了 KATE 在 Generalized Linear Models 中的 scale-invariance，并为一般平滑非凸问题建立了 O(log T / √T) 的收敛率，与 AdaGrad 和 Adam 的最佳已知收敛率相当。\n在数值实验中，KATE 在图像分类和文本分类等机器学习任务上表现优于 AdaGrad，并与 Adam 相当或更胜一筹。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.02648v4",
      "published_date": "2024-03-05 04:35:59 UTC",
      "updated_date": "2025-01-13 19:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:51:06.803920"
    },
    {
      "arxiv_id": "2403.02647v1",
      "title": "FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model",
      "title_zh": "FinReport：通过新闻因素分析模型的可解释股票收益预测",
      "authors": [
        "Xiangyu Li",
        "Xinjie Shen",
        "Yawen Zeng",
        "Xiaofen Xing",
        "Jin Xu"
      ],
      "abstract": "The task of stock earnings forecasting has received considerable attention\ndue to the demand investors in real-world scenarios. However, compared with\nfinancial institutions, it is not easy for ordinary investors to mine factors\nand analyze news. On the other hand, although large language models in the\nfinancial field can serve users in the form of dialogue robots, it still\nrequires users to have financial knowledge to ask reasonable questions. To\nserve the user experience, we aim to build an automatic system, FinReport, for\nordinary investors to collect information, analyze it, and generate reports\nafter summarizing.\n  Specifically, our FinReport is based on financial news announcements and a\nmulti-factor model to ensure the professionalism of the report. The FinReport\nconsists of three modules: news factorization module, return forecasting\nmodule, risk assessment module. The news factorization module involves\nunderstanding news information and combining it with stock factors, the return\nforecasting module aim to analysis the impact of news on market sentiment, and\nthe risk assessment module is adopted to control investment risk. Extensive\nexperiments on real-world datasets have well verified the effectiveness and\nexplainability of our proposed FinReport. Our codes and datasets are available\nat https://github.com/frinkleko/FinReport.",
      "tldr_zh": "本研究提出FinReport系统，这是一个基于新闻因素分析模型的可解释股票收益预测框架，旨在帮助普通投资者自动收集、分析金融新闻并生成专业报告，而无需用户具备深厚金融知识。FinReport由三个模块组成：news factorization module（用于理解新闻并结合股票因素）、return forecasting module（分析新闻对市场情绪的影响）和risk assessment module（控制投资风险），以多因子模型为基础确保报告的专业性。在真实数据集上的广泛实验验证了FinReport的有效性和可解释性，并提供了开源代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by WWW 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02647v1",
      "published_date": "2024-03-05 04:33:36 UTC",
      "updated_date": "2024-03-05 04:33:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:51:19.089233"
    },
    {
      "arxiv_id": "2403.02635v1",
      "title": "PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning",
      "title_zh": "PPS-QMIX：周期性地参数共享用于加速多智能体强化学习的收敛",
      "authors": [
        "Ke Zhang",
        "DanDan Zhu",
        "Qiuhan Xu",
        "Hao Zhou",
        "Ce Zheng"
      ],
      "abstract": "Training for multi-agent reinforcement learning(MARL) is a time-consuming\nprocess caused by distribution shift of each agent. One drawback is that\nstrategy of each agent in MARL is independent but actually in cooperation.\nThus, a vertical issue in multi-agent reinforcement learning is how to\nefficiently accelerate training process. To address this problem, current\nresearch has leveraged a centralized function(CF) across multiple agents to\nlearn contribution of the team reward for each agent. However, CF based methods\nintroduce joint error from other agents in estimation of value network. In so\ndoing, inspired by federated learning, we propose three simple novel approaches\ncalled Average Periodically Parameter Sharing(A-PPS), Reward-Scalability\nPeriodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically\nParameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents\nshare Q-value network periodically during the training process. Agents which\nhas same identity adapt collected reward as scalability and update partial\nneural network during period to share different parameters. We apply our\napproaches in classical MARL method QMIX and evaluate our approaches on various\ntasks in StarCraft Multi-Agent Challenge(SMAC) environment. Performance of\nnumerical experiments yield enormous enhancement, with an average improvement\nof 10\\%-30\\%, and enable to win tasks that QMIX cannot. Our code can be\ndownloaded from https://github.com/ColaZhang22/PPS-QMIX",
      "tldr_zh": "这篇论文针对多智能体强化学习 (MARL) 的训练过程耗时问题，提出了 PPS-QMIX 框架，通过定期参数共享机制来加速收敛。作者引入了三种新方法：Average Periodically Parameter Sharing (A-PPS)、Reward-Scalability Periodically Parameter Sharing (RS-PPS) 和 Partial Personalized Periodically Parameter Sharing (PP-PPS)，这些方法让智能体在训练中定期共享 Q-value network，并根据智能体身份调整奖励缩放和部分网络更新，以减少 centralized function (CF) 带来的联合错误。实验结果显示，在 StarCraft Multi-Agent Challenge (SMAC) 环境中的各种任务上，PPS-QMIX 比原始 QMIX 方法平均提高了 10%-30% 的性能，甚至在 QMIX 无法完成的任务上实现了胜利。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.02635v1",
      "published_date": "2024-03-05 03:59:01 UTC",
      "updated_date": "2024-03-05 03:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:51:32.523154"
    },
    {
      "arxiv_id": "2403.02624v2",
      "title": "Pareto-Optimal Estimation and Policy Learning on Short-term and Long-term Treatment Effects",
      "title_zh": "针对短期和长期治疗效果的帕累托最优估计与策略学习",
      "authors": [
        "Yingrong Wang",
        "Anpeng Wu",
        "Haoxuan Li",
        "Weiming Liu",
        "Qiaowei Miao",
        "Ruoxuan Xiong",
        "Fei Wu",
        "Kun Kuang"
      ],
      "abstract": "This paper focuses on developing Pareto-optimal estimation and policy\nlearning to identify the most effective treatment that maximizes the total\nreward from both short-term and long-term effects, which might conflict with\neach other. For example, a higher dosage of medication might increase the speed\nof a patient's recovery (short-term) but could also result in severe long-term\nside effects. Although recent works have investigated the problems about\nshort-term or long-term effects or the both, how to trade-off between them to\nachieve optimal treatment remains an open challenge. Moreover, when multiple\nobjectives are directly estimated using conventional causal representation\nlearning, the optimization directions among various tasks can conflict as well.\nIn this paper, we systematically investigate these issues and introduce a\nPareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and\nPareto-Optimal Policy Learning (POPL), to tackle them. POE incorporates a\ncontinuous Pareto module with representation balancing, enhancing estimation\nefficiency across multiple tasks. As for POPL, it involves deriving short-term\nand long-term outcomes linked with various treatment levels, facilitating an\nexploration of the Pareto frontier emanating from these outcomes. Results on\nboth the synthetic and real-world datasets demonstrate the superiority of our\nmethod.",
      "tldr_zh": "这篇论文开发了 Pareto-Optimal Estimation (POE) 和 Pareto-Optimal Policy Learning (POPL)，以识别最优治疗方案，该方案最大化短期和长期效果的总回报，同时处理两者可能冲突的问题，例如高剂量药物加速恢复但引发长期副作用。POE 通过引入连续 Pareto 模块和表示平衡，提高了多任务因果估计的效率，避免了任务间优化方向的冲突。POPL 则导出与不同治疗水平相关的短期和长期结果，并探索 Pareto frontier，以实现有效的权衡。最后，在合成和真实数据集上的实验结果证明了该方法的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02624v2",
      "published_date": "2024-03-05 03:32:02 UTC",
      "updated_date": "2024-03-12 06:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:51:43.955605"
    },
    {
      "arxiv_id": "2403.02622v3",
      "title": "World Models for Autonomous Driving: An Initial Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yanchen Guan",
        "Haicheng Liao",
        "Zhenning Li",
        "Jia Hu",
        "Runze Yuan",
        "Yunjian Li",
        "Guohui Zhang",
        "Chengzhong Xu"
      ],
      "abstract": "In the rapidly evolving landscape of autonomous driving, the capability to\naccurately predict future events and assess their implications is paramount for\nboth safety and efficiency, critically aiding the decision-making process.\nWorld models have emerged as a transformative approach, enabling autonomous\ndriving systems to synthesize and interpret vast amounts of sensor data,\nthereby predicting potential future scenarios and compensating for information\ngaps. This paper provides an initial review of the current state and\nprospective advancements of world models in autonomous driving, spanning their\ntheoretical underpinnings, practical applications, and the ongoing research\nefforts aimed at overcoming existing limitations. Highlighting the significant\nrole of world models in advancing autonomous driving technologies, this survey\naspires to serve as a foundational reference for the research community,\nfacilitating swift access to and comprehension of this burgeoning field, and\ninspiring continued innovation and exploration.",
      "tldr_zh": "这篇论文对自动驾驶领域的世界模型（world models）进行初步调查，强调其在预测未来事件和评估影响方面对安全与效率的关键作用。世界模型通过合成并解释大量传感器数据，帮助自动驾驶系统预测潜在场景并填补信息缺口。论文回顾了世界模型的理论基础、实际应用以及当前研究努力，以克服现有限制，并旨在为研究社区提供基础参考，促进该新兴领域的创新和发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02622v3",
      "published_date": "2024-03-05 03:23:55 UTC",
      "updated_date": "2024-05-07 13:28:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:51:54.602753"
    },
    {
      "arxiv_id": "2403.02616v1",
      "title": "Unsupervised Spatio-Temporal State Estimation for Fine-grained Adaptive Anomaly Diagnosis of Industrial Cyber-physical Systems",
      "title_zh": "无监督时空状态估计用于工业网络物理系统的细粒度自适应",
      "authors": [
        "Haili Sun",
        "Yan Huang",
        "Lansheng Han",
        "Cai Fu",
        "Chunjie Zhou"
      ],
      "abstract": "Accurate detection and diagnosis of abnormal behaviors such as network\nattacks from multivariate time series (MTS) are crucial for ensuring the stable\nand effective operation of industrial cyber-physical systems (CPS). However,\nexisting researches pay little attention to the logical dependencies among\nsystem working states, and have difficulties in explaining the evolution\nmechanisms of abnormal signals. To reveal the spatio-temporal association\nrelationships and evolution mechanisms of the working states of industrial CPS,\nthis paper proposes a fine-grained adaptive anomaly diagnosis method (i.e.\nMAD-Transformer) to identify and diagnose anomalies in MTS. MAD-Transformer\nfirst constructs a temporal state matrix to characterize and estimate the\nchange patterns of the system states in the temporal dimension. Then, to better\nlocate the anomalies, a spatial state matrix is also constructed to capture the\ninter-sensor state correlation relationships within the system. Subsequently,\nbased on these two types of state matrices, a three-branch structure of\nseries-temporal-spatial attention module is designed to simultaneously capture\nthe series, temporal, and space dependencies among MTS. Afterwards, three\nassociated alignment loss functions and a reconstruction loss are constructed\nto jointly optimize the model. Finally, anomalies are determined and diagnosed\nby comparing the residual matrices with the original matrices. We conducted\ncomparative experiments on five publicly datasets spanning three application\ndomains (service monitoring, spatial and earth exploration, and water\ntreatment), along with a petroleum refining simulation dataset collected by\nourselves. The results demonstrate that MAD-Transformer can adaptively detect\nfine-grained anomalies with short duration, and outperforms the\nstate-of-the-art baselines in terms of noise robustness and localization\nperformance.",
      "tldr_zh": "本文提出一种无监督的时空状态估计方法，即 MAD-Transformer，用于工业网络物理系统 (CPS) 的细粒度自适应异常诊断，旨在揭示多变量时间序列 (MTS) 中异常信号的时空关联和演化机制。方法包括构建时间状态矩阵和空间状态矩阵，以捕获系统状态的变化模式和传感器间相关性，并设计三分支系列-时间-空间注意力模块联合优化模型。实验在五个公开数据集和一个自收集石油精炼模拟数据集上验证，MAD-Transformer 显示出优秀的噪声鲁棒性和异常定位性能，显著优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.02616v1",
      "published_date": "2024-03-05 03:11:02 UTC",
      "updated_date": "2024-03-05 03:11:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:52:08.430838"
    },
    {
      "arxiv_id": "2403.02613v1",
      "title": "Large Language Models and Video Games: A Preliminary Scoping Review",
      "title_zh": "翻译失败",
      "authors": [
        "Penny Sweetser"
      ],
      "abstract": "Large language models (LLMs) hold interesting potential for the design,\ndevelopment, and research of video games. Building on the decades of prior\nresearch on generative AI in games, many researchers have sped to investigate\nthe power and potential of LLMs for games. Given the recent spike in\nLLM-related research in games, there is already a wealth of relevant research\nto survey. In order to capture a snapshot of the state of LLM research in\ngames, and to help lay the foundation for future work, we carried out an\ninitial scoping review of relevant papers published so far. In this paper, we\nreview 76 papers published between 2022 to early 2024 on LLMs and video games,\nwith key focus areas in game AI, game development, narrative, and game research\nand reviews. Our paper provides an early state of the field and lays the\ngroundwork for future research and reviews on this topic.",
      "tldr_zh": "这篇论文对 Large Language Models (LLMs) 在视频游戏设计、开发和研究中的潜力进行了初步范围审查 (scoping review)。作者审阅了 2022 年到 2024 年初发布的 76 篇相关论文，重点聚焦于游戏 AI、游戏开发、叙事以及游戏研究和评论等领域。审查结果揭示了 LLMs 在这些领域的应用前景，并为未来研究提供了基础性框架。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2403.02613v1",
      "published_date": "2024-03-05 03:04:35 UTC",
      "updated_date": "2024-03-05 03:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:52:19.332859"
    },
    {
      "arxiv_id": "2403.02611v3",
      "title": "A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuelin Zhang",
        "Pengyu Zheng",
        "Wanquan Yan",
        "Chengyu Fang",
        "Shing Shin Cheng"
      ],
      "abstract": "Defocus blur is a persistent problem in microscope imaging that poses harm to\npathology interpretation and medical intervention in cell microscopy and\nmicroscope surgery. To address this problem, a unified framework including the\nmulti-pyramid transformer (MPT) and extended frequency contrastive\nregularization (EFCR) is proposed to tackle two outstanding challenges in\nmicroscopy deblur: longer attention span and data deficiency. The MPT employs\nan explicit pyramid structure at each network stage that integrates the\ncross-scale window attention (CSWA), the intra-scale channel attention (ISCA),\nand the feature-enhancing feed-forward network (FEFN) to capture long-range\ncross-scale spatial interaction and global channel context. The EFCR addresses\nthe data deficiency problem by exploring latent deblur signals from different\nfrequency bands. It also enables deblur knowledge transfer to learn\ncross-domain information from extra data, improving deblur performance for\nlabeled and unlabeled data. Extensive experiments and downstream task\nvalidation show the framework achieves state-of-the-art performance across\nmultiple datasets. Project page: https://github.com/PieceZhang/MPT-CataBlur.",
      "tldr_zh": "本文提出一个统一框架，结合 Multi-Pyramid Transformer (MPT) 和 Extended Frequency Contrastive Regularization (EFCR)，用于解决显微镜成像中的散焦模糊（defocus blur）问题，提高病理解释和医疗干预的图像质量。MPT 通过显式金字塔结构整合 Cross-Scale Window Attention (CSWA)、Intra-Scale Channel Attention (ISCA) 和 Feature-Enhancing Feed-Forward Network (FEFN)，以捕捉长距离跨尺度空间交互和全局通道上下文。EFCR 则通过探索不同频率带的潜在去模糊信号，解决数据不足问题，并实现去模糊知识转移，提升带标签和无标签数据的性能。实验验证显示，该框架在多个数据集上达到最先进性能，并支持下游任务应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.02611v3",
      "published_date": "2024-03-05 02:59:35 UTC",
      "updated_date": "2024-06-04 02:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:52:32.997706"
    },
    {
      "arxiv_id": "2403.02610v1",
      "title": "ChatGPT4PCG 2 Competition: Prompt Engineering for Science Birds Level Generation",
      "title_zh": "ChatGPT4PCG 2 竞赛：Science Birds 关卡生成的提示工程",
      "authors": [
        "Pittawat Taveekitworachai",
        "Febri Abdullah",
        "Mury F. Dewantoro",
        "Yi Xia",
        "Pratch Suntichaikul",
        "Ruck Thawonmas",
        "Julian Togelius",
        "Jochen Renz"
      ],
      "abstract": "This paper presents the second ChatGPT4PCG competition at the 2024 IEEE\nConference on Games. In this edition of the competition, we follow the first\nedition, but make several improvements and changes. We introduce a new\nevaluation metric along with allowing a more flexible format for participants'\nsubmissions and making several improvements to the evaluation pipeline.\nContinuing from the first edition, we aim to foster and explore the realm of\nprompt engineering (PE) for procedural content generation (PCG). While the\nfirst competition saw success, it was hindered by various limitations; we aim\nto mitigate these limitations in this edition. We introduce diversity as a new\nmetric to discourage submissions aimed at producing repetitive structures.\nFurthermore, we allow submission of a Python program instead of a prompt text\nfile for greater flexibility in implementing advanced PE approaches, which may\nrequire control flow, including conditions and iterations. We also make several\nimprovements to the evaluation pipeline with a better classifier for similarity\nevaluation and better-performing function signatures. We thoroughly evaluate\nthe effectiveness of the new metric and the improved classifier. Additionally,\nwe perform an ablation study to select a function signature to instruct ChatGPT\nfor level generation. Finally, we provide implementation examples of various PE\ntechniques in Python and evaluate their preliminary performance. We hope this\ncompetition serves as a resource and platform for learning about PE and PCG in\ngeneral.",
      "tldr_zh": "这篇论文介绍了第二届 ChatGPT4PCG 比赛，聚焦于 prompt engineering (PE) 在 Science Birds 关卡生成中的应用，旨在通过改进评估指标和流程来提升比赛质量。相比第一届，他们引入了多样性指标以避免生成重复结构、允许参赛者提交 Python 程序实现高级 PE 方法，并优化了评估管道，包括改进的相似性分类器和函数签名。研究团队通过评估新指标的有效性、进行消融研究选择最佳函数签名，并提供各种 PE 技术的 Python 实现示例，最终为 PE 和 procedural content generation (PCG) 的学习与探索提供了一个更完善的平台。",
      "categories": [
        "cs.AI",
        "I.2.7; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02610v1",
      "published_date": "2024-03-05 02:58:57 UTC",
      "updated_date": "2024-03-05 02:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:52:43.926144"
    },
    {
      "arxiv_id": "2403.02607v1",
      "title": "MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Gong",
        "Lvyin Niu",
        "Yang Zhao",
        "Miao Xu",
        "Zhenzhe Zheng",
        "Haoqi Zhang",
        "Zhilin Zhang",
        "Fan Wu",
        "Rongquan Bai",
        "Chuan Yu",
        "Jian Xu",
        "Bo Zheng"
      ],
      "abstract": "Online bidding and auction are crucial aspects of the online advertising\nindustry. Conventionally, there is only one slot for ad display and most\ncurrent studies focus on it. Nowadays, multi-slot display advertising is\ngradually becoming popular where many ads could be displayed in a list and\nshown as a whole to users. However, multi-slot display advertising leads to\ndifferent cost-effectiveness. Advertisers have the incentive to adjust bid\nprices so as to win the most economical ad positions. In this study, we\nintroduce bid shading into multi-slot display advertising for bid price\nadjustment with a Multi-task End-to-end Bid Shading(MEBS) method. We prove the\noptimality of our method theoretically and examine its performance\nexperimentally. Through extensive offline and online experiments, we\ndemonstrate the effectiveness and efficiency of our method, and we obtain a\n7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Investment,\nand a 3.26% lift in ad buy count.",
      "tldr_zh": "本研究针对多槽位显示广告中的成本效益问题，提出MEBS（Multi-task End-to-end Bid Shading）方法，该方法通过多任务端到端框架调整出价，帮助广告商获得最经济的广告位。\nMEBS理论上证明了其优越性，能够有效处理多槽位竞标场景。\n实验结果显示，该方法在离线和在线测试中表现出色，提升了Gross Merchandise Volume 7.01%、Return on Investment 7.42%和ad buy count 3.26%。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02607v1",
      "published_date": "2024-03-05 02:44:58 UTC",
      "updated_date": "2024-03-05 02:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:52:55.512096"
    },
    {
      "arxiv_id": "2403.02589v1",
      "title": "MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Mou Wu",
        "Haibin Liao",
        "Zhengtao Ding",
        "Yonggang Xiao"
      ],
      "abstract": "Gradient-type distributed optimization methods have blossomed into one of the\nmost important tools for solving a minimization learning task over a networked\nagent system. However, only one gradient update per iteration is difficult to\nachieve a substantive acceleration of convergence. In this paper, we propose an\naccelerated framework named as MUSIC allowing each agent to perform multiple\nlocal updates and a single combination in each iteration. More importantly, we\nequip inexact and exact distributed optimization methods into this framework,\nthereby developing two new algorithms that exhibit accelerated linear\nconvergence and high communication efficiency. Our rigorous convergence\nanalysis reveals the sources of steady-state errors arising from inexact\npolicies and offers effective solutions. Numerical results based on synthetic\nand real datasets demonstrate both our theoretical motivations and analysis, as\nwell as performance advantages.",
      "tldr_zh": "本文提出名为 MUSIC 的加速框架，用于分布式优化，每个代理在每个迭代中进行多个本地更新和一个组合，以克服传统梯度型方法仅进行单一更新导致的收敛缓慢问题。该框架整合了 inexact 和 exact distributed optimization 方法，开发了两个新算法，实现加速的线性收敛和高通信效率，并通过严格的收敛分析揭示了 inexact 策略的稳态误差来源及解决方案。数值实验基于合成和真实数据集，验证了理论分析并展示了性能优势。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02589v1",
      "published_date": "2024-03-05 02:02:00 UTC",
      "updated_date": "2024-03-05 02:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:53:08.370446"
    },
    {
      "arxiv_id": "2403.02574v1",
      "title": "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Li",
        "Lu Chen",
        "Aiwei Liu",
        "Kai Yu",
        "Lijie Wen"
      ],
      "abstract": "The literature review is an indispensable step in the research process. It\nprovides the benefit of comprehending the research problem and understanding\nthe current research situation while conducting a comparative analysis of prior\nworks. However, literature summary is challenging and time consuming. The\nprevious LLM-based studies on literature review mainly focused on the complete\nprocess, including literature retrieval, screening, and summarization. However,\nfor the summarization step, simple CoT method often lacks the ability to\nprovide extensive comparative summary. In this work, we firstly focus on the\nindependent literature summarization step and introduce ChatCite, an LLM agent\nwith human workflow guidance for comparative literature summary. This agent, by\nmimicking the human workflow, first extracts key elements from relevant\nliterature and then generates summaries using a Reflective Incremental\nMechanism. In order to better evaluate the quality of the generated summaries,\nwe devised a LLM-based automatic evaluation metric, G-Score, in refer to the\nhuman evaluation criteria. The ChatCite agent outperformed other models in\nvarious dimensions in the experiments. The literature summaries generated by\nChatCite can also be directly used for drafting literature reviews.",
      "tldr_zh": "本研究针对文献综述中总结步骤的挑战，提出ChatCite，这是一个带有人类工作流程指导的LLM Agent，用于生成比较性文献总结。ChatCite通过模仿人类流程，首先从相关文献中提取关键元素，然后利用Reflective Incremental Mechanism生成总结，以克服简单Chain-of-Thought方法在提供全面比较方面的不足。为评估总结质量，研究设计了基于LLM的自动指标G-Score，参考人类评估标准。实验结果显示，ChatCite在多个维度上优于其他模型，其生成的总结可直接用于起草文献综述。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.IR",
      "comment": "18 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.02574v1",
      "published_date": "2024-03-05 01:13:56 UTC",
      "updated_date": "2024-03-05 01:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:53:20.563785"
    },
    {
      "arxiv_id": "2403.02567v2",
      "title": "Eliciting Better Multilingual Structured Reasoning from LLMs through Code",
      "title_zh": "翻译失败",
      "authors": [
        "Bryan Li",
        "Tamer Alkhouli",
        "Daniele Bonadiman",
        "Nikolaos Pappas",
        "Saab Mansour"
      ],
      "abstract": "The development of large language models (LLM) has shown progress on\nreasoning, though studies have largely considered either English or simple\nreasoning tasks. To address this, we introduce a multilingual structured\nreasoning and explanation dataset, termed xSTREET, that covers four tasks\nacross six languages. xSTREET exposes a gap in base LLM performance between\nEnglish and non-English reasoning tasks.\n  We then propose two methods to remedy this gap, building on the insight that\nLLMs trained on code are better reasoners. First, at training time, we augment\na code dataset with multilingual comments using machine translation while\nkeeping program code as-is. Second, at inference time, we bridge the gap\nbetween training and inference by employing a prompt structure that\nincorporates step-by-step code primitives to derive new facts and find a\nsolution. Our methods show improved multilingual performance on xSTREET, most\nnotably on the scientific commonsense reasoning subtask. Furthermore, the\nmodels show no regression on non-reasoning tasks, thus demonstrating our\ntechniques maintain general-purpose abilities.",
      "tldr_zh": "本文引入了 xSTREET 数据集，这是一个覆盖四个任务和六种语言的多语言结构化推理和解释数据集，暴露了基础 LLM 在英语和非英语推理任务之间的性能差距。作者提出两种基于代码的方法来弥补这一差距：一是训练时通过机器翻译为代码数据集添加多语言注释，同时保持程序代码不变；二是推理时使用包含逐步代码原语的提示结构，以推导新事实并解决问题。这些方法显著提升了 xSTREET 上的多语言性能，尤其在科学常识推理子任务上，同时模型在非推理任务上没有退化，保持了通用能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.02567v2",
      "published_date": "2024-03-05 00:48:56 UTC",
      "updated_date": "2024-06-12 07:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T12:53:32.817802"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 113,
  "processed_papers_count": 113,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T12:53:59.335584"
}