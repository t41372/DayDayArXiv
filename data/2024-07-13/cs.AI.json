{
  "date": "2024-07-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-13 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的优化、多模态处理、医疗应用以及材料设计创新，其中 Markus J. Buehler 的 AtomAgents 论文和 Graph Transformers 调查最为令人印象深刻，它们展示了 AI 在材料科学和图神经网络方面的突破性进展。\n\n下面，我将挑选并简要讨论今天的重点论文，先从最具话题度和影响力的 AI 相关文章开始，然后过渡到医疗和材料科学领域。其他较常规或应用性不强的论文（如某些特定数据集实验或小规模优化方法）将快速掠过，以控制篇幅。\n\n### 重点论文讨论\n\n**AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence**  \n（中文标题：通过物理感知的多模态多代理人工智能进行合金设计和发现）  \n这篇由 Markus J. Buehler 等人撰写的论文提出了一种多代理 AI 框架 AtomAgents，用于材料设计。它整合 LLM、物理模拟和数据分析，实现了合金性能预测和优化，显著提升了材料工程效率。该方法在生物医学和可持续能源领域有潜力，核心贡献在于自主协作代理系统，实验证明其在合金特性预测上优于传统模型。\n\n**Bilingual Adaptation of Monolingual Foundation Models**  \n（中文标题：单语基础模型的双语适应）  \n论文探讨了高效地将单语 LLM（如 Llama 2）适配到其他语言（如阿拉伯语）的技术，通过词汇扩展和双语预训练，实现了语言迁移而不丢失原有性能。核心发现是，该方法在保持英语能力的同时显著提升了目标语言表现，为低资源语言的 LLM 开发提供了实用框架。\n\n**Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers**  \n（中文标题：通过广义矩阵混合器实现的双向状态空间模型）  \nTri Dao 和 Albert Gu 参与的这篇工作扩展了状态空间模型（SSM），提出 Hydra 框架，支持双向序列处理。论文的核心在于矩阵混合器的创新设计，提升了模型在非因果任务中的性能（如 NLP 和图像分类），实验显示其作为注意力层的替代方案，在 GLUE 和 ImageNet 上优于 BERT 和 ViT。\n\n**Graph Transformers: A Survey**  \n（中文标题：图变换器：一个调查）  \n这篇全面调查总结了图变换器（Graph Transformers）的进展，包括其架构、注意机制和应用。核心贡献是提出一个分类框架，分析图数据处理效率和表达性，强调了其在节点、边和图级任务中的潜力。该调查为未来图神经网络研究提供了指导，具有广泛影响力。\n\n**IoT-LM: Large Multisensory Language Models for the Internet of Things**  \n（中文标题：物联网的大型多感官语言模型）  \n论文引入 IoT-LM，一种多模态 LLM，用于处理物联网数据（如传感器和图像）。核心发现是通过多感官预训练和数据集 MultiIoT，该模型在设备交互和实时分析中表现出色，适用于智能城市和健康监测，显著提高了传统 IoT 系统的 AI 能力。\n\n**Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation**  \n（中文标题：通过知识库引导生成进行文档级临床实体和关系抽取）  \n这篇医疗 NLP 论文利用 UMLS 知识库增强 GPT 模型的实体抽取能力。核心贡献是改进的提示机制，提升了文档级关系的准确性，实验显示其优于标准 RAG 方法，在医疗领域有实际应用潜力。\n\n**Causality extraction from medical text using Large Language Models (LLMs)**  \n（中文标题：使用大型语言模型从医疗文本中提取因果关系）  \n论文评估 LLM（如 BioBERT 和 GPT-4）在临床指南中的因果关系抽取。核心发现是 BioBERT 的 F1 分数达 0.72，作者还发布了标注数据集，这为医疗决策支持提供了新工具。\n\n其他论文如 Partial-differential-algebraic equations with PINN（涉及物理信息神经网络的框架评估）和 WojoodNER（阿拉伯命名实体识别任务）等，虽然有技术创新，但影响力相对有限，仅快速提及：前者提出 PINN 操作分割方法，提升了非线性动力学求解；后者在细粒度 NER 上取得了 92% 的 F1 分数。\n\n总之，今天的 arXiv 论文突显了 AI 领域的快速演进，LLM 和多代理系统等主题值得关注。明日拭目以待更多突破！",
  "papers": [
    {
      "arxiv_id": "2408.01914v3",
      "title": "Partial-differential-algebraic equations of nonlinear dynamics by Physics-Informed Neural-Network: (I) Operator splitting and framework assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Loc Vu-Quoc",
        "Alexander Humer"
      ],
      "abstract": "Several forms for constructing novel physics-informed neural-networks (PINN)\nfor the solution of partial-differential-algebraic equations based on\nderivative operator splitting are proposed, using the nonlinear Kirchhoff rod\nas a prototype for demonstration. The open-source DeepXDE is likely the most\nwell documented framework with many examples. Yet, we encountered some\npathological problems and proposed novel methods to resolve them. Among these\nnovel methods are the PDE forms, which evolve from the lower-level form with\nfewer unknown dependent variables to higher-level form with more dependent\nvariables, in addition to those from lower-level forms. Traditionally, the\nhighest-level form, the balance-of-momenta form, is the starting point for\n(hand) deriving the lowest-level form through a tedious (and error prone)\nprocess of successive substitutions. The next step in a finite element method\nis to discretize the lowest-level form upon forming a weak form and\nlinearization with appropriate interpolation functions, followed by their\nimplementation in a code and testing. The time-consuming tedium in all of these\nsteps could be bypassed by applying the proposed novel PINN directly to the\nhighest-level form. We developed a script based on JAX. While our JAX script\ndid not show the pathological problems of DDE-T (DDE with TensorFlow backend),\nit is slower than DDE-T. That DDE-T itself being more efficient in higher-level\nform than in lower-level form makes working directly with higher-level form\neven more attractive in addition to the advantages mentioned further above.\nSince coming up with an appropriate learning-rate schedule for a good solution\nis more art than science, we systematically codified in detail our experience\nrunning optimization through a normalization/standardization of the\nnetwork-training process so readers can reproduce our results.",
      "tldr_zh": "本研究提出基于导数算子分裂的新型 Physics-Informed Neural-Network (PINN) 形式，用于解决偏微分代数方程，以非线性 Kirchhoff 杆为例进行演示。论文引入从低级 PDE 形式（较少未知变量）到高级形式（更多变量）的演化方法，允许直接应用于最高级形式（如动量平衡形式），从而绕过传统的手动推导、离散化和实现过程，提高效率。相比传统框架，作者使用 JAX 脚本避免了 DeepXDE 的某些问题，尽管 JAX 速度较慢，但高级形式在 DeepXDE-T 上显示出更高的效率。最终，论文系统化了网络训练过程的标准化，包括学习率调度的详细指导，以便读者复现结果。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA",
        "74-10 (primary), 74H15 (primary), 74K10 (primary), 74B20 (secondary)",
        "I.2.8; I.6.5"
      ],
      "primary_category": "math.NA",
      "comment": "61 pages, 52 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.01914v3",
      "published_date": "2024-07-13 22:48:17 UTC",
      "updated_date": "2024-10-17 22:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:15:58.536515"
    },
    {
      "arxiv_id": "2407.10022v1",
      "title": "AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence",
      "title_zh": "AtomAgents：通过物理感知的多模态多智能体人工智能进行合金设计和发现",
      "authors": [
        "Alireza Ghafarollahi",
        "Markus J. Buehler"
      ],
      "abstract": "The design of alloys is a multi-scale problem that requires a holistic\napproach that involves retrieving relevant knowledge, applying advanced\ncomputational methods, conducting experimental validations, and analyzing the\nresults, a process that is typically reserved for human experts. Machine\nlearning (ML) can help accelerate this process, for instance, through the use\nof deep surrogate models that connect structural features to material\nproperties, or vice versa. However, existing data-driven models often target\nspecific material objectives, offering limited flexibility to integrate\nout-of-domain knowledge and cannot adapt to new, unforeseen challenges. Here,\nwe overcome these limitations by leveraging the distinct capabilities of\nmultiple AI agents that collaborate autonomously within a dynamic environment\nto solve complex materials design tasks. The proposed physics-aware generative\nAI platform, AtomAgents, synergizes the intelligence of large language models\n(LLM) the dynamic collaboration among AI agents with expertise in various\ndomains, including knowledge retrieval, multi-modal data integration,\nphysics-based simulations, and comprehensive results analysis across modalities\nthat includes numerical data and images of physical simulation results. The\nconcerted effort of the multi-agent system allows for addressing complex\nmaterials design problems, as demonstrated by examples that include\nautonomously designing metallic alloys with enhanced properties compared to\ntheir pure counterparts. Our results enable accurate prediction of key\ncharacteristics across alloys and highlight the crucial role of solid solution\nalloying to steer the development of advanced metallic alloys. Our framework\nenhances the efficiency of complex multi-objective design tasks and opens new\navenues in fields such as biomedical materials engineering, renewable energy,\nand environmental sustainability.",
      "tldr_zh": "本文提出 AtomAgents，一种基于 physics-aware 的多模态多代理人工智能框架，用于合金设计和发现，通过整合大型语言模型(LLM)、知识检索、多模态数据整合、物理模拟和结果分析，实现代理间的自主协作。相比传统数据驱动模型，该框架更灵活，能整合外部知识并适应新挑战，如自主设计性能优于纯金属的合金。实验结果显示，AtomAgents 准确预测合金关键特性，并突显固溶合金在材料开发中的重要作用。该方法提升了多目标设计任务的效率，并为生物医学材料工程、renewable energy 和 environmental sustainability 等领域提供新机遇。",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10022v1",
      "published_date": "2024-07-13 22:46:02 UTC",
      "updated_date": "2024-07-13 22:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:16:09.245015"
    },
    {
      "arxiv_id": "2407.10021v1",
      "title": "Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kriti Bhattarai",
        "Inez Y. Oh",
        "Zachary B. Abrams",
        "Albert M. Lai"
      ],
      "abstract": "Generative pre-trained transformer (GPT) models have shown promise in\nclinical entity and relation extraction tasks because of their precise\nextraction and contextual understanding capability. In this work, we further\nleverage the Unified Medical Language System (UMLS) knowledge base to\naccurately identify medical concepts and improve clinical entity and relation\nextraction at the document level. Our framework selects UMLS concepts relevant\nto the text and combines them with prompts to guide language models in\nextracting entities. Our experiments demonstrate that this initial concept\nmapping and the inclusion of these mapped concepts in the prompts improves\nextraction results compared to few-shot extraction tasks on generic language\nmodels that do not leverage UMLS. Further, our results show that this approach\nis more effective than the standard Retrieval Augmented Generation (RAG)\ntechnique, where retrieved data is compared with prompt embeddings to generate\nresults. Overall, we find that integrating UMLS concepts with GPT models\nsignificantly improves entity and relation identification, outperforming the\nbaseline and RAG models. By combining the precise concept mapping capability of\nknowledge-based approaches like UMLS with the contextual understanding\ncapability of GPT, our method highlights the potential of these approaches in\nspecialized domains like healthcare.",
      "tldr_zh": "这篇论文提出了一种基于知识库引导的生成框架，用于文档级别的临床实体和关系提取，旨在利用 Unified Medical Language System (UMLS) 知识库来准确识别医疗概念并提升 GPT 模型的提取性能。框架通过选择与文本相关的 UMLS 概念并将其整合到提示中，引导语言模型进行实体提取，从而比不使用 UMLS 的少样本任务更有效。实验结果表明，该方法优于标准 Retrieval Augmented Generation (RAG) 技术，并在实体和关系识别上显著超越基线模型，展示了知识库与 GPT 结合在医疗等专业领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at Association for Computational Linguistics BioNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.10021v1",
      "published_date": "2024-07-13 22:45:46 UTC",
      "updated_date": "2024-07-13 22:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:16:20.452063"
    },
    {
      "arxiv_id": "2407.10020v1",
      "title": "Causality extraction from medical text using Large Language Models (LLMs)",
      "title_zh": "翻译失败",
      "authors": [
        "Seethalakshmi Gopalakrishnan",
        "Luciana Garbayo",
        "Wlodek Zadrozny"
      ],
      "abstract": "This study explores the potential of natural language models, including large\nlanguage models, to extract causal relations from medical texts, specifically\nfrom Clinical Practice Guidelines (CPGs). The outcomes causality extraction\nfrom Clinical Practice Guidelines for gestational diabetes are presented,\nmarking a first in the field. We report on a set of experiments using variants\nof BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs),\nnamely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better\nthan other models, including the Large Language Models, with an average\nF1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less\nconsistency. We also release the code and an annotated a corpus of causal\nstatements within the Clinical Practice Guidelines for gestational diabetes.",
      "tldr_zh": "本文研究探讨了使用自然语言模型，包括 Large Language Models (LLMs)，从医疗文本特别是 Clinical Practice Guidelines (CPGs) 中提取因果关系，并首次针对妊娠糖尿病 CPGs 进行了相关实验。研究比较了 BERT 变体（如 BioBERT、DistilBERT 和 BERT）以及 GPT-4 和 LLaMA2 的性能，结果显示 BioBERT 以平均 F1-score 0.72 的成绩优于其他模型，而 LLMs 的表现虽相似但一致性较差。该研究还发布了实验代码和一个标注的妊娠糖尿病 CPGs 因果语句语料库，以促进进一步的领域应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10020v1",
      "published_date": "2024-07-13 22:33:29 UTC",
      "updated_date": "2024-07-13 22:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:16:33.129829"
    },
    {
      "arxiv_id": "2407.10016v1",
      "title": "Characterizing Disparity Between Edge Models and High-Accuracy Base Models for Vision Tasks",
      "title_zh": "视觉任务中边缘模型与高精度基础模型之间差异的表征",
      "authors": [
        "Zhenyu Wang",
        "Shahriar Nirjon"
      ],
      "abstract": "Edge devices, with their widely varying capabilities, support a diverse range\nof edge AI models. This raises the question: how does an edge model differ from\na high-accuracy (base) model for the same task? We introduce XDELTA, a novel\nexplainable AI tool that explains differences between a high-accuracy base\nmodel and a computationally efficient but lower-accuracy edge model. To achieve\nthis, we propose a learning-based approach to characterize the model\ndifference, named the DELTA network, which complements the feature\nrepresentation capability of the edge network in a compact form. To construct\nDELTA, we propose a sparsity optimization framework that extracts the essence\nof the base model to ensure compactness and sufficient feature representation\ncapability of DELTA, and implement a negative correlation learning approach to\nensure it complements the edge model. We conduct a comprehensive evaluation to\ntest XDELTA's ability to explain model discrepancies, using over 1.2 million\nimages and 24 models, and assessing real-world deployments with six\nparticipants. XDELTA excels in explaining differences between base and edge\nmodels (arbitrary pairs as well as compressed base models) through geometric\nand concept-level analysis, proving effective in real-world applications.",
      "tldr_zh": "本文探讨了视觉任务中边缘模型与高精度基线模型之间的差异，引入了XDELTA，一种可解释AI工具，用于解释计算高效但精度较低的边缘模型与基线模型的差距。XDELTA基于DELTA网络，通过学习-based approach、稀疏优化框架和负相关学习方法，补充边缘模型的特征表示能力，确保紧凑性。实验评估了超过120万张图像和24个模型的差异，并通过真实世界部署证明XDELTA在几何和概念级分析中表现出色，具有实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10016v1",
      "published_date": "2024-07-13 22:05:58 UTC",
      "updated_date": "2024-07-13 22:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:16:44.476662"
    },
    {
      "arxiv_id": "2407.10005v1",
      "title": "Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond",
      "title_zh": "细粒度分析上下文线性估计：数据、架构以及更多",
      "authors": [
        "Yingcong Li",
        "Ankit Singh Rawat",
        "Samet Oymak"
      ],
      "abstract": "Recent research has shown that Transformers with linear attention are capable\nof in-context learning (ICL) by implementing a linear estimator through\ngradient descent steps. However, the existing results on the optimization\nlandscape apply under stylized settings where task and feature vectors are\nassumed to be IID and the attention weights are fully parameterized. In this\nwork, we develop a stronger characterization of the optimization and\ngeneralization landscape of ICL through contributions on architectures,\nlow-rank parameterization, and correlated designs: (1) We study the landscape\nof 1-layer linear attention and 1-layer H3, a state-space model. Under a\nsuitable correlated design assumption, we prove that both implement 1-step\npreconditioned gradient descent. We show that thanks to its native convolution\nfilters, H3 also has the advantage of implementing sample weighting and\noutperforming linear attention in suitable settings. (2) By studying correlated\ndesigns, we provide new risk bounds for retrieval augmented generation (RAG)\nand task-feature alignment which reveal how ICL sample complexity benefits from\ndistributional alignment. (3) We derive the optimal risk for low-rank\nparameterized attention weights in terms of covariance spectrum. Through this,\nwe also shed light on how LoRA can adapt to a new distribution by capturing the\nshift between task covariances. Experimental results corroborate our\ntheoretical findings. Overall, this work explores the optimization and risk\nlandscape of ICL in practically meaningful settings and contributes to a more\nthorough understanding of its mechanics.",
      "tldr_zh": "本研究对 in-context learning (ICL) 的线性估计进行了细粒度分析，聚焦于数据、架构和相关设计，超越了现有假设（如任务和特征向量的独立同分布）。论文证明，1-layer linear attention 和 1-layer H3 模型在相关设计假设下均能实现 1-step preconditioned gradient descent，其中 H3 通过其卷积过滤器实现样本加权，并在特定场景下优于 linear attention。作者还提供了 retrieval augmented generation (RAG) 和任务-特征对齐的新风险边界，揭示 ICL 的样本复杂度如何从分布对齐中获益，并推导了低秩参数化注意力权重的风险，解释 LoRA 如何通过捕捉任务协方差偏移来适应新分布。实验结果验证了这些理论发现，为理解 ICL 的优化和泛化景观提供了更全面的见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.10005v1",
      "published_date": "2024-07-13 21:13:55 UTC",
      "updated_date": "2024-07-13 21:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:16:58.080169"
    },
    {
      "arxiv_id": "2407.12869v2",
      "title": "Bilingual Adaptation of Monolingual Foundation Models",
      "title_zh": "单语基础模型",
      "authors": [
        "Gurpreet Gosal",
        "Yishi Xu",
        "Gokul Ramakrishnan",
        "Rituraj Joshi",
        "Avraham Sheinin",
        "Zhiming",
        "Chen",
        "Biswajit Mishra",
        "Natalia Vassilieva",
        "Joel Hestness",
        "Neha Sengupta",
        "Sunil Kumar Sahu",
        "Bokang Jia",
        "Onkar Pandit",
        "Satheesh Katipomu",
        "Samta Kamboj",
        "Samujjwal Ghosh",
        "Rahul Pal",
        "Parvez Mullah",
        "Soundar Doraiswamy",
        "Mohamed El Karim Chami",
        "Preslav Nakov"
      ],
      "abstract": "We present an efficient method for adapting a monolingual Large Language\nModel (LLM) to another language, addressing challenges of catastrophic\nforgetting and tokenizer limitations. We focus this study on adapting Llama 2\nto Arabic. Our two-stage approach begins with expanding the vocabulary and\ntraining only the embeddings matrix, followed by full model continual\npre-training on a bilingual corpus. By continually pre-training on a mix of\nArabic and English corpora, the model retains its proficiency in English while\nacquiring capabilities in Arabic. Our approach results in significant\nimprovements in Arabic and slight enhancements in English, demonstrating\ncost-effective cross-lingual transfer. We perform ablations on embedding\ninitialization techniques, data mix ratios, and learning rates and release a\ndetailed training recipe. To demonstrate generalizability of this approach we\nalso adapted Llama 3 8B to Arabic and Llama 2 13B to Hindi.",
      "tldr_zh": "本研究提出了一种高效方法，用于将单语 Large Language Model (LLM) 适配到其他语言，解决灾难性遗忘和分词器限制问题，以 Llama 2 适配阿拉伯语为例。该方法采用两阶段策略：首先扩展词汇表并仅训练嵌入矩阵，其次在双语语料上进行完整模型的 continual pre-training，从而使模型保留英语能力同时显著提升阿拉伯语性能。实验结果显示，该方法在阿拉伯语任务上取得显著改进，英语能力略有增强，并通过消融实验（包括 embedding initialization、data mix ratios 和 learning rates）证明了其成本效益和泛化性，如成功适配 Llama 3 8B 到阿拉伯语和 Llama 2 13B 到印地语。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12869v2",
      "published_date": "2024-07-13 21:09:38 UTC",
      "updated_date": "2024-07-25 22:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:17:10.848907"
    },
    {
      "arxiv_id": "2407.09999v1",
      "title": "Pay Less On Clinical Images: Asymmetric Multi-Modal Fusion Method For Efficient Multi-Label Skin Lesion Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Tang",
        "Tobias Lasser"
      ],
      "abstract": "Existing multi-modal approaches primarily focus on enhancing multi-label skin\nlesion classification performance through advanced fusion modules, often\nneglecting the associated rise in parameters. In clinical settings, both\nclinical and dermoscopy images are captured for diagnosis; however, dermoscopy\nimages exhibit more crucial visual features for multi-label skin lesion\nclassification. Motivated by this observation, we introduce a novel asymmetric\nmulti-modal fusion method in this paper for efficient multi-label skin lesion\nclassification. Our fusion method incorporates two innovative schemes. Firstly,\nwe validate the effectiveness of our asymmetric fusion structure. It employs a\nlight and simple network for clinical images and a heavier, more complex one\nfor dermoscopy images, resulting in significant parameter savings compared to\nthe symmetric fusion structure using two identical networks for both\nmodalities. Secondly, in contrast to previous approaches using mutual attention\nmodules for interaction between image modalities, we propose an asymmetric\nattention module. This module solely leverages clinical image information to\nenhance dermoscopy image features, considering clinical images as supplementary\ninformation in our pipeline. We conduct the extensive experiments on the\nseven-point checklist dataset. Results demonstrate the generality of our\nproposed method for both networks and Transformer structures, showcasing its\nsuperiority over existing methods We will make our code publicly available.",
      "tldr_zh": "本文提出了一种不对称多模态融合方法（asymmetric multi-modal fusion），旨在高效进行多标签皮肤病变分类（multi-label skin lesion classification），通过减少对临床图像的参数开销来解决现有方法的局限性。该方法采用不对称融合结构，使用轻量网络处理临床图像，而为皮镜图像分配更复杂的网络；同时，引入不对称注意力模块（asymmetric attention module），仅利用临床图像作为补充信息来增强皮镜图像特征。在 seven-point checklist 数据集上的广泛实验显示，该方法在网络和 Transformer 结构中均优于现有方法，并显著节省参数，我们将公开代码。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09999v1",
      "published_date": "2024-07-13 20:46:04 UTC",
      "updated_date": "2024-07-13 20:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:17:20.806067"
    },
    {
      "arxiv_id": "2407.09986v1",
      "title": "Curriculum Is More Influential Than Haptic Information During Reinforcement Learning of Object Manipulation Against Gravity",
      "title_zh": "翻译失败",
      "authors": [
        "Pegah Ojaghi",
        "Romina Mir",
        "Ali Marjaninejad",
        "Andrew Erwin",
        "Michael Wehner",
        "Francisco J Valero-Cueva"
      ],
      "abstract": "Learning to lift and rotate objects with the fingertips is necessary for\nautonomous in-hand dexterous manipulation. In our study, we explore the impact\nof various factors on successful learning strategies for this task.\nSpecifically, we investigate the role of curriculum learning and haptic\nfeedback in enabling the learning of dexterous manipulation. Using model-free\nReinforcement Learning, we compare different curricula and two haptic\ninformation modalities (No-tactile vs. 3D-force sensing) for lifting and\nrotating a ball against gravity with a three-fingered simulated robotic hand\nwith no visual input. Note that our best results were obtained when we used a\nnovel curriculum-based learning rate scheduler, which adjusts the\nlinearly-decaying learning rate when the reward is changed as it accelerates\nconvergence to higher rewards. Our findings demonstrate that the choice of\ncurriculum greatly biases the acquisition of different features of dexterous\nmanipulation. Surprisingly, successful learning can be achieved even in the\nabsence of tactile feedback, challenging conventional assumptions about the\nnecessity of haptic information for dexterous manipulation tasks. We\ndemonstrate the generalizability of our results to balls of different weights\nand sizes, underscoring the robustness of our learning approach. This work,\ntherefore, emphasizes the importance of the choice curriculum and challenges\nlong-held notions about the need for tactile information to autonomously learn\nin-hand dexterous manipulation.",
      "tldr_zh": "本研究探讨了在强化学习（Reinforcement Learning）中，课程学习（curriculum learning）与触觉反馈（haptic information）对物体操作（如对抗重力抬起和旋转球体）的影响。研究者使用无模型强化学习比较了不同课程设计和触觉模式（无触觉 vs. 3D-force sensing），并引入了一个新型课程-based 学习率调度器来加速收敛。结果显示，课程选择对灵巧操作特征的获取影响更大，即使没有触觉反馈，机器人手也能成功完成任务，这挑战了触觉信息在自主手部操作中的必要性假设；此外，该方法在不同重量和大小的球体上表现出良好的泛化性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09986v1",
      "published_date": "2024-07-13 19:23:11 UTC",
      "updated_date": "2024-07-13 19:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:17:31.946740"
    },
    {
      "arxiv_id": "2407.09985v2",
      "title": "A Training Data Recipe to Accelerate A* Search with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Devaansh Gupta",
        "Boyang Li"
      ],
      "abstract": "Combining Large Language Models (LLMs) with heuristic search algorithms like\nA* holds the promise of enhanced LLM reasoning and scalable inference. To\naccelerate training and reduce computational demands, we investigate the\ncoreset selection problem for the training data of LLM heuristic learning. Few\nmethods to learn the heuristic functions consider the interaction between the\nsearch algorithm and the machine learning model. In this work, we empirically\ndisentangle the requirements of A* search algorithm from the requirements of\nthe LLM to generalise on this task. Surprisingly, we find an overlap between\ntheir requirements; A* requires more accurate predictions on search nodes near\nthe goal, and LLMs need the same set of nodes for effective generalisation.\nWith these insights, we derive a data-selection distribution for learning\nLLM-based heuristics. On three classical planning domains, maze navigation,\nSokoban and sliding tile puzzles, our technique reduces the number of\niterations required to find the solutions by up to 15x, with a wall-clock\nspeed-up of search up to 5x. The codebase is at\nhttps://github.com/devaansh100/a_star.",
      "tldr_zh": "该研究提出了一种训练数据选择策略，以加速 A* 搜索算法与 Large Language Models (LLMs) 的结合，从而提升 LLM 的推理能力和推理效率。通过实证方法分离 A* 算法对准确预测的需求（尤其在靠近目标的搜索节点）和 LLM 的泛化要求，发现二者存在重叠，从而推导出一套数据选择分布，用于学习基于 LLM 的启发式函数。在迷宫导航、Sokoban 和滑动拼图等三个经典规划领域，实验结果显示，该方法可以将 A* 搜索的迭代次数减少多达 15 倍，并实现高达 5 倍的实际搜索速度提升。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to Findings of EMNLP, 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09985v2",
      "published_date": "2024-07-13 19:21:44 UTC",
      "updated_date": "2024-10-23 22:37:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:17:53.992066"
    },
    {
      "arxiv_id": "2407.09965v1",
      "title": "Learning Online Scale Transformation for Talking Head Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Fa-Ting Hong",
        "Dan Xu"
      ],
      "abstract": "One-shot talking head video generation uses a source image and driving video\nto create a synthetic video where the source person's facial movements imitate\nthose of the driving video. However, differences in scale between the source\nand driving images remain a challenge for face reenactment. Existing methods\nattempt to locate a frame in the driving video that aligns best with the source\nimage, but imprecise alignment can result in suboptimal outcomes.\n  To this end, we introduce a scale transformation module that can\nautomatically adjust the scale of the driving image to fit that of the source\nimage, by using the information of scale difference maintained in the detected\nkeypoints of the source image and the driving frame. Furthermore, to keep\nperceiving the scale information of faces during the generation process, we\nincorporate the scale information learned from the scale transformation module\ninto each layer of the generation process to produce a final result with an\naccurate scale. Our method can perform accurate motion transfer between the two\nimages without any anchor frame, achieved through the contributions of the\nproposed online scale transformation facial reenactment network. Extensive\nexperiments have demonstrated that our proposed method adjusts the scale of the\ndriving face automatically according to the source face, and generates\nhigh-quality faces with an accurate scale in the cross-identity facial\nreenactment.",
      "tldr_zh": "这篇论文针对one-shot talking head video generation中的源图像和驱动视频尺度差异问题，提出了一种在线scale transformation模块，利用源图像和驱动帧的关键points信息自动调整驱动图像的尺度。方法将学到的尺度信息整合到生成过程的每个层中，确保最终结果的尺度准确，从而实现无需锚帧的精确动作转移。实验证明，该方法能自动适应驱动面部的尺度，并在跨身份面部重演中生成高质量的视频。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09965v1",
      "published_date": "2024-07-13 18:08:46 UTC",
      "updated_date": "2024-07-13 18:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:18:06.557992"
    },
    {
      "arxiv_id": "2407.09941v1",
      "title": "Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers",
      "title_zh": "翻译失败",
      "authors": [
        "Sukjun Hwang",
        "Aakash Lahoti",
        "Tri Dao",
        "Albert Gu"
      ],
      "abstract": "A wide array of sequence models are built on a framework modeled after\nTransformers, comprising alternating sequence mixer and channel mixer layers.\nThis paper studies a unifying matrix mixer view of sequence mixers that can be\nconceptualized as a linear map on the input sequence. This framework\nencompasses a broad range of well-known sequence models, including the\nself-attention of Transformers as well as recent strong alternatives such as\nstructured state space models (SSMs), and allows understanding downstream\ncharacteristics such as efficiency and expressivity through properties of their\nstructured matrix class. We identify a key axis of matrix parameterizations\ntermed sequence alignment, which increases the flexibility and performance of\nmatrix mixers, providing insights into the strong performance of Transformers\nand recent SSMs such as Mamba. Furthermore, the matrix mixer framework offers a\nsystematic approach to developing sequence mixers with desired properties,\nallowing us to develop several new sub-quadratic sequence models. In\nparticular, we propose a natural bidirectional extension of the Mamba model\n(Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates\nsuperior performance over other sequence models including Transformers on\nnon-causal tasks. As a drop-in replacement for attention layers, Hydra\noutperforms BERT by 0.8 points on the GLUE benchmark and ViT by 2% Top-1\naccuracy on ImageNet.",
      "tldr_zh": "本论文提出了一种统一的矩阵混合器框架，将序列混合器视为输入序列的线性映射，这涵盖了Transformer的自注意力以及结构化状态空间模型(SSMs)等模型，并通过“sequence alignment”参数化轴来提升其灵活性和性能。该框架揭示了Transformer和Mamba等模型的强大表现，并为开发子二次序列模型提供系统方法。具体地，作者引入了Hydra，一种Mamba的双向扩展，使用准分离矩阵混合器，在非因果任务上超越Transformer等模型。实验结果显示，Hydra作为注意力层的替换，在GLUE基准上比BERT提高0.8点，在ImageNet上比ViT提高2% Top-1准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09941v1",
      "published_date": "2024-07-13 16:34:18 UTC",
      "updated_date": "2024-07-13 16:34:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:18:28.664736"
    },
    {
      "arxiv_id": "2407.09936v1",
      "title": "WojoodNER 2024: The Second Arabic Named Entity Recognition Shared Task",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Jarrar",
        "Nagham Hamad",
        "Mohammed Khalilia",
        "Bashar Talafha",
        "AbdelRahim Elmadany",
        "Muhammad Abdul-Mageed"
      ],
      "abstract": "We present WojoodNER-2024, the second Arabic Named Entity Recognition (NER)\nShared Task. In WojoodNER-2024, we focus on fine-grained Arabic NER. We\nprovided participants with a new Arabic fine-grained NER dataset called\nwojoodfine, annotated with subtypes of entities. WojoodNER-2024 encompassed\nthree subtasks: (i) Closed-Track Flat Fine-Grained NER, (ii) Closed-Track\nNested Fine-Grained NER, and (iii) an Open-Track NER for the Israeli War on\nGaza. A total of 43 unique teams registered for this shared task. Five teams\nparticipated in the Flat Fine-Grained Subtask, among which two teams tackled\nthe Nested Fine-Grained Subtask and one team participated in the Open-Track NER\nSubtask. The winning teams achieved F-1 scores of 91% and 92% in the Flat\nFine-Grained and Nested Fine-Grained Subtasks, respectively. The sole team in\nthe Open-Track Subtask achieved an F-1 score of 73.7%.",
      "tldr_zh": "WojoodNER 2024 是第二次阿拉伯 Named Entity Recognition (NER) 共享任务，专注于细粒度阿拉伯 NER，并提供了新的数据集 wojoodfine，该数据集标注了实体子类型。任务包括三个子任务：(i) 封闭轨道平坦细粒度 NER、(ii) 封闭轨道嵌套细粒度 NER，以及(iii) 开放轨道 NER（针对以色列对加沙的战争）。共有43个团队注册，其中5个团队参与平坦细粒度子任务，获胜团队分别在平坦和嵌套细粒度子任务中取得91%和92%的 F-1 分数，而开放轨道子任务的唯一团队达到了73.7%的 F-1 分数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09936v1",
      "published_date": "2024-07-13 16:17:08 UTC",
      "updated_date": "2024-07-13 16:17:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:18:30.366124"
    },
    {
      "arxiv_id": "2407.09930v2",
      "title": "Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application",
      "title_zh": "评估不同量子核对支持向量机算法分类性能的影响：医疗数据集应用",
      "authors": [
        "Emine Akpinar",
        "Sardar M. N. Islam",
        "Murat Oduncuoglu"
      ],
      "abstract": "The support vector machine algorithm with a quantum kernel estimator\n(QSVM-Kernel), as a leading example of a quantum machine learning technique,\nhas undergone significant advancements. Nevertheless, its integration with\nclassical data presents unique challenges. While quantum computers primarily\ninteract with data in quantum states, embedding classical data into quantum\nstates using feature mapping techniques is essential for leveraging quantum\nalgorithms Despite the recognized importance of feature mapping, its specific\nimpact on data classification outcomes remains largely unexplored. This study\naddresses this gap by comprehensively assessing the effects of various feature\nmapping methods on classification results, taking medical data analysis as a\ncase study. In this study, the QSVM-Kernel method was applied to classification\nproblems in two different and publicly available medical datasets, namely, the\nWisconsin Breast Cancer (original) and The Cancer Genome Atlas (TCGA) Glioma\ndatasets. In the QSVM-Kernel algorithm, quantum kernel matrices obtained from 9\ndifferent quantum feature maps were used. Thus, the effects of these quantum\nfeature maps on the classification results of the QSVM-Kernel algorithm were\nexamined in terms of both classifier performance and total execution time. As a\nresult, in the Wisconsin Breast Cancer (original) and TCGA Glioma datasets,\nwhen Rx and Ry rotational gates were used, respectively, as feature maps in the\nQSVM-Kernel algorithm, the best classification performances were achieved both\nin terms of classification performance and total execution time. The\ncontributions of this study are that (1) it highlights the significant impact\nof feature mapping techniques on medical data classification outcomes using the\nQSVM-Kernel algorithm, and (2) it also guides undertaking research for improved\nQSVM classification performance.",
      "tldr_zh": "本研究评估了不同量子内核对支持向量机（Support Vector Machine）算法分类性能的影响，以医疗数据集为应用案例。研究使用 QSVM-Kernel 算法在 Wisconsin Breast Cancer 和 TCGA Glioma 两个公开数据集上测试了9种量子特征映射，分析了分类性能和总执行时间的影响。结果显示，使用 Rx 和 Ry 旋转门作为特征映射时，分别在两个数据集上取得了最佳分类性能和效率。该研究的主要贡献在于突出了量子特征映射对医疗数据分类结果的关键作用，并为提升 QSVM-Kernel 算法性能提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.09930v2",
      "published_date": "2024-07-13 15:53:37 UTC",
      "updated_date": "2024-07-19 10:37:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:18:42.152216"
    },
    {
      "arxiv_id": "2407.09926v1",
      "title": "Metric Learning for Clifford Group Equivariant Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Ali",
        "Paulina Kulytė",
        "Haitz Sáez de Ocáriz Borde",
        "Pietro Liò"
      ],
      "abstract": "Clifford Group Equivariant Neural Networks (CGENNs) leverage Clifford\nalgebras and multivectors as an alternative approach to incorporating group\nequivariance to ensure symmetry constraints in neural representations. In\nprinciple, this formulation generalizes to orthogonal groups and preserves\nequivariance regardless of the metric signature. However, previous works have\nrestricted internal network representations to Euclidean or Minkowski\n(pseudo-)metrics, handpicked depending on the problem at hand. In this work, we\npropose an alternative method that enables the metric to be learned in a\ndata-driven fashion, allowing the CGENN network to learn more flexible\nrepresentations. Specifically, we populate metric matrices fully, ensuring they\nare symmetric by construction, and leverage eigenvalue decomposition to\nintegrate this additional learnable component into the original CGENN\nformulation in a principled manner. Additionally, we motivate our method using\ninsights from category theory, which enables us to explain Clifford algebras as\na categorical construction and guarantee the mathematical soundness of our\napproach. We validate our method in various tasks and showcase the advantages\nof learning more flexible latent metric representations. The code and data are\navailable at https://github.com/rick-ali/Metric-Learning-for-CGENNs",
      "tldr_zh": "本研究针对Clifford Group Equivariant Neural Networks (CGENNs)提出了一种度量学习方法，允许网络在数据驱动方式下学习度量矩阵，从而实现更灵活的神经表示，避免了先前依赖固定Euclidean或Minkowski度量的问题。方法通过填充对称度量矩阵并利用特征值分解(eigenvalue decomposition)将其整合到CGENNs框架中，同时从范畴论(category theory)的视角解释Clifford代数，确保数学严谨性。在多种任务中验证后，该方法展示了学习更灵活的潜在度量表示的优势，提高了网络的适应性和性能。代码和数据可从指定仓库获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Workshop on Geometry-grounded Representation Learning and Generative\n  Modeling (GRaM) at the ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09926v1",
      "published_date": "2024-07-13 15:41:14 UTC",
      "updated_date": "2024-07-13 15:41:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:18:53.696887"
    },
    {
      "arxiv_id": "2407.21024v2",
      "title": "An Autonomous GIS Agent Framework for Geospatial Data Retrieval",
      "title_zh": "自主 GIS 代理框架用于地理空间数据检索",
      "authors": [
        "Huan Ning",
        "Zhenlong Li",
        "Temitope Akinboyewa",
        "M. Naser Lessani"
      ],
      "abstract": "Powered by the emerging large language models (LLMs), autonomous geographic\ninformation systems (GIS) agents have the potential to accomplish spatial\nanalyses and cartographic tasks. However, a research gap exists to support\nfully autonomous GIS agents: how to enable agents to discover and download the\nnecessary data for geospatial analyses. This study proposes an autonomous GIS\nagent framework capable of retrieving required geospatial data by generating,\nexecuting, and debugging programs. The framework utilizes the LLM as the\ndecision-maker, selects the appropriate data source (s) from a pre-defined\nsource list, and fetches the data from the chosen source. Each data source has\na handbook that records the metadata and technical details for data retrieval.\nThe proposed framework is designed in a plug-and-play style to ensure\nflexibility and extensibility. Human users or autonomous data scrawlers can add\nnew data sources by adding new handbooks. We developed a prototype agent based\non the framework, released as a QGIS plugin (GeoData Retrieve Agent) and a\nPython program. Experiment results demonstrate its capability of retrieving\ndata from various sources including OpenStreetMap, administrative boundaries\nand demographic data from the US Census Bureau, satellite basemaps from ESRI\nWorld Imagery, global digital elevation model (DEM) from OpenTopography.org,\nweather data from a commercial provider, the COVID-19 cases from the NYTimes\nGitHub. Our study is among the first attempts to develop an autonomous\ngeospatial data retrieval agent.",
      "tldr_zh": "本研究提出了一种自主 GIS 代理框架，利用大型语言模型 (LLMs) 实现地理空间数据的检索，填补了现有系统在数据发现和下载方面的研究空白。该框架以 LLM 作为决策者，通过生成、执行和调试程序，从预定义的数据源列表中选择并获取所需数据，每个来源配有记录元数据和技术的手册，并支持即插即用式扩展。实验结果显示，该框架能从多种来源（如 OpenStreetMap、US Census Bureau 和 ESRI World Imagery）成功检索数据，并已作为 QGIS 插件和 Python 程序发布，为自主地理空间分析奠定了基础。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.ET"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21024v2",
      "published_date": "2024-07-13 14:23:57 UTC",
      "updated_date": "2024-08-08 15:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:19:17.198181"
    },
    {
      "arxiv_id": "2407.09894v1",
      "title": "Transferring Structure Knowledge: A New Task to Fake news Detection Towards Cold-Start Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Lingwei Wei",
        "Dou Hu",
        "Wei Zhou",
        "Songlin Hu"
      ],
      "abstract": "Many fake news detection studies have achieved promising performance by\nextracting effective semantic and structure features from both content and\npropagation trees. However, it is challenging to apply them to practical\nsituations, especially when using the trained propagation-based models to\ndetect news with no propagation data. Towards this scenario, we study a new\ntask named cold-start fake news detection, which aims to detect content-only\nsamples with missing propagation. To achieve the task, we design a simple but\neffective Structure Adversarial Net (SAN) framework to learn transferable\nfeatures from available propagation to boost the detection of content-only\nsamples. SAN introduces a structure discriminator to estimate dissimilarities\namong learned features with and without propagation, and further learns\nstructure-invariant features to enhance the generalization of existing\npropagation-based methods for content-only samples. We conduct qualitative and\nquantitative experiments on three datasets. Results show the challenge of the\nnew task and the effectiveness of our SAN framework.",
      "tldr_zh": "该研究针对假新闻检测中的冷启动问题（cold-start fake news detection），提出一个新任务，即在缺少传播数据的情况下，仅基于内容样本进行检测，以解决现有方法依赖传播树的局限性。主要贡献是设计了Structure Adversarial Net (SAN)框架，通过结构鉴别器（structure discriminator）学习可转移的结构知识，实现从有传播数据的样本向内容-only样本的特征迁移，从而提升检测性能。在三个数据集上的实验结果证明了这一任务的挑战性，并验证了SAN框架的有效性。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SI",
      "comment": "ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09894v1",
      "published_date": "2024-07-13 14:04:55 UTC",
      "updated_date": "2024-07-13 14:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:19:17.353950"
    },
    {
      "arxiv_id": "2407.11082v1",
      "title": "Imbalanced Graph-Level Anomaly Detection via Counterfactual Augmentation and Feature Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zitong Wang",
        "Xuexiong Luo",
        "Enfeng Song",
        "Qiuqing Bai",
        "Fu Lin"
      ],
      "abstract": "Graph-level anomaly detection (GLAD) has already gained significant\nimportance and has become a popular field of study, attracting considerable\nattention across numerous downstream works. The core focus of this domain is to\ncapture and highlight the anomalous information within given graph datasets. In\nmost existing studies, anomalies are often the instances of few. The stark\nimbalance misleads current GLAD methods to focus on learning the patterns of\nnormal graphs more, further impacting anomaly detection performance. Moreover,\nexisting methods predominantly utilize the inherent features of nodes to\nidentify anomalous graph patterns which is approved suboptimal according to our\nexperiments. In this work, we propose an imbalanced GLAD method via\ncounterfactual augmentation and feature learning. Specifically, we first\nconstruct anomalous samples based on counterfactual learning, aiming to expand\nand balance the datasets. Additionally, we construct a module based on Graph\nNeural Networks (GNNs), which allows us to utilize degree attributes to\ncomplement the inherent attribute features of nodes. Then, we design an\nadaptive weight learning module to integrate features tailored to different\ndatasets effectively to avoid indiscriminately treating all features as\nequivalent. Furthermore, extensive baseline experiments conducted on public\ndatasets substantiate the robustness and effectiveness. Besides, we apply the\nmodel to brain disease datasets, which can prove the generalization capability\nof our work. The source code of our work is available online.",
      "tldr_zh": "本论文针对图级异常检测（Graph-Level Anomaly Detection, GLAD）中的数据不平衡问题，提出了一种结合反事实增强（Counterfactual Augmentation）和特征学习的方法，以改善现有模型对异常图模式的识别。方法首先通过反事实学习生成额外的异常样本来扩展并平衡数据集，然后利用基于Graph Neural Networks (GNNs)的模块整合节点固有特征和度属性，并设计自适应权重学习模块来有效融合不同数据集的特征。实验结果显示，该方法在公共数据集上表现出色，提高了检测性能，并在脑部疾病数据集上的应用证明了其鲁棒性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures, SSDBM2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11082v1",
      "published_date": "2024-07-13 13:40:06 UTC",
      "updated_date": "2024-07-13 13:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:19:30.951061"
    },
    {
      "arxiv_id": "2407.09888v1",
      "title": "FarFetched: Entity-centric Reasoning and Claim Validation for the Greek Language based on Textually Represented Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitris Papadopoulos",
        "Katerina Metropoulou",
        "Nikolaos Matsatsinis",
        "Nikolaos Papadakis"
      ],
      "abstract": "Our collective attention span is shortened by the flood of online\ninformation. With \\textit{FarFetched}, we address the need for automated claim\nvalidation based on the aggregated evidence derived from multiple online news\nsources. We introduce an entity-centric reasoning framework in which latent\nconnections between events, actions, or statements are revealed via entity\nmentions and represented in a graph database. Using entity linking and semantic\nsimilarity, we offer a way for collecting and combining information from\ndiverse sources in order to generate evidence relevant to the user's claim.\nThen, we leverage textual entailment recognition to quantitatively determine\nwhether this assertion is credible, based on the created evidence. Our approach\ntries to fill the gap in automated claim validation for less-resourced\nlanguages and is showcased on the Greek language, complemented by the training\nof relevant semantic textual similarity (STS) and natural language inference\n(NLI) models that are evaluated on translated versions of common benchmarks.",
      "tldr_zh": "本研究提出FarFetched框架，通过entity-centric reasoning进行基于文本环境的声明验证，旨在解决在线信息泛滥导致的注意力分散问题，特别是针对希腊语等资源较少语言。该框架利用实体链接和语义相似性从多个新闻来源收集证据，并在图数据库中揭示事件间的潜在连接，然后通过textual entailment recognition定量评估声明的可信度。作为主要贡献，该方法填补了自动化声明验证的空白，并训练了STS和NLI模型，在翻译的基准上进行了评估，展示了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "DeepLo NAACL 2022",
      "pdf_url": "http://arxiv.org/pdf/2407.09888v1",
      "published_date": "2024-07-13 13:30:20 UTC",
      "updated_date": "2024-07-13 13:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:19:42.741394"
    },
    {
      "arxiv_id": "2407.09874v1",
      "title": "SeFi-CD: A Semantic First Change Detection Paradigm That Can Detect Any Change You Want",
      "title_zh": "SeFi-CD：一种语义优先变更检测范",
      "authors": [
        "Ling Zhao",
        "Zhenyang Huang",
        "Dongsheng Kuang",
        "Chengli Peng",
        "Jun Gan",
        "Haifeng Li"
      ],
      "abstract": "The existing change detection(CD) methods can be summarized as the\nvisual-first change detection (ViFi-CD) paradigm, which first extracts change\nfeatures from visual differences and then assigns them specific semantic\ninformation. However, CD is essentially dependent on change regions of interest\n(CRoIs), meaning that the CD results are directly determined by the semantics\nchanges of interest, making its primary image factor semantic of interest\nrather than visual. The ViFi-CD paradigm can only assign specific semantics of\ninterest to specific change features extracted from visual differences, leading\nto the inevitable omission of potential CRoIs and the inability to adapt to\ndifferent CRoI CD tasks. In other words, changes in other CRoIs cannot be\ndetected by the ViFi-CD method without retraining the model or significantly\nmodifying the method. This paper introduces a new CD paradigm, the\nsemantic-first CD (SeFi-CD) paradigm. The core idea of SeFi-CD is to first\nperceive the dynamic semantics of interest and then visually search for change\nfeatures related to the semantics. Based on the SeFi-CD paradigm, we designed\nAnything You Want Change Detection (AUWCD). Experiments on public datasets\ndemonstrate that the AUWCD outperforms the current state-of-the-art CD methods,\nachieving an average F1 score 5.01\\% higher than that of these advanced\nsupervised baselines on the SECOND dataset, with a maximum increase of 13.17\\%.\nThe proposed SeFi-CD offers a novel CD perspective and approach.",
      "tldr_zh": "本研究指出，现有的视觉优先变化检测（ViFi-CD）范式先提取视觉差异特征再赋予语义信息，但这会导致潜在变化区域（CRoIs）的遗漏，无法适应不同任务，且需重新训练模型。针对这一问题，提出语义优先变化检测（SeFi-CD）范式，该范式先感知感兴趣的动态语义，然后搜索相关的视觉变化特征，从而实现灵活检测任何用户指定的CRoIs。基于SeFi-CD，设计了Anything You Want Change Detection (AUWCD)方法，并在公共数据集上实验证明其优于现有最先进方法，在SECOND数据集上F1分数平均提高5.01%，最高达13.17%。这项工作为变化检测提供了新的视角和方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09874v1",
      "published_date": "2024-07-13 12:49:58 UTC",
      "updated_date": "2024-07-13 12:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:19:53.867952"
    },
    {
      "arxiv_id": "2407.09873v1",
      "title": "Resource Management for Low-latency Cooperative Fine-tuning of Foundation Models at the Network Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Hai Wu",
        "Xu Chen",
        "Kaibin Huang"
      ],
      "abstract": "The emergence of large-scale foundation models (FoMo's) that can perform\nhuman-like intelligence motivates their deployment at the network edge for\ndevices to access state-of-the-art artificial intelligence. For better user\nexperiences, the pre-trained FoMo's need to be adapted to specialized\ndownstream tasks through fine-tuning techniques. To transcend a single device's\nmemory and computation limitations, we advocate multi-device cooperation within\nthe device-edge cooperative fine-tuning (DEFT) paradigm, where edge devices\ncooperate to simultaneously optimize different parts of fine-tuning parameters\nwithin a FoMo. However, the parameter blocks reside at different depths within\na FoMo architecture, leading to varied computation latency-and-memory cost due\nto gradient backpropagation-based calculations. The heterogeneous on-device\ncomputation and memory capacities and channel conditions necessitate an\nintegrated communication-and-computation allocation of local computation loads\nand communication resources to achieve low-latency (LoLa) DEFT. To this end, we\nconsider the depth-ware DEFT block allocation problem. The involved optimal\nblock-device matching is tackled by the proposed low-complexity\nCutting-RecoUNting-CHecking (CRUNCH) algorithm, which is designed by exploiting\nthe monotone-increasing property between block depth and computation\nlatency-and-memory cost. Next, the joint bandwidth-and-block allocation makes\nthe problem more sophisticated. We observe a splittable Lagrangian expression\nthrough the transformation and analysis of the original problem, where the\nvariables indicating device involvement are introduced. Then, the dual ascent\nmethod is employed to tackle this problem iteratively. Through extensive\nexperiments conducted on the GLUE benchmark, our results demonstrate\nsignificant latency reduction achievable by LoLa DEFT for fine-tuning a RoBERTa\nmodel.",
      "tldr_zh": "该论文探讨了在网络边缘部署基础模型 (FoMos) 的资源管理问题，旨在通过设备间合作 fine-tuning 实现低延迟 (LoLa) 处理。作者提出 DEFT 范式，让多个设备同时优化模型不同参数块，并针对块深度导致的计算延迟和内存成本差异，设计了 CRUNCH 算法进行块-设备匹配，以及对偶上升方法优化带宽和块分配。实验在 GLUE 基准上对 RoBERTa 模型进行 fine-tuning，结果显示 LoLa DEFT 显著降低了延迟，提高了整体效率。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2407.09873v1",
      "published_date": "2024-07-13 12:47:14 UTC",
      "updated_date": "2024-07-13 12:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:20:06.653845"
    },
    {
      "arxiv_id": "2407.11081v1",
      "title": "Generating In-store Customer Journeys from Scratch with GPT Architectures",
      "title_zh": "基于 GPT 架构从零开始生成店内客户旅程",
      "authors": [
        "Taizo Horikomi",
        "Takayuki Mizuno"
      ],
      "abstract": "We propose a method that can generate customer trajectories and purchasing\nbehaviors in retail stores simultaneously using Transformer-based deep learning\nstructure. Utilizing customer trajectory data, layout diagrams, and retail\nscanner data obtained from a retail store, we trained a GPT-2 architecture from\nscratch to generate indoor trajectories and purchase actions. Additionally, we\nexplored the effectiveness of fine-tuning the pre-trained model with data from\nanother store. Results demonstrate that our method reproduces in-store\ntrajectories and purchase behaviors more accurately than LSTM and SVM models,\nwith fine-tuning significantly reducing the required training data.",
      "tldr_zh": "本研究提出了一种基于 Transformer 的方法，使用 GPT-2 架构从零开始生成零售店的顾客轨迹和购买行为，结合顾客轨迹数据、布局图以及零售扫描器数据进行训练。该方法能够同时模拟室内轨迹和购买动作，并在与 LSTM 和 SVM 模型的比较中表现出更高的准确性。此外，通过微调预训练模型，显著减少了所需的训练数据，为零售场景模拟提供了更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11081v1",
      "published_date": "2024-07-13 12:35:52 UTC",
      "updated_date": "2024-07-13 12:35:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:20:17.873894"
    },
    {
      "arxiv_id": "2407.09861v3",
      "title": "Towards Systematic Monolingual NLP Surveys: GenA of Greek NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Juli Bakagianni",
        "Kanella Pouli",
        "Maria Gavriilidou",
        "John Pavlopoulos"
      ],
      "abstract": "Natural Language Processing (NLP) research has traditionally been\npredominantly focused on English, driven by the availability of resources, the\nsize of the research community, and market demands. Recently, there has been a\nnoticeable shift towards multilingualism in NLP, recognizing the need for\ninclusivity and effectiveness across diverse languages and cultures.\nMonolingual surveys have the potential to complement the broader trend towards\nmultilingualism in NLP by providing foundational insights and resources,\nnecessary for effectively addressing the linguistic diversity of global\ncommunication. However, monolingual NLP surveys are extremely rare in the\nliterature. This study introduces a generalizable methodology for creating\nsystematic and comprehensive monolingual NLP surveys, aimed at optimizing the\nprocess of constructing such surveys and thoroughly addressing a language's NLP\nsupport. Our approach integrates a structured search protocol to avoid\nselection bias and ensure reproducibility, an NLP task taxonomy to organize the\nsurveyed material coherently, and language resources (LRs) taxonomies to\nidentify potential benchmarks and highlight opportunities for improving\nresource availability (e.g., through better maintenance or licensing). We apply\nthis methodology to Greek NLP (2012-2023), providing a comprehensive overview\nof its current state and challenges. We discuss the progress of Greek NLP and\noutline the Greek LRs found, classified by availability and usability,\nassessing language support per NLP task. The presented systematic literature\nreview of Greek NLP serves as an application of our method that showcases the\nbenefits of monolingual NLP surveys more broadly. Similar applications could be\nconsidered for the myriads of languages whose progress in NLP lags behind that\nof well-supported languages.",
      "tldr_zh": "该研究探讨了自然语言处理(NLP)领域的单语种调查，旨在弥补现有文献的不足，并提出一种可泛化的方法来创建系统化和全面的单语种NLP调查。该方法整合了结构化搜索协议（以避免选择偏差并确保可重复性）、NLP任务分类法和语言资源(LRs)分类法，以组织材料并识别基准，同时突出资源改进机会（如维护或许可）。作者将此方法应用于希腊NLP（2012-2023），提供了希腊NLP的全面概述，包括进展、挑战和按可用性分类的语言资源支持评估。最终，该研究展示了单语种调查的益处，并建议类似方法可扩展到其他NLP落后语言，以促进全球语言多样性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "77 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.09861v3",
      "published_date": "2024-07-13 12:01:52 UTC",
      "updated_date": "2025-01-31 16:28:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:20:30.301097"
    },
    {
      "arxiv_id": "2407.09855v1",
      "title": "Building pre-train LLM Dataset for the INDIC Languages: a case study on Hindi",
      "title_zh": "翻译失败",
      "authors": [
        "Shantipriya Parida",
        "Shakshi Panwar",
        "Kusum Lata",
        "Sanskruti Mishra",
        "Sambit Sekhar"
      ],
      "abstract": "Large language models (LLMs) demonstrated transformative capabilities in many\napplications that require automatically generating responses based on human\ninstruction. However, the major challenge for building LLMs, particularly in\nIndic languages, is the availability of high-quality data for building\nfoundation LLMs. In this paper, we are proposing a large pre-train dataset in\nHindi useful for the Indic language Hindi. We have collected the data span\nacross several domains including major dialects in Hindi. The dataset contains\n1.28 billion Hindi tokens. We have explained our pipeline including data\ncollection, pre-processing, and availability for LLM pre-training. The proposed\napproach can be easily extended to other Indic and low-resource languages and\nwill be available freely for LLM pre-training and LLM research purposes.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在 Indic 语言（如印地语）中缺乏高质量预训练数据的问题，提出一个针对印地语的预训练数据集案例研究。数据集包含 1.28 亿标记，覆盖多个领域和主要方言，通过数据收集和预处理管道构建而成。该数据集免费提供，用于 LLM 预训练和研究，并可轻松扩展到其他 Indic 和低资源语言，从而促进这些语言的模型发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a book chapter in the book Title \"APPLIED SPEECH AND TEXT\n  PROCESSING FOR LOW RESOURCE LANGUAGES\"",
      "pdf_url": "http://arxiv.org/pdf/2407.09855v1",
      "published_date": "2024-07-13 11:29:20 UTC",
      "updated_date": "2024-07-13 11:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:20:45.558378"
    },
    {
      "arxiv_id": "2407.09828v1",
      "title": "Enhancing Semantic Segmentation with Adaptive Focal Loss: A Novel Approach",
      "title_zh": "使用自适应焦点损失增强语义分割：一种新颖方法",
      "authors": [
        "Md Rakibul Islam",
        "Riad Hassan",
        "Abdullah Nazib",
        "Kien Nguyen",
        "Clinton Fookes",
        "Md Zahidul Islam"
      ],
      "abstract": "Deep learning has achieved outstanding accuracy in medical image\nsegmentation, particularly for objects like organs or tumors with smooth\nboundaries or large sizes. Whereas, it encounters significant difficulties with\nobjects that have zigzag boundaries or are small in size, leading to a notable\ndecrease in segmentation effectiveness. In this context, using a loss function\nthat incorporates smoothness and volume information into a model's predictions\noffers a promising solution to these shortcomings. In this work, we introduce\nan Adaptive Focal Loss (A-FL) function designed to mitigate class imbalance by\ndown-weighting the loss for easy examples that results in up-weighting the loss\nfor hard examples and giving greater emphasis to challenging examples, such as\nsmall and irregularly shaped objects. The proposed A-FL involves dynamically\nadjusting a focusing parameter based on an object's surface smoothness, size\ninformation, and adjusting the class balancing parameter based on the ratio of\ntargeted area to total area in an image. We evaluated the performance of the\nA-FL using ResNet50-encoded U-Net architecture on the Picai 2022 and BraTS 2018\ndatasets. On the Picai 2022 dataset, the A-FL achieved an Intersection over\nUnion (IoU) of 0.696 and a Dice Similarity Coefficient (DSC) of 0.769,\noutperforming the regular Focal Loss (FL) by 5.5% and 5.4% respectively. It\nalso surpassed the best baseline Dice-Focal by 2.0% and 1.2%. On the BraTS 2018\ndataset, A-FL achieved an IoU of 0.883 and a DSC of 0.931. The comparative\nstudies show that the proposed A-FL function surpasses conventional methods,\nincluding Dice Loss, Focal Loss, and their hybrid variants, in IoU, DSC,\nSensitivity, and Specificity metrics. This work highlights A-FL's potential to\nimprove deep learning models for segmenting clinically significant regions in\nmedical images, leading to more precise and reliable diagnostic tools.",
      "tldr_zh": "本文提出了一种新的 Adaptive Focal Loss (A-FL) 函数，用于提升语义分割性能，特别是针对医疗图像中边界不规则或小尺寸物体（如器官或肿瘤）的分割挑战。A-FL 通过动态调整聚焦参数（基于物体的表面光滑度和大小信息）以及类平衡参数（根据目标区域与总区域比例），来减轻类不平衡问题，从而加强对困难样本的权重。实验在 ResNet50-encoded U-Net 架构上，使用 Picai 2022 和 BraTS 2018 数据集进行评估，结果显示 A-FL 在 Intersection over Union (IoU) 和 Dice Similarity Coefficient (DSC) 等指标上优于传统 Focal Loss 和 Dice Loss，分别在 Picai 2022 上提升了 5.5% 和 5.4%。这项创新有助于提高医疗图像分割的精确性和可靠性，为临床诊断工具提供更有效的支持。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09828v1",
      "published_date": "2024-07-13 09:41:20 UTC",
      "updated_date": "2024-07-13 09:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:20:56.459551"
    },
    {
      "arxiv_id": "2407.09823v2",
      "title": "NativQA: Multilingual Culturally-Aligned Natural Query for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Arid Hasan",
        "Maram Hasanain",
        "Fatema Ahmad",
        "Sahinur Rahman Laskar",
        "Sunaya Upadhyay",
        "Vrunda N Sukhadia",
        "Mucahid Kutlu",
        "Shammur Absar Chowdhury",
        "Firoj Alam"
      ],
      "abstract": "Natural Question Answering (QA) datasets play a crucial role in evaluating\nthe capabilities of large language models (LLMs), ensuring their effectiveness\nin real-world applications. Despite the numerous QA datasets that have been\ndeveloped, there is a notable lack of region-specific datasets generated by\nnative users in their own languages. This gap hinders the effective\nbenchmarking of LLMs for regional and cultural specificities. Furthermore, it\nalso limits the development of fine-tuned models. In this study, we propose a\nscalable, language-independent framework, NativQA, to seamlessly construct\nculturally and regionally aligned QA datasets in native languages, for LLM\nevaluation and tuning. We demonstrate the efficacy of the proposed framework by\ndesigning a multilingual natural QA dataset, \\mnqa, consisting of ~64k manually\nannotated QA pairs in seven languages, ranging from high to extremely low\nresource, based on queries from native speakers from 9 regions covering 18\ntopics. We benchmark open- and closed-source LLMs with the MultiNativQA\ndataset. We also showcase the framework efficacy in constructing fine-tuning\ndata especially for low-resource and dialectally-rich languages. We made both\nthe framework NativQA and MultiNativQA dataset publicly available for the\ncommunity (https://nativqa.gitlab.io).",
      "tldr_zh": "该论文提出 NativQA 框架，这是一个可扩展的、语言无关的系统，用于构建多语言文化相关的自然 QA 数据集，以解决现有数据集缺乏地区特定性和本地语言支持的问题。研究者创建了 MultiNativQA 数据集，包含约 64k 个手动标注的 QA 对，覆盖 7 种语言、9 个地区和 18 个主题，并使用该数据集基准测试了开源和闭源 LLMs。结果显示，NativQA 框架特别适用于低资源语言的 LLM 评估和微调，且框架及数据集已公开提供（https://nativqa.gitlab.io）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "LLMs, Native, Multilingual, Language Diversity, Contextual\n  Understanding, Minority Languages, Culturally Informed, Foundation Models,\n  Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2407.09823v2",
      "published_date": "2024-07-13 09:34:00 UTC",
      "updated_date": "2024-10-06 10:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:21:09.821037"
    },
    {
      "arxiv_id": "2407.09811v1",
      "title": "CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis",
      "title_zh": "CellAgent：基于LLM驱动的多智能体框架，用于自动化的单细胞数据分析",
      "authors": [
        "Yihang Xiao",
        "Jinyi Liu",
        "Yan Zheng",
        "Xiaohan Xie",
        "Jianye Hao",
        "Mingzhi Li",
        "Ruitao Wang",
        "Fei Ni",
        "Yuxiao Li",
        "Jintian Luo",
        "Shaoqing Jiao",
        "Jiajie Peng"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for\nbiological research, as it enables the precise characterization of cellular\nheterogeneity. However, manual manipulation of various tools to achieve desired\noutcomes can be labor-intensive for researchers. To address this, we introduce\nCellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework,\nspecifically designed for the automatic processing and execution of scRNA-seq\ndata analysis tasks, providing high-quality results with no human intervention.\nFirstly, to adapt general LLMs to the biological field, CellAgent constructs\nLLM-driven biological expert roles - planner, executor, and evaluator - each\nwith specific responsibilities. Then, CellAgent introduces a hierarchical\ndecision-making mechanism to coordinate these biological experts, effectively\ndriving the planning and step-by-step execution of complex data analysis tasks.\nFurthermore, we propose a self-iterative optimization mechanism, enabling\nCellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing\noutput quality. We evaluate CellAgent on a comprehensive benchmark dataset\nencompassing dozens of tissues and hundreds of distinct cell types. Evaluation\nresults consistently show that CellAgent effectively identifies the most\nsuitable tools and hyperparameters for single-cell analysis tasks, achieving\noptimal performance. This automated framework dramatically reduces the workload\nfor science data analyses, bringing us into the \"Agent for Science\" era.",
      "tldr_zh": "本研究针对单细胞 RNA 测序 (scRNA-seq) 数据分析的劳动密集型问题，提出 CellAgent，这是一个基于 LLM 驱动的多智能体框架，实现自动化处理和执行分析任务，无需人工干预。框架构建了 planner、executor 和 evaluator 等生物专家角色，并采用分层决策机制协调任务规划与逐步执行，以及自迭代优化机制来自主评估和改进解决方案。在基准数据集上评估结果显示，CellAgent 能有效识别最佳工具和超参数，显著提升分析性能，并大幅减少科学数据分析工作量，推动“Agent for Science”时代的发展。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "q-bio.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09811v1",
      "published_date": "2024-07-13 09:14:50 UTC",
      "updated_date": "2024-07-13 09:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:21:19.011784"
    },
    {
      "arxiv_id": "2407.09809v1",
      "title": "Preserving the Privacy of Reward Functions in MDPs through Deception",
      "title_zh": "翻译失败",
      "authors": [
        "Shashank Reddy Chirra",
        "Pradeep Varakantham",
        "Praveen Paruchuri"
      ],
      "abstract": "Preserving the privacy of preferences (or rewards) of a sequential\ndecision-making agent when decisions are observable is crucial in many physical\nand cybersecurity domains. For instance, in wildlife monitoring, agents must\nallocate patrolling resources without revealing animal locations to poachers.\nThis paper addresses privacy preservation in planning over a sequence of\nactions in MDPs, where the reward function represents the preference structure\nto be protected. Observers can use Inverse RL (IRL) to learn these preferences,\nmaking this a challenging task.\n  Current research on differential privacy in reward functions fails to ensure\nguarantee on the minimum expected reward and offers theoretical guarantees that\nare inadequate against IRL-based observers. To bridge this gap, we propose a\nnovel approach rooted in the theory of deception. Deception includes two\nmodels: dissimulation (hiding the truth) and simulation (showing the wrong).\nOur first contribution theoretically demonstrates significant privacy leaks in\nexisting dissimulation-based methods. Our second contribution is a novel\nRL-based planning algorithm that uses simulation to effectively address these\nprivacy concerns while ensuring a guarantee on the expected reward. Experiments\non multiple benchmark problems show that our approach outperforms previous\nmethods in preserving reward function privacy.",
      "tldr_zh": "该论文探讨了在MDPs（Markov Decision Processes）中保护奖励函数隐私的问题，尤其当决策可观察时，以防止观察者使用Inverse RL (IRL)来推断偏好。现有基于差分隐私的方法无法有效对抗IRL观察者，且不能保证最小预期奖励，因此作者从欺骗理论入手，分析了dissimulation（隐藏真相）方法的隐私泄露问题，并提出了一种新型RL-based规划算法，利用simulation（显示错误信息）来增强隐私保护，同时确保预期奖励。实验结果显示，该方法在多个基准问题上优于现有方法，有效提升了奖励函数的隐私保全。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.09809v1",
      "published_date": "2024-07-13 09:03:22 UTC",
      "updated_date": "2024-07-13 09:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:21:31.663223"
    },
    {
      "arxiv_id": "2407.11078v1",
      "title": "Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator",
      "title_zh": "通过联邦全局双生生成器克服联邦类增量学习中的灾难性遗忘",
      "authors": [
        "Thinh Nguyen",
        "Khoa D Doan",
        "Binh T. Nguyen",
        "Danh Le-Phuoc",
        "Kok-Seng Wong"
      ],
      "abstract": "Federated Class-Incremental Learning (FCIL) increasingly becomes important in\nthe decentralized setting, where it enables multiple participants to\ncollaboratively train a global model to perform well on a sequence of tasks\nwithout sharing their private data. In FCIL, conventional Federated Learning\nalgorithms such as FedAVG often suffer from catastrophic forgetting, resulting\nin significant performance declines on earlier tasks. Recent works, based on\ngenerative models, produce synthetic images to help mitigate this issue across\nall classes, but these approaches' testing accuracy on previous classes is\nstill much lower than recent classes, i.e., having better plasticity than\nstability. To overcome these issues, this paper presents Federated Global Twin\nGenerator (FedGTG), an FCIL framework that exploits privacy-preserving\ngenerative-model training on the global side without accessing client data.\nSpecifically, the server trains a data generator and a feature generator to\ncreate two types of information from all seen classes, and then it sends the\nsynthetic data to the client side. The clients then use\nfeature-direction-controlling losses to make the local models retain knowledge\nand learn new tasks well. We extensively analyze the robustness of FedGTG on\nnatural images, as well as its ability to converge to flat local minima and\nachieve better-predicting confidence (calibration). Experimental results on\nCIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy\nand forgetting measures of FedGTG compared to previous frameworks.",
      "tldr_zh": "该论文针对 Federated Class-Incremental Learning (FCIL) 中的 catastrophic forgetting 问题，提出了一种名为 Federated Global Twin Generator (FedGTG) 的框架，以帮助多个参与者在不共享私有数据的情况下协作训练全局模型。FedGTG 在服务器端训练数据生成器和特征生成器，从所有已见类生成合成数据，并将其发送到客户端，客户端则通过 feature-direction-controlling losses 来平衡模型的知识保留和新任务学习。实验结果显示，FedGTG 在 CIFAR-10、CIFAR-100 和 tiny-ImageNet 数据集上显著提高了准确率和遗忘度量指标，并展示了更好的鲁棒性、收敛到平坦局部最小点以及预测置信度校准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "68T07 (Primary), 68T45 (Secondary)"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11078v1",
      "published_date": "2024-07-13 08:23:21 UTC",
      "updated_date": "2024-07-13 08:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:21:43.161907"
    },
    {
      "arxiv_id": "2407.09801v1",
      "title": "IoT-LM: Large Multisensory Language Models for the Internet of Things",
      "title_zh": "IoT-LM：面向物联网的大型多感官语言模型",
      "authors": [
        "Shentong Mo",
        "Russ Salakhutdinov",
        "Louis-Philippe Morency",
        "Paul Pu Liang"
      ],
      "abstract": "The Internet of Things (IoT) network integrating billions of smart physical\ndevices embedded with sensors, software, and communication technologies is a\ncritical and rapidly expanding component of our modern world. The IoT ecosystem\nprovides a rich source of real-world modalities such as motion, thermal,\ngeolocation, imaging, depth, sensors, and audio to recognize the states of\nhumans and physical objects. Machine learning presents a rich opportunity to\nautomatically process IoT data at scale, enabling efficient inference for\nunderstanding human wellbeing, controlling physical devices, and\ninterconnecting smart cities. To realize this potential, we introduce IoT-LM,\nan open-source large multisensory language model tailored for the IoT\necosystem. IoT-LM is enabled by two technical contributions: the first is\nMultiIoT, the most expansive unified IoT dataset to date, encompassing over\n1.15 million samples from 12 modalities and 8 tasks prepared for multisensory\npre-training and instruction-tuning. The second is a new multisensory multitask\nadapter layer to condition pre-trained large language models on multisensory\nIoT data. Not only does IoT-LM yield substantial improvements on 8 supervised\nIoT classification tasks, but it also demonstrates new interactive\nquestion-answering, reasoning, and dialog capabilities conditioned on IoT\nsensors. We release IoT-LM's data sources and new multisensory language\nmodeling framework.",
      "tldr_zh": "本研究引入了IoT-LM，一种开源的大型多感官语言模型，旨在处理物联网(IoT)生态系统中的多种模态数据，如运动、热量和图像，以提升对人类状态和物理对象的理解。关键贡献包括构建MultiIoT数据集，该数据集包含超过115万样本、12个模态和8个任务，用于多感官预训练和指令微调，以及开发一个新的多感官多任务适配器层，用于在IoT数据上调节预训练的大型语言模型。IoT-LM在8个监督IoT分类任务上实现了显著性能提升，并展示了基于IoT传感器的交互式问答、推理和对话能力。该模型及其数据来源已开源发布，为智能设备互联和城市管理提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2311.06217",
      "pdf_url": "http://arxiv.org/pdf/2407.09801v1",
      "published_date": "2024-07-13 08:20:37 UTC",
      "updated_date": "2024-07-13 08:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:21:54.945857"
    },
    {
      "arxiv_id": "2407.11077v1",
      "title": "Deep reinforcement learning with symmetric data augmentation applied for aircraft lateral attitude tracking control",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Li",
        "Erik-jan van Kampen"
      ],
      "abstract": "Symmetry is an essential property in some dynamical systems that can be\nexploited for state transition prediction and control policy optimization. This\npaper develops two symmetry-integrated Reinforcement Learning (RL) algorithms\nbased on standard Deep Deterministic Policy Gradient (DDPG),which leverage\nenvironment symmetry to augment explored transition samples of a Markov\nDecision Process(MDP). The firstly developed algorithm is named as Deep\nDeterministic Policy Gradient with Symmetric Data Augmentation (DDPG-SDA),\nwhich enriches dataset of standard DDPG algorithm by symmetric data\naugmentation method under symmetry assumption of a dynamical system. To further\nimprove sample utilization efficiency, the second developed RL algorithm\nincorporates one extra critic network, which is independently trained with\naugmented dataset. A two-step approximate policy iteration method is proposed\nto integrate training for two critic networks and one actor network. The\nresulting RL algorithm is named as Deep Deterministic Policy Gradient with\nSymmetric Critic Augmentation (DDPG-SCA). Simulation results demonstrate\nenhanced sample efficiency and tracking performance of developed two RL\nalgorithms in aircraft lateral tracking control task.",
      "tldr_zh": "这篇论文提出两种基于 Deep Deterministic Policy Gradient (DDPG) 的强化学习算法，DDPG-SDA 和 DDPG-SCA，利用动态系统的对称性来增强 Markov Decision Process (MDP) 中的样本数据，以优化飞机横向姿态跟踪控制。DDPG-SDA 通过对称数据增强方法丰富数据集，而 DDPG-SCA 进一步引入额外的 critic 网络，并采用两步近似策略迭代方法来整合训练，提高样本利用效率。模拟实验结果表明，这两种算法在飞机横向跟踪任务中显著提升了样本效率和跟踪性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11077v1",
      "published_date": "2024-07-13 08:20:11 UTC",
      "updated_date": "2024-07-13 08:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:22:18.266739"
    },
    {
      "arxiv_id": "2407.12866v1",
      "title": "Beyond KV Caching: Shared Attention for Efficient LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Bingli Liao",
        "Danilo Vasconcellos Vargas"
      ],
      "abstract": "The efficiency of large language models (LLMs) remains a critical challenge,\nparticularly in contexts where computational resources are limited. Traditional\nattention mechanisms in these models, while powerful, require significant\ncomputational and memory resources due to the necessity of recalculating and\nstoring attention weights across different layers. This paper introduces a\nnovel Shared Attention (SA) mechanism, designed to enhance the efficiency of\nLLMs by directly sharing computed attention weights across multiple layers.\nUnlike previous methods that focus on sharing intermediate Key-Value (KV)\ncaches, our approach utilizes the isotropic tendencies of attention\ndistributions observed in advanced LLMs post-pretraining to reduce both the\ncomputational flops and the size of the KV cache required during inference. We\nempirically demonstrate that implementing SA across various LLMs results in\nminimal accuracy loss on standard benchmarks. Our findings suggest that SA not\nonly conserves computational resources but also maintains robust model\nperformance, thereby facilitating the deployment of more efficient LLMs in\nresource-constrained environments.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的效率挑战，提出了一种新型Shared Attention (SA) 机制，通过在多个层之间直接共享计算的注意力权重来减少计算浮点运算和KV缓存大小。不同于以往专注于共享Key-Value (KV) 缓存的方法，SA利用了LLMs训练后注意力分布的各向同性特性，从而显著降低资源消耗。实验结果显示，SA在各种LLMs上应用后，标准基准测试的准确性损失最小，同时提升了模型在资源受限环境中的部署性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12866v1",
      "published_date": "2024-07-13 07:23:07 UTC",
      "updated_date": "2024-07-13 07:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:22:20.488152"
    },
    {
      "arxiv_id": "2407.09788v1",
      "title": "Explanation is All You Need in Distillation: Mitigating Bias and Shortcut Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro R. A. S. Bassi",
        "Andrea Cavalli",
        "Sergio Decherchi"
      ],
      "abstract": "Bias and spurious correlations in data can cause shortcut learning,\nundermining out-of-distribution (OOD) generalization in deep neural networks.\nMost methods require unbiased data during training (and/or hyper-parameter\ntuning) to counteract shortcut learning. Here, we propose the use of\nexplanation distillation to hinder shortcut learning. The technique does not\nassume any access to unbiased data, and it allows an arbitrarily sized student\nnetwork to learn the reasons behind the decisions of an unbiased teacher, such\nas a vision-language model or a network processing debiased images. We found\nthat it is possible to train a neural network with explanation (e.g by Layer\nRelevance Propagation, LRP) distillation only, and that the technique leads to\nhigh resistance to shortcut learning, surpassing group-invariant learning,\nexplanation background minimization, and alternative distillation techniques.\nIn the COLOURED MNIST dataset, LRP distillation achieved 98.2% OOD accuracy,\nwhile deep feature distillation and IRM achieved 92.1% and 60.2%, respectively.\nIn COCO-on-Places, the undesirable generalization gap between in-distribution\nand OOD accuracy is only of 4.4% for LRP distillation, while the other two\ntechniques present gaps of 15.1% and 52.1%, respectively.",
      "tldr_zh": "该研究提出了一种名为“explanation distillation”的技术，用于缓解深度神经网络中的偏见和shortcut learning问题，从而提升分布外泛化（OOD）性能。该方法无需访问无偏数据，而是通过让学生网络从无偏教师（如视觉语言模型或处理去偏图像的网络）学习决策解释，例如使用Layer Relevance Propagation (LRP)。实验结果显示，LRP蒸馏在COLOURED MNIST数据集上实现了98.2%的OOD准确率，优于深特征蒸馏（92.1%）和IRM（60.2%）。此外，在COCO-on-Places数据集上，该技术仅表现出4.4%的OOD泛化差距，显著超过了其他方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09788v1",
      "published_date": "2024-07-13 07:04:28 UTC",
      "updated_date": "2024-07-13 07:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:22:32.986634"
    },
    {
      "arxiv_id": "2407.09779v1",
      "title": "Layout-and-Retouch: A Dual-stage Framework for Improving Diversity in Personalized Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kangyeol Kim",
        "Wooseok Seo",
        "Sehyun Nam",
        "Bodam Kim",
        "Suhyeon Jeong",
        "Wonwoo Cho",
        "Jaegul Choo",
        "Youngjae Yu"
      ],
      "abstract": "Personalized text-to-image (P-T2I) generation aims to create new, text-guided\nimages featuring the personalized subject with a few reference images. However,\nbalancing the trade-off relationship between prompt fidelity and identity\npreservation remains a critical challenge. To address the issue, we propose a\nnovel P-T2I method called Layout-and-Retouch, consisting of two stages: 1)\nlayout generation and 2) retouch. In the first stage, our step-blended\ninference utilizes the inherent sample diversity of vanilla T2I models to\nproduce diversified layout images, while also enhancing prompt fidelity. In the\nsecond stage, multi-source attention swapping integrates the context image from\nthe first stage with the reference image, leveraging the structure from the\ncontext image and extracting visual features from the reference image. This\nachieves high prompt fidelity while preserving identity characteristics.\nThrough our extensive experiments, we demonstrate that our method generates a\nwide variety of images with diverse layouts while maintaining the unique\nidentity features of the personalized objects, even with challenging text\nprompts. This versatility highlights the potential of our framework to handle\ncomplex conditions, significantly enhancing the diversity and applicability of\npersonalized image synthesis.",
      "tldr_zh": "这篇论文提出了Layout-and-Retouch框架，用于提升个性化文本到图像生成（P-T2I）的多样性，同时平衡提示忠实度和身份保留。框架分为两个阶段：第一阶段通过步进混合推理利用基础T2I模型的样本多样性生成多样化的布局图像，提高文本提示的准确性；第二阶段采用多源注意力交换，将第一阶段的上下文图像与参考图像整合，提取视觉特征并保留主体身份。实验结果显示，该方法在处理挑战性文本提示时，能够生成广泛多样化的图像布局，同时保持个性化对象的独特特征，显著提高了P-T2I的适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09779v1",
      "published_date": "2024-07-13 05:28:45 UTC",
      "updated_date": "2024-07-13 05:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:22:43.650885"
    },
    {
      "arxiv_id": "2407.09777v1",
      "title": "Graph Transformers: A Survey",
      "title_zh": "图 Transformer：综述",
      "authors": [
        "Ahsan Shehzad",
        "Feng Xia",
        "Shagufta Abid",
        "Ciyuan Peng",
        "Shuo Yu",
        "Dongyu Zhang",
        "Karin Verspoor"
      ],
      "abstract": "Graph transformers are a recent advancement in machine learning, offering a\nnew class of neural network models for graph-structured data. The synergy\nbetween transformers and graph learning demonstrates strong performance and\nversatility across various graph-related tasks. This survey provides an\nin-depth review of recent progress and challenges in graph transformer\nresearch. We begin with foundational concepts of graphs and transformers. We\nthen explore design perspectives of graph transformers, focusing on how they\nintegrate graph inductive biases and graph attention mechanisms into the\ntransformer architecture. Furthermore, we propose a taxonomy classifying graph\ntransformers based on depth, scalability, and pre-training strategies,\nsummarizing key principles for effective development of graph transformer\nmodels. Beyond technical analysis, we discuss the applications of graph\ntransformer models for node-level, edge-level, and graph-level tasks, exploring\ntheir potential in other application scenarios as well. Finally, we identify\nremaining challenges in the field, such as scalability and efficiency,\ngeneralization and robustness, interpretability and explainability, dynamic and\ncomplex graphs, as well as data quality and diversity, charting future\ndirections for graph transformer research.",
      "tldr_zh": "这篇调查论文回顾了Graph Transformers在机器学习中的最新进展，这是一种结合了Transformer架构和图结构数据的神经网络模型，展示了其在各种图相关任务中的强大性能和多功能性。论文从图和Transformers的基础概念入手，探讨了Graph Transformers的设计视角，包括如何整合图归纳偏差和Graph Attention Mechanisms，并提出一个基于深度、可扩展性和预训练策略的分类法，以总结有效模型开发的关键原则。该研究还分析了Graph Transformers在节点级、边级和图级任务中的应用潜力，同时指出了未来挑战，如可扩展性、泛化能力以及动态图处理，以指引该领域的进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 68T05, 68U01",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.09777v1",
      "published_date": "2024-07-13 05:15:24 UTC",
      "updated_date": "2024-07-13 05:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:22:54.975810"
    },
    {
      "arxiv_id": "2407.09774v3",
      "title": "ContextualStory: Consistent Visual Storytelling with Spatially-Enhanced and Storyline Context",
      "title_zh": "翻译失败",
      "authors": [
        "Sixiao Zheng",
        "Yanwei Fu"
      ],
      "abstract": "Visual storytelling involves generating a sequence of coherent frames from a\ntextual storyline while maintaining consistency in characters and scenes.\nExisting autoregressive methods, which rely on previous frame-sentence pairs,\nstruggle with high memory usage, slow generation speeds, and limited context\nintegration. To address these issues, we propose ContextualStory, a novel\nframework designed to generate coherent story frames and extend frames for\nvisual storytelling. ContextualStory utilizes Spatially-Enhanced Temporal\nAttention to capture spatial and temporal dependencies, handling significant\ncharacter movements effectively. Additionally, we introduce a Storyline\nContextualizer to enrich context in storyline embedding, and a StoryFlow\nAdapter to measure scene changes between frames for guiding the model.\nExtensive experiments on PororoSV and FlintstonesSV datasets demonstrate that\nContextualStory significantly outperforms existing SOTA methods in both story\nvisualization and continuation. Code is available at\nhttps://github.com/sixiaozheng/ContextualStory.",
      "tldr_zh": "本研究提出 ContextualStory 框架，用于生成连贯的视觉故事序列，确保角色和场景一致性，同时解决现有自回归方法的高内存消耗、慢速生成和上下文整合有限的问题。框架引入 Spatially-Enhanced Temporal Attention 来捕捉空间和时间依赖性，有效处理角色重大移动；Storyline Contextualizer 丰富故事线嵌入的上下文；StoryFlow Adapter 则测量帧间场景变化以指导模型。在 PororoSV 和 FlintstonesSV 数据集上的广泛实验显示，ContextualStory 在故事可视化和延续任务中显著优于现有 SOTA 方法。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09774v3",
      "published_date": "2024-07-13 05:02:42 UTC",
      "updated_date": "2025-02-24 14:02:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:23:07.726951"
    },
    {
      "arxiv_id": "2407.11075v7",
      "title": "A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)",
      "title_zh": "翻译失败",
      "authors": [
        "Tianrui Ji",
        "Yuntian Hou",
        "Di Zhang"
      ],
      "abstract": "Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have\ngained a thorough understanding of its theoretical foundation, architectural\ndesign, application scenarios, and current research progress. KAN, with its\nunique architecture and flexible activation functions, excels in handling\ncomplex data patterns and nonlinear relationships, demonstrating wide-ranging\napplication potential. While challenges remain, KAN is poised to pave the way\nfor innovative solutions in various fields, potentially revolutionizing how we\napproach complex computational problems.",
      "tldr_zh": "这篇论文对Kolmogorov-Arnold Networks (KAN) 进行了全面调查，涵盖了其理论基础、架构设计、应用场景以及当前研究进展。KAN 凭借独特架构和灵活的activation functions，能够出色地处理复杂数据模式和非线性关系，具有广泛的应用潜力。尽管仍存在挑战，但该网络有望在多个领域推动创新解决方案，革新复杂计算问题的处理方式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11075v7",
      "published_date": "2024-07-13 04:29:36 UTC",
      "updated_date": "2025-01-28 02:23:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:23:18.707975"
    },
    {
      "arxiv_id": "2407.11074v1",
      "title": "ST-RetNet: A Long-term Spatial-Temporal Traffic Flow Prediction Method",
      "title_zh": "ST-RetNet：一种长期时空交通流量预测方法",
      "authors": [
        "Baichao Long",
        "Wang Zhu",
        "Jianli Xiao"
      ],
      "abstract": "Traffic flow forecasting is considered a critical task in the field of\nintelligent transportation systems. In this paper, to address the issue of low\naccuracy in long-term forecasting of spatial-temporal big data on traffic flow,\nwe propose an innovative model called Spatial-Temporal Retentive Network\n(ST-RetNet). We extend the Retentive Network to address the task of traffic\nflow forecasting. At the spatial scale, we integrate a topological graph\nstructure into Spatial Retentive Network(S-RetNet), utilizing an adaptive\nadjacency matrix to extract dynamic spatial features of the road network. We\nalso employ Graph Convolutional Networks to extract static spatial features of\nthe road network. These two components are then fused to capture dynamic and\nstatic spatial correlations. At the temporal scale, we propose the Temporal\nRetentive Network(T-RetNet), which has been demonstrated to excel in capturing\nlong-term dependencies in traffic flow patterns compared to other time series\nmodels, including Recurrent Neural Networks based and transformer models. We\nachieve the spatial-temporal traffic flow forecasting task by integrating\nS-RetNet and T-RetNet to form ST-RetNet. Through experimental comparisons\nconducted on four real-world datasets, we demonstrate that ST-RetNet\noutperforms the state-of-the-art approaches in traffic flow forecasting.",
      "tldr_zh": "这篇论文提出了一种名为 ST-RetNet 的创新模型，用于解决交通流量预测中长期空间-时间数据准确性低的问题。ST-RetNet 扩展了 Retentive Network，在空间尺度上整合 Spatial Retentive Network (S-RetNet) 和 Graph Convolutional Networks (GCNs)，利用适应性邻接矩阵提取动态和静态空间特征；在时间尺度上，Temporal Retentive Network (T-RetNet) 优于传统 RNN 和 Transformer 模型，能够更好地捕捉长期依赖。通过在四个真实数据集上的实验，ST-RetNet 展示了比最先进方法更优异的预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11074v1",
      "published_date": "2024-07-13 03:52:32 UTC",
      "updated_date": "2024-07-13 03:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:23:31.921915"
    },
    {
      "arxiv_id": "2407.09760v1",
      "title": "ICCV23 Visual-Dialog Emotion Explanation Challenge: SEU_309 Team Technical Report",
      "title_zh": "ICCV23 视觉对话情感解释挑战：SEU_309 团队技术报告",
      "authors": [
        "Yixiao Yuan",
        "Yingzhe Peng"
      ],
      "abstract": "The Visual-Dialog Based Emotion Explanation Generation Challenge focuses on\ngenerating emotion explanations through visual-dialog interactions in art\ndiscussions. Our approach combines state-of-the-art multi-modal models,\nincluding Language Model (LM) and Large Vision Language Model (LVLM), to\nachieve superior performance. By leveraging these models, we outperform\nexisting benchmarks, securing the top rank in the ICCV23 Visual-Dialog Based\nEmotion Explanation Generation Challenge, which is part of the 5th Workshop On\nClosing The Loop Between Vision And Language (CLCV) with significant scores in\nF1 and BLEU metrics. Our method demonstrates exceptional ability in generating\naccurate emotion explanations, advancing our understanding of emotional impacts\nin art.",
      "tldr_zh": "该报告介绍了 SEU_309 团队在 ICCV23 视觉-对话情感解释生成挑战中的方法，该挑战聚焦于通过视觉-对话交互生成艺术讨论中的情感解释。\n他们结合了 Language Model (LM) 和 Large Vision Language Model (LVLM) 等多模态模型，超越了现有基准，并在 F1 和 BLEU 指标上取得最高分，获得挑战第一名。\n这项工作展示了生成准确情感解释的出色能力，推动了对艺术中情感影响的深入理解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09760v1",
      "published_date": "2024-07-13 03:39:41 UTC",
      "updated_date": "2024-07-13 03:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:23:43.868336"
    },
    {
      "arxiv_id": "2407.09739v2",
      "title": "Active Learning for Derivative-Based Global Sensitivity Analysis with Gaussian Processes",
      "title_zh": "基于高斯过程的主动学习，用于导数为基础的全局敏感性分析",
      "authors": [
        "Syrine Belakaria",
        "Benjamin Letham",
        "Janardhan Rao Doppa",
        "Barbara Engelhardt",
        "Stefano Ermon",
        "Eytan Bakshy"
      ],
      "abstract": "We consider the problem of active learning for global sensitivity analysis of\nexpensive black-box functions. Our aim is to efficiently learn the importance\nof different input variables, e.g., in vehicle safety experimentation, we study\nthe impact of the thickness of various components on safety objectives. Since\nfunction evaluations are expensive, we use active learning to prioritize\nexperimental resources where they yield the most value. We propose novel active\nlearning acquisition functions that directly target key quantities of\nderivative-based global sensitivity measures (DGSMs) under Gaussian process\nsurrogate models. We showcase the first application of active learning directly\nto DGSMs, and develop tractable uncertainty reduction and information gain\nacquisition functions for these measures. Through comprehensive evaluation on\nsynthetic and real-world problems, our study demonstrates how these active\nlearning acquisition strategies substantially enhance the sample efficiency of\nDGSM estimation, particularly with limited evaluation budgets. Our work paves\nthe way for more efficient and accurate sensitivity analysis in various\nscientific and engineering applications.",
      "tldr_zh": "本研究针对昂贵的黑箱函数进行全局敏感性分析，提出了一种基于高斯过程（Gaussian Processes）的主动学习（Active Learning）方法，以高效评估输入变量的重要性，例如在车辆安全实验中分析组件厚度对安全目标的影响。作者开发了新型获取函数，直接针对基于导数的全局敏感性度量（DGSMs），包括不确定性减少和信息增益策略，从而优先分配实验资源。实验结果显示，该方法在合成和真实世界问题上显著提高了DGSMs估计的样本效率，尤其在评估预算有限的情况下。该工作为科学和工程领域的敏感性分析提供了更高效、准确的途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09739v2",
      "published_date": "2024-07-13 01:41:12 UTC",
      "updated_date": "2024-10-19 22:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:23:55.782188"
    },
    {
      "arxiv_id": "2407.09726v1",
      "title": "On Mitigating Code LLM Hallucinations with API Documentation",
      "title_zh": "翻译失败",
      "authors": [
        "Nihal Jain",
        "Robert Kwiatkowski",
        "Baishakhi Ray",
        "Murali Krishna Ramanathan",
        "Varun Kumar"
      ],
      "abstract": "In this study, we address the issue of API hallucinations in various software\nengineering contexts. We introduce CloudAPIBench, a new benchmark designed to\nmeasure API hallucination occurrences. CloudAPIBench also provides annotations\nfor frequencies of API occurrences in the public domain, allowing us to study\nAPI hallucinations at various frequency levels. Our findings reveal that Code\nLLMs struggle with low frequency APIs: for e.g., GPT-4o achieves only 38.58%\nvalid low frequency API invocations. We demonstrate that Documentation\nAugmented Generation (DAG) significantly improves performance for low frequency\nAPIs (increase to 47.94% with DAG) but negatively impacts high frequency APIs\nwhen using sub-optimal retrievers (a 39.02% absolute drop). To mitigate this,\nwe propose to intelligently trigger DAG where we check against an API index or\nleverage Code LLMs' confidence scores to retrieve only when needed. We\ndemonstrate that our proposed methods enhance the balance between low and high\nfrequency API performance, resulting in more reliable API invocations (8.20%\nabsolute improvement on CloudAPIBench for GPT-4o).",
      "tldr_zh": "本研究针对Code LLMs在API hallucinations问题上表现不佳，特别是低频率API，引入了CloudAPIBench基准来评估和分析API幻觉发生频率。研究发现，GPT-4o在低频率API调用中仅达到38.58%的有效率，而Documentation Augmented Generation (DAG)方法显著提升了这一表现（提高至47.94%），但会降低高频率API的性能（绝对下降39.02%）。为优化此问题，作者提出智能触发DAG机制，使用API索引或Code LLMs的置信度分数来有选择地检索文档，最终在CloudAPIBench上实现了GPT-4o的8.20%绝对性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09726v1",
      "published_date": "2024-07-13 00:16:26 UTC",
      "updated_date": "2024-07-13 00:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T06:24:17.882088"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 41,
  "processed_papers_count": 41,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T06:24:35.939598"
}