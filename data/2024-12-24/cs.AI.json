{
  "date": "2024-12-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-24 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 和机器学习领域，包括 LLM 的优化、安全、多模态生成、知识图谱应用，以及在机器人、医疗和计算机视觉中的创新；重点有 LLM 在知识检索和视频生成的进展，如 CypherBench 和 DiTCtrl 等高话题度文章，以及对 AI 偏见和模型量化（如 1.58-bit FLUX）的深入探讨。\n\n下面，我挑选并简要讨论了今天更重要的论文，先从高影响力或创新性强的入手（如 LLM 相关和多模态生成），并将相关主题归类讨论。其他论文如综述或较基础的，我会快速掠过，以控制篇幅。\n\n### 1. **CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano**（中文标题：针对 Google Chrome 内建 Gemini Nano 的分块增强生成）\n   - 主要贡献：提出 CAG 架构，通过智能分块处理克服 Gemini Nano 的上下文窗口限制，实现高效处理大型文档，而不依赖外部 API。\n   - 发现：显著提升浏览器内 AI 处理能力，适用于大文档和数据集；开源实现可立即应用。\n\n### 2. **CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era**（中文标题：LLM 时代针对大规模知识图谱的精确检索基准）\n   - 主要贡献：引入属性图视图和 Cypher 查询，解决知识图谱（如 Wikidata）的大规模模式问题，并构建首个包含 780 万实体和 1 万+ 问题的基准。\n   - 发现：提升 LLM 在知识图谱检索的效率和准确性，适用于 RAG 系统；这篇论文在 LLM 增强知识检索领域有高话题度。\n\n### 3. **DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation**（中文标题：多模态扩散 Transformer 的注意力控制，用于无调优的多提示长视频生成）\n   - 主要贡献：开发无训练的多提示视频生成方法，通过注意力机制实现平滑过渡和一致性对象运动。\n   - 发现：显著改善多提示视频生成的质量和连贯性；与 Sora-like 模型相关，潜力应用于动态场景生成。\n\n### 4. **From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs**（中文标题：从幻觉到事实：利用精选知识图谱增强语言模型）\n   - 主要贡献：整合维基百科的知识图谱三元组，减少 LLM 的幻觉问题，提高响应的事实性和相关性。\n   - 发现：实验证明，该方法显著提升模型输出可靠性；这与 LLM 实际应用紧密相关，解决幻觉问题是热门话题。\n\n### 5. **Agents on the Bench: Large Language Model Based Multi Agent Framework for Trustworthy Digital Justice**（中文标题：基于 LLM 的多代理框架，用于可信数字司法决策）\n   - 主要贡献：提出 AgentsBench 框架，使用多个 LLM 代理模拟司法审议过程，提高决策的透明度和公平性。\n   - 发现：在法律判断预测任务中超越现有方法；强调 AI 在司法领域的可解释性和社会影响，作者 Cong Jiang 等有实际应用潜力。\n\n### 6. **Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning**（中文标题：利用自动生成奖励和多步强化学习的多样化红队测试）\n   - 主要贡献：开发 RL-based 方法生成多样且有效的攻击样本，用于测试 LLM 的鲁棒性。\n   - 发现：显著提升攻击的多样性和成功率；作者如 Alex Beutel 等来自知名机构，这在 AI 安全领域有重要启示。\n\n### 7. **Video Is Worth a Thousand Images: Exploring the Latest Trends in Long Video Generation**（中文标题：视频胜过千张图片：探索长视频生成的最新趋势）\n   - 主要贡献：综述长视频生成技术，包括 GAN 和扩散模型，讨论数据集和评估指标。\n   - 发现：强调分治策略提升可扩展性；这篇论文系统性强，适用于视频 AI 研究，但作为综述，我快速掠过核心点。\n\n### 8. **1.58-bit FLUX**（中文标题：1.58 位 FLUX：文本到图像模型的量化方法）\n   - 主要贡献：实现 FLUX.1-dev 模型的 1.58 位量化，减少存储和内存占用，同时保持生成质量。\n   - 发现：无数据访问的自监督量化方法提升计算效率；在模型部署中具有实际价值。\n\n### 9. **Interplay of ISMS and AIMS in context of the EU AI Act**（中文标题：ISMS 和 AIMS 在欧盟 AI 法案下的互动）\n   - 主要贡献：分析信息安全管理和 AI 管理系统如何符合欧盟 AI 法案，提出新模块和标准整合。\n   - 发现：为 AI 合规提供框架，提升系统安全性；这篇与政策相关的论文有现实影响，我简要提及。\n\n其他论文如 **SurvAttack**（黑盒攻击生存模型，贡献：提出攻击框架提升医疗模型鲁棒性）、**MapExplorer**（从可视化生成内容，贡献：新任务和评估指标）等，虽然有创新，但相对次要，我快速总结：\n- **SurvAttack**：针对 EHR 的黑盒攻击，改善模型鲁棒性和解释性。\n- **MapExplorer**：知识发现任务，提升可视化到文本生成。\n- 综述类如 **A Review of Latent Representation Models in Neuroimaging** 和 **Machine Learning and Deep Learning Techniques used in Cybersecurity**，我只提核心：前者讨论神经成像模型应用，后者概述安全技术，但不深入。\n\n总体而言，今天的论文突显 AI 模型的优化和应用潜力，LLM 在多领域（如知识图谱和生成）的进展尤为引人注目。未来几天，关注这些方向的跟进研究！",
  "papers": [
    {
      "arxiv_id": "2412.18708v1",
      "title": "CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano",
      "title_zh": "翻译失败",
      "authors": [
        "Vivek Vellaiyappan Surulimuthu",
        "Aditya Karnam Gururaj Rao"
      ],
      "abstract": "We present Chunked Augmented Generation (CAG), an architecture specifically\ndesigned to overcome the context window limitations of Google Chrome's built-in\nGemini Nano model. While Chrome's integration of Gemini Nano represents a\nsignificant advancement in bringing AI capabilities directly to the browser,\nits restricted context window poses challenges for processing large inputs. CAG\naddresses this limitation through intelligent input chunking and processing\nstrategies, enabling efficient handling of extensive content while maintaining\nthe model's performance within browser constraints. Our implementation\ndemonstrates particular efficacy in processing large documents and datasets\ndirectly within Chrome, making sophisticated AI capabilities accessible through\nthe browser without external API dependencies. Get started now at\nhttps://github.com/vivekVells/cag-js.",
      "tldr_zh": "我们提出了 Chunked Augmented Generation (CAG)，一种专为 Google Chrome 的内置 Gemini Nano 模型设计的架构，用于解决其上下文窗口限制问题。CAG 通过智能输入分块和处理策略，实现高效处理大型输入，同时保持模型性能。实验结果显示，该方法在浏览器内处理大文档和数据集时表现出色，提供无需外部 API 的 AI 功能，提升了可访问性。",
      "categories": [
        "cs.AI",
        "68T01 (Primary)",
        "I.2.0; I.2.1; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18708v1",
      "published_date": "2024-12-24 23:49:23 UTC",
      "updated_date": "2024-12-24 23:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:07:42.612027"
    },
    {
      "arxiv_id": "2412.18706v1",
      "title": "SurvAttack: Black-Box Attack On Survival Models through Ontology-Informed EHR Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Nayebi Kerdabadi",
        "Arya Hadizadeh Moghaddam",
        "Bin Liu",
        "Mei Liu",
        "Zijun Yao"
      ],
      "abstract": "Survival analysis (SA) models have been widely studied in mining electronic\nhealth records (EHRs), particularly in forecasting the risk of critical\nconditions for prioritizing high-risk patients. However, their vulnerability to\nadversarial attacks is much less explored in the literature. Developing\nblack-box perturbation algorithms and evaluating their impact on\nstate-of-the-art survival models brings two benefits to medical applications.\nFirst, it can effectively evaluate the robustness of models in pre-deployment\ntesting. Also, exploring how subtle perturbations would result in significantly\ndifferent outcomes can provide counterfactual insights into the clinical\ninterpretation of model prediction. In this work, we introduce SurvAttack, a\nnovel black-box adversarial attack framework leveraging subtle clinically\ncompatible, and semantically consistent perturbations on longitudinal EHRs to\ndegrade survival models' predictive performance. We specifically develop a\ngreedy algorithm to manipulate medical codes with various adversarial actions\nthroughout a patient's medical history. Then, these adversarial actions are\nprioritized using a composite scoring strategy based on multi-aspect\nperturbation quality, including saliency, perturbation stealthiness, and\nclinical meaningfulness. The proposed adversarial EHR perturbation algorithm is\nthen used in an efficient SA-specific strategy to attack a survival model when\nestimating the temporal ranking of survival urgency for patients. To\ndemonstrate the significance of our work, we conduct extensive experiments,\nincluding baseline comparisons, explainability analysis, and case studies. The\nexperimental results affirm our research's effectiveness in illustrating the\nvulnerabilities of patient survival models, model interpretation, and\nultimately contributing to healthcare quality.",
      "tldr_zh": "本文提出 SurvAttack，一种基于本体信息的黑盒攻击框架，通过对电子健康记录(EHRs)进行微小、临床兼容且语义一致的扰动，来评估和降低生存分析(SA)模型的预测性能。框架采用贪婪算法操纵患者医疗历史中的医疗代码，并通过显著性、扰动隐秘性和临床意义的多方面评分策略优先化这些扰动，从而针对模型对患者生存紧迫性的时间排名进行高效攻击。实验结果显示，SurvAttack 显著降低了基线模型的准确性，并通过解释性分析和案例研究，揭示了模型漏洞，提供反事实洞见以提升医疗应用的鲁棒性和质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18706v1",
      "published_date": "2024-12-24 23:35:42 UTC",
      "updated_date": "2024-12-24 23:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:07:54.966641"
    },
    {
      "arxiv_id": "2412.18702v2",
      "title": "CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era",
      "title_zh": "CypherBench：面向全规模现代知识图谱的精确检索，在LLM时代",
      "authors": [
        "Yanlin Feng",
        "Simone Papicchio",
        "Sajjadur Rahman"
      ],
      "abstract": "Retrieval from graph data is crucial for augmenting large language models\n(LLM) with both open-domain knowledge and private enterprise data, and it is\nalso a key component in the recent GraphRAG system (edge et al., 2024). Despite\ndecades of research on knowledge graphs and knowledge base question answering,\nleading LLM frameworks (e.g. Langchain and LlamaIndex) have only minimal\nsupport for retrieval from modern encyclopedic knowledge graphs like Wikidata.\nIn this paper, we analyze the root cause and suggest that modern RDF knowledge\ngraphs (e.g. Wikidata, Freebase) are less efficient for LLMs due to overly\nlarge schemas that far exceed the typical LLM context window, use of resource\nidentifiers, overlapping relation types and lack of normalization. As a\nsolution, we propose property graph views on top of the underlying RDF graph\nthat can be efficiently queried by LLMs using Cypher. We instantiated this idea\non Wikidata and introduced CypherBench, the first benchmark with 11\nlarge-scale, multi-domain property graphs with 7.8 million entities and over\n10,000 questions. To achieve this, we tackled several key challenges, including\ndeveloping an RDF-to-property graph conversion engine, creating a systematic\npipeline for text-to-Cypher task generation, and designing new evaluation\nmetrics.",
      "tldr_zh": "该研究分析了从现代知识图谱（如Wikidata）中检索数据的问题，指出其庞大模式、资源标识符和缺乏规范化导致LLM（如Langchain和LlamaIndex）支持不足，从而影响GraphRAG系统等应用。为解决此问题，论文提出在RDF图基础上构建属性图视图，并使用Cypher进行高效查询。核心贡献包括开发CypherBench基准测试，该基准包含11个大规模多域属性图（780万实体和超过10,000个问题），以及RDF-to-property图转换引擎、文本到Cypher任务生成管道和新评估指标，以提升知识图谱在LLM时代的精确检索能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18702v2",
      "published_date": "2024-12-24 23:22:04 UTC",
      "updated_date": "2025-04-04 19:44:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:08:07.146195"
    },
    {
      "arxiv_id": "2412.18697v1",
      "title": "Agents on the Bench: Large Language Model Based Multi Agent Framework for Trustworthy Digital Justice",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Jiang",
        "Xiaolei Yang"
      ],
      "abstract": "The justice system has increasingly employed AI techniques to enhance\nefficiency, yet limitations remain in improving the quality of decision-making,\nparticularly regarding transparency and explainability needed to uphold public\ntrust in legal AI. To address these challenges, we propose a large language\nmodel based multi-agent framework named AgentsBench, which aims to\nsimultaneously improve both efficiency and quality in judicial decision-making.\nOur approach leverages multiple LLM-driven agents that simulate the\ncollaborative deliberation and decision making process of a judicial bench. We\nconducted experiments on legal judgment prediction task, and the results show\nthat our framework outperforms existing LLM based methods in terms of\nperformance and decision quality. By incorporating these elements, our\nframework reflects real-world judicial processes more closely, enhancing\naccuracy, fairness, and society consideration. AgentsBench provides a more\nnuanced and realistic methods of trustworthy AI decision-making, with strong\npotential for application across various case types and legal scenarios.",
      "tldr_zh": "该论文提出AgentsBench，一种基于Large Language Model (LLM)的多智能体框架，旨在解决司法系统中AI决策的透明度和可解释性问题，从而提升决策效率和质量。该框架通过模拟司法bench的协作审议过程，使用多个LLM驱动的智能体进行集体决策，在法律判断预测任务中表现出色。实验结果显示，AgentsBench在性能和决策质量上优于现有LLM方法，提高了准确性、公平性和社会考虑。作为一种更贴近现实的AI决策方法，该框架具有潜力应用于各种案件类型和法律场景。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Draft version; Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.18697v1",
      "published_date": "2024-12-24 23:13:37 UTC",
      "updated_date": "2024-12-24 23:13:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:09:45.638068"
    },
    {
      "arxiv_id": "2412.18693v1",
      "title": "Diverse and Effective Red Teaming with Auto-generated Rewards and Multi-step Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Beutel",
        "Kai Xiao",
        "Johannes Heidecke",
        "Lilian Weng"
      ],
      "abstract": "Automated red teaming can discover rare model failures and generate\nchallenging examples that can be used for training or evaluation. However, a\ncore challenge in automated red teaming is ensuring that the attacks are both\ndiverse and effective. Prior methods typically succeed in optimizing either for\ndiversity or for effectiveness, but rarely both. In this paper, we provide\nmethods that enable automated red teaming to generate a large number of diverse\nand successful attacks.\n  Our approach decomposes the task into two steps: (1) automated methods for\ngenerating diverse attack goals and (2) generating effective attacks for those\ngoals. While we provide multiple straightforward methods for generating diverse\ngoals, our key contributions are to train an RL attacker that both follows\nthose goals and generates diverse attacks for those goals. First, we\ndemonstrate that it is easy to use a large language model (LLM) to generate\ndiverse attacker goals with per-goal prompts and rewards, including rule-based\nrewards (RBRs) to grade whether the attacks are successful for the particular\ngoal. Second, we demonstrate how training the attacker model with multi-step\nRL, where the model is rewarded for generating attacks that are different from\npast attempts further increases diversity while remaining effective. We use our\napproach to generate both prompt injection attacks and prompts that elicit\nunsafe responses. In both cases, we find that our approach is able to generate\nhighly-effective and considerably more diverse attacks than past general\nred-teaming approaches.",
      "tldr_zh": "本文提出了一种自动化红队测试方法，旨在同时实现攻击的多样性（diverse）和有效性（effective），以发现模型的罕见失败并生成挑战性例子。方法将任务分解为两步：首先，使用大型语言模型（LLM）结合基于规则的奖励（RBRs）自动生成多样化的攻击目标；其次，通过多步强化学习（multi-step RL）训练RL攻击者，确保生成的攻击既遵循目标又与过去尝试不同，从而提升多样性。实验结果表明，该方法在提示注入攻击（prompt injection attacks）和引发不安全响应的提示上，生成攻击的成功率和多样性均显著优于现有方法，为模型评估和训练提供了更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18693v1",
      "published_date": "2024-12-24 22:38:46 UTC",
      "updated_date": "2024-12-24 22:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:08:31.793866"
    },
    {
      "arxiv_id": "2412.18688v1",
      "title": "Video Is Worth a Thousand Images: Exploring the Latest Trends in Long Video Generation",
      "title_zh": "视频胜过千张图像：探索长视频生成的最新趋势",
      "authors": [
        "Faraz Waseem",
        "Muhammad Shahzad"
      ],
      "abstract": "An image may convey a thousand words, but a video composed of hundreds or\nthousands of image frames tells a more intricate story. Despite significant\nprogress in multimodal large language models (MLLMs), generating extended\nvideos remains a formidable challenge. As of this writing, OpenAI's Sora, the\ncurrent state-of-the-art system, is still limited to producing videos that are\nup to one minute in length. This limitation stems from the complexity of long\nvideo generation, which requires more than generative AI techniques for\napproximating density functions essential aspects such as planning, story\ndevelopment, and maintaining spatial and temporal consistency present\nadditional hurdles. Integrating generative AI with a divide-and-conquer\napproach could improve scalability for longer videos while offering greater\ncontrol. In this survey, we examine the current landscape of long video\ngeneration, covering foundational techniques like GANs and diffusion models,\nvideo generation strategies, large-scale training datasets, quality metrics for\nevaluating long videos, and future research areas to address the limitations of\nthe existing video generation capabilities. We believe it would serve as a\ncomprehensive foundation, offering extensive information to guide future\nadvancements and research in the field of long video generation.",
      "tldr_zh": "这篇论文探讨了长视频生成的最新趋势，强调视频比单张图像更能讲述复杂故事，但当前Multimodal Large Language Models (MLLMs)如OpenAI's Sora仍限于生成一分钟以内的视频。论文审查了基础技术（如GANs和diffusion models）、视频生成策略、大规模训练数据集以及质量评估指标，并指出挑战包括规划、故事发展和空间-temporal一致性。作者建议采用divide-and-conquer方法与生成AI结合，以提升可扩展性和控制力，为未来长视频生成研究提供全面指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 18 figures, Manuscript submitted to ACM",
      "pdf_url": "http://arxiv.org/pdf/2412.18688v1",
      "published_date": "2024-12-24 21:24:41 UTC",
      "updated_date": "2024-12-24 21:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:08:42.655235"
    },
    {
      "arxiv_id": "2412.18673v2",
      "title": "MapExplorer: New Content Generation from Low-Dimensional Visualizations",
      "title_zh": "MapExplorer：基于低维可视化的新内容生成",
      "authors": [
        "Xingjian Zhang",
        "Ziyang Xiong",
        "Shixuan Liu",
        "Yutong Xie",
        "Tolga Ergen",
        "Dongsub Shim",
        "Hua Xu",
        "Honglak Lee",
        "Qiaozhu Me"
      ],
      "abstract": "Low-dimensional visualizations, or \"projection maps,\" are widely used in\nscientific and creative domains to interpret large-scale and complex datasets.\nThese visualizations not only aid in understanding existing knowledge spaces\nbut also implicitly guide exploration into unknown areas. Although techniques\nsuch as t-SNE and UMAP can generate these maps, there exists no systematic\nmethod for leveraging them to generate new content. To address this, we\nintroduce MapExplorer, a novel knowledge discovery task that translates\ncoordinates within any projection map into coherent, contextually aligned\ntextual content. This allows users to interactively explore and uncover\ninsights embedded in the maps. To evaluate the performance of MapExplorer\nmethods, we propose Atometric, a fine-grained metric inspired by ROUGE that\nquantifies logical coherence and alignment between generated and reference\ntext. Experiments on diverse datasets demonstrate the versatility of\nMapExplorer in generating scientific hypotheses, crafting synthetic personas,\nand devising strategies for attacking large language models-even with simple\nbaseline methods. By bridging visualization and generation, our work highlights\nthe potential of MapExplorer to enable intuitive human-AI collaboration in\nlarge-scale data exploration.",
      "tldr_zh": "该研究针对低维可视化（projection maps，如 t-SNE 和 UMAP）在数据探索中的局限性，提出了一种新任务 MapExplorer，用于将这些地图中的坐标转化为连贯且上下文相关的文本内容，从而支持交互式知识发现。MapExplorer 结合了生成技术，允许用户从可视化中生成科学假设、合成人物或攻击大型语言模型的策略；同时，引入了 Atometric 指标（受 ROUGE 启发），用于评估生成的文本在逻辑一致性和对齐方面的表现。实验在多样数据集上验证了 MapExplorer 的多功能性，展示了其在桥接可视化和生成方面的潜力，促进人类-AI 在大规模数据探索中的协作。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18673v2",
      "published_date": "2024-12-24 20:16:13 UTC",
      "updated_date": "2025-05-15 15:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:08:54.474805"
    },
    {
      "arxiv_id": "2412.18672v1",
      "title": "From Hallucinations to Facts: Enhancing Language Models with Curated Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Ratnesh Kumar Joshi",
        "Sagnik Sengupta",
        "Asif Ekbal"
      ],
      "abstract": "Hallucination, a persistent challenge plaguing language models, undermines\ntheir efficacy and trustworthiness in various natural language processing\nendeavors by generating responses that deviate from factual accuracy or\ncoherence. This paper addresses language model hallucination by integrating\ncurated knowledge graph (KG) triples to anchor responses in empirical data. We\nmeticulously select and integrate relevant KG triples tailored to specific\ncontexts, enhancing factual grounding and alignment with input. Our\ncontribution involves constructing a comprehensive KG repository from Wikipedia\nand refining data to spotlight essential information for model training. By\nimbuing language models with access to this curated knowledge, we aim to\ngenerate both linguistically fluent responses and deeply rooted in factual\naccuracy and context relevance. This integration mitigates hallucinations by\nproviding a robust foundation of information, enabling models to draw upon a\nrich reservoir of factual data during response generation. Experimental\nevaluations demonstrate the effectiveness of multiple approaches in reducing\nhallucinatory responses, underscoring the role of curated knowledge graphs in\nimproving the reliability and trustworthiness of language model outputs.",
      "tldr_zh": "这篇论文针对语言模型的幻觉（Hallucination）问题，通过整合精选的知识图谱（KG）三元组来提升模型的准确性和可靠性。作者从Wikipedia构建了一个全面的KG仓库，并精炼数据以突出关键信息，使模型在生成响应时能锚定于经验事实，从而实现流畅且事实准确的输出。该方法在实验中证明了多种整合方式的有效性，显著降低了幻觉响应，并提高了语言模型的整体可信度和 trustworthiness。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 Pages, 5 Tables, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18672v1",
      "published_date": "2024-12-24 20:16:10 UTC",
      "updated_date": "2024-12-24 20:16:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:09:06.595910"
    },
    {
      "arxiv_id": "2412.18670v1",
      "title": "Interplay of ISMS and AIMS in context of the EU AI Act",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Pötsch"
      ],
      "abstract": "The EU AI Act (AIA) mandates the implementation of a risk management system\n(RMS) and a quality management system (QMS) for high-risk AI systems. The\nISO/IEC 42001 standard provides a foundation for fulfilling these requirements\nbut does not cover all EU-specific regulatory stipulations. To enhance the\nimplementation of the AIA in Germany, the Federal Office for Information\nSecurity (BSI) could introduce the national standard BSI 200-5, which specifies\nAIA requirements and integrates existing ISMS standards, such as ISO/IEC 27001.\nThis paper examines the interfaces between an information security management\nsystem (ISMS) and an AI management system (AIMS), demonstrating that\nincorporating existing ISMS controls with specific AI extensions presents an\neffective strategy for complying with Article 15 of the AIA. Four new AI\nmodules are introduced, proposed for inclusion in the BSI IT Grundschutz\nframework to comprehensively ensure the security of AI systems. Additionally,\nan approach for adapting BSI's qualification and certification systems is\noutlined to ensure that expertise in secure AI handling is continuously\ndeveloped. Finally, the paper discusses how the BSI could bridge international\nstandards and the specific requirements of the AIA through the nationalization\nof ISO/IEC 42001, creating synergies and bolstering the competitiveness of the\nGerman AI landscape.",
      "tldr_zh": "这篇论文探讨了信息安全管理系统（ISMS）和AI管理系统（AIMS）在欧盟AI法案（EU AI Act）下的互动关系，强调通过整合ISO/IEC 42001标准和德国BSI 200-5标准来满足高风险AI系统的风险管理和质量管理要求（RMS和QMS）。论文提出将现有ISMS控制与特定AI扩展相结合，作为符合Article 15的有效策略，并引入四个新的AI模块，建议纳入BSI IT Grundschutz框架以增强AI系统安全。最终，论文建议BSI通过国家化ISO/IEC 42001来桥接国际标准与欧盟规定，创造协同效应，提升德国AI领域的竞争力和合规性。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18670v1",
      "published_date": "2024-12-24 20:13:19 UTC",
      "updated_date": "2024-12-24 20:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:09:19.674924"
    },
    {
      "arxiv_id": "2412.18669v1",
      "title": "Advancing Explainability in Neural Machine Translation: Analytical Metrics for Attention and Alignment Consistency",
      "title_zh": "推进神经机器翻译中的可解释性",
      "authors": [
        "Anurag Mishra"
      ],
      "abstract": "Neural Machine Translation (NMT) models have shown remarkable performance but\nremain largely opaque in their decision making processes. The interpretability\nof these models, especially their internal attention mechanisms, is critical\nfor building trust and verifying that these systems behave as intended. In this\nwork, we introduce a systematic framework to quantitatively evaluate the\nexplainability of an NMT model attention patterns by comparing them against\nstatistical alignments and correlating them with standard machine translation\nquality metrics. We present a set of metrics attention entropy and alignment\nagreement and validate them on an English-German test subset from WMT14 using a\npre trained mT5 model. Our results indicate that sharper attention\ndistributions correlate with improved interpretability but do not always\nguarantee better translation quality. These findings advance our understanding\nof NMT explainability and guide future efforts toward building more transparent\nand reliable machine translation systems.",
      "tldr_zh": "这篇论文针对 Neural Machine Translation (NMT) 模型决策过程的不透明性，提出一个系统框架来量化评估其注意机制的解释性，通过比较注意模式与 statistical alignments，并与标准翻译质量指标相关联。研究引入了 attention entropy 和 alignment agreement 等新指标，在 WMT14 的英语-德语测试子集上使用预训练 mT5 模型进行验证。结果表明，更尖锐的 attention distributions 与更好的解释性相关，但并不总是保证更高的翻译质量。这些发现有助于深化对 NMT 解释性的理解，并指导未来构建更透明可靠的机器翻译系统。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "68T50",
        "I.2.7; I.2.3"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures, research paper from the Rochester Institute of\n  Technology, focused on explainability in Neural Machine Translation.\n  Validated metrics using English-German data subset from WMT14 and mT5 model.\n  Results connect attention entropy and alignment agreement with translation\n  quality",
      "pdf_url": "http://arxiv.org/pdf/2412.18669v1",
      "published_date": "2024-12-24 20:08:33 UTC",
      "updated_date": "2024-12-24 20:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:09:31.818672"
    },
    {
      "arxiv_id": "2412.19844v1",
      "title": "A Review of Latent Representation Models in Neuroimaging",
      "title_zh": "翻译失败",
      "authors": [
        "C. Vázquez-García",
        "F. J. Martínez-Murcia",
        "F. Segovia Román",
        "Juan M. Górriz"
      ],
      "abstract": "Neuroimaging data, particularly from techniques like MRI or PET, offer rich\nbut complex information about brain structure and activity. To manage this\ncomplexity, latent representation models - such as Autoencoders, Generative\nAdversarial Networks (GANs), and Latent Diffusion Models (LDMs) - are\nincreasingly applied. These models are designed to reduce high-dimensional\nneuroimaging data to lower-dimensional latent spaces, where key patterns and\nvariations related to brain function can be identified. By modeling these\nlatent spaces, researchers hope to gain insights into the biology and function\nof the brain, including how its structure changes with age or disease, or how\nit encodes sensory information, predicts and adapts to new inputs. This review\ndiscusses how these models are used for clinical applications, like disease\ndiagnosis and progression monitoring, but also for exploring fundamental brain\nmechanisms such as active inference and predictive coding. These approaches\nprovide a powerful tool for both understanding and simulating the brain's\ncomplex computational tasks, potentially advancing our knowledge of cognition,\nperception, and neural disorders.",
      "tldr_zh": "这篇综述探讨了潜在表示模型（如 Autoencoders、GANs 和 LDMs）在神经影像学（如 MRI 或 PET）中的应用，这些模型通过将高维数据降维到潜在空间，帮助识别大脑结构和功能的模式变化。论文强调这些模型在临床领域的价值，包括疾病诊断、进展监测，以及在基础研究中探索大脑机制如 active inference 和 predictive coding。总体而言，该综述展示了这些方法如何推进对大脑生物学、认知和神经障碍的理解，并为模拟大脑计算任务提供强大工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "31 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.19844v1",
      "published_date": "2024-12-24 19:12:11 UTC",
      "updated_date": "2024-12-24 19:12:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:09:57.258901"
    },
    {
      "arxiv_id": "2412.18653v1",
      "title": "1.58-bit FLUX",
      "title_zh": "1.58 位 FLUX",
      "authors": [
        "Chenglin Yang",
        "Celong Liu",
        "Xueqing Deng",
        "Dongwon Kim",
        "Xing Mei",
        "Xiaohui Shen",
        "Liang-Chieh Chen"
      ],
      "abstract": "We present 1.58-bit FLUX, the first successful approach to quantizing the\nstate-of-the-art text-to-image generation model, FLUX.1-dev, using 1.58-bit\nweights (i.e., values in {-1, 0, +1}) while maintaining comparable performance\nfor generating 1024 x 1024 images. Notably, our quantization method operates\nwithout access to image data, relying solely on self-supervision from the\nFLUX.1-dev model. Additionally, we develop a custom kernel optimized for\n1.58-bit operations, achieving a 7.7x reduction in model storage, a 5.1x\nreduction in inference memory, and improved inference latency. Extensive\nevaluations on the GenEval and T2I Compbench benchmarks demonstrate the\neffectiveness of 1.58-bit FLUX in maintaining generation quality while\nsignificantly enhancing computational efficiency.",
      "tldr_zh": "我们提出了 1.58-bit FLUX，这是首个成功将先进的文本到图像生成模型 FLUX.1-dev 量化到 1.58-bit 权重（值在 {-1, 0, +1}）的方法，同时保持了生成 1024 x 1024 图像的性能。该量化过程不依赖图像数据，仅使用模型的自监督技术，并开发了自定义内核，实现了模型存储减少 7.7 倍、推理内存减少 5.1 倍以及推理延迟的优化。在 GenEval 和 T2I Compbench 基准测试中，1.58-bit FLUX 证明了其在维持生成质量的同时显著提升计算效率的表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18653v1",
      "published_date": "2024-12-24 19:00:02 UTC",
      "updated_date": "2024-12-24 19:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:10:11.283104"
    },
    {
      "arxiv_id": "2412.18601v1",
      "title": "Decentralized Intelligence in GameFi: Embodied AI Agents and the Convergence of DeFi and Virtual Ecosystems",
      "title_zh": "GameFi 中的去中心化智能：具身 AI 代理以及 DeFi 与虚拟生态系统的融合",
      "authors": [
        "Fernando Jia",
        "Jade Zheng",
        "Florence Li"
      ],
      "abstract": "In the rapidly evolving landscape of GameFi, a fusion of gaming and\ndecentralized finance (DeFi), there exists a critical need to enhance player\nengagement and economic interaction within gaming ecosystems. Our GameFi\necosystem aims to fundamentally transform this landscape by integrating\nadvanced embodied AI agents into GameFi platforms. These AI agents, developed\nusing cutting-edge large language models (LLMs), such as GPT-4 and Claude AI,\nare capable of proactive, adaptive, and contextually rich interactions with\nplayers. By going beyond traditional scripted responses, these agents become\nintegral participants in the game's narrative and economic systems, directly\ninfluencing player strategies and in-game economies. We address the limitations\nof current GameFi platforms, which often lack immersive AI interactions and\nmechanisms for community engagement or creator monetization. Through the deep\nintegration of AI agents with blockchain technology, we establish a\nconsensus-driven, decentralized GameFi ecosystem. This ecosystem empowers\ncreators to monetize their contributions and fosters democratic collaboration\namong players and creators. Furthermore, by embedding DeFi mechanisms into the\ngaming experience, we enhance economic participation and provide new\nopportunities for financial interactions within the game. Our approach enhances\nplayer immersion and retention and advances the GameFi ecosystem by bridging\ntraditional gaming with Web3 technologies. By integrating sophisticated AI and\nDeFi elements, we contribute to the development of more engaging, economically\nrobust, and community-centric gaming environments. This project represents a\nsignificant advancement in the state-of-the-art in GameFi, offering insights\nand methodologies that can be applied throughout the gaming industry.",
      "tldr_zh": "这篇论文探讨了GameFi（游戏与DeFi的融合）领域的decentralized intelligence，通过整合embodied AI agents来提升玩家参与和经济互动。研究利用先进的LLMs（如GPT-4和Claude AI）开发这些AI代理，实现主动、适应性的游戏叙事和经济系统互动，并与区块链技术深度结合，构建一个consensus-driven的decentralized GameFi ecosystem。论文解决了当前平台缺乏沉浸式AI互动和创作者货币化的问题，促进玩家与创作者的民主合作，并通过嵌入DeFi机制增强游戏内的经济参与，最终为更具吸引力和社区导向的游戏环境提供创新方法和insights。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18601v1",
      "published_date": "2024-12-24 18:56:00 UTC",
      "updated_date": "2024-12-24 18:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:10:21.154534"
    },
    {
      "arxiv_id": "2412.18597v2",
      "title": "DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Minghong Cai",
        "Xiaodong Cun",
        "Xiaoyu Li",
        "Wenze Liu",
        "Zhaoyang Zhang",
        "Yong Zhang",
        "Ying Shan",
        "Xiangyu Yue"
      ],
      "abstract": "Sora-like video generation models have achieved remarkable progress with a\nMulti-Modal Diffusion Transformer MM-DiT architecture. However, the current\nvideo generation models predominantly focus on single-prompt, struggling to\ngenerate coherent scenes with multiple sequential prompts that better reflect\nreal-world dynamic scenarios. While some pioneering works have explored\nmulti-prompt video generation, they face significant challenges including\nstrict training data requirements, weak prompt following, and unnatural\ntransitions. To address these problems, we propose DiTCtrl, a training-free\nmulti-prompt video generation method under MM-DiT architectures for the first\ntime. Our key idea is to take the multi-prompt video generation task as\ntemporal video editing with smooth transitions. To achieve this goal, we first\nanalyze MM-DiT's attention mechanism, finding that the 3D full attention\nbehaves similarly to that of the cross/self-attention blocks in the UNet-like\ndiffusion models, enabling mask-guided precise semantic control across\ndifferent prompts with attention sharing for multi-prompt video generation.\nBased on our careful design, the video generated by DiTCtrl achieves smooth\ntransitions and consistent object motion given multiple sequential prompts\nwithout additional training. Besides, we also present MPVBench, a new benchmark\nspecially designed for multi-prompt video generation to evaluate the\nperformance of multi-prompt generation. Extensive experiments demonstrate that\nour method achieves state-of-the-art performance without additional training.",
      "tldr_zh": "该论文提出了 DiTCrl，一种无需训练的多提示视频生成方法，基于 Multi-Modal Diffusion Transformer (MM-DiT) 架构，旨在解决现有模型在处理多提示时存在的弱提示跟随和不自然过渡等问题。核心机制是通过分析 MM-DiT 的 3D 全注意力机制，将多提示视频生成视为时序视频编辑，实现精确语义控制和平滑过渡，同时保持物体运动的一致性。该方法还引入了新的基准 MPVBench 用于评估多提示生成性能，实验结果显示 DiTCrl 在各种场景下实现了最先进性能，而无需额外训练。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025; 21 pages, 23 figures, Project page:\n  https://onevfall.github.io/project_page/ditctrl ; GitHub repository:\n  https://github.com/TencentARC/DiTCtrl",
      "pdf_url": "http://arxiv.org/pdf/2412.18597v2",
      "published_date": "2024-12-24 18:51:19 UTC",
      "updated_date": "2025-03-26 09:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:10:34.766731"
    },
    {
      "arxiv_id": "2412.18588v1",
      "title": "A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "OpenMind",
        "Shaohong Zhong",
        "Adam Zhou",
        "Boyuan Chen",
        "Homin Luo",
        "Jan Liphardt"
      ],
      "abstract": "Large Language Models (LLMs) are compact representations of all public\nknowledge of our physical environment and animal and human behaviors. The\napplication of LLMs to robotics may offer a path to highly capable robots that\nperform well across most human tasks with limited or even zero tuning. Aside\nfrom increasingly sophisticated reasoning and task planning, networks of\n(suitably designed) LLMs offer ease of upgrading capabilities and allow humans\nto directly observe the robot's thinking. Here we explore the advantages,\nlimitations, and particularities of using LLMs to control physical robots. The\nbasic system consists of four LLMs communicating via a human language data bus\nimplemented via web sockets and ROS2 message passing. Surprisingly, rich robot\nbehaviors and good performance across different tasks could be achieved despite\nthe robot's data fusion cycle running at only 1Hz and the central data bus\nrunning at the extremely limited rates of the human brain, of around 40 bits/s.\nThe use of natural language for inter-LLM communication allowed the robot's\nreasoning and decision making to be directly observed by humans and made it\ntrivial to bias the system's behavior with sets of rules written in plain\nEnglish. These rules were immutably written into Ethereum, a global, public,\nand censorship resistant Turing-complete computer. We suggest that by using\nnatural language as the data bus among interacting AIs, and immutable public\nledgers to store behavior constraints, it is possible to build robots that\ncombine unexpectedly rich performance, upgradability, and durable alignment\nwith humans.",
      "tldr_zh": "该研究探讨了利用大型语言模型(LLMs)来实现丰富机器人行为的潜力，仅需一段文字即可驱动机器人执行多种人类任务。系统由四个LLMs通过人类语言数据总线（如web sockets和ROS2消息传递）交互通信，即使在低速率（如1Hz数据融合和40 bits/s总线）条件下，仍能实现良好的任务性能和可观察性。论文强调，使用自然语言作为AI间通信方式，并将行为规则以英文形式不可变地存储在Ethereum上，能够构建出性能强大、可升级且与人类对齐的机器人系统。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.18588v1",
      "published_date": "2024-12-24 18:41:15 UTC",
      "updated_date": "2024-12-24 18:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:10:45.752265"
    },
    {
      "arxiv_id": "2412.18647v1",
      "title": "Nationality, Race, and Ethnicity Biases in and Consequences of Detecting AI-Generated Self-Presentations",
      "title_zh": "翻译失败",
      "authors": [
        "Haoran Chu",
        "Linjuan Rita Men",
        "Sixiao Liu",
        "Shupei Yuan",
        "Yuan Sun"
      ],
      "abstract": "This study builds on person perception and human AI interaction (HAII)\ntheories to investigate how content and source cues, specifically race,\nethnicity, and nationality, affect judgments of AI-generated content in a\nhigh-stakes self-presentation context: college applications. Results of a\npre-registered experiment with a nationally representative U.S. sample (N =\n644) show that content heuristics, such as linguistic style, played a dominant\nrole in AI detection. Source heuristics, such as nationality, also emerged as a\nsignificant factor, with international students more likely to be perceived as\nusing AI, especially when their statements included AI-sounding features.\nInterestingly, Asian and Hispanic applicants were more likely to be judged as\nAI users when labeled as domestic students, suggesting interactions between\nracial stereotypes and AI detection. AI attribution led to lower perceptions of\npersonal statement quality and authenticity, as well as negative evaluations of\nthe applicant's competence, sociability, morality, and future success.",
      "tldr_zh": "本研究基于人际感知和人类 AI 交互 (HAII) 理论，探讨种族、民族和国籍等内容和来源线索如何影响对 AI-generated self-presentations 的检测偏见，特别是在大学申请这种高风险情境中。通过一个预注册实验，使用美国全国代表性样本 (N=644)，结果显示语言风格等内容启发式在 AI 检测中起主导作用，而国籍启发式则导致国际学生更容易被误判为使用 AI，尤其当陈述包含 AI 特征时。进一步发现，亚洲和西班牙裔申请者在被标记为国内学生时，更可能被判断为 AI 用户，这反映了种族刻板印象与检测过程的互动；此外，AI 归因会降低对个人陈述质量、真实性以及申请者能力、社交性、道德性和未来成功的评价。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18647v1",
      "published_date": "2024-12-24 18:31:44 UTC",
      "updated_date": "2024-12-24 18:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:10:59.637179"
    },
    {
      "arxiv_id": "2412.18573v2",
      "title": "Top General Performance = Top Domain Performance? DomainCodeBench: A Multi-domain Code Generation Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Dewu Zheng",
        "Yanlin Wang",
        "Ensheng Shi",
        "Xilin Liu",
        "Yuchi Ma",
        "Hongyu Zhang",
        "Zibin Zheng"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), extensive\nresearch has been conducted to investigate the code generation capabilities of\nLLMs. However, existing efforts primarily focus on general-domain tasks,\nleaving LLMs' code generation performance in real-world application domains\nunderexplored. This raises a critical question: can a model's general-domain\ncoding ability reliably represent its ability in specialized domains? In this\npaper, we introduce DomainCodeBench, a multi-domain code generation benchmark\ndesigned to systematically evaluate LLMs across 12 software application domains\nand 15 programming languages. DomainCodeBench contains 2,400 manually verified\ntasks with ground truth, human-annotated docstrings, and fine-grained\ndependency information to ensure more coverage of domain-specific challenges.\nSpecifically, we first identify the most popular application domains by topic\nmining. Then, we curate coding tasks based on commonly used frameworks and\nplatforms in each domain. We obtain several findings through extensive\nexperiments on DomainCodeBench with ten mainstream LLMs. (1) Performance\ndecoupling: experiments reveal that top general-domain models do not\nconsistently excel in specific application domains; (2) Domain-specific\nweaknesses: LLMs often fail due to domain knowledge gaps and third-party\nlibrary misusage; (3) Contextual enhancement: we show that augmenting prompts\nwith domain-specific knowledge improves performance by around 38.17%, providing\nactionable insights for performance optimization. Our replication package,\nincluding the benchmark, source code, and experimental results, is available at\nhttps://github.com/DeepSoftwareAnalytics/DomainCodeBench.",
      "tldr_zh": "这篇论文引入了 DomainCodeBench，一个多领域代码生成基准，用于系统评估大型语言模型 (LLMs) 在 12 个软件应用领域和 15 种编程语言中的性能，共包含 2400 个手动验证的任务，以覆盖领域特定挑战。研究通过主题挖掘和基于常用框架的任务收集方法，揭示了关键发现：顶级通用领域模型在特定领域不一定表现出色，常因领域知识缺口和第三方库误用而失败。实验还显示，通过在提示中添加领域特定知识，可将性能提升约 38.17%，为优化 LLMs 的代码生成能力提供了实用见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18573v2",
      "published_date": "2024-12-24 17:56:08 UTC",
      "updated_date": "2025-03-17 17:58:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:11:09.673893"
    },
    {
      "arxiv_id": "2501.03250v1",
      "title": "Machine Learning and Deep Learning Techniques used in Cybersecurity and Digital Forensics: a Review",
      "title_zh": "翻译失败",
      "authors": [
        "Jaouhar Fattahi"
      ],
      "abstract": "In the paced realms of cybersecurity and digital forensics machine learning\n(ML) and deep learning (DL) have emerged as game changing technologies that\nintroduce methods to identify stop and analyze cyber risks. This review\npresents an overview of the ML and DL approaches used in these fields\nshowcasing their advantages drawbacks and possibilities. It covers a range of\nAI techniques used in spotting intrusions in systems and classifying malware to\nprevent cybersecurity attacks, detect anomalies and enhance resilience. This\nstudy concludes by highlighting areas where further research is needed and\nsuggesting ways to create transparent and scalable ML and DL solutions that are\nsuited to the evolving landscape of cybersecurity and digital forensics.",
      "tldr_zh": "这篇综述论文探讨了Machine Learning (ML) 和 Deep Learning (DL) 在Cybersecurity 和 Digital Forensics 领域的应用，概述了这些技术在识别入侵、分类恶意软件和检测异常方面的优势、缺点以及潜在可能性。论文分析了ML和DL如何提升系统防御和风险分析能力，同时强调了这些方法的局限性，如可解释性和可扩展性问题。最终，它指出未来研究应聚焦于开发更透明、可扩展的解决方案，以适应网络安全和数字取证领域的快速发展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.03250v1",
      "published_date": "2024-12-24 17:22:51 UTC",
      "updated_date": "2024-12-24 17:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:11:20.931784"
    },
    {
      "arxiv_id": "2412.18547v4",
      "title": "Token-Budget-Aware LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Tingxu Han",
        "Zhenting Wang",
        "Chunrong Fang",
        "Shiyu Zhao",
        "Shiqing Ma",
        "Zhenyu Chen"
      ],
      "abstract": "Reasoning is critical for large language models (LLMs) to excel in a wide\nrange of tasks. While methods like Chain-of-Thought (CoT) reasoning enhance LLM\nperformance by decomposing problems into intermediate steps, they also incur\nsignificant overhead in token usage, leading to increased costs. We find that\nthe reasoning process of current LLMs is unnecessarily lengthy and it can be\ncompressed by including a reasonable token budget in the prompt, but the choice\nof token budget plays a crucial role in the actual compression effectiveness.\nWe then propose a token-budget-aware LLM reasoning framework, which dynamically\nestimates token budgets for different problems based on reasoning complexity\nand uses the estimated token budgets to guide the reasoning process.\nExperiments show that our method effectively reduces token costs in CoT\nreasoning with only a slight performance reduction, offering a practical\nsolution to balance efficiency and accuracy in LLM reasoning. Code:\nhttps://github.com/GeniusHTX/TALE.",
      "tldr_zh": "本研究发现，Chain-of-Thought (CoT) 等推理方法虽能提升大型语言模型 (LLMs) 的性能，但会显著增加 token 使用成本，且当前 LLMs 的推理过程可通过合理设置 token 预算来压缩。该论文提出了一种 token-budget-aware LLM reasoning 框架，该框架根据问题复杂性动态估计 token 预算，并用其指导推理过程。实验结果表明，该方法在 CoT 推理中有效降低了 token 成本，同时仅略微降低性能，从而提供了一个平衡效率与准确性的实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18547v4",
      "published_date": "2024-12-24 16:55:45 UTC",
      "updated_date": "2025-02-17 15:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:11:33.440839"
    },
    {
      "arxiv_id": "2412.18545v1",
      "title": "Advancing Deformable Medical Image Registration with Multi-axis Cross-covariance Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Mingyuan Meng",
        "Michael Fulham",
        "Lei Bi",
        "Jinman Kim"
      ],
      "abstract": "Deformable image registration is a fundamental requirement for medical image\nanalysis. Recently, transformers have been widely used in deep learning-based\nregistration methods for their ability to capture long-range dependency via\nself-attention (SA). However, the high computation and memory loads of SA\n(growing quadratically with the spatial resolution) hinder transformers from\nprocessing subtle textural information in high-resolution image features, e.g.,\nat the full and half image resolutions. This limits deformable registration as\nthe high-resolution textural information is crucial for finding precise\npixel-wise correspondence between subtle anatomical structures.\nCross-covariance Attention (XCA), as a \"transposed\" version of SA that operates\nacross feature channels, has complexity growing linearly with the spatial\nresolution, providing the feasibility of capturing long-range dependency among\nhigh-resolution image features. However, existing XCA-based transformers merely\ncapture coarse global long-range dependency, which are unsuitable for\ndeformable image registration relying primarily on fine-grained local\ncorrespondence. In this study, we propose to improve existing deep\nlearning-based registration methods by embedding a new XCA mechanism. To this\nend, we design an XCA-based transformer block optimized for deformable medical\nimage registration, named Multi-Axis XCA (MAXCA). Our MAXCA serves as a general\nnetwork block that can be embedded into various registration network\narchitectures. It can capture both global and local long-range dependency among\nhigh-resolution image features by applying regional and dilated XCA in parallel\nvia a multi-axis design. Extensive experiments on two well-benchmarked\ninter-/intra-patient registration tasks with seven public medical datasets\ndemonstrate that our MAXCA block enables state-of-the-art registration\nperformance.",
      "tldr_zh": "该论文针对 deformable image registration 在医疗图像分析中的挑战，指出传统 Transformer 的 self-attention (SA) 在处理高分辨率图像时计算量过大，无法有效捕捉细微纹理信息。作者提出 Multi-Axis Cross-covariance Attention (MAXCA)，一种新的 XCA 机制，通过并行应用 regional 和 dilated XCA 来捕捉高分辨率图像特征的全局和局部长距离依赖，从而优化注册网络架构。实验结果显示，在七个公共数据集上的 inter-/intra-patient 注册任务中，MAXCA 模块实现了 state-of-the-art 性能，显著提升了注册准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2412.18545v1",
      "published_date": "2024-12-24 16:52:21 UTC",
      "updated_date": "2024-12-24 16:52:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:11:47.172762"
    },
    {
      "arxiv_id": "2412.18544v2",
      "title": "Consistency Checks for Language Model Forecasters",
      "title_zh": "针对语言模型预测器的一致性检查",
      "authors": [
        "Daniel Paleka",
        "Abhimanyu Pallavi Sudhir",
        "Alejandro Alvarez",
        "Vineeth Bhat",
        "Adam Shen",
        "Evan Wang",
        "Florian Tramèr"
      ],
      "abstract": "Forecasting is a task that is difficult to evaluate: the ground truth can\nonly be known in the future. Recent work showing LLM forecasters rapidly\napproaching human-level performance begs the question: how can we benchmark and\nevaluate these forecasters instantaneously? Following the consistency check\nframework, we measure the performance of forecasters in terms of the\nconsistency of their predictions on different logically-related questions. We\npropose a new, general consistency metric based on arbitrage: for example, if a\nforecasting AI illogically predicts that both the Democratic and Republican\nparties have 60% probability of winning the 2024 US presidential election, an\narbitrageur can trade against the forecaster's predictions and make a profit.\nWe build an automated evaluation system that generates a set of base questions,\ninstantiates consistency checks from these questions, elicits the predictions\nof the forecaster, and measures the consistency of the predictions. We then\nbuild a standard, proper-scoring-rule forecasting benchmark, and show that our\n(instantaneous) consistency metrics correlate with LLM forecasters' ground\ntruth Brier scores (which are only known in the future). We also release a\nconsistency benchmark that resolves in 2028, providing a long-term evaluation\ntool for forecasting.",
      "tldr_zh": "这篇论文针对语言模型预测器的评估挑战，提出了一种基于一致性检查的框架，利用 arbitrage（套利）指标来即时衡量预测的一致性，例如检测模型在逻辑相关问题上的矛盾预测。研究构建了一个自动化系统，能够生成基础问题、实例化一致性检查、获取模型预测并计算一致性分数。结果显示，该指标与未来 Brier scores 高度相关，为语言模型预测提供了一个可靠的即时基准，并发布了到 2028 年的长期一致性基准测试。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "55 pages, 25 figures. Submitted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18544v2",
      "published_date": "2024-12-24 16:51:35 UTC",
      "updated_date": "2025-01-10 01:06:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:11:58.713929"
    },
    {
      "arxiv_id": "2412.18530v1",
      "title": "Characterizations of Language Generation With Breadth",
      "title_zh": "翻译失败",
      "authors": [
        "Alkis Kalavasis",
        "Anay Mehrotra",
        "Grigoris Velegkas"
      ],
      "abstract": "We study language generation in the limit, introduced by Kleinberg and\nMullainathan [KM24], building on classical works of Gold [Gol67] and Angluin\n[Ang79]. [KM24] proposed an algorithm that generates strings from any countable\nlanguage collection in the limit. While their algorithm eventually outputs\nstrings from the target language $K$, it sacrifices breadth, i.e., the ability\nto generate all strings in $K$. A key open question in [KM24] is whether this\ntrade-off between consistency and breadth is inherrent.\n  Recent works proposed different notions of consistent generation with\nbreadth. Kalavasis, Mehrotra, and Velegkas [KVM24] introduced three\ndefinitions: generation with exact breadth, approximate breadth, and\nunambiguous generation. Concurrently and independently, Charikar and Pabbaraju\n[CP24a] proposed exhaustive generation. Both works examined when generation\nwith these notions of breadth is possible.\n  Building on [CP24a, KVM24], we fully characterize language generation for\nthese notions and their natural combinations. For exact breadth, we provide an\nunconditional lower bound, removing a technical condition from [KVM24] and\nextending the result of [CP24a] that holds for specific collections of\nlanguages. We show that generation with exact breadth is characterized by\nAngluin's condition for identification. We further introduce a weaker version\nof Angluin's condition that tightly characterizes both approximate breadth and\nexhaustive generation, proving their equivalence. Additionally, we show that\nunambiguous generation is also characterized by Angluin's condition as a\nspecial case of a broader result. Finally, we strengthen [KVM24] by giving\nunconditional lower bounds for stable generators, showing that Angluin's\ncondition characterizes the previous breadth notions for stable generators.\nThis shows a separation between stable and unstable generation with approximate\nbreadth.",
      "tldr_zh": "本论文探讨了语言生成（language generation）的广度（breadth）概念，构建在Gold [Gol67]、Angluin [Ang79]和Kleinberg及Mullainathan [KM24]等经典工作的基础上，分析了生成算法在一致性和广度之间的权衡。研究全面表征了exact breadth、approximate breadth、unambiguous generation和exhaustive generation这些概念，证明了exact breadth由Angluin's condition表征，而approximate breadth和exhaustive generation则由一个更弱版本的条件紧致表征。最终，论文提供了无条件下界，展示了stable和unstable生成之间的分离，并扩展了先前工作的结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Abstract shortened to fix arXiv limit",
      "pdf_url": "http://arxiv.org/pdf/2412.18530v1",
      "published_date": "2024-12-24 16:24:43 UTC",
      "updated_date": "2024-12-24 16:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:12:11.647960"
    },
    {
      "arxiv_id": "2412.18644v3",
      "title": "DynaGRAG | Exploring the Topology of Information for Advancing Language Understanding and Generation in Graph Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Karishma Thakrar"
      ],
      "abstract": "Graph Retrieval-Augmented Generation (GRAG or Graph RAG) architectures aim to\nenhance language understanding and generation by leveraging external knowledge.\nHowever, effectively capturing and integrating the rich semantic information\npresent in textual and structured data remains a challenge. To address this, a\nnovel GRAG framework, Dynamic Graph Retrieval-Agumented Generation (DynaGRAG),\nis proposed to focus on enhancing subgraph representation and diversity within\nthe knowledge graph. By improving graph density, capturing entity and relation\ninformation more effectively, and dynamically prioritizing relevant and diverse\nsubgraphs and information within them, the proposed approach enables a more\ncomprehensive understanding of the underlying semantic structure. This is\nachieved through a combination of de-duplication processes, two-step mean\npooling of embeddings, query-aware retrieval considering unique nodes, and a\nDynamic Similarity-Aware BFS (DSA-BFS) traversal algorithm. Integrating Graph\nConvolutional Networks (GCNs) and Large Language Models (LLMs) through hard\nprompting further enhances the learning of rich node and edge representations\nwhile preserving the hierarchical subgraph structure. Experimental results\ndemonstrate the effectiveness of DynaGRAG, showcasing the significance of\nenhanced subgraph representation and diversity for improved language\nunderstanding and generation.",
      "tldr_zh": "该研究提出DynaGRAG框架，以提升Graph Retrieval-Augmented Generation (GRAG)中语言理解和生成的性能，通过增强子图表示和多样性来解决语义信息捕捉的挑战。\nDynaGRAG采用去重过程、两步均值池化、查询感知检索以及Dynamic Similarity-Aware BFS (DSA-BFS)遍历算法，并整合Graph Convolutional Networks (GCNs)和Large Language Models (LLMs)通过硬提示，动态优先相关子图以更有效地捕捉实体和关系信息。\n实验结果表明，DynaGRAG显著提高了语言理解和生成的整体效果，突出了增强子图表示和多样性的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18644v3",
      "published_date": "2024-12-24 16:06:53 UTC",
      "updated_date": "2025-01-28 14:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:12:23.536554"
    },
    {
      "arxiv_id": "2412.18500v1",
      "title": "Joint Adaptive OFDM and Reinforcement Learning Design for Autonomous Vehicles: Leveraging Age of Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Mamady Delamou",
        "Ahmed Naeem",
        "Huseyin Arslan",
        "El Mehdi Amhoud"
      ],
      "abstract": "Millimeter wave (mmWave)-based orthogonal frequency-division multiplexing\n(OFDM) stands out as a suitable alternative for high-resolution sensing and\nhigh-speed data transmission. To meet communication and sensing requirements,\nmany works propose a static configuration where the wave's hyperparameters such\nas the number of symbols in a frame and the number of frames in a communication\nslot are already predefined. However, two facts oblige us to redefine the\nproblem, (1) the environment is often dynamic and uncertain, and (2) mmWave is\nseverely impacted by wireless environments. A striking example where this\nchallenge is very prominent is autonomous vehicle (AV). Such a system leverages\nintegrated sensing and communication (ISAC) using mmWave to manage data\ntransmission and the dynamism of the environment. In this work, we consider an\nautonomous vehicle network where an AV utilizes its queue state information\n(QSI) and channel state information (CSI) in conjunction with reinforcement\nlearning techniques to manage communication and sensing. This enables the AV to\nachieve two primary objectives: establishing a stable communication link with\nother AVs and accurately estimating the velocities of surrounding objects with\nhigh resolution. The communication performance is therefore evaluated based on\nthe queue state, the effective data rate, and the discarded packets rate. In\ncontrast, the effectiveness of the sensing is assessed using the velocity\nresolution. In addition, we exploit adaptive OFDM techniques for dynamic\nmodulation, and we suggest a reward function that leverages the age of updates\nto handle the communication buffer and improve sensing. The system is validated\nusing advantage actor-critic (A2C) and proximal policy optimization (PPO).\nFurthermore, we compare our solution with the existing design and demonstrate\nits superior performance by computer simulations.",
      "tldr_zh": "这篇论文提出了一种结合自适应 OFDM 和 Reinforcement Learning 的联合设计，用于自动驾驶车辆 (AV)，以应对动态不确定环境下的通信和感知挑战，特别是利用 Age of Updates 优化系统性能。方法通过整合队列状态信息 (QSI) 和信道状态信息 (CSI)，实现稳定的通信链接（如基于队列状态、有效数据率和丢弃包率评估）和高分辨率物体速度估计。实验采用 A2C 和 PPO 算法进行验证，结果显示该方案比现有设计提升了性能，通过计算机模拟证明其优越性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "15 pages, 17 Figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18500v1",
      "published_date": "2024-12-24 15:32:58 UTC",
      "updated_date": "2024-12-24 15:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:12:36.632643"
    },
    {
      "arxiv_id": "2412.18495v1",
      "title": "How \"Real\" is Your Real-Time Simultaneous Speech-to-Text Translation System?",
      "title_zh": "你的实时同步语音到文本翻译系统到底有多“真实”？",
      "authors": [
        "Sara Papi",
        "Peter Polak",
        "Ondřej Bojar",
        "Dominik Macháček"
      ],
      "abstract": "Simultaneous speech-to-text translation (SimulST) translates source-language\nspeech into target-language text concurrently with the speaker's speech,\nensuring low latency for better user comprehension. Despite its intended\napplication to unbounded speech, most research has focused on human\npre-segmented speech, simplifying the task and overlooking significant\nchallenges. This narrow focus, coupled with widespread terminological\ninconsistencies, is limiting the applicability of research outcomes to\nreal-world applications, ultimately hindering progress in the field. Our\nextensive literature review of 110 papers not only reveals these critical\nissues in current research but also serves as the foundation for our key\ncontributions. We 1) define the steps and core components of a SimulST system,\nproposing a standardized terminology and taxonomy; 2) conduct a thorough\nanalysis of community trends, and 3) offer concrete recommendations and future\ndirections to bridge the gaps in existing literature, from evaluation\nframeworks to system architectures, for advancing the field towards more\nrealistic and effective SimulST solutions.",
      "tldr_zh": "本论文质疑当前实时同步语音到文本翻译（SimulST）系统的真实性，指出研究多聚焦于预分割语音而忽略真实场景的挑战，如延迟和术语不一致问题，从而限制了实际应用。作者通过对110篇文献的全面回顾，定义了SimulST系统的核心步骤和组件，并提出标准化术语和分类体系。论文还分析了社区趋势，并提供具体建议和未来方向，包括改进评估框架和系统架构，以推动SimulST领域向更可靠有效的解决方案发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at TACL",
      "pdf_url": "http://arxiv.org/pdf/2412.18495v1",
      "published_date": "2024-12-24 15:26:31 UTC",
      "updated_date": "2024-12-24 15:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:12:46.378985"
    },
    {
      "arxiv_id": "2412.18489v1",
      "title": "An Overview and Discussion of the Suitability of Existing Speech Datasets to Train Machine Learning Models for Collective Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Gnaneswar Villuri",
        "Alex Doboli"
      ],
      "abstract": "This report characterized the suitability of existing datasets for devising\nnew Machine Learning models, decision making methods, and analysis algorithms\nto improve Collaborative Problem Solving and then enumerated requirements for\nfuture datasets to be devised. Problem solving was assumed to be performed in\nteams of about three, four members, which talked to each other. A dataset\nconsists of the speech recordings of such teams. The characterization\nmethodology was based on metrics that capture cognitive, social, and emotional\nactivities and situations. The report presented the analysis of a large group\nof datasets developed for Spoken Language Understanding, a research area with\nsome similarity to Collaborative Problem Solving.",
      "tldr_zh": "该报告概述并讨论了现有语音数据集的适用性，用于训练机器学习（Machine Learning）模型以提升集体问题解决（Collaborative Problem Solving）。研究假设问题解决发生在3-4人的团队中，通过语音对话进行，并基于捕捉认知、社会和情感活动的指标对数据集进行表征。分析结果显示，这些数据集主要来自Spoken Language Understanding领域，但存在局限性，因此论文列出了未来数据集的设计要求，以支持开发新的决策方法和分析算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18489v1",
      "published_date": "2024-12-24 15:22:10 UTC",
      "updated_date": "2024-12-24 15:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:12:57.249041"
    },
    {
      "arxiv_id": "2412.18464v1",
      "title": "MotifGPL: Motif-Enhanced Graph Prototype Learning for Deciphering Urban Social Segregation",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei He",
        "Xiao Zhou"
      ],
      "abstract": "Social segregation in cities, spanning racial, residential, and income\ndimensions, is becoming more diverse and severe. As urban spaces and social\nrelations grow more complex, residents in metropolitan areas experience varying\nlevels of social segregation. If left unaddressed, this could lead to increased\ncrime rates, heightened social tensions, and other serious issues. Effectively\nquantifying and analyzing the structures within urban spaces and resident\ninteractions is crucial for addressing segregation. Previous studies have\nmainly focused on surface-level indicators of urban segregation, lacking\ncomprehensive analyses of urban structure and mobility. This limitation fails\nto capture the full complexity of segregation. To address this gap, we propose\na framework named Motif-Enhanced Graph Prototype Learning (MotifGPL),which\nconsists of three key modules: prototype-based graph structure extraction,\nmotif distribution discovery, and urban graph structure reconstruction.\nSpecifically, we use graph structure prototype learning to extract key\nprototypes from both the urban spatial graph and the origin-destination graph,\nincorporating key urban attributes such as points of interest, street view\nimages, and flow indices. To enhance interpretability, the motif distribution\ndiscovery module matches each prototype with similar motifs, representing\nsimpler graph structures reflecting local patterns. Finally, we use the motif\ndistribution results to guide the reconstruction of the two graphs. This model\nenables a detailed exploration of urban spatial structures and resident\nmobility patterns, helping identify and analyze motif patterns that influence\nurban segregation, guiding the reconstruction of urban graph structures.\nExperimental results demonstrate that MotifGPL effectively reveals the key\nmotifs affecting urban social segregation and offer robust guidance for\nmitigating this issue.",
      "tldr_zh": "本研究针对城市社会隔离（如种族、住宅和收入维度）的多样性和严重性，提出MotifGPL框架，以更全面地分析城市空间结构和居民互动。MotifGPL包括三个关键模块：基于原型的图结构提取（结合兴趣点、街景图像和流动指数）、motif分布发现（匹配原型以提升可解释性），以及城市图结构重建，通过motif模式指导空间和流动性图的重建。实验结果表明，该框架有效识别影响社会隔离的关键motif模式，并提供指导以缓解城市隔离问题。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI-25); 10 pages, 8 figures, 3 tables; Includes the appendix",
      "pdf_url": "http://arxiv.org/pdf/2412.18464v1",
      "published_date": "2024-12-24 14:50:11 UTC",
      "updated_date": "2024-12-24 14:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:13:10.241807"
    },
    {
      "arxiv_id": "2412.18460v2",
      "title": "GeFL: Model-Agnostic Federated Learning with Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Honggu Kang",
        "Seohyeon Cha",
        "Joonhyuk Kang"
      ],
      "abstract": "Federated learning (FL) is a distributed training paradigm that enables\ncollaborative learning across clients without sharing local data, thereby\npreserving privacy. However, the increasing scale and complexity of modern deep\nmodels often exceed the computational or memory capabilities of edge devices.\nFurthermore, clients may be constrained to use heterogeneous model\narchitectures due to hardware variability (e.g., ASICs, FPGAs) or proprietary\nrequirements that prevent the disclosure or modification of local model\nstructures. These practical considerations motivate the need for\nmodel-heterogeneous FL, where clients participate using distinct model\narchitectures. In this work, we propose Generative Model-Aided Federated\nLearning (GeFL), a framework that enables cross-client knowledge sharing via a\ngenerative model trained in a federated manner. This generative model captures\nglobal data semantics and facilitates local training without requiring model\nhomogeneity across clients. While GeFL achieves strong performance, empirical\nanalysis reveals limitations in scalability and potential privacy leakage due\nto generative sample memorization. To address these concerns, we propose\nGeFL-F, which utilizes feature-level generative modeling. This approach\nenhances scalability to large client populations and mitigates privacy risks.\nExtensive experiments across image classification tasks demonstrate that both\nGeFL and GeFL-F offer competitive performance in heterogeneous settings. Code\nis available at [1].",
      "tldr_zh": "本论文提出 GeFL 框架，这是一种模型无关的联邦学习（Federated Learning）方法，通过在联邦方式下训练生成模型（Generative Models），实现跨客户端知识共享，而无需客户端模型架构保持一致，从而解决边缘设备计算限制和模型异构问题。GeFL 通过生成模型捕获全局数据语义，支持本地训练，但存在可扩展性不足和潜在隐私泄露风险，如生成样本记忆。针对这些问题，作者引入 GeFL-F，使用特征级生成建模（feature-level generative modeling）来提升可扩展性和缓解隐私风险。在图像分类任务的广泛实验中，GeFL 和 GeFL-F 在异构设置中表现出与基准模型相当的竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18460v2",
      "published_date": "2024-12-24 14:39:47 UTC",
      "updated_date": "2025-05-17 02:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:13:22.984635"
    },
    {
      "arxiv_id": "2412.18454v1",
      "title": "Multi-Agent Norm Perception and Induction in Distributed Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Li",
        "Olga Petruchik",
        "Elizaveta Grishanina",
        "Sergey Kovalchuk"
      ],
      "abstract": "This paper presents a Multi-Agent Norm Perception and Induction Learning\nModel aimed at facilitating the integration of autonomous agent systems into\ndistributed healthcare environments through dynamic interaction processes. The\nnature of the medical norm system and its sharing channels necessitates\ndistinct approaches for Multi-Agent Systems to learn two types of norms.\nBuilding on this foundation, the model enables agents to simultaneously learn\ndescriptive norms, which capture collective tendencies, and prescriptive norms,\nwhich dictate ideal behaviors. Through parameterized mixed probability density\nmodels and practice-enhanced Markov games, the multi-agent system perceives\ndescriptive norms in dynamic interactions and captures emergent prescriptive\nnorms. We conducted experiments using a dataset from a neurological medical\ncenter spanning from 2016 to 2020.",
      "tldr_zh": "本论文提出了一种 Multi-Agent Norm Perception and Induction Learning Model，用于在分布式医疗环境中整合自主代理系统，通过动态交互过程学习规范。该模型使代理能够同时感知 descriptive norms（捕捉集体倾向）和 prescriptive norms（规定理想行为），并利用 parameterized mixed probability density models 以及 practice-enhanced Markov games 来处理动态交互中的规范感知和涌现。实验基于 2016-2020 年神经科医疗中心的数据集，展示了该方法在医疗规范学习中的有效性。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "I.2.11; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages,8 figures,152 conferences,3 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.18454v1",
      "published_date": "2024-12-24 14:30:19 UTC",
      "updated_date": "2024-12-24 14:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:13:35.209284"
    },
    {
      "arxiv_id": "2412.18442v4",
      "title": "SoK: On the Offensive Potential of AI",
      "title_zh": "翻译失败",
      "authors": [
        "Saskia Laura Schröer",
        "Giovanni Apruzzese",
        "Soheil Human",
        "Pavel Laskov",
        "Hyrum S. Anderson",
        "Edward W. N. Bernroider",
        "Aurore Fass",
        "Ben Nassi",
        "Vera Rimmer",
        "Fabio Roli",
        "Samer Salam",
        "Ashley Shen",
        "Ali Sunyaev",
        "Tim Wadhwa-Brown",
        "Isabel Wagner",
        "Gang Wang"
      ],
      "abstract": "Our society increasingly benefits from Artificial Intelligence (AI).\nUnfortunately, more and more evidence shows that AI is also used for offensive\npurposes. Prior works have revealed various examples of use cases in which the\ndeployment of AI can lead to violation of security and privacy objectives. No\nextant work, however, has been able to draw a holistic picture of the offensive\npotential of AI. In this SoK paper we seek to lay the ground for a systematic\nanalysis of the heterogeneous capabilities of offensive AI. In particular we\n(i) account for AI risks to both humans and systems while (ii) consolidating\nand distilling knowledge from academic literature, expert opinions, industrial\nvenues, as well as laypeople -- all of which being valuable sources of\ninformation on offensive AI.\n  To enable alignment of such diverse sources of knowledge, we devise a common\nset of criteria reflecting essential technological factors related to offensive\nAI. With the help of such criteria, we systematically analyze: 95 research\npapers; 38 InfoSec briefings (from, e.g., BlackHat); the responses of a user\nstudy (N=549) entailing individuals with diverse backgrounds and expertise; and\nthe opinion of 12 experts. Our contributions not only reveal concerning ways\n(some of which overlooked by prior work) in which AI can be offensively used\ntoday, but also represent a foothold to address this threat in the years to\ncome.",
      "tldr_zh": "这篇 SoK 论文系统分析了 AI 的攻击性潜力，揭示了 AI 如何被用于侵犯安全和隐私目标，并整合了学术文献、专家意见、行业简报以及大众调查等多源知识。作者制定了一套共同标准，分析了95篇研究论文、38个 InfoSec 简报、一个涉及549人的用户研究，以及12位专家的反馈，以全面评估 AI 对人类和系统的风险。研究发现了一些先前被忽略的攻击方式，并为未来应对 AI 威胁提供了重要基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Systematization of Knowledge (SoK) paper. Accepted to the 3rd IEEE\n  Conference on Secure and Trustworthy Machine Learning (SaTML'25)",
      "pdf_url": "http://arxiv.org/pdf/2412.18442v4",
      "published_date": "2024-12-24 14:02:44 UTC",
      "updated_date": "2025-01-24 11:39:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:13:45.502873"
    },
    {
      "arxiv_id": "2412.18431v1",
      "title": "GeAR: Graph-enhanced Agent for Retrieval-augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili Shen",
        "Chenxin Diao",
        "Pavlos Vougiouklis",
        "Pascual Merita",
        "Shriram Piramanayagam",
        "Damien Graux",
        "Dandan Tu",
        "Zeren Jiang",
        "Ruofei Lai",
        "Yang Ren",
        "Jeff Z. Pan"
      ],
      "abstract": "Retrieval-augmented generation systems rely on effective document retrieval\ncapabilities. By design, conventional sparse or dense retrievers face\nchallenges in multi-hop retrieval scenarios. In this paper, we present GeAR,\nwhich advances RAG performance through two key innovations: (i) graph\nexpansion, which enhances any conventional base retriever, such as BM25, and\n(ii) an agent framework that incorporates graph expansion. Our evaluation\ndemonstrates GeAR's superior retrieval performance on three multi-hop question\nanswering datasets. Additionally, our system achieves state-of-the-art results\nwith improvements exceeding 10% on the challenging MuSiQue dataset, while\nrequiring fewer tokens and iterations compared to other multi-step retrieval\nsystems.",
      "tldr_zh": "该论文提出 GeAR，一种图增强代理框架，用于提升 Retrieval-augmented Generation (RAG) 系统的文档检索性能，通过 graph expansion 增强传统检索器如 BM25，并整合一个代理框架来处理多跳检索场景。GeAR 的关键创新包括图扩展机制和代理体系，确保在复杂查询中实现更高效的检索。在三个 multi-hop question answering 数据集上，GeAR 展示了优越的检索性能，并在 MuSiQue 数据集上实现了超过 10% 的改进，同时使用更少的 tokens 和 iterations 比其他多步系统更高效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18431v1",
      "published_date": "2024-12-24 13:45:22 UTC",
      "updated_date": "2024-12-24 13:45:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:13:58.692120"
    },
    {
      "arxiv_id": "2412.18428v1",
      "title": "Explainable Multi-Modal Data Exploration in Natural Language via LLM Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Farhad Nooralahzadeh",
        "Yi Zhang",
        "Jonathan Furst",
        "Kurt Stockinger"
      ],
      "abstract": "International enterprises, organizations, or hospitals collect large amounts\nof multi-modal data stored in databases, text documents, images, and videos.\nWhile there has been recent progress in the separate fields of multi-modal data\nexploration as well as in database systems that automatically translate natural\nlanguage questions to database query languages, the research challenge of\nquerying database systems combined with other unstructured modalities such as\nimages in natural language is widely unexplored.\n  In this paper, we propose XMODE - a system that enables explainable,\nmulti-modal data exploration in natural language. Our approach is based on the\nfollowing research contributions: (1) Our system is inspired by a real-world\nuse case that enables users to explore multi-modal information systems. (2)\nXMODE leverages a LLM-based agentic AI framework to decompose a natural\nlanguage question into subtasks such as text-to-SQL generation and image\nanalysis. (3) Experimental results on multi-modal datasets over relational data\nand images demonstrate that our system outperforms state-of-the-art multi-modal\nexploration systems, excelling not only in accuracy but also in various\nperformance metrics such as query latency, API costs, planning efficiency, and\nexplanation quality, thanks to the more effective utilization of the reasoning\ncapabilities of LLMs.",
      "tldr_zh": "该论文提出XMODE系统，用于通过LLM Agent实现可解释的多模态数据探索，支持用户以自然语言查询结合数据库、文本、图像等非结构化数据。XMODE基于LLM的代理AI框架，将自然语言问题分解为子任务，如文本到SQL生成和图像分析，从而处理多模态信息系统的真实世界用例。实验结果显示，XMODE在多模态数据集上超越现有系统，不仅在准确性方面表现出色，还在查询延迟、API成本、规划效率和解释质量上实现优化，充分利用了LLM的推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18428v1",
      "published_date": "2024-12-24 13:42:44 UTC",
      "updated_date": "2024-12-24 13:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:14:10.390106"
    },
    {
      "arxiv_id": "2412.18426v1",
      "title": "GUI Testing Arena: A Unified Benchmark for Advancing Autonomous GUI Testing Agent",
      "title_zh": "GUI 测试竞技场：用于推进自治 GUI 测试代理的统一基准",
      "authors": [
        "Kangjia Zhao",
        "Jiahui Song",
        "Leigang Sha",
        "Haozhan Shen",
        "Zhi Chen",
        "Tiancheng Zhao",
        "Xiubo Liang",
        "Jianwei Yin"
      ],
      "abstract": "Nowadays, research on GUI agents is a hot topic in the AI community. However,\ncurrent research focuses on GUI task automation, limiting the scope of\napplications in various GUI scenarios. In this paper, we propose a formalized\nand comprehensive environment to evaluate the entire process of automated GUI\nTesting (GTArena), offering a fair, standardized environment for consistent\noperation of diverse multimodal large language models. We divide the testing\nprocess into three key subtasks: test intention generation, test task\nexecution, and GUI defect detection, and construct a benchmark dataset based on\nthese to conduct a comprehensive evaluation. It evaluates the performance of\ndifferent models using three data types: real mobile applications, mobile\napplications with artificially injected defects, and synthetic data, thoroughly\nassessing their capabilities in this relevant task. Additionally, we propose a\nmethod that helps researchers explore the correlation between the performance\nof multimodal language large models in specific scenarios and their general\ncapabilities in standard benchmark tests. Experimental results indicate that\neven the most advanced models struggle to perform well across all sub-tasks of\nautomated GUI Testing, highlighting a significant gap between the current\ncapabilities of Autonomous GUI Testing and its practical, real-world\napplicability. This gap provides guidance for the future direction of GUI Agent\ndevelopment. Our code is available at\nhttps://github.com/ZJU-ACES-ISE/ChatUITest.",
      "tldr_zh": "本文提出 GTArena，一种统一的基准环境，用于评估自主 GUI 测试代理的整个过程，提供公平标准化的设置以测试多模态大语言模型。研究将 GUI 测试分为三个子任务——测试意图生成、测试任务执行和 GUI 缺陷检测，并构建基准数据集，使用真实移动应用、有缺陷应用和合成数据进行全面评估。实验结果显示，即使最先进的模型在这些子任务上表现不佳，揭示了当前自主 GUI 测试技术与实际应用之间的显著差距，并为未来 GUI 代理的发展方向提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18426v1",
      "published_date": "2024-12-24 13:41:47 UTC",
      "updated_date": "2024-12-24 13:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:14:22.386265"
    },
    {
      "arxiv_id": "2412.18424v2",
      "title": "LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Deng",
        "Jiale Yuan",
        "Pi Bu",
        "Peijie Wang",
        "Zhong-Zhi Li",
        "Jian Xu",
        "Xiao-Hui Li",
        "Yuan Gao",
        "Jun Song",
        "Bo Zheng",
        "Cheng-Lin Liu"
      ],
      "abstract": "Large vision language models (LVLMs) have improved the document understanding\ncapabilities remarkably, enabling the handling of complex document elements,\nlonger contexts, and a wider range of tasks. However, existing document\nunderstanding benchmarks have been limited to handling only a small number of\npages and fail to provide a comprehensive analysis of layout elements locating.\nIn this paper, we first define three primary task categories: Long Document\nUnderstanding, numerical Reasoning, and cross-element Locating, and then\npropose a comprehensive benchmark, LongDocURL, integrating above three primary\ntasks and comprising 20 sub-tasks categorized based on different primary tasks\nand answer evidences. Furthermore, we develop a semi-automated construction\npipeline and collect 2,325 high-quality question-answering pairs, covering more\nthan 33,000 pages of documents, significantly outperforming existing\nbenchmarks. Subsequently, we conduct comprehensive evaluation experiments on\nboth open-source and closed-source models across 26 different configurations,\nrevealing critical performance gaps in this field.",
      "tldr_zh": "该论文介绍了LongDocURL，一种综合的多模态长文档基准，旨在整合Long Document Understanding、numerical Reasoning和cross-element Locating三大任务类别，并涵盖20个子任务，以评估Large Vision Language Models (LVLMs)在处理长文档时的性能。研究者开发了半自动化构建管道，收集了2,325个高质量问答对，覆盖超过33,000页文档，这大大超过了现有基准的规模和深度。实验结果显示，在26种开源和闭源模型配置上进行了全面评估，揭示了LVLMs在长文档理解、推理和定位方面的关键性能差距，为未来模型改进提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18424v2",
      "published_date": "2024-12-24 13:39:32 UTC",
      "updated_date": "2024-12-27 08:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:14:34.468597"
    },
    {
      "arxiv_id": "2412.18419v1",
      "title": "Research on the Proximity Relationships of Psychosomatic Disease Knowledge Graph Modules Extracted by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zihan Zhou",
        "Ziyi Zeng",
        "Wenhao Jiang",
        "Yihui Zhu",
        "Jiaxin Mao",
        "Yonggui Yuan",
        "Min Xia",
        "Shubin Zhao",
        "Mengyu Yao",
        "Yunqian Chen"
      ],
      "abstract": "As social changes accelerate, the incidence of psychosomatic disorders has\nsignificantly increased, becoming a major challenge in global health issues.\nThis necessitates an innovative knowledge system and analytical methods to aid\nin diagnosis and treatment. Here, we establish the ontology model and entity\ntypes, using the BERT model and LoRA-tuned LLM for named entity recognition,\nconstructing the knowledge graph with 9668 triples. Next, by analyzing the\nnetwork distances between disease, symptom, and drug modules, it was found that\ncloser network distances among diseases can predict greater similarities in\ntheir clinical manifestations, treatment approaches, and psychological\nmechanisms, and closer distances between symptoms indicate that they are more\nlikely to co-occur. Lastly, by comparing the proximity d and proximity z score,\nit was shown that symptom-disease pairs in primary diagnostic relationships\nhave a stronger association and are of higher referential value than those in\ndiagnostic relationships. The research results revealed the potential\nconnections between diseases, co-occurring symptoms, and similarities in\ntreatment strategies, providing new perspectives for the diagnosis and\ntreatment of psychosomatic disorders and valuable information for future mental\nhealth research and practice.",
      "tldr_zh": "本研究针对 psychosomatic disorders 发病率上升的问题，构建了一个包含 9668 个 triples 的知识图谱，使用 BERT 模型和 LoRA-tuned LLM 进行 named entity recognition，并分析疾病、症状和药物模块之间的 network distances。研究发现，疾病模块间距离较近时，其临床表现、治疗方法和心理机制更相似，而症状间距离较近则表明它们更可能共同发生；此外，通过比较 proximity d 和 proximity z score，确认主要诊断关系中的症状-疾病对具有更强的关联和参考价值。该工作揭示了疾病间潜在联系和治疗策略相似性，为 psychosomatic disorders 的诊断、治疗提供新视角，并为未来心理健康研究提供宝贵信息。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18419v1",
      "published_date": "2024-12-24 13:24:01 UTC",
      "updated_date": "2024-12-24 13:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:14:47.085774"
    },
    {
      "arxiv_id": "2412.18415v1",
      "title": "Multilingual Mathematical Reasoning: Advancing Open-Source LLMs in Hindi and English",
      "title_zh": "多语言数学推理：推进开源LLMs在印地语和英语中的发展",
      "authors": [
        "Avinash Anand",
        "Kritarth Prasad",
        "Chhavi Kirtani",
        "Ashwin R Nair",
        "Manvendra Kumar Nema",
        "Raj Jaiswal",
        "Rajiv Ratn Shah"
      ],
      "abstract": "Large Language Models (LLMs) excel in linguistic tasks but struggle with\nmathematical reasoning, particularly in non English languages like Hindi. This\nresearch aims to enhance the mathematical reasoning skills of smaller, resource\nefficient open-source LLMs in both Hindi and English. We evaluate models like\nOpenHathi 7B, LLaMA-2 7B, WizardMath 7B, Mistral 7B, LLeMMa 7B, MAmmoTH 7B,\nGemini Pro, and GPT-4 using zero-shot, few-shot chain-of-thought (CoT) methods,\nand supervised fine-tuning. Our approach incorporates curriculum learning,\nprogressively training models on increasingly difficult problems, a novel\nDecomposition Strategy to simplify complex arithmetic operations, and a\nStructured Solution Design that divides solutions into phases. Our experiments\nresult in notable performance enhancements. WizardMath 7B exceeds Gemini's\naccuracy on English datasets by +6% and matches Gemini's performance on Hindi\ndatasets. Adopting a bilingual approach that combines English and Hindi samples\nachieves results comparable to individual language models, demonstrating the\ncapability to learn mathematical reasoning in both languages. This research\nhighlights the potential for improving mathematical reasoning in open-source\nLLMs.",
      "tldr_zh": "本研究旨在提升开源大型语言模型（LLMs）在Hindi和English中的数学推理能力，针对模型如OpenHathi 7B、WizardMath 7B和Gemini Pro等，解决它们在非英语语言上的不足。方法包括zero-shot、few-shot chain-of-thought (CoT) 技术、supervised fine-tuning，以及创新策略如curriculum learning（逐步训练复杂问题）、Decomposition Strategy（简化算术操作）和Structured Solution Design（分阶段解决方案）。实验结果显示，WizardMath 7B在English数据集上比Gemini Pro准确率高6%，在Hindi数据集上与之相当；采用双语训练方法可实现与单语模型类似性能，证明了开源LLMs数学推理潜力的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18415v1",
      "published_date": "2024-12-24 13:07:29 UTC",
      "updated_date": "2024-12-24 13:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:01.381864"
    },
    {
      "arxiv_id": "2412.18408v1",
      "title": "Exploring Flexible Scenario Generation in Godot Simulator",
      "title_zh": "Godot 模拟",
      "authors": [
        "Daniel Peraltai",
        "Xin Qin"
      ],
      "abstract": "Cyber-physical systems (CPS) combine cyber and physical components engineered\nto make decisions and interact within dynamic environments. Ensuring the safety\nof CPS is of great importance, requiring extensive testing across diverse and\ncomplex scenarios. To generate as many testing scenarios as possible, previous\nefforts have focused on describing scenarios using formal languages to generate\nscenes. In this paper, we introduce an alternative approach: reconstructing\nscenes inside the open-source game engine, Godot. We have developed a pipeline\nthat enables the reconstruction of testing scenes directly from provided images\nof scenarios. These reconstructed scenes can then be deployed within simulated\nenvironments to assess a CPS. This approach offers a scalable and flexible\nsolution for testing CPS in realistic environments.",
      "tldr_zh": "本文探讨了在开源游戏引擎 Godot 中生成灵活测试场景的方法，以提升 Cyber-physical systems (CPS) 的安全性和测试效率。研究团队开发了一个管道，能够从提供的场景图像直接重建测试场景，并将其部署在模拟环境中进行评估。这种方法相较于传统使用正式语言生成场景的途径，更具可扩展性和灵活性，适用于多样化的真实环境测试。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18408v1",
      "published_date": "2024-12-24 12:55:28 UTC",
      "updated_date": "2024-12-24 12:55:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:10.822359"
    },
    {
      "arxiv_id": "2412.18407v1",
      "title": "A Statistical Framework for Ranking LLM-Based Chatbots",
      "title_zh": "翻译失败",
      "authors": [
        "Siavash Ameli",
        "Siyuan Zhuang",
        "Ion Stoica",
        "Michael W. Mahoney"
      ],
      "abstract": "Large language models (LLMs) have transformed natural language processing,\nwith frameworks like Chatbot Arena providing pioneering platforms for\nevaluating these models. By facilitating millions of pairwise comparisons based\non human judgments, Chatbot Arena has become a cornerstone in LLM evaluation,\noffering rich datasets for ranking models in open-ended conversational tasks.\nBuilding upon this foundation, we propose a statistical framework that\nincorporates key advancements to address specific challenges in pairwise\ncomparison analysis. First, we introduce a factored tie model that enhances the\nability to handle ties -- an integral aspect of human-judged comparisons --\nsignificantly improving the model's fit to observed data. Second, we extend the\nframework to model covariance between competitors, enabling deeper insights\ninto performance relationships and facilitating intuitive groupings into\nperformance tiers. Third, we resolve optimization challenges arising from\nparameter non-uniqueness by introducing novel constraints, ensuring stable and\ninterpretable parameter estimation. Through rigorous evaluation and extensive\nexperimentation, our framework demonstrates substantial improvements over\nexisting methods in modeling pairwise comparison data. To support\nreproducibility and practical adoption, we release leaderbot, an open-source\nPython package implementing our models and analyses.",
      "tldr_zh": "本论文提出一个统计框架，用于排名基于 LLMs 的聊天机器人，构建于 Chatbot Arena 的成对比较数据集之上，以解决人类判断中的挑战。该框架引入 factored tie model 来更好地处理 ties，提高数据拟合度；扩展到建模竞争者之间的协方差，以揭示性能关系并分组成性能层级；并通过新约束解决参数估计的优化问题，确保稳定性和可解释性。通过实验验证，该框架在建模成对比较数据上比现有方法有显著改进，并发布了开源 Python 包 leaderbot 以支持可重复性和实际应用。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18407v1",
      "published_date": "2024-12-24 12:54:19 UTC",
      "updated_date": "2024-12-24 12:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:22.240965"
    },
    {
      "arxiv_id": "2412.18391v1",
      "title": "TPAoI: Ensuring Fresh Service Status at the Network Edge in Compute-First Networking",
      "title_zh": "翻译失败",
      "authors": [
        "Haosheng He",
        "Jianpeng Qi",
        "Chao Liu",
        "Junyu Dong",
        "Yanwei Yu"
      ],
      "abstract": "In compute-first networking, maintaining fresh and accurate status\ninformation at the network edge is crucial for effective access to remote\nservices. This process typically involves three phases: Status updating, user\naccessing, and user requesting. However, current studies on status\neffectiveness, such as Age of Information at Query (QAoI), do not\ncomprehensively cover all these phases. Therefore, this paper introduces a\nnovel metric, TPAoI, aimed at optimizing update decisions by measuring the\nfreshness of service status. The stochastic nature of edge environments,\ncharacterized by unpredictable communication delays in updating, requesting,\nand user access times, poses a significant challenge when modeling. To address\nthis, we model the problem as a Markov Decision Process (MDP) and employ a\nDueling Double Deep Q-Network (D3QN) algorithm for optimization. Extensive\nexperiments demonstrate that the proposed TPAoI metric effectively minimizes\nAoI, ensuring timely and reliable service updates in dynamic edge environments.\nResults indicate that TPAoI reduces AoI by an average of 47\\% compared to QAoI\nmetrics and decreases update frequency by an average of 48\\% relative to\nconventional AoI metrics, showing significant improvement.",
      "tldr_zh": "本研究针对compute-first networking中网络边缘服务状态的新鲜性问题，引入了新型指标TPAoI，以优化更新决策并全面覆盖状态更新、用户访问和用户请求三个阶段。论文将问题建模为Markov Decision Process (MDP)，并采用Dueling Double Deep Q-Network (D3QN)算法来处理通信延迟等随机环境挑战，从而实现高效的服务状态管理。实验结果显示，TPAoI相较于QAoI指标平均降低了AoI 47%，并将更新频率减少48%，显著提升了动态边缘环境的可靠性和效率。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18391v1",
      "published_date": "2024-12-24 12:33:44 UTC",
      "updated_date": "2024-12-24 12:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:34.645757"
    },
    {
      "arxiv_id": "2412.18390v2",
      "title": "RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction",
      "title_zh": "RDPM：通过循环标记预测求解扩散概率模型",
      "authors": [
        "Xiaoping Wu",
        "Jie Hu",
        "Xiaoming Wei"
      ],
      "abstract": "Diffusion Probabilistic Models (DPMs) have emerged as the de facto approach\nfor high-fidelity image synthesis, operating diffusion processes on continuous\nVAE latent, which significantly differ from the text generation methods\nemployed by Large Language Models (LLMs). In this paper, we introduce a novel\ngenerative framework, the Recurrent Diffusion Probabilistic Model (RDPM), which\nenhances the diffusion process through a recurrent token prediction mechanism,\nthereby pioneering the field of Discrete Diffusion. By progressively\nintroducing Gaussian noise into the latent representations of images and\nencoding them into vector-quantized tokens in a recurrent manner, RDPM\nfacilitates a unique diffusion process on discrete-value domains. This process\niteratively predicts the token codes for subsequent timesteps, transforming the\ninitial standard Gaussian noise into the source data distribution, aligning\nwith GPT-style models in terms of the loss function. RDPM demonstrates superior\nperformance while benefiting from the speed advantage of requiring only a few\ninference steps. This model not only leverages the diffusion process to ensure\nhigh-quality generation but also converts continuous signals into a series of\nhigh-fidelity discrete tokens, thereby maintaining a unified optimization\nstrategy with other discrete tokens, such as text. We anticipate that this work\nwill contribute to the development of a unified model for multimodal\ngeneration, specifically by integrating continuous signal domains such as\nimages, videos, and audio with text. We will release the code and model weights\nto the open-source community.",
      "tldr_zh": "本论文提出了一种新型生成框架RDPM（Recurrent Diffusion Probabilistic Model），通过recurrent token prediction机制增强Diffusion Probabilistic Models（DPMs），实现Discrete Diffusion过程，将图像潜在表示逐步引入Gaussian noise并编码成vector-quantized tokens。相比传统方法，RDPM仅需少量推理步骤即可生成高质量图像，并与GPT风格模型的损失函数保持一致。实验结果显示，RDPM在图像合成方面表现出色，并为多模态生成（如图像、视频、音频与文本的统一模型）奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.18390v2",
      "published_date": "2024-12-24 12:28:19 UTC",
      "updated_date": "2024-12-25 12:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:47.871255"
    },
    {
      "arxiv_id": "2412.18387v2",
      "title": "Scaling Capability in Token Space: An Analysis of Large Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Tenghui Li",
        "Guoxu Zhou",
        "Xuyang Zhao",
        "Qibin Zhao"
      ],
      "abstract": "The scaling capability has been widely validated in neural language models\nwith respect to the number of parameters and the size of training data.\n  One important question is that does the scaling capability also exists\nsimilarly with respect to the number of vision tokens in large vision language\nModel?\n  This study fills the gap by investigating the relationship between the number\nof vision tokens and the performance on vision-language models.\n  Our theoretical analysis and empirical evaluations demonstrate that the model\nexhibits scalable performance \\(S(N_l)\\) with respect to the number of vision\ntokens \\(N_l\\), characterized by the relationship \\(S(N_l) \\approx\n(c/N_l)^{\\alpha}\\).\n  Furthermore, we also investigate the impact of a fusion mechanism that\nintegrates the user's question with vision tokens.\n  The results reveal two key findings.\n  First, the scaling capability remains intact with the incorporation of the\nfusion mechanism.\n  Second, the fusion mechanism enhances model performance, particularly when\nthe user's question is task-specific and relevant.\n  The analysis, conducted on fifteen diverse benchmarks spanning a broad range\nof tasks and domains, validates the effectiveness of the proposed approach.",
      "tldr_zh": "这篇论文分析了大型视觉语言模型（Large Vision Language Model）中视觉 token 数量（N_l）对模型性能的扩展能力（scaling capability），探讨了是否类似于参数或数据规模的扩展效应。研究通过理论分析和实证评估，证明了性能函数 S(N_l) ≈ (c/N_l)^α 的关系。进一步考察了融合机制（fusion mechanism），结果显示该机制不影响扩展能力，反而显著提升模型性能，特别是当用户的查询是任务特定的。实验在 15 个多样化基准上验证了这一方法的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18387v2",
      "published_date": "2024-12-24 12:20:24 UTC",
      "updated_date": "2024-12-30 11:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:15:59.545608"
    },
    {
      "arxiv_id": "2412.18377v3",
      "title": "ChaI-TeA: A Benchmark for Evaluating Autocompletion of Interactions with LLM-based Chatbots",
      "title_zh": "翻译失败",
      "authors": [
        "Shani Goren",
        "Oren Kalinsky",
        "Tomer Stav",
        "Yuri Rapoport",
        "Yaron Fairstein",
        "Ram Yazdi",
        "Nachshon Cohen",
        "Alexander Libov",
        "Guy Kushilevitz"
      ],
      "abstract": "The rise of LLMs has deflected a growing portion of human-computer\ninteractions towards LLM-based chatbots. The remarkable abilities of these\nmodels allow users to interact using long, diverse natural language text\ncovering a wide range of topics and styles. Phrasing these messages is a time\nand effort consuming task, calling for an autocomplete solution to assist\nusers. We introduce the task of chatbot interaction autocomplete. We present\nChaI-TeA: CHat InTEraction Autocomplete; An autcomplete evaluation framework\nfor LLM-based chatbot interactions. The framework includes a formal definition\nof the task, coupled with suitable datasets and metrics. We use the framework\nto evaluate After formally defining the task along with suitable datasets and\nmetrics, we test 9 models on the defined auto completion task, finding that\nwhile current off-the-shelf models perform fairly, there is still much room for\nimprovement, mainly in ranking of the generated suggestions. We provide\ninsights for practitioners working on this task and open new research\ndirections for researchers in the field. We release our framework to serve as a\nfoundation for future research.",
      "tldr_zh": "这篇论文引入了 ChaI-TeA 基准，用于评估 LLM-based chatbots 交互的自动完成任务，以帮助用户更高效地撰写自然语言消息。该框架包括任务的正式定义、合适的数据集和指标，并对 9 个模型进行了测试，结果显示当前模型在自动完成方面表现中等，但生成建议的排名仍有较大改进空间。作者提供了实用见解，并公开了框架作为未来研究的基石。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18377v3",
      "published_date": "2024-12-24 12:03:36 UTC",
      "updated_date": "2025-03-05 11:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:16:12.103765"
    },
    {
      "arxiv_id": "2412.18375v1",
      "title": "A Many Objective Problem Where Crossover is Provably Indispensable",
      "title_zh": "翻译失败",
      "authors": [
        "Andre Opris"
      ],
      "abstract": "This paper addresses theory in evolutionary multiobjective optimisation (EMO)\nand focuses on the role of crossover operators in many-objective optimisation.\nThe advantages of using crossover are hardly understood and rigorous runtime\nanalyses with crossover are lagging far behind its use in practice,\nspecifically in the case of more than two objectives. We present a\nmany-objective problem class together with a theoretical runtime analysis of\nthe widely used NSGA-III to demonstrate that crossover can yield an exponential\nspeedup on the runtime. In particular, this algorithm can find the Pareto set\nin expected polynomial time when using crossover while without crossover it\nrequires exponential time to even find a single Pareto-optimal point. To our\nknowledge, this is the first rigorous runtime analysis in many-objective\noptimisation demonstrating an exponential performance gap when using crossover\nfor more than two objectives.",
      "tldr_zh": "本论文探讨了进化多目标优化（EMO）中交叉算子（crossover operators）的作用，特别是在多目标优化场景下的重要性。作者提出一个多目标问题类，并对NSGA-III算法进行严格的运行时分析，证明使用交叉算子能使算法运行时间指数级加速。结果显示，使用交叉算子时，算法可在期望多项式时间内找到Pareto set，而不使用时，即使发现一个Pareto最优点也需指数时间。这是有史以来首个在超过两个目标的优化中，证明交叉算子带来指数级性能差距的理论分析。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear in the proceedings of AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18375v1",
      "published_date": "2024-12-24 12:00:37 UTC",
      "updated_date": "2024-12-24 12:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:16:23.589936"
    },
    {
      "arxiv_id": "2412.18370v3",
      "title": "Unveiling the Threat of Fraud Gangs to Graph Neural Networks: Multi-Target Graph Injection Attacks Against GNN-Based Fraud Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhyeok Choi",
        "Heehyeon Kim",
        "Joyce Jiyoung Whang"
      ],
      "abstract": "Graph neural networks (GNNs) have emerged as an effective tool for fraud\ndetection, identifying fraudulent users, and uncovering malicious behaviors.\nHowever, attacks against GNN-based fraud detectors and their risks have rarely\nbeen studied, thereby leaving potential threats unaddressed. Recent findings\nsuggest that frauds are increasingly organized as gangs or groups. In this\nwork, we design attack scenarios where fraud gangs aim to make their fraud\nnodes misclassified as benign by camouflaging their illicit activities in\ncollusion. Based on these scenarios, we study adversarial attacks against\nGNN-based fraud detectors by simulating attacks of fraud gangs in three\nreal-world fraud cases: spam reviews, fake news, and medical insurance frauds.\nWe define these attacks as multi-target graph injection attacks and propose\nMonTi, a transformer-based Multi-target one-Time graph injection attack model.\nMonTi simultaneously generates attributes and edges of all attack nodes with a\ntransformer encoder, capturing interdependencies between attributes and edges\nmore effectively than most existing graph injection attack methods that\ngenerate these elements sequentially. Additionally, MonTi adaptively allocates\nthe degree budget for each attack node to explore diverse injection structures\ninvolving target, candidate, and attack nodes, unlike existing methods that fix\nthe degree budget across all attack nodes. Experiments show that MonTi\noutperforms the state-of-the-art graph injection attack methods on five\nreal-world graphs.",
      "tldr_zh": "该研究揭示了欺诈团伙对Graph Neural Networks (GNNs) 的威胁，专注于multi-target graph injection attacks，以使GNN-based欺诈检测器将欺诈节点误分类为良性。作者模拟了真实场景中的攻击，包括spam reviews、fake news和medical insurance frauds，并提出MonTi，一种基于transformer的Multi-target one-Time graph injection attack模型。MonTi通过同时生成攻击节点的属性和边、捕捉属性与边间的相互依赖性，并自适应分配每个节点的degree budget，探索多样化的注入结构，从而优于现有方法。在五个真实世界图上，实验显示MonTi显著提高了攻击性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 5 figures, 12 tables, The 39th AAAI Conference on\n  Artificial Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.18370v3",
      "published_date": "2024-12-24 11:53:24 UTC",
      "updated_date": "2025-04-15 11:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:16:36.047386"
    },
    {
      "arxiv_id": "2412.18365v1",
      "title": "Hypergraph Attacks via Injecting Homogeneous Nodes into Elite Hyperedges",
      "title_zh": "翻译失败",
      "authors": [
        "Meixia He",
        "Peican Zhu",
        "Keke Tang",
        "Yangming Guo"
      ],
      "abstract": "Recent studies have shown that Hypergraph Neural Networks (HGNNs) are\nvulnerable to adversarial attacks. Existing approaches focus on hypergraph\nmodification attacks guided by gradients, overlooking node spanning in the\nhypergraph and the group identity of hyperedges, thereby resulting in limited\nattack performance and detectable attacks. In this manuscript, we present a\nnovel framework, i.e., Hypergraph Attacks via Injecting Homogeneous Nodes into\nElite Hyperedges (IE-Attack), to tackle these challenges. Initially, utilizing\nthe node spanning in the hypergraph, we propose the elite hyperedges sampler to\nidentify hyperedges to be injected. Subsequently, a node generator utilizing\nKernel Density Estimation (KDE) is proposed to generate the homogeneous node\nwith the group identity of hyperedges. Finally, by injecting the homogeneous\nnode into elite hyperedges, IE-Attack improves the attack performance and\nenhances the imperceptibility of attacks. Extensive experiments are conducted\non five authentic datasets to validate the effectiveness of IE-Attack and the\ncorresponding superiority to state-of-the-art methods.",
      "tldr_zh": "本研究针对Hypergraph Neural Networks (HGNNs)的易受攻击性问题，提出了一种新框架IE-Attack，通过注入同质节点(homogeneous node)到精英超边(elite hyperedges)中来提升攻击性能并提高隐蔽性。方法包括利用节点跨度(node spanning)来采样精英超边，并采用Kernel Density Estimation (KDE)生成与超边群组身份匹配的同质节点。实验在五个真实数据集上验证了IE-Attack的有效性，其性能优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, The 39th Annual AAAI Conference on Artificial\n  Intelligence(2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.18365v1",
      "published_date": "2024-12-24 11:48:41 UTC",
      "updated_date": "2024-12-24 11:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:16:46.884734"
    },
    {
      "arxiv_id": "2412.18362v1",
      "title": "Point-DeepONet: A Deep Operator Network Integrating PointNet for Nonlinear Analysis of Non-Parametric 3D Geometries and Load Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Jangseop Park",
        "Namwoo Kang"
      ],
      "abstract": "Nonlinear structural analyses in engineering often require extensive finite\nelement simulations, limiting their applicability in design optimization,\nuncertainty quantification, and real-time control. Conventional deep learning\nsurrogates, such as convolutional neural networks (CNNs), physics-informed\nneural networks (PINNs), and fourier neural operators (FNOs), face challenges\nwith complex non-parametric three-dimensional (3D) geometries, directionally\nvarying loads, and high-fidelity predictions on unstructured meshes. This work\npresents Point-DeepONet, an operator-learning-based surrogate that integrates\nPointNet into the DeepONet framework. By directly processing non-parametric\npoint clouds and incorporating signed distance functions (SDF) for geometric\ncontext, Point-DeepONet accurately predicts three-dimensional displacement and\nvon Mises stress fields without mesh parameterization or retraining. Trained\nusing only about 5,000 nodes (2.5% of the original 200,000-node mesh),\nPoint-DeepONet can still predict the entire mesh at high fidelity, achieving a\ncoefficient of determination reaching 0.987 for displacement and 0.923 for von\nMises stress under a horizontal load case. Compared to nonlinear finite element\nanalyses that require about 19.32 minutes per case, Point-DeepONet provides\npredictions in mere seconds-approximately 400 times faster-while maintaining\nexcellent scalability and accuracy with increasing dataset sizes. These\nfindings highlight the potential of Point-DeepONet to enable rapid,\nhigh-fidelity structural analyses, ultimately supporting more effective design\nexploration and informed decision-making in complex engineering workflows.",
      "tldr_zh": "该研究提出Point-DeepONet，一种将PointNet集成到DeepONet框架的操作学习代理模型，用于处理非参数3D几何和负载条件下的非线性结构分析。该模型直接处理点云数据，并利用带符号距离函数(SDF)提供几何上下文，从而准确预测三维位移和von Mises应力场，而无需网格参数化或重新训练。实验结果显示，使用仅约5,000个节点（原始网格的2.5%）训练后，Point-DeepONet在位移预测上达到0.987的决定系数，在von Mises应力上达到0.923，并将预测时间从非线性有限元分析的19.32分钟缩短到几秒钟，速度提升约400倍。相比传统方法如CNNs、PINNs和FNOs，该框架在复杂工程场景中展现出更高的可扩展性和准确性，支持快速设计优化和决策。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 16 figures, and 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.18362v1",
      "published_date": "2024-12-24 11:44:58 UTC",
      "updated_date": "2024-12-24 11:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:18:52.610726"
    },
    {
      "arxiv_id": "2412.18355v2",
      "title": "Handling Spatial-Temporal Data Heterogeneity for Federated Continual Learning via Tail Anchor",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yu",
        "Xin Yang",
        "Le Zhang",
        "Hanlin Gu",
        "Tianrui Li",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "Federated continual learning (FCL) allows each client to continually update\nits knowledge from task streams, enhancing the applicability of federated\nlearning in real-world scenarios. However, FCL needs to address not only\nspatial data heterogeneity between clients but also temporal data heterogeneity\nbetween tasks. In this paper, empirical experiments demonstrate that such\ninput-level heterogeneity significantly affects the model's internal parameters\nand outputs, leading to severe spatial-temporal catastrophic forgetting of\nlocal and previous knowledge. To this end, we propose Federated Tail Anchor\n(FedTA) to mix trainable Tail Anchor with the frozen output features to adjust\ntheir position in the feature space, thereby overcoming parameter-forgetting\nand output-forgetting. Three novel components are also included: Input\nEnhancement for improving the performance of pre-trained models on downstream\ntasks; Selective Input Knowledge Fusion for fusion of heterogeneous local\nknowledge on the server; and Best Global Prototype Selection for finding the\nbest anchor point for each class in the feature space. Extensive experiments\ndemonstrate that FedTA not only outperforms existing FCL methods but also\neffectively preserves the relative positions of features.",
      "tldr_zh": "该论文探讨了联邦持续学习 (FCL) 中空间数据异质性 (spatial data heterogeneity) 和时间数据异质性 (temporal data heterogeneity) 导致的空间-时间灾难性遗忘 (spatial-temporal catastrophic forgetting) 问题。作者提出 Federated Tail Anchor (FedTA) 方法，通过混合可训练的 Tail Anchor 与冻结输出特征来调整特征空间位置，并引入 Input Enhancement、Selective Input Knowledge Fusion 和 Best Global Prototype Selection 等组件，以融合异质知识并优化锚点。实验结果显示，FedTA 优于现有 FCL 方法，能够有效减少遗忘并保留特征的相对位置。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper is accepted by CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18355v2",
      "published_date": "2024-12-24 11:35:40 UTC",
      "updated_date": "2025-03-05 13:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:19:04.774848"
    },
    {
      "arxiv_id": "2412.18354v1",
      "title": "The Thousand Brains Project: A New Paradigm for Sensorimotor Intelligence",
      "title_zh": "The Thousand Brains Project: 感觉运动智能的新范式",
      "authors": [
        "Viviane Clay",
        "Niels Leadholm",
        "Jeff Hawkins"
      ],
      "abstract": "Artificial intelligence has advanced rapidly in the last decade, driven\nprimarily by progress in the scale of deep-learning systems. Despite these\nadvances, the creation of intelligent systems that can operate effectively in\ndiverse, real-world environments remains a significant challenge. In this white\npaper, we outline the Thousand Brains Project, an ongoing research effort to\ndevelop an alternative, complementary form of AI, derived from the operating\nprinciples of the neocortex. We present an early version of a thousand-brains\nsystem, a sensorimotor agent that is uniquely suited to quickly learn a wide\nrange of tasks and eventually implement any capabilities the human neocortex\nhas. Core to its design is the use of a repeating computational unit, the\nlearning module, modeled on the cortical columns found in mammalian brains.\nEach learning module operates as a semi-independent unit that can model entire\nobjects, represents information through spatially structured reference frames,\nand both estimates and is able to effect movement in the world. Learning is a\nquick, associative process, similar to Hebbian learning in the brain, and\nleverages inductive biases around the spatial structure of the world to enable\nrapid and continual learning. Multiple learning modules can interact with one\nanother both hierarchically and non-hierarchically via a \"cortical messaging\nprotocol\" (CMP), creating more abstract representations and supporting\nmultimodal integration. We outline the key principles motivating the design of\nthousand-brains systems and provide details about the implementation of Monty,\nour first instantiation of such a system. Code can be found at\nhttps://github.com/thousandbrainsproject/tbp.monty, along with more detailed\ndocumentation at https://thousandbrainsproject.readme.io/.",
      "tldr_zh": "这篇白皮书介绍了Thousand Brains Project，一种基于新皮质(neocortex)运作原理的AI范式，旨在开发能快速适应真实世界环境的传感器运动智能系统，以补充当前深度学习方法的局限性。核心设计采用重复的learning module，模仿大脑的cortical columns，每个模块能独立建模对象、使用空间参考帧表示信息，并通过类似于Hebbian learning的关联过程实现快速、持续学习。多个learning module通过cortical messaging protocol(CMP)进行层次化和非层次化互动，支持多模态集成和抽象表示；论文提供了Monty系统的早期实现及其开源代码，展示了该系统在学习广泛任务方面的潜力。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18354v1",
      "published_date": "2024-12-24 11:32:37 UTC",
      "updated_date": "2024-12-24 11:32:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:17:24.322926"
    },
    {
      "arxiv_id": "2412.18351v1",
      "title": "Multi-Agents Based on Large Language Models for Knowledge-based Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongjian Hu",
        "Peng Yang",
        "Bing Li",
        "Zhenqi Wang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved impressive results in\nknowledge-based Visual Question Answering (VQA). However existing methods still\nhave challenges: the inability to use external tools autonomously, and the\ninability to work in teams. Humans tend to know whether they need to use\nexternal tools when they encounter a new question, e.g., they tend to be able\nto give a direct answer to a familiar question, whereas they tend to use tools\nsuch as search engines when they encounter an unfamiliar question. In addition,\nhumans also tend to collaborate and discuss with others to get better answers.\nInspired by this, we propose the multi-agent voting framework. We design three\nLLM-based agents that simulate different levels of staff in a team, and assign\nthe available tools according to the levels. Each agent provides the\ncorresponding answer, and finally all the answers provided by the agents are\nvoted to get the final answer. Experiments on OK-VQA and A-OKVQA show that our\napproach outperforms other baselines by 2.2 and 1.0, respectively.",
      "tldr_zh": "该研究提出了一种基于大型语言模型(LLMs)的多智能体投票框架，用于知识型视觉问答(VQA)，以解决现有方法无法自主使用外部工具和团队协作的挑战。\n框架模拟人类行为，设计了三个LLM代理，分别代表团队中不同级别的员工，并根据级别分配可用工具，每个代理提供答案后通过投票机制得出最终结果。\n实验在OK-VQA和A-OKVQA数据集上表明，该方法分别比其他基线提高了2.2和1.0的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18351v1",
      "published_date": "2024-12-24 11:24:56 UTC",
      "updated_date": "2024-12-24 11:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:17:38.982931"
    },
    {
      "arxiv_id": "2412.18337v1",
      "title": "The Value of AI-Generated Metadata for UGC Platforms: Evidence from a Large-scale Field Experiment",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Zhang",
        "Chenshuo Sun",
        "Renyu Zhang",
        "Khim-Yong Goh"
      ],
      "abstract": "AI-generated content (AIGC), such as advertisement copy, product\ndescriptions, and social media posts, is becoming ubiquitous in business\npractices. However, the value of AI-generated metadata, such as titles, remains\nunclear on user-generated content (UGC) platforms. To address this gap, we\nconducted a large-scale field experiment on a leading short-video platform in\nAsia to provide about 1 million users access to AI-generated titles for their\nuploaded videos. Our findings show that the provision of AI-generated titles\nsignificantly boosted content consumption, increasing valid watches by 1.6% and\nwatch duration by 0.9%. When producers adopted these titles, these increases\njumped to 7.1% and 4.1%, respectively. This viewership-boost effect was largely\nattributed to the use of this generative AI (GAI) tool increasing the\nlikelihood of videos having a title by 41.4%. The effect was more pronounced\nfor groups more affected by metadata sparsity. Mechanism analysis revealed that\nAI-generated metadata improved user-video matching accuracy in the platform's\nrecommender system. Interestingly, for a video for which the producer would\nhave posted a title anyway, adopting the AI-generated title decreased its\nviewership on average, implying that AI-generated titles may be of lower\nquality than human-generated ones. However, when producers chose to co-create\nwith GAI and significantly revised the AI-generated titles, the videos\noutperformed their counterparts with either fully AI-generated or\nhuman-generated titles, showcasing the benefits of human-AI co-creation. This\nstudy highlights the value of AI-generated metadata and human-AI metadata\nco-creation in enhancing user-content matching and content consumption for UGC\nplatforms.",
      "tldr_zh": "这篇论文通过大规模实地实验探讨了 AI 生成元数据（如标题）在用户生成内容 (UGC) 平台上的价值，实验涉及亚洲领先的短视频平台，向约 100 万用户提供 AI 生成标题。结果显示，提供这些标题显著提升内容消费，有效观看次数增加 1.6%、观看时长增加 0.9%，而生产者采用后提升幅度更大（分别为 7.1% 和 4.1%），主要归因于 generative AI (GAI) 工具提高了视频有标题的可能性并改善了推荐系统的用户-视频匹配准确性。机制分析发现，对于原本有标题的视频，直接使用 AI 生成标题可能降低观看量，表明其质量可能逊于人类生成，但如果生产者通过 human-AI co-creation 修改标题，视频表现优于纯 AI 或纯人类标题。该研究强调了 AI 生成元数据和人类-AI 协作在提升 UGC 平台内容消费方面的潜在益处。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.HC",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18337v1",
      "published_date": "2024-12-24 10:47:27 UTC",
      "updated_date": "2024-12-24 10:47:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:17:49.660123"
    },
    {
      "arxiv_id": "2412.18335v2",
      "title": "FloNa: Floor Plan Guided Embodied Visual Navigation",
      "title_zh": "FloNa：基于楼层平面图的具身视觉导航",
      "authors": [
        "Jiaxin Li",
        "Weiqi Huang",
        "Zan Wang",
        "Wei Liang",
        "Huijun Di",
        "Feng Liu"
      ],
      "abstract": "Humans naturally rely on floor plans to navigate in unfamiliar environments,\nas they are readily available, reliable, and provide rich geometrical guidance.\nHowever, existing visual navigation settings overlook this valuable prior\nknowledge, leading to limited efficiency and accuracy. To eliminate this gap,\nwe introduce a novel navigation task: Floor Plan Visual Navigation (FloNa), the\nfirst attempt to incorporate floor plan into embodied visual navigation. While\nthe floor plan offers significant advantages, two key challenges emerge: (1)\nhandling the spatial inconsistency between the floor plan and the actual scene\nlayout for collision-free navigation, and (2) aligning observed images with the\nfloor plan sketch despite their distinct modalities. To address these\nchallenges, we propose FloDiff, a novel diffusion policy framework\nincorporating a localization module to facilitate alignment between the current\nobservation and the floor plan. We further collect $20k$ navigation episodes\nacross $117$ scenes in the iGibson simulator to support the training and\nevaluation. Extensive experiments demonstrate the effectiveness and efficiency\nof our framework in unfamiliar scenes using floor plan knowledge. Project\nwebsite: https://gauleejx.github.io/flona/.",
      "tldr_zh": "该论文引入了FloNa任务，即Floor Plan Visual Navigation，利用楼层平面图作为先验知识来提升视觉导航的效率和准确性，以解决现有方法的局限性。针对楼层平面图与实际场景的空间不一致以及图像与平面图模态对齐的挑战，作者提出FloDiff框架，该框架整合了定位模块和基于扩散策略的导航机制。在iGibson模拟器中收集的20k导航片段实验表明，FloDiff在陌生场景中显著提高了导航性能，证明了其有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18335v2",
      "published_date": "2024-12-24 10:42:25 UTC",
      "updated_date": "2025-03-07 03:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:19:17.185075"
    },
    {
      "arxiv_id": "2412.18322v1",
      "title": "Exploring Graph Mamba: A Comprehensive Survey on State-Space Models for Graph Learning",
      "title_zh": "探索 Graph Mamba：图学习中状态空间模型的全面调查",
      "authors": [
        "Safa Ben Atitallah",
        "Chaima Ben Rabah",
        "Maha Driss",
        "Wadii Boulila",
        "Anis Koubaa"
      ],
      "abstract": "Graph Mamba, a powerful graph embedding technique, has emerged as a\ncornerstone in various domains, including bioinformatics, social networks, and\nrecommendation systems. This survey represents the first comprehensive study\ndevoted to Graph Mamba, to address the critical gaps in understanding its\napplications, challenges, and future potential. We start by offering a detailed\nexplanation of the original Graph Mamba architecture, highlighting its key\ncomponents and underlying mechanisms. Subsequently, we explore the most recent\nmodifications and enhancements proposed to improve its performance and\napplicability. To demonstrate the versatility of Graph Mamba, we examine its\napplications across diverse domains. A comparative analysis of Graph Mamba and\nits variants is conducted to shed light on their unique characteristics and\npotential use cases. Furthermore, we identify potential areas where Graph Mamba\ncan be applied in the future, highlighting its potential to revolutionize data\nanalysis in these fields. Finally, we address the current limitations and open\nresearch questions associated with Graph Mamba. By acknowledging these\nchallenges, we aim to stimulate further research and development in this\npromising area. This survey serves as a valuable resource for both newcomers\nand experienced researchers seeking to understand and leverage the power of\nGraph Mamba.",
      "tldr_zh": "本调查论文首次对 Graph Mamba 进行了全面研究，该技术作为一种基于 State-Space Models 的图嵌入方法，已在生物信息学、社会网络和推荐系统中发挥关键作用。论文详细解释了 Graph Mamba 的原始架构、关键组件及其机制，并探讨了最近的改进和增强，以提升其性能和适用性。通过比较分析，论文突出了 Graph Mamba 与其变体的独特特性，并展示了其在多领域的实际应用和未来潜力，如革命性数据分析。最终，论文指出了当前限制和开放研究问题，以推动该领域的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18322v1",
      "published_date": "2024-12-24 10:17:14 UTC",
      "updated_date": "2024-12-24 10:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:19:27.372602"
    },
    {
      "arxiv_id": "2412.18319v2",
      "title": "Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Huanjin Yao",
        "Jiaxing Huang",
        "Wenhao Wu",
        "Jingyi Zhang",
        "Yibo Wang",
        "Shunyu Liu",
        "Yingjie Wang",
        "Yuxin Song",
        "Haocheng Feng",
        "Li Shen",
        "Dacheng Tao"
      ],
      "abstract": "In this work, we aim to develop an MLLM that understands and solves questions\nby learning to create each intermediate step of the reasoning involved till the\nfinal answer. To this end, we propose Collective Monte Carlo Tree Search\n(CoMCTS), a new learning-to-reason method for MLLMs, which introduces the\nconcept of collective learning into ``tree search'' for effective and efficient\nreasoning-path searching and learning. The core idea of CoMCTS is to leverage\ncollective knowledge from multiple models to collaboratively conjecture, search\nand identify effective reasoning paths toward correct answers via four\niterative operations including Expansion, Simulation and Error Positioning,\nBackpropagation, and Selection. Using CoMCTS, we construct Mulberry-260k, a\nmultimodal dataset with a tree of rich, explicit and well-defined reasoning\nnodes for each question. With Mulberry-260k, we perform collective SFT to train\nour model, Mulberry, a series of MLLMs with o1-like step-by-step Reasoning and\nReflection capabilities. Extensive experiments demonstrate the superiority of\nour proposed methods on various benchmarks. Code will be available at\nhttps://github.com/HJYao00/Mulberry",
      "tldr_zh": "本研究旨在开发一种多模态大型语言模型 (MLLM)，通过学习创建每个中间推理步骤来理解和解决复杂问题。论文提出 Collective Monte Carlo Tree Search (CoMCTS) 方法，将集体学习融入树搜索，利用多个模型的知识通过 Expansion、Simulation and Error Positioning、Backpropagation 和 Selection 等四项迭代操作，协同推测和优化有效的推理路径。基于 CoMCTS，构建了 Mulberry-260k 数据集，并通过集体监督微调 (SFT) 训练出 Mulberry 模型，实现 o1-like 的逐步推理和反思能力；在各种基准测试中，该方法表现出显著优越性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report",
      "pdf_url": "http://arxiv.org/pdf/2412.18319v2",
      "published_date": "2024-12-24 10:07:51 UTC",
      "updated_date": "2024-12-31 07:41:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:21:33.328412"
    },
    {
      "arxiv_id": "2412.18316v1",
      "title": "Data-Driven Self-Supervised Graph Representation Learning",
      "title_zh": "数据驱动的自监督图表示学习",
      "authors": [
        "Ahmed E. Samy",
        "Zekarias T. Kefatoa",
        "Sarunas Girdzijauskasa"
      ],
      "abstract": "Self-supervised graph representation learning (SSGRL) is a representation\nlearning paradigm used to reduce or avoid manual labeling. An essential part of\nSSGRL is graph data augmentation. Existing methods usually rely on heuristics\ncommonly identified through trial and error and are effective only within some\napplication domains. Also, it is not clear why one heuristic is better than\nanother. Moreover, recent studies have argued against some techniques (e.g.,\ndropout: that can change the properties of molecular graphs or destroy relevant\nsignals for graph-based document classification tasks).\n  In this study, we propose a novel data-driven SSGRL approach that\nautomatically learns a suitable graph augmentation from the signal encoded in\nthe graph (i.e., the nodes' predictive feature and topological information). We\npropose two complementary approaches that produce learnable feature and\ntopological augmentations. The former learns multi-view augmentation of node\nfeatures, and the latter learns a high-order view of the topology. Moreover,\nthe augmentations are jointly learned with the representation. Our approach is\ngeneral that it can be applied to homogeneous and heterogeneous graphs. We\nperform extensive experiments on node classification (using nine homogeneous\nand heterogeneous datasets) and graph property prediction (using another eight\ndatasets). The results show that the proposed method matches or outperforms the\nSOTA SSGRL baselines and performs similarly to semi-supervised methods. The\nanonymised source code is available at https://github.com/AhmedESamy/dsgrl/",
      "tldr_zh": "本文提出了一种数据驱动的 Self-Supervised Graph Representation Learning (SSGRL) 方法，以解决现有图数据增强依赖启发式规则的问题，该方法从图的节点特征和拓扑信息中自动学习合适的增强策略。研究包括两种互补方法：多视图节点特征增强和高阶拓扑视图增强，这些增强与表示学习过程联合优化，并适用于同质和异质图。实验在九个节点分类数据集和八个图属性预测数据集上进行，结果显示该方法优于或匹配 SOTA SSGRL 基线，甚至接近半监督方法的性能。源代码已在 GitHub 上公开，可供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18316v1",
      "published_date": "2024-12-24 10:04:19 UTC",
      "updated_date": "2024-12-24 10:04:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:19:52.890204"
    },
    {
      "arxiv_id": "2412.18299v1",
      "title": "M-Ped: Multi-Prompt Ensemble Decoding for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "Daimeng Wei",
        "Yuanchang Luo",
        "Shimin Tao",
        "Hengchao Shang",
        "Zongyao Li",
        "Shaojun Li",
        "Jinlong Yang",
        "Zhanglin Wu",
        "Zhiqiang Rao",
        "Hao Yang"
      ],
      "abstract": "With the widespread application of Large Language Models (LLMs) in the field\nof Natural Language Processing (NLP), enhancing their performance has become a\nresearch hotspot. This paper presents a novel multi-prompt ensemble decoding\napproach designed to bolster the generation quality of LLMs by leveraging the\naggregation of outcomes from multiple prompts. Given a unique input $X$, we\nsubmit $n$ variations of prompts with $X$ to LLMs in batch mode to decode and\nderive probability distributions. For each token prediction, we calculate the\nensemble probability by averaging the $n$ probability distributions within the\nbatch, utilizing this aggregated probability to generate the token. This\ntechnique is dubbed Inner-Batch Ensemble. To facilitate efficient batch\ninference, we implement a Left-Padding strategy to maintain uniform input\nlengths across the n prompts. Through extensive experimentation on diverse NLP\ntasks, including machine translation, code generation, and text simplification,\nwe demonstrate the efficacy of our method in enhancing LLM performance. The\nresults show substantial improvements in BLEU scores, pass@$k$ rates, and LENS\nmetrics over conventional methods.",
      "tldr_zh": "这篇论文提出了 M-Ped，一种多提示集成解码方法，用于提升大型语言模型(LLMs)在自然语言处理(NLP)任务中的生成质量。具体而言，该方法通过对单个输入$X$提交$n$个提示变体进行批量解码，计算每个 token 的集成概率（Inner-Batch Ensemble），并采用 Left-Padding 策略确保输入长度一致，从而优化推理效率。在机器翻译、代码生成和文本简化等任务上的实验显示，M-Ped 显著提高了 BLEU scores、pass@$k$ rates 和 LENS metrics 等指标，相比传统方法取得了实质性改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18299v1",
      "published_date": "2024-12-24 09:06:58 UTC",
      "updated_date": "2024-12-24 09:06:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:22:04.408098"
    },
    {
      "arxiv_id": "2412.18298v1",
      "title": "Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Ding",
        "Lei Wang"
      ],
      "abstract": "Video anomaly detection (VAD) has witnessed significant advancements through\nthe integration of large language models (LLMs) and vision-language models\n(VLMs), addressing critical challenges such as interpretability, temporal\nreasoning, and generalization in dynamic, open-world scenarios. This paper\npresents an in-depth review of cutting-edge LLM-/VLM-based methods in 2024,\nfocusing on four key aspects: (i) enhancing interpretability through semantic\ninsights and textual explanations, making visual anomalies more understandable;\n(ii) capturing intricate temporal relationships to detect and localize dynamic\nanomalies across video frames; (iii) enabling few-shot and zero-shot detection\nto minimize reliance on large, annotated datasets; and (iv) addressing\nopen-world and class-agnostic anomalies by using semantic understanding and\nmotion features for spatiotemporal coherence. We highlight their potential to\nredefine the landscape of VAD. Additionally, we explore the synergy between\nvisual and textual modalities offered by LLMs and VLMs, highlighting their\ncombined strengths and proposing future directions to fully exploit the\npotential in enhancing video anomaly detection.",
      "tldr_zh": "本论文综述了2024年大型语言模型(LLMs)和视觉语言模型(VLMs)在视频异常检测(VAD)中的先进应用，重点解决可解释性、时间推理和泛化等挑战。研究探讨了四个关键方面：(i) 通过语义洞见和文本解释提升异常的可理解性；(ii) 捕捉复杂的时间关系以检测动态异常；(iii) 实现少样本和零样本检测，减少对标注数据集的依赖；以及(iv) 处理开放世界和类别无关异常，利用语义理解和运动特征确保时空一致性。最终，该综述突出了LLMs和VLMs的协同潜力，重塑VAD领域，并提出未来方向以进一步挖掘视觉和文本模态的整合优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Research report",
      "pdf_url": "http://arxiv.org/pdf/2412.18298v1",
      "published_date": "2024-12-24 09:05:37 UTC",
      "updated_date": "2024-12-24 09:05:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:20:16.683775"
    },
    {
      "arxiv_id": "2412.18296v1",
      "title": "Navigating Data Corruption in Machine Learning: Balancing Quality, Quantity, and Imputation Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Liu",
        "Wanjing Ma"
      ],
      "abstract": "Data corruption, including missing and noisy data, poses significant\nchallenges in real-world machine learning. This study investigates the effects\nof data corruption on model performance and explores strategies to mitigate\nthese effects through two experimental setups: supervised learning with NLP\ntasks (NLP-SL) and deep reinforcement learning for traffic signal optimization\n(Signal-RL). We analyze the relationship between data corruption levels and\nmodel performance, evaluate the effectiveness of data imputation methods, and\nassess the utility of enlarging datasets to address data corruption.\n  Our results show that model performance under data corruption follows a\ndiminishing return curve, modeled by the exponential function. Missing data,\nwhile detrimental, is less harmful than noisy data, which causes severe\nperformance degradation and training instability, particularly in sequential\ndecision-making tasks like Signal-RL. Imputation strategies involve a\ntrade-off: they recover missing information but may introduce noise. Their\neffectiveness depends on imputation accuracy and corruption ratio. We identify\ndistinct regions in the imputation advantage heatmap, including an \"imputation\nadvantageous corner\" and an \"imputation disadvantageous edge\" and classify\ntasks as \"noise-sensitive\" or \"noise-insensitive\" based on their decision\nboundaries.\n  Furthermore, we find that increasing dataset size mitigates but cannot fully\novercome the effects of data corruption. The marginal utility of additional\ndata diminishes as corruption increases. An empirical rule emerges:\napproximately 30% of the data is critical for determining performance, while\nthe remaining 70% has minimal impact.\n  These findings provide actionable insights into data preprocessing,\nimputation strategies, and data collection practices, guiding the development\nof robust machine learning systems in noisy environments.",
      "tldr_zh": "该论文探讨了数据损坏（如缺失和噪声数据）对机器学习模型性能的影响，通过 NLP-SL（监督学习在 NLP 任务上）和 Signal-RL（深度强化学习在交通信号优化上）两个实验设置进行分析。研究发现，模型性能随数据损坏水平呈指数递减曲线，噪声数据比缺失数据更具破坏性，导致严重性能下降和训练不稳定。插值策略（imputation strategies）能恢复缺失信息，但存在权衡，可能引入噪声，并通过“imputation advantageous corner”和“imputation disadvantageous edge”热图识别其适用区域，将任务分类为“noise-sensitive”或“noise-insensitive”。此外，增加数据集大小可缓解损坏影响，但边际效用递减，且约 30% 的数据对性能至关重要，而其余 70% 影响最小。该研究为数据预处理、插值策略和数据收集实践提供了可操作指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18296v1",
      "published_date": "2024-12-24 09:04:06 UTC",
      "updated_date": "2024-12-24 09:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:20:30.553777"
    },
    {
      "arxiv_id": "2412.18295v2",
      "title": "Pirates of the RAG: Adaptively Attacking LLMs to Leak Knowledge Bases",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Di Maio",
        "Cristian Cosci",
        "Marco Maggini",
        "Valentina Poggioni",
        "Stefano Melacci"
      ],
      "abstract": "The growing ubiquity of Retrieval-Augmented Generation (RAG) systems in\nseveral real-world services triggers severe concerns about their security. A\nRAG system improves the generative capabilities of a Large Language Models\n(LLM) by a retrieval mechanism which operates on a private knowledge base,\nwhose unintended exposure could lead to severe consequences, including breaches\nof private and sensitive information. This paper presents a black-box attack to\nforce a RAG system to leak its private knowledge base which, differently from\nexisting approaches, is adaptive and automatic. A relevance-based mechanism and\nan attacker-side open-source LLM favor the generation of effective queries to\nleak most of the (hidden) knowledge base. Extensive experimentation proves the\nquality of the proposed algorithm in different RAG pipelines and domains,\ncomparing to very recent related approaches, which turn out to be either not\nfully black-box, not adaptive, or not based on open-source models. The findings\nfrom our study remark the urgent need for more robust privacy safeguards in the\ndesign and deployment of RAG systems.",
      "tldr_zh": "该研究提出了一种自适应黑盒攻击方法，名为“Pirates of the RAG”，旨在利用大型语言模型（LLM）的检索增强生成（RAG）系统泄露其私有知识库。攻击机制通过基于相关性的查询生成和攻击者端的开源LLM，自动创建有效查询来提取隐藏信息。实验结果显示，该算法在不同RAG管道和领域表现出色，比现有方法（如非黑盒或非自适应方法）更高效，成功泄露大部分知识基。研究强调了RAG系统在设计和部署中亟需更robust的隐私保护措施，以防范此类安全威胁。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18295v2",
      "published_date": "2024-12-24 09:03:57 UTC",
      "updated_date": "2024-12-29 21:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:20:39.371892"
    },
    {
      "arxiv_id": "2412.18293v2",
      "title": "MineStudio: A Streamlined Package for Minecraft AI Agent Development",
      "title_zh": "翻译失败",
      "authors": [
        "Shaofei Cai",
        "Zhancun Mu",
        "Kaichen He",
        "Bowei Zhang",
        "Xinyue Zheng",
        "Anji Liu",
        "Yitao Liang"
      ],
      "abstract": "Minecraft has emerged as a valuable testbed for embodied intelligence and\nsequential decision-making research, yet the development and validation of\nnovel agents remains hindered by significant engineering challenges. This paper\npresents MineStudio, an open-source software package designed to streamline\nembodied policy development in Minecraft. MineStudio represents the first\ncomprehensive integration of seven critical engineering components: simulator,\ndata, model, offline pretraining, online finetuning, inference, and benchmark,\nthereby allowing users to concentrate their efforts on algorithm innovation. We\nprovide a user-friendly API design accompanied by comprehensive documentation\nand tutorials. The complete codebase is publicly available at\nhttps://github.com/CraftJarvis/MineStudio.",
      "tldr_zh": "该论文介绍了 MineStudio，一个开源软件包，旨在简化 Minecraft 环境中的 AI 代理开发，解决 embodied intelligence 和 sequential decision-making 研究中的工程挑战。MineStudio 首次全面整合了七个关键组件，包括 simulator、data、model、offline pretraining、online finetuning、inference 和 benchmark，从而让用户能够专注于算法创新。软件提供用户友好的 API 设计、详细文档和教程，并已在 GitHub 上公开源码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18293v2",
      "published_date": "2024-12-24 09:01:43 UTC",
      "updated_date": "2024-12-25 04:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:20:52.095288"
    },
    {
      "arxiv_id": "2412.18291v2",
      "title": "DeepCRCEval: Revisiting the Evaluation of Code Review Comment Generation",
      "title_zh": "DeepCRCEval：重新审视代码审查评论生成的评估",
      "authors": [
        "Junyi Lu",
        "Xiaojia Li",
        "Zihan Hua",
        "Lei Yu",
        "Shiqi Cheng",
        "Li Yang",
        "Fengjun Zhang",
        "Chun Zuo"
      ],
      "abstract": "Code review is a vital but demanding aspect of software development,\ngenerating significant interest in automating review comments. Traditional\nevaluation methods for these comments, primarily based on text similarity, face\ntwo major challenges: inconsistent reliability of human-authored comments in\nopen-source projects and the weak correlation of text similarity with\nobjectives like enhancing code quality and detecting defects.\n  This study empirically analyzes benchmark comments using a novel set of\ncriteria informed by prior research and developer interviews. We then similarly\nrevisit the evaluation of existing methodologies. Our evaluation framework,\nDeepCRCEval, integrates human evaluators and Large Language Models (LLMs) for a\ncomprehensive reassessment of current techniques based on the criteria set.\nBesides, we also introduce an innovative and efficient baseline, LLM-Reviewer,\nleveraging the few-shot learning capabilities of LLMs for a target-oriented\ncomparison.\n  Our research highlights the limitations of text similarity metrics, finding\nthat less than 10% of benchmark comments are high quality for automation. In\ncontrast, DeepCRCEval effectively distinguishes between high and low-quality\ncomments, proving to be a more reliable evaluation mechanism. Incorporating LLM\nevaluators into DeepCRCEval significantly boosts efficiency, reducing time and\ncost by 88.78% and 90.32%, respectively. Furthermore, LLM-Reviewer demonstrates\nsignificant potential of focusing task real targets in comment generation.",
      "tldr_zh": "这篇论文重新审视了代码审查评论生成的评估方法，指出传统基于 text similarity 的方法存在可靠性不一致和与代码质量提升的弱相关性问题。研究者提出了 DeepCRCEval 框架，该框架整合人类评估者和 Large Language Models (LLMs) 进行全面评估，并引入了创新基线 LLM-Reviewer，利用 few-shot learning 能力进行目标导向比较。实验结果显示，少于 10% 的基准评论适合自动化，而 DeepCRCEval 显著提高了评估可靠性，并将时间和成本分别降低了 88.78% 和 90.32%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to the 28th International Conference on Fundamental\n  Approaches to Software Engineering (FASE 2025), part of the 28th European\n  Joint Conferences on Theory and Practice of Software (ETAPS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.18291v2",
      "published_date": "2024-12-24 08:53:54 UTC",
      "updated_date": "2025-01-25 08:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:21:05.449047"
    },
    {
      "arxiv_id": "2412.18288v1",
      "title": "Towards understanding how attention mechanism works in deep learning",
      "title_zh": "向着理解注意力机制在深度学习中的工作原理",
      "authors": [
        "Tianyu Ruan",
        "Shihua Zhang"
      ],
      "abstract": "Attention mechanism has been extensively integrated within mainstream neural\nnetwork architectures, such as Transformers and graph attention networks. Yet,\nits underlying working principles remain somewhat elusive. What is its essence?\nAre there any connections between it and traditional machine learning\nalgorithms? In this study, we inspect the process of computing similarity using\nclassic metrics and vector space properties in manifold learning, clustering,\nand supervised learning. We identify the key characteristics of similarity\ncomputation and information propagation in these methods and demonstrate that\nthe self-attention mechanism in deep learning adheres to the same principles\nbut operates more flexibly and adaptively. We decompose the self-attention\nmechanism into a learnable pseudo-metric function and an information\npropagation process based on similarity computation. We prove that the\nself-attention mechanism converges to a drift-diffusion process through\ncontinuous modeling provided the pseudo-metric is a transformation of a metric\nand certain reasonable assumptions hold. This equation could be transformed\ninto a heat equation under a new metric. In addition, we give a first-order\nanalysis of attention mechanism with a general pseudo-metric function. This\nstudy aids in understanding the effects and principle of attention mechanism\nthrough physical intuition. Finally, we propose a modified attention mechanism\ncalled metric-attention by leveraging the concept of metric learning to\nfacilitate the ability to learn desired metrics more effectively. Experimental\nresults demonstrate that it outperforms self-attention regarding training\nefficiency, accuracy, and robustness.",
      "tldr_zh": "这篇论文探讨了 attention mechanism 在深度学习中的工作原理，将其与传统机器学习的相似性计算和信息传播（如在流形学习、聚类和监督学习中）进行比较，揭示了 self-attention 机制遵循相同的核心原则但更具灵活性。作者将 self-attention 机制分解为可学习的伪度量函数和基于相似性的信息传播过程，并证明其在特定假设下收敛于漂移扩散过程，并可转化为热方程。最终，他们提出了一种改进的 metric-attention 机制，利用度量学习来更有效地学习度量，实验结果显示其在训练效率、准确性和鲁棒性上均优于传统 self-attention。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML",
        "68T07",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18288v1",
      "published_date": "2024-12-24 08:52:06 UTC",
      "updated_date": "2024-12-24 08:52:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:22:16.881879"
    },
    {
      "arxiv_id": "2412.18287v1",
      "title": "Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Sheng Xiang",
        "Mingzhi Zhu",
        "Dawei Cheng",
        "Enxia Li",
        "Ruihui Zhao",
        "Yi Ouyang",
        "Ling Chen",
        "Yefeng Zheng"
      ],
      "abstract": "Credit card fraud incurs a considerable cost for both cardholders and issuing\nbanks. Contemporary methods apply machine learning-based classifiers to detect\nfraudulent behavior from labeled transaction records. But labeled data are\nusually a small proportion of billions of real transactions due to expensive\nlabeling costs, which implies that they do not well exploit many natural\nfeatures from unlabeled data. Therefore, we propose a semi-supervised graph\nneural network for fraud detection. Specifically, we leverage transaction\nrecords to construct a temporal transaction graph, which is composed of\ntemporal transactions (nodes) and interactions (edges) among them. Then we pass\nmessages among the nodes through a Gated Temporal Attention Network (GTAN) to\nlearn the transaction representation. We further model the fraud patterns\nthrough risk propagation among transactions. The extensive experiments are\nconducted on a real-world transaction dataset and two publicly available fraud\ndetection datasets. The result shows that our proposed method, namely GTAN,\noutperforms other state-of-the-art baselines on three fraud detection datasets.\nSemi-supervised experiments demonstrate the excellent fraud detection\nperformance of our model with only a tiny proportion of labeled data.",
      "tldr_zh": "本文提出了一种半监督信用卡欺诈检测方法，即通过属性驱动图表示（Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation），以解决标注数据稀缺的问题。方法利用交易记录构建temporal transaction graph，并采用Gated Temporal Attention Network (GTAN) 在节点间传递消息学习交易表示，同时通过风险传播建模欺诈模式。在真实数据集和两个公开欺诈检测数据集上的实验表明，GTAN 优于现有基线模型，即使仅使用少量标注数据，也显著提升了检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures, AAAI 2023, code:\n  https://github.com/AI4Risk/antifraud",
      "pdf_url": "http://arxiv.org/pdf/2412.18287v1",
      "published_date": "2024-12-24 08:48:48 UTC",
      "updated_date": "2024-12-24 08:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:22:28.106951"
    },
    {
      "arxiv_id": "2412.18279v1",
      "title": "Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization",
      "title_zh": "通过直接优势策略优化提升大语言模型的多步推理能力",
      "authors": [
        "Jiacai Liu",
        "Chaojie Wang",
        "Chris Yuhao Liu",
        "Liang Zeng",
        "Rui Yan",
        "Yiwen Sun",
        "Yang Liu",
        "Yahui Zhou"
      ],
      "abstract": "The role of reinforcement learning (RL) in enhancing the reasoning of large\nlanguage models (LLMs) is becoming increasingly significant. Despite the\nsuccess of RL in many scenarios, there are still many challenges in improving\nthe reasoning of LLMs. One challenge is the sparse reward, which makes\noptimization difficult for RL and necessitates a large amount of data samples.\nAnother challenge stems from the inherent instability of RL, particularly when\nusing Actor-Critic (AC) methods to derive optimal policies, which often leads\nto unstable training processes. To address these issues, we introduce Direct\nAdvantage Policy Optimization (DAPO), an novel step-level offline RL algorithm.\nUnlike standard alignment that rely solely outcome rewards to optimize policies\n(such as DPO), DAPO employs a critic function to predict the reasoning accuracy\nat each step, thereby generating dense signals to refine the generation\nstrategy. Additionally, the Actor and Critic components in DAPO are trained\nindependently, avoiding the co-training instability observed in standard AC\nalgorithms like PPO. We train DAPO on mathematical and code query datasets and\nthen evaluate its performance on multiple benchmarks. Our results show that\nDAPO can effectively enhance the mathematical and code capabilities on both SFT\nmodels and RL models, demonstrating the effectiveness of DAPO.",
      "tldr_zh": "本研究针对强化学习（RL）在提升大型语言模型（LLMs）的多步推理能力时面临的稀疏奖励和训练不稳定性等问题，提出了一种新型步级离线 RL 算法Direct Advantage Policy Optimization (DAPO)。DAPO 通过使用 critic 函数预测每个步骤的推理准确性，提供密集奖励信号来优化生成策略，同时让 Actor 和 Critic 组件独立训练，以避免标准 Actor-Critic (AC) 方法如 PPO 的不稳定性。实验在数学和代码查询数据集上进行，结果显示 DAPO 显著提高了 SFT 模型和 RL 模型的数学及代码能力，在多个基准测试中证明了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18279v1",
      "published_date": "2024-12-24 08:39:35 UTC",
      "updated_date": "2024-12-24 08:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:22:42.072933"
    },
    {
      "arxiv_id": "2412.18274v1",
      "title": "GenAI Content Detection Task 2: AI vs. Human -- Academic Essay Authenticity Challenge",
      "title_zh": "GenAI 内容检测任务 2：AI 与人类——学术论文真实性挑战",
      "authors": [
        "Shammur Absar Chowdhury",
        "Hind Almerekhi",
        "Mucahid Kutlu",
        "Kaan Efe Keles",
        "Fatema Ahmad",
        "Tasnim Mohiuddin",
        "George Mikros",
        "Firoj Alam"
      ],
      "abstract": "This paper presents a comprehensive overview of the first edition of the\nAcademic Essay Authenticity Challenge, organized as part of the GenAI Content\nDetection shared tasks collocated with COLING 2025. This challenge focuses on\ndetecting machine-generated vs. human-authored essays for academic purposes.\nThe task is defined as follows: \"Given an essay, identify whether it is\ngenerated by a machine or authored by a human.'' The challenge involves two\nlanguages: English and Arabic. During the evaluation phase, 25 teams submitted\nsystems for English and 21 teams for Arabic, reflecting substantial interest in\nthe task. Finally, seven teams submitted system description papers. The\nmajority of submissions utilized fine-tuned transformer-based models, with one\nteam employing Large Language Models (LLMs) such as Llama 2 and Llama 3. This\npaper outlines the task formulation, details the dataset construction process,\nand explains the evaluation framework. Additionally, we present a summary of\nthe approaches adopted by participating teams. Nearly all submitted systems\noutperformed the n-gram-based baseline, with the top-performing systems\nachieving F1 scores exceeding 0.98 for both languages, indicating significant\nprogress in the detection of machine-generated text.",
      "tldr_zh": "本论文概述了GenAI Content Detection任务2，即Academic Essay Authenticity Challenge，这是COLING 2025的一部分，专注于检测学术论文是AI生成的还是人类撰写的，涉及英语和阿拉伯语语言。任务定义为给定一篇论文，判断其为机器生成或人类创作，共吸引25个团队提交英语系统和21个团队提交阿拉伯语系统，其中7个团队提供了系统描述。参与团队主要采用fine-tuned transformer-based models和Large Language Models (LLMs)如Llama 2和Llama 3等技术，几乎所有系统均超过了n-gram-based baseline。结果显示，最佳系统的F1 scores超过0.98，证明了在AI生成文本检测领域取得了显著进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "AI Generated Content, Academic Essay, LLMs, Arabic, English",
      "pdf_url": "http://arxiv.org/pdf/2412.18274v1",
      "published_date": "2024-12-24 08:33:44 UTC",
      "updated_date": "2024-12-24 08:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:22:53.002408"
    },
    {
      "arxiv_id": "2412.18273v1",
      "title": "Sampling Bag of Views for Open-Vocabulary Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hojun Choi",
        "Junsuk Choe",
        "Hyunjung Shim"
      ],
      "abstract": "Existing open-vocabulary object detection (OVD) develops methods for testing\nunseen categories by aligning object region embeddings with corresponding VLM\nfeatures. A recent study leverages the idea that VLMs implicitly learn\ncompositional structures of semantic concepts within the image. Instead of\nusing an individual region embedding, it utilizes a bag of region embeddings as\na new representation to incorporate compositional structures into the OVD task.\nHowever, this approach often fails to capture the contextual concepts of each\nregion, leading to noisy compositional structures. This results in only\nmarginal performance improvements and reduced efficiency. To address this, we\npropose a novel concept-based alignment method that samples a more powerful and\nefficient compositional structure. Our approach groups contextually related\n``concepts'' into a bag and adjusts the scale of concepts within the bag for\nmore effective embedding alignment. Combined with Faster R-CNN, our method\nachieves improvements of 2.6 box AP50 and 0.5 mask AP over prior work on novel\ncategories in the open-vocabulary COCO and LVIS benchmarks. Furthermore, our\nmethod reduces CLIP computation in FLOPs by 80.3% compared to previous\nresearch, significantly enhancing efficiency. Experimental results demonstrate\nthat the proposed method outperforms previous state-of-the-art models on the\nOVD datasets.",
      "tldr_zh": "本研究针对开放词汇物体检测 (OVD) 的问题，提出了一种新型概念-based alignment 方法，通过采样更强大的组合结构，将上下文相关的 \"concepts\" 分组成 bag，并调整概念规模，以提升嵌入对齐的有效性和效率。该方法结合 Faster R-CNN，解决了现有 bag of region embeddings 策略的噪声问题，并在开放词汇 COCO 和 LVIS 基准上实现了 box AP50 提高 2.6 和 mask AP 提高 0.5 的性能提升，同时将 CLIP 计算的 FLOPs 减少 80.3%。实验结果表明，该方法在 OVD 数据集上超过了之前的最先进模型，为更准确且高效的物体检测提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.18273v1",
      "published_date": "2024-12-24 08:32:38 UTC",
      "updated_date": "2024-12-24 08:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:23:06.570235"
    },
    {
      "arxiv_id": "2412.18270v1",
      "title": "Annotating References to Mythological Entities in French Literature",
      "title_zh": "法国文学中神话实体引用的标注",
      "authors": [
        "Thierry Poibeau"
      ],
      "abstract": "In this paper, we explore the relevance of large language models (LLMs) for\nannotating references to Roman and Greek mythological entities in modern and\ncontemporary French literature. We present an annotation scheme and demonstrate\nthat recent LLMs can be directly applied to follow this scheme effectively,\nalthough not without occasionally making significant analytical errors.\nAdditionally, we show that LLMs (and, more specifically, ChatGPT) are capable\nof offering interpretative insights into the use of mythological references by\nliterary authors. However, we also find that LLMs struggle to accurately\nidentify relevant passages in novels (when used as an information retrieval\nengine), often hallucinating and generating fabricated examples-an issue that\nraises significant ethical concerns. Nonetheless, when used carefully, LLMs\nremain valuable tools for performing annotations with high accuracy, especially\nfor tasks that would be difficult to annotate comprehensively on a large scale\nthrough manual methods alone.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 在标注现代和当代法国文学中罗马和希腊神话实体引用的应用潜力。研究者提出了一种标注方案，并证明了 LLMs 可以有效执行该方案，尽管偶尔会犯重大分析错误。同时，LLMs 如 ChatGPT 能够提供对文学作者使用神话引用的解释性洞见，但在其作为信息检索引擎时，常出现幻觉和虚构例子，引发伦理担忧。尽管存在这些局限性，如果谨慎使用，LLMs 仍是高准确率标注的宝贵工具，尤其适合大规模手动方法难以覆盖的任务。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18270v1",
      "published_date": "2024-12-24 08:29:00 UTC",
      "updated_date": "2024-12-24 08:29:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:23:16.211906"
    },
    {
      "arxiv_id": "2412.18256v1",
      "title": "Robust Semi-Supervised Learning in Open Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Lan-Zhe Guo",
        "Lin-Han Jia",
        "Jie-Jing Shao",
        "Yu-Feng Li"
      ],
      "abstract": "Semi-supervised learning (SSL) aims to improve performance by exploiting\nunlabeled data when labels are scarce. Conventional SSL studies typically\nassume close environments where important factors (e.g., label, feature,\ndistribution) between labeled and unlabeled data are consistent. However, more\npractical tasks involve open environments where important factors between\nlabeled and unlabeled data are inconsistent. It has been reported that\nexploiting inconsistent unlabeled data causes severe performance degradation,\neven worse than the simple supervised learning baseline. Manually verifying the\nquality of unlabeled data is not desirable, therefore, it is important to study\nrobust SSL with inconsistent unlabeled data in open environments. This paper\nbriefly introduces some advances in this line of research, focusing on\ntechniques concerning label, feature, and data distribution inconsistency in\nSSL, and presents the evaluation benchmarks. Open research problems are also\ndiscussed for reference purposes.",
      "tldr_zh": "这篇论文探讨了在开放环境下的鲁棒半监督学习 (SSL)，强调了当有标签和无标签数据在标签、特征或数据分部方面不一致时，传统 SSL 方法可能导致性能严重下降，甚至不如单纯的监督学习基准。论文介绍了针对这些不一致性的关键技术，包括处理 label、feature 和 distribution inconsistency 的进展，并提供了相应的评估基准。通过这些方法，研究旨在提升 SSL 的鲁棒性，避免手动验证无标签数据的需求。最终，论文讨论了未来开放的研究问题，以推动该领域的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18256v1",
      "published_date": "2024-12-24 08:13:01 UTC",
      "updated_date": "2024-12-24 08:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:23:28.878424"
    },
    {
      "arxiv_id": "2412.18248v1",
      "title": "Detection and Forecasting of Parkinson Disease Progression from Speech Signal Features Using MultiLayer Perceptron and LSTM",
      "title_zh": "翻译失败",
      "authors": [
        "Majid Ali",
        "Hina Shakir",
        "Asia Samreen",
        "Sohaib Ahmed"
      ],
      "abstract": "Accurate diagnosis of Parkinson disease, especially in its early stages, can\nbe a challenging task. The application of machine learning techniques helps\nimprove the diagnostic accuracy of Parkinson disease detection but only few\nstudies have presented work towards the prediction of disease progression. In\nthis research work, Long Short Term Memory LSTM was trained using the\ndiagnostic features on Parkinson patients speech signals, to predict the\ndisease progression while a Multilayer Perceptron MLP was trained on the same\ndiagnostic features to detect the disease. Diagnostic features selected using\ntwo well-known feature selection methods named Relief-F and Sequential Forward\nSelection and applied on LSTM and MLP have shown to accurately predict the\ndisease progression as stage 2 and 3 and its existence respectively.",
      "tldr_zh": "这篇论文针对帕金森病（Parkinson disease）的早期诊断和进展预测挑战，使用机器学习模型从患者语音信号特征中进行分析。具体方法包括训练 LSTM 模型来预测疾病进展（例如从阶段 2 到 3），以及训练 Multilayer Perceptron (MLP) 模型来检测疾病的存在，同时采用 Relief-F 和 Sequential Forward Selection 两种特征选择方法来优化诊断特征。实验结果表明，这些模型能够准确预测疾病进展阶段并提高检测准确性，为帕金森病管理提供潜在工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18248v1",
      "published_date": "2024-12-24 08:02:43 UTC",
      "updated_date": "2024-12-24 08:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:23:39.731707"
    },
    {
      "arxiv_id": "2412.18247v2",
      "title": "Fréchet regression with implicit denoising and multicollinearity reduction",
      "title_zh": "Fréchet 回归的隐式去噪与多重共线性减少",
      "authors": [
        "Dou El Kefel Mansouri",
        "Seif-Eddine Benkabou",
        "Khalid Benabdeslem"
      ],
      "abstract": "Fr\\'echet regression extends linear regression to model complex responses\n  in metric spaces, making it particularly relevant for multi-label regression,\n  where eachinstance can have multiple associated labels. However, addressing\n  noise and dependencies among predictors within this framework remains un\nderexplored. In this paper, we present an extension of the Global Fr\\'echet re\ngression model that enables explicit modeling of relationships between input\n  variables and multiple responses. To address challenges arising from noise\n  and multicollinearity, we propose a novel framework based on implicit regu\nlarization, which preserves the intrinsic structure of the data while\neffectively\n  capturing complex dependencies. Our approach ensures accurate and efficient\n  modeling without the biases introduced by traditional explicit regularization\n  methods. Theoretical guarantees are provided, and the performance of the\n  proposed method is demonstrated through numerical experiments.",
      "tldr_zh": "这篇论文扩展了 Fréchet regression 模型，应用于多标签回归等复杂响应空间中，允许显式建模输入变量与多个响应的关系。作者提出了一种基于 implicit regularization 的新框架，以有效处理噪声和 multicollinearity，同时保留数据内在结构并捕捉复杂依赖关系，避免了传统显式正则化方法的偏差。实验结果和理论保证证明了该方法的准确性和效率，为高级回归建模提供了可靠工具。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18247v2",
      "published_date": "2024-12-24 08:02:28 UTC",
      "updated_date": "2025-03-29 12:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:23:51.532556"
    },
    {
      "arxiv_id": "2412.18241v1",
      "title": "An Automatic Graph Construction Framework based on Large Language Models for Recommendation",
      "title_zh": "基于大语言模型的自动图构建框架用于推荐",
      "authors": [
        "Rong Shan",
        "Jianghao Lin",
        "Chenxu Zhu",
        "Bo Chen",
        "Menghui Zhu",
        "Kangning Zhang",
        "Jieming Zhu",
        "Ruiming Tang",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "abstract": "Graph neural networks (GNNs) have emerged as state-of-the-art methods to\nlearn from graph-structured data for recommendation. However, most existing\nGNN-based recommendation methods focus on the optimization of model structures\nand learning strategies based on pre-defined graphs, neglecting the importance\nof the graph construction stage. Earlier works for graph construction usually\nrely on speciffic rules or crowdsourcing, which are either too simplistic or\ntoo labor-intensive. Recent works start to utilize large language models (LLMs)\nto automate the graph construction, in view of their abundant open-world\nknowledge and remarkable reasoning capabilities. Nevertheless, they generally\nsuffer from two limitations: (1) invisibility of global view (e.g., overlooking\ncontextual information) and (2) construction inefficiency. To this end, we\nintroduce AutoGraph, an automatic graph construction framework based on LLMs\nfor recommendation. Specifically, we first use LLMs to infer the user\npreference and item knowledge, which is encoded as semantic vectors. Next, we\nemploy vector quantization to extract the latent factors from the semantic\nvectors. The latent factors are then incorporated as extra nodes to link the\nuser/item nodes, resulting in a graph with in-depth global-view semantics. We\nfurther design metapath-based message aggregation to effectively aggregate the\nsemantic and collaborative information. The framework is model-agnostic and\ncompatible with different backbone models. Extensive experiments on three\nreal-world datasets demonstrate the efficacy and efffciency of AutoGraph\ncompared to existing baseline methods. We have deployed AutoGraph in Huawei\nadvertising platform, and gain a 2.69% improvement on RPM and a 7.31%\nimprovement on eCPM in the online A/B test. Currently AutoGraph has been used\nas the main trafffc model, serving hundreds of millions of people.",
      "tldr_zh": "本研究提出AutoGraph，一种基于大型语言模型(LLMs)的自动图构建框架，用于提升图神经网络(GNNs)在推荐系统中的性能。该框架首先利用LLMs推断用户偏好和项目知识，并将其编码为语义向量，然后通过向量量化提取潜在因素，将这些因素作为额外节点连接用户/项目节点，以构建包含全局语义的图结构。框架还设计了基于metapath的消息聚合机制，以有效整合语义和协作信息，并兼容多种骨干模型。在三个真实数据集上的实验显示，AutoGraph比现有基线方法更高效有效；在线部署于华为广告平台后，实现了RPM提升2.69%和eCPM提升7.31%，并已作为主要流量模型服务数亿用户。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2412.18241v1",
      "published_date": "2024-12-24 07:51:29 UTC",
      "updated_date": "2024-12-24 07:51:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:24:04.051854"
    },
    {
      "arxiv_id": "2412.18224v1",
      "title": "Expand VSR Benchmark for VLLM to Expertize in Spatial Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Peijin Xie",
        "Lin Sun",
        "Bingquan Liu",
        "Dexin Wang",
        "Xiangzheng Zhang",
        "Chengjie Sun",
        "Jiajia Zhang"
      ],
      "abstract": "Distinguishing spatial relations is a basic part of human cognition which\nrequires fine-grained perception on cross-instance. Although benchmarks like\nMME, MMBench and SEED comprehensively have evaluated various capabilities which\nalready include visual spatial reasoning(VSR). There is still a lack of\nsufficient quantity and quality evaluation and optimization datasets for Vision\nLarge Language Models(VLLMs) specifically targeting visual positional\nreasoning. To handle this, we first diagnosed current VLLMs with the VSR\ndataset and proposed a unified test set. We found current VLLMs to exhibit a\ncontradiction of over-sensitivity to language instructions and\nunder-sensitivity to visual positional information. By expanding the original\nbenchmark from two aspects of tunning data and model structure, we mitigated\nthis phenomenon. To our knowledge, we expanded spatially positioned image data\ncontrollably using diffusion models for the first time and integrated original\nvisual encoding(CLIP) with other 3 powerful visual encoders(SigLIP, SAM and\nDINO). After conducting combination experiments on scaling data and models, we\nobtained a VLLM VSR Expert(VSRE) that not only generalizes better to different\ninstructions but also accurately distinguishes differences in visual positional\ninformation. VSRE achieved over a 27\\% increase in accuracy on the VSR test\nset. It becomes a performant VLLM on the position reasoning of both the VSR\ndataset and relevant subsets of other evaluation benchmarks. We open-sourced\nthe expanded model with data and Appendix at\n\\url{https://github.com/peijin360/vsre} and hope it will accelerate\nadvancements in VLLM on VSR learning.",
      "tldr_zh": "该论文诊断了当前 Vision Large Language Models (VLLMs) 在视觉空间推理 (VSR) 任务上存在的问题，即对语言指令过度敏感 (over-sensitivity) 而对视觉位置信息不敏感 (under-sensitivity)，并扩展了 VSR 基准以优化模型性能。作者通过使用扩散模型 (diffusion models) 可控地扩展空间定位图像数据，并将原始视觉编码器 CLIP 与 SigLIP、SAM 和 DINO 整合，进行了数据和模型结构的组合实验。最终，他们开发了 VSR Expert (VSRE) 模型，使其在不同指令上泛化更好，并在 VSR 测试集上准确率提升超过 27%，并开源了模型、数据和相关资源以推进 VLLMs 在 VSR 学习领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18224v1",
      "published_date": "2024-12-24 07:13:17 UTC",
      "updated_date": "2024-12-24 07:13:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:24:17.754873"
    },
    {
      "arxiv_id": "2412.18207v1",
      "title": "Sharper Error Bounds in Late Fusion Multi-view Clustering Using Eigenvalue Proportion",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Du",
        "Henghui Jiang",
        "Xiaodong Li",
        "Yiqing Guo",
        "Yan Chen",
        "Feijiang Li",
        "Peng Zhou",
        "Yuhua Qian"
      ],
      "abstract": "Multi-view clustering (MVC) aims to integrate complementary information from\nmultiple views to enhance clustering performance. Late Fusion Multi-View\nClustering (LFMVC) has shown promise by synthesizing diverse clustering results\ninto a unified consensus. However, current LFMVC methods struggle with noisy\nand redundant partitions and often fail to capture high-order correlations\nacross views. To address these limitations, we present a novel theoretical\nframework for analyzing the generalization error bounds of multiple kernel\n$k$-means, leveraging local Rademacher complexity and principal eigenvalue\nproportions. Our analysis establishes a convergence rate of $\\mathcal{O}(1/n)$,\nsignificantly improving upon the existing rate in the order of\n$\\mathcal{O}(\\sqrt{k/n})$. Building on this insight, we propose a low-pass\ngraph filtering strategy within a multiple linear $k$-means framework to\nmitigate noise and redundancy, further refining the principal eigenvalue\nproportion and enhancing clustering accuracy. Experimental results on benchmark\ndatasets confirm that our approach outperforms state-of-the-art methods in\nclustering performance and robustness. The related codes is available at\nhttps://github.com/csliangdu/GMLKM .",
      "tldr_zh": "本研究针对多视图聚类(Multi-view Clustering, MVC)中的晚融合方法(Late Fusion Multi-View Clustering, LFMVC)问题，提出一个新理论框架，利用局部 Rademacher 复杂度(local Rademacher complexity)和主特征值比例(principal eigenvalue proportions)分析多个核 k-means 的泛化错误边界，实现了收敛率从 $\\mathcal{O}(\\sqrt{k/n})$ 提升至 $\\mathcal{O}(1/n)$。基于此框架，该方法引入低通图过滤策略(low-pass graph filtering)在多个线性 k-means 框架中，减少噪声和冗余分区，并优化高阶跨视图相关性。实验结果显示，该方法在基准数据集上超越最先进方法，在聚类性能和鲁棒性方面表现出色，相关代码可访问 https://github.com/csliangdu/GMLKM。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18207v1",
      "published_date": "2024-12-24 06:24:08 UTC",
      "updated_date": "2024-12-24 06:24:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:24:28.662761"
    },
    {
      "arxiv_id": "2412.18194v1",
      "title": "VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Reasoning Tasks",
      "title_zh": "VLABench：一种用于语言条件机器人操作的大规模基准测试，包含长",
      "authors": [
        "Shiduo Zhang",
        "Zhe Xu",
        "Peiju Liu",
        "Xiaopeng Yu",
        "Yuan Li",
        "Qinghui Gao",
        "Zhaoye Fei",
        "Zhangyue Yin",
        "Zuxuan Wu",
        "Yu-Gang Jiang",
        "Xipeng Qiu"
      ],
      "abstract": "General-purposed embodied agents are designed to understand the users'\nnatural instructions or intentions and act precisely to complete universal\ntasks. Recently, methods based on foundation models especially\nVision-Language-Action models (VLAs) have shown a substantial potential to\nsolve language-conditioned manipulation (LCM) tasks well. However, existing\nbenchmarks do not adequately meet the needs of VLAs and relative algorithms. To\nbetter define such general-purpose tasks in the context of LLMs and advance the\nresearch in VLAs, we present VLABench, an open-source benchmark for evaluating\nuniversal LCM task learning. VLABench provides 100 carefully designed\ncategories of tasks, with strong randomization in each category of task and a\ntotal of 2000+ objects. VLABench stands out from previous benchmarks in four\nkey aspects: 1) tasks requiring world knowledge and common sense transfer, 2)\nnatural language instructions with implicit human intentions rather than\ntemplates, 3) long-horizon tasks demanding multi-step reasoning, and 4)\nevaluation of both action policies and language model capabilities. The\nbenchmark assesses multiple competencies including understanding of\nmesh\\&texture, spatial relationship, semantic instruction, physical laws,\nknowledge transfer and reasoning, etc. To support the downstream finetuning, we\nprovide high-quality training data collected via an automated framework\nincorporating heuristic skills and prior information. The experimental results\nindicate that both the current state-of-the-art pretrained VLAs and the\nworkflow based on VLMs face challenges in our tasks.",
      "tldr_zh": "本文提出 VLABench，一个大规模开源基准，用于评估语言条件下的机器人操作（Language-Conditioned Manipulation, LCM）任务，特别强调长horizon推理任务。该基准包括 100 个精心设计的任务类别、2000+ 对象，并突出四方面创新：如需要世界知识和常识转移、自然语言指令（非模板形式）、多步推理，以及对动作策略和语言模型能力的综合评估。同时，VLABench 通过自动化框架提供高质量训练数据，实验结果表明，当前最先进的 Vision-Language-Action models (VLAs) 和基于 VLM 的工作流在这些任务中仍面临显著挑战。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18194v1",
      "published_date": "2024-12-24 06:03:42 UTC",
      "updated_date": "2024-12-24 06:03:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:24:40.329956"
    },
    {
      "arxiv_id": "2412.18190v1",
      "title": "An Analysis on Automated Metrics for Evaluating Japanese-English Chat Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Andre Rusli",
        "Makoto Shishido"
      ],
      "abstract": "This paper analyses how traditional baseline metrics, such as BLEU and TER,\nand neural-based methods, such as BERTScore and COMET, score several NMT models\nperformance on chat translation and how these metrics perform when compared to\nhuman-annotated scores. The results show that for ranking NMT models in chat\ntranslations, all metrics seem consistent in deciding which model outperforms\nthe others. This implies that traditional baseline metrics, which are faster\nand simpler to use, can still be helpful. On the other hand, when it comes to\nbetter correlation with human judgment, neural-based metrics outperform\ntraditional metrics, with COMET achieving the highest correlation with the\nhuman-annotated score on a chat translation. However, we show that even the\nbest metric struggles when scoring English translations from sentences with\nanaphoric zero-pronoun in Japanese.",
      "tldr_zh": "本研究分析了传统指标（如 BLEU 和 TER）以及神经网络指标（如 BERTScore 和 COMET）在评估日英聊天翻译 NMT 模型性能时的表现，并将其与人类标注分数进行比较。结果显示，所有指标在排名 NMT 模型时表现出一致性，这表明传统指标因其速度和简单性而仍有实用价值。在与人类判断的相关性上，神经指标表现更优，COMET 取得了最高的相关性。然而，即使是最佳指标，在处理日语中带有 anaphoric zero-pronoun 的句子翻译时，仍存在显著挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 29th Annual Meeting of the Association for Natural\n  Language Processing (NLP2023). Published version available at\n  https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/A8-1.pdf",
      "pdf_url": "http://arxiv.org/pdf/2412.18190v1",
      "published_date": "2024-12-24 05:54:40 UTC",
      "updated_date": "2024-12-24 05:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:24:51.977229"
    },
    {
      "arxiv_id": "2412.18188v1",
      "title": "On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for Sentiment Classification in Distant Language Pairs",
      "title_zh": "翻译失败",
      "authors": [
        "Andre Rusli",
        "Makoto Shishido"
      ],
      "abstract": "This research explores the applicability of cross-lingual transfer learning\nfrom English to Japanese and Indonesian using the XLM-R pre-trained model. The\nresults are compared with several previous works, either by models using a\nsimilar zero-shot approach or a fully-supervised approach, to provide an\noverview of the zero-shot transfer learning approach's capability using XLM-R\nin comparison with existing models. Our models achieve the best result in one\nJapanese dataset and comparable results in other datasets in Japanese and\nIndonesian languages without being trained using the target language.\nFurthermore, the results suggest that it is possible to train a multi-lingual\nmodel, instead of one model for each language, and achieve promising results.",
      "tldr_zh": "本研究探讨了零-shot cross-lingual transfer learning 在情感分类中的适用性，使用 XLM-R 预训练模型从英语向日语和印尼语进行转移。研究将该零-shot 方法与之前的类似零-shot 或 fully-supervised 方法进行比较，结果显示模型在某些日语数据集上取得了最佳性能，在其他日语和印尼语数据集上表现相当，且无需使用目标语言进行训练。结果进一步表明，训练一个多语言模型而非针对每个语言单独模型，能够实现有前景的性能，提升了跨语言迁移学习的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the 28th Annual Meeting of the Association for Natural\n  Language Processing (NLP2022). Published version available at\n  https://www.anlp.jp/proceedings/annual_meeting/2022/pdf_dir/A6-1.pdf",
      "pdf_url": "http://arxiv.org/pdf/2412.18188v1",
      "published_date": "2024-12-24 05:50:18 UTC",
      "updated_date": "2024-12-24 05:50:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:25:03.764743"
    },
    {
      "arxiv_id": "2412.18185v3",
      "title": "TextMatch: Enhancing Image-Text Consistency Through Multimodal Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yucong Luo",
        "Mingyue Cheng",
        "Jie Ouyang",
        "Xiaoyu Tao",
        "Qi Liu"
      ],
      "abstract": "Text-to-image generative models excel in creating images from text but\nstruggle with ensuring alignment and consistency between outputs and prompts.\nThis paper introduces TextMatch, a novel framework that leverages multimodal\noptimization to address image-text discrepancies in text-to-image (T2I)\ngeneration and editing. TextMatch employs a scoring strategy powered by large\nlanguage models (LLMs) and visual question-answering (VQA) models to evaluate\nsemantic consistency between prompts and generated images. By integrating\nmultimodal in-context learning and chain of thought reasoning, our method\ndynamically refines prompts through iterative optimization. This process\nensures that the generated images better capture user intent of, resulting in\nhigher fidelity and relevance. Extensive experiments demonstrate that TextMatch\nsignificantly improves text-image consistency across multiple benchmarks,\nestablishing a reliable framework for advancing the capabilities of\ntext-to-image generative models. Our code is available at\nhttps://anonymous.4open.science/r/TextMatch-F55C/.",
      "tldr_zh": "本研究提出 TextMatch 框架，通过多模态优化提升文本到图像 (T2I) 生成和编辑中的图像-文本一致性，解决现有模型在输出与提示语义对齐方面的不足。TextMatch 利用大型语言模型 (LLMs) 和视觉问答 (VQA) 模型的评分策略来评估语义一致性，并结合多模态 in-context learning 和 chain of thought reasoning 进行动态提示迭代优化，从而确保生成的图像更准确地捕捉用户意图，提高保真度和相关性。实验结果显示，TextMatch 在多个基准上显著改善文本-图像一致性，为推进 T2I 生成模型的能力提供了可靠框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Need a lot of refinements",
      "pdf_url": "http://arxiv.org/pdf/2412.18185v3",
      "published_date": "2024-12-24 05:38:45 UTC",
      "updated_date": "2025-01-25 02:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:25:16.245908"
    },
    {
      "arxiv_id": "2412.18177v1",
      "title": "Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization",
      "title_zh": "翻译失败",
      "authors": [
        "Sihao Liu",
        "Yibo Yang",
        "Xiaojie Li",
        "David A. Clifton",
        "Bernard Ghanem"
      ],
      "abstract": "Online continual learning (OCL) seeks to learn new tasks from data streams\nthat appear only once, while retaining knowledge of previously learned tasks.\nMost existing methods rely on replay, focusing on enhancing memory retention\nthrough regularization or distillation. However, they often overlook the\nadaptability of the model, limiting the ability to learn generalizable and\ndiscriminative features incrementally from online training data. To address\nthis, we introduce a plug-and-play module, S6MOD, which can be integrated into\nmost existing methods and directly improve adaptability. Specifically, S6MOD\nintroduces an extra branch after the backbone, where a mixture of\ndiscretization selectively adjusts parameters in a selective state space model,\nenriching selective scan patterns such that the model can adaptively select the\nmost sensitive discretization method for current dynamics. We further design a\nclass-conditional routing algorithm for dynamic, uncertainty-based adjustment\nand implement a contrastive discretization loss to optimize it. Extensive\nexperiments combining our module with various models demonstrate that S6MOD\nsignificantly enhances model adaptability, leading to substantial performance\ngains and achieving the state-of-the-art results.",
      "tldr_zh": "本研究针对在线持续学习 (OCL)，提出一个可插拔模块 S6MOD，以解决现有方法依赖重放 (replay) 而忽略模型适应性的问题。S6MOD 在主干网络后添加额外分支，利用状态空间模型 (State Space Model) 和类条件混合离散化 (Class-Conditional Mixture of Discretization)，通过选择性参数调整、类条件路由算法以及对比离散化损失 (Contrastive Discretization Loss) 来增强模型对在线数据流的适应性和特征泛化能力。实验结果显示，与各种基线模型结合后，S6MOD 显著提升了性能，实现最先进的结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18177v1",
      "published_date": "2024-12-24 05:25:21 UTC",
      "updated_date": "2024-12-24 05:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:25:28.974241"
    },
    {
      "arxiv_id": "2412.18176v2",
      "title": "Molar: Multimodal LLMs with Collaborative Filtering Alignment for Enhanced Sequential Recommendation",
      "title_zh": "Molar：多模态大语言模型的协同过滤对齐用于增强序列推荐",
      "authors": [
        "Yucong Luo",
        "Qitao Qin",
        "Hao Zhang",
        "Mingyue Cheng",
        "Ruiran Yan",
        "Kefan Wang",
        "Jie Ouyang"
      ],
      "abstract": "Sequential recommendation (SR) systems have evolved significantly over the\npast decade, transitioning from traditional collaborative filtering to deep\nlearning approaches and, more recently, to large language models (LLMs). While\nthe adoption of LLMs has driven substantial advancements, these models\ninherently lack collaborative filtering information, relying primarily on\ntextual content data neglecting other modalities and thus failing to achieve\noptimal recommendation performance. To address this limitation, we propose\nMolar, a Multimodal large language sequential recommendation framework that\nintegrates multiple content modalities with ID information to capture\ncollaborative signals effectively. Molar employs an MLLM to generate unified\nitem representations from both textual and non-textual data, facilitating\ncomprehensive multimodal modeling and enriching item embeddings. Additionally,\nit incorporates collaborative filtering signals through a post-alignment\nmechanism, which aligns user representations from content-based and ID-based\nmodels, ensuring precise personalization and robust performance. By seamlessly\ncombining multimodal content with collaborative filtering insights, Molar\ncaptures both user interests and contextual semantics, leading to superior\nrecommendation accuracy. Extensive experiments validate that Molar\nsignificantly outperforms traditional and LLM-based baselines, highlighting its\nstrength in utilizing multimodal data and collaborative signals for sequential\nrecommendation tasks. The source code is available at\nhttps://anonymous.4open.science/r/Molar-8B06/.",
      "tldr_zh": "该论文提出Molar框架，一种多模态大型语言模型(Multimodal LLMs)系统，用于提升顺序推荐(Sequential Recommendation)，通过整合多模态内容（如文本和非文本数据）与协同过滤(Collaborative Filtering)信号来解决LLMs缺乏协作信息的局限性。Molar利用多模态大语言模型(MLLM)生成统一的物品表示，并通过后置对齐机制(post-alignment mechanism)将基于内容的用户表示与基于ID的模型对齐，实现精确的个性化推荐。实验结果显示，Molar在顺序推荐任务中显著优于传统和LLM-based基线，证明了其在利用多模态数据和协作信号方面的优势。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18176v2",
      "published_date": "2024-12-24 05:23:13 UTC",
      "updated_date": "2024-12-30 09:24:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:25:40.315957"
    },
    {
      "arxiv_id": "2412.18174v1",
      "title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent",
      "title_zh": "INVESTORBENCH：一个基于LLM代理的金融决策任务基准",
      "authors": [
        "Haohang Li",
        "Yupeng Cao",
        "Yangyang Yu",
        "Shashidhar Reddy Javaji",
        "Zhiyang Deng",
        "Yueru He",
        "Yuechen Jiang",
        "Zining Zhu",
        "Koduvayur Subbalakshmi",
        "Guojun Xiong",
        "Jimin Huang",
        "Lingfei Qian",
        "Xueqing Peng",
        "Qianqian Xie",
        "Jordan W. Suchow"
      ],
      "abstract": "Recent advancements have underscored the potential of large language model\n(LLM)-based agents in financial decision-making. Despite this progress, the\nfield currently encounters two main challenges: (1) the lack of a comprehensive\nLLM agent framework adaptable to a variety of financial tasks, and (2) the\nabsence of standardized benchmarks and consistent datasets for assessing agent\nperformance. To tackle these issues, we introduce \\textsc{InvestorBench}, the\nfirst benchmark specifically designed for evaluating LLM-based agents in\ndiverse financial decision-making contexts. InvestorBench enhances the\nversatility of LLM-enabled agents by providing a comprehensive suite of tasks\napplicable to different financial products, including single equities like\nstocks, cryptocurrencies and exchange-traded funds (ETFs). Additionally, we\nassess the reasoning and decision-making capabilities of our agent framework\nusing thirteen different LLMs as backbone models, across various market\nenvironments and tasks. Furthermore, we have curated a diverse collection of\nopen-source, multi-modal datasets and developed a comprehensive suite of\nenvironments for financial decision-making. This establishes a highly\naccessible platform for evaluating financial agents' performance across various\nscenarios.",
      "tldr_zh": "该论文针对LLM-based agents在金融决策中的应用，指出现有挑战包括缺乏通用框架和标准化基准，并引入InvestorBench作为首个评估这些代理的综合基准。InvestorBench涵盖多种金融任务，如股票、加密货币和ETFs，提供多样化的数据集和环境，以测试代理的推理和决策能力。研究使用13种不同LLMs作为骨干模型进行评估，展示了在各种市场情境下的性能提升，为金融决策代理的开发和评估提供了可访问的平台。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "q-fin.CP"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18174v1",
      "published_date": "2024-12-24 05:22:33 UTC",
      "updated_date": "2024-12-24 05:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:25:50.610000"
    },
    {
      "arxiv_id": "2412.18169v4",
      "title": "KunServe: Efficient Parameter-centric Memory Management for LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Rongxin Cheng",
        "Yuxin Lai",
        "Xingda Wei",
        "Rong Chen",
        "Haibo Chen"
      ],
      "abstract": "Serving LLMs with a cluster of GPUs is common nowadays, where the serving\nsystem must meet strict latency SLOs required by applications. However, the\nstateful nature of LLM serving requires maintaining huge states (i.e., KVCache)\nin limited GPU memory. Under spikes in real-world workloads, GPU memory can be\neasily throttled, leading to orders of magnitude higher response latency due to\nqueuing introduced by waiting for KVCache to be reclaimed. Prior\nKVCache-centric approaches handle load throttling by dropping, migrating, or\nswapping KVCache. These methods fail to release sufficient memory quickly with\nrequests still queued.\n  This paper proposes the first parameter-centric approach to handling\nthrottling by selectively dropping replicated parameters to instantly free\nmemory for requests, based on an unnoticed observation that model parameters\nare commonly replicated across GPUs for serving LLMs. With additional memory,\nall requests can be served with a larger batch without queuing. To make the\nparameter-centric approach correct and efficient, we cooperatively execute\nrequests on GPUs with a complete copy of parameters using pipeline parallelism,\nand derive an appropriate drop plan without unnecessary cooperation. We also\ndesign techniques to minimize the performance overhead due to pipeline\nparallelism with the execution patterns of requests under drop. Evaluations\nshow that {\\sys} reduces the tail TTFT of requests under throttling by up to\n72.2 times compared to the state-of-the-art systems including Llumnix, vLLM and\nInferCept.",
      "tldr_zh": "该论文提出KunServe，一种高效的parameter-centric内存管理方法，用于LLM Serving，以解决GPU内存瓶颈问题，特别是负载高峰时KVCache导致的响应延迟增加。不同于传统的KVCache-centric方法，KunServe通过选择性丢弃模型参数的复制副本来立即释放内存，并结合pipeline parallelism在有完整参数副本的GPU上执行请求，以最小化开销并优化请求处理。实验结果显示，KunServe将请求的尾部TTFT减少高达72.2倍，优于现有系统如Llumnix、vLLM和InferCept，从而显著提升LLM服务的性能和可靠性。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18169v4",
      "published_date": "2024-12-24 05:07:46 UTC",
      "updated_date": "2025-05-20 16:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:26:03.612171"
    },
    {
      "arxiv_id": "2501.06193v1",
      "title": "A Novel Task-Driven Method with Evolvable Interactive Agents Using Event Trees for Enhanced Emergency Decision Support",
      "title_zh": "一种新颖的任务驱动方法：利用可演化交互代理和事件树以增强紧急决策支持",
      "authors": [
        "Xingyu Xiao",
        "Peng Chen",
        "Ben Qi",
        "Jingang Liang",
        "Jiejuan Tong",
        "Haitao Wang"
      ],
      "abstract": "As climate change and other global challenges increase the likelihood of\nunforeseen emergencies, the limitations of human-driven strategies in critical\nsituations become more pronounced. Inadequate pre-established emergency plans\ncan lead operators to become overwhelmed during complex systems malfunctions.\nThis study addresses the urgent need for agile decision-making in response to\nvarious unforeseen incidents through a novel approach, EvoTaskTree (a\ntask-driven method with evolvable interactive agents using event trees for\nemergency decision support). This advanced approach integrates two types of\nagents powered by large language models (LLMs): task executors, responsible for\nexecuting critical procedures, and task validators, ensuring the efficacy of\nthose actions. By leveraging insights from event tree analysis, our framework\nencompasses three crucial tasks: initiating event subevent analysis, event tree\nheader event analysis, and decision recommendations. The agents learn from both\nsuccessful and unsuccessful responses from these tasks. Finally, we use nuclear\npower plants as a demonstration of a safety-critical system. Our findings\nindicate that the designed agents are not only effective but also outperform\nexisting approaches, achieving an impressive accuracy rate of up to 100 % in\nprocessing previously unencoun32 tered incident scenarios. This paper\ndemonstrates that EvoTaskTree significantly enhances the rapid formulation of\nemergency decision-making.",
      "tldr_zh": "本研究提出了一种名为EvoTaskTree的新型任务驱动方法，利用事件树和可演化的交互代理（由大型语言模型LLMs驱动），旨在提升紧急决策支持，应对气候变化等引发的复杂突发事件。该方法包括任务执行者（负责执行关键程序）和任务验证者（确保行动有效性），并处理起始事件子事件分析、事件树头部事件分析以及决策推荐等核心任务，代理可从成功与失败响应中学习。在核电站安全场景的演示中，EvoTaskTree实现了高达100%的准确率，显著优于现有方法，并证明了其在快速制定紧急决策方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06193v1",
      "published_date": "2024-12-24 04:53:46 UTC",
      "updated_date": "2024-12-24 04:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:26:16.179944"
    },
    {
      "arxiv_id": "2412.18163v1",
      "title": "Survey of Pseudonymization, Abstractive Summarization & Spell Checker for Hindi and Marathi",
      "title_zh": "翻译失败",
      "authors": [
        "Rasika Ransing",
        "Mohammed Amaan Dhamaskar",
        "Ayush Rajpurohit",
        "Amey Dhoke",
        "Sanket Dalvi"
      ],
      "abstract": "India's vast linguistic diversity presents unique challenges and\nopportunities for technological advancement, especially in the realm of Natural\nLanguage Processing (NLP). While there has been significant progress in NLP\napplications for widely spoken languages, the regional languages of India, such\nas Marathi and Hindi, remain underserved. Research in the field of NLP for\nIndian regional languages is at a formative stage and holds immense\nsignificance. The paper aims to build a platform which enables the user to use\nvarious features like text anonymization, abstractive text summarization and\nspell checking in English, Hindi and Marathi language. The aim of these tools\nis to serve enterprise and consumer clients who predominantly use Indian\nRegional Languages.",
      "tldr_zh": "该论文调查了针对Hindi和Marathi语言的Pseudonymization（文本匿名化）、Abstractive Summarization（抽象文本总结）和Spell Checker（拼写检查）技术，强调了印度语言多样性对Natural Language Processing (NLP) 的挑战和机遇。研究指出，Hindi和Marathi等区域语言在NLP应用中仍被忽视，因此构建了一个集成平台，提供这些工具的功能，以支持英语、Hindi和Marathi语言。平台旨在服务于主要使用印度区域语言的企业和消费者客户，推动区域语言的NLP发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18163v1",
      "published_date": "2024-12-24 04:51:32 UTC",
      "updated_date": "2024-12-24 04:51:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:26:27.042002"
    },
    {
      "arxiv_id": "2412.18161v1",
      "title": "VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities",
      "title_zh": "VISION: 用于科学用户设施中",
      "authors": [
        "Shray Mathur",
        "Noah van der Vleuten",
        "Kevin Yager",
        "Esther Tsai"
      ],
      "abstract": "Scientific user facilities, such as synchrotron beamlines, are equipped with\na wide array of hardware and software tools that require a codebase for\nhuman-computer-interaction. This often necessitates developers to be involved\nto establish connection between users/researchers and the complex\ninstrumentation. The advent of generative AI presents an opportunity to bridge\nthis knowledge gap, enabling seamless communication and efficient experimental\nworkflows. Here we present a modular architecture for the Virtual Scientific\nCompanion (VISION) by assembling multiple AI-enabled cognitive blocks that each\nscaffolds large language models (LLMs) for a specialized task. With VISION, we\nperformed LLM-based operation on the beamline workstation with low latency and\ndemonstrated the first voice-controlled experiment at an X-ray scattering\nbeamline. The modular and scalable architecture allows for easy adaptation to\nnew instrument and capabilities. Development on natural language-based\nscientific experimentation is a building block for an impending future where a\nscience exocortex -- a synthetic extension to the cognition of scientists --\nmay radically transform scientific practice and discovery.",
      "tldr_zh": "本研究提出了一种模块化 AI 助手 VISION，用于提升科学用户设施（如同步加速器束线）中自然的人机交互。VISION 通过组装多个 AI 启用的认知块来支撑大型语言模型 (LLMs) 执行特定任务，从而桥接用户与复杂仪器间的知识差距，并实现低延迟操作和首个语音控制实验。实验在 X 射线散射束线上验证了其有效性，展示了生成式 AI 在优化实验工作流程方面的潜力。该架构的模块化和可扩展性，为未来科学外皮 (science exocortex) 的发展奠定基础，可能彻底变革科学实践和发现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18161v1",
      "published_date": "2024-12-24 04:37:07 UTC",
      "updated_date": "2024-12-24 04:37:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:26:40.212450"
    },
    {
      "arxiv_id": "2412.18157v1",
      "title": "Smooth-Foley: Creating Continuous Sound for Video-to-Audio Generation Under Semantic Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Yaoyun Zhang",
        "Xuenan Xu",
        "Mengyue Wu"
      ],
      "abstract": "The video-to-audio (V2A) generation task has drawn attention in the field of\nmultimedia due to the practicality in producing Foley sound. Semantic and\ntemporal conditions are fed to the generation model to indicate sound events\nand temporal occurrence. Recent studies on synthesizing immersive and\nsynchronized audio are faced with challenges on videos with moving visual\npresence. The temporal condition is not accurate enough while low-resolution\nsemantic condition exacerbates the problem. To tackle these challenges, we\npropose Smooth-Foley, a V2A generative model taking semantic guidance from the\ntextual label across the generation to enhance both semantic and temporal\nalignment in audio. Two adapters are trained to leverage pre-trained\ntext-to-audio generation models. A frame adapter integrates high-resolution\nframe-wise video features while a temporal adapter integrates temporal\nconditions obtained from similarities of visual frames and textual labels. The\nincorporation of semantic guidance from textual labels achieves precise\naudio-video alignment. We conduct extensive quantitative and qualitative\nexperiments. Results show that Smooth-Foley performs better than existing\nmodels on both continuous sound scenarios and general scenarios. With semantic\nguidance, the audio generated by Smooth-Foley exhibits higher quality and\nbetter adherence to physical laws.",
      "tldr_zh": "该论文针对视频到音频（V2A）生成任务中的挑战，提出Smooth-Foley模型，利用文本标签的语义指导来提升音频的语义和时间对齐，尤其适用于包含移动视觉元素的视频。模型通过训练frame adapter整合高分辨率帧级视频特征，以及temporal adapter基于视觉帧和文本标签相似性生成时间条件，从而实现更精确的音频-视频同步。实验结果显示，Smooth-Foley在连续声音场景和一般场景上均优于现有模型，生成的音频质量更高且更符合物理定律。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18157v1",
      "published_date": "2024-12-24 04:29:46 UTC",
      "updated_date": "2024-12-24 04:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:26:51.466657"
    },
    {
      "arxiv_id": "2412.18156v1",
      "title": "scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
      "title_zh": "翻译失败",
      "authors": [
        "Cong Li",
        "Qingqing Long",
        "Yuanchun Zhou",
        "Meng Xiao"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
      "tldr_zh": "该研究提出 scReader，一种创新方法，通过提示 Large Language Models (LLMs) 结合领域特定模型来解释 scRNA-seq 数据，解决不同物种数据规模不一致的挑战。方法以基因作为基本单位，使用功能描述（如 LLaMA-2）初始化基因表示，并输入单细胞基因表达数据进行细胞表示建模，支持跨物种分析。实验结果显示，scReader 在人类和老鼠发育细胞的注释和可视化任务中，准确性和互操作性显著优于其他方法，为未来跨物种遗传分析提供了一个鲁棒框架。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "8 pages, Accepted by ICDM 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.18156v1",
      "published_date": "2024-12-24 04:28:42 UTC",
      "updated_date": "2024-12-24 04:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:27:04.117982"
    },
    {
      "arxiv_id": "2412.18154v1",
      "title": "GeneSUM: Large Language Model-based Gene Summary Extraction",
      "title_zh": "GeneSUM：基于大型语言模型的基因摘要提取",
      "authors": [
        "Zhijian Chen",
        "Chuan Hu",
        "Min Wu",
        "Qingqing Long",
        "Xuezhi Wang",
        "Yuanchun Zhou",
        "Meng Xiao"
      ],
      "abstract": "Emerging topics in biomedical research are continuously expanding, providing\na wealth of information about genes and their function. This rapid\nproliferation of knowledge presents unprecedented opportunities for scientific\ndiscovery and formidable challenges for researchers striving to keep abreast of\nthe latest advancements. One significant challenge is navigating the vast\ncorpus of literature to extract vital gene-related information, a\ntime-consuming and cumbersome task. To enhance the efficiency of this process,\nit is crucial to address several key challenges: (1) the overwhelming volume of\nliterature, (2) the complexity of gene functions, and (3) the automated\nintegration and generation. In response, we propose GeneSUM, a two-stage\nautomated gene summary extractor utilizing a large language model (LLM). Our\napproach retrieves and eliminates redundancy of target gene literature and then\nfine-tunes the LLM to refine and streamline the summarization process. We\nconducted extensive experiments to validate the efficacy of our proposed\nframework. The results demonstrate that LLM significantly enhances the\nintegration of gene-specific information, allowing more efficient\ndecision-making in ongoing research.",
      "tldr_zh": "本研究针对生物医学文献快速增长带来的挑战，包括文献量过大、基因功能复杂以及自动化整合生成等问题，提出GeneSUM框架——一种基于Large Language Model (LLM)的两阶段基因摘要提取器。该框架首先检索目标基因文献并去除冗余，然后微调LLM以精炼和简化总结过程。实验结果显示，GeneSUM显著提升了基因特定信息的整合效率，支持研究人员更高效地进行决策。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.GN",
      "comment": "7 pages, Accepted by BIBM 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.18154v1",
      "published_date": "2024-12-24 04:20:43 UTC",
      "updated_date": "2024-12-24 04:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:27:14.817801"
    },
    {
      "arxiv_id": "2412.18150v2",
      "title": "EvalMuse-40K: A Reliable and Fine-Grained Benchmark with Comprehensive Human Annotations for Text-to-Image Generation Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhao Han",
        "Haotian Fan",
        "Jiachen Fu",
        "Liang Li",
        "Tao Li",
        "Junhui Cui",
        "Yunqiu Wang",
        "Yang Tai",
        "Jingwei Sun",
        "Chunle Guo",
        "Chongyi Li"
      ],
      "abstract": "Recently, Text-to-Image (T2I) generation models have achieved significant\nadvancements. Correspondingly, many automated metrics have emerged to evaluate\nthe image-text alignment capabilities of generative models. However, the\nperformance comparison among these automated metrics is limited by existing\nsmall datasets. Additionally, these datasets lack the capacity to assess the\nperformance of automated metrics at a fine-grained level. In this study, we\ncontribute an EvalMuse-40K benchmark, gathering 40K image-text pairs with\nfine-grained human annotations for image-text alignment-related tasks. In the\nconstruction process, we employ various strategies such as balanced prompt\nsampling and data re-annotation to ensure the diversity and reliability of our\nbenchmark. This allows us to comprehensively evaluate the effectiveness of\nimage-text alignment metrics for T2I models. Meanwhile, we introduce two new\nmethods to evaluate the image-text alignment capabilities of T2I models:\nFGA-BLIP2 which involves end-to-end fine-tuning of a vision-language model to\nproduce fine-grained image-text alignment scores and PN-VQA which adopts a\nnovel positive-negative VQA manner in VQA models for zero-shot fine-grained\nevaluation. Both methods achieve impressive performance in image-text alignment\nevaluations. We also use our methods to rank current AIGC models, in which the\nresults can serve as a reference source for future study and promote the\ndevelopment of T2I generation. The data and code will be made publicly\navailable.",
      "tldr_zh": "本文提出 EvalMuse-40K 基准数据集，包含 40K 个图像-文本对，并提供细粒度的手动注释，用于评估 Text-to-Image (T2I) 生成模型的图像-文本对齐能力，以解决现有小数据集的局限性。研究通过平衡提示采样和数据重新标注，确保数据集的多样性和可靠性，并全面评估现有自动指标的有效性。同时，引入两种新方法：FGA-BLIP2（端到端微调视觉语言模型产生细粒度评分）和 PN-VQA（零样本正负 VQA 方式进行细粒度评估），这些方法在 T2I 模型评估中表现出色，并用于排名当前 AIGC 模型，作为未来研究的参考来源。数据和代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18150v2",
      "published_date": "2024-12-24 04:08:25 UTC",
      "updated_date": "2024-12-25 15:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:27:29.382041"
    },
    {
      "arxiv_id": "2412.18148v2",
      "title": "Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Sun",
        "Zongmin Zhang",
        "Xinyue Shen",
        "Ziyi Zhang",
        "Yule Liu",
        "Michael Backes",
        "Yang Zhang",
        "Xinlei He"
      ],
      "abstract": "Social media platforms are experiencing a growing presence of AI-Generated\nTexts (AIGTs). However, the misuse of AIGTs could have profound implications\nfor public opinion, such as spreading misinformation and manipulating\nnarratives. Despite its importance, it remains unclear how prevalent AIGTs are\non social media. To address this gap, this paper aims to quantify and monitor\nthe AIGTs on online social media platforms. We first collect a dataset (SM-D)\nwith around 2.4M posts from 3 major social media platforms: Medium, Quora, and\nReddit. Then, we construct a diverse dataset (AIGTBench) to train and evaluate\nAIGT detectors. AIGTBench combines popular open-source datasets and our AIGT\ndatasets generated from social media texts by 12 LLMs, serving as a benchmark\nfor evaluating mainstream detectors. With this setup, we identify the\nbest-performing detector (OSM-Det). We then apply OSM-Det to SM-D to track\nAIGTs across social media platforms from January 2022 to October 2024, using\nthe AI Attribution Rate (AAR) as the metric. Specifically, Medium and Quora\nexhibit marked increases in AAR, rising from 1.77% to 37.03% and 2.06% to\n38.95%, respectively. In contrast, Reddit shows slower growth, with AAR\nincreasing from 1.31% to 2.45% over the same period. Our further analysis\nindicates that AIGTs on social media differ from human-written texts across\nseveral dimensions, including linguistic patterns, topic distributions,\nengagement levels, and the follower distribution of authors. We envision our\nanalysis and findings on AIGTs in social media can shed light on future\nresearch in this domain.",
      "tldr_zh": "这篇论文量化了社交媒体上 AI 生成文本 (AIGT) 的流行程度，并探讨其潜在风险，如传播误信息。研究者收集了包含约 2.4M 帖子的 SM-D 数据集，并构建了 AIGTBench 基准数据集，用于训练和评估 AIGT 检测器，最终选出了最佳模型 OSM-Det。应用 OSM-Det 分析从 2022 年 1 月到 2024 年 10 月的数据，发现 Medium 和 Quora 的 AI Attribution Rate (AAR) 分别从 1.77% 上升到 37.03% 和从 2.06% 上升到 38.95%，而 Reddit 的增长较慢（从 1.31% 到 2.45%）；此外，AIGT 在语言模式、主题分布、互动水平和作者粉丝分布等方面与人类文本存在显著差异。该研究为监控和理解 AIGT 在社交媒体的影响提供了关键洞见。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages,22 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18148v2",
      "published_date": "2024-12-24 04:04:54 UTC",
      "updated_date": "2025-02-22 08:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:27:42.085764"
    },
    {
      "arxiv_id": "2412.18142v1",
      "title": "Text-Aware Adapter for Few-Shot Keyword Spotting",
      "title_zh": "文本感知适配器用于少样本关键词检测",
      "authors": [
        "Youngmoon Jung",
        "Jinyoung Lee",
        "Seungjin Lee",
        "Myunghun Jung",
        "Yong-Hyeok Lee",
        "Hoon-Young Cho"
      ],
      "abstract": "Recent advances in flexible keyword spotting (KWS) with text enrollment allow\nusers to personalize keywords without uttering them during enrollment. However,\nthere is still room for improvement in target keyword performance. In this\nwork, we propose a novel few-shot transfer learning method, called text-aware\nadapter (TA-adapter), designed to enhance a pre-trained flexible KWS model for\nspecific keywords with limited speech samples. To adapt the acoustic encoder,\nwe leverage a jointly pre-trained text encoder to generate a text embedding\nthat acts as a representative vector for the keyword. By fine-tuning only a\nsmall portion of the network while keeping the core components' weights intact,\nthe TA-adapter proves highly efficient for few-shot KWS, enabling a seamless\nreturn to the original pre-trained model. In our experiments, the TA-adapter\ndemonstrated significant performance improvements across 35 distinct keywords\nfrom the Google Speech Commands V2 dataset, with only a 0.14% increase in the\ntotal number of parameters.",
      "tldr_zh": "该论文提出了一种名为 Text-Aware Adapter (TA-adapter) 的少样本转移学习方法，用于提升预训练的灵活关键词识别 (KWS) 模型针对特定关键词的性能。TA-adapter 通过利用联合预训练的文本编码器生成关键词的文本嵌入，作为代表向量，仅微调网络的一小部分参数，从而保持核心组件的权重不变，并实现高效适应。实验在 Google Speech Commands V2 数据集的 35 个关键词上证明，该方法显著提高了识别准确率，同时仅增加了 0.14% 的参数数量。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures, Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18142v1",
      "published_date": "2024-12-24 03:54:40 UTC",
      "updated_date": "2024-12-24 03:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:27:52.087996"
    },
    {
      "arxiv_id": "2412.18125v1",
      "title": "Exact Acceleration of Subgraph Graph Neural Networks by Eliminating Computation Redundancy",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Tao",
        "Xiyuan Wang",
        "Muhan Zhang",
        "Shuxian Hu",
        "Wenyuan Yu",
        "Jingren Zhou"
      ],
      "abstract": "Graph neural networks (GNNs) have become a prevalent framework for graph\ntasks. Many recent studies have proposed the use of graph convolution methods\nover the numerous subgraphs of each graph, a concept known as subgraph graph\nneural networks (subgraph GNNs), to enhance GNNs' ability to distinguish\nnon-isomorphic graphs. To maximize the expressiveness, subgraph GNNs often\nrequire each subgraph to have equal size to the original graph. Despite their\nimpressive performance, subgraph GNNs face challenges due to the vast number\nand large size of subgraphs which lead to a surge in training data, resulting\nin both storage and computational inefficiencies. In response to this problem,\nthis paper introduces Ego-Nets-Fit-All (ENFA), a model that uniformly takes the\nsmaller ego nets as subgraphs, thereby providing greater storage and\ncomputational efficiency, while at the same time guarantees identical outputs\nto the original subgraph GNNs even taking the whole graph as subgraphs. The key\nis to identify and eliminate the redundant computation among subgraphs. For\nexample, a node $v_i$ may appear in multiple subgraphs but is far away from all\nof their centers (the unsymmetric part between subgraphs). Therefore, its first\nfew rounds of message passing within each subgraph can be computed once in the\noriginal graph instead of being computed multiple times within each subgraph.\nSuch strategy enables our ENFA to accelerate subgraph GNNs in an exact way,\nunlike previous sampling approaches that often lose the performance. Extensive\nexperiments across various datasets reveal that compared with the conventional\nsubgraph GNNs, ENFA can reduce storage space by 29.0% to 84.5% and improve\ntraining efficiency by up to 1.66x.",
      "tldr_zh": "该论文针对子图 Graph Neural Networks (subgraph GNNs) 在处理大量子图时存在的计算冗余问题，提出了一种精确加速方法，以提升存储和计算效率。作者引入了 Ego-Nets-Fit-All (ENFA) 模型，使用较小的 ego nets 作为子图，并通过识别和消除子图间冗余计算（如节点在多个子图中的重复消息传递）来确保输出与原 subgraph GNNs 完全一致，而非依赖性能损失的采样方法。实验在多个数据集上验证，ENFA 能减少29.0%至84.5%的存储空间，并将训练效率提高高达1.66倍。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18125v1",
      "published_date": "2024-12-24 03:21:03 UTC",
      "updated_date": "2024-12-24 03:21:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:28:05.677951"
    },
    {
      "arxiv_id": "2412.18120v2",
      "title": "Do Language Models Understand the Cognitive Tasks Given to Them? Investigations with the N-Back Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyang Hu",
        "Richard L. Lewis"
      ],
      "abstract": "Cognitive tasks originally developed for humans are now increasingly used to\nstudy language models. While applying these tasks is often straightforward,\ninterpreting their results can be challenging. In particular, when a model\nunderperforms, it is often unclear whether this results from a limitation in\nthe cognitive ability being tested or a failure to understand the task itself.\nA recent study argues that GPT 3.5's declining performance on 2-back and 3-back\ntasks reflects a working memory capacity limit similar to humans (Gong et al.,\n2024). By analyzing a range of open-source language models of varying\nperformance levels on these tasks, we show that the poor performance instead\nreflects a limitation in task comprehension and task set maintenance. In\naddition, we challenge the best-performing model with progressively harder\nversions of the task (up to 10-back) and experiment with alternative prompting\nstrategies, before analyzing model attentions. Our larger aim is to contribute\nto the ongoing conversation around refining methodologies for the cognitive\nevaluation of language models.",
      "tldr_zh": "本研究质疑语言模型是否真正理解分配给它们的认知任务，通过 N-Back Paradigm 进行调查。作者分析了多种开源语言模型的表现，发现这些模型在 2-back 和 3-back 任务上的低性能并非源于工作记忆容量限制（如先前研究Gong et al., 2024 所声称的GPT-3.5 类似人类情况），而是任务理解和任务集维护的缺陷。为了进一步验证，他们挑战最佳模型进行更难版本的任务（如10-back），并测试替代提示策略，同时分析模型注意力。最终，该研究为改进语言模型的认知评估方法提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18120v2",
      "published_date": "2024-12-24 03:06:52 UTC",
      "updated_date": "2024-12-26 16:31:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:28:17.343737"
    },
    {
      "arxiv_id": "2412.18116v3",
      "title": "AutoDroid-V2: Boosting SLM-based GUI Agents via Code Generation",
      "title_zh": "AutoDroid-V2：通过代码生成提升基于 SLM 的 GUI 代理",
      "authors": [
        "Hao Wen",
        "Shizuo Tian",
        "Borislav Pavlov",
        "Wenjie Du",
        "Yixuan Li",
        "Ge Chang",
        "Shanhui Zhao",
        "Jiacheng Liu",
        "Yunxin Liu",
        "Ya-Qin Zhang",
        "Yuanchun Li"
      ],
      "abstract": "Large language models (LLMs) have brought exciting new advances to mobile UI\nagents, a long-standing research field that aims to complete arbitrary natural\nlanguage tasks through mobile UI interactions. However, existing UI agents\nusually demand powerful large language models that are difficult to be deployed\nlocally on end-users' devices, raising huge concerns about user privacy and\ncentralized serving cost. Inspired by the remarkable coding abilities of recent\nsmall language models (SLMs), we propose to convert the UI task automation\nproblem to a code generation problem, which can be effectively solved by an\non-device SLM and efficiently executed with an on-device code interpreter.\nUnlike normal coding tasks that can be extensively pre-trained with public\ndatasets, generating UI automation code is challenging due to the diversity,\ncomplexity, and variability of target apps. Therefore, we adopt a\ndocument-centered approach that automatically builds fine-grained API\ndocumentation for each app and generates diverse task samples based on this\ndocumentation. By guiding the agent with the synthetic documents and task\nsamples, it learns to generate precise and efficient scripts to complete unseen\ntasks. Based on detailed comparisons with state-of-the-art mobile UI agents,\nour approach effectively improves the mobile task automation with significantly\nhigher success rates and lower latency/token consumption. Code is open-sourced\nat https://github.com/MobileLLM/AutoDroid-V2.",
      "tldr_zh": "该研究提出AutoDroid-V2框架，通过代码生成技术提升基于小型语言模型(SLMs)的GUI代理性能，以解决现有依赖大型语言模型(LLMs)的UI代理在隐私和部署成本上的问题。方法将UI任务自动化转化为代码生成问题，利用自动构建的细粒度API文档和多样化任务样本，指导SLMs生成精确的脚本，并在本地设备上通过代码解释器高效执行。实验结果显示，AutoDroid-V2显著提高了任务成功率，同时降低了延迟和token消耗，并开源代码以促进进一步发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18116v3",
      "published_date": "2024-12-24 02:54:56 UTC",
      "updated_date": "2025-05-06 12:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:28:28.547787"
    },
    {
      "arxiv_id": "2412.18111v1",
      "title": "AIGT: AI Generative Table Based on Prompt",
      "title_zh": "翻译失败",
      "authors": [
        "Mingming Zhang",
        "Zhiqing Xiao",
        "Guoshan Lu",
        "Sai Wu",
        "Weiqiang Wang",
        "Xing Fu",
        "Can Yi",
        "Junbo Zhao"
      ],
      "abstract": "Tabular data, which accounts for over 80% of enterprise data assets, is vital\nin various fields. With growing concerns about privacy protection and\ndata-sharing restrictions, generating high-quality synthetic tabular data has\nbecome essential. Recent advancements show that large language models (LLMs)\ncan effectively gener-ate realistic tabular data by leveraging semantic\ninformation and overcoming the challenges of high-dimensional data that arise\nfrom one-hot encoding. However, current methods do not fully utilize the rich\ninformation available in tables. To address this, we introduce AI Generative\nTable (AIGT) based on prompt enhancement, a novel approach that utilizes meta\ndata information, such as table descriptions and schemas, as prompts to\ngenerate ultra-high quality synthetic data. To overcome the token limit\nconstraints of LLMs, we propose long-token partitioning algorithms that enable\nAIGT to model tables of any scale. AIGT achieves state-of-the-art performance\non 14 out of 20 public datasets and two real industry datasets within the\nAlipay risk control system.",
      "tldr_zh": "本研究针对表格数据生成问题，提出 AIGT（AI Generative Table Based on Prompt）方法，该方法通过提示增强利用元数据信息（如表格描述和模式），生成高质量合成数据，以解决隐私保护和数据共享限制。AIGT 引入长 token 分区算法，克服大语言模型(LLMs)的 token 限制问题，从而处理任意规模的表格数据。实验结果显示，AIGT 在 20 个公共数据集和 2 个真实行业数据集上，取得了 14 个数据集的最先进性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18111v1",
      "published_date": "2024-12-24 02:51:06 UTC",
      "updated_date": "2024-12-24 02:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:28:43.646748"
    },
    {
      "arxiv_id": "2412.18110v1",
      "title": "SlimGPT: Layer-wise Structured Pruning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gui Ling",
        "Ziyang Wang",
        "Yuliang Yan",
        "Qingwen Liu"
      ],
      "abstract": "Large language models (LLMs) have garnered significant attention for their\nremarkable capabilities across various domains, whose vast parameter scales\npresent challenges for practical deployment. Structured pruning is an effective\nmethod to balance model performance with efficiency, but performance\nrestoration under computational resource constraints is a principal challenge\nin pruning LLMs. Therefore, we present a low-cost and fast structured pruning\nmethod for LLMs named SlimGPT based on the Optimal Brain Surgeon framework. We\npropose Batched Greedy Pruning for rapid and near-optimal pruning, which\nenhances the accuracy of head-wise pruning error estimation through grouped\nCholesky decomposition and improves the pruning efficiency of FFN via Dynamic\nGroup Size, thereby achieving approximate local optimal pruning results within\none hour. Besides, we explore the limitations of layer-wise pruning from the\nperspective of error accumulation and propose Incremental Pruning Ratio, a\nnon-uniform pruning strategy to reduce performance degradation. Experimental\nresults on the LLaMA benchmark show that SlimGPT outperforms other methods and\nachieves state-of-the-art results.",
      "tldr_zh": "本研究提出 SlimGPT，一种基于 Optimal Brain Surgeon 框架的低成本、快速层级结构化剪枝方法，旨在解决 Large Language Models (LLMs) 在部署效率与性能平衡上的挑战。SlimGPT 引入 Batched Greedy Pruning 技术，通过分组 Cholesky decomposition 提升头级剪枝误差估计的准确性，并利用 Dynamic Group Size 优化 FFN 层的剪枝效率，实现一小时内近似局部最优结果。此外，该方法探索误差积累问题，提出 Incremental Pruning Ratio 的非均匀剪枝策略，以减少性能下降；在 LLaMA 基准测试中，SlimGPT 优于其他方法，达到了最先进的效果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18110v1",
      "published_date": "2024-12-24 02:49:50 UTC",
      "updated_date": "2024-12-24 02:49:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:28:54.212143"
    },
    {
      "arxiv_id": "2412.18107v1",
      "title": "SongGLM: Lyric-to-Melody Generation with 2D Alignment Encoding and Multi-Task Pre-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxing Yu",
        "Xinda Wu",
        "Yunfei Xu",
        "Tieyao Zhang",
        "Songruoyao Wu",
        "Le Ma",
        "Kejun Zhang"
      ],
      "abstract": "Lyric-to-melody generation aims to automatically create melodies based on\ngiven lyrics, requiring the capture of complex and subtle correlations between\nthem. However, previous works usually suffer from two main challenges: 1)\nlyric-melody alignment modeling, which is often simplified to\none-syllable/word-to-one-note alignment, while others have the problem of low\nalignment accuracy; 2) lyric-melody harmony modeling, which usually relies\nheavily on intermediates or strict rules, limiting model's capabilities and\ngenerative diversity. In this paper, we propose SongGLM, a lyric-to-melody\ngeneration system that leverages 2D alignment encoding and multi-task\npre-training based on the General Language Model (GLM) to guarantee the\nalignment and harmony between lyrics and melodies. Specifically, 1) we\nintroduce a unified symbolic song representation for lyrics and melodies with\nword-level and phrase-level (2D) alignment encoding to capture the lyric-melody\nalignment; 2) we design a multi-task pre-training framework with hierarchical\nblank infilling objectives (n-gram, phrase, and long span), and incorporate\nlyric-melody relationships into the extraction of harmonized n-grams to ensure\nthe lyric-melody harmony. We also construct a large-scale lyric-melody paired\ndataset comprising over 200,000 English song pieces for pre-training and\nfine-tuning. The objective and subjective results indicate that SongGLM can\ngenerate melodies from lyrics with significant improvements in both alignment\nand harmony, outperforming all the previous baseline methods.",
      "tldr_zh": "该论文提出SongGLM系统，用于歌词到旋律的自动生成，通过2D alignment encoding和multi-task pre-training来解决歌词-旋律对齐和和谐建模的挑战。系统引入统一的符号歌曲表示，包括词级和短语级对齐编码，以捕捉歌词与旋律的精确对齐；同时设计多任务预训练框架，采用分层空白填充目标（n-gram、短语和长跨度）并融入歌词-旋律关系，确保生成的和谐性。研究者构建了一个超过20万首英文歌曲片段的配对数据集进行预训练和微调，结果显示SongGLM在对齐和和谐方面显著优于基线方法，提升了生成旋律的质量和多样性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Extended version of paper accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.18107v1",
      "published_date": "2024-12-24 02:30:07 UTC",
      "updated_date": "2024-12-24 02:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:29:06.502887"
    },
    {
      "arxiv_id": "2412.18106v1",
      "title": "Tackling the Dynamicity in a Production LLM Serving System with SOTA Optimizations via Hybrid Prefill/Decode/Verify Scheduling on Efficient Meta-kernels",
      "title_zh": "翻译失败",
      "authors": [
        "Mingcong Song",
        "Xinru Tang",
        "Fengfan Hou",
        "Jing Li",
        "Wei Wei",
        "Yipeng Ma",
        "Runqiu Xiao",
        "Hongjie Si",
        "Dingcheng Jiang",
        "Shouyi Yin",
        "Yang Hu",
        "Guoping Long"
      ],
      "abstract": "Meeting growing demands for low latency and cost efficiency in\nproduction-grade large language model (LLM) serving systems requires\nintegrating advanced optimization techniques. However, dynamic and\nunpredictable input-output lengths of LLM, compounded by these optimizations,\nexacerbate the issues of workload variability, making it difficult to maintain\nhigh efficiency on AI accelerators, especially DSAs with tile-based programming\nmodels. To address this challenge, we introduce XY-Serve, a versatile, Ascend\nnative, end-to-end production LLM-serving system. The core idea is an\nabstraction mechanism that smooths out the workload variability by decomposing\ncomputations into unified, hardware-friendly, fine-grained meta primitives. For\nattention, we propose a meta-kernel that computes the basic pattern of\nmatmul-softmax-matmul with architectural-aware tile sizes. For GEMM, we\nintroduce a virtual padding scheme that adapts to dynamic shape changes while\nusing highly efficient GEMM primitives with assorted fixed tile sizes. XY-Serve\nsits harmoniously with vLLM. Experimental results show up to 89% end-to-end\nthroughput improvement compared with current publicly available baselines on\nAscend NPUs. Additionally, our approach outperforms existing GEMM (average\n14.6% faster) and attention (average 21.5% faster) kernels relative to existing\nlibraries. While the work is Ascend native, we believe the approach can be\nreadily applicable to SIMT architectures as well.",
      "tldr_zh": "这篇论文提出 XY-Serve，一种针对生产级 LLM 服务系统的端到端优化框架，用于解决动态输入输出长度导致的工作负载变异性问题，通过混合预填充/解码/验证调度（Hybrid Prefill/Decode/Verify Scheduling）和高效 meta-kernels 来提升 AI 加速器（如 Ascend NPUs）的效率。核心方法包括为 attention 操作设计基于 matmul-softmax-matmul 的 meta-kernel，以及为 GEMM 操作引入虚拟填充方案（virtual padding scheme），以适应动态形状变化并利用固定 tile sizes。实验结果显示，XY-Serve 比现有基线端到端吞吐量提高高达 89%，GEMM 平均快 14.6%，attention 平均快 21.5%，并可扩展到 SIMT 架构。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18106v1",
      "published_date": "2024-12-24 02:27:44 UTC",
      "updated_date": "2024-12-24 02:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:29:20.280682"
    },
    {
      "arxiv_id": "2412.18100v1",
      "title": "EvoPat: A Multi-LLM-based Patents Summarization and Analysis Agent",
      "title_zh": "EvoPat：一种基于多 LLM 的专利摘要化和分析代理",
      "authors": [
        "Suyuan Wang",
        "Xueqian Yin",
        "Menghao Wang",
        "Ruofeng Guo",
        "Kai Nan"
      ],
      "abstract": "The rapid growth of scientific techniques and knowledge is reflected in the\nexponential increase in new patents filed annually. While these patents drive\ninnovation, they also present significant burden for researchers and engineers,\nespecially newcomers. To avoid the tedious work of navigating a vast and\ncomplex landscape to identify trends and breakthroughs, researchers urgently\nneed efficient tools to summarize, evaluate, and contextualize patents,\nrevealing their innovative contributions and underlying scientific\nprinciples.To address this need, we present EvoPat, a multi-LLM-based patent\nagent designed to assist users in analyzing patents through Retrieval-Augmented\nGeneration (RAG) and advanced search strategies. EvoPat leverages multiple\nLarge Language Models (LLMs), each performing specialized roles such as\nplanning, identifying innovations, and conducting comparative evaluations. The\nsystem integrates data from local databases, including patents, literature,\nproduct catalogous, and company repositories, and online searches to provide\nup-to-date insights. The ability to collect information not included in\noriginal database automatically is also implemented. Through extensive testing\nin the natural language processing (NLP) domain, we demonstrate that EvoPat\noutperforms GPT-4 in tasks such as patent summarization, comparative analysis,\nand technical evaluation. EvoPat represents a significant step toward creating\nAI-powered tools that empower researchers and engineers to efficiently navigate\nthe complexities of the patent landscape.",
      "tldr_zh": "该研究针对专利数量快速增长带来的信息过载问题，提出EvoPat，一种基于多Large Language Models (LLMs)的专利总结和分析代理。EvoPat利用Retrieval-Augmented Generation (RAG)和高级搜索策略，由多个LLMs分工协作，执行角色如规划、识别创新和比较评估，同时整合本地数据库（如专利、文献）和在线搜索以提供实时见解，并能自动收集新信息。在自然语言处理(NLP)领域测试中，EvoPat在专利总结、比较分析和技术评估任务上优于GPT-4，显著提升了研究者和工程师的效率。该框架代表了AI驱动工具在专利景观导航中的重要进展。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.DL",
      "comment": "15 pages,2 figures,8 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.18100v1",
      "published_date": "2024-12-24 02:21:09 UTC",
      "updated_date": "2024-12-24 02:21:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:29:29.997875"
    },
    {
      "arxiv_id": "2412.18099v1",
      "title": "An Attention-based Framework with Multistation Information for Earthquake Early Warnings",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Ming Huang",
        "Kuan-Yu Chen",
        "Wen-Wei Lin",
        "Da-Yi Chen"
      ],
      "abstract": "Earthquake early warning systems play crucial roles in reducing the risk of\nseismic disasters. Previously, the dominant modeling system was the\nsingle-station models. Such models digest signal data received at a given\nstation and predict earth-quake parameters, such as the p-phase arrival time,\nintensity, and magnitude at that location. Various methods have demonstrated\nadequate performance. However, most of these methods present the challenges of\nthe difficulty of speeding up the alarm time, providing early warning for\ndistant areas, and considering global information to enhance performance.\nRecently, deep learning has significantly impacted many fields, including\nseismology. Thus, this paper proposes a deep learning-based framework, called\nSENSE, for the intensity prediction task of earthquake early warning systems.\nTo explicitly consider global information from a regional or national\nperspective, the input to SENSE comprises statistics from a set of stations in\na given region or country. The SENSE model is designed to learn the\nrelationships among the set of input stations and the locality-specific\ncharacteristics of each station. Thus, SENSE is not only expected to provide\nmore reliable forecasts by considering multistation data but also has the\nability to provide early warnings to distant areas that have not yet received\nsignals. This study conducted extensive experiments on datasets from Taiwan and\nJapan. The results revealed that SENSE can deliver competitive or even better\nperformances compared with other state-of-the-art methods.",
      "tldr_zh": "本研究针对地震预警系统的局限性，提出了一种基于注意力机制的深度学习框架SENSE，利用多站信息来提升地震强度预测的准确性和及时性。SENSE框架通过整合区域或国家级别站点的统计数据，学习多站间关系及每个站点的局部特性，从而实现更可靠的预测，并为尚未接收信号的远距离区域提供早期预警。与传统单站模型相比，该方法解决了警报延迟和全局信息不足的问题。在台湾和日本数据集上的实验显示，SENSE的性能与最先进方法相当或更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18099v1",
      "published_date": "2024-12-24 02:18:17 UTC",
      "updated_date": "2024-12-24 02:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:29:40.543767"
    },
    {
      "arxiv_id": "2412.18097v3",
      "title": "LangYa: Revolutionizing Cross-Spatiotemporal Ocean Forecasting",
      "title_zh": "LangYa：革新跨时空海洋预报",
      "authors": [
        "Nan Yang",
        "Chong Wang",
        "Meihua Zhao",
        "Zimeng Zhao",
        "Huiling Zheng",
        "Bin Zhang",
        "Jianing Wang",
        "Xiaofeng Li"
      ],
      "abstract": "Ocean forecasting is crucial for both scientific research and societal\nbenefits. Currently, the most accurate forecasting systems are global ocean\nforecasting systems (GOFSs), which represent the ocean state variables (OSVs)\nas discrete grids and solve partial differential equations (PDEs) governing the\ntransitions of oceanic state variables using numerical methods. However, GOFSs\nprocesses are computationally expensive and prone to cumulative errors.\nRecently, large artificial intelligence (AI)-based models significantly boosted\nforecasting speed and accuracy. Unfortunately, building a large AI ocean\nforecasting system that can be considered cross-spatiotemporal and air-sea\ncoupled forecasts remains a significant challenge. Here, we introduce LangYa, a\ncross-spatiotemporal and air-sea coupled ocean forecasting system. Results\ndemonstrate that the time embedding module in LangYa enables a single model to\nmake forecasts with lead times ranging from 1 to 7 days. The air-sea coupled\nmodule effectively simulates air-sea interactions. The ocean self-attention\nmodule improves network stability and accelerates convergence during training,\nand the adaptive thermocline loss function improves the accuracy of thermocline\nforecasting. Compared to existing numerical and AI-based ocean forecasting\nsystems, LangYa uses 27 years of global ocean data from the Global Ocean\nReanalysis and Simulation version 12 (GLORYS12) for training and achieves more\nreliable deterministic forecasting results for OSVs. LangYa forecasting system\nprovides global ocean researchers with access to a powerful software tool for\naccurate ocean forecasting and opens a new paradigm for ocean science.",
      "tldr_zh": "该研究针对传统海洋预报系统（如 GOFSs）的计算密集和误差累积问题，引入了 LangYa，一种革命性的跨时空和空气-海洋耦合预报系统。LangYa 整合了时间嵌入模块（支持1-7天预报）、空气-海洋耦合模块、海洋自注意力模块（提升训练稳定性和收敛速度）以及自适应温跃层损失函数，使用27年的 GLORYS12 全球海洋数据进行训练。实验结果表明，LangYa 在海洋状态变量（OSVs）的确定性预报中比现有数值和 AI 系统更准确可靠，为全球海洋研究提供强大工具，并开辟了海洋科学的新范式。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "18pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18097v3",
      "published_date": "2024-12-24 02:14:39 UTC",
      "updated_date": "2025-03-31 03:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:29:55.732857"
    },
    {
      "arxiv_id": "2412.18096v1",
      "title": "Real-world Deployment and Evaluation of PErioperative AI CHatbot (PEACH) -- a Large Language Model Chatbot for Perioperative Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Yu He Ke",
        "Liyuan Jin",
        "Kabilan Elangovan",
        "Bryan Wen Xi Ong",
        "Chin Yang Oh",
        "Jacqueline Sim",
        "Kenny Wei-Tsen Loh",
        "Chai Rick Soh",
        "Jonathan Ming Hua Cheng",
        "Aaron Kwang Yang Lee",
        "Daniel Shu Wei Ting",
        "Nan Liu",
        "Hairil Rizal Abdullah"
      ],
      "abstract": "Large Language Models (LLMs) are emerging as powerful tools in healthcare,\nparticularly for complex, domain-specific tasks. This study describes the\ndevelopment and evaluation of the PErioperative AI CHatbot (PEACH), a secure\nLLM-based system integrated with local perioperative guidelines to support\npreoperative clinical decision-making. PEACH was embedded with 35 institutional\nperioperative protocols in the secure Claude 3.5 Sonet LLM framework within\nPair Chat (developed by Singapore Government) and tested in a silent deployment\nwith real-world data. Accuracy, safety, and usability were assessed. Deviations\nand hallucinations were categorized based on potential harm, and user feedback\nwas evaluated using the Technology Acceptance Model (TAM). Updates were made\nafter the initial silent deployment to amend one protocol.\n  In 240 real-world clinical iterations, PEACH achieved a first-generation\naccuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across\nthree iterations. The updated PEACH demonstrated improved accuracy of 97.9%\n(235/240), with a statistically significant difference from the null hypothesis\nof 95% accuracy (p = 0.018, 95% CI: 0.952-0.991). Minimal hallucinations and\ndeviations were observed (both 1/240 and 2/240, respectively). Clinicians\nreported that PEACH expedited decisions in 95% of cases, and inter-rater\nreliability ranged from kappa 0.772-0.893 within PEACH and 0.610-0.784 among\nattendings.\n  PEACH is an accurate, adaptable tool that enhances consistency and efficiency\nin perioperative decision-making. Future research should explore its\nscalability across specialties and its impact on clinical outcomes.",
      "tldr_zh": "本文开发并评估了 PErioperative AI CHatbot (PEACH)，一个基于 Large Language Models (LLMs) 的安全聊天机器人，旨在通过整合35个机构围手术期协议，支持术前临床决策。 在240次真实世界临床迭代中，PEACH 的准确率从97.5%提高到更新后的97.9%，幻觉 (hallucinations) 和偏差 (deviations) 发生率极低（分别为1/240和2/240），并在95%的病例中加速了决策，使用 Technology Acceptance Model (TAM) 确认了其可用性。 研究证明，PEACH 提升了围手术期决策的一致性和效率，并建议未来探索其在其他专科的可扩展性和对临床结果的影响。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 3 figures, 1 graphical abstract",
      "pdf_url": "http://arxiv.org/pdf/2412.18096v1",
      "published_date": "2024-12-24 02:14:13 UTC",
      "updated_date": "2024-12-24 02:14:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:30:06.807200"
    },
    {
      "arxiv_id": "2412.18092v1",
      "title": "BRIDGE: Bundle Recommendation via Instruction-Driven Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tuan-Nghia Bui",
        "Huy-Son Nguyen",
        "Cam-Van Nguyen Thi",
        "Hoang-Quynh Le",
        "Duc-Trong Le"
      ],
      "abstract": "Bundle recommendation aims to suggest a set of interconnected items to users.\nHowever, diverse interaction types and sparse interaction matrices often pose\nchallenges for previous approaches in accurately predicting user-bundle\nadoptions. Inspired by the distant supervision strategy and generative\nparadigm, we propose BRIDGE, a novel framework for bundle recommendation. It\nconsists of two main components namely the correlation-based item clustering\nand the pseudo bundle generation modules. Inspired by the distant supervision\napproach, the former is to generate more auxiliary information, e.g.,\ninstructive item clusters, for training without using external data. This\ninformation is subsequently aggregated with collaborative signals from user\nhistorical interactions to create pseudo `ideal' bundles. This capability\nallows BRIDGE to explore all aspects of bundles, rather than being limited to\nexisting real-world bundles. It effectively bridging the gap between user\nimagination and predefined bundles, hence improving the bundle recommendation\nperformance. Experimental results validate the superiority of our models over\nstate-of-the-art ranking-based methods across five benchmark datasets.",
      "tldr_zh": "这篇论文提出了 BRIDGE 框架，通过指令驱动生成（Instruction-Driven Generation）来提升 bundle recommendation（捆绑推荐）的性能，旨在解决多样交互类型和稀疏交互矩阵带来的挑战。BRIDGE 包括两个核心组件：基于相关性的物品聚类模块，利用远场监督策略生成指导性物品集群作为辅助训练信息；以及伪捆绑生成模块，将这些信息与用户历史交互聚合，创建理想的伪捆绑，从而探索捆绑的全面方面。实验结果表明，BRIDGE 在五个基准数据集上优于最先进的基于排名的方法，提高了推荐准确性和用户适应性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18092v1",
      "published_date": "2024-12-24 02:07:53 UTC",
      "updated_date": "2024-12-24 02:07:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:30:19.234717"
    },
    {
      "arxiv_id": "2412.18091v1",
      "title": "AutoSculpt: A Pattern-based Model Auto-pruning Framework Using Reinforcement Learning and Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lixian Jing",
        "Jianpeng Qi",
        "Junyu Dong",
        "Yanwei Yu"
      ],
      "abstract": "As deep neural networks (DNNs) are increasingly deployed on edge devices,\noptimizing models for constrained computational resources is critical. Existing\nauto-pruning methods face challenges due to the diversity of DNN models,\nvarious operators (e.g., filters), and the difficulty in balancing pruning\ngranularity with model accuracy. To address these limitations, we introduce\nAutoSculpt, a pattern-based automated pruning framework designed to enhance\nefficiency and accuracy by leveraging graph learning and deep reinforcement\nlearning (DRL). AutoSculpt automatically identifies and prunes regular patterns\nwithin DNN architectures that can be recognized by existing inference engines,\nenabling runtime acceleration. Three key steps in AutoSculpt include: (1)\nConstructing DNNs as graphs to encode their topology and parameter\ndependencies, (2) embedding computationally efficient pruning patterns, and (3)\nutilizing DRL to iteratively refine auto-pruning strategies until the optimal\nbalance between compression and accuracy is achieved. Experimental results\ndemonstrate the effectiveness of AutoSculpt across various architectures,\nincluding ResNet, MobileNet, VGG, and Vision Transformer, achieving pruning\nrates of up to 90% and nearly 18% improvement in FLOPs reduction, outperforming\nall baselines. The codes can be available at\nhttps://anonymous.4open.science/r/AutoSculpt-DDA0",
      "tldr_zh": "本研究提出 AutoSculpt，一种基于模式的自动剪枝框架，利用图学习和深度强化学习 (DRL) 来优化深度神经网络 (DNNs)，以应对模型多样性、操作复杂性和剪枝粒度与准确性平衡的挑战。AutoSculpt 通过将 DNNs 构建为图以编码拓扑和参数依赖、嵌入高效剪枝模式，并使用 DRL 迭代优化策略，实现模型压缩与性能的理想平衡。实验结果显示，该框架在 ResNet、MobileNet、VGG 和 Vision Transformer 等架构上实现了高达 90% 的剪枝率和近 18% 的 FLOPs 减少，显著优于现有基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18091v1",
      "published_date": "2024-12-24 02:05:51 UTC",
      "updated_date": "2024-12-24 02:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:30:33.296724"
    },
    {
      "arxiv_id": "2412.18090v1",
      "title": "Multi-Point Positional Insertion Tuning for Small Object Detection",
      "title_zh": "针对小物体检测的多点位置插入微调",
      "authors": [
        "Kanoko Goto",
        "Takumi Karasawa",
        "Takumi Hirose",
        "Rei Kawakami",
        "Nakamasa Inoue"
      ],
      "abstract": "Small object detection aims to localize and classify small objects within\nimages. With recent advances in large-scale vision-language pretraining,\nfinetuning pretrained object detection models has emerged as a promising\napproach. However, finetuning large models is computationally and memory\nexpensive. To address this issue, this paper introduces multi-point positional\ninsertion (MPI) tuning, a parameter-efficient finetuning (PEFT) method for\nsmall object detection. Specifically, MPI incorporates multiple positional\nembeddings into a frozen pretrained model, enabling the efficient detection of\nsmall objects by providing precise positional information to latent features.\nThrough experiments, we demonstrated the effectiveness of the proposed method\non the SODA-D dataset. MPI performed comparably to conventional PEFT methods,\nincluding CoOp and VPT, while significantly reducing the number of parameters\nthat need to be tuned.",
      "tldr_zh": "这篇论文针对小物体检测问题，提出了一种参数高效微调（PEFT）方法Multi-Point Positional Insertion (MPI) Tuning，以解决基于大型视觉语言预训练模型的计算和内存开销问题。MPI通过在冻结的预训练模型中加入多个位置嵌入，提供精确的位置信息来增强对小物体的检测和分类。实验结果显示，在SODA-D数据集上，MPI的性能与传统PEFT方法如CoOp和VPT相当，但显著减少了需要调优的参数，从而提高了整体效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18090v1",
      "published_date": "2024-12-24 02:04:47 UTC",
      "updated_date": "2024-12-24 02:04:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:30:42.428895"
    },
    {
      "arxiv_id": "2412.18086v2",
      "title": "Generating Traffic Scenarios via In-Context Learning to Learn Better Motion Planner",
      "title_zh": "通过上下文学习生成交通场景以学习更好的运动规划器",
      "authors": [
        "Aizierjiang Aiersilan"
      ],
      "abstract": "Motion planning is a crucial component in autonomous driving.\nState-of-the-art motion planners are trained on meticulously curated datasets,\nwhich are not only expensive to annotate but also insufficient in capturing\nrarely seen critical scenarios. Failing to account for such scenarios poses a\nsignificant risk to motion planners and may lead to incidents during testing.\nAn intuitive solution is to manually compose such scenarios by programming and\nexecuting a simulator (e.g., CARLA). However, this approach incurs substantial\nhuman costs. Motivated by this, we propose an inexpensive method for generating\ndiverse critical traffic scenarios to train more robust motion planners. First,\nwe represent traffic scenarios as scripts, which are then used by the simulator\nto generate traffic scenarios. Next, we develop a method that accepts\nuser-specified text descriptions, which a Large Language Model translates into\nscripts using in-context learning. The output scripts are sent to the simulator\nthat produces the corresponding traffic scenarios. As our method can generate\nabundant safety-critical traffic scenarios, we use them as synthetic training\ndata for motion planners. To demonstrate the value of generated scenarios, we\ntrain existing motion planners on our synthetic data, real-world datasets, and\na combination of both. Our experiments show that motion planners trained with\nour data significantly outperform those trained solely on real-world data,\nshowing the usefulness of our synthetic data and the effectiveness of our data\ngeneration method. Our source code is available at\nhttps://ezharjan.github.io/AutoSceneGen.",
      "tldr_zh": "该论文针对自动驾驶运动规划器的问题提出了一种利用 in-context learning 生成交通场景的方法，以解决现有数据集昂贵且无法覆盖稀有关键场景的局限性。具体而言，该方法使用大语言模型将用户文本描述转化为模拟器脚本，从而生成多样化的安全关键交通场景，并将其作为合成训练数据。实验结果显示，在使用这些合成数据（单独或与真实数据结合）训练的运动规划器上，性能显著优于仅使用真实数据的基线模型，证明了该生成方法的有效性和实用价值。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "We are excited to announce that this paper has been accepted for oral\n  presentation at the AAAI 2025 Main Conference. We are grateful for the\n  insightful feedback from the reviewers and look forward to contributing to\n  the discussions at AAAI",
      "pdf_url": "http://arxiv.org/pdf/2412.18086v2",
      "published_date": "2024-12-24 01:52:19 UTC",
      "updated_date": "2025-05-01 02:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:30:53.288898"
    },
    {
      "arxiv_id": "2412.18084v3",
      "title": "Property Enhanced Instruction Tuning for Multi-task Molecule Generation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Lin",
        "Long Chen",
        "Yile Wang",
        "Xiangxiang Zeng",
        "Philip S. Yu"
      ],
      "abstract": "Large language models (LLMs) are widely applied in various natural language\nprocessing tasks such as question answering and machine translation. However,\ndue to the lack of labeled data and the difficulty of manual annotation for\nbiochemical properties, the performance for molecule generation tasks is still\nlimited, especially for tasks involving multi-properties constraints. In this\nwork, we present a two-step framework PEIT (Property Enhanced Instruction\nTuning) to improve LLMs for molecular-related tasks. In the first step, we use\ntextual descriptions, SMILES, and biochemical properties as multimodal inputs\nto pre-train a model called PEIT-GEN, by aligning multi-modal representations\nto synthesize instruction data. In the second step, we fine-tune existing\nopen-source LLMs with the synthesized data, the resulting PEIT-LLM can handle\nmolecule captioning, text-based molecule generation, molecular property\nprediction, and our newly proposed multi-constraint molecule generation tasks.\nExperimental results show that our pre-trained PEIT-GEN outperforms MolT5 and\nBioT5 in molecule captioning, demonstrating modalities align well between\ntextual descriptions, structures, and biochemical properties. Furthermore,\nPEIT-LLM shows promising improvements in multi-task molecule generation,\nproving the scalability of the PEIT framework for various molecular tasks. We\nrelease the code, constructed instruction data, and model checkpoints in\nhttps://github.com/chenlong164/PEIT.",
      "tldr_zh": "本研究提出了一种名为 PEIT（Property Enhanced Instruction Tuning）的框架，用于提升大型语言模型（LLMs）在多任务分子生成中的性能，解决现有模型在处理多属性约束任务时因标注数据不足而表现有限的问题。框架分为两步：首先，使用文本描述、SMILES 和生化属性作为多模态输入预训练 PEIT-GEN 模型，通过对齐多模态表示来合成指令数据；其次，以合成的指令数据微调开源 LLMs，生成 PEIT-LLM 模型，能够处理分子描述、基于文本的分子生成、分子属性预测以及多约束分子生成任务。实验结果显示，PEIT-GEN 在分子描述任务上优于 MolT5 和 BioT5，证明了模态对齐的有效性，而 PEIT-LLM 在多任务分子生成中表现出显著改进，展示了框架的可扩展性。研究还发布了代码、数据和模型检查点，以促进进一步应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9",
      "pdf_url": "http://arxiv.org/pdf/2412.18084v3",
      "published_date": "2024-12-24 01:48:07 UTC",
      "updated_date": "2025-03-10 04:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:31:08.292737"
    },
    {
      "arxiv_id": "2412.18082v1",
      "title": "Prompt Tuning for Item Cold-start Recommendation",
      "title_zh": "物品冷启动推荐的提示调优",
      "authors": [
        "Yuezihan Jiang",
        "Gaode Chen",
        "Wenhan Zhang",
        "Jingchi Wang",
        "Yinjie Jiang",
        "Qi Zhang",
        "Jingjian Lin",
        "Peng Jiang",
        "Kaigui Bian"
      ],
      "abstract": "The item cold-start problem is crucial for online recommender systems, as the\nsuccess of the cold-start phase determines whether items can transition into\npopular ones. Prompt learning, a powerful technique used in natural language\nprocessing (NLP) to address zero- or few-shot problems, has been adapted for\nrecommender systems to tackle similar challenges. However, existing methods\ntypically rely on content-based properties or text descriptions for prompting,\nwhich we argue may be suboptimal for cold-start recommendations due to 1)\nsemantic gaps with recommender tasks, 2) model bias caused by warm-up items\ncontribute most of the positive feedback to the model, which is the core of the\ncold-start problem that hinders the recommender quality on cold-start items. We\npropose to leverage high-value positive feedback, termed pinnacle feedback as\nprompt information, to simultaneously resolve the above two problems. We\nexperimentally prove that compared to the content description proposed in\nexisting works, the positive feedback is more suitable to serve as prompt\ninformation by bridging the semantic gaps. Besides, we propose item-wise\npersonalized prompt networks to encode pinnaclce feedback to relieve the model\nbias by the positive feedback dominance problem. Extensive experiments on four\nreal-world datasets demonstrate the superiority of our model over\nstate-of-the-art methods. Moreover, PROMO has been successfully deployed on a\npopular short-video sharing platform, a billion-user scale commercial\nshort-video application, achieving remarkable performance gains across various\ncommercial metrics within cold-start scenarios",
      "tldr_zh": "该研究针对推荐系统的物品冷启动问题（item cold-start problem），提出了一种基于提示调优（prompt tuning）的新方法，以解决现有方法依赖内容描述导致的语义差距和模型偏差问题。具体而言，该方法使用高价值正反馈（pinnacle feedback）作为提示信息，并引入物品级个性化提示网络（item-wise personalized prompt networks）来编码反馈，从而提升冷启动物品的推荐质量。在四个真实数据集上的广泛实验中，该模型优于现有最先进方法，并在亿级用户短视频平台上实际部署，显著提高了冷启动场景下的商业指标表现。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18082v1",
      "published_date": "2024-12-24 01:38:19 UTC",
      "updated_date": "2024-12-24 01:38:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:31:17.406159"
    },
    {
      "arxiv_id": "2412.18076v1",
      "title": "COMO: Cross-Mamba Interaction and Offset-Guided Fusion for Multimodal Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Liu",
        "Xin Ma",
        "Xiaochen Yang",
        "Yuxiang Zhang",
        "Yanni Dong"
      ],
      "abstract": "Single-modal object detection tasks often experience performance degradation\nwhen encountering diverse scenarios. In contrast, multimodal object detection\ntasks can offer more comprehensive information about object features by\nintegrating data from various modalities. Current multimodal object detection\nmethods generally use various fusion techniques, including conventional neural\nnetworks and transformer-based models, to implement feature fusion strategies\nand achieve complementary information. However, since multimodal images are\ncaptured by different sensors, there are often misalignments between them,\nmaking direct matching challenging. This misalignment hinders the ability to\nestablish strong correlations for the same object across different modalities.\nIn this paper, we propose a novel approach called the CrOss-Mamba interaction\nand Offset-guided fusion (COMO) framework for multimodal object detection\ntasks. The COMO framework employs the cross-mamba technique to formulate\nfeature interaction equations, enabling multimodal serialized state\ncomputation. This results in interactive fusion outputs while reducing\ncomputational overhead and improving efficiency. Additionally, COMO leverages\nhigh-level features, which are less affected by misalignment, to facilitate\ninteraction and transfer complementary information between modalities,\naddressing the positional offset challenges caused by variations in camera\nangles and capture times. Furthermore, COMO incorporates a global and local\nscanning mechanism in the cross-mamba module to capture features with local\ncorrelation, particularly in remote sensing images. To preserve low-level\nfeatures, the offset-guided fusion mechanism ensures effective multiscale\nfeature utilization, allowing the construction of a multiscale fusion data cube\nthat enhances detection performance.",
      "tldr_zh": "该研究针对多模态物体检测中的图像错位问题，提出了一种新型COMO框架，利用Cross-Mamba交互技术进行特征交互，实现高效的多模态序列化状态计算，同时减少计算开销。COMO框架通过高层特征辅助交互和转移互补信息，解决不同传感器捕获导致的定位偏移挑战，并引入全局和局部扫描机制以捕捉遥感图像中的局部相关性。最终，Offset-Guided Fusion机制保留低层特征，构建多尺度融合数据立方体，从而显著提升物体检测的准确性和整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18076v1",
      "published_date": "2024-12-24 01:14:48 UTC",
      "updated_date": "2024-12-24 01:14:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:31:31.415344"
    },
    {
      "arxiv_id": "2412.18073v1",
      "title": "Understanding Artificial Neural Network's Behavior from Neuron Activation Perspective",
      "title_zh": "从神经元激活角度理解人工神经网络的行为",
      "authors": [
        "Yizhou Zhang",
        "Yang Sui"
      ],
      "abstract": "This paper explores the intricate behavior of deep neural networks (DNNs)\nthrough the lens of neuron activation dynamics. We propose a probabilistic\nframework that can analyze models' neuron activation patterns as a stochastic\nprocess, uncovering theoretical insights into neural scaling laws, such as\nover-parameterization and the power-law decay of loss with respect to dataset\nsize. By deriving key mathematical relationships, we present that the number of\nactivated neurons increases in the form of $N(1-(\\frac{bN}{D+bN})^b)$, and the\nneuron activation should follows power-law distribution. Based on these two\nmathematical results, we demonstrate how DNNs maintain generalization\ncapabilities even under over-parameterization, and we elucidate the phase\ntransition phenomenon observed in loss curves as dataset size plotted in\nlog-axis (i.e. the data magnitude increases linearly). Moreover, by combining\nthe above two phenomenons and the power-law distribution of neuron activation,\nwe derived the power-law decay of neural network's loss function as the data\nsize scale increases. Furthermore, our analysis bridges the gap between\nempirical observations and theoretical underpinnings, offering experimentally\ntestable predictions regarding parameter efficiency and model compressibility.\nThese findings provide a foundation for understanding neural network scaling\nand present new directions for optimizing DNN performance.",
      "tldr_zh": "这篇论文从神经元激活视角探索深度神经网络（DNNs）的行为，提出一个概率框架将神经元激活模式视为随机过程，以揭示神经缩放定律。研究推导了关键数学关系，包括激活神经元数量的公式 \\( N(1 - (\\frac{bN}{D + bN})^b) \\) 和神经元激活的幂律分布，解释了DNNs在过参数化条件下保持泛化能力的机制。论文进一步阐述了损失曲线中的相变现象，并证明了损失函数随数据集规模增加的幂律衰减。这些发现桥接了经验观察与理论基础，提供可测试的预测，如参数效率和模型可压缩性，为优化DNN性能和理解神经网络缩放提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18073v1",
      "published_date": "2024-12-24 01:01:06 UTC",
      "updated_date": "2024-12-24 01:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:31:43.932858"
    },
    {
      "arxiv_id": "2412.18072v1",
      "title": "MMFactory: A Universal Solution Search Engine for Vision-Language Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Wan-Cyuan Fan",
        "Tanzila Rahman",
        "Leonid Sigal"
      ],
      "abstract": "With advances in foundational and vision-language models, and effective\nfine-tuning techniques, a large number of both general and special-purpose\nmodels have been developed for a variety of visual tasks. Despite the\nflexibility and accessibility of these models, no single model is able to\nhandle all tasks and/or applications that may be envisioned by potential users.\nRecent approaches, such as visual programming and multimodal LLMs with\nintegrated tools aim to tackle complex visual tasks, by way of program\nsynthesis. However, such approaches overlook user constraints (e.g.,\nperformance / computational needs), produce test-time sample-specific solutions\nthat are difficult to deploy, and, sometimes, require low-level instructions\nthat maybe beyond the abilities of a naive user. To address these limitations,\nwe introduce MMFactory, a universal framework that includes model and metrics\nrouting components, acting like a solution search engine across various\navailable models. Based on a task description and few sample input-output pairs\nand (optionally) resource and/or performance constraints, MMFactory can suggest\na diverse pool of programmatic solutions by instantiating and combining\nvisio-lingual tools from its model repository. In addition to synthesizing\nthese solutions, MMFactory also proposes metrics and benchmarks performance /\nresource characteristics, allowing users to pick a solution that meets their\nunique design constraints. From the technical perspective, we also introduced a\ncommittee-based solution proposer that leverages multi-agent LLM conversation\nto generate executable, diverse, universal, and robust solutions for the user.\nExperimental results show that MMFactory outperforms existing methods by\ndelivering state-of-the-art solutions tailored to user problem specifications.\nProject page is available at https://davidhalladay.github.io/mmfactory_demo.",
      "tldr_zh": "该论文提出了MMFactory，一种通用框架，充当视觉语言任务(Vision-Language Tasks)的解决方案搜索引擎，以解决单一模型无法处理所有任务的问题。MMFactory基于任务描述、少量输入输出对以及可选的资源/性能约束，通过模型和指标路由组件来实例化和组合视觉语言工具，生成多样化的程序化解决方案，并评估其性能和资源特性以满足用户需求。从技术角度，该框架引入了基于多智能体LLM对话的委员会式解决方案提出者，确保生成的解决方案可执行、通用和稳健。实验结果显示，MMFactory优于现有方法，能提供符合用户规格的先进解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18072v1",
      "published_date": "2024-12-24 00:59:16 UTC",
      "updated_date": "2024-12-24 00:59:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:31:55.244799"
    },
    {
      "arxiv_id": "2412.18067v1",
      "title": "Automated Materials Discovery Platform Realized: Scanning Probe Microscopy of Combinatorial Libraries",
      "title_zh": "自动化的材料发现平台实现：组合库的",
      "authors": [
        "Yu Liu",
        "Rohit Pant",
        "Ichiro Takeuchi",
        "R. Jackson Spurling",
        "Jon-Paul Maria",
        "Maxim Ziatdinov",
        "Sergei V. Kalinin"
      ],
      "abstract": "Combinatorial libraries are a powerful approach for exploring the evolution\nof physical properties across binary and ternary cross-sections in\nmulticomponent phase diagrams. Although the synthesis of these libraries has\nbeen developed since the 1960s and expedited with advanced laboratory\nautomation, the broader application of combinatorial libraries relies on fast,\nreliable measurements of concentration-dependent structures and\nfunctionalities. Scanning Probe Microscopies (SPM), including piezoresponse\nforce microscopy (PFM), offer significant potential for quantitative,\nfunctionally relevant combi-library readouts. Here we demonstrate the\nimplementation of fully automated SPM to explore the evolution of ferroelectric\nproperties in combinatorial libraries, focusing on Sm-doped BiFeO3 and\nZnxMg1-xO systems. We also present and compare Gaussian Process-based Bayesian\nOptimization models for fully automated exploration, emphasizing local\nreproducibility (effective noise) as an essential factor in optimal experiment\nworkflows. Automated SPM, when coupled with upstream synthesis controls, plays\na pivotal role in bridging materials synthesis and characterization.",
      "tldr_zh": "该研究实现了自动化材料发现平台，通过扫描探针显微镜 (SPM) 对组合库进行快速、可靠的测量，探索多组分相图中二元和三元截面的物理属性演变，特别是铁电特性。研究聚焦于 Sm-doped BiFeO3 和 ZnxMg1-xO 系统，使用 piezoresponse force microscopy (PFM) 等技术进行定量分析，并引入基于高斯过程的贝叶斯优化模型来优化实验流程，强调局部再现性（有效噪声）的重要性。结果显示，这种自动化 SPM 方法显著提升了材料合成与表征的桥接效率，为材料发现提供了高效工具。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.mes-hall",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18067v1",
      "published_date": "2024-12-24 00:39:51 UTC",
      "updated_date": "2024-12-24 00:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:32:06.570181"
    },
    {
      "arxiv_id": "2412.18053v2",
      "title": "Neuron Empirical Gradient: Discovering and Quantifying Neurons Global Linear Controllability",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhao",
        "Zehui Jiang",
        "Naoki Yoshinaga"
      ],
      "abstract": "Although feed-forward neurons in pre-trained language models (PLMs) can store\nknowledge and their importance in influencing model outputs has been studied,\nexisting work focuses on finding a limited set of neurons and analyzing their\nrelative importance. However, the global quantitative role of activation values\nin shaping outputs remains unclear, hindering further advancements in\napplications like knowledge editing. Our study first investigates the numerical\nrelationship between neuron activations and model output and discovers the\nglobal linear relationship between them through neuron interventions on a\nknowledge probing dataset. We refer to the gradient of this linear relationship\nas neuron empirical gradient (NEG), and introduce NeurGrad, an accurate and\nefficient method for computing NEG. NeurGrad enables quantitative analysis of\nall neurons in PLMs, advancing our understanding of neurons' controllability.\nFurthermore, we explore NEG's ability to represent language skills across\ndiverse prompts via skill neuron probing. Experiments on MCEval8k, a\nmulti-choice knowledge benchmark spanning various genres, validate NEG's\nrepresentational ability. The data and code are released.",
      "tldr_zh": "本文研究了预训练语言模型(PLMs)中神经元激活值与输出之间的数值关系，发现了全局线性关系，并通过神经元干预引入了Neuron Empirical Gradient (NEG)来量化神经元的线性可控性。作者提出了NeurGrad，一种准确且高效的NEG计算方法，允许对所有神经元进行定量分析，并探索了NEG在表示语言技能方面的能力。实验在MCEval8k多选知识基准上验证了NEG的有效性，为知识编辑等应用提供了新进展，并发布了数据和代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.18053v2",
      "published_date": "2024-12-24 00:01:24 UTC",
      "updated_date": "2025-02-17 03:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:32:18.736702"
    },
    {
      "arxiv_id": "2412.18052v2",
      "title": "Beyond Gradient Averaging in Parallel Optimization: Improved Robustness through Gradient Agreement Filtering",
      "title_zh": "翻译失败",
      "authors": [
        "Francois Chaubard",
        "Duncan Eddy",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "We introduce Gradient Agreement Filtering (GAF) to improve on gradient\naveraging in distributed deep learning optimization. Traditional distributed\ndata-parallel stochastic gradient descent involves averaging gradients of\nmicrobatches to calculate a macrobatch gradient that is then used to update\nmodel parameters. We find that gradients across microbatches are often\northogonal or negatively correlated, especially in late stages of training,\nwhich leads to memorization of the training set, reducing generalization. In\nthis paper, we introduce a simple, computationally effective way to reduce\ngradient variance by computing the cosine distance between micro-gradients\nduring training and filtering out conflicting updates prior to averaging. We\nimprove validation accuracy with significantly smaller microbatch sizes. We\nalso show this reduces memorizing noisy labels. We demonstrate the\neffectiveness of this technique on standard image classification benchmarks\nincluding CIFAR-100 and CIFAR-100N-Fine. We show this technique consistently\noutperforms validation accuracy, in some cases by up to 18.2\\% compared to\ntraditional training approaches while reducing the computation required nearly\nan order of magnitude because we can now rely on smaller microbatch sizes\nwithout destabilizing training.",
      "tldr_zh": "本文提出 Gradient Agreement Filtering (GAF) 方法，以改进分布式深度学习优化中的梯度平均问题。GAF 通过计算微梯度之间的 cosine distance 并过滤冲突更新，减少梯度方差，从而缓解训练后期梯度正交或负相关导致的过拟合和泛化能力下降。在 CIFAR-100 和 CIFAR-100N-Fine 等图像分类基准上，实验结果显示 GAF 比传统 stochastic gradient descent 提高验证准确率最高达 18.2%，并允许使用更小的微批次大小，显著降低计算需求。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18052v2",
      "published_date": "2024-12-24 00:00:11 UTC",
      "updated_date": "2024-12-29 11:44:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:32:30.518102"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 112,
  "processed_papers_count": 112,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T17:32:52.542099"
}