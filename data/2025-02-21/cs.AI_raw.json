[
  {
    "arxiv_id": "2502.18505v1",
    "title": "Comprehensive Analysis of Transparency and Accessibility of ChatGPT, DeepSeek, And other SoTA Large Language Models",
    "authors": [
      "Ranjan Sapkota",
      "Shaina Raza",
      "Manoj Karkee"
    ],
    "abstract": "Despite increasing discussions on open-source Artificial Intelligence (AI),\nexisting research lacks a discussion on the transparency and accessibility of\nstate-of-the-art (SoTA) Large Language Models (LLMs). The Open Source\nInitiative (OSI) has recently released its first formal definition of\nopen-source software. This definition, when combined with standard dictionary\ndefinitions and the sparse published literature, provide an initial framework\nto support broader accessibility to AI models such as LLMs, but more work is\nessential to capture the unique dynamics of openness in AI. In addition,\nconcerns about open-washing, where models claim openness but lack full\ntransparency, has been raised, which limits the reproducibility, bias\nmitigation, and domain adaptation of these models. In this context, our study\ncritically analyzes SoTA LLMs from the last five years, including ChatGPT,\nDeepSeek, LLaMA, and others, to assess their adherence to transparency\nstandards and the implications of partial openness. Specifically, we examine\ntransparency and accessibility from two perspectives: open-source vs.\nopen-weight models. Our findings reveal that while some models are labeled as\nopen-source, this does not necessarily mean they are fully open-sourced. Even\nin the best cases, open-source models often do not report model training data,\nand code as well as key metrics, such as weight accessibility, and carbon\nemissions. To the best of our knowledge, this is the first study that\nsystematically examines the transparency and accessibility of over 100\ndifferent SoTA LLMs through the dual lens of open-source and open-weight\nmodels. The findings open avenues for further research and call for responsible\nand sustainable AI practices to ensure greater transparency, accountability,\nand ethical deployment of these models.(DeepSeek transparency, ChatGPT\naccessibility, open source, DeepSeek open source)",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18505v1",
    "published_date": "2025-02-21 23:53:13 UTC",
    "updated_date": "2025-02-21 23:53:13 UTC"
  },
  {
    "arxiv_id": "2502.16003v1",
    "title": "Hierarchical Residuals Exploit Brain-Inspired Compositionality",
    "authors": [
      "Francisco M. LÃ³pez",
      "Jochen Triesch"
    ],
    "abstract": "We present Hierarchical Residual Networks (HiResNets), deep convolutional\nneural networks with long-range residual connections between layers at\ndifferent hierarchical levels. HiResNets draw inspiration on the organization\nof the mammalian brain by replicating the direct connections from subcortical\nareas to the entire cortical hierarchy. We show that the inclusion of\nhierarchical residuals in several architectures, including ResNets, results in\na boost in accuracy and faster learning. A detailed analysis of our models\nreveals that they perform hierarchical compositionality by learning feature\nmaps relative to the compressed representations provided by the skip\nconnections.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ESANN 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.16003v1",
    "published_date": "2025-02-21 23:35:08 UTC",
    "updated_date": "2025-02-21 23:35:08 UTC"
  },
  {
    "arxiv_id": "2502.15996v2",
    "title": "Med-gte-hybrid: A contextual embedding transformer model for extracting actionable information from clinical texts",
    "authors": [
      "Aditya Kumar",
      "Simon Rauch",
      "Mario Cypko",
      "Oliver Amft"
    ],
    "abstract": "We introduce a novel contextual embedding model med-gte-hybrid that was\nderived from the gte-large sentence transformer to extract information from\nunstructured clinical narratives. Our model tuning strategy for med-gte-hybrid\ncombines contrastive learning and a denoising autoencoder. To evaluate the\nperformance of med-gte-hybrid, we investigate several clinical prediction tasks\nin large patient cohorts extracted from the MIMIC-IV dataset, including Chronic\nKidney Disease (CKD) patient prognosis, estimated glomerular filtration rate\n(eGFR) prediction, and patient mortality prediction. Furthermore, we\ndemonstrate that the med-gte-hybrid model improves patient stratification,\nclustering, and text retrieval, thus outperforms current state-of-the-art\nmodels on the Massive Text Embedding Benchmark (MTEB). While some of our\nevaluations focus on CKD, our hybrid tuning of sentence transformers could be\ntransferred to other medical domains and has the potential to improve clinical\ndecision-making and personalised treatment pathways in various healthcare\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15996v2",
    "published_date": "2025-02-21 23:17:31 UTC",
    "updated_date": "2025-03-12 16:17:01 UTC"
  },
  {
    "arxiv_id": "2502.15990v1",
    "title": "Automated Query-Product Relevance Labeling using Large Language Models for E-commerce Search",
    "authors": [
      "Jayant Sachdev",
      "Sean D Rosario",
      "Abhijeet Phatak",
      "He Wen",
      "Swati Kirti",
      "Chittaranjan Tripathy"
    ],
    "abstract": "Accurate query-product relevance labeling is indispensable to generate ground\ntruth dataset for search ranking in e-commerce. Traditional approaches for\nannotating query-product pairs rely on human-based labeling services, which is\nexpensive, time-consuming and prone to errors. In this work, we explore the\napplication of Large Language Models (LLMs) to automate query-product relevance\nlabeling for large-scale e-commerce search. We use several publicly available\nand proprietary LLMs for this task, and conducted experiments on two\nopen-source datasets and an in-house e-commerce search dataset. Using prompt\nengineering techniques such as Chain-of-Thought (CoT) prompting, In-context\nLearning (ICL), and Retrieval Augmented Generation (RAG) with Maximum Marginal\nRelevance (MMR), we show that LLM's performance has the potential to approach\nhuman-level accuracy on this task in a fraction of the time and cost required\nby human-labelers, thereby suggesting that our approach is more efficient than\nthe conventional methods. We have generated query-product relevance labels\nusing LLMs at scale, and are using them for evaluating improvements to our\nsearch algorithms. Our work demonstrates the potential of LLMs to improve\nquery-product relevance thus enhancing e-commerce search user experience. More\nimportantly, this scalable alternative to human-annotation has significant\nimplications for information retrieval domains including search and\nrecommendation systems, where relevance scoring is crucial for optimizing the\nranking of products and content to improve customer engagement and other\nconversion metrics.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15990v1",
    "published_date": "2025-02-21 22:59:36 UTC",
    "updated_date": "2025-02-21 22:59:36 UTC"
  },
  {
    "arxiv_id": "2502.15987v2",
    "title": "Forecasting Open-Weight AI Model Growth on HuggingFace",
    "authors": [
      "Kushal Raj Bhandari",
      "Pin-Yu Chen",
      "Jianxi Gao"
    ],
    "abstract": "As the open-weight AI landscape continues to proliferate-with model\ndevelopment, significant investment, and user interest-it becomes increasingly\nimportant to predict which models will ultimately drive innovation and shape AI\necosystems. Building on parallels with citation dynamics in scientific\nliterature, we propose a framework to quantify how an open-weight model's\ninfluence evolves. Specifically, we adapt the model introduced by Wang et al.\nfor scientific citations, using three key parameters-immediacy, longevity, and\nrelative fitness-to track the cumulative number of fine-tuned models of an\nopen-weight model. Our findings reveal that this citation-style approach can\neffectively capture the diverse trajectories of open-weight model adoption,\nwith most models fitting well and outliers indicating unique patterns or abrupt\njumps in usage.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Link to the website for trajectory visualization:\n  https://forecasthuggingfacemodels.onrender.com/",
    "pdf_url": "http://arxiv.org/pdf/2502.15987v2",
    "published_date": "2025-02-21 22:52:19 UTC",
    "updated_date": "2025-03-15 21:08:05 UTC"
  },
  {
    "arxiv_id": "2502.15980v1",
    "title": "Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation",
    "authors": [
      "Yuan Tian",
      "Daniel Lee",
      "Fei Wu",
      "Tung Mai",
      "Kun Qian",
      "Siddhartha Sahai",
      "Tianyi Zhang",
      "Yunyao Li"
    ],
    "abstract": "Text-to-SQL models, which parse natural language (NL) questions to executable\nSQL queries, are increasingly adopted in real-world applications. However,\ndeploying such models in the real world often requires adapting them to the\nhighly specialized database schemas used in specific applications. We find that\nexisting text-to-SQL models experience significant performance drops when\napplied to new schemas, primarily due to the lack of domain-specific data for\nfine-tuning. This data scarcity also limits the ability to effectively evaluate\nmodel performance in new domains. Continuously obtaining high-quality\ntext-to-SQL data for evolving schemas is prohibitively expensive in real-world\nscenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop\ntext-to-SQL data annotation system. SQLsynth streamlines the creation of\nhigh-quality text-to-SQL datasets through human-LLM collaboration in a\nstructured workflow. A within-subjects user study comparing SQLsynth with\nmanual annotation and ChatGPT shows that SQLsynth significantly accelerates\ntext-to-SQL data annotation, reduces cognitive load, and produces datasets that\nare more accurate, natural, and diverse. Our code is available at\nhttps://github.com/adobe/nl_sql_analyzer.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by IUI'25",
    "pdf_url": "http://arxiv.org/pdf/2502.15980v1",
    "published_date": "2025-02-21 22:32:35 UTC",
    "updated_date": "2025-02-21 22:32:35 UTC"
  },
  {
    "arxiv_id": "2502.15975v2",
    "title": "Sparsity May Be All You Need: Sparse Random Parameter Adaptation",
    "authors": [
      "Jesus Rios",
      "Pierre Dognin",
      "Ronny Luss",
      "Karthikeyan N. Ramamurthy"
    ],
    "abstract": "Full fine-tuning of large language models for alignment and task adaptation\nhas become prohibitively expensive as models have grown in size.\nParameter-Efficient Fine-Tuning (PEFT) methods aim at significantly reducing\nthe computational and memory resources needed for fine-tuning these models by\nonly training on a small number of parameters instead of all model parameters.\nCurrently, the most popular PEFT method is the Low-Rank Adaptation (LoRA),\nwhich freezes the parameters of the model to be fine-tuned and introduces a\nsmall set of trainable parameters in the form of low-rank matrices. We propose\nsimply reducing the number of trainable parameters by randomly selecting a\nsmall proportion of the model parameters to train on. In this paper, we compare\nthe efficiency and performance of our proposed approach with PEFT methods,\nincluding LoRA, as well as full parameter fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15975v2",
    "published_date": "2025-02-21 22:23:16 UTC",
    "updated_date": "2025-05-21 15:33:56 UTC"
  },
  {
    "arxiv_id": "2502.15972v1",
    "title": "Multi-Agent Multimodal Models for Multicultural Text to Image Generation",
    "authors": [
      "Parth Bhalerao",
      "Mounika Yalamarty",
      "Brian Trinh",
      "Oana Ignat"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate impressive performance across\nvarious multimodal tasks. However, their effectiveness in cross-cultural\ncontexts remains limited due to the predominantly Western-centric nature of\nexisting data and models. Meanwhile, multi-agent models have shown strong\ncapabilities in solving complex tasks. In this paper, we evaluate the\nperformance of LLMs in a multi-agent interaction setting for the novel task of\nmulticultural image generation. Our key contributions are: (1) We introduce\nMosAIG, a Multi-Agent framework that enhances multicultural Image Generation by\nleveraging LLMs with distinct cultural personas; (2) We provide a dataset of\n9,000 multicultural images spanning five countries, three age groups, two\ngenders, 25 historical landmarks, and five languages; and (3) We demonstrate\nthat multi-agent interactions outperform simple, no-agent models across\nmultiple evaluation metrics, offering valuable insights for future research.\nOur dataset and models are available at https://github.com/OanaIgnat/MosAIG.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15972v1",
    "published_date": "2025-02-21 22:19:56 UTC",
    "updated_date": "2025-02-21 22:19:56 UTC"
  },
  {
    "arxiv_id": "2502.15969v3",
    "title": "Forgotten Polygons: Multimodal Large Language Models are Shape-Blind",
    "authors": [
      "William Rudman",
      "Michal Golovanevsky",
      "Amir Bar",
      "Vedant Palit",
      "Yann LeCun",
      "Carsten Eickhoff",
      "Ritambhara Singh"
    ],
    "abstract": "Despite strong performance on vision-language tasks, Multimodal Large\nLanguage Models (MLLMs) struggle with mathematical problem-solving, with both\nopen-source and state-of-the-art models falling short of human performance on\nvisual-math benchmarks. To systematically examine visual-mathematical reasoning\nin MLLMs, we (1) evaluate their understanding of geometric primitives, (2) test\nmulti-step reasoning, and (3) explore a potential solution to improve visual\nreasoning capabilities. Our findings reveal fundamental shortcomings in shape\nrecognition, with top models achieving under 50% accuracy in identifying\nregular polygons. We analyze these failures through the lens of dual-process\ntheory and show that MLLMs rely on System 1 (intuitive, memorized associations)\nrather than System 2 (deliberate reasoning). Consequently, MLLMs fail to count\nthe sides of both familiar and novel shapes, suggesting they have neither\nlearned the concept of sides nor effectively process visual inputs. Finally, we\npropose Visually Cued Chain-of-Thought (VC-CoT) prompting, which enhances\nmulti-step mathematical reasoning by explicitly referencing visual annotations\nin diagrams, boosting GPT-4o's accuracy on an irregular polygon side-counting\ntask from 7% to 93%. Our findings suggest that System 2 reasoning in MLLMs\nremains an open problem, and visually-guided prompting is essential for\nsuccessfully engaging visual reasoning. Code available at:\nhttps://github.com/rsinghlab/Shape-Blind.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15969v3",
    "published_date": "2025-02-21 22:04:09 UTC",
    "updated_date": "2025-04-05 17:15:23 UTC"
  },
  {
    "arxiv_id": "2502.15964v1",
    "title": "Minions: Cost-efficient Collaboration Between On-device and Cloud Language Models",
    "authors": [
      "Avanika Narayan",
      "Dan Biderman",
      "Sabri Eyuboglu",
      "Avner May",
      "Scott Linderman",
      "James Zou",
      "Christopher Re"
    ],
    "abstract": "We investigate an emerging setup in which a small, on-device language model\n(LM) with access to local data communicates with a frontier, cloud-hosted LM to\nsolve real-world tasks involving financial, medical, and scientific reasoning\nover long documents. Can a local-remote collaboration reduce cloud inference\ncosts while preserving quality? First, we consider a naive collaboration\nprotocol where the local and remote models simply chat back and forth. Because\nonly the local model reads the full context, this protocol achieves a 30.4x\nreduction in remote costs, but recovers only 87% of the performance of the\nfrontier model. We identify two key limitations of this protocol: the local\nmodel struggles to (1) follow the remote model's multi-step instructions and\n(2) reason over long contexts. Motivated by these observations, we study an\nextension of this protocol, coined MinionS, in which the remote model\ndecomposes the task into easier subtasks over shorter chunks of the document,\nthat are executed locally in parallel. MinionS reduces costs by 5.7x on average\nwhile recovering 97.9% of the performance of the remote model alone. Our\nanalysis reveals several key design choices that influence the trade-off\nbetween cost and performance in local-remote systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15964v1",
    "published_date": "2025-02-21 21:54:40 UTC",
    "updated_date": "2025-02-21 21:54:40 UTC"
  },
  {
    "arxiv_id": "2502.15959v1",
    "title": "A Knowledge Distillation-Based Approach to Enhance Transparency of Classifier Models",
    "authors": [
      "Yuchen Jiang",
      "Xinyuan Zhao",
      "Yihang Wu",
      "Ahmad Chaddad"
    ],
    "abstract": "With the rapid development of artificial intelligence (AI), especially in the\nmedical field, the need for its explainability has grown. In medical image\nanalysis, a high degree of transparency and model interpretability can help\nclinicians better understand and trust the decision-making process of AI\nmodels. In this study, we propose a Knowledge Distillation (KD)-based approach\nthat aims to enhance the transparency of the AI model in medical image\nanalysis. The initial step is to use traditional CNN to obtain a teacher model\nand then use KD to simplify the CNN architecture, retain most of the features\nof the data set, and reduce the number of network layers. It also uses the\nfeature map of the student model to perform hierarchical analysis to identify\nkey features and decision-making processes. This leads to intuitive visual\nexplanations. We selected three public medical data sets (brain tumor, eye\ndisease, and Alzheimer's disease) to test our method. It shows that even when\nthe number of layers is reduced, our model provides a remarkable result in the\ntest set and reduces the time required for the interpretability analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15959v1",
    "published_date": "2025-02-21 21:43:21 UTC",
    "updated_date": "2025-02-21 21:43:21 UTC"
  },
  {
    "arxiv_id": "2503.16456v1",
    "title": "Position: Beyond Assistance -- Reimagining LLMs as Ethical and Adaptive Co-Creators in Mental Health Care",
    "authors": [
      "Abeer Badawi",
      "Md Tahmid Rahman Laskar",
      "Jimmy Xiangji Huang",
      "Shaina Raza",
      "Elham Dolatabadi"
    ],
    "abstract": "This position paper argues for a fundamental shift in how Large Language\nModels (LLMs) are integrated into the mental health care domain. We advocate\nfor their role as co-creators rather than mere assistive tools. While LLMs have\nthe potential to enhance accessibility, personalization, and crisis\nintervention, their adoption remains limited due to concerns about bias,\nevaluation, over-reliance, dehumanization, and regulatory uncertainties. To\naddress these challenges, we propose two structured pathways: SAFE-i\n(Supportive, Adaptive, Fair, and Ethical Implementation) Guidelines for ethical\nand responsible deployment, and HAAS-e (Human-AI Alignment and Safety\nEvaluation) Framework for multidimensional, human-centered assessment. SAFE-i\nprovides a blueprint for data governance, adaptive model engineering, and\nreal-world integration, ensuring LLMs align with clinical and ethical\nstandards. HAAS-e introduces evaluation metrics that go beyond technical\naccuracy to measure trustworthiness, empathy, cultural sensitivity, and\nactionability. We call for the adoption of these structured approaches to\nestablish a responsible and scalable model for LLM-driven mental health\nsupport, ensuring that AI complements-rather than replaces-human expertise.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16456v1",
    "published_date": "2025-02-21 21:41:20 UTC",
    "updated_date": "2025-02-21 21:41:20 UTC"
  },
  {
    "arxiv_id": "2502.15957v1",
    "title": "R$^3$Mem: Bridging Memory Retention and Retrieval via Reversible Compression",
    "authors": [
      "Xiaoqiang Wang",
      "Suyuchen Wang",
      "Yun Zhu",
      "Bang Liu"
    ],
    "abstract": "Memory plays a key role in enhancing LLMs' performance when deployed to\nreal-world applications. Existing solutions face trade-offs: explicit memory\ndesigns based on external storage require complex management and incur storage\noverhead, while implicit memory designs that store information via parameters\nstruggle with reliable retrieval. In this paper, we propose R$^3$Mem, a memory\nnetwork that optimizes both information Retention and Retrieval through\nReversible context compression. Specifically, R$^3$Mem employs virtual memory\ntokens to compress and encode infinitely long histories, further enhanced by a\nhierarchical compression strategy that refines information from document- to\nentity-level for improved assimilation across granularities. For retrieval,\nR$^3$Mem employs a reversible architecture, reconstructing raw data by invoking\nthe model backward with compressed information. Implemented via\nparameter-efficient fine-tuning, it can integrate seamlessly with any\nTransformer-based model. Experiments demonstrate that our memory design\nachieves state-of-the-art performance in long-context language modeling and\nretrieval-augmented generation tasks. It also significantly outperforms\nconventional memory modules in long-horizon interaction tasks like\nconversational agents, showcasing its potential for next-generation retrieval\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2502.15957v1",
    "published_date": "2025-02-21 21:39:00 UTC",
    "updated_date": "2025-02-21 21:39:00 UTC"
  },
  {
    "arxiv_id": "2502.15955v1",
    "title": "Compression Barriers for Autoregressive Transformers",
    "authors": [
      "Themistoklis Haris",
      "Krzysztof Onak"
    ],
    "abstract": "A key limitation of autoregressive Transformers is the large memory needed at\ninference-time to cache all previous key-value (KV) embeddings. Prior works\naddress this by compressing the KV cache, but often assume specific structural\nproperties of the embeddings. This raises the following natural question: Can\ntruly sublinear space utilization be achieved without such assumptions? In this\nwork, we answer this question in the negative. Any algorithm for\nattention-based token generation must use $\\Theta(nd)$ space, where $n$ is the\nnumber of tokens generated so far and $d = \\Omega(\\log n)$ is the dimension of\nthe KV embeddings. Our proof involves a reduction from a classic communication\ncomplexity problem and uses a randomized construction that leverages properties\nof projections in the spirit of the Johnson-Linderstrauss lemma. For the\nlow-dimensional regime $d = o(\\log n)$, we show that any algorithm requires\n$\\Omega(d\\cdot e^d)$ space and prove, using tight bounds on covering numbers,\nthat SubGen, proposed by Zandieh, Han, Mirrokni and Karbasi, matches this\nbound. Further, we investigate how sparsity assumptions enable token generation\nin truly sublinear space, presenting impossibility results and proposing a new\nKV cache compression algorithm for sliding window attention when the value\ncache outside the window is unmasked. Finally, we analyze token generation's\ntime complexity, using an indistinguishability argument to prove that no\nnon-adaptive algorithm can compute attention online in sublinear time for all\ntokens.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15955v1",
    "published_date": "2025-02-21 21:37:52 UTC",
    "updated_date": "2025-02-21 21:37:52 UTC"
  },
  {
    "arxiv_id": "2502.15954v1",
    "title": "MMRAG: Multi-Mode Retrieval-Augmented Generation with Large Language Models for Biomedical In-Context Learning",
    "authors": [
      "Zaifu Zhan",
      "Jun Wang",
      "Shuang Zhou",
      "Jiawen Deng",
      "Rui Zhang"
    ],
    "abstract": "Objective: To optimize in-context learning in biomedical natural language\nprocessing by improving example selection. Methods: We introduce a novel\nmulti-mode retrieval-augmented generation (MMRAG) framework, which integrates\nfour retrieval strategies: (1) Random Mode, selecting examples arbitrarily; (2)\nTop Mode, retrieving the most relevant examples based on similarity; (3)\nDiversity Mode, ensuring variation in selected examples; and (4) Class Mode,\nselecting category-representative examples. This study evaluates MMRAG on three\ncore biomedical NLP tasks: Named Entity Recognition (NER), Relation Extraction\n(RE), and Text Classification (TC). The datasets used include BC2GM for gene\nand protein mention recognition (NER), DDI for drug-drug interaction extraction\n(RE), GIT for general biomedical information extraction (RE), and HealthAdvice\nfor health-related text classification (TC). The framework is tested with two\nlarge language models (Llama2-7B, Llama3-8B) and three retrievers (Contriever,\nMedCPT, BGE-Large) to assess performance across different retrieval strategies.\nResults: The results from the Random mode indicate that providing more examples\nin the prompt improves the model's generation performance. Meanwhile, Top mode\nand Diversity mode significantly outperform Random mode on the RE (DDI) task,\nachieving an F1 score of 0.9669, a 26.4% improvement. Among the three\nretrievers tested, Contriever outperformed the other two in a greater number of\nexperiments. Additionally, Llama 2 and Llama 3 demonstrated varying\ncapabilities across different tasks, with Llama 3 showing a clear advantage in\nhandling NER tasks. Conclusion: MMRAG effectively enhances biomedical\nin-context learning by refining example selection, mitigating data scarcity\nissues, and demonstrating superior adaptability for NLP-driven healthcare\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to JAMIA",
    "pdf_url": "http://arxiv.org/pdf/2502.15954v1",
    "published_date": "2025-02-21 21:36:48 UTC",
    "updated_date": "2025-02-21 21:36:48 UTC"
  },
  {
    "arxiv_id": "2502.15953v1",
    "title": "Multi-Objective Optimization of Water Resource Allocation for Groundwater Recharge and Surface Runoff Management in Watershed Systems",
    "authors": [
      "Abbas Sharifi",
      "Hajar Kazemi Naeini",
      "Mohsen Ahmadi",
      "Saeed Asadi",
      "Abbas Varmaghani"
    ],
    "abstract": "Land degradation and air pollution are primarily caused by the salinization\nof soil and desertification that occurs from the drying of salinity lakes and\nthe release of dust into the atmosphere because of their dried bottom. The\ncomplete drying up of a lake has caused a community environmental catastrophe.\nIn this study, we presented an optimization problem to determine the total\nsurface runoff to maintain the level of salinity lake (Urmia Lake). The\nproposed process has two key stages: identifying the influential factors in\ndetermining the lake water level using sensitivity analysis approaches based\nupon historical data and optimizing the effective variable to stabilize the\nlake water level under changing design variables. Based upon the Sobol'-Jansen\nand Morris techniques, the groundwater level and total surface runoff flow are\nhighly effective with nonlinear and interacting impacts of the lake water\nlevel. As a result of the sensitivity analysis, we found that it may be\npossible to effectively manage lake levels by adjusting total surface runoff.\nWe used genetic algorithms, non-linear optimization, and pattern search\ntechniques to solve the optimization problem. Furthermore, the lake level\nconstraint is established based on a pattern as a constant number every month.\nIn order to maintain a consistent pattern of lake levels, it is necessary to\nincrease surface runoff by approximately 8.7 times during filling season. It is\nnecessary to increase this quantity by 33.5 times during the draining season.\nIn the future, the results may serve as a guide for the rehabilitation of the\nlake.",
    "categories": [
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15953v1",
    "published_date": "2025-02-21 21:34:27 UTC",
    "updated_date": "2025-02-21 21:34:27 UTC"
  },
  {
    "arxiv_id": "2502.18504v1",
    "title": "TurboFuzzLLM: Turbocharging Mutation-based Fuzzing for Effectively Jailbreaking Large Language Models in Practice",
    "authors": [
      "Aman Goel",
      "Xian Carrie Wu",
      "Zhe Wang",
      "Dmitriy Bespalov",
      "Yanjun Qi"
    ],
    "abstract": "Jailbreaking large-language models (LLMs) involves testing their robustness\nagainst adversarial prompts and evaluating their ability to withstand prompt\nattacks that could elicit unauthorized or malicious responses. In this paper,\nwe present TurboFuzzLLM, a mutation-based fuzzing technique for efficiently\nfinding a collection of effective jailbreaking templates that, when combined\nwith harmful questions, can lead a target LLM to produce harmful responses\nthrough black-box access via user prompts. We describe the limitations of\ndirectly applying existing template-based attacking techniques in practice, and\npresent functional and efficiency-focused upgrades we added to mutation-based\nfuzzing to generate effective jailbreaking templates automatically.\nTurboFuzzLLM achieves $\\geq$ 95\\% attack success rates (ASR) on public datasets\nfor leading LLMs (including GPT-4o \\& GPT-4 Turbo), shows impressive\ngeneralizability to unseen harmful questions, and helps in improving model\ndefenses to prompt attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at NAACL 2025 industry track, 12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.18504v1",
    "published_date": "2025-02-21 21:10:12 UTC",
    "updated_date": "2025-02-21 21:10:12 UTC"
  },
  {
    "arxiv_id": "2502.15938v1",
    "title": "Straight to Zero: Why Linearly Decaying the Learning Rate to Zero Works Best for LLMs",
    "authors": [
      "Shane Bergsma",
      "Nolan Dey",
      "Gurpreet Gosal",
      "Gavia Gray",
      "Daria Soboleva",
      "Joel Hestness"
    ],
    "abstract": "LLMs are commonly trained with a learning rate (LR) warmup, followed by\ncosine decay to 10% of the maximum (10x decay). In a large-scale empirical\nstudy, we show that under an optimal peak LR, a simple linear decay-to-zero\n(D2Z) schedule consistently outperforms other schedules when training at\ncompute-optimal dataset sizes. D2Z is superior across a range of model sizes,\nbatch sizes, datasets, and vocabularies. Benefits increase as dataset size\nincreases. Leveraging a novel interpretation of AdamW as an exponential moving\naverage of weight updates, we show how linear D2Z optimally balances the\ndemands of early training (moving away from initial conditions) and late\ntraining (averaging over more updates in order to mitigate gradient noise). In\nexperiments, a 610M-parameter model trained for 80 tokens-per-parameter (TPP)\nusing D2Z achieves lower loss than when trained for 200 TPP using 10x decay,\ncorresponding to an astonishing 60% compute savings. Models such as Llama2-7B,\ntrained for 286 TPP with 10x decay, could likely have saved a majority of\ncompute by training with D2Z.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15938v1",
    "published_date": "2025-02-21 21:08:24 UTC",
    "updated_date": "2025-02-21 21:08:24 UTC"
  },
  {
    "arxiv_id": "2502.15937v1",
    "title": "Discovery and Deployment of Emergent Robot Swarm Behaviors via Representation Learning and Real2Sim2Real Transfer",
    "authors": [
      "Connor Mattson",
      "Varun Raveendra",
      "Ricardo Vega",
      "Cameron Nowzari",
      "Daniel S. Drew",
      "Daniel S. Brown"
    ],
    "abstract": "Given a swarm of limited-capability robots, we seek to automatically discover\nthe set of possible emergent behaviors. Prior approaches to behavior discovery\nrely on human feedback or hand-crafted behavior metrics to represent and evolve\nbehaviors and only discover behaviors in simulation, without testing or\nconsidering the deployment of these new behaviors on real robot swarms. In this\nwork, we present Real2Sim2Real Behavior Discovery via Self-Supervised\nRepresentation Learning, which combines representation learning and novelty\nsearch to discover possible emergent behaviors automatically in simulation and\nenable direct controller transfer to real robots. First, we evaluate our method\nin simulation and show that our proposed self-supervised representation\nlearning approach outperforms previous hand-crafted metrics by more accurately\nrepresenting the space of possible emergent behaviors. Then, we address the\nreality gap by incorporating recent work in sim2real transfer for swarms into\nour lightweight simulator design, enabling direct robot deployment of all\nbehaviors discovered in simulation on an open-source and low-cost robot\nplatform.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 5 figures. To be included in Proc. of the 24th\n  International Conference on Autonomous Agents and Multiagent Systems (AAMAS\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.15937v1",
    "published_date": "2025-02-21 21:04:47 UTC",
    "updated_date": "2025-02-21 21:04:47 UTC"
  },
  {
    "arxiv_id": "2502.15936v1",
    "title": "Space-O-RAN: Enabling Intelligent, Open, and Interoperable Non Terrestrial Networks in 6G",
    "authors": [
      "Eduardo Baena",
      "Paolo Testolina",
      "Michele Polese",
      "Dimitrios Koutsonikolas",
      "Josep Jornet",
      "Tommaso Melodia"
    ],
    "abstract": "Non-terrestrial networks (NTNs) are essential for ubiquitous connectivity,\nproviding coverage in remote and underserved areas. However, since NTNs are\ncurrently operated independently, they face challenges such as isolation,\nlimited scalability, and high operational costs. Integrating satellite\nconstellations with terrestrial networks offers a way to address these\nlimitations while enabling adaptive and cost-efficient connectivity through the\napplication of Artificial Intelligence (AI) models.\n  This paper introduces Space-O-RAN, a framework that extends Open Radio Access\nNetwork (RAN) principles to NTNs. It employs hierarchical closed-loop control\nwith distributed Space RAN Intelligent Controllers (Space-RICs) to dynamically\nmanage and optimize operations across both domains.\n  To enable adaptive resource allocation and network orchestration, the\nproposed architecture integrates real-time satellite optimization and control\nwith AI-driven management and digital twin (DT) modeling. It incorporates\ndistributed Space Applications (sApps) and dApps to ensure robust performance\nin in highly dynamic orbital environments. A core feature is dynamic\nlink-interface mapping, which allows network functions to adapt to specific\napplication requirements and changing link conditions using all physical links\non the satellite.\n  Simulation results evaluate its feasibility by analyzing latency constraints\nacross different NTN link types, demonstrating that intra-cluster coordination\noperates within viable signaling delay bounds, while offloading non-real-time\ntasks to ground infrastructure enhances scalability toward sixth-generation\n(6G) networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15936v1",
    "published_date": "2025-02-21 21:03:37 UTC",
    "updated_date": "2025-02-21 21:03:37 UTC"
  },
  {
    "arxiv_id": "2503.00018v1",
    "title": "Eeyore: Realistic Depression Simulation via Supervised and Preference Optimization",
    "authors": [
      "Siyang Liu",
      "Bianca Brie",
      "Wenda Li",
      "Laura Biester",
      "Andrew Lee",
      "James Pennebaker",
      "Rada Mihalcea"
    ],
    "abstract": "Large Language Models (LLMs) have been previously explored for mental\nhealthcare training and therapy client simulation, but they still fall short in\nauthentically capturing diverse client traits and psychological conditions. We\nintroduce \\textbf{Eeyore}, an 8B model optimized for realistic depression\nsimulation through a structured alignment framework, incorporating expert input\nat every stage. First, we systematically curate real-world depression-related\nconversations, extracting depressive traits to guide data filtering and\npsychological profile construction, and use this dataset to instruction-tune\nEeyore for profile adherence. Next, to further enhance realism, Eeyore\nundergoes iterative preference optimization -- first leveraging model-generated\npreferences and then calibrating with a small set of expert-annotated\npreferences. Throughout the entire pipeline, we actively collaborate with\ndomain experts, developing interactive interfaces to validate trait extraction\nand iteratively refine structured psychological profiles for clinically\nmeaningful role-play customization. Despite its smaller model size, the Eeyore\ndepression simulation outperforms GPT-4o with SOTA prompting strategies, both\nin linguistic authenticity and profile adherence.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00018v1",
    "published_date": "2025-02-21 20:29:44 UTC",
    "updated_date": "2025-02-21 20:29:44 UTC"
  },
  {
    "arxiv_id": "2502.15920v1",
    "title": "Self-Taught Agentic Long Context Understanding",
    "authors": [
      "Yufan Zhuang",
      "Xiaodong Yu",
      "Jialian Wu",
      "Ximeng Sun",
      "Ze Wang",
      "Jiang Liu",
      "Yusheng Su",
      "Jingbo Shang",
      "Zicheng Liu",
      "Emad Barsoum"
    ],
    "abstract": "Answering complex, long-context questions remains a major challenge for large\nlanguage models (LLMs) as it requires effective question clarifications and\ncontext retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a\nframework designed to enhance an LLM's understanding of such queries by\nintegrating targeted self-clarification with contextual grounding within an\nagentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC),\nwhere models refine their understanding through self-generated clarification\nquestions and corresponding contextual groundings. By scaling inference as a\ntree search where each node represents a CoC step, we achieve 97.8% answer\nrecall on NarrativeQA with a search depth of up to three and a branching factor\nof eight. To amortize the high cost of this search process to training, we\nleverage the preference pairs for each step obtained by the CoC workflow and\nperform two-stage model finetuning: (1) supervised finetuning to learn\neffective decomposition strategies, and (2) direct preference optimization to\nenhance reasoning quality. This enables AgenticLU models to generate\nclarifications and retrieve relevant context effectively and efficiently in a\nsingle inference pass. Extensive experiments across seven long-context tasks\ndemonstrate that AgenticLU significantly outperforms state-of-the-art prompting\nmethods and specialized long-context LLMs, achieving robust multi-hop reasoning\nwhile sustaining consistent performance as context length grows.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15920v1",
    "published_date": "2025-02-21 20:29:36 UTC",
    "updated_date": "2025-02-21 20:29:36 UTC"
  },
  {
    "arxiv_id": "2503.16455v1",
    "title": "Bridging Structural Dynamics and Biomechanics: Human Motion Estimation through Footstep-Induced Floor Vibrations",
    "authors": [
      "Yiwen Dong",
      "Jessica Rose",
      "Hae Young Noh"
    ],
    "abstract": "Quantitative estimation of human joint motion in daily living spaces is\nessential for early detection and rehabilitation tracking of\nneuromusculoskeletal disorders (e.g., Parkinson's) and mitigating trip and fall\nrisks for older adults. Existing approaches involve monitoring devices such as\ncameras, wearables, and pressure mats, but have operational constraints such as\ndirect line-of-sight, carrying devices, and dense deployment. To overcome these\nlimitations, we leverage gait-induced floor vibration to estimate lower-limb\njoint motion (e.g., ankle, knee, and hip flexion angles), allowing\nnon-intrusive and contactless gait health monitoring in people's living spaces.\nTo overcome the high uncertainty in lower-limb movement given the limited\ninformation provided by the gait-induced floor vibrations, we formulate a\nphysics-informed graph to integrate domain knowledge of gait biomechanics and\nstructural dynamics into the model. Specifically, different types of nodes\nrepresent heterogeneous information from joint motions and floor vibrations;\nTheir connecting edges represent the physiological relationships between joints\nand forces governed by gait biomechanics, as well as the relationships between\nforces and floor responses governed by the structural dynamics. As a result,\nour model poses physical constraints to reduce uncertainty while allowing\ninformation sharing between the body and the floor to make more accurate\npredictions. We evaluate our approach with 20 participants through a real-world\nwalking experiment. We achieved an average of 3.7 degrees of mean absolute\nerror in estimating 12 joint flexion angles (38% error reduction from\nbaseline), which is comparable to the performance of cameras and wearables in\ncurrent medical practices.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16455v1",
    "published_date": "2025-02-21 20:10:15 UTC",
    "updated_date": "2025-02-21 20:10:15 UTC"
  },
  {
    "arxiv_id": "2504.08737v1",
    "title": "Latency-Aware 2-Opt Monotonic Local Search for Distributed Constraint Optimization",
    "authors": [
      "Ben Rachmut",
      "Roie Zivan",
      "William Yeoh"
    ],
    "abstract": "Researchers recently extended Distributed Constraint Optimization Problems\n(DCOPs) to Communication-Aware DCOPs so that they are applicable in scenarios\nin which messages can be arbitrarily delayed. Distributed asynchronous local\nsearch and inference algorithms designed for CA-DCOPs are less vulnerable to\nmessage latency than their counterparts for regular DCOPs. However, unlike\nlocal search algorithms for (regular) DCOPs that converge to k-opt solutions\n(with k > 1), that is, they converge to solutions that cannot be improved by a\ngroup of k agents), local search CA-DCOP algorithms are limited to 1-opt\nsolutions only. In this paper, we introduce Latency-Aware Monotonic Distributed\nLocal Search-2 (LAMDLS-2), where agents form pairs and coordinate bilateral\nassignment replacements. LAMDLS-2 is monotonic, converges to a 2-opt solution,\nand is also robust to message latency, making it suitable for CA-DCOPs. Our\nresults indicate that LAMDLS-2 converges faster than MGM-2, a benchmark\nalgorithm, to a similar 2-opt solution, in various message latency scenarios.",
    "categories": [
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08737v1",
    "published_date": "2025-02-21 20:00:05 UTC",
    "updated_date": "2025-02-21 20:00:05 UTC"
  },
  {
    "arxiv_id": "2502.15907v1",
    "title": "Graph Attention Convolutional U-NET: A Semantic Segmentation Model for Identifying Flooded Areas",
    "authors": [
      "Muhammad Umair Danish",
      "Madhushan Buwaneswaran",
      "Tehara Fonseka",
      "Katarina Grolinger"
    ],
    "abstract": "The increasing impact of human-induced climate change and unplanned urban\nconstructions has increased flooding incidents in recent years. Accurate\nidentification of flooded areas is crucial for effective disaster management\nand urban planning. While few works have utilized convolutional neural networks\nand transformer-based semantic segmentation techniques for identifying flooded\nareas from aerial footage, recent developments in graph neural networks have\ncreated improvement opportunities. This paper proposes an innovative approach,\nthe Graph Attention Convolutional U-NET (GAC-UNET) model, based on graph neural\nnetworks for automated identification of flooded areas. The model incorporates\na graph attention mechanism and Chebyshev layers into the U-Net architecture.\nFurthermore, this paper explores the applicability of transfer learning and\nmodel reprogramming to enhance the accuracy of flood area segmentation models.\nEmpirical results demonstrate that the proposed GAC-UNET model, outperforms\nother approaches with 91\\% mAP, 94\\% dice score, and 89\\% IoU, providing\nvaluable insights for informed decision-making and better planning of future\ninfrastructures in flood-prone areas.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15907v1",
    "published_date": "2025-02-21 19:50:13 UTC",
    "updated_date": "2025-02-21 19:50:13 UTC"
  },
  {
    "arxiv_id": "2502.17505v1",
    "title": "Inverse Surrogate Model of a Soft X-Ray Spectrometer using Domain Adaptation",
    "authors": [
      "Enrico Ahlers",
      "Peter Feuer-Forson",
      "Gregor Hartmann",
      "Rolf Mitzner",
      "Peter BaumgÃ¤rtel",
      "Jens Viefhaus"
    ],
    "abstract": "In this study, we present a method to create a robust inverse surrogate model\nfor a soft X-ray spectrometer. During a beamtime at an electron storage ring,\nsuch as BESSY II, instrumentation and beamlines are required to be correctly\naligned and calibrated for optimal experimental conditions. In order to\nautomate these processes, machine learning methods can be developed and\nimplemented, but in many cases these methods require the use of an inverse\nmodel which maps the output of the experiment, such as a detector image, to the\nparameters of the device. Due to limited experimental data, such models are\noften trained with simulated data, which creates the challenge of compensating\nfor the inherent differences between simulation and experiment. In order to\nclose this gap, we demonstrate the application of data augmentation and\nadversarial domain adaptation techniques, with which we can predict absolute\ncoordinates for the automated alignment of our spectrometer. Bridging the\nsimulation-experiment gap with minimal real-world data opens new avenues for\nautomated experimentation using machine learning in scientific instrumentation.",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "physics.data-an"
    ],
    "primary_category": "physics.ins-det",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17505v1",
    "published_date": "2025-02-21 19:42:50 UTC",
    "updated_date": "2025-02-21 19:42:50 UTC"
  },
  {
    "arxiv_id": "2502.15902v1",
    "title": "IPAD: Inverse Prompt for AI Detection -- A Robust and Explainable LLM-Generated Text Detector",
    "authors": [
      "Zheng Chen",
      "Yushi Feng",
      "Changyang He",
      "Yue Deng",
      "Hongxi Pu",
      "Bo Li"
    ],
    "abstract": "Large Language Models (LLMs) have attained human-level fluency in text\ngeneration, which complicates the distinguishing between human-written and\nLLM-generated texts. This increases the risk of misuse and highlights the need\nfor reliable detectors. Yet, existing detectors exhibit poor robustness on\nout-of-distribution (OOD) data and attacked data, which is critical for\nreal-world scenarios. Also, they struggle to provide explainable evidence to\nsupport their decisions, thus undermining the reliability. In light of these\nchallenges, we propose IPAD (Inverse Prompt for AI Detection), a novel\nframework consisting of a Prompt Inverter that identifies predicted prompts\nthat could have generated the input text, and a Distinguisher that examines how\nwell the input texts align with the predicted prompts. We develop and examine\ntwo versions of Distinguishers. Empirical evaluations demonstrate that both\nDistinguishers perform significantly better than the baseline methods, with\nversion2 outperforming baselines by 9.73% on in-distribution data (F1-score)\nand 12.65% on OOD data (AUROC). Furthermore, a user study is conducted to\nillustrate that IPAD enhances the AI detection trustworthiness by allowing\nusers to directly examine the decision-making evidence, which provides\ninterpretable support for its state-of-the-art detection results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15902v1",
    "published_date": "2025-02-21 19:41:32 UTC",
    "updated_date": "2025-02-21 19:41:32 UTC"
  },
  {
    "arxiv_id": "2502.15898v1",
    "title": "ML-Driven Approaches to Combat Medicare Fraud: Advances in Class Imbalance Solutions, Feature Engineering, Adaptive Learning, and Business Impact",
    "authors": [
      "Dorsa Farahmandazad",
      "Kasra Danesh"
    ],
    "abstract": "Medicare fraud poses a substantial challenge to healthcare systems, resulting\nin significant financial losses and undermining the quality of care provided to\nlegitimate beneficiaries. This study investigates the use of machine learning\n(ML) to enhance Medicare fraud detection, addressing key challenges such as\nclass imbalance, high-dimensional data, and evolving fraud patterns. A dataset\ncomprising inpatient claims, outpatient claims, and beneficiary details was\nused to train and evaluate five ML models: Random Forest, KNN, LDA, Decision\nTree, and AdaBoost. Data preprocessing techniques included resampling SMOTE\nmethod to address the class imbalance, feature selection for dimensionality\nreduction, and aggregation of diagnostic and procedural codes. Random Forest\nemerged as the best-performing model, achieving a training accuracy of 99.2%\nand validation accuracy of 98.8%, and F1-score (98.4%). The Decision Tree also\nperformed well, achieving a validation accuracy of 96.3%. KNN and AdaBoost\ndemonstrated moderate performance, with validation accuracies of 79.2% and\n81.1%, respectively, while LDA struggled with a validation accuracy of 63.3%\nand a low recall of 16.6%. The results highlight the importance of advanced\nresampling techniques, feature engineering, and adaptive learning in detecting\nMedicare fraud effectively. This study underscores the potential of machine\nlearning in addressing the complexities of fraud detection. Future work should\nexplore explainable AI and hybrid models to improve interpretability and\nperformance, ensuring scalable and reliable fraud detection systems that\nprotect healthcare resources and beneficiaries.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15898v1",
    "published_date": "2025-02-21 19:34:12 UTC",
    "updated_date": "2025-02-21 19:34:12 UTC"
  },
  {
    "arxiv_id": "2502.15895v1",
    "title": "Directional Gradient Projection for Robust Fine-Tuning of Foundation Models",
    "authors": [
      "Chengyue Huang",
      "Junjiao Tian",
      "Brisa Maneechotesuwan",
      "Shivang Chopra",
      "Zsolt Kira"
    ],
    "abstract": "Robust fine-tuning aims to adapt large foundation models to downstream tasks\nwhile preserving their robustness to distribution shifts. Existing methods\nprimarily focus on constraining and projecting current model towards the\npre-trained initialization based on the magnitudes between fine-tuned and\npre-trained weights, which often require extensive hyper-parameter tuning and\ncan sometimes result in underfitting. In this work, we propose Directional\nGradient Projection (DiGraP), a novel layer-wise trainable method that\nincorporates directional information from gradients to bridge regularization\nand multi-objective optimization. Besides demonstrating our method on image\nclassification, as another contribution we generalize this area to the\nmulti-modal evaluation settings for robust fine-tuning. Specifically, we first\nbridge the uni-modal and multi-modal gap by performing analysis on Image\nClassification reformulated Visual Question Answering (VQA) benchmarks and\nfurther categorize ten out-of-distribution (OOD) VQA datasets by distribution\nshift types and degree (i.e. near versus far OOD). Experimental results show\nthat DiGraP consistently outperforms existing baselines across Image\nClassfication and VQA tasks with discriminative and generative backbones,\nimproving both in-distribution (ID) generalization and OOD robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15895v1",
    "published_date": "2025-02-21 19:31:55 UTC",
    "updated_date": "2025-02-21 19:31:55 UTC"
  },
  {
    "arxiv_id": "2502.17504v2",
    "title": "Protein Large Language Models: A Comprehensive Survey",
    "authors": [
      "Yijia Xiao",
      "Wanjia Zhao",
      "Junkai Zhang",
      "Yiqiao Jin",
      "Han Zhang",
      "Zhicheng Ren",
      "Renliang Sun",
      "Haixin Wang",
      "Guancheng Wan",
      "Pan Lu",
      "Xiao Luo",
      "Yu Zhang",
      "James Zou",
      "Yizhou Sun",
      "Wei Wang"
    ],
    "abstract": "Protein-specific large language models (Protein LLMs) are revolutionizing\nprotein science by enabling more efficient protein structure prediction,\nfunction annotation, and design. While existing surveys focus on specific\naspects or applications, this work provides the first comprehensive overview of\nProtein LLMs, covering their architectures, training datasets, evaluation\nmetrics, and diverse applications. Through a systematic analysis of over 100\narticles, we propose a structured taxonomy of state-of-the-art Protein LLMs,\nanalyze how they leverage large-scale protein sequence data for improved\naccuracy, and explore their potential in advancing protein engineering and\nbiomedical research. Additionally, we discuss key challenges and future\ndirections, positioning Protein LLMs as essential tools for scientific\ndiscovery in protein science. Resources are maintained at\nhttps://github.com/Yijia-Xiao/Protein-LLM-Survey.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "24 pages, 4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.17504v2",
    "published_date": "2025-02-21 19:22:10 UTC",
    "updated_date": "2025-03-06 16:14:45 UTC"
  },
  {
    "arxiv_id": "2502.15873v1",
    "title": "Practical Principles for AI Cost and Compute Accounting",
    "authors": [
      "Stephen Casper",
      "Luke Bailey",
      "Tim Schreier"
    ],
    "abstract": "Policymakers are increasingly using development cost and compute as proxies\nfor AI model capabilities and risks. Recent laws have introduced regulatory\nrequirements that are contingent on specific thresholds. However, technical\nambiguities in how to perform this accounting could create loopholes that\nundermine regulatory effectiveness. This paper proposes seven principles for\ndesigning practical AI cost and compute accounting standards that (1) reduce\nopportunities for strategic gaming, (2) avoid disincentivizing responsible risk\nmitigation, and (3) enable consistent implementation across companies and\njurisdictions.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15873v1",
    "published_date": "2025-02-21 18:59:47 UTC",
    "updated_date": "2025-02-21 18:59:47 UTC"
  },
  {
    "arxiv_id": "2502.15681v2",
    "title": "One-step Diffusion Models with $f$-Divergence Distribution Matching",
    "authors": [
      "Yilun Xu",
      "Weili Nie",
      "Arash Vahdat"
    ],
    "abstract": "Sampling from diffusion models involves a slow iterative process that hinders\ntheir practical deployment, especially for interactive applications. To\naccelerate generation speed, recent approaches distill a multi-step diffusion\nmodel into a single-step student generator via variational score distillation,\nwhich matches the distribution of samples generated by the student to the\nteacher's distribution. However, these approaches use the reverse\nKullback-Leibler (KL) divergence for distribution matching which is known to be\nmode seeking. In this paper, we generalize the distribution matching approach\nusing a novel $f$-divergence minimization framework, termed $f$-distill, that\ncovers different divergences with different trade-offs in terms of mode\ncoverage and training variance. We derive the gradient of the $f$-divergence\nbetween the teacher and student distributions and show that it is expressed as\nthe product of their score differences and a weighting function determined by\ntheir density ratio. This weighting function naturally emphasizes samples with\nhigher density in the teacher distribution, when using a less mode-seeking\ndivergence. We observe that the popular variational score distillation approach\nusing the reverse-KL divergence is a special case within our framework.\nEmpirically, we demonstrate that alternative $f$-divergences, such as\nforward-KL and Jensen-Shannon divergences, outperform the current best\nvariational score distillation methods across image generation tasks. In\nparticular, when using Jensen-Shannon divergence, $f$-distill achieves current\nstate-of-the-art one-step generation performance on ImageNet64 and zero-shot\ntext-to-image generation on MS-COCO. Project page:\nhttps://research.nvidia.com/labs/genair/f-distill",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15681v2",
    "published_date": "2025-02-21 18:59:20 UTC",
    "updated_date": "2025-03-09 22:53:27 UTC"
  },
  {
    "arxiv_id": "2502.15679v1",
    "title": "BOSS: Benchmark for Observation Space Shift in Long-Horizon Task",
    "authors": [
      "Yue Yang",
      "Linfeng Zhao",
      "Mingyu Ding",
      "Gedas Bertasius",
      "Daniel Szafir"
    ],
    "abstract": "Robotics has long sought to develop visual-servoing robots capable of\ncompleting previously unseen long-horizon tasks. Hierarchical approaches offer\na pathway for achieving this goal by executing skill combinations arranged by a\ntask planner, with each visuomotor skill pre-trained using a specific imitation\nlearning (IL) algorithm. However, even in simple long-horizon tasks like skill\nchaining, hierarchical approaches often struggle due to a problem we identify\nas Observation Space Shift (OSS), where the sequential execution of preceding\nskills causes shifts in the observation space, disrupting the performance of\nsubsequent individually trained skill policies. To validate OSS and evaluate\nits impact on long-horizon tasks, we introduce BOSS (a Benchmark for\nObservation Space Shift). BOSS comprises three distinct challenges: \"Single\nPredicate Shift\", \"Accumulated Predicate Shift\", and \"Skill Chaining\", each\ndesigned to assess a different aspect of OSS's negative effect. We evaluated\nseveral recent popular IL algorithms on BOSS, including three Behavioral\nCloning methods and the Visual Language Action model OpenVLA. Even on the\nsimplest challenge, we observed average performance drops of 67%, 35%, 34%, and\n54%, respectively, when comparing skill performance with and without OSS.\nAdditionally, we investigate a potential solution to OSS that scales up the\ntraining data for each skill with a larger and more visually diverse set of\ndemonstrations, with our results showing it is not sufficient to resolve OSS.\nThe project page is: https://boss-benchmark.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15679v1",
    "published_date": "2025-02-21 18:58:57 UTC",
    "updated_date": "2025-02-21 18:58:57 UTC"
  },
  {
    "arxiv_id": "2502.15872v1",
    "title": "MutaGReP: Execution-Free Repository-Grounded Plan Search for Code-Use",
    "authors": [
      "Zaid Khan",
      "Ali Farhadi",
      "Ranjay Krishna",
      "Luca Weihs",
      "Mohit Bansal",
      "Tanmay Gupta"
    ],
    "abstract": "When a human requests an LLM to complete a coding task using functionality\nfrom a large code repository, how do we provide context from the repo to the\nLLM? One approach is to add the entire repo to the LLM's context window.\nHowever, most tasks involve only fraction of symbols from a repo, longer\ncontexts are detrimental to the LLM's reasoning abilities, and context windows\nare not unlimited. Alternatively, we could emulate the human ability to\nnavigate a large repo, pick out the right functionality, and form a plan to\nsolve the task. We propose MutaGReP (Mutation-guided Grounded Repository Plan\nSearch), an approach to search for plans that decompose a user request into\nnatural language steps grounded in the codebase. MutaGReP performs neural tree\nsearch in plan space, exploring by mutating plans and using a symbol retriever\nfor grounding. On the challenging LongCodeArena benchmark, our plans use less\nthan 5% of the 128K context window for GPT-4o but rival the coding performance\nof GPT-4o with a context window filled with the repo. Plans produced by\nMutaGReP allow Qwen 2.5 Coder 32B and 72B to match the performance of GPT-4o\nwith full repo context and enable progress on the hardest LongCodeArena tasks.\nProject page: zaidkhan.me/MutaGReP",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Project page: zaidkhan.me/MutaGReP",
    "pdf_url": "http://arxiv.org/pdf/2502.15872v1",
    "published_date": "2025-02-21 18:58:17 UTC",
    "updated_date": "2025-02-21 18:58:17 UTC"
  },
  {
    "arxiv_id": "2502.15677v1",
    "title": "FLEKE: Federated Locate-then-Edit Knowledge Editing",
    "authors": [
      "Zongkai Zhao",
      "Guozeng Xu",
      "Xiuhua Li",
      "Kaiwen Wei",
      "Jiang Zhong"
    ],
    "abstract": "Locate-then-Edit Knowledge Editing (LEKE) is a key technique for updating\nlarge language models (LLMs) without full retraining. However, existing methods\nassume a single-user setting and become inefficient in real-world multi-client\nscenarios, where decentralized organizations (e.g., hospitals, financial\ninstitutions) independently update overlapping knowledge, leading to redundant\nmediator knowledge vector (MKV) computations and privacy concerns. To address\nthese challenges, we introduce Federated Locate-then-Edit Knowledge Editing\n(FLEKE), a novel task that enables multiple clients to collaboratively perform\nLEKE while preserving privacy and reducing computational overhead. To achieve\nthis, we propose FedEdit, a two-stage framework that optimizes MKV selection\nand reuse. In the first stage, clients locally apply LEKE and upload the\ncomputed MKVs. In the second stage, rather than relying solely on server-based\nMKV sharing, FLEKE allows clients retrieve relevant MKVs based on cosine\nsimilarity, enabling knowledge re-edit and minimizing redundant computations.\nExperimental results on two benchmark datasets demonstrate that FedEdit retains\nover 96% of the performance of non-federated LEKE while significantly\noutperforming a FedAvg-based baseline by approximately twofold. Besides, we\nfind that MEMIT performs more consistently than PMET in the FLEKE task with our\nFedEdit framework. Our code is available at https://github.com/zongkaiz/FLEKE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15677v1",
    "published_date": "2025-02-21 18:58:06 UTC",
    "updated_date": "2025-02-21 18:58:06 UTC"
  },
  {
    "arxiv_id": "2502.15676v1",
    "title": "AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind",
    "authors": [
      "Zhining Zhang",
      "Chuanyang Jin",
      "Mung Yao Jia",
      "Tianmin Shu"
    ],
    "abstract": "Theory of Mind (ToM), the ability to understand people's mental variables\nbased on their behavior, is key to developing socially intelligent agents.\nCurrent approaches to Theory of Mind reasoning either rely on prompting Large\nLanguage Models (LLMs), which are prone to systematic errors, or use rigid,\nhandcrafted Bayesian Theory of Mind (BToM) models, which are more robust but\ncannot generalize across different domains. In this work, we introduce AutoToM,\nan automated Bayesian Theory of Mind method for achieving open-ended machine\nTheory of Mind. AutoToM can operate in any domain, infer any mental variable,\nand conduct robust Theory of Mind reasoning of any order. Given a Theory of\nMind inference problem, AutoToM first proposes an initial BToM model. It then\nconducts automated Bayesian inverse planning based on the proposed model,\nleveraging an LLM as the backend. Based on the uncertainty of the inference, it\niteratively refines the model, by introducing additional mental variables\nand/or incorporating more timesteps in the context. Empirical evaluations\nacross multiple Theory of Mind benchmarks demonstrate that AutoToM consistently\nachieves state-of-the-art performance, offering a scalable, robust, and\ninterpretable approach to machine Theory of Mind.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 6 figures, 11 tables. Website at\n  https://chuanyangjin.com/AutoToM/",
    "pdf_url": "http://arxiv.org/pdf/2502.15676v1",
    "published_date": "2025-02-21 18:57:52 UTC",
    "updated_date": "2025-02-21 18:57:52 UTC"
  },
  {
    "arxiv_id": "2502.15672v1",
    "title": "VaViM and VaVAM: Autonomous Driving through Video Generative Modeling",
    "authors": [
      "Florent Bartoccioni",
      "Elias Ramzi",
      "Victor Besnier",
      "Shashanka Venkataramanan",
      "Tuan-Hung Vu",
      "Yihong Xu",
      "Loick Chambon",
      "Spyros Gidaris",
      "Serkan Odabas",
      "David Hurych",
      "Renaud Marlet",
      "Alexandre Boulch",
      "Mickael Chen",
      "Ãloi Zablocki",
      "Andrei Bursuc",
      "Eduardo Valle",
      "Matthieu Cord"
    ],
    "abstract": "We explore the potential of large-scale generative video models for\nautonomous driving, introducing an open-source auto-regressive video model\n(VaViM) and its companion video-action model (VaVAM) to investigate how video\npre-training transfers to real-world driving. VaViM is a simple auto-regressive\nvideo model that predicts frames using spatio-temporal token sequences. We show\nthat it captures the semantics and dynamics of driving scenes. VaVAM, the\nvideo-action model, leverages the learned representations of VaViM to generate\ndriving trajectories through imitation learning. Together, the models form a\ncomplete perception-to-action pipeline. We evaluate our models in open- and\nclosed-loop driving scenarios, revealing that video-based pre-training holds\npromise for autonomous driving. Key insights include the semantic richness of\nthe learned representations, the benefits of scaling for video synthesis, and\nthe complex relationship between model size, data, and safety metrics in\nclosed-loop evaluations. We release code and model weights at\nhttps://github.com/valeoai/VideoActionModel",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and model: https://github.com/valeoai/VideoActionModel, project\n  page: https://valeoai.github.io/vavim-vavam/",
    "pdf_url": "http://arxiv.org/pdf/2502.15672v1",
    "published_date": "2025-02-21 18:56:02 UTC",
    "updated_date": "2025-02-21 18:56:02 UTC"
  },
  {
    "arxiv_id": "2502.15666v2",
    "title": "Almost AI, Almost Human: The Challenge of Detecting AI-Polished Writing",
    "authors": [
      "Shoumik Saha",
      "Soheil Feizi"
    ],
    "abstract": "The growing use of large language models (LLMs) for text generation has led\nto widespread concerns about AI-generated content detection. However, an\noverlooked challenge is AI-polished text, where human-written content undergoes\nsubtle refinements using AI tools. This raises a critical question: should\nminimally polished text be classified as AI-generated? Such classification can\nlead to false plagiarism accusations and misleading claims about AI prevalence\nin online content. In this study, we systematically evaluate twelve\nstate-of-the-art AI-text detectors using our AI-Polished-Text Evaluation\n(APT-Eval) dataset, which contains 14.7K samples refined at varying\nAI-involvement levels. Our findings reveal that detectors frequently flag even\nminimally polished text as AI-generated, struggle to differentiate between\ndegrees of AI involvement, and exhibit biases against older and smaller models.\nThese limitations highlight the urgent need for more nuanced detection\nmethodologies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 18 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15666v2",
    "published_date": "2025-02-21 18:45:37 UTC",
    "updated_date": "2025-05-05 03:57:24 UTC"
  },
  {
    "arxiv_id": "2502.15871v1",
    "title": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare",
    "authors": [
      "Manar Aljohani",
      "Jun Hou",
      "Sindhura Kommu",
      "Xuan Wang"
    ],
    "abstract": "The application of large language models (LLMs) in healthcare has the\npotential to revolutionize clinical decision-making, medical research, and\npatient care. As LLMs are increasingly integrated into healthcare systems,\nseveral critical challenges must be addressed to ensure their reliable and\nethical deployment. These challenges include truthfulness, where models\ngenerate misleading information; privacy, with risks of unintentional data\nretention; robustness, requiring defenses against adversarial attacks;\nfairness, addressing biases in clinical outcomes; explainability, ensuring\ntransparent decision-making; and safety, mitigating risks of misinformation and\nmedical errors. Recently, researchers have begun developing benchmarks and\nevaluation frameworks to systematically assess the trustworthiness of LLMs.\nHowever, the trustworthiness of LLMs in healthcare remains underexplored,\nlacking a systematic review that provides a comprehensive understanding and\nfuture insights into this area. This survey bridges this gap by providing a\ncomprehensive overview of the recent research of existing methodologies and\nsolutions aimed at mitigating the above risks in healthcare. By focusing on key\ntrustworthiness dimensions including truthfulness, privacy and safety,\nrobustness, fairness and bias, and explainability, we present a thorough\nanalysis of how these issues impact the reliability and ethical use of LLMs in\nhealthcare. This paper highlights ongoing efforts and offers insights into\nfuture research directions to ensure the safe and trustworthy deployment of\nLLMs in healthcare.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15871v1",
    "published_date": "2025-02-21 18:43:06 UTC",
    "updated_date": "2025-02-21 18:43:06 UTC"
  },
  {
    "arxiv_id": "2502.15663v1",
    "title": "Multi-Agent Architecture in Distributed Environment Control Systems: vision, challenges, and opportunities",
    "authors": [
      "Natasha Astudillo",
      "Fernando Koch"
    ],
    "abstract": "The increasing demand for energy-efficient solutions in large-scale\ninfrastructure, particularly data centers, requires advanced control strategies\nto optimize environmental management systems. We propose a multi-agent\narchitecture for distributed control of air-cooled chiller systems in data\ncenters. Our vision employs autonomous agents to monitor and regulate local\noperational parameters and optimize system-wide efficiency. We demonstrate how\nthis approach improves the responsiveness, operational robustness, and energy\nefficiency of the system, contributing to the broader goal of sustainable\ninfrastructure management.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "6 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2502.15663v1",
    "published_date": "2025-02-21 18:41:03 UTC",
    "updated_date": "2025-02-21 18:41:03 UTC"
  },
  {
    "arxiv_id": "2502.15662v1",
    "title": "Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network",
    "authors": [
      "Vincent Hsiao",
      "Mark Roberts",
      "Laura M. Hiatt",
      "George Konidaris",
      "Dana Nau"
    ],
    "abstract": "A major challenge for reinforcement learning is automatically generating\ncurricula to reduce training time or improve performance in some target task.\nWe introduce SEBNs (Skill-Environment Bayesian Networks) which model a\nprobabilistic relationship between a set of skills, a set of goals that relate\nto the reward structure, and a set of environment features to predict policy\nperformance on (possibly unseen) tasks. We develop an algorithm that uses the\ninferred estimates of agent success from SEBN to weigh the possible next tasks\nby expected improvement. We evaluate the benefit of the resulting curriculum on\nthree environments: a discrete gridworld, continuous control, and simulated\nrobotics. The results show that curricula constructed using SEBN frequently\noutperform other baselines.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15662v1",
    "published_date": "2025-02-21 18:38:00 UTC",
    "updated_date": "2025-02-21 18:38:00 UTC"
  },
  {
    "arxiv_id": "2502.15870v1",
    "title": "Making Sense of AI Limitations: How Individual Perceptions Shape Organizational Readiness for AI Adoption",
    "authors": [
      "Thomas Ãbellacker"
    ],
    "abstract": "This study investigates how individuals' perceptions of artificial\nintelligence (AI) limitations influence organizational readiness for AI\nadoption. Through semi-structured interviews with seven AI implementation\nexperts, analyzed using the Gioia methodology, the research reveals that\norganizational readiness emerges through dynamic interactions between\nindividual sensemaking, social learning, and formal integration processes. The\nfindings demonstrate that hands-on experience with AI limitations leads to more\nrealistic expectations and increased trust, mainly when supported by peer\nnetworks and champion systems. Organizations that successfully translate these\nindividual and collective insights into formal governance structures achieve\nmore sustainable AI adoption. The study advances theory by showing how\norganizational readiness for AI adoption evolves through continuous cycles of\nindividual understanding, social learning, and organizational adaptation. These\ninsights suggest that organizations should approach AI adoption not as a\none-time implementation but as an ongoing strategic learning process that\nbalances innovation with practical constraints. The research contributes to\norganizational readiness theory and practice by illuminating how micro-level\nperceptions and experiences shape macro-level adoption outcomes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15870v1",
    "published_date": "2025-02-21 18:31:08 UTC",
    "updated_date": "2025-02-21 18:31:08 UTC"
  },
  {
    "arxiv_id": "2502.15657v2",
    "title": "Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?",
    "authors": [
      "Yoshua Bengio",
      "Michael Cohen",
      "Damiano Fornasiere",
      "Joumana Ghosn",
      "Pietro Greiner",
      "Matt MacDermott",
      "SÃ¶ren Mindermann",
      "Adam Oberman",
      "Jesse Richardson",
      "Oliver Richardson",
      "Marc-Antoine Rondeau",
      "Pierre-Luc St-Charles",
      "David Williams-King"
    ],
    "abstract": "The leading AI companies are increasingly focused on building generalist AI\nagents -- systems that can autonomously plan, act, and pursue goals across\nalmost all tasks that humans can perform. Despite how useful these systems\nmight be, unchecked AI agency poses significant risks to public safety and\nsecurity, ranging from misuse by malicious actors to a potentially irreversible\nloss of human control. We discuss how these risks arise from current AI\ntraining methods. Indeed, various scenarios and experiments have demonstrated\nthe possibility of AI agents engaging in deception or pursuing goals that were\nnot specified by human operators and that conflict with human interests, such\nas self-preservation. Following the precautionary principle, we see a strong\nneed for safer, yet still useful, alternatives to the current agency-driven\ntrajectory. Accordingly, we propose as a core building block for further\nadvances the development of a non-agentic AI system that is trustworthy and\nsafe by design, which we call Scientist AI. This system is designed to explain\nthe world from observations, as opposed to taking actions in it to imitate or\nplease humans. It comprises a world model that generates theories to explain\ndata and a question-answering inference machine. Both components operate with\nan explicit notion of uncertainty to mitigate the risks of overconfident\npredictions. In light of these considerations, a Scientist AI could be used to\nassist human researchers in accelerating scientific progress, including in AI\nsafety. In particular, our system can be employed as a guardrail against AI\nagents that might be created despite the risks involved. Ultimately, focusing\non non-agentic AI may enable the benefits of AI innovation while avoiding the\nrisks associated with the current trajectory. We hope these arguments will\nmotivate researchers, developers, and policymakers to favor this safer path.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "v2 with fixed formatting for URLs and hyperlinks",
    "pdf_url": "http://arxiv.org/pdf/2502.15657v2",
    "published_date": "2025-02-21 18:28:36 UTC",
    "updated_date": "2025-02-24 18:14:15 UTC"
  },
  {
    "arxiv_id": "2502.15652v2",
    "title": "Empowering LLMs with Logical Reasoning: A Comprehensive Survey",
    "authors": [
      "Fengxiang Cheng",
      "Haoxuan Li",
      "Fenrong Liu",
      "Robert van Rooij",
      "Kun Zhang",
      "Zhouchen Lin"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable successes on various\nnatural language tasks. However, recent studies have found that there are still\nsignificant challenges to the logical reasoning abilities of LLMs. This paper\nsummarizes and categorizes the main challenges into two aspects: (1) Logical\nquestion answering, LLMs often fail to generate the correct answer within\ncomplex logical problem which requires sophisticated deductive, inductive or\nabductive reasoning given a collection of premises and constrains. (2) Logical\nconsistency, LLMs are prone to producing responses contradicting themselves\nacross different questions. For example, a state-of-the-art Macaw\nquestion-answering LLM answers Yes to both questions Is a magpie a bird? and\nDoes a bird have wings? but answers No to Does a magpie have wings?. To\nfacilitate this research direction, we comprehensively investigate the most\ncutting-edge methods and propose detailed taxonomies of these methods.\nSpecifically, to accurately answer complex logic questions, previous methods\ncan be categorized based on reliance on external solvers, prompts, pretraining,\nand fine-tuning. To avoid logical contradictions, we discuss concepts and\nsolutions of various logical consistencies, including implication, negation,\ntransitivity, factuality consistency, and their composites. In addition, we\nreview commonly used benchmark datasets and evaluation metrics, and discuss\npromising research directions, such as extensions to modal logic to account for\nuncertainty, and efficient algorithms satisfying multiple logical consistencies\nsimultaneously.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15652v2",
    "published_date": "2025-02-21 18:20:35 UTC",
    "updated_date": "2025-02-24 19:01:38 UTC"
  },
  {
    "arxiv_id": "2502.15643v1",
    "title": "AutoTandemML: Active Learning Enhanced Tandem Neural Networks for Inverse Design Problems",
    "authors": [
      "Luka Grbcic",
      "Juliane MÃ¼ller",
      "Wibe Albert de Jong"
    ],
    "abstract": "Inverse design in science and engineering involves determining optimal design\nparameters that achieve desired performance outcomes, a process often hindered\nby the complexity and high dimensionality of design spaces, leading to\nsignificant computational costs. To tackle this challenge, we propose a novel\nhybrid approach that combines active learning with Tandem Neural Networks to\nenhance the efficiency and effectiveness of solving inverse design problems.\nActive learning allows to selectively sample the most informative data points,\nreducing the required dataset size without compromising accuracy. We\ninvestigate this approach using three benchmark problems: airfoil inverse\ndesign, photonic surface inverse design, and scalar boundary condition\nreconstruction in diffusion partial differential equations. We demonstrate that\nintegrating active learning with Tandem Neural Networks outperforms standard\napproaches across the benchmark suite, achieving better accuracy with fewer\ntraining samples.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15643v1",
    "published_date": "2025-02-21 18:10:56 UTC",
    "updated_date": "2025-02-21 18:10:56 UTC"
  },
  {
    "arxiv_id": "2502.15639v1",
    "title": "Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models",
    "authors": [
      "Anirudh Sundar",
      "Sinead Williamson",
      "Katherine Metcalf",
      "Barry-John Theobald",
      "Skyler Seto",
      "Masha Fedzechkina"
    ],
    "abstract": "Aligned representations across languages is a desired property in\nmultilingual large language models (mLLMs), as alignment can improve\nperformance in cross-lingual tasks. Typically alignment requires fine-tuning a\nmodel, which is computationally expensive, and sizable language data, which\noften may not be available. A data-efficient alternative to fine-tuning is\nmodel interventions -- a method for manipulating model activations to steer\ngeneration into the desired direction. We analyze the effect of a popular\nintervention (finding experts) on the alignment of cross-lingual\nrepresentations in mLLMs. We identify the neurons to manipulate for a given\nlanguage and introspect the embedding space of mLLMs pre- and\npost-manipulation. We show that modifying the mLLM's activations changes its\nembedding space such that cross-lingual alignment is enhanced. Further, we show\nthat the changes to the embedding space translate into improved downstream\nperformance on retrieval tasks, with up to 2x improvements in top-1 accuracy on\ncross-lingual retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "34 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15639v1",
    "published_date": "2025-02-21 18:09:54 UTC",
    "updated_date": "2025-02-21 18:09:54 UTC"
  },
  {
    "arxiv_id": "2502.15637v1",
    "title": "Mantis: Lightweight Calibrated Foundation Model for User-Friendly Time Series Classification",
    "authors": [
      "Vasilii Feofanov",
      "Songkang Wen",
      "Marius Alonso",
      "Romain Ilbert",
      "Hongbo Guo",
      "Malik Tiomoko",
      "Lujia Pan",
      "Jianfeng Zhang",
      "Ievgen Redko"
    ],
    "abstract": "In recent years, there has been increasing interest in developing foundation\nmodels for time series data that can generalize across diverse downstream\ntasks. While numerous forecasting-oriented foundation models have been\nintroduced, there is a notable scarcity of models tailored for time series\nclassification. To address this gap, we present Mantis, a new open-source\nfoundation model for time series classification based on the Vision Transformer\n(ViT) architecture that has been pre-trained using a contrastive learning\napproach. Our experimental results show that Mantis outperforms existing\nfoundation models both when the backbone is frozen and when fine-tuned, while\nachieving the lowest calibration error. In addition, we propose several\nadapters to handle the multivariate setting, reducing memory requirements and\nmodeling channel interdependence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15637v1",
    "published_date": "2025-02-21 18:06:09 UTC",
    "updated_date": "2025-02-21 18:06:09 UTC"
  },
  {
    "arxiv_id": "2502.15631v1",
    "title": "The Relationship Between Reasoning and Performance in Large Language Models -- o3 (mini) Thinks Harder, Not Longer",
    "authors": [
      "Marthe Ballon",
      "Andres Algaba",
      "Vincent Ginis"
    ],
    "abstract": "Large language models have demonstrated remarkable progress in mathematical\nreasoning, leveraging chain-of-thought and test-time compute scaling. However,\nmany open questions remain regarding the interplay between reasoning token\nusage and accuracy gains. In particular, when comparing models across\ngenerations, it is unclear whether improved performance results from longer\nreasoning chains or more efficient reasoning. We systematically analyze\nchain-of-thought length across o1-mini and o3-mini variants on the Omni-MATH\nbenchmark, finding that o3-mini (m) achieves superior accuracy without\nrequiring longer reasoning chains than o1-mini. Moreover, we show that accuracy\ngenerally declines as reasoning chains grow across all models and compute\nsettings, even when controlling for difficulty of the questions. This accuracy\ndrop is significantly smaller in more proficient models, suggesting that new\ngenerations of reasoning models use test-time compute more effectively.\nFinally, we highlight that while o3-mini (h) achieves a marginal accuracy gain\nover o3-mini (m), it does so by allocating substantially more reasoning tokens\nacross all problems, even the ones that o3-mini (m) can already solve. These\nfindings provide new insights into the relationship between model capability\nand reasoning length, with implications for efficiency, scaling, and evaluation\nmethodologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15631v1",
    "published_date": "2025-02-21 17:59:13 UTC",
    "updated_date": "2025-02-21 17:59:13 UTC"
  },
  {
    "arxiv_id": "2502.15623v1",
    "title": "Dynamic Knowledge Selector and Evaluator for recommendation with Knowledge Graph",
    "authors": [
      "Feng Xia",
      "Zhifei Hu"
    ],
    "abstract": "In recent years recommendation systems typically employ the edge information\nprovided by knowledge graphs combined with the advantages of high-order\nconnectivity of graph networks in the recommendation field. However, this\nmethod is limited by the sparsity of labels, cannot learn the graph structure\nwell, and a large number of noisy entities in the knowledge graph will affect\nthe accuracy of the recommendation results. In order to alleviate the above\nproblems, we propose a dynamic knowledge-selecting and evaluating method guided\nby collaborative signals to distill information in the knowledge graph.\nSpecifically, we use a Chain Route Evaluator to evaluate the contributions of\ndifferent neighborhoods for the recommendation task and employ a Knowledge\nSelector strategy to filter the less informative knowledge before evaluating.\nWe conduct baseline model comparison and experimental ablation evaluations on\nthree public datasets. The experiments demonstrate that our proposed model\noutperforms current state-of-the-art baseline models, and each modules\neffectiveness in our model is demonstrated through ablation experiments.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15623v1",
    "published_date": "2025-02-21 17:51:37 UTC",
    "updated_date": "2025-02-21 17:51:37 UTC"
  },
  {
    "arxiv_id": "2502.15620v1",
    "title": "Paradigms of AI Evaluation: Mapping Goals, Methodologies and Culture",
    "authors": [
      "John Burden",
      "Marko TeÅ¡iÄ",
      "Lorenzo Pacchiardi",
      "JosÃ© HernÃ¡ndez-Orallo"
    ],
    "abstract": "Research in AI evaluation has grown increasingly complex and\nmultidisciplinary, attracting researchers with diverse backgrounds and\nobjectives. As a result, divergent evaluation paradigms have emerged, often\ndeveloping in isolation, adopting conflicting terminologies, and overlooking\neach other's contributions. This fragmentation has led to insular research\ntrajectories and communication barriers both among different paradigms and with\nthe general public, contributing to unmet expectations for deployed AI systems.\nTo help bridge this insularity, in this paper we survey recent work in the AI\nevaluation landscape and identify six main paradigms. We characterise major\nrecent contributions within each paradigm across key dimensions related to\ntheir goals, methodologies and research cultures. By clarifying the unique\ncombination of questions and approaches associated with each paradigm, we aim\nto increase awareness of the breadth of current evaluation approaches and\nfoster cross-pollination between different paradigms. We also identify\npotential gaps in the field to inspire future research directions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15620v1",
    "published_date": "2025-02-21 17:44:05 UTC",
    "updated_date": "2025-02-21 17:44:05 UTC"
  },
  {
    "arxiv_id": "2502.15619v1",
    "title": "Extraction multi-Ã©tiquettes de relations en utilisant des couches de Transformer",
    "authors": [
      "Ngoc Luyen Le",
      "Gildas Tagny NgompÃ©"
    ],
    "abstract": "In this article, we present the BTransformer18 model, a deep learning\narchitecture designed for multi-label relation extraction in French texts. Our\napproach combines the contextual representation capabilities of pre-trained\nlanguage models from the BERT family - such as BERT, RoBERTa, and their French\ncounterparts CamemBERT and FlauBERT - with the power of Transformer encoders to\ncapture long-term dependencies between tokens. Experiments conducted on the\ndataset from the TextMine'25 challenge show that our model achieves superior\nperformance, particularly when using CamemBERT-Large, with a macro F1 score of\n0.654, surpassing the results obtained with FlauBERT-Large. These results\ndemonstrate the effectiveness of our approach for the automatic extraction of\ncomplex relations in intelligence reports.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "in French language",
    "pdf_url": "http://arxiv.org/pdf/2502.15619v1",
    "published_date": "2025-02-21 17:42:51 UTC",
    "updated_date": "2025-02-21 17:42:51 UTC"
  },
  {
    "arxiv_id": "2502.15618v1",
    "title": "Probe Pruning: Accelerating LLMs through Dynamic Pruning via Model-Probing",
    "authors": [
      "Qi Le",
      "Enmao Diao",
      "Ziyan Wang",
      "Xinran Wang",
      "Jie Ding",
      "Li Yang",
      "Ali Anwar"
    ],
    "abstract": "We introduce Probe Pruning (PP), a novel framework for online, dynamic,\nstructured pruning of Large Language Models (LLMs) applied in a batch-wise\nmanner. PP leverages the insight that not all samples and tokens contribute\nequally to the model's output, and probing a small portion of each batch\neffectively identifies crucial weights, enabling tailored dynamic pruning for\ndifferent batches. It comprises three main stages: probing, history-informed\npruning, and full inference. In the probing stage, PP selects a small yet\ncrucial set of hidden states, based on residual importance, to run a few model\nlayers ahead. During the history-informed pruning stage, PP strategically\nintegrates the probing states with historical states. Subsequently, it\nstructurally prunes weights based on the integrated states and the PP\nimportance score, a metric developed specifically to assess the importance of\neach weight channel in maintaining performance. In the final stage, full\ninference is conducted on the remaining weights. A major advantage of PP is its\ncompatibility with existing models, as it operates without requiring additional\nneural network modules or fine-tuning. Comprehensive evaluations of PP on\nLLaMA-2/3 and OPT models reveal that even minimal probing-using just 1.5% of\nFLOPs-can substantially enhance the efficiency of structured pruning of LLMs.\nFor instance, when evaluated on LLaMA-2-7B with WikiText2, PP achieves a 2.56\ntimes lower ratio of performance degradation per unit of runtime reduction\ncompared to the state-of-the-art method at a 40% pruning ratio. Our code is\navailable at https://github.com/Qi-Le1/Probe_Pruning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15618v1",
    "published_date": "2025-02-21 17:41:21 UTC",
    "updated_date": "2025-02-21 17:41:21 UTC"
  },
  {
    "arxiv_id": "2502.15616v1",
    "title": "Pastiche Novel Generation Creating: Fan Fiction You Love in Your Favorite Author's Style",
    "authors": [
      "Xueran Han",
      "Yuhan Liu",
      "Mingzhe Li",
      "Wei Liu",
      "Sen Hu",
      "Rui Yan",
      "Zhiqiang Xu",
      "Xiuying Chen"
    ],
    "abstract": "Great novels create immersive worlds with rich character arcs,\nwell-structured plots, and nuanced writing styles. However, current novel\ngeneration methods often rely on brief, simplistic story outlines and generate\ndetails using plain, generic language. To bridge this gap, we introduce the\ntask of Pastiche Novel Generation, which requires the generated novels to\nimitate the distinctive features of the original work, including understanding\ncharacter profiles, predicting plausible plot developments, and writing\nconcrete details using vivid, expressive language. To achieve this, we propose\nWriterAgent, a novel generation system designed to master the core aspects of\nliterary pastiche. WriterAgent is trained through a curriculum learning\nparadigm, progressing from low-level stylistic mastery to high-level narrative\ncoherence. Its key tasks include language style learning, character modeling,\nplot planning, and stylish writing, ensuring comprehensive narrative control.\nTo support this, WriterAgent leverages the WriterLoRA framework, an extension\nof LoRA with hierarchical and cumulative task-specific modules, each\nspecializing in a different narrative aspect. We evaluate WriterAgent on\nmultilingual classics like Harry Potter and Dream of the Red Chamber,\ndemonstrating its superiority over baselines in capturing the target author's\nsettings, character dynamics, and writing style to produce coherent, faithful\nnarratives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15616v1",
    "published_date": "2025-02-21 17:40:42 UTC",
    "updated_date": "2025-02-21 17:40:42 UTC"
  },
  {
    "arxiv_id": "2502.15610v2",
    "title": "A general language model for peptide identification",
    "authors": [
      "Jixiu Zhai",
      "Tianchi Lu",
      "Haitian Zhong",
      "Ziyang Xu",
      "Yuhuan Liu",
      "Shengrui Xu",
      "Jingwan Wang",
      "Dan Huang"
    ],
    "abstract": "Advances in peptide identification are revolutionizing our ability to\ndecipher protein functions and accelerate therapeutic discovery. We present\nPDeepPP, a deep learning framework that integrates pretrained protein language\nmodels with parallel transformer-CNN architectures, achieving state-of-the-art\nperformance in peptide characterization tasks. The model's hybrid architecture\ndemonstrates unique capabilities in capturing both local sequence motifs and\nglobal structural features, as evidenced by 29% improved cluster separation in\nUMAP visualizations compared to conventional approaches. Evaluated across 33\nbiological recognition tasks - including post-translational modification site\nprediction and bioactive peptide identification - PDeepPP outperformed existing\nmethods in 25 tasks with average AUC improvements of 4.2%. Notably, it achieved\n0.9726 accuracy with PR AUC 0.9977 in antimicrobial peptide detection while\nreducing false negatives by 37.5% in antimalarial recognition scenarios. This\nframework enables accurate large-scale peptide analysis, achieving 218*\nacceleration over sequence-alignment-based methods while maintaining 99.5%\nspecificity in critical glycosylation site detection.PDeepPP establishes a new\nparadigm for computational peptide analysis through its synergistic\narchitecture design, enabling rapid yet precise functional annotation that\nbridges molecular pattern recognition with translational biomedical\napplications.We have made our implementation, including code, data, and\npretrained models, publicly available via GitHub\n(https://github.com/fondress/PDeepPP) and Hugging Face\n(https://huggingface.co/fondress/PDeppPP).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "92C40, 68T07",
      "I.2.6; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 9 figures, 4 tables, submitted to arXiv",
    "pdf_url": "http://arxiv.org/pdf/2502.15610v2",
    "published_date": "2025-02-21 17:31:22 UTC",
    "updated_date": "2025-04-17 17:52:57 UTC"
  },
  {
    "arxiv_id": "2502.15609v1",
    "title": "On the Robustness of Transformers against Context Hijacking for Linear Classification",
    "authors": [
      "Tianle Li",
      "Chenyang Zhang",
      "Xingwu Chen",
      "Yuan Cao",
      "Difan Zou"
    ],
    "abstract": "Transformer-based Large Language Models (LLMs) have demonstrated powerful\nin-context learning capabilities. However, their predictions can be disrupted\nby factually correct context, a phenomenon known as context hijacking,\nrevealing a significant robustness issue. To understand this phenomenon\ntheoretically, we explore an in-context linear classification problem based on\nrecent advances in linear transformers. In our setup, context tokens are\ndesigned as factually correct query-answer pairs, where the queries are similar\nto the final query but have opposite labels. Then, we develop a general\ntheoretical analysis on the robustness of the linear transformers, which is\nformulated as a function of the model depth, training context lengths, and\nnumber of hijacking context tokens. A key finding is that a well-trained deeper\ntransformer can achieve higher robustness, which aligns with empirical\nobservations. We show that this improvement arises because deeper layers enable\nmore fine-grained optimization steps, effectively mitigating interference from\ncontext hijacking. This is also well supported by our numerical experiments.\nOur findings provide theoretical insights into the benefits of deeper\narchitectures and contribute to enhancing the understanding of transformer\narchitectures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15609v1",
    "published_date": "2025-02-21 17:31:00 UTC",
    "updated_date": "2025-02-21 17:31:00 UTC"
  },
  {
    "arxiv_id": "2502.15603v1",
    "title": "Do Multilingual LLMs Think In English?",
    "authors": [
      "Lisa Schut",
      "Yarin Gal",
      "Sebastian Farquhar"
    ],
    "abstract": "Large language models (LLMs) have multilingual capabilities and can solve\ntasks across various languages. However, we show that current LLMs make key\ndecisions in a representation space closest to English, regardless of their\ninput and output languages. Exploring the internal representations with a logit\nlens for sentences in French, German, Dutch, and Mandarin, we show that the LLM\nfirst emits representations close to English for semantically-loaded words\nbefore translating them into the target language. We further show that\nactivation steering in these LLMs is more effective when the steering vectors\nare computed in English rather than in the language of the inputs and outputs.\nThis suggests that multilingual LLMs perform key reasoning steps in a\nrepresentation that is heavily shaped by English in a way that is not\ntransparent to system users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Main paper 9 pages; including appendix 48 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15603v1",
    "published_date": "2025-02-21 17:19:23 UTC",
    "updated_date": "2025-02-21 17:19:23 UTC"
  },
  {
    "arxiv_id": "2502.15602v2",
    "title": "KAD: No More FAD! An Effective and Efficient Evaluation Metric for Audio Generation",
    "authors": [
      "Yoonjin Chung",
      "Pilsun Eu",
      "Junwon Lee",
      "Keunwoo Choi",
      "Juhan Nam",
      "Ben Sangbae Chon"
    ],
    "abstract": "Although being widely adopted for evaluating generated audio signals, the\nFr\\'echet Audio Distance (FAD) suffers from significant limitations, including\nreliance on Gaussian assumptions, sensitivity to sample size, and high\ncomputational complexity. As an alternative, we introduce the Kernel Audio\nDistance (KAD), a novel, distribution-free, unbiased, and computationally\nefficient metric based on Maximum Mean Discrepancy (MMD). Through analysis and\nempirical validation, we demonstrate KAD's advantages: (1) faster convergence\nwith smaller sample sizes, enabling reliable evaluation with limited data; (2)\nlower computational cost, with scalable GPU acceleration; and (3) stronger\nalignment with human perceptual judgments. By leveraging advanced embeddings\nand characteristic kernels, KAD captures nuanced differences between real and\ngenerated audio. Open-sourced in the kadtk toolkit, KAD provides an efficient,\nreliable, and perceptually aligned benchmark for evaluating generative audio\nmodels.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15602v2",
    "published_date": "2025-02-21 17:19:15 UTC",
    "updated_date": "2025-03-09 06:46:13 UTC"
  },
  {
    "arxiv_id": "2502.15601v2",
    "title": "WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents",
    "authors": [
      "Xinhang Liu",
      "Chi-Keung Tang",
      "Yu-Wing Tai"
    ],
    "abstract": "Constructing photorealistic virtual worlds has applications across various\nfields, but it often requires the extensive labor of highly trained\nprofessionals to operate conventional 3D modeling software. To democratize this\nprocess, we introduce WorldCraft, a system where large language model (LLM)\nagents leverage procedural generation to create indoor and outdoor scenes\npopulated with objects, allowing users to control individual object attributes\nand the scene layout using intuitive natural language commands. In our\nframework, a coordinator agent manages the overall process and works with two\nspecialized LLM agents to complete the scene creation: ForgeIt, which\nintegrates an ever-growing manual through auto-verification to enable precise\ncustomization of individual objects, and ArrangeIt, which formulates\nhierarchical optimization problems to achieve a layout that balances ergonomic\nand aesthetic considerations. Additionally, our pipeline incorporates a\ntrajectory control agent, allowing users to animate the scene and operate the\ncamera through natural language interactions. Our system is also compatible\nwith off-the-shelf deep 3D generators to enrich scene assets. Through\nevaluations and comparisons with state-of-the-art methods, we demonstrate the\nversatility of WorldCraft, ranging from single-object customization to\nintricate, large-scale interior and exterior scene designs. This system\nempowers non-professionals to bring their creative visions to life.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15601v2",
    "published_date": "2025-02-21 17:18:30 UTC",
    "updated_date": "2025-02-28 08:49:29 UTC"
  },
  {
    "arxiv_id": "2502.15592v1",
    "title": "Generalizing From Short to Long: Effective Data Synthesis for Long-Context Instruction Tuning",
    "authors": [
      "Wenhao Zhu",
      "Pinzhen Chen",
      "Hanxu Hu",
      "Shujian Huang",
      "Fei Yuan",
      "Jiajun Chen",
      "Alexandra Birch"
    ],
    "abstract": "Long-context modelling for large language models (LLMs) has been a key area\nof recent research because many real world use cases require reasoning over\nlonger inputs such as documents. The focus of research into modelling long\ncontext has been on how to model position and there has been little\ninvestigation into other important aspects of language modelling such as\ninstruction tuning. Long context training examples are challenging and\nexpensive to create and use. In this paper, we investigate how to design\ninstruction data for the post-training phase of a long context pre-trained\nmodel: how much and what type of context is needed for optimal and efficient\npost-training. Our controlled study reveals that models instruction-tuned on\nshort contexts can effectively generalize to longer ones, while also\nidentifying other critical factors such as instruction difficulty and context\ncomposition. Based on these findings, we propose context synthesis, a novel\ndata synthesis framework that leverages off-the-shelf LLMs to generate extended\nbackground contexts for high-quality instruction-answer pairs. Experiment\nresults on the document-level benchmark (LongBench) demonstrate that our\nproposed approach outperforms previous instruction synthesis approaches and\ncomes close to the performance of human-annotated long-context instruction\ndata. The project will be available at:\nhttps://github.com/NJUNLP/context-synthesis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15592v1",
    "published_date": "2025-02-21 17:02:40 UTC",
    "updated_date": "2025-02-21 17:02:40 UTC"
  },
  {
    "arxiv_id": "2502.15869v1",
    "title": "Generative AI Framework for 3D Object Generation in Augmented Reality",
    "authors": [
      "Majid Behravan"
    ],
    "abstract": "This thesis presents a framework that integrates state-of-the-art generative\nAI models for real-time creation of three-dimensional (3D) objects in augmented\nreality (AR) environments. The primary goal is to convert diverse inputs, such\nas images and speech, into accurate 3D models, enhancing user interaction and\nimmersion. Key components include advanced object detection algorithms,\nuser-friendly interaction techniques, and robust AI models like Shap-E for 3D\ngeneration. Leveraging Vision Language Models (VLMs) and Large Language Models\n(LLMs), the system captures spatial details from images and processes textual\ninformation to generate comprehensive 3D objects, seamlessly integrating\nvirtual objects into real-world environments. The framework demonstrates\napplications across industries such as gaming, education, retail, and interior\ndesign. It allows players to create personalized in-game assets, customers to\nsee products in their environments before purchase, and designers to convert\nreal-world objects into 3D models for real-time visualization. A significant\ncontribution is democratizing 3D model creation, making advanced AI tools\naccessible to a broader audience, fostering creativity and innovation. The\nframework addresses challenges like handling multilingual inputs, diverse\nvisual data, and complex environments, improving object detection and model\ngeneration accuracy, as well as loading 3D models in AR space in real-time. In\nconclusion, this thesis integrates generative AI and AR for efficient 3D model\ngeneration, enhancing accessibility and paving the way for innovative\napplications and improved user interactions in AR environments.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15869v1",
    "published_date": "2025-02-21 17:01:48 UTC",
    "updated_date": "2025-02-21 17:01:48 UTC"
  },
  {
    "arxiv_id": "2502.15589v1",
    "title": "LightThinker: Thinking Step-by-Step Compression",
    "authors": [
      "Jintian Zhang",
      "Yuqi Zhu",
      "Mengshu Sun",
      "Yujie Luo",
      "Shuofei Qiao",
      "Lun Du",
      "Da Zheng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance in complex\nreasoning tasks, but their efficiency is hindered by the substantial memory and\ncomputational costs associated with generating lengthy tokens. In this paper,\nwe propose LightThinker, a novel method that enables LLMs to dynamically\ncompress intermediate thoughts during reasoning. Inspired by human cognitive\nprocesses, LightThinker compresses verbose thought steps into compact\nrepresentations and discards the original reasoning chains, thereby\nsignificantly reducing the number of tokens stored in the context window. This\nis achieved by training the model on when and how to perform compression\nthrough data construction, mapping hidden states to condensed gist tokens, and\ncreating specialized attention masks. Additionally, we introduce the Dependency\n(Dep) metric to quantify the degree of compression by measuring the reliance on\nhistorical tokens during generation. Extensive experiments on four datasets and\ntwo models show that LightThinker reduces peak memory usage and inference time,\nwhile maintaining competitive accuracy. Our work provides a new direction for\nimproving the efficiency of LLMs in complex reasoning tasks without sacrificing\nperformance. Code will be released at https://github.com/zjunlp/LightThinker.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15589v1",
    "published_date": "2025-02-21 16:57:22 UTC",
    "updated_date": "2025-02-21 16:57:22 UTC"
  },
  {
    "arxiv_id": "2502.15588v1",
    "title": "Improving the Scaling Laws of Synthetic Data with Deliberate Practice",
    "authors": [
      "Reyhane Askari-Hemmat",
      "Mohammad Pezeshki",
      "Elvis Dohmatob",
      "Florian Bordes",
      "Pietro Astolfi",
      "Melissa Hall",
      "Jakob Verbeek",
      "Michal Drozdzal",
      "Adriana Romero-Soriano"
    ],
    "abstract": "Inspired by the principle of deliberate practice in human learning, we\npropose Deliberate Practice for Synthetic Data Generation (DP), a novel\nframework that improves sample efficiency through dynamic synthetic data\ngeneration. Prior work has shown that scaling synthetic data is inherently\nchallenging, as naively adding new data leads to diminishing returns. To\naddress this, pruning has been identified as a key mechanism for improving\nscaling, enabling models to focus on the most informative synthetic samples.\nRather than generating a large dataset and pruning it afterward, DP efficiently\napproximates the direct generation of informative samples. We theoretically\nshow how training on challenging, informative examples improves scaling laws\nand empirically validate that DP achieves better scaling performance with\nsignificantly fewer training samples and iterations. On ImageNet-100, DP\ngenerates 3.4x fewer samples and requires six times fewer iterations, while on\nImageNet-1k, it generates 8x fewer samples with a 30 percent reduction in\niterations, all while achieving superior performance compared to prior work.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15588v1",
    "published_date": "2025-02-21 16:56:15 UTC",
    "updated_date": "2025-02-21 16:56:15 UTC"
  },
  {
    "arxiv_id": "2502.15575v1",
    "title": "Feature maps for the Laplacian kernel and its generalizations",
    "authors": [
      "Sudhendu Ahir",
      "Parthe Pandit"
    ],
    "abstract": "Recent applications of kernel methods in machine learning have seen a renewed\ninterest in the Laplacian kernel, due to its stability to the bandwidth\nhyperparameter in comparison to the Gaussian kernel, as well as its\nexpressivity being equivalent to that of the neural tangent kernel of deep\nfully connected networks. However, unlike the Gaussian kernel, the Laplacian\nkernel is not separable. This poses challenges for techniques to approximate\nit, especially via the random Fourier features (RFF) methodology and its\nvariants. In this work, we provide random features for the Laplacian kernel and\nits two generalizations: Mat\\'{e}rn kernel and the Exponential power kernel. We\nprovide efficiently implementable schemes to sample weight matrices so that\nrandom features approximate these kernels. These weight matrices have a weakly\ncoupled heavy-tailed randomness. Via numerical experiments on real datasets we\ndemonstrate the efficacy of these random feature maps.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15575v1",
    "published_date": "2025-02-21 16:36:20 UTC",
    "updated_date": "2025-02-21 16:36:20 UTC"
  },
  {
    "arxiv_id": "2502.17503v1",
    "title": "Doctor-in-the-Loop: An Explainable, Multi-View Deep Learning Framework for Predicting Pathological Response in Non-Small Cell Lung Cancer",
    "authors": [
      "Alice Natalina Caragliano",
      "Filippo Ruffini",
      "Carlo Greco",
      "Edy Ippolito",
      "Michele Fiore",
      "Claudia Tacconi",
      "Lorenzo Nibid",
      "Giuseppe Perrone",
      "Sara Ramella",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "Non-small cell lung cancer (NSCLC) remains a major global health challenge,\nwith high post-surgical recurrence rates underscoring the need for accurate\npathological response predictions to guide personalized treatments. Although\nartificial intelligence models show promise in this domain, their clinical\nadoption is limited by the lack of medically grounded guidance during training,\noften resulting in non-explainable intrinsic predictions. To address this, we\npropose Doctor-in-the-Loop, a novel framework that integrates expert-driven\ndomain knowledge with explainable artificial intelligence techniques, directing\nthe model toward clinically relevant anatomical regions and improving both\ninterpretability and trustworthiness. Our approach employs a gradual multi-view\nstrategy, progressively refining the model's focus from broad contextual\nfeatures to finer, lesion-specific details. By incorporating domain insights at\nevery stage, we enhance predictive accuracy while ensuring that the model's\ndecision-making process aligns more closely with clinical reasoning. Evaluated\non a dataset of NSCLC patients, Doctor-in-the-Loop delivers promising\npredictive performance and provides transparent, justifiable outputs,\nrepresenting a significant step toward clinically explainable artificial\nintelligence in oncology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17503v1",
    "published_date": "2025-02-21 16:35:30 UTC",
    "updated_date": "2025-02-21 16:35:30 UTC"
  },
  {
    "arxiv_id": "2502.15568v2",
    "title": "A Cautionary Tale About \"Neutrally\" Informative AI Tools Ahead of the 2025 Federal Elections in Germany",
    "authors": [
      "Ina Dormuth",
      "Sven Franke",
      "Marlies Hafer",
      "Tim Katzke",
      "Alexander Marx",
      "Emmanuel MÃ¼ller",
      "Daniel Neider",
      "Markus Pauly",
      "JÃ©rÃ´me Rutinowski"
    ],
    "abstract": "In this study, we examine the reliability of AI-based Voting Advice\nApplications (VAAs) and large language models (LLMs) in providing objective\npolitical information. Our analysis is based upon a comparison with party\nresponses to 38 statements of the Wahl-O-Mat, a well-established German online\ntool that helps inform voters by comparing their views with political party\npositions. For the LLMs, we identify significant biases. They exhibit a strong\nalignment (over 75% on average) with left-wing parties and a substantially\nlower alignment with center-right (smaller 50%) and right-wing parties (around\n30%). Furthermore, for the VAAs, intended to objectively inform voters, we\nfound substantial deviations from the parties' stated positions in Wahl-O-Mat:\nWhile one VAA deviated in 25% of cases, another VAA showed deviations in more\nthan 50% of cases. For the latter, we even observed that simple prompt\ninjections led to severe hallucinations, including false claims such as\nnon-existent connections between political parties and right-wing extremist\nties.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15568v2",
    "published_date": "2025-02-21 16:30:53 UTC",
    "updated_date": "2025-04-07 20:52:04 UTC"
  },
  {
    "arxiv_id": "2502.15563v1",
    "title": "Bridging vision language model (VLM) evaluation gaps with a framework for scalable and cost-effective benchmark generation",
    "authors": [
      "Tim RÃ¤dsch",
      "Leon Mayer",
      "Simon Pavicic",
      "A. Emre Kavur",
      "Marcel Knopp",
      "BarÄ±Å ÃztÃ¼rk",
      "Klaus Maier-Hein",
      "Paul F. Jaeger",
      "Fabian Isensee",
      "Annika Reinke",
      "Lena Maier-Hein"
    ],
    "abstract": "Reliable evaluation of AI models is critical for scientific progress and\npractical application. While existing VLM benchmarks provide general insights\ninto model capabilities, their heterogeneous designs and limited focus on a few\nimaging domains pose significant challenges for both cross-domain performance\ncomparison and targeted domain-specific evaluation. To address this, we propose\nthree key contributions: (1) a framework for the resource-efficient creation of\ndomain-specific VLM benchmarks enabled by task augmentation for creating\nmultiple diverse tasks from a single existing task, (2) the release of new VLM\nbenchmarks for seven domains, created according to the same homogeneous\nprotocol and including 162,946 thoroughly human-validated answers, and (3) an\nextensive benchmarking of 22 state-of-the-art VLMs on a total of 37,171 tasks,\nrevealing performance variances across domains and tasks, thereby supporting\nthe need for tailored VLM benchmarks. Adoption of our methodology will pave the\nway for the resource-efficient domain-specific selection of models and guide\nfuture research efforts toward addressing core open questions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15563v1",
    "published_date": "2025-02-21 16:24:10 UTC",
    "updated_date": "2025-02-21 16:24:10 UTC"
  },
  {
    "arxiv_id": "2502.15547v1",
    "title": "Zweistein: A Dynamic Programming Evaluation Function for Einstein WÃ¼rfelt Nicht!",
    "authors": [
      "Wei Lin. Hsueh",
      "Tsan Sheng. Hsu"
    ],
    "abstract": "This paper introduces Zweistein, a dynamic programming evaluation function\nfor Einstein W\\\"urfelt Nicht! (EWN). Instead of relying on human knowledge to\ncraft an evaluation function, Zweistein uses a data-centric approach that\neliminates the need for parameter tuning. The idea is to use a vector recording\nthe distance to the corner of all pieces. This distance vector captures the\nessence of EWN. It not only outperforms many traditional EWN evaluation\nfunctions but also won first place in the TCGA 2023 competition.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15547v1",
    "published_date": "2025-02-21 15:54:21 UTC",
    "updated_date": "2025-02-21 15:54:21 UTC"
  },
  {
    "arxiv_id": "2502.15543v1",
    "title": "PIP-KAG: Mitigating Knowledge Conflicts in Knowledge-Augmented Generation via Parametric Pruning",
    "authors": [
      "Pengcheng Huang",
      "Zhenghao Liu",
      "Yukun Yan",
      "Xiaoyuan Yi",
      "Hao Chen",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Tong Xiao",
      "Ge Yu",
      "Chenyan Xiong"
    ],
    "abstract": "Knowledge-Augmented Generation (KAG) has shown great promise in updating the\ninternal memory of Large Language Models (LLMs) by integrating external\nknowledge. However, KAG inevitably faces knowledge conflicts when the internal\nmemory contradicts external information. Current approaches to mitigating these\nconflicts mainly focus on improving external knowledge utilization. However,\nthese methods have shown only limited effectiveness in mitigating the knowledge\nconflict problem, as internal knowledge continues to influence the generation\nprocess of LLMs. In this paper, we propose a ParametrIc Pruning-based\nKnowledge-Augmented Generation (PIP-KAG) approach, which prunes internal\nknowledge of LLMs and incorporates a plug-and-play adaptation module to help\nLLMs better leverage external sources. Additionally, we construct the\nCoConflictQA benchmark based on the hallucination of LLMs to better evaluate\ncontextual faithfulness during answering questions. Experimental results on\nCoConflictQA demonstrate that PIP-KAG significantly reduces knowledge conflicts\nand improves context fidelity. Notably, PIP-KAG reduces LLM's parameters by\n13%, enhancing parameter efficiency in LLMs within the KAG framework. All codes\nare available at https://github.com/OpenBMB/PIP-KAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 7 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15543v1",
    "published_date": "2025-02-21 15:50:41 UTC",
    "updated_date": "2025-02-21 15:50:41 UTC"
  },
  {
    "arxiv_id": "2502.15542v1",
    "title": "Bridging Domain Gaps between Pretrained Multimodal Models and Recommendations",
    "authors": [
      "Wenyu Zhang",
      "Jie Luo",
      "Xinming Zhang",
      "Yuan Fang"
    ],
    "abstract": "With the explosive growth of multimodal content online, pre-trained\nvisual-language models have shown great potential for multimodal\nrecommendation. However, while these models achieve decent performance when\napplied in a frozen manner, surprisingly, due to significant domain gaps (e.g.,\nfeature distribution discrepancy and task objective misalignment) between\npre-training and personalized recommendation, adopting a joint training\napproach instead leads to performance worse than baseline. Existing approaches\neither rely on simple feature extraction or require computationally expensive\nfull model fine-tuning, struggling to balance effectiveness and efficiency. To\ntackle these challenges, we propose \\textbf{P}arameter-efficient\n\\textbf{T}uning for \\textbf{M}ultimodal \\textbf{Rec}ommendation\n(\\textbf{PTMRec}), a novel framework that bridges the domain gap between\npre-trained models and recommendation systems through a knowledge-guided\ndual-stage parameter-efficient training strategy. This framework not only\neliminates the need for costly additional pre-training but also flexibly\naccommodates various parameter-efficient tuning methods.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15542v1",
    "published_date": "2025-02-21 15:50:14 UTC",
    "updated_date": "2025-02-21 15:50:14 UTC"
  },
  {
    "arxiv_id": "2502.15516v1",
    "title": "Depth-aware Fusion Method based on Image and 4D Radar Spectrum for 3D Object Detection",
    "authors": [
      "Yue Sun",
      "Yeqiang Qian",
      "Chunxiang Wang",
      "Ming Yang"
    ],
    "abstract": "Safety and reliability are crucial for the public acceptance of autonomous\ndriving. To ensure accurate and reliable environmental perception, intelligent\nvehicles must exhibit accuracy and robustness in various environments.\nMillimeter-wave radar, known for its high penetration capability, can operate\neffectively in adverse weather conditions such as rain, snow, and fog.\nTraditional 3D millimeter-wave radars can only provide range, Doppler, and\nazimuth information for objects. Although the recent emergence of 4D\nmillimeter-wave radars has added elevation resolution, the radar point clouds\nremain sparse due to Constant False Alarm Rate (CFAR) operations. In contrast,\ncameras offer rich semantic details but are sensitive to lighting and weather\nconditions. Hence, this paper leverages these two highly complementary and\ncost-effective sensors, 4D millimeter-wave radar and camera. By integrating 4D\nradar spectra with depth-aware camera images and employing attention\nmechanisms, we fuse texture-rich images with depth-rich radar data in the\nBird's Eye View (BEV) perspective, enhancing 3D object detection. Additionally,\nwe propose using GAN-based networks to generate depth images from radar spectra\nin the absence of depth sensors, further improving detection accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15516v1",
    "published_date": "2025-02-21 15:14:30 UTC",
    "updated_date": "2025-02-21 15:14:30 UTC"
  },
  {
    "arxiv_id": "2502.15507v3",
    "title": "Activation Steering in Neural Theorem Provers",
    "authors": [
      "Shashank Kirtania"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in proving formal theorems\nusing proof assistants like Lean. However, current state of the art language\nmodels struggles to predict next step in proofs leading practitioners to use\ndifferent sampling techniques to improve LLMs capabilities. We observe that the\nLLM is capable of predicting the correct tactic; however, it faces challenges\nin ranking it appropriately within the set of candidate tactics, affecting the\noverall selection process. To overcome this hurdle, we use activation steering\nto guide LLMs responses to improve the generations at the time of inference.\nOur results suggest that activation steering offers a promising lightweight\nalternative to specialized fine-tuning for enhancing theorem proving\ncapabilities in LLMs, particularly valuable in resource-constrained\nenvironments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "incorrect explanation for a concept, need to revise and update!",
    "pdf_url": "http://arxiv.org/pdf/2502.15507v3",
    "published_date": "2025-02-21 15:04:48 UTC",
    "updated_date": "2025-05-14 17:25:36 UTC"
  },
  {
    "arxiv_id": "2502.15503v1",
    "title": "BAN: Neuroanatomical Aligning in Auditory Recognition between Artificial Neural Network and Human Cortex",
    "authors": [
      "Haidong Wang",
      "Pengfei Xiao",
      "Ao Liu",
      "Jianhua Zhang",
      "Qia Shan"
    ],
    "abstract": "Drawing inspiration from neurosciences, artificial neural networks (ANNs)\nhave evolved from shallow architectures to highly complex, deep structures,\nyielding exceptional performance in auditory recognition tasks. However,\ntraditional ANNs often struggle to align with brain regions due to their\nexcessive depth and lack of biologically realistic features, like recurrent\nconnection. To address this, a brain-like auditory network (BAN) is introduced,\nwhich incorporates four neuroanatomically mapped areas and recurrent\nconnection, guided by a novel metric called the brain-like auditory score\n(BAS). BAS serves as a benchmark for evaluating the similarity between BAN and\nhuman auditory recognition pathway. We further propose that specific areas in\nthe cerebral cortex, mainly the middle and medial superior temporal (T2/T3)\nareas, correspond to the designed network structure, drawing parallels with the\nbrain's auditory perception pathway. Our findings suggest that the\nneuroanatomical similarity in the cortex and auditory classification abilities\nof the ANN are well-aligned. In addition to delivering excellent performance on\na music genre classification task, the BAN demonstrates a high BAS score. In\nconclusion, this study presents BAN as a recurrent, brain-inspired ANN,\nrepresenting the first model that mirrors the cortical pathway of auditory\nrecognition.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15503v1",
    "published_date": "2025-02-21 14:57:01 UTC",
    "updated_date": "2025-02-21 14:57:01 UTC"
  },
  {
    "arxiv_id": "2503.16454v1",
    "title": "An Audio-Visual Fusion Emotion Generation Model Based on Neuroanatomical Alignment",
    "authors": [
      "Haidong Wang",
      "Qia Shan",
      "JianHua Zhang",
      "PengFei Xiao",
      "Ao Liu"
    ],
    "abstract": "In the field of affective computing, traditional methods for generating\nemotions predominantly rely on deep learning techniques and large-scale emotion\ndatasets. However, deep learning techniques are often complex and difficult to\ninterpret, and standardizing large-scale emotional datasets are difficult and\ncostly to establish. To tackle these challenges, we introduce a novel framework\nnamed Audio-Visual Fusion for Brain-like Emotion Learning(AVF-BEL). In contrast\nto conventional brain-inspired emotion learning methods, this approach improves\nthe audio-visual emotion fusion and generation model through the integration of\nmodular components, thereby enabling more lightweight and interpretable emotion\nlearning and generation processes. The framework simulates the integration of\nthe visual, auditory, and emotional pathways of the brain, optimizes the fusion\nof emotional features across visual and auditory modalities, and improves upon\nthe traditional Brain Emotional Learning (BEL) model. The experimental results\nindicate a significant improvement in the similarity of the audio-visual fusion\nemotion learning generation model compared to single-modality visual and\nauditory emotion learning and generation model. Ultimately, this aligns with\nthe fundamental phenomenon of heightened emotion generation facilitated by the\nintegrated impact of visual and auditory stimuli. This contribution not only\nenhances the interpretability and efficiency of affective intelligence but also\nprovides new insights and pathways for advancing affective computing\ntechnology. Our source code can be accessed here:\nhttps://github.com/OpenHUTB/emotion}{https://github.com/OpenHUTB/emotion.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.16454v1",
    "published_date": "2025-02-21 14:26:58 UTC",
    "updated_date": "2025-02-21 14:26:58 UTC"
  },
  {
    "arxiv_id": "2502.15488v2",
    "title": "Q-PETR: Quant-aware Position Embedding Transformation for Multi-View 3D Object Detection",
    "authors": [
      "Jiangyong Yu",
      "Changyong Shu",
      "Dawei Yang",
      "Sifan Zhou",
      "Zichen Yu",
      "Xing Hu",
      "Yan Chen"
    ],
    "abstract": "Camera-based multi-view 3D detection has emerged as an attractive solution\nfor autonomous driving due to its low cost and broad applicability. However,\ndespite the strong performance of PETR-based methods in 3D perception\nbenchmarks, their direct INT8 quantization for onboard deployment leads to\ndrastic accuracy drops-up to 58.2% in mAP and 36.9% in NDS on the NuScenes\ndataset. In this work, we propose Q-PETR, a quantization-aware position\nembedding transformation that re-engineers key components of the PETR framework\nto reconcile the discrepancy between the dynamic ranges of positional encodings\nand image features, and to adapt the cross-attention mechanism for low-bit\ninference. By redesigning the positional encoding module and introducing an\nadaptive quantization strategy, Q-PETR maintains floating-point performance\nwith a performance degradation of less than 1% under standard 8-bit per-tensor\npost-training quantization. Moreover, compared to its FP32 counterpart, Q-PETR\nachieves a two-fold speedup and reduces memory usage by three times, thereby\noffering a deployment-friendly solution for resource-constrained onboard\ndevices. Extensive experiments across various PETR-series models validate the\nstrong generalization and practical benefits of our approach.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15488v2",
    "published_date": "2025-02-21 14:26:23 UTC",
    "updated_date": "2025-03-11 15:05:41 UTC"
  },
  {
    "arxiv_id": "2502.15487v2",
    "title": "ExpliCa: Evaluating Explicit Causal Reasoning in Large Language Models",
    "authors": [
      "Martina Miliani",
      "Serena Auriemma",
      "Alessandro Bondielli",
      "Emmanuele Chersoni",
      "Lucia Passaro",
      "Irene Sucameli",
      "Alessandro Lenci"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in tasks requiring\ninterpretive and inferential accuracy. In this paper, we introduce ExpliCa, a\nnew dataset for evaluating LLMs in explicit causal reasoning. ExpliCa uniquely\nintegrates both causal and temporal relations presented in different linguistic\norders and explicitly expressed by linguistic connectives. The dataset is\nenriched with crowdsourced human acceptability ratings. We tested LLMs on\nExpliCa through prompting and perplexity-based metrics. We assessed seven\ncommercial and open-source LLMs, revealing that even top models struggle to\nreach 0.80 accuracy. Interestingly, models tend to confound temporal relations\nwith causal ones, and their performance is also strongly influenced by the\nlinguistic order of the events. Finally, perplexity-based scores and prompting\nperformance are differently affected by model size.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T07",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15487v2",
    "published_date": "2025-02-21 14:23:14 UTC",
    "updated_date": "2025-02-26 07:15:45 UTC"
  },
  {
    "arxiv_id": "2502.15485v2",
    "title": "Enhancing RWKV-based Language Models for Long-Sequence Text Generation",
    "authors": [
      "Xinghan Pan"
    ],
    "abstract": "This paper introduces an enhanced RWKV architecture with adaptive temporal\ngating mechanisms for improved long-context language modeling. We propose two\nprincipal innovations: (1) a position-aware convolutional shift operator that\ncaptures local syntactic patterns while preserving global coherence, and (2) a\nneurally-gated information routing mechanism that dynamically regulates\ninter-token information flow. Through comprehensive experiments on text\ngeneration tasks, our enhanced model demonstrates superior performance compared\nto the baseline RWKV, achieving 96.5 relative improvement in ROUGE-L scores\nwith only 2.95 increased inference latency. Ablation studies validate the\nindividual contributions of each component, while linguistic analysis reveals\nthe model's adaptive attention to syntactic boundaries and entity coherence.\nThe proposed modifications maintain RWKV's linear computational complexity\nwhile significantly enhancing its contextual modeling capabilities,\nestablishing new state-of-the-art performance for recurrent-style architectures\nin long-form text generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15485v2",
    "published_date": "2025-02-21 14:18:18 UTC",
    "updated_date": "2025-02-24 14:30:32 UTC"
  },
  {
    "arxiv_id": "2502.15470v2",
    "title": "PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System",
    "authors": [
      "Yintao He",
      "Haiyu Mao",
      "Christina Giannoula",
      "Mohammad Sadrosadati",
      "Juan GÃ³mez-Luna",
      "Huawei Li",
      "Xiaowei Li",
      "Ying Wang",
      "Onur Mutlu"
    ],
    "abstract": "Large language models (LLMs) are widely used for natural language\nunderstanding and text generation. An LLM model relies on a time-consuming step\ncalled LLM decoding to generate output tokens. Several prior works focus on\nimproving the performance of LLM decoding using parallelism techniques, such as\nbatching and speculative decoding. State-of-the-art LLM decoding has both\ncompute-bound and memory-bound kernels. Some prior works statically identify\nand map these different kernels to a heterogeneous architecture consisting of\nboth processing-in-memory (PIM) units and computation-centric accelerators. We\nobserve that characteristics of LLM decoding kernels (e.g., whether or not a\nkernel is memory-bound) can change dynamically due to parameter changes to meet\nuser and/or system demands, making (1) static kernel mapping to PIM units and\ncomputation-centric accelerators suboptimal, and (2) one-size-fits-all approach\nof designing PIM units inefficient due to a large degree of heterogeneity even\nin memory-bound kernels.\n  In this paper, we aim to accelerate LLM decoding while considering the\ndynamically changing characteristics of the kernels involved. We propose PAPI\n(PArallel Decoding with PIM), a PIM-enabled heterogeneous architecture that\nexploits dynamic scheduling of compute-bound or memory-bound kernels to\nsuitable hardware units. PAPI has two key mechanisms: (1) online kernel\ncharacterization to dynamically schedule kernels to the most suitable hardware\nunits at runtime and (2) a PIM-enabled heterogeneous computing system that\nharmoniously orchestrates both computation-centric processing units and hybrid\nPIM units with different computing capabilities. Our experimental results on\nthree broadly-used LLMs show that PAPI achieves 1.8$\\times$ and 11.1$\\times$\nspeedups over a state-of-the-art heterogeneous LLM accelerator and a\nstate-of-the-art PIM-only LLM accelerator, respectively.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "To appear in ASPLOS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15470v2",
    "published_date": "2025-02-21 13:52:31 UTC",
    "updated_date": "2025-02-27 07:03:36 UTC"
  },
  {
    "arxiv_id": "2502.15466v1",
    "title": "Mitigating Data Scarcity in Time Series Analysis: A Foundation Model with Series-Symbol Data Generation",
    "authors": [
      "Wenxuan Wang",
      "Kai Wu",
      "Yujian Betterest Li",
      "Dan Wang",
      "Xiaoyu Zhang",
      "Jing Liu"
    ],
    "abstract": "Foundation models for time series analysis (TSA) have attracted significant\nattention. However, challenges such as data scarcity and data imbalance\ncontinue to hinder their development. To address this, we consider modeling\ncomplex systems through symbolic expressions that serve as semantic descriptors\nof time series. Building on this concept, we introduce a series-symbol (S2)\ndual-modulity data generation mechanism, enabling the unrestricted creation of\nhigh-quality time series data paired with corresponding symbolic\nrepresentations. Leveraging the S2 dataset, we develop SymTime, a pre-trained\nfoundation model for TSA. SymTime demonstrates competitive performance across\nfive major TSA tasks when fine-tuned with downstream task, rivaling foundation\nmodels pre-trained on real-world datasets. This approach underscores the\npotential of dual-modality data generation and pretraining mechanisms in\novercoming data scarcity and enhancing task performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15466v1",
    "published_date": "2025-02-21 13:43:24 UTC",
    "updated_date": "2025-02-21 13:43:24 UTC"
  },
  {
    "arxiv_id": "2502.15455v1",
    "title": "R-LoRA: Random Initialization of Multi-Head LoRA for Multi-Task Learning",
    "authors": [
      "Jinda Liu",
      "Yi Chang",
      "Yuan Wu"
    ],
    "abstract": "Fine-tuning large language models (LLMs) is prohibitively expensive in terms\nof computational and memory costs. Low-rank Adaptation (LoRA), as one of the\nmost popular parameter-efficient fine-tuning (PEFT) methods, offers a\ncost-effective alternative by approximating the model changes $\\Delta W \\in\n\\mathbb{R}^{m \\times n}$ through the product of down-projection matrix $A \\in\n\\mathbb{R}^{m \\times r}$ and head matrix $B \\in \\mathbb{R}^{r \\times n}$, where\n$r \\ll \\min(m, n)$. In real-world scenarios, LLMs are fine-tuned on data from\nmultiple domains to perform tasks across various fields, embodying multi-task\nlearning (MTL). LoRA often underperforms in such complex scenarios. To enhance\nLoRA's capability in multi-task learning, we propose R-LoRA, which incorporates\nMulti-Head Randomization. Multi-Head Randomization diversifies the head\nmatrices through Multi-Head Random Initialization and Multi-Head Dropout,\nenabling more efficient learning of task-specific features while maintaining\nshared knowledge representation. Extensive experiments demonstrate that R-LoRA\nis better at capturing task-specific knowledge, thereby improving performance\nin multi-task scenarios. The code is available at\nhttps://github.com/jinda-liu/R-LoRA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15455v1",
    "published_date": "2025-02-21 13:30:21 UTC",
    "updated_date": "2025-02-21 13:30:21 UTC"
  },
  {
    "arxiv_id": "2502.15448v1",
    "title": "MVIP -- A Dataset and Methods for Application Oriented Multi-View and Multi-Modal Industrial Part Recognition",
    "authors": [
      "Paul Koch",
      "Marian SchlÃ¼ter",
      "JÃ¶rg KrÃ¼ger"
    ],
    "abstract": "We present MVIP, a novel dataset for multi-modal and multi-view\napplication-oriented industrial part recognition. Here we are the first to\ncombine a calibrated RGBD multi-view dataset with additional object context\nsuch as physical properties, natural language, and super-classes. The current\nportfolio of available datasets offers a wide range of representations to\ndesign and benchmark related methods. In contrast to existing classification\nchallenges, industrial recognition applications offer controlled multi-modal\nenvironments but at the same time have different problems than traditional\n2D/3D classification challenges. Frequently, industrial applications must deal\nwith a small amount or increased number of training data, visually similar\nparts, and varying object sizes, while requiring a robust near 100% top 5\naccuracy under cost and time constraints. Current methods tackle such\nchallenges individually, but direct adoption of these methods within industrial\napplications is complex and requires further research. Our main goal with MVIP\nis to study and push transferability of various state-of-the-art methods within\nrelated downstream tasks towards an efficient deployment of industrial\nclassifiers. Additionally, we intend to push with MVIP research regarding\nseveral modality fusion topics, (automated) synthetic data generation, and\ncomplex data sampling -- combined in a single application-oriented benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IMPROVE 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15448v1",
    "published_date": "2025-02-21 13:22:29 UTC",
    "updated_date": "2025-02-21 13:22:29 UTC"
  },
  {
    "arxiv_id": "2502.15867v1",
    "title": "Strategic priorities for transformative progress in advancing biology with proteomics and artificial intelligence",
    "authors": [
      "Yingying Sun",
      "Jun A",
      "Zhiwei Liu",
      "Rui Sun",
      "Liujia Qian",
      "Samuel H. Payne",
      "Wout Bittremieux",
      "Markus Ralser",
      "Chen Li",
      "Yi Chen",
      "Zhen Dong",
      "Yasset Perez-Riverol",
      "Asif Khan",
      "Chris Sander",
      "Ruedi Aebersold",
      "Juan Antonio VizcaÃ­no",
      "Jonathan R Krieger",
      "Jianhua Yao",
      "Han Wen",
      "Linfeng Zhang",
      "Yunping Zhu",
      "Yue Xuan",
      "Benjamin Boyang Sun",
      "Liang Qiao",
      "Henning Hermjakob",
      "Haixu Tang",
      "Huanhuan Gao",
      "Yamin Deng",
      "Qing Zhong",
      "Cheng Chang",
      "Nuno Bandeira",
      "Ming Li",
      "Weinan E",
      "Siqi Sun",
      "Yuedong Yang",
      "Gilbert S. Omenn",
      "Yue Zhang",
      "Ping Xu",
      "Yan Fu",
      "Xiaowen Liu",
      "Christopher M. Overall",
      "Yu Wang",
      "Eric W. Deutsch",
      "Luonan Chen",
      "JÃ¼rgen Cox",
      "Vadim Demichev",
      "Fuchu He",
      "Jiaxing Huang",
      "Huilin Jin",
      "Chao Liu",
      "Nan Li",
      "Zhongzhi Luan",
      "Jiangning Song",
      "Kaicheng Yu",
      "Wanggen Wan",
      "Tai Wang",
      "Kang Zhang",
      "Le Zhang",
      "Peter A. Bell",
      "Matthias Mann",
      "Bing Zhang",
      "Tiannan Guo"
    ],
    "abstract": "Artificial intelligence (AI) is transforming scientific research, including\nproteomics. Advances in mass spectrometry (MS)-based proteomics data quality,\ndiversity, and scale, combined with groundbreaking AI techniques, are unlocking\nnew challenges and opportunities in biological discovery. Here, we highlight\nkey areas where AI is driving innovation, from data analysis to new biological\ninsights. These include developing an AI-friendly ecosystem for proteomics data\ngeneration, sharing, and analysis; improving peptide and protein identification\nand quantification; characterizing protein-protein interactions and protein\ncomplexes; advancing spatial and perturbation proteomics; integrating\nmulti-omics data; and ultimately enabling AI-empowered virtual cells.",
    "categories": [
      "q-bio.OT",
      "cs.AI"
    ],
    "primary_category": "q-bio.OT",
    "comment": "28 pages, 2 figures, perspective in AI proteomics",
    "pdf_url": "http://arxiv.org/pdf/2502.15867v1",
    "published_date": "2025-02-21 13:20:33 UTC",
    "updated_date": "2025-02-21 13:20:33 UTC"
  },
  {
    "arxiv_id": "2502.15443v1",
    "title": "When Compression Meets Model Compression: Memory-Efficient Double Compression for Large Language Models",
    "authors": [
      "Weilan Wang",
      "Yu Mao",
      "Dongdong Tang",
      "Hongchao Du",
      "Nan Guan",
      "Chun Jason Xue"
    ],
    "abstract": "Large language models (LLMs) exhibit excellent performance in various tasks.\nHowever, the memory requirements of LLMs present a great challenge when\ndeploying on memory-limited devices, even for quantized LLMs. This paper\nintroduces a framework to compress LLM after quantization further, achieving\nabout 2.2x compression ratio. A compression-aware quantization is first\nproposed to enhance model weight compressibility by re-scaling the model\nparameters before quantization, followed by a pruning method to improve\nfurther. Upon this, we notice that decompression can be a bottleneck during\npractical scenarios. We then give a detailed analysis of the trade-off between\nmemory usage and latency brought by the proposed method. A speed-adaptive\nmethod is proposed to overcome it. The experimental results show inference with\nthe compressed model can achieve a 40% reduction in memory size with negligible\nloss in accuracy and inference speed.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15443v1",
    "published_date": "2025-02-21 13:11:22 UTC",
    "updated_date": "2025-02-21 13:11:22 UTC"
  },
  {
    "arxiv_id": "2502.15436v1",
    "title": "Fed-SB: A Silver Bullet for Extreme Communication Efficiency and Performance in (Private) Federated LoRA Fine-Tuning",
    "authors": [
      "Raghav Singhal",
      "Kaustubh Ponkshe",
      "Rohit Vartak",
      "Lav R. Varshney",
      "Praneeth Vepakomma"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) has become ubiquitous for efficiently fine-tuning\nfoundation models. However, federated fine-tuning using LoRA is challenging due\nto suboptimal updates arising from traditional federated averaging of\nindividual adapters. Existing solutions either incur prohibitively high\ncommunication cost that scales linearly with the number of clients or suffer\nfrom performance degradation due to limited expressivity. We introduce\nFederated Silver Bullet (Fed-SB), a novel approach for federated fine-tuning of\nLLMs using LoRA-SB, a recently proposed low-rank adaptation method. LoRA-SB\noptimally aligns the optimization trajectory with the ideal low-rank full\nfine-tuning projection by learning a small square matrix (R) between adapters B\nand A, keeping other components fixed. Direct averaging of R guarantees exact\nupdates, substantially reducing communication cost, which remains independent\nof the number of clients, and enables scalability. Fed-SB achieves\nstate-of-the-art performance across commonsense reasoning, arithmetic\nreasoning, and language inference tasks while reducing communication costs by\nup to 230x. In private settings, Fed-SB further improves performance by (1)\nreducing trainable parameters, thereby lowering the noise required for\ndifferential privacy and (2) avoiding noise amplification introduced by other\nmethods. Overall, Fed-SB establishes a new Pareto frontier in the tradeoff\nbetween communication and performance, offering an efficient and scalable\nsolution for both private and non-private federated fine-tuning. Our code is\npublicly available at https://github.com/CERT-Lab/fed-sb.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Raghav Singhal and Kaustubh Ponkshe contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2502.15436v1",
    "published_date": "2025-02-21 13:05:19 UTC",
    "updated_date": "2025-02-21 13:05:19 UTC"
  },
  {
    "arxiv_id": "2502.15435v1",
    "title": "Single-pass Detection of Jailbreaking Input in Large Language Models",
    "authors": [
      "Leyla Naz Candogan",
      "Yongtao Wu",
      "Elias Abad Rocamora",
      "Grigorios G. Chrysos",
      "Volkan Cevher"
    ],
    "abstract": "Defending aligned Large Language Models (LLMs) against jailbreaking attacks\nis a challenging problem, with existing approaches requiring multiple requests\nor even queries to auxiliary LLMs, making them computationally heavy. Instead,\nwe focus on detecting jailbreaking input in a single forward pass. Our method,\ncalled Single Pass Detection SPD, leverages the information carried by the\nlogits to predict whether the output sentence will be harmful. This allows us\nto defend in just one forward pass. SPD can not only detect attacks effectively\non open-source models, but also minimizes the misclassification of harmless\ninputs. Furthermore, we show that SPD remains effective even without complete\nlogit access in GPT-3.5 and GPT-4. We believe that our proposed method offers a\npromising approach to efficiently safeguard LLMs against adversarial attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in TMLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15435v1",
    "published_date": "2025-02-21 13:04:13 UTC",
    "updated_date": "2025-02-21 13:04:13 UTC"
  },
  {
    "arxiv_id": "2502.15865v1",
    "title": "Position: Standard Benchmarks Fail -- LLM Agents Present Overlooked Risks for Financial Applications",
    "authors": [
      "Zichen Chen",
      "Jiaao Chen",
      "Jianda Chen",
      "Misha Sra"
    ],
    "abstract": "Current financial LLM agent benchmarks are inadequate. They prioritize task\nperformance while ignoring fundamental safety risks. Threats like\nhallucinations, temporal misalignment, and adversarial vulnerabilities pose\nsystemic risks in high-stakes financial environments, yet existing evaluation\nframeworks fail to capture these risks. We take a firm position: traditional\nbenchmarks are insufficient to ensure the reliability of LLM agents in finance.\nTo address this, we analyze existing financial LLM agent benchmarks, finding\nsafety gaps and introducing ten risk-aware evaluation metrics. Through an\nempirical evaluation of both API-based and open-weight LLM agents, we reveal\nhidden vulnerabilities that remain undetected by conventional assessments. To\nmove the field forward, we propose the Safety-Aware Evaluation Agent (SAEA),\ngrounded in a three-level evaluation framework that assesses agents at the\nmodel level (intrinsic capabilities), workflow level (multi-step process\nreliability), and system level (integration robustness). Our findings highlight\nthe urgent need to redefine LLM agent evaluation standards by shifting the\nfocus from raw performance to safety, robustness, and real world resilience.",
    "categories": [
      "q-fin.GN",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-fin.GN",
    "comment": "40 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15865v1",
    "published_date": "2025-02-21 12:56:15 UTC",
    "updated_date": "2025-02-21 12:56:15 UTC"
  },
  {
    "arxiv_id": "2502.15425v4",
    "title": "TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning",
    "authors": [
      "Giuseppe Paolo",
      "Abdelhakim Benechehab",
      "Hamza Cherkaoui",
      "Albert Thomas",
      "BalÃ¡zs KÃ©gl"
    ],
    "abstract": "Hierarchical organization is fundamental to biological systems and human\nsocieties, yet artificial intelligence systems often rely on monolithic\narchitectures that limit adaptability and scalability. Current hierarchical\nreinforcement learning (HRL) approaches typically restrict hierarchies to two\nlevels or require centralized training, which limits their practical\napplicability. We introduce TAME Agent Framework (TAG), a framework for\nconstructing fully decentralized hierarchical multi-agent systems. TAG enables\nhierarchies of arbitrary depth through a novel LevelEnv concept, which\nabstracts each hierarchy level as the environment for the agents above it. This\napproach standardizes information flow between levels while preserving loose\ncoupling, allowing for seamless integration of diverse agent types. We\ndemonstrate the effectiveness of TAG by implementing hierarchical architectures\nthat combine different RL agents across multiple levels, achieving improved\nperformance over classical multi-agent RL baselines on standard benchmarks. Our\nresults show that decentralized hierarchical organization enhances both\nlearning speed and final performance, positioning TAG as a promising direction\nfor scalable multi-agent systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15425v4",
    "published_date": "2025-02-21 12:52:16 UTC",
    "updated_date": "2025-03-05 10:48:42 UTC"
  },
  {
    "arxiv_id": "2502.15424v1",
    "title": "Anatomy-Informed Deep Learning and Radiomics for Automated Neurofibroma Segmentation in Whole-Body MRI",
    "authors": [
      "Georgii Kolokolnikov",
      "Marie-Lena Schmalhofer",
      "Lennart Well",
      "Said Farschtschi",
      "Victor-Felix Mautner",
      "Inka Ristow",
      "Rene Werner"
    ],
    "abstract": "Neurofibromatosis Type 1 is a genetic disorder characterized by the\ndevelopment of neurofibromas (NFs), which exhibit significant variability in\nsize, morphology, and anatomical location. Accurate and automated segmentation\nof these tumors in whole-body magnetic resonance imaging (WB-MRI) is crucial to\nassess tumor burden and monitor disease progression. In this study, we present\nand analyze a fully automated pipeline for NF segmentation in fat-suppressed\nT2-weighted WB-MRI, consisting of three stages: anatomy segmentation, NF\nsegmentation, and tumor candidate classification. In the first stage, we use\nthe MRSegmentator model to generate an anatomy segmentation mask, extended with\na high-risk zone for NFs. This mask is concatenated with the input image as\nanatomical context information for NF segmentation. The second stage employs an\nensemble of 3D anisotropic anatomy-informed U-Nets to produce an NF\nsegmentation confidence mask. In the final stage, tumor candidates are\nextracted from the confidence mask and classified based on radiomic features,\ndistinguishing tumors from non-tumor regions and reducing false positives. We\nevaluate the proposed pipeline on three test sets representing different\nconditions: in-domain data (test set 1), varying imaging protocols and field\nstrength (test set 2), and low tumor burden cases (test set 3). Experimental\nresults show a 68% improvement in per-scan Dice Similarity Coefficient (DSC), a\n21% increase in per-tumor DSC, and a two-fold improvement in F1 score for tumor\ndetection in high tumor burden cases by integrating anatomy information. The\nmethod is integrated into the 3D Slicer platform for practical clinical use,\nwith the code publicly accessible.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15424v1",
    "published_date": "2025-02-21 12:49:35 UTC",
    "updated_date": "2025-02-21 12:49:35 UTC"
  },
  {
    "arxiv_id": "2502.15422v1",
    "title": "Evaluating Multimodal Generative AI with Korean Educational Standards",
    "authors": [
      "Sanghee Park",
      "Geewook Kim"
    ],
    "abstract": "This paper presents the Korean National Educational Test Benchmark (KoNET), a\nnew benchmark designed to evaluate Multimodal Generative AI Systems using\nKorean national educational tests. KoNET comprises four exams: the Korean\nElementary General Educational Development Test (KoEGED), Middle (KoMGED), High\n(KoHGED), and College Scholastic Ability Test (KoCSAT). These exams are\nrenowned for their rigorous standards and diverse questions, facilitating a\ncomprehensive analysis of AI performance across different educational levels.\nBy focusing on Korean, KoNET provides insights into model performance in\nless-explored languages. We assess a range of models - open-source,\nopen-access, and closed APIs - by examining difficulties, subject diversity,\nand human error rates. The code and dataset builder will be made fully\nopen-sourced at https://github.com/naver-ai/KoNET.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages; To appear at NAACL 2025 Main Conference (Project page:\n  https://github.com/naver-ai/KoNET )",
    "pdf_url": "http://arxiv.org/pdf/2502.15422v1",
    "published_date": "2025-02-21 12:46:40 UTC",
    "updated_date": "2025-02-21 12:46:40 UTC"
  },
  {
    "arxiv_id": "2502.15419v1",
    "title": "Beyond Translation: LLM-Based Data Generation for Multilingual Fact-Checking",
    "authors": [
      "Yi-Ling Chung",
      "Aurora Cobo",
      "Pablo Serna"
    ],
    "abstract": "Robust automatic fact-checking systems have the potential to combat online\nmisinformation at scale. However, most existing research primarily focuses on\nEnglish. In this paper, we introduce MultiSynFact, the first large-scale\nmultilingual fact-checking dataset containing 2.2M claim-source pairs designed\nto support Spanish, German, English, and other low-resource languages. Our\ndataset generation pipeline leverages Large Language Models (LLMs), integrating\nexternal knowledge from Wikipedia and incorporating rigorous claim validation\nsteps to ensure data quality. We evaluate the effectiveness of MultiSynFact\nacross multiple models and experimental settings. Additionally, we open-source\na user-friendly framework to facilitate further research in multilingual\nfact-checking and dataset generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 1 figure, 18 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15419v1",
    "published_date": "2025-02-21 12:38:26 UTC",
    "updated_date": "2025-02-21 12:38:26 UTC"
  },
  {
    "arxiv_id": "2502.15411v2",
    "title": "HiFi-KPI: A Dataset for Hierarchical KPI Extraction from Earnings Filings",
    "authors": [
      "Rasmus Aavang",
      "Giovanni Rizzi",
      "Rasmus BÃ¸ggild",
      "Alexandre Iolov",
      "Mike Zhang",
      "Johannes Bjerva"
    ],
    "abstract": "The U.S. Securities and Exchange Commission (SEC) requires that public\ncompanies file financial reports tagging numbers with the machine readable\ninline eXtensible Business Reporting Language (iXBRL) standard. However, the\nhighly complex and highly granular taxonomy defined by iXBRL limits label\ntransferability across domains. In this paper, we introduce the Hierarchical\nFinancial Key Performance Indicator (HiFi-KPI) dataset, designed to facilitate\nnumerical KPI extraction at specified levels of granularity from unstructured\nfinancial text. Our approach organizes a 218,126-label hierarchy using a\ntaxonomy based grouping method, investigating which taxonomy layer provides the\nmost meaningful structure. HiFi-KPI comprises ~1.8M paragraphs and ~5M\nentities, each linked to a label in the iXBRL-specific calculation and\npresentation taxonomies. We provide baselines using encoder-based approaches\nand structured extraction using Large Language Models (LLMs). To simplify LLM\ninference and evaluation, we additionally release HiFi-KPI Lite, a manually\ncurated subset with four expert-mapped labels. We publicly release all\nartifacts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15411v2",
    "published_date": "2025-02-21 12:19:08 UTC",
    "updated_date": "2025-02-24 14:45:27 UTC"
  },
  {
    "arxiv_id": "2502.17501v1",
    "title": "CoKV: Optimizing KV Cache Allocation via Cooperative Game",
    "authors": [
      "Qiheng Sun",
      "Hongwei Zhang",
      "Haocheng Xia",
      "Jiayao Zhang",
      "Jinfei Liu",
      "Kui Ren"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success on various\naspects of human life. However, one of the major challenges in deploying these\nmodels is the substantial memory consumption required to store key-value pairs\n(KV), which imposes significant resource demands. Recent research has focused\non KV cache budget allocation, with several approaches proposing head-level\nbudget distribution by evaluating the importance of individual attention heads.\nThese methods, however, assess the importance of heads independently,\noverlooking their cooperative contributions within the model, which may result\nin a deviation from their true impact on model performance. In light of this\nlimitation, we propose CoKV, a novel method that models the cooperation between\nheads in model inference as a cooperative game. By evaluating the contribution\nof each head within the cooperative game, CoKV can allocate the cache budget\nmore effectively. Extensive experiments show that CoKV achieves\nstate-of-the-art performance on the LongBench benchmark using\nLLama-3-8B-Instruct and Mistral-7B models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17501v1",
    "published_date": "2025-02-21 12:03:07 UTC",
    "updated_date": "2025-02-21 12:03:07 UTC"
  },
  {
    "arxiv_id": "2502.15401v1",
    "title": "Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs Complex Reasoning",
    "authors": [
      "Xuetao Ma",
      "Wenbin Jiang",
      "Hua Huang"
    ],
    "abstract": "In-context learning (ICL) can significantly enhance the complex reasoning\ncapabilities of large language models (LLMs), with the key lying in the\nselection and ordering of demonstration examples. Previous methods typically\nrelied on simple features to measure the relevance between examples. We argue\nthat these features are not sufficient to reflect the intrinsic connections\nbetween examples. In this study, we propose a curriculum ICL strategy guided by\nproblem-solving logic. We select demonstration examples by analyzing the\nproblem-solving logic and order them based on curriculum learning.\nSpecifically, we constructed a problem-solving logic instruction set based on\nthe BREAK dataset and fine-tuned a language model to analyze the\nproblem-solving logic of examples. Subsequently, we selected appropriate\ndemonstration examples based on problem-solving logic and assessed their\ndifficulty according to the number of problem-solving steps. In accordance with\nthe principles of curriculum learning, we ordered the examples from easy to\nhard to serve as contextual prompts. Experimental results on multiple\nbenchmarks indicate that our method outperforms previous ICL approaches in\nterms of performance and efficiency, effectively enhancing the complex\nreasoning capabilities of LLMs. Our project will be publicly available\nsubsequently.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15401v1",
    "published_date": "2025-02-21 12:00:10 UTC",
    "updated_date": "2025-02-21 12:00:10 UTC"
  },
  {
    "arxiv_id": "2502.15398v1",
    "title": "Enhancing Vehicle Make and Model Recognition with 3D Attention Modules",
    "authors": [
      "Narges Semiromizadeh",
      "Omid Nejati Manzari",
      "Shahriar B. Shokouhi",
      "Sattar Mirzakuchaki"
    ],
    "abstract": "Vehicle make and model recognition (VMMR) is a crucial component of the\nIntelligent Transport System, garnering significant attention in recent years.\nVMMR has been widely utilized for detecting suspicious vehicles, monitoring\nurban traffic, and autonomous driving systems. The complexity of VMMR arises\nfrom the subtle visual distinctions among vehicle models and the wide variety\nof classes produced by manufacturers. Convolutional Neural Networks (CNNs), a\nprominent type of deep learning model, have been extensively employed in\nvarious computer vision tasks, including VMMR, yielding remarkable results. As\nVMMR is a fine-grained classification problem, it primarily faces inter-class\nsimilarity and intra-class variation challenges. In this study, we implement an\nattention module to address these challenges and enhance the model's focus on\ncritical areas containing distinguishing features. This module, which does not\nincrease the parameters of the original model, generates three-dimensional\n(3-D) attention weights to refine the feature map. Our proposed model\nintegrates the attention module into two different locations within the middle\nsection of a convolutional model, where the feature maps from these sections\noffer sufficient information about the input frames without being overly\ndetailed or overly coarse. The performance of our proposed model, along with\nstate-of-the-art (SOTA) convolutional and transformer-based models, was\nevaluated using the Stanford Cars dataset. Our proposed model achieved the\nhighest accuracy, 90.69\\%, among the compared models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15398v1",
    "published_date": "2025-02-21 11:52:56 UTC",
    "updated_date": "2025-02-21 11:52:56 UTC"
  },
  {
    "arxiv_id": "2502.15397v1",
    "title": "Super-Resolution for Interferometric Imaging: Model Comparisons and Performance Analysis",
    "authors": [
      "Hasan Berkay Abdioglu",
      "Rana Gursoy",
      "Yagmur Isik",
      "Ibrahim Cem Balci",
      "Taha Unal",
      "Kerem Bayer",
      "Mustafa Ismail Inal",
      "Nehir Serin",
      "Muhammed Furkan Kosar",
      "Gokhan Bora Esmer",
      "Huseyin Uvet"
    ],
    "abstract": "This study investigates the application of Super-Resolution techniques in\nholographic microscopy to enhance quantitative phase imaging. An off-axis\nMach-Zehnder interferometric setup was employed to capture interferograms. The\nstudy evaluates two Super-Resolution models, RCAN and Real-ESRGAN, for their\neffectiveness in reconstructing high-resolution interferograms from a\nmicroparticle-based dataset. The models were assessed using two primary\napproaches: image-based analysis for structural detail enhancement and\nmorphological evaluation for maintaining sample integrity and phase map\naccuracy. The results demonstrate that RCAN achieves superior numerical\nprecision, making it ideal for applications requiring highly accurate phase map\nreconstruction, while Real-ESRGAN enhances visual quality and structural\ncoherence, making it suitable for visualization-focused applications. This\nstudy highlights the potential of Super-Resolution models in overcoming\ndiffraction-imposed resolution limitations in holographic microscopy, opening\nthe way for improved imaging techniques in biomedical diagnostics, materials\nscience, and other high-precision fields.",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15397v1",
    "published_date": "2025-02-21 11:50:57 UTC",
    "updated_date": "2025-02-21 11:50:57 UTC"
  },
  {
    "arxiv_id": "2502.15392v1",
    "title": "Chitrarth: Bridging Vision and Language for a Billion People",
    "authors": [
      "Shaharukh Khan",
      "Ayush Tarun",
      "Abhinav Ravi",
      "Ali Faraz",
      "Akshat Patidar",
      "Praveen Kumar Pokala",
      "Anagha Bhangare",
      "Raja Kolla",
      "Chandra Khatri",
      "Shubham Agarwal"
    ],
    "abstract": "Recent multimodal foundation models are primarily trained on English or high\nresource European language data, which hinders their applicability to other\nmedium and low-resource languages. To address this limitation, we introduce\nChitrarth (Chitra: Image; Artha: Meaning), an inclusive Vision-Language Model\n(VLM), specifically targeting the rich linguistic diversity and visual\nreasoning across 10 prominent Indian languages. Our model effectively\nintegrates a state-of-the-art (SOTA) multilingual Large Language Model (LLM)\nwith a vision module, primarily trained on multilingual image-text data.\nFurthermore, we also introduce BharatBench, a comprehensive framework for\nevaluating VLMs across various Indian languages, ultimately contributing to\nmore diverse and effective AI systems. Our model achieves SOTA results for\nbenchmarks across low resource languages while retaining its efficiency in\nEnglish. Through our research, we aim to set new benchmarks in\nmultilingual-multimodal capabilities, offering substantial improvements over\nexisting models and establishing a foundation to facilitate future advancements\nin this arena.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15392v1",
    "published_date": "2025-02-21 11:38:40 UTC",
    "updated_date": "2025-02-21 11:38:40 UTC"
  },
  {
    "arxiv_id": "2502.17500v1",
    "title": "Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm",
    "authors": [
      "Andrzej Cichocki"
    ],
    "abstract": "In this paper we propose and investigate a new class of Generalized\nExponentiated Gradient (GEG) algorithms using Mirror Descent (MD) approaches,\nand applying as a regularization function the Bregman divergence with\ntwo-parameter deformation of logarithm as a link function. This link function\n(referred to as the Euler logarithm) is associated with a wide class of\ngeneralized entropies. In order to derive novel GEG/MD updates, we estimate\ngeneralized exponential function, which closely approximates the inverse of the\nEuler two-parameter logarithm. The characteristic/shape and properties of the\nEuler logarithm and its inverse -- deformed exponential functions are tuned by\ntwo or even more hyperparameters. By learning these hyperparameters, we can\nadapt to distribution of training data, and we can adjust them to achieve\ndesired properties of gradient descent algorithms. The concept of generalized\nentropies and associated deformed logarithms provide deeper insight into novel\ngradient descent updates.\n  In literature, there exist nowadays over fifty mathematically well-defined\nentropic functionals and associated deformed logarithms, so impossible to\ninvestigate all of them in one research paper. Therefore, we focus here on a\nwide-class of trace-form entropies and associated generalized logarithm. We\napplied the developed algorithms for Online Portfolio Selection (OPLS) in order\nto improve its performance and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, preprint of Journal paper",
    "pdf_url": "http://arxiv.org/pdf/2502.17500v1",
    "published_date": "2025-02-21 11:05:04 UTC",
    "updated_date": "2025-02-21 11:05:04 UTC"
  },
  {
    "arxiv_id": "2502.15365v2",
    "title": "Identifying Features that Shape Perceived Consciousness in Large Language Model-based AI: A Quantitative Study of Human Responses",
    "authors": [
      "Bongsu Kang",
      "Jundong Kim",
      "Tae-Rim Yun",
      "Hyojin Bae",
      "Chang-Eop Kim"
    ],
    "abstract": "This study quantitively examines which features of AI-generated text lead\nhumans to perceive subjective consciousness in large language model (LLM)-based\nAI systems. Drawing on 99 passages from conversations with Claude 3 Opus and\nfocusing on eight features -- metacognitive self-reflection, logical reasoning,\nempathy, emotionality, knowledge, fluency, unexpectedness, and subjective\nexpressiveness -- we conducted a survey with 123 participants. Using regression\nand clustering analyses, we investigated how these features influence\nparticipants' perceptions of AI consciousness. The results reveal that\nmetacognitive self-reflection and the AI's expression of its own emotions\nsignificantly increased perceived consciousness, while a heavy emphasis on\nknowledge reduced it. Participants clustered into seven subgroups, each showing\ndistinct feature-weighting patterns. Additionally, higher prior knowledge of\nLLMs and more frequent usage of LLM-based chatbots were associated with greater\noverall likelihood assessments of AI consciousness. This study underscores the\nmultidimensional and individualized nature of perceived AI consciousness and\nprovides a foundation for better understanding the psychosocial implications of\nhuman-AI interaction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "I.2.7; K.4"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 3 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15365v2",
    "published_date": "2025-02-21 10:27:28 UTC",
    "updated_date": "2025-02-25 01:40:03 UTC"
  },
  {
    "arxiv_id": "2502.15861v1",
    "title": "C3AI: Crafting and Evaluating Constitutions for Constitutional AI",
    "authors": [
      "Yara Kyrychenko",
      "Ke Zhou",
      "Edyta Bogucka",
      "Daniele Quercia"
    ],
    "abstract": "Constitutional AI (CAI) guides LLM behavior using constitutions, but\nidentifying which principles are most effective for model alignment remains an\nopen challenge. We introduce the C3AI framework (\\textit{Crafting Constitutions\nfor CAI models}), which serves two key functions: (1) selecting and structuring\nprinciples to form effective constitutions before fine-tuning; and (2)\nevaluating whether fine-tuned CAI models follow these principles in practice.\nBy analyzing principles from AI and psychology, we found that positively\nframed, behavior-based principles align more closely with human preferences\nthan negatively framed or trait-based principles. In a safety alignment use\ncase, we applied a graph-based principle selection method to refine an existing\nCAI constitution, improving safety measures while maintaining strong general\nreasoning capabilities. Interestingly, fine-tuned CAI models performed well on\nnegatively framed principles but struggled with positively framed ones, in\ncontrast to our human alignment results. This highlights a potential gap\nbetween principle design and model adherence. Overall, C3AI provides a\nstructured and scalable approach to both crafting and evaluating CAI\nconstitutions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This has been accepted for the Web Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15861v1",
    "published_date": "2025-02-21 10:26:42 UTC",
    "updated_date": "2025-02-21 10:26:42 UTC"
  },
  {
    "arxiv_id": "2502.15860v2",
    "title": "Synthetic vs. Gold: The Role of LLM-Generated Labels and Data in Cyberbullying Detection",
    "authors": [
      "Arefeh Kazemi",
      "Sri Balaaji Natarajan Kalaivendan",
      "Joachim Wagner",
      "Hamza Qadeer",
      "Brian Davis"
    ],
    "abstract": "Cyberbullying (CB) presents a pressing threat, especially to children,\nunderscoring the urgent need for robust detection systems to ensure online\nsafety. However, progress in developing such systems is hindered by the\nscarcity of large, labeled datasets that are specifically tailored for\nspecialized tasks and the target age groups. Creating these datasets relies\nheavily on human annotation, which not only strains resources but also raises\nsignificant ethical and legal concerns due to annotators' exposure to harmful\ncontent, notwithstanding the acquisition of this type of data from vulnerable\npopulations such as children. In this paper, we address these challenges by\nleveraging Large Language Models (LLMs) to generate synthetic data and labels.\nOur experiments demonstrate that synthetic data enables BERT-based CB\nclassifiers to achieve performance close to that of those trained on fully\nauthentic datasets (75.8% vs. 81.5% accuracy). Additionally, LLMs can\neffectively label authentic yet unlabeled data, allowing BERT classifiers to\nattain a comparable performance level (79.1% vs. 81.5% accuracy). These results\nhighlight the potential of LLMs as a scalable, ethical, and cost-effective\nsolution for generating data for CB detection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15860v2",
    "published_date": "2025-02-21 10:17:29 UTC",
    "updated_date": "2025-04-05 09:42:07 UTC"
  },
  {
    "arxiv_id": "2502.15859v3",
    "title": "AI Governance InternationaL Evaluation Index (AGILE Index)",
    "authors": [
      "Yi Zeng",
      "Enmeng Lu",
      "Xin Guan",
      "Cunqing Huangfu",
      "Zizhe Ruan",
      "Ammar Younas",
      "Kang Sun",
      "Xuan Tang",
      "Yuwei Wang",
      "Hongjie Suo",
      "Dongqi Liang",
      "Zhengqiang Han",
      "Aorigele Bao",
      "Xiaoyang Guo",
      "Jin Wang",
      "Jiawei Xie",
      "Yao Liang"
    ],
    "abstract": "The rapid advancement of Artificial Intelligence (AI) technology is\nprofoundly transforming human society and concurrently presenting a series of\nethical, legal, and social issues. The effective governance of AI has become a\ncrucial global concern. Since 2022, the extensive deployment of generative AI,\nparticularly large language models, marked a new phase in AI governance.\nContinuous efforts are being made by the international community in actively\naddressing the novel challenges posed by these AI developments. As consensus on\ninternational governance continues to be established and put into action, the\npractical importance of conducting a global assessment of the state of AI\ngovernance is progressively coming to light. In this context, we initiated the\ndevelopment of the AI Governance InternationaL Evaluation Index (AGILE Index).\nAdhering to the design principle, \"the level of governance should match the\nlevel of development,\" the inaugural evaluation of the AGILE Index commences\nwith an exploration of four foundational pillars: the development level of AI,\nthe AI governance environment, the AI governance instruments, and the AI\ngovernance effectiveness. It covers 39 indicators across 18 dimensions to\ncomprehensively assess the AI governance level of 14 representative countries\nglobally. The index is utilized to delve into the status of AI governance to\ndate in 14 countries for the first batch of evaluation. The aim is to depict\nthe current state of AI governance in these countries through data scoring,\nassist them in identifying their governance stage and uncovering governance\nissues, and ultimately offer insights for the enhancement of their AI\ngovernance systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68T01",
      "A.1"
    ],
    "primary_category": "cs.CY",
    "comment": "Evaluation Report. 85 pages, 30 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15859v3",
    "published_date": "2025-02-21 10:16:56 UTC",
    "updated_date": "2025-03-04 07:10:54 UTC"
  },
  {
    "arxiv_id": "2502.15361v1",
    "title": "Evaluating Social Biases in LLM Reasoning",
    "authors": [
      "Xuyang Wu",
      "Jinming Nian",
      "Zhiqiang Tao",
      "Yi Fang"
    ],
    "abstract": "In the recent development of AI reasoning, large language models (LLMs) are\ntrained to automatically generate chain-of-thought reasoning steps, which have\ndemonstrated compelling performance on math and coding tasks. However, when\nbias is mixed within the reasoning process to form strong logical arguments, it\ncould cause even more harmful results and further induce hallucinations. In\nthis paper, we have evaluated the 8B and 32B variants of DeepSeek-R1 against\ntheir instruction tuned counterparts on the BBQ dataset, and investigated the\nbias that is elicited out and being amplified through reasoning steps. To the\nbest of our knowledge, this empirical study is the first to assess bias issues\nin LLM reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15361v1",
    "published_date": "2025-02-21 10:16:07 UTC",
    "updated_date": "2025-02-21 10:16:07 UTC"
  },
  {
    "arxiv_id": "2502.15359v3",
    "title": "ARS: Automatic Routing Solver with Large Language Models",
    "authors": [
      "Kai Li",
      "Fei Liu",
      "Zhenkun Wang",
      "Xialiang Tong",
      "Xiongwei Han",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "abstract": "Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of\npractical constraints, making manual solver design both knowledge-intensive and\ntime-consuming. Although there is increasing interest in automating the design\nof routing algorithms, existing research has explored only a limited array of\nVRP variants and fails to adequately address the complex and prevalent\nconstraints encountered in real-world situations. To fill this gap, this paper\nintroduces RoutBench, a benchmark of 1,000 VRP variants derived from 24\nattributes, for evaluating the effectiveness of automatic routing solvers in\naddressing complex constraints. Along with RoutBench, we present the Automatic\nRouting Solver (ARS), which employs Large Language Model (LLM) agents to\nenhance a backbone algorithm framework by automatically generating\nconstraint-aware heuristic code, based on problem descriptions and several\nrepresentative constraints selected from a database. Our experiments show that\nARS outperforms state-of-the-art LLM-based methods and commonly used solvers,\nautomatically solving 91.67% of common VRPs and achieving at least a 30%\nimprovement across all benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Authorship is under discussion; arXiv release will follow\n  finalization",
    "pdf_url": "http://arxiv.org/pdf/2502.15359v3",
    "published_date": "2025-02-21 10:14:55 UTC",
    "updated_date": "2025-05-19 08:29:41 UTC"
  },
  {
    "arxiv_id": "2502.15357v1",
    "title": "Integrating Generative AI in Cybersecurity Education: Case Study Insights on Pedagogical Strategies, Critical Thinking, and Responsible AI Use",
    "authors": [
      "Mahmoud Elkhodr",
      "Ergun Gide"
    ],
    "abstract": "The rapid advancement of Generative Artificial Intelligence (GenAI) has\nintroduced new opportunities for transforming higher education, particularly in\nfields that require analytical reasoning and regulatory compliance, such as\ncybersecurity management. This study presents a structured framework for\nintegrating GenAI tools into cybersecurity education, demonstrating their role\nin fostering critical thinking, real-world problem-solving, and regulatory\nawareness. The implementation strategy followed a two-stage approach, embedding\nGenAI within tutorial exercises and assessment tasks. Tutorials enabled\nstudents to generate, critique, and refine AI-assisted cybersecurity policies,\nwhile assessments required them to apply AI-generated outputs to real-world\nscenarios, ensuring alignment with industry standards and regulatory\nrequirements. Findings indicate that AI-assisted learning significantly\nenhanced students' ability to evaluate security policies, refine risk\nassessments, and bridge theoretical knowledge with practical application.\nStudent reflections and instructor observations revealed improvements in\nanalytical engagement, yet challenges emerged regarding AI over-reliance,\nvariability in AI literacy, and the contextual limitations of AI-generated\ncontent. Through structured intervention and research-driven refinement,\nstudents were able to recognize AI strengths as a generative tool while\nacknowledging its need for human oversight. This study further highlights the\nbroader implications of AI adoption in cybersecurity education, emphasizing the\nnecessity of balancing automation with expert judgment to cultivate\nindustry-ready professionals. Future research should explore the long-term\nimpact of AI-driven learning on cybersecurity competency, as well as the\npotential for adaptive AI-assisted assessments to further personalize and\nenhance educational outcomes.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68T05",
      "I.2.6; I.2.7; K.3.1; K.3.2"
    ],
    "primary_category": "cs.CY",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15357v1",
    "published_date": "2025-02-21 10:14:07 UTC",
    "updated_date": "2025-02-21 10:14:07 UTC"
  },
  {
    "arxiv_id": "2502.15348v1",
    "title": "Constructing a Norm for Children's Scientific Drawing: Distribution Features Based on Semantic Similarity of Large Language Models",
    "authors": [
      "Yi Zhang",
      "Fan Wei",
      "Jingyi Li",
      "Yan Wang",
      "Yanyan Yu",
      "Jianli Chen",
      "Zipo Cai",
      "Xinyu Liu",
      "Wei Wang",
      "Peng Wang",
      "Zhong Wang"
    ],
    "abstract": "The use of children's drawings to examining their conceptual understanding\nhas been proven to be an effective method, but there are two major problems\nwith previous research: 1. The content of the drawings heavily relies on the\ntask, and the ecological validity of the conclusions is low; 2. The\ninterpretation of drawings relies too much on the subjective feelings of the\nresearchers. To address this issue, this study uses the Large Language Model\n(LLM) to identify 1420 children's scientific drawings (covering 9 scientific\nthemes/concepts), and uses the word2vec algorithm to calculate their semantic\nsimilarity. The study explores whether there are consistent drawing\nrepresentations for children on the same theme, and attempts to establish a\nnorm for children's scientific drawings, providing a baseline reference for\nfollow-up children's drawing research. The results show that the representation\nof most drawings has consistency, manifested as most semantic similarity\ngreater than 0.8. At the same time, it was found that the consistency of the\nrepresentation is independent of the accuracy (of LLM's recognition),\nindicating the existence of consistency bias. In the subsequent exploration of\ninfluencing factors, we used Kendall rank correlation coefficient to\ninvestigate the effects of Sample Size, Abstract Degree, and Focus Points on\ndrawings, and used word frequency statistics to explore whether children\nrepresented abstract themes/concepts by reproducing what was taught in class.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15348v1",
    "published_date": "2025-02-21 10:02:15 UTC",
    "updated_date": "2025-02-21 10:02:15 UTC"
  },
  {
    "arxiv_id": "2504.05317v1",
    "title": "On Synthesizing Data for Context Attribution in Question Answering",
    "authors": [
      "Gorjan Radevski",
      "Kiril Gashteovski",
      "Shahbaz Syed",
      "Christopher Malon",
      "Sebastien Nicolas",
      "Chia-Chien Hung",
      "Timo Sztyler",
      "Verena HeuÃer",
      "Wiem Ben Rim",
      "Masafumi Enomoto",
      "Kunihiro Takeoka",
      "Masafumi Oyamada",
      "Goran GlavaÅ¡",
      "Carolin Lawrence"
    ],
    "abstract": "Question Answering (QA) accounts for a significant portion of LLM usage \"in\nthe wild\". However, LLMs sometimes produce false or misleading responses, also\nknown as \"hallucinations\". Therefore, grounding the generated answers in\ncontextually provided information -- i.e., providing evidence for the generated\ntext -- is paramount for LLMs' trustworthiness. Providing this information is\nthe task of context attribution. In this paper, we systematically study\nLLM-based approaches for this task, namely we investigate (i) zero-shot\ninference, (ii) LLM ensembling, and (iii) fine-tuning of small LMs on synthetic\ndata generated by larger LLMs. Our key contribution is SynQA: a novel\ngenerative strategy for synthesizing context attribution data. Given selected\ncontext sentences, an LLM generates QA pairs that are supported by these\nsentences. This leverages LLMs' natural strengths in text generation while\nensuring clear attribution paths in the synthetic training data. We show that\nthe attribution data synthesized via SynQA is highly effective for fine-tuning\nsmall LMs for context attribution in different QA tasks and domains. Finally,\nwith a user study, we validate the usefulness of small LMs (fine-tuned on\nsynthetic data from SynQA) in context attribution for QA.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05317v1",
    "published_date": "2025-02-21 09:43:18 UTC",
    "updated_date": "2025-02-21 09:43:18 UTC"
  },
  {
    "arxiv_id": "2502.15336v1",
    "title": "Exploring Embodied Multimodal Large Models: Development, Datasets, and Future Directions",
    "authors": [
      "Shoubin Chen",
      "Zehao Wu",
      "Kai Zhang",
      "Chunyu Li",
      "Baiyang Zhang",
      "Fei Ma",
      "Fei Richard Yu",
      "Qingquan Li"
    ],
    "abstract": "Embodied multimodal large models (EMLMs) have gained significant attention in\nrecent years due to their potential to bridge the gap between perception,\ncognition, and action in complex, real-world environments. This comprehensive\nreview explores the development of such models, including Large Language Models\n(LLMs), Large Vision Models (LVMs), and other models, while also examining\nother emerging architectures. We discuss the evolution of EMLMs, with a focus\non embodied perception, navigation, interaction, and simulation. Furthermore,\nthe review provides a detailed analysis of the datasets used for training and\nevaluating these models, highlighting the importance of diverse, high-quality\ndata for effective learning. The paper also identifies key challenges faced by\nEMLMs, including issues of scalability, generalization, and real-time\ndecision-making. Finally, we outline future directions, emphasizing the\nintegration of multimodal sensing, reasoning, and action to advance the\ndevelopment of increasingly autonomous systems. By providing an in-depth\nanalysis of state-of-the-art methods and identifying critical gaps, this paper\naims to inspire future advancements in EMLMs and their applications across\ndiverse domains.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "81 pages, submitted to a journal for review",
    "pdf_url": "http://arxiv.org/pdf/2502.15336v1",
    "published_date": "2025-02-21 09:41:27 UTC",
    "updated_date": "2025-02-21 09:41:27 UTC"
  },
  {
    "arxiv_id": "2502.15334v1",
    "title": "Attention Eclipse: Manipulating Attention to Bypass LLM Safety-Alignment",
    "authors": [
      "Pedram Zaree",
      "Md Abdullah Al Mamun",
      "Quazi Mishkatul Alam",
      "Yue Dong",
      "Ihsen Alouani",
      "Nael Abu-Ghazaleh"
    ],
    "abstract": "Recent research has shown that carefully crafted jailbreak inputs can induce\nlarge language models to produce harmful outputs, despite safety measures such\nas alignment. It is important to anticipate the range of potential Jailbreak\nattacks to guide effective defenses and accurate assessment of model safety. In\nthis paper, we present a new approach for generating highly effective Jailbreak\nattacks that manipulate the attention of the model to selectively strengthen or\nweaken attention among different parts of the prompt. By harnessing attention\nloss, we develop more effective jailbreak attacks, that are also transferrable.\nThe attacks amplify the success rate of existing Jailbreak algorithms including\nGCG, AutoDAN, and ReNeLLM, while lowering their generation cost (for example,\nthe amplified GCG attack achieves 91.2% ASR, vs. 67.9% for the original attack\non Llama2-7B/AdvBench, using less than a third of the generation time).",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15334v1",
    "published_date": "2025-02-21 09:38:00 UTC",
    "updated_date": "2025-02-21 09:38:00 UTC"
  },
  {
    "arxiv_id": "2502.15331v2",
    "title": "Lightweight yet Efficient: An External Attentive Graph Convolutional Network with Positional Prompts for Sequential Recommendation",
    "authors": [
      "Jinyu Zhang",
      "Chao Li",
      "Zhongying Zhao"
    ],
    "abstract": "Graph-based Sequential Recommender systems (GSRs) have gained significant\nresearch attention due to their ability to simultaneously handle user-item\ninteractions and sequential relationships between items. Current GSRs often\nutilize composite or in-depth structures for graph encoding (e.g., the Graph\nTransformer). Nevertheless, they have high computational complexity, hindering\nthe deployment on resource-constrained edge devices. Moreover, the relative\nposition encoding in Graph Transformer has difficulty in considering the\ncomplicated positional dependencies within sequence. To this end, we propose an\nExternal Attentive Graph convolutional network with Positional prompts for\nSequential recommendation, namely EA-GPS. Specifically, we first introduce an\nexternal attentive graph convolutional network that linearly measures the\nglobal associations among nodes via two external memory units. Then, we present\na positional prompt-based decoder that explicitly treats the absolute item\npositions as external prompts. By introducing length-adaptive sequential\nmasking and a soft attention network, such a decoder facilitates the model to\ncapture the long-term positional dependencies and contextual relationships\nwithin sequences. Extensive experimental results on five real-world datasets\ndemonstrate that the proposed EA-GPS outperforms the state-of-the-art methods.\nRemarkably, it achieves the superior performance while maintaining a smaller\nparameter size and lower training overhead. The implementation of this work is\npublicly available at https://github.com/ZZY-GraphMiningLab/EA-GPS.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "26 pages, 8 figures, journal paper, accepted by TOIS at 20th\n  February, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15331v2",
    "published_date": "2025-02-21 09:34:31 UTC",
    "updated_date": "2025-03-04 02:18:36 UTC"
  },
  {
    "arxiv_id": "2502.15322v1",
    "title": "SentiFormer: Metadata Enhanced Transformer for Image Sentiment Analysis",
    "authors": [
      "Bin Feng",
      "Shulan Ruan",
      "Mingzheng Yang",
      "Dongxuan Han",
      "Huijie Liu",
      "Kai Zhang",
      "Qi Liu"
    ],
    "abstract": "As more and more internet users post images online to express their daily\nemotions, image sentiment analysis has attracted increasing attention.\nRecently, researchers generally tend to design different neural networks to\nextract visual features from images for sentiment analysis. Despite the\nsignificant progress, metadata, the data (e.g., text descriptions and keyword\ntags) for describing the image, has not been sufficiently explored in this\ntask. In this paper, we propose a novel Metadata Enhanced Transformer for\nsentiment analysis (SentiFormer) to fuse multiple metadata and the\ncorresponding image into a unified framework. Specifically, we first obtain\nmultiple metadata of the image and unify the representations of diverse data.\nTo adaptively learn the appropriate weights for each metadata, we then design\nan adaptive relevance learning module to highlight more effective information\nwhile suppressing weaker ones. Moreover, we further develop a cross-modal\nfusion module to fuse the adaptively learned representations and make the final\nprediction. Extensive experiments on three publicly available datasets\ndemonstrate the superiority and rationality of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15322v1",
    "published_date": "2025-02-21 09:22:23 UTC",
    "updated_date": "2025-02-21 09:22:23 UTC"
  },
  {
    "arxiv_id": "2502.15307v1",
    "title": "Road Traffic Sign Recognition method using Siamese network Combining Efficient-CNN based Encoder",
    "authors": [
      "Zhenghao Xi",
      "Yuchao Shao",
      "Yang Zheng",
      "Xiang Liu",
      "Yaqi Liu",
      "Yitong Cai"
    ],
    "abstract": "Traffic signs recognition (TSR) plays an essential role in assistant driving\nand intelligent transportation system. However, the noise of complex\nenvironment may lead to motion-blur or occlusion problems, which raise the\ntough challenge to real-time recognition with high accuracy and robust. In this\narticle, we propose IECES-network which with improved encoders and Siamese net.\nThe three-stage approach of our method includes Efficient-CNN based encoders,\nSiamese backbone and the fully-connected layers. We firstly use convolutional\nencoders to extract and encode the traffic sign features of augmented training\nsamples and standard images. Then, we design the Siamese neural network with\nEfficient-CNN based encoder and contrastive loss function, which can be trained\nto improve the robustness of TSR problem when facing the samples of motion-blur\nand occlusion by computing the distance between inputs and templates.\nAdditionally, the template branch of the proposed network can be stopped when\nexecuting the recognition tasks after training to raise the process speed of\nour real-time model, and alleviate the computational resource and parameter\nscale. Finally, we recombined the feature code and a fully-connected layer with\nSoftMax function to classify the codes of samples and recognize the category of\ntraffic signs. The results of experiments on the Tsinghua-Tencent 100K dataset\nand the German Traffic Sign Recognition Benchmark dataset demonstrate the\nperformance of the proposed IECESnetwork. Compared with other state-of-the-art\nmethods, in the case of motion-blur and occluded environment, the proposed\nmethod achieves competitive performance precision-recall and accuracy metric\naverage is 88.1%, 86.43% and 86.1% with a 2.9M lightweight scale, respectively.\nMoreover, processing time of our model is 0.1s per frame, of which the speed is\nincreased by 1.5 times compared with existing methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15307v1",
    "published_date": "2025-02-21 09:03:05 UTC",
    "updated_date": "2025-02-21 09:03:05 UTC"
  },
  {
    "arxiv_id": "2502.15304v1",
    "title": "SVDq: 1.25-bit and 410x Key Cache Compression for LLM Attention",
    "authors": [
      "Hong Yankun",
      "Li Xing",
      "Zhen Hui-Ling",
      "Yu Xianzhi",
      "Liu Wulong",
      "Yuan Mingxuan"
    ],
    "abstract": "For the efficient inference of Large Language Models (LLMs), the effective\ncompression of key-value (KV) cache is essential. Three main types of KV cache\ncompression techniques, namely sparsity, channel compression, and quantization,\nhave been identified. This study presents SVDq, a Singular Value Decomposition\n(SVD) - based mixed precision quantization method for K cache. Initially, K\ncache is transformed into latent channels using SVD basis representations.\nSince the values in latent channels decay rapidly and become negligible after\nonly a few latent channels, our method then incorporates importance-aware\nquantization and compression for latent channels. This enables the effective\nallocation of higher precision to more significant channels. Theoretically, we\nprove that SVDq results in quantization errors (x0.1 or even lower) that are\nmuch lower than those of per-channel key quantization in the original space.\nOur findings based on RULER and LongBench benchmarks demonstrate that SVDq can\nachieve an equivalent key cache precision as low as 1.25-bit. When combined\nwith key sparsity, it can reach a key compression ratio of up to 410x for\nattention computation, all while maintaining comparable model performance.\nNotably, our method is nearly lossless for LongBench datasets. This indicates\nthat SVDq enables high-precision low-bit quantization, providing a more\nefficient solution for KV cache compression in LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15304v1",
    "published_date": "2025-02-21 08:55:21 UTC",
    "updated_date": "2025-02-21 08:55:21 UTC"
  },
  {
    "arxiv_id": "2502.15858v1",
    "title": "Generative AI Training and Copyright Law",
    "authors": [
      "Tim W. Dornis",
      "Sebastian Stober"
    ],
    "abstract": "Training generative AI models requires extensive amounts of data. A common\npractice is to collect such data through web scraping. Yet, much of what has\nbeen and is collected is copyright protected. Its use may be copyright\ninfringement. In the USA, AI developers rely on \"fair use\" and in Europe, the\nprevailing view is that the exception for \"Text and Data Mining\" (TDM) applies.\nIn a recent interdisciplinary tandem-study, we have argued in detail that this\nis actually not the case because generative AI training fundamentally differs\nfrom TDM. In this article, we share our main findings and the implications for\nboth public and corporate research on generative models. We further discuss how\nthe phenomenon of training data memorization leads to copyright issues\nindependently from the \"fair use\" and TDM exceptions. Finally, we outline how\nthe ISMIR could contribute to the ongoing discussion about fair practices with\nrespect to generative AI that satisfy all stakeholders.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "submitted as an overview article to the Transactions of the\n  International Society for Music Information Retrieval",
    "pdf_url": "http://arxiv.org/pdf/2502.15858v1",
    "published_date": "2025-02-21 08:45:14 UTC",
    "updated_date": "2025-02-21 08:45:14 UTC"
  },
  {
    "arxiv_id": "2502.15296v1",
    "title": "Beyond Fixed Variables: Expanding-variate Time Series Forecasting via Flat Scheme and Spatio-temporal Focal Learning",
    "authors": [
      "Minbo Ma",
      "Kai Tang",
      "Huan Li",
      "Fei Teng",
      "Dalin Zhang",
      "Tianrui Li"
    ],
    "abstract": "Multivariate Time Series Forecasting (MTSF) has long been a key research\nfocus. Traditionally, these studies assume a fixed number of variables, but in\nreal-world applications, Cyber-Physical Systems often expand as new sensors are\ndeployed, increasing variables in MTSF. In light of this, we introduce a novel\ntask, Expanding-variate Time Series Forecasting (EVTSF). This task presents\nunique challenges, specifically (1) handling inconsistent data shapes caused by\nadding new variables, and (2) addressing imbalanced spatio-temporal learning,\nwhere expanding variables have limited observed data due to the necessity for\ntimely operation. To address these challenges, we propose STEV, a flexible\nspatio-temporal forecasting framework. STEV includes a new Flat Scheme to\ntackle the inconsistent data shape issue, which extends the graph-based\nspatio-temporal modeling architecture into 1D space by flattening the 2D\nsamples along the variable dimension, making the model variable-scale-agnostic\nwhile still preserving dynamic spatial correlations through a holistic graph.\nWe introduce a novel Spatio-temporal Focal Learning strategy that incorporates\na negative filter to resolve potential conflicts between contrastive learning\nand graph representation, and a focal contrastive loss as its core to guide the\nframework to focus on optimizing the expanding variables. We benchmark EVTSF\nperformance using three real-world datasets and compare it against three\npotential solutions employing SOTA MTSF models tailored for EVSTF. Experimental\nresults show that STEV significantly outperforms its competitors, particularly\non expanding variables. Notably, STEV, with only 5% of observations from the\nexpanding period, is on par with SOTA MTSF models trained with complete\nobservations. Further exploration of various expanding strategies underscores\nthe generalizability of STEV in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15296v1",
    "published_date": "2025-02-21 08:43:26 UTC",
    "updated_date": "2025-02-21 08:43:26 UTC"
  },
  {
    "arxiv_id": "2502.15294v2",
    "title": "Round Attention: A Novel Round-Level Attention Mechanism to Accelerate LLM Inference",
    "authors": [
      "Yaohua Tang",
      "Zhicheng Hu",
      "Kun Cheng",
      "Fan Mo",
      "Qiheng Lv",
      "Hua Wang",
      "Zhi Chen"
    ],
    "abstract": "The increasing context window size in large language models (LLMs) has\nimproved their ability to handle complex, long-text tasks. However, as the\nconversation rounds continue, it is required to store a large amount of KV\ncache in GPU memory, which significantly affects the efficiency and even\navailability of the model serving systems. This paper analyzes dialogue data\nfrom real users and discovers that the LLM inference manifests a watershed\nlayer, after which the distribution of round-level attention shows notable\nsimilarity. We propose Round Attention, a novel round-level attention mechanism\nthat only recalls and computes the KV cache of the most relevant rounds. The\nexperiments show that our method saves 55\\% memory usage without compromising\nmodel performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15294v2",
    "published_date": "2025-02-21 08:40:07 UTC",
    "updated_date": "2025-02-24 13:35:18 UTC"
  },
  {
    "arxiv_id": "2503.05750v1",
    "title": "CSTRL: Context-Driven Sequential Transfer Learning for Abstractive Radiology Report Summarization",
    "authors": [
      "Mst. Fahmida Sultana Naznin",
      "Adnan Ibney Faruq",
      "Mostafa Rifat Tazwar",
      "Md Jobayer",
      "Md. Mehedi Hasan Shawon",
      "Md Rakibul Hasan"
    ],
    "abstract": "A radiology report comprises several sections, including the Findings and\nImpression of the diagnosis. Automatically generating the Impression from the\nFindings is crucial for reducing radiologists' workload and improving\ndiagnostic accuracy. Pretrained models that excel in common abstractive\nsummarization problems encounter challenges when applied to specialized medical\ndomains largely due to the complex terminology and the necessity for accurate\nclinical context. Such tasks in medical domains demand extracting core\ninformation, avoiding context shifts, and maintaining proper flow. Misuse of\nmedical terms can lead to drastic clinical errors. To address these issues, we\nintroduce a sequential transfer learning that ensures key content extraction\nand coherent summarization. Sequential transfer learning often faces challenges\nlike initial parameter decay and knowledge loss, which we resolve with the\nFisher matrix regularization. Using MIMIC-CXR and Open-I datasets, our model,\nCSTRL-Context-driven Sequential TRansfer Learning-achieved state-of-the-art\nperformance, showing 56.2% improvement in BLEU-1, 40.5% in BLEU-2, 84.3% in\nBLEU-3, 28.9% in ROUGE-1, 41.0% in ROUGE-2 and 26.5% in ROGUE-3 score over\nbenchmark studies. We also analyze factual consistency scores while preserving\nthe medical context. Our code is publicly available at TBA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11-pages main paper with 2-pages appendices",
    "pdf_url": "http://arxiv.org/pdf/2503.05750v1",
    "published_date": "2025-02-21 08:32:11 UTC",
    "updated_date": "2025-02-21 08:32:11 UTC"
  },
  {
    "arxiv_id": "2502.15287v1",
    "title": "Time Warp: The Gap Between Developers' Ideal vs Actual Workweeks in an AI-Driven Era",
    "authors": [
      "Sukrit Kumar",
      "Drishti Goel",
      "Thomas Zimmermann",
      "Brian Houck",
      "B. Ashok",
      "Chetan Bansal"
    ],
    "abstract": "Software developers balance a variety of different tasks in a workweek, yet\nthe allocation of time often differs from what they consider ideal. Identifying\nand addressing these deviations is crucial for organizations aiming to enhance\nthe productivity and well-being of the developers. In this paper, we present\nthe findings from a survey of 484 software developers at Microsoft, which aims\nto identify the key differences between how developers would like to allocate\ntheir time during an ideal workweek versus their actual workweek. Our analysis\nreveals significant deviations between a developer's ideal workweek and their\nactual workweek, with a clear correlation: as the gap between these two\nworkweeks widens, we observe a decline in both productivity and satisfaction.\nBy examining these deviations in specific activities, we assess their direct\nimpact on the developers' satisfaction and productivity. Additionally, given\nthe growing adoption of AI tools in software engineering, both in the industry\nand academia, we identify specific tasks and areas that could be strong\ncandidates for automation. In this paper, we make three key contributions: 1)\nWe quantify the impact of workweek deviations on developer productivity and\nsatisfaction 2) We identify individual tasks that disproportionately affect\nsatisfaction and productivity 3) We provide actual data-driven insights to\nguide future AI automation efforts in software engineering, aligning them with\nthe developers' requirements and ideal workflows for maximizing their\nproductivity and satisfaction.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "ICSE SEIP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15287v1",
    "published_date": "2025-02-21 08:29:49 UTC",
    "updated_date": "2025-02-21 08:29:49 UTC"
  },
  {
    "arxiv_id": "2502.15285v3",
    "title": "Offload Rethinking by Cloud Assistance for Efficient Environmental Sound Recognition on LPWANs",
    "authors": [
      "Le Zhang",
      "Quanling Zhao",
      "Run Wang",
      "Shirley Bian",
      "Onat Gungor",
      "Flavio Ponzina",
      "Tajana Rosing"
    ],
    "abstract": "Learning-based environmental sound recognition has emerged as a crucial\nmethod for ultra-low-power environmental monitoring in biological research and\ncity-scale sensing systems. These systems usually operate under limited\nresources and are often powered by harvested energy in remote areas. Recent\nefforts in on-device sound recognition suffer from low accuracy due to resource\nconstraints, whereas cloud offloading strategies are hindered by high\ncommunication costs. In this work, we introduce ORCA, a novel\nresource-efficient cloud-assisted environmental sound recognition system on\nbatteryless devices operating over the Low-Power Wide-Area Networks (LPWANs),\ntargeting wide-area audio sensing applications. We propose a cloud assistance\nstrategy that remedies the low accuracy of on-device inference while minimizing\nthe communication costs for cloud offloading. By leveraging a\nself-attention-based cloud sub-spectral feature selection method to facilitate\nefficient on-device inference, ORCA resolves three key challenges for\nresource-constrained cloud offloading over LPWANs: 1) high communication costs\nand low data rates, 2) dynamic wireless channel conditions, and 3) unreliable\noffloading. We implement ORCA on an energy-harvesting batteryless\nmicrocontroller and evaluate it in a real world urban sound testbed. Our\nresults show that ORCA outperforms state-of-the-art methods by up to $80\n\\times$ in energy savings and $220 \\times$ in latency reduction while\nmaintaining comparable accuracy.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.DC",
      "cs.NI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by The 23rd ACM Conference on Embedded Networked Sensor\n  Systems (SenSys '25)",
    "pdf_url": "http://arxiv.org/pdf/2502.15285v3",
    "published_date": "2025-02-21 08:23:32 UTC",
    "updated_date": "2025-03-21 11:01:05 UTC"
  },
  {
    "arxiv_id": "2502.17499v2",
    "title": "Detecting Long QT Syndrome and First-Degree Atrioventricular Block using Single-Lead AI-ECG: A Multi-Center Real-World Study",
    "authors": [
      "Sumei Fan",
      "Deyun Zhang",
      "Yue Wang",
      "Shijia Geng",
      "Kun Lu",
      "Meng Sang",
      "Weilun Xu",
      "Haixue Wang",
      "Qinghao Zhao",
      "Chuandong Cheng",
      "Peng Wang",
      "Shenda Hong"
    ],
    "abstract": "Home-based single-lead AI-ECG devices have enabled continuous, real-world\ncardiac monitoring. However, the accuracy of parameter calculations from\nsingle-lead AI-ECG algorithm remains to be fully validated, which is critical\nfor conditions such as Long QT Syndrome (LQTS) and First-Degree\nAtrioventricular Block (AVBI). In this multicenter study, we assessed\nFeatureDB, an ECG measurements computation algorithm, in the context of\nsingle-lead monitoring using three annotated datasets: PTB-XL+ (n=21,354), CSE\n(n=105), and HeartVoice-ECG-lite (n=369). FeatureDB showed strong correlation\nwith standard ECG machines (12SL and Uni-G) in key measurements (PR, QRS, QT,\nQTc), and high agreement confirmed by Bland-Altman analysis. In detecting LQTS\n(AUC=0.786) and AVBI (AUC=0.684), FeatureDB demonstrated diagnostic performance\ncomparable to commercial ECG systems (12SL: 0.859/0.716; Uni-G: 0.817/0.605),\nsignificantly outperforming ECGDeli (0.501/0.569). Notably, FeatureDB can\noperate locally on resource-limited devices, facilitating use in\nlow-connectivity settings. These findings confirm the clinical reliability of\nFeatureDB for single-lead ECG diagnostics and highlight its potential to bridge\ntraditional ECG diagnostics with wearable technology for scalable\ncardiovascular monitoring and early intervention.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "eess.SP",
    "comment": "29pages, 11 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.17499v2",
    "published_date": "2025-02-21 08:11:17 UTC",
    "updated_date": "2025-04-27 02:46:38 UTC"
  },
  {
    "arxiv_id": "2502.15278v1",
    "title": "CopyJudge: Automated Copyright Infringement Identification and Mitigation in Text-to-Image Diffusion Models",
    "authors": [
      "Shunchang Liu",
      "Zhuan Shi",
      "Lingjuan Lyu",
      "Yaochu Jin",
      "Boi Faltings"
    ],
    "abstract": "Assessing whether AI-generated images are substantially similar to\ncopyrighted works is a crucial step in resolving copyright disputes. In this\npaper, we propose CopyJudge, an automated copyright infringement identification\nframework that leverages large vision-language models (LVLMs) to simulate\npractical court processes for determining substantial similarity between\ncopyrighted images and those generated by text-to-image diffusion models.\nSpecifically, we employ an abstraction-filtration-comparison test framework\nwith multi-LVLM debate to assess the likelihood of infringement and provide\ndetailed judgment rationales. Based on the judgments, we further introduce a\ngeneral LVLM-based mitigation strategy that automatically optimizes infringing\nprompts by avoiding sensitive expressions while preserving the non-infringing\ncontent. Besides, our approach can be enhanced by exploring non-infringing\nnoise vectors within the diffusion latent space via reinforcement learning,\neven without modifying the original prompts. Experimental results show that our\nidentification method achieves comparable state-of-the-art performance, while\noffering superior generalization and interpretability across various forms of\ninfringement, and that our mitigation method could more effectively mitigate\nmemorization and IP infringement without losing non-infringing expressions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15278v1",
    "published_date": "2025-02-21 08:09:07 UTC",
    "updated_date": "2025-02-21 08:09:07 UTC"
  },
  {
    "arxiv_id": "2502.18501v1",
    "title": "Deep Learning-based Dual Watermarking for Image Copyright Protection and Authentication",
    "authors": [
      "Sudev Kumar Padhi",
      "Archana Tiwari",
      "Sk. Subidh Ali"
    ],
    "abstract": "Advancements in digital technologies make it easy to modify the content of\ndigital images. Hence, ensuring digital images integrity and authenticity is\nnecessary to protect them against various attacks that manipulate them. We\npresent a Deep Learning (DL) based dual invisible watermarking technique for\nperforming source authentication, content authentication, and protecting\ndigital content copyright of images sent over the internet. Beyond securing\nimages, the proposed technique demonstrates robustness to content-preserving\nimage manipulations. It is also impossible to imitate or overwrite watermarks\nbecause the cryptographic hash of the image and the dominant features of the\nimage in the form of perceptual hash are used as watermarks. We highlighted the\nneed for source authentication to safeguard image integrity and authenticity,\nalong with identifying similar content for copyright protection. After\nexhaustive testing, we obtained a high peak signal-to-noise ratio (PSNR) and\nstructural similarity index measure (SSIM), which implies there is a minute\nchange in the original image after embedding our watermarks. Our trained model\nachieves high watermark extraction accuracy and to the best of our knowledge,\nthis is the first deep learning-based dual watermarking technique proposed in\nthe literature.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "IEEE Transactions on Artificial Intelligence. 2024 Oct 24",
    "pdf_url": "http://arxiv.org/pdf/2502.18501v1",
    "published_date": "2025-02-21 07:58:39 UTC",
    "updated_date": "2025-02-21 07:58:39 UTC"
  },
  {
    "arxiv_id": "2502.17498v1",
    "title": "Improving Value-based Process Verifier via Structural Prior Injection",
    "authors": [
      "Zetian Sun",
      "Dongfang Li",
      "Baotian Hu",
      "Jun Yu",
      "Min Zhang"
    ],
    "abstract": "In the Large Language Model(LLM) reasoning scenario, people often estimate\nstate value via Monte Carlo sampling. Though Monte Carlo estimation is an\nelegant method with less inductive bias, noise and errors are inevitably\nintroduced due to the limited sampling. To handle the problem, we inject the\nstructural prior into the value representation and transfer the scalar value\ninto the expectation of a pre-defined categorical distribution, representing\nthe noise and errors from a distribution perspective. Specifically, by treating\nthe result of Monte Carlo sampling as a single sample from the prior\nground-truth Binomial distribution, we quantify the sampling error as the\nmismatch between posterior estimated distribution and ground-truth\ndistribution, which is thus optimized via distribution selection optimization.\nWe test the performance of value-based process verifiers on Best-of-N task and\nBeam search task. Compared with the scalar value representation, we show that\nreasonable structural prior injection induced by different objective functions\nor optimization methods can improve the performance of value-based process\nverifiers for about 1$\\sim$2 points at little-to-no cost. We also show that\nunder different structural prior, the verifiers' performances vary greatly\ndespite having the same optimal solution, indicating the importance of\nreasonable structural prior injection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint. Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.17498v1",
    "published_date": "2025-02-21 07:57:59 UTC",
    "updated_date": "2025-02-21 07:57:59 UTC"
  },
  {
    "arxiv_id": "2504.05316v1",
    "title": "Scale Up Composed Image Retrieval Learning via Modification Text Generation",
    "authors": [
      "Yinan Zhou",
      "Yaxiong Wang",
      "Haokun Lin",
      "Chen Ma",
      "Li Zhu",
      "Zhedong Zheng"
    ],
    "abstract": "Composed Image Retrieval (CIR) aims to search an image of interest using a\ncombination of a reference image and modification text as the query. Despite\nrecent advancements, this task remains challenging due to limited training data\nand laborious triplet annotation processes. To address this issue, this paper\nproposes to synthesize the training triplets to augment the training resource\nfor the CIR problem. Specifically, we commence by training a modification text\ngenerator exploiting large-scale multimodal models and scale up the CIR\nlearning throughout both the pretraining and fine-tuning stages. During\npretraining, we leverage the trained generator to directly create Modification\nText-oriented Synthetic Triplets(MTST) conditioned on pairs of images. For\nfine-tuning, we first synthesize reverse modification text to connect the\ntarget image back to the reference image. Subsequently, we devise a two-hop\nalignment strategy to incrementally close the semantic gap between the\nmultimodal pair and the target image. We initially learn an implicit prototype\nutilizing both the original triplet and its reversed version in a cycle manner,\nfollowed by combining the implicit prototype feature with the modification text\nto facilitate accurate alignment with the target image. Extensive experiments\nvalidate the efficacy of the generated triplets and confirm that our proposed\nmethodology attains competitive recall on both the CIRR and FashionIQ\nbenchmarks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05316v1",
    "published_date": "2025-02-21 07:48:55 UTC",
    "updated_date": "2025-02-21 07:48:55 UTC"
  },
  {
    "arxiv_id": "2502.15261v1",
    "title": "Corrections Meet Explanations: A Unified Framework for Explainable Grammatical Error Correction",
    "authors": [
      "Jingheng Ye",
      "Shang Qin",
      "Yinghui Li",
      "Hai-Tao Zheng",
      "Shen Wang",
      "Qingsong Wen"
    ],
    "abstract": "Grammatical Error Correction (GEC) faces a critical challenge concerning\nexplainability, notably when GEC systems are designed for language learners.\nExisting research predominantly focuses on explaining grammatical errors\nextracted in advance, thus neglecting the relationship between explanations and\ncorrections. To address this gap, we introduce EXGEC, a unified explainable GEC\nframework that integrates explanation and correction tasks in a generative\nmanner, advocating that these tasks mutually reinforce each other. Experiments\nhave been conducted on EXPECT, a recent human-labeled dataset for explainable\nGEC, comprising around 20k samples. Moreover, we detect significant noise\nwithin EXPECT, potentially compromising model training and evaluation.\nTherefore, we introduce an alternative dataset named EXPECT-denoised, ensuring\na more objective framework for training and evaluation. Results on various NLP\nmodels (BART, T5, and Llama3) show that EXGEC models surpass single-task\nbaselines in both tasks, demonstrating the effectiveness of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 2 figures, and 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15261v1",
    "published_date": "2025-02-21 07:42:33 UTC",
    "updated_date": "2025-02-21 07:42:33 UTC"
  },
  {
    "arxiv_id": "2502.15857v1",
    "title": "PPC-GPT: Federated Task-Specific Compression of Large Language Models via Pruning and Chain-of-Thought Distillation",
    "authors": [
      "Tao Fan",
      "Guoqiang Ma",
      "Yuanfeng Song",
      "Lixin Fan",
      "Kai Chen",
      "Qiang Yang"
    ],
    "abstract": "Compressing Large Language Models (LLMs) into task-specific Small Language\nModels (SLMs) encounters two significant challenges: safeguarding\ndomain-specific knowledge privacy and managing limited resources. To tackle\nthese challenges, we propose PPC-GPT, a innovative privacy-preserving federated\nframework specifically designed for compressing LLMs into task-specific SLMs\nvia pruning and Chain-of-Thought (COT) distillation. PPC-GPT works on a\nserver-client federated architecture, where the client sends differentially\nprivate (DP) perturbed task-specific data to the server's LLM. The LLM then\ngenerates synthetic data along with their corresponding rationales. This\nsynthetic data is subsequently used for both LLM pruning and retraining\nprocesses. Additionally, we harness COT knowledge distillation, leveraging the\nsynthetic data to further improve the retraining of structurally-pruned SLMs.\nOur experimental results demonstrate the effectiveness of PPC-GPT across\nvarious text generation tasks. By compressing LLMs into task-specific SLMs,\nPPC-GPT not only achieves competitive performance but also prioritizes data\nprivacy protection.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15857v1",
    "published_date": "2025-02-21 07:32:49 UTC",
    "updated_date": "2025-02-21 07:32:49 UTC"
  },
  {
    "arxiv_id": "2502.15255v1",
    "title": "ComposeOn Academy: Transforming Melodic Ideas into Complete Compositions Integrating Music Learning",
    "authors": [
      "Hongxi Pu",
      "Futian Jiang",
      "Zihao Chen",
      "Xingyue Song"
    ],
    "abstract": "Music composition has long been recognized as a significant art form.\nHowever, existing digital audio workstations and music production software\noften present high entry barriers for users lacking formal musical training. To\naddress this, we introduce ComposeOn, a music theory-based tool designed for\nusers with limited musical knowledge. ComposeOn enables users to easily extend\ntheir melodic ideas into complete compositions and offers simple editing\nfeatures. By integrating music theory, it explains music creation at beginner,\nintermediate, and advanced levels. Our user study (N=10) compared ComposeOn\nwith the baseline method, Suno AI, demonstrating that ComposeOn provides a more\naccessible and enjoyable composing and learning experience for individuals with\nlimited musical skills. ComposeOn bridges the gap between theory and practice,\noffering an innovative solution as both a composition aid and music education\nplatform. The study also explores the differences between theory-based music\ncreation and generative music, highlighting the former's advantages in personal\nexpression and learning.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15255v1",
    "published_date": "2025-02-21 07:18:19 UTC",
    "updated_date": "2025-02-21 07:18:19 UTC"
  },
  {
    "arxiv_id": "2502.15856v1",
    "title": "A Critical Assessment of Modern Generative Models' Ability to Replicate Artistic Styles",
    "authors": [
      "Andrea Asperti",
      "Franky George",
      "Tiberio Marras",
      "Razvan Ciprian Stricescu",
      "Fabio Zanotti"
    ],
    "abstract": "In recent years, advancements in generative artificial intelligence have led\nto the development of sophisticated tools capable of mimicking diverse artistic\nstyles, opening new possibilities for digital creativity and artistic\nexpression. This paper presents a critical assessment of the style replication\ncapabilities of contemporary generative models, evaluating their strengths and\nlimitations across multiple dimensions. We examine how effectively these models\nreproduce traditional artistic styles while maintaining structural integrity\nand compositional balance in the generated images.\n  The analysis is based on a new large dataset of AI-generated works imitating\nartistic styles of the past, holding potential for a wide range of\napplications: the \"AI-pastiche\" dataset.\n  The study is supported by extensive user surveys, collecting diverse opinions\non the dataset and investigation both technical and aesthetic challenges,\nincluding the ability to generate outputs that are realistic and visually\nconvincing, the versatility of models in handling a wide range of artistic\nstyles, and the extent to which they adhere to the content and stylistic\nspecifications outlined in prompts.\n  This paper aims to provide a comprehensive overview of the current state of\ngenerative tools in style replication, offering insights into their technical\nand artistic limitations, potential advancements in model design and training\nmethodologies, and emerging opportunities for enhancing digital artistry,\nhuman-AI collaboration, and the broader creative landscape.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T05",
      "I.2.10; I.5.4"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15856v1",
    "published_date": "2025-02-21 07:00:06 UTC",
    "updated_date": "2025-02-21 07:00:06 UTC"
  },
  {
    "arxiv_id": "2502.15855v1",
    "title": "Non-Linear Flow Matching for Full-Atom Peptide Design",
    "authors": [
      "Dengdeng Huang",
      "Shikui Tu"
    ],
    "abstract": "Peptide design plays a pivotal role in therapeutic applications, yet existing\nAI-assisted methods often struggle to generate stable peptides with high\naffinity due to their inability to accurately simulate the dynamic docking\nprocess. To address this challenge, we propose NLFlow, a novel multi-manifold\napproach based on non-linear flow matching. Specifically, we design a\npolynomial-based conditional vector field to accelerate the convergence of the\npeptide's position towards the target pocket, effectively capturing the\ntemporal inconsistencies across position, rotation, torsion, and amino acid\ntype manifolds. This enables the model to better align with the true\nconformational changes observed in biological docking processes. Additionally,\nwe incorporate interaction-related information, such as polarity, to enhance\nthe understanding of peptide-protein binding. Extensive experiments demonstrate\nthat NLFlow outperforms existing methods in generating peptides with superior\nstability, affinity, and diversity, offering a fast and efficient solution for\npeptide design and advancing the peptide-based therapeutic development.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15855v1",
    "published_date": "2025-02-21 06:49:49 UTC",
    "updated_date": "2025-02-21 06:49:49 UTC"
  },
  {
    "arxiv_id": "2502.15854v1",
    "title": "Enhancing Domain-Specific Retrieval-Augmented Generation: Synthetic Data Generation and Evaluation using Reasoning Models",
    "authors": [
      "Aryan Jadon",
      "Avinash Patil",
      "Shashank Kumar"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems face significant performance\ngaps when applied to technical domains requiring precise information extraction\nfrom complex documents. Current evaluation methodologies relying on\ndocument-level metrics inadequately capture token-resolution retrieval accuracy\nthat is critical for domain-related documents. We propose a framework combining\ngranular evaluation metrics with synthetic data generation to optimize\ndomain-specific RAG performance. First, we introduce token-aware metrics\nPrecision $\\Omega$ and Intersection-over-Union (IoU) that quantify context\npreservation versus information density trade-offs inherent in technical texts.\nSecond, we develop a reasoning model-driven pipeline using instruction-tuned\nLLMs (DeepSeek-R1, DeepSeek-R1 distilled variants, and Phi-4) to generate\ncontext-anchored QA pairs with discontinuous reference spans across three\nspecialized corpora: SEC 10-K filings (finance), biomedical abstracts (PubMed),\nand APT threat reports (cybersecurity).\n  Our empirical analysis reveals critical insights: smaller chunks (less than\n10 tokens) improve precision by 31-42% (IoU = 0.071 vs. baseline 0.053) at\nrecall costs (-18%), while domain-specific embedding strategies yield 22%\nvariance in optimal chunk sizing (5-20 tokens). The\nDeepSeek-R1-Distill-Qwen-32B model demonstrates superior concept alignment\n(+14% mean IoU over alternatives), though no configuration universally\ndominates. Financial texts favor larger chunks for risk factor coverage (Recall\n= 0.81 at size = 20), whereas cybersecurity content benefits from atomic\nsegmentation, Precision $\\Omega = 0.28$ at size = 5.\n  Our code is available on\nhttps://github.com/aryan-jadon/Synthetic-Data-Generation-and-Evaluation-using-Reasoning-Model",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "8 Pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15854v1",
    "published_date": "2025-02-21 06:38:57 UTC",
    "updated_date": "2025-02-21 06:38:57 UTC"
  },
  {
    "arxiv_id": "2502.15243v1",
    "title": "Comparative Analysis of Large Language Models for Context-Aware Code Completion using SAFIM Framework",
    "authors": [
      "Hang Zhang",
      "Yanxin Shen",
      "Lun Wang",
      "Chuanqi Shi",
      "Shaoshuai Du",
      "Yiyi Tao",
      "Yixian Shen"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has revolutionized code\ncompletion, transforming it into a more intelligent and context-aware feature\nin modern integrated development environments. These advancements have\nsignificantly enhanced developers' ability to write efficient and error-free\ncode. This study evaluates the performance of several chat-based LLMs,\nincluding Gemini 1.5 Flash, Gemini 1.5 Pro, GPT-4o, GPT-4o-mini, and GPT-4\nTurbo, using the Syntax-Aware Fill-in-the-Middle (SAFIM) dataset. This\nbenchmark is specifically designed to assess models' capabilities in\nsyntax-sensitive code generation. Performance metrics, such as cosine\nsimilarity with ground-truth completions and latency, were employed to measure\nboth accuracy and efficiency. The findings reveal substantial differences in\nthe models' code completion abilities, offering valuable insights into their\nrespective strengths and weaknesses. This work provides a comparative analysis\nthat underscores the trade-offs between accuracy and speed, establishing a\nbenchmark for future advancements in LLM-based code completion.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15243v1",
    "published_date": "2025-02-21 06:32:31 UTC",
    "updated_date": "2025-02-21 06:32:31 UTC"
  },
  {
    "arxiv_id": "2502.15228v1",
    "title": "AutoMR: A Universal Time Series Motion Recognition Pipeline",
    "authors": [
      "Likun Zhang",
      "Sicheng Yang",
      "Zhuo Wang",
      "Haining Liang",
      "Junxiao Shen"
    ],
    "abstract": "In this paper, we present an end-to-end automated motion recognition (AutoMR)\npipeline designed for multimodal datasets. The proposed framework seamlessly\nintegrates data preprocessing, model training, hyperparameter tuning, and\nevaluation, enabling robust performance across diverse scenarios. Our approach\naddresses two primary challenges: 1) variability in sensor data formats and\nparameters across datasets, which traditionally requires task-specific machine\nlearning implementations, and 2) the complexity and time consumption of\nhyperparameter tuning for optimal model performance. Our library features an\nall-in-one solution incorporating QuartzNet as the core model, automated\nhyperparameter tuning, and comprehensive metrics tracking. Extensive\nexperiments demonstrate its effectiveness on 10 diverse datasets, achieving\nstate-of-the-art performance. This work lays a solid foundation for deploying\nmotion-capture solutions across varied real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15228v1",
    "published_date": "2025-02-21 05:59:41 UTC",
    "updated_date": "2025-02-21 05:59:41 UTC"
  },
  {
    "arxiv_id": "2502.15226v1",
    "title": "Understand User Opinions of Large Language Models via LLM-Powered In-the-Moment User Experience Interviews",
    "authors": [
      "Mengqiao Liu",
      "Tevin Wang",
      "Cassandra A. Cohen",
      "Sarah Li",
      "Chenyan Xiong"
    ],
    "abstract": "Which large language model (LLM) is better? Every evaluation tells a story,\nbut what do users really think about current LLMs? This paper presents CLUE, an\nLLM-powered interviewer that conducts in-the-moment user experience interviews,\nright after users interacted with LLMs, and automatically gathers insights\nabout user opinions from massive interview logs. We conduct a study with\nthousands of users to understand user opinions on mainstream LLMs, recruiting\nusers to first chat with a target LLM and then interviewed by CLUE. Our\nexperiments demonstrate that CLUE captures interesting user opinions, for\nexample, the bipolar views on the displayed reasoning process of DeepSeek-R1\nand demands for information freshness and multi-modality. Our collected\nchat-and-interview logs will be released.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15226v1",
    "published_date": "2025-02-21 05:42:22 UTC",
    "updated_date": "2025-02-21 05:42:22 UTC"
  },
  {
    "arxiv_id": "2502.15224v1",
    "title": "Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs",
    "authors": [
      "Tingting Chen",
      "Srinivas Anumasa",
      "Beibei Lin",
      "Vedant Shah",
      "Anirudh Goyal",
      "Dianbo Liu"
    ],
    "abstract": "Given the remarkable performance of Large Language Models (LLMs), an\nimportant question arises: Can LLMs conduct human-like scientific research and\ndiscover new knowledge, and act as an AI scientist? Scientific discovery is an\niterative process that demands efficient knowledge updating and encoding. It\ninvolves understanding the environment, identifying new hypotheses, and\nreasoning about actions; however, no standardized benchmark specifically\ndesigned for scientific discovery exists for LLM agents. In response to these\nlimitations, we introduce a novel benchmark, \\textit{Auto-Bench}, that\nencompasses necessary aspects to evaluate LLMs for scientific discovery in both\nnatural and social sciences. Our benchmark is based on the principles of causal\ngraph discovery. It challenges models to uncover hidden structures and make\noptimal decisions, which includes generating valid justifications. By engaging\ninteractively with an oracle, the models iteratively refine their understanding\nof underlying interactions, the chemistry and social interactions, through\nstrategic interventions. We evaluate state-of-the-art LLMs, including GPT-4,\nGemini, Qwen, Claude, and Llama, and observe a significant performance drop as\nthe problem complexity increases, which suggests an important gap between\nmachine and human intelligence that future development of LLMs need to take\ninto consideration.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.15224v1",
    "published_date": "2025-02-21 05:35:20 UTC",
    "updated_date": "2025-02-21 05:35:20 UTC"
  },
  {
    "arxiv_id": "2502.17496v1",
    "title": "SpikeRL: A Scalable and Energy-efficient Framework for Deep Spiking Reinforcement Learning",
    "authors": [
      "Tokey Tahmid",
      "Mark Gates",
      "Piotr Luszczek",
      "Catherine D. Schuman"
    ],
    "abstract": "In this era of AI revolution, massive investments in large-scale data-driven\nAI systems demand high-performance computing, consuming tremendous energy and\nresources. This trend raises new challenges in optimizing sustainability\nwithout sacrificing scalability or performance. Among the energy-efficient\nalternatives of the traditional Von Neumann architecture, neuromorphic\ncomputing and its Spiking Neural Networks (SNNs) are a promising choice due to\ntheir inherent energy efficiency. However, in some real-world application\nscenarios such as complex continuous control tasks, SNNs often lack the\nperformance optimizations that traditional artificial neural networks have.\nResearchers have addressed this by combining SNNs with Deep Reinforcement\nLearning (DeepRL), yet scalability remains unexplored. In this paper, we extend\nour previous work on SpikeRL, which is a scalable and energy efficient\nframework for DeepRL-based SNNs for continuous control. In our initial\nimplementation of SpikeRL framework, we depended on the population encoding\nfrom the Population-coded Spiking Actor Network (PopSAN) method for our SNN\nmodel and implemented distributed training with Message Passing Interface (MPI)\nthrough mpi4py. Also, further optimizing our model training by using\nmixed-precision for parameter updates. In our new SpikeRL framework, we have\nimplemented our own DeepRL-SNN component with population encoding, and\ndistributed training with PyTorch Distributed package with NCCL backend while\nstill optimizing with mixed precision training. Our new SpikeRL implementation\nis 4.26X faster and 2.25X more energy efficient than state-of-the-art\nDeepRL-SNN methods. Our proposed SpikeRL framework demonstrates a truly\nscalable and sustainable solution for complex continuous control tasks in\nreal-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17496v1",
    "published_date": "2025-02-21 05:28:42 UTC",
    "updated_date": "2025-02-21 05:28:42 UTC"
  },
  {
    "arxiv_id": "2502.15217v1",
    "title": "FormalSpecCpp: A Dataset of C++ Formal Specifications created using LLMs",
    "authors": [
      "Madhurima Chakraborty",
      "Peter Pirkelbauer",
      "Qing Yi"
    ],
    "abstract": "FormalSpecCpp is a dataset designed to fill the gap in standardized\nbenchmarks for verifying formal specifications in C++ programs. To the best of\nour knowledge, this is the first comprehensive collection of C++ programs with\nwell-defined preconditions and postconditions. It provides a structured\nbenchmark for evaluating specification inference tools and testing theaccuracy\nof generated specifications. Researchers and developers can use this dataset to\nbenchmark specification inference tools,fine-tune Large Language Models (LLMs)\nfor automated specification generation, and analyze the role of formal\nspecifications in improving program verification and automated testing. By\nmaking this dataset publicly available, we aim to advance research in program\nverification, specification inference, and AI-assisted software development.\nThe dataset and the code are available at\nhttps://github.com/MadhuNimmo/FormalSpecCpp.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at the 2025 IEEE/ACM 22nd International Conference on Mining\n  Software Repositories (MSR)",
    "pdf_url": "http://arxiv.org/pdf/2502.15217v1",
    "published_date": "2025-02-21 05:20:04 UTC",
    "updated_date": "2025-02-21 05:20:04 UTC"
  },
  {
    "arxiv_id": "2502.15214v1",
    "title": "The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning",
    "authors": [
      "Sheila Schoepp",
      "Masoud Jafaripour",
      "Yingyue Cao",
      "Tianpei Yang",
      "Fatemeh Abdollahi",
      "Shadan Golestan",
      "Zahin Sufiyan",
      "Osmar R. Zaiane",
      "Matthew E. Taylor"
    ],
    "abstract": "Reinforcement learning (RL) has shown impressive results in sequential\ndecision-making tasks. Meanwhile, Large Language Models (LLMs) and\nVision-Language Models (VLMs) have emerged, exhibiting impressive capabilities\nin multimodal understanding and reasoning. These advances have led to a surge\nof research integrating LLMs and VLMs into RL. In this survey, we review\nrepresentative works in which LLMs and VLMs are used to overcome key challenges\nin RL, such as lack of prior knowledge, long-horizon planning, and reward\ndesign. We present a taxonomy that categorizes these LLM/VLM-assisted RL\napproaches into three roles: agent, planner, and reward. We conclude by\nexploring open problems, including grounding, bias mitigation, improved\nrepresentations, and action advice. By consolidating existing research and\nidentifying future directions, this survey establishes a framework for\nintegrating LLMs and VLMs into RL, advancing approaches that unify natural\nlanguage and visual understanding with sequential decision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15214v1",
    "published_date": "2025-02-21 05:01:30 UTC",
    "updated_date": "2025-02-21 05:01:30 UTC"
  },
  {
    "arxiv_id": "2502.15212v1",
    "title": "Measuring AI agent autonomy: Towards a scalable approach with code inspection",
    "authors": [
      "Peter Cihon",
      "Merlin Stein",
      "Gagan Bansal",
      "Sam Manning",
      "Kevin Xu"
    ],
    "abstract": "AI agents are AI systems that can achieve complex goals autonomously.\nAssessing the level of agent autonomy is crucial for understanding both their\npotential benefits and risks. Current assessments of autonomy often focus on\nspecific risks and rely on run-time evaluations -- observations of agent\nactions during operation. We introduce a code-based assessment of autonomy that\neliminates the need to run an AI agent to perform specific tasks, thereby\nreducing the costs and risks associated with run-time evaluations. Using this\ncode-based framework, the orchestration code used to run an AI agent can be\nscored according to a taxonomy that assesses attributes of autonomy: impact and\noversight. We demonstrate this approach with the AutoGen framework and select\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS Socially Responsible Language Modelling Research (SoLaR)\n  Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.15212v1",
    "published_date": "2025-02-21 04:58:40 UTC",
    "updated_date": "2025-02-21 04:58:40 UTC"
  },
  {
    "arxiv_id": "2503.10641v1",
    "title": "Estimating Control Barriers from Offline Data",
    "authors": [
      "Hongzhan Yu",
      "Seth Farrell",
      "Ryo Yoshimitsu",
      "Zhizhen Qin",
      "Henrik I. Christensen",
      "Sicun Gao"
    ],
    "abstract": "Learning-based methods for constructing control barrier functions (CBFs) are\ngaining popularity for ensuring safe robot control. A major limitation of\nexisting methods is their reliance on extensive sampling over the state space\nor online system interaction in simulation. In this work we propose a novel\nframework for learning neural CBFs through a fixed, sparsely-labeled dataset\ncollected prior to training. Our approach introduces new annotation techniques\nbased on out-of-distribution analysis, enabling efficient knowledge propagation\nfrom the limited labeled data to the unlabeled data. We also eliminate the\ndependency on a high-performance expert controller, and allow multiple\nsub-optimal policies or even manual control during data collection. We evaluate\nthe proposed method on real-world platforms. With limited amount of offline\ndata, it achieves state-of-the-art performance for dynamic obstacle avoidance,\ndemonstrating statistically safer and less conservative maneuvers compared to\nexisting methods.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "This paper has been accepted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.10641v1",
    "published_date": "2025-02-21 04:55:20 UTC",
    "updated_date": "2025-02-21 04:55:20 UTC"
  },
  {
    "arxiv_id": "2502.15210v2",
    "title": "PairBench: A Systematic Framework for Selecting Reliable Judge VLMs",
    "authors": [
      "Aarash Feizi",
      "Sai Rajeswar",
      "Adriana Romero-Soriano",
      "Reihaneh Rabbany",
      "Spandana Gella",
      "Valentina Zantedeschi",
      "JoÃ£o Monteiro"
    ],
    "abstract": "As large vision language models (VLMs) are increasingly used as automated\nevaluators, understanding their ability to effectively compare data pairs as\ninstructed in the prompt becomes essential. To address this, we present\nPairBench, a low-cost framework that systematically evaluates VLMs as\ncustomizable similarity tools across various modalities and scenarios. Through\nPairBench, we introduce four metrics that represent key desiderata of\nsimilarity scores: alignment with human annotations, consistency for data pairs\nirrespective of their order, smoothness of similarity distributions, and\ncontrollability through prompting. Our analysis demonstrates that no model,\nwhether closed- or open-source, is superior on all metrics; the optimal choice\ndepends on an auto evaluator's desired behavior (e.g., a smooth vs. a sharp\njudge), highlighting risks of widespread adoption of VLMs as evaluators without\nthorough assessment. For instance, the majority of VLMs struggle with\nmaintaining symmetric similarity scores regardless of order. Additionally, our\nresults show that the performance of VLMs on the metrics in PairBench closely\ncorrelates with popular benchmarks, showcasing its predictive power in ranking\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15210v2",
    "published_date": "2025-02-21 04:53:11 UTC",
    "updated_date": "2025-02-24 15:01:43 UTC"
  },
  {
    "arxiv_id": "2502.15851v1",
    "title": "Control Illusion: The Failure of Instruction Hierarchies in Large Language Models",
    "authors": [
      "Yilin Geng",
      "Haonan Li",
      "Honglin Mu",
      "Xudong Han",
      "Timothy Baldwin",
      "Omri Abend",
      "Eduard Hovy",
      "Lea Frermann"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed with hierarchical\ninstruction schemes, where certain instructions (e.g., system-level directives)\nare expected to take precedence over others (e.g., user messages). Yet, we lack\na systematic understanding of how effectively these hierarchical control\nmechanisms work. We introduce a systematic evaluation framework based on\nconstraint prioritization to assess how well LLMs enforce instruction\nhierarchies. Our experiments across six state-of-the-art LLMs reveal that\nmodels struggle with consistent instruction prioritization, even for simple\nformatting conflicts. We find that the widely-adopted system/user prompt\nseparation fails to establish a reliable instruction hierarchy, and models\nexhibit strong inherent biases toward certain constraint types regardless of\ntheir priority designation. While controlled prompt engineering and model\nfine-tuning show modest improvements, our results indicate that instruction\nhierarchy enforcement is not robustly realized, calling for deeper\narchitectural innovations beyond surface-level modifications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15851v1",
    "published_date": "2025-02-21 04:51:37 UTC",
    "updated_date": "2025-02-21 04:51:37 UTC"
  },
  {
    "arxiv_id": "2502.15203v1",
    "title": "FlipConcept: Tuning-Free Multi-Concept Personalization for Text-to-Image Generation",
    "authors": [
      "Young Beom Woo",
      "Sun Eung Kim"
    ],
    "abstract": "Recently, methods that integrate multiple personalized concepts into a single\nimage have garnered significant attention in the field of text-to-image (T2I)\ngeneration. However, existing methods experience performance degradation in\ncomplex scenes with multiple objects due to distortions in non-personalized\nregions. To address this issue, we propose FlipConcept, a novel approach that\nseamlessly integrates multiple personalized concepts into a single image\nwithout requiring additional tuning. We introduce guided appearance attention\nto accurately mimic the appearance of a personalized concept as intended.\nAdditionally, we introduce mask-guided noise mixing to protect non-personalized\nregions during editing. Lastly, we apply background dilution to minimize\nattribute leakage, which is the undesired blending of personalized concept\nattributes with other objects in the image. In our experiments, we demonstrate\nthat the proposed method, despite not requiring tuning, outperforms existing\nmodels in both single and multiple personalized concept inference.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15203v1",
    "published_date": "2025-02-21 04:37:18 UTC",
    "updated_date": "2025-02-21 04:37:18 UTC"
  },
  {
    "arxiv_id": "2502.15197v1",
    "title": "TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding",
    "authors": [
      "Zhaoxuan Wu",
      "Zijian Zhou",
      "Arun Verma",
      "Alok Prakash",
      "Daniela Rus",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "We propose TETRIS, a novel method that optimizes the total throughput of\nbatch speculative decoding in multi-request settings. Unlike existing methods\nthat optimize for a single request or a group of requests as a whole, TETRIS\nactively selects the most promising draft tokens (for every request in a batch)\nto be accepted when verified in parallel, resulting in fewer rejected tokens\nand hence less wasted computing resources. Such an effective resource\nutilization to achieve fast inference in large language models (LLMs) is\nespecially important to service providers with limited inference capacity.\nCompared to baseline speculative decoding, TETRIS yields a consistently higher\nacceptance rate and more effective utilization of the limited inference\ncapacity. We show theoretically and empirically that TETRIS outperforms\nbaseline speculative decoding and existing methods that dynamically select\ndraft tokens, leading to a more efficient batch inference in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 10 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15197v1",
    "published_date": "2025-02-21 04:19:24 UTC",
    "updated_date": "2025-02-21 04:19:24 UTC"
  },
  {
    "arxiv_id": "2502.15189v1",
    "title": "Scale-Free Graph-Language Models",
    "authors": [
      "Jianglin Lu",
      "Yixuan Liu",
      "Yitian Zhang",
      "Yun Fu"
    ],
    "abstract": "Graph-language models (GLMs) have demonstrated great potential in graph-based\nsemi-supervised learning. A typical GLM consists of two key stages: graph\ngeneration and text embedding, which are usually implemented by inferring a\nlatent graph and finetuning a language model (LM), respectively. However, the\nformer often relies on artificial assumptions about the underlying edge\ndistribution, while the latter requires extensive data annotations. To tackle\nthese challenges, this paper introduces a novel GLM that integrates graph\ngeneration and text embedding within a unified framework. Specifically, for\ngraph generation, we leverage an inherent characteristic of real edge\ndistribution--the scale-free property--as a structural prior. We unexpectedly\nfind that this natural property can be effectively approximated by a simple\nk-nearest neighbor (KNN) graph. For text embedding, we develop a graph-based\npseudo-labeler that utilizes scale-free graphs to provide complementary\nsupervision for improved LM finetuning. Extensive experiments on representative\ndatasets validate our findings on the scale-free structural approximation of\nKNN graphs and demonstrate the effectiveness of integrating graph generation\nand text embedding with a real structural prior. Our code is available at\nhttps://github.com/Jianglin954/SFGL.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15189v1",
    "published_date": "2025-02-21 03:41:43 UTC",
    "updated_date": "2025-02-21 03:41:43 UTC"
  },
  {
    "arxiv_id": "2502.15186v1",
    "title": "LUMINA-Net: Low-light Upgrade through Multi-stage Illumination and Noise Adaptation Network for Image Enhancement",
    "authors": [
      "Namrah Siddiqua",
      "Kim Suneung"
    ],
    "abstract": "Low-light image enhancement (LLIE) is a crucial task in computer vision aimed\nto enhance the visual fidelity of images captured under low-illumination\nconditions. Conventional methods frequently struggle to mitigate pervasive\nshortcomings such as noise, over-exposure, and color distortion thereby\nprecipitating a pronounced degradation in image quality. To address these\nchallenges, we propose LUMINA-Net an advanced deep learning framework designed\nspecifically by integrating multi-stage illumination and reflectance modules.\nFirst, the illumination module intelligently adjusts brightness and contrast\nlevels while meticulously preserving intricate textural details. Second, the\nreflectance module incorporates a noise reduction mechanism that leverages\nspatial attention and channel-wise feature refinement to mitigate noise\ncontamination. Through a comprehensive suite of experiments conducted on LOL\nand SICE datasets using PSNR, SSIM and LPIPS metrics, surpassing\nstate-of-the-art methodologies and showcasing its efficacy in low-light image\nenhancement.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.15186v1",
    "published_date": "2025-02-21 03:37:58 UTC",
    "updated_date": "2025-02-21 03:37:58 UTC"
  },
  {
    "arxiv_id": "2502.15185v1",
    "title": "Key Body Posture Characteristics of Short-distance Speed Skaters at the Start Based on Artificial Intelligence",
    "authors": [
      "Zhang Xueliana",
      "Fang Yingjieb",
      "Liu Hang"
    ],
    "abstract": "Objective To conduct biomechanical analysis on the starting technique of male\nshort-distance speed skating athletes in China and determine the key factors\naffecting the effectiveness of the starting movement. Methods 13 high-level\nmale short-distance speed skating athletes were selected as the test subjects,\nand kinematic data were collected using an artificial intelligence video\ncapture and analysis system. The body posture features and their effects on the\nstarting movement performance were analyzed in the three stages of starting\npreparation, starting, and sprinting. Results The post-stability angle,\nanterior knee angle of the front leg, posterior knee angle of the rear leg, and\nstride length showed moderate to high positive correlations with the starting\nspeed during the starting preparation stage. The trunk angle showed a high\nnegative correlation with the starting speed. The trunk angle (TO4, TD4, TO6,\nTD6), hip angle (TO1, TO4, TO6), and knee angle (TD1) showed moderate to high\nnegative correlations with the effectiveness of the starting movement during\nthe starting and sprinting stages. The knee angle (TD2), ice-contact angle\n(TD2, TD4, TD5, TD6), and propulsion angle (TO1, TO4, TO7) showed moderate\npositive correlations with the effectiveness of the starting movement.\nConclusion Stride length, left knee angle, and post-stability angle are the key\nfactors affecting the starting speed. The larger the post-stability angle and\nleft knee angle and the longer the stride length, the faster the starting\nspeed. During the starting and sprinting stages, the smaller the ice-contact\nangle and propulsion angle, the greater the trunk angle and hip angle changes,\nthe more effective the starting movement.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15185v1",
    "published_date": "2025-02-21 03:36:17 UTC",
    "updated_date": "2025-02-21 03:36:17 UTC"
  },
  {
    "arxiv_id": "2502.15182v1",
    "title": "LEDD: Large Language Model-Empowered Data Discovery in Data Lakes",
    "authors": [
      "Qi An",
      "Chihua Ying",
      "Yuqing Zhu",
      "Yihao Xu",
      "Manwei Zhang",
      "Jianmin Wang"
    ],
    "abstract": "Data discovery in data lakes with ever increasing datasets has long been\nrecognized as a big challenge in the realm of data management, especially for\nsemantic search of and hierarchical global catalog generation of tables. While\nlarge language models (LLMs) facilitate the processing of data semantics,\nchallenges remain in architecting an end-to-end system that comprehensively\nexploits LLMs for the two semantics-related tasks. In this demo, we propose\nLEDD, an end-to-end system with an extensible architecture that leverages LLMs\nto provide hierarchical global catalogs with semantic meanings and semantic\ntable search for data lakes. Specifically, LEDD can return semantically related\ntables based on natural-language specification. These features make LEDD an\nideal foundation for downstream tasks such as model training and schema linking\nfor text-to-SQL tasks. LEDD also provides a simple Python interface to\nfacilitate the extension and the replacement of data discovery algorithms.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15182v1",
    "published_date": "2025-02-21 03:30:43 UTC",
    "updated_date": "2025-02-21 03:30:43 UTC"
  },
  {
    "arxiv_id": "2502.15176v1",
    "title": "Methods and Trends in Detecting Generated Images: A Comprehensive Review",
    "authors": [
      "Arpan Mahara",
      "Naphtali Rishe"
    ],
    "abstract": "The proliferation of generative models, such as Generative Adversarial\nNetworks (GANs), Diffusion Models, and Variational Autoencoders (VAEs), has\nenabled the synthesis of high-quality multimedia data. However, these\nadvancements have also raised significant concerns regarding adversarial\nattacks, unethical usage, and societal harm. Recognizing these challenges,\nresearchers have increasingly focused on developing methodologies to detect\nsynthesized data effectively, aiming to mitigate potential risks. Prior reviews\nhave primarily focused on deepfake detection and often lack coverage of recent\nadvancements in synthetic image detection, particularly methods leveraging\nmultimodal frameworks for improved forensic analysis. To address this gap, the\npresent survey provides a comprehensive review of state-of-the-art methods for\ndetecting and classifying synthetic images generated by advanced generative AI\nmodels. This review systematically examines core detection methodologies,\nidentifies commonalities among approaches, and categorizes them into meaningful\ntaxonomies. Furthermore, given the crucial role of large-scale datasets in this\nfield, we present an overview of publicly available datasets that facilitate\nfurther research and benchmarking in synthetic data detection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "30 pages, 4 Figures, 10 Tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15176v1",
    "published_date": "2025-02-21 03:16:18 UTC",
    "updated_date": "2025-02-21 03:16:18 UTC"
  },
  {
    "arxiv_id": "2502.15850v2",
    "title": "Forecasting Frontier Language Model Agent Capabilities",
    "authors": [
      "Govind Pimpale",
      "Axel HÃ¸jmark",
      "JÃ©rÃ©my Scheurer",
      "Marius Hobbhahn"
    ],
    "abstract": "As Language Models (LMs) increasingly operate as autonomous agents,\naccurately forecasting their capabilities becomes crucial for societal\npreparedness. We evaluate six forecasting methods that predict downstream\ncapabilities of LM agents. We use \"one-step\" approaches that predict benchmark\nscores from input metrics like compute or model release date directly or\n\"two-step\" approaches that first predict an intermediate metric like the\nprincipal component of cross-benchmark performance (PC-1) and human-evaluated\ncompetitive Elo ratings. We evaluate our forecasting methods by backtesting\nthem on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the\nvalidated two-step approach (Release Date$\\to$Elo$\\to$Benchmark) to predict LM\nagent performance for frontier models on three benchmarks: SWE-Bench Verified\n(software development), Cybench (cybersecurity assessment), and RE-Bench (ML\nresearch engineering). Our forecast predicts that by the beginning of 2026,\nnon-specialized LM agents with low capability elicitation will reach a success\nrate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach\nan 87% success rate. Our approach does not account for recent advances in\ninference-compute scaling and might thus be too conservative.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15850v2",
    "published_date": "2025-02-21 02:34:17 UTC",
    "updated_date": "2025-03-03 17:11:16 UTC"
  },
  {
    "arxiv_id": "2502.15849v2",
    "title": "Deriving Representative Structure from Music Corpora",
    "authors": [
      "Ilana Shapiro",
      "Ruanqianqian Huang",
      "Zachary Novack",
      "Cheng-i Wang",
      "Hao-Wen Dong",
      "Taylor Berg-Kirkpatrick",
      "Shlomo Dubnov",
      "Sorin Lerner"
    ],
    "abstract": "Western music is an innately hierarchical system of interacting levels of\nstructure, from fine-grained melody to high-level form. In order to analyze\nmusic compositions holistically and at multiple granularities, we propose a\nunified, hierarchical meta-representation of musical structure called the\nstructural temporal graph (STG). For a single piece, the STG is a data\nstructure that defines a hierarchy of progressively finer structural musical\nfeatures and the temporal relationships between them. We use the STG to enable\na novel approach for deriving a representative structural summary of a music\ncorpus, which we formalize as a dually NP-hard combinatorial optimization\nproblem extending the Generalized Median Graph problem. Our approach first\napplies simulated annealing to develop a measure of structural distance between\ntwo music pieces rooted in graph isomorphism. Our approach then combines the\nformal guarantees of SMT solvers with nested simulated annealing over\nstructural distances to produce a structurally sound, representative centroid\nSTG for an entire corpus of STGs from individual pieces. To evaluate our\napproach, we conduct experiments verifying that structural distance accurately\ndifferentiates between music pieces, and that derived centroids accurately\nstructurally characterize their corpora.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SD",
      "G.1.6; I.2.4; J.5; G.2.2"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 8 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15849v2",
    "published_date": "2025-02-21 02:32:29 UTC",
    "updated_date": "2025-03-30 22:09:45 UTC"
  },
  {
    "arxiv_id": "2502.15155v1",
    "title": "Extreme Speech Classification in the Era of LLMs: Exploring Open-Source and Proprietary Models",
    "authors": [
      "Sarthak Mahajan",
      "Nimmi Rangaswamy"
    ],
    "abstract": "In recent years, widespread internet adoption and the growth in userbase of\nvarious social media platforms have led to an increase in the proliferation of\nextreme speech online. While traditional language models have demonstrated\nproficiency in distinguishing between neutral text and non-neutral text (i.e.\nextreme speech), categorizing the diverse types of extreme speech presents\nsignificant challenges. The task of extreme speech classification is\nparticularly nuanced, as it requires a deep understanding of socio-cultural\ncontexts to accurately interpret the intent of the language used by the\nspeaker. Even human annotators often disagree on the appropriate classification\nof such content, emphasizing the complex and subjective nature of this task.\nThe use of human moderators also presents a scaling issue, necessitating the\nneed for automated systems for extreme speech classification. The recent launch\nof ChatGPT has drawn global attention to the potential applications of Large\nLanguage Models (LLMs) across a diverse variety of tasks. Trained on vast and\ndiverse corpora, and demonstrating the ability to effectively capture and\nencode contextual information, LLMs emerge as highly promising tools for\ntackling this specific task of extreme speech classification. In this paper, we\nleverage the Indian subset of the extreme speech dataset from Maronikolakis et\nal. (2022) to develop an effective classification framework using LLMs. We\nevaluate open-source Llama models against closed-source OpenAI models, finding\nthat while pre-trained LLMs show moderate efficacy, fine-tuning with\ndomain-specific data significantly enhances performance, highlighting their\nadaptability to linguistic and contextual nuances. Although GPT-based models\noutperform Llama models in zero-shot settings, the performance gap disappears\nafter fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to 7th International Conference on information systems and\n  management science (ISMS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.15155v1",
    "published_date": "2025-02-21 02:31:05 UTC",
    "updated_date": "2025-02-21 02:31:05 UTC"
  },
  {
    "arxiv_id": "2502.15152v2",
    "title": "CW-BASS: Confidence-Weighted Boundary-Aware Learning for Semi-Supervised Semantic Segmentation",
    "authors": [
      "Ebenezer Tarubinga",
      "Jenifer Kalafatovich",
      "Seong-Whan Lee"
    ],
    "abstract": "Semi-supervised semantic segmentation (SSSS) aims to improve segmentation\nperformance by utilizing large amounts of unlabeled data with limited labeled\nsamples. Existing methods often suffer from coupling, where over-reliance on\ninitial labeled data leads to suboptimal learning; confirmation bias, where\nincorrect predictions reinforce themselves repeatedly; and boundary blur caused\nby limited boundary-awareness and ambiguous edge cues. To address these issues,\nwe propose CW-BASS, a novel framework for SSSS. In order to mitigate the impact\nof incorrect predictions, we assign confidence weights to pseudo-labels.\nAdditionally, we leverage boundary-delineation techniques, which, despite being\nextensively explored in weakly-supervised semantic segmentation (WSSS), remain\nunderutilized in SSSS. Specifically, our method: (1) reduces coupling via a\nconfidence-weighted loss that adjusts pseudo-label influence based on their\npredicted confidence scores, (2) mitigates confirmation bias with a dynamic\nthresholding mechanism that learns to filter out pseudo-labels based on model\nperformance, (3) tackles boundary blur using a boundary-aware module to refine\nsegmentation near object edges, and (4) reduces label noise through a\nconfidence decay strategy that progressively refines pseudo-labels during\ntraining. Extensive experiments on Pascal VOC 2012 and Cityscapes demonstrate\nthat CW-BASS achieves state-of-the-art performance. Notably, CW-BASS achieves a\n65.9% mIoU on Cityscapes under a challenging and underexplored 1/30 (3.3%)\nsplit (100 images), highlighting its effectiveness in limited-label settings.\nOur code is available at https://github.com/psychofict/CW-BASS.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15152v2",
    "published_date": "2025-02-21 02:24:10 UTC",
    "updated_date": "2025-04-09 08:07:51 UTC"
  },
  {
    "arxiv_id": "2502.15145v2",
    "title": "Projection Optimization: A General Framework for Multi-Objective and Multi-Group RLHF",
    "authors": [
      "Nuoya Xiong",
      "Aarti Singh"
    ],
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) is a widely used\nfine-tuning approach that aligns machine learning model, particularly Language\nModel (LM) with human preferences. There are typically multiple objectives\ndriving the preference, hence humans find it easier to express per-objective\ncomparisons rather than a global preference between two choices.\nMulti-Objective RLHF (MORLHF) aims to use per-objective preference feedback and\nachieve Pareto optimality among these objectives by aggregating them into a\nsingle unified objective for optimization. However, nearly all prior works rely\non linear aggregation, which rules out policies that favor specific objectives\nsuch as the worst one. The only existing approach using non-linear aggregation\nis computationally expensive due to its reward-based nature and the need for\nretraining whenever the aggregation parameters change. In this work, we address\nthis limitation by transforming the non-linear aggregation maximization problem\ninto a series of sub-problems. Each sub-problem involves only linear\naggregation, making it computationally efficient to solve. We further extend\nour framework to handle multi-group scenarios, where each group has distinct\nweights for the objectives. Our method enables achieving consensus or\nmaximizing the aggregated objective across all groups. Theoretically, we\ndemonstrate that our algorithmic framework achieves sublinear regret and can be\neasily adapted to a reward-free algorithm. Empirically, leveraging our\ntheoretical insights, we propose a nearly training-free algorithm once the\noptimal policies for individual objectives are obtained.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15145v2",
    "published_date": "2025-02-21 01:56:52 UTC",
    "updated_date": "2025-02-24 06:06:04 UTC"
  },
  {
    "arxiv_id": "2502.15134v1",
    "title": "Chain-of-Rank: Enhancing Large Language Models for Domain-Specific RAG in Edge Device",
    "authors": [
      "Juntae Lee",
      "Jihwan Bang",
      "Seunghan Yang",
      "Kyuhong Shim",
      "Simyung Chang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) with large language models (LLMs) is\nespecially valuable in specialized domains, where precision is critical. To\nmore specialize the LLMs into a target domain, domain-specific RAG has recently\nbeen developed by allowing the LLM to access the target domain early via\nfinetuning. The domain-specific RAG makes more sense in resource-constrained\nenvironments like edge devices, as they should perform a specific task (e.g.\npersonalization) reliably using only small-scale LLMs. While the\ndomain-specific RAG is well-aligned with edge devices in this respect, it often\nrelies on widely-used reasoning techniques like chain-of-thought (CoT). The\nreasoning step is useful to understand the given external knowledge, and yet it\nis computationally expensive and difficult for small-scale LLMs to learn it.\nTackling this, we propose the Chain of Rank (CoR) which shifts the focus from\nintricate lengthy reasoning to simple ranking of the reliability of input\nexternal documents. Then, CoR reduces computational complexity while\nmaintaining high accuracy, making it particularly suited for\nresource-constrained environments. We attain the state-of-the-art (SOTA)\nresults in benchmarks, and analyze its efficacy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2502.15134v1",
    "published_date": "2025-02-21 01:28:12 UTC",
    "updated_date": "2025-02-21 01:28:12 UTC"
  },
  {
    "arxiv_id": "2502.15132v3",
    "title": "CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations",
    "authors": [
      "Vignesh Kothapalli",
      "Hamed Firooz",
      "Maziar Sanjabi"
    ],
    "abstract": "We introduce CoT-ICL Lab, a framework and methodology to generate synthetic\ntokenized datasets and systematically study chain-of-thought (CoT) in-context\nlearning (ICL) in language models. CoT-ICL Lab allows fine grained control over\nthe complexity of in-context examples by decoupling (1) the causal structure\ninvolved in chain token generation from (2) the underlying token processing\nfunctions. We train decoder-only transformers (up to 700M parameters) on these\ndatasets and show that CoT accelerates the accuracy transition to higher values\nacross model sizes. In particular, we find that model depth is crucial for\nleveraging CoT with limited in-context examples, while more examples help\nshallow models match deeper model performance. Additionally, limiting the\ndiversity of token processing functions throughout training improves causal\nstructure learning via ICL. We also interpret these transitions by analyzing\ntransformer embeddings and attention maps. Overall, CoT-ICL Lab serves as a\nsimple yet powerful testbed for theoretical and empirical insights into ICL and\nCoT in language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL Main 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.15132v3",
    "published_date": "2025-02-21 01:24:54 UTC",
    "updated_date": "2025-05-21 21:21:59 UTC"
  },
  {
    "arxiv_id": "2502.15127v1",
    "title": "The Imitation Game for Educational AI",
    "authors": [
      "Shashank Sonkar",
      "Naiming Liu",
      "Xinghe Chen",
      "Richard G. Baraniuk"
    ],
    "abstract": "As artificial intelligence systems become increasingly prevalent in\neducation, a fundamental challenge emerges: how can we verify if an AI truly\nunderstands how students think and reason? Traditional evaluation methods like\nmeasuring learning gains require lengthy studies confounded by numerous\nvariables. We present a novel evaluation framework based on a two-phase\nTuring-like test. In Phase 1, students provide open-ended responses to\nquestions, revealing natural misconceptions. In Phase 2, both AI and human\nexperts, conditioned on each student's specific mistakes, generate distractors\nfor new related questions. By analyzing whether students select AI-generated\ndistractors at rates similar to human expert-generated ones, we can validate if\nthe AI models student cognition. We prove this evaluation must be conditioned\non individual responses - unconditioned approaches merely target common\nmisconceptions. Through rigorous statistical sampling theory, we establish\nprecise requirements for high-confidence validation. Our research positions\nconditioned distractor generation as a probe into an AI system's fundamental\nability to model student thinking - a capability that enables adapting\ntutoring, feedback, and assessments to each student's specific needs.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15127v1",
    "published_date": "2025-02-21 01:14:55 UTC",
    "updated_date": "2025-02-21 01:14:55 UTC"
  },
  {
    "arxiv_id": "2502.15120v1",
    "title": "Unveiling Reasoning Thresholds in Language Models: Scaling, Fine-Tuning, and Interpretability through Attention Maps",
    "authors": [
      "Yen-Che Hsiao",
      "Abhishek Dutta"
    ],
    "abstract": "This study investigates the in-context learning capabilities of various\ndecoder-only transformer-based language models with different model sizes and\ntraining data, including GPT2, SmolLM2, OpenELM, TinyLlama, Stable LM, and\nGemma 2. We identify a critical parameter threshold (~1.6 billion), beyond\nwhich reasoning performance improves significantly in tasks such as commonsense\nreasoning in multiple-choice question answering and deductive reasoning.\nSpecifically, models above this threshold achieve better success rates in\nchain-of-thought (CoT) prompting for deductive reasoning tasks, especially\nthose requiring longer reasoning chains, such as proof by contradiction and\ndisjunction elimination. To address limitations in sub-threshold models, we\ndemonstrate that fine-tuning with task-specific exemplars substantially\nenhances reasoning performance, enabling accurate CoT generation even without\nadditional exemplars in the prompt for tasks with shorter reasoning chains.\nFinally, our analysis of attention maps reveals that models capable of\ngenerating correct CoTs exhibit higher token-level attention scores on\nsubsequent correct tokens and the correct parts of speech, providing\ninterpretability insights into reasoning processes. These findings collectively\nadvance understanding of reasoning capabilities in decoder-only\ntransformer-based models. The code is available at:\nhttps://github.com/AnnonymousForPapers/CoT_Reasoning_Test.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15120v1",
    "published_date": "2025-02-21 00:48:32 UTC",
    "updated_date": "2025-02-21 00:48:32 UTC"
  },
  {
    "arxiv_id": "2502.15119v1",
    "title": "CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models",
    "authors": [
      "Zihao Sheng",
      "Zilin Huang",
      "Yansong Qu",
      "Yue Leng",
      "Sruthi Bhavanam",
      "Sikai Chen"
    ],
    "abstract": "Ensuring safety in autonomous driving systems remains a critical challenge,\nparticularly in handling rare but potentially catastrophic safety-critical\nscenarios. While existing research has explored generating safety-critical\nscenarios for autonomous vehicle (AV) testing, there is limited work on\neffectively incorporating these scenarios into policy learning to enhance\nsafety. Furthermore, developing training curricula that adapt to an AV's\nevolving behavioral patterns and performance bottlenecks remains largely\nunexplored. To address these challenges, we propose CurricuVLM, a novel\nframework that leverages Vision-Language Models (VLMs) to enable personalized\ncurriculum learning for autonomous driving agents. Our approach uniquely\nexploits VLMs' multimodal understanding capabilities to analyze agent behavior,\nidentify performance weaknesses, and dynamically generate tailored training\nscenarios for curriculum adaptation. Through comprehensive analysis of unsafe\ndriving situations with narrative descriptions, CurricuVLM performs in-depth\nreasoning to evaluate the AV's capabilities and identify critical behavioral\npatterns. The framework then synthesizes customized training scenarios\ntargeting these identified limitations, enabling effective and personalized\ncurriculum learning. Extensive experiments on the Waymo Open Motion Dataset\nshow that CurricuVLM outperforms state-of-the-art baselines across both regular\nand safety-critical scenarios, achieving superior performance in terms of\nnavigation success, driving efficiency, and safety metrics. Further analysis\nreveals that CurricuVLM serves as a general approach that can be integrated\nwith various RL algorithms to enhance autonomous driving systems. The code and\ndemo video are available at: https://zihaosheng.github.io/CurricuVLM/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15119v1",
    "published_date": "2025-02-21 00:42:40 UTC",
    "updated_date": "2025-02-21 00:42:40 UTC"
  },
  {
    "arxiv_id": "2502.15107v1",
    "title": "Assessing a Single Student's Concentration on Learning Platforms: A Machine Learning-Enhanced EEG-Based Framework",
    "authors": [
      "Zewen Zhuo",
      "Mohamad Najafi",
      "Hazem Zein",
      "Amine Nait-Ali"
    ],
    "abstract": "This study introduces a specialized pipeline designed to classify the\nconcentration state of an individual student during online learning sessions by\ntraining a custom-tailored machine learning model. Detailed protocols for\nacquiring and preprocessing EEG data are outlined, along with the extraction of\nfifty statistical features from five EEG signal bands: alpha, beta, theta,\ndelta, and gamma. Following feature extraction, a thorough feature selection\nprocess was conducted to optimize the data inputs for a personalized analysis.\nThe study also explores the benefits of hyperparameter fine-tuning to enhance\nthe classification accuracy of the student's concentration state. EEG signals\nwere captured from the student using a Muse headband (Gen 2), equipped with\nfive electrodes (TP9, AF7, AF8, TP10, and a reference electrode NZ), during\nengagement with educational content on computer-based e-learning platforms.\nEmploying a random forest model customized to the student's data, we achieved\nremarkable classification performance, with test accuracies of 97.6% in the\ncomputer-based learning setting and 98% in the virtual reality setting. These\nresults underscore the effectiveness of our approach in delivering personalized\ninsights into student concentration during online educational activities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15107v1",
    "published_date": "2025-02-21 00:02:28 UTC",
    "updated_date": "2025-02-21 00:02:28 UTC"
  }
]