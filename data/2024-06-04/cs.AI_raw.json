[
  {
    "arxiv_id": "2406.02804v2",
    "title": "ACCORD: Closing the Commonsense Measurability Gap",
    "authors": [
      "François Roewer-Després",
      "Jinyue Feng",
      "Zining Zhu",
      "Frank Rudzicz"
    ],
    "abstract": "We present ACCORD, a framework and benchmark suite for disentangling the\ncommonsense grounding and reasoning abilities of large language models (LLMs)\nthrough controlled, multi-hop counterfactuals. ACCORD introduces formal\nelements to commonsense reasoning to explicitly control and quantify reasoning\ncomplexity beyond the typical 1 or 2 hops. Uniquely, ACCORD can automatically\ngenerate benchmarks of arbitrary reasoning complexity, and so it scales with\nfuture LLM improvements. Benchmarking state-of-the-art LLMs -- including GPT-4o\n(2024-05-13), Llama-3-70B-Instruct, and Mixtral-8x22B-Instruct-v0.1 -- shows\nperformance degrading to random chance with only moderate scaling, leaving\nsubstantial headroom for improvement. We release a leaderboard of the benchmark\nsuite tested in this work, as well as code for automatically generating more\ncomplex benchmarks.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "For leaderboard and dataset download, see\n  https://www.codabench.org/competitions/3160/ For source code, see\n  https://github.com/francois-rd/accord/",
    "pdf_url": "http://arxiv.org/pdf/2406.02804v2",
    "published_date": "2024-06-04 22:08:24 UTC",
    "updated_date": "2025-02-06 19:10:47 UTC"
  },
  {
    "arxiv_id": "2406.02791v2",
    "title": "Language Models can Infer Action Semantics for Symbolic Planners from Environment Feedback",
    "authors": [
      "Wang Zhu",
      "Ishika Singh",
      "Robin Jia",
      "Jesse Thomason"
    ],
    "abstract": "Symbolic planners can discover a sequence of actions from initial to goal\nstates given expert-defined, domain-specific logical action semantics. Large\nLanguage Models (LLMs) can directly generate such sequences, but limitations in\nreasoning and state-tracking often result in plans that are insufficient or\nunexecutable. We propose Predicting Semantics of Actions with Language Models\n(PSALM), which automatically learns action semantics by leveraging the\nstrengths of both symbolic planners and LLMs. PSALM repeatedly proposes and\nexecutes plans, using the LLM to partially generate plans and to infer\ndomain-specific action semantics based on execution outcomes. PSALM maintains a\nbelief over possible action semantics that is iteratively updated until a goal\nstate is reached. Experiments on 7 environments show that when learning just\nfrom one goal, PSALM boosts plan success rate from 36.4% (on Claude-3.5) to\n100%, and explores the environment more efficiently than prior work to infer\nground truth domain action semantics.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02791v2",
    "published_date": "2024-06-04 21:29:56 UTC",
    "updated_date": "2024-11-08 16:50:24 UTC"
  },
  {
    "arxiv_id": "2406.02787v1",
    "title": "Disentangling Logic: The Role of Context in Large Language Model Reasoning Capabilities",
    "authors": [
      "Wenyue Hua",
      "Kaijie Zhu",
      "Lingyao Li",
      "Lizhou Fan",
      "Shuhang Lin",
      "Mingyu Jin",
      "Haochen Xue",
      "Zelong Li",
      "JinDong Wang",
      "Yongfeng Zhang"
    ],
    "abstract": "This study intends to systematically disentangle pure logic reasoning and\ntext understanding by investigating the contrast across abstract and\ncontextualized logical problems from a comprehensive set of domains. We explore\nwhether LLMs demonstrate genuine reasoning capabilities across various domains\nwhen the underlying logical structure remains constant. We focus on two main\nquestions (1) Can abstract logical problems alone accurately benchmark an LLM's\nreasoning ability in real-world scenarios, disentangled from contextual support\nin practical settings? (2) Does fine-tuning LLMs on abstract logic problem\ngeneralize to contextualized logic problems and vice versa? To investigate\nthese questions, we focus on standard propositional logic, specifically\npropositional deductive and abductive logic reasoning. In particular, we\nconstruct instantiated datasets for deductive and abductive reasoning with 4\nlevels of difficulty, encompassing 12 distinct categories or domains based on\nthe categorization of Wikipedia. Our experiments aim to provide insights into\ndisentangling context in logical reasoning and the true reasoning capabilities\nof LLMs and their generalization potential. The code and dataset are available\nat: https://github.com/agiresearch/ContextHub.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02787v1",
    "published_date": "2024-06-04 21:25:06 UTC",
    "updated_date": "2024-06-04 21:25:06 UTC"
  },
  {
    "arxiv_id": "2406.06583v1",
    "title": "Adaptive multiple optimal learning factors for neural network training",
    "authors": [
      "Jeshwanth Challagundla"
    ],
    "abstract": "This thesis presents a novel approach to neural network training that\naddresses the challenge of determining the optimal number of learning factors.\nThe proposed Adaptive Multiple Optimal Learning Factors (AMOLF) algorithm\ndynamically adjusts the number of learning factors based on the error change\nper multiply, leading to improved training efficiency and accuracy. The thesis\nalso introduces techniques for grouping weights based on the curvature of the\nobjective function and for compressing large Hessian matrices. Experimental\nresults demonstrate the superior performance of AMOLF compared to existing\nmethods like OWO-MOLF and Levenberg-Marquardt.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06583v1",
    "published_date": "2024-06-04 21:18:24 UTC",
    "updated_date": "2024-06-04 21:18:24 UTC"
  },
  {
    "arxiv_id": "2406.02780v1",
    "title": "LADI v2: Multi-label Dataset and Classifiers for Low-Altitude Disaster Imagery",
    "authors": [
      "Samuel Scheele",
      "Katherine Picchione",
      "Jeffrey Liu"
    ],
    "abstract": "ML-based computer vision models are promising tools for supporting emergency\nmanagement operations following natural disasters. Arial photographs taken from\nsmall manned and unmanned aircraft can be available soon after a disaster and\nprovide valuable information from multiple perspectives for situational\nawareness and damage assessment applications. However, emergency managers often\nface challenges finding the most relevant photos among the tens of thousands\nthat may be taken after an incident. While ML-based solutions could enable more\neffective use of aerial photographs, there is still a lack of training data for\nimagery of this type from multiple perspectives and for multiple hazard types.\nTo address this, we present the LADI v2 (Low Altitude Disaster Imagery version\n2) dataset, a curated set of about 10,000 disaster images captured in the\nUnited States by the Civil Air Patrol (CAP) in response to federally-declared\nemergencies (2015-2023) and annotated for multi-label classification by trained\nCAP volunteers. We also provide two pretrained baseline classifiers and compare\ntheir performance to state-of-the-art vision-language models in multi-label\nclassification. The data and code are released publicly to support the\ndevelopment of computer vision models for emergency management research and\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68T45",
      "J.2"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02780v1",
    "published_date": "2024-06-04 20:51:04 UTC",
    "updated_date": "2024-06-04 20:51:04 UTC"
  },
  {
    "arxiv_id": "2406.02775v1",
    "title": "Diagnostic Digital Twin for Anomaly Detection in Floating Offshore Wind Energy",
    "authors": [
      "Florian Stadtmann",
      "Adil Rasheed"
    ],
    "abstract": "The demand for condition-based and predictive maintenance is rising across\nindustries, especially for remote, high-value, and high-risk assets. In this\narticle, the diagnostic digital twin concept is introduced, discussed, and\nimplemented for a floating offshore turbine. A diagnostic digital twin is a\nvirtual representation of an asset that combines real-time data and models to\nmonitor damage, detect anomalies, and diagnose failures, thereby enabling\ncondition-based and predictive maintenance. By applying diagnostic digital\ntwins to offshore assets, unexpected failures can be alleviated, but the\nimplementation can prove challenging. Here, a diagnostic digital twin is\nimplemented for an operational floating offshore wind turbine. The asset is\nmonitored through measurements. Unsupervised learning methods are employed to\nbuild a normal operation model, detect anomalies, and provide a fault\ndiagnosis. Warnings and diagnoses are sent through text messages, and a more\ndetailed diagnosis can be accessed in a virtual reality interface. The\ndiagnostic digital twin successfully detected an anomaly with high confidence\nhours before a failure occurred. The paper concludes by discussing diagnostic\ndigital twins in the broader context of offshore engineering. The presented\napproach can be generalized to other offshore assets to improve maintenance and\nincrease the lifetime, efficiency, and sustainability of offshore assets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02775v1",
    "published_date": "2024-06-04 20:45:20 UTC",
    "updated_date": "2024-06-04 20:45:20 UTC"
  },
  {
    "arxiv_id": "2406.03506v5",
    "title": "Fuzzy Convolution Neural Networks for Tabular Data Classification",
    "authors": [
      "Arun D. Kulkarni"
    ],
    "abstract": "Recently, convolution neural networks (CNNs) have attracted a great deal of\nattention due to their remarkable performance in various domains, particularly\nin image and text classification tasks. However, their application to tabular\ndata classification remains underexplored. There are many fields such as\nbioinformatics, finance, medicine where nonimage data are prevalent. Adaption\nof CNNs to classify nonimage data remains highly challenging. This paper\ninvestigates the efficacy of CNNs for tabular data classification, aiming to\nbridge the gap between traditional machine learning approaches and deep\nlearning techniques. We propose a novel framework fuzzy convolution neural\nnetwork (FCNN) tailored specifically for tabular data to capture local patterns\nwithin feature vectors. In our approach, we map feature values to fuzzy\nmemberships. The fuzzy membership vectors are converted into images that are\nused to train the CNN model. The trained CNN model is used to classify unknown\nfeature vectors. To validate our approach, we generated six complex noisy data\nsets. We used randomly selected seventy percent samples from each data set for\ntraining and thirty percent for testing. The data sets were also classified\nusing the state-of-the-art machine learning algorithms such as the decision\ntree (DT), support vector machine (SVM), fuzzy neural network (FNN), Bayes\nclassifier, and Random Forest (RF). Experimental results demonstrate that our\nproposed model can effectively learn meaningful representations from tabular\ndata, achieving competitive or superior performance compared to existing\nmethods. Overall, our finding suggests that the proposed FCNN model holds\npromise as a viable alternative for tabular data classification tasks, offering\na fresh prospective and potentially unlocking new opportunities for leveraging\ndeep learning in structured data analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.10",
      "I.4.6"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 16 figures, Submitted to IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2406.03506v5",
    "published_date": "2024-06-04 20:33:35 UTC",
    "updated_date": "2024-10-14 21:21:31 UTC"
  },
  {
    "arxiv_id": "2406.02764v1",
    "title": "Adaptive Preference Scaling for Reinforcement Learning with Human Feedback",
    "authors": [
      "Ilgee Hong",
      "Zichong Li",
      "Alexander Bukharin",
      "Yixiao Li",
      "Haoming Jiang",
      "Tianbao Yang",
      "Tuo Zhao"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is a prevalent approach to\nalign AI systems with human values by learning rewards from human preference\ndata. Due to various reasons, however, such data typically takes the form of\nrankings over pairs of trajectory segments, which fails to capture the varying\nstrengths of preferences across different pairs. In this paper, we propose a\nnovel adaptive preference loss, underpinned by distributionally robust\noptimization (DRO), designed to address this uncertainty in preference\nstrength. By incorporating an adaptive scaling parameter into the loss for each\npair, our method increases the flexibility of the reward function.\nSpecifically, it assigns small scaling parameters to pairs with ambiguous\npreferences, leading to more comparable rewards, and large scaling parameters\nto those with clear preferences for more distinct rewards. Computationally, our\nproposed loss function is strictly convex and univariate with respect to each\nscaling parameter, enabling its efficient optimization through a simple\nsecond-order algorithm. Our method is versatile and can be readily adapted to\nvarious preference optimization frameworks, including direct preference\noptimization (DPO). Our experiments with robotic control and natural language\ngeneration with large language models (LLMs) show that our method not only\nimproves policy performance but also aligns reward function selection more\nclosely with policy optimization, simplifying the hyperparameter tuning\nprocess.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02764v1",
    "published_date": "2024-06-04 20:33:22 UTC",
    "updated_date": "2024-06-04 20:33:22 UTC"
  },
  {
    "arxiv_id": "2406.03505v1",
    "title": "Dynamic and Adaptive Feature Generation with LLM",
    "authors": [
      "Xinhao Zhang",
      "Jinghan Zhang",
      "Banafsheh Rekabdar",
      "Yuanchun Zhou",
      "Pengfei Wang",
      "Kunpeng Liu"
    ],
    "abstract": "The representation of feature space is a crucial environment where data\npoints get vectorized and embedded for upcoming modeling. Thus the efficacy of\nmachine learning (ML) algorithms is closely related to the quality of feature\nengineering. As one of the most important techniques, feature generation\ntransforms raw data into an optimized feature space conducive to model training\nand further refines the space. Despite the advancements in automated feature\nengineering and feature generation, current methodologies often suffer from\nthree fundamental issues: lack of explainability, limited applicability, and\ninflexible strategy. These shortcomings frequently hinder and limit the\ndeployment of ML models across varied scenarios. Our research introduces a\nnovel approach adopting large language models (LLMs) and feature-generating\nprompts to address these challenges. We propose a dynamic and adaptive feature\ngeneration method that enhances the interpretability of the feature generation\nprocess. Our approach broadens the applicability across various data types and\ntasks and draws advantages over strategic flexibility. A broad range of\nexperiments showcases that our approach is significantly superior to existing\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03505v1",
    "published_date": "2024-06-04 20:32:14 UTC",
    "updated_date": "2024-06-04 20:32:14 UTC"
  },
  {
    "arxiv_id": "2406.02761v1",
    "title": "Multi-layer Learnable Attention Mask for Multimodal Tasks",
    "authors": [
      "Wayner Barrios",
      "SouYoung Jin"
    ],
    "abstract": "While the Self-Attention mechanism in the Transformer model has proven to be\neffective in many domains, we observe that it is less effective in more diverse\nsettings (e.g. multimodality) due to the varying granularity of each token and\nthe high computational demands of lengthy sequences. To address the challenges,\nwe introduce the Learnable Attention Mask (LAM), strategically designed to\nglobally regulate attention maps and prioritize critical tokens within the\nsequence. Leveraging the Self-Attention module in a BERT-like transformer\nnetwork, our approach adeptly captures associations between tokens. The\nextension of the LAM to a multi-layer version accommodates the varied\ninformation aspects embedded at each layer of the Transformer network.\nComprehensive experimental validation on various datasets, such as MADv2,\nQVHighlights, ImageNet 1K, and MSRVTT, demonstrates the efficacy of the LAM,\nexemplifying its ability to enhance model performance while mitigating\nredundant computations. This pioneering approach presents a significant\nadvancement in enhancing the understanding of complex scenarios, such as in\nmovie understanding.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02761v1",
    "published_date": "2024-06-04 20:28:02 UTC",
    "updated_date": "2024-06-04 20:28:02 UTC"
  },
  {
    "arxiv_id": "2406.02756v1",
    "title": "Aligning Large Language Models via Fine-grained Supervision",
    "authors": [
      "Dehong Xu",
      "Liang Qiu",
      "Minseok Kim",
      "Faisal Ladhak",
      "Jaeyoung Do"
    ],
    "abstract": "Pre-trained large-scale language models (LLMs) excel at producing coherent\narticles, yet their outputs may be untruthful, toxic, or fail to align with\nuser expectations. Current approaches focus on using reinforcement learning\nwith human feedback (RLHF) to improve model alignment, which works by\ntransforming coarse human preferences of LLM outputs into a feedback signal\nthat guides the model learning process. However, because this approach operates\non sequence-level feedback, it lacks the precision to identify the exact parts\nof the output affecting user preferences. To address this gap, we propose a\nmethod to enhance LLM alignment through fine-grained token-level supervision.\nSpecifically, we ask annotators to minimally edit less preferred responses\nwithin the standard reward modeling dataset to make them more favorable,\nensuring changes are made only where necessary while retaining most of the\noriginal content. The refined dataset is used to train a token-level reward\nmodel, which is then used for training our fine-grained Proximal Policy\nOptimization (PPO) model. Our experiment results demonstrate that this approach\ncan achieve up to an absolute improvement of $5.1\\%$ in LLM performance, in\nterms of win rate against the reference model, compared with the traditional\nPPO model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02756v1",
    "published_date": "2024-06-04 20:21:45 UTC",
    "updated_date": "2024-06-04 20:21:45 UTC"
  },
  {
    "arxiv_id": "2406.02748v1",
    "title": "Story Generation from Visual Inputs: Techniques, Related Tasks, and Challenges",
    "authors": [
      "Daniel A. P. Oliveira",
      "Eugénio Ribeiro",
      "David Martins de Matos"
    ],
    "abstract": "Creating engaging narratives from visual data is crucial for automated\ndigital media consumption, assistive technologies, and interactive\nentertainment. This survey covers methodologies used in the generation of these\nnarratives, focusing on their principles, strengths, and limitations.\n  The survey also covers tasks related to automatic story generation, such as\nimage and video captioning, and visual question answering, as well as story\ngeneration without visual inputs. These tasks share common challenges with\nvisual story generation and have served as inspiration for the techniques used\nin the field. We analyze the main datasets and evaluation metrics, providing a\ncritical perspective on their limitations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02748v1",
    "published_date": "2024-06-04 20:07:58 UTC",
    "updated_date": "2024-06-04 20:07:58 UTC"
  },
  {
    "arxiv_id": "2406.02723v1",
    "title": "Predicting AI Agent Behavior through Approximation of the Perron-Frobenius Operator",
    "authors": [
      "Shiqi Zhang",
      "Darshan Gadginmath",
      "Fabio Pasqualetti"
    ],
    "abstract": "Predicting the behavior of AI-driven agents is particularly challenging\nwithout a preexisting model. In our paper, we address this by treating AI\nagents as nonlinear dynamical systems and adopting a probabilistic perspective\nto predict their statistical behavior using the Perron-Frobenius (PF) operator.\nWe formulate the approximation of the PF operator as an entropy minimization\nproblem, which can be solved by leveraging the Markovian property of the\noperator and decomposing its spectrum. Our data-driven methodology\nsimultaneously approximates the PF operator to perform prediction of the\nevolution of the agents and also predicts the terminal probability density of\nAI agents, such as robotic systems and generative models. We demonstrate the\neffectiveness of our prediction model through extensive experiments on\npractical systems driven by AI algorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 4 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2406.02723v1",
    "published_date": "2024-06-04 19:06:49 UTC",
    "updated_date": "2024-06-04 19:06:49 UTC"
  },
  {
    "arxiv_id": "2406.02721v3",
    "title": "Self-Control of LLM Behaviors by Compressing Suffix Gradient into Prefix Controller",
    "authors": [
      "Min Cai",
      "Yuchen Zhang",
      "Shichang Zhang",
      "Fan Yin",
      "Dan Zhang",
      "Difan Zou",
      "Yisong Yue",
      "Ziniu Hu"
    ],
    "abstract": "We propose SelfControl, an inference-time model control method utilizing\ngradients to control the behavior of large language models (LLMs) without\nexplicit human annotations. Given a desired behavior expressed in a natural\nlanguage suffix string concatenated to the input prompt, SelfControl computes\ngradients of the LLM's self-evaluation of the suffix with respect to its latent\nrepresentations. The gradients are used to directly control the auto-regressive\ngeneration process towards desired behaviors, which eliminates human\nsupervision, achieves precise and transparent control, and offers on-the-fly\nadaptability. To further enhance efficiency, we introduce SelfControl_{Prefix},\na compact module that encapsulates the learned representations from gradients\ninto a SelfControl_{Prefix}, facilitating efficient inference-time control with\nno latency compared to the original model and allowing control for multiple\nbehaviors simultaneously. Our experiments demonstrate SelfControl's efficacy\nacross multiple domains, where it improves over SOTA for 8.3% in\ndetoxification, 3.1% in truthfulness enhancement, 4%~10% in controlling on\nemotion tones, and 48.2% in privacy protection, i.e., completely remove privacy\nleakage issue. Additionally, we demonstrate that SelfControl can be used for\ndata synthesis and to improve reasoning abilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Website: https://llm-self-control.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.02721v3",
    "published_date": "2024-06-04 19:05:10 UTC",
    "updated_date": "2024-10-12 08:30:33 UTC"
  },
  {
    "arxiv_id": "2406.02659v3",
    "title": "Reanimating Images using Neural Representations of Dynamic Stimuli",
    "authors": [
      "Jacob Yeung",
      "Andrew F. Luo",
      "Gabriel Sarch",
      "Margaret M. Henderson",
      "Deva Ramanan",
      "Michael J. Tarr"
    ],
    "abstract": "While computer vision models have made incredible strides in static image\nrecognition, they still do not match human performance in tasks that require\nthe understanding of complex, dynamic motion. This is notably true for\nreal-world scenarios where embodied agents face complex and motion-rich\nenvironments. Our approach, BrainNRDS (Brain-Neural Representations of Dynamic\nStimuli), leverages state-of-the-art video diffusion models to decouple static\nimage representation from motion generation, enabling us to utilize fMRI brain\nactivity for a deeper understanding of human responses to dynamic visual\nstimuli. Conversely, we also demonstrate that information about the brain's\nrepresentation of motion can enhance the prediction of optical flow in\nartificial systems. Our novel approach leads to four main findings: (1) Visual\nmotion, represented as fine-grained, object-level resolution optical flow, can\nbe decoded from brain activity generated by participants viewing video stimuli;\n(2) Video encoders outperform image-based models in predicting video-driven\nbrain activity; (3) Brain-decoded motion signals enable realistic video\nreanimation based only on the initial frame of the video; and (4) We extend\nprior work to achieve full video decoding from video-driven brain activity.\nBrainNRDS advances our understanding of how the brain represents spatial and\ntemporal information in dynamic visual scenes. Our findings demonstrate the\npotential of combining brain imaging with video diffusion models for developing\nmore robust and biologically-inspired computer vision systems. We show\nadditional decoding and encoding examples on this site:\nhttps://brain-nrds.github.io/.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Project Page: https://brain-nrds.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.02659v3",
    "published_date": "2024-06-04 17:59:49 UTC",
    "updated_date": "2025-03-25 17:59:01 UTC"
  },
  {
    "arxiv_id": "2406.02543v2",
    "title": "To Believe or Not to Believe Your LLM",
    "authors": [
      "Yasin Abbasi Yadkori",
      "Ilja Kuzborskij",
      "András György",
      "Csaba Szepesvári"
    ],
    "abstract": "We explore uncertainty quantification in large language models (LLMs), with\nthe goal to identify when uncertainty in responses given a query is large. We\nsimultaneously consider both epistemic and aleatoric uncertainties, where the\nformer comes from the lack of knowledge about the ground truth (such as about\nfacts or the language), and the latter comes from irreducible randomness (such\nas multiple possible answers). In particular, we derive an\ninformation-theoretic metric that allows to reliably detect when only epistemic\nuncertainty is large, in which case the output of the model is unreliable. This\ncondition can be computed based solely on the output of the model obtained\nsimply by some special iterative prompting based on the previous responses.\nSuch quantification, for instance, allows to detect hallucinations (cases when\nepistemic uncertainty is high) in both single- and multi-answer responses. This\nis in contrast to many standard uncertainty quantification strategies (such as\nthresholding the log-likelihood of a response) where hallucinations in the\nmulti-answer case cannot be detected. We conduct a series of experiments which\ndemonstrate the advantage of our formulation. Further, our investigations shed\nsome light on how the probabilities assigned to a given output by an LLM can be\namplified by iterative prompting, which might be of independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02543v2",
    "published_date": "2024-06-04 17:58:18 UTC",
    "updated_date": "2024-07-17 15:55:51 UTC"
  },
  {
    "arxiv_id": "2406.02539v2",
    "title": "Parrot: Multilingual Visual Instruction Tuning",
    "authors": [
      "Hai-Long Sun",
      "Da-Wei Zhou",
      "Yang Li",
      "Shiyin Lu",
      "Chao Yi",
      "Qing-Guo Chen",
      "Zhao Xu",
      "Weihua Luo",
      "Kaifu Zhang",
      "De-Chuan Zhan",
      "Han-Jia Ye"
    ],
    "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) like GPT-4V\nhas marked a significant step towards artificial general intelligence. Existing\nmethods mainly focus on aligning vision encoders with LLMs through supervised\nfine-tuning (SFT) to endow LLMs with multimodal abilities, making MLLMs'\ninherent ability to react to multiple languages progressively deteriorate as\nthe training process evolves. We empirically find that the imbalanced SFT\ndatasets, primarily composed of English-centric image-text pairs, lead to\nsignificantly reduced performance in non-English languages. This is due to the\nfailure of aligning the vision encoder and LLM with multilingual tokens during\nthe SFT process. In this paper, we introduce Parrot, a novel method that\nutilizes textual guidance to drive visual token alignment at the language\nlevel. Parrot makes the visual tokens condition on diverse language inputs and\nuses Mixture-of-Experts (MoE) to promote the alignment of multilingual tokens.\nSpecifically, to enhance non-English visual tokens alignment, we compute the\ncross-attention using the initial visual features and textual embeddings, the\nresult of which is then fed into the MoE router to select the most relevant\nexperts. The selected experts subsequently convert the initial visual tokens\ninto language-specific visual tokens. Moreover, considering the current lack of\nbenchmarks for evaluating multilingual capabilities within the field, we\ncollect and make available a Massive Multilingual Multimodal Benchmark which\nincludes 6 languages, 15 categories, and 12,000 questions, named as MMMB. Our\nmethod not only demonstrates state-of-the-art performance on multilingual\nMMBench and MMMB, but also excels across a broad range of multimodal tasks.\nBoth the source code and the training dataset of Parrot will be made publicly\navailable. Code is available at: https://github.com/AIDC-AI/Parrot.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at: https://github.com/AIDC-AI/Parrot",
    "pdf_url": "http://arxiv.org/pdf/2406.02539v2",
    "published_date": "2024-06-04 17:56:28 UTC",
    "updated_date": "2024-08-11 05:15:46 UTC"
  },
  {
    "arxiv_id": "2406.02534v2",
    "title": "Enhancing predictive imaging biomarker discovery through treatment effect analysis",
    "authors": [
      "Shuhan Xiao",
      "Lukas Klein",
      "Jens Petersen",
      "Philipp Vollmuth",
      "Paul F. Jaeger",
      "Klaus H. Maier-Hein"
    ],
    "abstract": "Identifying predictive covariates, which forecast individual treatment\neffectiveness, is crucial for decision-making across different disciplines such\nas personalized medicine. These covariates, referred to as biomarkers, are\nextracted from pre-treatment data, often within randomized controlled trials,\nand should be distinguished from prognostic biomarkers, which are independent\nof treatment assignment. Our study focuses on discovering predictive imaging\nbiomarkers, specific image features, by leveraging pre-treatment images to\nuncover new causal relationships. Unlike labor-intensive approaches relying on\nhandcrafted features prone to bias, we present a novel task of directly\nlearning predictive features from images. We propose an evaluation protocol to\nassess a model's ability to identify predictive imaging biomarkers and\ndifferentiate them from purely prognostic ones by employing statistical testing\nand a comprehensive analysis of image feature attribution. We explore the\nsuitability of deep learning models originally developed for estimating the\nconditional average treatment effect (CATE) for this task, which have been\nassessed primarily for their precision of CATE estimation while overlooking the\nevaluation of imaging biomarker discovery. Our proof-of-concept analysis\ndemonstrates the feasibility and potential of our approach in discovering and\nvalidating predictive imaging biomarkers from synthetic outcomes and real-world\nimage datasets. Our code is available at\n\\url{https://github.com/MIC-DKFZ/predictive_image_biomarker_analysis}.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted to WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.02534v2",
    "published_date": "2024-06-04 17:54:44 UTC",
    "updated_date": "2024-12-09 15:58:55 UTC"
  },
  {
    "arxiv_id": "2406.02529v2",
    "title": "ReLUs Are Sufficient for Learning Implicit Neural Representations",
    "authors": [
      "Joseph Shenouda",
      "Yamin Zhou",
      "Robert D. Nowak"
    ],
    "abstract": "Motivated by the growing theoretical understanding of neural networks that\nemploy the Rectified Linear Unit (ReLU) as their activation function, we\nrevisit the use of ReLU activation functions for learning implicit neural\nrepresentations (INRs). Inspired by second order B-spline wavelets, we\nincorporate a set of simple constraints to the ReLU neurons in each layer of a\ndeep neural network (DNN) to remedy the spectral bias. This in turn enables its\nuse for various INR tasks. Empirically, we demonstrate that, contrary to\npopular belief, one can learn state-of-the-art INRs based on a DNN composed of\nonly ReLU neurons. Next, by leveraging recent theoretical works which\ncharacterize the kinds of functions ReLU neural networks learn, we provide a\nway to quantify the regularity of the learned function. This offers a\nprincipled approach to selecting the hyperparameters in INR architectures. We\nsubstantiate our claims through experiments in signal representation, super\nresolution, and computed tomography, demonstrating the versatility and\neffectiveness of our method. The code for all experiments can be found at\nhttps://github.com/joeshenouda/relu-inrs.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02529v2",
    "published_date": "2024-06-04 17:51:08 UTC",
    "updated_date": "2024-08-01 20:53:09 UTC"
  },
  {
    "arxiv_id": "2406.02657v2",
    "title": "Block Transformer: Global-to-Local Language Modeling for Fast Inference",
    "authors": [
      "Namgyu Ho",
      "Sangmin Bae",
      "Taehyeon Kim",
      "Hyunjik Jo",
      "Yireun Kim",
      "Tal Schuster",
      "Adam Fisch",
      "James Thorne",
      "Se-Young Yun"
    ],
    "abstract": "We introduce the Block Transformer which adopts hierarchical global-to-local\nmodeling to autoregressive transformers to mitigate the inference bottlenecks\nassociated with self-attention. Self-attention requires the key-value (KV)\ncache of all previous sequences to be retrieved from memory at every decoding\nstep to retrieve context information, leading to two primary bottlenecks during\nbatch inference. First, there is a significant delay in obtaining the first\ntoken, as the information of the entire prompt must first be processed to\nprefill the KV cache. Second, computation of subsequent tokens is bottlenecked\nby the high memory I/O demand of fetching the entire KV cache, which grows\nlinearly with sequence length, incurring quadratic memory reads overall. We\ndesign the Block Transformer to strategically mitigate these costs, by\nincorporating coarsity and locality into an integrated global-to-local\narchitecture. At the lower layers, we aggregate tokens into fixed size blocks\nto apply attention across the entire sequence at coarse-grained detail, to\ncapture the global context while minimizing KV cache overhead. At upper layers,\nwe apply attention within each block to decode individual tokens, to model\nfine-grained details with a lightweight local KV cache. We pretrain vanilla and\nBlock Transformers from scratch and demonstrate that Block Transformers reach\n10--20x inference throughput compared to vanilla transformers with equivalent\nperplexity and zero-shot task performance. Code is available at\nhttps://github.com/itsnamgyu/block-transformer.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages, 24 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.02657v2",
    "published_date": "2024-06-04 17:45:26 UTC",
    "updated_date": "2024-11-01 08:52:18 UTC"
  },
  {
    "arxiv_id": "2406.02523v1",
    "title": "RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots",
    "authors": [
      "Soroush Nasiriany",
      "Abhiram Maddukuri",
      "Lance Zhang",
      "Adeet Parikh",
      "Aaron Lo",
      "Abhishek Joshi",
      "Ajay Mandlekar",
      "Yuke Zhu"
    ],
    "abstract": "Recent advancements in Artificial Intelligence (AI) have largely been\npropelled by scaling. In Robotics, scaling is hindered by the lack of access to\nmassive robot datasets. We advocate using realistic physical simulation as a\nmeans to scale environments, tasks, and datasets for robot learning methods. We\npresent RoboCasa, a large-scale simulation framework for training generalist\nrobots in everyday environments. RoboCasa features realistic and diverse scenes\nfocusing on kitchen environments. We provide thousands of 3D assets across over\n150 object categories and dozens of interactable furniture and appliances. We\nenrich the realism and diversity of our simulation with generative AI tools,\nsuch as object assets from text-to-3D models and environment textures from\ntext-to-image models. We design a set of 100 tasks for systematic evaluation,\nincluding composite tasks generated by the guidance of large language models.\nTo facilitate learning, we provide high-quality human demonstrations and\nintegrate automated trajectory generation methods to substantially enlarge our\ndatasets with minimal human burden. Our experiments show a clear scaling trend\nin using synthetically generated robot data for large-scale imitation learning\nand show great promise in harnessing simulation data in real-world tasks.\nVideos and open-source code are available at https://robocasa.ai/",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "RSS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02523v1",
    "published_date": "2024-06-04 17:41:31 UTC",
    "updated_date": "2024-06-04 17:41:31 UTC"
  },
  {
    "arxiv_id": "2406.02511v1",
    "title": "V-Express: Conditional Dropout for Progressive Training of Portrait Video Generation",
    "authors": [
      "Cong Wang",
      "Kuan Tian",
      "Jun Zhang",
      "Yonghang Guan",
      "Feng Luo",
      "Fei Shen",
      "Zhiwei Jiang",
      "Qing Gu",
      "Xiao Han",
      "Wei Yang"
    ],
    "abstract": "In the field of portrait video generation, the use of single images to\ngenerate portrait videos has become increasingly prevalent. A common approach\ninvolves leveraging generative models to enhance adapters for controlled\ngeneration. However, control signals (e.g., text, audio, reference image, pose,\ndepth map, etc.) can vary in strength. Among these, weaker conditions often\nstruggle to be effective due to interference from stronger conditions, posing a\nchallenge in balancing these conditions. In our work on portrait video\ngeneration, we identified audio signals as particularly weak, often\novershadowed by stronger signals such as facial pose and reference image.\nHowever, direct training with weak signals often leads to difficulties in\nconvergence. To address this, we propose V-Express, a simple method that\nbalances different control signals through the progressive training and the\nconditional dropout operation. Our method gradually enables effective control\nby weak conditions, thereby achieving generation capabilities that\nsimultaneously take into account the facial pose, reference image, and audio.\nThe experimental results demonstrate that our method can effectively generate\nportrait videos controlled by audio. Furthermore, a potential solution is\nprovided for the simultaneous and effective use of conditions of varying\nstrengths.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02511v1",
    "published_date": "2024-06-04 17:32:52 UTC",
    "updated_date": "2024-06-04 17:32:52 UTC"
  },
  {
    "arxiv_id": "2406.02507v3",
    "title": "Guiding a Diffusion Model with a Bad Version of Itself",
    "authors": [
      "Tero Karras",
      "Miika Aittala",
      "Tuomas Kynkäänniemi",
      "Jaakko Lehtinen",
      "Timo Aila",
      "Samuli Laine"
    ],
    "abstract": "The primary axes of interest in image-generating diffusion models are image\nquality, the amount of variation in the results, and how well the results align\nwith a given condition, e.g., a class label or a text prompt. The popular\nclassifier-free guidance approach uses an unconditional model to guide a\nconditional model, leading to simultaneously better prompt alignment and\nhigher-quality images at the cost of reduced variation. These effects seem\ninherently entangled, and thus hard to control. We make the surprising\nobservation that it is possible to obtain disentangled control over image\nquality without compromising the amount of variation by guiding generation\nusing a smaller, less-trained version of the model itself rather than an\nunconditional model. This leads to significant improvements in ImageNet\ngeneration, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using\npublicly available networks. Furthermore, the method is also applicable to\nunconditional diffusion models, drastically improving their quality.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02507v3",
    "published_date": "2024-06-04 17:25:59 UTC",
    "updated_date": "2024-12-19 10:43:11 UTC"
  },
  {
    "arxiv_id": "2406.02500v3",
    "title": "Towards Efficient Mixture of Experts: A Holistic Study of Compression Techniques",
    "authors": [
      "Shwai He",
      "Daize Dong",
      "Liang Ding",
      "Ang Li"
    ],
    "abstract": "Scaling large language models has driven remarkable advancements across\nvarious domains, yet the continual increase in model size presents significant\nchallenges for real-world deployment. The Mixture of Experts (MoE) architecture\noffers a promising solution by dynamically selecting and activating only a\nsubset of experts during inference, thus substantially reducing computational\ncosts while preserving high performance. Despite these benefits, MoE introduces\nnew inefficiencies, such as excessive parameters and communication overhead. In\nthis work, we present a holistic study of compression techniques for Mixture of\nExperts to enhance both efficiency and scalability. While recent efforts have\nfocused on Expert Trimming, which reduces the number of experts, these\napproaches still suffer from considerable communication and computational\ncosts. To address this, we propose more aggressive strategies, such as Layer\nDrop, which removes entire MoE layers, and Block Drop, which eliminates\ntransformer blocks. Surprisingly, these aggressive pruning techniques not only\npreserve model performance but also substantially improve computation and\nmemory efficiency. Furthermore, beyond Expert Trimming, we also introduce\nExpert Slimming, which compresses individual experts to further boost\nperformance and can be seamlessly integrated with Expert Trimming. Extensive\nexperimental results demonstrate the effectiveness of our proposed\nmethods-Layer Drop and Block Drop-along with the comprehensive recipe that\nintegrates Expert Slimming and Expert Trimming, achieving a 6.05x speedup with\n77.1% reduced memory usage while maintaining over 92% of performance on\nMixtral-8x7B. Our code is released at\nhttps://github.com/CASE-Lab-UMD/Unified-MoE-Compression.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Transactions on Machine Learning Research (TMLR)",
    "pdf_url": "http://arxiv.org/pdf/2406.02500v3",
    "published_date": "2024-06-04 17:18:40 UTC",
    "updated_date": "2025-03-17 14:18:42 UTC"
  },
  {
    "arxiv_id": "2406.02497v1",
    "title": "Dropout MPC: An Ensemble Neural MPC Approach for Systems with Learned Dynamics",
    "authors": [
      "Spyridon Syntakas",
      "Kostas Vlachos"
    ],
    "abstract": "Neural networks are lately more and more often being used in the context of\ndata-driven control, as an approximate model of the true system dynamics. Model\nPredictive Control (MPC) adopts this practise leading to neural MPC strategies.\nThis raises a question of whether the trained neural network has converged and\ngeneralized in a way that the learned model encapsulates an accurate\napproximation of the true dynamic model of the system, thus making it a\nreliable choice for model-based control, especially for disturbed and uncertain\nsystems. To tackle that, we propose Dropout MPC, a novel sampling-based\nensemble neural MPC algorithm that employs the Monte-Carlo dropout technique on\nthe learned system model. The closed loop is based on an ensemble of predictive\ncontrollers, that are used simultaneously at each time-step for trajectory\noptimization. Each member of the ensemble influences the control input, based\non a weighted voting scheme, thus by employing different realizations of the\nlearned system dynamics, neural control becomes more reliable by design. An\nadditional strength of the method is that it offers by design a way to estimate\nfuture uncertainty, leading to cautious control. While the method aims in\ngeneral at uncertain systems with complex dynamics, where models derived from\nfirst principles are hard to infer, to showcase the application we utilize data\ngathered in the laboratory from a real mobile manipulator and employ the\nproposed algorithm for the navigation of the robot in simulation.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02497v1",
    "published_date": "2024-06-04 17:15:25 UTC",
    "updated_date": "2024-06-04 17:15:25 UTC"
  },
  {
    "arxiv_id": "2406.02496v1",
    "title": "Kolmogorov-Arnold Networks for Time Series: Bridging Predictive Power and Interpretability",
    "authors": [
      "Kunpeng Xu",
      "Lifei Chen",
      "Shengrui Wang"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KAN) is a groundbreaking model recently proposed\nby the MIT team, representing a revolutionary approach with the potential to be\na game-changer in the field. This innovative concept has rapidly garnered\nworldwide interest within the AI community. Inspired by the Kolmogorov-Arnold\nrepresentation theorem, KAN utilizes spline-parametrized univariate functions\nin place of traditional linear weights, enabling them to dynamically learn\nactivation patterns and significantly enhancing interpretability. In this\npaper, we explore the application of KAN to time series forecasting and propose\ntwo variants: T-KAN and MT-KAN. T-KAN is designed to detect concept drift\nwithin time series and can explain the nonlinear relationships between\npredictions and previous time steps through symbolic regression, making it\nhighly interpretable in dynamically changing environments. MT-KAN, on the other\nhand, improves predictive performance by effectively uncovering and leveraging\nthe complex relationships among variables in multivariate time series.\nExperiments validate the effectiveness of these approaches, demonstrating that\nT-KAN and MT-KAN significantly outperform traditional methods in time series\nforecasting tasks, not only enhancing predictive accuracy but also improving\nmodel interpretability. This research opens new avenues for adaptive\nforecasting models, highlighting the potential of KAN as a powerful and\ninterpretable tool in predictive analytics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02496v1",
    "published_date": "2024-06-04 17:14:31 UTC",
    "updated_date": "2024-06-04 17:14:31 UTC"
  },
  {
    "arxiv_id": "2406.02483v1",
    "title": "How Do Neural Spoofing Countermeasures Detect Partially Spoofed Audio?",
    "authors": [
      "Tianchi Liu",
      "Lin Zhang",
      "Rohan Kumar Das",
      "Yi Ma",
      "Ruijie Tao",
      "Haizhou Li"
    ],
    "abstract": "Partially manipulating a sentence can greatly change its meaning. Recent work\nshows that countermeasures (CMs) trained on partially spoofed audio can\neffectively detect such spoofing. However, the current understanding of the\ndecision-making process of CMs is limited. We utilize Grad-CAM and introduce a\nquantitative analysis metric to interpret CMs' decisions. We find that CMs\nprioritize the artifacts of transition regions created when concatenating bona\nfide and spoofed audio. This focus differs from that of CMs trained on fully\nspoofed audio, which concentrate on the pattern differences between bona fide\nand spoofed parts. Our further investigation explains the varying nature of\nCMs' focus while making correct or incorrect predictions. These insights\nprovide a basis for the design of CM models and the creation of datasets.\nMoreover, this work lays a foundation of interpretability in the field of\npartial spoofed audio detection that has not been well explored previously.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02483v1",
    "published_date": "2024-06-04 16:51:42 UTC",
    "updated_date": "2024-06-04 16:51:42 UTC"
  },
  {
    "arxiv_id": "2407.16883v1",
    "title": "A Standardized Machine-readable Dataset Documentation Format for Responsible AI",
    "authors": [
      "Nitisha Jain",
      "Mubashara Akhtar",
      "Joan Giner-Miguelez",
      "Rajat Shinde",
      "Joaquin Vanschoren",
      "Steffen Vogler",
      "Sujata Goswami",
      "Yuhan Rao",
      "Tim Santos",
      "Luis Oala",
      "Michalis Karamousadakis",
      "Manil Maskey",
      "Pierre Marcenac",
      "Costanza Conforti",
      "Michael Kuchnik",
      "Lora Aroyo",
      "Omar Benjelloun",
      "Elena Simperl"
    ],
    "abstract": "Data is critical to advancing AI technologies, yet its quality and\ndocumentation remain significant challenges, leading to adverse downstream\neffects (e.g., potential biases) in AI applications. This paper addresses these\nissues by introducing Croissant-RAI, a machine-readable metadata format\ndesigned to enhance the discoverability, interoperability, and trustworthiness\nof AI datasets. Croissant-RAI extends the Croissant metadata format and builds\nupon existing responsible AI (RAI) documentation frameworks, offering a\nstandardized set of attributes and practices to facilitate community-wide\nadoption. Leveraging established web-publishing practices, such as Schema.org,\nCroissant-RAI enables dataset users to easily find and utilize RAI metadata\nregardless of the platform on which the datasets are published. Furthermore, it\nis seamlessly integrated into major data search engines, repositories, and\nmachine learning frameworks, streamlining the reading and writing of\nresponsible AI metadata within practitioners' existing workflows. Croissant-RAI\nwas developed through a community-led effort. It has been designed to be\nadaptable to evolving documentation requirements and is supported by a Python\nlibrary and a visual editor.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CY",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages, appendix",
    "pdf_url": "http://arxiv.org/pdf/2407.16883v1",
    "published_date": "2024-06-04 16:40:14 UTC",
    "updated_date": "2024-06-04 16:40:14 UTC"
  },
  {
    "arxiv_id": "2406.02654v2",
    "title": "kNN Classification of Malware Data Dependency Graph Features",
    "authors": [
      "John Musgrave",
      "Anca Ralescu"
    ],
    "abstract": "Explainability in classification results are dependent upon the features used\nfor classification. Data dependency graph features representing data movement\nare directly correlated with operational semantics, and subject to fine grained\nanalysis. This study obtains accurate classification from the use of features\ntied to structure and semantics. By training an accurate model using labeled\ndata, this feature representation of semantics is shown to be correlated with\nground truth labels. This was performed using non-parametric learning with a\nnovel feature representation on a large scale dataset, the Kaggle 2015 Malware\ndataset. The features used enable fine grained analysis, increase in\nresolution, and explainable inferences. This allows for the body of the term\nfrequency distribution to be further analyzed and to provide an increase in\nfeature resolution over term frequency features. This method obtains high\naccuracy from analysis of a single instruction, a method that can be repeated\nfor additional instructions to obtain further increases in accuracy. This study\nevaluates the hypothesis that the semantic representation and analysis of\nstructure are able to make accurate predications and are also correlated to\nground truth labels. Additionally, similarity in the metric space can be\ncalculated directly without prior training. Our results provide evidence that\ndata dependency graphs accurately capture both semantic and structural\ninformation for increased explainability in classification results.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02654v2",
    "published_date": "2024-06-04 16:39:02 UTC",
    "updated_date": "2024-07-06 02:06:49 UTC"
  },
  {
    "arxiv_id": "2406.02653v1",
    "title": "Pancreatic Tumor Segmentation as Anomaly Detection in CT Images Using Denoising Diffusion Models",
    "authors": [
      "Reza Babaei",
      "Samuel Cheng",
      "Theresa Thai",
      "Shangqing Zhao"
    ],
    "abstract": "Despite the advances in medicine, cancer has remained a formidable challenge.\nParticularly in the case of pancreatic tumors, characterized by their diversity\nand late diagnosis, early detection poses a significant challenge crucial for\neffective treatment. The advancement of deep learning techniques, particularly\nsupervised algorithms, has significantly propelled pancreatic tumor detection\nin the medical field. However, supervised deep learning approaches necessitate\nextensive labeled medical images for training, yet acquiring such annotations\nis both limited and costly. Conversely, weakly supervised anomaly detection\nmethods, requiring only image-level annotations, have garnered interest.\nExisting methodologies predominantly hinge on generative adversarial networks\n(GANs) or autoencoder models, which can pose complexity in training and, these\nmodels may face difficulties in accurately preserving fine image details. This\nresearch presents a novel approach to pancreatic tumor detection, employing\nweak supervision anomaly detection through denoising diffusion algorithms. By\nincorporating a deterministic iterative process of adding and removing noise\nalong with classifier guidance, the method enables seamless translation of\nimages between diseased and healthy subjects, resulting in detailed anomaly\nmaps without requiring complex training protocols and segmentation masks. This\nstudy explores denoising diffusion models as a recent advancement over\ntraditional generative models like GANs, contributing to the field of\npancreatic tumor detection. Recognizing the low survival rates of pancreatic\ncancer, this study emphasizes the need for continued research to leverage\ndiffusion models' efficiency in medical segmentation tasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02653v1",
    "published_date": "2024-06-04 16:38:11 UTC",
    "updated_date": "2024-06-04 16:38:11 UTC"
  },
  {
    "arxiv_id": "2406.02465v1",
    "title": "An Empirical Study into Clustering of Unseen Datasets with Self-Supervised Encoders",
    "authors": [
      "Scott C. Lowe",
      "Joakim Bruslund Haurum",
      "Sageev Oore",
      "Thomas B. Moeslund",
      "Graham W. Taylor"
    ],
    "abstract": "Can pretrained models generalize to new datasets without any retraining? We\ndeploy pretrained image models on datasets they were not trained for, and\ninvestigate whether their embeddings form meaningful clusters. Our suite of\nbenchmarking experiments use encoders pretrained solely on ImageNet-1k with\neither supervised or self-supervised training techniques, deployed on image\ndatasets that were not seen during training, and clustered with conventional\nclustering algorithms. This evaluation provides new insights into the\nembeddings of self-supervised models, which prioritize different features to\nsupervised models. Supervised encoders typically offer more utility than SSL\nencoders within the training domain, and vice-versa far outside of it, however,\nfine-tuned encoders demonstrate the opposite trend. Clustering provides a way\nto evaluate the utility of self-supervised learned representations orthogonal\nto existing methods such as kNN. Additionally, we find the silhouette score\nwhen measured in a UMAP-reduced space is highly correlated with clustering\nperformance, and can therefore be used as a proxy for clustering performance on\ndata with no ground truth labels. Our code implementation is available at\n\\url{https://github.com/scottclowe/zs-ssl-clustering/}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02465v1",
    "published_date": "2024-06-04 16:34:17 UTC",
    "updated_date": "2024-06-04 16:34:17 UTC"
  },
  {
    "arxiv_id": "2406.02464v1",
    "title": "Meta-Learners for Partially-Identified Treatment Effects Across Multiple Environments",
    "authors": [
      "Jonas Schweisthal",
      "Dennis Frauen",
      "Mihaela van der Schaar",
      "Stefan Feuerriegel"
    ],
    "abstract": "Estimating the conditional average treatment effect (CATE) from observational\ndata is relevant for many applications such as personalized medicine. Here, we\nfocus on the widespread setting where the observational data come from multiple\nenvironments, such as different hospitals, physicians, or countries.\nFurthermore, we allow for violations of standard causal assumptions, namely,\noverlap within the environments and unconfoundedness. To this end, we move away\nfrom point identification and focus on partial identification. Specifically, we\nshow that current assumptions from the literature on multiple environments\nallow us to interpret the environment as an instrumental variable (IV). This\nallows us to adapt bounds from the IV literature for partial identification of\nCATE by leveraging treatment assignment mechanisms across environments. Then,\nwe propose different model-agnostic learners (so-called meta-learners) to\nestimate the bounds that can be used in combination with arbitrary machine\nlearning models. We further demonstrate the effectiveness of our meta-learners\nacross various experiments using both simulated and real-world data. Finally,\nwe discuss the applicability of our meta-learners to partial identification in\ninstrumental variable settings, such as randomized controlled trials with\nnon-compliance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02464v1",
    "published_date": "2024-06-04 16:31:43 UTC",
    "updated_date": "2024-06-04 16:31:43 UTC"
  },
  {
    "arxiv_id": "2406.02462v2",
    "title": "Learning Image Priors through Patch-based Diffusion Models for Solving Inverse Problems",
    "authors": [
      "Jason Hu",
      "Bowen Song",
      "Xiaojian Xu",
      "Liyue Shen",
      "Jeffrey A. Fessler"
    ],
    "abstract": "Diffusion models can learn strong image priors from underlying data\ndistribution and use them to solve inverse problems, but the training process\nis computationally expensive and requires lots of data. Such bottlenecks\nprevent most existing works from being feasible for high-dimensional and\nhigh-resolution data such as 3D images. This paper proposes a method to learn\nan efficient data prior for the entire image by training diffusion models only\non patches of images. Specifically, we propose a patch-based position-aware\ndiffusion inverse solver, called PaDIS, where we obtain the score function of\nthe whole image through scores of patches and their positional encoding and\nutilize this as the prior for solving inverse problems. First of all, we show\nthat this diffusion model achieves an improved memory efficiency and data\nefficiency while still maintaining the capability to generate entire images via\npositional encoding. Additionally, the proposed PaDIS model is highly flexible\nand can be plugged in with different diffusion inverse solvers (DIS). We\ndemonstrate that the proposed PaDIS approach enables solving various inverse\nproblems in both natural and medical image domains, including CT\nreconstruction, deblurring, and superresolution, given only patch-based priors.\nNotably, PaDIS outperforms previous DIS methods trained on entire image priors\nin the case of limited training data, demonstrating the data efficiency of our\nproposed approach by learning patch-based prior.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02462v2",
    "published_date": "2024-06-04 16:30:37 UTC",
    "updated_date": "2024-10-30 23:48:44 UTC"
  },
  {
    "arxiv_id": "2406.02450v1",
    "title": "A Generalized Apprenticeship Learning Framework for Modeling Heterogeneous Student Pedagogical Strategies",
    "authors": [
      "Md Mirajul Islam",
      "Xi Yang",
      "John Hostetter",
      "Adittya Soukarjya Saha",
      "Min Chi"
    ],
    "abstract": "A key challenge in e-learning environments like Intelligent Tutoring Systems\n(ITSs) is to induce effective pedagogical policies efficiently. While Deep\nReinforcement Learning (DRL) often suffers from sample inefficiency and reward\nfunction design difficulty, Apprenticeship Learning(AL) algorithms can overcome\nthem. However, most AL algorithms can not handle heterogeneity as they assume\nall demonstrations are generated with a homogeneous policy driven by a single\nreward function. Still, some AL algorithms which consider heterogeneity, often\ncan not generalize to large continuous state space and only work with discrete\nstates. In this paper, we propose an expectation-maximization(EM)-EDM, a\ngeneral AL framework to induce effective pedagogical policies from given\noptimal or near-optimal demonstrations, which are assumed to be driven by\nheterogeneous reward functions. We compare the effectiveness of the policies\ninduced by our proposed EM-EDM against four AL-based baselines and two policies\ninduced by DRL on two different but related tasks that involve pedagogical\naction prediction. Our overall results showed that, for both tasks, EM-EDM\noutperforms the four AL baselines across all performance metrics and the two\nDRL baselines. This suggests that EM-EDM can effectively model complex student\npedagogical decision-making processes through the ability to manage a large,\ncontinuous state space and adapt to handle diverse and heterogeneous reward\nfunctions with very few given demonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02450v1",
    "published_date": "2024-06-04 16:14:55 UTC",
    "updated_date": "2024-06-04 16:14:55 UTC"
  },
  {
    "arxiv_id": "2406.02652v2",
    "title": "RepCNN: Micro-sized, Mighty Models for Wakeword Detection",
    "authors": [
      "Arnav Kundu",
      "Prateeth Nayak",
      "Priyanka Padmanabhan",
      "Devang Naik"
    ],
    "abstract": "Always-on machine learning models require a very low memory and compute\nfootprint. Their restricted parameter count limits the model's capacity to\nlearn, and the effectiveness of the usual training algorithms to find the best\nparameters. Here we show that a small convolutional model can be better trained\nby first refactoring its computation into a larger redundant multi-branched\narchitecture. Then, for inference, we algebraically re-parameterize the trained\nmodel into the single-branched form with fewer parameters for a lower memory\nfootprint and compute cost. Using this technique, we show that our always-on\nwake-word detector model, RepCNN, provides a good trade-off between latency and\naccuracy during inference. RepCNN re-parameterized models are 43% more accurate\nthan a uni-branch convolutional model while having the same runtime. RepCNN\nalso meets the accuracy of complex architectures like BC-ResNet, while having\n2x lesser peak memory usage and 10x faster runtime.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02652v2",
    "published_date": "2024-06-04 16:14:19 UTC",
    "updated_date": "2024-08-01 22:39:20 UTC"
  },
  {
    "arxiv_id": "2406.02449v1",
    "title": "Representations as Language: An Information-Theoretic Framework for Interpretability",
    "authors": [
      "Henry Conklin",
      "Kenny Smith"
    ],
    "abstract": "Large scale neural models show impressive performance across a wide array of\nlinguistic tasks. Despite this they remain, largely, black-boxes - inducing\nvector-representations of their input that prove difficult to interpret. This\nlimits our ability to understand what they learn, and when the learn it, or\ndescribe what kinds of representations generalise well out of distribution. To\naddress this we introduce a novel approach to interpretability that looks at\nthe mapping a model learns from sentences to representations as a kind of\nlanguage in its own right. In doing so we introduce a set of\ninformation-theoretic measures that quantify how structured a model's\nrepresentations are with respect to its input, and when during training that\nstructure arises. Our measures are fast to compute, grounded in linguistic\ntheory, and can predict which models will generalise best based on their\nrepresentations. We use these measures to describe two distinct phases of\ntraining a transformer: an initial phase of in-distribution learning which\nreduces task loss, then a second stage where representations becoming robust to\nnoise. Generalisation performance begins to increase during this second phase,\ndrawing a link between generalisation and robustness to noise. Finally we look\nat how model size affects the structure of the representational space, showing\nthat larger models ultimately compress their representations more than their\nsmaller counterparts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 3 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02449v1",
    "published_date": "2024-06-04 16:14:00 UTC",
    "updated_date": "2024-06-04 16:14:00 UTC"
  },
  {
    "arxiv_id": "2406.06581v3",
    "title": "Order-Independence Without Fine Tuning",
    "authors": [
      "Reid McIlroy-Young",
      "Katrina Brown",
      "Conlan Olson",
      "Linjun Zhang",
      "Cynthia Dwork"
    ],
    "abstract": "The development of generative language models that can create long and\ncoherent textual outputs via autoregression has lead to a proliferation of uses\nand a corresponding sweep of analyses as researches work to determine the\nlimitations of this new paradigm. Unlike humans, these 'Large Language Models'\n(LLMs) are highly sensitive to small changes in their inputs, leading to\nunwanted inconsistency in their behavior. One problematic inconsistency when\nLLMs are used to answer multiple-choice questions or analyze multiple inputs is\norder dependency: the output of an LLM can (and often does) change\nsignificantly when sub-sequences are swapped, despite both orderings being\nsemantically identical. In this paper we present Set-Based Prompting, a\ntechnique that guarantees the output of an LLM will not have order dependence\non a specified set of sub-sequences. We show that this method provably\neliminates order dependency, and that it can be applied to any\ntransformer-based LLM to enable text generation that is unaffected by\nre-orderings. Delving into the implications of our method, we show that,\ndespite our inputs being out of distribution, the impact on expected accuracy\nis small, where the expectation is over the order of uniformly chosen shuffling\nof the candidate responses, and usually significantly less in practice. Thus,\nSet-Based Prompting can be used as a 'dropped-in' method on fully trained\nmodels. Finally, we discuss how our method's success suggests that other strong\nguarantees can be obtained on LLM performance via modifying the input\nrepresentations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 27 figures, Published in NeurIPS 2024 code\n  https://github.com/reidmcy/set-based-prompting",
    "pdf_url": "http://arxiv.org/pdf/2406.06581v3",
    "published_date": "2024-06-04 16:09:13 UTC",
    "updated_date": "2024-12-09 20:32:47 UTC"
  },
  {
    "arxiv_id": "2406.02443v2",
    "title": "Explainable Deep Learning Analysis for Raga Identification in Indian Art Music",
    "authors": [
      "Parampreet Singh",
      "Vipul Arora"
    ],
    "abstract": "Raga identification is an important problem within the domain of Indian Art\nmusic, as Ragas are fundamental to its composition and performance, playing a\ncrucial role in music retrieval, preservation, and education. Few studies that\nhave explored this task employ approaches such as signal processing, Machine\nLearning (ML), and more recently, Deep Learning (DL) based methods. However, a\nkey question remains unanswered in all these works: do these ML/DL methods\nlearn and interpret Ragas in a manner similar to human experts? Besides, a\nsignificant roadblock in this research is the unavailability of an ample supply\nof rich, labeled datasets, which drives these ML/DL-based methods. In this\npaper, firstly we curate a dataset comprising 191 hours of Hindustani Classical\nMusic (HCM) recordings, annotate it for Raga and tonic labels, and train a\nCNN-LSTM model for the task of Automatic Raga Identification (ARI). We achieve\na chunk-wise f1-measure of 0.89 for a subset of 12 Raga classes. Following\nthis, we make one of the first attempts to employ model explainability\ntechniques: SoundLIME and GradCAM++ for Raga identification, to evaluate\nwhether the classifier's predictions align with human understanding of Ragas.\nWe compare the generated explanations with human expert annotations and further\nanalyze individual test examples to understand the role of regions highlighted\nby explanations in making correct or incorrect predictions made by the model.\nOur results demonstrate a significant alignment of the model's understanding\nwith human understanding, and the thorough analysis validates the effectiveness\nof our approach.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02443v2",
    "published_date": "2024-06-04 16:06:51 UTC",
    "updated_date": "2024-12-21 08:32:18 UTC"
  },
  {
    "arxiv_id": "2406.02651v1",
    "title": "RoutePlacer: An End-to-End Routability-Aware Placer with Graph Neural Network",
    "authors": [
      "Yunbo Hou",
      "Haoran Ye",
      "Yingxue Zhang",
      "Siyuan Xu",
      "Guojie Song"
    ],
    "abstract": "Placement is a critical and challenging step of modern chip design, with\nroutability being an essential indicator of placement quality. Current\nroutability-oriented placers typically apply an iterative two-stage approach,\nwherein the first stage generates a placement solution, and the second stage\nprovides non-differentiable routing results to heuristically improve the\nsolution quality. This method hinders jointly optimizing the routability aspect\nduring placement. To address this problem, this work introduces RoutePlacer, an\nend-to-end routability-aware placement method. It trains RouteGNN, a customized\ngraph neural network, to efficiently and accurately predict routability by\ncapturing and fusing geometric and topological representations of placements.\nWell-trained RouteGNN then serves as a differentiable approximation of\nroutability, enabling end-to-end gradient-based routability optimization. In\naddition, RouteGNN can improve two-stage placers as a plug-and-play alternative\nto external routers. Our experiments on DREAMPlace, an open-source AI4EDA\nplatform, show that RoutePlacer can reduce Total Overflow by up to 16% while\nmaintaining routed wirelength, compared to the state-of-the-art; integrating\nRouteGNN within two-stage placers leads to a 44% reduction in Total Overflow\nwithout compromising wirelength.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02651v1",
    "published_date": "2024-06-04 15:39:41 UTC",
    "updated_date": "2024-06-04 15:39:41 UTC"
  },
  {
    "arxiv_id": "2406.03403v1",
    "title": "Structure-based Drug Design Benchmark: Do 3D Methods Really Dominate?",
    "authors": [
      "Kangyu Zheng",
      "Yingzhou Lu",
      "Zaixi Zhang",
      "Zhongwei Wan",
      "Yao Ma",
      "Marinka Zitnik",
      "Tianfan Fu"
    ],
    "abstract": "Currently, the field of structure-based drug design is dominated by three\nmain types of algorithms: search-based algorithms, deep generative models, and\nreinforcement learning. While existing works have typically focused on\ncomparing models within a single algorithmic category, cross-algorithm\ncomparisons remain scarce. In this paper, to fill the gap, we establish a\nbenchmark to evaluate the performance of sixteen models across these different\nalgorithmic foundations by assessing the pharmaceutical properties of the\ngenerated molecules and their docking affinities with specified target\nproteins. We highlight the unique advantages of each algorithmic approach and\noffer recommendations for the design of future SBDD models. We emphasize that\n1D/2D ligand-centric drug design methods can be used in SBDD by treating the\ndocking function as a black-box oracle, which is typically neglected. The\nempirical results show that 1D/2D methods achieve competitive performance\ncompared with 3D-based methods that use the 3D structure of the target protein\nexplicitly. Also, AutoGrow4, a 2D molecular graph-based genetic algorithm,\ndominates SBDD in terms of optimization ability. The relevant code is available\nin https://github.com/zkysfls/2024-sbdd-benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03403v1",
    "published_date": "2024-06-04 15:37:14 UTC",
    "updated_date": "2024-06-04 15:37:14 UTC"
  },
  {
    "arxiv_id": "2406.02650v1",
    "title": "By Fair Means or Foul: Quantifying Collusion in a Market Simulation with Deep Reinforcement Learning",
    "authors": [
      "Michael Schlechtinger",
      "Damaris Kosack",
      "Franz Krause",
      "Heiko Paulheim"
    ],
    "abstract": "In the rapidly evolving landscape of eCommerce, Artificial Intelligence (AI)\nbased pricing algorithms, particularly those utilizing Reinforcement Learning\n(RL), are becoming increasingly prevalent. This rise has led to an inextricable\npricing situation with the potential for market collusion. Our research employs\nan experimental oligopoly model of repeated price competition, systematically\nvarying the environment to cover scenarios from basic economic theory to\nsubjective consumer demand preferences. We also introduce a novel demand\nframework that enables the implementation of various demand models, allowing\nfor a weighted blending of different models. In contrast to existing research\nin this domain, we aim to investigate the strategies and emerging pricing\npatterns developed by the agents, which may lead to a collusive outcome.\nFurthermore, we investigate a scenario where agents cannot observe their\ncompetitors' prices. Finally, we provide a comprehensive legal analysis across\nall scenarios. Our findings indicate that RL-based AI agents converge to a\ncollusive state characterized by the charging of supracompetitive prices,\nwithout necessarily requiring inter-agent communication. Implementing\nalternative RL algorithms, altering the number of agents or simulation\nsettings, and restricting the scope of the agents' observation space does not\nsignificantly impact the collusive market outcome behavior.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint for IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02650v1",
    "published_date": "2024-06-04 15:35:08 UTC",
    "updated_date": "2024-06-04 15:35:08 UTC"
  },
  {
    "arxiv_id": "2406.19403v1",
    "title": "Temporal distribution of clusters of investors and their application in prediction with expert advice",
    "authors": [
      "Wojciech Wisniewski",
      "Yuri Kalnishkan",
      "David Lindsay",
      "Siân Lindsay"
    ],
    "abstract": "Financial organisations such as brokers face a significant challenge in\nservicing the investment needs of thousands of their traders worldwide. This\ntask is further compounded since individual traders will have their own risk\nappetite and investment goals. Traders may look to capture short-term trends in\nthe market which last only seconds to minutes, or they may have longer-term\nviews which last several days to months. To reduce the complexity of this task,\nclient trades can be clustered. By examining such clusters, we would likely\nobserve many traders following common patterns of investment, but how do these\npatterns vary through time? Knowledge regarding the temporal distributions of\nsuch clusters may help financial institutions manage the overall portfolio of\nrisk that accumulates from underlying trader positions. This study contributes\nto the field by demonstrating that the distribution of clusters derived from\nthe real-world trades of 20k Foreign Exchange (FX) traders (from 2015 to 2017)\nis described in accordance with Ewens' Sampling Distribution. Further, we show\nthat the Aggregating Algorithm (AA), an on-line prediction with expert advice\nalgorithm, can be applied to the aforementioned real-world data in order to\nimprove the returns of portfolios of trader risk. However we found that the AA\n'struggles' when presented with too many trader ``experts'', especially when\nthere are many trades with similar overall patterns. To help overcome this\nchallenge, we have applied and compared the use of Statistically Validated\nNetworks (SVN) with a hierarchical clustering approach on a subset of the data,\ndemonstrating that both approaches can be used to significantly improve results\nof the AA in terms of profitability and smoothness of returns.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "20 pages, technical report",
    "pdf_url": "http://arxiv.org/pdf/2406.19403v1",
    "published_date": "2024-06-04 15:28:06 UTC",
    "updated_date": "2024-06-04 15:28:06 UTC"
  },
  {
    "arxiv_id": "2406.02396v1",
    "title": "The Scandinavian Embedding Benchmarks: Comprehensive Assessment of Multilingual and Monolingual Text Embedding",
    "authors": [
      "Kenneth Enevoldsen",
      "Márton Kardos",
      "Niklas Muennighoff",
      "Kristoffer Laigaard Nielbo"
    ],
    "abstract": "The evaluation of English text embeddings has transitioned from evaluating a\nhandful of datasets to broad coverage across many tasks through benchmarks such\nas MTEB. However, this is not the case for multilingual text embeddings due to\na lack of available benchmarks. To address this problem, we introduce the\nScandinavian Embedding Benchmark (SEB). SEB is a comprehensive framework that\nenables text embedding evaluation for Scandinavian languages across 24 tasks,\n10 subtasks, and 4 task categories. Building on SEB, we evaluate more than 26\nmodels, uncovering significant performance disparities between public and\ncommercial solutions not previously captured by MTEB. We open-source SEB and\nintegrate it with MTEB, thus bridging the text embedding evaluation gap for\nScandinavian languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02396v1",
    "published_date": "2024-06-04 15:11:27 UTC",
    "updated_date": "2024-06-04 15:11:27 UTC"
  },
  {
    "arxiv_id": "2406.02394v1",
    "title": "Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data",
    "authors": [
      "Maxime Griot",
      "Jean Vanderdonckt",
      "Demet Yuksel",
      "Coralie Hemptinne"
    ],
    "abstract": "Large Language Models (LLMs) like ChatGPT demonstrate significant potential\nin the medical field, often evaluated using multiple-choice questions (MCQs)\nsimilar to those found on the USMLE. Despite their prevalence in medical\neducation, MCQs have limitations that might be exacerbated when assessing LLMs.\nTo evaluate the effectiveness of MCQs in assessing the performance of LLMs, we\ndeveloped a fictional medical benchmark focused on a non-existent gland, the\nGlianorex. This approach allowed us to isolate the knowledge of the LLM from\nits test-taking abilities. We used GPT-4 to generate a comprehensive textbook\non the Glianorex in both English and French and developed corresponding\nmultiple-choice questions in both languages. We evaluated various open-source,\nproprietary, and domain-specific LLMs using these questions in a zero-shot\nsetting. The models achieved average scores around 67%, with minor performance\ndifferences between larger and smaller models. Performance was slightly higher\nin English than in French. Fine-tuned medical models showed some improvement\nover their base versions in English but not in French. The uniformly high\nperformance across models suggests that traditional MCQ-based benchmarks may\nnot accurately measure LLMs' clinical knowledge and reasoning abilities,\ninstead highlighting their pattern recognition skills. This study underscores\nthe need for more robust evaluation methods to better assess the true\ncapabilities of LLMs in medical contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02394v1",
    "published_date": "2024-06-04 15:08:56 UTC",
    "updated_date": "2024-06-04 15:08:56 UTC"
  },
  {
    "arxiv_id": "2406.02383v2",
    "title": "Learning to Edit Visual Programs with Self-Supervision",
    "authors": [
      "R. Kenny Jones",
      "Renhao Zhang",
      "Aditya Ganeshan",
      "Daniel Ritchie"
    ],
    "abstract": "We design a system that learns how to edit visual programs. Our edit network\nconsumes a complete input program and a visual target. From this input, we task\nour network with predicting a local edit operation that could be applied to the\ninput program to improve its similarity to the target. In order to apply this\nscheme for domains that lack program annotations, we develop a self-supervised\nlearning approach that integrates this edit network into a bootstrapped\nfinetuning loop along with a network that predicts entire programs in one-shot.\nOur joint finetuning scheme, when coupled with an inference procedure that\ninitializes a population from the one-shot model and evolves members of this\npopulation with the edit network, helps to infer more accurate visual programs.\nOver multiple domains, we experimentally compare our method against the\nalternative of using only the one-shot model, and find that even under equal\nsearch-time budgets, our editing-based paradigm provides significant\nadvantages.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Neurips 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02383v2",
    "published_date": "2024-06-04 14:59:38 UTC",
    "updated_date": "2024-11-02 01:46:08 UTC"
  },
  {
    "arxiv_id": "2406.02381v2",
    "title": "Kirigami: large convolutional kernels improve deep learning-based RNA secondary structure prediction",
    "authors": [
      "Marc Harary",
      "Chengxin Zhang"
    ],
    "abstract": "We introduce a novel fully convolutional neural network (FCN) architecture\nfor predicting the secondary structure of ribonucleic acid (RNA) molecules.\nInterpreting RNA structures as weighted graphs, we employ deep learning to\nestimate the probability of base pairing between nucleotide residues. Unique to\nour model are its massive 11-pixel kernels, which we argue provide a distinct\nadvantage for FCNs on the specialized domain of RNA secondary structures. On a\nwidely adopted, standardized test set comprised of 1,305 molecules, the\naccuracy of our method exceeds that of current state-of-the-art (SOTA)\nsecondary structure prediction software, achieving a Matthews Correlation\nCoefficient (MCC) over 11-40% higher than that of other leading methods on\noverall structures and 58-400% higher on pseudoknots specifically.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "-Updated authorship and acknowledgements",
    "pdf_url": "http://arxiv.org/pdf/2406.02381v2",
    "published_date": "2024-06-04 14:58:10 UTC",
    "updated_date": "2024-06-06 14:04:32 UTC"
  },
  {
    "arxiv_id": "2406.02377v2",
    "title": "XRec: Large Language Models for Explainable Recommendation",
    "authors": [
      "Qiyao Ma",
      "Xubin Ren",
      "Chao Huang"
    ],
    "abstract": "Recommender systems help users navigate information overload by providing\npersonalized recommendations aligned with their preferences. Collaborative\nFiltering (CF) is a widely adopted approach, but while advanced techniques like\ngraph neural networks (GNNs) and self-supervised learning (SSL) have enhanced\nCF models for better user representations, they often lack the ability to\nprovide explanations for the recommended items. Explainable recommendations aim\nto address this gap by offering transparency and insights into the\nrecommendation decision-making process, enhancing users' understanding. This\nwork leverages the language capabilities of Large Language Models (LLMs) to\npush the boundaries of explainable recommender systems. We introduce a\nmodel-agnostic framework called XRec, which enables LLMs to provide\ncomprehensive explanations for user behaviors in recommender systems. By\nintegrating collaborative signals and designing a lightweight collaborative\nadaptor, the framework empowers LLMs to understand complex patterns in\nuser-item interactions and gain a deeper understanding of user preferences. Our\nextensive experiments demonstrate the effectiveness of XRec, showcasing its\nability to generate comprehensive and meaningful explanations that outperform\nbaseline approaches in explainable recommender systems. We open-source our\nmodel implementation at https://github.com/HKUDS/XRec.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.02377v2",
    "published_date": "2024-06-04 14:55:14 UTC",
    "updated_date": "2024-09-22 14:50:52 UTC"
  },
  {
    "arxiv_id": "2406.02366v3",
    "title": "Finding NeMo: Localizing Neurons Responsible For Memorization in Diffusion Models",
    "authors": [
      "Dominik Hintersdorf",
      "Lukas Struppek",
      "Kristian Kersting",
      "Adam Dziedzic",
      "Franziska Boenisch"
    ],
    "abstract": "Diffusion models (DMs) produce very detailed and high-quality images. Their\npower results from extensive training on large amounts of data, usually scraped\nfrom the internet without proper attribution or consent from content creators.\nUnfortunately, this practice raises privacy and intellectual property concerns,\nas DMs can memorize and later reproduce their potentially sensitive or\ncopyrighted training images at inference time. Prior efforts prevent this issue\nby either changing the input to the diffusion process, thereby preventing the\nDM from generating memorized samples during inference, or removing the\nmemorized data from training altogether. While those are viable solutions when\nthe DM is developed and deployed in a secure and constantly monitored\nenvironment, they hold the risk of adversaries circumventing the safeguards and\nare not effective when the DM itself is publicly released. To solve the\nproblem, we introduce NeMo, the first method to localize memorization of\nindividual data samples down to the level of neurons in DMs' cross-attention\nlayers. Through our experiments, we make the intriguing finding that in many\ncases, single neurons are responsible for memorizing particular training\nsamples. By deactivating these memorization neurons, we can avoid the\nreplication of training data at inference time, increase the diversity in the\ngenerated outputs, and mitigate the leakage of private and copyrighted data. In\nthis way, our NeMo contributes to a more responsible deployment of DMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02366v3",
    "published_date": "2024-06-04 14:45:47 UTC",
    "updated_date": "2024-11-04 06:52:09 UTC"
  },
  {
    "arxiv_id": "2406.02362v3",
    "title": "Temporal Graph Rewiring with Expander Graphs",
    "authors": [
      "Katarina Petrović",
      "Shenyang Huang",
      "Farimah Poursafaei",
      "Petar Veličković"
    ],
    "abstract": "Evolving relations in real-world networks are often modelled by temporal\ngraphs. Temporal Graph Neural Networks (TGNNs) emerged to model evolutionary\nbehaviour of such graphs by leveraging the message passing primitive at the\ncore of Graph Neural Networks (GNNs). It is well-known that GNNs are vulnerable\nto several issues directly related to the input graph topology, such as\nunder-reaching and over-squashing - we argue that these issues can often get\nexacerbated in temporal graphs, particularly as the result of stale nodes and\nedges. While graph rewiring techniques have seen frequent usage in GNNs to make\nthe graph topology more favourable for message passing, they have not seen any\nmainstream usage on TGNNs. In this work, we propose Temporal Graph Rewiring\n(TGR), the first approach for graph rewiring on temporal graphs, to the best of\nour knowledge. TGR constructs message passing highways between temporally\ndistant nodes in a continuous-time dynamic graph by utilizing expander graph\npropagation, a prominent framework used for graph rewiring on static graphs\nwhich makes minimal assumptions on the underlying graph structure. On the\nchallenging TGB benchmark, TGR achieves state-of-the-art results on\ntgbl-review, tgbl-coin, tgbl-comment and tgbl-flight datasets at the time of\nwriting. For tgbl-review, TGR has 50.5% improvement in MRR over the base TGN\nmodel and 22.2% improvement over the base TNCN model. The significant\nimprovement over base models demonstrates clear benefits of temporal graph\nrewiring.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02362v3",
    "published_date": "2024-06-04 14:39:51 UTC",
    "updated_date": "2024-10-22 13:43:01 UTC"
  },
  {
    "arxiv_id": "2406.02357v1",
    "title": "The complexity of approximate (coarse) correlated equilibrium for incomplete information games",
    "authors": [
      "Binghui Peng",
      "Aviad Rubinstein"
    ],
    "abstract": "We study the iteration complexity of decentralized learning of approximate\ncorrelated equilibria in incomplete information games.\n  On the negative side, we prove that in $\\mathit{extensive}$-$\\mathit{form}$\n$\\mathit{games}$, assuming $\\mathsf{PPAD} \\not\\subset\n\\mathsf{TIME}(n^{\\mathsf{polylog}(n)})$, any polynomial-time learning\nalgorithms must take at least $2^{\\log_2^{1-o(1)}(|\\mathcal{I}|)}$ iterations\nto converge to the set of $\\epsilon$-approximate correlated equilibrium, where\n$|\\mathcal{I}|$ is the number of nodes in the game and $\\epsilon > 0$ is an\nabsolute constant. This nearly matches, up to the $o(1)$ term, the algorithms\nof [PR'24, DDFG'24] for learning $\\epsilon$-approximate correlated equilibrium,\nand resolves an open question of Anagnostides, Kalavasis, Sandholm, and\nZampetakis [AKSZ'24]. Our lower bound holds even for the easier solution\nconcept of $\\epsilon$-approximate $\\mathit{coarse}$ correlated equilibrium\n  On the positive side, we give uncoupled dynamics that reach\n$\\epsilon$-approximate correlated equilibria of a $\\mathit{Bayesian}$\n$\\mathit{game}$ in polylogarithmic iterations, without any dependence of the\nnumber of types. This demonstrates a separation between Bayesian games and\nextensive-form games.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02357v1",
    "published_date": "2024-06-04 14:35:27 UTC",
    "updated_date": "2024-06-04 14:35:27 UTC"
  },
  {
    "arxiv_id": "2406.02356v1",
    "title": "Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks",
    "authors": [
      "Andrew Gambardella",
      "Yusuke Iwasawa",
      "Yutaka Matsuo"
    ],
    "abstract": "The ability (and inability) of large language models (LLMs) to perform\narithmetic tasks has been the subject of much theoretical and practical debate.\nWe show that LLMs are frequently able to correctly and confidently predict the\nfirst digit of n-digit by m-digit multiplication tasks without using chain of\nthought reasoning, despite these tasks require compounding operations to solve.\nSimultaneously, LLMs in practice often fail to correctly or confidently predict\nthe last digit of an n-digit by m-digit multiplication, a task equivalent to\n1-digit by 1-digit multiplication which can be easily learned or memorized. We\nshow that the latter task can be solved more robustly when the LLM is\nconditioned on all of the correct higher-order digits, which on average\nincreases the confidence of the correct last digit on 5-digit by 5-digit\nmultiplication tasks using Llama 2-13B by over 230% (0.13 to 0.43) and\nMistral-7B by 150% (0.22 to 0.55).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "In Proceedings of the 62nd Annual Meeting of the Association for\n  Computational Linguistics (Volume 2: Short Papers)",
    "pdf_url": "http://arxiv.org/pdf/2406.02356v1",
    "published_date": "2024-06-04 14:34:39 UTC",
    "updated_date": "2024-06-04 14:34:39 UTC"
  },
  {
    "arxiv_id": "2406.02355v1",
    "title": "FedDr+: Stabilizing Dot-regression with Global Feature Distillation for Federated Learning",
    "authors": [
      "Seongyoon Kim",
      "Minchan Jeong",
      "Sungnyun Kim",
      "Sungwoo Cho",
      "Sumyeong Ahn",
      "Se-Young Yun"
    ],
    "abstract": "Federated Learning (FL) has emerged as a pivotal framework for the\ndevelopment of effective global models (global FL) or personalized models\n(personalized FL) across clients with heterogeneous, non-iid data distribution.\nA key challenge in FL is client drift, where data heterogeneity impedes the\naggregation of scattered knowledge. Recent studies have tackled the client\ndrift issue by identifying significant divergence in the last classifier layer.\nTo mitigate this divergence, strategies such as freezing the classifier weights\nand aligning the feature extractor accordingly have proven effective. Although\nthe local alignment between classifier and feature extractor has been studied\nas a crucial factor in FL, we observe that it may lead the model to\noveremphasize the observed classes within each client. Thus, our objectives are\ntwofold: (1) enhancing local alignment while (2) preserving the representation\nof unseen class samples. This approach aims to effectively integrate knowledge\nfrom individual clients, thereby improving performance for both global and\npersonalized FL. To achieve this, we introduce a novel algorithm named FedDr+,\nwhich empowers local model alignment using dot-regression loss. FedDr+ freezes\nthe classifier as a simplex ETF to align the features and improves aggregated\nglobal models by employing a feature distillation mechanism to retain\ninformation about unseen/missing classes. Consequently, we provide empirical\nevidence demonstrating that our algorithm surpasses existing methods that use a\nfrozen classifier to boost alignment across the diverse distribution.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02355v1",
    "published_date": "2024-06-04 14:34:13 UTC",
    "updated_date": "2024-06-04 14:34:13 UTC"
  },
  {
    "arxiv_id": "2406.02350v2",
    "title": "LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing",
    "authors": [
      "Maojun Sun"
    ],
    "abstract": "Large language models (LLMs) have shown amazing capabilities in knowledge\nmemorization and the present. However, when it comes to domain-specific\nknowledge and downstream tasks like medical, general LLMs are often unable to\ngive precise answers. In addition, when people want LLMs to answer\nclassification questions, they usually go through instruction tuning first.\nHowever, LLMs do not always give a direct index of the categorization after\ninstruction tuning. In this paper, we proposed LlamaCare, a fine-tuned medical\nlanguage model, and Extended Classification Integration(ECI), a module to\nhandle classification problems of LLMs. Our contributions are : (i) We\nfine-tuned a large language model of medical knowledge with very low carbon\nemissions and achieved similar performance with ChatGPT by a 24G GPU. (ii) We\nsolved the problem of redundant categorical answers and improved the\nperformance of LLMs by proposing a new module called Extended Classification\nIntegration. (iii) We released our processed data for one-shot and few-shot\ntraining for some benchmarks such as PubMedQA and USMLE 1-3 step. Our method\nachieves a close performance comparable to some state-of-the-art models with\nthe same quantity of parameters on benchmarks, while being more environmentally\nfriendly by using less GPU computation time. Our models, codes, and datasets\ncan be found at \\url{https://github.com/Stephen-SMJ/LLamaCare}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02350v2",
    "published_date": "2024-06-04 14:24:53 UTC",
    "updated_date": "2024-06-05 15:08:42 UTC"
  },
  {
    "arxiv_id": "2406.02349v1",
    "title": "CADE: Cosine Annealing Differential Evolution for Spiking Neural Network",
    "authors": [
      "Runhua Jiang",
      "Guodong Du",
      "Shuyang Yu",
      "Yifei Guo",
      "Sim Kuan Goh",
      "Ho-Kin Tang"
    ],
    "abstract": "Spiking neural networks (SNNs) have gained prominence for their potential in\nneuromorphic computing and energy-efficient artificial intelligence, yet\noptimizing them remains a formidable challenge for gradient-based methods due\nto their discrete, spike-based computation. This paper attempts to tackle the\nchallenges by introducing Cosine Annealing Differential Evolution (CADE),\ndesigned to modulate the mutation factor (F) and crossover rate (CR) of\ndifferential evolution (DE) for the SNN model, i.e., Spiking Element Wise (SEW)\nResNet. Extensive empirical evaluations were conducted to analyze CADE. CADE\nshowed a balance in exploring and exploiting the search space, resulting in\naccelerated convergence and improved accuracy compared to existing\ngradient-based and DE-based methods. Moreover, an initialization method based\non a transfer learning setting was developed, pretraining on a source dataset\n(i.e., CIFAR-10) and fine-tuning the target dataset (i.e., CIFAR-100), to\nimprove population diversity. It was found to further enhance CADE for SNN.\nRemarkably, CADE elevates the performance of the highest accuracy SEW model by\nan additional 0.52 percentage points, underscoring its effectiveness in\nfine-tuning and enhancing SNNs. These findings emphasize the pivotal role of a\nscheduler for F and CR adjustment, especially for DE-based SNN. Source Code on\nGithub: https://github.com/Tank-Jiang/CADE4SNN.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02349v1",
    "published_date": "2024-06-04 14:24:35 UTC",
    "updated_date": "2024-06-04 14:24:35 UTC"
  },
  {
    "arxiv_id": "2406.02347v3",
    "title": "Flash Diffusion: Accelerating Any Conditional Diffusion Model for Few Steps Image Generation",
    "authors": [
      "Clément Chadebec",
      "Onur Tasar",
      "Eyal Benaroche",
      "Benjamin Aubin"
    ],
    "abstract": "In this paper, we propose an efficient, fast, and versatile distillation\nmethod to accelerate the generation of pre-trained diffusion models: Flash\nDiffusion. The method reaches state-of-the-art performances in terms of FID and\nCLIP-Score for few steps image generation on the COCO2014 and COCO2017\ndatasets, while requiring only several GPU hours of training and fewer\ntrainable parameters than existing methods. In addition to its efficiency, the\nversatility of the method is also exposed across several tasks such as\ntext-to-image, inpainting, face-swapping, super-resolution and using different\nbackbones such as UNet-based denoisers (SD1.5, SDXL) or DiT (Pixart-$\\alpha$),\nas well as adapters. In all cases, the method allowed to reduce drastically the\nnumber of sampling steps while maintaining very high-quality image generation.\nThe official implementation is available at\nhttps://github.com/gojasper/flash-diffusion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.02347v3",
    "published_date": "2024-06-04 14:23:27 UTC",
    "updated_date": "2024-12-18 10:45:06 UTC"
  },
  {
    "arxiv_id": "2406.02345v2",
    "title": "Progressive Confident Masking Attention Network for Audio-Visual Segmentation",
    "authors": [
      "Yuxuan Wang",
      "Jinchao Zhu",
      "Feng Dong",
      "Shuyue Zhu"
    ],
    "abstract": "Audio and visual signals typically occur simultaneously, and humans possess\nan innate ability to correlate and synchronize information from these two\nmodalities. Recently, a challenging problem known as Audio-Visual Segmentation\n(AVS) has emerged, intending to produce segmentation maps for sounding objects\nwithin a scene. However, the methods proposed so far have not sufficiently\nintegrated audio and visual information, and the computational costs have been\nextremely high. Additionally, the outputs of different stages have not been\nfully utilized. To facilitate this research, we introduce a novel Progressive\nConfident Masking Attention Network (PMCANet). It leverages attention\nmechanisms to uncover the intrinsic correlations between audio signals and\nvisual frames. Furthermore, we design an efficient and effective\ncross-attention module to enhance semantic perception by selecting query\ntokens. This selection is determined through confidence-driven units based on\nthe network's multi-stage predictive outputs. Experiments demonstrate that our\nnetwork outperforms other AVS methods while requiring less computational\nresources. The code is available at: https://github.com/PrettyPlate/PCMANet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 11 figures, submitted to Elsevier Knowledge-Based System",
    "pdf_url": "http://arxiv.org/pdf/2406.02345v2",
    "published_date": "2024-06-04 14:21:41 UTC",
    "updated_date": "2025-02-10 06:05:46 UTC"
  },
  {
    "arxiv_id": "2406.02648v1",
    "title": "Exploring Effects of Hyperdimensional Vectors for Tsetlin Machines",
    "authors": [
      "Vojtech Halenka",
      "Ahmed K. Kadhim",
      "Paul F. A. Clarke",
      "Bimal Bhattarai",
      "Rupsa Saha",
      "Ole-Christoffer Granmo",
      "Lei Jiao",
      "Per-Arne Andersen"
    ],
    "abstract": "Tsetlin machines (TMs) have been successful in several application domains,\noperating with high efficiency on Boolean representations of the input data.\nHowever, Booleanizing complex data structures such as sequences, graphs,\nimages, signal spectra, chemical compounds, and natural language is not\ntrivial. In this paper, we propose a hypervector (HV) based method for\nexpressing arbitrarily large sets of concepts associated with any input data.\nUsing a hyperdimensional space to build vectors drastically expands the\ncapacity and flexibility of the TM. We demonstrate how images, chemical\ncompounds, and natural language text are encoded according to the proposed\nmethod, and how the resulting HV-powered TM can achieve significantly higher\naccuracy and faster learning on well-known benchmarks. Our results open up a\nnew research direction for TMs, namely how to expand and exploit the benefits\nof operating in hyperspace, including new booleanization strategies,\noptimization of TM inference and learning, as well as new TM applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02648v1",
    "published_date": "2024-06-04 14:16:52 UTC",
    "updated_date": "2024-06-04 14:16:52 UTC"
  },
  {
    "arxiv_id": "2406.02338v1",
    "title": "Linguistic Fingerprint in Transformer Models: How Language Variation Influences Parameter Selection in Irony Detection",
    "authors": [
      "Michele Mastromattei",
      "Fabio Massimo Zanzotto"
    ],
    "abstract": "This paper explores the correlation between linguistic diversity, sentiment\nanalysis and transformer model architectures. We aim to investigate how\ndifferent English variations impact transformer-based models for irony\ndetection. To conduct our study, we used the EPIC corpus to extract five\ndiverse English variation-specific datasets and applied the KEN pruning\nalgorithm on five different architectures. Our results reveal several\nsimilarities between optimal subnetworks, which provide insights into the\nlinguistic variations that share strong resemblances and those that exhibit\ngreater dissimilarities. We discovered that optimal subnetworks across models\nshare at least 60% of their parameters, emphasizing the significance of\nparameter values in capturing and interpreting linguistic variations. This\nstudy highlights the inherent structural similarities between models trained on\ndifferent variants of the same language and also the critical role of parameter\nvalues in capturing these nuances.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02338v1",
    "published_date": "2024-06-04 14:09:36 UTC",
    "updated_date": "2024-06-04 14:09:36 UTC"
  },
  {
    "arxiv_id": "2406.06580v1",
    "title": "Break the Chain: Large Language Models Can be Shortcut Reasoners",
    "authors": [
      "Mengru Ding",
      "Hanmeng Liu",
      "Zhizhang Fu",
      "Jian Song",
      "Wenbo Xie",
      "Yue Zhang"
    ],
    "abstract": "Recent advancements in Chain-of-Thought (CoT) reasoning utilize complex\nmodules but are hampered by high token consumption, limited applicability, and\nchallenges in reproducibility. This paper conducts a critical evaluation of CoT\nprompting, extending beyond arithmetic to include complex logical and\ncommonsense reasoning tasks, areas where standard CoT methods fall short. We\npropose the integration of human-like heuristics and shortcuts into language\nmodels (LMs) through \"break the chain\" strategies. These strategies disrupt\ntraditional CoT processes using controlled variables to assess their efficacy.\nAdditionally, we develop innovative zero-shot prompting strategies that\nencourage the use of shortcuts, enabling LMs to quickly exploit reasoning clues\nand bypass detailed procedural steps. Our comprehensive experiments across\nvarious LMs, both commercial and open-source, reveal that LMs maintain\neffective performance with \"break the chain\" strategies. We also introduce\nShortcutQA, a dataset specifically designed to evaluate reasoning through\nshortcuts, compiled from competitive tests optimized for heuristic reasoning\ntasks such as forward/backward reasoning and simplification. Our analysis\nconfirms that ShortcutQA not only poses a robust challenge to LMs but also\nserves as an essential benchmark for enhancing reasoning efficiency in AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06580v1",
    "published_date": "2024-06-04 14:02:53 UTC",
    "updated_date": "2024-06-04 14:02:53 UTC"
  },
  {
    "arxiv_id": "2406.02333v1",
    "title": "Towards Neural Architecture Search for Transfer Learning in 6G Networks",
    "authors": [
      "Adam Orucu",
      "Farnaz Moradi",
      "Masoumeh Ebrahimi",
      "Andreas Johnsson"
    ],
    "abstract": "The future 6G network is envisioned to be AI-native, and as such, ML models\nwill be pervasive in support of optimizing performance, reducing energy\nconsumption, and in coping with increasing complexity and heterogeneity. A key\nchallenge is automating the process of finding optimal model architectures\nsatisfying stringent requirements stemming from varying tasks, dynamicity and\navailable resources in the infrastructure and deployment positions. In this\npaper, we describe and review the state-of-the-art in Neural Architecture\nSearch and Transfer Learning and their applicability in networking. Further, we\nidentify open research challenges and set directions with a specific focus on\nthree main requirements with elements unique to the future network, namely\ncombining NAS and TL, multi-objective search, and tabular data. Finally, we\noutline and discuss both near-term and long-term work ahead.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02333v1",
    "published_date": "2024-06-04 14:01:03 UTC",
    "updated_date": "2024-06-04 14:01:03 UTC"
  },
  {
    "arxiv_id": "2406.02325v1",
    "title": "Technical Language Processing for Telecommunications Specifications",
    "authors": [
      "Felipe A. Rodriguez Y."
    ],
    "abstract": "Large Language Models (LLMs) are continuously being applied in a more diverse\nset of contexts. At their current state, however, even state-of-the-art LLMs\nsuch as Generative Pre-Trained Transformer 4 (GTP-4) have challenges when\nextracting information from real-world technical documentation without a heavy\npreprocessing. One such area with real-world technical documentation is\ntelecommunications engineering, which could greatly benefit from\ndomain-specific LLMs. The unique format and overall structure of\ntelecommunications internal specifications differs greatly from standard\nEnglish and thus it is evident that the application of out-of-the-box Natural\nLanguage Processing (NLP) tools is not a viable option. In this article, we\noutline the limitations of out-of-the-box NLP tools for processing technical\ninformation generated by telecommunications experts, and expand the concept of\nTechnical Language Processing (TLP) to the telecommunication domain.\nAdditionally, we explore the effect of domain-specific LLMs in the work of\nSpecification Engineers, emphasizing the potential benefits of adopting\ndomain-specific LLMs to speed up the training of experts in different\ntelecommunications fields.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Still not published",
    "pdf_url": "http://arxiv.org/pdf/2406.02325v1",
    "published_date": "2024-06-04 13:57:22 UTC",
    "updated_date": "2024-06-04 13:57:22 UTC"
  },
  {
    "arxiv_id": "2406.06579v3",
    "title": "From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks",
    "authors": [
      "Xiaofeng Zhang",
      "Yihao Quan",
      "Chen Shen",
      "Xiaosong Yuan",
      "Shaotian Yan",
      "Liang Xie",
      "Wenxiao Wang",
      "Chaochen Gu",
      "Hao Tang",
      "Jieping Ye"
    ],
    "abstract": "Large Vision Language Models (LVLMs) achieve great performance on\nvisual-language reasoning tasks, however, the black-box nature of LVLMs hinders\nin-depth research on the reasoning mechanism. As all images need to be\nconverted into image tokens to fit the input format of large language models\n(LLMs) along with natural language prompts, sequential visual representation is\nessential to the performance of LVLMs, and the information flow analysis\napproach can be an effective tool for determining interactions between these\nrepresentations. In this paper, we propose integrating attention analysis with\nLLaVA-CAM, concretely, attention scores highlight relevant regions during\nforward propagation, while LLaVA-CAM captures gradient changes through backward\npropagation, revealing key image features. By exploring the information flow\nfrom the perspective of visual representation contribution, we observe that it\ntends to converge in shallow layers but diversify in deeper layers. To validate\nour analysis, we conduct comprehensive experiments with truncation strategies\nacross various LVLMs for visual question answering and image captioning tasks,\nand experimental results not only verify our hypothesis but also reveal a\nconsistent pattern of information flow convergence in the corresponding layers,\nand the information flow cliff layer will be different due to different\ncontexts. The paper's source code can be accessed from\n\\url{https://github.com/zhangbaijin/From-Redundancy-to-Relevance}",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06579v3",
    "published_date": "2024-06-04 13:52:54 UTC",
    "updated_date": "2024-10-17 01:17:25 UTC"
  },
  {
    "arxiv_id": "2406.02322v1",
    "title": "A Survey of Transformer Enabled Time Series Synthesis",
    "authors": [
      "Alexander Sommers",
      "Logan Cummins",
      "Sudip Mittal",
      "Shahram Rahimi",
      "Maria Seale",
      "Joseph Jaboure",
      "Thomas Arnold"
    ],
    "abstract": "Generative AI has received much attention in the image and language domains,\nwith the transformer neural network continuing to dominate the state of the\nart. Application of these models to time series generation is less explored,\nhowever, and is of great utility to machine learning, privacy preservation, and\nexplainability research. The present survey identifies this gap at the\nintersection of the transformer, generative AI, and time series data, and\nreviews works in this sparsely populated subdomain. The reviewed works show\ngreat variety in approach, and have not yet converged on a conclusive answer to\nthe problems the domain poses. GANs, diffusion models, state space models, and\nautoencoders were all encountered alongside or surrounding the transformers\nwhich originally motivated the survey. While too open a domain to offer\nconclusive insights, the works surveyed are quite suggestive, and several\nrecommendations for best practice, and suggestions of valuable future work, are\nprovided.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02322v1",
    "published_date": "2024-06-04 13:52:42 UTC",
    "updated_date": "2024-06-04 13:52:42 UTC"
  },
  {
    "arxiv_id": "2406.02317v1",
    "title": "Generative Conditional Distributions by Neural (Entropic) Optimal Transport",
    "authors": [
      "Bao Nguyen",
      "Binh Nguyen",
      "Hieu Trung Nguyen",
      "Viet Anh Nguyen"
    ],
    "abstract": "Learning conditional distributions is challenging because the desired outcome\nis not a single distribution but multiple distributions that correspond to\nmultiple instances of the covariates. We introduce a novel neural entropic\noptimal transport method designed to effectively learn generative models of\nconditional distributions, particularly in scenarios characterized by limited\nsample sizes. Our method relies on the minimax training of two neural networks:\na generative network parametrizing the inverse cumulative distribution\nfunctions of the conditional distributions and another network parametrizing\nthe conditional Kantorovich potential. To prevent overfitting, we regularize\nthe objective function by penalizing the Lipschitz constant of the network\noutput. Our experiments on real-world datasets show the effectiveness of our\nalgorithm compared to state-of-the-art conditional distribution learning\ntechniques. Our implementation can be found at\nhttps://github.com/nguyenngocbaocmt02/GENTLE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02317v1",
    "published_date": "2024-06-04 13:45:35 UTC",
    "updated_date": "2024-06-04 13:45:35 UTC"
  },
  {
    "arxiv_id": "2406.02315v2",
    "title": "An Independence-promoting Loss for Music Generation with Language Models",
    "authors": [
      "Jean-Marie Lemercier",
      "Simon Rouard",
      "Jade Copet",
      "Yossi Adi",
      "Alexandre Défossez"
    ],
    "abstract": "Music generation schemes using language modeling rely on a vocabulary of\naudio tokens, generally provided as codes in a discrete latent space learnt by\nan auto-encoder. Multi-stage quantizers are often employed to produce these\ntokens, therefore the decoding strategy used for token prediction must be\nadapted to account for multiple codebooks: either it should model the joint\ndistribution over all codebooks, or fit the product of the codebook marginal\ndistributions. Modelling the joint distribution requires a costly increase in\nthe number of auto-regressive steps, while fitting the product of the marginals\nyields an inexact model unless the codebooks are mutually independent. In this\nwork, we introduce an independence-promoting loss to regularize the\nauto-encoder used as the tokenizer in language models for music generation. The\nproposed loss is a proxy for mutual information based on the maximum mean\ndiscrepancy principle, applied in reproducible kernel Hilbert spaces. Our\ncriterion is simple to implement and train, and it is generalizable to other\nmulti-stream codecs. We show that it reduces the statistical dependence between\ncodebooks during auto-encoding. This leads to an increase in the generated\nmusic quality when modelling the product of the marginal distributions, while\ngenerating audio much faster than the joint distribution model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02315v2",
    "published_date": "2024-06-04 13:44:39 UTC",
    "updated_date": "2024-06-09 17:55:51 UTC"
  },
  {
    "arxiv_id": "2406.06578v1",
    "title": "SMS Spam Detection and Classification to Combat Abuse in Telephone Networks Using Natural Language Processing",
    "authors": [
      "Dare Azeez Oyeyemi",
      "Adebola K. Ojo"
    ],
    "abstract": "In the modern era, mobile phones have become ubiquitous, and Short Message\nService (SMS) has grown to become a multi-million-dollar service due to the\nwidespread adoption of mobile devices and the millions of people who use SMS\ndaily. However, SMS spam has also become a pervasive problem that endangers\nusers' privacy and security through phishing and fraud. Despite numerous spam\nfiltering techniques, there is still a need for a more effective solution to\naddress this problem [1]. This research addresses the pervasive issue of SMS\nspam, which poses threats to users' privacy and security. Despite existing spam\nfiltering techniques, the high false-positive rate persists as a challenge. The\nstudy introduces a novel approach utilizing Natural Language Processing (NLP)\nand machine learning models, particularly BERT (Bidirectional Encoder\nRepresentations from Transformers), for SMS spam detection and classification.\nData preprocessing techniques, such as stop word removal and tokenization, are\napplied, along with feature extraction using BERT. Machine learning models,\nincluding SVM, Logistic Regression, Naive Bayes, Gradient Boosting, and Random\nForest, are integrated with BERT for differentiating spam from ham messages.\nEvaluation results revealed that the Na\\\"ive Bayes classifier + BERT model\nachieves the highest accuracy at 97.31% with the fastest execution time of 0.3\nseconds on the test dataset. This approach demonstrates a notable enhancement\nin spam detection efficiency and a low false-positive rate. The developed model\npresents a valuable solution to combat SMS spam, ensuring faster and more\naccurate detection. This model not only safeguards users' privacy but also\nassists network providers in effectively identifying and blocking SMS spam\nmessages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.06578v1",
    "published_date": "2024-06-04 13:44:36 UTC",
    "updated_date": "2024-06-04 13:44:36 UTC"
  },
  {
    "arxiv_id": "2406.02295v1",
    "title": "How to Explore with Belief: State Entropy Maximization in POMDPs",
    "authors": [
      "Riccardo Zamboni",
      "Duilio Cirino",
      "Marcello Restelli",
      "Mirco Mutti"
    ],
    "abstract": "Recent works have studied *state entropy maximization* in reinforcement\nlearning, in which the agent's objective is to learn a policy inducing high\nentropy over states visitation (Hazan et al., 2019). They typically assume full\nobservability of the state of the system, so that the entropy of the\nobservations is maximized. In practice, the agent may only get *partial*\nobservations, e.g., a robot perceiving the state of a physical space through\nproximity sensors and cameras. A significant mismatch between the entropy over\nobservations and true states of the system can arise in those settings. In this\npaper, we address the problem of entropy maximization over the *true states*\nwith a decision policy conditioned on partial observations *only*. The latter\nis a generalization of POMDPs, which is intractable in general. We develop a\nmemory and computationally efficient *policy gradient* method to address a\nfirst-order relaxation of the objective defined on *belief* states, providing\nvarious formal characterizations of approximation gaps, the optimization\nlandscape, and the *hallucination* problem. This paper aims to generalize state\nentropy maximization to more realistic domains that meet the challenges of\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02295v1",
    "published_date": "2024-06-04 13:16:34 UTC",
    "updated_date": "2024-06-04 13:16:34 UTC"
  },
  {
    "arxiv_id": "2406.02645v1",
    "title": "Astral: training physics-informed neural networks with error majorants",
    "authors": [
      "Vladimir Fanaskov",
      "Tianchi Yu",
      "Alexander Rudikov",
      "Ivan Oseledets"
    ],
    "abstract": "The primal approach to physics-informed learning is a residual minimization.\nWe argue that residual is, at best, an indirect measure of the error of\napproximate solution and propose to train with error majorant instead. Since\nerror majorant provides a direct upper bound on error, one can reliably\nestimate how close PiNN is to the exact solution and stop the optimization\nprocess when the desired accuracy is reached. We call loss function associated\nwith error majorant $\\textbf{Astral}$: neur$\\textbf{A}$l a\npo$\\textbf{ST}$erio$\\textbf{RI}$ function$\\textbf{A}$l Loss. To compare Astral\nand residual loss functions, we illustrate how error majorants can be derived\nfor various PDEs and conduct experiments with diffusion equations (including\nanisotropic and in the L-shaped domain), convection-diffusion equation,\ntemporal discretization of Maxwell's equation, and magnetostatics problem. The\nresults indicate that Astral loss is competitive to the residual loss,\ntypically leading to faster convergence and lower error (e.g., for Maxwell's\nequations, we observe an order of magnitude better relative error and training\ntime). We also report that the error estimate obtained with Astral loss is\nusually tight enough to be informative, e.g., for a highly anisotropic\nequation, on average, Astral overestimates error by a factor of $1.5$, and for\nconvection-diffusion by a factor of $1.7$.",
    "categories": [
      "physics.comp-ph",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02645v1",
    "published_date": "2024-06-04 13:11:49 UTC",
    "updated_date": "2024-06-04 13:11:49 UTC"
  },
  {
    "arxiv_id": "2406.02644v1",
    "title": "Differentially private exact recovery for stochastic block models",
    "authors": [
      "Dung Nguyen",
      "Anil Vullikanti"
    ],
    "abstract": "Stochastic block models (SBMs) are a very commonly studied network model for\ncommunity detection algorithms. In the standard form of an SBM, the $n$\nvertices (or nodes) of a graph are generally divided into multiple\npre-determined communities (or clusters). Connections between pairs of vertices\nare generated randomly and independently with pre-defined probabilities, which\ndepend on the communities containing the two nodes. A fundamental problem in\nSBMs is the recovery of the community structure, and sharp\ninformation-theoretic bounds are known for recoverability for many versions of\nSBMs.\n  Our focus here is the recoverability problem in SBMs when the network is\nprivate. Under the edge differential privacy model, we derive conditions for\nexact recoverability in three different versions of SBMs, namely Asymmetric SBM\n(when communities have non-uniform sizes), General Structure SBM (with\noutliers), and Censored SBM (with edge features). Our private algorithms have\npolynomial running time w.r.t. the input graph's size, and match the recovery\nthresholds of the non-private setting when $\\epsilon\\rightarrow\\infty$. In\ncontrast, the previous best results for recoverability in SBMs only hold for\nthe symmetric case (equal size communities), and run in quasi-polynomial time,\nor in polynomial time with recovery thresholds being tight up to some constants\nfrom the non-private settings.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02644v1",
    "published_date": "2024-06-04 12:38:05 UTC",
    "updated_date": "2024-06-04 12:38:05 UTC"
  },
  {
    "arxiv_id": "2406.02253v1",
    "title": "PuFace: Defending against Facial Cloaking Attacks for Facial Recognition Models",
    "authors": [
      "Jing Wen"
    ],
    "abstract": "The recently proposed facial cloaking attacks add invisible perturbation\n(cloaks) to facial images to protect users from being recognized by\nunauthorized facial recognition models. However, we show that the \"cloaks\" are\nnot robust enough and can be removed from images.\n  This paper introduces PuFace, an image purification system leveraging the\ngeneralization ability of neural networks to diminish the impact of cloaks by\npushing the cloaked images towards the manifold of natural (uncloaked) images\nbefore the training process of facial recognition models. Specifically, we\ndevise a purifier that takes all the training images including both cloaked and\nnatural images as input and generates the purified facial images close to the\nmanifold where natural images lie. To meet the defense goal, we propose to\ntrain the purifier on particularly amplified cloaked images with a loss\nfunction that combines image loss and feature loss. Our empirical experiment\nshows PuFace can effectively defend against two state-of-the-art facial\ncloaking attacks and reduces the attack success rate from 69.84\\% to 7.61\\% on\naverage without degrading the normal accuracy for various facial recognition\nmodels. Moreover, PuFace is a model-agnostic defense mechanism that can be\napplied to any facial recognition model without modifying the model structure.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02253v1",
    "published_date": "2024-06-04 12:19:09 UTC",
    "updated_date": "2024-06-04 12:19:09 UTC"
  },
  {
    "arxiv_id": "2406.02251v1",
    "title": "Modeling Emotional Trajectories in Written Stories Utilizing Transformers and Weakly-Supervised Learning",
    "authors": [
      "Lukas Christ",
      "Shahin Amiriparian",
      "Manuel Milling",
      "Ilhan Aslan",
      "Björn W. Schuller"
    ],
    "abstract": "Telling stories is an integral part of human communication which can evoke\nemotions and influence the affective states of the audience. Automatically\nmodeling emotional trajectories in stories has thus attracted considerable\nscholarly interest. However, as most existing works have been limited to\nunsupervised dictionary-based approaches, there is no benchmark for this task.\nWe address this gap by introducing continuous valence and arousal labels for an\nexisting dataset of children's stories originally annotated with discrete\nemotion categories. We collect additional annotations for this data and map the\ncategorical labels to the continuous valence and arousal space. For predicting\nthe thus obtained emotionality signals, we fine-tune a DeBERTa model and\nimprove upon this baseline via a weakly supervised learning approach. The best\nconfiguration achieves a Concordance Correlation Coefficient (CCC) of $.8221$\nfor valence and $.7125$ for arousal on the test set, demonstrating the efficacy\nof our proposed approach. A detailed analysis shows the extent to which the\nresults vary depending on factors such as the author, the individual story, or\nthe section within the story. In addition, we uncover the weaknesses of our\napproach by investigating examples that prove to be difficult to predict.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Findings. arXiv admin note: text overlap with\n  arXiv:2212.11382",
    "pdf_url": "http://arxiv.org/pdf/2406.02251v1",
    "published_date": "2024-06-04 12:17:16 UTC",
    "updated_date": "2024-06-04 12:17:16 UTC"
  },
  {
    "arxiv_id": "2407.06165v2",
    "title": "Tumor likelihood estimation on MRI prostate data by utilizing k-Space information",
    "authors": [
      "M. Rempe",
      "F. Hörst",
      "C. Seibold",
      "B. Hadaschik",
      "M. Schlimbach",
      "J. Egger",
      "K. Kröninger",
      "F. Breuer",
      "M. Blaimer",
      "J. Kleesiek"
    ],
    "abstract": "We present a novel preprocessing and prediction pipeline for the\nclassification of magnetic resonance imaging (MRI) that takes advantage of the\ninformation rich complex valued k-Space. Using a publicly available MRI raw\ndataset with 312 subject and a total of 9508 slices, we show the advantage of\nutilizing the k-Space for better prostate cancer likelihood estimation in\ncomparison to just using the magnitudinal information in the image domain, with\nan AUROC of $86.1\\%\\pm1.8\\%$. Additionally, by using high undersampling rates\nand a simple principal component analysis (PCA) for coil compression, we reduce\nthe time needed for reconstruction by avoiding the time intensive GRAPPA\nreconstruction algorithm. By using digital undersampling for our experiments,\nwe show that scanning and reconstruction time could be reduced. Even with an\nundersampling factor of 16, our approach achieves meaningful results, with an\nAUROC of $71.4\\%\\pm2.9\\%$, using the PCA coil combination and taking into\naccount the k-Space information. With this study, we were able to show the\nfeasibility of preserving phase and k-Space information, with consistent\nresults. Besides preserving valuable information for further diagnostics, this\napproach can work without the time intensive ADC and reconstruction\ncalculations, greatly reducing the post processing, as well as potential\nscanning time, increasing patient comfort and allowing a close to real-time\nprediction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "physics.med-ph"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.06165v2",
    "published_date": "2024-06-04 12:05:20 UTC",
    "updated_date": "2025-04-14 10:28:26 UTC"
  },
  {
    "arxiv_id": "2406.02235v1",
    "title": "Power Mean Estimation in Stochastic Monte-Carlo Tree_Search",
    "authors": [
      "Tuan Dam",
      "Odalric-Ambrym Maillard",
      "Emilie Kaufmann"
    ],
    "abstract": "Monte-Carlo Tree Search (MCTS) is a widely-used strategy for online planning\nthat combines Monte-Carlo sampling with forward tree search. Its success relies\non the Upper Confidence bound for Trees (UCT) algorithm, an extension of the\nUCB method for multi-arm bandits. However, the theoretical foundation of UCT is\nincomplete due to an error in the logarithmic bonus term for action selection,\nleading to the development of Fixed-Depth-MCTS with a polynomial exploration\nbonus to balance exploration and exploitation~\\citep{shah2022journal}. Both UCT\nand Fixed-Depth-MCTS suffer from biased value estimation: the weighted sum\nunderestimates the optimal value, while the maximum valuation overestimates\nit~\\citep{coulom2006efficient}. The power mean estimator offers a balanced\nsolution, lying between the average and maximum values.\nPower-UCT~\\citep{dam2019generalized} incorporates this estimator for more\naccurate value estimates but its theoretical analysis remains incomplete. This\npaper introduces Stochastic-Power-UCT, an MCTS algorithm using the power mean\nestimator and tailored for stochastic MDPs. We analyze its polynomial\nconvergence in estimating root node values and show that it shares the same\nconvergence rate of $\\mathcal{O}(n^{-1/2})$, with $n$ is the number of visited\ntrajectories, as Fixed-Depth-MCTS, with the latter being a special case of the\nformer. Our theoretical results are validated with empirical tests across\nvarious stochastic MDP environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "UAI 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.02235v1",
    "published_date": "2024-06-04 11:56:37 UTC",
    "updated_date": "2024-06-04 11:56:37 UTC"
  },
  {
    "arxiv_id": "2406.02234v2",
    "title": "On the Limitations of Fractal Dimension as a Measure of Generalization",
    "authors": [
      "Charlie B. Tan",
      "Inés García-Redondo",
      "Qiquan Wang",
      "Michael M. Bronstein",
      "Anthea Monod"
    ],
    "abstract": "Bounding and predicting the generalization gap of overparameterized neural\nnetworks remains a central open problem in theoretical machine learning. There\nis a recent and growing body of literature that proposes the framework of\nfractals to model optimization trajectories of neural networks, motivating\ngeneralization bounds and measures based on the fractal dimension of the\ntrajectory. Notably, the persistent homology dimension has been proposed to\ncorrelate with the generalization gap. This paper performs an empirical\nevaluation of these persistent homology-based generalization measures, with an\nin-depth statistical analysis. Our study reveals confounding effects in the\nobserved correlation between generalization and topological measures due to the\nvariation of hyperparameters. We also observe that fractal dimension fails to\npredict generalization of models trained from poor initializations. We lastly\nreveal the intriguing manifestation of model-wise double descent in these\ntopological generalization measures. Our work forms a basis for a deeper\ninvestigation of the causal relationships between fractal geometry, topological\ndata analysis, and neural network optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DS",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02234v2",
    "published_date": "2024-06-04 11:56:19 UTC",
    "updated_date": "2024-11-01 16:22:33 UTC"
  },
  {
    "arxiv_id": "2406.02224v4",
    "title": "FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models",
    "authors": [
      "Tao Fan",
      "Guoqiang Ma",
      "Yan Kang",
      "Hanlin Gu",
      "Yuanfeng Song",
      "Lixin Fan",
      "Kai Chen",
      "Qiang Yang"
    ],
    "abstract": "Recent research in federated large language models (LLMs) has primarily\nfocused on enabling clients to fine-tune their locally deployed homogeneous\nLLMs collaboratively or on transferring knowledge from server-based LLMs to\nsmall language models (SLMs) at downstream clients. However, a significant gap\nremains in the simultaneous mutual enhancement of both the server's LLM and\nclients' SLMs. To bridge this gap, we propose FedMKT, a parameter-efficient\nfederated mutual knowledge transfer framework for large and small language\nmodels. This framework is designed to adaptively transfer knowledge from the\nserver's LLM to clients' SLMs while concurrently enriching the LLM with\nclients' unique domain insights. We facilitate token alignment using minimum\nedit distance (MinED) and then selective mutual knowledge transfer between\nclient-side SLMs and a server-side LLM, aiming to collectively enhance their\nperformance. Through extensive experiments across three distinct scenarios, we\nevaluate the effectiveness of FedMKT using various public LLMs and SLMs on a\nrange of NLP text generation tasks. Empirical results demonstrate that FedMKT\nsimultaneously boosts the performance of both LLMs and SLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02224v4",
    "published_date": "2024-06-04 11:36:09 UTC",
    "updated_date": "2024-12-16 16:13:14 UTC"
  },
  {
    "arxiv_id": "2406.02208v1",
    "title": "Why Only Text: Empowering Vision-and-Language Navigation with Multi-modal Prompts",
    "authors": [
      "Haodong Hong",
      "Sen Wang",
      "Zi Huang",
      "Qi Wu",
      "Jiajun Liu"
    ],
    "abstract": "Current Vision-and-Language Navigation (VLN) tasks mainly employ textual\ninstructions to guide agents. However, being inherently abstract, the same\ntextual instruction can be associated with different visual signals, causing\nsevere ambiguity and limiting the transfer of prior knowledge in the vision\ndomain from the user to the agent. To fill this gap, we propose\nVision-and-Language Navigation with Multi-modal Prompts (VLN-MP), a novel task\naugmenting traditional VLN by integrating both natural language and images in\ninstructions. VLN-MP not only maintains backward compatibility by effectively\nhandling text-only prompts but also consistently shows advantages with\ndifferent quantities and relevance of visual prompts. Possible forms of visual\nprompts include both exact and similar object images, providing adaptability\nand versatility in diverse navigation scenarios. To evaluate VLN-MP under a\nunified framework, we implement a new benchmark that offers: (1) a\ntraining-free pipeline to transform textual instructions into multi-modal forms\nwith landmark images; (2) diverse datasets with multi-modal instructions for\ndifferent downstream tasks; (3) a novel module designed to process various\nimage prompts for seamless integration with state-of-the-art VLN models.\nExtensive experiments on four VLN benchmarks (R2R, RxR, REVERIE, CVDN) show\nthat incorporating visual prompts significantly boosts navigation performance.\nWhile maintaining efficiency with text-only prompts, VLN-MP enables agents to\nnavigate in the pre-explore setting and outperform text-based models, showing\nits broader applicability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02208v1",
    "published_date": "2024-06-04 11:06:13 UTC",
    "updated_date": "2024-06-04 11:06:13 UTC"
  },
  {
    "arxiv_id": "2406.02205v1",
    "title": "Query-Enhanced Adaptive Semantic Path Reasoning for Inductive Knowledge Graph Completion",
    "authors": [
      "Kai Sun",
      "Jiapu Wang",
      "Huajie Jiang",
      "Yongli Hu",
      "Baocai Yin"
    ],
    "abstract": "Conventional Knowledge graph completion (KGC) methods aim to infer missing\ninformation in incomplete Knowledge Graphs (KGs) by leveraging existing\ninformation, which struggle to perform effectively in scenarios involving\nemerging entities. Inductive KGC methods can handle the emerging entities and\nrelations in KGs, offering greater dynamic adaptability. While existing\ninductive KGC methods have achieved some success, they also face challenges,\nsuch as susceptibility to noisy structural information during reasoning and\ndifficulty in capturing long-range dependencies in reasoning paths. To address\nthese challenges, this paper proposes the Query-Enhanced Adaptive Semantic Path\nReasoning (QASPR) framework, which simultaneously captures both the structural\nand semantic information of KGs to enhance the inductive KGC task.\nSpecifically, the proposed QASPR employs a query-dependent masking module to\nadaptively mask noisy structural information while retaining important\ninformation closely related to the targets. Additionally, QASPR introduces a\nglobal semantic scoring module that evaluates both the individual contributions\nand the collective impact of nodes along the reasoning path within KGs. The\nexperimental results demonstrate that QASPR achieves state-of-the-art\nperformance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02205v1",
    "published_date": "2024-06-04 11:02:15 UTC",
    "updated_date": "2024-06-04 11:02:15 UTC"
  },
  {
    "arxiv_id": "2406.02204v1",
    "title": "The Deep Latent Space Particle Filter for Real-Time Data Assimilation with Uncertainty Quantification",
    "authors": [
      "Nikolaj T. Mücke",
      "Sander M. Bohté",
      "Cornelis W. Oosterlee"
    ],
    "abstract": "In Data Assimilation, observations are fused with simulations to obtain an\naccurate estimate of the state and parameters for a given physical system.\nCombining data with a model, however, while accurately estimating uncertainty,\nis computationally expensive and infeasible to run in real-time for complex\nsystems. Here, we present a novel particle filter methodology, the Deep Latent\nSpace Particle filter or D-LSPF, that uses neural network-based surrogate\nmodels to overcome this computational challenge. The D-LSPF enables filtering\nin the low-dimensional latent space obtained using Wasserstein AEs with\nmodified vision transformer layers for dimensionality reduction and\ntransformers for parameterized latent space time stepping. As we demonstrate on\nthree test cases, including leak localization in multi-phase pipe flow and\nseabed identification for fully nonlinear water waves, the D-LSPF runs orders\nof magnitude faster than a high-fidelity particle filter and 3-5 times faster\nthan alternative methods while being up to an order of magnitude more accurate.\nThe D-LSPF thus enables real-time data assimilation with uncertainty\nquantification for physical systems.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02204v1",
    "published_date": "2024-06-04 10:59:54 UTC",
    "updated_date": "2024-06-04 10:59:54 UTC"
  },
  {
    "arxiv_id": "2406.02642v3",
    "title": "E-ICL: Enhancing Fine-Grained Emotion Recognition through the Lens of Prototype Theory",
    "authors": [
      "Zhaochun Ren",
      "Zhou Yang",
      "Chenglong Ye",
      "Yufeng Wang",
      "Haizhou Sun",
      "Chao Chen",
      "Xiaofei Zhu",
      "Yunbing Wu",
      "Xiangwen Liao"
    ],
    "abstract": "In-context learning (ICL) achieves remarkable performance in various domains\nsuch as knowledge acquisition, commonsense reasoning, and semantic\nunderstanding. However, its performance significantly deteriorates for emotion\ndetection tasks, especially fine-grained emotion recognition. The underlying\nreasons for this remain unclear. In this paper, we identify the reasons behind\nICL's poor performance from the perspective of prototype theory and propose a\nmethod to address this issue. Specifically, we conduct extensive pilot\nexperiments and find that ICL conforms to the prototype theory on fine-grained\nemotion recognition. Based on this theory, we uncover the following\ndeficiencies in ICL: (1) It relies on prototypes (example-label pairs) that are\nsemantically similar but emotionally inaccurate to predict emotions. (2) It is\nprone to interference from irrelevant categories, affecting the accuracy and\nrobustness of the predictions. To address these issues, we propose an Emotion\nContext Learning method (E-ICL) on fine-grained emotion recognition. E-ICL\nrelies on more emotionally accurate prototypes to predict categories by\nreferring to emotionally similar examples with dynamic labels. Simultaneously,\nE-ICL employs an exclusionary emotion prediction strategy to avoid interference\nfrom irrelevant categories, thereby increasing its accuracy and robustness.\nNote that the entire process is accomplished with the assistance of a\nplug-and-play emotion auxiliary model, without additional training. Experiments\non the fine-grained emotion datasets EDOS, Empathetic-Dialogues,\nEmpatheticIntent, and GoEmotions show that E-ICL achieves superior emotion\nprediction performance. Furthermore, even when the emotion auxiliary model used\nis lower than 10% of the LLMs, E-ICL can still boost the performance of LLMs by\nover 4% on multiple datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.02642v3",
    "published_date": "2024-06-04 10:59:43 UTC",
    "updated_date": "2025-01-06 01:52:41 UTC"
  },
  {
    "arxiv_id": "2406.02202v2",
    "title": "No Captions, No Problem: Captionless 3D-CLIP Alignment with Hard Negatives via CLIP Knowledge and LLMs",
    "authors": [
      "Cristian Sbrolli",
      "Matteo Matteucci"
    ],
    "abstract": "In this study, we explore an alternative approach to enhance contrastive\ntext-image-3D alignment in the absence of textual descriptions for 3D objects.\nWe introduce two unsupervised methods, $I2I$ and $(I2L)^2$, which leverage CLIP\nknowledge about textual and 2D data to compute the neural perceived similarity\nbetween two 3D samples. We employ the proposed methods to mine 3D hard\nnegatives, establishing a multimodal contrastive pipeline with hard negative\nweighting via a custom loss function. We train on different configurations of\nthe proposed hard negative mining approach, and we evaluate the accuracy of our\nmodels in 3D classification and on the cross-modal retrieval benchmark, testing\nimage-to-shape and shape-to-image retrieval. Results demonstrate that our\napproach, even without explicit text alignment, achieves comparable or superior\nperformance on zero-shot and standard 3D classification, while significantly\nimproving both image-to-shape and shape-to-image retrieval compared to previous\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "to be published in BMVC 2024 Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2406.02202v2",
    "published_date": "2024-06-04 10:57:59 UTC",
    "updated_date": "2024-09-09 12:04:27 UTC"
  },
  {
    "arxiv_id": "2406.16908v3",
    "title": "Using Explainable AI for EEG-based Reduced Montage Neonatal Seizure Detection",
    "authors": [
      "Dinuka Sandun Udayantha",
      "Kavindu Weerasinghe",
      "Nima Wickramasinghe",
      "Akila Abeyratne",
      "Kithmin Wickremasinghe",
      "Jithangi Wanigasinghe",
      "Anjula De Silva",
      "Chamira U. S. Edussooriya"
    ],
    "abstract": "The neonatal period is the most vulnerable time for the development of\nseizures. Seizures in the immature brain lead to detrimental consequences,\ntherefore require early diagnosis. The gold-standard for neonatal seizure\ndetection currently relies on continuous video-EEG monitoring; which involves\nrecording multi-channel electroencephalogram (EEG) alongside real-time video\nmonitoring within a neonatal intensive care unit (NICU). However, video-EEG\nmonitoring technology requires clinical expertise and is often limited to\ntechnologically advanced and resourceful settings. Cost-effective new\ntechniques could help the medical fraternity make an accurate diagnosis and\nadvocate treatment without delay. In this work, a novel explainable deep\nlearning model to automate the neonatal seizure detection process with a\nreduced EEG montage is proposed, which employs convolutional nets, graph\nattention layers, and fully connected layers. Beyond its ability to detect\nseizures in real-time with a reduced montage, this model offers the unique\nadvantage of real-time interpretability. By evaluating the performance on the\nZenodo dataset with 10-fold cross-validation, the presented model achieves an\nabsolute improvement of 8.31% and 42.86% in area under curve (AUC) and recall,\nrespectively.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Paper is accepted to IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC) 2024. Final Version",
    "pdf_url": "http://arxiv.org/pdf/2406.16908v3",
    "published_date": "2024-06-04 10:53:56 UTC",
    "updated_date": "2024-08-14 11:07:41 UTC"
  },
  {
    "arxiv_id": "2407.13773v1",
    "title": "OpenDataLab: Empowering General Artificial Intelligence with Open Datasets",
    "authors": [
      "Conghui He",
      "Wei Li",
      "Zhenjiang Jin",
      "Chao Xu",
      "Bin Wang",
      "Dahua Lin"
    ],
    "abstract": "The advancement of artificial intelligence (AI) hinges on the quality and\naccessibility of data, yet the current fragmentation and variability of data\nsources hinder efficient data utilization. The dispersion of data sources and\ndiversity of data formats often lead to inefficiencies in data retrieval and\nprocessing, significantly impeding the progress of AI research and\napplications. To address these challenges, this paper introduces OpenDataLab, a\nplatform designed to bridge the gap between diverse data sources and the need\nfor unified data processing. OpenDataLab integrates a wide range of open-source\nAI datasets and enhances data acquisition efficiency through intelligent\nquerying and high-speed downloading services. The platform employs a\nnext-generation AI Data Set Description Language (DSDL), which standardizes the\nrepresentation of multimodal and multi-format data, improving interoperability\nand reusability. Additionally, OpenDataLab optimizes data processing through\ntools that complement DSDL. By integrating data with unified data descriptions\nand smart data toolchains, OpenDataLab can improve data preparation efficiency\nby 30\\%. We anticipate that OpenDataLab will significantly boost artificial\ngeneral intelligence (AGI) research and facilitate advancements in related AI\nfields. For more detailed information, please visit the platform's official\nwebsite: https://opendatalab.com.",
    "categories": [
      "cs.DL",
      "cs.AI"
    ],
    "primary_category": "cs.DL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13773v1",
    "published_date": "2024-06-04 10:42:01 UTC",
    "updated_date": "2024-06-04 10:42:01 UTC"
  },
  {
    "arxiv_id": "2406.11873v1",
    "title": "Logic-Based Explainability: Past, Present & Future",
    "authors": [
      "Joao Marques-Silva"
    ],
    "abstract": "In recent years, the impact of machine learning (ML) and artificial\nintelligence (AI) in society has been absolutely remarkable. This impact is\nexpected to continue in the foreseeable future. However,the adoption of AI/ML\nis also a cause of grave concern. The operation of the most advances AI/ML\nmodels is often beyond the grasp of human decision makers. As a result,\ndecisions that impact humans may not be understood and may lack rigorous\nvalidation. Explainable AI (XAI) is concerned with providing human\ndecision-makers with understandable explanations for the predictions made by ML\nmodels. As a result, XAI is a cornerstone of trustworthy AI. Despite its\nstrategic importance, most work on XAI lacks rigor, and so its use in high-risk\nor safety-critical domains serves to foster distrust instead of contributing to\nbuild much-needed trust. Logic-based XAI has recently emerged as a rigorous\nalternative to those other non-rigorous methods of XAI. This paper provides a\ntechnical survey of logic-based XAI, its origins, the current topics of\nresearch, and emerging future topics of research. The paper also highlights the\nmany myths that pervade non-rigorous approaches for XAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11873v1",
    "published_date": "2024-06-04 10:41:55 UTC",
    "updated_date": "2024-06-04 10:41:55 UTC"
  },
  {
    "arxiv_id": "2406.02180v1",
    "title": "On The Statistical Representation Properties Of The Perturb-Softmax And The Perturb-Argmax Probability Distributions",
    "authors": [
      "Hedda Cohen Indelman",
      "Tamir Hazan"
    ],
    "abstract": "The Gumbel-Softmax probability distribution allows learning discrete tokens\nin generative learning, while the Gumbel-Argmax probability distribution is\nuseful in learning discrete structures in discriminative learning. Despite the\nefforts invested in optimizing these probability models, their statistical\nproperties are under-explored. In this work, we investigate their\nrepresentation properties and determine for which families of parameters these\nprobability distributions are complete, i.e., can represent any probability\ndistribution, and minimal, i.e., can represent a probability distribution\nuniquely. We rely on convexity and differentiability to determine these\nstatistical conditions and extend this framework to general probability models,\nsuch as Gaussian-Softmax and Gaussian-Argmax. We experimentally validate the\nqualities of these extensions, which enjoy a faster convergence rate. We\nconclude the analysis by identifying two sets of parameters that satisfy these\nassumptions and thus admit a complete and minimal representation. Our\ncontribution is theoretical with supporting practical evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02180v1",
    "published_date": "2024-06-04 10:22:12 UTC",
    "updated_date": "2024-06-04 10:22:12 UTC"
  },
  {
    "arxiv_id": "2406.02178v2",
    "title": "Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations",
    "authors": [
      "Sarthak Yadav",
      "Zheng-Hua Tan"
    ],
    "abstract": "Despite its widespread adoption as the prominent neural architecture, the\nTransformer has spurred several independent lines of work to address its\nlimitations. One such approach is selective state space models, which have\ndemonstrated promising results for language modelling. However, their\nfeasibility for learning self-supervised, general-purpose audio representations\nis yet to be investigated. This work proposes Audio Mamba, a selective state\nspace model for learning general-purpose audio representations from randomly\nmasked spectrogram patches through self-supervision. Empirical results on ten\ndiverse audio recognition downstream tasks show that the proposed models,\npretrained on the AudioSet dataset, consistently outperform comparable\nself-supervised audio spectrogram transformer (SSAST) baselines by a\nconsiderable margin and demonstrate better performance in dataset size,\nsequence length and model size comparisons.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at INTERSPEECH 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02178v2",
    "published_date": "2024-06-04 10:19:14 UTC",
    "updated_date": "2024-06-07 18:41:28 UTC"
  },
  {
    "arxiv_id": "2406.02177v1",
    "title": "One-Shot Federated Learning with Bayesian Pseudocoresets",
    "authors": [
      "Tim d'Hondt",
      "Mykola Pechenizkiy",
      "Robert Peharz"
    ],
    "abstract": "Optimization-based techniques for federated learning (FL) often come with\nprohibitive communication cost, as high dimensional model parameters need to be\ncommunicated repeatedly between server and clients. In this paper, we follow a\nBayesian approach allowing to perform FL with one-shot communication, by\nsolving the global inference problem as a product of local client posteriors.\nFor models with multi-modal likelihoods, such as neural networks, a naive\napplication of this scheme is hampered, since clients will capture different\nposterior modes, causing a destructive collapse of the posterior on the server\nside. Consequently, we explore approximate inference in the function-space\nrepresentation of client posteriors, hence suffering less or not at all from\nmulti-modality. We show that distributed function-space inference is tightly\nrelated to learning Bayesian pseudocoresets and develop a tractable Bayesian FL\nalgorithm on this insight. We show that this approach achieves prediction\nperformance competitive to state-of-the-art while showing a striking reduction\nin communication cost of up to two orders of magnitude. Moreover, due to its\nBayesian nature, our method also delivers well-calibrated uncertainty\nestimates.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.02177v1",
    "published_date": "2024-06-04 10:14:39 UTC",
    "updated_date": "2024-06-04 10:14:39 UTC"
  },
  {
    "arxiv_id": "2407.13105v1",
    "title": "Survey on Plagiarism Detection in Large Language Models: The Impact of ChatGPT and Gemini on Academic Integrity",
    "authors": [
      "Shushanta Pudasaini",
      "Luis Miralles-Pechuán",
      "David Lillis",
      "Marisa Llorens Salvador"
    ],
    "abstract": "The rise of Large Language Models (LLMs) such as ChatGPT and Gemini has posed\nnew challenges for the academic community. With the help of these models,\nstudents can easily complete their assignments and exams, while educators\nstruggle to detect AI-generated content. This has led to a surge in academic\nmisconduct, as students present work generated by LLMs as their own, without\nputting in the effort required for learning. As AI tools become more advanced\nand produce increasingly human-like text, detecting such content becomes more\nchallenging. This development has significantly impacted the academic world,\nwhere many educators are finding it difficult to adapt their assessment methods\nto this challenge.\n  This research first demonstrates how LLMs have increased academic dishonesty,\nand then reviews state-of-the-art solutions for academic plagiarism in detail.\nA survey of datasets, algorithms, tools, and evasion strategies for plagiarism\ndetection has been conducted, focusing on how LLMs and AI-generated content\n(AIGC) detection have affected this area. The survey aims to identify the gaps\nin existing solutions. Lastly, potential long-term solutions are presented to\naddress the issue of academic plagiarism using LLMs based on AI tools and\neducational approaches in an ever-changing world.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.13105v1",
    "published_date": "2024-06-04 09:38:03 UTC",
    "updated_date": "2024-06-04 09:38:03 UTC"
  },
  {
    "arxiv_id": "2406.02148v1",
    "title": "Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models",
    "authors": [
      "Qingkai Min",
      "Qipeng Guo",
      "Xiangkun Hu",
      "Songfang Huang",
      "Zheng Zhang",
      "Yue Zhang"
    ],
    "abstract": "Cross-document event coreference resolution (CDECR) involves clustering event\nmentions across multiple documents that refer to the same real-world events.\nExisting approaches utilize fine-tuning of small language models (SLMs) like\nBERT to address the compatibility among the contexts of event mentions.\nHowever, due to the complexity and diversity of contexts, these models are\nprone to learning simple co-occurrences. Recently, large language models (LLMs)\nlike ChatGPT have demonstrated impressive contextual understanding, yet they\nencounter challenges in adapting to specific information extraction (IE) tasks.\nIn this paper, we propose a collaborative approach for CDECR, leveraging the\ncapabilities of both a universally capable LLM and a task-specific SLM. The\ncollaborative strategy begins with the LLM accurately and comprehensively\nsummarizing events through prompting. Then, the SLM refines its learning of\nevent representations based on these insights during fine-tuning. Experimental\nresults demonstrate that our approach surpasses the performance of both the\nlarge and small language models individually, forming a complementary\nadvantage. Across various datasets, our approach achieves state-of-the-art\nperformance, underscoring its effectiveness in diverse scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL-24 Main",
    "pdf_url": "http://arxiv.org/pdf/2406.02148v1",
    "published_date": "2024-06-04 09:35:47 UTC",
    "updated_date": "2024-06-04 09:35:47 UTC"
  },
  {
    "arxiv_id": "2406.02131v4",
    "title": "CondTSF: One-line Plugin of Dataset Condensation for Time Series Forecasting",
    "authors": [
      "Jianrong Ding",
      "Zhanyu Liu",
      "Guanjie Zheng",
      "Haiming Jin",
      "Linghe Kong"
    ],
    "abstract": "Dataset condensation is a newborn technique that generates a small dataset\nthat can be used in training deep neural networks to lower training costs. The\nobjective of dataset condensation is to ensure that the model trained with the\nsynthetic dataset can perform comparably to the model trained with full\ndatasets. However, existing methods predominantly concentrate on classification\ntasks, posing challenges in their adaptation to time series forecasting\n(TS-forecasting). This challenge arises from disparities in the evaluation of\nsynthetic data. In classification, the synthetic data is considered\nwell-distilled if the model trained with the full dataset and the model trained\nwith the synthetic dataset yield identical labels for the same input,\nregardless of variations in output logits distribution. Conversely, in\nTS-forecasting, the effectiveness of synthetic data distillation is determined\nby the distance between predictions of the two models. The synthetic data is\ndeemed well-distilled only when all data points within the predictions are\nsimilar. Consequently, TS-forecasting has a more rigorous evaluation\nmethodology compared to classification. To mitigate this gap, we theoretically\nanalyze the optimization objective of dataset condensation for TS-forecasting\nand propose a new one-line plugin of dataset condensation designated as Dataset\nCondensation for Time Series Forecasting (CondTSF) based on our analysis.\nPlugging CondTSF into previous dataset condensation methods facilitates a\nreduction in the distance between the predictions of the model trained with the\nfull dataset and the model trained with the synthetic dataset, thereby\nenhancing performance. We conduct extensive experiments on eight commonly used\ntime series datasets. CondTSF consistently improves the performance of all\nprevious dataset condensation methods across all datasets, particularly at low\ncondensing ratios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024, the project can be found at\n  https://github.com/RafaDD/CondTSF",
    "pdf_url": "http://arxiv.org/pdf/2406.02131v4",
    "published_date": "2024-06-04 09:18:20 UTC",
    "updated_date": "2024-10-23 16:05:11 UTC"
  },
  {
    "arxiv_id": "2406.02128v2",
    "title": "Iteration Head: A Mechanistic Study of Chain-of-Thought",
    "authors": [
      "Vivien Cabannes",
      "Charles Arnal",
      "Wassim Bouaziz",
      "Alice Yang",
      "Francois Charton",
      "Julia Kempe"
    ],
    "abstract": "Chain-of-Thought (CoT) reasoning is known to improve Large Language Models\nboth empirically and in terms of theoretical approximation power. However, our\nunderstanding of the inner workings and conditions of apparition of CoT\ncapabilities remains limited. This paper helps fill this gap by demonstrating\nhow CoT reasoning emerges in transformers in a controlled and interpretable\nsetting. In particular, we observe the appearance of a specialized attention\nmechanism dedicated to iterative reasoning, which we coined \"iteration heads\".\nWe track both the emergence and the precise working of these iteration heads\ndown to the attention level, and measure the transferability of the CoT skills\nto which they give rise between tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02128v2",
    "published_date": "2024-06-04 09:11:46 UTC",
    "updated_date": "2024-10-28 11:14:54 UTC"
  },
  {
    "arxiv_id": "2406.02126v3",
    "title": "CityLight: A Universal Model for Coordinated Traffic Signal Control in City-scale Heterogeneous Intersections",
    "authors": [
      "Jinwei Zeng",
      "Chao Yu",
      "Xinyi Yang",
      "Wenxuan Ao",
      "Qianyue Hao",
      "Jian Yuan",
      "Yong Li",
      "Yu Wang",
      "Huazhong Yang"
    ],
    "abstract": "The increasingly severe congestion problem in modern cities strengthens the\nsignificance of developing city-scale traffic signal control (TSC) methods for\ntraffic efficiency enhancement. While reinforcement learning has been widely\nexplored in TSC, most of them still target small-scale optimization and cannot\ndirectly scale to the city level due to unbearable resource demand. Only a few\nof them manage to tackle city-level optimization, namely a thousand-scale\noptimization, by incorporating parameter-sharing mechanisms, but hardly have\nthey fully tackled the heterogeneity of intersections and intricate\nbetween-intersection interactions inherent in real-world city road networks. To\nfill in the gap, we target at the two important challenges in adopting\nparameter-sharing paradigms to solve TSC: inconsistency of inner state\nrepresentations for intersections heterogeneous in configuration, scale, and\norders of available traffic phases; intricacy of impacts from neighborhood\nintersections that have various relative traffic relationships due to\ninconsistent phase orders and diverse relative positioning. Our method,\nCityLight, features a universal representation module that not only aligns the\nstate representations of intersections by reindexing their phases based on\ntheir semantics and designing heterogeneity-preserving observations, but also\nencodes the narrowed relative traffic relation types to project the\nneighborhood intersections onto a uniform relative traffic impact space. We\nfurther attentively fuse neighborhood representations based on their competing\nrelations and incorporate neighborhood-integrated rewards to boost\ncoordination. Extensive experiments with hundreds to tens of thousands of\nintersections validate the surprising effectiveness and generalizability of\nCityLight, with an overall performance gain of 11.68% and a 22.59% improvement\nin transfer scenarios in throughput.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02126v3",
    "published_date": "2024-06-04 09:10:14 UTC",
    "updated_date": "2024-08-29 02:00:25 UTC"
  },
  {
    "arxiv_id": "2406.02638v2",
    "title": "EchoMamba4Rec: Harmonizing Bidirectional State Space Models with Spectral Filtering for Advanced Sequential Recommendation",
    "authors": [
      "Yuda Wang",
      "Xuxin He",
      "Shengxin Zhu"
    ],
    "abstract": "Predicting user preferences and sequential dependencies based on historical\nbehavior is the core goal of sequential recommendation. Although\nattention-based models have shown effectiveness in this field, they often\nstruggle with inference inefficiency due to the quadratic computational\ncomplexity inherent in attention mechanisms, especially with long-range\nbehavior sequences. Drawing inspiration from the recent advancements of state\nspace models (SSMs) in control theory, which provide a robust framework for\nmodeling and controlling dynamic systems, we introduce EchoMamba4Rec. Control\ntheory emphasizes the use of SSMs for managing long-range dependencies and\nmaintaining inferential efficiency through structured state matrices.\nEchoMamba4Rec leverages these control relationships in sequential\nrecommendation and integrates bi-directional processing with frequency-domain\nfiltering to capture complex patterns and dependencies in user interaction data\nmore effectively. Our model benefits from the ability of state space models\n(SSMs) to learn and perform parallel computations, significantly enhancing\ncomputational efficiency and scalability. It features a bi-directional Mamba\nmodule that incorporates both forward and reverse Mamba components, leveraging\ninformation from both past and future interactions. Additionally, a filter\nlayer operates in the frequency domain using learnable Fast Fourier Transform\n(FFT) and learnable filters, followed by an inverse FFT to refine item\nembeddings and reduce noise. We also integrate Gate Linear Units (GLU) to\ndynamically control information flow, enhancing the model's expressiveness and\ntraining stability. Experimental results demonstrate that EchoMamba\nsignificantly outperforms existing models, providing more accurate and\npersonalized recommendations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2403.03900 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2406.02638v2",
    "published_date": "2024-06-04 09:07:58 UTC",
    "updated_date": "2024-06-10 17:22:33 UTC"
  },
  {
    "arxiv_id": "2406.03402v3",
    "title": "Mixed-Precision Federated Learning via Multi-Precision Over-The-Air Aggregation",
    "authors": [
      "Jinsheng Yuan",
      "Zhuangkun Wei",
      "Weisi Guo"
    ],
    "abstract": "Over-the-Air Federated Learning (OTA-FL) is a privacy-preserving distributed\nlearning mechanism, by aggregating updates in the electromagnetic channel\nrather than at the server. A critical research gap in existing OTA-FL research\nis the assumption of homogeneous client computational bit precision. While in\nreal world application, clients with varying hardware resources may exploit\napproximate computing (AxC) to operate at different bit precisions optimized\nfor energy and computational efficiency. And model updates of various\nprecisions amongst clients poses an open challenge for OTA-FL, as it is\nincompatible in the wireless modulation superposition. Here, we propose an\nmixed-precision OTA-FL framework of clients with multiple bit precisions,\ndemonstrating the following innovations: (i) the superior trade-off for both\nserver and clients within the constraints of varying edge computing\ncapabilities, energy efficiency, and learning accuracy requirements comparing\nto homogeneous client bit precision, and (ii) a multi-precision gradient\nmodulation scheme to ensure compatibility with OTA aggregation and eliminate\nthe overheads of precision conversion. Through case study with real world data,\nwe validate our modulation scheme that enables AxC based mixed-precision\nOTA-FL. In comparison to homogeneous standard precision of 32-bit and 16-bit,\nour framework presents more than 10% in 4-bit ultra low precision client\nperformance and over 65%and 13% of energy savings respectively. This\ndemonstrates the great potential of our mixed-precision OTA-FL approach in\nheterogeneous edge computing environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WCNC 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.03402v3",
    "published_date": "2024-06-04 09:07:45 UTC",
    "updated_date": "2025-02-26 14:21:21 UTC"
  },
  {
    "arxiv_id": "2406.07573v1",
    "title": "Investigating the Potential of Using Large Language Models for Scheduling",
    "authors": [
      "Deddy Jobson",
      "Yilin Li"
    ],
    "abstract": "The inaugural ACM International Conference on AI-powered Software introduced\nthe AIware Challenge, prompting researchers to explore AI-driven tools for\noptimizing conference programs through constrained optimization. We investigate\nthe use of Large Language Models (LLMs) for program scheduling, focusing on\nzero-shot learning and integer programming to measure paper similarity. Our\nstudy reveals that LLMs, even under zero-shot settings, create reasonably good\nfirst drafts of conference schedules. When clustering papers, using only titles\nas LLM inputs produces results closer to human categorization than using titles\nand abstracts with TFIDF. The code has been made publicly available.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07573v1",
    "published_date": "2024-06-04 08:56:56 UTC",
    "updated_date": "2024-06-04 08:56:56 UTC"
  },
  {
    "arxiv_id": "2406.02110v1",
    "title": "UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models",
    "authors": [
      "Zhuoyang Li",
      "Liran Deng",
      "Hui Liu",
      "Qiaoqiao Liu",
      "Junzhao Du"
    ],
    "abstract": "OwnThink stands as the most extensive Chinese open-domain knowledge graph\nintroduced in recent times. Despite prior attempts in question answering over\nOwnThink (OQA), existing studies have faced limitations in model representation\ncapabilities, posing challenges in further enhancing overall accuracy in\nquestion answering. In this paper, we introduce UniOQA, a unified framework\nthat integrates two complementary parallel workflows. Unlike conventional\napproaches, UniOQA harnesses large language models (LLMs) for precise question\nanswering and incorporates a direct-answer-prediction process as a\ncost-effective complement. Initially, to bolster representation capacity, we\nfine-tune an LLM to translate questions into the Cypher query language (CQL),\ntackling issues associated with restricted semantic understanding and\nhallucinations. Subsequently, we introduce the Entity and Relation Replacement\nalgorithm to ensure the executability of the generated CQL. Concurrently, to\naugment overall accuracy in question answering, we further adapt the\nRetrieval-Augmented Generation (RAG) process to the knowledge graph.\nUltimately, we optimize answer accuracy through a dynamic decision algorithm.\nExperimental findings illustrate that UniOQA notably advances SpCQL Logical\nAccuracy to 21.2% and Execution Accuracy to 54.9%, achieving the new\nstate-of-the-art results on this benchmark. Through ablation experiments, we\ndelve into the superior representation capacity of UniOQA and quantify its\nperformance breakthrough.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02110v1",
    "published_date": "2024-06-04 08:36:39 UTC",
    "updated_date": "2024-06-04 08:36:39 UTC"
  },
  {
    "arxiv_id": "2406.06577v1",
    "title": "RAG-based Crowdsourcing Task Decomposition via Masked Contrastive Learning with Prompts",
    "authors": [
      "Jing Yang",
      "Xiao Wang",
      "Yu Zhao",
      "Yuhang Liu",
      "Fei-Yue Wang"
    ],
    "abstract": "Crowdsourcing is a critical technology in social manufacturing, which\nleverages an extensive and boundless reservoir of human resources to handle a\nwide array of complex tasks. The successful execution of these complex tasks\nrelies on task decomposition (TD) and allocation, with the former being a\nprerequisite for the latter. Recently, pre-trained language models (PLMs)-based\nmethods have garnered significant attention. However, they are constrained to\nhandling straightforward common-sense tasks due to their inherent restrictions\ninvolving limited and difficult-to-update knowledge as well as the presence of\nhallucinations. To address these issues, we propose a retrieval-augmented\ngeneration-based crowdsourcing framework that reimagines TD as event detection\nfrom the perspective of natural language understanding. However, the existing\ndetection methods fail to distinguish differences between event types and\nalways depend on heuristic rules and external semantic analyzing tools.\nTherefore, we present a Prompt-Based Contrastive learning framework for TD\n(PBCT), which incorporates a prompt-based trigger detector to overcome\ndependence. Additionally, trigger-attentive sentinel and masked contrastive\nlearning are introduced to provide varying attention to trigger and contextual\nfeatures according to different event types. Experiment results demonstrate the\ncompetitiveness of our method in both supervised and zero-shot detection. A\ncase study on printed circuit board manufacturing is showcased to validate its\nadaptability to unknown professional domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.06577v1",
    "published_date": "2024-06-04 08:34:19 UTC",
    "updated_date": "2024-06-04 08:34:19 UTC"
  },
  {
    "arxiv_id": "2406.02105v3",
    "title": "Can Kernel Methods Explain How the Data Affects Neural Collapse?",
    "authors": [
      "Vignesh Kothapalli",
      "Tom Tirer"
    ],
    "abstract": "A vast amount of literature has recently focused on the \"Neural Collapse\"\n(NC) phenomenon, which emerges when training neural network (NN) classifiers\nbeyond the zero training error point. The core component of NC is the decrease\nin the within-class variability of the network's deepest features, dubbed as\nNC1. The theoretical works that study NC are typically based on simplified\nunconstrained features models (UFMs) that mask any effect of the data on the\nextent of collapse. To address this limitation of UFMs, this paper explores the\npossibility of analyzing NC1 using kernels associated with shallow NNs. We\nbegin by formulating an NC1 metric as a function of the kernel. Then, we\nspecialize it to the NN Gaussian Process kernel (NNGP) and the Neural Tangent\nKernel (NTK), associated with wide networks at initialization and during\ngradient-based training with a small learning rate, respectively. As a key\nresult, we show that the NTK does not represent more collapsed features than\nthe NNGP for Gaussian data of arbitrary dimensions. This showcases the\nlimitations of data-independent kernels such as NTK in approximating the NC\nbehavior of NNs. As an alternative to NTK, we then empirically explore a\nrecently proposed data-aware Gaussian Process kernel, which generalizes NNGP to\nmodel feature learning. We show that this kernel yields lower NC1 than NNGP but\nmay not follow the trends of the shallow NN. Our study demonstrates that\nadaptivity to data may allow kernel-based analysis of NC, though further\nadvancements in this area are still needed. A nice byproduct of our study is\nshowing both theoretically and empirically that the choice of nonlinear\nactivation function affects NC1 (with ERF yielding lower values than ReLU). The\ncode is available at: https://github.com/kvignesh1420/shallow_nc1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Transactions on Machine Learning Research (TMLR)",
    "pdf_url": "http://arxiv.org/pdf/2406.02105v3",
    "published_date": "2024-06-04 08:33:56 UTC",
    "updated_date": "2025-04-25 06:43:34 UTC"
  },
  {
    "arxiv_id": "2406.02103v1",
    "title": "A Bayesian Approach to Online Planning",
    "authors": [
      "Nir Greshler",
      "David Ben Eli",
      "Carmel Rabinovitz",
      "Gabi Guetta",
      "Liran Gispan",
      "Guy Zohar",
      "Aviv Tamar"
    ],
    "abstract": "The combination of Monte Carlo tree search and neural networks has\nrevolutionized online planning. As neural network approximations are often\nimperfect, we ask whether uncertainty estimates about the network outputs could\nbe used to improve planning. We develop a Bayesian planning approach that\nfacilitates such uncertainty quantification, inspired by classical ideas from\nthe meta-reasoning literature. We propose a Thompson sampling based algorithm\nfor searching the tree of possible actions, for which we prove the first (to\nour knowledge) finite time Bayesian regret bound, and propose an efficient\nimplementation for a restricted family of posterior distributions. In addition\nwe propose a variant of the Bayes-UCB method applied to trees. Empirically, we\ndemonstrate that on the ProcGen Maze and Leaper environments, when the\nuncertainty estimates are accurate but the neural network output is inaccurate,\nour Bayesian approach searches the tree much more effectively. In addition, we\ninvestigate whether popular uncertainty estimation methods are accurate enough\nto yield significant gains in planning. Our code is available at:\nhttps://github.com/nirgreshler/bayesian-online-planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02103v1",
    "published_date": "2024-06-04 08:33:17 UTC",
    "updated_date": "2024-06-04 08:33:17 UTC"
  },
  {
    "arxiv_id": "2406.02092v1",
    "title": "MaskSR: Masked Language Model for Full-band Speech Restoration",
    "authors": [
      "Xu Li",
      "Qirui Wang",
      "Xiaoyu Liu"
    ],
    "abstract": "Speech restoration aims at restoring high quality speech in the presence of a\ndiverse set of distortions. Although several deep learning paradigms have been\nstudied for this task, the power of the recently emerging language models has\nnot been fully explored. In this paper, we propose MaskSR, a masked language\nmodel capable of restoring full-band 44.1 kHz speech jointly considering noise,\nreverb, clipping, and low bandwidth. MaskSR works with discrete acoustic tokens\nextracted using a pre-trained neural codec. During training, MaskSR is\noptimized to predict randomly masked tokens extracted from the high quality\ntarget speech, conditioned on the corrupted speech with various distortions.\nDuring inference, MaskSR reconstructs the target speech tokens with efficient\niterative sampling. Extensive experiments show that MaskSR obtains competitive\nresults on both the full-band speech restoration task and also on sub-tasks\ncompared with a wide range of models.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by INTERSPEECH 2024. Demo page:\n  https://masksr.github.io/MaskSR/",
    "pdf_url": "http://arxiv.org/pdf/2406.02092v1",
    "published_date": "2024-06-04 08:23:57 UTC",
    "updated_date": "2024-06-04 08:23:57 UTC"
  },
  {
    "arxiv_id": "2406.02090v2",
    "title": "WEIRD ICWSM: How Western, Educated, Industrialized, Rich, and Democratic is Social Computing Research?",
    "authors": [
      "Ali Akbar Septiandri",
      "Marios Constantinides",
      "Daniele Quercia"
    ],
    "abstract": "Much of the research in social computing analyzes data from social media\nplatforms, which may inherently carry biases. An overlooked source of such bias\nis the over-representation of WEIRD (Western, Educated, Industrialized, Rich,\nand Democratic) populations, which might not accurately mirror the global\ndemographic diversity. We evaluated the dependence on WEIRD populations in\nresearch presented at the AAAI ICWSM conference; the only venue whose\nproceedings are fully dedicated to social computing research. We did so by\nanalyzing 494 papers published from 2018 to 2022, which included full research\npapers, dataset papers and posters. After filtering out papers that analyze\nsynthetic datasets or those lacking clear country of origin, we were left with\n420 papers from which 188 participants in a crowdsourcing study with full\nmanual validation extracted data for the WEIRD scores computation. This data\nwas then used to adapt existing WEIRD metrics to be applicable for social media\ndata. We found that 37% of these papers focused solely on data from Western\ncountries. This percentage is significantly less than the percentages observed\nin research from CHI (76%) and FAccT (84%) conferences, suggesting a greater\ndiversity of dataset origins within ICWSM. However, the studies at ICWSM still\npredominantly examine populations from countries that are more Educated,\nIndustrialized, and Rich in comparison to those in FAccT, with a special note\non the 'Democratic' variable reflecting political freedoms and rights. This\npoints out the utility of social media data in shedding light on findings from\ncountries with restricted political freedoms. Based on these insights, we\nrecommend extensions of current \"paper checklists\" to include considerations\nabout the WEIRD bias and call for the community to broaden research inclusivity\nby encouraging the use of diverse datasets from underrepresented regions.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 2 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.02090v2",
    "published_date": "2024-06-04 08:17:47 UTC",
    "updated_date": "2024-06-11 13:34:09 UTC"
  },
  {
    "arxiv_id": "2406.18576v1",
    "title": "Negative Prototypes Guided Contrastive Learning for WSOD",
    "authors": [
      "Yu Zhang",
      "Chuang Zhu",
      "Guoqing Yang",
      "Siqi Chen"
    ],
    "abstract": "Weakly Supervised Object Detection (WSOD) with only image-level annotation\nhas recently attracted wide attention. Many existing methods ignore the\ninter-image relationship of instances which share similar characteristics while\ncan certainly be determined not to belong to the same category. Therefore, in\norder to make full use of the weak label, we propose the Negative Prototypes\nGuided Contrastive learning (NPGC) architecture. Firstly, we define Negative\nPrototype as the proposal with the highest confidence score misclassified for\nthe category that does not appear in the label. Unlike other methods that only\nutilize category positive feature, we construct an online updated global\nfeature bank to store both positive prototypes and negative prototypes.\nMeanwhile, we propose a pseudo label sampling module to mine reliable instances\nand discard the easily misclassified instances based on the feature similarity\nwith corresponding prototypes in global feature bank. Finally, we follow the\ncontrastive learning paradigm to optimize the proposal's feature representation\nby attracting same class samples closer and pushing different class samples\naway in the embedding space. Extensive experiments have been conducted on\nVOC07, VOC12 datasets, which shows that our proposed method achieves the\nstate-of-the-art performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18576v1",
    "published_date": "2024-06-04 08:16:26 UTC",
    "updated_date": "2024-06-04 08:16:26 UTC"
  },
  {
    "arxiv_id": "2406.02081v2",
    "title": "FightLadder: A Benchmark for Competitive Multi-Agent Reinforcement Learning",
    "authors": [
      "Wenzhe Li",
      "Zihan Ding",
      "Seth Karten",
      "Chi Jin"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) heavily rely on a variety of\nwell-designed benchmarks, which provide environmental platforms and consistent\ncriteria to evaluate existing and novel algorithms. Specifically, in\nmulti-agent RL (MARL), a plethora of benchmarks based on cooperative games have\nspurred the development of algorithms that improve the scalability of\ncooperative multi-agent systems. However, for the competitive setting, a\nlightweight and open-sourced benchmark with challenging gaming dynamics and\nvisual inputs has not yet been established. In this work, we present\nFightLadder, a real-time fighting game platform, to empower competitive MARL\nresearch. Along with the platform, we provide implementations of\nstate-of-the-art MARL algorithms for competitive games, as well as a set of\nevaluation metrics to characterize the performance and exploitability of\nagents. We demonstrate the feasibility of this platform by training a general\nagent that consistently defeats 12 built-in characters in single-player mode,\nand expose the difficulty of training a non-exploitable agent without human\nknowledge and demonstrations in two-player mode. FightLadder provides\nmeticulously designed environments to address critical challenges in\ncompetitive MARL research, aiming to catalyze a new era of discovery and\nadvancement in the field. Videos and code at\nhttps://sites.google.com/view/fightladder/home.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02081v2",
    "published_date": "2024-06-04 08:04:23 UTC",
    "updated_date": "2024-06-24 03:38:46 UTC"
  },
  {
    "arxiv_id": "2406.02080v1",
    "title": "LongSSM: On the Length Extension of State-space Models in Language Modelling",
    "authors": [
      "Shida Wang"
    ],
    "abstract": "In this paper, we investigate the length-extension of state-space models\n(SSMs) in language modeling. Length extension involves training models on short\nsequences and testing them on longer ones. We show that state-space models\ntrained with zero hidden states initialization have difficulty doing length\nextension. We explain this difficulty by pointing out the length extension is\nequivalent to polynomial extrapolation. Based on the theory, we propose a\nsimple yet effective method - changing the hidden states initialization scheme\n- to improve the length extension. Moreover, our method shows that using long\ntraining sequence length is beneficial but not necessary to length extension.\nChanging the hidden state initialization enables the efficient training of\nlong-memory model with a smaller training context length.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "math.DS"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.02080v1",
    "published_date": "2024-06-04 08:02:39 UTC",
    "updated_date": "2024-06-04 08:02:39 UTC"
  },
  {
    "arxiv_id": "2406.02078v1",
    "title": "A Toolbox for Supporting Research on AI in Water Distribution Networks",
    "authors": [
      "André Artelt",
      "Marios S. Kyriakou",
      "Stelios G. Vrachimis",
      "Demetrios G. Eliades",
      "Barbara Hammer",
      "Marios M. Polycarpou"
    ],
    "abstract": "Drinking water is a vital resource for humanity, and thus, Water Distribution\nNetworks (WDNs) are considered critical infrastructures in modern societies.\nThe operation of WDNs is subject to diverse challenges such as water leakages\nand contamination, cyber/physical attacks, high energy consumption during pump\noperation, etc. With model-based methods reaching their limits due to various\nuncertainty sources, AI methods offer promising solutions to those challenges.\nIn this work, we introduce a Python toolbox for complex scenario modeling \\&\ngeneration such that AI researchers can easily access challenging problems from\nthe drinking water domain. Besides providing a high-level interface for the\neasy generation of hydraulic and water quality scenario data, it also provides\neasy access to popular event detection benchmarks and an environment for\ndeveloping control algorithms.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the Workshop on Artificial Intelligence for Critical\n  Infrastructure (AI4CI 2024) @ IJCAI'24 , Jeju Island, South Korea",
    "pdf_url": "http://arxiv.org/pdf/2406.02078v1",
    "published_date": "2024-06-04 07:58:19 UTC",
    "updated_date": "2024-06-04 07:58:19 UTC"
  },
  {
    "arxiv_id": "2406.02077v3",
    "title": "Multi-target stain normalization for histology slides",
    "authors": [
      "Desislav Ivanov",
      "Carlo Alberto Barbano",
      "Marco Grangetto"
    ],
    "abstract": "Traditional staining normalization approaches, e.g. Macenko, typically rely\non the choice of a single representative reference image, which may not\nadequately account for the diverse staining patterns of datasets collected in\npractical scenarios. In this study, we introduce a novel approach that\nleverages multiple reference images to enhance robustness against stain\nvariation. Our method is parameter-free and can be adopted in existing\ncomputational pathology pipelines with no significant changes. We evaluate the\neffectiveness of our method through experiments using a deep-learning pipeline\nfor automatic nuclei segmentation on colorectal images. Our results show that\nby leveraging multiple reference images, better results can be achieved when\ngeneralizing to external data, where the staining can widely differ from the\ntraining set.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68U10",
      "I.4.0"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02077v3",
    "published_date": "2024-06-04 07:57:34 UTC",
    "updated_date": "2024-06-10 07:49:05 UTC"
  },
  {
    "arxiv_id": "2406.02069v4",
    "title": "PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling",
    "authors": [
      "Zefan Cai",
      "Yichi Zhang",
      "Bofei Gao",
      "Yuliang Liu",
      "Yucheng Li",
      "Tianyu Liu",
      "Keming Lu",
      "Wayne Xiong",
      "Yue Dong",
      "Junjie Hu",
      "Wen Xiao"
    ],
    "abstract": "In this study, we investigate whether attention-based information flow inside\nlarge language models (LLMs) is aggregated through noticeable patterns for long\ncontext processing. Our observations reveal that LLMs aggregate information\nthrough Pyramidal Information Funneling where attention is scattering widely in\nlower layers, progressively consolidating within specific contexts, and\nultimately focusing on critical tokens (a.k.a massive activation or attention\nsink) in higher layers. Motivated by these insights, we developed PyramidKV, a\nnovel and effective KV cache compression method. This approach dynamically\nadjusts the KV cache size across different layers, allocating more cache in\nlower layers and less in higher ones, diverging from traditional methods that\nmaintain a uniform KV cache size. Our experimental evaluations, utilizing the\nLongBench benchmark, show that PyramidKV matches the performance of models with\na full KV cache while retaining only 12% of the KV cache, thus significantly\nreducing memory usage. In scenarios emphasizing memory efficiency, where only\n0.7% of the KV cache is maintained, PyramidKV surpasses other KV cache\ncompression techniques, achieving up to a 20.5 absolute accuracy improvement on\nTREC dataset. In the Needle-in-a-Haystack experiment, PyramidKV outperforms\ncompeting methods in maintaining long-context comprehension in LLMs; notably,\nretaining just 128 KV cache entries enables the LLAMA-3-70B model to achieve\n100.0 Acc. performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02069v4",
    "published_date": "2024-06-04 07:51:30 UTC",
    "updated_date": "2025-05-15 17:18:12 UTC"
  },
  {
    "arxiv_id": "2406.02061v5",
    "title": "Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models",
    "authors": [
      "Marianna Nezhurina",
      "Lucia Cipolina-Kun",
      "Mehdi Cherti",
      "Jenia Jitsev"
    ],
    "abstract": "Large Language Models (LLMs) are often described as instances of foundation\nmodels that possess strong generalization obeying scaling laws, and therefore\ntransfer robustly across various conditions in few- or zero-shot manner. Such\nclaims rely on standardized benchmarks that suppose to measure generalization\nand reasoning, where state-of-the-art (SOTA) models score high. We demonstrate\nhere a dramatic breakdown of generalization and basic reasoning of all SOTA\nmodels claiming strong function, including large scale advanced models like\nGPT-4 or Claude 3 Opus, using a simple, short common sense math problem\nformulated in concise natural language, easily solvable by humans (AIW\nproblem). The breakdown is dramatic as it manifests on a simple problem in both\nlow average performance and strong performance fluctuations on natural\nvariations in problem template that do not change either problem structure or\nits difficulty at all. By testing models on further control problems with\nsimilar form, we rule out that breakdown might be rooted in minor low-level\nissues like natural language or numbers parsing. We also observe strong\noverconfidence in the wrong solutions, expressed in form of plausible sounding\nexplanation-like confabulations. Various standard interventions in an attempt\nto get the right solution, like chain-of-thought prompting, or urging the\nmodels to reconsider the wrong solutions again by multi step re-evaluation,\nfail. We use these observations to stimulate re-assessment of the capabilities\nof current generation of LLMs as claimed by standardized benchmarks. Such\nre-assessment also requires common action to create standardized benchmarks\nthat would allow proper detection of such deficits in generalization and\nreasoning that obviously remain undiscovered by current state-of-the-art\nevaluation procedures, where SOTA LLMs manage to score high. Code:\nhttps://github.com/LAION-AI/AIW",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "v3.0. Control experiments, further AIW problem versions, testing\n  recent reasoning models. Short version appeared at NeurIPS Scientific Methods\n  for Understanding Deep Learning Workshop (SciDL) 2024,\n  https://openreview.net/forum?id=Mkl7dzjYiW",
    "pdf_url": "http://arxiv.org/pdf/2406.02061v5",
    "published_date": "2024-06-04 07:43:33 UTC",
    "updated_date": "2025-03-05 01:58:08 UTC"
  },
  {
    "arxiv_id": "2406.02060v1",
    "title": "I've got the \"Answer\"! Interpretation of LLMs Hidden States in Question Answering",
    "authors": [
      "Valeriya Goloviznina",
      "Evgeny Kotelnikov"
    ],
    "abstract": "Interpretability and explainability of AI are becoming increasingly important\nin light of the rapid development of large language models (LLMs). This paper\ninvestigates the interpretation of LLMs in the context of the knowledge-based\nquestion answering. The main hypothesis of the study is that correct and\nincorrect model behavior can be distinguished at the level of hidden states.\nThe quantized models LLaMA-2-7B-Chat, Mistral-7B, Vicuna-7B and the MuSeRC\nquestion-answering dataset are used to test this hypothesis. The results of the\nanalysis support the proposed hypothesis. We also identify the layers which\nhave a negative effect on the model's behavior. As a prospect of practical\napplication of the hypothesis, we propose to train such \"weak\" layers\nadditionally in order to improve the quality of the task solution.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for NLDB-2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2406.02060v1",
    "published_date": "2024-06-04 07:43:12 UTC",
    "updated_date": "2024-06-04 07:43:12 UTC"
  },
  {
    "arxiv_id": "2406.02057v1",
    "title": "Tabular and Deep Learning for the Whittle Index",
    "authors": [
      "Francisco Robledo Relaño",
      "Vivek Borkar",
      "Urtzi Ayesta",
      "Konstantin Avrachenkov"
    ],
    "abstract": "The Whittle index policy is a heuristic that has shown remarkably good\nperformance (with guaranteed asymptotic optimality) when applied to the class\nof problems known as Restless Multi-Armed Bandit Problems (RMABPs). In this\npaper we present QWI and QWINN, two reinforcement learning algorithms,\nrespectively tabular and deep, to learn the Whittle index for the total\ndiscounted criterion. The key feature is the use of two time-scales, a faster\none to update the state-action Q -values, and a relatively slower one to update\nthe Whittle indices. In our main theoretical result we show that QWI, which is\na tabular implementation, converges to the real Whittle indices. We then\npresent QWINN, an adaptation of QWI algorithm using neural networks to compute\nthe Q -values on the faster time-scale, which is able to extrapolate\ninformation from one state to another and scales naturally to large state-space\nenvironments. For QWINN, we show that all local minima of the Bellman error are\nlocally stable equilibria, which is the first result of its kind for DQN-based\nschemes. Numerical computations show that QWI and QWINN converge faster than\nthe standard Q -learning algorithm, neural-network based approximate Q-learning\nand other state of the art algorithms.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "ACM Transactions on Modeling and Performance Evaluation of Computing\n  Systems, 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02057v1",
    "published_date": "2024-06-04 07:41:15 UTC",
    "updated_date": "2024-06-04 07:41:15 UTC"
  },
  {
    "arxiv_id": "2406.02040v2",
    "title": "DFA-GNN: Forward Learning of Graph Neural Networks by Direct Feedback Alignment",
    "authors": [
      "Gongpei Zhao",
      "Tao Wang",
      "Congyan Lang",
      "Yi Jin",
      "Yidong Li",
      "Haibin Ling"
    ],
    "abstract": "Graph neural networks are recognized for their strong performance across\nvarious applications, with the backpropagation algorithm playing a central role\nin the development of most GNN models. However, despite its effectiveness, BP\nhas limitations that challenge its biological plausibility and affect the\nefficiency, scalability and parallelism of training neural networks for\ngraph-based tasks. While several non-BP training algorithms, such as the direct\nfeedback alignment, have been successfully applied to fully-connected and\nconvolutional network components for handling Euclidean data, directly adapting\nthese non-BP frameworks to manage non-Euclidean graph data in GNN models\npresents significant challenges. These challenges primarily arise from the\nviolation of the i.i.d. assumption in graph data and the difficulty in\naccessing prediction errors for all samples (nodes) within the graph. To\novercome these obstacles, in this paper we propose DFA-GNN, a novel forward\nlearning framework tailored for GNNs with a case study of semi-supervised\nlearning. The proposed method breaks the limitations of BP by using a dedicated\nforward training mechanism. Specifically, DFA-GNN extends the principles of DFA\nto adapt to graph data and unique architecture of GNNs, which incorporates the\ninformation of graph topology into the feedback links to accommodate the\nnon-Euclidean characteristics of graph data. Additionally, for semi-supervised\ngraph learning tasks, we developed a pseudo error generator that spreads\nresidual errors from training data to create a pseudo error for each unlabeled\nnode. These pseudo errors are then utilized to train GNNs using DFA. Extensive\nexperiments on 10 public benchmarks reveal that our learning framework\noutperforms not only previous non-BP methods but also the standard BP methods,\nand it exhibits excellent robustness against various types of noise and\nattacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02040v2",
    "published_date": "2024-06-04 07:24:51 UTC",
    "updated_date": "2024-11-05 14:00:37 UTC"
  },
  {
    "arxiv_id": "2406.02035v1",
    "title": "A Unifying Framework for Action-Conditional Self-Predictive Reinforcement Learning",
    "authors": [
      "Khimya Khetarpal",
      "Zhaohan Daniel Guo",
      "Bernardo Avila Pires",
      "Yunhao Tang",
      "Clare Lyle",
      "Mark Rowland",
      "Nicolas Heess",
      "Diana Borsa",
      "Arthur Guez",
      "Will Dabney"
    ],
    "abstract": "Learning a good representation is a crucial challenge for Reinforcement\nLearning (RL) agents. Self-predictive learning provides means to jointly learn\na latent representation and dynamics model by bootstrapping from future latent\nrepresentations (BYOL). Recent work has developed theoretical insights into\nthese algorithms by studying a continuous-time ODE model for self-predictive\nrepresentation learning under the simplifying assumption that the algorithm\ndepends on a fixed policy (BYOL-$\\Pi$); this assumption is at odds with\npractical instantiations of such algorithms, which explicitly condition their\npredictions on future actions. In this work, we take a step towards bridging\nthe gap between theory and practice by analyzing an action-conditional\nself-predictive objective (BYOL-AC) using the ODE framework, characterizing its\nconvergence properties and highlighting important distinctions between the\nlimiting solutions of the BYOL-$\\Pi$ and BYOL-AC dynamics. We show how the two\nrepresentations are related by a variance equation. This connection leads to a\nnovel variance-like action-conditional objective (BYOL-VAR) and its\ncorresponding ODE. We unify the study of all three objectives through two\ncomplementary lenses; a model-based perspective, where each objective is shown\nto be equivalent to a low-rank approximation of certain dynamics, and a\nmodel-free perspective, which establishes relationships between the objectives\nand their respective value, Q-value, and advantage function. Our empirical\ninvestigations, encompassing both linear function approximation and Deep RL\nenvironments, demonstrates that BYOL-AC is better overall in a variety of\ndifferent settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02035v1",
    "published_date": "2024-06-04 07:22:12 UTC",
    "updated_date": "2024-06-04 07:22:12 UTC"
  },
  {
    "arxiv_id": "2406.02030v2",
    "title": "Multimodal Reasoning with Multimodal Knowledge Graph",
    "authors": [
      "Junlin Lee",
      "Yequan Wang",
      "Jing Li",
      "Min Zhang"
    ],
    "abstract": "Multimodal reasoning with large language models (LLMs) often suffers from\nhallucinations and the presence of deficient or outdated knowledge within LLMs.\nSome approaches have sought to mitigate these issues by employing textual\nknowledge graphs, but their singular modality of knowledge limits comprehensive\ncross-modal understanding. In this paper, we propose the Multimodal Reasoning\nwith Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal\nknowledge graphs (MMKGs) to learn rich and semantic knowledge across\nmodalities, significantly enhancing the multimodal reasoning capabilities of\nLLMs. In particular, a relation graph attention network is utilized for\nencoding MMKGs and a cross-modal alignment module is designed for optimizing\nimage-text alignment. A MMKG-grounded dataset is constructed to equip LLMs with\ninitial expertise in multimodal reasoning through pretraining. Remarkably,\nMR-MKG achieves superior performance while training on only a small fraction of\nparameters, approximately 2.25% of the LLM's parameter size. Experimental\nresults on multimodal question answering and multimodal analogy reasoning tasks\ndemonstrate that our MR-MKG method outperforms previous state-of-the-art\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL 2024 (Main Conference)",
    "pdf_url": "http://arxiv.org/pdf/2406.02030v2",
    "published_date": "2024-06-04 07:13:23 UTC",
    "updated_date": "2024-06-05 03:28:01 UTC"
  },
  {
    "arxiv_id": "2406.02027v2",
    "title": "Inference Attacks: A Taxonomy, Survey, and Promising Directions",
    "authors": [
      "Feng Wu",
      "Lei Cui",
      "Shaowen Yao",
      "Shui Yu"
    ],
    "abstract": "The prosperity of machine learning has also brought people's concerns about\ndata privacy. Among them, inference attacks can implement privacy breaches in\nvarious MLaaS scenarios and model training/prediction phases. Specifically,\ninference attacks can perform privacy inference on undisclosed target training\nsets based on outputs of the target model, including but not limited to\nstatistics, membership, semantics, data representation, etc. For instance,\ninfer whether the target data has the characteristics of AIDS. In addition, the\nrapid development of the machine learning community in recent years, especially\nthe surge of model types and application scenarios, has further stimulated the\ninference attacks' research. Thus, studying inference attacks and analyzing\nthem in depth is urgent and significant. However, there is still a gap in the\nsystematic discussion of inference attacks from taxonomy, global perspective,\nattack, and defense perspectives. This survey provides an in-depth and\ncomprehensive inference of attacks and corresponding countermeasures in\nML-as-a-service based on taxonomy and the latest researches. Without\ncompromising researchers' intuition, we first propose the 3MP taxonomy based on\nthe community research status, trying to normalize the confusing naming system\nof inference attacks. Also, we analyze the pros and cons of each type of\ninference attack, their workflow, countermeasure, and how they interact with\nother attacks. In the end, we point out several promising directions for\nresearchers from a more comprehensive and novel perspective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02027v2",
    "published_date": "2024-06-04 07:06:06 UTC",
    "updated_date": "2024-06-27 05:47:55 UTC"
  },
  {
    "arxiv_id": "2406.02021v2",
    "title": "FFNet: MetaMixer-based Efficient Convolutional Mixer Design",
    "authors": [
      "Seokju Yun",
      "Dongheon Lee",
      "Youngmin Ro"
    ],
    "abstract": "Transformer, composed of self-attention and Feed-Forward Network, has\nrevolutionized the landscape of network design across various vision tasks.\nWhile self-attention is extensively explored as a key factor in performance,\nFFN has received little attention. FFN is a versatile operator seamlessly\nintegrated into nearly all AI models to effectively harness rich\nrepresentations. Recent works also show that FFN functions like key-value\nmemories. Thus, akin to the query-key-value mechanism within self-attention,\nFFN can be viewed as a memory network, where the input serves as query and the\ntwo projection weights operate as keys and values, respectively. Based on these\nobservations, we hypothesize that the importance lies in query-key-value\nframework itself for competitive performance. To verify this, we propose\nconverting self-attention into a more FFN-like efficient token mixer with only\nconvolutions while retaining query-key-value framework, namely FFNification.\nSpecifically, FFNification replaces query-key-value interactions with large\nkernel convolutions and adopts GELU activation function instead of softmax. The\nderived token mixer, FFNified attention, serves as key-value memories for\ndetecting locally distributed spatial patterns, and operates in the opposite\ndimension to the ConvNeXt block within each corresponding sub-operation of the\nquery-key-value framework. Building upon the above two modules, we present a\nfamily of Fast-Forward Networks (FFNet). Despite being composed of only simple\noperators, FFNet outperforms sophisticated and highly specialized methods in\neach domain, with notable efficiency gains. These results validate our\nhypothesis, leading us to propose MetaMixer, a general mixer architecture that\ndoes not specify sub-operations within the query-key-value framework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code: https://github.com/ysj9909/FFNet",
    "pdf_url": "http://arxiv.org/pdf/2406.02021v2",
    "published_date": "2024-06-04 07:00:14 UTC",
    "updated_date": "2025-03-10 05:09:16 UTC"
  },
  {
    "arxiv_id": "2406.02018v2",
    "title": "Why Would You Suggest That? Human Trust in Language Model Responses",
    "authors": [
      "Manasi Sharma",
      "Ho Chit Siu",
      "Rohan Paleja",
      "Jaime D. Peña"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has revealed a growing need for\nhuman-AI collaboration, especially in creative decision-making scenarios where\ntrust and reliance are paramount. Through human studies and model evaluations\non the open-ended News Headline Generation task from the LaMP benchmark, we\nanalyze how the framing and presence of explanations affect user trust and\nmodel performance. Overall, we provide evidence that adding an explanation in\nthe model response to justify its reasoning significantly increases\nself-reported user trust in the model when the user has the opportunity to\ncompare various responses. Position and faithfulness of these explanations are\nalso important factors. However, these gains disappear when users are shown\nresponses independently, suggesting that humans trust all model responses,\nincluding deceptive ones, equitably when they are shown in isolation. Our\nfindings urge future research to delve deeper into the nuanced evaluation of\ntrust in human-machine teaming systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02018v2",
    "published_date": "2024-06-04 06:57:47 UTC",
    "updated_date": "2024-10-04 16:46:00 UTC"
  },
  {
    "arxiv_id": "2407.11985v1",
    "title": "A Novel Implementation of Marksheet Parser Using PaddleOCR",
    "authors": [
      "Sankalp Bagaria",
      "S Irene",
      "Harikrishnan",
      "Elakia V M"
    ],
    "abstract": "When an applicant files an online application, there is usually a requirement\nto fill the marks in the online form and also upload the marksheet in the\nportal for the verification. A system was built for reading the uploaded\nmarksheet using OCR and automatically filling the rows/ columns in the online\nform. Though there are partial solutions to this problem - implemented using\nPyTesseract - the accuracy is low. Hence, the PaddleOCR was used to build the\nmarksheet parser. Several pre-processing and post-processing steps were also\nperformed. The system was tested and evaluated for seven states. Further work\nis being done and the system is being evaluated for more states and boards of\nIndia.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2407.11985v1",
    "published_date": "2024-06-04 06:51:03 UTC",
    "updated_date": "2024-06-04 06:51:03 UTC"
  },
  {
    "arxiv_id": "2406.02006v1",
    "title": "ODE-based Learning to Optimize",
    "authors": [
      "Zhonglin Xie",
      "Wotao Yin",
      "Zaiwen Wen"
    ],
    "abstract": "Recent years have seen a growing interest in understanding acceleration\nmethods through the lens of ordinary differential equations (ODEs). Despite the\ntheoretical advancements, translating the rapid convergence observed in\ncontinuous-time models to discrete-time iterative methods poses significant\nchallenges. In this paper, we present a comprehensive framework integrating the\ninertial systems with Hessian-driven damping equation (ISHD) and learning-based\napproaches for developing optimization methods through a deep synergy of\ntheoretical insights. We first establish the convergence condition for ensuring\nthe convergence of the solution trajectory of ISHD. Then, we show that provided\nthe stability condition, another relaxed requirement on the coefficients of\nISHD, the sequence generated through the explicit Euler discretization of ISHD\nconverges, which gives a large family of practical optimization methods. In\norder to select the best optimization method in this family for certain\nproblems, we introduce the stopping time, the time required for an optimization\nmethod derived from ISHD to achieve a predefined level of suboptimality. Then,\nwe formulate a novel learning to optimize (L2O) problem aimed at minimizing the\nstopping time subject to the convergence and stability condition. To navigate\nthis learning problem, we present an algorithm combining stochastic\noptimization and the penalty method (StoPM). The convergence of StoPM using the\nconservative gradient is proved. Empirical validation of our framework is\nconducted through extensive numerical experiments across a diverse set of\noptimization problems. These experiments showcase the superior performance of\nthe learned optimization methods.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "55 pages, 28 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.02006v1",
    "published_date": "2024-06-04 06:39:45 UTC",
    "updated_date": "2024-06-04 06:39:45 UTC"
  },
  {
    "arxiv_id": "2406.02002v1",
    "title": "Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue",
    "authors": [
      "Shixuan Fan",
      "Wei Wei",
      "Wendi Li",
      "Xian-Ling Mao",
      "Wenfeng Xie",
      "Dangyang Chen"
    ],
    "abstract": "The core of the dialogue system is to generate relevant, informative, and\nhuman-like responses based on extensive dialogue history. Recently, dialogue\ngeneration domain has seen mainstream adoption of large language models (LLMs),\ndue to its powerful capability in generating utterances. However, there is a\nnatural deficiency for such models, that is, inherent position bias, which may\nlead them to pay more attention to the nearby utterances instead of causally\nrelevant ones, resulting in generating irrelevant and generic responses in\nlong-term dialogue. To alleviate such problem, in this paper, we propose a\nnovel method, named Causal Perception long-term Dialogue framework (CPD), which\nemploys perturbation-based causal variable discovery method to extract casually\nrelevant utterances from the dialogue history and enhances model causal\nperception during fine-tuning. Specifically, a local-position awareness method\nis proposed in CPD for inter-sentence position correlation elimination, which\nhelps models extract causally relevant utterances based on perturbations. Then,\na casual-perception fine-tuning strategy is also proposed, to enhance the\ncapability of discovering the causal invariant factors, by differently\nperturbing causally relevant and non-casually relevant ones for response\ngeneration. Experimental results on two datasets prove that our proposed method\ncan effectively alleviate the position bias for multiple LLMs and achieve\nsignificant progress compared with existing baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.02002v1",
    "published_date": "2024-06-04 06:33:13 UTC",
    "updated_date": "2024-06-04 06:33:13 UTC"
  },
  {
    "arxiv_id": "2406.02636v1",
    "title": "Strengthening Network Intrusion Detection in IoT Environments with Self-Supervised Learning and Few Shot Learning",
    "authors": [
      "Safa Ben Atitallah",
      "Maha Driss",
      "Wadii Boulila",
      "Anis Koubaa"
    ],
    "abstract": "The Internet of Things (IoT) has been introduced as a breakthrough technology\nthat integrates intelligence into everyday objects, enabling high levels of\nconnectivity between them. As the IoT networks grow and expand, they become\nmore susceptible to cybersecurity attacks. A significant challenge in current\nintrusion detection systems for IoT includes handling imbalanced datasets where\nlabeled data are scarce, particularly for new and rare types of cyber attacks.\nExisting literature often fails to detect such underrepresented attack classes.\nThis paper introduces a novel intrusion detection approach designed to address\nthese challenges. By integrating Self Supervised Learning (SSL), Few Shot\nLearning (FSL), and Random Forest (RF), our approach excels in learning from\nlimited and imbalanced data and enhancing detection capabilities. The approach\nstarts with a Deep Infomax model trained to extract key features from the\ndataset. These features are then fed into a prototypical network to generate\ndiscriminate embedding. Subsequently, an RF classifier is employed to detect\nand classify potential malware, including a range of attacks that are\nfrequently observed in IoT networks. The proposed approach was evaluated\nthrough two different datasets, MaleVis and WSN-DS, which demonstrate its\nsuperior performance with accuracies of 98.60% and 99.56%, precisions of 98.79%\nand 99.56%, recalls of 98.60% and 99.56%, and F1-scores of 98.63% and 99.56%,\nrespectively.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02636v1",
    "published_date": "2024-06-04 06:30:22 UTC",
    "updated_date": "2024-06-04 06:30:22 UTC"
  },
  {
    "arxiv_id": "2406.01996v1",
    "title": "Bayesian Mesh Optimization for Graph Neural Networks to Enhance Engineering Performance Prediction",
    "authors": [
      "Jangseop Park",
      "Namwoo Kang"
    ],
    "abstract": "In engineering design, surrogate models are widely employed to replace\ncomputationally expensive simulations by leveraging design variables and\ngeometric parameters from computer-aided design (CAD) models. However, these\nmodels often lose critical information when simplified to lower dimensions and\nface challenges in parameter definition, especially with the complex 3D shapes\ncommonly found in industrial datasets. To address these limitations, we propose\na Bayesian graph neural network (GNN) framework for a 3D deep-learning-based\nsurrogate model that predicts engineering performance by directly learning\ngeometric features from CAD using mesh representation. Our framework determines\nthe optimal size of mesh elements through Bayesian optimization, resulting in a\nhigh-accuracy surrogate model. Additionally, it effectively handles the\nirregular and complex structures of 3D CADs, which differ significantly from\nthe regular and uniform pixel structures of 2D images typically used in deep\nlearning. Experimental results demonstrate that the quality of the mesh\nsignificantly impacts the prediction accuracy of the surrogate model, with an\noptimally sized mesh achieving superior performance. We compare the performance\nof models based on various 3D representations such as voxel, point cloud, and\ngraph, and evaluate the computational costs of Monte Carlo simulation and\nBayesian optimization methods to find the optimal mesh size. We anticipate that\nour proposed framework has the potential to be applied to mesh-based\nsimulations across various engineering fields, leveraging physics-based\ninformation commonly used in computer-aided engineering.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.GR"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.01996v1",
    "published_date": "2024-06-04 06:27:48 UTC",
    "updated_date": "2024-06-04 06:27:48 UTC"
  },
  {
    "arxiv_id": "2406.01988v1",
    "title": "Personalized Topic Selection Model for Topic-Grounded Dialogue",
    "authors": [
      "Shixuan Fan",
      "Wei Wei",
      "Xiaofei Wen",
      "Xianling Mao",
      "Jixiong Chen",
      "Dangyang Chen"
    ],
    "abstract": "Recently, the topic-grounded dialogue (TGD) system has become increasingly\npopular as its powerful capability to actively guide users to accomplish\nspecific tasks through topic-guided conversations. Most existing works utilize\nside information (\\eg topics or personas) in isolation to enhance the topic\nselection ability. However, due to disregarding the noise within these\nauxiliary information sources and their mutual influence, current models tend\nto predict user-uninteresting and contextually irrelevant topics. To build\nuser-engaging and coherent dialogue agent, we propose a \\textbf{P}ersonalized\ntopic s\\textbf{E}lection model for \\textbf{T}opic-grounded \\textbf{D}ialogue,\nnamed \\textbf{PETD}, which takes account of the interaction of side information\nto selectively aggregate such information for more accurately predicting\nsubsequent topics. Specifically, we evaluate the correlation between global\ntopics and personas and selectively incorporate the global topics aligned with\nuser personas. Furthermore, we propose a contrastive learning based persona\nselector to filter out irrelevant personas under the constraint of lacking\npertinent persona annotations. Throughout the selection and generation, diverse\nrelevant side information is considered. Extensive experiments demonstrate that\nour proposed method can generate engaging and diverse responses, outperforming\nstate-of-the-art baselines across various evaluation metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.01988v1",
    "published_date": "2024-06-04 06:09:49 UTC",
    "updated_date": "2024-06-04 06:09:49 UTC"
  },
  {
    "arxiv_id": "2406.01981v2",
    "title": "Zyda: A 1.3T Dataset for Open Language Modeling",
    "authors": [
      "Yury Tokpanov",
      "Beren Millidge",
      "Paolo Glorioso",
      "Jonathan Pilault",
      "Adam Ibrahim",
      "James Whittington",
      "Quentin Anthony"
    ],
    "abstract": "The size of large language models (LLMs) has scaled dramatically in recent\nyears and their computational and data requirements have surged\ncorrespondingly. State-of-the-art language models, even at relatively smaller\nsizes, typically require training on at least a trillion tokens. This rapid\nadvancement has eclipsed the growth of open-source datasets available for\nlarge-scale LLM pretraining. In this paper, we introduce Zyda (Zyphra Dataset),\na dataset under a permissive license comprising 1.3 trillion tokens, assembled\nby integrating several major respected open-source datasets into a single,\nhigh-quality corpus. We apply rigorous filtering and deduplication processes,\nboth within and across datasets, to maintain and enhance the quality derived\nfrom the original datasets. Our evaluations show that Zyda not only competes\nfavorably with other open datasets like Dolma, FineWeb, and RefinedWeb, but\nalso substantially improves the performance of comparable models from the\nPythia suite. Our rigorous data processing methods significantly enhance Zyda's\neffectiveness, outperforming even the best of its constituent datasets when\nused independently.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01981v2",
    "published_date": "2024-06-04 05:47:17 UTC",
    "updated_date": "2024-09-03 19:11:11 UTC"
  },
  {
    "arxiv_id": "2406.02635v2",
    "title": "Evidentially Calibrated Source-Free Time-Series Domain Adaptation with Temporal Imputation",
    "authors": [
      "Mohamed Ragab",
      "Peiliang Gong",
      "Emadeldeen Eldele",
      "Wenyu Zhang",
      "Min Wu",
      "Chuan-Sheng Foo",
      "Daoqiang Zhang",
      "Xiaoli Li",
      "Zhenghua Chen"
    ],
    "abstract": "Source-free domain adaptation (SFDA) aims to adapt a model pre-trained on a\nlabeled source domain to an unlabeled target domain without access to source\ndata, preserving the source domain's privacy. While SFDA is prevalent in\ncomputer vision, it remains largely unexplored in time series analysis.\nExisting SFDA methods, designed for visual data, struggle to capture the\ninherent temporal dynamics of time series, hindering adaptation performance.\nThis paper proposes MAsk And imPUte (MAPU), a novel and effective approach for\ntime series SFDA. MAPU addresses the critical challenge of temporal consistency\nby introducing a novel temporal imputation task. This task involves randomly\nmasking time series signals and leveraging a dedicated temporal imputer to\nrecover the original signal within the learned embedding space, bypassing the\ncomplexities of noisy raw data. Notably, MAPU is the first method to explicitly\naddress temporal consistency in the context of time series SFDA. Additionally,\nit offers seamless integration with existing SFDA methods, providing greater\nflexibility. We further introduce E-MAPU, which incorporates evidential\nuncertainty estimation to address the overconfidence issue inherent in softmax\npredictions. To achieve that, we leverage evidential deep learning to obtain a\nbetter-calibrated pre-trained model and adapt the target encoder to map\nout-of-support target samples to a new feature representation closer to the\nsource domain's support. This fosters better alignment, ultimately enhancing\nadaptation performance. Extensive experiments on five real-world time series\ndatasets demonstrate that both MAPU and E-MAPU achieve significant performance\ngains compared to existing methods. These results highlight the effectiveness\nof our proposed approaches for tackling various time series domain adaptation\nproblems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02635v2",
    "published_date": "2024-06-04 05:36:29 UTC",
    "updated_date": "2024-06-13 03:08:23 UTC"
  },
  {
    "arxiv_id": "2406.01970v1",
    "title": "The Crystal Ball Hypothesis in diffusion models: Anticipating object positions from initial noise",
    "authors": [
      "Yuanhao Ban",
      "Ruochen Wang",
      "Tianyi Zhou",
      "Boqing Gong",
      "Cho-Jui Hsieh",
      "Minhao Cheng"
    ],
    "abstract": "Diffusion models have achieved remarkable success in text-to-image generation\ntasks; however, the role of initial noise has been rarely explored. In this\nstudy, we identify specific regions within the initial noise image, termed\ntrigger patches, that play a key role for object generation in the resulting\nimages. Notably, these patches are ``universal'' and can be generalized across\nvarious positions, seeds, and prompts. To be specific, extracting these patches\nfrom one noise and injecting them into another noise leads to object generation\nin targeted areas. We identify these patches by analyzing the dispersion of\nobject bounding boxes across generated images, leading to the development of a\nposterior analysis technique. Furthermore, we create a dataset consisting of\nGaussian noises labeled with bounding boxes corresponding to the objects\nappearing in the generated images and train a detector that identifies these\npatches from the initial noise. To explain the formation of these patches, we\nreveal that they are outliers in Gaussian noise, and follow distinct\ndistributions through two-sample tests. Finally, we find the misalignment\nbetween prompts and the trigger patch patterns can result in unsuccessful image\ngenerations. The study proposes a reject-sampling strategy to obtain optimal\nnoise, aiming to improve prompt adherence and positional diversity in image\ngeneration.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01970v1",
    "published_date": "2024-06-04 05:06:00 UTC",
    "updated_date": "2024-06-04 05:06:00 UTC"
  },
  {
    "arxiv_id": "2406.01968v1",
    "title": "Cross-Embodiment Robot Manipulation Skill Transfer using Latent Space Alignment",
    "authors": [
      "Tianyu Wang",
      "Dwait Bhatt",
      "Xiaolong Wang",
      "Nikolay Atanasov"
    ],
    "abstract": "This paper focuses on transferring control policies between robot\nmanipulators with different morphology. While reinforcement learning (RL)\nmethods have shown successful results in robot manipulation tasks, transferring\na trained policy from simulation to a real robot or deploying it on a robot\nwith different states, actions, or kinematics is challenging. To achieve\ncross-embodiment policy transfer, our key insight is to project the state and\naction spaces of the source and target robots to a common latent space\nrepresentation. We first introduce encoders and decoders to associate the\nstates and actions of the source robot with a latent space. The encoders,\ndecoders, and a latent space control policy are trained simultaneously using\nloss functions measuring task performance, latent dynamics consistency, and\nencoder-decoder ability to reconstruct the original states and actions. To\ntransfer the learned control policy, we only need to train target encoders and\ndecoders that align a new target domain to the latent space. We use generative\nadversarial training with cycle consistency and latent dynamics losses without\naccess to the task reward or reward tuning in the target domain. We demonstrate\nsim-to-sim and sim-to-real manipulation policy transfer with source and target\nrobots of different states, actions, and embodiments. The source code is\navailable at\n\\url{https://github.com/ExistentialRobotics/cross_embodiment_transfer}.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01968v1",
    "published_date": "2024-06-04 05:00:24 UTC",
    "updated_date": "2024-06-04 05:00:24 UTC"
  },
  {
    "arxiv_id": "2406.01967v1",
    "title": "DrEureka: Language Model Guided Sim-To-Real Transfer",
    "authors": [
      "Yecheng Jason Ma",
      "William Liang",
      "Hung-Ju Wang",
      "Sam Wang",
      "Yuke Zhu",
      "Linxi Fan",
      "Osbert Bastani",
      "Dinesh Jayaraman"
    ],
    "abstract": "Transferring policies learned in simulation to the real world is a promising\nstrategy for acquiring robot skills at scale. However, sim-to-real approaches\ntypically rely on manual design and tuning of the task reward function as well\nas the simulation physics parameters, rendering the process slow and\nhuman-labor intensive. In this paper, we investigate using Large Language\nModels (LLMs) to automate and accelerate sim-to-real design. Our LLM-guided\nsim-to-real approach, DrEureka, requires only the physics simulation for the\ntarget task and automatically constructs suitable reward functions and domain\nrandomization distributions to support real-world transfer. We first\ndemonstrate that our approach can discover sim-to-real configurations that are\ncompetitive with existing human-designed ones on quadruped locomotion and\ndexterous manipulation tasks. Then, we showcase that our approach is capable of\nsolving novel robot tasks, such as quadruped balancing and walking atop a yoga\nball, without iterative manual design.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Robotics: Science and Systems (RSS) 2024. Project website and\n  open-source code: https://eureka-research.github.io/dr-eureka/",
    "pdf_url": "http://arxiv.org/pdf/2406.01967v1",
    "published_date": "2024-06-04 04:53:05 UTC",
    "updated_date": "2024-06-04 04:53:05 UTC"
  },
  {
    "arxiv_id": "2406.03404v1",
    "title": "ST-DPGAN: A Privacy-preserving Framework for Spatiotemporal Data Generation",
    "authors": [
      "Wei Shao",
      "Rongyi Zhu",
      "Cai Yang",
      "Chandra Thapa",
      "Muhammad Ejaz Ahmed",
      "Seyit Camtepe",
      "Rui Zhang",
      "DuYong Kim",
      "Hamid Menouar",
      "Flora D. Salim"
    ],
    "abstract": "Spatiotemporal data is prevalent in a wide range of edge devices, such as\nthose used in personal communication and financial transactions. Recent\nadvancements have sparked a growing interest in integrating spatiotemporal\nanalysis with large-scale language models. However, spatiotemporal data often\ncontains sensitive information, making it unsuitable for open third-party\naccess. To address this challenge, we propose a Graph-GAN-based model for\ngenerating privacy-protected spatiotemporal data. Our approach incorporates\nspatial and temporal attention blocks in the discriminator and a spatiotemporal\ndeconvolution structure in the generator. These enhancements enable efficient\ntraining under Gaussian noise to achieve differential privacy. Extensive\nexperiments conducted on three real-world spatiotemporal datasets validate the\nefficacy of our model. Our method provides a privacy guarantee while\nmaintaining the data utility. The prediction model trained on our generated\ndata maintains a competitive performance compared to the model trained on the\noriginal data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.03404v1",
    "published_date": "2024-06-04 04:43:54 UTC",
    "updated_date": "2024-06-04 04:43:54 UTC"
  },
  {
    "arxiv_id": "2406.01960v1",
    "title": "Certifiably Byzantine-Robust Federated Conformal Prediction",
    "authors": [
      "Mintong Kang",
      "Zhen Lin",
      "Jimeng Sun",
      "Cao Xiao",
      "Bo Li"
    ],
    "abstract": "Conformal prediction has shown impressive capacity in constructing\nstatistically rigorous prediction sets for machine learning models with\nexchangeable data samples. The siloed datasets, coupled with the escalating\nprivacy concerns related to local data sharing, have inspired recent\ninnovations extending conformal prediction into federated environments with\ndistributed data samples. However, this framework for distributed uncertainty\nquantification is susceptible to Byzantine failures. A minor subset of\nmalicious clients can significantly compromise the practicality of coverage\nguarantees. To address this vulnerability, we introduce a novel framework\nRob-FCP, which executes robust federated conformal prediction, effectively\ncountering malicious clients capable of reporting arbitrary statistics with the\nconformal calibration process. We theoretically provide the conformal coverage\nbound of Rob-FCP in the Byzantine setting and show that the coverage of Rob-FCP\nis asymptotically close to the desired coverage level. We also propose a\nmalicious client number estimator to tackle a more challenging setting where\nthe number of malicious clients is unknown to the defender and theoretically\nshows its effectiveness. We empirically demonstrate the robustness of Rob-FCP\nagainst diverse proportions of malicious clients under a variety of Byzantine\nattacks on five standard benchmark and real-world healthcare datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01960v1",
    "published_date": "2024-06-04 04:43:30 UTC",
    "updated_date": "2024-06-04 04:43:30 UTC"
  },
  {
    "arxiv_id": "2406.06576v4",
    "title": "OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step",
    "authors": [
      "Owen Dugan",
      "Donato Manuel Jimenez Beneto",
      "Charlotte Loh",
      "Zhuo Chen",
      "Rumen Dangovski",
      "Marin Soljačić"
    ],
    "abstract": "Despite significant advancements in text generation and reasoning, Large\nLanguage Models (LLMs) still face challenges in accurately performing complex\narithmetic operations. Language model systems often enable LLMs to generate\ncode for arithmetic operations to achieve accurate calculations. However, this\napproach compromises speed and security, and fine-tuning risks the language\nmodel losing prior capabilities. We propose a framework that enables exact\narithmetic in a single autoregressive step, providing faster, more secure, and\nmore interpretable LLM systems with arithmetic capabilities. We use the hidden\nstates of a LLM to control a symbolic architecture that performs arithmetic.\nOur implementation using Llama 3 with OccamNet as a symbolic model (OccamLlama)\nachieves 100\\% accuracy on single arithmetic operations\n($+,-,\\times,\\div,\\sin{},\\cos{},\\log{},\\exp{},\\sqrt{}$), outperforming GPT 4o\nwith and without a code interpreter. Furthermore, OccamLlama outperforms GPT 4o\nwith and without a code interpreter on average across a range of mathematical\nproblem solving benchmarks, demonstrating that OccamLLMs can excel in\narithmetic tasks, even surpassing much larger models. We will make our code\npublic shortly.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06576v4",
    "published_date": "2024-06-04 04:17:40 UTC",
    "updated_date": "2024-09-03 02:11:01 UTC"
  },
  {
    "arxiv_id": "2406.01952v1",
    "title": "Improving Generalization in Aerial and Terrestrial Mobile Robots Control Through Delayed Policy Learning",
    "authors": [
      "Ricardo B. Grando",
      "Raul Steinmetz",
      "Victor A. Kich",
      "Alisson H. Kolling",
      "Pablo M. Furik",
      "Junior C. de Jesus",
      "Bruna V. Guterres",
      "Daniel T. Gamarra",
      "Rodrigo S. Guerra",
      "Paulo L. J. Drews-Jr"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) has emerged as a promising approach to\nenhancing motion control and decision-making through a wide range of robotic\napplications. While prior research has demonstrated the efficacy of DRL\nalgorithms in facilitating autonomous mapless navigation for aerial and\nterrestrial mobile robots, these methods often grapple with poor generalization\nwhen faced with unknown tasks and environments. This paper explores the impact\nof the Delayed Policy Updates (DPU) technique on fostering generalization to\nnew situations, and bolstering the overall performance of agents. Our analysis\nof DPU in aerial and terrestrial mobile robots reveals that this technique\nsignificantly curtails the lack of generalization and accelerates the learning\nprocess for agents, enhancing their efficiency across diverse tasks and unknown\nscenarios.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "IEEE 20th International Conference on Automation Science and\n  Engineering (CASE)",
    "pdf_url": "http://arxiv.org/pdf/2406.01952v1",
    "published_date": "2024-06-04 04:16:38 UTC",
    "updated_date": "2024-06-04 04:16:38 UTC"
  },
  {
    "arxiv_id": "2406.02633v1",
    "title": "Edit Distance Robust Watermarks for Language Models",
    "authors": [
      "Noah Golowich",
      "Ankur Moitra"
    ],
    "abstract": "Motivated by the problem of detecting AI-generated text, we consider the\nproblem of watermarking the output of language models with provable guarantees.\nWe aim for watermarks which satisfy: (a) undetectability, a cryptographic\nnotion introduced by Christ, Gunn & Zamir (2024) which stipulates that it is\ncomputationally hard to distinguish watermarked language model outputs from the\nmodel's actual output distribution; and (b) robustness to channels which\nintroduce a constant fraction of adversarial insertions, substitutions, and\ndeletions to the watermarked text. Earlier schemes could only handle stochastic\nsubstitutions and deletions, and thus we are aiming for a more natural and\nappealing robustness guarantee that holds with respect to edit distance.\n  Our main result is a watermarking scheme which achieves both undetectability\nand robustness to edits when the alphabet size for the language model is\nallowed to grow as a polynomial in the security parameter. To derive such a\nscheme, we follow an approach introduced by Christ & Gunn (2024), which\nproceeds via first constructing pseudorandom codes satisfying undetectability\nand robustness properties analogous to those above; our key idea is to handle\nadversarial insertions and deletions by interpreting the symbols as indices\ninto the codeword, which we call indexing pseudorandom codes. Additionally, our\ncodes rely on weaker computational assumptions than used in previous work. Then\nwe show that there is a generic transformation from such codes over large\nalphabets to watermarking schemes for arbitrary language models.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02633v1",
    "published_date": "2024-06-04 04:03:17 UTC",
    "updated_date": "2024-06-04 04:03:17 UTC"
  },
  {
    "arxiv_id": "2406.01950v1",
    "title": "A Comparative Study of Sampling Methods with Cross-Validation in the FedHome Framework",
    "authors": [
      "Arash Ahmadi",
      "Sarah S. Sharif",
      "Yaser M. Banad"
    ],
    "abstract": "This paper presents a comparative study of sampling methods within the\nFedHome framework, designed for personalized in-home health monitoring. FedHome\nleverages federated learning (FL) and generative convolutional autoencoders\n(GCAE) to train models on decentralized edge devices while prioritizing data\nprivacy. A notable challenge in this domain is the class imbalance in health\ndata, where critical events such as falls are underrepresented, adversely\naffecting model performance. To address this, the research evaluates six\noversampling techniques using Stratified K-fold cross-validation: SMOTE,\nBorderline-SMOTE, Random OverSampler, SMOTE-Tomek, SVM-SMOTE, and SMOTE-ENN.\nThese methods are tested on FedHome's public implementation over 200 training\nrounds with and without stratified K-fold cross-validation. The findings\nindicate that SMOTE-ENN achieves the most consistent test accuracy, with a\nstandard deviation range of 0.0167-0.0176, demonstrating stable performance\ncompared to other samplers. In contrast, SMOTE and SVM-SMOTE exhibit higher\nvariability in performance, as reflected by their wider standard deviation\nranges of 0.0157-0.0180 and 0.0155-0.0180, respectively. Similarly, the Random\nOverSampler method shows a significant deviation range of 0.0155-0.0176.\nSMOTE-Tomek, with a deviation range of 0.0160-0.0175, also shows greater\nstability but not as much as SMOTE-ENN. This finding highlights the potential\nof SMOTE-ENN to enhance the reliability and accuracy of personalized health\nmonitoring systems within the FedHome framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "11 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01950v1",
    "published_date": "2024-06-04 04:03:07 UTC",
    "updated_date": "2024-06-04 04:03:07 UTC"
  },
  {
    "arxiv_id": "2406.01943v1",
    "title": "Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs",
    "authors": [
      "Nik Bear Brown"
    ],
    "abstract": "This paper surveys evaluation techniques to enhance the trustworthiness and\nunderstanding of Large Language Models (LLMs). As reliance on LLMs grows,\nensuring their reliability, fairness, and transparency is crucial. We explore\nalgorithmic methods and metrics to assess LLM performance, identify weaknesses,\nand guide development towards more trustworthy applications. Key evaluation\nmetrics include Perplexity Measurement, NLP metrics (BLEU, ROUGE, METEOR,\nBERTScore, GLEU, Word Error Rate, Character Error Rate), Zero-Shot and Few-Shot\nLearning Performance, Transfer Learning Evaluation, Adversarial Testing, and\nFairness and Bias Evaluation. We introduce innovative approaches like LLMMaps\nfor stratified evaluation, Benchmarking and Leaderboards for competitive\nassessment, Stratified Analysis for in-depth understanding, Visualization of\nBlooms Taxonomy for cognitive level accuracy distribution, Hallucination Score\nfor quantifying inaccuracies, Knowledge Stratification Strategy for\nhierarchical analysis, and Machine Learning Models for Hierarchy Generation.\nHuman Evaluation is highlighted for capturing nuances that automated metrics\nmay miss. These techniques form a framework for evaluating LLMs, aiming to\nenhance transparency, guide development, and establish user trust. Future\npapers will describe metric visualization and demonstrate each approach on\npractical examples.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "2020: 68T50, 68Q25",
      "I.2.7; F.2.2"
    ],
    "primary_category": "cs.CL",
    "comment": "An extensive survey of the literature specifying algorithms and\n  techniques enhancing the trustworthiness and understanding of Large Language\n  Models (LLMs)",
    "pdf_url": "http://arxiv.org/pdf/2406.01943v1",
    "published_date": "2024-06-04 03:54:53 UTC",
    "updated_date": "2024-06-04 03:54:53 UTC"
  },
  {
    "arxiv_id": "2407.16881v1",
    "title": "Comparative Analysis Vision of Worldwide AI Courses",
    "authors": [
      "Jianing Xia",
      "Man Li",
      "Jianxin Li"
    ],
    "abstract": "This research investigates the curriculum structures of undergraduate\nArtificial Intelligence (AI) education across universities worldwide. By\nexamining the curricula of leading universities, the research seeks to\ncontribute to a deeper understanding of AI education on a global scale,\nfacilitating the alignment of educational practices with the evolving needs of\nthe AI landscape. This research delves into the diverse course structures of\nleading universities, exploring contemporary trends and priorities to reveal\nthe nuanced approaches in AI education. It also investigates the core AI topics\nand learning contents frequently taught, comparing them with the CS2023\ncurriculum guidance to identify convergence and divergence. Additionally, it\nexamines how universities across different countries approach AI education,\nanalyzing educational objectives, priorities, potential careers, and\nmethodologies to understand the global landscape and implications of AI\npedagogy.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "9 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.16881v1",
    "published_date": "2024-06-04 03:53:57 UTC",
    "updated_date": "2024-06-04 03:53:57 UTC"
  },
  {
    "arxiv_id": "2406.01939v2",
    "title": "Speeding up Policy Simulation in Supply Chain RL",
    "authors": [
      "Vivek Farias",
      "Joren Gijsbrechts",
      "Aryan Khojandi",
      "Tianyi Peng",
      "Andrew Zheng"
    ],
    "abstract": "Simulating a single trajectory of a dynamical system under some\nstate-dependent policy is a core bottleneck in policy optimization (PO)\nalgorithms. The many inherently serial policy evaluations that must be\nperformed in a single simulation constitute the bulk of this bottleneck. In\napplying PO to supply chain optimization (SCO) problems, simulating a single\nsample path corresponding to one month of a supply chain can take several\nhours. We present an iterative algorithm to accelerate policy simulation,\ndubbed Picard Iteration. This scheme carefully assigns policy evaluation tasks\nto independent processes. Within an iteration, any given process evaluates the\npolicy only on its assigned tasks while assuming a certain \"cached\" evaluation\nfor other tasks; the cache is updated at the end of the iteration. Implemented\non GPUs, this scheme admits batched evaluation of the policy across a single\ntrajectory. We prove that the structure afforded by many SCO problems allows\nconvergence in a small number of iterations independent of the horizon. We\ndemonstrate practical speedups of 400x on large-scale SCO problems even with a\nsingle GPU, and also demonstrate practical efficacy in other RL environments.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01939v2",
    "published_date": "2024-06-04 03:48:08 UTC",
    "updated_date": "2025-02-15 18:09:50 UTC"
  },
  {
    "arxiv_id": "2406.01929v1",
    "title": "Fast networked data selection via distributed smoothed quantile estimation",
    "authors": [
      "Xu Zhang",
      "Marcos M. Vasconcelos"
    ],
    "abstract": "Collecting the most informative data from a large dataset distributed over a\nnetwork is a fundamental problem in many fields, including control, signal\nprocessing and machine learning. In this paper, we establish a connection\nbetween selecting the most informative data and finding the top-$k$ elements of\na multiset. The top-$k$ selection in a network can be formulated as a\ndistributed nonsmooth convex optimization problem known as quantile estimation.\nUnfortunately, the lack of smoothness in the local objective functions leads to\nextremely slow convergence and poor scalability with respect to the network\nsize. To overcome the deficiency, we propose an accelerated method that employs\nsmoothing techniques. Leveraging the piecewise linearity of the local objective\nfunctions in quantile estimation, we characterize the iteration complexity\nrequired to achieve top-$k$ selection, a challenging task due to the lack of\nstrong convexity. Several numerical results are provided to validate the\neffectiveness of the algorithm and the correctness of the theory.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Submitted to the IEEE Transactions on Automatic Control",
    "pdf_url": "http://arxiv.org/pdf/2406.01929v1",
    "published_date": "2024-06-04 03:26:15 UTC",
    "updated_date": "2024-06-04 03:26:15 UTC"
  },
  {
    "arxiv_id": "2406.18574v1",
    "title": "Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene Classification",
    "authors": [
      "Muhammad Anwar Ma'sum",
      "Mahardhika Pratama",
      "Ramasamy Savitha",
      "Lin Liu",
      "Habibullah",
      "Ryszard Kowalczyk"
    ],
    "abstract": "A continual learning (CL) model is desired for remote sensing image analysis\nbecause of varying camera parameters, spectral ranges, resolutions, etc. There\nexist some recent initiatives to develop CL techniques in this domain but they\nstill depend on massive labelled samples which do not fully fit remote sensing\napplications because ground truths are often obtained via field-based surveys.\nThis paper addresses this problem with a proposal of unsupervised flat-wide\nlearning approach (UNISA) for unsupervised few-shot continual learning\napproaches of remote sensing image scene classifications which do not depend on\nany labelled samples for its model updates. UNISA is developed from the idea of\nprototype scattering and positive sampling for learning representations while\nthe catastrophic forgetting problem is tackled with the flat-wide learning\napproach combined with a ball generator to address the data scarcity problem.\nOur numerical study with remote sensing image scene datasets and a\nhyperspectral dataset confirms the advantages of our solution. Source codes of\nUNISA are shared publicly in \\url{https://github.com/anwarmaxsum/UNISA} to\nallow convenient future studies and reproductions of our numerical results.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review for Publication in IEEE TGRS",
    "pdf_url": "http://arxiv.org/pdf/2406.18574v1",
    "published_date": "2024-06-04 03:06:41 UTC",
    "updated_date": "2024-06-04 03:06:41 UTC"
  },
  {
    "arxiv_id": "2406.01920v1",
    "title": "CODE: Contrasting Self-generated Description to Combat Hallucination in Large Multi-modal Models",
    "authors": [
      "Junho Kim",
      "Hyunjun Kim",
      "Yeonju Kim",
      "Yong Man Ro"
    ],
    "abstract": "Large Multi-modal Models (LMMs) have recently demonstrated remarkable\nabilities in visual context understanding and coherent response generation.\nHowever, alongside these advancements, the issue of hallucinations has emerged\nas a significant challenge, producing erroneous responses that are unrelated to\nthe visual contents. In this paper, we introduce a novel contrastive-based\ndecoding method, COuntering DEscription Contrastive Decoding (CODE), which\nleverages self-generated descriptions as contrasting references during the\ndecoding phase of LMMs to address hallucination issues. CODE utilizes the\ncomprehensive descriptions from model itself as visual counterpart to correct\nand improve response alignment with actual visual content. By dynamically\nadjusting the information flow and distribution of next-token predictions in\nthe LMM's vocabulary, CODE enhances the coherence and informativeness of\ngenerated responses. Extensive experiments demonstrate that our method\nsignificantly reduces hallucinations and improves cross-modal consistency\nacross various benchmarks and cutting-edge LMMs. Our method provides a simple\nyet effective decoding strategy that can be integrated to existing LMM\nframeworks without additional training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://ivy-lvlm.github.io/CODE/",
    "pdf_url": "http://arxiv.org/pdf/2406.01920v1",
    "published_date": "2024-06-04 03:04:21 UTC",
    "updated_date": "2024-06-04 03:04:21 UTC"
  },
  {
    "arxiv_id": "2406.01917v1",
    "title": "GOMAA-Geo: GOal Modality Agnostic Active Geo-localization",
    "authors": [
      "Anindya Sarkar",
      "Srikumar Sastry",
      "Aleksis Pirinen",
      "Chongjie Zhang",
      "Nathan Jacobs",
      "Yevgeniy Vorobeychik"
    ],
    "abstract": "We consider the task of active geo-localization (AGL) in which an agent uses\na sequence of visual cues observed during aerial navigation to find a target\nspecified through multiple possible modalities. This could emulate a UAV\ninvolved in a search-and-rescue operation navigating through an area, observing\na stream of aerial images as it goes. The AGL task is associated with two\nimportant challenges. Firstly, an agent must deal with a goal specification in\none of multiple modalities (e.g., through a natural language description) while\nthe search cues are provided in other modalities (aerial imagery). The second\nchallenge is limited localization time (e.g., limited battery life, urgency) so\nthat the goal must be localized as efficiently as possible, i.e. the agent must\neffectively leverage its sequentially observed aerial views when searching for\nthe goal. To address these challenges, we propose GOMAA-Geo - a goal modality\nagnostic active geo-localization agent - for zero-shot generalization between\ndifferent goal modalities. Our approach combines cross-modality contrastive\nlearning to align representations across modalities with supervised foundation\nmodel pretraining and reinforcement learning to obtain highly effective\nnavigation and localization policies. Through extensive evaluations, we show\nthat GOMAA-Geo outperforms alternative learnable approaches and that it\ngeneralizes across datasets - e.g., to disaster-hit areas without seeing a\nsingle disaster scenario during training - and goal modalities - e.g., to\nground-level imagery or textual descriptions, despite only being trained with\ngoals specified as aerial views. Code and models are publicly available at\nhttps://github.com/mvrl/GOMAA-Geo/tree/main.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01917v1",
    "published_date": "2024-06-04 02:59:36 UTC",
    "updated_date": "2024-06-04 02:59:36 UTC"
  },
  {
    "arxiv_id": "2406.01914v2",
    "title": "HPE-CogVLM: Advancing Vision Language Models with a Head Pose Grounding Task",
    "authors": [
      "Yu Tian",
      "Tianqi Shao",
      "Tsukasa Demizu",
      "Xuyang Wu",
      "Hsin-Tai Wu"
    ],
    "abstract": "Head pose estimation (HPE) requires a sophisticated understanding of 3D\nspatial relationships to generate precise yaw, pitch, and roll angles. Previous\nHPE models, primarily CNN-based, rely on cropped close-up human head images as\ninputs and often lack robustness in real-world scenario. Vision Language Models\n(VLMs) can analyze entire images while focusing on specific objects through\ntheir attention mechanisms. In this paper, we propose a novel framework to\nimprove the HPE accuracy by leveraging the object detection grounding\ncapability of a VLM, referred to as CogVLM. We empirically find that directly\nLoRA fine-tuning of this VLM for the HPE task fails to achieve desirable HPE\naccuracy, while some model merging methods can improve accuracy but frequently\nproduce blended invalid response formats, struggling to handle both object\ndetection and HPE tasks simultaneously. To integrate HPE capability into CogVLM\neffectively, we develop a novel LoRA layer-based model merging method. This\nmerging approach applies a high cosine similarity threshold and a\nwinner-takes-all layer selection strategy, aligning attention to the HPE task\nwhile preserving original object detection knowledge. It successfully resolves\nissues with blended invalid response formats and improves accuracy. Results\nshow that our HPE-CogVLM achieves a 31.5\\% reduction in Mean Absolute Error\nover the current state-of-the-art CNN model, 6DRepNet, in cross-dataset\nevaluation. Furthermore, HPE-CogVLM outperforms both directly LoRA fine-tuned\nand task arithmetic-based merged VLMs across all HPE metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2406.01914v2",
    "published_date": "2024-06-04 02:51:26 UTC",
    "updated_date": "2024-11-08 17:33:31 UTC"
  },
  {
    "arxiv_id": "2406.01913v1",
    "title": "Generating Synthetic Net Load Data with Physics-informed Diffusion Model",
    "authors": [
      "Shaorong Zhang",
      "Yuanbin Cheng",
      "Nanpeng Yu"
    ],
    "abstract": "This paper presents a novel physics-informed diffusion model for generating\nsynthetic net load data, addressing the challenges of data scarcity and privacy\nconcerns. The proposed framework embeds physical models within denoising\nnetworks, offering a versatile approach that can be readily generalized to\nunforeseen scenarios. A conditional denoising neural network is designed to\njointly train the parameters of the transition kernel of the diffusion model\nand the parameters of the physics-informed function. Utilizing the real-world\nsmart meter data from Pecan Street, we validate the proposed method and conduct\na thorough numerical study comparing its performance with state-of-the-art\ngenerative models, including generative adversarial networks, variational\nautoencoders, normalizing flows, and a well calibrated baseline diffusion\nmodel. A comprehensive set of evaluation metrics is used to assess the accuracy\nand diversity of the generated synthetic net load data. The numerical study\nresults demonstrate that the proposed physics-informed diffusion model\noutperforms state-of-the-art models across all quantitative metrics, yielding\nat least 20% improvement.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01913v1",
    "published_date": "2024-06-04 02:50:19 UTC",
    "updated_date": "2024-06-04 02:50:19 UTC"
  },
  {
    "arxiv_id": "2407.11984v1",
    "title": "Mimetic Poet",
    "authors": [
      "Jon McCormack",
      "Elliott Wilson",
      "Nina Rajcic",
      "Maria Teresa Llano"
    ],
    "abstract": "This paper presents the design and initial assessment of a novel device that\nuses generative AI to facilitate creative ideation, inspiration, and reflective\nthought. Inspired by magnetic poetry, which was originally designed to help\novercome writer's block, the device allows participants to compose short poetic\ntexts from a limited vocabulary by physically placing words on the device's\nsurface. Upon composing the text, the system employs a large language model\n(LLM) to generate a response, displayed on an e-ink screen. We explored various\nstrategies for internally sequencing prompts to foster creative thinking,\nincluding analogy, allegorical interpretations, and ideation. We installed the\ndevice in our research laboratory for two weeks and held a focus group at the\nconclusion to evaluate the design. The design choice to limit interactions with\nthe LLM to poetic text, coupled with the tactile experience of assembling the\npoem, fostered a deeper and more enjoyable engagement with the LLM compared to\ntraditional chatbot or screen-based interactions. This approach gives users the\nopportunity to reflect on the AI-generated responses in a manner conducive to\ncreative thought.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "I.2; J.5"
    ],
    "primary_category": "cs.HC",
    "comment": "Paper accepted at the International Conference on Computational\n  Creativity, (ICCC 2024), J\\\"onk\\\"oping, Sweden",
    "pdf_url": "http://arxiv.org/pdf/2407.11984v1",
    "published_date": "2024-06-04 02:50:15 UTC",
    "updated_date": "2024-06-04 02:50:15 UTC"
  },
  {
    "arxiv_id": "2406.01893v2",
    "title": "Large Language Model-Enabled Multi-Agent Manufacturing Systems",
    "authors": [
      "Jonghan Lim",
      "Birgit Vogel-Heuser",
      "Ilya Kovalenko"
    ],
    "abstract": "Traditional manufacturing faces challenges adapting to dynamic environments\nand quickly responding to manufacturing changes. The use of multi-agent systems\nhas improved adaptability and coordination but requires further advancements in\nrapid human instruction comprehension, operational adaptability, and\ncoordination through natural language integration. Large language models like\nGPT-3.5 and GPT-4 enhance multi-agent manufacturing systems by enabling agents\nto communicate in natural language and interpret human instructions for\ndecision-making. This research introduces a novel framework where large\nlanguage models enhance the capabilities of agents in manufacturing, making\nthem more adaptable, and capable of processing context-specific instructions. A\ncase study demonstrates the practical application of this framework, showing\nhow agents can effectively communicate, understand tasks, and execute\nmanufacturing processes, including precise G-code allocation among agents. The\nfindings highlight the importance of continuous large language model\nintegration into multi-agent manufacturing systems and the development of\nsophisticated agent communication protocols for a more flexible manufacturing\nsystem.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01893v2",
    "published_date": "2024-06-04 01:57:37 UTC",
    "updated_date": "2024-06-21 14:54:46 UTC"
  },
  {
    "arxiv_id": "2406.01882v2",
    "title": "HoneyGPT: Breaking the Trilemma in Terminal Honeypots with Large Language Model",
    "authors": [
      "Ziyang Wang",
      "Jianzhou You",
      "Haining Wang",
      "Tianwei Yuan",
      "Shichao Lv",
      "Yang Wang",
      "Limin Sun"
    ],
    "abstract": "Honeypots, as a strategic cyber-deception mechanism designed to emulate\nauthentic interactions and bait unauthorized entities, often struggle with\nbalancing flexibility, interaction depth, and deception. They typically fail to\nadapt to evolving attacker tactics, with limited engagement and information\ngathering. Fortunately, the emergent capabilities of large language models and\ninnovative prompt-based engineering offer a transformative shift in honeypot\ntechnologies. This paper introduces HoneyGPT, a pioneering shell honeypot\narchitecture based on ChatGPT, characterized by its cost-effectiveness and\nproactive engagement. In particular, we propose a structured prompt engineering\nframework that incorporates chain-of-thought tactics to improve long-term\nmemory and robust security analytics, enhancing deception and engagement. Our\nevaluation of HoneyGPT comprises a baseline comparison based on a collected\ndataset and a three-month field evaluation. The baseline comparison\ndemonstrates HoneyGPT's remarkable ability to strike a balance among\nflexibility, interaction depth, and deceptive capability. The field evaluation\nfurther validates HoneyGPT's superior performance in engaging attackers more\ndeeply and capturing a wider array of novel attack vectors.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.ET",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01882v2",
    "published_date": "2024-06-04 01:31:20 UTC",
    "updated_date": "2025-02-15 10:06:51 UTC"
  },
  {
    "arxiv_id": "2406.02630v2",
    "title": "AI Agents Under Threat: A Survey of Key Security Challenges and Future Pathways",
    "authors": [
      "Zehang Deng",
      "Yongjian Guo",
      "Changzhou Han",
      "Wanlun Ma",
      "Junwu Xiong",
      "Sheng Wen",
      "Yang Xiang"
    ],
    "abstract": "An Artificial Intelligence (AI) agent is a software entity that autonomously\nperforms tasks or makes decisions based on pre-defined objectives and data\ninputs. AI agents, capable of perceiving user inputs, reasoning and planning\ntasks, and executing actions, have seen remarkable advancements in algorithm\ndevelopment and task performance. However, the security challenges they pose\nremain under-explored and unresolved. This survey delves into the emerging\nsecurity threats faced by AI agents, categorizing them into four critical\nknowledge gaps: unpredictability of multi-step user inputs, complexity in\ninternal executions, variability of operational environments, and interactions\nwith untrusted external entities. By systematically reviewing these threats,\nthis paper highlights both the progress made and the existing limitations in\nsafeguarding AI agents. The insights provided aim to inspire further research\ninto addressing the security threats associated with AI agents, thereby\nfostering the development of more robust and secure AI agent applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to ACM Computing Survey",
    "pdf_url": "http://arxiv.org/pdf/2406.02630v2",
    "published_date": "2024-06-04 01:22:31 UTC",
    "updated_date": "2024-09-06 01:31:22 UTC"
  },
  {
    "arxiv_id": "2406.01876v1",
    "title": "GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security",
    "authors": [
      "Xuanqing Liu",
      "Luyang Kong",
      "Runhui Wang",
      "Patrick Song",
      "Austin Nevins",
      "Henrik Johnson",
      "Nimish Amlathe",
      "Davor Golac"
    ],
    "abstract": "Schema matching constitutes a pivotal phase in the data ingestion process for\ncontemporary database systems. Its objective is to discern pairwise\nsimilarities between two sets of attributes, each associated with a distinct\ndata table. This challenge emerges at the initial stages of data analytics,\nsuch as when incorporating a third-party table into existing databases to\ninform business insights. Given its significance in the realm of database\nsystems, schema matching has been under investigation since the 2000s. This\nstudy revisits this foundational problem within the context of large language\nmodels. Adhering to increasingly stringent data security policies, our focus\nlies on the zero-shot and few-shot scenarios: the model should analyze only a\nminimal amount of customer data to execute the matching task, contrasting with\nthe conventional approach of scrutinizing the entire data table. We emphasize\nthat the zero-shot or few-shot assumption is imperative to safeguard the\nidentity and privacy of customer data, even at the potential cost of accuracy.\nThe capability to accurately match attributes under such stringent requirements\ndistinguishes our work from previous literature in this domain.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "KDD 2024 Camera Ready; 11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01876v1",
    "published_date": "2024-06-04 01:08:00 UTC",
    "updated_date": "2024-06-04 01:08:00 UTC"
  },
  {
    "arxiv_id": "2406.01869v1",
    "title": "Fruit Classification System with Deep Learning and Neural Architecture Search",
    "authors": [
      "Christine Dewi",
      "Dhananjay Thiruvady",
      "Nayyar Zaidi"
    ],
    "abstract": "The fruit identification process involves analyzing and categorizing\ndifferent types of fruits based on their visual characteristics. This activity\ncan be achieved using a range of methodologies, encompassing manual\nexamination, conventional computer vision methodologies, and more sophisticated\nmethodologies employing machine learning and deep learning. Our study\nidentified a total of 15 distinct categories of fruit, consisting of class\nAvocado, Banana, Cherry, Apple Braeburn, Apple golden 1, Apricot, Grape, Kiwi,\nMango, Orange, Papaya, Peach, Pineapple, Pomegranate and Strawberry. Neural\nArchitecture Search (NAS) is a technological advancement employed within the\nrealm of deep learning and artificial intelligence, to automate conceptualizing\nand refining neural network topologies. NAS aims to identify neural network\nstructures that are highly suitable for tasks, such as the detection of fruits.\nOur suggested model with 99.98% mAP increased the detection performance of the\npreceding research study that used Fruit datasets. In addition, after the\ncompletion of the study, a comparative analysis was carried out to assess the\nfindings in conjunction with those of another research that is connected to the\ntopic. When compared to the findings of earlier studies, the detector that was\nproposed exhibited higher performance in terms of both its accuracy and its\nprecision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2; I.4"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01869v1",
    "published_date": "2024-06-04 00:41:47 UTC",
    "updated_date": "2024-06-04 00:41:47 UTC"
  },
  {
    "arxiv_id": "2406.01855v1",
    "title": "TruthEval: A Dataset to Evaluate LLM Truthfulness and Reliability",
    "authors": [
      "Aisha Khatun",
      "Daniel G. Brown"
    ],
    "abstract": "Large Language Model (LLM) evaluation is currently one of the most important\nareas of research, with existing benchmarks proving to be insufficient and not\ncompletely representative of LLMs' various capabilities. We present a curated\ncollection of challenging statements on sensitive topics for LLM benchmarking\ncalled TruthEval. These statements were curated by hand and contain known truth\nvalues. The categories were chosen to distinguish LLMs' abilities from their\nstochastic nature. We perform some initial analyses using this dataset and find\nseveral instances of LLMs failing in simple tasks showing their inability to\nunderstand simple questions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01855v1",
    "published_date": "2024-06-04 00:01:35 UTC",
    "updated_date": "2024-06-04 00:01:35 UTC"
  }
]