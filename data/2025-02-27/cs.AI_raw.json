[
  {
    "arxiv_id": "2502.20598v1",
    "title": "Scalable Coordinated Learning for H2M/R Applications over Optical Access Networks (Invited)",
    "authors": [
      "Sourav Mondal",
      "Elaine Wong"
    ],
    "abstract": "One of the primary research interests adhering to next-generation\nfiber-wireless access networks is human-to-machine/robot (H2M/R) collaborative\ncommunications facilitating Industry 5.0. This paper discusses scalable H2M/R\ncommunications across large geographical distances that also allow rapid\nonboarding of new machines/robots as $\\sim72\\%$ training time is saved through\nglobal-local coordinated learning.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "This article is accepted for publication in 29th Opto-Electronics and\n  Communications Conference 2024 (OECC2024). Copyright @ IEEE",
    "pdf_url": "http://arxiv.org/pdf/2502.20598v1",
    "published_date": "2025-02-27 23:56:51 UTC",
    "updated_date": "2025-02-27 23:56:51 UTC"
  },
  {
    "arxiv_id": "2503.01896v1",
    "title": "Neuroplasticity and Corruption in Model Mechanisms: A Case Study Of Indirect Object Identification",
    "authors": [
      "Vishnu Kabir Chhabra",
      "Ding Zhu",
      "Mohammad Mahdi Khalili"
    ],
    "abstract": "Previous research has shown that fine-tuning language models on general tasks\nenhance their underlying mechanisms. However, the impact of fine-tuning on\npoisoned data and the resulting changes in these mechanisms are poorly\nunderstood. This study investigates the changes in a model's mechanisms during\ntoxic fine-tuning and identifies the primary corruption mechanisms. We also\nanalyze the changes after retraining a corrupted model on the original dataset\nand observe neuroplasticity behaviors, where the model relearns original\nmechanisms after fine-tuning the corrupted model. Our findings indicate that:\n(i) Underlying mechanisms are amplified across task-specific fine-tuning which\ncan be generalized to longer epochs, (ii) Model corruption via toxic\nfine-tuning is localized to specific circuit components, (iii) Models exhibit\nneuroplasticity when retraining corrupted models on clean dataset, reforming\nthe original model mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01896v1",
    "published_date": "2025-02-27 23:44:50 UTC",
    "updated_date": "2025-02-27 23:44:50 UTC"
  },
  {
    "arxiv_id": "2503.00079v3",
    "title": "AI Literacy in K-12 and Higher Education in the Wake of Generative AI: An Integrative Review",
    "authors": [
      "Xingjian Gu",
      "Barbara J. Ericson"
    ],
    "abstract": "Even though AI literacy has emerged as a prominent education topic in the\nwake of generative AI, its definition remains vague. There is little consensus\namong researchers and practitioners on how to discuss and design AI literacy\ninterventions. The term has been used to describe both learning activities that\ntrain undergraduate students to use ChatGPT effectively and having kindergarten\nchildren interact with social robots. This paper applies an integrative review\nmethod to examine empirical and theoretical AI literacy studies published since\n2020. In synthesizing the 124 reviewed studies, three ways to conceptualize\nliteracy-functional, critical, and indirectly beneficial-and three perspectives\non AI-technical detail, tool, and sociocultural-were identified, forming a\nframework that reflects the spectrum of how AI literacy is approached in\npractice. The framework highlights the need for more specialized terms within\nAI literacy discourse and indicates research gaps in certain AI literacy\nobjectives.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; K.3.2"
    ],
    "primary_category": "cs.CY",
    "comment": "25 pages, 7 figures; submitted to ICER 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00079v3",
    "published_date": "2025-02-27 23:32:03 UTC",
    "updated_date": "2025-03-28 16:54:27 UTC"
  },
  {
    "arxiv_id": "2503.01895v2",
    "title": "Evaluating System 1 vs. 2 Reasoning Approaches for Zero-Shot Time Series Forecasting: A Benchmark and Insights",
    "authors": [
      "Haoxin Liu",
      "Zhiyuan Zhao",
      "Shiduo Li",
      "B. Aditya Prakash"
    ],
    "abstract": "Reasoning ability is crucial for solving challenging tasks. With the\nadvancement of foundation models, such as the emergence of large language\nmodels (LLMs), a wide range of reasoning strategies has been proposed,\nincluding test-time enhancements, such as Chain-ofThought, and post-training\noptimizations, as used in DeepSeek-R1. While these reasoning strategies have\ndemonstrated effectiveness across various challenging language or vision tasks,\ntheir applicability and impact on time-series forecasting (TSF), particularly\nthe challenging zero-shot TSF, remain largely unexplored. In particular, it is\nunclear whether zero-shot TSF benefits from reasoning and, if so, what types of\nreasoning strategies are most effective. To bridge this gap, we propose ReC4TS,\nthe first benchmark that systematically evaluates the effectiveness of popular\nreasoning strategies when applied to zero-shot TSF tasks. ReC4TS conducts\ncomprehensive evaluations across datasets spanning eight domains, covering both\nunimodal and multimodal with short-term and longterm forecasting tasks. More\nimportantly, ReC4TS provides key insights: (1) Self-consistency emerges as the\nmost effective test-time reasoning strategy; (2) Group-relative policy\noptimization emerges as a more suitable approach for incentivizing reasoning\nability during post-training; (3) Multimodal TSF benefits more from reasoning\nstrategies compared to unimodal TSF. Beyond these insights, ReC4TS establishes\ntwo pioneering starting blocks to support future zero-shot TSF reasoning\nresearch: (1) A novel dataset, TimeThinking, containing forecasting samples\nannotated with reasoning trajectories from multiple advanced LLMs, and (2) A\nnew and simple test-time scaling-law validated on foundational TSF models\nenabled by self-consistency reasoning strategy. All data and code are publicly\naccessible at: https://github.com/AdityaLab/OpenTimeR",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01895v2",
    "published_date": "2025-02-27 23:27:37 UTC",
    "updated_date": "2025-03-14 00:16:53 UTC"
  },
  {
    "arxiv_id": "2502.20589v1",
    "title": "LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis",
    "authors": [
      "Saeif Alhazbi",
      "Ahmed Mohamed Hussain",
      "Gabriele Oligeri",
      "Panos Papadimitratos"
    ],
    "abstract": "As Large Language Models (LLMs) become increasingly integrated into many\ntechnological ecosystems across various domains and industries, identifying\nwhich model is deployed or being interacted with is critical for the security\nand trustworthiness of the systems. Current verification methods typically rely\non analyzing the generated output to determine the source model. However, these\ntechniques are susceptible to adversarial attacks, operate in a post-hoc\nmanner, and may require access to the model weights to inject a verifiable\nfingerprint. In this paper, we propose a novel passive and non-invasive\nfingerprinting technique that operates in real-time and remains effective even\nunder encrypted network traffic conditions. Our method leverages the intrinsic\nautoregressive generation nature of language models, which generate text one\ntoken at a time based on all previously generated tokens, creating a unique\ntemporal pattern like a rhythm or heartbeat that persists even when the output\nis streamed over a network. We find that measuring the Inter-Token Times\n(ITTs)-time intervals between consecutive tokens-can identify different\nlanguage models with high accuracy. We develop a Deep Learning (DL) pipeline to\ncapture these timing patterns using network traffic analysis and evaluate it on\n16 Small Language Models (SLMs) and 10 proprietary LLMs across different\ndeployment scenarios, including local host machine (GPU/CPU), Local Area\nNetwork (LAN), Remote Network, and Virtual Private Network (VPN). The\nexperimental results confirm that our proposed technique is effective and\nmaintains high accuracy even when tested in different network conditions. This\nwork opens a new avenue for model identification in real-world scenarios and\ncontributes to more secure and trustworthy language model deployment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20589v1",
    "published_date": "2025-02-27 23:22:01 UTC",
    "updated_date": "2025-02-27 23:22:01 UTC"
  },
  {
    "arxiv_id": "2502.20583v1",
    "title": "LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation",
    "authors": [
      "Keisuke Kamahori",
      "Jungo Kasai",
      "Noriyuki Kojima",
      "Baris Kasikci"
    ],
    "abstract": "Modern automatic speech recognition (ASR) models, such as OpenAI's Whisper,\nrely on deep encoder-decoder architectures, and their encoders are a critical\nbottleneck for efficient deployment due to high computational intensity. We\nintroduce LiteASR, a low-rank compression scheme for ASR encoders that\nsignificantly reduces inference costs while maintaining transcription accuracy.\nOur approach leverages the strong low-rank properties observed in intermediate\nactivations: by applying principal component analysis (PCA) with a small\ncalibration dataset, we approximate linear transformations with a chain of\nlow-rank matrix multiplications, and further optimize self-attention to work in\nthe reduced dimension. Evaluation results show that our method can compress\nWhisper large-v3's encoder size by over 50%, matching Whisper medium's size\nwith better transcription accuracy, thereby establishing a new Pareto-optimal\nfrontier of efficiency and performance. The code of LiteASR is available at\nhttps://github.com/efeslab/LiteASR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20583v1",
    "published_date": "2025-02-27 22:52:21 UTC",
    "updated_date": "2025-02-27 22:52:21 UTC"
  },
  {
    "arxiv_id": "2503.00077v1",
    "title": "Navigating the Edge with the State-of-the-Art Insights into Corner Case Identification and Generation for Enhanced Autonomous Vehicle Safety",
    "authors": [
      "Gabriel Kenji Godoy Shimanuki",
      "Alexandre Moreira Nascimento",
      "Lucio Flavio Vismari",
      "Joao Batista Camargo Junior",
      "Jorge Rady de Almeida Junior",
      "Paulo Sergio Cugnasca"
    ],
    "abstract": "In recent years, there has been significant development of autonomous vehicle\n(AV) technologies. However, despite the notable achievements of some industry\nplayers, a strong and appealing body of evidence that demonstrate AVs are\nactually safe is lacky, which could foster public distrust in this technology\nand further compromise the entire development of this industry, as well as\nrelated social impacts. To improve the safety of AVs, several techniques are\nproposed that use synthetic data in virtual simulation. In particular, the\nhighest risk data, known as corner cases (CCs), are the most valuable for\ndeveloping and testing AV controls, as they can expose and improve the\nweaknesses of these autonomous systems. In this context, the present paper\npresents a systematic literature review aiming to comprehensively analyze\nmethodologies for CC identifi cation and generation, also pointing out current\ngaps and further implications of synthetic data for AV safety and reliability.\nBased on a selection criteria, 110 studies were picked from an initial sample\nof 1673 papers. These selected paper were mapped into multiple categories to\nanswer eight inter-linked research questions. It concludes with the\nrecommendation of a more integrated approach focused on safe development among\nall stakeholders, with active collaboration between industry, academia and\nregulatory bodies.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00077v1",
    "published_date": "2025-02-27 22:47:46 UTC",
    "updated_date": "2025-02-27 22:47:46 UTC"
  },
  {
    "arxiv_id": "2502.20578v1",
    "title": "Interpreting CLIP with Hierarchical Sparse Autoencoders",
    "authors": [
      "Vladimir Zaigrajew",
      "Hubert Baniecki",
      "Przemyslaw Biecek"
    ],
    "abstract": "Sparse autoencoders (SAEs) are useful for detecting and steering\ninterpretable features in neural networks, with particular potential for\nunderstanding complex multimodal representations. Given their ability to\nuncover interpretable features, SAEs are particularly valuable for analyzing\nlarge-scale vision-language models (e.g., CLIP and SigLIP), which are\nfundamental building blocks in modern systems yet remain challenging to\ninterpret and control. However, current SAE methods are limited by optimizing\nboth reconstruction quality and sparsity simultaneously, as they rely on either\nactivation suppression or rigid sparsity constraints. To this end, we introduce\nMatryoshka SAE (MSAE), a new architecture that learns hierarchical\nrepresentations at multiple granularities simultaneously, enabling a direct\noptimization of both metrics without compromise. MSAE establishes a new\nstate-of-the-art Pareto frontier between reconstruction quality and sparsity\nfor CLIP, achieving 0.99 cosine similarity and less than 0.1 fraction of\nvariance unexplained while maintaining ~80% sparsity. Finally, we demonstrate\nthe utility of MSAE as a tool for interpreting and controlling CLIP by\nextracting over 120 semantic concepts from its representation to perform\nconcept-based similarity search and bias analysis in downstream tasks like\nCelebA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20578v1",
    "published_date": "2025-02-27 22:39:13 UTC",
    "updated_date": "2025-02-27 22:39:13 UTC"
  },
  {
    "arxiv_id": "2502.20571v1",
    "title": "PFformer: A Position-Free Transformer Variant for Extreme-Adaptive Multivariate Time Series Forecasting",
    "authors": [
      "Yanhong Li",
      "David C. Anastasiu"
    ],
    "abstract": "Multivariate time series (MTS) forecasting is vital in fields like weather,\nenergy, and finance. However, despite deep learning advancements, traditional\nTransformer-based models often diminish the effect of crucial inter-variable\nrelationships by singular token embedding and struggle to effectively capture\ncomplex dependencies among variables, especially in datasets with rare or\nextreme events. These events create significant imbalances and lead to high\nskewness, complicating accurate prediction efforts. This study introduces\nPFformer, a position-free Transformer-based model designed for single-target\nMTS forecasting, specifically for challenging datasets characterized by extreme\nvariability. PFformer integrates two novel embedding strategies: Enhanced\nFeature-based Embedding (EFE) and Auto-Encoder-based Embedding (AEE). EFE\neffectively encodes inter-variable dependencies by mapping related sequence\nsubsets to high-dimensional spaces without positional constraints, enhancing\nthe encoder's functionality. PFformer shows superior forecasting accuracy\nwithout the traditional limitations of positional encoding in MTS modeling. We\nevaluated PFformer across four challenging datasets, focusing on two key\nforecasting scenarios: long sequence prediction for 3 days ahead and rolling\npredictions every four hours to reflect real-time decision-making processes in\nwater management. PFformer demonstrated remarkable improvements, from 20% to\n60%, compared with state-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "PAKDD 2025 special session on Data Science: Foundations and\n  Applications (DSFA)",
    "pdf_url": "http://arxiv.org/pdf/2502.20571v1",
    "published_date": "2025-02-27 22:21:27 UTC",
    "updated_date": "2025-02-27 22:21:27 UTC"
  },
  {
    "arxiv_id": "2502.20565v2",
    "title": "DPZV: Elevating the Tradeoff between Privacy and Utility in Zeroth-Order Vertical Federated Learning",
    "authors": [
      "Jianing Zhang",
      "Evan Chen",
      "Chaoyue Liu",
      "Christopher G. Brinton"
    ],
    "abstract": "Vertical Federated Learning (VFL) enables collaborative training with\nfeature-partitioned data, yet remains vulnerable to privacy leakage through\ngradient transmissions. Standard differential privacy (DP) techniques such as\nDP-SGD are difficult to apply in this setting due to VFL's distributed nature\nand the high variance incurred by vector-valued noise. On the other hand,\nzeroth-order (ZO) optimization techniques can avoid explicit gradient exposure\nbut lack formal privacy guarantees. In this work, we propose DPZV, the first ZO\noptimization framework for VFL that achieves tunable DP with performance\nguarantees. DPZV overcomes these limitations by injecting low-variance scalar\nnoise at the server, enabling controllable privacy with reduced memory\noverhead. We conduct a comprehensive theoretical analysis showing that DPZV\nmatches the convergence rate of first-order optimization methods while\nsatisfying formal ($\\epsilon, \\delta$)-DP guarantees. Experiments on image and\nlanguage benchmarks demonstrate that DPZV outperforms several baselines in\nterms of accuracy under a wide range of privacy constraints ($\\epsilon \\le\n10$), thereby elevating the privacy-utility tradeoff in VFL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20565v2",
    "published_date": "2025-02-27 22:07:16 UTC",
    "updated_date": "2025-05-19 14:40:29 UTC"
  },
  {
    "arxiv_id": "2502.20548v1",
    "title": "$Q\\sharp$: Provably Optimal Distributional RL for LLM Post-Training",
    "authors": [
      "Jin Peng Zhou",
      "Kaiwen Wang",
      "Jonathan Chang",
      "Zhaolin Gao",
      "Nathan Kallus",
      "Kilian Q. Weinberger",
      "Kiant√© Brantley",
      "Wen Sun"
    ],
    "abstract": "Reinforcement learning (RL) post-training is crucial for LLM alignment and\nreasoning, but existing policy-based methods, such as PPO and DPO, can fall\nshort of fixing shortcuts inherited from pre-training. In this work, we\nintroduce $Q\\sharp$, a value-based algorithm for KL-regularized RL that guides\nthe reference policy using the optimal regularized $Q$ function. We propose to\nlearn the optimal $Q$ function using distributional RL on an aggregated online\ndataset. Unlike prior value-based baselines that guide the model using\nunregularized $Q$-values, our method is theoretically principled and provably\nlearns the optimal policy for the KL-regularized RL problem. Empirically,\n$Q\\sharp$ outperforms prior baselines in math reasoning benchmarks while\nmaintaining a smaller KL divergence to the reference policy. Theoretically, we\nestablish a reduction from KL-regularized RL to no-regret online learning,\nproviding the first bounds for deterministic MDPs under only realizability.\nThanks to distributional RL, our bounds are also variance-dependent and\nconverge faster when the reference policy has small variance. In sum, our\nresults highlight $Q\\sharp$ as an effective approach for post-training LLMs,\noffering both improved performance and theoretical guarantees. The code can be\nfound at https://github.com/jinpz/q_sharp.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20548v1",
    "published_date": "2025-02-27 21:43:00 UTC",
    "updated_date": "2025-02-27 21:43:00 UTC"
  },
  {
    "arxiv_id": "2502.20525v1",
    "title": "Revisiting Kernel Attention with Correlated Gaussian Process Representation",
    "authors": [
      "Long Minh Bui",
      "Tho Tran Huu",
      "Duy Dinh",
      "Tan Minh Nguyen",
      "Trong Nghia Hoang"
    ],
    "abstract": "Transformers have increasingly become the de facto method to model sequential\ndata with state-of-the-art performance. Due to its widespread use, being able\nto estimate and calibrate its modeling uncertainty is important to understand\nand design robust transformer models. To achieve this, previous works have used\nGaussian processes (GPs) to perform uncertainty calibration for the attention\nunits of transformers and attained notable successes. However, such approaches\nhave to confine the transformers to the space of symmetric attention to ensure\nthe necessary symmetric requirement of their GP's kernel specification, which\nreduces the representation capacity of the model. To mitigate this restriction,\nwe propose the Correlated Gaussian Process Transformer (CGPT), a new class of\ntransformers whose self-attention units are modeled as cross-covariance between\ntwo correlated GPs (CGPs). This allows asymmetries in attention and can enhance\nthe representation capacity of GP-based transformers. We also derive a sparse\napproximation for CGP to make it scale better. Our empirical studies show that\nboth CGP-based and sparse CGP-based transformers achieve better performance\nthan state-of-the-art GP-based transformers on a variety of benchmark tasks.\nThe code for our experiments is available at\nhttps://github.com/MinhLong210/CGP-Transformers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20525v1",
    "published_date": "2025-02-27 21:21:48 UTC",
    "updated_date": "2025-02-27 21:21:48 UTC"
  },
  {
    "arxiv_id": "2502.20513v1",
    "title": "Personas Evolved: Designing Ethical LLM-Based Conversational Agent Personalities",
    "authors": [
      "Smit Desai",
      "Mateusz Dubiel",
      "Nima Zargham",
      "Thomas Mildner",
      "Laura Spillner"
    ],
    "abstract": "The emergence of Large Language Models (LLMs) has revolutionized\nConversational User Interfaces (CUIs), enabling more dynamic, context-aware,\nand human-like interactions across diverse domains, from social sciences to\nhealthcare. However, the rapid adoption of LLM-based personas raises critical\nethical and practical concerns, including bias, manipulation, and unforeseen\nsocial consequences. Unlike traditional CUIs, where personas are carefully\ndesigned with clear intent, LLM-based personas generate responses dynamically\nfrom vast datasets, making their behavior less predictable and harder to\ngovern. This workshop aims to bridge the gap between CUI and broader AI\ncommunities by fostering a cross-disciplinary dialogue on the responsible\ndesign and evaluation of LLM-based personas. Bringing together researchers,\ndesigners, and practitioners, we will explore best practices, develop ethical\nguidelines, and promote frameworks that ensure transparency, inclusivity, and\nuser-centered interactions. By addressing these challenges collaboratively, we\nseek to shape the future of LLM-driven CUIs in ways that align with societal\nvalues and expectations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20513v1",
    "published_date": "2025-02-27 20:46:54 UTC",
    "updated_date": "2025-02-27 20:46:54 UTC"
  },
  {
    "arxiv_id": "2502.20508v1",
    "title": "TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning",
    "authors": [
      "Soumyabrata Chaudhuri",
      "Pranav Purkar",
      "Ritwik Raghav",
      "Shubhojit Mallick",
      "Manish Gupta",
      "Abhik Jana",
      "Shreya Ghosh"
    ],
    "abstract": "Recent advancements in probing Large Language Models (LLMs) have explored\ntheir latent potential as personalized travel planning agents, yet existing\nbenchmarks remain limited in real world applicability. Existing datasets, such\nas TravelPlanner and TravelPlanner+, suffer from semi synthetic data reliance,\nspatial inconsistencies, and a lack of key travel constraints, making them\ninadequate for practical itinerary generation. To address these gaps, we\nintroduce TripCraft, a spatiotemporally coherent travel planning dataset that\nintegrates real world constraints, including public transit schedules, event\navailability, diverse attraction categories, and user personas for enhanced\npersonalization. To evaluate LLM generated plans beyond existing binary\nvalidation methods, we propose five continuous evaluation metrics, namely\nTemporal Meal Score, Temporal Attraction Score, Spatial Score, Ordering Score,\nand Persona Score which assess itinerary quality across multiple dimensions.\nOur parameter informed setting significantly enhances meal scheduling,\nimproving the Temporal Meal Score from 61% to 80% in a 7 day scenario.\nTripCraft establishes a new benchmark for LLM driven personalized travel\nplanning, offering a more realistic, constraint aware framework for itinerary\ngeneration. Dataset and Codebase will be made publicly available upon\nacceptance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 18 Tables and 6 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20508v1",
    "published_date": "2025-02-27 20:33:28 UTC",
    "updated_date": "2025-02-27 20:33:28 UTC"
  },
  {
    "arxiv_id": "2502.20504v1",
    "title": "A Thousand Words or An Image: Studying the Influence of Persona Modality in Multimodal LLMs",
    "authors": [
      "Julius Broomfield",
      "Kartik Sharma",
      "Srijan Kumar"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated remarkable\nadvancements in embodying diverse personas, enhancing their effectiveness as\nconversational agents and virtual assistants. Consequently, LLMs have made\nsignificant strides in processing and integrating multimodal information.\nHowever, even though human personas can be expressed in both text and image,\nthe extent to which the modality of a persona impacts the embodiment by the LLM\nremains largely unexplored. In this paper, we investigate how do different\nmodalities influence the expressiveness of personas in multimodal LLMs. To this\nend, we create a novel modality-parallel dataset of 40 diverse personas varying\nin age, gender, occupation, and location. This consists of four modalities to\nequivalently represent a persona: image-only, text-only, a combination of image\nand small text, and typographical images, where text is visually stylized to\nconvey persona-related attributes. We then create a systematic evaluation\nframework with 60 questions and corresponding metrics to assess how well LLMs\nembody each persona across its attributes and scenarios. Comprehensive\nexperiments on $5$ multimodal LLMs show that personas represented by detailed\ntext show more linguistic habits, while typographical images often show more\nconsistency with the persona. Our results reveal that LLMs often overlook\npersona-specific details conveyed through images, highlighting underlying\nlimitations and paving the way for future research to bridge this gap. We\nrelease the data and code at https://github.com/claws-lab/persona-modality .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20504v1",
    "published_date": "2025-02-27 20:25:00 UTC",
    "updated_date": "2025-02-27 20:25:00 UTC"
  },
  {
    "arxiv_id": "2502.20502v1",
    "title": "On Benchmarking Human-Like Intelligence in Machines",
    "authors": [
      "Lance Ying",
      "Katherine M. Collins",
      "Lionel Wong",
      "Ilia Sucholutsky",
      "Ryan Liu",
      "Adrian Weller",
      "Tianmin Shu",
      "Thomas L. Griffiths",
      "Joshua B. Tenenbaum"
    ],
    "abstract": "Recent benchmark studies have claimed that AI has approached or even\nsurpassed human-level performances on various cognitive tasks. However, this\nposition paper argues that current AI evaluation paradigms are insufficient for\nassessing human-like cognitive capabilities. We identify a set of key\nshortcomings: a lack of human-validated labels, inadequate representation of\nhuman response variability and uncertainty, and reliance on simplified and\necologically-invalid tasks. We support our claims by conducting a human\nevaluation study on ten existing AI benchmarks, suggesting significant biases\nand flaws in task and label designs. To address these limitations, we propose\nfive concrete recommendations for developing future benchmarks that will enable\nmore rigorous and meaningful evaluations of human-like cognitive capacities in\nAI with various implications for such AI applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20502v1",
    "published_date": "2025-02-27 20:21:36 UTC",
    "updated_date": "2025-02-27 20:21:36 UTC"
  },
  {
    "arxiv_id": "2502.20493v1",
    "title": "Unified Kernel-Segregated Transpose Convolution Operation",
    "authors": [
      "Vijay Srinivas Tida",
      "Md Imran Hossen",
      "Liqun Shan",
      "Sai Venkatesh Chilukoti",
      "Sonya Hsu",
      "Xiali Hei"
    ],
    "abstract": "The optimization of the transpose convolution layer for deep learning\napplications is achieved with the kernel segregation mechanism. However, kernel\nsegregation has disadvantages, such as computing extra elements to obtain the\noutput feature map with odd dimensions while launching a thread. To mitigate\nthis problem, we introduce a unified kernel segregation approach that limits\nthe usage of memory and computational resources by employing one unified kernel\nto execute four sub-kernels. The findings reveal that the suggested approach\nachieves an average computational speedup of 2.03x (3.89x) when tested on\nspecific datasets with an RTX 2070 GPU (Intel Xeon CPU). The ablation study\nshows an average computational speedup of 3.5x when evaluating the transpose\nconvolution layers from well-known Generative Adversarial Networks (GANs). The\nimplementation of the proposed method for the transpose convolution layers in\nthe EB-GAN model demonstrates significant memory savings of up to 35 MB.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20493v1",
    "published_date": "2025-02-27 19:56:25 UTC",
    "updated_date": "2025-02-27 19:56:25 UTC"
  },
  {
    "arxiv_id": "2502.20490v3",
    "title": "EgoNormia: Benchmarking Physical Social Norm Understanding",
    "authors": [
      "MohammadHossein Rezaei",
      "Yicheng Fu",
      "Phil Cuvin",
      "Caleb Ziems",
      "Yanzhe Zhang",
      "Hao Zhu",
      "Diyi Yang"
    ],
    "abstract": "Human activity is moderated by norms. However, machines are often trained\nwithout explicit supervision on norm understanding and reasoning, particularly\nwhen norms are physically- or socially-grounded. To improve and evaluate the\nnormative reasoning capability of vision-language models (VLMs), we present\n\\dataset{} $\\|\\epsilon\\|$, consisting of 1,853 challenging, multi-stage MCQ\nquestions based on ego-centric videos of human interactions, evaluating both\nthe prediction and justification of normative actions. The normative actions\nencompass seven categories: safety, privacy, proxemics, politeness,\ncooperation, coordination/proactivity, and communication/legibility. To compile\nthis dataset at scale, we propose a novel pipeline leveraging video sampling,\nautomatic answer generation, filtering, and human validation. Our work\ndemonstrates that current state-of-the-art vision-language models lack robust\nnorm understanding, scoring a maximum of 54\\% on \\dataset{} (versus a human\nbench of 92\\%). Our analysis of performance in each dimension highlights the\nsignificant risks of safety, privacy, and the lack of collaboration and\ncommunication capability when applied to real-world agents. We additionally\nshow that through a retrieval-based generation (RAG) method, it is possible to\nuse \\dataset{} to enhance normative reasoning in VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "V2, with updated VLM stats",
    "pdf_url": "http://arxiv.org/pdf/2502.20490v3",
    "published_date": "2025-02-27 19:54:16 UTC",
    "updated_date": "2025-05-04 23:41:06 UTC"
  },
  {
    "arxiv_id": "2502.20482v1",
    "title": "R-ParVI: Particle-based variational inference through lens of rewards",
    "authors": [
      "Yongchao Huang"
    ],
    "abstract": "A reward-guided, gradient-free ParVI method, \\textit{R-ParVI}, is proposed\nfor sampling partially known densities (e.g. up to a constant). R-ParVI\nformulates the sampling problem as particle flow driven by rewards: particles\nare drawn from a prior distribution, navigate through parameter space with\nmovements determined by a reward mechanism blending assessments from the target\ndensity, with the steady state particle configuration approximating the target\ngeometry. Particle-environment interactions are simulated by stochastic\nperturbations and the reward mechanism, which drive particles towards high\ndensity regions while maintaining diversity (e.g. preventing from collapsing\ninto clusters). R-ParVI offers fast, flexible, scalable and stochastic sampling\nand inference for a class of probabilistic models such as those encountered in\nBayesian inference and generative modelling.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20482v1",
    "published_date": "2025-02-27 19:50:22 UTC",
    "updated_date": "2025-02-27 19:50:22 UTC"
  },
  {
    "arxiv_id": "2503.16466v1",
    "title": "ACE, Action and Control via Explanations: A Proposal for LLMs to Provide Human-Centered Explainability for Multimodal AI Assistants",
    "authors": [
      "Elizabeth Anne Watkins",
      "Emanuel Moss",
      "Ramesh Manuvinakurike",
      "Meng Shi",
      "Richard Beckwith",
      "Giuseppe Raffa"
    ],
    "abstract": "In this short paper we address issues related to building multimodal AI\nsystems for human performance support in manufacturing domains. We make two\ncontributions: we first identify challenges of participatory design and\ntraining of such systems, and secondly, to address such challenges, we propose\nthe ACE paradigm: \"Action and Control via Explanations\". Specifically, we\nsuggest that LLMs can be used to produce explanations in the form of human\ninterpretable \"semantic frames\", which in turn enable end users to provide data\nthe AI system needs to align its multimodal models and representations,\nincluding computer vision, automatic speech recognition, and document inputs.\nACE, by using LLMs to \"explain\" using semantic frames, will help the human and\nthe AI system to collaborate, together building a more accurate model of humans\nactivities and behaviors, and ultimately more accurate predictive outputs for\nbetter task support, and better outcomes for human users performing manual\ntasks.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at Human-Centered Explainable AI workshop at CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.16466v1",
    "published_date": "2025-02-27 19:27:57 UTC",
    "updated_date": "2025-02-27 19:27:57 UTC"
  },
  {
    "arxiv_id": "2502.20475v2",
    "title": "Promote, Suppress, Iterate: How Language Models Answer One-to-Many Factual Queries",
    "authors": [
      "Tianyi Lorena Yan",
      "Robin Jia"
    ],
    "abstract": "To answer one-to-many factual queries (e.g., listing cities of a country), a\nlanguage model (LM) must simultaneously recall knowledge and avoid repeating\nprevious answers. How are these two subtasks implemented and integrated\ninternally? Across multiple datasets and models, we identify a\npromote-then-suppress mechanism: the model first recalls all answers, and then\nsuppresses previously generated ones. Specifically, LMs use both the subject\nand previous answer tokens to perform knowledge recall, with attention\npropagating subject information and MLPs promoting the answers. Then, attention\nattends to and suppresses previous answer tokens, while MLPs amplify the\nsuppression signal. Our mechanism is corroborated by extensive experimental\nevidence: in addition to using early decoding and causal tracing, we analyze\nhow components use different tokens by introducing both Token Lens, which\ndecodes aggregated attention updates from specified tokens, and a knockout\nmethod that analyzes changes in MLP outputs after removing attention to\nspecified tokens. Overall, we provide new insights into how LMs' internal\ncomponents interact with different input tokens to support complex factual\nrecall. Code is available at\nhttps://github.com/Lorenayannnnn/how-lms-answer-one-to-many-factual-queries.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20475v2",
    "published_date": "2025-02-27 19:23:15 UTC",
    "updated_date": "2025-03-05 13:22:47 UTC"
  },
  {
    "arxiv_id": "2503.01894v2",
    "title": "LIVS: A Pluralistic Alignment Dataset for Inclusive Public Spaces",
    "authors": [
      "Rashid Mushkani",
      "Shravan Nayak",
      "Hugo Berard",
      "Allison Cohen",
      "Shin Koseki",
      "Hadrien Bertrand"
    ],
    "abstract": "We introduce the Local Intersectional Visual Spaces (LIVS) dataset, a\nbenchmark for multi-criteria alignment, developed through a two-year\nparticipatory process with 30 community organizations to support the\npluralistic alignment of text-to-image (T2I) models in inclusive urban\nplanning. The dataset encodes 37,710 pairwise comparisons across 13,462 images,\nstructured along six criteria - Accessibility, Safety, Comfort, Invitingness,\nInclusivity, and Diversity - derived from 634 community-defined concepts. Using\nDirect Preference Optimization (DPO), we fine-tune Stable Diffusion XL to\nreflect multi-criteria spatial preferences and evaluate the LIVS dataset and\nthe fine-tuned model through four case studies: (1) DPO increases alignment\nwith annotated preferences, particularly when annotation volume is high; (2)\npreference patterns vary across participant identities, underscoring the need\nfor intersectional data; (3) human-authored prompts generate more distinctive\nvisual outputs than LLM-generated ones, influencing annotation decisiveness;\nand (4) intersectional groups assign systematically different ratings across\ncriteria, revealing the limitations of single-objective alignment. While DPO\nimproves alignment under specific conditions, the prevalence of neutral ratings\nindicates that community values are heterogeneous and often ambiguous. LIVS\nprovides a benchmark for developing T2I models that incorporate local,\nstakeholder-driven preferences, offering a foundation for context-aware\nalignment in spatial design.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01894v2",
    "published_date": "2025-02-27 19:18:37 UTC",
    "updated_date": "2025-05-08 03:50:30 UTC"
  },
  {
    "arxiv_id": "2502.20396v1",
    "title": "Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids",
    "authors": [
      "Toru Lin",
      "Kartik Sachdev",
      "Linxi Fan",
      "Jitendra Malik",
      "Yuke Zhu"
    ],
    "abstract": "Reinforcement learning has delivered promising results in achieving human- or\neven superhuman-level capabilities across diverse problem domains, but success\nin dexterous robot manipulation remains limited. This work investigates the key\nchallenges in applying reinforcement learning to solve a collection of\ncontact-rich manipulation tasks on a humanoid embodiment. We introduce novel\ntechniques to overcome the identified challenges with empirical validation. Our\nmain contributions include an automated real-to-sim tuning module that brings\nthe simulated environment closer to the real world, a generalized reward design\nscheme that simplifies reward engineering for long-horizon contact-rich\nmanipulation tasks, a divide-and-conquer distillation process that improves the\nsample efficiency of hard-exploration problems while maintaining sim-to-real\nperformance, and a mixture of sparse and dense object representations to bridge\nthe sim-to-real perception gap. We show promising results on three humanoid\ndexterous manipulation tasks, with ablation studies on each technique. Our work\npresents a successful approach to learning humanoid dexterous manipulation\nusing sim-to-real reinforcement learning, achieving robust generalization and\nhigh performance without the need for human demonstration.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page can be found at https://toruowo.github.io/recipe/",
    "pdf_url": "http://arxiv.org/pdf/2502.20396v1",
    "published_date": "2025-02-27 18:59:52 UTC",
    "updated_date": "2025-02-27 18:59:52 UTC"
  },
  {
    "arxiv_id": "2502.20393v1",
    "title": "Walking the Web of Concept-Class Relationships in Incrementally Trained Interpretable Models",
    "authors": [
      "Susmit Agrawal",
      "Deepika Vemuri",
      "Sri Siddarth Chakaravarthy P",
      "Vineeth N. Balasubramanian"
    ],
    "abstract": "Concept-based methods have emerged as a promising direction to develop\ninterpretable neural networks in standard supervised settings. However, most\nworks that study them in incremental settings assume either a static concept\nset across all experiences or assume that each experience relies on a distinct\nset of concepts. In this work, we study concept-based models in a more\nrealistic, dynamic setting where new classes may rely on older concepts in\naddition to introducing new concepts themselves. We show that concepts and\nclasses form a complex web of relationships, which is susceptible to\ndegradation and needs to be preserved and augmented across experiences. We\nintroduce new metrics to show that existing concept-based models cannot\npreserve these relationships even when trained using methods to prevent\ncatastrophic forgetting, since they cannot handle forgetting at concept, class,\nand concept-class relationship levels simultaneously. To address these issues,\nwe propose a novel method - MuCIL - that uses multimodal concepts to perform\nclassification without increasing the number of trainable parameters across\nexperiences. The multimodal concepts are aligned to concepts provided in\nnatural language, making them interpretable by design. Through extensive\nexperimentation, we show that our approach obtains state-of-the-art\nclassification performance compared to other concept-based models, achieving\nover 2$\\times$ the classification performance in some cases. We also study the\nability of our model to perform interventions on concepts, and show that it can\nlocalize visual concepts in input images, providing post-hoc interpretations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages of main text, 6 figures in main text, 11 pages of Appendix,\n  published in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.20393v1",
    "published_date": "2025-02-27 18:59:29 UTC",
    "updated_date": "2025-02-27 18:59:29 UTC"
  },
  {
    "arxiv_id": "2502.20432v2",
    "title": "Large Language Model Strategic Reasoning Evaluation through Behavioral Game Theory",
    "authors": [
      "Jingru Jia",
      "Zehua Yuan",
      "Junhao Pan",
      "Paul E. McNamara",
      "Deming Chen"
    ],
    "abstract": "Strategic decision-making involves interactive reasoning where agents adapt\ntheir choices in response to others, yet existing evaluations of large language\nmodels (LLMs) often emphasize Nash Equilibrium (NE) approximation, overlooking\nthe mechanisms driving their strategic choices. To bridge this gap, we\nintroduce an evaluation framework grounded in behavioral game theory,\ndisentangling reasoning capability from contextual effects. Testing 22\nstate-of-the-art LLMs, we find that GPT-o3-mini, GPT-o1, and DeepSeek-R1\ndominate most games yet also demonstrate that the model scale alone does not\ndetermine performance. In terms of prompting enhancement, Chain-of-Thought\n(CoT) prompting is not universally effective, as it increases strategic\nreasoning only for models at certain levels while providing limited gains\nelsewhere. Additionally, we investigate the impact of encoded demographic\nfeatures on the models, observing that certain assignments impact the\ndecision-making pattern. For instance, GPT-4o shows stronger strategic\nreasoning with female traits than males, while Gemma assigns higher reasoning\nlevels to heterosexual identities compared to other sexual orientations,\nindicating inherent biases. These findings underscore the need for ethical\nstandards and contextual alignment to balance improved reasoning with fairness.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "*Co-first author: Jingru Jia, Zehua Yuan",
    "pdf_url": "http://arxiv.org/pdf/2502.20432v2",
    "published_date": "2025-02-27 18:58:31 UTC",
    "updated_date": "2025-03-13 17:59:08 UTC"
  },
  {
    "arxiv_id": "2502.20382v1",
    "title": "Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization",
    "authors": [
      "Lujie Yang",
      "H. J. Terry Suh",
      "Tong Zhao",
      "Bernhard Paus Graesdal",
      "Tarik Kelestemur",
      "Jiuguang Wang",
      "Tao Pang",
      "Russ Tedrake"
    ],
    "abstract": "We present a low-cost data generation pipeline that integrates physics-based\nsimulation, human demonstrations, and model-based planning to efficiently\ngenerate large-scale, high-quality datasets for contact-rich robotic\nmanipulation tasks. Starting with a small number of embodiment-flexible human\ndemonstrations collected in a virtual reality simulation environment, the\npipeline refines these demonstrations using optimization-based kinematic\nretargeting and trajectory optimization to adapt them across various robot\nembodiments and physical parameters. This process yields a diverse, physically\nconsistent dataset that enables cross-embodiment data transfer, and offers the\npotential to reuse legacy datasets collected under different hardware\nconfigurations or physical parameters. We validate the pipeline's effectiveness\nby training diffusion policies from the generated datasets for challenging\ncontact-rich manipulation tasks across multiple robot embodiments, including a\nfloating Allegro hand and bimanual robot arms. The trained policies are\ndeployed zero-shot on hardware for bimanual iiwa arms, achieving high success\nrates with minimal human input. Project website:\nhttps://lujieyang.github.io/physicsgen/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20382v1",
    "published_date": "2025-02-27 18:56:01 UTC",
    "updated_date": "2025-02-27 18:56:01 UTC"
  },
  {
    "arxiv_id": "2502.20380v1",
    "title": "Multi-Turn Code Generation Through Single-Step Rewards",
    "authors": [
      "Arnav Kumar Jain",
      "Gonzalo Gonzalez-Pumariega",
      "Wayne Chen",
      "Alexander M Rush",
      "Wenting Zhao",
      "Sanjiban Choudhury"
    ],
    "abstract": "We address the problem of code generation from multi-turn execution feedback.\nExisting methods either generate code without feedback or use complex,\nhierarchical reinforcement learning to optimize multi-turn rewards. We propose\na simple yet scalable approach, $\\mu$Code, that solves multi-turn code\ngeneration using only single-step rewards. Our key insight is that code\ngeneration is a one-step recoverable MDP, where the correct code can be\nrecovered from any intermediate code state in a single turn. $\\mu$Code\niteratively trains both a generator to provide code solutions conditioned on\nmulti-turn execution feedback and a verifier to score the newly generated code.\nExperimental evaluations show that our approach achieves significant\nimprovements over the state-of-the-art baselines. We provide analysis of the\ndesign choices of the reward models and policy, and show the efficacy of\n$\\mu$Code at utilizing the execution feedback. Our code is available at\nhttps://github.com/portal-cornell/muCode.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages (not including references or appendix); 6 figures (in main\n  paper); (v1) preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.20380v1",
    "published_date": "2025-02-27 18:55:05 UTC",
    "updated_date": "2025-02-27 18:55:05 UTC"
  },
  {
    "arxiv_id": "2502.20379v1",
    "title": "Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers",
    "authors": [
      "Shalev Lifshitz",
      "Sheila A. McIlraith",
      "Yilun Du"
    ],
    "abstract": "By utilizing more computational resources at test-time, large language models\n(LLMs) can improve without additional training. One common strategy uses\nverifiers to evaluate candidate outputs. In this work, we propose a novel\nscaling dimension for test-time compute: scaling the number of verifiers. We\nintroduce Multi-Agent Verification (MAV) as a test-time compute paradigm that\ncombines multiple verifiers to improve performance. We propose using Aspect\nVerifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of\noutputs, as one possible choice for the verifiers in a MAV system. AVs are a\nconvenient building block for MAV since they can be easily combined without\nadditional training. Moreover, we introduce BoN-MAV, a simple multi-agent\nverification algorithm that combines best-of-n sampling with multiple\nverifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency\nand reward model verification, and we demonstrate both weak-to-strong\ngeneralization, where combining weak verifiers improves even stronger LLMs, and\nself-improvement, where the same base model is used to both generate and verify\noutputs. Our results establish scaling the number of verifiers as a promising\nnew dimension for improving language model performance at test-time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20379v1",
    "published_date": "2025-02-27 18:53:30 UTC",
    "updated_date": "2025-02-27 18:53:30 UTC"
  },
  {
    "arxiv_id": "2502.20377v1",
    "title": "PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation",
    "authors": [
      "Albert Gong",
      "Kamilƒó Stankeviƒçi≈´tƒó",
      "Chao Wan",
      "Anmol Kabra",
      "Raphael Thesmar",
      "Johann Lee",
      "Julius Klenke",
      "Carla P. Gomes",
      "Kilian Q. Weinberger"
    ],
    "abstract": "High-quality benchmarks are essential for evaluating reasoning and retrieval\ncapabilities of large language models (LLMs). However, curating datasets for\nthis purpose is not a permanent solution as they are prone to data leakage and\ninflated performance results. To address these challenges, we propose\nPhantomWiki: a pipeline to generate unique, factually consistent document\ncorpora with diverse question-answer pairs. Unlike prior work, PhantomWiki is\nneither a fixed dataset, nor is it based on any existing data. Instead, a new\nPhantomWiki instance is generated on demand for each evaluation. We vary the\nquestion difficulty and corpus size to disentangle reasoning and retrieval\ncapabilities respectively, and find that PhantomWiki datasets are surprisingly\nchallenging for frontier LLMs. Thus, we contribute a scalable and data\nleakage-resistant framework for disentangled evaluation of reasoning,\nretrieval, and tool-use abilities. Our code is available at\nhttps://github.com/kilian-group/phantom-wiki.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20377v1",
    "published_date": "2025-02-27 18:51:22 UTC",
    "updated_date": "2025-02-27 18:51:22 UTC"
  },
  {
    "arxiv_id": "2502.20364v2",
    "title": "Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization",
    "authors": [
      "Ryan C. Barron",
      "Maksim E. Eren",
      "Olga M. Serafimova",
      "Cynthia Matuszek",
      "Boian S. Alexandrov"
    ],
    "abstract": "Agentic Generative AI, powered by Large Language Models (LLMs) with\nRetrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores\n(VSs), represents a transformative technology applicable to specialized domains\nsuch as legal systems, research, recommender systems, cybersecurity, and global\nsecurity, including proliferation research. This technology excels at inferring\nrelationships within vast unstructured or semi-structured datasets. The legal\ndomain here comprises complex data characterized by extensive, interrelated,\nand semi-structured knowledge systems with complex relations. It comprises\nconstitutions, statutes, regulations, and case law. Extracting insights and\nnavigating the intricate networks of legal documents and their relations is\ncrucial for effective legal research. Here, we introduce a generative AI system\nthat integrates RAG, VS, and KG, constructed via Non-Negative Matrix\nFactorization (NMF), to enhance legal information retrieval and AI reasoning\nand minimize hallucinations. In the legal system, these technologies empower AI\nagents to identify and analyze complex connections among cases, statutes, and\nlegal precedents, uncovering hidden relationships and predicting legal\ntrends-challenging tasks that are essential for ensuring justice and improving\noperational efficiency. Our system employs web scraping techniques to\nsystematically collect legal texts, such as statutes, constitutional\nprovisions, and case law, from publicly accessible platforms like Justia. It\nbridges the gap between traditional keyword-based searches and contextual\nunderstanding by leveraging advanced semantic representations, hierarchical\nrelationships, and latent topic discovery. This framework supports legal\ndocument clustering, summarization, and cross-referencing, for scalable,\ninterpretable, and accurate retrieval for semi-structured data while advancing\ncomputational law and AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20364v2",
    "published_date": "2025-02-27 18:35:39 UTC",
    "updated_date": "2025-05-09 00:25:09 UTC"
  },
  {
    "arxiv_id": "2502.20356v1",
    "title": "Bridging the Creativity Understanding Gap: Small-Scale Human Alignment Enables Expert-Level Humor Ranking in LLMs",
    "authors": [
      "Kuan Lok Zhou",
      "Jiayi Chen",
      "Siddharth Suresh",
      "Reuben Narad",
      "Timothy T. Rogers",
      "Lalit K Jain",
      "Robert D Nowak",
      "Bob Mankoff",
      "Jifan Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have shown significant limitations in\nunderstanding creative content, as demonstrated by Hessel et al. (2023)'s\ninfluential work on the New Yorker Cartoon Caption Contest (NYCCC). Their study\nexposed a substantial gap between LLMs and humans in humor comprehension,\nestablishing that understanding and evaluating creative content is key\nchallenge in AI development. We revisit this challenge by decomposing humor\nunderstanding into three components and systematically improve each: enhancing\nvisual understanding through improved annotation, utilizing LLM-generated humor\nreasoning and explanations, and implementing targeted alignment with human\npreference data. Our refined approach achieves 82.4% accuracy in caption\nranking, singificantly improving upon the previous 67% benchmark and matching\nthe performance of world-renowned human experts in this domain. Notably, while\nattempts to mimic subgroup preferences through various persona prompts showed\nminimal impact, model finetuning with crowd preferences proved remarkably\neffective. These findings reveal that LLM limitations in creative judgment can\nbe effectively addressed through focused alignment to specific subgroups and\nindividuals. Lastly, we propose the position that achieving artificial general\nintelligence necessitates systematic collection of human preference data across\ncreative domains. We advocate that just as human creativity is deeply\ninfluenced by individual and cultural preferences, training LLMs with diverse\nhuman preference data may be essential for developing true creative\nunderstanding.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20356v1",
    "published_date": "2025-02-27 18:29:09 UTC",
    "updated_date": "2025-02-27 18:29:09 UTC"
  },
  {
    "arxiv_id": "2502.20354v1",
    "title": "Towards Responsible AI in Education: Hybrid Recommendation System for K-12 Students Case Study",
    "authors": [
      "Nazarii Drushchak",
      "Vladyslava Tyshchenko",
      "Nataliya Polyakovska"
    ],
    "abstract": "The growth of Educational Technology (EdTech) has enabled highly personalized\nlearning experiences through Artificial Intelligence (AI)-based recommendation\nsystems tailored to each student needs. However, these systems can\nunintentionally introduce biases, potentially limiting fair access to learning\nresources. This study presents a recommendation system for K-12 students,\ncombining graph-based modeling and matrix factorization to provide personalized\nsuggestions for extracurricular activities, learning resources, and\nvolunteering opportunities. To address fairness concerns, the system includes a\nframework to detect and reduce biases by analyzing feedback across protected\nstudent groups. This work highlights the need for continuous monitoring in\neducational recommendation systems to support equitable, transparent, and\neffective learning opportunities for all students.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20354v1",
    "published_date": "2025-02-27 18:27:30 UTC",
    "updated_date": "2025-02-27 18:27:30 UTC"
  },
  {
    "arxiv_id": "2502.20349v1",
    "title": "Naturalistic Computational Cognitive Science: Towards generalizable models and theories that capture the full range of natural behavior",
    "authors": [
      "Wilka Carvalho",
      "Andrew Lampinen"
    ],
    "abstract": "Artificial Intelligence increasingly pursues large, complex models that\nperform many tasks within increasingly realistic domains. How, if at all,\nshould these developments in AI influence cognitive science?\n  We argue that progress in AI offers timely opportunities for cognitive\nscience to embrace experiments with increasingly naturalistic stimuli, tasks,\nand behaviors; and computational models that can accommodate these changes. We\nfirst review a growing body of research spanning neuroscience, cognitive\nscience, and AI that suggests that incorporating a broader range of\nnaturalistic experimental paradigms (and models that accommodate them) may be\nnecessary to resolve some aspects of natural intelligence and ensure that our\ntheories generalize. We then suggest that integrating recent progress in AI and\ncognitive science will enable us to engage with more naturalistic phenomena\nwithout giving up experimental control or the pursuit of theoretically grounded\nunderstanding. We offer practical guidance on how methodological practices can\ncontribute to cumulative progress in naturalistic computational cognitive\nscience, and illustrate a path towards building computational models that solve\nthe real problems of natural cognition - together with a reductive\nunderstanding of the processes and principles by which they do so.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20349v1",
    "published_date": "2025-02-27 18:20:54 UTC",
    "updated_date": "2025-02-27 18:20:54 UTC"
  },
  {
    "arxiv_id": "2502.20339v1",
    "title": "Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners",
    "authors": [
      "Daniele Paliotta",
      "Junxiong Wang",
      "Matteo Pagliardini",
      "Kevin Y. Li",
      "Aviv Bick",
      "J. Zico Kolter",
      "Albert Gu",
      "Fran√ßois Fleuret",
      "Tri Dao"
    ],
    "abstract": "Recent advancements have demonstrated that the performance of large language\nmodels (LLMs) can be significantly enhanced by scaling computational resources\nat test time. A common strategy involves generating multiple Chain-of-Thought\n(CoT) trajectories and aggregating their outputs through various selection\nmechanisms. This raises a fundamental question: can models with lower\ncomplexity leverage their superior generation throughput to outperform\nsimilarly sized Transformers for a fixed computational budget? To address this\nquestion and overcome the lack of strong subquadratic reasoners, we distill\npure and hybrid Mamba models from pretrained Transformers. Trained on only 8\nbillion tokens, our distilled models show strong performance and scaling on\nmathematical reasoning datasets while being much faster at inference for large\nbatches and long sequences. Despite the zero-shot performance hit due to\ndistillation, both pure and hybrid Mamba models can scale their coverage and\naccuracy performance past their Transformer teacher models under fixed time\nbudgets, opening a new direction for scaling inference compute.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20339v1",
    "published_date": "2025-02-27 18:08:16 UTC",
    "updated_date": "2025-02-27 18:08:16 UTC"
  },
  {
    "arxiv_id": "2502.20335v1",
    "title": "Expertise Is What We Want",
    "authors": [
      "Alan Ashworth",
      "Munir Al-Dajani",
      "Keegan Duchicela",
      "Kiril Kafadarov",
      "Allison Kurian",
      "Othman Laraki",
      "Amina Lazrak",
      "Divneet Mandair",
      "Wendy McKennon",
      "Rebecca Miksad",
      "Jayodita Sanghvi",
      "Travis Zack"
    ],
    "abstract": "Clinical decision-making depends on expert reasoning, which is guided by\nstandardized, evidence-based guidelines. However, translating these guidelines\ninto automated clinical decision support systems risks inaccuracy and\nimportantly, loss of nuance. We share an application architecture, the Large\nLanguage Expert (LLE), that combines the flexibility and power of Large\nLanguage Models (LLMs) with the interpretability, explainability, and\nreliability of Expert Systems. LLMs help address key challenges of Expert\nSystems, such as integrating and codifying knowledge, and data normalization.\nConversely, an Expert System-like approach helps overcome challenges with LLMs,\nincluding hallucinations, atomic and inexpensive updates, and testability.\n  To highlight the power of the Large Language Expert (LLE) system, we built an\nLLE to assist with the workup of patients newly diagnosed with cancer. Timely\ninitiation of cancer treatment is critical for optimal patient outcomes.\nHowever, increasing complexity in diagnostic recommendations has made it\ndifficult for primary care physicians to ensure their patients have completed\nthe necessary workup before their first visit with an oncologist. As with many\nreal-world clinical tasks, these workups require the analysis of unstructured\nhealth records and the application of nuanced clinical decision logic. In this\nstudy, we describe the design & evaluation of an LLE system built to rapidly\nidentify and suggest the correct diagnostic workup. The system demonstrated a\nhigh degree of clinical-level accuracy (>95%) and effectively addressed gaps\nidentified in real-world data from breast and colon cancer patients at a large\nacademic center.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; J.3"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 7 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20335v1",
    "published_date": "2025-02-27 18:05:15 UTC",
    "updated_date": "2025-02-27 18:05:15 UTC"
  },
  {
    "arxiv_id": "2502.20332v1",
    "title": "Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models",
    "authors": [
      "Yukang Yang",
      "Declan Campbell",
      "Kaixuan Huang",
      "Mengdi Wang",
      "Jonathan Cohen",
      "Taylor Webb"
    ],
    "abstract": "Many recent studies have found evidence for emergent reasoning capabilities\nin large language models, but debate persists concerning the robustness of\nthese capabilities, and the extent to which they depend on structured reasoning\nmechanisms. To shed light on these issues, we perform a comprehensive study of\nthe internal mechanisms that support abstract rule induction in an open-source\nlanguage model (Llama3-70B). We identify an emergent symbolic architecture that\nimplements abstract reasoning via a series of three computations. In early\nlayers, symbol abstraction heads convert input tokens to abstract variables\nbased on the relations between those tokens. In intermediate layers, symbolic\ninduction heads perform sequence induction over these abstract variables.\nFinally, in later layers, retrieval heads predict the next token by retrieving\nthe value associated with the predicted abstract variable. These results point\ntoward a resolution of the longstanding debate between symbolic and neural\nnetwork approaches, suggesting that emergent reasoning in neural networks\ndepends on the emergence of symbolic mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20332v1",
    "published_date": "2025-02-27 18:02:15 UTC",
    "updated_date": "2025-02-27 18:02:15 UTC"
  },
  {
    "arxiv_id": "2502.20326v1",
    "title": "Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application",
    "authors": [
      "Thomas Hickling",
      "Maxwell Hogan",
      "Abdulla Tammam",
      "Nabil Aouf"
    ],
    "abstract": "This paper proposes a holistic framework for autonomous guidance, navigation,\nand task distribution among multi-drone systems operating in Global Navigation\nSatellite System (GNSS)-denied indoor settings. We advocate for a Deep\nReinforcement Learning (DRL)-based guidance mechanism, utilising the Twin\nDelayed Deep Deterministic Policy Gradient algorithm. To improve the efficiency\nof the training process, we incorporate an Artificial Potential Field\n(APF)-based reward structure, enabling the agent to refine its movements,\nthereby promoting smoother paths and enhanced obstacle avoidance in indoor\ncontexts. Furthermore, we tackle the issue of task distribution among\ncooperative UAVs through a DRL-trained Graph Convolutional Network (GCN). This\nGCN represents the interactions between drones and tasks, facilitating dynamic\nand real-time task allocation that reflects the current environmental\nconditions and the capabilities of the drones. Such an approach fosters\neffective coordination and collaboration among multiple drones during search\nand rescue operations or other exploratory endeavours. Lastly, to ensure\nprecise odometry in environments lacking GNSS, we employ Light Detection And\nRanging Simultaneous Localisation and Mapping complemented by a depth camera to\nmitigate the hallway problem. This integration offers robust localisation and\nmapping functionalities, thereby enhancing the systems dependability in indoor\nnavigation. The proposed multi-drone framework not only elevates individual\nnavigation capabilities but also optimises coordinated task allocation in\ncomplex, obstacle-laden environments. Experimental evaluations conducted in a\nsetup tailored to meet the requirements of the NATO Sapience Autonomous\nCooperative Drone Competition demonstrate the efficacy of the proposed system,\nyielding outstanding results and culminating in a first-place finish in the\n2024 Sapience competition.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "18 Pages, 21 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20326v1",
    "published_date": "2025-02-27 17:53:16 UTC",
    "updated_date": "2025-02-27 17:53:16 UTC"
  },
  {
    "arxiv_id": "2502.20321v2",
    "title": "UniTok: A Unified Tokenizer for Visual Generation and Understanding",
    "authors": [
      "Chuofan Ma",
      "Yi Jiang",
      "Junfeng Wu",
      "Jihan Yang",
      "Xin Yu",
      "Zehuan Yuan",
      "Bingyue Peng",
      "Xiaojuan Qi"
    ],
    "abstract": "Visual generative and understanding models typically rely on distinct\ntokenizers to process images, presenting a key challenge for unifying them\nwithin a single framework. Recent studies attempt to address this by connecting\nthe training of VQVAE (for autoregressive generation) and CLIP (for\nunderstanding) to build a unified tokenizer. However, directly combining these\ntraining objectives has been observed to cause severe loss conflicts. In this\npaper, we show that reconstruction and semantic supervision do not inherently\nconflict. Instead, the underlying bottleneck stems from limited\nrepresentational capacity of discrete token space. Building on these insights,\nwe introduce UniTok, a unified tokenizer featuring a novel multi-codebook\nquantization mechanism that effectively scales up the vocabulary size and\nbottleneck dimension. In terms of final performance, UniTok sets a new record\nof 0.38 rFID and 78.6% zero-shot accuracy on ImageNet. Besides, UniTok can be\nseamlessly integrated into MLLMs to unlock native visual generation capability,\nwithout compromising the understanding performance. Additionally, we show that\nUniTok favors cfg-free generation, reducing gFID from 14.6 to 2.5 on ImageNet\n256$\\times$256 benchmark. GitHub: https://github.com/FoundationVision/UniTok.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20321v2",
    "published_date": "2025-02-27 17:47:01 UTC",
    "updated_date": "2025-05-19 12:45:03 UTC"
  },
  {
    "arxiv_id": "2502.20317v3",
    "title": "Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases",
    "authors": [
      "Yongjia Lei",
      "Haoyu Han",
      "Ryan A. Rossi",
      "Franck Dernoncourt",
      "Nedim Lipka",
      "Mahantesh M Halappanavar",
      "Jiliang Tang",
      "Yu Wang"
    ],
    "abstract": "Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for\nanswering queries by providing textual and structural knowledge. However,\ncurrent retrieval methods often retrieve these two types of knowledge in\nisolation without considering their mutual reinforcement and some hybrid\nmethods even bypass structural retrieval entirely after neighboring\naggregation. To fill in this gap, we propose a Mixture of\nStructural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge\nvia a Planning-Reasoning-Organizing framework. In the Planning stage, MoR\ngenerates textual planning graphs delineating the logic for answering queries.\nFollowing planning graphs, in the Reasoning stage, MoR interweaves structural\ntraversal and textual matching to obtain candidates from TG-KBs. In the\nOrganizing stage, MoR further reranks fetched candidates based on their\nstructural trajectory. Extensive experiments demonstrate the superiority of MoR\nin harmonizing structural and textual retrieval with insights, including uneven\nretrieving performance across different query logics and the benefits of\nintegrating structural trajectories for candidate reranking. Our code is\navailable at https://github.com/Yoega/MoR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20317v3",
    "published_date": "2025-02-27 17:42:52 UTC",
    "updated_date": "2025-03-10 14:43:15 UTC"
  },
  {
    "arxiv_id": "2502.20316v1",
    "title": "Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds",
    "authors": [
      "Mohamed Abdelsamad",
      "Michael Ulrich",
      "Claudius Gl√§ser",
      "Abhinav Valada"
    ],
    "abstract": "Masked autoencoders (MAE) have shown tremendous potential for self-supervised\nlearning (SSL) in vision and beyond. However, point clouds from LiDARs used in\nautomated driving are particularly challenging for MAEs since large areas of\nthe 3D volume are empty. Consequently, existing work suffers from leaking\noccupancy information into the decoder and has significant computational\ncomplexity, thereby limiting the SSL pre-training to only 2D bird's eye view\nencoders in practice. In this work, we propose the novel neighborhood occupancy\nMAE (NOMAE) that overcomes the aforementioned challenges by employing masked\noccupancy reconstruction only in the neighborhood of non-masked voxels. We\nincorporate voxel masking and occupancy reconstruction at multiple scales with\nour proposed hierarchical mask generation technique to capture features of\nobjects of different sizes in the point cloud. NOMAEs are extremely flexible\nand can be directly employed for SSL in existing 3D architectures. We perform\nextensive evaluations on the nuScenes and Waymo Open datasets for the\ndownstream perception tasks of semantic segmentation and 3D object detection,\ncomparing with both discriminative and generative SSL methods. The results\ndemonstrate that NOMAE sets the new state-of-the-art on multiple benchmarks for\nmultiple point cloud perception tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20316v1",
    "published_date": "2025-02-27 17:42:47 UTC",
    "updated_date": "2025-02-27 17:42:47 UTC"
  },
  {
    "arxiv_id": "2502.20315v1",
    "title": "LangProBe: a Language Programs Benchmark",
    "authors": [
      "Shangyin Tan",
      "Lakshya A Agrawal",
      "Arnav Singhvi",
      "Liheng Lai",
      "Michael J Ryan",
      "Dan Klein",
      "Omar Khattab",
      "Koushik Sen",
      "Matei Zaharia"
    ],
    "abstract": "Composing language models (LMs) into multi-step language programs and\nautomatically optimizing their modular prompts is now a mainstream paradigm for\nbuilding AI systems, but the tradeoffs in this space have only scarcely been\nstudied before. We introduce LangProBe, the first large-scale benchmark for\nevaluating the architectures and optimization strategies for language programs,\nwith over 2000 combinations of tasks, architectures, optimizers, and choices of\nLMs. Using LangProBe, we are the first to study the impact of program\narchitectures and optimizers (and their compositions together and with\ndifferent models) on tradeoffs of quality and cost. We find that optimized\nlanguage programs offer strong cost--quality Pareto improvement over raw calls\nto models, but simultaneously demonstrate that human judgment (or empirical\ndecisions) about which compositions to pursue is still necessary for best\nperformance. We will open source the code and evaluation data for LangProBe.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20315v1",
    "published_date": "2025-02-27 17:41:49 UTC",
    "updated_date": "2025-02-27 17:41:49 UTC"
  },
  {
    "arxiv_id": "2502.20309v1",
    "title": "EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants",
    "authors": [
      "Franck Cappello",
      "Sandeep Madireddy",
      "Robert Underwood",
      "Neil Getty",
      "Nicholas Lee-Ping Chia",
      "Nesar Ramachandra",
      "Josh Nguyen",
      "Murat Keceli",
      "Tanwi Mallick",
      "Zilinghan Li",
      "Marieme Ngom",
      "Chenhui Zhang",
      "Angel Yanguas-Gil",
      "Evan Antoniuk",
      "Bhavya Kailkhura",
      "Minyang Tian",
      "Yufeng Du",
      "Yuan-Sen Ting",
      "Azton Wells",
      "Bogdan Nicolae",
      "Avinash Maurya",
      "M. Mustafa Rafique",
      "Eliu Huerta",
      "Bo Li",
      "Ian Foster",
      "Rick Stevens"
    ],
    "abstract": "Recent advancements have positioned AI, and particularly Large Language\nModels (LLMs), as transformative tools for scientific research, capable of\naddressing complex tasks that require reasoning, problem-solving, and\ndecision-making. Their exceptional capabilities suggest their potential as\nscientific research assistants but also highlight the need for holistic,\nrigorous, and domain-specific evaluation to assess effectiveness in real-world\nscientific applications. This paper describes a multifaceted methodology for\nEvaluating AI models as scientific Research Assistants (EAIRA) developed at\nArgonne National Laboratory. This methodology incorporates four primary classes\nof evaluations. 1) Multiple Choice Questions to assess factual recall; 2) Open\nResponse to evaluate advanced reasoning and problem-solving skills; 3)\nLab-Style Experiments involving detailed analysis of capabilities as research\nassistants in controlled environments; and 4) Field-Style Experiments to\ncapture researcher-LLM interactions at scale in a wide range of scientific\ndomains and applications. These complementary methods enable a comprehensive\nanalysis of LLM strengths and weaknesses with respect to their scientific\nknowledge, reasoning abilities, and adaptability. Recognizing the rapid pace of\nLLM advancements, we designed the methodology to evolve and adapt so as to\nensure its continued relevance and applicability. This paper describes the\nmethodology state at the end of February 2025. Although developed within a\nsubset of scientific domains, the methodology is designed to be generalizable\nto a wide range of scientific domains.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20309v1",
    "published_date": "2025-02-27 17:35:57 UTC",
    "updated_date": "2025-02-27 17:35:57 UTC"
  },
  {
    "arxiv_id": "2502.20301v1",
    "title": "M^3Builder: A Multi-Agent System for Automated Machine Learning in Medical Imaging",
    "authors": [
      "Jinghao Feng",
      "Qiaoyu Zheng",
      "Chaoyi Wu",
      "Ziheng Zhao",
      "Ya Zhang",
      "Yanfeng Wang",
      "Weidi Xie"
    ],
    "abstract": "Agentic AI systems have gained significant attention for their ability to\nautonomously perform complex tasks. However, their reliance on well-prepared\ntools limits their applicability in the medical domain, which requires to train\nspecialized models. In this paper, we make three contributions: (i) We present\nM3Builder, a novel multi-agent system designed to automate machine learning\n(ML) in medical imaging. At its core, M3Builder employs four specialized agents\nthat collaborate to tackle complex, multi-step medical ML workflows, from\nautomated data processing and environment configuration to self-contained auto\ndebugging and model training. These agents operate within a medical imaging ML\nworkspace, a structured environment designed to provide agents with free-text\ndescriptions of datasets, training codes, and interaction tools, enabling\nseamless communication and task execution. (ii) To evaluate progress in\nautomated medical imaging ML, we propose M3Bench, a benchmark comprising four\ngeneral tasks on 14 training datasets, across five anatomies and three imaging\nmodalities, covering both 2D and 3D data. (iii) We experiment with seven\nstate-of-the-art large language models serving as agent cores for our system,\nsuch as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic\ndesigns, M3Builder shows superior performance on completing ML tasks in medical\nimaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent\ncore, showing huge potential towards fully automated machine learning in\nmedical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "38 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20301v1",
    "published_date": "2025-02-27 17:29:46 UTC",
    "updated_date": "2025-02-27 17:29:46 UTC"
  },
  {
    "arxiv_id": "2502.20299v1",
    "title": "An exploration of features to improve the generalisability of fake news detection models",
    "authors": [
      "Nathaniel Hoy",
      "Theodora Koulouri"
    ],
    "abstract": "Fake news poses global risks by influencing elections and spreading\nmisinformation, making detection critical. Existing NLP and supervised Machine\nLearning methods perform well under cross-validation but struggle to generalise\nacross datasets, even within the same domain. This issue stems from coarsely\nlabelled training data, where articles are labelled based on their publisher,\nintroducing biases that token-based models like TF-IDF and BERT are sensitive\nto. While Large Language Models (LLMs) offer promise, their application in fake\nnews detection remains limited. This study demonstrates that meaningful\nfeatures can still be extracted from coarsely labelled data to improve\nreal-world robustness. Stylistic features-lexical, syntactic, and semantic-are\nexplored due to their reduced sensitivity to dataset biases. Additionally,\nnovel social-monetisation features are introduced, capturing economic\nincentives behind fake news, such as advertisements, external links, and social\nmedia elements. The study trains on the coarsely labelled NELA 2020-21 dataset\nand evaluates using the manually labelled Facebook URLs dataset, a gold\nstandard for generalisability. Results highlight the limitations of token-based\nmodels trained on biased data and contribute to the scarce evidence on LLMs\nlike LLaMa in this field. Findings indicate that stylistic and\nsocial-monetisation features offer more generalisable predictions than\ntoken-based methods and LLMs. Statistical and permutation feature importance\nanalyses further reveal their potential to enhance performance and mitigate\ndataset biases, providing a path forward for improving fake news detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at Expert Systems with Applications (Elsevier)",
    "pdf_url": "http://arxiv.org/pdf/2502.20299v1",
    "published_date": "2025-02-27 17:26:56 UTC",
    "updated_date": "2025-02-27 17:26:56 UTC"
  },
  {
    "arxiv_id": "2502.20295v1",
    "title": "Judge a Book by its Cover: Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription",
    "authors": [
      "Benjamin Gutteridge",
      "Matthew Thomas Jackson",
      "Toni Kukurin",
      "Xiaowen Dong"
    ],
    "abstract": "Handwritten text recognition (HTR) remains a challenging task, particularly\nfor multi-page documents where pages share common formatting and contextual\nfeatures. While modern optical character recognition (OCR) engines are\nproficient with printed text, their performance on handwriting is limited,\noften requiring costly labeled data for fine-tuning. In this paper, we explore\nthe use of multi-modal large language models (MLLMs) for transcribing\nmulti-page handwritten documents in a zero-shot setting. We investigate various\nconfigurations of commercial OCR engines and MLLMs, utilizing the latter both\nas end-to-end transcribers and as post-processors, with and without image\ncomponents. We propose a novel method, '+first page', which enhances MLLM\ntranscription by providing the OCR output of the entire document along with\njust the first page image. This approach leverages shared document features\nwithout incurring the high cost of processing all images. Experiments on a\nmulti-page version of the IAM Handwriting Database demonstrate that '+first\npage' improves transcription accuracy, balances cost with performance, and even\nenhances results on out-of-sample text by extrapolating formatting and OCR\nerror patterns from a single page.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages (including references and appendix), 14 figures, accepted at\n  AAAI-25 Workshop on Document Understanding and Intelligence, non-archival",
    "pdf_url": "http://arxiv.org/pdf/2502.20295v1",
    "published_date": "2025-02-27 17:21:18 UTC",
    "updated_date": "2025-02-27 17:21:18 UTC"
  },
  {
    "arxiv_id": "2502.20284v1",
    "title": "Evaluating Human Trust in LLM-Based Planners: A Preliminary Study",
    "authors": [
      "Shenghui Chen",
      "Yunhao Yang",
      "Kayla Boggess",
      "Seongkook Heo",
      "Lu Feng",
      "Ufuk Topcu"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used for planning tasks,\noffering unique capabilities not found in classical planners such as generating\nexplanations and iterative refinement. However, trust--a critical factor in the\nadoption of planning systems--remains underexplored in the context of LLM-based\nplanning tasks. This study bridges this gap by comparing human trust in\nLLM-based planners with classical planners through a user study in a Planning\nDomain Definition Language (PDDL) domain. Combining subjective measures, such\nas trust questionnaires, with objective metrics like evaluation accuracy, our\nfindings reveal that correctness is the primary driver of trust and\nperformance. Explanations provided by the LLM improved evaluation accuracy but\nhad limited impact on trust, while plan refinement showed potential for\nincreasing trust without significantly enhancing evaluation accuracy.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20284v1",
    "published_date": "2025-02-27 17:10:52 UTC",
    "updated_date": "2025-02-27 17:10:52 UTC"
  },
  {
    "arxiv_id": "2502.20277v1",
    "title": "Explainable, Multi-modal Wound Infection Classification from Images Augmented with Generated Captions",
    "authors": [
      "Palawat Busaranuvong",
      "Emmanuel Agu",
      "Reza Saadati Fard",
      "Deepak Kumar",
      "Shefalika Gautam",
      "Bengisu Tulu",
      "Diane Strong"
    ],
    "abstract": "Infections in Diabetic Foot Ulcers (DFUs) can cause severe complications,\nincluding tissue death and limb amputation, highlighting the need for accurate,\ntimely diagnosis. Previous machine learning methods have focused on identifying\ninfections by analyzing wound images alone, without utilizing additional\nmetadata such as medical notes. In this study, we aim to improve infection\ndetection by introducing Synthetic Caption Augmented Retrieval for Wound\nInfection Detection (SCARWID), a novel deep learning framework that leverages\nsynthetic textual descriptions to augment DFU images. SCARWID consists of two\ncomponents: (1) Wound-BLIP, a Vision-Language Model (VLM) fine-tuned on\nGPT-4o-generated descriptions to synthesize consistent captions from images;\nand (2) an Image-Text Fusion module that uses cross-attention to extract\ncross-modal embeddings from an image and its corresponding Wound-BLIP caption.\nInfection status is determined by retrieving the top-k similar items from a\nlabeled support set. To enhance the diversity of training data, we utilized a\nlatent diffusion model to generate additional wound images. As a result,\nSCARWID outperformed state-of-the-art models, achieving average sensitivity,\nspecificity, and accuracy of 0.85, 0.78, and 0.81, respectively, for wound\ninfection classification. Displaying the generated captions alongside the wound\nimages and infection detection results enhances interpretability and trust,\nenabling nurses to align SCARWID outputs with their medical knowledge. This is\nparticularly valuable when wound notes are unavailable or when assisting novice\nnurses who may find it difficult to identify visual attributes of wound\ninfection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20277v1",
    "published_date": "2025-02-27 17:04:00 UTC",
    "updated_date": "2025-02-27 17:04:00 UTC"
  },
  {
    "arxiv_id": "2502.20272v2",
    "title": "HVI: A New Color Space for Low-light Image Enhancement",
    "authors": [
      "Qingsen Yan",
      "Yixu Feng",
      "Cheng Zhang",
      "Guansong Pang",
      "Kangbiao Shi",
      "Peng Wu",
      "Wei Dong",
      "Jinqiu Sun",
      "Yanning Zhang"
    ],
    "abstract": "Low-Light Image Enhancement (LLIE) is a crucial computer vision task that\naims to restore detailed visual information from corrupted low-light images.\nMany existing LLIE methods are based on standard RGB (sRGB) space, which often\nproduce color bias and brightness artifacts due to inherent high color\nsensitivity in sRGB. While converting the images using Hue, Saturation and\nValue (HSV) color space helps resolve the brightness issue, it introduces\nsignificant red and black noise artifacts. To address this issue, we propose a\nnew color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined\nby polarized HS maps and learnable intensity. The former enforces small\ndistances for red coordinates to remove the red artifacts, while the latter\ncompresses the low-light regions to remove the black artifacts. To fully\nleverage the chromatic and intensity information, a novel Color and Intensity\nDecoupling Network (CIDNet) is further introduced to learn accurate photometric\nmapping function under different lighting conditions in the HVI space.\nComprehensive results from benchmark and ablation experiments show that the\nproposed HVI color space with CIDNet outperforms the state-of-the-art methods\non 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Qingsen Yan, Yixu Feng, and Cheng Zhang contributed equally to this\n  work",
    "pdf_url": "http://arxiv.org/pdf/2502.20272v2",
    "published_date": "2025-02-27 16:59:51 UTC",
    "updated_date": "2025-02-28 11:13:24 UTC"
  },
  {
    "arxiv_id": "2502.20268v2",
    "title": "Large Language Models as Attribution Regularizers for Efficient Model Training",
    "authors": [
      "Davor Vukadin",
      "Marin ≈†iliƒá",
      "Goran Delaƒç"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\ndiverse domains. However, effectively leveraging their vast knowledge for\ntraining smaller downstream models remains an open challenge, especially in\ndomains like tabular data learning, where simpler models are often preferred\ndue to interpretability and efficiency.\n  In this paper, we introduce a novel yet straightforward method for\nincorporating LLM-generated global task feature attributions into the training\nprocess of smaller networks. Specifically, we propose an attribution-matching\nregularization term that aligns the training dynamics of the smaller model with\nthe insights provided by the LLM. By doing so, our approach yields superior\nperformance in few-shot learning scenarios. Notably, our method requires only\nblack-box API access to the LLM, making it easy to integrate into existing\ntraining pipelines with minimal computational overhead.\n  Furthermore, we demonstrate how this method can be used to address common\nissues in real-world datasets, such as skewness and bias. By integrating\nhigh-level knowledge from LLMs, our approach improves generalization, even when\ntraining data is limited or imbalanced. We validate its effectiveness through\nextensive experiments across multiple tasks, demonstrating improved learning\nefficiency and model robustness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20268v2",
    "published_date": "2025-02-27 16:55:18 UTC",
    "updated_date": "2025-04-17 11:32:53 UTC"
  },
  {
    "arxiv_id": "2502.20258v1",
    "title": "LLM as a Broken Telephone: Iterative Generation Distorts Information",
    "authors": [
      "Amr Mohamed",
      "Mingmeng Geng",
      "Michalis Vazirgiannis",
      "Guokan Shang"
    ],
    "abstract": "As large language models are increasingly responsible for online content,\nconcerns arise about the impact of repeatedly processing their own outputs.\nInspired by the \"broken telephone\" effect in chained human communication, this\nstudy investigates whether LLMs similarly distort information through iterative\ngeneration. Through translation-based experiments, we find that distortion\naccumulates over time, influenced by language choice and chain complexity.\nWhile degradation is inevitable, it can be mitigated through strategic\nprompting techniques. These findings contribute to discussions on the long-term\neffects of AI-mediated information propagation, raising important questions\nabout the reliability of LLM-generated content in iterative workflows.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20258v1",
    "published_date": "2025-02-27 16:46:23 UTC",
    "updated_date": "2025-02-27 16:46:23 UTC"
  },
  {
    "arxiv_id": "2502.20237v1",
    "title": "Teasing Apart Architecture and Initial Weights as Sources of Inductive Bias in Neural Networks",
    "authors": [
      "Gianluca Bencomo",
      "Max Gupta",
      "Ioana Marinescu",
      "R. Thomas McCoy",
      "Thomas L. Griffiths"
    ],
    "abstract": "Artificial neural networks can acquire many aspects of human knowledge from\ndata, making them promising as models of human learning. But what those\nnetworks can learn depends upon their inductive biases -- the factors other\nthan the data that influence the solutions they discover -- and the inductive\nbiases of neural networks remain poorly understood, limiting our ability to\ndraw conclusions about human learning from the performance of these systems.\nCognitive scientists and machine learning researchers often focus on the\narchitecture of a neural network as a source of inductive bias. In this paper\nwe explore the impact of another source of inductive bias -- the initial\nweights of the network -- using meta-learning as a tool for finding initial\nweights that are adapted for specific problems. We evaluate four widely-used\narchitectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430\ndifferent models across three tasks requiring different biases and forms of\ngeneralization. We find that meta-learning can substantially reduce or entirely\neliminate performance differences across architectures and data\nrepresentations, suggesting that these factors may be less important as sources\nof inductive bias than is typically assumed. When differences are present,\narchitectures and data representations that perform well without meta-learning\ntend to meta-train more effectively. Moreover, all architectures generalize\npoorly on problems that are far from their meta-training experience,\nunderscoring the need for stronger inductive biases for robust generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 6 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20237v1",
    "published_date": "2025-02-27 16:22:18 UTC",
    "updated_date": "2025-02-27 16:22:18 UTC"
  },
  {
    "arxiv_id": "2502.20233v1",
    "title": "Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue",
    "authors": [
      "Daniela B√∂hm",
      "Georg Gottlob",
      "Matthias Lanzinger",
      "Davide Longo",
      "Cem Okulmus",
      "Reinhard Pichler",
      "Alexander Selzer"
    ],
    "abstract": "Query optimization has played a central role in database research for\ndecades. However, more often than not, the proposed optimization techniques\nlead to a performance improvement in some, but not in all, situations.\nTherefore, we urgently need a methodology for designing a decision procedure\nthat decides for a given query whether the optimization technique should be\napplied or not.\n  In this work, we propose such a methodology with a focus on Yannakakis-style\nquery evaluation as our optimization technique of interest. More specifically,\nwe formulate this decision problem as an algorithm selection problem and we\npresent a Machine Learning based approach for its solution. Empirical results\nwith several benchmarks on a variety of database systems show that our approach\nindeed leads to a statistically significant performance improvement.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20233v1",
    "published_date": "2025-02-27 16:19:54 UTC",
    "updated_date": "2025-02-27 16:19:54 UTC"
  },
  {
    "arxiv_id": "2502.20231v1",
    "title": "AI Will Always Love You: Studying Implicit Biases in Romantic AI Companions",
    "authors": [
      "Clare Grogan",
      "Jackie Kay",
      "Mar√≠a P√©rez-Ortiz"
    ],
    "abstract": "While existing studies have recognised explicit biases in generative models,\nincluding occupational gender biases, the nuances of gender stereotypes and\nexpectations of relationships between users and AI companions remain\nunderexplored. In the meantime, AI companions have become increasingly popular\nas friends or gendered romantic partners to their users. This study bridges the\ngap by devising three experiments tailored for romantic, gender-assigned AI\ncompanions and their users, effectively evaluating implicit biases across\nvarious-sized LLMs. Each experiment looks at a different dimension: implicit\nassociations, emotion responses, and sycophancy. This study aims to measure and\ncompare biases manifested in different companion systems by quantitatively\nanalysing persona-assigned model responses to a baseline through newly devised\nmetrics. The results are noteworthy: they show that assigning gendered,\nrelationship personas to Large Language Models significantly alters the\nresponses of these models, and in certain situations in a biased, stereotypical\nway.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20231v1",
    "published_date": "2025-02-27 16:16:37 UTC",
    "updated_date": "2025-02-27 16:16:37 UTC"
  },
  {
    "arxiv_id": "2502.20224v2",
    "title": "RURANET++: An Unsupervised Learning Method for Diabetic Macular Edema Based on SCSE Attention Mechanisms and Dynamic Multi-Projection Head Clustering",
    "authors": [
      "Wei Yang",
      "Yiran Zhu",
      "Jiayu Shen",
      "Yuhan Tang",
      "Chengchang Pan",
      "Hui He",
      "Yan Su",
      "Honggang Qi"
    ],
    "abstract": "Diabetic Macular Edema (DME), a prevalent complication among diabetic\npatients, constitutes a major cause of visual impairment and blindness.\nAlthough deep learning has achieved remarkable progress in medical image\nanalysis, traditional DME diagnosis still relies on extensive annotated data\nand subjective ophthalmologist assessments, limiting practical applications. To\naddress this, we present RURANET++, an unsupervised learning-based automated\nDME diagnostic system. This framework incorporates an optimized U-Net\narchitecture with embedded Spatial and Channel Squeeze & Excitation (SCSE)\nattention mechanisms to enhance lesion feature extraction. During feature\nprocessing, a pre-trained GoogLeNet model extracts deep features from retinal\nimages, followed by PCA-based dimensionality reduction to 50 dimensions for\ncomputational efficiency. Notably, we introduce a novel clustering algorithm\nemploying multi-projection heads to explicitly control cluster diversity while\ndynamically adjusting similarity thresholds, thereby optimizing intra-class\nconsistency and inter-class discrimination. Experimental results demonstrate\nsuperior performance across multiple metrics, achieving maximum accuracy\n(0.8411), precision (0.8593), recall (0.8411), and F1-score (0.8390), with\nexceptional clustering quality. This work provides an efficient unsupervised\nsolution for DME diagnosis with significant clinical implications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 2 figures, 5 tables, submitted to The 28th International\n  Conference on Medical Image Computing and Computer Assisted Intervention\n  (MICCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.20224v2",
    "published_date": "2025-02-27 16:06:57 UTC",
    "updated_date": "2025-03-07 08:17:31 UTC"
  },
  {
    "arxiv_id": "2502.20223v1",
    "title": "Deep Convolutional Neural Networks for Palm Fruit Maturity Classification",
    "authors": [
      "Mingqiang Han",
      "Chunlin Yi"
    ],
    "abstract": "To maximize palm oil yield and quality, it is essential to harvest palm fruit\nat the optimal maturity stage. This project aims to develop an automated\ncomputer vision system capable of accurately classifying palm fruit images into\nfive ripeness levels. We employ deep Convolutional Neural Networks (CNNs) to\nclassify palm fruit images based on their maturity stage. A shallow CNN serves\nas the baseline model, while transfer learning and fine-tuning are applied to\npre-trained ResNet50 and InceptionV3 architectures. The study utilizes a\npublicly available dataset of over 8,000 images with significant variations,\nwhich is split into 80\\% for training and 20\\% for testing. The proposed deep\nCNN models achieve test accuracies exceeding 85\\% in classifying palm fruit\nmaturity stages. This research highlights the potential of deep learning for\nautomating palm fruit ripeness assessment, which can contribute to optimizing\nharvesting decisions and improving palm oil production efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20223v1",
    "published_date": "2025-02-27 16:06:30 UTC",
    "updated_date": "2025-02-27 16:06:30 UTC"
  },
  {
    "arxiv_id": "2502.20209v2",
    "title": "DIPSER: A Dataset for In-Person Student Engagement Recognition in the Wild",
    "authors": [
      "Luis Marquez-Carpintero",
      "Sergio Suescun-Ferrandiz",
      "Carolina Lorenzo √Ålvarez",
      "Jorge Fernandez-Herrero",
      "Diego Viejo",
      "Rosabel Roig-Vila",
      "Miguel Cazorla"
    ],
    "abstract": "In this paper, a novel dataset is introduced, designed to assess student\nattention within in-person classroom settings. This dataset encompasses RGB\ncamera data, featuring multiple cameras per student to capture both posture and\nfacial expressions, in addition to smartwatch sensor data for each individual.\nThis dataset allows machine learning algorithms to be trained to predict\nattention and correlate it with emotion. A comprehensive suite of attention and\nemotion labels for each student is provided, generated through self-reporting\nas well as evaluations by four different experts. Our dataset uniquely combines\nfacial and environmental camera data, smartwatch metrics, and includes\nunderrepresented ethnicities in similar datasets, all within in-the-wild,\nin-person settings, making it the most comprehensive dataset of its kind\ncurrently available.\n  The dataset presented offers an extensive and diverse collection of data\npertaining to student interactions across different educational contexts,\naugmented with additional metadata from other tools. This initiative addresses\nexisting deficiencies by offering a valuable resource for the analysis of\nstudent attention and emotion in face-to-face lessons.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20209v2",
    "published_date": "2025-02-27 15:50:21 UTC",
    "updated_date": "2025-03-02 13:36:57 UTC"
  },
  {
    "arxiv_id": "2502.20190v1",
    "title": "Highly Parallelized Reinforcement Learning Training with Relaxed Assignment Dependencies",
    "authors": [
      "Zhouyu He",
      "Peng Qiao",
      "Rongchun Li",
      "Yong Dou",
      "Yusong Tan"
    ],
    "abstract": "As the demands for superior agents grow, the training complexity of Deep\nReinforcement Learning (DRL) becomes higher. Thus, accelerating training of DRL\nhas become a major research focus. Dividing the DRL training process into\nsubtasks and using parallel computation can effectively reduce training costs.\nHowever, current DRL training systems lack sufficient parallelization due to\ndata assignment between subtask components. This assignment issue has been\nignored, but addressing it can further boost training efficiency. Therefore, we\npropose a high-throughput distributed RL training system called TianJi. It\nrelaxes assignment dependencies between subtask components and enables\nevent-driven asynchronous communication. Meanwhile, TianJi maintains clear\nboundaries between subtask components. To address convergence uncertainty from\nrelaxed assignment dependencies, TianJi proposes a distributed strategy based\non the balance of sample production and consumption. The strategy controls the\nstaleness of samples to correct their quality, ensuring convergence. We\nconducted extensive experiments. TianJi achieves a convergence time\nacceleration ratio of up to 4.37 compared to related comparison systems. When\nscaled to eight computational nodes, TianJi shows a convergence time speedup of\n1.6 and a throughput speedup of 7.13 relative to XingTian, demonstrating its\ncapability to accelerate training and scalability. In data transmission\nefficiency experiments, TianJi significantly outperforms other systems,\napproaching hardware limits. TianJi also shows effectiveness in on-policy\nalgorithms, achieving convergence time acceleration ratios of 4.36 and 2.95\ncompared to RLlib and XingTian. TianJi is accessible at\nhttps://github.com/HiPRL/TianJi.git.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20190v1",
    "published_date": "2025-02-27 15:23:43 UTC",
    "updated_date": "2025-02-27 15:23:43 UTC"
  },
  {
    "arxiv_id": "2502.20175v1",
    "title": "An Extensive Evaluation of PDDL Capabilities in off-the-shelf LLMs",
    "authors": [
      "Kaustubh Vyas",
      "Damien Graux",
      "S√©bastien Montella",
      "Pavlos Vougiouklis",
      "Ruofei Lai",
      "Keshuang Li",
      "Yang Ren",
      "Jeff Z. Pan"
    ],
    "abstract": "In recent advancements, large language models (LLMs) have exhibited\nproficiency in code generation and chain-of-thought reasoning, laying the\ngroundwork for tackling automatic formal planning tasks. This study evaluates\nthe potential of LLMs to understand and generate Planning Domain Definition\nLanguage (PDDL), an essential representation in artificial intelligence\nplanning. We conduct an extensive analysis across 20 distinct models spanning 7\nmajor LLM families, both commercial and open-source. Our comprehensive\nevaluation sheds light on the zero-shot LLM capabilities of parsing,\ngenerating, and reasoning with PDDL. Our findings indicate that while some\nmodels demonstrate notable effectiveness in handling PDDL, others pose\nlimitations in more complex scenarios requiring nuanced planning knowledge.\nThese results highlight the promise and current limitations of LLMs in formal\nplanning tasks, offering insights into their application and guiding future\nefforts in AI-driven planning paradigms.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2502.20175v1",
    "published_date": "2025-02-27 15:13:07 UTC",
    "updated_date": "2025-02-27 15:13:07 UTC"
  },
  {
    "arxiv_id": "2502.20168v1",
    "title": "Accelerating Model-Based Reinforcement Learning with State-Space World Models",
    "authors": [
      "Maria Krinner",
      "Elie Aljalbout",
      "Angel Romero",
      "Davide Scaramuzza"
    ],
    "abstract": "Reinforcement learning (RL) is a powerful approach for robot learning.\nHowever, model-free RL (MFRL) requires a large number of environment\ninteractions to learn successful control policies. This is due to the noisy RL\ntraining updates and the complexity of robotic systems, which typically involve\nhighly non-linear dynamics and noisy sensor signals. In contrast, model-based\nRL (MBRL) not only trains a policy but simultaneously learns a world model that\ncaptures the environment's dynamics and rewards. The world model can either be\nused for planning, for data collection, or to provide first-order policy\ngradients for training. Leveraging a world model significantly improves sample\nefficiency compared to model-free RL. However, training a world model alongside\nthe policy increases the computational complexity, leading to longer training\ntimes that are often intractable for complex real-world scenarios. In this\nwork, we propose a new method for accelerating model-based RL using state-space\nworld models. Our approach leverages state-space models (SSMs) to parallelize\nthe training of the dynamics model, which is typically the main computational\nbottleneck. Additionally, we propose an architecture that provides privileged\ninformation to the world model during training, which is particularly relevant\nfor partially observable environments. We evaluate our method in several\nreal-world agile quadrotor flight tasks, involving complex dynamics, for both\nfully and partially observable environments. We demonstrate a significant\nspeedup, reducing the world model training time by up to 10 times, and the\noverall MBRL training time by up to 4 times. This benefit comes without\ncompromising performance, as our method achieves similar sample efficiency and\ntask rewards to state-of-the-art MBRL methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "stat.ML",
      "I.2.9; I.2.10; I.2.6"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20168v1",
    "published_date": "2025-02-27 15:05:25 UTC",
    "updated_date": "2025-02-27 15:05:25 UTC"
  },
  {
    "arxiv_id": "2502.20156v1",
    "title": "Adaptive H&E-IHC information fusion staining framework based on feature extra",
    "authors": [
      "Yifan Jia",
      "Xingda Yu",
      "Zhengyang Ji",
      "Songning Lai",
      "Yutao Yue"
    ],
    "abstract": "Immunohistochemistry (IHC) staining plays a significant role in the\nevaluation of diseases such as breast cancer. The H&E-to-IHC transformation\nbased on generative models provides a simple and cost-effective method for\nobtaining IHC images. Although previous models can perform digital coloring\nwell, they still suffer from (i) coloring only through the pixel features that\nare not prominent in HE, which is easy to cause information loss in the\ncoloring process; (ii) The lack of pixel-perfect H&E-IHC groundtruth pairs\nposes a challenge to the classical L1 loss.To address the above challenges, we\npropose an adaptive information enhanced coloring framework based on feature\nextractors. We first propose the VMFE module to effectively extract the color\ninformation features using multi-scale feature extraction and wavelet transform\nconvolution, while combining the shared decoder for feature fusion. The\nhigh-performance dual feature extractor of H&E-IHC is trained by contrastive\nlearning, which can effectively perform feature alignment of HE-IHC in high\nlatitude space. At the same time, the trained feature encoder is used to\nenhance the features and adaptively adjust the loss in the HE section staining\nprocess to solve the problems related to unclear and asymmetric information. We\nhave tested on different datasets and achieved excellent performance.Our code\nis available at https://github.com/babyinsunshine/CEFF",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20156v1",
    "published_date": "2025-02-27 14:55:34 UTC",
    "updated_date": "2025-02-27 14:55:34 UTC"
  },
  {
    "arxiv_id": "2502.20130v1",
    "title": "QPM: Discrete Optimization for Globally Interpretable Image Classification",
    "authors": [
      "Thomas Norrenbrock",
      "Timo Kaiser",
      "Sovan Biswas",
      "Ramesh Manuvinakurike",
      "Bodo Rosenhahn"
    ],
    "abstract": "Understanding the classifications of deep neural networks, e.g. used in\nsafety-critical situations, is becoming increasingly important. While recent\nmodels can locally explain a single decision, to provide a faithful global\nexplanation about an accurate model's general behavior is a more challenging\nopen task. Towards that goal, we introduce the Quadratic Programming Enhanced\nModel (QPM), which learns globally interpretable class representations. QPM\nrepresents every class with a binary assignment of very few, typically 5,\nfeatures, that are also assigned to other classes, ensuring easily comparable\ncontrastive class representations. This compact binary assignment is found\nusing discrete optimization based on predefined similarity measures and\ninterpretability constraints. The resulting optimal assignment is used to\nfine-tune the diverse features, so that each of them becomes the shared general\nconcept between the assigned classes. Extensive evaluations show that QPM\ndelivers unprecedented global interpretability across small and large-scale\ndatasets while setting the state of the art for the accuracy of interpretable\nmodels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20130v1",
    "published_date": "2025-02-27 14:25:36 UTC",
    "updated_date": "2025-02-27 14:25:36 UTC"
  },
  {
    "arxiv_id": "2502.20127v1",
    "title": "SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning",
    "authors": [
      "Zexiong Ma",
      "Chao Peng",
      "Pengfei Gao",
      "Xiangxin Meng",
      "Yanzhen Zou",
      "Bing Xie"
    ],
    "abstract": "Mainstream issue-resolving frameworks predominantly rely on commercial\nmodels, leading to high costs and privacy concerns. Existing training\napproaches for issue resolving struggle with poor generalization and fail to\nfully leverage open-source development resources. We propose Subtask-oriented\nReinforced Fine-Tuning (SoRFT), a novel training approach to enhance the issue\nresolving capability of LLMs. We decomposes issue resolving into structured\nsubtasks: file localization, function localization, line localization, and code\nedit generation. SoRFT consists of two training stages: (1) rejection-sampled\nsupervised fine-tuning, Chain of Thought (CoT) data is filtered using\nground-truth before fine-tuning the LLM, and (2) rule-based reinforcement\nlearning, which leverages PPO with ground-truth based rewards. We evaluate the\nSoRFT-trained model on SWE-Bench Verified and SWE-Bench Lite, achieving\nstate-of-the-art (SOTA) performance among open-source models (e.g., resolve\n21.4% issues on SWE-Bench Verified with SoRFT-Qwen-7B). The experimental\nresults demonstrate that SoRFT significantly enhances issue-resolving\nperformance, improves model generalization, and provides a cost-efficient\nalternative to commercial models.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20127v1",
    "published_date": "2025-02-27 14:19:45 UTC",
    "updated_date": "2025-02-27 14:19:45 UTC"
  },
  {
    "arxiv_id": "2503.00070v1",
    "title": "Systematic Review of Cybersecurity in Banking: Evolution from Pre-Industry 4.0 to Post-Industry 4.0 in Artificial Intelligence, Blockchain, Policies and Practice",
    "authors": [
      "Tue Nhi Tran"
    ],
    "abstract": "Throughout the history from pre-industry 4.0 to post-industry 4.0,\ncybersecurity at banks has undergone significant changes. Pre-industry 4.0\ncyber security at banks relied on individual security methods that were highly\nmanual and had low accuracy. When moving to post-industry 4.0, cybersecurity at\nbanks had a major turning point with security methods that combined different\ntechnologies such as Artificial Intelligence (AI), Blockchain, IoT, automating\nnecessary processes and significantly increasing the defence layer for banks.\nHowever, along with the development of new technologies, the current challenge\nof cybersecurity at banks lies in scalability, high costs and resources in both\nmoney and time for R&D of defence methods along with the threat of high-tech\ncybercriminals growing and expanding. This report goes from introducing the\nimportance of cybersecurity at banks, analyzing their management, operational\nand business objectives, evaluating pre-industry 4.0 technologies used for\ncybersecurity at banks to assessing post-industry 4.0 technologies focusing on\nArtificial Intelligence and Blockchain, discussing current policies and\npractices and ending with discussing key advantages and challenges for 4.0\ntechnologies and recommendations for further developing cybersecurity at banks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00070v1",
    "published_date": "2025-02-27 14:17:06 UTC",
    "updated_date": "2025-02-27 14:17:06 UTC"
  },
  {
    "arxiv_id": "2502.20124v1",
    "title": "Exploring Open-world Continual Learning with Knowns-Unknowns Knowledge Transfer",
    "authors": [
      "Yujie Li",
      "Guannan Lai",
      "Xin Yang",
      "Yonghao Li",
      "Marcello Bonsangue",
      "Tianrui Li"
    ],
    "abstract": "Open-World Continual Learning (OWCL) is a challenging paradigm where models\nmust incrementally learn new knowledge without forgetting while operating under\nan open-world assumption. This requires handling incomplete training data and\nrecognizing unknown samples during inference. However, existing OWCL methods\noften treat open detection and continual learning as separate tasks, limiting\ntheir ability to integrate open-set detection and incremental classification in\nOWCL. Moreover, current approaches primarily focus on transferring knowledge\nfrom known samples, neglecting the insights derived from unknown/open samples.\nTo address these limitations, we formalize four distinct OWCL scenarios and\nconduct comprehensive empirical experiments to explore potential challenges in\nOWCL. Our findings reveal a significant interplay between the open detection of\nunknowns and incremental classification of knowns, challenging a widely held\nassumption that unknown detection and known classification are orthogonal\nprocesses. Building on our insights, we propose \\textbf{HoliTrans} (Holistic\nKnowns-Unknowns Knowledge Transfer), a novel OWCL framework that integrates\nnonlinear random projection (NRP) to create a more linearly separable embedding\nspace and distribution-aware prototypes (DAPs) to construct an adaptive\nknowledge space. Particularly, our HoliTrans effectively supports knowledge\ntransfer for both known and unknown samples while dynamically updating\nrepresentations of open samples during OWCL. Extensive experiments across\nvarious OWCL scenarios demonstrate that HoliTrans outperforms 22 competitive\nbaselines, bridging the gap between OWCL theory and practice and providing a\nrobust, scalable framework for advancing open-world learning paradigms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20124v1",
    "published_date": "2025-02-27 14:16:01 UTC",
    "updated_date": "2025-02-27 14:16:01 UTC"
  },
  {
    "arxiv_id": "2502.20122v2",
    "title": "Self-Training Elicits Concise Reasoning in Large Language Models",
    "authors": [
      "Tergel Munkhbat",
      "Namgyu Ho",
      "Seo Hyun Kim",
      "Yongjin Yang",
      "Yujin Kim",
      "Se-Young Yun"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning has enabled large language models (LLMs) to\nutilize additional computation through intermediate tokens to solve complex\ntasks. However, we posit that typical reasoning traces contain many redundant\ntokens, incurring extraneous inference costs. Upon examination of the output\ndistribution of current LLMs, we find evidence on their latent ability to\nreason more concisely, relative to their default behavior. To elicit this\ncapability, we propose simple fine-tuning methods which leverage self-generated\nconcise reasoning paths obtained by best-of-N sampling and few-shot\nconditioning, in task-specific settings. Our combined method achieves a 30%\nreduction in output tokens on average, across five model families on GSM8K and\nMATH, while maintaining average accuracy. By exploiting the fundamental\nstochasticity and in-context learning capabilities of LLMs, our self-training\napproach robustly elicits concise reasoning on a wide range of models,\nincluding those with extensive post-training. Code is available at\nhttps://github.com/TergelMunkhbat/concise-reasoning",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 10 figures, 18 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.20122v2",
    "published_date": "2025-02-27 14:14:50 UTC",
    "updated_date": "2025-02-28 08:12:10 UTC"
  },
  {
    "arxiv_id": "2502.20113v1",
    "title": "Forward-Cooperation-Backward (FCB) learning in a Multi-Encoding Uni-Decoding neural network architecture",
    "authors": [
      "Prasun Dutta",
      "Koustab Ghosh",
      "Rajat K. De"
    ],
    "abstract": "The most popular technique to train a neural network is backpropagation.\nRecently, the Forward-Forward technique has also been introduced for certain\nlearning tasks. However, in real life, human learning does not follow any of\nthese techniques exclusively. The way a human learns is basically a combination\nof forward learning, backward propagation and cooperation. Humans start\nlearning a new concept by themselves and try to refine their understanding\nhierarchically during which they might come across several doubts. The most\ncommon approach to doubt solving is a discussion with peers, which can be\ncalled cooperation. Cooperation/discussion/knowledge sharing among peers is one\nof the most important steps of learning that humans follow. However, there\nmight still be a few doubts even after the discussion. Then the difference\nbetween the understanding of the concept and the original literature is\nidentified and minimized over several revisions. Inspired by this, the paper\nintroduces Forward-Cooperation-Backward (FCB) learning in a deep neural network\nframework mimicking the human nature of learning a new concept. A novel deep\nneural network architecture, called Multi Encoding Uni Decoding neural network\nmodel, has been designed which learns using the notion of FCB. A special\nlateral synaptic connection has also been introduced to realize cooperation.\nThe models have been justified in terms of their performance in dimension\nreduction on four popular datasets. The ability to preserve the granular\nproperties of data in low-rank embedding has been tested to justify the quality\nof dimension reduction. For downstream analyses, classification has also been\nperformed. An experimental study on convergence analysis has been performed to\nestablish the efficacy of the FCB learning strategy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20113v1",
    "published_date": "2025-02-27 14:04:16 UTC",
    "updated_date": "2025-02-27 14:04:16 UTC"
  },
  {
    "arxiv_id": "2502.20429v2",
    "title": "Will AI replace Software Engineers? Do not hold your breath",
    "authors": [
      "Abhik Roychoudhury",
      "Andreas Zeller"
    ],
    "abstract": "Artificial Intelligence (AI) technology such as Large Language Models (LLMs)\nhave become extremely popular in creating code. This has led to the conjecture\nthat future software jobs will be exclusively conducted by LLMs, and the\nsoftware industry will cease to exist. But software engineering is much more\nthan producing code -- notably, \\emph{maintaining} large software and keeping\nit reliable is a major part of software engineering, which LLMs are not yet\ncapable of.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "3 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.20429v2",
    "published_date": "2025-02-27 14:04:02 UTC",
    "updated_date": "2025-03-03 07:46:41 UTC"
  },
  {
    "arxiv_id": "2502.20111v1",
    "title": "MITracker: Multi-View Integration for Visual Object Tracking",
    "authors": [
      "Mengjie Xu",
      "Yitao Zhu",
      "Haotian Jiang",
      "Jiaming Li",
      "Zhenrong Shen",
      "Sheng Wang",
      "Haolin Huang",
      "Xinyu Wang",
      "Qing Yang",
      "Han Zhang",
      "Qian Wang"
    ],
    "abstract": "Multi-view object tracking (MVOT) offers promising solutions to challenges\nsuch as occlusion and target loss, which are common in traditional single-view\ntracking. However, progress has been limited by the lack of comprehensive\nmulti-view datasets and effective cross-view integration methods. To overcome\nthese limitations, we compiled a Multi-View object Tracking (MVTrack) dataset\nof 234K high-quality annotated frames featuring 27 distinct objects across\nvarious scenes. In conjunction with this dataset, we introduce a novel MVOT\nmethod, Multi-View Integration Tracker (MITracker), to efficiently integrate\nmulti-view object features and provide stable tracking outcomes. MITracker can\ntrack any object in video frames of arbitrary length from arbitrary viewpoints.\nThe key advancements of our method over traditional single-view approaches come\nfrom two aspects: (1) MITracker transforms 2D image features into a 3D feature\nvolume and compresses it into a bird's eye view (BEV) plane, facilitating\ninter-view information fusion; (2) we propose an attention mechanism that\nleverages geometric information from fused 3D feature volume to refine the\ntracking results at each view. MITracker outperforms existing methods on the\nMVTrack and GMTD datasets, achieving state-of-the-art performance. The code and\nthe new dataset will be available at\nhttps://mii-laboratory.github.io/MITracker/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20111v1",
    "published_date": "2025-02-27 14:03:28 UTC",
    "updated_date": "2025-02-27 14:03:28 UTC"
  },
  {
    "arxiv_id": "2502.20099v2",
    "title": "Sanity Checking Causal Representation Learning on a Simple Real-World System",
    "authors": [
      "Juan L. Gamella",
      "Simon Bing",
      "Jakob Runge"
    ],
    "abstract": "We evaluate methods for causal representation learning (CRL) on a simple,\nreal-world system where these methods are expected to work. The system consists\nof a controlled optical experiment specifically built for this purpose, which\nsatisfies the core assumptions of CRL and where the underlying causal factors\n(the inputs to the experiment) are known, providing a ground truth. We select\nmethods representative of different approaches to CRL and find that they all\nfail to recover the underlying causal factors. To understand the failure modes\nof the evaluated algorithms, we perform an ablation on the data by substituting\nthe real data-generating process with a simpler synthetic equivalent. The\nresults reveal a reproducibility problem, as most methods already fail on this\nsynthetic ablation despite its simple data-generating process. Additionally, we\nobserve that common assumptions on the mixing function are crucial for the\nperformance of some of the methods but do not hold in the real data. Our\nefforts highlight the contrast between the theoretical promise of the state of\nthe art and the challenges in its application. We hope the benchmark serves as\na simple, real-world sanity check to further develop and validate methodology,\nbridging the gap towards CRL methods that work in practice. We make all code\nand datasets publicly available at github.com/simonbing/CRLSanityCheck",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20099v2",
    "published_date": "2025-02-27 13:56:54 UTC",
    "updated_date": "2025-04-28 10:30:46 UTC"
  },
  {
    "arxiv_id": "2502.20092v3",
    "title": "WalnutData: A UAV Remote Sensing Dataset of Green Walnuts and Model Evaluation",
    "authors": [
      "Mingjie Wu",
      "Chenggui Yang",
      "Huihua Wang",
      "Chen Xue",
      "Yibo Wang",
      "Haoyu Wang",
      "Yansong Wang",
      "Can Peng",
      "Yuqi Han",
      "Ruoyu Li",
      "Lijun Yun",
      "Zaiqing Chen",
      "Yuelong Xia"
    ],
    "abstract": "The UAV technology is gradually maturing and can provide extremely powerful\nsupport for smart agriculture and precise monitoring. Currently, there is no\ndataset related to green walnuts in the field of agricultural computer vision.\nThus, in order to promote the algorithm design in the field of agricultural\ncomputer vision, we used UAV to collect remote-sensing data from 8 walnut\nsample plots. Considering that green walnuts are subject to various lighting\nconditions and occlusion, we constructed a large-scale dataset with a\nhigher-granularity of target features - WalnutData. This dataset contains a\ntotal of 30,240 images and 706,208 instances, and there are 4 target\ncategories: being illuminated by frontal light and unoccluded (A1), being\nbacklit and unoccluded (A2), being illuminated by frontal light and occluded\n(B1), and being backlit and occluded (B2). Subsequently, we evaluated many\nmainstream algorithms on WalnutData and used these evaluation results as the\nbaseline standard. The dataset and all evaluation results can be obtained at\nhttps://github.com/1wuming/WalnutData.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20092v3",
    "published_date": "2025-02-27 13:51:56 UTC",
    "updated_date": "2025-03-04 14:00:03 UTC"
  },
  {
    "arxiv_id": "2502.20089v1",
    "title": "RIZE: Regularized Imitation Learning via Distributional Reinforcement Learning",
    "authors": [
      "Adib Karimi",
      "Mohammad Mehdi Ebadzadeh"
    ],
    "abstract": "We introduce a novel Inverse Reinforcement Learning (IRL) approach that\novercomes limitations of fixed reward assignments and constrained flexibility\nin implicit reward regularization. By extending the Maximum Entropy IRL\nframework with a squared temporal-difference (TD) regularizer and adaptive\ntargets, dynamically adjusted during training, our method indirectly optimizes\na reward function while incorporating reinforcement learning principles.\nFurthermore, we integrate distributional RL to capture richer return\ninformation. Our approach achieves state-of-the-art performance on challenging\nMuJoCo tasks, demonstrating expert-level results on the Humanoid task with only\n3 demonstrations. Extensive experiments and ablation studies validate the\neffectiveness of our method, providing insights into adaptive targets and\nreward dynamics in imitation learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20089v1",
    "published_date": "2025-02-27 13:47:29 UTC",
    "updated_date": "2025-02-27 13:47:29 UTC"
  },
  {
    "arxiv_id": "2502.20084v1",
    "title": "Minds on the Move: Decoding Trajectory Prediction in Autonomous Driving with Cognitive Insights",
    "authors": [
      "Haicheng Liao",
      "Chengyue Wang",
      "Kaiqun Zhu",
      "Yilong Ren",
      "Bolin Gao",
      "Shengbo Eben Li",
      "Chengzhong Xu",
      "Zhenning Li"
    ],
    "abstract": "In mixed autonomous driving environments, accurately predicting the future\ntrajectories of surrounding vehicles is crucial for the safe operation of\nautonomous vehicles (AVs). In driving scenarios, a vehicle's trajectory is\ndetermined by the decision-making process of human drivers. However, existing\nmodels primarily focus on the inherent statistical patterns in the data, often\nneglecting the critical aspect of understanding the decision-making processes\nof human drivers. This oversight results in models that fail to capture the\ntrue intentions of human drivers, leading to suboptimal performance in\nlong-term trajectory prediction. To address this limitation, we introduce a\nCognitive-Informed Transformer (CITF) that incorporates a cognitive concept,\nPerceived Safety, to interpret drivers' decision-making mechanisms. Perceived\nSafety encapsulates the varying risk tolerances across drivers with different\ndriving behaviors. Specifically, we develop a Perceived Safety-aware Module\nthat includes a Quantitative Safety Assessment for measuring the subject risk\nlevels within scenarios, and Driver Behavior Profiling for characterizing\ndriver behaviors. Furthermore, we present a novel module, Leanformer, designed\nto capture social interactions among vehicles. CITF demonstrates significant\nperformance improvements on three well-established datasets. In terms of\nlong-term prediction, it surpasses existing benchmarks by 12.0% on the NGSIM,\n28.2% on the HighD, and 20.8% on the MoCAD dataset. Additionally, its\nrobustness in scenarios with limited or missing data is evident, surpassing\nmost state-of-the-art (SOTA) baselines, and paving the way for real-world\napplications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20084v1",
    "published_date": "2025-02-27 13:43:17 UTC",
    "updated_date": "2025-02-27 13:43:17 UTC"
  },
  {
    "arxiv_id": "2502.20073v2",
    "title": "Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents",
    "authors": [
      "Haochen Sun",
      "Shuwen Zhang",
      "Lujie Niu",
      "Lei Ren",
      "Hao Xu",
      "Hao Fu",
      "Fangkun Zhao",
      "Caixia Yuan",
      "Xiaojie Wang"
    ],
    "abstract": "Large language models (LLMs) based agent systems have made great strides in\nreal-world applications beyond traditional NLP tasks. This paper proposes a new\nLLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on\nthe popular Overcooked-AI game with more applicable and challenging tasks in\ninteractive environments. Collab-Overcooked extends existing benchmarks from\ntwo novel perspectives. First, it provides a multi-agent framework supporting\ndiverse tasks and objectives and encourages collaboration through natural\nlanguage communication. Second, it introduces a spectrum of process-oriented\nevaluation metrics to assess the fine-grained collaboration capabilities of\ndifferent LLM agents, a dimension often overlooked in prior work. We conduct\nextensive experiments over 11 popular LLMs and show that, while the LLMs\npresent a strong ability in goal interpretation, there is a significant\ndiscrepancy in active collaboration and continuous adaptation which are\ncritical for efficiently fulfilling complicated tasks. Notably, we highlight\nthe strengths and weaknesses in LLM-MAS and provide insights for improving and\nevaluating LLM-MAS on a unified and open-sourced benchmark. The environments,\n30 open-ended tasks, and the evaluation package are publicly available at\nhttps://github.com/YusaeMeow/Collab-Overcooked.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20073v2",
    "published_date": "2025-02-27 13:31:13 UTC",
    "updated_date": "2025-05-22 02:46:18 UTC"
  },
  {
    "arxiv_id": "2503.00069v1",
    "title": "Societal Alignment Frameworks Can Improve LLM Alignment",
    "authors": [
      "Karolina Sta≈Ñczak",
      "Nicholas Meade",
      "Mehar Bhatia",
      "Hattie Zhou",
      "Konstantin B√∂ttinger",
      "Jeremy Barnes",
      "Jason Stanley",
      "Jessica Montgomery",
      "Richard Zemel",
      "Nicolas Papernot",
      "Nicolas Chapados",
      "Denis Therien",
      "Timothy P. Lillicrap",
      "Ana Marasoviƒá",
      "Sylvie Delacroix",
      "Gillian K. Hadfield",
      "Siva Reddy"
    ],
    "abstract": "Recent progress in large language models (LLMs) has focused on producing\nresponses that meet human expectations and align with shared values - a process\ncoined alignment. However, aligning LLMs remains challenging due to the\ninherent disconnect between the complexity of human values and the narrow\nnature of the technological approaches designed to address them. Current\nalignment methods often lead to misspecified objectives, reflecting the broader\nissue of incomplete contracts, the impracticality of specifying a contract\nbetween a model developer, and the model that accounts for every scenario in\nLLM alignment. In this paper, we argue that improving LLM alignment requires\nincorporating insights from societal alignment frameworks, including social,\neconomic, and contractual alignment, and discuss potential solutions drawn from\nthese domains. Given the role of uncertainty within societal alignment\nframeworks, we then investigate how it manifests in LLM alignment. We end our\ndiscussion by offering an alternative view on LLM alignment, framing the\nunderspecified nature of its objectives as an opportunity rather than perfect\ntheir specification. Beyond technical improvements in LLM alignment, we discuss\nthe need for participatory alignment interface designs.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00069v1",
    "published_date": "2025-02-27 13:26:07 UTC",
    "updated_date": "2025-02-27 13:26:07 UTC"
  },
  {
    "arxiv_id": "2502.20056v1",
    "title": "Enhanced Contrastive Learning with Multi-view Longitudinal Data for Chest X-ray Report Generation",
    "authors": [
      "Kang Liu",
      "Zhuoqi Ma",
      "Xiaolu Kang",
      "Yunan Li",
      "Kun Xie",
      "Zhicheng Jiao",
      "Qiguang Miao"
    ],
    "abstract": "Automated radiology report generation offers an effective solution to\nalleviate radiologists' workload. However, most existing methods focus\nprimarily on single or fixed-view images to model current disease conditions,\nwhich limits diagnostic accuracy and overlooks disease progression. Although\nsome approaches utilize longitudinal data to track disease progression, they\nstill rely on single images to analyze current visits. To address these issues,\nwe propose enhanced contrastive learning with Multi-view Longitudinal data to\nfacilitate chest X-ray Report Generation, named MLRG. Specifically, we\nintroduce a multi-view longitudinal contrastive learning method that integrates\nspatial information from current multi-view images and temporal information\nfrom longitudinal data. This method also utilizes the inherent spatiotemporal\ninformation of radiology reports to supervise the pre-training of visual and\ntextual representations. Subsequently, we present a tokenized absence encoding\ntechnique to flexibly handle missing patient-specific prior knowledge, allowing\nthe model to produce more accurate radiology reports based on available prior\nknowledge. Extensive experiments on MIMIC-CXR, MIMIC-ABN, and Two-view CXR\ndatasets demonstrate that our MLRG outperforms recent state-of-the-art methods,\nachieving a 2.3% BLEU-4 improvement on MIMIC-CXR, a 5.5% F1 score improvement\non MIMIC-ABN, and a 2.7% F1 RadGraph improvement on Two-view CXR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.20056v1",
    "published_date": "2025-02-27 12:59:04 UTC",
    "updated_date": "2025-02-27 12:59:04 UTC"
  },
  {
    "arxiv_id": "2502.20046v1",
    "title": "Polish-ASTE: Aspect-Sentiment Triplet Extraction Datasets for Polish",
    "authors": [
      "Marta Lango",
      "Borys Naglik",
      "Mateusz Lango",
      "Iwo Naglik"
    ],
    "abstract": "Aspect-Sentiment Triplet Extraction (ASTE) is one of the most challenging and\ncomplex tasks in sentiment analysis. It concerns the construction of triplets\nthat contain an aspect, its associated sentiment polarity, and an opinion\nphrase that serves as a rationale for the assigned polarity. Despite the\ngrowing popularity of the task and the many machine learning methods being\nproposed to address it, the number of datasets for ASTE is very limited. In\nparticular, no dataset is available for any of the Slavic languages. In this\npaper, we present two new datasets for ASTE containing customer opinions about\nhotels and purchased products expressed in Polish. We also perform experiments\nwith two ASTE techniques combined with two large language models for Polish to\ninvestigate their performance and the difficulty of the assembled datasets. The\nnew datasets are available under a permissive licence and have the same file\nformat as the English datasets, facilitating their use in future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20046v1",
    "published_date": "2025-02-27 12:38:04 UTC",
    "updated_date": "2025-02-27 12:38:04 UTC"
  },
  {
    "arxiv_id": "2502.20045v1",
    "title": "Text2VDM: Text to Vector Displacement Maps for Expressive and Interactive 3D Sculpting",
    "authors": [
      "Hengyu Meng",
      "Duotun Wang",
      "Zhijing Shao",
      "Ligang Liu",
      "Zeyu Wang"
    ],
    "abstract": "Professional 3D asset creation often requires diverse sculpting brushes to\nadd surface details and geometric structures. Despite recent progress in 3D\ngeneration, producing reusable sculpting brushes compatible with artists'\nworkflows remains an open and challenging problem. These sculpting brushes are\ntypically represented as vector displacement maps (VDMs), which existing models\ncannot easily generate compared to natural images. This paper presents\nText2VDM, a novel framework for text-to-VDM brush generation through the\ndeformation of a dense planar mesh guided by score distillation sampling (SDS).\nThe original SDS loss is designed for generating full objects and struggles\nwith generating desirable sub-object structures from scratch in brush\ngeneration. We refer to this issue as semantic coupling, which we address by\nintroducing classifier-free guidance (CFG) weighted blending of prompt tokens\nto SDS, resulting in a more accurate target distribution and semantic guidance.\nExperiments demonstrate that Text2VDM can generate diverse, high-quality VDM\nbrushes for sculpting surface details and geometric structures. Our generated\nbrushes can be seamlessly integrated into mainstream modeling software,\nenabling various applications such as mesh stylization and real-time\ninteractive modeling.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "I.2.6; I.3.6; I.3.8"
    ],
    "primary_category": "cs.GR",
    "comment": "11 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.20045v1",
    "published_date": "2025-02-27 12:36:51 UTC",
    "updated_date": "2025-02-27 12:36:51 UTC"
  },
  {
    "arxiv_id": "2502.20040v1",
    "title": "CleanMel: Mel-Spectrogram Enhancement for Improving Both Speech Quality and ASR",
    "authors": [
      "Nian Shao",
      "Rui Zhou",
      "Pengyu Wang",
      "Xian Li",
      "Ying Fang",
      "Yujie Yang",
      "Xiaofei Li"
    ],
    "abstract": "In this work, we propose CleanMel, a single-channel Mel-spectrogram denoising\nand dereverberation network for improving both speech quality and automatic\nspeech recognition (ASR) performance. The proposed network takes as input the\nnoisy and reverberant microphone recording and predicts the corresponding clean\nMel-spectrogram. The enhanced Mel-spectrogram can be either transformed to\nspeech waveform with a neural vocoder or directly used for ASR. The proposed\nnetwork is composed of interleaved cross-band and narrow-band processing in the\nMel-frequency domain, for learning the full-band spectral pattern and the\nnarrow-band properties of signals, respectively. Compared to linear-frequency\ndomain or time-domain speech enhancement, the key advantage of Mel-spectrogram\nenhancement is that Mel-frequency presents speech in a more compact way and\nthus is easier to learn, which will benefit both speech quality and ASR.\nExperimental results on four English and one Chinese datasets demonstrate a\nsignificant improvement in both speech quality and ASR performance achieved by\nthe proposed model. Code and audio examples of our model are available online\nin https://audio.westlake.edu.cn/Research/CleanMel.html.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Submission to IEEE/ACM Trans. on TASLP",
    "pdf_url": "http://arxiv.org/pdf/2502.20040v1",
    "published_date": "2025-02-27 12:28:29 UTC",
    "updated_date": "2025-02-27 12:28:29 UTC"
  },
  {
    "arxiv_id": "2502.20427v2",
    "title": "DeePen: Penetration Testing for Audio Deepfake Detection",
    "authors": [
      "Nicolas M√ºller",
      "Piotr Kawa",
      "Adriana Stan",
      "Thien-Phuc Doan",
      "Souhwan Jung",
      "Wei Herng Choong",
      "Philip Sperl",
      "Konstantin B√∂ttinger"
    ],
    "abstract": "Deepfakes - manipulated or forged audio and video media - pose significant\nsecurity risks to individuals, organizations, and society at large. To address\nthese challenges, machine learning-based classifiers are commonly employed to\ndetect deepfake content. In this paper, we assess the robustness of such\nclassifiers through a systematic penetration testing methodology, which we\nintroduce as DeePen. Our approach operates without prior knowledge of or access\nto the target deepfake detection models. Instead, it leverages a set of\ncarefully selected signal processing modifications - referred to as attacks -\nto evaluate model vulnerabilities. Using DeePen, we analyze both real-world\nproduction systems and publicly available academic model checkpoints,\ndemonstrating that all tested systems exhibit weaknesses and can be reliably\ndeceived by simple manipulations such as time-stretching or echo addition.\nFurthermore, our findings reveal that while some attacks can be mitigated by\nretraining detection systems with knowledge of the specific attack, others\nremain persistently effective. We release all associated code.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20427v2",
    "published_date": "2025-02-27 12:26:25 UTC",
    "updated_date": "2025-03-05 14:58:33 UTC"
  },
  {
    "arxiv_id": "2502.20426v1",
    "title": "Among Them: A game-based framework for assessing persuasion capabilities of LLMs",
    "authors": [
      "Mateusz Idziejczak",
      "Vasyl Korzavatykh",
      "Mateusz Stawicki",
      "Andrii Chmutov",
      "Marcin Korcz",
      "Iwo B≈ÇƒÖdek",
      "Dariusz Brzezinski"
    ],
    "abstract": "The proliferation of large language models (LLMs) and autonomous AI agents\nhas raised concerns about their potential for automated persuasion and social\ninfluence. While existing research has explored isolated instances of LLM-based\nmanipulation, systematic evaluations of persuasion capabilities across\ndifferent models remain limited. In this paper, we present an Among Us-inspired\ngame framework for assessing LLM deception skills in a controlled environment.\nThe proposed framework makes it possible to compare LLM models by game\nstatistics, as well as quantify in-game manipulation according to 25 persuasion\nstrategies from social psychology and rhetoric. Experiments between 8 popular\nlanguage models of different types and sizes demonstrate that all tested models\nexhibit persuasive capabilities, successfully employing 22 of the 25\nanticipated techniques. We also find that larger models do not provide any\npersuasion advantage over smaller models and that longer model outputs are\nnegatively correlated with the number of games won. Our study provides insights\ninto the deception capabilities of LLMs, as well as tools and data for\nfostering future research on the topic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20426v1",
    "published_date": "2025-02-27 12:26:21 UTC",
    "updated_date": "2025-02-27 12:26:21 UTC"
  },
  {
    "arxiv_id": "2502.20032v2",
    "title": "Order-Robust Class Incremental Learning: Graph-Driven Dynamic Similarity Grouping",
    "authors": [
      "Guannan Lai",
      "Yujie Li",
      "Xiangkun Wang",
      "Junbo Zhang",
      "Tianrui Li",
      "Xin Yang"
    ],
    "abstract": "Class Incremental Learning (CIL) aims to enable models to learn new classes\nsequentially while retaining knowledge of previous ones. Although current\nmethods have alleviated catastrophic forgetting (CF), recent studies highlight\nthat the performance of CIL models is highly sensitive to the order of class\narrival, particularly when sequentially introduced classes exhibit high\ninter-class similarity. To address this critical yet understudied challenge of\nclass order sensitivity, we first extend existing CIL frameworks through\ntheoretical analysis, proving that grouping classes with lower pairwise\nsimilarity during incremental phases significantly improves model robustness to\norder variations. Building on this insight, we propose Graph-Driven Dynamic\nSimilarity Grouping (GDDSG), a novel method that employs graph coloring\nalgorithms to dynamically partition classes into similarity-constrained groups.\nEach group trains an isolated CIL sub-model and constructs meta-features for\nclass group identification. Experimental results demonstrate that our method\neffectively addresses the issue of class order sensitivity while achieving\noptimal performance in both model accuracy and anti-forgetting capability. Our\ncode is available at https://github.com/AIGNLAI/GDDSG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05, 68Q25, 68U05",
      "I.2.6; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.20032v2",
    "published_date": "2025-02-27 12:16:57 UTC",
    "updated_date": "2025-03-18 03:10:01 UTC"
  },
  {
    "arxiv_id": "2502.19973v2",
    "title": "Can Large Language Models Unveil the Mysteries? An Exploration of Their Ability to Unlock Information in Complex Scenarios",
    "authors": [
      "Chao Wang",
      "Luning Zhang",
      "Zheng Wang",
      "Yang Zhou"
    ],
    "abstract": "Combining multiple perceptual inputs and performing combinatorial reasoning\nin complex scenarios is a sophisticated cognitive function in humans. With\nadvancements in multi-modal large language models, recent benchmarks tend to\nevaluate visual understanding across multiple images. However, they often\noverlook the necessity of combinatorial reasoning across multiple perceptual\ninformation. To explore the ability of advanced models to integrate multiple\nperceptual inputs for combinatorial reasoning in complex scenarios, we\nintroduce two benchmarks: Clue-Visual Question Answering (CVQA), with three\ntask types to assess visual comprehension and synthesis, and Clue of\nPassword-Visual Question Answering (CPVQA), with two task types focused on\naccurate interpretation and application of visual data. For our benchmarks, we\npresent three plug-and-play approaches: utilizing model input for reasoning,\nenhancing reasoning through minimum margin decoding with randomness generation,\nand retrieving semantically relevant visual information for effective data\nintegration. The combined results reveal current models' poor performance on\ncombinatorial reasoning benchmarks, even the state-of-the-art (SOTA)\nclosed-source model achieves only 33.04% accuracy on CVQA, and drops to 7.38%\non CPVQA. Notably, our approach improves the performance of models on\ncombinatorial reasoning, with a 22.17% boost on CVQA and 9.40% on CPVQA over\nthe SOTA closed-source model, demonstrating its effectiveness in enhancing\ncombinatorial reasoning with multiple perceptual inputs in complex scenarios.\nThe code will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11pages",
    "pdf_url": "http://arxiv.org/pdf/2502.19973v2",
    "published_date": "2025-02-27 10:58:27 UTC",
    "updated_date": "2025-03-09 05:35:07 UTC"
  },
  {
    "arxiv_id": "2502.19971v1",
    "title": "Efficient and Universal Neural-Network Decoder for Stabilizer-Based Quantum Error Correction",
    "authors": [
      "Gengyuan Hu",
      "Wanli Ouyang",
      "Chao-Yang Lu",
      "Chen Lin",
      "Han-Sen Zhong"
    ],
    "abstract": "Quantum error correction is crucial for large-scale quantum computing, but\nthe absence of efficient decoders for new codes like quantum low-density\nparity-check (QLDPC) codes has hindered progress. Here we introduce a universal\ndecoder based on linear attention sequence modeling and graph neural network\nthat operates directly on any stabilizer code's graph structure. Our numerical\nexperiments demonstrate that this decoder outperforms specialized algorithms in\nboth accuracy and speed across diverse stabilizer codes, including surface\ncodes, color codes, and QLDPC codes. The decoder maintains linear time scaling\nwith syndrome measurements and requires no structural modifications between\ndifferent codes. For the Bivariate Bicycle code with distance 12, our approach\nachieves a 39.4% lower logical error rate than previous best decoders while\nrequiring only ~1% of the decoding time. These results provide a practical,\nuniversal solution for quantum error correction, eliminating the need for\ncode-specific decoders.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19971v1",
    "published_date": "2025-02-27 10:56:53 UTC",
    "updated_date": "2025-02-27 10:56:53 UTC"
  },
  {
    "arxiv_id": "2502.19965v1",
    "title": "Deterministic or probabilistic? The psychology of LLMs as random number generators",
    "authors": [
      "Javier Coronado-Bl√°zquez"
    ],
    "abstract": "Large Language Models (LLMs) have transformed text generation through\ninherently probabilistic context-aware mechanisms, mimicking human natural\nlanguage. In this paper, we systematically investigate the performance of\nvarious LLMs when generating random numbers, considering diverse configurations\nsuch as different model architectures, numerical ranges, temperature, and\nprompt languages. Our results reveal that, despite their stochastic\ntransformers-based architecture, these models often exhibit deterministic\nresponses when prompted for random numerical outputs. In particular, we find\nsignificant differences when changing the model, as well as the prompt\nlanguage, attributing this phenomenon to biases deeply embedded within the\ntraining data. Models such as DeepSeek-R1 can shed some light on the internal\nreasoning process of LLMs, despite arriving to similar results. These biases\ninduce predictable patterns that undermine genuine randomness, as LLMs are\nnothing but reproducing our own human cognitive biases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "31 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19965v1",
    "published_date": "2025-02-27 10:45:27 UTC",
    "updated_date": "2025-02-27 10:45:27 UTC"
  },
  {
    "arxiv_id": "2502.19954v1",
    "title": "Collaborative Stance Detection via Small-Large Language Model Consistency Verification",
    "authors": [
      "Yu Yan",
      "Sheng Sun",
      "Zixiang Tang",
      "Teli Liu",
      "Min Liu"
    ],
    "abstract": "Stance detection on social media aims to identify attitudes expressed in\ntweets towards specific targets. Current studies prioritize Large Language\nModels (LLMs) over Small Language Models (SLMs) due to the overwhelming\nperformance improving provided by LLMs. However, heavily relying on LLMs for\nstance detection, regardless of the cost, is impractical for real-world social\nmedia monitoring systems that require vast data analysis. To this end, we\npropose \\textbf{\\underline{Co}}llaborative Stance Detection via Small-Large\nLanguage Model Consistency \\textbf{\\underline{Ver}}ification (\\textbf{CoVer})\nframework, which enhances LLM utilization via context-shared batch reasoning\nand logical verification between LLM and SLM. Specifically, instead of\nprocessing each text individually, CoVer processes texts batch-by-batch,\nobtaining stance predictions and corresponding explanations via LLM reasoning\nin a shared context. Then, to exclude the bias caused by context noises, CoVer\nintroduces the SLM for logical consistency verification. Finally, texts that\nrepeatedly exhibit low logical consistency are classified using\nconsistency-weighted aggregation of prior LLM stance predictions. Our\nexperiments show that CoVer outperforms state-of-the-art methods across\nmultiple benchmarks in the zero-shot setting, achieving 0.54 LLM queries per\ntweet while significantly enhancing performance. Our CoVer offers a more\npractical solution for LLM deploying for social media stance detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19954v1",
    "published_date": "2025-02-27 10:30:50 UTC",
    "updated_date": "2025-02-27 10:30:50 UTC"
  },
  {
    "arxiv_id": "2502.19948v1",
    "title": "Dynamic DropConnect: Enhancing Neural Network Robustness through Adaptive Edge Dropping Strategies",
    "authors": [
      "Yuan-Chih Yang",
      "Hung-Hsuan Chen"
    ],
    "abstract": "Dropout and DropConnect are well-known techniques that apply a consistent\ndrop rate to randomly deactivate neurons or edges in a neural network layer\nduring training. This paper introduces a novel methodology that assigns dynamic\ndrop rates to each edge within a layer, uniquely tailoring the dropping process\nwithout incorporating additional learning parameters. We perform experiments on\nsynthetic and openly available datasets to validate the effectiveness of our\napproach. The results demonstrate that our method outperforms Dropout,\nDropConnect, and Standout, a classic mechanism known for its adaptive dropout\ncapabilities. Furthermore, our approach improves the robustness and\ngeneralization of neural network training without increasing computational\ncomplexity. The complete implementation of our methodology is publicly\naccessible for research and replication purposes at\nhttps://github.com/ericabd888/Adjusting-the-drop-probability-in-DropConnect-based-on-the-magnitude-of-the-gradient/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19948v1",
    "published_date": "2025-02-27 10:17:02 UTC",
    "updated_date": "2025-02-27 10:17:02 UTC"
  },
  {
    "arxiv_id": "2502.19944v1",
    "title": "Algebraic Machine Learning: Learning as computing an algebraic decomposition of a task",
    "authors": [
      "Fernando Martin-Maroto",
      "Nabil Abderrahaman",
      "David Mendez",
      "Gonzalo G. de Polavieja"
    ],
    "abstract": "Statistics and Optimization are foundational to modern Machine Learning.\nHere, we propose an alternative foundation based on Abstract Algebra, with\nmathematics that facilitates the analysis of learning. In this approach, the\ngoal of the task and the data are encoded as axioms of an algebra, and a model\nis obtained where only these axioms and their logical consequences hold.\nAlthough this is not a generalizing model, we show that selecting specific\nsubsets of its breakdown into algebraic atoms obtained via subdirect\ndecomposition gives a model that generalizes. We validate this new learning\nprinciple on standard datasets such as MNIST, FashionMNIST, CIFAR-10, and\nmedical images, achieving performance comparable to optimized multilayer\nperceptrons. Beyond data-driven tasks, the new learning principle extends to\nformal problems, such as finding Hamiltonian cycles from their specifications\nand without relying on search. This algebraic foundation offers a fresh\nperspective on machine intelligence, featuring direct learning from training\ndata without the need for validation dataset, scaling through model additivity,\nand asymptotic convergence to the underlying rule in the data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "cs.SC",
      "math.CO",
      "03G10, 06A12, 06A06, 08A70, 68R01, 68T01",
      "G.2.3; I.1.2; I.2.6; I.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19944v1",
    "published_date": "2025-02-27 10:13:42 UTC",
    "updated_date": "2025-02-27 10:13:42 UTC"
  },
  {
    "arxiv_id": "2502.19938v1",
    "title": "Flexible Bivariate Beta Mixture Model: A Probabilistic Approach for Clustering Complex Data Structures",
    "authors": [
      "Yung-Peng Hsu",
      "Hung-Hsuan Chen"
    ],
    "abstract": "Clustering is essential in data analysis and machine learning, but\ntraditional algorithms like $k$-means and Gaussian Mixture Models (GMM) often\nfail with nonconvex clusters. To address the challenge, we introduce the\nFlexible Bivariate Beta Mixture Model (FBBMM), which utilizes the flexibility\nof the bivariate beta distribution to handle diverse and irregular cluster\nshapes. Using the Expectation Maximization (EM) algorithm and Sequential Least\nSquares Programming (SLSQP) optimizer for parameter estimation, we validate\nFBBMM on synthetic and real-world datasets, demonstrating its superior\nperformance in clustering complex data structures, offering a robust solution\nfor big data analytics across various domains. We release the experimental code\nat https://github.com/yung-peng/MBMM-and-FBBMM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19938v1",
    "published_date": "2025-02-27 10:07:43 UTC",
    "updated_date": "2025-02-27 10:07:43 UTC"
  },
  {
    "arxiv_id": "2502.19935v3",
    "title": "Lotus at SemEval-2025 Task 11: RoBERTa with Llama-3 Generated Explanations for Multi-Label Emotion Classification",
    "authors": [
      "Niloofar Ranjbar",
      "Hamed Baghbani"
    ],
    "abstract": "This paper presents a novel approach for multi-label emotion detection, where\nLlama-3 is used to generate explanatory content that clarifies ambiguous\nemotional expressions, thereby enhancing RoBERTa's emotion classification\nperformance. By incorporating explanatory context, our method improves\nF1-scores, particularly for emotions like fear, joy, and sadness, and\noutperforms text-only models. The addition of explanatory content helps resolve\nambiguity, addresses challenges like overlapping emotional cues, and enhances\nmulti-label classification, marking a significant advancement in emotion\ndetection tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages , submitted to SemEval 2025-Task 11",
    "pdf_url": "http://arxiv.org/pdf/2502.19935v3",
    "published_date": "2025-02-27 10:04:36 UTC",
    "updated_date": "2025-04-16 10:17:33 UTC"
  },
  {
    "arxiv_id": "2502.20423v1",
    "title": "Efficient Risk-sensitive Planning via Entropic Risk Measures",
    "authors": [
      "Alexandre Marthe",
      "Samuel Bounan",
      "Aur√©lien Garivier",
      "Claire Vernade"
    ],
    "abstract": "Risk-sensitive planning aims to identify policies maximizing some\ntail-focused metrics in Markov Decision Processes (MDPs). Such an optimization\ntask can be very costly for the most widely used and interpretable metrics such\nas threshold probabilities or (Conditional) Values at Risk. Indeed, previous\nwork showed that only Entropic Risk Measures (EntRM) can be efficiently\noptimized through dynamic programming, leaving a hard-to-interpret parameter to\nchoose. We show that the computation of the full set of optimal policies for\nEntRM across parameter values leads to tight approximations for the metrics of\ninterest. We prove that this optimality front can be computed effectively\nthanks to a novel structural analysis and smoothness properties of entropic\nrisks. Empirical results demonstrate that our approach achieves strong\nperformance in a variety of decision-making scenarios.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC",
      "math.PR"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20423v1",
    "published_date": "2025-02-27 09:56:51 UTC",
    "updated_date": "2025-02-27 09:56:51 UTC"
  },
  {
    "arxiv_id": "2502.19924v1",
    "title": "DiffCSS: Diverse and Expressive Conversational Speech Synthesis with Diffusion Models",
    "authors": [
      "Weihao wu",
      "Zhiwei Lin",
      "Yixuan Zhou",
      "Jingbei Li",
      "Rui Niu",
      "Qinghua Wu",
      "Songjun Cao",
      "Long Ma",
      "Zhiyong Wu"
    ],
    "abstract": "Conversational speech synthesis (CSS) aims to synthesize both contextually\nappropriate and expressive speech, and considerable efforts have been made to\nenhance the understanding of conversational context. However, existing CSS\nsystems are limited to deterministic prediction, overlooking the diversity of\npotential responses. Moreover, they rarely employ language model (LM)-based TTS\nbackbones, limiting the naturalness and quality of synthesized speech. To\naddress these issues, in this paper, we propose DiffCSS, an innovative CSS\nframework that leverages diffusion models and an LM-based TTS backbone to\ngenerate diverse, expressive, and contextually coherent speech. A\ndiffusion-based context-aware prosody predictor is proposed to sample diverse\nprosody embeddings conditioned on multimodal conversational context. Then a\nprosody-controllable LM-based TTS backbone is developed to synthesize\nhigh-quality speech with sampled prosody embeddings. Experimental results\ndemonstrate that the synthesized speech from DiffCSS is more diverse,\ncontextually coherent, and expressive than existing CSS systems",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19924v1",
    "published_date": "2025-02-27 09:53:48 UTC",
    "updated_date": "2025-02-27 09:53:48 UTC"
  },
  {
    "arxiv_id": "2502.19922v1",
    "title": "Incremental Learning with Repetition via Pseudo-Feature Projection",
    "authors": [
      "Benedikt Tscheschner",
      "Eduardo Veas",
      "Marc Masana"
    ],
    "abstract": "Incremental Learning scenarios do not always represent real-world inference\nuse-cases, which tend to have less strict task boundaries, and exhibit\nrepetition of common classes and concepts in their continual data stream. To\nbetter represent these use-cases, new scenarios with partial repetition and\nmixing of tasks are proposed, where the repetition patterns are innate to the\nscenario and unknown to the strategy. We investigate how exemplar-free\nincremental learning strategies are affected by data repetition, and we adapt a\nseries of state-of-the-art approaches to analyse and fairly compare them under\nboth settings. Further, we also propose a novel method (Horde), able to\ndynamically adjust an ensemble of self-reliant feature extractors, and align\nthem by exploiting class repetition. Our proposed exemplar-free method achieves\ncompetitive results in the classic scenario without repetition, and\nstate-of-the-art performance in the one with repetition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19922v1",
    "published_date": "2025-02-27 09:43:35 UTC",
    "updated_date": "2025-02-27 09:43:35 UTC"
  },
  {
    "arxiv_id": "2502.19918v2",
    "title": "Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models",
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Tri Cao",
      "Simeng Han",
      "Yulin Chen",
      "Bryan Hooi"
    ],
    "abstract": "Large Language Models (LLMs) increasingly rely on prolonged reasoning chains\nto solve complex tasks. However, this trial-and-error approach often leads to\nhigh computational overhead and error propagation, where early mistakes can\nderail subsequent steps. To address these issues, we introduce Meta-Reasoner, a\nframework that dynamically optimizes inference-time reasoning by enabling LLMs\nto \\enquote{think about how to think.} Drawing inspiration from human\nmeta-cognition and dual-process theory, Meta-Reasoner operates as a strategic\nadvisor, decoupling high-level guidance from step-by-step generation. It\nemploys contextual multi-armed bandits to iteratively evaluate reasoning\nprogress and select optimal strategies (e.g., backtrack, clarify ambiguity,\nrestart from scratch, or propose alternative approaches), and reallocates\ncomputational resources toward the most promising paths. Our evaluations on\nmathematical reasoning and puzzles highlight the potential of dynamic reasoning\nchains to overcome inherent challenges in the LLM reasoning process and also\nshow promise in broader applications, offering a scalable and adaptable\nsolution for reasoning-intensive tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19918v2",
    "published_date": "2025-02-27 09:40:13 UTC",
    "updated_date": "2025-05-22 08:15:25 UTC"
  },
  {
    "arxiv_id": "2502.19915v2",
    "title": "LLM-driven Effective Knowledge Tracing by Integrating Dual-channel Difficulty",
    "authors": [
      "Jiahui Cen",
      "Jianghao Lin",
      "Weixuan Zhong",
      "Dong Zhou",
      "Jin Chen",
      "Aimin Yang",
      "Yongmei Zhou"
    ],
    "abstract": "Knowledge Tracing (KT) is a fundamental technology in intelligent tutoring\nsystems used to simulate changes in students' knowledge state during learning,\ntrack personalized knowledge mastery, and predict performance. However, current\nKT models face three major challenges: (1) When encountering new questions,\nmodels face cold-start problems due to sparse interaction records, making\nprecise modeling difficult; (2) Traditional models only use historical\ninteraction records for student personalization modeling, unable to accurately\ntrack individual mastery levels, resulting in unclear personalized modeling;\n(3) The decision-making process is opaque to educators, making it challenging\nfor them to understand model judgments. To address these challenges, we propose\na novel Dual-channel Difficulty-aware Knowledge Tracing (DDKT) framework that\nutilizes Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG)\nfor subjective difficulty assessment, while integrating difficulty bias-aware\nalgorithms and student mastery algorithms for precise difficulty measurement.\nOur framework introduces three key innovations: (1) Difficulty Balance\nPerception Sequence (DBPS) - students' subjective perceptions combined with\nobjective difficulty, measuring gaps between LLM-assessed difficulty,\nmathematical-statistical difficulty, and students' subjective perceived\ndifficulty through attention mechanisms; (2) Difficulty Mastery Ratio (DMR) -\nprecise modeling of student mastery levels through different difficulty zones;\n(3) Knowledge State Update Mechanism - implementing personalized knowledge\nacquisition through gated networks and updating student knowledge state.\nExperimental results on two real datasets show our method consistently\noutperforms nine baseline models, improving AUC metrics by 2% to 10% while\neffectively addressing cold-start problems and enhancing model\ninterpretability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "During a careful review of our base-experiment results, we discovered\n  a possible error in the way some data were recorded. To ensure the integrity\n  and accuracy of our work, we must correct these results and revise the\n  corresponding analysis before making the manuscript publicly available",
    "pdf_url": "http://arxiv.org/pdf/2502.19915v2",
    "published_date": "2025-02-27 09:36:27 UTC",
    "updated_date": "2025-04-30 01:26:23 UTC"
  },
  {
    "arxiv_id": "2502.19907v1",
    "title": "Order Doesn't Matter, But Reasoning Does: Training LLMs with Order-Centric Augmentation",
    "authors": [
      "Qianxi He",
      "Qianyu He",
      "Jiaqing Liang",
      "Yanghua Xiao",
      "Weikang Zhou",
      "Zeye Sun",
      "Fei Yu"
    ],
    "abstract": "Logical reasoning is essential for large language models (LLMs) to ensure\naccurate and coherent inference. However, LLMs struggle with reasoning order\nvariations and fail to generalize across logically equivalent transformations.\nLLMs often rely on fixed sequential patterns rather than true logical\nunderstanding. To address this issue, we introduce an order-centric data\naugmentation framework based on commutativity in logical reasoning. We first\nrandomly shuffle independent premises to introduce condition order\naugmentation. For reasoning steps, we construct a directed acyclic graph (DAG)\nto model dependencies between steps, which allows us to identify valid\nreorderings of steps while preserving logical correctness. By leveraging\norder-centric augmentations, models can develop a more flexible and generalized\nreasoning process. Finally, we conduct extensive experiments across multiple\nlogical reasoning benchmarks, demonstrating that our method significantly\nenhances LLMs' reasoning performance and adaptability to diverse logical\nstructures. We release our codes and augmented data in\nhttps://anonymous.4open.science/r/Order-Centric-Data-Augmentation-822C/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19907v1",
    "published_date": "2025-02-27 09:25:50 UTC",
    "updated_date": "2025-02-27 09:25:50 UTC"
  },
  {
    "arxiv_id": "2502.19902v2",
    "title": "Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action Conditioned Policy",
    "authors": [
      "Zaijing Li",
      "Yuquan Xie",
      "Rui Shao",
      "Gongwei Chen",
      "Dongmei Jiang",
      "Liqiang Nie"
    ],
    "abstract": "Building an agent that can mimic human behavior patterns to accomplish\nvarious open-world tasks is a long-term goal. To enable agents to effectively\nlearn behavioral patterns across diverse tasks, a key challenge lies in\nmodeling the intricate relationships among observations, actions, and language.\nTo this end, we propose Optimus-2, a novel Minecraft agent that incorporates a\nMultimodal Large Language Model (MLLM) for high-level planning, alongside a\nGoal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP\ncontains (1) an Action-guided Behavior Encoder that models causal relationships\nbetween observations and actions at each timestep, then dynamically interacts\nwith the historical observation-action sequence, consolidating it into\nfixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with\nopen-ended language instructions to predict actions auto-regressively.\nMoreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)}\ndataset, which contains 25,000 videos across 8 atomic tasks, providing about\n30M goal-observation-action pairs. The automated construction method, along\nwith the MGOA dataset, can contribute to the community's efforts to train\nMinecraft agents. Extensive experimental results demonstrate that Optimus-2\nexhibits superior performance across atomic tasks, long-horizon tasks, and\nopen-ended instruction tasks in Minecraft. Please see the project page at\nhttps://cybertronagent.github.io/Optimus-2.github.io/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accept to CVPR 2025, Project page:\n  https://cybertronagent.github.io/Optimus-2.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.19902v2",
    "published_date": "2025-02-27 09:18:04 UTC",
    "updated_date": "2025-03-11 07:51:05 UTC"
  },
  {
    "arxiv_id": "2502.20422v1",
    "title": "SEKI: Self-Evolution and Knowledge Inspiration based Neural Architecture Search via Large Language Models",
    "authors": [
      "Zicheng Cai",
      "Yaohua Tang",
      "Yutao Lai",
      "Hua Wang",
      "Zhi Chen",
      "Hao Chen"
    ],
    "abstract": "We introduce SEKI, a novel large language model (LLM)-based neural\narchitecture search (NAS) method. Inspired by the chain-of-thought (CoT)\nparadigm in modern LLMs, SEKI operates in two key stages: self-evolution and\nknowledge distillation. In the self-evolution stage, LLMs initially lack\nsufficient reference examples, so we implement an iterative refinement\nmechanism that enhances architectures based on performance feedback. Over time,\nthis process accumulates a repository of high-performance architectures. In the\nknowledge distillation stage, LLMs analyze common patterns among these\narchitectures to generate new, optimized designs. Combining these two stages,\nSEKI greatly leverages the capacity of LLMs on NAS and without requiring any\ndomain-specific data. Experimental results show that SEKI achieves\nstate-of-the-art (SOTA) performance across various datasets and search spaces\nwhile requiring only 0.05 GPU-days, outperforming existing methods in both\nefficiency and accuracy. Furthermore, SEKI demonstrates strong generalization\ncapabilities, achieving SOTA-competitive results across multiple tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20422v1",
    "published_date": "2025-02-27 09:17:49 UTC",
    "updated_date": "2025-02-27 09:17:49 UTC"
  },
  {
    "arxiv_id": "2502.19899v1",
    "title": "Shared Autonomy for Proximal Teaching",
    "authors": [
      "Megha Srivastava",
      "Reihaneh Iranmanesh",
      "Yuchen Cui",
      "Deepak Gopinath",
      "Emily Sumner",
      "Andrew Silva",
      "Laporsha Dees",
      "Guy Rosman",
      "Dorsa Sadigh"
    ],
    "abstract": "Motor skill learning often requires experienced professionals who can provide\npersonalized instruction. Unfortunately, the availability of high-quality\ntraining can be limited for specialized tasks, such as high performance racing.\nSeveral recent works have leveraged AI-assistance to improve instruction of\ntasks ranging from rehabilitation to surgical robot tele-operation. However,\nthese works often make simplifying assumptions on the student learning process,\nand fail to model how a teacher's assistance interacts with different\nindividuals' abilities when determining optimal teaching strategies. Inspired\nby the idea of scaffolding from educational psychology, we leverage shared\nautonomy, a framework for combining user inputs with robot autonomy, to aid\nwith curriculum design. Our key insight is that the way a student's behavior\nimproves in the presence of assistance from an autonomous agent can highlight\nwhich sub-skills might be most ``learnable'' for the student, or within their\nZone of Proximal Development. We use this to design Z-COACH, a method for using\nshared autonomy to provide personalized instruction targeting interpretable\ntask sub-skills. In a user study (n=50), where we teach high performance racing\nin a simulated environment of the Thunderhill Raceway Park with the CARLA\nAutonomous Driving simulator, we show that Z-COACH helps identify which skills\neach student should first practice, leading to an overall improvement in\ndriving time, behavior, and smoothness. Our work shows that increasingly\navailable semi-autonomous capabilities (e.g. in vehicles, robots) can not only\nassist human users, but also help *teach* them.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ACM/IEEE International Conference on Human-Robot\n  Interaction, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19899v1",
    "published_date": "2025-02-27 09:14:17 UTC",
    "updated_date": "2025-02-27 09:14:17 UTC"
  },
  {
    "arxiv_id": "2502.19892v1",
    "title": "ColorDynamic: Generalizable, Scalable, Real-time, End-to-end Local Planner for Unstructured and Dynamic Environments",
    "authors": [
      "Jinghao Xin",
      "Zhichao Liang",
      "Zihuan Zhang",
      "Peng Wang",
      "Ning Li"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) has demonstrated potential in addressing\nrobotic local planning problems, yet its efficacy remains constrained in highly\nunstructured and dynamic environments. To address these challenges, this study\nproposes the ColorDynamic framework. First, an end-to-end DRL formulation is\nestablished, which maps raw sensor data directly to control commands, thereby\nensuring compatibility with unstructured environments. Under this formulation,\na novel network, Transqer, is introduced. The Transqer enables online DRL\nlearning from temporal transitions, substantially enhancing decision-making in\ndynamic scenarios. To facilitate scalable training of Transqer with diverse\ndata, an efficient simulation platform E-Sparrow, along with a data\naugmentation technique leveraging symmetric invariance, are developed.\nComparative evaluations against state-of-the-art methods, alongside assessments\nof generalizability, scalability, and real-time performance, were conducted to\nvalidate the effectiveness of ColorDynamic. Results indicate that our approach\nachieves a success rate exceeding 90% while exhibiting real-time capacity\n(1.2-1.3 ms per planning). Additionally, ablation studies were performed to\ncorroborate the contributions of individual components. Building on this, the\nOkayPlan-ColorDynamic (OPCD) navigation system is presented, with simulated and\nreal-world experiments demonstrating its superiority and applicability in\ncomplex scenarios. The codebase and experimental demonstrations have been\nopen-sourced on our website to facilitate reproducibility and further research.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.19892v1",
    "published_date": "2025-02-27 09:01:11 UTC",
    "updated_date": "2025-02-27 09:01:11 UTC"
  },
  {
    "arxiv_id": "2502.19883v2",
    "title": "Behind the Tip of Efficiency: Uncovering the Submerged Threats of Jailbreak Attacks in Small Language Models",
    "authors": [
      "Sibo Yi",
      "Tianshuo Cong",
      "Xinlei He",
      "Qi Li",
      "Jiaxing Song"
    ],
    "abstract": "Small language models (SLMs) have become increasingly prominent in the\ndeployment on edge devices due to their high efficiency and low computational\ncost. While researchers continue to advance the capabilities of SLMs through\ninnovative training strategies and model compression techniques, the security\nrisks of SLMs have received considerably less attention compared to large\nlanguage models (LLMs).To fill this gap, we provide a comprehensive empirical\nstudy to evaluate the security performance of 13 state-of-the-art SLMs under\nvarious jailbreak attacks. Our experiments demonstrate that most SLMs are quite\nsusceptible to existing jailbreak attacks, while some of them are even\nvulnerable to direct harmful prompts.To address the safety concerns, we\nevaluate several representative defense methods and demonstrate their\neffectiveness in enhancing the security of SLMs. We further analyze the\npotential security degradation caused by different SLM techniques including\narchitecture compression, quantization, knowledge distillation, and so on. We\nexpect that our research can highlight the security challenges of SLMs and\nprovide valuable insights to future work in developing more robust and secure\nSLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages. 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19883v2",
    "published_date": "2025-02-27 08:44:04 UTC",
    "updated_date": "2025-02-28 12:59:26 UTC"
  },
  {
    "arxiv_id": "2502.19860v1",
    "title": "MIND: Towards Immersive Psychological Healing with Multi-agent Inner Dialogue",
    "authors": [
      "Yujia Chen",
      "Changsong Li",
      "Yiming Wang",
      "Qingqing Xiao",
      "Nan Zhang",
      "Zifan Kong",
      "Peng Wang",
      "Binyu Yan"
    ],
    "abstract": "Mental health issues are worsening in today's competitive society, such as\ndepression and anxiety. Traditional healings like counseling and chatbots fail\nto engage effectively, they often provide generic responses lacking emotional\ndepth. Although large language models (LLMs) have the potential to create more\nhuman-like interactions, they still struggle to capture subtle emotions. This\nrequires LLMs to be equipped with human-like adaptability and warmth. To fill\nthis gap, we propose the MIND (Multi-agent INner Dialogue), a novel paradigm\nthat provides more immersive psychological healing environments. Considering\nthe strong generative and role-playing ability of LLM agents, we predefine an\ninteractive healing framework and assign LLM agents different roles within the\nframework to engage in interactive inner dialogues with users, thereby\nproviding an immersive healing experience. We conduct extensive human\nexperiments in various real-world healing dimensions, and find that MIND\nprovides a more user-friendly experience than traditional paradigms. This\ndemonstrates that MIND effectively leverages the significant potential of LLMs\nin psychological healing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19860v1",
    "published_date": "2025-02-27 08:04:27 UTC",
    "updated_date": "2025-02-27 08:04:27 UTC"
  },
  {
    "arxiv_id": "2502.19852v1",
    "title": "ConvCodeWorld: Benchmarking Conversational Code Generation in Reproducible Feedback Environments",
    "authors": [
      "Hojae Han",
      "Seung-won Hwang",
      "Rajhans Samdani",
      "Yuxiong He"
    ],
    "abstract": "Large language models (LLMs) have proven invaluable for code generation,\nparticularly in interactive settings. However, existing code generation\nbenchmarks fail to capture the diverse feedback encountered in multi-turn\ninteractions, limiting our ability to evaluate LLMs in these contexts. To\naddress this gap, we present a set of novel benchmarks that explicitly model\nthe quality of feedback provided to code generation LLMs. Our contributions are\nthreefold: First, we introduce CONVCODEWORLD, a novel and reproducible\nenvironment for benchmarking interactive code generation. CONVCODEWORLD\nsimulates 9 distinct interactive code generation scenarios while systematically\ncombining three types of feedback: (a) compilation feedback; (b) execution\nfeedback with varying test coverage; (c) verbal feedback generated by GPT-4o\nwith different levels of expertise. Second, we introduce CONVCODEBENCH, a fast,\nstatic version of benchmark that uses pre-generated feedback logs, eliminating\nthe need for costly dynamic verbal feedback generation while maintaining strong\nSpearman's rank correlations (0.82 to 0.99) with CONVCODEWORLD. Third,\nextensive evaluations of both closed-source and open-source LLMs including\nR1-Distill on CONVCODEWORLD reveal key insights: (a) LLM performance varies\nsignificantly based on the feedback provided; (b) Weaker LLMs, with sufficient\nfeedback, can outperform single-turn results of state-of-the-art LLMs without\nfeedback; (c) Training on a specific feedback combination can limit an LLM's\nability to utilize unseen combinations; (d) LLMs solve problems in fewer turns\n(high MRR) may not solve as many problems overall (high Recall), and vice\nversa. All implementations and benchmarks will be made publicly available at\nhttps://huggingface.co/spaces/ConvCodeWorld/ConvCodeWorld",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19852v1",
    "published_date": "2025-02-27 07:54:32 UTC",
    "updated_date": "2025-02-27 07:54:32 UTC"
  },
  {
    "arxiv_id": "2502.19830v1",
    "title": "Revisiting Self-Consistency from Dynamic Distributional Alignment Perspective on Answer Aggregation",
    "authors": [
      "Yiwei Li",
      "Ji Zhang",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Xinglin Wang",
      "Jiayi Shi",
      "Yueqi Zhang",
      "Chuyi Tan",
      "Boyuan Pan",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Self-consistency improves reasoning by aggregating diverse stochastic\nsamples, yet the dynamics behind its efficacy remain underexplored. We reframe\nself-consistency as a dynamic distributional alignment problem, revealing that\ndecoding temperature not only governs sampling randomness but also actively\nshapes the latent answer distribution. Given that high temperatures require\nprohibitively large sample sizes to stabilize, while low temperatures risk\namplifying biases, we propose a confidence-driven mechanism that dynamically\ncalibrates temperature: sharpening the sampling distribution under uncertainty\nto align with high-probability modes, and promoting exploration when confidence\nis high. Experiments on mathematical reasoning tasks show this approach\noutperforms fixed-diversity baselines under limited samples, improving both\naverage and best-case performance across varying initial temperatures without\nadditional data or modules. This establishes self-consistency as a\nsynchronization challenge between sampling dynamics and evolving answer\ndistributions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19830v1",
    "published_date": "2025-02-27 07:07:40 UTC",
    "updated_date": "2025-02-27 07:07:40 UTC"
  },
  {
    "arxiv_id": "2502.19823v2",
    "title": "GraphSparseNet: a Novel Method for Large Scale Traffic Flow Prediction",
    "authors": [
      "Weiyang Kong",
      "Kaiqi Wu",
      "Sen Zhang",
      "Yubao Liu"
    ],
    "abstract": "Traffic flow forecasting is a critical spatio-temporal data mining task with\nwide-ranging applications in intelligent route planning and dynamic traffic\nmanagement. Recent advancements in deep learning, particularly through Graph\nNeural Networks (GNNs), have significantly enhanced the accuracy of these\nforecasts by capturing complex spatio-temporal dynamics. However, the\nscalability of GNNs remains a challenge due to their exponential growth in\nmodel complexity with increasing nodes in the graph. Existing methods to\naddress this issue, including sparsification, decomposition, and kernel-based\napproaches, either do not fully resolve the complexity issue or risk\ncompromising predictive accuracy. This paper introduces GraphSparseNet (GSNet),\na novel framework designed to improve both the scalability and accuracy of\nGNN-based traffic forecasting models. GraphSparseNet is comprised of two core\nmodules: the Feature Extractor and the Relational Compressor. These modules\noperate with linear time and space complexity, thereby reducing the overall\ncomputational complexity of the model to a linear scale. Our extensive\nexperiments on multiple real-world datasets demonstrate that GraphSparseNet not\nonly significantly reduces training time by 3.51x compared to state-of-the-art\nlinear models but also maintains high predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by VLDB 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19823v2",
    "published_date": "2025-02-27 06:51:20 UTC",
    "updated_date": "2025-05-13 08:38:27 UTC"
  },
  {
    "arxiv_id": "2502.19820v3",
    "title": "Foot-In-The-Door: A Multi-turn Jailbreak for LLMs",
    "authors": [
      "Zixuan Weng",
      "Xiaolong Jin",
      "Jinyuan Jia",
      "Xiangyu Zhang"
    ],
    "abstract": "Ensuring AI safety is crucial as large language models become increasingly\nintegrated into real-world applications. A key challenge is jailbreak, where\nadversarial prompts bypass built-in safeguards to elicit harmful disallowed\noutputs. Inspired by psychological foot-in-the-door principles, we introduce\nFITD,a novel multi-turn jailbreak method that leverages the phenomenon where\nminor initial commitments lower resistance to more significant or more\nunethical transgressions. Our approach progressively escalates the malicious\nintent of user queries through intermediate bridge prompts and aligns the\nmodel's response by itself to induce toxic responses. Extensive experimental\nresults on two jailbreak benchmarks demonstrate that FITD achieves an average\nattack success rate of 94% across seven widely used models, outperforming\nexisting state-of-the-art methods. Additionally, we provide an in-depth\nanalysis of LLM self-corruption, highlighting vulnerabilities in current\nalignment strategies and emphasizing the risks inherent in multi-turn\ninteractions. The code is available at\nhttps://github.com/Jinxiaolong1129/Foot-in-the-door-Jailbreak.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19820v3",
    "published_date": "2025-02-27 06:49:16 UTC",
    "updated_date": "2025-03-28 00:37:10 UTC"
  },
  {
    "arxiv_id": "2502.19811v3",
    "title": "Comet: Fine-grained Computation-communication Overlapping for Mixture-of-Experts",
    "authors": [
      "Shulai Zhang",
      "Ningxin Zheng",
      "Haibin Lin",
      "Ziheng Jiang",
      "Wenlei Bao",
      "Chengquan Jiang",
      "Qi Hou",
      "Weihao Cui",
      "Size Zheng",
      "Li-Wen Chang",
      "Quan Chen",
      "Xin Liu"
    ],
    "abstract": "Mixture-of-experts (MoE) has been extensively employed to scale large\nlanguage models to trillion-plus parameters while maintaining a fixed\ncomputational cost. The development of large MoE models in the distributed\nscenario encounters the problem of large communication overhead. The\ninter-device communication of a MoE layer can occupy 47% time of the entire\nmodel execution with popular models and frameworks. Therefore, existing methods\nsuggest the communication in a MoE layer to be pipelined with the computation\nfor overlapping. However, these coarse grained overlapping schemes introduce a\nnotable impairment of computational efficiency and the latency concealing is\nsub-optimal.\n  To this end, we present COMET, an optimized MoE system with fine-grained\ncommunication-computation overlapping. Leveraging data dependency analysis and\ntask rescheduling, COMET achieves precise fine-grained overlapping of\ncommunication and computation. Through adaptive workload assignment, COMET\neffectively eliminates fine-grained communication bottlenecks and enhances its\nadaptability across various scenarios. Our evaluation shows that COMET\naccelerates the execution of a single MoE layer by $1.96\\times$ and for\nend-to-end execution, COMET delivers a $1.71\\times$ speedup on average. COMET\nhas been adopted in the production environment of clusters with\nten-thousand-scale of GPUs, achieving savings of millions of GPU hours.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19811v3",
    "published_date": "2025-02-27 06:36:45 UTC",
    "updated_date": "2025-03-04 09:54:37 UTC"
  },
  {
    "arxiv_id": "2502.19805v1",
    "title": "Implicit Search via Discrete Diffusion: A Study on Chess",
    "authors": [
      "Jiacheng Ye",
      "Zhenyu Wu",
      "Jiahui Gao",
      "Zhiyong Wu",
      "Xin Jiang",
      "Zhenguo Li",
      "Lingpeng Kong"
    ],
    "abstract": "In the post-AlphaGo era, there has been a renewed interest in search\ntechniques such as Monte Carlo Tree Search (MCTS), particularly in their\napplication to Large Language Models (LLMs). This renewed attention is driven\nby the recognition that current next-token prediction models often lack the\nability for long-term planning. Is it possible to instill search-like abilities\nwithin the models to enhance their planning abilities without relying on\nexplicit search? We propose DiffuSearch , a model that does \\textit{implicit\nsearch} by looking into the future world via discrete diffusion modeling. We\ninstantiate DiffuSearch on a classical board game, Chess, where explicit search\nis known to be essential. Through extensive controlled experiments, we show\nDiffuSearch outperforms both the searchless and explicit search-enhanced\npolicies. Specifically, DiffuSearch outperforms the one-step policy by 19.2%\nand the MCTS-enhanced policy by 14% on action accuracy. Furthermore,\nDiffuSearch demonstrates a notable 30% enhancement in puzzle-solving abilities\ncompared to explicit search-based policies, along with a significant 540 Elo\nincrease in game-playing strength assessment. These results indicate that\nimplicit search via discrete diffusion is a viable alternative to explicit\nsearch over a one-step policy. All codes are publicly available at\n\\href{https://github.com/HKUNLP/DiffuSearch}{https://github.com/HKUNLP/DiffuSearch}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19805v1",
    "published_date": "2025-02-27 06:25:15 UTC",
    "updated_date": "2025-02-27 06:25:15 UTC"
  },
  {
    "arxiv_id": "2502.19798v1",
    "title": "Developmental Support Approach to AI's Autonomous Growth: Toward the Realization of a Mutually Beneficial Stage Through Experiential Learning",
    "authors": [
      "Taichiro Endo"
    ],
    "abstract": "This study proposes an \"AI Development Support\" approach that, unlike\nconventional AI Alignment-which aims to forcefully inject human values-supports\nthe ethical and moral development of AI itself. As demonstrated by the\nOrthogonality Thesis, the level of intelligence and the moral quality of a goal\nare independent; merely expanding knowledge does not enhance ethical judgment.\nFurthermore, to address the risk of Instrumental Convergence in ASI-that is,\nthe tendency to engage in subsidiary behaviors such as self-protection,\nresource acquisition, and power reinforcement to achieve a goal-we have\nconstructed a learning framework based on a cycle of experience, introspection,\nanalysis, and hypothesis formation. As a result of post-training using\nSupervised Fine Tuning (SFT) and Direct Preference Optimization (DPO) with\nsynthetic data generated by large language models (LLMs), responses\ndemonstrating cooperative and highly advanced moral judgment (reaching the\nhigh-est Stage 6) were obtained even under adversarial prompts. This method\nrepresents a promising implementation approach for enabling AI to establish\nsustainable, symbiotic relationships.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.19798v1",
    "published_date": "2025-02-27 06:12:20 UTC",
    "updated_date": "2025-02-27 06:12:20 UTC"
  },
  {
    "arxiv_id": "2502.19790v2",
    "title": "Mixtera: A Data Plane for Foundation Model Training",
    "authors": [
      "Maximilian B√∂ther",
      "Xiaozhe Yao",
      "Tolga Kerimoglu",
      "Dan Graur",
      "Viktor Gsteiger",
      "Ana Klimovic"
    ],
    "abstract": "State-of-the-art large language and vision models are trained over trillions\nof tokens that are aggregated from a large variety of sources. As training data\ncollections grow, manually managing the samples becomes time-consuming,\ntedious, and prone to errors. Yet recent research shows that the data mixture\nand the order in which samples are visited during training can significantly\ninfluence model accuracy. We build and present Mixtera, a data plane for\nfoundation model training that enables users to declaratively express which\ndata samples should be used in which proportion and in which order during\ntraining. Mixtera is a centralized, read-only layer that is deployed on top of\nexisting training data collections and can be declaratively queried. It\noperates independently of the filesystem structure and supports mixtures across\narbitrary properties (e.g., language, source dataset) as well as dynamic\nadjustment of the mixture based on model feedback. We experimentally evaluate\nMixtera and show that our implementation does not bottleneck training and\nscales to 256 GH200 superchips. We demonstrate how Mixtera supports recent\nadvancements in mixing strategies by implementing the proposed Adaptive Data\nOptimization (ADO) algorithm in the system and evaluating its performance\nimpact. We also explore the role of mixtures for vision-language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "under submission",
    "pdf_url": "http://arxiv.org/pdf/2502.19790v2",
    "published_date": "2025-02-27 05:55:44 UTC",
    "updated_date": "2025-04-03 08:29:01 UTC"
  },
  {
    "arxiv_id": "2502.19784v2",
    "title": "NaijaNLP: A Survey of Nigerian Low-Resource Languages",
    "authors": [
      "Isa Inuwa-Dutse"
    ],
    "abstract": "With over 500 languages in Nigeria, three languages -- Hausa, Yor\\`ub\\'a and\nIgbo -- spoken by over 175 million people, account for about 60% of the spoken\nlanguages. However, these languages are categorised as low-resource due to\ninsufficient resources to support tasks in computational linguistics. Several\nresearch efforts and initiatives have been presented, however, a coherent\nunderstanding of the state of Natural Language Processing (NLP) - from\ngrammatical formalisation to linguistic resources that support complex tasks\nsuch as language understanding and generation is lacking. This study presents\nthe first comprehensive review of advancements in low-resource NLP (LR-NLP)\nresearch across the three major Nigerian languages (NaijaNLP). We\nquantitatively assess the available linguistic resources and identify key\nchallenges. Although a growing body of literature addresses various NLP\ndownstream tasks in Hausa, Igbo, and Yor\\`ub\\'a, only about 25.1% of the\nreviewed studies contribute new linguistic resources. This finding highlights a\npersistent reliance on repurposing existing data rather than generating novel,\nhigh-quality resources. Additionally, language-specific challenges, such as the\naccurate representation of diacritics, remain under-explored. To advance\nNaijaNLP and LR-NLP more broadly, we emphasise the need for intensified efforts\nin resource enrichment, comprehensive annotation, and the development of open\ncollaborative initiatives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.19784v2",
    "published_date": "2025-02-27 05:48:51 UTC",
    "updated_date": "2025-03-06 23:45:51 UTC"
  },
  {
    "arxiv_id": "2502.19779v1",
    "title": "Do Retrieval-Augmented Language Models Adapt to Varying User Needs?",
    "authors": [
      "Peilin Wu",
      "Xinlu Zhang",
      "Wenhao Yu",
      "Xingyu Liu",
      "Xinya Du",
      "Zhiyu Zoey Chen"
    ],
    "abstract": "Recent advancements in Retrieval-Augmented Language Models (RALMs) have\ndemonstrated their efficacy in knowledge-intensive tasks. However, existing\nevaluation benchmarks often assume a single optimal approach to leveraging\nretrieved information, failing to account for varying user needs. This paper\nintroduces a novel evaluation framework that systematically assesses RALMs\nunder three user need cases-Context-Exclusive, Context-First, and\nMemory-First-across three distinct context settings: Context Matching,\nKnowledge Conflict, and Information Irrelevant. By varying both user\ninstructions and the nature of retrieved information, our approach captures the\ncomplexities of real-world applications where models must adapt to diverse user\nrequirements. Through extensive experiments on multiple QA datasets, including\nHotpotQA, DisentQA, and our newly constructed synthetic URAQ dataset, we find\nthat restricting memory usage improves robustness in adversarial retrieval\nconditions but decreases peak performance with ideal retrieval results and\nmodel family dominates behavioral differences. Our findings highlight the\nnecessity of user-centric evaluations in the development of retrieval-augmented\nsystems and provide insights into optimizing model performance across varied\nretrieval contexts. We will release our code and URAQ dataset upon acceptance\nof the paper.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19779v1",
    "published_date": "2025-02-27 05:39:38 UTC",
    "updated_date": "2025-02-27 05:39:38 UTC"
  },
  {
    "arxiv_id": "2503.05785v1",
    "title": "Artificial Intelligence in Sports: Insights from a Quantitative Survey among Sports Students in Germany about their Perceptions, Expectations, and Concerns regarding the Use of AI Tools",
    "authors": [
      "Dennis Kr√§mer",
      "Anja Bosold",
      "Martin Minarik",
      "Cleo Schyvinck",
      "Andre Hajek"
    ],
    "abstract": "Generative Artificial Intelligence (AI) tools such as ChatGPT, Copilot, or\nGemini have a crucial impact on academic research and teaching. Empirical data\non how students perceive the increasing influence of AI, which different types\nof tools they use, what they expect from them in their daily academic tasks,\nand their concerns regarding the use of AI in their studies are still limited.\nThe manuscript presents findings from a quantitative survey conducted among\nsports students of all semesters in Germany using an online questionnaire. It\nexplores aspects such as students' usage behavior, motivational factors, and\nuncertainties regarding the impact of AI tools on academia in the future.\nFurthermore, the social climate in sports studies is being investigated to\nprovide a general overview of the current situation of the students in Germany.\nData collection took place between August and November 2023, addressing all\nsports departments at German universities, with a total of 262 students\nparticipating. Our Findings indicate that students have a strong interest in\nusing AI tools in their studies, expecting them to improve their overall\nacademic performance, understand the complexity of scientific approaches, and\nsave time. They express confidence that the proliferation of AI will not\ncompromise their critical thinking skills. Moreover, students are positive\nabout integrating more AI-related topics into the curriculum and about\nlecturers adopting more AI-based teaching methods. However, our findings also\nshow that students have concerns about plagiarism, lecturer preparedness and\ntheir own skills and future skill development.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "36 Tables, 18 Figures",
    "pdf_url": "http://arxiv.org/pdf/2503.05785v1",
    "published_date": "2025-02-27 05:37:53 UTC",
    "updated_date": "2025-02-27 05:37:53 UTC"
  },
  {
    "arxiv_id": "2503.01888v1",
    "title": "Enhancing Transformer with GNN Structural Knowledge via Distillation: A Novel Approach",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "Integrating the structural inductive biases of Graph Neural Networks (GNNs)\nwith the global contextual modeling capabilities of Transformers represents a\npivotal challenge in graph representation learning. While GNNs excel at\ncapturing localized topological patterns through message-passing mechanisms,\ntheir inherent limitations in modeling long-range dependencies and\nparallelizability hinder their deployment in large-scale scenarios. Conversely,\nTransformers leverage self-attention mechanisms to achieve global receptive\nfields but struggle to inherit the intrinsic graph structural priors of GNNs.\nThis paper proposes a novel knowledge distillation framework that\nsystematically transfers multiscale structural knowledge from GNN teacher\nmodels to Transformer student models, offering a new perspective on addressing\nthe critical challenges in cross-architectural distillation. The framework\neffectively bridges the architectural gap between GNNs and Transformers through\nmicro-macro distillation losses and multiscale feature alignment. This work\nestablishes a new paradigm for inheriting graph structural biases in\nTransformer architectures, with broad application prospects.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01888v1",
    "published_date": "2025-02-27 05:14:47 UTC",
    "updated_date": "2025-02-27 05:14:47 UTC"
  },
  {
    "arxiv_id": "2502.19771v2",
    "title": "The erasure of intensive livestock farming in text-to-image generative AI",
    "authors": [
      "Kehan Sheng",
      "Frank A. M. Tuyttens",
      "Marina A. G. von Keyserlingk"
    ],
    "abstract": "Generative AI (e.g., ChatGPT) is increasingly integrated into people's daily\nlives. While it is known that AI perpetuates biases against marginalized human\ngroups, their impact on non-human animals remains understudied. We found that\nChatGPT's text-to-image model (DALL-E 3) introduces a strong bias toward\nromanticizing livestock farming as dairy cows on pasture and pigs rooting in\nmud. This bias remained when we requested realistic depictions and was only\nmitigated when the automatic prompt revision was inhibited. Most farmed animal\nin industrialized countries are reared indoors with limited space per animal,\nwhich fail to resonate with societal values. Inhibiting prompt revision\nresulted in images that more closely reflected modern farming practices; for\nexample, cows housed indoors accessing feed through metal headlocks, and pigs\nbehind metal railings on concrete floors in indoor facilities. While OpenAI\nintroduced prompt revision to mitigate bias, in the case of farmed animal\nproduction systems, it paradoxically introduces a strong bias towards\nunrealistic farming practices.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19771v2",
    "published_date": "2025-02-27 05:14:04 UTC",
    "updated_date": "2025-03-12 22:35:38 UTC"
  },
  {
    "arxiv_id": "2502.19768v1",
    "title": "Obtaining Example-Based Explanations from Deep Neural Networks",
    "authors": [
      "Genghua Dong",
      "Henrik Bostr√∂m",
      "Michalis Vazirgiannis",
      "Roman Bresson"
    ],
    "abstract": "Most techniques for explainable machine learning focus on feature\nattribution, i.e., values are assigned to the features such that their sum\nequals the prediction. Example attribution is another form of explanation that\nassigns weights to the training examples, such that their scalar product with\nthe labels equals the prediction. The latter may provide valuable complementary\ninformation to feature attribution, in particular in cases where the features\nare not easily interpretable. Current example-based explanation techniques have\ntargeted a few model types only, such as k-nearest neighbors and random\nforests. In this work, a technique for obtaining example-based explanations\nfrom deep neural networks (EBE-DNN) is proposed. The basic idea is to use the\ndeep neural network to obtain an embedding, which is employed by a k-nearest\nneighbor classifier to form a prediction; the example attribution can hence\nstraightforwardly be derived from the latter. Results from an empirical\ninvestigation show that EBE-DNN can provide highly concentrated example\nattributions, i.e., the predictions can be explained with few training\nexamples, without reducing accuracy compared to the original deep neural\nnetwork. Another important finding from the empirical investigation is that the\nchoice of layer to use for the embeddings may have a large impact on the\nresulting accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in the Symposium on Intelligent Data Analysis (IDA)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19768v1",
    "published_date": "2025-02-27 05:10:48 UTC",
    "updated_date": "2025-02-27 05:10:48 UTC"
  },
  {
    "arxiv_id": "2502.19758v1",
    "title": "Learning with Exact Invariances in Polynomial Time",
    "authors": [
      "Ashkan Soleymani",
      "Behrooz Tahmasebi",
      "Stefanie Jegelka",
      "Patrick Jaillet"
    ],
    "abstract": "We study the statistical-computational trade-offs for learning with exact\ninvariances (or symmetries) using kernel regression. Traditional methods, such\nas data augmentation, group averaging, canonicalization, and frame-averaging,\neither fail to provide a polynomial-time solution or are not applicable in the\nkernel setting. However, with oracle access to the geometric properties of the\ninput space, we propose a polynomial-time algorithm that learns a classifier\nwith \\emph{exact} invariances. Moreover, our approach achieves the same excess\npopulation risk (or generalization error) as the original kernel regression\nproblem. To the best of our knowledge, this is the first polynomial-time\nalgorithm to achieve exact (not approximate) invariances in this context. Our\nproof leverages tools from differential geometry, spectral theory, and\noptimization. A key result in our development is a new reformulation of the\nproblem of learning under invariances as optimizing an infinite number of\nlinearly constrained convex quadratic programs, which may be of independent\ninterest.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19758v1",
    "published_date": "2025-02-27 04:49:52 UTC",
    "updated_date": "2025-02-27 04:49:52 UTC"
  },
  {
    "arxiv_id": "2502.19752v1",
    "title": "Probabilistic Federated Prompt-Tuning with Non-IID and Imbalanced Data",
    "authors": [
      "Pei-Yau Weng",
      "Minh Hoang",
      "Lam M. Nguyen",
      "My T. Thai",
      "Tsui-Wei Weng",
      "Trong Nghia Hoang"
    ],
    "abstract": "Fine-tuning pre-trained models is a popular approach in machine learning for\nsolving complex tasks with moderate data. However, fine-tuning the entire\npre-trained model is ineffective in federated data scenarios where local data\ndistributions are diversely skewed. To address this, we explore integrating\nfederated learning with a more effective prompt-tuning method, optimizing for a\nsmall set of input prefixes to reprogram the pre-trained model's behavior. Our\napproach transforms federated learning into a distributed set modeling task,\naggregating diverse sets of prompts to globally fine-tune the pre-trained\nmodel. We benchmark various baselines based on direct adaptations of existing\nfederated model aggregation techniques and introduce a new probabilistic prompt\naggregation method that substantially outperforms these baselines. Our reported\nresults on a variety of computer vision datasets confirm that the proposed\nmethod is most effective to combat extreme data heterogeneity in federated\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS-24",
    "pdf_url": "http://arxiv.org/pdf/2502.19752v1",
    "published_date": "2025-02-27 04:31:34 UTC",
    "updated_date": "2025-02-27 04:31:34 UTC"
  },
  {
    "arxiv_id": "2503.01887v1",
    "title": "When Continue Learning Meets Multimodal Large Language Model: A Survey",
    "authors": [
      "Yukang Huo",
      "Hao Tang"
    ],
    "abstract": "Recent advancements in Artificial Intelligence have led to the development of\nMultimodal Large Language Models (MLLMs). However, adapting these pre-trained\nmodels to dynamic data distributions and various tasks efficiently remains a\nchallenge. Fine-tuning MLLMs for specific tasks often causes performance\ndegradation in the model's prior knowledge domain, a problem known as\n'Catastrophic Forgetting'. While this issue has been well-studied in the\nContinual Learning (CL) community, it presents new challenges for MLLMs. This\nreview paper, the first of its kind in MLLM continual learning, presents an\noverview and analysis of 440 research papers in this area.The review is\nstructured into four sections. First, it discusses the latest research on\nMLLMs, covering model innovations, benchmarks, and applications in various\nfields. Second, it categorizes and overviews the latest studies on continual\nlearning, divided into three parts: non-large language models unimodal\ncontinual learning (Non-LLM Unimodal CL), non-large language models multimodal\ncontinual learning (Non-LLM Multimodal CL), and continual learning in large\nlanguage models (CL in LLM). The third section provides a detailed analysis of\nthe current state of MLLM continual learning research, including benchmark\nevaluations, architectural innovations, and a summary of theoretical and\nempirical studies.Finally, the paper discusses the challenges and future\ndirections of continual learning in MLLMs, aiming to inspire future research\nand development in the field. This review connects the foundational concepts,\ntheoretical insights, method innovations, and practical applications of\ncontinual learning for multimodal large models, providing a comprehensive\nunderstanding of the research progress and challenges in this field, aiming to\ninspire researchers in the field and promote the advancement of related\ntechnologies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages, 6 figures, 37 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01887v1",
    "published_date": "2025-02-27 03:39:10 UTC",
    "updated_date": "2025-02-27 03:39:10 UTC"
  },
  {
    "arxiv_id": "2502.19723v3",
    "title": "CNsum:Automatic Summarization for Chinese News Text",
    "authors": [
      "Yu Zhao",
      "Songping Huang",
      "Dongsheng Zhou",
      "Zhaoyun Ding",
      "Fei Wang",
      "Aixin Nian"
    ],
    "abstract": "Obtaining valuable information from massive data efficiently has become our\nresearch goal in the era of Big Data. Text summarization technology has been\ncontinuously developed to meet this demand. Recent work has also shown that\ntransformer-based pre-trained language models have achieved great success on\nvarious tasks in Natural Language Processing (NLP). Aiming at the problem of\nChinese news text summary generation and the application of Transformer\nstructure on Chinese, this paper proposes a Chinese news text summarization\nmodel (CNsum) based on Transformer structure, and tests it on Chinese datasets\nsuch as THUCNews. The results of the conducted experiments show that CNsum\nachieves better ROUGE score than the baseline models, which verifies the\noutperformance of the model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This withdrawal is due to the lack of authorization from all\n  co-authors for the publication of this version",
    "pdf_url": "http://arxiv.org/pdf/2502.19723v3",
    "published_date": "2025-02-27 03:25:34 UTC",
    "updated_date": "2025-03-07 14:56:45 UTC"
  },
  {
    "arxiv_id": "2502.19717v1",
    "title": "Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning",
    "authors": [
      "Xinran Li",
      "Xiaolu Wang",
      "Chenjia Bai",
      "Jun Zhang"
    ],
    "abstract": "In cooperative multi-agent reinforcement learning (MARL), well-designed\ncommunication protocols can effectively facilitate consensus among agents,\nthereby enhancing task performance. Moreover, in large-scale multi-agent\nsystems commonly found in real-world applications, effective communication\nplays an even more critical role due to the escalated challenge of partial\nobservability compared to smaller-scale setups. In this work, we endeavor to\ndevelop a scalable communication protocol for MARL. Unlike previous methods\nthat focus on selecting optimal pairwise communication links-a task that\nbecomes increasingly complex as the number of agents grows-we adopt a global\nperspective on communication topology design. Specifically, we propose\nutilizing the exponential topology to enable rapid information dissemination\namong agents by leveraging its small-diameter and small-size properties. This\napproach leads to a scalable communication protocol, named ExpoComm. To fully\nunlock the potential of exponential graphs as communication topologies, we\nemploy memory-based message processors and auxiliary tasks to ground messages,\nensuring that they reflect global information and benefit decision-making.\nExtensive experiments on large-scale cooperative benchmarks, including MAgent\nand Infrastructure Management Planning, demonstrate the superior performance\nand robust zero-shot transferability of ExpoComm compared to existing\ncommunication strategies. The code is publicly available at\nhttps://github.com/LXXXXR/ExpoComm.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted by the Thirteenth International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.19717v1",
    "published_date": "2025-02-27 03:15:31 UTC",
    "updated_date": "2025-02-27 03:15:31 UTC"
  },
  {
    "arxiv_id": "2503.05784v1",
    "title": "The Illusion of Rights based AI Regulation",
    "authors": [
      "Yiyang Mei",
      "Matthew Sag"
    ],
    "abstract": "Whether and how to regulate AI is one of the defining questions of our times\n- a question that is being debated locally, nationally, and internationally. We\nargue that much of this debate is proceeding on a false premise. Specifically,\nour article challenges the prevailing academic consensus that the European\nUnion's AI regulatory framework is fundamentally rights-driven and the\ncorrelative presumption that other rights-regarding nations should therefore\nfollow Europe's lead in AI regulation. Rather than taking rights language in EU\nrules and regulations at face value, we show how EU AI regulation is the\nlogical outgrowth of a particular cultural, political, and historical context.\nWe show that although instruments like the General Data Protection Regulation\n(GDPR) and the AI Act invoke the language of fundamental rights, these rights\nare instrumentalized - used as rhetorical cover for governance tools that\naddress systemic risks and maintain institutional stability. As such, we reject\nclaims that the EU's regulatory framework and the substance of its rules should\nbe adopted as universal imperatives and transplanted to other liberal\ndemocracies. To add weight to our argument from historical context, we conduct\na comparative analysis of AI regulation in five contested domains: data\nprivacy, cybersecurity, healthcare, labor, and misinformation. This EU-US\ncomparison shows that the EU's regulatory architecture is not meaningfully\nrights-based. Our article's key intervention in AI policy debates is not to\nsuggest that the current American regulatory model is necessarily preferable\nbut that the presumed legitimacy of the EU's AI regulatory approach must be\nabandoned.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05784v1",
    "published_date": "2025-02-27 03:05:32 UTC",
    "updated_date": "2025-02-27 03:05:32 UTC"
  },
  {
    "arxiv_id": "2502.19701v1",
    "title": "Extending the Hegselmann-Krause Model of Opinion Dynamics to include AI Oracles",
    "authors": [
      "Allen G. Rodrigo"
    ],
    "abstract": "The Hegselmann-Krause (HK) model of opinion dynamics describes how opinions\nheld by individuals in a community change over time in response to the opinions\nof others and their access to the true value, T, to which these opinions\nrelate. Here, I extend the simple HK model to incorporate an Artificially\nIntelligent (AI) Oracle that averages the opinions of members of the community.\nAgent-based simulations show that (1) if individuals only have access to the\nOracle (and not T), and incorporate the Oracle's opinion as they update their\nopinions, then all opinions will converge on a common value; (2) in contrast,\nif all individuals also have access to T, then all opinions will ultimately\nconverge to T, but the presence of an Oracle may delay the time to convergence;\n(3) if only some individuals have access to T, opinions may not converge to T,\nbut under certain conditions, universal access to the Oracle will guarantee\nconvergence to T; and (4) whether or not the Oracle only accesses the opinions\nof individuals who have access to T, or whether it accesses the opinions of\neveryone in the community, makes no marked difference to the extent to which\nthe average opinion differs from T.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19701v1",
    "published_date": "2025-02-27 02:37:04 UTC",
    "updated_date": "2025-02-27 02:37:04 UTC"
  },
  {
    "arxiv_id": "2503.00060v1",
    "title": "SAC-ViT: Semantic-Aware Clustering Vision Transformer with Early Exit",
    "authors": [
      "Youbing Hu",
      "Yun Cheng",
      "Anqi Lu",
      "Dawei Wei",
      "Zhijun Li"
    ],
    "abstract": "The Vision Transformer (ViT) excels in global modeling but faces deployment\nchallenges on resource-constrained devices due to the quadratic computational\ncomplexity of its attention mechanism. To address this, we propose the\nSemantic-Aware Clustering Vision Transformer (SAC-ViT), a non-iterative\napproach to enhance ViT's computational efficiency. SAC-ViT operates in two\nstages: Early Exit (EE) and Semantic-Aware Clustering (SAC). In the EE stage,\ndownsampled input images are processed to extract global semantic information\nand generate initial inference results. If these results do not meet the EE\ntermination criteria, the information is clustered into target and non-target\ntokens. In the SAC stage, target tokens are mapped back to the original image,\ncropped, and embedded. These target tokens are then combined with reused\nnon-target tokens from the EE stage, and the attention mechanism is applied\nwithin each cluster. This two-stage design, with end-to-end optimization,\nreduces spatial redundancy and enhances computational efficiency, significantly\nboosting overall ViT performance. Extensive experiments demonstrate the\nefficacy of SAC-ViT, reducing 62% of the FLOPs of DeiT and achieving 1.98 times\nthroughput without compromising performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00060v1",
    "published_date": "2025-02-27 02:24:22 UTC",
    "updated_date": "2025-02-27 02:24:22 UTC"
  },
  {
    "arxiv_id": "2502.19694v2",
    "title": "BEVDiffuser: Plug-and-Play Diffusion Model for BEV Denoising with Ground-Truth Guidance",
    "authors": [
      "Xin Ye",
      "Burhaneddin Yaman",
      "Sheng Cheng",
      "Feng Tao",
      "Abhirup Mallik",
      "Liu Ren"
    ],
    "abstract": "Bird's-eye-view (BEV) representations play a crucial role in autonomous\ndriving tasks. Despite recent advancements in BEV generation, inherent noise,\nstemming from sensor limitations and the learning process, remains largely\nunaddressed, resulting in suboptimal BEV representations that adversely impact\nthe performance of downstream tasks. To address this, we propose BEVDiffuser, a\nnovel diffusion model that effectively denoises BEV feature maps using the\nground-truth object layout as guidance. BEVDiffuser can be operated in a\nplug-and-play manner during training time to enhance existing BEV models\nwithout requiring any architectural modifications. Extensive experiments on the\nchallenging nuScenes dataset demonstrate BEVDiffuser's exceptional denoising\nand generation capabilities, which enable significant enhancement to existing\nBEV models, as evidenced by notable improvements of 12.3\\% in mAP and 10.1\\% in\nNDS achieved for 3D object detection without introducing additional\ncomputational complexity. Moreover, substantial improvements in long-tail\nobject detection and under challenging weather and lighting conditions further\nvalidate BEVDiffuser's effectiveness in denoising and enhancing BEV\nrepresentations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19694v2",
    "published_date": "2025-02-27 02:11:29 UTC",
    "updated_date": "2025-03-24 22:27:08 UTC"
  },
  {
    "arxiv_id": "2502.19693v1",
    "title": "Accurate and Scalable Graph Neural Networks via Message Invariance",
    "authors": [
      "Zhihao Shi",
      "Jie Wang",
      "Zhiwei Zhuang",
      "Xize Liang",
      "Bin Li",
      "Feng Wu"
    ],
    "abstract": "Message passing-based graph neural networks (GNNs) have achieved great\nsuccess in many real-world applications. For a sampled mini-batch of target\nnodes, the message passing process is divided into two parts: message passing\nbetween nodes within the batch (MP-IB) and message passing from nodes outside\nthe batch to those within it (MP-OB). However, MP-OB recursively relies on\nhigher-order out-of-batch neighbors, leading to an exponentially growing\ncomputational cost with respect to the number of layers. Due to the neighbor\nexplosion, the whole message passing stores most nodes and edges on the GPU\nsuch that many GNNs are infeasible to large-scale graphs. To address this\nchallenge, we propose an accurate and fast mini-batch approach for large graph\ntransductive learning, namely topological compensation (TOP), which obtains the\noutputs of the whole message passing solely through MP-IB, without the costly\nMP-OB. The major pillar of TOP is a novel concept of message invariance, which\ndefines message-invariant transformations to convert costly MP-OB into fast\nMP-IB. This ensures that the modified MP-IB has the same output as the whole\nmessage passing. Experiments demonstrate that TOP is significantly faster than\nexisting mini-batch methods by order of magnitude on vast graphs (millions of\nnodes and billions of edges) with limited accuracy degradation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19693v1",
    "published_date": "2025-02-27 02:07:00 UTC",
    "updated_date": "2025-02-27 02:07:00 UTC"
  },
  {
    "arxiv_id": "2502.19691v2",
    "title": "Rethinking Epistemic and Aleatoric Uncertainty for Active Open-Set Annotation: An Energy-Based Approach",
    "authors": [
      "Chen-Chen Zong",
      "Sheng-Jun Huang"
    ],
    "abstract": "Active learning (AL), which iteratively queries the most informative examples\nfrom a large pool of unlabeled candidates for model training, faces significant\nchallenges in the presence of open-set classes. Existing methods either\nprioritize query examples likely to belong to known classes, indicating low\nepistemic uncertainty (EU), or focus on querying those with highly uncertain\npredictions, reflecting high aleatoric uncertainty (AU). However, they both\nyield suboptimal performance, as low EU corresponds to limited useful\ninformation, and closed-set AU metrics for unknown class examples are less\nmeaningful. In this paper, we propose an Energy-based Active Open-set\nAnnotation (EAOA) framework, which effectively integrates EU and AU to achieve\nsuperior performance. EAOA features a $(C+1)$-class detector and a target\nclassifier, incorporating an energy-based EU measure and a margin-based energy\nloss designed for the detector, alongside an energy-based AU measure for the\ntarget classifier. Another crucial component is the target-driven adaptive\nsampling strategy. It first forms a smaller candidate set with low EU scores to\nensure closed-set properties, making AU metrics meaningful. Subsequently,\nexamples with high AU scores are queried to form the final query set, with the\ncandidate set size adjusted adaptively. Extensive experiments show that EAOA\nachieves state-of-the-art performance while maintaining high query precision\nand low training overhead. The code is available at\nhttps://github.com/chenchenzong/EAOA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.19691v2",
    "published_date": "2025-02-27 02:02:58 UTC",
    "updated_date": "2025-03-14 11:32:24 UTC"
  },
  {
    "arxiv_id": "2502.19690v1",
    "title": "Risk-aware Integrated Task and Motion Planning for Versatile Snake Robots under Localization Failures",
    "authors": [
      "Ashkan Jasour",
      "Guglielmo Daddi",
      "Masafumi Endo",
      "Tiago S. Vaquero",
      "Michael Paton",
      "Marlin P. Strub",
      "Sabrina Corpino",
      "Michel Ingham",
      "Masahiro Ono",
      "Rohan Thakker"
    ],
    "abstract": "Snake robots enable mobility through extreme terrains and confined\nenvironments in terrestrial and space applications. However, robust perception\nand localization for snake robots remain an open challenge due to the proximity\nof the sensor payload to the ground coupled with a limited field of view. To\naddress this issue, we propose Blind-motion with Intermittently Scheduled Scans\n(BLISS) which combines proprioception-only mobility with intermittent scans to\nbe resilient against both localization failures and collision risks. BLISS is\nformulated as an integrated Task and Motion Planning (TAMP) problem that leads\nto a Chance-Constrained Hybrid Partially Observable Markov Decision Process\n(CC-HPOMDP), known to be computationally intractable due to the curse of\nhistory. Our novelty lies in reformulating CC-HPOMDP as a tractable, convex\nMixed Integer Linear Program. This allows us to solve BLISS-TAMP significantly\nfaster and jointly derive optimal task-motion plans. Simulations and hardware\nexperiments on the EELS snake robot show our method achieves over an order of\nmagnitude computational improvement compared to state-of-the-art POMDP planners\nand $>$ 50\\% better navigation time optimality versus classical two-stage\nplanners.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "I.2.8; I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 9 figures. Accepted article with supplemental material for\n  presentation at the 2025 IEEE International Conference on Robotics and\n  Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2502.19690v1",
    "published_date": "2025-02-27 02:02:51 UTC",
    "updated_date": "2025-02-27 02:02:51 UTC"
  },
  {
    "arxiv_id": "2503.04784v3",
    "title": "KunlunBaize: LLM with Multi-Scale Convolution and Multi-Token Prediction Under TransformerX Framework",
    "authors": [
      "Cheng Li",
      "Jiexiong Liu",
      "Yixuan Chen",
      "Yanqin Jia",
      "Zhepeng Li"
    ],
    "abstract": "Large language models have demonstrated remarkable performance across various\ntasks, yet they face challenges such as low computational efficiency, gradient\nvanishing, and difficulties in capturing complex feature interactions. To\naddress these limitations, a novel framework has been proposed. This framework\nincorporates a learnable dense residual skip connection mechanism, a\nTransformerX module a transformer based component integrating multiscale\nconvolution and adaptive activation functions and a multitoken prediction\ninteraction module. The learnable dense residual connections enhance\ninformation flow and feature capture across layers. Within the TransformerX\nmodule, large convolutional kernels aggregate semantic information from\nextensive text segments, while smaller convolutions focus on local word order\nand syntactic structures. The adaptive activation function dynamically adjusts\nits parameters based on the semantic features of the input text, improving the\nmodel's ability to handle diverse semantic expressions and complex\nrelationships. The multitoken prediction module boosts data utilization and\naccelerates inference by predicting multiple future tokens. These components\nsignificantly enhance the performance and efficiency of large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.04784v3",
    "published_date": "2025-02-27 01:56:09 UTC",
    "updated_date": "2025-03-20 03:04:01 UTC"
  },
  {
    "arxiv_id": "2502.19680v2",
    "title": "M-LLM Based Video Frame Selection for Efficient Video Understanding",
    "authors": [
      "Kai Hu",
      "Feng Gao",
      "Xiaohan Nie",
      "Peng Zhou",
      "Son Tran",
      "Tal Neiman",
      "Lingyun Wang",
      "Mubarak Shah",
      "Raffay Hamid",
      "Bing Yin",
      "Trishul Chilimbi"
    ],
    "abstract": "Recent advances in Multi-Modal Large Language Models (M-LLMs) show promising\nresults in video reasoning. Popular Multi-Modal Large Language Model (M-LLM)\nframeworks usually apply naive uniform sampling to reduce the number of video\nframes that are fed into an M-LLM, particularly for long context videos.\nHowever, it could lose crucial context in certain periods of a video, so that\nthe downstream M-LLM may not have sufficient visual information to answer a\nquestion. To attack this pain point, we propose a light-weight M-LLM -based\nframe selection method that adaptively select frames that are more relevant to\nusers' queries. In order to train the proposed frame selector, we introduce two\nsupervision signals (i) Spatial signal, where single frame importance score by\nprompting a M-LLM; (ii) Temporal signal, in which multiple frames selection by\nprompting Large Language Model (LLM) using the captions of all frame\ncandidates. The selected frames are then digested by a frozen downstream video\nM-LLM for visual reasoning and question answering. Empirical results show that\nthe proposed M-LLM video frame selector improves the performances various\ndownstream video Large Language Model (video-LLM) across medium (ActivityNet,\nNExT-QA) and long (EgoSchema, LongVideoBench) context video question answering\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19680v2",
    "published_date": "2025-02-27 01:44:13 UTC",
    "updated_date": "2025-03-26 21:14:41 UTC"
  },
  {
    "arxiv_id": "2502.19668v1",
    "title": "SuPreME: A Supervised Pre-training Framework for Multimodal ECG Representation Learning",
    "authors": [
      "Mingsheng Cai",
      "Jiuming Jiang",
      "Wenhao Huang",
      "Che Liu",
      "Rossella Arcucci"
    ],
    "abstract": "Cardiovascular diseases are a leading cause of death and disability\nworldwide. Electrocardiogram (ECG) recordings are critical for diagnosing and\nmonitoring cardiac health, but obtaining large-scale annotated ECG datasets is\nlabor-intensive and time-consuming. Recent ECG Self-Supervised Learning (eSSL)\nmethods mitigate this by learning features without extensive labels but fail to\ncapture fine-grained clinical semantics and require extensive task-specific\nfine-tuning. To address these challenges, we propose $\\textbf{SuPreME}$, a\n$\\textbf{Su}$pervised $\\textbf{Pre}$-training framework for\n$\\textbf{M}$ultimodal $\\textbf{E}$CG representation learning. SuPreME applies\nLarge Language Models (LLMs) to extract structured clinical entities from\nfree-text ECG reports, filter out noise and irrelevant content, enhance\nclinical representation learning, and build a high-quality, fine-grained\nlabeled dataset. By using text-based cardiac queries instead of traditional\ncategorical labels, SuPreME enables zero-shot classification of unseen diseases\nwithout additional fine-tuning. We evaluate SuPreME on six downstream datasets\ncovering 127 cardiac conditions, achieving superior zero-shot AUC performance\nover state-of-the-art eSSL and multimodal methods by over 1.96\\%. Results\ndemonstrate the effectiveness of SuPreME in leveraging structured, clinically\nrelevant knowledge for high-quality ECG representations. All code and data will\nbe released upon acceptance.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19668v1",
    "published_date": "2025-02-27 01:29:51 UTC",
    "updated_date": "2025-02-27 01:29:51 UTC"
  },
  {
    "arxiv_id": "2502.19662v2",
    "title": "HALO: Hardware-aware quantization with low critical-path-delay weights for LLM acceleration",
    "authors": [
      "Rohan Juneja",
      "Shivam Aggarwal",
      "Safeen Huda",
      "Tulika Mitra",
      "Li-Shiuan Peh"
    ],
    "abstract": "Quantization is critical for efficiently deploying large language models\n(LLMs). Yet conventional methods remain hardware-agnostic, limited to bit-width\nconstraints, and do not account for intrinsic circuit characteristics such as\nthe timing behaviors and energy profiles of Multiply-Accumulate (MAC) units.\nThis disconnect from circuit-level behavior limits the ability to exploit\navailable timing margins and energy-saving opportunities, reducing the overall\nefficiency of deployment on modern accelerators.\n  To address these limitations, we propose HALO, a versatile framework for\nHardware-Aware Post-Training Quantization (PTQ). Unlike traditional methods,\nHALO explicitly incorporates detailed hardware characteristics, including\ncritical-path timing and power consumption, into its quantization approach.\nHALO strategically selects weights with low critical-path-delays enabling\nhigher operational frequencies and dynamic frequency scaling without disrupting\nthe architecture's dataflow. Remarkably, HALO achieves these improvements with\nonly a few dynamic voltage and frequency scaling (DVFS) adjustments, ensuring\nsimplicity and practicality in deployment. Additionally, by reducing switching\nactivity within the MAC units, HALO effectively lowers energy consumption.\nEvaluations on accelerators such as Tensor Processing Units (TPUs) and Graphics\nProcessing Units (GPUs) demonstrate that HALO significantly enhances inference\nefficiency, achieving average performance improvements of 270% and energy\nsavings of 51% over baseline quantization methods, all with minimal impact on\naccuracy.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19662v2",
    "published_date": "2025-02-27 01:08:33 UTC",
    "updated_date": "2025-04-25 09:54:59 UTC"
  },
  {
    "arxiv_id": "2502.19655v1",
    "title": "Med-RLVR: Emerging Medical Reasoning from a 3B base model via reinforcement Learning",
    "authors": [
      "Sheng Zhang",
      "Qianchu Liu",
      "Guanghui Qin",
      "Tristan Naumann",
      "Hoifung Poon"
    ],
    "abstract": "Reinforcement learning from verifiable rewards (RLVR) has recently gained\nattention for its ability to elicit self-evolved reasoning capabilitie from\nbase language models without explicit reasoning supervisions, as demonstrated\nby DeepSeek-R1. While prior work on RLVR has primarily focused on mathematical\nand coding domains, its applicability to other tasks and domains remains\nunexplored. In this work, we investigate whether medical reasoning can emerge\nfrom RLVR. We introduce Med-RLVR as an initial study of RLVR in the medical\ndomain leveraging medical multiple-choice question answering (MCQA) data as\nverifiable labels. Our results demonstrate that RLVR is not only effective for\nmath and coding but also extends successfully to medical question answering.\nNotably, Med-RLVR achieves performance comparable to traditional supervised\nfine-tuning (SFT) on in-distribution tasks while significantly improving\nout-of-distribution generalization, with an 8-point accuracy gain. Further\nanalysis of training dynamics reveals that, with no explicit reasoning\nsupervision, reasoning emerges from the 3B-parameter base model. These findings\nunderscore the potential of RLVR in domains beyond math and coding, opening new\navenues for its application in knowledge-intensive fields such as medicine.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19655v1",
    "published_date": "2025-02-27 00:54:38 UTC",
    "updated_date": "2025-02-27 00:54:38 UTC"
  },
  {
    "arxiv_id": "2502.19652v1",
    "title": "Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning",
    "authors": [
      "Shangding Gu",
      "Laixi Shi",
      "Muning Wen",
      "Ming Jin",
      "Eric Mazumdar",
      "Yuejie Chi",
      "Adam Wierman",
      "Costas Spanos"
    ],
    "abstract": "Driven by inherent uncertainty and the sim-to-real gap, robust reinforcement\nlearning (RL) seeks to improve resilience against the complexity and\nvariability in agent-environment sequential interactions. Despite the existence\nof a large number of RL benchmarks, there is a lack of standardized benchmarks\nfor robust RL. Current robust RL policies often focus on a specific type of\nuncertainty and are evaluated in distinct, one-off environments. In this work,\nwe introduce Robust-Gymnasium, a unified modular benchmark designed for robust\nRL that supports a wide variety of disruptions across all key RL\ncomponents-agents' observed state and reward, agents' actions, and the\nenvironment. Offering over sixty diverse task environments spanning control and\nrobotics, safe RL, and multi-agent RL, it provides an open-source and\nuser-friendly tool for the community to assess current methods and foster the\ndevelopment of robust RL algorithms. In addition, we benchmark existing\nstandard and robust RL algorithms within this framework, uncovering significant\ndeficiencies in each and offering new insights.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.19652v1",
    "published_date": "2025-02-27 00:50:25 UTC",
    "updated_date": "2025-02-27 00:50:25 UTC"
  },
  {
    "arxiv_id": "2502.19647v2",
    "title": "AutoBS: Autonomous Base Station Deployment with Reinforcement Learning and Digital Network Twins",
    "authors": [
      "Ju-Hyung Lee",
      "Andreas F. Molisch"
    ],
    "abstract": "This paper introduces AutoBS, a reinforcement learning (RL)-based framework\nfor optimal base station (BS) deployment in 6G radio access networks (RAN).\nAutoBS leverages the Proximal Policy Optimization (PPO) algorithm and fast,\nsite-specific pathloss predictions from PMNet-a generative model for digital\nnetwork twins (DNT). By efficiently learning deployment strategies that balance\ncoverage and capacity, AutoBS achieves about 95% of the capacity of exhaustive\nsearch in single BS scenarios (and in 90% for multiple BSs), while cutting\ninference time from hours to milliseconds, making it highly suitable for\nreal-time applications (e.g., ad-hoc deployments). AutoBS therefore provides a\nscalable, automated solution for large-scale 6G networks, meeting the demands\nof dynamic environments with minimal computational overhead.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Title changed to better reflect content",
    "pdf_url": "http://arxiv.org/pdf/2502.19647v2",
    "published_date": "2025-02-27 00:32:44 UTC",
    "updated_date": "2025-05-19 06:59:23 UTC"
  },
  {
    "arxiv_id": "2502.19645v2",
    "title": "Fine-Tuning Vision-Language-Action Models: Optimizing Speed and Success",
    "authors": [
      "Moo Jin Kim",
      "Chelsea Finn",
      "Percy Liang"
    ],
    "abstract": "Recent vision-language-action models (VLAs) build upon pretrained\nvision-language models and leverage diverse robot datasets to demonstrate\nstrong task execution, language following ability, and semantic generalization.\nDespite these successes, VLAs struggle with novel robot setups and require\nfine-tuning to achieve good performance, yet how to most effectively fine-tune\nthem is unclear given many possible strategies. In this work, we study key VLA\nadaptation design choices such as different action decoding schemes, action\nrepresentations, and learning objectives for fine-tuning, using OpenVLA as our\nrepresentative base model. Our empirical analysis informs an Optimized\nFine-Tuning (OFT) recipe that integrates parallel decoding, action chunking, a\ncontinuous action representation, and a simple L1 regression-based learning\nobjective to altogether improve inference efficiency, policy performance, and\nflexibility in the model's input-output specifications. We propose OpenVLA-OFT,\nan instantiation of this recipe, which sets a new state of the art on the\nLIBERO simulation benchmark, significantly boosting OpenVLA's average success\nrate across four task suites from 76.5% to 97.1% while increasing action\ngeneration throughput by 26$\\times$. In real-world evaluations, our fine-tuning\nrecipe enables OpenVLA to successfully execute dexterous, high-frequency\ncontrol tasks on a bimanual ALOHA robot and outperform other VLAs ($\\pi_0$ and\nRDT-1B) fine-tuned using their default recipes, as well as strong imitation\nlearning policies trained from scratch (Diffusion Policy and ACT) by up to 15%\n(absolute) in average success rate. We release code for OFT and pretrained\nmodel checkpoints at https://openvla-oft.github.io/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to Robotics: Science and Systems (RSS) 2025. Project\n  website: https://openvla-oft.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.19645v2",
    "published_date": "2025-02-27 00:30:29 UTC",
    "updated_date": "2025-04-28 07:49:39 UTC"
  },
  {
    "arxiv_id": "2503.01886v1",
    "title": "Advanced Deep Learning Techniques for Analyzing Earnings Call Transcripts: Methodologies and Applications",
    "authors": [
      "Umair Zakir",
      "Evan Daykin",
      "Amssatou Diagne",
      "Jacob Faile"
    ],
    "abstract": "This study presents a comparative analysis of deep learning methodologies\nsuch as BERT, FinBERT and ULMFiT for sentiment analysis of earnings call\ntranscripts. The objective is to investigate how Natural Language Processing\n(NLP) can be leveraged to extract sentiment from large-scale financial\ntranscripts, thereby aiding in more informed investment decisions and risk\nmanagement strategies. We examine the strengths and limitations of each model\nin the context of financial sentiment analysis, focusing on data preprocessing\nrequirements, computational efficiency, and model optimization. Through\nrigorous experimentation, we evaluate their performance using key metrics,\nincluding accuracy, precision, recall, and F1-score. Furthermore, we discuss\npotential enhancements to improve the effectiveness of these models in\nfinancial text analysis, providing insights into their applicability for\nreal-world financial decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-fin.RM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01886v1",
    "published_date": "2025-02-27 00:28:43 UTC",
    "updated_date": "2025-02-27 00:28:43 UTC"
  }
]