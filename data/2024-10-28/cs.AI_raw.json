[
  {
    "arxiv_id": "2410.21620v1",
    "title": "Asynchronous Tool Usage for Real-Time Agents",
    "authors": [
      "Antonio A. Ginart",
      "Naveen Kodali",
      "Jason Lee",
      "Caiming Xiong",
      "Silvio Savarese",
      "John Emmons"
    ],
    "abstract": "While frontier large language models (LLMs) are capable tool-using agents,\ncurrent AI systems still operate in a strict turn-based fashion, oblivious to\npassage of time. This synchronous design forces user queries and tool-use to\noccur sequentially, preventing the systems from multitasking and reducing\ninteractivity. To address this limitation, we introduce asynchronous AI agents\ncapable of parallel processing and real-time tool-use. Our key contribution is\nan event-driven finite-state machine architecture for agent execution and\nprompting, integrated with automatic speech recognition and text-to-speech.\nDrawing inspiration from the concepts originally developed for real-time\noperating systems, this work presents both a conceptual framework and practical\ntools for creating AI agents capable of fluid, multitasking interactions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21620v1",
    "published_date": "2024-10-28 23:57:19 UTC",
    "updated_date": "2024-10-28 23:57:19 UTC"
  },
  {
    "arxiv_id": "2410.21616v1",
    "title": "Identifying Selections for Unsupervised Subtask Discovery",
    "authors": [
      "Yiwen Qiu",
      "Yujia Zheng",
      "Kun Zhang"
    ],
    "abstract": "When solving long-horizon tasks, it is intriguing to decompose the high-level\ntask into subtasks. Decomposing experiences into reusable subtasks can improve\ndata efficiency, accelerate policy generalization, and in general provide\npromising solutions to multi-task reinforcement learning and imitation learning\nproblems. However, the concept of subtasks is not sufficiently understood and\nmodeled yet, and existing works often overlook the true structure of the data\ngeneration process: subtasks are the results of a $\\textit{selection}$\nmechanism on actions, rather than possible underlying confounders or\nintermediates. Specifically, we provide a theory to identify, and experiments\nto verify the existence of selection variables in such data. These selections\nserve as subgoals that indicate subtasks and guide policy. In light of this\nidea, we develop a sequential non-negative matrix factorization (seq- NMF)\nmethod to learn these subgoals and extract meaningful behavior patterns as\nsubtasks. Our empirical results on a challenging Kitchen environment\ndemonstrate that the learned subtasks effectively enhance the generalization to\nnew tasks in multi-task imitation learning scenarios. The codes are provided at\nhttps://anonymous.4open.science/r/Identifying\\_Selections\\_for\\_Unsupervised\\_Subtask\\_Discovery/README.md.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21616v1",
    "published_date": "2024-10-28 23:47:43 UTC",
    "updated_date": "2024-10-28 23:47:43 UTC"
  },
  {
    "arxiv_id": "2410.22371v2",
    "title": "Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs",
    "authors": [
      "Chun-Wei Kong",
      "Luca Laurenti",
      "Jay McMahon",
      "Morteza Lahijanian"
    ],
    "abstract": "Stochastic differential equations are commonly used to describe the evolution\nof stochastic processes. The state uncertainty of such processes is best\nrepresented by the probability density function (PDF), whose evolution is\ngoverned by the Fokker-Planck partial differential equation (FP-PDE). However,\nit is generally infeasible to solve the FP-PDE in closed form. In this work, we\nshow that physics-informed neural networks (PINNs) can be trained to\napproximate the solution PDF. Our main contribution is the analysis of PINN\napproximation error: we develop a theoretical framework to construct tight\nerror bounds using PINNs. In addition, we derive a practical error bound that\ncan be efficiently constructed with standard training methods. We discuss that\nthis error-bound framework generalizes to approximate solutions of other linear\nPDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems\nvalidate the correctness of our error bounds while demonstrating the\nscalability of PINNs and their significant computational speedup in obtaining\naccurate PDF solutions compared to the Monte Carlo approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "paper under review",
    "pdf_url": "http://arxiv.org/pdf/2410.22371v2",
    "published_date": "2024-10-28 23:25:55 UTC",
    "updated_date": "2025-03-03 16:16:00 UTC"
  },
  {
    "arxiv_id": "2410.22370v1",
    "title": "Survey of User Interface Design and Interaction Techniques in Generative AI Applications",
    "authors": [
      "Reuben Luera",
      "Ryan A. Rossi",
      "Alexa Siu",
      "Franck Dernoncourt",
      "Tong Yu",
      "Sungchul Kim",
      "Ruiyi Zhang",
      "Xiang Chen",
      "Hanieh Salehy",
      "Jian Zhao",
      "Samyadeep Basu",
      "Puneet Mathur",
      "Nedim Lipka"
    ],
    "abstract": "The applications of generative AI have become extremely impressive, and the\ninterplay between users and AI is even more so. Current human-AI interaction\nliterature has taken a broad look at how humans interact with generative AI,\nbut it lacks specificity regarding the user interface designs and patterns used\nto create these applications. Therefore, we present a survey that\ncomprehensively presents taxonomies of how a human interacts with AI and the\nuser interaction patterns designed to meet the needs of a variety of relevant\nuse cases. We focus primarily on user-guided interactions, surveying\ninteractions that are initiated by the user and do not include any implicit\nsignals given by the user. With this survey, we aim to create a compendium of\ndifferent user-interaction patterns that can be used as a reference for\ndesigners and developers alike. In doing so, we also strive to lower the entry\nbarrier for those attempting to learn more about the design of generative AI\napplications.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22370v1",
    "published_date": "2024-10-28 23:10:06 UTC",
    "updated_date": "2024-10-28 23:10:06 UTC"
  },
  {
    "arxiv_id": "2410.21597v2",
    "title": "Reducing the Scope of Language Models",
    "authors": [
      "David Yunis",
      "Siyu Huo",
      "Chulaka Gunasekara",
      "Danish Contractor"
    ],
    "abstract": "We now deploy language models in a wide variety of user-facing applications.\nTypically, these deployments have some specific purpose, like answering\nquestions about documentation or acting as coding assistants, but they require\ngeneral language understanding. Under these circumstances these models should\nnot be able to answer irrelevant requests such as, poetry generation or\nquestions about physics, etc. Instead we would like language models to only\nanswer to queries corresponding to desired behavior and refuse all other\nrequests, which we refer to as scoping. We conduct a comprehensive empirical\nevaluation of potential methods from prompting to fine-tuning to preference\nlearning to a recently proposed method for general alignment called Circuit\nBreakers (CB). Across three families of language models and a broad variety of\ntasks, we show that it is possible to scope language models. We examine scoping\nfor multiple topics, and fine-grained topics. We ablate diversity of irrelevant\nqueries, layer different techniques, conduct adversarial evaluations and more.\nAmong other results, we find that, when diverse examples of irrelevant queries\nare available, simple supervised fine-tuning produces the best results, but\nwhen such diversity is low, Circuit Breakers perform quite well. One can often\nget the benefits of both methods by layering them in succession. We intend our\nstudy to serve as a practitioner's guide to scoping language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21597v2",
    "published_date": "2024-10-28 23:06:57 UTC",
    "updated_date": "2025-04-17 19:17:21 UTC"
  },
  {
    "arxiv_id": "2410.21591v2",
    "title": "Can Large Language Models Replace Data Scientists in Biomedical Research?",
    "authors": [
      "Zifeng Wang",
      "Benjamin Danek",
      "Ziwei Yang",
      "Zheng Chen",
      "Jimeng Sun"
    ],
    "abstract": "Data science plays a critical role in biomedical research, but it requires\nprofessionals with expertise in coding and medical data analysis. Large\nlanguage models (LLMs) have shown great potential in supporting medical tasks\nand performing well in general coding tests. However, existing evaluations fail\nto assess their capability in biomedical data science, particularly in handling\ndiverse data types such as genomics and clinical datasets. To address this gap,\nwe developed a benchmark of data science coding tasks derived from the analyses\nof 39 published studies. This benchmark comprises 293 coding tasks (128 in\nPython and 165 in R) performed on real-world TCGA-type genomics and clinical\ndata. Our findings reveal that the vanilla prompting of LLMs yields suboptimal\nperformances due to drawbacks in following input instructions, understanding\ntarget data, and adhering to standard analysis practices. Next, we benchmarked\nsix cutting-edge LLMs and advanced adaptation methods, finding two methods to\nbe particularly effective: chain-of-thought prompting, which provides a\nstep-by-step plan for data analysis, which led to a 21% code accuracy\nimprovement (56.6% versus 35.3%); and self-reflection, enabling LLMs to refine\nthe buggy code iteratively, yielding an 11% code accuracy improvement (45.5%\nversus 34.3%). Building on these insights, we developed a platform that\nintegrates LLMs into the data science workflow for medical professionals. In a\nuser study with five medical professionals, we found that while LLMs cannot\nfully automate programming tasks, they significantly streamline the programming\nprocess. We found that 80% of their submitted code solutions were incorporated\nfrom LLM-generated code, with up to 96% reuse in some cases. Our analysis\nhighlights the potential of LLMs to enhance data science efficiency in\nbiomedical research when integrated into expert workflows.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21591v2",
    "published_date": "2024-10-28 22:48:06 UTC",
    "updated_date": "2025-04-08 21:48:54 UTC"
  },
  {
    "arxiv_id": "2410.21582v2",
    "title": "ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Always Guarantee Robustness after Fine-Tuning",
    "authors": [
      "Jaedong Hwang",
      "Brian Cheung",
      "Zhang-Wei Hong",
      "Akhilan Boopathy",
      "Pulkit Agrawal",
      "Ila Fiete"
    ],
    "abstract": "Highly performant large-scale pre-trained models promise to also provide a\nvaluable foundation for learning specialized tasks, by fine-tuning the model to\nthe desired task. By starting from a good general-purpose model, the goal is to\nachieve both specialization in the target task and maintain robustness. To\nassess the robustness of models on out-of-distribution samples after\nfine-tuning on downstream datasets, we introduce a new robust fine-tuning\nbenchmark, ImageNet-RIB (Robustness Inheritance Benchmark). The benchmark\nconsists of a set of related but distinct specialized (downstream) datasets;\npre-trained models are fine-tuned on one dataset in the set and their\nrobustness is assessed on the rest, iterating across all tasks for fine-tuning\nand assessment. The distance between the pre-training and downstream datasets,\nmeasured by optimal transport, predicts this performance degradation on the\npre-training dataset. Though continual learning methods help maintain\nrobustness, fine-tuning generally reduces generalization performance on related\ndownstream tasks across models. Counterintuitively, model robustness after\nfine-tuning on related downstream tasks is the worst when the pre-training\ndataset is the richest and the most diverse. This suggests that starting with\nthe strongest foundation model is not necessarily the best approach for\nperformance on specialist tasks. ImageNet-RIB thus offers key insights for\ndeveloping more resilient fine-tuning strategies and building robust machine\nlearning models. https://jd730.github.io/projects/ImageNet-RIB",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21582v2",
    "published_date": "2024-10-28 22:33:22 UTC",
    "updated_date": "2025-02-04 21:37:53 UTC"
  },
  {
    "arxiv_id": "2411.00024v3",
    "title": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges",
    "authors": [
      "Zifeng Wang",
      "Hanyin Wang",
      "Benjamin Danek",
      "Ying Li",
      "Christina Mack",
      "Hoifung Poon",
      "Yajuan Wang",
      "Pranav Rajpurkar",
      "Jimeng Sun"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into medical applications has\nsparked widespread interest across the healthcare industry, from drug discovery\nand development to clinical decision support, assisting telemedicine, medical\ndevices, and healthcare insurance applications. This perspective paper aims to\ndiscuss the inner workings of building LLM-powered medical AI applications and\nintroduces a comprehensive framework for their development. We review existing\nliterature and outline the unique challenges of applying LLMs in specialized\nmedical contexts. Additionally, we introduce a three-step framework to organize\nmedical LLM research activities: 1) Modeling: breaking down complex medical\nworkflows into manageable steps for developing medical-specific models; 2)\nOptimization: optimizing the model performance with crafted prompts and\nintegrating external knowledge and tools, and 3) System engineering:\ndecomposing complex tasks into subtasks and leveraging human expertise for\nbuilding medical AI applications. Furthermore, we offer a detailed use case\nplaybook that describes various LLM-powered medical AI applications, such as\noptimizing clinical trial design, enhancing clinical decision support, and\nadvancing medical imaging analysis. Finally, we discuss various challenges and\nconsiderations for building medical AI applications with LLMs, such as handling\nhallucination issues, data ownership and compliance, privacy, intellectual\nproperty considerations, compute cost, sustainability issues, and responsible\nAI requirements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00024v3",
    "published_date": "2024-10-28 22:30:06 UTC",
    "updated_date": "2024-11-30 00:17:01 UTC"
  },
  {
    "arxiv_id": "2410.21574v1",
    "title": "A Generative Model Based Honeypot for Industrial OPC UA Communication",
    "authors": [
      "Olaf Sassnick",
      "Georg Schäfer",
      "Thomas Rosenstatter",
      "Stefan Huber"
    ],
    "abstract": "Industrial Operational Technology (OT) systems are increasingly targeted by\ncyber-attacks due to their integration with Information Technology (IT) systems\nin the Industry 4.0 era. Besides intrusion detection systems, honeypots can\neffectively detect these attacks. However, creating realistic honeypots for\nbrownfield systems is particularly challenging. This paper introduces a\ngenerative model-based honeypot designed to mimic industrial OPC UA\ncommunication. Utilizing a Long ShortTerm Memory (LSTM) network, the honeypot\nlearns the characteristics of a highly dynamic mechatronic system from recorded\nstate space trajectories. Our contributions are twofold: first, we present a\nproof-of concept for a honeypot based on generative machine-learning models,\nand second, we publish a dataset for a cyclic industrial process. The results\ndemonstrate that a generative model-based honeypot can feasibly replicate a\ncyclic industrial process via OPC UA communication. In the short-term, the\ngenerative model indicates a stable and plausible trajectory generation, while\ndeviations occur over extended periods. The proposed honeypot implementation\noperates efficiently on constrained hardware, requiring low computational\nresources. Future work will focus on improving model accuracy, interaction\ncapabilities, and extending the dataset for broader applications.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  accepted and will be published in Computer Aided Systems Theory - EUROCAST\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21574v1",
    "published_date": "2024-10-28 22:12:06 UTC",
    "updated_date": "2024-10-28 22:12:06 UTC"
  },
  {
    "arxiv_id": "2410.21573v2",
    "title": "Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense",
    "authors": [
      "Samuel Cahyawijaya",
      "Ruochen Zhang",
      "Holy Lovenia",
      "Jan Christian Blaise Cruz",
      "Elisa Gilbert",
      "Hiroki Nomoto",
      "Alham Fikri Aji"
    ],
    "abstract": "Multilingual large language models (LLMs) have gained prominence, but\nconcerns arise regarding their reliability beyond English. This study addresses\nthe gap in cross-lingual semantic evaluation by introducing a novel benchmark\nfor cross-lingual sense disambiguation, StingrayBench. In this paper, we\ndemonstrate using false friends -- words that are orthographically similar but\nhave completely different meanings in two languages -- as a possible approach\nto pinpoint the limitation of cross-lingual sense disambiguation in LLMs. We\ncollect false friends in four language pairs, namely Indonesian-Malay,\nIndonesian-Tagalog, Chinese-Japanese, and English-German; and challenge LLMs to\ndistinguish the use of them in context. In our analysis of various models, we\nobserve they tend to be biased toward higher-resource languages. We also\npropose new metrics for quantifying the cross-lingual sense bias and\ncomprehension based on our benchmark. Our work contributes to developing more\ndiverse and inclusive language modeling, promoting fairer access for the wider\nmultilingual community.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21573v2",
    "published_date": "2024-10-28 22:09:43 UTC",
    "updated_date": "2024-10-30 11:56:17 UTC"
  },
  {
    "arxiv_id": "2410.21564v3",
    "title": "Mitigating Gradient Overlap in Deep Residual Networks with Gradient Normalization for Improved Non-Convex Optimization",
    "authors": [
      "Juyoung Yun"
    ],
    "abstract": "In deep learning, Residual Networks (ResNets) have proven effective in\naddressing the vanishing gradient problem, allowing for the successful training\nof very deep networks. However, skip connections in ResNets can lead to\ngradient overlap, where gradients from both the learned transformation and the\nskip connection combine, potentially resulting in overestimated gradients. This\noverestimation can cause inefficiencies in optimization, as some updates may\novershoot optimal regions, affecting weight updates. To address this, we\nexamine Z-score Normalization (ZNorm) as a technique to manage gradient\noverlap. ZNorm adjusts the gradient scale, standardizing gradients across\nlayers and reducing the negative impact of overlapping gradients. Our\nexperiments demonstrate that ZNorm improves training process, especially in\nnon-convex optimization scenarios common in deep learning, where finding\noptimal solutions is challenging. These findings suggest that ZNorm can affect\nthe gradient flow, enhancing performance in large-scale data processing where\naccuracy is critical.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21564v3",
    "published_date": "2024-10-28 21:54:44 UTC",
    "updated_date": "2024-11-15 00:32:50 UTC"
  },
  {
    "arxiv_id": "2410.21560v1",
    "title": "Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?",
    "authors": [
      "Amaya Gallagher-Syed",
      "Elena Pontarini",
      "Myles J. Lewis",
      "Michael R. Barnes",
      "Gregory Slabaugh"
    ],
    "abstract": "This study evaluates the generalisation capabilities of state-of-the-art\nhistopathology foundation models on out-of-distribution multi-stain autoimmune\nImmunohistochemistry datasets. We compare 13 feature extractor models,\nincluding ImageNet-pretrained networks, and histopathology foundation models\ntrained on both public and proprietary data, on Rheumatoid Arthritis subtyping\nand Sjogren's Disease detection tasks. Using a simple Attention-Based Multiple\nInstance Learning classifier, we assess the transferability of learned\nrepresentations from cancer H&E images to autoimmune IHC images. Contrary to\nexpectations, histopathology-pretrained models did not significantly outperform\nImageNet-pretrained models. Furthermore, there was evidence of both autoimmune\nfeature misinterpretation and biased feature importance. Our findings highlight\nthe challenges in transferring knowledge from cancer to autoimmune\nhistopathology and emphasise the need for careful evaluation of AI models\nacross diverse histopathological tasks. The code to run this benchmark is\navailable at https://github.com/AmayaGS/ImmunoHistoBench.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "q-bio.QM",
      "q-bio.TO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at Workshop on Advancements In Medical Foundation Models\n  (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.21560v1",
    "published_date": "2024-10-28 21:48:39 UTC",
    "updated_date": "2024-10-28 21:48:39 UTC"
  },
  {
    "arxiv_id": "2410.22368v1",
    "title": "Project MPG: towards a generalized performance benchmark for LLM capabilities",
    "authors": [
      "Lucas Spangher",
      "Tianle Li",
      "William F. Arnold",
      "Nick Masiewicki",
      "Xerxes Dotiwalla",
      "Rama Parusmathi",
      "Peter Grabowski",
      "Eugene Ie",
      "Dan Gruhl"
    ],
    "abstract": "There exists an extremely wide array of LLM benchmarking tasks, whereas\noftentimes a single number is the most actionable for decision-making,\nespecially by non-experts. No such aggregation schema exists that is not\nElo-based, which could be costly or time-consuming. Here we propose a method to\naggregate performance across a general space of benchmarks, nicknamed Project\n\"MPG,\" dubbed Model Performance and Goodness, additionally referencing a metric\nwidely understood to be an important yet inaccurate and crude measure of car\nperformance. Here, we create two numbers: a \"Goodness\" number (answer accuracy)\nand a \"Fastness\" number (cost or QPS). We compare models against each other and\npresent a ranking according to our general metric as well as subdomains. We\nfind significant agreement between the raw Pearson correlation of our scores\nand those of Chatbot Arena, even improving on the correlation of the MMLU\nleaderboard to Chatbot Arena.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22368v1",
    "published_date": "2024-10-28 21:25:37 UTC",
    "updated_date": "2024-10-28 21:25:37 UTC"
  },
  {
    "arxiv_id": "2411.08894v2",
    "title": "Temporal Patterns of Multiple Long-Term Conditions in Individuals with Intellectual Disability Living in Wales: An Unsupervised Clustering Approach to Disease Trajectories",
    "authors": [
      "Rania Kousovista",
      "Georgina Cosma",
      "Emeka Abakasanga",
      "Ashley Akbari",
      "Francesco Zaccardi",
      "Gyuchan Thomas Jun",
      "Reza Kiani",
      "Satheesh Gangadharan"
    ],
    "abstract": "Identifying and understanding the co-occurrence of multiple long-term\nconditions (MLTC) in individuals with intellectual disabilities (ID) is vital\nfor effective healthcare management. These individuals often face earlier onset\nand higher prevalence of MLTCs, yet specific co-occurrence patterns remain\nunexplored. This study applies an unsupervised approach to characterise MLTC\nclusters based on shared disease trajectories using electronic health records\n(EHRs) from 13069 individuals with ID in Wales (2000-2021). Disease\nassociations and temporal directionality were assessed, followed by spectral\nclustering to group shared trajectories. The population consisted of 52.3%\nmales and 47.7% females, with an average of 4.5 conditions per patient. Males\nunder 45 formed a single cluster dominated by neurological conditions (32.4%),\nwhile males above 45 had three clusters, the largest characterised circulatory\n(51.8%). Females under 45 formed one cluster with digestive conditions (24.6%)\nas most prevalent, while those aged 45 and older showed two clusters: one\ndominated by circulatory (34.1%), and the other by digestive (25.9%) and\nmusculoskeletal (21.9%) system conditions. Mental illness, epilepsy, and reflux\nwere common across groups. These clusters offer insights into disease\nprogression in individuals with ID, informing targeted interventions and\npersonalised healthcare strategies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08894v2",
    "published_date": "2024-10-28 21:15:49 UTC",
    "updated_date": "2024-11-15 18:58:47 UTC"
  },
  {
    "arxiv_id": "2410.21539v1",
    "title": "Bayesian Regression for Predicting Subscription to Bank Term Deposits in Direct Marketing Campaigns",
    "authors": [
      "Muhammad Farhan Tanvir",
      "Md Maruf Hossain",
      "Md Asifuzzaman Jishan"
    ],
    "abstract": "In the highly competitive environment of the banking industry, it is\nessential to precisely forecast the behavior of customers in order to maximize\nthe effectiveness of marketing initiatives and improve financial consequences.\nThe purpose of this research is to examine the efficacy of logit and probit\nmodels in predicting term deposit subscriptions using a Portuguese bank's\ndirect marketing data. There are several demographic, economic, and behavioral\ncharacteristics in the dataset that affect the probability of subscribing. To\nincrease model performance and provide an unbiased evaluation, the target\nvariable was balanced, considering the inherent imbalance in the dataset. The\ntwo model's prediction abilities were evaluated using Bayesian techniques and\nLeave-One-Out Cross-Validation (LOO-CV). The logit model performed better than\nthe probit model in handling this classification problem. The results highlight\nthe relevance of model selection when dealing with complicated decision-making\nprocesses in the financial services industry and imbalanced datasets. Findings\nfrom this study shed light on how banks can optimize their decision-making\nprocesses, improve their client segmentation, and boost their marketing\ncampaigns by utilizing machine learning models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21539v1",
    "published_date": "2024-10-28 21:04:58 UTC",
    "updated_date": "2024-10-28 21:04:58 UTC"
  },
  {
    "arxiv_id": "2410.21533v3",
    "title": "L3Ms -- Lagrange Large Language Models",
    "authors": [
      "Guneet S. Dhillon",
      "Xingjian Shi",
      "Yee Whye Teh",
      "Alex Smola"
    ],
    "abstract": "Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Learning Representations (ICLR), 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.21533v3",
    "published_date": "2024-10-28 21:02:13 UTC",
    "updated_date": "2025-03-16 10:12:08 UTC"
  },
  {
    "arxiv_id": "2410.23310v1",
    "title": "Moral Agency in Silico: Exploring Free Will in Large Language Models",
    "authors": [
      "Morgan S. Porter"
    ],
    "abstract": "This study investigates the potential of deterministic systems, specifically\nlarge language models (LLMs), to exhibit the functional capacities of moral\nagency and compatibilist free will. We develop a functional definition of free\nwill grounded in Dennett's compatibilist framework, building on an\ninterdisciplinary theoretical foundation that integrates Shannon's information\ntheory, Dennett's compatibilism, and Floridi's philosophy of information. This\nframework emphasizes the importance of reason-responsiveness and value\nalignment in determining moral responsibility rather than requiring\nmetaphysical libertarian free will. Shannon's theory highlights the role of\nprocessing complex information in enabling adaptive decision-making, while\nFloridi's philosophy reconciles these perspectives by conceptualizing agency as\na spectrum, allowing for a graduated view of moral status based on a system's\ncomplexity and responsiveness. Our analysis of LLMs' decision-making in moral\ndilemmas demonstrates their capacity for rational deliberation and their\nability to adjust choices in response to new information and identified\ninconsistencies. Thus, they exhibit features of a moral agency that align with\nour functional definition of free will. These results challenge traditional\nviews on the necessity of consciousness for moral responsibility, suggesting\nthat systems with self-referential reasoning capacities can instantiate degrees\nof free will and moral reasoning in artificial and biological contexts. This\nstudy proposes a parsimonious framework for understanding free will as a\nspectrum that spans artificial and biological systems, laying the groundwork\nfor further interdisciplinary research on agency and ethics in the artificial\nintelligence era.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23310v1",
    "published_date": "2024-10-28 20:48:14 UTC",
    "updated_date": "2024-10-28 20:48:14 UTC"
  },
  {
    "arxiv_id": "2410.21521v2",
    "title": "A Multi-Agent Reinforcement Learning Testbed for Cognitive Radio Applications",
    "authors": [
      "Sriniketh Vangaru",
      "Daniel Rosen",
      "Dylan Green",
      "Raphael Rodriguez",
      "Maxwell Wiecek",
      "Amos Johnson",
      "Alyse M. Jones",
      "William C. Headley"
    ],
    "abstract": "Technological trends show that Radio Frequency Reinforcement Learning (RFRL)\nwill play a prominent role in the wireless communication systems of the future.\nApplications of RFRL range from military communications jamming to enhancing\nWiFi networks. Before deploying algorithms for these purposes, they must be\ntrained in a simulation environment to ensure adequate performance. For this\nreason, we previously created the RFRL Gym: a standardized, accessible tool for\nthe development and testing of reinforcement learning (RL) algorithms in the\nwireless communications space. This environment leveraged the OpenAI Gym\nframework and featured customizable simulation scenarios within the RF\nspectrum. However, the RFRL Gym was limited to training a single RL agent per\nsimulation; this is not ideal, as most real-world RF scenarios will contain\nmultiple intelligent agents in cooperative, competitive, or mixed settings,\nwhich is a natural consequence of spectrum congestion. Therefore, through\nintegration with Ray RLlib, multi-agent reinforcement learning (MARL)\nfunctionality for training and assessment has been added to the RFRL Gym,\nmaking it even more of a robust tool for RF spectrum simulation. This paper\nprovides an overview of the updated RFRL Gym environment. In this work, the\ngeneral framework of the tool is described relative to comparable existing\nresources, highlighting the significant additions and refactoring we have\napplied to the Gym. Afterward, results from testing various RF scenarios in the\nMARL environment and future additions are discussed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE CCNC 2025. Added revisions from paper reviews",
    "pdf_url": "http://arxiv.org/pdf/2410.21521v2",
    "published_date": "2024-10-28 20:45:52 UTC",
    "updated_date": "2024-12-02 19:49:59 UTC"
  },
  {
    "arxiv_id": "2410.22367v3",
    "title": "MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language",
    "authors": [
      "Yoel Shoshan",
      "Moshiko Raboh",
      "Michal Ozery-Flato",
      "Vadim Ratner",
      "Alex Golts",
      "Jeffrey K. Weber",
      "Ella Barkan",
      "Simona Rabinovici-Cohen",
      "Sagi Polaczek",
      "Ido Amos",
      "Ben Shapira",
      "Liam Hazan",
      "Matan Ninio",
      "Sivan Ravid",
      "Michael M. Danziger",
      "Yosi Shamay",
      "Sharon Kurant",
      "Joseph A. Morrone",
      "Parthasarathy Suryanarayanan",
      "Michal Rosen-Zvi",
      "Efrat Hexter"
    ],
    "abstract": "Large language models applied to vast biological datasets have the potential\nto transform biology by uncovering disease mechanisms and accelerating drug\ndevelopment. However, current models are often siloed, trained separately on\nsmall-molecules, proteins, or transcriptomic data, limiting their ability to\ncapture complex, multi-modal interactions. Effective drug discovery requires\ncomputational tools that integrate multiple biological entities while\nsupporting prediction and generation, a challenge existing models struggle to\naddress. For this purpose, we present MAMMAL - Molecular Aligned Multi-Modal\nArchitecture and Language - a versatile method applied to create a multi-task\nfoundation model that learns from large-scale biological datasets across\ndiverse modalities, including proteins, small-molecules, and omics. MAMMAL's\nstructured prompt syntax supports classification, regression, and generation\ntasks while handling token and scalar inputs and outputs. Evaluated on eleven\ndiverse downstream tasks, it reaches a new state of the art (SOTA) in nine\ntasks and is comparable to SOTA in two tasks, all within a unified\narchitecture, unlike prior task-specific models. Additionally, we explored\nAlphafold 3 binding prediction capabilities on antibody-antigen and\nnanobody-antigen complexes showing significantly better classification\nperformance of MAMMAL in 3 out of 4 targets. The model code and pretrained\nweights are publicly available at\nhttps://github.com/BiomedSciAI/biomed-multi-alignment and\nhttps://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22367v3",
    "published_date": "2024-10-28 20:45:52 UTC",
    "updated_date": "2025-05-06 07:46:11 UTC"
  },
  {
    "arxiv_id": "2410.21514v1",
    "title": "Sabotage Evaluations for Frontier Models",
    "authors": [
      "Joe Benton",
      "Misha Wagner",
      "Eric Christiansen",
      "Cem Anil",
      "Ethan Perez",
      "Jai Srivastav",
      "Esin Durmus",
      "Deep Ganguli",
      "Shauna Kravec",
      "Buck Shlegeris",
      "Jared Kaplan",
      "Holden Karnofsky",
      "Evan Hubinger",
      "Roger Grosse",
      "Samuel R. Bowman",
      "David Duvenaud"
    ],
    "abstract": "Sufficiently capable models could subvert human oversight and decision-making\nin important contexts. For example, in the context of AI development, models\ncould covertly sabotage efforts to evaluate their own dangerous capabilities,\nto monitor their behavior, or to make decisions about their deployment. We\nrefer to this family of abilities as sabotage capabilities. We develop a set of\nrelated threat models and evaluations. These evaluations are designed to\nprovide evidence that a given model, operating under a given set of\nmitigations, could not successfully sabotage a frontier model developer or\nother large organization's activities in any of these ways. We demonstrate\nthese evaluations on Anthropic's Claude 3 Opus and Claude 3.5 Sonnet models.\nOur results suggest that for these models, minimal mitigations are currently\nsufficient to address sabotage risks, but that more realistic evaluations and\nstronger mitigations seem likely to be necessary soon as capabilities improve.\nWe also survey related evaluations we tried and abandoned. Finally, we discuss\nthe advantages of mitigation-aware capability evaluations, and of simulating\nlarge-scale deployments using small-scale statistics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21514v1",
    "published_date": "2024-10-28 20:34:51 UTC",
    "updated_date": "2024-10-28 20:34:51 UTC"
  },
  {
    "arxiv_id": "2410.21508v1",
    "title": "Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups",
    "authors": [
      "Davide Ghilardi",
      "Federico Belotti",
      "Marco Molinari"
    ],
    "abstract": "Sparse AutoEnocders (SAEs) have recently been employed as an unsupervised\napproach for understanding the inner workings of Large Language Models (LLMs).\nThey reconstruct the model's activations with a sparse linear combination of\ninterpretable features. However, training SAEs is computationally intensive,\nespecially as models grow in size and complexity. To address this challenge, we\npropose a novel training strategy that reduces the number of trained SAEs from\none per layer to one for a given group of contiguous layers. Our experimental\nresults on Pythia 160M highlight a speedup of up to 6x without compromising the\nreconstruction quality and performance on downstream tasks. Therefore, layer\nclustering presents an efficient approach to train SAEs in modern LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21508v1",
    "published_date": "2024-10-28 20:23:30 UTC",
    "updated_date": "2024-10-28 20:23:30 UTC"
  },
  {
    "arxiv_id": "2410.21494v1",
    "title": "Towards Multi-dimensional Explanation Alignment for Medical Classification",
    "authors": [
      "Lijie Hu",
      "Songning Lai",
      "Wenshuo Chen",
      "Hongru Xiao",
      "Hongbin Lin",
      "Lu Yu",
      "Jingfeng Zhang",
      "Di Wang"
    ],
    "abstract": "The lack of interpretability in the field of medical image analysis has\nsignificant ethical and legal implications. Existing interpretable methods in\nthis domain encounter several challenges, including dependency on specific\nmodels, difficulties in understanding and visualization, as well as issues\nrelated to efficiency. To address these limitations, we propose a novel\nframework called Med-MICN (Medical Multi-dimensional Interpretable Concept\nNetwork). Med-MICN provides interpretability alignment for various angles,\nincluding neural symbolic reasoning, concept semantics, and saliency maps,\nwhich are superior to current interpretable methods. Its advantages include\nhigh prediction accuracy, interpretability across multiple dimensions, and\nautomation through an end-to-end concept labeling process that reduces the need\nfor extensive human training effort when working with new datasets. To\ndemonstrate the effectiveness and interpretability of Med-MICN, we apply it to\nfour benchmark datasets and compare it with baselines. The results clearly\ndemonstrate the superior performance and interpretability of our Med-MICN.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21494v1",
    "published_date": "2024-10-28 20:03:19 UTC",
    "updated_date": "2024-10-28 20:03:19 UTC"
  },
  {
    "arxiv_id": "2410.21491v3",
    "title": "Trustworthiness of Stochastic Gradient Descent in Distributed Learning",
    "authors": [
      "Hongyang Li",
      "Caesar Wu",
      "Mohammed Chadli",
      "Said Mammar",
      "Pascal Bouvry"
    ],
    "abstract": "Distributed learning (DL) uses multiple nodes to accelerate training,\nenabling efficient optimization of large-scale models. Stochastic Gradient\nDescent (SGD), a key optimization algorithm, plays a central role in this\nprocess. However, communication bottlenecks often limit scalability and\nefficiency, leading to increasing adoption of compressed SGD techniques to\nalleviate these challenges. Despite addressing communication overheads,\ncompressed SGD introduces trustworthiness concerns, as gradient exchanges among\nnodes are vulnerable to attacks like gradient inversion (GradInv) and\nmembership inference attacks (MIA). The trustworthiness of compressed SGD\nremains unexplored, leaving important questions about its reliability\nunanswered.\n  In this paper, we provide a trustworthiness evaluation of compressed versus\nuncompressed SGD. Specifically, we conducted empirical studies using GradInv\nattacks, revealing that compressed SGD demonstrates significantly higher\nresistance to privacy leakage compared to uncompressed SGD. In addition, our\nfindings suggest that MIA may not be a reliable metric for assessing privacy\nrisks in distributed learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21491v3",
    "published_date": "2024-10-28 20:02:05 UTC",
    "updated_date": "2025-04-29 12:30:32 UTC"
  },
  {
    "arxiv_id": "2410.21490v1",
    "title": "Can Large Language Models Act as Symbolic Reasoners?",
    "authors": [
      "Rob Sullivan",
      "Nelly Elsayed"
    ],
    "abstract": "The performance of Large language models (LLMs) across a broad range of\ndomains has been impressive but have been critiqued as not being able to reason\nabout their process and conclusions derived. This is to explain the conclusions\ndraw, and also for determining a plan or strategy for their approach. This\npaper explores the current research in investigating symbolic reasoning and\nLLMs, and whether an LLM can inherently provide some form of reasoning or\nwhether supporting components are necessary, and, if there is evidence for a\nreasoning capability, is this evident in a specific domain or is this a general\ncapability? In addition, this paper aims to identify the current research gaps\nand future trends of LLM explainability, presenting a review of the literature,\nidentifying current research into this topic and suggests areas for future\nwork.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, currently under review",
    "pdf_url": "http://arxiv.org/pdf/2410.21490v1",
    "published_date": "2024-10-28 20:01:50 UTC",
    "updated_date": "2024-10-28 20:01:50 UTC"
  },
  {
    "arxiv_id": "2410.21487v1",
    "title": "Enhancing CTR Prediction in Recommendation Domain with Search Query Representation",
    "authors": [
      "Yuening Wang",
      "Man Chen",
      "Yaochen Hu",
      "Wei Guo",
      "Yingxue Zhang",
      "Huifeng Guo",
      "Yong Liu",
      "Mark Coates"
    ],
    "abstract": "Many platforms, such as e-commerce websites, offer both search and\nrecommendation services simultaneously to better meet users' diverse needs.\nRecommendation services suggest items based on user preferences, while search\nservices allow users to search for items before providing recommendations.\nSince users and items are often shared between the search and recommendation\ndomains, there is a valuable opportunity to enhance the recommendation domain\nby leveraging user preferences extracted from the search domain. Existing\napproaches either overlook the shift in user intention between these domains or\nfail to capture the significant impact of learning from users' search queries\non understanding their interests.\n  In this paper, we propose a framework that learns from user search query\nembeddings within the context of user preferences in the recommendation domain.\nSpecifically, user search query sequences from the search domain are used to\npredict the items users will click at the next time point in the recommendation\ndomain. Additionally, the relationship between queries and items is explored\nthrough contrastive learning. To address issues of data sparsity, the diffusion\nmodel is incorporated to infer positive items the user will select after\nsearching with certain queries in a denoising manner, which is particularly\neffective in preventing false positives. Effectively extracting this\ninformation, the queries are integrated into click-through rate prediction in\nthe recommendation domain. Experimental analysis demonstrates that our model\noutperforms state-of-the-art models in the recommendation domain.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by CIKM 2024 Full Research Track",
    "pdf_url": "http://arxiv.org/pdf/2410.21487v1",
    "published_date": "2024-10-28 19:52:09 UTC",
    "updated_date": "2024-10-28 19:52:09 UTC"
  },
  {
    "arxiv_id": "2411.00023v2",
    "title": "Device-Directed Speech Detection for Follow-up Conversations Using Large Language Models",
    "authors": [
      "Ognjen",
      "Rudovic",
      "Pranay Dighe",
      "Yi Su",
      "Vineet Garg",
      "Sameer Dharur",
      "Xiaochuan Niu",
      "Ahmed H. Abdelaziz",
      "Saurabh Adya",
      "Ahmed Tewfik"
    ],
    "abstract": "Follow-up conversations with virtual assistants (VAs) enable a user to\nseamlessly interact with a VA without the need to repeatedly invoke it using a\nkeyword (after the first query). Therefore, accurate Device-directed Speech\nDetection (DDSD) from the follow-up queries is critical for enabling\nnaturalistic user experience. To this end, we explore the notion of Large\nLanguage Models (LLMs) and model the first query when making inference about\nthe follow-ups (based on the ASR-decoded text), via prompting of a pretrained\nLLM, or by adapting a binary classifier on top of the LLM. In doing so, we also\nexploit the ASR uncertainty when designing the LLM prompts. We show on the\nreal-world dataset of follow-up conversations that this approach yields large\ngains (20-40% reduction in false alarms at 10% fixed false rejects) due to the\njoint modeling of the previous speech context and ASR uncertainty, compared to\nwhen follow-ups are modeled alone.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00023v2",
    "published_date": "2024-10-28 19:43:43 UTC",
    "updated_date": "2024-11-04 19:57:55 UTC"
  },
  {
    "arxiv_id": "2410.21480v1",
    "title": "AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification",
    "authors": [
      "Brendan Hogan",
      "Anmol Kabra",
      "Felipe Siqueira Pacheco",
      "Laura Greenstreet",
      "Joshua Fan",
      "Aaron Ferber",
      "Marta Ummus",
      "Alecsander Brito",
      "Olivia Graham",
      "Lillian Aoki",
      "Drew Harvell",
      "Alex Flecker",
      "Carla Gomes"
    ],
    "abstract": "Trust and interpretability are crucial for the use of Artificial Intelligence\n(AI) in scientific research, but current models often operate as black boxes\noffering limited transparency and justifications for their outputs. We\nintroduce AiSciVision, a framework that specializes Large Multimodal Models\n(LMMs) into interactive research partners and classification models for image\nclassification tasks in niche scientific domains. Our framework uses two key\ncomponents: (1) Visual Retrieval-Augmented Generation (VisRAG) and (2)\ndomain-specific tools utilized in an agentic workflow. To classify a target\nimage, AiSciVision first retrieves the most similar positive and negative\nlabeled images as context for the LMM. Then the LMM agent actively selects and\napplies tools to manipulate and inspect the target image over multiple rounds,\nrefining its analysis before making a final prediction. These VisRAG and\ntooling components are designed to mirror the processes of domain experts, as\nhumans often compare new data to similar examples and use specialized tools to\nmanipulate and inspect images before arriving at a conclusion. Each inference\nproduces both a prediction and a natural language transcript detailing the\nreasoning and tool usage that led to the prediction. We evaluate AiSciVision on\nthree real-world scientific image classification datasets: detecting the\npresence of aquaculture ponds, diseased eelgrass, and solar panels. Across\nthese datasets, our method outperforms fully supervised models in low and\nfull-labeled data settings. AiSciVision is actively deployed in real-world use,\nspecifically for aquaculture research, through a dedicated web application that\ndisplays and allows the expert users to converse with the transcripts. This\nwork represents a crucial step toward AI systems that are both interpretable\nand effective, advancing their use in scientific research and scientific\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21480v1",
    "published_date": "2024-10-28 19:35:47 UTC",
    "updated_date": "2024-10-28 19:35:47 UTC"
  },
  {
    "arxiv_id": "2410.21479v1",
    "title": "TransformLLM: Adapting Large Language Models via LLM-Transformed Reading Comprehension Text",
    "authors": [
      "Iftach Arbel",
      "Yehonathan Refael",
      "Ofir Lindenbaum"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in highly-specialized\ndomains, however challenges are still present in aspects of accuracy and costs.\nThese limitations restrict the usage of existing models in domain-specific\ntasks. While fine-tuning pre-trained models have shown promising results, this\nprocess can be computationally expensive and require massive datasets of the\nspecialized application in hand. In this work, we bridge that gap. We have\ndeveloped Phi-2-Legal and Mistral-Legal-7B, which are language models\nspecifically designed for legal applications. These models are based on Phi-2\nand Mistral-7B-v0.1, and have gone through continued pre-training with over 500\nmillion tokens of legal texts. Our innovative approach significantly improves\ncapabilities in legal tasks by using Large Language Models (LLMs) to convert\nraw training data into reading comprehension text. Our legal LLMs have\ndemonstrated superior performance in legal benchmarks, even outperforming\nmodels trained on much larger datasets with more resources. This work\nemphasizes the effectiveness of continued pre-training on domain-specific\ntexts, while using affordable LLMs for data conversion, which gives these\nmodels domain expertise while retaining general language understanding\ncapabilities. While this work uses the legal domain as a test case, our method\ncan be scaled and applied to any pre-training dataset, resulting in significant\nimprovements across different tasks. These findings underscore the potential of\ndomain-adaptive pre-training and reading comprehension for the development of\nhighly effective domain-specific language models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21479v1",
    "published_date": "2024-10-28 19:32:18 UTC",
    "updated_date": "2024-10-28 19:32:18 UTC"
  },
  {
    "arxiv_id": "2410.21478v1",
    "title": "Knowledge Distillation for Real-Time Classification of Early Media in Voice Communications",
    "authors": [
      "Kemal Altwlkany",
      "Hadžem Hadžić",
      "Amar Kurić",
      "Emanuel Lacic"
    ],
    "abstract": "This paper investigates the industrial setting of real-time classification of\nearly media exchanged during the initialization phase of voice calls. We\nexplore the application of state-of-the-art audio tagging models and highlight\nsome limitations when applied to the classification of early media. While most\nexisting approaches leverage convolutional neural networks, we propose a novel\napproach for low-resource requirements based on gradient-boosted trees. Our\napproach not only demonstrates a substantial improvement in runtime\nperformance, but also exhibits a comparable accuracy. We show that leveraging\nknowledge distillation and class aggregation techniques to train a simpler and\nsmaller model accelerates the classification of early media in voice calls. We\nprovide a detailed analysis of the results on a proprietary and publicly\navailable dataset, regarding accuracy and runtime performance. We additionally\nreport a case study of the achieved performance improvements at a regional data\ncenter in India.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MM",
      "eess.AS",
      "I.2.0"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21478v1",
    "published_date": "2024-10-28 19:32:17 UTC",
    "updated_date": "2024-10-28 19:32:17 UTC"
  },
  {
    "arxiv_id": "2410.21474v2",
    "title": "Estimating Causal Effects of Text Interventions Leveraging LLMs",
    "authors": [
      "Siyi Guo",
      "Myrl G. Marmarelis",
      "Fred Morstatter",
      "Kristina Lerman"
    ],
    "abstract": "Quantifying the effects of textual interventions in social systems, such as\nreducing anger in social media posts to see its impact on engagement, is\nchallenging. Real-world interventions are often infeasible, necessitating\nreliance on observational data. Traditional causal inference methods, typically\ndesigned for binary or discrete treatments, are inadequate for handling the\ncomplex, high-dimensional textual data. This paper addresses these challenges\nby proposing CausalDANN, a novel approach to estimate causal effects using text\ntransformations facilitated by large language models (LLMs). Unlike existing\nmethods, our approach accommodates arbitrary textual interventions and\nleverages text-level classifiers with domain adaptation ability to produce\nrobust effect estimates against domain shifts, even when only the control group\nis observed. This flexibility in handling various text interventions is a key\nadvancement in causal estimation for textual data, offering opportunities to\nbetter understand human behaviors and develop effective interventions within\nsocial systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21474v2",
    "published_date": "2024-10-28 19:19:35 UTC",
    "updated_date": "2025-03-20 23:59:00 UTC"
  },
  {
    "arxiv_id": "2410.21471v2",
    "title": "AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models",
    "authors": [
      "Yaopei Zeng",
      "Yuanpu Cao",
      "Bochuan Cao",
      "Yurui Chang",
      "Jinghui Chen",
      "Lu Lin"
    ],
    "abstract": "Recent advances in diffusion models have significantly enhanced the quality\nof image synthesis, yet they have also introduced serious safety concerns,\nparticularly the generation of Not Safe for Work (NSFW) content. Previous\nresearch has demonstrated that adversarial prompts can be used to generate NSFW\ncontent. However, such adversarial text prompts are often easily detectable by\ntext-based filters, limiting their efficacy. In this paper, we expose a\npreviously overlooked vulnerability: adversarial image attacks targeting\nImage-to-Image (I2I) diffusion models. We propose AdvI2I, a novel framework\nthat manipulates input images to induce diffusion models to generate NSFW\ncontent. By optimizing a generator to craft adversarial images, AdvI2I\ncircumvents existing defense mechanisms, such as Safe Latent Diffusion (SLD),\nwithout altering the text prompts. Furthermore, we introduce AdvI2I-Adaptive,\nan enhanced version that adapts to potential countermeasures and minimizes the\nresemblance between adversarial images and NSFW concept embeddings, making the\nattack more resilient against defenses. Through extensive experiments, we\ndemonstrate that both AdvI2I and AdvI2I-Adaptive can effectively bypass current\nsafeguards, highlighting the urgent need for stronger security measures to\naddress the misuse of I2I diffusion models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21471v2",
    "published_date": "2024-10-28 19:15:06 UTC",
    "updated_date": "2024-11-01 17:36:02 UTC"
  },
  {
    "arxiv_id": "2410.22366v2",
    "title": "Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders",
    "authors": [
      "Viacheslav Surkov",
      "Chris Wendler",
      "Mikhail Terekhov",
      "Justin Deschenaux",
      "Robert West",
      "Caglar Gulcehre"
    ],
    "abstract": "Sparse autoencoders (SAEs) have become a core ingredient in the reverse\nengineering of large-language models (LLMs). For LLMs, they have been shown to\ndecompose intermediate representations that often are not interpretable\ndirectly into sparse sums of interpretable features, facilitating better\ncontrol and subsequent analysis. However, similar analyses and approaches have\nbeen lacking for text-to-image models. We investigated the possibility of using\nSAEs to learn interpretable features for a few-step text-to-image diffusion\nmodels, such as SDXL Turbo. To this end, we train SAEs on the updates performed\nby transformer blocks within SDXL Turbo's denoising U-net. We find that their\nlearned features are interpretable, causally influence the generation process,\nand reveal specialization among the blocks. In particular, we find one block\nthat deals mainly with image composition, one that is mainly responsible for\nadding local details, and one for color, illumination, and style. Therefore,\nour work is an important first step towards better understanding the internals\nof generative text-to-image models like SDXL Turbo and showcases the potential\nof features learned by SAEs for the visual domain.\n  Code is available at https://github.com/surkovv/sdxl-unbox",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22366v2",
    "published_date": "2024-10-28 19:01:18 UTC",
    "updated_date": "2024-12-11 20:01:40 UTC"
  },
  {
    "arxiv_id": "2410.23308v1",
    "title": "Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures",
    "authors": [
      "Victoria Benjamin",
      "Emily Braca",
      "Israel Carter",
      "Hafsa Kanchwala",
      "Nava Khojasteh",
      "Charly Landow",
      "Yi Luo",
      "Caroline Ma",
      "Anna Magarelli",
      "Rachel Mirin",
      "Avery Moyer",
      "Kayla Simpson",
      "Amelia Skawinski",
      "Thomas Heverin"
    ],
    "abstract": "This study systematically analyzes the vulnerability of 36 large language\nmodels (LLMs) to various prompt injection attacks, a technique that leverages\ncarefully crafted prompts to elicit malicious LLM behavior. Across 144 prompt\ninjection tests, we observed a strong correlation between model parameters and\nvulnerability, with statistical analyses, such as logistic regression and\nrandom forest feature analysis, indicating that parameter size and architecture\nsignificantly influence susceptibility. Results revealed that 56 percent of\ntests led to successful prompt injections, emphasizing widespread vulnerability\nacross various parameter sizes, with clustering analysis identifying distinct\nvulnerability profiles associated with specific model configurations.\nAdditionally, our analysis uncovered correlations between certain prompt\ninjection techniques, suggesting potential overlaps in vulnerabilities. These\nfindings underscore the urgent need for robust, multi-layered defenses in LLMs\ndeployed across critical infrastructure and sensitive industries. Successful\nprompt injection attacks could result in severe consequences, including data\nbreaches, unauthorized access, or misinformation. Future research should\nexplore multilingual and multi-step defenses alongside adaptive mitigation\nstrategies to strengthen LLM security in diverse, real-world environments.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23308v1",
    "published_date": "2024-10-28 18:55:21 UTC",
    "updated_date": "2024-10-28 18:55:21 UTC"
  },
  {
    "arxiv_id": "2410.21443v2",
    "title": "TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors",
    "authors": [
      "Adonisz Dimitriu",
      "Tamás Michaletzky",
      "Viktor Remeli"
    ],
    "abstract": "Adversarial attacks threaten the reliability of machine learning models in\ncritical applications like autonomous vehicles and defense systems. As object\ndetectors become more robust with models like YOLOv8, developing effective\nadversarial methodologies is increasingly challenging. We present Truck\nAdversarial Camouflage Optimization (TACO), a novel framework that generates\nadversarial camouflage patterns on 3D vehicle models to deceive\nstate-of-the-art object detectors. Adopting Unreal Engine 5, TACO integrates\ndifferentiable rendering with a Photorealistic Rendering Network to optimize\nadversarial textures targeted at YOLOv8. To ensure the generated textures are\nboth effective in deceiving detectors and visually plausible, we introduce the\nConvolutional Smooth Loss function, a generalized smooth loss function.\nExperimental evaluations demonstrate that TACO significantly degrades YOLOv8's\ndetection performance, achieving an AP@0.5 of 0.0099 on unseen test data.\nFurthermore, these adversarial patterns exhibit strong transferability to other\nobject detection models such as Faster R-CNN and earlier YOLO versions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This version matches the final published version in Big Data and\n  Cognitive Computing (MDPI). Please cite the journal version when referencing\n  this work (doi: https://doi.org/10.3390/bdcc9030072)",
    "pdf_url": "http://arxiv.org/pdf/2410.21443v2",
    "published_date": "2024-10-28 18:40:06 UTC",
    "updated_date": "2025-04-11 12:13:02 UTC"
  },
  {
    "arxiv_id": "2410.21418v1",
    "title": "Large Language Models for Manufacturing",
    "authors": [
      "Yiwei Li",
      "Huaqin Zhao",
      "Hanqi Jiang",
      "Yi Pan",
      "Zhengliang Liu",
      "Zihao Wu",
      "Peng Shu",
      "Jie Tian",
      "Tianze Yang",
      "Shaochen Xu",
      "Yanjun Lyu",
      "Parker Blenk",
      "Jacob Pence",
      "Jason Rupram",
      "Eliza Banu",
      "Ninghao Liu",
      "Linbing Wang",
      "Wenzhan Song",
      "Xiaoming Zhai",
      "Kenan Song",
      "Dajiang Zhu",
      "Beiwen Li",
      "Xianqiao Wang",
      "Tianming Liu"
    ],
    "abstract": "The rapid advances in Large Language Models (LLMs) have the potential to\ntransform manufacturing industry, offering new opportunities to optimize\nprocesses, improve efficiency, and drive innovation. This paper provides a\ncomprehensive exploration of the integration of LLMs into the manufacturing\ndomain, focusing on their potential to automate and enhance various aspects of\nmanufacturing, from product design and development to quality control, supply\nchain optimization, and talent management. Through extensive evaluations across\nmultiple manufacturing tasks, we demonstrate the remarkable capabilities of\nstate-of-the-art LLMs, such as GPT-4V, in understanding and executing complex\ninstructions, extracting valuable insights from vast amounts of data, and\nfacilitating knowledge sharing. We also delve into the transformative potential\nof LLMs in reshaping manufacturing education, automating coding processes,\nenhancing robot control systems, and enabling the creation of immersive,\ndata-rich virtual environments through the industrial metaverse. By\nhighlighting the practical applications and emerging use cases of LLMs in\nmanufacturing, this paper aims to provide a valuable resource for\nprofessionals, researchers, and decision-makers seeking to harness the power of\nthese technologies to address real-world challenges, drive operational\nexcellence, and unlock sustainable growth in an increasingly competitive\nlandscape.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21418v1",
    "published_date": "2024-10-28 18:13:47 UTC",
    "updated_date": "2024-10-28 18:13:47 UTC"
  },
  {
    "arxiv_id": "2410.21415v2",
    "title": "Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding",
    "authors": [
      "He Jiang",
      "Yutong Wang",
      "Rishi Veerapaneni",
      "Tanishq Duhan",
      "Guillaume Sartoretti",
      "Jiaoyang Li"
    ],
    "abstract": "Lifelong Multi-Agent Path Finding (LMAPF) repeatedly finds collision-free\npaths for multiple agents that are continually assigned new goals when they\nreach current ones. Recently, this field has embraced learning-based methods,\nwhich reactively generate single-step actions based on individual local\nobservations. However, it is still challenging for them to match the\nperformance of the best search-based algorithms, especially in large-scale\nsettings. This work proposes an imitation-learning-based LMAPF solver that\nintroduces a novel communication module as well as systematic single-step\ncollision resolution and global guidance techniques. Our proposed solver,\nScalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning\nspeed of learning-based methods and the high solution quality of search-based\nmethods with the help of modern GPUs. Across six large-scale maps with up to\n10,000 agents and varying obstacle structures, SILLM surpasses the best\nlearning- and search-based baselines, achieving average throughput improvements\nof 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning\nsolution of the 2023 League of Robot Runners, an international LMAPF\ncompetition. Finally, we validated SILLM with 10 real robots and 100 virtual\nrobots in a mock warehouse environment.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "Accepted by ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.21415v2",
    "published_date": "2024-10-28 18:13:15 UTC",
    "updated_date": "2025-05-18 01:41:47 UTC"
  },
  {
    "arxiv_id": "2410.21414v1",
    "title": "CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart",
    "authors": [
      "Bowen Zhao",
      "Tianhao Cheng",
      "Yuejie Zhang",
      "Ying Cheng",
      "Rui Feng",
      "Xiaobo Zhang"
    ],
    "abstract": "Multimodal Question Answering (MMQA) is crucial as it enables comprehensive\nunderstanding and accurate responses by integrating insights from diverse data\nrepresentations such as tables, charts, and text. Most existing researches in\nMMQA only focus on two modalities such as image-text QA, table-text QA and\nchart-text QA, and there remains a notable scarcity in studies that investigate\nthe joint analysis of text, tables, and charts. In this paper, we present\nC$\\text{T}^2$C-QA, a pioneering Chinese reasoning-based QA dataset that\nincludes an extensive collection of text, tables, and charts, meticulously\ncompiled from 200 selectively sourced webpages. Our dataset simulates real\nwebpages and serves as a great test for the capability of the model to analyze\nand reason with multimodal data, because the answer to a question could appear\nin various modalities, or even potentially not exist at all. Additionally, we\npresent AED (\\textbf{A}llocating, \\textbf{E}xpert and \\textbf{D}esicion), a\nmulti-agent system implemented through collaborative deployment, information\ninteraction, and collective decision-making among different agents.\nSpecifically, the Assignment Agent is in charge of selecting and activating\nexpert agents, including those proficient in text, tables, and charts. The\nDecision Agent bears the responsibility of delivering the final verdict,\ndrawing upon the analytical insights provided by these expert agents. We\nexecute a comprehensive analysis, comparing AED with various state-of-the-art\nmodels in MMQA, including GPT-4. The experimental outcomes demonstrate that\ncurrent methodologies, including GPT-4, are yet to meet the benchmarks set by\nour dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21414v1",
    "published_date": "2024-10-28 18:13:14 UTC",
    "updated_date": "2024-10-28 18:13:14 UTC"
  },
  {
    "arxiv_id": "2410.21407v1",
    "title": "Exploring reinforcement learning for incident response in autonomous military vehicles",
    "authors": [
      "Henrik Madsen",
      "Gudmund Grov",
      "Federico Mancini",
      "Magnus Baksaas",
      "Åvald Åslaugson Sommervoll"
    ],
    "abstract": "Unmanned vehicles able to conduct advanced operations without human\nintervention are being developed at a fast pace for many purposes. Not\nsurprisingly, they are also expected to significantly change how military\noperations can be conducted. To leverage the potential of this new technology\nin a physically and logically contested environment, security risks are to be\nassessed and managed accordingly. Research on this topic points to autonomous\ncyber defence as one of the capabilities that may be needed to accelerate the\nadoption of these vehicles for military purposes. Here, we pursue this line of\ninvestigation by exploring reinforcement learning to train an agent that can\nautonomously respond to cyber attacks on unmanned vehicles in the context of a\nmilitary operation. We first developed a simple simulation environment to\nquickly prototype and test some proof-of-concept agents for an initial\nevaluation. This agent was then applied to a more realistic simulation\nenvironment and finally deployed on an actual unmanned ground vehicle for even\nmore realism. A key contribution of our work is demonstrating that\nreinforcement learning is a viable approach to train an agent that can be used\nfor autonomous cyber defence on a real unmanned ground vehicle, even when\ntrained in a simple simulation environment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CR",
    "comment": "DIGILIENCE 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21407v1",
    "published_date": "2024-10-28 18:08:23 UTC",
    "updated_date": "2024-10-28 18:08:23 UTC"
  },
  {
    "arxiv_id": "2410.21403v1",
    "title": "Unveiling the Role of Expert Guidance: A Comparative Analysis of User-centered Imitation Learning and Traditional Reinforcement Learning",
    "authors": [
      "Amr Gomaa",
      "Bilal Mahdy"
    ],
    "abstract": "Integration of human feedback plays a key role in improving the learning\ncapabilities of intelligent systems. This comparative study delves into the\nperformance, robustness, and limitations of imitation learning compared to\ntraditional reinforcement learning methods within these systems. Recognizing\nthe value of human-in-the-loop feedback, we investigate the influence of expert\nguidance and suboptimal demonstrations on the learning process. Through\nextensive experimentation and evaluations conducted in a pre-existing\nsimulation environment using the Unity platform, we meticulously analyze the\neffectiveness and limitations of these learning approaches. The insights gained\nfrom this study contribute to the advancement of human-centered artificial\nintelligence by highlighting the benefits and challenges associated with the\nincorporation of human feedback into the learning process. Ultimately, this\nresearch promotes the development of models that can effectively address\ncomplex real-world problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as CEUR Workshop Proceedings in Proceedings of the 1st\n  International Workshop on Human-in-the-Loop Applied Machine Learning (HITLAML\n  2023). Awarded Best Paper. https://ceur-ws.org/Vol-3524/paper1.pdf",
    "pdf_url": "http://arxiv.org/pdf/2410.21403v1",
    "published_date": "2024-10-28 18:07:44 UTC",
    "updated_date": "2024-10-28 18:07:44 UTC"
  },
  {
    "arxiv_id": "2410.21275v1",
    "title": "Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context",
    "authors": [
      "Manuel Benavent-Lledo",
      "David Mulero-Pérez",
      "David Ortiz-Perez",
      "Jose Garcia-Rodriguez",
      "Antonis Argyros"
    ],
    "abstract": "The sequential execution of actions and their hierarchical structure\nconsisting of different levels of abstraction, provide features that remain\nunexplored in the task of action recognition. In this study, we present a novel\napproach to improve action recognition by exploiting the hierarchical\norganization of actions and by incorporating contextualized textual\ninformation, including location and prior actions to reflect the sequential\ncontext. To achieve this goal, we introduce a novel transformer architecture\ntailored for action recognition that utilizes both visual and textual features.\nVisual features are obtained from RGB and optical flow data, while text\nembeddings represent contextual information. Furthermore, we define a joint\nloss function to simultaneously train the model for both coarse and\nfine-grained action recognition, thereby exploiting the hierarchical nature of\nactions. To demonstrate the effectiveness of our method, we extend the Toyota\nSmarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducing\nthe Hierarchical TSU dataset. We also conduct an ablation study to assess the\nimpact of different methods for integrating contextual and hierarchical data on\naction recognition performance. Results show that the proposed approach\noutperforms pre-trained SOTA methods when trained with the same\nhyperparameters. Moreover, they also show a 17.12% improvement in top-1\naccuracy over the equivalent fine-grained RGB version when using ground-truth\ncontextual information, and a 5.33% improvement when contextual information is\nobtained from actual predictions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21275v1",
    "published_date": "2024-10-28 17:59:35 UTC",
    "updated_date": "2024-10-28 17:59:35 UTC"
  },
  {
    "arxiv_id": "2410.21271v3",
    "title": "EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation",
    "authors": [
      "Shih-Yang Liu",
      "Maksim Khadkevich",
      "Nai Chit Fung",
      "Charbel Sakr",
      "Chao-Han Huck Yang",
      "Chien-Yi Wang",
      "Saurav Muralidharan",
      "Hongxu Yin",
      "Kwang-Ting Cheng",
      "Jan Kautz",
      "Yu-Chiang Frank Wang",
      "Pavlo Molchanov",
      "Min-Hung Chen"
    ],
    "abstract": "In this work, we re-formulate the model compression problem into the\ncustomized compensation problem: Given a compressed model, we aim to introduce\nresidual low-rank paths to compensate for compression errors under customized\nrequirements from users (e.g., tasks, compression ratios), resulting in greater\nflexibility in balancing accuracy and overhead(inference and model size)\nwithout being bound to fixed compression formats. However, naively applying SVD\nto derive residual paths causes suboptimal utilization of the low-rank\nrepresentation capacity. Instead, we propose Training-free Eigenspace Low-Rank\nApproximation (EoRA), a method that directly minimizes compression-induced\nerrors without requiring gradient-based training, achieving fast optimization\nin minutes using a small amount of calibration data. EoRA projects compression\nerrors into the eigenspace of input activations, leveraging eigenvalues to\neffectively prioritize the reconstruction of high-importance error components.\nMoreover, EoRA can be seamlessly integrated with fine-tuning and quantization\nto further improve effectiveness and efficiency. EoRA consistently outperforms\nprevious methods in compensating errors for compressed LLaMA2/3 models on\nvarious tasks, such as language generation, commonsense reasoning, and math\nreasoning tasks (e.g., 31.31%/12.88% and 9.69% improvements on\nARC-Easy/ARC-Challenge and MathQA when compensating LLaMA3-8B that is quantized\nto 4-bit and pruned to 2:4 sparsity). EoRA offers a scalable, training-free\nsolution to compensate for compression errors, making it a powerful tool to\ndeploy LLMs more flexibly. Code is available at https://github.com/NVlabs/EoRA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21271v3",
    "published_date": "2024-10-28 17:59:03 UTC",
    "updated_date": "2025-02-24 07:44:53 UTC"
  },
  {
    "arxiv_id": "2410.21264v1",
    "title": "LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior",
    "authors": [
      "Hanyu Wang",
      "Saksham Suri",
      "Yixuan Ren",
      "Hao Chen",
      "Abhinav Shrivastava"
    ],
    "abstract": "We present LARP, a novel video tokenizer designed to overcome limitations in\ncurrent video tokenization methods for autoregressive (AR) generative models.\nUnlike traditional patchwise tokenizers that directly encode local visual\npatches into discrete tokens, LARP introduces a holistic tokenization scheme\nthat gathers information from the visual content using a set of learned\nholistic queries. This design allows LARP to capture more global and semantic\nrepresentations, rather than being limited to local patch-level information.\nFurthermore, it offers flexibility by supporting an arbitrary number of\ndiscrete tokens, enabling adaptive and efficient tokenization based on the\nspecific requirements of the task. To align the discrete token space with\ndownstream AR generation tasks, LARP integrates a lightweight AR transformer as\na training-time prior model that predicts the next token on its discrete latent\nspace. By incorporating the prior model during training, LARP learns a latent\nspace that is not only optimized for video reconstruction but is also\nstructured in a way that is more conducive to autoregressive generation.\nMoreover, this process defines a sequential order for the discrete tokens,\nprogressively pushing them toward an optimal configuration during training,\nensuring smoother and more accurate AR generation at inference time.\nComprehensive experiments demonstrate LARP's strong performance, achieving\nstate-of-the-art FVD on the UCF101 class-conditional video generation\nbenchmark. LARP enhances the compatibility of AR models with videos and opens\nup the potential to build unified high-fidelity multimodal large language\nmodels (MLLMs).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://hywang66.github.io/larp/",
    "pdf_url": "http://arxiv.org/pdf/2410.21264v1",
    "published_date": "2024-10-28 17:57:07 UTC",
    "updated_date": "2024-10-28 17:57:07 UTC"
  },
  {
    "arxiv_id": "2410.21262v2",
    "title": "BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference",
    "authors": [
      "Changwoo Lee",
      "Soo Min Kwon",
      "Qing Qu",
      "Hun-Seok Kim"
    ],
    "abstract": "Large-scale foundation models have demonstrated exceptional performance in\nlanguage and vision tasks. However, the numerous dense matrix-vector operations\ninvolved in these large networks pose significant computational challenges\nduring inference. To address these challenges, we introduce the Block-Level\nAdaptive STructured (BLAST) matrix, designed to learn and leverage efficient\nstructures prevalent in the weight matrices of linear layers within deep\nlearning models. Compared to existing structured matrices, the BLAST matrix\noffers substantial flexibility, as it can represent various types of structures\nthat are either learned from data or computed from pre-existing weight\nmatrices. We demonstrate the efficiency of using the BLAST matrix for\ncompressing both language and vision tasks, showing that (i) for medium-sized\nmodels such as ViT and GPT-2, training with BLAST weights boosts performance\nwhile reducing complexity by 70% and 40%, respectively; and (ii) for large\nfoundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x\ncompression while exhibiting the lowest performance degradation among all\ntested structured matrices. Our code is available at\nhttps://github.com/changwoolee/BLAST.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21262v2",
    "published_date": "2024-10-28 17:56:18 UTC",
    "updated_date": "2024-10-30 00:38:11 UTC"
  },
  {
    "arxiv_id": "2410.21259v4",
    "title": "AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?",
    "authors": [
      "Han Bao",
      "Yue Huang",
      "Yanbo Wang",
      "Jiayi Ye",
      "Xiangqi Wang",
      "Xiuying Chen",
      "Yue Zhao",
      "Tianyi Zhou",
      "Mohamed Elhoseiny",
      "Xiangliang Zhang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have become essential for advancing the\nintegration of visual and linguistic information. However, the evaluation of\nLVLMs presents significant challenges as the evaluation benchmark always\ndemands lots of human cost for its construction, and remains static, lacking\nflexibility once constructed. Even though automatic evaluation has been\nexplored in textual modality, the visual modality remains under-explored. As a\nresult, in this work, we address a question: \"Can LVLMs themselves be used to\nbenchmark each other in the visual automatically domain?\". We introduce\nAutoBench-V, an automated framework for serving evaluation on demand, i.e.,\nbenchmarking LVLMs based on specific aspects of model capability. AutoBench-V\nleverages text-to-image models to generate relevant image samples and then\nutilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing\nthe evaluation process efficiently and flexibly. Through an extensive\nevaluation of nine popular LVLMs across five demanded user inputs (i.e.,\nevaluation capabilities), the framework shows effectiveness and reliability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21259v4",
    "published_date": "2024-10-28 17:55:08 UTC",
    "updated_date": "2025-03-06 03:31:32 UTC"
  },
  {
    "arxiv_id": "2410.21256v2",
    "title": "Multi-modal AI for comprehensive breast cancer prognostication",
    "authors": [
      "Jan Witowski",
      "Ken G. Zeng",
      "Joseph Cappadona",
      "Jailan Elayoubi",
      "Khalil Choucair",
      "Elena Diana Chiru",
      "Nancy Chan",
      "Young-Joon Kang",
      "Frederick Howard",
      "Irina Ostrovnaya",
      "Carlos Fernandez-Granda",
      "Freya Schnabel",
      "Zoe Steinsnyder",
      "Ugur Ozerdem",
      "Kangning Liu",
      "Waleed Abdulsattar",
      "Yu Zong",
      "Lina Daoud",
      "Rafic Beydoun",
      "Anas Saad",
      "Nitya Thakore",
      "Mohammad Sadic",
      "Frank Yeung",
      "Elisa Liu",
      "Theodore Hill",
      "Benjamin Swett",
      "Danielle Rigau",
      "Andrew Clayburn",
      "Valerie Speirs",
      "Marcus Vetter",
      "Lina Sojak",
      "Simone Soysal",
      "Daniel Baumhoer",
      "Jia-Wern Pan",
      "Haslina Makmur",
      "Soo-Hwang Teo",
      "Linda Ma Pak",
      "Victor Angel",
      "Dovile Zilenaite-Petrulaitiene",
      "Arvydas Laurinavicius",
      "Natalie Klar",
      "Brian D. Piening",
      "Carlo Bifulco",
      "Sun-Young Jun",
      "Jae Pak Yi",
      "Su Hyun Lim",
      "Adam Brufsky",
      "Francisco J. Esteva",
      "Lajos Pusztai",
      "Yann LeCun",
      "Krzysztof J. Geras"
    ],
    "abstract": "Treatment selection in breast cancer is guided by molecular subtypes and\nclinical characteristics. However, current tools including genomic assays lack\nthe accuracy required for optimal clinical decision-making. We developed a\nnovel artificial intelligence (AI)-based approach that integrates digital\npathology images with clinical data, providing a more robust and effective\nmethod for predicting the risk of cancer recurrence in breast cancer patients.\nSpecifically, we utilized a vision transformer pan-cancer foundation model\ntrained with self-supervised learning to extract features from digitized\nH&E-stained slides. These features were integrated with clinical data to form a\nmulti-modal AI test predicting cancer recurrence and death. The test was\ndeveloped and evaluated using data from a total of 8,161 female breast cancer\npatients across 15 cohorts originating from seven countries. Of these, 3,502\npatients from five cohorts were used exclusively for evaluation, while the\nremaining patients were used for training. Our test accurately predicted our\nprimary endpoint, disease-free interval, in the five evaluation cohorts\n(C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.001]). In a direct\ncomparison (n=858), the AI test was more accurate than Oncotype DX, the\nstandard-of-care 21-gene assay, achieving a C-index of 0.67 [0.61-0.74] versus\n0.61 [0.49-0.73], respectively. Additionally, the AI test added independent\nprognostic information to Oncotype DX in a multivariate analysis (HR: 3.11\n[1.91-5.09, p<0.001)]). The test demonstrated robust accuracy across major\nmolecular breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81],\nHR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently\nrecommended by clinical guidelines. These results suggest that our AI test\nimproves upon the accuracy of existing prognostic tests, while being applicable\nto a wider range of patients.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21256v2",
    "published_date": "2024-10-28 17:54:29 UTC",
    "updated_date": "2025-03-03 03:23:44 UTC"
  },
  {
    "arxiv_id": "2410.21249v1",
    "title": "Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach",
    "authors": [
      "Manav Vora",
      "Ilan Shomorony",
      "Melkior Ornik"
    ],
    "abstract": "Many real-world sequential repair problems can be effectively modeled using\nmonotonic Markov Decision Processes (MDPs), where the system state\nstochastically decreases and can only be increased by performing a restorative\naction. This work addresses the problem of solving multi-component monotonic\nMDPs with both budget and capacity constraints. The budget constraint limits\nthe total number of restorative actions and the capacity constraint limits the\nnumber of restorative actions that can be performed simultaneously. While prior\nmethods dealt with budget constraints, including capacity constraints in prior\nmethods leads to an exponential increase in computational complexity as the\nnumber of components in the MDP grows. We propose a two-step planning approach\nto address this challenge. First, we partition the components of the\nmulti-component MDP into groups, where the number of groups is determined by\nthe capacity constraint. We achieve this partitioning by solving a Linear Sum\nAssignment Problem (LSAP). Each group is then allocated a fraction of the total\nbudget proportional to its size. This partitioning effectively decouples the\nlarge multi-component MDP into smaller subproblems, which are computationally\nfeasible because the capacity constraint is simplified and the budget\nconstraint can be addressed using existing methods. Subsequently, we use a\nmeta-trained PPO agent to obtain an approximately optimal policy for each\ngroup. To validate our approach, we apply it to the problem of scheduling\nrepairs for a large group of industrial robots, constrained by a limited number\nof repair technicians and a total repair budget. Our results demonstrate that\nthe proposed method outperforms baseline approaches in terms of maximizing the\naverage uptime of the robot swarm, particularly for large swarm sizes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21249v1",
    "published_date": "2024-10-28 17:48:45 UTC",
    "updated_date": "2024-10-28 17:48:45 UTC"
  },
  {
    "arxiv_id": "2410.21359v2",
    "title": "Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games",
    "authors": [
      "Ji Ma"
    ],
    "abstract": "As Large Language Model (LLM)-based agents increasingly undertake real-world\ntasks and engage with human society, how well do we understand their behaviors?\nWe (1) investigate how LLM agents' prosocial behaviors -- a fundamental social\nnorm -- can be induced by different personas and benchmarked against human\nbehaviors; and (2) introduce a behavioral and social science approach to\nevaluate LLM agents' decision-making. We explored how different personas and\nexperimental framings affect these AI agents' altruistic behavior in dictator\ngames and compared their behaviors within the same LLM family, across various\nfamilies, and with human behaviors. The findings reveal substantial variations\nand inconsistencies among LLMs and notable differences compared to human\nbehaviors. Merely assigning a human-like identity to LLMs does not produce\nhuman-like behaviors. Despite being trained on extensive human-generated data,\nthese AI agents are unable to capture the internal processes of human\ndecision-making. Their alignment with human is highly variable and dependent on\nspecific model architectures and prompt formulations; even worse, such\ndependence does not follow a clear pattern. LLMs can be useful task-specific\ntools but are not yet intelligent human-like agents.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21359v2",
    "published_date": "2024-10-28 17:47:41 UTC",
    "updated_date": "2024-12-16 20:00:43 UTC"
  },
  {
    "arxiv_id": "2410.21242v1",
    "title": "Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback",
    "authors": [
      "Nour Jedidi",
      "Yung-Sung Chuang",
      "Leslie Shing",
      "James Glass"
    ],
    "abstract": "Building effective dense retrieval systems remains difficult when relevance\nsupervision is not available. Recent work has looked to overcome this challenge\nby using a Large Language Model (LLM) to generate hypothetical documents that\ncan be used to find the closest real document. However, this approach relies\nsolely on the LLM to have domain-specific knowledge relevant to the query,\nwhich may not be practical. Furthermore, generating hypothetical documents can\nbe inefficient as it requires the LLM to generate a large number of tokens for\neach query. To address these challenges, we introduce Real Document Embeddings\nfrom Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF\nproposes to re-frame hypothetical document generation as a relevance estimation\ntask, using an LLM to select which documents should be used for nearest\nneighbor search. Through this re-framing, the LLM no longer needs\ndomain-specific knowledge but only needs to judge what is relevant.\nAdditionally, relevance estimation only requires the LLM to output a single\ntoken, thereby improving search latency. Our experiments show that ReDE-RF\nconsistently surpasses state-of-the-art zero-shot dense retrieval methods\nacross a wide range of low-resource retrieval datasets while also making\nsignificant improvements in latency per-query.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21242v1",
    "published_date": "2024-10-28 17:40:40 UTC",
    "updated_date": "2024-10-28 17:40:40 UTC"
  },
  {
    "arxiv_id": "2410.21237v1",
    "title": "Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce",
    "authors": [
      "Zhantao Yang",
      "Han Zhang",
      "Fangyi Chen",
      "Anudeepsekhar Bolimera",
      "Marios Savvides"
    ],
    "abstract": "Knowledge Graph (KG) is playing an increasingly important role in various AI\nsystems. For e-commerce, an efficient and low-cost automated knowledge graph\nconstruction method is the foundation of enabling various successful downstream\napplications. In this paper, we propose a novel method for constructing\nstructured product knowledge graphs from raw product images. The method\ncooperatively leverages recent advances in the vision-language model (VLM) and\nlarge language model (LLM), fully automating the process and allowing timely\ngraph updates. We also present a human-annotated e-commerce product dataset for\nbenchmarking product property extraction in knowledge graph construction. Our\nmethod outperforms our baseline in all metrics and evaluated properties,\ndemonstrating its effectiveness and bright usage potential.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21237v1",
    "published_date": "2024-10-28 17:34:05 UTC",
    "updated_date": "2024-10-28 17:34:05 UTC"
  },
  {
    "arxiv_id": "2410.21236v2",
    "title": "Flaming-hot Initiation with Regular Execution Sampling for Large Language Models",
    "authors": [
      "Weizhe Chen",
      "Zhicheng Zhang",
      "Guanlin Liu",
      "Renjie Zheng",
      "Wenlei Shi",
      "Chen Dun",
      "Zheng Wu",
      "Xing Jin",
      "Lin Yan"
    ],
    "abstract": "Since the release of ChatGPT, large language models (LLMs) have demonstrated\nremarkable capabilities across various domains. A key challenge in developing\nthese general capabilities is efficiently sourcing diverse, high-quality data.\nThis becomes especially critical in reasoning-related tasks with sandbox\ncheckers, such as math or code, where the goal is to generate correct solutions\nto specific problems with higher probability. In this work, we introduce\nFlaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet\nhighly effective method to efficiently find good responses. Our empirical\nfindings show that FIRE sampling enhances inference-time generation quality and\nalso benefits training in the alignment stage. Furthermore, we explore how FIRE\nsampling improves performance by promoting diversity and analyze the impact of\nemploying FIRE at different positions within a response.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21236v2",
    "published_date": "2024-10-28 17:30:01 UTC",
    "updated_date": "2025-02-13 21:50:10 UTC"
  },
  {
    "arxiv_id": "2411.00820v1",
    "title": "AutoGLM: Autonomous Foundation Agents for GUIs",
    "authors": [
      "Xiao Liu",
      "Bo Qin",
      "Dongzhu Liang",
      "Guang Dong",
      "Hanyu Lai",
      "Hanchen Zhang",
      "Hanlin Zhao",
      "Iat Long Iong",
      "Jiadai Sun",
      "Jiaqi Wang",
      "Junjie Gao",
      "Junjun Shan",
      "Kangning Liu",
      "Shudan Zhang",
      "Shuntian Yao",
      "Siyi Cheng",
      "Wentao Yao",
      "Wenyi Zhao",
      "Xinghan Liu",
      "Xinyi Liu",
      "Xinying Chen",
      "Xinyue Yang",
      "Yang Yang",
      "Yifan Xu",
      "Yu Yang",
      "Yujia Wang",
      "Yulin Xu",
      "Zehan Qi",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "abstract": "We present AutoGLM, a new series in the ChatGLM family, designed to serve as\nfoundation agents for autonomous control of digital devices through Graphical\nUser Interfaces (GUIs). While foundation models excel at acquiring human\nknowledge, they often struggle with decision-making in dynamic real-world\nenvironments, limiting their progress toward artificial general intelligence.\nThis limitation underscores the importance of developing foundation agents\ncapable of learning through autonomous environmental interactions by\nreinforcing existing models. Focusing on Web Browser and Phone as\nrepresentative GUI scenarios, we have developed AutoGLM as a practical\nfoundation agent system for real-world GUI interactions. Our approach\nintegrates a comprehensive suite of techniques and infrastructures to create\ndeployable agent systems suitable for user delivery. Through this development,\nwe have derived two key insights: First, the design of an appropriate\n\"intermediate interface\" for GUI control is crucial, enabling the separation of\nplanning and grounding behaviors, which require distinct optimization for\nflexibility and accuracy respectively. Second, we have developed a novel\nprogressive training framework that enables self-evolving online curriculum\nreinforcement learning for AutoGLM. Our evaluations demonstrate AutoGLM's\neffectiveness across multiple domains. For web browsing, AutoGLM achieves a\n55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second\nattempt) and 96.2% on OpenTable evaluation tasks. In Android device control,\nAutoGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on\ncommon tasks in popular Chinese APPs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00820v1",
    "published_date": "2024-10-28 17:05:10 UTC",
    "updated_date": "2024-10-28 17:05:10 UTC"
  },
  {
    "arxiv_id": "2410.21220v1",
    "title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines",
    "authors": [
      "Zhixin Zhang",
      "Yiyuan Zhang",
      "Xiaohan Ding",
      "Xiangyu Yue"
    ],
    "abstract": "Search engines enable the retrieval of unknown information with texts.\nHowever, traditional methods fall short when it comes to understanding\nunfamiliar visual content, such as identifying an object that the model has\nnever seen before. This challenge is particularly pronounced for large\nvision-language models (VLMs): if the model has not been exposed to the object\ndepicted in an image, it struggles to generate reliable answers to the user's\nquestion regarding that image. Moreover, as new objects and events continuously\nemerge, frequently updating VLMs is impractical due to heavy computational\nburdens. To address this limitation, we propose Vision Search Assistant, a\nnovel framework that facilitates collaboration between VLMs and web agents.\nThis approach leverages VLMs' visual understanding capabilities and web agents'\nreal-time information access to perform open-world Retrieval-Augmented\nGeneration via the web. By integrating visual and textual representations\nthrough this collaboration, the model can provide informed responses even when\nthe image is novel to the system. Extensive experiments conducted on both\nopen-set and closed-set QA benchmarks demonstrate that the Vision Search\nAssistant significantly outperforms the other models and can be widely applied\nto existing VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at https://github.com/cnzzx/VSA",
    "pdf_url": "http://arxiv.org/pdf/2410.21220v1",
    "published_date": "2024-10-28 17:04:18 UTC",
    "updated_date": "2024-10-28 17:04:18 UTC"
  },
  {
    "arxiv_id": "2410.21216v2",
    "title": "HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation",
    "authors": [
      "Yuhan Chen",
      "Ang Lv",
      "Jian Luan",
      "Bin Wang",
      "Wei Liu"
    ],
    "abstract": "Many positional encodings (PEs) are designed to exhibit long-term decay,\nbased on an entrenched and long-standing inductive opinion: tokens farther away\nfrom the current position carry less relevant information. We argue that\nlong-term decay is outdated in the era of LLMs, as LLMs are now applied to\ntasks demanding precise retrieval of in-context information from arbitrary\npositions. Firstly, we present empirical analyses on various PEs, demonstrating\nthat models inherently learn attention with only a local-decay pattern while\nforming a U-shape pattern globally, contradicting the principle of long-term\ndecay. Furthermore, we conduct a detailed analysis of rotary position encoding\n(RoPE, a prevalent relative positional encoding in LLMs), and found that the\nU-shape attention is caused by some learned components, which are also the key\nfactor limiting RoPE's expressiveness and extrapolation.Inspired by these\ninsights, we propose High-frequency rotary Position Encoding (HoPE). HoPE\nreplaces the specific components in RoPE with position-independent ones,\nretaining only high-frequency signals, which also breaks the principle of\nlong-term decay in theory. HoPE achieves two major advantages: (1) Without\nconstraints imposed by long-term decay, contradictory factors that limit\nspontaneous attention optimization and model extrapolation performance are\nremoved. (2) Components representing positions and semantics are are optimized.\nThese enhances model's context awareness and extrapolation, as validated by\nextensive experiments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21216v2",
    "published_date": "2024-10-28 17:01:52 UTC",
    "updated_date": "2024-12-05 07:09:27 UTC"
  },
  {
    "arxiv_id": "2410.21203v1",
    "title": "SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning",
    "authors": [
      "MohammadReza EskandariNasab",
      "Shah Muhammad Hamdi",
      "Soukaina Filali Boubrahimi"
    ],
    "abstract": "Current Generative Adversarial Network (GAN)-based approaches for time series\ngeneration face challenges such as suboptimal convergence, information loss in\nembedding spaces, and instability. To overcome these challenges, we introduce\nan advanced framework that integrates the advantages of an\nautoencoder-generated embedding space with the adversarial training dynamics of\nGANs. This method employs two discriminators: one to specifically guide the\ngenerator and another to refine both the autoencoder's and generator's output.\nAdditionally, our framework incorporates a novel autoencoder-based loss\nfunction and supervision from a teacher-forcing supervisor network, which\ncaptures the stepwise conditional distributions of the data. The generator\noperates within the latent space, while the two discriminators work on latent\nand feature spaces separately, providing crucial feedback to both the generator\nand the autoencoder. By leveraging this dual-discriminator approach, we\nminimize information loss in the embedding space. Through joint training, our\nframework excels at generating high-fidelity time series data, consistently\noutperforming existing state-of-the-art benchmarks both qualitatively and\nquantitatively across a range of real and synthetic multivariate time series\ndatasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted at BigData 2024 on October 26, 2024, as a\n  regular paper for oral presentation",
    "pdf_url": "http://arxiv.org/pdf/2410.21203v1",
    "published_date": "2024-10-28 16:49:03 UTC",
    "updated_date": "2024-10-28 16:49:03 UTC"
  },
  {
    "arxiv_id": "2410.21200v1",
    "title": "BongLLaMA: LLaMA for Bangla Language",
    "authors": [
      "Abdullah Khan Zehady",
      "Safi Al Mamun",
      "Naymul Islam",
      "Santu Karmaker"
    ],
    "abstract": "Bangla (or \"Bengali\") is a language spoken by approximately 240 million\nnative speakers and around 300 million people worldwide. Despite being the 5th\nlargest spoken language in the world, Bangla is still a \"low-resource\"\nlanguage, and existing pretrained language models often struggle to perform\nwell on Bangla Language Processing (BLP) tasks. This work addresses this gap by\nintroducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model\nfine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.\nWe present our methodology, data augmentation techniques, fine-tuning details,\nand comprehensive benchmarking results showcasing the utility of BongLLaMA on\nBLP tasks. We believe BongLLaMA will serve as the new standard baseline for\nBangla Language Models and, thus, facilitate future benchmarking studies\nfocused on this widely-spoken yet \"low-resource\" language. All BongLLaMA models\nare available for public use at https://huggingface.co/BanglaLLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21200v1",
    "published_date": "2024-10-28 16:44:02 UTC",
    "updated_date": "2024-10-28 16:44:02 UTC"
  },
  {
    "arxiv_id": "2410.21195v1",
    "title": "Belief in the Machine: Investigating Epistemological Blind Spots of Language Models",
    "authors": [
      "Mirac Suzgun",
      "Tayfun Gur",
      "Federico Bianchi",
      "Daniel E. Ho",
      "Thomas Icard",
      "Dan Jurafsky",
      "James Zou"
    ],
    "abstract": "As language models (LMs) become integral to fields like healthcare, law, and\njournalism, their ability to differentiate between fact, belief, and knowledge\nis essential for reliable decision-making. Failure to grasp these distinctions\ncan lead to significant consequences in areas such as medical diagnosis, legal\njudgments, and dissemination of fake news. Despite this, current literature has\nlargely focused on more complex issues such as theory of mind, overlooking more\nfundamental epistemic challenges. This study systematically evaluates the\nepistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and\nLlama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13\ntasks. Our results reveal key limitations. First, while LMs achieve 86%\naccuracy on factual scenarios, their performance drops significantly with false\nscenarios, particularly in belief-related tasks. Second, LMs struggle with\nrecognizing and affirming personal beliefs, especially when those beliefs\ncontradict factual data, which raises concerns for applications in healthcare\nand counseling, where engaging with a person's beliefs is critical. Third, we\nidentify a salient bias in how LMs process first-person versus third-person\nbeliefs, performing better on third-person tasks (80.7%) compared to\nfirst-person tasks (54.4%). Fourth, LMs lack a robust understanding of the\nfactive nature of knowledge, namely, that knowledge inherently requires truth.\nFifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the\ndeeper reasoning. These findings highlight significant concerns about current\nLMs' ability to reason about truth, belief, and knowledge while emphasizing the\nneed for advancements in these areas before broad deployment in critical\nsectors.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/suzgunmirac/belief-in-the-machine",
    "pdf_url": "http://arxiv.org/pdf/2410.21195v1",
    "published_date": "2024-10-28 16:38:20 UTC",
    "updated_date": "2024-10-28 16:38:20 UTC"
  },
  {
    "arxiv_id": "2410.21175v1",
    "title": "Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks",
    "authors": [
      "Jiawei Zhang",
      "Jun Li",
      "Reachsak Ly",
      "Yunyi Liu",
      "Jiangpeng Shu"
    ],
    "abstract": "For structural health monitoring, continuous and automatic crack detection\nhas been a challenging problem. This study is conducted to propose a framework\nof automatic crack segmentation from high-resolution images containing crack\ninformation about steel box girders of bridges. Considering the multi-scale\nfeature of cracks, convolutional neural network architecture of Feature Pyramid\nNetworks (FPN) for crack detection is proposed. As for input, 120 raw images\nare processed via two approaches (shrinking the size of images and splitting\nimages into sub-images). Then, models with the proposed structure of FPN for\ncrack detection are developed. The result shows all developed models can\nautomatically detect the cracks at the raw images. By shrinking the images, the\ncomputation efficiency is improved without decreasing accuracy. Because of the\nseparable characteristic of crack, models using the splitting method provide\nmore accurate crack segmentations than models using the resizing method.\nTherefore, for high-resolution images, the FPN structure coupled with the\nsplitting method is an promising solution for the crack segmentation and\ndetection.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21175v1",
    "published_date": "2024-10-28 16:16:15 UTC",
    "updated_date": "2024-10-28 16:16:15 UTC"
  },
  {
    "arxiv_id": "2410.21169v4",
    "title": "Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction",
    "authors": [
      "Qintong Zhang",
      "Bin Wang",
      "Victor Shea-Jay Huang",
      "Junyuan Zhang",
      "Zhengren Wang",
      "Hao Liang",
      "Conghui He",
      "Wentao Zhang"
    ],
    "abstract": "Document parsing is essential for converting unstructured and semi-structured\ndocuments such as contracts, academic papers, and invoices into structured,\nmachine-readable data. Document parsing reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\noutlines future research directions and emphasizes the importance of developing\nlarger and more diverse datasets.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21169v4",
    "published_date": "2024-10-28 16:11:35 UTC",
    "updated_date": "2025-04-16 15:01:20 UTC"
  },
  {
    "arxiv_id": "2410.21159v2",
    "title": "CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants",
    "authors": [
      "Lize Alberts",
      "Benjamin Ellis",
      "Andrei Lupu",
      "Jakob Foerster"
    ],
    "abstract": "We introduce a multi-turn benchmark for evaluating personalised alignment in\nLLM-based AI assistants, focusing on their ability to handle user-provided\nsafety-critical contexts. Our assessment of ten leading models across five\nscenarios (with 337 use cases each) reveals systematic inconsistencies in\nmaintaining user-specific consideration, with even top-rated \"harmless\" models\nmaking recommendations that should be recognised as obviously harmful to the\nuser given the context provided. Key failure modes include inappropriate\nweighing of conflicting preferences, sycophancy (prioritising desires above\nsafety), a lack of attentiveness to critical user information within the\ncontext window, and inconsistent application of user-specific knowledge. The\nsame systematic biases were observed in OpenAI's o1, suggesting that strong\nreasoning capacities do not necessarily transfer to this kind of personalised\nthinking. We find that prompting LLMs to consider safety-critical context\nsignificantly improves performance, unlike a generic 'harmless and helpful'\ninstruction. Based on these findings, we propose research directions for\nembedding self-reflection capabilities, online user modelling, and dynamic risk\nassessment in AI assistants. Our work emphasises the need for nuanced,\ncontext-aware approaches to alignment in systems designed for persistent human\ninteraction, aiding the development of safe and considerate AI assistants.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "68T05",
      "I.2.0; I.2.7; K.4.2; H.5.2; I.2.6"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21159v2",
    "published_date": "2024-10-28 15:59:31 UTC",
    "updated_date": "2025-01-30 01:29:03 UTC"
  },
  {
    "arxiv_id": "2410.21154v2",
    "title": "Trajectory Flow Matching with Applications to Clinical Time Series Modeling",
    "authors": [
      "Xi Zhang",
      "Yuan Pu",
      "Yuki Kawamura",
      "Andrew Loza",
      "Yoshua Bengio",
      "Dennis L. Shung",
      "Alexander Tong"
    ],
    "abstract": "Modeling stochastic and irregularly sampled time series is a challenging\nproblem found in a wide range of applications, especially in medicine. Neural\nstochastic differential equations (Neural SDEs) are an attractive modeling\ntechnique for this problem, which parameterize the drift and diffusion terms of\nan SDE with neural networks. However, current algorithms for training Neural\nSDEs require backpropagation through the SDE dynamics, greatly limiting their\nscalability and stability. To address this, we propose Trajectory Flow Matching\n(TFM), which trains a Neural SDE in a simulation-free manner, bypassing\nbackpropagation through the dynamics. TFM leverages the flow matching technique\nfrom generative modeling to model time series. In this work we first establish\nnecessary conditions for TFM to learn time series data. Next, we present a\nreparameterization trick which improves training stability. Finally, we adapt\nTFM to the clinical time series setting, demonstrating improved performance on\nthree clinical time series datasets both in terms of absolute performance and\nuncertainty prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2410.21154v2",
    "published_date": "2024-10-28 15:54:50 UTC",
    "updated_date": "2025-02-04 17:54:45 UTC"
  },
  {
    "arxiv_id": "2410.21146v1",
    "title": "Palisade -- Prompt Injection Detection Framework",
    "authors": [
      "Sahasra Kokkula",
      "Somanathan R",
      "Nandavardhan R",
      "Aashishkumar",
      "G Divya"
    ],
    "abstract": "The advent of Large Language Models LLMs marks a milestone in Artificial\nIntelligence, altering how machines comprehend and generate human language.\nHowever, LLMs are vulnerable to malicious prompt injection attacks, where\ncrafted inputs manipulate the models behavior in unintended ways, compromising\nsystem integrity and causing incorrect outcomes. Conventional detection methods\nrely on static, rule-based approaches, which often fail against sophisticated\nthreats like abnormal token sequences and alias substitutions, leading to\nlimited adaptability and higher rates of false positives and false\nnegatives.This paper proposes a novel NLP based approach for prompt injection\ndetection, emphasizing accuracy and optimization through a layered input\nscreening process. In this framework, prompts are filtered through three\ndistinct layers rule-based, ML classifier, and companion LLM before reaching\nthe target model, thereby minimizing the risk of malicious interaction.Tests\nshow the ML classifier achieves the highest accuracy among individual layers,\nyet the multi-layer framework enhances overall detection accuracy by reducing\nfalse negatives. Although this increases false positives, it minimizes the risk\nof overlooking genuine injected prompts, thus prioritizing security.This\nmulti-layered detection approach highlights LLM vulnerabilities and provides a\ncomprehensive framework for future research, promoting secure interactions\nbetween humans and AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21146v1",
    "published_date": "2024-10-28 15:47:03 UTC",
    "updated_date": "2024-10-28 15:47:03 UTC"
  },
  {
    "arxiv_id": "2410.21353v1",
    "title": "Causal Interventions on Causal Paths: Mapping GPT-2's Reasoning From Syntax to Semantics",
    "authors": [
      "Isabelle Lee",
      "Joshua Lum",
      "Ziyi Liu",
      "Dani Yogatama"
    ],
    "abstract": "While interpretability research has shed light on some internal algorithms\nutilized by transformer-based LLMs, reasoning in natural language, with its\ndeep contextuality and ambiguity, defies easy categorization. As a result,\nformulating clear and motivating questions for circuit analysis that rely on\nwell-defined in-domain and out-of-domain examples required for causal\ninterventions is challenging. Although significant work has investigated\ncircuits for specific tasks, such as indirect object identification (IOI),\ndeciphering natural language reasoning through circuits remains difficult due\nto its inherent complexity. In this work, we take initial steps to characterize\ncausal reasoning in LLMs by analyzing clear-cut cause-and-effect sentences like\n\"I opened an umbrella because it started raining,\" where causal interventions\nmay be possible through carefully crafted scenarios using GPT-2 small. Our\nfindings indicate that causal syntax is localized within the first 2-3 layers,\nwhile certain heads in later layers exhibit heightened sensitivity to\nnonsensical variations of causal sentences. This suggests that models may infer\nreasoning by (1) detecting syntactic cues and (2) isolating distinct heads in\nthe final layers that focus on semantic relationships.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21353v1",
    "published_date": "2024-10-28 15:37:56 UTC",
    "updated_date": "2024-10-28 15:37:56 UTC"
  },
  {
    "arxiv_id": "2410.21131v3",
    "title": "Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments",
    "authors": [
      "Marharyta Domnich",
      "Julius Välja",
      "Rasmus Moorits Veski",
      "Giacomo Magnifico",
      "Kadi Tulver",
      "Eduard Barbu",
      "Raul Vicente"
    ],
    "abstract": "As machine learning models evolve, maintaining transparency demands more\nhuman-centric explainable AI techniques. Counterfactual explanations, with\nroots in human reasoning, identify the minimal input changes needed to obtain a\ngiven output and, hence, are crucial for supporting decision-making. Despite\ntheir importance, the evaluation of these explanations often lacks grounding in\nuser studies and remains fragmented, with existing metrics not fully capturing\nhuman perspectives. To address this challenge, we developed a diverse set of 30\ncounterfactual scenarios and collected ratings across 8 evaluation metrics from\n206 respondents. Subsequently, we fine-tuned different Large Language Models\n(LLMs) to predict average or individual human judgment across these metrics.\nOur methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot\nevaluations and 85% (over a 3-classes prediction) with fine-tuning across all\nmetrics. The fine-tuned models predicting human ratings offer better\ncomparability and scalability in evaluating different counterfactual\nexplanation frameworks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper extends the AAAI-2025 version by including the Appendix",
    "pdf_url": "http://arxiv.org/pdf/2410.21131v3",
    "published_date": "2024-10-28 15:33:37 UTC",
    "updated_date": "2025-04-22 14:15:38 UTC"
  },
  {
    "arxiv_id": "2410.21129v1",
    "title": "Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models",
    "authors": [
      "Tuwe Löfström",
      "Fatima Rabia Yapicioglu",
      "Alessandra Stramiglio",
      "Helena Löfström",
      "Fabio Vitali"
    ],
    "abstract": "This paper introduces Fast Calibrated Explanations, a method designed for\ngenerating rapid, uncertainty-aware explanations for machine learning models.\nBy incorporating perturbation techniques from ConformaSight - a global\nexplanation framework - into the core elements of Calibrated Explanations (CE),\nwe achieve significant speedups. These core elements include local feature\nimportance with calibrated predictions, both of which retain uncertainty\nquantification. While the new method sacrifices a small degree of detail, it\nexcels in computational efficiency, making it ideal for high-stakes, real-time\napplications. Fast Calibrated Explanations are applicable to probabilistic\nexplanations in classification and thresholded regression tasks, where they\nprovide the likelihood of a target being above or below a user-defined\nthreshold. This approach maintains the versatility of CE for both\nclassification and probabilistic regression, making it suitable for a range of\npredictive tasks where uncertainty quantification is crucial.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages, 5 figures, journal submission",
    "pdf_url": "http://arxiv.org/pdf/2410.21129v1",
    "published_date": "2024-10-28 15:29:35 UTC",
    "updated_date": "2024-10-28 15:29:35 UTC"
  },
  {
    "arxiv_id": "2410.21127v1",
    "title": "Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model",
    "authors": [
      "Yang Tan",
      "Ruilin Wang",
      "Banghao Wu",
      "Liang Hong",
      "Bingxin Zhou"
    ],
    "abstract": "Enzyme engineering enables the modification of wild-type proteins to meet\nindustrial and research demands by enhancing catalytic activity, stability,\nbinding affinities, and other properties. The emergence of deep learning\nmethods for protein modeling has demonstrated superior results at lower costs\ncompared to traditional approaches such as directed evolution and rational\ndesign. In mutation effect prediction, the key to pre-training deep learning\nmodels lies in accurately interpreting the complex relationships among protein\nsequence, structure, and function. This study introduces a retrieval-enhanced\nprotein language model for comprehensive analysis of native properties from\nsequence and local structural interactions, as well as evolutionary properties\nfrom retrieved homologous sequences. The state-of-the-art performance of the\nproposed ProtREM is validated on over 2 million mutants across 217 assays from\nan open benchmark (ProteinGym). We also conducted post-hoc analyses of the\nmodel's ability to improve the stability and binding affinity of a VHH\nantibody. Additionally, we designed 10 new mutants on a DNA polymerase and\nconducted wet-lab experiments to evaluate their enhanced activity at higher\ntemperatures. Both in silico and experimental evaluations confirmed that our\nmethod provides reliable predictions of mutation effects, offering an auxiliary\ntool for biologists aiming to evolve existing enzymes. The implementation is\npublicly available at https://github.com/tyang816/ProtREM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 10 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21127v1",
    "published_date": "2024-10-28 15:28:51 UTC",
    "updated_date": "2024-10-28 15:28:51 UTC"
  },
  {
    "arxiv_id": "2411.08892v1",
    "title": "Auto-assessment of assessment: A conceptual framework towards fulfilling the policy gaps in academic assessment practices",
    "authors": [
      "Wasiq Khan",
      "Luke K. Topham",
      "Peter Atherton",
      "Raghad Al-Shabandar",
      "Hoshang Kolivand",
      "Iftikhar Khan",
      "Abir Hussain"
    ],
    "abstract": "Education is being transformed by rapid advances in Artificial Intelligence\n(AI), including emerging Generative Artificial Intelligence (GAI). Such\ntechnology can significantly support academics and students by automating\nmonotonous tasks and making personalised suggestions. However, despite the\npotential of the technology, there are significant concerns regarding AI\nmisuse, particularly by students in assessments. There are two schools of\nthought: one advocates for a complete ban on it, while the other views it as a\nvaluable educational tool, provided it is governed by a robust usage policy.\nThis contradiction clearly indicates a major policy gap in academic practices,\nand new policies are required to uphold academic standards while enabling staff\nand students to benefit from technological advancements. We surveyed 117\nacademics from three countries (UK, UAE, and Iraq), and identified that most\nacademics retain positive opinions regarding AI in education. For example, the\nmajority of experienced academics do not favour complete bans, and they see the\npotential benefits of AI for students, teaching staff, and academic\ninstitutions. Importantly, academics specifically identified the particular\nbenefits of AI for autonomous assessment (71.79% of respondents agreed).\nTherefore, for the first time, we propose a novel AI framework for autonomously\nevaluating students' work (e.g., reports, coursework, etc.) and automatically\nassigning grades based on their knowledge and in-depth understanding of the\nsubmitted content. The survey results further highlight a significant lack of\nawareness of modern AI-based tools (e.g., ChatGPT) among experienced academics,\na gap that must be addressed to uphold educational standards.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "68-04",
      "I.2; K.3"
    ],
    "primary_category": "cs.CY",
    "comment": "20 Pages, 5 Figures, submitted for journal peer-review",
    "pdf_url": "http://arxiv.org/pdf/2411.08892v1",
    "published_date": "2024-10-28 15:22:37 UTC",
    "updated_date": "2024-10-28 15:22:37 UTC"
  },
  {
    "arxiv_id": "2411.09788v1",
    "title": "AI-Driven Human-Autonomy Teaming in Tactical Operations: Proposed Framework, Challenges, and Future Directions",
    "authors": [
      "Desta Haileselassie Hagos",
      "Hassan El Alami",
      "Danda B. Rawat"
    ],
    "abstract": "Artificial Intelligence (AI) techniques, particularly machine learning\ntechniques, are rapidly transforming tactical operations by augmenting human\ndecision-making capabilities. This paper explores AI-driven Human-Autonomy\nTeaming (HAT) as a transformative approach, focusing on how it empowers human\ndecision-making in complex environments. While trust and explainability\ncontinue to pose significant challenges, our exploration focuses on the\npotential of AI-driven HAT to transform tactical operations. By improving\nsituational awareness and supporting more informed decision-making, AI-driven\nHAT can enhance the effectiveness and safety of such operations. To this end,\nwe propose a comprehensive framework that addresses the key components of\nAI-driven HAT, including trust and transparency, optimal function allocation\nbetween humans and AI, situational awareness, and ethical considerations. The\nproposed framework can serve as a foundation for future research and\ndevelopment in the field. By identifying and discussing critical research\nchallenges and knowledge gaps in this framework, our work aims to guide the\nadvancement of AI-driven HAT for optimizing tactical operations. We emphasize\nthe importance of developing scalable and ethical AI-driven HAT systems that\nensure seamless human-machine collaboration, prioritize ethical considerations,\nenhance model transparency through Explainable AI (XAI) techniques, and\neffectively manage the cognitive load of human operators.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Submitted for review to the Proceedings of the IEEE",
    "pdf_url": "http://arxiv.org/pdf/2411.09788v1",
    "published_date": "2024-10-28 15:05:16 UTC",
    "updated_date": "2024-10-28 15:05:16 UTC"
  },
  {
    "arxiv_id": "2410.21091v1",
    "title": "Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality",
    "authors": [
      "Junlong Chen",
      "Jens Grubert",
      "Per Ola Kristensson"
    ],
    "abstract": "Selection of occluded objects is a challenging problem in virtual reality,\neven more so if multiple objects are involved. With the advent of new\nartificial intelligence technologies, we explore the possibility of leveraging\nlarge language models to assist multi-object selection tasks in virtual reality\nvia a multimodal speech and raycast interaction technique. We validate the\nfindings in a comparative user study (n=24), where participants selected target\nobjects in a virtual reality scene with different levels of scene perplexity.\nThe performance metrics and user experience metrics are compared against a\nmini-map based occluded object selection technique that serves as the baseline.\nResults indicate that the introduced technique, AssistVR, outperforms the\nbaseline technique when there are multiple target objects. Contrary to the\ncommon belief for speech interfaces, AssistVR was able to outperform the\nbaseline even when the target objects were difficult to reference verbally.\nThis work demonstrates the viability and interaction potential of an\nintelligent multimodal interactive system powered by large laguage models.\nBased on the results, we discuss the implications for design of future\nintelligent multimodal interactive systems in immersive environments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.21091v1",
    "published_date": "2024-10-28 14:56:51 UTC",
    "updated_date": "2024-10-28 14:56:51 UTC"
  },
  {
    "arxiv_id": "2410.21086v1",
    "title": "Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving",
    "authors": [
      "Jiyao Wang",
      "Xiao Yang",
      "Zhenyu Wang",
      "Ximeng Wei",
      "Ange Wang",
      "Dengbo He",
      "Kaishun Wu"
    ],
    "abstract": "Road safety remains a critical challenge worldwide, with approximately 1.35\nmillion fatalities annually attributed to traffic accidents, often due to human\nerrors. As we advance towards higher levels of vehicle automation, challenges\nstill exist, as driving with automation can cognitively over-demand drivers if\nthey engage in non-driving-related tasks (NDRTs), or lead to drowsiness if\ndriving was the sole task. This calls for the urgent need for an effective\nDriver Monitoring System (DMS) that can evaluate cognitive load and drowsiness\nin SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel\nmulti-task DMS, termed VDMoE, which leverages RGB video input to monitor driver\nstates non-invasively. By utilizing key facial features to minimize\ncomputational load and integrating remote Photoplethysmography (rPPG) for\nphysiological insights, our approach enhances detection accuracy while\nmaintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)\nframework to accommodate multi-modal inputs and improve performance across\ndifferent tasks. A novel prior-inclusive regularization method is introduced to\nalign model outputs with statistical priors, thus accelerating convergence and\nmitigating overfitting risks. We validate our method with the creation of a new\ndataset (MCDD), which comprises RGB video and physiological indicators from 42\nparticipants, and two public datasets. Our findings demonstrate the\neffectiveness of VDMoE in monitoring driver states, contributing to safer\nautonomous driving systems. The code and data will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21086v1",
    "published_date": "2024-10-28 14:49:18 UTC",
    "updated_date": "2024-10-28 14:49:18 UTC"
  },
  {
    "arxiv_id": "2410.21083v2",
    "title": "Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring",
    "authors": [
      "Honglin Mu",
      "Han He",
      "Yuxin Zhou",
      "Yunlong Feng",
      "Yang Xu",
      "Libo Qin",
      "Xiaoming Shi",
      "Zeming Liu",
      "Xudong Han",
      "Qi Shi",
      "Qingfu Zhu",
      "Wanxiang Che"
    ],
    "abstract": "Large language model (LLM) safety is a critical issue, with numerous studies\nemploying red team testing to enhance model security. Among these, jailbreak\nmethods explore potential vulnerabilities by crafting malicious prompts that\ninduce model outputs contrary to safety alignments. Existing black-box\njailbreak methods often rely on model feedback, repeatedly submitting queries\nwith detectable malicious instructions during the attack search process.\nAlthough these approaches are effective, the attacks may be intercepted by\ncontent moderators during the search process. We propose an improved transfer\nattack method that guides malicious prompt construction by locally training a\nmirror model of the target black-box model through benign data distillation.\nThis method offers enhanced stealth, as it does not involve submitting\nidentifiable malicious instructions to the target model during the search\nphase. Our approach achieved a maximum attack success rate of 92%, or a\nbalanced value of 80% with an average of 1.5 detectable jailbreak queries per\nsample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore\nthe need for more robust defense mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.21083v2",
    "published_date": "2024-10-28 14:48:05 UTC",
    "updated_date": "2025-03-06 12:38:42 UTC"
  },
  {
    "arxiv_id": "2410.21352v2",
    "title": "LLMCBench: Benchmarking Large Language Model Compression for Efficient Deployment",
    "authors": [
      "Ge Yang",
      "Changyi He",
      "Jinyang Guo",
      "Jianyu Wu",
      "Yifu Ding",
      "Aishan Liu",
      "Haotong Qin",
      "Pengliang Ji",
      "Xianglong Liu"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated their strong\nintelligence ability, the high demand for computation and storage hinders their\npractical application. To this end, many model compression techniques are\nproposed to increase the efficiency of LLMs. However, current researches only\nvalidate their methods on limited models, datasets, metrics, etc, and still\nlack a comprehensive evaluation under more general scenarios. So it is still a\nquestion of which model compression approach we should use under a specific\ncase. To mitigate this gap, we present the Large Language Model Compression\nBenchmark (LLMCBench), a rigorously designed benchmark with an in-depth\nanalysis for LLM compression algorithms. We first analyze the actual model\nproduction requirements and carefully design evaluation tracks and metrics.\nThen, we conduct extensive experiments and comparison using multiple mainstream\nLLM compression approaches. Finally, we perform an in-depth analysis based on\nthe evaluation and provide useful insight for LLM compression design. We hope\nour LLMCBench can contribute insightful suggestions for LLM compression\nalgorithm design and serve as a foundation for future research. Our code is\navailable at https://github.com/AboveParadise/LLMCBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024 Datasets and Benchmarks Track",
    "pdf_url": "http://arxiv.org/pdf/2410.21352v2",
    "published_date": "2024-10-28 14:45:01 UTC",
    "updated_date": "2024-10-31 06:01:26 UTC"
  },
  {
    "arxiv_id": "2410.21073v1",
    "title": "Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices",
    "authors": [
      "Hiroki Matsutani",
      "Masaaki Kondo",
      "Kazuki Sunaga",
      "Radu Marculescu"
    ],
    "abstract": "This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep\nneural networks to address the gap between pre-trained and deployed models. In\nour approach, trainable LoRA (low-rank adaptation) adapters are inserted\nbetween the last layer and every other layer to enhance the network expressive\npower while keeping the backward computation cost low. This architecture is\nwell-suited to cache intermediate computation results of the forward pass and\nthen can skip the forward computation of seen samples as training epochs\nprogress. We implemented the combination of the proposed architecture and\ncache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our\nresults show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average\ncompared to the counterpart that has the same number of trainable parameters\nwhile preserving the accuracy, while taking only a few seconds on the\nmicrocontroller board.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ASP-DAC 2025 (accepted)",
    "pdf_url": "http://arxiv.org/pdf/2410.21073v1",
    "published_date": "2024-10-28 14:35:12 UTC",
    "updated_date": "2024-10-28 14:35:12 UTC"
  },
  {
    "arxiv_id": "2410.21069v2",
    "title": "EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment",
    "authors": [
      "Xiaoqi Ling",
      "Cheng Cai",
      "Demin Kong",
      "Zhisheng Wei",
      "Jing Wu",
      "Lei Wang",
      "Zhaohong Deng"
    ],
    "abstract": "Computational protein design (CPD) refers to the use of computational methods\nto design proteins. Traditional methods relying on energy functions and\nheuristic algorithms for sequence design are inefficient and do not meet the\ndemands of the big data era in biomolecules, with their accuracy limited by the\nenergy functions and search algorithms. Existing deep learning methods are\nconstrained by the learning capabilities of the networks, failing to extract\neffective information from sparse protein structures, which limits the accuracy\nof protein design. To address these shortcomings, we developed an Efficient\nattention-based Models for Computational Protein Design using amino acid\nmicroenvironment (EMOCPD). It aims to predict the category of each amino acid\nin a protein by analyzing the three-dimensional atomic environment surrounding\nthe amino acids, and optimize the protein based on the predicted\nhigh-probability potential amino acid categories. EMOCPD employs a multi-head\nattention mechanism to focus on important features in the sparse protein\nmicroenvironment and utilizes an inverse residual structure to optimize the\nnetwork architecture. The proposed EMOCPD achieves over 80% accuracy on the\ntraining set and 68.33% and 62.32% accuracy on two independent test sets,\nrespectively, surpassing the best comparative methods by over 10%. In protein\ndesign, the thermal stability and protein expression of the predicted mutants\nfrom EMOCPD show significant improvements compared to the wild type,\neffectively validating EMOCPD's potential in designing superior proteins.\nFurthermore, the predictions of EMOCPD are influenced positively, negatively,\nor have minimal impact based on the content of the 20 amino acids, categorizing\namino acids as positive, negative, or neutral. Research findings indicate that\nEMOCPD is more suitable for designing proteins with lower contents of negative\namino acids.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21069v2",
    "published_date": "2024-10-28 14:31:18 UTC",
    "updated_date": "2024-10-29 05:45:14 UTC"
  },
  {
    "arxiv_id": "2410.21066v1",
    "title": "Learning to Handle Complex Constraints for Vehicle Routing Problems",
    "authors": [
      "Jieyi Bi",
      "Yining Ma",
      "Jianan Zhou",
      "Wen Song",
      "Zhiguang Cao",
      "Yaoxin Wu",
      "Jie Zhang"
    ],
    "abstract": "Vehicle Routing Problems (VRPs) can model many real-world scenarios and often\ninvolve complex constraints. While recent neural methods excel in constructing\nsolutions based on feasibility masking, they struggle with handling complex\nconstraints, especially when obtaining the masking itself is NP-hard. In this\npaper, we propose a novel Proactive Infeasibility Prevention (PIP) framework to\nadvance the capabilities of neural methods towards more complex VRPs. Our PIP\nintegrates the Lagrangian multiplier as a basis to enhance constraint awareness\nand introduces preventative infeasibility masking to proactively steer the\nsolution construction process. Moreover, we present PIP-D, which employs an\nauxiliary decoder and two adaptive strategies to learn and predict these\ntailored masks, potentially enhancing performance while significantly reducing\ncomputational costs during training. To verify our PIP designs, we conduct\nextensive experiments on the highly challenging Traveling Salesman Problem with\nTime Window (TSPTW), and TSP with Draft Limit (TSPDL) variants under different\nconstraint hardness levels. Notably, our PIP is generic to boost many neural\nmethods, and exhibits both a significant reduction in infeasible rate and a\nsubstantial improvement in solution quality.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21066v1",
    "published_date": "2024-10-28 14:26:54 UTC",
    "updated_date": "2024-10-28 14:26:54 UTC"
  },
  {
    "arxiv_id": "2410.21061v1",
    "title": "Kandinsky 3: Text-to-Image Synthesis for Multifunctional Generative Framework",
    "authors": [
      "Vladimir Arkhipkin",
      "Viacheslav Vasilev",
      "Andrei Filatov",
      "Igor Pavlov",
      "Julia Agafonova",
      "Nikolai Gerasimenko",
      "Anna Averchenkova",
      "Evelina Mironova",
      "Anton Bukashkin",
      "Konstantin Kulikov",
      "Andrey Kuznetsov",
      "Denis Dimitrov"
    ],
    "abstract": "Text-to-image (T2I) diffusion models are popular for introducing image\nmanipulation methods, such as editing, image fusion, inpainting, etc. At the\nsame time, image-to-video (I2V) and text-to-video (T2V) models are also built\non top of T2I models. We present Kandinsky 3, a novel T2I model based on latent\ndiffusion, achieving a high level of quality and photorealism. The key feature\nof the new architecture is the simplicity and efficiency of its adaptation for\nmany types of generation tasks. We extend the base T2I model for various\napplications and create a multifunctional generation system that includes\ntext-guided inpainting/outpainting, image fusion, text-image fusion, image\nvariations generation, I2V and T2V generation. We also present a distilled\nversion of the T2I model, evaluating inference in 4 steps of the reverse\nprocess without reducing image quality and 3 times faster than the base model.\nWe deployed a user-friendly demo system in which all the features can be tested\nin the public domain. Additionally, we released the source code and checkpoints\nfor the Kandinsky 3 and extended models. Human evaluations show that Kandinsky\n3 demonstrates one of the highest quality scores among open source generation\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for EMNLP 2024 (Demo track)",
    "pdf_url": "http://arxiv.org/pdf/2410.21061v1",
    "published_date": "2024-10-28 14:22:08 UTC",
    "updated_date": "2024-10-28 14:22:08 UTC"
  },
  {
    "arxiv_id": "2410.21060v2",
    "title": "CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models",
    "authors": [
      "Yutong Cheng",
      "Osama Bajaber",
      "Saimon Amanuel Tsegai",
      "Dawn Song",
      "Peng Gao"
    ],
    "abstract": "Textual descriptions in cyber threat intelligence (CTI) reports, such as\nsecurity articles and news, are rich sources of knowledge about cyber threats,\ncrucial for organizations to stay informed about the rapidly evolving threat\nlandscape. However, current CTI knowledge extraction methods lack flexibility\nand generalizability, often resulting in inaccurate and incomplete knowledge\nextraction. Syntax parsing relies on fixed rules and dictionaries, while model\nfine-tuning requires large annotated datasets, making both paradigms\nchallenging to adapt to new threats and ontologies. To bridge the gap, we\npropose CTINexus, a novel framework leveraging optimized in-context learning\n(ICL) of large language models (LLMs) for data-efficient CTI knowledge\nextraction and high-quality cybersecurity knowledge graph (CSKG) construction.\nUnlike existing methods, CTINexus requires neither extensive data nor parameter\ntuning and can adapt to various ontologies with minimal annotated examples.\nThis is achieved through: (1) a carefully designed automatic prompt\nconstruction strategy with optimal demonstration retrieval for extracting a\nwide range of cybersecurity entities and relations; (2) a hierarchical entity\nalignment technique that canonicalizes the extracted knowledge and removes\nredundancy; (3) an long-distance relation prediction technique to further\ncomplete the CSKG with missing links. Our extensive evaluations using 150\nreal-world CTI reports collected from 10 platforms demonstrate that CTINexus\nsignificantly outperforms existing methods in constructing accurate and\ncomplete CSKG, highlighting its potential to transform CTI analysis with an\nefficient and adaptable solution for the dynamic threat landscape.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at 2025 IEEE European Symposium on Security and Privacy\n  (Euro S&P)",
    "pdf_url": "http://arxiv.org/pdf/2410.21060v2",
    "published_date": "2024-10-28 14:18:32 UTC",
    "updated_date": "2025-04-21 14:37:40 UTC"
  },
  {
    "arxiv_id": "2410.21052v3",
    "title": "Getting By Goal Misgeneralization With a Little Help From a Mentor",
    "authors": [
      "Tu Trinh",
      "Mohamad H. Danesh",
      "Nguyen X. Khanh",
      "Benjamin Plaut"
    ],
    "abstract": "While reinforcement learning (RL) agents often perform well during training,\nthey can struggle with distribution shift in real-world deployments. One\nparticularly severe risk of distribution shift is goal misgeneralization, where\nthe agent learns a proxy goal that coincides with the true goal during training\nbut not during deployment. In this paper, we explore whether allowing an agent\nto ask for help from a supervisor in unfamiliar situations can mitigate this\nissue. We focus on agents trained with PPO in the CoinRun environment, a\nsetting known to exhibit goal misgeneralization. We evaluate multiple methods\nfor determining when the agent should request help and find that asking for\nhelp consistently improves performance. However, we also find that methods\nbased on the agent's internal state fail to proactively request help, instead\nwaiting until mistakes have already occurred. Further investigation suggests\nthat the agent's internal state does not represent the coin at all,\nhighlighting the importance of learning nuanced representations, the risks of\nignoring everything not immediately relevant to reward, and the necessity of\ndeveloping ask-for-help strategies tailored to the agent's training algorithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "SATA Workshop @ NeurIPS 2024 (Towards Safe and Trustworthy Agents)",
    "pdf_url": "http://arxiv.org/pdf/2410.21052v3",
    "published_date": "2024-10-28 14:07:41 UTC",
    "updated_date": "2024-11-10 05:36:32 UTC"
  },
  {
    "arxiv_id": "2411.08040v1",
    "title": "The Universal PDDL Domain",
    "authors": [
      "Patrik Haslum",
      "Augusto B. Corrêa"
    ],
    "abstract": "In AI planning, it is common to distinguish between planning domains and\nproblem instances, where a \"domain\" is generally understood as a set of related\nproblem instances. This distinction is important, for example, in generalised\nplanning, which aims to find a single, general plan or policy that solves all\ninstances of a given domain. In PDDL, domains and problem instances are clearly\nseparated: the domain defines the types, predicate symbols, and action\nschemata, while the problem instance specifies the concrete set of (typed)\nobjects, the initial state, and the goal condition. In this paper, we show that\nit is quite easy to define a PDDL domain such that any propositional planning\nproblem instance, from any domain, becomes an instance of this (lifted)\n\"universal\" domain. We construct different formulations of the universal\ndomain, and discuss their implications for the complexity of lifted\ndomain-dependent or generalised planning.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08040v1",
    "published_date": "2024-10-28 14:02:21 UTC",
    "updated_date": "2024-10-28 14:02:21 UTC"
  },
  {
    "arxiv_id": "2410.21043v1",
    "title": "Disentangled and Self-Explainable Node Representation Learning",
    "authors": [
      "Simone Piaggesi",
      "André Panisson",
      "Megha Khosla"
    ],
    "abstract": "Node representations, or embeddings, are low-dimensional vectors that capture\nnode properties, typically learned through unsupervised structural similarity\nobjectives or supervised tasks. While recent efforts have focused on explaining\ngraph model decisions, the interpretability of unsupervised node embeddings\nremains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled\nand Self-Explainable Node Embedding), a framework that generates\nself-explainable embeddings in an unsupervised manner. Our method employs\ndisentangled representation learning to produce dimension-wise interpretable\nembeddings, where each dimension is aligned with distinct topological structure\nof the graph. We formalize novel desiderata for disentangled and interpretable\nembeddings, which drive our new objective functions, optimizing simultaneously\nfor both interpretability and disentanglement. Additionally, we propose several\nnew metrics to evaluate representation quality and human interpretability.\nExtensive experiments across multiple benchmark datasets demonstrate the\neffectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21043v1",
    "published_date": "2024-10-28 13:58:52 UTC",
    "updated_date": "2024-10-28 13:58:52 UTC"
  },
  {
    "arxiv_id": "2410.21029v1",
    "title": "FairStream: Fair Multimedia Streaming Benchmark for Reinforcement Learning Agents",
    "authors": [
      "Jannis Weil",
      "Jonas Ringsdorf",
      "Julian Barthel",
      "Yi-Ping Phoebe Chen",
      "Tobias Meuser"
    ],
    "abstract": "Multimedia streaming accounts for the majority of traffic in today's\ninternet. Mechanisms like adaptive bitrate streaming control the bitrate of a\nstream based on the estimated bandwidth, ideally resulting in smooth playback\nand a good Quality of Experience (QoE). However, selecting the optimal bitrate\nis challenging under volatile network conditions. This motivated researchers to\ntrain Reinforcement Learning (RL) agents for multimedia streaming. The\nconsidered training environments are often simplified, leading to promising\nresults with limited applicability. Additionally, the QoE fairness across\nmultiple streams is seldom considered by recent RL approaches. With this work,\nwe propose a novel multi-agent environment that comprises multiple challenges\nof fair multimedia streaming: partial observability, multiple objectives, agent\nheterogeneity and asynchronicity. We provide and analyze baseline approaches\nacross five different traffic classes to gain detailed insights into the\nbehavior of the considered agents, and show that the commonly used Proximal\nPolicy Optimization (PPO) algorithm is outperformed by a simple greedy\nheuristic. Future work includes the adaptation of multi-agent RL algorithms and\nfurther expansions of the environment.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21029v1",
    "published_date": "2024-10-28 13:51:03 UTC",
    "updated_date": "2024-10-28 13:51:03 UTC"
  },
  {
    "arxiv_id": "2410.21028v1",
    "title": "Graph Based Traffic Analysis and Delay Prediction",
    "authors": [
      "Gabriele Borg",
      "Charlie Abela"
    ],
    "abstract": "This research is focused on traffic congestion in the small island of Malta\nwhich is the most densely populated country in the EU with about 1,672\ninhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Malta\nhas a rapid vehicle growth. Based on our research, the number of vehicles\nincreased by around 11,000 in a little more than 6 months, which shows how\nimportant it is to have an accurate and comprehensive means of collecting data\nto tackle the issue of fluctuating traffic in Malta. In this paper, we first\npresent the newly built comprehensive traffic dataset, called MalTra. This\ndataset includes realistic trips made by members of the public across the\nisland over a period of 200 days. We then describe the methodology we adopted\nto generate syntactic data to complete our data set as much as possible. In our\nresearch, we consider both MalTra and the Q-Traffic dataset, which has been\nused in several other research studies. The statistical ARIMA model and two\ngraph neural networks, the spatial temporal graph convolutional network (STGCN)\nand the diffusion convolutional recurrent network (DCRNN) were used to analyse\nand compare the results with existing research. From the evaluation, we found\nthat the DCRNN model outperforms the STGCN with the former resulting in MAE of\n3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of the\nlatter).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21028v1",
    "published_date": "2024-10-28 13:50:00 UTC",
    "updated_date": "2024-10-28 13:50:00 UTC"
  },
  {
    "arxiv_id": "2411.02426v1",
    "title": "Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis",
    "authors": [
      "Somayeh Farahani",
      "Marjaneh Hejazi",
      "Mehnaz Tabassum",
      "Antonio Di Ieva",
      "Neda Mahdavifar",
      "Sidong Liu"
    ],
    "abstract": "Gliomas, the most common primary brain tumors, show high heterogeneity in\nhistological and molecular characteristics. Accurate molecular profiling, like\nisocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, is critical for\ndiagnosis, treatment, and prognosis. This review evaluates MRI-based deep\nlearning (DL) models' efficacy in predicting these biomarkers. Following PRISMA\nguidelines, we systematically searched major databases (PubMed, Scopus, Ovid,\nand Web of Science) up to February 2024, screening studies that utilized DL to\npredict IDH and 1p/19q codeletion status from MRI data of glioma patients. We\nassessed the quality and risk of bias using the radiomics quality score and\nQUADAS-2 tool. Our meta-analysis used a bivariate model to compute pooled\nsensitivity, specificity, and meta-regression to assess inter-study\nheterogeneity. Of the 565 articles, 57 were selected for qualitative synthesis,\nand 52 underwent meta-analysis. The pooled estimates showed high diagnostic\nperformance, with validation sensitivity, specificity, and area under the curve\n(AUC) of 0.84 [prediction interval (PI): 0.67-0.93, I2=51.10%, p < 0.05], 0.87\n[PI: 0.49-0.98, I2=82.30%, p < 0.05], and 0.89 for IDH prediction, and 0.76\n[PI: 0.28-0.96, I2=77.60%, p < 0.05], 0.85 [PI: 0.49-0.97, I2=80.30%, p <\n0.05], and 0.90 for 1p/19q prediction, respectively. Meta-regression analyses\nrevealed significant heterogeneity influenced by glioma grade, data source,\ninclusion of non-radiomics data, MRI sequences, segmentation and feature\nextraction methods, and validation techniques. DL models demonstrate strong\npotential in predicting molecular biomarkers from MRI scans, with significant\nvariability influenced by technical and clinical factors. Thorough external\nvalidation is necessary to increase clinical utility.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02426v1",
    "published_date": "2024-10-28 13:39:52 UTC",
    "updated_date": "2024-10-28 13:39:52 UTC"
  },
  {
    "arxiv_id": "2410.21014v1",
    "title": "Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems",
    "authors": [
      "Helen Schneider",
      "Sebastian Nowak",
      "Aditya Parikh",
      "Yannik C. Layer",
      "Maike Theis",
      "Wolfgang Block",
      "Alois M. Sprinkart",
      "Ulrike Attenberger",
      "Rafet Sifa"
    ],
    "abstract": "Image-based diagnostic decision support systems (DDSS) utilizing deep\nlearning have the potential to optimize clinical workflows. However, developing\nDDSS requires extensive datasets with expert annotations and is therefore\ncostly. Leveraging report contents from radiological data bases with Natural\nLanguage Processing to annotate the corresponding image data promises to\nreplace labor-intensive manual annotation. As mining \"real world\" databases can\nintroduce label noise, noise-robust training losses are of great interest.\nHowever, current noise-robust losses do not consider noise estimations that can\nfor example be derived based on the performance of the automatic label\ngenerator used. In this study, we expand the noise-robust Deep Abstaining\nClassifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by\nincorporating noise level estimations during training. Our findings demonstrate\nthat IDAC enhances the noise robustness compared to DAC and several\nstate-of-the-art loss functions. The results are obtained on various simulated\nnoise levels using a public chest X-ray data set. These findings are reproduced\non an in-house noisy data set, where labels were extracted from the clinical\nsystems of the University Hospital Bonn by a text-based transformer. The IDAC\ncan therefore be a valuable tool for researchers, companies or clinics aiming\nto develop accurate and reliable DDSS from routine clinical data.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This preprint has no post-submission improvements or corrections. The\n  Version of Record of this contribution is published in the Neural Information\n  Processing, ICONIP 2024 Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2410.21014v1",
    "published_date": "2024-10-28 13:36:57 UTC",
    "updated_date": "2024-10-28 13:36:57 UTC"
  },
  {
    "arxiv_id": "2410.21012v1",
    "title": "FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval",
    "authors": [
      "Jinlin Wang",
      "Suyuchen Wang",
      "Ziwen Xia",
      "Sirui Hong",
      "Yun Zhu",
      "Bang Liu",
      "Chenglin Wu"
    ],
    "abstract": "Large Language Models (LLMs) are proficient at retrieving single facts from\nextended contexts, yet they struggle with tasks requiring the simultaneous\nretrieval of multiple facts, especially during generation. This paper\nidentifies a novel \"lost-in-the-middle\" phenomenon, where LLMs progressively\nlose track of critical information throughout the generation process, resulting\nin incomplete or inaccurate retrieval. To address this challenge, we introduce\nFind All Crucial Texts (FACT), an iterative retrieval method that refines\ncontext through successive rounds of rewriting. This approach enables models to\ncapture essential facts incrementally, which are often overlooked in\nsingle-pass retrieval. Experiments demonstrate that FACT substantially enhances\nmulti-fact retrieval performance across various tasks, though improvements are\nless notable in general-purpose QA scenarios. Our findings shed light on the\nlimitations of LLMs in multi-fact retrieval and underscore the need for more\nresilient long-context retrieval strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2410.21012v1",
    "published_date": "2024-10-28 13:36:41 UTC",
    "updated_date": "2024-10-28 13:36:41 UTC"
  },
  {
    "arxiv_id": "2411.00818v2",
    "title": "On the Black-box Explainability of Object Detection Models for Safe and Trustworthy Industrial Applications",
    "authors": [
      "Alain Andres",
      "Aitor Martinez-Seras",
      "Ibai Laña",
      "Javier Del Ser"
    ],
    "abstract": "In the realm of human-machine interaction, artificial intelligence has become\na powerful tool for accelerating data modeling tasks. Object detection methods\nhave achieved outstanding results and are widely used in critical domains like\nautonomous driving and video surveillance. However, their adoption in high-risk\napplications, where errors may cause severe consequences, remains limited.\nExplainable Artificial Intelligence methods aim to address this issue, but many\nexisting techniques are model-specific and designed for classification tasks,\nmaking them less effective for object detection and difficult for\nnon-specialists to interpret. In this work we focus on model-agnostic\nexplainability methods for object detection models and propose D-MFPP, an\nextension of the Morphological Fragmental Perturbation Pyramid (MFPP) technique\nbased on segmentation-based masks to generate explanations. Additionally, we\nintroduce D-Deletion, a novel metric combining faithfulness and localization,\nadapted specifically to meet the unique demands of object detectors. We\nevaluate these methods on real-world industrial and robotic datasets, examining\nthe influence of parameters such as the number of masks, model size, and image\nresolution on the quality of explanations. Our experiments use single-stage\nobject detection models applied to two safety-critical robotic environments: i)\na shared human-robot workspace where safety is of paramount importance, and ii)\nan assembly area of battery kits, where safety is critical due to the potential\nfor damage among high-risk components. Our findings evince that D-Deletion\neffectively gauges the performance of explanations when multiple elements of\nthe same class appear in a scene, while D-MFPP provides a promising alternative\nto D-RISE when fewer masks are used.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 10 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.00818v2",
    "published_date": "2024-10-28 13:28:05 UTC",
    "updated_date": "2024-11-28 08:09:26 UTC"
  },
  {
    "arxiv_id": "2410.21000v3",
    "title": "Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering",
    "authors": [
      "Zhilin Zhang",
      "Jie Wang",
      "Zhanghao Qin",
      "Ruiqi Zhu",
      "Xiaoliang Gong"
    ],
    "abstract": "Medical Visual Question Answering (MedVQA) has attracted growing interest at\nthe intersection of medical image understanding and natural language processing\nfor clinical applications. By interpreting medical images and providing precise\nanswers to relevant clinical inquiries, MedVQA has the potential to support\ndiagnostic decision-making and reduce workload across various fields like\nradiology. While recent approaches rely heavily on unified large pre-trained\nVisual-Language Models, research on more efficient fusion mechanisms remains\nrelatively limited in this domain. In this paper, we introduce a fusion model,\nOMniBAN, that integrates Orthogonality loss, Multi-head attention, and a\nBilinear Attention Network to achieve high computational efficiency as well as\nsolid performance. We conduct comprehensive experiments and demonstrate how\nbilinear attention fusion can approximate the performance of larger fusion\nmodels like cross-modal Transformer. Our results show that OMniBAN requires\nfewer parameters (approximately 2/3 of Transformer-based Co-Attention) and\nsubstantially lower FLOPs (approximately 1/4), while achieving comparable\noverall performance and even slight improvements on closed-ended questions on\ntwo key MedVQA benchmarks. This balance between efficiency and accuracy\nsuggests that OMniBAN could be a viable option for real-world medical image\nquestion answering, where computational resources are often constrained.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "To be published in 2025 International Joint Conference on Neural\n  Networks (IJCNN)",
    "pdf_url": "http://arxiv.org/pdf/2410.21000v3",
    "published_date": "2024-10-28 13:24:12 UTC",
    "updated_date": "2025-05-11 14:45:34 UTC"
  },
  {
    "arxiv_id": "2410.21351v1",
    "title": "LinFormer: A Linear-based Lightweight Transformer Architecture For Time-Aware MIMO Channel Prediction",
    "authors": [
      "Yanliang Jin",
      "Yifan Wu",
      "Yuan Gao",
      "Shunqing Zhang",
      "Shugong Xu",
      "Cheng-Xiang Wang"
    ],
    "abstract": "The emergence of 6th generation (6G) mobile networks brings new challenges in\nsupporting high-mobility communications, particularly in addressing the issue\nof channel aging. While existing channel prediction methods offer improved\naccuracy at the expense of increased computational complexity, limiting their\npractical application in mobile networks. To address these challenges, we\npresent LinFormer, an innovative channel prediction framework based on a\nscalable, all-linear, encoder-only Transformer model. Our approach, inspired by\nnatural language processing (NLP) models such as BERT, adapts an encoder-only\narchitecture specifically for channel prediction tasks. We propose replacing\nthe computationally intensive attention mechanism commonly used in Transformers\nwith a time-aware multi-layer perceptron (TMLP), significantly reducing\ncomputational demands. The inherent time awareness of TMLP module makes it\nparticularly suitable for channel prediction tasks. We enhance LinFormer's\ntraining process by employing a weighted mean squared error loss (WMSELoss)\nfunction and data augmentation techniques, leveraging larger, readily available\ncommunication datasets. Our approach achieves a substantial reduction in\ncomputational complexity while maintaining high prediction accuracy, making it\nmore suitable for deployment in cost-effective base stations (BS).\nComprehensive experiments using both simulated and measured data demonstrate\nthat LinFormer outperforms existing methods across various mobility scenarios,\noffering a promising solution for future wireless communication systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21351v1",
    "published_date": "2024-10-28 13:04:23 UTC",
    "updated_date": "2024-10-28 13:04:23 UTC"
  },
  {
    "arxiv_id": "2410.20981v3",
    "title": "EEG-Driven 3D Object Reconstruction with Style Consistency and Diffusion Prior",
    "authors": [
      "Xin Xiang",
      "Wenhui Zhou",
      "Guojun Dai"
    ],
    "abstract": "Electroencephalography (EEG)-based visual perception reconstruction has\nbecome an important area of research. Neuroscientific studies indicate that\nhumans can decode imagined 3D objects by perceiving or imagining various visual\ninformation, such as color, shape, and rotation. Existing EEG-based visual\ndecoding methods typically focus only on the reconstruction of 2D visual\nstimulus images and face various challenges in generation quality, including\ninconsistencies in texture, shape, and color between the visual stimuli and the\nreconstructed images. This paper proposes an EEG-based 3D object reconstruction\nmethod with style consistency and diffusion priors. The method consists of an\nEEG-driven multi-task joint learning stage and an EEG-to-3D diffusion stage.\nThe first stage uses a neural EEG encoder based on regional semantic learning,\nemploying a multi-task joint learning scheme that includes a masked EEG signal\nrecovery task and an EEG based visual classification task. The second stage\nintroduces a latent diffusion model (LDM) fine-tuning strategy with\nstyle-conditioned constraints and a neural radiance field (NeRF) optimization\nstrategy. This strategy explicitly embeds semantic- and location-aware latent\nEEG codes and combines them with visual stimulus maps to fine-tune the LDM. The\nfine-tuned LDM serves as a diffusion prior, which, combined with the style loss\nof visual stimuli, is used to optimize NeRF for generating 3D objects. Finally,\nthrough experimental validation, we demonstrate that this method can\neffectively use EEG data to reconstruct 3D objects with style consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20981v3",
    "published_date": "2024-10-28 12:59:24 UTC",
    "updated_date": "2024-11-16 04:08:36 UTC"
  },
  {
    "arxiv_id": "2410.20975v1",
    "title": "Geo-FuB: A Method for Constructing an Operator-Function Knowledge Base for Geospatial Code Generation Tasks Using Large Language Models",
    "authors": [
      "Shuyang Hou",
      "Anqi Zhao",
      "Jianyuan Liang",
      "Zhangxiao Shen",
      "Huayi Wu"
    ],
    "abstract": "The rise of spatiotemporal data and the need for efficient geospatial\nmodeling have spurred interest in automating these tasks with large language\nmodels (LLMs). However, general LLMs often generate errors in geospatial code\ndue to a lack of domain-specific knowledge on functions and operators. To\naddress this, a retrieval-augmented generation (RAG) approach, utilizing an\nexternal knowledge base of geospatial functions and operators, is proposed.\nThis study introduces a framework to construct such a knowledge base,\nleveraging geospatial script semantics. The framework includes: Function\nSemantic Framework Construction (Geo-FuSE), Frequent Operator Combination\nStatistics (Geo-FuST), and Semantic Mapping (Geo-FuM). Techniques like\nChain-of-Thought, TF-IDF, and the APRIORI algorithm are utilized to derive and\nalign geospatial functions. An example knowledge base, Geo-FuB, built from\n154,075 Google Earth Engine scripts, is available on GitHub. Evaluation metrics\nshow a high accuracy, reaching 88.89% overall, with structural and semantic\naccuracies of 92.03% and 86.79% respectively. Geo-FuB's potential to optimize\ngeospatial code generation through the RAG and fine-tuning paradigms is\nhighlighted.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20975v1",
    "published_date": "2024-10-28 12:50:27 UTC",
    "updated_date": "2024-10-28 12:50:27 UTC"
  },
  {
    "arxiv_id": "2410.20971v2",
    "title": "BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks",
    "authors": [
      "Yunhan Zhao",
      "Xiang Zheng",
      "Lin Luo",
      "Yige Li",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "abstract": "In this paper, we focus on black-box defense for VLMs against jailbreak\nattacks. Existing black-box defense methods are either unimodal or bimodal.\nUnimodal methods enhance either the vision or language module of the VLM, while\nbimodal methods robustify the model through text-image representation\nrealignment. However, these methods suffer from two limitations: 1) they fail\nto fully exploit the cross-modal information, or 2) they degrade the model\nperformance on benign inputs. To address these limitations, we propose a novel\nblue-team method BlueSuffix that defends target VLMs against jailbreak attacks\nwithout compromising its performance under black-box setting. BlueSuffix\nincludes three key components: 1) a visual purifier against jailbreak images,\n2) a textual purifier against jailbreak texts, and 3) a blue-team suffix\ngenerator using reinforcement fine-tuning for enhancing cross-modal robustness.\nWe empirically show on four VLMs (LLaVA, MiniGPT-4, InstructionBLIP, and\nGemini) and four safety benchmarks (Harmful Instruction, AdvBench,\nMM-SafetyBench, and RedTeam-2K) that BlueSuffix outperforms the baseline\ndefenses by a significant margin. Our BlueSuffix opens up a promising direction\nfor defending VLMs against jailbreak attacks. Code is available at\nhttps://github.com/Vinsonzyh/BlueSuffix.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20971v2",
    "published_date": "2024-10-28 12:43:47 UTC",
    "updated_date": "2025-02-12 05:52:11 UTC"
  },
  {
    "arxiv_id": "2410.20966v1",
    "title": "Improving Detection of Person Class Using Dense Pooling",
    "authors": [
      "Nouman Ahmad"
    ],
    "abstract": "Lately, the continuous development of deep learning models by many\nresearchers in the area of computer vision has attracted more researchers to\nfurther improve the accuracy of these models. FasterRCNN [32] has already\nprovided a state-of-the-art approach to improve the accuracy and detection of\n80 different objects given in the COCO dataset. To further improve the\nperformance of person detection we have conducted a different approach which\ngives the state-of-the-art conclusion. An ROI is a step in FasterRCNN that\nextract the features from the given image with a fixed size and transfer into\nfor further classification. To enhance the ROI performance, we have conducted\nan approach that implements dense pooling and converts the image into a 3D\nmodel to further transform into UV(ultra Violet) images which makes it easy to\nextract the right features from the images. To implement our approach we have\napproached the state-of-the-art COCO datasets and extracted 6982 images that\ninclude a person object and our final achievements conclude that using our\napproach has made significant results in detecting the person object in the\ngiven image",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20966v1",
    "published_date": "2024-10-28 12:36:28 UTC",
    "updated_date": "2024-10-28 12:36:28 UTC"
  },
  {
    "arxiv_id": "2410.20964v1",
    "title": "DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning",
    "authors": [
      "Xun Guo",
      "Shan Zhang",
      "Yongxin He",
      "Ting Zhang",
      "Wanquan Feng",
      "Haibin Huang",
      "Chongyang Ma"
    ],
    "abstract": "Current techniques for detecting AI-generated text are largely confined to\nmanual feature crafting and supervised binary classification paradigms. These\nmethodologies typically lead to performance bottlenecks and unsatisfactory\ngeneralizability. Consequently, these methods are often inapplicable for\nout-of-distribution (OOD) data and newly emerged large language models (LLMs).\nIn this paper, we revisit the task of AI-generated text detection. We argue\nthat the key to accomplishing this task lies in distinguishing writing styles\nof different authors, rather than simply classifying the text into\nhuman-written or AI-generated text. To this end, we propose DeTeCtive, a\nmulti-task auxiliary, multi-level contrastive learning framework. DeTeCtive is\ndesigned to facilitate the learning of distinct writing styles, combined with a\ndense information retrieval pipeline for AI-generated text detection. Our\nmethod is compatible with a range of text encoders. Extensive experiments\ndemonstrate that our method enhances the ability of various text encoders in\ndetecting AI-generated text across multiple benchmarks and achieves\nstate-of-the-art results. Notably, in OOD zero-shot evaluation, our method\noutperforms existing approaches by a large margin. Moreover, we find our method\nboasts a Training-Free Incremental Adaptation (TFIA) capability towards OOD\ndata, further enhancing its efficacy in OOD detection scenarios. We will\nopen-source our code and models in hopes that our work will spark new thoughts\nin the field of AI-generated text detection, ensuring safe application of LLMs\nand enhancing compliance. Our code is available at\nhttps://github.com/heyongxin233/DeTeCtive.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in NeurIPS 2024. Code is available at\n  https://github.com/heyongxin233/DeTeCtive",
    "pdf_url": "http://arxiv.org/pdf/2410.20964v1",
    "published_date": "2024-10-28 12:34:49 UTC",
    "updated_date": "2024-10-28 12:34:49 UTC"
  },
  {
    "arxiv_id": "2410.20957v1",
    "title": "Neuro-symbolic Learning Yielding Logical Constraints",
    "authors": [
      "Zenan Li",
      "Yunpeng Huang",
      "Zhaoyu Li",
      "Yuan Yao",
      "Jingwei Xu",
      "Taolue Chen",
      "Xiaoxing Ma",
      "Jian Lu"
    ],
    "abstract": "Neuro-symbolic systems combine the abilities of neural perception and logical\nreasoning. However, end-to-end learning of neuro-symbolic systems is still an\nunsolved challenge. This paper proposes a natural framework that fuses neural\nnetwork training, symbol grounding, and logical constraint synthesis into a\ncoherent and efficient end-to-end learning process. The capability of this\nframework comes from the improved interactions between the neural and the\nsymbolic parts of the system in both the training and inference stages.\nTechnically, to bridge the gap between the continuous neural network and the\ndiscrete logical constraint, we introduce a difference-of-convex programming\ntechnique to relax the logical constraints while maintaining their precision.\nWe also employ cardinality constraints as the language for logical constraint\nlearning and incorporate a trust region method to avoid the degeneracy of\nlogical constraint in learning. Both theoretical analyses and empirical\nevaluations substantiate the effectiveness of the proposed framework.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at NeurIPS 2023, and code is\n  available at [this url](https://github.com/Lizn-zn/Nesy-Programming)",
    "pdf_url": "http://arxiv.org/pdf/2410.20957v1",
    "published_date": "2024-10-28 12:18:25 UTC",
    "updated_date": "2024-10-28 12:18:25 UTC"
  },
  {
    "arxiv_id": "2410.21349v4",
    "title": "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system",
    "authors": [
      "Zeyuan Li",
      "Yangfan He",
      "Lewei He",
      "Jianhui Wang",
      "Tianyu Shi",
      "Bin Lei",
      "Yuchen Li",
      "Qiuwu Chen"
    ],
    "abstract": "Recently, large language models (LLMs) have achieved significant progress in\nautomated code generation. Despite their strong instruction-following\ncapabilities, these models frequently struggled to align with user intent in\ncoding scenarios. In particular, they were hampered by datasets that lacked\ndiversity and failed to address specialized tasks or edge cases. Furthermore,\nchallenges in supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) led to failures in generating precise,\nhuman-intent-aligned code. To tackle these challenges and improve the code\ngeneration performance for automated programming systems, we propose\nFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization\n(i.e., FALCON). FALCON is structured into two hierarchical levels. From the\nglobal level, long-term memory improves code quality by retaining and applying\nlearned knowledge. At the local level, short-term memory allows for the\nincorporation of immediate feedback from compilers and AI systems.\nAdditionally, we introduce meta-reinforcement learning with feedback rewards to\nsolve the global-local bi-level optimization problem and enhance the model's\nadaptability across diverse code generation tasks. Extensive experiments\ndemonstrate that our technique achieves state-of-the-art performance, leading\nother reinforcement learning methods by more than 4.5 percentage points on the\nMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The\nopen-sourced code is publicly available at https://github.com/titurte/FALCON.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21349v4",
    "published_date": "2024-10-28 12:18:22 UTC",
    "updated_date": "2025-03-23 17:12:25 UTC"
  },
  {
    "arxiv_id": "2410.20954v1",
    "title": "Active Legibility in Multiagent Reinforcement Learning",
    "authors": [
      "Yanyu Liu",
      "Yinghui Pan",
      "Yifeng Zeng",
      "Biyang Ma",
      "Doshi Prashant"
    ],
    "abstract": "A multiagent sequential decision problem has been seen in many critical\napplications including urban transportation, autonomous driving cars, military\noperations, etc. Its widely known solution, namely multiagent reinforcement\nlearning, has evolved tremendously in recent years. Among them, the solution\nparadigm of modeling other agents attracts our interest, which is different\nfrom traditional value decomposition or communication mechanisms. It enables\nagents to understand and anticipate others' behaviors and facilitates their\ncollaboration. Inspired by recent research on the legibility that allows agents\nto reveal their intentions through their behavior, we propose a multiagent\nactive legibility framework to improve their performance. The\nlegibility-oriented framework allows agents to conduct legible actions so as to\nhelp others optimise their behaviors. In addition, we design a series of\nproblem domains that emulate a common scenario and best characterize the\nlegibility in multiagent reinforcement learning. The experimental results\ndemonstrate that the new framework is more efficient and costs less training\ntime compared to several multiagent reinforcement learning algorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20954v1",
    "published_date": "2024-10-28 12:15:49 UTC",
    "updated_date": "2024-10-28 12:15:49 UTC"
  },
  {
    "arxiv_id": "2410.20941v4",
    "title": "Fine-Grained and Multi-Dimensional Metrics for Document-Level Machine Translation",
    "authors": [
      "Yirong Sun",
      "Dawei Zhu",
      "Yanjun Chen",
      "Erjia Xiao",
      "Xinghao Chen",
      "Xiaoyu Shen"
    ],
    "abstract": "Large language models (LLMs) have excelled in various NLP tasks, including\nmachine translation (MT), yet most studies focus on sentence-level translation.\nThis work investigates the inherent capability of instruction-tuned LLMs for\ndocument-level translation (docMT). Unlike prior approaches that require\nspecialized techniques, we evaluate LLMs by directly prompting them to\ntranslate entire documents in a single pass. Our results show that this method\nimproves translation quality compared to translating sentences separately, even\nwithout document-level fine-tuning. However, this advantage is not reflected in\nBLEU scores, which often favor sentence-based translations. We propose using\nthe LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess\ndocument coherence, accuracy, and fluency in a more nuanced way than\nn-gram-based metrics. Overall, our work demonstrates that instruction-tuned\nLLMs can effectively leverage document context for translation. However, we\ncaution against using BLEU scores for evaluating docMT, as they often provide\nmisleading outcomes, failing to capture the quality of document-level\ntranslation. Code and the outputs from GPT4-as-a-judge are available at\nhttps://github.com/EIT-NLP/BLEUless_DocMT",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 Student Research Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.20941v4",
    "published_date": "2024-10-28 11:49:58 UTC",
    "updated_date": "2025-04-20 12:03:36 UTC"
  },
  {
    "arxiv_id": "2410.21348v2",
    "title": "Large Language Model Benchmarks in Medical Tasks",
    "authors": [
      "Lawrence K. Q. Yan",
      "Qian Niu",
      "Ming Li",
      "Yichao Zhang",
      "Caitlyn Heqi Yin",
      "Cheng Fei",
      "Benji Peng",
      "Ziqian Bi",
      "Pohsun Feng",
      "Keyu Chen",
      "Tianyang Wang",
      "Yunze Wang",
      "Silin Chen",
      "Ming Liu",
      "Junyu Liu"
    ],
    "abstract": "With the increasing application of large language models (LLMs) in the\nmedical domain, evaluating these models' performance using benchmark datasets\nhas become crucial. This paper presents a comprehensive survey of various\nbenchmark datasets employed in medical LLM tasks. These datasets span multiple\nmodalities including text, image, and multimodal benchmarks, focusing on\ndifferent aspects of medical knowledge such as electronic health records\n(EHRs), doctor-patient dialogues, medical question-answering, and medical image\ncaptioning. The survey categorizes the datasets by modality, discussing their\nsignificance, data structure, and impact on the development of LLMs for\nclinical tasks such as diagnosis, report generation, and predictive decision\nsupport. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and\nCheXpert, which have facilitated advancements in tasks like medical report\ngeneration, clinical summarization, and synthetic data generation. The paper\nsummarizes the challenges and opportunities in leveraging these benchmarks for\nadvancing multimodal medical intelligence, emphasizing the need for datasets\nwith a greater degree of language diversity, structured omics data, and\ninnovative approaches to synthesis. This work also provides a foundation for\nfuture research in the application of LLMs in medicine, contributing to the\nevolving field of medical artificial intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21348v2",
    "published_date": "2024-10-28 11:07:33 UTC",
    "updated_date": "2024-12-09 10:11:22 UTC"
  },
  {
    "arxiv_id": "2410.20922v2",
    "title": "FACTS: A Factored State-Space Framework For World Modelling",
    "authors": [
      "Li Nanbo",
      "Firas Laakom",
      "Yucheng Xu",
      "Wenyi Wang",
      "Jürgen Schmidhuber"
    ],
    "abstract": "World modelling is essential for understanding and predicting the dynamics of\ncomplex systems by learning both spatial and temporal dependencies. However,\ncurrent frameworks, such as Transformers and selective state-space models like\nMambas, exhibit limitations in efficiently encoding spatial and temporal\nstructures, particularly in scenarios requiring long-term high-dimensional\nsequence modelling. To address these issues, we propose a novel recurrent\nframework, the \\textbf{FACT}ored \\textbf{S}tate-space (\\textbf{FACTS}) model,\nfor spatial-temporal world modelling. The FACTS framework constructs a\ngraph-structured memory with a routing mechanism that learns permutable memory\nrepresentations, ensuring invariance to input permutations while adapting\nthrough selective state-space propagation. Furthermore, FACTS supports parallel\ncomputation of high-dimensional sequences. We empirically evaluate FACTS across\ndiverse tasks, including multivariate time series forecasting, object-centric\nworld modelling, and spatial-temporal graph prediction, demonstrating that it\nconsistently outperforms or matches specialised state-of-the-art models,\ndespite its general-purpose world modelling design.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Code released in https://github.com/NanboLi/FACTS",
    "pdf_url": "http://arxiv.org/pdf/2410.20922v2",
    "published_date": "2024-10-28 11:04:42 UTC",
    "updated_date": "2025-02-28 08:20:18 UTC"
  },
  {
    "arxiv_id": "2410.20911v2",
    "title": "Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks",
    "authors": [
      "Dario Pasquini",
      "Evgenios M. Kornaropoulos",
      "Giuseppe Ateniese"
    ],
    "abstract": "Large language models (LLMs) are increasingly being harnessed to automate\ncyberattacks, making sophisticated exploits more accessible and scalable. In\nresponse, we propose a new defense strategy tailored to counter LLM-driven\ncyberattacks. We introduce Mantis, a defensive framework that exploits LLMs'\nsusceptibility to adversarial inputs to undermine malicious operations. Upon\ndetecting an automated cyberattack, Mantis plants carefully crafted inputs into\nsystem responses, leading the attacker's LLM to disrupt their own operations\n(passive defense) or even compromise the attacker's machine (active defense).\nBy deploying purposefully vulnerable decoy services to attract the attacker and\nusing dynamic prompt injections for the attacker's LLM, Mantis can autonomously\nhack back the attacker. In our experiments, Mantis consistently achieved over\n95% effectiveness against automated LLM-driven attacks. To foster further\nresearch and collaboration, Mantis is available as an open-source tool:\nhttps://github.com/pasquini-dario/project_mantis",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "v0.2 (evaluated on more agents)",
    "pdf_url": "http://arxiv.org/pdf/2410.20911v2",
    "published_date": "2024-10-28 10:43:34 UTC",
    "updated_date": "2024-11-18 09:15:46 UTC"
  },
  {
    "arxiv_id": "2410.20898v2",
    "title": "Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models",
    "authors": [
      "Weijian Luo",
      "Colin Zhang",
      "Debing Zhang",
      "Zhengyang Geng"
    ],
    "abstract": "In this paper, we introduce the Diff-Instruct* (DI*), an image data-free\napproach for building one-step text-to-image generative models that align with\nhuman preference while maintaining the ability to generate highly realistic\nimages. We frame human preference alignment as online reinforcement learning\nusing human feedback (RLHF), where the goal is to maximize the reward function\nwhile regularizing the generator distribution to remain close to a reference\ndiffusion process. Unlike traditional RLHF approaches, which rely on the KL\ndivergence for regularization, we introduce a novel score-based divergence\nregularization, which leads to significantly better performances. Although the\ndirect calculation of this preference alignment objective remains intractable,\nwe demonstrate that we can efficiently compute its gradient by deriving an\nequivalent yet tractable loss function. Remarkably, we used Diff-Instruct* to\ntrain a Stable Diffusion-XL-based 1-step model, the 2.6B DI*-SDXL-1step\ntext-to-image model, which can generate images of a resolution of 1024x1024\nwith only 1 generation step. DI*-SDXL-1step model uses only 1.88% inference\ntime and 29.30% GPU memory cost to outperform 12B FLUX-dev-50step significantly\nin PickScore, ImageReward, and CLIPScore on Parti prompt benchmark and HPSv2.1\non Human Preference Score benchmark, establishing a new state-of-the-art\nbenchmark of human-preferred 1-step text-to-image generative models. Besides\nthe strong quantitative performances, extensive qualitative comparisons also\nconfirm the advantages of DI* in terms of maintaining diversity, improving\nimage layouts, and enhancing aesthetic colors. We have released our\nindustry-ready model on the homepage:\n\\url{https://github.com/pkulwj1994/diff_instruct_star}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "revision: 2.6B 1-step text-to-image model outperforms 12B\n  Flux-dev-50step model in human preferences",
    "pdf_url": "http://arxiv.org/pdf/2410.20898v2",
    "published_date": "2024-10-28 10:26:19 UTC",
    "updated_date": "2024-12-24 05:22:40 UTC"
  },
  {
    "arxiv_id": "2410.20894v1",
    "title": "Active Causal Structure Learning with Latent Variables: Towards Learning to Detour in Autonomous Robots",
    "authors": [
      "Pablo de los Riscos",
      "Fernando Corbacho"
    ],
    "abstract": "Artificial General Intelligence (AGI) Agents and Robots must be able to cope\nwith everchanging environments and tasks. They must be able to actively\nconstruct new internal causal models of their interactions with the environment\nwhen new structural changes take place in the environment. Thus, we claim that\nactive causal structure learning with latent variables (ACSLWL) is a necessary\ncomponent to build AGI agents and robots. This paper describes how a complex\nplanning and expectation-based detour behavior can be learned by ACSLWL when,\nunexpectedly, and for the first time, the simulated robot encounters a sort of\ntransparent barrier in its pathway towards its target. ACSWL consists of acting\nin the environment, discovering new causal relations, constructing new causal\nmodels, exploiting the causal models to maximize its expected utility,\ndetecting possible latent variables when unexpected observations occur, and\nconstructing new structures-internal causal models and optimal estimation of\nthe associated parameters, to be able to cope efficiently with the new\nencountered situations. That is, the agent must be able to construct new causal\ninternal models that transform a previously unexpected and inefficient\n(sub-optimal) situation, into a predictable situation with an optimal operating\nplan.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "44 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20894v1",
    "published_date": "2024-10-28 10:21:26 UTC",
    "updated_date": "2024-10-28 10:21:26 UTC"
  },
  {
    "arxiv_id": "2410.20873v1",
    "title": "Explainability in AI Based Applications: A Framework for Comparing Different Techniques",
    "authors": [
      "Arne Grobrugge",
      "Nidhi Mishra",
      "Johannes Jakubik",
      "Gerhard Satzger"
    ],
    "abstract": "The integration of artificial intelligence into business processes has\nsignificantly enhanced decision-making capabilities across various industries\nsuch as finance, healthcare, and retail. However, explaining the decisions made\nby these AI systems poses a significant challenge due to the opaque nature of\nrecent deep learning models, which typically function as black boxes. To\naddress this opacity, a multitude of explainability techniques have emerged.\nHowever, in practical business applications, the challenge lies in selecting an\nappropriate explainability method that balances comprehensibility with\naccuracy. This paper addresses the practical need of understanding differences\nin the output of explainability techniques by proposing a novel method for the\nassessment of the agreement of different explainability techniques. Based on\nour proposed methods, we provide a comprehensive comparative analysis of six\nleading explainability techniques to help guiding the selection of such\ntechniques in practice. Our proposed general-purpose method is evaluated on top\nof one of the most popular deep learning architectures, the Vision Transformer\nmodel, which is frequently employed in business applications. Notably, we\npropose a novel metric to measure the agreement of explainability techniques\nthat can be interpreted visually. By providing a practical framework for\nunderstanding the agreement of diverse explainability techniques, our research\naims to facilitate the broader integration of interpretable AI systems in\nbusiness applications.",
    "categories": [
      "cs.AI",
      "14J60 (Primary) 14F05, 14J26 (Secondary)",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20873v1",
    "published_date": "2024-10-28 09:45:34 UTC",
    "updated_date": "2024-10-28 09:45:34 UTC"
  },
  {
    "arxiv_id": "2411.05802v1",
    "title": "Similarity-based context aware continual learning for spiking neural networks",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yang Li",
      "Qingqun Kong",
      "Xianqi Li",
      "Yi Zeng"
    ],
    "abstract": "Biological brains have the capability to adaptively coordinate relevant\nneuronal populations based on the task context to learn continuously changing\ntasks in real-world environments. However, existing spiking neural\nnetwork-based continual learning algorithms treat each task equally, ignoring\nthe guiding role of different task similarity associations for network\nlearning, which limits knowledge utilization efficiency. Inspired by the\ncontext-dependent plasticity mechanism of the brain, we propose a\nSimilarity-based Context Aware Spiking Neural Network (SCA-SNN) continual\nlearning algorithm to efficiently accomplish task incremental learning and\nclass incremental learning. Based on contextual similarity across tasks, the\nSCA-SNN model can adaptively reuse neurons from previous tasks that are\nbeneficial for new tasks (the more similar, the more neurons are reused) and\nflexibly expand new neurons for the new task (the more similar, the fewer\nneurons are expanded). Selective reuse and discriminative expansion\nsignificantly improve the utilization of previous knowledge and reduce energy\nconsumption. Extensive experimental results on CIFAR100, ImageNet generalized\ndatasets, and FMNIST-MNIST, SVHN-CIFAR100 mixed datasets show that our SCA-SNN\nmodel achieves superior performance compared to both SNN-based and DNN-based\ncontinual learning algorithms. Additionally, our algorithm has the capability\nto adaptively select similar groups of neurons for related tasks, offering a\npromising approach to enhancing the biological interpretability of efficient\ncontinual learning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05802v1",
    "published_date": "2024-10-28 09:38:57 UTC",
    "updated_date": "2024-10-28 09:38:57 UTC"
  },
  {
    "arxiv_id": "2410.21346v1",
    "title": "Towards Trustworthy Machine Learning in Production: An Overview of the Robustness in MLOps Approach",
    "authors": [
      "Firas Bayram",
      "Bestoun S. Ahmed"
    ],
    "abstract": "Artificial intelligence (AI), and especially its sub-field of Machine\nLearning (ML), are impacting the daily lives of everyone with their ubiquitous\napplications. In recent years, AI researchers and practitioners have introduced\nprinciples and guidelines to build systems that make reliable and trustworthy\ndecisions. From a practical perspective, conventional ML systems process\nhistorical data to extract the features that are consequently used to train ML\nmodels that perform the desired task. However, in practice, a fundamental\nchallenge arises when the system needs to be operationalized and deployed to\nevolve and operate in real-life environments continuously. To address this\nchallenge, Machine Learning Operations (MLOps) have emerged as a potential\nrecipe for standardizing ML solutions in deployment. Although MLOps\ndemonstrated great success in streamlining ML processes, thoroughly defining\nthe specifications of robust MLOps approaches remains of great interest to\nresearchers and practitioners. In this paper, we provide a comprehensive\noverview of the trustworthiness property of MLOps systems. Specifically, we\nhighlight technical practices to achieve robust MLOps systems. In addition, we\nsurvey the existing research approaches that address the robustness aspects of\nML systems in production. We also review the tools and software available to\nbuild MLOps systems and summarize their support to handle the robustness\naspects. Finally, we present the open challenges and propose possible future\ndirections and opportunities within this emerging field. The aim of this paper\nis to provide researchers and practitioners working on practical AI\napplications with a comprehensive view to adopt robust ML solutions in\nproduction environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21346v1",
    "published_date": "2024-10-28 09:34:08 UTC",
    "updated_date": "2024-10-28 09:34:08 UTC"
  },
  {
    "arxiv_id": "2410.20856v2",
    "title": "Strada-LLM: Graph LLM for traffic prediction",
    "authors": [
      "Seyed Mohamad Moghadas",
      "Yangxintong Lyu",
      "Bruno Cornelis",
      "Alexandre Alahi",
      "Adrian Munteanu"
    ],
    "abstract": "Traffic prediction is a vital component of intelligent transportation\nsystems. By reasoning about traffic patterns in both the spatial and temporal\ndimensions, accurate and interpretable predictions can be provided. A\nconsiderable challenge in traffic prediction lies in handling the diverse data\ndistributions caused by vastly different traffic conditions occurring at\ndifferent locations. LLMs have been a dominant solution due to their remarkable\ncapacity to adapt to new datasets with very few labeled data samples, i.e.,\nfew-shot adaptability. However, existing forecasting techniques mainly focus on\nextracting local graph information and forming a text-like prompt, leaving LLM-\nbased traffic prediction an open problem. This work presents a probabilistic\nLLM for traffic forecasting with three highlights. We propose a graph-aware LLM\nfor traffic prediction that considers proximal traffic information.\nSpecifically, by considering the traffic of neighboring nodes as covariates,\nour model outperforms the corresponding time-series LLM. Furthermore, we adopt\na lightweight approach for efficient domain adaptation when facing new data\ndistributions in few-shot fashion. The comparative experiment demonstrates the\nproposed method outperforms the state-of-the-art LLM-based methods and the\ntraditional GNN- based supervised approaches. Furthermore, Strada-LLM can be\neasily adapted to different LLM backbones without a noticeable performance\ndrop.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The reviewers decided to reject it. After getting the reviews, we\n  wanted to study more.",
    "pdf_url": "http://arxiv.org/pdf/2410.20856v2",
    "published_date": "2024-10-28 09:19:29 UTC",
    "updated_date": "2025-02-14 16:09:49 UTC"
  },
  {
    "arxiv_id": "2410.20848v1",
    "title": "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms",
    "authors": [
      "He Yu",
      "Jing Liu"
    ],
    "abstract": "Designing optimization approaches, whether heuristic or meta-heuristic,\nusually demands extensive manual intervention and has difficulty generalizing\nacross diverse problem domains. The combination of Large Language Models (LLMs)\nand Evolutionary Algorithms (EAs) offers a promising new approach to overcome\nthese limitations and make optimization more automated. In this setup, LLMs act\nas dynamic agents that can generate, refine, and interpret optimization\nstrategies, while EAs efficiently explore complex solution spaces through\nevolutionary operators. Since this synergy enables a more efficient and\ncreative search process, we first conduct an extensive review of recent\nresearch on the application of LLMs in optimization. We focus on LLMs' dual\nfunctionality as solution generators and algorithm designers. Then, we\nsummarize the common and valuable designs in existing work and propose a novel\nLLM-EA paradigm for automated optimization. Furthermore, centered on this\nparadigm, we conduct an in-depth analysis of innovative methods for three key\ncomponents: individual representation, variation operators, and fitness\nevaluation. We address challenges related to heuristic generation and solution\nexploration, especially from the LLM prompts' perspective. Our systematic\nreview and thorough analysis of the paradigm can assist researchers in better\nunderstanding the current research and promoting the development of combining\nLLMs with EAs for automated optimization.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20848v1",
    "published_date": "2024-10-28 09:04:49 UTC",
    "updated_date": "2024-10-28 09:04:49 UTC"
  },
  {
    "arxiv_id": "2410.22365v1",
    "title": "Vascular Segmentation of Functional Ultrasound Images using Deep Learning",
    "authors": [
      "Hana Sebia",
      "Thomas Guyet",
      "Mickaël Pereira",
      "Marco Valdebenito",
      "Hugues Berry",
      "Benjamin Vidal"
    ],
    "abstract": "Segmentation of medical images is a fundamental task with numerous\napplications. While MRI, CT, and PET modalities have significantly benefited\nfrom deep learning segmentation techniques, more recent modalities, like\nfunctional ultrasound (fUS), have seen limited progress. fUS is a non invasive\nimaging method that measures changes in cerebral blood volume (CBV) with high\nspatio-temporal resolution. However, distinguishing arterioles from venules in\nfUS is challenging due to opposing blood flow directions within the same pixel.\nUltrasound localization microscopy (ULM) can enhance resolution by tracking\nmicrobubble contrast agents but is invasive, and lacks dynamic CBV\nquantification. In this paper, we introduce the first deep learning-based\nsegmentation tool for fUS images, capable of differentiating signals from\ndifferent vascular compartments, based on ULM automatic annotation and enabling\ndynamic CBV quantification. We evaluate various UNet architectures on fUS\nimages of rat brains, achieving competitive segmentation performance, with 90%\naccuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames\nfrom a fUS stack. These results are comparable to those from tubular structure\nsegmentation in other imaging modalities. Additionally, models trained on\nresting-state data generalize well to images captured during visual\nstimulation, highlighting robustness. This work offers a non-invasive,\ncost-effective alternative to ULM, enhancing fUS data interpretation and\nimproving understanding of vessel function. Our pipeline shows high linear\ncorrelation coefficients between signals from predicted and actual compartments\nin both cortical and deeperregions, showcasing its ability to accurately\ncapture blood flow dynamics.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22365v1",
    "published_date": "2024-10-28 09:00:28 UTC",
    "updated_date": "2024-10-28 09:00:28 UTC"
  },
  {
    "arxiv_id": "2410.20843v1",
    "title": "Generative Simulations of The Solar Corona Evolution With Denoising Diffusion : Proof of Concept",
    "authors": [
      "Grégoire Francisco",
      "Francesco Pio Ramunno",
      "Manolis K. Georgoulis",
      "João Fernandes",
      "Teresa Barata",
      "Dario Del Moro"
    ],
    "abstract": "The solar magnetized corona is responsible for various manifestations with a\nspace weather impact, such as flares, coronal mass ejections (CMEs) and,\nnaturally, the solar wind. Modeling the corona's dynamics and evolution is\ntherefore critical for improving our ability to predict space weather In this\nwork, we demonstrate that generative deep learning methods, such as Denoising\nDiffusion Probabilistic Models (DDPM), can be successfully applied to simulate\nfuture evolutions of the corona as observed in Extreme Ultraviolet (EUV)\nwavelengths. Our model takes a 12-hour video of an Active Region (AR) as input\nand simulate the potential evolution of the AR over the subsequent 12 hours,\nwith a time-resolution of two hours. We propose a light UNet backbone\narchitecture adapted to our problem by adding 1D temporal convolutions after\neach classical 2D spatial ones, and spatio-temporal attention in the bottleneck\npart. The model not only produce visually realistic outputs but also captures\nthe inherent stochasticity of the system's evolution. Notably, the simulations\nenable the generation of reliable confidence intervals for key predictive\nmetrics such as the EUV peak flux and fluence of the ARs, paving the way for\nprobabilistic and interpretable space weather forecasting. Future studies will\nfocus on shorter forecasting horizons with increased spatial and temporal\nresolution, aiming at reducing the uncertainty of the simulations and providing\npractical applications for space weather forecasting. The code used for this\nstudy is available at the following link:\nhttps://github.com/gfrancisco20/video_diffusion",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20843v1",
    "published_date": "2024-10-28 08:55:33 UTC",
    "updated_date": "2024-10-28 08:55:33 UTC"
  },
  {
    "arxiv_id": "2410.20825v1",
    "title": "ADLM -- stega: A Universal Adaptive Token Selection Algorithm for Improving Steganographic Text Quality via Information Entropy",
    "authors": [
      "Zezheng Qin",
      "Congcong Sun",
      "Taiyi He",
      "Yuke He",
      "Azizol Abdullah",
      "Normalia Samian",
      "Nuur Alifah Roslan"
    ],
    "abstract": "In the context of widespread global information sharing, information security\nand privacy protection have become focal points. Steganographic systems enhance\ninformation security by embedding confidential information into public\ncarriers; however, existing generative text steganography methods face\nchallenges in handling the long-tail distribution of candidate word pools,\nwhich impacts the imperceptibility of steganographic information. This paper\nproposes a quality control theory for steganographic text generation based on\ninformation entropy constraints, exploring the relationship between the\nimperceptibility of steganographic texts and information entropy. By\ncontrolling the information entropy of the candidate word pool within a\nspecific range, we optimize the imperceptibility of the steganographic text. We\nestablish upper and lower bounds for information entropy and introduce an\nadaptive truncation method to balance semantic coherence and lexical diversity.\nExperimental results demonstrate that reasonably controlling the candidate pool\nsize and information entropy thresholds significantly enhances the quality and\ndetection resistance of steganographic texts, showcasing broad application\npotential in the field of natural language processing.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20825v1",
    "published_date": "2024-10-28 08:25:31 UTC",
    "updated_date": "2024-10-28 08:25:31 UTC"
  },
  {
    "arxiv_id": "2411.00816v3",
    "title": "CycleResearcher: Improving Automated Research via Automated Review",
    "authors": [
      "Yixuan Weng",
      "Minjun Zhu",
      "Guangsheng Bao",
      "Hongbo Zhang",
      "Jindong Wang",
      "Yue Zhang",
      "Linyi Yang"
    ],
    "abstract": "The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accept in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2411.00816v3",
    "published_date": "2024-10-28 08:10:21 UTC",
    "updated_date": "2025-03-08 14:01:34 UTC"
  },
  {
    "arxiv_id": "2410.20811v2",
    "title": "Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation",
    "authors": [
      "Jaechang Kim",
      "Jinmin Goh",
      "Inseok Hwang",
      "Jaewoong Cho",
      "Jungseul Ok"
    ],
    "abstract": "Deep learning-based expert models have reached superhuman performance in\ndecision-making domains such as chess and Go. However, it is under-explored to\nexplain or comment on given decisions although it is important for model\nexplainability and human education. The outputs of expert models are accurate,\nbut yet difficult to interpret for humans. On the other hand, large language\nmodels (LLMs) can produce fluent commentary but are prone to hallucinations due\nto their limited decision-making capabilities. To bridge this gap between\nexpert models and LLMs, we focus on chess commentary as a representative task\nof explaining complex decision-making processes through language and address\nboth the generation and evaluation of commentary. We introduce Concept-guided\nChess Commentary generation (CCC) for producing commentary and GPT-based Chess\nCommentary Evaluation (GCC-Eval) for assessing it. CCC integrates the\ndecision-making strengths of expert models with the linguistic fluency of LLMs\nthrough prioritized, concept-based explanations. GCC-Eval leverages expert\nknowledge to evaluate chess commentary based on informativeness and linguistic\nquality. Experimental results, validated by both human judges and GCC-Eval,\ndemonstrate that CCC generates commentary which is accurate, informative, and\nfluent.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Appears in NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.20811v2",
    "published_date": "2024-10-28 07:59:34 UTC",
    "updated_date": "2025-02-08 08:28:23 UTC"
  },
  {
    "arxiv_id": "2410.20791v2",
    "title": "From Cool Demos to Production-Ready FMware: Core Challenges and a Technology Roadmap",
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Gustavo A. Oliva",
      "Dayi Lin",
      "Ahmed E. Hassan"
    ],
    "abstract": "The rapid expansion of foundation models (FMs), such as large language models\n(LLMs), has given rise to FMware--software systems that integrate FMs as core\ncomponents. While building demonstration-level FMware is relatively\nstraightforward, transitioning to production-ready systems presents numerous\nchallenges, including reliability, high implementation costs, scalability, and\ncompliance with privacy regulations. Our paper conducts a semi-structured\nthematic synthesis to identify the key challenges in productionizing FMware\nacross diverse data sources including our own industry experience in developing\nFMArts--a FMware lifecycle engineering platform and integrating it into Huawei\ncloud, grey literature, academic publications, hands-on involvement in the Open\nPlatform for Enterprise AI (OPEA), organizing the AIware conference and\nBootcamp, and co-leading the ISO SPDX SBOM working group on AI and datasets. We\nidentify critical issues in FM selection, data and model alignment, prompt\nengineering, agent orchestration, system testing, and deployment, alongside\ncross-cutting concerns such as memory management, observability, and feedback\nintegration. We discuss needed technologies and strategies to address these\nchallenges and offer guidance on how to enable the transition from\ndemonstration systems to scalable, production-ready FMware solutions. Our\nfindings underscore the importance of continued research and multi-industry\ncollaboration to advance the development of production-ready FMware.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20791v2",
    "published_date": "2024-10-28 07:16:00 UTC",
    "updated_date": "2025-01-27 17:05:55 UTC"
  },
  {
    "arxiv_id": "2410.21345v1",
    "title": "Absorb & Escape: Overcoming Single Model Limitations in Generating Genomic Sequences",
    "authors": [
      "Zehui Li",
      "Yuhao Ni",
      "Guoxuan Xia",
      "William Beardall",
      "Akashaditya Das",
      "Guy-Bart Stan",
      "Yiren Zhao"
    ],
    "abstract": "Abstract Recent advances in immunology and synthetic biology have accelerated\nthe development of deep generative methods for DNA sequence design. Two\ndominant approaches in this field are AutoRegressive (AR) models and Diffusion\nModels (DMs). However, genomic sequences are functionally heterogeneous,\nconsisting of multiple connected regions (e.g., Promoter Regions, Exons, and\nIntrons) where elements within each region come from the same probability\ndistribution, but the overall sequence is non-homogeneous. This heterogeneous\nnature presents challenges for a single model to accurately generate genomic\nsequences. In this paper, we analyze the properties of AR models and DMs in\nheterogeneous genomic sequence generation, pointing out crucial limitations in\nboth methods: (i) AR models capture the underlying distribution of data by\nfactorizing and learning the transition probability but fail to capture the\nglobal property of DNA sequences. (ii) DMs learn to recover the global\ndistribution but tend to produce errors at the base pair level. To overcome the\nlimitations of both approaches, we propose a post-training sampling method,\ntermed Absorb & Escape (A&E) to perform compositional generation from AR models\nand DMs. This approach starts with samples generated by DMs and refines the\nsample quality using an AR model through the alternation of the Absorb and\nEscape steps. To assess the quality of generated sequences, we conduct\nextensive experiments on 15 species for conditional and unconditional DNA\ngeneration. The experiment results from motif distribution, diversity checks,\nand genome integration tests unequivocally show that A&E outperforms\nstate-of-the-art AR models and DMs in genomic sequence generation.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21345v1",
    "published_date": "2024-10-28 07:00:27 UTC",
    "updated_date": "2024-10-28 07:00:27 UTC"
  },
  {
    "arxiv_id": "2410.20783v1",
    "title": "Graph-based Uncertainty Metrics for Long-form Language Model Outputs",
    "authors": [
      "Mingjian Jiang",
      "Yangjun Ruan",
      "Prasanna Sattigeri",
      "Salim Roukos",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved text generation capabilities, but these systems are still known to\nhallucinate, and granular uncertainty estimation for long-form LLM generations\nremains challenging. In this work, we propose Graph Uncertainty -- which\nrepresents the relationship between LLM generations and claims within them as a\nbipartite graph and estimates the claim-level uncertainty with a family of\ngraph centrality metrics. Under this view, existing uncertainty estimation\nmethods based on the concept of self-consistency can be viewed as using degree\ncentrality as an uncertainty measure, and we show that more sophisticated\nalternatives such as closeness centrality provide consistent gains at\nclaim-level uncertainty estimation. Moreover, we present uncertainty-aware\ndecoding techniques that leverage both the graph structure and uncertainty\nestimates to improve the factuality of LLM generations by preserving only the\nmost reliable claims. Compared to existing methods, our graph-based uncertainty\nmetrics lead to an average of 6.8% relative gains on AUPRC across various\nlong-form generation settings, and our end-to-end system provides consistent\n2-4% gains in factuality over existing decoding techniques while significantly\nimproving the informativeness of generated responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a Spotlight paper at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20783v1",
    "published_date": "2024-10-28 06:47:25 UTC",
    "updated_date": "2024-10-28 06:47:25 UTC"
  },
  {
    "arxiv_id": "2411.08891v1",
    "title": "Calibrated Decision-Making through LLM-Assisted Retrieval",
    "authors": [
      "Chaeyun Jang",
      "Hyungi Lee",
      "Seanie Lee",
      "Juho Lee"
    ],
    "abstract": "Recently, large language models (LLMs) have been increasingly used to support\nvarious decision-making tasks, assisting humans in making informed decisions.\nHowever, when LLMs confidently provide incorrect information, it can lead\nhumans to make suboptimal decisions. To prevent LLMs from generating incorrect\ninformation on topics they are unsure of and to improve the accuracy of\ngenerated content, prior works have proposed Retrieval Augmented Generation\n(RAG), where external documents are referenced to generate responses. However,\ntraditional RAG methods focus only on retrieving documents most relevant to the\ninput query, without specifically aiming to ensure that the human user's\ndecisions are well-calibrated. To address this limitation, we propose a novel\nretrieval method called Calibrated Retrieval-Augmented Generation (CalibRAG),\nwhich ensures that decisions informed by the retrieved documents are\nwell-calibrated. Then we empirically validate that CalibRAG improves\ncalibration performance as well as accuracy, compared to other baselines across\nvarious datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08891v1",
    "published_date": "2024-10-28 06:41:05 UTC",
    "updated_date": "2024-10-28 06:41:05 UTC"
  },
  {
    "arxiv_id": "2410.20777v1",
    "title": "KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation",
    "authors": [
      "Rambod Azimi",
      "Rishav Rishav",
      "Marek Teichmann",
      "Samira Ebrahimi Kahou"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious downstream tasks. However, the high computational and memory\nrequirements of LLMs are a major bottleneck. To address this,\nparameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation\n(LoRA) have been proposed to reduce computational costs while ensuring minimal\nloss in performance. Additionally, knowledge distillation (KD) has been a\npopular choice for obtaining compact student models from teacher models. In\nthis work, we present KD-LoRA, a novel fine-tuning method that combines LoRA\nwith KD. Our results demonstrate that KD-LoRA achieves performance comparable\nto full fine-tuning (FFT) and LoRA while significantly reducing resource\nrequirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the\nGLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU\nmemory usage by 30% compared to LoRA, while decreasing inference time by 30%\ncompared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only\nmodels: BERT, RoBERTa, and DeBERTaV3. Code is available at\nhttps://github.com/rambodazimi/KD-LoRA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 4th NeurIPS Efficient Natural Language and Speech\n  Processing Workshop (ENLSP-IV 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.20777v1",
    "published_date": "2024-10-28 06:38:24 UTC",
    "updated_date": "2024-10-28 06:38:24 UTC"
  },
  {
    "arxiv_id": "2410.20772v3",
    "title": "Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting",
    "authors": [
      "Bong Gyun Kang",
      "Dongjun Lee",
      "HyunGi Kim",
      "DoHyun Chung",
      "Sungroh Yoon"
    ],
    "abstract": "Sequence modeling faces challenges in capturing long-range dependencies\nacross diverse tasks. Recent linear and transformer-based forecasters have\nshown superior performance in time series forecasting. However, they are\nconstrained by their inherent inability to effectively address long-range\ndependencies in time series data, primarily due to using fixed-size inputs for\nprediction. Furthermore, they typically sacrifice essential temporal\ncorrelation among consecutive training samples by shuffling them into\nmini-batches. To overcome these limitations, we introduce a fast and effective\nSpectral Attention mechanism, which preserves temporal correlations among\nsamples and facilitates the handling of long-range information while\nmaintaining the base model structure. Spectral Attention preserves long-period\ntrends through a low-pass filter and facilitates gradient to flow between\nsamples. Spectral Attention can be seamlessly integrated into most sequence\nmodels, allowing models with fixed-sized look-back windows to capture\nlong-range dependencies over thousands of steps. Through extensive experiments\non 11 real-world time series datasets using 7 recent forecasting models, we\nconsistently demonstrate the efficacy of our Spectral Attention mechanism,\nachieving state-of-the-art results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Co-first Author: Bong Gyun Kang, Dongjun Lee. NeurIPS 2024\n  (Conference on Neural Information Processing Systems)",
    "pdf_url": "http://arxiv.org/pdf/2410.20772v3",
    "published_date": "2024-10-28 06:17:20 UTC",
    "updated_date": "2024-11-22 01:41:37 UTC"
  },
  {
    "arxiv_id": "2410.20771v3",
    "title": "MrT5: Dynamic Token Merging for Efficient Byte-level Language Models",
    "authors": [
      "Julie Kallini",
      "Shikhar Murty",
      "Christopher D. Manning",
      "Christopher Potts",
      "Róbert Csordás"
    ],
    "abstract": "Models that rely on subword tokenization have significant drawbacks, such as\nsensitivity to character-level noise like spelling errors and inconsistent\ncompression rates across different languages and scripts. While character- or\nbyte-level models like ByT5 attempt to address these concerns, they have not\ngained widespread adoption -- processing raw byte streams without tokenization\nresults in significantly longer sequence lengths, making training and inference\ninefficient. This work introduces MrT5 (MergeT5), a more efficient variant of\nByT5 that integrates a token deletion mechanism in its encoder to dynamically\nshorten the input sequence length. After processing through a fixed number of\nencoder layers, a learned delete gate determines which tokens are to be removed\nand which are to be retained for subsequent layers. MrT5 effectively \"merges\"\ncritical information from deleted tokens into a more compact sequence,\nleveraging contextual information from the remaining tokens. In continued\npre-training experiments, we find that MrT5 can achieve significant gains in\ninference runtime with minimal effect on performance, as measured by\nbits-per-byte. Additionally, with multilingual training, MrT5 adapts to the\northographic characteristics of each language, learning language-specific\ncompression rates. Furthermore, MrT5 shows comparable accuracy to ByT5 on\ndownstream evaluations such as XNLI, TyDi QA, and character-level tasks while\nreducing sequence lengths by up to 75%. Our approach presents a solution to the\npractical limitations of existing byte-level models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20771v3",
    "published_date": "2024-10-28 06:14:12 UTC",
    "updated_date": "2025-04-02 03:23:02 UTC"
  },
  {
    "arxiv_id": "2410.20766v1",
    "title": "A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation",
    "authors": [
      "Wei-Nan Zhang",
      "Yiming Cui",
      "Kaiyan Zhang",
      "Yifa Wang",
      "Qingfu Zhu",
      "Lingzhi Li",
      "Ting Liu"
    ],
    "abstract": "Recently, research on open domain dialogue systems have attracted extensive\ninterests of academic and industrial researchers. The goal of an open domain\ndialogue system is to imitate humans in conversations. Previous works on single\nturn conversation generation have greatly promoted the research of open domain\ndialogue systems. However, understanding multiple single turn conversations is\nnot equal to the understanding of multi turn dialogue due to the coherent and\ncontext dependent properties of human dialogue. Therefore, in open domain multi\nturn dialogue generation, it is essential to modeling the contextual semantics\nof the dialogue history, rather than only according to the last utterance.\nPrevious research had verified the effectiveness of the hierarchical recurrent\nencoder-decoder framework on open domain multi turn dialogue generation.\nHowever, using RNN-based model to hierarchically encoding the utterances to\nobtain the representation of dialogue history still face the problem of a\nvanishing gradient. To address this issue, in this paper, we proposed a static\nand dynamic attention-based approach to model the dialogue history and then\ngenerate open domain multi turn dialogue responses. Experimental results on\nUbuntu and Opensubtitles datasets verify the effectiveness of the proposed\nstatic and dynamic attention-based approach on automatic and human evaluation\nmetrics in various experimental settings. Meanwhile, we also empirically verify\nthe performance of combining the static and dynamic attentions on open domain\nmulti turn dialogue generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "published as a journal paper at ACM Transactions on Information\n  Systems 2023. 30 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20766v1",
    "published_date": "2024-10-28 06:05:34 UTC",
    "updated_date": "2024-10-28 06:05:34 UTC"
  },
  {
    "arxiv_id": "2411.08890v1",
    "title": "Spotlight Session on Autonomous Weapons Systems at ICRC 34th International Conference",
    "authors": [
      "Susannah Kate Conroy"
    ],
    "abstract": "Autonomous weapons systems (AWS) change the way humans make decisions, the\neffect of those decisions and who is accountable for decisions made. We must\nremain vigilant, informed and human-centred as we tackle our deliberations on\ndeveloping norms regarding their development, use and justification. Ways to\nenhance compliance in international humanitarian law (IHL) include: Training\nweapons decision makers in IHL; developing best practice in weapons reviews\nincluding requirements for industry to ensure that any new weapon, means or\nmethod of warfare is capable of being used lawfully; develop human-centred test\nand evaluation methods; invest in digital infrastructure to increase knowledge\nof the civilian environment in a conflict and its dynamics; invest in research\non the real effects and consequences of civilian harms to the achievement of\nmilitary and political objectives; improve secure communications between\nstakeholders in a conflict; and finally to upskill governments and NGOs in what\nis technically achievable with emerging technologies so that they can\ncontribute to system requirements, test and evaluation protocols and\noperational rules of use and engagement. Governments are responsible for\nsetting requirements for weapons systems. They are responsible for driving\nethicality as well as lethality. Governments can require systems to be made and\nused to better protect civilians and protected objects. The UN can advocate for\ncompliance with IHL, human rights, human-centred use of weapons systems and\nimproved mechanisms to monitor and trace military decision making including\nthose decisions affected by autonomous functionality.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "8 pages, 2415 words, 1 figure. Panelist notes for the Spotlight\n  Session on Autonomous Weapons Systems at the ICRC 34th International\n  Conference 28-31 Oct 2024",
    "pdf_url": "http://arxiv.org/pdf/2411.08890v1",
    "published_date": "2024-10-28 05:36:41 UTC",
    "updated_date": "2024-10-28 05:36:41 UTC"
  },
  {
    "arxiv_id": "2410.20750v1",
    "title": "ODRL: A Benchmark for Off-Dynamics Reinforcement Learning",
    "authors": [
      "Jiafei Lyu",
      "Kang Xu",
      "Jiacheng Xu",
      "Mengbei Yan",
      "Jingwen Yang",
      "Zongzhang Zhang",
      "Chenjia Bai",
      "Zongqing Lu",
      "Xiu Li"
    ],
    "abstract": "We consider off-dynamics reinforcement learning (RL) where one needs to\ntransfer policies across different domains with dynamics mismatch. Despite the\nfocus on developing dynamics-aware algorithms, this field is hindered due to\nthe lack of a standard benchmark. To bridge this gap, we introduce ODRL, the\nfirst benchmark tailored for evaluating off-dynamics RL methods. ODRL contains\nfour experimental settings where the source and target domains can be either\nonline or offline, and provides diverse tasks and a broad spectrum of dynamics\nshifts, making it a reliable platform to comprehensively evaluate the agent's\nadaptation ability to the target domain. Furthermore, ODRL includes recent\noff-dynamics RL algorithms in a unified framework and introduces some extra\nbaselines for different settings, all implemented in a single-file manner. To\nunpack the true adaptation capability of existing methods, we conduct extensive\nbenchmarking experiments, which show that no method has universal advantages\nacross varied dynamics shifts. We hope this benchmark can serve as a\ncornerstone for future research endeavors. Our code is publicly available at\nhttps://github.com/OffDynamicsRL/off-dynamics-rl.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 D&B Track",
    "pdf_url": "http://arxiv.org/pdf/2410.20750v1",
    "published_date": "2024-10-28 05:29:38 UTC",
    "updated_date": "2024-10-28 05:29:38 UTC"
  },
  {
    "arxiv_id": "2410.20749v1",
    "title": "Matryoshka: Learning to Drive Black-Box LLMs with LLMs",
    "authors": [
      "Changhao Li",
      "Yuchen Zhuang",
      "Rushi Qiang",
      "Haotian Sun",
      "Hanjun Dai",
      "Chao Zhang",
      "Bo Dai"
    ],
    "abstract": "Despite the impressive generative abilities of black-box large language\nmodels (LLMs), their inherent opacity hinders further advancements in\ncapabilities such as reasoning, planning, and personalization. Existing works\naim to enhance LLM capabilities via domain-specific adaptation or in-context\nlearning, which require additional training on accessible model parameters, an\ninfeasible option for black-box LLMs. To address this challenge, we introduce\nMatryoshika, a lightweight white-box LLM controller that guides a large-scale\nblack-box LLM generator by decomposing complex tasks into a series of\nintermediate outputs. Specifically, we consider the black-box LLM as an\nenvironment, with Matryoshika serving as a policy to provide intermediate\nguidance through prompts for driving the black-box LLM. Matryoshika is trained\nto pivot the outputs of the black-box LLM aligning with preferences during\niterative interaction, which enables controllable multi-turn generation and\nself-improvement in optimizing intermediate guidance. Empirical evaluations on\nthree diverse tasks demonstrate that Matryoshika effectively enhances the\ncapabilities of black-box LLMs in complex, long-horizon tasks, including\nreasoning, planning, and personalization. By leveraging this pioneering\ncontroller-generator framework to mitigate dependence on model parameters,\nMatryoshika provides a transparent and practical solution for improving\nblack-box LLMs through controllable multi-turn generation using white-box LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2410.20749v1",
    "published_date": "2024-10-28 05:28:51 UTC",
    "updated_date": "2024-10-28 05:28:51 UTC"
  },
  {
    "arxiv_id": "2410.20745v2",
    "title": "Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models",
    "authors": [
      "Yilun Jin",
      "Zheng Li",
      "Chenwei Zhang",
      "Tianyu Cao",
      "Yifan Gao",
      "Pratik Jayarao",
      "Mao Li",
      "Xin Liu",
      "Ritesh Sarkhel",
      "Xianfeng Tang",
      "Haodong Wang",
      "Zhengyang Wang",
      "Wenju Xu",
      "Jingfeng Yang",
      "Qingyu Yin",
      "Xian Li",
      "Priyanka Nigam",
      "Yi Xu",
      "Kai Chen",
      "Qiang Yang",
      "Meng Jiang",
      "Bing Yin"
    ],
    "abstract": "Online shopping is a complex multi-task, few-shot learning problem with a\nwide and evolving range of entities, relations, and tasks. However, existing\nmodels and benchmarks are commonly tailored to specific tasks, falling short of\ncapturing the full complexity of online shopping. Large Language Models (LLMs),\nwith their multi-task and few-shot learning abilities, have the potential to\nprofoundly transform online shopping by alleviating task-specific engineering\nefforts and by providing users with interactive conversations. Despite the\npotential, LLMs face unique challenges in online shopping, such as\ndomain-specific concepts, implicit knowledge, and heterogeneous user behaviors.\nMotivated by the potential and challenges, we propose Shopping MMLU, a diverse\nmulti-task online shopping benchmark derived from real-world Amazon data.\nShopping MMLU consists of 57 tasks covering 4 major shopping skills: concept\nunderstanding, knowledge reasoning, user behavior alignment, and\nmulti-linguality, and can thus comprehensively evaluate the abilities of LLMs\nas general shop assistants. With Shopping MMLU, we benchmark over 20 existing\nLLMs and uncover valuable insights about practices and prospects of building\nversatile LLM-based shop assistants. Shopping MMLU can be publicly accessed at\nhttps://github.com/KL4805/ShoppingMMLU. In addition, with Shopping MMLU, we\nhost a competition in KDD Cup 2024 with over 500 participating teams. The\nwinning solutions and the associated workshop can be accessed at our website\nhttps://amazon-kddcup24.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Datasets and Benchmarks Track Accepted. Modified typos\n  in Figure 9",
    "pdf_url": "http://arxiv.org/pdf/2410.20745v2",
    "published_date": "2024-10-28 05:25:47 UTC",
    "updated_date": "2024-10-31 12:54:46 UTC"
  },
  {
    "arxiv_id": "2410.20742v1",
    "title": "Mitigating Unauthorized Speech Synthesis for Voice Protection",
    "authors": [
      "Zhisheng Zhang",
      "Qianyi Yang",
      "Derui Wang",
      "Pengyang Huang",
      "Yuxin Cao",
      "Kai Ye",
      "Jie Hao"
    ],
    "abstract": "With just a few speech samples, it is possible to perfectly replicate a\nspeaker's voice in recent years, while malicious voice exploitation (e.g.,\ntelecom fraud for illegal financial gain) has brought huge hazards in our daily\nlives. Therefore, it is crucial to protect publicly accessible speech data that\ncontains sensitive information, such as personal voiceprints. Most previous\ndefense methods have focused on spoofing speaker verification systems in timbre\nsimilarity but the synthesized deepfake speech is still of high quality. In\nresponse to the rising hazards, we devise an effective, transferable, and\nrobust proactive protection technology named Pivotal Objective Perturbation\n(POP) that applies imperceptible error-minimizing noises on original speech\nsamples to prevent them from being effectively learned for text-to-speech (TTS)\nsynthesis models so that high-quality deepfake speeches cannot be generated. We\nconduct extensive experiments on state-of-the-art (SOTA) TTS models utilizing\nobjective and subjective metrics to comprehensively evaluate our proposed\nmethod. The experimental results demonstrate outstanding effectiveness and\ntransferability across various models. Compared to the speech unclarity score\nof 21.94% from voice synthesizers trained on samples without protection,\nPOP-protected samples significantly increase it to 127.31%. Moreover, our\nmethod shows robustness against noise reduction and data augmentation\ntechniques, thereby greatly reducing potential hazards.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ACM CCS Workshop (LAMPS) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20742v1",
    "published_date": "2024-10-28 05:16:37 UTC",
    "updated_date": "2024-10-28 05:16:37 UTC"
  },
  {
    "arxiv_id": "2410.20739v3",
    "title": "Gender Bias in LLM-generated Interview Responses",
    "authors": [
      "Haein Kong",
      "Yongsu Ahn",
      "Sangyub Lee",
      "Yunho Maeng"
    ],
    "abstract": "LLMs have emerged as a promising tool for assisting individuals in diverse\ntext-generation tasks, including job-related texts. However, LLM-generated\nanswers have been increasingly found to exhibit gender bias. This study\nevaluates three LLMs (GPT-3.5, GPT-4, Claude) to conduct a multifaceted audit\nof LLM-generated interview responses across models, question types, and jobs,\nand their alignment with two gender stereotypes. Our findings reveal that\ngender bias is consistent, and closely aligned with gender stereotypes and the\ndominance of jobs. Overall, this study contributes to the systematic\nexamination of gender bias in LLM-generated interview responses, highlighting\nthe need for a mindful approach to mitigate such biases in related\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurlIPS 2024, SoLaR workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.20739v3",
    "published_date": "2024-10-28 05:08:08 UTC",
    "updated_date": "2024-11-28 19:54:09 UTC"
  },
  {
    "arxiv_id": "2410.20735v1",
    "title": "Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs",
    "authors": [
      "Rino Saiga",
      "Kaede Shiga",
      "Yo Maruta",
      "Chie Inomoto",
      "Hiroshi Kajiwara",
      "Naoya Nakamura",
      "Yu Kakimoto",
      "Yoshiro Yamamoto",
      "Masahiro Yasutake",
      "Masayuki Uesugi",
      "Akihisa Takeuchi",
      "Kentaro Uesugi",
      "Yasuko Terada",
      "Yoshio Suzuki",
      "Viktor Nikitin",
      "Vincent De Andrade",
      "Francesco De Carlo",
      "Yuichi Yamashita",
      "Masanari Itokawa",
      "Soichiro Ide",
      "Kazutaka Ikeda",
      "Ryuta Mizutani"
    ],
    "abstract": "Mouse and human brains have different functions that depend on their neuronal\nnetworks. In this study, we analyzed nanometer-scale three-dimensional\nstructures of brain tissues of the mouse medial prefrontal cortex and compared\nthem with structures of the human anterior cingulate cortex. The obtained\nresults indicated that mouse neuronal somata are smaller and neurites are\nthinner than those of human neurons. These structural features allow mouse\nneurons to be integrated in the limited space of the brain, though thin\nneurites should suppress distal connections according to cable theory. We\nimplemented this mouse-mimetic constraint in convolutional layers of a\ngenerative adversarial network (GAN) and a denoising diffusion implicit model\n(DDIM), which were then subjected to image generation tasks using photo\ndatasets of cat faces, cheese, human faces, and birds. The mouse-mimetic GAN\noutperformed a standard GAN in the image generation task using the cat faces\nand cheese photo datasets, but underperformed for human faces and birds. The\nmouse-mimetic DDIM gave similar results, suggesting that the nature of the\ndatasets affected the results. Analyses of the four datasets indicated\ndifferences in their image entropy, which should influence the number of\nparameters required for image generation. The preferences of the mouse-mimetic\nAIs coincided with the impressions commonly associated with mice. The\nrelationship between the neuronal network and brain function should be\ninvestigated by implementing other biological findings in artificial neural\nnetworks.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "physics.bio-ph"
    ],
    "primary_category": "q-bio.NC",
    "comment": "41 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20735v1",
    "published_date": "2024-10-28 04:55:57 UTC",
    "updated_date": "2024-10-28 04:55:57 UTC"
  },
  {
    "arxiv_id": "2410.21342v1",
    "title": "Heterogeneous Interaction Modeling With Reduced Accumulated Error for Multi-Agent Trajectory Prediction",
    "authors": [
      "Siyuan Chen",
      "Jiahai Wang"
    ],
    "abstract": "Dynamical complex systems composed of interactive heterogeneous agents are\nprevalent in the world, including urban traffic systems and social networks.\nModeling the interactions among agents is the key to understanding and\npredicting the dynamics of the complex system, e.g., predicting the\ntrajectories of traffic participants in the city. Compared with interaction\nmodeling in homogeneous systems such as pedestrians in a crowded scene,\nheterogeneous interaction modeling is less explored. Worse still, the error\naccumulation problem becomes more severe since the interactions are more\ncomplex. To tackle the two problems, this paper proposes heterogeneous\ninteraction modeling with reduced accumulated error for multi-agent trajectory\nprediction. Based on the historical trajectories, our method infers the dynamic\ninteraction graphs among agents, featured by directed interacting relations and\ninteracting effects. A heterogeneous attention mechanism is defined on the\ninteraction graphs for aggregating the influence from heterogeneous neighbors\nto the target agent. To alleviate the error accumulation problem, this paper\nanalyzes the error sources from the spatial and temporal perspectives, and\nproposes to introduce the graph entropy and the mixup training strategy for\nreducing the two types of errors respectively. Our method is examined on three\nreal-world datasets containing heterogeneous agents, and the experimental\nresults validate the superiority of our method.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "20 pages, accepted by IEEE TNNLS",
    "pdf_url": "http://arxiv.org/pdf/2410.21342v1",
    "published_date": "2024-10-28 04:53:42 UTC",
    "updated_date": "2024-10-28 04:53:42 UTC"
  },
  {
    "arxiv_id": "2410.20733v1",
    "title": "SEG:Seeds-Enhanced Iterative Refinement Graph Neural Network for Entity Alignment",
    "authors": [
      "Wei Ai",
      "Yinghui Gao",
      "Jianbin Li",
      "Jiayi Du",
      "Tao Meng",
      "Yuntao Shou",
      "Keqin Li"
    ],
    "abstract": "Entity alignment is crucial for merging knowledge across knowledge graphs, as\nit matches entities with identical semantics. The standard method matches these\nentities based on their embedding similarities using semi-supervised learning.\nHowever, diverse data sources lead to non-isomorphic neighborhood structures\nfor aligned entities, complicating alignment, especially for less common and\nsparsely connected entities. This paper presents a soft label propagation\nframework that integrates multi-source data and iterative seed enhancement,\naddressing scalability challenges in handling extensive datasets where scale\ncomputing excels. The framework uses seeds for anchoring and selects optimal\nrelationship pairs to create soft labels rich in neighborhood features and\nsemantic relationship data. A bidirectional weighted joint loss function is\nimplemented, which reduces the distance between positive samples and\ndifferentially processes negative samples, taking into account the\nnon-isomorphic neighborhood structures. Our method outperforms existing\nsemi-supervised approaches, as evidenced by superior results on multiple\ndatasets, significantly improving the quality of entity alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20733v1",
    "published_date": "2024-10-28 04:50:46 UTC",
    "updated_date": "2024-10-28 04:50:46 UTC"
  },
  {
    "arxiv_id": "2410.20730v1",
    "title": "GPRec: Bi-level User Modeling for Deep Recommenders",
    "authors": [
      "Yejing Wang",
      "Dong Xu",
      "Xiangyu Zhao",
      "Zhiren Mao",
      "Peng Xiang",
      "Ling Yan",
      "Yao Hu",
      "Zijian Zhang",
      "Xuetao Wei",
      "Qidong Liu"
    ],
    "abstract": "GPRec explicitly categorizes users into groups in a learnable manner and\naligns them with corresponding group embeddings. We design the dual group\nembedding space to offer a diverse perspective on group preferences by\ncontrasting positive and negative patterns. On the individual level, GPRec\nidentifies personal preferences from ID-like features and refines the obtained\nindividual representations to be independent of group ones, thereby providing a\nrobust complement to the group-level modeling. We also present various\nstrategies for the flexible integration of GPRec into various DRS models.\nRigorous testing of GPRec on three public datasets has demonstrated significant\nimprovements in recommendation quality.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20730v1",
    "published_date": "2024-10-28 04:49:05 UTC",
    "updated_date": "2024-10-28 04:49:05 UTC"
  },
  {
    "arxiv_id": "2410.21341v1",
    "title": "Retrieval-Retro: Retrieval-based Inorganic Retrosynthesis with Expert Knowledge",
    "authors": [
      "Heewoong Noh",
      "Namkyeong Lee",
      "Gyoung S. Na",
      "Chanyoung Park"
    ],
    "abstract": "While inorganic retrosynthesis planning is essential in the field of chemical\nscience, the application of machine learning in this area has been notably less\nexplored compared to organic retrosynthesis planning. In this paper, we propose\nRetrieval-Retro for inorganic retrosynthesis planning, which implicitly\nextracts the precursor information of reference materials that are retrieved\nfrom the knowledge base regarding domain expertise in the field. Specifically,\ninstead of directly employing the precursor information of reference materials,\nwe propose implicitly extracting it with various attention layers, which\nenables the model to learn novel synthesis recipes more effectively. Moreover,\nduring retrieval, we consider the thermodynamic relationship between target\nmaterial and precursors, which is essential domain expertise in identifying the\nmost probable precursor set among various options. Extensive experiments\ndemonstrate the superiority of Retrieval-Retro in retrosynthesis planning,\nespecially in discovering novel synthesis recipes, which is crucial for\nmaterials discovery. The source code for Retrieval-Retro is available at\nhttps://github.com/HeewoongNoh/Retrieval-Retro.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21341v1",
    "published_date": "2024-10-28 04:37:08 UTC",
    "updated_date": "2024-10-28 04:37:08 UTC"
  },
  {
    "arxiv_id": "2410.21340v1",
    "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
    "authors": [
      "Yuzhe Yang",
      "Yipeng Du",
      "Ahmad Farhan",
      "Claudio Angione",
      "Yue Zhao",
      "Harry Yang",
      "Fielding Johnston",
      "James Buban",
      "Patrick Colangelo"
    ],
    "abstract": "The deployment of large-scale models, such as large language models (LLMs)\nand sophisticated image generation systems, incurs substantial costs due to\ntheir computational demands. To mitigate these costs and address challenges\nrelated to scalability and data security, there is a growing shift towards\ndecentralized systems for deploying such models. In these decentralized\nenvironments, efficient inference acceleration becomes crucial to manage\ncomputational resources effectively and enhance system responsiveness. In this\nwork, we address the challenge of selecting optimal acceleration methods in\ndecentralized systems by introducing a meta-learning-based framework. This\nframework automates the selection process by learning from historical\nperformance data of various acceleration techniques across different tasks.\nUnlike traditional methods that rely on random selection or expert intuition,\nour approach systematically identifies the best acceleration strategies based\non the specific characteristics of each task. We demonstrate that our\nmeta-learning framework not only streamlines the decision-making process but\nalso consistently outperforms conventional methods in terms of efficiency and\nperformance. Our results highlight the potential of meta-learning to\nrevolutionize inference acceleration in decentralized AI systems, offering a\npath towards more democratic and economically feasible artificial intelligence\nsolutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21340v1",
    "published_date": "2024-10-28 04:29:16 UTC",
    "updated_date": "2024-10-28 04:29:16 UTC"
  },
  {
    "arxiv_id": "2410.20711v2",
    "title": "Contextual Representation Anchor Network to Alleviate Selection Bias in Few-Shot Drug Discovery",
    "authors": [
      "Ruifeng Li",
      "Wei Liu",
      "Xiangxin Zhou",
      "Mingqian Li",
      "Qiang Zhang",
      "Hongyang Chen",
      "Xuemin Lin"
    ],
    "abstract": "In the drug discovery process, the low success rate of drug candidate\nscreening often leads to insufficient labeled data, causing the few-shot\nlearning problem in molecular property prediction. Existing methods for\nfew-shot molecular property prediction overlook the sample selection bias,\nwhich arises from non-random sample selection in chemical experiments. This\nbias in data representativeness leads to suboptimal performance. To overcome\nthis challenge, we present a novel method named contextual representation\nanchor Network (CRA), where an anchor refers to a cluster center of the\nrepresentations of molecules and serves as a bridge to transfer enriched\ncontextual knowledge into molecular representations and enhance their\nexpressiveness. CRA introduces a dual-augmentation mechanism that includes\ncontext augmentation, which dynamically retrieves analogous unlabeled molecules\nand captures their task-specific contextual knowledge to enhance the anchors,\nand anchor augmentation, which leverages the anchors to augment the molecular\nrepresentations. We evaluate our approach on the MoleculeNet and FS-Mol\nbenchmarks, as well as in domain transfer experiments. The results demonstrate\nthat CRA outperforms the state-of-the-art by 2.60% and 3.28% in AUC and\n$\\Delta$AUC-PR metrics, respectively, and exhibits superior generalization\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM",
      "68U07",
      "I.2.1"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.20711v2",
    "published_date": "2024-10-28 03:54:10 UTC",
    "updated_date": "2024-10-29 06:40:41 UTC"
  },
  {
    "arxiv_id": "2410.20710v1",
    "title": "Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models",
    "authors": [
      "Heerin Yang",
      "Sseung-won Hwang",
      "Jungmin So"
    ],
    "abstract": "Although pre-trained language models show good performance on various natural\nlanguage processing tasks, they often rely on non-causal features and patterns\nto determine the outcome. For natural language inference tasks, previous\nresults have shown that even a model trained on a large number of data fails to\nperform well on counterfactually revised data, indicating that the model is not\nrobustly learning the semantics of the classes. In this paper, we propose a\nmethod in which we use token-based and sentence-based augmentation methods to\ngenerate counterfactual sentence pairs that belong to each class, and apply\ncontrastive learning to help the model learn the difference between sentence\npairs of different classes with similar contexts. Evaluation results with\ncounterfactually-revised dataset and general NLI datasets show that the\nproposed method can improve the performance and robustness of the NLI model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted at INTERSPEECH 2023",
    "pdf_url": "http://arxiv.org/pdf/2410.20710v1",
    "published_date": "2024-10-28 03:43:25 UTC",
    "updated_date": "2024-10-28 03:43:25 UTC"
  },
  {
    "arxiv_id": "2411.08889v1",
    "title": "Multilingual Standalone Trustworthy Voice-Based Social Network for Disaster Situations",
    "authors": [
      "Majid Behravan",
      "Elham Mohammadrezaei",
      "Mohamed Azab",
      "Denis Gracanin"
    ],
    "abstract": "In disaster scenarios, effective communication is crucial, yet language\nbarriers often hinder timely and accurate information dissemination,\nexacerbating vulnerabilities and complicating response efforts. This paper\npresents a novel, multilingual, voice-based social network specifically\ndesigned to address these challenges. The proposed system integrates advanced\nartificial intelligence (AI) with blockchain technology to enable secure,\nasynchronous voice communication across multiple languages. The application\noperates independently of external servers, ensuring reliability even in\ncompromised environments by functioning offline through local networks. Key\nfeatures include AI-driven real-time translation of voice messages, ensuring\nseamless cross-linguistic communication, and blockchain-enabled storage for\nsecure, immutable records of all interactions, safeguarding message integrity.\nDesigned for cross-platform use, the system offers consistent performance\nacross devices, from mobile phones to desktops, making it highly adaptable in\ndiverse disaster situations. Evaluation metrics demonstrate high accuracy in\nspeech recognition and translation, low latency, and user satisfaction,\nvalidating the system's effectiveness in enhancing communication during crises.\nThis solution represents a significant advancement in disaster communication,\nbridging language gaps to support more inclusive and efficient emergency\nresponse.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "I.2.7; K.4.4"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication in IEEE UEMCON 2024, to appear in December\n  2024. 7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.08889v1",
    "published_date": "2024-10-28 03:24:37 UTC",
    "updated_date": "2024-10-28 03:24:37 UTC"
  },
  {
    "arxiv_id": "2411.05801v1",
    "title": "Do LLM Personas Dream of Bull Markets? Comparing Human and AI Investment Strategies Through the Lens of the Five-Factor Model",
    "authors": [
      "Harris Borman",
      "Anna Leontjeva",
      "Luiz Pizzato",
      "Max Kun Jiang",
      "Dan Jermyn"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated the ability to adopt a\npersonality and behave in a human-like manner. There is a large body of\nresearch that investigates the behavioural impacts of personality in less\nobvious areas such as investment attitudes or creative decision making. In this\nstudy, we investigated whether an LLM persona with a specific Big Five\npersonality profile would perform an investment task similarly to a human with\nthe same personality traits. We used a simulated investment task to determine\nif these results could be generalised into actual behaviours. In this simulated\nenvironment, our results show these personas produced meaningful behavioural\ndifferences in all assessed categories, with these behaviours generally being\nconsistent with expectations derived from human research. We found that LLMs\nare able to generalise traits into expected behaviours in three areas: learning\nstyle, impulsivity and risk appetite while environmental attitudes could not be\naccurately represented. In addition, we showed that LLMs produce behaviour that\nis more reflective of human behaviour in a simulation environment compared to a\nsurvey environment.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.CY",
      "q-fin.GN"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.05801v1",
    "published_date": "2024-10-28 02:50:41 UTC",
    "updated_date": "2024-10-28 02:50:41 UTC"
  },
  {
    "arxiv_id": "2411.08888v1",
    "title": "Exploring Capabilities of Time Series Foundation Models in Building Analytics",
    "authors": [
      "Xiachong Lin",
      "Arian Prabowo",
      "Imran Razzak",
      "Hao Xue",
      "Matthew Amos",
      "Sam Behrens",
      "Flora D. Salim"
    ],
    "abstract": "The growing integration of digitized infrastructure with Internet of Things\n(IoT) networks has transformed the management and optimization of building\nenergy consumption. By leveraging IoT-based monitoring systems, stakeholders\nsuch as building managers, energy suppliers, and policymakers can make\ndata-driven decisions to improve energy efficiency. However, accurate energy\nforecasting and analytics face persistent challenges, primarily due to the\ninherent physical constraints of buildings and the diverse, heterogeneous\nnature of IoT-generated data. In this study, we conduct a comprehensive\nbenchmarking of two publicly available IoT datasets, evaluating the performance\nof time series foundation models in the context of building energy analytics.\nOur analysis shows that single-modal models demonstrate significant promise in\novercoming the complexities of data variability and physical limitations in\nbuildings, with future work focusing on optimizing multi-modal models for\nsustainable energy management.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 1 figures, and 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2411.08888v1",
    "published_date": "2024-10-28 02:49:22 UTC",
    "updated_date": "2024-10-28 02:49:22 UTC"
  },
  {
    "arxiv_id": "2411.08887v1",
    "title": "Deep Learning-Based CKM Construction with Image Super-Resolution",
    "authors": [
      "Shiyu Wang",
      "Xiaoli Xu",
      "Yong Zeng"
    ],
    "abstract": "Channel knowledge map (CKM) is a novel technique for achieving environment\nawareness, and thereby improving the communication and sensing performance for\nwireless systems. A fundamental problem associated with CKM is how to construct\na complete CKM that provides channel knowledge for a large number of locations\nbased solely on sparse data measurements. This problem bears similarities to\nthe super-resolution (SR) problem in image processing. In this letter, we\npropose an effective deep learning-based CKM construction method that leverages\nthe image SR network known as SRResNet. Unlike most existing studies, our\napproach does not require any additional input beyond the sparsely measured\ndata. In addition to the conventional path loss map construction, our approach\ncan also be applied to construct channel angle maps (CAMs), thanks to the use\nof a new dataset called CKMImageNet. The numerical results demonstrate that our\nmethod outperforms interpolation-based methods such as nearest neighbour and\nbicubic interpolation, as well as the SRGAN method in CKM construction.\nFurthermore, only 1/16 of the locations need to be measured in order to achieve\na root mean square error (RMSE) of 1.1 dB in path loss.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.08887v1",
    "published_date": "2024-10-28 02:33:35 UTC",
    "updated_date": "2024-10-28 02:33:35 UTC"
  },
  {
    "arxiv_id": "2411.07050v1",
    "title": "FedCVD: The First Real-World Federated Learning Benchmark on Cardiovascular Disease Data",
    "authors": [
      "Yukun Zhang",
      "Guanzhong Chen",
      "Zenglin Xu",
      "Jianyong Wang",
      "Dun Zeng",
      "Junfan Li",
      "Jinghua Wang",
      "Yuan Qi",
      "Irwin King"
    ],
    "abstract": "Cardiovascular diseases (CVDs) are currently the leading cause of death\nworldwide, highlighting the critical need for early diagnosis and treatment.\nMachine learning (ML) methods can help diagnose CVDs early, but their\nperformance relies on access to substantial data with high quality. However,\nthe sensitive nature of healthcare data often restricts individual clinical\ninstitutions from sharing data to train sufficiently generalized and unbiased\nML models. Federated Learning (FL) is an emerging approach, which offers a\npromising solution by enabling collaborative model training across multiple\nparticipants without compromising the privacy of the individual data owners.\nHowever, to the best of our knowledge, there has been limited prior research\napplying FL to the cardiovascular disease domain. Moreover, existing FL\nbenchmarks and datasets are typically simulated and may fall short of\nreplicating the complexity of natural heterogeneity found in realistic datasets\nthat challenges current FL algorithms. To address these gaps, this paper\npresents the first real-world FL benchmark for cardiovascular disease\ndetection, named FedCVD. This benchmark comprises two major tasks:\nelectrocardiogram (ECG) classification and echocardiogram (ECHO) segmentation,\nbased on naturally scattered datasets constructed from the CVD data of seven\ninstitutions. Our extensive experiments on these datasets reveal that FL faces\nnew challenges with real-world non-IID and long-tail data. The code and\ndatasets of FedCVD are available https://github.com/SMILELab-FL/FedCVD.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.07050v1",
    "published_date": "2024-10-28 02:24:01 UTC",
    "updated_date": "2024-10-28 02:24:01 UTC"
  },
  {
    "arxiv_id": "2410.20666v2",
    "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments",
    "authors": [
      "Sangmim Song",
      "Sarath Kodagoda",
      "Amal Gunatilake",
      "Marc G. Carmichael",
      "Karthick Thiyagarajan",
      "Jodi Martin"
    ],
    "abstract": "Navigation presents a significant challenge for persons with visual\nimpairments (PVI). While traditional aids such as white canes and guide dogs\nare invaluable, they fall short in delivering detailed spatial information and\nprecise guidance to desired locations. Recent developments in large language\nmodels (LLMs) and vision-language models (VLMs) offer new avenues for enhancing\nassistive navigation. In this paper, we introduce Guide-LLM, an embodied\nLLM-based agent designed to assist PVI in navigating large indoor environments.\nOur approach features a novel text-based topological map that enables the LLM\nto plan global paths using a simplified environmental representation, focusing\non straight paths and right-angle turns to facilitate navigation. Additionally,\nwe utilize the LLM's commonsense reasoning for hazard detection and\npersonalized path planning based on user preferences. Simulated experiments\ndemonstrate the system's efficacy in guiding PVI, underscoring its potential as\na significant advancement in assistive technology. The results highlight\nGuide-LLM's ability to offer efficient, adaptive, and personalized navigation\nassistance, pointing to promising advancements in this field.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20666v2",
    "published_date": "2024-10-28 01:58:21 UTC",
    "updated_date": "2025-03-11 23:45:58 UTC"
  },
  {
    "arxiv_id": "2410.20664v2",
    "title": "Embedding with Large Language Models for Classification of HIPAA Safeguard Compliance Rules",
    "authors": [
      "Md Abdur Rahman",
      "Md Abdul Barek",
      "ABM Kamrul Islam Riad",
      "Md Mostafizur Rahman",
      "Md Bajlur Rashid",
      "Smita Ambedkar",
      "Md Raihan Miaa",
      "Fan Wu",
      "Alfredo Cuzzocrea",
      "Sheikh Iqbal Ahamed"
    ],
    "abstract": "Although software developers of mHealth apps are responsible for protecting\npatient data and adhering to strict privacy and security requirements, many of\nthem lack awareness of HIPAA regulations and struggle to distinguish between\nHIPAA rules categories. Therefore, providing guidance of HIPAA rules patterns\nclassification is essential for developing secured applications for Google Play\nStore. In this work, we identified the limitations of traditional Word2Vec\nembeddings in processing code patterns. To address this, we adopt multilingual\nBERT (Bidirectional Encoder Representations from Transformers) which offers\ncontextualized embeddings to the attributes of dataset to overcome the issues.\nTherefore, we applied this BERT to our dataset for embedding code patterns and\nthen uses these embedded code to various machine learning approaches. Our\nresults demonstrate that the models significantly enhances classification\nperformance, with Logistic Regression achieving a remarkable accuracy of\n99.95\\%. Additionally, we obtained high accuracy from Support Vector Machine\n(99.79\\%), Random Forest (99.73\\%), and Naive Bayes (95.93\\%), outperforming\nexisting approaches. This work underscores the effectiveness and showcases its\npotential for secure application development.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "I am requesting the withdrawal of my paper due to critical issues\n  identified in the methodology/results that may impact its accuracy and\n  reliability. I also plan to make substantial revisions that go beyond minor\n  corrections",
    "pdf_url": "http://arxiv.org/pdf/2410.20664v2",
    "published_date": "2024-10-28 01:54:24 UTC",
    "updated_date": "2024-11-07 21:18:54 UTC"
  },
  {
    "arxiv_id": "2410.20660v2",
    "title": "TurboHopp: Accelerated Molecule Scaffold Hopping with Consistency Models",
    "authors": [
      "Kiwoong Yoo",
      "Owen Oertell",
      "Junhyun Lee",
      "Sanghoon Lee",
      "Jaewoo Kang"
    ],
    "abstract": "Navigating the vast chemical space of druggable compounds is a formidable\nchallenge in drug discovery, where generative models are increasingly employed\nto identify viable candidates. Conditional 3D structure-based drug design\n(3D-SBDD) models, which take into account complex three-dimensional\ninteractions and molecular geometries, are particularly promising. Scaffold\nhopping is an efficient strategy that facilitates the identification of similar\nactive compounds by strategically modifying the core structure of molecules,\neffectively narrowing the wide chemical space and enhancing the discovery of\ndrug-like products. However, the practical application of 3D-SBDD generative\nmodels is hampered by their slow processing speeds. To address this bottleneck,\nwe introduce TurboHopp, an accelerated pocket-conditioned 3D scaffold hopping\nmodel that merges the strategic effectiveness of traditional scaffold hopping\nwith rapid generation capabilities of consistency models. This synergy not only\nenhances efficiency but also significantly boosts generation speeds, achieving\nup to 30 times faster inference speed as well as superior generation quality\ncompared to existing diffusion-based models, establishing TurboHopp as a\npowerful tool in drug discovery. Supported by faster inference speed, we\nfurther optimize our model, using Reinforcement Learning for Consistency Models\n(RLCM), to output desirable molecules. We demonstrate the broad applicability\nof TurboHopp across multiple drug discovery scenarios, underscoring its\npotential in diverse molecular settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 11 figures, 8 tables. Presented at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20660v2",
    "published_date": "2024-10-28 01:36:42 UTC",
    "updated_date": "2025-02-01 21:43:28 UTC"
  },
  {
    "arxiv_id": "2410.20659v1",
    "title": "A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data",
    "authors": [
      "Saptarshi Chakraborty",
      "Peter L. Bartlett"
    ],
    "abstract": "Federated Learning (FL) has emerged as a groundbreaking paradigm in\ncollaborative machine learning, emphasizing decentralized model training to\naddress data privacy concerns. While significant progress has been made in\noptimizing federated learning, the exploration of generalization error,\nparticularly in heterogeneous settings, has been limited, focusing mainly on\nparametric cases. This paper investigates the generalization properties of deep\nfederated regression within a two-stage sampling model. Our findings highlight\nthat the intrinsic dimension, defined by the entropic dimension, is crucial for\ndetermining convergence rates when appropriate network sizes are used.\nSpecifically, if the true relationship between response and explanatory\nvariables is charecterized by a $\\beta$-H\\\"older function and there are $n$\nindependent and identically distributed (i.i.d.) samples from $m$ participating\nclients, the error rate for participating clients scales at most as\n$\\tilde{O}\\left((mn)^{-2\\beta/(2\\beta + \\bar{d}_{2\\beta}(\\lambda))}\\right)$,\nand for non-participating clients, it scales as $\\tilde{O}\\left(\\Delta \\cdot\nm^{-2\\beta/(2\\beta + \\bar{d}_{2\\beta}(\\lambda))} + (mn)^{-2\\beta/(2\\beta +\n\\bar{d}_{2\\beta}(\\lambda))}\\right)$. Here, $\\bar{d}_{2\\beta}(\\lambda)$\nrepresents the $2\\beta$-entropic dimension of $\\lambda$, the marginal\ndistribution of the explanatory variables, and $\\Delta$ characterizes the\ndependence between the sampling stages. Our results explicitly account for the\n\"closeness\" of clients, demonstrating that the convergence rates of deep\nfederated learners depend on intrinsic rather than nominal high-dimensionality.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20659v1",
    "published_date": "2024-10-28 01:36:25 UTC",
    "updated_date": "2024-10-28 01:36:25 UTC"
  },
  {
    "arxiv_id": "2410.20651v2",
    "title": "SubjECTive-QA: Measuring Subjectivity in Earnings Call Transcripts' QA Through Six-Dimensional Feature Analysis",
    "authors": [
      "Huzaifa Pardawala",
      "Siddhant Sukhani",
      "Agam Shah",
      "Veer Kejriwal",
      "Abhishek Pillai",
      "Rohan Bhasin",
      "Andrew DiBiasio",
      "Tarun Mandapati",
      "Dhruv Adha",
      "Sudheer Chava"
    ],
    "abstract": "Fact-checking is extensively studied in the context of misinformation and\ndisinformation, addressing objective inaccuracies. However, a softer form of\nmisinformation involves responses that are factually correct but lack certain\nfeatures such as clarity and relevance. This challenge is prevalent in formal\nQuestion-Answer (QA) settings such as press conferences in finance, politics,\nsports, and other domains, where subjective answers can obscure transparency.\nDespite this, there is a lack of manually annotated datasets for subjective\nfeatures across multiple dimensions. To address this gap, we introduce\nSubjECTive-QA, a human annotated dataset on Earnings Call Transcripts' (ECTs)\nQA sessions as the answers given by company representatives are often open to\nsubjective interpretations and scrutiny. The dataset includes 49,446\nannotations for long-form QA pairs across six features: Assertive, Cautious,\nOptimistic, Specific, Clear, and Relevant. These features are carefully\nselected to encompass the key attributes that reflect the tone of the answers\nprovided during QA sessions across different domain. Our findings are that the\nbest-performing Pre-trained Language Model (PLM), RoBERTa-base, has similar\nweighted F1 scores to Llama-3-70b-Chat on features with lower subjectivity,\nsuch as Relevant and Clear, with a mean difference of 2.17% in their weighted\nF1 scores. The models perform significantly better on features with higher\nsubjectivity, such as Specific and Assertive, with a mean difference of 10.01%\nin their weighted F1 scores. Furthermore, testing SubjECTive-QA's\ngeneralizability using QAs from White House Press Briefings and Gaggles yields\nan average weighted F1 score of 65.97% using our best models for each feature,\ndemonstrating broader applicability beyond the financial domain. SubjECTive-QA\nis publicly available under the CC BY 4.0 license",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.20651v2",
    "published_date": "2024-10-28 01:17:34 UTC",
    "updated_date": "2025-01-23 18:56:21 UTC"
  },
  {
    "arxiv_id": "2410.20650v1",
    "title": "NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks",
    "authors": [
      "Yongchang Hao",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "abstract": "The performance of neural networks improves when more parameters are used.\nHowever, the model sizes are constrained by the available on-device memory\nduring training and inference. Although applying techniques like quantization\ncan alleviate the constraint, they suffer from performance degradation. In this\nwork, we introduce NeuZip, a new weight compression scheme based on the entropy\nof floating-point numbers in neural networks. With NeuZip, we are able to\nachieve memory-efficient training and inference without sacrificing\nperformance. Notably, we significantly reduce the memory footprint of training\na Llama-3 8B model from 31GB to less than 16GB, while keeping the training\ndynamics fully unchanged. In inference, our method can reduce memory usage by\nmore than half while maintaining near-lossless performance. Our code is\npublicly available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20650v1",
    "published_date": "2024-10-28 01:12:20 UTC",
    "updated_date": "2024-10-28 01:12:20 UTC"
  },
  {
    "arxiv_id": "2410.21339v1",
    "title": "Machine Learning and Quantum Intelligence for Health Data Scenarios",
    "authors": [
      "Sanjeev Naguleswaran"
    ],
    "abstract": "The advent of quantum computing has opened new possibilities in data science,\noffering unique capabilities for addressing complex, data-intensive problems.\nTraditional machine learning algorithms often face challenges in\nhigh-dimensional or limited-quality datasets, which are common in healthcare.\nQuantum Machine Learning leverages quantum properties, such as superposition\nand entanglement, to enhance pattern recognition and classification,\npotentially surpassing classical approaches. This paper explores QML's\napplication in healthcare, focusing on quantum kernel methods and hybrid\nquantum-classical networks for heart disease prediction and COVID-19 detection,\nassessing their feasibility and performance.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Presented at Machine Learning and Machine Intelligence (MLMI)\n  Conference, Osaka, Japan 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.21339v1",
    "published_date": "2024-10-28 01:04:43 UTC",
    "updated_date": "2024-10-28 01:04:43 UTC"
  },
  {
    "arxiv_id": "2410.21338v2",
    "title": "FinTeamExperts: Role Specialized MOEs For Financial Analysis",
    "authors": [
      "Yue Yu",
      "Prayag Tiwari"
    ],
    "abstract": "Large Language Models (LLMs), such as ChatGPT, Phi3 and Llama-3, are leading\na significant leap in AI, as they can generalize knowledge from their training\nto new tasks without fine-tuning. However, their application in the financial\ndomain remains relatively limited. The financial field is inherently complex,\nrequiring a deep understanding across various perspectives, from macro, micro\neconomic trend to quantitative analysis. Motivated by this complexity, a\nmixture of expert LLMs tailored to specific financial domains could offer a\nmore comprehensive understanding for intricate financial tasks. In this paper,\nwe present the FinTeamExperts, a role-specialized LLM framework structured as a\nMixture of Experts (MOEs) for financial analysis. The framework simulates a\ncollaborative team setting by training each model to specialize in distinct\nroles: Macro Analysts, Micro analysts, and Quantitative Analysts. This\nrole-specific specialization enhances the model's ability to integrate their\ndomain-specific expertise. We achieve this by training three 8-billion\nparameter models on different corpus, each dedicated to excelling in specific\nfinance-related roles. We then instruct-tune FinTeamExperts on downstream tasks\nto align with practical financial tasks. The experimental results show that\nFinTeamExperts outperform all models of the same size and larger on three out\nof four datasets. On the fourth dataset, which presents a more complex task,\nFinTeamExperts still surpass all models of the same size. This highlights the\nsuccess of our role-based specialization approach and the continued training\napproach for FinTeamExperts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21338v2",
    "published_date": "2024-10-28 00:40:55 UTC",
    "updated_date": "2024-11-07 23:11:04 UTC"
  },
  {
    "arxiv_id": "2410.21337v2",
    "title": "Fine-tuned Large Language Models (LLMs): Improved Prompt Injection Attacks Detection",
    "authors": [
      "Md Abdur Rahman",
      "Fan Wu",
      "Alfredo Cuzzocrea",
      "Sheikh Iqbal Ahamed"
    ],
    "abstract": "Large language models (LLMs) are becoming a popular tool as they have\nsignificantly advanced in their capability to tackle a wide range of\nlanguage-based tasks. However, LLMs applications are highly vulnerable to\nprompt injection attacks, which poses a critical problem. These attacks target\nLLMs applications through using carefully designed input prompts to divert the\nmodel from adhering to original instruction, thereby it could execute\nunintended actions. These manipulations pose serious security threats which\npotentially results in data leaks, biased outputs, or harmful responses. This\nproject explores the security vulnerabilities in relation to prompt injection\nattacks. To detect whether a prompt is vulnerable or not, we follows two\napproaches: 1) a pre-trained LLM, and 2) a fine-tuned LLM. Then, we conduct a\nthorough analysis and comparison of the classification performance. Firstly, we\nuse pre-trained XLM-RoBERTa model to detect prompt injections using test\ndataset without any fine-tuning and evaluate it by zero-shot classification.\nThen, this proposed work will apply supervised fine-tuning to this pre-trained\nLLM using a task-specific labeled dataset from deepset in huggingface, and this\nfine-tuned model achieves impressive results with 99.13\\% accuracy, 100\\%\nprecision, 98.33\\% recall and 99.15\\% F1-score thorough rigorous\nexperimentation and evaluation. We observe that our approach is highly\nefficient in detecting prompt injection attacks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "I am requesting the withdrawal of my paper due to critical issues\n  identified in the methodology/results that may impact its accuracy and\n  reliability. I also plan to make substantial revisions that go beyond minor\n  corrections",
    "pdf_url": "http://arxiv.org/pdf/2410.21337v2",
    "published_date": "2024-10-28 00:36:21 UTC",
    "updated_date": "2024-11-07 21:20:31 UTC"
  }
]