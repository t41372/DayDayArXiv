{
  "date": "2024-10-28",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-28 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 模型的优化、安全应用和跨领域创新，特别是大型语言模型（LLMs）在实时交互、医疗诊断和图像生成中的进展，亮点包括 LLM 的异步工具使用和医疗 AI 基准测试，涉及知名学者如 Yoshua Bengio 和 Jie Zhang 的工作。\n\n### 重点论文回顾\n今天共有 146 篇论文，我挑选了最具影响力和话题度的几篇放在前面讨论，包括 LLM 安全与优化、医疗 AI 应用和图像处理领域，其他较次要的论文（如一些纯理论或小众方法）将快速掠过。以下按主题归类，相关论文放在一起聊。\n\n**LLM 优化与安全（AI 核心领域，令人印象深刻）**  \n- **Asynchronous Tool Usage for Real-Time Agents（异步工具使用在实时代理中的应用）**（Antonio A. Ginart 等）：论文提出了一种事件驱动的有限状态机架构，支持 LLM 的异步处理和实时工具使用，主要贡献是通过整合语音识别和文本转语音，实现多任务交互，提升 AI 系统的交互性和并行性。  \n- **Reducing the Scope of Language Models（缩小语言模型的范围）**（David Yunis 等）：该工作探索了通过微调和偏好学习来限制 LLM 的响应范围，主要发现是，当无关查询多样性高时，简单监督微调最有效；反之，Circuit Breakers 方法更佳，适用于防范 LLM 在特定应用中的滥用。  \n- **Sabotage Evaluations for Frontier Models（针对前沿模型的破坏评估）**（Joe Benton 等）：论文评估了 LLM 在对抗性场景下的破坏能力，主要贡献是开发一套评估框架，证明当前缓解措施（如 Anthropic 的 Claude 模型）能有效应对，但未来可能需更强防御。\n\n**医疗 AI 应用（实际影响大，有话题度）**  \n- **Can Large Language Models Replace Data Scientists in Biomedical Research?（大型语言模型能否取代生物医学数据科学家）**（Zifeng Wang 等）：主要发现是，LLM 通过链式思考和自反思提示，能提升生物医学任务的代码准确率 21%，并在用户研究中证明能辅助医疗专业人士，但无法完全自动化编程。  \n- **A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges（为专业医疗 AI 应用适应通用 AI 的视角及其挑战）**（Zifeng Wang 等）：论文提出一个三步框架（建模、优化和系统工程），主要贡献是讨论 LLM 在医疗中的挑战，如幻觉处理和隐私合规，并提供案例如临床试验优化。  \n- **Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs（Fokker-Planck PDE 中物理信息神经网络的误差界）**（Chun-Wei Kong 等）：快速掠过，该工作分析 PINN 的误差界，主要发现是 PINN 在高维系统中比蒙特卡罗方法更快且更准确。\n\n**图像生成与基准测试（技术创新强）**  \n- **ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Always Guarantee Robustness after Fine-Tuning（ImageNet-RIB 基准：大型预训练数据集不一定保证微调后的鲁棒性）**（Jaedong Hwang 等）：论文构建了一个新基准，主要贡献是证明预训练数据集的多样性不直接等同于微调鲁棒性，使用最丰富的预训练数据反而可能降低泛化性能。  \n- **Survey of User Interface Design and Interaction Techniques in Generative AI Applications（生成 AI 应用中用户界面设计和交互技术的调查）**（Reuben Luera 等）：主要发现是，用户引导交互模式（如基于文本的交互）能降低生成 AI 的入门门槛，提供全面分类和设计参考。\n\n其他论文如那些聚焦于特定算法优化（如 Mitigating Gradient Overlap 或 Efficient Training of Sparse Autoencoders）或小众领域（如 Temporal Patterns of Multiple Long-Term Conditions），虽有技术贡献但影响力较小，我快速掠过，仅提要：它们分别探讨了梯度归一化和稀疏自编码器的效率提升，以及无监督聚类在医疗轨迹分析中的应用，但未见重大突破。\n\n总之，今天的论文突显了 AI 模型在安全、效率和实际应用上的进展，LLM 相关工作尤其值得关注，期待后续研究进一步推动这些领域。明天见！",
  "papers": [
    {
      "arxiv_id": "2410.21620v1",
      "title": "Asynchronous Tool Usage for Real-Time Agents",
      "title_zh": "异步工具使用针对实时代理",
      "authors": [
        "Antonio A. Ginart",
        "Naveen Kodali",
        "Jason Lee",
        "Caiming Xiong",
        "Silvio Savarese",
        "John Emmons"
      ],
      "abstract": "While frontier large language models (LLMs) are capable tool-using agents,\ncurrent AI systems still operate in a strict turn-based fashion, oblivious to\npassage of time. This synchronous design forces user queries and tool-use to\noccur sequentially, preventing the systems from multitasking and reducing\ninteractivity. To address this limitation, we introduce asynchronous AI agents\ncapable of parallel processing and real-time tool-use. Our key contribution is\nan event-driven finite-state machine architecture for agent execution and\nprompting, integrated with automatic speech recognition and text-to-speech.\nDrawing inspiration from the concepts originally developed for real-time\noperating systems, this work presents both a conceptual framework and practical\ntools for creating AI agents capable of fluid, multitasking interactions.",
      "tldr_zh": "本文研究了现有大型语言模型(LLMs)代理的同步设计问题，导致查询和工具使用顺序执行，无法实现多任务和实时交互。为解决这一限制，论文引入异步AI代理，采用事件驱动的finite-state machine架构，并集成automatic speech recognition (ASR)和text-to-speech (TTS)，支持并行处理和实时工具使用。该框架借鉴实时操作系统概念，提供概念框架和实用工具，提升AI代理的流畅多任务交互能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21620v1",
      "published_date": "2024-10-28 23:57:19 UTC",
      "updated_date": "2024-10-28 23:57:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:25:41.889903"
    },
    {
      "arxiv_id": "2410.21616v1",
      "title": "Identifying Selections for Unsupervised Subtask Discovery",
      "title_zh": "无监督子任务发现的选择识别",
      "authors": [
        "Yiwen Qiu",
        "Yujia Zheng",
        "Kun Zhang"
      ],
      "abstract": "When solving long-horizon tasks, it is intriguing to decompose the high-level\ntask into subtasks. Decomposing experiences into reusable subtasks can improve\ndata efficiency, accelerate policy generalization, and in general provide\npromising solutions to multi-task reinforcement learning and imitation learning\nproblems. However, the concept of subtasks is not sufficiently understood and\nmodeled yet, and existing works often overlook the true structure of the data\ngeneration process: subtasks are the results of a $\\textit{selection}$\nmechanism on actions, rather than possible underlying confounders or\nintermediates. Specifically, we provide a theory to identify, and experiments\nto verify the existence of selection variables in such data. These selections\nserve as subgoals that indicate subtasks and guide policy. In light of this\nidea, we develop a sequential non-negative matrix factorization (seq- NMF)\nmethod to learn these subgoals and extract meaningful behavior patterns as\nsubtasks. Our empirical results on a challenging Kitchen environment\ndemonstrate that the learned subtasks effectively enhance the generalization to\nnew tasks in multi-task imitation learning scenarios. The codes are provided at\nhttps://anonymous.4open.science/r/Identifying\\_Selections\\_for\\_Unsupervised\\_Subtask\\_Discovery/README.md.",
      "tldr_zh": "该论文探讨了将长时域任务分解为子任务的重要性，以提升数据效率、策略泛化以及多任务强化学习和模仿学习的效果。作者提出一个理论框架，识别动作上的选择机制（selections）作为子目标，这些选择变量并非混杂因素，而是指导子任务的关键指标，并通过实验验证其存在。基于此，他们开发了顺序非负矩阵分解（seq-NMF）方法来学习子目标并提取行为模式；在 Kitchen 环境上的实验结果显示，该方法显著提高了多任务模仿学习场景下的新任务泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21616v1",
      "published_date": "2024-10-28 23:47:43 UTC",
      "updated_date": "2024-10-28 23:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:25:53.455308"
    },
    {
      "arxiv_id": "2410.22371v2",
      "title": "Error Bounds for Physics-Informed Neural Networks in Fokker-Planck PDEs",
      "title_zh": "针对福克-普朗克偏微分方程的物理信息神经网络误差边界",
      "authors": [
        "Chun-Wei Kong",
        "Luca Laurenti",
        "Jay McMahon",
        "Morteza Lahijanian"
      ],
      "abstract": "Stochastic differential equations are commonly used to describe the evolution\nof stochastic processes. The state uncertainty of such processes is best\nrepresented by the probability density function (PDF), whose evolution is\ngoverned by the Fokker-Planck partial differential equation (FP-PDE). However,\nit is generally infeasible to solve the FP-PDE in closed form. In this work, we\nshow that physics-informed neural networks (PINNs) can be trained to\napproximate the solution PDF. Our main contribution is the analysis of PINN\napproximation error: we develop a theoretical framework to construct tight\nerror bounds using PINNs. In addition, we derive a practical error bound that\ncan be efficiently constructed with standard training methods. We discuss that\nthis error-bound framework generalizes to approximate solutions of other linear\nPDEs. Empirical results on nonlinear, high-dimensional, and chaotic systems\nvalidate the correctness of our error bounds while demonstrating the\nscalability of PINNs and their significant computational speedup in obtaining\naccurate PDF solutions compared to the Monte Carlo approach.",
      "tldr_zh": "本论文探讨了使用 Physics-Informed Neural Networks (PINNs) 来逼近 Fokker-Planck PDEs (FP-PDEs) 的解决方案 Probability Density Function (PDF)，以解决随机过程演化的建模挑战。研究的主要贡献是开发了一个理论框架来构建紧致的 PINN 逼近误差边界，并推导了一个可通过标准训练方法高效实现的实用误差边界。该框架还可推广至其他线性 PDE 的逼近解决方案；实验结果在非线性、高维和混沌系统中验证了误差边界的准确性，并证明了 PINNs 相对于 Monte Carlo 方法的显著计算加速优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "paper under review",
      "pdf_url": "http://arxiv.org/pdf/2410.22371v2",
      "published_date": "2024-10-28 23:25:55 UTC",
      "updated_date": "2025-03-03 16:16:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:26:06.936990"
    },
    {
      "arxiv_id": "2410.22370v1",
      "title": "Survey of User Interface Design and Interaction Techniques in Generative AI Applications",
      "title_zh": "生成式 AI 应用中用户界面设计与交互技术的调查",
      "authors": [
        "Reuben Luera",
        "Ryan A. Rossi",
        "Alexa Siu",
        "Franck Dernoncourt",
        "Tong Yu",
        "Sungchul Kim",
        "Ruiyi Zhang",
        "Xiang Chen",
        "Hanieh Salehy",
        "Jian Zhao",
        "Samyadeep Basu",
        "Puneet Mathur",
        "Nedim Lipka"
      ],
      "abstract": "The applications of generative AI have become extremely impressive, and the\ninterplay between users and AI is even more so. Current human-AI interaction\nliterature has taken a broad look at how humans interact with generative AI,\nbut it lacks specificity regarding the user interface designs and patterns used\nto create these applications. Therefore, we present a survey that\ncomprehensively presents taxonomies of how a human interacts with AI and the\nuser interaction patterns designed to meet the needs of a variety of relevant\nuse cases. We focus primarily on user-guided interactions, surveying\ninteractions that are initiated by the user and do not include any implicit\nsignals given by the user. With this survey, we aim to create a compendium of\ndifferent user-interaction patterns that can be used as a reference for\ndesigners and developers alike. In doing so, we also strive to lower the entry\nbarrier for those attempting to learn more about the design of generative AI\napplications.",
      "tldr_zh": "这篇论文对生成式 AI 应用中的用户界面设计和互动技术进行了全面调查，填补了现有文献在具体设计模式方面的空白。研究者建立了人类与 AI 互动的分类体系，并总结了针对各种用例的用户互动模式，重点关注用户引导的互动（如用户主动发起的交互，而非隐式信号）。通过此调查，论文创建了一个可供设计师和开发者参考的互动模式大全，旨在降低生成式 AI 应用设计的学习门槛。实验和分析突出了这些模式的实用性，为未来的人机交互设计提供了宝贵指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22370v1",
      "published_date": "2024-10-28 23:10:06 UTC",
      "updated_date": "2024-10-28 23:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:26:17.383692"
    },
    {
      "arxiv_id": "2410.21597v2",
      "title": "Reducing the Scope of Language Models",
      "title_zh": "缩小语言模型的作用域",
      "authors": [
        "David Yunis",
        "Siyu Huo",
        "Chulaka Gunasekara",
        "Danish Contractor"
      ],
      "abstract": "We now deploy language models in a wide variety of user-facing applications.\nTypically, these deployments have some specific purpose, like answering\nquestions about documentation or acting as coding assistants, but they require\ngeneral language understanding. Under these circumstances these models should\nnot be able to answer irrelevant requests such as, poetry generation or\nquestions about physics, etc. Instead we would like language models to only\nanswer to queries corresponding to desired behavior and refuse all other\nrequests, which we refer to as scoping. We conduct a comprehensive empirical\nevaluation of potential methods from prompting to fine-tuning to preference\nlearning to a recently proposed method for general alignment called Circuit\nBreakers (CB). Across three families of language models and a broad variety of\ntasks, we show that it is possible to scope language models. We examine scoping\nfor multiple topics, and fine-grained topics. We ablate diversity of irrelevant\nqueries, layer different techniques, conduct adversarial evaluations and more.\nAmong other results, we find that, when diverse examples of irrelevant queries\nare available, simple supervised fine-tuning produces the best results, but\nwhen such diversity is low, Circuit Breakers perform quite well. One can often\nget the benefits of both methods by layering them in succession. We intend our\nstudy to serve as a practitioner's guide to scoping language models.",
      "tldr_zh": "本研究探讨了如何限制语言模型（Language Models）的响应范围（scoping），以确保它们仅处理特定用途的查询（如文档问答或代码辅助），而拒绝无关请求（如诗歌生成或物理问题）。研究者通过全面实证评估，包括提示（prompting）、微调（fine-tuning）、偏好学习（preference learning）和Circuit Breakers等方法，在多种语言模型和任务上进行了测试。结果显示，当有多样无关查询时，简单监督微调效果最佳；若查询多样性低，则Circuit Breakers表现突出，且二者可结合层叠使用。该研究为从业者提供了实用的语言模型scoping指南，以提升模型的安全性和针对性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21597v2",
      "published_date": "2024-10-28 23:06:57 UTC",
      "updated_date": "2025-04-17 19:17:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:26:30.775923"
    },
    {
      "arxiv_id": "2410.21591v2",
      "title": "Can Large Language Models Replace Data Scientists in Biomedical Research?",
      "title_zh": "大型语言模型能否取代生物医学研究中的数据科学家？",
      "authors": [
        "Zifeng Wang",
        "Benjamin Danek",
        "Ziwei Yang",
        "Zheng Chen",
        "Jimeng Sun"
      ],
      "abstract": "Data science plays a critical role in biomedical research, but it requires\nprofessionals with expertise in coding and medical data analysis. Large\nlanguage models (LLMs) have shown great potential in supporting medical tasks\nand performing well in general coding tests. However, existing evaluations fail\nto assess their capability in biomedical data science, particularly in handling\ndiverse data types such as genomics and clinical datasets. To address this gap,\nwe developed a benchmark of data science coding tasks derived from the analyses\nof 39 published studies. This benchmark comprises 293 coding tasks (128 in\nPython and 165 in R) performed on real-world TCGA-type genomics and clinical\ndata. Our findings reveal that the vanilla prompting of LLMs yields suboptimal\nperformances due to drawbacks in following input instructions, understanding\ntarget data, and adhering to standard analysis practices. Next, we benchmarked\nsix cutting-edge LLMs and advanced adaptation methods, finding two methods to\nbe particularly effective: chain-of-thought prompting, which provides a\nstep-by-step plan for data analysis, which led to a 21% code accuracy\nimprovement (56.6% versus 35.3%); and self-reflection, enabling LLMs to refine\nthe buggy code iteratively, yielding an 11% code accuracy improvement (45.5%\nversus 34.3%). Building on these insights, we developed a platform that\nintegrates LLMs into the data science workflow for medical professionals. In a\nuser study with five medical professionals, we found that while LLMs cannot\nfully automate programming tasks, they significantly streamline the programming\nprocess. We found that 80% of their submitted code solutions were incorporated\nfrom LLM-generated code, with up to 96% reuse in some cases. Our analysis\nhighlights the potential of LLMs to enhance data science efficiency in\nbiomedical research when integrated into expert workflows.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 是否能取代生物医学研究中的数据科学家，通过开发一个包含 293 个编码任务的基准（基于 39 个已发表研究的真实 TCGA-type 基因组和临床数据）来评估 LLMs 在处理多样化生物医学数据方面的能力。结果显示，直接提示 LLMs 的性能较差，主要由于指令遵循、数据理解和标准实践的不足；然而，chain-of-thought prompting 提升了 21% 的代码准确率（56.6% vs 35.3%），而 self-reflection 方法则提高了 11% 的代码准确率（45.5% vs 34.3%）。研究进一步构建了一个整合 LLMs 的平台，在五名医疗专业人员的用户研究中，发现他们提交的代码中有 80% 来自 LLM 生成，最高达 96% 的复用率，从而显著简化了数据科学工作流。总体而言，LLMs 虽不能完全取代数据科学家，但能显著提升生物医学研究的效率和生产力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "q-bio.GN",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21591v2",
      "published_date": "2024-10-28 22:48:06 UTC",
      "updated_date": "2025-04-08 21:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:26:44.381089"
    },
    {
      "arxiv_id": "2410.21582v2",
      "title": "ImageNet-RIB Benchmark: Large Pre-Training Datasets Don't Always Guarantee Robustness after Fine-Tuning",
      "title_zh": "ImageNet-RIB 基准：大型预训练数据集并不总是保证微调后的鲁棒",
      "authors": [
        "Jaedong Hwang",
        "Brian Cheung",
        "Zhang-Wei Hong",
        "Akhilan Boopathy",
        "Pulkit Agrawal",
        "Ila Fiete"
      ],
      "abstract": "Highly performant large-scale pre-trained models promise to also provide a\nvaluable foundation for learning specialized tasks, by fine-tuning the model to\nthe desired task. By starting from a good general-purpose model, the goal is to\nachieve both specialization in the target task and maintain robustness. To\nassess the robustness of models on out-of-distribution samples after\nfine-tuning on downstream datasets, we introduce a new robust fine-tuning\nbenchmark, ImageNet-RIB (Robustness Inheritance Benchmark). The benchmark\nconsists of a set of related but distinct specialized (downstream) datasets;\npre-trained models are fine-tuned on one dataset in the set and their\nrobustness is assessed on the rest, iterating across all tasks for fine-tuning\nand assessment. The distance between the pre-training and downstream datasets,\nmeasured by optimal transport, predicts this performance degradation on the\npre-training dataset. Though continual learning methods help maintain\nrobustness, fine-tuning generally reduces generalization performance on related\ndownstream tasks across models. Counterintuitively, model robustness after\nfine-tuning on related downstream tasks is the worst when the pre-training\ndataset is the richest and the most diverse. This suggests that starting with\nthe strongest foundation model is not necessarily the best approach for\nperformance on specialist tasks. ImageNet-RIB thus offers key insights for\ndeveloping more resilient fine-tuning strategies and building robust machine\nlearning models. https://jd730.github.io/projects/ImageNet-RIB",
      "tldr_zh": "本文提出ImageNet-RIB基准，用于评估在下游任务fine-tuning后模型的鲁棒性，发现大型预训练数据集并不总是保证泛化性能。基准通过一组相关但不同的专业数据集进行实验：模型在其中一个数据集上微调，然后在其他数据集上评估鲁棒性，并使用optimal transport测量预训练和下游数据集之间的距离来预测性能下降。研究结果显示，持续学习方法虽能帮助维持鲁棒性，但fine-tuning通常会降低在相关任务上的表现，且预训练数据集越丰富多样，模型在下游任务上的鲁棒性反而更差。这为开发更具弹性的fine-tuning策略和构建鲁棒机器学习模型提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21582v2",
      "published_date": "2024-10-28 22:33:22 UTC",
      "updated_date": "2025-02-04 21:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:26:54.980174"
    },
    {
      "arxiv_id": "2411.00024v3",
      "title": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Zifeng Wang",
        "Hanyin Wang",
        "Benjamin Danek",
        "Ying Li",
        "Christina Mack",
        "Hoifung Poon",
        "Yajuan Wang",
        "Pranav Rajpurkar",
        "Jimeng Sun"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into medical applications has\nsparked widespread interest across the healthcare industry, from drug discovery\nand development to clinical decision support, assisting telemedicine, medical\ndevices, and healthcare insurance applications. This perspective paper aims to\ndiscuss the inner workings of building LLM-powered medical AI applications and\nintroduces a comprehensive framework for their development. We review existing\nliterature and outline the unique challenges of applying LLMs in specialized\nmedical contexts. Additionally, we introduce a three-step framework to organize\nmedical LLM research activities: 1) Modeling: breaking down complex medical\nworkflows into manageable steps for developing medical-specific models; 2)\nOptimization: optimizing the model performance with crafted prompts and\nintegrating external knowledge and tools, and 3) System engineering:\ndecomposing complex tasks into subtasks and leveraging human expertise for\nbuilding medical AI applications. Furthermore, we offer a detailed use case\nplaybook that describes various LLM-powered medical AI applications, such as\noptimizing clinical trial design, enhancing clinical decision support, and\nadvancing medical imaging analysis. Finally, we discuss various challenges and\nconsiderations for building medical AI applications with LLMs, such as handling\nhallucination issues, data ownership and compliance, privacy, intellectual\nproperty considerations, compute cost, sustainability issues, and responsible\nAI requirements.",
      "tldr_zh": "这篇论文探讨了将通用AI（Large Language Models, LLMs）适应到专业医疗应用的视角，并介绍了构建LLM驱动医疗AI应用的全面框架。框架分为三个步骤：Modeling（将复杂医疗工作流程分解为可管理步骤以开发专用模型）、Optimization（通过精心设计的提示整合外部知识和工具来提升性能），以及System engineering（将任务分解为子任务并利用人类专业知识）。论文回顾了现有文献，提供用例手册如优化临床试验设计、增强临床决策支持和推进医疗图像分析，同时讨论了关键挑战，包括处理幻觉问题、数据所有权合规、隐私保护、知识产权、计算成本、可持续性和负责任AI要求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00024v3",
      "published_date": "2024-10-28 22:30:06 UTC",
      "updated_date": "2024-11-30 00:17:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:27:06.712970"
    },
    {
      "arxiv_id": "2410.21574v1",
      "title": "A Generative Model Based Honeypot for Industrial OPC UA Communication",
      "title_zh": "基于生成模型的蜜罐用于工业 OPC",
      "authors": [
        "Olaf Sassnick",
        "Georg Schäfer",
        "Thomas Rosenstatter",
        "Stefan Huber"
      ],
      "abstract": "Industrial Operational Technology (OT) systems are increasingly targeted by\ncyber-attacks due to their integration with Information Technology (IT) systems\nin the Industry 4.0 era. Besides intrusion detection systems, honeypots can\neffectively detect these attacks. However, creating realistic honeypots for\nbrownfield systems is particularly challenging. This paper introduces a\ngenerative model-based honeypot designed to mimic industrial OPC UA\ncommunication. Utilizing a Long ShortTerm Memory (LSTM) network, the honeypot\nlearns the characteristics of a highly dynamic mechatronic system from recorded\nstate space trajectories. Our contributions are twofold: first, we present a\nproof-of concept for a honeypot based on generative machine-learning models,\nand second, we publish a dataset for a cyclic industrial process. The results\ndemonstrate that a generative model-based honeypot can feasibly replicate a\ncyclic industrial process via OPC UA communication. In the short-term, the\ngenerative model indicates a stable and plausible trajectory generation, while\ndeviations occur over extended periods. The proposed honeypot implementation\noperates efficiently on constrained hardware, requiring low computational\nresources. Future work will focus on improving model accuracy, interaction\ncapabilities, and extending the dataset for broader applications.",
      "tldr_zh": "这篇论文提出了一种基于生成模型的 honeypot，用于模拟工业 OPC UA 通信，以检测针对工业 OT 系统的网络攻击。利用 LSTM 网络从记录的状态空间轨迹中学习动态机电系统的特征，该 honeypot 能够可行地复制循环工业过程，并在短期内生成稳定且合理的轨迹。贡献包括证明了生成机器学习模型-based honeypot 的概念，并发布了一个数据集；实验结果显示，该系统在受限硬件上高效运行，但长期可能出现偏差，未来工作将聚焦于提升模型准确性和交互能力。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "This preprint has not undergone peer review or any post-submission\n  improvements or corrections. The Version of Record of this contribution is\n  accepted and will be published in Computer Aided Systems Theory - EUROCAST\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21574v1",
      "published_date": "2024-10-28 22:12:06 UTC",
      "updated_date": "2024-10-28 22:12:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:27:19.085011"
    },
    {
      "arxiv_id": "2410.21573v2",
      "title": "Thank You, Stingray: Multilingual Large Language Models Can Not (Yet) Disambiguate Cross-Lingual Word Sense",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Cahyawijaya",
        "Ruochen Zhang",
        "Holy Lovenia",
        "Jan Christian Blaise Cruz",
        "Elisa Gilbert",
        "Hiroki Nomoto",
        "Alham Fikri Aji"
      ],
      "abstract": "Multilingual large language models (LLMs) have gained prominence, but\nconcerns arise regarding their reliability beyond English. This study addresses\nthe gap in cross-lingual semantic evaluation by introducing a novel benchmark\nfor cross-lingual sense disambiguation, StingrayBench. In this paper, we\ndemonstrate using false friends -- words that are orthographically similar but\nhave completely different meanings in two languages -- as a possible approach\nto pinpoint the limitation of cross-lingual sense disambiguation in LLMs. We\ncollect false friends in four language pairs, namely Indonesian-Malay,\nIndonesian-Tagalog, Chinese-Japanese, and English-German; and challenge LLMs to\ndistinguish the use of them in context. In our analysis of various models, we\nobserve they tend to be biased toward higher-resource languages. We also\npropose new metrics for quantifying the cross-lingual sense bias and\ncomprehension based on our benchmark. Our work contributes to developing more\ndiverse and inclusive language modeling, promoting fairer access for the wider\nmultilingual community.",
      "tldr_zh": "这篇论文探讨了多语言大型语言模型(Multilingual LLMs)在跨语言词义歧义方面的局限性，通过引入一个新基准StingrayBench来评估模型性能。研究者使用false friends（拼写相似但含义不同的词）从四个语言对（包括Indonesian-Malay、Indonesian-Tagalog、Chinese-Japanese和English-German）中收集数据，并测试LLMs在上下文中区分这些词的能力。结果显示，LLMs倾向于偏向资源丰富的语言，并提出了新的指标来量化跨语言语义偏见和理解水平。该工作有助于推动更多样化和包容性的语言模型开发，促进多语言社区的公平访问。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21573v2",
      "published_date": "2024-10-28 22:09:43 UTC",
      "updated_date": "2024-10-30 11:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:27:31.644209"
    },
    {
      "arxiv_id": "2410.21564v3",
      "title": "Mitigating Gradient Overlap in Deep Residual Networks with Gradient Normalization for Improved Non-Convex Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Juyoung Yun"
      ],
      "abstract": "In deep learning, Residual Networks (ResNets) have proven effective in\naddressing the vanishing gradient problem, allowing for the successful training\nof very deep networks. However, skip connections in ResNets can lead to\ngradient overlap, where gradients from both the learned transformation and the\nskip connection combine, potentially resulting in overestimated gradients. This\noverestimation can cause inefficiencies in optimization, as some updates may\novershoot optimal regions, affecting weight updates. To address this, we\nexamine Z-score Normalization (ZNorm) as a technique to manage gradient\noverlap. ZNorm adjusts the gradient scale, standardizing gradients across\nlayers and reducing the negative impact of overlapping gradients. Our\nexperiments demonstrate that ZNorm improves training process, especially in\nnon-convex optimization scenarios common in deep learning, where finding\noptimal solutions is challenging. These findings suggest that ZNorm can affect\nthe gradient flow, enhancing performance in large-scale data processing where\naccuracy is critical.",
      "tldr_zh": "Residual Networks (ResNets) 通过跳跃连接解决了梯度消失问题，但也可能导致梯度重叠，造成梯度过估并影响优化效率。论文提出使用 Z-score Normalization (ZNorm) 技术来标准化梯度规模，减少重叠的负面影响，从而改善非凸优化过程中的训练。实验结果表明，ZNorm 显著提升了模型性能，尤其在处理大规模数据时，提高了准确性和优化效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21564v3",
      "published_date": "2024-10-28 21:54:44 UTC",
      "updated_date": "2024-11-15 00:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:27:42.889878"
    },
    {
      "arxiv_id": "2410.21560v1",
      "title": "Going Beyond H&E and Oncology: How Do Histopathology Foundation Models Perform for Multi-stain IHC and Immunology?",
      "title_zh": "翻译失败",
      "authors": [
        "Amaya Gallagher-Syed",
        "Elena Pontarini",
        "Myles J. Lewis",
        "Michael R. Barnes",
        "Gregory Slabaugh"
      ],
      "abstract": "This study evaluates the generalisation capabilities of state-of-the-art\nhistopathology foundation models on out-of-distribution multi-stain autoimmune\nImmunohistochemistry datasets. We compare 13 feature extractor models,\nincluding ImageNet-pretrained networks, and histopathology foundation models\ntrained on both public and proprietary data, on Rheumatoid Arthritis subtyping\nand Sjogren's Disease detection tasks. Using a simple Attention-Based Multiple\nInstance Learning classifier, we assess the transferability of learned\nrepresentations from cancer H&E images to autoimmune IHC images. Contrary to\nexpectations, histopathology-pretrained models did not significantly outperform\nImageNet-pretrained models. Furthermore, there was evidence of both autoimmune\nfeature misinterpretation and biased feature importance. Our findings highlight\nthe challenges in transferring knowledge from cancer to autoimmune\nhistopathology and emphasise the need for careful evaluation of AI models\nacross diverse histopathological tasks. The code to run this benchmark is\navailable at https://github.com/AmayaGS/ImmunoHistoBench.",
      "tldr_zh": "本研究评估了最先进的组织病理学基础模型在多染色自身免疫Immunohistochemistry (IHC)数据集上的泛化能力，焦点是将其从癌症H&E图像转移到自身免疫任务，如类风湿性关节炎亚型分类和Sjogren's Disease检测。研究比较了13个特征提取模型，包括ImageNet-pretrained网络和基于公共或专有数据的组织病理学预训练模型，并使用Attention-Based Multiple Instance Learning分类器进行评估。结果显示，组织病理学预训练模型并未显著优于ImageNet-pretrained模型，且存在自身免疫特征误解和偏差特征重要性的问题，强调了从癌症到自身免疫组织病理学知识转移的挑战，并呼吁在多样化任务上仔细评估AI模型。代码可在GitHub仓库ImmunoHistoBench获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM",
        "q-bio.TO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Workshop on Advancements In Medical Foundation Models\n  (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.21560v1",
      "published_date": "2024-10-28 21:48:39 UTC",
      "updated_date": "2024-10-28 21:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:29:56.784029"
    },
    {
      "arxiv_id": "2410.22368v1",
      "title": "Project MPG: towards a generalized performance benchmark for LLM capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Spangher",
        "Tianle Li",
        "William F. Arnold",
        "Nick Masiewicki",
        "Xerxes Dotiwalla",
        "Rama Parusmathi",
        "Peter Grabowski",
        "Eugene Ie",
        "Dan Gruhl"
      ],
      "abstract": "There exists an extremely wide array of LLM benchmarking tasks, whereas\noftentimes a single number is the most actionable for decision-making,\nespecially by non-experts. No such aggregation schema exists that is not\nElo-based, which could be costly or time-consuming. Here we propose a method to\naggregate performance across a general space of benchmarks, nicknamed Project\n\"MPG,\" dubbed Model Performance and Goodness, additionally referencing a metric\nwidely understood to be an important yet inaccurate and crude measure of car\nperformance. Here, we create two numbers: a \"Goodness\" number (answer accuracy)\nand a \"Fastness\" number (cost or QPS). We compare models against each other and\npresent a ranking according to our general metric as well as subdomains. We\nfind significant agreement between the raw Pearson correlation of our scores\nand those of Chatbot Arena, even improving on the correlation of the MMLU\nleaderboard to Chatbot Arena.",
      "tldr_zh": "该研究针对大型语言模型（LLM）的基准测试多样性问题，提出了一种名为 Project MPG 的通用性能聚合方法，以提供简单、可行动的指标，支持非专家决策。该方法生成两个关键数字：\"Goodness\"（答案准确性）和\"Fastness\"（成本或 QPS），用于评估模型在各种基准上的整体表现，并据此创建模型排名。实验结果显示，Project MPG 的分数与 Chatbot Arena 的 Pearson 相关性显著，且比 MMLU 排行榜的相关性更高，从而为更有效的 LLM 评估奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22368v1",
      "published_date": "2024-10-28 21:25:37 UTC",
      "updated_date": "2024-10-28 21:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:28:07.118579"
    },
    {
      "arxiv_id": "2411.08894v2",
      "title": "Temporal Patterns of Multiple Long-Term Conditions in Individuals with Intellectual Disability Living in Wales: An Unsupervised Clustering Approach to Disease Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Rania Kousovista",
        "Georgina Cosma",
        "Emeka Abakasanga",
        "Ashley Akbari",
        "Francesco Zaccardi",
        "Gyuchan Thomas Jun",
        "Reza Kiani",
        "Satheesh Gangadharan"
      ],
      "abstract": "Identifying and understanding the co-occurrence of multiple long-term\nconditions (MLTC) in individuals with intellectual disabilities (ID) is vital\nfor effective healthcare management. These individuals often face earlier onset\nand higher prevalence of MLTCs, yet specific co-occurrence patterns remain\nunexplored. This study applies an unsupervised approach to characterise MLTC\nclusters based on shared disease trajectories using electronic health records\n(EHRs) from 13069 individuals with ID in Wales (2000-2021). Disease\nassociations and temporal directionality were assessed, followed by spectral\nclustering to group shared trajectories. The population consisted of 52.3%\nmales and 47.7% females, with an average of 4.5 conditions per patient. Males\nunder 45 formed a single cluster dominated by neurological conditions (32.4%),\nwhile males above 45 had three clusters, the largest characterised circulatory\n(51.8%). Females under 45 formed one cluster with digestive conditions (24.6%)\nas most prevalent, while those aged 45 and older showed two clusters: one\ndominated by circulatory (34.1%), and the other by digestive (25.9%) and\nmusculoskeletal (21.9%) system conditions. Mental illness, epilepsy, and reflux\nwere common across groups. These clusters offer insights into disease\nprogression in individuals with ID, informing targeted interventions and\npersonalised healthcare strategies.",
      "tldr_zh": "本研究探讨了威尔士智障人士（ID）中多重长期疾病（MLTC）的共同发生模式，使用电子健康记录（EHRs）对2000-2021年间13,069名个体的疾病轨迹进行分析。采用无监督聚类（spectral clustering）方法，评估疾病关联和时间方向性，结果显示：45岁以下男性主要聚类于神经系统疾病（32.4%），45岁以上男性则有三个聚类以循环系统疾病（51.8%）为主；女性中，45岁以下以消化系统疾病（24.6%）为主，45岁以上则分为循环系统（34.1%）主导的聚类和消化系统（25.9%）与肌肉骨骼系统（21.9%）并存的聚类。精神疾病、癫痫和反流在各组中普遍存在，这些发现为智障人士的疾病进展提供洞见，有助于制定针对性干预和个性化医疗策略。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08894v2",
      "published_date": "2024-10-28 21:15:49 UTC",
      "updated_date": "2024-11-15 18:58:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:28:21.783953"
    },
    {
      "arxiv_id": "2410.21539v1",
      "title": "Bayesian Regression for Predicting Subscription to Bank Term Deposits in Direct Marketing Campaigns",
      "title_zh": "贝",
      "authors": [
        "Muhammad Farhan Tanvir",
        "Md Maruf Hossain",
        "Md Asifuzzaman Jishan"
      ],
      "abstract": "In the highly competitive environment of the banking industry, it is\nessential to precisely forecast the behavior of customers in order to maximize\nthe effectiveness of marketing initiatives and improve financial consequences.\nThe purpose of this research is to examine the efficacy of logit and probit\nmodels in predicting term deposit subscriptions using a Portuguese bank's\ndirect marketing data. There are several demographic, economic, and behavioral\ncharacteristics in the dataset that affect the probability of subscribing. To\nincrease model performance and provide an unbiased evaluation, the target\nvariable was balanced, considering the inherent imbalance in the dataset. The\ntwo model's prediction abilities were evaluated using Bayesian techniques and\nLeave-One-Out Cross-Validation (LOO-CV). The logit model performed better than\nthe probit model in handling this classification problem. The results highlight\nthe relevance of model selection when dealing with complicated decision-making\nprocesses in the financial services industry and imbalanced datasets. Findings\nfrom this study shed light on how banks can optimize their decision-making\nprocesses, improve their client segmentation, and boost their marketing\ncampaigns by utilizing machine learning models.",
      "tldr_zh": "本研究利用Bayesian Regression方法，基于葡萄牙银行的直接营销数据，比较logit和probit模型在预测客户订阅银行定期存款方面的效能。研究者通过平衡目标变量、处理数据集中的不平衡问题，并采用Bayesian技术和Leave-One-Out Cross-Validation (LOO-CV)进行模型评估，发现logit模型在这一分类任务中表现优于probit模型。这些发现有助于银行优化决策流程、提升客户细分策略，并改进营销活动的效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21539v1",
      "published_date": "2024-10-28 21:04:58 UTC",
      "updated_date": "2024-10-28 21:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:28:31.008724"
    },
    {
      "arxiv_id": "2410.21533v3",
      "title": "L3Ms -- Lagrange Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Guneet S. Dhillon",
        "Xingjian Shi",
        "Yee Whye Teh",
        "Alex Smola"
      ],
      "abstract": "Supervised fine-tuning (SFT) and alignment of large language models (LLMs)\nare key steps in providing a good user experience. However, the concept of an\nappropriate alignment is inherently application-dependent, and current methods\noften rely on heuristic choices to drive optimization. In this work, we\nformulate SFT and alignment as a constrained optimization problem: the LLM is\nfine-tuned on a task while being required to meet application-specific\nrequirements, without resorting to heuristics. To solve this, we propose\nLagrange Large Language Models (L3Ms), which employ logarithmic barriers to\nenforce the constraints. This approach allows for the customization of L3Ms\nacross diverse applications while avoiding heuristic-driven processes. We\nexperimentally demonstrate the versatility and efficacy of L3Ms in achieving\ntailored alignments for various applications.",
      "tldr_zh": "本研究将大语言模型（Large Language Models, LLMs）的监督微调（Supervised fine-tuning, SFT）和对齐过程表述为约束优化问题，以满足特定应用需求，而非依赖启发式方法。提出Lagrange Large Language Models (L3Ms)，通过对数屏障强制执行约束，实现模型在多样化应用中的定制化微调。实验结果证明，L3Ms在各种场景下有效实现了针对性的对齐优化，提升了模型的适用性和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "International Conference on Learning Representations (ICLR), 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.21533v3",
      "published_date": "2024-10-28 21:02:13 UTC",
      "updated_date": "2025-03-16 10:12:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:28:42.575503"
    },
    {
      "arxiv_id": "2410.23310v1",
      "title": "Moral Agency in Silico: Exploring Free Will in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Morgan S. Porter"
      ],
      "abstract": "This study investigates the potential of deterministic systems, specifically\nlarge language models (LLMs), to exhibit the functional capacities of moral\nagency and compatibilist free will. We develop a functional definition of free\nwill grounded in Dennett's compatibilist framework, building on an\ninterdisciplinary theoretical foundation that integrates Shannon's information\ntheory, Dennett's compatibilism, and Floridi's philosophy of information. This\nframework emphasizes the importance of reason-responsiveness and value\nalignment in determining moral responsibility rather than requiring\nmetaphysical libertarian free will. Shannon's theory highlights the role of\nprocessing complex information in enabling adaptive decision-making, while\nFloridi's philosophy reconciles these perspectives by conceptualizing agency as\na spectrum, allowing for a graduated view of moral status based on a system's\ncomplexity and responsiveness. Our analysis of LLMs' decision-making in moral\ndilemmas demonstrates their capacity for rational deliberation and their\nability to adjust choices in response to new information and identified\ninconsistencies. Thus, they exhibit features of a moral agency that align with\nour functional definition of free will. These results challenge traditional\nviews on the necessity of consciousness for moral responsibility, suggesting\nthat systems with self-referential reasoning capacities can instantiate degrees\nof free will and moral reasoning in artificial and biological contexts. This\nstudy proposes a parsimonious framework for understanding free will as a\nspectrum that spans artificial and biological systems, laying the groundwork\nfor further interdisciplinary research on agency and ethics in the artificial\nintelligence era.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 作为确定性系统是否能体现道德代理和兼容主义自由意志 (compatibilist free will) 的功能特性。作者基于丹尼特的兼容主义框架 (Dennett's compatibilism)，整合了香农的信息理论 (Shannon's information theory) 和弗洛里迪的信息哲学 (Floridi's philosophy of information)，定义了自由意志作为一种强调理性响应和价值对齐的谱系概念，而非依赖形而上学的自由意志。分析结果显示，LLMs 在道德困境中能进行理性审议并根据新信息调整决策，从而展现出与该功能定义相符的道德代理特征。该研究挑战了意识对道德责任的传统要求，并为理解人工和生物系统中的自由意志光谱提供了简约框架，推动了人工智能时代代理与伦理的跨学科研究。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23310v1",
      "published_date": "2024-10-28 20:48:14 UTC",
      "updated_date": "2024-10-28 20:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:28:55.496009"
    },
    {
      "arxiv_id": "2410.21521v2",
      "title": "A Multi-Agent Reinforcement Learning Testbed for Cognitive Radio Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Sriniketh Vangaru",
        "Daniel Rosen",
        "Dylan Green",
        "Raphael Rodriguez",
        "Maxwell Wiecek",
        "Amos Johnson",
        "Alyse M. Jones",
        "William C. Headley"
      ],
      "abstract": "Technological trends show that Radio Frequency Reinforcement Learning (RFRL)\nwill play a prominent role in the wireless communication systems of the future.\nApplications of RFRL range from military communications jamming to enhancing\nWiFi networks. Before deploying algorithms for these purposes, they must be\ntrained in a simulation environment to ensure adequate performance. For this\nreason, we previously created the RFRL Gym: a standardized, accessible tool for\nthe development and testing of reinforcement learning (RL) algorithms in the\nwireless communications space. This environment leveraged the OpenAI Gym\nframework and featured customizable simulation scenarios within the RF\nspectrum. However, the RFRL Gym was limited to training a single RL agent per\nsimulation; this is not ideal, as most real-world RF scenarios will contain\nmultiple intelligent agents in cooperative, competitive, or mixed settings,\nwhich is a natural consequence of spectrum congestion. Therefore, through\nintegration with Ray RLlib, multi-agent reinforcement learning (MARL)\nfunctionality for training and assessment has been added to the RFRL Gym,\nmaking it even more of a robust tool for RF spectrum simulation. This paper\nprovides an overview of the updated RFRL Gym environment. In this work, the\ngeneral framework of the tool is described relative to comparable existing\nresources, highlighting the significant additions and refactoring we have\napplied to the Gym. Afterward, results from testing various RF scenarios in the\nMARL environment and future additions are discussed.",
      "tldr_zh": "该研究介绍了更新后的 RFRL Gym，这是一个用于无线通信领域的强化学习测试平台，旨在解决单代理训练的局限性，以适应现实中多代理（MARL）场景如合作、竞争或混合设置。研究者通过整合 Ray RLlib，将 RFRL Gym 扩展为支持多代理强化学习的功能，使其更适合模拟拥挤的 RF 频谱环境。相比原有基于 OpenAI Gym 的版本，该更新突出了框架的鲁棒性，并在各种 RF 场景中进行了测试，展示了显著的性能提升。最后，该工具为未来 RFRL 应用如军事通信和 WiFi 增强提供了更全面的开发和评估基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE CCNC 2025. Added revisions from paper reviews",
      "pdf_url": "http://arxiv.org/pdf/2410.21521v2",
      "published_date": "2024-10-28 20:45:52 UTC",
      "updated_date": "2024-12-02 19:49:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:29:07.119928"
    },
    {
      "arxiv_id": "2410.22367v3",
      "title": "MAMMAL -- Molecular Aligned Multi-Modal Architecture and Language",
      "title_zh": "MAMMAL：分子对齐多模态架构和语言",
      "authors": [
        "Yoel Shoshan",
        "Moshiko Raboh",
        "Michal Ozery-Flato",
        "Vadim Ratner",
        "Alex Golts",
        "Jeffrey K. Weber",
        "Ella Barkan",
        "Simona Rabinovici-Cohen",
        "Sagi Polaczek",
        "Ido Amos",
        "Ben Shapira",
        "Liam Hazan",
        "Matan Ninio",
        "Sivan Ravid",
        "Michael M. Danziger",
        "Yosi Shamay",
        "Sharon Kurant",
        "Joseph A. Morrone",
        "Parthasarathy Suryanarayanan",
        "Michal Rosen-Zvi",
        "Efrat Hexter"
      ],
      "abstract": "Large language models applied to vast biological datasets have the potential\nto transform biology by uncovering disease mechanisms and accelerating drug\ndevelopment. However, current models are often siloed, trained separately on\nsmall-molecules, proteins, or transcriptomic data, limiting their ability to\ncapture complex, multi-modal interactions. Effective drug discovery requires\ncomputational tools that integrate multiple biological entities while\nsupporting prediction and generation, a challenge existing models struggle to\naddress. For this purpose, we present MAMMAL - Molecular Aligned Multi-Modal\nArchitecture and Language - a versatile method applied to create a multi-task\nfoundation model that learns from large-scale biological datasets across\ndiverse modalities, including proteins, small-molecules, and omics. MAMMAL's\nstructured prompt syntax supports classification, regression, and generation\ntasks while handling token and scalar inputs and outputs. Evaluated on eleven\ndiverse downstream tasks, it reaches a new state of the art (SOTA) in nine\ntasks and is comparable to SOTA in two tasks, all within a unified\narchitecture, unlike prior task-specific models. Additionally, we explored\nAlphafold 3 binding prediction capabilities on antibody-antigen and\nnanobody-antigen complexes showing significantly better classification\nperformance of MAMMAL in 3 out of 4 targets. The model code and pretrained\nweights are publicly available at\nhttps://github.com/BiomedSciAI/biomed-multi-alignment and\nhttps://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m",
      "tldr_zh": "该研究针对生物学领域的数据孤岛问题，提出了MAMMAL（Molecular Aligned Multi-Modal Architecture and Language）框架，这是一种多模态基础模型，能够从大规模数据集（如蛋白质、小分子和组学数据）中学习，并整合多种生物实体以支持预测和生成任务。\nMAMMAL采用结构化的提示语法，处理标记和标量输入输出，并适用于分类、回归和生成等多种任务。\n在11个下游任务的评估中，MAMMAL达到了9个新SOTA（state-of-the-art），并在Alphafold 3的结合预测任务中表现出显著优势，为药物发现和疾病机制研究提供了更有效的工具，模型代码和预训练权重已公开可用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22367v3",
      "published_date": "2024-10-28 20:45:52 UTC",
      "updated_date": "2025-05-06 07:46:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:29:20.337888"
    },
    {
      "arxiv_id": "2410.21514v1",
      "title": "Sabotage Evaluations for Frontier Models",
      "title_zh": "针对前沿模型的破坏评估",
      "authors": [
        "Joe Benton",
        "Misha Wagner",
        "Eric Christiansen",
        "Cem Anil",
        "Ethan Perez",
        "Jai Srivastav",
        "Esin Durmus",
        "Deep Ganguli",
        "Shauna Kravec",
        "Buck Shlegeris",
        "Jared Kaplan",
        "Holden Karnofsky",
        "Evan Hubinger",
        "Roger Grosse",
        "Samuel R. Bowman",
        "David Duvenaud"
      ],
      "abstract": "Sufficiently capable models could subvert human oversight and decision-making\nin important contexts. For example, in the context of AI development, models\ncould covertly sabotage efforts to evaluate their own dangerous capabilities,\nto monitor their behavior, or to make decisions about their deployment. We\nrefer to this family of abilities as sabotage capabilities. We develop a set of\nrelated threat models and evaluations. These evaluations are designed to\nprovide evidence that a given model, operating under a given set of\nmitigations, could not successfully sabotage a frontier model developer or\nother large organization's activities in any of these ways. We demonstrate\nthese evaluations on Anthropic's Claude 3 Opus and Claude 3.5 Sonnet models.\nOur results suggest that for these models, minimal mitigations are currently\nsufficient to address sabotage risks, but that more realistic evaluations and\nstronger mitigations seem likely to be necessary soon as capabilities improve.\nWe also survey related evaluations we tried and abandoned. Finally, we discuss\nthe advantages of mitigation-aware capability evaluations, and of simulating\nlarge-scale deployments using small-scale statistics.",
      "tldr_zh": "这篇论文探讨了前沿模型(frontier models)可能破坏人类监督和决策的风险，特别是模型的破坏能力(sabotage capabilities)，如秘密干扰AI评估、监控或部署决策。作者开发了一系列威胁模型和评估方法，以验证给定模型在特定缓解措施(mitigations)下是否能成功破坏组织活动，并在Anthropic的Claude 3 Opus和Claude 3.5 Sonnet模型上进行了测试。结果显示，目前这些模型只需最小缓解措施即可应对破坏风险，但随着模型能力提升，可能需要更现实的评估和更强的缓解措施；论文还讨论了缓解感知能力评估的优势以及使用小规模统计模拟大规模部署的益处。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21514v1",
      "published_date": "2024-10-28 20:34:51 UTC",
      "updated_date": "2024-10-28 20:34:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:29:31.560789"
    },
    {
      "arxiv_id": "2410.21508v1",
      "title": "Efficient Training of Sparse Autoencoders for Large Language Models via Layer Groups",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Ghilardi",
        "Federico Belotti",
        "Marco Molinari"
      ],
      "abstract": "Sparse AutoEnocders (SAEs) have recently been employed as an unsupervised\napproach for understanding the inner workings of Large Language Models (LLMs).\nThey reconstruct the model's activations with a sparse linear combination of\ninterpretable features. However, training SAEs is computationally intensive,\nespecially as models grow in size and complexity. To address this challenge, we\npropose a novel training strategy that reduces the number of trained SAEs from\none per layer to one for a given group of contiguous layers. Our experimental\nresults on Pythia 160M highlight a speedup of up to 6x without compromising the\nreconstruction quality and performance on downstream tasks. Therefore, layer\nclustering presents an efficient approach to train SAEs in modern LLMs.",
      "tldr_zh": "该论文提出了一种高效训练策略，用于在大型语言模型(LLMs)中训练Sparse Autoencoders (SAEs)，以理解模型的内部机制。传统SAEs需要为每个层单独训练，而新方法通过将连续层分组，只为每个层组训练一个SAE，从而显著减少计算开销。在Pythia 160M模型上的实验显示，这种策略实现了高达6倍的速度提升，同时保持了激活重构质量和下游任务性能。总之，层聚类方法为现代LLMs的SAE训练提供了高效且可靠的途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21508v1",
      "published_date": "2024-10-28 20:23:30 UTC",
      "updated_date": "2024-10-28 20:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:30:07.882010"
    },
    {
      "arxiv_id": "2410.21494v1",
      "title": "Towards Multi-dimensional Explanation Alignment for Medical Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Lijie Hu",
        "Songning Lai",
        "Wenshuo Chen",
        "Hongru Xiao",
        "Hongbin Lin",
        "Lu Yu",
        "Jingfeng Zhang",
        "Di Wang"
      ],
      "abstract": "The lack of interpretability in the field of medical image analysis has\nsignificant ethical and legal implications. Existing interpretable methods in\nthis domain encounter several challenges, including dependency on specific\nmodels, difficulties in understanding and visualization, as well as issues\nrelated to efficiency. To address these limitations, we propose a novel\nframework called Med-MICN (Medical Multi-dimensional Interpretable Concept\nNetwork). Med-MICN provides interpretability alignment for various angles,\nincluding neural symbolic reasoning, concept semantics, and saliency maps,\nwhich are superior to current interpretable methods. Its advantages include\nhigh prediction accuracy, interpretability across multiple dimensions, and\nautomation through an end-to-end concept labeling process that reduces the need\nfor extensive human training effort when working with new datasets. To\ndemonstrate the effectiveness and interpretability of Med-MICN, we apply it to\nfour benchmark datasets and compare it with baselines. The results clearly\ndemonstrate the superior performance and interpretability of our Med-MICN.",
      "tldr_zh": "该研究针对医疗图像分类中可解释性不足的伦理和法律问题，提出了一种新型框架Med-MICN（Medical Multi-dimensional Interpretable Concept Network）。Med-MICN通过神经符号推理（neural symbolic reasoning）、概念语义（concept semantics）和显著性图（saliency maps）等多维度解释对齐，解决了现有方法的模型依赖性、可视化困难和效率问题。框架的优势在于高预测准确性、自动化端到端概念标记过程减少人工干预，并在四个基准数据集上实验证明，其性能和可解释性均优于基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21494v1",
      "published_date": "2024-10-28 20:03:19 UTC",
      "updated_date": "2024-10-28 20:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:30:20.016315"
    },
    {
      "arxiv_id": "2410.21491v3",
      "title": "Trustworthiness of Stochastic Gradient Descent in Distributed Learning",
      "title_zh": "随机梯度下降在分布式学习中的可信度",
      "authors": [
        "Hongyang Li",
        "Caesar Wu",
        "Mohammed Chadli",
        "Said Mammar",
        "Pascal Bouvry"
      ],
      "abstract": "Distributed learning (DL) uses multiple nodes to accelerate training,\nenabling efficient optimization of large-scale models. Stochastic Gradient\nDescent (SGD), a key optimization algorithm, plays a central role in this\nprocess. However, communication bottlenecks often limit scalability and\nefficiency, leading to increasing adoption of compressed SGD techniques to\nalleviate these challenges. Despite addressing communication overheads,\ncompressed SGD introduces trustworthiness concerns, as gradient exchanges among\nnodes are vulnerable to attacks like gradient inversion (GradInv) and\nmembership inference attacks (MIA). The trustworthiness of compressed SGD\nremains unexplored, leaving important questions about its reliability\nunanswered.\n  In this paper, we provide a trustworthiness evaluation of compressed versus\nuncompressed SGD. Specifically, we conducted empirical studies using GradInv\nattacks, revealing that compressed SGD demonstrates significantly higher\nresistance to privacy leakage compared to uncompressed SGD. In addition, our\nfindings suggest that MIA may not be a reliable metric for assessing privacy\nrisks in distributed learning.",
      "tldr_zh": "本研究评估了分布式学习（Distributed Learning, DL）中随机梯度下降（Stochastic Gradient Descent, SGD）的可信度，重点比较了压缩 SGD 与未压缩 SGD 在面对隐私攻击时的表现。作者通过实证实验，使用梯度反演攻击（GradInv）发现，压缩 SGD 比未压缩 SGD 具有显著更高的隐私泄露抵抗力，从而缓解了通信瓶颈带来的风险。此外，研究结果表明，会员推断攻击（MIA）可能不是评估 DL 中隐私风险的可靠指标，为改进 SGD 的安全性和效率提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21491v3",
      "published_date": "2024-10-28 20:02:05 UTC",
      "updated_date": "2025-04-29 12:30:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:30:32.571755"
    },
    {
      "arxiv_id": "2410.21490v1",
      "title": "Can Large Language Models Act as Symbolic Reasoners?",
      "title_zh": "大型语言模型能否充当符号推理器？",
      "authors": [
        "Rob Sullivan",
        "Nelly Elsayed"
      ],
      "abstract": "The performance of Large language models (LLMs) across a broad range of\ndomains has been impressive but have been critiqued as not being able to reason\nabout their process and conclusions derived. This is to explain the conclusions\ndraw, and also for determining a plan or strategy for their approach. This\npaper explores the current research in investigating symbolic reasoning and\nLLMs, and whether an LLM can inherently provide some form of reasoning or\nwhether supporting components are necessary, and, if there is evidence for a\nreasoning capability, is this evident in a specific domain or is this a general\ncapability? In addition, this paper aims to identify the current research gaps\nand future trends of LLM explainability, presenting a review of the literature,\nidentifying current research into this topic and suggests areas for future\nwork.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否能够充当符号推理器，重点审查其在解释过程、得出结论和制定策略方面的能力。论文通过文献综述评估了 LLMs 是否具备内在的符号推理能力，以及是否需要额外支持组件（如辅助工具），并分析这种能力是特定领域还是通用。最终，论文识别了 LLMs 可解释性的当前研究空白，并提出未来趋势和潜在研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, currently under review",
      "pdf_url": "http://arxiv.org/pdf/2410.21490v1",
      "published_date": "2024-10-28 20:01:50 UTC",
      "updated_date": "2024-10-28 20:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:30:44.164960"
    },
    {
      "arxiv_id": "2410.21487v1",
      "title": "Enhancing CTR Prediction in Recommendation Domain with Search Query Representation",
      "title_zh": "利用搜索查询表示增强推荐领域的点击通过率预测",
      "authors": [
        "Yuening Wang",
        "Man Chen",
        "Yaochen Hu",
        "Wei Guo",
        "Yingxue Zhang",
        "Huifeng Guo",
        "Yong Liu",
        "Mark Coates"
      ],
      "abstract": "Many platforms, such as e-commerce websites, offer both search and\nrecommendation services simultaneously to better meet users' diverse needs.\nRecommendation services suggest items based on user preferences, while search\nservices allow users to search for items before providing recommendations.\nSince users and items are often shared between the search and recommendation\ndomains, there is a valuable opportunity to enhance the recommendation domain\nby leveraging user preferences extracted from the search domain. Existing\napproaches either overlook the shift in user intention between these domains or\nfail to capture the significant impact of learning from users' search queries\non understanding their interests.\n  In this paper, we propose a framework that learns from user search query\nembeddings within the context of user preferences in the recommendation domain.\nSpecifically, user search query sequences from the search domain are used to\npredict the items users will click at the next time point in the recommendation\ndomain. Additionally, the relationship between queries and items is explored\nthrough contrastive learning. To address issues of data sparsity, the diffusion\nmodel is incorporated to infer positive items the user will select after\nsearching with certain queries in a denoising manner, which is particularly\neffective in preventing false positives. Effectively extracting this\ninformation, the queries are integrated into click-through rate prediction in\nthe recommendation domain. Experimental analysis demonstrates that our model\noutperforms state-of-the-art models in the recommendation domain.",
      "tldr_zh": "该研究针对电商等平台上搜索和推荐领域的用户共享问题，提出了一种框架，通过利用搜索查询表示来提升推荐领域的点击通过率（CTR）预测。具体地，该框架使用用户搜索查询序列预测推荐领域的下一个点击物品，并通过对比学习（Contrastive Learning）探索查询与物品的关系，同时引入扩散模型（Diffusion Model）处理数据稀疏问题，以去噪方式推断用户偏好并减少假阳性。实验结果表明，该模型在推荐领域表现优于现有最先进模型，为跨领域用户意图整合提供了有效方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by CIKM 2024 Full Research Track",
      "pdf_url": "http://arxiv.org/pdf/2410.21487v1",
      "published_date": "2024-10-28 19:52:09 UTC",
      "updated_date": "2024-10-28 19:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:30:56.086029"
    },
    {
      "arxiv_id": "2411.00023v2",
      "title": "Device-Directed Speech Detection for Follow-up Conversations Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ognjen",
        "Rudovic",
        "Pranay Dighe",
        "Yi Su",
        "Vineet Garg",
        "Sameer Dharur",
        "Xiaochuan Niu",
        "Ahmed H. Abdelaziz",
        "Saurabh Adya",
        "Ahmed Tewfik"
      ],
      "abstract": "Follow-up conversations with virtual assistants (VAs) enable a user to\nseamlessly interact with a VA without the need to repeatedly invoke it using a\nkeyword (after the first query). Therefore, accurate Device-directed Speech\nDetection (DDSD) from the follow-up queries is critical for enabling\nnaturalistic user experience. To this end, we explore the notion of Large\nLanguage Models (LLMs) and model the first query when making inference about\nthe follow-ups (based on the ASR-decoded text), via prompting of a pretrained\nLLM, or by adapting a binary classifier on top of the LLM. In doing so, we also\nexploit the ASR uncertainty when designing the LLM prompts. We show on the\nreal-world dataset of follow-up conversations that this approach yields large\ngains (20-40% reduction in false alarms at 10% fixed false rejects) due to the\njoint modeling of the previous speech context and ASR uncertainty, compared to\nwhen follow-ups are modeled alone.",
      "tldr_zh": "该研究针对虚拟助手（VAs）的后续对话，提出了一种使用Large Language Models (LLMs)改进Device-Directed Speech Detection (DDSD)的方法，以避免用户重复唤醒关键词。方法通过结合第一个查询的上下文和ASR不确定性，采用LLM提示或在LLM上构建二元分类器来进行推理建模。实验结果显示，在真实数据集上，这种联合建模方式比单独处理后续查询减少了20-40%的误报率（在10%的固定误拒率下），显著提升了用户交互的自然性和准确性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00023v2",
      "published_date": "2024-10-28 19:43:43 UTC",
      "updated_date": "2024-11-04 19:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:31:07.999925"
    },
    {
      "arxiv_id": "2410.21480v1",
      "title": "AiSciVision: A Framework for Specializing Large Multimodal Models in Scientific Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Brendan Hogan",
        "Anmol Kabra",
        "Felipe Siqueira Pacheco",
        "Laura Greenstreet",
        "Joshua Fan",
        "Aaron Ferber",
        "Marta Ummus",
        "Alecsander Brito",
        "Olivia Graham",
        "Lillian Aoki",
        "Drew Harvell",
        "Alex Flecker",
        "Carla Gomes"
      ],
      "abstract": "Trust and interpretability are crucial for the use of Artificial Intelligence\n(AI) in scientific research, but current models often operate as black boxes\noffering limited transparency and justifications for their outputs. We\nintroduce AiSciVision, a framework that specializes Large Multimodal Models\n(LMMs) into interactive research partners and classification models for image\nclassification tasks in niche scientific domains. Our framework uses two key\ncomponents: (1) Visual Retrieval-Augmented Generation (VisRAG) and (2)\ndomain-specific tools utilized in an agentic workflow. To classify a target\nimage, AiSciVision first retrieves the most similar positive and negative\nlabeled images as context for the LMM. Then the LMM agent actively selects and\napplies tools to manipulate and inspect the target image over multiple rounds,\nrefining its analysis before making a final prediction. These VisRAG and\ntooling components are designed to mirror the processes of domain experts, as\nhumans often compare new data to similar examples and use specialized tools to\nmanipulate and inspect images before arriving at a conclusion. Each inference\nproduces both a prediction and a natural language transcript detailing the\nreasoning and tool usage that led to the prediction. We evaluate AiSciVision on\nthree real-world scientific image classification datasets: detecting the\npresence of aquaculture ponds, diseased eelgrass, and solar panels. Across\nthese datasets, our method outperforms fully supervised models in low and\nfull-labeled data settings. AiSciVision is actively deployed in real-world use,\nspecifically for aquaculture research, through a dedicated web application that\ndisplays and allows the expert users to converse with the transcripts. This\nwork represents a crucial step toward AI systems that are both interpretable\nand effective, advancing their use in scientific research and scientific\ndiscovery.",
      "tldr_zh": "我们介绍了 AiSciVision 框架，用于将 Large Multimodal Models (LMMs) 专用于科学图像分类任务，从而提升 AI 的信任度和可解释性。该框架的核心组件包括 Visual Retrieval-Augmented Generation (VisRAG)，用于检索相似正负样本图像作为上下文，以及领域特定工具的代理工作流，支持多轮图像操作和分析，以模仿专家决策过程。每个推理输出不仅包括预测，还生成自然语言记录详细说明推理步骤。在三个真实数据集（如水产养殖池和病害鳗草检测）上，AiSciVision 在低标签和全标签设置下均优于完全监督模型，并已部署于实际水产研究应用中，推动了可解释 AI 在科学发现中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21480v1",
      "published_date": "2024-10-28 19:35:47 UTC",
      "updated_date": "2024-10-28 19:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:31:22.648092"
    },
    {
      "arxiv_id": "2410.21479v1",
      "title": "TransformLLM: Adapting Large Language Models via LLM-Transformed Reading Comprehension Text",
      "title_zh": "翻译失败",
      "authors": [
        "Iftach Arbel",
        "Yehonathan Refael",
        "Ofir Lindenbaum"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in highly-specialized\ndomains, however challenges are still present in aspects of accuracy and costs.\nThese limitations restrict the usage of existing models in domain-specific\ntasks. While fine-tuning pre-trained models have shown promising results, this\nprocess can be computationally expensive and require massive datasets of the\nspecialized application in hand. In this work, we bridge that gap. We have\ndeveloped Phi-2-Legal and Mistral-Legal-7B, which are language models\nspecifically designed for legal applications. These models are based on Phi-2\nand Mistral-7B-v0.1, and have gone through continued pre-training with over 500\nmillion tokens of legal texts. Our innovative approach significantly improves\ncapabilities in legal tasks by using Large Language Models (LLMs) to convert\nraw training data into reading comprehension text. Our legal LLMs have\ndemonstrated superior performance in legal benchmarks, even outperforming\nmodels trained on much larger datasets with more resources. This work\nemphasizes the effectiveness of continued pre-training on domain-specific\ntexts, while using affordable LLMs for data conversion, which gives these\nmodels domain expertise while retaining general language understanding\ncapabilities. While this work uses the legal domain as a test case, our method\ncan be scaled and applied to any pre-training dataset, resulting in significant\nimprovements across different tasks. These findings underscore the potential of\ndomain-adaptive pre-training and reading comprehension for the development of\nhighly effective domain-specific language models.",
      "tldr_zh": "这篇论文提出了 TransformLLM 方法，通过使用 Large Language Models (LLMs) 将原始训练数据转换为阅读 comprehension text，从而高效适应 LLMs 于特定领域任务，解决准确性和成本挑战。研究开发了 Phi-2-Legal 和 Mistral-Legal-7B 模型，这些基于 Phi-2 和 Mistral-7B-v0.1 的变体，通过超过 5 亿 tokens 的法律文本继续预训练（continued pre-training），在法律基准测试中表现出色，甚至优于使用更大数据集的模型。该方法证明了在领域特定文本上进行预训练的效力，同时保留了通用语言理解能力，并可扩展应用于其他领域以提升模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21479v1",
      "published_date": "2024-10-28 19:32:18 UTC",
      "updated_date": "2024-10-28 19:32:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:31:33.147594"
    },
    {
      "arxiv_id": "2410.21478v1",
      "title": "Knowledge Distillation for Real-Time Classification of Early Media in Voice Communications",
      "title_zh": "知识蒸馏用于语音通信中早期媒体的实时分类",
      "authors": [
        "Kemal Altwlkany",
        "Hadžem Hadžić",
        "Amar Kurić",
        "Emanuel Lacic"
      ],
      "abstract": "This paper investigates the industrial setting of real-time classification of\nearly media exchanged during the initialization phase of voice calls. We\nexplore the application of state-of-the-art audio tagging models and highlight\nsome limitations when applied to the classification of early media. While most\nexisting approaches leverage convolutional neural networks, we propose a novel\napproach for low-resource requirements based on gradient-boosted trees. Our\napproach not only demonstrates a substantial improvement in runtime\nperformance, but also exhibits a comparable accuracy. We show that leveraging\nknowledge distillation and class aggregation techniques to train a simpler and\nsmaller model accelerates the classification of early media in voice calls. We\nprovide a detailed analysis of the results on a proprietary and publicly\navailable dataset, regarding accuracy and runtime performance. We additionally\nreport a case study of the achieved performance improvements at a regional data\ncenter in India.",
      "tldr_zh": "这篇论文探讨了实时分类语音通话初始化阶段的早期媒体问题，指出现有基于卷积神经网络(convolutional neural networks)的音频标记模型在资源需求和性能上存在局限。作者提出了一种新型方法，利用梯度提升树(gradient-boosted trees)结合知识蒸馏(knowledge distillation)和类聚合(class aggregation)技术，训练更简单高效的模型，从而显著提升运行时性能，同时保持可比的准确率。在专有和公开数据集上进行的实验分析，以及印度区域数据中心的案例研究，证明了该方法的实际改进潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS",
        "I.2.0"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21478v1",
      "published_date": "2024-10-28 19:32:17 UTC",
      "updated_date": "2024-10-28 19:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:31:45.602807"
    },
    {
      "arxiv_id": "2410.21474v2",
      "title": "Estimating Causal Effects of Text Interventions Leveraging LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Siyi Guo",
        "Myrl G. Marmarelis",
        "Fred Morstatter",
        "Kristina Lerman"
      ],
      "abstract": "Quantifying the effects of textual interventions in social systems, such as\nreducing anger in social media posts to see its impact on engagement, is\nchallenging. Real-world interventions are often infeasible, necessitating\nreliance on observational data. Traditional causal inference methods, typically\ndesigned for binary or discrete treatments, are inadequate for handling the\ncomplex, high-dimensional textual data. This paper addresses these challenges\nby proposing CausalDANN, a novel approach to estimate causal effects using text\ntransformations facilitated by large language models (LLMs). Unlike existing\nmethods, our approach accommodates arbitrary textual interventions and\nleverages text-level classifiers with domain adaptation ability to produce\nrobust effect estimates against domain shifts, even when only the control group\nis observed. This flexibility in handling various text interventions is a key\nadvancement in causal estimation for textual data, offering opportunities to\nbetter understand human behaviors and develop effective interventions within\nsocial systems.",
      "tldr_zh": "本研究解决了量化文本干预（如减少社交媒体帖子愤怒对参与度的影响）所面临的挑战，因为现实干预不可行且传统因果推断方法不适合处理高维文本数据。作者提出 CausalDANN，一种新方法，利用大型语言模型 (LLMs) 进行文本转换，并结合文本级分类器和领域适应技术，即使只观察控制组，也能产生鲁棒的因果效果估计。该方法支持任意文本干预，提供灵活性，有助于更好地理解人类行为并开发有效的社会系统干预。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21474v2",
      "published_date": "2024-10-28 19:19:35 UTC",
      "updated_date": "2025-03-20 23:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:33:56.399148"
    },
    {
      "arxiv_id": "2410.21471v2",
      "title": "AdvI2I: Adversarial Image Attack on Image-to-Image Diffusion models",
      "title_zh": "AdvI2I：针对图像到图像扩散模型的对抗图像攻击",
      "authors": [
        "Yaopei Zeng",
        "Yuanpu Cao",
        "Bochuan Cao",
        "Yurui Chang",
        "Jinghui Chen",
        "Lu Lin"
      ],
      "abstract": "Recent advances in diffusion models have significantly enhanced the quality\nof image synthesis, yet they have also introduced serious safety concerns,\nparticularly the generation of Not Safe for Work (NSFW) content. Previous\nresearch has demonstrated that adversarial prompts can be used to generate NSFW\ncontent. However, such adversarial text prompts are often easily detectable by\ntext-based filters, limiting their efficacy. In this paper, we expose a\npreviously overlooked vulnerability: adversarial image attacks targeting\nImage-to-Image (I2I) diffusion models. We propose AdvI2I, a novel framework\nthat manipulates input images to induce diffusion models to generate NSFW\ncontent. By optimizing a generator to craft adversarial images, AdvI2I\ncircumvents existing defense mechanisms, such as Safe Latent Diffusion (SLD),\nwithout altering the text prompts. Furthermore, we introduce AdvI2I-Adaptive,\nan enhanced version that adapts to potential countermeasures and minimizes the\nresemblance between adversarial images and NSFW concept embeddings, making the\nattack more resilient against defenses. Through extensive experiments, we\ndemonstrate that both AdvI2I and AdvI2I-Adaptive can effectively bypass current\nsafeguards, highlighting the urgent need for stronger security measures to\naddress the misuse of I2I diffusion models.",
      "tldr_zh": "本研究揭示了 Image-to-Image (I2I) 扩散模型的潜在漏洞，提出 AdvI2I 框架，通过优化 generator 来生成对抗图像，从而诱导扩散模型产生 Not Safe for Work (NSFW) 内容，而无需修改文本提示，这有效地绕过了现有防御机制如 Safe Latent Diffusion (SLD)。AdvI2I-Adaptive 是框架的增强版本，能适应潜在的 countermeasures 并最小化对抗图像与 NSFW 概念嵌入的相似性，提高攻击的隐蔽性和 resilience。此外，实验结果显示，AdvI2I 和其变体在多种场景下成功绕过安全措施，强调了加强 I2I 扩散模型安全性的迫切需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21471v2",
      "published_date": "2024-10-28 19:15:06 UTC",
      "updated_date": "2024-11-01 17:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:34:10.145313"
    },
    {
      "arxiv_id": "2410.22366v2",
      "title": "Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders",
      "title_zh": "剖析 SDXL Turbo：使用稀疏自动编码器解读文本到图像模型",
      "authors": [
        "Viacheslav Surkov",
        "Chris Wendler",
        "Mikhail Terekhov",
        "Justin Deschenaux",
        "Robert West",
        "Caglar Gulcehre"
      ],
      "abstract": "Sparse autoencoders (SAEs) have become a core ingredient in the reverse\nengineering of large-language models (LLMs). For LLMs, they have been shown to\ndecompose intermediate representations that often are not interpretable\ndirectly into sparse sums of interpretable features, facilitating better\ncontrol and subsequent analysis. However, similar analyses and approaches have\nbeen lacking for text-to-image models. We investigated the possibility of using\nSAEs to learn interpretable features for a few-step text-to-image diffusion\nmodels, such as SDXL Turbo. To this end, we train SAEs on the updates performed\nby transformer blocks within SDXL Turbo's denoising U-net. We find that their\nlearned features are interpretable, causally influence the generation process,\nand reveal specialization among the blocks. In particular, we find one block\nthat deals mainly with image composition, one that is mainly responsible for\nadding local details, and one for color, illumination, and style. Therefore,\nour work is an important first step towards better understanding the internals\nof generative text-to-image models like SDXL Turbo and showcases the potential\nof features learned by SAEs for the visual domain.\n  Code is available at https://github.com/surkovv/sdxl-unbox",
      "tldr_zh": "本研究使用 Sparse Autoencoders (SAEs) 来反向工程文本到图像模型（如 SDXL Turbo），旨在将模型的中间表示分解为稀疏且可解释的特征，以提升对生成过程的理解和控制。研究者通过在 SDXL Turbo 的 denoising U-net 中的 transformer 块上训练 SAEs，发现这些特征不仅能影响图像生成，还揭示了块间的专业化：一个块主要处理图像合成，另一个负责添加局部细节，第三个则管理颜色、光照和风格。与大型语言模型类似，此方法为文本到图像模型的内部分析提供了新途径，并展示了 SAEs 在视觉领域的潜力。代码可从 GitHub 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22366v2",
      "published_date": "2024-10-28 19:01:18 UTC",
      "updated_date": "2024-12-11 20:01:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:34:19.695721"
    },
    {
      "arxiv_id": "2410.23308v1",
      "title": "Systematically Analyzing Prompt Injection Vulnerabilities in Diverse LLM Architectures",
      "title_zh": "系统分析多种LLM架构中的提示注入漏洞",
      "authors": [
        "Victoria Benjamin",
        "Emily Braca",
        "Israel Carter",
        "Hafsa Kanchwala",
        "Nava Khojasteh",
        "Charly Landow",
        "Yi Luo",
        "Caroline Ma",
        "Anna Magarelli",
        "Rachel Mirin",
        "Avery Moyer",
        "Kayla Simpson",
        "Amelia Skawinski",
        "Thomas Heverin"
      ],
      "abstract": "This study systematically analyzes the vulnerability of 36 large language\nmodels (LLMs) to various prompt injection attacks, a technique that leverages\ncarefully crafted prompts to elicit malicious LLM behavior. Across 144 prompt\ninjection tests, we observed a strong correlation between model parameters and\nvulnerability, with statistical analyses, such as logistic regression and\nrandom forest feature analysis, indicating that parameter size and architecture\nsignificantly influence susceptibility. Results revealed that 56 percent of\ntests led to successful prompt injections, emphasizing widespread vulnerability\nacross various parameter sizes, with clustering analysis identifying distinct\nvulnerability profiles associated with specific model configurations.\nAdditionally, our analysis uncovered correlations between certain prompt\ninjection techniques, suggesting potential overlaps in vulnerabilities. These\nfindings underscore the urgent need for robust, multi-layered defenses in LLMs\ndeployed across critical infrastructure and sensitive industries. Successful\nprompt injection attacks could result in severe consequences, including data\nbreaches, unauthorized access, or misinformation. Future research should\nexplore multilingual and multi-step defenses alongside adaptive mitigation\nstrategies to strengthen LLM security in diverse, real-world environments.",
      "tldr_zh": "这篇论文系统分析了36个大型语言模型(LLMs)对各种提示注入攻击的漏洞，通过144个测试评估了这些攻击如何诱导恶意行为。研究发现，56%的测试成功，统计方法如logistic regression和random forest分析显示，模型参数大小和架构是关键影响因素，并通过聚类分析识别了特定模型配置的漏洞模式。结果强调了LLMs在关键基础设施中的广泛风险，呼吁开发多层防御策略，并建议未来研究探索多语言和多步缓解措施以提升安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.23308v1",
      "published_date": "2024-10-28 18:55:21 UTC",
      "updated_date": "2024-10-28 18:55:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:34:32.063715"
    },
    {
      "arxiv_id": "2410.21443v2",
      "title": "TACO: Adversarial Camouflage Optimization on Trucks to Fool Object Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Adonisz Dimitriu",
        "Tamás Michaletzky",
        "Viktor Remeli"
      ],
      "abstract": "Adversarial attacks threaten the reliability of machine learning models in\ncritical applications like autonomous vehicles and defense systems. As object\ndetectors become more robust with models like YOLOv8, developing effective\nadversarial methodologies is increasingly challenging. We present Truck\nAdversarial Camouflage Optimization (TACO), a novel framework that generates\nadversarial camouflage patterns on 3D vehicle models to deceive\nstate-of-the-art object detectors. Adopting Unreal Engine 5, TACO integrates\ndifferentiable rendering with a Photorealistic Rendering Network to optimize\nadversarial textures targeted at YOLOv8. To ensure the generated textures are\nboth effective in deceiving detectors and visually plausible, we introduce the\nConvolutional Smooth Loss function, a generalized smooth loss function.\nExperimental evaluations demonstrate that TACO significantly degrades YOLOv8's\ndetection performance, achieving an AP@0.5 of 0.0099 on unseen test data.\nFurthermore, these adversarial patterns exhibit strong transferability to other\nobject detection models such as Faster R-CNN and earlier YOLO versions.",
      "tldr_zh": "该研究提出TACO框架，通过在卡车3D模型上优化对抗性伪装图案，来欺骗先进的物体检测器如YOLOv8。TACO利用Unreal Engine 5结合可微渲染和Photorealistic Rendering Network生成纹理，并引入Convolutional Smooth Loss函数，确保图案既有效又视觉上合理。实验结果显示，TACO使YOLOv8在未见测试数据上的AP@0.5降至0.0099，并展现出对Faster R-CNN和早期YOLO版本的强转移性，从而提升了对抗攻击的可靠性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This version matches the final published version in Big Data and\n  Cognitive Computing (MDPI). Please cite the journal version when referencing\n  this work (doi: https://doi.org/10.3390/bdcc9030072)",
      "pdf_url": "http://arxiv.org/pdf/2410.21443v2",
      "published_date": "2024-10-28 18:40:06 UTC",
      "updated_date": "2025-04-11 12:13:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:36:38.301028"
    },
    {
      "arxiv_id": "2410.21418v1",
      "title": "Large Language Models for Manufacturing",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwei Li",
        "Huaqin Zhao",
        "Hanqi Jiang",
        "Yi Pan",
        "Zhengliang Liu",
        "Zihao Wu",
        "Peng Shu",
        "Jie Tian",
        "Tianze Yang",
        "Shaochen Xu",
        "Yanjun Lyu",
        "Parker Blenk",
        "Jacob Pence",
        "Jason Rupram",
        "Eliza Banu",
        "Ninghao Liu",
        "Linbing Wang",
        "Wenzhan Song",
        "Xiaoming Zhai",
        "Kenan Song",
        "Dajiang Zhu",
        "Beiwen Li",
        "Xianqiao Wang",
        "Tianming Liu"
      ],
      "abstract": "The rapid advances in Large Language Models (LLMs) have the potential to\ntransform manufacturing industry, offering new opportunities to optimize\nprocesses, improve efficiency, and drive innovation. This paper provides a\ncomprehensive exploration of the integration of LLMs into the manufacturing\ndomain, focusing on their potential to automate and enhance various aspects of\nmanufacturing, from product design and development to quality control, supply\nchain optimization, and talent management. Through extensive evaluations across\nmultiple manufacturing tasks, we demonstrate the remarkable capabilities of\nstate-of-the-art LLMs, such as GPT-4V, in understanding and executing complex\ninstructions, extracting valuable insights from vast amounts of data, and\nfacilitating knowledge sharing. We also delve into the transformative potential\nof LLMs in reshaping manufacturing education, automating coding processes,\nenhancing robot control systems, and enabling the creation of immersive,\ndata-rich virtual environments through the industrial metaverse. By\nhighlighting the practical applications and emerging use cases of LLMs in\nmanufacturing, this paper aims to provide a valuable resource for\nprofessionals, researchers, and decision-makers seeking to harness the power of\nthese technologies to address real-world challenges, drive operational\nexcellence, and unlock sustainable growth in an increasingly competitive\nlandscape.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在制造业中的应用潜力，涵盖从产品设计、质量控制到供应链优化和人才管理的自动化与增强。通过对多种任务的广泛评估（如使用 GPT-4V），论文展示了 LLMs 在理解复杂指令、提取数据洞见和促进知识共享方面的卓越能力。论文还强调了 LLMs 在重塑制造业教育、自动化编码、机器人控制系统以及构建工业元宇宙的变革作用，为专业人士提供资源以应对实际挑战并推动可持续增长。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21418v1",
      "published_date": "2024-10-28 18:13:47 UTC",
      "updated_date": "2024-10-28 18:13:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:34:55.596095"
    },
    {
      "arxiv_id": "2410.21415v2",
      "title": "Deploying Ten Thousand Robots: Scalable Imitation Learning for Lifelong Multi-Agent Path Finding",
      "title_zh": "翻译失败",
      "authors": [
        "He Jiang",
        "Yutong Wang",
        "Rishi Veerapaneni",
        "Tanishq Duhan",
        "Guillaume Sartoretti",
        "Jiaoyang Li"
      ],
      "abstract": "Lifelong Multi-Agent Path Finding (LMAPF) repeatedly finds collision-free\npaths for multiple agents that are continually assigned new goals when they\nreach current ones. Recently, this field has embraced learning-based methods,\nwhich reactively generate single-step actions based on individual local\nobservations. However, it is still challenging for them to match the\nperformance of the best search-based algorithms, especially in large-scale\nsettings. This work proposes an imitation-learning-based LMAPF solver that\nintroduces a novel communication module as well as systematic single-step\ncollision resolution and global guidance techniques. Our proposed solver,\nScalable Imitation Learning for LMAPF (SILLM), inherits the fast reasoning\nspeed of learning-based methods and the high solution quality of search-based\nmethods with the help of modern GPUs. Across six large-scale maps with up to\n10,000 agents and varying obstacle structures, SILLM surpasses the best\nlearning- and search-based baselines, achieving average throughput improvements\nof 137.7% and 16.0%, respectively. Furthermore, SILLM also beats the winning\nsolution of the 2023 League of Robot Runners, an international LMAPF\ncompetition. Finally, we validated SILLM with 10 real robots and 100 virtual\nrobots in a mock warehouse environment.",
      "tldr_zh": "该研究针对 Lifelong Multi-Agent Path Finding (LMAPF) 问题，提出了一种可扩展的模仿学习框架 SILLM，用于持续为多达 10,000 个代理分配无碰撞路径。SILLM 引入新型通信模块、单步碰撞解析和全局指导技术，利用 GPUs 结合学习方法的快速推理与搜索方法的解决方案质量。实验结果显示，在六个大规模地图上，SILLM 比最佳学习基线提高 137.7% 的平均吞吐量、比搜索基线提高 16.0%，并击败了 2023 League of Robot Runners 比赛的获胜方案，同时在真实环境中使用 10 个机器人和 100 个虚拟机器人进行了验证。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted by ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.21415v2",
      "published_date": "2024-10-28 18:13:15 UTC",
      "updated_date": "2025-05-18 01:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:35:09.451896"
    },
    {
      "arxiv_id": "2410.21414v1",
      "title": "CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Zhao",
        "Tianhao Cheng",
        "Yuejie Zhang",
        "Ying Cheng",
        "Rui Feng",
        "Xiaobo Zhang"
      ],
      "abstract": "Multimodal Question Answering (MMQA) is crucial as it enables comprehensive\nunderstanding and accurate responses by integrating insights from diverse data\nrepresentations such as tables, charts, and text. Most existing researches in\nMMQA only focus on two modalities such as image-text QA, table-text QA and\nchart-text QA, and there remains a notable scarcity in studies that investigate\nthe joint analysis of text, tables, and charts. In this paper, we present\nC$\\text{T}^2$C-QA, a pioneering Chinese reasoning-based QA dataset that\nincludes an extensive collection of text, tables, and charts, meticulously\ncompiled from 200 selectively sourced webpages. Our dataset simulates real\nwebpages and serves as a great test for the capability of the model to analyze\nand reason with multimodal data, because the answer to a question could appear\nin various modalities, or even potentially not exist at all. Additionally, we\npresent AED (\\textbf{A}llocating, \\textbf{E}xpert and \\textbf{D}esicion), a\nmulti-agent system implemented through collaborative deployment, information\ninteraction, and collective decision-making among different agents.\nSpecifically, the Assignment Agent is in charge of selecting and activating\nexpert agents, including those proficient in text, tables, and charts. The\nDecision Agent bears the responsibility of delivering the final verdict,\ndrawing upon the analytical insights provided by these expert agents. We\nexecute a comprehensive analysis, comparing AED with various state-of-the-art\nmodels in MMQA, including GPT-4. The experimental outcomes demonstrate that\ncurrent methodologies, including GPT-4, are yet to meet the benchmarks set by\nour dataset.",
      "tldr_zh": "该论文提出了CT2C-QA，一种基于中文的多模态问答(Multimodal Question Answering, MMQA)数据集，包含文本、表格和图表，从200个网页中编译而成，用于测试模型对多模态数据的分析和推理能力。作者开发了AED（Allocating, Expert and Decision）多智能体系统，通过Assignment Agent分配任务、Expert Agents处理特定模态数据，以及Decision Agent整合分析结果，实现协作决策。实验结果显示，现有先进模型包括GPT-4在该数据集上表现不佳，突显了当前MMQA技术的局限性，并为未来研究提供了新基准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.21414v1",
      "published_date": "2024-10-28 18:13:14 UTC",
      "updated_date": "2024-10-28 18:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:35:20.796059"
    },
    {
      "arxiv_id": "2410.21407v1",
      "title": "Exploring reinforcement learning for incident response in autonomous military vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Henrik Madsen",
        "Gudmund Grov",
        "Federico Mancini",
        "Magnus Baksaas",
        "Åvald Åslaugson Sommervoll"
      ],
      "abstract": "Unmanned vehicles able to conduct advanced operations without human\nintervention are being developed at a fast pace for many purposes. Not\nsurprisingly, they are also expected to significantly change how military\noperations can be conducted. To leverage the potential of this new technology\nin a physically and logically contested environment, security risks are to be\nassessed and managed accordingly. Research on this topic points to autonomous\ncyber defence as one of the capabilities that may be needed to accelerate the\nadoption of these vehicles for military purposes. Here, we pursue this line of\ninvestigation by exploring reinforcement learning to train an agent that can\nautonomously respond to cyber attacks on unmanned vehicles in the context of a\nmilitary operation. We first developed a simple simulation environment to\nquickly prototype and test some proof-of-concept agents for an initial\nevaluation. This agent was then applied to a more realistic simulation\nenvironment and finally deployed on an actual unmanned ground vehicle for even\nmore realism. A key contribution of our work is demonstrating that\nreinforcement learning is a viable approach to train an agent that can be used\nfor autonomous cyber defence on a real unmanned ground vehicle, even when\ntrained in a simple simulation environment.",
      "tldr_zh": "这篇论文探讨了使用 reinforcement learning 训练代理，以实现自主军事车辆在网络攻击下的自动响应。研究者首先开发了一个简单模拟环境来原型化和测试代理，然后将其应用到更现实的模拟环境，并最终部署到实际无人地面车辆上。关键贡献在于证明 reinforcement learning 是一种可行的方法，即使在简单模拟环境中训练，代理也能有效支持 autonomous cyber defence，从而加速无人车辆在军事领域的采用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CR",
      "comment": "DIGILIENCE 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21407v1",
      "published_date": "2024-10-28 18:08:23 UTC",
      "updated_date": "2024-10-28 18:08:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:35:32.770678"
    },
    {
      "arxiv_id": "2410.21403v1",
      "title": "Unveiling the Role of Expert Guidance: A Comparative Analysis of User-centered Imitation Learning and Traditional Reinforcement Learning",
      "title_zh": "揭示专家指导的作用：用户中心模仿学习与传统强化学习的比较分析",
      "authors": [
        "Amr Gomaa",
        "Bilal Mahdy"
      ],
      "abstract": "Integration of human feedback plays a key role in improving the learning\ncapabilities of intelligent systems. This comparative study delves into the\nperformance, robustness, and limitations of imitation learning compared to\ntraditional reinforcement learning methods within these systems. Recognizing\nthe value of human-in-the-loop feedback, we investigate the influence of expert\nguidance and suboptimal demonstrations on the learning process. Through\nextensive experimentation and evaluations conducted in a pre-existing\nsimulation environment using the Unity platform, we meticulously analyze the\neffectiveness and limitations of these learning approaches. The insights gained\nfrom this study contribute to the advancement of human-centered artificial\nintelligence by highlighting the benefits and challenges associated with the\nincorporation of human feedback into the learning process. Ultimately, this\nresearch promotes the development of models that can effectively address\ncomplex real-world problems.",
      "tldr_zh": "这篇论文比较了以用户为中心的imitation learning和传统reinforcement learning在性能、鲁棒性和局限性方面的差异，重点探讨了专家指导和次优演示对智能系统学习过程的影响。研究通过在Unity模拟环境中进行广泛实验，分析了这些方法的有效性及其面临的挑战。结果表明，融入人类反馈能显著提升系统的学习能力，但也暴露了潜在问题，从而为以人为中心的AI发展提供重要见解，并促进处理复杂现实问题的模型优化。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as CEUR Workshop Proceedings in Proceedings of the 1st\n  International Workshop on Human-in-the-Loop Applied Machine Learning (HITLAML\n  2023). Awarded Best Paper. https://ceur-ws.org/Vol-3524/paper1.pdf",
      "pdf_url": "http://arxiv.org/pdf/2410.21403v1",
      "published_date": "2024-10-28 18:07:44 UTC",
      "updated_date": "2024-10-28 18:07:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:35:44.265427"
    },
    {
      "arxiv_id": "2410.21275v1",
      "title": "Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Benavent-Lledo",
        "David Mulero-Pérez",
        "David Ortiz-Perez",
        "Jose Garcia-Rodriguez",
        "Antonis Argyros"
      ],
      "abstract": "The sequential execution of actions and their hierarchical structure\nconsisting of different levels of abstraction, provide features that remain\nunexplored in the task of action recognition. In this study, we present a novel\napproach to improve action recognition by exploiting the hierarchical\norganization of actions and by incorporating contextualized textual\ninformation, including location and prior actions to reflect the sequential\ncontext. To achieve this goal, we introduce a novel transformer architecture\ntailored for action recognition that utilizes both visual and textual features.\nVisual features are obtained from RGB and optical flow data, while text\nembeddings represent contextual information. Furthermore, we define a joint\nloss function to simultaneously train the model for both coarse and\nfine-grained action recognition, thereby exploiting the hierarchical nature of\nactions. To demonstrate the effectiveness of our method, we extend the Toyota\nSmarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducing\nthe Hierarchical TSU dataset. We also conduct an ablation study to assess the\nimpact of different methods for integrating contextual and hierarchical data on\naction recognition performance. Results show that the proposed approach\noutperforms pre-trained SOTA methods when trained with the same\nhyperparameters. Moreover, they also show a 17.12% improvement in top-1\naccuracy over the equivalent fine-grained RGB version when using ground-truth\ncontextual information, and a 5.33% improvement when contextual information is\nobtained from actual predictions.",
      "tldr_zh": "这篇论文提出了一种新方法，通过利用行动的层次结构和文本上下文（如位置和先前行动）来提升行动识别（action recognition）性能。方法引入一个新型 Transformer 架构，结合 RGB 和 optical flow 的视觉特征以及文本嵌入（text embeddings），并使用联合损失函数（joint loss function）同时训练粗粒度和细粒度识别，以充分利用行动的层次组织。实验在扩展的 Hierarchical TSU 数据集上表明，该方法优于预训练的 SOTA 方法，使用 ground-truth 上下文信息时 top-1 准确率提高 17.12%，而使用实际预测的上下文信息时提升 5.33%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21275v1",
      "published_date": "2024-10-28 17:59:35 UTC",
      "updated_date": "2024-10-28 17:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:35:57.355379"
    },
    {
      "arxiv_id": "2410.21271v3",
      "title": "EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Shih-Yang Liu",
        "Maksim Khadkevich",
        "Nai Chit Fung",
        "Charbel Sakr",
        "Chao-Han Huck Yang",
        "Chien-Yi Wang",
        "Saurav Muralidharan",
        "Hongxu Yin",
        "Kwang-Ting Cheng",
        "Jan Kautz",
        "Yu-Chiang Frank Wang",
        "Pavlo Molchanov",
        "Min-Hung Chen"
      ],
      "abstract": "In this work, we re-formulate the model compression problem into the\ncustomized compensation problem: Given a compressed model, we aim to introduce\nresidual low-rank paths to compensate for compression errors under customized\nrequirements from users (e.g., tasks, compression ratios), resulting in greater\nflexibility in balancing accuracy and overhead(inference and model size)\nwithout being bound to fixed compression formats. However, naively applying SVD\nto derive residual paths causes suboptimal utilization of the low-rank\nrepresentation capacity. Instead, we propose Training-free Eigenspace Low-Rank\nApproximation (EoRA), a method that directly minimizes compression-induced\nerrors without requiring gradient-based training, achieving fast optimization\nin minutes using a small amount of calibration data. EoRA projects compression\nerrors into the eigenspace of input activations, leveraging eigenvalues to\neffectively prioritize the reconstruction of high-importance error components.\nMoreover, EoRA can be seamlessly integrated with fine-tuning and quantization\nto further improve effectiveness and efficiency. EoRA consistently outperforms\nprevious methods in compensating errors for compressed LLaMA2/3 models on\nvarious tasks, such as language generation, commonsense reasoning, and math\nreasoning tasks (e.g., 31.31%/12.88% and 9.69% improvements on\nARC-Easy/ARC-Challenge and MathQA when compensating LLaMA3-8B that is quantized\nto 4-bit and pruned to 2:4 sparsity). EoRA offers a scalable, training-free\nsolution to compensate for compression errors, making it a powerful tool to\ndeploy LLMs more flexibly. Code is available at https://github.com/NVlabs/EoRA.",
      "tldr_zh": "本文提出 EoRA 方法，将模型压缩问题转化为定制补偿问题，通过 Eigenspace Low-Rank Approximation 无需训练地引入残差低秩路径来补偿压缩错误，从而在任务和压缩比率下灵活平衡准确性和开销。EoRA 将压缩错误投影到输入激活的特征空间，利用特征值优先重建高重要性组件，并可无缝整合微调和量化技术。实验结果显示，EoRA 在补偿压缩的 LLaMA2/3 模型时表现出色，例如在量化到 4-bit 和修剪到 2:4 稀疏度的 LLaMA3-8B 上，在 ARC-Easy/ARC-Challenge 和 MathQA 任务上分别提升 31.31%、12.88% 和 9.69%。这一训练-free 方案为 LLM 的可扩展部署提供了强大工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21271v3",
      "published_date": "2024-10-28 17:59:03 UTC",
      "updated_date": "2025-02-24 07:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:36:52.119806"
    },
    {
      "arxiv_id": "2410.21264v1",
      "title": "LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyu Wang",
        "Saksham Suri",
        "Yixuan Ren",
        "Hao Chen",
        "Abhinav Shrivastava"
      ],
      "abstract": "We present LARP, a novel video tokenizer designed to overcome limitations in\ncurrent video tokenization methods for autoregressive (AR) generative models.\nUnlike traditional patchwise tokenizers that directly encode local visual\npatches into discrete tokens, LARP introduces a holistic tokenization scheme\nthat gathers information from the visual content using a set of learned\nholistic queries. This design allows LARP to capture more global and semantic\nrepresentations, rather than being limited to local patch-level information.\nFurthermore, it offers flexibility by supporting an arbitrary number of\ndiscrete tokens, enabling adaptive and efficient tokenization based on the\nspecific requirements of the task. To align the discrete token space with\ndownstream AR generation tasks, LARP integrates a lightweight AR transformer as\na training-time prior model that predicts the next token on its discrete latent\nspace. By incorporating the prior model during training, LARP learns a latent\nspace that is not only optimized for video reconstruction but is also\nstructured in a way that is more conducive to autoregressive generation.\nMoreover, this process defines a sequential order for the discrete tokens,\nprogressively pushing them toward an optimal configuration during training,\nensuring smoother and more accurate AR generation at inference time.\nComprehensive experiments demonstrate LARP's strong performance, achieving\nstate-of-the-art FVD on the UCF101 class-conditional video generation\nbenchmark. LARP enhances the compatibility of AR models with videos and opens\nup the potential to build unified high-fidelity multimodal large language\nmodels (MLLMs).",
      "tldr_zh": "该论文提出LARP，一种新型视频分词器，旨在克服传统补丁式分词器在自回归(AR)生成模型中的局限，通过学习的全局查询捕获更全面的语义表示，并支持任意数量的离散标记以实现自适应分词。LARP整合了一个轻量级AR transformer作为训练时的先验模型，优化离散潜在空间以提升视频重建和生成效率，确保标记顺序有利于平滑的AR生成。实验结果显示，LARP在UCF101数据集上实现了最先进的FVD性能，并提升了AR模型与视频的兼容性，为构建统一的高保真多模态大语言模型(MLLMs)提供了新潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://hywang66.github.io/larp/",
      "pdf_url": "http://arxiv.org/pdf/2410.21264v1",
      "published_date": "2024-10-28 17:57:07 UTC",
      "updated_date": "2024-10-28 17:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:37:03.008969"
    },
    {
      "arxiv_id": "2410.21262v2",
      "title": "BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference",
      "title_zh": "BLAST：块级自适应结构化矩阵用于高效深度神经网络推理",
      "authors": [
        "Changwoo Lee",
        "Soo Min Kwon",
        "Qing Qu",
        "Hun-Seok Kim"
      ],
      "abstract": "Large-scale foundation models have demonstrated exceptional performance in\nlanguage and vision tasks. However, the numerous dense matrix-vector operations\ninvolved in these large networks pose significant computational challenges\nduring inference. To address these challenges, we introduce the Block-Level\nAdaptive STructured (BLAST) matrix, designed to learn and leverage efficient\nstructures prevalent in the weight matrices of linear layers within deep\nlearning models. Compared to existing structured matrices, the BLAST matrix\noffers substantial flexibility, as it can represent various types of structures\nthat are either learned from data or computed from pre-existing weight\nmatrices. We demonstrate the efficiency of using the BLAST matrix for\ncompressing both language and vision tasks, showing that (i) for medium-sized\nmodels such as ViT and GPT-2, training with BLAST weights boosts performance\nwhile reducing complexity by 70% and 40%, respectively; and (ii) for large\nfoundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x\ncompression while exhibiting the lowest performance degradation among all\ntested structured matrices. Our code is available at\nhttps://github.com/changwoolee/BLAST.",
      "tldr_zh": "该研究引入了BLAST matrix，一种块级自适应结构矩阵，用于优化深度神经网络推理中的密集矩阵向量操作，从而解决大型基础模型计算挑战。BLAST matrix 能够从数据中学习或从现有权重矩阵计算各种高效结构，提供比传统结构矩阵更大的灵活性。在实验中，对于中等规模模型如 ViT 和 GPT-2，使用 BLAST 权重提升了性能，同时分别减少了 70% 和 40% 的复杂度；对于大型模型如 Llama-7B 和 DiT-XL，它实现了 2x 压缩并显示最低性能下降。代码已在 https://github.com/changwoolee/BLAST 公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21262v2",
      "published_date": "2024-10-28 17:56:18 UTC",
      "updated_date": "2024-10-30 00:38:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:37:15.686346"
    },
    {
      "arxiv_id": "2410.21259v4",
      "title": "AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?",
      "title_zh": "AutoBench-V: 大型视觉语言模型能否自我基准测试？",
      "authors": [
        "Han Bao",
        "Yue Huang",
        "Yanbo Wang",
        "Jiayi Ye",
        "Xiangqi Wang",
        "Xiuying Chen",
        "Yue Zhao",
        "Tianyi Zhou",
        "Mohamed Elhoseiny",
        "Xiangliang Zhang"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) have become essential for advancing the\nintegration of visual and linguistic information. However, the evaluation of\nLVLMs presents significant challenges as the evaluation benchmark always\ndemands lots of human cost for its construction, and remains static, lacking\nflexibility once constructed. Even though automatic evaluation has been\nexplored in textual modality, the visual modality remains under-explored. As a\nresult, in this work, we address a question: \"Can LVLMs themselves be used to\nbenchmark each other in the visual automatically domain?\". We introduce\nAutoBench-V, an automated framework for serving evaluation on demand, i.e.,\nbenchmarking LVLMs based on specific aspects of model capability. AutoBench-V\nleverages text-to-image models to generate relevant image samples and then\nutilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing\nthe evaluation process efficiently and flexibly. Through an extensive\nevaluation of nine popular LVLMs across five demanded user inputs (i.e.,\nevaluation capabilities), the framework shows effectiveness and reliability.",
      "tldr_zh": "本研究探讨了Large Vision-Language Models (LVLMs) 是否能自动评估自身性能，以解决传统基准测试的人力成本高和静态不灵活的问题。论文引入AutoBench-V框架，该框架利用文本到图像模型生成相关图像样本，并通过LVLMs组织视觉问答(VQA)任务，实现按需评估特定模型能力。实验结果显示，AutoBench-V在对九个热门LVLMs的五种评估能力测试中表现出色，证明了其有效性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21259v4",
      "published_date": "2024-10-28 17:55:08 UTC",
      "updated_date": "2025-03-06 03:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:37:26.017791"
    },
    {
      "arxiv_id": "2410.21256v2",
      "title": "Multi-modal AI for comprehensive breast cancer prognostication",
      "title_zh": "多模态AI用于全面乳腺癌预后预测",
      "authors": [
        "Jan Witowski",
        "Ken G. Zeng",
        "Joseph Cappadona",
        "Jailan Elayoubi",
        "Khalil Choucair",
        "Elena Diana Chiru",
        "Nancy Chan",
        "Young-Joon Kang",
        "Frederick Howard",
        "Irina Ostrovnaya",
        "Carlos Fernandez-Granda",
        "Freya Schnabel",
        "Zoe Steinsnyder",
        "Ugur Ozerdem",
        "Kangning Liu",
        "Waleed Abdulsattar",
        "Yu Zong",
        "Lina Daoud",
        "Rafic Beydoun",
        "Anas Saad",
        "Nitya Thakore",
        "Mohammad Sadic",
        "Frank Yeung",
        "Elisa Liu",
        "Theodore Hill",
        "Benjamin Swett",
        "Danielle Rigau",
        "Andrew Clayburn",
        "Valerie Speirs",
        "Marcus Vetter",
        "Lina Sojak",
        "Simone Soysal",
        "Daniel Baumhoer",
        "Jia-Wern Pan",
        "Haslina Makmur",
        "Soo-Hwang Teo",
        "Linda Ma Pak",
        "Victor Angel",
        "Dovile Zilenaite-Petrulaitiene",
        "Arvydas Laurinavicius",
        "Natalie Klar",
        "Brian D. Piening",
        "Carlo Bifulco",
        "Sun-Young Jun",
        "Jae Pak Yi",
        "Su Hyun Lim",
        "Adam Brufsky",
        "Francisco J. Esteva",
        "Lajos Pusztai",
        "Yann LeCun",
        "Krzysztof J. Geras"
      ],
      "abstract": "Treatment selection in breast cancer is guided by molecular subtypes and\nclinical characteristics. However, current tools including genomic assays lack\nthe accuracy required for optimal clinical decision-making. We developed a\nnovel artificial intelligence (AI)-based approach that integrates digital\npathology images with clinical data, providing a more robust and effective\nmethod for predicting the risk of cancer recurrence in breast cancer patients.\nSpecifically, we utilized a vision transformer pan-cancer foundation model\ntrained with self-supervised learning to extract features from digitized\nH&E-stained slides. These features were integrated with clinical data to form a\nmulti-modal AI test predicting cancer recurrence and death. The test was\ndeveloped and evaluated using data from a total of 8,161 female breast cancer\npatients across 15 cohorts originating from seven countries. Of these, 3,502\npatients from five cohorts were used exclusively for evaluation, while the\nremaining patients were used for training. Our test accurately predicted our\nprimary endpoint, disease-free interval, in the five evaluation cohorts\n(C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.001]). In a direct\ncomparison (n=858), the AI test was more accurate than Oncotype DX, the\nstandard-of-care 21-gene assay, achieving a C-index of 0.67 [0.61-0.74] versus\n0.61 [0.49-0.73], respectively. Additionally, the AI test added independent\nprognostic information to Oncotype DX in a multivariate analysis (HR: 3.11\n[1.91-5.09, p<0.001)]). The test demonstrated robust accuracy across major\nmolecular breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81],\nHR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently\nrecommended by clinical guidelines. These results suggest that our AI test\nimproves upon the accuracy of existing prognostic tests, while being applicable\nto a wider range of patients.",
      "tldr_zh": "这篇论文提出了一种多模态 AI 方法，通过整合数字病理图像和临床数据，提高乳腺癌复发风险预测的准确性，旨在优化临床决策。方法利用 vision transformer 泛癌基础模型通过自监督学习从 H&E 染色切片提取特征，并与临床数据结合，形成预测测试。实验在 8161 名患者的数据上进行，结果显示该测试在评估队列中 C-index 为 0.71、HR 为 3.63，且比标准工具 Oncotype DX 更准确（C-index 0.67 vs 0.61），并在 TNBC 等分子亚型中提供独立预后信息。这些发现表明，该 AI 测试可提升现有预后工具的精确性，并适用于更广泛的患者群体。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21256v2",
      "published_date": "2024-10-28 17:54:29 UTC",
      "updated_date": "2025-03-03 03:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:37:39.821449"
    },
    {
      "arxiv_id": "2410.21249v1",
      "title": "Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Manav Vora",
        "Ilan Shomorony",
        "Melkior Ornik"
      ],
      "abstract": "Many real-world sequential repair problems can be effectively modeled using\nmonotonic Markov Decision Processes (MDPs), where the system state\nstochastically decreases and can only be increased by performing a restorative\naction. This work addresses the problem of solving multi-component monotonic\nMDPs with both budget and capacity constraints. The budget constraint limits\nthe total number of restorative actions and the capacity constraint limits the\nnumber of restorative actions that can be performed simultaneously. While prior\nmethods dealt with budget constraints, including capacity constraints in prior\nmethods leads to an exponential increase in computational complexity as the\nnumber of components in the MDP grows. We propose a two-step planning approach\nto address this challenge. First, we partition the components of the\nmulti-component MDP into groups, where the number of groups is determined by\nthe capacity constraint. We achieve this partitioning by solving a Linear Sum\nAssignment Problem (LSAP). Each group is then allocated a fraction of the total\nbudget proportional to its size. This partitioning effectively decouples the\nlarge multi-component MDP into smaller subproblems, which are computationally\nfeasible because the capacity constraint is simplified and the budget\nconstraint can be addressed using existing methods. Subsequently, we use a\nmeta-trained PPO agent to obtain an approximately optimal policy for each\ngroup. To validate our approach, we apply it to the problem of scheduling\nrepairs for a large group of industrial robots, constrained by a limited number\nof repair technicians and a total repair budget. Our results demonstrate that\nthe proposed method outperforms baseline approaches in terms of maximizing the\naverage uptime of the robot swarm, particularly for large swarm sizes.",
      "tldr_zh": "这篇论文针对预算和容量约束下的多组件单调 Markov Decision Processes (MDPs) 问题，提出了一种基于元强化学习(meta-RL) 的两步规划方法，以解决计算复杂度的指数级增长。方法首先使用 Linear Sum Assignment Problem (LSAP) 将组件分区成组，并根据容量约束分配预算，从而将大问题分解为可处理的子问题；随后，应用 meta-trained PPO 代理为每个组生成近似最优策略。实验结果显示，该方法在工业机器人修复调度场景中显著提高了机器人群的平均正常运行时间，尤其在大型群组中优于基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21249v1",
      "published_date": "2024-10-28 17:48:45 UTC",
      "updated_date": "2024-10-28 17:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:39:52.081619"
    },
    {
      "arxiv_id": "2410.21359v2",
      "title": "Can Machines Think Like Humans? A Behavioral Evaluation of LLM-Agents in Dictator Games",
      "title_zh": "机器能像人类一样思考吗？ LLM-Agents 在独裁者",
      "authors": [
        "Ji Ma"
      ],
      "abstract": "As Large Language Model (LLM)-based agents increasingly undertake real-world\ntasks and engage with human society, how well do we understand their behaviors?\nWe (1) investigate how LLM agents' prosocial behaviors -- a fundamental social\nnorm -- can be induced by different personas and benchmarked against human\nbehaviors; and (2) introduce a behavioral and social science approach to\nevaluate LLM agents' decision-making. We explored how different personas and\nexperimental framings affect these AI agents' altruistic behavior in dictator\ngames and compared their behaviors within the same LLM family, across various\nfamilies, and with human behaviors. The findings reveal substantial variations\nand inconsistencies among LLMs and notable differences compared to human\nbehaviors. Merely assigning a human-like identity to LLMs does not produce\nhuman-like behaviors. Despite being trained on extensive human-generated data,\nthese AI agents are unable to capture the internal processes of human\ndecision-making. Their alignment with human is highly variable and dependent on\nspecific model architectures and prompt formulations; even worse, such\ndependence does not follow a clear pattern. LLMs can be useful task-specific\ntools but are not yet intelligent human-like agents.",
      "tldr_zh": "本研究评估了大型语言模型（LLM-agents）在独裁者游戏（dictator games）中的行为，旨在探讨不同角色（personas）和实验框架如何影响其亲社会行为，并与人类行为进行基准比较。研究发现，LLM-agents 的行为在同一模型家族、不同家族间存在显著变异和不一致，与人类决策过程差异明显，即使赋予人类-like 身份也无法复制真实的人类行为。结果表明，LLM-agents 的表现高度依赖于特定模型架构和提示设计，但整体上缺乏稳定的内部决策机制，因此更适合作为任务特定工具而非智能人类代理。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21359v2",
      "published_date": "2024-10-28 17:47:41 UTC",
      "updated_date": "2024-12-16 20:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:40:02.383233"
    },
    {
      "arxiv_id": "2410.21242v1",
      "title": "Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Nour Jedidi",
        "Yung-Sung Chuang",
        "Leslie Shing",
        "James Glass"
      ],
      "abstract": "Building effective dense retrieval systems remains difficult when relevance\nsupervision is not available. Recent work has looked to overcome this challenge\nby using a Large Language Model (LLM) to generate hypothetical documents that\ncan be used to find the closest real document. However, this approach relies\nsolely on the LLM to have domain-specific knowledge relevant to the query,\nwhich may not be practical. Furthermore, generating hypothetical documents can\nbe inefficient as it requires the LLM to generate a large number of tokens for\neach query. To address these challenges, we introduce Real Document Embeddings\nfrom Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF\nproposes to re-frame hypothetical document generation as a relevance estimation\ntask, using an LLM to select which documents should be used for nearest\nneighbor search. Through this re-framing, the LLM no longer needs\ndomain-specific knowledge but only needs to judge what is relevant.\nAdditionally, relevance estimation only requires the LLM to output a single\ntoken, thereby improving search latency. Our experiments show that ReDE-RF\nconsistently surpasses state-of-the-art zero-shot dense retrieval methods\nacross a wide range of low-resource retrieval datasets while also making\nsignificant improvements in latency per-query.",
      "tldr_zh": "该论文提出了一种名为ReDE-RF的Zero-Shot Dense Retrieval方法，利用LLM进行相关性估计，以解决缺乏相关性监督时构建稠密检索系统的挑战。不同于传统方法，ReDE-RF将假设文档生成重新框架为相关性反馈任务，让LLM仅需输出一个token来判断文档的相关性，从而减少对LLM领域知识的依赖并显著降低查询延迟。实验结果显示，该方法在多种低资源检索数据集上超越现有最先进零-shot稠密检索技术，查询延迟也得到显著改善。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21242v1",
      "published_date": "2024-10-28 17:40:40 UTC",
      "updated_date": "2024-10-28 17:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:38:14.682332"
    },
    {
      "arxiv_id": "2410.21237v1",
      "title": "Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce",
      "title_zh": "翻译失败",
      "authors": [
        "Zhantao Yang",
        "Han Zhang",
        "Fangyi Chen",
        "Anudeepsekhar Bolimera",
        "Marios Savvides"
      ],
      "abstract": "Knowledge Graph (KG) is playing an increasingly important role in various AI\nsystems. For e-commerce, an efficient and low-cost automated knowledge graph\nconstruction method is the foundation of enabling various successful downstream\napplications. In this paper, we propose a novel method for constructing\nstructured product knowledge graphs from raw product images. The method\ncooperatively leverages recent advances in the vision-language model (VLM) and\nlarge language model (LLM), fully automating the process and allowing timely\ngraph updates. We also present a human-annotated e-commerce product dataset for\nbenchmarking product property extraction in knowledge graph construction. Our\nmethod outperforms our baseline in all metrics and evaluated properties,\ndemonstrating its effectiveness and bright usage potential.",
      "tldr_zh": "本研究提出了一种从产品图像构建分层知识图谱（KG）的创新方法，旨在为可扩展的电商应用提供高效、低成本的自动化KG构建方案。该方法通过整合视觉语言模型（VLM）和大型语言模型（LLM）的协同作用，实现全自动化过程，并支持及时图谱更新。同时，研究提供了一个人工标注的电商产品数据集，用于基准测试产品属性提取，在所有指标和评估属性上均优于基线模型，展示了其在电商领域的实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21237v1",
      "published_date": "2024-10-28 17:34:05 UTC",
      "updated_date": "2024-10-28 17:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:38:25.098033"
    },
    {
      "arxiv_id": "2410.21236v2",
      "title": "Flaming-hot Initiation with Regular Execution Sampling for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhe Chen",
        "Zhicheng Zhang",
        "Guanlin Liu",
        "Renjie Zheng",
        "Wenlei Shi",
        "Chen Dun",
        "Zheng Wu",
        "Xing Jin",
        "Lin Yan"
      ],
      "abstract": "Since the release of ChatGPT, large language models (LLMs) have demonstrated\nremarkable capabilities across various domains. A key challenge in developing\nthese general capabilities is efficiently sourcing diverse, high-quality data.\nThis becomes especially critical in reasoning-related tasks with sandbox\ncheckers, such as math or code, where the goal is to generate correct solutions\nto specific problems with higher probability. In this work, we introduce\nFlaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet\nhighly effective method to efficiently find good responses. Our empirical\nfindings show that FIRE sampling enhances inference-time generation quality and\nalso benefits training in the alignment stage. Furthermore, we explore how FIRE\nsampling improves performance by promoting diversity and analyze the impact of\nemploying FIRE at different positions within a response.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)开发中的数据来源挑战，特别是推理任务（如数学或代码），提出了一种简单有效的FIRE sampling方法，即Flaming-hot Initiation with Regular Execution采样，以高效生成高质量响应。实验结果表明，FIRE sampling显著提升了推理时的生成质量，并改善了训练阶段的校准过程，同时通过促进响应多样性来增强整体性能。该方法还分析了FIRE sampling在响应不同位置的应用影响，为LLMs的优化提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21236v2",
      "published_date": "2024-10-28 17:30:01 UTC",
      "updated_date": "2025-02-13 21:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:38:37.220379"
    },
    {
      "arxiv_id": "2411.00820v1",
      "title": "AutoGLM: Autonomous Foundation Agents for GUIs",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Bo Qin",
        "Dongzhu Liang",
        "Guang Dong",
        "Hanyu Lai",
        "Hanchen Zhang",
        "Hanlin Zhao",
        "Iat Long Iong",
        "Jiadai Sun",
        "Jiaqi Wang",
        "Junjie Gao",
        "Junjun Shan",
        "Kangning Liu",
        "Shudan Zhang",
        "Shuntian Yao",
        "Siyi Cheng",
        "Wentao Yao",
        "Wenyi Zhao",
        "Xinghan Liu",
        "Xinyi Liu",
        "Xinying Chen",
        "Xinyue Yang",
        "Yang Yang",
        "Yifan Xu",
        "Yu Yang",
        "Yujia Wang",
        "Yulin Xu",
        "Zehan Qi",
        "Yuxiao Dong",
        "Jie Tang"
      ],
      "abstract": "We present AutoGLM, a new series in the ChatGLM family, designed to serve as\nfoundation agents for autonomous control of digital devices through Graphical\nUser Interfaces (GUIs). While foundation models excel at acquiring human\nknowledge, they often struggle with decision-making in dynamic real-world\nenvironments, limiting their progress toward artificial general intelligence.\nThis limitation underscores the importance of developing foundation agents\ncapable of learning through autonomous environmental interactions by\nreinforcing existing models. Focusing on Web Browser and Phone as\nrepresentative GUI scenarios, we have developed AutoGLM as a practical\nfoundation agent system for real-world GUI interactions. Our approach\nintegrates a comprehensive suite of techniques and infrastructures to create\ndeployable agent systems suitable for user delivery. Through this development,\nwe have derived two key insights: First, the design of an appropriate\n\"intermediate interface\" for GUI control is crucial, enabling the separation of\nplanning and grounding behaviors, which require distinct optimization for\nflexibility and accuracy respectively. Second, we have developed a novel\nprogressive training framework that enables self-evolving online curriculum\nreinforcement learning for AutoGLM. Our evaluations demonstrate AutoGLM's\neffectiveness across multiple domains. For web browsing, AutoGLM achieves a\n55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second\nattempt) and 96.2% on OpenTable evaluation tasks. In Android device control,\nAutoGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on\ncommon tasks in popular Chinese APPs.",
      "tldr_zh": "本论文提出 AutoGLM，一种基于 ChatGLM 系列的自主基础代理系统，旨在通过 Graphical User Interfaces (GUIs) 实现数字设备的自主控制，解决基础模型在动态环境中的决策难题。AutoGLM 整合了中间接口 (intermediate interface) 设计来分离规划和接地行为，以及一个新型渐进式训练框架 (progressive training framework) 支持在线强化学习 (reinforcement learning)，从而实现代理的自进化。实验结果显示，AutoGLM 在 Web 浏览任务上取得 55.2% 的成功率（VAB-WebArena-Lite），并在 Android 设备控制上达到 36.2% 的成功率（AndroidLab），证明了其在多领域应用的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00820v1",
      "published_date": "2024-10-28 17:05:10 UTC",
      "updated_date": "2024-10-28 17:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:40:14.957042"
    },
    {
      "arxiv_id": "2410.21220v1",
      "title": "Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixin Zhang",
        "Yiyuan Zhang",
        "Xiaohan Ding",
        "Xiangyu Yue"
      ],
      "abstract": "Search engines enable the retrieval of unknown information with texts.\nHowever, traditional methods fall short when it comes to understanding\nunfamiliar visual content, such as identifying an object that the model has\nnever seen before. This challenge is particularly pronounced for large\nvision-language models (VLMs): if the model has not been exposed to the object\ndepicted in an image, it struggles to generate reliable answers to the user's\nquestion regarding that image. Moreover, as new objects and events continuously\nemerge, frequently updating VLMs is impractical due to heavy computational\nburdens. To address this limitation, we propose Vision Search Assistant, a\nnovel framework that facilitates collaboration between VLMs and web agents.\nThis approach leverages VLMs' visual understanding capabilities and web agents'\nreal-time information access to perform open-world Retrieval-Augmented\nGeneration via the web. By integrating visual and textual representations\nthrough this collaboration, the model can provide informed responses even when\nthe image is novel to the system. Extensive experiments conducted on both\nopen-set and closed-set QA benchmarks demonstrate that the Vision Search\nAssistant significantly outperforms the other models and can be widely applied\nto existing VLMs.",
      "tldr_zh": "本文提出 Vision Search Assistant 框架，将视觉语言模型（VLMs）与网络代理结合，构建多模态搜索引擎，以解决 VLMs 在处理未知视觉内容（如从未见过的物体）时的局限性。该框架通过 VLMs 的视觉理解能力和 web agents 的实时信息访问，实现开放世界的 Retrieval-Augmented Generation，利用网络检索增强生成准确响应。实验在开放集和封闭集 QA 基准上表明，该方法显著优于其他模型，并可广泛应用于现有 VLMs。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code is available at https://github.com/cnzzx/VSA",
      "pdf_url": "http://arxiv.org/pdf/2410.21220v1",
      "published_date": "2024-10-28 17:04:18 UTC",
      "updated_date": "2024-10-28 17:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:40:26.547709"
    },
    {
      "arxiv_id": "2410.21216v2",
      "title": "HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Chen",
        "Ang Lv",
        "Jian Luan",
        "Bin Wang",
        "Wei Liu"
      ],
      "abstract": "Many positional encodings (PEs) are designed to exhibit long-term decay,\nbased on an entrenched and long-standing inductive opinion: tokens farther away\nfrom the current position carry less relevant information. We argue that\nlong-term decay is outdated in the era of LLMs, as LLMs are now applied to\ntasks demanding precise retrieval of in-context information from arbitrary\npositions. Firstly, we present empirical analyses on various PEs, demonstrating\nthat models inherently learn attention with only a local-decay pattern while\nforming a U-shape pattern globally, contradicting the principle of long-term\ndecay. Furthermore, we conduct a detailed analysis of rotary position encoding\n(RoPE, a prevalent relative positional encoding in LLMs), and found that the\nU-shape attention is caused by some learned components, which are also the key\nfactor limiting RoPE's expressiveness and extrapolation.Inspired by these\ninsights, we propose High-frequency rotary Position Encoding (HoPE). HoPE\nreplaces the specific components in RoPE with position-independent ones,\nretaining only high-frequency signals, which also breaks the principle of\nlong-term decay in theory. HoPE achieves two major advantages: (1) Without\nconstraints imposed by long-term decay, contradictory factors that limit\nspontaneous attention optimization and model extrapolation performance are\nremoved. (2) Components representing positions and semantics are are optimized.\nThese enhances model's context awareness and extrapolation, as validated by\nextensive experiments.",
      "tldr_zh": "该论文质疑了传统位置编码 (PEs) 的长期衰减假设，认为在大型语言模型 (LLMs) 时代，这种设计已不适合需要从任意位置精确检索上下文信息的任务。通过实证分析，作者发现模型注意力模式呈现局部衰减和全局 U 形，而 Rotary Position Encoding (RoPE) 的局限性源于某些学习组件。基于这些洞见，提出 High-frequency rotary Position Encoding (HoPE)，它去除长期衰减的约束，仅保留高频信号，从而优化位置和语义组件，提升模型的上下文感知和外推能力。广泛实验验证了 HoPE 在这些方面的显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21216v2",
      "published_date": "2024-10-28 17:01:52 UTC",
      "updated_date": "2024-12-05 07:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:40:39.753807"
    },
    {
      "arxiv_id": "2410.21203v1",
      "title": "SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning",
      "title_zh": "SeriesGAN:",
      "authors": [
        "MohammadReza EskandariNasab",
        "Shah Muhammad Hamdi",
        "Soukaina Filali Boubrahimi"
      ],
      "abstract": "Current Generative Adversarial Network (GAN)-based approaches for time series\ngeneration face challenges such as suboptimal convergence, information loss in\nembedding spaces, and instability. To overcome these challenges, we introduce\nan advanced framework that integrates the advantages of an\nautoencoder-generated embedding space with the adversarial training dynamics of\nGANs. This method employs two discriminators: one to specifically guide the\ngenerator and another to refine both the autoencoder's and generator's output.\nAdditionally, our framework incorporates a novel autoencoder-based loss\nfunction and supervision from a teacher-forcing supervisor network, which\ncaptures the stepwise conditional distributions of the data. The generator\noperates within the latent space, while the two discriminators work on latent\nand feature spaces separately, providing crucial feedback to both the generator\nand the autoencoder. By leveraging this dual-discriminator approach, we\nminimize information loss in the embedding space. Through joint training, our\nframework excels at generating high-fidelity time series data, consistently\noutperforming existing state-of-the-art benchmarks both qualitatively and\nquantitatively across a range of real and synthetic multivariate time series\ndatasets.",
      "tldr_zh": "该研究提出SeriesGAN框架，通过结合autoencoder的嵌入空间与GAN的对抗训练，解决时间序列生成中的收敛不佳、信息丢失和不稳定性问题。框架引入两个鉴别器——一个指导生成器，另一个精炼autoencoder和生成器的输出——并采用新型autoencoder-based损失函数和teacher-forcing supervisor network来捕捉数据逐步条件分布。实验结果显示，SeriesGAN在多种真实和合成多变量时间序列数据集上，定性和定量上均优于现有基准，实现了高保真度的生成输出。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted at BigData 2024 on October 26, 2024, as a\n  regular paper for oral presentation",
      "pdf_url": "http://arxiv.org/pdf/2410.21203v1",
      "published_date": "2024-10-28 16:49:03 UTC",
      "updated_date": "2024-10-28 16:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:40:51.400688"
    },
    {
      "arxiv_id": "2410.21200v1",
      "title": "BongLLaMA: LLaMA for Bangla Language",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah Khan Zehady",
        "Safi Al Mamun",
        "Naymul Islam",
        "Santu Karmaker"
      ],
      "abstract": "Bangla (or \"Bengali\") is a language spoken by approximately 240 million\nnative speakers and around 300 million people worldwide. Despite being the 5th\nlargest spoken language in the world, Bangla is still a \"low-resource\"\nlanguage, and existing pretrained language models often struggle to perform\nwell on Bangla Language Processing (BLP) tasks. This work addresses this gap by\nintroducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model\nfine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.\nWe present our methodology, data augmentation techniques, fine-tuning details,\nand comprehensive benchmarking results showcasing the utility of BongLLaMA on\nBLP tasks. We believe BongLLaMA will serve as the new standard baseline for\nBangla Language Models and, thus, facilitate future benchmarking studies\nfocused on this widely-spoken yet \"low-resource\" language. All BongLLaMA models\nare available for public use at https://huggingface.co/BanglaLLM.",
      "tldr_zh": "这篇论文介绍了 BongLLaMA，一种针对 Bangla 语言的开源大语言模型，基于 LLaMA 模型在大型 Bangla 语料和指令调整数据集上进行微调，以解决 Bangla 作为低资源语言在 Bangla Language Processing (BLP) 任务中的性能不足问题。研究者采用数据增强技术和详细的微调方法，确保模型适应 Bangla 的语言特性。实验结果显示，BongLLaMA 在各种 BLP 任务上表现出色，并将作为新的标准基准，促进未来针对这一全球第五大语言的研究，所有模型已在 Hugging Face 上公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.21200v1",
      "published_date": "2024-10-28 16:44:02 UTC",
      "updated_date": "2024-10-28 16:44:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:41:03.209733"
    },
    {
      "arxiv_id": "2410.21195v1",
      "title": "Belief in the Machine: Investigating Epistemological Blind Spots of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mirac Suzgun",
        "Tayfun Gur",
        "Federico Bianchi",
        "Daniel E. Ho",
        "Thomas Icard",
        "Dan Jurafsky",
        "James Zou"
      ],
      "abstract": "As language models (LMs) become integral to fields like healthcare, law, and\njournalism, their ability to differentiate between fact, belief, and knowledge\nis essential for reliable decision-making. Failure to grasp these distinctions\ncan lead to significant consequences in areas such as medical diagnosis, legal\njudgments, and dissemination of fake news. Despite this, current literature has\nlargely focused on more complex issues such as theory of mind, overlooking more\nfundamental epistemic challenges. This study systematically evaluates the\nepistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and\nLlama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13\ntasks. Our results reveal key limitations. First, while LMs achieve 86%\naccuracy on factual scenarios, their performance drops significantly with false\nscenarios, particularly in belief-related tasks. Second, LMs struggle with\nrecognizing and affirming personal beliefs, especially when those beliefs\ncontradict factual data, which raises concerns for applications in healthcare\nand counseling, where engaging with a person's beliefs is critical. Third, we\nidentify a salient bias in how LMs process first-person versus third-person\nbeliefs, performing better on third-person tasks (80.7%) compared to\nfirst-person tasks (54.4%). Fourth, LMs lack a robust understanding of the\nfactive nature of knowledge, namely, that knowledge inherently requires truth.\nFifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the\ndeeper reasoning. These findings highlight significant concerns about current\nLMs' ability to reason about truth, belief, and knowledge while emphasizing the\nneed for advancements in these areas before broad deployment in critical\nsectors.",
      "tldr_zh": "这篇论文探讨了语言模型 (LMs) 在区分事实、信念和知识方面的认识论盲点，强调这些能力对可靠决策（如医疗诊断和法律判断）的必要性。研究者使用新数据集 KaBLE（包含 13,000 个问题和 13 个任务）系统评估了 GPT-4、Claude-3 和 Llama-3 等模型，发现 LMs 在事实场景中准确率达 86%，但在信念相关任务中表现显著下降，尤其难以处理与事实矛盾的个人信念或第一人称视角（准确率仅 54.4% 对比第三人称的 80.7%）。此外，LMs 缺乏对知识的 factive 性质的理解，并依赖语言线索而非深入推理，这些局限性突显了在关键领域部署 LMs 前的改进需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/suzgunmirac/belief-in-the-machine",
      "pdf_url": "http://arxiv.org/pdf/2410.21195v1",
      "published_date": "2024-10-28 16:38:20 UTC",
      "updated_date": "2024-10-28 16:38:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:41:16.940077"
    },
    {
      "arxiv_id": "2410.21175v1",
      "title": "Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang",
        "Jun Li",
        "Reachsak Ly",
        "Yunyi Liu",
        "Jiangpeng Shu"
      ],
      "abstract": "For structural health monitoring, continuous and automatic crack detection\nhas been a challenging problem. This study is conducted to propose a framework\nof automatic crack segmentation from high-resolution images containing crack\ninformation about steel box girders of bridges. Considering the multi-scale\nfeature of cracks, convolutional neural network architecture of Feature Pyramid\nNetworks (FPN) for crack detection is proposed. As for input, 120 raw images\nare processed via two approaches (shrinking the size of images and splitting\nimages into sub-images). Then, models with the proposed structure of FPN for\ncrack detection are developed. The result shows all developed models can\nautomatically detect the cracks at the raw images. By shrinking the images, the\ncomputation efficiency is improved without decreasing accuracy. Because of the\nseparable characteristic of crack, models using the splitting method provide\nmore accurate crack segmentations than models using the resizing method.\nTherefore, for high-resolution images, the FPN structure coupled with the\nsplitting method is an promising solution for the crack segmentation and\ndetection.",
      "tldr_zh": "这篇论文提出了一种基于深度学习的框架，使用 Feature Pyramid Networks (FPN) 架构来自动检测桥梁钢箱梁上的疲劳裂缝，针对裂缝的多尺度特征进行优化。研究使用120张高分辨率图像作为输入，通过缩小图像大小和将图像分割成子图像两种方法进行预处理，以开发裂缝检测模型。结果表明，所有模型都能准确自动检测裂缝，其中缩小图像方法提高了计算效率，而分割方法提供了更精确的裂缝分割。总体上，FPN 结合分割方法为高分辨率图像的裂缝检测提供了高效且可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.21175v1",
      "published_date": "2024-10-28 16:16:15 UTC",
      "updated_date": "2024-10-28 16:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:41:27.391967"
    },
    {
      "arxiv_id": "2410.21169v4",
      "title": "Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Qintong Zhang",
        "Bin Wang",
        "Victor Shea-Jay Huang",
        "Junyuan Zhang",
        "Zhengren Wang",
        "Hao Liang",
        "Conghui He",
        "Wentao Zhang"
      ],
      "abstract": "Document parsing is essential for converting unstructured and semi-structured\ndocuments such as contracts, academic papers, and invoices into structured,\nmachine-readable data. Document parsing reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\noutlines future research directions and emphasizes the importance of developing\nlarger and more diverse datasets.",
      "tldr_zh": "这篇论文对文档解析（Document Parsing）进行了全面综述，旨在将非结构化和半结构化文档（如合同、学术论文和发票）转换为结构化、可机器读取的数据，从而支持知识库建设和训练数据生成，尤其在Large Language Models的背景下。该文回顾了关键方法，包括模块化管道系统和基于大型视觉语言模型（Large Vision-Language Models）的端到端模型，并详细分析了核心组件，如布局检测、内容提取（包括文本、表格和数学表达式）以及多模态数据整合。论文指出了现有系统的挑战，例如处理复杂布局、模块整合和高密度文本识别，并强调未来研究应聚焦于开发更大、更多样化的数据集，以推动该领域的进展。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21169v4",
      "published_date": "2024-10-28 16:11:35 UTC",
      "updated_date": "2025-04-16 15:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:41:39.370180"
    },
    {
      "arxiv_id": "2410.21159v2",
      "title": "CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Lize Alberts",
        "Benjamin Ellis",
        "Andrei Lupu",
        "Jakob Foerster"
      ],
      "abstract": "We introduce a multi-turn benchmark for evaluating personalised alignment in\nLLM-based AI assistants, focusing on their ability to handle user-provided\nsafety-critical contexts. Our assessment of ten leading models across five\nscenarios (with 337 use cases each) reveals systematic inconsistencies in\nmaintaining user-specific consideration, with even top-rated \"harmless\" models\nmaking recommendations that should be recognised as obviously harmful to the\nuser given the context provided. Key failure modes include inappropriate\nweighing of conflicting preferences, sycophancy (prioritising desires above\nsafety), a lack of attentiveness to critical user information within the\ncontext window, and inconsistent application of user-specific knowledge. The\nsame systematic biases were observed in OpenAI's o1, suggesting that strong\nreasoning capacities do not necessarily transfer to this kind of personalised\nthinking. We find that prompting LLMs to consider safety-critical context\nsignificantly improves performance, unlike a generic 'harmless and helpful'\ninstruction. Based on these findings, we propose research directions for\nembedding self-reflection capabilities, online user modelling, and dynamic risk\nassessment in AI assistants. Our work emphasises the need for nuanced,\ncontext-aware approaches to alignment in systems designed for persistent human\ninteraction, aiding the development of safe and considerate AI assistants.",
      "tldr_zh": "本研究引入CURATe基准，用于评估LLM-based AI助手的个性化对齐能力，重点测试其在处理用户提供的安全关键上下文时的表现。通过评估十个领先模型在五个场景（每个337个用例）中的表现，发现系统性问题，包括权衡冲突偏好不当、sycophancy（优先欲望而非安全）、忽略关键用户信息以及不一致应用用户知识，甚至强推理模型如OpenAI的o1也存在类似偏差。研究发现，提示LLM考虑安全上下文可显著提升性能，而泛化的“harmless and helpful”指令无效；基于此，提出未来研究方向，如嵌入自省能力、在线用户建模和动态风险评估，以推动开发更细致、上下文感知的AI助手，确保其在持久人机互动中的安全和可靠性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "68T05",
        "I.2.0; I.2.7; K.4.2; H.5.2; I.2.6"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21159v2",
      "published_date": "2024-10-28 15:59:31 UTC",
      "updated_date": "2025-01-30 01:29:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:43:44.006954"
    },
    {
      "arxiv_id": "2410.21154v2",
      "title": "Trajectory Flow Matching with Applications to Clinical Time Series Modeling",
      "title_zh": "轨迹流匹配及其在临床时间序列建模中的应用",
      "authors": [
        "Xi Zhang",
        "Yuan Pu",
        "Yuki Kawamura",
        "Andrew Loza",
        "Yoshua Bengio",
        "Dennis L. Shung",
        "Alexander Tong"
      ],
      "abstract": "Modeling stochastic and irregularly sampled time series is a challenging\nproblem found in a wide range of applications, especially in medicine. Neural\nstochastic differential equations (Neural SDEs) are an attractive modeling\ntechnique for this problem, which parameterize the drift and diffusion terms of\nan SDE with neural networks. However, current algorithms for training Neural\nSDEs require backpropagation through the SDE dynamics, greatly limiting their\nscalability and stability. To address this, we propose Trajectory Flow Matching\n(TFM), which trains a Neural SDE in a simulation-free manner, bypassing\nbackpropagation through the dynamics. TFM leverages the flow matching technique\nfrom generative modeling to model time series. In this work we first establish\nnecessary conditions for TFM to learn time series data. Next, we present a\nreparameterization trick which improves training stability. Finally, we adapt\nTFM to the clinical time series setting, demonstrating improved performance on\nthree clinical time series datasets both in terms of absolute performance and\nuncertainty prediction.",
      "tldr_zh": "本研究针对随机和不规则采样时间序列的建模问题，特别是医学应用，提出Trajectory Flow Matching (TFM)方法，用于训练Neural SDEs，而无需通过SDE动态进行反向传播，从而提升可扩展性和稳定性。TFM借鉴生成建模中的flow matching技术，首先确立了其学习时间序列数据的必要条件，并引入一个重新参数化技巧来改善训练稳定性。该方法被适应于临床时间序列场景，并在三个临床数据集上实现了性能提升，包括更高的绝对性能和不确定性预测。总体而言，TFM为高效处理医疗时间序列数据提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.21154v2",
      "published_date": "2024-10-28 15:54:50 UTC",
      "updated_date": "2025-02-04 17:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:42:02.056910"
    },
    {
      "arxiv_id": "2410.21146v1",
      "title": "Palisade -- Prompt Injection Detection Framework",
      "title_zh": "Palisade——提示注入检测框架",
      "authors": [
        "Sahasra Kokkula",
        "Somanathan R",
        "Nandavardhan R",
        "Aashishkumar",
        "G Divya"
      ],
      "abstract": "The advent of Large Language Models LLMs marks a milestone in Artificial\nIntelligence, altering how machines comprehend and generate human language.\nHowever, LLMs are vulnerable to malicious prompt injection attacks, where\ncrafted inputs manipulate the models behavior in unintended ways, compromising\nsystem integrity and causing incorrect outcomes. Conventional detection methods\nrely on static, rule-based approaches, which often fail against sophisticated\nthreats like abnormal token sequences and alias substitutions, leading to\nlimited adaptability and higher rates of false positives and false\nnegatives.This paper proposes a novel NLP based approach for prompt injection\ndetection, emphasizing accuracy and optimization through a layered input\nscreening process. In this framework, prompts are filtered through three\ndistinct layers rule-based, ML classifier, and companion LLM before reaching\nthe target model, thereby minimizing the risk of malicious interaction.Tests\nshow the ML classifier achieves the highest accuracy among individual layers,\nyet the multi-layer framework enhances overall detection accuracy by reducing\nfalse negatives. Although this increases false positives, it minimizes the risk\nof overlooking genuine injected prompts, thus prioritizing security.This\nmulti-layered detection approach highlights LLM vulnerabilities and provides a\ncomprehensive framework for future research, promoting secure interactions\nbetween humans and AI systems.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）面临的提示注入攻击问题，这些攻击通过恶意输入操纵模型行为，威胁系统完整性。作者提出Palisade框架，一种基于NLP的多层输入筛选方法，包括规则-based层、ML classifier层和伴随LLM层，以逐步过滤潜在威胁，提高检测准确性。实验结果显示，ML classifier层单独表现最佳，而多层框架整体减少了假阴性，尽管增加了假阳性，从而优先保障安全。该框架强调了LLMs的脆弱性，并为未来的人机交互安全研究提供全面指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21146v1",
      "published_date": "2024-10-28 15:47:03 UTC",
      "updated_date": "2024-10-28 15:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:45:47.750046"
    },
    {
      "arxiv_id": "2410.21353v1",
      "title": "Causal Interventions on Causal Paths: Mapping GPT-2's Reasoning From Syntax to Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Isabelle Lee",
        "Joshua Lum",
        "Ziyi Liu",
        "Dani Yogatama"
      ],
      "abstract": "While interpretability research has shed light on some internal algorithms\nutilized by transformer-based LLMs, reasoning in natural language, with its\ndeep contextuality and ambiguity, defies easy categorization. As a result,\nformulating clear and motivating questions for circuit analysis that rely on\nwell-defined in-domain and out-of-domain examples required for causal\ninterventions is challenging. Although significant work has investigated\ncircuits for specific tasks, such as indirect object identification (IOI),\ndeciphering natural language reasoning through circuits remains difficult due\nto its inherent complexity. In this work, we take initial steps to characterize\ncausal reasoning in LLMs by analyzing clear-cut cause-and-effect sentences like\n\"I opened an umbrella because it started raining,\" where causal interventions\nmay be possible through carefully crafted scenarios using GPT-2 small. Our\nfindings indicate that causal syntax is localized within the first 2-3 layers,\nwhile certain heads in later layers exhibit heightened sensitivity to\nnonsensical variations of causal sentences. This suggests that models may infer\nreasoning by (1) detecting syntactic cues and (2) isolating distinct heads in\nthe final layers that focus on semantic relationships.",
      "tldr_zh": "这篇论文探讨了GPT-2模型的内部推理机制，焦点在于通过causal interventions分析从syntax到semantics的因果路径，以理解transformer-based LLMs在处理自然语言推理时的复杂性。研究者使用精心设计的简单因果句子（如“I opened an umbrella because it started raining”）作为测试场景，在GPT-2 small上进行干预实验。结果显示，因果syntax主要在模型的前2-3层本地化，而后层的某些heads对无意义的因果句变化表现出更高的敏感性，表明LLMs可能通过检测语法线索和隔离语义相关的heads来实现推理。该工作为circuit analysis在自然语言领域的应用提供了初步见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.21353v1",
      "published_date": "2024-10-28 15:37:56 UTC",
      "updated_date": "2024-10-28 15:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:46:10.276810"
    },
    {
      "arxiv_id": "2410.21131v3",
      "title": "Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments",
      "title_zh": "翻译失败",
      "authors": [
        "Marharyta Domnich",
        "Julius Välja",
        "Rasmus Moorits Veski",
        "Giacomo Magnifico",
        "Kadi Tulver",
        "Eduard Barbu",
        "Raul Vicente"
      ],
      "abstract": "As machine learning models evolve, maintaining transparency demands more\nhuman-centric explainable AI techniques. Counterfactual explanations, with\nroots in human reasoning, identify the minimal input changes needed to obtain a\ngiven output and, hence, are crucial for supporting decision-making. Despite\ntheir importance, the evaluation of these explanations often lacks grounding in\nuser studies and remains fragmented, with existing metrics not fully capturing\nhuman perspectives. To address this challenge, we developed a diverse set of 30\ncounterfactual scenarios and collected ratings across 8 evaluation metrics from\n206 respondents. Subsequently, we fine-tuned different Large Language Models\n(LLMs) to predict average or individual human judgment across these metrics.\nOur methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot\nevaluations and 85% (over a 3-classes prediction) with fine-tuning across all\nmetrics. The fine-tuned models predicting human ratings offer better\ncomparability and scalability in evaluating different counterfactual\nexplanation frameworks.",
      "tldr_zh": "本文提出了一种统一评估Counterfactual explanations的方法，强调人类视角的重要性，以解决现有评估指标不全面和缺乏用户研究的问题。研究团队创建了30个counterfactual场景，从206名受访者收集了8个评价指标的评分，并微调Large Language Models (LLMs)来预测人类判断，结果在zero-shot evaluations中达到63%的准确率，微调后提升至85%。这种方法通过fine-tuned LLMs提升了counterfactual解释框架的comparability和scalability，为更可靠的解释性AI决策支持提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper extends the AAAI-2025 version by including the Appendix",
      "pdf_url": "http://arxiv.org/pdf/2410.21131v3",
      "published_date": "2024-10-28 15:33:37 UTC",
      "updated_date": "2025-04-22 14:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:46:14.423605"
    },
    {
      "arxiv_id": "2410.21129v1",
      "title": "Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models",
      "title_zh": "快速校准解释：高效且不确定性感知的机器学习模型解释",
      "authors": [
        "Tuwe Löfström",
        "Fatima Rabia Yapicioglu",
        "Alessandra Stramiglio",
        "Helena Löfström",
        "Fabio Vitali"
      ],
      "abstract": "This paper introduces Fast Calibrated Explanations, a method designed for\ngenerating rapid, uncertainty-aware explanations for machine learning models.\nBy incorporating perturbation techniques from ConformaSight - a global\nexplanation framework - into the core elements of Calibrated Explanations (CE),\nwe achieve significant speedups. These core elements include local feature\nimportance with calibrated predictions, both of which retain uncertainty\nquantification. While the new method sacrifices a small degree of detail, it\nexcels in computational efficiency, making it ideal for high-stakes, real-time\napplications. Fast Calibrated Explanations are applicable to probabilistic\nexplanations in classification and thresholded regression tasks, where they\nprovide the likelihood of a target being above or below a user-defined\nthreshold. This approach maintains the versatility of CE for both\nclassification and probabilistic regression, making it suitable for a range of\npredictive tasks where uncertainty quantification is crucial.",
      "tldr_zh": "本论文提出 Fast Calibrated Explanations，一种高效且包含不确定性的机器学习模型解释方法，通过将 ConformaSight 的扰动技术整合到 Calibrated Explanations (CE) 的核心元素中（如局部特征重要性和校准预测），实现了显著计算加速，同时保留不确定性量化。虽略微牺牲细节，但该方法适用于分类和阈值回归任务，能提供目标超过或低于用户定义阈值的可能性，适合高风险实时应用。实验结果显示，该方法在保持 CE 多功能性的基础上，提升了效率，为需要不确定性量化的预测任务提供了更实用的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages, 5 figures, journal submission",
      "pdf_url": "http://arxiv.org/pdf/2410.21129v1",
      "published_date": "2024-10-28 15:29:35 UTC",
      "updated_date": "2024-10-28 15:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:44:31.927810"
    },
    {
      "arxiv_id": "2410.21127v1",
      "title": "Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Tan",
        "Ruilin Wang",
        "Banghao Wu",
        "Liang Hong",
        "Bingxin Zhou"
      ],
      "abstract": "Enzyme engineering enables the modification of wild-type proteins to meet\nindustrial and research demands by enhancing catalytic activity, stability,\nbinding affinities, and other properties. The emergence of deep learning\nmethods for protein modeling has demonstrated superior results at lower costs\ncompared to traditional approaches such as directed evolution and rational\ndesign. In mutation effect prediction, the key to pre-training deep learning\nmodels lies in accurately interpreting the complex relationships among protein\nsequence, structure, and function. This study introduces a retrieval-enhanced\nprotein language model for comprehensive analysis of native properties from\nsequence and local structural interactions, as well as evolutionary properties\nfrom retrieved homologous sequences. The state-of-the-art performance of the\nproposed ProtREM is validated on over 2 million mutants across 217 assays from\nan open benchmark (ProteinGym). We also conducted post-hoc analyses of the\nmodel's ability to improve the stability and binding affinity of a VHH\nantibody. Additionally, we designed 10 new mutants on a DNA polymerase and\nconducted wet-lab experiments to evaluate their enhanced activity at higher\ntemperatures. Both in silico and experimental evaluations confirmed that our\nmethod provides reliable predictions of mutation effects, offering an auxiliary\ntool for biologists aiming to evolve existing enzymes. The implementation is\npublicly available at https://github.com/tyang816/ProtREM.",
      "tldr_zh": "本研究提出了一种检索增强蛋白质语言模型 ProtREM，用于提升零样本突变效果预测。该模型通过整合蛋白质序列、本地结构互动以及从同源序列检索的进化特性，实现了对突变影响的全面分析。在 ProteinGym 基准上，ProtREM 在超过 2 百万突变体和 217 个测验中表现出 state-of-the-art 性能，并通过后验分析改善了 VHH 抗体的稳定性和结合亲和力。实验验证包括设计 10 个新突变体应用于 DNA 聚合酶，并通过湿实验室实验确认其在更高温度下的增强活性，为酶工程提供可靠的辅助工具。模型实现已开源在 https://github.com/tyang816/ProtREM。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 10 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.21127v1",
      "published_date": "2024-10-28 15:28:51 UTC",
      "updated_date": "2024-10-28 15:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:44:44.347139"
    },
    {
      "arxiv_id": "2411.08892v1",
      "title": "Auto-assessment of assessment: A conceptual framework towards fulfilling the policy gaps in academic assessment practices",
      "title_zh": "翻译失败",
      "authors": [
        "Wasiq Khan",
        "Luke K. Topham",
        "Peter Atherton",
        "Raghad Al-Shabandar",
        "Hoshang Kolivand",
        "Iftikhar Khan",
        "Abir Hussain"
      ],
      "abstract": "Education is being transformed by rapid advances in Artificial Intelligence\n(AI), including emerging Generative Artificial Intelligence (GAI). Such\ntechnology can significantly support academics and students by automating\nmonotonous tasks and making personalised suggestions. However, despite the\npotential of the technology, there are significant concerns regarding AI\nmisuse, particularly by students in assessments. There are two schools of\nthought: one advocates for a complete ban on it, while the other views it as a\nvaluable educational tool, provided it is governed by a robust usage policy.\nThis contradiction clearly indicates a major policy gap in academic practices,\nand new policies are required to uphold academic standards while enabling staff\nand students to benefit from technological advancements. We surveyed 117\nacademics from three countries (UK, UAE, and Iraq), and identified that most\nacademics retain positive opinions regarding AI in education. For example, the\nmajority of experienced academics do not favour complete bans, and they see the\npotential benefits of AI for students, teaching staff, and academic\ninstitutions. Importantly, academics specifically identified the particular\nbenefits of AI for autonomous assessment (71.79% of respondents agreed).\nTherefore, for the first time, we propose a novel AI framework for autonomously\nevaluating students' work (e.g., reports, coursework, etc.) and automatically\nassigning grades based on their knowledge and in-depth understanding of the\nsubmitted content. The survey results further highlight a significant lack of\nawareness of modern AI-based tools (e.g., ChatGPT) among experienced academics,\na gap that must be addressed to uphold educational standards.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）和生成式人工智能（GAI）在教育评估中的政策空白，通过对117名来自英国、阿联酋和伊拉克的学术人员的调查，发现大多数人持积极态度，支持AI作为教育工具（如自主评估），而非完全禁止（71.79%的受访者同意AI用于评估）。调查还揭示了经验丰富的学术人员对现代AI工具（如ChatGPT）的认识不足，这需要通过政策干预来解决。论文的主要贡献是提出一个新AI框架，用于自动评估学生作品（如报告和课程作业），基于内容理解分配分数，从而提升学术标准并利用技术优势。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "68-04",
        "I.2; K.3"
      ],
      "primary_category": "cs.CY",
      "comment": "20 Pages, 5 Figures, submitted for journal peer-review",
      "pdf_url": "http://arxiv.org/pdf/2411.08892v1",
      "published_date": "2024-10-28 15:22:37 UTC",
      "updated_date": "2024-10-28 15:22:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:44:56.110853"
    },
    {
      "arxiv_id": "2411.09788v1",
      "title": "AI-Driven Human-Autonomy Teaming in Tactical Operations: Proposed Framework, Challenges, and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Desta Haileselassie Hagos",
        "Hassan El Alami",
        "Danda B. Rawat"
      ],
      "abstract": "Artificial Intelligence (AI) techniques, particularly machine learning\ntechniques, are rapidly transforming tactical operations by augmenting human\ndecision-making capabilities. This paper explores AI-driven Human-Autonomy\nTeaming (HAT) as a transformative approach, focusing on how it empowers human\ndecision-making in complex environments. While trust and explainability\ncontinue to pose significant challenges, our exploration focuses on the\npotential of AI-driven HAT to transform tactical operations. By improving\nsituational awareness and supporting more informed decision-making, AI-driven\nHAT can enhance the effectiveness and safety of such operations. To this end,\nwe propose a comprehensive framework that addresses the key components of\nAI-driven HAT, including trust and transparency, optimal function allocation\nbetween humans and AI, situational awareness, and ethical considerations. The\nproposed framework can serve as a foundation for future research and\ndevelopment in the field. By identifying and discussing critical research\nchallenges and knowledge gaps in this framework, our work aims to guide the\nadvancement of AI-driven HAT for optimizing tactical operations. We emphasize\nthe importance of developing scalable and ethical AI-driven HAT systems that\nensure seamless human-machine collaboration, prioritize ethical considerations,\nenhance model transparency through Explainable AI (XAI) techniques, and\neffectively manage the cognitive load of human operators.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)驱动的人机团队(Human-Autonomy Teaming, HAT)在战术操作中的应用，强调其如何通过提升态势感知和决策支持来增强人类决策能力，同时提出一个全面框架来处理关键组件，如信任与透明度、人类与AI的功能分配、态势感知以及伦理考虑。框架旨在解决当前挑战，包括信任问题、解释性(Explainable AI, XAI)不足以及操作员的认知负载管理。论文通过识别研究空白和挑战，为未来开发可扩展、道德的AI驱动HAT系统提供指导，以实现无缝的人机协作和优化战术操作的安全性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Submitted for review to the Proceedings of the IEEE",
      "pdf_url": "http://arxiv.org/pdf/2411.09788v1",
      "published_date": "2024-10-28 15:05:16 UTC",
      "updated_date": "2024-10-28 15:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:45:08.023854"
    },
    {
      "arxiv_id": "2410.21091v1",
      "title": "Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality",
      "title_zh": "翻译失败",
      "authors": [
        "Junlong Chen",
        "Jens Grubert",
        "Per Ola Kristensson"
      ],
      "abstract": "Selection of occluded objects is a challenging problem in virtual reality,\neven more so if multiple objects are involved. With the advent of new\nartificial intelligence technologies, we explore the possibility of leveraging\nlarge language models to assist multi-object selection tasks in virtual reality\nvia a multimodal speech and raycast interaction technique. We validate the\nfindings in a comparative user study (n=24), where participants selected target\nobjects in a virtual reality scene with different levels of scene perplexity.\nThe performance metrics and user experience metrics are compared against a\nmini-map based occluded object selection technique that serves as the baseline.\nResults indicate that the introduced technique, AssistVR, outperforms the\nbaseline technique when there are multiple target objects. Contrary to the\ncommon belief for speech interfaces, AssistVR was able to outperform the\nbaseline even when the target objects were difficult to reference verbally.\nThis work demonstrates the viability and interaction potential of an\nintelligent multimodal interactive system powered by large laguage models.\nBased on the results, we discuss the implications for design of future\nintelligent multimodal interactive systems in immersive environments.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models）如何通过语音和射线投射（raycast）交互技术辅助虚拟现实（Virtual Reality）中的多对象选择问题，提出了一种名为 AssistVR 的多模态交互方法，以解决被遮挡对象的挑战。研究通过一项用户研究（n=24）比较了 AssistVR 与基线方法（mini-map based），结果显示 AssistVR 在多目标场景中性能更优，甚至在目标对象难以用语言描述时也能超越基线。总体而言，此工作证明了智能多模态交互系统的可行性，并为未来沉浸式环境中的系统设计提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2410.21091v1",
      "published_date": "2024-10-28 14:56:51 UTC",
      "updated_date": "2024-10-28 14:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:45:19.501193"
    },
    {
      "arxiv_id": "2410.21086v1",
      "title": "Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyao Wang",
        "Xiao Yang",
        "Zhenyu Wang",
        "Ximeng Wei",
        "Ange Wang",
        "Dengbo He",
        "Kaishun Wu"
      ],
      "abstract": "Road safety remains a critical challenge worldwide, with approximately 1.35\nmillion fatalities annually attributed to traffic accidents, often due to human\nerrors. As we advance towards higher levels of vehicle automation, challenges\nstill exist, as driving with automation can cognitively over-demand drivers if\nthey engage in non-driving-related tasks (NDRTs), or lead to drowsiness if\ndriving was the sole task. This calls for the urgent need for an effective\nDriver Monitoring System (DMS) that can evaluate cognitive load and drowsiness\nin SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel\nmulti-task DMS, termed VDMoE, which leverages RGB video input to monitor driver\nstates non-invasively. By utilizing key facial features to minimize\ncomputational load and integrating remote Photoplethysmography (rPPG) for\nphysiological insights, our approach enhances detection accuracy while\nmaintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE)\nframework to accommodate multi-modal inputs and improve performance across\ndifferent tasks. A novel prior-inclusive regularization method is introduced to\nalign model outputs with statistical priors, thus accelerating convergence and\nmitigating overfitting risks. We validate our method with the creation of a new\ndataset (MCDD), which comprises RGB video and physiological indicators from 42\nparticipants, and two public datasets. Our findings demonstrate the\neffectiveness of VDMoE in monitoring driver states, contributing to safer\nautonomous driving systems. The code and data will be released.",
      "tldr_zh": "这篇论文针对自动驾驶中的道路安全问题，提出了一种高效的多任务驾驶员监控系统（VDMoE），利用 RGB 视频输入和远程光电容积描记术（rPPG）非侵入式评估驾驶员的认知负荷和困倦状态。VDMoE 通过提取关键面部特征减少计算负荷，并优化 Mixture-of-Experts (MoE) 框架来处理多模态输入，提高多任务性能。论文引入了 prior-inclusive regularization 方法，以加速模型收敛并缓解过拟合风险。实验在自创数据集 MCDD 和两个公共数据集上验证，证明 VDMoE 显著提升了检测准确性，为更安全的 SAE Level-2/3 自主驾驶系统贡献了重要支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21086v1",
      "published_date": "2024-10-28 14:49:18 UTC",
      "updated_date": "2024-10-28 14:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:45:33.215281"
    },
    {
      "arxiv_id": "2410.21083v2",
      "title": "Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring",
      "title_zh": "翻译失败",
      "authors": [
        "Honglin Mu",
        "Han He",
        "Yuxin Zhou",
        "Yunlong Feng",
        "Yang Xu",
        "Libo Qin",
        "Xiaoming Shi",
        "Zeming Liu",
        "Xudong Han",
        "Qi Shi",
        "Qingfu Zhu",
        "Wanxiang Che"
      ],
      "abstract": "Large language model (LLM) safety is a critical issue, with numerous studies\nemploying red team testing to enhance model security. Among these, jailbreak\nmethods explore potential vulnerabilities by crafting malicious prompts that\ninduce model outputs contrary to safety alignments. Existing black-box\njailbreak methods often rely on model feedback, repeatedly submitting queries\nwith detectable malicious instructions during the attack search process.\nAlthough these approaches are effective, the attacks may be intercepted by\ncontent moderators during the search process. We propose an improved transfer\nattack method that guides malicious prompt construction by locally training a\nmirror model of the target black-box model through benign data distillation.\nThis method offers enhanced stealth, as it does not involve submitting\nidentifiable malicious instructions to the target model during the search\nphase. Our approach achieved a maximum attack success rate of 92%, or a\nbalanced value of 80% with an average of 1.5 detectable jailbreak queries per\nsample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore\nthe need for more robust defense mechanisms.",
      "tldr_zh": "本论文提出了一种隐秘的jailbreak攻击方法，通过Benign Data Mirroring在本地训练目标黑盒模型的镜像模型，来指导恶意提示的构建，从而避免在攻击搜索过程中提交可检测的恶意指令。相比现有依赖模型反馈的方法，该方法提升了攻击的隐蔽性，并在GPT-3.5 Turbo上对AdvBench子集实现了最高攻击成功率92%，或平衡值为80%（平均每样本1.5个可检测查询）。这些结果突出了LLM安全性的脆弱性，并呼吁开发更 robust的防御机制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.21083v2",
      "published_date": "2024-10-28 14:48:05 UTC",
      "updated_date": "2025-03-06 12:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:47:45.656841"
    },
    {
      "arxiv_id": "2410.21352v2",
      "title": "LLMCBench: Benchmarking Large Language Model Compression for Efficient Deployment",
      "title_zh": "翻译失败",
      "authors": [
        "Ge Yang",
        "Changyi He",
        "Jinyang Guo",
        "Jianyu Wu",
        "Yifu Ding",
        "Aishan Liu",
        "Haotong Qin",
        "Pengliang Ji",
        "Xianglong Liu"
      ],
      "abstract": "Although large language models (LLMs) have demonstrated their strong\nintelligence ability, the high demand for computation and storage hinders their\npractical application. To this end, many model compression techniques are\nproposed to increase the efficiency of LLMs. However, current researches only\nvalidate their methods on limited models, datasets, metrics, etc, and still\nlack a comprehensive evaluation under more general scenarios. So it is still a\nquestion of which model compression approach we should use under a specific\ncase. To mitigate this gap, we present the Large Language Model Compression\nBenchmark (LLMCBench), a rigorously designed benchmark with an in-depth\nanalysis for LLM compression algorithms. We first analyze the actual model\nproduction requirements and carefully design evaluation tracks and metrics.\nThen, we conduct extensive experiments and comparison using multiple mainstream\nLLM compression approaches. Finally, we perform an in-depth analysis based on\nthe evaluation and provide useful insight for LLM compression design. We hope\nour LLMCBench can contribute insightful suggestions for LLM compression\nalgorithm design and serve as a foundation for future research. Our code is\navailable at https://github.com/AboveParadise/LLMCBench.",
      "tldr_zh": "本文提出 LLMCBench，一种针对大型语言模型 (LLMs) 压缩算法的全面基准，用于评估其在高效部署中的性能，以解决现有方法在模型、数据集和指标上缺乏通用性的问题。该基准通过分析实际模型生产需求，设计了专门的评估轨道和指标，并对多种主流 LLM 压缩方法进行了广泛实验和比较。最终，基于实验结果进行深入分析，提供有价值的见解，帮助优化 LLM 压缩算法设计，并为未来研究奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024 Datasets and Benchmarks Track",
      "pdf_url": "http://arxiv.org/pdf/2410.21352v2",
      "published_date": "2024-10-28 14:45:01 UTC",
      "updated_date": "2024-10-31 06:01:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:49:58.249981"
    },
    {
      "arxiv_id": "2410.21073v1",
      "title": "Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroki Matsutani",
        "Masaaki Kondo",
        "Kazuki Sunaga",
        "Radu Marculescu"
      ],
      "abstract": "This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep\nneural networks to address the gap between pre-trained and deployed models. In\nour approach, trainable LoRA (low-rank adaptation) adapters are inserted\nbetween the last layer and every other layer to enhance the network expressive\npower while keeping the backward computation cost low. This architecture is\nwell-suited to cache intermediate computation results of the forward pass and\nthen can skip the forward computation of seen samples as training epochs\nprogress. We implemented the combination of the proposed architecture and\ncache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our\nresults show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average\ncompared to the counterpart that has the same number of trainable parameters\nwhile preserving the accuracy, while taking only a few seconds on the\nmicrocontroller board.",
      "tldr_zh": "这篇论文提出了 Skip2-LoRA，一种轻量级 DNN 微调方法，旨在桥接预训练模型与部署模型的差距，特别适用于低成本边缘设备。该方法通过在最后一层和每隔一层插入可训练的 LoRA 适配器来增强网络表现力，同时利用缓存机制跳过已见样本的前向计算，从而显著降低后向计算成本。实验结果显示，在一个 15 美元单板计算机上，Skip2-LoRA 平均减少 90.0% 的微调时间，同时保持了准确性，仅需几秒钟即可完成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ASP-DAC 2025 (accepted)",
      "pdf_url": "http://arxiv.org/pdf/2410.21073v1",
      "published_date": "2024-10-28 14:35:12 UTC",
      "updated_date": "2024-10-28 14:35:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:50:10.634718"
    },
    {
      "arxiv_id": "2410.21069v2",
      "title": "EMOCPD: Efficient Attention-based Models for Computational Protein Design Using Amino Acid Microenvironment",
      "title_zh": "EMOCPD",
      "authors": [
        "Xiaoqi Ling",
        "Cheng Cai",
        "Demin Kong",
        "Zhisheng Wei",
        "Jing Wu",
        "Lei Wang",
        "Zhaohong Deng"
      ],
      "abstract": "Computational protein design (CPD) refers to the use of computational methods\nto design proteins. Traditional methods relying on energy functions and\nheuristic algorithms for sequence design are inefficient and do not meet the\ndemands of the big data era in biomolecules, with their accuracy limited by the\nenergy functions and search algorithms. Existing deep learning methods are\nconstrained by the learning capabilities of the networks, failing to extract\neffective information from sparse protein structures, which limits the accuracy\nof protein design. To address these shortcomings, we developed an Efficient\nattention-based Models for Computational Protein Design using amino acid\nmicroenvironment (EMOCPD). It aims to predict the category of each amino acid\nin a protein by analyzing the three-dimensional atomic environment surrounding\nthe amino acids, and optimize the protein based on the predicted\nhigh-probability potential amino acid categories. EMOCPD employs a multi-head\nattention mechanism to focus on important features in the sparse protein\nmicroenvironment and utilizes an inverse residual structure to optimize the\nnetwork architecture. The proposed EMOCPD achieves over 80% accuracy on the\ntraining set and 68.33% and 62.32% accuracy on two independent test sets,\nrespectively, surpassing the best comparative methods by over 10%. In protein\ndesign, the thermal stability and protein expression of the predicted mutants\nfrom EMOCPD show significant improvements compared to the wild type,\neffectively validating EMOCPD's potential in designing superior proteins.\nFurthermore, the predictions of EMOCPD are influenced positively, negatively,\nor have minimal impact based on the content of the 20 amino acids, categorizing\namino acids as positive, negative, or neutral. Research findings indicate that\nEMOCPD is more suitable for designing proteins with lower contents of negative\namino acids.",
      "tldr_zh": "本研究针对计算蛋白质设计 (CPD) 的效率和准确性问题，提出了一种基于氨基酸微环境的高效注意力模型 EMOCPD。该模型通过分析氨基酸的三维原子环境，使用多头注意力机制提取稀疏蛋白结构的重要特征，并采用逆残差结构优化网络架构，以预测并优化蛋白质的氨基酸类别。实验结果显示，EMOCPD 在训练集上准确率超过80%，在两个独立测试集上分别达到68.33%和62.32%，比最佳比较方法高出10%以上；此外，预测的蛋白突变体在热稳定性和表达水平上显著提升，且更适合设计负氨基酸含量较低的蛋白质。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21069v2",
      "published_date": "2024-10-28 14:31:18 UTC",
      "updated_date": "2024-10-29 05:45:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:48:23.010271"
    },
    {
      "arxiv_id": "2410.21066v1",
      "title": "Learning to Handle Complex Constraints for Vehicle Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Jieyi Bi",
        "Yining Ma",
        "Jianan Zhou",
        "Wen Song",
        "Zhiguang Cao",
        "Yaoxin Wu",
        "Jie Zhang"
      ],
      "abstract": "Vehicle Routing Problems (VRPs) can model many real-world scenarios and often\ninvolve complex constraints. While recent neural methods excel in constructing\nsolutions based on feasibility masking, they struggle with handling complex\nconstraints, especially when obtaining the masking itself is NP-hard. In this\npaper, we propose a novel Proactive Infeasibility Prevention (PIP) framework to\nadvance the capabilities of neural methods towards more complex VRPs. Our PIP\nintegrates the Lagrangian multiplier as a basis to enhance constraint awareness\nand introduces preventative infeasibility masking to proactively steer the\nsolution construction process. Moreover, we present PIP-D, which employs an\nauxiliary decoder and two adaptive strategies to learn and predict these\ntailored masks, potentially enhancing performance while significantly reducing\ncomputational costs during training. To verify our PIP designs, we conduct\nextensive experiments on the highly challenging Traveling Salesman Problem with\nTime Window (TSPTW), and TSP with Draft Limit (TSPDL) variants under different\nconstraint hardness levels. Notably, our PIP is generic to boost many neural\nmethods, and exhibits both a significant reduction in infeasible rate and a\nsubstantial improvement in solution quality.",
      "tldr_zh": "本研究针对车辆路径问题 (VRPs) 中的复杂约束，提出了一种创新的 Proactive Infeasibility Prevention (PIP) 框架，以提升神经方法的能力。PIP 通过整合 Lagrangian multiplier 增强约束意识，并引入 preventative infeasibility masking 来主动避免不可行解决方案，从而更好地指导解决方案构建过程。此外，PIP-D 版本使用辅助解码器和自适应策略来学习预测这些掩码，提高性能并显著降低训练计算成本。在 TSPTW 和 TSPDL 等问题上的实验显示，PIP 能将不可行率大幅减少，并改善解决方案质量，同时适用于多种神经方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21066v1",
      "published_date": "2024-10-28 14:26:54 UTC",
      "updated_date": "2024-10-28 14:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:50:26.525523"
    },
    {
      "arxiv_id": "2410.21061v1",
      "title": "Kandinsky 3: Text-to-Image Synthesis for Multifunctional Generative Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Arkhipkin",
        "Viacheslav Vasilev",
        "Andrei Filatov",
        "Igor Pavlov",
        "Julia Agafonova",
        "Nikolai Gerasimenko",
        "Anna Averchenkova",
        "Evelina Mironova",
        "Anton Bukashkin",
        "Konstantin Kulikov",
        "Andrey Kuznetsov",
        "Denis Dimitrov"
      ],
      "abstract": "Text-to-image (T2I) diffusion models are popular for introducing image\nmanipulation methods, such as editing, image fusion, inpainting, etc. At the\nsame time, image-to-video (I2V) and text-to-video (T2V) models are also built\non top of T2I models. We present Kandinsky 3, a novel T2I model based on latent\ndiffusion, achieving a high level of quality and photorealism. The key feature\nof the new architecture is the simplicity and efficiency of its adaptation for\nmany types of generation tasks. We extend the base T2I model for various\napplications and create a multifunctional generation system that includes\ntext-guided inpainting/outpainting, image fusion, text-image fusion, image\nvariations generation, I2V and T2V generation. We also present a distilled\nversion of the T2I model, evaluating inference in 4 steps of the reverse\nprocess without reducing image quality and 3 times faster than the base model.\nWe deployed a user-friendly demo system in which all the features can be tested\nin the public domain. Additionally, we released the source code and checkpoints\nfor the Kandinsky 3 and extended models. Human evaluations show that Kandinsky\n3 demonstrates one of the highest quality scores among open source generation\nsystems.",
      "tldr_zh": "本研究介绍了Kandinsky 3，一种基于latent diffusion的文本到图像(T2I)模型，实现了高质量和高逼真度的图像生成，其关键优势在于架构的简单性和高效适应性。研究扩展了基础T2I模型，支持多种任务，包括文本引导的inpainting/outpainting、图像融合、文本-图像融合、图像变体生成、图像到视频(I2V)和文本到视频(T2V)生成。作者还开发了一个蒸馏版本的T2I模型，能够在4步逆过程内完成推理，比基础模型快3倍且不降低图像质量，并通过开源代码、检查点和用户友好的演示系统进行发布。人类评估显示，Kandinsky 3在开源生成系统中表现出色，质量分数位居前列。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for EMNLP 2024 (Demo track)",
      "pdf_url": "http://arxiv.org/pdf/2410.21061v1",
      "published_date": "2024-10-28 14:22:08 UTC",
      "updated_date": "2024-10-28 14:22:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:48:45.497524"
    },
    {
      "arxiv_id": "2410.21060v2",
      "title": "CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Cheng",
        "Osama Bajaber",
        "Saimon Amanuel Tsegai",
        "Dawn Song",
        "Peng Gao"
      ],
      "abstract": "Textual descriptions in cyber threat intelligence (CTI) reports, such as\nsecurity articles and news, are rich sources of knowledge about cyber threats,\ncrucial for organizations to stay informed about the rapidly evolving threat\nlandscape. However, current CTI knowledge extraction methods lack flexibility\nand generalizability, often resulting in inaccurate and incomplete knowledge\nextraction. Syntax parsing relies on fixed rules and dictionaries, while model\nfine-tuning requires large annotated datasets, making both paradigms\nchallenging to adapt to new threats and ontologies. To bridge the gap, we\npropose CTINexus, a novel framework leveraging optimized in-context learning\n(ICL) of large language models (LLMs) for data-efficient CTI knowledge\nextraction and high-quality cybersecurity knowledge graph (CSKG) construction.\nUnlike existing methods, CTINexus requires neither extensive data nor parameter\ntuning and can adapt to various ontologies with minimal annotated examples.\nThis is achieved through: (1) a carefully designed automatic prompt\nconstruction strategy with optimal demonstration retrieval for extracting a\nwide range of cybersecurity entities and relations; (2) a hierarchical entity\nalignment technique that canonicalizes the extracted knowledge and removes\nredundancy; (3) an long-distance relation prediction technique to further\ncomplete the CSKG with missing links. Our extensive evaluations using 150\nreal-world CTI reports collected from 10 platforms demonstrate that CTINexus\nsignificantly outperforms existing methods in constructing accurate and\ncomplete CSKG, highlighting its potential to transform CTI analysis with an\nefficient and adaptable solution for the dynamic threat landscape.",
      "tldr_zh": "该研究提出 CTINexus，一种利用大型语言模型 (LLMs) 的优化 in-context learning (ICL) 框架，用于自动提取网络威胁情报 (CTI) 知识并构建高质量的 cybersecurity knowledge graph (CSKG)，以解决现有方法在灵活性和泛化性上的不足。CTINexus 通过自动提示构建策略、层次化实体对齐技术以及长距离关系预测技术，实现高效的实体和关系提取、冗余去除以及知识补充，而无需大量标注数据或参数调整。实验在 150 个真实 CTI 报告上表明，该框架显著优于现有方法，在 CSKG 的准确性和完整性上提升明显，为动态威胁景观提供高效可适应的 CTI 分析解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at 2025 IEEE European Symposium on Security and Privacy\n  (Euro S&P)",
      "pdf_url": "http://arxiv.org/pdf/2410.21060v2",
      "published_date": "2024-10-28 14:18:32 UTC",
      "updated_date": "2025-04-21 14:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:48:58.471857"
    },
    {
      "arxiv_id": "2410.21052v3",
      "title": "Getting By Goal Misgeneralization With a Little Help From a Mentor",
      "title_zh": "翻译失败",
      "authors": [
        "Tu Trinh",
        "Mohamad H. Danesh",
        "Nguyen X. Khanh",
        "Benjamin Plaut"
      ],
      "abstract": "While reinforcement learning (RL) agents often perform well during training,\nthey can struggle with distribution shift in real-world deployments. One\nparticularly severe risk of distribution shift is goal misgeneralization, where\nthe agent learns a proxy goal that coincides with the true goal during training\nbut not during deployment. In this paper, we explore whether allowing an agent\nto ask for help from a supervisor in unfamiliar situations can mitigate this\nissue. We focus on agents trained with PPO in the CoinRun environment, a\nsetting known to exhibit goal misgeneralization. We evaluate multiple methods\nfor determining when the agent should request help and find that asking for\nhelp consistently improves performance. However, we also find that methods\nbased on the agent's internal state fail to proactively request help, instead\nwaiting until mistakes have already occurred. Further investigation suggests\nthat the agent's internal state does not represent the coin at all,\nhighlighting the importance of learning nuanced representations, the risks of\nignoring everything not immediately relevant to reward, and the necessity of\ndeveloping ask-for-help strategies tailored to the agent's training algorithm.",
      "tldr_zh": "这篇论文探讨了强化学习 (RL) 代理在面对分布偏移时可能出现的目标错误泛化 (goal misgeneralization) 问题，即代理学习代理目标在训练中有效但在部署中失效。研究者提出让代理在不熟悉情况下向监督者寻求帮助作为缓解策略，并在 CoinRun 环境中使用 PPO 算法评估多种求助方法，结果显示求助能显著改善代理性能。实验发现，基于代理内部状态的求助方法往往被动，等到错误发生后才请求帮助，且代理内部状态并未正确表示关键元素，如硬币。这强调了学习细致表示、避免忽略非奖励相关信息，以及开发针对特定训练算法的求助策略的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "SATA Workshop @ NeurIPS 2024 (Towards Safe and Trustworthy Agents)",
      "pdf_url": "http://arxiv.org/pdf/2410.21052v3",
      "published_date": "2024-10-28 14:07:41 UTC",
      "updated_date": "2024-11-10 05:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:49:09.897006"
    },
    {
      "arxiv_id": "2411.08040v1",
      "title": "The Universal PDDL Domain",
      "title_zh": "通用 PDDL 域",
      "authors": [
        "Patrik Haslum",
        "Augusto B. Corrêa"
      ],
      "abstract": "In AI planning, it is common to distinguish between planning domains and\nproblem instances, where a \"domain\" is generally understood as a set of related\nproblem instances. This distinction is important, for example, in generalised\nplanning, which aims to find a single, general plan or policy that solves all\ninstances of a given domain. In PDDL, domains and problem instances are clearly\nseparated: the domain defines the types, predicate symbols, and action\nschemata, while the problem instance specifies the concrete set of (typed)\nobjects, the initial state, and the goal condition. In this paper, we show that\nit is quite easy to define a PDDL domain such that any propositional planning\nproblem instance, from any domain, becomes an instance of this (lifted)\n\"universal\" domain. We construct different formulations of the universal\ndomain, and discuss their implications for the complexity of lifted\ndomain-dependent or generalised planning.",
      "tldr_zh": "在 AI 规划中，本文探讨了 PDDL (Planning Domain Definition Language) 中领域与问题实例的区别，强调领域定义类型、谓词符号和动作模式，而问题实例指定具体对象、初始状态和目标条件。论文的主要贡献是构建了一个通用 PDDL 领域，使任何命题规划问题实例都能转化为该提升（lifted）领域的实例。作者讨论了不同表述的通用域对提升域依赖规划和广义规划（generalised planning）的复杂性影响，为 AI 规划研究提供了新的视角。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08040v1",
      "published_date": "2024-10-28 14:02:21 UTC",
      "updated_date": "2024-10-28 14:02:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:49:20.939763"
    },
    {
      "arxiv_id": "2410.21043v1",
      "title": "Disentangled and Self-Explainable Node Representation Learning",
      "title_zh": "解耦与自解释的节点表示学习",
      "authors": [
        "Simone Piaggesi",
        "André Panisson",
        "Megha Khosla"
      ],
      "abstract": "Node representations, or embeddings, are low-dimensional vectors that capture\nnode properties, typically learned through unsupervised structural similarity\nobjectives or supervised tasks. While recent efforts have focused on explaining\ngraph model decisions, the interpretability of unsupervised node embeddings\nremains underexplored. To bridge this gap, we introduce DiSeNE (Disentangled\nand Self-Explainable Node Embedding), a framework that generates\nself-explainable embeddings in an unsupervised manner. Our method employs\ndisentangled representation learning to produce dimension-wise interpretable\nembeddings, where each dimension is aligned with distinct topological structure\nof the graph. We formalize novel desiderata for disentangled and interpretable\nembeddings, which drive our new objective functions, optimizing simultaneously\nfor both interpretability and disentanglement. Additionally, we propose several\nnew metrics to evaluate representation quality and human interpretability.\nExtensive experiments across multiple benchmark datasets demonstrate the\neffectiveness of our approach.",
      "tldr_zh": "该论文提出 DiSeNE（Disentangled and Self-Explainable Node Embedding）框架，通过无监督学习生成可解释的节点表示（node representations），以解决传统嵌入方法的可解释性不足问题。框架采用 disentangled representation learning，使每个嵌入维度与图的特定拓扑结构对齐，并形式化了新的期望（desiderata）和目标函数，同时优化可解释性和 disentanglement。论文还引入了新的评估指标，并在多个基准数据集上进行广泛实验，证明了 DiSeNE 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21043v1",
      "published_date": "2024-10-28 13:58:52 UTC",
      "updated_date": "2024-10-28 13:58:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:49:34.047139"
    },
    {
      "arxiv_id": "2410.21029v1",
      "title": "FairStream: Fair Multimedia Streaming Benchmark for Reinforcement Learning Agents",
      "title_zh": "FairStream: 用于强化学习代理的公平多媒体流媒体基准",
      "authors": [
        "Jannis Weil",
        "Jonas Ringsdorf",
        "Julian Barthel",
        "Yi-Ping Phoebe Chen",
        "Tobias Meuser"
      ],
      "abstract": "Multimedia streaming accounts for the majority of traffic in today's\ninternet. Mechanisms like adaptive bitrate streaming control the bitrate of a\nstream based on the estimated bandwidth, ideally resulting in smooth playback\nand a good Quality of Experience (QoE). However, selecting the optimal bitrate\nis challenging under volatile network conditions. This motivated researchers to\ntrain Reinforcement Learning (RL) agents for multimedia streaming. The\nconsidered training environments are often simplified, leading to promising\nresults with limited applicability. Additionally, the QoE fairness across\nmultiple streams is seldom considered by recent RL approaches. With this work,\nwe propose a novel multi-agent environment that comprises multiple challenges\nof fair multimedia streaming: partial observability, multiple objectives, agent\nheterogeneity and asynchronicity. We provide and analyze baseline approaches\nacross five different traffic classes to gain detailed insights into the\nbehavior of the considered agents, and show that the commonly used Proximal\nPolicy Optimization (PPO) algorithm is outperformed by a simple greedy\nheuristic. Future work includes the adaptation of multi-agent RL algorithms and\nfurther expansions of the environment.",
      "tldr_zh": "本文提出 FairStream，一种新型多代理基准环境，用于评估强化学习 (RL) 代理在多媒体流媒体中的公平性问题，该环境模拟了实际挑战，如部分可观察性、多个目标、代理异质性和异步性。研究者分析了基线方法在五种不同流量类别上的表现，发现常用的 Proximal Policy Optimization (PPO) 算法被一个简单的贪婪启发式方法超越，这突显了现有 RL 方法的局限性。FairStream 旨在提升多媒体流媒体的 Quality of Experience (QoE) 公平性，为未来多代理 RL 算法的适应和环境扩展提供基础。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21029v1",
      "published_date": "2024-10-28 13:51:03 UTC",
      "updated_date": "2024-10-28 13:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:51:46.666023"
    },
    {
      "arxiv_id": "2410.21028v1",
      "title": "Graph Based Traffic Analysis and Delay Prediction",
      "title_zh": "基于图的交通分析与延误预测",
      "authors": [
        "Gabriele Borg",
        "Charlie Abela"
      ],
      "abstract": "This research is focused on traffic congestion in the small island of Malta\nwhich is the most densely populated country in the EU with about 1,672\ninhabitants per square kilometre (4,331 inhabitants/sq mi). Furthermore, Malta\nhas a rapid vehicle growth. Based on our research, the number of vehicles\nincreased by around 11,000 in a little more than 6 months, which shows how\nimportant it is to have an accurate and comprehensive means of collecting data\nto tackle the issue of fluctuating traffic in Malta. In this paper, we first\npresent the newly built comprehensive traffic dataset, called MalTra. This\ndataset includes realistic trips made by members of the public across the\nisland over a period of 200 days. We then describe the methodology we adopted\nto generate syntactic data to complete our data set as much as possible. In our\nresearch, we consider both MalTra and the Q-Traffic dataset, which has been\nused in several other research studies. The statistical ARIMA model and two\ngraph neural networks, the spatial temporal graph convolutional network (STGCN)\nand the diffusion convolutional recurrent network (DCRNN) were used to analyse\nand compare the results with existing research. From the evaluation, we found\nthat the DCRNN model outperforms the STGCN with the former resulting in MAE of\n3.98 (6.65 in the case of the latter) and a RMSE of 7.78 (against 12.73 of the\nlatter).",
      "tldr_zh": "本研究针对马耳他作为欧盟人口密度最高国家（每平方公里约1672人）的交通拥堵问题，构建了名为MalTra的全面交通数据集，该数据集涵盖了200天真实出行数据，并通过合成数据方法进行补充。研究采用ARIMA模型以及图神经网络（STGCN和DCRNN）对MalTra和Q-Traffic数据集进行交通分析和延误预测。结果表明，DCRNN模型的表现优于STGCN，前者在MAE上为3.98（对比STGCN的6.65），RMSE上为7.78（对比12.73），从而为更准确的交通管理提供参考。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21028v1",
      "published_date": "2024-10-28 13:50:00 UTC",
      "updated_date": "2024-10-28 13:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:51:58.560038"
    },
    {
      "arxiv_id": "2411.02426v1",
      "title": "Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Somayeh Farahani",
        "Marjaneh Hejazi",
        "Mehnaz Tabassum",
        "Antonio Di Ieva",
        "Neda Mahdavifar",
        "Sidong Liu"
      ],
      "abstract": "Gliomas, the most common primary brain tumors, show high heterogeneity in\nhistological and molecular characteristics. Accurate molecular profiling, like\nisocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, is critical for\ndiagnosis, treatment, and prognosis. This review evaluates MRI-based deep\nlearning (DL) models' efficacy in predicting these biomarkers. Following PRISMA\nguidelines, we systematically searched major databases (PubMed, Scopus, Ovid,\nand Web of Science) up to February 2024, screening studies that utilized DL to\npredict IDH and 1p/19q codeletion status from MRI data of glioma patients. We\nassessed the quality and risk of bias using the radiomics quality score and\nQUADAS-2 tool. Our meta-analysis used a bivariate model to compute pooled\nsensitivity, specificity, and meta-regression to assess inter-study\nheterogeneity. Of the 565 articles, 57 were selected for qualitative synthesis,\nand 52 underwent meta-analysis. The pooled estimates showed high diagnostic\nperformance, with validation sensitivity, specificity, and area under the curve\n(AUC) of 0.84 [prediction interval (PI): 0.67-0.93, I2=51.10%, p < 0.05], 0.87\n[PI: 0.49-0.98, I2=82.30%, p < 0.05], and 0.89 for IDH prediction, and 0.76\n[PI: 0.28-0.96, I2=77.60%, p < 0.05], 0.85 [PI: 0.49-0.97, I2=80.30%, p <\n0.05], and 0.90 for 1p/19q prediction, respectively. Meta-regression analyses\nrevealed significant heterogeneity influenced by glioma grade, data source,\ninclusion of non-radiomics data, MRI sequences, segmentation and feature\nextraction methods, and validation techniques. DL models demonstrate strong\npotential in predicting molecular biomarkers from MRI scans, with significant\nvariability influenced by technical and clinical factors. Thorough external\nvalidation is necessary to increase clinical utility.",
      "tldr_zh": "本研究通过系统回顾和元分析评估了基于 MRI 的深度学习（DL）模型在预测胶质瘤的 IDH 突变和 1p/19q 代码缺失方面的诊断性能，共筛选出 57 篇研究进行定性合成，并对 52 篇进行元分析。\n结果显示，IDH 预测的敏感性为 0.84、特异性为 0.87、AUC 为 0.89；1p/19q 预测的敏感性为 0.76、特异性为 0.85、AUC 为 0.90，表明 DL 模型具有较高的诊断效能。\n然而，元回归分析揭示了异质性因素，包括胶质瘤等级、数据来源、MRI 序列以及分割和特征提取方法，DL 模型的潜力虽强，但需进行彻底的外部验证以提升临床实用性。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02426v1",
      "published_date": "2024-10-28 13:39:52 UTC",
      "updated_date": "2024-10-28 13:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:52:12.130744"
    },
    {
      "arxiv_id": "2410.21014v1",
      "title": "Informed Deep Abstaining Classifier: Investigating noise-robust training for diagnostic decision support systems",
      "title_zh": "翻译失败",
      "authors": [
        "Helen Schneider",
        "Sebastian Nowak",
        "Aditya Parikh",
        "Yannik C. Layer",
        "Maike Theis",
        "Wolfgang Block",
        "Alois M. Sprinkart",
        "Ulrike Attenberger",
        "Rafet Sifa"
      ],
      "abstract": "Image-based diagnostic decision support systems (DDSS) utilizing deep\nlearning have the potential to optimize clinical workflows. However, developing\nDDSS requires extensive datasets with expert annotations and is therefore\ncostly. Leveraging report contents from radiological data bases with Natural\nLanguage Processing to annotate the corresponding image data promises to\nreplace labor-intensive manual annotation. As mining \"real world\" databases can\nintroduce label noise, noise-robust training losses are of great interest.\nHowever, current noise-robust losses do not consider noise estimations that can\nfor example be derived based on the performance of the automatic label\ngenerator used. In this study, we expand the noise-robust Deep Abstaining\nClassifier (DAC) loss to an Informed Deep Abstaining Classifier (IDAC) loss by\nincorporating noise level estimations during training. Our findings demonstrate\nthat IDAC enhances the noise robustness compared to DAC and several\nstate-of-the-art loss functions. The results are obtained on various simulated\nnoise levels using a public chest X-ray data set. These findings are reproduced\non an in-house noisy data set, where labels were extracted from the clinical\nsystems of the University Hospital Bonn by a text-based transformer. The IDAC\ncan therefore be a valuable tool for researchers, companies or clinics aiming\nto develop accurate and reliable DDSS from routine clinical data.",
      "tldr_zh": "本研究探讨了基于图像的诊断决策支持系统（DDSS），通过自然语言处理（NLP）从放射学数据库提取报告内容来自动标注数据，以降低手动标注的成本，但这可能引入标签噪声。作者扩展了Deep Abstaining Classifier (DAC)损失函数，提出Informed Deep Abstaining Classifier (IDAC)损失，通过整合噪声水平估计来提升训练的噪声鲁棒性。在公共胸部X光数据集和内部临床数据上进行的实验显示，IDAC比DAC和其他最先进损失函数表现出更好的噪声鲁棒性，为从常规临床数据开发准确可靠的DDSS提供了有价值的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This preprint has no post-submission improvements or corrections. The\n  Version of Record of this contribution is published in the Neural Information\n  Processing, ICONIP 2024 Proceedings",
      "pdf_url": "http://arxiv.org/pdf/2410.21014v1",
      "published_date": "2024-10-28 13:36:57 UTC",
      "updated_date": "2024-10-28 13:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:52:23.378400"
    },
    {
      "arxiv_id": "2410.21012v1",
      "title": "FACT: Examining the Effectiveness of Iterative Context Rewriting for Multi-fact Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlin Wang",
        "Suyuchen Wang",
        "Ziwen Xia",
        "Sirui Hong",
        "Yun Zhu",
        "Bang Liu",
        "Chenglin Wu"
      ],
      "abstract": "Large Language Models (LLMs) are proficient at retrieving single facts from\nextended contexts, yet they struggle with tasks requiring the simultaneous\nretrieval of multiple facts, especially during generation. This paper\nidentifies a novel \"lost-in-the-middle\" phenomenon, where LLMs progressively\nlose track of critical information throughout the generation process, resulting\nin incomplete or inaccurate retrieval. To address this challenge, we introduce\nFind All Crucial Texts (FACT), an iterative retrieval method that refines\ncontext through successive rounds of rewriting. This approach enables models to\ncapture essential facts incrementally, which are often overlooked in\nsingle-pass retrieval. Experiments demonstrate that FACT substantially enhances\nmulti-fact retrieval performance across various tasks, though improvements are\nless notable in general-purpose QA scenarios. Our findings shed light on the\nlimitations of LLMs in multi-fact retrieval and underscore the need for more\nresilient long-context retrieval strategies.",
      "tldr_zh": "本研究探讨了大语言模型 (LLMs) 在多事实检索(multi-fact retrieval)中的挑战，特别是“lost-in-the-middle”现象，即模型在生成过程中逐渐丢失关键信息，导致检索不完整或不准确。为解决此问题，论文引入了 Find All Crucial Texts (FACT)，一种通过迭代上下文重写的方法，允许模型逐步捕获被忽略的重要事实。实验结果显示，FACT 在多种任务中显著提升了多事实检索性能，但对通用问答(QA)场景的改善较不明显。该方法揭示了 LLMs 的局限性，并强调了开发更可靠的长上下文检索策略的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2410.21012v1",
      "published_date": "2024-10-28 13:36:41 UTC",
      "updated_date": "2024-10-28 13:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:52:34.771445"
    },
    {
      "arxiv_id": "2411.00818v2",
      "title": "On the Black-box Explainability of Object Detection Models for Safe and Trustworthy Industrial Applications",
      "title_zh": "黑盒对象检测模型的可解释性研究：用于安全和可信赖的工业应用",
      "authors": [
        "Alain Andres",
        "Aitor Martinez-Seras",
        "Ibai Laña",
        "Javier Del Ser"
      ],
      "abstract": "In the realm of human-machine interaction, artificial intelligence has become\na powerful tool for accelerating data modeling tasks. Object detection methods\nhave achieved outstanding results and are widely used in critical domains like\nautonomous driving and video surveillance. However, their adoption in high-risk\napplications, where errors may cause severe consequences, remains limited.\nExplainable Artificial Intelligence methods aim to address this issue, but many\nexisting techniques are model-specific and designed for classification tasks,\nmaking them less effective for object detection and difficult for\nnon-specialists to interpret. In this work we focus on model-agnostic\nexplainability methods for object detection models and propose D-MFPP, an\nextension of the Morphological Fragmental Perturbation Pyramid (MFPP) technique\nbased on segmentation-based masks to generate explanations. Additionally, we\nintroduce D-Deletion, a novel metric combining faithfulness and localization,\nadapted specifically to meet the unique demands of object detectors. We\nevaluate these methods on real-world industrial and robotic datasets, examining\nthe influence of parameters such as the number of masks, model size, and image\nresolution on the quality of explanations. Our experiments use single-stage\nobject detection models applied to two safety-critical robotic environments: i)\na shared human-robot workspace where safety is of paramount importance, and ii)\nan assembly area of battery kits, where safety is critical due to the potential\nfor damage among high-risk components. Our findings evince that D-Deletion\neffectively gauges the performance of explanations when multiple elements of\nthe same class appear in a scene, while D-MFPP provides a promising alternative\nto D-RISE when fewer masks are used.",
      "tldr_zh": "这篇论文探讨了对象检测模型在安全工业应用中的黑箱可解释性问题，针对现有方法对分类任务的局限性，提出了一种模型无关的解释框架。作者扩展了Morphological Fragmental Perturbation Pyramid技术，开发了D-MFPP基于分割掩码的解释生成方法，并引入了D-Deletion指标，该指标结合忠实度和定位能力，专门适用于对象检测器的性能评估。在真实工业和机器人数据集上的实验显示，D-Deletion能有效评估多元素场景下的解释质量，而D-MFPP在使用较少掩码时比D-RISE提供更好的表现，从而提升了高风险应用的安全性和可信度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 10 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.00818v2",
      "published_date": "2024-10-28 13:28:05 UTC",
      "updated_date": "2024-11-28 08:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:52:46.293013"
    },
    {
      "arxiv_id": "2410.21000v3",
      "title": "Efficient Bilinear Attention-based Fusion for Medical Visual Question Answering",
      "title_zh": "用于医疗视觉问答的高效双",
      "authors": [
        "Zhilin Zhang",
        "Jie Wang",
        "Zhanghao Qin",
        "Ruiqi Zhu",
        "Xiaoliang Gong"
      ],
      "abstract": "Medical Visual Question Answering (MedVQA) has attracted growing interest at\nthe intersection of medical image understanding and natural language processing\nfor clinical applications. By interpreting medical images and providing precise\nanswers to relevant clinical inquiries, MedVQA has the potential to support\ndiagnostic decision-making and reduce workload across various fields like\nradiology. While recent approaches rely heavily on unified large pre-trained\nVisual-Language Models, research on more efficient fusion mechanisms remains\nrelatively limited in this domain. In this paper, we introduce a fusion model,\nOMniBAN, that integrates Orthogonality loss, Multi-head attention, and a\nBilinear Attention Network to achieve high computational efficiency as well as\nsolid performance. We conduct comprehensive experiments and demonstrate how\nbilinear attention fusion can approximate the performance of larger fusion\nmodels like cross-modal Transformer. Our results show that OMniBAN requires\nfewer parameters (approximately 2/3 of Transformer-based Co-Attention) and\nsubstantially lower FLOPs (approximately 1/4), while achieving comparable\noverall performance and even slight improvements on closed-ended questions on\ntwo key MedVQA benchmarks. This balance between efficiency and accuracy\nsuggests that OMniBAN could be a viable option for real-world medical image\nquestion answering, where computational resources are often constrained.",
      "tldr_zh": "本文提出了一种高效的融合模型 OMniBAN，用于 Medical Visual Question Answering (MedVQA)，旨在提升医疗图像理解和自然语言处理的计算效率。OMniBAN 整合了 Orthogonality loss、Multi-head attention 和 Bilinear Attention Network，实现高性能融合机制。实验结果显示，该模型在两个关键 MedVQA 基准上与大型 cross-modal Transformer 模型性能相当，甚至在闭合问题上略有改善，同时参数减少约 2/3，FLOPs 降低约 1/4。该方法为资源受限的临床决策支持提供了实用选项。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "To be published in 2025 International Joint Conference on Neural\n  Networks (IJCNN)",
      "pdf_url": "http://arxiv.org/pdf/2410.21000v3",
      "published_date": "2024-10-28 13:24:12 UTC",
      "updated_date": "2025-05-11 14:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:52:59.248813"
    },
    {
      "arxiv_id": "2410.21351v1",
      "title": "LinFormer: A Linear-based Lightweight Transformer Architecture For Time-Aware MIMO Channel Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yanliang Jin",
        "Yifan Wu",
        "Yuan Gao",
        "Shunqing Zhang",
        "Shugong Xu",
        "Cheng-Xiang Wang"
      ],
      "abstract": "The emergence of 6th generation (6G) mobile networks brings new challenges in\nsupporting high-mobility communications, particularly in addressing the issue\nof channel aging. While existing channel prediction methods offer improved\naccuracy at the expense of increased computational complexity, limiting their\npractical application in mobile networks. To address these challenges, we\npresent LinFormer, an innovative channel prediction framework based on a\nscalable, all-linear, encoder-only Transformer model. Our approach, inspired by\nnatural language processing (NLP) models such as BERT, adapts an encoder-only\narchitecture specifically for channel prediction tasks. We propose replacing\nthe computationally intensive attention mechanism commonly used in Transformers\nwith a time-aware multi-layer perceptron (TMLP), significantly reducing\ncomputational demands. The inherent time awareness of TMLP module makes it\nparticularly suitable for channel prediction tasks. We enhance LinFormer's\ntraining process by employing a weighted mean squared error loss (WMSELoss)\nfunction and data augmentation techniques, leveraging larger, readily available\ncommunication datasets. Our approach achieves a substantial reduction in\ncomputational complexity while maintaining high prediction accuracy, making it\nmore suitable for deployment in cost-effective base stations (BS).\nComprehensive experiments using both simulated and measured data demonstrate\nthat LinFormer outperforms existing methods across various mobility scenarios,\noffering a promising solution for future wireless communication systems.",
      "tldr_zh": "该研究提出LinFormer，一种基于全线性、轻量级Transformer架构的框架，用于时间感知的MIMO通道预测，以应对6G移动网络中高移动性通信的通道老化问题。LinFormer借鉴NLP模型如BERT的编码器-only设计，将传统的计算密集型注意力机制替换为时间感知多层感知器(TMLP)，并通过加权均方误差损失(WMSELoss)和数据增强技术优化训练过程，从而显著降低计算复杂度。实验结果显示，LinFormer在模拟和实测数据上超越现有方法，在各种移动场景中保持高预测准确性，并更适合部署在成本有效的基站中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21351v1",
      "published_date": "2024-10-28 13:04:23 UTC",
      "updated_date": "2024-10-28 13:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:53:09.700356"
    },
    {
      "arxiv_id": "2410.20981v3",
      "title": "EEG-Driven 3D Object Reconstruction with Style Consistency and Diffusion Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Xiang",
        "Wenhui Zhou",
        "Guojun Dai"
      ],
      "abstract": "Electroencephalography (EEG)-based visual perception reconstruction has\nbecome an important area of research. Neuroscientific studies indicate that\nhumans can decode imagined 3D objects by perceiving or imagining various visual\ninformation, such as color, shape, and rotation. Existing EEG-based visual\ndecoding methods typically focus only on the reconstruction of 2D visual\nstimulus images and face various challenges in generation quality, including\ninconsistencies in texture, shape, and color between the visual stimuli and the\nreconstructed images. This paper proposes an EEG-based 3D object reconstruction\nmethod with style consistency and diffusion priors. The method consists of an\nEEG-driven multi-task joint learning stage and an EEG-to-3D diffusion stage.\nThe first stage uses a neural EEG encoder based on regional semantic learning,\nemploying a multi-task joint learning scheme that includes a masked EEG signal\nrecovery task and an EEG based visual classification task. The second stage\nintroduces a latent diffusion model (LDM) fine-tuning strategy with\nstyle-conditioned constraints and a neural radiance field (NeRF) optimization\nstrategy. This strategy explicitly embeds semantic- and location-aware latent\nEEG codes and combines them with visual stimulus maps to fine-tune the LDM. The\nfine-tuned LDM serves as a diffusion prior, which, combined with the style loss\nof visual stimuli, is used to optimize NeRF for generating 3D objects. Finally,\nthrough experimental validation, we demonstrate that this method can\neffectively use EEG data to reconstruct 3D objects with style consistency.",
      "tldr_zh": "本文提出了一种基于EEG的3D对象重建方法，旨在解决现有EEG视觉解码中纹理、形状和颜色不一致的问题，通过引入style consistency和diffusion prior来提升重建质量。该方法包括两个阶段：第一阶段采用EEG-driven multi-task joint learning，包括masked EEG signal recovery和EEG-based visual classification任务；第二阶段则通过fine-tuning latent diffusion model (LDM)并结合neural radiance field (NeRF)优化，利用semantic- and location-aware EEG codes生成风格一致的3D对象。实验结果证明，该方法能有效利用EEG数据重建高质量的3D对象。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20981v3",
      "published_date": "2024-10-28 12:59:24 UTC",
      "updated_date": "2024-11-16 04:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:54:08.442944"
    },
    {
      "arxiv_id": "2410.20975v1",
      "title": "Geo-FuB: A Method for Constructing an Operator-Function Knowledge Base for Geospatial Code Generation Tasks Using Large Language Models",
      "title_zh": "Geo",
      "authors": [
        "Shuyang Hou",
        "Anqi Zhao",
        "Jianyuan Liang",
        "Zhangxiao Shen",
        "Huayi Wu"
      ],
      "abstract": "The rise of spatiotemporal data and the need for efficient geospatial\nmodeling have spurred interest in automating these tasks with large language\nmodels (LLMs). However, general LLMs often generate errors in geospatial code\ndue to a lack of domain-specific knowledge on functions and operators. To\naddress this, a retrieval-augmented generation (RAG) approach, utilizing an\nexternal knowledge base of geospatial functions and operators, is proposed.\nThis study introduces a framework to construct such a knowledge base,\nleveraging geospatial script semantics. The framework includes: Function\nSemantic Framework Construction (Geo-FuSE), Frequent Operator Combination\nStatistics (Geo-FuST), and Semantic Mapping (Geo-FuM). Techniques like\nChain-of-Thought, TF-IDF, and the APRIORI algorithm are utilized to derive and\nalign geospatial functions. An example knowledge base, Geo-FuB, built from\n154,075 Google Earth Engine scripts, is available on GitHub. Evaluation metrics\nshow a high accuracy, reaching 88.89% overall, with structural and semantic\naccuracies of 92.03% and 86.79% respectively. Geo-FuB's potential to optimize\ngeospatial code generation through the RAG and fine-tuning paradigms is\nhighlighted.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在地理空间代码生成任务中因缺少领域特定知识而产生的错误，提出了一种构建操作符-函数知识库的方法。论文引入了Geo-FuB框架，包括Function Semantic Framework Construction (Geo-FuSE)、Frequent Operator Combination Statistics (Geo-FuST)和Semantic Mapping (Geo-FuM)，并利用Chain-of-Thought、TF-IDF和APRIORI算法从154,075个Google Earth Engine脚本中提取和对齐地理空间函数。实验结果显示，Geo-FuB通过检索增强生成(RAG)技术实现了88.89%的整体准确率，结构准确率92.03%和语义准确率86.79%，从而优化了LLMs在地理空间建模中的性能。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20975v1",
      "published_date": "2024-10-28 12:50:27 UTC",
      "updated_date": "2024-10-28 12:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:55:27.476807"
    },
    {
      "arxiv_id": "2410.20971v2",
      "title": "BlueSuffix: Reinforced Blue Teaming for Vision-Language Models Against Jailbreak Attacks",
      "title_zh": "BlueSuffix：",
      "authors": [
        "Yunhan Zhao",
        "Xiang Zheng",
        "Lin Luo",
        "Yige Li",
        "Xingjun Ma",
        "Yu-Gang Jiang"
      ],
      "abstract": "In this paper, we focus on black-box defense for VLMs against jailbreak\nattacks. Existing black-box defense methods are either unimodal or bimodal.\nUnimodal methods enhance either the vision or language module of the VLM, while\nbimodal methods robustify the model through text-image representation\nrealignment. However, these methods suffer from two limitations: 1) they fail\nto fully exploit the cross-modal information, or 2) they degrade the model\nperformance on benign inputs. To address these limitations, we propose a novel\nblue-team method BlueSuffix that defends target VLMs against jailbreak attacks\nwithout compromising its performance under black-box setting. BlueSuffix\nincludes three key components: 1) a visual purifier against jailbreak images,\n2) a textual purifier against jailbreak texts, and 3) a blue-team suffix\ngenerator using reinforcement fine-tuning for enhancing cross-modal robustness.\nWe empirically show on four VLMs (LLaVA, MiniGPT-4, InstructionBLIP, and\nGemini) and four safety benchmarks (Harmful Instruction, AdvBench,\nMM-SafetyBench, and RedTeam-2K) that BlueSuffix outperforms the baseline\ndefenses by a significant margin. Our BlueSuffix opens up a promising direction\nfor defending VLMs against jailbreak attacks. Code is available at\nhttps://github.com/Vinsonzyh/BlueSuffix.",
      "tldr_zh": "本文提出BlueSuffix，一种强化蓝队方法，用于在黑-box defense设置下保护Vision-Language Models (VLMs)免受jailbreak attacks，同时不影响模型在良性输入上的性能。该方法包括visual purifier针对越狱图像、textual purifier针对越狱文本，以及基于reinforcement fine-tuning的blue-team suffix generator，以充分利用跨模态信息并提升鲁棒性。在四个VLMs（LLaVA、MiniGPT-4、InstructionBLIP和Gemini）和四个安全基准（Harmful Instruction、AdvBench、MM-SafetyBench和RedTeam-2K）上的实验表明，BlueSuffix显著优于基线防御方法，为VLMs的安全防护开辟了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20971v2",
      "published_date": "2024-10-28 12:43:47 UTC",
      "updated_date": "2025-02-12 05:52:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:55:47.523574"
    },
    {
      "arxiv_id": "2410.20966v1",
      "title": "Improving Detection of Person Class Using Dense Pooling",
      "title_zh": "翻译失败",
      "authors": [
        "Nouman Ahmad"
      ],
      "abstract": "Lately, the continuous development of deep learning models by many\nresearchers in the area of computer vision has attracted more researchers to\nfurther improve the accuracy of these models. FasterRCNN [32] has already\nprovided a state-of-the-art approach to improve the accuracy and detection of\n80 different objects given in the COCO dataset. To further improve the\nperformance of person detection we have conducted a different approach which\ngives the state-of-the-art conclusion. An ROI is a step in FasterRCNN that\nextract the features from the given image with a fixed size and transfer into\nfor further classification. To enhance the ROI performance, we have conducted\nan approach that implements dense pooling and converts the image into a 3D\nmodel to further transform into UV(ultra Violet) images which makes it easy to\nextract the right features from the images. To implement our approach we have\napproached the state-of-the-art COCO datasets and extracted 6982 images that\ninclude a person object and our final achievements conclude that using our\napproach has made significant results in detecting the person object in the\ngiven image",
      "tldr_zh": "本研究旨在提升Faster R-CNN模型在COCO数据集上检测“person”类别的准确性，针对现有模型的局限性提出了一种新方法。研究者改进了ROI（Region of Interest）步骤，通过引入dense pooling将图像转换为3D模型并进一步转化为UV图像，从而更有效地提取关键特征。实验使用COCO数据集中的6982张包含人对象的图像进行测试，结果显示该方法显著提高了人对象检测的性能，达到了state-of-the-art水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20966v1",
      "published_date": "2024-10-28 12:36:28 UTC",
      "updated_date": "2024-10-28 12:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:55:58.208915"
    },
    {
      "arxiv_id": "2410.20964v1",
      "title": "DeTeCtive: Detecting AI-generated Text via Multi-Level Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xun Guo",
        "Shan Zhang",
        "Yongxin He",
        "Ting Zhang",
        "Wanquan Feng",
        "Haibin Huang",
        "Chongyang Ma"
      ],
      "abstract": "Current techniques for detecting AI-generated text are largely confined to\nmanual feature crafting and supervised binary classification paradigms. These\nmethodologies typically lead to performance bottlenecks and unsatisfactory\ngeneralizability. Consequently, these methods are often inapplicable for\nout-of-distribution (OOD) data and newly emerged large language models (LLMs).\nIn this paper, we revisit the task of AI-generated text detection. We argue\nthat the key to accomplishing this task lies in distinguishing writing styles\nof different authors, rather than simply classifying the text into\nhuman-written or AI-generated text. To this end, we propose DeTeCtive, a\nmulti-task auxiliary, multi-level contrastive learning framework. DeTeCtive is\ndesigned to facilitate the learning of distinct writing styles, combined with a\ndense information retrieval pipeline for AI-generated text detection. Our\nmethod is compatible with a range of text encoders. Extensive experiments\ndemonstrate that our method enhances the ability of various text encoders in\ndetecting AI-generated text across multiple benchmarks and achieves\nstate-of-the-art results. Notably, in OOD zero-shot evaluation, our method\noutperforms existing approaches by a large margin. Moreover, we find our method\nboasts a Training-Free Incremental Adaptation (TFIA) capability towards OOD\ndata, further enhancing its efficacy in OOD detection scenarios. We will\nopen-source our code and models in hopes that our work will spark new thoughts\nin the field of AI-generated text detection, ensuring safe application of LLMs\nand enhancing compliance. Our code is available at\nhttps://github.com/heyongxin233/DeTeCtive.",
      "tldr_zh": "该研究指出，现有的 AI-generated text 检测方法依赖手动特征构建和监督二分类，存在性能瓶颈和泛化性差的问题，尤其在 out-of-distribution (OOD) 数据和新出现的 LLMs 上表现不佳。作者提出 DeTeCtive 框架，这是一个多任务辅助、多级对比学习（Multi-Level Contrastive Learning）机制，旨在通过学习不同作者的写作风格并结合密集信息检索管道来提升检测能力。该框架兼容多种文本编码器，在多个基准测试中实现了最先进的结果，并在 OOD 零样本评估中大幅优于现有方法。此外，DeTeCtive 具备 Training-Free Incremental Adaptation (TFIA) 能力，支持对 OOD 数据的增量适应，并计划开源代码以促进 AI 生成文本检测领域的安全应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in NeurIPS 2024. Code is available at\n  https://github.com/heyongxin233/DeTeCtive",
      "pdf_url": "http://arxiv.org/pdf/2410.20964v1",
      "published_date": "2024-10-28 12:34:49 UTC",
      "updated_date": "2024-10-28 12:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:56:11.316217"
    },
    {
      "arxiv_id": "2410.20957v1",
      "title": "Neuro-symbolic Learning Yielding Logical Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Zenan Li",
        "Yunpeng Huang",
        "Zhaoyu Li",
        "Yuan Yao",
        "Jingwei Xu",
        "Taolue Chen",
        "Xiaoxing Ma",
        "Jian Lu"
      ],
      "abstract": "Neuro-symbolic systems combine the abilities of neural perception and logical\nreasoning. However, end-to-end learning of neuro-symbolic systems is still an\nunsolved challenge. This paper proposes a natural framework that fuses neural\nnetwork training, symbol grounding, and logical constraint synthesis into a\ncoherent and efficient end-to-end learning process. The capability of this\nframework comes from the improved interactions between the neural and the\nsymbolic parts of the system in both the training and inference stages.\nTechnically, to bridge the gap between the continuous neural network and the\ndiscrete logical constraint, we introduce a difference-of-convex programming\ntechnique to relax the logical constraints while maintaining their precision.\nWe also employ cardinality constraints as the language for logical constraint\nlearning and incorporate a trust region method to avoid the degeneracy of\nlogical constraint in learning. Both theoretical analyses and empirical\nevaluations substantiate the effectiveness of the proposed framework.",
      "tldr_zh": "这篇论文提出了一种神经符号(neuro-symbolic)学习框架，将神经网络训练、符号接地和逻辑约束合成整合成一个高效的端到端学习过程，以提升神经和符号部分在训练与推理阶段的交互。框架通过difference-of-convex programming技术来放松离散逻辑约束，同时保持其精度，并采用cardinality constraints作为约束语言，同时使用trust region method避免约束在学习中的退化。理论分析和实证评估证明了该框架的有效性，在解决神经符号系统挑战方面取得了显著进展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at NeurIPS 2023, and code is\n  available at [this url](https://github.com/Lizn-zn/Nesy-Programming)",
      "pdf_url": "http://arxiv.org/pdf/2410.20957v1",
      "published_date": "2024-10-28 12:18:25 UTC",
      "updated_date": "2024-10-28 12:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:56:22.810852"
    },
    {
      "arxiv_id": "2410.21349v4",
      "title": "FALCON: Feedback-driven Adaptive Long/short-term memory reinforced Coding Optimization system",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyuan Li",
        "Yangfan He",
        "Lewei He",
        "Jianhui Wang",
        "Tianyu Shi",
        "Bin Lei",
        "Yuchen Li",
        "Qiuwu Chen"
      ],
      "abstract": "Recently, large language models (LLMs) have achieved significant progress in\nautomated code generation. Despite their strong instruction-following\ncapabilities, these models frequently struggled to align with user intent in\ncoding scenarios. In particular, they were hampered by datasets that lacked\ndiversity and failed to address specialized tasks or edge cases. Furthermore,\nchallenges in supervised fine-tuning (SFT) and reinforcement learning from\nhuman feedback (RLHF) led to failures in generating precise,\nhuman-intent-aligned code. To tackle these challenges and improve the code\ngeneration performance for automated programming systems, we propose\nFeedback-driven Adaptive Long/short-term memory reinforced Coding Optimization\n(i.e., FALCON). FALCON is structured into two hierarchical levels. From the\nglobal level, long-term memory improves code quality by retaining and applying\nlearned knowledge. At the local level, short-term memory allows for the\nincorporation of immediate feedback from compilers and AI systems.\nAdditionally, we introduce meta-reinforcement learning with feedback rewards to\nsolve the global-local bi-level optimization problem and enhance the model's\nadaptability across diverse code generation tasks. Extensive experiments\ndemonstrate that our technique achieves state-of-the-art performance, leading\nother reinforcement learning methods by more than 4.5 percentage points on the\nMBPP benchmark and 6.1 percentage points on the Humaneval benchmark. The\nopen-sourced code is publicly available at https://github.com/titurte/FALCON.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在代码生成中存在的用户意图不匹配、数据集多样性不足以及SFT和RLHF挑战等问题，提出FALCON系统——一个反馈驱动的自适应长/短时记忆强化编码优化框架。FALCON采用两层级结构：全局层通过长时记忆保留并应用学到的知识提升代码质量，局部层则利用短时记忆整合编译器和AI系统的即时反馈；此外，引入元强化学习(meta-reinforcement learning)结合反馈奖励，解决全局-局部双层优化问题，提高模型在多样化任务中的适应性。实验结果显示，FALCON在MBPP基准上比其他强化学习方法领先4.5百分点，在Humaneval基准上领先6.1百分点，展示了其在自动化编程系统中的卓越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.21349v4",
      "published_date": "2024-10-28 12:18:22 UTC",
      "updated_date": "2025-03-23 17:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:56:35.443486"
    },
    {
      "arxiv_id": "2410.20954v1",
      "title": "Active Legibility in Multiagent Reinforcement Learning",
      "title_zh": "多智能体强化学习中的主动可读性",
      "authors": [
        "Yanyu Liu",
        "Yinghui Pan",
        "Yifeng Zeng",
        "Biyang Ma",
        "Doshi Prashant"
      ],
      "abstract": "A multiagent sequential decision problem has been seen in many critical\napplications including urban transportation, autonomous driving cars, military\noperations, etc. Its widely known solution, namely multiagent reinforcement\nlearning, has evolved tremendously in recent years. Among them, the solution\nparadigm of modeling other agents attracts our interest, which is different\nfrom traditional value decomposition or communication mechanisms. It enables\nagents to understand and anticipate others' behaviors and facilitates their\ncollaboration. Inspired by recent research on the legibility that allows agents\nto reveal their intentions through their behavior, we propose a multiagent\nactive legibility framework to improve their performance. The\nlegibility-oriented framework allows agents to conduct legible actions so as to\nhelp others optimise their behaviors. In addition, we design a series of\nproblem domains that emulate a common scenario and best characterize the\nlegibility in multiagent reinforcement learning. The experimental results\ndemonstrate that the new framework is more efficient and costs less training\ntime compared to several multiagent reinforcement learning algorithms.",
      "tldr_zh": "该论文探讨了多智能体强化学习（Multiagent Reinforcement Learning）中主动可读性（Active Legibility）的概念，旨在通过让智能体显式揭示意图来提升协作效率。研究提出一个新的框架，允许智能体采用可读行为来帮助其他智能体优化决策，从而解决传统价值分解或通信机制的局限。作者设计了一系列模拟场景的问题域进行实验，结果表明，该框架比现有算法更高效，并显著减少了训练时间。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20954v1",
      "published_date": "2024-10-28 12:15:49 UTC",
      "updated_date": "2024-10-28 12:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:56:46.733836"
    },
    {
      "arxiv_id": "2410.20941v4",
      "title": "Fine-Grained and Multi-Dimensional Metrics for Document-Level Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Yirong Sun",
        "Dawei Zhu",
        "Yanjun Chen",
        "Erjia Xiao",
        "Xinghao Chen",
        "Xiaoyu Shen"
      ],
      "abstract": "Large language models (LLMs) have excelled in various NLP tasks, including\nmachine translation (MT), yet most studies focus on sentence-level translation.\nThis work investigates the inherent capability of instruction-tuned LLMs for\ndocument-level translation (docMT). Unlike prior approaches that require\nspecialized techniques, we evaluate LLMs by directly prompting them to\ntranslate entire documents in a single pass. Our results show that this method\nimproves translation quality compared to translating sentences separately, even\nwithout document-level fine-tuning. However, this advantage is not reflected in\nBLEU scores, which often favor sentence-based translations. We propose using\nthe LLM-as-a-judge paradigm for evaluation, where GPT-4 is used to assess\ndocument coherence, accuracy, and fluency in a more nuanced way than\nn-gram-based metrics. Overall, our work demonstrates that instruction-tuned\nLLMs can effectively leverage document context for translation. However, we\ncaution against using BLEU scores for evaluating docMT, as they often provide\nmisleading outcomes, failing to capture the quality of document-level\ntranslation. Code and the outputs from GPT4-as-a-judge are available at\nhttps://github.com/EIT-NLP/BLEUless_DocMT",
      "tldr_zh": "该研究评估了指令微调的大语言模型 (LLMs) 在文档级机器翻译 (docMT) 的固有能力，通过直接提示 LLMs 一次性翻译整个文档，而非逐句处理。结果显示，这种方法在翻译质量上优于句子级翻译，即使未进行文档级微调，但传统 BLEU 分数未能准确反映这一优势。作者提出使用 LLM-as-a-judge 范式（如 GPT-4）来评估翻译的文档连贯性、准确性和流畅性，提供更细粒度和多维度的评估指标。总体上，该工作证明 LLMs 可以有效利用文档上下文进行翻译，并警告不要依赖 BLEU 分数，因为它可能误导 docMT 的质量评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 Student Research Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.20941v4",
      "published_date": "2024-10-28 11:49:58 UTC",
      "updated_date": "2025-04-20 12:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:57:00.469933"
    },
    {
      "arxiv_id": "2410.21348v2",
      "title": "Large Language Model Benchmarks in Medical Tasks",
      "title_zh": "大语言模型基准在医疗任务中",
      "authors": [
        "Lawrence K. Q. Yan",
        "Qian Niu",
        "Ming Li",
        "Yichao Zhang",
        "Caitlyn Heqi Yin",
        "Cheng Fei",
        "Benji Peng",
        "Ziqian Bi",
        "Pohsun Feng",
        "Keyu Chen",
        "Tianyang Wang",
        "Yunze Wang",
        "Silin Chen",
        "Ming Liu",
        "Junyu Liu"
      ],
      "abstract": "With the increasing application of large language models (LLMs) in the\nmedical domain, evaluating these models' performance using benchmark datasets\nhas become crucial. This paper presents a comprehensive survey of various\nbenchmark datasets employed in medical LLM tasks. These datasets span multiple\nmodalities including text, image, and multimodal benchmarks, focusing on\ndifferent aspects of medical knowledge such as electronic health records\n(EHRs), doctor-patient dialogues, medical question-answering, and medical image\ncaptioning. The survey categorizes the datasets by modality, discussing their\nsignificance, data structure, and impact on the development of LLMs for\nclinical tasks such as diagnosis, report generation, and predictive decision\nsupport. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and\nCheXpert, which have facilitated advancements in tasks like medical report\ngeneration, clinical summarization, and synthetic data generation. The paper\nsummarizes the challenges and opportunities in leveraging these benchmarks for\nadvancing multimodal medical intelligence, emphasizing the need for datasets\nwith a greater degree of language diversity, structured omics data, and\ninnovative approaches to synthesis. This work also provides a foundation for\nfuture research in the application of LLMs in medicine, contributing to the\nevolving field of medical artificial intelligence.",
      "tldr_zh": "这篇论文对大型语言模型（LLMs）在医疗任务中的基准数据集进行了全面调查，涵盖了文本、图像和多模态数据集，包括电子健康记录（EHRs）、医生-患者对话、医疗问答和医疗图像描述等领域。论文按模态分类讨论了这些数据集的意义、数据结构及其对LLMs在诊断、报告生成和预测决策支持等临床任务中的推动作用，突出了关键基准如MIMIC-III、MIMIC-IV、BioASQ和PubMedQA。最终，论文总结了面临的挑战，如需要更多语言多样性和结构化omics数据，并为LLMs在医疗人工智能领域的未来研究提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.21348v2",
      "published_date": "2024-10-28 11:07:33 UTC",
      "updated_date": "2024-12-09 10:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:57:11.541841"
    },
    {
      "arxiv_id": "2410.20922v2",
      "title": "FACTS: A Factored State-Space Framework For World Modelling",
      "title_zh": "翻译失败",
      "authors": [
        "Li Nanbo",
        "Firas Laakom",
        "Yucheng Xu",
        "Wenyi Wang",
        "Jürgen Schmidhuber"
      ],
      "abstract": "World modelling is essential for understanding and predicting the dynamics of\ncomplex systems by learning both spatial and temporal dependencies. However,\ncurrent frameworks, such as Transformers and selective state-space models like\nMambas, exhibit limitations in efficiently encoding spatial and temporal\nstructures, particularly in scenarios requiring long-term high-dimensional\nsequence modelling. To address these issues, we propose a novel recurrent\nframework, the \\textbf{FACT}ored \\textbf{S}tate-space (\\textbf{FACTS}) model,\nfor spatial-temporal world modelling. The FACTS framework constructs a\ngraph-structured memory with a routing mechanism that learns permutable memory\nrepresentations, ensuring invariance to input permutations while adapting\nthrough selective state-space propagation. Furthermore, FACTS supports parallel\ncomputation of high-dimensional sequences. We empirically evaluate FACTS across\ndiverse tasks, including multivariate time series forecasting, object-centric\nworld modelling, and spatial-temporal graph prediction, demonstrating that it\nconsistently outperforms or matches specialised state-of-the-art models,\ndespite its general-purpose world modelling design.",
      "tldr_zh": "本研究提出了一种新型循环框架FACTS（Factored State-Space），旨在解决现有模型如Transformers和Mambas在空间-时间世界建模中的局限性，特别是处理长期高维序列时的效率问题。FACTS通过构建图结构内存和路由机制，学习可交换的内存表示，确保对输入排列不变性，同时支持选择性状态空间传播和高维序列的并行计算。作为一个通用框架，FACTS在多元时间序列预测、对象中心世界建模以及空间-时间图预测等任务上，表现优于或匹配专业最先进模型，证明了其在复杂系统动态预测中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Code released in https://github.com/NanboLi/FACTS",
      "pdf_url": "http://arxiv.org/pdf/2410.20922v2",
      "published_date": "2024-10-28 11:04:42 UTC",
      "updated_date": "2025-02-28 08:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:57:23.835574"
    },
    {
      "arxiv_id": "2410.20911v2",
      "title": "Hacking Back the AI-Hacker: Prompt Injection as a Defense Against LLM-driven Cyberattacks",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Pasquini",
        "Evgenios M. Kornaropoulos",
        "Giuseppe Ateniese"
      ],
      "abstract": "Large language models (LLMs) are increasingly being harnessed to automate\ncyberattacks, making sophisticated exploits more accessible and scalable. In\nresponse, we propose a new defense strategy tailored to counter LLM-driven\ncyberattacks. We introduce Mantis, a defensive framework that exploits LLMs'\nsusceptibility to adversarial inputs to undermine malicious operations. Upon\ndetecting an automated cyberattack, Mantis plants carefully crafted inputs into\nsystem responses, leading the attacker's LLM to disrupt their own operations\n(passive defense) or even compromise the attacker's machine (active defense).\nBy deploying purposefully vulnerable decoy services to attract the attacker and\nusing dynamic prompt injections for the attacker's LLM, Mantis can autonomously\nhack back the attacker. In our experiments, Mantis consistently achieved over\n95% effectiveness against automated LLM-driven attacks. To foster further\nresearch and collaboration, Mantis is available as an open-source tool:\nhttps://github.com/pasquini-dario/project_mantis",
      "tldr_zh": "该研究提出Mantis框架，作为对抗基于大型语言模型(LLMs)驱动的网络攻击的新型防御策略。Mantis利用LLMs对对抗输入的易感性，通过在系统响应中植入精心设计的提示注入(prompt injection)，以破坏攻击者的操作，包括被动防御（干扰恶意活动）和主动防御（反制攻击者机器）。框架还部署诱饵服务(decoy services)来吸引攻击者，并实现动态提示注入以自主反击。实验结果显示，Mantis对自动化LLM驱动攻击的有效性超过95%，并作为开源工具提供（https://github.com/pasquini-dario/project_mantis）。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "v0.2 (evaluated on more agents)",
      "pdf_url": "http://arxiv.org/pdf/2410.20911v2",
      "published_date": "2024-10-28 10:43:34 UTC",
      "updated_date": "2024-11-18 09:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:57:34.815113"
    },
    {
      "arxiv_id": "2410.20898v2",
      "title": "Diff-Instruct*: Towards Human-Preferred One-step Text-to-image Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weijian Luo",
        "Colin Zhang",
        "Debing Zhang",
        "Zhengyang Geng"
      ],
      "abstract": "In this paper, we introduce the Diff-Instruct* (DI*), an image data-free\napproach for building one-step text-to-image generative models that align with\nhuman preference while maintaining the ability to generate highly realistic\nimages. We frame human preference alignment as online reinforcement learning\nusing human feedback (RLHF), where the goal is to maximize the reward function\nwhile regularizing the generator distribution to remain close to a reference\ndiffusion process. Unlike traditional RLHF approaches, which rely on the KL\ndivergence for regularization, we introduce a novel score-based divergence\nregularization, which leads to significantly better performances. Although the\ndirect calculation of this preference alignment objective remains intractable,\nwe demonstrate that we can efficiently compute its gradient by deriving an\nequivalent yet tractable loss function. Remarkably, we used Diff-Instruct* to\ntrain a Stable Diffusion-XL-based 1-step model, the 2.6B DI*-SDXL-1step\ntext-to-image model, which can generate images of a resolution of 1024x1024\nwith only 1 generation step. DI*-SDXL-1step model uses only 1.88% inference\ntime and 29.30% GPU memory cost to outperform 12B FLUX-dev-50step significantly\nin PickScore, ImageReward, and CLIPScore on Parti prompt benchmark and HPSv2.1\non Human Preference Score benchmark, establishing a new state-of-the-art\nbenchmark of human-preferred 1-step text-to-image generative models. Besides\nthe strong quantitative performances, extensive qualitative comparisons also\nconfirm the advantages of DI* in terms of maintaining diversity, improving\nimage layouts, and enhancing aesthetic colors. We have released our\nindustry-ready model on the homepage:\n\\url{https://github.com/pkulwj1994/diff_instruct_star}.",
      "tldr_zh": "本研究提出Diff-Instruct* (DI*)，一种无需图像数据的文本到图像生成方法，旨在构建一步式生成模型，使其与人类偏好对齐，同时保持高真实性图像输出。\nDI* 通过在线强化学习（RLHF）最大化奖励函数，并引入基于分数的散度正则化代替传统KL散度，以显著提升性能，并通过可计算损失函数高效优化。\n实验结果显示，基于Stable Diffusion-XL的DI*-SDXL-1step模型（2.6B参数）在Parti提示基准和HPSv2.1上，在PickScore、ImageReward和CLIPScore等指标上优于12B FLUX-dev-50step模型，仅需1.88%的推理时间和29.30%的GPU内存。\n此外，该模型在图像多样性、布局和美学颜色方面表现出色，并已开源发布。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "revision: 2.6B 1-step text-to-image model outperforms 12B\n  Flux-dev-50step model in human preferences",
      "pdf_url": "http://arxiv.org/pdf/2410.20898v2",
      "published_date": "2024-10-28 10:26:19 UTC",
      "updated_date": "2024-12-24 05:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:57:50.426797"
    },
    {
      "arxiv_id": "2410.20894v1",
      "title": "Active Causal Structure Learning with Latent Variables: Towards Learning to Detour in Autonomous Robots",
      "title_zh": "带有潜在变量的主动因",
      "authors": [
        "Pablo de los Riscos",
        "Fernando Corbacho"
      ],
      "abstract": "Artificial General Intelligence (AGI) Agents and Robots must be able to cope\nwith everchanging environments and tasks. They must be able to actively\nconstruct new internal causal models of their interactions with the environment\nwhen new structural changes take place in the environment. Thus, we claim that\nactive causal structure learning with latent variables (ACSLWL) is a necessary\ncomponent to build AGI agents and robots. This paper describes how a complex\nplanning and expectation-based detour behavior can be learned by ACSLWL when,\nunexpectedly, and for the first time, the simulated robot encounters a sort of\ntransparent barrier in its pathway towards its target. ACSWL consists of acting\nin the environment, discovering new causal relations, constructing new causal\nmodels, exploiting the causal models to maximize its expected utility,\ndetecting possible latent variables when unexpected observations occur, and\nconstructing new structures-internal causal models and optimal estimation of\nthe associated parameters, to be able to cope efficiently with the new\nencountered situations. That is, the agent must be able to construct new causal\ninternal models that transform a previously unexpected and inefficient\n(sub-optimal) situation, into a predictable situation with an optimal operating\nplan.",
      "tldr_zh": "该论文提出主动因果结构学习 with latent variables (ACSLWL) 作为构建人工智能通用智能 (AGI) 代理和机器人的关键组件，以应对动态环境中的结构变化。研究聚焦于让模拟机器人通过 ACSLWL 学习绕行行为，例如在首次遇到透明障碍时，通过行动、发现因果关系、构建新因果模型并优化参数来最大化预期效用。结果显示，该方法能将意外情况转化为可预测的、最优规划路径，从而提升机器人的适应性和效率。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "44 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20894v1",
      "published_date": "2024-10-28 10:21:26 UTC",
      "updated_date": "2024-10-28 10:21:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:58:01.150094"
    },
    {
      "arxiv_id": "2410.20873v1",
      "title": "Explainability in AI Based Applications: A Framework for Comparing Different Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Arne Grobrugge",
        "Nidhi Mishra",
        "Johannes Jakubik",
        "Gerhard Satzger"
      ],
      "abstract": "The integration of artificial intelligence into business processes has\nsignificantly enhanced decision-making capabilities across various industries\nsuch as finance, healthcare, and retail. However, explaining the decisions made\nby these AI systems poses a significant challenge due to the opaque nature of\nrecent deep learning models, which typically function as black boxes. To\naddress this opacity, a multitude of explainability techniques have emerged.\nHowever, in practical business applications, the challenge lies in selecting an\nappropriate explainability method that balances comprehensibility with\naccuracy. This paper addresses the practical need of understanding differences\nin the output of explainability techniques by proposing a novel method for the\nassessment of the agreement of different explainability techniques. Based on\nour proposed methods, we provide a comprehensive comparative analysis of six\nleading explainability techniques to help guiding the selection of such\ntechniques in practice. Our proposed general-purpose method is evaluated on top\nof one of the most popular deep learning architectures, the Vision Transformer\nmodel, which is frequently employed in business applications. Notably, we\npropose a novel metric to measure the agreement of explainability techniques\nthat can be interpreted visually. By providing a practical framework for\nunderstanding the agreement of diverse explainability techniques, our research\naims to facilitate the broader integration of interpretable AI systems in\nbusiness applications.",
      "tldr_zh": "本论文探讨了AI应用中解释性（explainability）的挑战，针对深度学习模型的黑箱特性，提出了一种新方法来评估不同explainability techniques之间的共识。该方法通过全面比较六种领先的解释性技术，并在Vision Transformer模型上进行评估，引入了一个新型的视觉可解释度量指标，帮助指导实践中的技术选择。研究结果显示，该框架能平衡可理解性和准确性，从而促进可解释AI在商业领域的更广泛整合。",
      "categories": [
        "cs.AI",
        "14J60 (Primary) 14F05, 14J26 (Secondary)",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20873v1",
      "published_date": "2024-10-28 09:45:34 UTC",
      "updated_date": "2024-10-28 09:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:58:13.428930"
    },
    {
      "arxiv_id": "2411.05802v1",
      "title": "Similarity-based context aware continual learning for spiking neural networks",
      "title_zh": "基于相似性的上下文感知持续学习，用于脉冲神经网络",
      "authors": [
        "Bing Han",
        "Feifei Zhao",
        "Yang Li",
        "Qingqun Kong",
        "Xianqi Li",
        "Yi Zeng"
      ],
      "abstract": "Biological brains have the capability to adaptively coordinate relevant\nneuronal populations based on the task context to learn continuously changing\ntasks in real-world environments. However, existing spiking neural\nnetwork-based continual learning algorithms treat each task equally, ignoring\nthe guiding role of different task similarity associations for network\nlearning, which limits knowledge utilization efficiency. Inspired by the\ncontext-dependent plasticity mechanism of the brain, we propose a\nSimilarity-based Context Aware Spiking Neural Network (SCA-SNN) continual\nlearning algorithm to efficiently accomplish task incremental learning and\nclass incremental learning. Based on contextual similarity across tasks, the\nSCA-SNN model can adaptively reuse neurons from previous tasks that are\nbeneficial for new tasks (the more similar, the more neurons are reused) and\nflexibly expand new neurons for the new task (the more similar, the fewer\nneurons are expanded). Selective reuse and discriminative expansion\nsignificantly improve the utilization of previous knowledge and reduce energy\nconsumption. Extensive experimental results on CIFAR100, ImageNet generalized\ndatasets, and FMNIST-MNIST, SVHN-CIFAR100 mixed datasets show that our SCA-SNN\nmodel achieves superior performance compared to both SNN-based and DNN-based\ncontinual learning algorithms. Additionally, our algorithm has the capability\nto adaptively select similar groups of neurons for related tasks, offering a\npromising approach to enhancing the biological interpretability of efficient\ncontinual learning.",
      "tldr_zh": "这篇论文提出了一种基于任务相似性的上下文感知持续学习算法（SCA-SNN），针对 Spiking Neural Networks（SNNs），以模拟生物大脑的上下文依赖可塑性机制。SCA-SNN 通过评估任务间的上下文相似性，自适应地重用先前任务的有益神经元（相似度越高，重用越多）和灵活扩展新神经元（相似度越高，扩展越少），从而提高知识利用效率并降低能耗。实验结果显示，该算法在 CIFAR100、ImageNet 等数据集以及 FMNIST-MNIST 和 SVHN-CIFAR100 混合数据集上，优于现有的 SNN-based 和 DNN-based 持续学习方法。总体上，SCA-SNN 不仅提升了任务增量学习和类增量学习的性能，还增强了算法的生物可解释性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05802v1",
      "published_date": "2024-10-28 09:38:57 UTC",
      "updated_date": "2024-10-28 09:38:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:58:26.572899"
    },
    {
      "arxiv_id": "2410.21346v1",
      "title": "Towards Trustworthy Machine Learning in Production: An Overview of the Robustness in MLOps Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Firas Bayram",
        "Bestoun S. Ahmed"
      ],
      "abstract": "Artificial intelligence (AI), and especially its sub-field of Machine\nLearning (ML), are impacting the daily lives of everyone with their ubiquitous\napplications. In recent years, AI researchers and practitioners have introduced\nprinciples and guidelines to build systems that make reliable and trustworthy\ndecisions. From a practical perspective, conventional ML systems process\nhistorical data to extract the features that are consequently used to train ML\nmodels that perform the desired task. However, in practice, a fundamental\nchallenge arises when the system needs to be operationalized and deployed to\nevolve and operate in real-life environments continuously. To address this\nchallenge, Machine Learning Operations (MLOps) have emerged as a potential\nrecipe for standardizing ML solutions in deployment. Although MLOps\ndemonstrated great success in streamlining ML processes, thoroughly defining\nthe specifications of robust MLOps approaches remains of great interest to\nresearchers and practitioners. In this paper, we provide a comprehensive\noverview of the trustworthiness property of MLOps systems. Specifically, we\nhighlight technical practices to achieve robust MLOps systems. In addition, we\nsurvey the existing research approaches that address the robustness aspects of\nML systems in production. We also review the tools and software available to\nbuild MLOps systems and summarize their support to handle the robustness\naspects. Finally, we present the open challenges and propose possible future\ndirections and opportunities within this emerging field. The aim of this paper\nis to provide researchers and practitioners working on practical AI\napplications with a comprehensive view to adopt robust ML solutions in\nproduction environments.",
      "tldr_zh": "这篇论文概述了在生产环境中构建可信赖的机器学习（Machine Learning, ML）系统的策略，重点关注 MLOps 框架的鲁棒性（Robustness）。作者讨论了 ML 系统从处理历史数据到实际部署的挑战，并提出技术实践来标准化 MLOps 系统，以确保其在真实环境中持续可靠运行。论文调查了现有研究方法、工具和软件对鲁棒性的支持，同时总结了开放挑战并建议未来方向，最终旨在为 AI 从业者提供指导，以采用更稳健的 ML 解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21346v1",
      "published_date": "2024-10-28 09:34:08 UTC",
      "updated_date": "2024-10-28 09:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:58:38.179896"
    },
    {
      "arxiv_id": "2410.20856v2",
      "title": "Strada-LLM: Graph LLM for traffic prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohamad Moghadas",
        "Yangxintong Lyu",
        "Bruno Cornelis",
        "Alexandre Alahi",
        "Adrian Munteanu"
      ],
      "abstract": "Traffic prediction is a vital component of intelligent transportation\nsystems. By reasoning about traffic patterns in both the spatial and temporal\ndimensions, accurate and interpretable predictions can be provided. A\nconsiderable challenge in traffic prediction lies in handling the diverse data\ndistributions caused by vastly different traffic conditions occurring at\ndifferent locations. LLMs have been a dominant solution due to their remarkable\ncapacity to adapt to new datasets with very few labeled data samples, i.e.,\nfew-shot adaptability. However, existing forecasting techniques mainly focus on\nextracting local graph information and forming a text-like prompt, leaving LLM-\nbased traffic prediction an open problem. This work presents a probabilistic\nLLM for traffic forecasting with three highlights. We propose a graph-aware LLM\nfor traffic prediction that considers proximal traffic information.\nSpecifically, by considering the traffic of neighboring nodes as covariates,\nour model outperforms the corresponding time-series LLM. Furthermore, we adopt\na lightweight approach for efficient domain adaptation when facing new data\ndistributions in few-shot fashion. The comparative experiment demonstrates the\nproposed method outperforms the state-of-the-art LLM-based methods and the\ntraditional GNN- based supervised approaches. Furthermore, Strada-LLM can be\neasily adapted to different LLM backbones without a noticeable performance\ndrop.",
      "tldr_zh": "该研究提出Strada-LLM，一种基于图结构的LLM，用于交通预测，通过考虑空间和时间维度的交通模式来处理不同地点的数据分布多样性。关键方法包括将临近节点的交通信息作为协变量进行graph-aware推理，并采用轻量级策略实现少样本域适应，从而提升预测的准确性和可解释性。实验结果显示，Strada-LLM优于现有LLM-based方法和传统GNN-based监督方法，并在不同LLM骨干网络上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The reviewers decided to reject it. After getting the reviews, we\n  wanted to study more.",
      "pdf_url": "http://arxiv.org/pdf/2410.20856v2",
      "published_date": "2024-10-28 09:19:29 UTC",
      "updated_date": "2025-02-14 16:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:00:49.944988"
    },
    {
      "arxiv_id": "2410.20848v1",
      "title": "Deep Insights into Automated Optimization with Large Language Models and Evolutionary Algorithms",
      "title_zh": "大型语言模型与进化算法在自动化优化中的深度见解",
      "authors": [
        "He Yu",
        "Jing Liu"
      ],
      "abstract": "Designing optimization approaches, whether heuristic or meta-heuristic,\nusually demands extensive manual intervention and has difficulty generalizing\nacross diverse problem domains. The combination of Large Language Models (LLMs)\nand Evolutionary Algorithms (EAs) offers a promising new approach to overcome\nthese limitations and make optimization more automated. In this setup, LLMs act\nas dynamic agents that can generate, refine, and interpret optimization\nstrategies, while EAs efficiently explore complex solution spaces through\nevolutionary operators. Since this synergy enables a more efficient and\ncreative search process, we first conduct an extensive review of recent\nresearch on the application of LLMs in optimization. We focus on LLMs' dual\nfunctionality as solution generators and algorithm designers. Then, we\nsummarize the common and valuable designs in existing work and propose a novel\nLLM-EA paradigm for automated optimization. Furthermore, centered on this\nparadigm, we conduct an in-depth analysis of innovative methods for three key\ncomponents: individual representation, variation operators, and fitness\nevaluation. We address challenges related to heuristic generation and solution\nexploration, especially from the LLM prompts' perspective. Our systematic\nreview and thorough analysis of the paradigm can assist researchers in better\nunderstanding the current research and promoting the development of combining\nLLMs with EAs for automated optimization.",
      "tldr_zh": "该论文探讨了使用 Large Language Models (LLMs) 和 Evolutionary Algorithms (EAs) 实现自动化的优化过程，以解决传统优化方法依赖手动干预和泛化困难的问题。研究首先回顾了 LLMs 在优化中的双重作用，即作为解决方案生成器和算法设计器，并总结了现有工作的关键设计。论文提出一个新型的 LLM-EA 范式，并对核心组件——个体表示、变异算子（variation operators）和适应度评估（fitness evaluation）——进行深入分析，从 LLM 提示（prompts）的角度解决启发式生成和解决方案探索的挑战。这种结合有助于提升优化的效率和创造性，并为未来研究提供指导。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20848v1",
      "published_date": "2024-10-28 09:04:49 UTC",
      "updated_date": "2024-10-28 09:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:00:55.177101"
    },
    {
      "arxiv_id": "2410.22365v1",
      "title": "Vascular Segmentation of Functional Ultrasound Images using Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hana Sebia",
        "Thomas Guyet",
        "Mickaël Pereira",
        "Marco Valdebenito",
        "Hugues Berry",
        "Benjamin Vidal"
      ],
      "abstract": "Segmentation of medical images is a fundamental task with numerous\napplications. While MRI, CT, and PET modalities have significantly benefited\nfrom deep learning segmentation techniques, more recent modalities, like\nfunctional ultrasound (fUS), have seen limited progress. fUS is a non invasive\nimaging method that measures changes in cerebral blood volume (CBV) with high\nspatio-temporal resolution. However, distinguishing arterioles from venules in\nfUS is challenging due to opposing blood flow directions within the same pixel.\nUltrasound localization microscopy (ULM) can enhance resolution by tracking\nmicrobubble contrast agents but is invasive, and lacks dynamic CBV\nquantification. In this paper, we introduce the first deep learning-based\nsegmentation tool for fUS images, capable of differentiating signals from\ndifferent vascular compartments, based on ULM automatic annotation and enabling\ndynamic CBV quantification. We evaluate various UNet architectures on fUS\nimages of rat brains, achieving competitive segmentation performance, with 90%\naccuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames\nfrom a fUS stack. These results are comparable to those from tubular structure\nsegmentation in other imaging modalities. Additionally, models trained on\nresting-state data generalize well to images captured during visual\nstimulation, highlighting robustness. This work offers a non-invasive,\ncost-effective alternative to ULM, enhancing fUS data interpretation and\nimproving understanding of vessel function. Our pipeline shows high linear\ncorrelation coefficients between signals from predicted and actual compartments\nin both cortical and deeperregions, showcasing its ability to accurately\ncapture blood flow dynamics.",
      "tldr_zh": "本论文提出了一种基于深度学习的工具，用于 functional ultrasound (fUS) 图像的血管分割，能够区分不同血管区段，如动脉和静脉，并支持动态 cerebral blood volume (CBV) 量化。方法采用各种 UNet 架构，利用 ultrasound localization microscopy (ULM) 的自动标注，在大鼠脑 fUS 图像上训练，仅需 100 个时间帧即可实现。实验结果显示，该工具在分割性能上达到 90% 准确率、71% F1 分数和 0.59 IoU，且模型在静息状态数据上训练后，能良好泛化到视觉刺激图像，提供非侵入性、成本效益高的替代方案，提升了对血管功能的理解和 fUS 数据解释。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22365v1",
      "published_date": "2024-10-28 09:00:28 UTC",
      "updated_date": "2024-10-28 09:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:59:14.849985"
    },
    {
      "arxiv_id": "2410.20843v1",
      "title": "Generative Simulations of The Solar Corona Evolution With Denoising Diffusion : Proof of Concept",
      "title_zh": "使用去噪扩散的太阳日冕演化生成式模拟：概念证明",
      "authors": [
        "Grégoire Francisco",
        "Francesco Pio Ramunno",
        "Manolis K. Georgoulis",
        "João Fernandes",
        "Teresa Barata",
        "Dario Del Moro"
      ],
      "abstract": "The solar magnetized corona is responsible for various manifestations with a\nspace weather impact, such as flares, coronal mass ejections (CMEs) and,\nnaturally, the solar wind. Modeling the corona's dynamics and evolution is\ntherefore critical for improving our ability to predict space weather In this\nwork, we demonstrate that generative deep learning methods, such as Denoising\nDiffusion Probabilistic Models (DDPM), can be successfully applied to simulate\nfuture evolutions of the corona as observed in Extreme Ultraviolet (EUV)\nwavelengths. Our model takes a 12-hour video of an Active Region (AR) as input\nand simulate the potential evolution of the AR over the subsequent 12 hours,\nwith a time-resolution of two hours. We propose a light UNet backbone\narchitecture adapted to our problem by adding 1D temporal convolutions after\neach classical 2D spatial ones, and spatio-temporal attention in the bottleneck\npart. The model not only produce visually realistic outputs but also captures\nthe inherent stochasticity of the system's evolution. Notably, the simulations\nenable the generation of reliable confidence intervals for key predictive\nmetrics such as the EUV peak flux and fluence of the ARs, paving the way for\nprobabilistic and interpretable space weather forecasting. Future studies will\nfocus on shorter forecasting horizons with increased spatial and temporal\nresolution, aiming at reducing the uncertainty of the simulations and providing\npractical applications for space weather forecasting. The code used for this\nstudy is available at the following link:\nhttps://github.com/gfrancisco20/video_diffusion",
      "tldr_zh": "这篇论文证明了使用 Denoising Diffusion Probabilistic Models (DDPM) 可以有效模拟太阳日冕在 Extreme Ultraviolet (EUV) 波长下的未来演化，作为一种空间天气预报工具。模型以 Active Region (AR) 的12小时视频为输入，通过改进的轻量级 UNet 架构（添加1D temporal convolutions 和 spatio-temporal attention），预测后续12小时的潜在变化，并捕捉系统的固有随机性。实验结果显示，模拟输出视觉逼真且能生成可靠的置信区间，如 EUV 峰值通量和流明，这为概率化和可解释的空间天气预报铺平了道路。未来工作将聚焦于缩短预测周期、提高空间和时间分辨率，以减少不确定性并实现实际应用。",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20843v1",
      "published_date": "2024-10-28 08:55:33 UTC",
      "updated_date": "2024-10-28 08:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:59:27.099978"
    },
    {
      "arxiv_id": "2410.20825v1",
      "title": "ADLM -- stega: A Universal Adaptive Token Selection Algorithm for Improving Steganographic Text Quality via Information Entropy",
      "title_zh": "ADLM -- stega：一种通用自适应令牌选择算法，通过信息熵提升隐写文本质量",
      "authors": [
        "Zezheng Qin",
        "Congcong Sun",
        "Taiyi He",
        "Yuke He",
        "Azizol Abdullah",
        "Normalia Samian",
        "Nuur Alifah Roslan"
      ],
      "abstract": "In the context of widespread global information sharing, information security\nand privacy protection have become focal points. Steganographic systems enhance\ninformation security by embedding confidential information into public\ncarriers; however, existing generative text steganography methods face\nchallenges in handling the long-tail distribution of candidate word pools,\nwhich impacts the imperceptibility of steganographic information. This paper\nproposes a quality control theory for steganographic text generation based on\ninformation entropy constraints, exploring the relationship between the\nimperceptibility of steganographic texts and information entropy. By\ncontrolling the information entropy of the candidate word pool within a\nspecific range, we optimize the imperceptibility of the steganographic text. We\nestablish upper and lower bounds for information entropy and introduce an\nadaptive truncation method to balance semantic coherence and lexical diversity.\nExperimental results demonstrate that reasonably controlling the candidate pool\nsize and information entropy thresholds significantly enhances the quality and\ndetection resistance of steganographic texts, showcasing broad application\npotential in the field of natural language processing.",
      "tldr_zh": "这篇论文提出了ADLM -- stega，一种通用的自适应令牌选择算法，通过信息熵（information entropy）约束来提升隐写文本（steganographic text）的质量，解决现有方法在处理候选词池长尾分布时影响信息隐秘性的问题。算法基于信息熵控制理论，建立了熵值上限和下限，并引入自适应截断方法（adaptive truncation method）以平衡语义连贯性和词汇多样性。实验结果表明，该方法显著提高了隐写文本的检测抵抗力和整体质量，在自然语言处理领域展现出广泛的应用潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20825v1",
      "published_date": "2024-10-28 08:25:31 UTC",
      "updated_date": "2024-10-28 08:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:59:38.674690"
    },
    {
      "arxiv_id": "2411.00816v3",
      "title": "CycleResearcher: Improving Automated Research via Automated Review",
      "title_zh": "CycleResearcher：通过自动化审阅改善自动化研究",
      "authors": [
        "Yixuan Weng",
        "Minjun Zhu",
        "Guangsheng Bao",
        "Hongbo Zhang",
        "Jindong Wang",
        "Yue Zhang",
        "Linyi Yang"
      ],
      "abstract": "The automation of scientific discovery has been a long-standing goal within\nthe research community, driven by the potential to accelerate knowledge\ncreation. While significant progress has been made using commercial large\nlanguage models (LLMs) as research assistants or idea generators, the\npossibility of automating the entire research process with open-source LLMs\nremains largely unexplored. This paper explores the feasibility of using\nopen-source post-trained LLMs as autonomous agents capable of performing the\nfull cycle of automated research and review, from literature review and\nmanuscript preparation to peer review and paper refinement. Our iterative\npreference training framework consists of CycleResearcher, which conducts\nresearch tasks, and CycleReviewer, which simulates the peer review process,\nproviding iterative feedback via reinforcement learning. To train these models,\nwe develop two new datasets, Review-5k and Research-14k, reflecting real-world\nmachine learning research and peer review dynamics. Our results demonstrate\nthat CycleReviewer achieves promising performance with a 26.89\\% reduction in\nmean absolute error (MAE) compared to individual human reviewers in predicting\npaper scores, indicating the potential of LLMs to effectively assist\nexpert-level research evaluation. In research, the papers generated by the\nCycleResearcher model achieved a score of 5.36 in simulated peer reviews,\nshowing some competitiveness in terms of simulated review scores compared to\nthe preprint level of 5.24 from human experts, while still having room for\nimprovement compared to the accepted paper level of 5.69. This work represents\na significant step toward fully automated scientific inquiry, providing ethical\nsafeguards and exploring AI-driven research capabilities. The code, dataset and\nmodel weight are released at https://wengsyx.github.io/Researcher/.",
      "tldr_zh": "这篇论文探讨了使用开源大型语言模型 (LLMs) 作为自主代理来自动化整个研究过程，包括文献综述、手稿准备、同行评审和论文完善。论文提出了一种迭代偏好训练框架，包含 CycleResearcher（负责研究任务）和 CycleReviewer（模拟同行评审并提供强化学习反馈），并开发了两个新数据集：Review-5k 和 Research-14k，以反映真实机器学习研究和评审动态。实验结果显示，CycleReviewer 在预测论文分数时比人类评审员减少了 26.89% 的平均绝对误差 (MAE)，而 CycleResearcher 生成的论文在模拟评审中得分 5.36，与人类专家预印本水平 (5.24) 相比具有竞争力，但仍需改进以达到接受论文水平 (5.69)。这项工作标志着向完全自动化科学研究迈进的重要一步，并提供了道德保障，同时开源了代码、数据集和模型权重。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accept in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.00816v3",
      "published_date": "2024-10-28 08:10:21 UTC",
      "updated_date": "2025-03-08 14:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T17:59:52.253916"
    },
    {
      "arxiv_id": "2410.20811v2",
      "title": "Bridging the Gap between Expert and Language Models: Concept-guided Chess Commentary Generation and Evaluation",
      "title_zh": "桥接专家模型与语言模型",
      "authors": [
        "Jaechang Kim",
        "Jinmin Goh",
        "Inseok Hwang",
        "Jaewoong Cho",
        "Jungseul Ok"
      ],
      "abstract": "Deep learning-based expert models have reached superhuman performance in\ndecision-making domains such as chess and Go. However, it is under-explored to\nexplain or comment on given decisions although it is important for model\nexplainability and human education. The outputs of expert models are accurate,\nbut yet difficult to interpret for humans. On the other hand, large language\nmodels (LLMs) can produce fluent commentary but are prone to hallucinations due\nto their limited decision-making capabilities. To bridge this gap between\nexpert models and LLMs, we focus on chess commentary as a representative task\nof explaining complex decision-making processes through language and address\nboth the generation and evaluation of commentary. We introduce Concept-guided\nChess Commentary generation (CCC) for producing commentary and GPT-based Chess\nCommentary Evaluation (GCC-Eval) for assessing it. CCC integrates the\ndecision-making strengths of expert models with the linguistic fluency of LLMs\nthrough prioritized, concept-based explanations. GCC-Eval leverages expert\nknowledge to evaluate chess commentary based on informativeness and linguistic\nquality. Experimental results, validated by both human judges and GCC-Eval,\ndemonstrate that CCC generates commentary which is accurate, informative, and\nfluent.",
      "tldr_zh": "这篇论文针对专家模型（如在国际象棋决策中表现超人但缺乏解释性）和大型语言模型（LLMs）（能生成流畅文本但易产生幻觉）的差距，提出Concept-guided Chess Commentary generation (CCC)方法，通过优先化的概念-based 解释整合二者优势，生成准确的国际象棋评论。同时，引入GPT-based Chess Commentary Evaluation (GCC-Eval)框架，基于信息性和语言质量评估评论的质量。实验结果显示，CCC 生成的评论在准确性、信息性和流畅性上均优于基线，经人类评判和GCC-Eval验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Appears in NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.20811v2",
      "published_date": "2024-10-28 07:59:34 UTC",
      "updated_date": "2025-02-08 08:28:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:01:06.816890"
    },
    {
      "arxiv_id": "2410.20791v2",
      "title": "From Cool Demos to Production-Ready FMware: Core Challenges and a Technology Roadmap",
      "title_zh": "翻译失败",
      "authors": [
        "Gopi Krishnan Rajbahadur",
        "Gustavo A. Oliva",
        "Dayi Lin",
        "Ahmed E. Hassan"
      ],
      "abstract": "The rapid expansion of foundation models (FMs), such as large language models\n(LLMs), has given rise to FMware--software systems that integrate FMs as core\ncomponents. While building demonstration-level FMware is relatively\nstraightforward, transitioning to production-ready systems presents numerous\nchallenges, including reliability, high implementation costs, scalability, and\ncompliance with privacy regulations. Our paper conducts a semi-structured\nthematic synthesis to identify the key challenges in productionizing FMware\nacross diverse data sources including our own industry experience in developing\nFMArts--a FMware lifecycle engineering platform and integrating it into Huawei\ncloud, grey literature, academic publications, hands-on involvement in the Open\nPlatform for Enterprise AI (OPEA), organizing the AIware conference and\nBootcamp, and co-leading the ISO SPDX SBOM working group on AI and datasets. We\nidentify critical issues in FM selection, data and model alignment, prompt\nengineering, agent orchestration, system testing, and deployment, alongside\ncross-cutting concerns such as memory management, observability, and feedback\nintegration. We discuss needed technologies and strategies to address these\nchallenges and offer guidance on how to enable the transition from\ndemonstration systems to scalable, production-ready FMware solutions. Our\nfindings underscore the importance of continued research and multi-industry\ncollaboration to advance the development of production-ready FMware.",
      "tldr_zh": "这篇论文探讨了基础模型（FMs）如大型语言模型（LLMs）在软件系统（FMware）中的应用，从演示级系统过渡到生产级系统的核心挑战，包括可靠性、高实施成本、可扩展性和隐私合规。作者通过半结构化主题合成方法，结合自身行业经验（如开发 FMArts 平台并整合到华为云）、灰色文献、学术出版物以及参与 OPEA 和 ISO SPDX SBOM 工作组，识别了关键问题，如 FM 选择、数据和模型对齐、提示工程、代理编排、系统测试和部署，以及跨领域关切如内存管理和可观察性。论文提出技术策略和路线图，以解决这些挑战，并指导从演示系统向可扩展生产级 FMware 的转型。最终，研究强调持续研究和多行业合作对于推进 FMware 发展的必要性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20791v2",
      "published_date": "2024-10-28 07:16:00 UTC",
      "updated_date": "2025-01-27 17:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:01:19.912136"
    },
    {
      "arxiv_id": "2410.21345v1",
      "title": "Absorb & Escape: Overcoming Single Model Limitations in Generating Genomic Sequences",
      "title_zh": "Absorb & Escape：克服单一模型在生成基因组序列中的局限性",
      "authors": [
        "Zehui Li",
        "Yuhao Ni",
        "Guoxuan Xia",
        "William Beardall",
        "Akashaditya Das",
        "Guy-Bart Stan",
        "Yiren Zhao"
      ],
      "abstract": "Abstract Recent advances in immunology and synthetic biology have accelerated\nthe development of deep generative methods for DNA sequence design. Two\ndominant approaches in this field are AutoRegressive (AR) models and Diffusion\nModels (DMs). However, genomic sequences are functionally heterogeneous,\nconsisting of multiple connected regions (e.g., Promoter Regions, Exons, and\nIntrons) where elements within each region come from the same probability\ndistribution, but the overall sequence is non-homogeneous. This heterogeneous\nnature presents challenges for a single model to accurately generate genomic\nsequences. In this paper, we analyze the properties of AR models and DMs in\nheterogeneous genomic sequence generation, pointing out crucial limitations in\nboth methods: (i) AR models capture the underlying distribution of data by\nfactorizing and learning the transition probability but fail to capture the\nglobal property of DNA sequences. (ii) DMs learn to recover the global\ndistribution but tend to produce errors at the base pair level. To overcome the\nlimitations of both approaches, we propose a post-training sampling method,\ntermed Absorb & Escape (A&E) to perform compositional generation from AR models\nand DMs. This approach starts with samples generated by DMs and refines the\nsample quality using an AR model through the alternation of the Absorb and\nEscape steps. To assess the quality of generated sequences, we conduct\nextensive experiments on 15 species for conditional and unconditional DNA\ngeneration. The experiment results from motif distribution, diversity checks,\nand genome integration tests unequivocally show that A&E outperforms\nstate-of-the-art AR models and DMs in genomic sequence generation.",
      "tldr_zh": "本研究分析了AutoRegressive (AR) 模型和Diffusion Models (DMs)在生成异质基因组序列时的局限性：AR 模型能捕捉局部分布但忽略全局属性，而DMs 虽学习全局分布却易在基础对级别出错。针对这些问题，作者提出了一种后训练采样方法Absorb & Escape (A&E)，通过交替Absorb和Escape步骤，利用DMs生成的样本并借助AR模型进行精炼，实现对Promoter Regions、Exons和Introns等区域的组合生成。在15个物种的条件和无条件DNA生成实验中，A&E在motif distribution、多样性检查和基因组整合测试方面均优于现有模型，显著提升了序列生成质量。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21345v1",
      "published_date": "2024-10-28 07:00:27 UTC",
      "updated_date": "2024-10-28 07:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:01:31.410451"
    },
    {
      "arxiv_id": "2410.20783v1",
      "title": "Graph-based Uncertainty Metrics for Long-form Language Model Outputs",
      "title_zh": "翻译失败",
      "authors": [
        "Mingjian Jiang",
        "Yangjun Ruan",
        "Prasanna Sattigeri",
        "Salim Roukos",
        "Tatsunori Hashimoto"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nimproved text generation capabilities, but these systems are still known to\nhallucinate, and granular uncertainty estimation for long-form LLM generations\nremains challenging. In this work, we propose Graph Uncertainty -- which\nrepresents the relationship between LLM generations and claims within them as a\nbipartite graph and estimates the claim-level uncertainty with a family of\ngraph centrality metrics. Under this view, existing uncertainty estimation\nmethods based on the concept of self-consistency can be viewed as using degree\ncentrality as an uncertainty measure, and we show that more sophisticated\nalternatives such as closeness centrality provide consistent gains at\nclaim-level uncertainty estimation. Moreover, we present uncertainty-aware\ndecoding techniques that leverage both the graph structure and uncertainty\nestimates to improve the factuality of LLM generations by preserving only the\nmost reliable claims. Compared to existing methods, our graph-based uncertainty\nmetrics lead to an average of 6.8% relative gains on AUPRC across various\nlong-form generation settings, and our end-to-end system provides consistent\n2-4% gains in factuality over existing decoding techniques while significantly\nimproving the informativeness of generated responses.",
      "tldr_zh": "本文提出 Graph Uncertainty 指标，通过构建二分图来表示 Large Language Models (LLMs) 长文本生成及其内部声明的关系，并使用图中心性指标（如 closeness centrality）来估计声明级别的不确定性。相比现有基于自一致性的方法（如度中心性），该方法显著提高了不确定性评估的准确性。作者还开发了不确定性感知解码技术，利用图结构筛选可靠声明，从而提升生成文本的真实性，在 AUPRC 上平均实现 6.8% 的相对提升，并使端到端系统在真实性上比现有技术提高 2-4%，同时增强了响应的信息性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a Spotlight paper at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20783v1",
      "published_date": "2024-10-28 06:47:25 UTC",
      "updated_date": "2024-10-28 06:47:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:01:43.343666"
    },
    {
      "arxiv_id": "2411.08891v1",
      "title": "Calibrated Decision-Making through LLM-Assisted Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Chaeyun Jang",
        "Hyungi Lee",
        "Seanie Lee",
        "Juho Lee"
      ],
      "abstract": "Recently, large language models (LLMs) have been increasingly used to support\nvarious decision-making tasks, assisting humans in making informed decisions.\nHowever, when LLMs confidently provide incorrect information, it can lead\nhumans to make suboptimal decisions. To prevent LLMs from generating incorrect\ninformation on topics they are unsure of and to improve the accuracy of\ngenerated content, prior works have proposed Retrieval Augmented Generation\n(RAG), where external documents are referenced to generate responses. However,\ntraditional RAG methods focus only on retrieving documents most relevant to the\ninput query, without specifically aiming to ensure that the human user's\ndecisions are well-calibrated. To address this limitation, we propose a novel\nretrieval method called Calibrated Retrieval-Augmented Generation (CalibRAG),\nwhich ensures that decisions informed by the retrieved documents are\nwell-calibrated. Then we empirically validate that CalibRAG improves\ncalibration performance as well as accuracy, compared to other baselines across\nvarious datasets.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)在决策任务中可能自信地提供错误信息，导致人类决策次优的问题。为解决这一问题，作者提出了一种新型方法Calibrated Retrieval-Augmented Generation (CalibRAG)，它通过改进的检索策略，确保检索文档能更好地校准决策过程，从而提升生成的响应准确性。实验验证显示，CalibRAG相较于传统RAG和其他基线方法，在多个数据集上显著提高了校准性能和整体准确性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08891v1",
      "published_date": "2024-10-28 06:41:05 UTC",
      "updated_date": "2024-10-28 06:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:01:54.404834"
    },
    {
      "arxiv_id": "2410.20777v1",
      "title": "KD-LoRA: A Hybrid Approach to Efficient Fine-Tuning with LoRA and Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Rambod Azimi",
        "Rishav Rishav",
        "Marek Teichmann",
        "Samira Ebrahimi Kahou"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance across\nvarious downstream tasks. However, the high computational and memory\nrequirements of LLMs are a major bottleneck. To address this,\nparameter-efficient fine-tuning (PEFT) methods such as low-rank adaptation\n(LoRA) have been proposed to reduce computational costs while ensuring minimal\nloss in performance. Additionally, knowledge distillation (KD) has been a\npopular choice for obtaining compact student models from teacher models. In\nthis work, we present KD-LoRA, a novel fine-tuning method that combines LoRA\nwith KD. Our results demonstrate that KD-LoRA achieves performance comparable\nto full fine-tuning (FFT) and LoRA while significantly reducing resource\nrequirements. Specifically, KD-LoRA retains 98% of LoRA's performance on the\nGLUE benchmark, while being 40% more compact. Additionally, KD-LoRA reduces GPU\nmemory usage by 30% compared to LoRA, while decreasing inference time by 30%\ncompared to both FFT and LoRA. We evaluate KD-LoRA across three encoder-only\nmodels: BERT, RoBERTa, and DeBERTaV3. Code is available at\nhttps://github.com/rambodazimi/KD-LoRA.",
      "tldr_zh": "本文提出 KD-LoRA，一种结合低秩适配（LoRA）和知识蒸馏（Knowledge Distillation）的新型混合微调方法，旨在解决大型语言模型（LLMs）的高计算和内存需求问题。相比于全量微调（FFT）和 LoRA，KD-LoRA 在 GLUE 基准上保留了 98% 的 LoRA 性能，同时将模型大小缩小 40%，并减少 30% 的 GPU 内存使用和推理时间。该方法在 BERT、RoBERTa 和 DeBERTaV3 等编码器模型上进行了评估，展示了其高效性，并提供了开源代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 4th NeurIPS Efficient Natural Language and Speech\n  Processing Workshop (ENLSP-IV 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.20777v1",
      "published_date": "2024-10-28 06:38:24 UTC",
      "updated_date": "2024-10-28 06:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:02:08.149976"
    },
    {
      "arxiv_id": "2410.20772v3",
      "title": "Introducing Spectral Attention for Long-Range Dependency in Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Bong Gyun Kang",
        "Dongjun Lee",
        "HyunGi Kim",
        "DoHyun Chung",
        "Sungroh Yoon"
      ],
      "abstract": "Sequence modeling faces challenges in capturing long-range dependencies\nacross diverse tasks. Recent linear and transformer-based forecasters have\nshown superior performance in time series forecasting. However, they are\nconstrained by their inherent inability to effectively address long-range\ndependencies in time series data, primarily due to using fixed-size inputs for\nprediction. Furthermore, they typically sacrifice essential temporal\ncorrelation among consecutive training samples by shuffling them into\nmini-batches. To overcome these limitations, we introduce a fast and effective\nSpectral Attention mechanism, which preserves temporal correlations among\nsamples and facilitates the handling of long-range information while\nmaintaining the base model structure. Spectral Attention preserves long-period\ntrends through a low-pass filter and facilitates gradient to flow between\nsamples. Spectral Attention can be seamlessly integrated into most sequence\nmodels, allowing models with fixed-sized look-back windows to capture\nlong-range dependencies over thousands of steps. Through extensive experiments\non 11 real-world time series datasets using 7 recent forecasting models, we\nconsistently demonstrate the efficacy of our Spectral Attention mechanism,\nachieving state-of-the-art results.",
      "tldr_zh": "本论文针对时间序列预测中捕捉长程依赖性的挑战，引入了Spectral Attention机制，以保留样本之间的时间相关性并有效处理长程信息，同时保持基础模型结构。Spectral Attention通过低通滤波器保留长周期趋势，并促进梯度在样本之间流动，从而允许固定大小的回溯窗口模型捕捉数千步的依赖性。该机制可无缝集成到大多数序列模型中，并在11个真实世界数据集上使用7个最新预测模型的广泛实验中，实现了state-of-the-art结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Co-first Author: Bong Gyun Kang, Dongjun Lee. NeurIPS 2024\n  (Conference on Neural Information Processing Systems)",
      "pdf_url": "http://arxiv.org/pdf/2410.20772v3",
      "published_date": "2024-10-28 06:17:20 UTC",
      "updated_date": "2024-11-22 01:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:02:19.004957"
    },
    {
      "arxiv_id": "2410.20771v3",
      "title": "MrT5: Dynamic Token Merging for Efficient Byte-level Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Julie Kallini",
        "Shikhar Murty",
        "Christopher D. Manning",
        "Christopher Potts",
        "Róbert Csordás"
      ],
      "abstract": "Models that rely on subword tokenization have significant drawbacks, such as\nsensitivity to character-level noise like spelling errors and inconsistent\ncompression rates across different languages and scripts. While character- or\nbyte-level models like ByT5 attempt to address these concerns, they have not\ngained widespread adoption -- processing raw byte streams without tokenization\nresults in significantly longer sequence lengths, making training and inference\ninefficient. This work introduces MrT5 (MergeT5), a more efficient variant of\nByT5 that integrates a token deletion mechanism in its encoder to dynamically\nshorten the input sequence length. After processing through a fixed number of\nencoder layers, a learned delete gate determines which tokens are to be removed\nand which are to be retained for subsequent layers. MrT5 effectively \"merges\"\ncritical information from deleted tokens into a more compact sequence,\nleveraging contextual information from the remaining tokens. In continued\npre-training experiments, we find that MrT5 can achieve significant gains in\ninference runtime with minimal effect on performance, as measured by\nbits-per-byte. Additionally, with multilingual training, MrT5 adapts to the\northographic characteristics of each language, learning language-specific\ncompression rates. Furthermore, MrT5 shows comparable accuracy to ByT5 on\ndownstream evaluations such as XNLI, TyDi QA, and character-level tasks while\nreducing sequence lengths by up to 75%. Our approach presents a solution to the\npractical limitations of existing byte-level models.",
      "tldr_zh": "本文提出 MrT5，一种基于 ByT5 的高效字节级语言模型，通过动态 token merging 机制在编码器中引入 learned delete gate，以缩短输入序列长度并合并关键信息。MrT5 在处理一定层数后自动删除非关键 token，利用剩余 token 的上下文信息实现序列压缩，在多语言训练中适应不同语言的正字法特征。实验结果显示，MrT5 在推理运行时显著提升，同时 bits-per-byte 性能影响最小，并在下游任务如 XNLI、TyDi QA 和字符级任务上与 ByT5 准确性相当，但序列长度减少高达 75%。这一方法有效解决了现有字节级模型的效率限制，为实际应用提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20771v3",
      "published_date": "2024-10-28 06:14:12 UTC",
      "updated_date": "2025-04-02 03:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:02:33.761903"
    },
    {
      "arxiv_id": "2410.20766v1",
      "title": "A Static and Dynamic Attention Framework for Multi Turn Dialogue Generation",
      "title_zh": "静态和动态注意力框架用于多轮对话生成",
      "authors": [
        "Wei-Nan Zhang",
        "Yiming Cui",
        "Kaiyan Zhang",
        "Yifa Wang",
        "Qingfu Zhu",
        "Lingzhi Li",
        "Ting Liu"
      ],
      "abstract": "Recently, research on open domain dialogue systems have attracted extensive\ninterests of academic and industrial researchers. The goal of an open domain\ndialogue system is to imitate humans in conversations. Previous works on single\nturn conversation generation have greatly promoted the research of open domain\ndialogue systems. However, understanding multiple single turn conversations is\nnot equal to the understanding of multi turn dialogue due to the coherent and\ncontext dependent properties of human dialogue. Therefore, in open domain multi\nturn dialogue generation, it is essential to modeling the contextual semantics\nof the dialogue history, rather than only according to the last utterance.\nPrevious research had verified the effectiveness of the hierarchical recurrent\nencoder-decoder framework on open domain multi turn dialogue generation.\nHowever, using RNN-based model to hierarchically encoding the utterances to\nobtain the representation of dialogue history still face the problem of a\nvanishing gradient. To address this issue, in this paper, we proposed a static\nand dynamic attention-based approach to model the dialogue history and then\ngenerate open domain multi turn dialogue responses. Experimental results on\nUbuntu and Opensubtitles datasets verify the effectiveness of the proposed\nstatic and dynamic attention-based approach on automatic and human evaluation\nmetrics in various experimental settings. Meanwhile, we also empirically verify\nthe performance of combining the static and dynamic attentions on open domain\nmulti turn dialogue generation.",
      "tldr_zh": "这篇论文针对开放域多轮对话生成的问题，提出了一种结合静态和动态注意力的框架（static and dynamic attention framework），以更好地建模对话历史的上下文语义，避免了传统层次化循环编码器-解码器框架（hierarchical recurrent encoder-decoder framework）的梯度消失问题。相比于仅依赖最后一句的单一轮对话方法，该框架通过静态和动态注意力机制来处理多轮对话的连贯性和依赖性。实验结果在 Ubuntu 和 Opensubtitles 数据集上显示，该方法在自动和人工评估指标上显著提升了性能，并验证了静态和动态注意力结合的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "published as a journal paper at ACM Transactions on Information\n  Systems 2023. 30 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20766v1",
      "published_date": "2024-10-28 06:05:34 UTC",
      "updated_date": "2024-10-28 06:05:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:02:43.354012"
    },
    {
      "arxiv_id": "2411.08890v1",
      "title": "Spotlight Session on Autonomous Weapons Systems at ICRC 34th International Conference",
      "title_zh": "翻译失败",
      "authors": [
        "Susannah Kate Conroy"
      ],
      "abstract": "Autonomous weapons systems (AWS) change the way humans make decisions, the\neffect of those decisions and who is accountable for decisions made. We must\nremain vigilant, informed and human-centred as we tackle our deliberations on\ndeveloping norms regarding their development, use and justification. Ways to\nenhance compliance in international humanitarian law (IHL) include: Training\nweapons decision makers in IHL; developing best practice in weapons reviews\nincluding requirements for industry to ensure that any new weapon, means or\nmethod of warfare is capable of being used lawfully; develop human-centred test\nand evaluation methods; invest in digital infrastructure to increase knowledge\nof the civilian environment in a conflict and its dynamics; invest in research\non the real effects and consequences of civilian harms to the achievement of\nmilitary and political objectives; improve secure communications between\nstakeholders in a conflict; and finally to upskill governments and NGOs in what\nis technically achievable with emerging technologies so that they can\ncontribute to system requirements, test and evaluation protocols and\noperational rules of use and engagement. Governments are responsible for\nsetting requirements for weapons systems. They are responsible for driving\nethicality as well as lethality. Governments can require systems to be made and\nused to better protect civilians and protected objects. The UN can advocate for\ncompliance with IHL, human rights, human-centred use of weapons systems and\nimproved mechanisms to monitor and trace military decision making including\nthose decisions affected by autonomous functionality.",
      "tldr_zh": "该论文聚焦于ICRC第34届国际会议上关于自主武器系统(Autonomous Weapons Systems, AWS)的专题讨论，强调AWS如何改变人类决策、影响决策效果以及责任归属问题，并呼吁以人为本的警觉性和规范制定。关键建议包括培训武器决策者在国际人道法(IHL)方面的知识、开发武器审查最佳实践（如要求行业确保武器能合法使用）、采用人类中心测试方法、投资数字基础设施以提升对冲突环境理解，以及研究平民伤害对军事目标的影响。政府被视为设定武器系统要求的主要责任方，应推动伦理性和合法性，确保系统更好地保护平民；联合国则倡导IHL遵守、人类权利和改进军事决策监控机制。总的来说，该讨论为AWS的开发、使用和问责提供了实用指导框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages, 2415 words, 1 figure. Panelist notes for the Spotlight\n  Session on Autonomous Weapons Systems at the ICRC 34th International\n  Conference 28-31 Oct 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.08890v1",
      "published_date": "2024-10-28 05:36:41 UTC",
      "updated_date": "2024-10-28 05:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:02:54.092754"
    },
    {
      "arxiv_id": "2410.20750v1",
      "title": "ODRL: A Benchmark for Off-Dynamics Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiafei Lyu",
        "Kang Xu",
        "Jiacheng Xu",
        "Mengbei Yan",
        "Jingwen Yang",
        "Zongzhang Zhang",
        "Chenjia Bai",
        "Zongqing Lu",
        "Xiu Li"
      ],
      "abstract": "We consider off-dynamics reinforcement learning (RL) where one needs to\ntransfer policies across different domains with dynamics mismatch. Despite the\nfocus on developing dynamics-aware algorithms, this field is hindered due to\nthe lack of a standard benchmark. To bridge this gap, we introduce ODRL, the\nfirst benchmark tailored for evaluating off-dynamics RL methods. ODRL contains\nfour experimental settings where the source and target domains can be either\nonline or offline, and provides diverse tasks and a broad spectrum of dynamics\nshifts, making it a reliable platform to comprehensively evaluate the agent's\nadaptation ability to the target domain. Furthermore, ODRL includes recent\noff-dynamics RL algorithms in a unified framework and introduces some extra\nbaselines for different settings, all implemented in a single-file manner. To\nunpack the true adaptation capability of existing methods, we conduct extensive\nbenchmarking experiments, which show that no method has universal advantages\nacross varied dynamics shifts. We hope this benchmark can serve as a\ncornerstone for future research endeavors. Our code is publicly available at\nhttps://github.com/OffDynamicsRL/off-dynamics-rl.",
      "tldr_zh": "本研究针对 off-dynamics reinforcement learning（离线动态强化学习）中的动态不匹配问题，引入了 ODRL 基准，这是第一个专门评估跨域策略转移方法的标准化平台。ODRL 包含四种实验设置（源域和目标域可为在线或离线），提供多样任务和广泛的 dynamics shifts，以全面测试代理在目标域的适应能力。该基准整合了最近的 off-dynamics RL 算法和额外基线，并通过广泛实验发现，没有方法在所有动态偏移中均占优势，为未来研究提供可靠基础。代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 D&B Track",
      "pdf_url": "http://arxiv.org/pdf/2410.20750v1",
      "published_date": "2024-10-28 05:29:38 UTC",
      "updated_date": "2024-10-28 05:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:03:06.361313"
    },
    {
      "arxiv_id": "2410.20749v1",
      "title": "Matryoshka: Learning to Drive Black-Box LLMs with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Changhao Li",
        "Yuchen Zhuang",
        "Rushi Qiang",
        "Haotian Sun",
        "Hanjun Dai",
        "Chao Zhang",
        "Bo Dai"
      ],
      "abstract": "Despite the impressive generative abilities of black-box large language\nmodels (LLMs), their inherent opacity hinders further advancements in\ncapabilities such as reasoning, planning, and personalization. Existing works\naim to enhance LLM capabilities via domain-specific adaptation or in-context\nlearning, which require additional training on accessible model parameters, an\ninfeasible option for black-box LLMs. To address this challenge, we introduce\nMatryoshika, a lightweight white-box LLM controller that guides a large-scale\nblack-box LLM generator by decomposing complex tasks into a series of\nintermediate outputs. Specifically, we consider the black-box LLM as an\nenvironment, with Matryoshika serving as a policy to provide intermediate\nguidance through prompts for driving the black-box LLM. Matryoshika is trained\nto pivot the outputs of the black-box LLM aligning with preferences during\niterative interaction, which enables controllable multi-turn generation and\nself-improvement in optimizing intermediate guidance. Empirical evaluations on\nthree diverse tasks demonstrate that Matryoshika effectively enhances the\ncapabilities of black-box LLMs in complex, long-horizon tasks, including\nreasoning, planning, and personalization. By leveraging this pioneering\ncontroller-generator framework to mitigate dependence on model parameters,\nMatryoshika provides a transparent and practical solution for improving\nblack-box LLMs through controllable multi-turn generation using white-box LLMs.",
      "tldr_zh": "这篇论文提出 Matryoshka，一种轻量级白盒 LLM 控制器，用于引导黑盒 LLMs 处理复杂任务，通过将任务分解成一系列中间输出并提供迭代指导提示，实现可控的多轮生成和自我改进。具体来说，Matryoshka 将黑盒 LLMs 视为环境，训练控制器优化输出以提升推理、规划和个性化能力。实验在三个多样化任务上证明，该框架显著增强了黑盒 LLMs 的性能，并提供了一个透明的解决方案，减少了对模型参数的依赖。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2410.20749v1",
      "published_date": "2024-10-28 05:28:51 UTC",
      "updated_date": "2024-10-28 05:28:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:03:19.967733"
    },
    {
      "arxiv_id": "2410.20745v2",
      "title": "Shopping MMLU: A Massive Multi-Task Online Shopping Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yilun Jin",
        "Zheng Li",
        "Chenwei Zhang",
        "Tianyu Cao",
        "Yifan Gao",
        "Pratik Jayarao",
        "Mao Li",
        "Xin Liu",
        "Ritesh Sarkhel",
        "Xianfeng Tang",
        "Haodong Wang",
        "Zhengyang Wang",
        "Wenju Xu",
        "Jingfeng Yang",
        "Qingyu Yin",
        "Xian Li",
        "Priyanka Nigam",
        "Yi Xu",
        "Kai Chen",
        "Qiang Yang",
        "Meng Jiang",
        "Bing Yin"
      ],
      "abstract": "Online shopping is a complex multi-task, few-shot learning problem with a\nwide and evolving range of entities, relations, and tasks. However, existing\nmodels and benchmarks are commonly tailored to specific tasks, falling short of\ncapturing the full complexity of online shopping. Large Language Models (LLMs),\nwith their multi-task and few-shot learning abilities, have the potential to\nprofoundly transform online shopping by alleviating task-specific engineering\nefforts and by providing users with interactive conversations. Despite the\npotential, LLMs face unique challenges in online shopping, such as\ndomain-specific concepts, implicit knowledge, and heterogeneous user behaviors.\nMotivated by the potential and challenges, we propose Shopping MMLU, a diverse\nmulti-task online shopping benchmark derived from real-world Amazon data.\nShopping MMLU consists of 57 tasks covering 4 major shopping skills: concept\nunderstanding, knowledge reasoning, user behavior alignment, and\nmulti-linguality, and can thus comprehensively evaluate the abilities of LLMs\nas general shop assistants. With Shopping MMLU, we benchmark over 20 existing\nLLMs and uncover valuable insights about practices and prospects of building\nversatile LLM-based shop assistants. Shopping MMLU can be publicly accessed at\nhttps://github.com/KL4805/ShoppingMMLU. In addition, with Shopping MMLU, we\nhost a competition in KDD Cup 2024 with over 500 participating teams. The\nwinning solutions and the associated workshop can be accessed at our website\nhttps://amazon-kddcup24.github.io/.",
      "tldr_zh": "本研究提出Shopping MMLU，一种基于真实Amazon数据的庞大多任务基准，用于评估大型语言模型(LLMs)在在线购物领域的性能。该基准包含57个任务，覆盖四个主要购物技能：概念理解、知识推理、用户行为对齐以及多语言性，从而全面测试LLMs作为通用购物助理的能力。通过基准测试超过20个现有LLMs，研究揭示了构建多功能LLM购物助理的最佳实践和前景，并已应用于KDD Cup 2024竞赛中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Datasets and Benchmarks Track Accepted. Modified typos\n  in Figure 9",
      "pdf_url": "http://arxiv.org/pdf/2410.20745v2",
      "published_date": "2024-10-28 05:25:47 UTC",
      "updated_date": "2024-10-31 12:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:03:30.651909"
    },
    {
      "arxiv_id": "2410.20742v1",
      "title": "Mitigating Unauthorized Speech Synthesis for Voice Protection",
      "title_zh": "缓解未经授权的语音合成以保护语音",
      "authors": [
        "Zhisheng Zhang",
        "Qianyi Yang",
        "Derui Wang",
        "Pengyang Huang",
        "Yuxin Cao",
        "Kai Ye",
        "Jie Hao"
      ],
      "abstract": "With just a few speech samples, it is possible to perfectly replicate a\nspeaker's voice in recent years, while malicious voice exploitation (e.g.,\ntelecom fraud for illegal financial gain) has brought huge hazards in our daily\nlives. Therefore, it is crucial to protect publicly accessible speech data that\ncontains sensitive information, such as personal voiceprints. Most previous\ndefense methods have focused on spoofing speaker verification systems in timbre\nsimilarity but the synthesized deepfake speech is still of high quality. In\nresponse to the rising hazards, we devise an effective, transferable, and\nrobust proactive protection technology named Pivotal Objective Perturbation\n(POP) that applies imperceptible error-minimizing noises on original speech\nsamples to prevent them from being effectively learned for text-to-speech (TTS)\nsynthesis models so that high-quality deepfake speeches cannot be generated. We\nconduct extensive experiments on state-of-the-art (SOTA) TTS models utilizing\nobjective and subjective metrics to comprehensively evaluate our proposed\nmethod. The experimental results demonstrate outstanding effectiveness and\ntransferability across various models. Compared to the speech unclarity score\nof 21.94% from voice synthesizers trained on samples without protection,\nPOP-protected samples significantly increase it to 127.31%. Moreover, our\nmethod shows robustness against noise reduction and data augmentation\ntechniques, thereby greatly reducing potential hazards.",
      "tldr_zh": "这篇论文针对未经授权的语音合成问题（如电信欺诈），提出了一种主动保护技术Pivotal Objective Perturbation (POP)，通过在原始语音样本上添加不易察觉的错误最小化噪声，防止Text-to-Speech (TTS)模型有效学习这些样本，从而抑制高质量假冒语音的生成。实验在多种SOTA TTS模型上进行，使用客观和主观指标评估，结果显示POP方法具有优秀的有效性和可转移性，将语音不清晰分数从21.94%显著提高到127.31%。此外，该方法对噪声减少和数据增强技术表现出强鲁棒性，极大降低了潜在安全风险。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ACM CCS Workshop (LAMPS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20742v1",
      "published_date": "2024-10-28 05:16:37 UTC",
      "updated_date": "2024-10-28 05:16:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:03:43.246942"
    },
    {
      "arxiv_id": "2410.20739v3",
      "title": "Gender Bias in LLM-generated Interview Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Haein Kong",
        "Yongsu Ahn",
        "Sangyub Lee",
        "Yunho Maeng"
      ],
      "abstract": "LLMs have emerged as a promising tool for assisting individuals in diverse\ntext-generation tasks, including job-related texts. However, LLM-generated\nanswers have been increasingly found to exhibit gender bias. This study\nevaluates three LLMs (GPT-3.5, GPT-4, Claude) to conduct a multifaceted audit\nof LLM-generated interview responses across models, question types, and jobs,\nand their alignment with two gender stereotypes. Our findings reveal that\ngender bias is consistent, and closely aligned with gender stereotypes and the\ndominance of jobs. Overall, this study contributes to the systematic\nexamination of gender bias in LLM-generated interview responses, highlighting\nthe need for a mindful approach to mitigate such biases in related\napplications.",
      "tldr_zh": "这篇论文评估了LLM（如GPT-3.5、GPT-4和Claude）在生成面试回答时的性别偏见问题，通过多方面审计考察了不同模型、问题类型、工作以及与两种性别刻板印象的关联。研究发现，性别偏见在这些LLM中一致存在，并与性别刻板印象以及职业主导性密切相关。总体而言，该研究为系统检查LLM生成面试响应中的偏见提供了重要贡献，并强调了在相关应用中采取措施减轻这种偏见的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurlIPS 2024, SoLaR workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.20739v3",
      "published_date": "2024-10-28 05:08:08 UTC",
      "updated_date": "2024-11-28 19:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:03:55.203998"
    },
    {
      "arxiv_id": "2410.20735v1",
      "title": "Murine AI excels at cats and cheese: Structural differences between human and mouse neurons and their implementation in generative AIs",
      "title_zh": "翻译失败",
      "authors": [
        "Rino Saiga",
        "Kaede Shiga",
        "Yo Maruta",
        "Chie Inomoto",
        "Hiroshi Kajiwara",
        "Naoya Nakamura",
        "Yu Kakimoto",
        "Yoshiro Yamamoto",
        "Masahiro Yasutake",
        "Masayuki Uesugi",
        "Akihisa Takeuchi",
        "Kentaro Uesugi",
        "Yasuko Terada",
        "Yoshio Suzuki",
        "Viktor Nikitin",
        "Vincent De Andrade",
        "Francesco De Carlo",
        "Yuichi Yamashita",
        "Masanari Itokawa",
        "Soichiro Ide",
        "Kazutaka Ikeda",
        "Ryuta Mizutani"
      ],
      "abstract": "Mouse and human brains have different functions that depend on their neuronal\nnetworks. In this study, we analyzed nanometer-scale three-dimensional\nstructures of brain tissues of the mouse medial prefrontal cortex and compared\nthem with structures of the human anterior cingulate cortex. The obtained\nresults indicated that mouse neuronal somata are smaller and neurites are\nthinner than those of human neurons. These structural features allow mouse\nneurons to be integrated in the limited space of the brain, though thin\nneurites should suppress distal connections according to cable theory. We\nimplemented this mouse-mimetic constraint in convolutional layers of a\ngenerative adversarial network (GAN) and a denoising diffusion implicit model\n(DDIM), which were then subjected to image generation tasks using photo\ndatasets of cat faces, cheese, human faces, and birds. The mouse-mimetic GAN\noutperformed a standard GAN in the image generation task using the cat faces\nand cheese photo datasets, but underperformed for human faces and birds. The\nmouse-mimetic DDIM gave similar results, suggesting that the nature of the\ndatasets affected the results. Analyses of the four datasets indicated\ndifferences in their image entropy, which should influence the number of\nparameters required for image generation. The preferences of the mouse-mimetic\nAIs coincided with the impressions commonly associated with mice. The\nrelationship between the neuronal network and brain function should be\ninvestigated by implementing other biological findings in artificial neural\nnetworks.",
      "tldr_zh": "该研究比较了小鼠和人类大脑神经结构的差异，发现小鼠神经元体细胞较小且神经突较细，这有助于在有限空间内整合神经元，但可能抑制远端连接。研究者将这些小鼠模拟约束应用到 GAN 和 DDIM 的卷积层中，并测试了生成猫脸、奶酪、人脸和鸟类图像的任务。结果显示，小鼠模拟的 GAN 在猫脸和奶酪数据集上表现优于标准 GAN，而在人脸和鸟类上表现较差，DDIM 模型类似，这种差异可能与数据集的图像熵有关。总体而言，该工作揭示了神经结构差异如何影响生成式 AI 的性能，并建议通过在人工神经网络中实现更多生物发现来探索脑功能。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "physics.bio-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "41 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20735v1",
      "published_date": "2024-10-28 04:55:57 UTC",
      "updated_date": "2024-10-28 04:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:04:07.045516"
    },
    {
      "arxiv_id": "2410.21342v1",
      "title": "Heterogeneous Interaction Modeling With Reduced Accumulated Error for Multi-Agent Trajectory Prediction",
      "title_zh": "异构交互建模，减少积累误差，用于多智能体轨迹预测",
      "authors": [
        "Siyuan Chen",
        "Jiahai Wang"
      ],
      "abstract": "Dynamical complex systems composed of interactive heterogeneous agents are\nprevalent in the world, including urban traffic systems and social networks.\nModeling the interactions among agents is the key to understanding and\npredicting the dynamics of the complex system, e.g., predicting the\ntrajectories of traffic participants in the city. Compared with interaction\nmodeling in homogeneous systems such as pedestrians in a crowded scene,\nheterogeneous interaction modeling is less explored. Worse still, the error\naccumulation problem becomes more severe since the interactions are more\ncomplex. To tackle the two problems, this paper proposes heterogeneous\ninteraction modeling with reduced accumulated error for multi-agent trajectory\nprediction. Based on the historical trajectories, our method infers the dynamic\ninteraction graphs among agents, featured by directed interacting relations and\ninteracting effects. A heterogeneous attention mechanism is defined on the\ninteraction graphs for aggregating the influence from heterogeneous neighbors\nto the target agent. To alleviate the error accumulation problem, this paper\nanalyzes the error sources from the spatial and temporal perspectives, and\nproposes to introduce the graph entropy and the mixup training strategy for\nreducing the two types of errors respectively. Our method is examined on three\nreal-world datasets containing heterogeneous agents, and the experimental\nresults validate the superiority of our method.",
      "tldr_zh": "这篇论文提出了一种异构交互建模方法，用于多智能体轨迹预测，旨在解决复杂系统中交互建模不足和错误积累问题。基于历史轨迹，该方法推断动态交互图，包括有向交互关系和交互效果，并引入异构注意力机制（heterogeneous attention mechanism）来聚合异构邻居对目标智能体的影响。为了缓解错误积累，该方法从空间和时间角度分析错误来源，并分别采用图熵（graph entropy）和mixup训练策略（mixup training strategy）进行优化。在三个真实数据集上的实验结果验证了该方法的优越性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "20 pages, accepted by IEEE TNNLS",
      "pdf_url": "http://arxiv.org/pdf/2410.21342v1",
      "published_date": "2024-10-28 04:53:42 UTC",
      "updated_date": "2024-10-28 04:53:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:04:19.425629"
    },
    {
      "arxiv_id": "2410.20733v1",
      "title": "SEG:Seeds-Enhanced Iterative Refinement Graph Neural Network for Entity Alignment",
      "title_zh": "SEG：种子",
      "authors": [
        "Wei Ai",
        "Yinghui Gao",
        "Jianbin Li",
        "Jiayi Du",
        "Tao Meng",
        "Yuntao Shou",
        "Keqin Li"
      ],
      "abstract": "Entity alignment is crucial for merging knowledge across knowledge graphs, as\nit matches entities with identical semantics. The standard method matches these\nentities based on their embedding similarities using semi-supervised learning.\nHowever, diverse data sources lead to non-isomorphic neighborhood structures\nfor aligned entities, complicating alignment, especially for less common and\nsparsely connected entities. This paper presents a soft label propagation\nframework that integrates multi-source data and iterative seed enhancement,\naddressing scalability challenges in handling extensive datasets where scale\ncomputing excels. The framework uses seeds for anchoring and selects optimal\nrelationship pairs to create soft labels rich in neighborhood features and\nsemantic relationship data. A bidirectional weighted joint loss function is\nimplemented, which reduces the distance between positive samples and\ndifferentially processes negative samples, taking into account the\nnon-isomorphic neighborhood structures. Our method outperforms existing\nsemi-supervised approaches, as evidenced by superior results on multiple\ndatasets, significantly improving the quality of entity alignment.",
      "tldr_zh": "本论文提出SEG框架，即Seeds-Enhanced Iterative Refinement Graph Neural Network，用于解决实体对齐(Entity Alignment)中的挑战，该问题因知识图谱的非同构邻居结构而复杂，尤其在稀疏实体上。SEG采用软标签传播框架，整合多源数据和迭代种子增强，通过种子作为锚点选择最佳关系对生成富含邻居特征和语义关系的软标签，并引入双向加权联合损失函数来减少正样本距离并差异化处理负样本。实验结果显示，该方法在多个数据集上优于现有半监督方法，显著提升了实体对齐的质量和可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20733v1",
      "published_date": "2024-10-28 04:50:46 UTC",
      "updated_date": "2024-10-28 04:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:04:31.388549"
    },
    {
      "arxiv_id": "2410.20730v1",
      "title": "GPRec: Bi-level User Modeling for Deep Recommenders",
      "title_zh": "翻译失败",
      "authors": [
        "Yejing Wang",
        "Dong Xu",
        "Xiangyu Zhao",
        "Zhiren Mao",
        "Peng Xiang",
        "Ling Yan",
        "Yao Hu",
        "Zijian Zhang",
        "Xuetao Wei",
        "Qidong Liu"
      ],
      "abstract": "GPRec explicitly categorizes users into groups in a learnable manner and\naligns them with corresponding group embeddings. We design the dual group\nembedding space to offer a diverse perspective on group preferences by\ncontrasting positive and negative patterns. On the individual level, GPRec\nidentifies personal preferences from ID-like features and refines the obtained\nindividual representations to be independent of group ones, thereby providing a\nrobust complement to the group-level modeling. We also present various\nstrategies for the flexible integration of GPRec into various DRS models.\nRigorous testing of GPRec on three public datasets has demonstrated significant\nimprovements in recommendation quality.",
      "tldr_zh": "本论文提出 GPRec，一种双层用户建模方法，用于提升深度推荐系统 (deep recommenders) 的性能。它通过可学习的方式将用户显式分组，并利用双组嵌入空间对比正负模式来捕捉多样化的组偏好；在个体层面，从 ID-like 特征中提取独立个人偏好，并将其与组表示分离，提供稳健的补充。论文提供了多种策略，将 GPRec 灵活整合到各种 DRS 模型中，并在三个公共数据集上进行严格测试，实现了推荐质量的显著改进。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20730v1",
      "published_date": "2024-10-28 04:49:05 UTC",
      "updated_date": "2024-10-28 04:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:04:42.946935"
    },
    {
      "arxiv_id": "2410.21341v1",
      "title": "Retrieval-Retro: Retrieval-based Inorganic Retrosynthesis with Expert Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Heewoong Noh",
        "Namkyeong Lee",
        "Gyoung S. Na",
        "Chanyoung Park"
      ],
      "abstract": "While inorganic retrosynthesis planning is essential in the field of chemical\nscience, the application of machine learning in this area has been notably less\nexplored compared to organic retrosynthesis planning. In this paper, we propose\nRetrieval-Retro for inorganic retrosynthesis planning, which implicitly\nextracts the precursor information of reference materials that are retrieved\nfrom the knowledge base regarding domain expertise in the field. Specifically,\ninstead of directly employing the precursor information of reference materials,\nwe propose implicitly extracting it with various attention layers, which\nenables the model to learn novel synthesis recipes more effectively. Moreover,\nduring retrieval, we consider the thermodynamic relationship between target\nmaterial and precursors, which is essential domain expertise in identifying the\nmost probable precursor set among various options. Extensive experiments\ndemonstrate the superiority of Retrieval-Retro in retrosynthesis planning,\nespecially in discovering novel synthesis recipes, which is crucial for\nmaterials discovery. The source code for Retrieval-Retro is available at\nhttps://github.com/HeewoongNoh/Retrieval-Retro.",
      "tldr_zh": "本研究提出Retrieval-Retro，一种基于检索的框架，用于无机逆合成规划（inorganic retrosynthesis planning），以填补该领域机器学习应用的空白。该方法从知识库中检索参考材料，并通过各种attention layers隐式提取前体信息（precursor information），而不是直接使用，从而更有效地学习新合成配方；同时，在检索过程中考虑目标材料与前体间的thermodynamic relationship作为领域专业知识。实验结果显示，Retrieval-Retro在逆合成规划中表现出色，尤其在发现新合成配方方面表现出优越性，这对材料发现至关重要。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21341v1",
      "published_date": "2024-10-28 04:37:08 UTC",
      "updated_date": "2024-10-28 04:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:04:55.628311"
    },
    {
      "arxiv_id": "2410.21340v1",
      "title": "Meta-Learning for Speeding Up Large Model Inference in Decentralized Environments",
      "title_zh": "用于在去中心化环境中加速大模型推理的元学习",
      "authors": [
        "Yuzhe Yang",
        "Yipeng Du",
        "Ahmad Farhan",
        "Claudio Angione",
        "Yue Zhao",
        "Harry Yang",
        "Fielding Johnston",
        "James Buban",
        "Patrick Colangelo"
      ],
      "abstract": "The deployment of large-scale models, such as large language models (LLMs)\nand sophisticated image generation systems, incurs substantial costs due to\ntheir computational demands. To mitigate these costs and address challenges\nrelated to scalability and data security, there is a growing shift towards\ndecentralized systems for deploying such models. In these decentralized\nenvironments, efficient inference acceleration becomes crucial to manage\ncomputational resources effectively and enhance system responsiveness. In this\nwork, we address the challenge of selecting optimal acceleration methods in\ndecentralized systems by introducing a meta-learning-based framework. This\nframework automates the selection process by learning from historical\nperformance data of various acceleration techniques across different tasks.\nUnlike traditional methods that rely on random selection or expert intuition,\nour approach systematically identifies the best acceleration strategies based\non the specific characteristics of each task. We demonstrate that our\nmeta-learning framework not only streamlines the decision-making process but\nalso consistently outperforms conventional methods in terms of efficiency and\nperformance. Our results highlight the potential of meta-learning to\nrevolutionize inference acceleration in decentralized AI systems, offering a\npath towards more democratic and economically feasible artificial intelligence\nsolutions.",
      "tldr_zh": "该论文针对大型模型（如LLMs）在去中心化环境中的推理过程所带来的高计算成本和可伸缩性挑战，提出了一种基于meta-learning的框架来加速模型推理。框架通过从历史性能数据中学习，自动选择最优的加速策略，适应不同任务的特性，从而避免依赖随机选择或专家直觉。实验结果表明，该方法在效率和性能上显著优于传统方法，为去中心化AI系统提供了更民主和经济可行的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21340v1",
      "published_date": "2024-10-28 04:29:16 UTC",
      "updated_date": "2024-10-28 04:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:05:07.274230"
    },
    {
      "arxiv_id": "2410.20711v2",
      "title": "Contextual Representation Anchor Network to Alleviate Selection Bias in Few-Shot Drug Discovery",
      "title_zh": "用于缓解少样本药物发现中选择偏差的上下文表示锚网络",
      "authors": [
        "Ruifeng Li",
        "Wei Liu",
        "Xiangxin Zhou",
        "Mingqian Li",
        "Qiang Zhang",
        "Hongyang Chen",
        "Xuemin Lin"
      ],
      "abstract": "In the drug discovery process, the low success rate of drug candidate\nscreening often leads to insufficient labeled data, causing the few-shot\nlearning problem in molecular property prediction. Existing methods for\nfew-shot molecular property prediction overlook the sample selection bias,\nwhich arises from non-random sample selection in chemical experiments. This\nbias in data representativeness leads to suboptimal performance. To overcome\nthis challenge, we present a novel method named contextual representation\nanchor Network (CRA), where an anchor refers to a cluster center of the\nrepresentations of molecules and serves as a bridge to transfer enriched\ncontextual knowledge into molecular representations and enhance their\nexpressiveness. CRA introduces a dual-augmentation mechanism that includes\ncontext augmentation, which dynamically retrieves analogous unlabeled molecules\nand captures their task-specific contextual knowledge to enhance the anchors,\nand anchor augmentation, which leverages the anchors to augment the molecular\nrepresentations. We evaluate our approach on the MoleculeNet and FS-Mol\nbenchmarks, as well as in domain transfer experiments. The results demonstrate\nthat CRA outperforms the state-of-the-art by 2.60% and 3.28% in AUC and\n$\\Delta$AUC-PR metrics, respectively, and exhibits superior generalization\ncapabilities.",
      "tldr_zh": "该研究针对药物发现中的少样本学习（few-shot learning）问题，特别解决了分子属性预测中样本选择偏差（selection bias）导致的性能下降。作者提出了一种新方法 Contextual Representation Anchor Network (CRA)，通过引入 anchor（分子表示的聚类中心）作为桥梁，并采用双重增强机制——context augmentation（动态检索类似无标签分子以捕获任务特定知识增强 anchor）和 anchor augmentation（利用 anchor 增强分子表示）——来提升分子表示的表达能力。在 MoleculeNet 和 FS-Mol 基准测试以及领域转移实验中，CRA 分别在 AUC 和 ΔAUC-PR 指标上比最先进方法提高了 2.60% 和 3.28%，并展示了出色的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "68U07",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.20711v2",
      "published_date": "2024-10-28 03:54:10 UTC",
      "updated_date": "2024-10-29 06:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:05:19.507573"
    },
    {
      "arxiv_id": "2410.20710v1",
      "title": "Relation-based Counterfactual Data Augmentation and Contrastive Learning for Robustifying Natural Language Inference Models",
      "title_zh": "翻译失败",
      "authors": [
        "Heerin Yang",
        "Sseung-won Hwang",
        "Jungmin So"
      ],
      "abstract": "Although pre-trained language models show good performance on various natural\nlanguage processing tasks, they often rely on non-causal features and patterns\nto determine the outcome. For natural language inference tasks, previous\nresults have shown that even a model trained on a large number of data fails to\nperform well on counterfactually revised data, indicating that the model is not\nrobustly learning the semantics of the classes. In this paper, we propose a\nmethod in which we use token-based and sentence-based augmentation methods to\ngenerate counterfactual sentence pairs that belong to each class, and apply\ncontrastive learning to help the model learn the difference between sentence\npairs of different classes with similar contexts. Evaluation results with\ncounterfactually-revised dataset and general NLI datasets show that the\nproposed method can improve the performance and robustness of the NLI model.",
      "tldr_zh": "本研究针对预-trained language models 在自然语言推理 (NLI) 任务中依赖非因果特征的问题，提出了一种基于关系的逆事实数据增强 (counterfactual data augmentation) 方法，包括 token-based 和 sentence-based 增强，以生成每个类别的逆事实句对。接着，通过 contrastive learning 训练模型，帮助其学习相似上下文下不同类别句对之间的差异，从而提升模型的稳健性。实验结果显示，该方法在逆事实修订数据集和一般 NLI 数据集上显著提高了模型的性能和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted at INTERSPEECH 2023",
      "pdf_url": "http://arxiv.org/pdf/2410.20710v1",
      "published_date": "2024-10-28 03:43:25 UTC",
      "updated_date": "2024-10-28 03:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:05:30.905845"
    },
    {
      "arxiv_id": "2411.08889v1",
      "title": "Multilingual Standalone Trustworthy Voice-Based Social Network for Disaster Situations",
      "title_zh": "翻译失败",
      "authors": [
        "Majid Behravan",
        "Elham Mohammadrezaei",
        "Mohamed Azab",
        "Denis Gracanin"
      ],
      "abstract": "In disaster scenarios, effective communication is crucial, yet language\nbarriers often hinder timely and accurate information dissemination,\nexacerbating vulnerabilities and complicating response efforts. This paper\npresents a novel, multilingual, voice-based social network specifically\ndesigned to address these challenges. The proposed system integrates advanced\nartificial intelligence (AI) with blockchain technology to enable secure,\nasynchronous voice communication across multiple languages. The application\noperates independently of external servers, ensuring reliability even in\ncompromised environments by functioning offline through local networks. Key\nfeatures include AI-driven real-time translation of voice messages, ensuring\nseamless cross-linguistic communication, and blockchain-enabled storage for\nsecure, immutable records of all interactions, safeguarding message integrity.\nDesigned for cross-platform use, the system offers consistent performance\nacross devices, from mobile phones to desktops, making it highly adaptable in\ndiverse disaster situations. Evaluation metrics demonstrate high accuracy in\nspeech recognition and translation, low latency, and user satisfaction,\nvalidating the system's effectiveness in enhancing communication during crises.\nThis solution represents a significant advancement in disaster communication,\nbridging language gaps to support more inclusive and efficient emergency\nresponse.",
      "tldr_zh": "本文提出了一种多语言、独立运行的基于语音的社交网络，旨在解决灾害场景中的语言障碍问题。该系统整合了 AI 驱动的实时翻译和区块链技术，实现安全异步语音通信，并支持离线操作以确保在受损环境中可靠运行。实验评估显示，该系统在语音识别和翻译方面表现出高准确率、低延迟以及用户满意度，为灾害响应提供了更包容和高效的通信解决方案。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS",
        "I.2.7; K.4.4"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in IEEE UEMCON 2024, to appear in December\n  2024. 7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.08889v1",
      "published_date": "2024-10-28 03:24:37 UTC",
      "updated_date": "2024-10-28 03:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:05:42.585830"
    },
    {
      "arxiv_id": "2411.05801v1",
      "title": "Do LLM Personas Dream of Bull Markets? Comparing Human and AI Investment Strategies Through the Lens of the Five-Factor Model",
      "title_zh": "翻译失败",
      "authors": [
        "Harris Borman",
        "Anna Leontjeva",
        "Luiz Pizzato",
        "Max Kun Jiang",
        "Dan Jermyn"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated the ability to adopt a\npersonality and behave in a human-like manner. There is a large body of\nresearch that investigates the behavioural impacts of personality in less\nobvious areas such as investment attitudes or creative decision making. In this\nstudy, we investigated whether an LLM persona with a specific Big Five\npersonality profile would perform an investment task similarly to a human with\nthe same personality traits. We used a simulated investment task to determine\nif these results could be generalised into actual behaviours. In this simulated\nenvironment, our results show these personas produced meaningful behavioural\ndifferences in all assessed categories, with these behaviours generally being\nconsistent with expectations derived from human research. We found that LLMs\nare able to generalise traits into expected behaviours in three areas: learning\nstyle, impulsivity and risk appetite while environmental attitudes could not be\naccurately represented. In addition, we showed that LLMs produce behaviour that\nis more reflective of human behaviour in a simulation environment compared to a\nsurvey environment.",
      "tldr_zh": "本研究比较了大型语言模型 (LLMs) 的投资策略与人类的策略，通过 Five-Factor Model（Big Five 个性模型）来评估 LLMs 是否能根据特定个性特征（如学习风格、冲动性和风险偏好）表现出类似人类的行为。研究采用模拟投资任务，让 LLMs 扮演特定个性角色进行测试，结果显示 LLMs 在学习风格、冲动性和风险偏好方面产生了与人类预期一致的行为，但在环境态度上表现不准确。相比调查环境，LLMs 在模拟环境中更能反映真实人类行为，这为理解 AI 个性建模在实际应用中的有效性提供了重要洞见。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CY",
        "q-fin.GN"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05801v1",
      "published_date": "2024-10-28 02:50:41 UTC",
      "updated_date": "2024-10-28 02:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:07:47.962184"
    },
    {
      "arxiv_id": "2411.08888v1",
      "title": "Exploring Capabilities of Time Series Foundation Models in Building Analytics",
      "title_zh": "探索时间序列基础模型在建筑分析中的能力",
      "authors": [
        "Xiachong Lin",
        "Arian Prabowo",
        "Imran Razzak",
        "Hao Xue",
        "Matthew Amos",
        "Sam Behrens",
        "Flora D. Salim"
      ],
      "abstract": "The growing integration of digitized infrastructure with Internet of Things\n(IoT) networks has transformed the management and optimization of building\nenergy consumption. By leveraging IoT-based monitoring systems, stakeholders\nsuch as building managers, energy suppliers, and policymakers can make\ndata-driven decisions to improve energy efficiency. However, accurate energy\nforecasting and analytics face persistent challenges, primarily due to the\ninherent physical constraints of buildings and the diverse, heterogeneous\nnature of IoT-generated data. In this study, we conduct a comprehensive\nbenchmarking of two publicly available IoT datasets, evaluating the performance\nof time series foundation models in the context of building energy analytics.\nOur analysis shows that single-modal models demonstrate significant promise in\novercoming the complexities of data variability and physical limitations in\nbuildings, with future work focusing on optimizing multi-modal models for\nsustainable energy management.",
      "tldr_zh": "该论文探讨了时间序列基础模型（Time Series Foundation Models）在建筑能源分析中的潜力，针对IoT（Internet of Things）数据带来的建筑物理约束和数据异质性挑战。研究者对两个公开IoT数据集进行了全面基准测试，评估这些模型的性能表现。结果表明，单模态模型（Single-modal models）在应对数据变异性和物理限制方面表现出显著优势，有望提升能源效率。未来工作将聚焦于优化多模态模型（Multi-modal models），以支持可持续能源管理。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 1 figures, and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.08888v1",
      "published_date": "2024-10-28 02:49:22 UTC",
      "updated_date": "2024-10-28 02:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:06:06.795882"
    },
    {
      "arxiv_id": "2411.08887v1",
      "title": "Deep Learning-Based CKM Construction with Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyu Wang",
        "Xiaoli Xu",
        "Yong Zeng"
      ],
      "abstract": "Channel knowledge map (CKM) is a novel technique for achieving environment\nawareness, and thereby improving the communication and sensing performance for\nwireless systems. A fundamental problem associated with CKM is how to construct\na complete CKM that provides channel knowledge for a large number of locations\nbased solely on sparse data measurements. This problem bears similarities to\nthe super-resolution (SR) problem in image processing. In this letter, we\npropose an effective deep learning-based CKM construction method that leverages\nthe image SR network known as SRResNet. Unlike most existing studies, our\napproach does not require any additional input beyond the sparsely measured\ndata. In addition to the conventional path loss map construction, our approach\ncan also be applied to construct channel angle maps (CAMs), thanks to the use\nof a new dataset called CKMImageNet. The numerical results demonstrate that our\nmethod outperforms interpolation-based methods such as nearest neighbour and\nbicubic interpolation, as well as the SRGAN method in CKM construction.\nFurthermore, only 1/16 of the locations need to be measured in order to achieve\na root mean square error (RMSE) of 1.1 dB in path loss.",
      "tldr_zh": "本研究提出了一种基于深度学习的CKM（Channel Knowledge Map）构建方法，利用图像超分辨率（SR）网络SRResNet，从稀疏数据测量中生成完整的CKM，以提升无线系统的环境感知和通信性能。该方法无需额外输入，不仅适用于路径损失图的构建，还能扩展到通道角度图（CAMs）的构建，并引入新数据集CKMImageNet进行训练。与插值方法（如nearest neighbour和bicubic interpolation）以及SRGAN相比，该方法在CKM构建中表现出色，仅需测量1/16的位置即可实现1.1 dB的RMSE（Root Mean Square Error）。这项创新为高效的无线系统优化提供了可靠的技术基础。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.08887v1",
      "published_date": "2024-10-28 02:33:35 UTC",
      "updated_date": "2024-10-28 02:33:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:08:12.361794"
    },
    {
      "arxiv_id": "2411.07050v1",
      "title": "FedCVD: The First Real-World Federated Learning Benchmark on Cardiovascular Disease Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yukun Zhang",
        "Guanzhong Chen",
        "Zenglin Xu",
        "Jianyong Wang",
        "Dun Zeng",
        "Junfan Li",
        "Jinghua Wang",
        "Yuan Qi",
        "Irwin King"
      ],
      "abstract": "Cardiovascular diseases (CVDs) are currently the leading cause of death\nworldwide, highlighting the critical need for early diagnosis and treatment.\nMachine learning (ML) methods can help diagnose CVDs early, but their\nperformance relies on access to substantial data with high quality. However,\nthe sensitive nature of healthcare data often restricts individual clinical\ninstitutions from sharing data to train sufficiently generalized and unbiased\nML models. Federated Learning (FL) is an emerging approach, which offers a\npromising solution by enabling collaborative model training across multiple\nparticipants without compromising the privacy of the individual data owners.\nHowever, to the best of our knowledge, there has been limited prior research\napplying FL to the cardiovascular disease domain. Moreover, existing FL\nbenchmarks and datasets are typically simulated and may fall short of\nreplicating the complexity of natural heterogeneity found in realistic datasets\nthat challenges current FL algorithms. To address these gaps, this paper\npresents the first real-world FL benchmark for cardiovascular disease\ndetection, named FedCVD. This benchmark comprises two major tasks:\nelectrocardiogram (ECG) classification and echocardiogram (ECHO) segmentation,\nbased on naturally scattered datasets constructed from the CVD data of seven\ninstitutions. Our extensive experiments on these datasets reveal that FL faces\nnew challenges with real-world non-IID and long-tail data. The code and\ndatasets of FedCVD are available https://github.com/SMILELab-FL/FedCVD.",
      "tldr_zh": "这篇论文引入了 FedCVD，这是第一个基于真实世界数据的 Federated Learning (FL) 基准，用于心血管疾病 (CVDs) 检测，以解决医疗数据隐私限制和模型泛化问题。FedCVD 包括 ECG 分类和 ECHO 分段两个任务，基于七个机构的自然分布数据进行实验，揭示了 FL 在真实 non-IID 和 long-tail 数据中面临的新挑战。该基准的开源代码和数据集可从 GitHub 获取，促进了 FL 在 CVD 领域的进一步研究。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.07050v1",
      "published_date": "2024-10-28 02:24:01 UTC",
      "updated_date": "2024-10-28 02:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:08:31.688778"
    },
    {
      "arxiv_id": "2410.20666v2",
      "title": "Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments",
      "title_zh": "翻译失败",
      "authors": [
        "Sangmim Song",
        "Sarath Kodagoda",
        "Amal Gunatilake",
        "Marc G. Carmichael",
        "Karthick Thiyagarajan",
        "Jodi Martin"
      ],
      "abstract": "Navigation presents a significant challenge for persons with visual\nimpairments (PVI). While traditional aids such as white canes and guide dogs\nare invaluable, they fall short in delivering detailed spatial information and\nprecise guidance to desired locations. Recent developments in large language\nmodels (LLMs) and vision-language models (VLMs) offer new avenues for enhancing\nassistive navigation. In this paper, we introduce Guide-LLM, an embodied\nLLM-based agent designed to assist PVI in navigating large indoor environments.\nOur approach features a novel text-based topological map that enables the LLM\nto plan global paths using a simplified environmental representation, focusing\non straight paths and right-angle turns to facilitate navigation. Additionally,\nwe utilize the LLM's commonsense reasoning for hazard detection and\npersonalized path planning based on user preferences. Simulated experiments\ndemonstrate the system's efficacy in guiding PVI, underscoring its potential as\na significant advancement in assistive technology. The results highlight\nGuide-LLM's ability to offer efficient, adaptive, and personalized navigation\nassistance, pointing to promising advancements in this field.",
      "tldr_zh": "本研究针对视觉障碍者（PVI）的导航难题，提出了Guide-LLM，这是一个基于LLM的实体代理系统，结合文本-based拓扑地图来简化室内环境路径规划。系统利用LLM的常识推理进行危险检测和用户偏好个性化路径规划，从而提供精确且高效的导航指导。模拟实验验证了Guide-LLM的有效性，展示了其在提升PVI导航辅助方面的显著潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20666v2",
      "published_date": "2024-10-28 01:58:21 UTC",
      "updated_date": "2025-03-11 23:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:06:42.790716"
    },
    {
      "arxiv_id": "2410.20664v2",
      "title": "Embedding with Large Language Models for Classification of HIPAA Safeguard Compliance Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abdur Rahman",
        "Md Abdul Barek",
        "ABM Kamrul Islam Riad",
        "Md Mostafizur Rahman",
        "Md Bajlur Rashid",
        "Smita Ambedkar",
        "Md Raihan Miaa",
        "Fan Wu",
        "Alfredo Cuzzocrea",
        "Sheikh Iqbal Ahamed"
      ],
      "abstract": "Although software developers of mHealth apps are responsible for protecting\npatient data and adhering to strict privacy and security requirements, many of\nthem lack awareness of HIPAA regulations and struggle to distinguish between\nHIPAA rules categories. Therefore, providing guidance of HIPAA rules patterns\nclassification is essential for developing secured applications for Google Play\nStore. In this work, we identified the limitations of traditional Word2Vec\nembeddings in processing code patterns. To address this, we adopt multilingual\nBERT (Bidirectional Encoder Representations from Transformers) which offers\ncontextualized embeddings to the attributes of dataset to overcome the issues.\nTherefore, we applied this BERT to our dataset for embedding code patterns and\nthen uses these embedded code to various machine learning approaches. Our\nresults demonstrate that the models significantly enhances classification\nperformance, with Logistic Regression achieving a remarkable accuracy of\n99.95\\%. Additionally, we obtained high accuracy from Support Vector Machine\n(99.79\\%), Random Forest (99.73\\%), and Naive Bayes (95.93\\%), outperforming\nexisting approaches. This work underscores the effectiveness and showcases its\npotential for secure application development.",
      "tldr_zh": "这篇论文针对 mHealth 应用开发者在 HIPAA 法规分类上的挑战，提出使用大型语言模型进行嵌入，以提高规则识别和遵守的准确性。研究者识别了传统 Word2Vec 嵌入的局限性，转而采用多语言 BERT 提供上下文化的嵌入，并将其应用于机器学习模型如 Logistic Regression、Support Vector Machine 和 Random Forest。结果显示，Logistic Regression 达到了 99.95% 的准确率，其他模型也取得了超过 95% 的高性能，显著优于现有方法。该方法突显了大型语言模型在提升 HIPAA 合规性应用开发方面的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "I am requesting the withdrawal of my paper due to critical issues\n  identified in the methodology/results that may impact its accuracy and\n  reliability. I also plan to make substantial revisions that go beyond minor\n  corrections",
      "pdf_url": "http://arxiv.org/pdf/2410.20664v2",
      "published_date": "2024-10-28 01:54:24 UTC",
      "updated_date": "2024-11-07 21:18:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:06:54.661555"
    },
    {
      "arxiv_id": "2410.20660v2",
      "title": "TurboHopp: Accelerated Molecule Scaffold Hopping with Consistency Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kiwoong Yoo",
        "Owen Oertell",
        "Junhyun Lee",
        "Sanghoon Lee",
        "Jaewoo Kang"
      ],
      "abstract": "Navigating the vast chemical space of druggable compounds is a formidable\nchallenge in drug discovery, where generative models are increasingly employed\nto identify viable candidates. Conditional 3D structure-based drug design\n(3D-SBDD) models, which take into account complex three-dimensional\ninteractions and molecular geometries, are particularly promising. Scaffold\nhopping is an efficient strategy that facilitates the identification of similar\nactive compounds by strategically modifying the core structure of molecules,\neffectively narrowing the wide chemical space and enhancing the discovery of\ndrug-like products. However, the practical application of 3D-SBDD generative\nmodels is hampered by their slow processing speeds. To address this bottleneck,\nwe introduce TurboHopp, an accelerated pocket-conditioned 3D scaffold hopping\nmodel that merges the strategic effectiveness of traditional scaffold hopping\nwith rapid generation capabilities of consistency models. This synergy not only\nenhances efficiency but also significantly boosts generation speeds, achieving\nup to 30 times faster inference speed as well as superior generation quality\ncompared to existing diffusion-based models, establishing TurboHopp as a\npowerful tool in drug discovery. Supported by faster inference speed, we\nfurther optimize our model, using Reinforcement Learning for Consistency Models\n(RLCM), to output desirable molecules. We demonstrate the broad applicability\nof TurboHopp across multiple drug discovery scenarios, underscoring its\npotential in diverse molecular settings.",
      "tldr_zh": "该研究提出TurboHopp，一种加速的pocket-conditioned 3D scaffold hopping模型，旨在解决药物发现中3D-SBDD（3D结构-based药物设计）模型处理速度慢的问题，通过整合consistency models的快速生成能力和传统scaffold hopping策略。模型采用Reinforcement Learning for Consistency Models (RLCM)优化输出，确保生成分子的高质量和适用性。实验结果显示，TurboHopp比现有diffusion-based模型快30倍，同时提升生成质量，在多个药物发现场景中展现出广泛潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 11 figures, 8 tables. Presented at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20660v2",
      "published_date": "2024-10-28 01:36:42 UTC",
      "updated_date": "2025-02-01 21:43:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:08:43.227974"
    },
    {
      "arxiv_id": "2410.20659v1",
      "title": "A Statistical Analysis of Deep Federated Learning for Intrinsically Low-dimensional Data",
      "title_zh": "本质上低维数据的深度联邦学习的统计分析",
      "authors": [
        "Saptarshi Chakraborty",
        "Peter L. Bartlett"
      ],
      "abstract": "Federated Learning (FL) has emerged as a groundbreaking paradigm in\ncollaborative machine learning, emphasizing decentralized model training to\naddress data privacy concerns. While significant progress has been made in\noptimizing federated learning, the exploration of generalization error,\nparticularly in heterogeneous settings, has been limited, focusing mainly on\nparametric cases. This paper investigates the generalization properties of deep\nfederated regression within a two-stage sampling model. Our findings highlight\nthat the intrinsic dimension, defined by the entropic dimension, is crucial for\ndetermining convergence rates when appropriate network sizes are used.\nSpecifically, if the true relationship between response and explanatory\nvariables is charecterized by a $\\beta$-H\\\"older function and there are $n$\nindependent and identically distributed (i.i.d.) samples from $m$ participating\nclients, the error rate for participating clients scales at most as\n$\\tilde{O}\\left((mn)^{-2\\beta/(2\\beta + \\bar{d}_{2\\beta}(\\lambda))}\\right)$,\nand for non-participating clients, it scales as $\\tilde{O}\\left(\\Delta \\cdot\nm^{-2\\beta/(2\\beta + \\bar{d}_{2\\beta}(\\lambda))} + (mn)^{-2\\beta/(2\\beta +\n\\bar{d}_{2\\beta}(\\lambda))}\\right)$. Here, $\\bar{d}_{2\\beta}(\\lambda)$\nrepresents the $2\\beta$-entropic dimension of $\\lambda$, the marginal\ndistribution of the explanatory variables, and $\\Delta$ characterizes the\ndependence between the sampling stages. Our results explicitly account for the\n\"closeness\" of clients, demonstrating that the convergence rates of deep\nfederated learners depend on intrinsic rather than nominal high-dimensionality.",
      "tldr_zh": "本研究对深层联邦学习（Federated Learning）在内在低维数据的应用进行了统计分析，重点探讨其泛化错误属性，特别是异构设置下的表现。作者采用两阶段采样模型，分析了当响应变量与解释变量关系为 β-Hölder 函数时，参与和非参与客户端的错误率；具体结果显示，错误率分别以 Ũ((mn)^(-2β/(2β + d̄_{2β}(λ)))）和 Ũ(Δ · m^(-2β/(2β + d̄_{2β}(λ))) + (mn)^(-2β/(2β + d̄_{2β}(λ))))）形式缩放，其中 d̄_{2β}(λ) 为 entropic dimension。总体发现强调，深层联邦学习的收敛率主要依赖于内在维度而非名义高维度，这为优化联邦学习框架提供了重要指导。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20659v1",
      "published_date": "2024-10-28 01:36:25 UTC",
      "updated_date": "2024-10-28 01:36:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:08:55.729193"
    },
    {
      "arxiv_id": "2410.20651v2",
      "title": "SubjECTive-QA: Measuring Subjectivity in Earnings Call Transcripts' QA Through Six-Dimensional Feature Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Huzaifa Pardawala",
        "Siddhant Sukhani",
        "Agam Shah",
        "Veer Kejriwal",
        "Abhishek Pillai",
        "Rohan Bhasin",
        "Andrew DiBiasio",
        "Tarun Mandapati",
        "Dhruv Adha",
        "Sudheer Chava"
      ],
      "abstract": "Fact-checking is extensively studied in the context of misinformation and\ndisinformation, addressing objective inaccuracies. However, a softer form of\nmisinformation involves responses that are factually correct but lack certain\nfeatures such as clarity and relevance. This challenge is prevalent in formal\nQuestion-Answer (QA) settings such as press conferences in finance, politics,\nsports, and other domains, where subjective answers can obscure transparency.\nDespite this, there is a lack of manually annotated datasets for subjective\nfeatures across multiple dimensions. To address this gap, we introduce\nSubjECTive-QA, a human annotated dataset on Earnings Call Transcripts' (ECTs)\nQA sessions as the answers given by company representatives are often open to\nsubjective interpretations and scrutiny. The dataset includes 49,446\nannotations for long-form QA pairs across six features: Assertive, Cautious,\nOptimistic, Specific, Clear, and Relevant. These features are carefully\nselected to encompass the key attributes that reflect the tone of the answers\nprovided during QA sessions across different domain. Our findings are that the\nbest-performing Pre-trained Language Model (PLM), RoBERTa-base, has similar\nweighted F1 scores to Llama-3-70b-Chat on features with lower subjectivity,\nsuch as Relevant and Clear, with a mean difference of 2.17% in their weighted\nF1 scores. The models perform significantly better on features with higher\nsubjectivity, such as Specific and Assertive, with a mean difference of 10.01%\nin their weighted F1 scores. Furthermore, testing SubjECTive-QA's\ngeneralizability using QAs from White House Press Briefings and Gaggles yields\nan average weighted F1 score of 65.97% using our best models for each feature,\ndemonstrating broader applicability beyond the financial domain. SubjECTive-QA\nis publicly available under the CC BY 4.0 license",
      "tldr_zh": "本文提出 SubjECTive-QA 数据集，用于测量收益电话会议（ECTs）QA 会话中的主观性，通过人工标注六个维度（Assertive, Cautious, Optimistic, Specific, Clear, and Relevant）来分析回答的语气，共包含 49,446 个注解。研究比较了 RoBERTa-base 和 Llama-3-70b-Chat 等预训练语言模型的性能，发现模型在主观性较低的特征（如 Relevant 和 Clear）上表现相似，F1 分数差异仅 2.17%，而在主观性较高的特征（如 Specific 和 Assertive）上差异达 10.01%。此外，该数据集在白宫新闻简报等其他领域展示出良好的泛化性，平均加权 F1 分数为 65.97%，并已公开可用以促进相关研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.20651v2",
      "published_date": "2024-10-28 01:17:34 UTC",
      "updated_date": "2025-01-23 18:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:09:09.616994"
    },
    {
      "arxiv_id": "2410.20650v1",
      "title": "NeuZip: Memory-Efficient Training and Inference with Dynamic Compression of Neural Networks",
      "title_zh": "NeuZip：利用神经网络动态压缩实现内存高效训练和推理",
      "authors": [
        "Yongchang Hao",
        "Yanshuai Cao",
        "Lili Mou"
      ],
      "abstract": "The performance of neural networks improves when more parameters are used.\nHowever, the model sizes are constrained by the available on-device memory\nduring training and inference. Although applying techniques like quantization\ncan alleviate the constraint, they suffer from performance degradation. In this\nwork, we introduce NeuZip, a new weight compression scheme based on the entropy\nof floating-point numbers in neural networks. With NeuZip, we are able to\nachieve memory-efficient training and inference without sacrificing\nperformance. Notably, we significantly reduce the memory footprint of training\na Llama-3 8B model from 31GB to less than 16GB, while keeping the training\ndynamics fully unchanged. In inference, our method can reduce memory usage by\nmore than half while maintaining near-lossless performance. Our code is\npublicly available.",
      "tldr_zh": "本研究针对神经网络训练和推理中受限于设备内存的问题，提出 NeuZip，一种基于浮点数熵（entropy）的动态权重压缩方案，能够实现内存高效操作而不牺牲性能。与传统量化（quantization）技术相比，NeuZip避免了性能下降。实验结果显示，在训练 Llama-3 8B 模型时，内存占用从 31GB 减少到不到 16GB，同时保持训练动态不变；在推理中，内存使用减少一半以上，同时维持近乎无损性能。该方法代码已公开可用，为大规模神经网络部署提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20650v1",
      "published_date": "2024-10-28 01:12:20 UTC",
      "updated_date": "2024-10-28 01:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:09:20.015635"
    },
    {
      "arxiv_id": "2410.21339v1",
      "title": "Machine Learning and Quantum Intelligence for Health Data Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjeev Naguleswaran"
      ],
      "abstract": "The advent of quantum computing has opened new possibilities in data science,\noffering unique capabilities for addressing complex, data-intensive problems.\nTraditional machine learning algorithms often face challenges in\nhigh-dimensional or limited-quality datasets, which are common in healthcare.\nQuantum Machine Learning leverages quantum properties, such as superposition\nand entanglement, to enhance pattern recognition and classification,\npotentially surpassing classical approaches. This paper explores QML's\napplication in healthcare, focusing on quantum kernel methods and hybrid\nquantum-classical networks for heart disease prediction and COVID-19 detection,\nassessing their feasibility and performance.",
      "tldr_zh": "这篇论文探讨了量子计算在数据科学中的潜力，特别是Quantum Machine Learning (QML) 如何通过利用superposition和entanglement等量子特性，提升模式识别和分类性能，以应对传统机器学习在高维或质量有限的医疗数据集中的挑战。论文重点评估了量子核方法和hybrid quantum-classical networks在心脏病预测和COVID-19检测中的应用。结果表明，这些方法在可行性和性能上显示出优势，有望超越经典方法，为医疗领域的数据处理带来新突破。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "Presented at Machine Learning and Machine Intelligence (MLMI)\n  Conference, Osaka, Japan 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.21339v1",
      "published_date": "2024-10-28 01:04:43 UTC",
      "updated_date": "2024-10-28 01:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:09:31.060982"
    },
    {
      "arxiv_id": "2410.21338v2",
      "title": "FinTeamExperts: Role Specialized MOEs For Financial Analysis",
      "title_zh": "FinTeamExperts：角色专业化的 MOEs 用于金融分析",
      "authors": [
        "Yue Yu",
        "Prayag Tiwari"
      ],
      "abstract": "Large Language Models (LLMs), such as ChatGPT, Phi3 and Llama-3, are leading\na significant leap in AI, as they can generalize knowledge from their training\nto new tasks without fine-tuning. However, their application in the financial\ndomain remains relatively limited. The financial field is inherently complex,\nrequiring a deep understanding across various perspectives, from macro, micro\neconomic trend to quantitative analysis. Motivated by this complexity, a\nmixture of expert LLMs tailored to specific financial domains could offer a\nmore comprehensive understanding for intricate financial tasks. In this paper,\nwe present the FinTeamExperts, a role-specialized LLM framework structured as a\nMixture of Experts (MOEs) for financial analysis. The framework simulates a\ncollaborative team setting by training each model to specialize in distinct\nroles: Macro Analysts, Micro analysts, and Quantitative Analysts. This\nrole-specific specialization enhances the model's ability to integrate their\ndomain-specific expertise. We achieve this by training three 8-billion\nparameter models on different corpus, each dedicated to excelling in specific\nfinance-related roles. We then instruct-tune FinTeamExperts on downstream tasks\nto align with practical financial tasks. The experimental results show that\nFinTeamExperts outperform all models of the same size and larger on three out\nof four datasets. On the fourth dataset, which presents a more complex task,\nFinTeamExperts still surpass all models of the same size. This highlights the\nsuccess of our role-based specialization approach and the continued training\napproach for FinTeamExperts.",
      "tldr_zh": "本研究提出 FinTeamExperts，一种基于 Mixture of Experts (MOEs) 的角色专业化框架，用于提升 Large Language Models (LLMs) 在金融分析中的性能，以应对金融领域的复杂性，如宏观经济趋势、微观分析和量化计算。框架模拟团队协作，训练三个8B参数的专家模型，分别专注于Macro Analysts（宏观分析师）、Micro Analysts（微观分析师）和Quantitative Analysts（量化分析师），并通过instruct-tune微调以适应实际任务。这种角色专项化方法使模型能够更好地整合领域知识。实验结果显示，FinTeamExperts 在四个数据集中的三个上超越了同等大小甚至更大的基线模型，在第四个更复杂任务上也优于同尺寸模型，验证了该方法的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21338v2",
      "published_date": "2024-10-28 00:40:55 UTC",
      "updated_date": "2024-11-07 23:11:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:09:43.190290"
    },
    {
      "arxiv_id": "2410.21337v2",
      "title": "Fine-tuned Large Language Models (LLMs): Improved Prompt Injection Attacks Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Md Abdur Rahman",
        "Fan Wu",
        "Alfredo Cuzzocrea",
        "Sheikh Iqbal Ahamed"
      ],
      "abstract": "Large language models (LLMs) are becoming a popular tool as they have\nsignificantly advanced in their capability to tackle a wide range of\nlanguage-based tasks. However, LLMs applications are highly vulnerable to\nprompt injection attacks, which poses a critical problem. These attacks target\nLLMs applications through using carefully designed input prompts to divert the\nmodel from adhering to original instruction, thereby it could execute\nunintended actions. These manipulations pose serious security threats which\npotentially results in data leaks, biased outputs, or harmful responses. This\nproject explores the security vulnerabilities in relation to prompt injection\nattacks. To detect whether a prompt is vulnerable or not, we follows two\napproaches: 1) a pre-trained LLM, and 2) a fine-tuned LLM. Then, we conduct a\nthorough analysis and comparison of the classification performance. Firstly, we\nuse pre-trained XLM-RoBERTa model to detect prompt injections using test\ndataset without any fine-tuning and evaluate it by zero-shot classification.\nThen, this proposed work will apply supervised fine-tuning to this pre-trained\nLLM using a task-specific labeled dataset from deepset in huggingface, and this\nfine-tuned model achieves impressive results with 99.13\\% accuracy, 100\\%\nprecision, 98.33\\% recall and 99.15\\% F1-score thorough rigorous\nexperimentation and evaluation. We observe that our approach is highly\nefficient in detecting prompt injection attacks.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）面临的安全威胁，特别是提示注入攻击（Prompt Injection Attacks），这些攻击通过精心设计的输入提示使模型偏离原指令，可能导致数据泄露或有害输出。为提升检测能力，研究采用两种方法：1) 使用预训练的XLM-RoBERTa模型进行零样本（zero-shot）分类；2) 通过监督微调（fine-tuning）LLMs，使用特定标记数据集训练模型。实验结果显示，微调后的模型在检测提示注入攻击方面表现出色，达到99.13%准确率、100%精确率、98.33%召回率和99.15% F1分数，显著提高了检测效率。总体而言，此方法为增强LLMs的安全性提供了有效策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "I am requesting the withdrawal of my paper due to critical issues\n  identified in the methodology/results that may impact its accuracy and\n  reliability. I also plan to make substantial revisions that go beyond minor\n  corrections",
      "pdf_url": "http://arxiv.org/pdf/2410.21337v2",
      "published_date": "2024-10-28 00:36:21 UTC",
      "updated_date": "2024-11-07 21:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T18:09:54.559030"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 147,
  "processed_papers_count": 147,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T18:10:11.870723"
}