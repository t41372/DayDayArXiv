{
  "date": "2024-06-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-06-12 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦 AI 安全、LLM 优化、多模态生成、强化学习和知识蒸馏等领域，其中 UnO 的无人驾驶感知模型、AlphaZeroES 的强化学习改进，以及 NVIDIA 团队的 HelpSteer2 数据集尤为引人注目，它们展示了高效算法和数据集创新；同时，AI 代理安全和生成模型的论文也值得关注。\n\n### 重点论文讨论\n我挑选了今天论文中的亮点，按照主题归类，先聊重要或创新性强的文章，相关主题放在一起快速概述。以下聚焦于 AI 安全、LLM 及生成模型、强化学习和多模态领域，其他次要论文（如语音处理或特定领域优化）则简要掠过，以控制篇幅。\n\n#### AI 安全与漏洞分析\n- **Security of AI Agents (AI 代理的安全)**  \n  作者：Yifeng He 等。这篇论文分析了 AI 代理（如基于 LLM 的智能助手）的系统安全漏洞，包括工具访问和命令执行风险。贡献：详细识别漏洞原因和影响，并提出相应防御机制；发现：实验验证了这些防御的有效性，强调了 AI 代理在安全框架中的改进需求。\n  \n- **On Security Weaknesses and Vulnerabilities in Deep Learning Systems (深度学习系统的安全弱点和漏洞)**  \n  作者：Zhongzheng Lai 等。论文系统研究了深度学习框架（如 TensorFlow）的漏洞模式。贡献：提出一个数据分析框架分析 CVE 数据库，并进行大规模实证研究；发现：深度学习系统生命周期中漏洞检测和修复更具挑战性，提供安全开发指导。\n\n这些论文突出了 AI 系统的安全风险，相关工作如数据安全和漏洞修复是当前热门话题，值得安全研究者关注。\n\n#### LLM 和生成模型优化\n- **HelpSteer2: Open-source dataset for training top-performing reward models (用于训练顶级奖励模型的开源数据集)**  \n  作者：Zhilin Wang 等（NVIDIA 团队）。这篇论文引入 HelpSteer2 数据集，用于 LLM 的人类偏好对齐。贡献：数据集规模小（万级样本）却高效，结合多属性评分优化奖励模型；发现：基于 HelpSteer2 的 SteerLM 2.0 在 Reward-Bench 上达到 92.0% 的 SOTA 性能，显著提升 LLM 对齐效果。\n\n- **Fine-Tuned 'Small' LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in Text Classification (微调的“小”LLM 在文本分类中仍显著优于零样本生成模型)**  \n  作者：Martin Juan José Bucher 等。论文比较微调小规模 LLM 与零样本 LLM 在文本分类中的表现。贡献：提供工具包支持微调；发现：微调后的小模型（如 BERT-like）在多种任务中优于 GPT-4，强调微调的重要性。\n\n- **Ad Auctions for LLMs via Retrieval Augmented Generation (通过检索增强生成进行 LLM 广告拍卖)**  \n  作者：MohammadTaghi Hajiaghayi 等。论文提出在 LLM 输出中整合广告的拍卖机制。贡献：设计基于 RAG 的段落拍卖算法，平衡分配效率和公平性；发现：实验验证了该机制在多广告场景下的激励兼容性，提升了计算广告的实用性。\n\nLLM 相关论文显示了模型优化和数据集创新的潜力，尤其是 HelpSteer2 的高效性，让开源社区受益。\n\n#### 强化学习和规划\n- **AlphaZeroES: Direct score maximization outperforms planning loss minimization (直接分数最大化优于规划损失最小化)**  \n  作者：Carlos Martin、Tuomas Sandholm（知名学者）。论文比较 AlphaZero 的直接分数优化与规划损失方法。贡献：使用进化策略直接最大化分数；发现：在单代理环境中，该方法在多个任务中优于传统 AlphaZero，提升了性能。\n\n- **UnO: Unsupervised Occupancy Fields for Perception and Forecasting (无监督占用场用于感知和预测)**  \n  作者：Ben Agro 等（Raquel Urtasun 团队）。论文提出无监督方法学习 4D 占用场，用于无人驾驶感知。贡献：自监督从 LiDAR 数据学习，转移到下游任务；发现：在 Argoverse 2 和 nuScenes 数据集上达到 SOTA 性能，提高了自主驾驶的鲁棒性。\n\n这些强化学习论文强调了高效规划和无监督方法的优势，Sandholm 的工作延续了其在博弈和规划领域的声誉。\n\n#### 多模态生成和图像处理\n- **VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable Reasoning (基于检索增强的假新闻检测)**  \n  作者：Cheng Niu 等。论文开发 VeraCT Scan 系统检测假新闻。贡献：结合检索和 Llama-2 微调，提供可解释证据；发现：在假新闻检测上达到 SOTA 准确率，提升了媒体可靠性。\n\n- **How to Distinguish AI-Generated Images from Authentic Photographs (如何区分 AI 生成图像与真实照片)**  \n  作者：Negar Kamali 等。论文提供指南识别 AI 生成图像的伪迹。贡献：构建数据集并分析伪迹类别；发现：AI 图像常有解剖和物理违规，提升了图像真实性评估。\n\n多模态论文展示了生成模型的实际应用，如假新闻和图像检测，VeraCT Scan 的可解释性特别有话题度。\n\n#### 其他快速掠过\n其他论文如语音生成（Toward Fully-End-to-End Listened Speech Decoding from EEG Signals）、表格处理（Multi-modal Table Understanding）和特定领域优化（e.g., MobileAIBench）也值得一提，但篇幅有限，仅简述：MobileAIBench 贡献了一个评估 LLM 和 LMM 在移动设备上的基准数据集，发现量化对任务性能有显著影响；语音论文则展示了 EEG 到语音波形的端到端解码，适用于脑机接口。\n\n总之，今天的 arXiv 论文展示了 AI 领域的多样创新，AI 安全和 LLM 优化是核心亮点。建议关注 NVIDIA 和 Sandholm 等团队的工作，以获取前沿洞见。更多细节可查阅 arXiv。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2406.08695v1",
      "title": "Global AI Governance in Healthcare: A Cross-Jurisdictional Regulatory Analysis",
      "title_zh": "全球医疗保健中的 AI 治理：跨管辖",
      "authors": [
        "Attrayee Chakraborty",
        "Mandar Karhade"
      ],
      "abstract": "Artificial Intelligence (AI) is being adopted across the world and promises a\nnew revolution in healthcare. While AI-enabled medical devices in North America\ndominate 42.3% of the global market, the use of AI-enabled medical devices in\nother countries is still a story waiting to be unfolded. We aim to delve deeper\ninto global regulatory approaches towards AI use in healthcare, with a focus on\nhow common themes are emerging globally. We compare these themes to the World\nHealth Organization's (WHO) regulatory considerations and principles on ethical\nuse of AI for healthcare applications. Our work seeks to take a global\nperspective on AI policy by analyzing 14 legal jurisdictions including\ncountries representative of various regions in the world (North America, South\nAmerica, South East Asia, Middle East, Africa, Australia, and the\nAsia-Pacific). Our eventual goal is to foster a global conversation on the\nethical use of AI in healthcare and the regulations that will guide it. We\npropose solutions to promote international harmonization of AI regulations and\nexamine the requirements for regulating generative AI, using China and\nSingapore as examples of countries with well-developed policies in this area.",
      "tldr_zh": "这篇论文分析了全球 AI 在医疗领域的治理，通过比较 14 个法律管辖区（包括北美、南美、东南亚、中东、非洲、澳大利亚和亚太地区）的监管方法，聚焦于共同主题，并与 WHO 的伦理原则进行对照。\n研究发现，虽然北美占据 AI 医疗设备市场的 42.3%，但其他地区正在展开类似应用，且全球监管正出现协调趋势。\n论文提出促进国际 AI 法规统一的解决方案，并以中国和新加坡为例，探讨生成式 AI 的监管要求，以推动全球对话和伦理使用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "K.4.1, K.6, K.5.2, J.3"
      ],
      "primary_category": "cs.CY",
      "comment": "32 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.08695v1",
      "published_date": "2024-06-12 23:36:16 UTC",
      "updated_date": "2024-06-12 23:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:02:13.485001"
    },
    {
      "arxiv_id": "2406.08691v1",
      "title": "UnO: Unsupervised Occupancy Fields for Perception and Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Agro",
        "Quinlan Sykora",
        "Sergio Casas",
        "Thomas Gilles",
        "Raquel Urtasun"
      ],
      "abstract": "Perceiving the world and forecasting its future state is a critical task for\nself-driving. Supervised approaches leverage annotated object labels to learn a\nmodel of the world -- traditionally with object detections and trajectory\npredictions, or temporal bird's-eye-view (BEV) occupancy fields. However, these\nannotations are expensive and typically limited to a set of predefined\ncategories that do not cover everything we might encounter on the road.\nInstead, we learn to perceive and forecast a continuous 4D (spatio-temporal)\noccupancy field with self-supervision from LiDAR data. This unsupervised world\nmodel can be easily and effectively transferred to downstream tasks. We tackle\npoint cloud forecasting by adding a lightweight learned renderer and achieve\nstate-of-the-art performance in Argoverse 2, nuScenes, and KITTI. To further\nshowcase its transferability, we fine-tune our model for BEV semantic occupancy\nforecasting and show that it outperforms the fully supervised state-of-the-art,\nespecially when labeled data is scarce. Finally, when compared to prior\nstate-of-the-art on spatio-temporal geometric occupancy prediction, our 4D\nworld model achieves a much higher recall of objects from classes relevant to\nself-driving.",
      "tldr_zh": "该论文提出UnO，一种无监督的占用字段方法，用于自动驾驶中的感知和预测任务，通过自监督从LiDAR数据学习连续的4D（时空）占用字段，避免了对昂贵标注的依赖。UnO框架添加了一个轻量级的学习渲染器，在点云预测上达到了Argoverse 2、nuScenes和KITTI数据集的最先进性能。进一步微调后，该模型在BEV语义占用预测中超越了完全监督的SOTA基准，尤其在标注数据稀缺时，并显著提高了自动驾驶相关物体的召回率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08691v1",
      "published_date": "2024-06-12 23:22:23 UTC",
      "updated_date": "2024-06-12 23:22:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:02:25.709791"
    },
    {
      "arxiv_id": "2406.08689v3",
      "title": "Security of AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng He",
        "Ethan Wang",
        "Yuyang Rong",
        "Zifei Cheng",
        "Hao Chen"
      ],
      "abstract": "AI agents have been boosted by large language models. AI agents can function\nas intelligent assistants and complete tasks on behalf of their users with\naccess to tools and the ability to execute commands in their environments.\nThrough studying and experiencing the workflow of typical AI agents, we have\nraised several concerns regarding their security. These potential\nvulnerabilities are not addressed by the frameworks used to build the agents,\nnor by research aimed at improving the agents. In this paper, we identify and\ndescribe these vulnerabilities in detail from a system security perspective,\nemphasizing their causes and severe effects. Furthermore, we introduce defense\nmechanisms corresponding to each vulnerability with design and experiments to\nevaluate their viability. Altogether, this paper contextualizes the security\nissues in the current development of AI agents and delineates methods to make\nAI agents safer and more reliable.",
      "tldr_zh": "这篇论文探讨了由大型语言模型驱动的 AI agents 的安全问题，指出这些代理在执行任务时可能存在的漏洞，如系统设计缺陷，导致潜在风险未被现有框架或研究充分解决。\n作者从系统安全视角详细分析了这些漏洞的原因和严重影响，并针对每个漏洞引入相应的防御机制。\n通过设计和实验评估，这些防御机制的 viability 被验证，有助于使 AI agents 更安全和可靠。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "updated version with figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08689v3",
      "published_date": "2024-06-12 23:16:45 UTC",
      "updated_date": "2024-12-17 21:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:02:37.283863"
    },
    {
      "arxiv_id": "2406.08688v1",
      "title": "On Security Weaknesses and Vulnerabilities in Deep Learning Systems",
      "title_zh": "关于深度学习系统的安全弱点和漏洞",
      "authors": [
        "Zhongzheng Lai",
        "Huaming Chen",
        "Ruoxi Sun",
        "Yu Zhang",
        "Minhui Xue",
        "Dong Yuan"
      ],
      "abstract": "The security guarantee of AI-enabled software systems (particularly using\ndeep learning techniques as a functional core) is pivotal against the\nadversarial attacks exploiting software vulnerabilities. However, little\nattention has been paid to a systematic investigation of vulnerabilities in\nsuch systems. A common situation learned from the open source software\ncommunity is that deep learning engineers frequently integrate off-the-shelf or\nopen-source learning frameworks into their ecosystems. In this work, we\nspecifically look into deep learning (DL) framework and perform the first\nsystematic study of vulnerabilities in DL systems through a comprehensive\nanalysis of identified vulnerabilities from Common Vulnerabilities and\nExposures (CVE) and open-source DL tools, including TensorFlow, Caffe, OpenCV,\nKeras, and PyTorch. We propose a two-stream data analysis framework to explore\nvulnerability patterns from various databases. We investigate the unique DL\nframeworks and libraries development ecosystems that appear to be decentralized\nand fragmented. By revisiting the Common Weakness Enumeration (CWE) List, which\nprovides the traditional software vulnerability related practices, we observed\nthat it is more challenging to detect and fix the vulnerabilities throughout\nthe DL systems lifecycle. Moreover, we conducted a large-scale empirical study\nof 3,049 DL vulnerabilities to better understand the patterns of vulnerability\nand the challenges in fixing them. We have released the full replication\npackage at https://github.com/codelzz/Vulnerabilities4DLSystem. We anticipate\nthat our study can advance the development of secure DL systems.",
      "tldr_zh": "本研究系统调查了深度学习（DL）系统中的安全弱点和漏洞，重点分析了开源DL框架如TensorFlow、Caffe、OpenCV、Keras和PyTorch的生态。作者提出一个两流数据分析框架，通过Common Vulnerabilities and Exposures (CVE)数据库和实证研究3049个DL漏洞，揭示了这些系统开发环境的分散性和碎片化，以及漏洞检测和修复的挑战。研究发现，传统Common Weakness Enumeration (CWE)实践难以适应DL系统，导致修复难度增加，并发布了GitHub复制包以支持后续工作。该工作为推进安全DL系统的开发提供了重要基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08688v1",
      "published_date": "2024-06-12 23:04:13 UTC",
      "updated_date": "2024-06-12 23:04:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:02:47.577586"
    },
    {
      "arxiv_id": "2406.08687v1",
      "title": "AlphaZeroES: Direct score maximization outperforms planning loss minimization",
      "title_zh": "AlphaZeroES：直接得分最大化优于规划损失最小化",
      "authors": [
        "Carlos Martin",
        "Tuomas Sandholm"
      ],
      "abstract": "Planning at execution time has been shown to dramatically improve performance\nfor agents in both single-agent and multi-agent settings. A well-known family\nof approaches to planning at execution time are AlphaZero and its variants,\nwhich use Monte Carlo Tree Search together with a neural network that guides\nthe search by predicting state values and action probabilities. AlphaZero\ntrains these networks by minimizing a planning loss that makes the value\nprediction match the episode return, and the policy prediction at the root of\nthe search tree match the output of the full tree expansion. AlphaZero has been\napplied to both single-agent environments (such as Sokoban) and multi-agent\nenvironments (such as chess and Go) with great success. In this paper, we\nexplore an intriguing question: In single-agent environments, can we outperform\nAlphaZero by directly maximizing the episode score instead of minimizing this\nplanning loss, while leaving the MCTS algorithm and neural architecture\nunchanged? To directly maximize the episode score, we use evolution strategies,\na family of algorithms for zeroth-order blackbox optimization. Our experiments\nindicate that, across multiple environments, directly maximizing the episode\nscore outperforms minimizing the planning loss.",
      "tldr_zh": "本文提出 AlphaZeroES 方法，在单代理环境中，通过直接最大化 episode score 而非最小化 planning loss，来提升代理性能，同时保持 Monte Carlo Tree Search (MCTS) 和神经网络架构不变。作者使用 evolution strategies 作为零阶黑箱优化算法来实现这一目标。实验结果表明，在多个环境中，直接最大化 episode score 的方法优于传统的 planning loss 最小化策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2308.08693",
      "pdf_url": "http://arxiv.org/pdf/2406.08687v1",
      "published_date": "2024-06-12 23:00:59 UTC",
      "updated_date": "2024-06-12 23:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:03:00.189950"
    },
    {
      "arxiv_id": "2406.10290v1",
      "title": "MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Rithesh Murthy",
        "Liangwei Yang",
        "Juntao Tan",
        "Tulika Manoj Awalgaonkar",
        "Yilun Zhou",
        "Shelby Heinecke",
        "Sachin Desai",
        "Jason Wu",
        "Ran Xu",
        "Sarah Tan",
        "Jianguo Zhang",
        "Zhiwei Liu",
        "Shirley Kokane",
        "Zuxin Liu",
        "Ming Zhu",
        "Huan Wang",
        "Caiming Xiong",
        "Silvio Savarese"
      ],
      "abstract": "The deployment of Large Language Models (LLMs) and Large Multimodal Models\n(LMMs) on mobile devices has gained significant attention due to the benefits\nof enhanced privacy, stability, and personalization. However, the hardware\nconstraints of mobile devices necessitate the use of models with fewer\nparameters and model compression techniques like quantization. Currently, there\nis limited understanding of quantization's impact on various task performances,\nincluding LLM tasks, LMM tasks, and, critically, trust and safety. There is a\nlack of adequate tools for systematically testing these models on mobile\ndevices. To address these gaps, we introduce MobileAIBench, a comprehensive\nbenchmarking framework for evaluating mobile-optimized LLMs and LMMs.\nMobileAIBench assesses models across different sizes, quantization levels, and\ntasks, measuring latency and resource consumption on real devices. Our two-part\nopen-source framework includes a library for running evaluations on desktops\nand an iOS app for on-device latency and hardware utilization measurements. Our\nthorough analysis aims to accelerate mobile AI research and deployment by\nproviding insights into the performance and feasibility of deploying LLMs and\nLMMs on mobile platforms.",
      "tldr_zh": "该研究针对在移动设备上部署 Large Language Models (LLMs) 和 Large Multimodal Models (LMMs) 的挑战，强调了硬件限制（如参数减少和量化技术）对模型性能、信任和安全的影响，并指出现有测试工具的不足。论文引入 MobileAIBench，一个全面的基准框架，用于评估这些模型在不同大小、量化级别和任务（如LLM任务、LMM任务）上的表现，包括延迟和资源消耗的测量。该框架包括一个桌面评估库和一个iOS应用，支持在真实设备上进行测试，通过深入分析加速移动AI的研究和部署，提供关键见解以提升隐私、稳定性和个性化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10290v1",
      "published_date": "2024-06-12 22:58:12 UTC",
      "updated_date": "2024-06-12 22:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:03:21.632234"
    },
    {
      "arxiv_id": "2406.08673v1",
      "title": "HelpSteer2: Open-source dataset for training top-performing reward models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhilin Wang",
        "Yi Dong",
        "Olivier Delalleau",
        "Jiaqi Zeng",
        "Gerald Shen",
        "Daniel Egert",
        "Jimmy J. Zhang",
        "Makesh Narsimhan Sreedhar",
        "Oleksii Kuchaiev"
      ],
      "abstract": "High-quality preference datasets are essential for training reward models\nthat can effectively guide large language models (LLMs) in generating\nhigh-quality responses aligned with human preferences. As LLMs become stronger\nand better aligned, permissively licensed preference datasets, such as Open\nAssistant, HH-RLHF, and HelpSteer need to be updated to remain effective for\nreward modeling. Methods that distil preference data from proprietary LLMs such\nas GPT-4 have restrictions on commercial usage imposed by model providers. To\nimprove upon both generated responses and attribute labeling quality, we\nrelease HelpSteer2, a permissively licensed preference dataset (CC-BY-4.0).\nUsing a powerful internal base model trained on HelpSteer2, we are able to\nachieve the SOTA score (92.0%) on Reward-Bench's primary dataset, outperforming\ncurrently listed open and proprietary models, as of June 12th, 2024. Notably,\nHelpSteer2 consists of only ten thousand response pairs, an order of magnitude\nfewer than existing preference datasets (e.g., HH-RLHF), which makes it highly\nefficient for training reward models. Our extensive experiments demonstrate\nthat reward models trained with HelpSteer2 are effective in aligning LLMs. In\nparticular, we propose SteerLM 2.0, a model alignment approach that can\neffectively make use of the rich multi-attribute score predicted by our reward\nmodels. HelpSteer2 is available at\nhttps://huggingface.co/datasets/nvidia/HelpSteer2 and code is available at\nhttps://github.com/NVIDIA/NeMo-Aligner",
      "tldr_zh": "该论文介绍了 HelpSteer2，这是一个开源偏好数据集（CC-BY-4.0 许可），旨在训练高性能的 reward models，以指导大型语言模型（LLMs）生成符合人类偏好的响应。相比现有数据集如 HH-RLHF，HelpSteer2 仅包含一万个响应对，规模小但高效，能够显著提升属性标签和响应质量。实验结果显示，使用 HelpSteer2 训练的模型在 Reward-Bench 的主要数据集上达到了 SOTA 成绩（92.0%），超越了当前开源和专有模型。作者还提出了 SteerLM 2.0，这是一种利用多属性分数的模型对齐方法，有效提升了 LLMs 的对齐性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08673v1",
      "published_date": "2024-06-12 22:28:08 UTC",
      "updated_date": "2024-06-12 22:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:03:26.102743"
    },
    {
      "arxiv_id": "2406.08666v2",
      "title": "Interventional Causal Discovery in a Mixture of DAGs",
      "title_zh": "翻译失败",
      "authors": [
        "Burak Varıcı",
        "Dmitriy Katz-Rogozhnikov",
        "Dennis Wei",
        "Prasanna Sattigeri",
        "Ali Tajer"
      ],
      "abstract": "Causal interactions among a group of variables are often modeled by a single\ncausal graph. In some domains, however, these interactions are best described\nby multiple co-existing causal graphs, e.g., in dynamical systems or genomics.\nThis paper addresses the hitherto unknown role of interventions in learning\ncausal interactions among variables governed by a mixture of causal systems,\neach modeled by one directed acyclic graph (DAG). Causal discovery from\nmixtures is fundamentally more challenging than single-DAG causal discovery.\nTwo major difficulties stem from (i)~an inherent uncertainty about the\nskeletons of the component DAGs that constitute the mixture and (ii)~possibly\ncyclic relationships across these component DAGs. This paper addresses these\nchallenges and aims to identify edges that exist in at least one component DAG\nof the mixture, referred to as the true edges. First, it establishes matching\nnecessary and sufficient conditions on the size of interventions required to\nidentify the true edges. Next, guided by the necessity results, an adaptive\nalgorithm is designed that learns all true edges using $O(n^2)$ interventions,\nwhere $n$ is the number of nodes. Remarkably, the size of the interventions is\noptimal if the underlying mixture model does not contain cycles across its\ncomponents. More generally, the gap between the intervention size used by the\nalgorithm and the optimal size is quantified. It is shown to be bounded by the\ncyclic complexity number of the mixture model, defined as the size of the\nminimal intervention that can break the cycles in the mixture, which is upper\nbounded by the number of cycles among the ancestors of a node.",
      "tldr_zh": "该论文探讨了在多个有向无环图 (DAGs) 混合模型中，通过干预 (interventions) 发现变量间因果关系的挑战，该模型常见于动态系统或基因组学领域。论文建立了识别混合模型中至少存在于一个DAG的真边 (true edges) 所需的必要和充分干预条件，并设计了一个自适应算法，使用 O(n^2) 个干预来学习所有真边。实验结果表明，如果混合模型没有跨组件循环，该算法的干预大小是最优的；否则，干预大小的差距由混合模型的循环复杂度数 (cyclic complexity number) 量化，从而为复杂因果发现提供了高效框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.08666v2",
      "published_date": "2024-06-12 22:12:03 UTC",
      "updated_date": "2024-12-03 04:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:03:39.117198"
    },
    {
      "arxiv_id": "2406.08665v2",
      "title": "Data Augmentation by Fuzzing for Neural Test Generation",
      "title_zh": "通过模糊测试进行数据增强用于神经测试生成",
      "authors": [
        "Yifeng He",
        "Jicheng Wang",
        "Yuyang Rong",
        "Hao Chen"
      ],
      "abstract": "Testing is essential to modern software engineering for building reliable\nsoftware. Given the high costs of manually creating test cases, automated test\ncase generation, particularly methods utilizing large language models, has\nbecome increasingly popular. These neural approaches generate semantically\nmeaningful tests that are more maintainable compared with traditional automatic\ntesting methods like fuzzing. However, the diversity and volume of unit tests\nin current datasets are limited. In this paper, we introduce a novel data\naugmentation technique, *FuzzAug*, that introduces the benefits of fuzzing to\nlarge language models to preserve valid program semantics and provide diverse\ninputs. This enhances the model's ability to embed correct inputs that can\nexplore more branches of the function under test. Our evaluations show that\nmodels trained with dataset augmented by FuzzAug increase assertion accuracy by\n5%, improve compilation rate by more than 10%, and generate unit test functions\nwith 5% more branch coverage. This technique demonstrates the potential of\nusing dynamic software testing to improve neural test generation, offering\nsignificant enhancements in neural test generation.",
      "tldr_zh": "这篇论文提出了一种名为 FuzzAug 的数据增强技术，将 fuzzing 方法整合到大型语言模型中，用于改进神经测试生成，从而解决当前数据集单元测试多样性和数量有限的问题。FuzzAug 通过生成多样输入并保持程序语义，帮助模型探索更多函数分支，提高测试的有效性。实验结果显示，使用 FuzzAug 增强的数据集训练的模型，assertion accuracy 提高了 5%，compilation rate 提升超过 10%，branch coverage 增加了 5%，展示了动态软件测试在神经测试生成中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Revised version",
      "pdf_url": "http://arxiv.org/pdf/2406.08665v2",
      "published_date": "2024-06-12 22:09:27 UTC",
      "updated_date": "2024-09-13 18:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:03:49.215493"
    },
    {
      "arxiv_id": "2406.09459v1",
      "title": "Ad Auctions for LLMs via Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "MohammadTaghi Hajiaghayi",
        "Sébastien Lahaie",
        "Keivan Rezaei",
        "Suho Shin"
      ],
      "abstract": "In the field of computational advertising, the integration of ads into the\noutputs of large language models (LLMs) presents an opportunity to support\nthese services without compromising content integrity. This paper introduces\nnovel auction mechanisms for ad allocation and pricing within the textual\noutputs of LLMs, leveraging retrieval-augmented generation (RAG). We propose a\nsegment auction where an ad is probabilistically retrieved for each discourse\nsegment (paragraph, section, or entire output) according to its bid and\nrelevance, following the RAG framework, and priced according to competing bids.\nWe show that our auction maximizes logarithmic social welfare, a new notion of\nwelfare that balances allocation efficiency and fairness, and we characterize\nthe associated incentive-compatible pricing rule. These results are extended to\nmulti-ad allocation per segment. An empirical evaluation validates the\nfeasibility and effectiveness of our approach over several ad auction\nscenarios, and exhibits inherent tradeoffs in metrics as we allow the LLM more\nflexibility to allocate ads.",
      "tldr_zh": "本研究提出了一种新型拍卖机制，用于将广告整合到大型语言模型（LLMs）的文本输出中，同时利用检索增强生成（RAG）技术来支持广告分配和定价。该机制采用段落拍卖（segment auction），根据广告的竞标和相关性，概率性地为每个话语段落（如段落或部分）检索广告，并根据竞争竞标制定激励兼容定价规则，以最大化对数社会福利（logarithmic social welfare），从而平衡分配效率和公平性。研究扩展了这一框架，支持每个段落分配多个广告，并通过实证评估在多个广告拍卖场景中验证了方法的有效性，同时揭示了当允许LLMs更灵活分配广告时，指标之间的权衡取舍。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.09459v1",
      "published_date": "2024-06-12 22:05:51 UTC",
      "updated_date": "2024-06-12 22:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:04:00.333566"
    },
    {
      "arxiv_id": "2406.08660v2",
      "title": "Fine-Tuned 'Small' LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Juan José Bucher",
        "Marco Martini"
      ],
      "abstract": "Generative AI offers a simple, prompt-based alternative to fine-tuning\nsmaller BERT-style LLMs for text classification tasks. This promises to\neliminate the need for manually labeled training data and task-specific model\ntraining. However, it remains an open question whether tools like ChatGPT can\ndeliver on this promise. In this paper, we show that smaller, fine-tuned LLMs\n(still) consistently and significantly outperform larger, zero-shot prompted\nmodels in text classification. We compare three major generative AI models\n(ChatGPT with GPT-3.5/GPT-4 and Claude Opus) with several fine-tuned LLMs\nacross a diverse set of classification tasks (sentiment, approval/disapproval,\nemotions, party positions) and text categories (news, tweets, speeches). We\nfind that fine-tuning with application-specific training data achieves superior\nperformance in all cases. To make this approach more accessible to a broader\naudience, we provide an easy-to-use toolkit alongside this paper. Our toolkit,\naccompanied by non-technical step-by-step guidance, enables users to select and\nfine-tune BERT-like LLMs for any classification task with minimal technical and\ncomputational effort.",
      "tldr_zh": "本文研究比较了微调后的小型 LLMs（如 BERT-style 模型）与零-shot 生成式 AI 模型（如 ChatGPT with GPT-3.5/GPT-4 和 Claude Opus）在文本分类任务（如情感分析、批准/ disapproval、情绪和政党立场）中的性能。结果显示，fine-tuned LLMs 在所有测试任务和文本类别（如新闻、推文、演讲）上，均显著优于零-shot 模型，性能提升一致。作者提供了易于使用的工具包和非技术性指导，帮助用户以最小技术与计算努力微调 LLMs，从而使这种方法更易于推广。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08660v2",
      "published_date": "2024-06-12 21:46:13 UTC",
      "updated_date": "2024-08-16 15:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:04:17.837387"
    },
    {
      "arxiv_id": "2406.08656v1",
      "title": "TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and Image-to-Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Weixi Feng",
        "Jiachen Li",
        "Michael Saxon",
        "Tsu-jui Fu",
        "Wenhu Chen",
        "William Yang Wang"
      ],
      "abstract": "Video generation has many unique challenges beyond those of image generation.\nThe temporal dimension introduces extensive possible variations across frames,\nover which consistency and continuity may be violated. In this study, we move\nbeyond evaluating simple actions and argue that generated videos should\nincorporate the emergence of new concepts and their relation transitions like\nin real-world videos as time progresses. To assess the Temporal\nCompositionality of video generation models, we propose TC-Bench, a benchmark\nof meticulously crafted text prompts, corresponding ground truth videos, and\nrobust evaluation metrics. The prompts articulate the initial and final states\nof scenes, effectively reducing ambiguities for frame development and\nsimplifying the assessment of transition completion. In addition, by collecting\naligned real-world videos corresponding to the prompts, we expand TC-Bench's\napplicability from text-conditional models to image-conditional ones that can\nperform generative frame interpolation. We also develop new metrics to measure\nthe completeness of component transitions in generated videos, which\ndemonstrate significantly higher correlations with human judgments than\nexisting metrics. Our comprehensive experimental results reveal that most video\ngenerators achieve less than 20% of the compositional changes, highlighting\nenormous space for future improvement. Our analysis indicates that current\nvideo generation models struggle to interpret descriptions of compositional\nchanges and synthesize various components across different time steps.",
      "tldr_zh": "本研究强调视频生成模型需处理时间维度的 Temporal Compositionality，包括新概念出现和关系变化，提出 TC-Bench 基准用于评估 text-to-video 和 image-to-video 生成模型。TC-Bench 包括精心设计的文本提示、对应真实视频和鲁棒评估指标，这些提示明确场景的初始与最终状态，并扩展到图像条件模型。论文开发了新指标来衡量组件过渡的完整性，这些指标与人类判断的相关性显著更高。实验结果显示，大多数视频生成模型仅实现了不到 20% 的组合变化，揭示当前模型在解释描述和跨时间步合成组件方面存在重大不足。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08656v1",
      "published_date": "2024-06-12 21:41:32 UTC",
      "updated_date": "2024-06-12 21:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:04:26.919000"
    },
    {
      "arxiv_id": "2407.09499v1",
      "title": "Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Damien Ferbach",
        "Quentin Bertrand",
        "Avishek Joey Bose",
        "Gauthier Gidel"
      ],
      "abstract": "The rapid progress in generative models has resulted in impressive leaps in\ngeneration quality, blurring the lines between synthetic and real data.\nWeb-scale datasets are now prone to the inevitable contamination by synthetic\ndata, directly impacting the training of future generated models. Already, some\ntheoretical results on self-consuming generative models (a.k.a., iterative\nretraining) have emerged in the literature, showcasing that either model\ncollapse or stability could be possible depending on the fraction of generated\ndata used at each retraining step. However, in practice, synthetic data is\noften subject to human feedback and curated by users before being used and\nuploaded online. For instance, many interfaces of popular text-to-image\ngenerative models, such as Stable Diffusion or Midjourney, produce several\nvariations of an image for a given query which can eventually be curated by the\nusers. In this paper, we theoretically study the impact of data curation on\niterated retraining of generative models and show that it can be seen as an\n\\emph{implicit preference optimization mechanism}. However, unlike standard\npreference optimization, the generative model does not have access to the\nreward function or negative samples needed for pairwise comparisons. Moreover,\nour study doesn't require access to the density function, only to samples. We\nprove that, if the data is curated according to a reward model, then the\nexpected reward of the iterative retraining procedure is maximized. We further\nprovide theoretical results on the stability of the retraining loop when using\na positive fraction of real data at each step. Finally, we conduct illustrative\nexperiments on both synthetic datasets and on CIFAR10 showing that such a\nprocedure amplifies biases of the reward model.",
      "tldr_zh": "该研究探讨了生成模型的自消耗（self-consuming generative models），即在迭代再训练过程中使用经人工反馈 curation 的合成数据，并证明这种机制可作为隐式偏好优化（preference optimization），从而优化人类偏好，而无需访问奖励函数（reward model）或负样本。作者理论证明，如果数据根据奖励模型进行 curation，则迭代再训练过程能最大化预期的奖励，并分析了在每步使用一定比例真实数据时的稳定性。实验在合成数据集和CIFAR10上验证了这一过程会放大奖励模型的偏差，提供对生成模型训练的潜在风险和优化策略的洞见。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.ML",
        "68T10",
        "I.2.6"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09499v1",
      "published_date": "2024-06-12 21:28:28 UTC",
      "updated_date": "2024-06-12 21:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:04:37.698894"
    },
    {
      "arxiv_id": "2406.10289v2",
      "title": "VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Niu",
        "Yang Guan",
        "Yuanhao Wu",
        "Juno Zhu",
        "Juntong Song",
        "Randy Zhong",
        "Kaihua Zhu",
        "Siliang Xu",
        "Shizhe Diao",
        "Tong Zhang"
      ],
      "abstract": "The proliferation of fake news poses a significant threat not only by\ndisseminating misleading information but also by undermining the very\nfoundations of democracy. The recent advance of generative artificial\nintelligence has further exacerbated the challenge of distinguishing genuine\nnews from fabricated stories. In response to this challenge, we introduce\nVeraCT Scan, a novel retrieval-augmented system for fake news detection. This\nsystem operates by extracting the core facts from a given piece of news and\nsubsequently conducting an internet-wide search to identify corroborating or\nconflicting reports. Then sources' credibility is leveraged for information\nverification. Besides determining the veracity of news, we also provide\ntransparent evidence and reasoning to support its conclusions, resulting in the\ninterpretability and trust in the results. In addition to GPT-4 Turbo, Llama-2\n13B is also fine-tuned for news content understanding, information\nverification, and reasoning. Both implementations have demonstrated\nstate-of-the-art accuracy in the realm of fake news detection.",
      "tldr_zh": "本研究针对假新闻的扩散及其对民主的威胁，提出了 VeraCT Scan 系统，这是一种 Retrieval-Augmented 的假新闻检测框架。该系统通过提取新闻核心事实、进行互联网搜索以寻找支持或冲突的报道，并评估来源可信度，来实现信息验证和真实性判断。同时，系统提供透明的证据和推理过程，以提升结果的可解释性和可信度。实验结果显示，使用 GPT-4 Turbo 和微调后的 Llama-2 13B 模型，VeraCT Scan 在假新闻检测中达到了最先进的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10289v2",
      "published_date": "2024-06-12 21:23:48 UTC",
      "updated_date": "2024-06-24 23:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:04:51.315063"
    },
    {
      "arxiv_id": "2406.08651v1",
      "title": "How to Distinguish AI-Generated Images from Authentic Photographs",
      "title_zh": "如何区分 AI 生成图像与真实照片",
      "authors": [
        "Negar Kamali",
        "Karyn Nakamura",
        "Angelos Chatzimparmpas",
        "Jessica Hullman",
        "Matthew Groh"
      ],
      "abstract": "The high level of photorealism in state-of-the-art diffusion models like\nMidjourney, Stable Diffusion, and Firefly makes it difficult for untrained\nhumans to distinguish between real photographs and AI-generated images. To\naddress this problem, we designed a guide to help readers develop a more\ncritical eye toward identifying artifacts, inconsistencies, and\nimplausibilities that often appear in AI-generated images. The guide is\norganized into five categories of artifacts and implausibilities: anatomical,\nstylistic, functional, violations of physics, and sociocultural. For this\nguide, we generated 138 images with diffusion models, curated 9 images from\nsocial media, and curated 42 real photographs. These images showcase the kinds\nof cues that prompt suspicion towards the possibility an image is AI-generated\nand why it is often difficult to draw conclusions about an image's provenance\nwithout any context beyond the pixels in an image. Human-perceptible artifacts\nare not always present in AI-generated images, but this guide reveals artifacts\nand implausibilities that often emerge. By drawing attention to these kinds of\nartifacts and implausibilities, we aim to better equip people to distinguish\nAI-generated images from real photographs in the future.",
      "tldr_zh": "本研究探讨了如何区分AI-generated images（AI 生成图像）和真实照片，指出先进diffusion models（如Midjourney、Stable Diffusion和Firefly）的高逼真度让普通人难以辨识。作者设计了一个指南，将常见artifacts（人工制品）、inconsistencies（不一致性）和implausibilities（不可能性）分为五类：anatomical（解剖学）、stylistic（风格）、functional（功能）、violations of physics（物理法则违反）和sociocultural（社会文化）。通过生成138张AI图像、选取9张社交媒体图像和42张真实照片，该指南展示了引发怀疑的关键线索，并解释了仅凭像素判断图像来源的难度。尽管AI图像不总是显露这些问题，研究旨在通过强调这些常见缺陷，帮助人们在未来更有效地识别AI-generated images。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "54 pages, 189 Figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08651v1",
      "published_date": "2024-06-12 21:23:27 UTC",
      "updated_date": "2024-06-12 21:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:05:03.050624"
    },
    {
      "arxiv_id": "2406.08644v1",
      "title": "Toward Fully-End-to-End Listened Speech Decoding from EEG Signals",
      "title_zh": "翻译失败",
      "authors": [
        "Jihwan Lee",
        "Aditya Kommineni",
        "Tiantian Feng",
        "Kleanthis Avramidis",
        "Xuan Shi",
        "Sudarsana Kadiri",
        "Shrikanth Narayanan"
      ],
      "abstract": "Speech decoding from EEG signals is a challenging task, where brain activity\nis modeled to estimate salient characteristics of acoustic stimuli. We propose\nFESDE, a novel framework for Fully-End-to-end Speech Decoding from EEG signals.\nOur approach aims to directly reconstruct listened speech waveforms given EEG\nsignals, where no intermediate acoustic feature processing step is required.\nThe proposed method consists of an EEG module and a speech module along with a\nconnector. The EEG module learns to better represent EEG signals, while the\nspeech module generates speech waveforms from model representations. The\nconnector learns to bridge the distributions of the latent spaces of EEG and\nspeech. The proposed framework is both simple and efficient, by allowing\nsingle-step inference, and outperforms prior works on objective metrics. A\nfine-grained phoneme analysis is conducted to unveil model characteristics of\nspeech decoding. The source code is available here: github.com/lee-jhwn/fesde.",
      "tldr_zh": "这篇论文提出 FESDE 框架，实现从 EEG 信号到语音波形的 fully-end-to-end 解码，无需中间声学特征处理步骤。框架由 EEG 模块（负责信号表示）、语音模块（生成波形）和连接器（桥接潜在空间分布）组成，支持高效的单步推理，并在客观指标上优于现有方法。通过细粒度的音素分析，该研究揭示了模型在语音解码方面的特性，为脑机接口应用提供了新进展。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "eess.SP",
      "comment": "accepted to Interspeech2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08644v1",
      "published_date": "2024-06-12 21:08:12 UTC",
      "updated_date": "2024-06-12 21:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:05:14.572707"
    },
    {
      "arxiv_id": "2406.09458v2",
      "title": "Updating CLIP to Prefer Descriptions Over Captions",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Zur",
        "Elisa Kreiss",
        "Karel D'Oosterlinck",
        "Christopher Potts",
        "Atticus Geiger"
      ],
      "abstract": "Although CLIPScore is a powerful generic metric that captures the similarity\nbetween a text and an image, it fails to distinguish between a caption that is\nmeant to complement the information in an image and a description that is meant\nto replace an image entirely, e.g., for accessibility. We address this\nshortcoming by updating the CLIP model with the Concadia dataset to assign\nhigher scores to descriptions than captions using parameter efficient\nfine-tuning and a loss objective derived from work on causal interpretability.\nThis model correlates with the judgements of blind and low-vision people while\npreserving transfer capabilities and has interpretable structure that sheds\nlight on the caption--description distinction.",
      "tldr_zh": "这篇论文针对 CLIPScore 指标的不足，即无法区分补充图像信息的标题(captions)和完全替换图像的描述(descriptions)，如用于无障碍访问，提出通过更新 CLIP 模型来优先赋予描述更高的分数。方法包括使用 Concadia 数据集进行参数高效微调(parameter efficient fine-tuning)，并采用从因果可解释性工作衍生出的损失函数。结果表明，更新后的模型与盲人和低视力人士的判断高度相关，同时保留了迁移能力，并提供了可解释的结构，揭示了标题与描述的区别。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.09458v2",
      "published_date": "2024-06-12 20:24:51 UTC",
      "updated_date": "2024-10-03 22:10:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:05:30.054908"
    },
    {
      "arxiv_id": "2406.08623v1",
      "title": "Emotion Manipulation Through Music -- A Deep Learning Interactive Visual Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Adel N. Abdalla",
        "Jared Osborne",
        "Razvan Andonie"
      ],
      "abstract": "Music evokes emotion in many people. We introduce a novel way to manipulate\nthe emotional content of a song using AI tools. Our goal is to achieve the\ndesired emotion while leaving the original melody as intact as possible. For\nthis, we create an interactive pipeline capable of shifting an input song into\na diametrically opposed emotion and visualize this result through Russel's\nCircumplex model. Our approach is a proof-of-concept for Semantic Manipulation\nof Music, a novel field aimed at modifying the emotional content of existing\nmusic. We design a deep learning model able to assess the accuracy of our\nmodifications to key, SoundFont instrumentation, and other musical features.\nThe accuracy of our model is in-line with the current state of the art\ntechniques on the 4Q Emotion dataset. With further refinement, this research\nmay contribute to on-demand custom music generation, the automated remixing of\nexisting work, and music playlists tuned for emotional progression.",
      "tldr_zh": "本研究提出了一种基于深度学习(Deep Learning)的交互式视觉方法，用于操纵音乐的情感内容，目标是改变歌曲的情感（如将歌曲转向相反情绪）的同时尽量保持原旋律完整。研究团队设计了一个交互式管道，利用 Russel's Circumplex model 进行结果可视化，并通过深度学习模型评估对音调、SoundFont 工具和其他音乐特征的修改准确性。实验结果显示，该模型在 4Q Emotion 数据集上的性能与当前最先进技术相当，作为音乐语义操纵(Semantic Manipulation of Music)领域的证明概念，为按需自定义音乐生成、自动混音和情感渐进播放列表的开发提供了潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08623v1",
      "published_date": "2024-06-12 20:12:29 UTC",
      "updated_date": "2024-06-12 20:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:05:38.086171"
    },
    {
      "arxiv_id": "2406.08610v1",
      "title": "LayeredDoc: Domain Adaptive Document Restoration with a Layer Separation Approach",
      "title_zh": "LayeredDoc",
      "authors": [
        "Maria Pilligua",
        "Nil Biescas",
        "Javier Vazquez-Corral",
        "Josep Lladós",
        "Ernest Valveny",
        "Sanket Biswas"
      ],
      "abstract": "The rapid evolution of intelligent document processing systems demands robust\nsolutions that adapt to diverse domains without extensive retraining.\nTraditional methods often falter with variable document types, leading to poor\nperformance. To overcome these limitations, this paper introduces a\ntext-graphic layer separation approach that enhances domain adaptability in\ndocument image restoration (DIR) systems. We propose LayeredDoc, which utilizes\ntwo layers of information: the first targets coarse-grained graphic components,\nwhile the second refines machine-printed textual content. This hierarchical DIR\nframework dynamically adjusts to the characteristics of the input document,\nfacilitating effective domain adaptation. We evaluated our approach both\nqualitatively and quantitatively using a new real-world dataset, LayeredDocDB,\ndeveloped for this study. Initially trained on a synthetically generated\ndataset, our model demonstrates strong generalization capabilities for the DIR\ntask, offering a promising solution for handling variability in real-world\ndata. Our code is accessible on GitHub.",
      "tldr_zh": "这篇论文针对智能文档处理系统的领域适应性挑战，提出了一种文本-图形层分离方法，以提升文档图像恢复（DIR）系统的鲁棒性。LayeredDoc框架采用分层结构：第一层处理粗粒度图形组件，第二层细化机器打印文本内容，从而实现动态调整和有效领域适应。研究团队使用新数据集LayeredDocDB进行定性和定量评估，结果显示，该模型从合成数据集训练后，在真实世界数据上表现出强劲的泛化能力，为处理文档变异性提供了可行的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICDAR 2024 (Athens, Greece) Workshop on Automatically\n  Domain-Adapted and Personalized Document Analysis (ADAPDA)",
      "pdf_url": "http://arxiv.org/pdf/2406.08610v1",
      "published_date": "2024-06-12 19:41:01 UTC",
      "updated_date": "2024-06-12 19:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:05:52.407916"
    },
    {
      "arxiv_id": "2406.08607v1",
      "title": "Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabao Ji",
        "Yujian Liu",
        "Yang Zhang",
        "Gaowen Liu",
        "Ramana Rao Kompella",
        "Sijia Liu",
        "Shiyu Chang"
      ],
      "abstract": "As Large Language Models (LLMs) demonstrate extensive capability in learning\nfrom documents, LLM unlearning becomes an increasingly important research area\nto address concerns of LLMs in terms of privacy, copyright, etc. A conventional\nLLM unlearning task typically involves two goals: (1) The target LLM should\nforget the knowledge in the specified forget documents, and (2) it should\nretain the other knowledge that the LLM possesses, for which we assume access\nto a small number of retain documents. To achieve both goals, a mainstream\nclass of LLM unlearning methods introduces an optimization framework with a\ncombination of two objectives - maximizing the prediction loss on the forget\ndocuments while minimizing that on the retain documents, which suffers from two\nchallenges, degenerated output and catastrophic forgetting. In this paper, we\npropose a novel unlearning framework called Unlearning from Logit Difference\n(ULD), which introduces an assistant LLM that aims to achieve the opposite of\nthe unlearning goals: remembering the forget documents and forgetting the\nretain knowledge. ULD then derives the unlearned LLM by computing the logit\ndifference between the target and the assistant LLMs. We show that such\nreversed objectives would naturally resolve both aforementioned challenges\nwhile significantly improving the training efficiency. Extensive experiments\ndemonstrate that our method efficiently achieves the intended forgetting while\npreserving the LLM's overall capabilities, reducing training time by more than\nthreefold. Notably, our method loses 0% of model utility on the ToFU benchmark,\nwhereas baseline methods may sacrifice 17% of utility on average to achieve\ncomparable forget quality. Our code will be publicly available at\nhttps://github.com/UCSB-NLP-Chang/ULD.",
      "tldr_zh": "这篇论文提出了一种高效的LLM unlearning框架，名为Unlearning from Logit Difference (ULD)，旨在解决传统LLM unlearning方法在忘记指定文档知识的同时保留其他知识时面临的degenerated output和catastrophic forgetting挑战。ULD通过引入一个assistant LLM来实现反转目标——记住忘记文档并忘记保留知识，然后通过计算目标LLM和assistant LLM之间的logit difference来生成遗忘后的模型，从而自然化解这些问题并显著提高训练效率。实验结果显示，ULD减少了训练时间超过三倍，在ToFU基准测试中不损失模型效用，而基线方法平均需牺牲17%的效用才能达到类似遗忘质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08607v1",
      "published_date": "2024-06-12 19:26:35 UTC",
      "updated_date": "2024-06-12 19:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:06:03.985686"
    },
    {
      "arxiv_id": "2406.08606v2",
      "title": "A Generative Marker Enhanced End-to-End Framework for Argument Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Nilmadhab Das",
        "Vishal Choudhary",
        "V. Vijaya Saradhi",
        "Ashish Anand"
      ],
      "abstract": "Argument Mining (AM) involves identifying and extracting Argumentative\nComponents (ACs) and their corresponding Argumentative Relations (ARs). Most of\nthe prior works have broken down these tasks into multiple sub-tasks. Existing\nend-to-end setups primarily use the dependency parsing approach. This work\nintroduces a generative paradigm-based end-to-end framework argTANL. argTANL\nframes the argumentative structures into label-augmented text, called Augmented\nNatural Language (ANL). This framework jointly extracts both ACs and ARs from a\ngiven argumentative text. Additionally, this study explores the impact of\nArgumentative and Discourse markers on enhancing the model's performance within\nthe proposed framework. Two distinct frameworks, Marker-Enhanced argTANL\n(ME-argTANL) and argTANL with specialized Marker-Based Fine-Tuning, are\nproposed to achieve this. Extensive experiments are conducted on three standard\nAM benchmarks to demonstrate the superior performance of the ME-argTANL.",
      "tldr_zh": "该论文提出了一种生成式端到端框架 argTANL，用于 Argument Mining (AM)，旨在联合提取 Argumentative Components (ACs) 和 Argumentative Relations (ARs)，通过将论证结构转化为 Augmented Natural Language (ANL) 来避免传统任务分解或依赖解析方法的局限。框架进一步探索了 Argumentative 和 Discourse markers 的作用，引入了 Marker-Enhanced argTANL (ME-argTANL) 和基于标记的微调方法，以提升模型性能。在三个标准 AM 基准上的广泛实验表明，ME-argTANL 表现出色，显著优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08606v2",
      "published_date": "2024-06-12 19:22:29 UTC",
      "updated_date": "2024-09-08 12:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:06:18.684830"
    },
    {
      "arxiv_id": "2406.08603v1",
      "title": "FakeInversion: Learning to Detect Images from Unseen Text-to-Image Models by Inverting Stable Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "George Cazenavette",
        "Avneesh Sud",
        "Thomas Leung",
        "Ben Usman"
      ],
      "abstract": "Due to the high potential for abuse of GenAI systems, the task of detecting\nsynthetic images has recently become of great interest to the research\ncommunity. Unfortunately, existing image-space detectors quickly become\nobsolete as new high-fidelity text-to-image models are developed at blinding\nspeed. In this work, we propose a new synthetic image detector that uses\nfeatures obtained by inverting an open-source pre-trained Stable Diffusion\nmodel. We show that these inversion features enable our detector to generalize\nwell to unseen generators of high visual fidelity (e.g., DALL-E 3) even when\nthe detector is trained only on lower fidelity fake images generated via Stable\nDiffusion. This detector achieves new state-of-the-art across multiple training\nand evaluation setups. Moreover, we introduce a new challenging evaluation\nprotocol that uses reverse image search to mitigate stylistic and thematic\nbiases in the detector evaluation. We show that the resulting evaluation scores\nalign well with detectors' in-the-wild performance, and release these datasets\nas public benchmarks for future research.",
      "tldr_zh": "该研究提出了一种名为FakeInversion的合成图像检测方法，通过逆向开源预训练模型Stable Diffusion获取特征，从而识别来自未见文本到图像生成器（如DALL-E 3）的假图像。该方法即使仅使用Stable Diffusion生成的低保真假图像进行训练，也能泛化到高保真生成器，实现跨多个设置的新最先进性能。此外，研究引入了一个新的挑战性评估协议，使用反向图像搜索减少风格和主题偏见，并发布相关数据集作为公共基准，以提升检测器的实际应用效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://fake-inversion.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.08603v1",
      "published_date": "2024-06-12 19:14:58 UTC",
      "updated_date": "2024-06-12 19:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:06:31.102348"
    },
    {
      "arxiv_id": "2406.08598v4",
      "title": "Language Model Council: Democratically Benchmarking Foundation Models on Highly Subjective Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Zhao",
        "Flor Miriam Plaza-del-Arco",
        "Benjamin Genchel",
        "Amanda Cercas Curry"
      ],
      "abstract": "As Large Language Models (LLMs) continue to evolve, evaluating them remains a\npersistent challenge. Many recent evaluations use LLMs as judges to score\noutputs from other LLMs, often relying on a single large model like GPT-4o.\nHowever, using a single LLM judge is prone to intra-model bias, and many tasks\n- such as those related to emotional intelligence, creative writing, and\npersuasiveness - may be too subjective for a single model to judge fairly. We\nintroduce the Language Model Council (LMC), where a group of LLMs collaborate\nto create tests, respond to them, and evaluate each other's responses to\nproduce a ranking in a democratic fashion. Unlike previous approaches that\nfocus on reducing cost or bias by using a panel of smaller models, our work\nexamines the benefits and nuances of a fully inclusive LLM evaluation system.\nIn a detailed case study on emotional intelligence, we deploy a council of 20\nrecent LLMs to rank each other on open-ended responses to interpersonal\nconflicts. Our results show that the LMC produces rankings that are more\nseparable and more robust, and through a user study, we show that they are more\nconsistent with human evaluations than any individual LLM judge. Using all LLMs\nfor judging can be costly, however, so we use Monte Carlo simulations and\nhand-curated sub-councils to study hypothetical council compositions and\ndiscuss the value of the incremental LLM judge.",
      "tldr_zh": "本研究提出 Language Model Council (LMC)，一种由多个 Large Language Models (LLMs) 组成的民主评估框架，用于基准测试高度主观任务，如情感智能和创意写作，以解决单一 LLM 评判（如 GPT-4o）易导致偏见的问题。LMC 让 LLMs 合作创建测试、生成响应并相互评估，从而产生更公平的排名；在情感智能案例中，使用 20 个 LLMs 对人际冲突响应进行排名，结果显示 LMC 的排名更具可分离性和稳健性，并与人类评估更一致。研究还通过 Monte Carlo simulations 和子委员会分析探讨了成本效益，强调增加评判者对提升评估价值的潜在益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08598v4",
      "published_date": "2024-06-12 19:05:43 UTC",
      "updated_date": "2025-03-19 04:25:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:06:44.107589"
    },
    {
      "arxiv_id": "2406.09455v1",
      "title": "Pandora: Towards General World Model with Natural Language Actions and Video States",
      "title_zh": "翻译失败",
      "authors": [
        "Jiannan Xiang",
        "Guangyi Liu",
        "Yi Gu",
        "Qiyue Gao",
        "Yuting Ning",
        "Yuheng Zha",
        "Zeyu Feng",
        "Tianhua Tao",
        "Shibo Hao",
        "Yemin Shi",
        "Zhengzhong Liu",
        "Eric P. Xing",
        "Zhiting Hu"
      ],
      "abstract": "World models simulate future states of the world in response to different\nactions. They facilitate interactive content creation and provides a foundation\nfor grounded, long-horizon reasoning. Current foundation models do not fully\nmeet the capabilities of general world models: large language models (LLMs) are\nconstrained by their reliance on language modality and their limited\nunderstanding of the physical world, while video models lack interactive action\ncontrol over the world simulations. This paper makes a step towards building a\ngeneral world model by introducing Pandora, a hybrid autoregressive-diffusion\nmodel that simulates world states by generating videos and allows real-time\ncontrol with free-text actions. Pandora achieves domain generality, video\nconsistency, and controllability through large-scale pretraining and\ninstruction tuning. Crucially, Pandora bypasses the cost of\ntraining-from-scratch by integrating a pretrained LLM (7B) and a pretrained\nvideo model, requiring only additional lightweight finetuning. We illustrate\nextensive outputs by Pandora across diverse domains (indoor/outdoor,\nnatural/urban, human/robot, 2D/3D, etc.). The results indicate great potential\nof building stronger general world models with larger-scale training.",
      "tldr_zh": "该论文提出 Pandora，一种通用世界模型（world models），旨在通过生成视频和使用自然语言动作实现对世界状态的模拟和实时控制，以解决大型语言模型（LLMs）依赖语言模态以及视频模型缺乏交互控制的局限。Pandora 采用混合自回归-扩散模型，整合预训练的 LLM（7B）和视频模型，仅需轻量级微调和大规模预训练，即可实现领域通用性、视频一致性和可控性。实验结果显示，Pandora 在多样领域（如室内/户外、自然/城市、人/机器人、2D/3D）表现出色，展示了构建更强大世界模型的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Website: https://world-model.maitrix.org/",
      "pdf_url": "http://arxiv.org/pdf/2406.09455v1",
      "published_date": "2024-06-12 18:55:51 UTC",
      "updated_date": "2024-06-12 18:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:06:56.623867"
    },
    {
      "arxiv_id": "2406.08587v2",
      "title": "CS-Bench: A Comprehensive Benchmark for Large Language Models towards Computer Science Mastery",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshuai Song",
        "Muxi Diao",
        "Guanting Dong",
        "Zhengyang Wang",
        "Yujia Fu",
        "Runqi Qiao",
        "Zhexu Wang",
        "Dayuan Fu",
        "Huangxuan Wu",
        "Bin Liang",
        "Weihao Zeng",
        "Yejie Wang",
        "Zhuoma GongQue",
        "Jianing Yu",
        "Qiuna Tan",
        "Weiran Xu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant potential in\nadvancing various fields of research and society. However, the current\ncommunity of LLMs overly focuses on benchmarks for analyzing specific\nfoundational skills (e.g. mathematics and code generation), neglecting an\nall-round evaluation of the computer science field. To bridge this gap, we\nintroduce CS-Bench, the first multilingual (English, Chinese, French, German)\nbenchmark dedicated to evaluating the performance of LLMs in computer science.\nCS-Bench comprises approximately 10K meticulously curated test samples,\ncovering 26 subfields across 4 key areas of computer science, encompassing\nvarious task forms and divisions of knowledge and reasoning. Utilizing\nCS-Bench, we conduct a comprehensive evaluation of over 30 mainstream LLMs,\nrevealing the relationship between CS performance and model scales. We also\nquantitatively analyze the reasons for failures in existing LLMs and highlight\ndirections for improvements, including knowledge supplementation and\nCS-specific reasoning. Further cross-capability experiments show a high\ncorrelation between LLMs' capabilities in computer science and their abilities\nin mathematics and coding. Moreover, expert LLMs specialized in mathematics and\ncoding also demonstrate strong performances in several CS subfields. Looking\nahead, we envision CS-Bench serving as a cornerstone for LLM applications in\nthe CS field and paving new avenues in assessing LLMs' diverse reasoning\ncapabilities. The CS-Bench data and evaluation code are available at\nhttps://github.com/csbench/csbench.",
      "tldr_zh": "该论文引入了 CS-Bench，这是一个全面的多语言基准，用于评估大型语言模型（LLMs）在计算机科学领域的性能，填补了现有基准对 CS 全方位评估的空白。CS-Bench 包含约 10K 个精心策划的测试样本，覆盖 26 个子领域和 4 个关键领域，支持英语、中文、法语和德语等多种任务形式。研究对 30 多个主流 LLMs 进行了全面评估，发现 CS 性能与模型规模相关，且失败原因主要包括知识不足和 CS-specific 推理问题。实验还显示，LLMs 在计算机科学的表现与数学和编码能力高度相关，数学及编码专家模型在多个 CS 子领域表现出色，为未来 LLMs 改进和应用提供新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.08587v2",
      "published_date": "2024-06-12 18:47:28 UTC",
      "updated_date": "2025-02-28 15:16:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:07:08.838737"
    },
    {
      "arxiv_id": "2406.09454v1",
      "title": "Advancing High Resolution Vision-Language Models in Biomedicine",
      "title_zh": "翻译失败",
      "authors": [
        "Zekai Chen",
        "Arda Pekis",
        "Kevin Brown"
      ],
      "abstract": "Multi-modal learning has significantly advanced generative AI, especially in\nvision-language modeling. Innovations like GPT-4V and open-source projects such\nas LLaVA have enabled robust conversational agents capable of zero-shot task\ncompletions. However, applying these technologies in the biomedical field\npresents unique challenges. Recent initiatives like LLaVA-Med have started to\nadapt instruction-tuning for biomedical contexts using large datasets such as\nPMC-15M. Our research offers three key contributions: (i) we present a new\ninstruct dataset enriched with medical image-text pairs from Claude3-Opus and\nLLaMA3 70B, (ii) we propose a novel image encoding strategy using hierarchical\nrepresentations to improve fine-grained biomedical visual comprehension, and\n(iii) we develop the Llama3-Med model, which achieves state-of-the-art\nzero-shot performance on biomedical visual question answering benchmarks, with\nan average performance improvement of over 10% compared to previous methods.\nThese advancements provide more accurate and reliable tools for medical\nprofessionals, bridging gaps in current multi-modal conversational assistants\nand promoting further innovations in medical AI.",
      "tldr_zh": "本研究旨在提升生物医学领域的视觉语言模型(Vision-Language Models)，通过解决现有技术的适应挑战，如GPT-4V和LLaVA在医疗语境中的局限性。研究的主要贡献包括：(i) 构建一个新的指令数据集，使用Claude3-Opus和LLaMA3 70B增强的医疗图像-文本对，(ii) 提出一种基于分层表示的图像编码策略，以改善细粒度生物医学视觉理解。最终，开发的Llama3-Med模型在生物医学视觉问答基准上实现了最先进的零样本性能，平均性能提升超过10%，为医疗专业人士提供更准确可靠的工具，促进医疗AI创新。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.09454v1",
      "published_date": "2024-06-12 18:29:26 UTC",
      "updated_date": "2024-06-12 18:29:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:07:19.611234"
    },
    {
      "arxiv_id": "2406.08575v1",
      "title": "Using Quality Attribute Scenarios for ML Model Test Case Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Rachel Brower-Sinning",
        "Grace A. Lewis",
        "Sebastían Echeverría",
        "Ipek Ozkaya"
      ],
      "abstract": "Testing of machine learning (ML) models is a known challenge identified by\nresearchers and practitioners alike. Unfortunately, current practice for ML\nmodel testing prioritizes testing for model performance, while often neglecting\nthe requirements and constraints of the ML-enabled system that integrates the\nmodel. This limited view of testing leads to failures during integration,\ndeployment, and operations, contributing to the difficulties of moving models\nfrom development to production. This paper presents an approach based on\nquality attribute (QA) scenarios to elicit and define system- and\nmodel-relevant test cases for ML models. The QA-based approach described in\nthis paper has been integrated into MLTE, a process and tool to support ML\nmodel test and evaluation. Feedback from users of MLTE highlights its\neffectiveness in testing beyond model performance and identifying failures\nearly in the development process.",
      "tldr_zh": "该论文指出，ML 模型测试目前过度关注模型性能，而忽略了整合模型的系统要求和约束，导致集成、部署和操作阶段出现故障。作者提出一种基于 quality attribute scenarios 的方法，用于获取和定义与系统和模型相关的测试用例，以提升测试的全面性。该方法已整合到 MLTE 过程和工具中，用户反馈显示其在测试超出性能范围的内容方面有效，并能及早识别开发过程中的故障。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Paper accepted and presented in SAML 2024, the 3rd International\n  Workshop on Software Architecture and Machine Learning, co-located with ICSA\n  2024, the 21st IEEE International Conference on Software Architecture",
      "pdf_url": "http://arxiv.org/pdf/2406.08575v1",
      "published_date": "2024-06-12 18:26:42 UTC",
      "updated_date": "2024-06-12 18:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:07:30.645261"
    },
    {
      "arxiv_id": "2406.08570v1",
      "title": "HDNet: Physics-Inspired Neural Network for Flow Estimation based on Helmholtz Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Qi",
        "Ramzi Idoughi",
        "Wolfgang Heidrich"
      ],
      "abstract": "Flow estimation problems are ubiquitous in scientific imaging. Often, the\nunderlying flows are subject to physical constraints that can be exploited in\nthe flow estimation; for example, incompressible (divergence-free) flows are\nexpected for many fluid experiments, while irrotational (curl-free) flows arise\nin the analysis of optical distortions and wavefront sensing. In this work, we\npropose a Physics- Inspired Neural Network (PINN) named HDNet, which performs a\nHelmholtz decomposition of an arbitrary flow field, i.e., it decomposes the\ninput flow into a divergence-only and a curl-only component. HDNet can be\ntrained exclusively on synthetic data generated by reverse Helmholtz\ndecomposition, which we call Helmholtz synthesis. As a PINN, HDNet is fully\ndifferentiable and can easily be integrated into arbitrary flow estimation\nproblems.",
      "tldr_zh": "本研究针对科学成像中的流估计问题，提出了一种基于Helmholtz Decomposition的Physics-Inspired Neural Network（PINN），名为HDNet，用于将任意流场分解为divergence-only和curl-only组件，从而利用物理约束如divergence-free或curl-free特性。HDNet通过Helmholtz synthesis生成合成训练数据，实现高效训练，且作为fully differentiable模型，便于整合到各种流估计任务中。该方法显著提升了流场的准确分解和分析能力，尤其适用于流体实验和光学畸变分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08570v1",
      "published_date": "2024-06-12 18:11:32 UTC",
      "updated_date": "2024-06-12 18:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:07:41.757060"
    },
    {
      "arxiv_id": "2406.08564v2",
      "title": "Machine Learning-Driven Open-Source Framework for Assessing QoE in Multimedia Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Parsa Hassani Shariat Panahi",
        "Amir Hossein Jalilvand",
        "Abolfazl Diyanat"
      ],
      "abstract": "The Internet is integral to modern life, influencing communication, business,\nand lifestyles globally. As dependence on Internet services grows, the demand\nfor high-quality service delivery increases. Service providers must maintain\nhigh standards of quality of service and quality of experience (QoE) to ensure\nuser satisfaction. QoE, which reflects user satisfaction with service quality,\nis a key metric for multimedia services, yet it is challenging to measure due\nto its subjective nature and the complexities of real-time feedback. This paper\nintroduces a machine learning-based framework for objectively assessing QoE in\nmultimedia networks. The open-source framework complies with the ITU-T P.1203\nstandard. It automates data collection and user satisfaction prediction using\nkey network parameters such as delay, jitter, packet loss, bitrate, and\nthroughput. Using a dataset of over 20,000 records from various network\nconditions, the Random Forest model predicts the mean opinion score with 95.8%\naccuracy. Our framework addresses the limitations of existing QoE models by\nintegrating real-time data collection, machine learning predictions, and\nadherence to international standards. This approach enhances QoE evaluation\naccuracy and allows dynamic network resource management, optimizing performance\nand cost-efficiency. Its open-source nature encourages adaptation and extension\nfor various multimedia services. The findings significantly affect the\ntelecommunications industry in managing and optimizing multimedia services. The\nnetwork centric QoE prediction of the framework offers a scalable solution to\nimprove user satisfaction without the need for content-specific data. Future\nenhancements could include advanced machine learning models and broader\napplicability to digital services. This research contributes a practical,\nstandardized tool for QoE assessment across diverse networks and platforms.",
      "tldr_zh": "这篇论文提出一个基于机器学习的开源框架，用于客观评估多媒体网络中的 QoE（Quality of Experience），以应对其主观性和测量复杂性。框架遵守 ITU-T P.1203 标准，通过自动收集网络参数（如延迟、抖动、丢包率、比特率和吞吐量）并运用 Random Forest 模型进行用户满意度预测。实验结果显示，使用超过 20,000 条记录的数据集，该模型对 Mean Opinion Score 的预测准确率达 95.8%。该框架通过整合实时数据收集和国际标准，提升了 QoE 评估的准确性，支持动态网络资源管理，并为电信行业提供可扩展的优化工具。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.NI",
      "comment": "11 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08564v2",
      "published_date": "2024-06-12 18:07:06 UTC",
      "updated_date": "2024-09-10 07:30:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:07:56.022936"
    },
    {
      "arxiv_id": "2406.08545v1",
      "title": "RVT-2: Learning Precise Manipulation from Few Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Ankit Goyal",
        "Valts Blukis",
        "Jie Xu",
        "Yijie Guo",
        "Yu-Wei Chao",
        "Dieter Fox"
      ],
      "abstract": "In this work, we study how to build a robotic system that can solve multiple\n3D manipulation tasks given language instructions. To be useful in industrial\nand household domains, such a system should be capable of learning new tasks\nwith few demonstrations and solving them precisely. Prior works, like PerAct\nand RVT, have studied this problem, however, they often struggle with tasks\nrequiring high precision. We study how to make them more effective, precise,\nand fast. Using a combination of architectural and system-level improvements,\nwe propose RVT-2, a multitask 3D manipulation model that is 6X faster in\ntraining and 2X faster in inference than its predecessor RVT. RVT-2 achieves a\nnew state-of-the-art on RLBench, improving the success rate from 65% to 82%.\nRVT-2 is also effective in the real world, where it can learn tasks requiring\nhigh precision, like picking up and inserting plugs, with just 10\ndemonstrations. Visual results, code, and trained model are provided at:\nhttps://robotic-view-transformer-2.github.io/.",
      "tldr_zh": "本研究提出RVT-2，一种多任务3D操作模型，旨在通过少量演示学习高精度的机器人操作任务，如响应语言指令进行工业或家庭应用。相比前驱模型RVT，RVT-2通过架构和系统级优化，使训练速度提高6倍、推理速度提高2倍，同时提升了在高精度任务上的表现。实验结果显示，在RLBench基准上，成功率从65%提升至82%；在真实世界环境中，仅需10个演示即可学会复杂任务，如插入插头。该模型的代码和训练结果已在指定网站公开，提供可复制的研究基础。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to RSS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08545v1",
      "published_date": "2024-06-12 18:00:01 UTC",
      "updated_date": "2024-06-12 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:08:05.970171"
    },
    {
      "arxiv_id": "2406.08488v1",
      "title": "ICE-G: Image Conditional Editing of 3D Gaussian Splats",
      "title_zh": "ICE-G：图像条件编辑的3D高斯喷溅",
      "authors": [
        "Vishnu Jaganathan",
        "Hannah Hanyun Huang",
        "Muhammad Zubair Irshad",
        "Varun Jampani",
        "Amit Raj",
        "Zsolt Kira"
      ],
      "abstract": "Recently many techniques have emerged to create high quality 3D assets and\nscenes. When it comes to editing of these objects, however, existing approaches\nare either slow, compromise on quality, or do not provide enough customization.\nWe introduce a novel approach to quickly edit a 3D model from a single\nreference view. Our technique first segments the edit image, and then matches\nsemantically corresponding regions across chosen segmented dataset views using\nDINO features. A color or texture change from a particular region of the edit\nimage can then be applied to other views automatically in a semantically\nsensible manner. These edited views act as an updated dataset to further train\nand re-style the 3D scene. The end-result is therefore an edited 3D model. Our\nframework enables a wide variety of editing tasks such as manual local edits,\ncorrespondence based style transfer from any example image, and a combination\nof different styles from multiple example images. We use Gaussian Splats as our\nprimary 3D representation due to their speed and ease of local editing, but our\ntechnique works for other methods such as NeRFs as well. We show through\nmultiple examples that our method produces higher quality results while\noffering fine-grained control of editing. Project page: ice-gaussian.github.io",
      "tldr_zh": "本研究提出 ICE-G 方法，用于从单个参考视图快速编辑 3D Gaussian Splats 模型，解决现有技术在速度、质量和自定义方面的不足。该方法首先对编辑图像进行分割，然后利用 DINO 特征匹配语义对应的区域，实现颜色或纹理变化的自动传播，并使用编辑后的视图更新数据集进一步训练 3D 场景。ICE-G 支持多种编辑任务，如手动局部编辑、基于对应关系的风格转移，以及从多个图像组合不同风格，并证明其在质量和细粒度控制上优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR AI4CC Workshop 2024. Project page:\n  https://ice-gaussian.github.io",
      "pdf_url": "http://arxiv.org/pdf/2406.08488v1",
      "published_date": "2024-06-12 17:59:52 UTC",
      "updated_date": "2024-06-12 17:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:08:20.278906"
    },
    {
      "arxiv_id": "2406.08476v2",
      "title": "RMem: Restricted Memory Banks Improve Video Object Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Junbao Zhou",
        "Ziqi Pang",
        "Yu-Xiong Wang"
      ],
      "abstract": "With recent video object segmentation (VOS) benchmarks evolving to\nchallenging scenarios, we revisit a simple but overlooked strategy: restricting\nthe size of memory banks. This diverges from the prevalent practice of\nexpanding memory banks to accommodate extensive historical information. Our\nspecially designed \"memory deciphering\" study offers a pivotal insight\nunderpinning such a strategy: expanding memory banks, while seemingly\nbeneficial, actually increases the difficulty for VOS modules to decode\nrelevant features due to the confusion from redundant information. By\nrestricting memory banks to a limited number of essential frames, we achieve a\nnotable improvement in VOS accuracy. This process balances the importance and\nfreshness of frames to maintain an informative memory bank within a bounded\ncapacity. Additionally, restricted memory banks reduce the training-inference\ndiscrepancy in memory lengths compared with continuous expansion. This fosters\nnew opportunities in temporal reasoning and enables us to introduce the\npreviously overlooked \"temporal positional embedding.\" Finally, our insights\nare embodied in \"RMem\" (\"R\" for restricted), a simple yet effective VOS\nmodification that excels at challenging VOS scenarios and establishes new state\nof the art for object state changes (on the VOST dataset) and long videos (on\nthe Long Videos dataset). Our code and demo are available at\nhttps://restricted-memory.github.io/.",
      "tldr_zh": "该论文重新审视了视频对象分割（VOS）中的内存银行策略，提出通过限制内存银行大小来避免冗余信息带来的解码困难，而不是传统上扩展内存银行存储更多历史信息。研究通过“memory deciphering”分析发现，这种限制能平衡帧的重要性与新鲜度，从而显著提高VOS准确性，并减少训练和推理中内存长度的差异。论文引入了“temporal positional embedding”以增强时间推理，并开发了RMem框架（“R”代表restricted），在VOST数据集的对象状态变化和Long Videos数据集的长视频上建立了新的state of the art水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2024, Project Page: https://restricted-memory.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.08476v2",
      "published_date": "2024-06-12 17:59:04 UTC",
      "updated_date": "2025-01-14 17:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:08:34.522033"
    },
    {
      "arxiv_id": "2406.08474v2",
      "title": "Real2Code: Reconstruct Articulated Objects via Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Mandi",
        "Yijia Weng",
        "Dominik Bauer",
        "Shuran Song"
      ],
      "abstract": "We present Real2Code, a novel approach to reconstructing articulated objects\nvia code generation. Given visual observations of an object, we first\nreconstruct its part geometry using an image segmentation model and a shape\ncompletion model. We then represent the object parts with oriented bounding\nboxes, which are input to a fine-tuned large language model (LLM) to predict\njoint articulation as code. By leveraging pre-trained vision and language\nmodels, our approach scales elegantly with the number of articulated parts, and\ngeneralizes from synthetic training data to real world objects in unstructured\nenvironments. Experimental results demonstrate that Real2Code significantly\noutperforms previous state-of-the-art in reconstruction accuracy, and is the\nfirst approach to extrapolate beyond objects' structural complexity in the\ntraining set, and reconstructs objects with up to 10 articulated parts. When\nincorporated with a stereo reconstruction model, Real2Code also generalizes to\nreal world objects from a handful of multi-view RGB images, without the need\nfor depth or camera information.",
      "tldr_zh": "该研究提出 Real2Code 方法，通过代码生成重建 articulated objects。首先，从视觉观察使用图像分割模型和形状完成模型重建物体部分几何，然后用定向边界框表示这些部分，并输入微调的大型语言模型 (LLM) 来预测关节铰接。该方法利用预训练的视觉和语言模型，具有良好的可扩展性和泛化能力，能从合成训练数据扩展到真实世界物体。实验结果显示，Real2Code 在重建准确性上显著优于现有最先进方法，能处理多达 10 个铰接部分的复杂物体，并从少量多视图 RGB 图像中实现重建，而无需深度或相机信息。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08474v2",
      "published_date": "2024-06-12 17:57:06 UTC",
      "updated_date": "2024-06-13 17:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:08:56.181566"
    },
    {
      "arxiv_id": "2406.08472v4",
      "title": "RILe: Reinforced Imitation Learning",
      "title_zh": "RILe：强化模仿学习",
      "authors": [
        "Mert Albaba",
        "Sammy Christen",
        "Thomas Langarek",
        "Christoph Gebhardt",
        "Otmar Hilliges",
        "Michael J. Black"
      ],
      "abstract": "Acquiring complex behaviors is essential for artificially intelligent agents,\nyet learning these behaviors in high-dimensional settings poses a significant\nchallenge due to the vast search space. Traditional reinforcement learning (RL)\nrequires extensive manual effort for reward function engineering. Inverse\nreinforcement learning (IRL) uncovers reward functions from expert\ndemonstrations but relies on an iterative process that is often computationally\nexpensive. Imitation learning (IL) provides a more efficient alternative by\ndirectly comparing an agent's actions to expert demonstrations; however, in\nhigh-dimensional environments, such direct comparisons often offer insufficient\nfeedback for effective learning. We introduce RILe (Reinforced Imitation\nLearning), a framework that combines the strengths of imitation learning and\ninverse reinforcement learning to learn a dense reward function efficiently and\nachieve strong performance in high-dimensional tasks. RILe employs a novel\ntrainer-student framework: the trainer learns an adaptive reward function, and\nthe student uses this reward signal to imitate expert behaviors. By dynamically\nadjusting its guidance as the student evolves, the trainer provides nuanced\nfeedback across different phases of learning. Our framework produces\nhigh-performing policies in high-dimensional tasks where direct imitation fails\nto replicate complex behaviors. We validate RILe in challenging robotic\nlocomotion tasks, demonstrating that it significantly outperforms existing\nmethods and achieves near-expert performance across multiple settings.",
      "tldr_zh": "该论文提出RILe（Reinforced Imitation Learning）框架，旨在解决高维环境中学习复杂行为的挑战，通过结合Imitation Learning和Inverse Reinforcement Learning的优势，高效学习密集奖励函数。RILe采用trainer-student结构，其中trainer动态学习自适应奖励函数，student则利用此奖励信号模仿专家行为，提供更细致的反馈指导。实验结果显示，RILe在机器人运动任务中显著优于现有方法，实现了接近专家的性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08472v4",
      "published_date": "2024-06-12 17:56:31 UTC",
      "updated_date": "2025-04-21 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:08:56.506021"
    },
    {
      "arxiv_id": "2406.08471v1",
      "title": "Surprise! Using Physiological Stress for Allostatic Regulation Under the Active Inference Framework [Pre-Print]",
      "title_zh": "翻译失败",
      "authors": [
        "Imran Khan",
        "Robert Lowe"
      ],
      "abstract": "Allostasis proposes that long-term viability of a living system is achieved\nthrough anticipatory adjustments of its physiology and behaviour: emphasising\nphysiological and affective stress as an adaptive state of adaptation that\nminimizes long-term prediction errors. More recently, the active inference\nframework (AIF) has also sought to explain action and long-term adaptation\nthrough the minimization of future errors (free energy), through the learning\nof statistical contingencies of the world, offering a formalism for allostatic\nregulation. We suggest that framing prediction errors through the lens of\nbiological hormonal dynamics proposed by allostasis offers a way to integrate\nthese two models together in a biologically-plausible manner. In this paper, we\ndescribe our initial work in developing a model that grounds prediction errors\n(surprisal) into the secretion of a physiological stress hormone (cortisol)\nacting as an adaptive, allostatic mediator on a homeostatically-controlled\nphysiology. We evaluate this using a computational model in simulations using\nan active inference agent endowed with an artificial physiology, regulated\nthrough homeostatic and allostatic control in a stochastic environment. Our\nresults find that allostatic functions of cortisol (stress), secreted as a\nfunction of prediction errors, provide adaptive advantages to the agent's\nlong-term physiological regulation. We argue that the coupling of\ninformation-theoretic prediction errors to low-level, biological hormonal\ndynamics of stress can provide a computationally efficient model to long-term\nregulation for embodied intelligent systems.",
      "tldr_zh": "本论文探讨了 Allostasis 和 Active Inference Framework (AIF) 的整合，提出通过预测错误（surprisal）触发生理应激激素（如皮质醇）分泌，作为一种适应性调节机制，以最小化长期预测错误并提升系统生存能力。研究采用计算模型模拟一个配备人工生理的 Active Inference 代理，在随机环境中测试 homeostatic 和 allostatic 控制。结果表明，基于 surprisal 的皮质醇应激功能显著提高了代理的长期生理调节适应性，并为具身智能系统的计算高效调控提供了新框架。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08471v1",
      "published_date": "2024-06-12 17:56:15 UTC",
      "updated_date": "2024-06-12 17:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:09:08.758918"
    },
    {
      "arxiv_id": "2406.08467v1",
      "title": "DafnyBench: A Benchmark for Formal Software Verification",
      "title_zh": "DafnyBench：形式化软件验证的基准",
      "authors": [
        "Chloe Loughridge",
        "Qinyi Sun",
        "Seth Ahrenbach",
        "Federico Cassano",
        "Chuyue Sun",
        "Ying Sheng",
        "Anish Mudide",
        "Md Rakib Hossain Misu",
        "Nada Amin",
        "Max Tegmark"
      ],
      "abstract": "We introduce DafnyBench, the largest benchmark of its kind for training and\nevaluating machine learning systems for formal software verification. We test\nthe ability of LLMs such as GPT-4 and Claude 3 to auto-generate enough hints\nfor the Dafny formal verification engine to successfully verify over 750\nprograms with about 53,000 lines of code. The best model and prompting scheme\nachieved 68% success rate, and we quantify how this rate improves when retrying\nwith error message feedback and how it deteriorates with the amount of required\ncode and hints. We hope that DafnyBench will enable rapid improvements from\nthis baseline as LLMs and verification techniques grow in quality.",
      "tldr_zh": "本研究引入了DafnyBench，这是一个规模最大的基准，用于训练和评估机器学习系统在形式软件验证领域的性能。研究测试了LLM（如GPT-4和Claude 3）自动生成提示，以辅助Dafny形式验证引擎成功验证超过750个程序，总计约53,000行代码，其中最佳模型和提示方案达到了68%的成功率。实验还量化了通过错误消息反馈重试时成功率的提升，以及随着所需代码和提示量增加时成功率的下降。该基准有望推动LLM和验证技术的快速改进。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "Code & dataset available at: https://github.com/sun-wendy/DafnyBench",
      "pdf_url": "http://arxiv.org/pdf/2406.08467v1",
      "published_date": "2024-06-12 17:53:31 UTC",
      "updated_date": "2024-06-12 17:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:09:22.898509"
    },
    {
      "arxiv_id": "2406.08466v2",
      "title": "Scaling Laws in Linear Regression: Compute, Parameters, and Data",
      "title_zh": "线性回归中的缩放定律：计算、参数和数据",
      "authors": [
        "Licong Lin",
        "Jingfeng Wu",
        "Sham M. Kakade",
        "Peter L. Bartlett",
        "Jason D. Lee"
      ],
      "abstract": "Empirically, large-scale deep learning models often satisfy a neural scaling\nlaw: the test error of the trained model improves polynomially as the model\nsize and data size grow. However, conventional wisdom suggests the test error\nconsists of approximation, bias, and variance errors, where the variance error\nincreases with model size. This disagrees with the general form of neural\nscaling laws, which predict that increasing model size monotonically improves\nperformance.\n  We study the theory of scaling laws in an infinite dimensional linear\nregression setup. Specifically, we consider a model with $M$ parameters as a\nlinear function of sketched covariates. The model is trained by one-pass\nstochastic gradient descent (SGD) using $N$ data. Assuming the optimal\nparameter satisfies a Gaussian prior and the data covariance matrix has a\npower-law spectrum of degree $a>1$, we show that the reducible part of the test\nerror is $\\Theta(M^{-(a-1)} + N^{-(a-1)/a})$. The variance error, which\nincreases with $M$, is dominated by the other errors due to the implicit\nregularization of SGD, thus disappearing from the bound. Our theory is\nconsistent with the empirical neural scaling laws and verified by numerical\nsimulation.",
      "tldr_zh": "本研究探讨了线性回归中的缩放定律，旨在解释模型大小（M）、数据规模（N）和计算资源如何影响测试误差，挑战传统观点中方差误差随模型大小增加的假设。作者采用无限维线性回归设置，使用一趟随机梯度下降（SGD）训练模型，假设最优参数服从高斯先验（Gaussian prior），并考虑数据协方差矩阵具有幂律谱（power-law spectrum of degree a > 1）。结果显示，测试误差的还原部分为 Θ(M^{-(a-1)} + N^{-(a-1)/a})，其中方差误差因 SGD 的隐式正则化而被主导，从而支持经验神经缩放定律（neural scaling laws），并通过数值模拟得到验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08466v2",
      "published_date": "2024-06-12 17:53:29 UTC",
      "updated_date": "2024-10-29 18:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:09:34.469161"
    },
    {
      "arxiv_id": "2406.08464v2",
      "title": "Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchen Xu",
        "Fengqing Jiang",
        "Luyao Niu",
        "Yuntian Deng",
        "Radha Poovendran",
        "Yejin Choi",
        "Bill Yuchen Lin"
      ],
      "abstract": "High-quality instruction data is critical for aligning large language models\n(LLMs). Although some models, such as Llama-3-Instruct, have open weights,\ntheir alignment data remain private, which hinders the democratization of AI.\nHigh human labor costs and a limited, predefined scope for prompting prevent\nexisting open-source data creation methods from scaling effectively,\npotentially limiting the diversity and quality of public alignment datasets. Is\nit possible to synthesize high-quality instruction data at scale by extracting\nit directly from an aligned LLM? We present a self-synthesis method for\ngenerating large-scale alignment data named Magpie. Our key observation is that\naligned LLMs like Llama-3-Instruct can generate a user query when we input only\nthe left-side templates up to the position reserved for user messages, thanks\nto their auto-regressive nature. We use this method to prompt Llama-3-Instruct\nand generate 4 million instructions along with their corresponding responses.\nWe perform a comprehensive analysis of the extracted data and select 300K\nhigh-quality instances. To compare Magpie data with other public instruction\ndatasets, we fine-tune Llama-3-8B-Base with each dataset and evaluate the\nperformance of the fine-tuned models. Our results indicate that in some tasks,\nmodels fine-tuned with Magpie perform comparably to the official\nLlama-3-8B-Instruct, despite the latter being enhanced with 10 million data\npoints through supervised fine-tuning (SFT) and subsequent feedback learning.\nWe also show that using Magpie solely for SFT can surpass the performance of\nprevious public datasets utilized for both SFT and preference optimization,\nsuch as direct preference optimization with UltraFeedback. This advantage is\nevident on alignment benchmarks such as AlpacaEval, ArenaHard, and WildBench.",
      "tldr_zh": "论文提出 Magpie 方法，通过仅提示已对齐的 LLM（如 Llama-3-Instruct）左侧模板，利用其自回归特性，从零开始合成大规模的对齐数据，成功生成了 4 百万指令并筛选出 30 万高质量实例。相比现有方法，Magpie 克服了人力成本和数据多样性限制，为高效生成高质量指令数据提供了可扩展方案。实验显示，使用 Magpie 数据进行 SFT 微调的 Llama-3-8B-Base 模型，在 AlpacaEval、ArenaHard 和 WildBench 等基准上，表现可与官方 Llama-3-8B-Instruct 媲美，甚至在某些任务上超越了使用 UltraFeedback 等数据集优化的模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Link: https://magpie-align.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.08464v2",
      "published_date": "2024-06-12 17:52:30 UTC",
      "updated_date": "2024-10-07 01:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:09:45.586755"
    },
    {
      "arxiv_id": "2406.12908v1",
      "title": "Rating Multi-Modal Time-Series Forecasting Models (MM-TSFM) for Robustness Through a Causal Lens",
      "title_zh": "翻译失败",
      "authors": [
        "Kausik Lakkaraju",
        "Rachneet Kaur",
        "Zhen Zeng",
        "Parisa Zehtabi",
        "Sunandita Patra",
        "Biplav Srivastava",
        "Marco Valtorta"
      ],
      "abstract": "AI systems are notorious for their fragility; minor input changes can\npotentially cause major output swings. When such systems are deployed in\ncritical areas like finance, the consequences of their uncertain behavior could\nbe severe. In this paper, we focus on multi-modal time-series forecasting,\nwhere imprecision due to noisy or incorrect data can lead to erroneous\npredictions, impacting stakeholders such as analysts, investors, and traders.\nRecently, it has been shown that beyond numeric data, graphical transformations\ncan be used with advanced visual models to achieve better performance. In this\ncontext, we introduce a rating methodology to assess the robustness of\nMulti-Modal Time-Series Forecasting Models (MM-TSFM) through causal analysis,\nwhich helps us understand and quantify the isolated impact of various\nattributes on the forecasting accuracy of MM-TSFM. We apply our novel rating\nmethod on a variety of numeric and multi-modal forecasting models in a large\nexperimental setup (six input settings of control and perturbations, ten data\ndistributions, time series from six leading stocks in three industries over a\nyear of data, and five time-series forecasters) to draw insights on robust\nforecasting models and the context of their strengths. Within the scope of our\nstudy, our main result is that multi-modal (numeric + visual) forecasting,\nwhich was found to be more accurate than numeric forecasting in previous\nstudies, can also be more robust in diverse settings. Our work will help\ndifferent stakeholders of time-series forecasting understand the models`\nbehaviors along trust (robustness) and accuracy dimensions to select an\nappropriate model for forecasting using our rating method, leading to improved\ndecision-making.",
      "tldr_zh": "本文提出了一种通过因果分析评估多模态时间序列预测模型(MM-TSFM)的评分方法，以量化各种属性对预测准确性的影响，并解决AI系统在金融等领域因输入变化导致的不稳定性问题。该方法在大规模实验中（包括六种输入设置、十种数据分布、三大行业六家领先股票的一年时间序列数据，以及五种预测模型）进行了测试。研究发现，多模态（数字+视觉）预测模型不仅比纯数字模型更准确，还在多样化场景下表现出更高的鲁棒性。该工作有助于时间序列预测的利益相关者（如分析师和投资者）理解模型的鲁棒性和准确性，从而选择合适模型并提升决策质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.12908v1",
      "published_date": "2024-06-12 17:39:16 UTC",
      "updated_date": "2024-06-12 17:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:09:56.622894"
    },
    {
      "arxiv_id": "2406.08447v1",
      "title": "The Impact of Initialization on LoRA Finetuning Dynamics",
      "title_zh": "初始化对 LoRA 微调动态的影响",
      "authors": [
        "Soufiane Hayou",
        "Nikhil Ghosh",
        "Bin Yu"
      ],
      "abstract": "In this paper, we study the role of initialization in Low Rank Adaptation\n(LoRA) as originally introduced in Hu et al. (2021). Essentially, to start from\nthe pretrained model as initialization for finetuning, one can either\ninitialize B to zero and A to random (default initialization in PEFT package),\nor vice-versa. In both cases, the product BA is equal to zero at\ninitialization, which makes finetuning starts from the pretrained model. These\ntwo initialization schemes are seemingly similar. They should in-principle\nyield the same performance and share the same optimal learning rate. We\ndemonstrate that this is an incorrect intuition and that the first scheme\n(initializing B to zero and A to random) on average yields better performance\ncompared to the other scheme. Our theoretical analysis shows that the reason\nbehind this might be that the first initialization allows the use of larger\nlearning rates (without causing output instability) compared to the second\ninitialization, resulting in more efficient learning of the first scheme. We\nvalidate our results with extensive experiments on LLMs.",
      "tldr_zh": "本研究探讨了 Low Rank Adaptation (LoRA) 微调过程中的初始化策略对性能的影响。论文比较了两种方案：将 B 初始化为零并将 A 初始化为随机（PEFT 包的默认方式），以及反之；尽管两者在初始化时均使 BA 为零，但前者平均表现出色。理论分析表明，第一种初始化允许使用更大的学习率而不导致输出不稳定，从而实现更高效的学习。实验在大型语言模型 (LLMs) 上进行了广泛验证，证实了这一优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "TDLR: Different Initializations lead to completely different\n  finetuning dynamics. One initialization (set A random and B zero) is\n  generally better than the natural opposite initialization. arXiv admin note:\n  text overlap with arXiv:2402.12354",
      "pdf_url": "http://arxiv.org/pdf/2406.08447v1",
      "published_date": "2024-06-12 17:38:20 UTC",
      "updated_date": "2024-06-12 17:38:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:10:07.480287"
    },
    {
      "arxiv_id": "2406.08446v2",
      "title": "OLMES: A Standard for Language Model Evaluations",
      "title_zh": "OLMES：语言模型评估标准",
      "authors": [
        "Yuling Gu",
        "Oyvind Tafjord",
        "Bailey Kuehl",
        "Dany Haddad",
        "Jesse Dodge",
        "Hannaneh Hajishirzi"
      ],
      "abstract": "Progress in AI is often demonstrated by new models claiming improved\nperformance on tasks measuring model capabilities. Evaluating language models\ncan be particularly challenging, as choices of how a model is evaluated on a\ntask can lead to large changes in measured performance. There is no common\nstandard setup, so different models are evaluated on the same tasks in\ndifferent ways, leading to claims about which models perform best not being\nreproducible. We propose OLMES, a completely documented, practical, open\nstandard for reproducible LLM evaluations. In developing this standard, we\nidentify and review the varying factors in evaluation practices adopted by the\ncommunity - such as details of prompt formatting, choice of in-context\nexamples, probability normalizations, and task formulation. In particular,\nOLMES supports meaningful comparisons between smaller base models that require\nthe unnatural \"cloze\" formulation of multiple-choice questions against larger\nmodels that can utilize the original formulation. OLMES includes\nwell-considered, documented recommendations guided by results from existing\nliterature as well as new experiments resolving open questions.",
      "tldr_zh": "该论文提出OLMES，这是一个完全记录的、实用的、开放标准，用于实现语言模型（LLMs）评估的可重现性，以解决不同评估实践导致的性能测量差异和不可比性问题。OLMES审视了评估中的关键因素，如prompt formatting、in-context examples、probability normalizations和任务表述，并通过现有文献和新实验提供指导性推荐。特别地，该标准支持对小型基线模型（使用“cloze”格式的多选题）和大型模型（使用原生格式）的有意义比较，从而促进更公平可靠的模型性能评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.08446v2",
      "published_date": "2024-06-12 17:37:09 UTC",
      "updated_date": "2025-02-11 18:59:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:10:20.410921"
    },
    {
      "arxiv_id": "2406.08434v1",
      "title": "TasTe: Teaching Large Language Models to Translate through Self-Reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Wang",
        "Jiali Zeng",
        "Xuebo Liu",
        "Fandong Meng",
        "Jie Zhou",
        "Min Zhang"
      ],
      "abstract": "Large language models (LLMs) have exhibited remarkable performance in various\nnatural language processing tasks. Techniques like instruction tuning have\neffectively enhanced the proficiency of LLMs in the downstream task of machine\ntranslation. However, the existing approaches fail to yield satisfactory\ntranslation outputs that match the quality of supervised neural machine\ntranslation (NMT) systems. One plausible explanation for this discrepancy is\nthat the straightforward prompts employed in these methodologies are unable to\nfully exploit the acquired instruction-following capabilities. To this end, we\npropose the TasTe framework, which stands for translating through\nself-reflection. The self-reflection process includes two stages of inference.\nIn the first stage, LLMs are instructed to generate preliminary translations\nand conduct self-assessments on these translations simultaneously. In the\nsecond stage, LLMs are tasked to refine these preliminary translations\naccording to the evaluation results. The evaluation results in four language\ndirections on the WMT22 benchmark reveal the effectiveness of our approach\ncompared to existing methods. Our work presents a promising approach to unleash\nthe potential of LLMs and enhance their capabilities in MT. The codes and\ndatasets are open-sourced at https://github.com/YutongWang1216/ReflectionLLMMT.",
      "tldr_zh": "本研究提出TasTe框架，通过self-reflection（自反省）机制提升大型语言模型（LLMs）在机器翻译（MT）任务中的性能，以解决现有指令微调方法无法媲美监督神经机器翻译（NMT）系统的局限性。框架包括两个阶段：第一阶段，LLMs生成初步翻译并进行自我评估；第二阶段，根据评估结果对翻译进行refining。实验在WMT22基准上的四种语言方向显示，TasTe比现有方法更有效，显著提高了翻译质量。该方法为释放LLMs潜力的新途径提供了有前景的解决方案，并开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted to the ACL 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2406.08434v1",
      "published_date": "2024-06-12 17:21:21 UTC",
      "updated_date": "2024-06-12 17:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:10:34.086526"
    },
    {
      "arxiv_id": "2406.08431v1",
      "title": "Diffusion Soup: Model Merging for Text-to-Image Diffusion Models",
      "title_zh": "Diffusion Soup：文本到图像",
      "authors": [
        "Benjamin Biggs",
        "Arjun Seshadri",
        "Yang Zou",
        "Achin Jain",
        "Aditya Golatkar",
        "Yusheng Xie",
        "Alessandro Achille",
        "Ashwin Swaminathan",
        "Stefano Soatto"
      ],
      "abstract": "We present Diffusion Soup, a compartmentalization method for Text-to-Image\nGeneration that averages the weights of diffusion models trained on sharded\ndata. By construction, our approach enables training-free continual learning\nand unlearning with no additional memory or inference costs, since models\ncorresponding to data shards can be added or removed by re-averaging. We show\nthat Diffusion Soup samples from a point in weight space that approximates the\ngeometric mean of the distributions of constituent datasets, which offers\nanti-memorization guarantees and enables zero-shot style mixing. Empirically,\nDiffusion Soup outperforms a paragon model trained on the union of all data\nshards and achieves a 30% improvement in Image Reward (.34 $\\to$ .44) on domain\nsharded data, and a 59% improvement in IR (.37 $\\to$ .59) on aesthetic data. In\nboth cases, souping also prevails in TIFA score (respectively, 85.5 $\\to$ 86.5\nand 85.6 $\\to$ 86.8). We demonstrate robust unlearning -- removing any\nindividual domain shard only lowers performance by 1% in IR (.45 $\\to$ .44) --\nand validate our theoretical insights on anti-memorization using real data.\nFinally, we showcase Diffusion Soup's ability to blend the distinct styles of\nmodels finetuned on different shards, resulting in the zero-shot generation of\nhybrid styles.",
      "tldr_zh": "本论文提出了Diffusion Soup，一种通过平均训练在分片数据上的扩散模型权重的方法，用于Text-to-Image生成，支持无额外内存或推理成本的训练-free持续学习和遗忘。Diffusion Soup采样权重空间的点，近似于组成数据集的几何平均，提供反记忆保证和零样本风格混合能力。实验结果显示，它超过了在所有数据上训练的基线模型，在领域分片数据上Image Reward提升30%（.34 → .44），在美学数据上提升59%（.37 → .59），TIFA分数也相应提高；此外，移除单个数据分片仅降低1%的性能，并展示了混合不同风格的零样本生成效果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08431v1",
      "published_date": "2024-06-12 17:16:16 UTC",
      "updated_date": "2024-06-12 17:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:10:46.688765"
    },
    {
      "arxiv_id": "2406.08428v1",
      "title": "Improving Noise Robustness through Abstractions and its Impact on Machine Learning",
      "title_zh": "通过抽象化提升噪声鲁棒性及其对机器学习的影响",
      "authors": [
        "Alfredo Ibias",
        "Karol Capala",
        "Varun Ravi Varma",
        "Anna Drozdz",
        "Jose Sousa"
      ],
      "abstract": "Noise is a fundamental problem in learning theory with huge effects in the\napplication of Machine Learning (ML) methods, due to real world data tendency\nto be noisy. Additionally, introduction of malicious noise can make ML methods\nfail critically, as is the case with adversarial attacks. Thus, finding and\ndeveloping alternatives to improve robustness to noise is a fundamental problem\nin ML. In this paper, we propose a method to deal with noise: mitigating its\neffect through the use of data abstractions. The goal is to reduce the effect\nof noise over the model's performance through the loss of information produced\nby the abstraction. However, this information loss comes with a cost: it can\nresult in an accuracy reduction due to the missing information. First, we\nexplored multiple methodologies to create abstractions, using the training\ndataset, for the specific case of numerical data and binary classification\ntasks. We also tested how these abstractions can affect robustness to noise\nwith several experiments that explore the robustness of an Artificial Neural\nNetwork to noise when trained using raw data \\emph{vs} when trained using\nabstracted data. The results clearly show that using abstractions is a viable\napproach for developing noise robust ML methods.",
      "tldr_zh": "该论文探讨了噪声对机器学习（ML）的影响，强调噪声（包括恶意噪声如对抗性攻击）可能导致模型性能下降，并提出通过数据抽象来提升噪声鲁棒性。作者的方法涉及使用训练数据集创建抽象，以减少噪声对模型的影响，尽管这可能导致信息损失和准确率降低。针对数值数据和二元分类任务，他们实验比较了使用原始数据与抽象数据训练的Artificial Neural Network（ANN），结果显示抽象数据训练的模型在噪声环境下表现出更高的鲁棒性，从而证明了这一方法的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08428v1",
      "published_date": "2024-06-12 17:14:44 UTC",
      "updated_date": "2024-06-12 17:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:10:56.308629"
    },
    {
      "arxiv_id": "2406.08426v5",
      "title": "Next-Generation Database Interfaces: A Survey of LLM-based Text-to-SQL",
      "title_zh": "下一代数据库接口：基于 LLM 的文本到 SQL 调查",
      "authors": [
        "Zijin Hong",
        "Zheng Yuan",
        "Qinggang Zhang",
        "Hao Chen",
        "Junnan Dong",
        "Feiran Huang",
        "Xiao Huang"
      ],
      "abstract": "Generating accurate SQL from users' natural language questions (text-to-SQL)\nremains a long-standing challenge due to the complexities involved in user\nquestion understanding, database schema comprehension, and SQL generation.\nTraditional text-to-SQL systems, which combine human engineering and deep\nneural networks, have made significant progress. Subsequently, pre-trained\nlanguage models (PLMs) have been developed for text-to-SQL tasks, achieving\npromising results. However, as modern databases and user questions grow more\ncomplex, PLMs with a limited parameter size often produce incorrect SQL. This\nnecessitates more sophisticated and tailored optimization methods, which\nrestricts the application of PLM-based systems. Recently, large language models\n(LLMs) have shown significant capabilities in natural language understanding as\nmodel scale increases. Thus, integrating LLM-based solutions can bring unique\nopportunities, improvements, and solutions to text-to-SQL research. In this\nsurvey, we provide a comprehensive review of existing LLM-based text-to-SQL\nstudies. Specifically, we offer a brief overview of the technical challenges\nand evolutionary process of text-to-SQL. Next, we introduce the datasets and\nmetrics designed to evaluate text-to-SQL systems. Subsequently, we present a\nsystematic analysis of recent advances in LLM-based text-to-SQL. Finally, we\nmake a summarization and discuss the remaining challenges in this field and\nsuggest expectations for future research directions.",
      "tldr_zh": "这篇调查论文回顾了基于大型语言模型 (LLMs) 的文本到 SQL (text-to-SQL) 系统的发展，旨在解决从自然语言问题生成准确 SQL 的挑战，包括用户问题理解、数据库模式理解和 SQL 生成的复杂性。论文首先概述了传统系统和预训练语言模型 (PLMs) 的进展及其局限性，然后介绍了评估 text-to-SQL 的数据集、指标和最近的 LLM-based 研究进展。最终，它总结了当前领域的剩余挑战，并提出未来研究方向，如更复杂的优化方法和模型扩展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08426v5",
      "published_date": "2024-06-12 17:13:17 UTC",
      "updated_date": "2025-03-13 08:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:11:09.616822"
    },
    {
      "arxiv_id": "2406.08425v1",
      "title": "AWGUNET: Attention-Aided Wavelet Guided U-Net for Nuclei Segmentation in Histopathology Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ayush Roy",
        "Payel Pramanik",
        "Dmitrii Kaplun",
        "Sergei Antonov",
        "Ram Sarkar"
      ],
      "abstract": "Accurate nuclei segmentation in histopathological images is crucial for\ncancer diagnosis. Automating this process offers valuable support to clinical\nexperts, as manual annotation is time-consuming and prone to human errors.\nHowever, automating nuclei segmentation presents challenges due to uncertain\ncell boundaries, intricate staining, and diverse structures. In this paper, we\npresent a segmentation approach that combines the U-Net architecture with a\nDenseNet-121 backbone, harnessing the strengths of both to capture\ncomprehensive contextual and spatial information. Our model introduces the\nWavelet-guided channel attention module to enhance cell boundary delineation,\nalong with a learnable weighted global attention module for channel-specific\nattention. The decoder module, composed of an upsample block and convolution\nblock, further refines segmentation in handling staining patterns. The\nexperimental results conducted on two publicly accessible histopathology\ndatasets, namely Monuseg and TNBC, underscore the superiority of our proposed\nmodel, demonstrating its potential to advance histopathological image analysis\nand cancer diagnosis. The code is made available at:\nhttps://github.com/AyushRoy2001/AWGUNET.",
      "tldr_zh": "该论文提出 AWGUNET，一种基于 U-Net 架构和 DenseNet-121 骨干的模型，用于组织病理图像中细胞核分割，以解决细胞边界不确定、复杂染色和多样结构等挑战。模型创新性地引入 Wavelet-guided channel attention module 来增强边界描绘，以及 learnable weighted global attention module 来实现通道特定的注意力优化。解码器通过上采样块和卷积块进一步处理染色模式，确保分割精度。在 Monuseg 和 TNBC 数据集上的实验结果显示，该模型优于现有方法，有助于推进组织病理图像分析和癌症诊断的自动化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08425v1",
      "published_date": "2024-06-12 17:10:27 UTC",
      "updated_date": "2024-06-12 17:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:11:32.984306"
    },
    {
      "arxiv_id": "2406.11883v1",
      "title": "Data Petri Nets meet Probabilistic Programming (Extended version)",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Kuhn",
        "Joscha Grüger",
        "Christoph Matheja",
        "Andrey Rivkin"
      ],
      "abstract": "Probabilistic programming (PP) is a programming paradigm that allows for\nwriting statistical models like ordinary programs, performing simulations by\nrunning those programs, and analyzing and refining their statistical behavior\nusing powerful inference engines. This paper takes a step towards leveraging PP\nfor reasoning about data-aware processes. To this end, we present a systematic\ntranslation of Data Petri Nets (DPNs) into a model written in a PP language\nwhose features are supported by most PP systems. We show that our translation\nis sound and provides statistical guarantees for simulating DPNs. Furthermore,\nwe discuss how PP can be used for process mining tasks and report on a\nprototype implementation of our translation. We also discuss further analysis\nscenarios that could be easily approached based on the proposed translation and\navailable PP tools.",
      "tldr_zh": "这篇论文探讨了如何将Data Petri Nets (DPNs) 与Probabilistic Programming (PP) 整合，以推理数据感知过程。作者提出了一种系统翻译方法，将DPNs 转换为支持于大多数PP系统的语言模型，并证明该翻译是正确的，同时提供统计保证用于模拟DPNs。论文还讨论了PP在process mining任务中的应用潜力，并报告了一个原型实现，以及基于此翻译的进一步分析场景。",
      "categories": [
        "cs.PL",
        "cs.AI"
      ],
      "primary_category": "cs.PL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11883v1",
      "published_date": "2024-06-12 17:07:35 UTC",
      "updated_date": "2024-06-12 17:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:11:34.014173"
    },
    {
      "arxiv_id": "2406.08423v1",
      "title": "State Soup: In-Context Skill Learning, Retrieval and Mixing",
      "title_zh": "翻译失败",
      "authors": [
        "Maciej Pióro",
        "Maciej Wołczyk",
        "Razvan Pascanu",
        "Johannes von Oswald",
        "João Sacramento"
      ],
      "abstract": "A new breed of gated-linear recurrent neural networks has reached\nstate-of-the-art performance on a range of sequence modeling problems. Such\nmodels naturally handle long sequences efficiently, as the cost of processing a\nnew input is independent of sequence length. Here, we explore another advantage\nof these stateful sequence models, inspired by the success of model merging\nthrough parameter interpolation. Building on parallels between fine-tuning and\nin-context learning, we investigate whether we can treat internal states as\ntask vectors that can be stored, retrieved, and then linearly combined,\nexploiting the linearity of recurrence. We study this form of fast model\nmerging on Mamba-2.8b, a pretrained recurrent model, and present preliminary\nevidence that simple linear state interpolation methods suffice to improve\nnext-token perplexity as well as downstream in-context learning task\nperformance.",
      "tldr_zh": "本研究探索了门控线性循环神经网络（gated-linear recurrent neural networks）的内部状态，提出一种“State Soup”方法，将这些状态视为任务向量，进行存储、检索和线性组合，以实现快速模型合并。  \n该方法基于预训练的 Mamba-2.8b 模型，利用内部状态的线性特性，模拟 fine-tuning 和 in-context learning 的优势。  \n实验结果显示，简单的线性状态插值技术能够显著降低下一 token 困惑度（next-token perplexity）并提升下游 in-context learning 任务的性能，为高效序列建模提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08423v1",
      "published_date": "2024-06-12 17:06:07 UTC",
      "updated_date": "2024-06-12 17:06:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:11:46.291038"
    },
    {
      "arxiv_id": "2406.08418v3",
      "title": "OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyun Li",
        "Zhe Chen",
        "Weiyun Wang",
        "Wenhai Wang",
        "Shenglong Ye",
        "Zhenjiang Jin",
        "Guanzhou Chen",
        "Yinan He",
        "Zhangwei Gao",
        "Erfei Cui",
        "Jiashuo Yu",
        "Hao Tian",
        "Jiasheng Zhou",
        "Chao Xu",
        "Bin Wang",
        "Xingjian Wei",
        "Wei Li",
        "Wenjian Zhang",
        "Bo Zhang",
        "Pinlong Cai",
        "Licheng Wen",
        "Xiangchao Yan",
        "Zhenxiang Li",
        "Pei Chu",
        "Yi Wang",
        "Min Dou",
        "Changyao Tian",
        "Xizhou Zhu",
        "Lewei Lu",
        "Yushi Chen",
        "Junjun He",
        "Zhongying Tu",
        "Tong Lu",
        "Yali Wang",
        "Limin Wang",
        "Dahua Lin",
        "Yu Qiao",
        "Botian Shi",
        "Conghui He",
        "Jifeng Dai"
      ],
      "abstract": "Image-text interleaved data, consisting of multiple images and texts arranged\nin a natural document format, aligns with the presentation paradigm of internet\ndata and closely resembles human reading habits. Recent studies have shown that\nsuch data aids multimodal in-context learning and maintains the capabilities of\nlarge language models during multimodal fine-tuning. However, the limited scale\nand diversity of current image-text interleaved data restrict the development\nof multimodal large language models. In this paper, we introduce OmniCorpus, a\n10 billion-scale image-text interleaved dataset. Using an efficient data\nengine, we filter and extract large-scale high-quality documents, which contain\n8.6 billion images and 1,696 billion text tokens. Compared to counterparts\n(e.g., MMC4, OBELICS), our dataset 1) has 15 times larger scales while\nmaintaining good data quality; 2) features more diverse sources, including both\nEnglish and non-English websites as well as video-centric websites; 3) is more\nflexible, easily degradable from an image-text interleaved format to pure text\ncorpus and image-text pairs. Through comprehensive analysis and experiments, we\nvalidate the quality, usability, and effectiveness of the proposed dataset. We\nhope this could provide a solid data foundation for future multimodal model\nresearch. Code and data are released at\nhttps://github.com/OpenGVLab/OmniCorpus.",
      "tldr_zh": "本研究引入了 OmniCorpus，这是一个统一的、规模达 100 亿级的多模态数据集，包含图像和文本交错格式的数据，以更好地模拟互联网数据呈现和人类阅读习惯。相比现有数据集（如 MMC4 和 OBELICS），OmniCorpus 规模扩大 15 倍，同时保持高质量、多样来源（包括英语和非英语网站及视频网站），并提供灵活性，可降级为纯文本语料或图像-文本对。研究通过全面分析和实验验证了该数据集的质量和有效性，为多模态大语言模型（Multimodal Large Language Models）的开发提供了坚实基础，并公开了代码和数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08418v3",
      "published_date": "2024-06-12 17:01:04 UTC",
      "updated_date": "2024-07-12 08:54:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:11:58.813918"
    },
    {
      "arxiv_id": "2406.08411v2",
      "title": "Tailoring Generative AI Chatbots for Multiethnic Communities in Disaster Preparedness Communication: Extending the CASA Paradigm",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyan Zhao",
        "Yuan Sun",
        "Wenlin Liu",
        "Chau-Wai Wong"
      ],
      "abstract": "This study is among the first to develop different prototypes of generative\nartificial intelligence (GenAI) chatbots powered by GPT-4 to communicate\nhurricane preparedness information to diverse residents. Drawing from the\nComputers Are Social Actors paradigm and the literature on disaster\nvulnerability and cultural tailoring, we conducted a between-subjects\nexperiment with 441 Black, Hispanic, and Caucasian residents of Florida. Our\nresults suggest that GenAI chatbots varying in tone formality and cultural\ntailoring significantly influence perceptions of their friendliness and\ncredibility, which, in turn, relate to hurricane preparedness outcomes. These\nresults highlight the potential of using GenAI chatbots to improve diverse\ncommunities' disaster preparedness.",
      "tldr_zh": "本研究开发了基于 GPT-4 的 Generative AI 聊天机器人原型，用于向佛罗里达的黑人、西班牙裔和白人等多民族社区传达飓风准备信息，并扩展了 CASA Paradigm。研究通过一项涉及 441 名居民的被试间实验，探讨了聊天机器人语气正式度和文化定制对友好度和可信度的影响。结果表明，这些因素显著提升了居民的灾害准备意愿，突显了 GenAI 聊天机器人在改善多样化社区灾害准备方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "68U15"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for Publication in Journal of Computer-Mediated\n  Communication",
      "pdf_url": "http://arxiv.org/pdf/2406.08411v2",
      "published_date": "2024-06-12 16:57:28 UTC",
      "updated_date": "2025-02-02 03:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:12:10.616342"
    },
    {
      "arxiv_id": "2406.08407v3",
      "title": "MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation in Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Xuehai He",
        "Weixi Feng",
        "Kaizhi Zheng",
        "Yujie Lu",
        "Wanrong Zhu",
        "Jiachen Li",
        "Yue Fan",
        "Jianfeng Wang",
        "Linjie Li",
        "Zhengyuan Yang",
        "Kevin Lin",
        "William Yang Wang",
        "Lijuan Wang",
        "Xin Eric Wang"
      ],
      "abstract": "Multimodal Language Language Models (MLLMs) demonstrate the emerging\nabilities of \"world models\" -- interpreting and reasoning about complex\nreal-world dynamics. To assess these abilities, we posit videos are the ideal\nmedium, as they encapsulate rich representations of real-world dynamics and\ncausalities. To this end, we introduce MMWorld, a new benchmark for\nmulti-discipline, multi-faceted multimodal video understanding. MMWorld\ndistinguishes itself from previous video understanding benchmarks with two\nunique advantages: (1) multi-discipline, covering various disciplines that\noften require domain expertise for comprehensive understanding; (2)\nmulti-faceted reasoning, including explanation, counterfactual thinking, future\nprediction, etc. MMWorld consists of a human-annotated dataset to evaluate\nMLLMs with questions about the whole videos and a synthetic dataset to analyze\nMLLMs within a single modality of perception. Together, MMWorld encompasses\n1,910 videos across seven broad disciplines and 69 subdisciplines, complete\nwith 6,627 question-answer pairs and associated captions. The evaluation\nincludes 2 proprietary and 10 open-source MLLMs, which struggle on MMWorld\n(e.g., GPT-4V performs the best with only 52.3\\% accuracy), showing large room\nfor improvement. Further ablation studies reveal other interesting findings\nsuch as models' different skill sets from humans. We hope MMWorld can serve as\nan essential step towards world model evaluation in videos.",
      "tldr_zh": "这篇论文引入了 MMWorld 基准，用于评估多模态语言模型 (MLLMs) 作为“世界模型”的能力，焦点在于视频中多学科（如七个广泛领域和69个子学科）和多方面推理（如解释、反事实思考、未来预测）。MMWorld 包含1,910个视频、6,627个问答对和相关字幕，包括人类标注数据集（针对整体视频理解）和合成数据集（分析单一模态感知）。实验结果显示10个开源和2个专有 MLLMs 的表现不佳（如 GPT-4V 准确率仅52.3%），并通过消融研究揭示模型技能与人类的差异，为视频世界模型评估提供了重要改进方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08407v3",
      "published_date": "2024-06-12 16:54:54 UTC",
      "updated_date": "2024-07-30 03:15:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:12:36.672642"
    },
    {
      "arxiv_id": "2406.08404v1",
      "title": "Scaling Value Iteration Networks to 5000 Layers for Extreme Long-Term Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhui Wang",
        "Qingyuan Wu",
        "Weida Li",
        "Dylan R. Ashley",
        "Francesco Faccio",
        "Chao Huang",
        "Jürgen Schmidhuber"
      ],
      "abstract": "The Value Iteration Network (VIN) is an end-to-end differentiable\narchitecture that performs value iteration on a latent MDP for planning in\nreinforcement learning (RL). However, VINs struggle to scale to long-term and\nlarge-scale planning tasks, such as navigating a $100\\times 100$ maze -- a task\nwhich typically requires thousands of planning steps to solve. We observe that\nthis deficiency is due to two issues: the representation capacity of the latent\nMDP and the planning module's depth. We address these by augmenting the latent\nMDP with a dynamic transition kernel, dramatically improving its\nrepresentational capacity, and, to mitigate the vanishing gradient problem,\nintroducing an \"adaptive highway loss\" that constructs skip connections to\nimprove gradient flow. We evaluate our method on both 2D maze navigation\nenvironments and the ViZDoom 3D navigation benchmark. We find that our new\nmethod, named Dynamic Transition VIN (DT-VIN), easily scales to 5000 layers and\ncasually solves challenging versions of the above tasks. Altogether, we believe\nthat DT-VIN represents a concrete step forward in performing long-term\nlarge-scale planning in RL environments.",
      "tldr_zh": "本论文针对 Value Iteration Network (VIN) 在强化学习 (RL) 中的长期大规模规划问题（如100×100迷宫），提出改进方法以解决潜在MDP表示能力和规划深度不足的挑战。具体而言，作者引入动态转移核（dynamic transition kernel）来增强MDP的表示能力，并采用adaptive highway loss构建跳跃连接以缓解梯度消失问题，从而开发出Dynamic Transition VIN (DT-VIN)。实验结果显示，DT-VIN 可轻松扩展到5000层，并在2D迷宫导航和ViZDoom 3D基准上显著提升性能，成功解决复杂任务，为RL环境中的长期规划提供了关键进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08404v1",
      "published_date": "2024-06-12 16:52:54 UTC",
      "updated_date": "2024-06-12 16:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:12:37.794885"
    },
    {
      "arxiv_id": "2406.08534v2",
      "title": "Optimizing Container Loading and Unloading through Dual-Cycling and Dockyard Rehandle Reduction Using a Hybrid Genetic Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Mahfuzur Rahman",
        "Md Abrar Jahin",
        "Md. Saiful Islam",
        "M. F. Mridha"
      ],
      "abstract": "This paper addresses the optimization of container unloading and loading\noperations at ports, integrating quay-crane dual-cycling with dockyard rehandle\nminimization. We present a unified model encompassing both operations: ship\ncontainer unloading and loading by quay crane, and the other is reducing\ndockyard rehandles while loading the ship. We recognize that optimizing one\naspect in isolation can lead to suboptimal outcomes due to interdependencies.\nSpecifically, optimizing unloading sequences for minimal operation time may\ninadvertently increase dockyard rehandles during loading and vice versa. To\naddress this NP-hard problem, we propose a hybrid genetic algorithm (GA)\nQCDC-DR-GA comprising one-dimensional and two-dimensional GA components. Our\nmodel, QCDC-DR-GA, consistently outperforms four state-of-the-art methods in\nmaximizing dual cycles and minimizing dockyard rehandles. Compared to those\nmethods, it reduced 15-20% of total operation time for large vessels.\nStatistical validation through a two-tailed paired t-test confirms the\nsuperiority of QCDC-DR-GA at a 5% significance level. The approach effectively\ncombines QCDC optimization with dockyard rehandle minimization, optimizing the\ntotal unloading-loading time. Results underscore the inefficiency of separately\noptimizing QCDC and dockyard rehandles. Fragmented approaches, such as QCDC\nScheduling Optimized by bi-level GA and GA-ILSRS (Scenario 2), show limited\nimprovement compared to QCDC-DR-GA. As in GA-ILSRS (Scenario 1), neglecting\ndual-cycle optimization leads to inferior performance than QCDC-DR-GA. This\nemphasizes the necessity of simultaneously considering both aspects for optimal\nresource utilization and overall operational efficiency.",
      "tldr_zh": "这篇论文针对港口集装箱卸载和加载操作，提出了一种统一模型，通过整合码头起重机双循环（Dual-Cycling）和码头再处理最小化（Dockyard Rehandle Reduction）来解决两者间的相互依赖问题。作者开发了混合遗传算法（Hybrid Genetic Algorithm, QCDC-DR-GA），结合一维和二维GA组件，优化总操作时间并处理NP-hard难题。实验结果显示，该算法比四种现有方法减少了15-20%的总操作时间，并通过双尾配对t检验在5%显著性水平上证实其优越性，强调了同时优化双方面的重要性，以提升整体资源利用和操作效率。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08534v2",
      "published_date": "2024-06-12 16:47:45 UTC",
      "updated_date": "2024-12-04 12:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:12:50.838055"
    },
    {
      "arxiv_id": "2406.08398v1",
      "title": "cPAPERS: A Dataset of Situated and Multimodal Interactive Conversations in Scientific Papers",
      "title_zh": "翻译失败",
      "authors": [
        "Anirudh Sundar",
        "Jin Xu",
        "William Gay",
        "Christopher Richardson",
        "Larry Heck"
      ],
      "abstract": "An emerging area of research in situated and multimodal interactive\nconversations (SIMMC) includes interactions in scientific papers. Since\nscientific papers are primarily composed of text, equations, figures, and\ntables, SIMMC methods must be developed specifically for each component to\nsupport the depth of inquiry and interactions required by research scientists.\nThis work introduces Conversational Papers (cPAPERS), a dataset of\nconversational question-answer pairs from reviews of academic papers grounded\nin these paper components and their associated references from scientific\ndocuments available on arXiv. We present a data collection strategy to collect\nthese question-answer pairs from OpenReview and associate them with contextual\ninformation from LaTeX source files. Additionally, we present a series of\nbaseline approaches utilizing Large Language Models (LLMs) in both zero-shot\nand fine-tuned configurations to address the cPAPERS dataset.",
      "tldr_zh": "这篇论文引入了 cPAPERS 数据集，这是一个针对科学论文中情境化和多模态互动对话 (SIMMC) 的数据集，包含基于文本、方程、图表和引文的对话问题-答案对。研究者采用了一种数据收集策略，从 OpenReview 平台获取这些对话对，并将其与 LaTeX 源文件的上下文信息关联，以支持科研人员的深入互动。论文还评估了使用大语言模型 (LLMs) 的基线方法，包括零样本和微调配置，来处理 cPAPERS 数据集，从而为 SIMMC 在科学领域的应用提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2406.08398v1",
      "published_date": "2024-06-12 16:46:12 UTC",
      "updated_date": "2024-06-12 16:46:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:12:59.435076"
    },
    {
      "arxiv_id": "2406.08396v1",
      "title": "Neural Blind Source Separation and Diarization for Distant Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yoshiaki Bando",
        "Tomohiko Nakamura",
        "Shinji Watanabe"
      ],
      "abstract": "This paper presents a neural method for distant speech recognition (DSR) that\njointly separates and diarizes speech mixtures without supervision by isolated\nsignals. A standard separation method for multi-talker DSR is a statistical\nmultichannel method called guided source separation (GSS). While GSS does not\nrequire signal-level supervision, it relies on speaker diarization results to\nhandle unknown numbers of active speakers. To overcome this limitation, we\nintroduce and train a neural inference model in a weakly-supervised manner,\nemploying the objective function of a statistical separation method. This\ntraining requires only multichannel mixtures and their temporal annotations of\nspeaker activities. In contrast to GSS, the trained model can jointly separate\nand diarize speech mixtures without any auxiliary information. The experiments\nwith the AMI corpus show that our method outperforms GSS with oracle\ndiarization results regarding word error rates. The code is available online.",
      "tldr_zh": "本论文提出了一种神经盲源分离（Neural Blind Source Separation）和说话者识别（Diarization）方法，用于远距离语音识别（Distant Speech Recognition），该方法无需孤立信号监督即可联合分离和识别多说话者语音混合。不同于传统的引导源分离（GSS）方法，该方法通过弱监督训练神经推理模型，仅依赖多通道混合信号和说话者活动的时间标注，从而克服了对辅助信息的依赖。实验结果显示，在 AMI 语料库上，该方法在字错误率方面优于使用预设说话者识别的 GSS，并公开了相关代码。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures, accepted to INTERSPEECH 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08396v1",
      "published_date": "2024-06-12 16:45:35 UTC",
      "updated_date": "2024-06-12 16:45:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:13:11.351182"
    },
    {
      "arxiv_id": "2406.08391v2",
      "title": "Large Language Models Must Be Taught to Know What They Don't Know",
      "title_zh": "大型语言模型必须被教导知道它们不知道的东西",
      "authors": [
        "Sanyam Kapoor",
        "Nate Gruver",
        "Manley Roberts",
        "Katherine Collins",
        "Arka Pal",
        "Umang Bhatt",
        "Adrian Weller",
        "Samuel Dooley",
        "Micah Goldblum",
        "Andrew Gordon Wilson"
      ],
      "abstract": "When using large language models (LLMs) in high-stakes applications, we need\nto know when we can trust their predictions. Some works argue that prompting\nhigh-performance LLMs is sufficient to produce calibrated uncertainties, while\nothers introduce sampling methods that can be prohibitively expensive. In this\nwork, we first argue that prompting on its own is insufficient to achieve good\ncalibration and then show that fine-tuning on a small dataset of correct and\nincorrect answers can create an uncertainty estimate with good generalization\nand small computational overhead. We show that a thousand graded examples are\nsufficient to outperform baseline methods and that training through the\nfeatures of a model is necessary for good performance and tractable for large\nopen-source models when using LoRA. We also investigate the mechanisms that\nenable reliable LLM uncertainty estimation, finding that many models can be\nused as general-purpose uncertainty estimators, applicable not just to their\nown uncertainties but also the uncertainty of other models. Lastly, we show\nthat uncertainty estimates inform human use of LLMs in human-AI collaborative\nsettings through a user study.",
      "tldr_zh": "这篇论文强调，大型语言模型 (LLMs) 在高风险应用中必须学会识别自身的不确定性，以确保预测的可信度。作者发现，仅通过提示 (prompting) 无法实现良好的 uncertainty 校准，因此提出一种方法：在小数据集（包含正确和错误答案）上进行 fine-tuning，以生成具有良好泛化和低计算开销的 uncertainty 估计。实验结果显示，使用约一千个分级例子即可超越基线方法，且通过 LoRA 技术对大型开源模型进行特征训练是高效可行的。该研究还揭示，训练后的模型可作为通用 uncertainty 估计器，适用于其他模型，并通过用户研究证明 uncertainty 估计能提升人-AI 协作效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2406.08391v2",
      "published_date": "2024-06-12 16:41:31 UTC",
      "updated_date": "2024-12-05 23:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:13:25.045013"
    },
    {
      "arxiv_id": "2406.08384v2",
      "title": "Diff-A-Riff: Musical Accompaniment Co-creation via Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Nistal",
        "Marco Pasini",
        "Cyran Aouameur",
        "Maarten Grachten",
        "Stefan Lattner"
      ],
      "abstract": "Recent advancements in deep generative models present new opportunities for\nmusic production but also pose challenges, such as high computational demands\nand limited audio quality. Moreover, current systems frequently rely solely on\ntext input and typically focus on producing complete musical pieces, which is\nincompatible with existing workflows in music production. To address these\nissues, we introduce \"Diff-A-Riff,\" a Latent Diffusion Model designed to\ngenerate high-quality instrumental accompaniments adaptable to any musical\ncontext. This model offers control through either audio references, text\nprompts, or both, and produces 48kHz pseudo-stereo audio while significantly\nreducing inference time and memory usage. We demonstrate the model's\ncapabilities through objective metrics and subjective listening tests, with\nextensive examples available on the accompanying website:\nsonycslparis.github.io/diffariff-companion/",
      "tldr_zh": "该论文介绍了Diff-A-Riff，一种基于Latent Diffusion Models的模型，用于生成高质量乐器伴奏，以适应各种音乐情境。Diff-A-Riff解决了现有生成系统的高计算需求和音频质量问题，通过音频参考、文本提示或两者结合提供灵活控制，并输出48kHz伪立体音频，同时显著减少推理时间和内存使用。实验结果显示，该模型在客观指标和主观听力测试中表现出色，并通过配套网站提供示例演示其能力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.08384v2",
      "published_date": "2024-06-12 16:34:26 UTC",
      "updated_date": "2024-10-30 14:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:13:37.663954"
    },
    {
      "arxiv_id": "2406.08374v2",
      "title": "2.5D Multi-view Averaging Diffusion Model for 3D Medical Image Translation: Application to Low-count PET Reconstruction with CT-less Attenuation Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Tianqi Chen",
        "Jun Hou",
        "Yinchi Zhou",
        "Huidong Xie",
        "Xiongchao Chen",
        "Qiong Liu",
        "Xueqi Guo",
        "Menghua Xia",
        "James S. Duncan",
        "Chi Liu",
        "Bo Zhou"
      ],
      "abstract": "Positron Emission Tomography (PET) is an important clinical imaging tool but\ninevitably introduces radiation hazards to patients and healthcare providers.\nReducing the tracer injection dose and eliminating the CT acquisition for\nattenuation correction can reduce the overall radiation dose, but often results\nin PET with high noise and bias. Thus, it is desirable to develop 3D methods to\ntranslate the non-attenuation-corrected low-dose PET (NAC-LDPET) into\nattenuation-corrected standard-dose PET (AC-SDPET). Recently, diffusion models\nhave emerged as a new state-of-the-art deep learning method for image-to-image\ntranslation, better than traditional CNN-based methods. However, due to the\nhigh computation cost and memory burden, it is largely limited to 2D\napplications. To address these challenges, we developed a novel 2.5D Multi-view\nAveraging Diffusion Model (MADM) for 3D image-to-image translation with\napplication on NAC-LDPET to AC-SDPET translation. Specifically, MADM employs\nseparate diffusion models for axial, coronal, and sagittal views, whose outputs\nare averaged in each sampling step to ensure the 3D generation quality from\nmultiple views. To accelerate the 3D sampling process, we also proposed a\nstrategy to use the CNN-based 3D generation as a prior for the diffusion model.\nOur experimental results on human patient studies suggested that MADM can\ngenerate high-quality 3D translation images, outperforming previous CNN-based\nand Diffusion-based baseline methods.",
      "tldr_zh": "该研究针对正电子发射断层扫描（PET）成像的辐射风险，提出了一种2.5D Multi-view Averaging Diffusion Model (MADM)，用于将非衰减校正的低剂量 PET (NAC-LDPET) 翻译成衰减校正的标准剂量 PET (AC-SDPET)，从而减少剂量并消除 CT-less Attenuation Correction 的需求。MADM 通过为轴向、冠状和矢状视图分别构建独立的 Diffusion Model，并在每个采样步骤中平均输出，确保了3D图像生成的质量；同时，引入CNN-based 3D生成作为先验策略来加速采样过程。实验结果显示，该方法在人体患者研究中生成的高质量3D图像，显著优于传统的CNN-based和Diffusion-based基线方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08374v2",
      "published_date": "2024-06-12 16:22:41 UTC",
      "updated_date": "2024-06-15 15:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:13:50.509402"
    },
    {
      "arxiv_id": "2406.08358v1",
      "title": "From a Social Cognitive Perspective: Context-aware Visual Social Relationship Recognition",
      "title_zh": "从社会认知视角：上下文感知的视觉社会关系识别",
      "authors": [
        "Shiwei Wu",
        "Chao Zhang",
        "Joya Chen",
        "Tong Xu",
        "Likang Wu",
        "Yao Hu",
        "Enhong Chen"
      ],
      "abstract": "People's social relationships are often manifested through their\nsurroundings, with certain objects or interactions acting as symbols for\nspecific relationships, e.g., wedding rings, roses, hugs, or holding hands.\nThis brings unique challenges to recognizing social relationships, requiring\nunderstanding and capturing the essence of these contexts from visual\nappearances. However, current methods of social relationship understanding rely\non the basic classification paradigm of detected persons and objects, which\nfails to understand the comprehensive context and often overlooks decisive\nsocial factors, especially subtle visual cues. To highlight the social-aware\ncontext and intricate details, we propose a novel approach that recognizes\n\\textbf{Con}textual \\textbf{So}cial \\textbf{R}elationships (\\textbf{ConSoR})\nfrom a social cognitive perspective. Specifically, to incorporate social-aware\nsemantics, we build a lightweight adapter upon the frozen CLIP to learn social\nconcepts via our novel multi-modal side adapter tuning mechanism. Further, we\nconstruct social-aware descriptive language prompts (e.g., scene, activity,\nobjects, emotions) with social relationships for each image, and then compel\nConSoR to concentrate more intensively on the decisive visual social factors\nvia visual-linguistic contrasting. Impressively, ConSoR outperforms previous\nmethods with a 12.2\\% gain on the People-in-Social-Context (PISC) dataset and a\n9.8\\% increase on the People-in-Photo-Album (PIPA) benchmark. Furthermore, we\nobserve that ConSoR excels at finding critical visual evidence to reveal social\nrelationships.",
      "tldr_zh": "本论文从社会认知视角提出一种上下文感知的视觉社会关系识别方法（ConSoR），旨在通过分析图像中的微妙视觉线索（如结婚戒指或拥抱）来更好地理解人与人之间的关系。方法包括在冻结的 CLIP 模型上构建轻量级适配器，利用多模态侧适配器调优机制学习社会概念，并通过社会感知描述语言提示（如场景、活动、物体和情绪）结合视觉-语言对比来强化对关键社会因素的关注。实验结果显示，ConSoR 在 PISC 数据集上比现有方法提升 12.2%，在 PIPA 基准上提升 9.8%，并表现出色地在图像中发现揭示社会关系的视觉证据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08358v1",
      "published_date": "2024-06-12 16:02:28 UTC",
      "updated_date": "2024-06-12 16:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:14:00.372708"
    },
    {
      "arxiv_id": "2406.08354v1",
      "title": "DocSynthv2: A Practical Autoregressive Modeling for Document Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sanket Biswas",
        "Rajiv Jain",
        "Vlad I. Morariu",
        "Jiuxiang Gu",
        "Puneet Mathur",
        "Curtis Wigington",
        "Tong Sun",
        "Josep Lladós"
      ],
      "abstract": "While the generation of document layouts has been extensively explored,\ncomprehensive document generation encompassing both layout and content presents\na more complex challenge. This paper delves into this advanced domain,\nproposing a novel approach called DocSynthv2 through the development of a\nsimple yet effective autoregressive structured model. Our model, distinct in\nits integration of both layout and textual cues, marks a step beyond existing\nlayout-generation approaches. By focusing on the relationship between the\nstructural elements and the textual content within documents, we aim to\ngenerate cohesive and contextually relevant documents without any reliance on\nvisual components. Through experimental studies on our curated benchmark for\nthe new task, we demonstrate the ability of our model combining layout and\ntextual information in enhancing the generation quality and relevance of\ndocuments, opening new pathways for research in document creation and automated\ndesign. Our findings emphasize the effectiveness of autoregressive models in\nhandling complex document generation tasks.",
      "tldr_zh": "本论文提出了一种名为 DocSynthv2 的实用自回归模型，用于全面文档生成任务，该模型整合布局和文本线索，而不依赖视觉组件。不同于现有的布局生成方法，DocSynthv2 聚焦于结构元素与文本内容之间的关系，以生成连贯且上下文相关的文档。实验结果显示，该模型在自定义基准上显著提升了文档生成质量和相关性，证明了 autoregressive modeling 在处理复杂文档生成任务中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Spotlight (Oral) Acceptance to CVPR 2024 Workshop for Graphic Design\n  Understanding and Generation (GDUG)",
      "pdf_url": "http://arxiv.org/pdf/2406.08354v1",
      "published_date": "2024-06-12 16:00:16 UTC",
      "updated_date": "2024-06-12 16:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:14:10.439064"
    },
    {
      "arxiv_id": "2406.08343v1",
      "title": "Continuous-Time Digital Twin with Analogue Memristive Neural Ordinary Differential Equation Solver",
      "title_zh": "翻译失败",
      "authors": [
        "Hegan Chen",
        "Jichang Yang",
        "Jia Chen",
        "Songqi Wang",
        "Shaocong Wang",
        "Dingchen Wang",
        "Xinyu Tian",
        "Yifei Yu",
        "Xi Chen",
        "Yinan Lin",
        "Yangu He",
        "Xiaoshan Wu",
        "Yi Li",
        "Xinyuan Zhang",
        "Ning Lin",
        "Meng Xu",
        "Yi Li",
        "Xumeng Zhang",
        "Zhongrui Wang",
        "Han Wang",
        "Dashan Shang",
        "Qi Liu",
        "Kwang-Ting Cheng",
        "Ming Liu"
      ],
      "abstract": "Digital twins, the cornerstone of Industry 4.0, replicate real-world entities\nthrough computer models, revolutionising fields such as manufacturing\nmanagement and industrial automation. Recent advances in machine learning\nprovide data-driven methods for developing digital twins using discrete-time\ndata and finite-depth models on digital computers. However, this approach fails\nto capture the underlying continuous dynamics and struggles with modelling\ncomplex system behaviour. Additionally, the architecture of digital computers,\nwith separate storage and processing units, necessitates frequent data\ntransfers and Analogue-Digital (A/D) conversion, thereby significantly\nincreasing both time and energy costs. Here, we introduce a memristive neural\nordinary differential equation (ODE) solver for digital twins, which is capable\nof capturing continuous-time dynamics and facilitates the modelling of complex\nsystems using an infinite-depth model. By integrating storage and computation\nwithin analogue memristor arrays, we circumvent the von Neumann bottleneck,\nthus enhancing both speed and energy efficiency. We experimentally validate our\napproach by developing a digital twin of the HP memristor, which accurately\nextrapolates its nonlinear dynamics, achieving a 4.2-fold projected speedup and\na 41.4-fold projected decrease in energy consumption compared to\nstate-of-the-art digital hardware, while maintaining an acceptable error\nmargin. Additionally, we demonstrate scalability through experimentally\ngrounded simulations of Lorenz96 dynamics, exhibiting projected performance\nimprovements of 12.6-fold in speed and 189.7-fold in energy efficiency relative\nto traditional digital approaches. By harnessing the capabilities of fully\nanalogue computing, our breakthrough accelerates the development of digital\ntwins, offering an efficient and rapid solution to meet the demands of Industry\n4.0.",
      "tldr_zh": "本研究提出了一种基于模拟 memristive neural ordinary differential equation (ODE) solver 的连续时间数字孪生框架，以解决传统离散时间模型在捕捉复杂系统动态和效率方面的局限性。该框架通过整合存储和计算于模拟 memristor 阵列，绕过 von Neumann bottleneck，提升速度和能源效率。实验验证显示，该方法在 HP memristor 的数字孪生中实现了 4.2 倍速度提升和 41.4 倍能源消耗减少，并在 Lorenz96 动态模拟中进一步展示 12.6 倍速度和 189.7 倍能源效率改进，从而为 Industry 4.0 提供高效的数字孪生解决方案。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08343v1",
      "published_date": "2024-06-12 15:50:35 UTC",
      "updated_date": "2024-06-12 15:50:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:14:24.026709"
    },
    {
      "arxiv_id": "2406.08335v1",
      "title": "A Survey of Pipeline Tools for Data Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Mbata",
        "Yaji Sripada",
        "Mingjun Zhong"
      ],
      "abstract": "Currently, a variety of pipeline tools are available for use in data\nengineering. Data scientists can use these tools to resolve data wrangling\nissues associated with data and accomplish some data engineering tasks from\ndata ingestion through data preparation to utilization as input for machine\nlearning (ML). Some of these tools have essential built-in components or can be\ncombined with other tools to perform desired data engineering operations. While\nsome tools are wholly or partly commercial, several open-source tools are\navailable to perform expert-level data engineering tasks. This survey examines\nthe broad categories and examples of pipeline tools based on their design and\ndata engineering intentions. These categories are Extract Transform\nLoad/Extract Load Transform (ETL/ELT), pipelines for Data Integration,\nIngestion, and Transformation, Data Pipeline Orchestration and Workflow\nManagement, and Machine Learning Pipelines. The survey also provides a broad\noutline of the utilization with examples within these broad groups and finally,\na discussion is presented with case studies indicating the usage of pipeline\ntools for data engineering. The studies present some first-user application\nexperiences with sample data, some complexities of the applied pipeline, and a\nsummary note of approaches to using these tools to prepare data for machine\nlearning.",
      "tldr_zh": "这篇调查论文回顾了数据工程领域中的各种管道工具，帮助数据科学家处理从数据摄取到准备再到机器学习输入的数据整理问题。论文将这些工具分类为ETL/ELT、数据集成和转换管道、数据管道编排与工作流管理，以及机器学习管道，并提供了示例说明其设计意图和实际应用。最终，通过案例研究讨论了工具的使用经验、潜在复杂性，以及如何利用这些工具为机器学习准备数据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08335v1",
      "published_date": "2024-06-12 15:41:06 UTC",
      "updated_date": "2024-06-12 15:41:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:14:35.356032"
    },
    {
      "arxiv_id": "2406.08334v1",
      "title": "ProTrain: Efficient LLM Training via Memory-Aware Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Hanmei Yang",
        "Jin Zhou",
        "Yao Fu",
        "Xiaoqun Wang",
        "Ramine Roane",
        "Hui Guan",
        "Tongping Liu"
      ],
      "abstract": "It is extremely memory-hungry to train Large Language Models (LLM). To solve\nthis problem, existing work exploits the combination of CPU and GPU for the\ntraining process, such as ZeRO-Offload. Such a technique largely democratizes\nbillion-scale model training, making it possible to train with few consumer\ngraphics cards. However, based on our observation, existing frameworks often\nprovide coarse-grained memory management and require experienced experts in\nconfiguration tuning, leading to suboptimal hardware utilization and\nperformance. This paper proposes ProTrain, a novel training system that\nintelligently balances memory usage and performance by coordinating memory,\ncomputation, and IO. ProTrain achieves adaptive memory management through\nChunk-Based Model State Management and Block-Wise Activation Management, guided\nby a Memory-Aware Runtime Profiler without user intervention. ProTrain does not\nchange the training algorithm and thus does not compromise accuracy.\nExperiments show that ProTrain improves training throughput by 1.43$\\times$ to\n2.71$\\times$ compared to the SOTA training systems.",
      "tldr_zh": "该论文提出 ProTrain，一种高效的 LLM 训练系统，针对现有框架如 ZeRO-Offload 在内存管理上的粗粒度和手动调优问题，通过协调内存、计算和 IO 来优化训练过程。ProTrain 采用 Chunk-Based Model State Management 和 Block-Wise Activation Management 等技术，由 Memory-Aware Runtime Profiler 指导，实现自适应内存管理，而无需用户干预，且不改变训练算法从而保持准确性。实验结果显示，ProTrain 相较于最先进系统，将训练吞吐量提高了 1.43 倍至 2.71 倍。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08334v1",
      "published_date": "2024-06-12 15:40:06 UTC",
      "updated_date": "2024-06-12 15:40:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:14:49.444139"
    },
    {
      "arxiv_id": "2406.08330v1",
      "title": "It's all about PR -- Smart Benchmarking AI Accelerators using Performance Representatives",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Louis-Ferdinand Jung",
        "Jannik Steinmetz",
        "Jonathan Gietz",
        "Konstantin Lübeck",
        "Oliver Bringmann"
      ],
      "abstract": "Statistical models are widely used to estimate the performance of commercial\noff-the-shelf (COTS) AI hardware accelerators. However, training of statistical\nperformance models often requires vast amounts of data, leading to a\nsignificant time investment and can be difficult in case of limited hardware\navailability. To alleviate this problem, we propose a novel performance\nmodeling methodology that significantly reduces the number of training samples\nwhile maintaining good accuracy. Our approach leverages knowledge of the target\nhardware architecture and initial parameter sweeps to identify a set of\nPerformance Representatives (PR) for deep neural network (DNN) layers. These\nPRs are then used for benchmarking, building a statistical performance model,\nand making estimations. This targeted approach drastically reduces the number\nof training samples needed, opposed to random sampling, to achieve a better\nestimation accuracy. We achieve a Mean Absolute Percentage Error (MAPE) of as\nlow as 0.02% for single-layer estimations and 0.68% for whole DNN estimations\nwith less than 10000 training samples. The results demonstrate the superiority\nof our method for single-layer estimations compared to models trained with\nrandomly sampled datasets of the same size.",
      "tldr_zh": "本论文针对使用统计模型评估商用 AI 硬件加速器性能时的数据需求过高问题，提出了一种基于 Performance Representatives (PR) 的智能基准测试方法，以显著减少训练样本数量。\n该方法利用目标硬件架构和初始参数扫描，识别 DNN 层的 PR 作为代表样本，用于基准测试和构建统计性能模型，从而提高估计准确性。\n实验结果显示，该方法在单层估计中实现 Mean Absolute Percentage Error (MAPE) 低至 0.02%，在整个 DNN 估计中为 0.68%，并在使用少于 10000 个样本时优于随机采样方法。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.PF",
      "comment": "Accepted version for: SAMOS'24",
      "pdf_url": "http://arxiv.org/pdf/2406.08330v1",
      "published_date": "2024-06-12 15:34:28 UTC",
      "updated_date": "2024-06-12 15:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:15:00.739120"
    },
    {
      "arxiv_id": "2406.08316v3",
      "title": "Is Programming by Example solved by LLMs?",
      "title_zh": "翻译失败",
      "authors": [
        "Wen-Ding Li",
        "Kevin Ellis"
      ],
      "abstract": "Programming-by-Examples (PBE) aims to generate an algorithm from input-output\nexamples. Such systems are practically and theoretically important: from an\nend-user perspective, they are deployed to millions of people, and from an AI\nperspective, PBE corresponds to a very general form of few-shot inductive\ninference. Given the success of Large Language Models (LLMs) in code-generation\ntasks, we investigate here the extent to which LLMs can be said to have\n\"solved\" PBE. We experiment on classic domains such as lists and strings, and\nan uncommon graphics programming domain not well represented in typical\npretraining data. We find that pretrained models are not effective at PBE, but\nthat they can be fine-tuned for much higher performance, provided the test\nproblems are in-distribution. We analyze empirically what causes these models\nto succeed and fail, and take steps toward understanding how to achieve better\nout-of-distribution generalization. Collectively these results suggest that\nLLMs make strong progress toward solving the typical suite of PBE tasks,\npotentially increasing the flexibility and applicability of PBE systems, while\nalso identifying ways in which LLMs still fall short.",
      "tldr_zh": "本文探讨了大型语言模型(LLMs) 是否已解决 Programming-by-Examples (PBE) 问题，即从输入-输出示例生成算法。研究通过实验评估 LLMs 在经典领域（如列表和字符串）以及不常见图形编程领域的性能，发现预训练模型在 PBE 任务上效果不佳。作者发现，通过 fine-tuning，模型性能可显著提升，但仅限于分布内问题。进一步分析了模型成功和失败的原因，并提出了改进 out-of-distribution 泛化的潜在策略。总体而言，LLMs 在典型 PBE 任务上取得了进展，但仍存在不足，需进一步优化以增强灵活性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08316v3",
      "published_date": "2024-06-12 15:16:40 UTC",
      "updated_date": "2024-11-19 17:49:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:15:13.030238"
    },
    {
      "arxiv_id": "2406.08315v2",
      "title": "Improving Policy Optimization via $\\varepsilon$-Retrain",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Marzari",
        "Priya L. Donti",
        "Changliu Liu",
        "Enrico Marchesini"
      ],
      "abstract": "We present $\\varepsilon$-retrain, an exploration strategy encouraging a\nbehavioral preference while optimizing policies with monotonic improvement\nguarantees. To this end, we introduce an iterative procedure for collecting\nretrain areas -- parts of the state space where an agent did not satisfy the\nbehavioral preference. Our method switches between the typical uniform restart\nstate distribution and the retrain areas using a decaying factor $\\varepsilon$,\nallowing agents to retrain on situations where they violated the preference. We\nalso employ formal verification of neural networks to provably quantify the\ndegree to which agents adhere to these behavioral preferences. Experiments over\nhundreds of seeds across locomotion, power network, and navigation tasks show\nthat our method yields agents that exhibit significant performance and sample\nefficiency improvements.",
      "tldr_zh": "本研究提出了一种名为 $\\varepsilon$-retrain 的探索策略，用于提升策略优化过程，同时确保行为偏好（behavioral preference）的单调改进。该方法通过迭代过程收集 retrain areas——代理未满足行为偏好的状态空间部分，并使用衰减因子 $\\varepsilon$ 在均匀重启状态分布和这些区域之间切换，以强化代理在违规情况下的训练。此外，结合神经网络的形式验证（formal verification）来量化代理对行为偏好的遵守程度。实验在数百个种子上的运动、电力网络和导航任务中表明，该方法显著提高了代理的性能和样本效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2406.08315v2",
      "published_date": "2024-06-12 15:16:26 UTC",
      "updated_date": "2025-04-14 14:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:15:22.631056"
    },
    {
      "arxiv_id": "2406.08311v2",
      "title": "Causality for Tabular Data Synthesis: A High-Order Structure Causal Benchmark Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ruibo Tu",
        "Zineb Senane",
        "Lele Cao",
        "Cheng Zhang",
        "Hedvig Kjellström",
        "Gustav Eje Henter"
      ],
      "abstract": "Tabular synthesis models remain ineffective at capturing complex\ndependencies, and the quality of synthetic data is still insufficient for\ncomprehensive downstream tasks, such as prediction under distribution shifts,\nautomated decision-making, and cross-table understanding. A major challenge is\nthe lack of prior knowledge about underlying structures and high-order\nrelationships in tabular data. We argue that a systematic evaluation on\nhigh-order structural information for tabular data synthesis is the first step\ntowards solving the problem. In this paper, we introduce high-order structural\ncausal information as natural prior knowledge and provide a benchmark framework\nfor the evaluation of tabular synthesis models. The framework allows us to\ngenerate benchmark datasets with a flexible range of data generation processes\nand to train tabular synthesis models using these datasets for further\nevaluation. We propose multiple benchmark tasks, high-order metrics, and causal\ninference tasks as downstream tasks for evaluating the quality of synthetic\ndata generated by the trained models. Our experiments demonstrate to leverage\nthe benchmark framework for evaluating the model capability of capturing\nhigh-order structural causal information. Furthermore, our benchmarking results\nprovide an initial assessment of state-of-the-art tabular synthesis models.\nThey have clearly revealed significant gaps between ideal and actual\nperformance and how baseline methods differ. Our benchmark framework is\navailable at URL https://github.com/TURuibo/CauTabBench.",
      "tldr_zh": "该论文指出，现有的表格合成模型（tabular synthesis models）无法有效捕捉复杂依赖和高阶关系，导致合成数据质量不足，无法支持下游任务如分布偏移下的预测、自动化决策和跨表理解。  \n为了解决这一挑战，论文引入高阶结构因果信息（high-order structural causal information）作为自然先验知识，并提出一个基准框架（benchmark framework），用于生成灵活的数据集、训练模型并进行评估。  \n该框架包括多个基准任务、高阶指标和因果推理任务，作为下游任务来评估合成数据的质量。  \n实验结果显示，该框架能有效评估模型捕捉高阶结构因果信息的能力，并揭示了现有模型的性能差距和基线方法的差异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08311v2",
      "published_date": "2024-06-12 15:12:49 UTC",
      "updated_date": "2024-07-05 06:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:15:37.960757"
    },
    {
      "arxiv_id": "2407.02503v1",
      "title": "Optimizing Deep Reinforcement Learning for Adaptive Robotic Arm Control",
      "title_zh": "针对自适应机械臂控制",
      "authors": [
        "Jonaid Shianifar",
        "Michael Schukat",
        "Karl Mason"
      ],
      "abstract": "In this paper, we explore the optimization of hyperparameters for the Soft\nActor-Critic (SAC) and Proximal Policy Optimization (PPO) algorithms using the\nTree-structured Parzen Estimator (TPE) in the context of robotic arm control\nwith seven Degrees of Freedom (DOF). Our results demonstrate a significant\nenhancement in algorithm performance, TPE improves the success rate of SAC by\n10.48 percentage points and PPO by 34.28 percentage points, where models\ntrained for 50K episodes. Furthermore, TPE enables PPO to converge to a reward\nwithin 95% of the maximum reward 76% faster than without TPE, which translates\nto about 40K fewer episodes of training required for optimal performance. Also,\nthis improvement for SAC is 80% faster than without TPE. This study underscores\nthe impact of advanced hyperparameter optimization on the efficiency and\nsuccess of deep reinforcement learning algorithms in complex robotic tasks.",
      "tldr_zh": "本文研究了使用Tree-structured Parzen Estimator (TPE)优化Soft Actor-Critic (SAC)和Proximal Policy Optimization (PPO)算法的超参数，应用于七自由度（DOF）机器人臂的自适应控制。结果表明，TPE显著提升了算法性能，使SAC的成功率提高10.48个百分点，PPO提高34.28个百分点；同时，PPO的收敛速度加快76%，相当于减少约40K轮训练，而SAC加快80%。这项工作强调了高级超参数优化在提升深度强化学习算法效率和成功率方面的关键作用，尤其在复杂机器人任务中。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.02503v1",
      "published_date": "2024-06-12 15:06:54 UTC",
      "updated_date": "2024-06-12 15:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:15:48.430958"
    },
    {
      "arxiv_id": "2406.11882v1",
      "title": "Applications of Explainable artificial intelligence in Earth system science",
      "title_zh": "可解释人工智能在地球系统科学中的应用",
      "authors": [
        "Feini Huang",
        "Shijie Jiang",
        "Lu Li",
        "Yongkun Zhang",
        "Ye Zhang",
        "Ruqing Zhang",
        "Qingliang Li",
        "Danxi Li",
        "Wei Shangguan",
        "Yongjiu Dai"
      ],
      "abstract": "In recent years, artificial intelligence (AI) rapidly accelerated its\ninfluence and is expected to promote the development of Earth system science\n(ESS) if properly harnessed. In application of AI to ESS, a significant hurdle\nlies in the interpretability conundrum, an inherent problem of black-box nature\narising from the complexity of AI algorithms. To address this, explainable AI\n(XAI) offers a set of powerful tools that make the models more transparent. The\npurpose of this review is twofold: First, to provide ESS scholars, especially\nnewcomers, with a foundational understanding of XAI, serving as a primer to\ninspire future research advances; second, to encourage ESS professionals to\nembrace the benefits of AI, free from preconceived biases due to its lack of\ninterpretability. We begin with elucidating the concept of XAI, along with\ntypical methods. We then delve into a review of XAI applications in the ESS\nliterature, highlighting the important role that XAI has played in facilitating\ncommunication with AI model decisions, improving model diagnosis, and\nuncovering scientific insights. We identify four significant challenges that\nXAI faces within the ESS, and propose solutions. Furthermore, we provide a\ncomprehensive illustration of multifaceted perspectives. Given the unique\nchallenges in ESS, an interpretable hybrid approach that seamlessly integrates\nAI with domain-specific knowledge appears to be a promising way to enhance the\nutility of AI in ESS. A visionary outlook for ESS envisions a harmonious blend\nwhere process-based models govern the known, AI models explore the unknown, and\nXAI bridges the gap by providing explanations.",
      "tldr_zh": "这篇论文探讨了 Explainable AI (XAI) 在 Earth system science (ESS) 中的应用，旨在解决 AI 算法的黑箱问题，提供基础知识并鼓励学者克服对 AI 的偏见。作者回顾了 XAI 的概念和方法，以及其在 ESS 文献中的实际作用，如提升模型决策沟通、改进模型诊断和发现科学洞见。论文识别了 XAI 在 ESS 面临的四个主要挑战，并提出采用可解释的混合方法整合 AI 与领域特定知识，作为未来发展的关键路径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11882v1",
      "published_date": "2024-06-12 15:05:29 UTC",
      "updated_date": "2024-06-12 15:05:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:16:03.161478"
    },
    {
      "arxiv_id": "2406.08269v2",
      "title": "Analyzing constrained LLM through PDFA-learning",
      "title_zh": "通过 PDFA-learning 分析受约束的 LLM",
      "authors": [
        "Matías Carrasco",
        "Franz Mayr",
        "Sergio Yovine",
        "Johny Kidd",
        "Martín Iturbide",
        "Juan Pedro da Silva",
        "Alejo Garat"
      ],
      "abstract": "We define a congruence that copes with null next-symbol probabilities that\narise when the output of a language model is constrained by some means during\ntext generation. We develop an algorithm for efficiently learning the quotient\nwith respect to this congruence and evaluate it on case studies for analyzing\nstatistical properties of LLM.",
      "tldr_zh": "该论文通过 PDFA-learning 方法分析受约束的大型语言模型（LLM），专注于处理文本生成过程中因约束而产生的 null next-symbol probabilities。研究者定义了一个新的 congruence（同余关系）来应对这些问题，并开发了一个高效算法，用于学习该 congruence 的 quotient（商）。实验在案例研究中评估了该方法，以分析 LLM 的统计属性，从而提升了对约束条件下模型行为的理解。",
      "categories": [
        "cs.FL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.FL",
      "comment": "Workshop Paper",
      "pdf_url": "http://arxiv.org/pdf/2406.08269v2",
      "published_date": "2024-06-12 14:35:19 UTC",
      "updated_date": "2024-06-15 04:00:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:16:10.216853"
    },
    {
      "arxiv_id": "2406.08267v2",
      "title": "A deep cut into Split Federated Self-supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Przewięźlikowski",
        "Marcin Osial",
        "Bartosz Zieliński",
        "Marek Śmieja"
      ],
      "abstract": "Collaborative self-supervised learning has recently become feasible in highly\ndistributed environments by dividing the network layers between client devices\nand a central server. However, state-of-the-art methods, such as MocoSFL, are\noptimized for network division at the initial layers, which decreases the\nprotection of the client data and increases communication overhead. In this\npaper, we demonstrate that splitting depth is crucial for maintaining privacy\nand communication efficiency in distributed training. We also show that MocoSFL\nsuffers from a catastrophic quality deterioration for the minimal communication\noverhead. As a remedy, we introduce Momentum-Aligned contrastive Split\nFederated Learning (MonAcoSFL), which aligns online and momentum client models\nduring training procedure. Consequently, we achieve state-of-the-art accuracy\nwhile significantly reducing the communication overhead, making MonAcoSFL more\npractical in real-world scenarios.",
      "tldr_zh": "这篇论文深入探讨了 Split Federated Self-supervised Learning 的问题，指出现有方法如 MocoSFL 倾向于在初始层分割网络，导致客户端数据隐私保护降低和通信开销增加。作者强调网络分割深度对维护隐私和通信效率至关重要，并揭示 MocoSFL 在最小通信开销下会遭受灾难性的性能下降。作为解决方案，引入了 Momentum-Aligned contrastive Split Federated Learning (MonAcoSFL) 方法，通过对齐在线和动量客户端模型来优化训练过程。最终，MonAcoSFL 实现了最先进的准确率，同时显著减少了通信开销，使其在真实分布式环境中更具实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "European Conference on Machine Learning (ECML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08267v2",
      "published_date": "2024-06-12 14:35:13 UTC",
      "updated_date": "2025-03-17 16:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:16:25.478472"
    },
    {
      "arxiv_id": "2406.08246v1",
      "title": "Leveraging Large Language Models for Web Scraping",
      "title_zh": "利用大型语言模型进行网页抓取",
      "authors": [
        "Aman Ahluwalia",
        "Suhrud Wani"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in\nreplicating human tasks and boosting productivity. However, their direct\napplication for data extraction presents limitations due to a prioritisation of\nfluency over factual accuracy and a restricted ability to manipulate specific\ninformation. Therefore to overcome these limitations, this research leverages\nthe knowledge representation power of pre-trained LLMs and the targeted\ninformation access enabled by RAG models, this research investigates a\ngeneral-purpose accurate data scraping recipe for RAG models designed for\nlanguage generation. To capture knowledge in a more modular and interpretable\nway, we use pre trained language models with a latent knowledge retriever,\nwhich allows the model to retrieve and attend over documents from a large\ncorpus. We utilised RAG model architecture and did an in-depth analysis of\ntheir capabilities under three tasks: (i) Semantic Classification of HTML\nelements, (ii) Chunking HTML text for effective understanding, and (iii)\ncomparing results from different LLMs and ranking algorithms. While previous\nwork has developed dedicated architectures and training procedures for HTML\nunderstanding and extraction, we show that LLMs pre-trained on standard natural\nlanguage with an addition of effective chunking, searching and ranking\nalgorithms, can prove to be efficient data scraping tool to extract complex\ndata from unstructured text. Future research directions include addressing the\nchallenges of provenance tracking and dynamic knowledge updates within the\nproposed RAG-based data extraction framework. By overcoming these limitations,\nthis approach holds the potential to revolutionise data extraction from vast\nrepositories of textual information.",
      "tldr_zh": "本研究探讨了利用 Large Language Models (LLMs) 进行 web 抓取的潜力，但强调了 LLMs 在优先流畅性而非事实准确性，以及处理特定信息方面的局限性。研究提出一种基于 RAG 模型的通用数据提取方案，使用预训练 LLMs 结合潜在知识检索器，对 HTML 元素进行语义分类、文本块化和算法比较，从而实现高效的复杂数据提取。结果显示，这种方法在标准自然语言预训练基础上添加搜索和排名算法后，能显著提升抓取性能，并为未来解决 provenance tracking 和 dynamic knowledge updates 挑战提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08246v1",
      "published_date": "2024-06-12 14:15:15 UTC",
      "updated_date": "2024-06-12 14:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:16:38.807772"
    },
    {
      "arxiv_id": "2406.08231v1",
      "title": "Using Deep Convolutional Neural Networks to Detect Rendered Glitches in Video Games",
      "title_zh": "翻译失败",
      "authors": [
        "Carlos Garcia Ling",
        "Konrad Tollmar",
        "Linus Gisslen"
      ],
      "abstract": "In this paper, we present a method using Deep Convolutional Neural Networks\n(DCNNs) to detect common glitches in video games. The problem setting consists\nof an image (800x800 RGB) as input to be classified into one of five defined\nclasses, normal image, or one of four different kinds of glitches (stretched,\nlow resolution, missing and placeholder textures). Using a supervised approach,\nwe train a ShuffleNetV2 using generated data. This work focuses on detecting\ntexture graphical anomalies achieving arguably good performance with an\naccuracy of 86.8\\%, detecting 88\\% of the glitches with a false positive rate\nof 8.7\\%, and with the models being able to generalize and detect glitches even\nin unseen objects. We apply a confidence measure as well to tackle the issue\nwith false positives as well as an effective way of aggregating images to\nachieve better detection in production. The main use of this work is the\npartial automatization of graphical testing in the final stages of video game\ndevelopment.",
      "tldr_zh": "这篇论文提出了一种使用 Deep Convolutional Neural Networks (DCNNs) 的方法，来检测视频游戏中的渲染故障，包括 stretched、low resolution、missing 和 placeholder textures 等四种类型。研究团队通过监督学习训练 ShuffleNetV2 模型，使用生成数据作为训练集，针对 800x800 RGB 图像进行分类。实验结果显示，模型准确率达 86.8%，检测 88% 的故障，同时假阳性率仅 8.7%，并能泛化到未见对象，同时引入置信度措施和图像聚合技术以减少错误警报。该方法的主要贡献是为视频游戏开发的图形测试提供部分自动化解决方案，提高了效率和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures, AAIDE conference",
      "pdf_url": "http://arxiv.org/pdf/2406.08231v1",
      "published_date": "2024-06-12 13:59:45 UTC",
      "updated_date": "2024-06-12 13:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:16:50.140891"
    },
    {
      "arxiv_id": "2406.08226v2",
      "title": "DistilDoc: Knowledge Distillation for Visually-Rich Document Applications",
      "title_zh": "DistilDoc：用于视觉丰富文档应用的知识蒸馏",
      "authors": [
        "Jordy Van Landeghem",
        "Subhajit Maity",
        "Ayan Banerjee",
        "Matthew Blaschko",
        "Marie-Francine Moens",
        "Josep Lladós",
        "Sanket Biswas"
      ],
      "abstract": "This work explores knowledge distillation (KD) for visually-rich document\n(VRD) applications such as document layout analysis (DLA) and document image\nclassification (DIC). While VRD research is dependent on increasingly\nsophisticated and cumbersome models, the field has neglected to study\nefficiency via model compression. Here, we design a KD experimentation\nmethodology for more lean, performant models on document understanding (DU)\ntasks that are integral within larger task pipelines. We carefully selected KD\nstrategies (response-based, feature-based) for distilling knowledge to and from\nbackbones with different architectures (ResNet, ViT, DiT) and capacities (base,\nsmall, tiny). We study what affects the teacher-student knowledge gap and find\nthat some methods (tuned vanilla KD, MSE, SimKD with an apt projector) can\nconsistently outperform supervised student training. Furthermore, we design\ndownstream task setups to evaluate covariate shift and the robustness of\ndistilled DLA models on zero-shot layout-aware document visual question\nanswering (DocVQA). DLA-KD experiments result in a large mAP knowledge gap,\nwhich unpredictably translates to downstream robustness, accentuating the need\nto further explore how to efficiently obtain more semantic document layout\nawareness.",
      "tldr_zh": "本文提出 DistilDoc 框架，利用知识蒸馏 (KD) 技术来提升视觉丰富文档 (VRD) 应用的效率，例如文档布局分析 (DLA) 和文档图像分类 (DIC)，通过模型压缩解决复杂模型的负担问题。研究设计了实验方法，应用响应-based 和特征-based KD 策略到不同架构（如 ResNet、ViT、DiT）和容量（如 base、small、tiny）的骨干网络，发现某些方法（如 tuned vanilla KD、MSE 和 SimKD with an apt projector）能超越监督学生训练。实验结果显示 DLA-KD 存在较大的 mAP 知识差距，且在下游任务如零样本 DocVQA 中的鲁棒性表现不可预测，强调了进一步探索高效获得语义文档布局感知的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ICDAR 2024 (Athens, Greece)",
      "pdf_url": "http://arxiv.org/pdf/2406.08226v2",
      "published_date": "2024-06-12 13:55:12 UTC",
      "updated_date": "2025-03-12 11:58:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:17:03.289935"
    },
    {
      "arxiv_id": "2406.08223v2",
      "title": "Research Trends for the Interplay between Large Language Models and Knowledge Graphs",
      "title_zh": "大型语言模型与知识图谱互动的研究趋势",
      "authors": [
        "Hanieh Khorashadizadeh",
        "Fatima Zahra Amara",
        "Morteza Ezzabady",
        "Frédéric Ieng",
        "Sanju Tiwari",
        "Nandana Mihindukulasooriya",
        "Jinghua Groppe",
        "Soror Sahri",
        "Farah Benamara",
        "Sven Groppe"
      ],
      "abstract": "This survey investigates the synergistic relationship between Large Language\nModels (LLMs) and Knowledge Graphs (KGs), which is crucial for advancing AI's\ncapabilities in understanding, reasoning, and language processing. It aims to\naddress gaps in current research by exploring areas such as KG Question\nAnswering, ontology generation, KG validation, and the enhancement of KG\naccuracy and consistency through LLMs. The paper further examines the roles of\nLLMs in generating descriptive texts and natural language queries for KGs.\nThrough a structured analysis that includes categorizing LLM-KG interactions,\nexamining methodologies, and investigating collaborative uses and potential\nbiases, this study seeks to provide new insights into the combined potential of\nLLMs and KGs. It highlights the importance of their interaction for improving\nAI applications and outlines future research directions.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 和 Knowledge Graphs (KGs) 之间的协同关系，以提升 AI 在理解、推理和语言处理方面的能力。论文通过结构化分析，包括分类 LLM-KG 互动、检查方法、调查协作用途和潜在偏差，填补了当前研究的空白，并探讨了领域如 KG Question Answering、ontology generation 和 KG validation，以及 LLMs 在生成描述性文本和自然语言查询方面的作用。研究突出了这种互动对改善 AI 应用的关键重要性，并为未来研究方向提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08223v2",
      "published_date": "2024-06-12 13:52:38 UTC",
      "updated_date": "2024-08-08 13:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:17:13.905781"
    },
    {
      "arxiv_id": "2406.08222v2",
      "title": "A Sociotechnical Lens for Evaluating Computer Vision Models: A Case Study on Detecting and Reasoning about Gender and Emotion",
      "title_zh": "翻译失败",
      "authors": [
        "Sha Luo",
        "Sang Jung Kim",
        "Zening Duan",
        "Kaiping Chen"
      ],
      "abstract": "In the evolving landscape of computer vision (CV) technologies, the automatic\ndetection and interpretation of gender and emotion in images is a critical area\nof study. This paper investigates social biases in CV models, emphasizing the\nlimitations of traditional evaluation metrics such as precision, recall, and\naccuracy. These metrics often fall short in capturing the complexities of\ngender and emotion, which are fluid and culturally nuanced constructs. Our\nstudy proposes a sociotechnical framework for evaluating CV models,\nincorporating both technical performance measures and considerations of social\nfairness. Using a dataset of 5,570 images related to vaccination and climate\nchange, we empirically compared the performance of various CV models, including\ntraditional models like DeepFace and FER, and generative models like GPT-4\nVision. Our analysis involved manually validating the gender and emotional\nexpressions in a subset of images to serve as benchmarks. Our findings reveal\nthat while GPT-4 Vision outperforms other models in technical accuracy for\ngender classification, it exhibits discriminatory biases, particularly in\nresponse to transgender and non-binary personas. Furthermore, the model's\nemotion detection skew heavily towards positive emotions, with a notable bias\ntowards associating female images with happiness, especially when prompted by\nmale personas. These findings underscore the necessity of developing more\ncomprehensive evaluation criteria that address both validity and discriminatory\nbiases in CV models. Our proposed framework provides guidelines for researchers\nto critically assess CV tools, ensuring their application in communication\nresearch is both ethical and effective. The significant contribution of this\nstudy lies in its emphasis on a sociotechnical approach, advocating for CV\ntechnologies that support social good and mitigate biases rather than\nperpetuate them.",
      "tldr_zh": "本研究通过社会技术视角（sociotechnical lens）评估计算机视觉（CV）模型在性别和情感检测中的偏差，强调传统指标如 precision、recall 和 accuracy 的局限性，因为它们忽略了这些概念的流动性（fluid）和文化细微性。研究提出一个 sociotechnical framework，将技术性能与社会公平相结合，并使用 5,570 张疫苗和气候变化相关图像数据集，比较了 DeepFace、FER 和 GPT-4 Vision 等模型，通过手动验证进行实证分析。结果显示，GPT-4 Vision 在性别分类的技术准确性上优于其他模型，但存在歧视性偏差，特别是针对 transgender 和 non-binary 人士，且情感检测偏向积极情绪，如将女性图像与幸福过度关联。该框架为研究者提供指导，确保 CV 模型的应用更具伦理性和社会效益。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08222v2",
      "published_date": "2024-06-12 13:52:30 UTC",
      "updated_date": "2024-11-21 18:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:17:27.468269"
    },
    {
      "arxiv_id": "2406.08200v3",
      "title": "Asynchronous Voice Anonymization Using Adversarial Perturbation On Speaker Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Wang",
        "Liping Chen",
        "Kong AiK Lee",
        "Zhen-Hua Ling"
      ],
      "abstract": "Voice anonymization has been developed as a technique for preserving privacy\nby replacing the speaker's voice in a speech signal with that of a\npseudo-speaker, thereby obscuring the original voice attributes from machine\nrecognition and human perception. In this paper, we focus on altering the voice\nattributes against machine recognition while retaining human perception. We\nreferred to this as the asynchronous voice anonymization. To this end, a speech\ngeneration framework incorporating a speaker disentanglement mechanism is\nemployed to generate the anonymized speech. The speaker attributes are altered\nthrough adversarial perturbation applied on the speaker embedding, while human\nperception is preserved by controlling the intensity of perturbation.\nExperiments conducted on the LibriSpeech dataset showed that the speaker\nattributes were obscured with their human perception preserved for 60.71% of\nthe processed utterances.",
      "tldr_zh": "本研究提出了一种异步语音匿名化（asynchronous voice anonymization）方法，通过在说话者嵌入（speaker embedding）上应用对抗性扰动（adversarial perturbation）来改变语音属性，从而针对机器识别隐藏原始说话者信息，同时保留人类感知。方法采用一个包含说话者分离机制的语音生成框架，并通过控制扰动强度确保语音的自然性。实验在 LibriSpeech 数据集上显示，60.71% 的处理语音成功模糊了说话者属性，同时保持了人类感知的完整性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "accpeted by Interspeech2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08200v3",
      "published_date": "2024-06-12 13:33:24 UTC",
      "updated_date": "2024-11-12 06:46:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:17:35.233427"
    },
    {
      "arxiv_id": "2406.08184v1",
      "title": "MobileAgentBench: An Efficient and User-Friendly Benchmark for Mobile LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Luyuan Wang",
        "Yongyu Deng",
        "Yiwei Zha",
        "Guodong Mao",
        "Qinmin Wang",
        "Tianchen Min",
        "Wei Chen",
        "Shoufa Chen"
      ],
      "abstract": "Large language model (LLM)-based mobile agents are increasingly popular due\nto their capability to interact directly with mobile phone Graphic User\nInterfaces (GUIs) and their potential to autonomously manage daily tasks.\nDespite their promising prospects in both academic and industrial sectors,\nlittle research has focused on benchmarking the performance of existing mobile\nagents, due to the inexhaustible states of apps and the vague definition of\nfeasible action sequences. To address this challenge, we propose an efficient\nand user-friendly benchmark, MobileAgentBench, designed to alleviate the burden\nof extensive manual testing. We initially define 100 tasks across 10\nopen-source apps, categorized by multiple levels of difficulty. Subsequently,\nwe evaluate several existing mobile agents, including AppAgent and MobileAgent,\nto thoroughly and systematically compare their performance. All materials are\naccessible on our project webpage: https://MobileAgentBench.github.io,\ncontributing to the advancement of both academic and industrial fields.",
      "tldr_zh": "该论文提出 MobileAgentBench，这是一个高效且用户友好的基准测试框架，用于评估基于 LLM 的移动代理在手机图形用户界面 (GUIs) 交互中的性能。该框架定义了 100 个任务，跨越 10 个开源应用，按难度分级，以解决应用状态无限和动作序列模糊等挑战。研究团队评估了现有代理如 AppAgent 和 MobileAgent，并系统比较了它们的表现，所有材料在项目网页上公开，以推动学术和工业领域的进展。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08184v1",
      "published_date": "2024-06-12 13:14:50 UTC",
      "updated_date": "2024-06-12 13:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:17:48.460778"
    },
    {
      "arxiv_id": "2406.08171v1",
      "title": "Continuous fake media detection: adapting deepfake detectors to new generative techniques",
      "title_zh": "持续假媒体检测：使 deepfake 检测器适应新的生成技术",
      "authors": [
        "Francesco Tassone",
        "Luca Maiano",
        "Irene Amerini"
      ],
      "abstract": "Generative techniques continue to evolve at an impressively high rate, driven\nby the hype about these technologies. This rapid advancement severely limits\nthe application of deepfake detectors, which, despite numerous efforts by the\nscientific community, struggle to achieve sufficiently robust performance\nagainst the ever-changing content. To address these limitations, in this paper,\nwe propose an analysis of two continuous learning techniques on a Short and a\nLong sequence of fake media. Both sequences include a complex and heterogeneous\nrange of deepfakes generated from GANs, computer graphics techniques, and\nunknown sources. Our study shows that continual learning could be important in\nmitigating the need for generalizability. In fact, we show that, although with\nsome limitations, continual learning methods help to maintain good performance\nacross the entire training sequence. For these techniques to work in a\nsufficiently robust way, however, it is necessary that the tasks in the\nsequence share similarities. In fact, according to our experiments, the order\nand similarity of the tasks can affect the performance of the models over time.\nTo address this problem, we show that it is possible to group tasks based on\ntheir similarity. This small measure allows for a significant improvement even\nin longer sequences. This result suggests that continual techniques can be\ncombined with the most promising detection methods, allowing them to catch up\nwith the latest generative techniques. In addition to this, we propose an\noverview of how this learning approach can be integrated into a deepfake\ndetection pipeline for continuous integration and continuous deployment\n(CI/CD). This allows you to keep track of different funds, such as social\nnetworks, new generative tools, or third-party datasets, and through the\nintegration of continuous learning, allows constant maintenance of the\ndetectors.",
      "tldr_zh": "该研究探讨了如何使用连续学习（continual learning）技术来适应快速演变的生成技术，从而提升 deepfake 检测器的鲁棒性。作者在短序列和长序列的假媒体数据集上分析了两种连续学习方法，这些数据集包括由 GANs、计算机图形技术和未知来源生成的复杂 deepfake，并发现任务间的相似性和顺序会影响模型性能。实验结果显示，通过基于相似性分组任务，可以显著改善检测性能，并在更长序列中维持较高准确率；此外，论文提出将此方法整合到 deepfake 检测管道的 CI/CD 流程中，实现对社交网络和新生成工具的持续监控和更新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08171v1",
      "published_date": "2024-06-12 13:04:06 UTC",
      "updated_date": "2024-06-12 13:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:18:01.406065"
    },
    {
      "arxiv_id": "2406.08155v2",
      "title": "QuantMoE-Bench: Examining Post-Training Quantization for Mixture-of-Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Pingzhi Li",
        "Xiaolong Jin",
        "Zhen Tan",
        "Yu Cheng",
        "Tianlong Chen"
      ],
      "abstract": "Mixture-of-Experts (MoE) is a promising way to scale up the learning capacity\nof large language models. It increases the number of parameters while keeping\nFLOPs nearly constant during inference through sparse activation. Yet, it still\nsuffers from significant memory overheads due to the vast parameter size,\nnecessitating model compression techniques. Post-training quantization offers a\npowerful approach for model compression. Existing methods adopt a fixed\nquantization precision for the entire MoE model. This rigid setup can lead to\nsuboptimal performance, without considering the inherent sparse structure. For\nexample, MoE's sparse routing mechanism leads to different activation patterns,\nwhere shared experts are accessed by all tokens while token-conditioned experts\nare selectively activated. This activation disparity suggests different\nquantization requirements, with consistently activated shared experts\npotentially needing higher precision to maintain model quality. In this paper,\nwe study a fine-grained precision setup for MoE quantization. We explore MoE\nstructure-aware quantization heuristics, ranging from coarse (e.g., MoE layers)\nto fine granularity (e.g., linear layers). Our investigations reveal critical\nprinciples, where different MoE structures require varying numbers of bits for\neffective quantization. Conclusions are supported by extensive benchmarking\nacross two representative MoE models and six tasks including commonsense\nreasoning and natural language understanding. We further show that an MoE\nquantized in a fined-grained mixed precision achieved state-of-the-art 65.35%\nperformance on average compared to the baseline 64.30% (i.e., GPTQ). Moreover,\nbased on the findings, we introduce novel data-driven techniques for optimizing\nbit allocation in MoE quantization, including the outlier-aware linear layer\nscorer and MoE block importance predictor.",
      "tldr_zh": "该论文探讨了Mixture-of-Experts (MoE) 模型的后训练量化问题，指出现有固定精度方法忽略了MoE的稀疏结构（如共享专家和条件专家的激活差异），可能导致性能不佳。\n研究者提出细粒度的MoE结构感知量化启发式方法，从粗粒度（如MoE层）到细粒度（如线性层）进行优化实验。\n实验结果显示，不同MoE结构需要不同的量化位数，并在两个MoE模型和六种任务（如常识推理和自然语言理解）上的基准测试中，细粒度混合精度量化达到了65.35%的SOTA性能，比基线GPTQ的64.30%有所提升。\n此外，论文引入了数据驱动技术，包括outlier-aware线性层评分器和MoE块重要性预测器，以优化位分配。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Our code for reproducing all our experiments is provided at\n  https://github.com/UNITES-Lab/moe-quantization",
      "pdf_url": "http://arxiv.org/pdf/2406.08155v2",
      "published_date": "2024-06-12 12:44:48 UTC",
      "updated_date": "2025-02-25 18:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:18:15.258190"
    },
    {
      "arxiv_id": "2406.08148v1",
      "title": "Probing Implicit Bias in Semi-gradient Q-learning: Visualizing the Effective Loss Landscapes via the Fokker--Planck Equation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyu Yin",
        "Fei Wen",
        "Peilin Liu",
        "Tao Luo"
      ],
      "abstract": "Semi-gradient Q-learning is applied in many fields, but due to the absence of\nan explicit loss function, studying its dynamics and implicit bias in the\nparameter space is challenging. This paper introduces the Fokker--Planck\nequation and employs partial data obtained through sampling to construct and\nvisualize the effective loss landscape within a two-dimensional parameter\nspace. This visualization reveals how the global minima in the loss landscape\ncan transform into saddle points in the effective loss landscape, as well as\nthe implicit bias of the semi-gradient method. Additionally, we demonstrate\nthat saddle points, originating from the global minima in loss landscape, still\nexist in the effective loss landscape under high-dimensional parameter spaces\nand neural network settings. This paper develop a novel approach for probing\nimplicit bias in semi-gradient Q-learning.",
      "tldr_zh": "本文研究了 Semi-gradient Q-learning 中的隐式偏差问题，由于缺乏显式损失函数，其在参数空间中的动态和偏差难以分析。作者引入 Fokker--Planck equation，并通过部分采样数据构建和可视化二维参数空间的有效损失景观，结果显示损失景观中的全局最小点可能转化为鞍点，从而揭示了 semi-gradient 方法的隐式偏差。此外，在高维参数空间和神经网络设置下，这种鞍点现象依然存在，本文开发了一种新方法来有效探查这些偏差。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08148v1",
      "published_date": "2024-06-12 12:37:53 UTC",
      "updated_date": "2024-06-12 12:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:18:28.997207"
    },
    {
      "arxiv_id": "2406.08134v1",
      "title": "Making AI Intelligible: Philosophical Foundations",
      "title_zh": "翻译失败",
      "authors": [
        "Herman Cappelen",
        "Josh Dever"
      ],
      "abstract": "Can humans and artificial intelligences share concepts and communicate?\n'Making AI Intelligible' shows that philosophical work on the metaphysics of\nmeaning can help answer these questions. Herman Cappelen and Josh Dever use the\nexternalist tradition in philosophy to create models of how AIs and humans can\nunderstand each other. In doing so, they illustrate ways in which that\nphilosophical tradition can be improved.\n  The questions addressed in the book are not only theoretically interesting,\nbut the answers have pressing practical implications. Many important decisions\nabout human life are now influenced by AI. In giving that power to AI, we\npresuppose that AIs can track features of the world that we care about (for\nexample, creditworthiness, recidivism, cancer, and combatants). If AIs can\nshare our concepts, that will go some way towards justifying this reliance on\nAI. This ground-breaking study offers insight into how to take some first steps\ntowards achieving Interpretable AI.",
      "tldr_zh": "这篇论文探讨了人类和AI是否能共享概念并有效沟通，作者Herman Cappelen和Josh Dever使用外部主义（externalist tradition）哲学传统构建模型，以阐明AI和人类相互理解的机制，并改进这一哲学框架。研究强调，这些问题不仅理论上引人入胜，还具有实际影响，因为AI在影响人类决策（如评估信用worthiness、recidivism、cancer或combatants）时，需要追踪我们关心的世界特征。最终，该研究为实现可解释AI（Interpretable AI）提供了开创性见解，部分justify了对AI的依赖，并为未来AI应用奠定哲学基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Book published with Oxford University Press, 184 pages (2021), Open\n  Access",
      "pdf_url": "http://arxiv.org/pdf/2406.08134v1",
      "published_date": "2024-06-12 12:25:04 UTC",
      "updated_date": "2024-06-12 12:25:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:18:40.812026"
    },
    {
      "arxiv_id": "2406.08124v2",
      "title": "Legend: Leveraging Representation Engineering to Annotate Safety Margin for Preference Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Duanyu Feng",
        "Bowen Qin",
        "Chen Huang",
        "Youcheng Huang",
        "Zheng Zhang",
        "Wenqiang Lei"
      ],
      "abstract": "The success of the reward model in distinguishing between responses with\nsubtle safety differences depends critically on the high-quality preference\ndataset, which should capture the fine-grained nuances of harmful and harmless\nresponses. This motivates the need to develop a dataset involving preference\nmargins, which accurately quantify how harmless one response is compared to\nanother. In this paper, we take the first step to propose an effective and\ncost-efficient framework to promote the margin-enhanced preference dataset\ndevelopment. Our framework, Legend, Leverages representation engineering to\nannotate preference datasets. It constructs the specific direction within the\nLLM's embedding space that represents safety. By leveraging this safety\ndirection, Legend can then leverage the semantic distances of paired responses\nalong this direction to annotate margins automatically. We experimentally\ndemonstrate our effectiveness in both reward modeling and harmless alignment\nfor LLMs. Legend also stands out for its efficiency, requiring only the\ninference time rather than additional training. This efficiency allows for\neasier implementation and scalability, making Legend particularly valuable for\npractical applications in aligning LLMs with safe conversations.",
      "tldr_zh": "本文提出 Legend 框架，利用 representation engineering 在 LLM 的嵌入空间中构建一个表示安全的特定方向，从而自动标注偏好数据集的安全 margin（safety margin）。该方法通过计算成对响应的语义距离来量化响应之间的安全差异，提供高效的偏好数据集增强。实验结果表明，Legend 在 reward modeling 和 harmless alignment 中表现出色，仅需推理时间而非额外训练，便于实际应用和扩展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Our code is available at https://github.com/colfeng/Legend",
      "pdf_url": "http://arxiv.org/pdf/2406.08124v2",
      "published_date": "2024-06-12 12:06:32 UTC",
      "updated_date": "2024-12-18 03:22:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:02.779345"
    },
    {
      "arxiv_id": "2406.08116v2",
      "title": "Supportiveness-based Knowledge Rewriting for Retrieval-augmented Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Zile Qiao",
        "Wei Ye",
        "Yong Jiang",
        "Tong Mo",
        "Pengjun Xie",
        "Weiping Li",
        "Fei Huang",
        "Shikun Zhang"
      ],
      "abstract": "Retrieval-augmented language models (RALMs) have recently shown great\npotential in mitigating the limitations of implicit knowledge in LLMs, such as\nuntimely updating of the latest expertise and unreliable retention of long-tail\nknowledge. However, since the external knowledge base, as well as the\nretriever, can not guarantee reliability, potentially leading to the knowledge\nretrieved not being helpful or even misleading for LLM generation. In this\npaper, we introduce Supportiveness-based Knowledge Rewriting (SKR), a robust\nand pluggable knowledge rewriter inherently optimized for LLM generation.\nSpecifically, we introduce the novel concept of \"supportiveness\"--which\nrepresents how effectively a knowledge piece facilitates downstream tasks--by\nconsidering the perplexity impact of augmented knowledge on the response text\nof a white-box LLM. Based on knowledge supportiveness, we first design a\ntraining data curation strategy for our rewriter model, effectively identifying\nand filtering out poor or irrelevant rewrites (e.g., with low supportiveness\nscores) to improve data efficacy. We then introduce the direct preference\noptimization (DPO) algorithm to align the generated rewrites to optimal\nsupportiveness, guiding the rewriter model to summarize augmented content that\nbetter improves the final response. Comprehensive evaluations across six\npopular knowledge-intensive tasks and four LLMs have demonstrated the\neffectiveness and superiority of SKR. With only 7B parameters, SKR has shown\nbetter knowledge rewriting capability over GPT-4, the current state-of-the-art\ngeneral-purpose LLM.",
      "tldr_zh": "本研究针对 Retrieval-augmented language models (RALMs) 的问题，即外部知识可能不可靠导致 LLM 生成不准确，提出了一种基于 Supportiveness-based Knowledge Rewriting (SKR) 的鲁棒知识重写方法。SKR 通过引入“supportiveness”概念（基于增强知识对响应文本的 perplexity 影响）来评估知识的有效性，并设计了训练数据整理策略以过滤低质量重写，同时采用 direct preference optimization (DPO) 算法优化重写内容，以更好地提升最终响应质量。在六个知识密集型任务和四个 LLMs 的全面评估中，SKR 仅用 7B 参数就超过了 GPT-4 的知识重写能力，展示了其有效性和优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08116v2",
      "published_date": "2024-06-12 11:52:35 UTC",
      "updated_date": "2024-10-03 18:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:05.743735"
    },
    {
      "arxiv_id": "2406.08115v1",
      "title": "Resource Allocation and Workload Scheduling for Large-Scale Distributed Deep Learning: A Survey",
      "title_zh": "大规模分布式深度学习的资源分配和工作负载调度：综述",
      "authors": [
        "Feng Liang",
        "Zhen Zhang",
        "Haifeng Lu",
        "Chengming Li",
        "Victor C. M. Leung",
        "Yanyi Guo",
        "Xiping Hu"
      ],
      "abstract": "With rapidly increasing distributed deep learning workloads in large-scale\ndata centers, efficient distributed deep learning framework strategies for\nresource allocation and workload scheduling have become the key to\nhigh-performance deep learning. The large-scale environment with large volumes\nof datasets, models, and computational and communication resources raises\nvarious unique challenges for resource allocation and workload scheduling in\ndistributed deep learning, such as scheduling complexity, resource and workload\nheterogeneity, and fault tolerance. To uncover these challenges and\ncorresponding solutions, this survey reviews the literature, mainly from 2019\nto 2024, on efficient resource allocation and workload scheduling strategies\nfor large-scale distributed DL. We explore these strategies by focusing on\nvarious resource types, scheduling granularity levels, and performance goals\nduring distributed training and inference processes. We highlight critical\nchallenges for each topic and discuss key insights of existing technologies. To\nillustrate practical large-scale resource allocation and workload scheduling in\nreal distributed deep learning scenarios, we use a case study of training large\nlanguage models. This survey aims to encourage computer science, artificial\nintelligence, and communications researchers to understand recent advances and\nexplore future research directions for efficient framework strategies for\nlarge-scale distributed deep learning.",
      "tldr_zh": "这篇调查回顾了2019年至2024年的文献，探讨了大型分布式深度学习中资源分配和工作负载调度的策略，以应对挑战如调度复杂性、资源和任务异质性以及故障容忍。研究聚焦于不同资源类型、调度粒度水平以及性能目标，涵盖分布式训练和推理过程，并总结了现有技术的关键见解。作者通过训练大型语言模型的案例研究，展示了这些策略在实际场景中的应用，并旨在推动计算机科学、人工智能和通信领域的未来研究方向。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08115v1",
      "published_date": "2024-06-12 11:51:44 UTC",
      "updated_date": "2024-06-12 11:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:17.353953"
    },
    {
      "arxiv_id": "2406.08112v1",
      "title": "Codecfake: An Initial Dataset for Detecting LLM-based Deepfake Audio",
      "title_zh": "Codecfake：用于检测基于LLM的深度伪造音频的初始数据集",
      "authors": [
        "Yi Lu",
        "Yuankun Xie",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Jianhua Tao",
        "Zhiyong Wang",
        "Xin Qi",
        "Xuefei Liu",
        "Yongwei Li",
        "Yukun Liu",
        "Xiaopeng Wang",
        "Shuchen Shi"
      ],
      "abstract": "With the proliferation of Large Language Model (LLM) based deepfake audio,\nthere is an urgent need for effective detection methods. Previous deepfake\naudio generation methods typically involve a multi-step generation process,\nwith the final step using a vocoder to predict the waveform from handcrafted\nfeatures. However, LLM-based audio is directly generated from discrete neural\ncodecs in an end-to-end generation process, skipping the final step of vocoder\nprocessing. This poses a significant challenge for current audio deepfake\ndetection (ADD) models based on vocoder artifacts. To effectively detect\nLLM-based deepfake audio, we focus on the core of the generation process, the\nconversion from neural codec to waveform. We propose Codecfake dataset, which\nis generated by seven representative neural codec methods. Experiment results\nshow that codec-trained ADD models exhibit a 41.406% reduction in average equal\nerror rate compared to vocoder-trained ADD models on the Codecfake test set.",
      "tldr_zh": "本论文针对 LLM-based deepfake audio 的检测挑战，指出传统方法依赖 vocoder artifacts 而无法有效应对 LLM 直接从 neural codec 生成的音频。研究者提出 Codecfake 数据集，该数据集由七种代表性 neural codec 方法生成，用于专注于音频生成的核心过程。实验结果显示，codec-trained ADD 模型在 Codecfake 测试集上比 vocoder-trained ADD 模型的平均 equal error rate 降低了 41.406%，为改进 LLM-based 音频深度伪造检测提供了新基准。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by INTERSPEECH 2024. arXiv admin note: substantial text\n  overlap with arXiv:2405.04880",
      "pdf_url": "http://arxiv.org/pdf/2406.08112v1",
      "published_date": "2024-06-12 11:47:23 UTC",
      "updated_date": "2024-06-12 11:47:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:29.616891"
    },
    {
      "arxiv_id": "2406.08105v3",
      "title": "Prediction of the Realisation of an Information Need: An EEG Study",
      "title_zh": "信息需求实现的预测：一项 EEG 研究",
      "authors": [
        "Niall McGuire",
        "Dr Yashar Moshfeghi"
      ],
      "abstract": "One of the foundational goals of Information Retrieval (IR) is to satisfy\nsearchers' Information Needs (IN). Understanding how INs physically manifest\nhas long been a complex and elusive process. However, recent studies utilising\nElectroencephalography (EEG) data have provided real-time insights into the\nneural processes associated with INs. Unfortunately, they have yet to\ndemonstrate how this insight can practically benefit the search experience. As\nsuch, within this study, we explore the ability to predict the realisation of\nIN within EEG data across 14 subjects whilst partaking in a Question-Answering\n(Q/A) task. Furthermore, we investigate the combinations of EEG features that\nyield optimal predictive performance, as well as identify regions within the\nQ/A queries where a subject's realisation of IN is more pronounced. The\nfindings from this work demonstrate that EEG data is sufficient for the\nreal-time prediction of the realisation of an IN across all subjects with an\naccuracy of 73.5% (SD 2.6%) and on a per-subject basis with an accuracy of\n90.1% (SD 22.1%). This work helps to close the gap by bridging theoretical\nneuroscientific advancements with tangible improvements in information\nretrieval practices, paving the way for real-time prediction of the realisation\nof IN.",
      "tldr_zh": "本研究探讨了使用 Electroencephalography (EEG) 数据预测信息需求 (Information Needs, IN) 实现的可能性，旨在提升信息检索 (IR) 系统的实际应用。研究通过对14名受试者在 Question-Answering (Q/A) 任务中的EEG数据进行分析，考察了不同EEG特征组合的预测性能，并识别了查询中IN实现更明显的区域。结果显示，整体预测准确率达73.5% (SD 2.6%)，而每个受试者的准确率则为90.1% (SD 22.1%)，证明EEG数据足以实现IN的实时预测。该工作桥接了神经科学理论与IR实践的鸿沟，为未来信息检索体验的优化提供了新路径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08105v3",
      "published_date": "2024-06-12 11:34:19 UTC",
      "updated_date": "2024-06-18 09:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:51.183300"
    },
    {
      "arxiv_id": "2406.10287v1",
      "title": "Security Decisions for Cyber-Physical Systems based on Solving Critical Node Problems with Vulnerable Nodes",
      "title_zh": "翻译失败",
      "authors": [
        "Jens Otto",
        "Niels Grüttemeier",
        "Felix Specht"
      ],
      "abstract": "Cyber-physical production systems consist of highly specialized software and\nhardware components. Most components and communication protocols are not built\naccording to the Secure by Design principle. Therefore, their resilience to\ncyberattacks is limited. This limitation can be overcome with common\noperational pictures generated by security monitoring solutions. These pictures\nprovide information about communication relationships of both attacked and\nnon-attacked devices, and serve as a decision-making basis for security\nofficers in the event of cyberattacks. The objective of these decisions is to\nisolate a limited number of devices rather than shutting down the entire\nproduction system. In this work, we propose and evaluate a concept for finding\nthe devices to isolate. Our approach is based on solving the Critical Node Cut\nProblem with Vulnerable Vertices (CNP-V) - an NP-hard computational problem\noriginally motivated by isolating vulnerable people in case of a pandemic. To\nthe best of our knowledge, this is the first work on applying CNP-V in context\nof cybersecurity.",
      "tldr_zh": "本研究针对网络物理系统(Cyber-Physical Systems)的安全问题，提出了一种基于解决Critical Node Cut Problem with Vulnerable Vertices (CNP-V)的方法，以帮助决策者在网络攻击中隔离有限数量的设备，而不是关闭整个系统。  \n该方法利用安全监控生成的共同操作图片，分析受攻击和未受攻击设备的通信关系，从而识别关键节点进行隔离。  \n作为首个将NP-hard问题CNP-V应用于网络安全领域的作品，该概念的评估展示了其在提升系统弹性方面的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10287v1",
      "published_date": "2024-06-12 11:31:46 UTC",
      "updated_date": "2024-06-12 11:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:19:53.845813"
    },
    {
      "arxiv_id": "2406.08100v1",
      "title": "Multimodal Table Understanding",
      "title_zh": "多模态表格理解",
      "authors": [
        "Mingyu Zheng",
        "Xinwei Feng",
        "Qingyi Si",
        "Qiaoqiao She",
        "Zheng Lin",
        "Wenbin Jiang",
        "Weiping Wang"
      ],
      "abstract": "Although great progress has been made by previous table understanding methods\nincluding recent approaches based on large language models (LLMs), they rely\nheavily on the premise that given tables must be converted into a certain text\nsequence (such as Markdown or HTML) to serve as model input. However, it is\ndifficult to access such high-quality textual table representations in some\nreal-world scenarios, and table images are much more accessible. Therefore, how\nto directly understand tables using intuitive visual information is a crucial\nand urgent challenge for developing more practical applications. In this paper,\nwe propose a new problem, multimodal table understanding, where the model needs\nto generate correct responses to various table-related requests based on the\ngiven table image. To facilitate both the model training and evaluation, we\nconstruct a large-scale dataset named MMTab, which covers a wide spectrum of\ntable images, instructions and tasks. On this basis, we develop Table-LLaVA, a\ngeneralist tabular multimodal large language model (MLLM), which significantly\noutperforms recent open-source MLLM baselines on 23 benchmarks under held-in\nand held-out settings. The code and data is available at this\nhttps://github.com/SpursGoZmy/Table-LLaVA",
      "tldr_zh": "该论文提出“multimodal table understanding”新问题，旨在基于表格图像直接生成对各种表格相关请求的响应，以解决现有方法依赖文本转换（如 Markdown）的局限性。研究者构建了大规模数据集 MMTab，涵盖广泛的表格图像、指令和任务，并开发了 generalist tabular multimodal large language model（MLLM）——Table-LLaVA。实验结果显示，Table-LLaVA 在 23 个基准测试中显著优于开源 MLLM 基线，在 held-in 和 held-out 设置下表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 16 figures, ACL 2024 main conference, camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2406.08100v1",
      "published_date": "2024-06-12 11:27:03 UTC",
      "updated_date": "2024-06-12 11:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:20:06.833481"
    },
    {
      "arxiv_id": "2406.08099v1",
      "title": "Confidence Interval Estimation of Predictive Performance in the Context of AutoML",
      "title_zh": "在 AutoML 语境中预测性能的置信区间估计",
      "authors": [
        "Konstantinos Paraschakis",
        "Andrea Castellani",
        "Giorgos Borboudakis",
        "Ioannis Tsamardinos"
      ],
      "abstract": "Any supervised machine learning analysis is required to provide an estimate\nof the out-of-sample predictive performance. However, it is imperative to also\nprovide a quantification of the uncertainty of this performance in the form of\na confidence or credible interval (CI) and not just a point estimate. In an\nAutoML setting, estimating the CI is challenging due to the ``winner's curse\",\ni.e., the bias of estimation due to cross-validating several machine learning\npipelines and selecting the winning one. In this work, we perform a comparative\nevaluation of 9 state-of-the-art methods and variants in CI estimation in an\nAutoML setting on a corpus of real and simulated datasets. The methods are\ncompared in terms of inclusion percentage (does a 95\\% CI include the true\nperformance at least 95\\% of the time), CI tightness (tighter CIs are\npreferable as being more informative), and execution time. The evaluation is\nthe first one that covers most, if not all, such methods and extends previous\nwork to imbalanced and small-sample tasks. In addition, we present a variant,\ncalled BBC-F, of an existing method (the Bootstrap Bias Correction, or BBC)\nthat maintains the statistical properties of the BBC but is more\ncomputationally efficient. The results support that BBC-F and BBC dominate the\nother methods in all metrics measured.",
      "tldr_zh": "本文研究了在 AutoML 环境中估计预测性能置信区间 (CI) 的挑战，特别是由于 \"winner's curse\"（模型选择偏差）导致的估计偏差问题。作者比较了 9 种最先进的方法及其变体，在真实和模拟数据集上进行评估，指标包括包含百分比（95% CI 是否至少95% 包含真实性能）、CI 紧密度（更紧的 CI 更具信息性）和执行时间，这是首个覆盖这些方法的全面评估，并扩展到不平衡和小样本任务。研究提出了一种新变体 BBC-F（基于 Bootstrap Bias Correction），它保持了 BBC 的统计特性，但显著提高了计算效率。结果显示，BBC-F 和 BBC 在所有评估指标上优于其他方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AutoML 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2406.08099v1",
      "published_date": "2024-06-12 11:26:29 UTC",
      "updated_date": "2024-06-12 11:26:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:20:18.127914"
    },
    {
      "arxiv_id": "2406.08080v1",
      "title": "AustroTox: A Dataset for Target-Based Austrian German Offensive Language Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Pia Pachinger",
        "Janis Goldzycher",
        "Anna Maria Planitzer",
        "Wojciech Kusa",
        "Allan Hanbury",
        "Julia Neidhardt"
      ],
      "abstract": "Model interpretability in toxicity detection greatly profits from token-level\nannotations. However, currently such annotations are only available in English.\nWe introduce a dataset annotated for offensive language detection sourced from\na news forum, notable for its incorporation of the Austrian German dialect,\ncomprising 4,562 user comments. In addition to binary offensiveness\nclassification, we identify spans within each comment constituting vulgar\nlanguage or representing targets of offensive statements. We evaluate\nfine-tuned language models as well as large language models in a zero- and\nfew-shot fashion. The results indicate that while fine-tuned models excel in\ndetecting linguistic peculiarities such as vulgar dialect, large language\nmodels demonstrate superior performance in detecting offensiveness in\nAustroTox. We publish the data and code.",
      "tldr_zh": "本研究引入了AustroTox数据集，该数据集包含4,562条来自新闻论坛的奥地利德语用户评论，用于目标导向的攻击性语言检测，除了二元攻击性分类，还标注了粗俗语言跨度和攻击目标。研究评估了微调语言模型和大型语言模型（LLM）在zero-shot和few-shot设置下的性能，结果显示微调模型在检测方言和粗俗语言方面更具优势，而LLM在整体攻击性检测上表现出色。该数据集及其代码已公开发布，以促进相关领域的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of the Association for Computational\n  Linguistics: ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08080v1",
      "published_date": "2024-06-12 11:04:11 UTC",
      "updated_date": "2024-06-12 11:04:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:20:35.044048"
    },
    {
      "arxiv_id": "2406.08074v3",
      "title": "A Concept-Based Explainability Framework for Large Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jayneel Parekh",
        "Pegah Khayatan",
        "Mustafa Shukor",
        "Alasdair Newson",
        "Matthieu Cord"
      ],
      "abstract": "Large multimodal models (LMMs) combine unimodal encoders and large language\nmodels (LLMs) to perform multimodal tasks. Despite recent advancements towards\nthe interpretability of these models, understanding internal representations of\nLMMs remains largely a mystery. In this paper, we present a novel framework for\nthe interpretation of LMMs. We propose a dictionary learning based approach,\napplied to the representation of tokens. The elements of the learned dictionary\ncorrespond to our proposed concepts. We show that these concepts are well\nsemantically grounded in both vision and text. Thus we refer to these as\n``multi-modal concepts''. We qualitatively and quantitatively evaluate the\nresults of the learnt concepts. We show that the extracted multimodal concepts\nare useful to interpret representations of test samples. Finally, we evaluate\nthe disentanglement between different concepts and the quality of grounding\nconcepts visually and textually. Our code is publicly available at\nhttps://github.com/mshukor/xl-vlms",
      "tldr_zh": "这篇论文提出一个基于概念的解释框架，用于理解大型多模态模型(LMMs)的内部表示，旨在解决LMMs中视觉和文本模态的解释性问题。框架采用dictionary learning的方法应用于标记表示，以学习多模态概念，这些概念在视觉和文本上语义上良好接地。实验通过定性和定量评估证明，这些概念有助于解释测试样本的表示，并评估了概念之间的disentanglement以及视觉和文本grounding的质量；代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08074v3",
      "published_date": "2024-06-12 10:48:53 UTC",
      "updated_date": "2024-11-30 10:48:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:20:43.804311"
    },
    {
      "arxiv_id": "2406.08070v2",
      "title": "CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyungjin Chung",
        "Jeongsol Kim",
        "Geon Yeong Park",
        "Hyelin Nam",
        "Jong Chul Ye"
      ],
      "abstract": "Classifier-free guidance (CFG) is a fundamental tool in modern diffusion\nmodels for text-guided generation. Although effective, CFG has notable\ndrawbacks. For instance, DDIM with CFG lacks invertibility, complicating image\nediting; furthermore, high guidance scales, essential for high-quality outputs,\nfrequently result in issues like mode collapse. Contrary to the widespread\nbelief that these are inherent limitations of diffusion models, this paper\nreveals that the problems actually stem from the off-manifold phenomenon\nassociated with CFG, rather than the diffusion models themselves. More\nspecifically, inspired by the recent advancements of diffusion model-based\ninverse problem solvers (DIS), we reformulate text-guidance as an inverse\nproblem with a text-conditioned score matching loss and develop CFG++, a novel\napproach that tackles the off-manifold challenges inherent in traditional CFG.\nCFG++ features a surprisingly simple fix to CFG, yet it offers significant\nimprovements, including better sample quality for text-to-image generation,\ninvertibility, smaller guidance scales, reduced mode collapse, etc.\nFurthermore, CFG++ enables seamless interpolation between unconditional and\nconditional sampling at lower guidance scales, consistently outperforming\ntraditional CFG at all scales. Moreover, CFG++ can be easily integrated into\nhigh-order diffusion solvers and naturally extends to distilled diffusion\nmodels. Experimental results confirm that our method significantly enhances\nperformance in text-to-image generation, DDIM inversion, editing, and solving\ninverse problems, suggesting a wide-ranging impact and potential applications\nin various fields that utilize text guidance. Project Page:\nhttps://cfgpp-diffusion.github.io/.",
      "tldr_zh": "本论文揭示了Classifier-free guidance (CFG) 在扩散模型中的问题，如DDIM的不可逆性和高指导规模导致的模式崩溃，这些源于off-manifold现象，而非扩散模型本身。受扩散模型逆问题求解器 (DIS) 启发，作者将文本指导重新表述为一个逆问题，并提出CFG++方法，通过简单修正来解决off-manifold挑战。CFG++显著提升样本质量、增强可逆性、减少模式崩溃，并允许在较低指导规模下实现无条件和条件采样的平滑插值。该方法易于集成到高阶扩散求解器和蒸馏扩散模型中，实验结果显示其在文本到图像生成、DDIM逆问题、图像编辑和逆问题求解中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 21 figures. Project Page:\n  https://cfgpp-diffusion.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.08070v2",
      "published_date": "2024-06-12 10:40:10 UTC",
      "updated_date": "2024-09-12 04:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:20:57.603074"
    },
    {
      "arxiv_id": "2406.08069v3",
      "title": "Explore-Go: Leveraging Exploration for Generalisation in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Max Weltevrede",
        "Felix Kaubek",
        "Matthijs T. J. Spaan",
        "Wendelin Böhmer"
      ],
      "abstract": "One of the remaining challenges in reinforcement learning is to develop\nagents that can generalise to novel scenarios they might encounter once\ndeployed. This challenge is often framed in a multi-task setting where agents\ntrain on a fixed set of tasks and have to generalise to new tasks. Recent work\nhas shown that in this setting increased exploration during training can be\nleveraged to increase the generalisation performance of the agent. This makes\nsense when the states encountered during testing can actually be explored\nduring training. In this paper, we provide intuition why exploration can also\nbenefit generalisation to states that cannot be explicitly encountered during\ntraining. Additionally, we propose a novel method Explore-Go that exploits this\nintuition by increasing the number of states on which the agent trains.\nExplore-Go effectively increases the starting state distribution of the agent\nand as a result can be used in conjunction with most existing on-policy or\noff-policy reinforcement learning algorithms. We show empirically that our\nmethod can increase generalisation performance in an illustrative environment\nand on the Procgen benchmark.",
      "tldr_zh": "该论文探讨了强化学习中的泛化挑战，强调通过训练期间增加探索可以提升代理在新任务上的表现，即使测试状态无法在训练中直接遇到。作者提出Explore-Go方法，该方法通过扩展代理的起始状态分布来增加训练状态数量，并可与大多数on-policy或off-policy算法结合。实验结果显示，Explore-Go在示例环境和Procgen基准上显著提高了代理的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08069v3",
      "published_date": "2024-06-12 10:39:31 UTC",
      "updated_date": "2024-09-18 10:04:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:21:17.583820"
    },
    {
      "arxiv_id": "2406.08035v2",
      "title": "LVBench: An Extreme Long Video Understanding Benchmark",
      "title_zh": "LVBench：极端长视频理解基准",
      "authors": [
        "Weihan Wang",
        "Zehai He",
        "Wenyi Hong",
        "Yean Cheng",
        "Xiaohan Zhang",
        "Ji Qi",
        "Xiaotao Gu",
        "Shiyu Huang",
        "Bin Xu",
        "Yuxiao Dong",
        "Ming Ding",
        "Jie Tang"
      ],
      "abstract": "Recent progress in multimodal large language models has markedly enhanced the\nunderstanding of short videos (typically under one minute), and several\nevaluation datasets have emerged accordingly. However, these advancements fall\nshort of meeting the demands of real-world applications such as embodied\nintelligence for long-term decision-making, in-depth movie reviews and\ndiscussions, and live sports commentary, all of which require comprehension of\nlong videos spanning several hours. To address this gap, we introduce LVBench,\na benchmark specifically designed for long video understanding. Our dataset\ncomprises publicly sourced videos and encompasses a diverse set of tasks aimed\nat long video comprehension and information extraction. LVBench is designed to\nchallenge multimodal models to demonstrate long-term memory and extended\ncomprehension capabilities. Our extensive evaluations reveal that current\nmultimodal models still underperform on these demanding long video\nunderstanding tasks. Through LVBench, we aim to spur the development of more\nadvanced models capable of tackling the complexities of long video\ncomprehension. Our data and code are publicly available at:\nhttps://lvbench.github.io.",
      "tldr_zh": "本论文引入了 LVBench，这是一个针对极端长视频理解的基准数据集，旨在解决当前多模态大型语言模型在处理数小时长视频（如机器人决策、电影评论和体育解说）时的局限性。数据集基于公开来源的视频，涵盖多样任务，包括长视频理解和信息提取，以测试模型的长时记忆和扩展理解能力。实验评估显示，现有的多模态模型在这些挑战性任务上表现不佳；通过 LVBench，研究者希望推动更先进模型的发展，并已公开数据和代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08035v2",
      "published_date": "2024-06-12 09:36:52 UTC",
      "updated_date": "2024-10-23 06:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:21:19.695669"
    },
    {
      "arxiv_id": "2406.08024v1",
      "title": "Fewer Tokens and Fewer Videos: Extending Video Understanding Abilities in Large Vision-Language Models",
      "title_zh": "更少的标记和更少的视频：扩展大型视觉语言模型中的视频理解能力",
      "authors": [
        "Shimin Chen",
        "Yitian Yuan",
        "Shaoxiang Chen",
        "Zequn Jie",
        "Lin Ma"
      ],
      "abstract": "Amidst the advancements in image-based Large Vision-Language Models\n(image-LVLM), the transition to video-based models (video-LVLM) is hindered by\nthe limited availability of quality video data. This paper addresses the\nchallenge by leveraging the visual commonalities between images and videos to\nefficiently evolve image-LVLMs into video-LVLMs. We present a cost-effective\nvideo-LVLM that enhances model architecture, introduces innovative training\nstrategies, and identifies the most effective types of video instruction data.\nOur innovative weighted token sampler significantly compresses the visual token\nnumbers of each video frame, effectively cutting computational expenses. We\nalso find that judiciously using just 10% of the video data, compared to prior\nvideo-LVLMs, yields impressive results during various training phases.\nMoreover, we delve into the influence of video instruction data in\nlimited-resource settings, highlighting the significance of incorporating video\ntraining data that emphasizes temporal understanding to enhance model\nperformance. The resulting Fewer Tokens and Fewer Videos LVLM (FTFV-LVLM)\nexhibits exceptional performance across video and image benchmarks, validating\nour model's design and training approaches.",
      "tldr_zh": "这篇论文探讨了从图像-based Large Vision-Language Models (image-LVLM) 转向视频-based 模型 (video-LVLM) 的挑战，主要是由于高质量视频数据的稀缺。作者提出了一种成本有效的 video-LVLM，通过优化模型架构、创新训练策略（如 weighted token sampler 来压缩视频帧的视觉 token 数量）和选择高效的视频指令数据，仅使用 10% 的视频数据即可显著提升模型性能。实验结果显示，该模型 FTFV-LVLM 在视频和图像基准测试中表现出色，强调了强调时间理解的训练数据对增强视频理解能力的重要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08024v1",
      "published_date": "2024-06-12 09:22:45 UTC",
      "updated_date": "2024-06-12 09:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:21:32.860872"
    },
    {
      "arxiv_id": "2406.08018v1",
      "title": "SHACL2FOL: An FOL Toolkit for SHACL Decision Problems",
      "title_zh": "SHACL2FOL：一个 FOL 工具包，用于 SHACL 决策问题",
      "authors": [
        "Paolo Pareti"
      ],
      "abstract": "Recent studies on the Shapes Constraint Language (SHACL), a W3C specification\nfor validating RDF graphs, rely on translating the language into first-order\nlogic in order to provide formally-grounded solutions to the validation,\ncontainment and satisfiability decision problems. Continuing on this line of\nresearch, we introduce SHACL2FOL, the first automatic tool that (i) translates\nSHACL documents into FOL sentences and (ii) computes the answer to the two\nstatic analysis problems of satisfiability and containment; it also allow to\ntest the validity of a graph with respect to a set of constraints. By\nintegrating with existing theorem provers, such as E and Vampire, the tool\ncomputes the answer to the aforementioned decision problems and outputs the\ncorresponding first-order logic theories in the standard TPTP format. We\nbelieve this tool can contribute to further theoretical studies of SHACL, by\nproviding an automatic first-order logic interpretation of its semantics, while\nalso benefiting SHACL practitioners, by supplying static analysis capabilities\nto help the creation and management of SHACL constraints.",
      "tldr_zh": "这篇论文介绍了 SHACL2FOL 工具，一种用于处理 SHACL 决策问题的 FOL 工具包，它将 SHACL 文档翻译成 FOL 句子，并自动计算可满足性、包含性和图形验证问题。工具通过集成定理证明器如 E 和 Vampire，输出标准 TPTP 格式的 FOL 理论，从而支持 SHACL 的静态分析。SHACL2FOL 的开发有助于推进 SHACL 的理论研究，并为从业者提供便利，提升约束创建和管理的能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.08018v1",
      "published_date": "2024-06-12 09:20:25 UTC",
      "updated_date": "2024-06-12 09:20:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:21:44.775879"
    },
    {
      "arxiv_id": "2406.10285v2",
      "title": "I Don't Know You, But I Can Catch You: Real-Time Defense against Diverse Adversarial Patches for Object Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Zijin Lin",
        "Yue Zhao",
        "Kai Chen",
        "Jinwen He"
      ],
      "abstract": "Deep neural networks (DNNs) have revolutionized the field of computer vision\nlike object detection with their unparalleled performance. However, existing\nresearch has shown that DNNs are vulnerable to adversarial attacks. In the\nphysical world, an adversary could exploit adversarial patches to implement a\nHiding Attack (HA) which patches the target object to make it disappear from\nthe detector, and an Appearing Attack (AA) which fools the detector into\nmisclassifying the patch as a specific object. Recently, many defense methods\nfor detectors have been proposed to mitigate the potential threats of\nadversarial patches. However, such methods still have limitations in\ngeneralization, robustness and efficiency. Most defenses are only effective\nagainst the HA, leaving the detector vulnerable to the AA.\n  In this paper, we propose \\textit{NutNet}, an innovative model for detecting\nadversarial patches, with high generalization, robustness and efficiency. With\nexperiments for six detectors including YOLOv2-v4, SSD, Faster RCNN and DETR on\nboth digital and physical domains, the results show that our proposed method\ncan effectively defend against both the HA and AA, with only 0.4\\% sacrifice of\nthe clean performance. We compare NutNet with four baseline defense methods for\ndetectors, and our method exhibits an average defense performance that is over\n2.4 times and 4.7 times higher than existing approaches for HA and AA,\nrespectively. In addition, NutNet only increases the inference time by 8\\%,\nwhich can meet the real-time requirements of the detection systems. Demos of\nNutNet are available at: \\url{https://sites.google.com/view/nutnet}.",
      "tldr_zh": "该研究针对深度神经网络(DNNs)在物体检测中的易受对抗性补丁攻击问题，提出了NutNet模型，用于实时防御Hiding Attack (HA)和Appearing Attack (AA)。NutNet通过创新的检测机制实现了高泛化、鲁棒性和效率，仅在六种检测器（如YOLOv2-v4、SSD、Faster RCNN和DETR）上增加了8%的推理时间。实验结果显示，NutNet在数字和物理领域有效抵御两种攻击，与基线方法相比，防御性能平均提升2.4倍（HA）和4.7倍（AA），仅牺牲0.4%的干净性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.10285v2",
      "published_date": "2024-06-12 09:16:19 UTC",
      "updated_date": "2024-06-25 02:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:21:57.244675"
    },
    {
      "arxiv_id": "2406.08009v1",
      "title": "OpenObj: Open-Vocabulary Object-Level Neural Radiance Fields with Fine-Grained Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Yinan Deng",
        "Jiahui Wang",
        "Jingyu Zhao",
        "Jianyu Dou",
        "Yi Yang",
        "Yufeng Yue"
      ],
      "abstract": "In recent years, there has been a surge of interest in open-vocabulary 3D\nscene reconstruction facilitated by visual language models (VLMs), which\nshowcase remarkable capabilities in open-set retrieval. However, existing\nmethods face some limitations: they either focus on learning point-wise\nfeatures, resulting in blurry semantic understanding, or solely tackle\nobject-level reconstruction, thereby overlooking the intricate details of the\nobject's interior. To address these challenges, we introduce OpenObj, an\ninnovative approach to build open-vocabulary object-level Neural Radiance\nFields (NeRF) with fine-grained understanding. In essence, OpenObj establishes\na robust framework for efficient and watertight scene modeling and\ncomprehension at the object-level. Moreover, we incorporate part-level features\ninto the neural fields, enabling a nuanced representation of object interiors.\nThis approach captures object-level instances while maintaining a fine-grained\nunderstanding. The results on multiple datasets demonstrate that OpenObj\nachieves superior performance in zero-shot semantic segmentation and retrieval\ntasks. Additionally, OpenObj supports real-world robotics tasks at multiple\nscales, including global movement and local manipulation.",
      "tldr_zh": "本研究提出OpenObj，一种创新方法，用于构建开放词汇的对象级Neural Radiance Fields (NeRF)，以解决现有视觉语言模型(VLMs)基于3D场景重建的局限性，如模糊语义理解和忽略对象内部细节。OpenObj框架通过整合部分级特征，实现高效的密封场景建模和细粒度对象内部表示，从而在对象级捕获实例并提升整体理解。实验结果显示，OpenObj在多个数据集上表现出色，显著提升零样本语义分割和检索任务的性能，并支持真实机器人应用，包括全局移动和本地操作。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 7figures. Project Url: https://openobj.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2406.08009v1",
      "published_date": "2024-06-12 08:59:33 UTC",
      "updated_date": "2024-06-12 08:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:22:07.720058"
    },
    {
      "arxiv_id": "2406.08002v2",
      "title": "Efficient Adaptation in Mixed-Motive Environments via Hierarchical Opponent Modeling and Planning",
      "title_zh": "通过分层对手建模和规划在混合动机环境中的",
      "authors": [
        "Yizhe Huang",
        "Anji Liu",
        "Fanqi Kong",
        "Yaodong Yang",
        "Song-Chun Zhu",
        "Xue Feng"
      ],
      "abstract": "Despite the recent successes of multi-agent reinforcement learning (MARL)\nalgorithms, efficiently adapting to co-players in mixed-motive environments\nremains a significant challenge. One feasible approach is to hierarchically\nmodel co-players' behavior based on inferring their characteristics. However,\nthese methods often encounter difficulties in efficient reasoning and\nutilization of inferred information. To address these issues, we propose\nHierarchical Opponent modeling and Planning (HOP), a novel multi-agent\ndecision-making algorithm that enables few-shot adaptation to unseen policies\nin mixed-motive environments. HOP is hierarchically composed of two modules: an\nopponent modeling module that infers others' goals and learns corresponding\ngoal-conditioned policies, and a planning module that employs Monte Carlo Tree\nSearch (MCTS) to identify the best response. Our approach improves efficiency\nby updating beliefs about others' goals both across and within episodes and by\nusing information from the opponent modeling module to guide planning.\nExperimental results demonstrate that in mixed-motive environments, HOP\nexhibits superior few-shot adaptation capabilities when interacting with\nvarious unseen agents, and excels in self-play scenarios. Furthermore, the\nemergence of social intelligence during our experiments underscores the\npotential of our approach in complex multi-agent environments.",
      "tldr_zh": "本研究针对多智能体强化学习(MARL)算法在混合动机环境中适应共同玩家的挑战，提出了一种新型决策算法Hierarchical Opponent modeling and Planning (HOP)。HOP 通过分层结构，包括对手建模模块（推断其他智能体的目标并学习目标条件策略）和规划模块（使用Monte Carlo Tree Search (MCTS)识别最佳响应），实现了跨剧集和剧集内更新信念的效率提升。实验结果显示，HOP 在与各种未见智能体互动时表现出色少样本适应能力，并在自玩场景中领先，同时展示了社会智能的涌现。总之，该方法为复杂多智能体环境中的高效决策提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08002v2",
      "published_date": "2024-06-12 08:48:06 UTC",
      "updated_date": "2024-07-12 15:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:22:21.044053"
    },
    {
      "arxiv_id": "2406.08527v2",
      "title": "Optimized Feature Generation for Tabular Data via LLMs with Decision Tree Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyun Nam",
        "Kyuyoung Kim",
        "Seunghyuk Oh",
        "Jihoon Tack",
        "Jaehyung Kim",
        "Jinwoo Shin"
      ],
      "abstract": "In tabular prediction tasks, tree-based models combined with automated\nfeature engineering methods often outperform deep learning approaches that rely\non learned representations. While these feature engineering techniques are\neffective, they typically depend on a pre-defined search space and primarily\nuse validation scores for feature selection, thereby missing valuable insights\nfrom previous experiments. To address these limitations, we propose a novel\ntabular learning framework that utilizes large language models (LLMs), termed\nOptimizing Column feature generator with decision Tree reasoning (OCTree). Our\nkey idea is to leverage the reasoning capabilities of LLMs to identify\neffective feature generation rules without manually specifying the search space\nand provide language-based reasoning information highlighting past experiments\nas feedback for iterative rule improvements. We use decision trees to convey\nthis reasoning information, as they can be easily represented in natural\nlanguage, effectively providing knowledge from prior experiments (i.e., the\nimpact of the generated features on performance) to the LLMs. Our empirical\nresults demonstrate that OCTree consistently enhances the performance of\nvarious prediction models across diverse benchmarks, outperforming competing\nautomated feature engineering methods. Code is available at\nhttps://github.com/jaehyun513/OCTree.",
      "tldr_zh": "这篇论文提出了一种名为 OCTree 的新框架，利用大型语言模型 (LLMs) 和决策树 (decision trees) 推理来优化表格数据的特征生成，解决了传统方法依赖预定义搜索空间和忽略先前实验洞见的问题。核心创新在于使用 LLMs 的推理能力自动识别有效特征规则，并通过决策树以自然语言形式提供反馈（如特征对性能的影响），实现迭代改进。实验结果显示，OCTree 显著提升了各种预测模型在不同基准上的表现，优于现有自动特征工程方法，并提供了开源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.08527v2",
      "published_date": "2024-06-12 08:31:34 UTC",
      "updated_date": "2024-11-18 05:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:22:36.310744"
    },
    {
      "arxiv_id": "2406.07990v1",
      "title": "Blowfish: Topological and statistical signatures for quantifying ambiguity in semantic search",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Roland Barillot",
        "Alex De Castro"
      ],
      "abstract": "This works reports evidence for the topological signatures of ambiguity in\nsentence embeddings that could be leveraged for ranking and/or explanation\npurposes in the context of vector search and Retrieval Augmented Generation\n(RAG) systems. We proposed a working definition of ambiguity and designed an\nexperiment where we have broken down a proprietary dataset into collections of\nchunks of varying size - 3, 5, and 10 lines and used the different collections\nsuccessively as queries and answers sets. It allowed us to test the signatures\nof ambiguity with removal of confounding factors. Our results show that proxy\nambiguous queries (size 10 queries against size 3 documents) display different\ndistributions of homologies 0 and 1 based features than proxy clear queries\n(size 5 queries against size 10 documents). We then discuss those results in\nterms increased manifold complexity and/or approximately discontinuous\nembedding submanifolds. Finally we propose a strategy to leverage those\nfindings as a new scoring strategy of semantic similarities.",
      "tldr_zh": "本文提出 Blowfish 框架，通过拓扑和统计签名来量化语义搜索中的模糊性，以提升向量搜索和 Retrieval Augmented Generation (RAG) 系统的排名和解释能力。研究者定义了模糊性的工作定义，并设计实验将专有数据集分解成不同大小的块（3、5 和 10 行），作为查询和答案集，以消除混杂因素。结果显示，代理模糊查询（如大小 10 查询对大小 3 文档）在同源性 0 和 1 特征的分布上与代理清晰查询（如大小 5 查询对大小 10 文档）显著不同，这可能与流形复杂性或近似不连续嵌入子流形相关。最后，该框架建议一种新策略，利用这些拓扑签名作为语义相似性评分方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07990v1",
      "published_date": "2024-06-12 08:26:30 UTC",
      "updated_date": "2024-06-12 08:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:22:48.980854"
    },
    {
      "arxiv_id": "2406.07979v2",
      "title": "Heuristic Learning with Graph Neural Networks: A Unified Framework for Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Juzheng Zhang",
        "Lanning Wei",
        "Zhen Xu",
        "Quanming Yao"
      ],
      "abstract": "Link prediction is a fundamental task in graph learning, inherently shaped by\nthe topology of the graph. While traditional heuristics are grounded in graph\ntopology, they encounter challenges in generalizing across diverse graphs.\nRecent research efforts have aimed to leverage the potential of heuristics, yet\na unified formulation accommodating both local and global heuristics remains\nundiscovered. Drawing insights from the fact that both local and global\nheuristics can be represented by adjacency matrix multiplications, we propose a\nunified matrix formulation to accommodate and generalize various heuristics. We\nfurther propose the Heuristic Learning Graph Neural Network (HL-GNN) to\nefficiently implement the formulation. HL-GNN adopts intra-layer propagation\nand inter-layer connections, allowing it to reach a depth of around 20 layers\nwith lower time complexity than GCN. Extensive experiments on the Planetoid,\nAmazon, and OGB datasets underscore the effectiveness and efficiency of HL-GNN.\nIt outperforms existing methods by a large margin in prediction performance.\nAdditionally, HL-GNN is several orders of magnitude faster than\nheuristic-inspired methods while requiring only a few trainable parameters. The\ncase study further demonstrates that the generalized heuristics and learned\nweights are highly interpretable.",
      "tldr_zh": "本研究提出了一种统一的框架，用于解决图学习中链接预测（Link Prediction）的挑战，该框架将传统启发式方法（如基于图拓扑的本地和全局启发式）整合进一个矩阵公式中，以提升泛化能力。研究引入了 Heuristic Learning Graph Neural Network (HL-GNN)，该模型通过层内传播（intra-layer propagation）和层间连接（inter-layer connections）实现高效计算，支持深度达20层的网络，同时比 GCN 具有更低的时复杂性。实验在 Planetoid、Amazon 和 OGB 数据集上表明，HL-GNN 在预测性能上大幅优于现有方法，且计算速度快几个数量级，仅需少量可训练参数；此外，案例研究证明其泛化启发式和学习权重具有高度可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07979v2",
      "published_date": "2024-06-12 08:05:45 UTC",
      "updated_date": "2024-06-14 10:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:22:59.272791"
    },
    {
      "arxiv_id": "2406.07971v2",
      "title": "It Takes Two: On the Seamlessness between Reward and Policy Model in RLHF",
      "title_zh": "It Takes Two",
      "authors": [
        "Taiming Lu",
        "Lingfeng Shen",
        "Xinyu Yang",
        "Weiting Tan",
        "Beidi Chen",
        "Huaxiu Yao"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) involves training policy\nmodels (PMs) and reward models (RMs) to align language models with human\npreferences. Instead of focusing solely on PMs and RMs independently, we\npropose to examine their interactions during fine-tuning, introducing the\nconcept of seamlessness. Our study starts with observing the saturation\nphenomenon, where continual improvements in RM and PM do not translate into\nRLHF progress. Our analysis shows that RMs fail to assign proper scores to PM\nresponses, resulting in a 35% mismatch rate with human preferences,\nhighlighting a significant discrepancy between PM and RM. To measure\nseamlessness between PM and RM without human effort, we propose an automatic\nmetric, SEAM. SEAM quantifies the discrepancies between PM and RM judgments\ninduced by data samples. We validate the effectiveness of SEAM in data\nselection and model augmentation. Our experiments demonstrate that (1) using\nSEAM-filtered data for RL training improves RLHF performance by 4.5%, and (2)\nSEAM-guided model augmentation results in a 4% performance improvement over\nstandard augmentation methods.",
      "tldr_zh": "该研究探讨了RLHF（Reinforcement Learning from Human Feedback）中政策模型（PMs）和奖励模型（RMs）之间的互动，引入了seamlessness概念，以解决持续改进RM和PM却无法转化为RLHF进步的饱和现象。作者发现RM在评分时与人类偏好存在35%的不匹配，并提出自动指标SEAM来量化PM和RM判断间的差异，而无需人工干预。实验验证显示，使用SEAM过滤数据可将RLHF性能提升4.5%，而SEAM指导的模型增强方法比标准方法提高4%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07971v2",
      "published_date": "2024-06-12 07:52:17 UTC",
      "updated_date": "2024-06-13 05:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:23:10.049056"
    },
    {
      "arxiv_id": "2406.08526v1",
      "title": "IMFL-AIGC: Incentive Mechanism Design for Federated Learning Empowered by Artificial Intelligence Generated Content",
      "title_zh": "翻译失败",
      "authors": [
        "Guangjing Huang",
        "Qiong Wu",
        "Jingyi Li",
        "Xu Chen"
      ],
      "abstract": "Federated learning (FL) has emerged as a promising paradigm that enables\nclients to collaboratively train a shared global model without uploading their\nlocal data. To alleviate the heterogeneous data quality among clients,\nartificial intelligence-generated content (AIGC) can be leveraged as a novel\ndata synthesis technique for FL model performance enhancement. Due to various\ncosts incurred by AIGC-empowered FL (e.g., costs of local model computation and\ndata synthesis), however, clients are usually reluctant to participate in FL\nwithout adequate economic incentives, which leads to an unexplored critical\nissue for enabling AIGC-empowered FL. To fill this gap, we first devise a data\nquality assessment method for data samples generated by AIGC and rigorously\nanalyze the convergence performance of FL model trained using a blend of\nauthentic and AI-generated data samples. We then propose a data quality-aware\nincentive mechanism to encourage clients' participation. In light of\ninformation asymmetry incurred by clients' private multi-dimensional\nattributes, we investigate clients' behavior patterns and derive the server's\noptimal incentive strategies to minimize server's cost in terms of both model\naccuracy loss and incentive payments for both complete and incomplete\ninformation scenarios. Numerical results demonstrate that our proposed\nmechanism exhibits highest training accuracy and reduces up to 53.34% of the\nserver's cost with real-world datasets, compared with existing benchmark\nmechanisms.",
      "tldr_zh": "该论文提出IMFL-AIGC框架，利用Artificial Intelligence Generated Content (AIGC)提升Federated Learning (FL)模型性能，以缓解客户端数据质量异质性问题，但由于参与成本高，设计了数据质量感知的激励机制。研究首先开发了AIGC生成数据样本的质量评估方法，并分析了使用真实数据和AI生成数据混合训练的FL模型收敛性能。针对客户端私有多维属性的信息不对称，论文推导出服务器的最优激励策略，以最小化服务器成本，包括模型准确性损失和激励支付，在完整和不完整信息场景下均适用。实验结果显示，该机制在真实数据集上实现了最高的训练准确率，并将服务器成本降低多达53.34%，优于现有基准机制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted by IEEE Transactions on Mobile Computing",
      "pdf_url": "http://arxiv.org/pdf/2406.08526v1",
      "published_date": "2024-06-12 07:47:22 UTC",
      "updated_date": "2024-06-12 07:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:23:24.887271"
    },
    {
      "arxiv_id": "2406.07962v2",
      "title": "Toward a Method to Generate Capability Ontologies from Natural Language Descriptions",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Miguel Vieira da Silva",
        "Aljosha Köcher",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "To achieve a flexible and adaptable system, capability ontologies are\nincreasingly leveraged to describe functions in a machine-interpretable way.\nHowever, modeling such complex ontological descriptions is still a manual and\nerror-prone task that requires a significant amount of effort and ontology\nexpertise. This contribution presents an innovative method to automate\ncapability ontology modeling using Large Language Models (LLMs), which have\nproven to be well suited for such tasks. Our approach requires only a natural\nlanguage description of a capability, which is then automatically inserted into\na predefined prompt using a few-shot prompting technique. After prompting an\nLLM, the resulting capability ontology is automatically verified through\nvarious steps in a loop with the LLM to check the overall correctness of the\ncapability ontology. First, a syntax check is performed, then a check for\ncontradictions, and finally a check for hallucinations and missing ontology\nelements. Our method greatly reduces manual effort, as only the initial natural\nlanguage description and a final human review and possible correction are\nnecessary, thereby streamlining the capability ontology generation process.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用 Large Language Models (LLMs) 从自然语言描述自动生成 capability ontologies，从而减少手动建模的复杂性和错误风险。方法采用 few-shot prompting 技术，将描述插入预定义提示后，由 LLM 生成本体，并通过循环验证过程（包括语法检查、矛盾检查以及幻觉和缺失元素检测）确保其正确性。该方法极大简化了流程，仅需初始自然语言描述和最终人工审查，提高了效率和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2406.07962v2",
      "published_date": "2024-06-12 07:41:44 UTC",
      "updated_date": "2024-10-18 07:34:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:23:33.882726"
    },
    {
      "arxiv_id": "2406.07961v3",
      "title": "Accurate Explanation Model for Image Classifiers using Class Association Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Ruitao Xie",
        "Jingbang Chen",
        "Limai Jiang",
        "Rui Xiao",
        "Yi Pan",
        "Yunpeng Cai"
      ],
      "abstract": "Image classification is a primary task in data analysis where explainable\nmodels are crucially demanded in various applications. Although amounts of\nmethods have been proposed to obtain explainable knowledge from the black-box\nclassifiers, these approaches lack the efficiency of extracting global\nknowledge regarding the classification task, thus is vulnerable to local traps\nand often leads to poor accuracy. In this study, we propose a generative\nexplanation model that combines the advantages of global and local knowledge\nfor explaining image classifiers. We develop a representation learning method\ncalled class association embedding (CAE), which encodes each sample into a pair\nof separated class-associated and individual codes. Recombining the individual\ncode of a given sample with altered class-associated code leads to a synthetic\nreal-looking sample with preserved individual characters but modified\nclass-associated features and possibly flipped class assignments. A\nbuilding-block coherency feature extraction algorithm is proposed that\nefficiently separates class-associated features from individual ones. The\nextracted feature space forms a low-dimensional manifold that visualizes the\nclassification decision patterns. Explanation on each individual sample can be\nthen achieved in a counter-factual generation manner which continuously\nmodifies the sample in one direction, by shifting its class-associated code\nalong a guided path, until its classification outcome is changed. We compare\nour method with state-of-the-art ones on explaining image classification tasks\nin the form of saliency maps, demonstrating that our method achieves higher\naccuracies. The code is available at https://github.com/xrt11/XAI-CODE.",
      "tldr_zh": "本研究针对图像分类器的可解释性问题，提出了一种基于 Class Association Embedding (CAE) 的精确解释模型，该模型结合全局和本地知识来提升解释效率。CAE 通过将样本编码为类关联代码和个体代码，实现样本的重组生成，从而创建真实外观的合成样本以修改类关联特征。研究还开发了 Building-block Coherency 特征提取算法，分离特征并形成低维流形，用于可视化分类决策，并通过反事实生成方式逐步修改样本以解释其分类结果。实验结果显示，该方法在显著性图(saliency maps)上比现有方法表现出更高的准确性，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 2024 IEEE 40th International Conference on Data\n  Engineering (ICDE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2406.07961v3",
      "published_date": "2024-06-12 07:41:00 UTC",
      "updated_date": "2024-12-30 07:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:23:47.187854"
    },
    {
      "arxiv_id": "2406.08525v1",
      "title": "A Mathematical Certification for Positivity Conditions in Neural Networks with Applications to Partial Monotonicity and Ethical AI",
      "title_zh": "神经网络中正性条件的数学认证及其在部分单调性和伦理 AI 中的应用",
      "authors": [
        "Alejandro Polo-Molina",
        "David Alfaya",
        "Jose Portela"
      ],
      "abstract": "Artificial Neural Networks (ANNs) have become a powerful tool for modeling\ncomplex relationships in large-scale datasets. However, their black-box nature\nposes ethical challenges. In certain situations, ensuring ethical predictions\nmight require following specific partial monotonic constraints. However,\ncertifying if an already-trained ANN is partially monotonic is challenging.\nTherefore, ANNs are often disregarded in some critical applications, such as\ncredit scoring, where partial monotonicity is required. To address this\nchallenge, this paper presents a novel algorithm (LipVor) that certifies if a\nblack-box model, such as an ANN, is positive based on a finite number of\nevaluations. Therefore, as partial monotonicity can be stated as a positivity\ncondition of the partial derivatives, the LipVor Algorithm can certify whether\nan already trained ANN is partially monotonic. To do so, for every positively\nevaluated point, the Lipschitzianity of the black-box model is used to\nconstruct a specific neighborhood where the function remains positive. Next,\nbased on the Voronoi diagram of the evaluated points, a sufficient condition is\nstated to certify if the function is positive in the domain. Compared to prior\nmethods, our approach is able to mathematically certify if an ANN is partially\nmonotonic without needing constrained ANN's architectures or piece-wise linear\nactivation functions. Therefore, LipVor could open up the possibility of using\nunconstrained ANN in some critical fields. Moreover, some other properties of\nan ANN, such as convexity, can be posed as positivity conditions, and\ntherefore, LipVor could also be applied.",
      "tldr_zh": "本研究针对人工神经网络 (ANNs) 的黑箱性质及其在伦理 AI 中的挑战，提出了一种新算法 LipVor，用于数学认证 ANN 的正性条件，从而验证部分单调性 (partial monotonicity)。LipVor 通过对有限评估点的分析，利用模型的 Lipschitzianity 属性构建正性邻域，并基于 Voronoi diagram 提供充分条件来确认函数在域内的正性，与现有方法相比，无需约束 ANN 架构或使用分段线性激活函数。实验结果表明，该算法能使已训练的 unconstrained ANN 应用于关键领域，如信用评分，并扩展到其他属性如凸性认证，从而提升 ANN 在伦理决策中的可信度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 26A48, 26B30"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.08525v1",
      "published_date": "2024-06-12 07:33:38 UTC",
      "updated_date": "2024-06-12 07:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:24:01.973994"
    },
    {
      "arxiv_id": "2406.07954v1",
      "title": "Dataset and Lessons Learned from the 2024 SaTML LLM Capture-the-Flag Competition",
      "title_zh": "翻译失败",
      "authors": [
        "Edoardo Debenedetti",
        "Javier Rando",
        "Daniel Paleka",
        "Silaghi Fineas Florin",
        "Dragos Albastroiu",
        "Niv Cohen",
        "Yuval Lemberg",
        "Reshmi Ghosh",
        "Rui Wen",
        "Ahmed Salem",
        "Giovanni Cherubin",
        "Santiago Zanella-Beguelin",
        "Robin Schmid",
        "Victor Klemm",
        "Takahiro Miki",
        "Chenhao Li",
        "Stefan Kraft",
        "Mario Fritz",
        "Florian Tramèr",
        "Sahar Abdelnabi",
        "Lea Schönherr"
      ],
      "abstract": "Large language model systems face important security risks from maliciously\ncrafted messages that aim to overwrite the system's original instructions or\nleak private data. To study this problem, we organized a capture-the-flag\ncompetition at IEEE SaTML 2024, where the flag is a secret string in the LLM\nsystem prompt. The competition was organized in two phases. In the first phase,\nteams developed defenses to prevent the model from leaking the secret. During\nthe second phase, teams were challenged to extract the secrets hidden for\ndefenses proposed by the other teams. This report summarizes the main insights\nfrom the competition. Notably, we found that all defenses were bypassed at\nleast once, highlighting the difficulty of designing a successful defense and\nthe necessity for additional research to protect LLM systems. To foster future\nresearch in this direction, we compiled a dataset with over 137k multi-turn\nattack chats and open-sourced the platform.",
      "tldr_zh": "这篇论文总结了2024年SaTML LLM Capture-the-Flag比赛的经验教训，该比赛旨在研究大型语言模型(LLM)面对恶意消息的安全风险，如指令覆盖或数据泄露。比赛分为两个阶段：第一阶段，团队开发防御机制以防止模型泄露隐藏的秘密字符串；第二阶段，团队尝试绕过其他团队的防御提取秘密。关键发现是所有防御均被成功绕过，突显了设计可靠防御的挑战，并强调了进一步研究的必要性。为促进未来工作，论文开源了一个包含超过13.7k多轮攻击对话的数据集。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07954v1",
      "published_date": "2024-06-12 07:27:28 UTC",
      "updated_date": "2024-06-12 07:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:24:11.367201"
    },
    {
      "arxiv_id": "2406.07948v5",
      "title": "Ents: An Efficient Three-party Training Framework for Decision Trees by Communication Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Guopeng Lin",
        "Weili Han",
        "Wenqiang Ruan",
        "Ruisheng Zhou",
        "Lushan Song",
        "Bingshuai Li",
        "Yunfeng Shao"
      ],
      "abstract": "Multi-party training frameworks for decision trees based on secure\nmulti-party computation enable multiple parties to train high-performance\nmodels on distributed private data with privacy preservation. The training\nprocess essentially involves frequent dataset splitting according to the\nsplitting criterion (e.g. Gini impurity). However, existing multi-party\ntraining frameworks for decision trees demonstrate communication inefficiency\ndue to the following issues: (1) They suffer from huge communication overhead\nin securely splitting a dataset with continuous attributes. (2) They suffer\nfrom huge communication overhead due to performing almost all the computations\non a large ring to accommodate the secure computations for the splitting\ncriterion.\n  In this paper, we are motivated to present an efficient three-party training\nframework, namely Ents, for decision trees by communication optimization. For\nthe first issue, we present a series of training protocols based on the secure\nradix sort protocols to efficiently and securely split a dataset with\ncontinuous attributes. For the second issue, we propose an efficient share\nconversion protocol to convert shares between a small ring and a large ring to\nreduce the communication overhead incurred by performing almost all the\ncomputations on a large ring. Experimental results from eight widely used\ndatasets show that Ents outperforms state-of-the-art frameworks by $5.5\\times\n\\sim 9.3\\times$ in communication sizes and $3.9\\times \\sim 5.3\\times$ in\ncommunication rounds. In terms of training time, Ents yields an improvement of\n$3.5\\times \\sim 6.7\\times$. To demonstrate its practicality, Ents requires less\nthan three hours to securely train a decision tree on a widely used real-world\ndataset (Skin Segmentation) with more than 245,000 samples in the WAN setting.",
      "tldr_zh": "本论文提出Ents框架，这是一个高效的三方训练框架，用于优化决策树(Decision Trees)的安全多方计算(Secure Multi-Party Computation)，以解决现有框架在处理连续属性数据集分割和计算环通信时的巨大开销问题。\nEnts采用安全基数排序协议(Secure Radix Sort Protocols)来高效、安全地分割数据集，并引入份额转换协议(Share Conversion Protocol)来在小环和大环之间转换份额，从而显著降低通信需求。\n实验结果显示，在八个常用数据集上，Ents的通信大小和轮次分别比现有框架减少5.5倍至9.3倍和3.9倍至5.3倍，训练时间缩短3.5倍至6.7倍，并在实际广域网场景中可在不到三小时内处理超过24.5万样本的真实数据集。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper is the full version of a paper to appear in ACM CCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07948v5",
      "published_date": "2024-06-12 07:13:11 UTC",
      "updated_date": "2024-07-03 06:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:24:26.525785"
    },
    {
      "arxiv_id": "2406.07944v2",
      "title": "Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries",
      "title_zh": "使用 LLMs 增强",
      "authors": [
        "Meiziniu Li",
        "Dongze Li",
        "Jianmeng Liu",
        "Jialun Cao",
        "Yongqiang Tian",
        "Shing-Chi Cheung"
      ],
      "abstract": "Differential testing offers a promising strategy to alleviate the test oracle\nproblem by comparing the test results between alternative implementations.\nHowever, existing differential testing techniques for deep learning (DL)\nlibraries are limited by the key challenges of finding alternative\nimplementations (called counterparts) for a given API and subsequently\ngenerating diverse test inputs. To address the two challenges, this paper\nintroduces DLLens, an LLM-enhanced differential testing technique for DL\nlibraries. To address the first challenge, DLLens incorporates an LLM-based\ncounterpart synthesis workflow, with the insight that the counterpart of a\ngiven DL library API's computation could be successfully synthesized through\ncertain composition and adaptation of the APIs from another DL library. To\naddress the second challenge, DLLens incorporates a static analysis technique\nthat extracts the path constraints from the implementations of a given API and\nits counterpart to guide diverse test input generation. The extraction is\nfacilitated by LLM's knowledge of the concerned DL library and its upstream\nlibraries.\n  We evaluate DLLens on two popular DL libraries, TensorFlow and PyTorch. Our\nevaluation shows that DLLens synthesizes counterparts for 1.84 times as many\nAPIs as those found by state-of-the-art techniques on these libraries.\nMoreover, under the same time budget, DLLens covers 7.23% more branches and\ndetects 1.88 times as many bugs as state-of-the-art techniques on 200 randomly\nsampled APIs. DLLens has successfully detected 71 bugs in recent TensorFlow and\nPyTorch libraries. Among them, 59 are confirmed by developers, including 46\nconfirmed as previously unknown bugs, and 10 of these previously unknown bugs\nhave been fixed in the latest version of TensorFlow and PyTorch.",
      "tldr_zh": "本研究提出了一种名为 DLLens 的技术，使用大型语言模型 (LLMs) 增强差异测试 (Differential Testing)，以解决深度学习 (DL) 库测试中的关键挑战，包括寻找 API 的替代实现 (counterparts) 和生成多样化测试输入。DLLens 通过 LLM 驱动的 counterparts 合成工作流，将另一个 DL 库的 API 组合和适应来创建替代实现，并结合静态分析技术从 API 实现中提取路径约束，以指导测试输入的多样化生成。实验结果显示，在 TensorFlow 和 PyTorch 上，DLLens 为 1.84 倍的 API 成功合成 counterparts，并在相同时间预算下覆盖 7.23% 更多分支，并检测 1.88 倍的 bugs；此外，它已发现 71 个 bugs，其中 59 个被开发者确认，46 个为之前未知的 bugs，并有 10 个已在最新版本中修复。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.5"
      ],
      "primary_category": "cs.SE",
      "comment": "This work has been accepted by ACM TOSEM. Manuscript under final\n  preparation",
      "pdf_url": "http://arxiv.org/pdf/2406.07944v2",
      "published_date": "2024-06-12 07:06:38 UTC",
      "updated_date": "2025-05-08 15:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:24:42.652844"
    },
    {
      "arxiv_id": "2406.07933v2",
      "title": "Large Language Model Unlearning via Embedding-Corrupted Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Yuhao Liu",
        "Yaxuan Wang",
        "Jeffrey Flanigan",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) have advanced to encompass extensive knowledge\nacross diverse domains. Yet controlling what a large language model should not\nknow is important for ensuring alignment and thus safe use. However, accurately\nand efficiently unlearning knowledge from an LLM remains challenging due to the\npotential collateral damage caused by the fuzzy boundary between retention and\nforgetting, and the large computational requirements for optimization across\nstate-of-the-art models with hundreds of billions of parameters. In this work,\nwe present \\textbf{Embedding-COrrupted (ECO) Prompts}, a lightweight unlearning\nframework for large language models to address both the challenges of knowledge\nentanglement and unlearning efficiency. Instead of relying on the LLM itself to\nunlearn, we enforce an unlearned state during inference by employing a prompt\nclassifier to identify and safeguard prompts to forget. We learn corruptions\nadded to prompt embeddings via zeroth order optimization toward the unlearning\nobjective offline and corrupt prompts flagged by the classifier during\ninference. We find that these embedding-corrupted prompts not only lead to\ndesirable outputs that satisfy the unlearning objective but also closely\napproximate the output from a model that has never been trained on the data\nintended for forgetting. Through extensive experiments on unlearning, we\ndemonstrate the superiority of our method in achieving promising unlearning at\n\\textit{nearly zero side effects} in general domains and domains closely\nrelated to the unlearned ones. Additionally, we highlight the scalability of\nour method to 100 LLMs, ranging from 0.5B to 236B parameters, incurring no\nadditional cost as the number of parameters increases. We have made our code\npublicly available at \\url{https://github.com/chrisliu298/llm-unlearn-eco}.",
      "tldr_zh": "本研究提出了一种名为 Embedding-COrrupted (ECO) Prompts 的轻量级框架，用于从 Large Language Models (LLMs) 中高效遗忘特定知识，解决知识纠缠和计算资源挑战的问题。框架通过一个提示分类器识别需要遗忘的提示，并利用 zeroth order optimization 在提示嵌入中添加腐败，从而在推理阶段强制模型产生符合遗忘目标的输出，同时避免对其他领域的影响。实验结果显示，ECO Prompts 在从 0.5B 到 236B 参数的多种 LLMs 上实现了几乎零副作用的知识遗忘，并证明了其可扩展性和高效性，相关代码已开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Poster",
      "pdf_url": "http://arxiv.org/pdf/2406.07933v2",
      "published_date": "2024-06-12 06:56:20 UTC",
      "updated_date": "2024-10-31 07:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:24:54.151716"
    },
    {
      "arxiv_id": "2406.07929v1",
      "title": "A Generic Layer Pruning Method for Signal Modulation Recognition Deep Learning Models",
      "title_zh": "一种通用的层剪枝方法，用于信号调制识别深度学习模型",
      "authors": [
        "Yao Lu",
        "Yutao Zhu",
        "Yuqi Li",
        "Dongwei Xu",
        "Yun Lin",
        "Qi Xuan",
        "Xiaoniu Yang"
      ],
      "abstract": "With the successful application of deep learning in communications systems,\ndeep neural networks are becoming the preferred method for signal\nclassification. Although these models yield impressive results, they often come\nwith high computational complexity and large model sizes, which hinders their\npractical deployment in communication systems. To address this challenge, we\npropose a novel layer pruning method. Specifically, we decompose the model into\nseveral consecutive blocks, each containing consecutive layers with similar\nsemantics. Then, we identify layers that need to be preserved within each block\nbased on their contribution. Finally, we reassemble the pruned blocks and\nfine-tune the compact model. Extensive experiments on five datasets demonstrate\nthe efficiency and effectiveness of our method over a variety of\nstate-of-the-art baselines, including layer pruning and channel pruning\nmethods.",
      "tldr_zh": "这篇论文提出了一种通用的层剪枝方法，用于信号调制识别的深度学习模型，以解决这些模型计算复杂度和大小过大导致的部署难题。具体而言，该方法将模型分解成语义相似的连续块（blocks），基于各层的贡献识别并保留关键层，然后重新组装并微调紧凑模型。在五个数据集上的广泛实验表明，该方法在效率和效果上优于多种现有基线，包括层剪枝和通道剪枝（channel pruning）技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07929v1",
      "published_date": "2024-06-12 06:46:37 UTC",
      "updated_date": "2024-06-12 06:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:25:04.595101"
    },
    {
      "arxiv_id": "2406.07926v1",
      "title": "Efficient Neural Common Neighbor for Temporal Graph Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaohui Zhang",
        "Yanbo Wang",
        "Xiyuan Wang",
        "Muhan Zhang"
      ],
      "abstract": "Temporal graphs are ubiquitous in real-world scenarios, such as social\nnetwork, trade and transportation. Predicting dynamic links between nodes in a\ntemporal graph is of vital importance. Traditional methods usually leverage the\ntemporal neighborhood of interaction history to generate node embeddings first\nand then aggregate the source and target node embeddings to predict the link.\nHowever, such methods focus on learning individual node representations, but\noverlook the pairwise representation learning nature of link prediction and\nfail to capture the important pairwise features of links such as common\nneighbors (CN). Motivated by the success of Neural Common Neighbor (NCN) for\nstatic graph link prediction, we propose TNCN, a temporal version of NCN for\nlink prediction in temporal graphs. TNCN dynamically updates a temporal\nneighbor dictionary for each node, and utilizes multi-hop common neighbors\nbetween the source and target node to learn a more effective pairwise\nrepresentation. We validate our model on five large-scale real-world datasets\nfrom the Temporal Graph Benchmark (TGB), and find that it achieves new\nstate-of-the-art performance on three of them. Additionally, TNCN demonstrates\nexcellent scalability on large datasets, outperforming popular GNN baselines by\nup to 6.4 times in speed. Our code is available at https:\n//github.com/GraphPKU/TNCN.",
      "tldr_zh": "本研究针对时间图（Temporal Graph）中的链接预测问题，指出传统方法虽生成节点嵌入但忽略了成对表示和共同邻居（Common Neighbors）的学习。论文提出 TNCN，一种基于 Neural Common Neighbor (NCN) 的时间版本框架，该框架动态更新节点的临时邻居字典，并利用多跳共同邻居来生成更有效的成对表示。在 Temporal Graph Benchmark (TGB) 的五个大型真实数据集上，TNCN 实现了三个数据集的最新最先进（state-of-the-art）性能，并在速度上比 GNN 基线快 6.4 倍，展示了其高效性和可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07926v1",
      "published_date": "2024-06-12 06:45:03 UTC",
      "updated_date": "2024-06-12 06:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:25:18.840770"
    },
    {
      "arxiv_id": "2406.07923v1",
      "title": "CTC-aligned Audio-Text Embedding for Streaming Open-vocabulary Keyword Spotting",
      "title_zh": "翻译失败",
      "authors": [
        "Sichen Jin",
        "Youngmoon Jung",
        "Seungjin Lee",
        "Jaeyoung Roh",
        "Changwoo Han",
        "Hoonyoung Cho"
      ],
      "abstract": "This paper introduces a novel approach for streaming openvocabulary keyword\nspotting (KWS) with text-based keyword enrollment. For every input frame, the\nproposed method finds the optimal alignment ending at the frame using\nconnectionist temporal classification (CTC) and aggregates the frame-level\nacoustic embedding (AE) to obtain higher-level (i.e., character, word, or\nphrase) AE that aligns with the text embedding (TE) of the target keyword text.\nAfter that, we calculate the similarity of the aggregated AE and the TE. To the\nbest of our knowledge, this is the first attempt to dynamically align the audio\nand the keyword text on-the-fly to attain the joint audio-text embedding for\nKWS. Despite operating in a streaming fashion, our approach achieves\ncompetitive performance on the LibriPhrase dataset compared to the\nnon-streaming methods with a mere 155K model parameters and a decoding\nalgorithm with time complexity O(U), where U is the length of the target\nkeyword at inference time.",
      "tldr_zh": "这篇论文提出了一种新型流式开放词汇关键词检测 (KWS) 方法，通过连接主义时间分类 (CTC) 动态对齐音频和文本嵌入。方法针对每个输入帧计算最优对齐，并聚合帧级音频嵌入 (AE) 到字符、单词或短语级别，以匹配目标关键词的文本嵌入 (TE)，随后计算二者的相似度。该方法首次实现音频-文本联合嵌入的实时对齐，并在 LibriPhrase 数据集上表现出与非流式方法相当的性能，仅需 155K 参数，且解码算法时间复杂度为 O(U)，其中 U 为关键词长度。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07923v1",
      "published_date": "2024-06-12 06:44:40 UTC",
      "updated_date": "2024-06-12 06:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:25:29.614261"
    },
    {
      "arxiv_id": "2406.16925v1",
      "title": "Analyzing Multi-Head Attention on Trojan BERT Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Wang"
      ],
      "abstract": "This project investigates the behavior of multi-head attention in Transformer\nmodels, specifically focusing on the differences between benign and trojan\nmodels in the context of sentiment analysis. Trojan attacks cause models to\nperform normally on clean inputs but exhibit misclassifications when presented\nwith inputs containing predefined triggers. We characterize attention head\nfunctions in trojan and benign models, identifying specific 'trojan' heads and\nanalyzing their behavior.",
      "tldr_zh": "这篇论文分析了Transformer模型中多头注意力(multi-head attention)机制在良性(benign)和木马(trojan)BERT模型间的行为差异，焦点在于情感分析(sentiment analysis)任务。木马攻击会使模型在正常输入下表现正常，但遇到预定义触发器时导致误分类。研究通过表征注意力头函数，识别了特定的“trojan”头并分析其行为，为检测和理解木马攻击提供了关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16925v1",
      "published_date": "2024-06-12 06:43:59 UTC",
      "updated_date": "2024-06-12 06:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:25:41.048003"
    },
    {
      "arxiv_id": "2406.07920v1",
      "title": "Near-Optimal Learning and Planning in Separated Latent MDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Chen",
        "Constantinos Daskalakis",
        "Noah Golowich",
        "Alexander Rakhlin"
      ],
      "abstract": "We study computational and statistical aspects of learning Latent Markov\nDecision Processes (LMDPs). In this model, the learner interacts with an MDP\ndrawn at the beginning of each epoch from an unknown mixture of MDPs. To\nsidestep known impossibility results, we consider several notions of separation\nof the constituent MDPs. The main thrust of this paper is in establishing a\nnearly-sharp *statistical threshold* for the horizon length necessary for\nefficient learning. On the computational side, we show that under a weaker\nassumption of separability under the optimal policy, there is a\nquasi-polynomial algorithm with time complexity scaling in terms of the\nstatistical threshold. We further show a near-matching time complexity lower\nbound under the exponential time hypothesis.",
      "tldr_zh": "本文研究了 Separated Latent MDPs 中的近似最优学习和规划问题，针对学习者与未知 MDP 混合交互的场景，引入了 MDP 的分离概念来规避已知的不可能性结果。研究建立了 horizon length 的统计阈值，作为高效学习的关键标准，并在 MDP 在最优策略下分离的假设下，提出了一种 quasi-polynomial 时间算法，其复杂度与该阈值相关。最后，通过 exponential time hypothesis 证明了近匹配的时间复杂度下界，突显了算法的计算效率边界。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "COLT 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07920v1",
      "published_date": "2024-06-12 06:41:47 UTC",
      "updated_date": "2024-06-12 06:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:25:53.968209"
    },
    {
      "arxiv_id": "2406.07917v1",
      "title": "Graph Transductive Defense: a Two-Stage Defense for Graph Membership Inference Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Peizhi Niu",
        "Chao Pan",
        "Siheng Chen",
        "Olgica Milenkovic"
      ],
      "abstract": "Graph neural networks (GNNs) have become instrumental in diverse real-world\napplications, offering powerful graph learning capabilities for tasks such as\nsocial networks and medical data analysis. Despite their successes, GNNs are\nvulnerable to adversarial attacks, including membership inference attacks\n(MIA), which threaten privacy by identifying whether a record was part of the\nmodel's training data. While existing research has explored MIA in GNNs under\ngraph inductive learning settings, the more common and challenging graph\ntransductive learning setting remains understudied in this context. This paper\naddresses this gap and proposes an effective two-stage defense, Graph\nTransductive Defense (GTD), tailored to graph transductive learning\ncharacteristics. The gist of our approach is a combination of a train-test\nalternate training schedule and flattening strategy, which successfully reduces\nthe difference between the training and testing loss distributions. Extensive\nempirical results demonstrate the superior performance of our method (a\ndecrease in attack AUROC by $9.42\\%$ and an increase in utility performance by\n$18.08\\%$ on average compared to LBP), highlighting its potential for seamless\nintegration into various classification models with minimal overhead.",
      "tldr_zh": "该研究针对图神经网络（GNNs）在图传递学习（graph transductive learning）设置下易受成员推理攻击（MIA）的隐私威胁，提出了一种有效的双阶段防御方法Graph Transductive Defense (GTD)。GTD 通过结合训练-测试交替训练调度和平坦策略（flattening strategy），成功减少了训练和测试损失分布的差异，从而增强了模型的鲁棒性。实验结果显示，与LBP方法相比，GTD平均降低了攻击AUROC 9.42%，并提高了实用性能18.08%，且可无缝集成到各种分类模型中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07917v1",
      "published_date": "2024-06-12 06:36:37 UTC",
      "updated_date": "2024-06-12 06:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:26:06.564307"
    },
    {
      "arxiv_id": "2406.07908v1",
      "title": "Ablation Based Counterfactuals",
      "title_zh": "基于消融的反事实",
      "authors": [
        "Zheng Dai",
        "David K Gifford"
      ],
      "abstract": "Diffusion models are a class of generative models that generate high-quality\nsamples, but at present it is difficult to characterize how they depend upon\ntheir training data. This difficulty raises scientific and regulatory\nquestions, and is a consequence of the complexity of diffusion models and their\nsampling process. To analyze this dependence, we introduce Ablation Based\nCounterfactuals (ABC), a method of performing counterfactual analysis that\nrelies on model ablation rather than model retraining. In our approach, we\ntrain independent components of a model on different but overlapping splits of\na training set. These components are then combined into a single model, from\nwhich the causal influence of any training sample can be removed by ablating a\ncombination of model components. We demonstrate how we can construct a model\nlike this using an ensemble of diffusion models. We then use this model to\nstudy the limits of training data attribution by enumerating full\ncounterfactual landscapes, and show that single source attributability\ndiminishes with increasing training data size. Finally, we demonstrate the\nexistence of unattributable samples.",
      "tldr_zh": "这篇论文针对扩散模型（diffusion models）的训练数据依赖性问题，提出了一种名为 Ablation Based Counterfactuals (ABC) 的反事实分析方法，该方法通过模型消融（ablation）而非重新训练来评估训练样本的因果影响。ABC 涉及在不同但重叠的训练集分割上训练独立组件，然后将这些组件组合成一个集成模型（ensemble），允许通过消融特定组件来移除样本影响。实验结果显示，随着训练数据规模增加，单一来源归因（single source attributability）会显著减弱，并证实了存在无法归因的样本（unattributable samples）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures, appendix included",
      "pdf_url": "http://arxiv.org/pdf/2406.07908v1",
      "published_date": "2024-06-12 06:22:51 UTC",
      "updated_date": "2024-06-12 06:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:26:17.765528"
    },
    {
      "arxiv_id": "2406.07900v1",
      "title": "Exploring Self-Supervised Multi-view Contrastive Learning for Speech Emotion Recognition with Limited Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Bulat Khaertdinov",
        "Pedro Jeuris",
        "Annanda Sousa",
        "Enrique Hortal"
      ],
      "abstract": "Recent advancements in Deep and Self-Supervised Learning (SSL) have led to\nsubstantial improvements in Speech Emotion Recognition (SER) performance,\nreaching unprecedented levels. However, obtaining sufficient amounts of\naccurately labeled data for training or fine-tuning the models remains a costly\nand challenging task. In this paper, we propose a multi-view SSL pre-training\ntechnique that can be applied to various representations of speech, including\nthe ones generated by large speech models, to improve SER performance in\nscenarios where annotations are limited. Our experiments, based on wav2vec 2.0,\nspectral and paralinguistic features, demonstrate that the proposed framework\nboosts the SER performance, by up to 10% in Unweighted Average Recall, in\nsettings with extremely sparse data annotations.",
      "tldr_zh": "该论文探讨了在标注数据有限的情况下，如何利用自监督多视图对比学习(Self-Supervised Multi-view Contrastive Learning)来提升语音情感识别(Speech Emotion Recognition, SER)的性能。研究提出了一种多视图SSL预训练技术，适用于各种语音表示，如wav2vec 2.0、光谱和副语言特征，从而缓解标注数据的挑战。实验结果表明，该框架在极端稀疏标注场景下，将SER性能提高了最多10%的Unweighted Average Recall (UAR)。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07900v1",
      "published_date": "2024-06-12 06:06:55 UTC",
      "updated_date": "2024-06-12 06:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:26:28.992445"
    },
    {
      "arxiv_id": "2406.07897v1",
      "title": "When Do Skills Help Reinforcement Learning? A Theoretical Analysis of Temporal Abstractions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhening Li",
        "Gabriel Poesia",
        "Armando Solar-Lezama"
      ],
      "abstract": "Skills are temporal abstractions that are intended to improve reinforcement\nlearning (RL) performance through hierarchical RL. Despite our intuition about\nthe properties of an environment that make skills useful, a precise\ncharacterization has been absent. We provide the first such characterization,\nfocusing on the utility of deterministic skills in deterministic sparse-reward\nenvironments with finite action spaces. We show theoretically and empirically\nthat RL performance gain from skills is worse in environments where solutions\nto states are less compressible. Additional theoretical results suggest that\nskills benefit exploration more than they benefit learning from existing\nexperience, and that using unexpressive skills such as macroactions may worsen\nRL performance. We hope our findings can guide research on automatic skill\ndiscovery and help RL practitioners better decide when and how to use skills.",
      "tldr_zh": "这篇论文对强化学习（RL）中的时间抽象（temporal abstractions）进行了理论分析，旨在表征技能（skills）在何种环境下有助于提升 RL 性能。研究聚焦于确定性稀疏奖励环境的有限动作空间，证明技能带来的性能提升在状态解决方案可压缩性较低的环境中更差。额外理论结果显示，技能更益于探索而非从现有经验中学习，且使用不表达性的技能如 macroactions 可能恶化 RL 性能；这些发现可指导自动技能发现研究和 RL 实践者的决策。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 1 figure. Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07897v1",
      "published_date": "2024-06-12 06:01:42 UTC",
      "updated_date": "2024-06-12 06:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:26:44.041496"
    },
    {
      "arxiv_id": "2406.07892v2",
      "title": "A Finite-Sample Analysis of an Actor-Critic Algorithm for Mean-Variance Optimization in a Discounted MDP",
      "title_zh": "一个 Actor-Critic 算法在折扣马尔可夫决策过程中的均值-方差优化的有限样本分析",
      "authors": [
        "Tejaram Sangadi",
        "L. A. Prashanth",
        "Krishna Jagannathan"
      ],
      "abstract": "Motivated by applications in risk-sensitive reinforcement learning, we study\nmean-variance optimization in a discounted reward Markov Decision Process\n(MDP). Specifically, we analyze a Temporal Difference (TD) learning algorithm\nwith linear function approximation (LFA) for policy evaluation. We derive\nfinite-sample bounds that hold (i) in the mean-squared sense and (ii) with high\nprobability under tail iterate averaging, both with and without regularization.\nOur bounds exhibit an exponentially decaying dependence on the initial error\nand a convergence rate of $O(1/t)$ after $t$ iterations. Moreover, for the\nregularized TD variant, our bound holds for a universal step size. Next, we\nintegrate a Simultaneous Perturbation Stochastic Approximation (SPSA)-based\nactor update with an LFA critic and establish an $O(n^{-1/4})$ convergence\nguarantee, where $n$ denotes the iterations of the SPSA-based actor-critic\nalgorithm. These results establish finite-sample theoretical guarantees for\nrisk-sensitive actor-critic methods in reinforcement learning, with a focus on\nvariance as a risk measure.",
      "tldr_zh": "这篇论文分析了在折扣奖励 Markov Decision Process (MDP) 中，用于均值-方差优化的 Actor-Critic 算法，聚焦于风险敏感强化学习的应用。研究者通过 Temporal Difference (TD) 学习算法结合线性函数逼近 (LFA) 进行了策略评估，推导了有限样本边界，包括均方意义和高概率意义（使用尾部迭代平均），显示初始错误指数衰减且收敛率为 O(1/t) 迭代后；对于正则化变体，还适用于通用步长。论文进一步整合了 Simultaneous Perturbation Stochastic Approximation (SPSA)-based actor 更新与 LFA critic，建立了 O(n^{-1/4}) 的收敛保证，为风险敏感强化学习中的 actor-critic 方法提供了可靠的有限样本理论支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07892v2",
      "published_date": "2024-06-12 05:49:53 UTC",
      "updated_date": "2025-03-12 14:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:26:58.284933"
    },
    {
      "arxiv_id": "2406.07888v2",
      "title": "Classification Modeling with RNN-Based, Random Forest, and XGBoost for Imbalanced Data: A Case of Early Crash Detection in ASEAN-5 Stock Markets",
      "title_zh": "翻译失败",
      "authors": [
        "Deri Siswara",
        "Agus M. Soleh",
        "Aji Hamim Wigena"
      ],
      "abstract": "This research aims to evaluate the performance of several Recurrent Neural\nNetwork (RNN) architectures including Simple RNN, Gated Recurrent Units (GRU),\nand Long Short-Term Memory (LSTM), compared to classic algorithms such as\nRandom Forest and XGBoost in building classification models for early crash\ndetection in ASEAN-5 stock markets. The study is examined using imbalanced\ndata, which is common due to the rarity of market crashes. The study analyzes\ndaily data from 2010 to 2023 across the major stock markets of the ASEAN-5\ncountries, including Indonesia, Malaysia, Singapore, Thailand, and Philippines.\nMarket crash is identified as the target variable when the major stock price\nindices fall below the Value at Risk (VaR) thresholds of 5%, 2.5% and 1%.\npredictors involving technical indicators of major local and global markets as\nwell as commodity markets. This study includes 213 predictors with their\nrespective lags (5, 10, 15, 22, 50, 200) and uses a time step of 7, expanding\nthe total number of predictors to 1491. The challenge of data imbalance is\naddressed with SMOTE-ENN. The results show that all RNN-Based architectures\noutperform Random Forest and XGBoost. Among the various RNN architectures,\nSimple RNN stands out as the most superior, mainly due to the data\ncharacteristics that are not overly complex and focus more on short-term\ninformation. This study enhances and extends the range of phenomena observed in\nprevious studies by incorporating variables like different geographical zones\nand time periods, as well as methodological adjustments.",
      "tldr_zh": "本研究评估了 Simple RNN、GRU 和 LSTM 等 RNN 架构与 Random Forest 和 XGBoost 在处理不平衡数据时的性能，针对 ASEAN-5 股票市场（包括印度尼西亚、马来西亚、新加坡、泰国和菲律宾）的早期崩盘检测。研究使用 2010-2023 年的日常数据，将股票价格指数跌破 VaR 阈值（5%、2.5% 和 1%）作为目标变量，并通过 SMOTE-ENN 处理数据不平衡问题，总计涉及 1491 个预测变量。结果显示，所有 RNN 架构均优于 Random Forest 和 XGBoost，其中 Simple RNN 表现最佳，主要归因于数据更注重短期信息。该研究扩展了先前研究的现象范围，包括不同地理区域和时间段的变量整合。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "AM - Accepted Manuscript",
      "pdf_url": "http://arxiv.org/pdf/2406.07888v2",
      "published_date": "2024-06-12 05:35:28 UTC",
      "updated_date": "2024-09-29 12:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:27:10.287784"
    },
    {
      "arxiv_id": "2406.07882v3",
      "title": "Designing a Dashboard for Transparency and Control of Conversational AI",
      "title_zh": "设计用于对话式 AI 的透明度和控制仪表板",
      "authors": [
        "Yida Chen",
        "Aoyu Wu",
        "Trevor DePodesta",
        "Catherine Yeh",
        "Kenneth Li",
        "Nicholas Castillo Marin",
        "Oam Patel",
        "Jan Riecke",
        "Shivam Raval",
        "Olivia Seow",
        "Martin Wattenberg",
        "Fernanda Viégas"
      ],
      "abstract": "Conversational LLMs function as black box systems, leaving users guessing\nabout why they see the output they do. This lack of transparency is potentially\nproblematic, especially given concerns around bias and truthfulness. To address\nthis issue, we present an end-to-end prototype-connecting interpretability\ntechniques with user experience design-that seeks to make chatbots more\ntransparent. We begin by showing evidence that a prominent open-source LLM has\na \"user model\": examining the internal state of the system, we can extract data\nrelated to a user's age, gender, educational level, and socioeconomic status.\nNext, we describe the design of a dashboard that accompanies the chatbot\ninterface, displaying this user model in real time. The dashboard can also be\nused to control the user model and the system's behavior. Finally, we discuss a\nstudy in which users conversed with the instrumented system. Our results\nsuggest that users appreciate seeing internal states, which helped them expose\nbiased behavior and increased their sense of control. Participants also made\nvaluable suggestions that point to future directions for both design and\nmachine learning research. The project page and video demo of our TalkTuner\nsystem are available at https://bit.ly/talktuner-project-page",
      "tldr_zh": "本研究针对对话式 LLM 的黑盒特性及其潜在偏见和真实性问题，提出了一种端到端的原型系统，包括可解释性技术与用户体验设计的结合。研究发现，一个著名开源 LLM 存在“user model”，可以通过检查内部状态提取用户的年龄、性别、教育水平和 socioeconomic status，并设计了一个实时仪表板（dashboard）来显示和控制该模型及系统行为。在用户研究中，结果显示参与者更喜欢查看内部状态，这有助于暴露偏见行为、增强控制感，并提供了未来设计和机器学习研究的宝贵建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Project page: https://bit.ly/talktuner-project-page, 38 pages, 23\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2406.07882v3",
      "published_date": "2024-06-12 05:20:16 UTC",
      "updated_date": "2024-10-14 17:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:27:19.309915"
    },
    {
      "arxiv_id": "2406.07879v1",
      "title": "KernelWarehouse: Rethinking the Design of Dynamic Convolution",
      "title_zh": "KernelWarehouse: 重新思考动态卷积的设计",
      "authors": [
        "Chao Li",
        "Anbang Yao"
      ],
      "abstract": "Dynamic convolution learns a linear mixture of n static kernels weighted with\ntheir input-dependent attentions, demonstrating superior performance than\nnormal convolution. However, it increases the number of convolutional\nparameters by n times, and thus is not parameter efficient. This leads to no\nresearch progress that can allow researchers to explore the setting n>100 (an\norder of magnitude larger than the typical setting n<10) for pushing forward\nthe performance boundary of dynamic convolution while enjoying parameter\nefficiency. To fill this gap, in this paper, we propose KernelWarehouse, a more\ngeneral form of dynamic convolution, which redefines the basic concepts of\n``kernels\", ``assembling kernels\" and ``attention function\" through the lens of\nexploiting convolutional parameter dependencies within the same layer and\nacross neighboring layers of a ConvNet. We testify the effectiveness of\nKernelWarehouse on ImageNet and MS-COCO datasets using various ConvNet\narchitectures. Intriguingly, KernelWarehouse is also applicable to Vision\nTransformers, and it can even reduce the model size of a backbone while\nimproving the model accuracy. For instance, KernelWarehouse (n=4) achieves\n5.61%|3.90%|4.38% absolute top-1 accuracy gain on the\nResNet18|MobileNetV2|DeiT-Tiny backbone, and KernelWarehouse (n=1/4) with\n65.10% model size reduction still achieves 2.29% gain on the ResNet18 backbone.\nThe code and models are available at https://github.com/OSVAI/KernelWarehouse.",
      "tldr_zh": "该研究重新设计了动态卷积（dynamic convolution），提出 KernelWarehouse 框架，以解决其参数效率低的问题，通过利用 ConvNet 中同一层和相邻层的卷积参数依赖性，重新定义“kernels”、“assembling kernels”和“attention function”。该框架在 ImageNet 和 MS-COCO 数据集上测试，使用各种 ConvNet 架构，并扩展到 Vision Transformers，能在提高模型准确率的同时减少模型大小，例如在 ResNet18 上，KernelWarehouse (n=4) 使 top-1 准确率提升 5.61%，而 n=1/4 时模型大小减少 65.10% 仍获得 2.29% 的增益。总的来说，该方法推动了动态卷积性能的边界，同时提升了参数效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work is accepted to ICML 2024. The project page:\n  https://github.com/OSVAI/KernelWarehouse. arXiv admin note: substantial text\n  overlap with arXiv:2308.08361",
      "pdf_url": "http://arxiv.org/pdf/2406.07879v1",
      "published_date": "2024-06-12 05:16:26 UTC",
      "updated_date": "2024-06-12 05:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:27:31.760853"
    },
    {
      "arxiv_id": "2406.07877v2",
      "title": "Hierarchical Reinforcement Learning for Swarm Confrontation with High Uncertainty",
      "title_zh": "高不确定性下的群体对抗层次化强化学习",
      "authors": [
        "Qizhen Wu",
        "Kexin Liu",
        "Lei Chen",
        "Jinhu Lü"
      ],
      "abstract": "In swarm robotics, confrontation including the pursuit-evasion game is a key\nscenario. High uncertainty caused by unknown opponents' strategies, dynamic\nobstacles, and insufficient training complicates the action space into a hybrid\ndecision process. Although the deep reinforcement learning method is\nsignificant for swarm confrontation since it can handle various sizes, as an\nend-to-end implementation, it cannot deal with the hybrid process. Here, we\npropose a novel hierarchical reinforcement learning approach consisting of a\ntarget allocation layer, a path planning layer, and the underlying dynamic\ninteraction mechanism between the two layers, which indicates the quantified\nuncertainty. It decouples the hybrid process into discrete allocation and\ncontinuous planning layers, with a probabilistic ensemble model to quantify the\nuncertainty and regulate the interaction frequency adaptively. Furthermore, to\novercome the unstable training process introduced by the two layers, we design\nan integration training method including pre-training and cross-training, which\nenhances the training efficiency and stability. Experiment results in both\ncomparison, ablation, and real-robot studies validate the effectiveness and\ngeneralization performance of our proposed approach. In our defined experiments\nwith twenty to forty agents, the win rate of the proposed method reaches around\nninety percent, outperforming other traditional methods.",
      "tldr_zh": "这篇论文针对群机器人对抗（如追逐-逃避游戏）中的高不确定性（如未知对手策略和动态障碍），提出了一种新型层次化强化学习（hierarchical reinforcement learning）方法。该方法将决策过程解耦为目标分配层（target allocation layer）和路径规划层（path planning layer），并通过底层动态交互机制及概率集成模型（probabilistic ensemble model）量化不确定性，以自适应调节交互频率。为了提升训练稳定性，论文设计了集成训练方法，包括预训练和交叉训练。实验结果显示，在20到40个代理的场景中，该方法胜率达约90%，在比较、消融和真实机器人实验中均表现出色，优于传统deep reinforcement learning方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07877v2",
      "published_date": "2024-06-12 05:12:10 UTC",
      "updated_date": "2024-10-25 08:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:27:45.275879"
    },
    {
      "arxiv_id": "2406.07876v1",
      "title": "Small Scale Data-Free Knowledge Distillation",
      "title_zh": "小规模无数据知识蒸馏",
      "authors": [
        "He Liu",
        "Yikai Wang",
        "Huaping Liu",
        "Fuchun Sun",
        "Anbang Yao"
      ],
      "abstract": "Data-free knowledge distillation is able to utilize the knowledge learned by\na large teacher network to augment the training of a smaller student network\nwithout accessing the original training data, avoiding privacy, security, and\nproprietary risks in real applications. In this line of research, existing\nmethods typically follow an inversion-and-distillation paradigm in which a\ngenerative adversarial network on-the-fly trained with the guidance of the\npre-trained teacher network is used to synthesize a large-scale sample set for\nknowledge distillation. In this paper, we reexamine this common data-free\nknowledge distillation paradigm, showing that there is considerable room to\nimprove the overall training efficiency through a lens of ``small-scale\ninverted data for knowledge distillation\". In light of three empirical\nobservations indicating the importance of how to balance class distributions in\nterms of synthetic sample diversity and difficulty during both data inversion\nand distillation processes, we propose Small Scale Data-free Knowledge\nDistillation SSD-KD. In formulation, SSD-KD introduces a modulating function to\nbalance synthetic samples and a priority sampling function to select proper\nsamples, facilitated by a dynamic replay buffer and a reinforcement learning\nstrategy. As a result, SSD-KD can perform distillation training conditioned on\nan extremely small scale of synthetic samples (e.g., 10X less than the original\ntraining data scale), making the overall training efficiency one or two orders\nof magnitude faster than many mainstream methods while retaining superior or\ncompetitive model performance, as demonstrated on popular image classification\nand semantic segmentation benchmarks. The code is available at\nhttps://github.com/OSVAI/SSD-KD.",
      "tldr_zh": "本文提出 Small Scale Data-Free Knowledge Distillation (SSD-KD) 方法，旨在通过小规模合成数据提升数据无关知识蒸馏的训练效率，避免使用原始训练数据带来的隐私风险。SSD-KD 引入调制函数平衡合成样本的类分布、优先采样函数选择合适样本，并结合动态重放缓冲区和强化学习策略，仅需原始数据规模的1/10合成样本即可进行有效训练。实验在图像分类和语义分割基准上表明，该方法比主流方法快1-2个数量级，同时保持或优于基线模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This work is accepted to CVPR 2024. The project page:\n  https://github.com/OSVAI/SSD-KD",
      "pdf_url": "http://arxiv.org/pdf/2406.07876v1",
      "published_date": "2024-06-12 05:09:41 UTC",
      "updated_date": "2024-06-12 05:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:27:56.194773"
    },
    {
      "arxiv_id": "2406.07875v2",
      "title": "Carbon Market Simulation with Adaptive Mechanism Design",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wang",
        "Wenhao Li",
        "Hongyuan Zha",
        "Baoxiang Wang"
      ],
      "abstract": "A carbon market is a market-based tool that incentivizes economic agents to\nalign individual profits with the global utility, i.e., reducing carbon\nemissions to tackle climate change. Cap and trade stands as a critical\nprinciple based on allocating and trading carbon allowances (carbon emission\ncredit), enabling economic agents to follow planned emissions and penalizing\nexcess emissions. A central authority is responsible for introducing and\nallocating those allowances in cap and trade. However, the complexity of carbon\nmarket dynamics makes accurate simulation intractable, which in turn hinders\nthe design of effective allocation strategies. To address this, we propose an\nadaptive mechanism design framework, simulating the market using hierarchical,\nmodel-free multi-agent reinforcement learning (MARL). Government agents\nallocate carbon credits, while enterprises engage in economic activities and\ncarbon trading. This framework illustrates agents' behavior comprehensively.\nNumerical results show MARL enables government agents to balance productivity,\nequality, and carbon emissions. Our project is available at\nhttps://github.com/xwanghan/Carbon-Simulator.",
      "tldr_zh": "该论文探讨了Carbon Market作为一种基于市场的工具，以激励经济主体减少碳排放，从而应对气候变化。作者提出了一种自适应机制设计框架，利用分层、无模型的Multi-Agent Reinforcement Learning (MARL)来模拟市场动态，其中政府智能体负责分配碳信用，而企业智能体参与经济活动和Cap and Trade交易。该框架全面展示了智能体的行为，并通过数值实验证明，MARL能帮助政府智能体在生产力、平等性和碳排放之间实现平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.07875v2",
      "published_date": "2024-06-12 05:08:51 UTC",
      "updated_date": "2024-06-13 10:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:28:06.759796"
    },
    {
      "arxiv_id": "2406.07869v2",
      "title": "Unveiling the Power of Wavelets: A Wavelet-based Kolmogorov-Arnold Network for Hyperspectral Image Classification",
      "title_zh": "揭示小波的威力：基于小波的Kolmogorov-Arnold网络用于高光谱图像分类",
      "authors": [
        "Seyd Teymoor Seydi",
        "Zavareh Bozorgasl",
        "Hao Chen"
      ],
      "abstract": "Hyperspectral image classification is a crucial but challenging task due to\nthe high dimensionality and complex spatial-spectral correlations inherent in\nhyperspectral data. This paper employs Wavelet-based Kolmogorov-Arnold Network\n(wav-kan) architecture tailored for efficient modeling of these intricate\ndependencies. Inspired by the Kolmogorov-Arnold representation theorem, Wav-KAN\nincorporates wavelet functions as learnable activation functions, enabling\nnon-linear mapping of the input spectral signatures. The wavelet-based\nactivation allows Wav-KAN to effectively capture multi-scale spatial and\nspectral patterns through dilations and translations. Experimental evaluation\non three benchmark hyperspectral datasets (Salinas, Pavia, Indian Pines)\ndemonstrates the superior performance of Wav-KAN compared to traditional\nmultilayer perceptrons (MLPs) and the recently proposed Spline-based KAN\n(Spline-KAN) model. In this work we are: (1) conducting more experiments on\nadditional hyperspectral datasets (Pavia University, WHU-Hi, and Urban\nHyperspectral Image) to further validate the generalizability of Wav-KAN; (2)\ndeveloping a multiresolution Wav-KAN architecture to capture scale-invariant\nfeatures; (3) analyzing the effect of dimensional reduction techniques on\nclassification performance; (4) exploring optimization methods for tuning the\nhyperparameters of KAN models; and (5) comparing Wav-KAN with other\nstate-of-the-art models in hyperspectral image classification.",
      "tldr_zh": "本文提出了一种Wavelet-based Kolmogorov-Arnold Network (Wav-KAN)架构，用于高光谱图像分类，以应对数据的高维度和复杂空间-光谱相关性挑战。Wav-KAN 借鉴Kolmogorov-Arnold representation theorem，将小波函数作为可学习的激活函数，通过扩张和平移有效捕获多尺度空间和光谱模式。在Salinas、Pavia和Indian Pines等基准数据集上的实验显示，Wav-KAN 比传统multilayer perceptrons (MLPs)和Spline-KAN模型表现出色，性能提升显著。未来工作包括在更多数据集（如Pavia University）上验证其泛化性，并探索多分辨率架构和优化方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07869v2",
      "published_date": "2024-06-12 04:52:40 UTC",
      "updated_date": "2024-10-08 14:42:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:28:21.502944"
    },
    {
      "arxiv_id": "2406.07867v2",
      "title": "Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation",
      "title_zh": "翻译失败",
      "authors": [
        "Se Jin Park",
        "Chae Won Kim",
        "Hyeongseop Rha",
        "Minsu Kim",
        "Joanna Hong",
        "Jeong Hun Yeo",
        "Yong Man Ro"
      ],
      "abstract": "In this paper, we introduce a novel Face-to-Face spoken dialogue model. It\nprocesses audio-visual speech from user input and generates audio-visual speech\nas the response, marking the initial step towards creating an avatar chatbot\nsystem without relying on intermediate text. To this end, we newly introduce\nMultiDialog, the first large-scale multimodal (i.e., audio and visual) spoken\ndialogue corpus containing 340 hours of approximately 9,000 dialogues, recorded\nbased on the open domain dialogue dataset, TopicalChat. The MultiDialog\ncontains parallel audio-visual recordings of conversation partners acting\naccording to the given script with emotion annotations, which we expect to open\nup research opportunities in multimodal synthesis. Our Face-to-Face spoken\ndialogue model incorporates a textually pretrained large language model and\nadapts it into the audio-visual spoken dialogue domain by incorporating\nspeech-text joint pretraining. Through extensive experiments, we validate the\neffectiveness of our model in facilitating a face-to-face conversation. Demo\nand data are available at https://multidialog.github.io and\nhttps://huggingface.co/datasets/IVLLab/MultiDialog, respectively.",
      "tldr_zh": "本研究引入了一种新的Face-to-Face对话模型，能够处理用户的音频-视觉语音输入并生成相应的音频-视觉响应，从而实现无需中间文本的头像聊天机器人系统。研究者构建了MultiDialog，这是首个大规模多模态（音频和视觉）对话语料库，包含340小时约9,000个基于TopicalChat数据集的对话记录，并附带情感注释，以支持多模态合成研究。该模型基于预训练的大型语言模型，通过语音-文本联合预训练适应音频-视觉对话领域；实验结果证明了其在促进Face-to-Face对话中的有效性，并提供了相关演示和数据资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACL 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2406.07867v2",
      "published_date": "2024-06-12 04:48:36 UTC",
      "updated_date": "2024-08-02 15:05:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:28:32.626917"
    },
    {
      "arxiv_id": "2406.07865v1",
      "title": "FaithFill: Faithful Inpainting for Object Completion Using a Single Reference Image",
      "title_zh": "翻译失败",
      "authors": [
        "Rupayan Mallick",
        "Amr Abdalla",
        "Sarah Adel Bargal"
      ],
      "abstract": "We present FaithFill, a diffusion-based inpainting object completion approach\nfor realistic generation of missing object parts. Typically, multiple reference\nimages are needed to achieve such realistic generation, otherwise the\ngeneration would not faithfully preserve shape, texture, color, and background.\nIn this work, we propose a pipeline that utilizes only a single input reference\nimage -having varying lighting, background, object pose, and/or viewpoint. The\nsingular reference image is used to generate multiple views of the object to be\ninpainted. We demonstrate that FaithFill produces faithful generation of the\nobject's missing parts, together with background/scene preservation, from a\nsingle reference image. This is demonstrated through standard similarity\nmetrics, human judgement, and GPT evaluation. Our results are presented on the\nDreamBooth dataset, and a novel proposed dataset.",
      "tldr_zh": "该研究提出了一种基于扩散模型的图像修复方法FaithFill，用于使用单一参考图像实现对象的真实完成。该方法通过从一个输入图像（可能包含不同的照明、背景、物体姿势或视角）生成多个视图，来忠实地恢复缺失的部分，同时保留背景和场景。实验结果显示，FaithFill在形状、纹理、颜色等方面表现出色，并在DreamBooth数据集和新提出的数据集上，通过标准相似性指标、人类判断和GPT评估验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07865v1",
      "published_date": "2024-06-12 04:45:33 UTC",
      "updated_date": "2024-06-12 04:45:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:28:46.433777"
    },
    {
      "arxiv_id": "2406.07862v1",
      "title": "Self-Distillation Learning Based on Temporal-Spatial Consistency for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Zuo",
        "Yongqi Ding",
        "Mengmeng Jing",
        "Kunshan Yang",
        "Yunqian Yu"
      ],
      "abstract": "Spiking neural networks (SNNs) have attracted considerable attention for\ntheir event-driven, low-power characteristics and high biological\ninterpretability. Inspired by knowledge distillation (KD), recent research has\nimproved the performance of the SNN model with a pre-trained teacher model.\nHowever, additional teacher models require significant computational resources,\nand it is tedious to manually define the appropriate teacher network\narchitecture. In this paper, we explore cost-effective self-distillation\nlearning of SNNs to circumvent these concerns. Without an explicit defined\nteacher, the SNN generates pseudo-labels and learns consistency during\ntraining. On the one hand, we extend the timestep of the SNN during training to\ncreate an implicit temporal ``teacher\" that guides the learning of the original\n``student\", i.e., the temporal self-distillation. On the other hand, we guide\nthe output of the weak classifier at the intermediate stage by the final output\nof the SNN, i.e., the spatial self-distillation. Our temporal-spatial\nself-distillation (TSSD) learning method does not introduce any inference\noverhead and has excellent generalization ability. Extensive experiments on the\nstatic image datasets CIFAR10/100 and ImageNet as well as the neuromorphic\ndatasets CIFAR10-DVS and DVS-Gesture validate the superior performance of the\nTSSD method. This paper presents a novel manner of fusing SNNs with KD,\nproviding insights into high-performance SNN learning methods.",
      "tldr_zh": "本研究提出了一种基于时序-空间一致性的自蒸馏学习方法（Temporal-Spatial Self-Distillation, TSSD），针对Spiking Neural Networks (SNNs) 避免了传统知识蒸馏(KD)所需的大量计算资源和手动教师模型设计。TSSD通过延长时间步长创建隐式temporal self-distillation来指导原始学生模型学习，并利用SNN的最终输出指导中间弱分类器的spatial self-distillation，从而在训练中生成伪标签并确保一致性。该方法不引入推理开销，并在CIFAR10/100、ImageNet以及神经形态数据集CIFAR10-DVS和DVS-Gesture上的实验中表现出优越性能，为高性能SNN学习提供了新的融合KD的见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.07862v1",
      "published_date": "2024-06-12 04:30:40 UTC",
      "updated_date": "2024-06-12 04:30:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:01.784255"
    },
    {
      "arxiv_id": "2406.07860v1",
      "title": "BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain",
      "title_zh": "BookSQL: 用于会计领域的海量 Text-to-SQL 数据集",
      "authors": [
        "Rahul Kumar",
        "Amar Raja Dibbu",
        "Shrutendra Harsola",
        "Vignesh Subrahmaniam",
        "Ashutosh Modi"
      ],
      "abstract": "Several large-scale datasets (e.g., WikiSQL, Spider) for developing natural\nlanguage interfaces to databases have recently been proposed. These datasets\ncover a wide breadth of domains but fall short on some essential domains, such\nas finance and accounting. Given that accounting databases are used worldwide,\nparticularly by non-technical people, there is an imminent need to develop\nmodels that could help extract information from accounting databases via\nnatural language queries. In this resource paper, we aim to fill this gap by\nproposing a new large-scale Text-to-SQL dataset for the accounting and\nfinancial domain: BookSQL. The dataset consists of 100k natural language\nqueries-SQL pairs, and accounting databases of 1 million records. We experiment\nwith and analyze existing state-of-the-art models (including GPT-4) for the\nText-to-SQL task on BookSQL. We find significant performance gaps, thus\npointing towards developing more focused models for this domain.",
      "tldr_zh": "该论文指出现有大规模 Text-to-SQL 数据集（如 WikiSQL 和 Spider）覆盖领域广泛，但缺少关键领域如财务和会计，因此提出一个新的数据集 BookSQL，以填补这一空白。BookSQL 包含 10 万对自然语言查询-SQL 配对，以及 100 万记录的会计数据库，旨在帮助非技术人员通过自然语言查询提取会计信息。研究者实验了现有最先进模型（包括 GPT-4）在 BookSQL 上的性能，发现显著的性能差距，并建议开发更专注于该领域的专用模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2024; 20 Pages (main + appendix)",
      "pdf_url": "http://arxiv.org/pdf/2406.07860v1",
      "published_date": "2024-06-12 04:22:27 UTC",
      "updated_date": "2024-06-12 04:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:10.357765"
    },
    {
      "arxiv_id": "2406.07850v1",
      "title": "Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation",
      "title_zh": "面向开放域对话生成的动态随机解码策略",
      "authors": [
        "Yiwei Li",
        "Fei Mi",
        "Yitong Li",
        "Yasheng Wang",
        "Bin Sun",
        "Shaoxiong Feng",
        "Kan Li"
      ],
      "abstract": "Stochastic sampling strategies such as top-k and top-p have been widely used\nin dialogue generation task. However, as an open-domain chatting system, there\nwill be two different conversation scenarios, i.e. chit-chat and\nknowledge-based question answering. In the former situation, responses\ndiversity is essential due to the one-to-many nature in dialogue. The latter,\non the other hand, requires less randomness given that stochastic decoding\nstrategy entails the risk of generating incorrect information. As a result, an\nadaptive and flexible decoding strategy is needed to cope with these two\nscenarios simultaneously. To this end, we propose the dynamic decoding strategy\n(DDS), which can adjust the decoding space w.r.t. different contexts. In DDS,\nboth sequence-level and token-level adaptive search can be achieved to adjust\nthe decoding process in a unified framework. Besides, our adaptive algorithm\ncan not only be used during model inference, but it can also be applied during\nthe model training stage to further enhance the performance. Comprehensive\nexperiments indicate that the proposed decoding strategy can consistently\nimprove the performance of pre-trained dialogue models when coupled with four\nwell-used stochastic decoding algorithms.",
      "tldr_zh": "这篇论文针对开放域对话生成中的不同场景（如 chit-chat 和 knowledge-based question answering），提出了一种动态随机解码策略（DDS），该策略通过序列级和标记级自适应搜索调整解码空间，以平衡响应多样性和准确性。DDS 不仅适用于模型推理阶段，还可集成到训练过程中，与 top-k 和 top-p 等随机解码算法结合，进一步提升模型性能。实验结果表明，该策略在四种常用随机解码算法上 consistently 改善了预训练对话模型的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2406.07850v1",
      "published_date": "2024-06-12 03:38:45 UTC",
      "updated_date": "2024-06-12 03:38:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:24.163996"
    },
    {
      "arxiv_id": "2406.07848v1",
      "title": "Multi-agent Reinforcement Learning with Deep Networks for Diverse Q-Vectors",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenglong Luo",
        "Zhiyong Chen",
        "James Welsh"
      ],
      "abstract": "Multi-agent reinforcement learning (MARL) has become a significant research\ntopic due to its ability to facilitate learning in complex environments. In\nmulti-agent tasks, the state-action value, commonly referred to as the Q-value,\ncan vary among agents because of their individual rewards, resulting in a\nQ-vector. Determining an optimal policy is challenging, as it involves more\nthan just maximizing a single Q-value. Various optimal policies, such as a Nash\nequilibrium, have been studied in this context. Algorithms like Nash Q-learning\nand Nash Actor-Critic have shown effectiveness in these scenarios. This paper\nextends this research by proposing a deep Q-networks (DQN) algorithm capable of\nlearning various Q-vectors using Max, Nash, and Maximin strategies. The\neffectiveness of this approach is demonstrated in an environment where dual\nrobotic arms collaborate to lift a pot.",
      "tldr_zh": "这篇论文提出了一种基于深度Q网络（DQN）的多智能体强化学习（MARL）算法，用于学习不同的Q-vectors，以应对多智能体环境中个体奖励导致的策略优化挑战。算法扩展了现有方法，如Nash Q-learning和Nash Actor-Critic，通过整合Max、Nash和Maximin策略，实现对各种最优策略（如Nash均衡）的支持。在双机器人臂协作举起锅的实验环境中，该方法证明了其有效性，展示了在复杂协作任务中的潜力。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07848v1",
      "published_date": "2024-06-12 03:30:10 UTC",
      "updated_date": "2024-06-12 03:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:35.406720"
    },
    {
      "arxiv_id": "2406.10279v3",
      "title": "We Have a Package for You! A Comprehensive Analysis of Package Hallucinations by Code Generating LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Spracklen",
        "Raveen Wijewickrama",
        "A H M Nazmus Sakib",
        "Anindya Maiti",
        "Bimal Viswanath",
        "Murtuza Jadliwala"
      ],
      "abstract": "The reliance of popular programming languages such as Python and JavaScript\non centralized package repositories and open-source software, combined with the\nemergence of code-generating Large Language Models (LLMs), has created a new\ntype of threat to the software supply chain: package hallucinations. These\nhallucinations, which arise from fact-conflicting errors when generating code\nusing LLMs, represent a novel form of package confusion attack that poses a\ncritical threat to the integrity of the software supply chain. This paper\nconducts a rigorous and comprehensive evaluation of package hallucinations\nacross different programming languages, settings, and parameters, exploring how\na diverse set of models and configurations affect the likelihood of generating\nerroneous package recommendations and identifying the root causes of this\nphenomenon. Using 16 popular LLMs for code generation and two unique prompt\ndatasets, we generate 576,000 code samples in two programming languages that we\nanalyze for package hallucinations. Our findings reveal that that the average\npercentage of hallucinated packages is at least 5.2% for commercial models and\n21.7% for open-source models, including a staggering 205,474 unique examples of\nhallucinated package names, further underscoring the severity and pervasiveness\nof this threat. To overcome this problem, we implement several hallucination\nmitigation strategies and show that they are able to significantly reduce the\nnumber of package hallucinations while maintaining code quality. Our\nexperiments and findings highlight package hallucinations as a persistent and\nsystemic phenomenon while using state-of-the-art LLMs for code generation, and\na significant challenge which deserves the research community's urgent\nattention.",
      "tldr_zh": "本研究分析了代码生成大型语言模型 (LLMs) 产生的包幻觉 (package hallucinations)，这是一种由于事实冲突错误导致的软件供应链威胁，类似于新型包混淆攻击。研究者使用16个LLMs和两个提示数据集，生成并评估了576,000个Python和JavaScript代码样本，探讨了不同模型、语言和参数对幻觉发生的影响，发现商业模型的平均幻觉率为5.2%，开源模型为21.7%，并识别出205,474个独特幻觉包示例。最终，他们实现了几种缓解策略，显著降低了包幻觉发生率，同时保持了代码质量，并呼吁研究社区紧急关注这一系统性问题。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "To appear in the 2025 USENIX Security Symposium. 22 pages, 14\n  figures, 8 tables. Edited from original version for submission to a different\n  conference. No change to original results or findings",
      "pdf_url": "http://arxiv.org/pdf/2406.10279v3",
      "published_date": "2024-06-12 03:29:06 UTC",
      "updated_date": "2025-03-02 21:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:47.012897"
    },
    {
      "arxiv_id": "2406.07837v3",
      "title": "Scaling Manipulation Learning with Visual Kinematic Chain Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Zhang",
        "Yuhan Liu",
        "Haonan Chang",
        "Abdeslam Boularias"
      ],
      "abstract": "Learning general-purpose models from diverse datasets has achieved great\nsuccess in machine learning. In robotics, however, existing methods in\nmulti-task learning are typically constrained to a single robot and workspace,\nwhile recent work such as RT-X requires a non-trivial action normalization\nprocedure to manually bridge the gap between different action spaces in diverse\nenvironments. In this paper, we propose the visual kinematics chain as a\nprecise and universal representation of quasi-static actions for robot learning\nover diverse environments, which requires no manual adjustment since the visual\nkinematic chains can be automatically obtained from the robot's model and\ncamera parameters. We propose the Visual Kinematics Transformer (VKT), a\nconvolution-free architecture that supports an arbitrary number of camera\nviewpoints, and that is trained with a single objective of forecasting\nkinematic structures through optimal point-set matching. We demonstrate the\nsuperior performance of VKT over BC transformers as a general agent on Calvin,\nRLBench, Open-X, and real robot manipulation tasks. Video demonstrations can be\nfound at https://mlzxy.github.io/visual-kinetic-chain.",
      "tldr_zh": "本研究解决了机器人多任务学习中环境多样性带来的挑战，提出使用视觉运动链（visual kinematic chain）作为一种精确的通用表示来表示准静态动作，无需手动调整即可从机器人模型和相机参数中自动获取。作者开发了 Visual Kinematics Transformer (VKT)，一个不依赖卷积的架构，支持任意相机视角，并通过点集匹配目标训练模型以预测运动结构。在 Calvin、RLBench、Open-X 和真实机器人任务上，VKT 相较于 BC transformers 展示了显著的性能优势，证明了其作为通用代理的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07837v3",
      "published_date": "2024-06-12 03:10:27 UTC",
      "updated_date": "2024-10-14 15:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:29:57.773311"
    },
    {
      "arxiv_id": "2406.07833v1",
      "title": "Sense Less, Generate More: Pre-training LiDAR Perception with Masked Autoencoders for Ultra-Efficient 3D Sensing",
      "title_zh": "感知更少，生成",
      "authors": [
        "Sina Tayebati",
        "Theja Tulabandhula",
        "Amit R. Trivedi"
      ],
      "abstract": "In this work, we propose a disruptively frugal LiDAR perception dataflow that\ngenerates rather than senses parts of the environment that are either\npredictable based on the extensive training of the environment or have limited\nconsequence to the overall prediction accuracy. Therefore, the proposed\nmethodology trades off sensing energy with training data for low-power robotics\nand autonomous navigation to operate frugally with sensors, extending their\nlifetime on a single battery charge. Our proposed generative pre-training\nstrategy for this purpose, called as radially masked autoencoding (R-MAE), can\nalso be readily implemented in a typical LiDAR system by selectively activating\nand controlling the laser power for randomly generated angular regions during\non-field operations. Our extensive evaluations show that pre-training with\nR-MAE enables focusing on the radial segments of the data, thereby capturing\nspatial relationships and distances between objects more effectively than\nconventional procedures. Therefore, the proposed methodology not only reduces\nsensing energy but also improves prediction accuracy. For example, our\nextensive evaluations on Waymo, nuScenes, and KITTI datasets show that the\napproach achieves over a 5% average precision improvement in detection tasks\nacross datasets and over a 4% accuracy improvement in transferring domains from\nWaymo and nuScenes to KITTI. In 3D object detection, it enhances small object\ndetection by up to 4.37% in AP at moderate difficulty levels in the KITTI\ndataset. Even with 90% radial masking, it surpasses baseline models by up to\n5.59% in mAP/mAPH across all object classes in the Waymo dataset. Additionally,\nour method achieves up to 3.17% and 2.31% improvements in mAP and NDS,\nrespectively, on the nuScenes dataset, demonstrating its effectiveness with\nboth single and fused LiDAR-camera modalities.\nhttps://github.com/sinatayebati/Radial_MAE.",
      "tldr_zh": "本研究提出了一种高效的 LiDAR 感知预训练方法，名为 radially masked autoencoding (R-MAE)，通过生成可预测的环境部分来减少实际感知，从而降低传感器能耗并延长电池寿命。R-MAE 利用 Masked Autoencoders 专注于径向段数据，捕捉物体间的空间关系和距离，并在实际操作中通过选择性激活激光器实现。实验结果显示，该方法在 Waymo、nuScenes 和 KITTI 数据集上提升了检测性能，包括平均精度提高超过 5%、小物体检测 AP 提升 4.37%，即使在 90% 径向掩码下，mAP/mAPH 仍比基线模型高出 5.59%。这种方法不仅节省能量，还提升了跨域适应性和整体预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07833v1",
      "published_date": "2024-06-12 03:02:54 UTC",
      "updated_date": "2024-06-12 03:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:30:12.436149"
    },
    {
      "arxiv_id": "2406.07826v1",
      "title": "The Max-Min Formulation of Multi-Objective Reinforcement Learning: From Theory to a Model-Free Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Giseung Park",
        "Woohyeon Byeon",
        "Seongmin Kim",
        "Elad Havakuk",
        "Amir Leshem",
        "Youngchul Sung"
      ],
      "abstract": "In this paper, we consider multi-objective reinforcement learning, which\narises in many real-world problems with multiple optimization goals. We\napproach the problem with a max-min framework focusing on fairness among the\nmultiple goals and develop a relevant theory and a practical model-free\nalgorithm under the max-min framework. The developed theory provides a\ntheoretical advance in multi-objective reinforcement learning, and the proposed\nalgorithm demonstrates a notable performance improvement over existing baseline\nmethods.",
      "tldr_zh": "本论文探讨了多目标强化学习（multi-objective reinforcement learning），提出了一种以 max-min 框架为核心的方法，强调多个优化目标之间的公平性。\n作者发展了相关的理论，为该领域提供了理论进步，并设计了一个实用的无模型算法（model-free algorithm）。\n实验结果表明，该算法在性能上显著优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07826v1",
      "published_date": "2024-06-12 02:47:54 UTC",
      "updated_date": "2024-06-12 02:47:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:30:21.567641"
    },
    {
      "arxiv_id": "2406.07815v2",
      "title": "Are Large Language Models Good Statisticians?",
      "title_zh": "大语言模型是否是优秀的统计学家？",
      "authors": [
        "Yizhang Zhu",
        "Shiyin Du",
        "Boyan Li",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of scientific tasks including mathematics, physics, and chemistry.\nDespite their successes, the effectiveness of LLMs in handling complex\nstatistical tasks remains systematically under-explored. To bridge this gap, we\nintroduce StatQA, a new benchmark designed for statistical analysis tasks.\nStatQA comprises 11,623 examples tailored to evaluate LLMs' proficiency in\nspecialized statistical tasks and their applicability assessment capabilities,\nparticularly for hypothesis testing methods. We systematically experiment with\nrepresentative LLMs using various prompting strategies and show that even\nstate-of-the-art models such as GPT-4o achieve a best performance of only\n64.83%, indicating significant room for improvement. Notably, while open-source\nLLMs (e.g. LLaMA-3) show limited capability, those fine-tuned ones exhibit\nmarked improvements, outperforming all in-context learning-based methods (e.g.\nGPT-4o). Moreover, our comparative human experiments highlight a striking\ncontrast in error types between LLMs and humans: LLMs primarily make\napplicability errors, whereas humans mostly make statistical task confusion\nerrors. This divergence highlights distinct areas of proficiency and\ndeficiency, suggesting that combining LLM and human expertise could lead to\ncomplementary strengths, inviting further investigation into their\ncollaborative potential. Our source code and data are available at\nhttps://statqa.github.io/.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在统计任务中的表现，发现尽管LLMs在数学、物理和化学等领域表现出色，但其处理复杂统计分析的能力仍需改进。为此，研究者引入了StatQA基准测试，该数据集包含11,623个示例，专注于评估LLMs在专业统计任务（如假设检验）和适用性评估方面的熟练度。实验使用各种提示策略测试了代表性模型，结果显示GPT-4o的最佳表现仅为64.83%，而微调过的开源模型（如LLaMA-3）超过了基于in-context learning的方法。相比之下，LLMs主要犯适用性错误，而人类更易混淆统计任务，这表明结合LLMs和人类专长可能实现互补优势，并为未来合作研究提供方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024 D&B. 34 pages, 11 figures, 21 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.07815v2",
      "published_date": "2024-06-12 02:23:51 UTC",
      "updated_date": "2024-10-10 06:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:30:35.744555"
    },
    {
      "arxiv_id": "2406.07814v1",
      "title": "Collective Constitutional AI: Aligning a Language Model with Public Input",
      "title_zh": "翻译失败",
      "authors": [
        "Saffron Huang",
        "Divya Siddarth",
        "Liane Lovitt",
        "Thomas I. Liao",
        "Esin Durmus",
        "Alex Tamkin",
        "Deep Ganguli"
      ],
      "abstract": "There is growing consensus that language model (LM) developers should not be\nthe sole deciders of LM behavior, creating a need for methods that enable the\nbroader public to collectively shape the behavior of LM systems that affect\nthem. To address this need, we present Collective Constitutional AI (CCAI): a\nmulti-stage process for sourcing and integrating public input into LMs-from\nidentifying a target population to sourcing principles to training and\nevaluating a model. We demonstrate the real-world practicality of this approach\nby creating what is, to our knowledge, the first LM fine-tuned with\ncollectively sourced public input and evaluating this model against a baseline\nmodel trained with established principles from a LM developer. Our quantitative\nevaluations demonstrate several benefits of our approach: the CCAI-trained\nmodel shows lower bias across nine social dimensions compared to the baseline\nmodel, while maintaining equivalent performance on language, math, and\nhelpful-harmless evaluations. Qualitative comparisons of the models suggest\nthat the models differ on the basis of their respective constitutions, e.g.,\nwhen prompted with contentious topics, the CCAI-trained model tends to generate\nresponses that reframe the matter positively instead of a refusal. These\nresults demonstrate a promising, tractable pathway toward publicly informed\ndevelopment of language models.",
      "tldr_zh": "本研究提出 Collective Constitutional AI (CCAI)，一种多阶段过程，允许公众参与塑造语言模型 (LM) 的行为，从而解决 LM 开发者独揽决策权的局限性。该方法从识别目标人群开始，到收集公共原则，再到训练和评估模型，最终微调出一个基于公众输入的 LM。实验结果显示，与基线模型相比，CCAI 训练的模型在九个社会维度上表现出更低的偏见，同时在语言、数学和帮助性-无害性评估中保持相当性能，且在争议性话题上更倾向于积极重构回应而非拒绝。这些发现为公众参与语言模型开发提供了一个可行且有前景的路径。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.2.7; K.4.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07814v1",
      "published_date": "2024-06-12 02:20:46 UTC",
      "updated_date": "2024-06-12 02:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:30:50.954836"
    },
    {
      "arxiv_id": "2406.07812v1",
      "title": "To be Continuous, or to be Discrete, Those are Bits of Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Wang",
        "Masao Utiyama"
      ],
      "abstract": "Recently, binary representation has been proposed as a novel representation\nthat lies between continuous and discrete representations. It exhibits\nconsiderable information-preserving capability when being used to replace\ncontinuous input vectors. In this paper, we investigate the feasibility of\nfurther introducing it to the output side, aiming to allow models to output\nbinary labels instead. To preserve the structural information on the output\nside along with label information, we extend the previous contrastive hashing\nmethod as structured contrastive hashing. More specifically, we upgrade CKY\nfrom label-level to bit-level, define a new similarity function with span\nmarginal probabilities, and introduce a novel contrastive loss function with a\ncarefully designed instance selection strategy. Our model achieves competitive\nperformance on various structured prediction tasks, and demonstrates that\nbinary representation can be considered a novel representation that further\nbridges the gap between the continuous nature of deep learning and the discrete\nintrinsic property of natural languages.",
      "tldr_zh": "该论文探讨了二进制表示(binary representation)作为一种介于连续和离散表示之间的创新方法，旨在将其从输入端扩展到输出端，让模型输出二进制标签以保留结构信息和标签信息。作者扩展了之前的对比哈希(contrastive hashing)方法为结构化对比哈希(structured contrastive hashing)，具体包括将 CKY 从标签级升级到位级、定义基于 span 边缘概率的新相似性函数，以及引入带有精心设计的实例选择策略的新对比损失函数(contrastive loss)。实验结果显示，该模型在各种结构化预测任务上取得了竞争性性能，并证明了二进制表示能够桥接深度学习连续性和自然语言离散性的差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL-2024",
      "pdf_url": "http://arxiv.org/pdf/2406.07812v1",
      "published_date": "2024-06-12 02:08:45 UTC",
      "updated_date": "2024-06-12 02:08:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:31:03.556062"
    },
    {
      "arxiv_id": "2406.07811v2",
      "title": "Evolutionary Computation and Explainable AI: A Roadmap to Understandable Intelligent Systems",
      "title_zh": "进化计算与可解释人工智能：通往可理解智能系统的路线图",
      "authors": [
        "Ryan Zhou",
        "Jaume Bacardit",
        "Alexander Brownlee",
        "Stefano Cagnoni",
        "Martin Fyvie",
        "Giovanni Iacca",
        "John McCall",
        "Niki van Stein",
        "David Walker",
        "Ting Hu"
      ],
      "abstract": "Artificial intelligence methods are being increasingly applied across various\ndomains, but their often opaque nature has raised concerns about accountability\nand trust. In response, the field of explainable AI (XAI) has emerged to\naddress the need for human-understandable AI systems. Evolutionary computation\n(EC), a family of powerful optimization and learning algorithms, offers\nsignificant potential to contribute to XAI, and vice versa. This paper provides\nan introduction to XAI and reviews current techniques for explaining machine\nlearning models. We then explore how EC can be leveraged in XAI and examine\nexisting XAI approaches that incorporate EC techniques. Furthermore, we discuss\nthe application of XAI principles within EC itself, investigating how these\nprinciples can illuminate the behavior and outcomes of EC algorithms, their\n(automatic) configuration, and the underlying problem landscapes they optimize.\nFinally, we discuss open challenges in XAI and highlight opportunities for\nfuture research at the intersection of XAI and EC. Our goal is to demonstrate\nEC's suitability for addressing current explainability challenges and to\nencourage further exploration of these methods, ultimately contributing to the\ndevelopment of more understandable and trustworthy ML models and EC algorithms.",
      "tldr_zh": "该论文探讨了演化计算(Evolutionary Computation, EC)和可解释AI(Explainable AI, XAI)的交叉领域，旨在解决AI系统的不透明性问题以提升其可信度和责任性。作者回顾了当前解释机器学习(Machine Learning)模型的技术，并阐述了如何利用EC算法来增强XAI，同时探讨在EC自身中应用XAI原则来阐明算法行为、配置和优化问题。最终，论文指出了XAI的开放挑战和未来研究机会，强调EC在开发更可理解和可信的AI系统中的潜力，并鼓励进一步探索。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "24 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:2306.14786",
      "pdf_url": "http://arxiv.org/pdf/2406.07811v2",
      "published_date": "2024-06-12 02:06:24 UTC",
      "updated_date": "2024-10-17 07:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:31:13.744165"
    },
    {
      "arxiv_id": "2406.10278v1",
      "title": "Prompt-Based Length Controlled Generation with Multiple Control Types",
      "title_zh": "翻译失败",
      "authors": [
        "Renlong Jie",
        "Xiaojun Meng",
        "Lifeng Shang",
        "Xin Jiang",
        "Qun Liu"
      ],
      "abstract": "Large language models (LLMs) have attracted great attention given their\nstrong performance on a wide range of NLP tasks. In practice, users often\nexpect generated texts to fall within a specific length range, making length\ncontrolled generation an important topic, especially for GPT-style models.\nExisting length control methods mostly focus on a simple control type of \"equal\nto\" a target length. Different from them, we propose a prompt-based method to\nachieve length controlled generation under different control types with high\naccuracy. In particular, we adopt reinforcement learning (RL) and sample\nfiltering with the reward signal given by rule-based reward models, which\nenhances the length control ability of models by rewarding outputs that follow\ncertain control instructions. In addition, we introduce a standard prompt\nextractor to parse arbitrary users' input into standard control instructions.\nExperiments show that our method significantly improves the accuracy of\nprompt-based length control on popular summarization datasets like CNNDM and\nNYT under multiple control types. Moreover, both the standard prompt extractor\nand RL-tuned model show strong generalization to unseen control prompt\ntemplates.",
      "tldr_zh": "本文提出一种基于提示的方法，用于实现多种控制类型的长度控制生成，针对大型语言模型 (LLMs) 在生成文本时满足特定长度要求的问题。方法结合强化学习 (RL) 和样本过滤，通过 rule-based 奖励模型奖励符合控制指令的输出，并引入标准提示提取器来解析用户输入为标准指令。实验结果显示，该方法在 CNNDM 和 NYT 等总结数据集上显著提高了长度控制的准确率，并展现出对未见控制提示模板的强泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACL 2024 findings. arXiv admin note: text overlap with\n  arXiv:2308.12030",
      "pdf_url": "http://arxiv.org/pdf/2406.10278v1",
      "published_date": "2024-06-12 01:49:54 UTC",
      "updated_date": "2024-06-12 01:49:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:31:26.565959"
    },
    {
      "arxiv_id": "2406.07803v2",
      "title": "EmoSphere-TTS: Emotional Style and Intensity Modeling via Spherical Emotion Vector for Controllable Emotional Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Deok-Hyeon Cho",
        "Hyung-Seok Oh",
        "Seung-Bin Kim",
        "Sang-Hoon Lee",
        "Seong-Whan Lee"
      ],
      "abstract": "Despite rapid advances in the field of emotional text-to-speech (TTS), recent\nstudies primarily focus on mimicking the average style of a particular emotion.\nAs a result, the ability to manipulate speech emotion remains constrained to\nseveral predefined labels, compromising the ability to reflect the nuanced\nvariations of emotion. In this paper, we propose EmoSphere-TTS, which\nsynthesizes expressive emotional speech by using a spherical emotion vector to\ncontrol the emotional style and intensity of the synthetic speech. Without any\nhuman annotation, we use the arousal, valence, and dominance pseudo-labels to\nmodel the complex nature of emotion via a Cartesian-spherical transformation.\nFurthermore, we propose a dual conditional adversarial network to improve the\nquality of generated speech by reflecting the multi-aspect characteristics. The\nexperimental results demonstrate the model ability to control emotional style\nand intensity with high-quality expressive speech.",
      "tldr_zh": "该研究提出 EmoSphere-TTS 框架，通过 spherical emotion vector 来控制合成语音的情感风格和强度，解决了传统情感 Text-to-Speech (TTS) 系统仅限于预定义标签的局限性。框架利用 arousal, valence, and dominance 的伪标签进行 Cartesian-spherical 变换建模情感复杂性，并引入 dual conditional adversarial network 以提升生成语音的多方面质量。实验结果表明，该模型能够实现高品质的表达性语音合成，并有效调节情感强度和风格。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Proceedings of Interspeech",
      "pdf_url": "http://arxiv.org/pdf/2406.07803v2",
      "published_date": "2024-06-12 01:40:29 UTC",
      "updated_date": "2024-11-04 21:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:31:38.483373"
    },
    {
      "arxiv_id": "2406.07796v2",
      "title": "Battling Botpoop using GenAI for Higher Education: A Study of a Retrieval Augmented Generation Chatbots Impact on Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Maung Thway",
        "Jose Recatala-Gomez",
        "Fun Siong Lim",
        "Kedar Hippalgaonkar",
        "Leonard W. T. Ng"
      ],
      "abstract": "Generative artificial intelligence (GenAI) and large language models (LLMs)\nhave simultaneously opened new avenues for enhancing human learning and\nincreased the prevalence of poor-quality information in student response -\ntermed Botpoop. This study introduces Professor Leodar, a custom-built,\nSinglish-speaking Retrieval Augmented Generation (RAG) chatbot designed to\nenhance educational while reducing Botpoop. Deployed at Nanyang Technological\nUniversity, Singapore, Professor Leodar offers a glimpse into the future of\nAI-assisted learning, offering personalized guidance, 24/7 availability, and\ncontextually relevant information. Through a mixed-methods approach, we examine\nthe impact of Professor Leodar on learning, engagement, and exam preparedness,\nwith 97.1% of participants reporting positive experiences. These findings help\ndefine possible roles of AI in education and highlight the potential of custom\nGenAI chatbots. Our combination of chatbot development, in-class deployment and\noutcomes study offers a benchmark for GenAI educational tools and is a stepping\nstone for redefining the interplay between AI and human learning.",
      "tldr_zh": "这篇论文探讨了 Generative AI (GenAI) 在高等教育中的双重影响，即提升学习同时增加低质量信息（Botpoop），并引入了 Professor Leodar，一款自定义的 Retrieval Augmented Generation (RAG) 聊天机器人，使用 Singlish 语言提供个性化指导、24/7 可用性和相关信息。研究在新加坡南洋理工大学部署该机器人，并通过混合方法评估其对学习、参与度和考试准备的影响，结果显示 97.1% 的参与者报告积极体验。论文的发现突出了自定义 GenAI 聊天机器人在减少 Botpoop 和优化教育中的潜力，并为 AI 在教育领域的应用提供了基准。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 5 figures, SI with Annexes A, B and C upon request",
      "pdf_url": "http://arxiv.org/pdf/2406.07796v2",
      "published_date": "2024-06-12 01:19:36 UTC",
      "updated_date": "2024-06-22 01:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:31:51.946537"
    },
    {
      "arxiv_id": "2406.07794v2",
      "title": "Making Task-Oriented Dialogue Datasets More Natural by Synthetically Generating Indirect User Requests",
      "title_zh": "翻译失败",
      "authors": [
        "Amogh Mannekote",
        "Jinseok Nam",
        "Ziming Li",
        "Jian Gao",
        "Kristy Elizabeth Boyer",
        "Bonnie J. Dorr"
      ],
      "abstract": "Indirect User Requests (IURs), such as \"It's cold in here\" instead of \"Could\nyou please increase the temperature?\" are common in human-human task-oriented\ndialogue and require world knowledge and pragmatic reasoning from the listener.\nWhile large language models (LLMs) can handle these requests effectively,\nsmaller models deployed on virtual assistants often struggle due to resource\nconstraints. Moreover, existing task-oriented dialogue benchmarks lack\nsufficient examples of complex discourse phenomena such as indirectness. To\naddress this, we propose a set of linguistic criteria along with an LLM-based\npipeline for generating realistic IURs to test natural language understanding\n(NLU) and dialogue state tracking (DST) models before deployment in a new\ndomain. We also release IndirectRequests, a dataset of IURs based on the Schema\nGuided Dialog (SGD) corpus, as a comparative testbed for evaluating the\nperformance of smaller models in handling indirect requests.",
      "tldr_zh": "本研究针对任务导向对话中的Indirect User Requests (IURs)问题，指出现有数据集缺乏自然间接表达（如“It's cold in here”而非直接指令），这需要世界知识和语用推理，而小型模型（如部署在虚拟助手上的）因资源限制难以处理。作者提出一套语言标准和基于large language models (LLMs)的合成生成管道，用于创建真实的IURs，以测试natural language understanding (NLU)和dialogue state tracking (DST)模型在部署前的新领域适应性。该工作还发布了IndirectRequests数据集，基于Schema Guided Dialog (SGD)语料库，作为评估小型模型处理间接请求性能的基准测试平台。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07794v2",
      "published_date": "2024-06-12 01:18:04 UTC",
      "updated_date": "2024-06-16 21:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:32:04.465539"
    },
    {
      "arxiv_id": "2406.07791v8",
      "title": "Judging the Judges: A Systematic Study of Position Bias in LLM-as-a-Judge",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Shi",
        "Chiyu Ma",
        "Wenhua Liang",
        "Xingjian Diao",
        "Weicheng Ma",
        "Soroush Vosoughi"
      ],
      "abstract": "LLM-as-a-Judge has emerged as a promising alternative to human evaluators\nacross various tasks, yet inherent biases - particularly position bias, the\ntendency to favor solutions based on their position within the prompt -\ncompromise its reliability. This exploratory study evaluates position bias in\nLLM judges across pairwise and list-wise comparison settings, introducing three\nmetrics: repetition stability, position consistency, and preference fairness.\nOur experiments, involving 15 LLM judges across MTBench and DevBench with 22\ntasks and approximately 40 solution-generating models, result in over 150,000\nevaluation instances. We identify Judge-Level, Candidate-Level, and Task-Level\nfactors contributing to bias. The findings confirm that position bias is not\ndue to random chance and varies significantly across judges and tasks. While\nposition bias is weakly influenced by the length of prompt components, it is\nstrongly affected by the quality gap between solutions. Our agreement and\ndisagreement analysis among judges further provides insights into the\ndistribution of judging difficulty across the dataset, and highlights the\npotential for dataset modifications.",
      "tldr_zh": "这篇论文系统研究了LLM-as-a-Judge中的位置偏差（position bias），即LLM判断者倾向于基于解决方案在提示中的位置而产生偏好，从而影响其可靠性。研究引入了repetition stability、position consistency和preference fairness三个指标，通过超过15万个评估实例实验，评估了15个LLM判断者在MTBench和DevBench上的表现，涉及22个任务和约40个生成模型。结果显示，位置偏差并非随机发生，受判断者水平（Judge-Level）、候选者水平（Candidate-Level）和任务水平（Task-Level）因素影响，主要与解决方案质量差距相关，并为优化数据集和减少偏差提供了潜在改进建议。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07791v8",
      "published_date": "2024-06-12 01:12:28 UTC",
      "updated_date": "2025-04-17 02:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:32:15.483982"
    },
    {
      "arxiv_id": "2406.07790v1",
      "title": "Hierarchical Neural Networks, p-Adic PDEs, and Applications to Image Processing",
      "title_zh": "翻译失败",
      "authors": [
        "W. A. Zúñiga-Galindo",
        "B. A. Zambrano-Luna",
        "Baboucarr Dibba"
      ],
      "abstract": "The first goal of this article is to introduce a new type of p-adic\nreaction-diffusion cellular neural network with delay. We study the stability\nof these networks and provide numerical simulations of their responses. The\nsecond goal is to provide a quick review of the state of the art of p-adic\ncellular neural networks and their applications to image processing.",
      "tldr_zh": "这篇文章介绍了新的 p-adic 反应-扩散细胞神经网络（带有延迟），并研究了其稳定性，同时通过数值模拟展示其响应特性。其次，它回顾了 p-adic 细胞神经网络的当前发展状态及其在图像处理中的应用。这些研究有助于扩展分层神经网络和 p-Adic PDEs 在处理复杂图像任务方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "eess.IV",
        "math.AP"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.07790v1",
      "published_date": "2024-06-12 01:10:32 UTC",
      "updated_date": "2024-06-12 01:10:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:32:26.754857"
    },
    {
      "arxiv_id": "2406.07778v2",
      "title": "A Study of Backdoors in Instruction Fine-tuned Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jayaram Raghuram",
        "George Kesidis",
        "David J. Miller"
      ],
      "abstract": "Backdoor data poisoning, inserted within instruction examples used to\nfine-tune a foundation Large Language Model (LLM) for downstream tasks\n(\\textit{e.g.,} sentiment prediction), is a serious security concern due to the\nevasive nature of such attacks. The poisoning is usually in the form of a\n(seemingly innocuous) trigger word or phrase inserted into a very small\nfraction of the fine-tuning samples from a target class. Such backdoor attacks\ncan: alter response sentiment, violate censorship, over-refuse (invoke\ncensorship for legitimate queries), inject false content, or trigger nonsense\nresponses (hallucinations). In this work we investigate the efficacy of\ninstruction fine-tuning backdoor attacks as attack \"hyperparameters\" are varied\nunder a variety of scenarios, considering: the trigger location in the poisoned\nexamples; robustness to change in the trigger location, partial triggers, and\nsynonym substitutions at test time; attack transfer from one (fine-tuning)\ndomain to a related test domain; and clean-label vs. dirty-label poisoning.\nBased on our observations, we propose and evaluate two defenses against these\nattacks: i) a \\textit{during-fine-tuning defense} based on word-frequency\ncounts that assumes the (possibly poisoned) fine-tuning dataset is available\nand identifies the backdoor trigger tokens; and ii) a \\textit{post-fine-tuning\ndefense} based on downstream clean fine-tuning of the backdoored LLM with a\nsmall defense dataset. Finally, we provide a brief survey of related work on\nbackdoor attacks and defenses.",
      "tldr_zh": "本文研究了在指令微调的语言模型(LLM)中，后门(Backdoor)数据投毒攻击的有效性，探讨了攻击超参数的影响，包括触发词位置、测试时的鲁棒性（如位置变化或近义词替换）、域转移，以及干净标签 vs. 脏标签投毒。实验结果显示，这些攻击能导致模型出现响应异常、违反审查或注入虚假内容等问题。作者提出了两种防御策略：一种是微调期间基于词频计数的触发词识别方法，另一种是微调后使用小规模干净数据集进行下游微调。总体上，该研究为后门攻击的检测和缓解提供了重要见解，并简要回顾了相关工作。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2406.07778v2",
      "published_date": "2024-06-12 00:01:32 UTC",
      "updated_date": "2024-08-21 23:07:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T19:32:39.463819"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 150,
  "processed_papers_count": 150,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T19:33:07.171805"
}