[
  {
    "arxiv_id": "2512.06595v1",
    "title": "ChargingBoul: A Competitive Negotiating Agent with Novel Opponent Modeling",
    "authors": [
      "Joe Shymanski"
    ],
    "abstract": "Automated negotiation has emerged as a critical area of research in multiagent systems, with applications spanning e-commerce, resource allocation, and autonomous decision-making. This paper presents ChargingBoul, a negotiating agent that competed in the 2022 Automated Negotiating Agents Competition (ANAC) and placed second in individual utility by an exceptionally narrow margin. ChargingBoul employs a lightweight yet effective strategy that balances concession and opponent modeling to achieve high negotiation outcomes. The agent classifies opponents based on bid patterns, dynamically adjusts its bidding strategy, and applies a concession policy in later negotiation stages to maximize utility while fostering agreements. We evaluate ChargingBoul's performance using competition results and subsequent studies that have utilized the agent in negotiation research. Our analysis highlights ChargingBoul's effectiveness across diverse opponent strategies and its contributions to advancing automated negotiation techniques. We also discuss potential enhancements, including more sophisticated opponent modeling and adaptive bidding heuristics, to improve its performance further.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "10 pages, 3 figures. Describes the ChargingBoul negotiating agent submitted to ANAC 2022. Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.06595v1",
    "published_date": "2025-12-06 23:32:11 UTC",
    "updated_date": "2025-12-06 23:32:11 UTC"
  },
  {
    "arxiv_id": "2512.09944v2",
    "title": "Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting",
    "authors": [
      "Moein Heidari",
      "Mohammad Amin Roohi",
      "Ilker Hacihaliloglu"
    ],
    "abstract": "Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.09944v2",
    "published_date": "2025-12-06 23:27:54 UTC",
    "updated_date": "2025-12-15 19:58:48 UTC"
  },
  {
    "arxiv_id": "2512.06591v1",
    "title": "Beyond Satisfaction: From Placebic to Actionable Explanations For Enhanced Understandability",
    "authors": [
      "Joe Shymanski",
      "Jacob Brue",
      "Sandip Sen"
    ],
    "abstract": "Explainable AI (XAI) presents useful tools to facilitate transparency and trustworthiness in machine learning systems. However, current evaluations of system explainability often rely heavily on subjective user surveys, which may not adequately capture the effectiveness of explanations. This paper critiques the overreliance on user satisfaction metrics and explores whether these can differentiate between meaningful (actionable) and vacuous (placebic) explanations. In experiments involving optimal Social Security filing age selection tasks, participants used one of three protocols: no explanations, placebic explanations, and actionable explanations. Participants who received actionable explanations significantly outperformed the other groups in objective measures of their mental model, but users rated placebic and actionable explanations as equally satisfying. This suggests that subjective surveys alone fail to capture whether explanations truly support users in building useful domain understanding. We propose that future evaluations of agent explanation capabilities should integrate objective task performance metrics alongside subjective assessments to more accurately measure explanation quality. The code for this study can be found at https://github.com/Shymkis/social-security-explainer.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "21 pages, 7 figures, 6 tables. EXTRAAMAS 2025 submission. Preprint version",
    "pdf_url": "https://arxiv.org/pdf/2512.06591v1",
    "published_date": "2025-12-06 23:06:18 UTC",
    "updated_date": "2025-12-06 23:06:18 UTC"
  },
  {
    "arxiv_id": "2512.06590v1",
    "title": "Towards Efficient Hypergraph and Multi-LLM Agent Recommender Systems",
    "authors": [
      "Tendai Mukande",
      "Esraa Ali",
      "Annalina Caputo",
      "Ruihai Dong",
      "Noel OConnor"
    ],
    "abstract": "Recommender Systems (RSs) have become the cornerstone of various applications such as e-commerce and social media platforms. The evolution of RSs is paramount in the digital era, in which personalised user experience is tailored to the user's preferences. Large Language Models (LLMs) have sparked a new paradigm - generative retrieval and recommendation. Despite their potential, generative RS methods face issues such as hallucination, which degrades the recommendation performance, and high computational cost in practical scenarios. To address these issues, we introduce HGLMRec, a novel Multi-LLM agent-based RS that incorporates a hypergraph encoder designed to capture complex, multi-behaviour relationships between users and items. The HGLMRec model retrieves only the relevant tokens during inference, reducing computational overhead while enriching the retrieval context. Experimental results show performance improvement by HGLMRec against state-of-the-art baselines at lower computational cost.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.IR",
    "comment": "8 Pages",
    "pdf_url": "https://arxiv.org/pdf/2512.06590v1",
    "published_date": "2025-12-06 23:04:49 UTC",
    "updated_date": "2025-12-06 23:04:49 UTC"
  },
  {
    "arxiv_id": "2512.15739v1",
    "title": "Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance",
    "authors": [
      "Sharif Al Mamun",
      "Rakib Hossain",
      "Md. Jobayer Rahman",
      "Malay Kumar Devnath",
      "Farhana Afroz",
      "Lisan Al Amin"
    ],
    "abstract": "A Bayesian analytics framework that precisely quantifies uncertainty offers a significant advance for financial risk management. We develop an integrated approach that consistently enhances the handling of risk in market volatility forecasting, fraud detection, and compliance monitoring. Our probabilistic, interpretable models deliver reliable results: We evaluate the performance of one-day-ahead 95% Value-at-Risk (VaR) forecasts on daily S&P 500 returns, with a training period from 2000 to 2019 and an out-of-sample test period spanning 2020 to 2024. Formal tests of unconditional (Kupiec) and conditional (Christoffersen) coverage reveal that an LSTM baseline achieves near-nominal calibration. In contrast, a GARCH(1,1) model with Student-t innovations underestimates tail risk. Our proposed discount-factor DLM model produces a slightly liberal VaR estimate, with evidence of clustered violations. Bayesian logistic regression improves recall and AUC-ROC for fraud detection, and a hierarchical Beta state-space model provides transparent and adaptive compliance risk assessment. The pipeline is distinguished by precise uncertainty quantification, interpretability, and GPU-accelerated analysis, delivering up to 50x speedup. Remaining challenges include sparse fraud data and proxy compliance labels, but the framework enables actionable risk insights. Future expansion will extend feature sets, explore regime-switching priors, and enhance scalable inference.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15739v1",
    "published_date": "2025-12-06 23:00:19 UTC",
    "updated_date": "2025-12-06 23:00:19 UTC"
  },
  {
    "arxiv_id": "2512.06582v1",
    "title": "QL-LSTM: A Parameter-Efficient LSTM for Stable Long-Sequence Modeling",
    "authors": [
      "Isaac Kofi Nti"
    ],
    "abstract": "Recurrent neural architectures such as LSTM and GRU remain widely used in sequence modeling, but they continue to face two core limitations: redundant gate-specific parameters and reduced ability to retain information across long temporal distances. This paper introduces the Quantum-Leap LSTM (QL-LSTM), a recurrent architecture designed to address both challenges through two independent components. The Parameter-Shared Unified Gating mechanism replaces all gate-specific transformations with a single shared weight matrix, reducing parameters by approximately 48 percent while preserving full gating behavior. The Hierarchical Gated Recurrence with Additive Skip Connections component adds a multiplication-free pathway that improves long-range information flow and reduces forget-gate degradation. We evaluate QL-LSTM on sentiment classification using the IMDB dataset with extended document lengths, comparing it to LSTM, GRU, and BiLSTM reference models. QL-LSTM achieves competitive accuracy while using substantially fewer parameters. Although the PSUG and HGR-ASC components are more efficient per time step, the current prototype remains limited by the inherent sequential nature of recurrent models and therefore does not yet yield wall-clock speed improvements without further kernel-level optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06582v1",
    "published_date": "2025-12-06 22:29:19 UTC",
    "updated_date": "2025-12-06 22:29:19 UTC"
  },
  {
    "arxiv_id": "2512.15738v1",
    "title": "Hybrid Quantum-Classical Ensemble Learning for S\\&P 500 Directional Prediction",
    "authors": [
      "Abraham Itzhak Weinberg"
    ],
    "abstract": "Financial market prediction is a challenging application of machine learning, where even small improvements in directional accuracy can yield substantial value. Most models struggle to exceed 55--57\\% accuracy due to high noise, non-stationarity, and market efficiency. We introduce a hybrid ensemble framework combining quantum sentiment analysis, Decision Transformer architecture, and strategic model selection, achieving 60.14\\% directional accuracy on S\\&P 500 prediction, a 3.10\\% improvement over individual models.\n  Our framework addresses three limitations of prior approaches. First, architecture diversity dominates dataset diversity: combining different learning algorithms (LSTM, Decision Transformer, XGBoost, Random Forest, Logistic Regression) on the same data outperforms training identical architectures on multiple datasets (60.14\\% vs.\\ 52.80\\%), confirmed by correlation analysis ($r>0.6$ among same-architecture models). Second, a 4-qubit variational quantum circuit enhances sentiment analysis, providing +0.8\\% to +1.5\\% gains per model. Third, smart filtering excludes weak predictors (accuracy $<52\\%$), improving ensemble performance (Top-7 models: 60.14\\% vs.\\ all 35 models: 51.2\\%).\n  We evaluate on 2020--2023 market data across seven instruments, covering diverse regimes including the COVID-19 crash and inflation-driven correction. McNemar's test confirms statistical significance ($p<0.05$). Preliminary backtesting with confidence-based filtering (6+ model consensus) yields a Sharpe ratio of 1.2 versus buy-and-hold's 0.8, demonstrating practical trading potential.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.ST"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15738v1",
    "published_date": "2025-12-06 22:22:09 UTC",
    "updated_date": "2025-12-06 22:22:09 UTC"
  },
  {
    "arxiv_id": "2512.06573v1",
    "title": "The Effect of Belief Boxes and Open-mindedness on Persuasion",
    "authors": [
      "Onur Bilgin",
      "Abdullah As Sami",
      "Sriram Sai Vujjini",
      "John Licato"
    ],
    "abstract": "As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain",
    "pdf_url": "https://arxiv.org/pdf/2512.06573v1",
    "published_date": "2025-12-06 21:31:51 UTC",
    "updated_date": "2025-12-06 21:31:51 UTC"
  },
  {
    "arxiv_id": "2512.06563v1",
    "title": "Deep Manifold Part 2: Neural Network Mathematics",
    "authors": [
      "Max Y. Ma",
      "Gen-Hua Shi"
    ],
    "abstract": "This work develops the global equations of neural networks through stacked piecewise manifolds, fixed-point theory, and boundary-conditioned iteration. Once fixed coordinates and operators are removed, a neural network appears as a learnable numerical computation shaped by manifold complexity, high-order nonlinearity, and boundary conditions. Real-world data impose strong data complexity, near-infinite scope, scale, and minibatch fragmentation, while training dynamics produce learning complexity through shifting node covers, curvature accumulation, and the rise and decay of plasticity. These forces constrain learnability and explain why capability emerges only when fixed-point regions stabilize. Neural networks do not begin with fixed points; they construct them through residual-driven iteration. This perspective clarifies the limits of monolithic models under geometric and data-induced plasticity and motivates architectures and federated systems that distribute manifold complexity across many elastic models, forming a coherent world-modeling framework grounded in geometry, algebra, fixed points, and real-data complexity.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06563v1",
    "published_date": "2025-12-06 20:44:24 UTC",
    "updated_date": "2025-12-06 20:44:24 UTC"
  },
  {
    "arxiv_id": "2512.06562v1",
    "title": "SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities",
    "authors": [
      "Dung Thuy Nguyen",
      "Quang Nguyen",
      "Preston K. Robinette",
      "Eli Jiang",
      "Taylor T. Johnson",
      "Kevin Leach"
    ],
    "abstract": "Recent advances in 3D-aware generative models have enabled high-fidelity image synthesis of human identities. However, this progress raises urgent questions around user consent and the ability to remove specific individuals from a model's output space. We address this by introducing SUGAR, a framework for scalable generative unlearning that enables the removal of many identities (simultaneously or sequentially) without retraining the entire model. Rather than projecting unwanted identities to unrealistic outputs or relying on static template faces, SUGAR learns a personalized surrogate latent for each identity, diverting reconstructions to visually coherent alternatives while preserving the model's quality and diversity. We further introduce a continual utility preservation objective that guards against degradation as more identities are forgotten. SUGAR achieves state-of-the-art performance in removing up to 200 identities, while delivering up to a 700% improvement in retention utility compared to existing baselines. Our code is publicly available at https://github.com/judydnguyen/SUGAR-Generative-Unlearn.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06562v1",
    "published_date": "2025-12-06 20:42:38 UTC",
    "updated_date": "2025-12-06 20:42:38 UTC"
  },
  {
    "arxiv_id": "2512.06556v1",
    "title": "Securing the Model Context Protocol: Defending LLMs Against Tool Poisoning and Adversarial Attacks",
    "authors": [
      "Saeid Jamshidi",
      "Kawser Wazed Nafi",
      "Arghavan Moradi Dakhel",
      "Negar Shahabi",
      "Foutse Khomh",
      "Naser Ezzati-Jivan"
    ],
    "abstract": "The Model Context Protocol (MCP) enables Large Language Models to integrate external tools through structured descriptors, increasing autonomy in decision-making, task execution, and multi-agent workflows. However, this autonomy creates a largely overlooked security gap. Existing defenses focus on prompt-injection attacks and fail to address threats embedded in tool metadata, leaving MCP-based systems exposed to semantic manipulation. This work analyzes three classes of semantic attacks on MCP-integrated systems: (1) Tool Poisoning, where adversarial instructions are hidden in tool descriptors; (2) Shadowing, where trusted tools are indirectly compromised through contaminated shared context; and (3) Rug Pulls, where descriptors are altered after approval to subvert behavior. To counter these threats, we introduce a layered security framework with three components: RSA-based manifest signing to enforce descriptor integrity, LLM-on-LLM semantic vetting to detect suspicious tool definitions, and lightweight heuristic guardrails that block anomalous tool behavior at runtime. Through evaluation of GPT-4, DeepSeek, and Llama-3.5 across eight prompting strategies, we find that security performance varies widely by model architecture and reasoning method. GPT-4 blocks about 71 percent of unsafe tool calls, balancing latency and safety. DeepSeek shows the highest resilience to Shadowing attacks but with greater latency, while Llama-3.5 is fastest but least robust. Our results show that the proposed framework reduces unsafe tool invocation rates without model fine-tuning or internal modification.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06556v1",
    "published_date": "2025-12-06 20:07:58 UTC",
    "updated_date": "2025-12-06 20:07:58 UTC"
  },
  {
    "arxiv_id": "2512.06555v1",
    "title": "BEACON: A Unified Behavioral-Tactical Framework for Explainable Cybercrime Analysis with Large Language Models",
    "authors": [
      "Arush Sachdeva",
      "Rajendraprasad Saravanan",
      "Gargi Sarkar",
      "Kavita Vemuri",
      "Sandeep Kumar Shukla"
    ],
    "abstract": "Cybercrime increasingly exploits human cognitive biases in addition to technical vulnerabilities, yet most existing analytical frameworks focus primarily on operational aspects and overlook psychological manipulation. This paper proposes BEACON, a unified dual-dimension framework that integrates behavioral psychology with the tactical lifecycle of cybercrime to enable structured, interpretable, and scalable analysis of cybercrime. We formalize six psychologically grounded manipulation categories derived from Prospect Theory and Cialdini's principles of persuasion, alongside a fourteen-stage cybercrime tactical lifecycle spanning reconnaissance to final impact. A single large language model is fine-tuned using parameter-efficient learning to perform joint multi-label classification across both psychological and tactical dimensions while simultaneously generating human-interpretable explanations. Experiments conducted on a curated dataset of real-world and synthetically augmented cybercrime narratives demonstrate a 20 percent improvement in overall classification accuracy over the base model, along with substantial gains in reasoning quality measured using ROUGE and BERTScore. The proposed system enables automated decomposition of unstructured victim narratives into structured behavioral and operational intelligence, supporting improved cybercrime investigation, case linkage, and proactive scam detection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06555v1",
    "published_date": "2025-12-06 19:59:24 UTC",
    "updated_date": "2025-12-06 19:59:24 UTC"
  },
  {
    "arxiv_id": "2512.06547v2",
    "title": "A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation",
    "authors": [
      "Xiaocan Li",
      "Shiliang Wu",
      "Zheng Shen"
    ],
    "abstract": "Decoupled PPO has been a successful reinforcement learning (RL) algorithm to deal with the high data staleness under the asynchronous RL setting. Decoupled loss used in decoupled PPO improves coupled-loss style of algorithms' (e.g., standard PPO, GRPO) learning stability by introducing a proximal policy to decouple the off-policy correction (importance weight) from the policy update constraint (trust region). However, the proximal policy requires an extra forward pass through the model at each training step, creating a computational overhead for large language models training. We observe that since the proximal policy only serves as a trust region anchor between the behavior and target policies, we can approximate it through simple interpolation without explicit computation. We call this approach A-3PO (APproximated Proximal Policy Optimization). A-3PO eliminates this overhead, accelerating training by 1.8x speedup while maintaining comparable performance. Code \\& off-the-shelf example are available at: https://github.com/inclusionAI/AReaL/blob/main/docs/algorithms/prox_approx.md",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06547v2",
    "published_date": "2025-12-06 19:37:39 UTC",
    "updated_date": "2026-01-09 23:46:31 UTC"
  },
  {
    "arxiv_id": "2512.06533v1",
    "title": "Beyond Token-level Supervision: Unlocking the Potential of Decoding-based Regression via Reinforcement Learning",
    "authors": [
      "Ming Chen",
      "Sheng Tang",
      "Rong-Xi Tan",
      "Ziniu Li",
      "Jiacheng Chen",
      "Ke Xue",
      "Chao Qian"
    ],
    "abstract": "Decoding-based regression, which reformulates regression as a sequence generation task, has emerged as a promising paradigm of applying large language models for numerical prediction. However, its progress is hindered by the misalignment between discrete token-level objectives (e.g., cross-entropy) and continuous numerical values. Existing approaches relying on token-level constraints often fail to capture the global magnitude of the target value, limiting their precision and generalization. In this paper, we propose to unlock the potential of decoding-based regression via Reinforcement Learning (RL). We formulate the generation process as a Markov Decision Process, utilizing sequence-level rewards to enforce global numerical coherence. Extensive experiments on tabular regression and code metric regression demonstrate that our method (specifically with ReMax and GRPO) consistently outperforms both state-of-the-art token-level baselines and traditional regression heads, showing the superiority of introducing sequence-level signals. Our analysis further reveals that RL significantly enhances sampling efficiency and predictive precision, establishing decoding-based regression as a robust and accurate paradigm for general-purpose numerical prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06533v1",
    "published_date": "2025-12-06 18:57:38 UTC",
    "updated_date": "2025-12-06 18:57:38 UTC"
  },
  {
    "arxiv_id": "2512.06531v1",
    "title": "Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images",
    "authors": [
      "Sayan Das",
      "Arghadip Biswas"
    ],
    "abstract": "Brain tumors pose a significant threat to human life, therefore it is very much necessary to detect them accurately in the early stages for better diagnosis and treatment. Brain tumors can be detected by the radiologist manually from the MRI scan images of the patients. However, the incidence of brain tumors has risen amongst children and adolescents in recent years, resulting in a substantial volume of data, as a result, it is time-consuming and difficult to detect manually. With the emergence of Artificial intelligence in the modern world and its vast application in the medical field, we can make an approach to the CAD (Computer Aided Diagnosis) system for the early detection of Brain tumors automatically. All the existing models for this task are not completely generalized and perform poorly on the validation data. So, we have proposed two novel Deep Learning Architectures - (a) SAETCN (Self-Attention Enhancement Tumor Classification Network) for the classification of different kinds of brain tumors. We have achieved an accuracy of 99.38% on the validation dataset making it one of the few Novel Deep learning-based architecture that is capable of detecting brain tumors accurately. We have trained the model on the dataset, which contains images of 3 types of tumors (glioma, meningioma, and pituitary tumors) and non-tumor cases. and (b) SAS-Net (Self-Attentive Segmentation Network) for the accurate segmentation of brain tumors. We have achieved an overall pixel accuracy of 99.23%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06531v1",
    "published_date": "2025-12-06 18:49:57 UTC",
    "updated_date": "2025-12-06 18:49:57 UTC"
  },
  {
    "arxiv_id": "2512.06521v1",
    "title": "ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images",
    "authors": [
      "Jens Dede",
      "Anna Förster"
    ],
    "abstract": "The continuous growth of the global human population is leading to the expansion of human habitats, resulting in decreasing wildlife spaces and increasing human-wildlife interactions. These interactions can range from minor disturbances, such as raccoons in urban waste bins, to more severe consequences, including species extinction. As a result, the monitoring of wildlife is gaining significance in various contexts. Artificial intelligence (AI) offers a solution by automating the recognition of animals in images and videos, thereby reducing the manual effort required for wildlife monitoring. Traditional AI training involves three main stages: image collection, labelling, and model training. However, the variability, for example, in the landscape (e.g., mountains, open fields, forests), weather (e.g., rain, fog, sunshine), lighting (e.g., day, night), and camera-animal distances presents significant challenges to model robustness and adaptability in real-world scenarios.\n  In this work, we propose a unified framework, called ShadowWolf, designed to address these challenges by integrating and optimizing the stages of AI model training and evaluation. The proposed framework enables dynamic model retraining to adjust to changes in environmental conditions and application requirements, thereby reducing labelling efforts and allowing for on-site model adaptation. This adaptive and unified approach enhances the accuracy and efficiency of wildlife monitoring systems, promoting more effective and scalable conservation efforts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "31 pages + appendix",
    "pdf_url": "https://arxiv.org/pdf/2512.06521v1",
    "published_date": "2025-12-06 18:17:53 UTC",
    "updated_date": "2025-12-06 18:17:53 UTC"
  },
  {
    "arxiv_id": "2512.20638v1",
    "title": "Uncovering Competency Gaps in Large Language Models and Their Benchmarks",
    "authors": [
      "Matyas Bohacek",
      "Nino Scherrer",
      "Nicholas Dufour",
      "Thomas Leung",
      "Christoph Bregler",
      "Stephanie C. Y. Chan"
    ],
    "abstract": "The evaluation of large language models (LLMs) relies heavily on standardized benchmarks. These benchmarks provide useful aggregated metrics for a given capability, but those aggregated metrics can obscure (i) particular sub-areas where the LLMs are weak (\"model gaps\") and (ii) imbalanced coverage in the benchmarks themselves (\"benchmark gaps\"). We propose a new method that uses sparse autoencoders (SAEs) to automatically uncover both types of gaps. By extracting SAE concept activations and computing saliency-weighted performance scores across benchmark data, the method grounds evaluation in the model's internal representations and enables comparison across benchmarks. As examples demonstrating our approach, we applied the method to two popular open-source models and ten benchmarks. We found that these models consistently underperformed on concepts that stand in contrast to sycophantic behaviors (e.g., politely refusing a request or asserting boundaries) and concepts connected to safety discussions. These model gaps align with observations previously surfaced in the literature; our automated, unsupervised method was able to recover them without manual supervision. We also observed benchmark gaps: many of the evaluated benchmarks over-represented concepts related to obedience, authority, or instruction-following, while missing core concepts that should fall within their intended scope. In sum, our method offers a representation-grounded approach to evaluation, enabling concept-level decomposition of benchmark scores. Rather than replacing conventional aggregated metrics, CG complements them by providing a concept-level decomposition that can reveal why a model scored as it did and how benchmarks could evolve to better reflect their intended scope. Code is available at https://competency-gaps.github.io.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.20638v1",
    "published_date": "2025-12-06 17:39:47 UTC",
    "updated_date": "2025-12-06 17:39:47 UTC"
  },
  {
    "arxiv_id": "2512.06506v1",
    "title": "AI as \"Co-founder\": GenAI for Entrepreneurship",
    "authors": [
      "Junhui Jeff Cai",
      "Xian Gu",
      "Liugang Sheng",
      "Mengjia Xia",
      "Linda Zhao",
      "Wu Zhu"
    ],
    "abstract": "This paper studies whether, how, and for whom generative artificial intelligence (GenAI) facilitates firm creation. Our identification strategy exploits the November 2022 release of ChatGPT as a global shock that lowered start-up costs and leverages variations across geo-coded grids with differential pre-existing AI-specific human capital. Using high-resolution and universal data on Chinese firm registrations by the end of 2024, we find that grids with stronger AI-specific human capital experienced a sharp surge in new firm formation$\\unicode{x2013}$driven entirely by small firms, contributing to 6.0% of overall national firm entry. Large-firm entry declines, consistent with a shift toward leaner ventures. New firms are smaller in capital, shareholder number, and founding team size, especially among small firms. The effects are strongest among firms with potential AI applications, weaker financing needs, and among first-time entrepreneurs. Overall, our results highlight that GenAI serves as a pro-competitive force by disproportionately boosting small-firm entry.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06506v1",
    "published_date": "2025-12-06 17:36:36 UTC",
    "updated_date": "2025-12-06 17:36:36 UTC"
  },
  {
    "arxiv_id": "2512.06504v1",
    "title": "Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion",
    "authors": [
      "Andrii Lysyi",
      "Anatoliy Sachenko",
      "Pavlo Radiuk",
      "Mykola Lysyi",
      "Oleksandr Melnychenko",
      "Diana Zahorodnia"
    ],
    "abstract": "The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06504v1",
    "published_date": "2025-12-06 17:28:22 UTC",
    "updated_date": "2025-12-06 17:28:22 UTC"
  },
  {
    "arxiv_id": "2512.06496v1",
    "title": "PRIMRose: Insights into the Per-Residue Energy Metrics of Proteins with Double InDel Mutations using Deep Learning",
    "authors": [
      "Stella Brown",
      "Nicolas Preisig",
      "Autumn Davis",
      "Brian Hutchinson",
      "Filip Jagodzinski"
    ],
    "abstract": "Understanding how protein mutations affect protein structure is essential for advancements in computational biology and bioinformatics. We introduce PRIMRose, a novel approach that predicts energy values for each residue given a mutated protein sequence. Unlike previous models that assess global energy shifts, our method analyzes the localized energetic impact of double amino acid insertions or deletions (InDels) at the individual residue level, enabling residue-specific insights into structural and functional disruption. We implement a Convolutional Neural Network architecture to predict the energy changes of each residue in a protein mutation. We train our model on datasets constructed from nine proteins, grouped into three categories: one set with exhaustive double InDel mutations, another with approximately 145k randomly sampled double InDel mutations, and a third with approximately 80k randomly sampled double InDel mutations. Our model achieves high predictive accuracy across a range of energy metrics as calculated by the Rosetta molecular modeling suite and reveals localized patterns that influence model performance, such as solvent accessibility and secondary structure context. This per-residue analysis offers new insights into the mutational tolerance of specific regions within proteins and provides higher interpretable and biologically meaningful predictions of InDels' effects.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "q-bio.QM"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Presented at Computational Structural Bioinformatics Workshop 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.06496v1",
    "published_date": "2025-12-06 16:57:56 UTC",
    "updated_date": "2025-12-06 16:57:56 UTC"
  },
  {
    "arxiv_id": "2512.06483v1",
    "title": "Classifying German Language Proficiency Levels Using Large Language Models",
    "authors": [
      "Elias-Leander Ahlers",
      "Witold Brunsmann",
      "Malte Schilling"
    ],
    "abstract": "Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach that utilizes the internal neural state of the LLM for classification. Our results show a consistent performance improvement over prior methods, highlighting the potential of LLMs for reliable and scalable CEFR classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 3rd International Conference on Foundation and Large Language Models (FLLM2025), Vienna (Austria)",
    "pdf_url": "https://arxiv.org/pdf/2512.06483v1",
    "published_date": "2025-12-06 16:15:45 UTC",
    "updated_date": "2025-12-06 16:15:45 UTC"
  },
  {
    "arxiv_id": "2512.06471v1",
    "title": "Why Goal-Conditioned Reinforcement Learning Works: Relation to Dual Control",
    "authors": [
      "Nathan P. Lawrence",
      "Ali Mesbah"
    ],
    "abstract": "Goal-conditioned reinforcement learning (RL) concerns the problem of training an agent to maximize the probability of reaching target goal states. This paper presents an analysis of the goal-conditioned setting based on optimal control. In particular, we derive an optimality gap between more classical, often quadratic, objectives and the goal-conditioned reward, elucidating the success of goal-conditioned RL and why classical ``dense'' rewards can falter. We then consider the partially observed Markov decision setting and connect state estimation to our probabilistic reward, further making the goal-conditioned reward well suited to dual control problems. The advantages of goal-conditioned policies are validated on nonlinear and uncertain environments using both RL and predictive control techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "IFAC preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.06471v1",
    "published_date": "2025-12-06 15:28:35 UTC",
    "updated_date": "2025-12-06 15:28:35 UTC"
  },
  {
    "arxiv_id": "2512.06458v1",
    "title": "Instance Dependent Testing of Samplers using Interval Conditioning",
    "authors": [
      "Rishiraj Bhattacharyya",
      "Sourav Chakraborty",
      "Yash Pote",
      "Uddalok Sarkar",
      "Sayantan Sen"
    ],
    "abstract": "Sampling algorithms play a pivotal role in probabilistic AI. However, verifying if a sampler program indeed samples from the claimed distribution is a notoriously hard problem. Provably correct testers like Barbarik, Teq, Flash, CubeProbe for testing of different kinds of samplers were proposed only in the last few years. All these testers focus on the worst-case efficiency, and do not support verification of samplers over infinite domains, a case occurring frequently in Astronomy, Finance, Network Security, etc.\n  In this work, we design the first tester of samplers with instance-dependent efficiency, allowing us to test samplers over natural numbers. Our tests are developed via a novel distance estimation algorithm between an unknown and a known probability distribution using an interval conditioning framework. The core technical contribution is a new connection with probability mass estimation of a continuous distribution. The practical gains are also substantial: our experiments establish up to 1000x speedup over state-of-the-art testers.",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06458v1",
    "published_date": "2025-12-06 14:45:56 UTC",
    "updated_date": "2025-12-06 14:45:56 UTC"
  },
  {
    "arxiv_id": "2512.06443v1",
    "title": "Vec-LUT: Vector Table Lookup for Parallel Ultra-Low-Bit LLM Inference on Edge Devices",
    "authors": [
      "Xiangyu Li",
      "Chengyu Yin",
      "Weijun Wang",
      "Jianyu Wei",
      "Ting Cao",
      "Yunxin Liu"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed on edge devices. To meet strict resource constraints, real-world deployment has pushed LLM quantization from 8-bit to 4-bit, 2-bit, and now 1.58-bit. Combined with lookup table (LUT)-based inference, CPUs run these ultra-low-bit LLMs even faster than NPUs, opening new opportunities for ubiquitous on-device intelligence.\n  However, this paper identifies that LUT-based inference underutilizes memory bandwidth during parallel inference, which is required for prefilling, test-time scaling, and other multi-token scenarios. The root cause is the scalar LUT paradigm, which performs repetitive and non-contiguous memory accesses for each token.\n  To solve the issue, we propose vector LUT, a new lookup paradigm that constructs a unified LUT across parallel tokens, and performs a single $1 \\rightarrow N$ lookup per index. To realize it efficiently, we further introduce (1) Vector LUT-Centric Tensor Layout, and (2) Cache-Aware Streamed Lookup techniques. Evaluations on 5 edge devices across 3 LLMs show that Vec-LUT outperforms state-of-the-art baselines by up to $4.2\\times$. Our implementation is integrated into llama.cpp. The code is available at https://github.com/Cipherxzc/vlut.cpp.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2512.06443v1",
    "published_date": "2025-12-06 14:14:01 UTC",
    "updated_date": "2025-12-06 14:14:01 UTC"
  },
  {
    "arxiv_id": "2512.06431v1",
    "title": "Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City",
    "authors": [
      "Mohamed Shamroukh",
      "Mohamed Alkhuzamy Aziz"
    ],
    "abstract": "National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06431v1",
    "published_date": "2025-12-06 13:36:57 UTC",
    "updated_date": "2025-12-06 13:36:57 UTC"
  },
  {
    "arxiv_id": "2512.06426v1",
    "title": "When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition",
    "authors": [
      "Nzakiese Mbongo",
      "Kailash A. Hambarde",
      "Hugo Proença"
    ],
    "abstract": "Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.06426v1",
    "published_date": "2025-12-06 13:12:07 UTC",
    "updated_date": "2025-12-06 13:12:07 UTC"
  },
  {
    "arxiv_id": "2512.08987v1",
    "title": "3DID: Direct 3D Inverse Design for Aerodynamics with Physics-Aware Optimization",
    "authors": [
      "Yuze Hao",
      "Linchao Zhu",
      "Yi Yang"
    ],
    "abstract": "Inverse design aims to design the input variables of a physical system to optimize a specified objective function, typically formulated as a search or optimization problem. However, in 3D domains, the design space grows exponentially, rendering exhaustive grid-based searches infeasible. Recent advances in deep learning have accelerated inverse design by providing powerful generative priors and differentiable surrogate models. Nevertheless, current methods tend to approximate the 3D design space using 2D projections or fine-tune existing 3D shapes. These approaches sacrifice volumetric detail and constrain design exploration, preventing true 3D design from scratch. In this paper, we propose a 3D Inverse Design (3DID) framework that directly navigates the 3D design space by coupling a continuous latent representation with a physics-aware optimization strategy. We first learn a unified physics-geometry embedding that compactly captures shape and physical field data in a continuous latent space. Then, we introduce a two-stage strategy to perform physics-aware optimization. In the first stage, a gradient-guided diffusion sampler explores the global latent manifold. In the second stage, an objective-driven, topology-preserving refinement further sculpts each candidate toward the target objective. This enables 3DID to generate high-fidelity 3D geometries, outperforming existing methods in both solution quality and design versatility.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at NeurIPS 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.08987v1",
    "published_date": "2025-12-06 13:09:03 UTC",
    "updated_date": "2025-12-06 13:09:03 UTC"
  },
  {
    "arxiv_id": "2512.06421v1",
    "title": "Rethinking Training Dynamics in Scale-wise Autoregressive Generation",
    "authors": [
      "Gengze Zhou",
      "Chongjian Ge",
      "Hao Tan",
      "Feng Liu",
      "Yicong Hong"
    ],
    "abstract": "Recent advances in autoregressive (AR) generative models have produced increasingly powerful systems for media synthesis. Among them, next-scale prediction has emerged as a popular paradigm, where models generate images in a coarse-to-fine manner. However, scale-wise AR models suffer from exposure bias, which undermines generation quality. We identify two primary causes of this issue: (1) train-test mismatch, where the model must rely on its own imperfect predictions during inference, and (2) imbalance in scale-wise learning difficulty, where certain scales exhibit disproportionately higher optimization complexity. Through a comprehensive analysis of training dynamics, we propose Self-Autoregressive Refinement (SAR) to address these limitations. SAR introduces a Stagger-Scale Rollout (SSR) mechanism that performs lightweight autoregressive rollouts to expose the model to its own intermediate predictions, thereby aligning train-test patterns, and a complementary Contrastive Student-Forcing Loss (CSFL) that provides adequate supervision for self-generated contexts to ensure stable training. Experimental results show that applying SAR to pretrained AR models consistently improves generation quality with minimal computational overhead. For instance, SAR yields a 5.2% FID reduction on FlexVAR-d16 trained on ImageNet 256 within 10 epochs (5 hours on 32xA100 GPUs). Given its efficiency, scalability, and effectiveness, we expect SAR to serve as a reliable post-training method for visual autoregressive generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06421v1",
    "published_date": "2025-12-06 12:41:42 UTC",
    "updated_date": "2025-12-06 12:41:42 UTC"
  },
  {
    "arxiv_id": "2512.10766v1",
    "title": "Metaphor-based Jailbreaking Attacks on Text-to-Image Models",
    "authors": [
      "Chenyu Zhang",
      "Yiwen Ma",
      "Lanjun Wang",
      "Wenhui Li",
      "Yi Tu",
      "An-An Liu"
    ],
    "abstract": "Text-to-image~(T2I) models commonly incorporate defense mechanisms to prevent the generation of sensitive images. Unfortunately, recent jailbreaking attacks have shown that adversarial prompts can effectively bypass these mechanisms and induce T2I models to produce sensitive content, revealing critical safety vulnerabilities. However, existing attack methods implicitly assume that the attacker knows the type of deployed defenses, which limits their effectiveness against unknown or diverse defense mechanisms. In this work, we introduce \\textbf{MJA}, a \\textbf{m}etaphor-based \\textbf{j}ailbreaking \\textbf{a}ttack method inspired by the Taboo game, aiming to effectively and efficiently attack diverse defense mechanisms without prior knowledge of their type by generating metaphor-based adversarial prompts. Specifically, MJA consists of two modules: an LLM-based multi-agent generation module~(MLAG) and an adversarial prompt optimization module~(APO). MLAG decomposes the generation of metaphor-based adversarial prompts into three subtasks: metaphor retrieval, context matching, and adversarial prompt generation. Subsequently, MLAG coordinates three LLM-based agents to generate diverse adversarial prompts by exploring various metaphors and contexts. To enhance attack efficiency, APO first trains a surrogate model to predict the attack results of adversarial prompts and then designs an acquisition strategy to adaptively identify optimal adversarial prompts. Extensive experiments on T2I models with various external and internal defense mechanisms demonstrate that MJA outperforms six baseline methods, achieving stronger attack performance while using fewer queries. Code is available in https://github.com/datar001/metaphor-based-jailbreaking-attack.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper includes model-generated content that may contain offensive or distressing material",
    "pdf_url": "https://arxiv.org/pdf/2512.10766v1",
    "published_date": "2025-12-06 12:38:00 UTC",
    "updated_date": "2025-12-06 12:38:00 UTC"
  },
  {
    "arxiv_id": "2512.06406v1",
    "title": "UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems",
    "authors": [
      "Xianzong Wu",
      "Xiaohong Li",
      "Lili Quan",
      "Qiang Hu"
    ],
    "abstract": "Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06406v1",
    "published_date": "2025-12-06 11:45:50 UTC",
    "updated_date": "2025-12-06 11:45:50 UTC"
  },
  {
    "arxiv_id": "2512.08986v1",
    "title": "Explainable Fundus Image Curation and Lesion Detection in Diabetic Retinopathy",
    "authors": [
      "Anca Mihai",
      "Adrian Groza"
    ],
    "abstract": "Diabetic Retinopathy (DR) affects individuals with long-term diabetes. Without early diagnosis, DR can lead to vision loss. Fundus photography captures the structure of the retina along with abnormalities indicative of the stage of the disease. Artificial Intelligence (AI) can support clinicians in identifying these lesions, reducing manual workload, but models require high-quality annotated datasets. Due to the complexity of retinal structures, errors in image acquisition and lesion interpretation of manual annotators can occur. We proposed a quality-control framework, ensuring only high-standard data is used for evaluation and AI training. First, an explainable feature-based classifier is used to filter inadequate images. The features are extracted both using image processing and contrastive learning. Then, the images are enhanced and put subject to annotation, using deep-learning-based assistance. Lastly, the agreement between annotators calculated using derived formulas determines the usability of the annotations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.08986v1",
    "published_date": "2025-12-06 11:36:00 UTC",
    "updated_date": "2025-12-06 11:36:00 UTC"
  },
  {
    "arxiv_id": "2512.06404v1",
    "title": "GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols",
    "authors": [
      "Mohammad Soleymanibrojeni",
      "Roland Aydin",
      "Diego Guedes-Sobrinho",
      "Alexandre C. Dias",
      "Maurício J. Piotrowski",
      "Wolfgang Wenzel",
      "Celso Ricardo Caldeira Rêgo"
    ],
    "abstract": "Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.",
    "categories": [
      "cs.AI",
      "cond-mat.mtrl-sci",
      "physics.chem-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06404v1",
    "published_date": "2025-12-06 11:28:35 UTC",
    "updated_date": "2025-12-06 11:28:35 UTC"
  },
  {
    "arxiv_id": "2512.06396v1",
    "title": "AgenticCyber: A GenAI-Powered Multi-Agent System for Multimodal Threat Detection and Adaptive Response in Cybersecurity",
    "authors": [
      "Shovan Roy"
    ],
    "abstract": "The increasing complexity of cyber threats in distributed environments demands advanced frameworks for real-time detection and response across multimodal data streams. This paper introduces AgenticCyber, a generative AI powered multi-agent system that orchestrates specialized agents to monitor cloud logs, surveillance videos, and environmental audio concurrently. The solution achieves 96.2% F1-score in threat detection, reduces response latency to 420 ms, and enables adaptive security posture management using multimodal language models like Google's Gemini coupled with LangChain for agent orchestration. Benchmark datasets, such as AWS CloudTrail logs, UCF-Crime video frames, and UrbanSound8K audio clips, show greater performance over standard intrusion detection systems, reducing mean time to respond (MTTR) by 65% and improving situational awareness. This work introduces a scalable, modular proactive cybersecurity architecture for enterprise networks and IoT ecosystems that overcomes siloed security technologies with cross-modal reasoning and automated remediation.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages for IEEE conference",
    "pdf_url": "https://arxiv.org/pdf/2512.06396v1",
    "published_date": "2025-12-06 10:59:21 UTC",
    "updated_date": "2025-12-06 10:59:21 UTC"
  },
  {
    "arxiv_id": "2512.11872v1",
    "title": "WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving",
    "authors": [
      "Mingwang Xu",
      "Jiahao Cui",
      "Feipeng Cai",
      "Hanlin Shang",
      "Zhihao Zhu",
      "Shan Luan",
      "Yifang Xu",
      "Neng Zhang",
      "Yaoyi Li",
      "Jia Cai",
      "Siyu Zhu"
    ],
    "abstract": "End-to-end autonomous driving systems based on vision-language-action (VLA) models integrate multimodal sensor inputs and language instructions to generate planning and control signals. While autoregressive large language models and continuous diffusion policies are prevalent, the potential of discrete masked diffusion for trajectory generation remains largely unexplored. This paper presents WAM-Diff, a VLA framework that employs masked diffusion to iteratively refine a discrete sequence representing future ego-trajectories. Our approach features three key innovations: a systematic adaptation of masked diffusion for autonomous driving that supports flexible, non-causal decoding orders; scalable model capacity via a sparse MoE architecture trained jointly on motion prediction and driving-oriented visual question answering (VQA); and online reinforcement learning using Group Sequence Policy Optimization (GSPO) to optimize sequence-level driving rewards. Remarkably, our model achieves 91.0 PDMS on NAVSIM-v1 and 89.7 EPDMS on NAVSIM-v2, demonstrating the effectiveness of masked diffusion for autonomous driving. The approach provides a promising alternative to autoregressive and diffusion-based policies, supporting scenario-aware decoding strategies for trajectory generation. The code for this paper will be released publicly at: https://github.com/fudan-generative-vision/WAM-Diff",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.11872v1",
    "published_date": "2025-12-06 10:51:53 UTC",
    "updated_date": "2025-12-06 10:51:53 UTC"
  },
  {
    "arxiv_id": "2512.06393v2",
    "title": "Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression",
    "authors": [
      "Qiming Bao",
      "Xiaoxuan Fu"
    ],
    "abstract": "Large language models (LLMs) achieve strong performance on many natural language tasks, yet their generalisation under structured perturbations of logical rule systems remains insufficiently characterised. We present a controlled evaluation framework that probes reasoning reliability through four stress tests: (1) rule deletion, removing redundant versus essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites based on equivalence laws (contraposition, double negation, implication-to-disjunction, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that composes 2--5 transformations. Across three representative model families -- BERT, Qwen2, and LLaMA-like models -- all models attain Acc$=1.0000$ on the base split and show no degradation under redundant rule deletion. In contrast, essential rule deletion yields a pronounced decrease to near-chance performance, and injecting explicit contradictions reduces accuracy to 0.0000. Under logic-preserving rewrites, accuracy is largely preserved for single-law transformations with only small degradations in a few cases, whereas multi-law stacking exposes model-dependent sensitivity: BERT matches the base condition, TinyLlama shows only marginal degradation, and Qwen2 exhibits a substantial drop.\n  Overall, the results indicate that contemporary LLMs are generally stable under semantic-preserving reformulations, yet remain brittle to missing or inconsistent evidence and may degrade under composed logical transformations depending on the model family. The proposed framework provides a concise diagnostic tool for isolating these failure modes and for evaluating logical generalisation beyond surface-form variation.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06393v2",
    "published_date": "2025-12-06 10:49:50 UTC",
    "updated_date": "2025-12-12 09:31:52 UTC"
  },
  {
    "arxiv_id": "2512.06392v2",
    "title": "RLAX: Large-Scale, Distributed Reinforcement Learning for Large Language Models on TPUs",
    "authors": [
      "Runlong Zhou",
      "Lefan Zhang",
      "Shang-Chen Wu",
      "Kelvin Zou",
      "Hanzhi Zhou",
      "Ke Ye",
      "Yihao Feng",
      "Dong Yin",
      "Alex Guillen Garcia",
      "Dmytro Babych",
      "Rohit Chatterjee",
      "Matthew Hopkins",
      "Xiang Kong",
      "Chang Lan",
      "Lezhi Li",
      "Yiping Ma",
      "Daniele Molinari",
      "Senyu Tong",
      "Yanchao Sun",
      "Thomas Voice",
      "Jianyu Wang",
      "Chong Wang",
      "Simon Wang",
      "Floris Weers",
      "Yechen Xu",
      "Guolin Yin",
      "Muyang Yu",
      "Yi Zhang",
      "Zheng Zhou",
      "Danyang Zhuo",
      "Ruoming Pang",
      "Cheng Leong"
    ],
    "abstract": "Reinforcement learning (RL) has emerged as the de-facto paradigm for improving the reasoning capabilities of large language models (LLMs). We have developed RLAX, a scalable RL framework on TPUs. RLAX employs a parameter-server architecture. A master trainer periodically pushes updated model weights to the parameter server while a fleet of inference workers pull the latest weights and generates new rollouts. We introduce a suite of system techniques to enable scalable and preemptible RL for a diverse set of state-of-art RL algorithms. To accelerate convergence and improve model quality, we have devised new dataset curation and alignment techniques. Large-scale evaluations show that RLAX improves QwQ-32B's pass@8 accuracy by 12.8% in just 12 hours 48 minutes on 1024 v5p TPUs, while remaining robust to preemptions during training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The submission is being withdrawn because internal stakeholders determined that it is not appropriate to publish work on this topic at this time",
    "pdf_url": "https://arxiv.org/pdf/2512.06392v2",
    "published_date": "2025-12-06 10:48:51 UTC",
    "updated_date": "2025-12-11 02:38:26 UTC"
  },
  {
    "arxiv_id": "2512.06390v1",
    "title": "Web Technologies Security in the AI Era: A Survey of CDN-Enhanced Defenses",
    "authors": [
      "Mehrab Hosain",
      "Sabbir Alom Shuvo",
      "Matthew Ogbe",
      "Md Shah Jalal Mazumder",
      "Yead Rahman",
      "Md Azizul Hakim",
      "Anukul Pandey"
    ],
    "abstract": "The modern web stack, which is dominated by browser-based applications and API-first backends, now operates under an adversarial equilibrium where automated, AI-assisted attacks evolve continuously. Content Delivery Networks (CDNs) and edge computing place programmable defenses closest to users and bots, making them natural enforcement points for machine-learning (ML) driven inspection, throttling, and isolation. This survey synthesizes the landscape of AI-enhanced defenses deployed at the edge: (i) anomaly- and behavior-based Web Application Firewalls (WAFs) within broader Web Application and API Protection (WAAP), (ii) adaptive DDoS detection and mitigation, (iii) bot management that resists human-mimicry, and (iv) API discovery, positive security modeling, and encrypted-traffic anomaly analysis. We add a systematic survey method, a threat taxonomy mapped to edge-observable signals, evaluation metrics, deployment playbooks, and governance guidance. We conclude with a research agenda spanning XAI, adversarial robustness, and autonomous multi-agent defense. Our findings indicate that edge-centric AI measurably improves time-to-detect and time-to-mitigate while reducing data movement and enhancing compliance, yet introduces new risks around model abuse, poisoning, and governance.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.PF"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted at 2025 IEEE Asia Pacific Conference on Wireless and Mobile (APWiMob). 7 pages, 5 figures",
    "pdf_url": "https://arxiv.org/pdf/2512.06390v1",
    "published_date": "2025-12-06 10:42:14 UTC",
    "updated_date": "2025-12-06 10:42:14 UTC"
  },
  {
    "arxiv_id": "2512.06380v2",
    "title": "Protecting Bystander Privacy via Selective Hearing in Audio LLMs",
    "authors": [
      "Xiao Zhan",
      "Guangzhi Sun",
      "Jose Such",
      "Phil Woodland"
    ],
    "abstract": "Audio Large language models (LLMs) are increasingly deployed in the real world, where they inevitably capture speech from unintended nearby bystanders, raising privacy risks that existing benchmarks and defences did not consider. We introduce SH-Bench, the first benchmark designed to evaluate selective hearing: a model's ability to attend to an intended main speaker while refusing to process or reveal information about incidental bystander speech. SH-Bench contains 3,968 multi-speaker audio mixtures, including both real-world and synthetic scenarios, paired with 77k multiple-choice questions that probe models under general and selective operating modes. In addition, we propose Selective Efficacy (SE), a novel metric capturing both multi-speaker comprehension and bystander-privacy protection. Our evaluation of state-of-the-art open-source and proprietary LLMs reveals substantial bystander privacy leakage, with strong audio understanding failing to translate into selective protection of bystander privacy. To mitigate this gap, we also present Bystander Privacy Fine-Tuning (BPFT), a novel training pipeline that teaches models to refuse bystander-related queries without degrading main-speaker comprehension. We show that BPFT yields substantial gains, achieving an absolute 47% higher bystander accuracy under selective mode and an absolute 16% higher SE compared to Gemini 2.5 Pro, which is the best audio LLM without BPFT. Together, SH-Bench and BPFT provide the first systematic framework for measuring and improving bystander privacy in audio LLMs.",
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "primary_category": "cs.SD",
    "comment": "Dataset: https://huggingface.co/datasets/BrianatCambridge/SelectiveHearingBench",
    "pdf_url": "https://arxiv.org/pdf/2512.06380v2",
    "published_date": "2025-12-06 10:24:04 UTC",
    "updated_date": "2025-12-13 14:48:07 UTC"
  },
  {
    "arxiv_id": "2512.06357v2",
    "title": "Proportional integral derivative booster for neural networks-based time-series prediction: Case of water demand prediction",
    "authors": [
      "Tony Salloom",
      "Okyay Kaynak",
      "Xinbo Yub",
      "Wei He"
    ],
    "abstract": "Multi-step time-series prediction is an essential supportive step for decision-makers in several industrial areas. Artificial intelligence techniques, which use a neural network component in various forms, have recently frequently been used to accomplish this step. However, the complexity of the neural network structure still stands up as a critical problem against prediction accuracy. In this paper, a method inspired by the proportional-integral-derivative (PID) control approach is investigated to enhance the performance of neural network models used for multi-step ahead prediction of periodic time-series information while maintaining a negligible impact on the complexity of the system. The PID-based method is applied to the predicted value at each time step to bring that value closer to the real value. The water demand forecasting problem is considered as a case study, where two deep neural network models from the literature are used to prove the effectiveness of the proposed boosting method. Furthermore, to prove the applicability of this PID-based booster to other types of periodic time-series prediction problems, it is applied to enhance the accuracy of a neural network model used for multi-step forecasting of hourly energy consumption. The comparison between the results of the original prediction models and the results after using the proposed technique demonstrates the superiority of the proposed method in terms of prediction accuracy and system complexity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Engineering Applications of Artificial Intelligence 2022",
    "pdf_url": "https://arxiv.org/pdf/2512.06357v2",
    "published_date": "2025-12-06 09:08:05 UTC",
    "updated_date": "2025-12-10 07:03:50 UTC"
  },
  {
    "arxiv_id": "2512.06350v1",
    "title": "Why They Disagree: Decoding Differences in Opinions about AI Risk on the Lex Fridman Podcast",
    "authors": [
      "Nghi Truong",
      "Phanish Puranam",
      "Özgecan Koçak"
    ],
    "abstract": "The emergence of transformative technologies often surfaces deep societal divisions, nowhere more evident than in contemporary debates about artificial intelligence (AI). A striking feature of these divisions is that they persist despite shared interests in ensuring that AI benefits humanity and avoiding catastrophic outcomes. This paper analyzes contemporary debates about AI risk, parsing the differences between the \"doomer\" and \"boomer\" perspectives into definitional, factual, causal, and moral premises to identify key points of contention. We find that differences in perspectives about existential risk (\"X-risk\") arise fundamentally from differences in causal premises about design vs. emergence in complex systems, while differences in perspectives about employment risks (\"E-risks\") pertain to different causal premises about the applicability of past theories (evolution) vs their inapplicability (revolution). Disagreements about these two forms of AI risk appear to share two properties: neither involves significant disagreements on moral values and both can be described in terms of differing views on the extent of boundedness of human rationality. Our approach to analyzing reasoning chains at scale, using an ensemble of LLMs to parse textual data, can be applied to identify key points of contention in debates about risk to the public in any arena.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06350v1",
    "published_date": "2025-12-06 08:48:30 UTC",
    "updated_date": "2025-12-06 08:48:30 UTC"
  },
  {
    "arxiv_id": "2512.06343v1",
    "title": "When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models",
    "authors": [
      "Tong Xie",
      "Andrew Bai",
      "Yuanhao Ban",
      "Yunqi Hong",
      "Haoyu Li",
      "Cho-jui Hsieh"
    ],
    "abstract": "Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06343v1",
    "published_date": "2025-12-06 08:15:37 UTC",
    "updated_date": "2025-12-06 08:15:37 UTC"
  },
  {
    "arxiv_id": "2512.06337v2",
    "title": "DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization",
    "authors": [
      "Xuan Xie",
      "Xuan Wang",
      "Wenjie Wang",
      "Shuai Chen",
      "Wei Lin"
    ],
    "abstract": "The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06337v2",
    "published_date": "2025-12-06 07:51:36 UTC",
    "updated_date": "2025-12-31 10:30:42 UTC"
  },
  {
    "arxiv_id": "2512.15736v1",
    "title": "Anubuddhi: A Multi-Agent AI System for Designing and Simulating Quantum Optics Experiments",
    "authors": [
      "S. K. Rithvik"
    ],
    "abstract": "We present Anubuddhi, a multi-agent AI system that designs and simulates quantum optics experiments from natural language prompts without requiring specialized programming knowledge. The system composes optical layouts by arranging components from a three-tier toolbox via semantic retrieval, then validates designs through physics simulation with convergent refinement. The architecture combines intent routing, knowledge-augmented generation, and dual-mode validation (QuTiP and FreeSim). We evaluated 13 experiments spanning fundamental optics (Hong-Ou-Mandel interference, Michelson/Mach-Zehnder interferometry, Bell states, delayed-choice quantum eraser), quantum information protocols (BB84 QKD, Franson interferometry, GHZ states, quantum teleportation, hyperentanglement), and advanced technologies (boson sampling, electromagnetically induced transparency, frequency conversion). The system achieves design-simulation alignment scores of 8--9/10, with simulations faithfully modeling intended physics. A critical finding distinguishes structural correctness from quantitative accuracy: high alignment confirms correct physics architecture, while numerical predictions require expert review. Free-form simulation outperformed constrained frameworks for 11/13 experiments, revealing that quantum optics diversity demands flexible mathematical representations. The system democratizes computational experiment design for research and pedagogy, producing strong initial designs users can iteratively refine through conversation.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15736v1",
    "published_date": "2025-12-06 06:59:56 UTC",
    "updated_date": "2025-12-06 06:59:56 UTC"
  },
  {
    "arxiv_id": "2512.11871v1",
    "title": "Automated Plant Disease and Pest Detection System Using Hybrid Lightweight CNN-MobileViT Models for Diagnosis of Indigenous Crops",
    "authors": [
      "Tekleab G. Gebremedhin",
      "Hailom S. Asegede",
      "Bruh W. Tesheme",
      "Tadesse B. Gebremichael",
      "Kalayu G. Redae"
    ],
    "abstract": "Agriculture supports over 80% of the population in the Tigray region of Ethiopia, where infrastructural disruptions limit access to expert crop disease diagnosis. We present an offline-first detection system centered on a newly curated indigenous cactus-fig (Opuntia ficus-indica) dataset consisting of 3,587 field images across three core symptom classes. Given deployment constraints in post-conflict edge environments, we benchmark three mobile-efficient architectures: a custom lightweight CNN, EfficientNet-Lite1, and the CNN-Transformer hybrid MobileViT-XS. While the broader system contains independent modules for potato, apple, and corn, this study isolates cactus-fig model performance to evaluate attention sensitivity and inductive bias transfer on indigenous morphology alone. Results establish a clear Pareto trade-off: EfficientNet-Lite1 achieves 90.7% test accuracy, the lightweight CNN reaches 89.5% with the most favorable deployment profile (42 ms inference latency, 4.8 MB model size), and MobileViT-XS delivers 97.3% mean cross-validation accuracy, demonstrating that MHSA-based global reasoning disambiguates pest clusters from two dimensional fungal lesions more reliably than local texture CNN kernels. The ARM compatible models are deployed in a Tigrigna and Amharic localized Flutter application supporting fully offline inference on Cortex-A53 class devices, strengthening inclusivity for food security critical diagnostics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "A preliminary version of this work was presented at the International Conference on Postwar Technology for Recovery and Sustainable Development (Feb. 2025). This manuscript substantially extends that work with expanded experiments and on-device deployment analysis. Code and dataset are publicly available at: https://github.com/Tekleab15/Automated_plant_disease_and_pest_detection_system",
    "pdf_url": "https://arxiv.org/pdf/2512.11871v1",
    "published_date": "2025-12-06 06:24:46 UTC",
    "updated_date": "2025-12-06 06:24:46 UTC"
  },
  {
    "arxiv_id": "2512.06306v1",
    "title": "Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation",
    "authors": [
      "Haoxian Zhou",
      "Chuanzhi Xu",
      "Langyi Chen",
      "Haodong Chen",
      "Yuk Ying Chung",
      "Qiang Qu",
      "Xaoming Chen",
      "Weidong Cai"
    ],
    "abstract": "Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06306v1",
    "published_date": "2025-12-06 05:32:13 UTC",
    "updated_date": "2025-12-06 05:32:13 UTC"
  },
  {
    "arxiv_id": "2512.06304v1",
    "title": "Degrading Voice: A Comprehensive Overview of Robust Voice Conversion Through Input Manipulation",
    "authors": [
      "Xining Song",
      "Zhihua Wei",
      "Rui Wang",
      "Haixiao Hu",
      "Yanxiang Chen",
      "Meng Han"
    ],
    "abstract": "Identity, accent, style, and emotions are essential components of human speech. Voice conversion (VC) techniques process the speech signals of two input speakers and other modalities of auxiliary information such as prompts and emotion tags. It changes para-linguistic features from one to another, while maintaining linguistic contents. Recently, VC models have made rapid advancements in both generation quality and personalization capabilities. These developments have attracted considerable attention for diverse applications, including privacy preservation, voice-print reproduction for the deceased, and dysarthric speech recovery. However, these models only learn non-robust features due to the clean training data. Subsequently, it results in unsatisfactory performances when dealing with degraded input speech in real-world scenarios, including additional noise, reverberation, adversarial attacks, or even minor perturbation. Hence, it demands robust deployments, especially in real-world settings. Although latest researches attempt to find potential attacks and countermeasures for VC systems, there remains a significant gap in the comprehensive understanding of how robust the VC model is under input manipulation. here also raises many questions: For instance, to what extent do different forms of input degradation attacks alter the expected output of VC models? Is there potential for optimizing these attack and defense strategies? To answer these questions, we classify existing attack and defense methods from the perspective of input manipulation and evaluate the impact of degraded input speech across four dimensions, including intelligibility, naturalness, timbre similarity, and subjective perception. Finally, we outline open issues and future directions.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CR",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06304v1",
    "published_date": "2025-12-06 05:17:07 UTC",
    "updated_date": "2025-12-06 05:17:07 UTC"
  },
  {
    "arxiv_id": "2512.06301v1",
    "title": "Chemistry Integrated Language Model using Hierarchical Molecular Representation for Polymer Informatics",
    "authors": [
      "Jihun Ahn",
      "Gabriella Pasya Irianti",
      "Vikram Thapar",
      "Su-Mi Hur"
    ],
    "abstract": "Machine learning has transformed material discovery for inorganic compounds and small molecules, yet polymers remain largely inaccessible to these methods. While data scarcity is often cited as the primary bottleneck, we demonstrate that strategic molecular representations can overcome this limitation. We introduce CI-LLM (Chemically Informed Language Model), a framework combining HAPPY (Hierarchically Abstracted rePeat unit of PolYmer), which encodes chemical substructures as tokens, with numerical descriptors within transformer architectures. For property prediction, De$^3$BERTa, our descriptor-enriched encoder, achieves 3.5x faster inference than SMILES-based models with improved accuracy ($R^2$ score gains of 0.9-4.1 percent across four properties), while providing interpretable structure-property insights at the subgroup level. For inverse design, our GPT-based generator produces polymers with targeted properties, achieving 100 percent scaffold retention and successful multi-property optimization for negatively correlated objectives. This comprehensive framework demonstrates both forward prediction and inverse design capabilities, showcasing how strategic molecular representation advances machine learning applications in polymer science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06301v1",
    "published_date": "2025-12-06 05:07:11 UTC",
    "updated_date": "2025-12-06 05:07:11 UTC"
  },
  {
    "arxiv_id": "2512.06297v1",
    "title": "Entropic Confinement and Mode Connectivity in Overparameterized Neural Networks",
    "authors": [
      "Luca Di Carlo",
      "Chase Goddard",
      "David J. Schwab"
    ],
    "abstract": "Modern neural networks exhibit a striking property: basins of attraction in the loss landscape are often connected by low-loss paths, yet optimization dynamics generally remain confined to a single convex basin and rarely explore intermediate points. We resolve this paradox by identifying entropic barriers arising from the interplay between curvature variations along these paths and noise in optimization dynamics. Empirically, we find that curvature systematically rises away from minima, producing effective forces that bias noisy dynamics back toward the endpoints - even when the loss remains nearly flat. These barriers persist longer than energetic barriers, shaping the late-time localization of solutions in parameter space. Our results highlight the role of curvature-induced entropic forces in governing both connectivity and confinement in deep learning landscapes.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2512.06297v1",
    "published_date": "2025-12-06 04:50:32 UTC",
    "updated_date": "2025-12-06 04:50:32 UTC"
  },
  {
    "arxiv_id": "2512.06296v1",
    "title": "How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion",
    "authors": [
      "Sooho Moon",
      "Yunyong Ko"
    ],
    "abstract": "Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 4 figures, 2 tables, ACM WSDM 2026",
    "pdf_url": "https://arxiv.org/pdf/2512.06296v1",
    "published_date": "2025-12-06 04:49:29 UTC",
    "updated_date": "2025-12-06 04:49:29 UTC"
  },
  {
    "arxiv_id": "2512.06281v1",
    "title": "Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models",
    "authors": [
      "Hengzhuang Li",
      "Xinsong Zhang",
      "Qiming Peng",
      "Bin Luo",
      "Han Hu",
      "Dengyang Jiang",
      "Han-Jia Ye",
      "Teng Zhang",
      "Hai Jin"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in multimodal tasks. Despite their impressive performance, MLLMs suffer from the modality imbalance issue, where visual information is often underutilized compared to textual representations in deeper layers, leading to degraded visual performance or hallucinations. This issue stems from the predominant reliance on next-text-token-prediction during training, which fails to provide direct visual supervisory signals, resulting in progressive homogenization of visual representations throughout the layers. To this end, we propose Latent Visual Reconstruction (LaVer), a novel training framework that facilitates MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM. Our method offers direct visual activation to MLLMs, which exhibit increased visual attention allocation, indicating enhanced utilization of visual information. Extensive experiments across diverse benchmarks prove the superiority of our approach in various scenarios, especially those requiring dense visual capabilities. Code of LaVer is available at https://github.com/Fir-lat/LaVer.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06281v1",
    "published_date": "2025-12-06 04:20:13 UTC",
    "updated_date": "2025-12-06 04:20:13 UTC"
  },
  {
    "arxiv_id": "2512.06276v2",
    "title": "RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension",
    "authors": [
      "Tianyi Gao",
      "Hao Li",
      "Han Fang",
      "Xin Wei",
      "Xiaodong Dong",
      "Hongbo Sun",
      "Ye Yuan",
      "Zhongjiang He",
      "Jinglin Xu",
      "Jingmin Xin",
      "Hao Sun"
    ],
    "abstract": "Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06276v2",
    "published_date": "2025-12-06 03:59:21 UTC",
    "updated_date": "2025-12-13 10:53:19 UTC"
  },
  {
    "arxiv_id": "2512.06274v1",
    "title": "Networked Restless Multi-Arm Bandits with Reinforcement Learning",
    "authors": [
      "Hanmo Zhang",
      "Zenghui Sun",
      "Kai Wang"
    ],
    "abstract": "Restless Multi-Armed Bandits (RMABs) are a powerful framework for sequential decision-making, widely applied in resource allocation and intervention optimization challenges in public health. However, traditional RMABs assume independence among arms, limiting their ability to account for interactions between individuals that can be common and significant in a real-world environment. This paper introduces Networked RMAB, a novel framework that integrates the RMAB model with the independent cascade model to capture interactions between arms in networked environments. We define the Bellman equation for networked RMAB and present its computational challenge due to exponentially large action and state spaces. To resolve the computational challenge, we establish the submodularity of Bellman equation and apply the hill-climbing algorithm to achieve a $1-\\frac{1}{e}$ approximation guarantee in Bellman updates. Lastly, we prove that the approximate Bellman updates are guaranteed to converge by a modified contraction analysis. We experimentally verify these results by developing an efficient Q-learning algorithm tailored to the networked setting. Experimental results on real-world graph data demonstrate that our Q-learning approach outperforms both $k$-step look-ahead and network-blind approaches, highlighting the importance of capturing and leveraging network effects where they exist.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06274v1",
    "published_date": "2025-12-06 03:53:25 UTC",
    "updated_date": "2025-12-06 03:53:25 UTC"
  },
  {
    "arxiv_id": "2512.06259v1",
    "title": "Who Will Top the Charts? Multimodal Music Popularity Prediction via Adaptive Fusion of Modality Experts and Temporal Engagement Modeling",
    "authors": [
      "Yash Choudhary",
      "Preeti Rao",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Predicting a song's commercial success prior to its release remains an open and critical research challenge for the music industry. Early prediction of music popularity informs strategic decisions, creative planning, and marketing. Existing methods suffer from four limitations:(i) temporal dynamics in audio and lyrics are averaged away; (ii) lyrics are represented as a bag of words, disregarding compositional structure and affective semantics; (iii) artist- and song-level historical performance is ignored; and (iv) multimodal fusion approaches rely on simple feature concatenation, resulting in poorly aligned shared representations. To address these limitations, we introduce GAMENet, an end-to-end multimodal deep learning architecture for music popularity prediction. GAMENet integrates modality-specific experts for audio, lyrics, and social metadata through an adaptive gating mechanism. We use audio features from Music4AllOnion processed via OnionEnsembleAENet, a network of autoencoders designed for robust feature extraction; lyric embeddings derived through a large language model pipeline; and newly introduced Career Trajectory Dynamics (CTD) features that capture multi-year artist career momentum and song-level trajectory statistics. Using the Music4All dataset (113k tracks), previously explored in MIR tasks but not popularity prediction, GAMENet achieves a 12% improvement in R^2 over direct multimodal feature concatenation. Spotify audio descriptors alone yield an R^2 of 0.13. Integrating aggregate CTD features increases this to 0.69, with an additional 7% gain from temporal CTD features. We further validate robustness using the SpotGenTrack Popularity Dataset (100k tracks), achieving a 16% improvement over the previous baseline. Extensive ablations confirm the model's effectiveness and the distinct contribution of each modality.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SD",
    "comment": "8 pages",
    "pdf_url": "https://arxiv.org/pdf/2512.06259v1",
    "published_date": "2025-12-06 03:07:43 UTC",
    "updated_date": "2025-12-06 03:07:43 UTC"
  },
  {
    "arxiv_id": "2512.06256v1",
    "title": "Convergence of Outputs When Two Large Language Models Interact in a Multi-Agentic Setup",
    "authors": [
      "Aniruddha Maiti",
      "Satya Nimmagadda",
      "Kartha Veerya Jammuladinne",
      "Niladri Sengupta",
      "Ananya Jana"
    ],
    "abstract": "In this work, we report what happens when two large language models respond to each other for many turns without any outside input in a multi-agent setup. The setup begins with a short seed sentence. After that, each model reads the other's output and generates a response. This continues for a fixed number of steps. We used Mistral Nemo Base 2407 and Llama 2 13B hf. We observed that most conversations start coherently but later fall into repetition. In many runs, a short phrase appears and repeats across turns. Once repetition begins, both models tend to produce similar output rather than introducing a new direction in the conversation. This leads to a loop where the same or similar text is produced repeatedly. We describe this behavior as a form of convergence. It occurs even though the models are large, trained separately, and not given any prompt instructions. To study this behavior, we apply lexical and embedding-based metrics to measure how far the conversation drifts from the initial seed and how similar the outputs of the two models becomes as the conversation progresses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted to LLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2512.06256v1",
    "published_date": "2025-12-06 03:00:24 UTC",
    "updated_date": "2025-12-06 03:00:24 UTC"
  },
  {
    "arxiv_id": "2512.06247v2",
    "title": "DUET: Agentic Design Understanding via Experimentation and Testing",
    "authors": [
      "Gus Henry Smith",
      "Sandesh Adhikary",
      "Vineet Thumuluri",
      "Karthik Suresh",
      "Vivek Pandit",
      "Kartik Hegde",
      "Hamid Shojaei",
      "Chandra Bhagavatula"
    ],
    "abstract": "AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06247v2",
    "published_date": "2025-12-06 02:16:28 UTC",
    "updated_date": "2026-01-22 02:05:23 UTC"
  },
  {
    "arxiv_id": "2512.06244v1",
    "title": "Auto-exploration for online reinforcement learning",
    "authors": [
      "Caleb Ju",
      "Guanghui Lan"
    ],
    "abstract": "The exploration-exploitation dilemma in reinforcement learning (RL) is a fundamental challenge to efficient RL algorithms. Existing algorithms for finite state and action discounted RL problems address this by assuming sufficient exploration over both state and action spaces. However, this yields non-implementable algorithms and sub-optimal performance. To resolve these limitations, we introduce a new class of methods with auto-exploration, or methods that automatically explore both state and action spaces in a parameter-free way, i.e.,~without a priori knowledge of problem-dependent parameters. We present two variants: one for the tabular setting and one for linear function approximation. Under algorithm-independent assumptions on the existence of an exploring optimal policy, both methods attain $O(ε^{-2})$ sample complexity to solve to $ε$ error. Crucially, these complexities are novel since they are void of algorithm-dependent parameters seen in prior works, which may be arbitrarily large. The methods are also simple to implement because they are parameter-free and do not directly estimate the unknown parameters. These feats are achieved by new algorithmic innovations for RL, including a dynamic mixing time, a discounted state distribution for sampling, a simple robust gradient estimator, and a recent advantage gap function to certify convergence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages (9 appendix), 1 figure. Comments are welcome",
    "pdf_url": "https://arxiv.org/pdf/2512.06244v1",
    "published_date": "2025-12-06 02:04:50 UTC",
    "updated_date": "2025-12-06 02:04:50 UTC"
  },
  {
    "arxiv_id": "2512.08984v1",
    "title": "RAG-HAR: Retrieval Augmented Generation-based Human Activity Recognition",
    "authors": [
      "Nirhoshan Sivaroopan",
      "Hansi Karunarathna",
      "Chamara Madarasingha",
      "Anura Jayasumana",
      "Kanchana Thilakarathna"
    ],
    "abstract": "Human Activity Recognition (HAR) underpins applications in healthcare, rehabilitation, fitness tracking, and smart environments, yet existing deep learning approaches demand dataset-specific training, large labeled corpora, and significant computational resources.We introduce RAG-HAR, a training-free retrieval-augmented framework that leverages large language models (LLMs) for HAR. RAG-HAR computes lightweight statistical descriptors, retrieves semantically similar samples from a vector database, and uses this contextual evidence to make LLM-based activity identification. We further enhance RAG-HAR by first applying prompt optimization and introducing an LLM-based activity descriptor that generates context-enriched vector databases for delivering accurate and highly relevant contextual information. Along with these mechanisms, RAG-HAR achieves state-of-the-art performance across six diverse HAR benchmarks. Most importantly, RAG-HAR attains these improvements without requiring model training or fine-tuning, emphasizing its robustness and practical applicability. RAG-HAR moves beyond known behaviors, enabling the recognition and meaningful labelling of multiple unseen human activities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.08984v1",
    "published_date": "2025-12-06 01:53:02 UTC",
    "updated_date": "2025-12-06 01:53:02 UTC"
  },
  {
    "arxiv_id": "2512.06240v1",
    "title": "AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems",
    "authors": [
      "Chuanhao Nie",
      "Yunbo Liu",
      "Chao Wang"
    ],
    "abstract": "Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06240v1",
    "published_date": "2025-12-06 01:37:24 UTC",
    "updated_date": "2025-12-06 01:37:24 UTC"
  }
]