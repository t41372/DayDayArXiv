[
  {
    "arxiv_id": "2410.21280v1",
    "title": "TraderTalk: An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions",
    "authors": [
      "Alicia Vidler",
      "Toby Walsh"
    ],
    "abstract": "We introduce a novel hybrid approach that augments Agent-Based Models (ABMs)\nwith behaviors generated by Large Language Models (LLMs) to simulate human\ntrading interactions. We call our model TraderTalk. Leveraging LLMs trained on\nextensive human-authored text, we capture detailed and nuanced representations\nof bilateral conversations in financial trading. Applying this Generative\nAgent-Based Model (GABM) to government bond markets, we replicate trading\ndecisions between two stylised virtual humans. Our method addresses both\nstructural challenges, such as coordinating turn-taking between realistic\nLLM-based agents, and design challenges, including the interpretation of LLM\noutputs by the agent model. By exploring prompt design opportunistically rather\nthan systematically, we enhance the realism of agent interactions without\nexhaustive overfitting or model reliance. Our approach successfully replicates\ntrade-to-order volume ratios observed in related asset markets, demonstrating\nthe potential of LLM-augmented ABMs in financial simulations",
    "categories": [
      "q-fin.TR",
      "cs.AI"
    ],
    "primary_category": "q-fin.TR",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.21280v1",
    "published_date": "2024-10-10 23:58:07 UTC",
    "updated_date": "2024-10-10 23:58:07 UTC"
  },
  {
    "arxiv_id": "2410.08406v1",
    "title": "Promptly Yours? A Human Subject Study on Prompt Inference in AI-Generated Art",
    "authors": [
      "Khoi Trinh",
      "Joseph Spracklen",
      "Raveen Wijewickrama",
      "Bimal Viswanath",
      "Murtuza Jadliwala",
      "Anindya Maiti"
    ],
    "abstract": "The emerging field of AI-generated art has witnessed the rise of prompt\nmarketplaces, where creators can purchase, sell, or share prompts for\ngenerating unique artworks. These marketplaces often assert ownership over\nprompts, claiming them as intellectual property. This paper investigates\nwhether concealed prompts sold on prompt marketplaces can be considered as\nsecure intellectual property, given that humans and AI tools may be able to\napproximately infer the prompts based on publicly advertised sample images\naccompanying each prompt on sale. Specifically, our survey aims to assess (i)\nhow accurately can humans infer the original prompt solely by examining an\nAI-generated image, with the goal of generating images similar to the original\nimage, and (ii) the possibility of improving upon individual human and AI\nprompt inferences by crafting human-AI combined prompts with the help of a\nlarge language model. Although previous research has explored the use of AI and\nmachine learning to infer (and also protect against) prompt inference, we are\nthe first to include humans in the loop. Our findings indicate that while\nhumans and human-AI collaborations can infer prompts and generate similar\nimages with high accuracy, they are not as successful as using the original\nprompt.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08406v1",
    "published_date": "2024-10-10 22:41:13 UTC",
    "updated_date": "2024-10-10 22:41:13 UTC"
  },
  {
    "arxiv_id": "2410.08405v2",
    "title": "AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning",
    "authors": [
      "Muhammad Awais",
      "Ali Husain Salem Abdulla Alharthi",
      "Amandeep Kumar",
      "Hisham Cholakkal",
      "Rao Muhammad Anwer"
    ],
    "abstract": "Significant progress has been made in advancing large multimodal\nconversational models (LMMs), capitalizing on vast repositories of image-text\ndata available online. Despite this progress, these models often encounter\nsubstantial domain gaps, hindering their ability to engage in complex\nconversations across new domains. Recent efforts have aimed to mitigate this\nissue, albeit relying on domain-specific image-text data to curate\ninstruction-tuning data. However, many domains, such as agriculture, lack such\nvision-language data. In this work, we propose an approach to construct\ninstruction-tuning data that harnesses vision-only data for the agriculture\ndomain. We utilize diverse agricultural datasets spanning multiple domains,\ncurate class-specific information, and employ large language models (LLMs) to\nconstruct an expert-tuning set, resulting in a 70k expert-tuning dataset called\nAgroInstruct. Subsequently, we expert-tuned and created AgroGPT, an efficient\nLMM that can hold complex agriculture-related conversations and provide useful\ninsights. We also develop AgroEvals for evaluation and compare {AgroGPT's}\nperformance with large open and closed-source models. {AgroGPT} excels at\nidentifying fine-grained agricultural concepts, can act as an agriculture\nexpert, and provides helpful information for multimodal agriculture questions.\nThe code, datasets, and models are available at\nhttps://github.com/awaisrauf/agroGPT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV, 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08405v2",
    "published_date": "2024-10-10 22:38:26 UTC",
    "updated_date": "2025-01-09 18:43:18 UTC"
  },
  {
    "arxiv_id": "2410.12854v2",
    "title": "TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees",
    "authors": [
      "Weibin Liao",
      "Xu Chu",
      "Yasha Wang"
    ],
    "abstract": "In the domain of complex reasoning tasks, such as mathematical reasoning,\nrecent advancements have proposed the use of Direct Preference Optimization\n(DPO) to suppress output of dispreferred responses, thereby enhancing the\nlong-chain reasoning capabilities of large language models (LLMs). To this end,\nthese studies employed LLMs to generate preference trees via Tree-of-thoughts\n(ToT) and sample the paired preference responses required by the DPO algorithm.\nHowever, the DPO algorithm based on binary preference optimization is unable to\nlearn multiple responses with varying degrees of preference/dispreference that\nprovided by the preference trees, resulting in incomplete preference learning.\nIn this work, we introduce Tree Preference Optimization (TPO), that does not\nsample paired preference responses from the preference tree; instead, it\ndirectly learns from the entire preference tree during the fine-tuning.\nSpecifically, TPO formulates the language model alignment as a Preference List\nRanking problem, where the policy can potentially learn more effectively from a\nranked preference list of responses given the prompt. In addition, to further\nassist LLMs in identifying discriminative steps within long-chain reasoning and\nincrease the relative reward margin in the preference list, TPO utilizes\nAdaptive Step Reward to adjust the reward values of each step in trajectory for\nperforming fine-grained preference optimization. We carry out extensive\nexperiments on mathematical reasoning tasks to evaluate TPO. The experimental\nresults indicate that TPO consistently outperforms DPO across five public large\nlanguage models on four datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12854v2",
    "published_date": "2024-10-10 22:22:05 UTC",
    "updated_date": "2025-03-13 06:40:44 UTC"
  },
  {
    "arxiv_id": "2410.08397v1",
    "title": "VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis",
    "authors": [
      "Andrew Hoopes",
      "Victor Ion Butoi",
      "John V. Guttag",
      "Adrian V. Dalca"
    ],
    "abstract": "We present VoxelPrompt, an agent-driven vision-language framework that\ntackles diverse radiological tasks through joint modeling of natural language,\nimage volumes, and analytical metrics. VoxelPrompt is multi-modal and\nversatile, leveraging the flexibility of language interaction while providing\nquantitatively grounded image analysis. Given a variable number of 3D medical\nvolumes, such as MRI and CT scans, VoxelPrompt employs a language agent that\niteratively predicts executable instructions to solve a task specified by an\ninput prompt. These instructions communicate with a vision network to encode\nimage features and generate volumetric outputs (e.g., segmentations).\nVoxelPrompt interprets the results of intermediate instructions and plans\nfurther actions to compute discrete measures (e.g., tumor growth across a\nseries of scans) and present relevant outputs to the user. We evaluate this\nframework in a sandbox of diverse neuroimaging tasks, and we show that the\nsingle VoxelPrompt model can delineate hundreds of anatomical and pathological\nfeatures, measure many complex morphological properties, and perform\nopen-language analysis of lesion characteristics. VoxelPrompt carries out these\nobjectives with accuracy similar to that of fine-tuned, single-task models for\nsegmentation and visual question-answering, while facilitating a much larger\nrange of tasks. Therefore, by supporting accurate image processing with\nlanguage interaction, VoxelPrompt provides comprehensive utility for numerous\nimaging tasks that traditionally require specialized models to address.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "21 pages, 5 figures, vision-language agent, medical image analysis,\n  neuroimage foundation model",
    "pdf_url": "http://arxiv.org/pdf/2410.08397v1",
    "published_date": "2024-10-10 22:11:43 UTC",
    "updated_date": "2024-10-10 22:11:43 UTC"
  },
  {
    "arxiv_id": "2410.08393v1",
    "title": "The Effects of Hallucinations in Synthetic Training Data for Relation Extraction",
    "authors": [
      "Steven Rogulsky",
      "Nicholas Popovic",
      "Michael Färber"
    ],
    "abstract": "Relation extraction is crucial for constructing knowledge graphs, with large\nhigh-quality datasets serving as the foundation for training, fine-tuning, and\nevaluating models. Generative data augmentation (GDA) is a common approach to\nexpand such datasets. However, this approach often introduces hallucinations,\nsuch as spurious facts, whose impact on relation extraction remains\nunderexplored. In this paper, we examine the effects of hallucinations on the\nperformance of relation extraction on the document and sentence levels. Our\nempirical study reveals that hallucinations considerably compromise the ability\nof models to extract relations from text, with recall reductions between 19.1%\nand 39.2%. We identify that relevant hallucinations impair the model's\nperformance, while irrelevant hallucinations have a minimal impact.\nAdditionally, we develop methods for the detection of hallucinations to improve\ndata quality and model performance. Our approaches successfully classify texts\nas either 'hallucinated' or 'clean,' achieving high F1-scores of 83.8% and\n92.2%. These methods not only assist in removing hallucinations but also help\nin estimating their prevalence within datasets, which is crucial for selecting\nhigh-quality data. Overall, our work confirms the profound impact of relevant\nhallucinations on the effectiveness of relation extraction models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at KBC-LM@ISWC'24",
    "pdf_url": "http://arxiv.org/pdf/2410.08393v1",
    "published_date": "2024-10-10 22:00:16 UTC",
    "updated_date": "2024-10-10 22:00:16 UTC"
  },
  {
    "arxiv_id": "2410.12853v2",
    "title": "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks",
    "authors": [
      "Mahmood Hegazy"
    ],
    "abstract": "Large language models (LLMs) excel in natural language generation but often\nconfidently produce incorrect responses, especially in tasks like mathematical\nreasoning. Chain-of-thought prompting, self-verification, and multi-agent\ndebate are among the strategies proposed to improve the reasoning and factual\naccuracy of LLMs. Building on Du et al.'s multi-agent debate framework, we find\nthat multi-agent debate helps at any model scale, and that diversity of thought\nelicits stronger reasoning in debating LLMs. Across various model sizes,\nperformance on mathematical reasoning tasks benefits most when diverse trained\nmodels are used. Remarkably, after 4 rounds of debate, a diverse set of\nmedium-capacity models (Gemini-Pro, Mixtral 7BX8, and PaLM 2-M) outperforms\nGPT-4 on the GSM-8K benchmark, scoring 91% accuracy. By comparison, when 3\ninstances of Gemini-Pro are used, performance only reaches 82%. Finally, this\ndiverse set of medium-capacity models sets a new state-of-the-art performance\non the ASDiv benchmark (94%). These results underscore the idea that the future\nof AI is agentic, with diverse cooperating agents yielding emergent\ncapabilities beyond even the most powerful individual models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12853v2",
    "published_date": "2024-10-10 21:59:01 UTC",
    "updated_date": "2025-01-23 22:22:13 UTC"
  },
  {
    "arxiv_id": "2410.08391v1",
    "title": "KV Prediction for Improved Time to First Token",
    "authors": [
      "Maxwell Horton",
      "Qingqing Cao",
      "Chenfan Sun",
      "Yanzi Jin",
      "Sachin Mehta",
      "Mohammad Rastegari",
      "Moin Nabi"
    ],
    "abstract": "Inference with transformer-based language models begins with a prompt\nprocessing step. In this step, the model generates the first output token and\nstores the KV cache needed for future generation steps. This prompt processing\nstep can be computationally expensive, taking 10s of seconds or more for\nbillion-parameter models on edge devices when prompt lengths or batch sizes\nrise. This degrades user experience by introducing significant latency into the\nmodel's outputs. To reduce the time spent producing the first output (known as\nthe ``time to first token'', or TTFT) of a pretrained model, we introduce a\nnovel method called KV Prediction. In our method, a small auxiliary model is\nused to process the prompt and produce an approximation of the KV cache used by\na base model. This approximated KV cache is then used with the base model for\nautoregressive generation without the need to query the auxiliary model again.\nWe demonstrate that our method produces a pareto-optimal efficiency-accuracy\ntrade-off when compared to baselines. On TriviaQA, we demonstrate relative\naccuracy improvements in the range of $15\\%-50\\%$ across a range of TTFT FLOPs\nbudgets. We also demonstrate accuracy improvements of up to $30\\%$ on HumanEval\npython code completion at fixed TTFT FLOPs budgets. Additionally, we benchmark\nmodels on an Apple M2 Pro CPU and demonstrate that our improvement in FLOPs\ntranslates to a TTFT speedup on hardware. We release our code at\nhttps://github.com/apple/corenet/tree/main/projects/kv-prediction .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08391v1",
    "published_date": "2024-10-10 21:55:11 UTC",
    "updated_date": "2024-10-10 21:55:11 UTC"
  },
  {
    "arxiv_id": "2410.08390v1",
    "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data",
    "authors": [
      "Andy Zhou",
      "Xiaojun Xu",
      "Ramesh Raghunathan",
      "Alok Lal",
      "Xinze Guan",
      "Bin Yu",
      "Bo Li"
    ],
    "abstract": "Graph-based anomaly detection is pivotal in diverse security applications,\nsuch as fraud detection in transaction networks and intrusion detection for\nnetwork traffic. Standard approaches, including Graph Neural Networks (GNNs),\noften struggle to generalize across shifting data distributions. Meanwhile,\nreal-world domain knowledge is more stable and a common existing component of\nreal-world detection strategies. To explicitly integrate such knowledge into\ndata-driven models such as GCNs, we propose KnowGraph, which integrates domain\nknowledge with data-driven learning for enhanced graph-based anomaly detection.\nKnowGraph comprises two principal components: (1) a statistical learning\ncomponent that utilizes a main model for the overarching detection task,\naugmented by multiple specialized knowledge models that predict domain-specific\nsemantic entities; (2) a reasoning component that employs probabilistic\ngraphical models to execute logical inferences based on model outputs, encoding\ndomain knowledge through weighted first-order logic formulas. Extensive\nexperiments on these large-scale real-world datasets show that KnowGraph\nconsistently outperforms state-of-the-art baselines in both transductive and\ninductive settings, achieving substantial gains in average precision when\ngeneralizing to completely unseen test graphs. Further ablation studies\ndemonstrate the effectiveness of the proposed reasoning component in improving\ndetection performance, especially under extreme class imbalance. These results\nhighlight the potential of integrating domain knowledge into data-driven models\nfor high-stakes, graph-based security applications.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ACM CCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08390v1",
    "published_date": "2024-10-10 21:53:33 UTC",
    "updated_date": "2024-10-10 21:53:33 UTC"
  },
  {
    "arxiv_id": "2410.08388v4",
    "title": "The GUS Framework: Benchmarking Social Bias Classification with Discriminative (Encoder-Only) and Generative (Decoder-Only) Language Models",
    "authors": [
      "Maximus Powers",
      "Shaina Raza",
      "Alex Chang",
      "Umang Mavani",
      "Harshitha Reddy Jonala",
      "Ansh Tiwari",
      "Hua Wei"
    ],
    "abstract": "The detection of social bias in text is a critical challenge, particularly\ndue to the limitations of binary classification methods. These methods often\noversimplify nuanced biases, leading to high emotional impact when content is\nmisclassified as either \"biased\" or \"fair.\" To address these shortcomings, we\npropose a more nuanced framework that focuses on three key linguistic\ncomponents underlying social bias: Generalizations, Unfairness, and Stereotypes\n(the GUS framework). The GUS framework employs a semi-automated approach to\ncreate a comprehensive synthetic dataset, which is then verified by humans to\nmaintain ethical standards. This dataset enables robust multi-label token\nclassification. Our methodology, which combines discriminative (encoder-only)\nmodels and generative (auto-regressive large language models), identifies\nbiased entities in text. Through extensive experiments, we demonstrate that\nencoder-only models are effective for this complex task, often outperforming\nstate-of-the-art methods, both in terms of macro and entity-wise F1-score and\nHamming loss. These findings can guide the choice of model for different use\ncases, highlighting the GUS framework's effectiveness in capturing explicit and\nimplicit biases across diverse contexts, and offering a pathway for future\nresearch and applications in various fields.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08388v4",
    "published_date": "2024-10-10 21:51:22 UTC",
    "updated_date": "2025-02-28 18:55:08 UTC"
  },
  {
    "arxiv_id": "2410.08385v1",
    "title": "Language model developers should report train-test overlap",
    "authors": [
      "Andy K Zhang",
      "Kevin Klyman",
      "Yifan Mai",
      "Yoav Levine",
      "Yian Zhang",
      "Rishi Bommasani",
      "Percy Liang"
    ],
    "abstract": "Language models are extensively evaluated, but correctly interpreting\nevaluation results requires knowledge of train-test overlap which refers to the\nextent to which the language model is trained on the very data it is being\ntested on. The public currently lacks adequate information about train-test\noverlap: most models have no public train-test overlap statistics, and third\nparties cannot directly measure train-test overlap since they do not have\naccess to the training data. To make this clear, we document the practices of\n30 model developers, finding that just 9 developers report train-test overlap:\n4 developers release training data under open-source licenses, enabling the\ncommunity to directly measure train-test overlap, and 5 developers publish\ntheir train-test overlap methodology and statistics. By engaging with language\nmodel developers, we provide novel information about train-test overlap for\nthree additional developers. Overall, we take the position that language model\ndevelopers should publish train-test overlap statistics and/or training data\nwhenever they report evaluation results on public test sets. We hope our work\nincreases transparency into train-test overlap to increase the community-wide\ntrust in model evaluations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08385v1",
    "published_date": "2024-10-10 21:44:56 UTC",
    "updated_date": "2024-10-10 21:44:56 UTC"
  },
  {
    "arxiv_id": "2410.08377v1",
    "title": "Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach",
    "authors": [
      "Niclas Boehmer",
      "Yunfan Zhao",
      "Guojun Xiong",
      "Paula Rodriguez-Diaz",
      "Paola Del Cueto Cibrian",
      "Joseph Ngonzi",
      "Adeline Boatin",
      "Milind Tambe"
    ],
    "abstract": "Maternal mortality remains a significant global public health challenge. One\npromising approach to reducing maternal deaths occurring during facility-based\nchildbirth is through early warning systems, which require the consistent\nmonitoring of mothers' vital signs after giving birth. Wireless vital sign\nmonitoring devices offer a labor-efficient solution for continuous monitoring,\nbut their scarcity raises the critical question of how to allocate them most\neffectively. We devise an allocation algorithm for this problem by modeling it\nas a variant of the popular Restless Multi-Armed Bandit (RMAB) paradigm. In\ndoing so, we identify and address novel, previously unstudied constraints\nunique to this domain, which render previous approaches for RMABs unsuitable\nand significantly increase the complexity of the learning and planning problem.\nTo overcome these challenges, we adopt the popular Proximal Policy Optimization\n(PPO) algorithm from reinforcement learning to learn an allocation policy by\ntraining a policy and value function network. We demonstrate in simulations\nthat our approach outperforms the best heuristic baseline by up to a factor of\n$4$.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08377v1",
    "published_date": "2024-10-10 21:20:07 UTC",
    "updated_date": "2024-10-10 21:20:07 UTC"
  },
  {
    "arxiv_id": "2410.08371v1",
    "title": "Merging in a Bottle: Differentiable Adaptive Merging (DAM) and the Path from Averaging to Automation",
    "authors": [
      "Thomas Gauthier-Caron",
      "Shamane Siriwardhana",
      "Elliot Stein",
      "Malikeh Ehghaghi",
      "Charles Goddard",
      "Mark McQuade",
      "Jacob Solawetz",
      "Maxime Labonne"
    ],
    "abstract": "By merging models, AI systems can combine the distinct strengths of separate\nlanguage models, achieving a balance between multiple capabilities without\nrequiring substantial retraining. However, the integration process can be\nintricate due to differences in training methods and fine-tuning, typically\nnecessitating specialized knowledge and repeated refinement. This paper\nexplores model merging techniques across a spectrum of complexity, examining\nwhere automated methods like evolutionary strategies stand compared to\nhyperparameter-driven approaches such as DARE, TIES-Merging and simpler methods\nlike Model Soups. In addition, we introduce Differentiable Adaptive Merging\n(DAM), an efficient, adaptive merging approach as an alternative to\nevolutionary merging that optimizes model integration through scaling\ncoefficients, minimizing computational demands. Our findings reveal that even\nsimple averaging methods, like Model Soups, perform competitively when model\nsimilarity is high, underscoring each technique's unique strengths and\nlimitations. We open-sourced DAM, including the implementation code and\nexperiment pipeline, on GitHub: https://github.com/arcee-ai/DAM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 figure, and 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08371v1",
    "published_date": "2024-10-10 20:58:29 UTC",
    "updated_date": "2024-10-10 20:58:29 UTC"
  },
  {
    "arxiv_id": "2410.08345v1",
    "title": "Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations",
    "authors": [
      "Henry Gasztowtt",
      "Benjamin Smith",
      "Vincent Zhu",
      "Qinxun Bai",
      "Edwin Zhang"
    ],
    "abstract": "The improvement of economic policymaking presents an opportunity for broad\nsocietal benefit, a notion that has inspired research towards AI-driven\npolicymaking tools. AI policymaking holds the potential to surpass human\nperformance through the ability to process data quickly at scale. However,\nexisting RL-based methods exhibit sample inefficiency, and are further limited\nby an inability to flexibly incorporate nuanced information into their\ndecision-making processes. Thus, we propose a novel method in which we instead\nutilize pre-trained Large Language Models (LLMs), as sample-efficient\npolicymakers in socially complex multi-agent reinforcement learning (MARL)\nscenarios. We demonstrate significant efficiency gains, outperforming existing\nmethods across three environments. Our code is available at\nhttps://github.com/hegasz/large-legislative-models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08345v1",
    "published_date": "2024-10-10 20:04:58 UTC",
    "updated_date": "2024-10-10 20:04:58 UTC"
  },
  {
    "arxiv_id": "2410.08336v2",
    "title": "Kernel Banzhaf: A Fast and Robust Estimator for Banzhaf Values",
    "authors": [
      "Yurong Liu",
      "R. Teal Witter",
      "Flip Korn",
      "Tarfah Alrashed",
      "Dimitris Paparas",
      "Christopher Musco",
      "Juliana Freire"
    ],
    "abstract": "Banzhaf values provide a popular, interpretable alternative to the\nwidely-used Shapley values for quantifying the importance of features in\nmachine learning models. Like Shapley values, computing Banzhaf values exactly\nrequires time exponential in the number of features, necessitating the use of\nefficient estimators. Existing estimators, however, are limited to Monte Carlo\nsampling methods. In this work, we introduce Kernel Banzhaf, the first\nregression-based estimator for Banzhaf values. Our approach leverages a novel\nregression formulation, whose exact solution corresponds to the exact Banzhaf\nvalues. Inspired by the success of Kernel SHAP for Shapley values, Kernel\nBanzhaf efficiently solves a sampled instance of this regression problem.\nThrough empirical evaluations across eight datasets, we find that Kernel\nBanzhaf significantly outperforms existing Monte Carlo methods in terms of\naccuracy, sample efficiency, robustness to noise, and feature ranking recovery.\nFinally, we complement our experimental evaluation with strong theoretical\nguarantees on Kernel Banzhaf's performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08336v2",
    "published_date": "2024-10-10 19:51:29 UTC",
    "updated_date": "2025-02-18 04:11:52 UTC"
  },
  {
    "arxiv_id": "2410.08334v1",
    "title": "Exploring Natural Language-Based Strategies for Efficient Number Learning in Children through Reinforcement Learning",
    "authors": [
      "Tirthankar Mittra"
    ],
    "abstract": "This paper investigates how children learn numbers using the framework of\nreinforcement learning (RL), with a focus on the impact of language\ninstructions. The motivation for using reinforcement learning stems from its\nparallels with psychological learning theories in controlled environments. By\nusing state of the art deep reinforcement learning models, we simulate and\nanalyze the effects of various forms of language instructions on number\nacquisition. Our findings indicate that certain linguistic structures more\neffectively improve numerical comprehension in RL agents. Additionally, our\nmodel predicts optimal sequences for presenting numbers to RL agents which\nenhance their speed of learning. This research provides valuable insights into\nthe interplay between language and numerical cognition, with implications for\nboth educational strategies and the development of artificial intelligence\nsystems designed to support early childhood learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08334v1",
    "published_date": "2024-10-10 19:49:13 UTC",
    "updated_date": "2024-10-10 19:49:13 UTC"
  },
  {
    "arxiv_id": "2410.08332v1",
    "title": "Level of agreement between emotions generated by Artificial Intelligence and human evaluation: a methodological proposal",
    "authors": [
      "Miguel Carrasco",
      "Cesar Gonzalez-Martin",
      "Sonia Navajas-Torrente",
      "Raul Dastres"
    ],
    "abstract": "Images are capable of conveying emotions, but emotional experience is highly\nsubjective. Advances in artificial intelligence have enabled the generation of\nimages based on emotional descriptions. However, the level of agreement between\nthe generative images and human emotional responses has not yet been evaluated.\nTo address this, 20 artistic landscapes were generated using StyleGAN2-ADA.\nFour variants evoking positive emotions (contentment, amusement) and negative\nemotions (fear, sadness) were created for each image, resulting in 80 pictures.\nAn online questionnaire was designed using this material, in which 61 observers\nclassified the generated images. Statistical analyses were performed on the\ncollected data to determine the level of agreement among participants, between\nthe observer's responses, and the AI-generated emotions. A generally good level\nof agreement was found, with better results for negative emotions. However, the\nstudy confirms the subjectivity inherent in emotional evaluation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08332v1",
    "published_date": "2024-10-10 19:44:32 UTC",
    "updated_date": "2024-10-10 19:44:32 UTC"
  },
  {
    "arxiv_id": "2410.08328v1",
    "title": "Agents Thinking Fast and Slow: A Talker-Reasoner Architecture",
    "authors": [
      "Konstantina Christakopoulou",
      "Shibl Mourad",
      "Maja Matarić"
    ],
    "abstract": "Large language models have enabled agents of all kinds to interact with users\nthrough natural conversation. Consequently, agents now have two jobs:\nconversing and planning/reasoning. Their conversational responses must be\ninformed by all available information, and their actions must help to achieve\ngoals. This dichotomy between conversing with the user and doing multi-step\nreasoning and planning can be seen as analogous to the human systems of\n\"thinking fast and slow\" as introduced by Kahneman. Our approach is comprised\nof a \"Talker\" agent (System 1) that is fast and intuitive, and tasked with\nsynthesizing the conversational response; and a \"Reasoner\" agent (System 2)\nthat is slower, more deliberative, and more logical, and is tasked with\nmulti-step reasoning and planning, calling tools, performing actions in the\nworld, and thereby producing the new agent state. We describe the new\nTalker-Reasoner architecture and discuss its advantages, including modularity\nand decreased latency. We ground the discussion in the context of a sleep\ncoaching agent, in order to demonstrate real-world relevance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08328v1",
    "published_date": "2024-10-10 19:31:35 UTC",
    "updated_date": "2024-10-10 19:31:35 UTC"
  },
  {
    "arxiv_id": "2410.08307v1",
    "title": "UNIQ: Offline Inverse Q-learning for Avoiding Undesirable Demonstrations",
    "authors": [
      "Huy Hoang",
      "Tien Mai",
      "Pradeep Varakantham"
    ],
    "abstract": "We address the problem of offline learning a policy that avoids undesirable\ndemonstrations. Unlike conventional offline imitation learning approaches that\naim to imitate expert or near-optimal demonstrations, our setting involves\navoiding undesirable behavior (specified using undesirable demonstrations). To\ntackle this problem, unlike standard imitation learning where the aim is to\nminimize the distance between learning policy and expert demonstrations, we\nformulate the learning task as maximizing a statistical distance, in the space\nof state-action stationary distributions, between the learning policy and the\nundesirable policy. This significantly different approach results in a novel\ntraining objective that necessitates a new algorithm to address it. Our\nalgorithm, UNIQ, tackles these challenges by building on the inverse Q-learning\nframework, framing the learning problem as a cooperative (non-adversarial)\ntask. We then demonstrate how to efficiently leverage unlabeled data for\npractical training. Our method is evaluated on standard benchmark environments,\nwhere it consistently outperforms state-of-the-art baselines. The code\nimplementation can be accessed at: https://github.com/hmhuy0/UNIQ.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08307v1",
    "published_date": "2024-10-10 18:52:58 UTC",
    "updated_date": "2024-10-10 18:52:58 UTC"
  },
  {
    "arxiv_id": "2410.08292v1",
    "title": "Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning?",
    "authors": [
      "Khashayar Gatmiry",
      "Nikunj Saunshi",
      "Sashank J. Reddi",
      "Stefanie Jegelka",
      "Sanjiv Kumar"
    ],
    "abstract": "The remarkable capability of Transformers to do reasoning and few-shot\nlearning, without any fine-tuning, is widely conjectured to stem from their\nability to implicitly simulate a multi-step algorithms -- such as gradient\ndescent -- with their weights in a single forward pass. Recently, there has\nbeen progress in understanding this complex phenomenon from an expressivity\npoint of view, by demonstrating that Transformers can express such multi-step\nalgorithms. However, our knowledge about the more fundamental aspect of its\nlearnability, beyond single layer models, is very limited. In particular, can\ntraining Transformers enable convergence to algorithmic solutions? In this work\nwe resolve this for in-context linear regression with linear looped\nTransformers -- a multi-layer model with weight sharing that is conjectured to\nhave an inductive bias to learn fix-point iterative algorithms. More\nspecifically, for this setting we show that the global minimizer of the\npopulation training loss implements multi-step preconditioned gradient descent,\nwith a preconditioner that adapts to the data distribution. Furthermore, we\nshow a fast convergence for gradient flow on the regression loss, despite the\nnon-convexity of the landscape, by proving a novel gradient dominance\ncondition. To our knowledge, this is the first theoretical analysis for\nmulti-layer Transformer in this setting. We further validate our theoretical\nfindings through synthetic experiments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08292v1",
    "published_date": "2024-10-10 18:29:05 UTC",
    "updated_date": "2024-10-10 18:29:05 UTC"
  },
  {
    "arxiv_id": "2410.08289v1",
    "title": "Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference",
    "authors": [
      "William Thorne",
      "Ambrose Robinson",
      "Bohua Peng",
      "Chenghua Lin",
      "Diana Maynard"
    ],
    "abstract": "As the cultural heritage sector increasingly adopts technologies like\nRetrieval-Augmented Generation (RAG) to provide more personalised search\nexperiences and enable conversations with collections data, the demand for\nspecialised evaluation datasets has grown. While end-to-end system testing is\nessential, it's equally important to assess individual components. We target\nthe final, answering task, which is well-suited to Machine Reading\nComprehension (MRC). Although existing MRC datasets address general domains,\nthey lack the specificity needed for cultural heritage information.\nUnfortunately, the manual creation of such datasets is prohibitively expensive\nfor most heritage institutions. This paper presents a cost-effective approach\nfor generating domain-specific MRC datasets with increased difficulty using\nReinforcement Learning from Human Feedback (RLHF) from synthetic preference\ndata. Our method leverages the performance of existing question-answering\nmodels on a subset of SQuAD to create a difficulty metric, assuming that more\nchallenging questions are answered correctly less frequently. This research\ncontributes: (1) A methodology for increasing question difficulty using PPO and\nsynthetic data; (2) Empirical evidence of the method's effectiveness, including\nhuman evaluation; (3) An in-depth error analysis and study of emergent\nphenomena; and (4) An open-source codebase and set of three llama-2-chat\nadapters for reproducibility and adaptation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50 (Primary) 91F20 (Secondary)",
      "I.2.7; J.5"
    ],
    "primary_category": "cs.CL",
    "comment": "is to be published in NLP4DH 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08289v1",
    "published_date": "2024-10-10 18:21:00 UTC",
    "updated_date": "2024-10-10 18:21:00 UTC"
  },
  {
    "arxiv_id": "2410.09118v1",
    "title": "FSW-GNN: A Bi-Lipschitz WL-Equivalent Graph Neural Network",
    "authors": [
      "Yonatan Sverdlov",
      "Yair Davidson",
      "Nadav Dym",
      "Tal Amir"
    ],
    "abstract": "Many of the most popular graph neural networks fall into the category of\nmessage-passing neural networks (MPNNs). Famously, MPNNs' ability to\ndistinguish between graphs is limited to graphs separable by the\nWeisfeiler-Lemann (WL) graph isomorphism test, and the strongest MPNNs, in\nterms of separation power, are WL-equivalent.\n  Recently, it was shown that the quality of separation provided by standard\nWL-equivalent MPNN can be very low, resulting in WL-separable graphs being\nmapped to very similar, hardly distinguishable features. This paper addresses\nthis issue by seeking bi-Lipschitz continuity guarantees for MPNNs. We\ndemonstrate that, in contrast with standard summation-based MPNNs, which lack\nbi-Lipschitz properties, our proposed model provides a bi-Lipschitz graph\nembedding with respect to two standard graph metrics. Empirically, we show that\nour MPNN is competitive with standard MPNNs for several graph learning tasks\nand is far more accurate in over-squashing long-range tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09118v1",
    "published_date": "2024-10-10 18:11:23 UTC",
    "updated_date": "2024-10-10 18:11:23 UTC"
  },
  {
    "arxiv_id": "2410.08282v1",
    "title": "FusionSense: Bridging Common Sense, Vision, and Touch for Robust Sparse-View Reconstruction",
    "authors": [
      "Irving Fang",
      "Kairui Shi",
      "Xujin He",
      "Siqi Tan",
      "Yifan Wang",
      "Hanwen Zhao",
      "Hung-Jui Huang",
      "Wenzhen Yuan",
      "Chen Feng",
      "Jing Zhang"
    ],
    "abstract": "Humans effortlessly integrate common-sense knowledge with sensory input from\nvision and touch to understand their surroundings. Emulating this capability,\nwe introduce FusionSense, a novel 3D reconstruction framework that enables\nrobots to fuse priors from foundation models with highly sparse observations\nfrom vision and tactile sensors. FusionSense addresses three key challenges:\n(i) How can robots efficiently acquire robust global shape information about\nthe surrounding scene and objects? (ii) How can robots strategically select\ntouch points on the object using geometric and common-sense priors? (iii) How\ncan partial observations such as tactile signals improve the overall\nrepresentation of the object? Our framework employs 3D Gaussian Splatting as a\ncore representation and incorporates a hierarchical optimization strategy\ninvolving global structure construction, object visual hull pruning and local\ngeometric constraints. This advancement results in fast and robust perception\nin environments with traditionally challenging objects that are transparent,\nreflective, or dark, enabling more downstream manipulation or navigation tasks.\nExperiments on real-world data suggest that our framework outperforms\npreviously state-of-the-art sparse-view methods. All code and data are\nopen-sourced on the project website.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "I.4.5; I.4.8"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08282v1",
    "published_date": "2024-10-10 18:07:07 UTC",
    "updated_date": "2024-10-10 18:07:07 UTC"
  },
  {
    "arxiv_id": "2410.09117v1",
    "title": "REDO: Execution-Free Runtime Error Detection for COding Agents",
    "authors": [
      "Shou Li",
      "Andrey Kan",
      "Laurent Callot",
      "Bhavana Bhasker",
      "Muhammad Shihab Rashid",
      "Timothy B Esler"
    ],
    "abstract": "As LLM-based agents exhibit exceptional capabilities in addressing complex\nproblems, there is a growing focus on developing coding agents to tackle\nincreasingly sophisticated tasks. Despite their promising performance, these\ncoding agents often produce programs or modifications that contain runtime\nerrors, which can cause code failures and are difficult for static analysis\ntools to detect. Enhancing the ability of coding agents to statically identify\nsuch errors could significantly improve their overall performance. In this\nwork, we introduce Execution-free Runtime Error Detection for COding Agents\n(REDO), a method that integrates LLMs with static analysis tools to detect\nruntime errors for coding agents, without code execution. Additionally, we\npropose a benchmark task, SWE-Bench-Error-Detection (SWEDE), based on SWE-Bench\n(lite), to evaluate error detection in repository-level problems with complex\nexternal dependencies. Finally, through both quantitative and qualitative\nanalyses across various error detection tasks, we demonstrate that REDO\noutperforms current state-of-the-art methods by achieving a 11.0% higher\naccuracy and 9.1% higher weighted F1 score; and provide insights into the\nadvantages of incorporating LLMs for error detection.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "27 pages, 13 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.09117v1",
    "published_date": "2024-10-10 18:06:29 UTC",
    "updated_date": "2024-10-10 18:06:29 UTC"
  },
  {
    "arxiv_id": "2410.08211v1",
    "title": "LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts",
    "authors": [
      "Anh-Quan Cao",
      "Maximilian Jaritz",
      "Matthieu Guillaumin",
      "Raoul de Charette",
      "Loris Bazzani"
    ],
    "abstract": "Large-scale vision-language pre-trained (VLP) models (e.g., CLIP) are\nrenowned for their versatility, as they can be applied to diverse applications\nin a zero-shot setup. However, when these models are used in specific domains,\ntheir performance often falls short due to domain gaps or the\nunder-representation of these domains in the training data. While fine-tuning\nVLP models on custom datasets with human-annotated labels can address this\nissue, annotating even a small-scale dataset (e.g., 100k samples) can be an\nexpensive endeavor, often requiring expert annotators if the task is complex.\nTo address these challenges, we propose LatteCLIP, an unsupervised method for\nfine-tuning CLIP models on classification with known class names in custom\ndomains, without relying on human annotations. Our method leverages Large\nMultimodal Models (LMMs) to generate expressive textual descriptions for both\nindividual images and groups of images. These provide additional contextual\ninformation to guide the fine-tuning process in the custom domains. Since\nLMM-generated descriptions are prone to hallucination or missing details, we\nintroduce a novel strategy to distill only the useful information and stabilize\nthe training. Specifically, we learn rich per-class prototype representations\nfrom noisy generated texts and dual pseudo-labels. Our experiments on 10\ndomain-specific datasets show that LatteCLIP outperforms pre-trained zero-shot\nmethods by an average improvement of +4.74 points in top-1 accuracy and other\nstate-of-the-art unsupervised methods by +3.45 points.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08211v1",
    "published_date": "2024-10-10 17:59:59 UTC",
    "updated_date": "2024-10-10 17:59:59 UTC"
  },
  {
    "arxiv_id": "2410.08210v1",
    "title": "PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection",
    "authors": [
      "Botao Ren",
      "Xue Yang",
      "Yi Yu",
      "Junwei Luo",
      "Zhidong Deng"
    ],
    "abstract": "Single point supervised oriented object detection has gained attention and\nmade initial progress within the community. Diverse from those approaches\nrelying on one-shot samples or powerful pretrained models (e.g. SAM), PointOBB\nhas shown promise due to its prior-free feature. In this paper, we propose\nPointOBB-v2, a simpler, faster, and stronger method to generate pseudo rotated\nboxes from points without relying on any other prior. Specifically, we first\ngenerate a Class Probability Map (CPM) by training the network with non-uniform\npositive and negative sampling. We show that the CPM is able to learn the\napproximate object regions and their contours. Then, Principal Component\nAnalysis (PCA) is applied to accurately estimate the orientation and the\nboundary of objects. By further incorporating a separation mechanism, we\nresolve the confusion caused by the overlapping on the CPM, enabling its\noperation in high-density scenarios. Extensive comparisons demonstrate that our\nmethod achieves a training speed 15.58x faster and an accuracy improvement of\n11.60%/25.15%/21.19% on the DOTA-v1.0/v1.5/v2.0 datasets compared to the\nprevious state-of-the-art, PointOBB. This significantly advances the cutting\nedge of single point supervised oriented detection in the modular track.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 4 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08210v1",
    "published_date": "2024-10-10 17:59:56 UTC",
    "updated_date": "2024-10-10 17:59:56 UTC"
  },
  {
    "arxiv_id": "2410.08209v1",
    "title": "Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision",
    "authors": [
      "Shengcao Cao",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ],
    "abstract": "Current large multimodal models (LMMs) face challenges in grounding, which\nrequires the model to relate language components to visual entities. Contrary\nto the common practice that fine-tunes LMMs with additional grounding\nsupervision, we find that the grounding ability can in fact emerge in LMMs\ntrained without explicit grounding supervision. To reveal this emerging\ngrounding, we introduce an \"attend-and-segment\" method which leverages\nattention maps from standard LMMs to perform pixel-level segmentation.\nFurthermore, to enhance the grounding ability, we propose DIFFLMM, an LMM\nutilizing a diffusion-based visual encoder, as opposed to the standard CLIP\nvisual encoder, and trained with the same weak supervision. Without being\nconstrained by the biases and limited scale of grounding-specific supervision\ndata, our approach is more generalizable and scalable. We achieve competitive\nperformance on both grounding-specific and general visual question answering\nbenchmarks, compared with grounding LMMs and generalist LMMs, respectively.\nNotably, we achieve a 44.2 grounding mask recall on grounded conversation\ngeneration without any grounding supervision, outperforming the extensively\nsupervised model GLaMM. Project page: https://groundLMM.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08209v1",
    "published_date": "2024-10-10 17:59:55 UTC",
    "updated_date": "2024-10-10 17:59:55 UTC"
  },
  {
    "arxiv_id": "2410.08208v3",
    "title": "SPA: 3D Spatial-Awareness Enables Effective Embodied Representation",
    "authors": [
      "Haoyi Zhu",
      "Honghui Yang",
      "Yating Wang",
      "Jiange Yang",
      "Limin Wang",
      "Tong He"
    ],
    "abstract": "In this paper, we introduce SPA, a novel representation learning framework\nthat emphasizes the importance of 3D spatial awareness in embodied AI. Our\napproach leverages differentiable neural rendering on multi-view images to\nendow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.\nWe present the most comprehensive evaluation of embodied representation\nlearning to date, covering 268 tasks across 8 simulators with diverse policies\nin both single-task and language-conditioned multi-task scenarios. The results\nare compelling: SPA consistently outperforms more than 10 state-of-the-art\nrepresentation methods, including those specifically designed for embodied AI,\nvision-centric tasks, and multi-modal applications, while using less training\ndata. Furthermore, we conduct a series of real-world experiments to confirm its\neffectiveness in practical scenarios. These results highlight the critical role\nof 3D spatial awareness for embodied representation learning. Our strongest\nmodel takes more than 6000 GPU hours to train and we are committed to\nopen-sourcing all code and model weights to foster future research in embodied\nrepresentation learning. Project Page: https://haoyizhu.github.io/spa/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://haoyizhu.github.io/spa/",
    "pdf_url": "http://arxiv.org/pdf/2410.08208v3",
    "published_date": "2024-10-10 17:59:51 UTC",
    "updated_date": "2025-03-01 15:51:38 UTC"
  },
  {
    "arxiv_id": "2410.12851v7",
    "title": "VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models",
    "authors": [
      "Lisa Dunlap",
      "Krishna Mandal",
      "Trevor Darrell",
      "Jacob Steinhardt",
      "Joseph E Gonzalez"
    ],
    "abstract": "Large language models (LLMs) often exhibit subtle yet distinctive\ncharacteristics in their outputs that users intuitively recognize, but struggle\nto quantify. These \"vibes\" -- such as tone, formatting, or writing style --\ninfluence user preferences, yet traditional evaluations focus primarily on the\nsingular axis of correctness. We introduce VibeCheck, a system for\nautomatically comparing a pair of LLMs by discovering identifying traits of a\nmodel (vibes) that are well-defined, differentiating, and user-aligned.\nVibeCheck iteratively discovers vibes from model outputs and then utilizes a\npanel of LLM judges to quantitatively measure the utility of each vibe. We\nvalidate that the vibes generated by VibeCheck align with those found in human\ndiscovery and run VibeCheck on pairwise preference data from real-world user\nconversations with Llama-3-70b vs GPT-4. VibeCheck reveals that Llama has a\nfriendly, funny, and somewhat controversial vibe. These vibes predict model\nidentity with 80% accuracy and human preference with 61% accuracy. Lastly, we\nrun VibeCheck on a variety of models and tasks including summarization, math,\nand captioning to provide insight into differences in model behavior. VibeCheck\ndiscovers vibes like Command X prefers to add concrete intros and conclusions\nwhen summarizing in comparison to TNGL, Llama-405b often overexplains its\nthought process on math problems compared to GPT-4o, and GPT-4 prefers to focus\non the mood and emotions of the scene when captioning compared to\nGemini-1.5-Flash. Code and vibe visualizer found at https://bench-mark.org/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "unironic use of the word 'vibe', added more analysis and cooler\n  graphs. added website link",
    "pdf_url": "http://arxiv.org/pdf/2410.12851v7",
    "published_date": "2024-10-10 17:59:17 UTC",
    "updated_date": "2025-04-19 23:14:54 UTC"
  },
  {
    "arxiv_id": "2410.19750v2",
    "title": "The Geometry of Concepts: Sparse Autoencoder Feature Structure",
    "authors": [
      "Yuxiao Li",
      "Eric J. Michaud",
      "David D. Baek",
      "Joshua Engels",
      "Xiaoqing Sun",
      "Max Tegmark"
    ],
    "abstract": "Sparse autoencoders have recently produced dictionaries of high-dimensional\nvectors corresponding to the universe of concepts represented by large language\nmodels. We find that this concept universe has interesting structure at three\nlevels: 1) The \"atomic\" small-scale structure contains \"crystals\" whose faces\nare parallelograms or trapezoids, generalizing well-known examples such as\n(man-woman-king-queen). We find that the quality of such parallelograms and\nassociated function vectors improves greatly when projecting out global\ndistractor directions such as word length, which is efficiently done with\nlinear discriminant analysis. 2) The \"brain\" intermediate-scale structure has\nsignificant spatial modularity; for example, math and code features form a\n\"lobe\" akin to functional lobes seen in neural fMRI images. We quantify the\nspatial locality of these lobes with multiple metrics and find that clusters of\nco-occurring features, at coarse enough scale, also cluster together spatially\nfar more than one would expect if feature geometry were random. 3) The \"galaxy\"\nscale large-scale structure of the feature point cloud is not isotropic, but\ninstead has a power law of eigenvalues with steepest slope in middle layers. We\nalso quantify how the clustering entropy depends on the layer.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "16 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19750v2",
    "published_date": "2024-10-10 17:58:47 UTC",
    "updated_date": "2025-03-30 23:55:03 UTC"
  },
  {
    "arxiv_id": "2410.08197v2",
    "title": "From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions",
    "authors": [
      "Changle Qu",
      "Sunhao Dai",
      "Xiaochi Wei",
      "Hengyi Cai",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Jun Xu",
      "Ji-Rong Wen"
    ],
    "abstract": "Tool learning enables Large Language Models (LLMs) to interact with external\nenvironments by invoking tools, serving as an effective strategy to mitigate\nthe limitations inherent in their pre-training data. In this process, tool\ndocumentation plays a crucial role by providing usage instructions for LLMs,\nthereby facilitating effective tool utilization. This paper concentrates on the\ncritical challenge of bridging the comprehension gap between LLMs and external\ntools due to the inadequacies and inaccuracies inherent in existing\nhuman-centric tool documentation. We propose a novel framework, DRAFT, aimed at\nDynamically Refining tool documentation through the Analysis of Feedback and\nTrials emanating from LLMs' interactions with external tools. This methodology\npivots on an innovative trial-and-error approach, consisting of three distinct\nlearning phases: experience gathering, learning from experience, and\ndocumentation rewriting, to iteratively enhance the tool documentation. This\nprocess is further optimized by implementing a diversity-promoting exploration\nstrategy to ensure explorative diversity and a tool-adaptive termination\nmechanism to prevent overfitting while enhancing efficiency. Extensive\nexperiments on multiple datasets demonstrate that DRAFT's iterative,\nfeedback-based refinement significantly ameliorates documentation quality,\nfostering a deeper comprehension and more effective utilization of tools by\nLLMs. Notably, our analysis reveals that the tool documentation refined via our\napproach demonstrates robust cross-model generalization capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Oral;GitHub:https://github.com/quchangle1/DRAFT",
    "pdf_url": "http://arxiv.org/pdf/2410.08197v2",
    "published_date": "2024-10-10 17:58:44 UTC",
    "updated_date": "2025-02-26 03:24:58 UTC"
  },
  {
    "arxiv_id": "2410.08196v1",
    "title": "MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code",
    "authors": [
      "Zimu Lu",
      "Aojun Zhou",
      "Ke Wang",
      "Houxing Ren",
      "Weikang Shi",
      "Junting Pan",
      "Mingjie Zhan",
      "Hongsheng Li"
    ],
    "abstract": "Code has been shown to be effective in enhancing the mathematical reasoning\nabilities of large language models due to its precision and accuracy. Previous\nworks involving continued mathematical pretraining often include code that\nutilizes math-related packages, which are primarily designed for fields such as\nengineering, machine learning, signal processing, or module testing, rather\nthan being directly focused on mathematical reasoning. In this paper, we\nintroduce a novel method for generating mathematical code accompanied with\ncorresponding reasoning steps for continued pretraining. Our approach begins\nwith the construction of a high-quality mathematical continued pretraining\ndataset by incorporating math-related web data, code using mathematical\npackages, math textbooks, and synthetic data. Next, we construct reasoning\nsteps by extracting LaTeX expressions, the conditions needed for the\nexpressions, and the results of the expressions from the previously collected\ndataset. Based on this extracted information, we generate corresponding code to\naccurately capture the mathematical reasoning process. Appending the generated\ncode to each reasoning step results in data consisting of paired natural\nlanguage reasoning steps and their corresponding code. Combining this data with\nthe original dataset results in a 19.2B-token high-performing mathematical\npretraining corpus, which we name MathCode-Pile. Training several popular base\nmodels with this corpus significantly improves their mathematical abilities,\nleading to the creation of the MathCoder2 family of models. All of our data\nprocessing and training code is open-sourced, ensuring full transparency and\neasy reproducibility of the entire data collection and training pipeline. The\ncode is released at https://github.com/mathllm/MathCoder2 .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/mathllm/MathCoder2",
    "pdf_url": "http://arxiv.org/pdf/2410.08196v1",
    "published_date": "2024-10-10 17:58:40 UTC",
    "updated_date": "2024-10-10 17:58:40 UTC"
  },
  {
    "arxiv_id": "2410.08260v2",
    "title": "Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content",
    "authors": [
      "Qiuheng Wang",
      "Yukai Shi",
      "Jiarong Ou",
      "Rui Chen",
      "Ke Lin",
      "Jiahao Wang",
      "Boyuan Jiang",
      "Haotian Yang",
      "Mingwu Zheng",
      "Xin Tao",
      "Fei Yang",
      "Pengfei Wan",
      "Di Zhang"
    ],
    "abstract": "With the continuous progress of visual generation technologies, the scale of\nvideo datasets has grown exponentially. The quality of these datasets plays a\npivotal role in the performance of video generation models. We assert that\ntemporal splitting, detailed captions, and video quality filtering are three\ncrucial determinants of dataset quality. However, existing datasets exhibit\nvarious limitations in these areas. To address these challenges, we introduce\nKoala-36M, a large-scale, high-quality video dataset featuring accurate\ntemporal splitting, detailed captions, and superior video quality. The essence\nof our approach lies in improving the consistency between fine-grained\nconditions and video content. Specifically, we employ a linear classifier on\nprobability distributions to enhance the accuracy of transition detection,\nensuring better temporal consistency. We then provide structured captions for\nthe splitted videos, with an average length of 200 words, to improve text-video\nalignment. Additionally, we develop a Video Training Suitability Score (VTSS)\nthat integrates multiple sub-metrics, allowing us to filter high-quality videos\nfrom the original corpus. Finally, we incorporate several metrics into the\ntraining process of the generation model, further refining the fine-grained\nconditions. Our experiments demonstrate the effectiveness of our data\nprocessing pipeline and the quality of the proposed Koala-36M dataset. Our\ndataset and code have been released at https://koala36m.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025. Project page: https://koala36m.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.08260v2",
    "published_date": "2024-10-10 17:57:49 UTC",
    "updated_date": "2025-04-26 17:58:24 UTC"
  },
  {
    "arxiv_id": "2410.08188v1",
    "title": "DifFRelight: Diffusion-Based Facial Performance Relighting",
    "authors": [
      "Mingming He",
      "Pascal Clausen",
      "Ahmet Levent Taşel",
      "Li Ma",
      "Oliver Pilarski",
      "Wenqi Xian",
      "Laszlo Rikker",
      "Xueming Yu",
      "Ryan Burgert",
      "Ning Yu",
      "Paul Debevec"
    ],
    "abstract": "We present a novel framework for free-viewpoint facial performance relighting\nusing diffusion-based image-to-image translation. Leveraging a subject-specific\ndataset containing diverse facial expressions captured under various lighting\nconditions, including flat-lit and one-light-at-a-time (OLAT) scenarios, we\ntrain a diffusion model for precise lighting control, enabling high-fidelity\nrelit facial images from flat-lit inputs. Our framework includes\nspatially-aligned conditioning of flat-lit captures and random noise, along\nwith integrated lighting information for global control, utilizing prior\nknowledge from the pre-trained Stable Diffusion model. This model is then\napplied to dynamic facial performances captured in a consistent flat-lit\nenvironment and reconstructed for novel-view synthesis using a scalable dynamic\n3D Gaussian Splatting method to maintain quality and consistency in the relit\nresults. In addition, we introduce unified lighting control by integrating a\nnovel area lighting representation with directional lighting, allowing for\njoint adjustments in light size and direction. We also enable high dynamic\nrange imaging (HDRI) composition using multiple directional lights to produce\ndynamic sequences under complex lighting conditions. Our evaluations\ndemonstrate the models efficiency in achieving precise lighting control and\ngeneralizing across various facial expressions while preserving detailed\nfeatures such as skintexture andhair. The model accurately reproduces complex\nlighting effects like eye reflections, subsurface scattering, self-shadowing,\nand translucency, advancing photorealism within our framework.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, SIGGRAPH Asia 2024 Conference Papers (SA Conference Papers\n  '24), December 3--6, 2024, Tokyo, Japan. Project page:\n  https://www.eyelinestudios.com/research/diffrelight.html",
    "pdf_url": "http://arxiv.org/pdf/2410.08188v1",
    "published_date": "2024-10-10 17:56:44 UTC",
    "updated_date": "2024-10-10 17:56:44 UTC"
  },
  {
    "arxiv_id": "2410.08182v2",
    "title": "MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models",
    "authors": [
      "Wenbo Hu",
      "Jia-Chen Gu",
      "Zi-Yi Dou",
      "Mohsen Fayyaz",
      "Pan Lu",
      "Kai-Wei Chang",
      "Nanyun Peng"
    ],
    "abstract": "Existing multimodal retrieval benchmarks primarily focus on evaluating\nwhether models can retrieve and utilize external textual knowledge for question\nanswering. However, there are scenarios where retrieving visual information is\neither more beneficial or easier to access than textual data. In this paper, we\nintroduce a multimodal retrieval-augmented generation benchmark, MRAG-Bench, in\nwhich we systematically identify and categorize scenarios where visually\naugmented knowledge is better than textual knowledge, for instance, more images\nfrom varying viewpoints. MRAG-Bench consists of 16,130 images and 1,353\nhuman-annotated multiple-choice questions across 9 distinct scenarios. With\nMRAG-Bench, we conduct an evaluation of 10 open-source and 4 proprietary large\nvision-language models (LVLMs). Our results show that all LVLMs exhibit greater\nimprovements when augmented with images compared to textual knowledge,\nconfirming that MRAG-Bench is vision-centric. Additionally, we conduct\nextensive analysis with MRAG-Bench, which offers valuable insights into\nretrieval-augmented LVLMs. Notably, the top-performing model, GPT-4o, faces\nchallenges in effectively leveraging retrieved knowledge, achieving only a\n5.82% improvement with ground-truth information, in contrast to a 33.16%\nimprovement observed in human participants. These findings highlight the\nimportance of MRAG-Bench in encouraging the community to enhance LVLMs' ability\nto utilize retrieved visual knowledge more effectively.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08182v2",
    "published_date": "2024-10-10 17:55:02 UTC",
    "updated_date": "2025-03-19 20:58:37 UTC"
  },
  {
    "arxiv_id": "2410.08174v2",
    "title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models",
    "authors": [
      "Qingni Wang",
      "Tiantian Geng",
      "Zhiyuan Wang",
      "Teng Wang",
      "Bo Fu",
      "Feng Zheng"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) exhibit promising advancements\nacross various tasks, yet they still encounter significant trustworthiness\nissues. Prior studies apply Split Conformal Prediction (SCP) in language\nmodeling to construct prediction sets with statistical guarantees. However,\nthese methods typically rely on internal model logits or are restricted to\nmultiple-choice settings, which hampers their generalizability and adaptability\nin dynamic, open-ended environments. In this paper, we introduce TRON, a\ntwo-step framework for risk control and assessment, applicable to any MLLM that\nsupports sampling in both open-ended and closed-ended scenarios. TRON comprises\ntwo main components: (1) a novel conformal score to sample response sets of\nminimum size, and (2) a nonconformity score to identify high-quality responses\nbased on self-consistency theory, controlling the error rates by two specific\nrisk levels. Furthermore, we investigate semantic redundancy in prediction sets\nwithin open-ended contexts for the first time, leading to a promising\nevaluation metric for MLLMs based on average set size. Our comprehensive\nexperiments across four Video Question-Answering (VideoQA) datasets utilizing\neight MLLMs show that TRON achieves desired error rates bounded by two\nuser-specified risk levels. Additionally, deduplicated prediction sets maintain\nadaptiveness while being more efficient and stable for risk assessment under\ndifferent risk levels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08174v2",
    "published_date": "2024-10-10 17:50:42 UTC",
    "updated_date": "2024-12-14 10:34:35 UTC"
  },
  {
    "arxiv_id": "2410.08172v1",
    "title": "On the Evaluation of Generative Robotic Simulations",
    "authors": [
      "Feng Chen",
      "Botian Xu",
      "Pu Hua",
      "Peiqi Duan",
      "Yanchao Yang",
      "Yi Ma",
      "Huazhe Xu"
    ],
    "abstract": "Due to the difficulty of acquiring extensive real-world data, robot\nsimulation has become crucial for parallel training and sim-to-real transfer,\nhighlighting the importance of scalable simulated robotic tasks. Foundation\nmodels have demonstrated impressive capacities in autonomously generating\nfeasible robotic tasks. However, this new paradigm underscores the challenge of\nadequately evaluating these autonomously generated tasks. To address this, we\npropose a comprehensive evaluation framework tailored to generative\nsimulations. Our framework segments evaluation into three core aspects:\nquality, diversity, and generalization. For single-task quality, we evaluate\nthe realism of the generated task and the completeness of the generated\ntrajectories using large language models and vision-language models. In terms\nof diversity, we measure both task and data diversity through text similarity\nof task descriptions and world model loss trained on collected task\ntrajectories. For task-level generalization, we assess the zero-shot\ngeneralization ability on unseen tasks of a policy trained with multiple\ngenerated tasks. Experiments conducted on three representative task generation\npipelines demonstrate that the results from our framework are highly consistent\nwith human evaluations, confirming the feasibility and validity of our\napproach. The findings reveal that while metrics of quality and diversity can\nbe achieved through certain methods, no single approach excels across all\nmetrics, suggesting a need for greater focus on balancing these different\nmetrics. Additionally, our analysis further highlights the common challenge of\nlow generalization capability faced by current works. Our anonymous website:\nhttps://sites.google.com/view/evaltasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Project website: https://sites.google.com/view/evaltasks",
    "pdf_url": "http://arxiv.org/pdf/2410.08172v1",
    "published_date": "2024-10-10 17:49:25 UTC",
    "updated_date": "2024-10-10 17:49:25 UTC"
  },
  {
    "arxiv_id": "2410.08164v1",
    "title": "Agent S: An Open Agentic Framework that Uses Computers Like a Human",
    "authors": [
      "Saaket Agashe",
      "Jiuzhou Han",
      "Shuyu Gan",
      "Jiachen Yang",
      "Ang Li",
      "Xin Eric Wang"
    ],
    "abstract": "We present Agent S, an open agentic framework that enables autonomous\ninteraction with computers through a Graphical User Interface (GUI), aimed at\ntransforming human-computer interaction by automating complex, multi-step\ntasks. Agent S aims to address three key challenges in automating computer\ntasks: acquiring domain-specific knowledge, planning over long task horizons,\nand handling dynamic, non-uniform interfaces. To this end, Agent S introduces\nexperience-augmented hierarchical planning, which learns from external\nknowledge search and internal experience retrieval at multiple levels,\nfacilitating efficient task planning and subtask execution. In addition, it\nemploys an Agent-Computer Interface (ACI) to better elicit the reasoning and\ncontrol capabilities of GUI agents based on Multimodal Large Language Models\n(MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the\nbaseline by 9.37% on success rate (an 83.6% relative improvement) and achieves\na new state-of-the-art. Comprehensive analysis highlights the effectiveness of\nindividual components and provides insights for future improvements.\nFurthermore, Agent S demonstrates broad generalizability to different operating\nsystems on a newly-released WindowsAgentArena benchmark. Code available at\nhttps://github.com/simular-ai/Agent-S.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 16 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08164v1",
    "published_date": "2024-10-10 17:43:51 UTC",
    "updated_date": "2024-10-10 17:43:51 UTC"
  },
  {
    "arxiv_id": "2410.19749v1",
    "title": "Using AI Alignment Theory to understand the potential pitfalls of regulatory frameworks",
    "authors": [
      "Alejandro Tlaie"
    ],
    "abstract": "This paper leverages insights from Alignment Theory (AT) research, which\nprimarily focuses on the potential pitfalls of technical alignment in\nArtificial Intelligence, to critically examine the European Union's Artificial\nIntelligence Act (EU AI Act). In the context of AT research, several key\nfailure modes - such as proxy gaming, goal drift, reward hacking or\nspecification gaming - have been identified. These can arise when AI systems\nare not properly aligned with their intended objectives. The central logic of\nthis report is: what can we learn if we treat regulatory efforts in the same\nway as we treat advanced AI systems? As we systematically apply these concepts\nto the EU AI Act, we uncover potential vulnerabilities and areas for\nimprovement in the regulation.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19749v1",
    "published_date": "2024-10-10 17:38:38 UTC",
    "updated_date": "2024-10-10 17:38:38 UTC"
  },
  {
    "arxiv_id": "2410.08143v2",
    "title": "DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory",
    "authors": [
      "Yutong Wang",
      "Jiali Zeng",
      "Xuebo Liu",
      "Derek F. Wong",
      "Fandong Meng",
      "Jie Zhou",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) have achieved reasonable quality improvements in\nmachine translation (MT). However, most current research on MT-LLMs still faces\nsignificant challenges in maintaining translation consistency and accuracy when\nprocessing entire documents. In this paper, we introduce DelTA, a\nDocument-levEL Translation Agent designed to overcome these limitations. DelTA\nfeatures a multi-level memory structure that stores information across various\ngranularities and spans, including Proper Noun Records, Bilingual Summary,\nLong-Term Memory, and Short-Term Memory, which are continuously retrieved and\nupdated by auxiliary LLM-based components. Experimental results indicate that\nDelTA significantly outperforms strong baselines in terms of translation\nconsistency and quality across four open/closed-source LLMs and two\nrepresentative document translation datasets, achieving an increase in\nconsistency scores by up to 4.58 percentage points and in COMET scores by up to\n3.16 points on average. DelTA employs a sentence-by-sentence translation\nstrategy, ensuring no sentence omissions and offering a memory-efficient\nsolution compared to the mainstream method. Furthermore, DelTA improves pronoun\nand context-dependent translation accuracy, and the summary component of the\nagent also shows promise as a tool for query-based summarization tasks. The\ncode and data of our approach are released at\nhttps://github.com/YutongWang1216/DocMTAgent.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08143v2",
    "published_date": "2024-10-10 17:30:09 UTC",
    "updated_date": "2025-03-05 17:50:44 UTC"
  },
  {
    "arxiv_id": "2410.08134v1",
    "title": "Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction",
    "authors": [
      "Jarrid Rector-Brooks",
      "Mohsin Hasan",
      "Zhangzhi Peng",
      "Zachary Quinn",
      "Chenghao Liu",
      "Sarthak Mittal",
      "Nouha Dziri",
      "Michael Bronstein",
      "Yoshua Bengio",
      "Pranam Chatterjee",
      "Alexander Tong",
      "Avishek Joey Bose"
    ],
    "abstract": "Generative modeling of discrete data underlies important applications\nspanning text-based agents like ChatGPT to the design of the very building\nblocks of life in protein sequences. However, application domains need to exert\ncontrol over the generated data by steering the generative process - typically\nvia RLHF - to satisfy a specified property, reward, or affinity metric. In this\npaper, we study the problem of steering Masked Diffusion Models (MDMs), a\nrecent class of discrete diffusion models that offer a compelling alternative\nto traditional autoregressive models. We introduce Discrete Denoising Posterior\nPrediction (DDPP), a novel framework that casts the task of steering\npre-trained MDMs as a problem of probabilistic inference by learning to sample\nfrom a target Bayesian posterior. Our DDPP framework leads to a family of three\nnovel objectives that are all simulation-free, and thus scalable while applying\nto general non-differentiable reward functions. Empirically, we instantiate\nDDPP by steering MDMs to perform class-conditional pixel-level image modeling,\nRLHF-based alignment of MDMs using text-based rewards, and finetuning protein\nlanguage models to generate more diverse secondary structures and shorter\nproteins. We substantiate our designs via wet-lab validation, where we observe\ntransient expression of reward-optimized protein sequences.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08134v1",
    "published_date": "2024-10-10 17:18:30 UTC",
    "updated_date": "2024-10-10 17:18:30 UTC"
  },
  {
    "arxiv_id": "2410.08133v1",
    "title": "Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks",
    "authors": [
      "Mathis Pink",
      "Vy A. Vo",
      "Qinyuan Wu",
      "Jianing Mu",
      "Javier S. Turek",
      "Uri Hasson",
      "Kenneth A. Norman",
      "Sebastian Michelmann",
      "Alexander Huth",
      "Mariya Toneva"
    ],
    "abstract": "Current LLM benchmarks focus on evaluating models' memory of facts and\nsemantic relations, primarily assessing semantic aspects of long-term memory.\nHowever, in humans, long-term memory also includes episodic memory, which links\nmemories to their contexts, such as the time and place they occurred. The\nability to contextualize memories is crucial for many cognitive tasks and\neveryday functions. This form of memory has not been evaluated in LLMs with\nexisting benchmarks. To address the gap in evaluating memory in LLMs, we\nintroduce Sequence Order Recall Tasks (SORT), which we adapt from tasks used to\nstudy episodic memory in cognitive psychology. SORT requires LLMs to recall the\ncorrect order of text segments, and provides a general framework that is both\neasily extendable and does not require any additional annotations. We present\nan initial evaluation dataset, Book-SORT, comprising 36k pairs of segments\nextracted from 9 books recently added to the public domain. Based on a human\nexperiment with 155 participants, we show that humans can recall sequence order\nbased on long-term memory of a book. We find that models can perform the task\nwith high accuracy when relevant text is given in-context during the SORT\nevaluation. However, when presented with the book text only during training,\nLLMs' performance on SORT falls short. By allowing to evaluate more aspects of\nmemory, we believe that SORT will aid in the emerging development of\nmemory-augmented models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08133v1",
    "published_date": "2024-10-10 17:17:38 UTC",
    "updated_date": "2024-10-10 17:17:38 UTC"
  },
  {
    "arxiv_id": "2410.09116v1",
    "title": "Optimizing Hard-to-Place Kidney Allocation: A Machine Learning Approach to Center Ranking",
    "authors": [
      "Sean Berry",
      "Berk Gorgulu",
      "Sait Tunc",
      "Mucahit Cevik",
      "Matthew J Ellis"
    ],
    "abstract": "Kidney transplantation is the preferred treatment for end-stage renal\ndisease, yet the scarcity of donors and inefficiencies in allocation systems\ncreate major bottlenecks, resulting in prolonged wait times and alarming\nmortality rates. Despite their severe scarcity, timely and effective\ninterventions to prevent non-utilization of life-saving organs remain\ninadequate. Expedited out-of-sequence placement of hard-to-place kidneys to\ncenters with the highest likelihood of utilizing them has been recommended in\nthe literature as an effective strategy to improve placement success.\nNevertheless, current attempts towards this practice is non-standardized and\nheavily rely on the subjective judgment of the decision-makers. This paper\nproposes a novel data-driven, machine learning-based ranking system for\nallocating hard-to-place kidneys to centers with a higher likelihood of\naccepting and successfully transplanting them. Using the national deceased\ndonor kidney offer and transplant datasets, we construct a unique dataset with\ndonor-, center-, and patient-specific features. We propose a data-driven\nout-of-sequence placement policy that utilizes machine learning models to\npredict the acceptance probability of a given kidney by a set of transplant\ncenters, ranking them accordingly based on their likelihood of acceptance. Our\nexperiments demonstrate that the proposed policy can reduce the average number\nof centers considered before placement by fourfold for all kidneys and tenfold\nfor hard-to-place kidneys. This significant reduction indicates that our method\ncan improve the utilization of hard-to-place kidneys and accelerate their\nacceptance, ultimately reducing patient mortality and the risk of graft\nfailure. Further, we utilize machine learning interpretability tools to provide\ninsights into factors influencing the kidney allocation decisions.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09116v1",
    "published_date": "2024-10-10 17:15:41 UTC",
    "updated_date": "2024-10-10 17:15:41 UTC"
  },
  {
    "arxiv_id": "2410.08126v2",
    "title": "Mars: Situated Inductive Reasoning in an Open-World Environment",
    "authors": [
      "Xiaojuan Tang",
      "Jiaqi Li",
      "Yitao Liang",
      "Song-chun Zhu",
      "Muhan Zhang",
      "Zilong Zheng"
    ],
    "abstract": "Large Language Models (LLMs) trained on massive corpora have shown remarkable\nsuccess in knowledge-intensive tasks. Yet, most of them rely on pre-stored\nknowledge. Inducing new general knowledge from a specific environment and\nperforming reasoning with the acquired knowledge -- \\textit{situated inductive\nreasoning}, is crucial and challenging for machine intelligence. In this paper,\nwe design Mars, an interactive environment devised for situated inductive\nreasoning. It introduces counter-commonsense game mechanisms by modifying\nterrain, survival setting and task dependency while adhering to certain\nprinciples. In Mars, agents need to actively interact with their surroundings,\nderive useful rules and perform decision-making tasks in specific contexts. We\nconduct experiments on various RL-based and LLM-based methods, finding that\nthey all struggle on this challenging situated inductive reasoning benchmark.\nFurthermore, we explore \\textit{Induction from Reflection}, where we instruct\nagents to perform inductive reasoning from history trajectory. The superior\nperformance underscores the importance of inductive reasoning in Mars. Through\nMars, we aim to galvanize advancements in situated inductive reasoning and set\nthe stage for developing the next generation of AI systems that can reason in\nan adaptive and context-sensitive way.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024 Track Datasets and Benchmarks. Project page:\n  https://marscrafter.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.08126v2",
    "published_date": "2024-10-10 17:10:34 UTC",
    "updated_date": "2024-10-31 11:11:18 UTC"
  },
  {
    "arxiv_id": "2410.08121v1",
    "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection",
    "authors": [
      "Moirangthem Tiken Singh",
      "Rabinder Kumar Prasad",
      "Gurumayum Robert Michael",
      "N K Kaphungkui",
      "N. Hemarjit Singh"
    ],
    "abstract": "The digital revolution has significantly impacted financial transactions,\nleading to a notable increase in credit card usage. However, this convenience\ncomes with a trade-off: a substantial rise in fraudulent activities.\nTraditional machine learning methods for fraud detection often struggle to\ncapture the inherent interconnectedness within financial data. This paper\nproposes a novel approach for credit card fraud detection that leverages Graph\nNeural Networks (GNNs) with attention mechanisms applied to heterogeneous graph\nrepresentations of financial data. Unlike homogeneous graphs, heterogeneous\ngraphs capture intricate relationships between various entities in the\nfinancial ecosystem, such as cardholders, merchants, and transactions,\nproviding a richer and more comprehensive data representation for fraud\nanalysis. To address the inherent class imbalance in fraud data, where genuine\ntransactions significantly outnumber fraudulent ones, the proposed approach\nintegrates an autoencoder. This autoencoder, trained on genuine transactions,\nlearns a latent representation and flags deviations during reconstruction as\npotential fraud. This research investigates two key questions: (1) How\neffectively can a GNN with an attention mechanism detect and prevent credit\ncard fraud when applied to a heterogeneous graph? (2) How does the efficacy of\nthe autoencoder with attention approach compare to traditional methods? The\nresults are promising, demonstrating that the proposed model outperforms\nbenchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR\nof 0.89 and an F1-score of 0.81. This research significantly advances fraud\ndetection systems and the overall security of financial transactions by\nleveraging GNNs with attention mechanisms and addressing class imbalance\nthrough an autoencoder.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08121v1",
    "published_date": "2024-10-10 17:05:27 UTC",
    "updated_date": "2024-10-10 17:05:27 UTC"
  },
  {
    "arxiv_id": "2410.08115v2",
    "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System",
    "authors": [
      "Weize Chen",
      "Jiarui Yuan",
      "Chen Qian",
      "Cheng Yang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) show remarkable\npotential in collaborative problem-solving, yet they still face critical\nchallenges: low communication efficiency, poor scalability, and a lack of\neffective parameter-updating optimization methods. We present Optima, a novel\nframework that addresses these issues by significantly enhancing both\ncommunication efficiency and task effectiveness in LLM-based MAS through LLM\ntraining. Optima employs an iterative generate, rank, select, and train\nparadigm with a reward function balancing task performance, token efficiency,\nand communication readability. We explore various RL algorithms, including\nSupervised Fine-Tuning, Direct Preference Optimization, and their hybrid\napproaches, providing insights into their effectiveness-efficiency trade-offs.\nWe integrate Monte Carlo Tree Search-inspired techniques for DPO data\ngeneration, treating conversation turns as tree nodes to explore diverse\ninteraction paths. Evaluated on common multi-agent tasks, including\ninformation-asymmetric question answering and complex reasoning, Optima shows\nconsistent and substantial improvements over single-agent baselines and vanilla\nMAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than\n10\\% tokens on tasks requiring heavy information exchange. Moreover, Optima's\nefficiency gains open new possibilities for leveraging inference-compute more\neffectively, leading to improved inference-time scaling laws. By addressing\nfundamental challenges in LLM-based MAS, Optima shows the potential towards\nscalable, efficient, and effective MAS\n(https://chenweize1998.github.io/optima-project-page).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2410.08115v2",
    "published_date": "2024-10-10 17:00:06 UTC",
    "updated_date": "2025-02-18 12:50:00 UTC"
  },
  {
    "arxiv_id": "2410.08113v1",
    "title": "Robust AI-Generated Text Detection by Restricted Embeddings",
    "authors": [
      "Kristian Kuznetsov",
      "Eduard Tulchinskii",
      "Laida Kushnareva",
      "German Magai",
      "Serguei Barannikov",
      "Sergey Nikolenko",
      "Irina Piontkovskaya"
    ],
    "abstract": "Growing amount and quality of AI-generated texts makes detecting such content\nmore difficult. In most real-world scenarios, the domain (style and topic) of\ngenerated data and the generator model are not known in advance. In this work,\nwe focus on the robustness of classifier-based detectors of AI-generated text,\nnamely their ability to transfer to unseen generators or semantic domains. We\ninvestigate the geometry of the embedding space of Transformer-based text\nencoders and show that clearing out harmful linear subspaces helps to train a\nrobust classifier, ignoring domain-specific spurious features. We investigate\nseveral subspace decomposition and feature selection strategies and achieve\nsignificant improvements over state of the art methods in cross-domain and\ncross-generator transfer. Our best approaches for head-wise and\ncoordinate-based subspace removal increase the mean out-of-distribution (OOD)\nclassification score by up to 9% and 14% in particular setups for RoBERTa and\nBERT embeddings respectively. We release our code and data:\nhttps://github.com/SilverSolver/RobustATD",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08113v1",
    "published_date": "2024-10-10 16:58:42 UTC",
    "updated_date": "2024-10-10 16:58:42 UTC"
  },
  {
    "arxiv_id": "2410.08111v1",
    "title": "Active Fourier Auditor for Estimating Distributional Properties of ML Models",
    "authors": [
      "Ayoub Ajarra",
      "Bishwamittra Ghosh",
      "Debabrota Basu"
    ],
    "abstract": "With the pervasive deployment of Machine Learning (ML) models in real-world\napplications, verifying and auditing properties of ML models have become a\ncentral concern. In this work, we focus on three properties: robustness,\nindividual fairness, and group fairness. We discuss two approaches for auditing\nML model properties: estimation with and without reconstruction of the target\nmodel under audit. Though the first approach is studied in the literature, the\nsecond approach remains unexplored. For this purpose, we develop a new\nframework that quantifies different properties in terms of the Fourier\ncoefficients of the ML model under audit but does not parametrically\nreconstruct it. We propose the Active Fourier Auditor (AFA), which queries\nsample points according to the Fourier coefficients of the ML model, and\nfurther estimates the properties. We derive high probability error bounds on\nAFA's estimates, along with the worst-case lower bounds on the sample\ncomplexity to audit them. Numerically we demonstrate on multiple datasets and\nmodels that AFA is more accurate and sample-efficient to estimate the\nproperties of interest than the baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08111v1",
    "published_date": "2024-10-10 16:57:01 UTC",
    "updated_date": "2024-10-10 16:57:01 UTC"
  },
  {
    "arxiv_id": "2410.08109v3",
    "title": "A Closer Look at Machine Unlearning for Large Language Models",
    "authors": [
      "Xiaojian Yuan",
      "Tianyu Pang",
      "Chao Du",
      "Kejiang Chen",
      "Weiming Zhang",
      "Min Lin"
    ],
    "abstract": "Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08109v3",
    "published_date": "2024-10-10 16:56:05 UTC",
    "updated_date": "2025-03-03 02:45:58 UTC"
  },
  {
    "arxiv_id": "2410.08098v1",
    "title": "A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation",
    "authors": [
      "Aparna Kishore",
      "Swapna Thorve",
      "Madhav Marathe"
    ],
    "abstract": "Residential rooftop solar adoption is considered crucial for reducing carbon\nemissions. The lack of photovoltaic (PV) data at a finer resolution (e.g.,\nhousehold, hourly levels) poses a significant roadblock to informed\ndecision-making. We discuss a novel methodology to generate a highly granular,\nresidential-scale realistic dataset for rooftop solar adoption across the\ncontiguous United States. The data-driven methodology consists of: (i)\nintegrated machine learning models to identify PV adopters, (ii) methods to\naugment the data using explainable AI techniques to glean insights about key\nfeatures and their interactions, and (iii) methods to generate household-level\nhourly solar energy output using an analytical model. The resulting synthetic\ndatasets are validated using real-world data and can serve as a digital twin\nfor modeling downstream tasks. Finally, a policy-based case study utilizing the\ndigital twin for Virginia demonstrated increased rooftop solar adoption with\nthe 30\\% Federal Solar Investment Tax Credit, especially in\nLow-to-Moderate-Income communities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "41 pages including references and supplementary",
    "pdf_url": "http://arxiv.org/pdf/2410.08098v1",
    "published_date": "2024-10-10 16:41:43 UTC",
    "updated_date": "2024-10-10 16:41:43 UTC"
  },
  {
    "arxiv_id": "2410.08256v1",
    "title": "AdaShadow: Responsive Test-time Model Adaptation in Non-stationary Mobile Environments",
    "authors": [
      "Cheng Fang",
      "Sicong Liu",
      "Zimu Zhou",
      "Bin Guo",
      "Jiaqi Tang",
      "Ke Ma",
      "Zhiwen Yu"
    ],
    "abstract": "On-device adapting to continual, unpredictable domain shifts is essential for\nmobile applications like autonomous driving and augmented reality to deliver\nseamless user experiences in evolving environments. Test-time adaptation (TTA)\nemerges as a promising solution by tuning model parameters with unlabeled live\ndata immediately before prediction. However, TTA's unique\nforward-backward-reforward pipeline notably increases the latency over standard\ninference, undermining the responsiveness in time-sensitive mobile\napplications. This paper presents AdaShadow, a responsive test-time adaptation\nframework for non-stationary mobile data distribution and resource dynamics via\nselective updates of adaptation-critical layers. Although the tactic is\nrecognized in generic on-device training, TTA's unsupervised and online context\npresents unique challenges in estimating layer importance and latency, as well\nas scheduling the optimal layer update plan. AdaShadow addresses these\nchallenges with a backpropagation-free assessor to rapidly identify critical\nlayers, a unit-based runtime predictor to account for resource dynamics in\nlatency estimation, and an online scheduler for prompt layer update planning.\nAlso, AdaShadow incorporates a memory I/O-aware computation reuse scheme to\nfurther reduce latency in the reforward pass. Results show that AdaShadow\nachieves the best accuracy-latency balance under continual shifts. At low\nmemory and energy costs, Adashadow provides a 2x to 3.5x speedup (ms-level)\nover state-of-the-art TTA methods with comparable accuracy and a 14.8% to 25.4%\naccuracy boost over efficient supervised methods with similar latency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper is accepted by SenSys 2024. Copyright may be transferred\n  without notice",
    "pdf_url": "http://arxiv.org/pdf/2410.08256v1",
    "published_date": "2024-10-10 16:41:39 UTC",
    "updated_date": "2024-10-10 16:41:39 UTC"
  },
  {
    "arxiv_id": "2410.08094v2",
    "title": "SAKA: An Intelligent Platform for Semi-automated Knowledge Graph Construction and Application",
    "authors": [
      "Hanrong Zhang",
      "Xinyue Wang",
      "Jiabao Pan",
      "Hongwei Wang"
    ],
    "abstract": "Knowledge graph (KG) technology is extensively utilized in many areas, and\nmany companies offer applications based on KG. Nonetheless, most KG platforms\nnecessitate expertise and tremendous time and effort from users to construct KG\nrecords manually, which poses great difficulties for ordinary people.\nAdditionally, audio data is abundant and holds valuable information, but it is\nchallenging to transform it into a KG. What's more, the platforms usually do\nnot leverage the full potential of the KGs constructed by users. In this paper,\nwe propose an intelligent and user-friendly platform for Semi-automated KG\nConstruction and Application (SAKA) to address the aforementioned problems.\nPrimarily, users can semi-automatically construct KGs from structured data of\nnumerous areas by interacting with the platform, based on which multi-versions\nof KG can be stored, viewed, managed, and updated. Moreover, we propose an\nAudio-based KG Information Extraction (AGIE) method to establish KGs from audio\ndata. Lastly, the platform creates a semantic parsing-based knowledge base\nquestion answering (KBQA) system based on the user-created KGs. We prove the\nfeasibility of the semi-automatic KG construction method on the SAKA platform.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated Version",
    "pdf_url": "http://arxiv.org/pdf/2410.08094v2",
    "published_date": "2024-10-10 16:37:02 UTC",
    "updated_date": "2024-12-15 09:20:03 UTC"
  },
  {
    "arxiv_id": "2410.08085v3",
    "title": "Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering",
    "authors": [
      "Yuan Sui",
      "Yufei He",
      "Zifeng Ding",
      "Bryan Hooi"
    ],
    "abstract": "Recent works integrating Knowledge Graphs (KGs) have led to promising\nimprovements in enhancing the reasoning accuracy of Large Language Models\n(LLMs). However, current benchmarks focus mainly on closed-ended tasks, leaving\na gap in the assessment of more complex real-world scenarios. This gap has also\nobscured the evaluation of KGs' potential to mitigate the problem of\nhallucination in LLMs. To fill the gap, we introduce OKGQA, a new benchmark\nspecifically designed to assess LLMs enhanced with KGs under open-ended,\nreal-world question answering scenarios. OKGQA is designed to closely reflect\nthe complexities of practical applications using questions from different\ntypes, and incorporates specific metrics to measure both hallucination ratio\nand the enhancement in reasoning capabilities. To consider the scenario in\nwhich KGs may have varying levels of mistakes, we propose another benchmark\nvariant OKGQA-P to assess model performance when the semantics and structure of\nKGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore\nwhether KGs can make LLMs more trustworthy in an open-ended setting, and (2)\nconduct a comparative analysis to shed light on method design. We believe that\nthis study can facilitate a more complete performance comparison and encourage\ncontinuous improvement in integrating KGs with LLMs to reduce hallucination.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08085v3",
    "published_date": "2024-10-10 16:29:21 UTC",
    "updated_date": "2025-02-19 08:25:48 UTC"
  },
  {
    "arxiv_id": "2410.08081v3",
    "title": "Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning",
    "authors": [
      "Shuhe Wang",
      "Guoyin Wang",
      "Yizhong Wang",
      "Jiwei Li",
      "Eduard Hovy",
      "Chen Guo"
    ],
    "abstract": "Packing, initially utilized in the pre-training phase, is an optimization\ntechnique designed to maximize hardware resource efficiency by combining\ndifferent training sequences to fit the model's maximum input length. Although\nit has demonstrated effectiveness during pre-training, there remains a lack of\ncomprehensive analysis for the supervised fine-tuning (SFT) stage on the\nfollowing points: (1) whether packing can effectively enhance training\nefficiency while maintaining performance, (2) the suitable size of the model\nand dataset for fine-tuning with the packing method, and (3) whether packing\nunrelated or related training samples might cause the model to either\nexcessively disregard or over-rely on the context.\n  In this paper, we perform extensive comparisons between SFT methods using\npadding and packing, covering SFT datasets ranging from 69K to 1.2M and models\nfrom 8B to 70B. This provides the first comprehensive analysis of the\nadvantages and limitations of packing versus padding, as well as practical\nconsiderations for implementing packing in various training scenarios. Our\nanalysis covers various benchmarks, including knowledge, reasoning, and coding,\nas well as GPT-based evaluations, time efficiency, and other fine-tuning\nparameters. We also open-source our code for fine-tuning and evaluation and\nprovide checkpoints fine-tuned on datasets of different sizes, aiming to\nadvance future research on packing methods. Code is available at:\nhttps://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08081v3",
    "published_date": "2024-10-10 16:25:34 UTC",
    "updated_date": "2024-11-06 07:31:28 UTC"
  },
  {
    "arxiv_id": "2410.08255v1",
    "title": "Generalization from Starvation: Hints of Universality in LLM Knowledge Graph Learning",
    "authors": [
      "David D. Baek",
      "Yuxiao Li",
      "Max Tegmark"
    ],
    "abstract": "Motivated by interpretability and reliability, we investigate how neural\nnetworks represent knowledge during graph learning, We find hints of\nuniversality, where equivalent representations are learned across a range of\nmodel sizes (from $10^2$ to $10^9$ parameters) and contexts (MLP toy models,\nLLM in-context learning and LLM training). We show that these attractor\nrepresentations optimize generalization to unseen examples by exploiting\nproperties of knowledge graph relations (e.g. symmetry and meta-transitivity).\nWe find experimental support for such universality by showing that LLMs and\nsimpler neural networks can be stitched, i.e., by stitching the first part of\none model to the last part of another, mediated only by an affine or almost\naffine transformation. We hypothesize that this dynamic toward simplicity and\ngeneralization is driven by \"intelligence from starvation\": where overfitting\nis minimized by pressure to minimize the use of resources that are either\nscarce or competed for against other tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08255v1",
    "published_date": "2024-10-10 16:23:42 UTC",
    "updated_date": "2024-10-10 16:23:42 UTC"
  },
  {
    "arxiv_id": "2410.08069v2",
    "title": "Unlearning-based Neural Interpretations",
    "authors": [
      "Ching Lam Choi",
      "Alexandre Duplessis",
      "Serge Belongie"
    ],
    "abstract": "Gradient-based interpretations often require an anchor point of comparison to\navoid saturation in computing feature importance. We show that current\nbaselines defined using static functions--constant mapping, averaging or\nblurring--inject harmful colour, texture or frequency assumptions that deviate\nfrom model behaviour. This leads to accumulation of irregular gradients,\nresulting in attribution maps that are biased, fragile and manipulable.\nDeparting from the static approach, we propose UNI to compute an (un)learnable,\ndebiased and adaptive baseline by perturbing the input towards an unlearning\ndirection of steepest ascent. Our method discovers reliable baselines and\nsucceeds in erasing salient features, which in turn locally smooths the\nhigh-curvature decision boundaries. Our analyses point to unlearning as a\npromising avenue for generating faithful, efficient and robust interpretations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08069v2",
    "published_date": "2024-10-10 16:02:39 UTC",
    "updated_date": "2025-02-10 22:59:07 UTC"
  },
  {
    "arxiv_id": "2410.08068v1",
    "title": "Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models",
    "authors": [
      "Wenting Tan",
      "Dongxiao Chen",
      "Jieting Xue",
      "Zihao Wang",
      "Taijie Chen"
    ],
    "abstract": "Large Language Models (LLMs) exhibit impressive performance across various\ndomains but still struggle with arithmetic reasoning tasks. Recent work shows\nthe effectiveness of prompt design methods in enhancing reasoning capabilities.\nHowever, these approaches overlook crucial requirements for prior knowledge of\nspecific concepts, theorems, and tricks to tackle most arithmetic reasoning\nproblems successfully. To address this issue, we propose a novel and effective\nTeaching-Inspired Integrated Framework, which emulates the instructional\nprocess of a teacher guiding students. This method equips LLMs with essential\nconcepts, relevant theorems, and similar problems with analogous solution\napproaches, facilitating the enhancement of reasoning abilities. Additionally,\nwe introduce two new Chinese datasets, MathMC and MathToF, both with detailed\nexplanations and answers. Experiments are conducted on nine benchmarks which\ndemonstrates that our approach improves the reasoning accuracy of LLMs. With\nGPT-4 and our framework, we achieve new state-of-the-art performance on four\nmath benchmarks (AddSub, SVAMP, Math23K and AQuA) with accuracies of 98.2%\n(+3.3%), 93.9% (+0.2%), 94.3% (+7.2%) and 81.1% (+1.2%). Our data and code are\navailable at https://github.com/SallyTan13/Teaching-Inspired-Prompting.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08068v1",
    "published_date": "2024-10-10 16:02:36 UTC",
    "updated_date": "2024-10-10 16:02:36 UTC"
  },
  {
    "arxiv_id": "2410.08067v6",
    "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs",
    "authors": [
      "Shenao Zhang",
      "Zhihan Liu",
      "Boyi Liu",
      "Yufeng Zhang",
      "Yingxiang Yang",
      "Yongfei Liu",
      "Liyu Chen",
      "Tao Sun",
      "Zhaoran Wang"
    ],
    "abstract": "Preference alignment in Large Language Models (LLMs) has significantly\nimproved their ability to adhere to human instructions and intentions. However,\nexisting direct alignment algorithms primarily focus on relative preferences\nand often overlook the qualitative aspects of responses, despite having access\nto preference data that includes reward scores from judge models during AI\nfeedback. Striving to maximize the implicit reward gap between the chosen and\nthe slightly inferior rejected responses can cause overfitting and unnecessary\nunlearning of the high-quality rejected responses. The unawareness of the\nreward scores also drives the LLM to indiscriminately favor the low-quality\nchosen responses and fail to generalize to optimal responses that are sparse in\ndata. To overcome these shortcomings, our study introduces reward-conditioned\nLLM policies that discern and learn from the entire spectrum of response\nquality within the dataset, helping extrapolate to more optimal regions. We\npropose an effective yet simple data relabeling method that conditions the\npreference pairs on quality scores to construct a reward-augmented dataset. The\nexperiments across various benchmarks and diverse models demonstrate that our\napproach consistently boosts DPO by a considerable margin. Through\ncomprehensive ablation studies, we demonstrate that our method not only\nmaximizes the utility of preference data but also mitigates the issue of\nunlearning, demonstrating its broad effectiveness beyond mere data expansion.\nOur code is available at\nhttps://github.com/shenao-zhang/reward-augmented-preference.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08067v6",
    "published_date": "2024-10-10 16:01:51 UTC",
    "updated_date": "2025-05-11 22:01:18 UTC"
  },
  {
    "arxiv_id": "2410.08060v1",
    "title": "Optimal Transportation by Orthogonal Coupling Dynamics",
    "authors": [
      "Mohsen Sadr",
      "Peyman Mohajerin Esfehani",
      "Hossein Gorji"
    ],
    "abstract": "Many numerical algorithms and learning tasks rest on solution of the\nMonge-Kantorovich problem and corresponding Wasserstein distances. While the\nnatural approach is to treat the problem as an infinite-dimensional linear\nprogramming, such a methodology severely limits the computational performance\ndue to the polynomial scaling with respect to the sample size along with\nintensive memory requirements. We propose a novel alternative framework to\naddress the Monge-Kantorovich problem based on a projection type gradient\ndescent scheme. The micro-dynamics is built on the notion of the conditional\nexpectation, where the connection with the opinion dynamics is explored and\nleveraged to build compact numerical schemes. We demonstrate that the devised\ndynamics recovers random maps with favourable computational performance. Along\nwith the theoretical insight, the provided dynamics paves the way for\ninnovative approaches to construct numerical schemes for computing optimal\ntransport maps as well as Wasserstein distances.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08060v1",
    "published_date": "2024-10-10 15:53:48 UTC",
    "updated_date": "2024-10-10 15:53:48 UTC"
  },
  {
    "arxiv_id": "2410.08058v1",
    "title": "Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions",
    "authors": [
      "Inderjeet Nair",
      "Jiaye Tan",
      "Xiaotian Su",
      "Anne Gere",
      "Xu Wang",
      "Lu Wang"
    ],
    "abstract": "Providing feedback is widely recognized as crucial for refining students'\nwriting skills. Recent advances in language models (LMs) have made it possible\nto automatically generate feedback that is actionable and well-aligned with\nhuman-specified attributes. However, it remains unclear whether the feedback\ngenerated by these models is truly effective in enhancing the quality of\nstudent revisions. Moreover, prompting LMs with a precise set of instructions\nto generate feedback is nontrivial due to the lack of consensus regarding the\nspecific attributes that can lead to improved revising performance. To address\nthese challenges, we propose PROF that PROduces Feedback via learning from LM\nsimulated student revisions. PROF aims to iteratively optimize the feedback\ngenerator by directly maximizing the effectiveness of students' overall\nrevising performance as simulated by LMs. Focusing on an economic essay\nassignment, we empirically test the efficacy of PROF and observe that our\napproach not only surpasses a variety of baseline methods in effectiveness of\nimproving students' writing but also demonstrates enhanced pedagogical values,\neven though it was not explicitly trained for this aspect.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08058v1",
    "published_date": "2024-10-10 15:52:48 UTC",
    "updated_date": "2024-10-10 15:52:48 UTC"
  },
  {
    "arxiv_id": "2410.19748v1",
    "title": "C^2DA: Contrastive and Context-aware Domain Adaptive Semantic Segmentation",
    "authors": [
      "Md. Al-Masrur Khan",
      "Zheng Chen",
      "Lantao Liu"
    ],
    "abstract": "Unsupervised domain adaptive semantic segmentation (UDA-SS) aims to train a\nmodel on the source domain data (e.g., synthetic) and adapt the model to\npredict target domain data (e.g., real-world) without accessing target\nannotation data. Most existing UDA-SS methods only focus on inter-domain\nknowledge to mitigate the data-shift problem. However, learning the inherent\nstructure of the images and exploring the intrinsic pixel distribution of both\ndomains are ignored, which prevents the UDA-SS methods from producing\nsatisfactory performance like supervised learning. Moreover, incorporating\ncontextual knowledge is also often overlooked. Considering these issues, in\nthis work, we propose a UDA-SS framework that learns both intra-domain and\ncontext-aware knowledge. To learn the intra-domain knowledge, we incorporate\ncontrastive loss in both domains, which pulls pixels of similar classes\ntogether and pushes the rest away, facilitating intra-image-pixel-wise\ncorrelations. To learn context-aware knowledge, we modify the mixing technique\nby leveraging contextual dependency among the classes. Moreover, we adapt the\nMask Image Modeling (MIM) technique to properly use context clues for robust\nvisual recognition, using limited information about the masked images.\nComprehensive experiments validate that our proposed method improves the\nstate-of-the-art UDA-SS methods by a margin of 0.51% mIoU and 0.54% mIoU in the\nadaptation of GTA-V->Cityscapes and Synthia->Cityscapes, respectively. We\nopen-source our C2DA code. Code link: github.com/Masrur02/C-Squared-DA",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has 16 pages, 6 figures, 5 tables. It has been accepted\n  for publication at the International Symposium of Robotics Research (ISRR),\n  Long Beach, California, USA, 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19748v1",
    "published_date": "2024-10-10 15:51:35 UTC",
    "updated_date": "2024-10-10 15:51:35 UTC"
  },
  {
    "arxiv_id": "2410.08049v1",
    "title": "Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations",
    "authors": [
      "Yiyuan Zhang",
      "Xiaohan Ding",
      "Xiangyu Yue"
    ],
    "abstract": "This paper proposes the paradigm of large convolutional kernels in designing\nmodern Convolutional Neural Networks (ConvNets). We establish that employing a\nfew large kernels, instead of stacking multiple smaller ones, can be a superior\ndesign strategy. Our work introduces a set of architecture design guidelines\nfor large-kernel ConvNets that optimize their efficiency and performance. We\npropose the UniRepLKNet architecture, which offers systematical architecture\ndesign principles specifically crafted for large-kernel ConvNets, emphasizing\ntheir unique ability to capture extensive spatial information without deep\nlayer stacking. This results in a model that not only surpasses its\npredecessors with an ImageNet accuracy of 88.0%, an ADE20K mIoU of 55.6%, and a\nCOCO box AP of 56.4% but also demonstrates impressive scalability and\nperformance on various modalities such as time-series forecasting, audio, point\ncloud, and video recognition. These results indicate the universal modeling\nabilities of large-kernel ConvNets with faster inference speed compared with\nvision transformers. Our findings reveal that large-kernel ConvNets possess\nlarger effective receptive fields and a higher shape bias, moving away from the\ntexture bias typical of smaller-kernel CNNs. All codes and models are publicly\navailable at https://github.com/AILab-CVC/UniRepLKNet promoting further\nresearch and development in the community.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This is the journal version of arXiv:2203.06717 and arXiv:2311.15599",
    "pdf_url": "http://arxiv.org/pdf/2410.08049v1",
    "published_date": "2024-10-10 15:43:55 UTC",
    "updated_date": "2024-10-10 15:43:55 UTC"
  },
  {
    "arxiv_id": "2410.08041v1",
    "title": "On the Convergence of (Stochastic) Gradient Descent for Kolmogorov--Arnold Networks",
    "authors": [
      "Yihang Gao",
      "Vincent Y. F. Tan"
    ],
    "abstract": "Kolmogorov--Arnold Networks (KANs), a recently proposed neural network\narchitecture, have gained significant attention in the deep learning community,\ndue to their potential as a viable alternative to multi-layer perceptrons\n(MLPs) and their broad applicability to various scientific tasks. Empirical\ninvestigations demonstrate that KANs optimized via stochastic gradient descent\n(SGD) are capable of achieving near-zero training loss in various machine\nlearning (e.g., regression, classification, and time series forecasting, etc.)\nand scientific tasks (e.g., solving partial differential equations). In this\npaper, we provide a theoretical explanation for the empirical success by\nconducting a rigorous convergence analysis of gradient descent (GD) and SGD for\ntwo-layer KANs in solving both regression and physics-informed tasks. For\nregression problems, we establish using the neural tangent kernel perspective\nthat GD achieves global linear convergence of the objective function when the\nhidden dimension of KANs is sufficiently large. We further extend these results\nto SGD, demonstrating a similar global convergence in expectation.\nAdditionally, we analyze the global convergence of GD and SGD for\nphysics-informed KANs, which unveils additional challenges due to the more\ncomplex loss structure. This is the first work establishing the global\nconvergence guarantees for GD and SGD applied to optimize KANs and\nphysics-informed KANs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08041v1",
    "published_date": "2024-10-10 15:34:10 UTC",
    "updated_date": "2024-10-10 15:34:10 UTC"
  },
  {
    "arxiv_id": "2410.08032v2",
    "title": "Strategic Classification With Externalities",
    "authors": [
      "Safwan Hossain",
      "Evi Micha",
      "Yiling Chen",
      "Ariel Procaccia"
    ],
    "abstract": "We propose a new variant of the strategic classification problem: a principal\nreveals a classifier, and $n$ agents report their (possibly manipulated)\nfeatures to be classified. Motivated by real-world applications, our model\ncrucially allows the manipulation of one agent to affect another; that is, it\nexplicitly captures inter-agent externalities. The principal-agent interactions\nare formally modeled as a Stackelberg game, with the resulting agent\nmanipulation dynamics captured as a simultaneous game. We show that under\ncertain assumptions, the pure Nash Equilibrium of this agent manipulation game\nis unique and can be efficiently computed. Leveraging this result, PAC learning\nguarantees are established for the learner: informally, we show that it is\npossible to learn classifiers that minimize loss on the distribution, even when\na random number of agents are manipulating their way to a pure Nash\nEquilibrium. We also comment on the optimization of such classifiers through\ngradient-based approaches. This work sets the theoretical foundations for a\nmore realistic analysis of classifiers that are robust against multiple\nstrategic actors interacting in a common environment.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08032v2",
    "published_date": "2024-10-10 15:28:04 UTC",
    "updated_date": "2025-02-26 19:58:22 UTC"
  },
  {
    "arxiv_id": "2410.08027v1",
    "title": "Private Language Models via Truncated Laplacian Mechanism",
    "authors": [
      "Tianhao Huang",
      "Tao Yang",
      "Ivan Habernal",
      "Lijie Hu",
      "Di Wang"
    ],
    "abstract": "Deep learning models for NLP tasks are prone to variants of privacy attacks.\nTo prevent privacy leakage, researchers have investigated word-level\nperturbations, relying on the formal guarantees of differential privacy (DP) in\nthe embedding space. However, many existing approaches either achieve\nunsatisfactory performance in the high privacy regime when using the Laplacian\nor Gaussian mechanism, or resort to weaker relaxations of DP that are inferior\nto the canonical DP in terms of privacy strength. This raises the question of\nwhether a new method for private word embedding can be designed to overcome\nthese limitations. In this paper, we propose a novel private embedding method\ncalled the high dimensional truncated Laplacian mechanism. Specifically, we\nintroduce a non-trivial extension of the truncated Laplacian mechanism, which\nwas previously only investigated in one-dimensional space cases. Theoretically,\nwe show that our method has a lower variance compared to the previous private\nword embedding methods. To further validate its effectiveness, we conduct\ncomprehensive experiments on private embedding and downstream tasks using three\ndatasets. Remarkably, even in the high privacy regime, our approach only incurs\na slight decrease in utility compared to the non-private scenario.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024, Main Track",
    "pdf_url": "http://arxiv.org/pdf/2410.08027v1",
    "published_date": "2024-10-10 15:25:02 UTC",
    "updated_date": "2024-10-10 15:25:02 UTC"
  },
  {
    "arxiv_id": "2410.12850v1",
    "title": "RecurFormer: Not All Transformer Heads Need Self-Attention",
    "authors": [
      "Ruiqing Yan",
      "Linghan Zheng",
      "Xingbo Du",
      "Han Zou",
      "Yufeng Guo",
      "Jianfei Yang"
    ],
    "abstract": "Transformer-based large language models (LLMs) excel in modeling complex\nlanguage patterns but face significant computational costs during inference,\nespecially with long inputs due to the attention mechanism's memory overhead.\nWe observe that certain attention heads exhibit a distribution where the\nattention weights concentrate on tokens near the query token, termed as recency\naware, which focuses on local and short-range dependencies. Leveraging this\ninsight, we propose RecurFormer, a novel architecture that replaces these\nattention heads with linear recurrent neural networks (RNNs), specifically the\nMamba architecture. This replacement reduces the cache size without evicting\ntokens, thus maintaining generation quality. RecurFormer retains the ability to\nmodel long-range dependencies through the remaining attention heads and allows\nfor reusing pre-trained Transformer-based LLMs weights with continual training.\nExperiments demonstrate that RecurFormer matches the original model's\nperformance while significantly enhancing inference efficiency. Our approach\nprovides a practical solution to the computational challenges of\nTransformer-based LLMs inference, making it highly attractive for tasks\ninvolving long inputs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12850v1",
    "published_date": "2024-10-10 15:24:12 UTC",
    "updated_date": "2024-10-10 15:24:12 UTC"
  },
  {
    "arxiv_id": "2410.08025v3",
    "title": "The Computational Complexity of Circuit Discovery for Inner Interpretability",
    "authors": [
      "Federico Adolfi",
      "Martina G. Vilas",
      "Todd Wareham"
    ],
    "abstract": "Many proposed applications of neural networks in machine learning,\ncognitive/brain science, and society hinge on the feasibility of inner\ninterpretability via circuit discovery. This calls for empirical and\ntheoretical explorations of viable algorithmic options. Despite advances in the\ndesign and testing of heuristics, there are concerns about their scalability\nand faithfulness at a time when we lack understanding of the complexity\nproperties of the problems they are deployed to solve. To address this, we\nstudy circuit discovery with classical and parameterized computational\ncomplexity theory: (1) we describe a conceptual scaffolding to reason about\ncircuit finding queries in terms of affordances for description, explanation,\nprediction and control; (2) we formalize a comprehensive set of queries for\nmechanistic explanation, and propose a formal framework for their analysis; (3)\nwe use it to settle the complexity of many query variants and relaxations of\npractical interest on multi-layer perceptrons. Our findings reveal a\nchallenging complexity landscape. Many queries are intractable, remain\nfixed-parameter intractable relative to model/circuit features, and\ninapproximable under additive, multiplicative, and probabilistic approximation\nschemes. To navigate this landscape, we prove there exist transformations to\ntackle some of these hard problems with better-understood heuristics, and prove\nthe tractability or fixed-parameter tractability of more modest queries which\nretain useful affordances. This framework allows us to understand the scope and\nlimits of interpretability queries, explore viable options, and compare their\nresource demands on existing and future architectures.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2410.08025v3",
    "published_date": "2024-10-10 15:22:48 UTC",
    "updated_date": "2025-04-01 14:16:47 UTC"
  },
  {
    "arxiv_id": "2410.08024v1",
    "title": "Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling",
    "authors": [
      "Alessio Fallani",
      "Ramil Nugmanov",
      "Jose Arjona-Medina",
      "Jörg Kurt Wegner",
      "Alexandre Tkatchenko",
      "Kostiantyn Chernichenko"
    ],
    "abstract": "We evaluate the impact of pretraining Graph Transformer architectures on\natom-level quantum-mechanical features for the modeling of absorption,\ndistribution, metabolism, excretion, and toxicity (ADMET) properties of\ndrug-like compounds. We compare this pretraining strategy with two others: one\nbased on molecular quantum properties (specifically the HOMO-LUMO gap) and one\nusing a self-supervised atom masking technique. After fine-tuning on\nTherapeutic Data Commons ADMET datasets, we evaluate the performance\nimprovement in the different models observing that models pretrained with\natomic quantum mechanical properties produce in general better results. We then\nanalyse the latent representations and observe that the supervised strategies\npreserve the pretraining information after finetuning and that different\npretrainings produce different trends in latent expressivity across layers.\nFurthermore, we find that models pretrained on atomic quantum mechanical\nproperties capture more low-frequency laplacian eigenmodes of the input graph\nvia the attention weights and produce better representations of atomic\nenvironments within the molecule. Application of the analysis to a much larger\nnon-public dataset for microsomal clearance illustrates generalizability of the\nstudied indicators. In this case the performances of the models are in\naccordance with the representation analysis and highlight, especially for the\ncase of masking pretraining and atom-level quantum property pretraining, how\nmodel types with similar performance on public benchmarks can have different\nperformances on large scale pharmaceutical data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08024v1",
    "published_date": "2024-10-10 15:20:30 UTC",
    "updated_date": "2024-10-10 15:20:30 UTC"
  },
  {
    "arxiv_id": "2410.08023v1",
    "title": "GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder",
    "authors": [
      "Junzhou Chen",
      "Xuan Wen",
      "Ronghui Zhang",
      "Bingtao Ren",
      "Di Wu",
      "Zhigang Xu",
      "Danwei Wang"
    ],
    "abstract": "Unsupervised Domain Adaptation (UDA) aims to adapt a model trained on a\nlabeled source domain to an unlabeled target domain by addressing the domain\nshift. Existing Unsupervised Domain Adaptation (UDA) methods often fall short\nin fully leveraging contextual information from the target domain, leading to\nsuboptimal decision boundary separation during source and target domain\nalignment. To address this, we introduce GrabDAE, an innovative UDA framework\ndesigned to tackle domain shift in visual classification tasks. GrabDAE\nincorporates two key innovations: the Grab-Mask module, which blurs background\ninformation in target domain images, enabling the model to focus on essential,\ndomain-relevant features through contrastive learning; and the Denoising\nAuto-Encoder (DAE), which enhances feature alignment by reconstructing features\nand filtering noise, ensuring a more robust adaptation to the target domain.\nThese components empower GrabDAE to effectively handle unlabeled target domain\ndata, significantly improving both classification accuracy and robustness.\nExtensive experiments on benchmark datasets, including VisDA-2017, Office-Home,\nand Office31, demonstrate that GrabDAE consistently surpasses state-of-the-art\nUDA methods, setting new performance benchmarks. By tackling UDA's critical\nchallenges with its novel feature masking and denoising approach, GrabDAE\noffers both significant theoretical and practical advancements in domain\nadaptation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08023v1",
    "published_date": "2024-10-10 15:19:57 UTC",
    "updated_date": "2024-10-10 15:19:57 UTC"
  },
  {
    "arxiv_id": "2410.08022v2",
    "title": "Probabilistic Satisfaction of Temporal Logic Constraints in Reinforcement Learning via Adaptive Policy-Switching",
    "authors": [
      "Xiaoshan Lin",
      "Sadık Bera Yüksel",
      "Yasin Yazıcıoğlu",
      "Derya Aksaray"
    ],
    "abstract": "Constrained Reinforcement Learning (CRL) is a subset of machine learning that\nintroduces constraints into the traditional reinforcement learning (RL)\nframework. Unlike conventional RL which aims solely to maximize cumulative\nrewards, CRL incorporates additional constraints that represent specific\nmission requirements or limitations that the agent must comply with during the\nlearning process. In this paper, we address a type of CRL problem where an\nagent aims to learn the optimal policy to maximize reward while ensuring a\ndesired level of temporal logic constraint satisfaction throughout the learning\nprocess. We propose a novel framework that relies on switching between pure\nlearning (reward maximization) and constraint satisfaction. This framework\nestimates the probability of constraint satisfaction based on earlier trials\nand properly adjusts the probability of switching between learning and\nconstraint satisfaction policies. We theoretically validate the correctness of\nthe proposed algorithm and demonstrate its performance through comprehensive\nsimulations.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08022v2",
    "published_date": "2024-10-10 15:19:45 UTC",
    "updated_date": "2024-11-27 22:08:00 UTC"
  },
  {
    "arxiv_id": "2410.08020v3",
    "title": "Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs",
    "authors": [
      "Jonas Hübotter",
      "Sascha Bongni",
      "Ido Hakimi",
      "Andreas Krause"
    ],
    "abstract": "Recent efforts in fine-tuning language models often rely on automatic data\nselection, commonly using Nearest Neighbors retrieval from large datasets.\nHowever, we theoretically show that this approach tends to select redundant\ndata, limiting its effectiveness or even hurting performance. To address this,\nwe introduce SIFT, a data selection algorithm designed to reduce uncertainty\nabout the model's response given a prompt, which unifies ideas from retrieval\nand active learning. Whereas Nearest Neighbor retrieval typically fails in the\npresence of information duplication, SIFT accounts for information duplication\nand optimizes the overall information gain of the selected examples. We focus\nour evaluations on fine-tuning at test-time for prompt-specific language\nmodeling on the Pile dataset, and show that SIFT consistently outperforms\nNearest Neighbor retrieval, with minimal computational overhead. Moreover, we\nshow that our uncertainty estimates can predict the performance gain of\ntest-time fine-tuning, and use this to develop an adaptive algorithm that\ninvests test-time compute proportional to realized performance gains. We\nprovide the $\\texttt{activeft}$ (Active Fine-Tuning) library which can be used\nas a drop-in replacement for Nearest Neighbor retrieval.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted in ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08020v3",
    "published_date": "2024-10-10 15:17:49 UTC",
    "updated_date": "2025-02-08 19:39:09 UTC"
  },
  {
    "arxiv_id": "2410.18991v2",
    "title": "TRIAGE: Ethical Benchmarking of AI Models Through Mass Casualty Simulations",
    "authors": [
      "Nathalie Maria Kirch",
      "Konstantin Hebenstreit",
      "Matthias Samwald"
    ],
    "abstract": "We present the TRIAGE Benchmark, a novel machine ethics (ME) benchmark that\ntests LLMs' ability to make ethical decisions during mass casualty incidents.\nIt uses real-world ethical dilemmas with clear solutions designed by medical\nprofessionals, offering a more realistic alternative to annotation-based\nbenchmarks. TRIAGE incorporates various prompting styles to evaluate model\nperformance across different contexts. Most models consistently outperformed\nrandom guessing, suggesting LLMs may support decision-making in triage\nscenarios. Neutral or factual scenario formulations led to the best\nperformance, unlike other ME benchmarks where ethical reminders improved\noutcomes. Adversarial prompts reduced performance but not to random guessing\nlevels. Open-source models made more morally serious errors, and general\ncapability overall predicted better performance.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.18991v2",
    "published_date": "2024-10-10 15:06:12 UTC",
    "updated_date": "2024-11-04 12:38:38 UTC"
  },
  {
    "arxiv_id": "2410.08001v3",
    "title": "Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation",
    "authors": [
      "Qingwen Bu",
      "Hongyang Li",
      "Li Chen",
      "Jisong Cai",
      "Jia Zeng",
      "Heming Cui",
      "Maoqing Yao",
      "Yu Qiao"
    ],
    "abstract": "The increasing demand for versatile robotic systems to operate in diverse and\ndynamic environments has emphasized the importance of a generalist policy,\nwhich leverages a large cross-embodiment data corpus to facilitate broad\nadaptability and high-level reasoning. However, the generalist would struggle\nwith inefficient inference and cost-expensive training. The specialist policy,\ninstead, is curated for specific domain data and excels at task-level precision\nwith efficiency. Yet, it lacks the generalization capacity for a wide range of\napplications. Inspired by these observations, we introduce RoboDual, a\nsynergistic dual-system that supplements the merits of both generalist and\nspecialist policy. A diffusion transformer-based specialist is devised for\nmulti-step action rollouts, exquisitely conditioned on the high-level task\nunderstanding and discretized action output of a vision-language-action (VLA)\nbased generalist. Compared to OpenVLA, RoboDual achieves 26.7% improvement in\nreal-world setting and 12% gain on CALVIN by introducing a specialist policy\nwith merely 20M trainable parameters. It maintains strong performance with 5%\nof demonstration data only, and enables a 3.8 times higher control frequency in\nreal-world deployment. Code would be made publicly available. Our project page\nis hosted at: https://opendrivelab.com/RoboDual/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Project page: https://opendrivelab.com/RoboDual/",
    "pdf_url": "http://arxiv.org/pdf/2410.08001v3",
    "published_date": "2024-10-10 14:57:51 UTC",
    "updated_date": "2025-02-06 12:37:15 UTC"
  },
  {
    "arxiv_id": "2410.11878v1",
    "title": "Neural Metamorphosis",
    "authors": [
      "Xingyi Yang",
      "Xinchao Wang"
    ],
    "abstract": "This paper introduces a new learning paradigm termed Neural Metamorphosis\n(NeuMeta), which aims to build self-morphable neural networks. Contrary to\ncrafting separate models for different architectures or sizes, NeuMeta directly\nlearns the continuous weight manifold of neural networks. Once trained, we can\nsample weights for any-sized network directly from the manifold, even for\npreviously unseen configurations, without retraining. To achieve this ambitious\ngoal, NeuMeta trains neural implicit functions as hypernetworks. They accept\ncoordinates within the model space as input, and generate corresponding weight\nvalues on the manifold. In other words, the implicit function is learned in a\nway, that the predicted weights is well-performed across various models sizes.\nIn training those models, we notice that, the final performance closely relates\non smoothness of the learned manifold. In pursuit of enhancing this smoothness,\nwe employ two strategies. First, we permute weight matrices to achieve\nintra-model smoothness, by solving the Shortest Hamiltonian Path problem.\nBesides, we add a noise on the input coordinates when training the implicit\nfunction, ensuring models with various sizes shows consistent outputs. As such,\nNeuMeta shows promising results in synthesizing parameters for various network\nconfigurations. Our extensive tests in image classification, semantic\nsegmentation, and image generation reveal that NeuMeta sustains full-size\nperformance even at a 75% compression rate.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "in ECCV2024, https://adamdad.github.io/neumeta/",
    "pdf_url": "http://arxiv.org/pdf/2410.11878v1",
    "published_date": "2024-10-10 14:49:58 UTC",
    "updated_date": "2024-10-10 14:49:58 UTC"
  },
  {
    "arxiv_id": "2410.07991v5",
    "title": "Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets",
    "authors": [
      "Tommaso Giorgi",
      "Lorenzo Cima",
      "Tiziano Fagni",
      "Marco Avvenuti",
      "Stefano Cresci"
    ],
    "abstract": "The rise of online platforms exacerbated the spread of hate speech, demanding\nscalable and effective detection. However, the accuracy of hate speech\ndetection systems heavily relies on human-labeled data, which is inherently\nsusceptible to biases. While previous work has examined the issue, the\ninterplay between the characteristics of the annotator and those of the target\nof the hate are still unexplored. We fill this gap by leveraging an extensive\ndataset with rich socio-demographic information of both annotators and targets,\nuncovering how human biases manifest in relation to the target's attributes.\nOur analysis surfaces the presence of widespread biases, which we\nquantitatively describe and characterize based on their intensity and\nprevalence, revealing marked differences. Furthermore, we compare human biases\nwith those exhibited by persona-based LLMs. Our findings indicate that while\npersona-based LLMs do exhibit biases, these differ significantly from those of\nhuman annotators. Overall, our work offers new and nuanced results on human\nbiases in hate speech annotations, as well as fresh insights into the design of\nAI-driven hate speech detection systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07991v5",
    "published_date": "2024-10-10 14:48:57 UTC",
    "updated_date": "2025-04-09 15:05:27 UTC"
  },
  {
    "arxiv_id": "2410.07981v2",
    "title": "MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning",
    "authors": [
      "Andrei Manolache",
      "Dragos Tantaru",
      "Mathias Niepert"
    ],
    "abstract": "In this work, we propose a simple transformer-based baseline for multimodal\nmolecular representation learning, integrating three distinct modalities:\nSMILES strings, 2D graph representations, and 3D conformers of molecules. A key\naspect of our approach is the aggregation of 3D conformers, allowing the model\nto account for the fact that molecules can adopt multiple conformations-an\nimportant factor for accurate molecular representation. The tokens for each\nmodality are extracted using modality-specific encoders: a transformer for\nSMILES strings, a message-passing neural network for 2D graphs, and an\nequivariant neural network for 3D conformers. The flexibility and modularity of\nthis framework enable easy adaptation and replacement of these encoders, making\nthe model highly versatile for different molecular tasks. The extracted tokens\nare then combined into a unified multimodal sequence, which is processed by a\ndownstream transformer for prediction tasks. To efficiently scale our model for\nlarge multimodal datasets, we utilize Flash Attention 2 and bfloat16 precision.\nDespite its simplicity, our approach achieves state-of-the-art results across\nmultiple datasets, demonstrating its effectiveness as a strong baseline for\nmultimodal molecular representation learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Machine Learning for Structural Biology Workshop, NeurIPS 2024 v2:\n  Added optimizer references",
    "pdf_url": "http://arxiv.org/pdf/2410.07981v2",
    "published_date": "2024-10-10 14:36:58 UTC",
    "updated_date": "2024-10-24 08:34:50 UTC"
  },
  {
    "arxiv_id": "2410.07980v3",
    "title": "D-Wave's Nonlinear-Program Hybrid Solver: Description and Performance Analysis",
    "authors": [
      "Eneko Osaba",
      "Pablo Miranda-Rodriguez"
    ],
    "abstract": "The development of advanced quantum-classical algorithms is among the most\nprominent strategies in quantum computing. Numerous hybrid solvers have been\nintroduced recently. Many of these methods are created ad hoc to address\nspecific use cases. However, several well-established schemes are frequently\nutilized to address optimization problems. In this context, D-Wave launched the\nHybrid Solver Service in 2020, offering a portfolio of methods designed to\naccelerate time-to-solution for users aiming to optimize performance and\noperational processes. Recently, a new technique has been added to this\nportfolio: the Nonlinear-Program Hybrid Solver. This paper describes this\nsolver and evaluates its performance through a benchmark of 45 instances across\nthree combinatorial optimization problems: the Traveling Salesman Problem, the\nKnapsack Problem, and the Maximum Cut Problem. To facilitate the use of this\nrelatively unexplored solver, we provide details of the implementation used to\nsolve these three optimization problems.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.ET",
    "comment": "13 pages, 9 figures and 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.07980v3",
    "published_date": "2024-10-10 14:36:24 UTC",
    "updated_date": "2024-12-04 12:14:56 UTC"
  },
  {
    "arxiv_id": "2410.07974v4",
    "title": "Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling",
    "authors": [
      "Yuanqi Du",
      "Michael Plainer",
      "Rob Brekelmans",
      "Chenru Duan",
      "Frank Noé",
      "Carla P. Gomes",
      "Alán Aspuru-Guzik",
      "Kirill Neklyudov"
    ],
    "abstract": "Rare event sampling in dynamical systems is a fundamental problem arising in\nthe natural sciences, which poses significant computational challenges due to\nan exponentially large space of trajectories. For settings where the dynamical\nsystem of interest follows a Brownian motion with known drift, the question of\nconditioning the process to reach a given endpoint or desired rare event is\ndefinitively answered by Doob's h-transform. However, the naive estimation of\nthis transform is infeasible, as it requires simulating sufficiently many\nforward trajectories to estimate rare event probabilities. In this work, we\npropose a variational formulation of Doob's h-transform as an optimization\nproblem over trajectories between a given initial point and the desired ending\npoint. To solve this optimization, we propose a simulation-free training\nobjective with a model parameterization that imposes the desired boundary\nconditions by design. Our approach significantly reduces the search space over\ntrajectories and avoids expensive trajectory simulation and inefficient\nimportance sampling estimators which are required in existing methods. We\ndemonstrate the ability of our method to find feasible transition paths on\nreal-world molecular simulation and protein folding tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.bio-ph",
      "physics.chem-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as Spotlight at Conference on Neural Information Processing\n  Systems (NeurIPS 2024); Alanine dipeptide results updated after fixing\n  unphysical parameterization and energy computation",
    "pdf_url": "http://arxiv.org/pdf/2410.07974v4",
    "published_date": "2024-10-10 14:32:16 UTC",
    "updated_date": "2024-12-10 01:57:00 UTC"
  },
  {
    "arxiv_id": "2410.07966v1",
    "title": "Neural Reasoning Networks: Efficient Interpretable Neural Networks With Automatic Textual Explanations",
    "authors": [
      "Stephen Carrow",
      "Kyle Harper Erwin",
      "Olga Vilenskaia",
      "Parikshit Ram",
      "Tim Klinger",
      "Naweed Aghmad Khan",
      "Ndivhuwo Makondo",
      "Alexander Gray"
    ],
    "abstract": "Recent advances in machine learning have led to a surge in adoption of neural\nnetworks for various tasks, but lack of interpretability remains an issue for\nmany others in which an understanding of the features influencing the\nprediction is necessary to ensure fairness, safety, and legal compliance. In\nthis paper we consider one class of such tasks, tabular dataset classification,\nand propose a novel neuro-symbolic architecture, Neural Reasoning Networks\n(NRN), that is scalable and generates logically sound textual explanations for\nits predictions. NRNs are connected layers of logical neurons which implement a\nform of real valued logic. A training algorithm (R-NRN) learns the weights of\nthe network as usual using gradient descent optimization with backprop, but\nalso learns the network structure itself using a bandit-based optimization.\nBoth are implemented in an extension to PyTorch\n(https://github.com/IBM/torchlogic) that takes full advantage of GPU scaling\nand batched training. Evaluation on a diverse set of 22 open-source datasets\nfor tabular classification demonstrates performance (measured by ROC AUC) which\nimproves over multi-layer perceptron (MLP) and is statistically similar to\nother state-of-the-art approaches such as Random Forest, XGBoost and Gradient\nBoosted Trees, while offering 43% faster training and a more than 2 orders of\nmagnitude reduction in the number of parameters required, on average.\nFurthermore, R-NRN explanations are shorter than the compared approaches while\nproducing more accurate feature importance scores.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07966v1",
    "published_date": "2024-10-10 14:27:12 UTC",
    "updated_date": "2024-10-10 14:27:12 UTC"
  },
  {
    "arxiv_id": "2410.07962v1",
    "title": "Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation",
    "authors": [
      "Tomas Bueno Momcilovic",
      "Beat Buesser",
      "Giulio Zizzo",
      "Mark Purcell",
      "Dian Balta"
    ],
    "abstract": "Despite the impressive adaptability of large language models (LLMs),\nchallenges remain in ensuring their security, transparency, and\ninterpretability. Given their susceptibility to adversarial attacks, LLMs need\nto be defended with an evolving combination of adversarial training and\nguardrails. However, managing the implicit and heterogeneous knowledge for\ncontinuously assuring robustness is difficult. We introduce a novel approach\nfor assurance of the adversarial robustness of LLMs based on formal\nargumentation. Using ontologies for formalization, we structure\nstate-of-the-art attacks and defenses, facilitating the creation of a\nhuman-readable assurance case, and a machine-readable representation. We\ndemonstrate its application with examples in English language and code\ntranslation tasks, and provide implications for theory and practice, by\ntargeting engineers, data scientists, users, and auditors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in xAI 2024, late-breaking track",
    "pdf_url": "http://arxiv.org/pdf/2410.07962v1",
    "published_date": "2024-10-10 14:24:43 UTC",
    "updated_date": "2024-10-10 14:24:43 UTC"
  },
  {
    "arxiv_id": "2410.07959v2",
    "title": "COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act",
    "authors": [
      "Philipp Guldimann",
      "Alexander Spiridonov",
      "Robin Staab",
      "Nikola Jovanović",
      "Mark Vero",
      "Velko Vechev",
      "Anna-Maria Gueorguieva",
      "Mislav Balunović",
      "Nikola Konstantinov",
      "Pavol Bielik",
      "Petar Tsankov",
      "Martin Vechev"
    ],
    "abstract": "The EU's Artificial Intelligence Act (AI Act) is a significant step towards\nresponsible AI development, but lacks clear technical interpretation, making it\ndifficult to assess models' compliance. This work presents COMPL-AI, a\ncomprehensive framework consisting of (i) the first technical interpretation of\nthe EU AI Act, translating its broad regulatory requirements into measurable\ntechnical requirements, with the focus on large language models (LLMs), and\n(ii) an open-source Act-centered benchmarking suite, based on thorough\nsurveying and implementation of state-of-the-art LLM benchmarks. By evaluating\n12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings in\nexisting models and benchmarks, particularly in areas like robustness, safety,\ndiversity, and fairness. This work highlights the need for a shift in focus\ntowards these aspects, encouraging balanced development of LLMs and more\ncomprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for the\nfirst time demonstrates the possibilities and difficulties of bringing the\nAct's obligations to a more concrete, technical level. As such, our work can\nserve as a useful first step towards having actionable recommendations for\nmodel providers, and contributes to ongoing efforts of the EU to enable\napplication of the Act, such as the drafting of the GPAI Code of Practice.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07959v2",
    "published_date": "2024-10-10 14:23:51 UTC",
    "updated_date": "2025-02-03 14:51:44 UTC"
  },
  {
    "arxiv_id": "2410.07928v3",
    "title": "The Function-Representation Model of Computation",
    "authors": [
      "Alfredo Ibias",
      "Hector Antona",
      "Guillem Ramirez-Miranda",
      "Enric Guinovart",
      "Eduard Alarcon"
    ],
    "abstract": "Cognitive Architectures are the forefront of the research into developing an\nartificial cognition. However, they approach the problem from a separated\nmemory and program model of computation. This model of computation poses a\nfundamental problem: the knowledge retrieval heuristic. In this paper we\npropose to solve this problem by using a novel model of computation, one where\nmemory and program are merged: the Function-Representation. This model of\ncomputation involves defining a generic Function-Representation and\ninstantiating multiple instances of it. In this paper we explore the potential\nof this novel model of computation through mathematical definitions and proofs.\nWe also explore the kind of functions a Function-Representation can implement,\nand present different ways to organise multiple instances of a\nFunction-Representation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07928v3",
    "published_date": "2024-10-10 13:54:35 UTC",
    "updated_date": "2024-11-06 17:45:39 UTC"
  },
  {
    "arxiv_id": "2410.07923v1",
    "title": "Deep Learning for Generalised Planning with Background Knowledge",
    "authors": [
      "Dillon Z. Chen",
      "Rostislav Horčík",
      "Gustav Šír"
    ],
    "abstract": "Automated planning is a form of declarative problem solving which has\nrecently drawn attention from the machine learning (ML) community. ML has been\napplied to planning either as a way to test `reasoning capabilities' of\narchitectures, or more pragmatically in an attempt to scale up solvers with\nlearned domain knowledge. In practice, planning problems are easy to solve but\nhard to optimise. However, ML approaches still struggle to solve many problems\nthat are often easy for both humans and classical planners. In this paper, we\nthus propose a new ML approach that allows users to specify background\nknowledge (BK) through Datalog rules to guide both the learning and planning\nprocesses in an integrated fashion. By incorporating BK, our approach bypasses\nthe need to relearn how to solve problems from scratch and instead focuses the\nlearning on plan quality optimisation. Experiments with BK demonstrate that our\nmethod successfully scales and learns to plan efficiently with high quality\nsolutions from small training data generated in under 5 seconds.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07923v1",
    "published_date": "2024-10-10 13:49:05 UTC",
    "updated_date": "2024-10-10 13:49:05 UTC"
  },
  {
    "arxiv_id": "2410.07921v2",
    "title": "Boosting Hierarchical Reinforcement Learning with Meta-Learning for Complex Task Adaptation",
    "authors": [
      "Arash Khajooeinejad",
      "Fatemeh Sadat Masoumi",
      "Masoumeh Chapariniya"
    ],
    "abstract": "Hierarchical Reinforcement Learning (HRL) is well-suitedd for solving complex\ntasks by breaking them down into structured policies. However, HRL agents often\nstruggle with efficient exploration and quick adaptation. To overcome these\nlimitations, we propose integrating meta-learning into HRL to enable agents to\nlearn and adapt hierarchical policies more effectively. Our method leverages\nmeta-learning to facilitate rapid task adaptation using prior experience, while\nintrinsic motivation mechanisms drive efficient exploration by rewarding the\ndiscovery of novel states. Specifically, our agent employs a high-level policy\nto choose among multiple low-level policies within custom-designed grid\nenvironments. By incorporating gradient-based meta-learning with differentiable\ninner-loop updates, we optimize performance across a curriculum of\nprogressively challenging tasks. Experimental results highlight that our\nmetalearning-enhanced hierarchical agent significantly outperforms standard HRL\napproaches lacking meta-learning and intrinsic motivation. The agent\ndemonstrates faster learning, greater cumulative rewards, and higher success\nrates in complex grid-based scenarios. These Findings underscore the\neffectiveness of combining meta-learning, curriculum learning, and intrinsic\nmotivation to enhance the capability of HRL agents in tackling complex tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07921v2",
    "published_date": "2024-10-10 13:47:37 UTC",
    "updated_date": "2025-03-14 18:52:03 UTC"
  },
  {
    "arxiv_id": "2410.11877v1",
    "title": "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts",
    "authors": [
      "Hung-Fu Chang",
      "Tong Li"
    ],
    "abstract": "Creativity involves not only generating new ideas from scratch but also\nredefining existing concepts and synthesizing previous insights. Among various\ntechniques developed to foster creative thinking, brainstorming is widely used.\nWith recent advancements in Large Language Models (LLMs), tools like ChatGPT\nhave significantly impacted various fields by using prompts to facilitate\ncomplex tasks. While current research primarily focuses on generating accurate\nresponses, there is a need to explore how prompt engineering can enhance\ncreativity, particularly in brainstorming. Therefore, this study addresses this\ngap by proposing a framework called GPS, which employs goals, prompts, and\nstrategies to guide designers to systematically work with an LLM tool for\nimproving the creativity of ideas generated during brainstorming. Additionally,\nwe adapted the Torrance Tests of Creative Thinking (TTCT) for measuring the\ncreativity of the ideas generated by AI. Our framework, tested through a design\nexample and a case study, demonstrates its effectiveness in stimulating\ncreativity and its seamless LLM tool integration into design practices. The\nresults indicate that our framework can benefit brainstorming sessions with LLM\ntools, enhancing both the creativity and usefulness of generated ideas.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.m"
    ],
    "primary_category": "cs.HC",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11877v1",
    "published_date": "2024-10-10 13:39:27 UTC",
    "updated_date": "2024-10-10 13:39:27 UTC"
  },
  {
    "arxiv_id": "2410.07908v4",
    "title": "ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation",
    "authors": [
      "Léo Machado",
      "Hélène Philippe",
      "Élodie Ferreres",
      "Julien Khlaut",
      "Julie Dupuis",
      "Korentin Le Floch",
      "Denis Habip Gatenyo",
      "Pascal Roux",
      "Jules Grégory",
      "Maxime Ronot",
      "Corentin Dancette",
      "Tom Boeken",
      "Daniel Tordjman",
      "Pierre Manceron",
      "Paul Hérent"
    ],
    "abstract": "Carcinogenesis is a proteiform phenomenon, with tumors emerging in various\nlocations and displaying complex, diverse shapes. At the crucial intersection\nof research and clinical practice, it demands precise and flexible assessment.\nHowever, current biomarkers, such as RECIST 1.1's long and short axis\nmeasurements, fall short of capturing this complexity, offering an approximate\nestimate of tumor burden and a simplistic representation of a more intricate\nprocess. Additionally, existing supervised AI models face challenges in\naddressing the variability in tumor presentations, limiting their clinical\nutility. These limitations arise from the scarcity of annotations and the\nmodels' focus on narrowly defined tasks.\n  To address these challenges, we developed ONCOPILOT, an interactive\nradiological foundation model trained on approximately 7,500 CT scans covering\nthe whole body, from both normal anatomy and a wide range of oncological cases.\nONCOPILOT performs 3D tumor segmentation using visual prompts like point-click\nand bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and\nachieving radiologist-level accuracy in RECIST 1.1 measurements. The key\nadvantage of this foundation model is its ability to surpass state-of-the-art\nperformance while keeping the radiologist in the loop, a capability that\nprevious models could not achieve. When radiologists interactively refine the\nsegmentations, accuracy improves further. ONCOPILOT also accelerates\nmeasurement processes and reduces inter-reader variability, facilitating\nvolumetric analysis and unlocking new biomarkers for deeper insights.\n  This AI assistant is expected to enhance the precision of RECIST 1.1\nmeasurements, unlock the potential of volumetric biomarkers, and improve\npatient stratification and clinical care, while seamlessly integrating into the\nradiological workflow.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07908v4",
    "published_date": "2024-10-10 13:36:49 UTC",
    "updated_date": "2024-11-19 19:03:07 UTC"
  },
  {
    "arxiv_id": "2410.07896v1",
    "title": "Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines",
    "authors": [
      "Junyu Lai",
      "Jiahe Xu",
      "Yao Yang",
      "Yunpeng Huang",
      "Chun Cao",
      "Jingwei Xu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of natural language processing and reasoning tasks. However, their\nperformance in the foundational domain of arithmetic remains unsatisfactory.\nWhen dealing with arithmetic tasks, LLMs often memorize specific examples\nrather than learning the underlying computational logic, limiting their ability\nto generalize to new problems. In this paper, we propose a Composable\nArithmetic Execution Framework (CAEF) that enables LLMs to learn to execute\nstep-by-step computations by emulating Turing Machines, thereby gaining a\ngenuine understanding of computational logic. Moreover, the proposed framework\nis highly scalable, allowing composing learned operators to significantly\nreduce the difficulty of learning complex operators. In our evaluation, CAEF\nachieves nearly 100% accuracy across seven common mathematical operations on\nthe LLaMA 3.1-8B model, effectively supporting computations involving operands\nwith up to 100 digits, a level where GPT-4o falls short noticeably in some\nsettings.",
    "categories": [
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.07896v1",
    "published_date": "2024-10-10 13:23:49 UTC",
    "updated_date": "2024-10-10 13:23:49 UTC"
  },
  {
    "arxiv_id": "2410.08250v1",
    "title": "Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis",
    "authors": [
      "Tuan Nguyen",
      "Corinne Fredouille",
      "Alain Ghio",
      "Mathieu Balaguer",
      "Virginie Woisard"
    ],
    "abstract": "With the rise of SSL and ASR technologies, the Wav2Vec2 ASR-based model has\nbeen fine-tuned for automated speech disorder quality assessment tasks,\nyielding impressive results and setting a new baseline for Head and Neck Cancer\nspeech contexts. This demonstrates that the ASR dimension from Wav2Vec2 closely\naligns with assessment dimensions. Despite its effectiveness, this system\nremains a black box with no clear interpretation of the connection between the\nmodel ASR dimension and clinical assessments. This paper presents the first\nanalysis of this baseline model for speech quality assessment, focusing on\nintelligibility and severity tasks. We conduct a layer-wise analysis to\nidentify key layers and compare different SSL and ASR Wav2Vec2 models based on\npre-trained data. Additionally, post-hoc XAI methods, including Canonical\nCorrelation Analysis (CCA) and visualization techniques, are used to track\nmodel evolution and visualize embeddings for enhanced interpretability.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at the Spoken Language Technology (SLT) Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08250v1",
    "published_date": "2024-10-10 13:12:17 UTC",
    "updated_date": "2024-10-10 13:12:17 UTC"
  },
  {
    "arxiv_id": "2410.07869v3",
    "title": "Benchmarking Agentic Workflow Generation",
    "authors": [
      "Shuofei Qiao",
      "Runnan Fang",
      "Zhisong Qiu",
      "Xiaobin Wang",
      "Ningyu Zhang",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Huajun Chen"
    ],
    "abstract": "Large Language Models (LLMs), with their exceptional ability to handle a wide\nrange of tasks, have driven significant advancements in tackling reasoning and\nplanning tasks, wherein decomposing complex problems into executable workflows\nis a crucial step in this process. Existing workflow evaluation frameworks\neither focus solely on holistic performance or suffer from limitations such as\nrestricted scenario coverage, simplistic workflow structures, and lax\nevaluation standards. To this end, we introduce WorfBench, a unified workflow\ngeneration benchmark with multi-faceted scenarios and intricate graph workflow\nstructures. Additionally, we present WorfEval, a systemic evaluation protocol\nutilizing subsequence and subgraph matching algorithms to accurately quantify\nthe LLM agent's workflow generation capabilities. Through comprehensive\nevaluations across different types of LLMs, we discover distinct gaps between\nthe sequence planning capabilities and graph planning capabilities of LLM\nagents, with even GPT-4 exhibiting a gap of around 15%. We also train two\nopen-source models and evaluate their generalization abilities on held-out\ntasks. Furthermore, we observe that the generated workflows can enhance\ndownstream tasks, enabling them to achieve superior performance with less time\nduring inference. Code and dataset are available at\nhttps://github.com/zjunlp/WorfBench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.07869v3",
    "published_date": "2024-10-10 12:41:19 UTC",
    "updated_date": "2025-02-23 15:16:14 UTC"
  },
  {
    "arxiv_id": "2410.07867v1",
    "title": "The Sets of Power",
    "authors": [
      "Joao Marques-Silva",
      "Carlos Mencía",
      "Raúl Mencía"
    ],
    "abstract": "Measures of voting power have been the subject of extensive research since\nthe mid 1940s. More recently, similar measures of relative importance have been\nstudied in other domains that include inconsistent knowledge bases, intensity\nof attacks in argumentation, different problems in the analysis of database\nmanagement, and explainability. This paper demonstrates that all these examples\nare instantiations of computing measures of importance for a rather more\ngeneral problem domain. The paper then shows that the best-known measures of\nimportance can be computed for any reference set whenever one is given a\nmonotonically increasing predicate that partitions the subsets of that\nreference set. As a consequence, the paper also proves that measures of\nimportance can be devised in several domains, for some of which such measures\nhave not yet been studied nor proposed. Furthermore, the paper highlights\nseveral research directions related with computing measures of importance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07867v1",
    "published_date": "2024-10-10 12:35:50 UTC",
    "updated_date": "2024-10-10 12:35:50 UTC"
  },
  {
    "arxiv_id": "2410.07866v3",
    "title": "System 2 Reasoning via Generality and Adaptation",
    "authors": [
      "Sejin Kim",
      "Sundong Kim"
    ],
    "abstract": "While significant progress has been made in task-specific applications,\ncurrent models struggle with deep reasoning, generality, and adaptation -- key\ncomponents of System 2 reasoning that are crucial for achieving Artificial\nGeneral Intelligence (AGI). Despite the promise of approaches such as program\nsynthesis, language models, and transformers, these methods often fail to\ngeneralize beyond their training data and to adapt to novel tasks, limiting\ntheir ability to perform human-like reasoning. This paper explores the\nlimitations of existing approaches in achieving advanced System 2 reasoning and\nhighlights the importance of generality and adaptation for AGI. Moreover, we\npropose four key research directions to address these gaps: (1) learning human\nintentions from action sequences, (2) combining symbolic and neural models, (3)\nmeta-learning for unfamiliar environments, and (4) reinforcement learning to\nreason multi-step. Through these directions, we aim to advance the ability to\ngeneralize and adapt, bringing computational models closer to the reasoning\ncapabilities required for AGI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS 2024 Workshop on System 2 Reasoning at Scale",
    "pdf_url": "http://arxiv.org/pdf/2410.07866v3",
    "published_date": "2024-10-10 12:34:25 UTC",
    "updated_date": "2024-12-09 12:14:28 UTC"
  },
  {
    "arxiv_id": "2410.07864v2",
    "title": "RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation",
    "authors": [
      "Songming Liu",
      "Lingxuan Wu",
      "Bangguo Li",
      "Hengkai Tan",
      "Huayu Chen",
      "Zhengyi Wang",
      "Ke Xu",
      "Hang Su",
      "Jun Zhu"
    ],
    "abstract": "Bimanual manipulation is essential in robotics, yet developing foundation\nmodels is extremely challenging due to the inherent complexity of coordinating\ntwo robot arms (leading to multi-modal action distributions) and the scarcity\nof training data. In this paper, we present the Robotics Diffusion Transformer\n(RDT), a pioneering diffusion foundation model for bimanual manipulation. RDT\nbuilds on diffusion models to effectively represent multi-modality, with\ninnovative designs of a scalable Transformer to deal with the heterogeneity of\nmulti-modal inputs and to capture the nonlinearity and high frequency of\nrobotic data. To address data scarcity, we further introduce a Physically\nInterpretable Unified Action Space, which can unify the action representations\nof various robots while preserving the physical meanings of original actions,\nfacilitating learning transferrable physical knowledge. With these designs, we\nmanaged to pre-train RDT on the largest collection of multi-robot datasets to\ndate and scaled it up to 1.2B parameters, which is the largest diffusion-based\nfoundation model for robotic manipulation. We finally fine-tuned RDT on a\nself-created multi-task bimanual dataset with over 6K+ episodes to refine its\nmanipulation capabilities. Experiments on real robots demonstrate that RDT\nsignificantly outperforms existing methods. It exhibits zero-shot\ngeneralization to unseen objects and scenes, understands and follows language\ninstructions, learns new skills with just 1~5 demonstrations, and effectively\nhandles complex, dexterous tasks. We refer to\nhttps://rdt-robotics.github.io/rdt-robotics/ for the code and videos.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2410.07864v2",
    "published_date": "2024-10-10 12:33:46 UTC",
    "updated_date": "2025-03-01 08:57:15 UTC"
  },
  {
    "arxiv_id": "2410.07863v2",
    "title": "Learning to Balance Altruism and Self-interest Based on Empathy in Mixed-Motive Games",
    "authors": [
      "Fanqi Kong",
      "Yizhe Huang",
      "Song-Chun Zhu",
      "Siyuan Qi",
      "Xue Feng"
    ],
    "abstract": "Real-world multi-agent scenarios often involve mixed motives, demanding\naltruistic agents capable of self-protection against potential exploitation.\nHowever, existing approaches often struggle to achieve both objectives. In this\npaper, based on that empathic responses are modulated by inferred social\nrelationships between agents, we propose LASE Learning to balance Altruism and\nSelf-interest based on Empathy), a distributed multi-agent reinforcement\nlearning algorithm that fosters altruistic cooperation through gifting while\navoiding exploitation by other agents in mixed-motive games. LASE allocates a\nportion of its rewards to co-players as gifts, with this allocation adapting\ndynamically based on the social relationship -- a metric evaluating the\nfriendliness of co-players estimated by counterfactual reasoning. In\nparticular, social relationship measures each co-player by comparing the\nestimated $Q$-function of current joint action to a counterfactual baseline\nwhich marginalizes the co-player's action, with its action distribution\ninferred by a perspective-taking module. Comprehensive experiments are\nperformed in spatially and temporally extended mixed-motive games,\ndemonstrating LASE's ability to promote group collaboration without\ncompromising fairness and its capacity to adapt policies to various types of\ninteractive co-players.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07863v2",
    "published_date": "2024-10-10 12:30:56 UTC",
    "updated_date": "2025-01-18 06:45:01 UTC"
  },
  {
    "arxiv_id": "2410.07858v1",
    "title": "From Logits to Hierarchies: Hierarchical Clustering made Simple",
    "authors": [
      "Emanuele Palumbo",
      "Moritz Vandenhirtz",
      "Alain Ryser",
      "Imant Daunhawer",
      "Julia E. Vogt"
    ],
    "abstract": "The structure of many real-world datasets is intrinsically hierarchical,\nmaking the modeling of such hierarchies a critical objective in both\nunsupervised and supervised machine learning. Recently, novel approaches for\nhierarchical clustering with deep architectures have been proposed. In this\nwork, we take a critical perspective on this line of research and demonstrate\nthat many approaches exhibit major limitations when applied to realistic\ndatasets, partly due to their high computational complexity. In particular, we\nshow that a lightweight procedure implemented on top of pre-trained\nnon-hierarchical clustering models outperforms models designed specifically for\nhierarchical clustering. Our proposed approach is computationally efficient and\napplicable to any pre-trained clustering model that outputs logits, without\nrequiring any fine-tuning. To highlight the generality of our findings, we\nillustrate how our method can also be applied in a supervised setup, recovering\nmeaningful hierarchies from a pre-trained ImageNet classifier.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07858v1",
    "published_date": "2024-10-10 12:27:45 UTC",
    "updated_date": "2024-10-10 12:27:45 UTC"
  },
  {
    "arxiv_id": "2410.07857v1",
    "title": "SNN-PAR: Energy Efficient Pedestrian Attribute Recognition via Spiking Neural Networks",
    "authors": [
      "Haiyang Wang",
      "Qian Zhu",
      "Mowen She",
      "Yabo Li",
      "Haoyu Song",
      "Minghe Xu",
      "Xiao Wang"
    ],
    "abstract": "Artificial neural network based Pedestrian Attribute Recognition (PAR) has\nbeen widely studied in recent years, despite many progresses, however, the\nenergy consumption is still high. To address this issue, in this paper, we\npropose a Spiking Neural Network (SNN) based framework for energy-efficient\nattribute recognition. Specifically, we first adopt a spiking tokenizer module\nto transform the given pedestrian image into spiking feature representations.\nThen, the output will be fed into the spiking Transformer backbone networks for\nenergy-efficient feature extraction. We feed the enhanced spiking features into\na set of feed-forward networks for pedestrian attribute recognition. In\naddition to the widely used binary cross-entropy loss function, we also exploit\nknowledge distillation from the artificial neural network to the spiking\nTransformer network for more accurate attribute recognition. Extensive\nexperiments on three widely used PAR benchmark datasets fully validated the\neffectiveness of our proposed SNN-PAR framework. The source code of this paper\nis released on \\url{https://github.com/Event-AHU/OpenPAR}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07857v1",
    "published_date": "2024-10-10 12:26:06 UTC",
    "updated_date": "2024-10-10 12:26:06 UTC"
  },
  {
    "arxiv_id": "2410.08249v2",
    "title": "Federated Graph Learning for Cross-Domain Recommendation",
    "authors": [
      "Ziqi Yang",
      "Zhaopeng Peng",
      "Zihui Wang",
      "Jianzhong Qi",
      "Chaochao Chen",
      "Weike Pan",
      "Chenglu Wen",
      "Cheng Wang",
      "Xiaoliang Fan"
    ],
    "abstract": "Cross-domain recommendation (CDR) offers a promising solution to the data\nsparsity problem by enabling knowledge transfer across source and target\ndomains. However, many recent CDR models overlook crucial issues such as\nprivacy as well as the risk of negative transfer (which negatively impact model\nperformance), especially in multi-domain settings. To address these challenges,\nwe propose FedGCDR, a novel federated graph learning framework that securely\nand effectively leverages positive knowledge from multiple source domains.\nFirst, we design a positive knowledge transfer module that ensures privacy\nduring inter-domain knowledge transmission. This module employs differential\nprivacy-based knowledge extraction combined with a feature mapping mechanism,\ntransforming source domain embeddings from federated graph attention networks\ninto reliable domain knowledge. Second, we design a knowledge activation module\nto filter out potential harmful or conflicting knowledge from source domains,\naddressing the issues of negative transfer. This module enhances target domain\ntraining by expanding the graph of the target domain to generate reliable\ndomain attentions and fine-tunes the target model for improved negative\nknowledge filtering and more accurate predictions. We conduct extensive\nexperiments on 16 popular domains of the Amazon dataset, demonstrating that\nFedGCDR significantly outperforms state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS'24",
    "pdf_url": "http://arxiv.org/pdf/2410.08249v2",
    "published_date": "2024-10-10 12:19:51 UTC",
    "updated_date": "2024-11-04 02:50:41 UTC"
  },
  {
    "arxiv_id": "2410.09114v2",
    "title": "Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities",
    "authors": [
      "Andrey Anurin",
      "Jonathan Ng",
      "Kibo Schaffer",
      "Jason Schreiber",
      "Esben Kran"
    ],
    "abstract": "LLM agents have the potential to revolutionize defensive cyber operations,\nbut their offensive capabilities are not yet fully understood. To prepare for\nemerging threats, model developers and governments are evaluating the cyber\ncapabilities of foundation models. However, these assessments often lack\ntransparency and a comprehensive focus on offensive capabilities. In response,\nwe introduce the Catastrophic Cyber Capabilities Benchmark (3CB), a novel\nframework designed to rigorously assess the real-world offensive capabilities\nof LLM agents. Our evaluation of modern LLMs on 3CB reveals that frontier\nmodels, such as GPT-4o and Claude 3.5 Sonnet, can perform offensive tasks such\nas reconnaissance and exploitation across domains ranging from binary analysis\nto web technologies. Conversely, smaller open-source models exhibit limited\noffensive capabilities. Our software solution and the corresponding benchmark\nprovides a critical tool to reduce the gap between rapidly improving\ncapabilities and robustness of cyber offense evaluations, aiding in the safer\ndeployment and regulation of these powerful technologies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CR",
    "comment": "https://cybercapabilities.org/",
    "pdf_url": "http://arxiv.org/pdf/2410.09114v2",
    "published_date": "2024-10-10 12:06:48 UTC",
    "updated_date": "2024-11-02 09:35:35 UTC"
  },
  {
    "arxiv_id": "2410.07838v3",
    "title": "Minority-Focused Text-to-Image Generation via Prompt Optimization",
    "authors": [
      "Soobin Um",
      "Jong Chul Ye"
    ],
    "abstract": "We investigate the generation of minority samples using pretrained\ntext-to-image (T2I) latent diffusion models. Minority instances, in the context\nof T2I generation, can be defined as ones living on low-density regions of\ntext-conditional data distributions. They are valuable for various applications\nof modern T2I generators, such as data augmentation and creative AI.\nUnfortunately, existing pretrained T2I diffusion models primarily focus on\nhigh-density regions, largely due to the influence of guided samplers (like\nCFG) that are essential for high-quality generation. To address this, we\npresent a novel framework to counter the high-density-focus of T2I diffusion\nmodels. Specifically, we first develop an online prompt optimization framework\nthat encourages emergence of desired properties during inference while\npreserving semantic contents of user-provided prompts. We subsequently tailor\nthis generic prompt optimizer into a specialized solver that promotes\ngeneration of minority features by incorporating a carefully-crafted likelihood\nobjective. Extensive experiments conducted across various types of T2I models\ndemonstrate that our approach significantly enhances the capability to produce\nhigh-quality minority instances compared to existing samplers. Code is\navailable at https://github.com/soobin-um/MinorityPrompt.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 (Oral), 21 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07838v3",
    "published_date": "2024-10-10 11:56:09 UTC",
    "updated_date": "2025-04-04 10:37:36 UTC"
  },
  {
    "arxiv_id": "2410.19746v2",
    "title": "Metamizer: a versatile neural optimizer for fast and accurate physics simulations",
    "authors": [
      "Nils Wandel",
      "Stefan Schulz",
      "Reinhard Klein"
    ],
    "abstract": "Efficient physics simulations are essential for numerous applications,\nranging from realistic cloth animations or smoke effects in video games, to\nanalyzing pollutant dispersion in environmental sciences, to calculating\nvehicle drag coefficients in engineering applications. Unfortunately,\nanalytical solutions to the underlying physical equations are rarely available,\nand numerical solutions require high computational resources. Latest\ndevelopments in the field of physics-based Deep Learning have led to promising\nefficiency improvements but still suffer from limited generalization\ncapabilities and low accuracy compared to numerical solvers.\n  In this work, we introduce Metamizer, a novel neural optimizer that\niteratively solves a wide range of physical systems with high accuracy by\nminimizing a physics-based loss function. To this end, our approach leverages a\nscale-invariant architecture that enhances gradient descent updates to\naccelerate convergence. Since the neural network itself acts as an optimizer,\ntraining this neural optimizer falls into the category of meta-optimization\napproaches.\n  We demonstrate that Metamizer achieves unprecedented accuracy for deep\nlearning based approaches - sometimes approaching machine precision - across\nmultiple PDEs after training on the Laplace, advection-diffusion and\nincompressible Navier-Stokes equation as well as on cloth simulations.\nRemarkably, the model also generalizes to PDEs that were not covered during\ntraining such as the Poisson, wave and Burgers equation.\n  Our results suggest that Metamizer could have a profound impact on future\nnumerical solvers, paving the way for fast and accurate neural physics\nsimulations without the need for retraining.",
    "categories": [
      "physics.comp-ph",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "to be published at International Conference on Learning\n  Representations (ICLR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.19746v2",
    "published_date": "2024-10-10 11:54:31 UTC",
    "updated_date": "2025-04-20 19:42:42 UTC"
  },
  {
    "arxiv_id": "2410.17281v1",
    "title": "A Comprehensive Survey and Classification of Evaluation Criteria for Trustworthy Artificial Intelligence",
    "authors": [
      "Louise McCormack",
      "Malika Bendechache"
    ],
    "abstract": "This paper presents a systematic review of the literature on evaluation\ncriteria for Trustworthy Artificial Intelligence (TAI), with a focus on the\nseven EU principles of TAI. This systematic literature review identifies and\nanalyses current evaluation criteria, maps them to the EU TAI principles and\nproposes a new classification system for each principle. The findings reveal\nboth a need for and significant barriers to standardising criteria for TAI\nevaluation. The proposed classification contributes to the development,\nselection and standardization of evaluation criteria for TAI governance.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "This work has been accepted for publication in AI and Ethics",
    "pdf_url": "http://arxiv.org/pdf/2410.17281v1",
    "published_date": "2024-10-10 11:54:14 UTC",
    "updated_date": "2024-10-10 11:54:14 UTC"
  },
  {
    "arxiv_id": "2410.07836v5",
    "title": "Masked Generative Priors Improve World Models Sequence Modelling Capabilities",
    "authors": [
      "Cristian Meo",
      "Mircea Lica",
      "Zarif Ikram",
      "Akihiro Nakano",
      "Vedant Shah",
      "Aniket Rajiv Didolkar",
      "Dianbo Liu",
      "Anirudh Goyal",
      "Justin Dauwels"
    ],
    "abstract": "Deep Reinforcement Learning (RL) has become the leading approach for creating\nartificial agents in complex environments. Model-based approaches, which are RL\nmethods with world models that predict environment dynamics, are among the most\npromising directions for improving data efficiency, forming a critical step\ntoward bridging the gap between research and real-world deployment. In\nparticular, world models enhance sample efficiency by learning in imagination,\nwhich involves training a generative sequence model of the environment in a\nself-supervised manner. Recently, Masked Generative Modelling has emerged as a\nmore efficient and superior inductive bias for modelling and generating token\nsequences. Building on the Efficient Stochastic Transformer-based World Models\n(STORM) architecture, we replace the traditional MLP prior with a Masked\nGenerative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM. We evaluate our\nmodel on two downstream tasks: reinforcement learning and video prediction.\nGIT-STORM demonstrates substantial performance gains in RL tasks on the Atari\n100k benchmark. Moreover, we apply Transformer-based World Models to continuous\naction environments for the first time, addressing a significant gap in prior\nresearch. To achieve this, we employ a state mixer function that integrates\nlatent state representations with actions, enabling our model to handle\ncontinuous control tasks. We validate this approach through qualitative and\nquantitative analyses on the DeepMind Control Suite, showcasing the\neffectiveness of Transformer-based World Models in this new domain. Our results\nhighlight the versatility and efficacy of the MaskGIT dynamics prior, paving\nthe way for more accurate world models and effective RL policies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07836v5",
    "published_date": "2024-10-10 11:52:07 UTC",
    "updated_date": "2025-04-30 17:22:52 UTC"
  },
  {
    "arxiv_id": "2410.07832v1",
    "title": "LaB-CL: Localized and Balanced Contrastive Learning for improving parking slot detection",
    "authors": [
      "U Jin Jeong",
      "Sumin Roh",
      "Il Yong Chun"
    ],
    "abstract": "Parking slot detection is an essential technology in autonomous parking\nsystems. In general, the classification problem of parking slot detection\nconsists of two tasks, a task determining whether localized candidates are\njunctions of parking slots or not, and the other that identifies a shape of\ndetected junctions. Both classification tasks can easily face biased learning\ntoward the majority class, degrading classification performances. Yet, the data\nimbalance issue has been overlooked in parking slot detection. We propose the\nfirst supervised contrastive learning framework for parking slot detection,\nLocalized and Balanced Contrastive Learning for improving parking slot\ndetection (LaB-CL). The proposed LaB-CL framework uses two main approaches.\nFirst, we propose to include class prototypes to consider representations from\nall classes in every mini batch, from the local perspective. Second, we propose\na new hard negative sampling scheme that selects local representations with\nhigh prediction error. Experiments with the benchmark dataset demonstrate that\nthe proposed LaB-CL framework can outperform existing parking slot detection\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07832v1",
    "published_date": "2024-10-10 11:50:26 UTC",
    "updated_date": "2024-10-10 11:50:26 UTC"
  },
  {
    "arxiv_id": "2410.08247v1",
    "title": "Forecasting mortality associated emergency department crowding",
    "authors": [
      "Jalmari Nevanlinna",
      "Anna Eidstø",
      "Jari Ylä-Mattila",
      "Teemu Koivistoinen",
      "Niku Oksala",
      "Juho Kanniainen",
      "Ari Palomäki",
      "Antti Roine"
    ],
    "abstract": "Emergency department (ED) crowding is a global public health issue that has\nbeen repeatedly associated with increased mortality. Predicting future service\ndemand would enable preventative measures aiming to eliminate crowding along\nwith it's detrimental effects. Recent findings in our ED indicate that\noccupancy ratios exceeding 90% are associated with increased 10-day mortality.\nIn this paper, we aim to predict these crisis periods using retrospective data\nfrom a large Nordic ED with a LightGBM model. We provide predictions for the\nwhole ED and individually for it's different operational sections. We\ndemonstrate that afternoon crowding can be predicted at 11 a.m. with an AUC of\n0.82 (95% CI 0.78-0.86) and at 8 a.m. with an AUC up to 0.79 (95% CI\n0.75-0.83). Consequently we show that forecasting mortality-associated crowding\nusing anonymous administrative data is feasible.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08247v1",
    "published_date": "2024-10-10 11:38:39 UTC",
    "updated_date": "2024-10-10 11:38:39 UTC"
  },
  {
    "arxiv_id": "2410.09113v1",
    "title": "M$^2$-ViT: Accelerating Hybrid Vision Transformers with Two-Level Mixed Quantization",
    "authors": [
      "Yanbiao Liang",
      "Huihong Shi",
      "Zhongfeng Wang"
    ],
    "abstract": "Although Vision Transformers (ViTs) have achieved significant success, their\nintensive computations and substantial memory overheads challenge their\ndeployment on edge devices. To address this, efficient ViTs have emerged,\ntypically featuring Convolution-Transformer hybrid architectures to enhance\nboth accuracy and hardware efficiency. While prior work has explored\nquantization for efficient ViTs to marry the best of efficient hybrid ViT\narchitectures and quantization, it focuses on uniform quantization and\noverlooks the potential advantages of mixed quantization. Meanwhile, although\nseveral works have studied mixed quantization for standard ViTs, they are not\ndirectly applicable to hybrid ViTs due to their distinct algorithmic and\nhardware characteristics. To bridge this gap, we present M$^2$-ViT to\naccelerate Convolution-Transformer hybrid efficient ViTs with two-level mixed\nquantization. Specifically, we introduce a hardware-friendly two-level mixed\nquantization (M$^2$Q) strategy, characterized by both mixed quantization\nprecision and mixed quantization schemes (i.e., uniform and power-of-two), to\nexploit the architectural properties of efficient ViTs. We further build a\ndedicated accelerator with heterogeneous computing engines to transform our\nalgorithmic benefits into real hardware improvements. Experimental results\nvalidate our effectiveness, showcasing an average of $80\\%$ energy-delay\nproduct (EDP) saving with comparable quantization accuracy compared to the\nprior work.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09113v1",
    "published_date": "2024-10-10 11:16:57 UTC",
    "updated_date": "2024-10-10 11:16:57 UTC"
  },
  {
    "arxiv_id": "2410.07820v1",
    "title": "Mitigating Gender Bias in Code Large Language Models via Model Editing",
    "authors": [
      "Zhanyue Qin",
      "Haochuan Wang",
      "Zecheng Wang",
      "Deyuan Liu",
      "Cunhang Fan",
      "Zhao Lv",
      "Zhiying Tu",
      "Dianhui Chu",
      "Dianbo Sui"
    ],
    "abstract": "In recent years, with the maturation of large language model (LLM) technology\nand the emergence of high-quality programming code datasets, researchers have\nbecome increasingly confident in addressing the challenges of program synthesis\nautomatically. However, since most of the training samples for LLMs are\nunscreened, it is inevitable that LLMs' performance may not align with\nreal-world scenarios, leading to the presence of social bias. To evaluate and\nquantify the gender bias in code LLMs, we propose a dataset named CodeGenBias\n(Gender Bias in the Code Generation) and an evaluation metric called FB-Score\n(Factual Bias Score) based on the actual gender distribution of correlative\nprofessions. With the help of CodeGenBias and FB-Score, we evaluate and analyze\nthe gender bias in eight mainstream Code LLMs. Previous work has demonstrated\nthat model editing methods that perform well in knowledge editing have the\npotential to mitigate social bias in LLMs. Therefore, we develop a model\nediting approach named MG-Editing (Multi-Granularity model Editing), which\nincludes the locating and editing phases. Our model editing method MG-Editing\ncan be applied at five different levels of model parameter granularity: full\nparameters level, layer level, module level, row level, and neuron level.\nExtensive experiments not only demonstrate that our MG-Editing can effectively\nmitigate the gender bias in code LLMs while maintaining their general code\ngeneration capabilities, but also showcase its excellent generalization. At the\nsame time, the experimental results show that, considering both the gender bias\nof the model and its general code generation capability, MG-Editing is most\neffective when applied at the row and neuron levels of granularity.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07820v1",
    "published_date": "2024-10-10 11:11:32 UTC",
    "updated_date": "2024-10-10 11:11:32 UTC"
  },
  {
    "arxiv_id": "2410.07812v2",
    "title": "Temporal-Difference Variational Continual Learning",
    "authors": [
      "Luckeciano C. Melo",
      "Alessandro Abate",
      "Yarin Gal"
    ],
    "abstract": "Machine Learning models in real-world applications must continuously learn\nnew tasks to adapt to shifts in the data-generating distribution. Yet, for\nContinual Learning (CL), models often struggle to balance learning new tasks\n(plasticity) with retaining previous knowledge (memory stability).\nConsequently, they are susceptible to Catastrophic Forgetting, which degrades\nperformance and undermines the reliability of deployed systems. In the Bayesian\nCL literature, variational methods tackle this challenge by employing a\nlearning objective that recursively updates the posterior distribution while\nconstraining it to stay close to its previous estimate. Nonetheless, we argue\nthat these methods may be ineffective due to compounding approximation errors\nover successive recursions. To mitigate this, we propose new learning\nobjectives that integrate the regularization effects of multiple previous\nposterior estimations, preventing individual errors from dominating future\nposterior updates and compounding over time. We reveal insightful connections\nbetween these objectives and Temporal-Difference methods, a popular learning\nmechanism in Reinforcement Learning and Neuroscience. Experiments on\nchallenging CL benchmarks show that our approach effectively mitigates\nCatastrophic Forgetting, outperforming strong Variational CL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07812v2",
    "published_date": "2024-10-10 10:58:41 UTC",
    "updated_date": "2025-05-14 18:18:45 UTC"
  },
  {
    "arxiv_id": "2410.09112v1",
    "title": "HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction",
    "authors": [
      "Qianyue Hao",
      "Jingyang Fan",
      "Fengli Xu",
      "Jian Yuan",
      "Yong Li"
    ],
    "abstract": "Citation networks are critical in modern science, and predicting which\nprevious papers (candidates) will a new paper (query) cite is a critical\nproblem. However, the roles of a paper's citations vary significantly, ranging\nfrom foundational knowledge basis to superficial contexts. Distinguishing these\nroles requires a deeper understanding of the logical relationships among\npapers, beyond simple edges in citation networks. The emergence of LLMs with\ntextual reasoning capabilities offers new possibilities for discerning these\nrelationships, but there are two major challenges. First, in practice, a new\npaper may select its citations from gigantic existing papers, where the texts\nexceed the context length of LLMs. Second, logical relationships between papers\nare implicit, and directly prompting an LLM to predict citations may result in\nsurface-level textual similarities rather than the deeper logical reasoning. In\nthis paper, we introduce the novel concept of core citation, which identifies\nthe critical references that go beyond superficial mentions. Thereby, we\nelevate the citation prediction task from a simple binary classification to\ndistinguishing core citations from both superficial citations and\nnon-citations. To address this, we propose $\\textbf{HLM-Cite}$, a\n$\\textbf{H}$ybrid $\\textbf{L}$anguage $\\textbf{M}$odel workflow for citation\nprediction, which combines embedding and generative LMs. We design a curriculum\nfinetune procedure to adapt a pretrained text embedding model to coarsely\nretrieve high-likelihood core citations from vast candidates and then design an\nLLM agentic workflow to rank the retrieved papers through one-shot reasoning,\nrevealing the implicit relationships among papers. With the pipeline, we can\nscale the candidate sets to 100K papers. We evaluate HLM-Cite across 19\nscientific fields, demonstrating a 17.6% performance improvement comparing SOTA\nmethods.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.DL",
    "comment": "NeurIPS 2024 paper",
    "pdf_url": "http://arxiv.org/pdf/2410.09112v1",
    "published_date": "2024-10-10 10:46:06 UTC",
    "updated_date": "2024-10-10 10:46:06 UTC"
  },
  {
    "arxiv_id": "2410.07797v1",
    "title": "Rewriting Conversational Utterances with Instructed Large Language Models",
    "authors": [
      "Elnara Galimzhanova",
      "Cristina Ioana Muntean",
      "Franco Maria Nardini",
      "Raffaele Perego",
      "Guido Rocchietti"
    ],
    "abstract": "Many recent studies have shown the ability of large language models (LLMs) to\nachieve state-of-the-art performance on many NLP tasks, such as question\nanswering, text summarization, coding, and translation. In some cases, the\nresults provided by LLMs are on par with those of human experts. These models'\nmost disruptive innovation is their ability to perform tasks via zero-shot or\nfew-shot prompting. This capability has been successfully exploited to train\ninstructed LLMs, where reinforcement learning with human feedback is used to\nguide the model to follow the user's requests directly. In this paper, we\ninvestigate the ability of instructed LLMs to improve conversational search\neffectiveness by rewriting user questions in a conversational setting. We study\nwhich prompts provide the most informative rewritten utterances that lead to\nthe best retrieval performance. Reproducible experiments are conducted on\npublicly-available TREC CAST datasets. The results show that rewriting\nconversational utterances with instructed LLMs achieves significant\nimprovements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and\n11.5% in Recall@500 over state-of-the-art techniques.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07797v1",
    "published_date": "2024-10-10 10:30:28 UTC",
    "updated_date": "2024-10-10 10:30:28 UTC"
  },
  {
    "arxiv_id": "2410.07793v3",
    "title": "Do Current Language Models Support Code Intelligence for R Programming Language?",
    "authors": [
      "ZiXiao Zhao",
      "Fatemeh H. Fard"
    ],
    "abstract": "Recent advancements in developing Pre-trained Language Models for Code\n(Code-PLMs) have urged many areas of Software Engineering (SE) and brought\nbreakthrough results for many SE tasks. Though these models have achieved the\nstate-of-the-art performance for SE tasks for many popular programming\nlanguages, such as Java and Python, the Scientific Software and its related\nlanguages like R programming language have rarely benefited or even been\nevaluated with the Code-PLMs. Research has shown that R has many differences\nwith other programming languages and requires specific techniques. In this\nstudy, we provide the first insights for code intelligence for R. For this\npurpose, we collect and open source an R dataset, and evaluate Code-PLMs for\nthe two tasks of code summarization and method name prediction using several\nsettings and strategies, including the differences in two R styles, Tidy-verse\nand Base R. Our results demonstrate that the studied models have experienced\nvarying degrees of performance degradation when processing R programming\nlanguage code, which is supported by human evaluation. Additionally, not all\nmodels show performance improvement in R-specific tasks even after\nmulti-language fine-tuning. The dual syntax paradigms in R significantly impact\nthe models' performance, particularly in code summarization tasks. Furthermore,\nthe project-specific context inherent in R codebases significantly impacts the\nperformance when attempting cross-project training.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07793v3",
    "published_date": "2024-10-10 10:23:23 UTC",
    "updated_date": "2025-05-15 22:41:11 UTC"
  },
  {
    "arxiv_id": "2410.07787v2",
    "title": "Mastering Contact-rich Tasks by Combining Soft and Rigid Robotics with Imitation Learning",
    "authors": [
      "Mariano Ramírez Montero",
      "Ebrahim Shahabi",
      "Giovanni Franzese",
      "Jens Kober",
      "Barbara Mazzolai",
      "Cosimo Della Santina"
    ],
    "abstract": "Soft robots have the potential to revolutionize the use of robotic systems\nwith their capability of establishing safe, robust, and adaptable interactions\nwith their environment, but their precise control remains challenging. In\ncontrast, traditional rigid robots offer high accuracy and repeatability but\nlack the flexibility of soft robots. We argue that combining these\ncharacteristics in a hybrid robotic platform can significantly enhance overall\ncapabilities. This work presents a novel hybrid robotic platform that\nintegrates a rigid manipulator with a fully developed soft arm. This system is\nequipped with the intelligence necessary to perform flexible and generalizable\ntasks through imitation learning autonomously. The physical softness and\nmachine learning enable our platform to achieve highly generalizable skills,\nwhile the rigid components ensure precision and repeatability.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Corrected missing citation",
    "pdf_url": "http://arxiv.org/pdf/2410.07787v2",
    "published_date": "2024-10-10 10:18:03 UTC",
    "updated_date": "2024-10-11 11:41:00 UTC"
  },
  {
    "arxiv_id": "2410.07771v1",
    "title": "Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models",
    "authors": [
      "Adriana Fernandez-Lopez",
      "Shiwei Liu",
      "Lu Yin",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "abstract": "This paper investigates the under-explored area of low-rank weight training\nfor large-scale Conformer-based speech recognition models from scratch. Our\nstudy demonstrates the viability of this training paradigm for such models,\nyielding several notable findings. Firstly, we discover that applying a\nlow-rank structure exclusively to the attention modules can unexpectedly\nenhance performance, even with a significant rank reduction of 12%. In\ncontrast, feed-forward layers present greater challenges, as they begin to\nexhibit performance degradation with a moderate 50% rank reduction.\nFurthermore, we find that both initialization and layer-wise rank assignment\nplay critical roles in successful low-rank training. Specifically, employing\nSVD initialization and linear layer-wise rank mapping significantly boosts the\nefficacy of low-rank weight training. Building on these insights, we introduce\nthe Low-Rank Speech Model from Scratch (LR-SMS), an approach that achieves\nperformance parity with full-rank training while delivering substantial\nreductions in parameters count (by at least 2x), and training time speedups (by\n1.3x for ASR and 1.15x for AVSR).",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.07771v1",
    "published_date": "2024-10-10 09:58:35 UTC",
    "updated_date": "2024-10-10 09:58:35 UTC"
  },
  {
    "arxiv_id": "2410.07765v1",
    "title": "GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps",
    "authors": [
      "Muhammad Umair Nasir",
      "Steven James",
      "Julian Togelius"
    ],
    "abstract": "Large language models (LLMs) have recently demonstrated great success in\ngenerating and understanding natural language. While they have also shown\npotential beyond the domain of natural language, it remains an open question as\nto what extent and in which way these LLMs can plan. We investigate their\nplanning capabilities by proposing GameTraversalBenchmark (GTB), a benchmark\nconsisting of diverse 2D grid-based game maps. An LLM succeeds if it can\ntraverse through given objectives, with a minimum number of steps and a minimum\nnumber of generation errors. We evaluate a number of LLMs on GTB and found that\nGPT-4-Turbo achieved the highest score of 44.97% on GTB\\_Score (GTBS), a\ncomposite score that combines the three above criteria. Furthermore, we\npreliminarily test large reasoning models, namely o1, which scores $67.84\\%$ on\nGTBS, indicating that the benchmark remains challenging for current models.\nCode, data, and documentation are available at\nhttps://github.com/umair-nasir14/Game-Traversal-Benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024) Track on Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2410.07765v1",
    "published_date": "2024-10-10 09:54:28 UTC",
    "updated_date": "2024-10-10 09:54:28 UTC"
  },
  {
    "arxiv_id": "2410.12848v1",
    "title": "Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions",
    "authors": [
      "Per Niklas Waaler",
      "Musarrat Hussain",
      "Igor Molchanov",
      "Lars Ailo Bongo",
      "Brita Elvevåg"
    ],
    "abstract": "Patients with schizophrenia often present with cognitive impairments that may\nhinder their ability to learn about their condition. These individuals could\nbenefit greatly from education platforms that leverage the adaptability of\nLarge Language Models (LLMs) such as GPT-4. While LLMs have the potential to\nmake topical mental health information more accessible and engaging, their\nblack-box nature raises concerns about ethics and safety. Prompting offers a\nway to produce semi-scripted chatbots with responses anchored in instructions\nand validated information, but prompt-engineered chatbots may drift from their\nintended identity as the conversation progresses. We propose a Critical\nAnalysis Filter for achieving better control over chatbot behavior. In this\nsystem, a team of prompted LLM agents are prompt-engineered to critically\nanalyze and refine the chatbot's response and deliver real-time feedback to the\nchatbot. To test this approach, we develop an informational schizophrenia\nchatbot and converse with it (with the filter deactivated) until it oversteps\nits scope. Once drift has been observed, AI-agents are used to automatically\ngenerate sample conversations in which the chatbot is being enticed to talk\nabout out-of-bounds topics. We manually assign to each response a compliance\nscore that quantifies the chatbot's compliance to its instructions;\nspecifically the rules about accurately conveying sources and being transparent\nabout limitations. Activating the Critical Analysis Filter resulted in an\nacceptable compliance score (>=2) in 67.0% of responses, compared to only 8.7%\nwhen the filter was deactivated. These results suggest that a self-reflection\nlayer could enable LLMs to be used effectively and safely in mental health\nplatforms, maintaining adaptability while reliably limiting their scope to\nappropriate use cases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12848v1",
    "published_date": "2024-10-10 09:49:24 UTC",
    "updated_date": "2024-10-10 09:49:24 UTC"
  },
  {
    "arxiv_id": "2410.07763v1",
    "title": "HARIVO: Harnessing Text-to-Image Models for Video Generation",
    "authors": [
      "Mingi Kwon",
      "Seoung Wug Oh",
      "Yang Zhou",
      "Difan Liu",
      "Joon-Young Lee",
      "Haoran Cai",
      "Baqiao Liu",
      "Feng Liu",
      "Youngjung Uh"
    ],
    "abstract": "We present a method to create diffusion-based video models from pretrained\nText-to-Image (T2I) models. Recently, AnimateDiff proposed freezing the T2I\nmodel while only training temporal layers. We advance this method by proposing\na unique architecture, incorporating a mapping network and frame-wise tokens,\ntailored for video generation while maintaining the diversity and creativity of\nthe original T2I model. Key innovations include novel loss functions for\ntemporal smoothness and a mitigating gradient sampling technique, ensuring\nrealistic and temporally consistent video generation despite limited public\nvideo data. We have successfully integrated video-specific inductive biases\ninto the architecture and loss functions. Our method, built on the frozen\nStableDiffusion model, simplifies training processes and allows for seamless\nintegration with off-the-shelf models like ControlNet and DreamBooth. project\npage: https://kwonminki.github.io/HARIVO",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2410.07763v1",
    "published_date": "2024-10-10 09:47:39 UTC",
    "updated_date": "2024-10-10 09:47:39 UTC"
  },
  {
    "arxiv_id": "2410.07761v1",
    "title": "$\\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models",
    "authors": [
      "Yong-Hyun Park",
      "Chieh-Hsin Lai",
      "Satoshi Hayakawa",
      "Yuhta Takida",
      "Yuki Mitsufuji"
    ],
    "abstract": "Diffusion models have seen notable success in continuous domains, leading to\nthe development of discrete diffusion models (DDMs) for discrete variables.\nDespite recent advances, DDMs face the challenge of slow sampling speeds. While\nparallel sampling methods like $\\tau$-leaping accelerate this process, they\nintroduce $\\textit{Compounding Decoding Error}$ (CDE), where discrepancies\narise between the true distribution and the approximation from parallel token\ngeneration, leading to degraded sample quality. In this work, we present\n$\\textit{Jump Your Steps}$ (JYS), a novel approach that optimizes the\nallocation of discrete sampling timesteps by minimizing CDE without extra\ncomputational cost. More precisely, we derive a practical upper bound on CDE\nand propose an efficient algorithm for searching for the optimal sampling\nschedule. Extensive experiments across image, music, and text generation show\nthat JYS significantly improves sampling quality, establishing it as a\nversatile framework for enhancing DDM performance for fast sampling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07761v1",
    "published_date": "2024-10-10 09:44:25 UTC",
    "updated_date": "2024-10-10 09:44:25 UTC"
  },
  {
    "arxiv_id": "2410.08245v2",
    "title": "Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts",
    "authors": [
      "Sukwon Yun",
      "Inyoung Choi",
      "Jie Peng",
      "Yangfan Wu",
      "Jingxuan Bao",
      "Qiyiwen Zhang",
      "Jiayi Xin",
      "Qi Long",
      "Tianlong Chen"
    ],
    "abstract": "Multimodal learning has gained increasing importance across various fields,\noffering the ability to integrate data from diverse sources such as images,\ntext, and personalized records, which are frequently observed in medical\ndomains. However, in scenarios where some modalities are missing, many existing\nframeworks struggle to accommodate arbitrary modality combinations, often\nrelying heavily on a single modality or complete data. This oversight of\npotential modality combinations limits their applicability in real-world\nsituations. To address this challenge, we propose Flex-MoE (Flexible\nMixture-of-Experts), a new framework designed to flexibly incorporate arbitrary\nmodality combinations while maintaining robustness to missing data. The core\nidea of Flex-MoE is to first address missing modalities using a new missing\nmodality bank that integrates observed modality combinations with the\ncorresponding missing ones. This is followed by a uniquely designed Sparse MoE\nframework. Specifically, Flex-MoE first trains experts using samples with all\nmodalities to inject generalized knowledge through the generalized router\n($\\mathcal{G}$-Router). The $\\mathcal{S}$-Router then specializes in handling\nfewer modality combinations by assigning the top-1 gate to the expert\ncorresponding to the observed modality combination. We evaluate Flex-MoE on the\nADNI dataset, which encompasses four modalities in the Alzheimer's Disease\ndomain, as well as on the MIMIC-IV dataset. The results demonstrate the\neffectiveness of Flex-MoE highlighting its ability to model arbitrary modality\ncombinations in diverse missing modality scenarios. Code is available at\nhttps://github.com/UNITES-Lab/flex-moe.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2410.08245v2",
    "published_date": "2024-10-10 09:37:21 UTC",
    "updated_date": "2024-10-31 10:44:50 UTC"
  },
  {
    "arxiv_id": "2410.08244v2",
    "title": "RAB$^2$-DEF: Dynamic and explainable defense against adversarial attacks in Federated Learning to fair poor clients",
    "authors": [
      "Nuria Rodríguez-Barroso",
      "M. Victoria Luzón",
      "Francisco Herrera"
    ],
    "abstract": "At the same time that artificial intelligence is becoming popular, concern\nand the need for regulation is growing, including among other requirements the\ndata privacy. In this context, Federated Learning is proposed as a solution to\ndata privacy concerns derived from different source data scenarios due to its\ndistributed learning. The defense mechanisms proposed in literature are just\nfocused on defending against adversarial attacks and the performance, leaving\naside other important qualities such as explainability, fairness to poor\nquality clients, dynamism in terms of attacks configuration and generality in\nterms of being resilient against different kinds of attacks. In this work, we\npropose RAB$^2$-DEF, a $\\textbf{r}$esilient $\\textbf{a}$gainst\n$\\textbf{b}\\text{yzantine}$ and $\\textbf{b}$ackdoor attacks which is\n$\\textbf{d}$ynamic, $\\textbf{e}$xplainable and $\\textbf{f}$air to poor clients\nusing local linear explanations. We test the performance of RAB$^2$-DEF in\nimage datasets and both byzantine and backdoor attacks considering the\nstate-of-the-art defenses and achieve that RAB$^2$-DEF is a proper defense at\nthe same time that it boosts the other qualities towards trustworthy artificial\nintelligence.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08244v2",
    "published_date": "2024-10-10 09:32:59 UTC",
    "updated_date": "2025-04-16 07:54:52 UTC"
  },
  {
    "arxiv_id": "2410.07751v2",
    "title": "Learning Low-Level Causal Relations using a Simulated Robotic Arm",
    "authors": [
      "Miroslav Cibula",
      "Matthias Kerzel",
      "Igor Farkaš"
    ],
    "abstract": "Causal learning allows humans to predict the effect of their actions on the\nknown environment and use this knowledge to plan the execution of more complex\nactions. Such knowledge also captures the behaviour of the environment and can\nbe used for its analysis and the reasoning behind the behaviour. This type of\nknowledge is also crucial in the design of intelligent robotic systems with\ncommon sense. In this paper, we study causal relations by learning the forward\nand inverse models based on data generated by a simulated robotic arm involved\nin two sensorimotor tasks. As a next step, we investigate feature attribution\nmethods for the analysis of the forward model, which reveals the low-level\ncausal effects corresponding to individual features of the state vector related\nto both the arm joints and the environment features. This type of analysis\nprovides solid ground for dimensionality reduction of the state\nrepresentations, as well as for the aggregation of knowledge towards the\nexplainability of causal effects at higher levels.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "14 pages, 5 figures, 3 tables. Appeared in 2024 International\n  Conference on Artificial Neural Networks (ICANN) proceedings. Published\n  version copyrighted by Springer. This work was funded by the Horizon Europe\n  Twinning project TERAIS, G.A. number 101079338 and in part by the Slovak\n  Grant Agency for Science (VEGA), project 1/0373/23. The code can be found at\n  https://doi.org/10.5281/zenodo.14550231",
    "pdf_url": "http://arxiv.org/pdf/2410.07751v2",
    "published_date": "2024-10-10 09:28:30 UTC",
    "updated_date": "2024-12-24 21:47:37 UTC"
  },
  {
    "arxiv_id": "2410.07738v1",
    "title": "Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning",
    "authors": [
      "Jingyuan Zhang",
      "Yiyang Duan",
      "Shuaicheng Niu",
      "Yang Cao",
      "Wei Yang Bryan Lim"
    ],
    "abstract": "Federated Domain Adaptation (FDA) is a Federated Learning (FL) scenario where\nmodels are trained across multiple clients with unique data domains but a\nshared category space, without transmitting private data. The primary challenge\nin FDA is data heterogeneity, which causes significant divergences in gradient\nupdates when using conventional averaging-based aggregation methods, reducing\nthe efficacy of the global model. This further undermines both in-domain and\nout-of-domain performance (within the same federated system but outside the\nlocal client). To address this, we propose a novel framework called\n\\textbf{M}ulti-domain \\textbf{P}rototype-based \\textbf{F}ederated\nFine-\\textbf{T}uning (MPFT). MPFT fine-tunes a pre-trained model using\nmulti-domain prototypes, i.e., pretrained representations enriched with\ndomain-specific information from category-specific local data. This enables\nsupervised learning on the server to derive a globally optimized adapter that\nis subsequently distributed to local clients, without the intrusion of data\nprivacy. Empirical results show that MPFT significantly improves both in-domain\nand out-of-domain accuracy over conventional methods, enhancing knowledge\npreservation and adaptation in FDA. Notably, MPFT achieves convergence within a\nsingle communication round, greatly reducing computation and communication\ncosts. To ensure privacy, MPFT applies differential privacy to protect the\nprototypes. Additionally, we develop a prototype-based feature space hijacking\nattack to evaluate robustness, confirming that raw data samples remain\nunrecoverable even after extensive training epochs. The complete implementation\nof MPFL is available at \\url{https://anonymous.4open.science/r/DomainFL/}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07738v1",
    "published_date": "2024-10-10 09:15:56 UTC",
    "updated_date": "2024-10-10 09:15:56 UTC"
  },
  {
    "arxiv_id": "2410.09111v1",
    "title": "IceDiff: High Resolution and High-Quality Sea Ice Forecasting with Generative Diffusion Prior",
    "authors": [
      "Jingyi Xu",
      "Siwei Tu",
      "Weidong Yang",
      "Shuhao Li",
      "Keyi Liu",
      "Yeqi Luo",
      "Lipeng Ma",
      "Ben Fei",
      "Lei Bai"
    ],
    "abstract": "Variation of Arctic sea ice has significant impacts on polar ecosystems,\ntransporting routes, coastal communities, and global climate. Tracing the\nchange of sea ice at a finer scale is paramount for both operational\napplications and scientific studies. Recent pan-Arctic sea ice forecasting\nmethods that leverage advances in artificial intelligence has made promising\nprogress over numerical models. However, forecasting sea ice at higher\nresolutions is still under-explored. To bridge the gap, we propose a two-staged\ndeep learning framework, IceDiff, to forecast sea ice concentration at finer\nscales. IceDiff first leverages an independently trained vision transformer to\ngenerate coarse yet superior forecasting over previous methods at a regular\n25km x 25km grid. This high-quality sea ice forecasting can be utilized as\nreliable guidance for the next stage. Subsequently, an unconditional diffusion\nmodel pre-trained on sea ice concentration maps is utilized for sampling\ndown-scaled sea ice forecasting via a zero-shot guided sampling strategy and a\npatch-based method. For the first time, IceDiff demonstrates sea ice\nforecasting with the 6.25km x 6.25km resolution. IceDiff extends the boundary\nof existing sea ice forecasting models and more importantly, its capability to\ngenerate high-resolution sea ice concentration data is vital for pragmatic\nusages and research.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09111v1",
    "published_date": "2024-10-10 08:53:41 UTC",
    "updated_date": "2024-10-10 08:53:41 UTC"
  },
  {
    "arxiv_id": "2410.07717v1",
    "title": "On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models",
    "authors": [
      "Gabriel Jarry",
      "Ramon Dalmau",
      "Philippe Very",
      "Junzi Sun"
    ],
    "abstract": "Accurately estimating aircraft fuel flow is essential for evaluating new\nprocedures, designing next-generation aircraft, and monitoring the\nenvironmental impact of current aviation practices. This paper investigates the\ngeneralization capabilities of deep learning models in predicting fuel\nconsumption, focusing particularly on their performance for aircraft types\nabsent from the training data. We propose a novel methodology that integrates\nneural network architectures with domain generalization techniques to enhance\nrobustness and reliability across a wide range of aircraft. A comprehensive\ndataset containing 101 different aircraft types, separated into training and\ngeneralization sets, with each aircraft type set containing 1,000 flights. We\nemployed the base of aircraft data (BADA) model for fuel flow estimates,\nintroduced a pseudo-distance metric to assess aircraft type similarity, and\nexplored various sampling strategies to optimize model performance in\ndata-sparse regions. Our results reveal that for previously unseen aircraft\ntypes, the introduction of noise into aircraft and engine parameters improved\nmodel generalization. The model is able to generalize with acceptable mean\nabsolute percentage error between 2\\% and 10\\% for aircraft close to existing\naircraft, while performance is below 1\\% error for known aircraft in the\ntraining set. This study highlights the potential of combining domain-specific\ninsights with advanced machine learning techniques to develop scalable,\naccurate, and generalizable fuel flow estimation models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07717v1",
    "published_date": "2024-10-10 08:34:19 UTC",
    "updated_date": "2024-10-10 08:34:19 UTC"
  },
  {
    "arxiv_id": "2410.19744v1",
    "title": "Towards Next-Generation LLM-based Recommender Systems: A Survey and Beyond",
    "authors": [
      "Qi Wang",
      "Jindong Li",
      "Shiqi Wang",
      "Qianli Xing",
      "Runliang Niu",
      "He Kong",
      "Rui Li",
      "Guodong Long",
      "Yi Chang",
      "Chengqi Zhang"
    ],
    "abstract": "Large language models (LLMs) have not only revolutionized the field of\nnatural language processing (NLP) but also have the potential to bring a\nparadigm shift in many other fields due to their remarkable abilities of\nlanguage understanding, as well as impressive generalization capabilities and\nreasoning skills. As a result, recent studies have actively attempted to\nharness the power of LLMs to improve recommender systems, and it is imperative\nto thoroughly review the recent advances and challenges of LLM-based\nrecommender systems. Unlike existing work, this survey does not merely analyze\nthe classifications of LLM-based recommendation systems according to the\ntechnical framework of LLMs. Instead, it investigates how LLMs can better serve\nrecommendation tasks from the perspective of the recommender system community,\nthus enhancing the integration of large language models into the research of\nrecommender system and its practical application. In addition, the\nlong-standing gap between academic research and industrial applications related\nto recommender systems has not been well discussed, especially in the era of\nlarge language models. In this review, we introduce a novel taxonomy that\noriginates from the intrinsic essence of recommendation, delving into the\napplication of large language model-based recommendation systems and their\nindustrial implementation. Specifically, we propose a three-tier structure that\nmore accurately reflects the developmental progression of recommendation\nsystems from research to practical implementation, including representing and\nunderstanding, scheming and utilizing, and industrial deployment. Furthermore,\nwe discuss critical challenges and opportunities in this emerging field. A more\nup-to-date version of the papers is maintained at:\nhttps://github.com/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19744v1",
    "published_date": "2024-10-10 08:22:04 UTC",
    "updated_date": "2024-10-10 08:22:04 UTC"
  },
  {
    "arxiv_id": "2410.07708v2",
    "title": "Learning Tree Pattern Transformations",
    "authors": [
      "Daniel Neider",
      "Leif Sabellek",
      "Johannes Schmidt",
      "Fabian Vehlken",
      "Thomas Zeume"
    ],
    "abstract": "Explaining why and how a tree $t$ structurally differs from another tree\n$t^\\star$ is a question that is encountered throughout computer science,\nincluding in understanding tree-structured data such as XML or JSON data. In\nthis article, we explore how to learn explanations for structural differences\nbetween pairs of trees from sample data: suppose we are given a set $\\{(t_1,\nt_1^\\star),\\dots, (t_n, t_n^\\star)\\}$ of pairs of labelled, ordered trees; is\nthere a small set of rules that explains the structural differences between all\npairs $(t_i, t_i^\\star)$? This raises two research questions: (i) what is a\ngood notion of \"rule\" in this context?; and (ii) how can sets of rules\nexplaining a data set be learned algorithmically?\n  We explore these questions from the perspective of database theory by (1)\nintroducing a pattern-based specification language for tree transformations;\n(2) exploring the computational complexity of variants of the above algorithmic\nproblem, e.g. showing NP-hardness for very restricted variants; and (3)\ndiscussing how to solve the problem for data from CS education research using\nSAT solvers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Full version of the ICDT 2025 paper",
    "pdf_url": "http://arxiv.org/pdf/2410.07708v2",
    "published_date": "2024-10-10 08:20:57 UTC",
    "updated_date": "2025-02-18 15:41:56 UTC"
  },
  {
    "arxiv_id": "2410.07706v1",
    "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
    "authors": [
      "Yifan Song",
      "Weimin Xiong",
      "Xiutian Zhao",
      "Dawei Zhu",
      "Wenhao Wu",
      "Ke Wang",
      "Cheng Li",
      "Wei Peng",
      "Sujian Li"
    ],
    "abstract": "Fine-tuning on agent-environment interaction trajectory data holds\nsignificant promise for surfacing generalized agent capabilities in open-source\nlarge language models (LLMs). In this work, we introduce AgentBank, by far the\nlargest trajectory tuning data collection featuring more than 50k diverse\nhigh-quality interaction trajectories which comprises 16 tasks covering five\ndistinct agent skill dimensions. Leveraging a novel annotation pipeline, we are\nable to scale the annotated trajectories and generate a trajectory dataset with\nminimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a\nseries of agent models, Samoyed. Our comparative experiments demonstrate the\neffectiveness of scaling the interaction trajectory data to acquire generalized\nagent capabilities. Additional studies also reveal some key observations\nregarding trajectory tuning and agent skill generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.07706v1",
    "published_date": "2024-10-10 08:19:12 UTC",
    "updated_date": "2024-10-10 08:19:12 UTC"
  },
  {
    "arxiv_id": "2410.08243v1",
    "title": "Self-Attention Mechanism in Multimodal Context for Banking Transaction Flow",
    "authors": [
      "Cyrile Delestre",
      "Yoann Sola"
    ],
    "abstract": "Banking Transaction Flow (BTF) is a sequential data found in a number of\nbanking activities such as marketing, credit risk or banking fraud. It is a\nmultimodal data composed of three modalities: a date, a numerical value and a\nwording. We propose in this work an application of self-attention mechanism to\nthe processing of BTFs. We trained two general models on a large amount of BTFs\nin a self-supervised way: one RNN-based model and one Transformer-based model.\nWe proposed a specific tokenization in order to be able to process BTFs. The\nperformance of these two models was evaluated on two banking downstream tasks:\na transaction categorization task and a credit risk task. The results show that\nfine-tuning these two pre-trained models allowed to perform better than the\nstate-of-the-art approaches for both tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08243v1",
    "published_date": "2024-10-10 08:13:39 UTC",
    "updated_date": "2024-10-10 08:13:39 UTC"
  },
  {
    "arxiv_id": "2410.12847v2",
    "title": "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning",
    "authors": [
      "Yu-Chen Lin",
      "Wei-Hua Li",
      "Jun-Cheng Chen",
      "Chu-Song Chen"
    ],
    "abstract": "Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method\nattributed to its remarkable performance with few updated parameters on various\nlarge-scale pretrained Language Models (PLMs). Traditionally, each prompt has\nbeen considered indivisible and updated independently, leading the parameters\nincrease proportionally as prompt length grows. To address this issue, we\npropose Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT).\nIn our method, we refer to the concept of product quantization (PQ), allowing\nall soft prompts to share a set of learnable codebook vectors in each subspace,\nwith each prompt differentiated by a set of adaptive weights. We achieve the\nsuperior performance on 17 diverse natural language tasks including natural\nlanguage understanding (NLU) and question answering (QA) tasks by tuning only\n0.3% of parameters of the PLMs. Our approach also excels in few-shot and large\nmodel settings, highlighting its significant potential.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12847v2",
    "published_date": "2024-10-10 07:48:53 UTC",
    "updated_date": "2024-10-18 02:56:32 UTC"
  },
  {
    "arxiv_id": "2410.07675v1",
    "title": "Adversarial Robustness Overestimation and Instability in TRADES",
    "authors": [
      "Jonathan Weiping Li",
      "Ren-Wei Liang",
      "Cheng-Han Yeh",
      "Cheng-Chang Tsai",
      "Kuanchun Yu",
      "Chun-Shien Lu",
      "Shang-Tse Chen"
    ],
    "abstract": "This paper examines the phenomenon of probabilistic robustness overestimation\nin TRADES, a prominent adversarial training method. Our study reveals that\nTRADES sometimes yields disproportionately high PGD validation accuracy\ncompared to the AutoAttack testing accuracy in the multiclass classification\ntask. This discrepancy highlights a significant overestimation of robustness\nfor these instances, potentially linked to gradient masking. We further analyze\nthe parameters contributing to unstable models that lead to overestimation. Our\nfindings indicate that smaller batch sizes, lower beta values (which control\nthe weight of the robust loss term in TRADES), larger learning rates, and\nhigher class complexity (e.g., CIFAR-100 versus CIFAR-10) are associated with\nan increased likelihood of robustness overestimation. By examining metrics such\nas the First-Order Stationary Condition (FOSC), inner-maximization, and\ngradient information, we identify the underlying cause of this phenomenon as\ngradient masking and provide insights into it. Furthermore, our experiments\nshow that certain unstable training instances may return to a state without\nrobust overestimation, inspiring our attempts at a solution. In addition to\nadjusting parameter settings to reduce instability or retraining when\noverestimation occurs, we recommend incorporating Gaussian noise in inputs when\nthe FOSC score exceed the threshold. This method aims to mitigate robustness\noverestimation of TRADES and other similar methods at its source, ensuring more\nreliable representation of adversarial robustness during evaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07675v1",
    "published_date": "2024-10-10 07:32:40 UTC",
    "updated_date": "2024-10-10 07:32:40 UTC"
  },
  {
    "arxiv_id": "2410.07673v1",
    "title": "Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference",
    "authors": [
      "Jianxing Yu",
      "Shiqi Wang",
      "Han Yin",
      "Zhenlong Sun",
      "Ruobing Xie",
      "Bo Zhang",
      "Yanghui Rao"
    ],
    "abstract": "This paper focuses on detecting clickbait posts on the Web. These posts often\nuse eye-catching disinformation in mixed modalities to mislead users to click\nfor profit. That affects the user experience and thus would be blocked by\ncontent provider. To escape detection, malicious creators use tricks to add\nsome irrelevant non-bait content into bait posts, dressing them up as legal to\nfool the detector. This content often has biased relations with non-bait\nlabels, yet traditional detectors tend to make predictions based on simple\nco-occurrence rather than grasping inherent factors that lead to malicious\nbehavior. This spurious bias would easily cause misjudgments. To address this\nproblem, we propose a new debiased method based on causal inference. We first\nemploy a set of features in multiple modalities to characterize the posts.\nConsidering these features are often mixed up with unknown biases, we then\ndisentangle three kinds of latent factors from them, including the invariant\nfactor that indicates intrinsic bait intention; the causal factor which\nreflects deceptive patterns in a certain scenario, and non-causal noise. By\neliminating the noise that causes bias, we can use invariant and causal factors\nto build a robust model with good generalization ability. Experiments on three\npopular datasets show the effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07673v1",
    "published_date": "2024-10-10 07:29:56 UTC",
    "updated_date": "2024-10-10 07:29:56 UTC"
  },
  {
    "arxiv_id": "2410.07672v2",
    "title": "MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization",
    "authors": [
      "Yougang Lyu",
      "Lingyong Yan",
      "Zihan Wang",
      "Dawei Yin",
      "Pengjie Ren",
      "Maarten de Rijke",
      "Zhaochun Ren"
    ],
    "abstract": "As large language models (LLMs) are rapidly advancing and achieving\nnear-human capabilities on specific tasks, aligning them with human values is\nbecoming more urgent. In scenarios where LLMs outperform humans, we face a\nweak-to-strong alignment problem where we need to effectively align strong\nstudent LLMs through weak supervision generated by weak teachers. Existing\nalignment methods mainly focus on strong-to-weak alignment and self-alignment\nsettings, and it is impractical to adapt them to the much harder weak-to-strong\nalignment setting. To fill this gap, we propose a multi-agent contrastive\npreference optimization (MACPO) framework. MACPO facilitates weak teachers and\nstrong students to learn from each other by iteratively reinforcing unfamiliar\npositive behaviors while penalizing familiar negative ones. To get this, we\ndevise a mutual positive behavior augmentation strategy to encourage weak\nteachers and strong students to learn from each other's positive behavior and\nfurther provide higher quality positive behavior for the next iteration.\nAdditionally, we propose a hard negative behavior construction strategy to\ninduce weak teachers and strong students to generate familiar negative behavior\nby fine-tuning on negative behavioral data. Experimental results on the HH-RLHF\nand PKU-SafeRLHF datasets, evaluated using both automatic metrics and human\njudgments, demonstrate that MACPO simultaneously improves the alignment\nperformance of strong students and weak teachers. Moreover, as the number of\nweak teachers increases, MACPO achieves better weak-to-strong alignment\nperformance through more iteration optimization rounds.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.07672v2",
    "published_date": "2024-10-10 07:29:35 UTC",
    "updated_date": "2025-03-02 06:25:14 UTC"
  },
  {
    "arxiv_id": "2410.07671v2",
    "title": "DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation",
    "authors": [
      "Xiaoshan Yu",
      "Chuan Qin",
      "Qi Zhang",
      "Chen Zhu",
      "Haiping Ma",
      "Xingyi Zhang",
      "Hengshu Zhu"
    ],
    "abstract": "The rapid development of online recruitment platforms has created\nunprecedented opportunities for job seekers while concurrently posing the\nsignificant challenge of quickly and accurately pinpointing positions that\nalign with their skills and preferences. Job recommendation systems have\nsignificantly alleviated the extensive search burden for job seekers by\noptimizing user engagement metrics, such as clicks and applications, thus\nachieving notable success. In recent years, a substantial amount of research\nhas been devoted to developing effective job recommendation models, primarily\nfocusing on text-matching based and behavior modeling based methods. While\nthese approaches have realized impressive outcomes, it is imperative to note\nthat research on the explainability of recruitment recommendations remains\nprofoundly unexplored. To this end, in this paper, we propose DISCO, a\nhierarchical Disentanglement based Cognitive diagnosis framework, aimed at\nflexibly accommodating the underlying representation learning model for\neffective and interpretable job recommendations. Specifically, we first design\na hierarchical representation disentangling module to explicitly mine the\nhierarchical skill-related factors implied in hidden representations of job\nseekers and jobs. Subsequently, we propose level-aware association modeling to\nenhance information communication and robust representation learning both\ninter- and intra-level, which consists of the interlevel knowledge influence\nmodule and the level-wise contrastive learning. Finally, we devise an\ninteraction diagnosis module incorporating a neural diagnosis function for\neffectively modeling the multi-level recruitment interaction process between\njob seekers and jobs, which introduces the cognitive measurement theory.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by ICDM 2024. 10 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.07671v2",
    "published_date": "2024-10-10 07:29:31 UTC",
    "updated_date": "2024-10-15 15:29:51 UTC"
  },
  {
    "arxiv_id": "2410.16317v1",
    "title": "A Survey on Physical Adversarial Attacks against Face Recognition Systems",
    "authors": [
      "Mingsi Wang",
      "Jiachen Zhou",
      "Tianlin Li",
      "Guozhu Meng",
      "Kai Chen"
    ],
    "abstract": "As Face Recognition (FR) technology becomes increasingly prevalent in\nfinance, the military, public safety, and everyday life, security concerns have\ngrown substantially. Physical adversarial attacks targeting FR systems in\nreal-world settings have attracted considerable research interest due to their\npracticality and the severe threats they pose. However, a systematic overview\nfocused on physical adversarial attacks against FR systems is still lacking,\nhindering an in-depth exploration of the challenges and future directions in\nthis field. In this paper, we bridge this gap by comprehensively collecting and\nanalyzing physical adversarial attack methods targeting FR systems.\nSpecifically, we first investigate the key challenges of physical attacks on FR\nsystems. We then categorize existing physical attacks into three categories\nbased on the physical medium used and summarize how the research in each\ncategory has evolved to address these challenges. Furthermore, we review\ncurrent defense strategies and discuss potential future research directions.\nOur goal is to provide a fresh, comprehensive, and deep understanding of\nphysical adversarial attacks against FR systems, thereby inspiring relevant\nresearch in this area.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16317v1",
    "published_date": "2024-10-10 06:21:44 UTC",
    "updated_date": "2024-10-10 06:21:44 UTC"
  },
  {
    "arxiv_id": "2410.07638v1",
    "title": "Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits",
    "authors": [
      "Yunlong Hou",
      "Vincent Y. F. Tan",
      "Zixin Zhong"
    ],
    "abstract": "We propose a {\\em novel} piecewise stationary linear bandit (PSLB) model,\nwhere the environment randomly samples a context from an unknown probability\ndistribution at each changepoint, and the quality of an arm is measured by its\nreturn averaged over all contexts. The contexts and their distribution, as well\nas the changepoints are unknown to the agent. We design {\\em\nPiecewise-Stationary $\\varepsilon$-Best Arm Identification$^+$}\n(PS$\\varepsilon$BAI$^+$), an algorithm that is guaranteed to identify an\n$\\varepsilon$-optimal arm with probability $\\ge 1-\\delta$ and with a minimal\nnumber of samples. PS$\\varepsilon$BAI$^+$ consists of two subroutines,\nPS$\\varepsilon$BAI and {\\sc Na\\\"ive $\\varepsilon$-BAI} (N$\\varepsilon$BAI),\nwhich are executed in parallel. PS$\\varepsilon$BAI actively detects\nchangepoints and aligns contexts to facilitate the arm identification process.\nWhen PS$\\varepsilon$BAI and N$\\varepsilon$BAI are utilized judiciously in\nparallel, PS$\\varepsilon$BAI$^+$ is shown to have a finite expected sample\ncomplexity. By proving a lower bound, we show the expected sample complexity of\nPS$\\varepsilon$BAI$^+$ is optimal up to a logarithmic factor. We compare\nPS$\\varepsilon$BAI$^+$ to baseline algorithms using numerical experiments which\ndemonstrate its efficiency. Both our analytical and numerical results\ncorroborate that the efficacy of PS$\\varepsilon$BAI$^+$ is due to the delicate\nchange detection and context alignment procedures embedded in\nPS$\\varepsilon$BAI.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "69 pages. Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.07638v1",
    "published_date": "2024-10-10 06:15:42 UTC",
    "updated_date": "2024-10-10 06:15:42 UTC"
  },
  {
    "arxiv_id": "2410.07627v2",
    "title": "Automatic Curriculum Expert Iteration for Reliable LLM Reasoning",
    "authors": [
      "Zirui Zhao",
      "Hanze Dong",
      "Amrita Saha",
      "Caiming Xiong",
      "Doyen Sahoo"
    ],
    "abstract": "Hallucinations (i.e., generating plausible but inaccurate content) and\nlaziness (i.e. excessive refusals or defaulting to \"I don't know\") persist as\nmajor challenges in LLM reasoning. Current efforts to reduce hallucinations\nprimarily focus on factual errors in knowledge-grounded tasks, often neglecting\nhallucinations related to faulty reasoning. Meanwhile, some approaches render\nLLMs overly conservative, limiting their problem-solving capabilities. To\nmitigate hallucination and laziness in reasoning tasks, we propose Automatic\nCurriculum Expert Iteration (Auto-CEI) to enhance LLM reasoning and align\nresponses to the model's capabilities--assertively answering within its limits\nand declining when tasks exceed them. In our method, Expert Iteration explores\nthe reasoning trajectories near the LLM policy, guiding incorrect paths back on\ntrack to reduce compounding errors and improve robustness; it also promotes\nappropriate \"I don't know\" responses after sufficient reasoning attempts. The\ncurriculum automatically adjusts rewards, incentivizing extended reasoning\nbefore acknowledging incapability, thereby pushing the limits of LLM reasoning\nand aligning its behaviour with these limits. We compare Auto-CEI with various\nSOTA baselines across logical reasoning, mathematics, and planning tasks, where\nAuto-CEI achieves superior alignment by effectively balancing assertiveness and\nconservativeness. The code is available at\nhttps://github.com/SalesforceAIResearch/Auto-CEI .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.07627v2",
    "published_date": "2024-10-10 05:43:07 UTC",
    "updated_date": "2025-03-20 05:08:24 UTC"
  },
  {
    "arxiv_id": "2410.09109v1",
    "title": "Compressing high-resolution data through latent representation encoding for downscaling large-scale AI weather forecast model",
    "authors": [
      "Qian Liu",
      "Bing Gong",
      "Xiaoran Zhuang",
      "Xiaohui Zhong",
      "Zhiming Kang",
      "Hao Li"
    ],
    "abstract": "The rapid advancement of artificial intelligence (AI) in weather research has\nbeen driven by the ability to learn from large, high-dimensional datasets.\nHowever, this progress also poses significant challenges, particularly\nregarding the substantial costs associated with processing extensive data and\nthe limitations of computational resources. Inspired by the Neural Image\nCompression (NIC) task in computer vision, this study seeks to compress weather\ndata to address these challenges and enhance the efficiency of downstream\napplications. Specifically, we propose a variational autoencoder (VAE)\nframework tailored for compressing high-resolution datasets, specifically the\nHigh Resolution China Meteorological Administration Land Data Assimilation\nSystem (HRCLDAS) with a spatial resolution of 1 km. Our framework successfully\nreduced the storage size of 3 years of HRCLDAS data from 8.61 TB to just 204\nGB, while preserving essential information. In addition, we demonstrated the\nutility of the compressed data through a downscaling task, where the model\ntrained on the compressed dataset achieved accuracy comparable to that of the\nmodel trained on the original data. These results highlight the effectiveness\nand potential of the compressed data for future weather research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09109v1",
    "published_date": "2024-10-10 05:38:03 UTC",
    "updated_date": "2024-10-10 05:38:03 UTC"
  },
  {
    "arxiv_id": "2410.12846v3",
    "title": "Accurate and Regret-aware Numerical Problem Solver for Tabular Question Answering",
    "authors": [
      "Yuxiang Wang",
      "Jianzhong Qi",
      "Junhao Gan"
    ],
    "abstract": "Question answering on free-form tables (a.k.a. TableQA) is a challenging task\nbecause of the flexible structure and complex schema of tables. Recent studies\nuse Large Language Models (LLMs) for this task, exploiting their capability in\nunderstanding the questions and tabular data, which are typically given in\nnatural language and contain many textual fields, respectively. While this\napproach has shown promising results, it overlooks the challenges brought by\nnumerical values which are common in tabular data, and LLMs are known to\nstruggle with such values. We aim to address this issue, and we propose a model\nnamed TabLaP that uses LLMs as a planner rather than an answer generator. This\napproach exploits LLMs' capability in multi-step reasoning while leaving the\nactual numerical calculations to a Python interpreter for accurate calculation.\nRecognizing the inaccurate nature of LLMs, we further make a first attempt to\nquantify the trustworthiness of the answers produced by TabLaP, such that users\ncan use TabLaP in a regret-aware manner. Experimental results on two benchmark\ndatasets show that TabLaP is substantially more accurate than the\nstate-of-the-art models, improving the answer accuracy by 5.7% and 5.8% on the\ntwo datasets, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12846v3",
    "published_date": "2024-10-10 05:34:00 UTC",
    "updated_date": "2025-02-07 04:36:53 UTC"
  },
  {
    "arxiv_id": "2410.07618v1",
    "title": "Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation",
    "authors": [
      "Kaiyuan Liu",
      "Jiahao Mei",
      "Hengyu Zhang",
      "Yihuai Zhang",
      "Xingjiao Wu",
      "Daoguo Dong",
      "Liang He"
    ],
    "abstract": "Although Chinese calligraphy generation has achieved style transfer,\ngenerating calligraphy by specifying the calligrapher, font, and character\nstyle remains challenging. To address this, we propose a new Chinese\ncalligraphy generation model 'Moyun' , which replaces the Unet in the Diffusion\nmodel with Vision Mamba and introduces the TripleLabel control mechanism to\nachieve controllable calligraphy generation. The model was tested on our\nlarge-scale dataset 'Mobao' of over 1.9 million images, and the results\ndemonstrate that 'Moyun' can effectively control the generation process and\nproduce calligraphy in the specified style. Even for calligraphy the\ncalligrapher has not written, 'Moyun' can generate calligraphy that matches the\nstyle of the calligrapher.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07618v1",
    "published_date": "2024-10-10 05:14:03 UTC",
    "updated_date": "2024-10-10 05:14:03 UTC"
  },
  {
    "arxiv_id": "2410.07610v4",
    "title": "CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features",
    "authors": [
      "Po-han Li",
      "Sandeep P. Chinchali",
      "Ufuk Topcu"
    ],
    "abstract": "Multimodal encoders like CLIP excel in tasks such as zero-shot image\nclassification and cross-modal retrieval. However, they require excessive\ntraining data. We propose canonical similarity analysis (CSA), which uses two\nunimodal encoders to replicate multimodal encoders using limited data. CSA maps\nunimodal features into a multimodal space, using a new similarity score to\nretain only the multimodal information. CSA only involves the inference of\nunimodal encoders and a cubic-complexity matrix decomposition, eliminating the\nneed for extensive GPU-based model training. Experiments show that CSA\noutperforms CLIP while requiring $50,000\\times$ fewer multimodal data pairs to\nbridge the modalities given pre-trained unimodal encoders on ImageNet\nclassification and misinformative news caption detection. CSA surpasses the\nstate-of-the-art method to map unimodal features to multimodal features. We\nalso demonstrate the ability of CSA with modalities beyond image and text,\npaving the way for future modality pairs with limited paired multimodal data\nbut abundant unpaired unimodal data, such as lidar and text.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07610v4",
    "published_date": "2024-10-10 04:54:37 UTC",
    "updated_date": "2025-03-13 20:40:49 UTC"
  },
  {
    "arxiv_id": "2410.19743v1",
    "title": "AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction",
    "authors": [
      "Hongru Wang",
      "Rui Wang",
      "Boyang Xue",
      "Heming Xia",
      "Jingtao Cao",
      "Zeming Liu",
      "Jeff Z. Pan",
      "Kam-Fai Wong"
    ],
    "abstract": "Large Language Models (LLMs) can interact with the real world by connecting\nwith versatile external APIs, resulting in better problem-solving and task\nautomation capabilities. Previous research primarily focuses on APIs with\nlimited arguments from a single source or overlooks the complex dependency\nrelationship between different APIs. However, it is essential to utilize\nmultiple APIs collaboratively from various sources (e.g., different Apps in the\niPhone), especially for complex user instructions. In this paper, we introduce\n\\texttt{AppBench}, the first benchmark to evaluate LLMs' ability to plan and\nexecute multiple APIs from various sources in order to complete the user's\ntask. Specifically, we consider two significant challenges in multiple APIs:\n\\textit{1) graph structures:} some APIs can be executed independently while\nothers need to be executed one by one, resulting in graph-like execution order;\nand \\textit{2) permission constraints:} which source is authorized to execute\nthe API call. We have experimental results on 9 distinct LLMs; e.g., GPT-4o\nachieves only a 2.0\\% success rate at the most complex instruction, revealing\nthat the existing state-of-the-art LLMs still cannot perform well in this\nsituation even with the help of in-context learning and finetuning. Our code\nand data are publicly available at https://github.com/ruleGreen/AppBench.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19743v1",
    "published_date": "2024-10-10 04:03:13 UTC",
    "updated_date": "2024-10-10 04:03:13 UTC"
  },
  {
    "arxiv_id": "2410.07593v2",
    "title": "A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks",
    "authors": [
      "Hoin Jung",
      "Taeuk Jang",
      "Xiaoqian Wang"
    ],
    "abstract": "Recent advancements in Vision-Language Models (VLMs) have enabled complex\nmultimodal tasks by processing text and image data simultaneously,\nsignificantly enhancing the field of artificial intelligence. However, these\nmodels often exhibit biases that can skew outputs towards societal stereotypes,\nthus necessitating debiasing strategies. Existing debiasing methods focus\nnarrowly on specific modalities or tasks, and require extensive retraining. To\naddress these limitations, this paper introduces Selective Feature Imputation\nfor Debiasing (SFID), a novel methodology that integrates feature pruning and\nlow confidence imputation (LCI) to effectively reduce biases in VLMs. SFID is\nversatile, maintaining the semantic integrity of outputs and costly effective\nby eliminating the need for retraining. Our experimental results demonstrate\nSFID's effectiveness across various VLMs tasks including zero-shot\nclassification, text-to-image retrieval, image captioning, and text-to-image\ngeneration, by significantly reducing gender biases without compromising\nperformance. This approach not only enhances the fairness of VLMs applications\nbut also preserves their efficiency and utility across diverse scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 (Spotlight), the Thirty-Eighth Annual Conference on\n  Neural Information Processing Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.07593v2",
    "published_date": "2024-10-10 03:57:48 UTC",
    "updated_date": "2024-10-29 02:16:08 UTC"
  },
  {
    "arxiv_id": "2410.07592v1",
    "title": "Diversified and Adaptive Negative Sampling on Knowledge Graphs",
    "authors": [
      "Ran Liu",
      "Zhongzhou Liu",
      "Xiaoli Li",
      "Hao Wu",
      "Yuan Fang"
    ],
    "abstract": "In knowledge graph embedding, aside from positive triplets (ie: facts in the\nknowledge graph), the negative triplets used for training also have a direct\ninfluence on the model performance. In reality, since knowledge graphs are\nsparse and incomplete, negative triplets often lack explicit labels, and thus\nthey are often obtained from various sampling strategies (eg: randomly\nreplacing an entity in a positive triplet). An ideal sampled negative triplet\nshould be informative enough to help the model train better. However, existing\nmethods often ignore diversity and adaptiveness in their sampling process,\nwhich harms the informativeness of negative triplets. As such, we propose a\ngenerative adversarial approach called Diversified and Adaptive Negative\nSampling DANS on knowledge graphs. DANS is equipped with a two-way generator\nthat generates more diverse negative triplets through two pathways, and an\nadaptive mechanism that produces more fine-grained examples by localizing the\nglobal generator for different entities and relations. On the one hand, the\ntwo-way generator increase the overall informativeness with more diverse\nnegative examples; on the other hand, the adaptive mechanism increases the\nindividual sample-wise informativeness with more fine-grained sampling.\nFinally, we evaluate the performance of DANS on three benchmark knowledge\ngraphs to demonstrate its effectiveness through quantitative and qualitative\nexperiments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures, Journal",
    "pdf_url": "http://arxiv.org/pdf/2410.07592v1",
    "published_date": "2024-10-10 03:53:49 UTC",
    "updated_date": "2024-10-10 03:53:49 UTC"
  },
  {
    "arxiv_id": "2410.09107v1",
    "title": "Federated Learning for Data Market: Shapley-UCB for Seller Selection and Incentives",
    "authors": [
      "Kongyang Chen",
      "Zeming Xu"
    ],
    "abstract": "In recent years, research on the data trading market has been continuously\ndeepened. In the transaction process, there is an information asymmetry process\nbetween agents and sellers. For sellers, direct data delivery faces the risk of\nprivacy leakage. At the same time, sellers are not willing to provide data. A\nreasonable compensation method is needed to encourage sellers to provide data\nresources. For agents, the quality of data provided by sellers needs to be\nexamined and evaluated. Otherwise, agents may consume too much cost and\nresources by recruiting sellers with poor data quality. Therefore, it is\nnecessary to build a complete delivery process for the interaction between\nsellers and agents in the trading market so that the needs of sellers and\nagents can be met. The federated learning architecture is widely used in the\ndata market due to its good privacy protection. Therefore, in this work, in\nresponse to the above challenges, we propose a transaction framework based on\nthe federated learning architecture, and design a seller selection algorithm\nand incentive compensation mechanism. Specifically, we use gradient similarity\nand Shapley algorithm to fairly and accurately evaluate the contribution of\nsellers, and use the modified UCB algorithm to select sellers. After the\ntraining, fair compensation is made according to the seller's participation in\nthe training. In view of the above work, we designed reasonable experiments for\ndemonstration and obtained results, proving the rationality and effectiveness\nof the framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09107v1",
    "published_date": "2024-10-10 03:50:20 UTC",
    "updated_date": "2024-10-10 03:50:20 UTC"
  },
  {
    "arxiv_id": "2410.07582v2",
    "title": "Detecting Training Data of Large Language Models via Expectation Maximization",
    "authors": [
      "Gyuwan Kim",
      "Yang Li",
      "Evangelia Spiliopoulou",
      "Jie Ma",
      "Miguel Ballesteros",
      "William Yang Wang"
    ],
    "abstract": "The advancement of large language models has grown parallel to the opacity of\ntheir training data. Membership inference attacks (MIAs) aim to determine\nwhether specific data was used to train a model. They offer valuable insights\ninto detecting data contamination and ensuring compliance with privacy and\ncopyright standards. However, MIA for LLMs is challenging due to the massive\nscale of training data and the inherent ambiguity of membership in texts.\nMoreover, creating realistic MIA evaluation benchmarks is difficult as training\nand test data distributions are often unknown. We introduce EM-MIA, a novel\nmembership inference method that iteratively refines membership scores and\nprefix scores via an expectation-maximization algorithm. Our approach leverages\nthe observation that these scores can improve each other: membership scores\nhelp identify effective prefixes for detecting training data, while prefix\nscores help determine membership. As a result, EM-MIA achieves state-of-the-art\nresults on WikiMIA. To enable comprehensive evaluation, we introduce OLMoMIA, a\nbenchmark built from OLMo resources, which allows controlling task difficulty\nthrough varying degrees of overlap between training and test data\ndistributions. Our experiments demonstrate EM-MIA is robust across different\nscenarios while also revealing fundamental limitations of current MIA\napproaches when member and non-member distributions are nearly identical.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.07582v2",
    "published_date": "2024-10-10 03:31:16 UTC",
    "updated_date": "2025-04-21 02:22:06 UTC"
  },
  {
    "arxiv_id": "2410.09105v1",
    "title": "Artificial intelligence techniques in inherited retinal diseases: A review",
    "authors": [
      "Han Trinh",
      "Jordan Vice",
      "Jason Charng",
      "Zahra Tajbakhsh",
      "Khyber Alam",
      "Fred K. Chen",
      "Ajmal Mian"
    ],
    "abstract": "Inherited retinal diseases (IRDs) are a diverse group of genetic disorders\nthat lead to progressive vision loss and are a major cause of blindness in\nworking-age adults. The complexity and heterogeneity of IRDs pose significant\nchallenges in diagnosis, prognosis, and management. Recent advancements in\nartificial intelligence (AI) offer promising solutions to these challenges.\nHowever, the rapid development of AI techniques and their varied applications\nhave led to fragmented knowledge in this field. This review consolidates\nexisting studies, identifies gaps, and provides an overview of AI's potential\nin diagnosing and managing IRDs. It aims to structure pathways for advancing\nclinical applications by exploring AI techniques like machine learning and deep\nlearning, particularly in disease detection, progression prediction, and\npersonalized treatment planning. Special focus is placed on the effectiveness\nof convolutional neural networks in these areas. Additionally, the integration\nof explainable AI is discussed, emphasizing its importance in clinical settings\nto improve transparency and trust in AI-based systems. The review addresses the\nneed to bridge existing gaps in focused studies on AI's role in IRDs, offering\na structured analysis of current AI techniques and outlining future research\ndirections. It concludes with an overview of the challenges and opportunities\nin deploying AI for IRDs, highlighting the need for interdisciplinary\ncollaboration and the continuous development of robust, interpretable AI models\nto advance clinical applications.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09105v1",
    "published_date": "2024-10-10 03:14:51 UTC",
    "updated_date": "2024-10-10 03:14:51 UTC"
  },
  {
    "arxiv_id": "2410.07567v2",
    "title": "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context",
    "authors": [
      "Enrique Noriega-Atala",
      "Robert Vacareanu",
      "Salena Torres Ashton",
      "Adarsh Pyarelal",
      "Clayton T. Morrison",
      "Mihai Surdeanu"
    ],
    "abstract": "We introduce a neural architecture finetuned for the task of scenario context\ngeneration: The relevant location and time of an event or entity mentioned in\ntext. Contextualizing information extraction helps to scope the validity of\nautomated finings when aggregating them as knowledge graphs. Our approach uses\na high-quality curated dataset of time and location annotations in a corpus of\nepidemiology papers to train an encoder-decoder architecture. We also explored\nthe use of data augmentation techniques during training. Our findings suggest\nthat a relatively small fine-tuned encoder-decoder model performs better than\nout-of-the-box LLMs and semantic role labeling parsers to accurate predict the\nrelevant scenario information of a particular entity or event.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07567v2",
    "published_date": "2024-10-10 03:05:48 UTC",
    "updated_date": "2024-10-20 17:39:46 UTC"
  },
  {
    "arxiv_id": "2410.07563v2",
    "title": "PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency",
    "authors": [
      "Preferred Elements",
      ":",
      "Kenshin Abe",
      "Kaizaburo Chubachi",
      "Yasuhiro Fujita",
      "Yuta Hirokawa",
      "Kentaro Imajo",
      "Toshiki Kataoka",
      "Hiroyoshi Komatsu",
      "Hiroaki Mikami",
      "Tsuguo Mogami",
      "Shogo Murai",
      "Kosuke Nakago",
      "Daisuke Nishino",
      "Toru Ogawa",
      "Daisuke Okanohara",
      "Yoshihiko Ozaki",
      "Shotaro Sano",
      "Shuji Suzuki",
      "Tianqi Xu",
      "Toshihiko Yanase"
    ],
    "abstract": "We introduce PLaMo-100B, a large-scale language model designed for Japanese\nproficiency. The model was trained from scratch using 2 trillion tokens, with\narchitecture such as QK Normalization and Z-Loss to ensure training stability\nduring the training process. Post-training techniques, including Supervised\nFine-Tuning and Direct Preference Optimization, were applied to refine the\nmodel's performance. Benchmark evaluations suggest that PLaMo-100B performs\nwell, particularly in Japanese-specific tasks, achieving results that are\ncompetitive with frontier models like GPT-4. The base model is available at\nhttps://huggingface.co/pfnet/plamo-100b.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07563v2",
    "published_date": "2024-10-10 02:59:36 UTC",
    "updated_date": "2024-10-22 09:06:38 UTC"
  },
  {
    "arxiv_id": "2410.14715v1",
    "title": "Animating the Past: Reconstruct Trilobite via Video Generation",
    "authors": [
      "Xiaoran Wu",
      "Zien Huang",
      "Chonghan Yu"
    ],
    "abstract": "Paleontology, the study of past life, fundamentally relies on fossils to\nreconstruct ancient ecosystems and understand evolutionary dynamics.\nTrilobites, as an important group of extinct marine arthropods, offer valuable\ninsights into Paleozoic environments through their well-preserved fossil\nrecords. Reconstructing trilobite behaviour from static fossils will set new\nstandards for dynamic reconstructions in scientific research and education.\nDespite the potential, current computational methods for this purpose like\ntext-to-video (T2V) face significant challenges, such as maintaining visual\nrealism and consistency, which hinder their application in science contexts. To\novercome these obstacles, we introduce an automatic T2V prompt learning method.\nWithin this framework, prompts for a fine-tuned video generation model are\ngenerated by a large language model, which is trained using rewards that\nquantify the visual realism and smoothness of the generated video. The\nfine-tuning of the video generation model, along with the reward calculations\nmake use of a collected dataset of 9,088 Eoredlichia intermedia fossil images,\nwhich provides a common representative of visual details of all class of\ntrilobites. Qualitative and quantitative experiments show that our method can\ngenerate trilobite videos with significantly higher visual realism compared to\npowerful baselines, promising to boost both scientific understanding and public\nengagement.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14715v1",
    "published_date": "2024-10-10 02:54:58 UTC",
    "updated_date": "2024-10-10 02:54:58 UTC"
  },
  {
    "arxiv_id": "2410.07553v2",
    "title": "COMMA: A Communicative Multimodal Multi-Agent Benchmark",
    "authors": [
      "Timothy Ossowski",
      "Jixuan Chen",
      "Danyal Maqbool",
      "Zefan Cai",
      "Tyler Bradshaw",
      "Junjie Hu"
    ],
    "abstract": "The rapid advances of multimodal agents built on large foundation models have\nlargely overlooked their potential for language-based communication between\nagents in collaborative tasks. This oversight presents a critical gap in\nunderstanding their effectiveness in real-world deployments, particularly when\ncommunicating with humans. Existing agentic benchmarks fail to address key\naspects of inter-agent communication and collaboration, particularly in\nscenarios where agents have unequal access to information and must work\ntogether to achieve tasks beyond the scope of individual capabilities. To fill\nthis gap, we introduce a novel benchmark designed to evaluate the collaborative\nperformance of multimodal multi-agent systems through language communication.\nOur benchmark features a variety of scenarios, providing a comprehensive\nevaluation across four key categories of agentic capability in a communicative\ncollaboration setting. By testing both agent-agent and agent-human\ncollaborations using open-source and closed-source models, our findings reveal\nsurprising weaknesses in state-of-the-art models, including proprietary models\nlike GPT-4o. Some of these models struggle to outperform even a simple random\nagent baseline in agent-agent collaboration and only surpass the random\nbaseline when a human is involved.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07553v2",
    "published_date": "2024-10-10 02:49:47 UTC",
    "updated_date": "2025-02-06 22:55:46 UTC"
  },
  {
    "arxiv_id": "2410.07551v1",
    "title": "KRAG Framework for Enhancing LLMs in the Legal Domain",
    "authors": [
      "Nguyen Ha Thanh",
      "Ken Satoh"
    ],
    "abstract": "This paper introduces Knowledge Representation Augmented Generation (KRAG), a\nnovel framework designed to enhance the capabilities of Large Language Models\n(LLMs) within domain-specific applications. KRAG points to the strategic\ninclusion of critical knowledge entities and relationships that are typically\nabsent in standard data sets and which LLMs do not inherently learn. In the\ncontext of legal applications, we present Soft PROLEG, an implementation model\nunder KRAG, which uses inference graphs to aid LLMs in delivering structured\nlegal reasoning, argumentation, and explanations tailored to user inquiries.\nThe integration of KRAG, either as a standalone framework or in tandem with\nretrieval augmented generation (RAG), markedly improves the ability of language\nmodels to navigate and solve the intricate challenges posed by legal texts and\nterminologies. This paper details KRAG's methodology, its implementation\nthrough Soft PROLEG, and potential broader applications, underscoring its\nsignificant role in advancing natural language understanding and processing in\nspecialized knowledge domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.07551v1",
    "published_date": "2024-10-10 02:48:06 UTC",
    "updated_date": "2024-10-10 02:48:06 UTC"
  },
  {
    "arxiv_id": "2410.07549v1",
    "title": "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting",
    "authors": [
      "Xukai Liu",
      "Ye Liu",
      "Kai Zhang",
      "Kehang Wang",
      "Qi Liu",
      "Enhong Chen"
    ],
    "abstract": "Entity Linking (EL) is the process of associating ambiguous textual mentions\nto specific entities in a knowledge base. Traditional EL methods heavily rely\non large datasets to enhance their performance, a dependency that becomes\nproblematic in the context of few-shot entity linking, where only a limited\nnumber of examples are available for training. To address this challenge, we\npresent OneNet, an innovative framework that utilizes the few-shot learning\ncapabilities of Large Language Models (LLMs) without the need for fine-tuning.\nTo the best of our knowledge, this marks a pioneering approach to applying LLMs\nto few-shot entity linking tasks. OneNet is structured around three key\ncomponents prompted by LLMs: (1) an entity reduction processor that simplifies\ninputs by summarizing and filtering out irrelevant entities, (2) a\ndual-perspective entity linker that combines contextual cues and prior\nknowledge for precise entity linking, and (3) an entity consensus judger that\nemploys a unique consistency algorithm to alleviate the hallucination in the\nentity linking reasoning. Comprehensive evaluations across seven benchmark\ndatasets reveal that OneNet outperforms current state-of-the-art entity linking\nmethods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2410.07549v1",
    "published_date": "2024-10-10 02:45:23 UTC",
    "updated_date": "2024-10-10 02:45:23 UTC"
  },
  {
    "arxiv_id": "2410.07547v2",
    "title": "HM-DF SNN: Transcending Conventional Online Learning with Advanced Training and Deployment",
    "authors": [
      "Zecheng Hao",
      "Yifan Huang",
      "Zijie Xu",
      "Wenxuan Liu",
      "Yuanhong Tang",
      "Zhaofei Yu",
      "Tiejun Huang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are considered to have enormous potential in\nthe future development of Artificial Intelligence due to their brain-inspired\nand energy-efficient properties. Compared to vanilla Spatial-Temporal\nBack-propagation (STBP) training methods, online training can effectively\novercome the risk of GPU memory explosion. However, current online learning\nframework cannot tackle the inseparability problem of temporal dependent\ngradients and merely aim to optimize the training memory, resulting in no\nperformance advantages compared to the STBP training models in the inference\nphase. To address the aforementioned challenges, we propose Hybrid\nMechanism-Driven Firing (HM-DF) model, which is a family of advanced models\nthat respectively adopt different spiking calculation schemes in the\nupper-region and lower-region of the firing threshold. We point out that HM-DF\nmodel can effectively separate temporal gradients and tackle the mismatch\nproblem of surrogate gradients, as well as achieving full-stage optimization\ntowards computation speed and memory footprint. Experimental results have\ndemonstrated that HM-DF model can be flexibly combined with various techniques\nto achieve state-of-the-art performance in the field of online learning,\nwithout triggering further power consumption.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07547v2",
    "published_date": "2024-10-10 02:39:22 UTC",
    "updated_date": "2025-05-07 10:08:15 UTC"
  },
  {
    "arxiv_id": "2410.07543v1",
    "title": "Generalization Ability Analysis of Through-the-Wall Radar Human Activity Recognition",
    "authors": [
      "Weicheng Gao",
      "Xiaodong Qu",
      "Xiaopeng Yang"
    ],
    "abstract": "Through-the-Wall radar (TWR) human activity recognition (HAR) is a technology\nthat uses low-frequency ultra-wideband (UWB) signal to detect and analyze\nindoor human motion. However, the high dependence of existing end-to-end\nrecognition models on the distribution of TWR training data makes it difficult\nto achieve good generalization across different indoor testers. In this regard,\nthe generalization ability of TWR HAR is analyzed in this paper. In detail, an\nend-to-end linear neural network method for TWR HAR and its generalization\nerror bound are first discussed. Second, a micro-Doppler corner representation\nmethod and the change of the generalization error before and after dimension\nreduction are presented. The appropriateness of the theoretical generalization\nerrors is proved through numerical simulations and experiments. The results\ndemonstrate that feature dimension reduction is effective in allowing\nrecognition models to generalize across different indoor testers.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "94",
      "I.5.1"
    ],
    "primary_category": "eess.SP",
    "comment": "6 pages, 4 figures, 0 table, in Proc. IEEE International Conference\n  on Signal, Information and Data Processing (ICSIDP), 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.07543v1",
    "published_date": "2024-10-10 02:29:10 UTC",
    "updated_date": "2024-10-10 02:29:10 UTC"
  },
  {
    "arxiv_id": "2410.07542v1",
    "title": "Generalizable Indoor Human Activity Recognition Method Based on Micro-Doppler Corner Point Cloud and Dynamic Graph Learning",
    "authors": [
      "Xiaopeng Yang",
      "Weicheng Gao",
      "Xiaodong Qu",
      "Haoyu Meng"
    ],
    "abstract": "Through-the-wall radar (TWR) human activity recognition can be achieved by\nfusing micro-Doppler signature extraction and intelligent decision-making\nalgorithms. However, limited by the insufficient priori of tester in practical\nindoor scenarios, the trained models on one tester are commonly difficult to\ninference well on other testers, which causes poor generalization ability. To\nsolve this problem, this paper proposes a generalizable indoor human activity\nrecognition method based on micro-Doppler corner point cloud and dynamic graph\nlearning. In the proposed method, DoG-{\\mu}D-CornerDet is used for\nmicro-Doppler corner extraction on two types of radar profiles. Then, a\nmicro-Doppler corner filtering method based on polynomial fitting smoothing is\nproposed to maximize the feature distance under the constraints of the\nkinematic model. The extracted corners from the two types of radar profiles are\nconcatenated together into three-dimensional point cloud. Finally, the paper\nproposes a dynamic graph neural network (DGNN)-based recognition method for\ndata-to-activity label mapping. Visualization, comparison and ablation\nexperiments are carried out to verify the effectiveness of the proposed method.\nThe results prove that the proposed method has strong generalization ability on\nradar data collected from different testers.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "94",
      "I.5.1"
    ],
    "primary_category": "eess.SP",
    "comment": "15 pages, 12 figures, 6 tables, in IEEE Transactions on Aerospace and\n  Electronics Systems, 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.07542v1",
    "published_date": "2024-10-10 02:24:07 UTC",
    "updated_date": "2024-10-10 02:24:07 UTC"
  },
  {
    "arxiv_id": "2410.07539v1",
    "title": "Efficient Generation of Molecular Clusters with Dual-Scale Equivariant Flow Matching",
    "authors": [
      "Akshay Subramanian",
      "Shuhui Qu",
      "Cheol Woo Park",
      "Sulin Liu",
      "Janghwan Lee",
      "Rafael Gómez-Bombarelli"
    ],
    "abstract": "Amorphous molecular solids offer a promising alternative to inorganic\nsemiconductors, owing to their mechanical flexibility and solution\nprocessability. The packing structure of these materials plays a crucial role\nin determining their electronic and transport properties, which are key to\nenhancing the efficiency of devices like organic solar cells (OSCs). However,\nobtaining these optoelectronic properties computationally requires molecular\ndynamics (MD) simulations to generate a conformational ensemble, a process that\ncan be computationally expensive due to the large system sizes involved. Recent\nadvances have focused on using generative models, particularly flow-based\nmodels as Boltzmann generators, to improve the efficiency of MD sampling. In\nthis work, we developed a dual-scale flow matching method that separates\ntraining and inference into coarse-grained and all-atom stages and enhances\nboth the accuracy and efficiency of standard flow matching samplers. We\ndemonstrate the effectiveness of this method on a dataset of Y6 molecular\nclusters obtained through MD simulations, and we benchmark its efficiency and\naccuracy against single-scale flow matching methods.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07539v1",
    "published_date": "2024-10-10 02:17:27 UTC",
    "updated_date": "2024-10-10 02:17:27 UTC"
  },
  {
    "arxiv_id": "2410.12845v1",
    "title": "Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data",
    "authors": [
      "Sarvesh Soni",
      "Dina Demner-Fushman"
    ],
    "abstract": "Regular documentation of progress notes is one of the main contributors to\nclinician burden. The abundance of structured chart information in medical\nrecords further exacerbates the burden, however, it also presents an\nopportunity to automate the generation of progress notes. In this paper, we\npropose a task to automate progress note generation using structured or tabular\ninformation present in electronic health records. To this end, we present a\nnovel framework and a large dataset, ChartPNG, for the task which contains\n$7089$ annotation instances (each having a pair of progress notes and interim\nstructured chart data) across $1616$ patients. We establish baselines on the\ndataset using large language models from general and biomedical domains. We\nperform both automated (where the best performing Biomistral model achieved a\nBERTScore F1 of $80.53$ and MEDCON score of $19.61$) and manual (where we found\nthat the model was able to leverage relevant structured data with $76.9\\%$\naccuracy) analyses to identify the challenges with the proposed task and\nopportunities for future research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the AMIA 2024 Annual Symposium",
    "pdf_url": "http://arxiv.org/pdf/2410.12845v1",
    "published_date": "2024-10-10 02:03:27 UTC",
    "updated_date": "2024-10-10 02:03:27 UTC"
  },
  {
    "arxiv_id": "2410.07531v1",
    "title": "Reducing the Cost of Dropout in Flash-Attention by Hiding RNG with GEMM",
    "authors": [
      "Haiyue Ma",
      "Jian Liu",
      "Ronny Krashinsky"
    ],
    "abstract": "Dropout, a network operator, when enabled is likely to dramatically impact\nthe performance of Flash-Attention, which in turn increases the end-to-end\ntraining time of Large-Language-Models (LLMs). The main contributor to such\nperformance degradation is the Random Number Generation (RNG) phase that is\ntraditionally fused into the Flash-Attention kernel. As RNG and Attention have\nthe same hardware bottlenecks, RNG latency can hardly be hidden within the\nAttention kernel.\n  We propose overlapping RNG with previous GEMM layers in the network to hide\nRNG runtime and improve end-to-end performance. RNG and GEMM have distinct\nresource requirements and hardware bottlenecks, so they can run in parallel\nwithout compromising each other's performance. Our fine-grained performance\nmodel, cross-validated by silicon results, shows 1.14x speedup on one\ntransformer block (including multi-head attention and feed-forward layers) for\nLlama2, and up to 1.23x speedup when varying workload sizes, on GH100 GPUs with\nFP8 precision. Further, we extend our theoretical model to different RNG\nimplementations and hardware architectures, and discuss the widely applicable\nbenefits for overlapping RNG with GEMM layers.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07531v1",
    "published_date": "2024-10-10 01:59:06 UTC",
    "updated_date": "2024-10-10 01:59:06 UTC"
  },
  {
    "arxiv_id": "2410.08241v1",
    "title": "LecPrompt: A Prompt-based Approach for Logical Error Correction with CodeBERT",
    "authors": [
      "Zhenyu Xu",
      "Victor S. Sheng"
    ],
    "abstract": "Logical errors in programming don't raise compiler alerts, making them hard\nto detect. These silent errors can disrupt a program's function or cause\nrun-time issues. Their correction requires deep insight into the program's\nlogic, highlighting the importance of automated detection and repair. In this\npaper, we introduce LecPrompt to localize and repair logical errors, an\nprompt-based approach that harnesses the capabilities of CodeBERT, a\ntransformer-based large language model trained on code. First, LecPrompt\nleverages a large language model to calculate perplexity and log probability\nmetrics, pinpointing logical errors at both token and line levels. Through\nstatistical analysis, it identifies tokens and lines that deviate significantly\nfrom the expected patterns recognized by large language models, marking them as\npotential error sources. Second, by framing the logical error correction\nchallenge as a Masked Language Modeling (MLM) task, LecPrompt employs CodeBERT\nto autoregressively repair the identified error tokens. Finally, the\nsoft-prompt method provides a novel solution in low-cost scenarios, ensuring\nthat the model can be fine-tuned to the specific nuances of the logical error\ncorrection task without incurring high computational costs. To evaluate\nLecPrompt's performance, we created a method to introduce logical errors into\ncorrect code and applying this on QuixBugs to produce the QuixBugs-LE dataset.\nOur evaluations on the QuixBugs-LE dataset for both Python and Java highlight\nthe impressive capabilities of our method, LecPrompt. For Python, LecPrompt\nachieves a noteworthy 74.58% top-1 token-level repair accuracy and 27.4%\nprogram-level repair accuracy. In Java, LecPrompt delivers a 69.23\\% top-1\ntoken-level repair accuracy and 24.7% full program-level repair accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08241v1",
    "published_date": "2024-10-10 01:56:04 UTC",
    "updated_date": "2024-10-10 01:56:04 UTC"
  },
  {
    "arxiv_id": "2410.07530v1",
    "title": "Audio Explanation Synthesis with Generative Foundation Models",
    "authors": [
      "Alican Akman",
      "Qiyang Sun",
      "Björn W. Schuller"
    ],
    "abstract": "The increasing success of audio foundation models across various tasks has\nled to a growing need for improved interpretability to understand their\nintricate decision-making processes better. Existing methods primarily focus on\nexplaining these models by attributing importance to elements within the input\nspace based on their influence on the final decision. In this paper, we\nintroduce a novel audio explanation method that capitalises on the generative\ncapacity of audio foundation models. Our method leverages the intrinsic\nrepresentational power of the embedding space within these models by\nintegrating established feature attribution techniques to identify significant\nfeatures in this space. The method then generates listenable audio explanations\nby prioritising the most important features. Through rigorous benchmarking\nagainst standard datasets, including keyword spotting and speech emotion\nrecognition, our model demonstrates its efficacy in producing audio\nexplanations.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07530v1",
    "published_date": "2024-10-10 01:55:58 UTC",
    "updated_date": "2024-10-10 01:55:58 UTC"
  },
  {
    "arxiv_id": "2410.07526v1",
    "title": "MKGL: Mastery of a Three-Word Language",
    "authors": [
      "Lingbing Guo",
      "Zhongpu Bo",
      "Zhuo Chen",
      "Yichi Zhang",
      "Jiaoyan Chen",
      "Yarong Lan",
      "Mengshu Sun",
      "Zhiqiang Zhang",
      "Yangyifei Luo",
      "Qian Li",
      "Qiang Zhang",
      "Wen Zhang",
      "Huajun Chen"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced performance across a\nspectrum of natural language processing (NLP) tasks. Yet, their application to\nknowledge graphs (KGs), which describe facts in the form of triplets and allow\nminimal hallucinations, remains an underexplored frontier. In this paper, we\ninvestigate the integration of LLMs with KGs by introducing a specialized KG\nLanguage (KGL), where a sentence precisely consists of an entity noun, a\nrelation verb, and ends with another entity noun. Despite KGL's unfamiliar\nvocabulary to the LLM, we facilitate its learning through a tailored dictionary\nand illustrative sentences, and enhance context understanding via real-time KG\ncontext retrieval and KGL token embedding augmentation. Our results reveal that\nLLMs can achieve fluency in KGL, drastically reducing errors compared to\nconventional KG embedding methods on KG completion. Furthermore, our enhanced\nLLM shows exceptional competence in generating accurate three-word sentences\nfrom an initial entity and interpreting new unseen terms out of KGs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2410.07526v1",
    "published_date": "2024-10-10 01:39:26 UTC",
    "updated_date": "2024-10-10 01:39:26 UTC"
  },
  {
    "arxiv_id": "2410.07525v2",
    "title": "Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare",
    "authors": [
      "Nan Fang",
      "Guiliang Liu",
      "Wei Gong"
    ],
    "abstract": "Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical\ndecisions and treatment, such as excessive dosages or abrupt changes, often due\nto agents overlooking common-sense constraints. Consequently, Constrained\nReinforcement Learning (CRL) is a natural choice for safe decisions. However,\nspecifying the exact cost function is inherently difficult in healthcare.\nRecent Inverse Constrained Reinforcement Learning (ICRL) is a promising\napproach that infers constraints from expert demonstrations. ICRL algorithms\nmodel Markovian decisions in an interactive environment. These settings do not\nalign with the practical requirement of a decision-making system in healthcare,\nwhere decisions rely on historical treatment recorded in an offline dataset. To\ntackle these issues, we propose the Constraint Transformer (CT). Specifically,\n1) we utilize a causal attention mechanism to incorporate historical decisions\nand observations into the constraint modeling, while employing a Non-Markovian\nlayer for weighted constraints to capture critical states. 2) A generative\nworld model is used to perform exploratory data augmentation, enabling offline\nRL methods to simulate unsafe decision sequences. In multiple medical\nscenarios, empirical results demonstrate that CT can capture unsafe states and\nachieve strategies that approximate lower mortality rates, reducing the\noccurrence probability of unsafe behaviors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07525v2",
    "published_date": "2024-10-10 01:36:27 UTC",
    "updated_date": "2024-10-14 05:25:45 UTC"
  },
  {
    "arxiv_id": "2410.07524v1",
    "title": "Upcycling Large Language Models into Mixture of Experts",
    "authors": [
      "Ethan He",
      "Abhinav Khattar",
      "Ryan Prenger",
      "Vijay Korthikanti",
      "Zijie Yan",
      "Tong Liu",
      "Shiqing Fan",
      "Ashwath Aithal",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "abstract": "Upcycling pre-trained dense language models into sparse mixture-of-experts\n(MoE) models is an efficient approach to increase the model capacity of already\ntrained models. However, optimal techniques for upcycling at scale remain\nunclear. In this work, we conduct an extensive study of upcycling methods and\nhyperparameters for billion-parameter scale language models. We propose a novel\n\"virtual group\" initialization scheme and weight scaling approach to enable\nupcycling into fine-grained MoE architectures. Through ablations, we find that\nupcycling outperforms continued dense model training. In addition, we show that\nsoftmax-then-topK expert routing improves over topK-then-softmax approach and\nhigher granularity MoEs can help improve accuracy. Finally, we upcycled\nNemotron-4 15B on 1T tokens and compared it to a continuously trained version\nof the same model on the same 1T tokens: the continuous trained model achieved\n65.3% MMLU, whereas the upcycled model achieved 67.6%. Our results offer\ninsights and best practices to effectively leverage upcycling for building MoE\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07524v1",
    "published_date": "2024-10-10 01:36:03 UTC",
    "updated_date": "2024-10-10 01:36:03 UTC"
  },
  {
    "arxiv_id": "2410.07523v1",
    "title": "DemoShapley: Valuation of Demonstrations for In-Context Learning",
    "authors": [
      "Shan Xie",
      "Man Luo",
      "Chadly Daniel Stern",
      "Mengnan Du",
      "Lu Cheng"
    ],
    "abstract": "Large language models (LLMs) leveraging in-context learning (ICL) have set\nnew benchmarks in few-shot learning across various tasks without needing\ntask-specific fine-tuning. However, extensive research has demonstrated that\nthe effectiveness of ICL is significantly influenced by the selection and\nordering of demonstrations. Considering the critical role of demonstration\nselection in ICL, we introduce DemoShapley which is inspired by the Data\nShapley valuation theorem. This approach assesses the influence of individual\ndemonstration instances, distinguishing between those that contribute\npositively and those that may hinder performance. Our findings reveal that\nDemoShapley not only enhances model performance in terms of accuracy and\nfairness but also generalizes queries from domains distinct from those of the\nin-context demonstrations, highlighting its versatility and effectiveness in\noptimizing ICL demonstration selection. Last but not least, DemoShapley\ndemonstrates its ability to aid in identifying noisy data within the\ndemonstration set.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07523v1",
    "published_date": "2024-10-10 01:35:03 UTC",
    "updated_date": "2024-10-10 01:35:03 UTC"
  },
  {
    "arxiv_id": "2410.11876v3",
    "title": "Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots",
    "authors": [
      "Jijie Zhou",
      "Eryue Xu",
      "Yaoyao Wu",
      "Tianshi Li"
    ],
    "abstract": "The proliferation of LLM-based conversational agents has resulted in\nexcessive disclosure of identifiable or sensitive information. However,\nexisting technologies fail to offer perceptible control or account for users'\npersonal preferences about privacy-utility tradeoffs due to the lack of user\ninvolvement. To bridge this gap, we designed, built, and evaluated Rescriber, a\nbrowser extension that supports user-led data minimization in LLM-based\nconversational agents by helping users detect and sanitize personal information\nin their prompts. Our studies (N=12) showed that Rescriber helped users reduce\nunnecessary disclosure and addressed their privacy concerns. Users' subjective\nperceptions of the system powered by Llama3-8B were on par with that by GPT-4o.\nThe comprehensiveness and consistency of the detection and sanitization emerge\nas essential factors that affect users' trust and perceived protection. Our\nfindings confirm the viability of smaller-LLM-powered, user-facing, on-device\nprivacy controls, presenting a promising approach to address the privacy and\ntrust challenges of AI.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11876v3",
    "published_date": "2024-10-10 01:23:16 UTC",
    "updated_date": "2025-02-11 19:56:20 UTC"
  },
  {
    "arxiv_id": "2410.07513v1",
    "title": "Evolutionary Contrastive Distillation for Language Model Alignment",
    "authors": [
      "Julian Katz-Samuels",
      "Zheng Li",
      "Hyokun Yun",
      "Priyanka Nigam",
      "Yi Xu",
      "Vaclav Petricek",
      "Bing Yin",
      "Trishul Chilimbi"
    ],
    "abstract": "The ability of large language models (LLMs) to execute complex instructions\nis essential for their real-world applications. However, several recent studies\nindicate that LLMs struggle with challenging instructions. In this paper, we\npropose Evolutionary Contrastive Distillation (ECD), a novel method for\ngenerating high-quality synthetic preference data designed to enhance the\ncomplex instruction-following capability of language models. ECD generates data\nthat specifically illustrates the difference between a response that\nsuccessfully follows a set of complex instructions and a response that is\nhigh-quality, but nevertheless makes some subtle mistakes. This is done by\nprompting LLMs to progressively evolve simple instructions to more complex\ninstructions. When the complexity of an instruction is increased, the original\nsuccessful response to the original instruction becomes a \"hard negative\"\nresponse for the new instruction, mostly meeting requirements of the new\ninstruction, but barely missing one or two. By pairing a good response with\nsuch a hard negative response, and employing contrastive learning algorithms\nsuch as DPO, we improve language models' ability to follow complex\ninstructions. Empirically, we observe that our method yields a 7B model that\nexceeds the complex instruction-following performance of current SOTA 7B models\nand is competitive even with open-source 70B models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07513v1",
    "published_date": "2024-10-10 01:04:03 UTC",
    "updated_date": "2024-10-10 01:04:03 UTC"
  },
  {
    "arxiv_id": "2410.07505v1",
    "title": "CrossQuant: A Post-Training Quantization Method with Smaller Quantization Kernel for Precise Large Language Model Compression",
    "authors": [
      "Wenyuan Liu",
      "Xindian Ma",
      "Peng Zhang",
      "Yan Wang"
    ],
    "abstract": "Post-Training Quantization (PTQ) is an effective technique for compressing\nLarge Language Models (LLMs). While many studies focus on quantizing both\nweights and activations, it is still a challenge to maintain the accuracy of\nLLM after activating quantization. To investigate the primary cause, we extend\nthe concept of kernel from linear algebra to quantization functions to define a\nnew term, \"quantization kernel\", which refers to the set of elements in\nactivations that are quantized to zero. Through quantitative analysis of the\nquantization kernel, we find that these elements are crucial for maintaining\nthe accuracy of quantized LLMs. With the decrease of quantization kernel, the\nprecision of quantized LLMs increases. If the quantization kernel proportion is\nkept below 19% for OPT models and below 1% for LLaMA models, the precision loss\nfrom quantizing activations to INT8 becomes negligible. Motivated by the goal\nof developing a quantization method with small quantization kernel, we propose\nCrossQuant: a simple yet effective method for quantizing activations.\nCrossQuant cross-quantizes elements using row and column-wise absolute maximum\nvectors, achieving a quantization kernel of approximately 16% for OPT models\nand less than 0.1% for LLaMA models. Experimental results on LLMs (LLaMA, OPT)\nranging from 6.7B to 70B parameters demonstrate that CrossQuant improves or\nmaintains perplexity and accuracy in language modeling, zero-shot, and few-shot\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07505v1",
    "published_date": "2024-10-10 00:44:24 UTC",
    "updated_date": "2024-10-10 00:44:24 UTC"
  },
  {
    "arxiv_id": "2410.07504v1",
    "title": "Using LLMs to Discover Legal Factors",
    "authors": [
      "Morgan Gray",
      "Jaromir Savelka",
      "Wesley Oliver",
      "Kevin Ashley"
    ],
    "abstract": "Factors are a foundational component of legal analysis and computational\nmodels of legal reasoning. These factor-based representations enable lawyers,\njudges, and AI and Law researchers to reason about legal cases. In this paper,\nwe introduce a methodology that leverages large language models (LLMs) to\ndiscover lists of factors that effectively represent a legal domain. Our method\ntakes as input raw court opinions and produces a set of factors and associated\ndefinitions. We demonstrate that a semi-automated approach, incorporating\nminimal human involvement, produces factor representations that can predict\ncase outcomes with moderate success, if not yet as well as expert-defined\nfactors can.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.07504v1",
    "published_date": "2024-10-10 00:42:10 UTC",
    "updated_date": "2024-10-10 00:42:10 UTC"
  },
  {
    "arxiv_id": "2410.19742v1",
    "title": "SALINA: Towards Sustainable Live Sonar Analytics in Wild Ecosystems",
    "authors": [
      "Chi Xu",
      "Rongsheng Qian",
      "Hao Fang",
      "Xiaoqiang Ma",
      "William I. Atlas",
      "Jiangchuan Liu",
      "Mark A. Spoljaric"
    ],
    "abstract": "Sonar radar captures visual representations of underwater objects and\nstructures using sound wave reflections, making it essential for exploration,\nmapping, and continuous surveillance in wild ecosystems. Real-time analysis of\nsonar data is crucial for time-sensitive applications, including environmental\nanomaly detection and in-season fishery management, where rapid decision-making\nis needed. However, the lack of both relevant datasets and pre-trained DNN\nmodels, coupled with resource limitations in wild environments, hinders the\neffective deployment and continuous operation of live sonar analytics.\n  We present SALINA, a sustainable live sonar analytics system designed to\naddress these challenges. SALINA enables real-time processing of acoustic sonar\ndata with spatial and temporal adaptations, and features energy-efficient\noperation through a robust energy management module. Deployed for six months at\ntwo inland rivers in British Columbia, Canada, SALINA provided continuous 24/7\nunderwater monitoring, supporting fishery stewardship and wildlife restoration\nefforts. Through extensive real-world testing, SALINA demonstrated an up to\n9.5% improvement in average precision and a 10.1% increase in tracking metrics.\nThe energy management module successfully handled extreme weather, preventing\noutages and reducing contingency costs. These results offer valuable insights\nfor long-term deployment of acoustic data systems in the wild.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "eess.SP",
    "comment": "14 pages, accepted by ACM SenSys 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19742v1",
    "published_date": "2024-10-10 00:32:28 UTC",
    "updated_date": "2024-10-10 00:32:28 UTC"
  },
  {
    "arxiv_id": "2410.07499v1",
    "title": "Dense Optimizer : An Information Entropy-Guided Structural Search Method for Dense-like Neural Network Design",
    "authors": [
      "Liu Tianyuan",
      "Hou Libin",
      "Wang Linyuan",
      "Song Xiyu",
      "Yan Bin"
    ],
    "abstract": "Dense Convolutional Network has been continuously refined to adopt a highly\nefficient and compact architecture, owing to its lightweight and efficient\nstructure. However, the current Dense-like architectures are mainly designed\nmanually, it becomes increasingly difficult to adjust the channels and reuse\nlevel based on past experience. As such, we propose an architecture search\nmethod called Dense Optimizer that can search high-performance dense-like\nnetwork automatically. In Dense Optimizer, we view the dense network as a\nhierarchical information system, maximize the network's information entropy\nwhile constraining the distribution of the entropy across each stage via a\npower law, thereby constructing an optimization problem. We also propose a\nbranch-and-bound optimization algorithm, tightly integrates power-law principle\nwith search space scaling to solve the optimization problem efficiently. The\nsuperiority of Dense Optimizer has been validated on different computer vision\nbenchmark datasets. Specifically, Dense Optimizer completes high-quality search\nbut only costs 4 hours with one CPU. Our searched model DenseNet-OPT achieved a\ntop 1 accuracy of 84.3% on CIFAR-100, which is 5.97% higher than the original\none.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "7 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.07499v1",
    "published_date": "2024-10-10 00:23:34 UTC",
    "updated_date": "2024-10-10 00:23:34 UTC"
  }
]