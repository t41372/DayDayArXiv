{
  "date": "2024-10-10",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-10 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 167 篇论文，主要聚焦于 AI 模型优化（如 LLM 对齐和鲁棒性）、强化学习应用、多模态生成模型，以及跨领域应用如医疗和机器人领域，其中令人印象深刻的文章包括 LLM 在复杂任务中的改进（如 Tree Preference Optimization）和多代理协作框架（Diversity of Thought），并有知名学者如 Toby Walsh 和 Percy Liang 参与的相关工作。\n\n以下是今日论文的精选摘要，我会优先讨论重要、创新性和话题度高的论文（如 LLM 优化和医疗应用），并快速掠过较常规或次要的文章。每篇论文会列出标题（中文 + 英文），并简要描述主要贡献和发现。\n\n### LLM 和模型优化相关（重点讨论，创新性强）\n- **Tree Preference Optimization: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees**（TPO: 使用多分支多步偏好树对齐大型语言模型）  \n  作者包括 Yasha Wang，这篇论文提出 TPO 方法，通过多分支偏好树优化 LLM 的复杂推理（如数学任务），显著提升了模型在 GSM-8K 等数据集上的性能，贡献在于更全面的偏好学习，超越了传统 DPO 算法。\n\n- **Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks**（多样化思维提升多代理辩论框架的推理能力）  \n  作者 Mahmood Hegazy 探索了多代理辩论中多样化模型的益处，发现使用不同模型（如 Gemini-Pro 和 PaLM 2）能提升数学推理准确率至 91%，主要发现是代理多样性带来新涌现能力，远超单一模型。\n\n- **Agents Thinking Fast and Slow: A Talker-Reasoner Architecture**（代理快速与缓慢思考：对话-推理架构）  \n  作者包括 Maja Matarić，这篇工作引入了类似 Kahneman 理论的架构，将 LLM 分成快速对话代理和缓慢推理代理，提高了任务规划效率，适用于现实应用如睡眠指导。\n\n- **From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions**（从探索到精通：通过自驱动交互让 LLM 掌握工具）  \n  这篇论文提出 DRAFT 框架，使用试错和反馈迭代优化 LLM 与工具的交互，显著提升了工具使用现实性和效率，贡献在于自适应提示设计。\n\n- **Merging in a Bottle: Differentiable Adaptive Merging (DAM) and the Path from Averaging to Automation**（瓶中合并：可微适配合并和从平均到自动化的路径）  \n  作者开发了 DAM 方法，通过可微分优化合并模型参数，改进了模型融合效率，实验显示在高相似性模型上与简单平均法相当，但更自动化。\n\n其他 LLM 相关论文（如 Prompt Engineering 和 KV Prediction）快速掠过：这些工作优化了提示设计和缓存预测，提升 LLM 效率，但贡献较为具体，未见重大突破。\n\n### 强化学习和决策相关（有影响，快速讨论）\n- **TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees**（已在上文讨论，此处略过细节）  \n  此外，论文如 \"UNIQ: Offline Inverse Q-learning for Avoiding Undesirable Demonstrations\" 提出逆强化学习方法，避免负面行为，贡献在于离线优化决策。\n\n- **Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks**（已讨论）  \n  其他如 \"Agents Thinking Fast and Slow\" 在多代理协作中应用强化学习，快速掠过。\n\n快速掠过其他强化学习论文（如 \"Evolutionary Contrastive Distillation\"），这些工作改善了代理训练，但未有显著新颖性。\n\n### 多模态和应用相关（跨领域，印象深刻）\n- **VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis**（VoxelPrompt: 一种用于 grounded 医学图像分析的视觉-语言代理）  \n  作者包括 John V. Guttag，这篇论文创新性地结合视觉和语言代理分析 3D 医学图像，如 MRI 分割，贡献在于无需任务特定微调即可处理多种医学任务，准确性与专业模型相当。\n\n- **AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning**（AgroGPT: 高效农业视觉-语言模型通过专家调优）  \n  这篇工作创建了 AgroInstruct 数据集并训练 AgroGPT 模型，用于农业图像分析，显著提升了细粒度概念识别，WACV 2025 接受，贡献在于解决农业领域数据缺失问题。\n\n- **KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data**（KnowGraph: 通过图数据逻辑推理的知识增强异常检测）  \n  作者包括 Bo Li，这篇论文整合统计学习和概率图模型检测图数据异常（如欺诈），实验显示在真实数据集上精度大幅提升，ACM CCS 2024 接受。\n\n其他应用论文（如 \"Mars: Situated Inductive Reasoning\" 和 \"FusionSense\"）快速掠过：这些探索了机器人和生成模型在环境感知中的应用，但影响力较局限于特定领域。\n\n### 其他领域快速总结\n今日还有许多论文涉及生成模型优化（如 \"LatteCLIP\" 和 \"MathCoder2\"，提升了图像和数学生成能力）和安全（如 \"REDO: Execution-Free Runtime Error Detection\"，检测代码错误），但这些工作较为常规，仅在特定任务中有所改进。论文如 \"Promptly Yours?\" 和 \"The Effects of Hallucinations\" 讨论了 AI 生成内容的偏见和幻觉问题，值得关注但未有突破性发现。\n\n总之，今天的更新突出了 LLM 和多代理系统的优化潜力，尤其在推理和应用领域的进展，建议关注 TPO 和 VoxelPrompt 等创新工作。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.21280v1",
      "title": "TraderTalk: An LLM Behavioural ABM applied to Simulating Human Bilateral Trading Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Alicia Vidler",
        "Toby Walsh"
      ],
      "abstract": "We introduce a novel hybrid approach that augments Agent-Based Models (ABMs)\nwith behaviors generated by Large Language Models (LLMs) to simulate human\ntrading interactions. We call our model TraderTalk. Leveraging LLMs trained on\nextensive human-authored text, we capture detailed and nuanced representations\nof bilateral conversations in financial trading. Applying this Generative\nAgent-Based Model (GABM) to government bond markets, we replicate trading\ndecisions between two stylised virtual humans. Our method addresses both\nstructural challenges, such as coordinating turn-taking between realistic\nLLM-based agents, and design challenges, including the interpretation of LLM\noutputs by the agent model. By exploring prompt design opportunistically rather\nthan systematically, we enhance the realism of agent interactions without\nexhaustive overfitting or model reliance. Our approach successfully replicates\ntrade-to-order volume ratios observed in related asset markets, demonstrating\nthe potential of LLM-augmented ABMs in financial simulations",
      "tldr_zh": "我们引入了 TraderTalk，一种将 Agent-Based Models (ABMs) 与 Large Language Models (LLMs) 结合的混合方法，用于模拟人类双边交易互动。该方法利用 LLMs 训练的数据捕捉金融交易对话的细微细节，并在政府债券市场中模拟两个虚拟人类的交易决策，同时解决了代理协调（如轮流发言）和输出解释等挑战。通过灵活的提示设计而非过度拟合，我们成功复制了相关资产市场的贸易到订单量比率，证明了 Generative Agent-Based Model (GABM) 在金融模拟中的潜力。",
      "categories": [
        "q-fin.TR",
        "cs.AI"
      ],
      "primary_category": "q-fin.TR",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.21280v1",
      "published_date": "2024-10-10 23:58:07 UTC",
      "updated_date": "2024-10-10 23:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:29:40.152254"
    },
    {
      "arxiv_id": "2410.08406v1",
      "title": "Promptly Yours? A Human Subject Study on Prompt Inference in AI-Generated Art",
      "title_zh": "翻译失败",
      "authors": [
        "Khoi Trinh",
        "Joseph Spracklen",
        "Raveen Wijewickrama",
        "Bimal Viswanath",
        "Murtuza Jadliwala",
        "Anindya Maiti"
      ],
      "abstract": "The emerging field of AI-generated art has witnessed the rise of prompt\nmarketplaces, where creators can purchase, sell, or share prompts for\ngenerating unique artworks. These marketplaces often assert ownership over\nprompts, claiming them as intellectual property. This paper investigates\nwhether concealed prompts sold on prompt marketplaces can be considered as\nsecure intellectual property, given that humans and AI tools may be able to\napproximately infer the prompts based on publicly advertised sample images\naccompanying each prompt on sale. Specifically, our survey aims to assess (i)\nhow accurately can humans infer the original prompt solely by examining an\nAI-generated image, with the goal of generating images similar to the original\nimage, and (ii) the possibility of improving upon individual human and AI\nprompt inferences by crafting human-AI combined prompts with the help of a\nlarge language model. Although previous research has explored the use of AI and\nmachine learning to infer (and also protect against) prompt inference, we are\nthe first to include humans in the loop. Our findings indicate that while\nhumans and human-AI collaborations can infer prompts and generate similar\nimages with high accuracy, they are not as successful as using the original\nprompt.",
      "tldr_zh": "本文研究AI生成艺术中的prompt市场，探讨这些prompt是否能作为安全知识产权，因为人类和AI可能通过公开样本图像推断原prompt。研究通过人类主题调查评估了（i）人类仅凭AI生成图像的准确性来推断prompt并生成类似图像，以及（ii）利用大语言模型的人类-AI协作是否能提升推断效果。该研究首次将人类纳入prompt inference的分析中，发现人类和人类-AI协作虽能高准确度推断prompt并生成相似图像，但整体效果仍不如使用原prompt。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08406v1",
      "published_date": "2024-10-10 22:41:13 UTC",
      "updated_date": "2024-10-10 22:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:29:51.085943"
    },
    {
      "arxiv_id": "2410.08405v2",
      "title": "AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Awais",
        "Ali Husain Salem Abdulla Alharthi",
        "Amandeep Kumar",
        "Hisham Cholakkal",
        "Rao Muhammad Anwer"
      ],
      "abstract": "Significant progress has been made in advancing large multimodal\nconversational models (LMMs), capitalizing on vast repositories of image-text\ndata available online. Despite this progress, these models often encounter\nsubstantial domain gaps, hindering their ability to engage in complex\nconversations across new domains. Recent efforts have aimed to mitigate this\nissue, albeit relying on domain-specific image-text data to curate\ninstruction-tuning data. However, many domains, such as agriculture, lack such\nvision-language data. In this work, we propose an approach to construct\ninstruction-tuning data that harnesses vision-only data for the agriculture\ndomain. We utilize diverse agricultural datasets spanning multiple domains,\ncurate class-specific information, and employ large language models (LLMs) to\nconstruct an expert-tuning set, resulting in a 70k expert-tuning dataset called\nAgroInstruct. Subsequently, we expert-tuned and created AgroGPT, an efficient\nLMM that can hold complex agriculture-related conversations and provide useful\ninsights. We also develop AgroEvals for evaluation and compare {AgroGPT's}\nperformance with large open and closed-source models. {AgroGPT} excels at\nidentifying fine-grained agricultural concepts, can act as an agriculture\nexpert, and provides helpful information for multimodal agriculture questions.\nThe code, datasets, and models are available at\nhttps://github.com/awaisrauf/agroGPT.",
      "tldr_zh": "该论文针对农业领域缺乏视觉语言数据的问题，提出了一种利用仅视觉数据构建指令调整数据集的方法，创建了70k的AgroInstruct数据集，并通过大型语言模型(LLMs)进行专家调整，开发了高效的农业视觉语言模型AgroGPT。AgroGPT能够处理复杂的农业相关对话，提供有用见解，并在识别细粒度农业概念和多模态问题上表现出色。相比大型开源和闭源模型，AgroGPT在AgroEvals评估中表现出优越性能，代码、数据集和模型已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV, 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08405v2",
      "published_date": "2024-10-10 22:38:26 UTC",
      "updated_date": "2025-01-09 18:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:30:05.706808"
    },
    {
      "arxiv_id": "2410.12854v2",
      "title": "TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees",
      "title_zh": "TPO：使用多分支",
      "authors": [
        "Weibin Liao",
        "Xu Chu",
        "Yasha Wang"
      ],
      "abstract": "In the domain of complex reasoning tasks, such as mathematical reasoning,\nrecent advancements have proposed the use of Direct Preference Optimization\n(DPO) to suppress output of dispreferred responses, thereby enhancing the\nlong-chain reasoning capabilities of large language models (LLMs). To this end,\nthese studies employed LLMs to generate preference trees via Tree-of-thoughts\n(ToT) and sample the paired preference responses required by the DPO algorithm.\nHowever, the DPO algorithm based on binary preference optimization is unable to\nlearn multiple responses with varying degrees of preference/dispreference that\nprovided by the preference trees, resulting in incomplete preference learning.\nIn this work, we introduce Tree Preference Optimization (TPO), that does not\nsample paired preference responses from the preference tree; instead, it\ndirectly learns from the entire preference tree during the fine-tuning.\nSpecifically, TPO formulates the language model alignment as a Preference List\nRanking problem, where the policy can potentially learn more effectively from a\nranked preference list of responses given the prompt. In addition, to further\nassist LLMs in identifying discriminative steps within long-chain reasoning and\nincrease the relative reward margin in the preference list, TPO utilizes\nAdaptive Step Reward to adjust the reward values of each step in trajectory for\nperforming fine-grained preference optimization. We carry out extensive\nexperiments on mathematical reasoning tasks to evaluate TPO. The experimental\nresults indicate that TPO consistently outperforms DPO across five public large\nlanguage models on four datasets.",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在复杂推理任务中的偏好优化问题，提出Tree Preference Optimization (TPO)方法，以解决Direct Preference Optimization (DPO)基于二元偏好的局限性，无法充分利用Tree-of-thoughts (ToT)生成的偏好树。TPO将语言模型对齐转化为Preference List Ranking问题，直接从整个偏好树学习响应排名，从而实现更有效的多分支和多步骤偏好优化；同时，引入Adaptive Step Reward机制来调整推理轨迹中每个步骤的奖励值，进行细粒度优化。实验结果显示，TPO在四个数据集上 consistently outperforms DPO，并在五个公共LLMs上表现出色，提升了数学推理等任务的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12854v2",
      "published_date": "2024-10-10 22:22:05 UTC",
      "updated_date": "2025-03-13 06:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:30:15.891526"
    },
    {
      "arxiv_id": "2410.08397v1",
      "title": "VoxelPrompt: A Vision-Language Agent for Grounded Medical Image Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Hoopes",
        "Victor Ion Butoi",
        "John V. Guttag",
        "Adrian V. Dalca"
      ],
      "abstract": "We present VoxelPrompt, an agent-driven vision-language framework that\ntackles diverse radiological tasks through joint modeling of natural language,\nimage volumes, and analytical metrics. VoxelPrompt is multi-modal and\nversatile, leveraging the flexibility of language interaction while providing\nquantitatively grounded image analysis. Given a variable number of 3D medical\nvolumes, such as MRI and CT scans, VoxelPrompt employs a language agent that\niteratively predicts executable instructions to solve a task specified by an\ninput prompt. These instructions communicate with a vision network to encode\nimage features and generate volumetric outputs (e.g., segmentations).\nVoxelPrompt interprets the results of intermediate instructions and plans\nfurther actions to compute discrete measures (e.g., tumor growth across a\nseries of scans) and present relevant outputs to the user. We evaluate this\nframework in a sandbox of diverse neuroimaging tasks, and we show that the\nsingle VoxelPrompt model can delineate hundreds of anatomical and pathological\nfeatures, measure many complex morphological properties, and perform\nopen-language analysis of lesion characteristics. VoxelPrompt carries out these\nobjectives with accuracy similar to that of fine-tuned, single-task models for\nsegmentation and visual question-answering, while facilitating a much larger\nrange of tasks. Therefore, by supporting accurate image processing with\nlanguage interaction, VoxelPrompt provides comprehensive utility for numerous\nimaging tasks that traditionally require specialized models to address.",
      "tldr_zh": "本文提出VoxelPrompt，一种基于视觉语言代理的框架，用于处理各种放射学任务，通过联合建模自然语言、图像体积和分析指标，提供定量的医疗图像分析。框架利用语言代理迭代预测可执行指令，与视觉网络交互，编码3D医疗图像（如MRI和CT scans）的特征，生成体积输出（如segmentation），并计算离散测量（如肿瘤生长）。实验结果显示，VoxelPrompt模型在神经影像任务中能准确划分数百种解剖和病理特征、测量复杂形态属性，并支持开放语言分析，其性能与微调的单任务模型相当，但覆盖更广泛的任务，提供更全面的实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "21 pages, 5 figures, vision-language agent, medical image analysis,\n  neuroimage foundation model",
      "pdf_url": "http://arxiv.org/pdf/2410.08397v1",
      "published_date": "2024-10-10 22:11:43 UTC",
      "updated_date": "2024-10-10 22:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:30:29.015510"
    },
    {
      "arxiv_id": "2410.08393v1",
      "title": "The Effects of Hallucinations in Synthetic Training Data for Relation Extraction",
      "title_zh": "合成训练数据中幻觉对关系抽取的影响",
      "authors": [
        "Steven Rogulsky",
        "Nicholas Popovic",
        "Michael Färber"
      ],
      "abstract": "Relation extraction is crucial for constructing knowledge graphs, with large\nhigh-quality datasets serving as the foundation for training, fine-tuning, and\nevaluating models. Generative data augmentation (GDA) is a common approach to\nexpand such datasets. However, this approach often introduces hallucinations,\nsuch as spurious facts, whose impact on relation extraction remains\nunderexplored. In this paper, we examine the effects of hallucinations on the\nperformance of relation extraction on the document and sentence levels. Our\nempirical study reveals that hallucinations considerably compromise the ability\nof models to extract relations from text, with recall reductions between 19.1%\nand 39.2%. We identify that relevant hallucinations impair the model's\nperformance, while irrelevant hallucinations have a minimal impact.\nAdditionally, we develop methods for the detection of hallucinations to improve\ndata quality and model performance. Our approaches successfully classify texts\nas either 'hallucinated' or 'clean,' achieving high F1-scores of 83.8% and\n92.2%. These methods not only assist in removing hallucinations but also help\nin estimating their prevalence within datasets, which is crucial for selecting\nhigh-quality data. Overall, our work confirms the profound impact of relevant\nhallucinations on the effectiveness of relation extraction models.",
      "tldr_zh": "这篇论文探讨了生成数据增强(GDA)中幻觉(Hallucinations)对关系提取(Relation Extraction)任务的影响，揭示幻觉会显著降低模型性能，导致召回率下降19.1%至39.2%，尤其是相关幻觉，而无关幻觉的影响较小。研究通过实证分析在文档和句子级别评估了这些效果，并开发了检测幻觉的方法，这些方法能准确分类文本为“幻觉”或“干净”，F1分数高达92.2%。总体贡献在于确认幻觉对模型有效性的深刻影响，并提供工具来提升数据质量和训练效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at KBC-LM@ISWC'24",
      "pdf_url": "http://arxiv.org/pdf/2410.08393v1",
      "published_date": "2024-10-10 22:00:16 UTC",
      "updated_date": "2024-10-10 22:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:30:50.588678"
    },
    {
      "arxiv_id": "2410.12853v2",
      "title": "Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmood Hegazy"
      ],
      "abstract": "Large language models (LLMs) excel in natural language generation but often\nconfidently produce incorrect responses, especially in tasks like mathematical\nreasoning. Chain-of-thought prompting, self-verification, and multi-agent\ndebate are among the strategies proposed to improve the reasoning and factual\naccuracy of LLMs. Building on Du et al.'s multi-agent debate framework, we find\nthat multi-agent debate helps at any model scale, and that diversity of thought\nelicits stronger reasoning in debating LLMs. Across various model sizes,\nperformance on mathematical reasoning tasks benefits most when diverse trained\nmodels are used. Remarkably, after 4 rounds of debate, a diverse set of\nmedium-capacity models (Gemini-Pro, Mixtral 7BX8, and PaLM 2-M) outperforms\nGPT-4 on the GSM-8K benchmark, scoring 91% accuracy. By comparison, when 3\ninstances of Gemini-Pro are used, performance only reaches 82%. Finally, this\ndiverse set of medium-capacity models sets a new state-of-the-art performance\non the ASDiv benchmark (94%). These results underscore the idea that the future\nof AI is agentic, with diverse cooperating agents yielding emergent\ncapabilities beyond even the most powerful individual models.",
      "tldr_zh": "本研究扩展了多智能体辩论框架，发现思想多样性能显著提升大型语言模型(LLMs)的推理能力，尤其在数学推理任务中。通过使用多样化训练模型（如Gemini-Pro、Mixtral 7BX8和PaLM 2-M）进行辩论，实验显示在GSM-8K基准上，4轮辩论后这些中容量模型组合达到91%准确率，超过GPT-4，而使用多个相同模型实例仅为82%。此外，该组合在ASDiv基准上设定了新的最先进性能（94%）。这些结果突显了多样化代理合作在AI中的潜力，能产生超越单个强大模型的emergent能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.12853v2",
      "published_date": "2024-10-10 21:59:01 UTC",
      "updated_date": "2025-01-23 22:22:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:30:53.156117"
    },
    {
      "arxiv_id": "2410.08391v1",
      "title": "KV Prediction for Improved Time to First Token",
      "title_zh": "KV 预测用于改进首 Token 时间",
      "authors": [
        "Maxwell Horton",
        "Qingqing Cao",
        "Chenfan Sun",
        "Yanzi Jin",
        "Sachin Mehta",
        "Mohammad Rastegari",
        "Moin Nabi"
      ],
      "abstract": "Inference with transformer-based language models begins with a prompt\nprocessing step. In this step, the model generates the first output token and\nstores the KV cache needed for future generation steps. This prompt processing\nstep can be computationally expensive, taking 10s of seconds or more for\nbillion-parameter models on edge devices when prompt lengths or batch sizes\nrise. This degrades user experience by introducing significant latency into the\nmodel's outputs. To reduce the time spent producing the first output (known as\nthe ``time to first token'', or TTFT) of a pretrained model, we introduce a\nnovel method called KV Prediction. In our method, a small auxiliary model is\nused to process the prompt and produce an approximation of the KV cache used by\na base model. This approximated KV cache is then used with the base model for\nautoregressive generation without the need to query the auxiliary model again.\nWe demonstrate that our method produces a pareto-optimal efficiency-accuracy\ntrade-off when compared to baselines. On TriviaQA, we demonstrate relative\naccuracy improvements in the range of $15\\%-50\\%$ across a range of TTFT FLOPs\nbudgets. We also demonstrate accuracy improvements of up to $30\\%$ on HumanEval\npython code completion at fixed TTFT FLOPs budgets. Additionally, we benchmark\nmodels on an Apple M2 Pro CPU and demonstrate that our improvement in FLOPs\ntranslates to a TTFT speedup on hardware. We release our code at\nhttps://github.com/apple/corenet/tree/main/projects/kv-prediction .",
      "tldr_zh": "该论文针对Transformer-based语言模型的提示处理步骤中Time to First Token (TTFT)延迟问题，提出了一种名为KV Prediction的新方法。该方法使用小型辅助模型处理提示并生成KV cache的近似值，从而加速基模型的自回归生成过程，而无需进一步查询辅助模型。在TriviaQA基准上，该方法在不同TTFT FLOPs预算下实现了15%-50%的相对准确率提升，并在HumanEval代码补全任务中提高了up to 30%的准确率。此外，实验在Apple M2 Pro CPU上验证了其实际TTFT加速效果，并展示了效率-准确性的Pareto-optimal权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08391v1",
      "published_date": "2024-10-10 21:55:11 UTC",
      "updated_date": "2024-10-10 21:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:31:03.527990"
    },
    {
      "arxiv_id": "2410.08390v1",
      "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data",
      "title_zh": "KnowGraph: 基于知识的逻辑推理在图数据上的异常检测",
      "authors": [
        "Andy Zhou",
        "Xiaojun Xu",
        "Ramesh Raghunathan",
        "Alok Lal",
        "Xinze Guan",
        "Bin Yu",
        "Bo Li"
      ],
      "abstract": "Graph-based anomaly detection is pivotal in diverse security applications,\nsuch as fraud detection in transaction networks and intrusion detection for\nnetwork traffic. Standard approaches, including Graph Neural Networks (GNNs),\noften struggle to generalize across shifting data distributions. Meanwhile,\nreal-world domain knowledge is more stable and a common existing component of\nreal-world detection strategies. To explicitly integrate such knowledge into\ndata-driven models such as GCNs, we propose KnowGraph, which integrates domain\nknowledge with data-driven learning for enhanced graph-based anomaly detection.\nKnowGraph comprises two principal components: (1) a statistical learning\ncomponent that utilizes a main model for the overarching detection task,\naugmented by multiple specialized knowledge models that predict domain-specific\nsemantic entities; (2) a reasoning component that employs probabilistic\ngraphical models to execute logical inferences based on model outputs, encoding\ndomain knowledge through weighted first-order logic formulas. Extensive\nexperiments on these large-scale real-world datasets show that KnowGraph\nconsistently outperforms state-of-the-art baselines in both transductive and\ninductive settings, achieving substantial gains in average precision when\ngeneralizing to completely unseen test graphs. Further ablation studies\ndemonstrate the effectiveness of the proposed reasoning component in improving\ndetection performance, especially under extreme class imbalance. These results\nhighlight the potential of integrating domain knowledge into data-driven models\nfor high-stakes, graph-based security applications.",
      "tldr_zh": "本文提出 KnowGraph，一种将领域知识整合到数据驱动模型（如 GCNs）中的框架，用于提升图-based anomaly detection 的性能，解决标准方法如 GNNs 在数据分布变化时的泛化问题。KnowGraph 包括统计学习组件（主模型结合多个知识模型预测领域特定实体）和推理组件（利用 probabilistic graphical models 和 weighted first-order logic formulas 进行逻辑推理）。在大型真实数据集上的实验表明，KnowGraph 在 transductive 和 inductive 设置中显著优于现有基线，平均精度有实质性提升，尤其在泛化到未见测试图时。消融研究进一步证明，推理组件在极端类别不平衡场景下特别有效，为高风险图-based 安全应用（如欺诈检测）提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to ACM CCS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08390v1",
      "published_date": "2024-10-10 21:53:33 UTC",
      "updated_date": "2024-10-10 21:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:31:17.254954"
    },
    {
      "arxiv_id": "2410.08388v4",
      "title": "The GUS Framework: Benchmarking Social Bias Classification with Discriminative (Encoder-Only) and Generative (Decoder-Only) Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Maximus Powers",
        "Shaina Raza",
        "Alex Chang",
        "Umang Mavani",
        "Harshitha Reddy Jonala",
        "Ansh Tiwari",
        "Hua Wei"
      ],
      "abstract": "The detection of social bias in text is a critical challenge, particularly\ndue to the limitations of binary classification methods. These methods often\noversimplify nuanced biases, leading to high emotional impact when content is\nmisclassified as either \"biased\" or \"fair.\" To address these shortcomings, we\npropose a more nuanced framework that focuses on three key linguistic\ncomponents underlying social bias: Generalizations, Unfairness, and Stereotypes\n(the GUS framework). The GUS framework employs a semi-automated approach to\ncreate a comprehensive synthetic dataset, which is then verified by humans to\nmaintain ethical standards. This dataset enables robust multi-label token\nclassification. Our methodology, which combines discriminative (encoder-only)\nmodels and generative (auto-regressive large language models), identifies\nbiased entities in text. Through extensive experiments, we demonstrate that\nencoder-only models are effective for this complex task, often outperforming\nstate-of-the-art methods, both in terms of macro and entity-wise F1-score and\nHamming loss. These findings can guide the choice of model for different use\ncases, highlighting the GUS framework's effectiveness in capturing explicit and\nimplicit biases across diverse contexts, and offering a pathway for future\nresearch and applications in various fields.",
      "tldr_zh": "这篇论文提出 GUS framework，用于基准测试社会偏见分类，聚焦于文本中的三大关键成分：Generalizations、Unfairness 和 Stereotypes，以克服二元分类方法的局限性。框架通过半自动化方法创建合成数据集，并结合 discriminative (encoder-only) 模型和 generative (decoder-only) 语言模型进行多标签 token 分类，识别偏见实体。实验结果显示，encoder-only 模型在宏 F1-score、实体-wise F1-score 和 Hamming loss 上优于现有方法，展示了框架在捕捉显性和隐性偏见方面的有效性，并为未来应用提供指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08388v4",
      "published_date": "2024-10-10 21:51:22 UTC",
      "updated_date": "2025-02-28 18:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:31:28.667338"
    },
    {
      "arxiv_id": "2410.08385v1",
      "title": "Language model developers should report train-test overlap",
      "title_zh": "语言模型开发者应报告训练测试重叠",
      "authors": [
        "Andy K Zhang",
        "Kevin Klyman",
        "Yifan Mai",
        "Yoav Levine",
        "Yian Zhang",
        "Rishi Bommasani",
        "Percy Liang"
      ],
      "abstract": "Language models are extensively evaluated, but correctly interpreting\nevaluation results requires knowledge of train-test overlap which refers to the\nextent to which the language model is trained on the very data it is being\ntested on. The public currently lacks adequate information about train-test\noverlap: most models have no public train-test overlap statistics, and third\nparties cannot directly measure train-test overlap since they do not have\naccess to the training data. To make this clear, we document the practices of\n30 model developers, finding that just 9 developers report train-test overlap:\n4 developers release training data under open-source licenses, enabling the\ncommunity to directly measure train-test overlap, and 5 developers publish\ntheir train-test overlap methodology and statistics. By engaging with language\nmodel developers, we provide novel information about train-test overlap for\nthree additional developers. Overall, we take the position that language model\ndevelopers should publish train-test overlap statistics and/or training data\nwhenever they report evaluation results on public test sets. We hope our work\nincreases transparency into train-test overlap to increase the community-wide\ntrust in model evaluations.",
      "tldr_zh": "语言模型评估中，train-test overlap（训练测试重叠）问题常被忽略，这指的是模型是否在训练数据中包含了测试数据，从而影响评估结果的可靠性。作者调查了30个模型开发者，发现仅有9个报告了相关信息：4个开源了训练数据，5个发布了方法和统计数据。通过与开发者的互动，论文提供了额外三个开发者的信息，并主张语言模型开发者应在报告公共测试集评估结果时，发布train-test overlap统计数据和/或训练数据，以提升社区对模型评估的透明度和信任。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08385v1",
      "published_date": "2024-10-10 21:44:56 UTC",
      "updated_date": "2024-10-10 21:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:31:40.780760"
    },
    {
      "arxiv_id": "2410.08377v1",
      "title": "Optimizing Vital Sign Monitoring in Resource-Constrained Maternal Care: An RL-Based Restless Bandit Approach",
      "title_zh": "在资源受限的产科护理中优化生命体征监测：一种基于 RL 的 Restless Bandit 方法",
      "authors": [
        "Niclas Boehmer",
        "Yunfan Zhao",
        "Guojun Xiong",
        "Paula Rodriguez-Diaz",
        "Paola Del Cueto Cibrian",
        "Joseph Ngonzi",
        "Adeline Boatin",
        "Milind Tambe"
      ],
      "abstract": "Maternal mortality remains a significant global public health challenge. One\npromising approach to reducing maternal deaths occurring during facility-based\nchildbirth is through early warning systems, which require the consistent\nmonitoring of mothers' vital signs after giving birth. Wireless vital sign\nmonitoring devices offer a labor-efficient solution for continuous monitoring,\nbut their scarcity raises the critical question of how to allocate them most\neffectively. We devise an allocation algorithm for this problem by modeling it\nas a variant of the popular Restless Multi-Armed Bandit (RMAB) paradigm. In\ndoing so, we identify and address novel, previously unstudied constraints\nunique to this domain, which render previous approaches for RMABs unsuitable\nand significantly increase the complexity of the learning and planning problem.\nTo overcome these challenges, we adopt the popular Proximal Policy Optimization\n(PPO) algorithm from reinforcement learning to learn an allocation policy by\ntraining a policy and value function network. We demonstrate in simulations\nthat our approach outperforms the best heuristic baseline by up to a factor of\n$4$.",
      "tldr_zh": "该论文针对资源受限的孕产妇护理，提出了一种基于 Restless Multi-Armed Bandit (RMAB) 变体的算法，用于优化无线生命体征监控设备的分配，以降低产后死亡率。作者识别了该领域的独特约束，并采用 Proximal Policy Optimization (PPO) 强化学习算法训练策略网络，解决学习和规划的复杂性。模拟实验结果显示，该方法比最佳启发式基线性能提升高达 4 倍，为高效的早期预警系统提供实用解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08377v1",
      "published_date": "2024-10-10 21:20:07 UTC",
      "updated_date": "2024-10-10 21:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:31:52.396723"
    },
    {
      "arxiv_id": "2410.08371v1",
      "title": "Merging in a Bottle: Differentiable Adaptive Merging (DAM) and the Path from Averaging to Automation",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Gauthier-Caron",
        "Shamane Siriwardhana",
        "Elliot Stein",
        "Malikeh Ehghaghi",
        "Charles Goddard",
        "Mark McQuade",
        "Jacob Solawetz",
        "Maxime Labonne"
      ],
      "abstract": "By merging models, AI systems can combine the distinct strengths of separate\nlanguage models, achieving a balance between multiple capabilities without\nrequiring substantial retraining. However, the integration process can be\nintricate due to differences in training methods and fine-tuning, typically\nnecessitating specialized knowledge and repeated refinement. This paper\nexplores model merging techniques across a spectrum of complexity, examining\nwhere automated methods like evolutionary strategies stand compared to\nhyperparameter-driven approaches such as DARE, TIES-Merging and simpler methods\nlike Model Soups. In addition, we introduce Differentiable Adaptive Merging\n(DAM), an efficient, adaptive merging approach as an alternative to\nevolutionary merging that optimizes model integration through scaling\ncoefficients, minimizing computational demands. Our findings reveal that even\nsimple averaging methods, like Model Soups, perform competitively when model\nsimilarity is high, underscoring each technique's unique strengths and\nlimitations. We open-sourced DAM, including the implementation code and\nexperiment pipeline, on GitHub: https://github.com/arcee-ai/DAM.",
      "tldr_zh": "本论文探讨了模型合并技术，用于结合不同语言模型的优势，实现多种能力的平衡，而无需大量重新训练。作者引入了Differentiable Adaptive Merging (DAM)，一种高效的自适应方法，通过优化缩放系数来整合模型，减少计算需求，并作为进化策略的替代方案。实验比较了DAM与其他技术如DARE、TIES-Merging和Model Soups，发现简单平均方法在模型相似度高时表现竞争力，并突显了各方法的优缺点。该研究开源了DAM的实现代码和实验流程于GitHub。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 figure, and 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08371v1",
      "published_date": "2024-10-10 20:58:29 UTC",
      "updated_date": "2024-10-10 20:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:32:03.931784"
    },
    {
      "arxiv_id": "2410.08345v1",
      "title": "Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Gasztowtt",
        "Benjamin Smith",
        "Vincent Zhu",
        "Qinxun Bai",
        "Edwin Zhang"
      ],
      "abstract": "The improvement of economic policymaking presents an opportunity for broad\nsocietal benefit, a notion that has inspired research towards AI-driven\npolicymaking tools. AI policymaking holds the potential to surpass human\nperformance through the ability to process data quickly at scale. However,\nexisting RL-based methods exhibit sample inefficiency, and are further limited\nby an inability to flexibly incorporate nuanced information into their\ndecision-making processes. Thus, we propose a novel method in which we instead\nutilize pre-trained Large Language Models (LLMs), as sample-efficient\npolicymakers in socially complex multi-agent reinforcement learning (MARL)\nscenarios. We demonstrate significant efficiency gains, outperforming existing\nmethods across three environments. Our code is available at\nhttps://github.com/hegasz/large-legislative-models.",
      "tldr_zh": "该论文探讨了利用 AI 提升经济决策效率的潜力，指出现有基于强化学习 (RL) 的方法存在样本效率低下和无法灵活处理复杂信息的问题。作者提出一种新方法，使用预训练的大型语言模型 (LLMs) 作为多智能体强化学习 (MARL) 场景中的高效决策者，以实现更灵活的 AI 政策制定。实验结果显示，该方法在三个环境中显著优于现有方法，并提供了开源代码（https://github.com/hegasz/large-legislative-models）。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08345v1",
      "published_date": "2024-10-10 20:04:58 UTC",
      "updated_date": "2024-10-10 20:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:32:16.440794"
    },
    {
      "arxiv_id": "2410.08336v2",
      "title": "Kernel Banzhaf: A Fast and Robust Estimator for Banzhaf Values",
      "title_zh": "Kernel Banzhaf：Banzhaf 值的快速且鲁棒估计器",
      "authors": [
        "Yurong Liu",
        "R. Teal Witter",
        "Flip Korn",
        "Tarfah Alrashed",
        "Dimitris Paparas",
        "Christopher Musco",
        "Juliana Freire"
      ],
      "abstract": "Banzhaf values provide a popular, interpretable alternative to the\nwidely-used Shapley values for quantifying the importance of features in\nmachine learning models. Like Shapley values, computing Banzhaf values exactly\nrequires time exponential in the number of features, necessitating the use of\nefficient estimators. Existing estimators, however, are limited to Monte Carlo\nsampling methods. In this work, we introduce Kernel Banzhaf, the first\nregression-based estimator for Banzhaf values. Our approach leverages a novel\nregression formulation, whose exact solution corresponds to the exact Banzhaf\nvalues. Inspired by the success of Kernel SHAP for Shapley values, Kernel\nBanzhaf efficiently solves a sampled instance of this regression problem.\nThrough empirical evaluations across eight datasets, we find that Kernel\nBanzhaf significantly outperforms existing Monte Carlo methods in terms of\naccuracy, sample efficiency, robustness to noise, and feature ranking recovery.\nFinally, we complement our experimental evaluation with strong theoretical\nguarantees on Kernel Banzhaf's performance.",
      "tldr_zh": "该研究提出Kernel Banzhaf，一种基于回归的估计器，用于高效计算Banzhaf values，以量化机器学习模型中特征的重要性。不同于现有的Monte Carlo采样方法，Kernel Banzhaf采用一个新颖的回归公式，其精确解对应于精确的Banzhaf values，并受Kernel SHAP启发，通过解决回归问题的采样实例实现高效计算。在八个数据集上的实证评估中，Kernel Banzhaf在准确性、样本效率、噪声鲁棒性和特征排名恢复方面显著优于Monte Carlo方法，并提供了强有力的理论性能保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08336v2",
      "published_date": "2024-10-10 19:51:29 UTC",
      "updated_date": "2025-02-18 04:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:32:27.573891"
    },
    {
      "arxiv_id": "2410.08334v1",
      "title": "Exploring Natural Language-Based Strategies for Efficient Number Learning in Children through Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tirthankar Mittra"
      ],
      "abstract": "This paper investigates how children learn numbers using the framework of\nreinforcement learning (RL), with a focus on the impact of language\ninstructions. The motivation for using reinforcement learning stems from its\nparallels with psychological learning theories in controlled environments. By\nusing state of the art deep reinforcement learning models, we simulate and\nanalyze the effects of various forms of language instructions on number\nacquisition. Our findings indicate that certain linguistic structures more\neffectively improve numerical comprehension in RL agents. Additionally, our\nmodel predicts optimal sequences for presenting numbers to RL agents which\nenhance their speed of learning. This research provides valuable insights into\nthe interplay between language and numerical cognition, with implications for\nboth educational strategies and the development of artificial intelligence\nsystems designed to support early childhood learning.",
      "tldr_zh": "本研究通过强化学习（RL）框架模拟儿童数字学习过程，重点探讨语言指令对学习效率的影响。使用先进的深度RL模型分析不同语言结构，发现某些语言形式能更有效地提升RL代理的数字理解和获取速度。研究还预测了呈现数字的最佳序列，以加速学习过程，并为教育策略和支持儿童学习的AI系统开发提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08334v1",
      "published_date": "2024-10-10 19:49:13 UTC",
      "updated_date": "2024-10-10 19:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:32:39.782709"
    },
    {
      "arxiv_id": "2410.08332v1",
      "title": "Level of agreement between emotions generated by Artificial Intelligence and human evaluation: a methodological proposal",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Carrasco",
        "Cesar Gonzalez-Martin",
        "Sonia Navajas-Torrente",
        "Raul Dastres"
      ],
      "abstract": "Images are capable of conveying emotions, but emotional experience is highly\nsubjective. Advances in artificial intelligence have enabled the generation of\nimages based on emotional descriptions. However, the level of agreement between\nthe generative images and human emotional responses has not yet been evaluated.\nTo address this, 20 artistic landscapes were generated using StyleGAN2-ADA.\nFour variants evoking positive emotions (contentment, amusement) and negative\nemotions (fear, sadness) were created for each image, resulting in 80 pictures.\nAn online questionnaire was designed using this material, in which 61 observers\nclassified the generated images. Statistical analyses were performed on the\ncollected data to determine the level of agreement among participants, between\nthe observer's responses, and the AI-generated emotions. A generally good level\nof agreement was found, with better results for negative emotions. However, the\nstudy confirms the subjectivity inherent in emotional evaluation.",
      "tldr_zh": "这篇论文提出了一种方法来评估人工智能（AI）生成的图像情绪与人类评价的一致性，旨在解决情绪主观性的挑战。研究人员使用 StyleGAN2-ADA 生成 80 张艺术景观图像，包括针对积极情绪（contentment 和 amusement）和消极情绪（fear 和 sadness）的变体，并通过在线问卷让 61 名观察者进行分类。统计分析结果显示，参与者之间的一致性整体良好，尤其在消极情绪上表现更佳，但同时确认了情绪评估的固有主观性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08332v1",
      "published_date": "2024-10-10 19:44:32 UTC",
      "updated_date": "2024-10-10 19:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:32:54.909117"
    },
    {
      "arxiv_id": "2410.08328v1",
      "title": "Agents Thinking Fast and Slow: A Talker-Reasoner Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantina Christakopoulou",
        "Shibl Mourad",
        "Maja Matarić"
      ],
      "abstract": "Large language models have enabled agents of all kinds to interact with users\nthrough natural conversation. Consequently, agents now have two jobs:\nconversing and planning/reasoning. Their conversational responses must be\ninformed by all available information, and their actions must help to achieve\ngoals. This dichotomy between conversing with the user and doing multi-step\nreasoning and planning can be seen as analogous to the human systems of\n\"thinking fast and slow\" as introduced by Kahneman. Our approach is comprised\nof a \"Talker\" agent (System 1) that is fast and intuitive, and tasked with\nsynthesizing the conversational response; and a \"Reasoner\" agent (System 2)\nthat is slower, more deliberative, and more logical, and is tasked with\nmulti-step reasoning and planning, calling tools, performing actions in the\nworld, and thereby producing the new agent state. We describe the new\nTalker-Reasoner architecture and discuss its advantages, including modularity\nand decreased latency. We ground the discussion in the context of a sleep\ncoaching agent, in order to demonstrate real-world relevance.",
      "tldr_zh": "这篇论文提出了一种Talker-Reasoner架构，灵感来源于Kahneman的“thinking fast and slow”系统，用于提升Large language models驱动的代理在对话和规划方面的能力。架构包括Talker代理（System 1），负责快速、直观的对话响应合成；以及Reasoner代理（System 2），专注于缓慢、逻辑的多步推理、规划、工具调用和状态更新。这种设计提高了代理的模块性和降低了延迟，并在睡眠指导代理的实际应用中进行了验证。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08328v1",
      "published_date": "2024-10-10 19:31:35 UTC",
      "updated_date": "2024-10-10 19:31:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:33:03.802139"
    },
    {
      "arxiv_id": "2410.08307v1",
      "title": "UNIQ: Offline Inverse Q-learning for Avoiding Undesirable Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Huy Hoang",
        "Tien Mai",
        "Pradeep Varakantham"
      ],
      "abstract": "We address the problem of offline learning a policy that avoids undesirable\ndemonstrations. Unlike conventional offline imitation learning approaches that\naim to imitate expert or near-optimal demonstrations, our setting involves\navoiding undesirable behavior (specified using undesirable demonstrations). To\ntackle this problem, unlike standard imitation learning where the aim is to\nminimize the distance between learning policy and expert demonstrations, we\nformulate the learning task as maximizing a statistical distance, in the space\nof state-action stationary distributions, between the learning policy and the\nundesirable policy. This significantly different approach results in a novel\ntraining objective that necessitates a new algorithm to address it. Our\nalgorithm, UNIQ, tackles these challenges by building on the inverse Q-learning\nframework, framing the learning problem as a cooperative (non-adversarial)\ntask. We then demonstrate how to efficiently leverage unlabeled data for\npractical training. Our method is evaluated on standard benchmark environments,\nwhere it consistently outperforms state-of-the-art baselines. The code\nimplementation can be accessed at: https://github.com/hmhuy0/UNIQ.",
      "tldr_zh": "该论文解决了离线模仿学习中避免不想要演示的问题，与传统方法不同，它通过最大化学习政策与不想要政策的统计距离（在状态-动作平稳分布空间）来制定训练目标。UNIQ 算法基于 Inverse Q-learning 框架，将问题视为合作任务，并高效利用无标签数据进行训练。在标准基准环境中，UNIQ 算法的表现优于最先进基线方法，代码实现可在 GitHub 上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08307v1",
      "published_date": "2024-10-10 18:52:58 UTC",
      "updated_date": "2024-10-10 18:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:33:14.902709"
    },
    {
      "arxiv_id": "2410.08292v1",
      "title": "Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning?",
      "title_zh": "循环 Transformer 是否能够学会实现多步梯度下降用于上下文学习？",
      "authors": [
        "Khashayar Gatmiry",
        "Nikunj Saunshi",
        "Sashank J. Reddi",
        "Stefanie Jegelka",
        "Sanjiv Kumar"
      ],
      "abstract": "The remarkable capability of Transformers to do reasoning and few-shot\nlearning, without any fine-tuning, is widely conjectured to stem from their\nability to implicitly simulate a multi-step algorithms -- such as gradient\ndescent -- with their weights in a single forward pass. Recently, there has\nbeen progress in understanding this complex phenomenon from an expressivity\npoint of view, by demonstrating that Transformers can express such multi-step\nalgorithms. However, our knowledge about the more fundamental aspect of its\nlearnability, beyond single layer models, is very limited. In particular, can\ntraining Transformers enable convergence to algorithmic solutions? In this work\nwe resolve this for in-context linear regression with linear looped\nTransformers -- a multi-layer model with weight sharing that is conjectured to\nhave an inductive bias to learn fix-point iterative algorithms. More\nspecifically, for this setting we show that the global minimizer of the\npopulation training loss implements multi-step preconditioned gradient descent,\nwith a preconditioner that adapts to the data distribution. Furthermore, we\nshow a fast convergence for gradient flow on the regression loss, despite the\nnon-convexity of the landscape, by proving a novel gradient dominance\ncondition. To our knowledge, this is the first theoretical analysis for\nmulti-layer Transformer in this setting. We further validate our theoretical\nfindings through synthetic experiments.",
      "tldr_zh": "本研究探讨了Looped Transformers是否能通过训练学习实现多步梯度下降（multi-step gradient descent），以支持in-context learning。作者针对in-context linear regression，使用linear looped Transformers（一种多层权重共享模型，具有学习固定点迭代算法的诱导偏差）进行分析，证明其全局最小化器可以实现多步预处理梯度下降（multi-step preconditioned gradient descent），并根据数据分布调整预处理器。尽管损失景观是非凸的，研究还证明了梯度流在回归损失上的快速收敛，通过一个新的gradient dominance condition。实验结果通过合成数据验证了这些理论发现，为理解Transformers的算法模拟能力提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08292v1",
      "published_date": "2024-10-10 18:29:05 UTC",
      "updated_date": "2024-10-10 18:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:33:28.262139"
    },
    {
      "arxiv_id": "2410.08289v1",
      "title": "Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference",
      "title_zh": "通过使用合成偏好的强化学习增加自动生成问题的难度",
      "authors": [
        "William Thorne",
        "Ambrose Robinson",
        "Bohua Peng",
        "Chenghua Lin",
        "Diana Maynard"
      ],
      "abstract": "As the cultural heritage sector increasingly adopts technologies like\nRetrieval-Augmented Generation (RAG) to provide more personalised search\nexperiences and enable conversations with collections data, the demand for\nspecialised evaluation datasets has grown. While end-to-end system testing is\nessential, it's equally important to assess individual components. We target\nthe final, answering task, which is well-suited to Machine Reading\nComprehension (MRC). Although existing MRC datasets address general domains,\nthey lack the specificity needed for cultural heritage information.\nUnfortunately, the manual creation of such datasets is prohibitively expensive\nfor most heritage institutions. This paper presents a cost-effective approach\nfor generating domain-specific MRC datasets with increased difficulty using\nReinforcement Learning from Human Feedback (RLHF) from synthetic preference\ndata. Our method leverages the performance of existing question-answering\nmodels on a subset of SQuAD to create a difficulty metric, assuming that more\nchallenging questions are answered correctly less frequently. This research\ncontributes: (1) A methodology for increasing question difficulty using PPO and\nsynthetic data; (2) Empirical evidence of the method's effectiveness, including\nhuman evaluation; (3) An in-depth error analysis and study of emergent\nphenomena; and (4) An open-source codebase and set of three llama-2-chat\nadapters for reproducibility and adaptation.",
      "tldr_zh": "这篇论文提出了一种使用 Reinforcement Learning from Human Feedback (RLHF) 结合合成偏好数据的方法，来增加自动生成问题的难度，针对文化遗产领域的 Machine Reading Comprehension (MRC) 数据集，以解决现有数据集缺乏特定性和手动创建成本高的问题。研究利用 SQuAD 子集的模型性能作为难度指标，并通过 Proximal Policy Optimization (PPO) 算法优化问题生成过程。贡献包括：(1) 一种提升问题难度的系统方法；(2) 通过人类评估验证的有效性证据；(3) 深入的错误分析和新兴现象研究；以及(4) 开源代码和三个 llama-2-chat 适配器，促进可复现性和应用。整体方法为文化遗产领域的个性化搜索和对话系统提供了成本有效的评估工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Primary) 91F20 (Secondary)",
        "I.2.7; J.5"
      ],
      "primary_category": "cs.CL",
      "comment": "is to be published in NLP4DH 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08289v1",
      "published_date": "2024-10-10 18:21:00 UTC",
      "updated_date": "2024-10-10 18:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:33:40.372019"
    },
    {
      "arxiv_id": "2410.09118v1",
      "title": "FSW-GNN: A Bi-Lipschitz WL-Equivalent Graph Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yonatan Sverdlov",
        "Yair Davidson",
        "Nadav Dym",
        "Tal Amir"
      ],
      "abstract": "Many of the most popular graph neural networks fall into the category of\nmessage-passing neural networks (MPNNs). Famously, MPNNs' ability to\ndistinguish between graphs is limited to graphs separable by the\nWeisfeiler-Lemann (WL) graph isomorphism test, and the strongest MPNNs, in\nterms of separation power, are WL-equivalent.\n  Recently, it was shown that the quality of separation provided by standard\nWL-equivalent MPNN can be very low, resulting in WL-separable graphs being\nmapped to very similar, hardly distinguishable features. This paper addresses\nthis issue by seeking bi-Lipschitz continuity guarantees for MPNNs. We\ndemonstrate that, in contrast with standard summation-based MPNNs, which lack\nbi-Lipschitz properties, our proposed model provides a bi-Lipschitz graph\nembedding with respect to two standard graph metrics. Empirically, we show that\nour MPNN is competitive with standard MPNNs for several graph learning tasks\nand is far more accurate in over-squashing long-range tasks.",
      "tldr_zh": "该论文提出 FSW-GNN，一种 bi-Lipschitz WL-Equivalent 图神经网络，旨在解决标准消息传递神经网络(MPNNs) 在图分离能力上的不足，这些 MPNNs 虽等价于 Weisfeiler-Lemann (WL) 图同构测试，但往往将可分离图映射到相似的特征。FSW-GNN 通过提供 bi-Lipschitz 连续性保证，在两个标准图度量上实现更稳定的图嵌入，与传统基于求和的 MPNNs 不同。实验结果表明，FSW-GNN 在多个图学习任务中与标准 MPNNs 竞争，并在处理长距离任务时表现出更高的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09118v1",
      "published_date": "2024-10-10 18:11:23 UTC",
      "updated_date": "2024-10-10 18:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:33:53.010887"
    },
    {
      "arxiv_id": "2410.08282v1",
      "title": "FusionSense: Bridging Common Sense, Vision, and Touch for Robust Sparse-View Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Irving Fang",
        "Kairui Shi",
        "Xujin He",
        "Siqi Tan",
        "Yifan Wang",
        "Hanwen Zhao",
        "Hung-Jui Huang",
        "Wenzhen Yuan",
        "Chen Feng",
        "Jing Zhang"
      ],
      "abstract": "Humans effortlessly integrate common-sense knowledge with sensory input from\nvision and touch to understand their surroundings. Emulating this capability,\nwe introduce FusionSense, a novel 3D reconstruction framework that enables\nrobots to fuse priors from foundation models with highly sparse observations\nfrom vision and tactile sensors. FusionSense addresses three key challenges:\n(i) How can robots efficiently acquire robust global shape information about\nthe surrounding scene and objects? (ii) How can robots strategically select\ntouch points on the object using geometric and common-sense priors? (iii) How\ncan partial observations such as tactile signals improve the overall\nrepresentation of the object? Our framework employs 3D Gaussian Splatting as a\ncore representation and incorporates a hierarchical optimization strategy\ninvolving global structure construction, object visual hull pruning and local\ngeometric constraints. This advancement results in fast and robust perception\nin environments with traditionally challenging objects that are transparent,\nreflective, or dark, enabling more downstream manipulation or navigation tasks.\nExperiments on real-world data suggest that our framework outperforms\npreviously state-of-the-art sparse-view methods. All code and data are\nopen-sourced on the project website.",
      "tldr_zh": "该论文提出FusionSense，一种创新的3D重建框架，帮助机器人整合foundation models的常识先验与视觉和触觉传感器的稀疏观察，实现鲁棒的物体重建。框架针对三大挑战：高效获取全局形状信息、使用几何和常识先验选择触点，以及利用触觉信号改善物体表示，通过3D Gaussian Splatting作为核心表示和分层优化策略（如全局结构构建、物体视觉外壳修剪和局部几何约束）来解决这些问题。实验结果显示，FusionSense在处理透明、反射或黑暗物体时显著优于现有稀疏视图方法，并在真实世界数据上表现出色，所有代码和数据已开源。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "I.4.5; I.4.8"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08282v1",
      "published_date": "2024-10-10 18:07:07 UTC",
      "updated_date": "2024-10-10 18:07:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:34:04.141824"
    },
    {
      "arxiv_id": "2410.09117v1",
      "title": "REDO: Execution-Free Runtime Error Detection for COding Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Shou Li",
        "Andrey Kan",
        "Laurent Callot",
        "Bhavana Bhasker",
        "Muhammad Shihab Rashid",
        "Timothy B Esler"
      ],
      "abstract": "As LLM-based agents exhibit exceptional capabilities in addressing complex\nproblems, there is a growing focus on developing coding agents to tackle\nincreasingly sophisticated tasks. Despite their promising performance, these\ncoding agents often produce programs or modifications that contain runtime\nerrors, which can cause code failures and are difficult for static analysis\ntools to detect. Enhancing the ability of coding agents to statically identify\nsuch errors could significantly improve their overall performance. In this\nwork, we introduce Execution-free Runtime Error Detection for COding Agents\n(REDO), a method that integrates LLMs with static analysis tools to detect\nruntime errors for coding agents, without code execution. Additionally, we\npropose a benchmark task, SWE-Bench-Error-Detection (SWEDE), based on SWE-Bench\n(lite), to evaluate error detection in repository-level problems with complex\nexternal dependencies. Finally, through both quantitative and qualitative\nanalyses across various error detection tasks, we demonstrate that REDO\noutperforms current state-of-the-art methods by achieving a 11.0% higher\naccuracy and 9.1% higher weighted F1 score; and provide insights into the\nadvantages of incorporating LLMs for error detection.",
      "tldr_zh": "该研究针对LLM-based coding agents在生成代码时常出现的运行时错误问题，提出REDO方法，该方法整合LLMs与静态分析工具，实现无需代码执行的运行时错误检测，从而提升agents的整体性能。研究者还开发了SWE-Bench-Error-Detection (SWEDE)基准任务，用于评估仓库级复杂问题的错误检测。实验结果显示，REDO在各种任务中比现有最先进方法准确率提高11.0%、加权F1分数提高9.1%，并提供洞见，证明了整合LLMs的优势。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "27 pages, 13 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.09117v1",
      "published_date": "2024-10-10 18:06:29 UTC",
      "updated_date": "2024-10-10 18:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:34:16.043782"
    },
    {
      "arxiv_id": "2410.08211v1",
      "title": "LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Anh-Quan Cao",
        "Maximilian Jaritz",
        "Matthieu Guillaumin",
        "Raoul de Charette",
        "Loris Bazzani"
      ],
      "abstract": "Large-scale vision-language pre-trained (VLP) models (e.g., CLIP) are\nrenowned for their versatility, as they can be applied to diverse applications\nin a zero-shot setup. However, when these models are used in specific domains,\ntheir performance often falls short due to domain gaps or the\nunder-representation of these domains in the training data. While fine-tuning\nVLP models on custom datasets with human-annotated labels can address this\nissue, annotating even a small-scale dataset (e.g., 100k samples) can be an\nexpensive endeavor, often requiring expert annotators if the task is complex.\nTo address these challenges, we propose LatteCLIP, an unsupervised method for\nfine-tuning CLIP models on classification with known class names in custom\ndomains, without relying on human annotations. Our method leverages Large\nMultimodal Models (LMMs) to generate expressive textual descriptions for both\nindividual images and groups of images. These provide additional contextual\ninformation to guide the fine-tuning process in the custom domains. Since\nLMM-generated descriptions are prone to hallucination or missing details, we\nintroduce a novel strategy to distill only the useful information and stabilize\nthe training. Specifically, we learn rich per-class prototype representations\nfrom noisy generated texts and dual pseudo-labels. Our experiments on 10\ndomain-specific datasets show that LatteCLIP outperforms pre-trained zero-shot\nmethods by an average improvement of +4.74 points in top-1 accuracy and other\nstate-of-the-art unsupervised methods by +3.45 points.",
      "tldr_zh": "该研究提出 LatteCLIP，一种无监督微调 CLIP 模型的方法，利用 Large Multimodal Models (LMM) 生成合成文本描述（如图像的表达性描述），以桥接特定领域的视觉语言模型性能差距，而无需人工标注。  \n为了处理 LMM 生成文本可能存在的幻觉或细节缺失问题，该方法引入策略从噪声文本中提炼有用信息，包括学习每个类的原型表示和双伪标签，从而稳定训练过程。  \n实验结果显示，在10个领域特定数据集上，LatteCLIP 比预训练零样本方法平均提高4.74点的top-1准确率，并比其他无监督方法提升3.45点。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08211v1",
      "published_date": "2024-10-10 17:59:59 UTC",
      "updated_date": "2024-10-10 17:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:34:28.520892"
    },
    {
      "arxiv_id": "2410.08210v1",
      "title": "PointOBB-v2: Towards Simpler, Faster, and Stronger Single Point Supervised Oriented Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Botao Ren",
        "Xue Yang",
        "Yi Yu",
        "Junwei Luo",
        "Zhidong Deng"
      ],
      "abstract": "Single point supervised oriented object detection has gained attention and\nmade initial progress within the community. Diverse from those approaches\nrelying on one-shot samples or powerful pretrained models (e.g. SAM), PointOBB\nhas shown promise due to its prior-free feature. In this paper, we propose\nPointOBB-v2, a simpler, faster, and stronger method to generate pseudo rotated\nboxes from points without relying on any other prior. Specifically, we first\ngenerate a Class Probability Map (CPM) by training the network with non-uniform\npositive and negative sampling. We show that the CPM is able to learn the\napproximate object regions and their contours. Then, Principal Component\nAnalysis (PCA) is applied to accurately estimate the orientation and the\nboundary of objects. By further incorporating a separation mechanism, we\nresolve the confusion caused by the overlapping on the CPM, enabling its\noperation in high-density scenarios. Extensive comparisons demonstrate that our\nmethod achieves a training speed 15.58x faster and an accuracy improvement of\n11.60%/25.15%/21.19% on the DOTA-v1.0/v1.5/v2.0 datasets compared to the\nprevious state-of-the-art, PointOBB. This significantly advances the cutting\nedge of single point supervised oriented detection in the modular track.",
      "tldr_zh": "本论文提出 PointOBB-v2，一种更简单、更快、更强的 Single Point Supervised Oriented Object Detection 方法，用于从单点生成伪旋转框，而不依赖其他先验。具体而言，该方法首先通过非均匀正负采样训练网络生成 Class Probability Map (CPM)，以学习物体的近似区域和轮廓；随后应用 Principal Component Analysis (PCA) 精确估计物体的方向和边界，并引入分离机制解决 CPM 上重叠引起的混淆，提升高密度场景的性能。实验结果显示，与 PointOBB 相比，PointOBB-v2 在 DOTA-v1.0/v1.5/v2.0 数据集上训练速度提高 15.58 倍，准确率分别提升 11.60%、25.15% 和 21.19%，显著推进了该领域的模块化轨道前沿。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 4 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08210v1",
      "published_date": "2024-10-10 17:59:56 UTC",
      "updated_date": "2024-10-10 17:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:34:40.414619"
    },
    {
      "arxiv_id": "2410.08209v1",
      "title": "Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision",
      "title_zh": "大型多模态模型中无监督像素地点的涌现",
      "authors": [
        "Shengcao Cao",
        "Liang-Yan Gui",
        "Yu-Xiong Wang"
      ],
      "abstract": "Current large multimodal models (LMMs) face challenges in grounding, which\nrequires the model to relate language components to visual entities. Contrary\nto the common practice that fine-tunes LMMs with additional grounding\nsupervision, we find that the grounding ability can in fact emerge in LMMs\ntrained without explicit grounding supervision. To reveal this emerging\ngrounding, we introduce an \"attend-and-segment\" method which leverages\nattention maps from standard LMMs to perform pixel-level segmentation.\nFurthermore, to enhance the grounding ability, we propose DIFFLMM, an LMM\nutilizing a diffusion-based visual encoder, as opposed to the standard CLIP\nvisual encoder, and trained with the same weak supervision. Without being\nconstrained by the biases and limited scale of grounding-specific supervision\ndata, our approach is more generalizable and scalable. We achieve competitive\nperformance on both grounding-specific and general visual question answering\nbenchmarks, compared with grounding LMMs and generalist LMMs, respectively.\nNotably, we achieve a 44.2 grounding mask recall on grounded conversation\ngeneration without any grounding supervision, outperforming the extensively\nsupervised model GLaMM. Project page: https://groundLMM.github.io.",
      "tldr_zh": "本研究发现，大型多模态模型 (LMMs) 在没有显式 grounding 监督的情况下，grounding 能力（将语言组件与视觉实体关联）可以自然出现。论文引入了 \"attend-and-segment\" 方法，利用标准 LMMs 的 attention maps 进行像素级分割，并提出 DIFFLMM，这是一种采用 diffusion-based visual encoder 而非传统 CLIP visual encoder 的模型，仅通过弱监督训练。相比受 grounding-specific 数据限制的传统方法，该方法更具泛化性和可扩展性，在 grounding 特定基准上实现 44.2 的 grounding mask recall，并在一般视觉问答任务中表现出色，甚至超越了广泛监督的模型 GLaMM。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08209v1",
      "published_date": "2024-10-10 17:59:55 UTC",
      "updated_date": "2024-10-10 17:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:34:52.878841"
    },
    {
      "arxiv_id": "2410.08208v3",
      "title": "SPA: 3D Spatial-Awareness Enables Effective Embodied Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Zhu",
        "Honghui Yang",
        "Yating Wang",
        "Jiange Yang",
        "Limin Wang",
        "Tong He"
      ],
      "abstract": "In this paper, we introduce SPA, a novel representation learning framework\nthat emphasizes the importance of 3D spatial awareness in embodied AI. Our\napproach leverages differentiable neural rendering on multi-view images to\nendow a vanilla Vision Transformer (ViT) with intrinsic spatial understanding.\nWe present the most comprehensive evaluation of embodied representation\nlearning to date, covering 268 tasks across 8 simulators with diverse policies\nin both single-task and language-conditioned multi-task scenarios. The results\nare compelling: SPA consistently outperforms more than 10 state-of-the-art\nrepresentation methods, including those specifically designed for embodied AI,\nvision-centric tasks, and multi-modal applications, while using less training\ndata. Furthermore, we conduct a series of real-world experiments to confirm its\neffectiveness in practical scenarios. These results highlight the critical role\nof 3D spatial awareness for embodied representation learning. Our strongest\nmodel takes more than 6000 GPU hours to train and we are committed to\nopen-sourcing all code and model weights to foster future research in embodied\nrepresentation learning. Project Page: https://haoyizhu.github.io/spa/.",
      "tldr_zh": "这篇论文引入了 SPA 框架，一种强调 3D Spatial-Awareness 的新型表示学习方法，用于提升 Embodied AI 的性能。该框架通过 Differentiable Neural Rendering 在多视图图像上增强 Vision Transformer (ViT)，赋予模型内在的空间理解能力。在全面评估中，SPA 涵盖 268 个任务和 8 个模拟器，包括单任务和语言条件的多任务场景，并优于 10 多个最先进方法，同时使用更少训练数据。真实世界实验进一步验证了其实际有效性，作者承诺开源代码和模型权重以推动未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://haoyizhu.github.io/spa/",
      "pdf_url": "http://arxiv.org/pdf/2410.08208v3",
      "published_date": "2024-10-10 17:59:51 UTC",
      "updated_date": "2025-03-01 15:51:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:35:14.504079"
    },
    {
      "arxiv_id": "2410.12851v7",
      "title": "VibeCheck: Discover and Quantify Qualitative Differences in Large Language Models",
      "title_zh": "VibeCheck: 发现并量化大语言模型中的定性差异",
      "authors": [
        "Lisa Dunlap",
        "Krishna Mandal",
        "Trevor Darrell",
        "Jacob Steinhardt",
        "Joseph E Gonzalez"
      ],
      "abstract": "Large language models (LLMs) often exhibit subtle yet distinctive\ncharacteristics in their outputs that users intuitively recognize, but struggle\nto quantify. These \"vibes\" -- such as tone, formatting, or writing style --\ninfluence user preferences, yet traditional evaluations focus primarily on the\nsingular axis of correctness. We introduce VibeCheck, a system for\nautomatically comparing a pair of LLMs by discovering identifying traits of a\nmodel (vibes) that are well-defined, differentiating, and user-aligned.\nVibeCheck iteratively discovers vibes from model outputs and then utilizes a\npanel of LLM judges to quantitatively measure the utility of each vibe. We\nvalidate that the vibes generated by VibeCheck align with those found in human\ndiscovery and run VibeCheck on pairwise preference data from real-world user\nconversations with Llama-3-70b vs GPT-4. VibeCheck reveals that Llama has a\nfriendly, funny, and somewhat controversial vibe. These vibes predict model\nidentity with 80% accuracy and human preference with 61% accuracy. Lastly, we\nrun VibeCheck on a variety of models and tasks including summarization, math,\nand captioning to provide insight into differences in model behavior. VibeCheck\ndiscovers vibes like Command X prefers to add concrete intros and conclusions\nwhen summarizing in comparison to TNGL, Llama-405b often overexplains its\nthought process on math problems compared to GPT-4o, and GPT-4 prefers to focus\non the mood and emotions of the scene when captioning compared to\nGemini-1.5-Flash. Code and vibe visualizer found at https://bench-mark.org/",
      "tldr_zh": "该论文提出 VibeCheck 系统，用于发现和量化大型语言模型 (LLMs) 的定性差异，这些差异被称为 \"vibes\"，包括语气、格式和写作风格，以弥补传统评估仅关注正确性的局限。\nVibeCheck 通过迭代从模型输出中发现 vibes，并使用 LLM 判断者量化每个 vibes 的效用，确保这些特征明确、可区分且与用户偏好一致。\n实验验证显示，该系统发现的 vibes 与人类认知高度一致，并在比较 Llama-3-70b 和 GPT-4 时，揭示 Llama 具有友好、幽默且有些争议的 vibes，能以 80% 准确率预测模型身份和 61% 准确率预测人类偏好。\n此外，在总结、数学和标题生成等任务上，VibeCheck 识别出具体差异，如 Command X 在总结时更倾向于添加具体引言和结论。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "unironic use of the word 'vibe', added more analysis and cooler\n  graphs. added website link",
      "pdf_url": "http://arxiv.org/pdf/2410.12851v7",
      "published_date": "2024-10-10 17:59:17 UTC",
      "updated_date": "2025-04-19 23:14:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:35:17.331586"
    },
    {
      "arxiv_id": "2410.19750v2",
      "title": "The Geometry of Concepts: Sparse Autoencoder Feature Structure",
      "title_zh": "概念的几何学：稀疏自编码器特征结构",
      "authors": [
        "Yuxiao Li",
        "Eric J. Michaud",
        "David D. Baek",
        "Joshua Engels",
        "Xiaoqing Sun",
        "Max Tegmark"
      ],
      "abstract": "Sparse autoencoders have recently produced dictionaries of high-dimensional\nvectors corresponding to the universe of concepts represented by large language\nmodels. We find that this concept universe has interesting structure at three\nlevels: 1) The \"atomic\" small-scale structure contains \"crystals\" whose faces\nare parallelograms or trapezoids, generalizing well-known examples such as\n(man-woman-king-queen). We find that the quality of such parallelograms and\nassociated function vectors improves greatly when projecting out global\ndistractor directions such as word length, which is efficiently done with\nlinear discriminant analysis. 2) The \"brain\" intermediate-scale structure has\nsignificant spatial modularity; for example, math and code features form a\n\"lobe\" akin to functional lobes seen in neural fMRI images. We quantify the\nspatial locality of these lobes with multiple metrics and find that clusters of\nco-occurring features, at coarse enough scale, also cluster together spatially\nfar more than one would expect if feature geometry were random. 3) The \"galaxy\"\nscale large-scale structure of the feature point cloud is not isotropic, but\ninstead has a power law of eigenvalues with steepest slope in middle layers. We\nalso quantify how the clustering entropy depends on the layer.",
      "tldr_zh": "这篇论文探讨了稀疏自编码器（Sparse Autoencoders）在大型语言模型中生成的特征向量的几何结构，揭示了概念宇宙的三级结构。原子级小规模结构包括“晶体”（crystals），其面为平行四边形或梯形，通过投影出全局干扰方向（如单词长度）并使用线性判别分析（Linear Discriminant Analysis），这些结构的质量得到显著改善。脑级中规模结构显示出空间模块性，例如数学和代码特征形成类似神经 fMRI 图像的“叶”（lobe），并量化了特征集群的空间局部性，证明其远超随机几何的聚类倾向。星系级大规模结构则呈现非各向同性的点云分布，具有幂律（power law）特征值斜率，并在不同层中量化了聚类熵的依赖性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "16 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19750v2",
      "published_date": "2024-10-10 17:58:47 UTC",
      "updated_date": "2025-03-30 23:55:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:35:29.104608"
    },
    {
      "arxiv_id": "2410.08197v2",
      "title": "From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Changle Qu",
        "Sunhao Dai",
        "Xiaochi Wei",
        "Hengyi Cai",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Jun Xu",
        "Ji-Rong Wen"
      ],
      "abstract": "Tool learning enables Large Language Models (LLMs) to interact with external\nenvironments by invoking tools, serving as an effective strategy to mitigate\nthe limitations inherent in their pre-training data. In this process, tool\ndocumentation plays a crucial role by providing usage instructions for LLMs,\nthereby facilitating effective tool utilization. This paper concentrates on the\ncritical challenge of bridging the comprehension gap between LLMs and external\ntools due to the inadequacies and inaccuracies inherent in existing\nhuman-centric tool documentation. We propose a novel framework, DRAFT, aimed at\nDynamically Refining tool documentation through the Analysis of Feedback and\nTrials emanating from LLMs' interactions with external tools. This methodology\npivots on an innovative trial-and-error approach, consisting of three distinct\nlearning phases: experience gathering, learning from experience, and\ndocumentation rewriting, to iteratively enhance the tool documentation. This\nprocess is further optimized by implementing a diversity-promoting exploration\nstrategy to ensure explorative diversity and a tool-adaptive termination\nmechanism to prevent overfitting while enhancing efficiency. Extensive\nexperiments on multiple datasets demonstrate that DRAFT's iterative,\nfeedback-based refinement significantly ameliorates documentation quality,\nfostering a deeper comprehension and more effective utilization of tools by\nLLMs. Notably, our analysis reveals that the tool documentation refined via our\napproach demonstrates robust cross-model generalization capabilities.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）通过工具学习与外部环境交互的挑战，特别是在现有工具文档不完善导致理解差距的问题上。研究提出了一种创新框架DRAFT（Dynamically Refining tool documentation through the Analysis of Feedback and Trials），通过三个阶段——经验收集、从经验中学习和文档重写——结合试错方法、促进多样性的探索策略以及适应工具的终止机制，动态优化工具文档。实验结果显示，DRAFT显著提升了文档质量，使LLMs更有效地掌握和利用工具，并展示了强大的跨模型泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Oral;GitHub:https://github.com/quchangle1/DRAFT",
      "pdf_url": "http://arxiv.org/pdf/2410.08197v2",
      "published_date": "2024-10-10 17:58:44 UTC",
      "updated_date": "2025-02-26 03:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:35:39.666869"
    },
    {
      "arxiv_id": "2410.08196v1",
      "title": "MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code",
      "title_zh": "翻译失败",
      "authors": [
        "Zimu Lu",
        "Aojun Zhou",
        "Ke Wang",
        "Houxing Ren",
        "Weikang Shi",
        "Junting Pan",
        "Mingjie Zhan",
        "Hongsheng Li"
      ],
      "abstract": "Code has been shown to be effective in enhancing the mathematical reasoning\nabilities of large language models due to its precision and accuracy. Previous\nworks involving continued mathematical pretraining often include code that\nutilizes math-related packages, which are primarily designed for fields such as\nengineering, machine learning, signal processing, or module testing, rather\nthan being directly focused on mathematical reasoning. In this paper, we\nintroduce a novel method for generating mathematical code accompanied with\ncorresponding reasoning steps for continued pretraining. Our approach begins\nwith the construction of a high-quality mathematical continued pretraining\ndataset by incorporating math-related web data, code using mathematical\npackages, math textbooks, and synthetic data. Next, we construct reasoning\nsteps by extracting LaTeX expressions, the conditions needed for the\nexpressions, and the results of the expressions from the previously collected\ndataset. Based on this extracted information, we generate corresponding code to\naccurately capture the mathematical reasoning process. Appending the generated\ncode to each reasoning step results in data consisting of paired natural\nlanguage reasoning steps and their corresponding code. Combining this data with\nthe original dataset results in a 19.2B-token high-performing mathematical\npretraining corpus, which we name MathCode-Pile. Training several popular base\nmodels with this corpus significantly improves their mathematical abilities,\nleading to the creation of the MathCoder2 family of models. All of our data\nprocessing and training code is open-sourced, ensuring full transparency and\neasy reproducibility of the entire data collection and training pipeline. The\ncode is released at https://github.com/mathllm/MathCoder2 .",
      "tldr_zh": "本研究提出了一种新方法，通过在模型翻译的数学代码上进行持续预训练（Continued Pretraining），提升大语言模型的数学推理能力。方法包括构建一个高质量数据集（MathCode-Pile），整合数学网页数据、代码、教科书和合成数据，然后从中提取 LaTeX 表达式、条件和结果，生成对应的数学代码，并将其与推理步骤配对，形成19.2B-token的预训练语料库。利用此语料库训练流行基模型，显著提高了它们的数学能力，进而开发出MathCoder2模型家族。所有数据处理和训练代码已开源，提供在GitHub，确保实验的可复现性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/mathllm/MathCoder2",
      "pdf_url": "http://arxiv.org/pdf/2410.08196v1",
      "published_date": "2024-10-10 17:58:40 UTC",
      "updated_date": "2024-10-10 17:58:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:35:51.093676"
    },
    {
      "arxiv_id": "2410.08260v2",
      "title": "Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content",
      "title_zh": "翻译失败",
      "authors": [
        "Qiuheng Wang",
        "Yukai Shi",
        "Jiarong Ou",
        "Rui Chen",
        "Ke Lin",
        "Jiahao Wang",
        "Boyuan Jiang",
        "Haotian Yang",
        "Mingwu Zheng",
        "Xin Tao",
        "Fei Yang",
        "Pengfei Wan",
        "Di Zhang"
      ],
      "abstract": "With the continuous progress of visual generation technologies, the scale of\nvideo datasets has grown exponentially. The quality of these datasets plays a\npivotal role in the performance of video generation models. We assert that\ntemporal splitting, detailed captions, and video quality filtering are three\ncrucial determinants of dataset quality. However, existing datasets exhibit\nvarious limitations in these areas. To address these challenges, we introduce\nKoala-36M, a large-scale, high-quality video dataset featuring accurate\ntemporal splitting, detailed captions, and superior video quality. The essence\nof our approach lies in improving the consistency between fine-grained\nconditions and video content. Specifically, we employ a linear classifier on\nprobability distributions to enhance the accuracy of transition detection,\nensuring better temporal consistency. We then provide structured captions for\nthe splitted videos, with an average length of 200 words, to improve text-video\nalignment. Additionally, we develop a Video Training Suitability Score (VTSS)\nthat integrates multiple sub-metrics, allowing us to filter high-quality videos\nfrom the original corpus. Finally, we incorporate several metrics into the\ntraining process of the generation model, further refining the fine-grained\nconditions. Our experiments demonstrate the effectiveness of our data\nprocessing pipeline and the quality of the proposed Koala-36M dataset. Our\ndataset and code have been released at https://koala36m.github.io/.",
      "tldr_zh": "这篇论文介绍了 Koala-36M，一个大规模高质量视频数据集，旨在提升细粒度条件（如时间分割、详细描述和视频质量过滤）与视频内容的一致性。研究团队采用线性分类器在概率分布上优化过渡检测以确保时间一致性，并为分割视频提供平均200字的结构化描述，以改善文本-视频对齐；同时，他们开发了 Video Training Suitability Score (VTSS) 指标来筛选高质量视频，并将多个指标整合到生成模型训练中。实验结果证明了这一数据处理管道的有效性，展示了 Koala-36M 在提升视频生成模型性能方面的优势，该数据集及其代码已在 https://koala36m.github.io/ 公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025. Project page: https://koala36m.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.08260v2",
      "published_date": "2024-10-10 17:57:49 UTC",
      "updated_date": "2025-04-26 17:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:36:04.416778"
    },
    {
      "arxiv_id": "2410.08188v1",
      "title": "DifFRelight: Diffusion-Based Facial Performance Relighting",
      "title_zh": "翻译失败",
      "authors": [
        "Mingming He",
        "Pascal Clausen",
        "Ahmet Levent Taşel",
        "Li Ma",
        "Oliver Pilarski",
        "Wenqi Xian",
        "Laszlo Rikker",
        "Xueming Yu",
        "Ryan Burgert",
        "Ning Yu",
        "Paul Debevec"
      ],
      "abstract": "We present a novel framework for free-viewpoint facial performance relighting\nusing diffusion-based image-to-image translation. Leveraging a subject-specific\ndataset containing diverse facial expressions captured under various lighting\nconditions, including flat-lit and one-light-at-a-time (OLAT) scenarios, we\ntrain a diffusion model for precise lighting control, enabling high-fidelity\nrelit facial images from flat-lit inputs. Our framework includes\nspatially-aligned conditioning of flat-lit captures and random noise, along\nwith integrated lighting information for global control, utilizing prior\nknowledge from the pre-trained Stable Diffusion model. This model is then\napplied to dynamic facial performances captured in a consistent flat-lit\nenvironment and reconstructed for novel-view synthesis using a scalable dynamic\n3D Gaussian Splatting method to maintain quality and consistency in the relit\nresults. In addition, we introduce unified lighting control by integrating a\nnovel area lighting representation with directional lighting, allowing for\njoint adjustments in light size and direction. We also enable high dynamic\nrange imaging (HDRI) composition using multiple directional lights to produce\ndynamic sequences under complex lighting conditions. Our evaluations\ndemonstrate the models efficiency in achieving precise lighting control and\ngeneralizing across various facial expressions while preserving detailed\nfeatures such as skintexture andhair. The model accurately reproduces complex\nlighting effects like eye reflections, subsurface scattering, self-shadowing,\nand translucency, advancing photorealism within our framework.",
      "tldr_zh": "这篇论文提出了 DifFRelight，一个基于 Diffusion-Based 图像到图像翻译的框架，用于实现自由视点面部性能重照明。该框架利用主题特定的数据集训练扩散模型，从平光输入生成高保真重照明图像，并整合 Stable Diffusion 的先验知识以及动态 3D Gaussian Splatting 方法来处理新视图合成和照明控制。创新点包括统一的区域照明表示和方向照明调整，以及支持 HDRI 合成；实验结果显示，该模型在精确控制复杂照明效果（如眼部反射和自阴影）方面高效，并能泛化到各种面部表情，同时保留皮肤纹理和头发细节。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, SIGGRAPH Asia 2024 Conference Papers (SA Conference Papers\n  '24), December 3--6, 2024, Tokyo, Japan. Project page:\n  https://www.eyelinestudios.com/research/diffrelight.html",
      "pdf_url": "http://arxiv.org/pdf/2410.08188v1",
      "published_date": "2024-10-10 17:56:44 UTC",
      "updated_date": "2024-10-10 17:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:36:17.547188"
    },
    {
      "arxiv_id": "2410.08182v2",
      "title": "MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Hu",
        "Jia-Chen Gu",
        "Zi-Yi Dou",
        "Mohsen Fayyaz",
        "Pan Lu",
        "Kai-Wei Chang",
        "Nanyun Peng"
      ],
      "abstract": "Existing multimodal retrieval benchmarks primarily focus on evaluating\nwhether models can retrieve and utilize external textual knowledge for question\nanswering. However, there are scenarios where retrieving visual information is\neither more beneficial or easier to access than textual data. In this paper, we\nintroduce a multimodal retrieval-augmented generation benchmark, MRAG-Bench, in\nwhich we systematically identify and categorize scenarios where visually\naugmented knowledge is better than textual knowledge, for instance, more images\nfrom varying viewpoints. MRAG-Bench consists of 16,130 images and 1,353\nhuman-annotated multiple-choice questions across 9 distinct scenarios. With\nMRAG-Bench, we conduct an evaluation of 10 open-source and 4 proprietary large\nvision-language models (LVLMs). Our results show that all LVLMs exhibit greater\nimprovements when augmented with images compared to textual knowledge,\nconfirming that MRAG-Bench is vision-centric. Additionally, we conduct\nextensive analysis with MRAG-Bench, which offers valuable insights into\nretrieval-augmented LVLMs. Notably, the top-performing model, GPT-4o, faces\nchallenges in effectively leveraging retrieved knowledge, achieving only a\n5.82% improvement with ground-truth information, in contrast to a 33.16%\nimprovement observed in human participants. These findings highlight the\nimportance of MRAG-Bench in encouraging the community to enhance LVLMs' ability\nto utilize retrieved visual knowledge more effectively.",
      "tldr_zh": "本论文引入了 MRAG-Bench，这是一个以视觉为中心的多模态检索增强生成基准，系统识别并分类了视觉知识（如不同视角的图像）优于文本知识的场景，以评估大型视觉语言模型 (LVLMs) 的性能。该基准包含 16,130 张图像和 1,353 个人工标注的多选题，跨越 9 个不同场景，并对 10 个开源和 4 个专有 LVLMs 进行了评估。结果显示，所有 LVLMs 在使用图像增强时比文本知识有更大改善，但顶级模型 GPT-4o 只实现了 5.82% 的性能提升，与人类参与者的 33.16% 形成鲜明对比。这些发现强调了 MRAG-Bench 在推动 LVLMs 更有效地利用检索视觉知识方面的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08182v2",
      "published_date": "2024-10-10 17:55:02 UTC",
      "updated_date": "2025-03-19 20:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:36:29.377980"
    },
    {
      "arxiv_id": "2410.08174v2",
      "title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models",
      "title_zh": "采样然后识别：多模态大型语言模型中风险控制和评估的通用框架",
      "authors": [
        "Qingni Wang",
        "Tiantian Geng",
        "Zhiyuan Wang",
        "Teng Wang",
        "Bo Fu",
        "Feng Zheng"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) exhibit promising advancements\nacross various tasks, yet they still encounter significant trustworthiness\nissues. Prior studies apply Split Conformal Prediction (SCP) in language\nmodeling to construct prediction sets with statistical guarantees. However,\nthese methods typically rely on internal model logits or are restricted to\nmultiple-choice settings, which hampers their generalizability and adaptability\nin dynamic, open-ended environments. In this paper, we introduce TRON, a\ntwo-step framework for risk control and assessment, applicable to any MLLM that\nsupports sampling in both open-ended and closed-ended scenarios. TRON comprises\ntwo main components: (1) a novel conformal score to sample response sets of\nminimum size, and (2) a nonconformity score to identify high-quality responses\nbased on self-consistency theory, controlling the error rates by two specific\nrisk levels. Furthermore, we investigate semantic redundancy in prediction sets\nwithin open-ended contexts for the first time, leading to a promising\nevaluation metric for MLLMs based on average set size. Our comprehensive\nexperiments across four Video Question-Answering (VideoQA) datasets utilizing\neight MLLMs show that TRON achieves desired error rates bounded by two\nuser-specified risk levels. Additionally, deduplicated prediction sets maintain\nadaptiveness while being more efficient and stable for risk assessment under\ndifferent risk levels.",
      "tldr_zh": "该研究提出TRON框架，一种通用的风险控制和评估方法，针对Multimodal Large Language Models (MLLMs)在开放和封闭场景中的可信度问题。TRON包括两个关键组件：一个新的conformal score用于采样最小响应集，以及一个基于自一致性理论的nonconformity score来识别高质量响应，并通过两个风险水平控制错误率。该框架还首次探讨了开放环境中的语义冗余，并引入基于平均集大小的评估指标。在四个Video Question-Answering (VideoQA)数据集上使用八个MLLMs的实验显示，TRON实现了预期的错误率控制，且通过去重预测集提升了效率和稳定性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08174v2",
      "published_date": "2024-10-10 17:50:42 UTC",
      "updated_date": "2024-12-14 10:34:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:36:40.125301"
    },
    {
      "arxiv_id": "2410.08172v1",
      "title": "On the Evaluation of Generative Robotic Simulations",
      "title_zh": "关于生成式机器人模拟的评估",
      "authors": [
        "Feng Chen",
        "Botian Xu",
        "Pu Hua",
        "Peiqi Duan",
        "Yanchao Yang",
        "Yi Ma",
        "Huazhe Xu"
      ],
      "abstract": "Due to the difficulty of acquiring extensive real-world data, robot\nsimulation has become crucial for parallel training and sim-to-real transfer,\nhighlighting the importance of scalable simulated robotic tasks. Foundation\nmodels have demonstrated impressive capacities in autonomously generating\nfeasible robotic tasks. However, this new paradigm underscores the challenge of\nadequately evaluating these autonomously generated tasks. To address this, we\npropose a comprehensive evaluation framework tailored to generative\nsimulations. Our framework segments evaluation into three core aspects:\nquality, diversity, and generalization. For single-task quality, we evaluate\nthe realism of the generated task and the completeness of the generated\ntrajectories using large language models and vision-language models. In terms\nof diversity, we measure both task and data diversity through text similarity\nof task descriptions and world model loss trained on collected task\ntrajectories. For task-level generalization, we assess the zero-shot\ngeneralization ability on unseen tasks of a policy trained with multiple\ngenerated tasks. Experiments conducted on three representative task generation\npipelines demonstrate that the results from our framework are highly consistent\nwith human evaluations, confirming the feasibility and validity of our\napproach. The findings reveal that while metrics of quality and diversity can\nbe achieved through certain methods, no single approach excels across all\nmetrics, suggesting a need for greater focus on balancing these different\nmetrics. Additionally, our analysis further highlights the common challenge of\nlow generalization capability faced by current works. Our anonymous website:\nhttps://sites.google.com/view/evaltasks.",
      "tldr_zh": "该论文探讨了机器人模拟任务的生成评估问题，强调了由于真实数据获取困难，自主生成任务的重要性，但评估挑战突出。研究提出一个全面评估框架，针对生成模拟任务，从质量、多样性和泛化三个方面进行评估：质量使用大型语言模型(LLMs)和视觉语言模型(VLMs)检查任务真实性和轨迹完整性；多样性通过任务描述的文本相似性和世界模型损失衡量任务及数据多样；泛化评估策略在多个生成任务上训练后的零样本泛化能力。实验在三个任务生成管道上验证了框架的有效性，与人工评估高度一致，并发现当前方法在平衡质量、多样性和泛化方面存在不足，亟需改进以提升整体性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://sites.google.com/view/evaltasks",
      "pdf_url": "http://arxiv.org/pdf/2410.08172v1",
      "published_date": "2024-10-10 17:49:25 UTC",
      "updated_date": "2024-10-10 17:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:36:52.389065"
    },
    {
      "arxiv_id": "2410.08164v1",
      "title": "Agent S: An Open Agentic Framework that Uses Computers Like a Human",
      "title_zh": "翻译失败",
      "authors": [
        "Saaket Agashe",
        "Jiuzhou Han",
        "Shuyu Gan",
        "Jiachen Yang",
        "Ang Li",
        "Xin Eric Wang"
      ],
      "abstract": "We present Agent S, an open agentic framework that enables autonomous\ninteraction with computers through a Graphical User Interface (GUI), aimed at\ntransforming human-computer interaction by automating complex, multi-step\ntasks. Agent S aims to address three key challenges in automating computer\ntasks: acquiring domain-specific knowledge, planning over long task horizons,\nand handling dynamic, non-uniform interfaces. To this end, Agent S introduces\nexperience-augmented hierarchical planning, which learns from external\nknowledge search and internal experience retrieval at multiple levels,\nfacilitating efficient task planning and subtask execution. In addition, it\nemploys an Agent-Computer Interface (ACI) to better elicit the reasoning and\ncontrol capabilities of GUI agents based on Multimodal Large Language Models\n(MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the\nbaseline by 9.37% on success rate (an 83.6% relative improvement) and achieves\na new state-of-the-art. Comprehensive analysis highlights the effectiveness of\nindividual components and provides insights for future improvements.\nFurthermore, Agent S demonstrates broad generalizability to different operating\nsystems on a newly-released WindowsAgentArena benchmark. Code available at\nhttps://github.com/simular-ai/Agent-S.",
      "tldr_zh": "我们介绍了 Agent S，一个开放的代理框架，它通过图形用户界面 (GUI) 实现自主计算机交互，旨在像人类一样自动化复杂多步任务，并解决领域特定知识获取、长任务规划以及动态接口的挑战。该框架采用 experience-augmented hierarchical planning 方法，从外部知识搜索和内部经验检索中学习，并在多个级别上进行任务规划和执行，同时利用 Agent-Computer Interface (ACI) 增强基于 Multimodal Large Language Models (MLLMs) 的推理和控制能力。在 OSWorld 基准测试中，Agent S 比基线成功率提高了 9.37%（相对改善 83.6%），达到新状态-of-the-art，并展示了在 WindowsAgentArena 上的广泛泛化潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 16 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08164v1",
      "published_date": "2024-10-10 17:43:51 UTC",
      "updated_date": "2024-10-10 17:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:37:07.472271"
    },
    {
      "arxiv_id": "2410.19749v1",
      "title": "Using AI Alignment Theory to understand the potential pitfalls of regulatory frameworks",
      "title_zh": "利用 AI Alignment Theory 理解监管框架的潜在陷阱",
      "authors": [
        "Alejandro Tlaie"
      ],
      "abstract": "This paper leverages insights from Alignment Theory (AT) research, which\nprimarily focuses on the potential pitfalls of technical alignment in\nArtificial Intelligence, to critically examine the European Union's Artificial\nIntelligence Act (EU AI Act). In the context of AT research, several key\nfailure modes - such as proxy gaming, goal drift, reward hacking or\nspecification gaming - have been identified. These can arise when AI systems\nare not properly aligned with their intended objectives. The central logic of\nthis report is: what can we learn if we treat regulatory efforts in the same\nway as we treat advanced AI systems? As we systematically apply these concepts\nto the EU AI Act, we uncover potential vulnerabilities and areas for\nimprovement in the regulation.",
      "tldr_zh": "本论文利用AI Alignment Theory (AT) 的研究见解，分析欧盟人工智能法案 (EU AI Act) 可能存在的缺陷，将监管框架视为类似于AI系统。AT 识别出的关键失败模式，包括proxy gaming、goal drift、reward hacking 和 specification gaming，这些问题可能在AI目标对齐不当时出现。论文通过系统应用这些概念，揭示了EU AI Act 的潜在漏洞，并提出改进建议，以增强监管框架的有效性和可靠性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19749v1",
      "published_date": "2024-10-10 17:38:38 UTC",
      "updated_date": "2024-10-10 17:38:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:37:15.242246"
    },
    {
      "arxiv_id": "2410.08143v2",
      "title": "DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Yutong Wang",
        "Jiali Zeng",
        "Xuebo Liu",
        "Derek F. Wong",
        "Fandong Meng",
        "Jie Zhou",
        "Min Zhang"
      ],
      "abstract": "Large language models (LLMs) have achieved reasonable quality improvements in\nmachine translation (MT). However, most current research on MT-LLMs still faces\nsignificant challenges in maintaining translation consistency and accuracy when\nprocessing entire documents. In this paper, we introduce DelTA, a\nDocument-levEL Translation Agent designed to overcome these limitations. DelTA\nfeatures a multi-level memory structure that stores information across various\ngranularities and spans, including Proper Noun Records, Bilingual Summary,\nLong-Term Memory, and Short-Term Memory, which are continuously retrieved and\nupdated by auxiliary LLM-based components. Experimental results indicate that\nDelTA significantly outperforms strong baselines in terms of translation\nconsistency and quality across four open/closed-source LLMs and two\nrepresentative document translation datasets, achieving an increase in\nconsistency scores by up to 4.58 percentage points and in COMET scores by up to\n3.16 points on average. DelTA employs a sentence-by-sentence translation\nstrategy, ensuring no sentence omissions and offering a memory-efficient\nsolution compared to the mainstream method. Furthermore, DelTA improves pronoun\nand context-dependent translation accuracy, and the summary component of the\nagent also shows promise as a tool for query-based summarization tasks. The\ncode and data of our approach are released at\nhttps://github.com/YutongWang1216/DocMTAgent.",
      "tldr_zh": "本文提出 DelTA，一种基于多级内存的在线文档级翻译代理，旨在解决 LLMs 在机器翻译中处理整个文档时的一致性和准确性挑战。DelTA 采用多级内存结构，包括 Proper Noun Records、Bilingual Summary、Long-Term Memory 和 Short-Term Memory，这些由辅助 LLM 组件持续检索和更新，并结合逐句翻译策略以确保无遗漏和内存高效。实验结果显示，DelTA 在四个开源/闭源 LLMs 和两个文档翻译数据集上，显著优于基线模型，提升翻译一致性分数高达 4.58 百分点和 COMET 分数高达 3.16 点，同时改善了代词和上下文相关翻译的准确性，并展示了摘要组件在查询-based 总结任务中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08143v2",
      "published_date": "2024-10-10 17:30:09 UTC",
      "updated_date": "2025-03-05 17:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:37:28.272073"
    },
    {
      "arxiv_id": "2410.08134v1",
      "title": "Steering Masked Discrete Diffusion Models via Discrete Denoising Posterior Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jarrid Rector-Brooks",
        "Mohsin Hasan",
        "Zhangzhi Peng",
        "Zachary Quinn",
        "Chenghao Liu",
        "Sarthak Mittal",
        "Nouha Dziri",
        "Michael Bronstein",
        "Yoshua Bengio",
        "Pranam Chatterjee",
        "Alexander Tong",
        "Avishek Joey Bose"
      ],
      "abstract": "Generative modeling of discrete data underlies important applications\nspanning text-based agents like ChatGPT to the design of the very building\nblocks of life in protein sequences. However, application domains need to exert\ncontrol over the generated data by steering the generative process - typically\nvia RLHF - to satisfy a specified property, reward, or affinity metric. In this\npaper, we study the problem of steering Masked Diffusion Models (MDMs), a\nrecent class of discrete diffusion models that offer a compelling alternative\nto traditional autoregressive models. We introduce Discrete Denoising Posterior\nPrediction (DDPP), a novel framework that casts the task of steering\npre-trained MDMs as a problem of probabilistic inference by learning to sample\nfrom a target Bayesian posterior. Our DDPP framework leads to a family of three\nnovel objectives that are all simulation-free, and thus scalable while applying\nto general non-differentiable reward functions. Empirically, we instantiate\nDDPP by steering MDMs to perform class-conditional pixel-level image modeling,\nRLHF-based alignment of MDMs using text-based rewards, and finetuning protein\nlanguage models to generate more diverse secondary structures and shorter\nproteins. We substantiate our designs via wet-lab validation, where we observe\ntransient expression of reward-optimized protein sequences.",
      "tldr_zh": "本研究探讨了如何引导Masked Diffusion Models (MDMs)以生成满足特定属性或奖励的离散数据，提出了Discrete Denoising Posterior Prediction (DDPP)框架，将此任务转化为从目标贝叶斯后验中采样的概率推断问题。DDPP引入了三种模拟-free且可扩展的目标，适用于一般非可微奖励函数，从而避免了传统RLHF方法的复杂性。实验验证包括引导MDMs进行类条件像素级图像建模、基于文本奖励的模型对齐，以及微调蛋白质语言模型以生成更多样化的二级结构和更短蛋白质；湿实验室测试进一步证实了奖励优化蛋白序列的实际表达效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08134v1",
      "published_date": "2024-10-10 17:18:30 UTC",
      "updated_date": "2024-10-10 17:18:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:38:34.255832"
    },
    {
      "arxiv_id": "2410.08133v1",
      "title": "Assessing Episodic Memory in LLMs with Sequence Order Recall Tasks",
      "title_zh": "使用序列顺序回忆任务评估大语言模型",
      "authors": [
        "Mathis Pink",
        "Vy A. Vo",
        "Qinyuan Wu",
        "Jianing Mu",
        "Javier S. Turek",
        "Uri Hasson",
        "Kenneth A. Norman",
        "Sebastian Michelmann",
        "Alexander Huth",
        "Mariya Toneva"
      ],
      "abstract": "Current LLM benchmarks focus on evaluating models' memory of facts and\nsemantic relations, primarily assessing semantic aspects of long-term memory.\nHowever, in humans, long-term memory also includes episodic memory, which links\nmemories to their contexts, such as the time and place they occurred. The\nability to contextualize memories is crucial for many cognitive tasks and\neveryday functions. This form of memory has not been evaluated in LLMs with\nexisting benchmarks. To address the gap in evaluating memory in LLMs, we\nintroduce Sequence Order Recall Tasks (SORT), which we adapt from tasks used to\nstudy episodic memory in cognitive psychology. SORT requires LLMs to recall the\ncorrect order of text segments, and provides a general framework that is both\neasily extendable and does not require any additional annotations. We present\nan initial evaluation dataset, Book-SORT, comprising 36k pairs of segments\nextracted from 9 books recently added to the public domain. Based on a human\nexperiment with 155 participants, we show that humans can recall sequence order\nbased on long-term memory of a book. We find that models can perform the task\nwith high accuracy when relevant text is given in-context during the SORT\nevaluation. However, when presented with the book text only during training,\nLLMs' performance on SORT falls short. By allowing to evaluate more aspects of\nmemory, we believe that SORT will aid in the emerging development of\nmemory-augmented models.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）的情景记忆（episodic memory）评估问题，指出现有基准测试主要关注事实和语义记忆，而忽略了记忆与上下文（如时间和地点）的关联。研究引入Sequence Order Recall Tasks (SORT)，一种从认知心理学改编的框架，要求LLMs回忆文本片段的正确顺序，并创建了Book-SORT数据集（包含36k对书籍片段），无需额外标注。实验结果显示，LLMs在提供上下文时准确率较高，但仅依赖训练数据时表现不足；此外，通过155名参与者的人类实验，证实人类能基于长期记忆完成类似任务，这有助于推动记忆增强模型的开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08133v1",
      "published_date": "2024-10-10 17:17:38 UTC",
      "updated_date": "2024-10-10 17:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:37:53.022012"
    },
    {
      "arxiv_id": "2410.09116v1",
      "title": "Optimizing Hard-to-Place Kidney Allocation: A Machine Learning Approach to Center Ranking",
      "title_zh": "优化难以安置的肾脏分配：一种用于中心排名的机器学习方法",
      "authors": [
        "Sean Berry",
        "Berk Gorgulu",
        "Sait Tunc",
        "Mucahit Cevik",
        "Matthew J Ellis"
      ],
      "abstract": "Kidney transplantation is the preferred treatment for end-stage renal\ndisease, yet the scarcity of donors and inefficiencies in allocation systems\ncreate major bottlenecks, resulting in prolonged wait times and alarming\nmortality rates. Despite their severe scarcity, timely and effective\ninterventions to prevent non-utilization of life-saving organs remain\ninadequate. Expedited out-of-sequence placement of hard-to-place kidneys to\ncenters with the highest likelihood of utilizing them has been recommended in\nthe literature as an effective strategy to improve placement success.\nNevertheless, current attempts towards this practice is non-standardized and\nheavily rely on the subjective judgment of the decision-makers. This paper\nproposes a novel data-driven, machine learning-based ranking system for\nallocating hard-to-place kidneys to centers with a higher likelihood of\naccepting and successfully transplanting them. Using the national deceased\ndonor kidney offer and transplant datasets, we construct a unique dataset with\ndonor-, center-, and patient-specific features. We propose a data-driven\nout-of-sequence placement policy that utilizes machine learning models to\npredict the acceptance probability of a given kidney by a set of transplant\ncenters, ranking them accordingly based on their likelihood of acceptance. Our\nexperiments demonstrate that the proposed policy can reduce the average number\nof centers considered before placement by fourfold for all kidneys and tenfold\nfor hard-to-place kidneys. This significant reduction indicates that our method\ncan improve the utilization of hard-to-place kidneys and accelerate their\nacceptance, ultimately reducing patient mortality and the risk of graft\nfailure. Further, we utilize machine learning interpretability tools to provide\ninsights into factors influencing the kidney allocation decisions.",
      "tldr_zh": "这篇论文针对肾移植中难分配（hard-to-place）肾脏的问题，提出了一种基于 Machine Learning 的数据驱动排名系统，以优化肾脏分配效率。方法包括构建包含捐赠者、中心和患者特定特征的独特数据集，并利用 Machine Learning 模型预测各移植中心的接受概率，从而对中心进行排名，实现出-of-sequence 放置策略。实验结果显示，该策略可将平均中心考虑数量减少四倍（所有肾脏）和十倍（难分配肾脏），从而提高肾脏利用率、加速接受过程，并降低患者死亡风险和移植物失败风险。此外，论文通过 Machine Learning 可解释性工具，提供了影响分配决策的关键因素洞见。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09116v1",
      "published_date": "2024-10-10 17:15:41 UTC",
      "updated_date": "2024-10-10 17:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:38:04.361956"
    },
    {
      "arxiv_id": "2410.08126v2",
      "title": "Mars: Situated Inductive Reasoning in an Open-World Environment",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojuan Tang",
        "Jiaqi Li",
        "Yitao Liang",
        "Song-chun Zhu",
        "Muhan Zhang",
        "Zilong Zheng"
      ],
      "abstract": "Large Language Models (LLMs) trained on massive corpora have shown remarkable\nsuccess in knowledge-intensive tasks. Yet, most of them rely on pre-stored\nknowledge. Inducing new general knowledge from a specific environment and\nperforming reasoning with the acquired knowledge -- \\textit{situated inductive\nreasoning}, is crucial and challenging for machine intelligence. In this paper,\nwe design Mars, an interactive environment devised for situated inductive\nreasoning. It introduces counter-commonsense game mechanisms by modifying\nterrain, survival setting and task dependency while adhering to certain\nprinciples. In Mars, agents need to actively interact with their surroundings,\nderive useful rules and perform decision-making tasks in specific contexts. We\nconduct experiments on various RL-based and LLM-based methods, finding that\nthey all struggle on this challenging situated inductive reasoning benchmark.\nFurthermore, we explore \\textit{Induction from Reflection}, where we instruct\nagents to perform inductive reasoning from history trajectory. The superior\nperformance underscores the importance of inductive reasoning in Mars. Through\nMars, we aim to galvanize advancements in situated inductive reasoning and set\nthe stage for developing the next generation of AI systems that can reason in\nan adaptive and context-sensitive way.",
      "tldr_zh": "这篇论文介绍了 Mars，一个设计用于情境归纳推理（Situated Inductive Reasoning）的交互式开放世界环境，旨在帮助 AI 从特定环境中归纳新知识并进行决策。Mars 通过修改地形、生存设置和任务依赖，引入反常识机制，让代理需主动互动、推导出有用规则，并在特定上下文中执行任务。实验结果显示，各种基于 RL 和 LLM 的方法在这一基准上表现不佳，而采用 Induction from Reflection 的方法——让代理从历史轨迹中进行归纳推理——取得了显著优势。该框架旨在推动 AI 系统的适应性和上下文敏感性发展，为下一代机器智能奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024 Track Datasets and Benchmarks. Project page:\n  https://marscrafter.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2410.08126v2",
      "published_date": "2024-10-10 17:10:34 UTC",
      "updated_date": "2024-10-31 11:11:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:38:17.143779"
    },
    {
      "arxiv_id": "2410.08121v1",
      "title": "Heterogeneous Graph Auto-Encoder for CreditCard Fraud Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Moirangthem Tiken Singh",
        "Rabinder Kumar Prasad",
        "Gurumayum Robert Michael",
        "N K Kaphungkui",
        "N. Hemarjit Singh"
      ],
      "abstract": "The digital revolution has significantly impacted financial transactions,\nleading to a notable increase in credit card usage. However, this convenience\ncomes with a trade-off: a substantial rise in fraudulent activities.\nTraditional machine learning methods for fraud detection often struggle to\ncapture the inherent interconnectedness within financial data. This paper\nproposes a novel approach for credit card fraud detection that leverages Graph\nNeural Networks (GNNs) with attention mechanisms applied to heterogeneous graph\nrepresentations of financial data. Unlike homogeneous graphs, heterogeneous\ngraphs capture intricate relationships between various entities in the\nfinancial ecosystem, such as cardholders, merchants, and transactions,\nproviding a richer and more comprehensive data representation for fraud\nanalysis. To address the inherent class imbalance in fraud data, where genuine\ntransactions significantly outnumber fraudulent ones, the proposed approach\nintegrates an autoencoder. This autoencoder, trained on genuine transactions,\nlearns a latent representation and flags deviations during reconstruction as\npotential fraud. This research investigates two key questions: (1) How\neffectively can a GNN with an attention mechanism detect and prevent credit\ncard fraud when applied to a heterogeneous graph? (2) How does the efficacy of\nthe autoencoder with attention approach compare to traditional methods? The\nresults are promising, demonstrating that the proposed model outperforms\nbenchmark algorithms such as Graph Sage and FI-GRL, achieving a superior AUC-PR\nof 0.89 and an F1-score of 0.81. This research significantly advances fraud\ndetection systems and the overall security of financial transactions by\nleveraging GNNs with attention mechanisms and addressing class imbalance\nthrough an autoencoder.",
      "tldr_zh": "这篇论文针对信用卡欺诈检测问题，提出了一种基于异构图（heterogeneous graphs）的Graph Neural Networks (GNNs)框架，结合注意力机制（attention mechanisms），以捕捉金融数据中卡持有者、商户和交易等实体间的复杂关系。论文引入autoencoder来处理类别不平衡问题，通过在正常交易上训练autoencoder并检测重建偏差来识别潜在欺诈。实验结果显示，该模型在AUC-PR达到0.89、F1-score达到0.81，优于基准算法如Graph Sage和FI-GRL，从而显著提升了欺诈检测系统的准确性和金融交易安全性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08121v1",
      "published_date": "2024-10-10 17:05:27 UTC",
      "updated_date": "2024-10-10 17:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:39:15.174847"
    },
    {
      "arxiv_id": "2410.08115v2",
      "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Weize Chen",
        "Jiarui Yuan",
        "Chen Qian",
        "Cheng Yang",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) show remarkable\npotential in collaborative problem-solving, yet they still face critical\nchallenges: low communication efficiency, poor scalability, and a lack of\neffective parameter-updating optimization methods. We present Optima, a novel\nframework that addresses these issues by significantly enhancing both\ncommunication efficiency and task effectiveness in LLM-based MAS through LLM\ntraining. Optima employs an iterative generate, rank, select, and train\nparadigm with a reward function balancing task performance, token efficiency,\nand communication readability. We explore various RL algorithms, including\nSupervised Fine-Tuning, Direct Preference Optimization, and their hybrid\napproaches, providing insights into their effectiveness-efficiency trade-offs.\nWe integrate Monte Carlo Tree Search-inspired techniques for DPO data\ngeneration, treating conversation turns as tree nodes to explore diverse\ninteraction paths. Evaluated on common multi-agent tasks, including\ninformation-asymmetric question answering and complex reasoning, Optima shows\nconsistent and substantial improvements over single-agent baselines and vanilla\nMAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than\n10\\% tokens on tasks requiring heavy information exchange. Moreover, Optima's\nefficiency gains open new possibilities for leveraging inference-compute more\neffectively, leading to improved inference-time scaling laws. By addressing\nfundamental challenges in LLM-based MAS, Optima shows the potential towards\nscalable, efficient, and effective MAS\n(https://chenweize1998.github.io/optima-project-page).",
      "tldr_zh": "该研究提出Optima框架，旨在优化基于Large Language Model (LLM)的多智能体系统 (MAS)，解决其低通信效率、可扩展性差和参数更新优化不足的问题。Optima采用迭代的生成、排名、选择和训练范式，结合奖励函数平衡任务性能、token效率和通信可读性，并探索Supervised Fine-Tuning (SFT)、Direct Preference Optimization (DPO)及其混合算法，同时融入Monte Carlo Tree Search (MCTS)启发的技术生成数据。在信息不对称问答和复杂推理任务上，Optima相较于基于Llama 3 8B的单智能体基线和普通MAS，实现高达2.8倍的性能提升，同时仅使用少于10%的token。总体而言，该框架提升了MAS的可扩展性和效率，为更有效的推理计算缩放定律提供了新可能性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2410.08115v2",
      "published_date": "2024-10-10 17:00:06 UTC",
      "updated_date": "2025-02-18 12:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:38:46.986939"
    },
    {
      "arxiv_id": "2410.08113v1",
      "title": "Robust AI-Generated Text Detection by Restricted Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Kristian Kuznetsov",
        "Eduard Tulchinskii",
        "Laida Kushnareva",
        "German Magai",
        "Serguei Barannikov",
        "Sergey Nikolenko",
        "Irina Piontkovskaya"
      ],
      "abstract": "Growing amount and quality of AI-generated texts makes detecting such content\nmore difficult. In most real-world scenarios, the domain (style and topic) of\ngenerated data and the generator model are not known in advance. In this work,\nwe focus on the robustness of classifier-based detectors of AI-generated text,\nnamely their ability to transfer to unseen generators or semantic domains. We\ninvestigate the geometry of the embedding space of Transformer-based text\nencoders and show that clearing out harmful linear subspaces helps to train a\nrobust classifier, ignoring domain-specific spurious features. We investigate\nseveral subspace decomposition and feature selection strategies and achieve\nsignificant improvements over state of the art methods in cross-domain and\ncross-generator transfer. Our best approaches for head-wise and\ncoordinate-based subspace removal increase the mean out-of-distribution (OOD)\nclassification score by up to 9% and 14% in particular setups for RoBERTa and\nBERT embeddings respectively. We release our code and data:\nhttps://github.com/SilverSolver/RobustATD",
      "tldr_zh": "该研究针对AI-generated text检测的鲁棒性问题，提出了一种基于Restricted Embeddings的方法，以应对未知生成器模型和语义领域的挑战。通过调查Transformer-based文本编码器的嵌入空间几何，该方法清除有害线性子空间，忽略领域特定的无关特征，并采用子空间分解和特征选择策略来训练鲁棒分类器。实验结果显示，该方法在跨域和跨生成器转移场景下显著提升性能，其中RoBERTa嵌入的平均out-of-distribution (OOD)分类分数提高最多9%，BERT嵌入提高最多14%。作者发布了代码和数据，以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08113v1",
      "published_date": "2024-10-10 16:58:42 UTC",
      "updated_date": "2024-10-10 16:58:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:38:58.472775"
    },
    {
      "arxiv_id": "2410.08111v1",
      "title": "Active Fourier Auditor for Estimating Distributional Properties of ML Models",
      "title_zh": "主动傅立叶审计器用于估计机器学习模型的分布属性",
      "authors": [
        "Ayoub Ajarra",
        "Bishwamittra Ghosh",
        "Debabrota Basu"
      ],
      "abstract": "With the pervasive deployment of Machine Learning (ML) models in real-world\napplications, verifying and auditing properties of ML models have become a\ncentral concern. In this work, we focus on three properties: robustness,\nindividual fairness, and group fairness. We discuss two approaches for auditing\nML model properties: estimation with and without reconstruction of the target\nmodel under audit. Though the first approach is studied in the literature, the\nsecond approach remains unexplored. For this purpose, we develop a new\nframework that quantifies different properties in terms of the Fourier\ncoefficients of the ML model under audit but does not parametrically\nreconstruct it. We propose the Active Fourier Auditor (AFA), which queries\nsample points according to the Fourier coefficients of the ML model, and\nfurther estimates the properties. We derive high probability error bounds on\nAFA's estimates, along with the worst-case lower bounds on the sample\ncomplexity to audit them. Numerically we demonstrate on multiple datasets and\nmodels that AFA is more accurate and sample-efficient to estimate the\nproperties of interest than the baselines.",
      "tldr_zh": "该论文针对机器学习（ML）模型的鲁棒性（robustness）、个体公平性（individual fairness）和群体公平性（group fairness）等分布属性，提出了一种新的审计框架。该框架利用傅立叶系数（Fourier coefficients）量化这些属性，而无需参数化重建目标模型。作者开发了 Active Fourier Auditor (AFA)，该方法通过根据模型的傅立叶系数查询样本点来估计属性，并提供了高概率误差界和样本复杂度下界。实验结果显示，AFA 在多个数据集和模型上比基线方法更准确和样本高效，从而提升了 ML 模型审计的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08111v1",
      "published_date": "2024-10-10 16:57:01 UTC",
      "updated_date": "2024-10-10 16:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:39:09.691943"
    },
    {
      "arxiv_id": "2410.08109v3",
      "title": "A Closer Look at Machine Unlearning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojian Yuan",
        "Tianyu Pang",
        "Chao Du",
        "Kejiang Chen",
        "Weiming Zhang",
        "Min Lin"
      ],
      "abstract": "Large language models (LLMs) may memorize sensitive or copyrighted content,\nraising privacy and legal concerns. Due to the high cost of retraining from\nscratch, researchers attempt to employ machine unlearning to remove specific\ncontent from LLMs while preserving the overall performance. In this paper, we\ndiscuss several issues in machine unlearning for LLMs and provide our insights\non possible approaches. To address the issue of inadequate evaluation of model\noutputs after unlearning, we introduce three additional metrics to evaluate\ntoken diversity, sentence semantics, and factual correctness. We then\ncategorize unlearning methods into untargeted and targeted, and discuss their\nissues respectively. Specifically, the behavior that untargeted unlearning\nattempts to approximate is unpredictable and may involve hallucinations, and\nexisting regularization is insufficient for targeted unlearning. To alleviate\nthese issues, we propose using the objective of maximizing entropy (ME) for\nuntargeted unlearning and incorporate answer preservation (AP) loss as\nregularization for targeted unlearning. Experimental results across three\nscenarios, i.e., fictitious unlearning, continual unlearning, and real-world\nunlearning, demonstrate the effectiveness of our approaches. The code is\navailable at https://github.com/sail-sg/closer-look-LLM-unlearning.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中机器遗忘（machine unlearning）的关键问题，旨在移除敏感或版权内容，同时保持模型整体性能，以解决隐私和法律担忧。作者引入了三个新指标，用于评估令牌多样性、句子语义和事实正确性，以改进遗忘后的模型输出评估，并将遗忘方法分为无目标（untargeted）和有目标（targeted）类型。针对无目标遗忘的不可预测性和幻觉问题，他们提出使用最大熵（ME）目标；针对有目标遗忘的正则化不足，则添加答案保留（AP）损失作为优化。实验在虚构、持续和真实世界场景中验证了这些方法的有效性，代码已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08109v3",
      "published_date": "2024-10-10 16:56:05 UTC",
      "updated_date": "2025-03-03 02:45:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:39:30.006128"
    },
    {
      "arxiv_id": "2410.08098v1",
      "title": "A Generative AI Technique for Synthesizing a Digital Twin for U.S. Residential Solar Adoption and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Aparna Kishore",
        "Swapna Thorve",
        "Madhav Marathe"
      ],
      "abstract": "Residential rooftop solar adoption is considered crucial for reducing carbon\nemissions. The lack of photovoltaic (PV) data at a finer resolution (e.g.,\nhousehold, hourly levels) poses a significant roadblock to informed\ndecision-making. We discuss a novel methodology to generate a highly granular,\nresidential-scale realistic dataset for rooftop solar adoption across the\ncontiguous United States. The data-driven methodology consists of: (i)\nintegrated machine learning models to identify PV adopters, (ii) methods to\naugment the data using explainable AI techniques to glean insights about key\nfeatures and their interactions, and (iii) methods to generate household-level\nhourly solar energy output using an analytical model. The resulting synthetic\ndatasets are validated using real-world data and can serve as a digital twin\nfor modeling downstream tasks. Finally, a policy-based case study utilizing the\ndigital twin for Virginia demonstrated increased rooftop solar adoption with\nthe 30\\% Federal Solar Investment Tax Credit, especially in\nLow-to-Moderate-Income communities.",
      "tldr_zh": "该论文提出了一种基于生成式AI（Generative AI）的技术，用于合成美国住宅太阳能采用和发电的数字孪生（Digital Twin），以解决缺乏精细分辨率（如家庭和小时级）光伏（PV）数据的问题。主要方法包括整合机器学习（Machine Learning）模型识别PV采用者、使用可解释AI（Explainable AI）技术增强数据并分析关键特征交互，以及通过分析模型生成家庭级别的每小时太阳能输出。生成的合成数据集经真实数据验证，可用于下游建模任务；案例研究显示，在弗吉尼亚州实施30%联邦太阳能投资税收抵免后，屋顶太阳能采用率显著增加，尤其在低到中等收入社区。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages including references and supplementary",
      "pdf_url": "http://arxiv.org/pdf/2410.08098v1",
      "published_date": "2024-10-10 16:41:43 UTC",
      "updated_date": "2024-10-10 16:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:39:40.565725"
    },
    {
      "arxiv_id": "2410.08256v1",
      "title": "AdaShadow: Responsive Test-time Model Adaptation in Non-stationary Mobile Environments",
      "title_zh": "AdaShadow：响应式的测试时模型适应于非平稳",
      "authors": [
        "Cheng Fang",
        "Sicong Liu",
        "Zimu Zhou",
        "Bin Guo",
        "Jiaqi Tang",
        "Ke Ma",
        "Zhiwen Yu"
      ],
      "abstract": "On-device adapting to continual, unpredictable domain shifts is essential for\nmobile applications like autonomous driving and augmented reality to deliver\nseamless user experiences in evolving environments. Test-time adaptation (TTA)\nemerges as a promising solution by tuning model parameters with unlabeled live\ndata immediately before prediction. However, TTA's unique\nforward-backward-reforward pipeline notably increases the latency over standard\ninference, undermining the responsiveness in time-sensitive mobile\napplications. This paper presents AdaShadow, a responsive test-time adaptation\nframework for non-stationary mobile data distribution and resource dynamics via\nselective updates of adaptation-critical layers. Although the tactic is\nrecognized in generic on-device training, TTA's unsupervised and online context\npresents unique challenges in estimating layer importance and latency, as well\nas scheduling the optimal layer update plan. AdaShadow addresses these\nchallenges with a backpropagation-free assessor to rapidly identify critical\nlayers, a unit-based runtime predictor to account for resource dynamics in\nlatency estimation, and an online scheduler for prompt layer update planning.\nAlso, AdaShadow incorporates a memory I/O-aware computation reuse scheme to\nfurther reduce latency in the reforward pass. Results show that AdaShadow\nachieves the best accuracy-latency balance under continual shifts. At low\nmemory and energy costs, Adashadow provides a 2x to 3.5x speedup (ms-level)\nover state-of-the-art TTA methods with comparable accuracy and a 14.8% to 25.4%\naccuracy boost over efficient supervised methods with similar latency.",
      "tldr_zh": "该论文提出AdaShadow框架，用于在非平稳移动环境中实现响应式的Test-time Adaptation (TTA)，以应对移动应用（如自动驾驶和增强现实）面对持续领域转移时的延迟问题。AdaShadow通过选择性地更新适应关键层来优化TTA的forward-backward-reforward流程，包括使用无反向传播评估器快速识别关键层、基于单元的运行时预测器估计延迟以及在线调度器规划更新策略，并融入内存I/O感知的计算重用方案以减少延迟。实验结果显示，AdaShadow在低内存和能量消耗下，比最先进的TTA方法快2x到3.5x（毫秒级）且准确率相当，同时比高效监督方法准确率提升14.8%到25.4%，实现了最佳的准确率-延迟平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper is accepted by SenSys 2024. Copyright may be transferred\n  without notice",
      "pdf_url": "http://arxiv.org/pdf/2410.08256v1",
      "published_date": "2024-10-10 16:41:39 UTC",
      "updated_date": "2024-10-10 16:41:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:39:52.417764"
    },
    {
      "arxiv_id": "2410.08094v2",
      "title": "SAKA: An Intelligent Platform for Semi-automated Knowledge Graph Construction and Application",
      "title_zh": "SAKA：智能平台，用于半自动知识图谱构建和应用",
      "authors": [
        "Hanrong Zhang",
        "Xinyue Wang",
        "Jiabao Pan",
        "Hongwei Wang"
      ],
      "abstract": "Knowledge graph (KG) technology is extensively utilized in many areas, and\nmany companies offer applications based on KG. Nonetheless, most KG platforms\nnecessitate expertise and tremendous time and effort from users to construct KG\nrecords manually, which poses great difficulties for ordinary people.\nAdditionally, audio data is abundant and holds valuable information, but it is\nchallenging to transform it into a KG. What's more, the platforms usually do\nnot leverage the full potential of the KGs constructed by users. In this paper,\nwe propose an intelligent and user-friendly platform for Semi-automated KG\nConstruction and Application (SAKA) to address the aforementioned problems.\nPrimarily, users can semi-automatically construct KGs from structured data of\nnumerous areas by interacting with the platform, based on which multi-versions\nof KG can be stored, viewed, managed, and updated. Moreover, we propose an\nAudio-based KG Information Extraction (AGIE) method to establish KGs from audio\ndata. Lastly, the platform creates a semantic parsing-based knowledge base\nquestion answering (KBQA) system based on the user-created KGs. We prove the\nfeasibility of the semi-automatic KG construction method on the SAKA platform.",
      "tldr_zh": "本文提出 SAKA 平台，这是一个智能的半自动知识图谱 (KG) 构建和应用系统，旨在解决传统 KG 平台需要手动构建、耗时费力的问题，并处理音频数据转化为 KG 的挑战。平台允许用户通过交互从结构化数据半自动构建 KG，支持多版本存储、管理和更新，同时引入 Audio-based KG Information Extraction (AGIE) 方法从音频数据提取信息。最终，SAKA 基于用户创建的 KG 构建语义解析的知识库问答 (KBQA) 系统，并证明了半自动构建方法的 feasibility。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated Version",
      "pdf_url": "http://arxiv.org/pdf/2410.08094v2",
      "published_date": "2024-10-10 16:37:02 UTC",
      "updated_date": "2024-12-15 09:20:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:40:04.164909"
    },
    {
      "arxiv_id": "2410.08085v3",
      "title": "Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Sui",
        "Yufei He",
        "Zifeng Ding",
        "Bryan Hooi"
      ],
      "abstract": "Recent works integrating Knowledge Graphs (KGs) have led to promising\nimprovements in enhancing the reasoning accuracy of Large Language Models\n(LLMs). However, current benchmarks focus mainly on closed-ended tasks, leaving\na gap in the assessment of more complex real-world scenarios. This gap has also\nobscured the evaluation of KGs' potential to mitigate the problem of\nhallucination in LLMs. To fill the gap, we introduce OKGQA, a new benchmark\nspecifically designed to assess LLMs enhanced with KGs under open-ended,\nreal-world question answering scenarios. OKGQA is designed to closely reflect\nthe complexities of practical applications using questions from different\ntypes, and incorporates specific metrics to measure both hallucination ratio\nand the enhancement in reasoning capabilities. To consider the scenario in\nwhich KGs may have varying levels of mistakes, we propose another benchmark\nvariant OKGQA-P to assess model performance when the semantics and structure of\nKGs are deliberately perturbed and contaminated. OKGQA aims to (1) explore\nwhether KGs can make LLMs more trustworthy in an open-ended setting, and (2)\nconduct a comparative analysis to shed light on method design. We believe that\nthis study can facilitate a more complete performance comparison and encourage\ncontinuous improvement in integrating KGs with LLMs to reduce hallucination.",
      "tldr_zh": "本研究探讨了 Knowledge Graphs (KGs) 是否能提升 Large Language Models (LLMs) 在开放式问答中的可信赖性，特别是减少幻觉问题。研究者引入了新基准 OKGQA，用于评估 KGs 增强 LLMs 在真实世界开放式场景下的表现，该基准涵盖不同问题类型，并通过特定指标测量幻觉比例和推理能力提升。为模拟 KGs 可能存在的错误，提出 OKGQA-P 变体，通过故意扰动 KGs 的语义和结构来测试模型鲁棒性。该工作旨在通过实证分析比较不同方法，鼓励更可靠的 KGs 与 LLMs 整合。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08085v3",
      "published_date": "2024-10-10 16:29:21 UTC",
      "updated_date": "2025-02-19 08:25:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:40:16.657889"
    },
    {
      "arxiv_id": "2410.08081v3",
      "title": "Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning",
      "title_zh": "打包分析：打包在监督微调中更适用于大型模型或数据集",
      "authors": [
        "Shuhe Wang",
        "Guoyin Wang",
        "Yizhong Wang",
        "Jiwei Li",
        "Eduard Hovy",
        "Chen Guo"
      ],
      "abstract": "Packing, initially utilized in the pre-training phase, is an optimization\ntechnique designed to maximize hardware resource efficiency by combining\ndifferent training sequences to fit the model's maximum input length. Although\nit has demonstrated effectiveness during pre-training, there remains a lack of\ncomprehensive analysis for the supervised fine-tuning (SFT) stage on the\nfollowing points: (1) whether packing can effectively enhance training\nefficiency while maintaining performance, (2) the suitable size of the model\nand dataset for fine-tuning with the packing method, and (3) whether packing\nunrelated or related training samples might cause the model to either\nexcessively disregard or over-rely on the context.\n  In this paper, we perform extensive comparisons between SFT methods using\npadding and packing, covering SFT datasets ranging from 69K to 1.2M and models\nfrom 8B to 70B. This provides the first comprehensive analysis of the\nadvantages and limitations of packing versus padding, as well as practical\nconsiderations for implementing packing in various training scenarios. Our\nanalysis covers various benchmarks, including knowledge, reasoning, and coding,\nas well as GPT-based evaluations, time efficiency, and other fine-tuning\nparameters. We also open-source our code for fine-tuning and evaluation and\nprovide checkpoints fine-tuned on datasets of different sizes, aiming to\nadvance future research on packing methods. Code is available at:\nhttps://github.com/ShuheWang1998/Packing-Analysis?tab=readme-ov-file.",
      "tldr_zh": "本研究分析了Packing技术在监督微调（Supervised Fine-tuning, SFT）阶段的应用，旨在探讨其是否能提升训练效率同时保持性能，以及其适用于大型模型（如8B到70B规模）或数据集（如69K到1.2M规模）的适用性。研究通过广泛实验比较了Packing与Padding方法，评估了知识、推理、编码等基准，以及时间效率和模型上下文依赖问题，结果显示Packing更适合处理大规模场景，但需注意避免模型过度忽略或依赖上下文。论文提供了首个全面分析，包括开源代码和检查点，以指导Packing在实际训练中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08081v3",
      "published_date": "2024-10-10 16:25:34 UTC",
      "updated_date": "2024-11-06 07:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:40:27.941292"
    },
    {
      "arxiv_id": "2410.08255v1",
      "title": "Generalization from Starvation: Hints of Universality in LLM Knowledge Graph Learning",
      "title_zh": "翻译失败",
      "authors": [
        "David D. Baek",
        "Yuxiao Li",
        "Max Tegmark"
      ],
      "abstract": "Motivated by interpretability and reliability, we investigate how neural\nnetworks represent knowledge during graph learning, We find hints of\nuniversality, where equivalent representations are learned across a range of\nmodel sizes (from $10^2$ to $10^9$ parameters) and contexts (MLP toy models,\nLLM in-context learning and LLM training). We show that these attractor\nrepresentations optimize generalization to unseen examples by exploiting\nproperties of knowledge graph relations (e.g. symmetry and meta-transitivity).\nWe find experimental support for such universality by showing that LLMs and\nsimpler neural networks can be stitched, i.e., by stitching the first part of\none model to the last part of another, mediated only by an affine or almost\naffine transformation. We hypothesize that this dynamic toward simplicity and\ngeneralization is driven by \"intelligence from starvation\": where overfitting\nis minimized by pressure to minimize the use of resources that are either\nscarce or competed for against other tasks.",
      "tldr_zh": "本研究调查了神经网络在知识图学习中的知识表示，发现了普遍性(universality)，即不同模型规模（从10^2到10^9参数）和上下文（包括MLP玩具模型、LLM in-context learning和LLM训练）下学习了等价的表示，这些表示通过利用知识图关系的属性（如symmetry和meta-transitivity）优化了对未见示例的泛化。实验支持这一普遍性，通过展示LLM和更简单神经网络可以被缝合(stitching)，即一个模型的前半部分与另一个模型的后半部分结合，仅需一个仿射或近似仿射变换。作者假设，这种向简单性和泛化的动态是由“intelligence from starvation”驱动的，即通过最小化资源使用来减少过拟合，从而提升模型的可靠性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08255v1",
      "published_date": "2024-10-10 16:23:42 UTC",
      "updated_date": "2024-10-10 16:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:40:40.711854"
    },
    {
      "arxiv_id": "2410.08069v2",
      "title": "Unlearning-based Neural Interpretations",
      "title_zh": "基于反学习的神经解释",
      "authors": [
        "Ching Lam Choi",
        "Alexandre Duplessis",
        "Serge Belongie"
      ],
      "abstract": "Gradient-based interpretations often require an anchor point of comparison to\navoid saturation in computing feature importance. We show that current\nbaselines defined using static functions--constant mapping, averaging or\nblurring--inject harmful colour, texture or frequency assumptions that deviate\nfrom model behaviour. This leads to accumulation of irregular gradients,\nresulting in attribution maps that are biased, fragile and manipulable.\nDeparting from the static approach, we propose UNI to compute an (un)learnable,\ndebiased and adaptive baseline by perturbing the input towards an unlearning\ndirection of steepest ascent. Our method discovers reliable baselines and\nsucceeds in erasing salient features, which in turn locally smooths the\nhigh-curvature decision boundaries. Our analyses point to unlearning as a\npromising avenue for generating faithful, efficient and robust interpretations.",
      "tldr_zh": "这篇论文指出，传统的 gradient-based interpretations 在计算特征重要性时依赖静态基准（如常量映射、平均或模糊），这些基准引入了颜色、纹理或频率的有害假设，导致 attribution maps 出现偏差、脆弱和易操纵的问题。为了解决此问题，作者提出 UNI 方法，通过向 unlearning direction 的最陡上升方向扰动输入，计算一个可学习的、去偏的、自适应基准，从而消除显著特征并平滑高曲率决策边界。实验分析表明，unlearning 是一种生成忠实、高效和鲁棒的神经解释的有前景途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08069v2",
      "published_date": "2024-10-10 16:02:39 UTC",
      "updated_date": "2025-02-10 22:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:40:52.795792"
    },
    {
      "arxiv_id": "2410.08068v1",
      "title": "Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models",
      "title_zh": "教学启发式集成",
      "authors": [
        "Wenting Tan",
        "Dongxiao Chen",
        "Jieting Xue",
        "Zihao Wang",
        "Taijie Chen"
      ],
      "abstract": "Large Language Models (LLMs) exhibit impressive performance across various\ndomains but still struggle with arithmetic reasoning tasks. Recent work shows\nthe effectiveness of prompt design methods in enhancing reasoning capabilities.\nHowever, these approaches overlook crucial requirements for prior knowledge of\nspecific concepts, theorems, and tricks to tackle most arithmetic reasoning\nproblems successfully. To address this issue, we propose a novel and effective\nTeaching-Inspired Integrated Framework, which emulates the instructional\nprocess of a teacher guiding students. This method equips LLMs with essential\nconcepts, relevant theorems, and similar problems with analogous solution\napproaches, facilitating the enhancement of reasoning abilities. Additionally,\nwe introduce two new Chinese datasets, MathMC and MathToF, both with detailed\nexplanations and answers. Experiments are conducted on nine benchmarks which\ndemonstrates that our approach improves the reasoning accuracy of LLMs. With\nGPT-4 and our framework, we achieve new state-of-the-art performance on four\nmath benchmarks (AddSub, SVAMP, Math23K and AQuA) with accuracies of 98.2%\n(+3.3%), 93.9% (+0.2%), 94.3% (+7.2%) and 81.1% (+1.2%). Our data and code are\navailable at https://github.com/SallyTan13/Teaching-Inspired-Prompting.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 在算术推理任务上的表现不足，提出了一种新型 Teaching-Inspired Integrated Prompting Framework，该框架模仿教师指导过程，向 LLMs 提供必要概念、定理和类似问题，以增强其推理能力。研究同时引入了两个新的中文数据集 MathMC 和 MathToF，并附带详细解释和答案。在九个基准测试中，该方法显著提高了 LLMs 的准确率，使用 GPT-4 时在 AddSub、SVAMP、Math23K 和 AQuA 等基准上达到了新的最先进性能，准确率分别为 98.2% (+3.3%)、93.9% (+0.2%)、94.3% (+7.2%) 和 81.1% (+1.2%)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08068v1",
      "published_date": "2024-10-10 16:02:36 UTC",
      "updated_date": "2024-10-10 16:02:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:41:06.000102"
    },
    {
      "arxiv_id": "2410.08067v6",
      "title": "Reward-Augmented Data Enhances Direct Preference Alignment of LLMs",
      "title_zh": "奖励增强数据提升大型语言模型的直接偏好对齐",
      "authors": [
        "Shenao Zhang",
        "Zhihan Liu",
        "Boyi Liu",
        "Yufeng Zhang",
        "Yingxiang Yang",
        "Yongfei Liu",
        "Liyu Chen",
        "Tao Sun",
        "Zhaoran Wang"
      ],
      "abstract": "Preference alignment in Large Language Models (LLMs) has significantly\nimproved their ability to adhere to human instructions and intentions. However,\nexisting direct alignment algorithms primarily focus on relative preferences\nand often overlook the qualitative aspects of responses, despite having access\nto preference data that includes reward scores from judge models during AI\nfeedback. Striving to maximize the implicit reward gap between the chosen and\nthe slightly inferior rejected responses can cause overfitting and unnecessary\nunlearning of the high-quality rejected responses. The unawareness of the\nreward scores also drives the LLM to indiscriminately favor the low-quality\nchosen responses and fail to generalize to optimal responses that are sparse in\ndata. To overcome these shortcomings, our study introduces reward-conditioned\nLLM policies that discern and learn from the entire spectrum of response\nquality within the dataset, helping extrapolate to more optimal regions. We\npropose an effective yet simple data relabeling method that conditions the\npreference pairs on quality scores to construct a reward-augmented dataset. The\nexperiments across various benchmarks and diverse models demonstrate that our\napproach consistently boosts DPO by a considerable margin. Through\ncomprehensive ablation studies, we demonstrate that our method not only\nmaximizes the utility of preference data but also mitigates the issue of\nunlearning, demonstrating its broad effectiveness beyond mere data expansion.\nOur code is available at\nhttps://github.com/shenao-zhang/reward-augmented-preference.",
      "tldr_zh": "本研究指出，现有的直接偏好对齐算法（Direct Preference Alignment）主要关注相对偏好，而忽略了Large Language Models (LLMs)数据集中的奖励分数，这可能导致过拟合和不必要的高质量响应被遗忘。作者提出了一种奖励增强数据方法，通过简单的数据重标记（relabeling）将偏好对与质量分数相结合，构建奖励-conditioned LLM policies，以从响应质量的全谱学习并外推到更优区域。实验在多种基准和模型上显示，该方法显著提高了Direct Preference Optimization (DPO)的性能，并通过消融研究证明了其在最大化偏好数据效用和缓解不学习问题方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08067v6",
      "published_date": "2024-10-10 16:01:51 UTC",
      "updated_date": "2025-05-11 22:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:41:16.189850"
    },
    {
      "arxiv_id": "2410.08060v1",
      "title": "Optimal Transportation by Orthogonal Coupling Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Mohsen Sadr",
        "Peyman Mohajerin Esfehani",
        "Hossein Gorji"
      ],
      "abstract": "Many numerical algorithms and learning tasks rest on solution of the\nMonge-Kantorovich problem and corresponding Wasserstein distances. While the\nnatural approach is to treat the problem as an infinite-dimensional linear\nprogramming, such a methodology severely limits the computational performance\ndue to the polynomial scaling with respect to the sample size along with\nintensive memory requirements. We propose a novel alternative framework to\naddress the Monge-Kantorovich problem based on a projection type gradient\ndescent scheme. The micro-dynamics is built on the notion of the conditional\nexpectation, where the connection with the opinion dynamics is explored and\nleveraged to build compact numerical schemes. We demonstrate that the devised\ndynamics recovers random maps with favourable computational performance. Along\nwith the theoretical insight, the provided dynamics paves the way for\ninnovative approaches to construct numerical schemes for computing optimal\ntransport maps as well as Wasserstein distances.",
      "tldr_zh": "本文提出了一种基于投影型梯度下降的新框架，用于解决 Monge-Kantorovich 问题和对应的 Wasserstein 距离计算效率问题，以克服传统无限维线性规划方法的计算性能低下和内存需求高的问题。该框架通过条件期望的概念构建微观动态，并结合意见动态设计紧凑的数值方案，能够高效恢复随机映射。实验结果表明，该方法显著提升了计算性能，并为开发创新的数值方案以计算最优传输映射和 Wasserstein 距离提供了理论基础。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08060v1",
      "published_date": "2024-10-10 15:53:48 UTC",
      "updated_date": "2024-10-10 15:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:41:28.109751"
    },
    {
      "arxiv_id": "2410.08058v1",
      "title": "Closing the Loop: Learning to Generate Writing Feedback via Language Model Simulated Student Revisions",
      "title_zh": "翻译失败",
      "authors": [
        "Inderjeet Nair",
        "Jiaye Tan",
        "Xiaotian Su",
        "Anne Gere",
        "Xu Wang",
        "Lu Wang"
      ],
      "abstract": "Providing feedback is widely recognized as crucial for refining students'\nwriting skills. Recent advances in language models (LMs) have made it possible\nto automatically generate feedback that is actionable and well-aligned with\nhuman-specified attributes. However, it remains unclear whether the feedback\ngenerated by these models is truly effective in enhancing the quality of\nstudent revisions. Moreover, prompting LMs with a precise set of instructions\nto generate feedback is nontrivial due to the lack of consensus regarding the\nspecific attributes that can lead to improved revising performance. To address\nthese challenges, we propose PROF that PROduces Feedback via learning from LM\nsimulated student revisions. PROF aims to iteratively optimize the feedback\ngenerator by directly maximizing the effectiveness of students' overall\nrevising performance as simulated by LMs. Focusing on an economic essay\nassignment, we empirically test the efficacy of PROF and observe that our\napproach not only surpasses a variety of baseline methods in effectiveness of\nimproving students' writing but also demonstrates enhanced pedagogical values,\neven though it was not explicitly trained for this aspect.",
      "tldr_zh": "该研究针对语言模型（LMs）生成的写作反馈是否能有效提升学生修订质量的问题，提出了一种名为 PROF 的方法，通过模拟学生修订来优化反馈生成器。PROF 采用迭代优化策略，直接最大化 LMs 模拟的修订性能，从而避免了手动定义反馈属性的难题。在经济作文任务上实验表明，PROF 比多种基线方法更有效地改善了学生的写作质量，并意外提升了教学价值，尽管未针对此方面进行显式训练。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08058v1",
      "published_date": "2024-10-10 15:52:48 UTC",
      "updated_date": "2024-10-10 15:52:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:41:39.457011"
    },
    {
      "arxiv_id": "2410.19748v1",
      "title": "C^2DA: Contrastive and Context-aware Domain Adaptive Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Al-Masrur Khan",
        "Zheng Chen",
        "Lantao Liu"
      ],
      "abstract": "Unsupervised domain adaptive semantic segmentation (UDA-SS) aims to train a\nmodel on the source domain data (e.g., synthetic) and adapt the model to\npredict target domain data (e.g., real-world) without accessing target\nannotation data. Most existing UDA-SS methods only focus on inter-domain\nknowledge to mitigate the data-shift problem. However, learning the inherent\nstructure of the images and exploring the intrinsic pixel distribution of both\ndomains are ignored, which prevents the UDA-SS methods from producing\nsatisfactory performance like supervised learning. Moreover, incorporating\ncontextual knowledge is also often overlooked. Considering these issues, in\nthis work, we propose a UDA-SS framework that learns both intra-domain and\ncontext-aware knowledge. To learn the intra-domain knowledge, we incorporate\ncontrastive loss in both domains, which pulls pixels of similar classes\ntogether and pushes the rest away, facilitating intra-image-pixel-wise\ncorrelations. To learn context-aware knowledge, we modify the mixing technique\nby leveraging contextual dependency among the classes. Moreover, we adapt the\nMask Image Modeling (MIM) technique to properly use context clues for robust\nvisual recognition, using limited information about the masked images.\nComprehensive experiments validate that our proposed method improves the\nstate-of-the-art UDA-SS methods by a margin of 0.51% mIoU and 0.54% mIoU in the\nadaptation of GTA-V->Cityscapes and Synthia->Cityscapes, respectively. We\nopen-source our C2DA code. Code link: github.com/Masrur02/C-Squared-DA",
      "tldr_zh": "本研究提出了一种名为 C^2DA 的框架，用于无监督域适应语义分割 (UDA-SS)，旨在通过学习域内知识和上下文感知知识来解决现有方法忽略图像内在结构和像素分布的问题。框架中引入 contrastive loss 在源域和目标域中拉近相同类别的像素并推开不同类别，从而增强像素级相关性；同时，通过修改 mixing technique 和 Mask Image Modeling (MIM) 技术，利用类之间的上下文依赖来提升视觉识别的鲁棒性。实验结果显示，该方法在 GTA-V 到 Cityscapes 的适应中比最先进方法提高 0.51% mIoU，在 Synthia 到 Cityscapes 中提高 0.54% mIoU，并开源了代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has 16 pages, 6 figures, 5 tables. It has been accepted\n  for publication at the International Symposium of Robotics Research (ISRR),\n  Long Beach, California, USA, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19748v1",
      "published_date": "2024-10-10 15:51:35 UTC",
      "updated_date": "2024-10-10 15:51:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:41:52.769114"
    },
    {
      "arxiv_id": "2410.08049v1",
      "title": "Scaling Up Your Kernels: Large Kernel Design in ConvNets towards Universal Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyuan Zhang",
        "Xiaohan Ding",
        "Xiangyu Yue"
      ],
      "abstract": "This paper proposes the paradigm of large convolutional kernels in designing\nmodern Convolutional Neural Networks (ConvNets). We establish that employing a\nfew large kernels, instead of stacking multiple smaller ones, can be a superior\ndesign strategy. Our work introduces a set of architecture design guidelines\nfor large-kernel ConvNets that optimize their efficiency and performance. We\npropose the UniRepLKNet architecture, which offers systematical architecture\ndesign principles specifically crafted for large-kernel ConvNets, emphasizing\ntheir unique ability to capture extensive spatial information without deep\nlayer stacking. This results in a model that not only surpasses its\npredecessors with an ImageNet accuracy of 88.0%, an ADE20K mIoU of 55.6%, and a\nCOCO box AP of 56.4% but also demonstrates impressive scalability and\nperformance on various modalities such as time-series forecasting, audio, point\ncloud, and video recognition. These results indicate the universal modeling\nabilities of large-kernel ConvNets with faster inference speed compared with\nvision transformers. Our findings reveal that large-kernel ConvNets possess\nlarger effective receptive fields and a higher shape bias, moving away from the\ntexture bias typical of smaller-kernel CNNs. All codes and models are publicly\navailable at https://github.com/AILab-CVC/UniRepLKNet promoting further\nresearch and development in the community.",
      "tldr_zh": "本论文提出使用大卷积核（large convolutional kernels）设计现代 ConvNets 的新范式，主张采用几个大核代替堆叠多个小核，以提升效率和性能。作者引入 UniRepLKNet 架构，提供针对大核 ConvNets 的系统设计原则，强调其捕获广泛空间信息的能力，而无需深层堆叠。实验结果显示，UniRepLKNet 在 ImageNet 上达到 88.0% 准确率、ADE20K mIoU 55.6% 和 COCO box AP 56.4%，并在时间序列预测、音频、点云和视频识别等模态上表现出色，具有更大的有效感受野、更高的形状偏差以及比视觉变压器更快的推理速度。代码和模型已在 GitHub 上公开，促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This is the journal version of arXiv:2203.06717 and arXiv:2311.15599",
      "pdf_url": "http://arxiv.org/pdf/2410.08049v1",
      "published_date": "2024-10-10 15:43:55 UTC",
      "updated_date": "2024-10-10 15:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:42:05.361399"
    },
    {
      "arxiv_id": "2410.08041v1",
      "title": "On the Convergence of (Stochastic) Gradient Descent for Kolmogorov--Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Yihang Gao",
        "Vincent Y. F. Tan"
      ],
      "abstract": "Kolmogorov--Arnold Networks (KANs), a recently proposed neural network\narchitecture, have gained significant attention in the deep learning community,\ndue to their potential as a viable alternative to multi-layer perceptrons\n(MLPs) and their broad applicability to various scientific tasks. Empirical\ninvestigations demonstrate that KANs optimized via stochastic gradient descent\n(SGD) are capable of achieving near-zero training loss in various machine\nlearning (e.g., regression, classification, and time series forecasting, etc.)\nand scientific tasks (e.g., solving partial differential equations). In this\npaper, we provide a theoretical explanation for the empirical success by\nconducting a rigorous convergence analysis of gradient descent (GD) and SGD for\ntwo-layer KANs in solving both regression and physics-informed tasks. For\nregression problems, we establish using the neural tangent kernel perspective\nthat GD achieves global linear convergence of the objective function when the\nhidden dimension of KANs is sufficiently large. We further extend these results\nto SGD, demonstrating a similar global convergence in expectation.\nAdditionally, we analyze the global convergence of GD and SGD for\nphysics-informed KANs, which unveils additional challenges due to the more\ncomplex loss structure. This is the first work establishing the global\nconvergence guarantees for GD and SGD applied to optimize KANs and\nphysics-informed KANs.",
      "tldr_zh": "本文分析了Kolmogorov--Arnold Networks (KANs) 在使用梯度下降(GD)和随机梯度下降(SGD)优化时的收敛性，以解释其在回归、分类和科学任务中的经验成功。通过神经切线核(neural tangent kernel)视角，证明了当KANs的隐藏维度足够大时，GD能实现全局线性收敛，且SGD在期望上也具有类似全局收敛。对于physics-informed KANs，论文进一步探讨了GD和SGD的收敛，但强调了更复杂的损失结构带来的挑战，这是首次为优化KANs和physics-informed KANs建立全局收敛保证的工作。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08041v1",
      "published_date": "2024-10-10 15:34:10 UTC",
      "updated_date": "2024-10-10 15:34:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:42:15.648072"
    },
    {
      "arxiv_id": "2410.08032v2",
      "title": "Strategic Classification With Externalities",
      "title_zh": "具有外部性的战略分类",
      "authors": [
        "Safwan Hossain",
        "Evi Micha",
        "Yiling Chen",
        "Ariel Procaccia"
      ],
      "abstract": "We propose a new variant of the strategic classification problem: a principal\nreveals a classifier, and $n$ agents report their (possibly manipulated)\nfeatures to be classified. Motivated by real-world applications, our model\ncrucially allows the manipulation of one agent to affect another; that is, it\nexplicitly captures inter-agent externalities. The principal-agent interactions\nare formally modeled as a Stackelberg game, with the resulting agent\nmanipulation dynamics captured as a simultaneous game. We show that under\ncertain assumptions, the pure Nash Equilibrium of this agent manipulation game\nis unique and can be efficiently computed. Leveraging this result, PAC learning\nguarantees are established for the learner: informally, we show that it is\npossible to learn classifiers that minimize loss on the distribution, even when\na random number of agents are manipulating their way to a pure Nash\nEquilibrium. We also comment on the optimization of such classifiers through\ngradient-based approaches. This work sets the theoretical foundations for a\nmore realistic analysis of classifiers that are robust against multiple\nstrategic actors interacting in a common environment.",
      "tldr_zh": "本研究提出了一种新的战略分类（Strategic Classification）变体，考虑代理（agents）间的外部性（Externalities），即一个代理的特征操纵会影响其他代理。模型将主体（principal）发布分类器后的代理互动建模为Stackelberg游戏，并通过同时游戏捕获操纵动态；在特定假设下，代理操纵游戏的纯Nash Equilibrium唯一且可高效计算。研究建立了PAC learning guarantees，即使代理在纯Nash Equilibrium中操纵，也能学习出最小化损失的分类器；此外，讨论了通过梯度-based方法优化此类分类器。该工作为分析在共同环境中互动的多个战略代理的鲁棒分类器提供了更现实的理论基础。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08032v2",
      "published_date": "2024-10-10 15:28:04 UTC",
      "updated_date": "2025-02-26 19:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:42:27.599931"
    },
    {
      "arxiv_id": "2410.08027v1",
      "title": "Private Language Models via Truncated Laplacian Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Tianhao Huang",
        "Tao Yang",
        "Ivan Habernal",
        "Lijie Hu",
        "Di Wang"
      ],
      "abstract": "Deep learning models for NLP tasks are prone to variants of privacy attacks.\nTo prevent privacy leakage, researchers have investigated word-level\nperturbations, relying on the formal guarantees of differential privacy (DP) in\nthe embedding space. However, many existing approaches either achieve\nunsatisfactory performance in the high privacy regime when using the Laplacian\nor Gaussian mechanism, or resort to weaker relaxations of DP that are inferior\nto the canonical DP in terms of privacy strength. This raises the question of\nwhether a new method for private word embedding can be designed to overcome\nthese limitations. In this paper, we propose a novel private embedding method\ncalled the high dimensional truncated Laplacian mechanism. Specifically, we\nintroduce a non-trivial extension of the truncated Laplacian mechanism, which\nwas previously only investigated in one-dimensional space cases. Theoretically,\nwe show that our method has a lower variance compared to the previous private\nword embedding methods. To further validate its effectiveness, we conduct\ncomprehensive experiments on private embedding and downstream tasks using three\ndatasets. Remarkably, even in the high privacy regime, our approach only incurs\na slight decrease in utility compared to the non-private scenario.",
      "tldr_zh": "该论文针对NLP深度学习模型的隐私攻击问题，提出了一种新的私人嵌入方法，即高维Truncated Laplacian Mechanism，以克服现有基于Laplacian或Gaussian机制的差分隐私(DP)方法在高隐私环境下性能不佳的局限性。该方法扩展了原有的一维截断Laplacian机制到高维空间，并理论证明其方差比之前方法更低。通过在三个数据集上的实验验证，该方法在私人嵌入和下游任务中，即使在高隐私制度下，也仅导致微小实用性下降，为更强的隐私保护提供了有效方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024, Main Track",
      "pdf_url": "http://arxiv.org/pdf/2410.08027v1",
      "published_date": "2024-10-10 15:25:02 UTC",
      "updated_date": "2024-10-10 15:25:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:42:40.656573"
    },
    {
      "arxiv_id": "2410.12850v1",
      "title": "RecurFormer: Not All Transformer Heads Need Self-Attention",
      "title_zh": "RecurFormer：并非所有 Transformer Heads 都需要自注意力",
      "authors": [
        "Ruiqing Yan",
        "Linghan Zheng",
        "Xingbo Du",
        "Han Zou",
        "Yufeng Guo",
        "Jianfei Yang"
      ],
      "abstract": "Transformer-based large language models (LLMs) excel in modeling complex\nlanguage patterns but face significant computational costs during inference,\nespecially with long inputs due to the attention mechanism's memory overhead.\nWe observe that certain attention heads exhibit a distribution where the\nattention weights concentrate on tokens near the query token, termed as recency\naware, which focuses on local and short-range dependencies. Leveraging this\ninsight, we propose RecurFormer, a novel architecture that replaces these\nattention heads with linear recurrent neural networks (RNNs), specifically the\nMamba architecture. This replacement reduces the cache size without evicting\ntokens, thus maintaining generation quality. RecurFormer retains the ability to\nmodel long-range dependencies through the remaining attention heads and allows\nfor reusing pre-trained Transformer-based LLMs weights with continual training.\nExperiments demonstrate that RecurFormer matches the original model's\nperformance while significantly enhancing inference efficiency. Our approach\nprovides a practical solution to the computational challenges of\nTransformer-based LLMs inference, making it highly attractive for tasks\ninvolving long inputs.",
      "tldr_zh": "Transformer-based LLMs 在处理长输入时因注意力机制而面临高计算成本，本文观察到某些 attention heads 专注于局部短程依赖（recency aware）。为此，提出 RecurFormer 架构，将这些 attention heads 替换为线性 RNN（特别是 Mamba 架构），从而减少缓存大小并维持生成质量，同时保留其他 heads 以支持长程依赖建模。实验证明，RecurFormer 与原模型性能相当，但显著提升了推理效率，为 Transformer-based LLMs 在长输入任务中的计算挑战提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12850v1",
      "published_date": "2024-10-10 15:24:12 UTC",
      "updated_date": "2024-10-10 15:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:42:52.244270"
    },
    {
      "arxiv_id": "2410.08025v3",
      "title": "The Computational Complexity of Circuit Discovery for Inner Interpretability",
      "title_zh": "针对内部可解释性的电路发现计算复杂性",
      "authors": [
        "Federico Adolfi",
        "Martina G. Vilas",
        "Todd Wareham"
      ],
      "abstract": "Many proposed applications of neural networks in machine learning,\ncognitive/brain science, and society hinge on the feasibility of inner\ninterpretability via circuit discovery. This calls for empirical and\ntheoretical explorations of viable algorithmic options. Despite advances in the\ndesign and testing of heuristics, there are concerns about their scalability\nand faithfulness at a time when we lack understanding of the complexity\nproperties of the problems they are deployed to solve. To address this, we\nstudy circuit discovery with classical and parameterized computational\ncomplexity theory: (1) we describe a conceptual scaffolding to reason about\ncircuit finding queries in terms of affordances for description, explanation,\nprediction and control; (2) we formalize a comprehensive set of queries for\nmechanistic explanation, and propose a formal framework for their analysis; (3)\nwe use it to settle the complexity of many query variants and relaxations of\npractical interest on multi-layer perceptrons. Our findings reveal a\nchallenging complexity landscape. Many queries are intractable, remain\nfixed-parameter intractable relative to model/circuit features, and\ninapproximable under additive, multiplicative, and probabilistic approximation\nschemes. To navigate this landscape, we prove there exist transformations to\ntackle some of these hard problems with better-understood heuristics, and prove\nthe tractability or fixed-parameter tractability of more modest queries which\nretain useful affordances. This framework allows us to understand the scope and\nlimits of interpretability queries, explore viable options, and compare their\nresource demands on existing and future architectures.",
      "tldr_zh": "这篇论文探讨了用于内部可解释性（inner interpretability）的电路发现（circuit discovery）的计算复杂性，强调了其在机器学习和认知科学中的重要性。作者提出一个概念框架来分析电路发现查询的特性，包括描述、解释、预测和控制，并形式化了一套机制解释查询，使用经典和参数化计算复杂性理论（computational complexity theory）对其在多层感知器（multi-layer perceptrons）上的变体进行分析。结果显示，许多查询是 intractable 的，且在各种近似方案下不可近似，但作者证明了某些转换和更简单的查询是 fixed-parameter tractable 的，从而为设计可扩展的解释算法提供了可行路径。",
      "categories": [
        "cs.AI",
        "cs.CC",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.08025v3",
      "published_date": "2024-10-10 15:22:48 UTC",
      "updated_date": "2025-04-01 14:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:43:05.224910"
    },
    {
      "arxiv_id": "2410.08024v1",
      "title": "Pretraining Graph Transformers with Atom-in-a-Molecule Quantum Properties for Improved ADMET Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Alessio Fallani",
        "Ramil Nugmanov",
        "Jose Arjona-Medina",
        "Jörg Kurt Wegner",
        "Alexandre Tkatchenko",
        "Kostiantyn Chernichenko"
      ],
      "abstract": "We evaluate the impact of pretraining Graph Transformer architectures on\natom-level quantum-mechanical features for the modeling of absorption,\ndistribution, metabolism, excretion, and toxicity (ADMET) properties of\ndrug-like compounds. We compare this pretraining strategy with two others: one\nbased on molecular quantum properties (specifically the HOMO-LUMO gap) and one\nusing a self-supervised atom masking technique. After fine-tuning on\nTherapeutic Data Commons ADMET datasets, we evaluate the performance\nimprovement in the different models observing that models pretrained with\natomic quantum mechanical properties produce in general better results. We then\nanalyse the latent representations and observe that the supervised strategies\npreserve the pretraining information after finetuning and that different\npretrainings produce different trends in latent expressivity across layers.\nFurthermore, we find that models pretrained on atomic quantum mechanical\nproperties capture more low-frequency laplacian eigenmodes of the input graph\nvia the attention weights and produce better representations of atomic\nenvironments within the molecule. Application of the analysis to a much larger\nnon-public dataset for microsomal clearance illustrates generalizability of the\nstudied indicators. In this case the performances of the models are in\naccordance with the representation analysis and highlight, especially for the\ncase of masking pretraining and atom-level quantum property pretraining, how\nmodel types with similar performance on public benchmarks can have different\nperformances on large scale pharmaceutical data.",
      "tldr_zh": "本研究评估了使用原子级量子机械特性预训练 Graph Transformer 以改善药物化合物的 ADMET 属性建模的效果，并与其他策略（如基于分子量子特性 HOMO-LUMO 间隙的预训练和自监督原子掩码技术）进行比较。结果显示，原子量子特性预训练模型在 Therapeutic Data Commons ADMET 数据集上表现最佳，能够更好地保留预训练信息并通过注意力权重捕获更多低频拉普拉斯特征，从而提升原子环境的表示。进一步分析表明，这种方法在大型非公开制药数据集上显示出更强的泛化性，突显了不同预训练策略在实际应用中的差异。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08024v1",
      "published_date": "2024-10-10 15:20:30 UTC",
      "updated_date": "2024-10-10 15:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:43:17.052075"
    },
    {
      "arxiv_id": "2410.08023v1",
      "title": "GrabDAE: An Innovative Framework for Unsupervised Domain Adaptation Utilizing Grab-Mask and Denoise Auto-Encoder",
      "title_zh": "翻译失败",
      "authors": [
        "Junzhou Chen",
        "Xuan Wen",
        "Ronghui Zhang",
        "Bingtao Ren",
        "Di Wu",
        "Zhigang Xu",
        "Danwei Wang"
      ],
      "abstract": "Unsupervised Domain Adaptation (UDA) aims to adapt a model trained on a\nlabeled source domain to an unlabeled target domain by addressing the domain\nshift. Existing Unsupervised Domain Adaptation (UDA) methods often fall short\nin fully leveraging contextual information from the target domain, leading to\nsuboptimal decision boundary separation during source and target domain\nalignment. To address this, we introduce GrabDAE, an innovative UDA framework\ndesigned to tackle domain shift in visual classification tasks. GrabDAE\nincorporates two key innovations: the Grab-Mask module, which blurs background\ninformation in target domain images, enabling the model to focus on essential,\ndomain-relevant features through contrastive learning; and the Denoising\nAuto-Encoder (DAE), which enhances feature alignment by reconstructing features\nand filtering noise, ensuring a more robust adaptation to the target domain.\nThese components empower GrabDAE to effectively handle unlabeled target domain\ndata, significantly improving both classification accuracy and robustness.\nExtensive experiments on benchmark datasets, including VisDA-2017, Office-Home,\nand Office31, demonstrate that GrabDAE consistently surpasses state-of-the-art\nUDA methods, setting new performance benchmarks. By tackling UDA's critical\nchallenges with its novel feature masking and denoising approach, GrabDAE\noffers both significant theoretical and practical advancements in domain\nadaptation.",
      "tldr_zh": "本研究提出了一种创新框架GrabDAE，用于Unsupervised Domain Adaptation (UDA)，旨在通过处理域移位问题，将模型从有标签源域适应到无标签目标域。GrabDAE的核心创新包括Grab-Mask模块，该模块通过模糊目标域图像的背景信息并利用对比学习，聚焦于关键的域相关特征；以及Denoising Auto-Encoder (DAE)，它通过重建特征并过滤噪声，提升特征对齐和模型鲁棒性。在VisDA-2017、Office-Home和Office31等基准数据集上的实验表明，GrabDAE超越了现有最先进方法，显著提高了分类准确性和整体性能，为UDA领域提供了重要的理论和实践进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08023v1",
      "published_date": "2024-10-10 15:19:57 UTC",
      "updated_date": "2024-10-10 15:19:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:43:28.354764"
    },
    {
      "arxiv_id": "2410.08022v2",
      "title": "Probabilistic Satisfaction of Temporal Logic Constraints in Reinforcement Learning via Adaptive Policy-Switching",
      "title_zh": "通过自适应策略切换实现强化学习中时序逻辑约束的概率满足",
      "authors": [
        "Xiaoshan Lin",
        "Sadık Bera Yüksel",
        "Yasin Yazıcıoğlu",
        "Derya Aksaray"
      ],
      "abstract": "Constrained Reinforcement Learning (CRL) is a subset of machine learning that\nintroduces constraints into the traditional reinforcement learning (RL)\nframework. Unlike conventional RL which aims solely to maximize cumulative\nrewards, CRL incorporates additional constraints that represent specific\nmission requirements or limitations that the agent must comply with during the\nlearning process. In this paper, we address a type of CRL problem where an\nagent aims to learn the optimal policy to maximize reward while ensuring a\ndesired level of temporal logic constraint satisfaction throughout the learning\nprocess. We propose a novel framework that relies on switching between pure\nlearning (reward maximization) and constraint satisfaction. This framework\nestimates the probability of constraint satisfaction based on earlier trials\nand properly adjusts the probability of switching between learning and\nconstraint satisfaction policies. We theoretically validate the correctness of\nthe proposed algorithm and demonstrate its performance through comprehensive\nsimulations.",
      "tldr_zh": "该论文探讨了Constrained Reinforcement Learning (CRL)，一种在传统Reinforcement Learning (RL)基础上加入约束的机器学习方法，以确保代理在最大化累积奖励的同时满足temporal logic约束。研究提出一个创新框架，通过adaptive policy-switching在纯学习（奖励最大化）和约束满足模式之间动态切换，并基于早期试验估算约束满足概率来调整切换策略。该框架的正确性得到了理论验证，并在全面模拟实验中证明了其有效性能，展示了在CRL任务中的优越性。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08022v2",
      "published_date": "2024-10-10 15:19:45 UTC",
      "updated_date": "2024-11-27 22:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:43:39.719930"
    },
    {
      "arxiv_id": "2410.08020v3",
      "title": "Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Hübotter",
        "Sascha Bongni",
        "Ido Hakimi",
        "Andreas Krause"
      ],
      "abstract": "Recent efforts in fine-tuning language models often rely on automatic data\nselection, commonly using Nearest Neighbors retrieval from large datasets.\nHowever, we theoretically show that this approach tends to select redundant\ndata, limiting its effectiveness or even hurting performance. To address this,\nwe introduce SIFT, a data selection algorithm designed to reduce uncertainty\nabout the model's response given a prompt, which unifies ideas from retrieval\nand active learning. Whereas Nearest Neighbor retrieval typically fails in the\npresence of information duplication, SIFT accounts for information duplication\nand optimizes the overall information gain of the selected examples. We focus\nour evaluations on fine-tuning at test-time for prompt-specific language\nmodeling on the Pile dataset, and show that SIFT consistently outperforms\nNearest Neighbor retrieval, with minimal computational overhead. Moreover, we\nshow that our uncertainty estimates can predict the performance gain of\ntest-time fine-tuning, and use this to develop an adaptive algorithm that\ninvests test-time compute proportional to realized performance gains. We\nprovide the $\\texttt{activeft}$ (Active Fine-Tuning) library which can be used\nas a drop-in replacement for Nearest Neighbor retrieval.",
      "tldr_zh": "该论文揭示了现有语言模型(LLMs) fine-tuning 方法，如 Nearest Neighbors retrieval，在数据选择时易选到冗余数据，从而影响性能。作者提出 SIFT 算法，通过整合检索和 active learning 的理念，减少模型对提示响应的不确定性，并优化信息增益以处理信息重复问题。在 Pile 数据集上的测试时间 fine-tuning 实验中，SIFT 比 Nearest Neighbors retrieval 表现出色，同时计算开销最小；此外，该方法还能预测性能提升，并开发自适应算法来按比例分配计算资源，最终提供 activeft 库作为易用替换。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08020v3",
      "published_date": "2024-10-10 15:17:49 UTC",
      "updated_date": "2025-02-08 19:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:43:52.179967"
    },
    {
      "arxiv_id": "2410.18991v2",
      "title": "TRIAGE: Ethical Benchmarking of AI Models Through Mass Casualty Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Nathalie Maria Kirch",
        "Konstantin Hebenstreit",
        "Matthias Samwald"
      ],
      "abstract": "We present the TRIAGE Benchmark, a novel machine ethics (ME) benchmark that\ntests LLMs' ability to make ethical decisions during mass casualty incidents.\nIt uses real-world ethical dilemmas with clear solutions designed by medical\nprofessionals, offering a more realistic alternative to annotation-based\nbenchmarks. TRIAGE incorporates various prompting styles to evaluate model\nperformance across different contexts. Most models consistently outperformed\nrandom guessing, suggesting LLMs may support decision-making in triage\nscenarios. Neutral or factual scenario formulations led to the best\nperformance, unlike other ME benchmarks where ethical reminders improved\noutcomes. Adversarial prompts reduced performance but not to random guessing\nlevels. Open-source models made more morally serious errors, and general\ncapability overall predicted better performance.",
      "tldr_zh": "本研究引入了 TRIAGE Benchmark，这是一个新型的机器伦理 (ME) 基准，用于评估大型语言模型 (LLMs) 在大规模伤亡事件中做出伦理决策的能力。TRIAGE 采用由医疗专业人士设计的真实世界伦理困境作为测试场景，提供明确的解决方案，并通过各种提示风格（如中性表述或对抗性提示）来考察模型在不同上下文下的表现。与传统基准不同，该基准发现中性或事实性的场景表述能带来最佳性能，而伦理提醒并不总是有效。大多数模型的表现超过了随机猜测水平，开源模型更易犯道德上严重的错误，且模型的总体能力与性能正相关。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.18991v2",
      "published_date": "2024-10-10 15:06:12 UTC",
      "updated_date": "2024-11-04 12:38:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:44:04.036052"
    },
    {
      "arxiv_id": "2410.08001v3",
      "title": "Towards Synergistic, Generalized, and Efficient Dual-System for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Qingwen Bu",
        "Hongyang Li",
        "Li Chen",
        "Jisong Cai",
        "Jia Zeng",
        "Heming Cui",
        "Maoqing Yao",
        "Yu Qiao"
      ],
      "abstract": "The increasing demand for versatile robotic systems to operate in diverse and\ndynamic environments has emphasized the importance of a generalist policy,\nwhich leverages a large cross-embodiment data corpus to facilitate broad\nadaptability and high-level reasoning. However, the generalist would struggle\nwith inefficient inference and cost-expensive training. The specialist policy,\ninstead, is curated for specific domain data and excels at task-level precision\nwith efficiency. Yet, it lacks the generalization capacity for a wide range of\napplications. Inspired by these observations, we introduce RoboDual, a\nsynergistic dual-system that supplements the merits of both generalist and\nspecialist policy. A diffusion transformer-based specialist is devised for\nmulti-step action rollouts, exquisitely conditioned on the high-level task\nunderstanding and discretized action output of a vision-language-action (VLA)\nbased generalist. Compared to OpenVLA, RoboDual achieves 26.7% improvement in\nreal-world setting and 12% gain on CALVIN by introducing a specialist policy\nwith merely 20M trainable parameters. It maintains strong performance with 5%\nof demonstration data only, and enables a 3.8 times higher control frequency in\nreal-world deployment. Code would be made publicly available. Our project page\nis hosted at: https://opendrivelab.com/RoboDual/",
      "tldr_zh": "该研究针对机器人操作的需求，提出RoboDual协同双系统，结合generalist政策的高级推理能力和specialist政策的任务精确性，以实现泛化、效率和协同优化。方法包括使用基于vision-language-action (VLA)的generalist提供高水平任务理解和离散化动作输出，再由diffusion transformer-based specialist进行多步动作rollout。实验结果显示，RoboDual相较OpenVLA在真实世界场景提升26.7%、在CALVIN基准上提升12%，仅需20M可训练参数和5%的演示数据，即可实现3.8倍的控制频率提高。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project page: https://opendrivelab.com/RoboDual/",
      "pdf_url": "http://arxiv.org/pdf/2410.08001v3",
      "published_date": "2024-10-10 14:57:51 UTC",
      "updated_date": "2025-02-06 12:37:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:44:17.500406"
    },
    {
      "arxiv_id": "2410.11878v1",
      "title": "Neural Metamorphosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyi Yang",
        "Xinchao Wang"
      ],
      "abstract": "This paper introduces a new learning paradigm termed Neural Metamorphosis\n(NeuMeta), which aims to build self-morphable neural networks. Contrary to\ncrafting separate models for different architectures or sizes, NeuMeta directly\nlearns the continuous weight manifold of neural networks. Once trained, we can\nsample weights for any-sized network directly from the manifold, even for\npreviously unseen configurations, without retraining. To achieve this ambitious\ngoal, NeuMeta trains neural implicit functions as hypernetworks. They accept\ncoordinates within the model space as input, and generate corresponding weight\nvalues on the manifold. In other words, the implicit function is learned in a\nway, that the predicted weights is well-performed across various models sizes.\nIn training those models, we notice that, the final performance closely relates\non smoothness of the learned manifold. In pursuit of enhancing this smoothness,\nwe employ two strategies. First, we permute weight matrices to achieve\nintra-model smoothness, by solving the Shortest Hamiltonian Path problem.\nBesides, we add a noise on the input coordinates when training the implicit\nfunction, ensuring models with various sizes shows consistent outputs. As such,\nNeuMeta shows promising results in synthesizing parameters for various network\nconfigurations. Our extensive tests in image classification, semantic\nsegmentation, and image generation reveal that NeuMeta sustains full-size\nperformance even at a 75% compression rate.",
      "tldr_zh": "这篇论文介绍了 Neural Metamorphosis (NeuMeta)，一种新学习范式，旨在构建自变形的神经网络，通过直接学习神经网络的 continuous weight manifold，实现从单一模型中采样权重以适应任意大小的网络，而无需重新训练。NeuMeta 使用神经隐式函数作为 hypernetworks，接受模型空间坐标作为输入生成权重，并通过两个策略提升流形平滑性：排列权重矩阵解决 Shortest Hamiltonian Path 问题，以及在训练时向输入坐标添加噪声以确保输出一致。实验结果显示，在图像分类、语义分割和图像生成任务中，NeuMeta 即使在75%压缩率下，仍能维持全尺寸性能，为高效的模型适应性提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "in ECCV2024, https://adamdad.github.io/neumeta/",
      "pdf_url": "http://arxiv.org/pdf/2410.11878v1",
      "published_date": "2024-10-10 14:49:58 UTC",
      "updated_date": "2024-10-10 14:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:44:29.342740"
    },
    {
      "arxiv_id": "2410.07991v5",
      "title": "Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets",
      "title_zh": "翻译失败",
      "authors": [
        "Tommaso Giorgi",
        "Lorenzo Cima",
        "Tiziano Fagni",
        "Marco Avvenuti",
        "Stefano Cresci"
      ],
      "abstract": "The rise of online platforms exacerbated the spread of hate speech, demanding\nscalable and effective detection. However, the accuracy of hate speech\ndetection systems heavily relies on human-labeled data, which is inherently\nsusceptible to biases. While previous work has examined the issue, the\ninterplay between the characteristics of the annotator and those of the target\nof the hate are still unexplored. We fill this gap by leveraging an extensive\ndataset with rich socio-demographic information of both annotators and targets,\nuncovering how human biases manifest in relation to the target's attributes.\nOur analysis surfaces the presence of widespread biases, which we\nquantitatively describe and characterize based on their intensity and\nprevalence, revealing marked differences. Furthermore, we compare human biases\nwith those exhibited by persona-based LLMs. Our findings indicate that while\npersona-based LLMs do exhibit biases, these differ significantly from those of\nhuman annotators. Overall, our work offers new and nuanced results on human\nbiases in hate speech annotations, as well as fresh insights into the design of\nAI-driven hate speech detection systems.",
      "tldr_zh": "本文研究了人类和LLMs在仇恨言论(hate speech)标注中的偏见，通过社会人口统计(socio-demographic)分析探讨了标注者和目标特征之间的互动。利用一个包含丰富社会人口统计信息的数据集，作者量化并描述了偏见的强度和普遍性，发现人类标注中存在显著差异。相比之下，persona-based LLMs也表现出偏见，但其类型与人类有明显不同，为设计更可靠的AI驱动仇恨言论检测系统提供了新颖见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07991v5",
      "published_date": "2024-10-10 14:48:57 UTC",
      "updated_date": "2025-04-09 15:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:44:40.439565"
    },
    {
      "arxiv_id": "2410.07981v2",
      "title": "MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning",
      "title_zh": "MolMix：一个简单却有效的多模态分子表示学习基准",
      "authors": [
        "Andrei Manolache",
        "Dragos Tantaru",
        "Mathias Niepert"
      ],
      "abstract": "In this work, we propose a simple transformer-based baseline for multimodal\nmolecular representation learning, integrating three distinct modalities:\nSMILES strings, 2D graph representations, and 3D conformers of molecules. A key\naspect of our approach is the aggregation of 3D conformers, allowing the model\nto account for the fact that molecules can adopt multiple conformations-an\nimportant factor for accurate molecular representation. The tokens for each\nmodality are extracted using modality-specific encoders: a transformer for\nSMILES strings, a message-passing neural network for 2D graphs, and an\nequivariant neural network for 3D conformers. The flexibility and modularity of\nthis framework enable easy adaptation and replacement of these encoders, making\nthe model highly versatile for different molecular tasks. The extracted tokens\nare then combined into a unified multimodal sequence, which is processed by a\ndownstream transformer for prediction tasks. To efficiently scale our model for\nlarge multimodal datasets, we utilize Flash Attention 2 and bfloat16 precision.\nDespite its simplicity, our approach achieves state-of-the-art results across\nmultiple datasets, demonstrating its effectiveness as a strong baseline for\nmultimodal molecular representation learning.",
      "tldr_zh": "本文提出 MolMix，一种简单有效的 Transformer 基于基线，用于多模态分子表示学习，通过整合 SMILES 字符串、2D 图表示和 3D 构象来处理分子多构象问题。方法使用特定编码器提取模态标记（Transformer 用于 SMILES、message-passing neural network 用于 2D 图、equivariant neural network 用于 3D 构象），然后将这些标记组合成统一序列，由下游 Transformer 进行预测，并通过 Flash Attention 2 和 bfloat16 精度实现高效扩展。尽管框架简洁，MolMix 在多个数据集上达到了 state-of-the-art 结果，为多模态分子表示学习提供了强有力的基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Machine Learning for Structural Biology Workshop, NeurIPS 2024 v2:\n  Added optimizer references",
      "pdf_url": "http://arxiv.org/pdf/2410.07981v2",
      "published_date": "2024-10-10 14:36:58 UTC",
      "updated_date": "2024-10-24 08:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:46.715463"
    },
    {
      "arxiv_id": "2410.07980v3",
      "title": "D-Wave's Nonlinear-Program Hybrid Solver: Description and Performance Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Eneko Osaba",
        "Pablo Miranda-Rodriguez"
      ],
      "abstract": "The development of advanced quantum-classical algorithms is among the most\nprominent strategies in quantum computing. Numerous hybrid solvers have been\nintroduced recently. Many of these methods are created ad hoc to address\nspecific use cases. However, several well-established schemes are frequently\nutilized to address optimization problems. In this context, D-Wave launched the\nHybrid Solver Service in 2020, offering a portfolio of methods designed to\naccelerate time-to-solution for users aiming to optimize performance and\noperational processes. Recently, a new technique has been added to this\nportfolio: the Nonlinear-Program Hybrid Solver. This paper describes this\nsolver and evaluates its performance through a benchmark of 45 instances across\nthree combinatorial optimization problems: the Traveling Salesman Problem, the\nKnapsack Problem, and the Maximum Cut Problem. To facilitate the use of this\nrelatively unexplored solver, we provide details of the implementation used to\nsolve these three optimization problems.",
      "tldr_zh": "该论文介绍了D-Wave的Nonlinear-Program Hybrid Solver，这是一种新的量子-经典混合求解器，旨在加速优化问题的求解过程。该求解器作为D-Wave Hybrid Solver Service的一部分，针对组合优化问题进行了描述和性能评估，通过基准测试了45个实例，包括Traveling Salesman Problem、Knapsack Problem和Maximum Cut Problem。实验结果展示了该求解器的有效性，并提供了这些问题的实施细节，以便用户更好地应用。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "13 pages, 9 figures and 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.07980v3",
      "published_date": "2024-10-10 14:36:24 UTC",
      "updated_date": "2024-12-04 12:14:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:03.749881"
    },
    {
      "arxiv_id": "2410.07974v4",
      "title": "Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanqi Du",
        "Michael Plainer",
        "Rob Brekelmans",
        "Chenru Duan",
        "Frank Noé",
        "Carla P. Gomes",
        "Alán Aspuru-Guzik",
        "Kirill Neklyudov"
      ],
      "abstract": "Rare event sampling in dynamical systems is a fundamental problem arising in\nthe natural sciences, which poses significant computational challenges due to\nan exponentially large space of trajectories. For settings where the dynamical\nsystem of interest follows a Brownian motion with known drift, the question of\nconditioning the process to reach a given endpoint or desired rare event is\ndefinitively answered by Doob's h-transform. However, the naive estimation of\nthis transform is infeasible, as it requires simulating sufficiently many\nforward trajectories to estimate rare event probabilities. In this work, we\npropose a variational formulation of Doob's h-transform as an optimization\nproblem over trajectories between a given initial point and the desired ending\npoint. To solve this optimization, we propose a simulation-free training\nobjective with a model parameterization that imposes the desired boundary\nconditions by design. Our approach significantly reduces the search space over\ntrajectories and avoids expensive trajectory simulation and inefficient\nimportance sampling estimators which are required in existing methods. We\ndemonstrate the ability of our method to find feasible transition paths on\nreal-world molecular simulation and protein folding tasks.",
      "tldr_zh": "这篇论文提出了一种样本高效的变分方法，名为 Doob's Lagrangian，用于解决动态系统中稀有事件采样的计算挑战，特别是针对布朗运动系统的过渡路径采样问题。该方法将 Doob's h-transform 转化为轨迹优化问题，并采用无模拟训练目标和设计好的模型参数来满足边界条件，从而减少轨迹搜索空间并避免昂贵的模拟和重要性采样。实验结果表明，该方法在真实分子模拟和蛋白质折叠任务中成功找到了可行过渡路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as Spotlight at Conference on Neural Information Processing\n  Systems (NeurIPS 2024); Alanine dipeptide results updated after fixing\n  unphysical parameterization and energy computation",
      "pdf_url": "http://arxiv.org/pdf/2410.07974v4",
      "published_date": "2024-10-10 14:32:16 UTC",
      "updated_date": "2024-12-10 01:57:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:16.562218"
    },
    {
      "arxiv_id": "2410.07966v1",
      "title": "Neural Reasoning Networks: Efficient Interpretable Neural Networks With Automatic Textual Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Carrow",
        "Kyle Harper Erwin",
        "Olga Vilenskaia",
        "Parikshit Ram",
        "Tim Klinger",
        "Naweed Aghmad Khan",
        "Ndivhuwo Makondo",
        "Alexander Gray"
      ],
      "abstract": "Recent advances in machine learning have led to a surge in adoption of neural\nnetworks for various tasks, but lack of interpretability remains an issue for\nmany others in which an understanding of the features influencing the\nprediction is necessary to ensure fairness, safety, and legal compliance. In\nthis paper we consider one class of such tasks, tabular dataset classification,\nand propose a novel neuro-symbolic architecture, Neural Reasoning Networks\n(NRN), that is scalable and generates logically sound textual explanations for\nits predictions. NRNs are connected layers of logical neurons which implement a\nform of real valued logic. A training algorithm (R-NRN) learns the weights of\nthe network as usual using gradient descent optimization with backprop, but\nalso learns the network structure itself using a bandit-based optimization.\nBoth are implemented in an extension to PyTorch\n(https://github.com/IBM/torchlogic) that takes full advantage of GPU scaling\nand batched training. Evaluation on a diverse set of 22 open-source datasets\nfor tabular classification demonstrates performance (measured by ROC AUC) which\nimproves over multi-layer perceptron (MLP) and is statistically similar to\nother state-of-the-art approaches such as Random Forest, XGBoost and Gradient\nBoosted Trees, while offering 43% faster training and a more than 2 orders of\nmagnitude reduction in the number of parameters required, on average.\nFurthermore, R-NRN explanations are shorter than the compared approaches while\nproducing more accurate feature importance scores.",
      "tldr_zh": "该论文提出了 Neural Reasoning Networks (NRN)，一种新型神经符号架构，用于表格数据集分类任务，能够生成高效的、可解释的模型并自动提供逻辑上合理的文本解释。NRN 通过连接的逻辑神经元实现 real valued logic，其训练算法 R-NRN 结合梯度下降优化权重和 Bandit-based 优化学习网络结构，并在 PyTorch 的扩展中支持 GPU 加速。实验结果显示，在 22 个开源数据集上，NRN 的 ROC AUC 性能优于 MLP，并与 Random Forest、XGBoost 等方法相当，同时训练速度提高 43%，参数减少两个数量级以上，且其解释更简短且特征重要性得分更准确。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07966v1",
      "published_date": "2024-10-10 14:27:12 UTC",
      "updated_date": "2024-10-10 14:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:28.681666"
    },
    {
      "arxiv_id": "2410.07962v1",
      "title": "Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation",
      "title_zh": "翻译失败",
      "authors": [
        "Tomas Bueno Momcilovic",
        "Beat Buesser",
        "Giulio Zizzo",
        "Mark Purcell",
        "Dian Balta"
      ],
      "abstract": "Despite the impressive adaptability of large language models (LLMs),\nchallenges remain in ensuring their security, transparency, and\ninterpretability. Given their susceptibility to adversarial attacks, LLMs need\nto be defended with an evolving combination of adversarial training and\nguardrails. However, managing the implicit and heterogeneous knowledge for\ncontinuously assuring robustness is difficult. We introduce a novel approach\nfor assurance of the adversarial robustness of LLMs based on formal\nargumentation. Using ontologies for formalization, we structure\nstate-of-the-art attacks and defenses, facilitating the creation of a\nhuman-readable assurance case, and a machine-readable representation. We\ndemonstrate its application with examples in English language and code\ntranslation tasks, and provide implications for theory and practice, by\ntargeting engineers, data scientists, users, and auditors.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的对抗攻击问题，提出了一种基于本体(ontologies)驱动的正式论证(formal argumentation)方法，以确保LLMs的安全性、透明性和可解释性。该方法通过形式化结构化state-of-the-art攻击和防御，生成人类可读和机器可读的保证案例，从而简化鲁棒性管理。在英语语言和代码翻译任务中进行了实际演示，并为工程师、数据科学家、用户和审计员提供了理论和实践启示。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in xAI 2024, late-breaking track",
      "pdf_url": "http://arxiv.org/pdf/2410.07962v1",
      "published_date": "2024-10-10 14:24:43 UTC",
      "updated_date": "2024-10-10 14:24:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:41.273532"
    },
    {
      "arxiv_id": "2410.07959v2",
      "title": "COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act",
      "title_zh": "COMPL-AI Framework：欧盟人工智能法案的技术解释和LLM基准测试套件",
      "authors": [
        "Philipp Guldimann",
        "Alexander Spiridonov",
        "Robin Staab",
        "Nikola Jovanović",
        "Mark Vero",
        "Velko Vechev",
        "Anna-Maria Gueorguieva",
        "Mislav Balunović",
        "Nikola Konstantinov",
        "Pavol Bielik",
        "Petar Tsankov",
        "Martin Vechev"
      ],
      "abstract": "The EU's Artificial Intelligence Act (AI Act) is a significant step towards\nresponsible AI development, but lacks clear technical interpretation, making it\ndifficult to assess models' compliance. This work presents COMPL-AI, a\ncomprehensive framework consisting of (i) the first technical interpretation of\nthe EU AI Act, translating its broad regulatory requirements into measurable\ntechnical requirements, with the focus on large language models (LLMs), and\n(ii) an open-source Act-centered benchmarking suite, based on thorough\nsurveying and implementation of state-of-the-art LLM benchmarks. By evaluating\n12 prominent LLMs in the context of COMPL-AI, we reveal shortcomings in\nexisting models and benchmarks, particularly in areas like robustness, safety,\ndiversity, and fairness. This work highlights the need for a shift in focus\ntowards these aspects, encouraging balanced development of LLMs and more\ncomprehensive regulation-aligned benchmarks. Simultaneously, COMPL-AI for the\nfirst time demonstrates the possibilities and difficulties of bringing the\nAct's obligations to a more concrete, technical level. As such, our work can\nserve as a useful first step towards having actionable recommendations for\nmodel providers, and contributes to ongoing efforts of the EU to enable\napplication of the Act, such as the drafting of the GPAI Code of Practice.",
      "tldr_zh": "本研究提出了 COMPL-AI 框架，这是首个针对 EU Artificial Intelligence Act 的技术解释工具，专注于将该法规的广泛要求转化为可测量的技术标准，特别是针对 large language models (LLMs)。框架包括一个开源的基准测试套件，通过调查和实施 state-of-the-art LLM 基准，对 12 个主要 LLMs 进行了评估，揭示了这些模型在 robustness、safety、diversity 和 fairness 方面的显著不足。最终，COMPL-AI 强调了推动 LLM 平衡发展与法规符合基准的必要性，并为模型提供者提供可操作的推荐，支持 EU 的努力，如 GPAI Code of Practice 的起草。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07959v2",
      "published_date": "2024-10-10 14:23:51 UTC",
      "updated_date": "2025-02-03 14:51:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:45:59.474815"
    },
    {
      "arxiv_id": "2410.07928v3",
      "title": "The Function-Representation Model of Computation",
      "title_zh": "函数表示计算模型",
      "authors": [
        "Alfredo Ibias",
        "Hector Antona",
        "Guillem Ramirez-Miranda",
        "Enric Guinovart",
        "Eduard Alarcon"
      ],
      "abstract": "Cognitive Architectures are the forefront of the research into developing an\nartificial cognition. However, they approach the problem from a separated\nmemory and program model of computation. This model of computation poses a\nfundamental problem: the knowledge retrieval heuristic. In this paper we\npropose to solve this problem by using a novel model of computation, one where\nmemory and program are merged: the Function-Representation. This model of\ncomputation involves defining a generic Function-Representation and\ninstantiating multiple instances of it. In this paper we explore the potential\nof this novel model of computation through mathematical definitions and proofs.\nWe also explore the kind of functions a Function-Representation can implement,\nand present different ways to organise multiple instances of a\nFunction-Representation.",
      "tldr_zh": "本文针对认知架构（Cognitive Architectures）的传统模型——分离的内存和程序计算方式——所带来的知识检索难题，提出了一种新型计算模型：Function-Representation，将内存和程序合并为一体。该模型通过定义一个通用的Function-Representation并实例化多个版本，利用数学定义和证明来探索其潜力。研究讨论了这种模型能实现的功能类型，以及组织多个实例的多种策略，为提升人工认知系统的效率提供了新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07928v3",
      "published_date": "2024-10-10 13:54:35 UTC",
      "updated_date": "2024-11-06 17:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:46:09.408724"
    },
    {
      "arxiv_id": "2410.07923v1",
      "title": "Deep Learning for Generalised Planning with Background Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Z. Chen",
        "Rostislav Horčík",
        "Gustav Šír"
      ],
      "abstract": "Automated planning is a form of declarative problem solving which has\nrecently drawn attention from the machine learning (ML) community. ML has been\napplied to planning either as a way to test `reasoning capabilities' of\narchitectures, or more pragmatically in an attempt to scale up solvers with\nlearned domain knowledge. In practice, planning problems are easy to solve but\nhard to optimise. However, ML approaches still struggle to solve many problems\nthat are often easy for both humans and classical planners. In this paper, we\nthus propose a new ML approach that allows users to specify background\nknowledge (BK) through Datalog rules to guide both the learning and planning\nprocesses in an integrated fashion. By incorporating BK, our approach bypasses\nthe need to relearn how to solve problems from scratch and instead focuses the\nlearning on plan quality optimisation. Experiments with BK demonstrate that our\nmethod successfully scales and learns to plan efficiently with high quality\nsolutions from small training data generated in under 5 seconds.",
      "tldr_zh": "本研究提出了一种结合深度学习（Deep Learning）的通用规划（Generalised Planning）方法，允许用户通过 Datalog rules 指定背景知识（BK），以指导机器学习（ML）和规划过程的整合。相比传统 ML 方式，该方法避免从零开始学习，而是专注于优化计划质量，从而提升求解效率。实验结果显示，使用少量训练数据（在 5 秒内生成），该方法能高效生成高质量解决方案，并在实际规划问题上表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07923v1",
      "published_date": "2024-10-10 13:49:05 UTC",
      "updated_date": "2024-10-10 13:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:46:21.231946"
    },
    {
      "arxiv_id": "2410.07921v2",
      "title": "Boosting Hierarchical Reinforcement Learning with Meta-Learning for Complex Task Adaptation",
      "title_zh": "利用元学习提升分层强化学习以适应复杂任务",
      "authors": [
        "Arash Khajooeinejad",
        "Fatemeh Sadat Masoumi",
        "Masoumeh Chapariniya"
      ],
      "abstract": "Hierarchical Reinforcement Learning (HRL) is well-suitedd for solving complex\ntasks by breaking them down into structured policies. However, HRL agents often\nstruggle with efficient exploration and quick adaptation. To overcome these\nlimitations, we propose integrating meta-learning into HRL to enable agents to\nlearn and adapt hierarchical policies more effectively. Our method leverages\nmeta-learning to facilitate rapid task adaptation using prior experience, while\nintrinsic motivation mechanisms drive efficient exploration by rewarding the\ndiscovery of novel states. Specifically, our agent employs a high-level policy\nto choose among multiple low-level policies within custom-designed grid\nenvironments. By incorporating gradient-based meta-learning with differentiable\ninner-loop updates, we optimize performance across a curriculum of\nprogressively challenging tasks. Experimental results highlight that our\nmetalearning-enhanced hierarchical agent significantly outperforms standard HRL\napproaches lacking meta-learning and intrinsic motivation. The agent\ndemonstrates faster learning, greater cumulative rewards, and higher success\nrates in complex grid-based scenarios. These Findings underscore the\neffectiveness of combining meta-learning, curriculum learning, and intrinsic\nmotivation to enhance the capability of HRL agents in tackling complex tasks.",
      "tldr_zh": "该论文针对Hierarchical Reinforcement Learning (HRL)代理在复杂任务中存在的探索效率和快速适应问题，提出了一种整合meta-learning的方法，以提升代理的适应能力。方法通过meta-learning实现快速任务适应，利用内在动机机制（如奖励发现新状态）驱动探索，并在自定义网格环境中使用高层政策选择多个低层政策，结合基于梯度的内循环更新和课程学习优化性能。实验结果显示，该增强型HRL代理在复杂网格场景中显著优于标准HRL方法，实现了更快的学习、更高的累积奖励和成功率，证明了meta-learning、课程学习和内在动机的结合效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07921v2",
      "published_date": "2024-10-10 13:47:37 UTC",
      "updated_date": "2025-03-14 18:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:46:34.603745"
    },
    {
      "arxiv_id": "2410.11877v1",
      "title": "A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Hung-Fu Chang",
        "Tong Li"
      ],
      "abstract": "Creativity involves not only generating new ideas from scratch but also\nredefining existing concepts and synthesizing previous insights. Among various\ntechniques developed to foster creative thinking, brainstorming is widely used.\nWith recent advancements in Large Language Models (LLMs), tools like ChatGPT\nhave significantly impacted various fields by using prompts to facilitate\ncomplex tasks. While current research primarily focuses on generating accurate\nresponses, there is a need to explore how prompt engineering can enhance\ncreativity, particularly in brainstorming. Therefore, this study addresses this\ngap by proposing a framework called GPS, which employs goals, prompts, and\nstrategies to guide designers to systematically work with an LLM tool for\nimproving the creativity of ideas generated during brainstorming. Additionally,\nwe adapted the Torrance Tests of Creative Thinking (TTCT) for measuring the\ncreativity of the ideas generated by AI. Our framework, tested through a design\nexample and a case study, demonstrates its effectiveness in stimulating\ncreativity and its seamless LLM tool integration into design practices. The\nresults indicate that our framework can benefit brainstorming sessions with LLM\ntools, enhancing both the creativity and usefulness of generated ideas.",
      "tldr_zh": "本研究提出一个名为 GPS 的框架，利用目标(goals)、提示(prompts)和策略(strategies)来指导设计师与大型语言模型(LLMs)工具合作，提升脑力激荡过程中的创意生成。\n该框架强调提示工程(prompt engineering)的作用，改编了 Torrance Tests of Creative Thinking (TTCT) 来评估 AI 生成想法的创意性。\n通过设计示例和案例研究，框架证明了其有效性，能够显著增强脑力激荡会议中想法的创意性和实用性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.m"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.11877v1",
      "published_date": "2024-10-10 13:39:27 UTC",
      "updated_date": "2024-10-10 13:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:46:46.822014"
    },
    {
      "arxiv_id": "2410.07908v4",
      "title": "ONCOPILOT: A Promptable CT Foundation Model For Solid Tumor Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Léo Machado",
        "Hélène Philippe",
        "Élodie Ferreres",
        "Julien Khlaut",
        "Julie Dupuis",
        "Korentin Le Floch",
        "Denis Habip Gatenyo",
        "Pascal Roux",
        "Jules Grégory",
        "Maxime Ronot",
        "Corentin Dancette",
        "Tom Boeken",
        "Daniel Tordjman",
        "Pierre Manceron",
        "Paul Hérent"
      ],
      "abstract": "Carcinogenesis is a proteiform phenomenon, with tumors emerging in various\nlocations and displaying complex, diverse shapes. At the crucial intersection\nof research and clinical practice, it demands precise and flexible assessment.\nHowever, current biomarkers, such as RECIST 1.1's long and short axis\nmeasurements, fall short of capturing this complexity, offering an approximate\nestimate of tumor burden and a simplistic representation of a more intricate\nprocess. Additionally, existing supervised AI models face challenges in\naddressing the variability in tumor presentations, limiting their clinical\nutility. These limitations arise from the scarcity of annotations and the\nmodels' focus on narrowly defined tasks.\n  To address these challenges, we developed ONCOPILOT, an interactive\nradiological foundation model trained on approximately 7,500 CT scans covering\nthe whole body, from both normal anatomy and a wide range of oncological cases.\nONCOPILOT performs 3D tumor segmentation using visual prompts like point-click\nand bounding boxes, outperforming state-of-the-art models (e.g., nnUnet) and\nachieving radiologist-level accuracy in RECIST 1.1 measurements. The key\nadvantage of this foundation model is its ability to surpass state-of-the-art\nperformance while keeping the radiologist in the loop, a capability that\nprevious models could not achieve. When radiologists interactively refine the\nsegmentations, accuracy improves further. ONCOPILOT also accelerates\nmeasurement processes and reduces inter-reader variability, facilitating\nvolumetric analysis and unlocking new biomarkers for deeper insights.\n  This AI assistant is expected to enhance the precision of RECIST 1.1\nmeasurements, unlock the potential of volumetric biomarkers, and improve\npatient stratification and clinical care, while seamlessly integrating into the\nradiological workflow.",
      "tldr_zh": "本研究提出 ONCOPILOT，一种可提示的 CT 基础模型，用于固体肿瘤评估，以解决现有方法如 RECIST 1.1 在捕捉肿瘤多样性方面的局限性。模型基于约 7500 个全身体部 CT 扫描训练，支持 3D 肿瘤分割并使用视觉提示（如点选和边界框），其性能超越状态模型（如 nnUnet），达到放射科医生水平的准确性，并通过交互式精炼进一步提升精度。ONCOPILOT 加速测量过程、减少读者间变异，并启用体积分析和新生物标志物，促进更精确的患者分层和临床护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07908v4",
      "published_date": "2024-10-10 13:36:49 UTC",
      "updated_date": "2024-11-19 19:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:46:58.434522"
    },
    {
      "arxiv_id": "2410.07896v1",
      "title": "Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Lai",
        "Jiahe Xu",
        "Yao Yang",
        "Yunpeng Huang",
        "Chun Cao",
        "Jingwei Xu"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of natural language processing and reasoning tasks. However, their\nperformance in the foundational domain of arithmetic remains unsatisfactory.\nWhen dealing with arithmetic tasks, LLMs often memorize specific examples\nrather than learning the underlying computational logic, limiting their ability\nto generalize to new problems. In this paper, we propose a Composable\nArithmetic Execution Framework (CAEF) that enables LLMs to learn to execute\nstep-by-step computations by emulating Turing Machines, thereby gaining a\ngenuine understanding of computational logic. Moreover, the proposed framework\nis highly scalable, allowing composing learned operators to significantly\nreduce the difficulty of learning complex operators. In our evaluation, CAEF\nachieves nearly 100% accuracy across seven common mathematical operations on\nthe LLaMA 3.1-8B model, effectively supporting computations involving operands\nwith up to 100 digits, a level where GPT-4o falls short noticeably in some\nsettings.",
      "tldr_zh": "该研究发现，大型语言模型(LLMs)在算术任务上表现不佳，主要依赖记忆特定例子而非理解底层计算逻辑。为解决此问题，论文提出Composable Arithmetic Execution Framework(CAEF)，通过模拟Turing Machines让LLMs学习逐步执行计算，从而获得真正的计算逻辑理解，且框架支持可组合操作符以简化复杂运算的学习。在评估中，CAEF在LLaMA 3.1-8B模型上实现了近100%的准确率，支持多达100位数字的操作，显著超越GPT-4o在某些场景下的表现。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.07896v1",
      "published_date": "2024-10-10 13:23:49 UTC",
      "updated_date": "2024-10-10 13:23:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:47:09.494049"
    },
    {
      "arxiv_id": "2410.08250v1",
      "title": "Exploring ASR-Based Wav2Vec2 for Automated Speech Disorder Assessment: Insights and Analysis",
      "title_zh": "探索基于 ASR 的 Wav2Vec2 用于自动化语音障碍评估：洞见与分析",
      "authors": [
        "Tuan Nguyen",
        "Corinne Fredouille",
        "Alain Ghio",
        "Mathieu Balaguer",
        "Virginie Woisard"
      ],
      "abstract": "With the rise of SSL and ASR technologies, the Wav2Vec2 ASR-based model has\nbeen fine-tuned for automated speech disorder quality assessment tasks,\nyielding impressive results and setting a new baseline for Head and Neck Cancer\nspeech contexts. This demonstrates that the ASR dimension from Wav2Vec2 closely\naligns with assessment dimensions. Despite its effectiveness, this system\nremains a black box with no clear interpretation of the connection between the\nmodel ASR dimension and clinical assessments. This paper presents the first\nanalysis of this baseline model for speech quality assessment, focusing on\nintelligibility and severity tasks. We conduct a layer-wise analysis to\nidentify key layers and compare different SSL and ASR Wav2Vec2 models based on\npre-trained data. Additionally, post-hoc XAI methods, including Canonical\nCorrelation Analysis (CCA) and visualization techniques, are used to track\nmodel evolution and visualize embeddings for enhanced interpretability.",
      "tldr_zh": "这篇论文探讨了基于 ASR 的 Wav2Vec2 模型在自动化语音障碍评估中的应用，特别是针对头部和颈部癌症相关语音上下文的清晰度和严重度任务。研究通过层级分析比较了不同 SSL 和 ASR Wav2Vec2 模型，识别关键层并使用后验 XAI 方法如 Canonical Correlation Analysis (CCA) 和可视化技术来提升模型的可解释性。结果显示，该模型设定了新基准，证明 ASR 维度与临床评估高度相关，为未来语音障碍评估系统的开发提供了重要洞见。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at the Spoken Language Technology (SLT) Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08250v1",
      "published_date": "2024-10-10 13:12:17 UTC",
      "updated_date": "2024-10-10 13:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:47:23.015771"
    },
    {
      "arxiv_id": "2410.07869v3",
      "title": "Benchmarking Agentic Workflow Generation",
      "title_zh": "代理式工作流生成的基准测试",
      "authors": [
        "Shuofei Qiao",
        "Runnan Fang",
        "Zhisong Qiu",
        "Xiaobin Wang",
        "Ningyu Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen"
      ],
      "abstract": "Large Language Models (LLMs), with their exceptional ability to handle a wide\nrange of tasks, have driven significant advancements in tackling reasoning and\nplanning tasks, wherein decomposing complex problems into executable workflows\nis a crucial step in this process. Existing workflow evaluation frameworks\neither focus solely on holistic performance or suffer from limitations such as\nrestricted scenario coverage, simplistic workflow structures, and lax\nevaluation standards. To this end, we introduce WorfBench, a unified workflow\ngeneration benchmark with multi-faceted scenarios and intricate graph workflow\nstructures. Additionally, we present WorfEval, a systemic evaluation protocol\nutilizing subsequence and subgraph matching algorithms to accurately quantify\nthe LLM agent's workflow generation capabilities. Through comprehensive\nevaluations across different types of LLMs, we discover distinct gaps between\nthe sequence planning capabilities and graph planning capabilities of LLM\nagents, with even GPT-4 exhibiting a gap of around 15%. We also train two\nopen-source models and evaluate their generalization abilities on held-out\ntasks. Furthermore, we observe that the generated workflows can enhance\ndownstream tasks, enabling them to achieve superior performance with less time\nduring inference. Code and dataset are available at\nhttps://github.com/zjunlp/WorfBench.",
      "tldr_zh": "该研究针对大语言模型(LLMs)在处理推理和规划任务时的工作流生成能力进行了基准测试，指出现有评估框架存在场景覆盖有限、工作流结构简单等问题。论文引入了WorfBench基准测试平台，支持多场景和复杂图形工作流结构，并提出了WorfEval评估协议，使用子序列和子图匹配算法来精确量化LLMs的工作流生成能力。实验结果显示，各种LLMs在序列规划和图规划之间存在显著差距（如GPT-4约为15%），同时训练的开源模型显示出良好的泛化能力，且生成的流程能提升下游任务的性能和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.07869v3",
      "published_date": "2024-10-10 12:41:19 UTC",
      "updated_date": "2025-02-23 15:16:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:47:34.875335"
    },
    {
      "arxiv_id": "2410.07867v1",
      "title": "The Sets of Power",
      "title_zh": "翻译失败",
      "authors": [
        "Joao Marques-Silva",
        "Carlos Mencía",
        "Raúl Mencía"
      ],
      "abstract": "Measures of voting power have been the subject of extensive research since\nthe mid 1940s. More recently, similar measures of relative importance have been\nstudied in other domains that include inconsistent knowledge bases, intensity\nof attacks in argumentation, different problems in the analysis of database\nmanagement, and explainability. This paper demonstrates that all these examples\nare instantiations of computing measures of importance for a rather more\ngeneral problem domain. The paper then shows that the best-known measures of\nimportance can be computed for any reference set whenever one is given a\nmonotonically increasing predicate that partitions the subsets of that\nreference set. As a consequence, the paper also proves that measures of\nimportance can be devised in several domains, for some of which such measures\nhave not yet been studied nor proposed. Furthermore, the paper highlights\nseveral research directions related with computing measures of importance.",
      "tldr_zh": "这篇论文将投票权力（voting power）和其他领域的相对重要性度量（如不一致知识库、论辩攻击强度和数据库管理分析）统一到一个更一般的框架中，证明这些都是计算重要性度量的实例。论文展示了，当给定一个单调递增的谓词（monotonically increasing predicate）来分区参考集的子集时，最知名的重要性度量（measures of importance）可以适用于任何参考集，从而扩展到尚未研究的新领域。最终，论文突出了计算重要性度量的若干研究方向，为相关领域提供了新的理论基础和应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07867v1",
      "published_date": "2024-10-10 12:35:50 UTC",
      "updated_date": "2024-10-10 12:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:47:46.696724"
    },
    {
      "arxiv_id": "2410.07866v3",
      "title": "System 2 Reasoning via Generality and Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Sejin Kim",
        "Sundong Kim"
      ],
      "abstract": "While significant progress has been made in task-specific applications,\ncurrent models struggle with deep reasoning, generality, and adaptation -- key\ncomponents of System 2 reasoning that are crucial for achieving Artificial\nGeneral Intelligence (AGI). Despite the promise of approaches such as program\nsynthesis, language models, and transformers, these methods often fail to\ngeneralize beyond their training data and to adapt to novel tasks, limiting\ntheir ability to perform human-like reasoning. This paper explores the\nlimitations of existing approaches in achieving advanced System 2 reasoning and\nhighlights the importance of generality and adaptation for AGI. Moreover, we\npropose four key research directions to address these gaps: (1) learning human\nintentions from action sequences, (2) combining symbolic and neural models, (3)\nmeta-learning for unfamiliar environments, and (4) reinforcement learning to\nreason multi-step. Through these directions, we aim to advance the ability to\ngeneralize and adapt, bringing computational models closer to the reasoning\ncapabilities required for AGI.",
      "tldr_zh": "本论文探讨了当前模型在 System 2 Reasoning 中的局限性，包括深度推理、一般性和适应性的不足，这些是实现 Artificial General Intelligence (AGI) 的关键挑战。尽管程序合成、语言模型和 transformers 等方法取得了进展，但它们往往无法超出训练数据泛化或适应新任务。作者提出了四个关键研究方向来解决这些问题：(1) 从动作序列中学习人类意图，(2) 结合符号和神经模型，(3) 元学习用于不熟悉的环境，以及(4) 强化学习支持多步推理。通过这些方向，论文旨在提升模型的泛化和适应能力，使其更接近人类般的推理水平。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NeurIPS 2024 Workshop on System 2 Reasoning at Scale",
      "pdf_url": "http://arxiv.org/pdf/2410.07866v3",
      "published_date": "2024-10-10 12:34:25 UTC",
      "updated_date": "2024-12-09 12:14:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:47:57.803710"
    },
    {
      "arxiv_id": "2410.07864v2",
      "title": "RDT-1B: a Diffusion Foundation Model for Bimanual Manipulation",
      "title_zh": "RDT-1B：扩散基础模型用于双臂操控",
      "authors": [
        "Songming Liu",
        "Lingxuan Wu",
        "Bangguo Li",
        "Hengkai Tan",
        "Huayu Chen",
        "Zhengyi Wang",
        "Ke Xu",
        "Hang Su",
        "Jun Zhu"
      ],
      "abstract": "Bimanual manipulation is essential in robotics, yet developing foundation\nmodels is extremely challenging due to the inherent complexity of coordinating\ntwo robot arms (leading to multi-modal action distributions) and the scarcity\nof training data. In this paper, we present the Robotics Diffusion Transformer\n(RDT), a pioneering diffusion foundation model for bimanual manipulation. RDT\nbuilds on diffusion models to effectively represent multi-modality, with\ninnovative designs of a scalable Transformer to deal with the heterogeneity of\nmulti-modal inputs and to capture the nonlinearity and high frequency of\nrobotic data. To address data scarcity, we further introduce a Physically\nInterpretable Unified Action Space, which can unify the action representations\nof various robots while preserving the physical meanings of original actions,\nfacilitating learning transferrable physical knowledge. With these designs, we\nmanaged to pre-train RDT on the largest collection of multi-robot datasets to\ndate and scaled it up to 1.2B parameters, which is the largest diffusion-based\nfoundation model for robotic manipulation. We finally fine-tuned RDT on a\nself-created multi-task bimanual dataset with over 6K+ episodes to refine its\nmanipulation capabilities. Experiments on real robots demonstrate that RDT\nsignificantly outperforms existing methods. It exhibits zero-shot\ngeneralization to unseen objects and scenes, understands and follows language\ninstructions, learns new skills with just 1~5 demonstrations, and effectively\nhandles complex, dexterous tasks. We refer to\nhttps://rdt-robotics.github.io/rdt-robotics/ for the code and videos.",
      "tldr_zh": "本文提出 RDT-1B，一种基于扩散模型的 Transformer 基础模型，用于处理双臂操作 (Bimanual Manipulation) 的复杂性，包括多模态动作分布和数据稀缺问题。RDT 创新性地设计了可扩展的 Transformer 来管理多模态输入的异质性，并引入 Physically Interpretable Unified Action Space，以统一不同机器人的动作表示并保留物理含义，促进知识转移。模型在最大的多机器人数据集上预训练，规模达 1.2B 参数，并通过微调一个包含 6K+ 剧集的多任务数据集，提升了操作能力。实验结果显示，RDT 在真实机器人上显著优于现有方法，实现了零样本泛化、语言指令理解以及仅需 1~5 次演示即可学习新技能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2410.07864v2",
      "published_date": "2024-10-10 12:33:46 UTC",
      "updated_date": "2025-03-01 08:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:48:12.620589"
    },
    {
      "arxiv_id": "2410.07863v2",
      "title": "Learning to Balance Altruism and Self-interest Based on Empathy in Mixed-Motive Games",
      "title_zh": "翻译失败",
      "authors": [
        "Fanqi Kong",
        "Yizhe Huang",
        "Song-Chun Zhu",
        "Siyuan Qi",
        "Xue Feng"
      ],
      "abstract": "Real-world multi-agent scenarios often involve mixed motives, demanding\naltruistic agents capable of self-protection against potential exploitation.\nHowever, existing approaches often struggle to achieve both objectives. In this\npaper, based on that empathic responses are modulated by inferred social\nrelationships between agents, we propose LASE Learning to balance Altruism and\nSelf-interest based on Empathy), a distributed multi-agent reinforcement\nlearning algorithm that fosters altruistic cooperation through gifting while\navoiding exploitation by other agents in mixed-motive games. LASE allocates a\nportion of its rewards to co-players as gifts, with this allocation adapting\ndynamically based on the social relationship -- a metric evaluating the\nfriendliness of co-players estimated by counterfactual reasoning. In\nparticular, social relationship measures each co-player by comparing the\nestimated $Q$-function of current joint action to a counterfactual baseline\nwhich marginalizes the co-player's action, with its action distribution\ninferred by a perspective-taking module. Comprehensive experiments are\nperformed in spatially and temporally extended mixed-motive games,\ndemonstrating LASE's ability to promote group collaboration without\ncompromising fairness and its capacity to adapt policies to various types of\ninteractive co-players.",
      "tldr_zh": "该论文探讨了混合动机游戏(multi-agent reinforcement learning)中如何平衡利他主义(altruism)和自我利益(self-interest)，以应对代理可能被利用的风险。作者提出 LASE（Learning to Balance Altruism and Self-interest based on Empathy）算法，这是一种分布式多智能体强化学习方法，通过动态分配奖励作为礼物来促进合作，同时利用反事实推理(counterfactual reasoning)和视角转换模块评估合作者的社会关系。LASE 根据每个合作者的友好度调整资源分配，具体通过比较当前联合动作的 Q-function 与反事实基准来衡量关系。实验结果显示，在空间和时间扩展的混合动机游戏中，LASE 显著提升了团体合作，同时维持了公平性，并能适应不同类型的互动代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07863v2",
      "published_date": "2024-10-10 12:30:56 UTC",
      "updated_date": "2025-01-18 06:45:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:48:22.568988"
    },
    {
      "arxiv_id": "2410.07858v1",
      "title": "From Logits to Hierarchies: Hierarchical Clustering made Simple",
      "title_zh": "翻译失败",
      "authors": [
        "Emanuele Palumbo",
        "Moritz Vandenhirtz",
        "Alain Ryser",
        "Imant Daunhawer",
        "Julia E. Vogt"
      ],
      "abstract": "The structure of many real-world datasets is intrinsically hierarchical,\nmaking the modeling of such hierarchies a critical objective in both\nunsupervised and supervised machine learning. Recently, novel approaches for\nhierarchical clustering with deep architectures have been proposed. In this\nwork, we take a critical perspective on this line of research and demonstrate\nthat many approaches exhibit major limitations when applied to realistic\ndatasets, partly due to their high computational complexity. In particular, we\nshow that a lightweight procedure implemented on top of pre-trained\nnon-hierarchical clustering models outperforms models designed specifically for\nhierarchical clustering. Our proposed approach is computationally efficient and\napplicable to any pre-trained clustering model that outputs logits, without\nrequiring any fine-tuning. To highlight the generality of our findings, we\nillustrate how our method can also be applied in a supervised setup, recovering\nmeaningful hierarchies from a pre-trained ImageNet classifier.",
      "tldr_zh": "该论文批评了现有基于深度架构的层次聚类方法在实际数据集上存在的局限性，如计算复杂度高和性能不足。作者提出了一种轻量级方法，利用预训练的非层次聚类模型的logits输出来构建层次结构，无需任何微调。实验结果显示，该方法在计算效率上优越，并在无监督和监督场景中表现出色，例如从预训练的ImageNet分类器中恢复有意义的层次结构，从而为建模真实数据集的内在层次提供了更简单有效的途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07858v1",
      "published_date": "2024-10-10 12:27:45 UTC",
      "updated_date": "2024-10-10 12:27:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:48:33.435952"
    },
    {
      "arxiv_id": "2410.07857v1",
      "title": "SNN-PAR: Energy Efficient Pedestrian Attribute Recognition via Spiking Neural Networks",
      "title_zh": "SNN-PAR",
      "authors": [
        "Haiyang Wang",
        "Qian Zhu",
        "Mowen She",
        "Yabo Li",
        "Haoyu Song",
        "Minghe Xu",
        "Xiao Wang"
      ],
      "abstract": "Artificial neural network based Pedestrian Attribute Recognition (PAR) has\nbeen widely studied in recent years, despite many progresses, however, the\nenergy consumption is still high. To address this issue, in this paper, we\npropose a Spiking Neural Network (SNN) based framework for energy-efficient\nattribute recognition. Specifically, we first adopt a spiking tokenizer module\nto transform the given pedestrian image into spiking feature representations.\nThen, the output will be fed into the spiking Transformer backbone networks for\nenergy-efficient feature extraction. We feed the enhanced spiking features into\na set of feed-forward networks for pedestrian attribute recognition. In\naddition to the widely used binary cross-entropy loss function, we also exploit\nknowledge distillation from the artificial neural network to the spiking\nTransformer network for more accurate attribute recognition. Extensive\nexperiments on three widely used PAR benchmark datasets fully validated the\neffectiveness of our proposed SNN-PAR framework. The source code of this paper\nis released on \\url{https://github.com/Event-AHU/OpenPAR}.",
      "tldr_zh": "该论文提出SNN-PAR框架，利用Spiking Neural Networks (SNN)实现能源高效的Pedestrian Attribute Recognition (PAR)，以解决现有基于Artificial Neural Network (ANN)方法的能源消耗问题。具体而言，该框架包括spiking tokenizer模块将行人图像转化为脉冲特征表示、spiking Transformer骨干网络进行特征提取，以及前馈网络进行属性识别，同时结合知识蒸馏从ANN到SNN以提升准确性。在三个常用PAR基准数据集上的广泛实验验证了框架的有效性，并提供了源代码开源链接。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07857v1",
      "published_date": "2024-10-10 12:26:06 UTC",
      "updated_date": "2024-10-10 12:26:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:48:46.844478"
    },
    {
      "arxiv_id": "2410.08249v2",
      "title": "Federated Graph Learning for Cross-Domain Recommendation",
      "title_zh": "联邦图学习用于跨域推荐",
      "authors": [
        "Ziqi Yang",
        "Zhaopeng Peng",
        "Zihui Wang",
        "Jianzhong Qi",
        "Chaochao Chen",
        "Weike Pan",
        "Chenglu Wen",
        "Cheng Wang",
        "Xiaoliang Fan"
      ],
      "abstract": "Cross-domain recommendation (CDR) offers a promising solution to the data\nsparsity problem by enabling knowledge transfer across source and target\ndomains. However, many recent CDR models overlook crucial issues such as\nprivacy as well as the risk of negative transfer (which negatively impact model\nperformance), especially in multi-domain settings. To address these challenges,\nwe propose FedGCDR, a novel federated graph learning framework that securely\nand effectively leverages positive knowledge from multiple source domains.\nFirst, we design a positive knowledge transfer module that ensures privacy\nduring inter-domain knowledge transmission. This module employs differential\nprivacy-based knowledge extraction combined with a feature mapping mechanism,\ntransforming source domain embeddings from federated graph attention networks\ninto reliable domain knowledge. Second, we design a knowledge activation module\nto filter out potential harmful or conflicting knowledge from source domains,\naddressing the issues of negative transfer. This module enhances target domain\ntraining by expanding the graph of the target domain to generate reliable\ndomain attentions and fine-tunes the target model for improved negative\nknowledge filtering and more accurate predictions. We conduct extensive\nexperiments on 16 popular domains of the Amazon dataset, demonstrating that\nFedGCDR significantly outperforms state-of-the-art methods.",
      "tldr_zh": "本论文提出FedGCDR，一种基于联邦图学习的框架，用于解决跨域推荐（Cross-Domain Recommendation）中的数据稀疏问题，同时处理隐私和负面转移（negative transfer）风险。该框架包括正向知识转移模块，使用差分隐私（differential privacy）结合特征映射机制，从联邦图注意力网络（federated graph attention networks）中安全提取源域嵌入，确保知识传输的隐私性。知识激活模块则通过扩展目标域图生成可靠的域注意力，并微调模型以过滤有害知识，从而提升预测准确性。在Amazon数据集的16个域上进行的实验表明，FedGCDR显著优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS'24",
      "pdf_url": "http://arxiv.org/pdf/2410.08249v2",
      "published_date": "2024-10-10 12:19:51 UTC",
      "updated_date": "2024-11-04 02:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:48:58.294922"
    },
    {
      "arxiv_id": "2410.09114v2",
      "title": "Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Andrey Anurin",
        "Jonathan Ng",
        "Kibo Schaffer",
        "Jason Schreiber",
        "Esben Kran"
      ],
      "abstract": "LLM agents have the potential to revolutionize defensive cyber operations,\nbut their offensive capabilities are not yet fully understood. To prepare for\nemerging threats, model developers and governments are evaluating the cyber\ncapabilities of foundation models. However, these assessments often lack\ntransparency and a comprehensive focus on offensive capabilities. In response,\nwe introduce the Catastrophic Cyber Capabilities Benchmark (3CB), a novel\nframework designed to rigorously assess the real-world offensive capabilities\nof LLM agents. Our evaluation of modern LLMs on 3CB reveals that frontier\nmodels, such as GPT-4o and Claude 3.5 Sonnet, can perform offensive tasks such\nas reconnaissance and exploitation across domains ranging from binary analysis\nto web technologies. Conversely, smaller open-source models exhibit limited\noffensive capabilities. Our software solution and the corresponding benchmark\nprovides a critical tool to reduce the gap between rapidly improving\ncapabilities and robustness of cyber offense evaluations, aiding in the safer\ndeployment and regulation of these powerful technologies.",
      "tldr_zh": "该研究引入了Catastrophic Cyber Capabilities Benchmark (3CB)，一个新的框架，用于透明且全面评估大型语言模型(LLM)代理的真实世界网络攻击能力，以应对潜在威胁。研究评估了前沿模型如GPT-4o和Claude 3.5 Sonnet，发现它们在侦察、利用等任务中表现出色，而较小的开源模型则能力有限。3CB提供的软件工具有助于缩小能力提升与评估稳健性之间的差距，促进LLM技术的更安全部署和监管。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CR",
      "comment": "https://cybercapabilities.org/",
      "pdf_url": "http://arxiv.org/pdf/2410.09114v2",
      "published_date": "2024-10-10 12:06:48 UTC",
      "updated_date": "2024-11-02 09:35:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:49:10.727968"
    },
    {
      "arxiv_id": "2410.07838v3",
      "title": "Minority-Focused Text-to-Image Generation via Prompt Optimization",
      "title_zh": "针对少数样本的文本到图像生成通过提示优化",
      "authors": [
        "Soobin Um",
        "Jong Chul Ye"
      ],
      "abstract": "We investigate the generation of minority samples using pretrained\ntext-to-image (T2I) latent diffusion models. Minority instances, in the context\nof T2I generation, can be defined as ones living on low-density regions of\ntext-conditional data distributions. They are valuable for various applications\nof modern T2I generators, such as data augmentation and creative AI.\nUnfortunately, existing pretrained T2I diffusion models primarily focus on\nhigh-density regions, largely due to the influence of guided samplers (like\nCFG) that are essential for high-quality generation. To address this, we\npresent a novel framework to counter the high-density-focus of T2I diffusion\nmodels. Specifically, we first develop an online prompt optimization framework\nthat encourages emergence of desired properties during inference while\npreserving semantic contents of user-provided prompts. We subsequently tailor\nthis generic prompt optimizer into a specialized solver that promotes\ngeneration of minority features by incorporating a carefully-crafted likelihood\nobjective. Extensive experiments conducted across various types of T2I models\ndemonstrate that our approach significantly enhances the capability to produce\nhigh-quality minority instances compared to existing samplers. Code is\navailable at https://github.com/soobin-um/MinorityPrompt.",
      "tldr_zh": "本文研究了使用预训练的 text-to-image (T2I) 潜在扩散模型生成位于低密度区域的少数派样本，这些样本可用于数据增强和创意 AI，但现有模型因受引导采样器（如 CFG）影响而偏向高密度区域。作者提出一个在线提示优化框架（online prompt optimization framework），该框架在推理过程中保留用户提示的语义内容，同时通过一个结合精心设计的似然目标（likelihood objective）的专门求解器来促进少数派特征的生成。实验结果显示，该方法在多种 T2I 模型上显著提升了生成高质量少数派实例的能力，比现有采样器更有效。代码可访问 https://github.com/soobin-um/MinorityPrompt。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (Oral), 21 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07838v3",
      "published_date": "2024-10-10 11:56:09 UTC",
      "updated_date": "2025-04-04 10:37:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:49:23.513745"
    },
    {
      "arxiv_id": "2410.19746v2",
      "title": "Metamizer: a versatile neural optimizer for fast and accurate physics simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Nils Wandel",
        "Stefan Schulz",
        "Reinhard Klein"
      ],
      "abstract": "Efficient physics simulations are essential for numerous applications,\nranging from realistic cloth animations or smoke effects in video games, to\nanalyzing pollutant dispersion in environmental sciences, to calculating\nvehicle drag coefficients in engineering applications. Unfortunately,\nanalytical solutions to the underlying physical equations are rarely available,\nand numerical solutions require high computational resources. Latest\ndevelopments in the field of physics-based Deep Learning have led to promising\nefficiency improvements but still suffer from limited generalization\ncapabilities and low accuracy compared to numerical solvers.\n  In this work, we introduce Metamizer, a novel neural optimizer that\niteratively solves a wide range of physical systems with high accuracy by\nminimizing a physics-based loss function. To this end, our approach leverages a\nscale-invariant architecture that enhances gradient descent updates to\naccelerate convergence. Since the neural network itself acts as an optimizer,\ntraining this neural optimizer falls into the category of meta-optimization\napproaches.\n  We demonstrate that Metamizer achieves unprecedented accuracy for deep\nlearning based approaches - sometimes approaching machine precision - across\nmultiple PDEs after training on the Laplace, advection-diffusion and\nincompressible Navier-Stokes equation as well as on cloth simulations.\nRemarkably, the model also generalizes to PDEs that were not covered during\ntraining such as the Poisson, wave and Burgers equation.\n  Our results suggest that Metamizer could have a profound impact on future\nnumerical solvers, paving the way for fast and accurate neural physics\nsimulations without the need for retraining.",
      "tldr_zh": "该论文提出了一种多功能神经优化器Metamizer，用于实现快速且高精度的物理模拟。该方法通过最小化基于物理的损失函数并采用scale-invariant架构来增强梯度下降更新，从而加速收敛并支持meta-optimization框架。Metamizer在训练于Laplace、advection-diffusion和incompressible Navier-Stokes方程以及布料模拟后，实现了比传统深度学习方法更高的准确性，有时接近机器精度，并成功泛化到未训练的PDEs，如Poisson、wave和Burgers方程。该优化器有望革新数值求解器，提供无需重新训练的神经物理模拟解决方案。",
      "categories": [
        "physics.comp-ph",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "to be published at International Conference on Learning\n  Representations (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.19746v2",
      "published_date": "2024-10-10 11:54:31 UTC",
      "updated_date": "2025-04-20 19:42:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:49:44.318722"
    },
    {
      "arxiv_id": "2410.17281v1",
      "title": "A Comprehensive Survey and Classification of Evaluation Criteria for Trustworthy Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Louise McCormack",
        "Malika Bendechache"
      ],
      "abstract": "This paper presents a systematic review of the literature on evaluation\ncriteria for Trustworthy Artificial Intelligence (TAI), with a focus on the\nseven EU principles of TAI. This systematic literature review identifies and\nanalyses current evaluation criteria, maps them to the EU TAI principles and\nproposes a new classification system for each principle. The findings reveal\nboth a need for and significant barriers to standardising criteria for TAI\nevaluation. The proposed classification contributes to the development,\nselection and standardization of evaluation criteria for TAI governance.",
      "tldr_zh": "这篇论文对 Trustworthy Artificial Intelligence (TAI) 的评价标准进行了系统文献综述，重点关注欧盟的七大 TAI 原则，通过识别和分析现有标准，并将它们映射到这些原则上，提出了一种新的分类系统。研究发现，虽然标准化 TAI 评价标准的需求迫切，但仍面临显著障碍，如一致性问题和实施挑战。该分类系统有助于提升 TAI 治理中的标准开发、选择和标准化进程。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "This work has been accepted for publication in AI and Ethics",
      "pdf_url": "http://arxiv.org/pdf/2410.17281v1",
      "published_date": "2024-10-10 11:54:14 UTC",
      "updated_date": "2024-10-10 11:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:49:45.710856"
    },
    {
      "arxiv_id": "2410.07836v5",
      "title": "Masked Generative Priors Improve World Models Sequence Modelling Capabilities",
      "title_zh": "掩码生成先验提升世界模型的序列建模能力",
      "authors": [
        "Cristian Meo",
        "Mircea Lica",
        "Zarif Ikram",
        "Akihiro Nakano",
        "Vedant Shah",
        "Aniket Rajiv Didolkar",
        "Dianbo Liu",
        "Anirudh Goyal",
        "Justin Dauwels"
      ],
      "abstract": "Deep Reinforcement Learning (RL) has become the leading approach for creating\nartificial agents in complex environments. Model-based approaches, which are RL\nmethods with world models that predict environment dynamics, are among the most\npromising directions for improving data efficiency, forming a critical step\ntoward bridging the gap between research and real-world deployment. In\nparticular, world models enhance sample efficiency by learning in imagination,\nwhich involves training a generative sequence model of the environment in a\nself-supervised manner. Recently, Masked Generative Modelling has emerged as a\nmore efficient and superior inductive bias for modelling and generating token\nsequences. Building on the Efficient Stochastic Transformer-based World Models\n(STORM) architecture, we replace the traditional MLP prior with a Masked\nGenerative Prior (e.g., MaskGIT Prior) and introduce GIT-STORM. We evaluate our\nmodel on two downstream tasks: reinforcement learning and video prediction.\nGIT-STORM demonstrates substantial performance gains in RL tasks on the Atari\n100k benchmark. Moreover, we apply Transformer-based World Models to continuous\naction environments for the first time, addressing a significant gap in prior\nresearch. To achieve this, we employ a state mixer function that integrates\nlatent state representations with actions, enabling our model to handle\ncontinuous control tasks. We validate this approach through qualitative and\nquantitative analyses on the DeepMind Control Suite, showcasing the\neffectiveness of Transformer-based World Models in this new domain. Our results\nhighlight the versatility and efficacy of the MaskGIT dynamics prior, paving\nthe way for more accurate world models and effective RL policies.",
      "tldr_zh": "本研究探讨了在深度强化学习（Deep Reinforcement Learning）中，使用 Masked Generative Priors 提升世界模型（world models）的序列建模能力，以提高数据效率和实际部署潜力。论文基于 Efficient Stochastic Transformer-based World Models (STORM) 架构，将传统 MLP prior 替换为 Masked Generative Prior（如 MaskGIT Prior），开发出 GIT-STORM 模型，并在强化学习和视频预测任务上进行评估。结果显示，GIT-STORM 在 Atari 100k benchmark 的 RL 任务中实现了显著性能提升，并首次将 Transformer-based World Models 应用于连续动作环境，通过 state mixer 函数整合潜状态和动作，在 DeepMind Control Suite 上验证了其有效性。该方法突出了 MaskGIT dynamics prior 的多功能性，为更准确的世界模型和高效 RL 策略奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07836v5",
      "published_date": "2024-10-10 11:52:07 UTC",
      "updated_date": "2025-04-30 17:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:49:59.402011"
    },
    {
      "arxiv_id": "2410.07832v1",
      "title": "LaB-CL: Localized and Balanced Contrastive Learning for improving parking slot detection",
      "title_zh": "LaB-CL：用于提升停车位检测的本地化和平衡对比学习",
      "authors": [
        "U Jin Jeong",
        "Sumin Roh",
        "Il Yong Chun"
      ],
      "abstract": "Parking slot detection is an essential technology in autonomous parking\nsystems. In general, the classification problem of parking slot detection\nconsists of two tasks, a task determining whether localized candidates are\njunctions of parking slots or not, and the other that identifies a shape of\ndetected junctions. Both classification tasks can easily face biased learning\ntoward the majority class, degrading classification performances. Yet, the data\nimbalance issue has been overlooked in parking slot detection. We propose the\nfirst supervised contrastive learning framework for parking slot detection,\nLocalized and Balanced Contrastive Learning for improving parking slot\ndetection (LaB-CL). The proposed LaB-CL framework uses two main approaches.\nFirst, we propose to include class prototypes to consider representations from\nall classes in every mini batch, from the local perspective. Second, we propose\na new hard negative sampling scheme that selects local representations with\nhigh prediction error. Experiments with the benchmark dataset demonstrate that\nthe proposed LaB-CL framework can outperform existing parking slot detection\nmethods.",
      "tldr_zh": "停车位检测是自动停车系统的重要技术，但由于数据不平衡，分类任务（如判断本地化候选物是否为停车位连接点和识别其形状）容易偏向多数类，导致性能下降。研究提出LaB-CL框架，这是一种监督对比学习（supervised contrastive learning）方法，包括两个关键创新：一是加入类原型，以在每个小批量中考虑所有类的局部表示；二是采用新的硬负采样方案，选择预测错误高的局部表示。实验结果显示，在基准数据集上，LaB-CL优于现有停车位检测方法，提高了整体检测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07832v1",
      "published_date": "2024-10-10 11:50:26 UTC",
      "updated_date": "2024-10-10 11:50:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:50:10.088680"
    },
    {
      "arxiv_id": "2410.08247v1",
      "title": "Forecasting mortality associated emergency department crowding",
      "title_zh": "预测与死亡率相关的急诊室拥挤",
      "authors": [
        "Jalmari Nevanlinna",
        "Anna Eidstø",
        "Jari Ylä-Mattila",
        "Teemu Koivistoinen",
        "Niku Oksala",
        "Juho Kanniainen",
        "Ari Palomäki",
        "Antti Roine"
      ],
      "abstract": "Emergency department (ED) crowding is a global public health issue that has\nbeen repeatedly associated with increased mortality. Predicting future service\ndemand would enable preventative measures aiming to eliminate crowding along\nwith it's detrimental effects. Recent findings in our ED indicate that\noccupancy ratios exceeding 90% are associated with increased 10-day mortality.\nIn this paper, we aim to predict these crisis periods using retrospective data\nfrom a large Nordic ED with a LightGBM model. We provide predictions for the\nwhole ED and individually for it's different operational sections. We\ndemonstrate that afternoon crowding can be predicted at 11 a.m. with an AUC of\n0.82 (95% CI 0.78-0.86) and at 8 a.m. with an AUC up to 0.79 (95% CI\n0.75-0.83). Consequently we show that forecasting mortality-associated crowding\nusing anonymous administrative data is feasible.",
      "tldr_zh": "本研究探讨了急诊室 (ED) 拥挤与增加死亡率的相关性，旨在通过预测未来服务需求来预防危机。研究者使用 LightGBM 模型分析大型北欧 ED 的回顾性数据，对整个 ED 及其不同操作部分进行拥挤预测。结果显示，在上午 11 点预测下午拥挤的 AUC 为 0.82 (95% CI 0.78-0.86)，而在上午 8 点可达 0.79 (95% CI 0.75-0.83)。这项工作证明，使用匿名行政数据预测与死亡率相关的 ED 拥挤是可行的，从而为采取预防措施提供基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08247v1",
      "published_date": "2024-10-10 11:38:39 UTC",
      "updated_date": "2024-10-10 11:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:50:25.680941"
    },
    {
      "arxiv_id": "2410.09113v1",
      "title": "M$^2$-ViT: Accelerating Hybrid Vision Transformers with Two-Level Mixed Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbiao Liang",
        "Huihong Shi",
        "Zhongfeng Wang"
      ],
      "abstract": "Although Vision Transformers (ViTs) have achieved significant success, their\nintensive computations and substantial memory overheads challenge their\ndeployment on edge devices. To address this, efficient ViTs have emerged,\ntypically featuring Convolution-Transformer hybrid architectures to enhance\nboth accuracy and hardware efficiency. While prior work has explored\nquantization for efficient ViTs to marry the best of efficient hybrid ViT\narchitectures and quantization, it focuses on uniform quantization and\noverlooks the potential advantages of mixed quantization. Meanwhile, although\nseveral works have studied mixed quantization for standard ViTs, they are not\ndirectly applicable to hybrid ViTs due to their distinct algorithmic and\nhardware characteristics. To bridge this gap, we present M$^2$-ViT to\naccelerate Convolution-Transformer hybrid efficient ViTs with two-level mixed\nquantization. Specifically, we introduce a hardware-friendly two-level mixed\nquantization (M$^2$Q) strategy, characterized by both mixed quantization\nprecision and mixed quantization schemes (i.e., uniform and power-of-two), to\nexploit the architectural properties of efficient ViTs. We further build a\ndedicated accelerator with heterogeneous computing engines to transform our\nalgorithmic benefits into real hardware improvements. Experimental results\nvalidate our effectiveness, showcasing an average of $80\\%$ energy-delay\nproduct (EDP) saving with comparable quantization accuracy compared to the\nprior work.",
      "tldr_zh": "该研究针对Vision Transformers (ViTs)的高计算和内存开销问题，提出M²-ViT框架，通过两级混合量化（two-level mixed quantization）加速Convolution-Transformer混合架构的ViTs。具体而言，M²-ViT引入混合量化精度和量化方案（如uniform和power-of-two），以利用混合ViTs的架构特性，并设计了异构计算引擎的专用加速器。实验结果显示，与现有工作相比，M²-ViT实现了平均80%的能量延迟乘积(EDP)节省，同时保持了可比的量化准确性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09113v1",
      "published_date": "2024-10-10 11:16:57 UTC",
      "updated_date": "2024-10-10 11:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:50:34.280087"
    },
    {
      "arxiv_id": "2410.07820v1",
      "title": "Mitigating Gender Bias in Code Large Language Models via Model Editing",
      "title_zh": "通过模型编辑减轻代码大语言模型中的性别偏见",
      "authors": [
        "Zhanyue Qin",
        "Haochuan Wang",
        "Zecheng Wang",
        "Deyuan Liu",
        "Cunhang Fan",
        "Zhao Lv",
        "Zhiying Tu",
        "Dianhui Chu",
        "Dianbo Sui"
      ],
      "abstract": "In recent years, with the maturation of large language model (LLM) technology\nand the emergence of high-quality programming code datasets, researchers have\nbecome increasingly confident in addressing the challenges of program synthesis\nautomatically. However, since most of the training samples for LLMs are\nunscreened, it is inevitable that LLMs' performance may not align with\nreal-world scenarios, leading to the presence of social bias. To evaluate and\nquantify the gender bias in code LLMs, we propose a dataset named CodeGenBias\n(Gender Bias in the Code Generation) and an evaluation metric called FB-Score\n(Factual Bias Score) based on the actual gender distribution of correlative\nprofessions. With the help of CodeGenBias and FB-Score, we evaluate and analyze\nthe gender bias in eight mainstream Code LLMs. Previous work has demonstrated\nthat model editing methods that perform well in knowledge editing have the\npotential to mitigate social bias in LLMs. Therefore, we develop a model\nediting approach named MG-Editing (Multi-Granularity model Editing), which\nincludes the locating and editing phases. Our model editing method MG-Editing\ncan be applied at five different levels of model parameter granularity: full\nparameters level, layer level, module level, row level, and neuron level.\nExtensive experiments not only demonstrate that our MG-Editing can effectively\nmitigate the gender bias in code LLMs while maintaining their general code\ngeneration capabilities, but also showcase its excellent generalization. At the\nsame time, the experimental results show that, considering both the gender bias\nof the model and its general code generation capability, MG-Editing is most\neffective when applied at the row and neuron levels of granularity.",
      "tldr_zh": "本论文针对代码大型语言模型（LLMs）中的性别偏见问题，提出了数据集 CodeGenBias 和评估指标 FB-Score，用于量化八个主流代码 LLMs 的性别偏见，并基于实际职业性别分布进行评估。作者开发了 MG-Editing（Multi-Granularity model Editing）方法，包括定位和编辑阶段，可在 full parameters level、layer level、module level、row level 和 neuron level 等五个粒度级别应用，以减轻偏见同时保持模型的代码生成能力。实验结果表明，MG-Editing 不仅有效缓解了性别偏见，还展示了优秀的泛化性能，且在 row level 和 neuron level 级别时效果最佳。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07820v1",
      "published_date": "2024-10-10 11:11:32 UTC",
      "updated_date": "2024-10-10 11:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:50:47.356959"
    },
    {
      "arxiv_id": "2410.07812v2",
      "title": "Temporal-Difference Variational Continual Learning",
      "title_zh": "时间差分变分持续学习",
      "authors": [
        "Luckeciano C. Melo",
        "Alessandro Abate",
        "Yarin Gal"
      ],
      "abstract": "Machine Learning models in real-world applications must continuously learn\nnew tasks to adapt to shifts in the data-generating distribution. Yet, for\nContinual Learning (CL), models often struggle to balance learning new tasks\n(plasticity) with retaining previous knowledge (memory stability).\nConsequently, they are susceptible to Catastrophic Forgetting, which degrades\nperformance and undermines the reliability of deployed systems. In the Bayesian\nCL literature, variational methods tackle this challenge by employing a\nlearning objective that recursively updates the posterior distribution while\nconstraining it to stay close to its previous estimate. Nonetheless, we argue\nthat these methods may be ineffective due to compounding approximation errors\nover successive recursions. To mitigate this, we propose new learning\nobjectives that integrate the regularization effects of multiple previous\nposterior estimations, preventing individual errors from dominating future\nposterior updates and compounding over time. We reveal insightful connections\nbetween these objectives and Temporal-Difference methods, a popular learning\nmechanism in Reinforcement Learning and Neuroscience. Experiments on\nchallenging CL benchmarks show that our approach effectively mitigates\nCatastrophic Forgetting, outperforming strong Variational CL methods.",
      "tldr_zh": "这篇论文针对持续学习（Continual Learning）中的灾难性遗忘（Catastrophic Forgetting）问题，提出了一种新的学习目标，通过整合多个后验估计的正则化效果来防止递归过程中的近似错误积累。作者将这些目标与强化学习和神经科学中的时差方法（Temporal-Difference methods）建立了联系，增强了模型在学习新任务（plasticity）时保留旧知识（memory stability）的能力。实验在挑战性的CL基准上显示，该方法显著优于现有的变分方法（Variational methods），有效提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07812v2",
      "published_date": "2024-10-10 10:58:41 UTC",
      "updated_date": "2025-05-14 18:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:50:58.853116"
    },
    {
      "arxiv_id": "2410.09112v1",
      "title": "HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Qianyue Hao",
        "Jingyang Fan",
        "Fengli Xu",
        "Jian Yuan",
        "Yong Li"
      ],
      "abstract": "Citation networks are critical in modern science, and predicting which\nprevious papers (candidates) will a new paper (query) cite is a critical\nproblem. However, the roles of a paper's citations vary significantly, ranging\nfrom foundational knowledge basis to superficial contexts. Distinguishing these\nroles requires a deeper understanding of the logical relationships among\npapers, beyond simple edges in citation networks. The emergence of LLMs with\ntextual reasoning capabilities offers new possibilities for discerning these\nrelationships, but there are two major challenges. First, in practice, a new\npaper may select its citations from gigantic existing papers, where the texts\nexceed the context length of LLMs. Second, logical relationships between papers\nare implicit, and directly prompting an LLM to predict citations may result in\nsurface-level textual similarities rather than the deeper logical reasoning. In\nthis paper, we introduce the novel concept of core citation, which identifies\nthe critical references that go beyond superficial mentions. Thereby, we\nelevate the citation prediction task from a simple binary classification to\ndistinguishing core citations from both superficial citations and\nnon-citations. To address this, we propose $\\textbf{HLM-Cite}$, a\n$\\textbf{H}$ybrid $\\textbf{L}$anguage $\\textbf{M}$odel workflow for citation\nprediction, which combines embedding and generative LMs. We design a curriculum\nfinetune procedure to adapt a pretrained text embedding model to coarsely\nretrieve high-likelihood core citations from vast candidates and then design an\nLLM agentic workflow to rank the retrieved papers through one-shot reasoning,\nrevealing the implicit relationships among papers. With the pipeline, we can\nscale the candidate sets to 100K papers. We evaluate HLM-Cite across 19\nscientific fields, demonstrating a 17.6% performance improvement comparing SOTA\nmethods.",
      "tldr_zh": "这篇论文针对科学引用预测问题，引入了“core citation”的概念，以区分核心引用与表面引用或非引用，从而超越传统二分类方法。论文提出HLM-Cite，一种混合语言模型工作流，结合课程微调的文本嵌入模型进行粗略检索，以及LLM代理工作流通过one-shot reasoning揭示论文间的隐性逻辑关系，支持处理10万论文候选集。该框架在19个科学领域评估中，比现有最先进方法提升17.6%的性能，为更准确的引用预测提供了新途径。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.DL",
      "comment": "NeurIPS 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2410.09112v1",
      "published_date": "2024-10-10 10:46:06 UTC",
      "updated_date": "2024-10-10 10:46:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:51:54.051314"
    },
    {
      "arxiv_id": "2410.07797v1",
      "title": "Rewriting Conversational Utterances with Instructed Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elnara Galimzhanova",
        "Cristina Ioana Muntean",
        "Franco Maria Nardini",
        "Raffaele Perego",
        "Guido Rocchietti"
      ],
      "abstract": "Many recent studies have shown the ability of large language models (LLMs) to\nachieve state-of-the-art performance on many NLP tasks, such as question\nanswering, text summarization, coding, and translation. In some cases, the\nresults provided by LLMs are on par with those of human experts. These models'\nmost disruptive innovation is their ability to perform tasks via zero-shot or\nfew-shot prompting. This capability has been successfully exploited to train\ninstructed LLMs, where reinforcement learning with human feedback is used to\nguide the model to follow the user's requests directly. In this paper, we\ninvestigate the ability of instructed LLMs to improve conversational search\neffectiveness by rewriting user questions in a conversational setting. We study\nwhich prompts provide the most informative rewritten utterances that lead to\nthe best retrieval performance. Reproducible experiments are conducted on\npublicly-available TREC CAST datasets. The results show that rewriting\nconversational utterances with instructed LLMs achieves significant\nimprovements of up to 25.2% in MRR, 31.7% in Precision@1, 27% in NDCG@3, and\n11.5% in Recall@500 over state-of-the-art techniques.",
      "tldr_zh": "这篇论文探讨了使用指导型大型语言模型 (instructed LLMs) 来改写对话语句，以提升对话搜索的检索效果。研究方法包括通过强化学习与人类反馈训练 LLMs，并测试各种零样本或少样本提示，以生成最优的改写语句。实验在公开的 TREC CAST 数据集上进行，结果显示改写后在 MRR 上提高了 25.2%、Precision@1 上提高了 31.7%、NDCG@3 上提高了 27%、以及 Recall@500 上提高了 11.5%，显著优于现有技术。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07797v1",
      "published_date": "2024-10-10 10:30:28 UTC",
      "updated_date": "2024-10-10 10:30:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:51:22.971153"
    },
    {
      "arxiv_id": "2410.07793v3",
      "title": "Do Current Language Models Support Code Intelligence for R Programming Language?",
      "title_zh": "当前的语言模型是否支持 R 编程语言的代码智能？",
      "authors": [
        "ZiXiao Zhao",
        "Fatemeh H. Fard"
      ],
      "abstract": "Recent advancements in developing Pre-trained Language Models for Code\n(Code-PLMs) have urged many areas of Software Engineering (SE) and brought\nbreakthrough results for many SE tasks. Though these models have achieved the\nstate-of-the-art performance for SE tasks for many popular programming\nlanguages, such as Java and Python, the Scientific Software and its related\nlanguages like R programming language have rarely benefited or even been\nevaluated with the Code-PLMs. Research has shown that R has many differences\nwith other programming languages and requires specific techniques. In this\nstudy, we provide the first insights for code intelligence for R. For this\npurpose, we collect and open source an R dataset, and evaluate Code-PLMs for\nthe two tasks of code summarization and method name prediction using several\nsettings and strategies, including the differences in two R styles, Tidy-verse\nand Base R. Our results demonstrate that the studied models have experienced\nvarying degrees of performance degradation when processing R programming\nlanguage code, which is supported by human evaluation. Additionally, not all\nmodels show performance improvement in R-specific tasks even after\nmulti-language fine-tuning. The dual syntax paradigms in R significantly impact\nthe models' performance, particularly in code summarization tasks. Furthermore,\nthe project-specific context inherent in R codebases significantly impacts the\nperformance when attempting cross-project training.",
      "tldr_zh": "本研究评估了当前代码预训练语言模型（Code-PLMs）在 R 编程语言上的代码智能表现，指出尽管这些模型在 Java 和 Python 等语言中表现出色，但 R 语言的独特特性（如特定技术和双重语法范式）尚未得到充分支持。研究者收集并开源了一个 R 数据集，并针对代码总结和方法名称预测任务进行了多设置评估，包括 Tidy-verse 和 Base R 风格。结果显示，模型在处理 R 代码时性能显著下降，即使进行多语言微调也未能全面改善，且项目特定上下文进一步影响了跨项目训练的成效。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07793v3",
      "published_date": "2024-10-10 10:23:23 UTC",
      "updated_date": "2025-05-15 22:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:51:34.911748"
    },
    {
      "arxiv_id": "2410.07787v2",
      "title": "Mastering Contact-rich Tasks by Combining Soft and Rigid Robotics with Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mariano Ramírez Montero",
        "Ebrahim Shahabi",
        "Giovanni Franzese",
        "Jens Kober",
        "Barbara Mazzolai",
        "Cosimo Della Santina"
      ],
      "abstract": "Soft robots have the potential to revolutionize the use of robotic systems\nwith their capability of establishing safe, robust, and adaptable interactions\nwith their environment, but their precise control remains challenging. In\ncontrast, traditional rigid robots offer high accuracy and repeatability but\nlack the flexibility of soft robots. We argue that combining these\ncharacteristics in a hybrid robotic platform can significantly enhance overall\ncapabilities. This work presents a novel hybrid robotic platform that\nintegrates a rigid manipulator with a fully developed soft arm. This system is\nequipped with the intelligence necessary to perform flexible and generalizable\ntasks through imitation learning autonomously. The physical softness and\nmachine learning enable our platform to achieve highly generalizable skills,\nwhile the rigid components ensure precision and repeatability.",
      "tldr_zh": "本文提出了一种新型混合机器人平台，将软机器人和刚性机器人相结合，以解决软机器人控制精度不足和刚性机器人灵活性欠缺的问题。该平台整合了刚性机械臂和完全开发的软臂，并通过imitation learning实现自主执行灵活且可泛化的接触丰富任务。实验结果表明，这种设计利用软臂的物理柔性和机器学习的优势，加上刚性部件的精度和重复性，显著提升了机器人的整体性能和泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Corrected missing citation",
      "pdf_url": "http://arxiv.org/pdf/2410.07787v2",
      "published_date": "2024-10-10 10:18:03 UTC",
      "updated_date": "2024-10-11 11:41:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:51:46.317548"
    },
    {
      "arxiv_id": "2410.07771v1",
      "title": "Full-Rank No More: Low-Rank Weight Training for Modern Speech Recognition Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adriana Fernandez-Lopez",
        "Shiwei Liu",
        "Lu Yin",
        "Stavros Petridis",
        "Maja Pantic"
      ],
      "abstract": "This paper investigates the under-explored area of low-rank weight training\nfor large-scale Conformer-based speech recognition models from scratch. Our\nstudy demonstrates the viability of this training paradigm for such models,\nyielding several notable findings. Firstly, we discover that applying a\nlow-rank structure exclusively to the attention modules can unexpectedly\nenhance performance, even with a significant rank reduction of 12%. In\ncontrast, feed-forward layers present greater challenges, as they begin to\nexhibit performance degradation with a moderate 50% rank reduction.\nFurthermore, we find that both initialization and layer-wise rank assignment\nplay critical roles in successful low-rank training. Specifically, employing\nSVD initialization and linear layer-wise rank mapping significantly boosts the\nefficacy of low-rank weight training. Building on these insights, we introduce\nthe Low-Rank Speech Model from Scratch (LR-SMS), an approach that achieves\nperformance parity with full-rank training while delivering substantial\nreductions in parameters count (by at least 2x), and training time speedups (by\n1.3x for ASR and 1.15x for AVSR).",
      "tldr_zh": "这篇论文探讨了从零开始对大型 Conformer-based 语音识别模型应用 low-rank weight training 的可行性。研究发现，仅对注意力模块施加低秩结构（如减少 12% 秩）可意外提升性能，而前馈层在 50% 秩减少时则会出现性能下降；此外，SVD initialization 和线性层级秩分配是成功训练的关键因素。最终，他们提出了 Low-Rank Speech Model from Scratch (LR-SMS) 方法，实现与全秩训练相当的性能，同时减少至少 2 倍参数数量，并加速训练时间（ASR 提速 1.3 倍，AVSR 提速 1.15 倍）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.07771v1",
      "published_date": "2024-10-10 09:58:35 UTC",
      "updated_date": "2024-10-10 09:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:52:15.536046"
    },
    {
      "arxiv_id": "2410.07765v1",
      "title": "GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps",
      "title_zh": "GameTraversalBenchmark：通过遍历 2D 游戏地图评估大语言模型的规划能力",
      "authors": [
        "Muhammad Umair Nasir",
        "Steven James",
        "Julian Togelius"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated great success in\ngenerating and understanding natural language. While they have also shown\npotential beyond the domain of natural language, it remains an open question as\nto what extent and in which way these LLMs can plan. We investigate their\nplanning capabilities by proposing GameTraversalBenchmark (GTB), a benchmark\nconsisting of diverse 2D grid-based game maps. An LLM succeeds if it can\ntraverse through given objectives, with a minimum number of steps and a minimum\nnumber of generation errors. We evaluate a number of LLMs on GTB and found that\nGPT-4-Turbo achieved the highest score of 44.97% on GTB\\_Score (GTBS), a\ncomposite score that combines the three above criteria. Furthermore, we\npreliminarily test large reasoning models, namely o1, which scores $67.84\\%$ on\nGTBS, indicating that the benchmark remains challenging for current models.\nCode, data, and documentation are available at\nhttps://github.com/umair-nasir14/Game-Traversal-Benchmark.",
      "tldr_zh": "该论文提出GameTraversalBenchmark (GTB)，一个由多样化的2D网格-based游戏地图组成的基准，用于评估Large Language Models (LLMs)的规划能力。LLMs需要在最小步骤和最小生成错误的情况下遍历给定目标，以实现成功。实验结果显示，GPT-4-Turbo在GTB_Score (GTBS)上得分最高为44.97%，而大型推理模型o1达到了67.84%，表明该基准对当前模型仍具挑战性，并为进一步研究LLMs的规划能力提供了新工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 38th Conference on Neural Information Processing Systems\n  (NeurIPS 2024) Track on Datasets and Benchmarks",
      "pdf_url": "http://arxiv.org/pdf/2410.07765v1",
      "published_date": "2024-10-10 09:54:28 UTC",
      "updated_date": "2024-10-10 09:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:52:17.892234"
    },
    {
      "arxiv_id": "2410.12848v1",
      "title": "Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Per Niklas Waaler",
        "Musarrat Hussain",
        "Igor Molchanov",
        "Lars Ailo Bongo",
        "Brita Elvevåg"
      ],
      "abstract": "Patients with schizophrenia often present with cognitive impairments that may\nhinder their ability to learn about their condition. These individuals could\nbenefit greatly from education platforms that leverage the adaptability of\nLarge Language Models (LLMs) such as GPT-4. While LLMs have the potential to\nmake topical mental health information more accessible and engaging, their\nblack-box nature raises concerns about ethics and safety. Prompting offers a\nway to produce semi-scripted chatbots with responses anchored in instructions\nand validated information, but prompt-engineered chatbots may drift from their\nintended identity as the conversation progresses. We propose a Critical\nAnalysis Filter for achieving better control over chatbot behavior. In this\nsystem, a team of prompted LLM agents are prompt-engineered to critically\nanalyze and refine the chatbot's response and deliver real-time feedback to the\nchatbot. To test this approach, we develop an informational schizophrenia\nchatbot and converse with it (with the filter deactivated) until it oversteps\nits scope. Once drift has been observed, AI-agents are used to automatically\ngenerate sample conversations in which the chatbot is being enticed to talk\nabout out-of-bounds topics. We manually assign to each response a compliance\nscore that quantifies the chatbot's compliance to its instructions;\nspecifically the rules about accurately conveying sources and being transparent\nabout limitations. Activating the Critical Analysis Filter resulted in an\nacceptable compliance score (>=2) in 67.0% of responses, compared to only 8.7%\nwhen the filter was deactivated. These results suggest that a self-reflection\nlayer could enable LLMs to be used effectively and safely in mental health\nplatforms, maintaining adaptability while reliably limiting their scope to\nappropriate use cases.",
      "tldr_zh": "这篇论文提出了一种多智能体方法，用于提升精神分裂症聊天机器人的提示工程（Prompt Engineering），以解决Large Language Models (LLMs) 在心理健康教育中的伦理和安全问题。具体而言，他们设计了Critical Analysis Filter系统，由多个LLM代理组成，对聊天机器人的响应进行实时分析和优化，确保遵守指令并保持透明。实验结果显示，在激活该过滤器后，机器人的响应遵守率（compliance score >=2）从8.7% 提高到67.0%，证明这种自反层（self-reflection layer）能有效限制LLMs 的范围，使其更安全可靠地应用于精神健康平台。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12848v1",
      "published_date": "2024-10-10 09:49:24 UTC",
      "updated_date": "2024-10-10 09:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:52:29.371211"
    },
    {
      "arxiv_id": "2410.07763v1",
      "title": "HARIVO: Harnessing Text-to-Image Models for Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mingi Kwon",
        "Seoung Wug Oh",
        "Yang Zhou",
        "Difan Liu",
        "Joon-Young Lee",
        "Haoran Cai",
        "Baqiao Liu",
        "Feng Liu",
        "Youngjung Uh"
      ],
      "abstract": "We present a method to create diffusion-based video models from pretrained\nText-to-Image (T2I) models. Recently, AnimateDiff proposed freezing the T2I\nmodel while only training temporal layers. We advance this method by proposing\na unique architecture, incorporating a mapping network and frame-wise tokens,\ntailored for video generation while maintaining the diversity and creativity of\nthe original T2I model. Key innovations include novel loss functions for\ntemporal smoothness and a mitigating gradient sampling technique, ensuring\nrealistic and temporally consistent video generation despite limited public\nvideo data. We have successfully integrated video-specific inductive biases\ninto the architecture and loss functions. Our method, built on the frozen\nStableDiffusion model, simplifies training processes and allows for seamless\nintegration with off-the-shelf models like ControlNet and DreamBooth. project\npage: https://kwonminki.github.io/HARIVO",
      "tldr_zh": "本研究提出HARIVO方法，利用预训练的Text-to-Image (T2I)模型构建基于扩散的视频生成模型，改进AnimateDiff框架，通过冻结T2I模型并仅训练时间层来保持原模型的多样性和创造力。  \n关键创新包括引入mapping network和frame-wise tokens的独特架构，以及新型损失函数（如temporal smoothness损失）和梯度采样技术，以确保视频生成在有限公共数据下实现真实性和时间一致性。  \n该方法整合了视频特定的归纳偏差，基于冻结的StableDiffusion模型简化训练过程，并支持与ControlNet和DreamBooth等现成模型的无缝集成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07763v1",
      "published_date": "2024-10-10 09:47:39 UTC",
      "updated_date": "2024-10-10 09:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:52:41.784867"
    },
    {
      "arxiv_id": "2410.07761v1",
      "title": "$\\textit{Jump Your Steps}$: Optimizing Sampling Schedule of Discrete Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yong-Hyun Park",
        "Chieh-Hsin Lai",
        "Satoshi Hayakawa",
        "Yuhta Takida",
        "Yuki Mitsufuji"
      ],
      "abstract": "Diffusion models have seen notable success in continuous domains, leading to\nthe development of discrete diffusion models (DDMs) for discrete variables.\nDespite recent advances, DDMs face the challenge of slow sampling speeds. While\nparallel sampling methods like $\\tau$-leaping accelerate this process, they\nintroduce $\\textit{Compounding Decoding Error}$ (CDE), where discrepancies\narise between the true distribution and the approximation from parallel token\ngeneration, leading to degraded sample quality. In this work, we present\n$\\textit{Jump Your Steps}$ (JYS), a novel approach that optimizes the\nallocation of discrete sampling timesteps by minimizing CDE without extra\ncomputational cost. More precisely, we derive a practical upper bound on CDE\nand propose an efficient algorithm for searching for the optimal sampling\nschedule. Extensive experiments across image, music, and text generation show\nthat JYS significantly improves sampling quality, establishing it as a\nversatile framework for enhancing DDM performance for fast sampling.",
      "tldr_zh": "本研究针对离散扩散模型(DDMs)的慢速采样问题，提出了$\\textit{Jump Your Steps}$ (JYS)方法，以最小化$\\textit{Compounding Decoding Error}$ (CDE)，后者是并行采样技术如τ-leaping导致的样本质量下降问题。JYS通过推导CDE的实用上界并设计一个高效搜索算法，优化采样时间步的分配，而无需额外计算成本。在图像、音乐和文本生成任务上的广泛实验显示，JYS显著提高了采样质量，并将其确立为一个通用的框架，用于提升DDMs的快速采样性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07761v1",
      "published_date": "2024-10-10 09:44:25 UTC",
      "updated_date": "2024-10-10 09:44:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:52:53.417698"
    },
    {
      "arxiv_id": "2410.08245v2",
      "title": "Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts",
      "title_zh": "Flex-MoE：通过灵活的混合专家模型建",
      "authors": [
        "Sukwon Yun",
        "Inyoung Choi",
        "Jie Peng",
        "Yangfan Wu",
        "Jingxuan Bao",
        "Qiyiwen Zhang",
        "Jiayi Xin",
        "Qi Long",
        "Tianlong Chen"
      ],
      "abstract": "Multimodal learning has gained increasing importance across various fields,\noffering the ability to integrate data from diverse sources such as images,\ntext, and personalized records, which are frequently observed in medical\ndomains. However, in scenarios where some modalities are missing, many existing\nframeworks struggle to accommodate arbitrary modality combinations, often\nrelying heavily on a single modality or complete data. This oversight of\npotential modality combinations limits their applicability in real-world\nsituations. To address this challenge, we propose Flex-MoE (Flexible\nMixture-of-Experts), a new framework designed to flexibly incorporate arbitrary\nmodality combinations while maintaining robustness to missing data. The core\nidea of Flex-MoE is to first address missing modalities using a new missing\nmodality bank that integrates observed modality combinations with the\ncorresponding missing ones. This is followed by a uniquely designed Sparse MoE\nframework. Specifically, Flex-MoE first trains experts using samples with all\nmodalities to inject generalized knowledge through the generalized router\n($\\mathcal{G}$-Router). The $\\mathcal{S}$-Router then specializes in handling\nfewer modality combinations by assigning the top-1 gate to the expert\ncorresponding to the observed modality combination. We evaluate Flex-MoE on the\nADNI dataset, which encompasses four modalities in the Alzheimer's Disease\ndomain, as well as on the MIMIC-IV dataset. The results demonstrate the\neffectiveness of Flex-MoE highlighting its ability to model arbitrary modality\ncombinations in diverse missing modality scenarios. Code is available at\nhttps://github.com/UNITES-Lab/flex-moe.",
      "tldr_zh": "本文研究了多模态学习在处理模态缺失时的挑战，现有框架往往无法灵活适应任意模态组合。作者提出 Flex-MoE 框架，通过 missing modality bank 整合观察到的和缺失的模态，并结合 Sparse MoE 结构，利用 generalized router (G-Router) 注入一般知识，以及 specialized router (S-Router) 针对特定模态组合分配专家。实验在 ADNI 和 MIMIC-IV 数据集上显示，Flex-MoE 有效提升了模型对多样缺失场景的鲁棒性和性能，为实际应用提供了新方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.08245v2",
      "published_date": "2024-10-10 09:37:21 UTC",
      "updated_date": "2024-10-31 10:44:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:53:04.911845"
    },
    {
      "arxiv_id": "2410.08244v2",
      "title": "RAB$^2$-DEF: Dynamic and explainable defense against adversarial attacks in Federated Learning to fair poor clients",
      "title_zh": "翻译失败",
      "authors": [
        "Nuria Rodríguez-Barroso",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "abstract": "At the same time that artificial intelligence is becoming popular, concern\nand the need for regulation is growing, including among other requirements the\ndata privacy. In this context, Federated Learning is proposed as a solution to\ndata privacy concerns derived from different source data scenarios due to its\ndistributed learning. The defense mechanisms proposed in literature are just\nfocused on defending against adversarial attacks and the performance, leaving\naside other important qualities such as explainability, fairness to poor\nquality clients, dynamism in terms of attacks configuration and generality in\nterms of being resilient against different kinds of attacks. In this work, we\npropose RAB$^2$-DEF, a $\\textbf{r}$esilient $\\textbf{a}$gainst\n$\\textbf{b}\\text{yzantine}$ and $\\textbf{b}$ackdoor attacks which is\n$\\textbf{d}$ynamic, $\\textbf{e}$xplainable and $\\textbf{f}$air to poor clients\nusing local linear explanations. We test the performance of RAB$^2$-DEF in\nimage datasets and both byzantine and backdoor attacks considering the\nstate-of-the-art defenses and achieve that RAB$^2$-DEF is a proper defense at\nthe same time that it boosts the other qualities towards trustworthy artificial\nintelligence.",
      "tldr_zh": "本文提出RAB²-DEF，这是一个动态且可解释的防御框架，用于Federated Learning中对抗Byzantine attacks和backdoor attacks，同时确保对低质量客户端的公平性。该框架利用本地线性解释来增强弹性、解释性和动态调整能力，解决了现有防御机制的局限性，如忽略公平性和泛化性。在图像数据集上的实验表明，RAB²-DEF比现有方法表现出色，不仅提高了防御性能，还提升了可信赖人工智能的整体品质。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08244v2",
      "published_date": "2024-10-10 09:32:59 UTC",
      "updated_date": "2025-04-16 07:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:53:17.357835"
    },
    {
      "arxiv_id": "2410.07751v2",
      "title": "Learning Low-Level Causal Relations using a Simulated Robotic Arm",
      "title_zh": "翻译失败",
      "authors": [
        "Miroslav Cibula",
        "Matthias Kerzel",
        "Igor Farkaš"
      ],
      "abstract": "Causal learning allows humans to predict the effect of their actions on the\nknown environment and use this knowledge to plan the execution of more complex\nactions. Such knowledge also captures the behaviour of the environment and can\nbe used for its analysis and the reasoning behind the behaviour. This type of\nknowledge is also crucial in the design of intelligent robotic systems with\ncommon sense. In this paper, we study causal relations by learning the forward\nand inverse models based on data generated by a simulated robotic arm involved\nin two sensorimotor tasks. As a next step, we investigate feature attribution\nmethods for the analysis of the forward model, which reveals the low-level\ncausal effects corresponding to individual features of the state vector related\nto both the arm joints and the environment features. This type of analysis\nprovides solid ground for dimensionality reduction of the state\nrepresentations, as well as for the aggregation of knowledge towards the\nexplainability of causal effects at higher levels.",
      "tldr_zh": "本研究探讨了使用模拟机器人臂学习低级因果关系，以帮助智能机器人系统预测行动效果并提升环境行为分析。研究基于两个传感器运动任务生成数据，学习前向模型和逆向模型，并应用feature attribution方法分析模型，揭示与臂关节和环境特征相关的因果效果。这种方法为状态表示的维度减少和向更高水平因果知识的聚合提供了基础，从而增强系统的可解释性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "14 pages, 5 figures, 3 tables. Appeared in 2024 International\n  Conference on Artificial Neural Networks (ICANN) proceedings. Published\n  version copyrighted by Springer. This work was funded by the Horizon Europe\n  Twinning project TERAIS, G.A. number 101079338 and in part by the Slovak\n  Grant Agency for Science (VEGA), project 1/0373/23. The code can be found at\n  https://doi.org/10.5281/zenodo.14550231",
      "pdf_url": "http://arxiv.org/pdf/2410.07751v2",
      "published_date": "2024-10-10 09:28:30 UTC",
      "updated_date": "2024-12-24 21:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:53:29.114520"
    },
    {
      "arxiv_id": "2410.07738v1",
      "title": "Enhancing Federated Domain Adaptation with Multi-Domain Prototype-Based Federated Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyuan Zhang",
        "Yiyang Duan",
        "Shuaicheng Niu",
        "Yang Cao",
        "Wei Yang Bryan Lim"
      ],
      "abstract": "Federated Domain Adaptation (FDA) is a Federated Learning (FL) scenario where\nmodels are trained across multiple clients with unique data domains but a\nshared category space, without transmitting private data. The primary challenge\nin FDA is data heterogeneity, which causes significant divergences in gradient\nupdates when using conventional averaging-based aggregation methods, reducing\nthe efficacy of the global model. This further undermines both in-domain and\nout-of-domain performance (within the same federated system but outside the\nlocal client). To address this, we propose a novel framework called\n\\textbf{M}ulti-domain \\textbf{P}rototype-based \\textbf{F}ederated\nFine-\\textbf{T}uning (MPFT). MPFT fine-tunes a pre-trained model using\nmulti-domain prototypes, i.e., pretrained representations enriched with\ndomain-specific information from category-specific local data. This enables\nsupervised learning on the server to derive a globally optimized adapter that\nis subsequently distributed to local clients, without the intrusion of data\nprivacy. Empirical results show that MPFT significantly improves both in-domain\nand out-of-domain accuracy over conventional methods, enhancing knowledge\npreservation and adaptation in FDA. Notably, MPFT achieves convergence within a\nsingle communication round, greatly reducing computation and communication\ncosts. To ensure privacy, MPFT applies differential privacy to protect the\nprototypes. Additionally, we develop a prototype-based feature space hijacking\nattack to evaluate robustness, confirming that raw data samples remain\nunrecoverable even after extensive training epochs. The complete implementation\nof MPFL is available at \\url{https://anonymous.4open.science/r/DomainFL/}.",
      "tldr_zh": "本研究针对Federated Domain Adaptation (FDA)中的数据异质性问题，提出了一种新型框架Multi-domain Prototype-based Federated Fine-Tuning (MPFT)。MPFT利用多域原型（基于预训练表示并融入域特定信息）在服务器端进行监督微调，生成全局优化的适配器，并分发至客户端，从而避免了数据隐私泄露。实验结果显示，MPFT显著提升了领域内和领域外准确率，并在单轮通信中实现收敛，大大降低了计算和通信成本。同时，通过应用差分隐私保护原型，并开发原型-based特征空间劫持攻击，验证了框架的鲁棒性和隐私安全性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07738v1",
      "published_date": "2024-10-10 09:15:56 UTC",
      "updated_date": "2024-10-10 09:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:53:41.168730"
    },
    {
      "arxiv_id": "2410.09111v1",
      "title": "IceDiff: High Resolution and High-Quality Sea Ice Forecasting with Generative Diffusion Prior",
      "title_zh": "IceDiff:",
      "authors": [
        "Jingyi Xu",
        "Siwei Tu",
        "Weidong Yang",
        "Shuhao Li",
        "Keyi Liu",
        "Yeqi Luo",
        "Lipeng Ma",
        "Ben Fei",
        "Lei Bai"
      ],
      "abstract": "Variation of Arctic sea ice has significant impacts on polar ecosystems,\ntransporting routes, coastal communities, and global climate. Tracing the\nchange of sea ice at a finer scale is paramount for both operational\napplications and scientific studies. Recent pan-Arctic sea ice forecasting\nmethods that leverage advances in artificial intelligence has made promising\nprogress over numerical models. However, forecasting sea ice at higher\nresolutions is still under-explored. To bridge the gap, we propose a two-staged\ndeep learning framework, IceDiff, to forecast sea ice concentration at finer\nscales. IceDiff first leverages an independently trained vision transformer to\ngenerate coarse yet superior forecasting over previous methods at a regular\n25km x 25km grid. This high-quality sea ice forecasting can be utilized as\nreliable guidance for the next stage. Subsequently, an unconditional diffusion\nmodel pre-trained on sea ice concentration maps is utilized for sampling\ndown-scaled sea ice forecasting via a zero-shot guided sampling strategy and a\npatch-based method. For the first time, IceDiff demonstrates sea ice\nforecasting with the 6.25km x 6.25km resolution. IceDiff extends the boundary\nof existing sea ice forecasting models and more importantly, its capability to\ngenerate high-resolution sea ice concentration data is vital for pragmatic\nusages and research.",
      "tldr_zh": "这篇论文提出 IceDiff 框架，一种两阶段深度学习方法，用于实现高分辨率和高品质的北极海冰浓度预测，以应对海冰变化对生态、交通和气候的影响。第一阶段利用 vision transformer 生成 25km x 25km 网格的粗略但高质量预测，作为后续指导；第二阶段则通过预训练的无条件 diffusion model 结合 zero-shot guided sampling 和 patch-based method，首次实现 6.25km x 6.25km 分辨率的精确海冰预测。IceDiff 超越了现有模型的边界，为实际应用和科学研究提供了更可靠的高分辨率海冰数据。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "9 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09111v1",
      "published_date": "2024-10-10 08:53:41 UTC",
      "updated_date": "2024-10-10 08:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:53:53.431946"
    },
    {
      "arxiv_id": "2410.07717v1",
      "title": "On the Generalization Properties of Deep Learning for Aircraft Fuel Flow Estimation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Jarry",
        "Ramon Dalmau",
        "Philippe Very",
        "Junzi Sun"
      ],
      "abstract": "Accurately estimating aircraft fuel flow is essential for evaluating new\nprocedures, designing next-generation aircraft, and monitoring the\nenvironmental impact of current aviation practices. This paper investigates the\ngeneralization capabilities of deep learning models in predicting fuel\nconsumption, focusing particularly on their performance for aircraft types\nabsent from the training data. We propose a novel methodology that integrates\nneural network architectures with domain generalization techniques to enhance\nrobustness and reliability across a wide range of aircraft. A comprehensive\ndataset containing 101 different aircraft types, separated into training and\ngeneralization sets, with each aircraft type set containing 1,000 flights. We\nemployed the base of aircraft data (BADA) model for fuel flow estimates,\nintroduced a pseudo-distance metric to assess aircraft type similarity, and\nexplored various sampling strategies to optimize model performance in\ndata-sparse regions. Our results reveal that for previously unseen aircraft\ntypes, the introduction of noise into aircraft and engine parameters improved\nmodel generalization. The model is able to generalize with acceptable mean\nabsolute percentage error between 2\\% and 10\\% for aircraft close to existing\naircraft, while performance is below 1\\% error for known aircraft in the\ntraining set. This study highlights the potential of combining domain-specific\ninsights with advanced machine learning techniques to develop scalable,\naccurate, and generalizable fuel flow estimation models.",
      "tldr_zh": "这篇论文探讨了深度学习模型在估计飞机燃油流量时的泛化性能，特别是对训练数据中未包含的飞机类型，旨在提升模型的鲁棒性和可靠性，以支持航空程序评估、飞机设计和环境监测。研究提出了一种新方法，将神经网络架构与领域泛化技术相结合，使用BADA模型、伪距离度量和各种采样策略来优化数据稀缺区域的表现，并通过引入噪声到飞机和引擎参数中改善泛化能力。实验基于一个包含101种飞机类型的数据集，结果显示模型对已知飞机的平均绝对百分比错误低于1%，而对相似未见飞机的错误在2%到10%之间。该研究强调了整合领域特定洞见与高级机器学习技术的潜力，以开发可扩展、准确的燃油流量估计模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07717v1",
      "published_date": "2024-10-10 08:34:19 UTC",
      "updated_date": "2024-10-10 08:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:54:07.842840"
    },
    {
      "arxiv_id": "2410.19744v1",
      "title": "Towards Next-Generation LLM-based Recommender Systems: A Survey and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Wang",
        "Jindong Li",
        "Shiqi Wang",
        "Qianli Xing",
        "Runliang Niu",
        "He Kong",
        "Rui Li",
        "Guodong Long",
        "Yi Chang",
        "Chengqi Zhang"
      ],
      "abstract": "Large language models (LLMs) have not only revolutionized the field of\nnatural language processing (NLP) but also have the potential to bring a\nparadigm shift in many other fields due to their remarkable abilities of\nlanguage understanding, as well as impressive generalization capabilities and\nreasoning skills. As a result, recent studies have actively attempted to\nharness the power of LLMs to improve recommender systems, and it is imperative\nto thoroughly review the recent advances and challenges of LLM-based\nrecommender systems. Unlike existing work, this survey does not merely analyze\nthe classifications of LLM-based recommendation systems according to the\ntechnical framework of LLMs. Instead, it investigates how LLMs can better serve\nrecommendation tasks from the perspective of the recommender system community,\nthus enhancing the integration of large language models into the research of\nrecommender system and its practical application. In addition, the\nlong-standing gap between academic research and industrial applications related\nto recommender systems has not been well discussed, especially in the era of\nlarge language models. In this review, we introduce a novel taxonomy that\noriginates from the intrinsic essence of recommendation, delving into the\napplication of large language model-based recommendation systems and their\nindustrial implementation. Specifically, we propose a three-tier structure that\nmore accurately reflects the developmental progression of recommendation\nsystems from research to practical implementation, including representing and\nunderstanding, scheming and utilizing, and industrial deployment. Furthermore,\nwe discuss critical challenges and opportunities in this emerging field. A more\nup-to-date version of the papers is maintained at:\nhttps://github.com/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）在推荐系统中的应用潜力，旨在推动下一代推荐系统的范式转变，通过分析LLMs的语言理解和推理能力来提升推荐性能。论文从推荐系统社区视角提出一个新的三层结构——representing and understanding（表示和理解）、scheming and utilizing（规划和利用）、以及industrial deployment（工业部署），以更好地整合LLMs从学术研究到实际应用的进程。最终，它审查了现有进展、关键挑战（如学术与工业差距）和未来机会，并维护了一个动态更新的论文列表（https://github.com/jindongli-Ai/Next-Generation-LLM-based-Recommender-Systems-Survey）。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19744v1",
      "published_date": "2024-10-10 08:22:04 UTC",
      "updated_date": "2024-10-10 08:22:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:54:17.191922"
    },
    {
      "arxiv_id": "2410.07708v2",
      "title": "Learning Tree Pattern Transformations",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Neider",
        "Leif Sabellek",
        "Johannes Schmidt",
        "Fabian Vehlken",
        "Thomas Zeume"
      ],
      "abstract": "Explaining why and how a tree $t$ structurally differs from another tree\n$t^\\star$ is a question that is encountered throughout computer science,\nincluding in understanding tree-structured data such as XML or JSON data. In\nthis article, we explore how to learn explanations for structural differences\nbetween pairs of trees from sample data: suppose we are given a set $\\{(t_1,\nt_1^\\star),\\dots, (t_n, t_n^\\star)\\}$ of pairs of labelled, ordered trees; is\nthere a small set of rules that explains the structural differences between all\npairs $(t_i, t_i^\\star)$? This raises two research questions: (i) what is a\ngood notion of \"rule\" in this context?; and (ii) how can sets of rules\nexplaining a data set be learned algorithmically?\n  We explore these questions from the perspective of database theory by (1)\nintroducing a pattern-based specification language for tree transformations;\n(2) exploring the computational complexity of variants of the above algorithmic\nproblem, e.g. showing NP-hardness for very restricted variants; and (3)\ndiscussing how to solve the problem for data from CS education research using\nSAT solvers.",
      "tldr_zh": "该论文探讨了从样本数据中学习规则，以解释树结构差异，例如在 XML 或 JSON 等树状数据中。研究者引入了一种基于模式的树 transformations 规范语言，用于描述树对 $(t_i, t_i^\\star)$ 的结构变化。论文分析了相关算法问题的计算复杂性，发现某些变体是 NP-hard，并讨论了使用 SAT solvers 来解决实际问题，如 CS 教育研究中的数据处理。总体上，这为自动化解释树模式变换提供了理论基础和可行方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Full version of the ICDT 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2410.07708v2",
      "published_date": "2024-10-10 08:20:57 UTC",
      "updated_date": "2025-02-18 15:41:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:54:28.310752"
    },
    {
      "arxiv_id": "2410.07706v1",
      "title": "AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Song",
        "Weimin Xiong",
        "Xiutian Zhao",
        "Dawei Zhu",
        "Wenhao Wu",
        "Ke Wang",
        "Cheng Li",
        "Wei Peng",
        "Sujian Li"
      ],
      "abstract": "Fine-tuning on agent-environment interaction trajectory data holds\nsignificant promise for surfacing generalized agent capabilities in open-source\nlarge language models (LLMs). In this work, we introduce AgentBank, by far the\nlargest trajectory tuning data collection featuring more than 50k diverse\nhigh-quality interaction trajectories which comprises 16 tasks covering five\ndistinct agent skill dimensions. Leveraging a novel annotation pipeline, we are\nable to scale the annotated trajectories and generate a trajectory dataset with\nminimized difficulty bias. Furthermore, we fine-tune LLMs on AgentBank to get a\nseries of agent models, Samoyed. Our comparative experiments demonstrate the\neffectiveness of scaling the interaction trajectory data to acquire generalized\nagent capabilities. Additional studies also reveal some key observations\nregarding trajectory tuning and agent skill generalization.",
      "tldr_zh": "本研究引入了 AgentBank，这是一个规模最大的数据集，包含超过 50k 个多样化高质量交互轨迹，涵盖 16 个任务和五个代理技能维度，通过新型标注管道减少难度偏差，以提升开源 LLM 的泛化代理能力。研究者利用 AgentBank 对 LLM 进行 fine-tuning，开发出 Samoyed 系列代理模型。实验结果表明，这种基于轨迹调优的方法显著提高了代理的泛化能力，并揭示了关于轨迹调优和代理技能泛化的关键观察。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07706v1",
      "published_date": "2024-10-10 08:19:12 UTC",
      "updated_date": "2024-10-10 08:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:54:41.106283"
    },
    {
      "arxiv_id": "2410.08243v1",
      "title": "Self-Attention Mechanism in Multimodal Context for Banking Transaction Flow",
      "title_zh": "银行交易流程的多模态上下文中的自注意力机制",
      "authors": [
        "Cyrile Delestre",
        "Yoann Sola"
      ],
      "abstract": "Banking Transaction Flow (BTF) is a sequential data found in a number of\nbanking activities such as marketing, credit risk or banking fraud. It is a\nmultimodal data composed of three modalities: a date, a numerical value and a\nwording. We propose in this work an application of self-attention mechanism to\nthe processing of BTFs. We trained two general models on a large amount of BTFs\nin a self-supervised way: one RNN-based model and one Transformer-based model.\nWe proposed a specific tokenization in order to be able to process BTFs. The\nperformance of these two models was evaluated on two banking downstream tasks:\na transaction categorization task and a credit risk task. The results show that\nfine-tuning these two pre-trained models allowed to perform better than the\nstate-of-the-art approaches for both tasks.",
      "tldr_zh": "这篇论文探讨了自注意力机制(Self-Attention Mechanism)在多模态银行交易流程(Banking Transaction Flow, BTF)中的应用，BTF是一种由日期、数值和文字组成的顺序数据，常用于银行营销、信用风险或欺诈检测。研究者提出了一种特定标记化(tokenization)方法，并训练了两个自监督模型：一个基于 RNN 的模型和一个基于 Transformer 的模型。实验结果显示，在交易分类任务和信用风险任务上，微调这些预训练模型的表现优于现有最先进(state-of-the-art)方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08243v1",
      "published_date": "2024-10-10 08:13:39 UTC",
      "updated_date": "2024-10-10 08:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:54:52.770694"
    },
    {
      "arxiv_id": "2410.12847v2",
      "title": "ACCEPT: Adaptive Codebook for Composite and Efficient Prompt Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Chen Lin",
        "Wei-Hua Li",
        "Jun-Cheng Chen",
        "Chu-Song Chen"
      ],
      "abstract": "Prompt Tuning has been a popular Parameter-Efficient Fine-Tuning method\nattributed to its remarkable performance with few updated parameters on various\nlarge-scale pretrained Language Models (PLMs). Traditionally, each prompt has\nbeen considered indivisible and updated independently, leading the parameters\nincrease proportionally as prompt length grows. To address this issue, we\npropose Adaptive Codebook for Composite and Efficient Prompt Tuning (ACCEPT).\nIn our method, we refer to the concept of product quantization (PQ), allowing\nall soft prompts to share a set of learnable codebook vectors in each subspace,\nwith each prompt differentiated by a set of adaptive weights. We achieve the\nsuperior performance on 17 diverse natural language tasks including natural\nlanguage understanding (NLU) and question answering (QA) tasks by tuning only\n0.3% of parameters of the PLMs. Our approach also excels in few-shot and large\nmodel settings, highlighting its significant potential.",
      "tldr_zh": "本文提出 ACCEPT 方法，这是一种基于产品量化（PQ）的自适应代码书（Adaptive Codebook）技术，用于优化 Prompt Tuning 的参数效率问题。ACCEPT 允许所有软提示共享一组可学习的 codebook vectors，并在每个子空间通过自适应 weights 进行区分，从而减少参数更新量，仅需调整预训练语言模型（PLMs）的 0.3%。实验结果显示，该方法在 17 个多样化自然语言任务上，包括自然语言理解（NLU）和问答（QA），取得了优越性能，并在少样本和大型模型场景中表现出显著潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.12847v2",
      "published_date": "2024-10-10 07:48:53 UTC",
      "updated_date": "2024-10-18 02:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:55:05.241758"
    },
    {
      "arxiv_id": "2410.07675v1",
      "title": "Adversarial Robustness Overestimation and Instability in TRADES",
      "title_zh": "TRADES 中的对抗鲁棒性过度估计与不稳定性",
      "authors": [
        "Jonathan Weiping Li",
        "Ren-Wei Liang",
        "Cheng-Han Yeh",
        "Cheng-Chang Tsai",
        "Kuanchun Yu",
        "Chun-Shien Lu",
        "Shang-Tse Chen"
      ],
      "abstract": "This paper examines the phenomenon of probabilistic robustness overestimation\nin TRADES, a prominent adversarial training method. Our study reveals that\nTRADES sometimes yields disproportionately high PGD validation accuracy\ncompared to the AutoAttack testing accuracy in the multiclass classification\ntask. This discrepancy highlights a significant overestimation of robustness\nfor these instances, potentially linked to gradient masking. We further analyze\nthe parameters contributing to unstable models that lead to overestimation. Our\nfindings indicate that smaller batch sizes, lower beta values (which control\nthe weight of the robust loss term in TRADES), larger learning rates, and\nhigher class complexity (e.g., CIFAR-100 versus CIFAR-10) are associated with\nan increased likelihood of robustness overestimation. By examining metrics such\nas the First-Order Stationary Condition (FOSC), inner-maximization, and\ngradient information, we identify the underlying cause of this phenomenon as\ngradient masking and provide insights into it. Furthermore, our experiments\nshow that certain unstable training instances may return to a state without\nrobust overestimation, inspiring our attempts at a solution. In addition to\nadjusting parameter settings to reduce instability or retraining when\noverestimation occurs, we recommend incorporating Gaussian noise in inputs when\nthe FOSC score exceed the threshold. This method aims to mitigate robustness\noverestimation of TRADES and other similar methods at its source, ensuring more\nreliable representation of adversarial robustness during evaluation.",
      "tldr_zh": "该论文揭示了TRADES方法在对抗训练中存在的鲁棒性过估计问题，即PGD验证准确率远高于AutoAttack测试准确率，导致潜在的gradient masking。研究分析了影响因素，包括较小批量大小、更低beta值（控制鲁棒损失权重）、更大学习率及更高类复杂性（如CIFAR-100 vs CIFAR-10），这些参数会增加模型不稳定性。通过First-Order Stationary Condition (FOSC)、内最大化及梯度信息等指标，确认了gradient masking的根源，并实验证明某些不稳定训练实例可恢复正常。作者建议调整参数设置、重新训练，或在FOSC得分超过阈值时添加高斯噪声，以缓解TRADES及其他类似方法的鲁棒性过估计问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07675v1",
      "published_date": "2024-10-10 07:32:40 UTC",
      "updated_date": "2024-10-10 07:32:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:55:17.061729"
    },
    {
      "arxiv_id": "2410.07673v1",
      "title": "Multimodal Clickbait Detection by De-confounding Biases Using Causal Representation Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Jianxing Yu",
        "Shiqi Wang",
        "Han Yin",
        "Zhenlong Sun",
        "Ruobing Xie",
        "Bo Zhang",
        "Yanghui Rao"
      ],
      "abstract": "This paper focuses on detecting clickbait posts on the Web. These posts often\nuse eye-catching disinformation in mixed modalities to mislead users to click\nfor profit. That affects the user experience and thus would be blocked by\ncontent provider. To escape detection, malicious creators use tricks to add\nsome irrelevant non-bait content into bait posts, dressing them up as legal to\nfool the detector. This content often has biased relations with non-bait\nlabels, yet traditional detectors tend to make predictions based on simple\nco-occurrence rather than grasping inherent factors that lead to malicious\nbehavior. This spurious bias would easily cause misjudgments. To address this\nproblem, we propose a new debiased method based on causal inference. We first\nemploy a set of features in multiple modalities to characterize the posts.\nConsidering these features are often mixed up with unknown biases, we then\ndisentangle three kinds of latent factors from them, including the invariant\nfactor that indicates intrinsic bait intention; the causal factor which\nreflects deceptive patterns in a certain scenario, and non-causal noise. By\neliminating the noise that causes bias, we can use invariant and causal factors\nto build a robust model with good generalization ability. Experiments on three\npopular datasets show the effectiveness of our approach.",
      "tldr_zh": "本文提出了一种基于因果表示推理（Causal Representation Inference）的多模态点击诱饵检测方法，旨在解决传统检测器因简单共现而忽略内在恶意因素的问题，导致偏差和误判。方法首先使用多模态特征表征帖子，然后通过因果推理解缠潜在因素，包括不变因素（表示内在诱饵意图）、因果因素（反映特定场景的欺骗模式）和非因果噪声，从而消除偏差并构建具有良好泛化能力的鲁棒模型。在三个流行数据集上的实验证明，该方法显著提高了检测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07673v1",
      "published_date": "2024-10-10 07:29:56 UTC",
      "updated_date": "2024-10-10 07:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:55:29.167120"
    },
    {
      "arxiv_id": "2410.07672v2",
      "title": "MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization",
      "title_zh": "MACPO：通过多智能体对比偏好优化的弱到强对齐",
      "authors": [
        "Yougang Lyu",
        "Lingyong Yan",
        "Zihan Wang",
        "Dawei Yin",
        "Pengjie Ren",
        "Maarten de Rijke",
        "Zhaochun Ren"
      ],
      "abstract": "As large language models (LLMs) are rapidly advancing and achieving\nnear-human capabilities on specific tasks, aligning them with human values is\nbecoming more urgent. In scenarios where LLMs outperform humans, we face a\nweak-to-strong alignment problem where we need to effectively align strong\nstudent LLMs through weak supervision generated by weak teachers. Existing\nalignment methods mainly focus on strong-to-weak alignment and self-alignment\nsettings, and it is impractical to adapt them to the much harder weak-to-strong\nalignment setting. To fill this gap, we propose a multi-agent contrastive\npreference optimization (MACPO) framework. MACPO facilitates weak teachers and\nstrong students to learn from each other by iteratively reinforcing unfamiliar\npositive behaviors while penalizing familiar negative ones. To get this, we\ndevise a mutual positive behavior augmentation strategy to encourage weak\nteachers and strong students to learn from each other's positive behavior and\nfurther provide higher quality positive behavior for the next iteration.\nAdditionally, we propose a hard negative behavior construction strategy to\ninduce weak teachers and strong students to generate familiar negative behavior\nby fine-tuning on negative behavioral data. Experimental results on the HH-RLHF\nand PKU-SafeRLHF datasets, evaluated using both automatic metrics and human\njudgments, demonstrate that MACPO simultaneously improves the alignment\nperformance of strong students and weak teachers. Moreover, as the number of\nweak teachers increases, MACPO achieves better weak-to-strong alignment\nperformance through more iteration optimization rounds.",
      "tldr_zh": "本文提出 MACPO 框架，通过多智能体对比偏好优化（Multi-Agent Contrastive Preference Optimization）解决大型语言模型（LLMs）的弱到强对齐问题，即利用弱教师模型指导强学生模型。MACPO 采用相互正行为增强策略和硬负行为构建策略，允许弱教师和强学生迭代学习彼此的正行为并惩罚熟悉的负行为，从而提升对齐质量。实验结果显示，在 HH-RLHF 和 PKU-SafeRLHF 数据集上，MACPO 显著提高了强学生和弱教师的性能，且增加弱教师数量可通过更多迭代优化进一步改善弱-to-strong alignment 效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.07672v2",
      "published_date": "2024-10-10 07:29:35 UTC",
      "updated_date": "2025-03-02 06:25:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:55:41.407811"
    },
    {
      "arxiv_id": "2410.07671v2",
      "title": "DISCO: A Hierarchical Disentangled Cognitive Diagnosis Framework for Interpretable Job Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoshan Yu",
        "Chuan Qin",
        "Qi Zhang",
        "Chen Zhu",
        "Haiping Ma",
        "Xingyi Zhang",
        "Hengshu Zhu"
      ],
      "abstract": "The rapid development of online recruitment platforms has created\nunprecedented opportunities for job seekers while concurrently posing the\nsignificant challenge of quickly and accurately pinpointing positions that\nalign with their skills and preferences. Job recommendation systems have\nsignificantly alleviated the extensive search burden for job seekers by\noptimizing user engagement metrics, such as clicks and applications, thus\nachieving notable success. In recent years, a substantial amount of research\nhas been devoted to developing effective job recommendation models, primarily\nfocusing on text-matching based and behavior modeling based methods. While\nthese approaches have realized impressive outcomes, it is imperative to note\nthat research on the explainability of recruitment recommendations remains\nprofoundly unexplored. To this end, in this paper, we propose DISCO, a\nhierarchical Disentanglement based Cognitive diagnosis framework, aimed at\nflexibly accommodating the underlying representation learning model for\neffective and interpretable job recommendations. Specifically, we first design\na hierarchical representation disentangling module to explicitly mine the\nhierarchical skill-related factors implied in hidden representations of job\nseekers and jobs. Subsequently, we propose level-aware association modeling to\nenhance information communication and robust representation learning both\ninter- and intra-level, which consists of the interlevel knowledge influence\nmodule and the level-wise contrastive learning. Finally, we devise an\ninteraction diagnosis module incorporating a neural diagnosis function for\neffectively modeling the multi-level recruitment interaction process between\njob seekers and jobs, which introduces the cognitive measurement theory.",
      "tldr_zh": "本研究针对在线招聘平台的职位推荐问题，提出DISCO框架，这是一个基于层次化解耦的认知诊断框架，旨在实现有效的可解释推荐。具体地，DISCO首先通过层次化表示解耦模块挖掘求职者和职位中隐含的层次技能相关因素；其次，引入层级感知关联建模，包括层间知识影响模块和层级对比学习，以增强信息交流和表示学习；最后，设计交互诊断模块，利用神经诊断函数和认知测量理论来模型多层招聘互动过程。该框架可灵活适应底层表示学习模型，提高推荐系统的解释性和准确性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ICDM 2024. 10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.07671v2",
      "published_date": "2024-10-10 07:29:31 UTC",
      "updated_date": "2024-10-15 15:29:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:55:52.489466"
    },
    {
      "arxiv_id": "2410.16317v1",
      "title": "A Survey on Physical Adversarial Attacks against Face Recognition Systems",
      "title_zh": "针对人脸识别系统的物理对抗攻击综述",
      "authors": [
        "Mingsi Wang",
        "Jiachen Zhou",
        "Tianlin Li",
        "Guozhu Meng",
        "Kai Chen"
      ],
      "abstract": "As Face Recognition (FR) technology becomes increasingly prevalent in\nfinance, the military, public safety, and everyday life, security concerns have\ngrown substantially. Physical adversarial attacks targeting FR systems in\nreal-world settings have attracted considerable research interest due to their\npracticality and the severe threats they pose. However, a systematic overview\nfocused on physical adversarial attacks against FR systems is still lacking,\nhindering an in-depth exploration of the challenges and future directions in\nthis field. In this paper, we bridge this gap by comprehensively collecting and\nanalyzing physical adversarial attack methods targeting FR systems.\nSpecifically, we first investigate the key challenges of physical attacks on FR\nsystems. We then categorize existing physical attacks into three categories\nbased on the physical medium used and summarize how the research in each\ncategory has evolved to address these challenges. Furthermore, we review\ncurrent defense strategies and discuss potential future research directions.\nOur goal is to provide a fresh, comprehensive, and deep understanding of\nphysical adversarial attacks against FR systems, thereby inspiring relevant\nresearch in this area.",
      "tldr_zh": "这篇调查论文系统地概述了针对人脸识别 (FR) 系统的物理对抗攻击，填补了该领域的文献空白。论文首先分析了物理攻击的关键挑战，然后将现有攻击方法分为基于物理介质的三类，并总结了每类方法的演变过程。最终，论文审阅了当前的防御策略，并讨论了潜在的未来研究方向，以提供全面理解并激发进一步探索。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16317v1",
      "published_date": "2024-10-10 06:21:44 UTC",
      "updated_date": "2024-10-10 06:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:56:05.071095"
    },
    {
      "arxiv_id": "2410.07638v1",
      "title": "Almost Minimax Optimal Best Arm Identification in Piecewise Stationary Linear Bandits",
      "title_zh": "翻译失败",
      "authors": [
        "Yunlong Hou",
        "Vincent Y. F. Tan",
        "Zixin Zhong"
      ],
      "abstract": "We propose a {\\em novel} piecewise stationary linear bandit (PSLB) model,\nwhere the environment randomly samples a context from an unknown probability\ndistribution at each changepoint, and the quality of an arm is measured by its\nreturn averaged over all contexts. The contexts and their distribution, as well\nas the changepoints are unknown to the agent. We design {\\em\nPiecewise-Stationary $\\varepsilon$-Best Arm Identification$^+$}\n(PS$\\varepsilon$BAI$^+$), an algorithm that is guaranteed to identify an\n$\\varepsilon$-optimal arm with probability $\\ge 1-\\delta$ and with a minimal\nnumber of samples. PS$\\varepsilon$BAI$^+$ consists of two subroutines,\nPS$\\varepsilon$BAI and {\\sc Na\\\"ive $\\varepsilon$-BAI} (N$\\varepsilon$BAI),\nwhich are executed in parallel. PS$\\varepsilon$BAI actively detects\nchangepoints and aligns contexts to facilitate the arm identification process.\nWhen PS$\\varepsilon$BAI and N$\\varepsilon$BAI are utilized judiciously in\nparallel, PS$\\varepsilon$BAI$^+$ is shown to have a finite expected sample\ncomplexity. By proving a lower bound, we show the expected sample complexity of\nPS$\\varepsilon$BAI$^+$ is optimal up to a logarithmic factor. We compare\nPS$\\varepsilon$BAI$^+$ to baseline algorithms using numerical experiments which\ndemonstrate its efficiency. Both our analytical and numerical results\ncorroborate that the efficacy of PS$\\varepsilon$BAI$^+$ is due to the delicate\nchange detection and context alignment procedures embedded in\nPS$\\varepsilon$BAI.",
      "tldr_zh": "本研究提出了一种新型分段平稳线性老虎机（Piecewise Stationary Linear Bandit, PSLB）模型，其中环境在未知变化点随机采样上下文，并评估臂的质量基于所有上下文的平均回报。论文设计了Piecewise-Stationary ε-Best Arm Identification+ (PSεBAI+)算法，该算法通过并行执行PSεBAI（负责检测变化点并对齐上下文）和NεBAI子例程，以最小样本数保证识别ε-optimal arm的概率至少为1-δ。结果显示，PSεBAI+的预期样本复杂度几乎是最优的（minimax optimal，仅差一个对数因子），并通过数值实验证明其比基线算法更高效，突显了变化检测和上下文对齐的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "69 pages. Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07638v1",
      "published_date": "2024-10-10 06:15:42 UTC",
      "updated_date": "2024-10-10 06:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:56:17.440004"
    },
    {
      "arxiv_id": "2410.07627v2",
      "title": "Automatic Curriculum Expert Iteration for Reliable LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Zirui Zhao",
        "Hanze Dong",
        "Amrita Saha",
        "Caiming Xiong",
        "Doyen Sahoo"
      ],
      "abstract": "Hallucinations (i.e., generating plausible but inaccurate content) and\nlaziness (i.e. excessive refusals or defaulting to \"I don't know\") persist as\nmajor challenges in LLM reasoning. Current efforts to reduce hallucinations\nprimarily focus on factual errors in knowledge-grounded tasks, often neglecting\nhallucinations related to faulty reasoning. Meanwhile, some approaches render\nLLMs overly conservative, limiting their problem-solving capabilities. To\nmitigate hallucination and laziness in reasoning tasks, we propose Automatic\nCurriculum Expert Iteration (Auto-CEI) to enhance LLM reasoning and align\nresponses to the model's capabilities--assertively answering within its limits\nand declining when tasks exceed them. In our method, Expert Iteration explores\nthe reasoning trajectories near the LLM policy, guiding incorrect paths back on\ntrack to reduce compounding errors and improve robustness; it also promotes\nappropriate \"I don't know\" responses after sufficient reasoning attempts. The\ncurriculum automatically adjusts rewards, incentivizing extended reasoning\nbefore acknowledging incapability, thereby pushing the limits of LLM reasoning\nand aligning its behaviour with these limits. We compare Auto-CEI with various\nSOTA baselines across logical reasoning, mathematics, and planning tasks, where\nAuto-CEI achieves superior alignment by effectively balancing assertiveness and\nconservativeness. The code is available at\nhttps://github.com/SalesforceAIResearch/Auto-CEI .",
      "tldr_zh": "该研究针对大型语言模型(LLM) 在推理任务中的幻觉(hallucinations)和懒惰(laziness)问题，提出了一种 Automatic Curriculum Expert Iteration (Auto-CEI) 方法，以提升推理可靠性和响应平衡。Auto-CEI 通过 Expert Iteration 探索 LLM 策略附近的推理轨迹，修正错误路径并促进在充分尝试后给出“I don't know”响应，同时自动调整奖励机制来鼓励更深入的推理。实验结果显示，在逻辑推理、数学和规划任务上，Auto-CEI 比现有 SOTA 基线实现了更好的自信与保守平衡，显著提高了模型的鲁棒性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.07627v2",
      "published_date": "2024-10-10 05:43:07 UTC",
      "updated_date": "2025-03-20 05:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:56:28.779976"
    },
    {
      "arxiv_id": "2410.09109v1",
      "title": "Compressing high-resolution data through latent representation encoding for downscaling large-scale AI weather forecast model",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Liu",
        "Bing Gong",
        "Xiaoran Zhuang",
        "Xiaohui Zhong",
        "Zhiming Kang",
        "Hao Li"
      ],
      "abstract": "The rapid advancement of artificial intelligence (AI) in weather research has\nbeen driven by the ability to learn from large, high-dimensional datasets.\nHowever, this progress also poses significant challenges, particularly\nregarding the substantial costs associated with processing extensive data and\nthe limitations of computational resources. Inspired by the Neural Image\nCompression (NIC) task in computer vision, this study seeks to compress weather\ndata to address these challenges and enhance the efficiency of downstream\napplications. Specifically, we propose a variational autoencoder (VAE)\nframework tailored for compressing high-resolution datasets, specifically the\nHigh Resolution China Meteorological Administration Land Data Assimilation\nSystem (HRCLDAS) with a spatial resolution of 1 km. Our framework successfully\nreduced the storage size of 3 years of HRCLDAS data from 8.61 TB to just 204\nGB, while preserving essential information. In addition, we demonstrated the\nutility of the compressed data through a downscaling task, where the model\ntrained on the compressed dataset achieved accuracy comparable to that of the\nmodel trained on the original data. These results highlight the effectiveness\nand potential of the compressed data for future weather research.",
      "tldr_zh": "这篇论文针对AI天气预测模型处理高分辨率数据的计算成本和资源限制问题，提出了一种基于变分自编码器（VAE）的框架，受Neural Image Compression（NIC）任务启发，用于压缩High Resolution China Meteorological Administration Land Data Assimilation System（HRCLDAS）数据。具体而言，该框架将3年HRCLDAS数据从8.61 TB成功压缩至204 GB，同时保留了核心信息。在下采样任务中，使用压缩数据的模型准确性与原始数据相当，展示了这一方法在提升天气研究效率方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09109v1",
      "published_date": "2024-10-10 05:38:03 UTC",
      "updated_date": "2024-10-10 05:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:56:41.544675"
    },
    {
      "arxiv_id": "2410.12846v3",
      "title": "Accurate and Regret-aware Numerical Problem Solver for Tabular Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wang",
        "Jianzhong Qi",
        "Junhao Gan"
      ],
      "abstract": "Question answering on free-form tables (a.k.a. TableQA) is a challenging task\nbecause of the flexible structure and complex schema of tables. Recent studies\nuse Large Language Models (LLMs) for this task, exploiting their capability in\nunderstanding the questions and tabular data, which are typically given in\nnatural language and contain many textual fields, respectively. While this\napproach has shown promising results, it overlooks the challenges brought by\nnumerical values which are common in tabular data, and LLMs are known to\nstruggle with such values. We aim to address this issue, and we propose a model\nnamed TabLaP that uses LLMs as a planner rather than an answer generator. This\napproach exploits LLMs' capability in multi-step reasoning while leaving the\nactual numerical calculations to a Python interpreter for accurate calculation.\nRecognizing the inaccurate nature of LLMs, we further make a first attempt to\nquantify the trustworthiness of the answers produced by TabLaP, such that users\ncan use TabLaP in a regret-aware manner. Experimental results on two benchmark\ndatasets show that TabLaP is substantially more accurate than the\nstate-of-the-art models, improving the answer accuracy by 5.7% and 5.8% on the\ntwo datasets, respectively.",
      "tldr_zh": "这篇论文针对表格问答(TableQA)任务中数值处理的挑战，提出了一种名为TabLaP的模型，以解决大型语言模型(LLMs)在处理数值时的不准确问题。TabLaP将LLMs用作多步推理规划器，而将实际计算任务交给Python解释器，以确保计算精度；同时，论文首次量化答案的可信度，实现regret-aware的后悔感知机制，让用户更可靠地应用模型。实验结果显示，TabLaP在两个基准数据集上分别比最先进模型提高了5.7%和5.8%的答案准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12846v3",
      "published_date": "2024-10-10 05:34:00 UTC",
      "updated_date": "2025-02-07 04:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:56:52.771497"
    },
    {
      "arxiv_id": "2410.07618v1",
      "title": "Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Liu",
        "Jiahao Mei",
        "Hengyu Zhang",
        "Yihuai Zhang",
        "Xingjiao Wu",
        "Daoguo Dong",
        "Liang He"
      ],
      "abstract": "Although Chinese calligraphy generation has achieved style transfer,\ngenerating calligraphy by specifying the calligrapher, font, and character\nstyle remains challenging. To address this, we propose a new Chinese\ncalligraphy generation model 'Moyun' , which replaces the Unet in the Diffusion\nmodel with Vision Mamba and introduces the TripleLabel control mechanism to\nachieve controllable calligraphy generation. The model was tested on our\nlarge-scale dataset 'Mobao' of over 1.9 million images, and the results\ndemonstrate that 'Moyun' can effectively control the generation process and\nproduce calligraphy in the specified style. Even for calligraphy the\ncalligrapher has not written, 'Moyun' can generate calligraphy that matches the\nstyle of the calligrapher.",
      "tldr_zh": "本文提出 Moyun 模型，这是一个基于 Diffusion 的系统，用于生成特定书法家、字体和字符风格的中文书法。Moyun 通过将 Diffusion 模型中的 Unet 替换为 Vision Mamba，并引入 TripleLabel 控制机制，实现对书法生成过程的可控性。在超过 1.9 百万图像的 Mobao 数据集上测试，结果显示该模型能有效产生指定风格的书法，甚至生成书法家未写过的风格，但仍匹配其整体风格。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07618v1",
      "published_date": "2024-10-10 05:14:03 UTC",
      "updated_date": "2024-10-10 05:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:57:04.981801"
    },
    {
      "arxiv_id": "2410.07610v4",
      "title": "CSA: Data-efficient Mapping of Unimodal Features to Multimodal Features",
      "title_zh": "翻译失败",
      "authors": [
        "Po-han Li",
        "Sandeep P. Chinchali",
        "Ufuk Topcu"
      ],
      "abstract": "Multimodal encoders like CLIP excel in tasks such as zero-shot image\nclassification and cross-modal retrieval. However, they require excessive\ntraining data. We propose canonical similarity analysis (CSA), which uses two\nunimodal encoders to replicate multimodal encoders using limited data. CSA maps\nunimodal features into a multimodal space, using a new similarity score to\nretain only the multimodal information. CSA only involves the inference of\nunimodal encoders and a cubic-complexity matrix decomposition, eliminating the\nneed for extensive GPU-based model training. Experiments show that CSA\noutperforms CLIP while requiring $50,000\\times$ fewer multimodal data pairs to\nbridge the modalities given pre-trained unimodal encoders on ImageNet\nclassification and misinformative news caption detection. CSA surpasses the\nstate-of-the-art method to map unimodal features to multimodal features. We\nalso demonstrate the ability of CSA with modalities beyond image and text,\npaving the way for future modality pairs with limited paired multimodal data\nbut abundant unpaired unimodal data, such as lidar and text.",
      "tldr_zh": "本研究提出了一种数据高效的方法——Canonical Similarity Analysis (CSA)，它利用两个 unimodal encoders 将单模态特征映射到多模态空间，仅需有限的数据即可模拟多模态 encoders 如 CLIP 的性能。CSA 通过一个新的 similarity score 保留多模态信息，并仅涉及 unimodal encoders 的推理和立方复杂度矩阵分解，从而避免了大规模 GPU 训练。实验结果显示，CSA 在 ImageNet 分类和 misinformative news caption detection 任务上超过了 CLIP，且只需其 1/50,000 的多模态数据对，同时超越了现有的 state-of-the-art 方法。该方法还扩展到图像和文本以外的模态组合，如 lidar 和文本，适用于有丰富 unpaired unimodal 数据但 paired 数据有限的场景。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07610v4",
      "published_date": "2024-10-10 04:54:37 UTC",
      "updated_date": "2025-03-13 20:40:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:57:16.920287"
    },
    {
      "arxiv_id": "2410.19743v1",
      "title": "AppBench: Planning of Multiple APIs from Various APPs for Complex User Instruction",
      "title_zh": "AppBench：各种APP中多个API的规划，用于复杂用户指令",
      "authors": [
        "Hongru Wang",
        "Rui Wang",
        "Boyang Xue",
        "Heming Xia",
        "Jingtao Cao",
        "Zeming Liu",
        "Jeff Z. Pan",
        "Kam-Fai Wong"
      ],
      "abstract": "Large Language Models (LLMs) can interact with the real world by connecting\nwith versatile external APIs, resulting in better problem-solving and task\nautomation capabilities. Previous research primarily focuses on APIs with\nlimited arguments from a single source or overlooks the complex dependency\nrelationship between different APIs. However, it is essential to utilize\nmultiple APIs collaboratively from various sources (e.g., different Apps in the\niPhone), especially for complex user instructions. In this paper, we introduce\n\\texttt{AppBench}, the first benchmark to evaluate LLMs' ability to plan and\nexecute multiple APIs from various sources in order to complete the user's\ntask. Specifically, we consider two significant challenges in multiple APIs:\n\\textit{1) graph structures:} some APIs can be executed independently while\nothers need to be executed one by one, resulting in graph-like execution order;\nand \\textit{2) permission constraints:} which source is authorized to execute\nthe API call. We have experimental results on 9 distinct LLMs; e.g., GPT-4o\nachieves only a 2.0\\% success rate at the most complex instruction, revealing\nthat the existing state-of-the-art LLMs still cannot perform well in this\nsituation even with the help of in-context learning and finetuning. Our code\nand data are publicly available at https://github.com/ruleGreen/AppBench.",
      "tldr_zh": "本文提出 AppBench，这是一个新的基准，用于评估大型语言模型 (LLMs) 在处理复杂用户指令时，对来自不同来源 (如 iPhone 上的各种 Apps) 的多个 APIs 进行规划和执行的能力。AppBench 特别关注两个挑战：图结构 (APIs 可能独立或顺序执行，形成图状依赖关系) 和权限约束 (确定哪些来源有权调用 APIs)。实验结果显示，在 9 个不同 LLMs 上测试时，GPT-4o 在最复杂指令下仅达到 2.0% 的成功率，表明现有模型即使借助 in-context learning 和 finetuning 仍需进一步改进。代码和数据已公开在 GitHub。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19743v1",
      "published_date": "2024-10-10 04:03:13 UTC",
      "updated_date": "2024-10-10 04:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:57:29.989239"
    },
    {
      "arxiv_id": "2410.07593v2",
      "title": "A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hoin Jung",
        "Taeuk Jang",
        "Xiaoqian Wang"
      ],
      "abstract": "Recent advancements in Vision-Language Models (VLMs) have enabled complex\nmultimodal tasks by processing text and image data simultaneously,\nsignificantly enhancing the field of artificial intelligence. However, these\nmodels often exhibit biases that can skew outputs towards societal stereotypes,\nthus necessitating debiasing strategies. Existing debiasing methods focus\nnarrowly on specific modalities or tasks, and require extensive retraining. To\naddress these limitations, this paper introduces Selective Feature Imputation\nfor Debiasing (SFID), a novel methodology that integrates feature pruning and\nlow confidence imputation (LCI) to effectively reduce biases in VLMs. SFID is\nversatile, maintaining the semantic integrity of outputs and costly effective\nby eliminating the need for retraining. Our experimental results demonstrate\nSFID's effectiveness across various VLMs tasks including zero-shot\nclassification, text-to-image retrieval, image captioning, and text-to-image\ngeneration, by significantly reducing gender biases without compromising\nperformance. This approach not only enhances the fairness of VLMs applications\nbut also preserves their efficiency and utility across diverse scenarios.",
      "tldr_zh": "这篇论文针对 Vision-Language Models (VLMs) 中的偏见问题，提出了一种统一的去偏见方法 Selective Feature Imputation for Debiasing (SFID)。SFID 通过特征修剪和 low confidence imputation (LCI) 技术，减少模型在多模态任务中的社会刻板印象，同时保持输出语义完整性并避免重新训练的开销。实验结果显示，该方法在零样本分类、文本到图像检索、图像描述和文本到图像生成等任务上显著降低了性别偏见，而不影响模型性能。总体上，SFID 提升了 VLMs 的公平性、效率和在多样场景中的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 (Spotlight), the Thirty-Eighth Annual Conference on\n  Neural Information Processing Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.07593v2",
      "published_date": "2024-10-10 03:57:48 UTC",
      "updated_date": "2024-10-29 02:16:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:57:41.785304"
    },
    {
      "arxiv_id": "2410.07592v1",
      "title": "Diversified and Adaptive Negative Sampling on Knowledge Graphs",
      "title_zh": "知识图谱上的多样化和自适应负采样",
      "authors": [
        "Ran Liu",
        "Zhongzhou Liu",
        "Xiaoli Li",
        "Hao Wu",
        "Yuan Fang"
      ],
      "abstract": "In knowledge graph embedding, aside from positive triplets (ie: facts in the\nknowledge graph), the negative triplets used for training also have a direct\ninfluence on the model performance. In reality, since knowledge graphs are\nsparse and incomplete, negative triplets often lack explicit labels, and thus\nthey are often obtained from various sampling strategies (eg: randomly\nreplacing an entity in a positive triplet). An ideal sampled negative triplet\nshould be informative enough to help the model train better. However, existing\nmethods often ignore diversity and adaptiveness in their sampling process,\nwhich harms the informativeness of negative triplets. As such, we propose a\ngenerative adversarial approach called Diversified and Adaptive Negative\nSampling DANS on knowledge graphs. DANS is equipped with a two-way generator\nthat generates more diverse negative triplets through two pathways, and an\nadaptive mechanism that produces more fine-grained examples by localizing the\nglobal generator for different entities and relations. On the one hand, the\ntwo-way generator increase the overall informativeness with more diverse\nnegative examples; on the other hand, the adaptive mechanism increases the\nindividual sample-wise informativeness with more fine-grained sampling.\nFinally, we evaluate the performance of DANS on three benchmark knowledge\ngraphs to demonstrate its effectiveness through quantitative and qualitative\nexperiments.",
      "tldr_zh": "这篇论文针对知识图（Knowledge Graphs）嵌入中的负样本采样问题，提出了一种生成对抗方法DANS（Diversified and Adaptive Negative Sampling），旨在通过双向生成器和适应机制生成更多样化和精细的负样本，提高样本的信息性。双向生成器通过两条路径增加负样本的多样性，而适应机制则根据不同实体和关系的特性进行本地化采样，从而提升整体和个体样本的训练效果。实验在三个基准知识图上进行，定量和定性结果证明了DANS比传统方法更有效。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 7 figures, Journal",
      "pdf_url": "http://arxiv.org/pdf/2410.07592v1",
      "published_date": "2024-10-10 03:53:49 UTC",
      "updated_date": "2024-10-10 03:53:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:57:53.604044"
    },
    {
      "arxiv_id": "2410.09107v1",
      "title": "Federated Learning for Data Market: Shapley-UCB for Seller Selection and Incentives",
      "title_zh": "翻译失败",
      "authors": [
        "Kongyang Chen",
        "Zeming Xu"
      ],
      "abstract": "In recent years, research on the data trading market has been continuously\ndeepened. In the transaction process, there is an information asymmetry process\nbetween agents and sellers. For sellers, direct data delivery faces the risk of\nprivacy leakage. At the same time, sellers are not willing to provide data. A\nreasonable compensation method is needed to encourage sellers to provide data\nresources. For agents, the quality of data provided by sellers needs to be\nexamined and evaluated. Otherwise, agents may consume too much cost and\nresources by recruiting sellers with poor data quality. Therefore, it is\nnecessary to build a complete delivery process for the interaction between\nsellers and agents in the trading market so that the needs of sellers and\nagents can be met. The federated learning architecture is widely used in the\ndata market due to its good privacy protection. Therefore, in this work, in\nresponse to the above challenges, we propose a transaction framework based on\nthe federated learning architecture, and design a seller selection algorithm\nand incentive compensation mechanism. Specifically, we use gradient similarity\nand Shapley algorithm to fairly and accurately evaluate the contribution of\nsellers, and use the modified UCB algorithm to select sellers. After the\ntraining, fair compensation is made according to the seller's participation in\nthe training. In view of the above work, we designed reasonable experiments for\ndemonstration and obtained results, proving the rationality and effectiveness\nof the framework.",
      "tldr_zh": "这篇论文针对数据交易市场的信息不对称问题，提出了一种基于Federated Learning的交易框架，以解决卖家隐私泄露风险和代理数据质量评估挑战。框架中，使用梯度相似度和Shapley算法来公平评估卖家贡献，并采用修改后的UCB算法进行卖家选择，同时设计激励补偿机制，根据卖家的训练参与度提供合理补偿。实验结果证明，该框架能有效提升交易效率和公平性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09107v1",
      "published_date": "2024-10-10 03:50:20 UTC",
      "updated_date": "2024-10-10 03:50:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:58:04.232042"
    },
    {
      "arxiv_id": "2410.07582v2",
      "title": "Detecting Training Data of Large Language Models via Expectation Maximization",
      "title_zh": "通过期望最大化检测大型语言模型的训练数据",
      "authors": [
        "Gyuwan Kim",
        "Yang Li",
        "Evangelia Spiliopoulou",
        "Jie Ma",
        "Miguel Ballesteros",
        "William Yang Wang"
      ],
      "abstract": "The advancement of large language models has grown parallel to the opacity of\ntheir training data. Membership inference attacks (MIAs) aim to determine\nwhether specific data was used to train a model. They offer valuable insights\ninto detecting data contamination and ensuring compliance with privacy and\ncopyright standards. However, MIA for LLMs is challenging due to the massive\nscale of training data and the inherent ambiguity of membership in texts.\nMoreover, creating realistic MIA evaluation benchmarks is difficult as training\nand test data distributions are often unknown. We introduce EM-MIA, a novel\nmembership inference method that iteratively refines membership scores and\nprefix scores via an expectation-maximization algorithm. Our approach leverages\nthe observation that these scores can improve each other: membership scores\nhelp identify effective prefixes for detecting training data, while prefix\nscores help determine membership. As a result, EM-MIA achieves state-of-the-art\nresults on WikiMIA. To enable comprehensive evaluation, we introduce OLMoMIA, a\nbenchmark built from OLMo resources, which allows controlling task difficulty\nthrough varying degrees of overlap between training and test data\ndistributions. Our experiments demonstrate EM-MIA is robust across different\nscenarios while also revealing fundamental limitations of current MIA\napproaches when member and non-member distributions are nearly identical.",
      "tldr_zh": "该论文探讨了通过 Expectation Maximization 算法检测大型语言模型（LLMs）训练数据的 Membership Inference Attacks (MIAs)，以识别数据污染并确保隐私和版权合规。作者提出 EM-MIA 方法，该方法通过迭代优化成员身份分数和前缀分数，利用两者相互增强的特性来提高检测准确性。实验结果显示，EM-MIA 在 WikiMIA 基准上达到了 state-of-the-art 性能，同时引入了新基准 OLMoMIA，通过调整训练和测试数据分布的重叠来评估任务难度。总体而言，该研究展示了 EM-MIA 的鲁棒性，但也揭示了当前 MIA 方法在成员和非成员分布相似时的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.07582v2",
      "published_date": "2024-10-10 03:31:16 UTC",
      "updated_date": "2025-04-21 02:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:58:17.382670"
    },
    {
      "arxiv_id": "2410.09105v1",
      "title": "Artificial intelligence techniques in inherited retinal diseases: A review",
      "title_zh": "遗传性视网膜疾病中的人工智能技术：综述",
      "authors": [
        "Han Trinh",
        "Jordan Vice",
        "Jason Charng",
        "Zahra Tajbakhsh",
        "Khyber Alam",
        "Fred K. Chen",
        "Ajmal Mian"
      ],
      "abstract": "Inherited retinal diseases (IRDs) are a diverse group of genetic disorders\nthat lead to progressive vision loss and are a major cause of blindness in\nworking-age adults. The complexity and heterogeneity of IRDs pose significant\nchallenges in diagnosis, prognosis, and management. Recent advancements in\nartificial intelligence (AI) offer promising solutions to these challenges.\nHowever, the rapid development of AI techniques and their varied applications\nhave led to fragmented knowledge in this field. This review consolidates\nexisting studies, identifies gaps, and provides an overview of AI's potential\nin diagnosing and managing IRDs. It aims to structure pathways for advancing\nclinical applications by exploring AI techniques like machine learning and deep\nlearning, particularly in disease detection, progression prediction, and\npersonalized treatment planning. Special focus is placed on the effectiveness\nof convolutional neural networks in these areas. Additionally, the integration\nof explainable AI is discussed, emphasizing its importance in clinical settings\nto improve transparency and trust in AI-based systems. The review addresses the\nneed to bridge existing gaps in focused studies on AI's role in IRDs, offering\na structured analysis of current AI techniques and outlining future research\ndirections. It concludes with an overview of the challenges and opportunities\nin deploying AI for IRDs, highlighting the need for interdisciplinary\ncollaboration and the continuous development of robust, interpretable AI models\nto advance clinical applications.",
      "tldr_zh": "这篇综述论文探讨了人工智能(AI)技术在遗传性视网膜疾病(IRD)中的应用，旨在解决这些疾病在诊断、预后和管理方面的复杂挑战。论文整合了现有研究，重点分析了机器学习、深度学习和卷积神经网络(convolutional neural networks)在疾病检测、进展预测以及个性化治疗规划中的潜力，并强调了可解释AI(explainable AI)的整合，以提升临床环境的透明度和信任。最终，它识别了研究空白，概述了未来方向，包括跨学科合作和开发稳健AI模型，以推动IRD的临床应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09105v1",
      "published_date": "2024-10-10 03:14:51 UTC",
      "updated_date": "2024-10-10 03:14:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:23.488788"
    },
    {
      "arxiv_id": "2410.07567v2",
      "title": "When and Where Did it Happen? An Encoder-Decoder Model to Identify Scenario Context",
      "title_zh": "翻译失败",
      "authors": [
        "Enrique Noriega-Atala",
        "Robert Vacareanu",
        "Salena Torres Ashton",
        "Adarsh Pyarelal",
        "Clayton T. Morrison",
        "Mihai Surdeanu"
      ],
      "abstract": "We introduce a neural architecture finetuned for the task of scenario context\ngeneration: The relevant location and time of an event or entity mentioned in\ntext. Contextualizing information extraction helps to scope the validity of\nautomated finings when aggregating them as knowledge graphs. Our approach uses\na high-quality curated dataset of time and location annotations in a corpus of\nepidemiology papers to train an encoder-decoder architecture. We also explored\nthe use of data augmentation techniques during training. Our findings suggest\nthat a relatively small fine-tuned encoder-decoder model performs better than\nout-of-the-box LLMs and semantic role labeling parsers to accurate predict the\nrelevant scenario information of a particular entity or event.",
      "tldr_zh": "本研究提出了一种微调的编码器-解码器模型，用于识别文本中事件或实体的场景上下文，包括相关的时间和位置，以支持知识图谱的准确聚合。研究团队利用一个高质量的标注数据集（基于流行病学论文的时空注释）进行训练，并探索了数据增强技术来提升模型性能。结果显示，该小型微调模型在预测场景信息方面优于现成的LLMs和语义角色标注解析器，提供了一种更精确的上下文提取方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07567v2",
      "published_date": "2024-10-10 03:05:48 UTC",
      "updated_date": "2024-10-20 17:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:58:40.626693"
    },
    {
      "arxiv_id": "2410.07563v2",
      "title": "PLaMo-100B: A Ground-Up Language Model Designed for Japanese Proficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Preferred Elements",
        ":",
        "Kenshin Abe",
        "Kaizaburo Chubachi",
        "Yasuhiro Fujita",
        "Yuta Hirokawa",
        "Kentaro Imajo",
        "Toshiki Kataoka",
        "Hiroyoshi Komatsu",
        "Hiroaki Mikami",
        "Tsuguo Mogami",
        "Shogo Murai",
        "Kosuke Nakago",
        "Daisuke Nishino",
        "Toru Ogawa",
        "Daisuke Okanohara",
        "Yoshihiko Ozaki",
        "Shotaro Sano",
        "Shuji Suzuki",
        "Tianqi Xu",
        "Toshihiko Yanase"
      ],
      "abstract": "We introduce PLaMo-100B, a large-scale language model designed for Japanese\nproficiency. The model was trained from scratch using 2 trillion tokens, with\narchitecture such as QK Normalization and Z-Loss to ensure training stability\nduring the training process. Post-training techniques, including Supervised\nFine-Tuning and Direct Preference Optimization, were applied to refine the\nmodel's performance. Benchmark evaluations suggest that PLaMo-100B performs\nwell, particularly in Japanese-specific tasks, achieving results that are\ncompetitive with frontier models like GPT-4. The base model is available at\nhttps://huggingface.co/pfnet/plamo-100b.",
      "tldr_zh": "我们介绍了PLaMo-100B，一种从零设计的规模化语言模型，专注于日语能力提升。该模型使用2万亿tokens进行训练，采用了QK Normalization和Z-Loss等架构来确保训练稳定性，并通过Supervised Fine-Tuning和Direct Preference Optimization等后训练技巧优化性能。在基准评估中，PLaMo-100B在日语特定任务上表现出色，与GPT-4的水平相当，并已在Hugging Face上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07563v2",
      "published_date": "2024-10-10 02:59:36 UTC",
      "updated_date": "2024-10-22 09:06:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:58:53.056810"
    },
    {
      "arxiv_id": "2410.14715v1",
      "title": "Animating the Past: Reconstruct Trilobite via Video Generation",
      "title_zh": "动画化过去：通过视频生成重建三叶虫Trilobite",
      "authors": [
        "Xiaoran Wu",
        "Zien Huang",
        "Chonghan Yu"
      ],
      "abstract": "Paleontology, the study of past life, fundamentally relies on fossils to\nreconstruct ancient ecosystems and understand evolutionary dynamics.\nTrilobites, as an important group of extinct marine arthropods, offer valuable\ninsights into Paleozoic environments through their well-preserved fossil\nrecords. Reconstructing trilobite behaviour from static fossils will set new\nstandards for dynamic reconstructions in scientific research and education.\nDespite the potential, current computational methods for this purpose like\ntext-to-video (T2V) face significant challenges, such as maintaining visual\nrealism and consistency, which hinder their application in science contexts. To\novercome these obstacles, we introduce an automatic T2V prompt learning method.\nWithin this framework, prompts for a fine-tuned video generation model are\ngenerated by a large language model, which is trained using rewards that\nquantify the visual realism and smoothness of the generated video. The\nfine-tuning of the video generation model, along with the reward calculations\nmake use of a collected dataset of 9,088 Eoredlichia intermedia fossil images,\nwhich provides a common representative of visual details of all class of\ntrilobites. Qualitative and quantitative experiments show that our method can\ngenerate trilobite videos with significantly higher visual realism compared to\npowerful baselines, promising to boost both scientific understanding and public\nengagement.",
      "tldr_zh": "该研究旨在通过视频生成技术重建三叶虫(Trilobites)的行为动态，以提升古生物学中古生态和进化动态的研究。该方法引入一种自动文本到视频(T2V)提示学习框架，使用大语言模型生成提示，并通过奖励函数（基于视觉真实性和平滑度）对视频生成模型进行微调，利用一个包含9,088张Eoredlichia intermedia化石图像的数据集进行训练。实验结果显示，该方法生成的视频在视觉真实性和一致性上显著优于现有基线模型，有望增强科学研究、教育和公众参与。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14715v1",
      "published_date": "2024-10-10 02:54:58 UTC",
      "updated_date": "2024-10-10 02:54:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:05.649140"
    },
    {
      "arxiv_id": "2410.07553v2",
      "title": "COMMA: A Communicative Multimodal Multi-Agent Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Timothy Ossowski",
        "Jixuan Chen",
        "Danyal Maqbool",
        "Zefan Cai",
        "Tyler Bradshaw",
        "Junjie Hu"
      ],
      "abstract": "The rapid advances of multimodal agents built on large foundation models have\nlargely overlooked their potential for language-based communication between\nagents in collaborative tasks. This oversight presents a critical gap in\nunderstanding their effectiveness in real-world deployments, particularly when\ncommunicating with humans. Existing agentic benchmarks fail to address key\naspects of inter-agent communication and collaboration, particularly in\nscenarios where agents have unequal access to information and must work\ntogether to achieve tasks beyond the scope of individual capabilities. To fill\nthis gap, we introduce a novel benchmark designed to evaluate the collaborative\nperformance of multimodal multi-agent systems through language communication.\nOur benchmark features a variety of scenarios, providing a comprehensive\nevaluation across four key categories of agentic capability in a communicative\ncollaboration setting. By testing both agent-agent and agent-human\ncollaborations using open-source and closed-source models, our findings reveal\nsurprising weaknesses in state-of-the-art models, including proprietary models\nlike GPT-4o. Some of these models struggle to outperform even a simple random\nagent baseline in agent-agent collaboration and only surpass the random\nbaseline when a human is involved.",
      "tldr_zh": "该研究引入了 COMMA，这是一个用于评估多模态多代理系统（Multimodal Multi-Agent）在语言通信中的协作性能的新基准。COMMA 针对现有基准的不足，设计了各种场景来测试代理在信息不均等条件下进行代理-代理和代理-人类协作的四个关键能力类别。实验结果显示，即使是先进的闭源模型如 GPT-4o，在代理-代理协作中往往无法超越简单随机代理基线，但在涉及人类时表现有所提升。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07553v2",
      "published_date": "2024-10-10 02:49:47 UTC",
      "updated_date": "2025-02-06 22:55:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:16.681916"
    },
    {
      "arxiv_id": "2410.07551v1",
      "title": "KRAG Framework for Enhancing LLMs in the Legal Domain",
      "title_zh": "KRAG",
      "authors": [
        "Nguyen Ha Thanh",
        "Ken Satoh"
      ],
      "abstract": "This paper introduces Knowledge Representation Augmented Generation (KRAG), a\nnovel framework designed to enhance the capabilities of Large Language Models\n(LLMs) within domain-specific applications. KRAG points to the strategic\ninclusion of critical knowledge entities and relationships that are typically\nabsent in standard data sets and which LLMs do not inherently learn. In the\ncontext of legal applications, we present Soft PROLEG, an implementation model\nunder KRAG, which uses inference graphs to aid LLMs in delivering structured\nlegal reasoning, argumentation, and explanations tailored to user inquiries.\nThe integration of KRAG, either as a standalone framework or in tandem with\nretrieval augmented generation (RAG), markedly improves the ability of language\nmodels to navigate and solve the intricate challenges posed by legal texts and\nterminologies. This paper details KRAG's methodology, its implementation\nthrough Soft PROLEG, and potential broader applications, underscoring its\nsignificant role in advancing natural language understanding and processing in\nspecialized knowledge domains.",
      "tldr_zh": "本论文引入了 Knowledge Representation Augmented Generation (KRAG) 框架，以增强 Large Language Models (LLMs) 在特定领域（如法律）的能力，通过战略性地添加关键知识实体和关系来弥补标准数据集的不足。KRAG 的实现模型 Soft PROLEG 利用推理图 (inference graphs) 帮助 LLMs 进行结构化的法律推理、论证和解释，并可与检索增强生成 (RAG) 结合，提升模型处理复杂法律文本和术语的性能。实验结果显示，KRAG 显著提高了 LLMs 在法律领域的准确性和适用性，并具有更广泛的应用潜力，用于推进专业知识领域的自然语言理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
      "pdf_url": "http://arxiv.org/pdf/2410.07551v1",
      "published_date": "2024-10-10 02:48:06 UTC",
      "updated_date": "2024-10-10 02:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:38.560697"
    },
    {
      "arxiv_id": "2410.07549v1",
      "title": "OneNet: A Fine-Tuning Free Framework for Few-Shot Entity Linking via Large Language Model Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Xukai Liu",
        "Ye Liu",
        "Kai Zhang",
        "Kehang Wang",
        "Qi Liu",
        "Enhong Chen"
      ],
      "abstract": "Entity Linking (EL) is the process of associating ambiguous textual mentions\nto specific entities in a knowledge base. Traditional EL methods heavily rely\non large datasets to enhance their performance, a dependency that becomes\nproblematic in the context of few-shot entity linking, where only a limited\nnumber of examples are available for training. To address this challenge, we\npresent OneNet, an innovative framework that utilizes the few-shot learning\ncapabilities of Large Language Models (LLMs) without the need for fine-tuning.\nTo the best of our knowledge, this marks a pioneering approach to applying LLMs\nto few-shot entity linking tasks. OneNet is structured around three key\ncomponents prompted by LLMs: (1) an entity reduction processor that simplifies\ninputs by summarizing and filtering out irrelevant entities, (2) a\ndual-perspective entity linker that combines contextual cues and prior\nknowledge for precise entity linking, and (3) an entity consensus judger that\nemploys a unique consistency algorithm to alleviate the hallucination in the\nentity linking reasoning. Comprehensive evaluations across seven benchmark\ndatasets reveal that OneNet outperforms current state-of-the-art entity linking\nmethods.",
      "tldr_zh": "这篇论文介绍了 OneNet，一种无需 fine-tuning 的框架，通过 Large Language Models (LLMs) 提示来处理 Few-Shot Entity Linking 任务，从而解决传统方法依赖大量数据集的局限性。OneNet 由三个关键组件组成：实体减少处理器（用于总结和过滤无关实体）、双视角实体链接器（结合上下文线索和先验知识进行精确链接），以及实体共识判断器（采用一致性算法减少幻觉）。实验结果显示，在七个基准数据集上，OneNet 优于当前最先进的方法，证明了其在少样本场景下的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2410.07549v1",
      "published_date": "2024-10-10 02:45:23 UTC",
      "updated_date": "2024-10-10 02:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:47.891827"
    },
    {
      "arxiv_id": "2410.07547v2",
      "title": "HM-DF SNN: Transcending Conventional Online Learning with Advanced Training and Deployment",
      "title_zh": "HM-DF SNN：通过先进的训练和部署超越传统在线学习",
      "authors": [
        "Zecheng Hao",
        "Yifan Huang",
        "Zijie Xu",
        "Wenxuan Liu",
        "Yuanhong Tang",
        "Zhaofei Yu",
        "Tiejun Huang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are considered to have enormous potential in\nthe future development of Artificial Intelligence due to their brain-inspired\nand energy-efficient properties. Compared to vanilla Spatial-Temporal\nBack-propagation (STBP) training methods, online training can effectively\novercome the risk of GPU memory explosion. However, current online learning\nframework cannot tackle the inseparability problem of temporal dependent\ngradients and merely aim to optimize the training memory, resulting in no\nperformance advantages compared to the STBP training models in the inference\nphase. To address the aforementioned challenges, we propose Hybrid\nMechanism-Driven Firing (HM-DF) model, which is a family of advanced models\nthat respectively adopt different spiking calculation schemes in the\nupper-region and lower-region of the firing threshold. We point out that HM-DF\nmodel can effectively separate temporal gradients and tackle the mismatch\nproblem of surrogate gradients, as well as achieving full-stage optimization\ntowards computation speed and memory footprint. Experimental results have\ndemonstrated that HM-DF model can be flexibly combined with various techniques\nto achieve state-of-the-art performance in the field of online learning,\nwithout triggering further power consumption.",
      "tldr_zh": "该研究针对 Spiking Neural Networks (SNNs) 的在线训练问题，提出 Hybrid Mechanism-Driven Firing (HM-DF) 模型，以解决时间依赖梯度的不可分离性和 surrogate gradients 的不匹配问题。HM-DF 通过在 firing threshold 的上部和下部采用不同的 spiking 计算方案，实现梯度的有效分离，并实现训练和推理阶段的计算速度和内存足迹的全阶段优化。实验结果表明，HM-DF 可以灵活与其他技术结合，达到在线学习领域的 state-of-the-art 性能，同时不增加功耗。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07547v2",
      "published_date": "2024-10-10 02:39:22 UTC",
      "updated_date": "2025-05-07 10:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T09:59:59.742793"
    },
    {
      "arxiv_id": "2410.07543v1",
      "title": "Generalization Ability Analysis of Through-the-Wall Radar Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Weicheng Gao",
        "Xiaodong Qu",
        "Xiaopeng Yang"
      ],
      "abstract": "Through-the-Wall radar (TWR) human activity recognition (HAR) is a technology\nthat uses low-frequency ultra-wideband (UWB) signal to detect and analyze\nindoor human motion. However, the high dependence of existing end-to-end\nrecognition models on the distribution of TWR training data makes it difficult\nto achieve good generalization across different indoor testers. In this regard,\nthe generalization ability of TWR HAR is analyzed in this paper. In detail, an\nend-to-end linear neural network method for TWR HAR and its generalization\nerror bound are first discussed. Second, a micro-Doppler corner representation\nmethod and the change of the generalization error before and after dimension\nreduction are presented. The appropriateness of the theoretical generalization\nerrors is proved through numerical simulations and experiments. The results\ndemonstrate that feature dimension reduction is effective in allowing\nrecognition models to generalize across different indoor testers.",
      "tldr_zh": "这篇论文分析了 Through-the-Wall Radar (TWR) 在人类活动识别 (HAR) 中的泛化能力问题，指出现有端到端模型高度依赖训练数据分布，导致在不同室内测试者之间表现不佳。论文首先讨论了端到端线性神经网络方法及其泛化错误边界，并引入微多普勒角表示方法及特征降维技术，以评估降维前后泛化错误的改变。通过数值模拟和实验验证，结果显示特征降维能有效提升模型的泛化性能。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "94",
        "I.5.1"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 4 figures, 0 table, in Proc. IEEE International Conference\n  on Signal, Information and Data Processing (ICSIDP), 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07543v1",
      "published_date": "2024-10-10 02:29:10 UTC",
      "updated_date": "2024-10-10 02:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:00:14.749893"
    },
    {
      "arxiv_id": "2410.07542v1",
      "title": "Generalizable Indoor Human Activity Recognition Method Based on Micro-Doppler Corner Point Cloud and Dynamic Graph Learning",
      "title_zh": "基于微多普勒角点云和动态图学习的通用室内人类活动识别方法",
      "authors": [
        "Xiaopeng Yang",
        "Weicheng Gao",
        "Xiaodong Qu",
        "Haoyu Meng"
      ],
      "abstract": "Through-the-wall radar (TWR) human activity recognition can be achieved by\nfusing micro-Doppler signature extraction and intelligent decision-making\nalgorithms. However, limited by the insufficient priori of tester in practical\nindoor scenarios, the trained models on one tester are commonly difficult to\ninference well on other testers, which causes poor generalization ability. To\nsolve this problem, this paper proposes a generalizable indoor human activity\nrecognition method based on micro-Doppler corner point cloud and dynamic graph\nlearning. In the proposed method, DoG-{\\mu}D-CornerDet is used for\nmicro-Doppler corner extraction on two types of radar profiles. Then, a\nmicro-Doppler corner filtering method based on polynomial fitting smoothing is\nproposed to maximize the feature distance under the constraints of the\nkinematic model. The extracted corners from the two types of radar profiles are\nconcatenated together into three-dimensional point cloud. Finally, the paper\nproposes a dynamic graph neural network (DGNN)-based recognition method for\ndata-to-activity label mapping. Visualization, comparison and ablation\nexperiments are carried out to verify the effectiveness of the proposed method.\nThe results prove that the proposed method has strong generalization ability on\nradar data collected from different testers.",
      "tldr_zh": "本论文提出了一种基于微-Doppler 角点云和动态图学习的可泛化室内人类活动识别方法，旨在解决通过墙壁雷达 (TWR) 模型在不同测试者间泛化能力差的问题。方法首先使用 DoG-μD-CornerDet 提取微-Doppler 角点，并通过基于多项式拟合平滑的过滤技术最大化特征距离，同时符合运动学模型；随后，将提取的角点合并成三维点云，并采用动态图神经网络 (DGNN) 进行数据到活动标签的映射。实验结果显示，该方法在可视化、比较和消融测试中表现出强泛化能力，能够有效处理不同测试者收集的雷达数据。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "94",
        "I.5.1"
      ],
      "primary_category": "eess.SP",
      "comment": "15 pages, 12 figures, 6 tables, in IEEE Transactions on Aerospace and\n  Electronics Systems, 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.07542v1",
      "published_date": "2024-10-10 02:24:07 UTC",
      "updated_date": "2024-10-10 02:24:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:00:24.393584"
    },
    {
      "arxiv_id": "2410.07539v1",
      "title": "Efficient Generation of Molecular Clusters with Dual-Scale Equivariant Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay Subramanian",
        "Shuhui Qu",
        "Cheol Woo Park",
        "Sulin Liu",
        "Janghwan Lee",
        "Rafael Gómez-Bombarelli"
      ],
      "abstract": "Amorphous molecular solids offer a promising alternative to inorganic\nsemiconductors, owing to their mechanical flexibility and solution\nprocessability. The packing structure of these materials plays a crucial role\nin determining their electronic and transport properties, which are key to\nenhancing the efficiency of devices like organic solar cells (OSCs). However,\nobtaining these optoelectronic properties computationally requires molecular\ndynamics (MD) simulations to generate a conformational ensemble, a process that\ncan be computationally expensive due to the large system sizes involved. Recent\nadvances have focused on using generative models, particularly flow-based\nmodels as Boltzmann generators, to improve the efficiency of MD sampling. In\nthis work, we developed a dual-scale flow matching method that separates\ntraining and inference into coarse-grained and all-atom stages and enhances\nboth the accuracy and efficiency of standard flow matching samplers. We\ndemonstrate the effectiveness of this method on a dataset of Y6 molecular\nclusters obtained through MD simulations, and we benchmark its efficiency and\naccuracy against single-scale flow matching methods.",
      "tldr_zh": "该研究针对无定形分子固体（如用于有机太阳能电池OSCs）的堆积结构建模问题，指出传统分子动力学（MD）模拟计算成本高的问题。作者提出了一种双尺度等变流匹配（Dual-Scale Equivariant Flow Matching）方法，将训练和推理分为粗粒化和全原子阶段，从而提高生成分子簇的准确性和效率。在Y6分子簇数据集上进行基准测试，结果显示该方法优于单尺度流匹配方法，为加速MD采样和优化材料性能提供了高效解决方案。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07539v1",
      "published_date": "2024-10-10 02:17:27 UTC",
      "updated_date": "2024-10-10 02:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:00:35.116644"
    },
    {
      "arxiv_id": "2410.12845v1",
      "title": "Toward Relieving Clinician Burden by Automatically Generating Progress Notes using Interim Hospital Data",
      "title_zh": "翻译失败",
      "authors": [
        "Sarvesh Soni",
        "Dina Demner-Fushman"
      ],
      "abstract": "Regular documentation of progress notes is one of the main contributors to\nclinician burden. The abundance of structured chart information in medical\nrecords further exacerbates the burden, however, it also presents an\nopportunity to automate the generation of progress notes. In this paper, we\npropose a task to automate progress note generation using structured or tabular\ninformation present in electronic health records. To this end, we present a\nnovel framework and a large dataset, ChartPNG, for the task which contains\n$7089$ annotation instances (each having a pair of progress notes and interim\nstructured chart data) across $1616$ patients. We establish baselines on the\ndataset using large language models from general and biomedical domains. We\nperform both automated (where the best performing Biomistral model achieved a\nBERTScore F1 of $80.53$ and MEDCON score of $19.61$) and manual (where we found\nthat the model was able to leverage relevant structured data with $76.9\\%$\naccuracy) analyses to identify the challenges with the proposed task and\nopportunities for future research.",
      "tldr_zh": "这篇论文针对临床医生撰写 progress notes 的负担问题，提出一个任务，使用电子健康记录中的结构化数据自动生成进展笔记。研究团队引入了 ChartPNG 框架和数据集，包含 7089 个标注实例（基于 1616 名患者的进展笔记和临时结构化图表数据），并使用 large language models（如 Biomistral）建立基线模型。实验结果显示，Biomistral 模型在 BERTScore F1 达到 80.53% 和 MEDCON 得分 19.61%，手动评估准确率达 76.9%，同时识别了任务挑战并指出了未来研究机会。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at the AMIA 2024 Annual Symposium",
      "pdf_url": "http://arxiv.org/pdf/2410.12845v1",
      "published_date": "2024-10-10 02:03:27 UTC",
      "updated_date": "2024-10-10 02:03:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:00:47.841015"
    },
    {
      "arxiv_id": "2410.07531v1",
      "title": "Reducing the Cost of Dropout in Flash-Attention by Hiding RNG with GEMM",
      "title_zh": "翻译失败",
      "authors": [
        "Haiyue Ma",
        "Jian Liu",
        "Ronny Krashinsky"
      ],
      "abstract": "Dropout, a network operator, when enabled is likely to dramatically impact\nthe performance of Flash-Attention, which in turn increases the end-to-end\ntraining time of Large-Language-Models (LLMs). The main contributor to such\nperformance degradation is the Random Number Generation (RNG) phase that is\ntraditionally fused into the Flash-Attention kernel. As RNG and Attention have\nthe same hardware bottlenecks, RNG latency can hardly be hidden within the\nAttention kernel.\n  We propose overlapping RNG with previous GEMM layers in the network to hide\nRNG runtime and improve end-to-end performance. RNG and GEMM have distinct\nresource requirements and hardware bottlenecks, so they can run in parallel\nwithout compromising each other's performance. Our fine-grained performance\nmodel, cross-validated by silicon results, shows 1.14x speedup on one\ntransformer block (including multi-head attention and feed-forward layers) for\nLlama2, and up to 1.23x speedup when varying workload sizes, on GH100 GPUs with\nFP8 precision. Further, we extend our theoretical model to different RNG\nimplementations and hardware architectures, and discuss the widely applicable\nbenefits for overlapping RNG with GEMM layers.",
      "tldr_zh": "这篇论文解决了Dropout在Flash-Attention中的性能问题，主要通过将Random Number Generation (RNG)与GEMM层重叠运行来隐藏RNG的延迟，从而减少Large Language Models (LLMs)训练时间的开销。作者利用RNG和GEMM的资源需求和硬件瓶颈差异，使它们能并行执行而不相互干扰。实验结果显示，在GH100 GPUs上使用FP8精度，对Llama2的transformer块实现了1.14x加速，工作负载变化时最高可达1.23x，并扩展了模型到不同RNG实现和硬件架构，证明了其广泛适用性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07531v1",
      "published_date": "2024-10-10 01:59:06 UTC",
      "updated_date": "2024-10-10 01:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:00:59.614787"
    },
    {
      "arxiv_id": "2410.08241v1",
      "title": "LecPrompt: A Prompt-based Approach for Logical Error Correction with CodeBERT",
      "title_zh": "LecPrompt：一种基于提示的方法，用于使用 CodeBERT 进行逻辑错误修正",
      "authors": [
        "Zhenyu Xu",
        "Victor S. Sheng"
      ],
      "abstract": "Logical errors in programming don't raise compiler alerts, making them hard\nto detect. These silent errors can disrupt a program's function or cause\nrun-time issues. Their correction requires deep insight into the program's\nlogic, highlighting the importance of automated detection and repair. In this\npaper, we introduce LecPrompt to localize and repair logical errors, an\nprompt-based approach that harnesses the capabilities of CodeBERT, a\ntransformer-based large language model trained on code. First, LecPrompt\nleverages a large language model to calculate perplexity and log probability\nmetrics, pinpointing logical errors at both token and line levels. Through\nstatistical analysis, it identifies tokens and lines that deviate significantly\nfrom the expected patterns recognized by large language models, marking them as\npotential error sources. Second, by framing the logical error correction\nchallenge as a Masked Language Modeling (MLM) task, LecPrompt employs CodeBERT\nto autoregressively repair the identified error tokens. Finally, the\nsoft-prompt method provides a novel solution in low-cost scenarios, ensuring\nthat the model can be fine-tuned to the specific nuances of the logical error\ncorrection task without incurring high computational costs. To evaluate\nLecPrompt's performance, we created a method to introduce logical errors into\ncorrect code and applying this on QuixBugs to produce the QuixBugs-LE dataset.\nOur evaluations on the QuixBugs-LE dataset for both Python and Java highlight\nthe impressive capabilities of our method, LecPrompt. For Python, LecPrompt\nachieves a noteworthy 74.58% top-1 token-level repair accuracy and 27.4%\nprogram-level repair accuracy. In Java, LecPrompt delivers a 69.23\\% top-1\ntoken-level repair accuracy and 24.7% full program-level repair accuracy.",
      "tldr_zh": "本文提出 LecPrompt，一种基于 prompt 的方法，利用 CodeBERT 来定位和修复编程中的逻辑错误，通过计算 perplexity 和 log probability 指标识别异常 token 和 line，并将修复任务转化为 Masked Language Modeling (MLM) 问题进行自动修正。LecPrompt 采用 soft-prompt 技术实现低成本微调，避免高计算开销。为评估其性能，研究者创建了 QuixBugs-LE 数据集，并在 Python 和 Java 上测试，分别获得 74.58% 和 69.23% 的 top-1 token-level 修复准确率，以及 27.4% 和 24.7% 的 program-level 修复准确率。该方法为自动化逻辑错误检测与修复提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08241v1",
      "published_date": "2024-10-10 01:56:04 UTC",
      "updated_date": "2024-10-10 01:56:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:01:12.197722"
    },
    {
      "arxiv_id": "2410.07530v1",
      "title": "Audio Explanation Synthesis with Generative Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alican Akman",
        "Qiyang Sun",
        "Björn W. Schuller"
      ],
      "abstract": "The increasing success of audio foundation models across various tasks has\nled to a growing need for improved interpretability to understand their\nintricate decision-making processes better. Existing methods primarily focus on\nexplaining these models by attributing importance to elements within the input\nspace based on their influence on the final decision. In this paper, we\nintroduce a novel audio explanation method that capitalises on the generative\ncapacity of audio foundation models. Our method leverages the intrinsic\nrepresentational power of the embedding space within these models by\nintegrating established feature attribution techniques to identify significant\nfeatures in this space. The method then generates listenable audio explanations\nby prioritising the most important features. Through rigorous benchmarking\nagainst standard datasets, including keyword spotting and speech emotion\nrecognition, our model demonstrates its efficacy in producing audio\nexplanations.",
      "tldr_zh": "本文提出了一种新型音频解释合成方法，利用生成式基础模型（generative foundation models）的生成能力来提升音频模型的可解释性。该方法通过在模型的嵌入空间中整合特征归因（feature attribution）技术，识别并优先处理重要特征，从而生成可听的音频解释。在关键词识别和语音情感识别等标准数据集上的基准测试中，该方法证明了其在产生有效音频解释方面的功效。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07530v1",
      "published_date": "2024-10-10 01:55:58 UTC",
      "updated_date": "2024-10-10 01:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:01:22.637561"
    },
    {
      "arxiv_id": "2410.07526v1",
      "title": "MKGL: Mastery of a Three-Word Language",
      "title_zh": "翻译失败",
      "authors": [
        "Lingbing Guo",
        "Zhongpu Bo",
        "Zhuo Chen",
        "Yichi Zhang",
        "Jiaoyan Chen",
        "Yarong Lan",
        "Mengshu Sun",
        "Zhiqiang Zhang",
        "Yangyifei Luo",
        "Qian Li",
        "Qiang Zhang",
        "Wen Zhang",
        "Huajun Chen"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced performance across a\nspectrum of natural language processing (NLP) tasks. Yet, their application to\nknowledge graphs (KGs), which describe facts in the form of triplets and allow\nminimal hallucinations, remains an underexplored frontier. In this paper, we\ninvestigate the integration of LLMs with KGs by introducing a specialized KG\nLanguage (KGL), where a sentence precisely consists of an entity noun, a\nrelation verb, and ends with another entity noun. Despite KGL's unfamiliar\nvocabulary to the LLM, we facilitate its learning through a tailored dictionary\nand illustrative sentences, and enhance context understanding via real-time KG\ncontext retrieval and KGL token embedding augmentation. Our results reveal that\nLLMs can achieve fluency in KGL, drastically reducing errors compared to\nconventional KG embedding methods on KG completion. Furthermore, our enhanced\nLLM shows exceptional competence in generating accurate three-word sentences\nfrom an initial entity and interpreting new unseen terms out of KGs.",
      "tldr_zh": "该论文探讨了大型语言模型(LLMs)与知识图谱(KGs)的整合，引入了一种专门的三词语言KGL（Knowledge Graph Language），其中句子由实体名词、关系动词和另一个实体名词组成，以减少幻觉并提升KG任务性能。通过定制字典、示例句子、实时KG上下文检索以及KGL标记嵌入增强，论文帮助LLMs学习这一新语言。结果显示，增强后的LLMs在KGL上实现了流畅性，与传统KG嵌入方法相比显著减少错误，并在KG完成任务中表现出色，能够从初始实体生成准确的三词句子并解释未见术语。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2410.07526v1",
      "published_date": "2024-10-10 01:39:26 UTC",
      "updated_date": "2024-10-10 01:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:01:34.804771"
    },
    {
      "arxiv_id": "2410.07525v2",
      "title": "Offline Inverse Constrained Reinforcement Learning for Safe-Critical Decision Making in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Nan Fang",
        "Guiliang Liu",
        "Wei Gong"
      ],
      "abstract": "Reinforcement Learning (RL) applied in healthcare can lead to unsafe medical\ndecisions and treatment, such as excessive dosages or abrupt changes, often due\nto agents overlooking common-sense constraints. Consequently, Constrained\nReinforcement Learning (CRL) is a natural choice for safe decisions. However,\nspecifying the exact cost function is inherently difficult in healthcare.\nRecent Inverse Constrained Reinforcement Learning (ICRL) is a promising\napproach that infers constraints from expert demonstrations. ICRL algorithms\nmodel Markovian decisions in an interactive environment. These settings do not\nalign with the practical requirement of a decision-making system in healthcare,\nwhere decisions rely on historical treatment recorded in an offline dataset. To\ntackle these issues, we propose the Constraint Transformer (CT). Specifically,\n1) we utilize a causal attention mechanism to incorporate historical decisions\nand observations into the constraint modeling, while employing a Non-Markovian\nlayer for weighted constraints to capture critical states. 2) A generative\nworld model is used to perform exploratory data augmentation, enabling offline\nRL methods to simulate unsafe decision sequences. In multiple medical\nscenarios, empirical results demonstrate that CT can capture unsafe states and\nachieve strategies that approximate lower mortality rates, reducing the\noccurrence probability of unsafe behaviors.",
      "tldr_zh": "这篇论文针对强化学习（RL）在医疗决策中的安全问题，提出了一种离线逆向受限强化学习（ICRL）方法，以解决传统方法忽略约束导致的不安全行为，如过量剂量。论文引入Constraint Transformer (CT)，通过因果注意力机制整合历史决策和观察，并结合Non-Markovian层处理加权约束，以及生成世界模型进行探索数据增强，以模拟和避免不安全决策序列。实验结果显示，CT在多个医疗场景中有效捕捉不安全状态，显著降低死亡率并减少不安全行为发生概率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07525v2",
      "published_date": "2024-10-10 01:36:27 UTC",
      "updated_date": "2024-10-14 05:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:01:47.350017"
    },
    {
      "arxiv_id": "2410.07524v1",
      "title": "Upcycling Large Language Models into Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Ethan He",
        "Abhinav Khattar",
        "Ryan Prenger",
        "Vijay Korthikanti",
        "Zijie Yan",
        "Tong Liu",
        "Shiqing Fan",
        "Ashwath Aithal",
        "Mohammad Shoeybi",
        "Bryan Catanzaro"
      ],
      "abstract": "Upcycling pre-trained dense language models into sparse mixture-of-experts\n(MoE) models is an efficient approach to increase the model capacity of already\ntrained models. However, optimal techniques for upcycling at scale remain\nunclear. In this work, we conduct an extensive study of upcycling methods and\nhyperparameters for billion-parameter scale language models. We propose a novel\n\"virtual group\" initialization scheme and weight scaling approach to enable\nupcycling into fine-grained MoE architectures. Through ablations, we find that\nupcycling outperforms continued dense model training. In addition, we show that\nsoftmax-then-topK expert routing improves over topK-then-softmax approach and\nhigher granularity MoEs can help improve accuracy. Finally, we upcycled\nNemotron-4 15B on 1T tokens and compared it to a continuously trained version\nof the same model on the same 1T tokens: the continuous trained model achieved\n65.3% MMLU, whereas the upcycled model achieved 67.6%. Our results offer\ninsights and best practices to effectively leverage upcycling for building MoE\nlanguage models.",
      "tldr_zh": "本研究探讨了将预训练的密集语言模型 upcycling 成稀疏的 Mixture-of-Experts (MoE) 模型，以高效提升模型容量。作者提出了一种新型 \"virtual group\" 初始化方案和权重缩放方法，支持细粒度的 MoE 架构，并通过消融实验发现 upcycling 优于继续训练密集模型，同时 softmax-then-topK 专家路由方式和更高 MoE 粒度可改善准确率。在实际应用中，将 Nemotron-4 15B 模型 upcycled 在 1T 标记上，其 MMLU 成绩达 67.6%，比持续训练的 65.3% 更优，为构建高效 MoE 语言模型提供了最佳实践。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07524v1",
      "published_date": "2024-10-10 01:36:03 UTC",
      "updated_date": "2024-10-10 01:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:00.026082"
    },
    {
      "arxiv_id": "2410.07523v1",
      "title": "DemoShapley: Valuation of Demonstrations for In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Xie",
        "Man Luo",
        "Chadly Daniel Stern",
        "Mengnan Du",
        "Lu Cheng"
      ],
      "abstract": "Large language models (LLMs) leveraging in-context learning (ICL) have set\nnew benchmarks in few-shot learning across various tasks without needing\ntask-specific fine-tuning. However, extensive research has demonstrated that\nthe effectiveness of ICL is significantly influenced by the selection and\nordering of demonstrations. Considering the critical role of demonstration\nselection in ICL, we introduce DemoShapley which is inspired by the Data\nShapley valuation theorem. This approach assesses the influence of individual\ndemonstration instances, distinguishing between those that contribute\npositively and those that may hinder performance. Our findings reveal that\nDemoShapley not only enhances model performance in terms of accuracy and\nfairness but also generalizes queries from domains distinct from those of the\nin-context demonstrations, highlighting its versatility and effectiveness in\noptimizing ICL demonstration selection. Last but not least, DemoShapley\ndemonstrates its ability to aid in identifying noisy data within the\ndemonstration set.",
      "tldr_zh": "该论文提出 DemoShapley，一种基于 Data Shapley 估值定理的方法，用于评估 In-Context Learning (ICL) 中演示实例的影响，从而区分积极贡献和负面影响的演示。DemoShapley 通过优化演示选择，提升 Large Language Models (LLMs) 的准确性和公平性，同时使其能够泛化到与演示领域不同的查询。研究结果表明，该方法不仅改善了 ICL 性能，还能有效识别演示集中的噪声数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07523v1",
      "published_date": "2024-10-10 01:35:03 UTC",
      "updated_date": "2024-10-10 01:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:10.879865"
    },
    {
      "arxiv_id": "2410.11876v3",
      "title": "Rescriber: Smaller-LLM-Powered User-Led Data Minimization for LLM-Based Chatbots",
      "title_zh": "翻译失败",
      "authors": [
        "Jijie Zhou",
        "Eryue Xu",
        "Yaoyao Wu",
        "Tianshi Li"
      ],
      "abstract": "The proliferation of LLM-based conversational agents has resulted in\nexcessive disclosure of identifiable or sensitive information. However,\nexisting technologies fail to offer perceptible control or account for users'\npersonal preferences about privacy-utility tradeoffs due to the lack of user\ninvolvement. To bridge this gap, we designed, built, and evaluated Rescriber, a\nbrowser extension that supports user-led data minimization in LLM-based\nconversational agents by helping users detect and sanitize personal information\nin their prompts. Our studies (N=12) showed that Rescriber helped users reduce\nunnecessary disclosure and addressed their privacy concerns. Users' subjective\nperceptions of the system powered by Llama3-8B were on par with that by GPT-4o.\nThe comprehensiveness and consistency of the detection and sanitization emerge\nas essential factors that affect users' trust and perceived protection. Our\nfindings confirm the viability of smaller-LLM-powered, user-facing, on-device\nprivacy controls, presenting a promising approach to address the privacy and\ntrust challenges of AI.",
      "tldr_zh": "这篇论文介绍了Rescriber，一种基于较小LLM（如Llama3-8B）的浏览器扩展，旨在通过用户主导的数据最小化，帮助用户在LLM-based chatbots中检测和净化prompt中的个人信息，从而解决过度披露敏感信息的隐私问题。用户研究（N=12）显示，Rescriber显著减少了不必要的披露，缓解了隐私担忧，且其性能与GPT-4o相当。研究强调，检测和净化的全面性与一致性是影响用户信任和感知保护的关键因素，并证明了使用较小LLM驱动的本地隐私控制在解决AI隐私和信任挑战中的可行性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.11876v3",
      "published_date": "2024-10-10 01:23:16 UTC",
      "updated_date": "2025-02-11 19:56:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:27.149740"
    },
    {
      "arxiv_id": "2410.07513v1",
      "title": "Evolutionary Contrastive Distillation for Language Model Alignment",
      "title_zh": "用于语言模型对齐的进化对比蒸馏",
      "authors": [
        "Julian Katz-Samuels",
        "Zheng Li",
        "Hyokun Yun",
        "Priyanka Nigam",
        "Yi Xu",
        "Vaclav Petricek",
        "Bing Yin",
        "Trishul Chilimbi"
      ],
      "abstract": "The ability of large language models (LLMs) to execute complex instructions\nis essential for their real-world applications. However, several recent studies\nindicate that LLMs struggle with challenging instructions. In this paper, we\npropose Evolutionary Contrastive Distillation (ECD), a novel method for\ngenerating high-quality synthetic preference data designed to enhance the\ncomplex instruction-following capability of language models. ECD generates data\nthat specifically illustrates the difference between a response that\nsuccessfully follows a set of complex instructions and a response that is\nhigh-quality, but nevertheless makes some subtle mistakes. This is done by\nprompting LLMs to progressively evolve simple instructions to more complex\ninstructions. When the complexity of an instruction is increased, the original\nsuccessful response to the original instruction becomes a \"hard negative\"\nresponse for the new instruction, mostly meeting requirements of the new\ninstruction, but barely missing one or two. By pairing a good response with\nsuch a hard negative response, and employing contrastive learning algorithms\nsuch as DPO, we improve language models' ability to follow complex\ninstructions. Empirically, we observe that our method yields a 7B model that\nexceeds the complex instruction-following performance of current SOTA 7B models\nand is competitive even with open-source 70B models.",
      "tldr_zh": "本文提出 Evolutionary Contrastive Distillation (ECD) 方法，用于生成高质量合成偏好数据，以提升大型语言模型 (LLMs) 处理复杂指令的能力。ECD 通过提示 LLMs 逐步演化简单指令为更复杂指令，并将原始成功响应作为“硬负样本”（hard negative），即高质量但有细微错误的响应，结合对比学习算法如 DPO 进行训练。实验结果显示，该方法使 7B 模型在复杂指令遵循性能上超过当前 SOTA 7B 模型，甚至与开源 70B 模型竞争。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07513v1",
      "published_date": "2024-10-10 01:04:03 UTC",
      "updated_date": "2024-10-10 01:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:35.413078"
    },
    {
      "arxiv_id": "2410.07505v1",
      "title": "CrossQuant: A Post-Training Quantization Method with Smaller Quantization Kernel for Precise Large Language Model Compression",
      "title_zh": "CrossQuant：一种后训练量化方法，具有更小的量化内核，用于精确的大语言模型压缩",
      "authors": [
        "Wenyuan Liu",
        "Xindian Ma",
        "Peng Zhang",
        "Yan Wang"
      ],
      "abstract": "Post-Training Quantization (PTQ) is an effective technique for compressing\nLarge Language Models (LLMs). While many studies focus on quantizing both\nweights and activations, it is still a challenge to maintain the accuracy of\nLLM after activating quantization. To investigate the primary cause, we extend\nthe concept of kernel from linear algebra to quantization functions to define a\nnew term, \"quantization kernel\", which refers to the set of elements in\nactivations that are quantized to zero. Through quantitative analysis of the\nquantization kernel, we find that these elements are crucial for maintaining\nthe accuracy of quantized LLMs. With the decrease of quantization kernel, the\nprecision of quantized LLMs increases. If the quantization kernel proportion is\nkept below 19% for OPT models and below 1% for LLaMA models, the precision loss\nfrom quantizing activations to INT8 becomes negligible. Motivated by the goal\nof developing a quantization method with small quantization kernel, we propose\nCrossQuant: a simple yet effective method for quantizing activations.\nCrossQuant cross-quantizes elements using row and column-wise absolute maximum\nvectors, achieving a quantization kernel of approximately 16% for OPT models\nand less than 0.1% for LLaMA models. Experimental results on LLMs (LLaMA, OPT)\nranging from 6.7B to 70B parameters demonstrate that CrossQuant improves or\nmaintains perplexity and accuracy in language modeling, zero-shot, and few-shot\ntasks.",
      "tldr_zh": "该论文提出了一种名为CrossQuant的Post-Training Quantization (PTQ)方法，旨在通过最小化quantization kernel来实现大型语言模型 (LLMs) 的精确压缩，其中quantization kernel指激活中被量化为零的元素，这些元素对模型精度至关重要。研究发现，通过将quantization kernel比例控制在OPT模型低于19%和LLaMA模型低于1%，可以将激活量化到INT8时带来的精度损失降至可忽略水平。CrossQuant采用行和列向量的绝对最大值进行交叉量化，实现了OPT模型约16%和LLaMA模型小于0.1%的quantization kernel，并在6.7B到70B参数的LLMs实验中，改善或维持了perplexity以及零样本和少样本任务的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07505v1",
      "published_date": "2024-10-10 00:44:24 UTC",
      "updated_date": "2024-10-10 00:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:47.006155"
    },
    {
      "arxiv_id": "2410.07504v1",
      "title": "Using LLMs to Discover Legal Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Morgan Gray",
        "Jaromir Savelka",
        "Wesley Oliver",
        "Kevin Ashley"
      ],
      "abstract": "Factors are a foundational component of legal analysis and computational\nmodels of legal reasoning. These factor-based representations enable lawyers,\njudges, and AI and Law researchers to reason about legal cases. In this paper,\nwe introduce a methodology that leverages large language models (LLMs) to\ndiscover lists of factors that effectively represent a legal domain. Our method\ntakes as input raw court opinions and produces a set of factors and associated\ndefinitions. We demonstrate that a semi-automated approach, incorporating\nminimal human involvement, produces factor representations that can predict\ncase outcomes with moderate success, if not yet as well as expert-defined\nfactors can.",
      "tldr_zh": "本研究提出了一种利用大型语言模型（LLMs）的方法，来自动发现法律领域的关键因素（factors），以支持法律分析和计算模型。方法以原始法庭意见（raw court opinions）作为输入，通过半自动过程生成因素列表及其定义，仅需少量人类干预。该方法生成的因素表示能够中等成功地预测案件结果，尽管尚未达到专家定义因素的水平。该贡献为AI辅助法律推理提供了更高效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.07504v1",
      "published_date": "2024-10-10 00:42:10 UTC",
      "updated_date": "2024-10-10 00:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:02:57.976892"
    },
    {
      "arxiv_id": "2410.19742v1",
      "title": "SALINA: Towards Sustainable Live Sonar Analytics in Wild Ecosystems",
      "title_zh": "翻译失败",
      "authors": [
        "Chi Xu",
        "Rongsheng Qian",
        "Hao Fang",
        "Xiaoqiang Ma",
        "William I. Atlas",
        "Jiangchuan Liu",
        "Mark A. Spoljaric"
      ],
      "abstract": "Sonar radar captures visual representations of underwater objects and\nstructures using sound wave reflections, making it essential for exploration,\nmapping, and continuous surveillance in wild ecosystems. Real-time analysis of\nsonar data is crucial for time-sensitive applications, including environmental\nanomaly detection and in-season fishery management, where rapid decision-making\nis needed. However, the lack of both relevant datasets and pre-trained DNN\nmodels, coupled with resource limitations in wild environments, hinders the\neffective deployment and continuous operation of live sonar analytics.\n  We present SALINA, a sustainable live sonar analytics system designed to\naddress these challenges. SALINA enables real-time processing of acoustic sonar\ndata with spatial and temporal adaptations, and features energy-efficient\noperation through a robust energy management module. Deployed for six months at\ntwo inland rivers in British Columbia, Canada, SALINA provided continuous 24/7\nunderwater monitoring, supporting fishery stewardship and wildlife restoration\nefforts. Through extensive real-world testing, SALINA demonstrated an up to\n9.5% improvement in average precision and a 10.1% increase in tracking metrics.\nThe energy management module successfully handled extreme weather, preventing\noutages and reducing contingency costs. These results offer valuable insights\nfor long-term deployment of acoustic data systems in the wild.",
      "tldr_zh": "该研究针对野外生态系统中声纳雷达（Sonar radar）的实时分析挑战，提出 SALINA 系统，以解决数据集缺失、预训练 DNN 模型缺乏以及资源限制问题。SALINA 通过实时处理声纳数据、实现空间和时间适应，以及集成能量管理模块，确保可持续和高效操作。系统在加拿大不列颠哥伦比亚省的两条内陆河流上部署六个月，提供 24/7 监控，支持渔业管理和野生动物恢复。实验结果显示，SALINA 平均精度提升高达 9.5%、跟踪指标提高 10.1%，并有效应对极端天气，减少中断和成本，为野外声学数据系统的长期部署提供了关键见解。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "eess.SP",
      "comment": "14 pages, accepted by ACM SenSys 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19742v1",
      "published_date": "2024-10-10 00:32:28 UTC",
      "updated_date": "2024-10-10 00:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:03:11.889485"
    },
    {
      "arxiv_id": "2410.07499v1",
      "title": "Dense Optimizer : An Information Entropy-Guided Structural Search Method for Dense-like Neural Network Design",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Tianyuan",
        "Hou Libin",
        "Wang Linyuan",
        "Song Xiyu",
        "Yan Bin"
      ],
      "abstract": "Dense Convolutional Network has been continuously refined to adopt a highly\nefficient and compact architecture, owing to its lightweight and efficient\nstructure. However, the current Dense-like architectures are mainly designed\nmanually, it becomes increasingly difficult to adjust the channels and reuse\nlevel based on past experience. As such, we propose an architecture search\nmethod called Dense Optimizer that can search high-performance dense-like\nnetwork automatically. In Dense Optimizer, we view the dense network as a\nhierarchical information system, maximize the network's information entropy\nwhile constraining the distribution of the entropy across each stage via a\npower law, thereby constructing an optimization problem. We also propose a\nbranch-and-bound optimization algorithm, tightly integrates power-law principle\nwith search space scaling to solve the optimization problem efficiently. The\nsuperiority of Dense Optimizer has been validated on different computer vision\nbenchmark datasets. Specifically, Dense Optimizer completes high-quality search\nbut only costs 4 hours with one CPU. Our searched model DenseNet-OPT achieved a\ntop 1 accuracy of 84.3% on CIFAR-100, which is 5.97% higher than the original\none.",
      "tldr_zh": "该论文提出了一种名为Dense Optimizer的信息熵引导结构搜索方法，旨在自动设计高效紧凑的Dense-like神经网络架构，以克服手动调整通道和重用级别的难题。方法将Dense网络视为分层信息系统，通过最大化网络的信息熵并施加幂律约束来构建优化问题，并采用分支定界算法结合搜索空间缩放进行高效求解。实验结果显示，在CIFAR-100数据集上，搜索出的DenseNet-OPT模型实现了84.3%的top-1准确率，比原版提升5.97%，且整个搜索过程仅需4小时使用一个CPU，证明了该方法的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.07499v1",
      "published_date": "2024-10-10 00:23:34 UTC",
      "updated_date": "2024-10-10 00:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:03:22.831058"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 167,
  "processed_papers_count": 167,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T10:03:39.686626"
}